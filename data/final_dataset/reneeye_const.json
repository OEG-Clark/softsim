{"home.repos.pwc.inspect_result.reneeye_const.None.setup.NumpyExtension.__init__": [[52, 55], ["setuptools.Extension.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "__include_dirs", "=", "[", "]", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.None.setup.NumpyExtension.include_dirs": [[62, 65], ["None"], "methods", ["None"], ["", "@", "include_dirs", ".", "setter", "\n", "def", "include_dirs", "(", "self", ",", "dirs", ")", ":", "\n", "        ", "self", ".", "__include_dirs", "=", "dirs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.None.setup.write_version_py": [[19, 34], ["open", "f.read().strip", "subprocess.check_output().decode().strip", "open", "f.write", "os.path.join", "os.path.join", "f.read", "subprocess.check_output().decode", "subprocess.check_output"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "write_version_py", "(", ")", ":", "\n", "    ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "\"fairseq\"", ",", "\"version.txt\"", ")", ")", "as", "f", ":", "\n", "        ", "version", "=", "f", ".", "read", "(", ")", ".", "strip", "(", ")", "\n", "\n", "# append latest commit hash to version string", "\n", "", "try", ":", "\n", "        ", "sha", "=", "subprocess", ".", "check_output", "(", "[", "\"git\"", ",", "\"rev-parse\"", ",", "\"HEAD\"", "]", ")", ".", "decode", "(", "\"ascii\"", ")", ".", "strip", "(", ")", "\n", "version", "+=", "\"+\"", "+", "sha", "[", ":", "7", "]", "\n", "", "except", "Exception", ":", "\n", "        ", "pass", "\n", "\n", "# write version info to fairseq/version.py", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "\"fairseq\"", ",", "\"version.py\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "\"__version__ = \\\"{}\\\"\\n\"", ".", "format", "(", "version", ")", ")", "\n", "", "return", "version", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.None.setup.do_setup": [[157, 214], ["setuptools.setup", "setuptools.find_packages"], "function", ["None"], ["", "def", "do_setup", "(", "package_data", ")", ":", "\n", "    ", "setup", "(", "\n", "name", "=", "\"fairseq\"", ",", "\n", "version", "=", "version", ",", "\n", "description", "=", "\"Facebook AI Research Sequence-to-Sequence Toolkit\"", ",", "\n", "url", "=", "\"https://github.com/pytorch/fairseq\"", ",", "\n", "classifiers", "=", "[", "\n", "\"Intended Audience :: Science/Research\"", ",", "\n", "\"License :: OSI Approved :: MIT License\"", ",", "\n", "\"Programming Language :: Python :: 3.6\"", ",", "\n", "\"Topic :: Scientific/Engineering :: Artificial Intelligence\"", ",", "\n", "]", ",", "\n", "long_description", "=", "readme", ",", "\n", "long_description_content_type", "=", "\"text/markdown\"", ",", "\n", "setup_requires", "=", "[", "\n", "\"cython\"", ",", "\n", "\"numpy\"", ",", "\n", "\"setuptools>=18.0\"", ",", "\n", "]", ",", "\n", "install_requires", "=", "[", "\n", "\"cffi\"", ",", "\n", "\"cython\"", ",", "\n", "\"dataclasses\"", ",", "\n", "\"hydra-core\"", ",", "\n", "\"numpy\"", ",", "\n", "\"regex\"", ",", "\n", "\"sacrebleu>=1.4.12\"", ",", "\n", "\"torch\"", ",", "\n", "\"tqdm\"", ",", "\n", "]", ",", "\n", "dependency_links", "=", "dependency_links", ",", "\n", "packages", "=", "find_packages", "(", "\n", "exclude", "=", "[", "\n", "\"examples\"", ",", "\n", "\"examples.*\"", ",", "\n", "\"scripts\"", ",", "\n", "\"scripts.*\"", ",", "\n", "\"tests\"", ",", "\n", "\"tests.*\"", ",", "\n", "]", "\n", ")", "+", "extra_packages", ",", "\n", "package_data", "=", "package_data", ",", "\n", "ext_modules", "=", "extensions", ",", "\n", "test_suite", "=", "\"tests\"", ",", "\n", "entry_points", "=", "{", "\n", "\"console_scripts\"", ":", "[", "\n", "\"fairseq-eval-lm = fairseq_cli.eval_lm:cli_main\"", ",", "\n", "\"fairseq-generate = fairseq_cli.generate:cli_main\"", ",", "\n", "\"fairseq-interactive = fairseq_cli.interactive:cli_main\"", ",", "\n", "\"fairseq-preprocess = fairseq_cli.preprocess:cli_main\"", ",", "\n", "\"fairseq-score = fairseq_cli.score:cli_main\"", ",", "\n", "\"fairseq-train = fairseq_cli.train:cli_main\"", ",", "\n", "\"fairseq-validate = fairseq_cli.validate:cli_main\"", ",", "\n", "]", ",", "\n", "}", ",", "\n", "cmdclass", "=", "cmdclass", ",", "\n", "zip_safe", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.None.setup.get_files": [[217, 226], ["os.walk", "os.path.relpath", "file.endswith", "all_files.append", "os.path.join"], "function", ["None"], ["", "def", "get_files", "(", "path", ",", "relative_to", "=", "\"fairseq\"", ")", ":", "\n", "    ", "all_files", "=", "[", "]", "\n", "for", "root", ",", "_dirs", ",", "files", "in", "os", ".", "walk", "(", "path", ",", "followlinks", "=", "True", ")", ":", "\n", "        ", "root", "=", "os", ".", "path", ".", "relpath", "(", "root", ",", "relative_to", ")", "\n", "for", "file", "in", "files", ":", "\n", "            ", "if", "file", ".", "endswith", "(", "\".pyc\"", ")", ":", "\n", "                ", "continue", "\n", "", "all_files", ".", "append", "(", "os", ".", "path", ".", "join", "(", "root", ",", "file", ")", ")", "\n", "", "", "return", "all_files", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.validate.main": [[30, 127], ["isinstance", "fairseq.utils.import_user_module", "logger.info", "fairseq.checkpoint_utils.load_model_ensemble_and_task", "logger.info", "task.build_criterion", "task.build_criterion.eval", "fairseq.dataclass.utils.convert_namespace_to_omegaconf.dataset.valid_subset.split", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "torch.cuda.is_available", "torch.cuda.set_device", "vars", "vars.update", "task.get_batch_iterator().next_epoch_itr", "fairseq.logging.progress_bar.progress_bar", "enumerate", "progress_bar.progress_bar.print", "eval", "model.half", "model.cuda", "task.load_dataset", "task.dataset", "task.valid_step", "progress_bar.progress_bar.log", "list.append", "fairseq.distributed_utils.all_gather_list", "list", "fairseq.logging.metrics.aggregate", "task.reduce_metrics", "agg.get_smoothed_values", "getattr", "Exception", "task.get_batch_iterator", "fairseq.utils.move_to_cuda", "itertools.chain.from_iterable", "fairseq.distributed_utils.get_data_parallel_group", "fairseq.utils.resolve_max_positions", "task.max_positions", "m.max_positions"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.import_user_module", "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_model_ensemble_and_task", "home.repos.pwc.inspect_result.reneeye_const.criterions.composite_loss.CompositeLoss.build_criterion", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.next_epoch_itr", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.progress_bar", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print", "home.repos.pwc.inspect_result.reneeye_const.lightconv_layer.lightconv_layer.LightconvLayer.half", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.cuda", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyMTTask.load_dataset", "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.dataset", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.valid_step", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.all_gather_list", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.aggregate", "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.reduce_metrics", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.get_smoothed_values", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.get_batch_iterator", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.move_to_cuda", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_data_parallel_group", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.resolve_max_positions", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions"], ["def", "main", "(", "cfg", ":", "DictConfig", ",", "override_args", "=", "None", ")", ":", "\n", "    ", "if", "isinstance", "(", "cfg", ",", "Namespace", ")", ":", "\n", "        ", "cfg", "=", "convert_namespace_to_omegaconf", "(", "cfg", ")", "\n", "\n", "", "utils", ".", "import_user_module", "(", "cfg", ".", "common", ")", "\n", "\n", "assert", "(", "\n", "cfg", ".", "dataset", ".", "max_tokens", "is", "not", "None", "or", "cfg", ".", "dataset", ".", "batch_size", "is", "not", "None", "\n", ")", ",", "\"Must specify batch size either with --max-tokens or --batch-size\"", "\n", "\n", "use_fp16", "=", "cfg", ".", "common", ".", "fp16", "\n", "use_cuda", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "cfg", ".", "common", ".", "cpu", "\n", "\n", "if", "use_cuda", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "cfg", ".", "distributed_training", ".", "device_id", ")", "\n", "\n", "", "if", "override_args", "is", "not", "None", ":", "\n", "        ", "overrides", "=", "vars", "(", "override_args", ")", "\n", "overrides", ".", "update", "(", "eval", "(", "getattr", "(", "override_args", ",", "\"model_overrides\"", ",", "\"{}\"", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "overrides", "=", "None", "\n", "\n", "# Load ensemble", "\n", "", "logger", ".", "info", "(", "\"loading model(s) from {}\"", ".", "format", "(", "cfg", ".", "common_eval", ".", "path", ")", ")", "\n", "models", ",", "saved_cfg", ",", "task", "=", "checkpoint_utils", ".", "load_model_ensemble_and_task", "(", "\n", "[", "cfg", ".", "common_eval", ".", "path", "]", ",", "\n", "arg_overrides", "=", "overrides", ",", "\n", "suffix", "=", "cfg", ".", "checkpoint", ".", "checkpoint_suffix", ",", "\n", ")", "\n", "model", "=", "models", "[", "0", "]", "\n", "\n", "# Move models to GPU", "\n", "for", "model", "in", "models", ":", "\n", "        ", "if", "use_fp16", ":", "\n", "            ", "model", ".", "half", "(", ")", "\n", "", "if", "use_cuda", ":", "\n", "            ", "model", ".", "cuda", "(", ")", "\n", "\n", "# Print args", "\n", "", "", "logger", ".", "info", "(", "saved_cfg", ")", "\n", "\n", "# Build criterion", "\n", "criterion", "=", "task", ".", "build_criterion", "(", "saved_cfg", ".", "criterion", ")", "\n", "criterion", ".", "eval", "(", ")", "\n", "\n", "for", "subset", "in", "cfg", ".", "dataset", ".", "valid_subset", ".", "split", "(", "\",\"", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "task", ".", "load_dataset", "(", "subset", ",", "combine", "=", "False", ",", "epoch", "=", "1", ",", "task_cfg", "=", "saved_cfg", ".", "task", ")", "\n", "dataset", "=", "task", ".", "dataset", "(", "subset", ")", "\n", "", "except", "KeyError", ":", "\n", "            ", "raise", "Exception", "(", "\"Cannot find dataset: \"", "+", "subset", ")", "\n", "\n", "# Initialize data iterator", "\n", "", "itr", "=", "task", ".", "get_batch_iterator", "(", "\n", "dataset", "=", "dataset", ",", "\n", "max_tokens", "=", "cfg", ".", "dataset", ".", "max_tokens", ",", "\n", "max_sentences", "=", "cfg", ".", "dataset", ".", "batch_size", ",", "\n", "max_positions", "=", "utils", ".", "resolve_max_positions", "(", "\n", "task", ".", "max_positions", "(", ")", ",", "\n", "*", "[", "m", ".", "max_positions", "(", ")", "for", "m", "in", "models", "]", ",", "\n", ")", ",", "\n", "ignore_invalid_inputs", "=", "cfg", ".", "dataset", ".", "skip_invalid_size_inputs_valid_test", ",", "\n", "required_batch_size_multiple", "=", "cfg", ".", "dataset", ".", "required_batch_size_multiple", ",", "\n", "seed", "=", "cfg", ".", "common", ".", "seed", ",", "\n", "num_shards", "=", "cfg", ".", "distributed_training", ".", "distributed_world_size", ",", "\n", "shard_id", "=", "cfg", ".", "distributed_training", ".", "distributed_rank", ",", "\n", "num_workers", "=", "cfg", ".", "dataset", ".", "num_workers", ",", "\n", "data_buffer_size", "=", "cfg", ".", "dataset", ".", "data_buffer_size", ",", "\n", ")", ".", "next_epoch_itr", "(", "shuffle", "=", "False", ")", "\n", "progress", "=", "progress_bar", ".", "progress_bar", "(", "\n", "itr", ",", "\n", "log_format", "=", "cfg", ".", "common", ".", "log_format", ",", "\n", "log_interval", "=", "cfg", ".", "common", ".", "log_interval", ",", "\n", "prefix", "=", "f\"valid on '{subset}' subset\"", ",", "\n", "default_log_format", "=", "(", "\"tqdm\"", "if", "not", "cfg", ".", "common", ".", "no_progress_bar", "else", "\"simple\"", ")", ",", "\n", ")", "\n", "\n", "log_outputs", "=", "[", "]", "\n", "for", "i", ",", "sample", "in", "enumerate", "(", "progress", ")", ":", "\n", "            ", "sample", "=", "utils", ".", "move_to_cuda", "(", "sample", ")", "if", "use_cuda", "else", "sample", "\n", "_loss", ",", "_sample_size", ",", "log_output", "=", "task", ".", "valid_step", "(", "sample", ",", "model", ",", "criterion", ")", "\n", "progress", ".", "log", "(", "log_output", ",", "step", "=", "i", ")", "\n", "log_outputs", ".", "append", "(", "log_output", ")", "\n", "\n", "", "if", "cfg", ".", "distributed_training", ".", "distributed_world_size", ">", "1", ":", "\n", "            ", "log_outputs", "=", "distributed_utils", ".", "all_gather_list", "(", "\n", "log_outputs", ",", "\n", "max_size", "=", "cfg", ".", "common", ".", "all_gather_list_size", ",", "\n", "group", "=", "distributed_utils", ".", "get_data_parallel_group", "(", ")", ",", "\n", ")", "\n", "log_outputs", "=", "list", "(", "chain", ".", "from_iterable", "(", "log_outputs", ")", ")", "\n", "\n", "", "with", "metrics", ".", "aggregate", "(", ")", "as", "agg", ":", "\n", "            ", "task", ".", "reduce_metrics", "(", "log_outputs", ",", "criterion", ")", "\n", "log_output", "=", "agg", ".", "get_smoothed_values", "(", ")", "\n", "\n", "", "progress", ".", "print", "(", "log_output", ",", "tag", "=", "subset", ",", "step", "=", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.validate.cli_main": [[129, 138], ["fairseq.options.get_validation_parser", "fairseq.options.parse_args_and_arch", "fairseq.options.get_validation_parser", "fairseq.options.parse_args_and_arch", "fairseq.distributed_utils.call_main", "fairseq.dataclass.utils.convert_namespace_to_omegaconf"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.options.get_validation_parser", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.parse_args_and_arch", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.get_validation_parser", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.parse_args_and_arch", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.call_main", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.convert_namespace_to_omegaconf"], ["", "", "def", "cli_main", "(", ")", ":", "\n", "    ", "parser", "=", "options", ".", "get_validation_parser", "(", ")", "\n", "args", "=", "options", ".", "parse_args_and_arch", "(", "parser", ")", "\n", "\n", "# only override args that are explicitly given on the command line", "\n", "override_parser", "=", "options", ".", "get_validation_parser", "(", ")", "\n", "override_args", "=", "options", ".", "parse_args_and_arch", "(", "override_parser", ",", "suppress_defaults", "=", "True", ")", "\n", "\n", "distributed_utils", ".", "call_main", "(", "convert_namespace_to_omegaconf", "(", "args", ")", ",", "main", ",", "override_args", "=", "override_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.generate.main": [[28, 51], ["isinstance", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "os.makedirs", "os.path.join", "generate._main", "open", "generate._main"], "function", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.generate._main", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.generate._main"], ["def", "main", "(", "cfg", ":", "DictConfig", ")", ":", "\n", "\n", "    ", "if", "isinstance", "(", "cfg", ",", "Namespace", ")", ":", "\n", "        ", "cfg", "=", "convert_namespace_to_omegaconf", "(", "cfg", ")", "\n", "\n", "", "assert", "cfg", ".", "common_eval", ".", "path", "is", "not", "None", ",", "\"--path required for generation!\"", "\n", "assert", "(", "\n", "not", "cfg", ".", "generation", ".", "sampling", "or", "cfg", ".", "generation", ".", "nbest", "==", "cfg", ".", "generation", ".", "beam", "\n", ")", ",", "\"--sampling requires --nbest to be equal to --beam\"", "\n", "assert", "(", "\n", "cfg", ".", "generation", ".", "replace_unk", "is", "None", "or", "cfg", ".", "dataset", ".", "dataset_impl", "==", "\"raw\"", "\n", ")", ",", "\"--replace-unk requires a raw text dataset (--dataset-impl=raw)\"", "\n", "\n", "if", "cfg", ".", "common_eval", ".", "results_path", "is", "not", "None", ":", "\n", "        ", "os", ".", "makedirs", "(", "cfg", ".", "common_eval", ".", "results_path", ",", "exist_ok", "=", "True", ")", "\n", "output_path", "=", "os", ".", "path", ".", "join", "(", "\n", "cfg", ".", "common_eval", ".", "results_path", ",", "\n", "\"generate-{}.txt\"", ".", "format", "(", "cfg", ".", "dataset", ".", "gen_subset", ")", ",", "\n", ")", "\n", "with", "open", "(", "output_path", ",", "\"w\"", ",", "buffering", "=", "1", ",", "encoding", "=", "\"utf-8\"", ")", "as", "h", ":", "\n", "            ", "return", "_main", "(", "cfg", ",", "h", ")", "\n", "", "", "else", ":", "\n", "        ", "return", "_main", "(", "cfg", ",", "sys", ".", "stdout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.generate.get_symbols_to_strip_from_output": [[53, 58], ["hasattr"], "function", ["None"], ["", "", "def", "get_symbols_to_strip_from_output", "(", "generator", ")", ":", "\n", "    ", "if", "hasattr", "(", "generator", ",", "\"symbols_to_strip_from_output\"", ")", ":", "\n", "        ", "return", "generator", ".", "symbols_to_strip_from_output", "\n", "", "else", ":", "\n", "        ", "return", "{", "generator", ".", "eos", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.generate._main": [[60, 389], ["logging.basicConfig", "logging.getLogger", "fairseq.utils.import_user_module", "logging.getLogger.info", "fairseq.tasks.setup_task", "ast.literal_eval", "logging.getLogger.info", "fairseq.checkpoint_utils.load_model_ensemble", "tasks.setup_task.load_dataset", "itertools.chain", "fairseq.utils.load_align_dict", "tasks.setup_task.get_batch_iterator().next_epoch_itr", "fairseq.logging.progress_bar.progress_bar", "fairseq.logging.meters.StopwatchMeter", "tasks.setup_task.build_generator", "tasks.setup_task.build_tokenizer", "tasks.setup_task.build_bpe", "fairseq.scoring.build_scorer", "fairseq.logging.meters.TimeMeter", "logging.getLogger.info", "logging.getLogger.info", "numpy.random.seed", "fairseq.utils.set_torch_seed", "torch.cuda.is_available", "getattr", "fairseq.utils.split_paths", "model.prepare_for_inference_", "fairseq.logging.meters.StopwatchMeter.start", "tasks.setup_task.inference_step", "sum", "fairseq.logging.meters.StopwatchMeter.stop", "enumerate", "fairseq.logging.meters.TimeMeter.update", "progress_bar.progress_bar.log", "print", "os.environ.get().upper", "fairseq.checkpoint_utils.load_model_ensemble", "len", "model.half", "model.cuda", "tasks.setup_task.get_batch_iterator", "task.build_bpe.decode", "task.build_tokenizer.decode", "fairseq.utils.move_to_cuda", "sample[].tolist", "generate._main.decode_fn", "sys.stdout"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.import_user_module", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyMTTask.setup_task", "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_model_ensemble", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyMTTask.load_dataset", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.load_align_dict", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.next_epoch_itr", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.progress_bar", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.build_generator", "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.build_tokenizer", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.build_bpe", "home.repos.pwc.inspect_result.reneeye_const.scoring.__init__.build_scorer", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.prepare_for_inference_", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.start", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.inference_step", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.stop", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print", "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_model_ensemble", "home.repos.pwc.inspect_result.reneeye_const.lightconv_layer.lightconv_layer.LightconvLayer.half", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.cuda", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.get_batch_iterator", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.move_to_cuda"], ["", "", "def", "_main", "(", "cfg", ":", "DictConfig", ",", "output_file", ")", ":", "\n", "    ", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\"", ",", "\n", "datefmt", "=", "\"%Y-%m-%d %H:%M:%S\"", ",", "\n", "level", "=", "os", ".", "environ", ".", "get", "(", "\"LOGLEVEL\"", ",", "\"INFO\"", ")", ".", "upper", "(", ")", ",", "\n", "stream", "=", "output_file", ",", "\n", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "\"fairseq_cli.generate\"", ")", "\n", "\n", "utils", ".", "import_user_module", "(", "cfg", ".", "common", ")", "\n", "\n", "if", "cfg", ".", "dataset", ".", "max_tokens", "is", "None", "and", "cfg", ".", "dataset", ".", "batch_size", "is", "None", ":", "\n", "        ", "cfg", ".", "dataset", ".", "max_tokens", "=", "12000", "\n", "", "logger", ".", "info", "(", "cfg", ")", "\n", "\n", "# Fix seed for stochastic decoding", "\n", "if", "cfg", ".", "common", ".", "seed", "is", "not", "None", "and", "not", "cfg", ".", "generation", ".", "no_seed_provided", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "cfg", ".", "common", ".", "seed", ")", "\n", "utils", ".", "set_torch_seed", "(", "cfg", ".", "common", ".", "seed", ")", "\n", "\n", "", "use_cuda", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "cfg", ".", "common", ".", "cpu", "\n", "\n", "# Load dataset splits", "\n", "task", "=", "tasks", ".", "setup_task", "(", "cfg", ".", "task", ")", "\n", "\n", "\n", "# Set dictionaries", "\n", "try", ":", "\n", "        ", "src_dict", "=", "getattr", "(", "task", ",", "\"source_dictionary\"", ",", "None", ")", "\n", "", "except", "NotImplementedError", ":", "\n", "        ", "src_dict", "=", "None", "\n", "", "tgt_dict", "=", "task", ".", "target_dictionary", "\n", "\n", "overrides", "=", "ast", ".", "literal_eval", "(", "cfg", ".", "common_eval", ".", "model_overrides", ")", "\n", "\n", "# Load ensemble", "\n", "logger", ".", "info", "(", "\"loading model(s) from {}\"", ".", "format", "(", "cfg", ".", "common_eval", ".", "path", ")", ")", "\n", "models", ",", "saved_cfg", "=", "checkpoint_utils", ".", "load_model_ensemble", "(", "\n", "utils", ".", "split_paths", "(", "cfg", ".", "common_eval", ".", "path", ")", ",", "\n", "arg_overrides", "=", "overrides", ",", "\n", "task", "=", "task", ",", "\n", "suffix", "=", "cfg", ".", "checkpoint", ".", "checkpoint_suffix", ",", "\n", "strict", "=", "(", "cfg", ".", "checkpoint", ".", "checkpoint_shard_count", "==", "1", ")", ",", "\n", "num_shards", "=", "cfg", ".", "checkpoint", ".", "checkpoint_shard_count", ",", "\n", ")", "\n", "\n", "# loading the dataset should happen after the checkpoint has been loaded so we can give it the saved task config", "\n", "task", ".", "load_dataset", "(", "cfg", ".", "dataset", ".", "gen_subset", ",", "task_cfg", "=", "saved_cfg", ".", "task", ")", "\n", "\n", "if", "cfg", ".", "generation", ".", "lm_path", "is", "not", "None", ":", "\n", "        ", "overrides", "[", "\"data\"", "]", "=", "cfg", ".", "task", ".", "data", "\n", "\n", "try", ":", "\n", "            ", "lms", ",", "_", "=", "checkpoint_utils", ".", "load_model_ensemble", "(", "\n", "[", "cfg", ".", "generation", ".", "lm_path", "]", ",", "arg_overrides", "=", "overrides", ",", "task", "=", "None", "\n", ")", "\n", "", "except", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "f\"Failed to load language model! Please make sure that the language model dict is the same \"", "\n", "f\"as target dict and is located in the data dir ({cfg.task.data})\"", "\n", ")", "\n", "raise", "\n", "\n", "", "assert", "len", "(", "lms", ")", "==", "1", "\n", "", "else", ":", "\n", "        ", "lms", "=", "[", "None", "]", "\n", "\n", "# Optimize ensemble for generation", "\n", "", "for", "model", "in", "chain", "(", "models", ",", "lms", ")", ":", "\n", "        ", "if", "model", "is", "None", ":", "\n", "            ", "continue", "\n", "", "if", "cfg", ".", "common", ".", "fp16", ":", "\n", "            ", "model", ".", "half", "(", ")", "\n", "", "if", "use_cuda", "and", "not", "cfg", ".", "distributed_training", ".", "pipeline_model_parallel", ":", "\n", "            ", "model", ".", "cuda", "(", ")", "\n", "", "model", ".", "prepare_for_inference_", "(", "cfg", ")", "\n", "\n", "# Load alignment dictionary for unknown word replacement", "\n", "# (None if no unknown word replacement, empty if no path to align dictionary)", "\n", "", "align_dict", "=", "utils", ".", "load_align_dict", "(", "cfg", ".", "generation", ".", "replace_unk", ")", "\n", "\n", "# Load dataset (possibly sharded)", "\n", "itr", "=", "task", ".", "get_batch_iterator", "(", "\n", "dataset", "=", "task", ".", "dataset", "(", "cfg", ".", "dataset", ".", "gen_subset", ")", ",", "\n", "max_tokens", "=", "cfg", ".", "dataset", ".", "max_tokens", ",", "\n", "max_sentences", "=", "cfg", ".", "dataset", ".", "batch_size", ",", "\n", "max_positions", "=", "utils", ".", "resolve_max_positions", "(", "\n", "task", ".", "max_positions", "(", ")", ",", "*", "[", "m", ".", "max_positions", "(", ")", "for", "m", "in", "models", "]", "\n", ")", ",", "\n", "ignore_invalid_inputs", "=", "cfg", ".", "dataset", ".", "skip_invalid_size_inputs_valid_test", ",", "\n", "required_batch_size_multiple", "=", "cfg", ".", "dataset", ".", "required_batch_size_multiple", ",", "\n", "seed", "=", "cfg", ".", "common", ".", "seed", ",", "\n", "num_shards", "=", "cfg", ".", "distributed_training", ".", "distributed_world_size", ",", "\n", "shard_id", "=", "cfg", ".", "distributed_training", ".", "distributed_rank", ",", "\n", "num_workers", "=", "cfg", ".", "dataset", ".", "num_workers", ",", "\n", "data_buffer_size", "=", "cfg", ".", "dataset", ".", "data_buffer_size", ",", "\n", ")", ".", "next_epoch_itr", "(", "shuffle", "=", "False", ")", "\n", "progress", "=", "progress_bar", ".", "progress_bar", "(", "\n", "itr", ",", "\n", "log_format", "=", "cfg", ".", "common", ".", "log_format", ",", "\n", "log_interval", "=", "cfg", ".", "common", ".", "log_interval", ",", "\n", "default_log_format", "=", "(", "\"tqdm\"", "if", "not", "cfg", ".", "common", ".", "no_progress_bar", "else", "\"simple\"", ")", ",", "\n", ")", "\n", "\n", "# Initialize generator", "\n", "gen_timer", "=", "StopwatchMeter", "(", ")", "\n", "\n", "extra_gen_cls_kwargs", "=", "{", "\"lm_model\"", ":", "lms", "[", "0", "]", ",", "\"lm_weight\"", ":", "cfg", ".", "generation", ".", "lm_weight", "}", "\n", "generator", "=", "task", ".", "build_generator", "(", "\n", "models", ",", "cfg", ".", "generation", ",", "extra_gen_cls_kwargs", "=", "extra_gen_cls_kwargs", "\n", ")", "\n", "\n", "# Handle tokenization and BPE", "\n", "# tokenizer = encoders.build_tokenizer(cfg.tokenizer)", "\n", "# bpe = encoders.build_bpe(cfg.bpe)", "\n", "tokenizer", "=", "task", ".", "build_tokenizer", "(", "cfg", ".", "tokenizer", ")", "\n", "bpe", "=", "task", ".", "build_bpe", "(", "cfg", ".", "bpe", ")", "\n", "\n", "def", "decode_fn", "(", "x", ")", ":", "\n", "        ", "if", "bpe", "is", "not", "None", ":", "\n", "            ", "x", "=", "bpe", ".", "decode", "(", "x", ")", "\n", "", "if", "tokenizer", "is", "not", "None", ":", "\n", "            ", "x", "=", "tokenizer", ".", "decode", "(", "x", ")", "\n", "", "return", "x", "\n", "\n", "", "scorer", "=", "scoring", ".", "build_scorer", "(", "cfg", ".", "scoring", ",", "tgt_dict", ")", "\n", "\n", "num_sentences", "=", "0", "\n", "has_target", "=", "True", "\n", "wps_meter", "=", "TimeMeter", "(", ")", "\n", "for", "sample", "in", "progress", ":", "\n", "        ", "sample", "=", "utils", ".", "move_to_cuda", "(", "sample", ")", "if", "use_cuda", "else", "sample", "\n", "if", "\"net_input\"", "not", "in", "sample", ":", "\n", "            ", "continue", "\n", "\n", "", "prefix_tokens", "=", "None", "\n", "if", "cfg", ".", "generation", ".", "prefix_size", ">", "0", ":", "\n", "            ", "prefix_tokens", "=", "sample", "[", "\"target\"", "]", "[", ":", ",", ":", "cfg", ".", "generation", ".", "prefix_size", "]", "\n", "\n", "", "constraints", "=", "None", "\n", "if", "\"constraints\"", "in", "sample", ":", "\n", "            ", "constraints", "=", "sample", "[", "\"constraints\"", "]", "\n", "\n", "", "gen_timer", ".", "start", "(", ")", "\n", "hypos", "=", "task", ".", "inference_step", "(", "\n", "generator", ",", "\n", "models", ",", "\n", "sample", ",", "\n", "prefix_tokens", "=", "prefix_tokens", ",", "\n", "constraints", "=", "constraints", ",", "\n", ")", "\n", "num_generated_tokens", "=", "sum", "(", "len", "(", "h", "[", "0", "]", "[", "\"tokens\"", "]", ")", "for", "h", "in", "hypos", ")", "\n", "gen_timer", ".", "stop", "(", "num_generated_tokens", ")", "\n", "\n", "for", "i", ",", "sample_id", "in", "enumerate", "(", "sample", "[", "\"id\"", "]", ".", "tolist", "(", ")", ")", ":", "\n", "            ", "has_target", "=", "sample", "[", "\"target\"", "]", "is", "not", "None", "\n", "\n", "# Remove padding", "\n", "if", "\"src_tokens\"", "in", "sample", "[", "\"net_input\"", "]", ":", "\n", "                ", "src_tokens", "=", "utils", ".", "strip_pad", "(", "\n", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "[", "i", ",", ":", "]", ",", "tgt_dict", ".", "pad", "(", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "src_tokens", "=", "None", "\n", "\n", "", "target_tokens", "=", "None", "\n", "if", "has_target", ":", "\n", "                ", "target_tokens", "=", "(", "\n", "utils", ".", "strip_pad", "(", "sample", "[", "\"target\"", "]", "[", "i", ",", ":", "]", ",", "tgt_dict", ".", "pad", "(", ")", ")", ".", "int", "(", ")", ".", "cpu", "(", ")", "\n", ")", "\n", "\n", "# Either retrieve the original sentences or regenerate them from tokens.", "\n", "", "if", "align_dict", "is", "not", "None", ":", "\n", "                ", "src_str", "=", "task", ".", "dataset", "(", "cfg", ".", "dataset", ".", "gen_subset", ")", ".", "src", ".", "get_original_text", "(", "\n", "sample_id", "\n", ")", "\n", "target_str", "=", "task", ".", "dataset", "(", "cfg", ".", "dataset", ".", "gen_subset", ")", ".", "tgt", ".", "get_original_text", "(", "\n", "sample_id", "\n", ")", "\n", "", "else", ":", "\n", "                ", "if", "src_dict", "is", "not", "None", ":", "\n", "                    ", "src_str", "=", "src_dict", ".", "string", "(", "src_tokens", ",", "cfg", ".", "common_eval", ".", "post_process", ")", "\n", "", "else", ":", "\n", "                    ", "src_str", "=", "\"\"", "\n", "", "if", "has_target", ":", "\n", "                    ", "target_str", "=", "tgt_dict", ".", "string", "(", "\n", "target_tokens", ",", "\n", "cfg", ".", "common_eval", ".", "post_process", ",", "\n", "escape_unk", "=", "True", ",", "\n", "extra_symbols_to_ignore", "=", "get_symbols_to_strip_from_output", "(", "\n", "generator", "\n", ")", ",", "\n", ")", "\n", "\n", "", "", "src_str", "=", "decode_fn", "(", "src_str", ")", "\n", "if", "has_target", ":", "\n", "                ", "target_str", "=", "decode_fn", "(", "target_str", ")", "\n", "\n", "", "if", "not", "cfg", ".", "common_eval", ".", "quiet", ":", "\n", "                ", "if", "src_dict", "is", "not", "None", ":", "\n", "                    ", "print", "(", "\"S-{}\\t{}\"", ".", "format", "(", "sample_id", ",", "src_str", ")", ",", "file", "=", "output_file", ")", "\n", "", "if", "has_target", ":", "\n", "                    ", "print", "(", "\"T-{}\\t{}\"", ".", "format", "(", "sample_id", ",", "target_str", ")", ",", "file", "=", "output_file", ")", "\n", "\n", "# Process top predictions", "\n", "", "", "for", "j", ",", "hypo", "in", "enumerate", "(", "hypos", "[", "i", "]", "[", ":", "cfg", ".", "generation", ".", "nbest", "]", ")", ":", "\n", "                ", "hypo_tokens", ",", "hypo_str", ",", "alignment", "=", "utils", ".", "post_process_prediction", "(", "\n", "hypo_tokens", "=", "hypo", "[", "\"tokens\"", "]", ".", "int", "(", ")", ".", "cpu", "(", ")", ",", "\n", "src_str", "=", "src_str", ",", "\n", "alignment", "=", "hypo", "[", "\"alignment\"", "]", ",", "\n", "align_dict", "=", "align_dict", ",", "\n", "tgt_dict", "=", "tgt_dict", ",", "\n", "remove_bpe", "=", "cfg", ".", "common_eval", ".", "post_process", ",", "\n", "extra_symbols_to_ignore", "=", "get_symbols_to_strip_from_output", "(", "generator", ")", ",", "\n", ")", "\n", "detok_hypo_str", "=", "decode_fn", "(", "hypo_str", ")", "\n", "if", "not", "cfg", ".", "common_eval", ".", "quiet", ":", "\n", "                    ", "score", "=", "hypo", "[", "\"score\"", "]", "/", "math", ".", "log", "(", "2", ")", "# convert to base 2", "\n", "# original hypothesis (after tokenization and BPE)", "\n", "print", "(", "\n", "\"H-{}\\t{}\\t{}\"", ".", "format", "(", "sample_id", ",", "score", ",", "hypo_str", ")", ",", "\n", "file", "=", "output_file", ",", "\n", ")", "\n", "# detokenized hypothesis", "\n", "print", "(", "\n", "\"D-{}\\t{}\\t{}\"", ".", "format", "(", "sample_id", ",", "score", ",", "detok_hypo_str", ")", ",", "\n", "file", "=", "output_file", ",", "\n", ")", "\n", "print", "(", "\n", "\"P-{}\\t{}\"", ".", "format", "(", "\n", "sample_id", ",", "\n", "\" \"", ".", "join", "(", "\n", "map", "(", "\n", "lambda", "x", ":", "\"{:.4f}\"", ".", "format", "(", "x", ")", ",", "\n", "# convert from base e to base 2", "\n", "hypo", "[", "\"positional_scores\"", "]", "\n", ".", "div_", "(", "math", ".", "log", "(", "2", ")", ")", "\n", ".", "tolist", "(", ")", ",", "\n", ")", "\n", ")", ",", "\n", ")", ",", "\n", "file", "=", "output_file", ",", "\n", ")", "\n", "\n", "if", "cfg", ".", "generation", ".", "print_alignment", ":", "\n", "                        ", "print", "(", "\n", "\"A-{}\\t{}\"", ".", "format", "(", "\n", "sample_id", ",", "\n", "\" \"", ".", "join", "(", "\n", "[", "\n", "\"{}-{}\"", ".", "format", "(", "src_idx", ",", "tgt_idx", ")", "\n", "for", "src_idx", ",", "tgt_idx", "in", "alignment", "\n", "]", "\n", ")", ",", "\n", ")", ",", "\n", "file", "=", "output_file", ",", "\n", ")", "\n", "\n", "", "if", "cfg", ".", "generation", ".", "print_step", ":", "\n", "                        ", "print", "(", "\n", "\"I-{}\\t{}\"", ".", "format", "(", "sample_id", ",", "hypo", "[", "\"steps\"", "]", ")", ",", "\n", "file", "=", "output_file", ",", "\n", ")", "\n", "\n", "", "if", "cfg", ".", "generation", ".", "retain_iter_history", ":", "\n", "                        ", "for", "step", ",", "h", "in", "enumerate", "(", "hypo", "[", "\"history\"", "]", ")", ":", "\n", "                            ", "_", ",", "h_str", ",", "_", "=", "utils", ".", "post_process_prediction", "(", "\n", "hypo_tokens", "=", "h", "[", "\"tokens\"", "]", ".", "int", "(", ")", ".", "cpu", "(", ")", ",", "\n", "src_str", "=", "src_str", ",", "\n", "alignment", "=", "None", ",", "\n", "align_dict", "=", "None", ",", "\n", "tgt_dict", "=", "tgt_dict", ",", "\n", "remove_bpe", "=", "None", ",", "\n", ")", "\n", "print", "(", "\n", "\"E-{}_{}\\t{}\"", ".", "format", "(", "sample_id", ",", "step", ",", "h_str", ")", ",", "\n", "file", "=", "output_file", ",", "\n", ")", "\n", "\n", "# Score only the top hypothesis", "\n", "", "", "", "if", "has_target", "and", "j", "==", "0", ":", "\n", "                    ", "if", "align_dict", "is", "not", "None", "or", "cfg", ".", "common_eval", ".", "post_process", "is", "not", "None", ":", "\n", "# Convert back to tokens for evaluation with unk replacement and/or without BPE", "\n", "                        ", "target_tokens", "=", "tgt_dict", ".", "encode_line", "(", "\n", "target_str", ",", "add_if_not_exist", "=", "True", "\n", ")", "\n", "hypo_tokens", "=", "tgt_dict", ".", "encode_line", "(", "\n", "detok_hypo_str", ",", "add_if_not_exist", "=", "True", "\n", ")", "\n", "", "if", "hasattr", "(", "scorer", ",", "\"add_string\"", ")", ":", "\n", "                        ", "scorer", ".", "add_string", "(", "target_str", ",", "detok_hypo_str", ")", "\n", "", "else", ":", "\n", "                        ", "scorer", ".", "add", "(", "target_tokens", ",", "hypo_tokens", ")", "\n", "\n", "", "", "", "", "wps_meter", ".", "update", "(", "num_generated_tokens", ")", "\n", "progress", ".", "log", "(", "{", "\"wps\"", ":", "round", "(", "wps_meter", ".", "avg", ")", "}", ")", "\n", "num_sentences", "+=", "(", "\n", "sample", "[", "\"nsentences\"", "]", "if", "\"nsentences\"", "in", "sample", "else", "sample", "[", "\"id\"", "]", ".", "numel", "(", ")", "\n", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"NOTE: hypothesis and token scores are output in base 2\"", ")", "\n", "logger", ".", "info", "(", "\n", "\"Translated {} sentences ({} tokens) in {:.1f}s ({:.2f} sentences/s, {:.2f} tokens/s)\"", ".", "format", "(", "\n", "num_sentences", ",", "\n", "gen_timer", ".", "n", ",", "\n", "gen_timer", ".", "sum", ",", "\n", "num_sentences", "/", "gen_timer", ".", "sum", ",", "\n", "1.0", "/", "gen_timer", ".", "avg", ",", "\n", ")", "\n", ")", "\n", "if", "has_target", ":", "\n", "        ", "if", "cfg", ".", "bpe", "and", "not", "cfg", ".", "generation", ".", "sacrebleu", ":", "\n", "            ", "if", "cfg", ".", "common_eval", ".", "post_process", ":", "\n", "                ", "logger", ".", "warning", "(", "\n", "\"BLEU score is being computed by splitting detokenized string on spaces, this is probably not what you want. Use --sacrebleu for standard 13a BLEU tokenization\"", "\n", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "warning", "(", "\n", "\"If you are using BPE on the target side, the BLEU score is computed on BPE tokens, not on proper words.  Use --sacrebleu for standard 13a BLEU tokenization\"", "\n", ")", "\n", "# use print to be consistent with other main outputs: S-, H-, T-, D- and so on", "\n", "", "", "print", "(", "\n", "\"Generate {} with beam={}: {}\"", ".", "format", "(", "\n", "cfg", ".", "dataset", ".", "gen_subset", ",", "cfg", ".", "generation", ".", "beam", ",", "scorer", ".", "result_string", "(", ")", "\n", ")", ",", "\n", "file", "=", "output_file", ",", "\n", ")", "\n", "\n", "", "return", "scorer", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.generate.cli_main": [[391, 395], ["fairseq.options.get_generation_parser", "fairseq.options.parse_args_and_arch", "generate.main"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.options.get_generation_parser", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.parse_args_and_arch", "home.repos.pwc.inspect_result.reneeye_const.scripts.average_checkpoints.main"], ["", "def", "cli_main", "(", ")", ":", "\n", "    ", "parser", "=", "options", ".", "get_generation_parser", "(", ")", "\n", "args", "=", "options", ".", "parse_args_and_arch", "(", "parser", ")", "\n", "main", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.interactive.buffered_read": [[43, 54], ["fileinput.input", "len", "buffer.append", "fileinput.hook_encoded", "src_str.strip", "len"], "function", ["None"], ["def", "buffered_read", "(", "input", ",", "buffer_size", ")", ":", "\n", "    ", "buffer", "=", "[", "]", "\n", "with", "fileinput", ".", "input", "(", "files", "=", "[", "input", "]", ",", "openhook", "=", "fileinput", ".", "hook_encoded", "(", "\"utf-8\"", ")", ")", "as", "h", ":", "\n", "        ", "for", "src_str", "in", "h", ":", "\n", "            ", "buffer", ".", "append", "(", "src_str", ".", "strip", "(", ")", ")", "\n", "if", "len", "(", "buffer", ")", ">=", "buffer_size", ":", "\n", "                ", "yield", "buffer", "\n", "buffer", "=", "[", "]", "\n", "\n", "", "", "", "if", "len", "(", "buffer", ")", ">", "0", ":", "\n", "        ", "yield", "buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.interactive.make_batches": [[56, 112], ["task.get_batch_iterator().next_epoch_itr", "interactive.main.encode_fn", "enumerate", "enumerate", "task.source_dictionary.encode_line().long", "fairseq.token_generation_constraints.pack_constraints", "t.numel", "batch.get", "list", "task.get_batch_iterator", "Batch", "line.split", "task.target_dictionary.encode_line", "task.source_dictionary.encode_line", "interactive.make_batches.encode_fn_target"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.next_epoch_itr", "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.pack_constraints", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.get_batch_iterator", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.encode_line", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.encode_line"], ["", "", "def", "make_batches", "(", "lines", ",", "cfg", ",", "task", ",", "max_positions", ",", "encode_fn", ")", ":", "\n", "    ", "def", "encode_fn_target", "(", "x", ")", ":", "\n", "        ", "return", "encode_fn", "(", "x", ")", "\n", "\n", "", "if", "cfg", ".", "generation", ".", "constraints", ":", "\n", "# Strip (tab-delimited) contraints, if present, from input lines,", "\n", "# store them in batch_constraints", "\n", "        ", "batch_constraints", "=", "[", "list", "(", ")", "for", "_", "in", "lines", "]", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "\"\\t\"", "in", "line", ":", "\n", "                ", "lines", "[", "i", "]", ",", "*", "batch_constraints", "[", "i", "]", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "\n", "# Convert each List[str] to List[Tensor]", "\n", "", "", "for", "i", ",", "constraint_list", "in", "enumerate", "(", "batch_constraints", ")", ":", "\n", "            ", "batch_constraints", "[", "i", "]", "=", "[", "\n", "task", ".", "target_dictionary", ".", "encode_line", "(", "\n", "encode_fn_target", "(", "constraint", ")", ",", "\n", "append_eos", "=", "False", ",", "\n", "add_if_not_exist", "=", "False", ",", "\n", ")", "\n", "for", "constraint", "in", "constraint_list", "\n", "]", "\n", "\n", "", "", "tokens", "=", "[", "\n", "task", ".", "source_dictionary", ".", "encode_line", "(", "\n", "encode_fn", "(", "src_str", ")", ",", "add_if_not_exist", "=", "False", "\n", ")", ".", "long", "(", ")", "\n", "for", "src_str", "in", "lines", "\n", "]", "\n", "\n", "if", "cfg", ".", "generation", ".", "constraints", ":", "\n", "        ", "constraints_tensor", "=", "pack_constraints", "(", "batch_constraints", ")", "\n", "", "else", ":", "\n", "        ", "constraints_tensor", "=", "None", "\n", "\n", "", "lengths", "=", "[", "t", ".", "numel", "(", ")", "for", "t", "in", "tokens", "]", "\n", "itr", "=", "task", ".", "get_batch_iterator", "(", "\n", "dataset", "=", "task", ".", "build_dataset_for_inference", "(", "\n", "tokens", ",", "lengths", ",", "constraints", "=", "constraints_tensor", "\n", ")", ",", "\n", "max_tokens", "=", "cfg", ".", "dataset", ".", "max_tokens", ",", "\n", "max_sentences", "=", "cfg", ".", "dataset", ".", "batch_size", ",", "\n", "max_positions", "=", "max_positions", ",", "\n", "ignore_invalid_inputs", "=", "cfg", ".", "dataset", ".", "skip_invalid_size_inputs_valid_test", ",", "\n", ")", ".", "next_epoch_itr", "(", "shuffle", "=", "False", ")", "\n", "for", "batch", "in", "itr", ":", "\n", "        ", "ids", "=", "batch", "[", "\"id\"", "]", "\n", "src_tokens", "=", "batch", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "\n", "src_lengths", "=", "batch", "[", "\"net_input\"", "]", "[", "\"src_lengths\"", "]", "\n", "constraints", "=", "batch", ".", "get", "(", "\"constraints\"", ",", "None", ")", "\n", "\n", "yield", "Batch", "(", "\n", "ids", "=", "ids", ",", "\n", "src_tokens", "=", "src_tokens", ",", "\n", "src_lengths", "=", "src_lengths", ",", "\n", "constraints", "=", "constraints", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.interactive.main": [[115, 311], ["isinstance", "time.time", "fairseq.utils.import_user_module", "logger.info", "fairseq.tasks.setup_task", "ast.literal_eval", "logger.info", "fairseq.checkpoint_utils.load_model_ensemble", "tasks.setup_task.build_generator", "fairseq.data.encoders.build_tokenizer", "fairseq.data.encoders.build_bpe", "fairseq.utils.load_align_dict", "fairseq.utils.resolve_max_positions", "logger.info", "logger.info", "interactive.buffered_read", "logger.info", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "numpy.random.seed", "fairseq.utils.set_torch_seed", "torch.cuda.is_available", "fairseq.utils.split_paths", "model.prepare_for_inference_", "tasks.setup_task.max_positions", "logger.warning", "logger.info", "interactive.make_batches", "sorted", "len", "model.half", "model.cuda", "encoders.build_tokenizer.encode", "encoders.build_bpe.encode", "encoders.build_bpe.decode", "encoders.build_tokenizer.decode", "batch.src_tokens.size", "time.time", "tasks.setup_task.inference_step", "enumerate", "model.max_positions", "src_tokens.cuda.cuda", "src_lengths.cuda.cuda", "time.time", "zip", "fairseq.utils.strip_pad", "results.append", "src_dict.string", "print", "print", "fairseq.utils.post_process_prediction", "interactive.main.decode_fn"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.import_user_module", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyMTTask.setup_task", "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_model_ensemble", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.build_generator", "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.build_tokenizer", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.build_bpe", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.load_align_dict", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.resolve_max_positions", "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.interactive.buffered_read", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.prepare_for_inference_", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions", "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.interactive.make_batches", "home.repos.pwc.inspect_result.reneeye_const.lightconv_layer.lightconv_layer.LightconvLayer.half", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.cuda", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.inference_step", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.cuda", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.cuda", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.strip_pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.post_process_prediction"], ["", "", "def", "main", "(", "cfg", ":", "FairseqConfig", ")", ":", "\n", "    ", "if", "isinstance", "(", "cfg", ",", "Namespace", ")", ":", "\n", "        ", "cfg", "=", "convert_namespace_to_omegaconf", "(", "cfg", ")", "\n", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "total_translate_time", "=", "0", "\n", "\n", "utils", ".", "import_user_module", "(", "cfg", ".", "common", ")", "\n", "\n", "if", "cfg", ".", "interactive", ".", "buffer_size", "<", "1", ":", "\n", "        ", "cfg", ".", "interactive", ".", "buffer_size", "=", "1", "\n", "", "if", "cfg", ".", "dataset", ".", "max_tokens", "is", "None", "and", "cfg", ".", "dataset", ".", "batch_size", "is", "None", ":", "\n", "        ", "cfg", ".", "dataset", ".", "batch_size", "=", "1", "\n", "\n", "", "assert", "(", "\n", "not", "cfg", ".", "generation", ".", "sampling", "or", "cfg", ".", "generation", ".", "nbest", "==", "cfg", ".", "generation", ".", "beam", "\n", ")", ",", "\"--sampling requires --nbest to be equal to --beam\"", "\n", "assert", "(", "\n", "not", "cfg", ".", "dataset", ".", "batch_size", "\n", "or", "cfg", ".", "dataset", ".", "batch_size", "<=", "cfg", ".", "interactive", ".", "buffer_size", "\n", ")", ",", "\"--batch-size cannot be larger than --buffer-size\"", "\n", "\n", "logger", ".", "info", "(", "cfg", ")", "\n", "\n", "# Fix seed for stochastic decoding", "\n", "if", "cfg", ".", "common", ".", "seed", "is", "not", "None", "and", "not", "cfg", ".", "generation", ".", "no_seed_provided", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "cfg", ".", "common", ".", "seed", ")", "\n", "utils", ".", "set_torch_seed", "(", "cfg", ".", "common", ".", "seed", ")", "\n", "\n", "", "use_cuda", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "cfg", ".", "common", ".", "cpu", "\n", "\n", "# Setup task, e.g., translation", "\n", "task", "=", "tasks", ".", "setup_task", "(", "cfg", ".", "task", ")", "\n", "\n", "# Load ensemble", "\n", "overrides", "=", "ast", ".", "literal_eval", "(", "cfg", ".", "common_eval", ".", "model_overrides", ")", "\n", "logger", ".", "info", "(", "\"loading model(s) from {}\"", ".", "format", "(", "cfg", ".", "common_eval", ".", "path", ")", ")", "\n", "models", ",", "_model_args", "=", "checkpoint_utils", ".", "load_model_ensemble", "(", "\n", "utils", ".", "split_paths", "(", "cfg", ".", "common_eval", ".", "path", ")", ",", "\n", "arg_overrides", "=", "overrides", ",", "\n", "task", "=", "task", ",", "\n", "suffix", "=", "cfg", ".", "checkpoint", ".", "checkpoint_suffix", ",", "\n", "strict", "=", "(", "cfg", ".", "checkpoint", ".", "checkpoint_shard_count", "==", "1", ")", ",", "\n", "num_shards", "=", "cfg", ".", "checkpoint", ".", "checkpoint_shard_count", ",", "\n", ")", "\n", "\n", "# Set dictionaries", "\n", "src_dict", "=", "task", ".", "source_dictionary", "\n", "tgt_dict", "=", "task", ".", "target_dictionary", "\n", "\n", "# Optimize ensemble for generation", "\n", "for", "model", "in", "models", ":", "\n", "        ", "if", "model", "is", "None", ":", "\n", "            ", "continue", "\n", "", "if", "cfg", ".", "common", ".", "fp16", ":", "\n", "            ", "model", ".", "half", "(", ")", "\n", "", "if", "use_cuda", "and", "not", "cfg", ".", "distributed_training", ".", "pipeline_model_parallel", ":", "\n", "            ", "model", ".", "cuda", "(", ")", "\n", "", "model", ".", "prepare_for_inference_", "(", "cfg", ")", "\n", "\n", "# Initialize generator", "\n", "", "generator", "=", "task", ".", "build_generator", "(", "models", ",", "cfg", ".", "task", ")", "\n", "\n", "# Handle tokenization and BPE", "\n", "tokenizer", "=", "encoders", ".", "build_tokenizer", "(", "cfg", ".", "tokenizer", ")", "\n", "bpe", "=", "encoders", ".", "build_bpe", "(", "cfg", ".", "bpe", ")", "\n", "\n", "def", "encode_fn", "(", "x", ")", ":", "\n", "        ", "if", "tokenizer", "is", "not", "None", ":", "\n", "            ", "x", "=", "tokenizer", ".", "encode", "(", "x", ")", "\n", "", "if", "bpe", "is", "not", "None", ":", "\n", "            ", "x", "=", "bpe", ".", "encode", "(", "x", ")", "\n", "", "return", "x", "\n", "\n", "", "def", "decode_fn", "(", "x", ")", ":", "\n", "        ", "if", "bpe", "is", "not", "None", ":", "\n", "            ", "x", "=", "bpe", ".", "decode", "(", "x", ")", "\n", "", "if", "tokenizer", "is", "not", "None", ":", "\n", "            ", "x", "=", "tokenizer", ".", "decode", "(", "x", ")", "\n", "", "return", "x", "\n", "\n", "# Load alignment dictionary for unknown word replacement", "\n", "# (None if no unknown word replacement, empty if no path to align dictionary)", "\n", "", "align_dict", "=", "utils", ".", "load_align_dict", "(", "cfg", ".", "generation", ".", "replace_unk", ")", "\n", "\n", "max_positions", "=", "utils", ".", "resolve_max_positions", "(", "\n", "task", ".", "max_positions", "(", ")", ",", "*", "[", "model", ".", "max_positions", "(", ")", "for", "model", "in", "models", "]", "\n", ")", "\n", "\n", "if", "cfg", ".", "generation", ".", "constraints", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "\"NOTE: Constrained decoding currently assumes a shared subword vocabulary.\"", "\n", ")", "\n", "\n", "", "if", "cfg", ".", "interactive", ".", "buffer_size", ">", "1", ":", "\n", "        ", "logger", ".", "info", "(", "\"Sentence buffer size: %s\"", ",", "cfg", ".", "interactive", ".", "buffer_size", ")", "\n", "", "logger", ".", "info", "(", "\"NOTE: hypothesis and token scores are output in base 2\"", ")", "\n", "logger", ".", "info", "(", "\"Type the input sentence and press return:\"", ")", "\n", "start_id", "=", "0", "\n", "for", "inputs", "in", "buffered_read", "(", "cfg", ".", "interactive", ".", "input", ",", "cfg", ".", "interactive", ".", "buffer_size", ")", ":", "\n", "        ", "results", "=", "[", "]", "\n", "for", "batch", "in", "make_batches", "(", "inputs", ",", "cfg", ",", "task", ",", "max_positions", ",", "encode_fn", ")", ":", "\n", "            ", "bsz", "=", "batch", ".", "src_tokens", ".", "size", "(", "0", ")", "\n", "src_tokens", "=", "batch", ".", "src_tokens", "\n", "src_lengths", "=", "batch", ".", "src_lengths", "\n", "constraints", "=", "batch", ".", "constraints", "\n", "if", "use_cuda", ":", "\n", "                ", "src_tokens", "=", "src_tokens", ".", "cuda", "(", ")", "\n", "src_lengths", "=", "src_lengths", ".", "cuda", "(", ")", "\n", "if", "constraints", "is", "not", "None", ":", "\n", "                    ", "constraints", "=", "constraints", ".", "cuda", "(", ")", "\n", "\n", "", "", "sample", "=", "{", "\n", "\"net_input\"", ":", "{", "\n", "\"src_tokens\"", ":", "src_tokens", ",", "\n", "\"src_lengths\"", ":", "src_lengths", ",", "\n", "}", ",", "\n", "}", "\n", "translate_start_time", "=", "time", ".", "time", "(", ")", "\n", "translations", "=", "task", ".", "inference_step", "(", "\n", "generator", ",", "models", ",", "sample", ",", "constraints", "=", "constraints", "\n", ")", "\n", "translate_time", "=", "time", ".", "time", "(", ")", "-", "translate_start_time", "\n", "total_translate_time", "+=", "translate_time", "\n", "list_constraints", "=", "[", "[", "]", "for", "_", "in", "range", "(", "bsz", ")", "]", "\n", "if", "cfg", ".", "generation", ".", "constraints", ":", "\n", "                ", "list_constraints", "=", "[", "unpack_constraints", "(", "c", ")", "for", "c", "in", "constraints", "]", "\n", "", "for", "i", ",", "(", "id", ",", "hypos", ")", "in", "enumerate", "(", "zip", "(", "batch", ".", "ids", ".", "tolist", "(", ")", ",", "translations", ")", ")", ":", "\n", "                ", "src_tokens_i", "=", "utils", ".", "strip_pad", "(", "src_tokens", "[", "i", "]", ",", "tgt_dict", ".", "pad", "(", ")", ")", "\n", "constraints", "=", "list_constraints", "[", "i", "]", "\n", "results", ".", "append", "(", "\n", "(", "\n", "start_id", "+", "id", ",", "\n", "src_tokens_i", ",", "\n", "hypos", ",", "\n", "{", "\n", "\"constraints\"", ":", "constraints", ",", "\n", "\"time\"", ":", "translate_time", "/", "len", "(", "translations", ")", ",", "\n", "}", ",", "\n", ")", "\n", ")", "\n", "\n", "# sort output to match input order", "\n", "", "", "for", "id_", ",", "src_tokens", ",", "hypos", ",", "info", "in", "sorted", "(", "results", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", ":", "\n", "            ", "if", "src_dict", "is", "not", "None", ":", "\n", "                ", "src_str", "=", "src_dict", ".", "string", "(", "src_tokens", ",", "cfg", ".", "common_eval", ".", "post_process", ")", "\n", "print", "(", "\"S-{}\\t{}\"", ".", "format", "(", "id_", ",", "src_str", ")", ")", "\n", "print", "(", "\"W-{}\\t{:.3f}\\tseconds\"", ".", "format", "(", "id_", ",", "info", "[", "\"time\"", "]", ")", ")", "\n", "for", "constraint", "in", "info", "[", "\"constraints\"", "]", ":", "\n", "                    ", "print", "(", "\n", "\"C-{}\\t{}\"", ".", "format", "(", "\n", "id_", ",", "tgt_dict", ".", "string", "(", "constraint", ",", "cfg", ".", "common_eval", ".", "post_process", ")", "\n", ")", "\n", ")", "\n", "\n", "# Process top predictions", "\n", "", "", "for", "hypo", "in", "hypos", "[", ":", "min", "(", "len", "(", "hypos", ")", ",", "cfg", ".", "generation", ".", "nbest", ")", "]", ":", "\n", "                ", "hypo_tokens", ",", "hypo_str", ",", "alignment", "=", "utils", ".", "post_process_prediction", "(", "\n", "hypo_tokens", "=", "hypo", "[", "\"tokens\"", "]", ".", "int", "(", ")", ".", "cpu", "(", ")", ",", "\n", "src_str", "=", "src_str", ",", "\n", "alignment", "=", "hypo", "[", "\"alignment\"", "]", ",", "\n", "align_dict", "=", "align_dict", ",", "\n", "tgt_dict", "=", "tgt_dict", ",", "\n", "remove_bpe", "=", "cfg", ".", "common_eval", ".", "post_process", ",", "\n", "extra_symbols_to_ignore", "=", "get_symbols_to_strip_from_output", "(", "generator", ")", ",", "\n", ")", "\n", "detok_hypo_str", "=", "decode_fn", "(", "hypo_str", ")", "\n", "score", "=", "hypo", "[", "\"score\"", "]", "/", "math", ".", "log", "(", "2", ")", "# convert to base 2", "\n", "# original hypothesis (after tokenization and BPE)", "\n", "print", "(", "\"H-{}\\t{}\\t{}\"", ".", "format", "(", "id_", ",", "score", ",", "hypo_str", ")", ")", "\n", "# detokenized hypothesis", "\n", "print", "(", "\"D-{}\\t{}\\t{}\"", ".", "format", "(", "id_", ",", "score", ",", "detok_hypo_str", ")", ")", "\n", "print", "(", "\n", "\"P-{}\\t{}\"", ".", "format", "(", "\n", "id_", ",", "\n", "\" \"", ".", "join", "(", "\n", "map", "(", "\n", "lambda", "x", ":", "\"{:.4f}\"", ".", "format", "(", "x", ")", ",", "\n", "# convert from base e to base 2", "\n", "hypo", "[", "\"positional_scores\"", "]", ".", "div_", "(", "math", ".", "log", "(", "2", ")", ")", ".", "tolist", "(", ")", ",", "\n", ")", "\n", ")", ",", "\n", ")", "\n", ")", "\n", "if", "cfg", ".", "generation", ".", "print_alignment", ":", "\n", "                    ", "alignment_str", "=", "\" \"", ".", "join", "(", "\n", "[", "\"{}-{}\"", ".", "format", "(", "src", ",", "tgt", ")", "for", "src", ",", "tgt", "in", "alignment", "]", "\n", ")", "\n", "print", "(", "\"A-{}\\t{}\"", ".", "format", "(", "id_", ",", "alignment_str", ")", ")", "\n", "\n", "# update running id_ counter", "\n", "", "", "", "start_id", "+=", "len", "(", "inputs", ")", "\n", "\n", "", "logger", ".", "info", "(", "\n", "\"Total time: {:.3f} seconds; translation time: {:.3f}\"", ".", "format", "(", "\n", "time", ".", "time", "(", ")", "-", "start_time", ",", "total_translate_time", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.interactive.cli_main": [[315, 319], ["fairseq.options.get_interactive_generation_parser", "fairseq.options.parse_args_and_arch", "fairseq.distributed_utils.call_main", "fairseq.dataclass.utils.convert_namespace_to_omegaconf"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.options.get_interactive_generation_parser", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.parse_args_and_arch", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.call_main", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.convert_namespace_to_omegaconf"], ["", "def", "cli_main", "(", ")", ":", "\n", "    ", "parser", "=", "options", ".", "get_interactive_generation_parser", "(", ")", "\n", "args", "=", "options", ".", "parse_args_and_arch", "(", "parser", ")", "\n", "distributed_utils", ".", "call_main", "(", "convert_namespace_to_omegaconf", "(", "args", ")", ",", "main", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.main": [[45, 147], ["isinstance", "fairseq.utils.import_user_module", "fairseq.logging.metrics.reset", "numpy.random.seed", "fairseq.utils.set_torch_seed", "fairseq.distributed_utils.is_master", "logger.info", "omegaconf.OmegaConf.save", "fairseq.tasks.setup_task", "fairseq.dataclass.utils.convert_namespace_to_omegaconf.dataset.valid_subset.split", "tasks.setup_task.build_model", "tasks.setup_task.build_criterion", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "fairseq.checkpoint_utils.load_checkpoint", "fairseq.model_parallel.megatron_trainer.MegatronTrainer.get_lr", "fairseq.logging.meters.StopwatchMeter", "meters.StopwatchMeter.start", "meters.StopwatchMeter.stop", "logger.info", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "fairseq.checkpoint_utils.verify_checkpoint_directory", "tasks.setup_task.load_dataset", "fairseq.quantization_utils.Quantizer", "fairseq.trainer.Trainer", "fairseq.model_parallel.megatron_trainer.MegatronTrainer", "train.train", "fairseq.model_parallel.megatron_trainer.MegatronTrainer.lr_step", "fairseq.model_parallel.megatron_trainer.MegatronTrainer.get_train_iterator", "sum", "sum", "tasks.setup_task.has_sharded_data", "tasks.setup_task.has_sharded_data", "tasks.setup_task.has_sharded_data", "p.numel", "p.numel", "task.build_model.parameters", "task.build_model.parameters"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.import_user_module", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.reset", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.is_master", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.save", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyMTTask.setup_task", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model", "home.repos.pwc.inspect_result.reneeye_const.criterions.composite_loss.CompositeLoss.build_criterion", "home.repos.pwc.inspect_result.reneeye_const.model_parallel.megatron_trainer.MegatronTrainer.load_checkpoint", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.start", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.stop", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.verify_checkpoint_directory", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyMTTask.load_dataset", "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.train", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.lr_step", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_train_iterator", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.has_sharded_data", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.has_sharded_data", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.has_sharded_data"], []], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.should_stop_early": [[149, 175], ["getattr", "train.should_stop_early.is_better"], "function", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.train": [[177, 249], ["fairseq.logging.metrics.aggregate", "epoch_itr.next_epoch_itr", "fairseq.data.iterators.GroupedIterator", "getattr", "fairseq.logging.progress_bar.progress_bar", "trainer.begin_epoch", "cfg.dataset.valid_subset.split", "trainer.get_num_updates", "enumerate", "logger.info", "train.get_training_stats", "progress_bar.progress_bar.print", "fairseq.logging.metrics.reset_meters", "fairseq.utils.tpu_data_loader", "train.validate_and_save", "fairseq.logging.metrics.get_smoothed_values", "len", "fairseq.logging.metrics.aggregate", "torch.autograd.profiler.record_function", "trainer.train_step", "trainer.get_num_updates", "utils.tpu_data_loader.has_next", "fairseq.distributed_utils.is_master", "fairseq.distributed_utils.is_master", "train.get_training_stats", "progress_bar.progress_bar.log", "fairseq.logging.metrics.reset_meters", "fairseq.logging.metrics.get_smoothed_values"], "function", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.aggregate", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.next_epoch_itr", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.progress_bar", "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.begin_epoch", "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.get_training_stats", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.reset_meters", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.tpu_data_loader", "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.validate_and_save", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.get_smoothed_values", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.aggregate", "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.train_step", "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.CountingIterator.has_next", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.is_master", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.is_master", "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.get_training_stats", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.reset_meters", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.get_smoothed_values"], []], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.validate_and_save": [[251, 319], ["trainer.get_num_updates", "train.validate", "train.should_stop_early", "logger.info", "fairseq.checkpoint_utils.save_checkpoint", "trainer.get_num_updates", "int", "os.path.join", "logger.info", "trainer.cumulative_training_time"], "function", ["home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.validate", "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.should_stop_early", "home.repos.pwc.inspect_result.reneeye_const.model_parallel.megatron_trainer.MegatronTrainer.save_checkpoint", "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.cumulative_training_time"], []], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.get_training_stats": [[321, 324], ["round", "fairseq.logging.metrics.get_meter"], "function", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.get_meter"], []], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.validate": [[326, 378], ["trainer.begin_valid_epoch", "fairseq.utils.set_torch_seed", "logger.info", "trainer.get_valid_iterator().next_epoch_itr", "fairseq.logging.progress_bar.progress_bar", "train.get_valid_stats", "progress_bar.progress_bar.print", "valid_losses.append", "valid_losses.append", "fairseq.utils.tpu_data_loader", "fairseq.logging.metrics.aggregate", "agg.get_smoothed_values", "trainer.get_valid_iterator", "trainer.valid_step", "trainer.get_num_updates", "fairseq.distributed_utils.is_master", "fairseq.distributed_utils.is_master"], "function", ["home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.begin_valid_epoch", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.next_epoch_itr", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.progress_bar", "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.get_valid_stats", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.tpu_data_loader", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.aggregate", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.get_smoothed_values", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_valid_iterator", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.valid_step", "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.is_master", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.is_master"], []], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.get_valid_stats": [[380, 394], ["trainer.get_num_updates", "hasattr", "best_function"], "function", ["home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.get_num_updates"], []], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.cli_main": [[396, 410], ["fairseq.options.get_training_parser", "fairseq.options.parse_args_and_arch", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "fairseq.distributed_utils.call_main", "torch.cuda.profiler.profile", "torch.autograd.profiler.emit_nvtx", "fairseq.distributed_utils.call_main"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.options.get_training_parser", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.parse_args_and_arch", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.call_main", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.call_main"], []], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.preprocess.main": [[32, 334], ["fairseq.utils.import_user_module", "os.makedirs", "logger.addHandler", "logger.info", "fairseq.tasks.get_task", "build_dictionary.save", "preprocess.main.make_all"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.import_user_module", "home.repos.pwc.inspect_result.reneeye_const.tasks.__init__.get_task", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.save"], ["def", "main", "(", "args", ")", ":", "\n", "    ", "utils", ".", "import_user_module", "(", "args", ")", "\n", "\n", "os", ".", "makedirs", "(", "args", ".", "destdir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "logger", ".", "addHandler", "(", "\n", "logging", ".", "FileHandler", "(", "\n", "filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "destdir", ",", "\"preprocess.log\"", ")", ",", "\n", ")", "\n", ")", "\n", "logger", ".", "info", "(", "args", ")", "\n", "\n", "task", "=", "tasks", ".", "get_task", "(", "args", ".", "task", ")", "\n", "\n", "def", "train_path", "(", "lang", ")", ":", "\n", "        ", "return", "\"{}{}\"", ".", "format", "(", "args", ".", "trainpref", ",", "(", "\".\"", "+", "lang", ")", "if", "lang", "else", "\"\"", ")", "\n", "\n", "", "def", "file_name", "(", "prefix", ",", "lang", ")", ":", "\n", "        ", "fname", "=", "prefix", "\n", "if", "lang", "is", "not", "None", ":", "\n", "            ", "fname", "+=", "\".{lang}\"", ".", "format", "(", "lang", "=", "lang", ")", "\n", "", "return", "fname", "\n", "\n", "", "def", "dest_path", "(", "prefix", ",", "lang", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "args", ".", "destdir", ",", "file_name", "(", "prefix", ",", "lang", ")", ")", "\n", "\n", "", "def", "dict_path", "(", "lang", ")", ":", "\n", "        ", "return", "dest_path", "(", "\"dict\"", ",", "lang", ")", "+", "\".txt\"", "\n", "\n", "", "def", "build_dictionary", "(", "filenames", ",", "src", "=", "False", ",", "tgt", "=", "False", ")", ":", "\n", "        ", "assert", "src", "^", "tgt", "\n", "return", "task", ".", "build_dictionary", "(", "\n", "filenames", ",", "\n", "workers", "=", "args", ".", "workers", ",", "\n", "threshold", "=", "args", ".", "thresholdsrc", "if", "src", "else", "args", ".", "thresholdtgt", ",", "\n", "nwords", "=", "args", ".", "nwordssrc", "if", "src", "else", "args", ".", "nwordstgt", ",", "\n", "padding_factor", "=", "args", ".", "padding_factor", ",", "\n", ")", "\n", "\n", "", "target", "=", "not", "args", ".", "only_source", "\n", "\n", "if", "not", "args", ".", "srcdict", "and", "os", ".", "path", ".", "exists", "(", "dict_path", "(", "args", ".", "source_lang", ")", ")", ":", "\n", "        ", "raise", "FileExistsError", "(", "dict_path", "(", "args", ".", "source_lang", ")", ")", "\n", "", "if", "target", "and", "not", "args", ".", "tgtdict", "and", "os", ".", "path", ".", "exists", "(", "dict_path", "(", "args", ".", "target_lang", ")", ")", ":", "\n", "        ", "raise", "FileExistsError", "(", "dict_path", "(", "args", ".", "target_lang", ")", ")", "\n", "\n", "", "if", "args", ".", "joined_dictionary", ":", "\n", "        ", "assert", "(", "\n", "not", "args", ".", "srcdict", "or", "not", "args", ".", "tgtdict", "\n", ")", ",", "\"cannot use both --srcdict and --tgtdict with --joined-dictionary\"", "\n", "\n", "if", "args", ".", "srcdict", ":", "\n", "            ", "src_dict", "=", "task", ".", "load_dictionary", "(", "args", ".", "srcdict", ")", "\n", "", "elif", "args", ".", "tgtdict", ":", "\n", "            ", "src_dict", "=", "task", ".", "load_dictionary", "(", "args", ".", "tgtdict", ")", "\n", "", "else", ":", "\n", "            ", "assert", "(", "\n", "args", ".", "trainpref", "\n", ")", ",", "\"--trainpref must be set if --srcdict is not specified\"", "\n", "src_dict", "=", "build_dictionary", "(", "\n", "{", "train_path", "(", "lang", ")", "for", "lang", "in", "[", "args", ".", "source_lang", ",", "args", ".", "target_lang", "]", "}", ",", "\n", "src", "=", "True", ",", "\n", ")", "\n", "", "tgt_dict", "=", "src_dict", "\n", "", "else", ":", "\n", "        ", "if", "args", ".", "srcdict", ":", "\n", "            ", "src_dict", "=", "task", ".", "load_dictionary", "(", "args", ".", "srcdict", ")", "\n", "", "else", ":", "\n", "            ", "assert", "(", "\n", "args", ".", "trainpref", "\n", ")", ",", "\"--trainpref must be set if --srcdict is not specified\"", "\n", "src_dict", "=", "build_dictionary", "(", "[", "train_path", "(", "args", ".", "source_lang", ")", "]", ",", "src", "=", "True", ")", "\n", "\n", "", "if", "target", ":", "\n", "            ", "if", "args", ".", "tgtdict", ":", "\n", "                ", "tgt_dict", "=", "task", ".", "load_dictionary", "(", "args", ".", "tgtdict", ")", "\n", "", "else", ":", "\n", "                ", "assert", "(", "\n", "args", ".", "trainpref", "\n", ")", ",", "\"--trainpref must be set if --tgtdict is not specified\"", "\n", "tgt_dict", "=", "build_dictionary", "(", "[", "train_path", "(", "args", ".", "target_lang", ")", "]", ",", "tgt", "=", "True", ")", "\n", "", "", "else", ":", "\n", "            ", "tgt_dict", "=", "None", "\n", "\n", "", "", "src_dict", ".", "save", "(", "dict_path", "(", "args", ".", "source_lang", ")", ")", "\n", "if", "target", "and", "tgt_dict", "is", "not", "None", ":", "\n", "        ", "tgt_dict", ".", "save", "(", "dict_path", "(", "args", ".", "target_lang", ")", ")", "\n", "\n", "", "def", "make_binary_dataset", "(", "vocab", ",", "input_prefix", ",", "output_prefix", ",", "lang", ",", "num_workers", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"[{}] Dictionary: {} types\"", ".", "format", "(", "lang", ",", "len", "(", "vocab", ")", ")", ")", "\n", "n_seq_tok", "=", "[", "0", ",", "0", "]", "\n", "replaced", "=", "Counter", "(", ")", "\n", "\n", "def", "merge_result", "(", "worker_result", ")", ":", "\n", "            ", "replaced", ".", "update", "(", "worker_result", "[", "\"replaced\"", "]", ")", "\n", "n_seq_tok", "[", "0", "]", "+=", "worker_result", "[", "\"nseq\"", "]", "\n", "n_seq_tok", "[", "1", "]", "+=", "worker_result", "[", "\"ntok\"", "]", "\n", "\n", "", "input_file", "=", "\"{}{}\"", ".", "format", "(", "\n", "input_prefix", ",", "(", "\".\"", "+", "lang", ")", "if", "lang", "is", "not", "None", "else", "\"\"", "\n", ")", "\n", "offsets", "=", "Binarizer", ".", "find_offsets", "(", "input_file", ",", "num_workers", ")", "\n", "pool", "=", "None", "\n", "if", "num_workers", ">", "1", ":", "\n", "            ", "pool", "=", "Pool", "(", "processes", "=", "num_workers", "-", "1", ")", "\n", "for", "worker_id", "in", "range", "(", "1", ",", "num_workers", ")", ":", "\n", "                ", "prefix", "=", "\"{}{}\"", ".", "format", "(", "output_prefix", ",", "worker_id", ")", "\n", "pool", ".", "apply_async", "(", "\n", "binarize", ",", "\n", "(", "\n", "args", ",", "\n", "input_file", ",", "\n", "vocab", ",", "\n", "prefix", ",", "\n", "lang", ",", "\n", "offsets", "[", "worker_id", "]", ",", "\n", "offsets", "[", "worker_id", "+", "1", "]", ",", "\n", ")", ",", "\n", "callback", "=", "merge_result", ",", "\n", ")", "\n", "", "pool", ".", "close", "(", ")", "\n", "\n", "", "ds", "=", "indexed_dataset", ".", "make_builder", "(", "\n", "dataset_dest_file", "(", "args", ",", "output_prefix", ",", "lang", ",", "\"bin\"", ")", ",", "\n", "impl", "=", "args", ".", "dataset_impl", ",", "\n", "vocab_size", "=", "len", "(", "vocab", ")", ",", "\n", ")", "\n", "merge_result", "(", "\n", "Binarizer", ".", "binarize", "(", "\n", "input_file", ",", "vocab", ",", "lambda", "t", ":", "ds", ".", "add_item", "(", "t", ")", ",", "offset", "=", "0", ",", "end", "=", "offsets", "[", "1", "]", "\n", ")", "\n", ")", "\n", "if", "num_workers", ">", "1", ":", "\n", "            ", "pool", ".", "join", "(", ")", "\n", "for", "worker_id", "in", "range", "(", "1", ",", "num_workers", ")", ":", "\n", "                ", "prefix", "=", "\"{}{}\"", ".", "format", "(", "output_prefix", ",", "worker_id", ")", "\n", "temp_file_path", "=", "dataset_dest_prefix", "(", "args", ",", "prefix", ",", "lang", ")", "\n", "ds", ".", "merge_file_", "(", "temp_file_path", ")", "\n", "os", ".", "remove", "(", "indexed_dataset", ".", "data_file_path", "(", "temp_file_path", ")", ")", "\n", "os", ".", "remove", "(", "indexed_dataset", ".", "index_file_path", "(", "temp_file_path", ")", ")", "\n", "\n", "", "", "ds", ".", "finalize", "(", "dataset_dest_file", "(", "args", ",", "output_prefix", ",", "lang", ",", "\"idx\"", ")", ")", "\n", "\n", "logger", ".", "info", "(", "\n", "\"[{}] {}: {} sents, {} tokens, {:.3}% replaced by {}\"", ".", "format", "(", "\n", "lang", ",", "\n", "input_file", ",", "\n", "n_seq_tok", "[", "0", "]", ",", "\n", "n_seq_tok", "[", "1", "]", ",", "\n", "100", "*", "sum", "(", "replaced", ".", "values", "(", ")", ")", "/", "n_seq_tok", "[", "1", "]", ",", "\n", "vocab", ".", "unk_word", ",", "\n", ")", "\n", ")", "\n", "\n", "", "def", "make_binary_alignment_dataset", "(", "input_prefix", ",", "output_prefix", ",", "num_workers", ")", ":", "\n", "        ", "nseq", "=", "[", "0", "]", "\n", "\n", "def", "merge_result", "(", "worker_result", ")", ":", "\n", "            ", "nseq", "[", "0", "]", "+=", "worker_result", "[", "\"nseq\"", "]", "\n", "\n", "", "input_file", "=", "input_prefix", "\n", "offsets", "=", "Binarizer", ".", "find_offsets", "(", "input_file", ",", "num_workers", ")", "\n", "pool", "=", "None", "\n", "if", "num_workers", ">", "1", ":", "\n", "            ", "pool", "=", "Pool", "(", "processes", "=", "num_workers", "-", "1", ")", "\n", "for", "worker_id", "in", "range", "(", "1", ",", "num_workers", ")", ":", "\n", "                ", "prefix", "=", "\"{}{}\"", ".", "format", "(", "output_prefix", ",", "worker_id", ")", "\n", "pool", ".", "apply_async", "(", "\n", "binarize_alignments", ",", "\n", "(", "\n", "args", ",", "\n", "input_file", ",", "\n", "utils", ".", "parse_alignment", ",", "\n", "prefix", ",", "\n", "offsets", "[", "worker_id", "]", ",", "\n", "offsets", "[", "worker_id", "+", "1", "]", ",", "\n", ")", ",", "\n", "callback", "=", "merge_result", ",", "\n", ")", "\n", "", "pool", ".", "close", "(", ")", "\n", "\n", "", "ds", "=", "indexed_dataset", ".", "make_builder", "(", "\n", "dataset_dest_file", "(", "args", ",", "output_prefix", ",", "None", ",", "\"bin\"", ")", ",", "impl", "=", "args", ".", "dataset_impl", "\n", ")", "\n", "\n", "merge_result", "(", "\n", "Binarizer", ".", "binarize_alignments", "(", "\n", "input_file", ",", "\n", "utils", ".", "parse_alignment", ",", "\n", "lambda", "t", ":", "ds", ".", "add_item", "(", "t", ")", ",", "\n", "offset", "=", "0", ",", "\n", "end", "=", "offsets", "[", "1", "]", ",", "\n", ")", "\n", ")", "\n", "if", "num_workers", ">", "1", ":", "\n", "            ", "pool", ".", "join", "(", ")", "\n", "for", "worker_id", "in", "range", "(", "1", ",", "num_workers", ")", ":", "\n", "                ", "prefix", "=", "\"{}{}\"", ".", "format", "(", "output_prefix", ",", "worker_id", ")", "\n", "temp_file_path", "=", "dataset_dest_prefix", "(", "args", ",", "prefix", ",", "None", ")", "\n", "ds", ".", "merge_file_", "(", "temp_file_path", ")", "\n", "os", ".", "remove", "(", "indexed_dataset", ".", "data_file_path", "(", "temp_file_path", ")", ")", "\n", "os", ".", "remove", "(", "indexed_dataset", ".", "index_file_path", "(", "temp_file_path", ")", ")", "\n", "\n", "", "", "ds", ".", "finalize", "(", "dataset_dest_file", "(", "args", ",", "output_prefix", ",", "None", ",", "\"idx\"", ")", ")", "\n", "\n", "logger", ".", "info", "(", "\"[alignments] {}: parsed {} alignments\"", ".", "format", "(", "input_file", ",", "nseq", "[", "0", "]", ")", ")", "\n", "\n", "", "def", "make_dataset", "(", "vocab", ",", "input_prefix", ",", "output_prefix", ",", "lang", ",", "num_workers", "=", "1", ")", ":", "\n", "        ", "if", "args", ".", "dataset_impl", "==", "\"raw\"", ":", "\n", "# Copy original text file to destination folder", "\n", "            ", "output_text_file", "=", "dest_path", "(", "\n", "output_prefix", "+", "\".{}-{}\"", ".", "format", "(", "args", ".", "source_lang", ",", "args", ".", "target_lang", ")", ",", "\n", "lang", ",", "\n", ")", "\n", "shutil", ".", "copyfile", "(", "file_name", "(", "input_prefix", ",", "lang", ")", ",", "output_text_file", ")", "\n", "", "else", ":", "\n", "            ", "make_binary_dataset", "(", "vocab", ",", "input_prefix", ",", "output_prefix", ",", "lang", ",", "num_workers", ")", "\n", "\n", "", "", "def", "make_all", "(", "lang", ",", "vocab", ")", ":", "\n", "        ", "if", "args", ".", "trainpref", ":", "\n", "            ", "make_dataset", "(", "vocab", ",", "args", ".", "trainpref", ",", "\"train\"", ",", "lang", ",", "num_workers", "=", "args", ".", "workers", ")", "\n", "", "if", "args", ".", "validpref", ":", "\n", "            ", "for", "k", ",", "validpref", "in", "enumerate", "(", "args", ".", "validpref", ".", "split", "(", "\",\"", ")", ")", ":", "\n", "                ", "outprefix", "=", "\"valid{}\"", ".", "format", "(", "k", ")", "if", "k", ">", "0", "else", "\"valid\"", "\n", "make_dataset", "(", "\n", "vocab", ",", "validpref", ",", "outprefix", ",", "lang", ",", "num_workers", "=", "args", ".", "workers", "\n", ")", "\n", "", "", "if", "args", ".", "testpref", ":", "\n", "            ", "for", "k", ",", "testpref", "in", "enumerate", "(", "args", ".", "testpref", ".", "split", "(", "\",\"", ")", ")", ":", "\n", "                ", "outprefix", "=", "\"test{}\"", ".", "format", "(", "k", ")", "if", "k", ">", "0", "else", "\"test\"", "\n", "make_dataset", "(", "vocab", ",", "testpref", ",", "outprefix", ",", "lang", ",", "num_workers", "=", "args", ".", "workers", ")", "\n", "\n", "", "", "", "def", "make_all_alignments", "(", ")", ":", "\n", "        ", "if", "args", ".", "trainpref", "and", "os", ".", "path", ".", "exists", "(", "args", ".", "trainpref", "+", "\".\"", "+", "args", ".", "align_suffix", ")", ":", "\n", "            ", "make_binary_alignment_dataset", "(", "\n", "args", ".", "trainpref", "+", "\".\"", "+", "args", ".", "align_suffix", ",", "\n", "\"train.align\"", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "\n", ")", "\n", "", "if", "args", ".", "validpref", "and", "os", ".", "path", ".", "exists", "(", "args", ".", "validpref", "+", "\".\"", "+", "args", ".", "align_suffix", ")", ":", "\n", "            ", "make_binary_alignment_dataset", "(", "\n", "args", ".", "validpref", "+", "\".\"", "+", "args", ".", "align_suffix", ",", "\n", "\"valid.align\"", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "\n", ")", "\n", "", "if", "args", ".", "testpref", "and", "os", ".", "path", ".", "exists", "(", "args", ".", "testpref", "+", "\".\"", "+", "args", ".", "align_suffix", ")", ":", "\n", "            ", "make_binary_alignment_dataset", "(", "\n", "args", ".", "testpref", "+", "\".\"", "+", "args", ".", "align_suffix", ",", "\n", "\"test.align\"", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "\n", ")", "\n", "\n", "", "", "make_all", "(", "args", ".", "source_lang", ",", "src_dict", ")", "\n", "if", "target", ":", "\n", "        ", "make_all", "(", "args", ".", "target_lang", ",", "tgt_dict", ")", "\n", "", "if", "args", ".", "align_suffix", ":", "\n", "        ", "make_all_alignments", "(", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Wrote preprocessed data to {}\"", ".", "format", "(", "args", ".", "destdir", ")", ")", "\n", "\n", "if", "args", ".", "alignfile", ":", "\n", "        ", "assert", "args", ".", "trainpref", ",", "\"--trainpref must be set if --alignfile is specified\"", "\n", "src_file_name", "=", "train_path", "(", "args", ".", "source_lang", ")", "\n", "tgt_file_name", "=", "train_path", "(", "args", ".", "target_lang", ")", "\n", "freq_map", "=", "{", "}", "\n", "with", "open", "(", "args", ".", "alignfile", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "align_file", ":", "\n", "            ", "with", "open", "(", "src_file_name", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "src_file", ":", "\n", "                ", "with", "open", "(", "tgt_file_name", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "tgt_file", ":", "\n", "                    ", "for", "a", ",", "s", ",", "t", "in", "zip_longest", "(", "align_file", ",", "src_file", ",", "tgt_file", ")", ":", "\n", "                        ", "si", "=", "src_dict", ".", "encode_line", "(", "s", ",", "add_if_not_exist", "=", "False", ")", "\n", "ti", "=", "tgt_dict", ".", "encode_line", "(", "t", ",", "add_if_not_exist", "=", "False", ")", "\n", "ai", "=", "list", "(", "map", "(", "lambda", "x", ":", "tuple", "(", "x", ".", "split", "(", "\"-\"", ")", ")", ",", "a", ".", "split", "(", ")", ")", ")", "\n", "for", "sai", ",", "tai", "in", "ai", ":", "\n", "                            ", "srcidx", "=", "si", "[", "int", "(", "sai", ")", "]", "\n", "tgtidx", "=", "ti", "[", "int", "(", "tai", ")", "]", "\n", "if", "srcidx", "!=", "src_dict", ".", "unk", "(", ")", "and", "tgtidx", "!=", "tgt_dict", ".", "unk", "(", ")", ":", "\n", "                                ", "assert", "srcidx", "!=", "src_dict", ".", "pad", "(", ")", "\n", "assert", "srcidx", "!=", "src_dict", ".", "eos", "(", ")", "\n", "assert", "tgtidx", "!=", "tgt_dict", ".", "pad", "(", ")", "\n", "assert", "tgtidx", "!=", "tgt_dict", ".", "eos", "(", ")", "\n", "\n", "if", "srcidx", "not", "in", "freq_map", ":", "\n", "                                    ", "freq_map", "[", "srcidx", "]", "=", "{", "}", "\n", "", "if", "tgtidx", "not", "in", "freq_map", "[", "srcidx", "]", ":", "\n", "                                    ", "freq_map", "[", "srcidx", "]", "[", "tgtidx", "]", "=", "1", "\n", "", "else", ":", "\n", "                                    ", "freq_map", "[", "srcidx", "]", "[", "tgtidx", "]", "+=", "1", "\n", "\n", "", "", "", "", "", "", "", "align_dict", "=", "{", "}", "\n", "for", "srcidx", "in", "freq_map", ".", "keys", "(", ")", ":", "\n", "            ", "align_dict", "[", "srcidx", "]", "=", "max", "(", "freq_map", "[", "srcidx", "]", ",", "key", "=", "freq_map", "[", "srcidx", "]", ".", "get", ")", "\n", "\n", "", "with", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "destdir", ",", "\n", "\"alignment.{}-{}.txt\"", ".", "format", "(", "args", ".", "source_lang", ",", "args", ".", "target_lang", ")", ",", "\n", ")", ",", "\n", "\"w\"", ",", "\n", "encoding", "=", "\"utf-8\"", ",", "\n", ")", "as", "f", ":", "\n", "            ", "for", "k", ",", "v", "in", "align_dict", ".", "items", "(", ")", ":", "\n", "                ", "print", "(", "\"{} {}\"", ".", "format", "(", "src_dict", "[", "k", "]", ",", "tgt_dict", "[", "v", "]", ")", ",", "file", "=", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.preprocess.binarize": [[336, 351], ["fairseq.data.indexed_dataset.make_builder", "fairseq.binarizer.Binarizer.binarize", "indexed_dataset.make_builder.finalize", "preprocess.dataset_dest_file", "indexed_dataset.make_builder.add_item", "preprocess.dataset_dest_file", "len"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.make_builder", "home.repos.pwc.inspect_result.reneeye_const.fairseq.binarizer.Binarizer.binarize", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDatasetBuilder.finalize", "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.preprocess.dataset_dest_file", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDatasetBuilder.add_item", "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.preprocess.dataset_dest_file"], ["", "", "", "", "def", "binarize", "(", "args", ",", "filename", ",", "vocab", ",", "output_prefix", ",", "lang", ",", "offset", ",", "end", ",", "append_eos", "=", "True", ")", ":", "\n", "    ", "ds", "=", "indexed_dataset", ".", "make_builder", "(", "\n", "dataset_dest_file", "(", "args", ",", "output_prefix", ",", "lang", ",", "\"bin\"", ")", ",", "\n", "impl", "=", "args", ".", "dataset_impl", ",", "\n", "vocab_size", "=", "len", "(", "vocab", ")", ",", "\n", ")", "\n", "\n", "def", "consumer", "(", "tensor", ")", ":", "\n", "        ", "ds", ".", "add_item", "(", "tensor", ")", "\n", "\n", "", "res", "=", "Binarizer", ".", "binarize", "(", "\n", "filename", ",", "vocab", ",", "consumer", ",", "append_eos", "=", "append_eos", ",", "offset", "=", "offset", ",", "end", "=", "end", "\n", ")", "\n", "ds", ".", "finalize", "(", "dataset_dest_file", "(", "args", ",", "output_prefix", ",", "lang", ",", "\"idx\"", ")", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.preprocess.binarize_alignments": [[353, 368], ["fairseq.data.indexed_dataset.make_builder", "fairseq.binarizer.Binarizer.binarize_alignments", "indexed_dataset.make_builder.finalize", "preprocess.dataset_dest_file", "indexed_dataset.make_builder.add_item", "preprocess.dataset_dest_file"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.make_builder", "home.repos.pwc.inspect_result.reneeye_const.fairseq.binarizer.Binarizer.binarize_alignments", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDatasetBuilder.finalize", "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.preprocess.dataset_dest_file", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDatasetBuilder.add_item", "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.preprocess.dataset_dest_file"], ["", "def", "binarize_alignments", "(", "args", ",", "filename", ",", "parse_alignment", ",", "output_prefix", ",", "offset", ",", "end", ")", ":", "\n", "    ", "ds", "=", "indexed_dataset", ".", "make_builder", "(", "\n", "dataset_dest_file", "(", "args", ",", "output_prefix", ",", "None", ",", "\"bin\"", ")", ",", "\n", "impl", "=", "args", ".", "dataset_impl", ",", "\n", "vocab_size", "=", "None", ",", "\n", ")", "\n", "\n", "def", "consumer", "(", "tensor", ")", ":", "\n", "        ", "ds", ".", "add_item", "(", "tensor", ")", "\n", "\n", "", "res", "=", "Binarizer", ".", "binarize_alignments", "(", "\n", "filename", ",", "parse_alignment", ",", "consumer", ",", "offset", "=", "offset", ",", "end", "=", "end", "\n", ")", "\n", "ds", ".", "finalize", "(", "dataset_dest_file", "(", "args", ",", "output_prefix", ",", "None", ",", "\"idx\"", ")", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.preprocess.dataset_dest_prefix": [[370, 380], ["None"], "function", ["None"], ["", "def", "dataset_dest_prefix", "(", "args", ",", "output_prefix", ",", "lang", ")", ":", "\n", "    ", "base", "=", "\"{}/{}\"", ".", "format", "(", "args", ".", "destdir", ",", "output_prefix", ")", "\n", "if", "lang", "is", "not", "None", ":", "\n", "        ", "lang_part", "=", "\".{}-{}.{}\"", ".", "format", "(", "args", ".", "source_lang", ",", "args", ".", "target_lang", ",", "lang", ")", "\n", "", "elif", "args", ".", "only_source", ":", "\n", "        ", "lang_part", "=", "\"\"", "\n", "", "else", ":", "\n", "        ", "lang_part", "=", "\".{}-{}\"", ".", "format", "(", "args", ".", "source_lang", ",", "args", ".", "target_lang", ")", "\n", "\n", "", "return", "\"{}{}\"", ".", "format", "(", "base", ",", "lang_part", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.preprocess.dataset_dest_file": [[382, 385], ["preprocess.dataset_dest_prefix"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.preprocess.dataset_dest_prefix"], ["", "def", "dataset_dest_file", "(", "args", ",", "output_prefix", ",", "lang", ",", "extension", ")", ":", "\n", "    ", "base", "=", "dataset_dest_prefix", "(", "args", ",", "output_prefix", ",", "lang", ")", "\n", "return", "\"{}.{}\"", ".", "format", "(", "base", ",", "extension", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.preprocess.get_offsets": [[387, 389], ["fairseq.binarizer.Binarizer.find_offsets"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.binarizer.Binarizer.find_offsets"], ["", "def", "get_offsets", "(", "input_file", ",", "num_workers", ")", ":", "\n", "    ", "return", "Binarizer", ".", "find_offsets", "(", "input_file", ",", "num_workers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.preprocess.cli_main": [[391, 395], ["fairseq.options.get_preprocessing_parser", "options.get_preprocessing_parser.parse_args", "preprocess.main"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.options.get_preprocessing_parser", "home.repos.pwc.inspect_result.reneeye_const.scripts.average_checkpoints.main"], ["", "def", "cli_main", "(", ")", ":", "\n", "    ", "parser", "=", "options", ".", "get_preprocessing_parser", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "main", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.score.get_parser": [[18, 35], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "get_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Command-line script for BLEU scoring.\"", "\n", ")", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'-s'", ",", "'--sys'", ",", "default", "=", "'-'", ",", "help", "=", "'system output'", ")", "\n", "parser", ".", "add_argument", "(", "'-r'", ",", "'--ref'", ",", "required", "=", "True", ",", "help", "=", "'references'", ")", "\n", "parser", ".", "add_argument", "(", "'-o'", ",", "'--order'", ",", "default", "=", "4", ",", "metavar", "=", "'N'", ",", "\n", "type", "=", "int", ",", "help", "=", "'consider ngrams up to this order'", ")", "\n", "parser", ".", "add_argument", "(", "'--ignore-case'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'case-insensitive scoring'", ")", "\n", "parser", ".", "add_argument", "(", "'--sacrebleu'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'score with sacrebleu'", ")", "\n", "parser", ".", "add_argument", "(", "'--sentence-bleu'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'report sentence-level BLEUs (i.e., with +1 smoothing)'", ")", "\n", "# fmt: on", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.score.cli_main": [[37, 99], ["score.get_parser", "get_parser.parse_args", "print", "os.path.exists", "fairseq.data.dictionary.Dictionary", "os.path.exists", "fd.readlines", "score.cli_main.score"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.options.get_parser", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.scoring.__init__.BaseScorer.score"], ["", "def", "cli_main", "(", ")", ":", "\n", "    ", "parser", "=", "get_parser", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "print", "(", "args", ")", "\n", "\n", "assert", "args", ".", "sys", "==", "\"-\"", "or", "os", ".", "path", ".", "exists", "(", "\n", "args", ".", "sys", "\n", ")", ",", "\"System output file {} does not exist\"", ".", "format", "(", "args", ".", "sys", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "args", ".", "ref", ")", ",", "\"Reference file {} does not exist\"", ".", "format", "(", "args", ".", "ref", ")", "\n", "\n", "dict", "=", "dictionary", ".", "Dictionary", "(", ")", "\n", "\n", "def", "readlines", "(", "fd", ")", ":", "\n", "        ", "for", "line", "in", "fd", ".", "readlines", "(", ")", ":", "\n", "            ", "if", "args", ".", "ignore_case", ":", "\n", "                ", "yield", "line", ".", "lower", "(", ")", "\n", "", "else", ":", "\n", "                ", "yield", "line", "\n", "\n", "", "", "", "if", "args", ".", "sacrebleu", ":", "\n", "        ", "import", "sacrebleu", "\n", "\n", "def", "score", "(", "fdsys", ")", ":", "\n", "            ", "with", "open", "(", "args", ".", "ref", ")", "as", "fdref", ":", "\n", "                ", "print", "(", "sacrebleu", ".", "corpus_bleu", "(", "fdsys", ",", "[", "fdref", "]", ")", ".", "format", "(", ")", ")", "\n", "\n", "", "", "", "elif", "args", ".", "sentence_bleu", ":", "\n", "\n", "        ", "def", "score", "(", "fdsys", ")", ":", "\n", "            ", "with", "open", "(", "args", ".", "ref", ")", "as", "fdref", ":", "\n", "                ", "scorer", "=", "bleu", ".", "Scorer", "(", "dict", ".", "pad", "(", ")", ",", "dict", ".", "eos", "(", ")", ",", "dict", ".", "unk", "(", ")", ")", "\n", "for", "i", ",", "(", "sys_tok", ",", "ref_tok", ")", "in", "enumerate", "(", "\n", "zip", "(", "readlines", "(", "fdsys", ")", ",", "readlines", "(", "fdref", ")", ")", "\n", ")", ":", "\n", "                    ", "scorer", ".", "reset", "(", "one_init", "=", "True", ")", "\n", "sys_tok", "=", "dict", ".", "encode_line", "(", "sys_tok", ")", "\n", "ref_tok", "=", "dict", ".", "encode_line", "(", "ref_tok", ")", "\n", "scorer", ".", "add", "(", "ref_tok", ",", "sys_tok", ")", "\n", "print", "(", "i", ",", "scorer", ".", "result_string", "(", "args", ".", "order", ")", ")", "\n", "\n", "", "", "", "", "else", ":", "\n", "\n", "        ", "def", "score", "(", "fdsys", ")", ":", "\n", "            ", "with", "open", "(", "args", ".", "ref", ")", "as", "fdref", ":", "\n", "                ", "scorer", "=", "bleu", ".", "Scorer", "(", "\n", "bleu", ".", "BleuConfig", "(", "\n", "pad", "=", "dict", ".", "pad", "(", ")", ",", "\n", "eos", "=", "dict", ".", "eos", "(", ")", ",", "\n", "unk", "=", "dict", ".", "unk", "(", ")", ",", "\n", ")", "\n", ")", "\n", "for", "sys_tok", ",", "ref_tok", "in", "zip", "(", "readlines", "(", "fdsys", ")", ",", "readlines", "(", "fdref", ")", ")", ":", "\n", "                    ", "sys_tok", "=", "dict", ".", "encode_line", "(", "sys_tok", ")", "\n", "ref_tok", "=", "dict", ".", "encode_line", "(", "ref_tok", ")", "\n", "scorer", ".", "add", "(", "ref_tok", ",", "sys_tok", ")", "\n", "", "print", "(", "scorer", ".", "result_string", "(", "args", ".", "order", ")", ")", "\n", "\n", "", "", "", "if", "args", ".", "sys", "==", "\"-\"", ":", "\n", "        ", "score", "(", "sys", ".", "stdin", ")", "\n", "", "else", ":", "\n", "        ", "with", "open", "(", "args", ".", "sys", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "score", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.eval_lm.WordStat.__init__": [[35, 42], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "word", ",", "is_bpe", ")", ":", "\n", "        ", "self", ".", "word", "=", "word", "\n", "self", ".", "is_bpe", "=", "is_bpe", "\n", "self", ".", "log_prob", "=", "0", "\n", "self", ".", "next_word_prob", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "self", ".", "missing_next_words", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.eval_lm.WordStat.add": [[43, 54], ["None"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "log_prob", ",", "next_word_prob", ")", ":", "\n", "        ", "\"\"\"increments counters for the sum of log probs of current word and next\n        word (given context ending at current word). Since the next word might be at the end of the example,\n        or it might be not counted because it is not an ending subword unit,\n        also keeps track of how many of those we have seen\"\"\"", "\n", "if", "next_word_prob", "is", "not", "None", ":", "\n", "            ", "self", ".", "next_word_prob", "+=", "next_word_prob", "\n", "", "else", ":", "\n", "            ", "self", ".", "missing_next_words", "+=", "1", "\n", "", "self", ".", "log_prob", "+=", "log_prob", "\n", "self", ".", "count", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.eval_lm.WordStat.__str__": [[55, 63], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\"", ".", "format", "(", "\n", "self", ".", "word", ",", "\n", "self", ".", "count", ",", "\n", "self", ".", "log_prob", ",", "\n", "self", ".", "is_bpe", ",", "\n", "self", ".", "next_word_prob", ",", "\n", "self", ".", "count", "-", "self", ".", "missing_next_words", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.eval_lm.main": [[66, 273], ["isinstance", "fairseq.utils.import_user_module", "logger.info", "logger.info", "fairseq.tasks.setup_task", "fairseq.checkpoint_utils.load_model_ensemble_and_task", "tasks.setup_task.load_dataset", "tasks.setup_task.dataset", "logger.info", "logger.info", "tasks.setup_task.get_batch_iterator().next_epoch_itr", "fairseq.logging.progress_bar.progress_bar", "fairseq.logging.meters.StopwatchMeter", "fairseq.sequence_scorer.SequenceScorer", "dict", "fairseq.logging.meters.TimeMeter", "logger.info", "logger.info", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "torch.cuda.is_available", "torch.cuda.set_device", "fairseq.data.LMContextWindowDataset", "model.prepare_for_inference_", "len", "len", "fairseq.logging.meters.StopwatchMeter.start", "fairseq.sequence_scorer.SequenceScorer.generate", "fairseq.logging.meters.StopwatchMeter.stop", "enumerate", "fairseq.logging.meters.TimeMeter.update", "progress_bar.progress_bar.log", "sorted", "eval", "len", "model.half", "model.cuda", "sum", "tasks.setup_task.get_batch_iterator", "fairseq.dataclass.utils.convert_namespace_to_omegaconf.common_eval.post_process.rstrip", "fairseq.utils.move_to_cuda", "tokens.numel", "hypo[].float", "getattr", "inf_scores.any", "hypo[].float.sum().cpu", "math.log", "dict.values", "logger.info", "tasks.setup_task.source_dictionary.pad", "range", "hypo[].float.eq", "hypo[].float.eq", "logger.info", "hypo[].float.numel", "range", "round", "p.numel", "fairseq.utils.resolve_max_positions", "max", "max", "range", "tasks.setup_task.source_dictionary[].endswith", "[].item", "tasks.setup_task.target_dictionary.bos", "float", "float", "tasks.setup_task.target_dictionary.string", "hypo[].float.sum", "len", "tokens[].item", "logger.info", "models[].parameters", "len", "tokens[].item", "word_prob.append", "dict.setdefault().add", "len", "pos_scores[].item", "model.max_positions", "inf_scores.nonzero", "pos_scores[].item", "pos_scores[].item", "dict.setdefault", "str", "eval_lm.WordStat", "int"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.import_user_module", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyMTTask.setup_task", "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_model_ensemble_and_task", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyMTTask.load_dataset", "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.dataset", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.next_epoch_itr", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.progress_bar", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.prepare_for_inference_", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.start", "home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.generate", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.stop", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.lightconv_layer.lightconv_layer.LightconvLayer.half", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.cuda", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.get_batch_iterator", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.move_to_cuda", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.resolve_max_positions", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "", "def", "main", "(", "cfg", ":", "DictConfig", ",", "**", "unused_kwargs", ")", ":", "\n", "    ", "if", "isinstance", "(", "cfg", ",", "Namespace", ")", ":", "\n", "        ", "cfg", "=", "convert_namespace_to_omegaconf", "(", "cfg", ")", "\n", "\n", "", "utils", ".", "import_user_module", "(", "cfg", ".", "common", ")", "\n", "\n", "use_fp16", "=", "cfg", ".", "common", ".", "fp16", "\n", "use_cuda", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "cfg", ".", "common", ".", "cpu", "\n", "\n", "if", "use_cuda", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "cfg", ".", "distributed_training", ".", "device_id", ")", "\n", "\n", "", "logger", ".", "info", "(", "cfg", ")", "\n", "\n", "# Load ensemble", "\n", "logger", ".", "info", "(", "\"loading model(s) from {}\"", ".", "format", "(", "cfg", ".", "common_eval", ".", "path", ")", ")", "\n", "\n", "# reduce tokens per sample by the required context window size", "\n", "cfg", ".", "task", ".", "tokens_per_sample", "-=", "cfg", ".", "eval_lm", ".", "context_window", "\n", "\n", "# Initialize the task using the current *cfg*", "\n", "task", "=", "tasks", ".", "setup_task", "(", "cfg", ".", "task", ")", "\n", "\n", "# Initialize the model (but not the task) using the checkpoint's *cfg*", "\n", "models", ",", "model_args", ",", "task", "=", "checkpoint_utils", ".", "load_model_ensemble_and_task", "(", "\n", "[", "cfg", ".", "common_eval", ".", "path", "]", ",", "\n", "arg_overrides", "=", "eval", "(", "cfg", ".", "common_eval", ".", "model_overrides", ")", ",", "\n", "suffix", "=", "cfg", ".", "checkpoint", ".", "checkpoint_suffix", ",", "\n", "strict", "=", "(", "cfg", ".", "checkpoint", ".", "checkpoint_shard_count", "==", "1", ")", ",", "\n", "num_shards", "=", "cfg", ".", "checkpoint", ".", "checkpoint_shard_count", ",", "\n", "task", "=", "task", ",", "\n", ")", "\n", "\n", "# Load dataset splits", "\n", "gen_subset", "=", "cfg", ".", "dataset", ".", "gen_subset", "\n", "task", ".", "load_dataset", "(", "gen_subset", ")", "\n", "dataset", "=", "task", ".", "dataset", "(", "gen_subset", ")", "\n", "if", "cfg", ".", "eval_lm", ".", "context_window", ">", "0", ":", "\n", "        ", "dataset", "=", "LMContextWindowDataset", "(", "\n", "dataset", "=", "dataset", ",", "\n", "tokens_per_sample", "=", "cfg", ".", "task", ".", "tokens_per_sample", ",", "\n", "context_window", "=", "cfg", ".", "eval_lm", ".", "context_window", ",", "\n", "pad_idx", "=", "task", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", ")", "\n", "", "logger", ".", "info", "(", "\"{} {} {} examples\"", ".", "format", "(", "cfg", ".", "task", ".", "data", ",", "gen_subset", ",", "len", "(", "dataset", ")", ")", ")", "\n", "\n", "# Optimize ensemble for generation and set the source and dest dicts on the model (required by scorer)", "\n", "for", "model", "in", "models", ":", "\n", "        ", "if", "use_fp16", ":", "\n", "            ", "model", ".", "half", "(", ")", "\n", "", "if", "use_cuda", "and", "not", "cfg", ".", "distributed_training", ".", "pipeline_model_parallel", ":", "\n", "            ", "model", ".", "cuda", "(", ")", "\n", "", "model", ".", "prepare_for_inference_", "(", "cfg", ")", "\n", "\n", "", "assert", "len", "(", "models", ")", ">", "0", "\n", "\n", "logger", ".", "info", "(", "\n", "\"num. model params: {}\"", ".", "format", "(", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "models", "[", "0", "]", ".", "parameters", "(", ")", ")", ")", "\n", ")", "\n", "\n", "itr", "=", "task", ".", "get_batch_iterator", "(", "\n", "dataset", "=", "dataset", ",", "\n", "max_tokens", "=", "cfg", ".", "dataset", ".", "max_tokens", "or", "36000", ",", "\n", "max_sentences", "=", "cfg", ".", "dataset", ".", "batch_size", ",", "\n", "max_positions", "=", "utils", ".", "resolve_max_positions", "(", "\n", "*", "[", "model", ".", "max_positions", "(", ")", "for", "model", "in", "models", "]", "\n", ")", ",", "\n", "ignore_invalid_inputs", "=", "True", ",", "\n", "num_shards", "=", "max", "(", "\n", "cfg", ".", "dataset", ".", "num_shards", ",", "\n", "cfg", ".", "distributed_training", ".", "distributed_world_size", ",", "\n", ")", ",", "\n", "shard_id", "=", "max", "(", "\n", "cfg", ".", "dataset", ".", "shard_id", ",", "\n", "cfg", ".", "distributed_training", ".", "distributed_rank", ",", "\n", ")", ",", "\n", "num_workers", "=", "cfg", ".", "dataset", ".", "num_workers", ",", "\n", "data_buffer_size", "=", "cfg", ".", "dataset", ".", "data_buffer_size", ",", "\n", ")", ".", "next_epoch_itr", "(", "shuffle", "=", "False", ")", "\n", "progress", "=", "progress_bar", ".", "progress_bar", "(", "\n", "itr", ",", "\n", "log_format", "=", "cfg", ".", "common", ".", "log_format", ",", "\n", "log_interval", "=", "cfg", ".", "common", ".", "log_interval", ",", "\n", "default_log_format", "=", "(", "\"tqdm\"", "if", "not", "cfg", ".", "common", ".", "no_progress_bar", "else", "\"simple\"", ")", ",", "\n", ")", "\n", "\n", "gen_timer", "=", "StopwatchMeter", "(", ")", "\n", "scorer", "=", "SequenceScorer", "(", "task", ".", "target_dictionary", ",", "cfg", ".", "eval_lm", ".", "softmax_batch", ")", "\n", "\n", "score_sum", "=", "0.0", "\n", "count", "=", "0", "\n", "\n", "if", "cfg", ".", "common_eval", ".", "post_process", "is", "not", "None", ":", "\n", "        ", "if", "cfg", ".", "common_eval", ".", "post_process", "==", "\"sentencepiece\"", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "bpe_cont", "=", "cfg", ".", "common_eval", ".", "post_process", ".", "rstrip", "(", ")", "\n", "bpe_toks", "=", "{", "\n", "i", "\n", "for", "i", "in", "range", "(", "len", "(", "task", ".", "source_dictionary", ")", ")", "\n", "if", "task", ".", "source_dictionary", "[", "i", "]", ".", "endswith", "(", "bpe_cont", ")", "\n", "}", "\n", "", "bpe_len", "=", "len", "(", "bpe_cont", ")", "\n", "", "else", ":", "\n", "        ", "bpe_toks", "=", "None", "\n", "bpe_len", "=", "0", "\n", "\n", "", "word_stats", "=", "dict", "(", ")", "\n", "\n", "wps_meter", "=", "TimeMeter", "(", ")", "\n", "\n", "for", "sample", "in", "progress", ":", "\n", "        ", "if", "\"net_input\"", "not", "in", "sample", ":", "\n", "            ", "continue", "\n", "\n", "", "sample", "=", "utils", ".", "move_to_cuda", "(", "sample", ")", "if", "use_cuda", "else", "sample", "\n", "\n", "gen_timer", ".", "start", "(", ")", "\n", "hypos", "=", "scorer", ".", "generate", "(", "models", ",", "sample", ")", "\n", "gen_timer", ".", "stop", "(", "sample", "[", "\"ntokens\"", "]", ")", "\n", "\n", "for", "i", ",", "hypos_i", "in", "enumerate", "(", "hypos", ")", ":", "\n", "            ", "hypo", "=", "hypos_i", "[", "0", "]", "\n", "sample_id", "=", "sample", "[", "\"id\"", "]", "[", "i", "]", "\n", "\n", "tokens", "=", "hypo", "[", "\"tokens\"", "]", "\n", "tgt_len", "=", "tokens", ".", "numel", "(", ")", "\n", "pos_scores", "=", "hypo", "[", "\"positional_scores\"", "]", ".", "float", "(", ")", "\n", "\n", "if", "getattr", "(", "cfg", ".", "task", ",", "\"add_bos_token\"", ",", "False", ")", ":", "\n", "                ", "assert", "hypo", "[", "\"tokens\"", "]", "[", "0", "]", ".", "item", "(", ")", "==", "task", ".", "target_dictionary", ".", "bos", "(", ")", "\n", "tokens", "=", "tokens", "[", "1", ":", "]", "\n", "pos_scores", "=", "pos_scores", "[", "1", ":", "]", "\n", "\n", "", "skipped_toks", "=", "0", "\n", "if", "bpe_toks", "is", "not", "None", ":", "\n", "                ", "for", "i", "in", "range", "(", "tgt_len", "-", "1", ")", ":", "\n", "                    ", "if", "tokens", "[", "i", "]", ".", "item", "(", ")", "in", "bpe_toks", ":", "\n", "                        ", "skipped_toks", "+=", "1", "\n", "pos_scores", "[", "i", "+", "1", "]", "+=", "pos_scores", "[", "i", "]", "\n", "pos_scores", "[", "i", "]", "=", "0", "\n", "\n", "", "", "", "inf_scores", "=", "pos_scores", ".", "eq", "(", "float", "(", "\"inf\"", ")", ")", "|", "pos_scores", ".", "eq", "(", "float", "(", "\"-inf\"", ")", ")", "\n", "if", "inf_scores", ".", "any", "(", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"skipping tokens with inf scores:\"", ",", "\n", "task", ".", "target_dictionary", ".", "string", "(", "tokens", "[", "inf_scores", ".", "nonzero", "(", ")", "]", ")", ",", "\n", ")", "\n", "pos_scores", "=", "pos_scores", "[", "(", "~", "inf_scores", ")", ".", "nonzero", "(", ")", "]", "\n", "", "score_sum", "+=", "pos_scores", ".", "sum", "(", ")", ".", "cpu", "(", ")", "\n", "count", "+=", "pos_scores", ".", "numel", "(", ")", "-", "skipped_toks", "\n", "\n", "if", "cfg", ".", "eval_lm", ".", "output_word_probs", "or", "cfg", ".", "eval_lm", ".", "output_word_stats", ":", "\n", "                ", "w", "=", "\"\"", "\n", "word_prob", "=", "[", "]", "\n", "is_bpe", "=", "False", "\n", "for", "i", "in", "range", "(", "len", "(", "tokens", ")", ")", ":", "\n", "                    ", "w_ind", "=", "tokens", "[", "i", "]", ".", "item", "(", ")", "\n", "w", "+=", "task", ".", "source_dictionary", "[", "w_ind", "]", "\n", "if", "bpe_toks", "is", "not", "None", "and", "w_ind", "in", "bpe_toks", ":", "\n", "                        ", "w", "=", "w", "[", ":", "-", "bpe_len", "]", "\n", "is_bpe", "=", "True", "\n", "", "else", ":", "\n", "                        ", "word_prob", ".", "append", "(", "(", "w", ",", "pos_scores", "[", "i", "]", ".", "item", "(", ")", ")", ")", "\n", "\n", "next_prob", "=", "None", "\n", "ind", "=", "i", "+", "1", "\n", "while", "ind", "<", "len", "(", "tokens", ")", ":", "\n", "                            ", "if", "pos_scores", "[", "ind", "]", ".", "item", "(", ")", "!=", "0", ":", "\n", "                                ", "next_prob", "=", "pos_scores", "[", "ind", "]", "\n", "break", "\n", "", "ind", "+=", "1", "\n", "\n", "", "word_stats", ".", "setdefault", "(", "w", ",", "WordStat", "(", "w", ",", "is_bpe", ")", ")", ".", "add", "(", "\n", "pos_scores", "[", "i", "]", ".", "item", "(", ")", ",", "next_prob", "\n", ")", "\n", "is_bpe", "=", "False", "\n", "w", "=", "\"\"", "\n", "", "", "if", "cfg", ".", "eval_lm", ".", "output_word_probs", ":", "\n", "                    ", "logger", ".", "info", "(", "\n", "str", "(", "int", "(", "sample_id", ")", ")", "\n", "+", "\" \"", "\n", "+", "(", "\n", "\"\\t\"", ".", "join", "(", "\n", "\"{} [{:2f}]\"", ".", "format", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ")", "for", "x", "in", "word_prob", "\n", ")", "\n", ")", "\n", ")", "\n", "\n", "", "", "", "wps_meter", ".", "update", "(", "sample", "[", "\"ntokens\"", "]", ")", "\n", "progress", ".", "log", "(", "{", "\"wps\"", ":", "round", "(", "wps_meter", ".", "avg", ")", "}", ")", "\n", "\n", "", "avg_nll_loss", "=", "-", "score_sum", "/", "count", "/", "math", ".", "log", "(", "2", ")", "if", "count", ">", "0", "else", "0", "# convert to base 2", "\n", "logger", ".", "info", "(", "\n", "\"Evaluated {} tokens in {:.1f}s ({:.2f} tokens/s)\"", ".", "format", "(", "\n", "gen_timer", ".", "n", ",", "gen_timer", ".", "sum", ",", "1.0", "/", "gen_timer", ".", "avg", "if", "gen_timer", ".", "avg", ">", "0", "else", "0", "\n", ")", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"Loss (base 2): {:.4f}, Perplexity: {:.2f}\"", ".", "format", "(", "\n", "avg_nll_loss", ",", "2", "**", "avg_nll_loss", "\n", ")", "\n", ")", "\n", "\n", "if", "cfg", ".", "eval_lm", ".", "output_word_stats", ":", "\n", "        ", "for", "ws", "in", "sorted", "(", "word_stats", ".", "values", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", ".", "count", ",", "reverse", "=", "True", ")", ":", "\n", "            ", "logger", ".", "info", "(", "ws", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.eval_lm.cli_main": [[275, 280], ["fairseq.options.get_eval_lm_parser", "fairseq.options.parse_args_and_arch", "fairseq.distributed_utils.call_main", "fairseq.dataclass.utils.convert_namespace_to_omegaconf"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.options.get_eval_lm_parser", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.parse_args_and_arch", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.call_main", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.convert_namespace_to_omegaconf"], ["", "", "", "def", "cli_main", "(", ")", ":", "\n", "    ", "parser", "=", "options", ".", "get_eval_lm_parser", "(", ")", "\n", "args", "=", "options", ".", "parse_args_and_arch", "(", "parser", ")", "\n", "\n", "distributed_utils", ".", "call_main", "(", "convert_namespace_to_omegaconf", "(", "args", ")", ",", "main", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.hydra_train.hydra_main": [[23, 36], ["hydra.main", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.set_struct", "omegaconf.OmegaConf.to_container", "fairseq.distributed_utils.call_main", "os.path.join", "torch.cuda.profiler.profile", "torch.autograd.profiler.emit_nvtx", "fairseq.distributed_utils.call_main"], "function", ["home.repos.pwc.inspect_result.reneeye_const.scripts.average_checkpoints.main", "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.create", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.call_main", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.call_main"], ["@", "hydra", ".", "main", "(", "config_path", "=", "os", ".", "path", ".", "join", "(", "\"..\"", ",", "\"fairseq\"", ",", "\"config\"", ")", ",", "config_name", "=", "\"config\"", ")", "\n", "def", "hydra_main", "(", "cfg", ":", "FairseqConfig", ")", "->", "None", ":", "\n", "\n", "    ", "cfg", "=", "OmegaConf", ".", "create", "(", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ",", "enum_to_str", "=", "True", ")", ")", "\n", "\n", "OmegaConf", ".", "set_struct", "(", "cfg", ",", "True", ")", "\n", "\n", "if", "cfg", ".", "common", ".", "profile", ":", "\n", "        ", "with", "torch", ".", "cuda", ".", "profiler", ".", "profile", "(", ")", ":", "\n", "            ", "with", "torch", ".", "autograd", ".", "profiler", ".", "emit_nvtx", "(", ")", ":", "\n", "                ", "distributed_utils", ".", "call_main", "(", "cfg", ",", "pre_main", ")", "\n", "", "", "", "else", ":", "\n", "        ", "distributed_utils", ".", "call_main", "(", "cfg", ",", "pre_main", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.__init__": [[134, 142], ["print"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print"], ["def", "__init__", "(", "self", ",", "yaml_path", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "yaml", "\n", "", "except", "ImportError", ":", "\n", "            ", "print", "(", "\"Please install PyYAML to load YAML files for S2T data config\"", ")", "\n", "", "self", ".", "yaml", "=", "yaml", "\n", "self", ".", "yaml_path", "=", "yaml_path", "\n", "self", ".", "config", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.flush": [[143, 146], ["open", "data_utils.S2TDataConfigWriter.yaml.dump"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["", "def", "flush", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "yaml_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "self", ".", "yaml", ".", "dump", "(", "self", ".", "config", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_audio_root": [[147, 149], ["None"], "methods", ["None"], ["", "", "def", "set_audio_root", "(", "self", ",", "audio_root", "=", "\"\"", ")", ":", "\n", "        ", "self", ".", "config", "[", "\"audio_root\"", "]", "=", "audio_root", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_vocab_filename": [[150, 152], ["None"], "methods", ["None"], ["", "def", "set_vocab_filename", "(", "self", ",", "vocab_filename", "=", "\"dict.txt\"", ")", ":", "\n", "        ", "self", ".", "config", "[", "\"vocab_filename\"", "]", "=", "vocab_filename", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_specaugment": [[153, 169], ["None"], "methods", ["None"], ["", "def", "set_specaugment", "(", "\n", "self", ",", "\n", "time_wrap_w", ":", "int", ",", "\n", "freq_mask_n", ":", "int", ",", "\n", "freq_mask_f", ":", "int", ",", "\n", "time_mask_n", ":", "int", ",", "\n", "time_mask_t", ":", "int", ",", "\n", "time_mask_p", ":", "float", ",", "\n", ")", ":", "\n", "        ", "self", ".", "config", "[", "\"specaugment\"", "]", "=", "{", "\n", "\"time_wrap_W\"", ":", "time_wrap_w", ",", "\n", "\"freq_mask_N\"", ":", "freq_mask_n", ",", "\n", "\"freq_mask_F\"", ":", "freq_mask_f", ",", "\n", "\"time_mask_N\"", ":", "time_mask_n", ",", "\n", "\"time_mask_T\"", ":", "time_mask_t", ",", "\n", "\"time_mask_p\"", ":", "time_mask_p", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_specaugment_lb_policy": [[171, 179], ["data_utils.S2TDataConfigWriter.set_specaugment"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_specaugment"], ["", "def", "set_specaugment_lb_policy", "(", "self", ")", ":", "\n", "        ", "self", ".", "set_specaugment", "(", "\n", "time_wrap_w", "=", "0", ",", "\n", "freq_mask_n", "=", "1", ",", "\n", "freq_mask_f", "=", "27", ",", "\n", "time_mask_n", "=", "1", ",", "\n", "time_mask_t", "=", "100", ",", "\n", "time_mask_p", "=", "1.0", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_specaugment_ld_policy": [[181, 189], ["data_utils.S2TDataConfigWriter.set_specaugment"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_specaugment"], ["", "def", "set_specaugment_ld_policy", "(", "self", ")", ":", "\n", "        ", "self", ".", "set_specaugment", "(", "\n", "time_wrap_w", "=", "0", ",", "\n", "freq_mask_n", "=", "2", ",", "\n", "freq_mask_f", "=", "27", ",", "\n", "time_mask_n", "=", "2", ",", "\n", "time_mask_t", "=", "100", ",", "\n", "time_mask_p", "=", "1.0", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_specaugment_sm_policy": [[191, 199], ["data_utils.S2TDataConfigWriter.set_specaugment"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_specaugment"], ["", "def", "set_specaugment_sm_policy", "(", "self", ")", ":", "\n", "        ", "self", ".", "set_specaugment", "(", "\n", "time_wrap_w", "=", "0", ",", "\n", "freq_mask_n", "=", "2", ",", "\n", "freq_mask_f", "=", "15", ",", "\n", "time_mask_n", "=", "2", ",", "\n", "time_mask_t", "=", "70", ",", "\n", "time_mask_p", "=", "0.2", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_specaugment_ss_policy": [[201, 209], ["data_utils.S2TDataConfigWriter.set_specaugment"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_specaugment"], ["", "def", "set_specaugment_ss_policy", "(", "self", ")", ":", "\n", "        ", "self", ".", "set_specaugment", "(", "\n", "time_wrap_w", "=", "0", ",", "\n", "freq_mask_n", "=", "2", ",", "\n", "freq_mask_f", "=", "27", ",", "\n", "time_mask_n", "=", "2", ",", "\n", "time_mask_t", "=", "70", ",", "\n", "time_mask_p", "=", "0.2", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_input_channels": [[211, 213], ["None"], "methods", ["None"], ["", "def", "set_input_channels", "(", "self", ",", "input_channels", "=", "1", ")", ":", "\n", "        ", "self", ".", "config", "[", "\"input_channels\"", "]", "=", "input_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_input_feat_per_channel": [[214, 216], ["None"], "methods", ["None"], ["", "def", "set_input_feat_per_channel", "(", "self", ",", "input_feat_per_channel", "=", "80", ")", ":", "\n", "        ", "self", ".", "config", "[", "\"input_feat_per_channel\"", "]", "=", "input_feat_per_channel", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_bpe_tokenizer": [[217, 219], ["None"], "methods", ["None"], ["", "def", "set_bpe_tokenizer", "(", "self", ",", "bpe_tokenizer", ":", "Dict", "[", "str", ",", "Any", "]", ")", ":", "\n", "        ", "self", ".", "config", "[", "\"bpe_tokenizer\"", "]", "=", "bpe_tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_feature_transforms": [[220, 224], ["None"], "methods", ["None"], ["", "def", "set_feature_transforms", "(", "self", ",", "split", ",", "transforms", ":", "List", "[", "str", "]", ")", ":", "\n", "        ", "if", "\"transforms\"", "not", "in", "self", ".", "config", ":", "\n", "            ", "self", ".", "config", "[", "\"transforms\"", "]", "=", "{", "}", "\n", "", "self", ".", "config", "[", "\"transforms\"", "]", "[", "split", "]", "=", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_prepend_tgt_lang_tag": [[225, 227], ["None"], "methods", ["None"], ["", "def", "set_prepend_tgt_lang_tag", "(", "self", ",", "flag", "=", "True", ")", ":", "\n", "        ", "self", ".", "config", "[", "\"prepend_tgt_lang_tag\"", "]", "=", "flag", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_prepend_src_lang_tag": [[228, 230], ["None"], "methods", ["None"], ["", "def", "set_prepend_src_lang_tag", "(", "self", ",", "flag", "=", "True", ")", ":", "\n", "        ", "self", ".", "config", "[", "\"prepend_src_lang_tag\"", "]", "=", "flag", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_sampling_alpha": [[231, 233], ["None"], "methods", ["None"], ["", "def", "set_sampling_alpha", "(", "self", ",", "sampling_alpha", "=", "1.0", ")", ":", "\n", "        ", "self", ".", "config", "[", "\"sampling_alpha\"", "]", "=", "sampling_alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_use_audio_input": [[234, 236], ["None"], "methods", ["None"], ["", "def", "set_use_audio_input", "(", "self", ",", "flag", "=", "True", ")", ":", "\n", "        ", "self", ".", "config", "[", "\"use_audio_input\"", "]", "=", "flag", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_shuffle_dataset": [[237, 239], ["None"], "methods", ["None"], ["", "def", "set_shuffle_dataset", "(", "self", ",", "flag", "=", "True", ")", ":", "\n", "        ", "self", ".", "config", "[", "\"shuffle\"", "]", "=", "flag", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.gen_vocab": [[20, 56], ["sentencepiece.SentencePieceTrainer.train", "sentencepiece.SentencePieceProcessor", "sp.SentencePieceProcessor.Load", "sp.SentencePieceProcessor.IdToPiece", "open", "sorted", "range", "vocab.get", "vocab.get", "vocab.get", "vocab.get", "vocab.items", "vocab.items", "f_out.write", "sp.SentencePieceProcessor.GetPieceSize"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.train", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["def", "gen_vocab", "(", "input_path", ":", "str", ",", "\n", "output_path_prefix", ":", "str", ",", "\n", "model_type", "=", "\"bpe\"", ",", "\n", "vocab_size", "=", "1000", ",", "\n", "accept_language", "=", "None", ",", "\n", "user_defined_symbols", "=", "None", "\n", ")", ":", "\n", "# Train SentencePiece Model", "\n", "    ", "sp", ".", "SentencePieceTrainer", ".", "train", "(", "input", "=", "input_path", ",", "\n", "model_prefix", "=", "output_path_prefix", ",", "\n", "model_type", "=", "model_type", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "accept_language", "=", "accept_language", ",", "\n", "user_defined_symbols", "=", "user_defined_symbols", ",", "\n", "unk_piece", "=", "UNK_TOKEN", ",", "unk_id", "=", "UNK_TOKEN_ID", ",", "\n", "bos_piece", "=", "BOS_TOKEN", ",", "bos_id", "=", "BOS_TOKEN_ID", ",", "\n", "eos_piece", "=", "EOS_TOKEN", ",", "eos_id", "=", "EOS_TOKEN_ID", ",", "\n", "pad_piece", "=", "PAD_TOKEN", ",", "pad_id", "=", "PAD_TOKEN_ID", ")", "\n", "# Export fairseq dictionary", "\n", "spm", "=", "sp", ".", "SentencePieceProcessor", "(", ")", "\n", "spm", ".", "Load", "(", "output_path_prefix", "+", "\".model\"", ")", "\n", "vocab", "=", "{", "i", ":", "spm", ".", "IdToPiece", "(", "i", ")", "for", "i", "in", "range", "(", "spm", ".", "GetPieceSize", "(", ")", ")", "}", "\n", "assert", "(", "\n", "vocab", ".", "get", "(", "UNK_TOKEN_ID", ")", "==", "UNK_TOKEN", "\n", "and", "vocab", ".", "get", "(", "PAD_TOKEN_ID", ")", "==", "PAD_TOKEN", "\n", "and", "vocab", ".", "get", "(", "BOS_TOKEN_ID", ")", "==", "BOS_TOKEN", "\n", "and", "vocab", ".", "get", "(", "EOS_TOKEN_ID", ")", "==", "EOS_TOKEN", "\n", ")", "\n", "vocab", "=", "{", "\n", "i", ":", "s", "\n", "for", "i", ",", "s", "in", "vocab", ".", "items", "(", ")", "\n", "if", "s", "not", "in", "{", "UNK_TOKEN", ",", "BOS_TOKEN", ",", "EOS_TOKEN", ",", "PAD_TOKEN", "}", "\n", "}", "\n", "with", "open", "(", "output_path_prefix", "+", "\".txt\"", ",", "\"w\"", ")", "as", "f_out", ":", "\n", "        ", "for", "_", ",", "s", "in", "sorted", "(", "vocab", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", ":", "\n", "            ", "f_out", ".", "write", "(", "f\"{s} 1\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.gen_config_yaml": [[58, 81], ["os.abspath", "data_utils.S2TDataConfigWriter", "data_utils.S2TDataConfigWriter.set_audio_root", "data_utils.S2TDataConfigWriter.set_vocab_filename", "data_utils.S2TDataConfigWriter.set_input_channels", "data_utils.S2TDataConfigWriter.set_bpe_tokenizer", "data_utils.S2TDataConfigWriter.set_prepend_tgt_lang_tag", "data_utils.S2TDataConfigWriter.set_prepend_src_lang_tag", "data_utils.S2TDataConfigWriter.set_use_audio_input", "data_utils.S2TDataConfigWriter.set_shuffle_dataset", "data_utils.S2TDataConfigWriter.flush", "os.join", "os.abspath", "spm_filename.replace", "os.join"], "function", ["home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_audio_root", "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_vocab_filename", "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_input_channels", "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_bpe_tokenizer", "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_prepend_tgt_lang_tag", "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_prepend_src_lang_tag", "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_use_audio_input", "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.set_shuffle_dataset", "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.flush"], ["", "", "", "def", "gen_config_yaml", "(", "\n", "data_root", ",", "\n", "spm_filename", ",", "\n", "yaml_filename", "=", "\"config.yaml\"", ",", "\n", "prepend_tgt_lang_tag", "=", "True", ",", "\n", "prepend_src_lang_tag", "=", "True", "\n", ")", ":", "\n", "    ", "data_root", "=", "op", ".", "abspath", "(", "data_root", ")", "\n", "writer", "=", "S2TDataConfigWriter", "(", "op", ".", "join", "(", "data_root", ",", "yaml_filename", ")", ")", "\n", "writer", ".", "set_audio_root", "(", "op", ".", "abspath", "(", "data_root", ")", ")", "\n", "writer", ".", "set_vocab_filename", "(", "spm_filename", ".", "replace", "(", "\".model\"", ",", "\".txt\"", ")", ")", "\n", "writer", ".", "set_input_channels", "(", "1", ")", "\n", "writer", ".", "set_bpe_tokenizer", "(", "\n", "{", "\n", "\"bpe\"", ":", "\"sentencepiece\"", ",", "\n", "\"sentencepiece_model\"", ":", "op", ".", "join", "(", "data_root", ",", "spm_filename", ")", ",", "\n", "}", "\n", ")", "\n", "writer", ".", "set_prepend_tgt_lang_tag", "(", "prepend_tgt_lang_tag", ")", "\n", "writer", ".", "set_prepend_src_lang_tag", "(", "prepend_src_lang_tag", ")", "\n", "writer", ".", "set_use_audio_input", "(", "True", ")", "\n", "writer", ".", "set_shuffle_dataset", "(", "True", ")", "\n", "writer", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.load_df_from_tsv": [[83, 92], ["pandas.read_csv"], "function", ["None"], ["", "def", "load_df_from_tsv", "(", "path", ":", "str", ")", ":", "\n", "    ", "return", "pd", ".", "read_csv", "(", "\n", "path", ",", "\n", "sep", "=", "\"\\t\"", ",", "\n", "header", "=", "0", ",", "\n", "encoding", "=", "\"utf-8\"", ",", "\n", "escapechar", "=", "\"\\\\\"", ",", "\n", "quoting", "=", "csv", ".", "QUOTE_NONE", ",", "\n", "na_filter", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.save_df_to_tsv": [[95, 104], ["dataframe.to_csv"], "function", ["None"], ["", "def", "save_df_to_tsv", "(", "dataframe", ",", "path", ")", ":", "\n", "    ", "dataframe", ".", "to_csv", "(", "\n", "path", ",", "\n", "sep", "=", "\"\\t\"", ",", "\n", "header", "=", "True", ",", "\n", "index", "=", "False", ",", "\n", "encoding", "=", "\"utf-8\"", ",", "\n", "escapechar", "=", "\"\\\\\"", ",", "\n", "quoting", "=", "csv", ".", "QUOTE_NONE", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.filter_manifest_df": [[107, 127], ["functools.reduce", "print", "filters.update", "filters.values", "functools.reduce.sum", "valid.sum", "filters.items", "f.sum"], "function", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update"], ["", "def", "filter_manifest_df", "(", "\n", "df", ",", "is_train_split", "=", "False", ",", "extra_filters", "=", "None", ",", "min_n_frames", "=", "5", ",", "max_n_frames", "=", "3000", "\n", ")", ":", "\n", "    ", "filters", "=", "{", "\n", "\"no speech\"", ":", "df", "[", "\"audio\"", "]", "==", "\"\"", ",", "\n", "f\"short speech (<{min_n_frames} frames)\"", ":", "df", "[", "\"n_frames\"", "]", "<", "min_n_frames", ",", "\n", "\"empty sentence\"", ":", "df", "[", "\"tgt_text\"", "]", "==", "\"\"", ",", "\n", "}", "\n", "if", "is_train_split", ":", "\n", "        ", "filters", "[", "f\"long speech (>{max_n_frames} frames)\"", "]", "=", "df", "[", "\"n_frames\"", "]", ">", "max_n_frames", "\n", "", "if", "extra_filters", "is", "not", "None", ":", "\n", "        ", "filters", ".", "update", "(", "extra_filters", ")", "\n", "", "invalid", "=", "reduce", "(", "lambda", "x", ",", "y", ":", "x", "|", "y", ",", "filters", ".", "values", "(", ")", ")", "\n", "valid", "=", "~", "invalid", "\n", "print", "(", "\n", "\"| \"", "\n", "+", "\", \"", ".", "join", "(", "f\"{n}: {f.sum()}\"", "for", "n", ",", "f", "in", "filters", ".", "items", "(", ")", ")", "\n", "+", "f\", total {invalid.sum()} filtered, {valid.sum()} remained.\"", "\n", ")", "\n", "return", "df", "[", "valid", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.prep_mustc_data.MUSTC.__init__": [[39, 79], ["os.join", "itertools.groupby", "os.join", "os.join", "os.isdir", "os.isdir", "os.isdir", "open", "yaml.load", "enumerate", "os.join", "os.relpath", "sorted", "enumerate", "print", "os.join", "open", "len", "len", "torchaudio.info", "int", "int", "prep_mustc_data.MUSTC.data.append", "os.join", "r.strip", "float", "float", "os.splitext"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["def", "__init__", "(", "self", ",", "root", ":", "str", ",", "lang", ":", "str", ",", "split", ":", "str", ")", "->", "None", ":", "\n", "        ", "assert", "split", "in", "self", ".", "SPLITS", "and", "lang", "in", "self", ".", "LANGUAGES", "\n", "_root", "=", "op", ".", "join", "(", "root", ",", "f\"en-{lang}\"", ",", "\"data\"", ",", "split", ")", "\n", "wav_root", ",", "txt_root", "=", "op", ".", "join", "(", "_root", ",", "\"wav\"", ")", ",", "op", ".", "join", "(", "_root", ",", "\"txt\"", ")", "\n", "assert", "op", ".", "isdir", "(", "_root", ")", "and", "op", ".", "isdir", "(", "wav_root", ")", "and", "op", ".", "isdir", "(", "txt_root", ")", "\n", "# Load audio segments", "\n", "try", ":", "\n", "            ", "import", "yaml", "\n", "", "except", "ImportError", ":", "\n", "            ", "print", "(", "\"Please install PyYAML to load YAML files for \"", "\"the MuST-C dataset\"", ")", "\n", "", "with", "open", "(", "op", ".", "join", "(", "txt_root", ",", "f\"{split}.yaml\"", ")", ")", "as", "f", ":", "\n", "            ", "segments", "=", "yaml", ".", "load", "(", "f", ",", "Loader", "=", "yaml", ".", "BaseLoader", ")", "\n", "# Load source and target utterances", "\n", "", "for", "_lang", "in", "[", "\"en\"", ",", "lang", "]", ":", "\n", "            ", "with", "open", "(", "op", ".", "join", "(", "txt_root", ",", "f\"{split}.{_lang}\"", ")", ")", "as", "f", ":", "\n", "                ", "utterances", "=", "[", "r", ".", "strip", "(", ")", "for", "r", "in", "f", "]", "\n", "", "assert", "len", "(", "segments", ")", "==", "len", "(", "utterances", ")", "\n", "for", "i", ",", "u", "in", "enumerate", "(", "utterances", ")", ":", "\n", "                ", "segments", "[", "i", "]", "[", "_lang", "]", "=", "u", "\n", "# Gather info", "\n", "", "", "self", ".", "data", "=", "[", "]", "\n", "for", "wav_filename", ",", "_seg_group", "in", "groupby", "(", "segments", ",", "lambda", "x", ":", "x", "[", "\"wav\"", "]", ")", ":", "\n", "            ", "wav_path", "=", "op", ".", "join", "(", "wav_root", ",", "wav_filename", ")", "\n", "relative_wav_path", "=", "op", ".", "relpath", "(", "wav_path", ",", "root", ")", "\n", "sample_rate", "=", "torchaudio", ".", "info", "(", "wav_path", ")", ".", "sample_rate", "\n", "seg_group", "=", "sorted", "(", "_seg_group", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"offset\"", "]", ")", "\n", "for", "i", ",", "segment", "in", "enumerate", "(", "seg_group", ")", ":", "\n", "                ", "offset", "=", "int", "(", "float", "(", "segment", "[", "\"offset\"", "]", ")", "*", "sample_rate", ")", "\n", "n_frames", "=", "int", "(", "float", "(", "segment", "[", "\"duration\"", "]", ")", "*", "sample_rate", ")", "\n", "_id", "=", "f\"{op.splitext(wav_filename)[0]}_{i}\"", "\n", "self", ".", "data", ".", "append", "(", "\n", "(", "\n", "relative_wav_path", ",", "\n", "offset", ",", "\n", "n_frames", ",", "\n", "sample_rate", ",", "\n", "segment", "[", "\"en\"", "]", ",", "\n", "segment", "[", "lang", "]", ",", "\n", "segment", "[", "\"speaker_id\"", "]", ",", "\n", "_id", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.prep_mustc_data.MUSTC.__getitem__": [[82, 84], ["None"], "methods", ["None"], ["", "", "", "def", "__getitem__", "(", "self", ",", "n", ":", "int", ")", "->", "Tuple", "[", "str", ",", "int", ",", "int", ",", "int", ",", "str", ",", "str", ",", "str", ",", "str", "]", ":", "\n", "        ", "return", "self", ".", "data", "[", "n", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.prep_mustc_data.MUSTC.__len__": [[85, 87], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.prep_mustc_data.process": [[89, 135], ["os.join", "data_utils.gen_config_yaml", "os.isdir", "FileExistsError", "split.startswith", "prep_mustc_data.MUSTC", "tqdm.tqdm", "pandas.DataFrame.from_dict", "data_utils.filter_manifest_df", "data_utils.save_df_to_tsv", "str", "tempfile.NamedTemporaryFile", "data_utils.gen_vocab", "manifest[].append", "manifest[].append", "manifest[].append", "manifest[].append", "manifest[].append", "manifest[].append", "manifest[].append", "manifest[].append", "train_text.extend", "train_text.extend", "os.join", "f.write", "os.join"], "function", ["home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.gen_config_yaml", "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.filter_manifest_df", "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.save_df_to_tsv", "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.gen_vocab"], ["", "", "def", "process", "(", "args", ")", ":", "\n", "    ", "lang", "=", "args", ".", "lang", "\n", "cur_root", "=", "op", ".", "join", "(", "args", ".", "data_root", ",", "f\"en-{lang}\"", ")", "\n", "if", "not", "op", ".", "isdir", "(", "cur_root", ")", ":", "\n", "        ", "FileExistsError", "(", "f\"{cur_root} does not exist.\"", ")", "\n", "", "train_text", "=", "[", "]", "\n", "for", "split", "in", "MUSTC", ".", "SPLITS", ":", "\n", "        ", "is_train_split", "=", "split", ".", "startswith", "(", "\"train\"", ")", "\n", "manifest", "=", "{", "c", ":", "[", "]", "for", "c", "in", "MANIFEST_COLUMNS", "}", "\n", "dataset", "=", "MUSTC", "(", "args", ".", "data_root", ",", "lang", ",", "split", ")", "\n", "for", "wav_path", ",", "offset", ",", "n_frames", ",", "sr", ",", "src_utt", ",", "tgt_utt", ",", "spk_id", ",", "utt_id", "in", "tqdm", "(", "dataset", ")", ":", "\n", "            ", "manifest", "[", "\"id\"", "]", ".", "append", "(", "utt_id", ")", "\n", "manifest", "[", "\"audio\"", "]", ".", "append", "(", "f\"{wav_path}:{offset}:{n_frames}\"", ")", "\n", "manifest", "[", "\"n_frames\"", "]", ".", "append", "(", "n_frames", ")", "\n", "manifest", "[", "\"tgt_text\"", "]", ".", "append", "(", "tgt_utt", ")", "\n", "manifest", "[", "\"speaker\"", "]", ".", "append", "(", "spk_id", ")", "\n", "manifest", "[", "\"src_lang\"", "]", ".", "append", "(", "\"en\"", ")", "\n", "manifest", "[", "\"tgt_lang\"", "]", ".", "append", "(", "lang", ")", "\n", "manifest", "[", "\"src_text\"", "]", ".", "append", "(", "src_utt", ")", "\n", "", "if", "is_train_split", ":", "\n", "            ", "train_text", ".", "extend", "(", "manifest", "[", "\"tgt_text\"", "]", ")", "\n", "train_text", ".", "extend", "(", "manifest", "[", "\"src_text\"", "]", ")", "\n", "", "df", "=", "pd", ".", "DataFrame", ".", "from_dict", "(", "manifest", ")", "\n", "df", "=", "filter_manifest_df", "(", "df", ",", "is_train_split", "=", "is_train_split", ",", "min_n_frames", "=", "1000", ",", "max_n_frames", "=", "480000", ")", "\n", "save_df_to_tsv", "(", "df", ",", "op", ".", "join", "(", "args", ".", "data_root", ",", "f\"{split}_st.tsv\"", ")", ")", "\n", "\n", "", "v_size_str", "=", "\"\"", "if", "args", ".", "vocab_type", "==", "\"char\"", "else", "str", "(", "args", ".", "vocab_size", ")", "\n", "spm_filename_prefix", "=", "f\"spm_{args.vocab_type}{v_size_str}_st\"", "\n", "with", "NamedTemporaryFile", "(", "mode", "=", "\"w\"", ")", "as", "f", ":", "\n", "        ", "for", "t", "in", "train_text", ":", "\n", "            ", "f", ".", "write", "(", "t", "+", "\"\\n\"", ")", "\n", "", "gen_vocab", "(", "\n", "f", ".", "name", ",", "\n", "op", ".", "join", "(", "args", ".", "data_root", ",", "spm_filename_prefix", ")", ",", "\n", "args", ".", "vocab_type", ",", "\n", "args", ".", "vocab_size", ",", "\n", "accept_language", "=", "[", "\"en\"", ",", "f\"{lang}\"", "]", ",", "\n", "user_defined_symbols", "=", "[", "\"<lang:en>\"", ",", "f\"<lang:{lang}>\"", "]", ",", "\n", ")", "\n", "# Generate config YAML", "\n", "", "gen_config_yaml", "(", "\n", "args", ".", "data_root", ",", "\n", "spm_filename_prefix", "+", "\".model\"", ",", "\n", "yaml_filename", "=", "f\"config_st.yaml\"", ",", "\n", "prepend_tgt_lang_tag", "=", "True", ",", "\n", "prepend_src_lang_tag", "=", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.prepare_data.prep_mustc_data.main": [[138, 149], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "prep_mustc_data.process"], "function", ["home.repos.pwc.inspect_result.reneeye_const.prepare_data.prep_mustc_data.process"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--data-root\"", ",", "\"-d\"", ",", "required", "=", "True", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--lang\"", ",", "type", "=", "str", ",", "default", "=", "\"de\"", ",", "\n", "choices", "=", "[", "\"de\"", ",", "\"es\"", ",", "\"fr\"", ",", "\"it\"", ",", "\"nl\"", ",", "\"pt\"", ",", "\"ro\"", ",", "\"ru\"", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--vocab-type\"", ",", "default", "=", "\"unigram\"", ",", "required", "=", "True", ",", "type", "=", "str", ",", "\n", "choices", "=", "[", "\"bpe\"", ",", "\"unigram\"", ",", "\"char\"", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--vocab-size\"", ",", "default", "=", "10000", ",", "type", "=", "int", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "process", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scripts.average_checkpoints.average_checkpoints": [[16, 74], ["collections.OrderedDict", "len", "collections.OrderedDict", "collections.OrderedDict.items", "list", "averaged_params[].is_floating_point", "fairseq.file_io.PathManager.open", "torch.load", "model_params.keys", "isinstance", "averaged_params[].div_", "KeyError", "p.float.float", "p.float.clone", "torch.serialization.default_restore_location"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load"], ["def", "average_checkpoints", "(", "inputs", ")", ":", "\n", "    ", "\"\"\"Loads checkpoints from inputs and returns a model with averaged weights.\n\n    Args:\n      inputs: An iterable of string paths of checkpoints to load from.\n\n    Returns:\n      A dict of string keys mapping to various values. The 'model' key\n      from the returned dict should correspond to an OrderedDict mapping\n      string parameter names to torch Tensors.\n    \"\"\"", "\n", "params_dict", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "params_keys", "=", "None", "\n", "new_state", "=", "None", "\n", "num_models", "=", "len", "(", "inputs", ")", "\n", "\n", "for", "fpath", "in", "inputs", ":", "\n", "        ", "with", "PathManager", ".", "open", "(", "fpath", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "state", "=", "torch", ".", "load", "(", "\n", "f", ",", "\n", "map_location", "=", "(", "\n", "lambda", "s", ",", "_", ":", "torch", ".", "serialization", ".", "default_restore_location", "(", "s", ",", "\"cpu\"", ")", "\n", ")", ",", "\n", ")", "\n", "# Copies over the settings from the first checkpoint", "\n", "", "if", "new_state", "is", "None", ":", "\n", "            ", "new_state", "=", "state", "\n", "\n", "", "model_params", "=", "state", "[", "\"model\"", "]", "\n", "\n", "model_params_keys", "=", "list", "(", "model_params", ".", "keys", "(", ")", ")", "\n", "if", "params_keys", "is", "None", ":", "\n", "            ", "params_keys", "=", "model_params_keys", "\n", "", "elif", "params_keys", "!=", "model_params_keys", ":", "\n", "            ", "raise", "KeyError", "(", "\n", "\"For checkpoint {}, expected list of params: {}, \"", "\n", "\"but found: {}\"", ".", "format", "(", "f", ",", "params_keys", ",", "model_params_keys", ")", "\n", ")", "\n", "\n", "", "for", "k", "in", "params_keys", ":", "\n", "            ", "p", "=", "model_params", "[", "k", "]", "\n", "if", "isinstance", "(", "p", ",", "torch", ".", "HalfTensor", ")", ":", "\n", "                ", "p", "=", "p", ".", "float", "(", ")", "\n", "", "if", "k", "not", "in", "params_dict", ":", "\n", "                ", "params_dict", "[", "k", "]", "=", "p", ".", "clone", "(", ")", "\n", "# NOTE: clone() is needed in case of p is a shared parameter", "\n", "", "else", ":", "\n", "                ", "params_dict", "[", "k", "]", "+=", "p", "\n", "\n", "", "", "", "averaged_params", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "params_dict", ".", "items", "(", ")", ":", "\n", "        ", "averaged_params", "[", "k", "]", "=", "v", "\n", "if", "averaged_params", "[", "k", "]", ".", "is_floating_point", "(", ")", ":", "\n", "            ", "averaged_params", "[", "k", "]", ".", "div_", "(", "num_models", ")", "\n", "", "else", ":", "\n", "            ", "averaged_params", "[", "k", "]", "//=", "num_models", "\n", "", "", "new_state", "[", "\"model\"", "]", "=", "averaged_params", "\n", "return", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scripts.average_checkpoints.last_n_checkpoints": [[76, 97], ["fairseq.file_io.PathManager.ls", "len", "re.compile", "re.compile", "re.compile.fullmatch", "len", "Exception", "os.path.join", "int", "len", "pt_regexp.fullmatch.group", "entries.append", "sorted", "pt_regexp.fullmatch.group"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.ls"], ["", "def", "last_n_checkpoints", "(", "paths", ",", "n", ",", "update_based", ",", "upper_bound", "=", "None", ")", ":", "\n", "    ", "assert", "len", "(", "paths", ")", "==", "1", "\n", "path", "=", "paths", "[", "0", "]", "\n", "if", "update_based", ":", "\n", "        ", "pt_regexp", "=", "re", ".", "compile", "(", "r\"checkpoint_\\d+_(\\d+)\\.pt\"", ")", "\n", "", "else", ":", "\n", "        ", "pt_regexp", "=", "re", ".", "compile", "(", "r\"checkpoint(\\d+)\\.pt\"", ")", "\n", "", "files", "=", "PathManager", ".", "ls", "(", "path", ")", "\n", "\n", "entries", "=", "[", "]", "\n", "for", "f", "in", "files", ":", "\n", "        ", "m", "=", "pt_regexp", ".", "fullmatch", "(", "f", ")", "\n", "if", "m", "is", "not", "None", ":", "\n", "            ", "sort_key", "=", "int", "(", "m", ".", "group", "(", "1", ")", ")", "\n", "if", "upper_bound", "is", "None", "or", "sort_key", "<=", "upper_bound", ":", "\n", "                ", "entries", ".", "append", "(", "(", "sort_key", ",", "m", ".", "group", "(", "0", ")", ")", ")", "\n", "", "", "", "if", "len", "(", "entries", ")", "<", "n", ":", "\n", "        ", "raise", "Exception", "(", "\n", "\"Found {} checkpoint files but need at least {}\"", ",", "len", "(", "entries", ")", ",", "n", "\n", ")", "\n", "", "return", "[", "os", ".", "path", ".", "join", "(", "path", ",", "x", "[", "1", "]", ")", "for", "x", "in", "sorted", "(", "entries", ",", "reverse", "=", "True", ")", "[", ":", "n", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scripts.average_checkpoints.get_ckpt_from_prefix": [[99, 110], ["fairseq.file_io.PathManager.ls", "len", "f.startswith", "entries.append", "os.path.join"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.ls"], ["", "def", "get_ckpt_from_prefix", "(", "paths", ",", "prefix", ")", ":", "\n", "    ", "assert", "len", "(", "paths", ")", "==", "1", "\n", "path", "=", "paths", "[", "0", "]", "\n", "files", "=", "PathManager", ".", "ls", "(", "path", ")", "\n", "\n", "entries", "=", "[", "]", "\n", "for", "f", "in", "files", ":", "\n", "        ", "if", "f", ".", "startswith", "(", "prefix", ")", ":", "\n", "            ", "entries", ".", "append", "(", "os", ".", "path", ".", "join", "(", "path", ",", "f", ")", ")", "\n", "\n", "", "", "return", "entries", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scripts.average_checkpoints.main": [[112, 181], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_mutually_exclusive_group", "parser.add_mutually_exclusive_group.add_argument", "parser.add_mutually_exclusive_group.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "print", "average_checkpoints.average_checkpoints", "parser.parse_args.output.endswith", "print", "average_checkpoints.last_n_checkpoints", "print", "average_checkpoints.get_ckpt_from_prefix", "print", "parser.parse_args.inputs[].split", "fairseq.file_io.PathManager.open", "torch.save"], "function", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print", "home.repos.pwc.inspect_result.reneeye_const.scripts.average_checkpoints.average_checkpoints", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print", "home.repos.pwc.inspect_result.reneeye_const.scripts.average_checkpoints.last_n_checkpoints", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print", "home.repos.pwc.inspect_result.reneeye_const.scripts.average_checkpoints.get_ckpt_from_prefix", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.save"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Tool to average the params of input checkpoints to \"", "\n", "\"produce a new checkpoint\"", ",", "\n", ")", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--inputs'", ",", "required", "=", "True", ",", "nargs", "=", "'+'", ",", "\n", "help", "=", "'Input checkpoint file paths.'", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "required", "=", "True", ",", "metavar", "=", "'FILE'", ",", "\n", "help", "=", "'Write the new checkpoint containing the averaged weights to this path.'", ")", "\n", "num_group", "=", "parser", ".", "add_mutually_exclusive_group", "(", ")", "\n", "num_group", ".", "add_argument", "(", "'--num-epoch-checkpoints'", ",", "type", "=", "int", ",", "\n", "help", "=", "'if set, will try to find checkpoints with names checkpoint_xx.pt in the path specified by input, '", "\n", "'and average last this many of them.'", ")", "\n", "num_group", ".", "add_argument", "(", "'--num-update-checkpoints'", ",", "type", "=", "int", ",", "\n", "help", "=", "'if set, will try to find checkpoints with names checkpoint_ee_xx.pt in the path specified by input, '", "\n", "'and average last this many of them.'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint-upper-bound'", ",", "type", "=", "int", ",", "\n", "help", "=", "'when using --num-epoch-checkpoints, this will set an upper bound on which epoch to use, '", "\n", "'when using --num-update-checkpoints, this will set an upper bound on which update to use'", "\n", "'e.g., with --num-epoch-checkpoints=10 --checkpoint-upper-bound=50, checkpoints 41-50 would be averaged.'", "\n", "'e.g., with --num-update-checkpoints=10 --checkpoint-upper-bound=50000, checkpoints 40500-50000 would be averaged assuming --save-interval-updates 500'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "'--prefix'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"prefix of the checkpoints\"", ")", "\n", "# fmt: on", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "print", "(", "args", ")", "\n", "\n", "num", "=", "None", "\n", "is_update_based", "=", "False", "\n", "if", "args", ".", "num_update_checkpoints", "is", "not", "None", ":", "\n", "        ", "num", "=", "args", ".", "num_update_checkpoints", "\n", "is_update_based", "=", "True", "\n", "", "elif", "args", ".", "num_epoch_checkpoints", "is", "not", "None", ":", "\n", "        ", "num", "=", "args", ".", "num_epoch_checkpoints", "\n", "\n", "", "assert", "args", ".", "checkpoint_upper_bound", "is", "None", "or", "(", "\n", "args", ".", "num_epoch_checkpoints", "is", "not", "None", "\n", "or", "args", ".", "num_update_checkpoints", "is", "not", "None", "\n", ")", ",", "\"--checkpoint-upper-bound requires --num-epoch-checkpoints or --num-update-checkpoints\"", "\n", "assert", "(", "\n", "args", ".", "num_epoch_checkpoints", "is", "None", "or", "args", ".", "num_update_checkpoints", "is", "None", "\n", ")", ",", "\"Cannot combine --num-epoch-checkpoints and --num-update-checkpoints\"", "\n", "\n", "if", "num", "is", "not", "None", ":", "\n", "        ", "args", ".", "inputs", "=", "last_n_checkpoints", "(", "\n", "args", ".", "inputs", ",", "\n", "num", ",", "\n", "is_update_based", ",", "\n", "upper_bound", "=", "args", ".", "checkpoint_upper_bound", ",", "\n", ")", "\n", "print", "(", "\"averaging checkpoints: \"", ",", "args", ".", "inputs", ")", "\n", "\n", "", "if", "args", ".", "prefix", "is", "not", "None", ":", "\n", "        ", "args", ".", "inputs", "=", "get_ckpt_from_prefix", "(", "\n", "args", ".", "inputs", ",", "\n", "args", ".", "prefix", "\n", ")", "\n", "print", "(", "f\"averaging checkpoints start with {args.prefix}:\"", ",", "args", ".", "inputs", ")", "\n", "\n", "", "new_state", "=", "average_checkpoints", "(", "args", ".", "inputs", ")", "\n", "latest_model_name", "=", "args", ".", "inputs", "[", "0", "]", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "\n", "if", "args", ".", "output", ".", "endswith", "(", "\".pt\"", ")", ":", "\n", "        ", "output_model_name", "=", "args", ".", "output", "\n", "", "else", ":", "\n", "        ", "output_model_name", "=", "args", ".", "output", "+", "\"_\"", "+", "latest_model_name", "\n", "", "with", "PathManager", ".", "open", "(", "output_model_name", ",", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "torch", ".", "save", "(", "new_state", ",", "f", ")", "\n", "", "print", "(", "\"Finished writing averaged checkpoint to {}\"", ".", "format", "(", "output_model_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.get_preprocessing_parser": [[29, 33], ["options.get_parser", "options.add_preprocess_args"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.options.get_parser", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_preprocess_args"], ["def", "get_preprocessing_parser", "(", "default_task", "=", "\"translation\"", ")", ":", "\n", "    ", "parser", "=", "get_parser", "(", "\"Preprocessing\"", ",", "default_task", ")", "\n", "add_preprocess_args", "(", "parser", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.get_training_parser": [[35, 43], ["options.get_parser", "options.add_dataset_args", "options.add_distributed_training_args", "options.add_model_args", "options.add_optimization_args", "options.add_checkpoint_args"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.options.get_parser", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_dataset_args", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_distributed_training_args", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_model_args", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_optimization_args", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_checkpoint_args"], ["", "def", "get_training_parser", "(", "default_task", "=", "\"translation\"", ")", ":", "\n", "    ", "parser", "=", "get_parser", "(", "\"Trainer\"", ",", "default_task", ")", "\n", "add_dataset_args", "(", "parser", ",", "train", "=", "True", ")", "\n", "add_distributed_training_args", "(", "parser", ")", "\n", "add_model_args", "(", "parser", ")", "\n", "add_optimization_args", "(", "parser", ")", "\n", "add_checkpoint_args", "(", "parser", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.get_generation_parser": [[45, 54], ["options.get_parser", "options.add_dataset_args", "options.add_distributed_training_args", "options.add_generation_args", "options.add_checkpoint_args", "options.add_interactive_args"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.options.get_parser", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_dataset_args", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_distributed_training_args", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_generation_args", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_checkpoint_args", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_interactive_args"], ["", "def", "get_generation_parser", "(", "interactive", "=", "False", ",", "default_task", "=", "\"translation\"", ")", ":", "\n", "    ", "parser", "=", "get_parser", "(", "\"Generation\"", ",", "default_task", ")", "\n", "add_dataset_args", "(", "parser", ",", "gen", "=", "True", ")", "\n", "add_distributed_training_args", "(", "parser", ",", "default_world_size", "=", "1", ")", "\n", "add_generation_args", "(", "parser", ")", "\n", "add_checkpoint_args", "(", "parser", ")", "\n", "if", "interactive", ":", "\n", "        ", "add_interactive_args", "(", "parser", ")", "\n", "", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.get_interactive_generation_parser": [[56, 58], ["options.get_generation_parser"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.options.get_generation_parser"], ["", "def", "get_interactive_generation_parser", "(", "default_task", "=", "\"translation\"", ")", ":", "\n", "    ", "return", "get_generation_parser", "(", "interactive", "=", "True", ",", "default_task", "=", "default_task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.get_eval_lm_parser": [[60, 66], ["options.get_parser", "options.add_dataset_args", "options.add_distributed_training_args", "options.add_eval_lm_args"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.options.get_parser", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_dataset_args", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_distributed_training_args", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_eval_lm_args"], ["", "def", "get_eval_lm_parser", "(", "default_task", "=", "\"language_modeling\"", ")", ":", "\n", "    ", "parser", "=", "get_parser", "(", "\"Evaluate Language Model\"", ",", "default_task", ")", "\n", "add_dataset_args", "(", "parser", ",", "gen", "=", "True", ")", "\n", "add_distributed_training_args", "(", "parser", ",", "default_world_size", "=", "1", ")", "\n", "add_eval_lm_args", "(", "parser", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.get_validation_parser": [[68, 75], ["options.get_parser", "options.add_dataset_args", "options.add_distributed_training_args", "get_parser.add_argument_group", "fairseq.dataclass.utils.gen_parser_from_dataclass", "fairseq.dataclass.configs.CommonEvalConfig"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.options.get_parser", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_dataset_args", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_distributed_training_args", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.gen_parser_from_dataclass"], ["", "def", "get_validation_parser", "(", "default_task", "=", "None", ")", ":", "\n", "    ", "parser", "=", "get_parser", "(", "\"Validation\"", ",", "default_task", ")", "\n", "add_dataset_args", "(", "parser", ",", "train", "=", "True", ")", "\n", "add_distributed_training_args", "(", "parser", ",", "default_world_size", "=", "1", ")", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "\"Evaluation\"", ")", "\n", "gen_parser_from_dataclass", "(", "group", ",", "CommonEvalConfig", "(", ")", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.parse_args_and_arch": [[77, 208], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "fairseq.utils.import_user_module", "parser.parse_known_args", "hasattr", "hasattr", "getattr", "REGISTRIES.items", "getattr", "getattr", "getattr", "getattr", "options.parse_args_and_arch", "argparse.ArgumentParser", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.parse_args", "argparse.Namespace", "modify_parser", "parser.add_argument_group", "TASK_REGISTRY[].add_args", "FairseqBMUF.add_args", "getattr", "modify_parser", "parser.parse_known_args", "parser.parse_args", "hasattr", "ValueError", "getattr", "hasattr", "ARCH_MODEL_REGISTRY[].add_args", "hasattr", "hasattr", "hasattr", "MODEL_REGISTRY[].add_args", "RuntimeError", "cls.add_args", "hasattr", "fairseq.dataclass.utils.gen_parser_from_dataclass", "vars().items", "vars().items", "cls.__dataclass", "vars", "vars"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.import_user_module", "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.parse_args_and_arch", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.gen_parser_from_dataclass"], ["", "def", "parse_args_and_arch", "(", "\n", "parser", ":", "argparse", ".", "ArgumentParser", ",", "\n", "input_args", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "parse_known", ":", "bool", "=", "False", ",", "\n", "suppress_defaults", ":", "bool", "=", "False", ",", "\n", "modify_parser", ":", "Optional", "[", "Callable", "[", "[", "argparse", ".", "ArgumentParser", "]", ",", "None", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        parser (ArgumentParser): the parser\n        input_args (List[str]): strings to parse, defaults to sys.argv\n        parse_known (bool): only parse known arguments, similar to\n            `ArgumentParser.parse_known_args`\n        suppress_defaults (bool): parse while ignoring all default values\n        modify_parser (Optional[Callable[[ArgumentParser], None]]):\n            function to modify the parser, e.g., to set default values\n    \"\"\"", "\n", "if", "suppress_defaults", ":", "\n", "# Parse args without any default values. This requires us to parse", "\n", "# twice, once to identify all the necessary task/model args, and a second", "\n", "# time with all defaults set to None.", "\n", "        ", "args", "=", "parse_args_and_arch", "(", "\n", "parser", ",", "\n", "input_args", "=", "input_args", ",", "\n", "parse_known", "=", "parse_known", ",", "\n", "suppress_defaults", "=", "False", ",", "\n", ")", "\n", "suppressed_parser", "=", "argparse", ".", "ArgumentParser", "(", "add_help", "=", "False", ",", "parents", "=", "[", "parser", "]", ")", "\n", "suppressed_parser", ".", "set_defaults", "(", "**", "{", "k", ":", "None", "for", "k", ",", "v", "in", "vars", "(", "args", ")", ".", "items", "(", ")", "}", ")", "\n", "args", "=", "suppressed_parser", ".", "parse_args", "(", "input_args", ")", "\n", "return", "argparse", ".", "Namespace", "(", "\n", "**", "{", "k", ":", "v", "for", "k", ",", "v", "in", "vars", "(", "args", ")", ".", "items", "(", ")", "if", "v", "is", "not", "None", "}", "\n", ")", "\n", "\n", "", "from", "fairseq", ".", "models", "import", "ARCH_MODEL_REGISTRY", ",", "ARCH_CONFIG_REGISTRY", ",", "MODEL_REGISTRY", "\n", "\n", "# Before creating the true parser, we need to import optional user module", "\n", "# in order to eagerly import custom tasks, optimizers, architectures, etc.", "\n", "usr_parser", "=", "argparse", ".", "ArgumentParser", "(", "add_help", "=", "False", ",", "allow_abbrev", "=", "False", ")", "\n", "usr_parser", ".", "add_argument", "(", "\"--user-dir\"", ",", "default", "=", "None", ")", "\n", "usr_args", ",", "_", "=", "usr_parser", ".", "parse_known_args", "(", "input_args", ")", "\n", "utils", ".", "import_user_module", "(", "usr_args", ")", "\n", "\n", "if", "modify_parser", "is", "not", "None", ":", "\n", "        ", "modify_parser", "(", "parser", ")", "\n", "\n", "# The parser doesn't know about model/criterion/optimizer-specific args, so", "\n", "# we parse twice. First we parse the model/criterion/optimizer, then we", "\n", "# parse a second time after adding the *-specific arguments.", "\n", "# If input_args is given, we will parse those args instead of sys.argv.", "\n", "", "args", ",", "_", "=", "parser", ".", "parse_known_args", "(", "input_args", ")", "\n", "\n", "# Add model-specific args to parser.", "\n", "if", "hasattr", "(", "args", ",", "\"arch\"", ")", ":", "\n", "        ", "model_specific_group", "=", "parser", ".", "add_argument_group", "(", "\n", "\"Model-specific configuration\"", ",", "\n", "# Only include attributes which are explicitly given as command-line", "\n", "# arguments or which have default values.", "\n", "argument_default", "=", "argparse", ".", "SUPPRESS", ",", "\n", ")", "\n", "if", "args", ".", "arch", "in", "ARCH_MODEL_REGISTRY", ":", "\n", "            ", "ARCH_MODEL_REGISTRY", "[", "args", ".", "arch", "]", ".", "add_args", "(", "model_specific_group", ")", "\n", "", "elif", "args", ".", "arch", "in", "MODEL_REGISTRY", ":", "\n", "            ", "MODEL_REGISTRY", "[", "args", ".", "arch", "]", ".", "add_args", "(", "model_specific_group", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", ")", "\n", "\n", "", "", "if", "hasattr", "(", "args", ",", "\"task\"", ")", ":", "\n", "        ", "from", "fairseq", ".", "tasks", "import", "TASK_REGISTRY", "\n", "\n", "TASK_REGISTRY", "[", "args", ".", "task", "]", ".", "add_args", "(", "parser", ")", "\n", "", "if", "getattr", "(", "args", ",", "\"use_bmuf\"", ",", "False", ")", ":", "\n", "# hack to support extra args for block distributed data parallelism", "\n", "        ", "from", "fairseq", ".", "optim", ".", "bmuf", "import", "FairseqBMUF", "\n", "\n", "FairseqBMUF", ".", "add_args", "(", "parser", ")", "\n", "\n", "# Add *-specific args to parser.", "\n", "", "from", "fairseq", ".", "registry", "import", "REGISTRIES", "\n", "\n", "for", "registry_name", ",", "REGISTRY", "in", "REGISTRIES", ".", "items", "(", ")", ":", "\n", "        ", "choice", "=", "getattr", "(", "args", ",", "registry_name", ",", "None", ")", "\n", "if", "choice", "is", "not", "None", ":", "\n", "            ", "cls", "=", "REGISTRY", "[", "\"registry\"", "]", "[", "choice", "]", "\n", "if", "hasattr", "(", "cls", ",", "\"add_args\"", ")", ":", "\n", "                ", "cls", ".", "add_args", "(", "parser", ")", "\n", "", "elif", "hasattr", "(", "cls", ",", "\"__dataclass\"", ")", ":", "\n", "                ", "gen_parser_from_dataclass", "(", "parser", ",", "cls", ".", "__dataclass", "(", ")", ")", "\n", "\n", "# Modify the parser a second time, since defaults may have been reset", "\n", "", "", "", "if", "modify_parser", "is", "not", "None", ":", "\n", "        ", "modify_parser", "(", "parser", ")", "\n", "\n", "# Parse a second time.", "\n", "", "if", "parse_known", ":", "\n", "        ", "args", ",", "extra", "=", "parser", ".", "parse_known_args", "(", "input_args", ")", "\n", "", "else", ":", "\n", "        ", "args", "=", "parser", ".", "parse_args", "(", "input_args", ")", "\n", "extra", "=", "None", "\n", "# Post-process args.", "\n", "", "if", "(", "\n", "hasattr", "(", "args", ",", "\"batch_size_valid\"", ")", "and", "args", ".", "batch_size_valid", "is", "None", "\n", ")", "or", "not", "hasattr", "(", "args", ",", "\"batch_size_valid\"", ")", ":", "\n", "        ", "args", ".", "batch_size_valid", "=", "args", ".", "batch_size", "\n", "", "if", "hasattr", "(", "args", ",", "\"max_tokens_valid\"", ")", "and", "args", ".", "max_tokens_valid", "is", "None", ":", "\n", "        ", "args", ".", "max_tokens_valid", "=", "args", ".", "max_tokens", "\n", "", "if", "getattr", "(", "args", ",", "\"memory_efficient_fp16\"", ",", "False", ")", ":", "\n", "        ", "args", ".", "fp16", "=", "True", "\n", "", "if", "getattr", "(", "args", ",", "\"memory_efficient_bf16\"", ",", "False", ")", ":", "\n", "        ", "args", ".", "bf16", "=", "True", "\n", "", "args", ".", "tpu", "=", "getattr", "(", "args", ",", "\"tpu\"", ",", "False", ")", "\n", "args", ".", "bf16", "=", "getattr", "(", "args", ",", "\"bf16\"", ",", "False", ")", "\n", "if", "args", ".", "bf16", ":", "\n", "        ", "args", ".", "tpu", "=", "True", "\n", "", "if", "args", ".", "tpu", "and", "args", ".", "fp16", ":", "\n", "        ", "raise", "ValueError", "(", "\"Cannot combine --fp16 and --tpu, use --bf16 on TPUs\"", ")", "\n", "\n", "", "if", "getattr", "(", "args", ",", "\"seed\"", ",", "None", ")", "is", "None", ":", "\n", "        ", "args", ".", "seed", "=", "1", "# default seed for training", "\n", "args", ".", "no_seed_provided", "=", "True", "\n", "", "else", ":", "\n", "        ", "args", ".", "no_seed_provided", "=", "False", "\n", "\n", "# Apply architecture configuration.", "\n", "", "if", "hasattr", "(", "args", ",", "\"arch\"", ")", "and", "args", ".", "arch", "in", "ARCH_CONFIG_REGISTRY", ":", "\n", "        ", "ARCH_CONFIG_REGISTRY", "[", "args", ".", "arch", "]", "(", "args", ")", "\n", "\n", "", "if", "parse_known", ":", "\n", "        ", "return", "args", ",", "extra", "\n", "", "else", ":", "\n", "        ", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.get_parser": [[210, 242], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "fairseq.utils.import_user_module", "argparse.ArgumentParser", "fairseq.dataclass.utils.gen_parser_from_dataclass", "REGISTRIES.items", "argparse.ArgumentParser.add_argument", "fairseq.dataclass.configs.CommonConfig", "argparse.ArgumentParser.add_argument", "TASK_REGISTRY.keys", "registry_name.replace", "REGISTRY[].keys"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.import_user_module", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.gen_parser_from_dataclass"], ["", "", "def", "get_parser", "(", "desc", ",", "default_task", "=", "\"translation\"", ")", ":", "\n", "# Before creating the true parser, we need to import optional user module", "\n", "# in order to eagerly import custom tasks, optimizers, architectures, etc.", "\n", "    ", "usr_parser", "=", "argparse", ".", "ArgumentParser", "(", "add_help", "=", "False", ",", "allow_abbrev", "=", "False", ")", "\n", "usr_parser", ".", "add_argument", "(", "\"--user-dir\"", ",", "default", "=", "None", ")", "\n", "usr_args", ",", "_", "=", "usr_parser", ".", "parse_known_args", "(", ")", "\n", "utils", ".", "import_user_module", "(", "usr_args", ")", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "allow_abbrev", "=", "False", ")", "\n", "gen_parser_from_dataclass", "(", "parser", ",", "CommonConfig", "(", ")", ")", "\n", "\n", "from", "fairseq", ".", "registry", "import", "REGISTRIES", "\n", "\n", "for", "registry_name", ",", "REGISTRY", "in", "REGISTRIES", ".", "items", "(", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "\n", "\"--\"", "+", "registry_name", ".", "replace", "(", "\"_\"", ",", "\"-\"", ")", ",", "\n", "default", "=", "REGISTRY", "[", "\"default\"", "]", ",", "\n", "choices", "=", "REGISTRY", "[", "\"registry\"", "]", ".", "keys", "(", ")", ",", "\n", ")", "\n", "\n", "# Task definitions can be found under fairseq/tasks/", "\n", "", "from", "fairseq", ".", "tasks", "import", "TASK_REGISTRY", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--task\"", ",", "\n", "metavar", "=", "\"TASK\"", ",", "\n", "default", "=", "default_task", ",", "\n", "choices", "=", "TASK_REGISTRY", ".", "keys", "(", ")", ",", "\n", "help", "=", "\"task\"", ",", "\n", ")", "\n", "# fmt: on", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_preprocess_args": [[244, 290], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "fairseq.data.indexed_dataset.get_available_dataset_impl"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.get_available_dataset_impl"], ["", "def", "add_preprocess_args", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "\"Preprocessing\"", ")", "\n", "# fmt: off", "\n", "group", ".", "add_argument", "(", "\"-s\"", ",", "\"--source-lang\"", ",", "default", "=", "None", ",", "metavar", "=", "\"SRC\"", ",", "\n", "help", "=", "\"source language\"", ")", "\n", "group", ".", "add_argument", "(", "\"-t\"", ",", "\"--target-lang\"", ",", "default", "=", "None", ",", "metavar", "=", "\"TARGET\"", ",", "\n", "help", "=", "\"target language\"", ")", "\n", "group", ".", "add_argument", "(", "\"--trainpref\"", ",", "metavar", "=", "\"FP\"", ",", "default", "=", "None", ",", "\n", "help", "=", "\"train file prefix (also used to build dictionaries)\"", ")", "\n", "group", ".", "add_argument", "(", "\"--validpref\"", ",", "metavar", "=", "\"FP\"", ",", "default", "=", "None", ",", "\n", "help", "=", "\"comma separated, valid file prefixes \"", "\n", "\"(words missing from train set are replaced with <unk>)\"", ")", "\n", "group", ".", "add_argument", "(", "\"--testpref\"", ",", "metavar", "=", "\"FP\"", ",", "default", "=", "None", ",", "\n", "help", "=", "\"comma separated, test file prefixes \"", "\n", "\"(words missing from train set are replaced with <unk>)\"", ")", "\n", "group", ".", "add_argument", "(", "\"--align-suffix\"", ",", "metavar", "=", "\"FP\"", ",", "default", "=", "None", ",", "\n", "help", "=", "\"alignment file suffix\"", ")", "\n", "group", ".", "add_argument", "(", "\"--destdir\"", ",", "metavar", "=", "\"DIR\"", ",", "default", "=", "\"data-bin\"", ",", "\n", "help", "=", "\"destination dir\"", ")", "\n", "group", ".", "add_argument", "(", "\"--thresholdtgt\"", ",", "metavar", "=", "\"N\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"map words appearing less than threshold times to unknown\"", ")", "\n", "group", ".", "add_argument", "(", "\"--thresholdsrc\"", ",", "metavar", "=", "\"N\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"map words appearing less than threshold times to unknown\"", ")", "\n", "group", ".", "add_argument", "(", "\"--tgtdict\"", ",", "metavar", "=", "\"FP\"", ",", "\n", "help", "=", "\"reuse given target dictionary\"", ")", "\n", "group", ".", "add_argument", "(", "\"--srcdict\"", ",", "metavar", "=", "\"FP\"", ",", "\n", "help", "=", "\"reuse given source dictionary\"", ")", "\n", "group", ".", "add_argument", "(", "\"--nwordstgt\"", ",", "metavar", "=", "\"N\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"number of target words to retain\"", ")", "\n", "group", ".", "add_argument", "(", "\"--nwordssrc\"", ",", "metavar", "=", "\"N\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"number of source words to retain\"", ")", "\n", "group", ".", "add_argument", "(", "\"--alignfile\"", ",", "metavar", "=", "\"ALIGN\"", ",", "default", "=", "None", ",", "\n", "help", "=", "\"an alignment file (optional)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset-impl'", ",", "metavar", "=", "'FORMAT'", ",", "default", "=", "'mmap'", ",", "\n", "choices", "=", "get_available_dataset_impl", "(", ")", ",", "\n", "help", "=", "'output dataset implementation'", ")", "\n", "group", ".", "add_argument", "(", "\"--joined-dictionary\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Generate joined dictionary\"", ")", "\n", "group", ".", "add_argument", "(", "\"--only-source\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Only process the source language\"", ")", "\n", "group", ".", "add_argument", "(", "\"--padding-factor\"", ",", "metavar", "=", "\"N\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Pad dictionary size to be multiple of N\"", ")", "\n", "group", ".", "add_argument", "(", "\"--workers\"", ",", "metavar", "=", "\"N\"", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"number of parallel workers\"", ")", "\n", "# fmt: on", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_dataset_args": [[292, 297], ["parser.add_argument_group", "fairseq.dataclass.utils.gen_parser_from_dataclass", "fairseq.dataclass.configs.DatasetConfig"], "function", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.gen_parser_from_dataclass"], ["", "def", "add_dataset_args", "(", "parser", ",", "train", "=", "False", ",", "gen", "=", "False", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "\"dataset_data_loading\"", ")", "\n", "gen_parser_from_dataclass", "(", "group", ",", "DatasetConfig", "(", ")", ")", "\n", "# fmt: on", "\n", "return", "group", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_distributed_training_args": [[299, 307], ["parser.add_argument_group", "fairseq.dataclass.utils.gen_parser_from_dataclass", "max", "fairseq.dataclass.configs.DistributedTrainingConfig", "torch.cuda.device_count"], "function", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.gen_parser_from_dataclass"], ["", "def", "add_distributed_training_args", "(", "parser", ",", "default_world_size", "=", "None", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "\"distributed_training\"", ")", "\n", "if", "default_world_size", "is", "None", ":", "\n", "        ", "default_world_size", "=", "max", "(", "1", ",", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", "\n", "", "gen_parser_from_dataclass", "(", "\n", "group", ",", "DistributedTrainingConfig", "(", "distributed_world_size", "=", "default_world_size", ")", "\n", ")", "\n", "return", "group", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_optimization_args": [[309, 315], ["parser.add_argument_group", "fairseq.dataclass.utils.gen_parser_from_dataclass", "fairseq.dataclass.configs.OptimizationConfig"], "function", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.gen_parser_from_dataclass"], ["", "def", "add_optimization_args", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "\"optimization\"", ")", "\n", "# fmt: off", "\n", "gen_parser_from_dataclass", "(", "group", ",", "OptimizationConfig", "(", ")", ")", "\n", "# fmt: on", "\n", "return", "group", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_checkpoint_args": [[317, 323], ["parser.add_argument_group", "fairseq.dataclass.utils.gen_parser_from_dataclass", "fairseq.dataclass.configs.CheckpointConfig"], "function", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.gen_parser_from_dataclass"], ["", "def", "add_checkpoint_args", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "\"checkpoint\"", ")", "\n", "# fmt: off", "\n", "gen_parser_from_dataclass", "(", "group", ",", "CheckpointConfig", "(", ")", ")", "\n", "# fmt: on", "\n", "return", "group", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_common_eval_args": [[325, 327], ["fairseq.dataclass.utils.gen_parser_from_dataclass", "fairseq.dataclass.configs.CommonEvalConfig"], "function", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.gen_parser_from_dataclass"], ["", "def", "add_common_eval_args", "(", "group", ")", ":", "\n", "    ", "gen_parser_from_dataclass", "(", "group", ",", "CommonEvalConfig", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_eval_lm_args": [[329, 333], ["parser.add_argument_group", "options.add_common_eval_args", "fairseq.dataclass.utils.gen_parser_from_dataclass", "fairseq.dataclass.configs.EvalLMConfig"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_common_eval_args", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.gen_parser_from_dataclass"], ["", "def", "add_eval_lm_args", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "\"LM Evaluation\"", ")", "\n", "add_common_eval_args", "(", "group", ")", "\n", "gen_parser_from_dataclass", "(", "group", ",", "EvalLMConfig", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_generation_args": [[335, 340], ["parser.add_argument_group", "options.add_common_eval_args", "fairseq.dataclass.utils.gen_parser_from_dataclass", "fairseq.dataclass.configs.GenerationConfig"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_common_eval_args", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.gen_parser_from_dataclass"], ["", "def", "add_generation_args", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "\"Generation\"", ")", "\n", "add_common_eval_args", "(", "group", ")", "\n", "gen_parser_from_dataclass", "(", "group", ",", "GenerationConfig", "(", ")", ")", "\n", "return", "group", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_interactive_args": [[342, 345], ["parser.add_argument_group", "fairseq.dataclass.utils.gen_parser_from_dataclass", "fairseq.dataclass.configs.InteractiveConfig"], "function", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.gen_parser_from_dataclass"], ["", "def", "add_interactive_args", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "\"Interactive\"", ")", "\n", "gen_parser_from_dataclass", "(", "group", ",", "InteractiveConfig", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.options.add_model_args": [[347, 364], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "ARCH_MODEL_REGISTRY.keys"], "function", ["None"], ["", "def", "add_model_args", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "\"Model configuration\"", ")", "\n", "# fmt: off", "\n", "\n", "# Model definitions can be found under fairseq/models/", "\n", "#", "\n", "# The model architecture can be specified in several ways.", "\n", "# In increasing order of priority:", "\n", "# 1) model defaults (lowest priority)", "\n", "# 2) --arch argument", "\n", "# 3) --encoder/decoder-* arguments (highest priority)", "\n", "from", "fairseq", ".", "models", "import", "ARCH_MODEL_REGISTRY", "\n", "group", ".", "add_argument", "(", "'--arch'", ",", "'-a'", ",", "metavar", "=", "'ARCH'", ",", "\n", "choices", "=", "ARCH_MODEL_REGISTRY", ".", "keys", "(", ")", ",", "\n", "help", "=", "'model architecture'", ")", "\n", "# fmt: on", "\n", "return", "group", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.is_master": [[42, 44], ["None"], "function", ["None"], ["def", "is_master", "(", "cfg", ":", "DistributedTrainingConfig", ")", ":", "\n", "    ", "return", "cfg", ".", "distributed_rank", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.infer_init_method": [[46, 212], ["all", "fairseq.utils.eval_str_list", "torch.cuda.device_count", "torch.cuda.device_count", "int", "int", "ValueError", "ValueError", "fairseq.utils.eval_str_list", "len", "fairseq.utils.eval_str_list", "fairseq.utils.eval_str_list", "len", "os.environ.get", "logger.debug", "torch.cuda.set_device", "torch.cuda.set_device", "logger.info", "set", "set", "os.environ.get", "random.randint", "omegaconf.open_dict", "omegaconf.open_dict", "omegaconf.open_dict", "min", "subprocess.check_output", "int", "os.environ.get", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "os.environ.get", "int", "int", "int", "int", "torch.cuda.device_count", "torch.cuda.device_count", "int", "torch.cuda.device_count", "torch.cuda.device_count", "[].decode", "os.environ.get", "os.environ.get", "os.environ.get", "int", "int", "int", "int", "os.environ.get", "os.environ.get", "os.environ.get", "os.environ.get", "subprocess.check_output.split"], "function", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.eval_str_list", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.eval_str_list", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.eval_str_list", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.eval_str_list", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "infer_init_method", "(", "cfg", ":", "DistributedTrainingConfig", ",", "force_distributed", "=", "False", ")", ":", "\n", "    ", "if", "cfg", ".", "distributed_init_method", "is", "not", "None", "or", "cfg", ".", "tpu", ":", "\n", "        ", "return", "\n", "\n", "", "if", "cfg", ".", "pipeline_model_parallel", ":", "\n", "        ", "balance_exists", "=", "(", "\n", "cfg", ".", "pipeline_balance", "is", "not", "None", "\n", "or", "cfg", ".", "pipeline_encoder_balance", "is", "not", "None", "\n", "or", "cfg", ".", "pipeline_decoder_balance", "is", "not", "None", "\n", ")", "\n", "devices_exist", "=", "(", "\n", "cfg", ".", "pipeline_devices", "is", "not", "None", "\n", "or", "cfg", ".", "pipeline_encoder_devices", "is", "not", "None", "\n", "or", "cfg", ".", "pipeline_decoder_devices", "is", "not", "None", "\n", ")", "\n", "if", "not", "balance_exists", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"--pipeline-balance is currently required for pipeline model parallelism\"", "\n", ")", "\n", "", "if", "not", "devices_exist", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"--pipeline-devices is currently required for pipeline model parallelism\"", "\n", ")", "\n", "\n", "", "cfg", ".", "pipeline_balance", "=", "utils", ".", "eval_str_list", "(", "cfg", ".", "pipeline_balance", ",", "type", "=", "int", ")", "\n", "if", "cfg", ".", "pipeline_devices", "is", "not", "None", ":", "\n", "            ", "cfg", ".", "pipeline_devices", "=", "utils", ".", "eval_str_list", "(", "cfg", ".", "pipeline_devices", ",", "type", "=", "int", ")", "\n", "num_pipeline_devices", "=", "len", "(", "set", "(", "cfg", ".", "pipeline_devices", ")", ")", "\n", "", "else", ":", "\n", "            ", "cfg", ".", "pipeline_encoder_devices", "=", "utils", ".", "eval_str_list", "(", "\n", "cfg", ".", "pipeline_encoder_devices", ",", "type", "=", "int", "\n", ")", "\n", "cfg", ".", "pipeline_decoder_devices", "=", "utils", ".", "eval_str_list", "(", "\n", "cfg", ".", "pipeline_decoder_devices", ",", "type", "=", "int", "\n", ")", "\n", "num_pipeline_devices", "=", "len", "(", "\n", "set", "(", "cfg", ".", "pipeline_encoder_devices", "+", "cfg", ".", "pipeline_decoder_devices", ")", "\n", ")", "\n", "", "gpus_per_node", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "assert", "(", "\n", "gpus_per_node", ">=", "num_pipeline_devices", "\n", "and", "gpus_per_node", "%", "num_pipeline_devices", "==", "0", "\n", ")", ",", "(", "\n", "\"the number of unique device IDs in --pipeline-devices must evenly divide \"", "\n", "\"the number of GPUs per node (multi-node pipelining is not yet supported)\"", "\n", ")", "\n", "num_pipelines_per_node", "=", "gpus_per_node", "//", "num_pipeline_devices", "\n", "\n", "# support torch.distributed.launch", "\n", "", "if", "all", "(", "\n", "key", "in", "os", ".", "environ", "\n", "for", "key", "in", "[", "\"MASTER_ADDR\"", ",", "\"MASTER_PORT\"", ",", "\"WORLD_SIZE\"", ",", "\"RANK\"", "]", "\n", ")", ":", "\n", "        ", "cfg", ".", "distributed_init_method", "=", "\"env://\"", "\n", "cfg", ".", "distributed_world_size", "=", "int", "(", "os", ".", "environ", "[", "\"WORLD_SIZE\"", "]", ")", "\n", "cfg", ".", "distributed_rank", "=", "int", "(", "os", ".", "environ", "[", "\"RANK\"", "]", ")", "\n", "# processes are created by torch.distributed.launch", "\n", "cfg", ".", "distributed_no_spawn", "=", "True", "\n", "\n", "# we can determine the init method automatically for Slurm", "\n", "", "elif", "cfg", ".", "distributed_port", ">", "0", ":", "\n", "        ", "node_list", "=", "os", ".", "environ", ".", "get", "(", "\"SLURM_STEP_NODELIST\"", ")", "\n", "if", "node_list", "is", "None", ":", "\n", "            ", "node_list", "=", "os", ".", "environ", ".", "get", "(", "\"SLURM_JOB_NODELIST\"", ")", "\n", "", "if", "node_list", "is", "not", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "hostnames", "=", "subprocess", ".", "check_output", "(", "\n", "[", "\"scontrol\"", ",", "\"show\"", ",", "\"hostnames\"", ",", "node_list", "]", "\n", ")", "\n", "cfg", ".", "distributed_init_method", "=", "\"tcp://{host}:{port}\"", ".", "format", "(", "\n", "host", "=", "hostnames", ".", "split", "(", ")", "[", "0", "]", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "port", "=", "cfg", ".", "distributed_port", ",", "\n", ")", "\n", "nnodes", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "\"SLURM_NNODES\"", ")", ")", "\n", "ntasks_per_node", "=", "os", ".", "environ", ".", "get", "(", "\"SLURM_NTASKS_PER_NODE\"", ")", "\n", "if", "ntasks_per_node", "is", "not", "None", ":", "\n", "                    ", "ntasks_per_node", "=", "int", "(", "ntasks_per_node", ")", "\n", "", "else", ":", "\n", "                    ", "ntasks", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "\"SLURM_NTASKS\"", ")", ")", "\n", "nnodes", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "\"SLURM_NNODES\"", ")", ")", "\n", "assert", "ntasks", "%", "nnodes", "==", "0", "\n", "ntasks_per_node", "=", "int", "(", "ntasks", "/", "nnodes", ")", "\n", "", "if", "ntasks_per_node", "==", "1", ":", "\n", "                    ", "gpus_per_node", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "node_id", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "\"SLURM_NODEID\"", ")", ")", "\n", "cfg", ".", "distributed_rank", "=", "node_id", "*", "gpus_per_node", "\n", "cfg", ".", "distributed_world_size", "=", "nnodes", "*", "gpus_per_node", "\n", "", "elif", "cfg", ".", "pipeline_model_parallel", ":", "\n", "                    ", "assert", "ntasks_per_node", "==", "num_pipelines_per_node", ",", "(", "\n", "\"SLURM --ntasks-per-node must match number of pipelines per \"", "\n", "\"node (={})\"", ".", "format", "(", "num_pipelines_per_node", ")", "\n", ")", "\n", "cfg", ".", "distributed_no_spawn", "=", "True", "\n", "# For 4-way MP on nodes with 8 GPUs, ranks will be [0, 1] on", "\n", "# the first node, [1, 2] on the second node, etc. This", "\n", "# matches torch.distributed.launch.", "\n", "node_id", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "\"SLURM_NODEID\"", ")", ")", "\n", "local_id", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "\"SLURM_LOCALID\"", ")", ")", "\n", "cfg", ".", "distributed_rank", "=", "node_id", "*", "num_pipelines_per_node", "+", "local_id", "\n", "# In the above example, device_id will always be in [0, 1],", "\n", "# which also matches torch.distributed.launch.", "\n", "cfg", ".", "device_id", "=", "local_id", "\n", "# We also want to set distributed_world_size to be the total", "\n", "# number of pipelines across all nodes.", "\n", "cfg", ".", "distributed_world_size", "=", "nnodes", "*", "num_pipelines_per_node", "\n", "", "else", ":", "\n", "                    ", "assert", "ntasks_per_node", "==", "cfg", ".", "distributed_world_size", "//", "nnodes", "\n", "cfg", ".", "distributed_no_spawn", "=", "True", "\n", "cfg", ".", "distributed_rank", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "\"SLURM_PROCID\"", ")", ")", "\n", "cfg", ".", "device_id", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "\"SLURM_LOCALID\"", ")", ")", "\n", "", "", "except", "subprocess", ".", "CalledProcessError", "as", "e", ":", "# scontrol failed", "\n", "                ", "raise", "e", "\n", "", "except", "FileNotFoundError", ":", "# Slurm is not installed", "\n", "                ", "pass", "\n", "\n", "", "", "", "elif", "cfg", ".", "distributed_world_size", ">", "1", "or", "force_distributed", ":", "\n", "# fallback for single node with multiple GPUs", "\n", "        ", "assert", "cfg", ".", "distributed_world_size", "<=", "torch", ".", "cuda", ".", "device_count", "(", ")", ",", "f\"world size is {cfg.distributed_world_size} but have {torch.cuda.device_count()} available devices\"", "\n", "port", "=", "random", ".", "randint", "(", "10000", ",", "20000", ")", "\n", "cfg", ".", "distributed_init_method", "=", "\"tcp://localhost:{port}\"", ".", "format", "(", "port", "=", "port", ")", "\n", "\n", "", "if", "cfg", ".", "pipeline_model_parallel", ":", "\n", "        ", "if", "not", "cfg", ".", "distributed_no_spawn", ":", "\n", "# When distributed_no_spawn is False, we expect distributed_rank and", "\n", "# distributed_world_size to be based on the total number of GPUs, so", "\n", "# we need to correct them to be based on the number of pipelines.", "\n", "            ", "assert", "cfg", ".", "distributed_world_size", "%", "num_pipeline_devices", "==", "0", "\n", "cfg", ".", "distributed_world_size", "=", "(", "\n", "cfg", ".", "distributed_world_size", "//", "num_pipeline_devices", "\n", ")", "\n", "# In the case of 4-way MP on nodes with 8 GPUs, we want", "\n", "# distributed_rank to be the starting GPU index for each pipeline", "\n", "# i.e., 0, 2, ...", "\n", "assert", "cfg", ".", "distributed_rank", "%", "gpus_per_node", "==", "0", "\n", "assert", "cfg", ".", "distributed_rank", "%", "num_pipeline_devices", "==", "0", "\n", "\n", "with", "open_dict", "(", "cfg", ")", ":", "\n", "                ", "cfg", ".", "distributed_rank", "=", "cfg", ".", "distributed_rank", "//", "num_pipeline_devices", "\n", "# launch one process per pipeline", "\n", "cfg", ".", "distributed_num_procs", "=", "num_pipelines_per_node", "\n", "\n", "# if we have 4-way MP on a node with 8 GPUs, we want device_ids to be 0", "\n", "# and 4, indicating the starting device IDs for each pipeline", "\n", "", "", "cfg", ".", "device_id", "*=", "num_pipeline_devices", "\n", "\n", "if", "cfg", ".", "device_id", ">", "0", ":", "\n", "# if there's multiple pipelines on a node (e.g., 4-way MP on an 8", "\n", "# GPU node), we need to adjust pipeline_devices accordingly", "\n", "            ", "logger", ".", "debug", "(", "\n", "\"setting CUDA device={} on rank {}\"", ".", "format", "(", "\n", "cfg", ".", "device_id", ",", "cfg", ".", "distributed_rank", "\n", ")", "\n", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "cfg", ".", "device_id", ")", "\n", "with", "open_dict", "(", "cfg", ")", ":", "\n", "                ", "cfg", ".", "pipeline_devices", "=", "[", "cfg", ".", "device_id", "+", "d", "for", "d", "in", "cfg", ".", "pipeline_devices", "]", "\n", "", "logger", ".", "info", "(", "\n", "\"setting pipeline_devices={} on rank {}\"", ".", "format", "(", "\n", "cfg", ".", "pipeline_devices", ",", "cfg", ".", "distributed_rank", "\n", ")", "\n", ")", "\n", "", "", "elif", "not", "cfg", ".", "distributed_no_spawn", ":", "\n", "        ", "with", "open_dict", "(", "cfg", ")", ":", "\n", "            ", "cfg", ".", "distributed_num_procs", "=", "min", "(", "\n", "torch", ".", "cuda", ".", "device_count", "(", ")", ",", "cfg", ".", "distributed_world_size", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.distributed_init": [[215, 285], ["isinstance", "distributed_utils.is_master", "convert_namespace_to_omegaconf", "torch.distributed.get_rank", "torch.distributed.get_rank", "xm.get_local_ordinal", "xm.get_ordinal", "xm.rendezvous", "xm.mark_step", "logging.getLogger().setLevel", "logging.getLogger().setLevel", "initialize_model_parallel", "model_parallel_cuda_manual_seed", "distributed_utils.get_model_parallel_rank", "torch.distributed.is_available", "torch.distributed.is_available", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "warnings.warn", "logger.info", "torch.init_process_group", "logger.info", "torch.cuda.is_available", "torch.cuda.is_available", "xm.xrt_world_size", "torch.all_reduce", "logging.getLogger", "logging.getLogger", "ImportError", "socket.gethostname", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.is_master", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_model_parallel_rank", "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.cuda", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.cuda"], ["", "", "", "def", "distributed_init", "(", "cfg", ":", "FairseqConfig", ")", ":", "\n", "    ", "if", "isinstance", "(", "cfg", ",", "Namespace", ")", ":", "\n", "        ", "from", "fairseq", ".", "dataclass", ".", "utils", "import", "convert_namespace_to_omegaconf", "\n", "\n", "cfg", "=", "convert_namespace_to_omegaconf", "(", "cfg", ")", "\n", "\n", "", "if", "not", "cfg", ".", "common", ".", "tpu", ":", "\n", "        ", "if", "torch", ".", "distributed", ".", "is_available", "(", ")", "and", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"Distributed is already initialized, cannot initialize twice!\"", "\n", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"distributed init (rank {}): {}\"", ".", "format", "(", "\n", "cfg", ".", "distributed_training", ".", "distributed_rank", ",", "\n", "cfg", ".", "distributed_training", ".", "distributed_init_method", ",", "\n", ")", "\n", ")", "\n", "dist", ".", "init_process_group", "(", "\n", "backend", "=", "cfg", ".", "distributed_training", ".", "distributed_backend", ",", "\n", "init_method", "=", "cfg", ".", "distributed_training", ".", "distributed_init_method", ",", "\n", "world_size", "=", "cfg", ".", "distributed_training", ".", "distributed_world_size", ",", "\n", "rank", "=", "cfg", ".", "distributed_training", ".", "distributed_rank", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"initialized host {} as rank {}\"", ".", "format", "(", "\n", "socket", ".", "gethostname", "(", ")", ",", "\n", "cfg", ".", "distributed_training", ".", "distributed_rank", ",", "\n", ")", "\n", ")", "\n", "\n", "# perform a dummy all-reduce to initialize the NCCL communicator", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "dist", ".", "all_reduce", "(", "torch", ".", "zeros", "(", "1", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "", "", "cfg", ".", "distributed_training", ".", "distributed_rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "", "else", ":", "\n", "        ", "assert", "xm", ".", "xrt_world_size", "(", ")", "==", "cfg", ".", "distributed_training", ".", "distributed_world_size", "\n", "global", "_USE_XLA", "\n", "_USE_XLA", "=", "True", "\n", "cfg", ".", "distributed_training", ".", "device_id", "=", "xm", ".", "get_local_ordinal", "(", ")", "\n", "cfg", ".", "distributed_training", ".", "distributed_rank", "=", "xm", ".", "get_ordinal", "(", ")", "\n", "xm", ".", "rendezvous", "(", "\"distributed_init\"", ")", "# wait for all workers", "\n", "xm", ".", "mark_step", "(", ")", "\n", "\n", "", "if", "is_master", "(", "cfg", ".", "distributed_training", ")", ":", "\n", "        ", "logging", ".", "getLogger", "(", ")", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "getLogger", "(", ")", ".", "setLevel", "(", "logging", ".", "WARNING", ")", "\n", "\n", "", "if", "cfg", ".", "common", ".", "model_parallel_size", ">", "1", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "fairseq", ".", "model_parallel", ".", "megatron", ".", "mpu", "import", "(", "\n", "initialize_model_parallel", ",", "\n", "model_parallel_cuda_manual_seed", ",", "\n", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"\\n\\nPlease install the megatron submodule:\"", "\n", "\"\\n\\n  git submodule update --init \"", "\n", "\"fairseq/model_parallel/megatron\"", "\n", ")", "\n", "", "global", "_USE_MEGATRON", "\n", "_USE_MEGATRON", "=", "True", "\n", "initialize_model_parallel", "(", "cfg", ".", "common", ".", "model_parallel_size", ")", "\n", "model_parallel_cuda_manual_seed", "(", "cfg", ".", "common", ".", "seed", ")", "\n", "model_part_number", "=", "get_model_parallel_rank", "(", ")", "\n", "cfg", ".", "checkpoint", ".", "checkpoint_suffix", "+=", "\"-model_part-{0}\"", ".", "format", "(", "model_part_number", ")", "\n", "\n", "", "return", "cfg", ".", "distributed_training", ".", "distributed_rank", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.distributed_main": [[287, 301], ["distributed_utils.distributed_init", "kwargs.pop", "main", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.set_device", "torch.cuda.set_device", "kwargs.pop.", "kwargs.pop"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.distributed_init", "home.repos.pwc.inspect_result.reneeye_const.scripts.average_checkpoints.main"], ["", "def", "distributed_main", "(", "i", ",", "main", ",", "cfg", ":", "FairseqConfig", ",", "kwargs", ")", ":", "\n", "    ", "cfg", ".", "distributed_training", ".", "device_id", "=", "i", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "cfg", ".", "common", ".", "cpu", "and", "not", "cfg", ".", "common", ".", "tpu", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "cfg", ".", "distributed_training", ".", "device_id", ")", "\n", "", "if", "cfg", ".", "distributed_training", ".", "distributed_rank", "is", "None", ":", "# torch.multiprocessing.spawn", "\n", "        ", "cfg", ".", "distributed_training", ".", "distributed_rank", "=", "kwargs", ".", "pop", "(", "\"start_rank\"", ",", "0", ")", "+", "i", "\n", "\n", "", "cfg", ".", "distributed_training", ".", "distributed_rank", "=", "distributed_init", "(", "cfg", ")", "\n", "\n", "after_distributed_init_fn", "=", "kwargs", ".", "pop", "(", "\"after_distributed_init_fn\"", ",", "None", ")", "\n", "if", "after_distributed_init_fn", ":", "\n", "        ", "cfg", "=", "after_distributed_init_fn", "(", "cfg", ")", "\n", "\n", "", "main", "(", "cfg", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.call_main": [[303, 335], ["distributed_utils.infer_init_method", "torch.multiprocessing.spawn", "torch.multiprocessing.spawn", "distributed_utils.distributed_main", "torch.multiprocessing.set_sharing_strategy", "torch.multiprocessing.set_sharing_strategy", "xmp.spawn", "main", "min", "torch.cuda.device_count", "torch.cuda.device_count"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.infer_init_method", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.distributed_main", "home.repos.pwc.inspect_result.reneeye_const.scripts.average_checkpoints.main"], ["", "def", "call_main", "(", "cfg", ":", "FairseqConfig", ",", "main", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "cfg", ".", "distributed_training", ".", "distributed_init_method", "is", "None", ":", "\n", "        ", "infer_init_method", "(", "cfg", ".", "distributed_training", ")", "\n", "\n", "", "if", "cfg", ".", "distributed_training", ".", "distributed_init_method", "is", "not", "None", ":", "\n", "# distributed training", "\n", "        ", "if", "not", "cfg", ".", "distributed_training", ".", "distributed_no_spawn", ":", "\n", "            ", "start_rank", "=", "cfg", ".", "distributed_training", ".", "distributed_rank", "\n", "cfg", ".", "distributed_training", ".", "distributed_rank", "=", "None", "# assign automatically", "\n", "kwargs", "[", "\"start_rank\"", "]", "=", "start_rank", "\n", "torch", ".", "multiprocessing", ".", "spawn", "(", "\n", "fn", "=", "distributed_main", ",", "\n", "args", "=", "(", "main", ",", "cfg", ",", "kwargs", ")", ",", "\n", "nprocs", "=", "min", "(", "\n", "torch", ".", "cuda", ".", "device_count", "(", ")", ",", "\n", "cfg", ".", "distributed_training", ".", "distributed_world_size", ",", "\n", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "distributed_main", "(", "cfg", ".", "distributed_training", ".", "device_id", ",", "main", ",", "cfg", ",", "kwargs", ")", "\n", "", "", "elif", "cfg", ".", "common", ".", "tpu", "and", "cfg", ".", "distributed_training", ".", "distributed_world_size", ">", "1", ":", "\n", "        ", "import", "torch_xla", ".", "distributed", ".", "xla_multiprocessing", "as", "xmp", "\n", "\n", "torch", ".", "multiprocessing", ".", "set_sharing_strategy", "(", "\"file_system\"", ")", "\n", "xmp", ".", "spawn", "(", "\n", "fn", "=", "distributed_main", ",", "\n", "args", "=", "(", "main", ",", "cfg", ",", "kwargs", ")", ",", "\n", "nprocs", "=", "8", ",", "# use all 8 TPU cores", "\n", ")", "\n", "", "else", ":", "\n", "# single GPU main", "\n", "        ", "main", "(", "cfg", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.use_xla": [[337, 340], ["None"], "function", ["None"], ["", "", "def", "use_xla", "(", ")", ":", "\n", "    ", "global", "_USE_XLA", "\n", "return", "_USE_XLA", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.new_groups": [[342, 349], ["distributed_utils.use_xla", "distributed_utils._find_my_group_index", "torch.new_group"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.use_xla", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils._find_my_group_index"], ["", "def", "new_groups", "(", "grouped_ranks", ":", "List", "[", "List", "[", "int", "]", "]", ")", ":", "\n", "    ", "if", "use_xla", "(", ")", ":", "\n", "        ", "return", "(", "\"tpu\"", ",", "grouped_ranks", ")", "\n", "", "else", ":", "\n", "        ", "groups", "=", "[", "dist", ".", "new_group", "(", "g", ")", "for", "g", "in", "grouped_ranks", "]", "\n", "my_group_idx", "=", "_find_my_group_index", "(", "grouped_ranks", ")", "\n", "return", "groups", "[", "my_group_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils._find_my_group_index": [[351, 357], ["distributed_utils.get_global_rank", "enumerate"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_global_rank"], ["", "", "def", "_find_my_group_index", "(", "grouped_ranks", ")", ":", "\n", "    ", "my_rank", "=", "get_global_rank", "(", ")", "\n", "for", "i", ",", "group", "in", "enumerate", "(", "grouped_ranks", ")", ":", "\n", "        ", "if", "my_rank", "in", "group", ":", "\n", "            ", "return", "i", "\n", "", "", "raise", "RuntimeError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils._find_my_group": [[359, 362], ["distributed_utils._find_my_group_index"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils._find_my_group_index"], ["", "def", "_find_my_group", "(", "grouped_ranks", ")", ":", "\n", "    ", "index", "=", "_find_my_group_index", "(", "grouped_ranks", ")", "\n", "return", "grouped_ranks", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_rank": [[364, 371], ["distributed_utils.use_xla", "distributed_utils._find_my_group", "_find_my_group.index", "torch.get_rank", "distributed_utils.get_global_rank"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.use_xla", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils._find_my_group", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.index", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_global_rank"], ["", "def", "get_rank", "(", "group", ")", ":", "\n", "    ", "if", "use_xla", "(", ")", ":", "\n", "        ", "assert", "group", "[", "0", "]", "==", "\"tpu\"", "\n", "my_group", "=", "_find_my_group", "(", "group", "[", "1", "]", ")", "\n", "return", "my_group", ".", "index", "(", "get_global_rank", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "dist", ".", "get_rank", "(", "group", "=", "group", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_world_size": [[373, 380], ["distributed_utils.use_xla", "distributed_utils._find_my_group", "len", "torch.get_world_size"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.use_xla", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils._find_my_group", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_world_size"], ["", "", "def", "get_world_size", "(", "group", ")", ":", "\n", "    ", "if", "use_xla", "(", ")", ":", "\n", "        ", "assert", "group", "[", "0", "]", "==", "\"tpu\"", "\n", "my_group", "=", "_find_my_group", "(", "group", "[", "1", "]", ")", "\n", "return", "len", "(", "my_group", ")", "\n", "", "else", ":", "\n", "        ", "return", "dist", ".", "get_world_size", "(", "group", "=", "group", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_global_group": [[382, 393], ["distributed_utils.use_xla", "distributed_utils.new_groups", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "list", "hasattr", "torch.new_group", "range", "distributed_utils.get_global_world_size"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.use_xla", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.new_groups", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_global_world_size"], ["", "", "def", "get_global_group", "(", ")", ":", "\n", "    ", "if", "use_xla", "(", ")", ":", "\n", "        ", "return", "new_groups", "(", "[", "list", "(", "range", "(", "get_global_world_size", "(", ")", ")", ")", "]", ")", "\n", "", "elif", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "get_global_group", ",", "\"_global_group\"", ")", ":", "\n", "# ideally we could use torch.distributed.group.WORLD, but it seems", "\n", "# to cause random NCCL hangs in some cases", "\n", "            ", "get_global_group", ".", "_global_group", "=", "dist", ".", "new_group", "(", ")", "\n", "", "return", "get_global_group", ".", "_global_group", "\n", "", "else", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_global_rank": [[395, 402], ["distributed_utils.use_xla", "xm.get_ordinal", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.get_rank", "torch.distributed.get_rank"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.use_xla", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_rank"], ["", "", "def", "get_global_rank", "(", ")", ":", "\n", "    ", "if", "use_xla", "(", ")", ":", "\n", "        ", "return", "xm", ".", "get_ordinal", "(", ")", "\n", "", "elif", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_global_world_size": [[404, 411], ["distributed_utils.use_xla", "xm.xrt_world_size", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.get_world_size", "torch.distributed.get_world_size"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.use_xla", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_world_size"], ["", "", "def", "get_global_world_size", "(", ")", ":", "\n", "    ", "if", "use_xla", "(", ")", ":", "\n", "        ", "return", "xm", ".", "xrt_world_size", "(", ")", "\n", "", "elif", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_data_parallel_group": [[413, 421], ["mpu.get_data_parallel_group", "distributed_utils.get_global_group"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_data_parallel_group", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_global_group"], ["", "", "def", "get_data_parallel_group", "(", ")", ":", "\n", "    ", "\"\"\"Get the data parallel group the caller rank belongs to.\"\"\"", "\n", "global", "_USE_MEGATRON", "\n", "if", "_USE_MEGATRON", ":", "\n", "        ", "from", "fairseq", ".", "model_parallel", ".", "megatron", "import", "mpu", "\n", "return", "mpu", ".", "get_data_parallel_group", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "get_global_group", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_data_parallel_rank": [[423, 426], ["distributed_utils.get_rank", "distributed_utils.get_data_parallel_group"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_data_parallel_group"], ["", "", "def", "get_data_parallel_rank", "(", ")", ":", "\n", "    ", "\"\"\"Return my rank for the data parallel group.\"\"\"", "\n", "return", "get_rank", "(", "get_data_parallel_group", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_data_parallel_world_size": [[428, 431], ["distributed_utils.get_world_size", "distributed_utils.get_data_parallel_group"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_data_parallel_group"], ["", "def", "get_data_parallel_world_size", "(", ")", ":", "\n", "    ", "\"\"\"Return world size for the data parallel group.\"\"\"", "\n", "return", "get_world_size", "(", "get_data_parallel_group", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_model_parallel_group": [[433, 440], ["mpu.get_model_parallel_group"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_model_parallel_group"], ["", "def", "get_model_parallel_group", "(", ")", ":", "\n", "    ", "global", "_USE_MEGATRON", "\n", "if", "_USE_MEGATRON", ":", "\n", "        ", "from", "fairseq", ".", "model_parallel", ".", "megatron", "import", "mpu", "\n", "return", "mpu", ".", "get_model_parallel_group", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_model_parallel_rank": [[442, 445], ["distributed_utils.get_rank", "distributed_utils.get_model_parallel_group"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_model_parallel_group"], ["", "", "def", "get_model_parallel_rank", "(", ")", ":", "\n", "    ", "\"\"\"Return my rank for the model parallel group.\"\"\"", "\n", "return", "get_rank", "(", "get_model_parallel_group", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_model_parallel_world_size": [[447, 450], ["distributed_utils.get_world_size", "distributed_utils.get_model_parallel_group"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_model_parallel_group"], ["", "def", "get_model_parallel_world_size", "(", ")", ":", "\n", "    ", "\"\"\"Return world size for the model parallel group.\"\"\"", "\n", "return", "get_world_size", "(", "get_model_parallel_group", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.all_reduce": [[452, 466], ["distributed_utils.use_xla", "torch.all_reduce", "isinstance", "xm.all_reduce"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.use_xla", "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce", "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce"], ["", "def", "all_reduce", "(", "tensor", ",", "group", ",", "op", "=", "\"sum\"", ")", ":", "\n", "    ", "if", "use_xla", "(", ")", ":", "\n", "        ", "assert", "isinstance", "(", "group", ",", "tuple", ")", "and", "group", "[", "0", "]", "==", "\"tpu\"", "\n", "tensor", "=", "[", "tensor", "]", "# wrap in a list to make xm.all_reduce in-place", "\n", "return", "xm", ".", "all_reduce", "(", "op", ",", "tensor", ",", "groups", "=", "group", "[", "1", "]", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "if", "op", "==", "\"sum\"", ":", "\n", "            ", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", "\n", "", "elif", "op", "==", "\"max\"", ":", "\n", "            ", "op", "=", "dist", ".", "ReduceOp", ".", "MAX", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "dist", ".", "all_reduce", "(", "tensor", ",", "op", "=", "op", ",", "group", "=", "group", ")", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.broadcast": [[468, 476], ["distributed_utils.use_xla", "distributed_utils.all_reduce", "torch.broadcast", "distributed_utils.get_rank", "tensor.zero_"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.use_xla", "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.broadcast", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_rank"], ["", "", "def", "broadcast", "(", "tensor", ",", "src", ",", "group", ")", ":", "\n", "    ", "if", "use_xla", "(", ")", ":", "\n", "# XLA doesn't support broadcast, hack it with all_reduce", "\n", "        ", "if", "get_rank", "(", "group", ")", "!=", "src", ":", "\n", "            ", "tensor", ".", "zero_", "(", ")", "\n", "", "all_reduce", "(", "tensor", ",", "group", ")", "\n", "", "else", ":", "\n", "        ", "dist", ".", "broadcast", "(", "tensor", ",", "src", "=", "src", ",", "group", "=", "group", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.all_to_all": [[478, 496], ["distributed_utils.get_world_size", "distributed_utils.use_xla", "tensor.dim", "xm.all_to_all", "torch.zeros_like", "torch.zeros_like", "torch.all_to_all_single", "tensor.numel", "isinstance"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.use_xla", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.all_to_all"], ["", "", "def", "all_to_all", "(", "tensor", ",", "group", ")", ":", "\n", "    ", "\"\"\"Perform an all-to-all operation on a 1D Tensor.\"\"\"", "\n", "assert", "tensor", ".", "dim", "(", ")", "==", "1", "\n", "split_count", "=", "get_world_size", "(", "group", "=", "group", ")", "\n", "assert", "tensor", ".", "numel", "(", ")", "%", "split_count", "==", "0", "\n", "if", "use_xla", "(", ")", ":", "\n", "        ", "assert", "isinstance", "(", "group", ",", "tuple", ")", "and", "group", "[", "0", "]", "==", "\"tpu\"", "\n", "return", "xm", ".", "all_to_all", "(", "\n", "tensor", ",", "\n", "split_dimension", "=", "0", ",", "\n", "concat_dimension", "=", "0", ",", "\n", "split_count", "=", "split_count", ",", "\n", "groups", "=", "group", "[", "1", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "output", "=", "torch", ".", "zeros_like", "(", "tensor", ")", "\n", "dist", ".", "all_to_all_single", "(", "output", ",", "tensor", ",", "group", "=", "group", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.all_gather": [[498, 519], ["distributed_utils.use_xla", "xm.all_gather", "distributed_utils.get_world_size", "result.view.view", "distributed_utils.get_world_size", "distributed_utils.get_rank", "torch.all_gather", "torch.stack", "torch.stack", "tensor.size", "torch.empty_like", "torch.empty_like", "range", "range"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.use_xla", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.all_gather", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.all_gather", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "", "def", "all_gather", "(", "tensor", ",", "group", ",", "return_tensor", "=", "False", ")", ":", "\n", "    ", "\"\"\"Perform an all-gather operation.\"\"\"", "\n", "if", "use_xla", "(", ")", ":", "\n", "        ", "result", "=", "xm", ".", "all_gather", "(", "tensor", ",", "groups", "=", "group", "[", "1", "]", ")", "\n", "world_size", "=", "get_world_size", "(", "group", "=", "group", ")", "\n", "result", "=", "result", ".", "view", "(", "world_size", ",", "*", "tensor", ".", "size", "(", ")", ")", "\n", "if", "return_tensor", ":", "\n", "            ", "return", "result", "\n", "", "else", ":", "\n", "            ", "return", "[", "result", "[", "i", "]", "for", "i", "in", "range", "(", "world_size", ")", "]", "\n", "", "", "else", ":", "\n", "        ", "world_size", "=", "get_world_size", "(", "group", "=", "group", ")", "\n", "rank", "=", "get_rank", "(", "group", "=", "group", ")", "\n", "tensor_list", "=", "[", "\n", "tensor", "if", "i", "==", "rank", "else", "torch", ".", "empty_like", "(", "tensor", ")", "for", "i", "in", "range", "(", "world_size", ")", "\n", "]", "\n", "dist", ".", "all_gather", "(", "tensor_list", ",", "tensor", ",", "group", "=", "group", ")", "\n", "if", "return_tensor", ":", "\n", "            ", "return", "torch", ".", "stack", "(", "tensor_list", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "return", "tensor_list", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.all_gather_list": [[521, 582], ["distributed_utils.get_rank", "distributed_utils.get_world_size", "buffer.cpu.zero_", "fairseq.utils.move_to_cpu", "pickle.dumps", "len", "struct.pack", "torch.ByteTensor", "torch.ByteTensor", "buffer[].copy_", "distributed_utils.all_reduce", "buffer.cpu.cpu", "distributed_utils.get_global_group", "torch.cuda.ByteTensor", "torch.cuda.ByteTensor", "torch.ByteTensor().pin_memory", "torch.ByteTensor().pin_memory", "ValueError", "list", "range", "hasattr", "all_gather_list._buffer.numel", "struct.unpack", "Exception", "torch.ByteTensor", "torch.ByteTensor", "bytes", "result.append", "out_buffer[].tolist", "pickle.loads", "bytes", "out_buffer[].tolist"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.move_to_cpu", "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_global_group"], ["", "", "", "def", "all_gather_list", "(", "data", ",", "group", "=", "None", ",", "max_size", "=", "16384", ")", ":", "\n", "    ", "\"\"\"Gathers arbitrary data from all nodes into a list.\n\n    Similar to :func:`~torch.distributed.all_gather` but for arbitrary Python\n    data. Note that *data* must be picklable.\n\n    Args:\n        data (Any): data from the local worker to be gathered on other workers\n        group: group of the collective\n        max_size (int, optional): maximum size of the data to be gathered\n            across workers\n    \"\"\"", "\n", "if", "group", "is", "None", ":", "\n", "        ", "group", "=", "get_global_group", "(", ")", "\n", "", "rank", "=", "get_rank", "(", "group", "=", "group", ")", "\n", "world_size", "=", "get_world_size", "(", "group", "=", "group", ")", "\n", "\n", "buffer_size", "=", "max_size", "*", "world_size", "\n", "if", "(", "\n", "not", "hasattr", "(", "all_gather_list", ",", "\"_buffer\"", ")", "\n", "or", "all_gather_list", ".", "_buffer", ".", "numel", "(", ")", "<", "buffer_size", "\n", ")", ":", "\n", "        ", "all_gather_list", ".", "_buffer", "=", "torch", ".", "cuda", ".", "ByteTensor", "(", "buffer_size", ")", "\n", "all_gather_list", ".", "_cpu_buffer", "=", "torch", ".", "ByteTensor", "(", "max_size", ")", ".", "pin_memory", "(", ")", "\n", "", "buffer", "=", "all_gather_list", ".", "_buffer", "\n", "buffer", ".", "zero_", "(", ")", "\n", "cpu_buffer", "=", "all_gather_list", ".", "_cpu_buffer", "\n", "\n", "data", "=", "utils", ".", "move_to_cpu", "(", "data", ")", "\n", "enc", "=", "pickle", ".", "dumps", "(", "data", ")", "\n", "enc_size", "=", "len", "(", "enc", ")", "\n", "header_size", "=", "4", "# size of header that contains the length of the encoded data", "\n", "size", "=", "header_size", "+", "enc_size", "\n", "if", "size", ">", "max_size", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"encoded data size ({}) exceeds max_size ({})\"", ".", "format", "(", "size", ",", "max_size", ")", "\n", ")", "\n", "\n", "", "header", "=", "struct", ".", "pack", "(", "\">I\"", ",", "enc_size", ")", "\n", "cpu_buffer", "[", ":", "size", "]", "=", "torch", ".", "ByteTensor", "(", "list", "(", "header", "+", "enc", ")", ")", "\n", "start", "=", "rank", "*", "max_size", "\n", "buffer", "[", "start", ":", "start", "+", "size", "]", ".", "copy_", "(", "cpu_buffer", "[", ":", "size", "]", ")", "\n", "\n", "all_reduce", "(", "buffer", ",", "group", "=", "group", ")", "\n", "\n", "buffer", "=", "buffer", ".", "cpu", "(", ")", "\n", "try", ":", "\n", "        ", "result", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "world_size", ")", ":", "\n", "            ", "out_buffer", "=", "buffer", "[", "i", "*", "max_size", ":", "(", "i", "+", "1", ")", "*", "max_size", "]", "\n", "(", "enc_size", ",", ")", "=", "struct", ".", "unpack", "(", "\">I\"", ",", "bytes", "(", "out_buffer", "[", ":", "header_size", "]", ".", "tolist", "(", ")", ")", ")", "\n", "if", "enc_size", ">", "0", ":", "\n", "                ", "result", ".", "append", "(", "\n", "pickle", ".", "loads", "(", "\n", "bytes", "(", "out_buffer", "[", "header_size", ":", "header_size", "+", "enc_size", "]", ".", "tolist", "(", ")", ")", "\n", ")", "\n", ")", "\n", "", "", "return", "result", "\n", "", "except", "pickle", ".", "UnpicklingError", ":", "\n", "        ", "raise", "Exception", "(", "\n", "\"Unable to unpickle data from other workers. all_gather_list requires all \"", "\n", "\"workers to enter the function together, so this error usually indicates \"", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.all_reduce_dict": [[591, 638], ["list", "collections.OrderedDict", "collections.OrderedDict", "distributed_utils.all_reduce_dict._all_reduce_dict"], "function", ["None"], ["", "", "def", "all_reduce_dict", "(", "data", ":", "Mapping", "[", "str", ",", "Any", "]", ",", "device", ",", "group", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "    ", "\"\"\"\n    AllReduce a dictionary of values across workers. We separately\n    reduce items that are already on the device and items on CPU for\n    better performance.\n\n    Args:\n        data (Mapping[str, Any]): dictionary of data to all-reduce, but\n            cannot be a nested dictionary\n        device (torch.device): device for the reduction\n        group: group of the collective\n    \"\"\"", "\n", "data_keys", "=", "list", "(", "data", ".", "keys", "(", ")", ")", "\n", "\n", "# We want to separately reduce items that are already on the", "\n", "# device and items on CPU for performance reasons.", "\n", "cpu_data", "=", "OrderedDict", "(", ")", "\n", "device_data", "=", "OrderedDict", "(", ")", "\n", "for", "k", "in", "data_keys", ":", "\n", "        ", "t", "=", "data", "[", "k", "]", "\n", "if", "not", "torch", ".", "is_tensor", "(", "t", ")", ":", "\n", "            ", "cpu_data", "[", "k", "]", "=", "torch", ".", "tensor", "(", "t", ",", "dtype", "=", "torch", ".", "double", ")", "\n", "", "elif", "t", ".", "device", ".", "type", "!=", "device", ".", "type", ":", "\n", "            ", "cpu_data", "[", "k", "]", "=", "t", ".", "to", "(", "dtype", "=", "torch", ".", "double", ")", "\n", "", "else", ":", "\n", "            ", "device_data", "[", "k", "]", "=", "t", ".", "to", "(", "dtype", "=", "torch", ".", "double", ")", "\n", "\n", "", "", "def", "_all_reduce_dict", "(", "data", ":", "OrderedDict", ")", ":", "\n", "        ", "if", "len", "(", "data", ")", "==", "0", ":", "\n", "            ", "return", "data", "\n", "", "buf", "=", "torch", ".", "cat", "(", "[", "t", ".", "view", "(", "-", "1", ")", "for", "t", "in", "data", ".", "values", "(", ")", "]", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "all_reduce", "(", "buf", ",", "group", "=", "group", ")", "\n", "split_buf", "=", "torch", ".", "split", "(", "buf", ",", "[", "t", ".", "numel", "(", ")", "for", "t", "in", "data", ".", "values", "(", ")", "]", ")", "\n", "reduced_data", "=", "[", "t", ".", "view_as", "(", "orig", ")", "for", "t", ",", "orig", "in", "zip", "(", "split_buf", ",", "data", ".", "values", "(", ")", ")", "]", "\n", "return", "OrderedDict", "(", "zip", "(", "data", ".", "keys", "(", ")", ",", "reduced_data", ")", ")", "\n", "\n", "", "cpu_data", "=", "_all_reduce_dict", "(", "cpu_data", ")", "\n", "device_data", "=", "_all_reduce_dict", "(", "device_data", ")", "\n", "\n", "def", "get_from_stack", "(", "key", ")", ":", "\n", "        ", "if", "key", "in", "cpu_data", ":", "\n", "            ", "return", "cpu_data", "[", "key", "]", "\n", "", "elif", "key", "in", "device_data", ":", "\n", "            ", "return", "device_data", "[", "key", "]", "\n", "", "raise", "KeyError", "\n", "\n", "", "return", "OrderedDict", "(", "[", "(", "key", ",", "get_from_stack", "(", "key", ")", ")", "for", "key", "in", "data_keys", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.broadcast_object": [[641, 681], ["distributed_utils.get_rank", "io.BytesIO", "torch.save", "torch.save", "bytearray", "torch.tensor", "torch.tensor", "distributed_utils.broadcast", "torch.tensor", "torch.tensor", "distributed_utils.broadcast", "torch.tensor", "torch.tensor", "distributed_utils.broadcast", "torch.zeros", "torch.zeros", "distributed_utils.broadcast", "io.BytesIO", "torch.load", "torch.load", "torch.distributed.get_backend", "torch.distributed.get_backend", "torch.device", "torch.device", "torch.device", "torch.device", "io.BytesIO.getbuffer", "torch.zeros.cpu().numpy", "len", "int", "torch.tensor.item", "torch.zeros.cpu"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_rank", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.save", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.save", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.broadcast", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.broadcast", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.broadcast", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.broadcast", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.device", "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.device", "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.device", "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.device", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "def", "broadcast_object", "(", "\n", "obj", ":", "Any", ",", "\n", "src_rank", ":", "int", ",", "\n", "group", ":", "object", ",", "\n", "dist_device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ",", "\n", "dist_length_dtype", ":", "Optional", "[", "torch", ".", "dtype", "]", "=", "torch", ".", "long", ",", "\n", "dist_dtype", ":", "Optional", "[", "torch", ".", "dtype", "]", "=", "torch", ".", "uint8", ",", "\n", ")", "->", "Any", ":", "\n", "    ", "\"\"\"\n    Either broadcast from master to the fleet (default),\n    or use the src setting as the original rank.\n    \"\"\"", "\n", "if", "dist_device", "is", "None", ":", "\n", "        ", "if", "torch", ".", "distributed", ".", "get_backend", "(", "group", ")", "==", "\"nccl\"", ":", "\n", "            ", "dist_device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "", "else", ":", "\n", "            ", "dist_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "", "", "if", "get_rank", "(", "group", ")", "==", "src_rank", ":", "\n", "# Emit data", "\n", "        ", "buffer", "=", "io", ".", "BytesIO", "(", ")", "\n", "torch", ".", "save", "(", "obj", ",", "buffer", ")", "\n", "data", "=", "bytearray", "(", "buffer", ".", "getbuffer", "(", ")", ")", "\n", "length_tensor", "=", "torch", ".", "tensor", "(", "\n", "[", "len", "(", "data", ")", "]", ",", "dtype", "=", "dist_length_dtype", ",", "device", "=", "dist_device", "\n", ")", "\n", "broadcast", "(", "length_tensor", ",", "src", "=", "src_rank", ",", "group", "=", "group", ")", "\n", "data_send_tensor", "=", "torch", ".", "tensor", "(", "data", ",", "dtype", "=", "dist_dtype", ",", "device", "=", "dist_device", ")", "\n", "broadcast", "(", "data_send_tensor", ",", "src", "=", "src_rank", ",", "group", "=", "group", ")", "\n", "", "else", ":", "\n", "# Fetch from the source", "\n", "        ", "length_tensor", "=", "torch", ".", "tensor", "(", "[", "0", "]", ",", "dtype", "=", "dist_length_dtype", ",", "device", "=", "dist_device", ")", "\n", "broadcast", "(", "length_tensor", ",", "src", "=", "src_rank", ",", "group", "=", "group", ")", "\n", "data_recv_tensor", "=", "torch", ".", "zeros", "(", "\n", "[", "int", "(", "length_tensor", ".", "item", "(", ")", ")", "]", ",", "dtype", "=", "dist_dtype", ",", "device", "=", "dist_device", "\n", ")", "\n", "broadcast", "(", "data_recv_tensor", ",", "src", "=", "src_rank", ",", "group", "=", "group", ")", "\n", "buffer", "=", "io", ".", "BytesIO", "(", "data_recv_tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "obj", "=", "torch", ".", "load", "(", "buffer", ",", "map_location", "=", "\"cpu\"", ")", "\n", "", "return", "obj", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.__init__": [[43, 67], ["torch.nn.Module.__init__", "distributed_utils.get_world_size", "min", "collections.OrderedDict", "legacy_distributed_data_parallel.LegacyDistributedDataParallel.module.parameters", "list", "sum", "collections.OrderedDict.values", "collections.OrderedDict.get", "p.numel", "module.parameters"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_world_size"], ["def", "__init__", "(", "self", ",", "module", ",", "process_group", ",", "buffer_size", "=", "2", "**", "28", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "module", "=", "module", "\n", "self", ".", "process_group", "=", "process_group", "\n", "self", ".", "world_size", "=", "distributed_utils", ".", "get_world_size", "(", "self", ".", "process_group", ")", "\n", "\n", "# Never use a bigger buffer than the number of model params", "\n", "self", ".", "buffer_size", "=", "min", "(", "buffer_size", ",", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "module", ".", "parameters", "(", ")", ")", ")", "\n", "self", ".", "buffer", "=", "None", "\n", "\n", "# We can also forcibly accumulate grads locally and only do the", "\n", "# all-reduce at some later time", "\n", "self", ".", "accumulate_grads", "=", "False", "\n", "self", ".", "old_accumulate_grads", "=", "None", "\n", "\n", "# make per-device lists of parameters", "\n", "paramlists", "=", "OrderedDict", "(", ")", "\n", "for", "param", "in", "self", ".", "module", ".", "parameters", "(", ")", ":", "\n", "            ", "device", "=", "param", ".", "device", "\n", "if", "paramlists", ".", "get", "(", "device", ")", "is", "None", ":", "\n", "                ", "paramlists", "[", "device", "]", "=", "[", "]", "\n", "", "paramlists", "[", "device", "]", "+=", "[", "param", "]", "\n", "", "self", ".", "per_device_params", "=", "list", "(", "paramlists", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.__getstate__": [[68, 71], ["copy.copy"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.copy"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "attrs", "=", "copy", ".", "copy", "(", "self", ".", "__dict__", ")", "\n", "return", "attrs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.__setstate__": [[72, 74], ["super().__setstate__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.plasma_utils.PlasmaArray.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", ")", ".", "__setstate__", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.no_sync": [[75, 83], ["None"], "methods", ["None"], ["", "@", "contextmanager", "\n", "def", "no_sync", "(", "self", ")", ":", "\n", "        ", "\"\"\"A context manager to disable gradient synchronization.\"\"\"", "\n", "self", ".", "old_accumulate_grads", "=", "self", ".", "accumulate_grads", "\n", "self", ".", "accumulate_grads", "=", "True", "\n", "yield", "\n", "self", ".", "accumulate_grads", "=", "self", ".", "old_accumulate_grads", "\n", "self", ".", "old_accumulate_grads", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.no_sync_recover": [[84, 88], ["None"], "methods", ["None"], ["", "def", "no_sync_recover", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "old_accumulate_grads", "is", "not", "None", ":", "\n", "            ", "self", ".", "accumulate_grads", "=", "self", ".", "old_accumulate_grads", "\n", "self", ".", "old_accumulate_grads", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.forward": [[89, 91], ["legacy_distributed_data_parallel.LegacyDistributedDataParallel.module"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "module", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce": [[92, 177], ["legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce.reduction_fn"], "methods", ["None"], ["", "def", "all_reduce", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        This function must be called explicitly after backward to reduce\n        gradients. There is no automatic hook like c10d.\n        \"\"\"", "\n", "\n", "def", "all_reduce_params", "(", "params", ")", ":", "\n", "            ", "buffer", "=", "self", ".", "buffer", "\n", "nonzero_buffer", "=", "False", "\n", "if", "len", "(", "params", ")", ">", "1", ":", "\n", "                ", "offset", "=", "0", "\n", "for", "p", "in", "params", ":", "\n", "                    ", "sz", "=", "p", ".", "numel", "(", ")", "\n", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "buffer", "[", "offset", ":", "offset", "+", "sz", "]", ".", "copy_", "(", "p", ".", "grad", ".", "data", ".", "view", "(", "-", "1", ")", ")", "\n", "nonzero_buffer", "=", "True", "\n", "", "else", ":", "\n", "                        ", "buffer", "[", "offset", ":", "offset", "+", "sz", "]", ".", "zero_", "(", ")", "\n", "", "offset", "+=", "sz", "\n", "", "", "else", ":", "\n", "# we only have a single grad to all-reduce", "\n", "                ", "p", "=", "params", "[", "0", "]", "\n", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                    ", "buffer", "=", "p", ".", "grad", ".", "data", "\n", "nonzero_buffer", "=", "True", "\n", "", "elif", "p", ".", "numel", "(", ")", "<=", "self", ".", "buffer", ".", "numel", "(", ")", ":", "\n", "                    ", "buffer", "=", "buffer", "[", ":", "p", ".", "numel", "(", ")", "]", "\n", "buffer", ".", "zero_", "(", ")", "\n", "", "else", ":", "\n", "                    ", "buffer", "=", "torch", ".", "zeros_like", "(", "p", ")", "\n", "\n", "", "", "if", "nonzero_buffer", ":", "\n", "                ", "buffer", ".", "div_", "(", "self", ".", "world_size", ")", "\n", "\n", "", "distributed_utils", ".", "all_reduce", "(", "buffer", ",", "self", ".", "process_group", ")", "\n", "\n", "# copy all-reduced grads back into their original place", "\n", "offset", "=", "0", "\n", "for", "p", "in", "params", ":", "\n", "                ", "sz", "=", "p", ".", "numel", "(", ")", "\n", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                    ", "p", ".", "grad", ".", "data", ".", "copy_", "(", "buffer", "[", "offset", ":", "offset", "+", "sz", "]", ".", "view_as", "(", "p", ")", ")", "\n", "", "else", ":", "\n", "                    ", "p", ".", "grad", "=", "buffer", "[", "offset", ":", "offset", "+", "sz", "]", ".", "view_as", "(", "p", ")", ".", "clone", "(", ")", "\n", "", "offset", "+=", "sz", "\n", "\n", "", "", "def", "reduction_fn", "(", ")", ":", "\n", "# This function only needs to be called once", "\n", "            ", "if", "self", ".", "accumulate_grads", ":", "\n", "                ", "return", "\n", "\n", "", "if", "self", ".", "buffer", "is", "None", ":", "\n", "                ", "self", ".", "buffer", "=", "next", "(", "self", ".", "module", ".", "parameters", "(", ")", ")", ".", "new", "(", "self", ".", "buffer_size", ")", "\n", "\n", "", "for", "params", "in", "self", ".", "per_device_params", ":", "\n", "# All-reduce the gradients in buckets", "\n", "                ", "offset", "=", "0", "\n", "buffered_params", "=", "[", "]", "\n", "for", "param", "in", "params", ":", "\n", "                    ", "if", "not", "param", ".", "requires_grad", ":", "\n", "                        ", "continue", "\n", "", "if", "param", ".", "grad", "is", "None", ":", "\n", "                        ", "param", ".", "grad", "=", "torch", ".", "zeros_like", "(", "param", ")", "\n", "", "if", "param", ".", "grad", ".", "requires_grad", ":", "\n", "                        ", "raise", "RuntimeError", "(", "\n", "\"DistributedDataParallel only works \"", "\n", "\"with gradients that don't require \"", "\n", "\"grad\"", "\n", ")", "\n", "", "sz", "=", "param", ".", "numel", "(", ")", "\n", "if", "sz", ">", "self", ".", "buffer", ".", "numel", "(", ")", ":", "\n", "# all-reduce big params directly", "\n", "                        ", "all_reduce_params", "(", "[", "param", "]", ")", "\n", "", "else", ":", "\n", "                        ", "if", "offset", "+", "sz", ">", "self", ".", "buffer", ".", "numel", "(", ")", ":", "\n", "                            ", "all_reduce_params", "(", "buffered_params", ")", "\n", "offset", "=", "0", "\n", "buffered_params", ".", "clear", "(", ")", "\n", "", "buffered_params", ".", "append", "(", "param", ")", "\n", "offset", "+=", "sz", "\n", "\n", "", "", "if", "len", "(", "buffered_params", ")", ">", "0", ":", "\n", "                    ", "all_reduce_params", "(", "buffered_params", ")", "\n", "\n", "", "", "", "reduction_fn", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.ConstraintState.__init__": [[37, 39], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.ConstraintNode.__init__": [[116, 129], ["int"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "token", ":", "int", "=", "None", ",", "parent", "=", "None", ")", ":", "\n", "# The token associate with this node (None for the root)", "\n", "        ", "self", ".", "token", "=", "int", "(", "token", ")", "if", "token", "is", "not", "None", "else", "None", "\n", "# The parent (None at the root)", "\n", "self", ".", "parent", "=", "parent", "\n", "# Whether this node is a completed constraint", "\n", "self", ".", "terminal", "=", "0", "\n", "# List of child nodes", "\n", "self", ".", "children", "=", "{", "}", "\n", "\n", "# The cumulative number of constraints from this point in the", "\n", "# trie forward", "\n", "self", ".", "num_constraints", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.ConstraintNode.id": [[130, 133], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "id", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "token", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.ConstraintNode.__str__": [[134, 137], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "term", "=", "self", ".", "terminal", "!=", "0", "\n", "return", "f\"[{self.token}].{term}#{self.num_constraints}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.ConstraintNode.__getitem__": [[138, 140], ["token_generation_constraints.ConstraintNode.children.get"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "key", ":", "int", ")", ":", "\n", "        ", "return", "self", ".", "children", ".", "get", "(", "key", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.ConstraintNode.next_tokens": [[141, 144], ["set", "token_generation_constraints.ConstraintNode.children.keys"], "methods", ["None"], ["", "def", "next_tokens", "(", "self", ")", "->", "Set", "[", "int", "]", ":", "\n", "        ", "\"\"\"The set of child labels.\"\"\"", "\n", "return", "set", "(", "self", ".", "children", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.ConstraintNode.create": [[145, 152], ["token_generation_constraints.ConstraintNode", "token_generation_constraints.ConstraintNode.add_sequence"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.ConstraintNode.add_sequence"], ["", "@", "staticmethod", "\n", "def", "create", "(", "constraints", ":", "List", "[", "List", "[", "int", "]", "]", ")", ":", "\n", "        ", "root", "=", "ConstraintNode", "(", ")", "\n", "for", "sequence", "in", "constraints", ":", "\n", "            ", "root", ".", "add_sequence", "(", "sequence", ")", "\n", "\n", "", "return", "root", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.ConstraintNode.print_graph": [[153, 163], ["len", "str", "node.children.values", "token_generation_constraints.ConstraintNode.print_graph"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.ConstraintNode.print_graph"], ["", "@", "staticmethod", "\n", "def", "print_graph", "(", "node", ":", "\"ConstraintNode\"", ")", ":", "\n", "        ", "if", "len", "(", "node", ".", "children", ")", "==", "0", ":", "\n", "            ", "return", "str", "(", "node", ")", "\n", "", "else", ":", "\n", "            ", "s", "=", "f\"({node}\"", "\n", "for", "child", "in", "node", ".", "children", ".", "values", "(", ")", ":", "\n", "                ", "s", "+=", "\" \"", "+", "ConstraintNode", ".", "print_graph", "(", "child", ")", "\n", "", "s", "+=", "\")\"", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.ConstraintNode.token_counts": [[164, 176], ["collections.Counter", "list", "token_generation_constraints.ConstraintNode.children.values", "len", "list.pop", "list", "list.pop.children.values"], "methods", ["None"], ["", "", "def", "token_counts", "(", "self", ")", "->", "Counter", ":", "\n", "        ", "\"\"\"Returns a counter of the number of times each token is used\n        in a constraint.\n        \"\"\"", "\n", "token_counts", "=", "Counter", "(", ")", "\n", "kids", "=", "list", "(", "self", ".", "children", ".", "values", "(", ")", ")", "\n", "while", "len", "(", "kids", ")", ">", "0", ":", "\n", "            ", "kid", "=", "kids", ".", "pop", "(", ")", "\n", "token_counts", "[", "kid", ".", "id", "]", "+=", "kid", ".", "num_constraints", "\n", "kids", "+=", "list", "(", "kid", ".", "children", ".", "values", "(", ")", ")", "\n", "\n", "", "return", "token_counts", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.ConstraintNode.tokens": [[177, 180], ["set", "token_generation_constraints.ConstraintNode.token_counts().keys", "token_generation_constraints.ConstraintNode.token_counts"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.token_counts"], ["", "def", "tokens", "(", "self", ")", "->", "Set", "[", "int", "]", ":", "\n", "        ", "\"\"\"Returns the set of tokens in constraints.\"\"\"", "\n", "return", "set", "(", "self", ".", "token_counts", "(", ")", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.ConstraintNode.add_sequence": [[181, 200], ["int", "len", "token_generation_constraints.ConstraintNode", "len", "node.add_sequence"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.ConstraintNode.add_sequence"], ["", "def", "add_sequence", "(", "self", ",", "sequence", ":", "List", "[", "int", "]", ")", ":", "\n", "        ", "\"\"\"Adds a constraint, represented as a list of integers, to\n        the trie.\"\"\"", "\n", "assert", "len", "(", "sequence", ")", ">", "0", "\n", "\n", "token", "=", "int", "(", "sequence", "[", "0", "]", ")", "\n", "if", "token", "not", "in", "self", ".", "children", ":", "\n", "            ", "self", ".", "children", "[", "token", "]", "=", "ConstraintNode", "(", "token", ",", "parent", "=", "self", ")", "\n", "\n", "", "node", "=", "self", ".", "children", "[", "token", "]", "\n", "if", "len", "(", "sequence", ")", "==", "1", ":", "\n", "            ", "node", ".", "terminal", "+=", "1", "\n", "node", ".", "num_constraints", "+=", "1", "\n", "parent", "=", "node", ".", "parent", "\n", "while", "parent", "is", "not", "None", ":", "\n", "                ", "parent", ".", "num_constraints", "+=", "1", "\n", "parent", "=", "parent", ".", "parent", "\n", "", "", "else", ":", "\n", "            ", "node", ".", "add_sequence", "(", "sequence", "[", "1", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.UnorderedConstraintState.__init__": [[208, 228], ["collections.Counter", "collections.Counter", "token_generation_constraints.UnorderedConstraintState.root.tokens", "collections.Counter", "collections.Counter"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.tokens"], ["def", "__init__", "(", "self", ",", "node", ":", "ConstraintNode", ",", "copy_from", ":", "\"ConstraintState\"", "=", "None", ")", ":", "\n", "        ", "self", ".", "node", "=", "node", "\n", "\n", "if", "copy_from", "is", "None", ":", "\n", "# The root node", "\n", "            ", "self", ".", "root", "=", "node", "\n", "# The set of states in the graph that have been completed", "\n", "self", ".", "completed", "=", "Counter", "(", ")", "\n", "# The...", "\n", "self", ".", "generated", "=", "Counter", "(", ")", "\n", "# The list of tokens we need to generate", "\n", "self", ".", "needed_tokens", "=", "self", ".", "root", ".", "tokens", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "completed", "=", "Counter", "(", "copy_from", ".", "completed", ")", "\n", "self", ".", "generated", "=", "Counter", "(", "copy_from", ".", "generated", ")", "\n", "self", ".", "root", "=", "copy_from", ".", "root", "\n", "\n", "# Mark the node as generated", "\n", "", "if", "self", ".", "node", "!=", "self", ".", "root", ":", "\n", "            ", "self", ".", "generated", "[", "node", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.UnorderedConstraintState.create": [[229, 234], ["token_generation_constraints.unpack_constraints", "token_generation_constraints.ConstraintNode.create", "token_generation_constraints.UnorderedConstraintState"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.unpack_constraints", "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.create"], ["", "", "@", "staticmethod", "\n", "def", "create", "(", "constraint_tensor", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "constraint_list", "=", "unpack_constraints", "(", "constraint_tensor", ")", "\n", "constraint_trie_root", "=", "ConstraintNode", ".", "create", "(", "constraint_list", ")", "\n", "return", "UnorderedConstraintState", "(", "constraint_trie_root", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.UnorderedConstraintState.__str__": [[235, 238], ["str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "gen_str", "=", "\",\"", ".", "join", "(", "[", "str", "(", "node", ")", "for", "node", "in", "self", ".", "generated", "]", ")", "\n", "return", "f\"{self.name}/{self.bank}({gen_str})x{self.num_completed}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.UnorderedConstraintState.__copy__": [[239, 242], ["token_generation_constraints.UnorderedConstraintState"], "methods", ["None"], ["", "def", "__copy__", "(", "self", ")", ":", "\n", "        ", "copied_state", "=", "UnorderedConstraintState", "(", "self", ".", "node", ",", "copy_from", "=", "self", ")", "\n", "return", "copied_state", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.UnorderedConstraintState.copy": [[243, 245], ["token_generation_constraints.UnorderedConstraintState.__copy__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.__copy__"], ["", "def", "copy", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__copy__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.UnorderedConstraintState.name": [[246, 252], ["str"], "methods", ["None"], ["", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "node", ".", "id", "is", "None", ":", "\n", "            ", "return", "\"ROOT\"", "\n", "", "else", ":", "\n", "            ", "return", "str", "(", "self", ".", "node", ".", "id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.UnorderedConstraintState.is_root": [[253, 256], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "is_root", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "node", "==", "self", ".", "root", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.UnorderedConstraintState.bank": [[257, 260], ["sum", "token_generation_constraints.UnorderedConstraintState.generated.values"], "methods", ["None"], ["", "@", "property", "\n", "def", "bank", "(", "self", ")", ":", "\n", "        ", "return", "sum", "(", "self", ".", "generated", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.UnorderedConstraintState.num_completed": [[261, 270], ["sum", "token_generation_constraints.UnorderedConstraintState.completed.values"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_completed", "(", "self", ")", ":", "\n", "        ", "\"\"\"The number of constraints (not constraint tokens) that are completed.\n        In addition to the already-completed states, we need to account for the\n        current state, which might get marked as completed when another token\n        is generated.\n        \"\"\"", "\n", "in_final", "=", "self", ".", "node", ".", "terminal", "and", "self", ".", "completed", "[", "self", ".", "node", "]", "<", "self", ".", "node", ".", "terminal", "\n", "return", "sum", "(", "self", ".", "completed", ".", "values", "(", ")", ")", "+", "in_final", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.UnorderedConstraintState.finished": [[271, 274], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "finished", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "root", ".", "num_constraints", "-", "self", ".", "num_completed", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.UnorderedConstraintState.token_counts": [[275, 278], ["token_generation_constraints.UnorderedConstraintState.root.token_counts"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.token_counts"], ["", "@", "property", "\n", "def", "token_counts", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "root", ".", "token_counts", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.UnorderedConstraintState.tokens": [[279, 282], ["token_generation_constraints.UnorderedConstraintState.root.tokens"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.tokens"], ["", "@", "property", "\n", "def", "tokens", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "root", ".", "tokens", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.UnorderedConstraintState.num_constraint_tokens": [[283, 286], ["sum", "token_generation_constraints.UnorderedConstraintState.token_counts.values"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_constraint_tokens", "(", "self", ")", ":", "\n", "        ", "return", "sum", "(", "self", ".", "token_counts", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.UnorderedConstraintState.next_tokens": [[287, 297], ["token_generation_constraints.UnorderedConstraintState.root.next_tokens().union", "token_generation_constraints.UnorderedConstraintState.root.next_tokens", "token_generation_constraints.UnorderedConstraintState.node.next_tokens", "token_generation_constraints.UnorderedConstraintState.root.next_tokens"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.next_tokens", "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.next_tokens", "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.next_tokens"], ["", "def", "next_tokens", "(", "self", ")", "->", "Set", "[", "int", "]", ":", "\n", "        ", "\"\"\"Returns the list of tokens that could come next.\n        These are (a) all tokens extending the root state and, for\n        non-root states, additionally all tokens extending the current\n        state.\"\"\"", "\n", "\n", "if", "self", ".", "node", "!=", "self", ".", "root", ":", "\n", "            ", "return", "self", ".", "root", ".", "next_tokens", "(", ")", ".", "union", "(", "self", ".", "node", ".", "next_tokens", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "root", ".", "next_tokens", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.UnorderedConstraintState.advance": [[298, 359], ["int", "token_generation_constraints.UnorderedConstraintState", "token_generation_constraints.UnorderedConstraintState.advance.rewind"], "methods", ["None"], ["", "", "def", "advance", "(", "self", ",", "token", ":", "int", ")", ":", "\n", "        ", "\"\"\"Reads in a token and advances the state. Here's how it works.\n\n        We can advance to the next state if:\n        - there is a matching child\n        - its path isn't blocked\n\n        A path is blocked when all constraints that are descendants of\n        that node have already been generated, in the current state.\n\n        If we are not able to advance from the current state, we \"fall\n        off the graph\" and return to the root state. There, we again\n        try to advance, checking the same criteria.\n\n        In any case, when falling off the graph, we need to do some\n        bookkeeping. We:\n        - check whether any constraints were met (all prefixes of\n          current state)\n        - if one is found, mark it as completed\n        - adjust visited nodes accordingly\n        \"\"\"", "\n", "token", "=", "int", "(", "token", ")", "\n", "\n", "next_state", "=", "None", "\n", "child", "=", "self", ".", "node", "[", "token", "]", "\n", "if", "child", "is", "not", "None", "and", "self", ".", "generated", "[", "child", "]", "<", "child", ".", "num_constraints", ":", "\n", "            ", "next_state", "=", "UnorderedConstraintState", "(", "child", ",", "copy_from", "=", "self", ")", "\n", "\n", "", "def", "rewind", "(", ")", ":", "\n", "            ", "\"\"\"If we're mid-trie and an \"illegal\" token is chosen next, we need\n            to reset our state to the root state. However, along the way, we need\n            to check whether a prefix of the current trie state represents a state\n            we could mark as completed.\n            \"\"\"", "\n", "node", "=", "self", ".", "node", "\n", "while", "node", "!=", "self", ".", "root", ":", "\n", "                ", "if", "node", ".", "terminal", "and", "self", ".", "completed", "[", "node", "]", "<", "node", ".", "terminal", ":", "\n", "                    ", "next_state", ".", "completed", "[", "node", "]", "+=", "1", "\n", "return", "\n", "\n", "", "next_state", ".", "generated", "[", "node", "]", "-=", "1", "\n", "node", "=", "node", ".", "parent", "\n", "\n", "# Fall off the graph, check the root", "\n", "", "", "if", "next_state", "is", "None", "and", "token", "in", "self", ".", "root", ".", "next_tokens", "(", ")", ":", "\n", "            ", "child", "=", "self", ".", "root", "[", "token", "]", "\n", "# We can only traverse this edge if it's not saturated", "\n", "if", "self", ".", "generated", "[", "child", "]", "<", "child", ".", "num_constraints", ":", "\n", "                ", "next_state", "=", "UnorderedConstraintState", "(", "child", ",", "copy_from", "=", "self", ")", "\n", "", "else", ":", "\n", "                ", "next_state", "=", "UnorderedConstraintState", "(", "self", ".", "root", ",", "copy_from", "=", "self", ")", "\n", "\n", "# Rewind", "\n", "", "rewind", "(", ")", "\n", "\n", "", "elif", "next_state", "is", "None", ":", "\n", "            ", "next_state", "=", "UnorderedConstraintState", "(", "self", ".", "root", ",", "copy_from", "=", "self", ")", "\n", "# Rewind", "\n", "rewind", "(", ")", "\n", "\n", "", "return", "next_state", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.ConstraintSequence.__init__": [[362, 376], ["set", "len", "token_generation_constraints.ConstraintSequence.tokens.add", "range", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add"], ["    ", "def", "__init__", "(", "self", ",", "sequences", ":", "List", "[", "List", "[", "int", "]", "]", ")", ":", "\n", "        ", "\"\"\"Represents a set of possibly multitoken constraints by\n        concatenating them and internally recording the end points.\n        \"\"\"", "\n", "self", ".", "sequences", "=", "[", "]", "\n", "self", ".", "endpoints", "=", "[", "]", "\n", "self", ".", "num_tokens", "=", "0", "\n", "self", ".", "tokens", "=", "set", "(", ")", "\n", "for", "sequence", "in", "sequences", ":", "\n", "            ", "for", "token", "in", "sequence", ":", "\n", "                ", "self", ".", "tokens", ".", "add", "(", "token", ")", "\n", "", "self", ".", "num_tokens", "+=", "len", "(", "sequence", ")", "\n", "self", ".", "endpoints", "+=", "[", "False", "for", "x", "in", "range", "(", "len", "(", "sequence", ")", "-", "1", ")", "]", "+", "[", "True", "]", "\n", "self", ".", "sequences", "+=", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.ConstraintSequence.__getitem__": [[377, 379], ["None"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "key", ":", "int", ")", ":", "\n", "        ", "return", "self", ".", "sequences", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.ConstraintSequence.__len__": [[380, 382], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sequences", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.ConstraintSequence.__str__": [[383, 385], ["str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "sequences", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.__init__": [[392, 395], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "sequence", ":", "ConstraintSequence", ",", "state", ":", "int", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "sequence", "=", "sequence", "\n", "self", ".", "state", "=", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.create": [[396, 400], ["token_generation_constraints.unpack_constraints", "token_generation_constraints.OrderedConstraintState", "token_generation_constraints.ConstraintSequence"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.unpack_constraints"], ["", "@", "staticmethod", "\n", "def", "create", "(", "constraint_tensor", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "constraint_list", "=", "unpack_constraints", "(", "constraint_tensor", ")", "\n", "return", "OrderedConstraintState", "(", "ConstraintSequence", "(", "constraint_list", ")", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.__str__": [[401, 403], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "f\"{self.state}/{self.bank}x{self.num_completed}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.__copy__": [[404, 406], ["token_generation_constraints.OrderedConstraintState"], "methods", ["None"], ["", "def", "__copy__", "(", "self", ")", ":", "\n", "        ", "return", "OrderedConstraintState", "(", "self", ".", "sequence", ",", "self", ".", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.copy": [[407, 409], ["token_generation_constraints.OrderedConstraintState.__copy__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.__copy__"], ["", "def", "copy", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__copy__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.num_completed": [[410, 418], ["len", "list", "filter"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_completed", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "state", "==", "-", "1", ":", "\n", "            ", "return", "0", "\n", "", "count", "=", "len", "(", "\n", "list", "(", "filter", "(", "lambda", "x", ":", "x", ",", "self", ".", "sequence", ".", "endpoints", "[", "0", ":", "self", ".", "state", "+", "1", "]", ")", ")", "\n", ")", "\n", "return", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.is_root": [[419, 422], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "is_root", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "state", "==", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.name": [[423, 429], ["str"], "methods", ["None"], ["", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "state", "==", "-", "1", ":", "\n", "            ", "return", "\"ROOT\"", "\n", "", "else", ":", "\n", "            ", "return", "str", "(", "self", ".", "sequence", "[", "self", ".", "state", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.bank": [[430, 433], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "bank", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "state", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.finished": [[434, 437], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "finished", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "state", "+", "1", "==", "len", "(", "self", ".", "sequence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.token_counts": [[438, 441], ["token_generation_constraints.OrderedConstraintState.sequence.token_counts"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.token_counts"], ["", "@", "property", "\n", "def", "token_counts", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sequence", ".", "token_counts", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.tokens": [[442, 445], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "tokens", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sequence", ".", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.num_constraint_tokens": [[446, 449], ["sum", "token_generation_constraints.OrderedConstraintState.token_counts.values"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_constraint_tokens", "(", "self", ")", ":", "\n", "        ", "return", "sum", "(", "self", ".", "token_counts", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.next_tokens": [[450, 462], ["set", "set.add", "set.add"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add"], ["", "def", "next_tokens", "(", "self", ")", "->", "Set", "[", "int", "]", ":", "\n", "        ", "\"\"\"Returns the list of tokens that could come next.\n        These are (a) all tokens extending the root state and, for\n        non-root states, additionally all tokens extending the current\n        state.\"\"\"", "\n", "\n", "tokens", "=", "set", "(", ")", "\n", "if", "self", ".", "state", ">", "0", ":", "\n", "            ", "tokens", ".", "add", "(", "self", ".", "sequence", "[", "0", "]", ")", "\n", "", "if", "not", "self", ".", "finished", ":", "\n", "            ", "tokens", ".", "add", "(", "self", ".", "sequence", "[", "self", ".", "state", "+", "1", "]", ")", "\n", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.advance": [[463, 507], ["int", "token_generation_constraints.OrderedConstraintState.copy", "token_generation_constraints.OrderedConstraintState", "token_generation_constraints.OrderedConstraintState.copy", "token_generation_constraints.OrderedConstraintState", "token_generation_constraints.OrderedConstraintState"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.copy", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.copy"], ["", "def", "advance", "(", "self", ",", "token", ":", "int", ")", ":", "\n", "        ", "\"\"\"Reads in a token and advances the state. Here's how it works.\n\n        We can advance to the next state if:\n        - there is a matching child\n        - its path isn't blocked\n\n        A path is blocked when all constraints that are descendants of\n        that node have already been generated, in the current state.\n\n        If we are not able to advance from the current state, we \"fall\n        off the graph\" and return to the root state. There, we again\n        try to advance, checking the same criteria.\n\n        In any case, when falling off the graph, we need to do some\n        bookkeeping. We:\n        - check whether any constraints were met (all prefixes of\n          current state)\n        - if one is found, mark it as completed\n        - adjust visited nodes accordingly\n        \"\"\"", "\n", "token", "=", "int", "(", "token", ")", "\n", "# print(f\"{self} ADVANCE({token}) {self.sequence} -> \", end=\"\")", "\n", "\n", "if", "self", ".", "finished", ":", "\n", "# Accept anything", "\n", "            ", "next_state", "=", "self", ".", "copy", "(", ")", "\n", "\n", "", "elif", "self", ".", "sequence", "[", "self", ".", "state", "+", "1", "]", "==", "token", ":", "\n", "# Advance to the next token", "\n", "            ", "next_state", "=", "OrderedConstraintState", "(", "self", ".", "sequence", ",", "self", ".", "state", "+", "1", ")", "\n", "\n", "", "elif", "self", ".", "sequence", ".", "endpoints", "[", "self", ".", "state", "]", ":", "\n", "# Accept anything between constraints (*)", "\n", "            ", "next_state", "=", "self", ".", "copy", "(", ")", "\n", "\n", "", "elif", "token", "==", "self", ".", "sequence", "[", "0", "]", ":", "\n", "# Start over having generated the first token", "\n", "            ", "next_state", "=", "OrderedConstraintState", "(", "self", ".", "sequence", ",", "0", ")", "\n", "", "else", ":", "\n", "# Start over from the root", "\n", "            ", "next_state", "=", "OrderedConstraintState", "(", "self", ".", "sequence", ",", "-", "1", ")", "\n", "\n", "", "return", "next_state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.pack_constraints": [[41, 92], ["len", "torch.zeros().long", "enumerate", "torch.zeros().long.long", "len", "len", "enumerate", "max", "torch.zeros", "constraint.size", "len", "sum", "c.size"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "", "def", "pack_constraints", "(", "batch_constraints", ":", "List", "[", "List", "[", "torch", ".", "Tensor", "]", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Takes a list of list of constraints in tensor form (a list of\n    tensor constraints for each sentence) and transforms it into a\n    packed Tensor. For example, here is a batch of size 3 with 3, 0,\n    and 1 constraints:\n\n        [ [ [3 1 2], [3], [4 5 6 7], ]\n          [],\n          [ [1 8 9 10 1 4 11 12], ]\n        ]\n\n    Its corresponding packed structure is:\n\n        [ [ 3  3  1  2  0  3  0  4  5  6  7  0],\n          [ 0  0  0  0  0  0  0  0  0  0  0  0],\n          [ 1  1  8  9 10  1  4 11 12  0  0  0] ]\n\n    The packed tensor has shape (batch size, maxlen), where\n    maxlen is defined below. Each row contains concatenated\n    constraint tokens for that sentence, with 0 appended after\n    each constraint. The first item in each row is the number\n    of constraints for that sentence. So maxlen is the maximum\n    of\n\n    (number of constraints) + (sum length of constraints) + 1.\n\n    across all sentences in the batch.\n    \"\"\"", "\n", "# The maximum word length of concatenated constraints for any sentence", "\n", "max_constraints_len", "=", "1", "\n", "for", "sentence_constraints", "in", "batch_constraints", ":", "\n", "        ", "if", "len", "(", "sentence_constraints", ")", ":", "\n", "# number of constraints, plus sum of constrain lens, plus a zero after each", "\n", "            ", "constraints_len", "=", "(", "\n", "1", "\n", "+", "sum", "(", "[", "c", ".", "size", "(", "0", ")", "for", "c", "in", "sentence_constraints", "]", ")", "\n", "+", "len", "(", "sentence_constraints", ")", "\n", ")", "\n", "max_constraints_len", "=", "max", "(", "max_constraints_len", ",", "constraints_len", ")", "\n", "\n", "", "", "batch_size", "=", "len", "(", "batch_constraints", ")", "\n", "constraints_tensor", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "max_constraints_len", ")", ")", ".", "long", "(", ")", "\n", "for", "i", ",", "sentence_constraints", "in", "enumerate", "(", "batch_constraints", ")", ":", "\n", "        ", "constraints_tensor", "[", "i", ",", "0", "]", "=", "len", "(", "sentence_constraints", ")", "\n", "offset", "=", "1", "\n", "for", "j", ",", "constraint", "in", "enumerate", "(", "sentence_constraints", ")", ":", "\n", "            ", "this_len", "=", "constraint", ".", "size", "(", "0", ")", "\n", "constraints_tensor", "[", "i", ",", "offset", ":", "offset", "+", "this_len", "]", "=", "constraint", "\n", "offset", "+=", "this_len", "+", "1", "\n", "\n", "", "", "return", "constraints_tensor", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.unpack_constraints": [[94, 109], ["constraint_tensor.tolist", "range", "constraint_tensor.tolist.index", "constraint_list.append"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.index"], ["", "def", "unpack_constraints", "(", "constraint_tensor", ":", "torch", ".", "Tensor", ")", "->", "List", "[", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n    Transforms *one row* of a packed constraint tensor (e.g., for one\n    sentence in the batch) into a list of constraint tensors.\n    \"\"\"", "\n", "constraint_list", "=", "[", "]", "\n", "num_constraints", "=", "constraint_tensor", "[", "0", "]", "\n", "constraints", "=", "constraint_tensor", ".", "tolist", "(", ")", "\n", "offset", "=", "1", "\n", "for", "i", "in", "range", "(", "num_constraints", ")", ":", "\n", "        ", "where", "=", "constraints", ".", "index", "(", "0", ",", "offset", ")", "\n", "constraint_list", ".", "append", "(", "constraint_tensor", "[", "offset", ":", "where", "]", ")", "\n", "offset", "=", "where", "+", "1", "\n", "\n", "", "return", "constraint_list", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.__init__": [[19, 30], ["list", "nan_detector.NanDetector.reset", "model.named_modules", "model.named_parameters", "nan_detector.NanDetector.add_hooks"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.reset", "home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.add_hooks"], ["def", "__init__", "(", "self", ",", "model", ",", "forward", "=", "True", ",", "backward", "=", "True", ")", ":", "\n", "        ", "self", ".", "bhooks", "=", "[", "]", "\n", "self", ".", "fhooks", "=", "[", "]", "\n", "self", ".", "forward", "=", "forward", "\n", "self", ".", "backward", "=", "backward", "\n", "self", ".", "named_parameters", "=", "list", "(", "model", ".", "named_parameters", "(", ")", ")", "\n", "self", ".", "reset", "(", ")", "\n", "\n", "for", "name", ",", "mod", "in", "model", ".", "named_modules", "(", ")", ":", "\n", "            ", "mod", ".", "__module_name", "=", "name", "\n", "self", ".", "add_hooks", "(", "mod", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.__enter__": [[31, 33], ["None"], "methods", ["None"], ["", "", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.__exit__": [[34, 50], ["nan_detector.NanDetector.close", "len", "logger.info", "logger.info", "logger.info", "torch.norm", "torch.norm.item", "torch.isnan().any", "torch.isinf().any", "torch.isnan", "torch.isinf"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.close", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_value", ",", "exc_traceback", ")", ":", "\n", "# Dump out all model gnorms to enable better debugging", "\n", "        ", "norm", "=", "{", "}", "\n", "gradients", "=", "{", "}", "\n", "for", "name", ",", "param", "in", "self", ".", "named_parameters", ":", "\n", "            ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                ", "grad_norm", "=", "torch", ".", "norm", "(", "param", ".", "grad", ".", "data", ",", "p", "=", "2", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "norm", "[", "name", "]", "=", "grad_norm", ".", "item", "(", ")", "\n", "if", "torch", ".", "isnan", "(", "grad_norm", ")", ".", "any", "(", ")", "or", "torch", ".", "isinf", "(", "grad_norm", ")", ".", "any", "(", ")", ":", "\n", "                    ", "gradients", "[", "name", "]", "=", "param", ".", "grad", ".", "data", "\n", "", "", "", "if", "len", "(", "gradients", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Detected nan/inf grad norm, dumping norms...\"", ")", "\n", "logger", ".", "info", "(", "f\"norms: {norm}\"", ")", "\n", "logger", ".", "info", "(", "f\"gradients: {gradients}\"", ")", "\n", "\n", "", "self", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.add_hooks": [[51, 56], ["nan_detector.NanDetector.fhooks.append", "nan_detector.NanDetector.bhooks.append", "module.register_forward_hook", "module.register_backward_hook"], "methods", ["None"], ["", "def", "add_hooks", "(", "self", ",", "module", ")", ":", "\n", "        ", "if", "self", ".", "forward", ":", "\n", "            ", "self", ".", "fhooks", ".", "append", "(", "module", ".", "register_forward_hook", "(", "self", ".", "fhook_fn", ")", ")", "\n", "", "if", "self", ".", "backward", ":", "\n", "            ", "self", ".", "bhooks", ".", "append", "(", "module", ".", "register_backward_hook", "(", "self", ".", "bhook_fn", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.reset": [[57, 60], ["None"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "has_printed_f", "=", "False", "\n", "self", ".", "has_printed_b", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector._detect": [[61, 76], ["torch.is_floating_point", "tensor.numel", "torch.no_grad", "torch.isnan().any", "torch.isinf().any", "torch.isnan", "torch.isinf"], "methods", ["None"], ["", "def", "_detect", "(", "self", ",", "tensor", ",", "name", ",", "backward", ")", ":", "\n", "        ", "err", "=", "None", "\n", "if", "(", "\n", "torch", ".", "is_floating_point", "(", "tensor", ")", "\n", "# single value tensors (like the loss) will not provide much info", "\n", "and", "tensor", ".", "numel", "(", ")", ">=", "2", "\n", ")", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "if", "torch", ".", "isnan", "(", "tensor", ")", ".", "any", "(", ")", ":", "\n", "                    ", "err", "=", "\"NaN\"", "\n", "", "elif", "torch", ".", "isinf", "(", "tensor", ")", ".", "any", "(", ")", ":", "\n", "                    ", "err", "=", "\"Inf\"", "\n", "", "", "", "if", "err", "is", "not", "None", ":", "\n", "            ", "err", "=", "f\"{err} detected in output of {name}, shape: {tensor.shape}, {'backward' if backward else 'forward'}\"", "\n", "", "return", "err", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector._apply": [[77, 97], ["torch.is_tensor", "nan_detector.NanDetector._detect", "isinstance", "isinstance", "logger.warning", "setattr", "x.values", "len", "torch.is_tensor", "nan_detector.NanDetector._apply", "isinstance", "isinstance", "nan_detector.NanDetector._apply", "inp.max().item", "inp.min().item", "inp.max", "inp.min"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector._detect", "home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector._apply", "home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector._apply", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "def", "_apply", "(", "self", ",", "module", ",", "inp", ",", "x", ",", "backward", ")", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "x", ")", ":", "\n", "            ", "if", "isinstance", "(", "inp", ",", "tuple", ")", "and", "len", "(", "inp", ")", ">", "0", ":", "\n", "                ", "inp", "=", "inp", "[", "0", "]", "\n", "", "err", "=", "self", ".", "_detect", "(", "x", ",", "module", ".", "__module_name", ",", "backward", ")", "\n", "if", "err", "is", "not", "None", ":", "\n", "                ", "if", "torch", ".", "is_tensor", "(", "inp", ")", "and", "not", "backward", ":", "\n", "                    ", "err", "+=", "(", "\n", "f\" input max: {inp.max().item()}, input min: {inp.min().item()}\"", "\n", ")", "\n", "\n", "", "has_printed_attr", "=", "\"has_printed_b\"", "if", "backward", "else", "\"has_printed_f\"", "\n", "logger", ".", "warning", "(", "err", ")", "\n", "setattr", "(", "self", ",", "has_printed_attr", ",", "True", ")", "\n", "", "", "elif", "isinstance", "(", "x", ",", "dict", ")", ":", "\n", "            ", "for", "v", "in", "x", ".", "values", "(", ")", ":", "\n", "                ", "self", ".", "_apply", "(", "module", ",", "inp", ",", "v", ",", "backward", ")", "\n", "", "", "elif", "isinstance", "(", "x", ",", "list", ")", "or", "isinstance", "(", "x", ",", "tuple", ")", ":", "\n", "            ", "for", "v", "in", "x", ":", "\n", "                ", "self", ".", "_apply", "(", "module", ",", "inp", ",", "v", ",", "backward", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.fhook_fn": [[98, 101], ["nan_detector.NanDetector._apply"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector._apply"], ["", "", "", "def", "fhook_fn", "(", "self", ",", "module", ",", "inp", ",", "output", ")", ":", "\n", "        ", "if", "not", "self", ".", "has_printed_f", ":", "\n", "            ", "self", ".", "_apply", "(", "module", ",", "inp", ",", "output", ",", "backward", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.bhook_fn": [[102, 105], ["nan_detector.NanDetector._apply"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector._apply"], ["", "", "def", "bhook_fn", "(", "self", ",", "module", ",", "inp", ",", "output", ")", ":", "\n", "        ", "if", "not", "self", ".", "has_printed_b", ":", "\n", "            ", "self", ".", "_apply", "(", "module", ",", "inp", ",", "output", ",", "backward", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.close": [[106, 109], ["hook.remove"], "methods", ["None"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "for", "hook", "in", "self", ".", "fhooks", "+", "self", ".", "bhooks", ":", "\n", "            ", "hook", ".", "remove", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.__init__": [[89, 114], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "fairseq.utils.load_align_dict", "fairseq.data.encoders.build_tokenizer", "fairseq.data.encoders.build_bpe", "fairseq.utils.resolve_max_positions", "hub_utils.GeneratorHubInterface.register_buffer", "model.prepare_for_inference_", "hub_utils.GeneratorHubInterface.task.max_positions", "torch.tensor", "model.max_positions"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.load_align_dict", "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.build_tokenizer", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.build_bpe", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.resolve_max_positions", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.prepare_for_inference_", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions"], ["def", "__init__", "(", "self", ",", "cfg", ",", "task", ",", "models", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "models", "=", "nn", ".", "ModuleList", "(", "models", ")", "\n", "self", ".", "src_dict", "=", "task", ".", "source_dictionary", "\n", "self", ".", "tgt_dict", "=", "task", ".", "target_dictionary", "\n", "\n", "# optimize model for generation", "\n", "for", "model", "in", "self", ".", "models", ":", "\n", "            ", "model", ".", "prepare_for_inference_", "(", "cfg", ")", "\n", "\n", "# Load alignment dictionary for unknown word replacement", "\n", "# (None if no unknown word replacement, empty if no path to align dictionary)", "\n", "", "self", ".", "align_dict", "=", "utils", ".", "load_align_dict", "(", "cfg", ".", "generation", ".", "replace_unk", ")", "\n", "\n", "self", ".", "tokenizer", "=", "encoders", ".", "build_tokenizer", "(", "cfg", ".", "tokenizer", ")", "\n", "self", ".", "bpe", "=", "encoders", ".", "build_bpe", "(", "cfg", ".", "bpe", ")", "\n", "\n", "self", ".", "max_positions", "=", "utils", ".", "resolve_max_positions", "(", "\n", "self", ".", "task", ".", "max_positions", "(", ")", ",", "*", "[", "model", ".", "max_positions", "(", ")", "for", "model", "in", "models", "]", "\n", ")", "\n", "\n", "# this is useful for determining the device", "\n", "self", ".", "register_buffer", "(", "\"_float_tensor\"", ",", "torch", ".", "tensor", "(", "[", "0", "]", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.device": [[115, 118], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_float_tensor", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.translate": [[119, 123], ["hub_utils.GeneratorHubInterface.sample"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.sample"], ["", "def", "translate", "(", "\n", "self", ",", "sentences", ":", "List", "[", "str", "]", ",", "beam", ":", "int", "=", "5", ",", "verbose", ":", "bool", "=", "False", ",", "**", "kwargs", "\n", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "return", "self", ".", "sample", "(", "sentences", ",", "beam", ",", "verbose", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.sample": [[124, 132], ["isinstance", "hub_utils.GeneratorHubInterface.generate", "hub_utils.GeneratorHubInterface.encode", "hub_utils.GeneratorHubInterface.decode", "hub_utils.GeneratorHubInterface.sample"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.generate", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode", "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.sample"], ["", "def", "sample", "(", "\n", "self", ",", "sentences", ":", "List", "[", "str", "]", ",", "beam", ":", "int", "=", "1", ",", "verbose", ":", "bool", "=", "False", ",", "**", "kwargs", "\n", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "if", "isinstance", "(", "sentences", ",", "str", ")", ":", "\n", "            ", "return", "self", ".", "sample", "(", "[", "sentences", "]", ",", "beam", "=", "beam", ",", "verbose", "=", "verbose", ",", "**", "kwargs", ")", "[", "0", "]", "\n", "", "tokenized_sentences", "=", "[", "self", ".", "encode", "(", "sentence", ")", "for", "sentence", "in", "sentences", "]", "\n", "batched_hypos", "=", "self", ".", "generate", "(", "tokenized_sentences", ",", "beam", ",", "verbose", ",", "**", "kwargs", ")", "\n", "return", "[", "self", ".", "decode", "(", "hypos", "[", "0", "]", "[", "\"tokens\"", "]", ")", "for", "hypos", "in", "batched_hypos", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.score": [[133, 142], ["isinstance", "hub_utils.GeneratorHubInterface.encode", "hub_utils.GeneratorHubInterface.score", "hub_utils.GeneratorHubInterface.generate"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode", "home.repos.pwc.inspect_result.reneeye_const.scoring.__init__.BaseScorer.score", "home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.generate"], ["", "def", "score", "(", "self", ",", "sentences", ":", "List", "[", "str", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "isinstance", "(", "sentences", ",", "str", ")", ":", "\n", "            ", "return", "self", ".", "score", "(", "[", "sentences", "]", ",", "**", "kwargs", ")", "[", "0", "]", "\n", "# NOTE: this doesn't support translation tasks currently", "\n", "", "tokenized_sentences", "=", "[", "self", ".", "encode", "(", "sentence", ")", "for", "sentence", "in", "sentences", "]", "\n", "return", "[", "\n", "hypos", "[", "0", "]", "\n", "for", "hypos", "in", "self", ".", "generate", "(", "\n", "tokenized_sentences", ",", "score_reference", "=", "True", ",", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.generate": [[145, 215], ["copy.copy", "hub_utils.GeneratorHubInterface.task.build_generator", "hub_utils.GeneratorHubInterface._build_batches", "torch.is_tensor", "omegaconf.open_dict", "kwargs.items", "fairseq.utils.apply_to_sample", "hub_utils.GeneratorHubInterface.task.inference_step", "zip", "zip", "tokenized_sentences.dim", "hub_utils.GeneratorHubInterface.generate", "setattr", "batch[].tolist", "results.append", "sorted", "getattr", "hub_utils.GeneratorHubInterface.string", "logger.info", "tokenized_sentences.unsqueeze", "t.to", "getattr", "hub_utils.GeneratorHubInterface.decode", "logger.info", "logger.info", "hub_utils.GeneratorHubInterface.generate.getarg"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.copy", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.build_generator", "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface._build_batches", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.apply_to_sample", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.inference_step", "home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.generate", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "generate", "(", "\n", "self", ",", "\n", "tokenized_sentences", ":", "List", "[", "torch", ".", "LongTensor", "]", ",", "\n", "beam", ":", "int", "=", "5", ",", "\n", "verbose", ":", "bool", "=", "False", ",", "\n", "skip_invalid_size_inputs", "=", "False", ",", "\n", "inference_step_args", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", "->", "List", "[", "List", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", "]", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "tokenized_sentences", ")", "and", "tokenized_sentences", ".", "dim", "(", ")", "==", "1", ":", "\n", "            ", "return", "self", ".", "generate", "(", "\n", "tokenized_sentences", ".", "unsqueeze", "(", "0", ")", ",", "beam", "=", "beam", ",", "verbose", "=", "verbose", ",", "**", "kwargs", "\n", ")", "[", "0", "]", "\n", "\n", "# build generator using current args as well as any kwargs", "\n", "", "gen_args", "=", "copy", ".", "copy", "(", "self", ".", "cfg", ")", "\n", "with", "open_dict", "(", "gen_args", ")", ":", "\n", "            ", "gen_args", ".", "beam", "=", "beam", "\n", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "                ", "setattr", "(", "gen_args", ",", "k", ",", "v", ")", "\n", "", "", "generator", "=", "self", ".", "task", ".", "build_generator", "(", "self", ".", "models", ",", "gen_args", ")", "\n", "\n", "inference_step_args", "=", "inference_step_args", "or", "{", "}", "\n", "results", "=", "[", "]", "\n", "for", "batch", "in", "self", ".", "_build_batches", "(", "tokenized_sentences", ",", "skip_invalid_size_inputs", ")", ":", "\n", "            ", "batch", "=", "utils", ".", "apply_to_sample", "(", "lambda", "t", ":", "t", ".", "to", "(", "self", ".", "device", ")", ",", "batch", ")", "\n", "translations", "=", "self", ".", "task", ".", "inference_step", "(", "\n", "generator", ",", "self", ".", "models", ",", "batch", ",", "**", "inference_step_args", "\n", ")", "\n", "for", "id", ",", "hypos", "in", "zip", "(", "batch", "[", "\"id\"", "]", ".", "tolist", "(", ")", ",", "translations", ")", ":", "\n", "                ", "results", ".", "append", "(", "(", "id", ",", "hypos", ")", ")", "\n", "\n", "# sort output to match input order", "\n", "", "", "outputs", "=", "[", "hypos", "for", "_", ",", "hypos", "in", "sorted", "(", "results", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "]", "\n", "\n", "if", "verbose", ":", "\n", "\n", "            ", "def", "getarg", "(", "name", ",", "default", ")", ":", "\n", "                ", "return", "getattr", "(", "gen_args", ",", "name", ",", "getattr", "(", "self", ".", "args", ",", "name", ",", "default", ")", ")", "\n", "\n", "", "for", "source_tokens", ",", "target_hypotheses", "in", "zip", "(", "tokenized_sentences", ",", "outputs", ")", ":", "\n", "                ", "src_str_with_unk", "=", "self", ".", "string", "(", "source_tokens", ")", "\n", "logger", ".", "info", "(", "\"S\\t{}\"", ".", "format", "(", "src_str_with_unk", ")", ")", "\n", "for", "hypo", "in", "target_hypotheses", ":", "\n", "                    ", "hypo_str", "=", "self", ".", "decode", "(", "hypo", "[", "\"tokens\"", "]", ")", "\n", "logger", ".", "info", "(", "\"H\\t{}\\t{}\"", ".", "format", "(", "hypo", "[", "\"score\"", "]", ",", "hypo_str", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"P\\t{}\"", ".", "format", "(", "\n", "\" \"", ".", "join", "(", "\n", "map", "(", "\n", "lambda", "x", ":", "\"{:.4f}\"", ".", "format", "(", "x", ")", ",", "\n", "hypo", "[", "\"positional_scores\"", "]", ".", "tolist", "(", ")", ",", "\n", ")", "\n", ")", "\n", ")", "\n", ")", "\n", "if", "hypo", "[", "\"alignment\"", "]", "is", "not", "None", "and", "getarg", "(", "\n", "\"print_alignment\"", ",", "False", "\n", ")", ":", "\n", "                        ", "logger", ".", "info", "(", "\n", "\"A\\t{}\"", ".", "format", "(", "\n", "\" \"", ".", "join", "(", "\n", "[", "\n", "\"{}-{}\"", ".", "format", "(", "src_idx", ",", "tgt_idx", ")", "\n", "for", "src_idx", ",", "tgt_idx", "in", "hypo", "[", "\"alignment\"", "]", "\n", "]", "\n", ")", "\n", ")", "\n", ")", "\n", "", "", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.encode": [[216, 220], ["hub_utils.GeneratorHubInterface.tokenize", "hub_utils.GeneratorHubInterface.apply_bpe", "hub_utils.GeneratorHubInterface.binarize"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scoring.tokenizer.EvaluationTokenizer.tokenize", "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.apply_bpe", "home.repos.pwc.inspect_result.reneeye_const.fairseq.binarizer.Binarizer.binarize"], ["", "def", "encode", "(", "self", ",", "sentence", ":", "str", ")", "->", "torch", ".", "LongTensor", ":", "\n", "        ", "sentence", "=", "self", ".", "tokenize", "(", "sentence", ")", "\n", "sentence", "=", "self", ".", "apply_bpe", "(", "sentence", ")", "\n", "return", "self", ".", "binarize", "(", "sentence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.decode": [[221, 225], ["hub_utils.GeneratorHubInterface.string", "hub_utils.GeneratorHubInterface.remove_bpe", "hub_utils.GeneratorHubInterface.detokenize"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.remove_bpe", "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.detokenize"], ["", "def", "decode", "(", "self", ",", "tokens", ":", "torch", ".", "LongTensor", ")", "->", "str", ":", "\n", "        ", "sentence", "=", "self", ".", "string", "(", "tokens", ")", "\n", "sentence", "=", "self", ".", "remove_bpe", "(", "sentence", ")", "\n", "return", "self", ".", "detokenize", "(", "sentence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.tokenize": [[226, 230], ["hub_utils.GeneratorHubInterface.tokenizer.encode"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "def", "tokenize", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "if", "self", ".", "tokenizer", "is", "not", "None", ":", "\n", "            ", "sentence", "=", "self", ".", "tokenizer", ".", "encode", "(", "sentence", ")", "\n", "", "return", "sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.detokenize": [[231, 235], ["hub_utils.GeneratorHubInterface.tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "detokenize", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "if", "self", ".", "tokenizer", "is", "not", "None", ":", "\n", "            ", "sentence", "=", "self", ".", "tokenizer", ".", "decode", "(", "sentence", ")", "\n", "", "return", "sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.apply_bpe": [[236, 240], ["hub_utils.GeneratorHubInterface.bpe.encode"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "def", "apply_bpe", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "if", "self", ".", "bpe", "is", "not", "None", ":", "\n", "            ", "sentence", "=", "self", ".", "bpe", ".", "encode", "(", "sentence", ")", "\n", "", "return", "sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.remove_bpe": [[241, 245], ["hub_utils.GeneratorHubInterface.bpe.decode"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "remove_bpe", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "if", "self", ".", "bpe", "is", "not", "None", ":", "\n", "            ", "sentence", "=", "self", ".", "bpe", ".", "decode", "(", "sentence", ")", "\n", "", "return", "sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.binarize": [[246, 248], ["hub_utils.GeneratorHubInterface.src_dict.encode_line().long", "hub_utils.GeneratorHubInterface.src_dict.encode_line"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.encode_line"], ["", "def", "binarize", "(", "self", ",", "sentence", ":", "str", ")", "->", "torch", ".", "LongTensor", ":", "\n", "        ", "return", "self", ".", "src_dict", ".", "encode_line", "(", "sentence", ",", "add_if_not_exist", "=", "False", ")", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.string": [[249, 251], ["hub_utils.GeneratorHubInterface.tgt_dict.string"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.string"], ["", "def", "string", "(", "self", ",", "tokens", ":", "torch", ".", "LongTensor", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "tgt_dict", ".", "string", "(", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface._build_batches": [[252, 265], ["torch.LongTensor", "hub_utils.GeneratorHubInterface.task.get_batch_iterator().next_epoch_itr", "t.numel", "hub_utils.GeneratorHubInterface.task.get_batch_iterator", "hub_utils.GeneratorHubInterface.task.build_dataset_for_inference"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.next_epoch_itr", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.get_batch_iterator", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.build_dataset_for_inference"], ["", "def", "_build_batches", "(", "\n", "self", ",", "tokens", ":", "List", "[", "List", "[", "int", "]", "]", ",", "skip_invalid_size_inputs", ":", "bool", "\n", ")", "->", "Iterator", "[", "Dict", "[", "str", ",", "Any", "]", "]", ":", "\n", "        ", "lengths", "=", "torch", ".", "LongTensor", "(", "[", "t", ".", "numel", "(", ")", "for", "t", "in", "tokens", "]", ")", "\n", "batch_iterator", "=", "self", ".", "task", ".", "get_batch_iterator", "(", "\n", "dataset", "=", "self", ".", "task", ".", "build_dataset_for_inference", "(", "tokens", ",", "lengths", ")", ",", "\n", "max_tokens", "=", "self", ".", "cfg", ".", "dataset", ".", "max_tokens", ",", "\n", "max_sentences", "=", "self", ".", "cfg", ".", "dataset", ".", "batch_size", ",", "\n", "max_positions", "=", "self", ".", "max_positions", ",", "\n", "ignore_invalid_inputs", "=", "skip_invalid_size_inputs", ",", "\n", "disable_iterator_cache", "=", "True", ",", "\n", ")", ".", "next_epoch_itr", "(", "shuffle", "=", "False", ")", "\n", "return", "batch_iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.BPEHubInterface.__init__": [[270, 275], ["object.__init__", "argparse.Namespace", "fairseq.data.encoders.build_bpe"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.build_bpe"], ["def", "__init__", "(", "self", ",", "bpe", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "args", "=", "argparse", ".", "Namespace", "(", "bpe", "=", "bpe", ",", "**", "kwargs", ")", "\n", "self", ".", "bpe", "=", "encoders", ".", "build_bpe", "(", "args", ")", "\n", "assert", "self", ".", "bpe", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.BPEHubInterface.encode": [[276, 278], ["hub_utils.BPEHubInterface.bpe.encode"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "def", "encode", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "bpe", ".", "encode", "(", "sentence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.BPEHubInterface.decode": [[279, 281], ["hub_utils.BPEHubInterface.bpe.decode"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "decode", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "bpe", ".", "decode", "(", "sentence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.TokenizerHubInterface.__init__": [[286, 291], ["object.__init__", "argparse.Namespace", "fairseq.data.encoders.build_tokenizer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.build_tokenizer"], ["def", "__init__", "(", "self", ",", "tokenizer", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "args", "=", "argparse", ".", "Namespace", "(", "tokenizer", "=", "tokenizer", ",", "**", "kwargs", ")", "\n", "self", ".", "tokenizer", "=", "encoders", ".", "build_tokenizer", "(", "args", ")", "\n", "assert", "self", ".", "tokenizer", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.TokenizerHubInterface.encode": [[292, 294], ["hub_utils.TokenizerHubInterface.tokenizer.encode"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "def", "encode", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "encode", "(", "sentence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.TokenizerHubInterface.decode": [[295, 297], ["hub_utils.TokenizerHubInterface.tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "decode", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "decode", "(", "sentence", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.from_pretrained": [[23, 80], ["file_utils.load_archive_file", "data_name_or_path.startswith", "checkpoint_utils.load_model_ensemble_and_task", "isinstance", "os.path.abspath", "file_utils.load_archive_file", "os.path.join", "os.path.exists", "fairseq.utils.import_user_module", "model_name_or_path.items", "os.path.join", "argparse.Namespace", "os.path.join", "checkpoint_file.split"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.load_archive_file", "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_model_ensemble_and_task", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.load_archive_file", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.import_user_module"], ["def", "from_pretrained", "(", "\n", "model_name_or_path", ",", "\n", "checkpoint_file", "=", "\"model.pt\"", ",", "\n", "data_name_or_path", "=", "\".\"", ",", "\n", "archive_map", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "    ", "from", "fairseq", "import", "checkpoint_utils", ",", "file_utils", "\n", "\n", "if", "archive_map", "is", "not", "None", ":", "\n", "        ", "if", "model_name_or_path", "in", "archive_map", ":", "\n", "            ", "model_name_or_path", "=", "archive_map", "[", "model_name_or_path", "]", "\n", "", "if", "data_name_or_path", "is", "not", "None", "and", "data_name_or_path", "in", "archive_map", ":", "\n", "            ", "data_name_or_path", "=", "archive_map", "[", "data_name_or_path", "]", "\n", "\n", "# allow archive_map to set default arg_overrides (e.g., tokenizer, bpe)", "\n", "# for each model", "\n", "", "if", "isinstance", "(", "model_name_or_path", ",", "dict", ")", ":", "\n", "            ", "for", "k", ",", "v", "in", "model_name_or_path", ".", "items", "(", ")", ":", "\n", "                ", "if", "k", "==", "\"checkpoint_file\"", ":", "\n", "                    ", "checkpoint_file", "=", "v", "\n", "", "elif", "(", "\n", "k", "!=", "\"path\"", "\n", "# only set kwargs that don't already have overrides", "\n", "and", "k", "not", "in", "kwargs", "\n", ")", ":", "\n", "                    ", "kwargs", "[", "k", "]", "=", "v", "\n", "", "", "model_name_or_path", "=", "model_name_or_path", "[", "\"path\"", "]", "\n", "\n", "", "", "model_path", "=", "file_utils", ".", "load_archive_file", "(", "model_name_or_path", ")", "\n", "\n", "# convenience hack for loading data and BPE codes from model archive", "\n", "if", "data_name_or_path", ".", "startswith", "(", "\".\"", ")", ":", "\n", "        ", "kwargs", "[", "\"data\"", "]", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "model_path", ",", "data_name_or_path", ")", ")", "\n", "", "else", ":", "\n", "        ", "kwargs", "[", "\"data\"", "]", "=", "file_utils", ".", "load_archive_file", "(", "data_name_or_path", ")", "\n", "", "for", "file", ",", "arg", "in", "{", "\n", "\"code\"", ":", "\"bpe_codes\"", ",", "\n", "\"bpecodes\"", ":", "\"bpe_codes\"", ",", "\n", "\"sentencepiece.bpe.model\"", ":", "\"sentencepiece_model\"", ",", "\n", "}", ".", "items", "(", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "model_path", ",", "file", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "            ", "kwargs", "[", "arg", "]", "=", "path", "\n", "\n", "", "", "if", "\"user_dir\"", "in", "kwargs", ":", "\n", "        ", "utils", ".", "import_user_module", "(", "argparse", ".", "Namespace", "(", "user_dir", "=", "kwargs", "[", "\"user_dir\"", "]", ")", ")", "\n", "\n", "", "models", ",", "args", ",", "task", "=", "checkpoint_utils", ".", "load_model_ensemble_and_task", "(", "\n", "[", "os", ".", "path", ".", "join", "(", "model_path", ",", "cpt", ")", "for", "cpt", "in", "checkpoint_file", ".", "split", "(", "os", ".", "pathsep", ")", "]", ",", "\n", "arg_overrides", "=", "kwargs", ",", "\n", ")", "\n", "\n", "return", "{", "\n", "\"args\"", ":", "args", ",", "\n", "\"task\"", ":", "task", ",", "\n", "\"models\"", ":", "models", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_scorer.SequenceScorer.__init__": [[15, 32], ["tgt_dict.pad", "tgt_dict.eos", "symbols_to_strip_from_output.union"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["def", "__init__", "(", "\n", "self", ",", "\n", "tgt_dict", ",", "\n", "softmax_batch", "=", "None", ",", "\n", "compute_alignment", "=", "False", ",", "\n", "eos", "=", "None", ",", "\n", "symbols_to_strip_from_output", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "pad", "=", "tgt_dict", ".", "pad", "(", ")", "\n", "self", ".", "eos", "=", "tgt_dict", ".", "eos", "(", ")", "if", "eos", "is", "None", "else", "eos", "\n", "self", ".", "softmax_batch", "=", "softmax_batch", "or", "sys", ".", "maxsize", "\n", "assert", "self", ".", "softmax_batch", ">", "0", "\n", "self", ".", "compute_alignment", "=", "compute_alignment", "\n", "self", ".", "symbols_to_strip_from_output", "=", "(", "\n", "symbols_to_strip_from_output", ".", "union", "(", "{", "self", ".", "eos", "}", ")", "\n", "if", "symbols_to_strip_from_output", "is", "not", "None", "\n", "else", "{", "self", ".", "eos", "}", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_scorer.SequenceScorer.generate": [[34, 154], ["torch.no_grad", "avg_probs.size", "range", "curr_prob.new.gather", "model.eval", "model", "sequence_scorer.SequenceScorer.generate.batch_for_softmax"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate", "(", "self", ",", "models", ",", "sample", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Score a batch of translations.\"\"\"", "\n", "net_input", "=", "sample", "[", "\"net_input\"", "]", "\n", "\n", "def", "batch_for_softmax", "(", "dec_out", ",", "target", ")", ":", "\n", "# assumes decoder_out[0] is the only thing needed (may not be correct for future models!)", "\n", "            ", "first", ",", "rest", "=", "dec_out", "[", "0", "]", ",", "dec_out", "[", "1", ":", "]", "\n", "bsz", ",", "tsz", ",", "dim", "=", "first", ".", "shape", "\n", "if", "bsz", "*", "tsz", "<", "self", ".", "softmax_batch", ":", "\n", "                ", "yield", "dec_out", ",", "target", ",", "True", "\n", "", "else", ":", "\n", "                ", "flat", "=", "first", ".", "contiguous", "(", ")", ".", "view", "(", "1", ",", "-", "1", ",", "dim", ")", "\n", "flat_tgt", "=", "target", ".", "contiguous", "(", ")", ".", "view", "(", "flat", ".", "shape", "[", ":", "-", "1", "]", ")", "\n", "s", "=", "0", "\n", "while", "s", "<", "flat", ".", "size", "(", "1", ")", ":", "\n", "                    ", "e", "=", "s", "+", "self", ".", "softmax_batch", "\n", "yield", "(", "flat", "[", ":", ",", "s", ":", "e", "]", ",", ")", "+", "rest", ",", "flat_tgt", "[", ":", ",", "s", ":", "e", "]", ",", "False", "\n", "s", "=", "e", "\n", "\n", "", "", "", "def", "gather_target_probs", "(", "probs", ",", "target", ")", ":", "\n", "            ", "probs", "=", "probs", ".", "gather", "(", "\n", "dim", "=", "2", ",", "\n", "index", "=", "target", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", ")", "\n", "return", "probs", "\n", "\n", "", "orig_target", "=", "sample", "[", "\"target\"", "]", "\n", "\n", "# compute scores for each model in the ensemble", "\n", "avg_probs", "=", "None", "\n", "avg_attn", "=", "None", "\n", "for", "model", "in", "models", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "decoder_out", "=", "model", "(", "**", "net_input", ")", "\n", "attn", "=", "decoder_out", "[", "1", "]", "if", "len", "(", "decoder_out", ")", ">", "1", "else", "None", "\n", "if", "type", "(", "attn", ")", "is", "dict", ":", "\n", "                ", "attn", "=", "attn", ".", "get", "(", "\"attn\"", ",", "None", ")", "\n", "\n", "", "batched", "=", "batch_for_softmax", "(", "decoder_out", ",", "orig_target", ")", "\n", "probs", ",", "idx", "=", "None", ",", "0", "\n", "for", "bd", ",", "tgt", ",", "is_single", "in", "batched", ":", "\n", "                ", "sample", "[", "\"target\"", "]", "=", "tgt", "\n", "curr_prob", "=", "model", ".", "get_normalized_probs", "(", "\n", "bd", ",", "log_probs", "=", "len", "(", "models", ")", "==", "1", ",", "sample", "=", "sample", "\n", ")", ".", "data", "\n", "if", "is_single", ":", "\n", "                    ", "probs", "=", "gather_target_probs", "(", "curr_prob", ",", "orig_target", ")", "\n", "", "else", ":", "\n", "                    ", "if", "probs", "is", "None", ":", "\n", "                        ", "probs", "=", "curr_prob", ".", "new", "(", "orig_target", ".", "numel", "(", ")", ")", "\n", "", "step", "=", "curr_prob", ".", "size", "(", "0", ")", "*", "curr_prob", ".", "size", "(", "1", ")", "\n", "end", "=", "step", "+", "idx", "\n", "tgt_probs", "=", "gather_target_probs", "(", "\n", "curr_prob", ".", "view", "(", "tgt", ".", "shape", "+", "(", "curr_prob", ".", "size", "(", "-", "1", ")", ",", ")", ")", ",", "tgt", "\n", ")", "\n", "probs", "[", "idx", ":", "end", "]", "=", "tgt_probs", ".", "view", "(", "-", "1", ")", "\n", "idx", "=", "end", "\n", "", "sample", "[", "\"target\"", "]", "=", "orig_target", "\n", "\n", "", "probs", "=", "probs", ".", "view", "(", "sample", "[", "\"target\"", "]", ".", "shape", ")", "\n", "\n", "if", "avg_probs", "is", "None", ":", "\n", "                ", "avg_probs", "=", "probs", "\n", "", "else", ":", "\n", "                ", "avg_probs", ".", "add_", "(", "probs", ")", "\n", "", "if", "attn", "is", "not", "None", ":", "\n", "                ", "if", "torch", ".", "is_tensor", "(", "attn", ")", ":", "\n", "                    ", "attn", "=", "attn", ".", "data", "\n", "", "else", ":", "\n", "                    ", "attn", "=", "attn", "[", "0", "]", "\n", "", "if", "avg_attn", "is", "None", ":", "\n", "                    ", "avg_attn", "=", "attn", "\n", "", "else", ":", "\n", "                    ", "avg_attn", ".", "add_", "(", "attn", ")", "\n", "", "", "", "if", "len", "(", "models", ")", ">", "1", ":", "\n", "            ", "avg_probs", ".", "div_", "(", "len", "(", "models", ")", ")", "\n", "avg_probs", ".", "log_", "(", ")", "\n", "if", "avg_attn", "is", "not", "None", ":", "\n", "                ", "avg_attn", ".", "div_", "(", "len", "(", "models", ")", ")", "\n", "\n", "", "", "bsz", "=", "avg_probs", ".", "size", "(", "0", ")", "\n", "hypos", "=", "[", "]", "\n", "start_idxs", "=", "sample", "[", "\"start_indices\"", "]", "if", "\"start_indices\"", "in", "sample", "else", "[", "0", "]", "*", "bsz", "\n", "for", "i", "in", "range", "(", "bsz", ")", ":", "\n", "# remove padding from ref", "\n", "            ", "ref", "=", "(", "\n", "utils", ".", "strip_pad", "(", "sample", "[", "\"target\"", "]", "[", "i", ",", "start_idxs", "[", "i", "]", ":", "]", ",", "self", ".", "pad", ")", "\n", "if", "sample", "[", "\"target\"", "]", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "tgt_len", "=", "ref", ".", "numel", "(", ")", "\n", "avg_probs_i", "=", "avg_probs", "[", "i", "]", "[", "start_idxs", "[", "i", "]", ":", "start_idxs", "[", "i", "]", "+", "tgt_len", "]", "\n", "score_i", "=", "avg_probs_i", ".", "sum", "(", ")", "/", "tgt_len", "\n", "if", "avg_attn", "is", "not", "None", ":", "\n", "                ", "avg_attn_i", "=", "avg_attn", "[", "i", "]", "\n", "if", "self", ".", "compute_alignment", ":", "\n", "                    ", "alignment", "=", "utils", ".", "extract_hard_alignment", "(", "\n", "avg_attn_i", ",", "\n", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "[", "i", "]", ",", "\n", "sample", "[", "\"target\"", "]", "[", "i", "]", ",", "\n", "self", ".", "pad", ",", "\n", "self", ".", "eos", ",", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "alignment", "=", "None", "\n", "", "", "else", ":", "\n", "                ", "avg_attn_i", "=", "alignment", "=", "None", "\n", "", "hypos", ".", "append", "(", "\n", "[", "\n", "{", "\n", "\"tokens\"", ":", "ref", ",", "\n", "\"score\"", ":", "score_i", ",", "\n", "\"attention\"", ":", "avg_attn_i", ",", "\n", "\"alignment\"", ":", "alignment", ",", "\n", "\"positional_scores\"", ":", "avg_probs_i", ",", "\n", "}", "\n", "]", "\n", ")", "\n", "", "return", "hypos", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.tokenizer.tokenize_line": [[12, 16], ["SPACE_NORMALIZER.sub", "line.strip.strip", "line.strip.split"], "function", ["None"], ["def", "tokenize_line", "(", "line", ")", ":", "\n", "    ", "line", "=", "SPACE_NORMALIZER", ".", "sub", "(", "\" \"", ",", "line", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", "\n", "return", "line", ".", "split", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.load_archive_file": [[54, 96], ["file_utils.cached_path", "logger.info", "logger.info", "os.path.isdir", "tempfile.mkdtemp", "logger.info", "os.remove", "shutil.move", "shutil.rmtree", "logger.info", "tarfile.open", "os.path.commonprefix", "archive.extractall", "os.path.join", "os.path.splitext", "archive.getnames"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.cached_path", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["def", "load_archive_file", "(", "archive_file", ")", ":", "\n", "# redirect to the cache, if necessary", "\n", "    ", "try", ":", "\n", "        ", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ",", "cache_dir", "=", "None", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "        ", "logger", ".", "info", "(", "\n", "\"Archive name '{}' was not found in archive name list. \"", "\n", "\"We assumed '{}' was a path or URL but couldn't find any file \"", "\n", "\"associated to this path or URL.\"", ".", "format", "(", "\n", "archive_file", ",", "\n", "archive_file", ",", "\n", ")", "\n", ")", "\n", "return", "None", "\n", "\n", "", "if", "resolved_archive_file", "==", "archive_file", ":", "\n", "        ", "logger", ".", "info", "(", "\"loading archive file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\n", "\"loading archive file {} from cache at {}\"", ".", "format", "(", "\n", "archive_file", ",", "resolved_archive_file", "\n", ")", "\n", ")", "\n", "\n", "# Extract archive to temp dir and replace .tar.bz2 if necessary", "\n", "", "tempdir", "=", "None", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "resolved_archive_file", ")", ":", "\n", "        ", "tempdir", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "logger", ".", "info", "(", "\n", "\"extracting archive file {} to temp dir {}\"", ".", "format", "(", "\n", "resolved_archive_file", ",", "tempdir", "\n", ")", "\n", ")", "\n", "ext", "=", "os", ".", "path", ".", "splitext", "(", "archive_file", ")", "[", "1", "]", "[", "1", ":", "]", "\n", "with", "tarfile", ".", "open", "(", "resolved_archive_file", ",", "\"r:\"", "+", "ext", ")", "as", "archive", ":", "\n", "            ", "top_dir", "=", "os", ".", "path", ".", "commonprefix", "(", "archive", ".", "getnames", "(", ")", ")", "\n", "archive", ".", "extractall", "(", "tempdir", ")", "\n", "", "os", ".", "remove", "(", "resolved_archive_file", ")", "\n", "shutil", ".", "move", "(", "os", ".", "path", ".", "join", "(", "tempdir", ",", "top_dir", ")", ",", "resolved_archive_file", ")", "\n", "shutil", ".", "rmtree", "(", "tempdir", ")", "\n", "\n", "", "return", "resolved_archive_file", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.url_to_filename": [[98, 114], ["url.encode", "hashlib.sha256", "hashlib.sha256.hexdigest", "etag.encode", "hashlib.sha256", "hashlib.sha256.hexdigest"], "function", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "def", "url_to_filename", "(", "url", ",", "etag", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Convert `url` into a hashed filename in a repeatable way.\n    If `etag` is specified, append its hash to the URL's, delimited\n    by a period.\n    \"\"\"", "\n", "url_bytes", "=", "url", ".", "encode", "(", "\"utf-8\"", ")", "\n", "url_hash", "=", "sha256", "(", "url_bytes", ")", "\n", "filename", "=", "url_hash", ".", "hexdigest", "(", ")", "\n", "\n", "if", "etag", ":", "\n", "        ", "etag_bytes", "=", "etag", ".", "encode", "(", "\"utf-8\"", ")", "\n", "etag_hash", "=", "sha256", "(", "etag_bytes", ")", "\n", "filename", "+=", "\".\"", "+", "etag_hash", ".", "hexdigest", "(", ")", "\n", "\n", "", "return", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.filename_to_url": [[116, 140], ["isinstance", "os.path.join", "str", "os.path.exists", "EnvironmentError", "os.path.exists", "EnvironmentError", "io.open", "json.load"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load"], ["", "def", "filename_to_url", "(", "filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Return the url and etag (which may be ``None``) stored for `filename`.\n    Raise ``EnvironmentError`` if `filename` or its stored metadata do not exist.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_FAIRSEQ_CACHE", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "cache_path", ")", ")", "\n", "\n", "", "meta_path", "=", "cache_path", "+", "\".json\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "meta_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "meta_path", ")", ")", "\n", "\n", "", "with", "open", "(", "meta_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "meta_file", ":", "\n", "        ", "metadata", "=", "json", ".", "load", "(", "meta_file", ")", "\n", "", "url", "=", "metadata", "[", "\"url\"", "]", "\n", "etag", "=", "metadata", "[", "\"etag\"", "]", "\n", "\n", "return", "url", ",", "etag", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.cached_path": [[142, 171], ["isinstance", "isinstance", "urlparse", "str", "str", "file_utils.get_from_cache", "os.path.exists", "EnvironmentError", "ValueError"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.get_from_cache", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists"], ["", "def", "cached_path", "(", "url_or_filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given something that might be a URL (or might be a local path),\n    determine which. If it's a URL, download the file and cache it, and\n    return the path to the cached file. If it's already a local path,\n    make sure the file exists and then return the path.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_FAIRSEQ_CACHE", "\n", "", "if", "isinstance", "(", "url_or_filename", ",", "Path", ")", ":", "\n", "        ", "url_or_filename", "=", "str", "(", "url_or_filename", ")", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "parsed", "=", "urlparse", "(", "url_or_filename", ")", "\n", "\n", "if", "parsed", ".", "scheme", "in", "(", "\"http\"", ",", "\"https\"", ",", "\"s3\"", ")", ":", "\n", "# URL, so get it from the cache (downloading if necessary)", "\n", "        ", "return", "get_from_cache", "(", "url_or_filename", ",", "cache_dir", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "url_or_filename", ")", ":", "\n", "# File, and it exists.", "\n", "        ", "return", "url_or_filename", "\n", "", "elif", "parsed", ".", "scheme", "==", "\"\"", ":", "\n", "# File, but it doesn't exist.", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "", "else", ":", "\n", "# Something unknown", "\n", "        ", "raise", "ValueError", "(", "\n", "\"unable to parse {} as a URL or as a local path\"", ".", "format", "(", "url_or_filename", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.split_s3_path": [[174, 185], ["urlparse", "s3_path.startswith", "ValueError"], "function", ["None"], ["", "", "def", "split_s3_path", "(", "url", ")", ":", "\n", "    ", "\"\"\"Split a full s3 path into the bucket name and path.\"\"\"", "\n", "parsed", "=", "urlparse", "(", "url", ")", "\n", "if", "not", "parsed", ".", "netloc", "or", "not", "parsed", ".", "path", ":", "\n", "        ", "raise", "ValueError", "(", "\"bad s3 path {}\"", ".", "format", "(", "url", ")", ")", "\n", "", "bucket_name", "=", "parsed", ".", "netloc", "\n", "s3_path", "=", "parsed", ".", "path", "\n", "# Remove '/' at beginning of path.", "\n", "if", "s3_path", ".", "startswith", "(", "\"/\"", ")", ":", "\n", "        ", "s3_path", "=", "s3_path", "[", "1", ":", "]", "\n", "", "return", "bucket_name", ",", "s3_path", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.s3_request": [[187, 206], ["functools.wraps", "func", "int", "EnvironmentError"], "function", ["None"], ["", "def", "s3_request", "(", "func", ")", ":", "\n", "    ", "\"\"\"\n    Wrapper function for s3 requests in order to create more helpful error\n    messages.\n    \"\"\"", "\n", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "from", "botocore", ".", "exceptions", "import", "ClientError", "\n", "\n", "try", ":", "\n", "            ", "return", "func", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "ClientError", "as", "exc", ":", "\n", "            ", "if", "int", "(", "exc", ".", "response", "[", "\"Error\"", "]", "[", "\"Code\"", "]", ")", "==", "404", ":", "\n", "                ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "\n", "", "", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.s3_etag": [[208, 217], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Object"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_etag", "(", "url", ")", ":", "\n", "    ", "\"\"\"Check ETag on S3 object.\"\"\"", "\n", "import", "boto3", "\n", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_object", "=", "s3_resource", ".", "Object", "(", "bucket_name", ",", "s3_path", ")", "\n", "return", "s3_object", ".", "e_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.s3_get": [[219, 227], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Bucket().download_fileobj", "boto3.resource.Bucket"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_get", "(", "url", ",", "temp_file", ")", ":", "\n", "    ", "\"\"\"Pull a file directly from S3.\"\"\"", "\n", "import", "boto3", "\n", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_resource", ".", "Bucket", "(", "bucket_name", ")", ".", "download_fileobj", "(", "s3_path", ",", "temp_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.request_wrap_timeout": [[229, 245], ["enumerate", "RuntimeError", "func", "logger.warning"], "function", ["None"], ["", "def", "request_wrap_timeout", "(", "func", ",", "url", ")", ":", "\n", "    ", "import", "requests", "\n", "\n", "for", "attempt", ",", "timeout", "in", "enumerate", "(", "[", "10", ",", "20", ",", "40", ",", "60", ",", "60", "]", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "func", "(", "timeout", "=", "timeout", ")", "\n", "", "except", "requests", ".", "exceptions", ".", "Timeout", "as", "e", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Request for %s timed-out (attempt %d). Retrying with a timeout of %d secs\"", ",", "\n", "url", ",", "\n", "attempt", ",", "\n", "timeout", ",", "\n", "exc_info", "=", "e", ",", "\n", ")", "\n", "continue", "\n", "", "", "raise", "RuntimeError", "(", "f\"Unable to fetch file {url}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.http_get": [[247, 260], ["file_utils.request_wrap_timeout", "request_wrap_timeout.headers.get", "tqdm", "request_wrap_timeout.iter_content", "tqdm.close", "functools.partial", "int", "tqdm.update", "temp_file.write", "len"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.request_wrap_timeout", "home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.close", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update"], ["", "def", "http_get", "(", "url", ",", "temp_file", ")", ":", "\n", "    ", "import", "requests", "\n", "from", "tqdm", "import", "tqdm", "\n", "\n", "req", "=", "request_wrap_timeout", "(", "partial", "(", "requests", ".", "get", ",", "url", ",", "stream", "=", "True", ")", ",", "url", ")", "\n", "content_length", "=", "req", ".", "headers", ".", "get", "(", "\"Content-Length\"", ")", "\n", "total", "=", "int", "(", "content_length", ")", "if", "content_length", "is", "not", "None", "else", "None", "\n", "progress", "=", "tqdm", "(", "unit", "=", "\"B\"", ",", "total", "=", "total", ")", "\n", "for", "chunk", "in", "req", ".", "iter_content", "(", "chunk_size", "=", "1024", ")", ":", "\n", "        ", "if", "chunk", ":", "# filter out keep-alive new chunks", "\n", "            ", "progress", ".", "update", "(", "len", "(", "chunk", ")", ")", "\n", "temp_file", ".", "write", "(", "chunk", ")", "\n", "", "", "progress", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.get_from_cache": [[262, 336], ["isinstance", "url.startswith", "file_utils.url_to_filename", "os.path.join", "str", "os.path.exists", "os.makedirs", "file_utils.s3_etag", "fnmatch.filter", "list", "os.path.exists", "file_utils.request_wrap_timeout", "os.path.exists", "os.listdir", "filter", "os.path.join", "tempfile.NamedTemporaryFile", "logger.info", "url.startswith", "temp_file.flush", "temp_file.seek", "logger.info", "logger.info", "logger.info", "functools.partial", "request_wrap_timeout.headers.get", "file_utils.s3_get", "file_utils.http_get", "io.open", "shutil.copyfileobj", "io.open", "json.dumps", "meta_file.write", "s.endswith"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.url_to_filename", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.s3_etag", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.request_wrap_timeout", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.flush", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.s3_get", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.http_get", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["", "def", "get_from_cache", "(", "url", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given a URL, look for the corresponding dataset in the local cache.\n    If it's not there, download it. Then return the path to the cached file.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_FAIRSEQ_CACHE", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "cache_dir", ")", "\n", "\n", "# Get eTag to add to filename, if it exists.", "\n", "", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "        ", "etag", "=", "s3_etag", "(", "url", ")", "\n", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "requests", "\n", "\n", "response", "=", "request_wrap_timeout", "(", "\n", "partial", "(", "requests", ".", "head", ",", "url", ",", "allow_redirects", "=", "True", ")", ",", "url", "\n", ")", "\n", "if", "response", ".", "status_code", "!=", "200", ":", "\n", "                ", "etag", "=", "None", "\n", "", "else", ":", "\n", "                ", "etag", "=", "response", ".", "headers", ".", "get", "(", "\"ETag\"", ")", "\n", "", "", "except", "RuntimeError", ":", "\n", "            ", "etag", "=", "None", "\n", "\n", "", "", "filename", "=", "url_to_filename", "(", "url", ",", "etag", ")", "\n", "\n", "# get cache path to put the file", "\n", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "\n", "# If we don't have a connection (etag is None) and can't identify the file", "\n", "# try to get the last downloaded one", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", "and", "etag", "is", "None", ":", "\n", "        ", "matching_files", "=", "fnmatch", ".", "filter", "(", "os", ".", "listdir", "(", "cache_dir", ")", ",", "filename", "+", "\".*\"", ")", "\n", "matching_files", "=", "list", "(", "filter", "(", "lambda", "s", ":", "not", "s", ".", "endswith", "(", "\".json\"", ")", ",", "matching_files", ")", ")", "\n", "if", "matching_files", ":", "\n", "            ", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "matching_files", "[", "-", "1", "]", ")", "\n", "\n", "", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "# Download to temporary file, then copy to cache dir once finished.", "\n", "# Otherwise you get corrupt cache entries if the download gets interrupted.", "\n", "        ", "with", "tempfile", ".", "NamedTemporaryFile", "(", ")", "as", "temp_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"%s not found in cache, downloading to %s\"", ",", "url", ",", "temp_file", ".", "name", ")", "\n", "\n", "# GET file object", "\n", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "                ", "s3_get", "(", "url", ",", "temp_file", ")", "\n", "", "else", ":", "\n", "                ", "http_get", "(", "url", ",", "temp_file", ")", "\n", "\n", "# we are copying the file before closing it, so flush to avoid truncation", "\n", "", "temp_file", ".", "flush", "(", ")", "\n", "# shutil.copyfileobj() starts at the current position, so go to the start", "\n", "temp_file", ".", "seek", "(", "0", ")", "\n", "\n", "logger", ".", "info", "(", "\"copying %s to cache at %s\"", ",", "temp_file", ".", "name", ",", "cache_path", ")", "\n", "with", "open", "(", "cache_path", ",", "\"wb\"", ")", "as", "cache_file", ":", "\n", "                ", "shutil", ".", "copyfileobj", "(", "temp_file", ",", "cache_file", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"creating metadata file for %s\"", ",", "cache_path", ")", "\n", "meta", "=", "{", "\"url\"", ":", "url", ",", "\"etag\"", ":", "etag", "}", "\n", "meta_path", "=", "cache_path", "+", "\".json\"", "\n", "with", "open", "(", "meta_path", ",", "\"w\"", ")", "as", "meta_file", ":", "\n", "                ", "output_string", "=", "json", ".", "dumps", "(", "meta", ")", "\n", "meta_file", ".", "write", "(", "output_string", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"removing temp file %s\"", ",", "temp_file", ".", "name", ")", "\n", "\n", "", "", "return", "cache_path", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.read_set_from_file": [[338, 348], ["set", "io.open", "set.add", "line.rstrip"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add"], ["", "def", "read_set_from_file", "(", "filename", ")", ":", "\n", "    ", "\"\"\"\n    Extract a de-duped collection (set) of text from a file.\n    Expected file format is one item per line.\n    \"\"\"", "\n", "collection", "=", "set", "(", ")", "\n", "with", "open", "(", "filename", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "file_", ":", "\n", "        ", "for", "line", "in", "file_", ":", "\n", "            ", "collection", ".", "add", "(", "line", ".", "rstrip", "(", ")", ")", "\n", "", "", "return", "collection", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.get_file_extension": [[350, 354], ["os.path.splitext", "ext.lower"], "function", ["None"], ["", "def", "get_file_extension", "(", "path", ",", "dot", "=", "True", ",", "lower", "=", "True", ")", ":", "\n", "    ", "ext", "=", "os", ".", "path", ".", "splitext", "(", "path", ")", "[", "1", "]", "\n", "ext", "=", "ext", "if", "dot", "else", "ext", "[", "1", ":", "]", "\n", "return", "ext", ".", "lower", "(", ")", "if", "lower", "else", "ext", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.quantization_utils.Quantizer.__init__": [[24, 70], ["len", "fairseq.modules.quantization.quantization_options.parse_config_yaml", "ImportError", "open", "fairseq.modules.quantization.quantization_options.parse_config_yaml", "yaml.safe_load"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.quantization.quantization_options.parse_config_yaml", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.quantization.quantization_options.parse_config_yaml"], ["    ", "def", "__init__", "(", "self", ",", "config_path", ",", "max_epoch", ",", "max_update", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "yaml", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install yaml with: pip install yaml\"", ")", "\n", "\n", "# parse config", "\n", "", "if", "config_path", ":", "\n", "            ", "with", "open", "(", "config_path", ")", "as", "config_file", ":", "\n", "                ", "config", "=", "quantization_options", ".", "parse_config_yaml", "(", "\n", "yaml", ".", "safe_load", "(", "config_file", ")", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "config", "=", "quantization_options", ".", "parse_config_yaml", "(", "{", "}", ")", "\n", "\n", "", "self", ".", "n_centroids_config", "=", "config", "[", "\"n_centroids\"", "]", "\n", "self", ".", "block_sizes_config", "=", "config", "[", "\"block_sizes\"", "]", "\n", "self", ".", "layers_to_quantize", "=", "config", "[", "\"layers_to_quantize\"", "]", "\n", "\n", "# We assume that training will run for a fixed number of epochs", "\n", "# (or updates) and that we should train for equal durations", "\n", "# between iterations of PQ.", "\n", "num_iterations", "=", "len", "(", "self", ".", "layers_to_quantize", ")", "\n", "if", "max_epoch", ">", "0", ":", "\n", "            ", "assert", "max_epoch", "%", "num_iterations", "==", "0", ",", "(", "\n", "\"for iterative PQ, --max-epoch (={}) must be evenly divisible by \"", "\n", "\"len(layers_to_quantize) (={})\"", ".", "format", "(", "max_epoch", ",", "num_iterations", ")", "\n", ")", "\n", "self", ".", "epoch_schedule", "=", "max_epoch", "//", "num_iterations", "\n", "", "else", ":", "\n", "            ", "self", ".", "epoch_schedule", "=", "None", "\n", "", "if", "max_update", ">", "0", ":", "\n", "            ", "assert", "max_update", "%", "num_iterations", "==", "0", ",", "(", "\n", "\"for iterative PQ, --max-update (={}) must be evenly divisible by \"", "\n", "\"len(layers_to_quantize) (={})\"", ".", "format", "(", "max_update", ",", "num_iterations", ")", "\n", ")", "\n", "self", ".", "update_schedule", "=", "max_update", "//", "num_iterations", "\n", "", "else", ":", "\n", "            ", "self", ".", "update_schedule", "=", "None", "\n", "", "assert", "(", "self", ".", "epoch_schedule", "is", "not", "None", ")", "^", "(", "\n", "self", ".", "update_schedule", "is", "not", "None", "\n", ")", ",", "\"for iterative PQ, cannot specify both --max-update and --max-epoch\"", "\n", "\n", "# 0 is a special value for quantization step, which will force", "\n", "# the first call to begin_epoch() to call step()", "\n", "self", ".", "quantization_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.quantization_utils.Quantizer.set_trainer": [[71, 74], ["fairseq.modules.quantization.pq.SizeTracker", "quantization_utils.Quantizer.trainer.get_model"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_model"], ["", "def", "set_trainer", "(", "self", ",", "trainer", ")", ":", "\n", "        ", "self", ".", "trainer", "=", "trainer", "\n", "self", ".", "size_tracker", "=", "pq", ".", "SizeTracker", "(", "self", ".", "trainer", ".", "get_model", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.quantization_utils.Quantizer.step": [[75, 103], ["logger.info", "fairseq.modules.quantization.pq.quantize_model_", "logger.info", "logger.info", "quantization_utils.Quantizer.trainer.reinitialize", "len", "quantization_utils.Quantizer.trainer.get_model"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pq.utils.quantize_model_", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.reinitialize", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_model"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"\"\"Move to the next stage of quantization.\"\"\"", "\n", "if", "self", ".", "quantization_step", ">=", "len", "(", "self", ".", "layers_to_quantize", ")", ":", "\n", "# Maybe we just finished the last training step or we loaded", "\n", "# a checkpoint for an iterative PQ model which previously", "\n", "# finished training. Either way, don't quantize again.", "\n", "            ", "return", "\n", "\n", "", "logger", ".", "info", "(", "\n", "\"quantizing model (step={}; layers_to_quantize[step]={})\"", ".", "format", "(", "\n", "self", ".", "quantization_step", ",", "self", ".", "layers_to_quantize", "[", "self", ".", "quantization_step", "]", "\n", ")", "\n", ")", "\n", "quantized_layers", "=", "pq", ".", "quantize_model_", "(", "\n", "self", ".", "trainer", ".", "get_model", "(", ")", ",", "\n", "self", ".", "size_tracker", ",", "\n", "self", ".", "layers_to_quantize", ",", "\n", "self", ".", "block_sizes_config", ",", "\n", "self", ".", "n_centroids_config", ",", "\n", "step", "=", "self", ".", "quantization_step", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"quantized layers: {}\"", ".", "format", "(", "quantized_layers", ")", ")", "\n", "logger", ".", "info", "(", "self", ".", "size_tracker", ")", "\n", "\n", "self", ".", "quantization_step", "+=", "1", "\n", "\n", "# reintialize the Trainer since model parameters have changed", "\n", "self", ".", "trainer", ".", "reinitialize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.quantization_utils.Quantizer.begin_epoch": [[104, 117], ["quantization_utils.Quantizer.step"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step"], ["", "def", "begin_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Called at the beginning of each epoch (epochs start at 1).\"\"\"", "\n", "if", "(", "\n", "(", "\n", "self", ".", "epoch_schedule", "is", "not", "None", "\n", "and", "epoch", ">", "0", "\n", "and", "(", "epoch", "-", "1", ")", "%", "self", ".", "epoch_schedule", "==", "0", "\n", ")", "\n", "# we always step once in the beginning, even if using", "\n", "# update-based quantization", "\n", "or", "self", ".", "quantization_step", "==", "0", "\n", ")", ":", "\n", "            ", "self", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.quantization_utils.Quantizer.step_update": [[118, 126], ["quantization_utils.Quantizer.step"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step"], ["", "", "def", "step_update", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Called at the end of each step.\"\"\"", "\n", "if", "(", "\n", "self", ".", "update_schedule", "is", "not", "None", "\n", "and", "num_updates", ">", "0", "\n", "and", "num_updates", "%", "self", ".", "update_schedule", "==", "0", "\n", ")", ":", "\n", "            ", "self", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.quantization_utils.Quantizer.state_dict": [[127, 135], ["None"], "methods", ["None"], ["", "", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"n_centroids_config\"", ":", "self", ".", "n_centroids_config", ",", "\n", "\"block_sizes_config\"", ":", "self", ".", "block_sizes_config", ",", "\n", "\"layers_to_quantize\"", ":", "self", ".", "layers_to_quantize", ",", "\n", "\"epoch_schedule\"", ":", "self", ".", "epoch_schedule", ",", "\n", "\"update_schedule\"", ":", "self", ".", "update_schedule", ",", "\n", "\"quantization_step\"", ":", "self", ".", "quantization_step", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.quantization_utils.Quantizer.load_state_dict": [[137, 144], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "n_centroids_config", "=", "state_dict", "[", "\"n_centroids_config\"", "]", "\n", "self", ".", "block_sizes_config", "=", "state_dict", "[", "\"block_sizes_config\"", "]", "\n", "self", ".", "layers_to_quantize", "=", "state_dict", "[", "\"layers_to_quantize\"", "]", "\n", "self", ".", "epoch_schedule", "=", "state_dict", "[", "\"epoch_schedule\"", "]", "\n", "self", ".", "update_schedule", "=", "state_dict", "[", "\"update_schedule\"", "]", "\n", "self", ".", "quantization_step", "=", "state_dict", "[", "\"quantization_step\"", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.quantization_utils.quantize_model_scalar": [[15, 21], ["getattr", "fairseq.modules.quantization.scalar.quantize_model_"], "function", ["home.repos.pwc.inspect_result.reneeye_const.pq.utils.quantize_model_"], ["def", "quantize_model_scalar", "(", "model", ",", "model_cfg", ":", "DictConfig", ")", ":", "\n", "    ", "quant_noise_scalar", "=", "getattr", "(", "model_cfg", ",", "\"quant_noise_scalar\"", ",", "0", ")", "or", "0", "\n", "if", "quant_noise_scalar", ">", "0", ":", "\n", "# quantize_model edits the model in place", "\n", "        ", "scalar", ".", "quantize_model_", "(", "model", ",", "p", "=", "quant_noise_scalar", ",", "bits", "=", "8", ",", "update_step", "=", "1000", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.__init__": [[41, 132], ["isinstance", "trainer._catalog_shared_params", "set", "fairseq.logging.metrics.log_start_time", "time.time", "logger.warning", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "torch.cuda.is_available", "torch.device", "trainer.Trainer._criterion.half", "trainer.Trainer._model.half", "trainer.Trainer._criterion.to", "trainer.Trainer._model.to", "torch.device", "trainer._get_module_by_path", "torch.cuda.DoubleTensor", "trainer.Trainer.quantizer.set_trainer", "fairseq.utils.CudaEnvironment", "fairseq.utils.get_tpu_device", "torch.device", "trainer.Trainer._criterion.to", "trainer.Trainer._model.to", "logger.info", "trainer._set_module_by_path", "fairseq.distributed_utils.all_gather_list", "fairseq.utils.CudaEnvironment.pretty_print_cuda_env_list"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer._catalog_shared_params", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_start_time", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.device", "home.repos.pwc.inspect_result.reneeye_const.lightconv_layer.lightconv_layer.LightconvLayer.half", "home.repos.pwc.inspect_result.reneeye_const.lightconv_layer.lightconv_layer.LightconvLayer.half", "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.device", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer._get_module_by_path", "home.repos.pwc.inspect_result.reneeye_const.fairseq.quantization_utils.Quantizer.set_trainer", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_tpu_device", "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.device", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer._set_module_by_path", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.all_gather_list", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.CudaEnvironment.pretty_print_cuda_env_list"], ["def", "__init__", "(", "self", ",", "cfg", ":", "FairseqConfig", ",", "task", ",", "model", ",", "criterion", ",", "quantizer", "=", "None", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "cfg", ",", "Namespace", ")", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"argparse.Namespace configuration is deprecated! Automatically converting to OmegaConf\"", "\n", ")", "\n", "cfg", "=", "convert_namespace_to_omegaconf", "(", "cfg", ")", "\n", "\n", "", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "task", "=", "task", "\n", "\n", "# catalog shared parameters", "\n", "shared_params", "=", "_catalog_shared_params", "(", "model", ")", "\n", "self", ".", "tpu", "=", "cfg", ".", "common", ".", "tpu", "\n", "self", ".", "cuda", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "cfg", ".", "common", ".", "cpu", "and", "not", "self", ".", "tpu", "\n", "if", "self", ".", "cuda", ":", "\n", "            ", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "", "elif", "self", ".", "tpu", ":", "\n", "            ", "self", ".", "device", "=", "utils", ".", "get_tpu_device", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "# copy model and criterion to current device/dtype", "\n", "", "self", ".", "_criterion", "=", "criterion", "\n", "self", ".", "_model", "=", "model", "\n", "if", "cfg", ".", "common", ".", "fp16", ":", "\n", "            ", "self", ".", "_criterion", "=", "self", ".", "_criterion", ".", "half", "(", ")", "\n", "self", ".", "_model", "=", "self", ".", "_model", ".", "half", "(", ")", "\n", "", "elif", "cfg", ".", "common", ".", "bf16", ":", "\n", "            ", "self", ".", "_criterion", "=", "self", ".", "_criterion", ".", "to", "(", "dtype", "=", "torch", ".", "bfloat16", ")", "\n", "self", ".", "_model", "=", "self", ".", "_model", ".", "to", "(", "dtype", "=", "torch", ".", "bfloat16", ")", "\n", "", "if", "not", "cfg", ".", "distributed_training", ".", "pipeline_model_parallel", ":", "\n", "            ", "self", ".", "_criterion", "=", "self", ".", "_criterion", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "_model", "=", "self", ".", "_model", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "", "self", ".", "pipeline_model_parallel", "=", "cfg", ".", "distributed_training", ".", "pipeline_model_parallel", "\n", "self", ".", "last_device", "=", "None", "\n", "if", "self", ".", "cuda", "and", "self", ".", "pipeline_model_parallel", ":", "\n", "            ", "self", ".", "last_device", "=", "torch", ".", "device", "(", "\n", "cfg", ".", "distributed_training", ".", "pipeline_devices", "[", "-", "1", "]", "\n", ")", "\n", "\n", "# check that shared parameters are preserved after device transfer", "\n", "", "for", "shared_param", "in", "shared_params", ":", "\n", "            ", "ref", "=", "_get_module_by_path", "(", "self", ".", "_model", ",", "shared_param", "[", "0", "]", ")", "\n", "for", "path", "in", "shared_param", "[", "1", ":", "]", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"detected shared parameter: {} <- {}\"", ".", "format", "(", "shared_param", "[", "0", "]", ",", "path", ")", "\n", ")", "\n", "_set_module_by_path", "(", "self", ".", "_model", ",", "path", ",", "ref", ")", "\n", "\n", "", "", "self", ".", "_dummy_batch", "=", "None", "# indicates we don't have a dummy batch at first", "\n", "self", ".", "_lr_scheduler", "=", "None", "\n", "self", ".", "_num_updates", "=", "0", "\n", "self", ".", "_num_xla_compiles", "=", "0", "# for TPUs", "\n", "self", ".", "_optim_history", "=", "None", "\n", "self", ".", "_optimizer", "=", "None", "\n", "self", ".", "_warn_once", "=", "set", "(", ")", "\n", "self", ".", "_wrapped_criterion", "=", "None", "\n", "self", ".", "_wrapped_model", "=", "None", "\n", "\n", "# TODO(myleott): support tpu", "\n", "if", "self", ".", "cuda", "and", "self", ".", "data_parallel_world_size", ">", "1", ":", "\n", "            ", "self", ".", "_grad_norm_buf", "=", "torch", ".", "cuda", ".", "DoubleTensor", "(", "self", ".", "data_parallel_world_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_grad_norm_buf", "=", "None", "\n", "\n", "", "self", ".", "quantizer", "=", "quantizer", "\n", "if", "self", ".", "quantizer", "is", "not", "None", ":", "\n", "            ", "self", ".", "quantizer", ".", "set_trainer", "(", "self", ")", "\n", "\n", "# get detailed cuda environment", "\n", "", "if", "self", ".", "cuda", ":", "\n", "            ", "self", ".", "cuda_env", "=", "utils", ".", "CudaEnvironment", "(", ")", "\n", "if", "self", ".", "data_parallel_world_size", ">", "1", ":", "\n", "# self.cuda_env_arr = distributed_utils.all_gather_list(", "\n", "#     self.cuda_env, group=distributed_utils.get_global_group()", "\n", "# )", "\n", "                ", "self", ".", "cuda_env_arr", "=", "distributed_utils", ".", "all_gather_list", "(", "self", ".", "cuda_env", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "cuda_env_arr", "=", "[", "self", ".", "cuda_env", "]", "\n", "", "if", "self", ".", "data_parallel_rank", "==", "0", ":", "\n", "                ", "utils", ".", "CudaEnvironment", ".", "pretty_print_cuda_env_list", "(", "self", ".", "cuda_env_arr", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "cuda_env", "=", "None", "\n", "self", ".", "cuda_env_arr", "=", "None", "\n", "\n", "", "metrics", ".", "log_start_time", "(", "\"wall\"", ",", "priority", "=", "790", ",", "round", "=", "0", ")", "\n", "\n", "self", ".", "_start_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "_previous_training_time", "=", "0", "\n", "self", ".", "_cumulative_training_time", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.reinitialize": [[133, 139], ["None"], "methods", ["None"], ["", "def", "reinitialize", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reinitialize the Trainer, typically after model params change.\"\"\"", "\n", "self", ".", "_lr_scheduler", "=", "None", "\n", "self", ".", "_optimizer", "=", "None", "\n", "self", ".", "_wrapped_criterion", "=", "None", "\n", "self", ".", "_wrapped_model", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.data_parallel_world_size": [[140, 145], ["fairseq.distributed_utils.get_data_parallel_world_size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_data_parallel_world_size"], ["", "@", "property", "\n", "def", "data_parallel_world_size", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "cfg", ".", "distributed_training", ".", "distributed_world_size", "==", "1", ":", "\n", "            ", "return", "1", "\n", "", "return", "distributed_utils", ".", "get_data_parallel_world_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.data_parallel_process_group": [[146, 149], ["fairseq.distributed_utils.get_data_parallel_group"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_data_parallel_group"], ["", "@", "property", "\n", "def", "data_parallel_process_group", "(", "self", ")", ":", "\n", "        ", "return", "distributed_utils", ".", "get_data_parallel_group", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.data_parallel_rank": [[150, 155], ["fairseq.distributed_utils.get_data_parallel_rank"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_data_parallel_rank"], ["", "@", "property", "\n", "def", "data_parallel_rank", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "cfg", ".", "distributed_training", ".", "distributed_world_size", "==", "1", ":", "\n", "            ", "return", "0", "\n", "", "return", "distributed_utils", ".", "get_data_parallel_rank", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.is_data_parallel_master": [[156, 161], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "is_data_parallel_master", "(", "self", ")", ":", "\n", "# NOTE: this returns true for all model parallel replicas with data", "\n", "# parallel rank 0", "\n", "        ", "return", "self", ".", "data_parallel_rank", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.criterion": [[162, 178], ["fairseq.utils.has_parameters", "fairseq.models.DistributedFairseqModel"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.has_parameters", "home.repos.pwc.inspect_result.reneeye_const.models.distributed_fairseq_model.DistributedFairseqModel"], ["", "@", "property", "\n", "def", "criterion", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_wrapped_criterion", "is", "None", ":", "\n", "            ", "if", "(", "\n", "utils", ".", "has_parameters", "(", "self", ".", "_criterion", ")", "\n", "and", "self", ".", "data_parallel_world_size", ">", "1", "\n", "and", "not", "self", ".", "cfg", ".", "optimization", ".", "use_bmuf", "\n", ")", ":", "\n", "                ", "self", ".", "_wrapped_criterion", "=", "models", ".", "DistributedFairseqModel", "(", "\n", "self", ".", "cfg", ".", "distributed_training", ",", "\n", "self", ".", "_criterion", ",", "\n", "process_group", "=", "self", ".", "data_parallel_process_group", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_wrapped_criterion", "=", "self", ".", "_criterion", "\n", "", "", "return", "self", ".", "_wrapped_criterion", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model": [[179, 194], ["fairseq.models.DistributedFairseqModel"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.distributed_fairseq_model.DistributedFairseqModel"], ["", "@", "property", "\n", "def", "model", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_wrapped_model", "is", "None", ":", "\n", "            ", "if", "(", "\n", "self", ".", "data_parallel_world_size", ">", "1", "\n", "and", "not", "self", ".", "cfg", ".", "optimization", ".", "use_bmuf", "\n", ")", ":", "\n", "                ", "self", ".", "_wrapped_model", "=", "models", ".", "DistributedFairseqModel", "(", "\n", "self", ".", "cfg", ".", "distributed_training", ",", "\n", "self", ".", "_model", ",", "\n", "process_group", "=", "self", ".", "data_parallel_process_group", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_wrapped_model", "=", "self", ".", "_model", "\n", "", "", "return", "self", ".", "_wrapped_model", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.optimizer": [[195, 200], ["trainer.Trainer._build_optimizer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._build_optimizer"], ["", "@", "property", "\n", "def", "optimizer", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_optimizer", "is", "None", ":", "\n", "            ", "self", ".", "_build_optimizer", "(", ")", "\n", "", "return", "self", ".", "_optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.lr_scheduler": [[201, 206], ["trainer.Trainer._build_optimizer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._build_optimizer"], ["", "@", "property", "\n", "def", "lr_scheduler", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_lr_scheduler", "is", "None", ":", "\n", "            ", "self", ".", "_build_optimizer", "(", ")", "# this will initialize self._lr_scheduler", "\n", "", "return", "self", ".", "_lr_scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._build_optimizer": [[207, 261], ["list", "fairseq.optim.lr_scheduler.build_lr_scheduler", "trainer.Trainer._lr_scheduler.step_update", "filter", "fairseq.optim.build_optimizer", "fairseq.optim.FairseqBMUF", "itertools.chain", "logger.info", "fairseq.optim.MemoryEfficientFP16Optimizer.build_optimizer", "fairseq.optim.FP16Optimizer.build_optimizer", "logger.info", "ValueError", "fairseq.optim.shard_", "trainer.Trainer.model.parameters", "trainer.Trainer.criterion.parameters", "torch.cuda.get_device_capability", "torch.cuda.get_device_capability"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.__init__.build_lr_scheduler", "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step_update", "home.repos.pwc.inspect_result.reneeye_const.optim.__init__.build_optimizer", "home.repos.pwc.inspect_result.reneeye_const.optim.__init__.build_optimizer", "home.repos.pwc.inspect_result.reneeye_const.optim.__init__.build_optimizer", "home.repos.pwc.inspect_result.reneeye_const.optim.shard.shard_"], ["", "def", "_build_optimizer", "(", "self", ")", ":", "\n", "        ", "params", "=", "list", "(", "\n", "filter", "(", "\n", "lambda", "p", ":", "p", ".", "requires_grad", ",", "\n", "chain", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "criterion", ".", "parameters", "(", ")", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "if", "self", ".", "cfg", ".", "common", ".", "fp16", "or", "self", ".", "cfg", ".", "common", ".", "bf16", ":", "\n", "            ", "if", "self", ".", "cuda", "and", "torch", ".", "cuda", ".", "get_device_capability", "(", "0", ")", "[", "0", "]", "<", "7", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"NOTE: your device does NOT support faster training with --fp16, \"", "\n", "\"please switch to FP32 which is likely to be faster\"", "\n", ")", "\n", "", "if", "(", "\n", "self", ".", "cfg", ".", "common", ".", "memory_efficient_fp16", "\n", "or", "self", ".", "cfg", ".", "common", ".", "memory_efficient_bf16", "\n", ")", ":", "\n", "                ", "self", ".", "_optimizer", "=", "optim", ".", "MemoryEfficientFP16Optimizer", ".", "build_optimizer", "(", "\n", "self", ".", "cfg", ",", "params", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_optimizer", "=", "optim", ".", "FP16Optimizer", ".", "build_optimizer", "(", "self", ".", "cfg", ",", "params", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "cuda", "and", "torch", ".", "cuda", ".", "get_device_capability", "(", "0", ")", "[", "0", "]", ">=", "7", ":", "\n", "                ", "logger", ".", "info", "(", "\"NOTE: your device may support faster training with --fp16\"", ")", "\n", "", "self", ".", "_optimizer", "=", "optim", ".", "build_optimizer", "(", "self", ".", "cfg", ".", "optimizer", ",", "params", ")", "\n", "\n", "", "if", "self", ".", "cfg", ".", "optimization", ".", "use_bmuf", ":", "\n", "            ", "self", ".", "_optimizer", "=", "optim", ".", "FairseqBMUF", "(", "\n", "self", ".", "cfg", ".", "bmuf", ",", "\n", "self", ".", "_optimizer", ",", "\n", ")", "\n", "\n", "", "if", "self", ".", "cfg", ".", "distributed_training", ".", "zero_sharding", "==", "\"os\"", ":", "\n", "            ", "if", "(", "\n", "self", ".", "cfg", ".", "common", ".", "fp16", "\n", "and", "not", "self", ".", "cfg", ".", "common", ".", "memory_efficient_fp16", "\n", "and", "not", "self", ".", "cfg", ".", "common", ".", "memory_efficient_bf16", "\n", ")", "and", "not", "self", ".", "cfg", ".", "common", ".", "fp16_no_flatten_grads", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"ZeRO is incomptabile with fp16 and flattened grads. \"", "\n", "\"Please use --fp16-no-flatten-grads\"", "\n", ")", "\n", "", "else", ":", "\n", "                ", "optim", ".", "shard_", "(", "self", ".", "_optimizer", ",", "self", ".", "data_parallel_process_group", ")", "\n", "\n", "# We should initialize the learning rate scheduler immediately after", "\n", "# building the optimizer, so that the initial learning rate is set.", "\n", "", "", "self", ".", "_lr_scheduler", "=", "lr_scheduler", ".", "build_lr_scheduler", "(", "\n", "self", ".", "cfg", ".", "lr_scheduler", ",", "\n", "self", ".", "optimizer", ",", "\n", ")", "\n", "self", ".", "_lr_scheduler", ".", "step_update", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.consolidate_optimizer": [[262, 266], ["hasattr", "trainer.Trainer.optimizer.optimizer.consolidate_state_dict"], "methods", ["None"], ["", "def", "consolidate_optimizer", "(", "self", ")", ":", "\n", "        ", "\"\"\"For OSS, we need to consolidate the state dict.\"\"\"", "\n", "if", "hasattr", "(", "self", ".", "optimizer", ".", "optimizer", ",", "\"consolidate_state_dict\"", ")", ":", "\n", "            ", "self", ".", "optimizer", ".", "optimizer", ".", "consolidate_state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.save_checkpoint": [[267, 282], ["fairseq.logging.metrics.state_dict", "trainer.Trainer.cumulative_training_time", "fairseq.checkpoint_utils.save_state", "trainer.Trainer.get_model().state_dict", "trainer.Trainer.get_criterion", "trainer.Trainer.get_num_updates", "trainer.Trainer.get_model"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.state_dict", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.cumulative_training_time", "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.save_state", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.state_dict", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_criterion", "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_model"], ["", "", "def", "save_checkpoint", "(", "self", ",", "filename", ",", "extra_state", ")", ":", "\n", "        ", "\"\"\"Save all training state in a checkpoint file.\"\"\"", "\n", "if", "self", ".", "is_data_parallel_master", ":", "# only save one checkpoint", "\n", "            ", "extra_state", "[", "\"metrics\"", "]", "=", "metrics", ".", "state_dict", "(", ")", "\n", "extra_state", "[", "\"previous_training_time\"", "]", "=", "self", ".", "cumulative_training_time", "(", ")", "\n", "checkpoint_utils", ".", "save_state", "(", "\n", "filename", ",", "\n", "self", ".", "cfg", ",", "\n", "self", ".", "get_model", "(", ")", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "get_criterion", "(", ")", ",", "\n", "self", ".", "optimizer", ",", "\n", "self", ".", "lr_scheduler", ",", "\n", "self", ".", "get_num_updates", "(", ")", ",", "\n", "self", ".", "_optim_history", ",", "\n", "extra_state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.load_checkpoint": [[284, 414], ["fairseq.file_io.PathManager.isfile", "fairseq.checkpoint_utils.load_checkpoint_to_cpu", "fairseq.checkpoint_utils.load_checkpoint_to_cpu.get", "trainer.Trainer._build_optimizer", "trainer.Trainer.optimizer.load_state_dict", "trainer.Trainer.set_num_updates", "logger.info", "trainer.Trainer.lr_step", "logger.info", "trainer.Trainer.get_model().load_state_dict", "fairseq.utils.has_parameters", "trainer.Trainer.lr_scheduler.load_state_dict", "time.time", "fairseq.logging.metrics.load_state_dict", "fairseq.logging.metrics.get_meters", "trainer.Trainer.get_criterion", "trainer.Trainer.get_criterion().load_state_dict", "trainer.Trainer.get_model().load_state_dict", "logger.info", "logger.info", "fairseq.utils.has_parameters", "Exception", "trainer.Trainer.get_num_updates", "isinstance", "trainer.Trainer.get_model", "trainer.Trainer.get_criterion", "trainer.Trainer.get_criterion().load_state_dict", "trainer.Trainer.get_criterion", "meter.reset", "trainer.Trainer.get_criterion", "trainer.Trainer.get_model", "trainer.Trainer.get_criterion"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.isfile", "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_checkpoint_to_cpu", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._build_optimizer", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.Wav2VecEncoder.set_num_updates", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.lr_step", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.has_parameters", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.get_meters", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_criterion", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.has_parameters", "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_model", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_criterion", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_criterion", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.reset", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_criterion", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_model", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_criterion"], ["", "", "def", "load_checkpoint", "(", "\n", "self", ",", "\n", "filename", ",", "\n", "reset_optimizer", "=", "False", ",", "\n", "reset_lr_scheduler", "=", "False", ",", "\n", "optimizer_overrides", "=", "None", ",", "\n", "reset_meters", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Load all training state from a checkpoint file.\n        rank = 0 will load the checkpoint, and then broadcast it to all\n        other ranks.\n        \"\"\"", "\n", "extra_state", ",", "self", ".", "_optim_history", ",", "last_optim_state", "=", "None", ",", "[", "]", ",", "None", "\n", "\n", "bexists", "=", "PathManager", ".", "isfile", "(", "filename", ")", "\n", "if", "bexists", ":", "\n", "# if (", "\n", "#     self.data_parallel_rank == 0", "\n", "#     # TPUs don't support broadcast yet, so load checkpoints", "\n", "#     # on every worker for now", "\n", "#     or self.tpu", "\n", "# ):", "\n", "#     state = checkpoint_utils.load_checkpoint_to_cpu(filename)", "\n", "#     last_optim_state = state.get(\"last_optimizer_state\", None)", "\n", "#", "\n", "#     # If doing zero_sharding, do not broadcast global optimizer", "\n", "#     # state. Later we will broadcast sharded states to each rank", "\n", "#     # to avoid memory from exploding.", "\n", "#     if (", "\n", "#         self.cfg.distributed_training.zero_sharding == \"os\"", "\n", "#         and \"last_optimizer_state\" in state", "\n", "#         and self.data_parallel_world_size > 1", "\n", "#     ):", "\n", "#         state[\"last_optimizer_state\"] = \"SHARDED\"", "\n", "# else:", "\n", "#     last_optim_state = None", "\n", "#     state = None", "\n", "#", "\n", "# if (", "\n", "#     self.data_parallel_world_size > 1", "\n", "#     # disable on TPUs until they support broadcast", "\n", "#     and not self.tpu", "\n", "# ):", "\n", "#     state = distributed_utils.broadcast_object(", "\n", "#         state,", "\n", "#         src_rank=0,", "\n", "#         group=self.data_parallel_process_group,", "\n", "#         dist_device=self.device,", "\n", "#     )", "\n", "#     if self.data_parallel_rank > 0:", "\n", "#         last_optim_state = state.get(\"last_optimizer_state\", None)", "\n", "            ", "state", "=", "checkpoint_utils", ".", "load_checkpoint_to_cpu", "(", "filename", ")", "\n", "# load model parameters", "\n", "try", ":", "\n", "                ", "self", ".", "get_model", "(", ")", ".", "load_state_dict", "(", "\n", "state", "[", "\"model\"", "]", ",", "strict", "=", "True", ",", "model_cfg", "=", "self", ".", "cfg", ".", "model", "\n", ")", "\n", "if", "utils", ".", "has_parameters", "(", "self", ".", "get_criterion", "(", ")", ")", ":", "\n", "                    ", "self", ".", "get_criterion", "(", ")", ".", "load_state_dict", "(", "\n", "state", "[", "\"criterion\"", "]", ",", "strict", "=", "True", "\n", ")", "\n", "", "", "except", "Exception", ":", "\n", "                ", "missing_unexpected_keys", "=", "self", ".", "get_model", "(", ")", ".", "load_state_dict", "(", "\n", "state", "[", "\"model\"", "]", ",", "strict", "=", "False", ",", "model_cfg", "=", "self", ".", "cfg", ".", "model", "\n", ")", "\n", "logger", ".", "info", "(", "f\"missing keys: [{', '.join(missing_unexpected_keys.missing_keys)}]\"", ")", "\n", "logger", ".", "info", "(", "f\"unexpected keys: [{', '.join(missing_unexpected_keys.unexpected_keys)}]\"", ")", "\n", "if", "utils", ".", "has_parameters", "(", "self", ".", "get_criterion", "(", ")", ")", ":", "\n", "                    ", "self", ".", "get_criterion", "(", ")", ".", "load_state_dict", "(", "\n", "state", "[", "\"criterion\"", "]", ",", "strict", "=", "True", "\n", ")", "\n", "", "", "except", ":", "\n", "                ", "raise", "Exception", "(", "\n", "\"Cannot load model parameters from checkpoint {}; \"", "\n", "\"please ensure that the architectures match.\"", ".", "format", "(", "filename", ")", "\n", ")", "\n", "", "extra_state", "=", "state", "[", "\"extra_state\"", "]", "\n", "self", ".", "_optim_history", "=", "state", "[", "\"optimizer_history\"", "]", "\n", "last_optim_state", "=", "state", ".", "get", "(", "\"last_optimizer_state\"", ",", "None", ")", "\n", "\n", "", "if", "last_optim_state", "is", "not", "None", "and", "not", "reset_optimizer", ":", "\n", "# rebuild optimizer after loading model, since params may have changed", "\n", "            ", "self", ".", "_build_optimizer", "(", ")", "\n", "\n", "# only reload optimizer and lr_scheduler if they match", "\n", "last_optim", "=", "self", ".", "_optim_history", "[", "-", "1", "]", "\n", "assert", "(", "\n", "last_optim", "[", "\"criterion_name\"", "]", "==", "self", ".", "get_criterion", "(", ")", ".", "__class__", ".", "__name__", "\n", ")", ",", "\"Criterion does not match; please reset the optimizer (--reset-optimizer).\"", "\n", "assert", "(", "\n", "last_optim", "[", "\"optimizer_name\"", "]", "==", "self", ".", "optimizer", ".", "__class__", ".", "__name__", "\n", ")", ",", "\"Optimizer does not match; please reset the optimizer (--reset-optimizer).\"", "\n", "\n", "if", "not", "reset_lr_scheduler", ":", "\n", "                ", "self", ".", "lr_scheduler", ".", "load_state_dict", "(", "last_optim", "[", "\"lr_scheduler_state\"", "]", ")", "\n", "#", "\n", "# if self.data_parallel_world_size > 1:", "\n", "#     last_optim_state = self.optimizer.broadcast_global_state_dict(", "\n", "#         last_optim_state", "\n", "#     )", "\n", "", "self", ".", "optimizer", ".", "load_state_dict", "(", "last_optim_state", ",", "optimizer_overrides", ")", "\n", "\n", "self", ".", "set_num_updates", "(", "last_optim", "[", "\"num_updates\"", "]", ")", "\n", "\n", "", "if", "extra_state", "is", "not", "None", ":", "\n", "            ", "epoch", "=", "extra_state", "[", "\"train_iterator\"", "]", "[", "\"epoch\"", "]", "\n", "logger", ".", "info", "(", "\n", "\"loaded checkpoint {} (epoch {} @ {} updates)\"", ".", "format", "(", "\n", "filename", ",", "epoch", ",", "self", ".", "get_num_updates", "(", ")", "\n", ")", "\n", ")", "\n", "\n", "if", "\"previous_training_time\"", "in", "extra_state", ":", "\n", "                ", "self", ".", "_previous_training_time", "=", "extra_state", "[", "\"previous_training_time\"", "]", "\n", "self", ".", "_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "self", ".", "lr_step", "(", "epoch", ")", "\n", "\n", "if", "\"metrics\"", "in", "extra_state", "and", "not", "reset_meters", ":", "\n", "                ", "metrics", ".", "load_state_dict", "(", "extra_state", "[", "\"metrics\"", "]", ")", "\n", "\n", "# reset TimeMeters, since their start times don't make sense anymore", "\n", "for", "meter", "in", "metrics", ".", "get_meters", "(", "\"default\"", ")", ":", "\n", "                    ", "if", "isinstance", "(", "meter", ",", "meters", ".", "TimeMeter", ")", ":", "\n", "                        ", "meter", ".", "reset", "(", ")", "\n", "", "", "", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"no existing checkpoint found {}\"", ".", "format", "(", "filename", ")", ")", "\n", "\n", "", "return", "extra_state", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_train_iterator": [[415, 455], ["trainer.Trainer.task.get_batch_iterator", "trainer.Trainer.reset_dummy_batch", "logger.info", "trainer.Trainer.task.load_dataset", "trainer.Trainer.task.dataset", "fairseq.utils.resolve_max_positions", "trainer.Trainer.task.max_positions", "trainer.Trainer.model.max_positions"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.get_batch_iterator", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.reset_dummy_batch", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyMTTask.load_dataset", "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.dataset", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.resolve_max_positions", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions"], ["", "def", "get_train_iterator", "(", "\n", "self", ",", "\n", "epoch", ",", "\n", "combine", "=", "True", ",", "\n", "load_dataset", "=", "True", ",", "\n", "data_selector", "=", "None", ",", "\n", "shard_batch_itr", "=", "True", ",", "\n", "disable_iterator_cache", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Return an EpochBatchIterator over the training set for a given epoch.\"\"\"", "\n", "if", "load_dataset", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading train data for epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "self", ".", "task", ".", "load_dataset", "(", "\n", "self", ".", "cfg", ".", "dataset", ".", "train_subset", ",", "\n", "epoch", "=", "epoch", ",", "\n", "combine", "=", "combine", ",", "\n", "data_selector", "=", "data_selector", ",", "\n", ")", "\n", "", "batch_iterator", "=", "self", ".", "task", ".", "get_batch_iterator", "(", "\n", "dataset", "=", "self", ".", "task", ".", "dataset", "(", "self", ".", "cfg", ".", "dataset", ".", "train_subset", ")", ",", "\n", "max_tokens", "=", "self", ".", "cfg", ".", "dataset", ".", "max_tokens", ",", "\n", "max_sentences", "=", "self", ".", "cfg", ".", "dataset", ".", "batch_size", ",", "\n", "max_positions", "=", "utils", ".", "resolve_max_positions", "(", "\n", "self", ".", "task", ".", "max_positions", "(", ")", ",", "\n", "self", ".", "model", ".", "max_positions", "(", ")", ",", "\n", "self", ".", "cfg", ".", "dataset", ".", "max_tokens", ",", "\n", ")", ",", "\n", "# keep_num_indices=self.cfg.dataset.keep_num_indices,", "\n", "ignore_invalid_inputs", "=", "True", ",", "\n", "required_batch_size_multiple", "=", "self", ".", "cfg", ".", "dataset", ".", "required_batch_size_multiple", ",", "\n", "seed", "=", "self", ".", "cfg", ".", "common", ".", "seed", ",", "\n", "num_shards", "=", "self", ".", "data_parallel_world_size", "if", "shard_batch_itr", "else", "1", ",", "\n", "shard_id", "=", "self", ".", "data_parallel_rank", "if", "shard_batch_itr", "else", "0", ",", "\n", "num_workers", "=", "self", ".", "cfg", ".", "dataset", ".", "num_workers", ",", "\n", "epoch", "=", "epoch", ",", "\n", "data_buffer_size", "=", "self", ".", "cfg", ".", "dataset", ".", "data_buffer_size", ",", "\n", "disable_iterator_cache", "=", "disable_iterator_cache", ",", "\n", ")", "\n", "self", ".", "reset_dummy_batch", "(", "batch_iterator", ".", "first_batch", ")", "\n", "return", "batch_iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_valid_iterator": [[456, 481], ["trainer.Trainer.task.get_batch_iterator", "trainer.Trainer.reset_dummy_batch", "trainer.Trainer.task.dataset", "fairseq.utils.resolve_max_positions", "trainer.Trainer.task.max_positions", "trainer.Trainer.model.max_positions"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.get_batch_iterator", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.reset_dummy_batch", "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.dataset", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.resolve_max_positions", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions"], ["", "def", "get_valid_iterator", "(", "\n", "self", ",", "\n", "subset", ",", "\n", "disable_iterator_cache", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Return an EpochBatchIterator over given validation subset for a given epoch.\"\"\"", "\n", "batch_iterator", "=", "self", ".", "task", ".", "get_batch_iterator", "(", "\n", "dataset", "=", "self", ".", "task", ".", "dataset", "(", "subset", ")", ",", "\n", "max_tokens", "=", "self", ".", "cfg", ".", "dataset", ".", "max_tokens_valid", ",", "\n", "max_sentences", "=", "self", ".", "cfg", ".", "dataset", ".", "batch_size_valid", ",", "\n", "max_positions", "=", "utils", ".", "resolve_max_positions", "(", "\n", "self", ".", "task", ".", "max_positions", "(", ")", ",", "\n", "self", ".", "model", ".", "max_positions", "(", ")", ",", "\n", ")", ",", "\n", "ignore_invalid_inputs", "=", "self", ".", "cfg", ".", "dataset", ".", "skip_invalid_size_inputs_valid_test", ",", "\n", "required_batch_size_multiple", "=", "self", ".", "cfg", ".", "dataset", ".", "required_batch_size_multiple", ",", "\n", "seed", "=", "self", ".", "cfg", ".", "common", ".", "seed", ",", "\n", "num_shards", "=", "self", ".", "data_parallel_world_size", ",", "\n", "shard_id", "=", "self", ".", "data_parallel_rank", ",", "\n", "num_workers", "=", "self", ".", "cfg", ".", "dataset", ".", "num_workers", ",", "\n", "data_buffer_size", "=", "self", ".", "cfg", ".", "dataset", ".", "data_buffer_size", ",", "\n", "disable_iterator_cache", "=", "disable_iterator_cache", ",", "\n", ")", "\n", "self", ".", "reset_dummy_batch", "(", "batch_iterator", ".", "first_batch", ")", "\n", "return", "batch_iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.begin_epoch": [[482, 499], ["logger.info", "trainer.Trainer.task.begin_epoch", "trainer.Trainer.quantizer.begin_epoch", "trainer.Trainer.get_model", "xm.rendezvous", "xm.mark_step"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.begin_epoch", "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.begin_epoch", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_model"], ["", "def", "begin_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Called at the beginning of each epoch.\"\"\"", "\n", "logger", ".", "info", "(", "\"begin training epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "\n", "# self.lr_step_begin_epoch(epoch)", "\n", "\n", "if", "self", ".", "quantizer", "is", "not", "None", ":", "\n", "            ", "self", ".", "quantizer", ".", "begin_epoch", "(", "epoch", ")", "\n", "\n", "# task specific setup per epoch", "\n", "", "self", ".", "task", ".", "begin_epoch", "(", "epoch", ",", "self", ".", "get_model", "(", ")", ")", "\n", "\n", "if", "self", ".", "tpu", ":", "\n", "            ", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "\n", "\n", "xm", ".", "rendezvous", "(", "\"begin_epoch\"", ")", "# wait for all workers", "\n", "xm", ".", "mark_step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.begin_valid_epoch": [[500, 505], ["trainer.Trainer.task.begin_valid_epoch", "trainer.Trainer.get_model"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.begin_valid_epoch", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_model"], ["", "", "def", "begin_valid_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Called at the beginning of each validation epoch.\"\"\"", "\n", "\n", "# task specific setup per validation epoch", "\n", "self", ".", "task", ".", "begin_valid_epoch", "(", "epoch", ",", "self", ".", "get_model", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.reset_dummy_batch": [[506, 508], ["None"], "methods", ["None"], ["", "def", "reset_dummy_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "self", ".", "_dummy_batch", "=", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.train_step": [[509, 812], ["fairseq.logging.metrics.aggregate", "trainer.Trainer._set_seed", "trainer.Trainer.model.train", "trainer.Trainer.criterion.train", "trainer.Trainer.zero_grad", "fairseq.logging.metrics.log_start_time", "enumerate", "torch.is_tensor", "trainer.Trainer._sync_stats", "hasattr", "hasattr", "fairseq.logging.metrics.log_stop_time", "trainer.Trainer._prepare_sample", "torch.is_tensor", "float.float", "float", "trainer.Trainer._local_cumulative_training_time", "trainer.Trainer._aggregate_logging_outputs", "trainer.Trainer.model.all_reduce", "hasattr", "trainer.Trainer.set_num_updates", "fairseq.logging.metrics.log_scalar", "trainer.Trainer._prepare_sample", "logging_outputs.append", "xm.mark_step", "float.zero_", "fairseq.distributed_utils.all_reduce_dict", "xm._fetch_gradients", "xm.all_reduce", "torch.autograd.profiler.record_function", "trainer.Trainer.optimizer.all_reduce_grads", "fairseq.utils.has_parameters", "torch.autograd.profiler.record_function", "torch.autograd.profiler.record_function", "trainer.Trainer.clip_grad_norm", "trainer.Trainer._check_grad_norms", "torch.autograd.profiler.record_function", "trainer.Trainer.optimizer.step", "logger.info", "torch.tensor().cuda", "trainer.Trainer.zero_grad", "trainer.Trainer.model.perform_additional_optimizer_actions", "trainer.Trainer.model.perform_additional_optimizer_actions", "xm.mark_step", "trainer.Trainer._check_xla_compilation", "trainer.Trainer._reduce_and_log_stats", "hasattr", "trainer.Trainer.model.no_sync", "contextlib.ExitStack", "hasattr", "trainer.Trainer.model.no_sync_recover", "trainer.Trainer.train_step.maybe_no_sync"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.aggregate", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._set_seed", "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.train", "home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.train", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_start_time", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._sync_stats", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_stop_time", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._prepare_sample", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._local_cumulative_training_time", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._aggregate_logging_outputs", "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.Wav2VecEncoder.set_num_updates", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._prepare_sample", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.all_reduce_dict", "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce", "home.repos.pwc.inspect_result.reneeye_const.models.distributed_fairseq_model.TPUDistributedDataParallel.all_reduce_grads", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.has_parameters", "home.repos.pwc.inspect_result.reneeye_const.model_parallel.megatron_trainer.MegatronTrainer.clip_grad_norm", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._check_grad_norms", "home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.cuda", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._check_xla_compilation", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._reduce_and_log_stats", "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.no_sync", "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.no_sync_recover"], ["", "@", "metrics", ".", "aggregate", "(", "\"train\"", ")", "\n", "def", "train_step", "(", "self", ",", "samples", ",", "raise_oom", "=", "False", ")", ":", "\n", "        ", "\"\"\"Do forward, backward and parameter update.\"\"\"", "\n", "self", ".", "_set_seed", "(", ")", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "self", ".", "criterion", ".", "train", "(", ")", "\n", "self", ".", "zero_grad", "(", ")", "\n", "distributed_cuda_oom", "=", "False", "\n", "\n", "metrics", ".", "log_start_time", "(", "\"train_wall\"", ",", "priority", "=", "800", ",", "round", "=", "0", ")", "\n", "\n", "# forward and backward pass", "\n", "logging_outputs", ",", "sample_size", ",", "ooms", "=", "[", "]", ",", "0", ",", "0", "\n", "for", "i", ",", "sample", "in", "enumerate", "(", "samples", ")", ":", "\n", "            ", "sample", "=", "self", ".", "_prepare_sample", "(", "sample", ")", "\n", "if", "sample", "is", "None", ":", "\n", "# when sample is None, run forward/backward on a dummy batch", "\n", "# and ignore the resulting gradients", "\n", "                ", "sample", "=", "self", ".", "_prepare_sample", "(", "self", ".", "_dummy_batch", ")", "\n", "is_dummy_batch", "=", "True", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "_dummy_batch", "==", "\"DUMMY\"", ":", "\n", "                    ", "self", ".", "_dummy_batch", "=", "sample", "\n", "", "is_dummy_batch", "=", "False", "\n", "\n", "", "def", "maybe_no_sync", "(", ")", ":", "\n", "                ", "\"\"\"\n                Whenever *samples* contains more than one mini-batch, we\n                want to accumulate gradients locally and only call\n                all-reduce in the last backwards pass.\n                \"\"\"", "\n", "if", "(", "\n", "self", ".", "data_parallel_world_size", ">", "1", "\n", "and", "hasattr", "(", "self", ".", "model", ",", "\"no_sync\"", ")", "\n", "and", "i", "<", "len", "(", "samples", ")", "-", "1", "\n", ")", ":", "\n", "                    ", "return", "self", ".", "model", ".", "no_sync", "(", ")", "\n", "", "else", ":", "\n", "                    ", "return", "contextlib", ".", "ExitStack", "(", ")", "# dummy contextmanager", "\n", "\n", "", "", "def", "maybe_no_sync_recover", "(", ")", ":", "\n", "                ", "if", "(", "\n", "self", ".", "data_parallel_world_size", ">", "1", "\n", "and", "hasattr", "(", "self", ".", "model", ",", "\"no_sync\"", ")", "\n", "and", "i", "<", "len", "(", "samples", ")", "-", "1", "\n", ")", ":", "\n", "                    ", "self", ".", "model", ".", "no_sync_recover", "(", ")", "\n", "\n", "", "", "try", ":", "\n", "                ", "with", "maybe_no_sync", "(", ")", ":", "\n", "# forward and backward", "\n", "                    ", "loss", ",", "sample_size_i", ",", "logging_output", "=", "self", ".", "task", ".", "train_step", "(", "\n", "sample", "=", "sample", ",", "\n", "model", "=", "self", ".", "model", ",", "\n", "criterion", "=", "self", ".", "criterion", ",", "\n", "optimizer", "=", "self", ".", "optimizer", ",", "\n", "update_num", "=", "self", ".", "get_num_updates", "(", ")", ",", "\n", "ignore_grad", "=", "is_dummy_batch", ",", "\n", ")", "\n", "del", "loss", "\n", "\n", "", "logging_outputs", ".", "append", "(", "logging_output", ")", "\n", "sample_size", "+=", "sample_size_i", "\n", "\n", "# emptying the CUDA cache after the first step can", "\n", "# reduce the chance of OOM", "\n", "if", "self", ".", "cuda", "and", "self", ".", "get_num_updates", "(", ")", "==", "0", ":", "\n", "                    ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "", "", "except", "RuntimeError", "as", "e", ":", "\n", "                ", "maybe_no_sync_recover", "(", ")", "\n", "if", "\"out of memory\"", "in", "str", "(", "e", ")", ":", "\n", "                    ", "self", ".", "_log_oom", "(", "e", ")", "\n", "if", "raise_oom", ":", "\n", "                        ", "raise", "e", "\n", "", "logger", ".", "warning", "(", "\n", "\"attempting to recover from OOM in forward/backward pass\"", "\n", ")", "\n", "ooms", "+=", "1", "\n", "self", ".", "zero_grad", "(", ")", "\n", "if", "self", ".", "cuda", ":", "\n", "                        ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "", "if", "self", ".", "cfg", ".", "distributed_training", ".", "distributed_world_size", "==", "1", ":", "\n", "                        ", "return", "None", "\n", "", "else", ":", "\n", "                        ", "distributed_cuda_oom", "=", "True", "\n", "", "", "else", ":", "\n", "                    ", "raise", "e", "\n", "\n", "", "", "if", "self", ".", "tpu", "and", "i", "<", "len", "(", "samples", ")", "-", "1", ":", "\n", "# tpu-comment: every XLA operation before marking step is", "\n", "# appended to the IR graph, and processing too many batches", "\n", "# before marking step can lead to OOM errors.", "\n", "# To handle gradient accumulation use case, we explicitly", "\n", "# mark step here for every forward pass without a backward pass", "\n", "                ", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "\n", "\n", "xm", ".", "mark_step", "(", ")", "\n", "\n", "", "", "if", "is_dummy_batch", ":", "\n", "            ", "if", "torch", ".", "is_tensor", "(", "sample_size", ")", ":", "\n", "                ", "sample_size", ".", "zero_", "(", ")", "\n", "", "else", ":", "\n", "                ", "sample_size", "*=", "0.0", "\n", "\n", "", "", "if", "torch", ".", "is_tensor", "(", "sample_size", ")", ":", "\n", "            ", "sample_size", "=", "sample_size", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "            ", "sample_size", "=", "float", "(", "sample_size", ")", "\n", "\n", "# gather logging outputs from all replicas", "\n", "", "if", "self", ".", "_sync_stats", "(", ")", ":", "\n", "            ", "distributed_cuda_oom", "=", "distributed_utils", ".", "all_reduce_dict", "(", "\n", "{", "'distributed_cuda_oom'", ":", "float", "(", "distributed_cuda_oom", ")", "}", ",", "\n", "device", "=", "self", ".", "device", ",", "group", "=", "self", ".", "data_parallel_process_group", "\n", ")", "[", "'distributed_cuda_oom'", "]", "\n", "if", "distributed_cuda_oom", "!=", "0", ":", "\n", "                ", "return", "None", "\n", "\n", "", "train_time", "=", "self", ".", "_local_cumulative_training_time", "(", ")", "\n", "logging_outputs", ",", "(", "\n", "sample_size", ",", "\n", "ooms", ",", "\n", "total_train_time", ",", "\n", ")", "=", "self", ".", "_aggregate_logging_outputs", "(", "\n", "logging_outputs", ",", "\n", "sample_size", ",", "\n", "ooms", ",", "\n", "train_time", ",", "\n", "ignore", "=", "is_dummy_batch", ",", "\n", ")", "\n", "self", ".", "_cumulative_training_time", "=", "(", "\n", "total_train_time", "/", "self", ".", "data_parallel_world_size", "\n", ")", "\n", "\n", "", "if", "hasattr", "(", "self", ".", "model", ",", "\"all_reduce\"", ")", ":", "\n", "            ", "self", ".", "model", ".", "all_reduce", "(", ")", "\n", "\n", "", "overflow", "=", "False", "\n", "try", ":", "\n", "            ", "if", "self", ".", "tpu", "and", "self", ".", "data_parallel_world_size", ">", "1", ":", "\n", "                ", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "\n", "\n", "gradients", "=", "xm", ".", "_fetch_gradients", "(", "self", ".", "optimizer", ".", "optimizer", ")", "\n", "xm", ".", "all_reduce", "(", "\n", "\"sum\"", ",", "gradients", ",", "scale", "=", "1.0", "/", "self", ".", "data_parallel_world_size", "\n", ")", "\n", "\n", "", "with", "torch", ".", "autograd", ".", "profiler", ".", "record_function", "(", "\"reduce-grads\"", ")", ":", "\n", "                ", "self", ".", "optimizer", ".", "all_reduce_grads", "(", "self", ".", "model", ")", "\n", "if", "utils", ".", "has_parameters", "(", "self", ".", "criterion", ")", ":", "\n", "                    ", "self", ".", "optimizer", ".", "all_reduce_grads", "(", "self", ".", "criterion", ")", "\n", "\n", "", "", "with", "torch", ".", "autograd", ".", "profiler", ".", "record_function", "(", "\"multiply-grads\"", ")", ":", "\n", "# multiply gradients by (data_parallel_size / sample_size) since", "\n", "# DDP already normalizes by the number of data parallel workers.", "\n", "# Thus we get (sum_of_gradients / sample_size) at the end.", "\n", "                ", "if", "not", "self", ".", "cfg", ".", "optimization", ".", "use_bmuf", ":", "\n", "                    ", "self", ".", "optimizer", ".", "multiply_grads", "(", "\n", "self", ".", "data_parallel_world_size", "/", "sample_size", "\n", ")", "\n", "", "elif", "sample_size", ">", "0", ":", "# BMUF needs to check sample size", "\n", "                    ", "num", "=", "self", ".", "data_parallel_world_size", "if", "self", ".", "_sync_stats", "(", ")", "else", "1", "\n", "self", ".", "optimizer", ".", "multiply_grads", "(", "num", "/", "sample_size", ")", "\n", "\n", "", "", "with", "torch", ".", "autograd", ".", "profiler", ".", "record_function", "(", "\"clip-grads\"", ")", ":", "\n", "# clip grads", "\n", "                ", "grad_norm", "=", "self", ".", "clip_grad_norm", "(", "self", ".", "cfg", ".", "optimization", ".", "clip_norm", ")", "\n", "\n", "# check that grad norms are consistent across workers", "\n", "", "if", "(", "\n", "not", "self", ".", "cfg", ".", "optimization", ".", "use_bmuf", "\n", "and", "self", ".", "cfg", ".", "distributed_training", ".", "distributed_wrapper", "!=", "\"SlowMo\"", "\n", "and", "not", "self", ".", "tpu", "\n", ")", ":", "\n", "                ", "self", ".", "_check_grad_norms", "(", "grad_norm", ")", "\n", "\n", "# on tpu check tensor is slow", "\n", "# if not self.tpu:", "\n", "#     if (", "\n", "#         not self.cfg.optimization.use_bmuf", "\n", "#         and self.cfg.distributed_training.distributed_wrapper != \"SlowMo\"", "\n", "#     ):", "\n", "#         self._check_grad_norms(grad_norm)", "\n", "#     if not torch.isfinite(grad_norm).all():", "\n", "#         # check local gradnorm single GPU case, trigger NanDetector", "\n", "#         raise FloatingPointError(\"gradients are Nan/Inf\")", "\n", "\n", "", "with", "torch", ".", "autograd", ".", "profiler", ".", "record_function", "(", "\"optimizer\"", ")", ":", "\n", "# take an optimization step", "\n", "                ", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "", "except", "FloatingPointError", ":", "\n", "# re-run the forward and backward pass with hooks attached to print", "\n", "# out where it fails", "\n", "            ", "with", "NanDetector", "(", "self", ".", "get_model", "(", ")", ")", ":", "\n", "                ", "self", ".", "task", ".", "train_step", "(", "\n", "sample", ",", "\n", "self", ".", "model", ",", "\n", "self", ".", "criterion", ",", "\n", "self", ".", "optimizer", ",", "\n", "self", ".", "get_num_updates", "(", ")", ",", "\n", "ignore_grad", "=", "False", ",", "\n", ")", "\n", "", "raise", "\n", "", "except", "OverflowError", "as", "e", ":", "\n", "            ", "overflow", "=", "True", "\n", "logger", ".", "info", "(", "\"NOTE: overflow detected, \"", "+", "str", "(", "e", ")", ")", "\n", "grad_norm", "=", "torch", ".", "tensor", "(", "0.0", ")", ".", "cuda", "(", ")", "\n", "self", ".", "zero_grad", "(", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "            ", "if", "\"out of memory\"", "in", "str", "(", "e", ")", ":", "\n", "                ", "self", ".", "_log_oom", "(", "e", ")", "\n", "logger", ".", "error", "(", "\"OOM during optimization, irrecoverable\"", ")", "\n", "", "raise", "e", "\n", "\n", "# Some distributed wrappers (e.g., SlowMo) need access to the optimizer after the step", "\n", "", "if", "hasattr", "(", "self", ".", "model", ",", "\"perform_additional_optimizer_actions\"", ")", ":", "\n", "            ", "if", "hasattr", "(", "self", ".", "optimizer", ",", "\"fp32_params\"", ")", ":", "\n", "                ", "self", ".", "model", ".", "perform_additional_optimizer_actions", "(", "\n", "self", ".", "optimizer", ".", "optimizer", ",", "self", ".", "optimizer", ".", "fp32_params", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "model", ".", "perform_additional_optimizer_actions", "(", "\n", "self", ".", "optimizer", ".", "optimizer", "\n", ")", "\n", "\n", "", "", "logging_output", "=", "None", "\n", "if", "(", "\n", "not", "overflow", "\n", "or", "self", ".", "cfg", ".", "distributed_training", ".", "distributed_wrapper", "==", "\"SlowMo\"", "\n", ")", ":", "\n", "            ", "self", ".", "set_num_updates", "(", "self", ".", "get_num_updates", "(", ")", "+", "1", ")", "\n", "\n", "if", "self", ".", "tpu", ":", "\n", "# mark step on TPUs", "\n", "                ", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "\n", "\n", "xm", ".", "mark_step", "(", ")", "\n", "\n", "# only log stats every log_interval steps", "\n", "# this causes wps to be misreported when log_interval > 1", "\n", "logging_output", "=", "{", "}", "\n", "if", "self", ".", "get_num_updates", "(", ")", "%", "self", ".", "cfg", ".", "common", ".", "log_interval", "==", "0", ":", "\n", "# log memory usage", "\n", "                    ", "mem_info", "=", "xm", ".", "get_memory_info", "(", "self", ".", "device", ")", "\n", "gb_free", "=", "mem_info", "[", "\"kb_free\"", "]", "/", "1024", "/", "1024", "\n", "gb_total", "=", "mem_info", "[", "\"kb_total\"", "]", "/", "1024", "/", "1024", "\n", "metrics", ".", "log_scalar", "(", "\n", "\"gb_free\"", ",", "\n", "gb_free", ",", "\n", "priority", "=", "1500", ",", "\n", "round", "=", "1", ",", "\n", "weight", "=", "0", ",", "\n", ")", "\n", "metrics", ".", "log_scalar", "(", "\n", "\"gb_total\"", ",", "\n", "gb_total", ",", "\n", "priority", "=", "1600", ",", "\n", "round", "=", "1", ",", "\n", "weight", "=", "0", ",", "\n", ")", "\n", "\n", "logging_output", "=", "self", ".", "_reduce_and_log_stats", "(", "\n", "logging_outputs", ",", "\n", "sample_size", ",", "\n", "grad_norm", ",", "\n", ")", "\n", "\n", "# log whenever there's an XLA compilation, since these", "\n", "# slow down training and may indicate opportunities for", "\n", "# optimization", "\n", "", "self", ".", "_check_xla_compilation", "(", ")", "\n", "", "else", ":", "\n", "# log stats", "\n", "                ", "logging_output", "=", "self", ".", "_reduce_and_log_stats", "(", "\n", "logging_outputs", ",", "\n", "sample_size", ",", "\n", "grad_norm", ",", "\n", ")", "\n", "\n", "# clear CUDA cache to reduce memory fragmentation", "\n", "if", "(", "\n", "self", ".", "cuda", "\n", "and", "self", ".", "cfg", ".", "common", ".", "empty_cache_freq", ">", "0", "\n", "and", "(", "\n", "(", "self", ".", "get_num_updates", "(", ")", "+", "self", ".", "cfg", ".", "common", ".", "empty_cache_freq", "-", "1", ")", "\n", "%", "self", ".", "cfg", ".", "common", ".", "empty_cache_freq", "\n", ")", "\n", "==", "0", "\n", ")", ":", "\n", "                    ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "", "", "", "if", "self", ".", "cfg", ".", "common", ".", "fp16", ":", "\n", "            ", "metrics", ".", "log_scalar", "(", "\n", "\"loss_scale\"", ",", "\n", "self", ".", "optimizer", ".", "scaler", ".", "loss_scale", ",", "\n", "priority", "=", "700", ",", "\n", "round", "=", "4", ",", "\n", "weight", "=", "0", ",", "\n", ")", "\n", "\n", "", "metrics", ".", "log_stop_time", "(", "\"train_wall\"", ")", "\n", "return", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.valid_step": [[813, 873], ["fairseq.logging.metrics.aggregate", "trainer.Trainer._reduce_and_log_stats", "xm.rendezvous", "xm.mark_step", "torch.no_grad", "trainer.Trainer.model.eval", "trainer.Trainer.criterion.eval", "trainer.Trainer._prepare_sample", "trainer.Trainer._aggregate_logging_outputs", "trainer.Trainer._prepare_sample", "trainer.Trainer.task.valid_step", "torch.is_tensor", "sample_size.zero_", "str", "trainer.Trainer._log_oom", "logger.warning", "trainer.Trainer.model.parameters", "trainer.Trainer.valid_step", "torch.cuda.empty_cache"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.aggregate", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._reduce_and_log_stats", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._prepare_sample", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._aggregate_logging_outputs", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._prepare_sample", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.valid_step", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._log_oom", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.valid_step"], ["", "@", "metrics", ".", "aggregate", "(", "\"valid\"", ")", "\n", "def", "valid_step", "(", "self", ",", "sample", ",", "raise_oom", "=", "False", ")", ":", "\n", "        ", "\"\"\"Do forward pass in evaluation mode.\"\"\"", "\n", "if", "self", ".", "tpu", ":", "\n", "            ", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "\n", "\n", "xm", ".", "rendezvous", "(", "\"valid_step\"", ")", "# wait for all workers", "\n", "xm", ".", "mark_step", "(", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "criterion", ".", "eval", "(", ")", "\n", "\n", "sample", "=", "self", ".", "_prepare_sample", "(", "sample", ")", "\n", "if", "sample", "is", "None", ":", "\n", "                ", "sample", "=", "self", ".", "_prepare_sample", "(", "self", ".", "_dummy_batch", ")", "\n", "is_dummy_batch", "=", "True", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "_dummy_batch", "==", "\"DUMMY\"", ":", "\n", "                    ", "self", ".", "_dummy_batch", "=", "sample", "\n", "", "is_dummy_batch", "=", "False", "\n", "\n", "", "try", ":", "\n", "                ", "_loss", ",", "sample_size", ",", "logging_output", "=", "self", ".", "task", ".", "valid_step", "(", "\n", "sample", ",", "self", ".", "model", ",", "self", ".", "criterion", "\n", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "                ", "if", "\"out of memory\"", "in", "str", "(", "e", ")", ":", "\n", "                    ", "self", ".", "_log_oom", "(", "e", ")", "\n", "if", "not", "raise_oom", ":", "\n", "                        ", "logger", ".", "warning", "(", "\n", "\"ran out of memory in validation step, retrying batch\"", "\n", ")", "\n", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "                            ", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                                ", "p", ".", "grad", "=", "None", "# free some memory", "\n", "", "", "if", "self", ".", "cuda", ":", "\n", "                            ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "", "return", "self", ".", "valid_step", "(", "sample", ",", "raise_oom", "=", "True", ")", "\n", "", "", "raise", "e", "\n", "\n", "", "logging_outputs", "=", "[", "logging_output", "]", "\n", "if", "is_dummy_batch", ":", "\n", "                ", "if", "torch", ".", "is_tensor", "(", "sample_size", ")", ":", "\n", "                    ", "sample_size", ".", "zero_", "(", ")", "\n", "", "else", ":", "\n", "                    ", "sample_size", "*=", "0.0", "\n", "\n", "# gather logging outputs from all replicas", "\n", "", "", "", "if", "self", ".", "data_parallel_world_size", ">", "1", ":", "\n", "            ", "logging_outputs", ",", "(", "sample_size", ",", ")", "=", "self", ".", "_aggregate_logging_outputs", "(", "\n", "logging_outputs", ",", "\n", "sample_size", ",", "\n", "ignore", "=", "is_dummy_batch", ",", "\n", ")", "\n", "\n", "# log validation stats", "\n", "", "logging_output", "=", "self", ".", "_reduce_and_log_stats", "(", "logging_outputs", ",", "sample_size", ")", "\n", "\n", "return", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.zero_grad": [[874, 876], ["trainer.Trainer.optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad"], ["", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.lr_step_begin_epoch": [[877, 882], ["trainer.Trainer.lr_scheduler.step_begin_epoch", "trainer.Trainer.lr_step_update"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step_begin_epoch", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.lr_step_update"], ["", "def", "lr_step_begin_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Adjust the learning rate at the beginning of the epoch.\"\"\"", "\n", "self", ".", "lr_scheduler", ".", "step_begin_epoch", "(", "epoch", ")", "\n", "# prefer updating the LR based on the number of steps", "\n", "return", "self", ".", "lr_step_update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.lr_step": [[883, 888], ["trainer.Trainer.lr_scheduler.step", "trainer.Trainer.lr_step_update"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.lr_step_update"], ["", "def", "lr_step", "(", "self", ",", "epoch", ",", "val_loss", "=", "None", ")", ":", "\n", "        ", "\"\"\"Adjust the learning rate at the end of the epoch.\"\"\"", "\n", "self", ".", "lr_scheduler", ".", "step", "(", "epoch", ",", "val_loss", ")", "\n", "# prefer updating the LR based on the number of steps", "\n", "return", "self", ".", "lr_step_update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.lr_step_update": [[889, 894], ["trainer.Trainer.lr_scheduler.step_update", "fairseq.logging.metrics.log_scalar", "trainer.Trainer.get_num_updates"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step_update", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.get_num_updates"], ["", "def", "lr_step_update", "(", "self", ")", ":", "\n", "        ", "\"\"\"Update the learning rate after each update.\"\"\"", "\n", "new_lr", "=", "self", ".", "lr_scheduler", ".", "step_update", "(", "self", ".", "get_num_updates", "(", ")", ")", "\n", "metrics", ".", "log_scalar", "(", "\"lr\"", ",", "new_lr", ",", "weight", "=", "0", ",", "priority", "=", "300", ")", "\n", "return", "new_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_lr": [[895, 898], ["trainer.Trainer.optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the current learning rate.\"\"\"", "\n", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_model": [[899, 902], ["None"], "methods", ["None"], ["", "def", "get_model", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the (non-wrapped) model instance.\"\"\"", "\n", "return", "self", ".", "_model", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_criterion": [[903, 906], ["None"], "methods", ["None"], ["", "def", "get_criterion", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the (non-wrapped) criterion instance.\"\"\"", "\n", "return", "self", ".", "_criterion", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_meter": [[907, 947], ["fairseq.logging.metrics.get_meters", "trainer.Trainer._warn_once.add", "fairseq.utils.deprecation_warning", "fairseq.logging.metrics.get_meters.get", "fairseq.logging.meters.AverageMeter", "fairseq.logging.metrics.get_meter", "fairseq.logging.meters.TimeMeter", "fairseq.logging.metrics.get_meter", "fairseq.logging.meters.TimeMeter", "fairseq.logging.metrics.get_meter", "fairseq.logging.meters.AverageMeter", "fairseq.logging.meters.AverageMeter", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.get_meters", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.deprecation_warning", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.get_meter", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.get_meter", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.get_meter"], ["", "def", "get_meter", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"[deprecated] Get a specific meter by name.\"\"\"", "\n", "from", "fairseq", "import", "meters", "\n", "\n", "if", "\"get_meter\"", "not", "in", "self", ".", "_warn_once", ":", "\n", "            ", "self", ".", "_warn_once", ".", "add", "(", "\"get_meter\"", ")", "\n", "utils", ".", "deprecation_warning", "(", "\n", "\"Trainer.get_meter is deprecated. Please use fairseq.metrics instead.\"", "\n", ")", "\n", "\n", "", "train_meters", "=", "metrics", ".", "get_meters", "(", "\"train\"", ")", "\n", "if", "train_meters", "is", "None", ":", "\n", "            ", "train_meters", "=", "{", "}", "\n", "\n", "", "if", "name", "==", "\"train_loss\"", "and", "\"loss\"", "in", "train_meters", ":", "\n", "            ", "return", "train_meters", "[", "\"loss\"", "]", "\n", "", "elif", "name", "==", "\"train_nll_loss\"", ":", "\n", "# support for legacy train.py, which assumed this meter is", "\n", "# always initialized", "\n", "            ", "m", "=", "train_meters", ".", "get", "(", "\"nll_loss\"", ",", "None", ")", "\n", "return", "m", "or", "meters", ".", "AverageMeter", "(", ")", "\n", "", "elif", "name", "==", "\"wall\"", ":", "\n", "# support for legacy train.py, which assumed this meter is", "\n", "# always initialized", "\n", "            ", "m", "=", "metrics", ".", "get_meter", "(", "\"default\"", ",", "\"wall\"", ")", "\n", "return", "m", "or", "meters", ".", "TimeMeter", "(", ")", "\n", "", "elif", "name", "==", "\"wps\"", ":", "\n", "            ", "m", "=", "metrics", ".", "get_meter", "(", "\"train\"", ",", "\"wps\"", ")", "\n", "return", "m", "or", "meters", ".", "TimeMeter", "(", ")", "\n", "", "elif", "name", "in", "{", "\"valid_loss\"", ",", "\"valid_nll_loss\"", "}", ":", "\n", "# support for legacy train.py, which assumed these meters", "\n", "# are always initialized", "\n", "            ", "k", "=", "name", "[", "len", "(", "\"valid_\"", ")", ":", "]", "\n", "m", "=", "metrics", ".", "get_meter", "(", "\"valid\"", ",", "k", ")", "\n", "return", "m", "or", "meters", ".", "AverageMeter", "(", ")", "\n", "", "elif", "name", "==", "\"oom\"", ":", "\n", "            ", "return", "meters", ".", "AverageMeter", "(", ")", "\n", "", "elif", "name", "in", "train_meters", ":", "\n", "            ", "return", "train_meters", "[", "name", "]", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_num_updates": [[948, 951], ["None"], "methods", ["None"], ["", "def", "get_num_updates", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the number of parameters updates.\"\"\"", "\n", "return", "self", ".", "_num_updates", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.set_num_updates": [[952, 959], ["trainer.Trainer.lr_step_update", "fairseq.logging.metrics.log_scalar", "trainer.Trainer.quantizer.step_update"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.lr_step_update", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step_update"], ["", "def", "set_num_updates", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Set the number of parameters updates.\"\"\"", "\n", "self", ".", "_num_updates", "=", "num_updates", "\n", "self", ".", "lr_step_update", "(", ")", "\n", "if", "self", ".", "quantizer", ":", "\n", "            ", "self", ".", "quantizer", ".", "step_update", "(", "self", ".", "_num_updates", ")", "\n", "", "metrics", ".", "log_scalar", "(", "\"num_updates\"", ",", "self", ".", "_num_updates", ",", "weight", "=", "0", ",", "priority", "=", "200", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.clip_grad_norm": [[960, 962], ["trainer.Trainer.optimizer.clip_grad_norm"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.model_parallel.megatron_trainer.MegatronTrainer.clip_grad_norm"], ["", "def", "clip_grad_norm", "(", "self", ",", "clip_norm", ")", ":", "\n", "        ", "return", "self", ".", "optimizer", ".", "clip_grad_norm", "(", "clip_norm", ",", "aggregate_norm_fn", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.cumulative_training_time": [[963, 969], ["trainer.Trainer._local_cumulative_training_time"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._local_cumulative_training_time"], ["", "def", "cumulative_training_time", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_cumulative_training_time", "is", "None", ":", "\n", "# single GPU", "\n", "            ", "return", "self", ".", "_local_cumulative_training_time", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_cumulative_training_time", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._local_cumulative_training_time": [[970, 973], ["time.time"], "methods", ["None"], ["", "", "def", "_local_cumulative_training_time", "(", "self", ")", ":", "\n", "        ", "\"\"\"Aggregate training time in seconds.\"\"\"", "\n", "return", "time", ".", "time", "(", ")", "-", "self", ".", "_start_time", "+", "self", ".", "_previous_training_time", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._prepare_sample": [[974, 1011], ["Exception", "fairseq.utils.apply_to_sample", "fairseq.utils.apply_to_sample", "len", "fairseq.utils.move_to_cuda", "t.half", "t.to", "fairseq.utils.move_to_cuda"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.apply_to_sample", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.apply_to_sample", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.move_to_cuda", "home.repos.pwc.inspect_result.reneeye_const.lightconv_layer.lightconv_layer.LightconvLayer.half", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.move_to_cuda"], ["", "def", "_prepare_sample", "(", "self", ",", "sample", ")", ":", "\n", "        ", "if", "sample", "==", "\"DUMMY\"", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"Trying to use an uninitialized 'dummy' batch. This usually indicates \"", "\n", "\"that the total number of batches is smaller than the number of \"", "\n", "\"participating GPUs. Try reducing the batch size or using fewer GPUs.\"", "\n", ")", "\n", "\n", "", "if", "sample", "is", "None", "or", "len", "(", "sample", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "", "if", "self", ".", "cuda", ":", "\n", "            ", "if", "self", ".", "pipeline_model_parallel", ":", "\n", "                ", "if", "\"target\"", "in", "sample", ":", "\n", "                    ", "sample", "[", "\"target\"", "]", "=", "utils", ".", "move_to_cuda", "(", "\n", "sample", "[", "\"target\"", "]", ",", "device", "=", "self", ".", "last_device", "\n", ")", "\n", "", "", "else", ":", "\n", "                ", "sample", "=", "utils", ".", "move_to_cuda", "(", "sample", ")", "\n", "\n", "", "", "def", "apply_half", "(", "t", ")", ":", "\n", "            ", "if", "t", ".", "dtype", "is", "torch", ".", "float32", ":", "\n", "                ", "return", "t", ".", "half", "(", ")", "\n", "", "return", "t", "\n", "\n", "", "def", "apply_bfloat16", "(", "t", ")", ":", "\n", "            ", "if", "t", ".", "dtype", "is", "torch", ".", "float32", ":", "\n", "                ", "return", "t", ".", "to", "(", "dtype", "=", "torch", ".", "bfloat16", ")", "\n", "", "return", "t", "\n", "\n", "", "if", "self", ".", "cfg", ".", "common", ".", "fp16", ":", "\n", "            ", "sample", "=", "utils", ".", "apply_to_sample", "(", "apply_half", ",", "sample", ")", "\n", "\n", "", "if", "self", ".", "cfg", ".", "common", ".", "bf16", ":", "\n", "            ", "sample", "=", "utils", ".", "apply_to_sample", "(", "apply_bfloat16", ",", "sample", ")", "\n", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._set_seed": [[1012, 1017], ["fairseq.utils.set_torch_seed", "trainer.Trainer.get_num_updates"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.get_num_updates"], ["", "def", "_set_seed", "(", "self", ")", ":", "\n", "# Set seed based on args.seed and the update number so that we get", "\n", "# reproducible results when resuming from checkpoints", "\n", "        ", "seed", "=", "self", ".", "cfg", ".", "common", ".", "seed", "+", "self", ".", "get_num_updates", "(", ")", "\n", "utils", ".", "set_torch_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._sync_stats": [[1018, 1031], ["trainer.Trainer.get_num_updates", "trainer.Trainer.get_num_updates"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.get_num_updates"], ["", "def", "_sync_stats", "(", "self", ")", ":", "\n", "# Return True if it's using multiple GPUs and DDP or multiple GPUs with", "\n", "# BMUF and it's a bmuf sync with warmup iterations completed before.", "\n", "        ", "if", "self", ".", "data_parallel_world_size", "==", "1", ":", "\n", "            ", "return", "False", "\n", "", "elif", "self", ".", "cfg", ".", "optimization", ".", "use_bmuf", ":", "\n", "            ", "return", "(", "\n", "self", ".", "get_num_updates", "(", ")", "+", "1", "\n", ")", "%", "self", ".", "cfg", ".", "bmuf", ".", "global_sync_iter", "==", "0", "and", "(", "\n", "self", ".", "get_num_updates", "(", ")", "+", "1", "\n", ")", ">", "self", ".", "cfg", ".", "bmuf", ".", "warmup_iterations", "\n", "", "else", ":", "\n", "            ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._log_oom": [[1032, 1039], ["logger.warning", "sys.stderr.flush"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.flush"], ["", "", "def", "_log_oom", "(", "self", ",", "exc", ")", ":", "\n", "        ", "msg", "=", "\"OOM: Ran out of memory with exception: {}\"", ".", "format", "(", "exc", ")", "\n", "logger", ".", "warning", "(", "msg", ")", "\n", "# if torch.cuda.is_available() and hasattr(torch.cuda, \"memory_summary\"):", "\n", "#     for device_idx in range(torch.cuda.device_count()):", "\n", "#         logger.warning(torch.cuda.memory_summary(device=device_idx))", "\n", "sys", ".", "stderr", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._aggregate_logging_outputs": [[1040, 1053], ["trainer.Trainer.task.__class__.logging_outputs_can_be_summed", "trainer.Trainer.get_criterion", "trainer.Trainer._fast_stat_sync_sum", "trainer.Trainer._all_gather_list_sync"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.criterions.sentence_prediction.SentencePredictionCriterion.logging_outputs_can_be_summed", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_criterion", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._fast_stat_sync_sum", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._all_gather_list_sync"], ["", "def", "_aggregate_logging_outputs", "(", "\n", "self", ",", "\n", "logging_outputs", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ",", "\n", "*", "extra_stats_to_sum", ",", "\n", "ignore", "=", "False", ",", "\n", ")", ":", "\n", "        ", "if", "self", ".", "task", ".", "__class__", ".", "logging_outputs_can_be_summed", "(", "self", ".", "get_criterion", "(", ")", ")", ":", "\n", "            ", "return", "self", ".", "_fast_stat_sync_sum", "(", "\n", "logging_outputs", ",", "*", "extra_stats_to_sum", ",", "ignore", "=", "ignore", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_all_gather_list_sync", "(", "\n", "logging_outputs", ",", "*", "extra_stats_to_sum", ",", "ignore", "=", "ignore", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._all_gather_list_sync": [[1055, 1082], ["list", "list", "zip", "itertools.chain.from_iterable", "sum", "fairseq.distributed_utils.all_gather_list", "list", "getattr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.all_gather_list"], ["", "", "def", "_all_gather_list_sync", "(", "\n", "self", ",", "\n", "logging_outputs", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ",", "\n", "*", "extra_stats_to_sum", ",", "\n", "ignore", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Sync logging outputs across workers. all_gather_list_sync is\n        suitable when logging outputs are complex types.\n        \"\"\"", "\n", "if", "self", ".", "tpu", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "if", "ignore", ":", "\n", "            ", "logging_outputs", "=", "[", "]", "\n", "", "results", "=", "list", "(", "\n", "zip", "(", "\n", "*", "distributed_utils", ".", "all_gather_list", "(", "\n", "[", "logging_outputs", "]", "+", "list", "(", "extra_stats_to_sum", ")", ",", "\n", "max_size", "=", "getattr", "(", "self", ".", "cfg", ".", "common", ",", "\"all_gather_list_size\"", ",", "16384", ")", ",", "\n", "group", "=", "self", ".", "data_parallel_process_group", ",", "\n", ")", "\n", ")", "\n", ")", "\n", "logging_outputs", ",", "extra_stats_to_sum", "=", "results", "[", "0", "]", ",", "results", "[", "1", ":", "]", "\n", "logging_outputs", "=", "list", "(", "chain", ".", "from_iterable", "(", "logging_outputs", ")", ")", "\n", "extra_stats_to_sum", "=", "[", "sum", "(", "s", ")", "for", "s", "in", "extra_stats_to_sum", "]", "\n", "return", "logging_outputs", ",", "extra_stats_to_sum", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._fast_stat_sync_sum": [[1083, 1122], ["enumerate", "fairseq.distributed_utils.all_reduce_dict", "len", "list", "logging_outputs[].keys", "range", "sum", "len", "str", "torch.is_tensor", "torch.zeros_like", "str"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.all_reduce_dict"], ["", "def", "_fast_stat_sync_sum", "(", "\n", "self", ",", "\n", "logging_outputs", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ",", "\n", "*", "extra_stats_to_sum", ",", "\n", "ignore", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Sync logging outputs across workers. fast_stat_sync_sum is\n        faster than all_gather_list_sync, but is only suitable when\n        logging outputs are scalars and can be summed. Note that\n        *logging_outputs* cannot contain any nested dicts/lists.\n        \"\"\"", "\n", "data", "=", "{", "}", "\n", "for", "i", ",", "stat", "in", "enumerate", "(", "extra_stats_to_sum", ")", ":", "\n", "            ", "data", "[", "\"extra_stats_\"", "+", "str", "(", "i", ")", "]", "=", "stat", "\n", "", "if", "len", "(", "logging_outputs", ")", ">", "0", ":", "\n", "            ", "log_keys", "=", "list", "(", "logging_outputs", "[", "0", "]", ".", "keys", "(", ")", ")", "\n", "for", "k", "in", "log_keys", ":", "\n", "                ", "if", "not", "ignore", ":", "\n", "                    ", "v", "=", "sum", "(", "log", "[", "k", "]", "for", "log", "in", "logging_outputs", "if", "k", "in", "log", ")", "\n", "", "else", ":", "\n", "                    ", "v", "=", "logging_outputs", "[", "0", "]", "[", "k", "]", "\n", "v", "=", "torch", ".", "zeros_like", "(", "v", ")", "if", "torch", ".", "is_tensor", "(", "v", ")", "else", "0", "\n", "", "data", "[", "\"logging_outputs_\"", "+", "k", "]", "=", "v", "\n", "", "", "else", ":", "\n", "            ", "log_keys", "=", "None", "\n", "\n", "", "data", "=", "distributed_utils", ".", "all_reduce_dict", "(", "\n", "data", ",", "device", "=", "self", ".", "device", ",", "group", "=", "self", ".", "data_parallel_process_group", "\n", ")", "\n", "\n", "extra_stats_to_sum", "=", "[", "\n", "data", "[", "\"extra_stats_\"", "+", "str", "(", "i", ")", "]", "for", "i", "in", "range", "(", "len", "(", "extra_stats_to_sum", ")", ")", "\n", "]", "\n", "if", "log_keys", "is", "not", "None", ":", "\n", "            ", "logging_outputs", "=", "[", "{", "k", ":", "data", "[", "\"logging_outputs_\"", "+", "k", "]", "for", "k", "in", "log_keys", "}", "]", "\n", "", "else", ":", "\n", "            ", "logging_outputs", "=", "[", "]", "\n", "", "return", "logging_outputs", ",", "extra_stats_to_sum", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._check_grad_norms": [[1123, 1157], ["trainer.Trainer._grad_norm_buf.zero_", "fairseq.distributed_utils.all_reduce", "torch.max", "trainer.Trainer._check_grad_norms.is_consistent"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce"], ["", "def", "_check_grad_norms", "(", "self", ",", "grad_norm", ")", ":", "\n", "        ", "\"\"\"Check that grad norms are consistent across workers.\"\"\"", "\n", "if", "self", ".", "_grad_norm_buf", "is", "not", "None", ":", "\n", "            ", "self", ".", "_grad_norm_buf", ".", "zero_", "(", ")", "\n", "self", ".", "_grad_norm_buf", "[", "self", ".", "data_parallel_rank", "]", "=", "grad_norm", "\n", "distributed_utils", ".", "all_reduce", "(", "\n", "self", ".", "_grad_norm_buf", ",", "group", "=", "self", ".", "data_parallel_process_group", "\n", ")", "\n", "\n", "def", "is_consistent", "(", "tensor", ")", ":", "\n", "                ", "max_abs_diff", "=", "torch", ".", "max", "(", "torch", ".", "abs", "(", "tensor", "-", "tensor", "[", "0", "]", ")", ")", "\n", "return", "(", "\n", "torch", ".", "isfinite", "(", "tensor", ")", ".", "any", "(", ")", "\n", "# torch.isfinite(tensor).all()", "\n", "or", "(", "max_abs_diff", "/", "(", "tensor", "[", "0", "]", "+", "1e-6", ")", "<", "1e-6", ")", ".", "all", "(", ")", "\n", ")", "\n", "\n", "", "if", "not", "is_consistent", "(", "self", ".", "_grad_norm_buf", ")", ":", "\n", "                ", "pretty_detail", "=", "\"\\n\"", ".", "join", "(", "\n", "\"rank {:3d} = {:.8f}\"", ".", "format", "(", "r", ",", "n", ")", "\n", "for", "r", ",", "n", "in", "enumerate", "(", "self", ".", "_grad_norm_buf", ".", "tolist", "(", ")", ")", "\n", ")", "\n", "error_detail", "=", "\"grad_norm across the workers:\\n{}\\n\"", ".", "format", "(", "\n", "pretty_detail", "\n", ")", "\n", "# use FloatingPointError to trigger NanDetector", "\n", "raise", "FloatingPointError", "(", "\n", "\"Fatal error: gradients are inconsistent between workers. \"", "\n", "\"Try --ddp-backend=no_c10d. \"", "\n", "\"Or are you mixing up different generation of GPUs in training?\"", "\n", "+", "\"\\n\"", "\n", "+", "\"-\"", "*", "80", "\n", "+", "\"\\n{}\\n\"", ".", "format", "(", "error_detail", ")", "\n", "+", "\"-\"", "*", "80", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._reduce_and_log_stats": [[1159, 1203], ["fairseq.logging.metrics.log_speed", "fairseq.logging.metrics.log_scalar", "fairseq.logging.metrics.aggregate", "fairseq.logging.metrics.log_scalar", "trainer.Trainer.task.reduce_metrics", "fairseq.logging.metrics.log_scalar", "agg.get_smoothed_values", "torch.where", "trainer.Trainer.get_criterion", "trainer.Trainer._warn_once.add", "logger.warning", "grad_norm.new_tensor", "grad_norm.new_tensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_speed", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.aggregate", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.reduce_metrics", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.get_smoothed_values", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_criterion", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add"], ["", "", "", "def", "_reduce_and_log_stats", "(", "self", ",", "logging_outputs", ",", "sample_size", ",", "grad_norm", "=", "None", ")", ":", "\n", "        ", "if", "grad_norm", "is", "not", "None", ":", "\n", "# if grad_norm is not None and (", "\n", "#     not torch.is_tensor(grad_norm) or torch.isfinite(grad_norm)", "\n", "# ):", "\n", "            ", "metrics", ".", "log_speed", "(", "\"ups\"", ",", "1.0", ",", "priority", "=", "100", ",", "round", "=", "2", ")", "\n", "metrics", ".", "log_scalar", "(", "\"gnorm\"", ",", "grad_norm", ",", "priority", "=", "400", ",", "round", "=", "3", ")", "\n", "if", "self", ".", "cfg", ".", "optimization", ".", "clip_norm", ">", "0", ":", "\n", "                ", "metrics", ".", "log_scalar", "(", "\n", "\"clip\"", ",", "\n", "torch", ".", "where", "(", "\n", "grad_norm", ">", "self", ".", "cfg", ".", "optimization", ".", "clip_norm", ",", "\n", "grad_norm", ".", "new_tensor", "(", "100", ")", ",", "\n", "grad_norm", ".", "new_tensor", "(", "0", ")", ",", "\n", ")", ",", "\n", "priority", "=", "500", ",", "\n", "round", "=", "1", ",", "\n", ")", "\n", "\n", "", "", "with", "metrics", ".", "aggregate", "(", ")", "as", "agg", ":", "\n", "            ", "if", "logging_outputs", "is", "not", "None", ":", "\n", "                ", "self", ".", "task", ".", "reduce_metrics", "(", "logging_outputs", ",", "self", ".", "get_criterion", "(", ")", ")", "\n", "del", "logging_outputs", "\n", "\n", "# extra warning for criterions that don't properly log a loss value", "\n", "", "if", "\"loss\"", "not", "in", "agg", ":", "\n", "                ", "if", "\"loss\"", "not", "in", "self", ".", "_warn_once", ":", "\n", "                    ", "self", ".", "_warn_once", ".", "add", "(", "\"loss\"", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Criterion.reduce_metrics did not log a 'loss' value, \"", "\n", "\"which may break some functionality\"", "\n", ")", "\n", "", "metrics", ".", "log_scalar", "(", "\"loss\"", ",", "-", "1", ")", "\n", "\n", "# support legacy interface", "\n", "", "if", "self", ".", "tpu", ":", "\n", "                ", "logging_output", "=", "{", "}", "\n", "", "else", ":", "\n", "                ", "logging_output", "=", "agg", ".", "get_smoothed_values", "(", ")", "\n", "logging_output", "[", "\"sample_size\"", "]", "=", "sample_size", "\n", "for", "key_to_delete", "in", "[", "\"ppl\"", ",", "\"wps\"", ",", "\"wpb\"", ",", "\"bsz\"", "]", ":", "\n", "                    ", "if", "key_to_delete", "in", "logging_output", ":", "\n", "                        ", "del", "logging_output", "[", "key_to_delete", "]", "\n", "", "", "", "return", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._check_xla_compilation": [[1204, 1219], ["met.metric_data", "logger.warning"], "methods", ["None"], ["", "", "def", "_check_xla_compilation", "(", "self", ")", ":", "\n", "        ", "import", "torch_xla", ".", "debug", ".", "metrics", "as", "met", "\n", "\n", "compile_stats", "=", "met", ".", "metric_data", "(", "\"CompileTime\"", ")", "\n", "if", "compile_stats", "is", "None", ":", "\n", "            ", "return", "\n", "", "num_xla_compiles", "=", "compile_stats", "[", "0", "]", "\n", "if", "num_xla_compiles", ">", "self", ".", "_num_xla_compiles", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"XLA compilation detected on device #{}; too many of these can lead \"", "\n", "\"to slow training, but we expect a few in the beginning\"", ".", "format", "(", "\n", "self", ".", "cfg", ".", "distributed_training", ".", "distributed_rank", "\n", ")", "\n", ")", "\n", "", "self", ".", "_num_xla_compiles", "=", "num_xla_compiles", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer._catalog_shared_params": [[1221, 1239], ["module._parameters.items", "module._modules.items", "memo[].append", "trainer._catalog_shared_params", "memo.values", "len"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer._catalog_shared_params"], ["", "", "def", "_catalog_shared_params", "(", "module", ",", "memo", "=", "None", ",", "prefix", "=", "\"\"", ")", ":", "\n", "    ", "if", "memo", "is", "None", ":", "\n", "        ", "first_call", "=", "True", "\n", "memo", "=", "{", "}", "\n", "", "else", ":", "\n", "        ", "first_call", "=", "False", "\n", "", "for", "name", ",", "param", "in", "module", ".", "_parameters", ".", "items", "(", ")", ":", "\n", "        ", "param_prefix", "=", "prefix", "+", "(", "\".\"", "if", "prefix", "else", "\"\"", ")", "+", "name", "\n", "if", "param", "not", "in", "memo", ":", "\n", "            ", "memo", "[", "param", "]", "=", "[", "]", "\n", "", "memo", "[", "param", "]", ".", "append", "(", "param_prefix", ")", "\n", "", "for", "name", ",", "m", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "        ", "if", "m", "is", "None", ":", "\n", "            ", "continue", "\n", "", "submodule_prefix", "=", "prefix", "+", "(", "\".\"", "if", "prefix", "else", "\"\"", ")", "+", "name", "\n", "_catalog_shared_params", "(", "m", ",", "memo", ",", "submodule_prefix", ")", "\n", "", "if", "first_call", ":", "\n", "        ", "return", "[", "x", "for", "x", "in", "memo", ".", "values", "(", ")", "if", "len", "(", "x", ")", ">", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer._get_module_by_path": [[1241, 1246], ["path.split.split", "getattr"], "function", ["None"], ["", "", "def", "_get_module_by_path", "(", "module", ",", "path", ")", ":", "\n", "    ", "path", "=", "path", ".", "split", "(", "\".\"", ")", "\n", "for", "name", "in", "path", ":", "\n", "        ", "module", "=", "getattr", "(", "module", ",", "name", ")", "\n", "", "return", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer._set_module_by_path": [[1248, 1253], ["path.split.split", "setattr", "getattr"], "function", ["None"], ["", "def", "_set_module_by_path", "(", "module", ",", "path", ",", "value", ")", ":", "\n", "    ", "path", "=", "path", ".", "split", "(", "\".\"", ")", "\n", "for", "name", "in", "path", "[", ":", "-", "1", "]", ":", "\n", "        ", "module", "=", "getattr", "(", "module", ",", "name", ")", "\n", "", "setattr", "(", "module", ",", "path", "[", "-", "1", "]", ",", "value", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.pdb.MultiprocessingPdb.__init__": [[29, 31], ["pdb.Pdb.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "pdb", ".", "Pdb", ".", "__init__", "(", "self", ",", "nosigint", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.pdb.MultiprocessingPdb._cmdloop": [[32, 43], ["pdb.MultiprocessingPdb.cmdloop", "os.fdopen"], "methods", ["None"], ["", "def", "_cmdloop", "(", "self", ")", ":", "\n", "        ", "stdin_bak", "=", "sys", ".", "stdin", "\n", "with", "_stdin_lock", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "_stdin_fd", "is", "not", "None", ":", "\n", "                    ", "if", "not", "_stdin", "[", "0", "]", ":", "\n", "                        ", "_stdin", "[", "0", "]", "=", "os", ".", "fdopen", "(", "_stdin_fd", ")", "\n", "", "sys", ".", "stdin", "=", "_stdin", "[", "0", "]", "\n", "", "self", ".", "cmdloop", "(", ")", "\n", "", "finally", ":", "\n", "                ", "sys", ".", "stdin", "=", "stdin_bak", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.pdb.set_trace": [[45, 48], ["pdb.MultiprocessingPdb", "MultiprocessingPdb.set_trace", "sys._getframe"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.pdb.set_trace"], ["", "", "", "", "def", "set_trace", "(", ")", ":", "\n", "    ", "pdb", "=", "MultiprocessingPdb", "(", ")", "\n", "pdb", ".", "set_trace", "(", "sys", ".", "_getframe", "(", ")", ".", "f_back", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.registry.setup_registry": [[17, 101], ["registry_name[].replace.startswith", "registry_name[].replace", "set", "isinstance", "hasattr", "getattr.", "isinstance", "getattr", "fairseq.dataclass.utils.merge_with_parent", "getattr", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "hydra.core.config_store.ConfigStore.instance", "dataclass", "ConfigStore.instance.store", "dc", "fairseq.dataclass.utils.populate_dataclass", "issubclass", "issubclass"], "function", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.merge_with_parent", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.populate_dataclass"], ["def", "setup_registry", "(", "registry_name", ":", "str", ",", "base_class", "=", "None", ",", "default", "=", "None", ",", "required", "=", "False", ")", ":", "\n", "    ", "assert", "registry_name", ".", "startswith", "(", "\"--\"", ")", "\n", "registry_name", "=", "registry_name", "[", "2", ":", "]", ".", "replace", "(", "\"-\"", ",", "\"_\"", ")", "\n", "\n", "REGISTRY", "=", "{", "}", "\n", "REGISTRY_CLASS_NAMES", "=", "set", "(", ")", "\n", "DATACLASS_REGISTRY", "=", "{", "}", "\n", "\n", "# maintain a registry of all registries", "\n", "if", "registry_name", "in", "REGISTRIES", ":", "\n", "        ", "return", "# registry already exists", "\n", "", "REGISTRIES", "[", "registry_name", "]", "=", "{", "\n", "\"registry\"", ":", "REGISTRY", ",", "\n", "\"default\"", ":", "default", ",", "\n", "\"dataclass_registry\"", ":", "DATACLASS_REGISTRY", ",", "\n", "}", "\n", "\n", "def", "build_x", "(", "cfg", ":", "Union", "[", "DictConfig", ",", "str", ",", "Namespace", "]", ",", "*", "extra_args", ",", "**", "extra_kwargs", ")", ":", "\n", "        ", "if", "isinstance", "(", "cfg", ",", "DictConfig", ")", ":", "\n", "            ", "choice", "=", "cfg", ".", "_name", "\n", "\n", "if", "choice", "and", "choice", "in", "DATACLASS_REGISTRY", ":", "\n", "                ", "dc", "=", "DATACLASS_REGISTRY", "[", "choice", "]", "\n", "cfg", "=", "merge_with_parent", "(", "dc", "(", ")", ",", "cfg", ")", "\n", "", "", "elif", "isinstance", "(", "cfg", ",", "str", ")", ":", "\n", "            ", "choice", "=", "cfg", "\n", "if", "choice", "in", "DATACLASS_REGISTRY", ":", "\n", "                ", "cfg", "=", "DATACLASS_REGISTRY", "[", "choice", "]", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "choice", "=", "getattr", "(", "cfg", ",", "registry_name", ",", "None", ")", "\n", "if", "choice", "in", "DATACLASS_REGISTRY", ":", "\n", "                ", "cfg", "=", "populate_dataclass", "(", "DATACLASS_REGISTRY", "[", "choice", "]", "(", ")", ",", "cfg", ")", "\n", "\n", "", "", "if", "choice", "is", "None", ":", "\n", "            ", "if", "required", ":", "\n", "                ", "raise", "ValueError", "(", "\"{} is required!\"", ".", "format", "(", "registry_name", ")", ")", "\n", "", "return", "None", "\n", "\n", "", "cls", "=", "REGISTRY", "[", "choice", "]", "\n", "if", "hasattr", "(", "cls", ",", "\"build_\"", "+", "registry_name", ")", ":", "\n", "            ", "builder", "=", "getattr", "(", "cls", ",", "\"build_\"", "+", "registry_name", ")", "\n", "", "else", ":", "\n", "            ", "builder", "=", "cls", "\n", "\n", "", "return", "builder", "(", "cfg", ",", "*", "extra_args", ",", "**", "extra_kwargs", ")", "\n", "\n", "", "def", "register_x", "(", "name", ",", "dataclass", "=", "None", ")", ":", "\n", "        ", "def", "register_x_cls", "(", "cls", ")", ":", "\n", "            ", "if", "name", "in", "REGISTRY", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Cannot register duplicate {} ({})\"", ".", "format", "(", "registry_name", ",", "name", ")", "\n", ")", "\n", "", "if", "cls", ".", "__name__", "in", "REGISTRY_CLASS_NAMES", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Cannot register {} with duplicate class name ({})\"", ".", "format", "(", "\n", "registry_name", ",", "cls", ".", "__name__", "\n", ")", "\n", ")", "\n", "", "if", "base_class", "is", "not", "None", "and", "not", "issubclass", "(", "cls", ",", "base_class", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"{} must extend {}\"", ".", "format", "(", "cls", ".", "__name__", ",", "base_class", ".", "__name__", ")", "\n", ")", "\n", "\n", "", "if", "dataclass", "is", "not", "None", "and", "not", "issubclass", "(", "dataclass", ",", "FairseqDataclass", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Dataclass {} must extend FairseqDataclass\"", ".", "format", "(", "dataclass", ")", "\n", ")", "\n", "\n", "", "cls", ".", "__dataclass", "=", "dataclass", "\n", "if", "cls", ".", "__dataclass", "is", "not", "None", ":", "\n", "                ", "DATACLASS_REGISTRY", "[", "name", "]", "=", "cls", ".", "__dataclass", "\n", "\n", "cs", "=", "ConfigStore", ".", "instance", "(", ")", "\n", "node", "=", "dataclass", "(", ")", "\n", "node", ".", "_name", "=", "name", "\n", "cs", ".", "store", "(", "name", "=", "name", ",", "group", "=", "registry_name", ",", "node", "=", "node", ",", "provider", "=", "\"fairseq\"", ")", "\n", "\n", "", "REGISTRY", "[", "name", "]", "=", "cls", "\n", "\n", "return", "cls", "\n", "\n", "", "return", "register_x_cls", "\n", "\n", "", "return", "build_x", ",", "register_x", ",", "REGISTRY", ",", "DATACLASS_REGISTRY", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.binarizer.Binarizer.binarize": [[25, 77], ["collections.Counter", "open", "f.seek", "binarizer.safe_readline", "sum", "collections.Counter.update", "fairseq.file_io.PathManager.get_local_path", "len", "consumer", "f.readline", "collections.Counter.values", "f.readline.strip().split", "torch.IntTensor", "dict.encode_line", "f.tell", "int", "id_list.reverse", "id_list.append", "f.readline.strip", "dict.eos"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.fairseq.binarizer.safe_readline", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.get_local_path", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.encode_line", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["    ", "@", "staticmethod", "\n", "def", "binarize", "(", "\n", "filename", ",", "\n", "dict", ",", "\n", "consumer", ",", "\n", "tokenize", "=", "tokenize_line", ",", "\n", "append_eos", "=", "True", ",", "\n", "reverse_order", "=", "False", ",", "\n", "offset", "=", "0", ",", "\n", "end", "=", "-", "1", ",", "\n", "already_numberized", "=", "False", ",", "\n", ")", ":", "\n", "        ", "nseq", ",", "ntok", "=", "0", ",", "0", "\n", "replaced", "=", "Counter", "(", ")", "\n", "\n", "def", "replaced_consumer", "(", "word", ",", "idx", ")", ":", "\n", "            ", "if", "idx", "==", "dict", ".", "unk_index", "and", "word", "!=", "dict", ".", "unk_word", ":", "\n", "                ", "replaced", ".", "update", "(", "[", "word", "]", ")", "\n", "\n", "", "", "with", "open", "(", "PathManager", ".", "get_local_path", "(", "filename", ")", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "seek", "(", "offset", ")", "\n", "# next(f) breaks f.tell(), hence readline() must be used", "\n", "line", "=", "safe_readline", "(", "f", ")", "\n", "while", "line", ":", "\n", "                ", "if", "end", ">", "0", "and", "f", ".", "tell", "(", ")", ">", "end", ":", "\n", "                    ", "break", "\n", "", "if", "already_numberized", ":", "\n", "                    ", "id_strings", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "id_list", "=", "[", "int", "(", "id_string", ")", "for", "id_string", "in", "id_strings", "]", "\n", "if", "reverse_order", ":", "\n", "                        ", "id_list", ".", "reverse", "(", ")", "\n", "", "if", "append_eos", ":", "\n", "                        ", "id_list", ".", "append", "(", "dict", ".", "eos", "(", ")", ")", "\n", "", "ids", "=", "torch", ".", "IntTensor", "(", "id_list", ")", "\n", "", "else", ":", "\n", "                    ", "ids", "=", "dict", ".", "encode_line", "(", "\n", "line", "=", "line", ",", "\n", "line_tokenizer", "=", "tokenize", ",", "\n", "add_if_not_exist", "=", "False", ",", "\n", "consumer", "=", "replaced_consumer", ",", "\n", "append_eos", "=", "append_eos", ",", "\n", "reverse_order", "=", "reverse_order", ",", "\n", ")", "\n", "", "nseq", "+=", "1", "\n", "ntok", "+=", "len", "(", "ids", ")", "\n", "consumer", "(", "ids", ")", "\n", "line", "=", "f", ".", "readline", "(", ")", "\n", "", "", "return", "{", "\n", "\"nseq\"", ":", "nseq", ",", "\n", "\"nunk\"", ":", "sum", "(", "replaced", ".", "values", "(", ")", ")", ",", "\n", "\"ntok\"", ":", "ntok", ",", "\n", "\"replaced\"", ":", "replaced", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.binarizer.Binarizer.binarize_alignments": [[79, 94], ["open", "f.seek", "binarizer.safe_readline", "fairseq.file_io.PathManager.get_local_path", "alignment_parser", "consumer", "f.readline", "f.tell"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.fairseq.binarizer.safe_readline", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.get_local_path"], ["", "@", "staticmethod", "\n", "def", "binarize_alignments", "(", "filename", ",", "alignment_parser", ",", "consumer", ",", "offset", "=", "0", ",", "end", "=", "-", "1", ")", ":", "\n", "        ", "nseq", "=", "0", "\n", "\n", "with", "open", "(", "PathManager", ".", "get_local_path", "(", "filename", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "seek", "(", "offset", ")", "\n", "line", "=", "safe_readline", "(", "f", ")", "\n", "while", "line", ":", "\n", "                ", "if", "end", ">", "0", "and", "f", ".", "tell", "(", ")", ">", "end", ":", "\n", "                    ", "break", "\n", "", "ids", "=", "alignment_parser", "(", "line", ")", "\n", "nseq", "+=", "1", "\n", "consumer", "(", "ids", ")", "\n", "line", "=", "f", ".", "readline", "(", ")", "\n", "", "", "return", "{", "\"nseq\"", ":", "nseq", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.binarizer.Binarizer.find_offsets": [[95, 106], ["open", "range", "fairseq.file_io.PathManager.get_local_path", "os.fstat", "f.seek", "binarizer.safe_readline", "f.tell", "f.fileno", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.get_local_path", "home.repos.pwc.inspect_result.reneeye_const.fairseq.binarizer.safe_readline"], ["", "@", "staticmethod", "\n", "def", "find_offsets", "(", "filename", ",", "num_chunks", ")", ":", "\n", "        ", "with", "open", "(", "PathManager", ".", "get_local_path", "(", "filename", ")", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "size", "=", "os", ".", "fstat", "(", "f", ".", "fileno", "(", ")", ")", ".", "st_size", "\n", "chunk_size", "=", "size", "//", "num_chunks", "\n", "offsets", "=", "[", "0", "for", "_", "in", "range", "(", "num_chunks", "+", "1", ")", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "num_chunks", ")", ":", "\n", "                ", "f", ".", "seek", "(", "chunk_size", "*", "i", ")", "\n", "safe_readline", "(", "f", ")", "\n", "offsets", "[", "i", "]", "=", "f", ".", "tell", "(", ")", "\n", "", "return", "offsets", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.binarizer.safe_readline": [[14, 22], ["f.tell", "f.readline", "f.seek"], "function", ["None"], ["def", "safe_readline", "(", "f", ")", ":", "\n", "    ", "pos", "=", "f", ".", "tell", "(", ")", "\n", "while", "True", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "f", ".", "readline", "(", ")", "\n", "", "except", "UnicodeDecodeError", ":", "\n", "            ", "pos", "-=", "1", "\n", "f", ".", "seek", "(", "pos", ")", "# search where this character begins", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.Search.__init__": [[20, 29], ["torch.Module.__init__", "tgt_dict.pad", "tgt_dict.unk", "tgt_dict.eos", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["    ", "def", "__init__", "(", "self", ",", "tgt_dict", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pad", "=", "tgt_dict", ".", "pad", "(", ")", "\n", "self", ".", "unk", "=", "tgt_dict", ".", "unk", "(", ")", "\n", "self", ".", "eos", "=", "tgt_dict", ".", "eos", "(", ")", "\n", "self", ".", "vocab_size", "=", "len", "(", "tgt_dict", ")", "\n", "self", ".", "src_lengths", "=", "torch", ".", "tensor", "(", "-", "1", ")", "\n", "self", ".", "supports_constraints", "=", "False", "\n", "self", ".", "stop_on_max_len", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.Search.step": [[30, 59], ["None"], "methods", ["None"], ["", "def", "step", "(", "\n", "self", ",", "step", ",", "lprobs", ",", "scores", ",", "prev_output_tokens", "=", "None", ",", "original_batch_idxs", "=", "None", "\n", ")", ":", "\n", "        ", "\"\"\"Take a single search step.\n\n        Args:\n            step: the current search step, starting at 0\n            lprobs: (bsz x input_beam_size x vocab_size)\n                the model's log-probabilities over the vocabulary at the current step\n            scores: (bsz x input_beam_size x step)\n                the historical model scores of each hypothesis up to this point\n            prev_output_tokens: (bsz x step)\n                the previously generated oputput tokens\n            original_batch_idxs: (bsz)\n                the tensor with the batch indices, in the range [0, bsz)\n                this is useful in case there has been applied a re-ordering\n                and we need to know the orignal indices\n\n        Return: A tuple of (scores, indices, beams) where:\n            scores: (bsz x output_beam_size)\n                the scores of the chosen elements; output_beam_size can be\n                larger than input_beam_size, e.g., we may return\n                2*input_beam_size to account for EOS\n            indices: (bsz x output_beam_size)\n                the indices of the chosen elements\n            beams: (bsz x output_beam_size)\n                the hypothesis ids of the chosen elements, in the range [0, input_beam_size)\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.Search.set_src_lengths": [[60, 63], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "set_src_lengths", "(", "self", ",", "src_lengths", ")", ":", "\n", "        ", "self", ".", "src_lengths", "=", "src_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.Search.init_constraints": [[64, 77], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "init_constraints", "(", "self", ",", "batch_constraints", ":", "Optional", "[", "Tensor", "]", ",", "beam_size", ":", "int", ")", ":", "\n", "        ", "\"\"\"Initialize constraint states for constrained decoding (if supported).\n\n        Args:\n            batch_constraints: (torch.Tensor, optional)\n                the list of constraints, in packed form\n            beam_size: (int)\n                the beam size\n        Returns:\n            *encoder_out* rearranged according to *new_order*\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.Search.prune_sentences": [[78, 88], ["None"], "methods", ["None"], ["", "def", "prune_sentences", "(", "self", ",", "batch_idxs", ":", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Removes constraint states for completed sentences (if supported).\n        This is called from sequence_generator._generate() when sentences are\n        deleted from the batch.\n\n        Args:\n            batch_idxs: Indices of *sentences* whose constraint state should be *kept*.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.Search.update_constraints": [[89, 101], ["None"], "methods", ["None"], ["", "def", "update_constraints", "(", "self", ",", "active_hypos", ":", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Updates the constraint states by selecting the beam items that are retained.\n        This is called at each time step of sequence_generator._generate() when\n        the set of 2 * {beam_size} candidate hypotheses are reduced to the beam size.\n\n        Args:\n            active_hypos: (batch size, beam size)\n              list of integers denoting, for each sentence, which beam candidate items\n              should be kept.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.BeamSearch.__init__": [[104, 107], ["search.Search.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "tgt_dict", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tgt_dict", ")", "\n", "self", ".", "constraint_states", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.BeamSearch.step": [[108, 145], ["lprobs[].contiguous.size", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "indices_buf.fmod.fmod.fmod", "lprobs[].contiguous", "lprobs[].contiguous.view", "scores[].unsqueeze", "min", "lprobs[].contiguous.view().size", "lprobs[].contiguous.view"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "step", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "lprobs", ",", "\n", "scores", ":", "Optional", "[", "Tensor", "]", ",", "\n", "prev_output_tokens", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "original_batch_idxs", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "bsz", ",", "beam_size", ",", "vocab_size", "=", "lprobs", ".", "size", "(", ")", "\n", "\n", "if", "step", "==", "0", ":", "\n", "# at the first step all hypotheses are equally likely, so use", "\n", "# only the first beam", "\n", "            ", "lprobs", "=", "lprobs", "[", ":", ",", ":", ":", "beam_size", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "# make probs contain cumulative scores for each hypothesis", "\n", "            ", "assert", "scores", "is", "not", "None", "\n", "lprobs", "=", "lprobs", "+", "scores", "[", ":", ",", ":", ",", "step", "-", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "", "top_prediction", "=", "torch", ".", "topk", "(", "\n", "lprobs", ".", "view", "(", "bsz", ",", "-", "1", ")", ",", "\n", "k", "=", "min", "(", "\n", "# Take the best 2 x beam_size predictions. We'll choose the first", "\n", "# beam_size of these which don't predict eos to continue with.", "\n", "beam_size", "*", "2", ",", "\n", "lprobs", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "size", "(", "1", ")", "-", "1", ",", "# -1 so we never select pad", "\n", ")", ",", "\n", ")", "\n", "scores_buf", "=", "top_prediction", "[", "0", "]", "\n", "indices_buf", "=", "top_prediction", "[", "1", "]", "\n", "# Project back into relative indices and beams", "\n", "beams_buf", "=", "indices_buf", "//", "vocab_size", "\n", "indices_buf", "=", "indices_buf", ".", "fmod", "(", "vocab_size", ")", "\n", "\n", "# At this point, beams_buf and indices_buf are single-dim and contain relative indices", "\n", "return", "scores_buf", ",", "indices_buf", ",", "beams_buf", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.PrefixConstrainedBeamSearch.__init__": [[148, 152], ["search.Search.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "tgt_dict", ",", "prefix_allowed_tokens_fn", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tgt_dict", ")", "\n", "self", ".", "prefix_allowed_tokens_fn", "=", "prefix_allowed_tokens_fn", "\n", "self", ".", "stop_on_max_len", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.PrefixConstrainedBeamSearch.apply_mask": [[153, 167], ["original_batch_idxs.unsqueeze().repeat().flatten().tolist.unsqueeze().repeat().flatten().tolist.unsqueeze().repeat().flatten().tolist", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "enumerate", "zip", "original_batch_idxs.unsqueeze().repeat().flatten().tolist.unsqueeze().repeat().flatten().tolist.unsqueeze().repeat().flatten", "original_batch_idxs.unsqueeze().repeat().flatten().tolist.unsqueeze().repeat().flatten().tolist.unsqueeze().repeat", "search.PrefixConstrainedBeamSearch.prefix_allowed_tokens_fn", "original_batch_idxs.unsqueeze().repeat().flatten().tolist.unsqueeze().repeat().flatten().tolist.unsqueeze"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "apply_mask", "(", "self", ",", "x", ",", "prev_output_tokens", ",", "original_batch_idxs", ")", ":", "\n", "        ", "beam_size", "=", "x", ".", "shape", "[", "0", "]", "//", "original_batch_idxs", ".", "shape", "[", "0", "]", "\n", "original_batch_idxs", "=", "(", "\n", "original_batch_idxs", ".", "unsqueeze", "(", "-", "1", ")", ".", "repeat", "(", "(", "1", ",", "beam_size", ")", ")", ".", "flatten", "(", ")", ".", "tolist", "(", ")", "\n", ")", "\n", "\n", "mask", "=", "torch", ".", "full_like", "(", "x", ",", "-", "math", ".", "inf", ")", "\n", "for", "sent_i", ",", "(", "sent", ",", "batch_i", ")", "in", "enumerate", "(", "\n", "zip", "(", "prev_output_tokens", ",", "original_batch_idxs", ")", "\n", ")", ":", "\n", "            ", "mask", "[", "sent_i", ",", ":", ",", "self", ".", "prefix_allowed_tokens_fn", "(", "batch_i", ",", "sent", ")", "]", "=", "0", "\n", "\n", "", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.PrefixConstrainedBeamSearch.step": [[168, 208], ["lprobs[].contiguous.size", "search.PrefixConstrainedBeamSearch.apply_mask().view", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "indices_buf.fmod.fmod.fmod", "lprobs[].contiguous", "lprobs[].contiguous.view", "search.PrefixConstrainedBeamSearch.apply_mask", "scores[].unsqueeze", "min", "lprobs[].contiguous.view", "lprobs[].contiguous.view().size", "lprobs[].contiguous.view"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.data.mask_tokens_dataset.MaskTokensDataset.apply_mask", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "step", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "lprobs", ":", "Tensor", ",", "\n", "scores", ":", "Tensor", ",", "\n", "prev_output_tokens", ":", "Tensor", ",", "\n", "original_batch_idxs", ":", "Tensor", ",", "\n", ")", ":", "\n", "        ", "bsz", ",", "beam_size", ",", "vocab_size", "=", "lprobs", ".", "size", "(", ")", "\n", "\n", "lprobs", "+=", "self", ".", "apply_mask", "(", "\n", "lprobs", ".", "view", "(", "bsz", "*", "beam_size", ",", "1", ",", "vocab_size", ")", ",", "\n", "prev_output_tokens", ",", "\n", "original_batch_idxs", ",", "\n", ")", ".", "view", "(", "bsz", ",", "beam_size", ",", "vocab_size", ")", "\n", "\n", "if", "step", "==", "0", ":", "\n", "# at the first step all hypotheses are equally likely, so use", "\n", "# only the first beam", "\n", "            ", "lprobs", "=", "lprobs", "[", ":", ",", ":", ":", "beam_size", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "# make probs contain cumulative scores for each hypothesis", "\n", "            ", "assert", "scores", "is", "not", "None", "\n", "lprobs", "=", "lprobs", "+", "scores", "[", ":", ",", ":", ",", "step", "-", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "", "top_prediction", "=", "torch", ".", "topk", "(", "\n", "lprobs", ".", "view", "(", "bsz", ",", "-", "1", ")", ",", "\n", "k", "=", "min", "(", "\n", "# Take the best beam_size predictions. We'll choose the first", "\n", "# beam_size of these which don't predict eos to continue with.", "\n", "beam_size", ",", "\n", "lprobs", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "size", "(", "1", ")", "-", "1", ",", "# -1 so we never select pad", "\n", ")", ",", "\n", ")", "\n", "scores_buf", "=", "top_prediction", "[", "0", "]", "\n", "indices_buf", "=", "top_prediction", "[", "1", "]", "\n", "beams_buf", "=", "indices_buf", "//", "vocab_size", "\n", "indices_buf", "=", "indices_buf", ".", "fmod", "(", "vocab_size", ")", "\n", "return", "scores_buf", ",", "indices_buf", ",", "beams_buf", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.LexicallyConstrainedBeamSearch.__init__": [[229, 235], ["search.Search.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "tgt_dict", ",", "representation", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tgt_dict", ")", "\n", "self", ".", "representation", "=", "representation", "\n", "self", ".", "vocab_size", "=", "len", "(", "tgt_dict", ")", "\n", "self", ".", "num_cands", "=", "0", "\n", "self", ".", "supports_constraints", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.LexicallyConstrainedBeamSearch.init_constraints": [[236, 246], ["search.LexicallyConstrainedBeamSearch.constraint_states.append", "fairseq.token_generation_constraints.OrderedConstraintState.create", "fairseq.token_generation_constraints.UnorderedConstraintState.create", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.create", "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.create"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "init_constraints", "(", "self", ",", "batch_constraints", ":", "Optional", "[", "Tensor", "]", ",", "beam_size", ":", "int", ")", ":", "\n", "        ", "self", ".", "constraint_states", "=", "[", "]", "\n", "for", "constraint_tensor", "in", "batch_constraints", ":", "\n", "            ", "if", "self", ".", "representation", "==", "\"ordered\"", ":", "\n", "                ", "constraint_state", "=", "OrderedConstraintState", ".", "create", "(", "constraint_tensor", ")", "\n", "", "elif", "self", ".", "representation", "==", "\"unordered\"", ":", "\n", "                ", "constraint_state", "=", "UnorderedConstraintState", ".", "create", "(", "constraint_tensor", ")", "\n", "\n", "", "self", ".", "constraint_states", ".", "append", "(", "[", "constraint_state", "for", "i", "in", "range", "(", "beam_size", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.LexicallyConstrainedBeamSearch.prune_sentences": [[247, 251], ["batch_idxs.tolist"], "methods", ["None"], ["", "", "@", "torch", ".", "jit", ".", "export", "\n", "def", "prune_sentences", "(", "self", ",", "batch_idxs", ":", "Tensor", ")", ":", "\n", "        ", "self", ".", "constraint_states", "=", "[", "\n", "self", ".", "constraint_states", "[", "i", "]", "for", "i", "in", "batch_idxs", ".", "tolist", "(", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.LexicallyConstrainedBeamSearch.update_constraints": [[253, 260], ["active_hypos.size", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "update_constraints", "(", "self", ",", "active_hypos", ":", "Tensor", ")", ":", "\n", "        ", "if", "self", ".", "constraint_states", ":", "\n", "            ", "batch_size", "=", "active_hypos", ".", "size", "(", "0", ")", "\n", "for", "sentid", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "self", ".", "constraint_states", "[", "sentid", "]", "=", "[", "\n", "self", ".", "constraint_states", "[", "sentid", "]", "[", "i", "]", "for", "i", "in", "active_hypos", "[", "sentid", "]", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.LexicallyConstrainedBeamSearch.step": [[262, 379], ["lprobs[].contiguous.size", "min", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.cat.fmod", "torch.cat.fmod", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "enumerate", "enumerate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "lprobs[].contiguous", "lprobs[].contiguous.view", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "top_scores.view.view.view", "top_indices.view.view.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange().repeat", "torch.arange().repeat", "torch.arange().repeat", "torch.arange().repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "search.LexicallyConstrainedBeamSearch.step_sentence", "lprobs[].contiguous.view().size", "enumerate", "torch.tensor.numel", "torch.tensor.numel", "scores[].unsqueeze", "lprobs[].contiguous.view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "beams_buf[].clone", "indices_buf[].clone", "scores_buf[].clone", "lprobs[].contiguous.view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "lprobs[].contiguous.view", "torch.tensor.append", "torch.tensor.append"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.LexicallyConstrainedBeamSearch.step_sentence", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "", "", "@", "torch", ".", "jit", ".", "export", "\n", "def", "step", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "lprobs", ":", "Tensor", ",", "\n", "scores", ":", "Optional", "[", "Tensor", "]", ",", "\n", "prev_output_tokens", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "original_batch_idxs", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        A constrained step builds a large candidates list from the following:\n        - the top 2 * {beam_size} items over the whole beam\n        - for each item in the beam\n          - the top {each_k} (default 1)\n          - all next constraints\n        We then compute the constrained state of each beam item, and assign\n        stripe codes: 0 to the best in each bank, 1 to the 2nd-best, and so\n        on. We then sort by (stripe, score), and truncate the list at\n        2 * beam size.\n\n        Args:\n            step: the decoder step\n            lprobs: (batch size, beam size, target vocab)\n                the target-vocab distributions for each item in the beam.\n        Retrun: A tuple of (scores, indices, beams, constraints) where:\n            scores: (batch, output beam size)\n                the scores of the chosen elements\n            indices: (batch, output beam size)\n                the target vocab indices of the chosen elements\n            beams: (batch, output beam size)\n                the 0-indexed hypothesis ids of the chosen elements\n            constraints: (batch, output beam size)\n                the new constraint states\n        \"\"\"", "\n", "each_k", "=", "1", "\n", "device", "=", "lprobs", ".", "device", "\n", "\n", "batch_size", ",", "beam_size", ",", "vocab_size", "=", "lprobs", ".", "size", "(", ")", "\n", "\n", "self", ".", "num_cands", "=", "min", "(", "\n", "# Just take the k-best. We'll get another k from the 1-best from each", "\n", "# row, plus more from the constraints", "\n", "beam_size", "*", "2", ",", "\n", "lprobs", ".", "view", "(", "batch_size", ",", "-", "1", ")", ".", "size", "(", "1", ")", "-", "1", ",", "# -1 so we never select pad", "\n", ")", "\n", "\n", "# STEP 0: Preliminary. Prevent EOS for unfinished hyps across all batch items", "\n", "constraint_states", "=", "self", ".", "constraint_states", "\n", "if", "constraint_states", "and", "step", ">", "0", ":", "\n", "            ", "not_finished_indices", "=", "[", "]", "\n", "for", "sentno", ",", "sent_constraints", "in", "enumerate", "(", "constraint_states", ")", ":", "\n", "                ", "for", "beamno", ",", "state", "in", "enumerate", "(", "sent_constraints", ")", ":", "\n", "                    ", "index", "=", "sentno", "*", "beam_size", "+", "beamno", "\n", "if", "not", "state", ".", "finished", ":", "\n", "                        ", "not_finished_indices", ".", "append", "(", "index", ")", "\n", "", "", "", "not_finished_indices", "=", "torch", ".", "tensor", "(", "not_finished_indices", ")", "\n", "if", "not_finished_indices", ".", "numel", "(", ")", ">", "0", ":", "\n", "                ", "lprobs", ".", "view", "(", "batch_size", "*", "beam_size", ",", "-", "1", ")", "[", "\n", "not_finished_indices", ",", "self", ".", "eos", "\n", "]", "=", "-", "math", ".", "inf", "\n", "\n", "", "", "if", "step", "==", "0", ":", "\n", "# at the first step all hypotheses are equally likely, so use", "\n", "# only the first beam entry for each batch item", "\n", "            ", "lprobs", "=", "lprobs", "[", ":", ",", ":", ":", "beam_size", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "# make probs contain cumulative scores for each hypothesis", "\n", "            ", "assert", "scores", "is", "not", "None", "\n", "lprobs", "=", "lprobs", "+", "scores", "[", ":", ",", ":", ",", "step", "-", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "", "top_prediction", "=", "torch", ".", "topk", "(", "\n", "lprobs", ".", "view", "(", "batch_size", ",", "-", "1", ")", ",", "\n", "self", ".", "num_cands", ",", "\n", ")", "\n", "scores_buf", ",", "indices_buf", "=", "top_prediction", "\n", "# Project back into relative indices and beams", "\n", "beams_buf", "=", "indices_buf", "//", "vocab_size", "\n", "indices_buf", "=", "indices_buf", ".", "fmod", "(", "vocab_size", ")", "\n", "\n", "# Short circuit if there are no constraints in this batch", "\n", "if", "not", "constraint_states", ":", "\n", "            ", "return", "scores_buf", ",", "indices_buf", ",", "beams_buf", "\n", "\n", "# STEP 1: get top-1 from each hypothesis across all sentences in the batch", "\n", "", "if", "step", ">", "0", ":", "\n", "            ", "top_scores", ",", "top_indices", "=", "torch", ".", "topk", "(", "\n", "lprobs", ".", "view", "(", "batch_size", "*", "beam_size", ",", "-", "1", ")", ",", "\n", "k", "=", "each_k", ",", "\n", "dim", "=", "1", ",", "\n", ")", "\n", "top_scores", "=", "top_scores", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "top_indices", "=", "top_indices", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "scores_buf", "=", "torch", ".", "cat", "(", "(", "scores_buf", ",", "top_scores", ")", ",", "dim", "=", "1", ")", "\n", "indices_buf", "=", "torch", ".", "cat", "(", "(", "indices_buf", ",", "top_indices", ")", ",", "dim", "=", "1", ")", "\n", "new_beams", "=", "torch", ".", "arange", "(", "0", ",", "beam_size", ",", "device", "=", "device", ")", ".", "repeat", "(", "batch_size", ",", "1", ")", "\n", "beams_buf", "=", "torch", ".", "cat", "(", "(", "beams_buf", ",", "new_beams", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# Now, process sentences in the batch one by one.", "\n", "", "new_scores_buf", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "2", "*", "beam_size", ")", ",", "device", "=", "device", ")", "\n", "new_indices_buf", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "2", "*", "beam_size", ")", ",", "device", "=", "device", ")", ".", "long", "(", ")", "\n", "new_beams_buf", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "2", "*", "beam_size", ")", ",", "device", "=", "device", ")", ".", "long", "(", ")", "\n", "for", "sentno", ",", "states", "in", "enumerate", "(", "constraint_states", ")", ":", "\n", "            ", "scores", ",", "indices", ",", "beams", ",", "new_states", "=", "self", ".", "step_sentence", "(", "\n", "step", ",", "\n", "sentno", ",", "\n", "lprobs", "[", "sentno", "]", ",", "\n", "constraint_states", "[", "sentno", "]", ",", "\n", "beams_buf", "[", "sentno", "]", ".", "clone", "(", ")", ",", "\n", "indices_buf", "[", "sentno", "]", ".", "clone", "(", ")", ",", "\n", "scores_buf", "[", "sentno", "]", ".", "clone", "(", ")", ",", "\n", ")", "\n", "new_scores_buf", "[", "sentno", "]", "=", "scores", "\n", "new_indices_buf", "[", "sentno", "]", "=", "indices", "\n", "new_beams_buf", "[", "sentno", "]", "=", "beams", "\n", "self", ".", "constraint_states", "[", "sentno", "]", "=", "new_states", "\n", "\n", "", "return", "new_scores_buf", ",", "new_indices_buf", ",", "new_beams_buf", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.LexicallyConstrainedBeamSearch.step_sentence": [[380, 524], ["enumerate", "torch.cat.size", "torch.cat.size", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "sort_key.sort", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "enumerate", "torch.zeros_like.sort", "torch.zeros_like.sort", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "constraint_states[].advance", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "search.LexicallyConstrainedBeamSearch.step_sentence.roll"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.advance"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "step_sentence", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "sentno", ":", "int", ",", "\n", "lprobs", ":", "Tensor", ",", "\n", "constraint_states", ":", "List", "[", "List", "[", "ConstraintState", "]", "]", ",", "\n", "beams_buf", ":", "Tensor", ",", "\n", "indices_buf", ":", "Tensor", ",", "\n", "scores_buf", ":", "Tensor", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Does per-sentence processing. Adds all constraints for each\n        hypothesis to the list of candidates; then removes duplicates,\n        sorts, and dynamically stripes across the banks. All tensor inputs\n        are collapsed to those pertaining to a single input sentence.\n        \"\"\"", "\n", "device", "=", "lprobs", ".", "device", "\n", "\n", "# STEP 2: Add all constraints for each beam item", "\n", "for", "beamno", ",", "state", "in", "enumerate", "(", "constraint_states", ")", ":", "\n", "            ", "next_tokens", "=", "torch", ".", "tensor", "(", "list", "(", "state", ".", "next_tokens", "(", ")", ")", ",", "device", "=", "device", ")", ".", "long", "(", ")", "\n", "if", "next_tokens", ".", "numel", "(", ")", "!=", "0", ":", "\n", "                ", "indices_buf", "=", "torch", ".", "cat", "(", "(", "indices_buf", ",", "next_tokens", ")", ")", "\n", "next_beams", "=", "(", "\n", "torch", ".", "tensor", "(", "beamno", ",", "device", "=", "device", ")", "\n", ".", "repeat", "(", "next_tokens", ".", "size", "(", "0", ")", ")", "\n", ".", "long", "(", ")", "\n", ")", "\n", "beams_buf", "=", "torch", ".", "cat", "(", "(", "beams_buf", ",", "next_beams", ")", ")", "\n", "next_values", "=", "lprobs", "[", "beamno", "]", ".", "take", "(", "next_tokens", ".", "view", "(", "-", "1", ")", ")", "\n", "scores_buf", "=", "torch", ".", "cat", "(", "(", "scores_buf", ",", "next_values", ")", ")", "\n", "\n", "# At the 0th time step, there is just one beam item", "\n", "", "if", "step", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "# STEP 3: Compute the \"bank\" for each candidate. This is the", "\n", "# number of constraints it's generated. We need this so that", "\n", "# we can do round-robin allocation of the beam across these", "\n", "# banks. If C is the number of constraints, we select the best", "\n", "# item in bank C, then the best in bank C-1, etc, followed by", "\n", "# the 2nd-best in bank C, the 2nd-best in bank C-1, etc, and so", "\n", "# on, until the maximum beam size. We accomplish this by", "\n", "# creating a sort key and striping across the banks.", "\n", "\n", "# Compute the new states for all candidates", "\n", "", "", "cands_size", "=", "indices_buf", ".", "size", "(", "0", ")", "\n", "constraint_states", "=", "[", "\n", "constraint_states", "[", "beams_buf", "[", "i", "]", "]", ".", "advance", "(", "indices_buf", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "cands_size", ")", "\n", "]", "\n", "\n", "banks", "=", "torch", ".", "tensor", "(", "[", "state", ".", "bank", "for", "state", "in", "constraint_states", "]", ",", "device", "=", "device", ")", "\n", "\n", "# STEP 4: Sort", "\n", "num_constraint_tokens", "=", "len", "(", "state", ".", "tokens", ")", "\n", "\n", "# Sort by keys (bank, score) (i.e., sort banks together, and scores", "\n", "# within banks). AFAIK pytorch doesn't support either stable sort or", "\n", "# multi-key sorting, so we have to hack this.", "\n", "MAX_SCORE", "=", "-", "100", "\n", "sort_key", "=", "(", "num_constraint_tokens", "-", "banks", ")", "*", "MAX_SCORE", "+", "scores_buf", "\n", "sort_values", ",", "sort_indices", "=", "sort_key", ".", "sort", "(", "dim", "=", "0", ",", "descending", "=", "True", ")", "\n", "scores_buf", "=", "scores_buf", "[", "sort_indices", "]", "\n", "indices_buf", "=", "indices_buf", "[", "sort_indices", "]", "\n", "beams_buf", "=", "beams_buf", "[", "sort_indices", "]", "\n", "banks", "=", "banks", "[", "sort_indices", "]", "\n", "\n", "# Sort the constraints to follow suit", "\n", "constraint_states", "=", "[", "constraint_states", "[", "i", "]", "for", "i", "in", "sort_indices", "]", "\n", "\n", "# STEP 5: Remove duplicates. The topk calls (overall and", "\n", "# per-row) plus the per-row generation of constraints will", "\n", "# produce duplicates. Here we remove them.", "\n", "\n", "def", "roll", "(", "t", ")", ":", "\n", "            ", "\"\"\"Rolls a 1d tensor left by 1.\n\n            [0, 1, 2, 3, 4] becomes [4, 0, 1, 2, 3]\n            \"\"\"", "\n", "return", "torch", ".", "cat", "(", "(", "t", "[", "-", "1", "]", ".", "unsqueeze", "(", "0", ")", ",", "t", "[", "0", ":", "-", "1", "]", ")", ",", "dim", "=", "0", ")", "\n", "\n", "# We map candidates (beam, token_id) to a single dimension.", "\n", "# This is then shifted by 1. We can then easily identify", "\n", "# duplicates and create a mask that identifies unique", "\n", "# extensions.", "\n", "", "uniques_mask", "=", "beams_buf", "*", "(", "self", ".", "vocab_size", "+", "1", ")", "+", "indices_buf", "\n", "uniques_mask", "=", "roll", "(", "uniques_mask", ")", "!=", "uniques_mask", "\n", "\n", "# Use the mask to pare down the data structures", "\n", "scores_buf", "=", "torch", ".", "masked_select", "(", "scores_buf", ",", "uniques_mask", ")", "\n", "indices_buf", "=", "torch", ".", "masked_select", "(", "indices_buf", ",", "uniques_mask", ")", "\n", "beams_buf", "=", "torch", ".", "masked_select", "(", "beams_buf", ",", "uniques_mask", ")", "\n", "banks", "=", "torch", ".", "masked_select", "(", "banks", ",", "uniques_mask", ")", "\n", "i", "=", "1", "\n", "for", "mask", "in", "uniques_mask", "[", "1", ":", "]", ":", "\n", "            ", "if", "not", "mask", ":", "\n", "                ", "constraint_states", ".", "pop", "(", "i", ")", "\n", "", "i", "+=", "mask", "\n", "\n", "# STEP 6: Assign IDs round-robin across banks, sort, and", "\n", "# truncate. Now that the candidates are sorted by (bank,", "\n", "# score) and uniqed, we dynamically allocate the {beam_size}", "\n", "# beam by striping across the candidates. These stripes will", "\n", "# be used as sort keys to do round-robin selection. This is", "\n", "# accomplished in a single pass with offsets. Sorting by", "\n", "# highest-banks (furthest-along hypotheses) first ensures", "\n", "# progress through the constraints.", "\n", "#", "\n", "# e.g., BANKS: 3 3 3 2 2 2 2 1 1 1 0 0", "\n", "# OLD STRIPES: 0 1 2 0 1 2 3 0 1 2 0 1", "\n", "# NEW STRIPES: 0 1+4 2+8 0+1 1+5 2+9 3+11 0+2 1+6 2+10 0+3 1+7", "\n", "#            = 0 5 10 1 6 11 13 2 7 12 3 8", "\n", "#", "\n", "# Sorting by this then gives the following banks:", "\n", "#", "\n", "#             3 2 1 0 3 2 1 0 3 2 1 2", "\n", "#", "\n", "# We'll take the top {beam_size} of these.", "\n", "", "stripe_offsets", "=", "[", "offset", "*", "(", "len", "(", "banks", ")", "+", "1", ")", "for", "offset", "in", "range", "(", "len", "(", "banks", ")", "+", "1", ")", "]", "\n", "stripes", "=", "torch", ".", "zeros_like", "(", "banks", ")", "\n", "cur_bank_count", "=", "-", "1", "\n", "cur_bank", "=", "banks", "[", "0", "]", "\n", "for", "i", ",", "bank", "in", "enumerate", "(", "banks", ")", ":", "\n", "            ", "if", "bank", "!=", "cur_bank", ":", "\n", "                ", "cur_bank_count", "=", "0", "\n", "cur_bank", "=", "bank", "\n", "", "else", ":", "\n", "                ", "cur_bank_count", "+=", "1", "\n", "", "stripes", "[", "i", "]", "=", "num_constraint_tokens", "-", "bank", "+", "stripe_offsets", "[", "cur_bank_count", "]", "\n", "\n", "# STEP 7: Sort by the stripes values", "\n", "", "sort_values", ",", "sort_indices", "=", "stripes", ".", "sort", "(", "dim", "=", "0", ")", "\n", "scores_buf", "=", "scores_buf", "[", "sort_indices", "]", "\n", "indices_buf", "=", "indices_buf", "[", "sort_indices", "]", "\n", "beams_buf", "=", "beams_buf", "[", "sort_indices", "]", "\n", "constraint_states", "=", "[", "constraint_states", "[", "i", "]", "for", "i", "in", "sort_indices", "]", "\n", "\n", "# STEP 8: Truncate to the candidates size!", "\n", "scores_buf", "=", "scores_buf", "[", ":", "self", ".", "num_cands", "]", "\n", "indices_buf", "=", "indices_buf", "[", ":", "self", ".", "num_cands", "]", "\n", "beams_buf", "=", "beams_buf", "[", ":", "self", ".", "num_cands", "]", "\n", "\n", "return", "scores_buf", ",", "indices_buf", ",", "beams_buf", ",", "constraint_states", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.LengthConstrainedBeamSearch.__init__": [[527, 535], ["search.Search.__init__", "search.BeamSearch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "tgt_dict", ",", "min_len_a", ",", "min_len_b", ",", "max_len_a", ",", "max_len_b", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tgt_dict", ")", "\n", "self", ".", "min_len_a", "=", "min_len_a", "\n", "self", ".", "min_len_b", "=", "min_len_b", "\n", "self", ".", "max_len_a", "=", "max_len_a", "\n", "self", ".", "max_len_b", "=", "max_len_b", "\n", "self", ".", "beam", "=", "BeamSearch", "(", "tgt_dict", ")", "\n", "self", ".", "needs_src_lengths", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.LengthConstrainedBeamSearch.step": [[536, 549], ["search.LengthConstrainedBeamSearch.beam.step"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step"], ["", "def", "step", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "lprobs", ",", "\n", "scores", ",", "\n", "prev_output_tokens", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "original_batch_idxs", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "min_lens", "=", "self", ".", "min_len_a", "*", "self", ".", "src_lengths", "+", "self", ".", "min_len_b", "\n", "max_lens", "=", "self", ".", "max_len_a", "*", "self", ".", "src_lengths", "+", "self", ".", "max_len_b", "\n", "lprobs", "[", "step", "<", "min_lens", ",", ":", ",", "self", ".", "eos", "]", "=", "-", "math", ".", "inf", "\n", "lprobs", "[", "step", ">=", "max_lens", ",", ":", ",", "self", ".", "eos", "]", "=", "0", "\n", "return", "self", ".", "beam", ".", "step", "(", "step", ",", "lprobs", ",", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.DiverseBeamSearch.__init__": [[561, 566], ["search.Search.__init__", "search.BeamSearch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "tgt_dict", ",", "num_groups", ",", "diversity_strength", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tgt_dict", ")", "\n", "self", ".", "num_groups", "=", "num_groups", "\n", "self", ".", "diversity_strength", "=", "-", "diversity_strength", "\n", "self", ".", "beam", "=", "BeamSearch", "(", "tgt_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.DiverseBeamSearch.step": [[567, 619], ["lprobs.size", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "ValueError", "search.DiverseBeamSearch.beam.step", "torch.stack().view.mul_().add_", "torch.stack().view.mul_().add_", "scores_G.append", "indices_G.append", "beams_G.append", "torch.zeros().to.scatter_add_", "torch.zeros().to.scatter_add_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.add", "torch.add", "torch.add", "torch.add", "lprobs_g.contiguous.contiguous.contiguous", "torch.stack().view.clone", "torch.stack().view.clone", "torch.stack().view.clone", "torch.stack().view.clone", "torch.stack().view.clone", "torch.stack().view.clone", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "lprobs[].size", "torch.stack().view.mul_", "torch.stack().view.mul_", "torch.zeros().to.unsqueeze", "torch.zeros().to.unsqueeze", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.stack().view.size", "torch.stack().view.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "step", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "lprobs", ",", "\n", "scores", ",", "\n", "prev_output_tokens", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "original_batch_idxs", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "bsz", ",", "beam_size", ",", "vocab_size", "=", "lprobs", ".", "size", "(", ")", "\n", "if", "beam_size", "%", "self", ".", "num_groups", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"DiverseBeamSearch requires --beam to be divisible by the number of groups\"", "\n", ")", "\n", "\n", "# initialize diversity penalty", "\n", "", "diversity_buf", "=", "torch", ".", "zeros", "(", "lprobs", "[", ":", ",", "0", ",", ":", "]", ".", "size", "(", ")", ")", ".", "to", "(", "lprobs", ")", "\n", "\n", "scores_G", ",", "indices_G", ",", "beams_G", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "g", "in", "range", "(", "self", ".", "num_groups", ")", ":", "\n", "            ", "lprobs_g", "=", "lprobs", "[", ":", ",", "g", ":", ":", "self", ".", "num_groups", ",", ":", "]", "\n", "scores_g", "=", "scores", "[", ":", ",", "g", ":", ":", "self", ".", "num_groups", ",", ":", "]", "if", "step", ">", "0", "else", "None", "\n", "\n", "# apply diversity penalty", "\n", "if", "g", ">", "0", ":", "\n", "                ", "lprobs_g", "=", "torch", ".", "add", "(", "\n", "lprobs_g", ",", "\n", "other", "=", "diversity_buf", ".", "unsqueeze", "(", "1", ")", ",", "\n", "alpha", "=", "self", ".", "diversity_strength", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "lprobs_g", "=", "lprobs_g", ".", "contiguous", "(", ")", "\n", "\n", "", "scores_buf", ",", "indices_buf", ",", "beams_buf", "=", "self", ".", "beam", ".", "step", "(", "\n", "step", ",", "lprobs_g", ",", "scores_g", "\n", ")", "\n", "beams_buf", ".", "mul_", "(", "self", ".", "num_groups", ")", ".", "add_", "(", "g", ")", "\n", "\n", "scores_G", ".", "append", "(", "scores_buf", ".", "clone", "(", ")", ")", "\n", "indices_G", ".", "append", "(", "indices_buf", ".", "clone", "(", ")", ")", "\n", "beams_G", ".", "append", "(", "beams_buf", ".", "clone", "(", ")", ")", "\n", "\n", "# update diversity penalty", "\n", "diversity_buf", ".", "scatter_add_", "(", "\n", "1", ",", "indices_buf", ",", "torch", ".", "ones", "(", "indices_buf", ".", "size", "(", ")", ")", ".", "to", "(", "diversity_buf", ")", "\n", ")", "\n", "\n", "# interleave results from different groups", "\n", "", "scores_buf", "=", "torch", ".", "stack", "(", "scores_G", ",", "dim", "=", "2", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", "\n", "indices_buf", "=", "torch", ".", "stack", "(", "indices_G", ",", "dim", "=", "2", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", "\n", "beams_buf", "=", "torch", ".", "stack", "(", "beams_G", ",", "dim", "=", "2", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", "\n", "return", "scores_buf", ",", "indices_buf", ",", "beams_buf", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.Sampling.__init__": [[625, 629], ["search.Search.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "tgt_dict", ",", "sampling_topk", "=", "-", "1", ",", "sampling_topp", "=", "-", "1.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tgt_dict", ")", "\n", "self", ".", "sampling_topk", "=", "sampling_topk", "\n", "self", ".", "sampling_topp", "=", "sampling_topp", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.Sampling._sample_topp": [[630, 674], ["lprobs.exp_", "lprobs.exp_.sort", "sorted_probs.cumsum", "sorted_probs.cumsum.lt", "mask.scatter_.scatter_.cumsum", "last_included.clamp_", "mask.scatter_.scatter_.scatter_", "last_included.max", "truncated_probs.masked_fill_", "mask.scatter_.scatter_.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.cumsum", "home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.cumsum", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "_sample_topp", "(", "self", ",", "lprobs", ")", ":", "\n", "        ", "\"\"\"Sample among the smallest set of elements whose cumulative probability mass exceeds p.\n\n        See `\"The Curious Case of Neural Text Degeneration\"\n        (Holtzman et al., 2019) <https://arxiv.org/abs/1904.09751>`_.\n\n        Args:\n            lprobs: (bsz x input_beam_size x vocab_size)\n                the model's log-probabilities over the vocabulary at the current step\n\n        Return: A tuple of (trimed_probs, truncated_indices) where:\n            trimed_probs: (bsz x input_beam_size x ?)\n                the model's probabilities over the elements selected to sample from. The\n                width of the third dimension is determined by top-P.\n            truncated_indices: (bsz x input_beam_size x ?)\n                the indices of the chosen elements.\n        \"\"\"", "\n", "probs", "=", "lprobs", ".", "exp_", "(", ")", "\n", "\n", "# sort the last dimension (vocab dimension) in descending order", "\n", "sorted_probs", ",", "sorted_indices", "=", "probs", ".", "sort", "(", "descending", "=", "True", ")", "\n", "\n", "# compute a mask to indicate the words to be included in the top-P set.", "\n", "cumsum_probs", "=", "sorted_probs", ".", "cumsum", "(", "dim", "=", "2", ")", "\n", "mask", "=", "cumsum_probs", ".", "lt", "(", "self", ".", "sampling_topp", ")", "\n", "\n", "# note that mask was computed by 'lt'. One more word needs to be included", "\n", "# so that the cumulative probability mass can exceed p.", "\n", "cumsum_mask", "=", "mask", ".", "cumsum", "(", "dim", "=", "2", ")", "\n", "last_included", "=", "cumsum_mask", "[", ":", ",", ":", ",", "-", "1", ":", "]", "\n", "last_included", ".", "clamp_", "(", "0", ",", "mask", ".", "size", "(", ")", "[", "2", "]", "-", "1", ")", "\n", "mask", "=", "mask", ".", "scatter_", "(", "2", ",", "last_included", ",", "1", ")", "\n", "\n", "# truncate unnecessary dims.", "\n", "max_dim", "=", "last_included", ".", "max", "(", ")", "\n", "truncated_mask", "=", "mask", "[", ":", ",", ":", ",", ":", "max_dim", "+", "1", "]", "\n", "truncated_probs", "=", "sorted_probs", "[", ":", ",", ":", ",", ":", "max_dim", "+", "1", "]", "\n", "truncated_indices", "=", "sorted_indices", "[", ":", ",", ":", ",", ":", "max_dim", "+", "1", "]", "\n", "\n", "# trim the words that are not in top-P by setting their probabilities", "\n", "# to 0, so that they would not be sampled later.", "\n", "trim_mask", "=", "~", "truncated_mask", "\n", "trimed_probs", "=", "truncated_probs", ".", "masked_fill_", "(", "trim_mask", ",", "0", ")", "\n", "return", "trimed_probs", ",", "truncated_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.Sampling.step": [[675, 743], ["lprobs[].contiguous.size", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "scores_buf.log_().view.log_().view.log_().view", "lprobs[].contiguous", "search.Sampling._sample_topp", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "lprobs[].contiguous.exp_.expand", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze.new_zeros", "torch.gather().squeeze.new_zeros", "torch.arange().to().repeat", "torch.arange().to().repeat", "torch.arange().to().repeat", "torch.arange().to().repeat", "scores_buf.log_().view.log_().view.add_", "lprobs[].contiguous.topk", "lprobs[].contiguous.exp_", "lprobs[].contiguous.exp_", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.gather().squeeze.unsqueeze", "torch.gather().squeeze.unsqueeze", "scores_buf.log_().view.log_().view.log_", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "lprobs[].contiguous.exp_.view", "lprobs[].contiguous.exp_.view", "torch.empty().to.expand", "torch.empty().to.expand", "torch.gather().squeeze.unsqueeze", "torch.gather().squeeze.unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.Sampling._sample_topp"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "step", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "lprobs", ",", "\n", "scores", ",", "\n", "prev_output_tokens", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "original_batch_idxs", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "bsz", ",", "beam_size", ",", "vocab_size", "=", "lprobs", ".", "size", "(", ")", "\n", "\n", "if", "step", "==", "0", ":", "\n", "# at the first step all hypotheses are equally likely, so use", "\n", "# only the first beam", "\n", "            ", "lprobs", "=", "lprobs", "[", ":", ",", ":", ":", "beam_size", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "\n", "", "if", "self", ".", "sampling_topp", ">", "0", ":", "\n", "# only sample from the smallest set of words whose cumulative probability mass exceeds p", "\n", "            ", "probs", ",", "top_indices", "=", "self", ".", "_sample_topp", "(", "lprobs", ")", "\n", "", "elif", "self", ".", "sampling_topk", ">", "0", ":", "\n", "# only sample from top-k candidates", "\n", "            ", "lprobs", ",", "top_indices", "=", "lprobs", ".", "topk", "(", "self", ".", "sampling_topk", ")", "\n", "probs", "=", "lprobs", ".", "exp_", "(", ")", "\n", "", "else", ":", "\n", "            ", "probs", "=", "lprobs", ".", "exp_", "(", ")", "\n", "\n", "# dummy data to be consistent with true branch for type check", "\n", "top_indices", "=", "torch", ".", "empty", "(", "0", ")", ".", "to", "(", "probs", ")", "\n", "# sample", "\n", "", "if", "step", "==", "0", ":", "\n", "            ", "indices_buf", "=", "torch", ".", "multinomial", "(", "\n", "probs", ".", "view", "(", "bsz", ",", "-", "1", ")", ",", "\n", "beam_size", ",", "\n", "replacement", "=", "True", ",", "\n", ")", ".", "view", "(", "bsz", ",", "beam_size", ")", "\n", "", "else", ":", "\n", "            ", "indices_buf", "=", "torch", ".", "multinomial", "(", "\n", "probs", ".", "view", "(", "bsz", "*", "beam_size", ",", "-", "1", ")", ",", "\n", "1", ",", "\n", "replacement", "=", "True", ",", "\n", ")", ".", "view", "(", "bsz", ",", "beam_size", ")", "\n", "\n", "", "if", "step", "==", "0", ":", "\n", "# expand to beam size", "\n", "            ", "probs", "=", "probs", ".", "expand", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", "\n", "\n", "# gather scores", "\n", "", "scores_buf", "=", "torch", ".", "gather", "(", "probs", ",", "dim", "=", "2", ",", "index", "=", "indices_buf", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "scores_buf", "=", "scores_buf", ".", "log_", "(", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", "\n", "\n", "# remap indices if using top-k or top-P sampling", "\n", "if", "self", ".", "sampling_topk", ">", "0", "or", "self", ".", "sampling_topp", ">", "0", ":", "\n", "            ", "indices_buf", "=", "torch", ".", "gather", "(", "\n", "top_indices", ".", "expand", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", ",", "\n", "dim", "=", "2", ",", "\n", "index", "=", "indices_buf", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", ")", ".", "squeeze", "(", "2", ")", "\n", "\n", "", "if", "step", "==", "0", ":", "\n", "            ", "beams_buf", "=", "indices_buf", ".", "new_zeros", "(", "bsz", ",", "beam_size", ")", "\n", "", "else", ":", "\n", "            ", "beams_buf", "=", "torch", ".", "arange", "(", "0", ",", "beam_size", ")", ".", "to", "(", "indices_buf", ")", ".", "repeat", "(", "bsz", ",", "1", ")", "\n", "# make scores cumulative", "\n", "scores_buf", ".", "add_", "(", "\n", "torch", ".", "gather", "(", "scores", "[", ":", ",", ":", ",", "step", "-", "1", "]", ",", "dim", "=", "1", ",", "index", "=", "beams_buf", ")", "\n", ")", "\n", "\n", "", "return", "scores_buf", ",", "indices_buf", ",", "beams_buf", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.DiverseSiblingsSearch.__init__": [[760, 764], ["search.Search.__init__", "search.BeamSearch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "tgt_dict", ",", "diversity_rate", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tgt_dict", ")", "\n", "self", ".", "diversity_rate", "=", "diversity_rate", "\n", "self", ".", "beam", "=", "BeamSearch", "(", "tgt_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.DiverseSiblingsSearch.step": [[765, 815], ["lprobs.size", "min", "lprobs.add_", "range", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "range", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "search.DiverseSiblingsSearch.beam.step", "scores[].unsqueeze", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "i_list[].fmod_", "s_list[].sub_", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "lprobs.view().size", "range", "range", "lprobs[].view", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "lprobs.view"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "step", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "lprobs", ",", "\n", "scores", ",", "\n", "prev_output_tokens", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "original_batch_idxs", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "bsz", ",", "beam_size", ",", "vocab_size", "=", "lprobs", ".", "size", "(", ")", "\n", "k", "=", "min", "(", "\n", "# Take the best 2 x beam_size predictions. We'll choose the first", "\n", "# beam_size of these which don't predict eos to continue with.", "\n", "beam_size", "*", "2", ",", "\n", "lprobs", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "size", "(", "1", ")", "-", "1", ",", "# -1 so we never select pad", "\n", ")", "\n", "s_list", ":", "List", "[", "Tensor", "]", "\n", "i_list", ":", "List", "[", "Tensor", "]", "\n", "s_list", "=", "[", "torch", ".", "empty", "(", "0", ")", ".", "to", "(", "lprobs", ")", "for", "i", "in", "range", "(", "beam_size", ")", "]", "\n", "i_list", "=", "[", "torch", ".", "LongTensor", "(", ")", ".", "to", "(", "device", "=", "lprobs", ".", "device", ")", "for", "i", "in", "range", "(", "beam_size", ")", "]", "\n", "sibling_score", "=", "torch", ".", "arange", "(", "1", ",", "k", "+", "1", ")", ".", "to", "(", "lprobs", ")", "*", "self", ".", "diversity_rate", "\n", "\n", "if", "step", "==", "0", ":", "\n", "            ", "return", "self", ".", "beam", ".", "step", "(", "step", ",", "lprobs", ",", "scores", ")", "\n", "", "lprobs", ".", "add_", "(", "scores", "[", ":", ",", ":", ",", "step", "-", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "\n", "# 1/ Calculate hypotheses for each beam", "\n", "for", "i", "in", "range", "(", "beam_size", ")", ":", "\n", "            ", "torch", ".", "topk", "(", "lprobs", "[", ":", ",", "i", ",", ":", "]", ".", "view", "(", "bsz", ",", "-", "1", ")", ",", "k", ",", "out", "=", "(", "s_list", "[", "i", "]", ",", "i_list", "[", "i", "]", ")", ")", "\n", "i_list", "[", "i", "]", ".", "fmod_", "(", "vocab_size", ")", "\n", "\n", "# 2/ Intra-sibling ordering by default from topk + 3/ Rewrite scores", "\n", "s_list", "[", "i", "]", ".", "sub_", "(", "sibling_score", ")", "\n", "\n", "# 4/ Choose top K hypotheses", "\n", "", "indices", "=", "torch", ".", "stack", "(", "i_list", ",", "dim", "=", "1", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", "\n", "\n", "final_scores", "=", "torch", ".", "empty", "(", "0", ")", ".", "to", "(", "lprobs", ")", "\n", "final_indices", "=", "torch", ".", "LongTensor", "(", ")", ".", "to", "(", "device", "=", "lprobs", ".", "device", ")", "\n", "final_beams", "=", "torch", ".", "LongTensor", "(", ")", ".", "to", "(", "device", "=", "lprobs", ".", "device", ")", "\n", "(", "final_scores", ",", "final_indices", ")", "=", "torch", ".", "topk", "(", "\n", "torch", ".", "stack", "(", "s_list", ",", "dim", "=", "1", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", ",", "\n", "k", ",", "\n", ")", "\n", "\n", "final_beams", "=", "final_indices", "//", "k", "\n", "\n", "for", "i", "in", "range", "(", "bsz", ")", ":", "\n", "            ", "final_indices", "[", "i", "]", "=", "indices", "[", "i", "]", "[", "final_indices", "[", "i", "]", "]", "\n", "\n", "", "return", "final_scores", ",", "final_indices", ",", "final_beams", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.iterative_refinement_generator.IterativeRefinementGenerator.__init__": [[20, 61], ["tgt_dict.bos", "tgt_dict.pad", "tgt_dict.unk", "tgt_dict.eos", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "tgt_dict", ",", "\n", "models", "=", "None", ",", "\n", "eos_penalty", "=", "0.0", ",", "\n", "max_iter", "=", "10", ",", "\n", "max_ratio", "=", "2", ",", "\n", "beam_size", "=", "1", ",", "\n", "decoding_format", "=", "None", ",", "\n", "retain_dropout", "=", "False", ",", "\n", "adaptive", "=", "True", ",", "\n", "retain_history", "=", "False", ",", "\n", "reranking", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Generates translations based on iterative refinement.\n\n        Args:\n            tgt_dict: target dictionary\n            eos_penalty: if > 0.0, it penalized early-stopping in decoding\n            max_iter: maximum number of refinement iterations\n            max_ratio: generate sequences of maximum length ax, where x is the source length\n            decoding_format: decoding mode in {'unigram', 'ensemble', 'vote', 'dp', 'bs'}\n            retain_dropout: retaining dropout in the inference\n            adaptive: decoding with early stop\n        \"\"\"", "\n", "self", ".", "bos", "=", "tgt_dict", ".", "bos", "(", ")", "\n", "self", ".", "pad", "=", "tgt_dict", ".", "pad", "(", ")", "\n", "self", ".", "unk", "=", "tgt_dict", ".", "unk", "(", ")", "\n", "self", ".", "eos", "=", "tgt_dict", ".", "eos", "(", ")", "\n", "self", ".", "vocab_size", "=", "len", "(", "tgt_dict", ")", "\n", "self", ".", "eos_penalty", "=", "eos_penalty", "\n", "self", ".", "max_iter", "=", "max_iter", "\n", "self", ".", "max_ratio", "=", "max_ratio", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "self", ".", "reranking", "=", "reranking", "\n", "self", ".", "decoding_format", "=", "decoding_format", "\n", "self", ".", "retain_dropout", "=", "retain_dropout", "\n", "self", ".", "retain_history", "=", "retain_history", "\n", "self", ".", "adaptive", "=", "adaptive", "\n", "self", ".", "models", "=", "models", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.iterative_refinement_generator.IterativeRefinementGenerator.generate_batched_itr": [[62, 100], ["enumerate", "timer.start", "torch.no_grad", "iterative_refinement_generator.IterativeRefinementGenerator.generate", "timer.stop", "fairseq.utils.strip_pad", "fairseq.utils.strip_pad"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.start", "home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.generate", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.stop", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.strip_pad", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.strip_pad"], ["", "def", "generate_batched_itr", "(", "\n", "self", ",", "\n", "data_itr", ",", "\n", "maxlen_a", "=", "None", ",", "\n", "maxlen_b", "=", "None", ",", "\n", "cuda", "=", "False", ",", "\n", "timer", "=", "None", ",", "\n", "prefix_size", "=", "0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Iterate over a batched dataset and yield individual translations.\n\n        Args:\n            maxlen_a/b: generate sequences of maximum length ax + b,\n                where x is the source sentence length.\n            cuda: use GPU for generation\n            timer: StopwatchMeter for timing generations.\n        \"\"\"", "\n", "\n", "for", "sample", "in", "data_itr", ":", "\n", "            ", "if", "\"net_input\"", "not", "in", "sample", ":", "\n", "                ", "continue", "\n", "", "if", "timer", "is", "not", "None", ":", "\n", "                ", "timer", ".", "start", "(", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "hypos", "=", "self", ".", "generate", "(", "\n", "self", ".", "models", ",", "\n", "sample", ",", "\n", "prefix_tokens", "=", "sample", "[", "\"target\"", "]", "[", ":", ",", ":", "prefix_size", "]", "\n", "if", "prefix_size", ">", "0", "\n", "else", "None", ",", "\n", ")", "\n", "", "if", "timer", "is", "not", "None", ":", "\n", "                ", "timer", ".", "stop", "(", "sample", "[", "\"ntokens\"", "]", ")", "\n", "", "for", "i", ",", "id", "in", "enumerate", "(", "sample", "[", "\"id\"", "]", ")", ":", "\n", "# remove padding", "\n", "                ", "src", "=", "utils", ".", "strip_pad", "(", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "[", "i", ",", ":", "]", ",", "self", ".", "pad", ")", "\n", "ref", "=", "utils", ".", "strip_pad", "(", "sample", "[", "\"target\"", "]", "[", "i", ",", ":", "]", ",", "self", ".", "pad", ")", "\n", "yield", "id", ",", "src", ",", "ref", ",", "hypos", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.iterative_refinement_generator.IterativeRefinementGenerator.generate": [[101, 312], ["torch.no_grad", "src_tokens.size", "model.forward_encoder", "model.initialize_output_tokens", "torch.arange", "decoder_out._replace._replace.output_tokens.clone", "range", "NotImplementedError", "hasattr", "model.enable_ensemble", "fairseq.utils.new_arange().t().reshape", "model.encoder.reorder_encoder_out", "model.regenerate_length_beam", "decoder_out._replace._replace._replace", "prev_out_token.ne", "decoder_out._replace._replace._replace", "model.forward_decoder", "range", "decoder_out._replace._replace._replace", "model.encoder.reorder_encoder_out", "decoder_out._replace._replace.output_tokens.clone", "model.eval", "len", "len", "range", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat", "torch.cat", "scores.mean", "iterative_refinement_generator.IterativeRefinementGenerator.generate.is_a_loop"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.BasicEnsembleModel.forward_encoder", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.initialize_output_tokens", "home.repos.pwc.inspect_result.reneeye_const.nat.fairseq_nat_model.FairseqNATModel.enable_ensemble", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerEncoder.reorder_encoder_out", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerModel.regenerate_length_beam", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_decoder", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerEncoder.reorder_encoder_out", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate", "(", "self", ",", "models", ",", "sample", ",", "prefix_tokens", "=", "None", ",", "constraints", "=", "None", ")", ":", "\n", "        ", "if", "constraints", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Constrained decoding with the IterativeRefinementGenerator is not supported\"", "\n", ")", "\n", "\n", "# TODO: iterative refinement generator does not support ensemble for now.", "\n", "", "if", "not", "self", ".", "retain_dropout", ":", "\n", "            ", "for", "model", "in", "models", ":", "\n", "                ", "model", ".", "eval", "(", ")", "\n", "\n", "", "", "model", ",", "reranker", "=", "models", "[", "0", "]", ",", "None", "\n", "if", "self", ".", "reranking", ":", "\n", "            ", "assert", "len", "(", "models", ")", ">", "1", ",", "\"Assuming the last checkpoint is the reranker\"", "\n", "assert", "(", "\n", "self", ".", "beam_size", ">", "1", "\n", ")", ",", "\"Reranking requires multiple translation for each example\"", "\n", "\n", "reranker", "=", "models", "[", "-", "1", "]", "\n", "models", "=", "models", "[", ":", "-", "1", "]", "\n", "\n", "", "if", "len", "(", "models", ")", ">", "1", "and", "hasattr", "(", "model", ",", "\"enable_ensemble\"", ")", ":", "\n", "            ", "assert", "model", ".", "allow_ensemble", ",", "\"{} does not support ensembling\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", "\n", ")", "\n", "model", ".", "enable_ensemble", "(", "models", ")", "\n", "\n", "# TODO: better encoder inputs?", "\n", "", "src_tokens", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "\n", "src_lengths", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_lengths\"", "]", "\n", "bsz", ",", "src_len", "=", "src_tokens", ".", "size", "(", ")", "\n", "\n", "# initialize", "\n", "encoder_out", "=", "model", ".", "forward_encoder", "(", "[", "src_tokens", ",", "src_lengths", "]", ")", "\n", "prev_decoder_out", "=", "model", ".", "initialize_output_tokens", "(", "encoder_out", ",", "src_tokens", ")", "\n", "\n", "if", "self", ".", "beam_size", ">", "1", ":", "\n", "            ", "assert", "(", "\n", "model", ".", "allow_length_beam", "\n", ")", ",", "\"{} does not support decoding with length beam.\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", "\n", ")", "\n", "\n", "# regenerate data based on length-beam", "\n", "length_beam_order", "=", "(", "\n", "utils", ".", "new_arange", "(", "src_tokens", ",", "self", ".", "beam_size", ",", "bsz", ")", ".", "t", "(", ")", ".", "reshape", "(", "-", "1", ")", "\n", ")", "\n", "encoder_out", "=", "model", ".", "encoder", ".", "reorder_encoder_out", "(", "\n", "encoder_out", ",", "length_beam_order", "\n", ")", "\n", "prev_decoder_out", "=", "model", ".", "regenerate_length_beam", "(", "\n", "prev_decoder_out", ",", "self", ".", "beam_size", "\n", ")", "\n", "bsz", "=", "bsz", "*", "self", ".", "beam_size", "\n", "\n", "", "sent_idxs", "=", "torch", ".", "arange", "(", "bsz", ")", "\n", "prev_output_tokens", "=", "prev_decoder_out", ".", "output_tokens", ".", "clone", "(", ")", "\n", "\n", "if", "self", ".", "retain_history", ":", "\n", "            ", "prev_decoder_out", "=", "prev_decoder_out", ".", "_replace", "(", "history", "=", "[", "prev_output_tokens", "]", ")", "\n", "\n", "", "finalized", "=", "[", "[", "]", "for", "_", "in", "range", "(", "bsz", ")", "]", "\n", "\n", "def", "is_a_loop", "(", "x", ",", "y", ",", "s", ",", "a", ")", ":", "\n", "            ", "b", ",", "l_x", ",", "l_y", "=", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ",", "y", ".", "size", "(", "1", ")", "\n", "if", "l_x", ">", "l_y", ":", "\n", "                ", "y", "=", "torch", ".", "cat", "(", "[", "y", ",", "x", ".", "new_zeros", "(", "b", ",", "l_x", "-", "l_y", ")", ".", "fill_", "(", "self", ".", "pad", ")", "]", ",", "1", ")", "\n", "s", "=", "torch", ".", "cat", "(", "[", "s", ",", "s", ".", "new_zeros", "(", "b", ",", "l_x", "-", "l_y", ")", "]", ",", "1", ")", "\n", "if", "a", "is", "not", "None", ":", "\n", "                    ", "a", "=", "torch", ".", "cat", "(", "[", "a", ",", "a", ".", "new_zeros", "(", "b", ",", "l_x", "-", "l_y", ",", "a", ".", "size", "(", "2", ")", ")", "]", ",", "1", ")", "\n", "", "", "elif", "l_x", "<", "l_y", ":", "\n", "                ", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "y", ".", "new_zeros", "(", "b", ",", "l_y", "-", "l_x", ")", ".", "fill_", "(", "self", ".", "pad", ")", "]", ",", "1", ")", "\n", "", "return", "(", "x", "==", "y", ")", ".", "all", "(", "1", ")", ",", "y", ",", "s", ",", "a", "\n", "\n", "", "def", "finalized_hypos", "(", "step", ",", "prev_out_token", ",", "prev_out_score", ",", "prev_out_attn", ")", ":", "\n", "            ", "cutoff", "=", "prev_out_token", ".", "ne", "(", "self", ".", "pad", ")", "\n", "tokens", "=", "prev_out_token", "[", "cutoff", "]", "\n", "if", "prev_out_score", "is", "None", ":", "\n", "                ", "scores", ",", "score", "=", "None", ",", "None", "\n", "", "else", ":", "\n", "                ", "scores", "=", "prev_out_score", "[", "cutoff", "]", "\n", "score", "=", "scores", ".", "mean", "(", ")", "\n", "\n", "", "if", "prev_out_attn", "is", "None", ":", "\n", "                ", "hypo_attn", ",", "alignment", "=", "None", ",", "None", "\n", "", "else", ":", "\n", "                ", "hypo_attn", "=", "prev_out_attn", "[", "cutoff", "]", "\n", "alignment", "=", "hypo_attn", ".", "max", "(", "dim", "=", "1", ")", "[", "1", "]", "\n", "", "return", "{", "\n", "\"steps\"", ":", "step", ",", "\n", "\"tokens\"", ":", "tokens", ",", "\n", "\"positional_scores\"", ":", "scores", ",", "\n", "\"score\"", ":", "score", ",", "\n", "\"hypo_attn\"", ":", "hypo_attn", ",", "\n", "\"alignment\"", ":", "alignment", ",", "\n", "}", "\n", "\n", "", "for", "step", "in", "range", "(", "self", ".", "max_iter", "+", "1", ")", ":", "\n", "\n", "            ", "decoder_options", "=", "{", "\n", "\"eos_penalty\"", ":", "self", ".", "eos_penalty", ",", "\n", "\"max_ratio\"", ":", "self", ".", "max_ratio", ",", "\n", "\"decoding_format\"", ":", "self", ".", "decoding_format", ",", "\n", "}", "\n", "prev_decoder_out", "=", "prev_decoder_out", ".", "_replace", "(", "\n", "step", "=", "step", ",", "\n", "max_step", "=", "self", ".", "max_iter", "+", "1", ",", "\n", ")", "\n", "\n", "decoder_out", "=", "model", ".", "forward_decoder", "(", "\n", "prev_decoder_out", ",", "encoder_out", ",", "**", "decoder_options", "\n", ")", "\n", "\n", "if", "self", ".", "adaptive", ":", "\n", "# terminate if there is a loop", "\n", "                ", "terminated", ",", "out_tokens", ",", "out_scores", ",", "out_attn", "=", "is_a_loop", "(", "\n", "prev_output_tokens", ",", "\n", "decoder_out", ".", "output_tokens", ",", "\n", "decoder_out", ".", "output_scores", ",", "\n", "decoder_out", ".", "attn", ",", "\n", ")", "\n", "decoder_out", "=", "decoder_out", ".", "_replace", "(", "\n", "output_tokens", "=", "out_tokens", ",", "\n", "output_scores", "=", "out_scores", ",", "\n", "attn", "=", "out_attn", ",", "\n", ")", "\n", "\n", "", "else", ":", "\n", "                ", "terminated", "=", "decoder_out", ".", "output_tokens", ".", "new_zeros", "(", "\n", "decoder_out", ".", "output_tokens", ".", "size", "(", "0", ")", "\n", ")", ".", "bool", "(", ")", "\n", "\n", "", "if", "step", "==", "self", ".", "max_iter", ":", "# reach last iteration, terminate", "\n", "                ", "terminated", ".", "fill_", "(", "1", ")", "\n", "\n", "# collect finalized sentences", "\n", "", "finalized_idxs", "=", "sent_idxs", "[", "terminated", "]", "\n", "finalized_tokens", "=", "decoder_out", ".", "output_tokens", "[", "terminated", "]", "\n", "finalized_scores", "=", "decoder_out", ".", "output_scores", "[", "terminated", "]", "\n", "finalized_attn", "=", "(", "\n", "None", "\n", "if", "(", "decoder_out", ".", "attn", "is", "None", "or", "decoder_out", ".", "attn", ".", "size", "(", "0", ")", "==", "0", ")", "\n", "else", "decoder_out", ".", "attn", "[", "terminated", "]", "\n", ")", "\n", "\n", "if", "self", ".", "retain_history", ":", "\n", "                ", "finalized_history_tokens", "=", "[", "h", "[", "terminated", "]", "for", "h", "in", "decoder_out", ".", "history", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "finalized_idxs", ".", "size", "(", "0", ")", ")", ":", "\n", "                ", "finalized", "[", "finalized_idxs", "[", "i", "]", "]", "=", "[", "\n", "finalized_hypos", "(", "\n", "step", ",", "\n", "finalized_tokens", "[", "i", "]", ",", "\n", "finalized_scores", "[", "i", "]", ",", "\n", "None", "if", "finalized_attn", "is", "None", "else", "finalized_attn", "[", "i", "]", ",", "\n", ")", "\n", "]", "\n", "\n", "if", "self", ".", "retain_history", ":", "\n", "                    ", "finalized", "[", "finalized_idxs", "[", "i", "]", "]", "[", "0", "]", "[", "\"history\"", "]", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "finalized_history_tokens", ")", ")", ":", "\n", "                        ", "finalized", "[", "finalized_idxs", "[", "i", "]", "]", "[", "0", "]", "[", "\"history\"", "]", ".", "append", "(", "\n", "finalized_hypos", "(", "\n", "step", ",", "finalized_history_tokens", "[", "j", "]", "[", "i", "]", ",", "None", ",", "None", "\n", ")", "\n", ")", "\n", "\n", "# check if all terminated", "\n", "", "", "", "if", "terminated", ".", "sum", "(", ")", "==", "terminated", ".", "size", "(", "0", ")", ":", "\n", "                ", "break", "\n", "\n", "# for next step", "\n", "", "not_terminated", "=", "~", "terminated", "\n", "prev_decoder_out", "=", "decoder_out", ".", "_replace", "(", "\n", "output_tokens", "=", "decoder_out", ".", "output_tokens", "[", "not_terminated", "]", ",", "\n", "output_scores", "=", "decoder_out", ".", "output_scores", "[", "not_terminated", "]", ",", "\n", "attn", "=", "decoder_out", ".", "attn", "[", "not_terminated", "]", "\n", "if", "(", "decoder_out", ".", "attn", "is", "not", "None", "and", "decoder_out", ".", "attn", ".", "size", "(", "0", ")", ">", "0", ")", "\n", "else", "None", ",", "\n", "history", "=", "[", "h", "[", "not_terminated", "]", "for", "h", "in", "decoder_out", ".", "history", "]", "\n", "if", "decoder_out", ".", "history", "is", "not", "None", "\n", "else", "None", ",", "\n", ")", "\n", "encoder_out", "=", "model", ".", "encoder", ".", "reorder_encoder_out", "(", "\n", "encoder_out", ",", "not_terminated", ".", "nonzero", "(", "as_tuple", "=", "False", ")", ".", "squeeze", "(", ")", "\n", ")", "\n", "sent_idxs", "=", "sent_idxs", "[", "not_terminated", "]", "\n", "prev_output_tokens", "=", "prev_decoder_out", ".", "output_tokens", ".", "clone", "(", ")", "\n", "\n", "", "if", "self", ".", "beam_size", ">", "1", ":", "\n", "            ", "if", "reranker", "is", "not", "None", ":", "\n", "                ", "finalized", "=", "self", ".", "rerank", "(", "\n", "reranker", ",", "finalized", ",", "[", "src_tokens", ",", "src_lengths", "]", ",", "self", ".", "beam_size", "\n", ")", "\n", "\n", "# aggregate information from length beam", "\n", "", "finalized", "=", "[", "\n", "finalized", "[", "\n", "np", ".", "argmax", "(", "\n", "[", "\n", "finalized", "[", "self", ".", "beam_size", "*", "i", "+", "j", "]", "[", "0", "]", "[", "\"score\"", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "beam_size", ")", "\n", "]", "\n", ")", "\n", "+", "self", ".", "beam_size", "*", "i", "\n", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "finalized", ")", "//", "self", ".", "beam_size", ")", "\n", "]", "\n", "\n", "", "return", "finalized", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.iterative_refinement_generator.IterativeRefinementGenerator.rerank": [[313, 360], ["iterative_refinement_generator.IterativeRefinementGenerator.rerank.rebuild_batch"], "methods", ["None"], ["", "def", "rerank", "(", "self", ",", "reranker", ",", "finalized", ",", "encoder_input", ",", "beam_size", ")", ":", "\n", "        ", "def", "rebuild_batch", "(", "finalized", ")", ":", "\n", "            ", "finalized_tokens", "=", "[", "f", "[", "0", "]", "[", "\"tokens\"", "]", "for", "f", "in", "finalized", "]", "\n", "finalized_maxlen", "=", "max", "(", "f", ".", "size", "(", "0", ")", "for", "f", "in", "finalized_tokens", ")", "\n", "final_output_tokens", "=", "(", "\n", "finalized_tokens", "[", "0", "]", "\n", ".", "new_zeros", "(", "len", "(", "finalized_tokens", ")", ",", "finalized_maxlen", ")", "\n", ".", "fill_", "(", "self", ".", "pad", ")", "\n", ")", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "finalized_tokens", ")", ":", "\n", "                ", "final_output_tokens", "[", "i", ",", ":", "f", ".", "size", "(", "0", ")", "]", "=", "f", "\n", "", "return", "final_output_tokens", "\n", "\n", "", "final_output_tokens", "=", "rebuild_batch", "(", "finalized", ")", "\n", "final_output_tokens", "[", "\n", ":", ",", "0", "\n", "]", "=", "self", ".", "eos", "# autoregressive model assumes starting with EOS", "\n", "\n", "reranker_encoder_out", "=", "reranker", ".", "encoder", "(", "*", "encoder_input", ")", "\n", "length_beam_order", "=", "(", "\n", "utils", ".", "new_arange", "(", "\n", "final_output_tokens", ",", "beam_size", ",", "reranker_encoder_out", ".", "encoder_out", ".", "size", "(", "1", ")", "\n", ")", "\n", ".", "t", "(", ")", "\n", ".", "reshape", "(", "-", "1", ")", "\n", ")", "\n", "reranker_encoder_out", "=", "reranker", ".", "encoder", ".", "reorder_encoder_out", "(", "\n", "reranker_encoder_out", ",", "length_beam_order", "\n", ")", "\n", "reranking_scores", "=", "reranker", ".", "get_normalized_probs", "(", "\n", "reranker", ".", "decoder", "(", "final_output_tokens", "[", ":", ",", ":", "-", "1", "]", ",", "reranker_encoder_out", ")", ",", "\n", "True", ",", "\n", "None", ",", "\n", ")", "\n", "reranking_scores", "=", "reranking_scores", ".", "gather", "(", "2", ",", "final_output_tokens", "[", ":", ",", "1", ":", ",", "None", "]", ")", "\n", "reranking_masks", "=", "final_output_tokens", "[", ":", ",", "1", ":", "]", ".", "ne", "(", "self", ".", "pad", ")", "\n", "reranking_scores", "=", "(", "\n", "reranking_scores", "[", ":", ",", ":", ",", "0", "]", ".", "masked_fill_", "(", "~", "reranking_masks", ",", "0", ")", ".", "sum", "(", "1", ")", "\n", ")", "\n", "reranking_scores", "=", "reranking_scores", "/", "reranking_masks", ".", "sum", "(", "1", ")", ".", "type_as", "(", "\n", "reranking_scores", "\n", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "finalized", ")", ")", ":", "\n", "            ", "finalized", "[", "i", "]", "[", "0", "]", "[", "\"score\"", "]", "=", "reranking_scores", "[", "i", "]", "\n", "\n", "", "return", "finalized", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.incremental_decoding_utils.FairseqIncrementalState.__init__": [[13, 16], ["object.__init__", "incremental_decoding_utils.FairseqIncrementalState.init_incremental_state"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.fairseq.incremental_decoding_utils.FairseqIncrementalState.init_incremental_state"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "init_incremental_state", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.incremental_decoding_utils.FairseqIncrementalState.init_incremental_state": [[17, 19], ["str", "uuid.uuid4"], "methods", ["None"], ["", "def", "init_incremental_state", "(", "self", ")", ":", "\n", "        ", "self", ".", "_incremental_state_id", "=", "str", "(", "uuid", ".", "uuid4", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.incremental_decoding_utils.FairseqIncrementalState._get_full_incremental_state_key": [[20, 22], ["None"], "methods", ["None"], ["", "def", "_get_full_incremental_state_key", "(", "self", ",", "key", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "\"{}.{}\"", ".", "format", "(", "self", ".", "_incremental_state_id", ",", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.incremental_decoding_utils.FairseqIncrementalState.get_incremental_state": [[23, 33], ["incremental_decoding_utils.FairseqIncrementalState._get_full_incremental_state_key"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.incremental_decoding_utils.FairseqIncrementalState._get_full_incremental_state_key"], ["", "def", "get_incremental_state", "(", "\n", "self", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "key", ":", "str", ",", "\n", ")", "->", "Optional", "[", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ":", "\n", "        ", "\"\"\"Helper for getting incremental state for an nn.Module.\"\"\"", "\n", "full_key", "=", "self", ".", "_get_full_incremental_state_key", "(", "key", ")", "\n", "if", "incremental_state", "is", "None", "or", "full_key", "not", "in", "incremental_state", ":", "\n", "            ", "return", "None", "\n", "", "return", "incremental_state", "[", "full_key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.incremental_decoding_utils.FairseqIncrementalState.set_incremental_state": [[34, 45], ["incremental_decoding_utils.FairseqIncrementalState._get_full_incremental_state_key"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.incremental_decoding_utils.FairseqIncrementalState._get_full_incremental_state_key"], ["", "def", "set_incremental_state", "(", "\n", "self", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "key", ":", "str", ",", "\n", "value", ":", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", ",", "\n", ")", "->", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ":", "\n", "        ", "\"\"\"Helper for setting incremental state for an nn.Module.\"\"\"", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "full_key", "=", "self", ".", "_get_full_incremental_state_key", "(", "key", ")", "\n", "incremental_state", "[", "full_key", "]", "=", "value", "\n", "", "return", "incremental_state", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.incremental_decoding_utils.with_incremental_state": [[47, 52], ["tuple"], "function", ["None"], ["", "", "def", "with_incremental_state", "(", "cls", ")", ":", "\n", "    ", "cls", ".", "__bases__", "=", "(", "FairseqIncrementalState", ",", ")", "+", "tuple", "(", "\n", "b", "for", "b", "in", "cls", ".", "__bases__", "if", "b", "!=", "FairseqIncrementalState", "\n", ")", "\n", "return", "cls", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open": [[27, 52], ["file_io.PathManager.open"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["@", "staticmethod", "\n", "def", "open", "(", "\n", "path", ":", "str", ",", "\n", "mode", ":", "str", "=", "\"r\"", ",", "\n", "buffering", ":", "int", "=", "-", "1", ",", "\n", "encoding", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "errors", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "newline", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "FVCorePathManager", ":", "\n", "            ", "return", "FVCorePathManager", ".", "open", "(", "\n", "path", "=", "path", ",", "\n", "mode", "=", "mode", ",", "\n", "buffering", "=", "buffering", ",", "\n", "encoding", "=", "encoding", ",", "\n", "errors", "=", "errors", ",", "\n", "newline", "=", "newline", ",", "\n", ")", "\n", "", "return", "open", "(", "\n", "path", ",", "\n", "mode", "=", "mode", ",", "\n", "buffering", "=", "buffering", ",", "\n", "encoding", "=", "encoding", ",", "\n", "errors", "=", "errors", ",", "\n", "newline", "=", "newline", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.copy": [[54, 61], ["shutil.copyfile", "FVCorePathManager.copy"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.copy"], ["", "@", "staticmethod", "\n", "def", "copy", "(", "src_path", ":", "str", ",", "dst_path", ":", "str", ",", "overwrite", ":", "bool", "=", "False", ")", "->", "bool", ":", "\n", "        ", "if", "FVCorePathManager", ":", "\n", "            ", "return", "FVCorePathManager", ".", "copy", "(", "\n", "src_path", "=", "src_path", ",", "dst_path", "=", "dst_path", ",", "overwrite", "=", "overwrite", "\n", ")", "\n", "", "return", "shutil", ".", "copyfile", "(", "src_path", ",", "dst_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.get_local_path": [[62, 67], ["FVCorePathManager.get_local_path"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.get_local_path"], ["", "@", "staticmethod", "\n", "def", "get_local_path", "(", "path", ":", "str", ",", "**", "kwargs", ")", "->", "str", ":", "\n", "        ", "if", "FVCorePathManager", ":", "\n", "            ", "return", "FVCorePathManager", ".", "get_local_path", "(", "path", ",", "**", "kwargs", ")", "\n", "", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.exists": [[68, 73], ["os.path.exists", "FVCorePathManager.exists"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists"], ["", "@", "staticmethod", "\n", "def", "exists", "(", "path", ":", "str", ")", "->", "bool", ":", "\n", "        ", "if", "FVCorePathManager", ":", "\n", "            ", "return", "FVCorePathManager", ".", "exists", "(", "path", ")", "\n", "", "return", "os", ".", "path", ".", "exists", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.isfile": [[74, 79], ["os.path.isfile", "FVCorePathManager.isfile"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.isfile", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.isfile"], ["", "@", "staticmethod", "\n", "def", "isfile", "(", "path", ":", "str", ")", "->", "bool", ":", "\n", "        ", "if", "FVCorePathManager", ":", "\n", "            ", "return", "FVCorePathManager", ".", "isfile", "(", "path", ")", "\n", "", "return", "os", ".", "path", ".", "isfile", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.ls": [[80, 85], ["os.listdir", "FVCorePathManager.ls"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.ls"], ["", "@", "staticmethod", "\n", "def", "ls", "(", "path", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "if", "FVCorePathManager", ":", "\n", "            ", "return", "FVCorePathManager", ".", "ls", "(", "path", ")", "\n", "", "return", "os", ".", "listdir", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.mkdirs": [[86, 91], ["os.makedirs", "FVCorePathManager.mkdirs"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.mkdirs"], ["", "@", "staticmethod", "\n", "def", "mkdirs", "(", "path", ":", "str", ")", "->", "None", ":", "\n", "        ", "if", "FVCorePathManager", ":", "\n", "            ", "return", "FVCorePathManager", ".", "mkdirs", "(", "path", ")", "\n", "", "os", ".", "makedirs", "(", "path", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.rm": [[92, 97], ["os.remove", "FVCorePathManager.rm"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.rm"], ["", "@", "staticmethod", "\n", "def", "rm", "(", "path", ":", "str", ")", "->", "None", ":", "\n", "        ", "if", "FVCorePathManager", ":", "\n", "            ", "return", "FVCorePathManager", ".", "rm", "(", "path", ")", "\n", "", "os", ".", "remove", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.chmod": [[98, 102], ["os.chmod"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.chmod"], ["", "@", "staticmethod", "\n", "def", "chmod", "(", "path", ":", "str", ",", "mode", ":", "int", ")", "->", "None", ":", "\n", "        ", "if", "\"manifold\"", "not", "in", "path", ":", "\n", "            ", "os", ".", "chmod", "(", "path", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.register_handler": [[103, 107], ["FVCorePathManager.register_handler"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.register_handler"], ["", "", "@", "staticmethod", "\n", "def", "register_handler", "(", "handler", ")", "->", "None", ":", "\n", "        ", "if", "FVCorePathManager", ":", "\n", "            ", "return", "FVCorePathManager", ".", "register_handler", "(", "handler", "=", "handler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.copy_from_local": [[108, 117], ["shutil.copyfile", "FVCorePathManager.copy_from_local"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.copy_from_local"], ["", "", "@", "staticmethod", "\n", "def", "copy_from_local", "(", "\n", "local_path", ":", "str", ",", "dst_path", ":", "str", ",", "overwrite", ":", "bool", "=", "False", ",", "**", "kwargs", "\n", ")", "->", "None", ":", "\n", "        ", "if", "FVCorePathManager", ":", "\n", "            ", "return", "FVCorePathManager", ".", "copy_from_local", "(", "\n", "local_path", "=", "local_path", ",", "dst_path", "=", "dst_path", ",", "overwrite", "=", "overwrite", ",", "**", "kwargs", "\n", ")", "\n", "", "return", "shutil", ".", "copyfile", "(", "local_path", ",", "dst_path", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.save_checkpoint": [[29, 131], ["getattr", "trainer.consolidate_optimizer", "meters.StopwatchMeter", "meters.StopwatchMeter.start", "epoch_itr.end_of_epoch", "trainer.get_num_updates", "collections.OrderedDict", "hasattr", "os.makedirs", "best_function", "epoch_itr.state_dict", "extra_state.update", "os.path.join", "len", "trainer.save_checkpoint", "meters.StopwatchMeter.stop", "logger.info", "checkpoint_utils.checkpoint_paths", "checkpoint_utils.checkpoint_paths", "checkpoint_utils.checkpoint_paths", "checkpoint_utils.save_checkpoint.is_better"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.consolidate_optimizer", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.start", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.end_of_epoch", "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.state_dict", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.reneeye_const.model_parallel.megatron_trainer.MegatronTrainer.save_checkpoint", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.stop", "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.checkpoint_paths", "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.checkpoint_paths", "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.checkpoint_paths"], ["def", "save_checkpoint", "(", "cfg", ":", "CheckpointConfig", ",", "trainer", ",", "epoch_itr", ",", "val_loss", ")", ":", "\n", "    ", "from", "fairseq", "import", "meters", "\n", "\n", "# only one worker should attempt to create the required dir", "\n", "if", "cfg", ".", "distributed_rank", "==", "0", ":", "\n", "        ", "os", ".", "makedirs", "(", "cfg", ".", "save_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "prev_best", "=", "getattr", "(", "save_checkpoint", ",", "\"best\"", ",", "val_loss", ")", "\n", "if", "val_loss", "is", "not", "None", ":", "\n", "        ", "best_function", "=", "max", "if", "cfg", ".", "maximize_best_checkpoint_metric", "else", "min", "\n", "save_checkpoint", ".", "best", "=", "best_function", "(", "val_loss", ",", "prev_best", ")", "\n", "\n", "", "if", "cfg", ".", "no_save", ":", "\n", "        ", "return", "\n", "\n", "", "trainer", ".", "consolidate_optimizer", "(", ")", "\n", "\n", "if", "not", "trainer", ".", "is_data_parallel_master", ":", "\n", "        ", "return", "\n", "\n", "", "def", "is_better", "(", "a", ",", "b", ")", ":", "\n", "        ", "return", "a", ">=", "b", "if", "cfg", ".", "maximize_best_checkpoint_metric", "else", "a", "<=", "b", "\n", "\n", "", "write_timer", "=", "meters", ".", "StopwatchMeter", "(", ")", "\n", "write_timer", ".", "start", "(", ")", "\n", "\n", "epoch", "=", "epoch_itr", ".", "epoch", "\n", "end_of_epoch", "=", "epoch_itr", ".", "end_of_epoch", "(", ")", "\n", "updates", "=", "trainer", ".", "get_num_updates", "(", ")", "\n", "\n", "suffix", "=", "cfg", ".", "checkpoint_suffix", "or", "\"\"", "\n", "checkpoint_conds", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "checkpoint_conds", "[", "\"checkpoint{}{}.pt\"", ".", "format", "(", "epoch", ",", "suffix", ")", "]", "=", "(", "\n", "end_of_epoch", "and", "not", "cfg", ".", "no_epoch_checkpoints", "and", "epoch", "%", "cfg", ".", "save_interval", "==", "0", "\n", ")", "\n", "checkpoint_conds", "[", "\"checkpoint_{}_{}{}.pt\"", ".", "format", "(", "epoch", ",", "updates", ",", "suffix", ")", "]", "=", "(", "\n", "not", "end_of_epoch", "\n", "and", "cfg", ".", "save_interval_updates", ">", "0", "\n", "and", "updates", "%", "cfg", ".", "save_interval_updates", "==", "0", "\n", ")", "\n", "checkpoint_conds", "[", "\"checkpoint_best{}.pt\"", ".", "format", "(", "suffix", ")", "]", "=", "val_loss", "is", "not", "None", "and", "(", "\n", "not", "hasattr", "(", "save_checkpoint", ",", "\"best\"", ")", "\n", "or", "is_better", "(", "val_loss", ",", "save_checkpoint", ".", "best", ")", "\n", ")", "\n", "if", "val_loss", "is", "not", "None", "and", "cfg", ".", "keep_best_checkpoints", ">", "0", ":", "\n", "        ", "checkpoint_conds", "[", "\n", "\"checkpoint.best_{}_{:.2f}.pt\"", ".", "format", "(", "cfg", ".", "best_checkpoint_metric", ",", "val_loss", ")", "\n", "]", "=", "not", "hasattr", "(", "save_checkpoint", ",", "\"best\"", ")", "or", "is_better", "(", "\n", "val_loss", ",", "save_checkpoint", ".", "best", "\n", ")", "\n", "", "checkpoint_conds", "[", "\n", "\"checkpoint_last{}.pt\"", ".", "format", "(", "suffix", ")", "\n", "]", "=", "not", "cfg", ".", "no_last_checkpoints", "\n", "\n", "extra_state", "=", "{", "\"train_iterator\"", ":", "epoch_itr", ".", "state_dict", "(", ")", ",", "\"val_loss\"", ":", "val_loss", "}", "\n", "if", "hasattr", "(", "save_checkpoint", ",", "\"best\"", ")", ":", "\n", "        ", "extra_state", ".", "update", "(", "{", "\"best\"", ":", "save_checkpoint", ".", "best", "}", ")", "\n", "\n", "", "checkpoints", "=", "[", "\n", "os", ".", "path", ".", "join", "(", "cfg", ".", "save_dir", ",", "fn", ")", "for", "fn", ",", "cond", "in", "checkpoint_conds", ".", "items", "(", ")", "if", "cond", "\n", "]", "\n", "if", "len", "(", "checkpoints", ")", ">", "0", ":", "\n", "        ", "trainer", ".", "save_checkpoint", "(", "checkpoints", "[", "0", "]", ",", "extra_state", ")", "\n", "for", "cp", "in", "checkpoints", "[", "1", ":", "]", ":", "\n", "            ", "PathManager", ".", "copy", "(", "checkpoints", "[", "0", "]", ",", "cp", ",", "overwrite", "=", "True", ")", "\n", "\n", "", "write_timer", ".", "stop", "(", ")", "\n", "logger", ".", "info", "(", "\n", "\"saved checkpoint {} (epoch {} @ {} updates, score {}) (writing took {} seconds)\"", ".", "format", "(", "\n", "checkpoints", "[", "0", "]", ",", "epoch", ",", "updates", ",", "val_loss", ",", "write_timer", ".", "sum", "\n", ")", "\n", ")", "\n", "\n", "", "if", "not", "end_of_epoch", "and", "cfg", ".", "keep_interval_updates", ">", "0", ":", "\n", "# remove old checkpoints; checkpoints are sorted in descending order", "\n", "        ", "checkpoints", "=", "checkpoint_paths", "(", "\n", "cfg", ".", "save_dir", ",", "pattern", "=", "r\"checkpoint_\\d+_(\\d+)\\.pt\"", "\n", ")", "\n", "for", "old_chk", "in", "checkpoints", "[", "cfg", ".", "keep_interval_updates", ":", "]", ":", "\n", "            ", "if", "os", ".", "path", ".", "lexists", "(", "old_chk", ")", ":", "\n", "                ", "os", ".", "remove", "(", "old_chk", ")", "\n", "\n", "", "", "", "if", "cfg", ".", "keep_last_epochs", ">", "0", ":", "\n", "# remove old epoch checkpoints; checkpoints are sorted in descending order", "\n", "        ", "checkpoints", "=", "checkpoint_paths", "(", "cfg", ".", "save_dir", ",", "pattern", "=", "r\"checkpoint(\\d+)\\.pt\"", ")", "\n", "for", "old_chk", "in", "checkpoints", "[", "cfg", ".", "keep_last_epochs", ":", "]", ":", "\n", "            ", "if", "os", ".", "path", ".", "lexists", "(", "old_chk", ")", ":", "\n", "                ", "os", ".", "remove", "(", "old_chk", ")", "\n", "\n", "", "", "", "if", "cfg", ".", "keep_best_checkpoints", ">", "0", ":", "\n", "# only keep the best N checkpoints according to validation metric", "\n", "        ", "checkpoints", "=", "checkpoint_paths", "(", "\n", "cfg", ".", "save_dir", ",", "\n", "pattern", "=", "r\"checkpoint\\.best_{}_(\\d+\\.?\\d*)\\.pt\"", ".", "format", "(", "\n", "cfg", ".", "best_checkpoint_metric", "\n", ")", ",", "\n", ")", "\n", "if", "not", "cfg", ".", "maximize_best_checkpoint_metric", ":", "\n", "            ", "checkpoints", "=", "checkpoints", "[", ":", ":", "-", "1", "]", "\n", "", "for", "old_chk", "in", "checkpoints", "[", "cfg", ".", "keep_best_checkpoints", ":", "]", ":", "\n", "            ", "if", "os", ".", "path", ".", "lexists", "(", "old_chk", ")", ":", "\n", "                ", "os", ".", "remove", "(", "old_chk", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_checkpoint": [[133, 222], ["ast.literal_eval", "trainer.load_checkpoint", "trainer.lr_step", "ValueError", "os.path.join", "ValueError", "trainer.get_train_iterator", "trainer.get_train_iterator.load_state_dict", "trainer.get_train_iterator", "fairseq.file_io.PathManager.exists", "fairseq.file_io.PathManager.exists", "cfg.restore_file.replace", "logger.info", "ValueError", "str"], "function", ["home.repos.pwc.inspect_result.reneeye_const.model_parallel.megatron_trainer.MegatronTrainer.load_checkpoint", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.lr_step", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_train_iterator", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.get_train_iterator", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists"], ["", "", "", "", "def", "load_checkpoint", "(", "cfg", ":", "CheckpointConfig", ",", "trainer", ",", "**", "passthrough_args", ")", ":", "\n", "    ", "\"\"\"\n    Load a checkpoint and restore the training iterator.\n\n    *passthrough_args* will be passed through to\n    ``trainer.get_train_iterator``.\n    \"\"\"", "\n", "\n", "reset_optimizer", "=", "cfg", ".", "reset_optimizer", "\n", "reset_lr_scheduler", "=", "cfg", ".", "reset_lr_scheduler", "\n", "optimizer_overrides", "=", "ast", ".", "literal_eval", "(", "cfg", ".", "optimizer_overrides", ")", "\n", "reset_meters", "=", "cfg", ".", "reset_meters", "\n", "reset_dataloader", "=", "cfg", ".", "reset_dataloader", "\n", "\n", "if", "cfg", ".", "finetune_from_model", "is", "not", "None", "and", "(", "\n", "reset_optimizer", "or", "reset_lr_scheduler", "or", "reset_meters", "or", "reset_dataloader", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"--finetune-from-model can not be set together with either --reset-optimizer\"", "\n", "\" or reset_lr_scheduler or reset_meters or reset_dataloader\"", "\n", ")", "\n", "\n", "", "suffix", "=", "cfg", ".", "checkpoint_suffix", "\n", "if", "(", "\n", "cfg", ".", "restore_file", "==", "\"checkpoint_last.pt\"", "\n", ")", ":", "# default value of restore_file is 'checkpoint_last.pt'", "\n", "        ", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "\n", "cfg", ".", "save_dir", ",", "\"checkpoint_last{}.pt\"", ".", "format", "(", "suffix", ")", "\n", ")", "\n", "first_launch", "=", "not", "PathManager", ".", "exists", "(", "checkpoint_path", ")", "\n", "if", "cfg", ".", "finetune_from_model", "is", "not", "None", "and", "first_launch", ":", "\n", "# if there is no last checkpoint to restore, start the finetune from pretrained model", "\n", "# else just use usual logic to load checkpoint, e.g. restart from last checkpoint and etc.", "\n", "            ", "if", "PathManager", ".", "exists", "(", "cfg", ".", "finetune_from_model", ")", ":", "\n", "                ", "checkpoint_path", "=", "cfg", ".", "finetune_from_model", "\n", "reset_optimizer", "=", "True", "\n", "reset_lr_scheduler", "=", "True", "\n", "reset_meters", "=", "True", "\n", "reset_dataloader", "=", "True", "\n", "logger", ".", "info", "(", "\n", "f\"loading pretrained model from {checkpoint_path}: \"", "\n", "\"optimizer, lr scheduler, meters, dataloader will be reset\"", "\n", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"--funetune-from-model {cfg.finetune_from_model} does not exist\"", "\n", ")", "\n", "", "", "", "elif", "cfg", ".", "model_parallel_size", ">", "1", ":", "\n", "        ", "checkpoint_path", "=", "cfg", ".", "restore_file", ".", "replace", "(", "\".pt\"", ",", "suffix", "+", "\".pt\"", ")", "\n", "", "else", ":", "\n", "        ", "checkpoint_path", "=", "cfg", ".", "restore_file", "\n", "\n", "", "if", "cfg", ".", "restore_file", "!=", "\"checkpoint_last.pt\"", "and", "cfg", ".", "finetune_from_model", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"--finetune-from-model and --restore-file (non-default value) \"", "\n", "\"can not be specified together: \"", "+", "str", "(", "cfg", ")", "\n", ")", "\n", "\n", "", "extra_state", "=", "trainer", ".", "load_checkpoint", "(", "\n", "checkpoint_path", ",", "\n", "reset_optimizer", ",", "\n", "reset_lr_scheduler", ",", "\n", "optimizer_overrides", ",", "\n", "reset_meters", "=", "reset_meters", ",", "\n", ")", "\n", "\n", "if", "(", "\n", "extra_state", "is", "not", "None", "\n", "and", "\"best\"", "in", "extra_state", "\n", "and", "not", "reset_optimizer", "\n", "and", "not", "reset_meters", "\n", ")", ":", "\n", "        ", "save_checkpoint", ".", "best", "=", "extra_state", "[", "\"best\"", "]", "\n", "\n", "", "if", "extra_state", "is", "not", "None", "and", "not", "reset_dataloader", ":", "\n", "# restore iterator from checkpoint", "\n", "        ", "itr_state", "=", "extra_state", "[", "\"train_iterator\"", "]", "\n", "epoch_itr", "=", "trainer", ".", "get_train_iterator", "(", "\n", "epoch", "=", "itr_state", "[", "\"epoch\"", "]", ",", "load_dataset", "=", "True", ",", "**", "passthrough_args", "\n", ")", "\n", "epoch_itr", ".", "load_state_dict", "(", "itr_state", ")", "\n", "", "else", ":", "\n", "        ", "epoch_itr", "=", "trainer", ".", "get_train_iterator", "(", "\n", "epoch", "=", "1", ",", "load_dataset", "=", "True", ",", "**", "passthrough_args", "\n", ")", "\n", "\n", "", "trainer", ".", "lr_step", "(", "epoch_itr", ".", "epoch", ")", "\n", "\n", "return", "extra_state", ",", "epoch_itr", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_checkpoint_to_cpu": [[224, 239], ["checkpoint_utils._upgrade_state_dict", "open", "torch.load", "arg_overrides.items", "fairseq.dataclass.utils.overwrite_args_by_name", "fairseq.file_io.PathManager.get_local_path", "setattr", "torch.device"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils._upgrade_state_dict", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.overwrite_args_by_name", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.get_local_path", "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.device"], ["", "def", "load_checkpoint_to_cpu", "(", "path", ",", "arg_overrides", "=", "None", ")", ":", "\n", "    ", "\"\"\"Loads a checkpoint to CPU (with upgrading for backward compatibility).\"\"\"", "\n", "with", "open", "(", "PathManager", ".", "get_local_path", "(", "path", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "state", "=", "torch", ".", "load", "(", "f", ",", "map_location", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "\n", "", "if", "\"args\"", "in", "state", "and", "state", "[", "\"args\"", "]", "is", "not", "None", "and", "arg_overrides", "is", "not", "None", ":", "\n", "        ", "args", "=", "state", "[", "\"args\"", "]", "\n", "for", "arg_name", ",", "arg_val", "in", "arg_overrides", ".", "items", "(", ")", ":", "\n", "            ", "setattr", "(", "args", ",", "arg_name", ",", "arg_val", ")", "\n", "\n", "", "", "if", "\"cfg\"", "in", "state", "and", "state", "[", "\"cfg\"", "]", "is", "not", "None", "and", "arg_overrides", "is", "not", "None", ":", "\n", "        ", "overwrite_args_by_name", "(", "state", "[", "\"cfg\"", "]", ",", "arg_overrides", ")", "\n", "\n", "", "state", "=", "_upgrade_state_dict", "(", "state", ")", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_model_ensemble": [[241, 265], ["checkpoint_utils.load_model_ensemble_and_task"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_model_ensemble_and_task"], ["", "def", "load_model_ensemble", "(", "\n", "filenames", ",", "arg_overrides", "=", "None", ",", "task", "=", "None", ",", "strict", "=", "True", ",", "suffix", "=", "\"\"", ",", "num_shards", "=", "1", ",", "state", "=", "None", "\n", ")", ":", "\n", "    ", "\"\"\"Loads an ensemble of models.\n\n    Args:\n        filenames (List[str]): checkpoint files to load\n        arg_overrides (Dict[str,Any], optional): override model args that\n            were used during model training\n        task (fairseq.tasks.FairseqTask, optional): task to use for loading\n    \"\"\"", "\n", "assert", "not", "(", "\n", "strict", "and", "num_shards", ">", "1", "\n", ")", ",", "\"Cannot load state dict with strict=True and checkpoint shards > 1\"", "\n", "ensemble", ",", "args", ",", "_task", "=", "load_model_ensemble_and_task", "(", "\n", "filenames", ",", "\n", "arg_overrides", ",", "\n", "task", ",", "\n", "strict", ",", "\n", "suffix", ",", "\n", "num_shards", ",", "\n", "state", ",", "\n", ")", "\n", "return", "ensemble", ",", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_model_ensemble_and_task": [[267, 314], ["range", "ensemble.append", "len", "tasks.setup_task.build_model", "task.build_model.load_state_dict", "filename.replace.replace", "fairseq.file_io.PathManager.exists", "IOError", "checkpoint_utils.load_checkpoint_to_cpu", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "tasks.setup_task", "RuntimeError", "load_checkpoint_to_cpu.keys"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_checkpoint_to_cpu", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyMTTask.setup_task"], ["", "def", "load_model_ensemble_and_task", "(", "\n", "filenames", ",", "arg_overrides", "=", "None", ",", "task", "=", "None", ",", "strict", "=", "True", ",", "suffix", "=", "\"\"", ",", "num_shards", "=", "1", ",", "state", "=", "None", "\n", ")", ":", "\n", "    ", "assert", "state", "is", "None", "or", "len", "(", "filenames", ")", "==", "1", "\n", "\n", "from", "fairseq", "import", "tasks", "\n", "\n", "assert", "not", "(", "\n", "strict", "and", "num_shards", ">", "1", "\n", ")", ",", "\"Cannot load state dict with strict=True and checkpoint shards > 1\"", "\n", "ensemble", "=", "[", "]", "\n", "cfg", "=", "None", "\n", "for", "filename", "in", "filenames", ":", "\n", "        ", "orig_filename", "=", "filename", "\n", "assert", "num_shards", ">", "0", "\n", "for", "shard_idx", "in", "range", "(", "num_shards", ")", ":", "\n", "            ", "if", "num_shards", "==", "1", ":", "\n", "                ", "filename", "=", "filename", ".", "replace", "(", "\".pt\"", ",", "suffix", "+", "\".pt\"", ")", "\n", "", "else", ":", "\n", "                ", "filename", "=", "orig_filename", "[", ":", "-", "3", "]", "+", "f\"_part{shard_idx}.pt\"", "\n", "\n", "", "if", "not", "PathManager", ".", "exists", "(", "filename", ")", ":", "\n", "                ", "raise", "IOError", "(", "\"Model file not found: {}\"", ".", "format", "(", "filename", ")", ")", "\n", "", "if", "state", "is", "None", ":", "\n", "                ", "state", "=", "load_checkpoint_to_cpu", "(", "filename", ",", "arg_overrides", ")", "\n", "", "if", "\"args\"", "in", "state", "and", "state", "[", "\"args\"", "]", "is", "not", "None", ":", "\n", "                ", "cfg", "=", "convert_namespace_to_omegaconf", "(", "state", "[", "\"args\"", "]", ")", "\n", "", "elif", "\"cfg\"", "in", "state", "and", "state", "[", "\"cfg\"", "]", "is", "not", "None", ":", "\n", "                ", "cfg", "=", "state", "[", "\"cfg\"", "]", "\n", "", "else", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "f\"Neither args nor cfg exist in state keys = {state.keys()}\"", "\n", ")", "\n", "\n", "", "if", "task", "is", "None", ":", "\n", "                ", "task", "=", "tasks", ".", "setup_task", "(", "cfg", ".", "task", ")", "\n", "\n", "# build model for ensemble", "\n", "", "model", "=", "task", ".", "build_model", "(", "cfg", ".", "model", ")", "\n", "\n", "model", ".", "load_state_dict", "(", "state", "[", "\"model\"", "]", ",", "strict", "=", "strict", ",", "model_cfg", "=", "cfg", ".", "model", ")", "\n", "\n", "# reset state so it gets loaded for the next model in ensemble", "\n", "state", "=", "None", "\n", "\n", "", "ensemble", ".", "append", "(", "model", ")", "\n", "", "return", "ensemble", ",", "cfg", ",", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.checkpoint_paths": [[316, 333], ["re.compile", "os.listdir", "enumerate", "re.compile.fullmatch", "os.path.join", "entries.append", "sorted", "float", "len", "pt_regexp.fullmatch.group", "pt_regexp.fullmatch.group", "pt_regexp.fullmatch.groups"], "function", ["None"], ["", "def", "checkpoint_paths", "(", "path", ",", "pattern", "=", "r\"checkpoint(\\d+)\\.pt\"", ")", ":", "\n", "    ", "\"\"\"Retrieves all checkpoints found in `path` directory.\n\n    Checkpoints are identified by matching filename to the specified pattern. If\n    the pattern contains groups, the result will be sorted by the first group in\n    descending order.\n    \"\"\"", "\n", "pt_regexp", "=", "re", ".", "compile", "(", "pattern", ")", "\n", "files", "=", "os", ".", "listdir", "(", "path", ")", "\n", "\n", "entries", "=", "[", "]", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "files", ")", ":", "\n", "        ", "m", "=", "pt_regexp", ".", "fullmatch", "(", "f", ")", "\n", "if", "m", "is", "not", "None", ":", "\n", "            ", "idx", "=", "float", "(", "m", ".", "group", "(", "1", ")", ")", "if", "len", "(", "m", ".", "groups", "(", ")", ")", ">", "0", "else", "i", "\n", "entries", ".", "append", "(", "(", "idx", ",", "m", ".", "group", "(", "0", ")", ")", ")", "\n", "", "", "return", "[", "os", ".", "path", ".", "join", "(", "path", ",", "x", "[", "1", "]", ")", "for", "x", "in", "sorted", "(", "entries", ",", "reverse", "=", "True", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.torch_persistent_save": [[335, 346], ["isinstance", "range", "fairseq.file_io.PathManager.open", "checkpoint_utils.torch_persistent_save", "torch.save", "logger.error", "traceback.format_exc"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.torch_persistent_save", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.save"], ["", "def", "torch_persistent_save", "(", "obj", ",", "f", ")", ":", "\n", "    ", "if", "isinstance", "(", "f", ",", "str", ")", ":", "\n", "        ", "with", "PathManager", ".", "open", "(", "f", ",", "\"wb\"", ")", "as", "h", ":", "\n", "            ", "torch_persistent_save", "(", "obj", ",", "h", ")", "\n", "", "return", "\n", "", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "torch", ".", "save", "(", "obj", ",", "f", ")", "\n", "", "except", "Exception", ":", "\n", "            ", "if", "i", "==", "2", ":", "\n", "                ", "logger", ".", "error", "(", "traceback", ".", "format_exc", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.save_state": [[348, 400], ["utils.has_parameters", "isinstance", "utils.move_to_cpu", "kwargs.get", "criterion.state_dict", "optimizer.state_dict", "fairseq.file_io.PathManager.open", "checkpoint_utils.torch_persistent_save", "lr_scheduler.state_dict"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.has_parameters", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.move_to_cpu", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.state_dict", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.state_dict", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.torch_persistent_save", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.state_dict"], ["", "", "", "", "def", "save_state", "(", "\n", "filename", ",", "\n", "cfg", ":", "FairseqConfig", ",", "\n", "model_state_dict", ",", "\n", "criterion", ",", "\n", "optimizer", ",", "\n", "lr_scheduler", ",", "\n", "num_updates", ",", "\n", "optim_history", "=", "None", ",", "\n", "extra_state", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "    ", "from", "fairseq", "import", "utils", "\n", "\n", "if", "optim_history", "is", "None", ":", "\n", "        ", "optim_history", "=", "[", "]", "\n", "", "if", "extra_state", "is", "None", ":", "\n", "        ", "extra_state", "=", "{", "}", "\n", "", "state_dict", "=", "{", "\n", "\"cfg\"", ":", "cfg", ",", "\n", "\"args\"", ":", "kwargs", ".", "get", "(", "\"args\"", ",", "None", ")", ",", "\n", "\"model\"", ":", "model_state_dict", "or", "{", "}", ",", "\n", "\"optimizer_history\"", ":", "optim_history", "\n", "+", "[", "\n", "{", "\n", "\"criterion_name\"", ":", "criterion", ".", "__class__", ".", "__name__", ",", "\n", "\"optimizer_name\"", ":", "optimizer", ".", "__class__", ".", "__name__", ",", "\n", "\"lr_scheduler_state\"", ":", "lr_scheduler", ".", "state_dict", "(", ")", ",", "\n", "\"num_updates\"", ":", "num_updates", ",", "\n", "}", "\n", "]", ",", "\n", "\"extra_state\"", ":", "extra_state", ",", "\n", "}", "\n", "if", "utils", ".", "has_parameters", "(", "criterion", ")", ":", "\n", "        ", "state_dict", "[", "\"criterion\"", "]", "=", "criterion", ".", "state_dict", "(", ")", "\n", "\n", "", "if", "cfg", "is", "None", ":", "\n", "        ", "cfg", "=", "state_dict", "[", "\"args\"", "]", "\n", "assert", "cfg", "is", "not", "None", ",", "\"must provide cfg or args\"", "\n", "\n", "", "if", "isinstance", "(", "cfg", ",", "DictConfig", ")", ":", "\n", "        ", "no_save_optimizer_state", "=", "cfg", ".", "checkpoint", ".", "no_save_optimizer_state", "\n", "", "else", ":", "\n", "        ", "no_save_optimizer_state", "=", "cfg", ".", "no_save_optimizer_state", "\n", "", "if", "not", "no_save_optimizer_state", ":", "\n", "        ", "state_dict", "[", "\"last_optimizer_state\"", "]", "=", "optimizer", ".", "state_dict", "(", ")", "\n", "\n", "# keep everything on CPU", "\n", "", "state_dict", "=", "utils", ".", "move_to_cpu", "(", "state_dict", ")", "\n", "\n", "with", "PathManager", ".", "open", "(", "filename", ",", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "torch_persistent_save", "(", "state_dict", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils._upgrade_state_dict": [[402, 484], ["getattr", "hasattr", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "state[].get", "hasattr", "getattr", "max", "omegaconf.open_dict", "[].get", "hasattr", "hasattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.convert_namespace_to_omegaconf"], ["", "", "def", "_upgrade_state_dict", "(", "state", ")", ":", "\n", "    ", "\"\"\"Helper for upgrading old model checkpoints.\"\"\"", "\n", "from", "fairseq", "import", "models", ",", "registry", ",", "tasks", "\n", "\n", "# add optimizer_history", "\n", "if", "\"optimizer_history\"", "not", "in", "state", ":", "\n", "        ", "state", "[", "\"optimizer_history\"", "]", "=", "[", "\n", "{", "\"criterion_name\"", ":", "\"CrossEntropyCriterion\"", ",", "\"best_loss\"", ":", "state", "[", "\"best_loss\"", "]", "}", "\n", "]", "\n", "state", "[", "\"last_optimizer_state\"", "]", "=", "state", "[", "\"optimizer\"", "]", "\n", "del", "state", "[", "\"optimizer\"", "]", "\n", "del", "state", "[", "\"best_loss\"", "]", "\n", "# move extra_state into sub-dictionary", "\n", "", "if", "\"epoch\"", "in", "state", "and", "\"extra_state\"", "not", "in", "state", ":", "\n", "        ", "state", "[", "\"extra_state\"", "]", "=", "{", "\n", "\"epoch\"", ":", "state", "[", "\"epoch\"", "]", ",", "\n", "\"batch_offset\"", ":", "state", "[", "\"batch_offset\"", "]", ",", "\n", "\"val_loss\"", ":", "state", "[", "\"val_loss\"", "]", ",", "\n", "}", "\n", "del", "state", "[", "\"epoch\"", "]", "\n", "del", "state", "[", "\"batch_offset\"", "]", "\n", "del", "state", "[", "\"val_loss\"", "]", "\n", "# reduce optimizer history's memory usage (only keep the last state)", "\n", "", "if", "\"optimizer\"", "in", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", ":", "\n", "        ", "state", "[", "\"last_optimizer_state\"", "]", "=", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", "[", "\"optimizer\"", "]", "\n", "for", "optim_hist", "in", "state", "[", "\"optimizer_history\"", "]", ":", "\n", "            ", "del", "optim_hist", "[", "\"optimizer\"", "]", "\n", "# record the optimizer class name", "\n", "", "", "if", "\"optimizer_name\"", "not", "in", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", ":", "\n", "        ", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", "[", "\"optimizer_name\"", "]", "=", "\"FairseqNAG\"", "\n", "# move best_loss into lr_scheduler_state", "\n", "", "if", "\"lr_scheduler_state\"", "not", "in", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", ":", "\n", "        ", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", "[", "\"lr_scheduler_state\"", "]", "=", "{", "\n", "\"best\"", ":", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", "[", "\"best_loss\"", "]", "\n", "}", "\n", "del", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", "[", "\"best_loss\"", "]", "\n", "# keep track of number of updates", "\n", "", "if", "\"num_updates\"", "not", "in", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", ":", "\n", "        ", "state", "[", "\"optimizer_history\"", "]", "[", "-", "1", "]", "[", "\"num_updates\"", "]", "=", "0", "\n", "# use stateful training data iterator", "\n", "", "if", "\"train_iterator\"", "not", "in", "state", "[", "\"extra_state\"", "]", ":", "\n", "        ", "state", "[", "\"extra_state\"", "]", "[", "\"train_iterator\"", "]", "=", "{", "\n", "\"epoch\"", ":", "state", "[", "\"extra_state\"", "]", "[", "\"epoch\"", "]", ",", "\n", "\"iterations_in_epoch\"", ":", "state", "[", "\"extra_state\"", "]", ".", "get", "(", "\"batch_offset\"", ",", "0", ")", ",", "\n", "}", "\n", "\n", "# old model checkpoints may not have separate source/target positions", "\n", "# backward compatibility, cfg updates", "\n", "", "if", "\"args\"", "in", "state", "and", "state", "[", "\"args\"", "]", "is", "not", "None", ":", "\n", "# default to translation task", "\n", "        ", "if", "not", "hasattr", "(", "state", "[", "\"args\"", "]", ",", "\"task\"", ")", ":", "\n", "            ", "state", "[", "\"args\"", "]", ".", "task", "=", "\"translation\"", "\n", "# --raw-text and --lazy-load are deprecated", "\n", "", "if", "getattr", "(", "state", "[", "\"args\"", "]", ",", "\"raw_text\"", ",", "False", ")", ":", "\n", "            ", "state", "[", "\"args\"", "]", ".", "dataset_impl", "=", "\"raw\"", "\n", "", "elif", "getattr", "(", "state", "[", "\"args\"", "]", ",", "\"lazy_load\"", ",", "False", ")", ":", "\n", "            ", "state", "[", "\"args\"", "]", ".", "dataset_impl", "=", "\"lazy\"", "\n", "# epochs start at 1", "\n", "", "if", "state", "[", "\"extra_state\"", "]", "[", "\"train_iterator\"", "]", "is", "not", "None", ":", "\n", "            ", "state", "[", "\"extra_state\"", "]", "[", "\"train_iterator\"", "]", "[", "\"epoch\"", "]", "=", "max", "(", "\n", "state", "[", "\"extra_state\"", "]", "[", "\"train_iterator\"", "]", ".", "get", "(", "\"epoch\"", ",", "1", ")", ",", "1", "\n", ")", "\n", "\n", "", "if", "hasattr", "(", "state", "[", "\"args\"", "]", ",", "\"remove_bpe\"", ")", ":", "\n", "            ", "state", "[", "\"args\"", "]", ".", "post_process", "=", "state", "[", "\"args\"", "]", ".", "remove_bpe", "\n", "\n", "", "state", "[", "\"cfg\"", "]", "=", "convert_namespace_to_omegaconf", "(", "state", "[", "\"args\"", "]", ")", "\n", "\n", "", "if", "\"cfg\"", "in", "state", "and", "state", "[", "\"cfg\"", "]", "is", "not", "None", ":", "\n", "        ", "with", "open_dict", "(", "state", "[", "\"cfg\"", "]", ")", ":", "\n", "            ", "if", "state", "[", "\"cfg\"", "]", ".", "task", "is", "not", "None", ":", "\n", "                ", "if", "hasattr", "(", "state", "[", "\"cfg\"", "]", ".", "task", ",", "\"max_positions\"", ")", "and", "not", "hasattr", "(", "\n", "state", "[", "\"cfg\"", "]", ".", "task", ",", "\"max_source_positions\"", "\n", ")", ":", "\n", "                    ", "state", "[", "\"cfg\"", "]", ".", "task", ".", "max_source_positions", "=", "state", "[", "\n", "\"cfg\"", "\n", "]", ".", "task", ".", "max_positions", "\n", "state", "[", "\"cfg\"", "]", ".", "task", ".", "max_target_positions", "=", "state", "[", "\n", "\"cfg\"", "\n", "]", ".", "task", ".", "max_positions", "\n", "\n", "", "", "", "", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.prune_state_dict": [[486, 574], ["getattr", "getattr", "logger.info", "state_dict.keys", "sorted", "range", "re.compile", "pruning_passes.append", "pruning_passes.append", "re.search", "re.search.group", "omegaconf.open_dict", "hasattr", "hasattr", "isinstance", "getattr", "len", "str", "checkpoint_utils.prune_state_dict.create_pruning_pass"], "function", ["None"], ["", "def", "prune_state_dict", "(", "state_dict", ",", "model_cfg", ":", "Optional", "[", "DictConfig", "]", ")", ":", "\n", "    ", "\"\"\"Prune the given state_dict if desired for LayerDrop\n    (https://arxiv.org/abs/1909.11556).\n\n    Training with LayerDrop allows models to be robust to pruning at inference\n    time. This function prunes state_dict to allow smaller models to be loaded\n    from a larger model and re-maps the existing state_dict for this to occur.\n\n    It's called by functions that load models from checkpoints and does not\n    need to be called directly.\n    \"\"\"", "\n", "arch", "=", "None", "\n", "if", "model_cfg", "is", "not", "None", ":", "\n", "        ", "arch", "=", "(", "\n", "model_cfg", ".", "_name", "\n", "if", "isinstance", "(", "model_cfg", ",", "DictConfig", ")", "\n", "else", "getattr", "(", "model_cfg", ",", "\"arch\"", ",", "None", ")", "\n", ")", "\n", "\n", "", "if", "not", "model_cfg", "or", "arch", "is", "None", "or", "arch", "==", "\"ptt_transformer\"", ":", "\n", "# args should not be none, but don't crash if it is.", "\n", "        ", "return", "state_dict", "\n", "\n", "", "encoder_layers_to_keep", "=", "getattr", "(", "model_cfg", ",", "\"encoder_layers_to_keep\"", ",", "None", ")", "\n", "decoder_layers_to_keep", "=", "getattr", "(", "model_cfg", ",", "\"decoder_layers_to_keep\"", ",", "None", ")", "\n", "\n", "if", "not", "encoder_layers_to_keep", "and", "not", "decoder_layers_to_keep", ":", "\n", "        ", "return", "state_dict", "\n", "\n", "# apply pruning", "\n", "", "logger", ".", "info", "(", "\n", "\"Pruning model to specified layer configuration - this works best if the model was trained with LayerDrop\"", "\n", ")", "\n", "\n", "def", "create_pruning_pass", "(", "layers_to_keep", ",", "layer_name", ")", ":", "\n", "        ", "keep_layers", "=", "sorted", "(", "\n", "int", "(", "layer_string", ")", "for", "layer_string", "in", "layers_to_keep", ".", "split", "(", "\",\"", ")", "\n", ")", "\n", "mapping_dict", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "keep_layers", ")", ")", ":", "\n", "            ", "mapping_dict", "[", "str", "(", "keep_layers", "[", "i", "]", ")", "]", "=", "str", "(", "i", ")", "\n", "\n", "", "regex", "=", "re", ".", "compile", "(", "r\"^{layer}.*\\.layers\\.(\\d+)\"", ".", "format", "(", "layer", "=", "layer_name", ")", ")", "\n", "return", "{", "\"substitution_regex\"", ":", "regex", ",", "\"mapping_dict\"", ":", "mapping_dict", "}", "\n", "\n", "", "pruning_passes", "=", "[", "]", "\n", "if", "encoder_layers_to_keep", ":", "\n", "        ", "pruning_passes", ".", "append", "(", "create_pruning_pass", "(", "encoder_layers_to_keep", ",", "\"encoder\"", ")", ")", "\n", "", "if", "decoder_layers_to_keep", ":", "\n", "        ", "pruning_passes", ".", "append", "(", "create_pruning_pass", "(", "decoder_layers_to_keep", ",", "\"decoder\"", ")", ")", "\n", "\n", "", "new_state_dict", "=", "{", "}", "\n", "for", "layer_name", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "        ", "match", "=", "re", ".", "search", "(", "r\"\\.layers\\.(\\d+)\\.\"", ",", "layer_name", ")", "\n", "# if layer has no number in it, it is a supporting layer, such as an", "\n", "# embedding", "\n", "if", "not", "match", ":", "\n", "            ", "new_state_dict", "[", "layer_name", "]", "=", "state_dict", "[", "layer_name", "]", "\n", "continue", "\n", "\n", "# otherwise, layer should be pruned.", "\n", "", "original_layer_number", "=", "match", ".", "group", "(", "1", ")", "\n", "# figure out which mapping dict to replace from", "\n", "for", "pruning_pass", "in", "pruning_passes", ":", "\n", "            ", "if", "original_layer_number", "in", "pruning_pass", "[", "\"mapping_dict\"", "]", "and", "pruning_pass", "[", "\n", "\"substitution_regex\"", "\n", "]", ".", "search", "(", "layer_name", ")", ":", "\n", "                ", "new_layer_number", "=", "pruning_pass", "[", "\"mapping_dict\"", "]", "[", "original_layer_number", "]", "\n", "substitution_match", "=", "pruning_pass", "[", "\"substitution_regex\"", "]", ".", "search", "(", "\n", "layer_name", "\n", ")", "\n", "new_state_key", "=", "(", "\n", "layer_name", "[", ":", "substitution_match", ".", "start", "(", "1", ")", "]", "\n", "+", "new_layer_number", "\n", "+", "layer_name", "[", "substitution_match", ".", "end", "(", "1", ")", ":", "]", "\n", ")", "\n", "new_state_dict", "[", "new_state_key", "]", "=", "state_dict", "[", "layer_name", "]", "\n", "\n", "# Since layers are now pruned, *_layers_to_keep are no longer needed.", "\n", "# This is more of \"It would make it work fix\" rather than a proper fix.", "\n", "\n", "", "", "", "with", "open_dict", "(", "model_cfg", ")", ":", "\n", "        ", "if", "hasattr", "(", "model_cfg", ",", "\"encoder_layers_to_keep\"", ")", ":", "\n", "            ", "model_cfg", ".", "encoder_layers_to_keep", "=", "None", "\n", "", "if", "hasattr", "(", "model_cfg", ",", "\"decoder_layers_to_keep\"", ")", ":", "\n", "            ", "model_cfg", ".", "decoder_layers_to_keep", "=", "None", "\n", "\n", "", "", "return", "new_state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_pretrained_component_from_model": [[576, 605], ["checkpoint_utils.load_checkpoint_to_cpu", "isinstance", "collections.OrderedDict", "state[].keys", "component.load_state_dict", "fairseq.file_io.PathManager.exists", "IOError", "isinstance", "key.startswith", "ValueError", "len"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_checkpoint_to_cpu", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists"], ["", "def", "load_pretrained_component_from_model", "(", "\n", "component", ":", "Union", "[", "FairseqEncoder", ",", "FairseqDecoder", "]", ",", "checkpoint", ":", "str", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Load a pretrained FairseqEncoder or FairseqDecoder from checkpoint into the\n    provided `component` object. If state_dict fails to load, there may be a\n    mismatch in the architecture of the corresponding `component` found in the\n    `checkpoint` file.\n    \"\"\"", "\n", "if", "not", "PathManager", ".", "exists", "(", "checkpoint", ")", ":", "\n", "        ", "raise", "IOError", "(", "\"Model file not found: {}\"", ".", "format", "(", "checkpoint", ")", ")", "\n", "", "state", "=", "load_checkpoint_to_cpu", "(", "checkpoint", ")", "\n", "if", "isinstance", "(", "component", ",", "FairseqEncoder", ")", ":", "\n", "        ", "component_type", "=", "\"encoder\"", "\n", "", "elif", "isinstance", "(", "component", ",", "FairseqDecoder", ")", ":", "\n", "        ", "component_type", "=", "\"decoder\"", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"component to load must be either a FairseqEncoder or \"", "\n", "\"FairseqDecoder. Loading other component types are not supported.\"", "\n", ")", "\n", "", "component_state_dict", "=", "OrderedDict", "(", ")", "\n", "for", "key", "in", "state", "[", "\"model\"", "]", ".", "keys", "(", ")", ":", "\n", "        ", "if", "key", ".", "startswith", "(", "component_type", ")", ":", "\n", "# encoder.input_layers.0.0.weight --> input_layers.0.0.weight", "\n", "            ", "component_subkey", "=", "key", "[", "len", "(", "component_type", ")", "+", "1", ":", "]", "\n", "component_state_dict", "[", "component_subkey", "]", "=", "state", "[", "\"model\"", "]", "[", "key", "]", "\n", "", "", "component", ".", "load_state_dict", "(", "component_state_dict", ",", "strict", "=", "True", ")", "\n", "return", "component", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.verify_checkpoint_directory": [[607, 621], ["os.path.join", "os.path.exists", "os.makedirs", "os.remove", "open", "logger.warning"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["", "def", "verify_checkpoint_directory", "(", "save_dir", ":", "str", ")", "->", "None", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "save_dir", ",", "exist_ok", "=", "True", ")", "\n", "", "temp_file_path", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"dummy\"", ")", "\n", "try", ":", "\n", "        ", "with", "open", "(", "temp_file_path", ",", "\"w\"", ")", ":", "\n", "            ", "pass", "\n", "", "", "except", "OSError", "as", "e", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "\"Unable to access checkpoint save directory: {}\"", ".", "format", "(", "save_dir", ")", "\n", ")", "\n", "raise", "e", "\n", "", "else", ":", "\n", "        ", "os", ".", "remove", "(", "temp_file_path", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.__init__": [[19, 107], ["torch.Module.__init__", "isinstance", "tgt_dict.pad", "tgt_dict.unk", "len", "min", "sequence_generator.SequenceGenerator.model.eval", "sequence_generator.EnsembleModel", "tgt_dict.eos", "symbols_to_strip_from_output.union", "fairseq.search.BeamSearch", "hasattr", "sequence_generator.SequenceGenerator.lm_model.eval"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "models", ",", "\n", "tgt_dict", ",", "\n", "beam_size", "=", "1", ",", "\n", "max_len_a", "=", "0", ",", "\n", "max_len_b", "=", "200", ",", "\n", "min_len", "=", "1", ",", "\n", "normalize_scores", "=", "True", ",", "\n", "len_penalty", "=", "1.0", ",", "\n", "unk_penalty", "=", "0.0", ",", "\n", "temperature", "=", "1.0", ",", "\n", "match_source_len", "=", "False", ",", "\n", "no_repeat_ngram_size", "=", "0", ",", "\n", "search_strategy", "=", "None", ",", "\n", "eos", "=", "None", ",", "\n", "symbols_to_strip_from_output", "=", "None", ",", "\n", "lm_model", "=", "None", ",", "\n", "lm_weight", "=", "1.0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Generates translations of a given source sentence.\n\n        Args:\n            models (List[~fairseq.models.FairseqModel]): ensemble of models,\n                currently support fairseq.models.TransformerModel for scripting\n            beam_size (int, optional): beam width (default: 1)\n            max_len_a/b (int, optional): generate sequences of maximum length\n                ax + b, where x is the source length\n            min_len (int, optional): the minimum length of the generated output\n                (not including end-of-sentence)\n            normalize_scores (bool, optional): normalize scores by the length\n                of the output (default: True)\n            len_penalty (float, optional): length penalty, where <1.0 favors\n                shorter, >1.0 favors longer sentences (default: 1.0)\n            unk_penalty (float, optional): unknown word penalty, where <0\n                produces more unks, >0 produces fewer (default: 0.0)\n            temperature (float, optional): temperature, where values\n                >1.0 produce more uniform samples and values <1.0 produce\n                sharper samples (default: 1.0)\n            match_source_len (bool, optional): outputs should match the source\n                length (default: False)\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "models", ",", "EnsembleModel", ")", ":", "\n", "            ", "self", ".", "model", "=", "models", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", "=", "EnsembleModel", "(", "models", ")", "\n", "", "self", ".", "tgt_dict", "=", "tgt_dict", "\n", "self", ".", "pad", "=", "tgt_dict", ".", "pad", "(", ")", "\n", "self", ".", "unk", "=", "tgt_dict", ".", "unk", "(", ")", "\n", "self", ".", "eos", "=", "tgt_dict", ".", "eos", "(", ")", "if", "eos", "is", "None", "else", "eos", "\n", "self", ".", "symbols_to_strip_from_output", "=", "(", "\n", "symbols_to_strip_from_output", ".", "union", "(", "{", "self", ".", "eos", "}", ")", "\n", "if", "symbols_to_strip_from_output", "is", "not", "None", "\n", "else", "{", "self", ".", "eos", "}", "\n", ")", "\n", "self", ".", "vocab_size", "=", "len", "(", "tgt_dict", ")", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "# the max beam size is the dictionary size - 1, since we never select pad", "\n", "self", ".", "beam_size", "=", "min", "(", "beam_size", ",", "self", ".", "vocab_size", "-", "1", ")", "\n", "self", ".", "max_len_a", "=", "max_len_a", "\n", "self", ".", "max_len_b", "=", "max_len_b", "\n", "self", ".", "min_len", "=", "min_len", "\n", "\n", "self", ".", "normalize_scores", "=", "normalize_scores", "\n", "self", ".", "len_penalty", "=", "len_penalty", "\n", "self", ".", "unk_penalty", "=", "unk_penalty", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "match_source_len", "=", "match_source_len", "\n", "self", ".", "no_repeat_ngram_size", "=", "no_repeat_ngram_size", "\n", "assert", "temperature", ">", "0", ",", "\"--temperature must be greater than 0\"", "\n", "\n", "self", ".", "search", "=", "(", "\n", "search", ".", "BeamSearch", "(", "tgt_dict", ")", "if", "search_strategy", "is", "None", "else", "search_strategy", "\n", ")", "\n", "# We only need to set src_lengths in LengthConstrainedBeamSearch.", "\n", "# As a module attribute, setting it would break in multithread", "\n", "# settings when the model is shared.", "\n", "self", ".", "should_set_src_lengths", "=", "(", "\n", "hasattr", "(", "self", ".", "search", ",", "\"needs_src_lengths\"", ")", "and", "self", ".", "search", ".", "needs_src_lengths", "\n", ")", "\n", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "self", ".", "lm_model", "=", "lm_model", "\n", "self", ".", "lm_weight", "=", "lm_weight", "\n", "if", "self", ".", "lm_model", "is", "not", "None", ":", "\n", "            ", "self", ".", "lm_model", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.cuda": [[108, 111], ["sequence_generator.SequenceGenerator.model.cuda"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.cuda"], ["", "", "def", "cuda", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", ".", "cuda", "(", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.forward": [[112, 129], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sequence_generator.SequenceGenerator._generate"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator._generate"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "sample", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Tensor", "]", "]", ",", "\n", "prefix_tokens", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "bos_token", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Generate a batch of translations.\n\n        Args:\n            sample (dict): batch\n            prefix_tokens (torch.LongTensor, optional): force decoder to begin\n                with these tokens\n            bos_token (int, optional): beginning of sentence token\n                (default: self.eos)\n        \"\"\"", "\n", "return", "self", ".", "_generate", "(", "sample", ",", "prefix_tokens", ",", "bos_token", "=", "bos_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.generate_batched_itr": [[131, 162], ["enumerate", "fairseq.utils.move_to_cuda", "timer.start", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sequence_generator.SequenceGenerator.generate", "timer.stop", "fairseq.utils.strip_pad", "input.items", "sum", "fairseq.utils.strip_pad", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.move_to_cuda", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.start", "home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.generate", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.stop", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.strip_pad", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.strip_pad"], ["", "def", "generate_batched_itr", "(", "self", ",", "data_itr", ",", "beam_size", "=", "None", ",", "cuda", "=", "False", ",", "timer", "=", "None", ")", ":", "\n", "        ", "\"\"\"Iterate over a batched dataset and yield individual translations.\n        Args:\n            cuda (bool, optional): use GPU for generation\n            timer (StopwatchMeter, optional): time generations\n        \"\"\"", "\n", "for", "sample", "in", "data_itr", ":", "\n", "            ", "s", "=", "utils", ".", "move_to_cuda", "(", "sample", ")", "if", "cuda", "else", "sample", "\n", "if", "\"net_input\"", "not", "in", "s", ":", "\n", "                ", "continue", "\n", "", "input", "=", "s", "[", "\"net_input\"", "]", "\n", "# model.forward normally channels prev_output_tokens into the decoder", "\n", "# separately, but SequenceGenerator directly calls model.encoder", "\n", "encoder_input", "=", "{", "\n", "k", ":", "v", "for", "k", ",", "v", "in", "input", ".", "items", "(", ")", "if", "k", "!=", "\"prev_output_tokens\"", "\n", "}", "\n", "if", "timer", "is", "not", "None", ":", "\n", "                ", "timer", ".", "start", "(", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "hypos", "=", "self", ".", "generate", "(", "encoder_input", ")", "\n", "", "if", "timer", "is", "not", "None", ":", "\n", "                ", "timer", ".", "stop", "(", "sum", "(", "len", "(", "h", "[", "0", "]", "[", "\"tokens\"", "]", ")", "for", "h", "in", "hypos", ")", ")", "\n", "", "for", "i", ",", "id", "in", "enumerate", "(", "s", "[", "\"id\"", "]", ".", "data", ")", ":", "\n", "# remove padding", "\n", "                ", "src", "=", "utils", ".", "strip_pad", "(", "input", "[", "\"src_tokens\"", "]", ".", "data", "[", "i", ",", ":", "]", ",", "self", ".", "pad", ")", "\n", "ref", "=", "(", "\n", "utils", ".", "strip_pad", "(", "s", "[", "\"target\"", "]", ".", "data", "[", "i", ",", ":", "]", ",", "self", ".", "pad", ")", "\n", "if", "s", "[", "\"target\"", "]", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "yield", "id", ",", "src", ",", "ref", ",", "hypos", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.generate": [[163, 178], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sequence_generator.SequenceGenerator._generate"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator._generate"], ["", "", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate", "(", "self", ",", "models", ",", "sample", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Tensor", "]", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Generate translations. Match the api of other fairseq generators.\n\n        Args:\n            models (List[~fairseq.models.FairseqModel]): ensemble of models\n            sample (dict): batch\n            prefix_tokens (torch.LongTensor, optional): force decoder to begin\n                with these tokens\n            constraints (torch.LongTensor, optional): force decoder to include\n                the list of constraints\n            bos_token (int, optional): beginning of sentence token\n                (default: self.eos)\n        \"\"\"", "\n", "return", "self", ".", "_generate", "(", "sample", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator._generate": [[179, 543], ["torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "sequence_generator.SequenceGenerator.search.init_constraints", "sequence_generator.SequenceGenerator.model.forward_encoder", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "new_order.to().long.to().long.to().long", "sequence_generator.SequenceGenerator.model.reorder_encoder_out", "torch.zeros().to().float", "torch.zeros().to().float", "torch.zeros().to().float", "torch.zeros().to().float", "torch.zeros().to().long().fill_", "torch.zeros().to().long().fill_", "torch.zeros().to().long().fill_", "torch.zeros().to().long().fill_", "torch.zeros().to().eq", "torch.zeros().to().eq", "torch.zeros().to().eq", "torch.zeros().to().eq", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "range", "range", "src_tokens.size", "NotImplementedError", "src_lengths.max().item", "min", "isinstance", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "sequence_generator.SequenceGenerator.model.forward_decoder", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "[].view.type_as", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "sequence_generator.SequenceGenerator.search.step", "cand_beams.add", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.add", "torch.add", "torch.add", "torch.add", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "active_bbsz_idx.view.view.view", "active_scores.view.view.view", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "sequence_generator.SequenceGenerator.search.update_constraints", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "Exception", "int", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view().repeat", "new_order.to().long.to().long.to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to().long", "torch.zeros().to().long", "torch.zeros().to().long", "torch.zeros().to().long", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "range", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "sequence_generator.SequenceGenerator.model.reorder_incremental_state", "sequence_generator.SequenceGenerator.model.reorder_encoder_out", "sequence_generator.SequenceGenerator.lm_model", "sequence_generator.SequenceGenerator.lm_model.get_normalized_probs", "sequence_generator.SequenceGenerator._prefix_tokens", "attn[].copy_", "sequence_generator.SequenceGenerator.search.set_src_lengths", "sequence_generator.SequenceGenerator._no_repeat_ngram", "sequence_generator.SequenceGenerator.view", "cand_indices.eq", "cand_scores.ne", "torch.masked_select.numel", "torch.masked_select.numel", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "sequence_generator.SequenceGenerator.finalize_hypos", "len", "len", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.arange().masked_select", "torch.arange().masked_select", "torch.arange().masked_select", "torch.arange().masked_select", "sequence_generator.SequenceGenerator.search.prune_sentences", "bbsz_offsets.resize_", "cand_beams.add", "[].view", "[].view", "new_cands_to_ignore.ge", "[].view.view", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "[].view.view", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "range", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "src_lengths.max", "sequence_generator.SequenceGenerator.model.max_decoder_positions", "range", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "reorder_state.view().add_", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "prefix_tokens.size", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "[].view.view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "[].view", "eos_mask.type_as", "float", "net_input[].size", "net_input[].sum", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "[].view.size", "eos_mask.size", "elem[].item", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "reorder_state.view", "corr.unsqueeze", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "[].view.view", "[].view.view", "src_tokens.ne", "src_tokens.ne", "src_tokens.size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "avg_attn_scores.size", "[].view.view", "torch.arange().masked_select.numel", "torch.arange().masked_select.numel"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.search.LexicallyConstrainedBeamSearch.init_constraints", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.BasicEnsembleModel.forward_encoder", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerEncoder.reorder_encoder_out", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_decoder", "home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add", "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.LexicallyConstrainedBeamSearch.update_constraints", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.LSTMDecoder.reorder_incremental_state", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerEncoder.reorder_encoder_out", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.get_normalized_probs", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator._prefix_tokens", "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.Search.set_src_lengths", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator._no_repeat_ngram", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.finalize_hypos", "home.repos.pwc.inspect_result.reneeye_const.fairseq.search.LexicallyConstrainedBeamSearch.prune_sentences", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.max_decoder_positions", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "_generate", "(", "\n", "self", ",", "\n", "sample", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Tensor", "]", "]", ",", "\n", "prefix_tokens", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "constraints", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "bos_token", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "incremental_states", "=", "torch", ".", "jit", ".", "annotate", "(", "\n", "List", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "[", "\n", "torch", ".", "jit", ".", "annotate", "(", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ",", "{", "}", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "model", ".", "models_size", ")", "\n", "]", ",", "\n", ")", "\n", "net_input", "=", "sample", "[", "\"net_input\"", "]", "\n", "\n", "if", "\"src_tokens\"", "in", "net_input", ":", "\n", "            ", "src_tokens", "=", "net_input", "[", "\"src_tokens\"", "]", "\n", "# length of the source text being the character length except EndOfSentence and pad", "\n", "src_lengths", "=", "(", "\n", "(", "src_tokens", ".", "ne", "(", "self", ".", "eos", ")", "&", "src_tokens", ".", "ne", "(", "self", ".", "pad", ")", ")", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", ")", "\n", "", "elif", "\"source\"", "in", "net_input", ":", "\n", "            ", "src_tokens", "=", "net_input", "[", "\"source\"", "]", "\n", "src_lengths", "=", "(", "\n", "net_input", "[", "\"padding_mask\"", "]", ".", "size", "(", "-", "1", ")", "-", "net_input", "[", "\"padding_mask\"", "]", ".", "sum", "(", "-", "1", ")", "\n", "if", "net_input", "[", "\"padding_mask\"", "]", "is", "not", "None", "\n", "else", "torch", ".", "tensor", "(", "src_tokens", ".", "size", "(", "-", "1", ")", ")", ".", "to", "(", "src_tokens", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"expected src_tokens or source in net input\"", ")", "\n", "\n", "# bsz: total number of sentences in beam", "\n", "# Note that src_tokens may have more than 2 dimenions (i.e. audio features)", "\n", "", "bsz", ",", "src_len", "=", "src_tokens", ".", "size", "(", ")", "[", ":", "2", "]", "\n", "beam_size", "=", "self", ".", "beam_size", "\n", "\n", "if", "constraints", "is", "not", "None", "and", "not", "self", ".", "search", ".", "supports_constraints", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Target-side constraints were provided, but search method doesn't support them\"", "\n", ")", "\n", "\n", "# Initialize constraints, when active", "\n", "", "self", ".", "search", ".", "init_constraints", "(", "constraints", ",", "beam_size", ")", "\n", "\n", "max_len", ":", "int", "=", "-", "1", "\n", "if", "self", ".", "match_source_len", ":", "\n", "            ", "max_len", "=", "src_lengths", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "            ", "max_len", "=", "min", "(", "\n", "int", "(", "self", ".", "max_len_a", "*", "src_len", "+", "self", ".", "max_len_b", ")", ",", "\n", "# exclude the EOS marker", "\n", "self", ".", "model", ".", "max_decoder_positions", "(", ")", "-", "1", ",", "\n", ")", "\n", "", "assert", "(", "\n", "self", ".", "min_len", "<=", "max_len", "\n", ")", ",", "\"min_len cannot be larger than max_len, please adjust these!\"", "\n", "# compute the encoder output for each beam", "\n", "encoder_outs", "=", "self", ".", "model", ".", "forward_encoder", "(", "net_input", ")", "\n", "\n", "# placeholder of indices for bsz * beam_size to hold tokens and accumulative scores", "\n", "new_order", "=", "torch", ".", "arange", "(", "bsz", ")", ".", "view", "(", "-", "1", ",", "1", ")", ".", "repeat", "(", "1", ",", "beam_size", ")", ".", "view", "(", "-", "1", ")", "\n", "new_order", "=", "new_order", ".", "to", "(", "src_tokens", ".", "device", ")", ".", "long", "(", ")", "\n", "encoder_outs", "=", "self", ".", "model", ".", "reorder_encoder_out", "(", "encoder_outs", ",", "new_order", ")", "\n", "# ensure encoder_outs is a List.", "\n", "assert", "encoder_outs", "is", "not", "None", "\n", "\n", "# initialize buffers", "\n", "scores", "=", "(", "\n", "torch", ".", "zeros", "(", "bsz", "*", "beam_size", ",", "max_len", "+", "1", ")", ".", "to", "(", "src_tokens", ")", ".", "float", "(", ")", "\n", ")", "# +1 for eos; pad is never chosen for scoring", "\n", "tokens", "=", "(", "\n", "torch", ".", "zeros", "(", "bsz", "*", "beam_size", ",", "max_len", "+", "2", ")", "\n", ".", "to", "(", "src_tokens", ")", "\n", ".", "long", "(", ")", "\n", ".", "fill_", "(", "self", ".", "pad", ")", "\n", ")", "# +2 for eos and pad", "\n", "tokens", "[", ":", ",", "0", "]", "=", "self", ".", "eos", "if", "bos_token", "is", "None", "else", "bos_token", "\n", "attn", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "\n", "# A list that indicates candidates that should be ignored.", "\n", "# For example, suppose we're sampling and have already finalized 2/5", "\n", "# samples. Then cands_to_ignore would mark 2 positions as being ignored,", "\n", "# so that we only finalize the remaining 3 samples.", "\n", "cands_to_ignore", "=", "(", "\n", "torch", ".", "zeros", "(", "bsz", ",", "beam_size", ")", ".", "to", "(", "src_tokens", ")", ".", "eq", "(", "-", "1", ")", "\n", ")", "# forward and backward-compatible False mask", "\n", "\n", "# list of completed sentences", "\n", "finalized", "=", "torch", ".", "jit", ".", "annotate", "(", "\n", "List", "[", "List", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", "]", ",", "\n", "[", "torch", ".", "jit", ".", "annotate", "(", "List", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", ",", "[", "]", ")", "for", "i", "in", "range", "(", "bsz", ")", "]", ",", "\n", ")", "# contains lists of dictionaries of infomation about the hypothesis being finalized at each step", "\n", "\n", "finished", "=", "[", "\n", "False", "for", "i", "in", "range", "(", "bsz", ")", "\n", "]", "# a boolean array indicating if the sentence at the index is finished or not", "\n", "num_remaining_sent", "=", "bsz", "# number of sentences remaining", "\n", "\n", "# number of candidate hypos per step", "\n", "cand_size", "=", "2", "*", "beam_size", "# 2 x beam size in case half are EOS", "\n", "\n", "# offset arrays for converting between different indexing schemes", "\n", "bbsz_offsets", "=", "(", "torch", ".", "arange", "(", "0", ",", "bsz", ")", "*", "beam_size", ")", ".", "unsqueeze", "(", "1", ")", ".", "type_as", "(", "tokens", ")", "\n", "cand_offsets", "=", "torch", ".", "arange", "(", "0", ",", "cand_size", ")", ".", "type_as", "(", "tokens", ")", "\n", "\n", "reorder_state", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "batch_idxs", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "\n", "original_batch_idxs", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "if", "\"id\"", "in", "sample", "and", "isinstance", "(", "sample", "[", "\"id\"", "]", ",", "Tensor", ")", ":", "\n", "            ", "original_batch_idxs", "=", "sample", "[", "\"id\"", "]", "\n", "", "else", ":", "\n", "            ", "original_batch_idxs", "=", "torch", ".", "arange", "(", "0", ",", "bsz", ")", ".", "type_as", "(", "tokens", ")", "\n", "\n", "", "for", "step", "in", "range", "(", "max_len", "+", "1", ")", ":", "# one extra step for EOS marker", "\n", "# reorder decoder internal states based on the prev choice of beams", "\n", "            ", "if", "reorder_state", "is", "not", "None", ":", "\n", "                ", "if", "batch_idxs", "is", "not", "None", ":", "\n", "# update beam indices to take into account removed sentences", "\n", "                    ", "corr", "=", "batch_idxs", "-", "torch", ".", "arange", "(", "batch_idxs", ".", "numel", "(", ")", ")", ".", "type_as", "(", "\n", "batch_idxs", "\n", ")", "\n", "reorder_state", ".", "view", "(", "-", "1", ",", "beam_size", ")", ".", "add_", "(", "\n", "corr", ".", "unsqueeze", "(", "-", "1", ")", "*", "beam_size", "\n", ")", "\n", "original_batch_idxs", "=", "original_batch_idxs", "[", "batch_idxs", "]", "\n", "", "self", ".", "model", ".", "reorder_incremental_state", "(", "incremental_states", ",", "reorder_state", ")", "\n", "encoder_outs", "=", "self", ".", "model", ".", "reorder_encoder_out", "(", "\n", "encoder_outs", ",", "reorder_state", "\n", ")", "\n", "\n", "", "lprobs", ",", "avg_attn_scores", "=", "self", ".", "model", ".", "forward_decoder", "(", "\n", "tokens", "[", ":", ",", ":", "step", "+", "1", "]", ",", "\n", "encoder_outs", ",", "\n", "incremental_states", ",", "\n", "self", ".", "temperature", ",", "\n", ")", "\n", "\n", "if", "self", ".", "lm_model", "is", "not", "None", ":", "\n", "                ", "lm_out", "=", "self", ".", "lm_model", "(", "tokens", "[", ":", ",", ":", "step", "+", "1", "]", ")", "\n", "probs", "=", "self", ".", "lm_model", ".", "get_normalized_probs", "(", "\n", "lm_out", ",", "log_probs", "=", "True", ",", "sample", "=", "None", "\n", ")", "\n", "probs", "=", "probs", "[", ":", ",", "-", "1", ",", ":", "]", "*", "self", ".", "lm_weight", "\n", "lprobs", "+=", "probs", "\n", "\n", "", "lprobs", "[", "lprobs", "!=", "lprobs", "]", "=", "torch", ".", "tensor", "(", "-", "math", ".", "inf", ")", ".", "to", "(", "lprobs", ")", "\n", "\n", "lprobs", "[", ":", ",", "self", ".", "pad", "]", "=", "-", "math", ".", "inf", "# never select pad", "\n", "lprobs", "[", ":", ",", "self", ".", "unk", "]", "-=", "self", ".", "unk_penalty", "# apply unk penalty", "\n", "\n", "# handle max length constraint", "\n", "if", "step", ">=", "max_len", ":", "\n", "                ", "lprobs", "[", ":", ",", ":", "self", ".", "eos", "]", "=", "-", "math", ".", "inf", "\n", "lprobs", "[", ":", ",", "self", ".", "eos", "+", "1", ":", "]", "=", "-", "math", ".", "inf", "\n", "\n", "# handle prefix tokens (possibly with different lengths)", "\n", "", "if", "(", "\n", "prefix_tokens", "is", "not", "None", "\n", "and", "step", "<", "prefix_tokens", ".", "size", "(", "1", ")", "\n", "and", "step", "<", "max_len", "\n", ")", ":", "\n", "                ", "lprobs", ",", "tokens", ",", "scores", "=", "self", ".", "_prefix_tokens", "(", "\n", "step", ",", "lprobs", ",", "scores", ",", "tokens", ",", "prefix_tokens", ",", "beam_size", "\n", ")", "\n", "\n", "", "elif", "step", "<", "self", ".", "min_len", ":", "\n", "# minimum length constraint (does not apply if using prefix_tokens)", "\n", "                ", "lprobs", "[", ":", ",", "self", ".", "eos", "]", "=", "-", "math", ".", "inf", "\n", "\n", "# Record attention scores, only support avg_attn_scores is a Tensor", "\n", "", "if", "avg_attn_scores", "is", "not", "None", ":", "\n", "                ", "if", "attn", "is", "None", ":", "\n", "                    ", "attn", "=", "torch", ".", "empty", "(", "\n", "bsz", "*", "beam_size", ",", "avg_attn_scores", ".", "size", "(", "1", ")", ",", "max_len", "+", "2", "\n", ")", ".", "to", "(", "scores", ")", "\n", "", "attn", "[", ":", ",", ":", ",", "step", "+", "1", "]", ".", "copy_", "(", "avg_attn_scores", ")", "\n", "\n", "", "scores", "=", "scores", ".", "type_as", "(", "lprobs", ")", "\n", "eos_bbsz_idx", "=", "torch", ".", "empty", "(", "0", ")", ".", "to", "(", "\n", "tokens", "\n", ")", "# indices of hypothesis ending with eos (finished sentences)", "\n", "eos_scores", "=", "torch", ".", "empty", "(", "0", ")", ".", "to", "(", "\n", "scores", "\n", ")", "# scores of hypothesis ending with eos (finished sentences)", "\n", "\n", "if", "self", ".", "should_set_src_lengths", ":", "\n", "                ", "self", ".", "search", ".", "set_src_lengths", "(", "src_lengths", ")", "\n", "\n", "", "if", "self", ".", "no_repeat_ngram_size", ">", "0", ":", "\n", "                ", "lprobs", "=", "self", ".", "_no_repeat_ngram", "(", "tokens", ",", "lprobs", ",", "bsz", ",", "beam_size", ",", "step", ")", "\n", "\n", "# Shape: (batch, cand_size)", "\n", "", "cand_scores", ",", "cand_indices", ",", "cand_beams", "=", "self", ".", "search", ".", "step", "(", "\n", "step", ",", "\n", "lprobs", ".", "view", "(", "bsz", ",", "-", "1", ",", "self", ".", "vocab_size", ")", ",", "\n", "scores", ".", "view", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", "[", ":", ",", ":", ",", ":", "step", "]", ",", "\n", "tokens", "[", ":", ",", ":", "step", "+", "1", "]", ",", "\n", "original_batch_idxs", ",", "\n", ")", "\n", "\n", "# cand_bbsz_idx contains beam indices for the top candidate", "\n", "# hypotheses, with a range of values: [0, bsz*beam_size),", "\n", "# and dimensions: [bsz, cand_size]", "\n", "cand_bbsz_idx", "=", "cand_beams", ".", "add", "(", "bbsz_offsets", ")", "\n", "\n", "# finalize hypotheses that end in eos", "\n", "# Shape of eos_mask: (batch size, beam size)", "\n", "eos_mask", "=", "cand_indices", ".", "eq", "(", "self", ".", "eos", ")", "&", "cand_scores", ".", "ne", "(", "-", "math", ".", "inf", ")", "\n", "eos_mask", "[", ":", ",", ":", "beam_size", "]", "[", "cands_to_ignore", "]", "=", "torch", ".", "tensor", "(", "0", ")", ".", "to", "(", "eos_mask", ")", "\n", "\n", "# only consider eos when it's among the top beam_size indices", "\n", "# Now we know what beam item(s) to finish", "\n", "# Shape: 1d list of absolute-numbered", "\n", "eos_bbsz_idx", "=", "torch", ".", "masked_select", "(", "\n", "cand_bbsz_idx", "[", ":", ",", ":", "beam_size", "]", ",", "mask", "=", "eos_mask", "[", ":", ",", ":", "beam_size", "]", "\n", ")", "\n", "\n", "finalized_sents", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "if", "eos_bbsz_idx", ".", "numel", "(", ")", ">", "0", ":", "\n", "                ", "eos_scores", "=", "torch", ".", "masked_select", "(", "\n", "cand_scores", "[", ":", ",", ":", "beam_size", "]", ",", "mask", "=", "eos_mask", "[", ":", ",", ":", "beam_size", "]", "\n", ")", "\n", "\n", "finalized_sents", "=", "self", ".", "finalize_hypos", "(", "\n", "step", ",", "\n", "eos_bbsz_idx", ",", "\n", "eos_scores", ",", "\n", "tokens", ",", "\n", "scores", ",", "\n", "finalized", ",", "\n", "finished", ",", "\n", "beam_size", ",", "\n", "attn", ",", "\n", "src_lengths", ",", "\n", "max_len", ",", "\n", ")", "\n", "num_remaining_sent", "-=", "len", "(", "finalized_sents", ")", "\n", "\n", "", "assert", "num_remaining_sent", ">=", "0", "\n", "if", "num_remaining_sent", "==", "0", ":", "\n", "                ", "break", "\n", "", "if", "self", ".", "search", ".", "stop_on_max_len", "and", "step", ">=", "max_len", ":", "\n", "                ", "break", "\n", "", "assert", "step", "<", "max_len", "\n", "\n", "# Remove finalized sentences (ones for which {beam_size}", "\n", "# finished hypotheses have been generated) from the batch.", "\n", "if", "len", "(", "finalized_sents", ")", ">", "0", ":", "\n", "                ", "new_bsz", "=", "bsz", "-", "len", "(", "finalized_sents", ")", "\n", "\n", "# construct batch_idxs which holds indices of batches to keep for the next pass", "\n", "batch_mask", "=", "torch", ".", "ones", "(", "\n", "bsz", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "cand_indices", ".", "device", "\n", ")", "\n", "batch_mask", "[", "finalized_sents", "]", "=", "False", "\n", "# TODO replace `nonzero(as_tuple=False)` after TorchScript supports it", "\n", "batch_idxs", "=", "torch", ".", "arange", "(", "\n", "bsz", ",", "device", "=", "cand_indices", ".", "device", "\n", ")", ".", "masked_select", "(", "batch_mask", ")", "\n", "\n", "# Choose the subset of the hypothesized constraints that will continue", "\n", "self", ".", "search", ".", "prune_sentences", "(", "batch_idxs", ")", "\n", "\n", "eos_mask", "=", "eos_mask", "[", "batch_idxs", "]", "\n", "cand_beams", "=", "cand_beams", "[", "batch_idxs", "]", "\n", "bbsz_offsets", ".", "resize_", "(", "new_bsz", ",", "1", ")", "\n", "cand_bbsz_idx", "=", "cand_beams", ".", "add", "(", "bbsz_offsets", ")", "\n", "cand_scores", "=", "cand_scores", "[", "batch_idxs", "]", "\n", "cand_indices", "=", "cand_indices", "[", "batch_idxs", "]", "\n", "\n", "if", "prefix_tokens", "is", "not", "None", ":", "\n", "                    ", "prefix_tokens", "=", "prefix_tokens", "[", "batch_idxs", "]", "\n", "", "src_lengths", "=", "src_lengths", "[", "batch_idxs", "]", "\n", "cands_to_ignore", "=", "cands_to_ignore", "[", "batch_idxs", "]", "\n", "\n", "scores", "=", "scores", ".", "view", "(", "bsz", ",", "-", "1", ")", "[", "batch_idxs", "]", ".", "view", "(", "new_bsz", "*", "beam_size", ",", "-", "1", ")", "\n", "tokens", "=", "tokens", ".", "view", "(", "bsz", ",", "-", "1", ")", "[", "batch_idxs", "]", ".", "view", "(", "new_bsz", "*", "beam_size", ",", "-", "1", ")", "\n", "if", "attn", "is", "not", "None", ":", "\n", "                    ", "attn", "=", "attn", ".", "view", "(", "bsz", ",", "-", "1", ")", "[", "batch_idxs", "]", ".", "view", "(", "\n", "new_bsz", "*", "beam_size", ",", "attn", ".", "size", "(", "1", ")", ",", "-", "1", "\n", ")", "\n", "", "bsz", "=", "new_bsz", "\n", "", "else", ":", "\n", "                ", "batch_idxs", "=", "None", "\n", "\n", "# Set active_mask so that values > cand_size indicate eos hypos", "\n", "# and values < cand_size indicate candidate active hypos.", "\n", "# After, the min values per row are the top candidate active hypos", "\n", "\n", "# Rewrite the operator since the element wise or is not supported in torchscript.", "\n", "\n", "", "eos_mask", "[", ":", ",", ":", "beam_size", "]", "=", "~", "(", "(", "~", "cands_to_ignore", ")", "&", "(", "~", "eos_mask", "[", ":", ",", ":", "beam_size", "]", ")", ")", "\n", "active_mask", "=", "torch", ".", "add", "(", "\n", "eos_mask", ".", "type_as", "(", "cand_offsets", ")", "*", "cand_size", ",", "\n", "cand_offsets", "[", ":", "eos_mask", ".", "size", "(", "1", ")", "]", ",", "\n", ")", "\n", "\n", "# get the top beam_size active hypotheses, which are just", "\n", "# the hypos with the smallest values in active_mask.", "\n", "# {active_hypos} indicates which {beam_size} hypotheses", "\n", "# from the list of {2 * beam_size} candidates were", "\n", "# selected. Shapes: (batch size, beam size)", "\n", "new_cands_to_ignore", ",", "active_hypos", "=", "torch", ".", "topk", "(", "\n", "active_mask", ",", "k", "=", "beam_size", ",", "dim", "=", "1", ",", "largest", "=", "False", "\n", ")", "\n", "\n", "# update cands_to_ignore to ignore any finalized hypos.", "\n", "cands_to_ignore", "=", "new_cands_to_ignore", ".", "ge", "(", "cand_size", ")", "[", ":", ",", ":", "beam_size", "]", "\n", "# Make sure there is at least one active item for each sentence in the batch.", "\n", "assert", "(", "~", "cands_to_ignore", ")", ".", "any", "(", "dim", "=", "1", ")", ".", "all", "(", ")", "\n", "\n", "# update cands_to_ignore to ignore any finalized hypos", "\n", "\n", "# {active_bbsz_idx} denotes which beam number is continued for each new hypothesis (a beam", "\n", "# can be selected more than once).", "\n", "active_bbsz_idx", "=", "torch", ".", "gather", "(", "cand_bbsz_idx", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", ")", "\n", "active_scores", "=", "torch", ".", "gather", "(", "cand_scores", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", ")", "\n", "\n", "active_bbsz_idx", "=", "active_bbsz_idx", ".", "view", "(", "-", "1", ")", "\n", "active_scores", "=", "active_scores", ".", "view", "(", "-", "1", ")", "\n", "\n", "# copy tokens and scores for active hypotheses", "\n", "\n", "# Set the tokens for each beam (can select the same row more than once)", "\n", "tokens", "[", ":", ",", ":", "step", "+", "1", "]", "=", "torch", ".", "index_select", "(", "\n", "tokens", "[", ":", ",", ":", "step", "+", "1", "]", ",", "dim", "=", "0", ",", "index", "=", "active_bbsz_idx", "\n", ")", "\n", "# Select the next token for each of them", "\n", "tokens", ".", "view", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", "[", ":", ",", ":", ",", "step", "+", "1", "]", "=", "torch", ".", "gather", "(", "\n", "cand_indices", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", "\n", ")", "\n", "if", "step", ">", "0", ":", "\n", "                ", "scores", "[", ":", ",", ":", "step", "]", "=", "torch", ".", "index_select", "(", "\n", "scores", "[", ":", ",", ":", "step", "]", ",", "dim", "=", "0", ",", "index", "=", "active_bbsz_idx", "\n", ")", "\n", "", "scores", ".", "view", "(", "bsz", ",", "beam_size", ",", "-", "1", ")", "[", ":", ",", ":", ",", "step", "]", "=", "torch", ".", "gather", "(", "\n", "cand_scores", ",", "dim", "=", "1", ",", "index", "=", "active_hypos", "\n", ")", "\n", "\n", "# Update constraints based on which candidates were selected for the next beam", "\n", "self", ".", "search", ".", "update_constraints", "(", "active_hypos", ")", "\n", "\n", "# copy attention for active hypotheses", "\n", "if", "attn", "is", "not", "None", ":", "\n", "                ", "attn", "[", ":", ",", ":", ",", ":", "step", "+", "2", "]", "=", "torch", ".", "index_select", "(", "\n", "attn", "[", ":", ",", ":", ",", ":", "step", "+", "2", "]", ",", "dim", "=", "0", ",", "index", "=", "active_bbsz_idx", "\n", ")", "\n", "\n", "# reorder incremental state in decoder", "\n", "", "reorder_state", "=", "active_bbsz_idx", "\n", "\n", "# sort by score descending", "\n", "", "for", "sent", "in", "range", "(", "len", "(", "finalized", ")", ")", ":", "\n", "            ", "scores", "=", "torch", ".", "tensor", "(", "\n", "[", "float", "(", "elem", "[", "\"score\"", "]", ".", "item", "(", ")", ")", "for", "elem", "in", "finalized", "[", "sent", "]", "]", "\n", ")", "\n", "_", ",", "sorted_scores_indices", "=", "torch", ".", "sort", "(", "scores", ",", "descending", "=", "True", ")", "\n", "finalized", "[", "sent", "]", "=", "[", "finalized", "[", "sent", "]", "[", "ssi", "]", "for", "ssi", "in", "sorted_scores_indices", "]", "\n", "finalized", "[", "sent", "]", "=", "torch", ".", "jit", ".", "annotate", "(", "\n", "List", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", ",", "finalized", "[", "sent", "]", "\n", ")", "\n", "", "return", "finalized", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator._prefix_tokens": [[544, 572], ["prefix_tokens[].unsqueeze().repeat().view", "sequence_generator.SequenceGenerator.gather", "prefix_tokens[].unsqueeze().repeat().view.ne", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "lprobs[].scatter", "prefix_tokens[].unsqueeze().repeat().view.eq", "prefix_tokens[].unsqueeze().repeat().view.eq.any", "prefix_tokens[].unsqueeze().repeat().view.unsqueeze", "prefix_toks[].unsqueeze", "sequence_generator.SequenceGenerator.replicate_first_beam", "sequence_generator.SequenceGenerator.replicate_first_beam", "sequence_generator.SequenceGenerator.replicate_first_beam", "prefix_tokens[].unsqueeze().repeat", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "tokens[].view", "prefix_tokens[].unsqueeze().repeat().view.eq.view", "sequence_generator.SequenceGenerator.size", "prefix_tokens[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.replicate_first_beam", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.replicate_first_beam", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.replicate_first_beam", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "_prefix_tokens", "(", "\n", "self", ",", "step", ":", "int", ",", "lprobs", ",", "scores", ",", "tokens", ",", "prefix_tokens", ",", "beam_size", ":", "int", "\n", ")", ":", "\n", "        ", "\"\"\"Handle prefix tokens\"\"\"", "\n", "prefix_toks", "=", "prefix_tokens", "[", ":", ",", "step", "]", ".", "unsqueeze", "(", "-", "1", ")", ".", "repeat", "(", "1", ",", "beam_size", ")", ".", "view", "(", "-", "1", ")", "\n", "prefix_lprobs", "=", "lprobs", ".", "gather", "(", "-", "1", ",", "prefix_toks", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "prefix_mask", "=", "prefix_toks", ".", "ne", "(", "self", ".", "pad", ")", "\n", "lprobs", "[", "prefix_mask", "]", "=", "torch", ".", "tensor", "(", "-", "math", ".", "inf", ")", ".", "to", "(", "lprobs", ")", "\n", "lprobs", "[", "prefix_mask", "]", "=", "lprobs", "[", "prefix_mask", "]", ".", "scatter", "(", "\n", "-", "1", ",", "prefix_toks", "[", "prefix_mask", "]", ".", "unsqueeze", "(", "-", "1", ")", ",", "prefix_lprobs", "[", "prefix_mask", "]", "\n", ")", "\n", "# if prefix includes eos, then we should make sure tokens and", "\n", "# scores are the same across all beams", "\n", "eos_mask", "=", "prefix_toks", ".", "eq", "(", "self", ".", "eos", ")", "\n", "if", "eos_mask", ".", "any", "(", ")", ":", "\n", "# validate that the first beam matches the prefix", "\n", "            ", "first_beam", "=", "tokens", "[", "eos_mask", "]", ".", "view", "(", "-", "1", ",", "beam_size", ",", "tokens", ".", "size", "(", "-", "1", ")", ")", "[", "\n", ":", ",", "0", ",", "1", ":", "step", "+", "1", "\n", "]", "\n", "eos_mask_batch_dim", "=", "eos_mask", ".", "view", "(", "-", "1", ",", "beam_size", ")", "[", ":", ",", "0", "]", "\n", "target_prefix", "=", "prefix_tokens", "[", "eos_mask_batch_dim", "]", "[", ":", ",", ":", "step", "]", "\n", "assert", "(", "first_beam", "==", "target_prefix", ")", ".", "all", "(", ")", "\n", "\n", "# copy tokens, scores and lprobs from the first beam to all beams", "\n", "tokens", "=", "self", ".", "replicate_first_beam", "(", "tokens", ",", "eos_mask_batch_dim", ",", "beam_size", ")", "\n", "scores", "=", "self", ".", "replicate_first_beam", "(", "scores", ",", "eos_mask_batch_dim", ",", "beam_size", ")", "\n", "lprobs", "=", "self", ".", "replicate_first_beam", "(", "lprobs", ",", "eos_mask_batch_dim", ",", "beam_size", ")", "\n", "", "return", "lprobs", ",", "tokens", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.replicate_first_beam": [[573, 577], ["tensor.view.view.view", "tensor.view.view.view", "tensor.view.view.size", "tensor.view.view.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "replicate_first_beam", "(", "self", ",", "tensor", ",", "mask", ",", "beam_size", ":", "int", ")", ":", "\n", "        ", "tensor", "=", "tensor", ".", "view", "(", "-", "1", ",", "beam_size", ",", "tensor", ".", "size", "(", "-", "1", ")", ")", "\n", "tensor", "[", "mask", "]", "=", "tensor", "[", "mask", "]", "[", ":", ",", ":", "1", ",", ":", "]", "\n", "return", "tensor", ".", "view", "(", "-", "1", ",", "tensor", ".", "size", "(", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.finalize_hypos": [[578, 695], ["range", "sents_seen.keys", "bbsz_idx.numel", "eos_scores.numel", "tokens.index_select", "scores.index_select", "int", "int", "attn.index_select", "cum_unfin.append", "bbsz_idx.size", "str", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "len", "finalized[].append", "float", "float", "sequence_generator.SequenceGenerator.is_finished", "newly_finished.append", "str", "unfin_idx.item", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "len", "sent.item", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "seen.split", "seen.split"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.is_finished", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "def", "finalize_hypos", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "bbsz_idx", ",", "\n", "eos_scores", ",", "\n", "tokens", ",", "\n", "scores", ",", "\n", "finalized", ":", "List", "[", "List", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", "]", ",", "\n", "finished", ":", "List", "[", "bool", "]", ",", "\n", "beam_size", ":", "int", ",", "\n", "attn", ":", "Optional", "[", "Tensor", "]", ",", "\n", "src_lengths", ",", "\n", "max_len", ":", "int", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Finalize hypothesis, store finalized information in `finalized`, and change `finished` accordingly.\n        A sentence is finalized when {beam_size} finished items have been collected for it.\n\n        Returns number of sentences (not beam items) being finalized.\n        These will be removed from the batch and not processed further.\n        Args:\n            bbsz_idx (Tensor):\n        \"\"\"", "\n", "assert", "bbsz_idx", ".", "numel", "(", ")", "==", "eos_scores", ".", "numel", "(", ")", "\n", "\n", "# clone relevant token and attention tensors.", "\n", "# tokens is (batch * beam, max_len). So the index_select", "\n", "# gets the newly EOS rows, then selects cols 1..{step + 2}", "\n", "tokens_clone", "=", "tokens", ".", "index_select", "(", "0", ",", "bbsz_idx", ")", "[", "\n", ":", ",", "1", ":", "step", "+", "2", "\n", "]", "# skip the first index, which is EOS", "\n", "\n", "tokens_clone", "[", ":", ",", "step", "]", "=", "self", ".", "eos", "\n", "attn_clone", "=", "(", "\n", "attn", ".", "index_select", "(", "0", ",", "bbsz_idx", ")", "[", ":", ",", ":", ",", "1", ":", "step", "+", "2", "]", "\n", "if", "attn", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "\n", "# compute scores per token position", "\n", "pos_scores", "=", "scores", ".", "index_select", "(", "0", ",", "bbsz_idx", ")", "[", ":", ",", ":", "step", "+", "1", "]", "\n", "pos_scores", "[", ":", ",", "step", "]", "=", "eos_scores", "\n", "# convert from cumulative to per-position scores", "\n", "pos_scores", "[", ":", ",", "1", ":", "]", "=", "pos_scores", "[", ":", ",", "1", ":", "]", "-", "pos_scores", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "# normalize sentence-level scores", "\n", "if", "self", ".", "normalize_scores", ":", "\n", "            ", "eos_scores", "/=", "(", "step", "+", "1", ")", "**", "self", ".", "len_penalty", "\n", "\n", "# cum_unfin records which sentences in the batch are finished.", "\n", "# It helps match indexing between (a) the original sentences", "\n", "# in the batch and (b) the current, possibly-reduced set of", "\n", "# sentences.", "\n", "", "cum_unfin", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "prev", "=", "0", "\n", "for", "f", "in", "finished", ":", "\n", "            ", "if", "f", ":", "\n", "                ", "prev", "+=", "1", "\n", "", "else", ":", "\n", "                ", "cum_unfin", ".", "append", "(", "prev", ")", "\n", "\n", "# The keys here are of the form \"{sent}_{unfin_idx}\", where", "\n", "# \"unfin_idx\" is the index in the current (possibly reduced)", "\n", "# list of sentences, and \"sent\" is the index in the original,", "\n", "# unreduced batch", "\n", "# set() is not supported in script export", "\n", "", "", "sents_seen", ":", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "=", "{", "}", "\n", "\n", "# For every finished beam item", "\n", "for", "i", "in", "range", "(", "bbsz_idx", ".", "size", "(", ")", "[", "0", "]", ")", ":", "\n", "            ", "idx", "=", "bbsz_idx", "[", "i", "]", "\n", "score", "=", "eos_scores", "[", "i", "]", "\n", "# sentence index in the current (possibly reduced) batch", "\n", "unfin_idx", "=", "idx", "//", "beam_size", "\n", "# sentence index in the original (unreduced) batch", "\n", "sent", "=", "unfin_idx", "+", "cum_unfin", "[", "unfin_idx", "]", "\n", "# Cannot create dict for key type '(int, int)' in torchscript.", "\n", "# The workaround is to cast int to string", "\n", "seen", "=", "str", "(", "sent", ".", "item", "(", ")", ")", "+", "\"_\"", "+", "str", "(", "unfin_idx", ".", "item", "(", ")", ")", "\n", "if", "seen", "not", "in", "sents_seen", ":", "\n", "                ", "sents_seen", "[", "seen", "]", "=", "None", "\n", "\n", "", "if", "self", ".", "match_source_len", "and", "step", ">", "src_lengths", "[", "unfin_idx", "]", ":", "\n", "                ", "score", "=", "torch", ".", "tensor", "(", "-", "math", ".", "inf", ")", ".", "to", "(", "score", ")", "\n", "\n", "# An input sentence (among those in a batch) is finished when", "\n", "# beam_size hypotheses have been collected for it", "\n", "", "if", "len", "(", "finalized", "[", "sent", "]", ")", "<", "beam_size", ":", "\n", "                ", "if", "attn_clone", "is", "not", "None", ":", "\n", "# remove padding tokens from attn scores", "\n", "                    ", "hypo_attn", "=", "attn_clone", "[", "i", "]", "\n", "", "else", ":", "\n", "                    ", "hypo_attn", "=", "torch", ".", "empty", "(", "0", ")", "\n", "\n", "", "finalized", "[", "sent", "]", ".", "append", "(", "\n", "{", "\n", "\"tokens\"", ":", "tokens_clone", "[", "i", "]", ",", "\n", "\"score\"", ":", "score", ",", "\n", "\"attention\"", ":", "hypo_attn", ",", "# src_len x tgt_len", "\n", "\"alignment\"", ":", "torch", ".", "empty", "(", "0", ")", ",", "\n", "\"positional_scores\"", ":", "pos_scores", "[", "i", "]", ",", "\n", "}", "\n", ")", "\n", "\n", "", "", "newly_finished", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "\n", "for", "seen", "in", "sents_seen", ".", "keys", "(", ")", ":", "\n", "# check termination conditions for this sentence", "\n", "            ", "sent", ":", "int", "=", "int", "(", "float", "(", "seen", ".", "split", "(", "\"_\"", ")", "[", "0", "]", ")", ")", "\n", "unfin_idx", ":", "int", "=", "int", "(", "float", "(", "seen", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ")", ")", "\n", "\n", "if", "not", "finished", "[", "sent", "]", "and", "self", ".", "is_finished", "(", "\n", "step", ",", "unfin_idx", ",", "max_len", ",", "len", "(", "finalized", "[", "sent", "]", ")", ",", "beam_size", "\n", ")", ":", "\n", "                ", "finished", "[", "sent", "]", "=", "True", "\n", "newly_finished", ".", "append", "(", "unfin_idx", ")", "\n", "\n", "", "", "return", "newly_finished", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.is_finished": [[696, 713], ["None"], "methods", ["None"], ["", "def", "is_finished", "(", "\n", "self", ",", "\n", "step", ":", "int", ",", "\n", "unfin_idx", ":", "int", ",", "\n", "max_len", ":", "int", ",", "\n", "finalized_sent_len", ":", "int", ",", "\n", "beam_size", ":", "int", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Check whether decoding for a sentence is finished, which\n        occurs when the list of finalized sentences has reached the\n        beam size, or when we reach the maximum length.\n        \"\"\"", "\n", "assert", "finalized_sent_len", "<=", "beam_size", "\n", "if", "finalized_sent_len", "==", "beam_size", "or", "step", "==", "max_len", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.calculate_banned_tokens": [[714, 728], ["tokens[].tolist", "gen_ngrams[].get", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "str"], "methods", ["None"], ["", "def", "calculate_banned_tokens", "(", "\n", "self", ",", "\n", "tokens", ",", "\n", "step", ":", "int", ",", "\n", "gen_ngrams", ":", "List", "[", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "]", ",", "\n", "no_repeat_ngram_size", ":", "int", ",", "\n", "bbsz_idx", ":", "int", ",", "\n", ")", ":", "\n", "        ", "tokens_list", ":", "List", "[", "int", "]", "=", "tokens", "[", "\n", "bbsz_idx", ",", "step", "+", "2", "-", "no_repeat_ngram_size", ":", "step", "+", "1", "\n", "]", ".", "tolist", "(", ")", "\n", "# before decoding the next token, prevent decoding of ngrams that have already appeared", "\n", "ngram_index", "=", "\",\"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "tokens_list", "]", ")", "\n", "return", "gen_ngrams", "[", "bbsz_idx", "]", ".", "get", "(", "ngram_index", ",", "torch", ".", "jit", ".", "annotate", "(", "List", "[", "int", "]", ",", "[", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.transpose_list": [[729, 734], ["min", "len", "range"], "methods", ["None"], ["", "def", "transpose_list", "(", "self", ",", "l", ":", "List", "[", "List", "[", "int", "]", "]", ")", ":", "\n", "# GeneratorExp aren't supported in TS so ignoring the lint", "\n", "        ", "min_len", "=", "min", "(", "[", "len", "(", "x", ")", "for", "x", "in", "l", "]", ")", "# noqa", "\n", "l2", "=", "[", "[", "row", "[", "i", "]", "for", "row", "in", "l", "]", "for", "i", "in", "range", "(", "min_len", ")", "]", "\n", "return", "l2", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator._no_repeat_ngram": [[735, 769], ["tokens.cpu", "range", "range", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "cpu_tokens[].tolist", "sequence_generator.SequenceGenerator.transpose_list", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "range", "sequence_generator.SequenceGenerator.calculate_banned_tokens", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "gen_ngrams[].get", "range", "range", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "range", "str", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.transpose_list", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.calculate_banned_tokens"], ["", "def", "_no_repeat_ngram", "(", "self", ",", "tokens", ",", "lprobs", ",", "bsz", ":", "int", ",", "beam_size", ":", "int", ",", "step", ":", "int", ")", ":", "\n", "# for each beam and batch sentence, generate a list of previous ngrams", "\n", "        ", "gen_ngrams", ":", "List", "[", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "]", "=", "[", "\n", "torch", ".", "jit", ".", "annotate", "(", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ",", "{", "}", ")", "\n", "for", "bbsz_idx", "in", "range", "(", "bsz", "*", "beam_size", ")", "\n", "]", "\n", "cpu_tokens", "=", "tokens", ".", "cpu", "(", ")", "\n", "for", "bbsz_idx", "in", "range", "(", "bsz", "*", "beam_size", ")", ":", "\n", "            ", "gen_tokens", ":", "List", "[", "int", "]", "=", "cpu_tokens", "[", "bbsz_idx", "]", ".", "tolist", "(", ")", "\n", "for", "ngram", "in", "self", ".", "transpose_list", "(", "\n", "[", "gen_tokens", "[", "i", ":", "]", "for", "i", "in", "range", "(", "self", ".", "no_repeat_ngram_size", ")", "]", "\n", ")", ":", "\n", "                ", "key", "=", "\",\"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "ngram", "[", ":", "-", "1", "]", "]", ")", "\n", "gen_ngrams", "[", "bbsz_idx", "]", "[", "key", "]", "=", "gen_ngrams", "[", "bbsz_idx", "]", ".", "get", "(", "\n", "key", ",", "torch", ".", "jit", ".", "annotate", "(", "List", "[", "int", "]", ",", "[", "]", ")", "\n", ")", "+", "[", "ngram", "[", "-", "1", "]", "]", "\n", "\n", "", "", "if", "step", "+", "2", "-", "self", ".", "no_repeat_ngram_size", ">=", "0", ":", "\n", "# no banned tokens if we haven't generated no_repeat_ngram_size tokens yet", "\n", "            ", "banned_tokens", "=", "[", "\n", "self", ".", "calculate_banned_tokens", "(", "\n", "tokens", ",", "step", ",", "gen_ngrams", ",", "self", ".", "no_repeat_ngram_size", ",", "bbsz_idx", "\n", ")", "\n", "for", "bbsz_idx", "in", "range", "(", "bsz", "*", "beam_size", ")", "\n", "]", "\n", "", "else", ":", "\n", "            ", "banned_tokens", "=", "[", "\n", "torch", ".", "jit", ".", "annotate", "(", "List", "[", "int", "]", ",", "[", "]", ")", "for", "bbsz_idx", "in", "range", "(", "bsz", "*", "beam_size", ")", "\n", "]", "\n", "", "for", "bbsz_idx", "in", "range", "(", "bsz", "*", "beam_size", ")", ":", "\n", "            ", "lprobs", "[", "bbsz_idx", "]", "[", "\n", "torch", ".", "tensor", "(", "banned_tokens", "[", "bbsz_idx", "]", ")", ".", "long", "(", ")", "\n", "]", "=", "torch", ".", "tensor", "(", "-", "math", ".", "inf", ")", ".", "to", "(", "lprobs", ")", "\n", "", "return", "lprobs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.EnsembleModel.__init__": [[774, 787], ["torch.Module.__init__", "len", "torch.ModuleList", "torch.ModuleList", "all", "hasattr", "isinstance"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "models", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "models_size", "=", "len", "(", "models", ")", "\n", "# method '__len__' is not supported in ModuleList for torch script", "\n", "self", ".", "single_model", "=", "models", "[", "0", "]", "\n", "self", ".", "models", "=", "nn", ".", "ModuleList", "(", "models", ")", "\n", "\n", "self", ".", "has_incremental", ":", "bool", "=", "False", "\n", "if", "all", "(", "\n", "hasattr", "(", "m", ",", "\"decoder\"", ")", "and", "isinstance", "(", "m", ".", "decoder", ",", "FairseqIncrementalDecoder", ")", "\n", "for", "m", "in", "models", "\n", ")", ":", "\n", "            ", "self", ".", "has_incremental", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.EnsembleModel.forward": [[788, 790], ["None"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.EnsembleModel.has_encoder": [[791, 793], ["hasattr"], "methods", ["None"], ["", "def", "has_encoder", "(", "self", ")", ":", "\n", "        ", "return", "hasattr", "(", "self", ".", "single_model", ",", "\"encoder\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.EnsembleModel.has_incremental_states": [[794, 796], ["None"], "methods", ["None"], ["", "def", "has_incremental_states", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "has_incremental", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.EnsembleModel.max_decoder_positions": [[797, 799], ["min", "m.max_decoder_positions"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.max_decoder_positions"], ["", "def", "max_decoder_positions", "(", "self", ")", ":", "\n", "        ", "return", "min", "(", "[", "m", ".", "max_decoder_positions", "(", ")", "for", "m", "in", "self", ".", "models", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.EnsembleModel.forward_encoder": [[800, 805], ["sequence_generator.EnsembleModel.has_encoder", "model.encoder.forward_torchscript"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.BasicEnsembleModel.has_encoder", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_encoder.FairseqEncoder.forward_torchscript"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "forward_encoder", "(", "self", ",", "net_input", ":", "Dict", "[", "str", ",", "Tensor", "]", ")", ":", "\n", "        ", "if", "not", "self", ".", "has_encoder", "(", ")", ":", "\n", "            ", "return", "None", "\n", "", "return", "[", "model", ".", "encoder", ".", "forward_torchscript", "(", "net_input", ")", "for", "model", "in", "self", ".", "models", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.EnsembleModel.forward_decoder": [[806, 870], ["enumerate", "sequence_generator.EnsembleModel.has_encoder", "sequence_generator.EnsembleModel.has_incremental_states", "len", "model.get_normalized_probs", "log_probs.append", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "math.log", "avg_attn.div_", "model.decoder.forward", "model.decoder.forward", "isinstance", "[].div_", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "isinstance", "avg_attn.add_"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.BasicEnsembleModel.has_encoder", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.EnsembleModel.has_incremental_states", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.get_normalized_probs", "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.forward", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.forward"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "forward_decoder", "(", "\n", "self", ",", "\n", "tokens", ",", "\n", "encoder_outs", ":", "List", "[", "EncoderOut", "]", ",", "\n", "incremental_states", ":", "List", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "temperature", ":", "float", "=", "1.0", ",", "\n", ")", ":", "\n", "        ", "log_probs", "=", "[", "]", "\n", "avg_attn", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "encoder_out", ":", "Optional", "[", "EncoderOut", "]", "=", "None", "\n", "for", "i", ",", "model", "in", "enumerate", "(", "self", ".", "models", ")", ":", "\n", "            ", "if", "self", ".", "has_encoder", "(", ")", ":", "\n", "                ", "encoder_out", "=", "encoder_outs", "[", "i", "]", "\n", "# decode each model", "\n", "", "if", "self", ".", "has_incremental_states", "(", ")", ":", "\n", "                ", "decoder_out", "=", "model", ".", "decoder", ".", "forward", "(", "\n", "tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", "incremental_state", "=", "incremental_states", "[", "i", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "decoder_out", "=", "model", ".", "decoder", ".", "forward", "(", "tokens", ",", "encoder_out", "=", "encoder_out", ")", "\n", "\n", "", "attn", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "decoder_len", "=", "len", "(", "decoder_out", ")", "\n", "if", "decoder_len", ">", "1", "and", "decoder_out", "[", "1", "]", "is", "not", "None", ":", "\n", "                ", "if", "isinstance", "(", "decoder_out", "[", "1", "]", ",", "Tensor", ")", ":", "\n", "                    ", "attn", "=", "decoder_out", "[", "1", "]", "\n", "", "else", ":", "\n", "                    ", "attn_holder", "=", "decoder_out", "[", "1", "]", "[", "\"attn\"", "]", "\n", "if", "isinstance", "(", "attn_holder", ",", "Tensor", ")", ":", "\n", "                        ", "attn", "=", "attn_holder", "\n", "", "elif", "attn_holder", "is", "not", "None", ":", "\n", "                        ", "attn", "=", "attn_holder", "[", "0", "]", "\n", "", "", "if", "attn", "is", "not", "None", ":", "\n", "                    ", "attn", "=", "attn", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "\n", "", "", "decoder_out_tuple", "=", "(", "\n", "decoder_out", "[", "0", "]", "[", ":", ",", "-", "1", ":", ",", ":", "]", ".", "div_", "(", "temperature", ")", ",", "\n", "None", "if", "decoder_len", "<=", "1", "else", "decoder_out", "[", "1", "]", ",", "\n", ")", "\n", "\n", "probs", "=", "model", ".", "get_normalized_probs", "(", "\n", "decoder_out_tuple", ",", "log_probs", "=", "True", ",", "sample", "=", "None", "\n", ")", "\n", "probs", "=", "probs", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "if", "self", ".", "models_size", "==", "1", ":", "\n", "                ", "return", "probs", ",", "attn", "\n", "\n", "", "log_probs", ".", "append", "(", "probs", ")", "\n", "if", "attn", "is", "not", "None", ":", "\n", "                ", "if", "avg_attn", "is", "None", ":", "\n", "                    ", "avg_attn", "=", "attn", "\n", "", "else", ":", "\n", "                    ", "avg_attn", ".", "add_", "(", "attn", ")", "\n", "\n", "", "", "", "avg_probs", "=", "torch", ".", "logsumexp", "(", "torch", ".", "stack", "(", "log_probs", ",", "dim", "=", "0", ")", ",", "dim", "=", "0", ")", "-", "math", ".", "log", "(", "\n", "self", ".", "models_size", "\n", ")", "\n", "\n", "if", "avg_attn", "is", "not", "None", ":", "\n", "            ", "avg_attn", ".", "div_", "(", "self", ".", "models_size", ")", "\n", "", "return", "avg_probs", ",", "avg_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.EnsembleModel.reorder_encoder_out": [[871, 892], ["enumerate", "sequence_generator.EnsembleModel.has_encoder", "new_outs.append", "model.encoder.reorder_encoder_out"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.BasicEnsembleModel.has_encoder", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerEncoder.reorder_encoder_out"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "reorder_encoder_out", "(", "self", ",", "encoder_outs", ":", "Optional", "[", "List", "[", "EncoderOut", "]", "]", ",", "new_order", ")", ":", "\n", "        ", "\"\"\"\n        Reorder encoder output according to *new_order*.\n\n        Args:\n            encoder_out: output from the ``forward()`` method\n            new_order (LongTensor): desired order\n\n        Returns:\n            *encoder_out* rearranged according to *new_order*\n        \"\"\"", "\n", "new_outs", ":", "List", "[", "EncoderOut", "]", "=", "[", "]", "\n", "if", "not", "self", ".", "has_encoder", "(", ")", ":", "\n", "            ", "return", "new_outs", "\n", "", "for", "i", ",", "model", "in", "enumerate", "(", "self", ".", "models", ")", ":", "\n", "            ", "assert", "encoder_outs", "is", "not", "None", "\n", "new_outs", ".", "append", "(", "\n", "model", ".", "encoder", ".", "reorder_encoder_out", "(", "encoder_outs", "[", "i", "]", ",", "new_order", ")", "\n", ")", "\n", "", "return", "new_outs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.EnsembleModel.reorder_incremental_state": [[893, 904], ["enumerate", "sequence_generator.EnsembleModel.has_incremental_states", "model.decoder.reorder_incremental_state_scripting"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.EnsembleModel.has_incremental_states", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.reorder_incremental_state_scripting"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "reorder_incremental_state", "(", "\n", "self", ",", "\n", "incremental_states", ":", "List", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "new_order", ",", "\n", ")", ":", "\n", "        ", "if", "not", "self", ".", "has_incremental_states", "(", ")", ":", "\n", "            ", "return", "\n", "", "for", "i", ",", "model", "in", "enumerate", "(", "self", ".", "models", ")", ":", "\n", "            ", "model", ".", "decoder", ".", "reorder_incremental_state_scripting", "(", "\n", "incremental_states", "[", "i", "]", ",", "new_order", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGeneratorWithAlignment.__init__": [[908, 921], ["sequence_generator.SequenceGenerator.__init__", "sequence_generator.EnsembleModelWithAlignment"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "models", ",", "tgt_dict", ",", "left_pad_target", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Generates translations of a given source sentence.\n\n        Produces alignments following \"Jointly Learning to Align and\n        Translate with Transformer Models\" (Garg et al., EMNLP 2019).\n\n        Args:\n            left_pad_target (bool, optional): Whether or not the\n                hypothesis should be left padded or not when they are\n                teacher forced for generating alignments.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "EnsembleModelWithAlignment", "(", "models", ")", ",", "tgt_dict", ",", "**", "kwargs", ")", "\n", "self", ".", "left_pad_target", "=", "left_pad_target", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGeneratorWithAlignment.generate": [[922, 955], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sequence_generator.SequenceGenerator._generate", "sequence_generator.SequenceGeneratorWithAlignment._prepare_batch_for_alignment", "any", "range", "sequence_generator.SequenceGeneratorWithAlignment.model.forward_align", "src_tokens.to.to.to", "tgt_tokens.to.to.to", "fairseq.utils.extract_hard_alignment", "getattr", "[].transpose", "i.to", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator._generate", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGeneratorWithAlignment._prepare_batch_for_alignment", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.EnsembleModelWithAlignment.forward_align", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.extract_hard_alignment"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate", "(", "self", ",", "models", ",", "sample", ",", "**", "kwargs", ")", ":", "\n", "        ", "finalized", "=", "super", "(", ")", ".", "_generate", "(", "sample", ",", "**", "kwargs", ")", "\n", "\n", "src_tokens", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "\n", "bsz", "=", "src_tokens", ".", "shape", "[", "0", "]", "\n", "beam_size", "=", "self", ".", "beam_size", "\n", "(", "\n", "src_tokens", ",", "\n", "src_lengths", ",", "\n", "prev_output_tokens", ",", "\n", "tgt_tokens", ",", "\n", ")", "=", "self", ".", "_prepare_batch_for_alignment", "(", "sample", ",", "finalized", ")", "\n", "if", "any", "(", "getattr", "(", "m", ",", "\"full_context_alignment\"", ",", "False", ")", "for", "m", "in", "self", ".", "model", ".", "models", ")", ":", "\n", "            ", "attn", "=", "self", ".", "model", ".", "forward_align", "(", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ")", "\n", "", "else", ":", "\n", "            ", "attn", "=", "[", "\n", "finalized", "[", "i", "//", "beam_size", "]", "[", "i", "%", "beam_size", "]", "[", "\"attention\"", "]", ".", "transpose", "(", "1", ",", "0", ")", "\n", "for", "i", "in", "range", "(", "bsz", "*", "beam_size", ")", "\n", "]", "\n", "\n", "", "if", "src_tokens", ".", "device", "!=", "\"cpu\"", ":", "\n", "            ", "src_tokens", "=", "src_tokens", ".", "to", "(", "\"cpu\"", ")", "\n", "tgt_tokens", "=", "tgt_tokens", ".", "to", "(", "\"cpu\"", ")", "\n", "attn", "=", "[", "i", ".", "to", "(", "\"cpu\"", ")", "for", "i", "in", "attn", "]", "\n", "\n", "# Process the attn matrix to extract hard alignments.", "\n", "", "for", "i", "in", "range", "(", "bsz", "*", "beam_size", ")", ":", "\n", "            ", "alignment", "=", "utils", ".", "extract_hard_alignment", "(", "\n", "attn", "[", "i", "]", ",", "src_tokens", "[", "i", "]", ",", "tgt_tokens", "[", "i", "]", ",", "self", ".", "pad", ",", "self", ".", "eos", "\n", ")", "\n", "finalized", "[", "i", "//", "beam_size", "]", "[", "i", "%", "beam_size", "]", "[", "\"alignment\"", "]", "=", "alignment", "\n", "", "return", "finalized", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGeneratorWithAlignment._prepare_batch_for_alignment": [[956, 987], ["src_tokens[].expand().contiguous().view", "src_lengths[].expand().contiguous().view", "fairseq.data.data_utils.collate_tokens", "fairseq.data.data_utils.collate_tokens", "src_tokens[].expand().contiguous", "src_lengths[].expand().contiguous", "src_tokens[].expand", "src_lengths[].expand"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils.collate_tokens", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.collate_tokens"], ["", "def", "_prepare_batch_for_alignment", "(", "self", ",", "sample", ",", "hypothesis", ")", ":", "\n", "        ", "src_tokens", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "\n", "bsz", "=", "src_tokens", ".", "shape", "[", "0", "]", "\n", "src_tokens", "=", "(", "\n", "src_tokens", "[", ":", ",", "None", ",", ":", "]", "\n", ".", "expand", "(", "-", "1", ",", "self", ".", "beam_size", ",", "-", "1", ")", "\n", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "bsz", "*", "self", ".", "beam_size", ",", "-", "1", ")", "\n", ")", "\n", "src_lengths", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_lengths\"", "]", "\n", "src_lengths", "=", "(", "\n", "src_lengths", "[", ":", ",", "None", "]", "\n", ".", "expand", "(", "-", "1", ",", "self", ".", "beam_size", ")", "\n", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "bsz", "*", "self", ".", "beam_size", ")", "\n", ")", "\n", "prev_output_tokens", "=", "data_utils", ".", "collate_tokens", "(", "\n", "[", "beam", "[", "\"tokens\"", "]", "for", "example", "in", "hypothesis", "for", "beam", "in", "example", "]", ",", "\n", "self", ".", "pad", ",", "\n", "self", ".", "eos", ",", "\n", "self", ".", "left_pad_target", ",", "\n", "move_eos_to_beginning", "=", "True", ",", "\n", ")", "\n", "tgt_tokens", "=", "data_utils", ".", "collate_tokens", "(", "\n", "[", "beam", "[", "\"tokens\"", "]", "for", "example", "in", "hypothesis", "for", "beam", "in", "example", "]", ",", "\n", "self", ".", "pad", ",", "\n", "self", ".", "eos", ",", "\n", "self", ".", "left_pad_target", ",", "\n", "move_eos_to_beginning", "=", "False", ",", "\n", ")", "\n", "return", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "tgt_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.EnsembleModelWithAlignment.__init__": [[992, 994], ["sequence_generator.EnsembleModel.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "models", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "models", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.EnsembleModelWithAlignment.forward_align": [[995, 1007], ["model", "len", "avg_attn.div_", "avg_attn.add_", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model"], ["", "def", "forward_align", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ")", ":", "\n", "        ", "avg_attn", "=", "None", "\n", "for", "model", "in", "self", ".", "models", ":", "\n", "            ", "decoder_out", "=", "model", "(", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ")", "\n", "attn", "=", "decoder_out", "[", "1", "]", "[", "\"attn\"", "]", "[", "0", "]", "\n", "if", "avg_attn", "is", "None", ":", "\n", "                ", "avg_attn", "=", "attn", "\n", "", "else", ":", "\n", "                ", "avg_attn", ".", "add_", "(", "attn", ")", "\n", "", "", "if", "len", "(", "self", ".", "models", ")", ">", "1", ":", "\n", "            ", "avg_attn", ".", "div_", "(", "len", "(", "self", ".", "models", ")", ")", "\n", "", "return", "avg_attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.FileContentsAction.__init__": [[48, 52], ["argparse.Action.__init__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "nargs", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "nargs", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"nargs not allowed\"", ")", "\n", "", "super", "(", "FileContentsAction", ",", "self", ")", ".", "__init__", "(", "option_strings", ",", "dest", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.FileContentsAction.__call__": [[53, 60], ["fairseq.file_io.PathManager.isfile", "setattr", "fairseq.file_io.PathManager.open", "f.read().strip", "f.read"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.isfile", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "option_string", "=", "None", ")", ":", "\n", "        ", "if", "PathManager", ".", "isfile", "(", "values", ")", ":", "\n", "            ", "with", "PathManager", ".", "open", "(", "values", ")", "as", "f", ":", "\n", "                ", "argument", "=", "f", ".", "read", "(", ")", ".", "strip", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "argument", "=", "values", "\n", "", "setattr", "(", "namespace", ",", "self", ".", "dest", ",", "argument", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_torch_seed.__init__": [[564, 573], ["isinstance", "utils.get_rng_state", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "xm.set_rng_state", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_rng_state", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_rng_state"], ["    ", "def", "__init__", "(", "self", ",", "seed", ")", ":", "\n", "        ", "assert", "isinstance", "(", "seed", ",", "int", ")", "\n", "self", ".", "rng_state", "=", "get_rng_state", "(", ")", "\n", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "if", "xm", "is", "not", "None", ":", "\n", "            ", "xm", ".", "set_rng_state", "(", "seed", ")", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_torch_seed.__enter__": [[574, 576], ["None"], "methods", ["None"], ["", "", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_torch_seed.__exit__": [[577, 579], ["utils.set_rng_state"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_rng_state"], ["", "def", "__exit__", "(", "self", ",", "*", "exc", ")", ":", "\n", "        ", "set_rng_state", "(", "self", ".", "rng_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.CudaEnvironment.__init__": [[663, 670], ["torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.get_device_properties", "torch.cuda.get_device_properties", "torch.cuda.get_device_properties", "torch.cuda.get_device_properties"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "cur_device", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "prop", "=", "torch", ".", "cuda", ".", "get_device_properties", "(", "\"cuda:{}\"", ".", "format", "(", "cur_device", ")", ")", "\n", "self", ".", "name", "=", "prop", ".", "name", "\n", "self", ".", "major", "=", "prop", ".", "major", "\n", "self", ".", "minor", "=", "prop", ".", "minor", "\n", "self", ".", "total_memory_in_GB", "=", "prop", ".", "total_memory", "/", "1024", "/", "1024", "/", "1024", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.CudaEnvironment.pretty_print_cuda_env_list": [[671, 689], ["len", "logger.info", "enumerate", "logger.info", "logger.info", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "pretty_print_cuda_env_list", "(", "cuda_env_list", ")", ":", "\n", "        ", "\"\"\"\n        Given a list of CudaEnviorments, pretty print them\n        \"\"\"", "\n", "num_workers", "=", "len", "(", "cuda_env_list", ")", "\n", "center", "=", "\"CUDA enviroments for all {} workers\"", ".", "format", "(", "num_workers", ")", "\n", "banner_len", "=", "40", "-", "len", "(", "center", ")", "//", "2", "\n", "first_line", "=", "\"*\"", "*", "banner_len", "+", "center", "+", "\"*\"", "*", "banner_len", "\n", "logger", ".", "info", "(", "first_line", ")", "\n", "for", "r", ",", "env", "in", "enumerate", "(", "cuda_env_list", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"rank {:3d}: \"", ".", "format", "(", "r", ")", "\n", "+", "\"capabilities = {:2d}.{:<2d} ; \"", ".", "format", "(", "env", ".", "major", ",", "env", ".", "minor", ")", "\n", "+", "\"total memory = {:.3f} GB ; \"", ".", "format", "(", "env", ".", "total_memory_in_GB", ")", "\n", "+", "\"name = {:40s}\"", ".", "format", "(", "env", ".", "name", ")", "\n", ")", "\n", "", "logger", ".", "info", "(", "first_line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths": [[62, 67], ["paths.split", "paths.split"], "function", ["None"], ["", "", "def", "split_paths", "(", "paths", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "return", "(", "\n", "paths", ".", "split", "(", "os", ".", "pathsep", ")", "\n", "if", "\"://\"", "not", "in", "paths", "\n", "else", "paths", ".", "split", "(", "MANIFOLD_PATH_SEP", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.load_ensemble_for_inference": [[70, 79], ["utils.deprecation_warning", "checkpoint_utils.load_model_ensemble"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.deprecation_warning", "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_model_ensemble"], ["", "def", "load_ensemble_for_inference", "(", "filenames", ",", "task", ",", "model_arg_overrides", "=", "None", ")", ":", "\n", "    ", "from", "fairseq", "import", "checkpoint_utils", "\n", "\n", "deprecation_warning", "(", "\n", "\"utils.load_ensemble_for_inference is deprecated. \"", "\n", "\"Please use checkpoint_utils.load_model_ensemble instead.\"", "\n", ")", "\n", "return", "checkpoint_utils", ".", "load_model_ensemble", "(", "\n", "filenames", ",", "arg_overrides", "=", "model_arg_overrides", ",", "task", "=", "task", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.apply_to_sample": [[82, 101], ["utils.apply_to_sample._apply"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector._apply"], ["", "def", "apply_to_sample", "(", "f", ",", "sample", ")", ":", "\n", "    ", "if", "hasattr", "(", "sample", ",", "\"__len__\"", ")", "and", "len", "(", "sample", ")", "==", "0", ":", "\n", "        ", "return", "{", "}", "\n", "\n", "", "def", "_apply", "(", "x", ")", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "x", ")", ":", "\n", "            ", "return", "f", "(", "x", ")", "\n", "", "elif", "isinstance", "(", "x", ",", "dict", ")", ":", "\n", "            ", "return", "{", "key", ":", "_apply", "(", "value", ")", "for", "key", ",", "value", "in", "x", ".", "items", "(", ")", "}", "\n", "", "elif", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "            ", "return", "[", "_apply", "(", "x", ")", "for", "x", "in", "x", "]", "\n", "", "elif", "isinstance", "(", "x", ",", "tuple", ")", ":", "\n", "            ", "return", "tuple", "(", "_apply", "(", "x", ")", "for", "x", "in", "x", ")", "\n", "", "elif", "isinstance", "(", "x", ",", "set", ")", ":", "\n", "            ", "return", "{", "_apply", "(", "x", ")", "for", "x", "in", "x", "}", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n", "", "", "return", "_apply", "(", "sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.move_to_cuda": [[103, 112], ["utils.apply_to_sample", "torch.cuda.current_device", "torch.cuda.current_device", "tensor.cuda"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.apply_to_sample", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.cuda"], ["", "def", "move_to_cuda", "(", "sample", ",", "device", "=", "None", ")", ":", "\n", "    ", "device", "=", "device", "or", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "\n", "def", "_move_to_cuda", "(", "tensor", ")", ":", "\n", "# non_blocking is ignored if tensor is not pinned, so we can always set", "\n", "# to True (see github.com/PyTorchLightning/pytorch-lightning/issues/620)", "\n", "        ", "return", "tensor", ".", "cuda", "(", "device", "=", "device", ",", "non_blocking", "=", "True", ")", "\n", "\n", "", "return", "apply_to_sample", "(", "_move_to_cuda", ",", "sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.move_to_cpu": [[114, 123], ["utils.apply_to_sample", "tensor.to.cpu", "tensor.to.to"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.apply_to_sample"], ["", "def", "move_to_cpu", "(", "sample", ")", ":", "\n", "    ", "def", "_move_to_cpu", "(", "tensor", ")", ":", "\n", "# PyTorch has poor support for half tensors (float16) on CPU.", "\n", "# Move any such tensors to float32.", "\n", "        ", "if", "tensor", ".", "dtype", "in", "{", "torch", ".", "bfloat16", ",", "torch", ".", "float16", "}", ":", "\n", "            ", "tensor", "=", "tensor", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", "\n", "", "return", "tensor", ".", "cpu", "(", ")", "\n", "\n", "", "return", "apply_to_sample", "(", "_move_to_cpu", ",", "sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_incremental_state": [[125, 132], ["module.get_incremental_state"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_incremental_state"], ["", "def", "get_incremental_state", "(", "\n", "module", ":", "MultiheadAttention", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "key", ":", "str", ",", "\n", ")", "->", "Optional", "[", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ":", "\n", "    ", "\"\"\"Helper for getting incremental state for an nn.Module.\"\"\"", "\n", "return", "module", ".", "get_incremental_state", "(", "incremental_state", ",", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_incremental_state": [[134, 146], ["module.set_incremental_state"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_incremental_state"], ["", "def", "set_incremental_state", "(", "\n", "module", ":", "MultiheadAttention", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "key", ":", "str", ",", "\n", "value", ":", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", ",", "\n", ")", "->", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ":", "\n", "    ", "\"\"\"Helper for setting incremental state for an nn.Module.\"\"\"", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "        ", "result", "=", "module", ".", "set_incremental_state", "(", "incremental_state", ",", "key", ",", "value", ")", "\n", "if", "result", "is", "not", "None", ":", "\n", "            ", "incremental_state", "=", "result", "\n", "", "", "return", "incremental_state", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.load_align_dict": [[148, 163], ["isinstance", "len", "open", "line.split"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["", "def", "load_align_dict", "(", "replace_unk", ")", ":", "\n", "    ", "if", "replace_unk", "is", "None", ":", "\n", "        ", "align_dict", "=", "None", "\n", "", "elif", "isinstance", "(", "replace_unk", ",", "str", ")", "and", "len", "(", "replace_unk", ")", ">", "0", ":", "\n", "# Load alignment dictionary for unknown word replacement if it was passed as an argument.", "\n", "        ", "align_dict", "=", "{", "}", "\n", "with", "open", "(", "replace_unk", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "cols", "=", "line", ".", "split", "(", ")", "\n", "align_dict", "[", "cols", "[", "0", "]", "]", "=", "cols", "[", "1", "]", "\n", "", "", "", "else", ":", "\n", "# No alignment dictionary provided but we still want to perform unknown word replacement by copying the", "\n", "# original source word.", "\n", "        ", "align_dict", "=", "{", "}", "\n", "", "return", "align_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.print_embed_overlap": [[165, 170], ["set", "set", "len", "logger.info", "embed_dict.keys", "len"], "function", ["None"], ["", "def", "print_embed_overlap", "(", "embed_dict", ",", "vocab_dict", ")", ":", "\n", "    ", "embed_keys", "=", "set", "(", "embed_dict", ".", "keys", "(", ")", ")", "\n", "vocab_keys", "=", "set", "(", "vocab_dict", ".", "symbols", ")", "\n", "overlap", "=", "len", "(", "embed_keys", "&", "vocab_keys", ")", "\n", "logger", ".", "info", "(", "\"found {}/{} types in embedding file\"", ".", "format", "(", "overlap", ",", "len", "(", "vocab_dict", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.parse_embedding": [[172, 192], ["open", "next", "line.rstrip().split", "torch.Tensor", "torch.Tensor", "line.rstrip", "float"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["", "def", "parse_embedding", "(", "embed_path", ")", ":", "\n", "    ", "\"\"\"Parse embedding text file into a dictionary of word and embedding tensors.\n\n    The first line can have vocabulary size and dimension. The following lines\n    should contain word and embedding separated by spaces.\n\n    Example:\n        2 5\n        the -0.0230 -0.0264  0.0287  0.0171  0.1403\n        at -0.0395 -0.1286  0.0275  0.0254 -0.0932\n    \"\"\"", "\n", "embed_dict", "=", "{", "}", "\n", "with", "open", "(", "embed_path", ")", "as", "f_embed", ":", "\n", "        ", "next", "(", "f_embed", ")", "# skip header", "\n", "for", "line", "in", "f_embed", ":", "\n", "            ", "pieces", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "embed_dict", "[", "pieces", "[", "0", "]", "]", "=", "torch", ".", "Tensor", "(", "\n", "[", "float", "(", "weight", ")", "for", "weight", "in", "pieces", "[", "1", ":", "]", "]", "\n", ")", "\n", "", "", "return", "embed_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.load_embedding": [[194, 200], ["range", "len"], "function", ["None"], ["", "def", "load_embedding", "(", "embed_dict", ",", "vocab", ",", "embedding", ")", ":", "\n", "    ", "for", "idx", "in", "range", "(", "len", "(", "vocab", ")", ")", ":", "\n", "        ", "token", "=", "vocab", "[", "idx", "]", "\n", "if", "token", "in", "embed_dict", ":", "\n", "            ", "embedding", ".", "weight", ".", "data", "[", "idx", "]", "=", "embed_dict", "[", "token", "]", "\n", "", "", "return", "embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.replace_unk": [[202, 215], ["tokenizer.tokenize_line", "enumerate", "tokenizer.tokenize_line", "align_dict.get"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.tokenizer.tokenize_line", "home.repos.pwc.inspect_result.reneeye_const.fairseq.tokenizer.tokenize_line"], ["", "def", "replace_unk", "(", "hypo_str", ",", "src_str", ",", "alignment", ",", "align_dict", ",", "unk", ")", ":", "\n", "    ", "from", "fairseq", "import", "tokenizer", "\n", "\n", "# Tokens are strings here", "\n", "hypo_tokens", "=", "tokenizer", ".", "tokenize_line", "(", "hypo_str", ")", "\n", "# TODO: Very rare cases where the replacement is '<eos>' should be handled gracefully", "\n", "src_tokens", "=", "tokenizer", ".", "tokenize_line", "(", "src_str", ")", "+", "[", "\"<eos>\"", "]", "\n", "for", "i", ",", "ht", "in", "enumerate", "(", "hypo_tokens", ")", ":", "\n", "        ", "if", "ht", "==", "unk", ":", "\n", "            ", "src_token", "=", "src_tokens", "[", "alignment", "[", "i", "]", "]", "\n", "# Either take the corresponding value in the aligned dictionary or just copy the original value.", "\n", "hypo_tokens", "[", "i", "]", "=", "align_dict", ".", "get", "(", "src_token", ",", "src_token", ")", "\n", "", "", "return", "\" \"", ".", "join", "(", "hypo_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.post_process_prediction": [[217, 238], ["tgt_dict.string", "utils.replace_unk", "tgt_dict.encode_line", "tgt_dict.unk_string"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.replace_unk", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.encode_line", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk_string"], ["", "def", "post_process_prediction", "(", "\n", "hypo_tokens", ",", "\n", "src_str", ",", "\n", "alignment", ",", "\n", "align_dict", ",", "\n", "tgt_dict", ",", "\n", "remove_bpe", "=", "None", ",", "\n", "extra_symbols_to_ignore", "=", "None", ",", "\n", ")", ":", "\n", "    ", "hypo_str", "=", "tgt_dict", ".", "string", "(", "\n", "hypo_tokens", ",", "remove_bpe", ",", "extra_symbols_to_ignore", "=", "extra_symbols_to_ignore", "\n", ")", "\n", "if", "align_dict", "is", "not", "None", ":", "\n", "        ", "hypo_str", "=", "replace_unk", "(", "\n", "hypo_str", ",", "src_str", ",", "alignment", ",", "align_dict", ",", "tgt_dict", ".", "unk_string", "(", ")", "\n", ")", "\n", "", "if", "align_dict", "is", "not", "None", "or", "remove_bpe", "is", "not", "None", ":", "\n", "# Convert back to tokens for evaluating with unk replacement or without BPE", "\n", "# Note that the dictionary can be modified inside the method.", "\n", "        ", "hypo_tokens", "=", "tgt_dict", ".", "encode_line", "(", "hypo_str", ",", "add_if_not_exist", "=", "True", ")", "\n", "", "return", "hypo_tokens", ",", "hypo_str", ",", "alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.make_positions": [[240, 251], ["tensor.ne().int", "tensor.ne", "torch.cumsum().type_as", "torch.cumsum().type_as", "torch.cumsum", "torch.cumsum"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.cumsum", "home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.cumsum"], ["", "def", "make_positions", "(", "tensor", ",", "padding_idx", ":", "int", ",", "onnx_trace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Replace non-padding symbols with their position numbers.\n\n    Position numbers begin at padding_idx+1. Padding symbols are ignored.\n    \"\"\"", "\n", "# The series of casts and type-conversions here are carefully", "\n", "# balanced to both work with ONNX export and XLA. In particular XLA", "\n", "# prefers ints, cumsum defaults to output longs, and ONNX doesn't know", "\n", "# how to handle the dtype kwarg in cumsum.", "\n", "mask", "=", "tensor", ".", "ne", "(", "padding_idx", ")", ".", "int", "(", ")", "\n", "return", "(", "torch", ".", "cumsum", "(", "mask", ",", "dim", "=", "1", ")", ".", "type_as", "(", "mask", ")", "*", "mask", ")", ".", "long", "(", ")", "+", "padding_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.strip_pad": [[253, 255], ["tensor.ne"], "function", ["None"], ["", "def", "strip_pad", "(", "tensor", ",", "pad", ")", ":", "\n", "    ", "return", "tensor", "[", "tensor", ".", "ne", "(", "pad", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.buffered_arange": [[257, 264], ["hasattr", "torch.LongTensor", "torch.LongTensor", "buffered_arange.buf.numel", "buffered_arange.buf.resize_", "torch.arange", "torch.arange"], "function", ["None"], ["", "def", "buffered_arange", "(", "max", ")", ":", "\n", "    ", "if", "not", "hasattr", "(", "buffered_arange", ",", "\"buf\"", ")", ":", "\n", "        ", "buffered_arange", ".", "buf", "=", "torch", ".", "LongTensor", "(", ")", "\n", "", "if", "max", ">", "buffered_arange", ".", "buf", ".", "numel", "(", ")", ":", "\n", "        ", "buffered_arange", ".", "buf", ".", "resize_", "(", "max", ")", "\n", "torch", ".", "arange", "(", "max", ",", "out", "=", "buffered_arange", ".", "buf", ")", "\n", "", "return", "buffered_arange", ".", "buf", "[", ":", "max", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.convert_padding_direction": [[266, 291], ["src_tokens.eq", "src_tokens.size", "torch.empty().long", "torch.empty().long", "torch.empty().long.type_as().expand_as", "src_tokens.eq.long().sum", "src_tokens.gather", "src_tokens.eq.any", "torch.arange", "torch.arange", "torch.remainder", "torch.remainder", "torch.remainder", "torch.remainder", "pad_mask[].any", "pad_mask[].any", "torch.empty", "torch.empty", "torch.empty().long.type_as", "src_tokens.eq.long"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "convert_padding_direction", "(", "\n", "src_tokens", ",", "padding_idx", ",", "right_to_left", ":", "bool", "=", "False", ",", "left_to_right", ":", "bool", "=", "False", "\n", ")", ":", "\n", "    ", "assert", "right_to_left", "^", "left_to_right", "\n", "pad_mask", "=", "src_tokens", ".", "eq", "(", "padding_idx", ")", "\n", "if", "not", "pad_mask", ".", "any", "(", ")", ":", "\n", "# no padding, return early", "\n", "        ", "return", "src_tokens", "\n", "", "if", "left_to_right", "and", "not", "pad_mask", "[", ":", ",", "0", "]", ".", "any", "(", ")", ":", "\n", "# already right padded", "\n", "        ", "return", "src_tokens", "\n", "", "if", "right_to_left", "and", "not", "pad_mask", "[", ":", ",", "-", "1", "]", ".", "any", "(", ")", ":", "\n", "# already left padded", "\n", "        ", "return", "src_tokens", "\n", "", "max_len", "=", "src_tokens", ".", "size", "(", "1", ")", "\n", "buffered", "=", "torch", ".", "empty", "(", "0", ")", ".", "long", "(", ")", "\n", "if", "max_len", ">", "0", ":", "\n", "        ", "torch", ".", "arange", "(", "max_len", ",", "out", "=", "buffered", ")", "\n", "", "range", "=", "buffered", ".", "type_as", "(", "src_tokens", ")", ".", "expand_as", "(", "src_tokens", ")", "\n", "num_pads", "=", "pad_mask", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "if", "right_to_left", ":", "\n", "        ", "index", "=", "torch", ".", "remainder", "(", "range", "-", "num_pads", ",", "max_len", ")", "\n", "", "else", ":", "\n", "        ", "index", "=", "torch", ".", "remainder", "(", "range", "+", "num_pads", ",", "max_len", ")", "\n", "", "return", "src_tokens", ".", "gather", "(", "1", ",", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item": [[293, 299], ["hasattr", "hasattr", "tensor.item"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "def", "item", "(", "tensor", ")", ":", "\n", "    ", "if", "hasattr", "(", "tensor", ",", "\"item\"", ")", ":", "\n", "        ", "return", "tensor", ".", "item", "(", ")", "\n", "", "if", "hasattr", "(", "tensor", ",", "\"__getitem__\"", ")", ":", "\n", "        ", "return", "tensor", "[", "0", "]", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.multi_tensor_total_norm": [[301, 325], ["per_device_grads.keys", "torch.norm", "torch.norm", "per_device_grads.get", "per_device_grads.get.append", "torch.stack", "torch.stack", "torch.zeros", "torch.zeros", "norms.append", "torch.cuda.device", "torch.cuda.device", "multi_tensor_l2norm", "norm[].to", "torch.norm", "torch.norm", "torch.cuda.current_device", "torch.cuda.current_device"], "function", ["home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.device", "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.device"], ["", "def", "multi_tensor_total_norm", "(", "grads", ",", "chunk_size", "=", "2048", "*", "32", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "per_device_grads", "=", "{", "}", "\n", "norms", "=", "[", "]", "\n", "for", "grad", "in", "grads", ":", "\n", "        ", "device", "=", "grad", ".", "device", "\n", "cur_device_grads", "=", "per_device_grads", ".", "get", "(", "device", ")", "\n", "if", "cur_device_grads", "is", "None", ":", "\n", "            ", "cur_device_grads", "=", "[", "]", "\n", "per_device_grads", "[", "device", "]", "=", "cur_device_grads", "\n", "", "cur_device_grads", ".", "append", "(", "grad", ")", "\n", "", "for", "device", "in", "per_device_grads", ".", "keys", "(", ")", ":", "\n", "        ", "cur_device_grads", "=", "per_device_grads", "[", "device", "]", "\n", "if", "device", ".", "type", "==", "\"cuda\"", ":", "\n", "# TODO(msb) return has_inf", "\n", "            ", "has_inf", "=", "torch", ".", "zeros", "(", "(", "1", ",", "1", ")", ",", "dtype", "=", "torch", ".", "int", ",", "device", "=", "device", ")", "\n", "with", "torch", ".", "cuda", ".", "device", "(", "device", ")", ":", "\n", "                ", "norm", "=", "multi_tensor_l2norm", "(", "\n", "chunk_size", ",", "has_inf", ",", "[", "cur_device_grads", "]", ",", "False", "\n", ")", "\n", "", "norms", ".", "append", "(", "norm", "[", "0", "]", ".", "to", "(", "torch", ".", "cuda", ".", "current_device", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "norms", "+=", "[", "torch", ".", "norm", "(", "g", ",", "p", "=", "2", ",", "dtype", "=", "torch", ".", "float32", ")", "for", "g", "in", "cur_device_grads", "]", "\n", "", "", "total_norm", "=", "torch", ".", "norm", "(", "torch", ".", "stack", "(", "norms", ")", ")", "\n", "return", "total_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.clip_grad_norm_": [[327, 370], ["torch.no_grad", "torch.no_grad", "isinstance", "list", "p.grad.detach", "len", "len", "torch.norm", "torch.norm", "aggregate_norm_fn", "float", "filter", "len", "params[].new_tensor", "torch.tensor", "torch.tensor", "utils.multi_tensor_total_norm", "torch.cuda.is_available", "torch.cuda.is_available", "torch.norm", "torch.norm", "g.mul_", "warnings.warn", "torch.cuda.current_device", "torch.cuda.current_device", "torch.stack", "torch.stack", "torch.device", "torch.device", "torch.norm().to", "torch.norm().to", "torch.norm", "torch.norm"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.multi_tensor_total_norm", "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.device", "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.device"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "clip_grad_norm_", "(", "params", ",", "max_norm", ",", "aggregate_norm_fn", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "if", "isinstance", "(", "params", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "params", "=", "[", "params", "]", "\n", "", "params", "=", "list", "(", "params", ")", "\n", "grads", "=", "[", "p", ".", "grad", ".", "detach", "(", ")", "for", "p", "in", "filter", "(", "lambda", "p", ":", "p", ".", "grad", "is", "not", "None", ",", "params", ")", "]", "\n", "if", "len", "(", "grads", ")", "==", "0", ":", "\n", "        ", "if", "len", "(", "params", ")", ">", "0", ":", "\n", "            ", "return", "params", "[", "0", "]", ".", "new_tensor", "(", "0.0", ")", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "tensor", "(", "0.0", ")", "\n", "\n", "", "", "if", "len", "(", "grads", ")", "==", "1", ":", "\n", "        ", "total_norm", "=", "torch", ".", "norm", "(", "grads", "[", "0", "]", ",", "p", "=", "2", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "", "else", ":", "\n", "        ", "if", "multi_tensor_l2norm_available", ":", "\n", "            ", "total_norm", "=", "multi_tensor_total_norm", "(", "grads", ")", "\n", "", "else", ":", "\n", "            ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "warnings", ".", "warn", "(", "\n", "\"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"", "\n", "\"you may get better performance by installing NVIDIA's apex library\"", "\n", ")", "\n", "device", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "", "elif", "grads", "[", "0", "]", ".", "device", ".", "type", "==", "\"xla\"", ":", "\n", "                ", "device", "=", "grads", "[", "0", "]", ".", "device", "\n", "", "else", ":", "\n", "                ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "", "total_norm", "=", "torch", ".", "norm", "(", "\n", "torch", ".", "stack", "(", "\n", "[", "torch", ".", "norm", "(", "g", ",", "p", "=", "2", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "to", "(", "device", ")", "for", "g", "in", "grads", "]", "\n", ")", "\n", ")", "\n", "\n", "", "", "if", "aggregate_norm_fn", "is", "not", "None", ":", "\n", "        ", "total_norm", "=", "aggregate_norm_fn", "(", "total_norm", ")", "\n", "\n", "", "if", "max_norm", ">", "0", ":", "\n", "        ", "max_norm", "=", "float", "(", "max_norm", ")", "\n", "clip_coef", "=", "(", "max_norm", "/", "(", "total_norm", "+", "1e-6", ")", ")", ".", "clamp_", "(", "max", "=", "1", ")", "\n", "for", "g", "in", "grads", ":", "\n", "            ", "g", ".", "mul_", "(", "clip_coef", ")", "\n", "", "", "return", "total_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.fill_with_neg_inf": [[372, 375], ["t.float().fill_().type_as", "t.float().fill_", "float", "t.float"], "function", ["None"], ["", "def", "fill_with_neg_inf", "(", "t", ")", ":", "\n", "    ", "\"\"\"FP16-compatible function that fills a tensor with -inf.\"\"\"", "\n", "return", "t", ".", "float", "(", ")", ".", "fill_", "(", "float", "(", "\"-inf\"", ")", ")", ".", "type_as", "(", "t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils._match_types": [[377, 397], ["isinstance", "isinstance", "isinstance", "tuple", "isinstance", "utils._match_types.upgrade"], "function", ["None"], ["", "def", "_match_types", "(", "arg1", ",", "arg2", ")", ":", "\n", "    ", "\"\"\"Convert the numerical argument to the same type as the other argument\"\"\"", "\n", "\n", "def", "upgrade", "(", "arg_number", ",", "arg_structure", ")", ":", "\n", "        ", "if", "isinstance", "(", "arg_structure", ",", "tuple", ")", ":", "\n", "            ", "return", "tuple", "(", "[", "arg_number", "]", "*", "len", "(", "arg_structure", ")", ")", "\n", "", "elif", "isinstance", "(", "arg_structure", ",", "dict", ")", ":", "\n", "            ", "arg", "=", "copy", ".", "deepcopy", "(", "arg_structure", ")", "\n", "for", "k", "in", "arg", ":", "\n", "                ", "arg", "[", "k", "]", "=", "upgrade", "(", "arg_number", ",", "arg_structure", "[", "k", "]", ")", "\n", "", "return", "arg", "\n", "", "else", ":", "\n", "            ", "return", "arg_number", "\n", "\n", "", "", "if", "isinstance", "(", "arg1", ",", "float", ")", "or", "isinstance", "(", "arg1", ",", "int", ")", ":", "\n", "        ", "return", "upgrade", "(", "arg1", ",", "arg2", ")", ",", "arg2", "\n", "", "elif", "isinstance", "(", "arg2", ",", "float", ")", "or", "isinstance", "(", "arg2", ",", "int", ")", ":", "\n", "        ", "return", "arg1", ",", "upgrade", "(", "arg2", ",", "arg1", ")", "\n", "\n", "", "return", "arg1", ",", "arg2", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.resolve_max_positions": [[399, 434], ["copy.deepcopy", "min", "utils._match_types", "isinstance", "isinstance", "min", "isinstance", "utils.resolve_max_positions.map_value_update"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils._match_types"], ["", "def", "resolve_max_positions", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"Resolve max position constraints from multiple sources.\"\"\"", "\n", "\n", "def", "map_value_update", "(", "d1", ",", "d2", ")", ":", "\n", "        ", "updated_value", "=", "copy", ".", "deepcopy", "(", "d1", ")", "\n", "for", "key", "in", "d2", ":", "\n", "            ", "if", "key", "not", "in", "updated_value", ":", "\n", "                ", "updated_value", "[", "key", "]", "=", "d2", "[", "key", "]", "\n", "", "else", ":", "\n", "                ", "updated_value", "[", "key", "]", "=", "min", "(", "d1", "[", "key", "]", ",", "d2", "[", "key", "]", ")", "\n", "", "", "return", "updated_value", "\n", "\n", "", "def", "nullsafe_min", "(", "l", ")", ":", "\n", "        ", "minim", "=", "None", "\n", "for", "item", "in", "l", ":", "\n", "            ", "if", "minim", "is", "None", ":", "\n", "                ", "minim", "=", "item", "\n", "", "elif", "item", "is", "not", "None", "and", "item", "<", "minim", ":", "\n", "                ", "minim", "=", "item", "\n", "", "", "return", "minim", "\n", "\n", "", "max_positions", "=", "None", "\n", "for", "arg", "in", "args", ":", "\n", "        ", "if", "max_positions", "is", "None", ":", "\n", "            ", "max_positions", "=", "arg", "\n", "", "elif", "arg", "is", "not", "None", ":", "\n", "            ", "max_positions", ",", "arg", "=", "_match_types", "(", "max_positions", ",", "arg", ")", "\n", "if", "isinstance", "(", "arg", ",", "float", ")", "or", "isinstance", "(", "arg", ",", "int", ")", ":", "\n", "                ", "max_positions", "=", "min", "(", "max_positions", ",", "arg", ")", "\n", "", "elif", "isinstance", "(", "arg", ",", "dict", ")", ":", "\n", "                ", "max_positions", "=", "map_value_update", "(", "max_positions", ",", "arg", ")", "\n", "", "else", ":", "\n", "                ", "max_positions", "=", "tuple", "(", "map", "(", "nullsafe_min", ",", "zip", "(", "max_positions", ",", "arg", ")", ")", ")", "\n", "\n", "", "", "", "return", "max_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.import_user_module": [[436, 467], ["getattr", "os.path.abspath", "getattr", "os.path.exists", "os.path.join", "os.path.exists", "set", "import_user_module.memo.add", "os.path.split", "os.path.dirname", "os.path.join", "os.path.exists", "sys.path.insert", "importlib.import_module", "ImportError", "os.path.dirname", "FileNotFoundError"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists"], ["", "def", "import_user_module", "(", "args", ")", ":", "\n", "    ", "module_path", "=", "getattr", "(", "args", ",", "\"user_dir\"", ",", "None", ")", "\n", "if", "module_path", "is", "not", "None", ":", "\n", "        ", "module_path", "=", "os", ".", "path", ".", "abspath", "(", "args", ".", "user_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "module_path", ")", ":", "\n", "            ", "fairseq_rel_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "args", ".", "user_dir", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "fairseq_rel_path", ")", ":", "\n", "                ", "module_path", "=", "fairseq_rel_path", "\n", "", "else", ":", "\n", "                ", "fairseq_rel_path", "=", "os", ".", "path", ".", "join", "(", "\n", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "\"..\"", ",", "args", ".", "user_dir", "\n", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "fairseq_rel_path", ")", ":", "\n", "                    ", "module_path", "=", "fairseq_rel_path", "\n", "", "else", ":", "\n", "                    ", "raise", "FileNotFoundError", "(", "module_path", ")", "\n", "\n", "# ensure that user modules are only imported once", "\n", "", "", "", "import_user_module", ".", "memo", "=", "getattr", "(", "import_user_module", ",", "\"memo\"", ",", "set", "(", ")", ")", "\n", "if", "module_path", "not", "in", "import_user_module", ".", "memo", ":", "\n", "            ", "import_user_module", ".", "memo", ".", "add", "(", "module_path", ")", "\n", "\n", "module_parent", ",", "module_name", "=", "os", ".", "path", ".", "split", "(", "module_path", ")", "\n", "if", "module_name", "not", "in", "sys", ".", "modules", ":", "\n", "                ", "sys", ".", "path", ".", "insert", "(", "0", ",", "module_parent", ")", "\n", "importlib", ".", "import_module", "(", "module_name", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ImportError", "(", "\n", "\"Failed to import --user-dir={} because the corresponding module name \"", "\n", "\"({}) is not globally unique. Please rename the directory to \"", "\n", "\"something unique and try again.\"", ".", "format", "(", "module_path", ",", "module_name", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax": [[470, 475], ["torch.softmax", "torch.softmax", "x.float"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax"], ["", "", "", "", "def", "softmax", "(", "x", ",", "dim", ":", "int", ",", "onnx_trace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "if", "onnx_trace", ":", "\n", "        ", "return", "F", ".", "softmax", "(", "x", ".", "float", "(", ")", ",", "dim", "=", "dim", ")", "\n", "", "else", ":", "\n", "        ", "return", "F", ".", "softmax", "(", "x", ",", "dim", "=", "dim", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax": [[477, 482], ["torch.log_softmax", "torch.log_softmax", "x.float"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax"], ["", "", "def", "log_softmax", "(", "x", ",", "dim", ":", "int", ",", "onnx_trace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "if", "onnx_trace", ":", "\n", "        ", "return", "F", ".", "log_softmax", "(", "x", ".", "float", "(", ")", ",", "dim", "=", "dim", ")", "\n", "", "else", ":", "\n", "        ", "return", "F", ".", "log_softmax", "(", "x", ",", "dim", "=", "dim", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_perplexity": [[484, 491], ["fairseq.logging.meters.safe_round", "float"], "function", ["home.repos.pwc.inspect_result.reneeye_const.logging.meters.safe_round"], ["", "", "def", "get_perplexity", "(", "loss", ",", "round", "=", "2", ",", "base", "=", "2", ")", ":", "\n", "    ", "if", "loss", "is", "None", ":", "\n", "        ", "return", "0.0", "\n", "", "try", ":", "\n", "        ", "return", "safe_round", "(", "base", "**", "loss", ",", "round", ")", "\n", "", "except", "OverflowError", ":", "\n", "        ", "return", "float", "(", "\"inf\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.deprecation_warning": [[493, 496], ["warnings.warn"], "function", ["None"], ["", "", "def", "deprecation_warning", "(", "message", ",", "stacklevel", "=", "3", ")", ":", "\n", "# don't use DeprecationWarning, since it's ignored by default", "\n", "    ", "warnings", ".", "warn", "(", "message", ",", "stacklevel", "=", "stacklevel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_activation_fn": [[498, 517], ["utils.deprecation_warning", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.deprecation_warning"], ["", "def", "get_activation_fn", "(", "activation", ":", "str", ")", "->", "Callable", ":", "\n", "    ", "\"\"\" Returns the activation function corresponding to `activation` \"\"\"", "\n", "if", "activation", "==", "\"relu\"", ":", "\n", "        ", "return", "F", ".", "relu", "\n", "", "elif", "activation", "==", "\"gelu\"", ":", "\n", "        ", "return", "gelu", "\n", "", "elif", "activation", "==", "\"gelu_fast\"", ":", "\n", "        ", "deprecation_warning", "(", "\n", "\"--activation-fn=gelu_fast has been renamed to gelu_accurate\"", "\n", ")", "\n", "return", "gelu_accurate", "\n", "", "elif", "activation", "==", "\"gelu_accurate\"", ":", "\n", "        ", "return", "gelu_accurate", "\n", "", "elif", "activation", "==", "\"tanh\"", ":", "\n", "        ", "return", "torch", ".", "tanh", "\n", "", "elif", "activation", "==", "\"linear\"", ":", "\n", "        ", "return", "lambda", "x", ":", "x", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"--activation-fn {} not supported\"", ".", "format", "(", "activation", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_available_activation_fns": [[519, 527], ["None"], "function", ["None"], ["", "", "def", "get_available_activation_fns", "(", ")", "->", "List", ":", "\n", "    ", "return", "[", "\n", "\"relu\"", ",", "\n", "\"gelu\"", ",", "\n", "\"gelu_fast\"", ",", "# deprecated", "\n", "\"gelu_accurate\"", ",", "\n", "\"tanh\"", ",", "\n", "\"linear\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.model_eval": [[530, 536], ["model.eval", "model.train"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.train"], ["", "@", "contextlib", ".", "contextmanager", "\n", "def", "model_eval", "(", "model", ")", ":", "\n", "    ", "is_training", "=", "model", ".", "training", "\n", "model", ".", "eval", "(", ")", "\n", "yield", "\n", "model", ".", "train", "(", "is_training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.has_parameters": [[538, 544], ["next", "module.parameters"], "function", ["None"], ["", "def", "has_parameters", "(", "module", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "next", "(", "module", ".", "parameters", "(", ")", ")", "\n", "return", "True", "\n", "", "except", "StopIteration", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_rng_state": [[546, 553], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.get_rng_state", "torch.get_rng_state", "xm.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_rng_state", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_rng_state", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_rng_state", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_rng_state", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_rng_state"], ["", "", "def", "get_rng_state", "(", ")", ":", "\n", "    ", "state", "=", "{", "\"torch_rng_state\"", ":", "torch", ".", "get_rng_state", "(", ")", "}", "\n", "if", "xm", "is", "not", "None", ":", "\n", "        ", "state", "[", "\"xla_rng_state\"", "]", "=", "xm", ".", "get_rng_state", "(", ")", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "state", "[", "\"cuda_rng_state\"", "]", "=", "torch", ".", "cuda", ".", "get_rng_state", "(", ")", "\n", "", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_rng_state": [[555, 561], ["torch.set_rng_state", "torch.set_rng_state", "torch.cuda.is_available", "torch.cuda.is_available", "xm.set_rng_state", "torch.cuda.set_rng_state", "torch.cuda.set_rng_state"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_rng_state", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_rng_state", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_rng_state", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_rng_state", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_rng_state"], ["", "def", "set_rng_state", "(", "state", ")", ":", "\n", "    ", "torch", ".", "set_rng_state", "(", "state", "[", "\"torch_rng_state\"", "]", ")", "\n", "if", "xm", "is", "not", "None", ":", "\n", "        ", "xm", ".", "set_rng_state", "(", "state", "[", "\"xla_rng_state\"", "]", ")", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_rng_state", "(", "state", "[", "\"cuda_rng_state\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.parse_alignment": [[581, 600], ["line.strip().split", "torch.IntTensor", "torch.IntTensor", "enumerate", "alignment.split", "int", "int", "line.strip", "len"], "function", ["None"], ["", "", "def", "parse_alignment", "(", "line", ")", ":", "\n", "    ", "\"\"\"\n    Parses a single line from the alingment file.\n\n    Args:\n        line (str): String containing the alignment of the format:\n            <src_idx_1>-<tgt_idx_1> <src_idx_2>-<tgt_idx_2> ..\n            <src_idx_m>-<tgt_idx_m>. All indices are 0 indexed.\n\n    Returns:\n        torch.IntTensor: packed alignments of shape (2 * m).\n    \"\"\"", "\n", "alignments", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "parsed_alignment", "=", "torch", ".", "IntTensor", "(", "2", "*", "len", "(", "alignments", ")", ")", "\n", "for", "idx", ",", "alignment", "in", "enumerate", "(", "alignments", ")", ":", "\n", "        ", "src_idx", ",", "tgt_idx", "=", "alignment", ".", "split", "(", "\"-\"", ")", "\n", "parsed_alignment", "[", "2", "*", "idx", "]", "=", "int", "(", "src_idx", ")", "\n", "parsed_alignment", "[", "2", "*", "idx", "+", "1", "]", "=", "int", "(", "tgt_idx", ")", "\n", "", "return", "parsed_alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_token_to_word_mapping": [[602, 608], ["len", "list", "int", "itertools.accumulate", "range"], "function", ["None"], ["", "def", "get_token_to_word_mapping", "(", "tokens", ",", "exclude_list", ")", ":", "\n", "    ", "n", "=", "len", "(", "tokens", ")", "\n", "word_start", "=", "[", "int", "(", "token", "not", "in", "exclude_list", ")", "for", "token", "in", "tokens", "]", "\n", "word_idx", "=", "list", "(", "accumulate", "(", "word_start", ")", ")", "\n", "token_to_word", "=", "{", "i", ":", "word_idx", "[", "i", "]", "for", "i", "in", "range", "(", "n", ")", "}", "\n", "return", "token_to_word", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.extract_hard_alignment": [[610, 632], ["utils.get_token_to_word_mapping", "utils.get_token_to_word_mapping", "float", "attn_valid.max", "zip", "len", "len", "len", "alignment.append", "src_idx.item", "tgt_idx.item"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_token_to_word_mapping", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_token_to_word_mapping", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "def", "extract_hard_alignment", "(", "attn", ",", "src_sent", ",", "tgt_sent", ",", "pad", ",", "eos", ")", ":", "\n", "    ", "tgt_valid", "=", "(", "\n", "(", "(", "tgt_sent", "!=", "pad", ")", "&", "(", "tgt_sent", "!=", "eos", ")", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", ".", "squeeze", "(", "dim", "=", "-", "1", ")", "\n", ")", "\n", "src_invalid", "=", "(", "\n", "(", "(", "src_sent", "==", "pad", ")", "|", "(", "src_sent", "==", "eos", ")", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", ".", "squeeze", "(", "dim", "=", "-", "1", ")", "\n", ")", "\n", "src_token_to_word", "=", "get_token_to_word_mapping", "(", "src_sent", ",", "[", "eos", ",", "pad", "]", ")", "\n", "tgt_token_to_word", "=", "get_token_to_word_mapping", "(", "tgt_sent", ",", "[", "eos", ",", "pad", "]", ")", "\n", "alignment", "=", "[", "]", "\n", "if", "len", "(", "tgt_valid", ")", "!=", "0", "and", "len", "(", "src_invalid", ")", "<", "len", "(", "src_sent", ")", ":", "\n", "        ", "attn_valid", "=", "attn", "[", "tgt_valid", "]", "\n", "attn_valid", "[", ":", ",", "src_invalid", "]", "=", "float", "(", "\"-inf\"", ")", "\n", "_", ",", "src_indices", "=", "attn_valid", ".", "max", "(", "dim", "=", "1", ")", "\n", "for", "tgt_idx", ",", "src_idx", "in", "zip", "(", "tgt_valid", ",", "src_indices", ")", ":", "\n", "            ", "alignment", ".", "append", "(", "\n", "(", "\n", "src_token_to_word", "[", "src_idx", ".", "item", "(", ")", "]", "-", "1", ",", "\n", "tgt_token_to_word", "[", "tgt_idx", ".", "item", "(", ")", "]", "-", "1", ",", "\n", ")", "\n", ")", "\n", "", "", "return", "alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.new_arange": [[634, 642], ["torch.arange().expand().contiguous", "torch.arange().expand().contiguous", "len", "x.size", "torch.arange().expand", "torch.arange().expand", "torch.arange", "torch.arange"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "new_arange", "(", "x", ",", "*", "size", ")", ":", "\n", "    ", "\"\"\"\n    Return a Tensor of `size` filled with a range function on the device of x.\n    If size is empty, using the size of the variable x.\n    \"\"\"", "\n", "if", "len", "(", "size", ")", "==", "0", ":", "\n", "        ", "size", "=", "x", ".", "size", "(", ")", "\n", "", "return", "torch", ".", "arange", "(", "size", "[", "-", "1", "]", ",", "device", "=", "x", ".", "device", ")", ".", "expand", "(", "*", "size", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_tpu_device": [[644, 646], ["xm.xla_device"], "function", ["None"], ["", "def", "get_tpu_device", "(", ")", ":", "\n", "    ", "return", "xm", ".", "xla_device", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.tpu_data_loader": [[648, 659], ["xm.rendezvous", "xm.mark_step", "xm.xla_device", "fairseq.data.iterators.CountingIterator", "pl.ParallelLoader().per_device_loader", "getattr", "len", "pl.ParallelLoader"], "function", ["None"], ["", "def", "tpu_data_loader", "(", "itr", ")", ":", "\n", "    ", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "\n", "import", "torch_xla", ".", "distributed", ".", "parallel_loader", "as", "pl", "\n", "\n", "xm", ".", "rendezvous", "(", "\"tpu_data_loader\"", ")", "# wait for all workers", "\n", "xm", ".", "mark_step", "(", ")", "\n", "device", "=", "xm", ".", "xla_device", "(", ")", "\n", "return", "iterators", ".", "CountingIterator", "(", "\n", "pl", ".", "ParallelLoader", "(", "itr", ",", "[", "device", "]", ")", ".", "per_device_loader", "(", "device", ")", ",", "\n", "start", "=", "getattr", "(", "itr", ",", "\"n\"", ",", "0", ")", ",", "\n", "total", "=", "len", "(", "itr", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.csv_str_list": [[691, 693], ["x.split"], "function", ["None"], ["", "", "def", "csv_str_list", "(", "x", ")", ":", "\n", "    ", "return", "x", ".", "split", "(", "\",\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.eval_str_list": [[695, 704], ["isinstance", "eval", "list", "map", "type"], "function", ["None"], ["", "def", "eval_str_list", "(", "x", ",", "type", "=", "float", ")", ":", "\n", "    ", "if", "x", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "if", "isinstance", "(", "x", ",", "str", ")", ":", "\n", "        ", "x", "=", "eval", "(", "x", ")", "\n", "", "try", ":", "\n", "        ", "return", "list", "(", "map", "(", "type", ",", "x", ")", ")", "\n", "", "except", "TypeError", ":", "\n", "        ", "return", "[", "type", "(", "x", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.eval_str_dict": [[706, 712], ["isinstance", "eval"], "function", ["None"], ["", "", "def", "eval_str_dict", "(", "x", ",", "type", "=", "dict", ")", ":", "\n", "    ", "if", "x", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "if", "isinstance", "(", "x", ",", "str", ")", ":", "\n", "        ", "x", "=", "eval", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.eval_bool": [[714, 721], ["bool", "eval"], "function", ["None"], ["", "def", "eval_bool", "(", "x", ",", "default", "=", "False", ")", ":", "\n", "    ", "if", "x", "is", "None", ":", "\n", "        ", "return", "default", "\n", "", "try", ":", "\n", "        ", "return", "bool", "(", "eval", "(", "x", ")", ")", "\n", "", "except", "TypeError", ":", "\n", "        ", "return", "default", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.constants.StrEnum.__str__": [[11, 13], ["None"], "methods", ["None"], ["    ", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.constants.StrEnum.__eq__": [[14, 16], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ":", "str", ")", ":", "\n", "        ", "return", "self", ".", "value", "==", "other", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.constants.StrEnum.__repr__": [[17, 19], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.constants.StrEnum.__hash__": [[20, 22], ["hash", "str"], "methods", ["None"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "return", "hash", "(", "str", "(", "self", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.constants.ChoiceEnum": [[24, 27], ["constants.StrEnum"], "function", ["None"], ["", "", "def", "ChoiceEnum", "(", "choices", ":", "List", "[", "str", "]", ")", ":", "\n", "    ", "\"\"\"return the Enum class used to enforce list of choices\"\"\"", "\n", "return", "StrEnum", "(", "\"Choices\"", ",", "{", "k", ":", "k", "for", "k", "in", "choices", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.initialize.hydra_init": [[16, 28], ["hydra.core.config_store.ConfigStore.instance", "ConfigStore.instance.store", "ConfigStore.instance.store", "logger.error"], "function", ["None"], ["def", "hydra_init", "(", "cfg_name", "=", "\"config\"", ")", "->", "None", ":", "\n", "\n", "    ", "cs", "=", "ConfigStore", ".", "instance", "(", ")", "\n", "cs", ".", "store", "(", "name", "=", "cfg_name", ",", "node", "=", "FairseqConfig", ")", "\n", "\n", "for", "k", "in", "FairseqConfig", ".", "__dataclass_fields__", ":", "\n", "        ", "v", "=", "FairseqConfig", ".", "__dataclass_fields__", "[", "k", "]", ".", "default", "\n", "try", ":", "\n", "            ", "cs", ".", "store", "(", "name", "=", "k", ",", "node", "=", "v", ")", "\n", "", "except", "BaseException", ":", "\n", "            ", "logger", ".", "error", "(", "f\"{k} - {v}\"", ")", "\n", "raise", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.eval_str_list": [[25, 36], ["isinstance", "ast.literal_eval", "list", "len", "map", "x_type"], "function", ["None"], ["from", "torch", "import", "Tensor", "\n", "\n", "\n", "try", ":", "\n", "    ", "from", "amp_C", "import", "multi_tensor_l2norm", "\n", "\n", "multi_tensor_l2norm_available", "=", "True", "\n", "", "except", "ImportError", ":", "\n", "    ", "multi_tensor_l2norm_available", "=", "False", "\n", "\n", "", "try", ":", "\n", "    ", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.interpret_dc_type": [[38, 49], ["isinstance", "str", "re.match", "RuntimeError"], "function", ["None"], ["    ", "xm", "=", "None", "\n", "\n", "\n", "", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "\n", "MANIFOLD_PATH_SEP", "=", "\"|\"", "\n", "\n", "\n", "class", "FileContentsAction", "(", "argparse", ".", "Action", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "nargs", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "nargs", "is", "not", "None", ":", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.gen_parser_from_dataclass": [[51, 167], ["dataclass_instance._get_all_attributes", "dataclass_instance._get_type", "utils.interpret_dc_type", "dataclass_instance._get_default", "dataclass_instance._get_help", "dataclass_instance._get_argparse_const", "utils.gen_parser_from_dataclass.argparse_name"], "function", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.configs.FairseqDataclass._get_all_attributes", "home.repos.pwc.inspect_result.reneeye_const.dataclass.configs.FairseqDataclass._get_type", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.interpret_dc_type", "home.repos.pwc.inspect_result.reneeye_const.dataclass.configs.FairseqDataclass._get_default", "home.repos.pwc.inspect_result.reneeye_const.dataclass.configs.FairseqDataclass._get_help", "home.repos.pwc.inspect_result.reneeye_const.dataclass.configs.FairseqDataclass._get_argparse_const"], ["", "super", "(", "FileContentsAction", ",", "self", ")", ".", "__init__", "(", "option_strings", ",", "dest", ",", "**", "kwargs", ")", "\n", "\n", "", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "option_string", "=", "None", ")", ":", "\n", "        ", "if", "PathManager", ".", "isfile", "(", "values", ")", ":", "\n", "            ", "with", "PathManager", ".", "open", "(", "values", ")", "as", "f", ":", "\n", "                ", "argument", "=", "f", ".", "read", "(", ")", ".", "strip", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "argument", "=", "values", "\n", "", "setattr", "(", "namespace", ",", "self", ".", "dest", ",", "argument", ")", "\n", "\n", "\n", "", "", "def", "split_paths", "(", "paths", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "return", "(", "\n", "paths", ".", "split", "(", "os", ".", "pathsep", ")", "\n", "if", "\"://\"", "not", "in", "paths", "\n", "else", "paths", ".", "split", "(", "MANIFOLD_PATH_SEP", ")", "\n", ")", "\n", "\n", "\n", "", "def", "load_ensemble_for_inference", "(", "filenames", ",", "task", ",", "model_arg_overrides", "=", "None", ")", ":", "\n", "    ", "from", "fairseq", "import", "checkpoint_utils", "\n", "\n", "deprecation_warning", "(", "\n", "\"utils.load_ensemble_for_inference is deprecated. \"", "\n", "\"Please use checkpoint_utils.load_model_ensemble instead.\"", "\n", ")", "\n", "return", "checkpoint_utils", ".", "load_model_ensemble", "(", "\n", "filenames", ",", "arg_overrides", "=", "model_arg_overrides", ",", "task", "=", "task", "\n", ")", "\n", "\n", "\n", "", "def", "apply_to_sample", "(", "f", ",", "sample", ")", ":", "\n", "    ", "if", "hasattr", "(", "sample", ",", "\"__len__\"", ")", "and", "len", "(", "sample", ")", "==", "0", ":", "\n", "        ", "return", "{", "}", "\n", "\n", "", "def", "_apply", "(", "x", ")", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "x", ")", ":", "\n", "            ", "return", "f", "(", "x", ")", "\n", "", "elif", "isinstance", "(", "x", ",", "dict", ")", ":", "\n", "            ", "return", "{", "key", ":", "_apply", "(", "value", ")", "for", "key", ",", "value", "in", "x", ".", "items", "(", ")", "}", "\n", "", "elif", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "            ", "return", "[", "_apply", "(", "x", ")", "for", "x", "in", "x", "]", "\n", "", "elif", "isinstance", "(", "x", ",", "tuple", ")", ":", "\n", "            ", "return", "tuple", "(", "_apply", "(", "x", ")", "for", "x", "in", "x", ")", "\n", "", "elif", "isinstance", "(", "x", ",", "set", ")", ":", "\n", "            ", "return", "{", "_apply", "(", "x", ")", "for", "x", "in", "x", "}", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n", "", "", "return", "_apply", "(", "sample", ")", "\n", "\n", "\n", "", "def", "move_to_cuda", "(", "sample", ",", "device", "=", "None", ")", ":", "\n", "    ", "device", "=", "device", "or", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "\n", "def", "_move_to_cuda", "(", "tensor", ")", ":", "\n", "# non_blocking is ignored if tensor is not pinned, so we can always set", "\n", "# to True (see github.com/PyTorchLightning/pytorch-lightning/issues/620)", "\n", "        ", "return", "tensor", ".", "cuda", "(", "device", "=", "device", ",", "non_blocking", "=", "True", ")", "\n", "\n", "", "return", "apply_to_sample", "(", "_move_to_cuda", ",", "sample", ")", "\n", "\n", "\n", "", "def", "move_to_cpu", "(", "sample", ")", ":", "\n", "    ", "def", "_move_to_cpu", "(", "tensor", ")", ":", "\n", "# PyTorch has poor support for half tensors (float16) on CPU.", "\n", "# Move any such tensors to float32.", "\n", "        ", "if", "tensor", ".", "dtype", "in", "{", "torch", ".", "bfloat16", ",", "torch", ".", "float16", "}", ":", "\n", "            ", "tensor", "=", "tensor", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", "\n", "", "return", "tensor", ".", "cpu", "(", ")", "\n", "\n", "", "return", "apply_to_sample", "(", "_move_to_cpu", ",", "sample", ")", "\n", "\n", "\n", "", "def", "get_incremental_state", "(", "\n", "module", ":", "MultiheadAttention", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "key", ":", "str", ",", "\n", ")", "->", "Optional", "[", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ":", "\n", "    ", "\"\"\"Helper for getting incremental state for an nn.Module.\"\"\"", "\n", "return", "module", ".", "get_incremental_state", "(", "incremental_state", ",", "key", ")", "\n", "\n", "\n", "", "def", "set_incremental_state", "(", "\n", "module", ":", "MultiheadAttention", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "key", ":", "str", ",", "\n", "value", ":", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", ",", "\n", ")", "->", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ":", "\n", "    ", "\"\"\"Helper for setting incremental state for an nn.Module.\"\"\"", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "        ", "result", "=", "module", ".", "set_incremental_state", "(", "incremental_state", ",", "key", ",", "value", ")", "\n", "if", "result", "is", "not", "None", ":", "\n", "            ", "incremental_state", "=", "result", "\n", "", "", "return", "incremental_state", "\n", "\n", "\n", "", "def", "load_align_dict", "(", "replace_unk", ")", ":", "\n", "    ", "if", "replace_unk", "is", "None", ":", "\n", "        ", "align_dict", "=", "None", "\n", "", "elif", "isinstance", "(", "replace_unk", ",", "str", ")", "and", "len", "(", "replace_unk", ")", ">", "0", ":", "\n", "# Load alignment dictionary for unknown word replacement if it was passed as an argument.", "\n", "        ", "align_dict", "=", "{", "}", "\n", "with", "open", "(", "replace_unk", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "cols", "=", "line", ".", "split", "(", ")", "\n", "align_dict", "[", "cols", "[", "0", "]", "]", "=", "cols", "[", "1", "]", "\n", "", "", "", "else", ":", "\n", "# No alignment dictionary provided but we still want to perform unknown word replacement by copying the", "\n", "# original source word.", "\n", "        ", "align_dict", "=", "{", "}", "\n", "", "return", "align_dict", "\n", "\n", "\n", "", "def", "print_embed_overlap", "(", "embed_dict", ",", "vocab_dict", ")", ":", "\n", "    ", "embed_keys", "=", "set", "(", "embed_dict", ".", "keys", "(", ")", ")", "\n", "vocab_keys", "=", "set", "(", "vocab_dict", ".", "symbols", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils._set_legacy_defaults": [[169, 190], ["argparse.ArgumentParser", "cls.add_args", "argparse.Namespace", "vars().items", "hasattr", "vars", "hasattr", "setattr", "hasattr", "setattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args"], ["logger", ".", "info", "(", "\"found {}/{} types in embedding file\"", ".", "format", "(", "overlap", ",", "len", "(", "vocab_dict", ")", ")", ")", "\n", "\n", "\n", "", "def", "parse_embedding", "(", "embed_path", ")", ":", "\n", "    ", "\"\"\"Parse embedding text file into a dictionary of word and embedding tensors.\n\n    The first line can have vocabulary size and dimension. The following lines\n    should contain word and embedding separated by spaces.\n\n    Example:\n        2 5\n        the -0.0230 -0.0264  0.0287  0.0171  0.1403\n        at -0.0395 -0.1286  0.0275  0.0254 -0.0932\n    \"\"\"", "\n", "embed_dict", "=", "{", "}", "\n", "with", "open", "(", "embed_path", ")", "as", "f_embed", ":", "\n", "        ", "next", "(", "f_embed", ")", "# skip header", "\n", "for", "line", "in", "f_embed", ":", "\n", "            ", "pieces", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "embed_dict", "[", "pieces", "[", "0", "]", "]", "=", "torch", ".", "Tensor", "(", "\n", "[", "float", "(", "weight", ")", "for", "weight", "in", "pieces", "[", "1", ":", "]", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils._override_attr": [[192, 249], ["data_class.__dataclass_fields__.items", "k.startswith", "utils.interpret_dc_type", "isinstance", "inspect.isclass", "issubclass", "isinstance", "f.default_factory", "utils._override_attr.get_default", "fairseq.dataclass.configs.FairseqConfig.__dataclass_fields__[].type"], "function", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.interpret_dc_type"], ["\n", "\n", "", "def", "load_embedding", "(", "embed_dict", ",", "vocab", ",", "embedding", ")", ":", "\n", "    ", "for", "idx", "in", "range", "(", "len", "(", "vocab", ")", ")", ":", "\n", "        ", "token", "=", "vocab", "[", "idx", "]", "\n", "if", "token", "in", "embed_dict", ":", "\n", "            ", "embedding", ".", "weight", ".", "data", "[", "idx", "]", "=", "embed_dict", "[", "token", "]", "\n", "", "", "return", "embedding", "\n", "\n", "\n", "", "def", "replace_unk", "(", "hypo_str", ",", "src_str", ",", "alignment", ",", "align_dict", ",", "unk", ")", ":", "\n", "    ", "from", "fairseq", "import", "tokenizer", "\n", "\n", "# Tokens are strings here", "\n", "hypo_tokens", "=", "tokenizer", ".", "tokenize_line", "(", "hypo_str", ")", "\n", "# TODO: Very rare cases where the replacement is '<eos>' should be handled gracefully", "\n", "src_tokens", "=", "tokenizer", ".", "tokenize_line", "(", "src_str", ")", "+", "[", "\"<eos>\"", "]", "\n", "for", "i", ",", "ht", "in", "enumerate", "(", "hypo_tokens", ")", ":", "\n", "        ", "if", "ht", "==", "unk", ":", "\n", "            ", "src_token", "=", "src_tokens", "[", "alignment", "[", "i", "]", "]", "\n", "# Either take the corresponding value in the aligned dictionary or just copy the original value.", "\n", "hypo_tokens", "[", "i", "]", "=", "align_dict", ".", "get", "(", "src_token", ",", "src_token", ")", "\n", "", "", "return", "\" \"", ".", "join", "(", "hypo_tokens", ")", "\n", "\n", "\n", "", "def", "post_process_prediction", "(", "\n", "hypo_tokens", ",", "\n", "src_str", ",", "\n", "alignment", ",", "\n", "align_dict", ",", "\n", "tgt_dict", ",", "\n", "remove_bpe", "=", "None", ",", "\n", "extra_symbols_to_ignore", "=", "None", ",", "\n", ")", ":", "\n", "    ", "hypo_str", "=", "tgt_dict", ".", "string", "(", "\n", "hypo_tokens", ",", "remove_bpe", ",", "extra_symbols_to_ignore", "=", "extra_symbols_to_ignore", "\n", ")", "\n", "if", "align_dict", "is", "not", "None", ":", "\n", "        ", "hypo_str", "=", "replace_unk", "(", "\n", "hypo_str", ",", "src_str", ",", "alignment", ",", "align_dict", ",", "tgt_dict", ".", "unk_string", "(", ")", "\n", ")", "\n", "", "if", "align_dict", "is", "not", "None", "or", "remove_bpe", "is", "not", "None", ":", "\n", "# Convert back to tokens for evaluating with unk replacement or without BPE", "\n", "# Note that the dictionary can be modified inside the method.", "\n", "        ", "hypo_tokens", "=", "tgt_dict", ".", "encode_line", "(", "hypo_str", ",", "add_if_not_exist", "=", "True", ")", "\n", "", "return", "hypo_tokens", ",", "hypo_str", ",", "alignment", "\n", "\n", "\n", "", "def", "make_positions", "(", "tensor", ",", "padding_idx", ":", "int", ",", "onnx_trace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Replace non-padding symbols with their position numbers.\n\n    Position numbers begin at padding_idx+1. Padding symbols are ignored.\n    \"\"\"", "\n", "# The series of casts and type-conversions here are carefully", "\n", "# balanced to both work with ONNX export and XLA. In particular XLA", "\n", "# prefers ints, cumsum defaults to output longs, and ONNX doesn't know", "\n", "# how to handle the dtype kwarg in cumsum.", "\n", "mask", "=", "tensor", ".", "ne", "(", "padding_idx", ")", ".", "int", "(", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.migrate_registry": [[251, 262], ["overrides.append", "overrides.append", "overrides.extend", "utils._override_attr", "overrides.append", "deletes.append"], "function", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils._override_attr"], ["\n", "\n", "", "def", "strip_pad", "(", "tensor", ",", "pad", ")", ":", "\n", "    ", "return", "tensor", "[", "tensor", ".", "ne", "(", "pad", ")", "]", "\n", "\n", "\n", "", "def", "buffered_arange", "(", "max", ")", ":", "\n", "    ", "if", "not", "hasattr", "(", "buffered_arange", ",", "\"buf\"", ")", ":", "\n", "        ", "buffered_arange", ".", "buf", "=", "torch", ".", "LongTensor", "(", ")", "\n", "", "if", "max", ">", "buffered_arange", ".", "buf", ".", "numel", "(", ")", ":", "\n", "        ", "buffered_arange", ".", "buf", ".", "resize_", "(", "max", ")", "\n", "torch", ".", "arange", "(", "max", ",", "out", "=", "buffered_arange", ".", "buf", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.override_module_args": [[264, 322], ["fairseq.dataclass.configs.FairseqConfig.__dataclass_fields__.keys", "overrides.extend", "hasattr", "REGISTRIES.items", "hasattr", "utils._override_attr", "utils.migrate_registry", "deletes.append", "hasattr", "deletes.append", "utils.migrate_registry", "deletes.append", "getattr", "getattr", "overrides.append", "overrides.append", "overrides.extend", "utils._override_attr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils._override_attr", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.migrate_registry", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.migrate_registry", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils._override_attr"], ["\n", "\n", "", "def", "convert_padding_direction", "(", "\n", "src_tokens", ",", "padding_idx", ",", "right_to_left", ":", "bool", "=", "False", ",", "left_to_right", ":", "bool", "=", "False", "\n", ")", ":", "\n", "    ", "assert", "right_to_left", "^", "left_to_right", "\n", "pad_mask", "=", "src_tokens", ".", "eq", "(", "padding_idx", ")", "\n", "if", "not", "pad_mask", ".", "any", "(", ")", ":", "\n", "# no padding, return early", "\n", "        ", "return", "src_tokens", "\n", "", "if", "left_to_right", "and", "not", "pad_mask", "[", ":", ",", "0", "]", ".", "any", "(", ")", ":", "\n", "# already right padded", "\n", "        ", "return", "src_tokens", "\n", "", "if", "right_to_left", "and", "not", "pad_mask", "[", ":", ",", "-", "1", "]", ".", "any", "(", ")", ":", "\n", "# already left padded", "\n", "        ", "return", "src_tokens", "\n", "", "max_len", "=", "src_tokens", ".", "size", "(", "1", ")", "\n", "buffered", "=", "torch", ".", "empty", "(", "0", ")", ".", "long", "(", ")", "\n", "if", "max_len", ">", "0", ":", "\n", "        ", "torch", ".", "arange", "(", "max_len", ",", "out", "=", "buffered", ")", "\n", "", "range", "=", "buffered", ".", "type_as", "(", "src_tokens", ")", ".", "expand_as", "(", "src_tokens", ")", "\n", "num_pads", "=", "pad_mask", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "if", "right_to_left", ":", "\n", "        ", "index", "=", "torch", ".", "remainder", "(", "range", "-", "num_pads", ",", "max_len", ")", "\n", "", "else", ":", "\n", "        ", "index", "=", "torch", ".", "remainder", "(", "range", "+", "num_pads", ",", "max_len", ")", "\n", "", "return", "src_tokens", ".", "gather", "(", "1", ",", "index", ")", "\n", "\n", "\n", "", "def", "item", "(", "tensor", ")", ":", "\n", "    ", "if", "hasattr", "(", "tensor", ",", "\"item\"", ")", ":", "\n", "        ", "return", "tensor", ".", "item", "(", ")", "\n", "", "if", "hasattr", "(", "tensor", ",", "\"__getitem__\"", ")", ":", "\n", "        ", "return", "tensor", "[", "0", "]", "\n", "", "return", "tensor", "\n", "\n", "\n", "", "def", "multi_tensor_total_norm", "(", "grads", ",", "chunk_size", "=", "2048", "*", "32", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "per_device_grads", "=", "{", "}", "\n", "norms", "=", "[", "]", "\n", "for", "grad", "in", "grads", ":", "\n", "        ", "device", "=", "grad", ".", "device", "\n", "cur_device_grads", "=", "per_device_grads", ".", "get", "(", "device", ")", "\n", "if", "cur_device_grads", "is", "None", ":", "\n", "            ", "cur_device_grads", "=", "[", "]", "\n", "per_device_grads", "[", "device", "]", "=", "cur_device_grads", "\n", "", "cur_device_grads", ".", "append", "(", "grad", ")", "\n", "", "for", "device", "in", "per_device_grads", ".", "keys", "(", ")", ":", "\n", "        ", "cur_device_grads", "=", "per_device_grads", "[", "device", "]", "\n", "if", "device", ".", "type", "==", "\"cuda\"", ":", "\n", "# TODO(msb) return has_inf", "\n", "            ", "has_inf", "=", "torch", ".", "zeros", "(", "(", "1", ",", "1", ")", ",", "dtype", "=", "torch", ".", "int", ",", "device", "=", "device", ")", "\n", "with", "torch", ".", "cuda", ".", "device", "(", "device", ")", ":", "\n", "                ", "norm", "=", "multi_tensor_l2norm", "(", "\n", "chunk_size", ",", "has_inf", ",", "[", "cur_device_grads", "]", ",", "False", "\n", ")", "\n", "", "norms", ".", "append", "(", "norm", "[", "0", "]", ".", "to", "(", "torch", ".", "cuda", ".", "current_device", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "norms", "+=", "[", "torch", ".", "norm", "(", "g", ",", "p", "=", "2", ",", "dtype", "=", "torch", ".", "float32", ")", "for", "g", "in", "cur_device_grads", "]", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.convert_namespace_to_omegaconf": [[324, 390], ["utils.override_module_args", "os.path.join", "hydra.core.global_hydra.GlobalHydra.instance().clear", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.set_struct", "hydra.experimental.initialize", "omegaconf.OmegaConf.to_container", "getattr", "argparse.Namespace", "utils._set_legacy_defaults", "getattr", "argparse.Namespace", "utils._set_legacy_defaults", "getattr", "argparse.Namespace", "utils._set_legacy_defaults", "getattr", "argparse.Namespace", "utils._set_legacy_defaults", "getattr", "argparse.Namespace", "utils._set_legacy_defaults", "hydra.core.global_hydra.GlobalHydra.instance", "hydra.experimental.compose", "logger.error", "vars", "vars", "vars", "vars", "vars", "str"], "function", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.override_module_args", "home.repos.pwc.inspect_result.reneeye_const.fairseq.token_generation_constraints.OrderedConstraintState.create", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils._set_legacy_defaults", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils._set_legacy_defaults", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils._set_legacy_defaults", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils._set_legacy_defaults", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils._set_legacy_defaults"], ["return", "total_norm", "\n", "\n", "\n", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "clip_grad_norm_", "(", "params", ",", "max_norm", ",", "aggregate_norm_fn", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "if", "isinstance", "(", "params", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "params", "=", "[", "params", "]", "\n", "", "params", "=", "list", "(", "params", ")", "\n", "grads", "=", "[", "p", ".", "grad", ".", "detach", "(", ")", "for", "p", "in", "filter", "(", "lambda", "p", ":", "p", ".", "grad", "is", "not", "None", ",", "params", ")", "]", "\n", "if", "len", "(", "grads", ")", "==", "0", ":", "\n", "        ", "if", "len", "(", "params", ")", ">", "0", ":", "\n", "            ", "return", "params", "[", "0", "]", ".", "new_tensor", "(", "0.0", ")", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "tensor", "(", "0.0", ")", "\n", "\n", "", "", "if", "len", "(", "grads", ")", "==", "1", ":", "\n", "        ", "total_norm", "=", "torch", ".", "norm", "(", "grads", "[", "0", "]", ",", "p", "=", "2", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "", "else", ":", "\n", "        ", "if", "multi_tensor_l2norm_available", ":", "\n", "            ", "total_norm", "=", "multi_tensor_total_norm", "(", "grads", ")", "\n", "", "else", ":", "\n", "            ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "warnings", ".", "warn", "(", "\n", "\"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"", "\n", "\"you may get better performance by installing NVIDIA's apex library\"", "\n", ")", "\n", "device", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "", "elif", "grads", "[", "0", "]", ".", "device", ".", "type", "==", "\"xla\"", ":", "\n", "                ", "device", "=", "grads", "[", "0", "]", ".", "device", "\n", "", "else", ":", "\n", "                ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "", "total_norm", "=", "torch", ".", "norm", "(", "\n", "torch", ".", "stack", "(", "\n", "[", "torch", ".", "norm", "(", "g", ",", "p", "=", "2", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "to", "(", "device", ")", "for", "g", "in", "grads", "]", "\n", ")", "\n", ")", "\n", "\n", "", "", "if", "aggregate_norm_fn", "is", "not", "None", ":", "\n", "        ", "total_norm", "=", "aggregate_norm_fn", "(", "total_norm", ")", "\n", "\n", "", "if", "max_norm", ">", "0", ":", "\n", "        ", "max_norm", "=", "float", "(", "max_norm", ")", "\n", "clip_coef", "=", "(", "max_norm", "/", "(", "total_norm", "+", "1e-6", ")", ")", ".", "clamp_", "(", "max", "=", "1", ")", "\n", "for", "g", "in", "grads", ":", "\n", "            ", "g", ".", "mul_", "(", "clip_coef", ")", "\n", "", "", "return", "total_norm", "\n", "\n", "\n", "", "def", "fill_with_neg_inf", "(", "t", ")", ":", "\n", "    ", "\"\"\"FP16-compatible function that fills a tensor with -inf.\"\"\"", "\n", "return", "t", ".", "float", "(", ")", ".", "fill_", "(", "float", "(", "\"-inf\"", ")", ")", ".", "type_as", "(", "t", ")", "\n", "\n", "\n", "", "def", "_match_types", "(", "arg1", ",", "arg2", ")", ":", "\n", "    ", "\"\"\"Convert the numerical argument to the same type as the other argument\"\"\"", "\n", "\n", "def", "upgrade", "(", "arg_number", ",", "arg_structure", ")", ":", "\n", "        ", "if", "isinstance", "(", "arg_structure", ",", "tuple", ")", ":", "\n", "            ", "return", "tuple", "(", "[", "arg_number", "]", "*", "len", "(", "arg_structure", ")", ")", "\n", "", "elif", "isinstance", "(", "arg_structure", ",", "dict", ")", ":", "\n", "            ", "arg", "=", "copy", ".", "deepcopy", "(", "arg_structure", ")", "\n", "for", "k", "in", "arg", ":", "\n", "                ", "arg", "[", "k", "]", "=", "upgrade", "(", "arg_number", ",", "arg_structure", "[", "k", "]", ")", "\n", "", "return", "arg", "\n", "", "else", ":", "\n", "            ", "return", "arg_number", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.populate_dataclass": [[392, 404], ["dataclass.__dataclass_fields__.keys", "k.startswith", "hasattr", "setattr", "getattr"], "function", ["None"], ["        ", "return", "upgrade", "(", "arg1", ",", "arg2", ")", ",", "arg2", "\n", "", "elif", "isinstance", "(", "arg2", ",", "float", ")", "or", "isinstance", "(", "arg2", ",", "int", ")", ":", "\n", "        ", "return", "arg1", ",", "upgrade", "(", "arg2", ",", "arg1", ")", "\n", "\n", "", "return", "arg1", ",", "arg2", "\n", "\n", "\n", "", "def", "resolve_max_positions", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"Resolve max position constraints from multiple sources.\"\"\"", "\n", "\n", "def", "map_value_update", "(", "d1", ",", "d2", ")", ":", "\n", "        ", "updated_value", "=", "copy", ".", "deepcopy", "(", "d1", ")", "\n", "for", "key", "in", "d2", ":", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.overwrite_args_by_name": [[406, 431], ["omegaconf.open_dict", "cfg.keys", "isinstance", "utils.overwrite_args_by_name", "isinstance", "overrides.items", "setattr", "omegaconf.DictConfig", "utils.overwrite_args_by_name"], "function", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.overwrite_args_by_name", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.overwrite_args_by_name"], ["                ", "updated_value", "[", "key", "]", "=", "d2", "[", "key", "]", "\n", "", "else", ":", "\n", "                ", "updated_value", "[", "key", "]", "=", "min", "(", "d1", "[", "key", "]", ",", "d2", "[", "key", "]", ")", "\n", "", "", "return", "updated_value", "\n", "\n", "", "def", "nullsafe_min", "(", "l", ")", ":", "\n", "        ", "minim", "=", "None", "\n", "for", "item", "in", "l", ":", "\n", "            ", "if", "minim", "is", "None", ":", "\n", "                ", "minim", "=", "item", "\n", "", "elif", "item", "is", "not", "None", "and", "item", "<", "minim", ":", "\n", "                ", "minim", "=", "item", "\n", "", "", "return", "minim", "\n", "\n", "", "max_positions", "=", "None", "\n", "for", "arg", "in", "args", ":", "\n", "        ", "if", "max_positions", "is", "None", ":", "\n", "            ", "max_positions", "=", "arg", "\n", "", "elif", "arg", "is", "not", "None", ":", "\n", "            ", "max_positions", ",", "arg", "=", "_match_types", "(", "max_positions", ",", "arg", ")", "\n", "if", "isinstance", "(", "arg", ",", "float", ")", "or", "isinstance", "(", "arg", ",", "int", ")", ":", "\n", "                ", "max_positions", "=", "min", "(", "max_positions", ",", "arg", ")", "\n", "", "elif", "isinstance", "(", "arg", ",", "dict", ")", ":", "\n", "                ", "max_positions", "=", "map_value_update", "(", "max_positions", ",", "arg", ")", "\n", "", "else", ":", "\n", "                ", "max_positions", "=", "tuple", "(", "map", "(", "nullsafe_min", ",", "zip", "(", "max_positions", ",", "arg", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.merge_with_parent": [[433, 439], ["omegaconf.DictConfig", "omegaconf.OmegaConf.merge", "omegaconf.OmegaConf.set_struct"], "function", ["None"], ["", "", "", "return", "max_positions", "\n", "\n", "\n", "", "def", "import_user_module", "(", "args", ")", ":", "\n", "    ", "module_path", "=", "getattr", "(", "args", ",", "\"user_dir\"", ",", "None", ")", "\n", "if", "module_path", "is", "not", "None", ":", "\n", "        ", "module_path", "=", "os", ".", "path", ".", "abspath", "(", "args", ".", "user_dir", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.configs.FairseqDataclass.name": [[32, 35], ["None"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "name", "(", ")", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.configs.FairseqDataclass._get_all_attributes": [[36, 38], ["configs.FairseqDataclass.__dataclass_fields__.keys"], "methods", ["None"], ["", "def", "_get_all_attributes", "(", "self", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "return", "[", "k", "for", "k", "in", "self", ".", "__dataclass_fields__", ".", "keys", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.configs.FairseqDataclass._get_meta": [[39, 43], ["configs.FairseqDataclass.__dataclass_fields__[].metadata.get"], "methods", ["None"], ["", "def", "_get_meta", "(", "\n", "self", ",", "attribute_name", ":", "str", ",", "meta", ":", "str", ",", "default", ":", "Optional", "[", "Any", "]", "=", "None", "\n", ")", "->", "Any", ":", "\n", "        ", "return", "self", ".", "__dataclass_fields__", "[", "attribute_name", "]", ".", "metadata", ".", "get", "(", "meta", ",", "default", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.configs.FairseqDataclass._get_name": [[44, 46], ["None"], "methods", ["None"], ["", "def", "_get_name", "(", "self", ",", "attribute_name", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "__dataclass_fields__", "[", "attribute_name", "]", ".", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.configs.FairseqDataclass._get_default": [[47, 65], ["hasattr", "str().startswith", "isinstance", "f.default_factory", "str", "str().startswith", "str", "getattr", "str", "getattr", "str", "getattr", "getattr"], "methods", ["None"], ["", "def", "_get_default", "(", "self", ",", "attribute_name", ":", "str", ")", "->", "Any", ":", "\n", "        ", "if", "hasattr", "(", "self", ",", "attribute_name", ")", ":", "\n", "            ", "if", "str", "(", "getattr", "(", "self", ",", "attribute_name", ")", ")", ".", "startswith", "(", "\"${\"", ")", ":", "\n", "                ", "return", "str", "(", "getattr", "(", "self", ",", "attribute_name", ")", ")", "\n", "", "elif", "str", "(", "self", ".", "__dataclass_fields__", "[", "attribute_name", "]", ".", "default", ")", ".", "startswith", "(", "\n", "\"${\"", "\n", ")", ":", "\n", "                ", "return", "str", "(", "self", ".", "__dataclass_fields__", "[", "attribute_name", "]", ".", "default", ")", "\n", "", "elif", "(", "\n", "getattr", "(", "self", ",", "attribute_name", ")", "\n", "!=", "self", ".", "__dataclass_fields__", "[", "attribute_name", "]", ".", "default", "\n", ")", ":", "\n", "                ", "return", "getattr", "(", "self", ",", "attribute_name", ")", "\n", "\n", "", "", "f", "=", "self", ".", "__dataclass_fields__", "[", "attribute_name", "]", "\n", "if", "not", "isinstance", "(", "f", ".", "default_factory", ",", "_MISSING_TYPE", ")", ":", "\n", "            ", "return", "f", ".", "default_factory", "(", ")", "\n", "", "return", "f", ".", "default", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.configs.FairseqDataclass._get_type": [[66, 68], ["None"], "methods", ["None"], ["", "def", "_get_type", "(", "self", ",", "attribute_name", ":", "str", ")", "->", "Any", ":", "\n", "        ", "return", "self", ".", "__dataclass_fields__", "[", "attribute_name", "]", ".", "type", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.configs.FairseqDataclass._get_help": [[69, 71], ["configs.FairseqDataclass._get_meta"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary._get_meta"], ["", "def", "_get_help", "(", "self", ",", "attribute_name", ":", "str", ")", "->", "Any", ":", "\n", "        ", "return", "self", ".", "_get_meta", "(", "attribute_name", ",", "\"help\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.configs.FairseqDataclass._get_argparse_const": [[72, 74], ["configs.FairseqDataclass._get_meta"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary._get_meta"], ["", "def", "_get_argparse_const", "(", "self", ",", "attribute_name", ":", "str", ")", "->", "Any", ":", "\n", "        ", "return", "self", ".", "_get_meta", "(", "attribute_name", ",", "\"argparse_const\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.configs.FairseqDataclass._get_argparse_alias": [[75, 77], ["configs.FairseqDataclass._get_meta"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary._get_meta"], ["", "def", "_get_argparse_alias", "(", "self", ",", "attribute_name", ":", "str", ")", "->", "Any", ":", "\n", "        ", "return", "self", ".", "_get_meta", "(", "attribute_name", ",", "\"argparse_alias\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dataclass.configs.FairseqDataclass._get_choices": [[78, 80], ["configs.FairseqDataclass._get_meta"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary._get_meta"], ["", "def", "_get_choices", "(", "self", ",", "attribute_name", ":", "str", ")", "->", "Any", ":", "\n", "        ", "return", "self", ".", "_get_meta", "(", "attribute_name", ",", "\"choices\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adamax.FairseqAdamax.__init__": [[14, 17], ["LegacyFairseqOptimizer.__init__", "adamax.Adamax"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "_optimizer", "=", "Adamax", "(", "params", ",", "**", "self", ".", "optimizer_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adamax.FairseqAdamax.add_args": [[18, 30], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add optimizer-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--adamax-betas'", ",", "default", "=", "'(0.9, 0.999)'", ",", "metavar", "=", "'B'", ",", "\n", "help", "=", "'betas for Adam optimizer'", ")", "\n", "parser", ".", "add_argument", "(", "'--adamax-eps'", ",", "type", "=", "float", ",", "default", "=", "1e-8", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'epsilon for Adam optimizer'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight-decay'", ",", "'--wd'", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "metavar", "=", "'WD'", ",", "\n", "help", "=", "'weight decay'", ")", "\n", "parser", ".", "add_argument", "(", "'--no-bias-correction'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'disable bias correction'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adamax.FairseqAdamax.optimizer_config": [[32, 46], ["eval"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a kwarg dictionary that will be used to override optimizer\n        args stored in checkpoints. This allows us to load a checkpoint and\n        resume training using a different set of optimizer args, e.g., with a\n        different learning rate.\n        \"\"\"", "\n", "return", "{", "\n", "\"lr\"", ":", "self", ".", "args", ".", "lr", "[", "0", "]", ",", "\n", "\"betas\"", ":", "eval", "(", "self", ".", "args", ".", "adamax_betas", ")", ",", "\n", "\"eps\"", ":", "self", ".", "args", ".", "adamax_eps", ",", "\n", "\"weight_decay\"", ":", "self", ".", "args", ".", "weight_decay", ",", "\n", "\"bias_correction\"", ":", "not", "self", ".", "args", ".", "no_bias_correction", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adamax.Adamax.__init__": [[70, 98], ["dict", "super().__init__", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "params", ",", "\n", "lr", "=", "2e-3", ",", "\n", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "\n", "eps", "=", "1e-8", ",", "\n", "weight_decay", "=", "0", ",", "\n", "bias_correction", "=", "True", ",", "\n", ")", ":", "\n", "        ", "if", "not", "0.0", "<=", "lr", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {}\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "not", "0.0", "<=", "eps", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {}\"", ".", "format", "(", "eps", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "0", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter at index 0: {}\"", ".", "format", "(", "betas", "[", "0", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "1", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter at index 1: {}\"", ".", "format", "(", "betas", "[", "1", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "weight_decay", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid weight_decay value: {}\"", ".", "format", "(", "weight_decay", ")", ")", "\n", "\n", "", "defaults", "=", "dict", "(", "\n", "lr", "=", "lr", ",", "\n", "betas", "=", "betas", ",", "\n", "eps", "=", "eps", ",", "\n", "weight_decay", "=", "weight_decay", ",", "\n", "bias_correction", "=", "bias_correction", ",", "\n", ")", "\n", "super", "(", "Adamax", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adamax.Adamax.supports_memory_efficient_fp16": [[99, 102], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_memory_efficient_fp16", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adamax.Adamax.supports_flat_params": [[103, 106], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_flat_params", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adamax.Adamax.step": [[107, 173], ["closure", "p.grad.data.float", "exp_avg.mul_().add_", "torch.max", "torch.max", "torch.max", "torch.max", "p_data_fp32.float.float.addcdiv_", "RuntimeError", "p_data_fp32.float.float.float", "len", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "state[].to", "state[].to", "exp_inf.mul_", "p.grad.data.float.abs_", "p_data_fp32.float.float.add_", "exp_inf.add", "p.data.copy_", "exp_avg.mul_"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "\"params\"", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", ".", "float", "(", ")", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\"Adamax does not support sparse gradients\"", ")", "\n", "\n", "", "p_data_fp32", "=", "p", ".", "data", "\n", "if", "p", ".", "data", ".", "dtype", "in", "{", "torch", ".", "float16", ",", "torch", ".", "bfloat16", "}", ":", "\n", "                    ", "p_data_fp32", "=", "p_data_fp32", ".", "float", "(", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "\"step\"", "]", "=", "0", "\n", "state", "[", "\"exp_avg\"", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "state", "[", "\"exp_inf\"", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "", "else", ":", "\n", "                    ", "state", "[", "\"exp_avg\"", "]", "=", "state", "[", "\"exp_avg\"", "]", ".", "to", "(", "p_data_fp32", ")", "\n", "state", "[", "\"exp_inf\"", "]", "=", "state", "[", "\"exp_inf\"", "]", ".", "to", "(", "p_data_fp32", ")", "\n", "\n", "", "exp_avg", ",", "exp_inf", "=", "state", "[", "\"exp_avg\"", "]", ",", "state", "[", "\"exp_inf\"", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "\"betas\"", "]", "\n", "eps", "=", "group", "[", "\"eps\"", "]", "\n", "\n", "state", "[", "\"step\"", "]", "+=", "1", "\n", "\n", "# Update biased first moment estimate.", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "grad", ",", "alpha", "=", "1", "-", "beta1", ")", "\n", "\n", "# Update the exponentially weighted infinity norm.", "\n", "torch", ".", "max", "(", "\n", "exp_inf", ".", "mul_", "(", "beta2", ")", ",", "\n", "grad", ".", "abs_", "(", ")", ",", "\n", "out", "=", "exp_inf", ",", "\n", ")", "\n", "\n", "step_size", "=", "group", "[", "\"lr\"", "]", "\n", "if", "group", "[", "\"bias_correction\"", "]", ":", "\n", "                    ", "bias_correction", "=", "1", "-", "beta1", "**", "state", "[", "\"step\"", "]", "\n", "step_size", "/=", "bias_correction", "\n", "\n", "", "if", "group", "[", "\"weight_decay\"", "]", "!=", "0", ":", "\n", "                    ", "p_data_fp32", ".", "add_", "(", "\n", "p_data_fp32", ",", "alpha", "=", "-", "group", "[", "\"weight_decay\"", "]", "*", "group", "[", "\"lr\"", "]", "\n", ")", "\n", "\n", "", "p_data_fp32", ".", "addcdiv_", "(", "exp_avg", ",", "exp_inf", ".", "add", "(", "eps", ")", ",", "value", "=", "-", "step_size", ")", "\n", "\n", "if", "p", ".", "data", ".", "dtype", "in", "{", "torch", ".", "float16", ",", "torch", ".", "bfloat16", "}", ":", "\n", "                    ", "p", ".", "data", ".", "copy_", "(", "p_data_fp32", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.optim.adagrad.Adagrad.__init__": [[13, 16], ["LegacyFairseqOptimizer.__init__", "torch.optim.Adagrad"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "_optimizer", "=", "torch", ".", "optim", ".", "Adagrad", "(", "params", ",", "**", "self", ".", "optimizer_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adagrad.Adagrad.add_args": [[17, 23], ["parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add optimizer-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--weight-decay'", ",", "'--wd'", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "metavar", "=", "'WD'", ",", "\n", "help", "=", "'weight decay'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adagrad.Adagrad.optimizer_config": [[25, 36], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a kwarg dictionary that will be used to override optimizer\n        args stored in checkpoints. This allows us to load a checkpoint and\n        resume training using a different set of optimizer args, e.g., with a\n        different learning rate.\n        \"\"\"", "\n", "return", "{", "\n", "\"lr\"", ":", "self", ".", "args", ".", "lr", "[", "0", "]", ",", "\n", "\"weight_decay\"", ":", "self", ".", "args", ".", "weight_decay", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adagrad.Adagrad.supports_flat_params": [[38, 41], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_flat_params", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.__init__": [[12, 15], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.add_args": [[16, 22], ["getattr", "fairseq.dataclass.utils.gen_parser_from_dataclass", "getattr."], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.gen_parser_from_dataclass"], ["", "@", "classmethod", "\n", "def", "add_args", "(", "cls", ",", "parser", ")", ":", "\n", "        ", "\"\"\"Add optimizer-specific arguments to the parser.\"\"\"", "\n", "dc", "=", "getattr", "(", "cls", ",", "\"__dataclass\"", ",", "None", ")", "\n", "if", "dc", "is", "not", "None", ":", "\n", "            ", "gen_parser_from_dataclass", "(", "parser", ",", "dc", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.optimizer": [[32, 40], ["hasattr", "isinstance", "ValueError"], "methods", ["None"], ["", "@", "optimizer", ".", "setter", "\n", "def", "optimizer", "(", "self", ",", "optimizer", ")", ":", "\n", "        ", "\"\"\"Reset optimizer instance.\"\"\"", "\n", "if", "not", "hasattr", "(", "self", ",", "\"_optimizer\"", ")", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "if", "not", "isinstance", "(", "self", ".", "_optimizer", ",", "torch", ".", "optim", ".", "Optimizer", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"_optimizer must be an instance of torch.optim.Optimizer\"", ")", "\n", "", "self", ".", "_optimizer", "=", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.optimizer_config": [[41, 50], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a kwarg dictionary that will be used to override optimizer\n        args stored in checkpoints. This allows us to load a checkpoint and\n        resume training using a different set of optimizer args, e.g., with a\n        different learning rate.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.params": [[51, 57], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "params", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return an iterable of the parameters held by the optimizer.\"\"\"", "\n", "for", "param_group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "param_group", "[", "\"params\"", "]", ":", "\n", "                ", "yield", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.param_groups": [[58, 61], ["None"], "methods", ["None"], ["", "", "", "@", "property", "\n", "def", "param_groups", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "optimizer", ".", "param_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.__getstate__": [[62, 64], ["fairseq_optimizer.FairseqOptimizer._optimizer.__getstate__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.plasma_utils.PlasmaArray.__getstate__"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_optimizer", ".", "__getstate__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.get_lr": [[65, 68], ["None"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the current learning rate.\"\"\"", "\n", "return", "self", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.set_lr": [[69, 73], ["None"], "methods", ["None"], ["", "def", "set_lr", "(", "self", ",", "lr", ")", ":", "\n", "        ", "\"\"\"Set the learning rate.\"\"\"", "\n", "for", "param_group", "in", "self", ".", "param_groups", ":", "\n", "            ", "param_group", "[", "\"lr\"", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.state_dict": [[74, 77], ["fairseq_optimizer.FairseqOptimizer.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.state_dict"], ["", "", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the optimizer's state dict.\"\"\"", "\n", "return", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.load_state_dict": [[78, 92], ["fairseq_optimizer.FairseqOptimizer.optimizer.load_state_dict", "len", "group.update"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "optimizer_overrides", "=", "None", ")", ":", "\n", "        ", "\"\"\"Load an optimizer state dict.\n\n        In general we should prefer the configuration of the existing optimizer\n        instance (e.g., learning rate) over that found in the state_dict. This\n        allows us to resume training from a checkpoint using a new set of\n        optimizer args.\n        \"\"\"", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n", "if", "optimizer_overrides", "is", "not", "None", "and", "len", "(", "optimizer_overrides", ")", ">", "0", ":", "\n", "# override learning rate, momentum, etc. with latest values", "\n", "            ", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "                ", "group", ".", "update", "(", "optimizer_overrides", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.backward": [[93, 96], ["loss.backward"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward"], ["", "", "", "def", "backward", "(", "self", ",", "loss", ")", ":", "\n", "        ", "\"\"\"Computes the sum of gradients of the given tensor w.r.t. graph leaves.\"\"\"", "\n", "loss", ".", "backward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.all_reduce_grads": [[97, 101], ["hasattr", "module.all_reduce_grads"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.distributed_fairseq_model.TPUDistributedDataParallel.all_reduce_grads"], ["", "def", "all_reduce_grads", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\"Manually all-reduce gradients (if required).\"\"\"", "\n", "if", "hasattr", "(", "module", ",", "\"all_reduce_grads\"", ")", ":", "\n", "            ", "module", ".", "all_reduce_grads", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.multiply_grads": [[102, 107], ["p.grad.data.mul_"], "methods", ["None"], ["", "", "def", "multiply_grads", "(", "self", ",", "c", ")", ":", "\n", "        ", "\"\"\"Multiplies grads by a constant *c*.\"\"\"", "\n", "for", "p", "in", "self", ".", "params", ":", "\n", "            ", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                ", "p", ".", "grad", ".", "data", ".", "mul_", "(", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.clip_grad_norm": [[108, 111], ["fairseq.utils.clip_grad_norm_"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.clip_grad_norm_"], ["", "", "", "def", "clip_grad_norm", "(", "self", ",", "max_norm", ",", "aggregate_norm_fn", "=", "None", ")", ":", "\n", "        ", "\"\"\"Clips gradient norm.\"\"\"", "\n", "return", "utils", ".", "clip_grad_norm_", "(", "self", ".", "params", ",", "max_norm", ",", "aggregate_norm_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.step": [[112, 120], ["fairseq_optimizer.FairseqOptimizer.optimizer.step", "fairseq_optimizer.FairseqOptimizer.optimizer.step", "fairseq_optimizer.FairseqOptimizer.multiply_grads"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step", "home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.multiply_grads"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ",", "scale", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\"\"\"", "\n", "if", "self", ".", "supports_step_with_scale", ":", "\n", "            ", "self", ".", "optimizer", ".", "step", "(", "closure", ",", "scale", "=", "scale", ")", "\n", "", "else", ":", "\n", "            ", "if", "scale", "!=", "1.0", ":", "\n", "                ", "self", ".", "multiply_grads", "(", "1.0", "/", "scale", ")", "\n", "", "self", ".", "optimizer", ".", "step", "(", "closure", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.zero_grad": [[121, 126], ["fairseq_optimizer.FairseqOptimizer.optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad"], ["", "", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\"Clears the gradients of all optimized parameters.\"\"\"", "\n", "for", "p", "in", "self", ".", "params", ":", "\n", "            ", "p", ".", "grad", "=", "None", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.supports_memory_efficient_fp16": [[127, 132], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_memory_efficient_fp16", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "optimizer", ",", "\"supports_memory_efficient_fp16\"", ")", ":", "\n", "            ", "return", "self", ".", "optimizer", ".", "supports_memory_efficient_fp16", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.supports_step_with_scale": [[133, 138], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_step_with_scale", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "optimizer", ",", "\"supports_step_with_scale\"", ")", ":", "\n", "            ", "return", "self", ".", "optimizer", ".", "supports_step_with_scale", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.supports_flat_params": [[139, 148], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_flat_params", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Whether the optimizer supports collapsing of the model\n        parameters/gradients into a single contiguous Tensor.\n        \"\"\"", "\n", "if", "hasattr", "(", "self", ".", "optimizer", ",", "\"supports_flat_params\"", ")", ":", "\n", "            ", "return", "self", ".", "optimizer", ".", "supports_flat_params", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.average_params": [[149, 151], ["None"], "methods", ["None"], ["", "def", "average_params", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.broadcast_global_state_dict": [[152, 161], ["hasattr", "fairseq_optimizer.FairseqOptimizer.optimizer.broadcast_global_state_dict"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.FairseqOptimizer.broadcast_global_state_dict"], ["", "def", "broadcast_global_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"\n        Broadcasts a global state dict to all ranks.\n        Useful for optimizers that shard state between ranks.\n        \"\"\"", "\n", "if", "hasattr", "(", "self", ".", "optimizer", ",", "\"broadcast_global_state_dict\"", ")", ":", "\n", "            ", "return", "self", ".", "optimizer", ".", "broadcast_global_state_dict", "(", "state_dict", ")", "\n", "", "else", ":", "\n", "            ", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fairseq_optimizer.LegacyFairseqOptimizer.__init__": [[164, 166], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.optim.adadelta.Adadelta.__init__": [[13, 16], ["LegacyFairseqOptimizer.__init__", "torch.optim.Adadelta"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "_optimizer", "=", "torch", ".", "optim", ".", "Adadelta", "(", "params", ",", "**", "self", ".", "optimizer_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adadelta.Adadelta.add_args": [[17, 28], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add optimizer-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--adadelta-rho'", ",", "type", "=", "float", ",", "default", "=", "0.9", ",", "metavar", "=", "'RHO'", ",", "\n", "help", "=", "'coefficient used for computing a running average of squared gradients'", ")", "\n", "parser", ".", "add_argument", "(", "'--adadelta-eps'", ",", "type", "=", "float", ",", "default", "=", "1e-6", ",", "metavar", "=", "'EPS'", ",", "\n", "help", "=", "'term added to the denominator to improve numerical stability'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight-decay'", ",", "'--wd'", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "metavar", "=", "'WD'", ",", "\n", "help", "=", "'weight decay'", ")", "\n", "parser", ".", "add_argument", "(", "'--anneal-eps'", ",", "action", "=", "'store_true'", ",", "help", "=", "'flag to anneal eps'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adadelta.Adadelta.optimizer_config": [[30, 43], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a kwarg dictionary that will be used to override optimizer\n        args stored in checkpoints. This allows us to load a checkpoint and\n        resume training using a different set of optimizer args, e.g., with a\n        different learning rate.\n        \"\"\"", "\n", "return", "{", "\n", "\"lr\"", ":", "self", ".", "args", ".", "lr", "[", "0", "]", ",", "\n", "\"rho\"", ":", "self", ".", "args", ".", "adadelta_rho", ",", "\n", "\"eps\"", ":", "self", ".", "args", ".", "adadelta_eps", ",", "\n", "\"weight_decay\"", ":", "self", ".", "args", ".", "weight_decay", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adadelta.Adadelta.supports_flat_params": [[45, 48], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_flat_params", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.__init__": [[25, 38], ["fairseq.optim.fairseq_optimizer.FairseqOptimizer.__init__", "bmuf.FairseqBMUF._reset_local_data", "bmuf.FairseqBMUF._optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF._reset_local_data", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.state_dict"], ["def", "__init__", "(", "self", ",", "cfg", ":", "FairseqBMUFConfig", ",", "optimizer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ")", "\n", "self", ".", "_optimizer", "=", "optimizer", "\n", "self", ".", "_num_updates", "=", "0", "\n", "self", ".", "sync_iter", "=", "cfg", ".", "global_sync_iter", "\n", "self", ".", "block_momentum", "=", "cfg", ".", "block_momentum", "\n", "self", ".", "block_lr", "=", "cfg", ".", "block_lr", "\n", "self", ".", "_reset_local_data", "(", ")", "\n", "self", ".", "warmup_iteration", "=", "cfg", ".", "warmup_iterations", "\n", "self", ".", "use_nbm", "=", "cfg", ".", "use_nbm", "\n", "self", ".", "initial_state", "=", "self", ".", "_optimizer", ".", "state_dict", "(", ")", "\n", "self", ".", "average_sync", "=", "self", ".", "cfg", ".", "average_sync", "\n", "self", ".", "world_size", "=", "self", ".", "cfg", ".", "distributed_world_size", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.add_args": [[39, 43], ["fairseq.dataclass.utils.gen_parser_from_dataclass", "fairseq.dataclass.configs.FairseqBMUFConfig"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.gen_parser_from_dataclass"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add optimizer-specific arguments to the parser.\"\"\"", "\n", "gen_parser_from_dataclass", "(", "parser", ",", "FairseqBMUFConfig", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.optimizer": [[44, 47], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_optimizer", ".", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.optimizer_config": [[48, 51], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_optimizer", ".", "optimizer_config", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.get_lr": [[52, 54], ["bmuf.FairseqBMUF._optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.set_lr": [[55, 57], ["bmuf.FairseqBMUF._optimizer.set_lr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["", "def", "set_lr", "(", "self", ",", "lr", ")", ":", "\n", "        ", "self", ".", "_optimizer", ".", "set_lr", "(", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.state_dict": [[58, 60], ["bmuf.FairseqBMUF._optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_optimizer", ".", "state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.load_state_dict": [[61, 64], ["bmuf.FairseqBMUF._optimizer.load_state_dict", "bmuf.FairseqBMUF._optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "optimizer_overrides", "=", "None", ")", ":", "\n", "        ", "self", ".", "_optimizer", ".", "load_state_dict", "(", "state_dict", ",", "optimizer_overrides", ")", "\n", "self", ".", "initial_state", "=", "self", ".", "_optimizer", ".", "state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.multiply_grads": [[65, 68], ["bmuf.FairseqBMUF._optimizer.multiply_grads"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.multiply_grads"], ["", "def", "multiply_grads", "(", "self", ",", "c", ")", ":", "\n", "        ", "\"\"\"Multiplies grads by a constant *c*.\"\"\"", "\n", "self", ".", "_optimizer", ".", "multiply_grads", "(", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.clip_grad_norm": [[69, 72], ["bmuf.FairseqBMUF._optimizer.clip_grad_norm"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.model_parallel.megatron_trainer.MegatronTrainer.clip_grad_norm"], ["", "def", "clip_grad_norm", "(", "self", ",", "max_norm", ",", "aggregate_norm_fn", "=", "None", ")", ":", "\n", "        ", "\"\"\"Clips gradient norm.\"\"\"", "\n", "return", "self", ".", "_optimizer", ".", "clip_grad_norm", "(", "max_norm", ",", "aggregate_norm_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.average_params": [[73, 75], ["bmuf.FairseqBMUF._optimizer.average_params"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.adam.FairseqAdam.average_params"], ["", "def", "average_params", "(", "self", ")", ":", "\n", "        ", "self", ".", "_optimizer", ".", "average_params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF._block_sync": [[76, 95], ["bmuf.FairseqBMUF._avg_grad_from_all_gpus", "bmuf.FairseqBMUF._calc_grad", "bmuf.FairseqBMUF._update_global_model", "bmuf.FairseqBMUF.average_params"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF._avg_grad_from_all_gpus", "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF._calc_grad", "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF._update_global_model", "home.repos.pwc.inspect_result.reneeye_const.optim.adam.FairseqAdam.average_params"], ["", "def", "_block_sync", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "world_size", "<=", "1", ":", "\n", "            ", "return", "\n", "# Update the global model using local models from all GPUs", "\n", "# (Step-1) Calculate grad between previously synced model and", "\n", "# currrent local model", "\n", "", "if", "self", ".", "block_momentum", "!=", "0", ":", "\n", "            ", "self", ".", "_calc_grad", "(", ")", "\n", "\n", "# (Step-2) Average gradient from all GPUs", "\n", "", "self", ".", "_avg_grad_from_all_gpus", "(", ")", "\n", "\n", "# (Step-3) Calculate global momentum and update the global model", "\n", "if", "self", ".", "block_momentum", "!=", "0", ":", "\n", "            ", "self", ".", "_update_global_model", "(", ")", "\n", "\n", "# (Step-4) Average local optimizer params", "\n", "", "if", "self", ".", "average_sync", ":", "\n", "            ", "self", ".", "average_params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF._is_warmup_end": [[96, 101], ["bmuf.FairseqBMUF.get_num_updates"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.get_num_updates"], ["", "", "def", "_is_warmup_end", "(", "self", ")", ":", "\n", "# Check whether train iterations is equal to warmup iter", "\n", "        ", "if", "self", ".", "get_num_updates", "(", ")", "==", "self", ".", "warmup_iteration", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF._is_bmuf_iter": [[102, 109], ["bmuf.FairseqBMUF.get_num_updates", "bmuf.FairseqBMUF.get_num_updates"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.get_num_updates"], ["", "def", "_is_bmuf_iter", "(", "self", ")", ":", "\n", "# Check whether train iterations is equal to bmuf sync iter", "\n", "        ", "if", "(", "self", ".", "get_num_updates", "(", ")", ">", "self", ".", "warmup_iteration", ")", "and", "(", "\n", "self", ".", "get_num_updates", "(", ")", "%", "self", ".", "sync_iter", "==", "0", "\n", ")", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF._warmup_sync": [[110, 124], ["bmuf.FairseqBMUF._reset_local_data", "torch.broadcast", "torch.broadcast", "bmuf.FairseqBMUF._optimizer.average_params", "bmuf.FairseqBMUF._optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF._reset_local_data", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.broadcast", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.broadcast", "home.repos.pwc.inspect_result.reneeye_const.optim.adam.FairseqAdam.average_params", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict"], ["", "def", "_warmup_sync", "(", "self", ",", "root_rank", "=", "0", ")", ":", "\n", "        ", "if", "self", ".", "world_size", "<=", "1", ":", "\n", "            ", "return", "\n", "# Broadcast the local model to all gpus", "\n", "", "for", "param", "in", "self", ".", "params", ":", "\n", "            ", "dist", ".", "broadcast", "(", "param", ".", "data", ",", "src", "=", "root_rank", ")", "\n", "\n", "# Update local optimizer state", "\n", "", "if", "self", ".", "average_sync", ":", "\n", "            ", "self", ".", "_optimizer", ".", "average_params", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_optimizer", ".", "load_state_dict", "(", "self", ".", "initial_state", ")", "\n", "\n", "", "self", ".", "_reset_local_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.step": [[125, 133], ["bmuf.FairseqBMUF._optimizer.step", "bmuf.FairseqBMUF.set_num_updates", "bmuf.FairseqBMUF._is_warmup_end", "bmuf.FairseqBMUF._warmup_sync", "bmuf.FairseqBMUF._is_bmuf_iter", "bmuf.FairseqBMUF.get_num_updates", "bmuf.FairseqBMUF._block_sync"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.Wav2VecEncoder.set_num_updates", "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF._is_warmup_end", "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF._warmup_sync", "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF._is_bmuf_iter", "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.get_num_updates", "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF._block_sync"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\"\"\"", "\n", "self", ".", "_optimizer", ".", "step", "(", "closure", ")", "\n", "self", ".", "set_num_updates", "(", "self", ".", "get_num_updates", "(", ")", "+", "1", ")", "\n", "if", "self", ".", "_is_warmup_end", "(", ")", ":", "\n", "            ", "self", ".", "_warmup_sync", "(", ")", "\n", "", "elif", "self", ".", "_is_bmuf_iter", "(", ")", ":", "\n", "            ", "self", ".", "_block_sync", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.zero_grad": [[134, 137], ["bmuf.FairseqBMUF._optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad"], ["", "", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\"Clears the gradients of all optimized parameters.\"\"\"", "\n", "self", ".", "_optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.get_num_updates": [[138, 141], ["None"], "methods", ["None"], ["", "def", "get_num_updates", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the number of parameters updates.\"\"\"", "\n", "return", "self", ".", "_num_updates", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF.set_num_updates": [[142, 145], ["None"], "methods", ["None"], ["", "def", "set_num_updates", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Set the number of parameters updates.\"\"\"", "\n", "self", ".", "_num_updates", "=", "num_updates", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF._reset_local_data": [[146, 156], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "zip", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "p.data.new_zeros", "p.data.new_zeros", "global_param.copy_", "p.data.size", "p.data.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_reset_local_data", "(", "self", ")", ":", "\n", "# (Step-0) Initialize global momentum parameters and store global copy on each gpu", "\n", "        ", "self", ".", "global_params", "=", "[", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "for", "p", "in", "self", ".", "params", "]", "\n", "self", ".", "smoothed_grads", "=", "[", "p", ".", "data", ".", "new_zeros", "(", "p", ".", "data", ".", "size", "(", ")", ")", "for", "p", "in", "self", ".", "params", "]", "\n", "self", ".", "grads", "=", "[", "p", ".", "data", ".", "new_zeros", "(", "p", ".", "data", ".", "size", "(", ")", ")", "for", "p", "in", "self", ".", "params", "]", "\n", "\n", "# saving the global model locally for calculating gradient during bmuf sync", "\n", "for", "param", ",", "global_param", "in", "zip", "(", "self", ".", "params", ",", "self", ".", "global_params", ")", ":", "\n", "            ", "global_param", ".", "copy_", "(", "param", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF._calc_grad": [[157, 167], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "zip"], "methods", ["None"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_calc_grad", "(", "self", ")", ":", "\n", "# global_params is basically the global copy from the previously finished", "\n", "# synchronisation. param.data is local parameter after block_sync_freq", "\n", "# for the local gpu. so grad is difference between previously synced", "\n", "# model and currrent local model.", "\n", "        ", "for", "index", ",", "(", "param", ",", "global_param", ")", "in", "enumerate", "(", "\n", "zip", "(", "self", ".", "params", ",", "self", ".", "global_params", ")", "\n", ")", ":", "\n", "            ", "self", ".", "grads", "[", "index", "]", "=", "global_param", "-", "param", ".", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF._avg_grad_from_all_gpus": [[168, 173], ["enumerate", "float", "torch.all_reduce", "torch.all_reduce", "torch.get_world_size", "torch.get_world_size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce", "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_world_size"], ["", "", "def", "_avg_grad_from_all_gpus", "(", "self", ")", ":", "\n", "        ", "for", "index", ",", "param", "in", "enumerate", "(", "self", ".", "params", ")", ":", "\n", "            ", "sync_para", "=", "param", ".", "data", "if", "self", ".", "block_momentum", "==", "0", "else", "self", ".", "grads", "[", "index", "]", "\n", "sync_para", "/=", "float", "(", "dist", ".", "get_world_size", "(", ")", ")", "\n", "dist", ".", "all_reduce", "(", "sync_para", ",", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.bmuf.FairseqBMUF._update_global_model": [[174, 201], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "zip", "param.data.copy_", "global_param.copy_", "param.data.copy_"], "methods", ["None"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_update_global_model", "(", "self", ")", ":", "\n", "        ", "for", "index", ",", "(", "param", ",", "global_param", ",", "smoothed_grad", ",", "grad", ")", "in", "enumerate", "(", "\n", "zip", "(", "\n", "self", ".", "params", ",", "\n", "self", ".", "global_params", ",", "\n", "self", ".", "smoothed_grads", ",", "\n", "# all gpus would share the same value of smoothed_grad, since it is", "\n", "# always computed on synchronized gradients.", "\n", "self", ".", "grads", ",", "\n", ")", "\n", ")", ":", "\n", "# global_param is basically last syncrhornized parameter. though", "\n", "# smoothed_grad is local, all processes will have same value of", "\n", "# smoothed_grad and hence param is globally synchronized copy.", "\n", "# smoothed_grad(t) = BM * smoothed_grad(t-1) + BM_lr * grad(t)", "\n", "            ", "smoothed_grad", "=", "self", ".", "block_momentum", "*", "smoothed_grad", "+", "self", ".", "block_lr", "*", "grad", "\n", "param", ".", "data", ".", "copy_", "(", "global_param", "-", "smoothed_grad", ")", "\n", "\n", "# A Nesterov momentum here is to do a partial weight update before", "\n", "# calculating the gradient", "\n", "if", "self", ".", "use_nbm", ":", "\n", "                ", "param", ".", "data", ".", "copy_", "(", "param", ".", "data", "-", "self", ".", "block_momentum", "*", "smoothed_grad", ")", "\n", "\n", "# backup for the next synchronization.", "\n", "", "self", ".", "smoothed_grads", "[", "index", "]", "=", "smoothed_grad", "\n", "global_param", ".", "copy_", "(", "param", ".", "data", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.optim.shard.shard_": [[19, 97], ["type", "FairseqOSS", "ImportError", "AttributeError", "name.startswith", "hasattr", "getattr", "range", "torch.tensor", "range", "send_state.update", "utils.broadcast_object", "utils.broadcast_object"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.broadcast_object", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.broadcast_object"], ["", "def", "shard_", "(", "optimizer", ",", "group", ")", ":", "\n", "    ", "if", "not", "_has_fairscale", ":", "\n", "        ", "raise", "ImportError", "(", "\n", "\"\\n\\nPlease install the fairscale package:\"", "\"\\n\\n  pip install fairscale\"", "\n", ")", "\n", "\n", "", "class", "FairseqOSS", "(", "OSS", ")", ":", "\n", "        ", "@", "property", "\n", "def", "disable_mem_eff_fp16_loading_hack", "(", "self", ")", ":", "\n", "            ", "return", "True", "\n", "\n", "", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "            ", "if", "name", ".", "startswith", "(", "\"supports\"", ")", "and", "hasattr", "(", "self", ".", "optim", ",", "name", ")", ":", "\n", "                ", "return", "getattr", "(", "self", ".", "optim", ",", "name", ")", "\n", "", "raise", "AttributeError", "(", "\n", "\"'FairseqOSS' object has no attribute {0!r}\"", ".", "format", "(", "name", ")", "\n", ")", "\n", "\n", "", "def", "broadcast_global_state_dict", "(", "\n", "self", ",", "state_dict", ":", "Dict", "[", "str", ",", "Any", "]", "\n", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "            ", "\"\"\"\n            Broadcasts the relevant parts of a global state dict from rank 0 to\n            all other ranks.\n            \"\"\"", "\n", "if", "self", ".", "rank", "==", "0", ":", "\n", "\n", "# Create template state dict for all other keys not related to sharding", "\n", "                ", "template_state_dict", "=", "{", "\n", "key", ":", "state_dict", "[", "key", "]", "\n", "for", "key", "in", "state_dict", "\n", "if", "key", "not", "in", "(", "\"param_groups\"", ",", "\"state\"", ")", "\n", "}", "\n", "template_state_dict", "[", "\"local_state_dict\"", "]", "=", "True", "\n", "\n", "for", "dst_rank", "in", "range", "(", "self", ".", "world_size", ")", ":", "\n", "# Get the dst_rank's param_groups shard", "\n", "                    ", "send_state", "=", "{", "\n", "\"param_groups\"", ":", "state_dict", "[", "\"param_groups\"", "]", "[", "\n", "state_dict", "[", "\"partition\"", "]", "[", "dst_rank", "]", "[", "0", "]", ":", "state_dict", "[", "\n", "\"partition\"", "\n", "]", "[", "dst_rank", "]", "[", "1", "]", "\n", "]", ",", "\n", "\"state\"", ":", "state_dict", "[", "\"state\"", "]", "[", "dst_rank", "]", ",", "\n", "}", "\n", "send_state", ".", "update", "(", "template_state_dict", ")", "\n", "\n", "if", "dst_rank", "==", "0", ":", "\n", "                        ", "recv_state", "=", "send_state", "\n", "", "else", ":", "\n", "                        ", "utils", ".", "broadcast_object", "(", "\n", "send_state", ",", "\n", "src_rank", "=", "0", ",", "\n", "group", "=", "self", ".", "group", ",", "\n", "dist_device", "=", "self", ".", "_device", ",", "\n", ")", "\n", "", "", "", "else", ":", "\n", "                ", "empty_buffer", "=", "torch", ".", "tensor", "(", "[", "0", "]", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "self", ".", "_device", ")", "\n", "for", "dst_rank", "in", "range", "(", "1", ",", "self", ".", "world_size", ")", ":", "\n", "                    ", "state", "=", "utils", ".", "broadcast_object", "(", "\n", "empty_buffer", ",", "\n", "src_rank", "=", "0", ",", "\n", "group", "=", "self", ".", "group", ",", "\n", "dist_device", "=", "self", ".", "_device", ",", "\n", ")", "\n", "if", "dst_rank", "==", "self", ".", "rank", ":", "\n", "                        ", "recv_state", "=", "state", "\n", "\n", "", "", "", "return", "recv_state", "\n", "\n", "", "", "torch_optimizer", "=", "optimizer", ".", "optimizer", "\n", "optim_cls", "=", "type", "(", "torch_optimizer", ")", "\n", "\n", "optimizer", ".", "optimizer", "=", "FairseqOSS", "(", "\n", "torch_optimizer", ".", "param_groups", ",", "\n", "optim_cls", ",", "\n", "group", "=", "group", ",", "\n", "**", "optimizer", ".", "optimizer_config", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._FP16OptimizerMixin.__init__": [[17, 21], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# forward __init__ call to the next class in mro(method resolution order)", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_multiply_factor", "=", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._FP16OptimizerMixin.has_flat_params": [[22, 27], ["torch.is_tensor", "isinstance", "all", "torch.is_tensor", "fp16_optimizer._FP16OptimizerMixin.fp32_params.values"], "methods", ["None"], ["", "@", "property", "\n", "def", "has_flat_params", "(", "self", ")", ":", "\n", "        ", "return", "torch", ".", "is_tensor", "(", "self", ".", "fp32_params", ")", "or", "(", "\n", "isinstance", "(", "self", ".", "fp32_params", ",", "dict", ")", "\n", "and", "all", "(", "torch", ".", "is_tensor", "(", "t", ")", "for", "t", "in", "self", ".", "fp32_params", ".", "values", "(", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._FP16OptimizerMixin.build_fp32_params": [[29, 70], ["sum", "getattr", "getattr", "torch.cuda.current_device", "list", "device_params[].new().float().new", "torch.nn.Parameter", "fp32_params[].data.new", "torch.nn.Parameter", "torch.zeros_like", "fp32_params.append", "p.data.numel", "set", "sum", "p.data.numel", "[].copy_", "p.data.float", "device_params[].new().float", "p.data.view", "p.data.numel", "device_params[].new"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_fp32_params", "(", "cls", ",", "args", ",", "params", ",", "flatten", "=", "True", ")", ":", "\n", "# create FP32 copy of parameters and grads", "\n", "        ", "if", "flatten", ":", "\n", "            ", "is_pipeline_parallel", "=", "getattr", "(", "\n", "args", ",", "\"pipeline_model_parallel\"", ",", "False", "\n", ")", "and", "getattr", "(", "args", ",", "\"distributed_no_spawn\"", ",", "False", ")", "\n", "total_param_size", "=", "sum", "(", "p", ".", "data", ".", "numel", "(", ")", "for", "p", "in", "params", ")", "\n", "devices", "=", "[", "torch", ".", "cuda", ".", "current_device", "(", ")", "]", "\n", "if", "is_pipeline_parallel", ":", "\n", "                ", "devices", "=", "list", "(", "set", "(", "args", ".", "pipeline_devices", ")", ")", "\n", "", "fp32_params", "=", "{", "}", "\n", "for", "device", "in", "devices", ":", "\n", "                ", "if", "is_pipeline_parallel", ":", "\n", "                    ", "device_param_size", "=", "sum", "(", "\n", "p", ".", "data", ".", "numel", "(", ")", "for", "p", "in", "params", "if", "p", ".", "device", ".", "index", "==", "device", "\n", ")", "\n", "device_params", "=", "[", "p", "for", "p", "in", "params", "if", "p", ".", "device", ".", "index", "==", "device", "]", "\n", "", "else", ":", "\n", "                    ", "device_param_size", "=", "total_param_size", "\n", "device_params", "=", "params", "\n", "", "fp32_params", "[", "device", "]", "=", "(", "\n", "device_params", "[", "0", "]", ".", "new", "(", "0", ")", ".", "float", "(", ")", ".", "new", "(", "device_param_size", ")", "\n", ")", "\n", "offset", "=", "0", "\n", "for", "p", "in", "device_params", ":", "\n", "                    ", "numel", "=", "p", ".", "data", ".", "numel", "(", ")", "\n", "fp32_params", "[", "device", "]", "[", "offset", ":", "offset", "+", "numel", "]", ".", "copy_", "(", "p", ".", "data", ".", "view", "(", "-", "1", ")", ")", "\n", "offset", "+=", "numel", "\n", "", "fp32_params", "[", "device", "]", "=", "torch", ".", "nn", ".", "Parameter", "(", "fp32_params", "[", "device", "]", ")", "\n", "fp32_params", "[", "device", "]", ".", "grad", "=", "fp32_params", "[", "device", "]", ".", "data", ".", "new", "(", "\n", "device_param_size", "\n", ")", "\n", "", "return", "fp32_params", "\n", "", "else", ":", "\n", "            ", "fp32_params", "=", "[", "]", "\n", "for", "p", "in", "params", ":", "\n", "                ", "p32", "=", "torch", ".", "nn", ".", "Parameter", "(", "p", ".", "data", ".", "float", "(", ")", ")", "\n", "p32", ".", "grad", "=", "torch", ".", "zeros_like", "(", "p32", ".", "data", ")", "\n", "fp32_params", ".", "append", "(", "p32", ")", "\n", "", "return", "fp32_params", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._FP16OptimizerMixin.state_dict": [[71, 77], ["fp16_optimizer._FP16OptimizerMixin.fp32_optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.state_dict"], ["", "", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the optimizer's state dict.\"\"\"", "\n", "state_dict", "=", "self", ".", "fp32_optimizer", ".", "state_dict", "(", ")", "\n", "if", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "state_dict", "[", "\"loss_scale\"", "]", "=", "self", ".", "scaler", ".", "loss_scale", "\n", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._FP16OptimizerMixin.load_state_dict": [[78, 89], ["fp16_optimizer._FP16OptimizerMixin.fp32_optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "optimizer_overrides", "=", "None", ")", ":", "\n", "        ", "\"\"\"Load an optimizer state dict.\n\n        In general we should prefer the configuration of the existing optimizer\n        instance (e.g., learning rate) over that found in the state_dict. This\n        allows us to resume training from a checkpoint using a new set of\n        optimizer args.\n        \"\"\"", "\n", "if", "\"loss_scale\"", "in", "state_dict", "and", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "self", ".", "scaler", ".", "loss_scale", "=", "state_dict", "[", "\"loss_scale\"", "]", "\n", "", "self", ".", "fp32_optimizer", ".", "load_state_dict", "(", "state_dict", ",", "optimizer_overrides", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._FP16OptimizerMixin.backward": [[90, 101], ["fp16_optimizer._FP16OptimizerMixin.backward", "fp16_optimizer._FP16OptimizerMixin.scaler.scale"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward", "home.repos.pwc.inspect_result.reneeye_const.optim.dynamic_loss_scaler.DynamicLossScaler.scale"], ["", "def", "backward", "(", "self", ",", "loss", ")", ":", "\n", "        ", "\"\"\"Computes the sum of gradients of the given tensor w.r.t. graph leaves.\n\n        Compared to :func:`fairseq.optim.FairseqOptimizer.backward`, this\n        function additionally dynamically scales the loss to avoid gradient\n        underflow.\n        \"\"\"", "\n", "if", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "loss", "=", "self", ".", "scaler", ".", "scale", "(", "loss", ")", "\n", "", "loss", ".", "backward", "(", ")", "\n", "self", ".", "_needs_sync", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._FP16OptimizerMixin._sync_fp16_grads_to_fp32": [[102, 138], ["list", "collections.defaultdict", "zip", "fp16_optimizer._FP16OptimizerMixin.fp32_params.keys", "device_params_dict[].append", "grad_data.numel", "fp16_optimizer._FP16OptimizerMixin.fp32_params[].grad.data[].copy_", "torch.zeros_like", "p.data.new_zeros", "grad_data.view", "p.grad.data.float", "p32.grad.data.copy_"], "methods", ["None"], ["", "def", "_sync_fp16_grads_to_fp32", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_needs_sync", ":", "\n", "# copy FP16 grads to FP32", "\n", "            ", "if", "self", ".", "has_flat_params", ":", "\n", "                ", "devices", "=", "list", "(", "self", ".", "fp32_params", ".", "keys", "(", ")", ")", "\n", "device_params_dict", "=", "defaultdict", "(", "list", ")", "\n", "for", "p", "in", "self", ".", "fp16_params", ":", "\n", "                    ", "if", "p", ".", "requires_grad", ":", "\n", "                        ", "device_params_dict", "[", "p", ".", "device", ".", "index", "]", ".", "append", "(", "p", ")", "\n", "", "", "for", "device", "in", "devices", ":", "\n", "                    ", "device_params", "=", "device_params_dict", "[", "device", "]", "\n", "offset", "=", "0", "\n", "for", "p", "in", "device_params", ":", "\n", "                        ", "grad_data", "=", "(", "\n", "p", ".", "grad", ".", "data", "\n", "if", "p", ".", "grad", "is", "not", "None", "\n", "else", "p", ".", "data", ".", "new_zeros", "(", "p", ".", "data", ".", "shape", ")", "\n", ")", "\n", "numel", "=", "grad_data", ".", "numel", "(", ")", "\n", "self", ".", "fp32_params", "[", "device", "]", ".", "grad", ".", "data", "[", "\n", "offset", ":", "offset", "+", "numel", "\n", "]", ".", "copy_", "(", "grad_data", ".", "view", "(", "-", "1", ")", ")", "\n", "offset", "+=", "numel", "\n", "", "", "", "else", ":", "\n", "                ", "for", "p", ",", "p32", "in", "zip", "(", "self", ".", "fp16_params", ",", "self", ".", "fp32_params", ")", ":", "\n", "                    ", "if", "not", "p", ".", "requires_grad", ":", "\n", "                        ", "continue", "\n", "", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "if", "p32", ".", "grad", "is", "None", ":", "\n", "                            ", "p32", ".", "grad", "=", "p", ".", "grad", ".", "data", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "                            ", "p32", ".", "grad", ".", "data", ".", "copy_", "(", "p", ".", "grad", ".", "data", ")", "\n", "", "", "else", ":", "\n", "                        ", "p32", ".", "grad", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "", "", "self", ".", "_needs_sync", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._FP16OptimizerMixin._sync_fp32_params_to_fp16": [[139, 162], ["list", "collections.defaultdict", "zip", "fp16_optimizer._FP16OptimizerMixin.fp32_params.keys", "device_params_dict[].append", "p.data.copy_", "p.data.numel", "p.data.copy_", "fp16_optimizer._FP16OptimizerMixin.fp32_params[].data[].view_as"], "methods", ["None"], ["", "", "def", "_sync_fp32_params_to_fp16", "(", "self", ")", ":", "\n", "# copy FP32 params back into FP16 model", "\n", "        ", "if", "self", ".", "has_flat_params", ":", "\n", "            ", "devices", "=", "list", "(", "self", ".", "fp32_params", ".", "keys", "(", ")", ")", "\n", "device_params_dict", "=", "defaultdict", "(", "list", ")", "\n", "for", "p", "in", "self", ".", "fp16_params", ":", "\n", "                ", "device_params_dict", "[", "p", ".", "device", ".", "index", "]", ".", "append", "(", "p", ")", "\n", "", "for", "device", "in", "devices", ":", "\n", "                ", "device_params", "=", "device_params_dict", "[", "device", "]", "\n", "offset", "=", "0", "\n", "for", "p", "in", "device_params", ":", "\n", "                    ", "numel", "=", "p", ".", "data", ".", "numel", "(", ")", "\n", "p", ".", "data", ".", "copy_", "(", "\n", "self", ".", "fp32_params", "[", "device", "]", "\n", ".", "data", "[", "offset", ":", "offset", "+", "numel", "]", "\n", ".", "view_as", "(", "p", ".", "data", ")", "\n", ")", "\n", "offset", "+=", "numel", "\n", "", "", "", "else", ":", "\n", "            ", "for", "p", ",", "p32", "in", "zip", "(", "self", ".", "fp16_params", ",", "self", ".", "fp32_params", ")", ":", "\n", "                ", "if", "not", "p", ".", "requires_grad", ":", "\n", "                    ", "continue", "\n", "", "p", ".", "data", ".", "copy_", "(", "p32", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._FP16OptimizerMixin._unscale_grads": [[163, 177], ["fp16_optimizer._FP16OptimizerMixin._sync_fp16_grads_to_fp32", "torch.is_tensor", "fp16_optimizer._FP16OptimizerMixin.fp32_optimizer.multiply_grads"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._FP16OptimizerMixin._sync_fp16_grads_to_fp32", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.multiply_grads"], ["", "", "", "def", "_unscale_grads", "(", "self", ")", ":", "\n", "        ", "self", ".", "_sync_fp16_grads_to_fp32", "(", ")", "\n", "if", "(", "\n", "# Skip the multiplication if it's a no-op (i.e., if _multiply_factor", "\n", "# is 1.0). At the same time, we want to avoid the device-to-host", "\n", "# transfer by comparing it to 1.0. Since _multiply_factor starts as", "\n", "# a Python float, we roughly assume that if it's a tensor then it's", "\n", "# probably not =1.0 anymore and we do the multiplication. Otherwise", "\n", "# we can safely check the value without a D2H transfer.", "\n", "torch", ".", "is_tensor", "(", "self", ".", "_multiply_factor", ")", "\n", "or", "self", ".", "_multiply_factor", "!=", "1.0", "\n", ")", ":", "\n", "            ", "self", ".", "fp32_optimizer", ".", "multiply_grads", "(", "self", ".", "_multiply_factor", ")", "\n", "self", ".", "_multiply_factor", "=", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._FP16OptimizerMixin.multiply_grads": [[178, 181], ["None"], "methods", ["None"], ["", "", "def", "multiply_grads", "(", "self", ",", "c", ")", ":", "\n", "        ", "\"\"\"Multiplies grads by a constant ``c``.\"\"\"", "\n", "self", ".", "_multiply_factor", "*=", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._FP16OptimizerMixin.clip_grad_norm": [[182, 200], ["fp16_optimizer._FP16OptimizerMixin._sync_fp16_grads_to_fp32", "fp16_optimizer._FP16OptimizerMixin.fp32_optimizer.clip_grad_norm", "fp16_optimizer._FP16OptimizerMixin.scaler.check_overflow"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._FP16OptimizerMixin._sync_fp16_grads_to_fp32", "home.repos.pwc.inspect_result.reneeye_const.model_parallel.megatron_trainer.MegatronTrainer.clip_grad_norm", "home.repos.pwc.inspect_result.reneeye_const.optim.dynamic_loss_scaler.DynamicLossScaler.check_overflow"], ["", "def", "clip_grad_norm", "(", "self", ",", "max_norm", ",", "aggregate_norm_fn", "=", "None", ")", ":", "\n", "        ", "\"\"\"Clips gradient norm and updates dynamic loss scaler.\"\"\"", "\n", "self", ".", "_sync_fp16_grads_to_fp32", "(", ")", "\n", "\n", "grad_norm", "=", "self", ".", "_multiply_factor", "*", "self", ".", "fp32_optimizer", ".", "clip_grad_norm", "(", "\n", "0", ",", "aggregate_norm_fn", "\n", ")", "\n", "\n", "if", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "if", "grad_norm", ">", "max_norm", ">", "0.0", ":", "\n", "                ", "self", ".", "_multiply_factor", "*=", "max_norm", "/", "grad_norm", "\n", "\n", "", "self", ".", "scaler", ".", "check_overflow", "(", "grad_norm", ")", "\n", "", "elif", "max_norm", ">", "0.0", ":", "\n", "            ", "clip_coef", "=", "(", "max_norm", "/", "(", "grad_norm", "+", "1e-6", ")", ")", ".", "clamp_", "(", "max", "=", "1", ")", "\n", "self", ".", "_multiply_factor", "*=", "clip_coef", "\n", "\n", "", "return", "grad_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._FP16OptimizerMixin.step": [[201, 215], ["fp16_optimizer._FP16OptimizerMixin._sync_fp16_grads_to_fp32", "getattr", "fp16_optimizer._FP16OptimizerMixin._sync_fp32_params_to_fp16", "fp16_optimizer._FP16OptimizerMixin.fp32_optimizer.step", "fp16_optimizer._FP16OptimizerMixin._unscale_grads", "fp16_optimizer._FP16OptimizerMixin.fp32_optimizer.step", "fp16_optimizer._FP16OptimizerMixin.scaler.update"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._FP16OptimizerMixin._sync_fp16_grads_to_fp32", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._FP16OptimizerMixin._sync_fp32_params_to_fp16", "home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin._unscale_grads", "home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\"\"\"", "\n", "self", ".", "_sync_fp16_grads_to_fp32", "(", ")", "\n", "\n", "if", "getattr", "(", "self", ",", "\"supports_step_with_scale\"", ",", "False", ")", ":", "\n", "            ", "self", ".", "fp32_optimizer", ".", "step", "(", "closure", ",", "scale", "=", "(", "1.0", "/", "self", ".", "_multiply_factor", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_unscale_grads", "(", ")", "\n", "self", ".", "fp32_optimizer", ".", "step", "(", "closure", ")", "\n", "\n", "", "if", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "self", ".", "scaler", ".", "update", "(", ")", "\n", "\n", "", "self", ".", "_sync_fp32_params_to_fp16", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._FP16OptimizerMixin.zero_grad": [[216, 236], ["torch.is_tensor", "fp16_optimizer._FP16OptimizerMixin.fp32_params.grad.zero_", "isinstance", "float", "fp16_optimizer._FP16OptimizerMixin.fp32_params.values", "RuntimeError", "p32.grad.zero_", "fp32_params.grad.zero_"], "methods", ["None"], ["", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\"Clears the gradients of all optimized parameters.\"\"\"", "\n", "for", "p", "in", "self", ".", "fp16_params", ":", "\n", "            ", "p", ".", "grad", "=", "None", "\n", "", "if", "self", ".", "has_flat_params", ":", "\n", "            ", "if", "torch", ".", "is_tensor", "(", "self", ".", "fp32_params", ")", ":", "\n", "                ", "self", ".", "fp32_params", ".", "grad", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "fp32_params", ",", "dict", ")", ":", "\n", "                ", "for", "fp32_params", "in", "self", ".", "fp32_params", ".", "values", "(", ")", ":", "\n", "                    ", "fp32_params", ".", "grad", ".", "zero_", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"self.fp32_params must be a tensor or dict\"", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "p32", "in", "self", ".", "fp32_params", ":", "\n", "                ", "if", "p32", ".", "grad", "is", "not", "None", ":", "\n", "                    ", "p32", ".", "grad", ".", "zero_", "(", ")", "\n", "", "", "", "self", ".", "_needs_sync", "=", "False", "\n", "\n", "if", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "self", ".", "_multiply_factor", "=", "1.0", "/", "float", "(", "self", ".", "scaler", ".", "loss_scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.FP16Optimizer.__init__": [[243, 276], ["super().__init__", "getattr", "int", "int", "getattr", "dynamic_loss_scaler.DynamicLossScaler", "len", "ValueError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "params", ",", "fp32_optimizer", ",", "fp32_params", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ".", "optimizer", ")", "\n", "self", ".", "fp16_params", "=", "params", "\n", "self", ".", "fp32_optimizer", "=", "fp32_optimizer", "\n", "self", ".", "fp32_params", "=", "fp32_params", "\n", "\n", "if", "getattr", "(", "cfg", ".", "common", ",", "\"fp16_scale_window\"", ",", "None", ")", "is", "None", ":", "\n", "            ", "if", "len", "(", "cfg", ".", "optimization", ".", "update_freq", ")", ">", "1", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"--fp16-scale-window must be given explicitly when using a \"", "\n", "\"custom --update-freq schedule\"", "\n", ")", "\n", "", "data_parallel_size", "=", "int", "(", "\n", "cfg", ".", "distributed_training", ".", "distributed_world_size", "\n", "/", "cfg", ".", "common", ".", "model_parallel_size", "\n", ")", "\n", "scale_window", "=", "int", "(", "\n", "2", "**", "14", "/", "data_parallel_size", "/", "cfg", ".", "optimization", ".", "update_freq", "[", "0", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "scale_window", "=", "cfg", ".", "common", ".", "fp16_scale_window", "\n", "\n", "", "if", "not", "getattr", "(", "cfg", ".", "common", ",", "\"bf16\"", ",", "False", ")", ":", "\n", "            ", "self", ".", "scaler", "=", "DynamicLossScaler", "(", "\n", "init_scale", "=", "cfg", ".", "common", ".", "fp16_init_scale", ",", "\n", "scale_window", "=", "scale_window", ",", "\n", "tolerance", "=", "cfg", ".", "common", ".", "fp16_scale_tolerance", ",", "\n", "threshold", "=", "cfg", ".", "common", ".", "threshold_loss_scale", ",", "\n", "min_loss_scale", "=", "cfg", ".", "common", ".", "min_loss_scale", ",", "\n", ")", "\n", "", "else", ":", "\n", "# disable loss scaling for bfloat16", "\n", "            ", "self", ".", "scaler", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.FP16Optimizer.build_optimizer": [[277, 297], ["getattr", "cls.build_fp32_params", "cls", "getattr", "fairseq.optim.build_optimizer", "fairseq.optim.build_optimizer", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._FP16OptimizerMixin.build_fp32_params", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls", "home.repos.pwc.inspect_result.reneeye_const.optim.__init__.build_optimizer", "home.repos.pwc.inspect_result.reneeye_const.optim.__init__.build_optimizer"], ["", "", "@", "classmethod", "\n", "def", "build_optimizer", "(", "cls", ",", "cfg", ":", "DictConfig", ",", "params", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            cfg (omegaconf.DictConfig): fairseq args\n            params (iterable): iterable of parameters to optimize\n        \"\"\"", "\n", "flatten", "=", "not", "getattr", "(", "cfg", ".", "common", ",", "\"fp16_no_flatten_grads\"", ",", "False", ")", "\n", "if", "getattr", "(", "cfg", ".", "common", ",", "\"bf16\"", ",", "False", ")", ":", "\n", "            ", "flatten", "=", "False", "# mixed precision is faster on TPUs without flat grads", "\n", "", "fp32_params", "=", "cls", ".", "build_fp32_params", "(", "cfg", ".", "optimizer", ",", "params", ",", "flatten", "=", "flatten", ")", "\n", "if", "flatten", ":", "\n", "            ", "fp32_optimizer", "=", "optim", ".", "build_optimizer", "(", "cfg", ".", "optimizer", ",", "[", "fp32_params", "]", ")", "\n", "", "else", ":", "\n", "            ", "fp32_optimizer", "=", "optim", ".", "build_optimizer", "(", "cfg", ".", "optimizer", ",", "fp32_params", ")", "\n", "", "if", "flatten", "and", "not", "fp32_optimizer", ".", "supports_flat_params", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "f\"chosen optimizer {fp32_optimizer.__class__.__name__} does not support flat params, please set --fp16-no-flatten-grads\"", "\n", ")", "\n", "", "return", "cls", "(", "cfg", ",", "params", ",", "fp32_optimizer", ",", "fp32_params", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.FP16Optimizer.optimizer": [[302, 305], ["None"], "methods", ["None"], ["", "@", "optimizer", ".", "setter", "\n", "def", "optimizer", "(", "self", ",", "optimizer", ")", ":", "\n", "        ", "self", ".", "fp32_optimizer", ".", "optimizer", "=", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.FP16Optimizer.optimizer_config": [[306, 309], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "fp32_optimizer", ".", "optimizer_config", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.FP16Optimizer.get_lr": [[310, 312], ["fp16_optimizer.FP16Optimizer.fp32_optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "fp32_optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.FP16Optimizer.set_lr": [[313, 315], ["fp16_optimizer.FP16Optimizer.fp32_optimizer.set_lr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["", "def", "set_lr", "(", "self", ",", "lr", ")", ":", "\n", "        ", "self", ".", "fp32_optimizer", ".", "set_lr", "(", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.FP16Optimizer.all_reduce_grads": [[316, 318], ["fp16_optimizer.FP16Optimizer.fp32_optimizer.all_reduce_grads"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.distributed_fairseq_model.TPUDistributedDataParallel.all_reduce_grads"], ["", "def", "all_reduce_grads", "(", "self", ",", "module", ")", ":", "\n", "        ", "self", ".", "fp32_optimizer", ".", "all_reduce_grads", "(", "module", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.__init__": [[321, 325], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# forward __init__ call to the next class in MRO (method resolution order)", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_multiply_factor", "=", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.has_flat_params": [[326, 329], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "has_flat_params", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.state_dict": [[330, 336], ["fp16_optimizer._MemoryEfficientFP16OptimizerMixin.wrapped_optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the optimizer's state dict.\"\"\"", "\n", "state_dict", "=", "self", ".", "wrapped_optimizer", ".", "state_dict", "(", ")", "\n", "if", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "state_dict", "[", "\"loss_scale\"", "]", "=", "self", ".", "scaler", ".", "loss_scale", "\n", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.load_state_dict": [[337, 369], ["fp16_optimizer._MemoryEfficientFP16OptimizerMixin.wrapped_optimizer.load_state_dict", "getattr", "state_dict[].items", "zip", "itertools.chain", "itertools.chain"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "optimizer_overrides", "=", "None", ")", ":", "\n", "        ", "\"\"\"Load an optimizer state dict.\n\n        In general we should prefer the configuration of the existing optimizer\n        instance (e.g., learning rate) over that found in the state_dict. This\n        allows us to resume training from a checkpoint using a new set of\n        optimizer args.\n        \"\"\"", "\n", "if", "\"loss_scale\"", "in", "state_dict", "and", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "self", ".", "scaler", ".", "loss_scale", "=", "state_dict", "[", "\"loss_scale\"", "]", "\n", "\n", "", "self", ".", "wrapped_optimizer", ".", "load_state_dict", "(", "state_dict", ",", "optimizer_overrides", ")", "\n", "\n", "# Hack: PyTorch automatically casts the optimizer state to match the", "\n", "# type of the current parameters. But with --memory-efficient-fp16 the", "\n", "# params are FP16 while the optimizer state is FP32 and we don't want", "\n", "# to cast. A workaround is to manually copy back the original state", "\n", "# after the optimizer has been loaded.", "\n", "if", "not", "getattr", "(", "self", ".", "optimizer", ",", "\"disable_mem_eff_fp16_loading_hack\"", ",", "False", ")", ":", "\n", "            ", "groups", "=", "self", ".", "optimizer", ".", "param_groups", "\n", "saved_groups", "=", "state_dict", "[", "\"param_groups\"", "]", "\n", "id_map", "=", "{", "\n", "old_id", ":", "p", "\n", "for", "old_id", ",", "p", "in", "zip", "(", "\n", "chain", "(", "*", "(", "g", "[", "\"params\"", "]", "for", "g", "in", "saved_groups", ")", ")", ",", "\n", "chain", "(", "*", "(", "g", "[", "\"params\"", "]", "for", "g", "in", "groups", ")", ")", ",", "\n", ")", "\n", "}", "\n", "for", "k", ",", "v", "in", "state_dict", "[", "\"state\"", "]", ".", "items", "(", ")", ":", "\n", "                ", "if", "k", "in", "id_map", ":", "\n", "                    ", "param", "=", "id_map", "[", "k", "]", "\n", "self", ".", "optimizer", ".", "state", "[", "param", "]", "=", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.backward": [[370, 380], ["fp16_optimizer._MemoryEfficientFP16OptimizerMixin.backward", "fp16_optimizer._MemoryEfficientFP16OptimizerMixin.scaler.scale"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward", "home.repos.pwc.inspect_result.reneeye_const.optim.dynamic_loss_scaler.DynamicLossScaler.scale"], ["", "", "", "", "def", "backward", "(", "self", ",", "loss", ")", ":", "\n", "        ", "\"\"\"Computes the sum of gradients of the given tensor w.r.t. graph leaves.\n\n        Compared to :func:`fairseq.optim.FairseqOptimizer.backward`, this\n        function additionally dynamically scales the loss to avoid gradient\n        underflow.\n        \"\"\"", "\n", "if", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "loss", "=", "self", ".", "scaler", ".", "scale", "(", "loss", ")", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin._unscale_grads": [[381, 394], ["torch.is_tensor", "fp16_optimizer._MemoryEfficientFP16OptimizerMixin.wrapped_optimizer.multiply_grads"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.multiply_grads"], ["", "def", "_unscale_grads", "(", "self", ")", ":", "\n", "        ", "if", "(", "\n", "# Skip the multiplication if it's a no-op (i.e., if _multiply_factor", "\n", "# is 1.0). At the same time, we want to avoid the device-to-host", "\n", "# transfer by comparing it to 1.0. Since _multiply_factor starts as", "\n", "# a Python float, we roughly assume that if it's a tensor then it's", "\n", "# probably not =1.0 anymore and we do the multiplication. Otherwise", "\n", "# we can safely check the value without a D2H transfer.", "\n", "torch", ".", "is_tensor", "(", "self", ".", "_multiply_factor", ")", "\n", "or", "self", ".", "_multiply_factor", "!=", "1.0", "\n", ")", ":", "\n", "            ", "self", ".", "wrapped_optimizer", ".", "multiply_grads", "(", "self", ".", "_multiply_factor", ")", "\n", "self", ".", "_multiply_factor", "=", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.multiply_grads": [[395, 398], ["None"], "methods", ["None"], ["", "", "def", "multiply_grads", "(", "self", ",", "c", ")", ":", "\n", "        ", "\"\"\"Multiplies grads by a constant *c*.\"\"\"", "\n", "self", ".", "_multiply_factor", "*=", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.clip_grad_norm": [[399, 418], ["float", "fp16_optimizer._MemoryEfficientFP16OptimizerMixin.wrapped_optimizer.clip_grad_norm", "float", "fp16_optimizer._MemoryEfficientFP16OptimizerMixin.scaler.check_overflow"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.model_parallel.megatron_trainer.MegatronTrainer.clip_grad_norm", "home.repos.pwc.inspect_result.reneeye_const.optim.dynamic_loss_scaler.DynamicLossScaler.check_overflow"], ["", "def", "clip_grad_norm", "(", "self", ",", "max_norm", ",", "aggregate_norm_fn", "=", "None", ")", ":", "\n", "        ", "\"\"\"Clips gradient norm and updates dynamic loss scaler.\"\"\"", "\n", "max_norm", "=", "float", "(", "max_norm", ")", "\n", "grad_norm", "=", "self", ".", "_multiply_factor", "*", "self", ".", "wrapped_optimizer", ".", "clip_grad_norm", "(", "\n", "0", ",", "aggregate_norm_fn", "\n", ")", "\n", "\n", "if", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "grad_norm_cpu", "=", "float", "(", "grad_norm", ")", "\n", "if", "grad_norm_cpu", ">", "max_norm", ">", "0.0", ":", "\n", "                ", "self", ".", "_multiply_factor", "*=", "max_norm", "/", "grad_norm_cpu", "\n", "\n", "# detect overflow and adjust loss scale", "\n", "", "self", ".", "scaler", ".", "check_overflow", "(", "grad_norm_cpu", ")", "\n", "", "elif", "max_norm", ">", "0.0", ":", "\n", "            ", "clip_coef", "=", "(", "max_norm", "/", "(", "grad_norm", "+", "1e-6", ")", ")", ".", "clamp_", "(", "max", "=", "1", ")", "\n", "self", ".", "_multiply_factor", "*=", "clip_coef", "\n", "\n", "", "return", "grad_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.step": [[419, 430], ["getattr", "fp16_optimizer._MemoryEfficientFP16OptimizerMixin.wrapped_optimizer.step", "fp16_optimizer._MemoryEfficientFP16OptimizerMixin._unscale_grads", "fp16_optimizer._MemoryEfficientFP16OptimizerMixin.wrapped_optimizer.step", "fp16_optimizer._MemoryEfficientFP16OptimizerMixin.scaler.update"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin._unscale_grads", "home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\"\"\"", "\n", "if", "getattr", "(", "self", ",", "\"supports_step_with_scale\"", ",", "False", ")", ":", "\n", "# NOTE(msb) optimizer divides by scale factor", "\n", "            ", "self", ".", "wrapped_optimizer", ".", "step", "(", "closure", ",", "scale", "=", "(", "1.0", "/", "self", ".", "_multiply_factor", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_unscale_grads", "(", ")", "\n", "self", ".", "wrapped_optimizer", ".", "step", "(", "closure", ")", "\n", "\n", "", "if", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "self", ".", "scaler", ".", "update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad": [[431, 438], ["fp16_optimizer._MemoryEfficientFP16OptimizerMixin.wrapped_optimizer.zero_grad", "float"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer._MemoryEfficientFP16OptimizerMixin.zero_grad"], ["", "", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\"Clears the gradients of all optimized parameters.\"\"\"", "\n", "self", ".", "wrapped_optimizer", ".", "zero_grad", "(", ")", "\n", "if", "self", ".", "scaler", "is", "not", "None", ":", "\n", "            ", "self", ".", "_multiply_factor", "=", "1.0", "/", "float", "(", "self", ".", "scaler", ".", "loss_scale", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_multiply_factor", "=", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.__init__": [[458, 494], ["super().__init__", "ValueError", "getattr", "int", "getattr", "dynamic_loss_scaler.DynamicLossScaler", "len", "ValueError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "params", ",", "optimizer", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "optimizer", ".", "supports_memory_efficient_fp16", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Unsupported optimizer: {}\"", ".", "format", "(", "optimizer", ".", "__class__", ".", "__name__", ")", "\n", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "cfg", ".", "optimizer", ")", "\n", "self", ".", "wrapped_optimizer", "=", "optimizer", "\n", "\n", "if", "getattr", "(", "cfg", ".", "common", ",", "\"fp16_scale_window\"", ",", "None", ")", "is", "None", ":", "\n", "            ", "if", "len", "(", "cfg", ".", "optimization", ".", "update_freq", ")", ">", "1", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"--fp16-scale-window must be given explicitly when using a \"", "\n", "\"custom --update-freq schedule\"", "\n", ")", "\n", "", "data_parallel_size", "=", "int", "(", "\n", "cfg", ".", "distributed_training", ".", "distributed_world_size", "\n", "/", "cfg", ".", "common", ".", "model_parallel_size", "\n", ")", "\n", "scale_window", "=", "(", "\n", "2", "**", "14", "/", "data_parallel_size", "/", "cfg", ".", "optimization", ".", "update_freq", "[", "0", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "scale_window", "=", "cfg", ".", "common", ".", "fp16_scale_window", "\n", "\n", "", "if", "not", "getattr", "(", "cfg", ".", "common", ",", "\"bf16\"", ",", "False", ")", ":", "\n", "            ", "self", ".", "scaler", "=", "DynamicLossScaler", "(", "\n", "init_scale", "=", "cfg", ".", "common", ".", "fp16_init_scale", ",", "\n", "scale_window", "=", "scale_window", ",", "\n", "tolerance", "=", "cfg", ".", "common", ".", "fp16_scale_tolerance", ",", "\n", "threshold", "=", "cfg", ".", "common", ".", "threshold_loss_scale", ",", "\n", "min_loss_scale", "=", "cfg", ".", "common", ".", "min_loss_scale", ",", "\n", ")", "\n", "", "else", ":", "\n", "# disable loss scaling for bfloat16", "\n", "            ", "self", ".", "scaler", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.build_optimizer": [[495, 504], ["fairseq.optim.build_optimizer", "cls"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.__init__.build_optimizer", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "", "@", "classmethod", "\n", "def", "build_optimizer", "(", "cls", ",", "cfg", ":", "DictConfig", ",", "params", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            args (argparse.Namespace): fairseq args\n            params (iterable): iterable of parameters to optimize\n        \"\"\"", "\n", "fp16_optimizer", "=", "optim", ".", "build_optimizer", "(", "cfg", ".", "optimizer", ",", "params", ")", "\n", "return", "cls", "(", "cfg", ",", "params", ",", "fp16_optimizer", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.optimizer": [[509, 512], ["None"], "methods", ["None"], ["", "@", "optimizer", ".", "setter", "\n", "def", "optimizer", "(", "self", ",", "optimizer", ")", ":", "\n", "        ", "self", ".", "wrapped_optimizer", ".", "optimizer", "=", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.optimizer_config": [[513, 516], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "wrapped_optimizer", ".", "optimizer_config", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr": [[517, 519], ["fp16_optimizer.MemoryEfficientFP16Optimizer.wrapped_optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "wrapped_optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr": [[520, 522], ["fp16_optimizer.MemoryEfficientFP16Optimizer.wrapped_optimizer.set_lr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["", "def", "set_lr", "(", "self", ",", "lr", ")", ":", "\n", "        ", "self", ".", "wrapped_optimizer", ".", "set_lr", "(", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.all_reduce_grads": [[523, 525], ["fp16_optimizer.MemoryEfficientFP16Optimizer.wrapped_optimizer.all_reduce_grads"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.distributed_fairseq_model.TPUDistributedDataParallel.all_reduce_grads"], ["", "def", "all_reduce_grads", "(", "self", ",", "module", ")", ":", "\n", "        ", "self", ".", "wrapped_optimizer", ".", "all_reduce_grads", "(", "module", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.optim.fused_lamb.FairseqLAMB.__init__": [[13, 21], ["fairseq.optim.LegacyFairseqOptimizer.__init__", "FusedLAMB", "ImportError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "args", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "try", ":", "\n", "            ", "from", "apex", ".", "optimizers", "import", "FusedLAMB", "\n", "\n", "self", ".", "_optimizer", "=", "FusedLAMB", "(", "params", ",", "**", "self", ".", "optimizer_config", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex to use LAMB optimizer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fused_lamb.FairseqLAMB.add_args": [[22, 32], ["parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add optimizer-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--lamb-betas'", ",", "default", "=", "'(0.9, 0.999)'", ",", "metavar", "=", "'B'", ",", "\n", "help", "=", "'betas for LAMB optimizer'", ")", "\n", "parser", ".", "add_argument", "(", "'--lamb-eps'", ",", "type", "=", "float", ",", "default", "=", "1e-8", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'epsilon for LAMB optimizer'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight-decay'", ",", "'--wd'", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "metavar", "=", "'WD'", ",", "\n", "help", "=", "'weight decay'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fused_lamb.FairseqLAMB.optimizer_config": [[34, 47], ["eval"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a kwarg dictionary that will be used to override optimizer\n        args stored in checkpoints. This allows us to load a checkpoint and\n        resume training using a different set of optimizer args, e.g., with a\n        different learning rate.\n        \"\"\"", "\n", "return", "{", "\n", "\"lr\"", ":", "self", ".", "args", ".", "lr", "[", "0", "]", ",", "\n", "\"betas\"", ":", "eval", "(", "self", ".", "args", ".", "lamb_betas", ")", ",", "\n", "\"eps\"", ":", "self", ".", "args", ".", "lamb_eps", ",", "\n", "\"weight_decay\"", ":", "self", ".", "args", ".", "weight_decay", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fused_lamb.FairseqLAMB.supports_flat_params": [[49, 52], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_flat_params", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.optim.adam.FairseqAdam.__init__": [[50, 67], ["fairseq.optim.FairseqOptimizer.__init__", "fairseq.optim.fused_adam.get_fused_adam_class", "getattr", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "adam.Adam", "getattr", "logger.info", "fairseq.optim.fused_adam.get_fused_adam_class.", "adam.Adam"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.optim.fused_adam.get_fused_adam_class"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ")", "\n", "fused_adam_cls", "=", "get_fused_adam_class", "(", ")", "\n", "use_fused_adam", "=", "(", "\n", "not", "getattr", "(", "cfg", ",", "\"use_old_adam\"", ",", "False", ")", "\n", "and", "fused_adam_cls", "is", "not", "None", "\n", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", ")", "\n", "if", "getattr", "(", "cfg", ",", "\"tpu\"", ",", "False", ")", ":", "\n", "# on TPUs we use the Adam defined here, since it", "\n", "# automatically casts gradients to FP32", "\n", "            ", "self", ".", "_optimizer", "=", "Adam", "(", "params", ",", "**", "self", ".", "optimizer_config", ")", "\n", "", "elif", "use_fused_adam", ":", "\n", "            ", "logger", ".", "info", "(", "\"using FusedAdam\"", ")", "\n", "self", ".", "_optimizer", "=", "fused_adam_cls", "(", "params", ",", "**", "self", ".", "optimizer_config", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_optimizer", "=", "Adam", "(", "params", ",", "**", "self", ".", "optimizer_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adam.FairseqAdam.optimizer_config": [[68, 83], ["eval", "isinstance"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a kwarg dictionary that will be used to override optimizer\n        args stored in checkpoints. This allows us to load a checkpoint and\n        resume training using a different set of optimizer args, e.g., with a\n        different learning rate.\n        \"\"\"", "\n", "return", "{", "\n", "\"lr\"", ":", "self", ".", "cfg", ".", "lr", "[", "0", "]", "\n", "if", "isinstance", "(", "self", ".", "cfg", ".", "lr", ",", "Collection", ")", "\n", "else", "self", ".", "cfg", ".", "lr", ",", "\n", "\"betas\"", ":", "eval", "(", "self", ".", "cfg", ".", "adam_betas", ")", ",", "\n", "\"eps\"", ":", "self", ".", "cfg", ".", "adam_eps", ",", "\n", "\"weight_decay\"", ":", "self", ".", "cfg", ".", "weight_decay", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adam.FairseqAdam.average_params": [[85, 95], ["adam.FairseqAdam.optimizer.state_dict", "float", "state_dict[].items", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.state_dict", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_world_size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce", "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce", "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce", "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce", "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce", "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce"], ["", "def", "average_params", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reduce Params is only used during BMUF distributed training.\"\"\"", "\n", "state_dict", "=", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "total_gpus", "=", "float", "(", "dist", ".", "get_world_size", "(", ")", ")", "\n", "\n", "for", "_", ",", "value", "in", "state_dict", "[", "\"state\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "value", "[", "\"exp_avg\"", "]", "/=", "total_gpus", "\n", "value", "[", "\"exp_avg_sq\"", "]", "/=", "total_gpus", "\n", "dist", ".", "all_reduce", "(", "value", "[", "\"exp_avg\"", "]", ",", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", ")", "\n", "dist", ".", "all_reduce", "(", "value", "[", "\"exp_avg_sq\"", "]", ",", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adam.Adam.__init__": [[124, 137], ["dict", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "params", ",", "\n", "lr", "=", "1e-3", ",", "\n", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "\n", "eps", "=", "1e-8", ",", "\n", "weight_decay", "=", "0", ",", "\n", "amsgrad", "=", "False", ",", "\n", ")", ":", "\n", "        ", "defaults", "=", "dict", "(", "\n", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "weight_decay", "=", "weight_decay", ",", "amsgrad", "=", "amsgrad", "\n", ")", "\n", "super", "(", "Adam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adam.Adam.supports_memory_efficient_fp16": [[138, 141], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_memory_efficient_fp16", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adam.Adam.supports_flat_params": [[142, 145], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_flat_params", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adam.Adam.step": [[146, 227], ["closure", "group.get", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "p_data_fp32.float.float.addcdiv_", "grad.float.float.float", "RuntimeError", "p_data_fp32.float.float.float", "len", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "state[].to", "state[].to", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "max_exp_avg_sq.sqrt().add_", "exp_avg_sq.sqrt().add_", "p_data_fp32.float.float.add_", "p.data.copy_", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "state[].to", "exp_avg.mul_", "exp_avg_sq.mul_", "math.sqrt", "max_exp_avg_sq.sqrt", "exp_avg_sq.sqrt"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "\"params\"", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "dtype", "in", "{", "torch", ".", "float16", ",", "torch", ".", "bfloat16", "}", ":", "\n", "                    ", "grad", "=", "grad", ".", "float", "(", ")", "\n", "", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\n", "\"Adam does not support sparse gradients, please consider SparseAdam instead\"", "\n", ")", "\n", "", "amsgrad", "=", "group", ".", "get", "(", "\"amsgrad\"", ",", "False", ")", "\n", "\n", "p_data_fp32", "=", "p", ".", "data", "\n", "if", "p", ".", "data", ".", "dtype", "in", "{", "torch", ".", "float16", ",", "torch", ".", "bfloat16", "}", ":", "\n", "                    ", "p_data_fp32", "=", "p_data_fp32", ".", "float", "(", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "\"step\"", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "\"exp_avg\"", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "\"exp_avg_sq\"", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "if", "amsgrad", ":", "\n", "# Maintains max of all exp. moving avg. of sq. grad. values", "\n", "                        ", "state", "[", "\"max_exp_avg_sq\"", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "", "", "else", ":", "\n", "                    ", "state", "[", "\"exp_avg\"", "]", "=", "state", "[", "\"exp_avg\"", "]", ".", "to", "(", "p_data_fp32", ")", "\n", "state", "[", "\"exp_avg_sq\"", "]", "=", "state", "[", "\"exp_avg_sq\"", "]", ".", "to", "(", "p_data_fp32", ")", "\n", "if", "amsgrad", ":", "\n", "                        ", "state", "[", "\"max_exp_avg_sq\"", "]", "=", "state", "[", "\"max_exp_avg_sq\"", "]", ".", "to", "(", "\n", "p_data_fp32", "\n", ")", "\n", "\n", "", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "\"exp_avg\"", "]", ",", "state", "[", "\"exp_avg_sq\"", "]", "\n", "if", "amsgrad", ":", "\n", "                    ", "max_exp_avg_sq", "=", "state", "[", "\"max_exp_avg_sq\"", "]", "\n", "", "beta1", ",", "beta2", "=", "group", "[", "\"betas\"", "]", "\n", "\n", "state", "[", "\"step\"", "]", "+=", "1", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "grad", ",", "alpha", "=", "1", "-", "beta1", ")", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "grad", ",", "grad", ",", "value", "=", "1", "-", "beta2", ")", "\n", "if", "amsgrad", ":", "\n", "# Maintains the maximum of all 2nd moment running avg. till now", "\n", "                    ", "torch", ".", "max", "(", "max_exp_avg_sq", ",", "exp_avg_sq", ",", "out", "=", "max_exp_avg_sq", ")", "\n", "# Use the max. for normalizing running avg. of gradient", "\n", "denom", "=", "max_exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "\"eps\"", "]", ")", "\n", "", "else", ":", "\n", "                    ", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "\"eps\"", "]", ")", "\n", "\n", "", "bias_correction1", "=", "1", "-", "beta1", "**", "state", "[", "\"step\"", "]", "\n", "bias_correction2", "=", "1", "-", "beta2", "**", "state", "[", "\"step\"", "]", "\n", "step_size", "=", "group", "[", "\"lr\"", "]", "*", "math", ".", "sqrt", "(", "bias_correction2", ")", "/", "bias_correction1", "\n", "\n", "if", "group", "[", "\"weight_decay\"", "]", "!=", "0", ":", "\n", "                    ", "p_data_fp32", ".", "add_", "(", "\n", "p_data_fp32", ",", "alpha", "=", "-", "group", "[", "\"weight_decay\"", "]", "*", "group", "[", "\"lr\"", "]", "\n", ")", "\n", "\n", "", "p_data_fp32", ".", "addcdiv_", "(", "exp_avg", ",", "denom", ",", "value", "=", "-", "step_size", ")", "\n", "\n", "if", "p", ".", "data", ".", "dtype", "in", "{", "torch", ".", "float16", ",", "torch", ".", "bfloat16", "}", ":", "\n", "                    ", "p", ".", "data", ".", "copy_", "(", "p_data_fp32", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.optim.__init__.build_optimizer": [[35, 40], ["all", "list", "_build_optimizer", "filter", "isinstance", "p.values"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer._build_optimizer"], []], "home.repos.pwc.inspect_result.reneeye_const.optim.nag.FairseqNAG.__init__": [[28, 31], ["FairseqOptimizer.__init__", "nag.NAG"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ")", "\n", "self", ".", "_optimizer", "=", "NAG", "(", "params", ",", "**", "self", ".", "optimizer_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.nag.FairseqNAG.optimizer_config": [[32, 46], ["isinstance"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a kwarg dictionary that will be used to override optimizer\n        args stored in checkpoints. This allows us to load a checkpoint and\n        resume training using a different set of optimizer args, e.g., with a\n        different learning rate.\n        \"\"\"", "\n", "return", "{", "\n", "\"lr\"", ":", "self", ".", "cfg", ".", "lr", "[", "0", "]", "\n", "if", "isinstance", "(", "self", ".", "cfg", ".", "lr", ",", "Collection", ")", "\n", "else", "self", ".", "cfg", ".", "lr", ",", "\n", "\"momentum\"", ":", "self", ".", "cfg", ".", "momentum", ",", "\n", "\"weight_decay\"", ":", "self", ".", "cfg", ".", "weight_decay", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.nag.NAG.__init__": [[50, 53], ["dict", "torch.optim.optimizer.Optimizer.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "required", ",", "momentum", "=", "0", ",", "weight_decay", "=", "0", ")", ":", "\n", "        ", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "lr_old", "=", "lr", ",", "momentum", "=", "momentum", ",", "weight_decay", "=", "weight_decay", ")", "\n", "super", "(", "NAG", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.nag.NAG.supports_memory_efficient_fp16": [[54, 57], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_memory_efficient_fp16", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.nag.NAG.supports_flat_params": [[58, 61], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_flat_params", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.nag.NAG.step": [[62, 112], ["closure", "group.get", "p.grad.data.float", "p_data_fp32.float.float.add_", "p_data_fp32.float.float.add_", "buf.mul_().add_", "p_data_fp32.float.float.float", "torch.zeros_like", "param_state[].to", "p_data_fp32.float.float.mul_", "p.data.copy_", "buf.mul_"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "weight_decay", "=", "group", "[", "\"weight_decay\"", "]", "\n", "momentum", "=", "group", "[", "\"momentum\"", "]", "\n", "lr", "=", "group", "[", "\"lr\"", "]", "\n", "lr_old", "=", "group", ".", "get", "(", "\"lr_old\"", ",", "lr", ")", "\n", "lr_correct", "=", "lr", "/", "lr_old", "\n", "\n", "for", "p", "in", "group", "[", "\"params\"", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "\n", "", "p_data_fp32", "=", "p", ".", "data", "\n", "if", "p_data_fp32", ".", "dtype", "in", "{", "torch", ".", "float16", ",", "torch", ".", "bfloat16", "}", ":", "\n", "                    ", "p_data_fp32", "=", "p_data_fp32", ".", "float", "(", ")", "\n", "\n", "", "d_p", "=", "p", ".", "grad", ".", "data", ".", "float", "(", ")", "\n", "param_state", "=", "self", ".", "state", "[", "p", "]", "\n", "if", "\"momentum_buffer\"", "not", "in", "param_state", ":", "\n", "                    ", "param_state", "[", "\"momentum_buffer\"", "]", "=", "torch", ".", "zeros_like", "(", "d_p", ")", "\n", "", "else", ":", "\n", "                    ", "param_state", "[", "\"momentum_buffer\"", "]", "=", "param_state", "[", "\"momentum_buffer\"", "]", ".", "to", "(", "\n", "d_p", "\n", ")", "\n", "\n", "", "buf", "=", "param_state", "[", "\"momentum_buffer\"", "]", "\n", "\n", "if", "weight_decay", "!=", "0", ":", "\n", "                    ", "p_data_fp32", ".", "mul_", "(", "1", "-", "lr", "*", "weight_decay", ")", "\n", "", "p_data_fp32", ".", "add_", "(", "buf", ",", "alpha", "=", "momentum", "*", "momentum", "*", "lr_correct", ")", "\n", "p_data_fp32", ".", "add_", "(", "d_p", ",", "alpha", "=", "-", "(", "1", "+", "momentum", ")", "*", "lr", ")", "\n", "\n", "buf", ".", "mul_", "(", "momentum", "*", "lr_correct", ")", ".", "add_", "(", "d_p", ",", "alpha", "=", "-", "lr", ")", "\n", "\n", "if", "p", ".", "data", ".", "dtype", "in", "{", "torch", ".", "float16", ",", "torch", ".", "bfloat16", "}", ":", "\n", "                    ", "p", ".", "data", ".", "copy_", "(", "p_data_fp32", ")", "\n", "\n", "", "", "group", "[", "\"lr_old\"", "]", "=", "lr", "\n", "\n", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.optim.dynamic_loss_scaler.DynamicLossScaler.__init__": [[8, 27], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "init_scale", "=", "2.0", "**", "15", ",", "\n", "scale_factor", "=", "2.0", ",", "\n", "scale_window", "=", "2000", ",", "\n", "tolerance", "=", "0.05", ",", "\n", "threshold", "=", "None", ",", "\n", "min_loss_scale", "=", "1e-4", ",", "\n", ")", ":", "\n", "        ", "self", ".", "loss_scale", "=", "init_scale", "\n", "self", ".", "scale_factor", "=", "scale_factor", "\n", "self", ".", "scale_window", "=", "scale_window", "\n", "self", ".", "tolerance", "=", "tolerance", "\n", "self", ".", "threshold", "=", "threshold", "\n", "self", ".", "_iter", "=", "0", "\n", "self", ".", "_last_overflow_iter", "=", "-", "1", "\n", "self", ".", "_last_rescale_iter", "=", "-", "1", "\n", "self", ".", "_overflows_since_rescale", "=", "0", "\n", "self", ".", "min_loss_scale", "=", "min_loss_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.dynamic_loss_scaler.DynamicLossScaler.scale": [[28, 30], ["None"], "methods", ["None"], ["", "def", "scale", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "return", "self", ".", "loss_scale", "*", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.dynamic_loss_scaler.DynamicLossScaler.update": [[31, 36], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ")", ":", "\n", "        ", "if", "(", "self", ".", "_iter", "-", "self", ".", "_last_overflow_iter", ")", "%", "self", ".", "scale_window", "==", "0", ":", "\n", "            ", "self", ".", "loss_scale", "*=", "self", ".", "scale_factor", "\n", "self", ".", "_last_rescale_iter", "=", "self", ".", "_iter", "\n", "", "self", ".", "_iter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.dynamic_loss_scaler.DynamicLossScaler._decrease_loss_scale": [[37, 41], ["max"], "methods", ["None"], ["", "def", "_decrease_loss_scale", "(", "self", ")", ":", "\n", "        ", "self", ".", "loss_scale", "/=", "self", ".", "scale_factor", "\n", "if", "self", ".", "threshold", "is", "not", "None", ":", "\n", "            ", "self", ".", "loss_scale", "=", "max", "(", "self", ".", "loss_scale", ",", "self", ".", "threshold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.dynamic_loss_scaler.DynamicLossScaler.check_overflow": [[42, 71], ["OverflowError", "float", "float", "dynamic_loss_scaler.DynamicLossScaler._decrease_loss_scale", "FloatingPointError", "str"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.dynamic_loss_scaler.DynamicLossScaler._decrease_loss_scale"], ["", "", "def", "check_overflow", "(", "self", ",", "grad_norm", ")", ":", "\n", "# detect inf and nan", "\n", "        ", "if", "grad_norm", "==", "float", "(", "\"inf\"", ")", "or", "grad_norm", "!=", "grad_norm", ":", "\n", "# overflow has occured", "\n", "            ", "prev_scale", "=", "self", ".", "loss_scale", "\n", "iter_since_rescale", "=", "self", ".", "_iter", "-", "self", ".", "_last_rescale_iter", "\n", "\n", "self", ".", "_last_overflow_iter", "=", "self", ".", "_iter", "\n", "self", ".", "_overflows_since_rescale", "+=", "1", "\n", "pct_overflow", "=", "self", ".", "_overflows_since_rescale", "/", "float", "(", "iter_since_rescale", ")", "\n", "if", "pct_overflow", ">=", "self", ".", "tolerance", ":", "\n", "                ", "self", ".", "_decrease_loss_scale", "(", ")", "\n", "self", ".", "_last_rescale_iter", "=", "self", ".", "_iter", "\n", "self", ".", "_overflows_since_rescale", "=", "0", "\n", "\n", "", "if", "self", ".", "loss_scale", "<=", "self", ".", "min_loss_scale", ":", "\n", "# Use FloatingPointError as an uncommon error that parent", "\n", "# functions can safely catch to stop training.", "\n", "                ", "self", ".", "loss_scale", "=", "prev_scale", "\n", "raise", "FloatingPointError", "(", "\n", "(", "\n", "\"Minimum loss scale reached ({}). Your loss is probably exploding. \"", "\n", "\"Try lowering the learning rate, using gradient clipping or \"", "\n", "\"increasing the batch size.\"", "\n", ")", ".", "format", "(", "self", ".", "min_loss_scale", ")", "\n", ")", "\n", "\n", "", "self", ".", "_iter", "+=", "1", "\n", "raise", "OverflowError", "(", "\"setting loss scale to: \"", "+", "str", "(", "self", ".", "loss_scale", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.optim.fused_adam.FusedAdamV1.__init__": [[72, 101], ["importlib.import_module", "super().__init__", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "params", ",", "\n", "lr", "=", "1e-3", ",", "\n", "bias_correction", "=", "True", ",", "\n", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "\n", "eps", "=", "1e-8", ",", "\n", "eps_inside_sqrt", "=", "False", ",", "\n", "weight_decay", "=", "0.0", ",", "\n", "max_grad_norm", "=", "0.0", ",", "\n", "amsgrad", "=", "False", ",", "\n", ")", ":", "\n", "        ", "global", "fused_adam_cuda", "\n", "import", "importlib", "\n", "\n", "fused_adam_cuda", "=", "importlib", ".", "import_module", "(", "\"fused_adam_cuda\"", ")", "\n", "\n", "if", "amsgrad", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"FusedAdam does not support the AMSGrad variant.\"", ")", "\n", "", "defaults", "=", "{", "\n", "\"lr\"", ":", "lr", ",", "\n", "\"bias_correction\"", ":", "bias_correction", ",", "\n", "\"betas\"", ":", "betas", ",", "\n", "\"eps\"", ":", "eps", ",", "\n", "\"weight_decay\"", ":", "weight_decay", ",", "\n", "\"max_grad_norm\"", ":", "max_grad_norm", ",", "\n", "}", "\n", "super", "(", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "self", ".", "eps_mode", "=", "0", "if", "eps_inside_sqrt", "else", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fused_adam.FusedAdamV1.supports_memory_efficient_fp16": [[102, 105], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_memory_efficient_fp16", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fused_adam.FusedAdamV1.supports_flat_params": [[106, 109], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_flat_params", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fused_adam.FusedAdamV1.supports_step_with_scale": [[110, 113], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_step_with_scale", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fused_adam.FusedAdamV1.step": [[114, 217], ["zip", "closure", "isinstance", "zip", "len", "len", "group.get", "group.get", "p.data.float", "type", "len", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "state[].to", "state[].to", "torch.cuda.device", "fused_adam_cuda.adam"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.device"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ",", "grads", "=", "None", ",", "scale", "=", "1.0", ",", "grad_norms", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n            grads (list of tensors, optional): weight gradient to use for the\n                optimizer update. If gradients have type torch.half, parameters\n                are expected to be in type torch.float. (default: None)\n            output params (list of tensors, optional): A reduced precision copy\n                of the updated weights written out in addition to the regular\n                updated weights. Have to be of same type as gradients. (default: None)\n            scale (float, optional): factor to divide gradient tensor values\n                by before applying to weights. (default: 1)\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "if", "grads", "is", "None", ":", "\n", "            ", "grads_group", "=", "[", "None", "]", "*", "len", "(", "self", ".", "param_groups", ")", "\n", "# backward compatibility", "\n", "# assuming a list/generator of parameter means single group", "\n", "", "elif", "isinstance", "(", "grads", ",", "types", ".", "GeneratorType", ")", ":", "\n", "            ", "grads_group", "=", "[", "grads", "]", "\n", "", "elif", "type", "(", "grads", "[", "0", "]", ")", "!=", "list", ":", "\n", "            ", "grads_group", "=", "[", "grads", "]", "\n", "", "else", ":", "\n", "            ", "grads_group", "=", "grads", "\n", "\n", "", "if", "grad_norms", "is", "None", ":", "\n", "            ", "grad_norms", "=", "[", "None", "]", "*", "len", "(", "self", ".", "param_groups", ")", "\n", "\n", "", "for", "group", ",", "grads_this_group", ",", "grad_norm", "in", "zip", "(", "\n", "self", ".", "param_groups", ",", "grads_group", ",", "grad_norms", "\n", ")", ":", "\n", "            ", "if", "grads_this_group", "is", "None", ":", "\n", "                ", "grads_this_group", "=", "[", "None", "]", "*", "len", "(", "group", "[", "\"params\"", "]", ")", "\n", "\n", "# compute combined scale factor for this group", "\n", "", "combined_scale", "=", "scale", "\n", "if", "group", ".", "get", "(", "\"max_grad_norm\"", ",", "0", ")", ">", "0", ":", "\n", "# norm is in fact norm*scale", "\n", "                ", "clip", "=", "(", "(", "grad_norm", "/", "scale", ")", "+", "1e-6", ")", "/", "group", "[", "\"max_grad_norm\"", "]", "\n", "if", "clip", ">", "1", ":", "\n", "                    ", "combined_scale", "=", "clip", "*", "scale", "\n", "\n", "", "", "bias_correction", "=", "1", "if", "group", ".", "get", "(", "\"bias_correction\"", ",", "1", ")", "else", "0", "\n", "\n", "for", "p", ",", "grad", "in", "zip", "(", "group", "[", "\"params\"", "]", ",", "grads_this_group", ")", ":", "\n", "# note: p.grad should not ever be set for correct", "\n", "# operation of mixed precision optimizer that sometimes", "\n", "# sends None gradients", "\n", "                ", "if", "p", ".", "grad", "is", "None", "and", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "if", "grad", "is", "None", ":", "\n", "                    ", "grad", "=", "p", ".", "grad", ".", "data", "\n", "", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\n", "\"FusedAdam does not support sparse gradients, \"", "\n", "\"please consider SparseAdam instead\"", "\n", ")", "\n", "\n", "", "p_data_fp32", "=", "p", ".", "data", ".", "float", "(", ")", "\n", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "\"step\"", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "\"exp_avg\"", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "\"exp_avg_sq\"", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "", "else", ":", "\n", "                    ", "state", "[", "\"exp_avg\"", "]", "=", "state", "[", "\"exp_avg\"", "]", ".", "to", "(", "p_data_fp32", ")", "\n", "state", "[", "\"exp_avg_sq\"", "]", "=", "state", "[", "\"exp_avg_sq\"", "]", ".", "to", "(", "p_data_fp32", ")", "\n", "\n", "", "exp_avg", "=", "state", "[", "\"exp_avg\"", "]", "\n", "exp_avg_sq", "=", "state", "[", "\"exp_avg_sq\"", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "\"betas\"", "]", "\n", "\n", "state", "[", "\"step\"", "]", "+=", "1", "\n", "\n", "out_p", "=", "p", ".", "data", "\n", "with", "torch", ".", "cuda", ".", "device", "(", "p", ".", "device", ")", ":", "\n", "                    ", "fused_adam_cuda", ".", "adam", "(", "\n", "p_data_fp32", ",", "\n", "out_p", ",", "\n", "exp_avg", ",", "\n", "exp_avg_sq", ",", "\n", "grad", ",", "\n", "group", "[", "\"lr\"", "]", ",", "\n", "beta1", ",", "\n", "beta2", ",", "\n", "group", "[", "\"eps\"", "]", ",", "\n", "combined_scale", ",", "\n", "state", "[", "\"step\"", "]", ",", "\n", "self", ".", "eps_mode", ",", "\n", "bias_correction", ",", "\n", "group", "[", "\"weight_decay\"", "]", ",", "\n", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.fused_adam.get_fused_adam_class": [[11, 38], ["importlib.import_module"], "function", ["None"], ["def", "get_fused_adam_class", "(", ")", ":", "\n", "    ", "\"\"\"\n    Look for the FusedAdam optimizer from apex. We first try to load the\n    \"contrib\" interface, which is a bit faster than the main interface,\n    but is technically deprecated.\n    \"\"\"", "\n", "try", ":", "\n", "# The \"deprecated\" interface in recent versions of apex is a bit", "\n", "# faster than the main interface, since we don't use the apex", "\n", "# optimizer. This can be installed by passing the", "\n", "# `--deprecated_fused_adam` option when building apex.", "\n", "        ", "global", "fused_adam_cuda", "\n", "import", "importlib", "\n", "\n", "fused_adam_cuda", "=", "importlib", ".", "import_module", "(", "\"fused_adam_cuda\"", ")", "\n", "return", "FusedAdamV1", "\n", "", "except", "ImportError", ":", "\n", "        ", "try", ":", "\n", "# fallback to the newer interface", "\n", "            ", "from", "apex", ".", "optimizers", "import", "FusedAdam", "as", "_FusedAdam", "# noqa", "\n", "from", "apex", ".", "multi_tensor_apply", "import", "multi_tensor_applier", "\n", "\n", "if", "multi_tensor_applier", ".", "available", ":", "\n", "                ", "return", "FusedAdamV2", "\n", "", "", "except", "ImportError", ":", "\n", "            ", "pass", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.sgd.SGD.__init__": [[13, 16], ["LegacyFairseqOptimizer.__init__", "torch.optim.SGD"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "_optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "params", ",", "**", "self", ".", "optimizer_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.sgd.SGD.add_args": [[17, 25], ["parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add optimizer-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--momentum'", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "metavar", "=", "'M'", ",", "\n", "help", "=", "'momentum factor'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight-decay'", ",", "'--wd'", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "metavar", "=", "'WD'", ",", "\n", "help", "=", "'weight decay'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.sgd.SGD.optimizer_config": [[27, 39], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a kwarg dictionary that will be used to override optimizer\n        args stored in checkpoints. This allows us to load a checkpoint and\n        resume training using a different set of optimizer args, e.g., with a\n        different learning rate.\n        \"\"\"", "\n", "return", "{", "\n", "\"lr\"", ":", "self", ".", "args", ".", "lr", "[", "0", "]", ",", "\n", "\"momentum\"", ":", "self", ".", "args", ".", "momentum", ",", "\n", "\"weight_decay\"", ":", "self", ".", "args", ".", "weight_decay", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.sgd.SGD.supports_flat_params": [[41, 44], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_flat_params", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.optim.adafactor.FairseqAdafactor.__init__": [[16, 19], ["LegacyFairseqOptimizer.__init__", "adafactor.Adafactor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "_optimizer", "=", "Adafactor", "(", "params", ",", "**", "self", ".", "optimizer_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adafactor.FairseqAdafactor.add_args": [[20, 41], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add optimizer-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--adafactor-eps'", ",", "default", "=", "'(1e-30, 1e-3)'", ",", "metavar", "=", "\"E\"", ",", "\n", "help", "=", "'epsilons for Adafactor optimizer'", ")", "\n", "parser", ".", "add_argument", "(", "'--clip-threshold'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "metavar", "=", "\"C\"", ",", "\n", "help", "=", "'threshold for clipping update root mean square'", ")", "\n", "parser", ".", "add_argument", "(", "'--decay-rate'", ",", "type", "=", "float", ",", "default", "=", "-", "0.8", ",", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "'decay rate of the second moment estimator'", ")", "\n", "parser", ".", "add_argument", "(", "'--beta1'", ",", "type", "=", "float", ",", "default", "=", "None", ",", "metavar", "=", "\"B\"", ",", "\n", "help", "=", "'beta for first moment estimator. Optional'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight-decay'", ",", "'--wd'", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "metavar", "=", "'WD'", ",", "\n", "help", "=", "'weight decay'", ")", "\n", "parser", ".", "add_argument", "(", "'--scale-parameter'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'scale learning rate by root mean square of parameter'", ")", "\n", "parser", ".", "add_argument", "(", "'--relative-step'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'set learning rate to inverse square root of timestep,'", "\n", "'otherwise use external learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup-init'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use relative step for warm-up learning rate schedule'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adafactor.FairseqAdafactor.optimizer_config": [[43, 63], ["eval"], "methods", ["None"], ["", "@", "property", "\n", "def", "optimizer_config", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a kwarg dictionary that will be used to override optimizer\n        args stored in checkpoints. This allows us to load a checkpoint and\n        resume training using a different set of optimizer args, e.g., with a\n        different learning rate.\n        Note : Convergence issues empirically observed with fp16 on.\n               Might require search for appropriate configuration.\n        \"\"\"", "\n", "return", "{", "\n", "\"lr\"", ":", "self", ".", "args", ".", "lr", "[", "0", "]", ",", "\n", "\"eps\"", ":", "eval", "(", "self", ".", "args", ".", "adafactor_eps", ")", ",", "\n", "\"clip_threshold\"", ":", "self", ".", "args", ".", "clip_threshold", ",", "\n", "\"decay_rate\"", ":", "self", ".", "args", ".", "decay_rate", ",", "\n", "\"beta1\"", ":", "self", ".", "args", ".", "beta1", ",", "\n", "\"weight_decay\"", ":", "self", ".", "args", ".", "weight_decay", ",", "\n", "\"scale_parameter\"", ":", "self", ".", "args", ".", "scale_parameter", ",", "# defaults to False", "\n", "\"relative_step\"", ":", "self", ".", "args", ".", "relative_step", ",", "# defaults to False", "\n", "\"warmup_init\"", ":", "self", ".", "args", ".", "warmup_init", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adafactor.Adafactor.__init__": [[100, 130], ["dict", "super().__init__", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "params", ",", "\n", "lr", "=", "None", ",", "\n", "eps", "=", "(", "1e-30", ",", "1e-3", ")", ",", "\n", "clip_threshold", "=", "1.0", ",", "\n", "decay_rate", "=", "-", "0.8", ",", "\n", "beta1", "=", "None", ",", "\n", "weight_decay", "=", "0.0", ",", "\n", "scale_parameter", "=", "True", ",", "\n", "relative_step", "=", "True", ",", "\n", "warmup_init", "=", "False", ",", "\n", ")", ":", "\n", "        ", "if", "lr", "is", "not", "None", "and", "relative_step", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot combine manual lr and relative_step options\"", ")", "\n", "", "if", "warmup_init", "and", "not", "relative_step", ":", "\n", "            ", "raise", "ValueError", "(", "\"warmup_init requires relative_step=True\"", ")", "\n", "\n", "", "defaults", "=", "dict", "(", "\n", "lr", "=", "lr", ",", "\n", "eps", "=", "eps", ",", "\n", "clip_threshold", "=", "clip_threshold", ",", "\n", "decay_rate", "=", "decay_rate", ",", "\n", "beta1", "=", "beta1", ",", "\n", "weight_decay", "=", "weight_decay", ",", "\n", "scale_parameter", "=", "scale_parameter", ",", "\n", "relative_step", "=", "relative_step", ",", "\n", "warmup_init", "=", "warmup_init", ",", "\n", ")", "\n", "super", "(", "Adafactor", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adafactor.Adafactor.supports_memory_efficient_fp16": [[131, 134], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_memory_efficient_fp16", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adafactor.Adafactor.supports_flat_params": [[135, 138], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_flat_params", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adafactor.Adafactor._get_lr": [[139, 150], ["min", "max", "math.sqrt"], "methods", ["None"], ["", "def", "_get_lr", "(", "self", ",", "param_group", ",", "param_state", ")", ":", "\n", "        ", "rel_step_sz", "=", "param_group", "[", "\"lr\"", "]", "\n", "if", "param_group", "[", "\"relative_step\"", "]", ":", "\n", "            ", "min_step", "=", "(", "\n", "1e-6", "*", "param_state", "[", "\"step\"", "]", "if", "param_group", "[", "\"warmup_init\"", "]", "else", "1e-2", "\n", ")", "\n", "rel_step_sz", "=", "min", "(", "min_step", ",", "1.0", "/", "math", ".", "sqrt", "(", "param_state", "[", "\"step\"", "]", ")", ")", "\n", "", "param_scale", "=", "1.0", "\n", "if", "param_group", "[", "\"scale_parameter\"", "]", ":", "\n", "            ", "param_scale", "=", "max", "(", "param_group", "[", "\"eps\"", "]", "[", "1", "]", ",", "param_state", "[", "\"RMS\"", "]", ")", "\n", "", "return", "param_scale", "*", "rel_step_sz", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adafactor.Adafactor._get_options": [[151, 155], ["len"], "methods", ["None"], ["", "def", "_get_options", "(", "self", ",", "param_group", ",", "param_shape", ")", ":", "\n", "        ", "factored", "=", "len", "(", "param_shape", ")", ">=", "2", "\n", "use_first_moment", "=", "param_group", "[", "\"beta1\"", "]", "is", "not", "None", "\n", "return", "factored", ",", "use_first_moment", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adafactor.Adafactor._rms": [[156, 158], ["tensor.norm", "tensor.numel"], "methods", ["None"], ["", "def", "_rms", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "return", "tensor", ".", "norm", "(", "2", ")", "/", "(", "tensor", ".", "numel", "(", ")", "**", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adafactor.Adafactor._approx_sq_grad": [[159, 167], ["exp_avg_sq_col.unsqueeze().rsqrt", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "exp_avg_sq_col.unsqueeze", "exp_avg_sq_row.mean"], "methods", ["None"], ["", "def", "_approx_sq_grad", "(", "self", ",", "exp_avg_sq_row", ",", "exp_avg_sq_col", ")", ":", "\n", "        ", "r_factor", "=", "(", "\n", "(", "exp_avg_sq_row", "/", "exp_avg_sq_row", ".", "mean", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", ")", "\n", ".", "rsqrt_", "(", ")", "\n", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "\n", "c_factor", "=", "exp_avg_sq_col", ".", "unsqueeze", "(", "-", "2", ")", ".", "rsqrt", "(", ")", "\n", "return", "torch", ".", "mul", "(", "r_factor", ",", "c_factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.optim.adafactor.Adafactor.step": [[168, 269], ["closure", "adafactor.Adafactor._get_options", "adafactor.Adafactor._rms", "adafactor.Adafactor._get_lr", "exp_avg_sq.rsqrt().mul_.div_", "exp_avg_sq.rsqrt().mul_.mul_", "p_data_fp32.float.float.add_", "grad.float.float.float", "RuntimeError", "len", "p_data_fp32.float.float.float", "math.pow", "exp_avg_sq_row.mul_().add_", "exp_avg_sq_col.mul_().add_", "adafactor.Adafactor._approx_sq_grad", "exp_avg_sq.rsqrt().mul_.mul_", "exp_avg_sq.mul_().add_", "exp_avg_sq.rsqrt().mul_", "exp_avg.mul_().add_", "p_data_fp32.float.float.add_", "p.data.copy_", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "state[].to", "state[].to", "state[].to", "state[].to", "exp_avg_sq.rsqrt().mul_.mean", "exp_avg_sq.rsqrt().mul_.mean", "exp_avg_sq_row.mul_", "exp_avg_sq_col.mul_", "exp_avg_sq.mul_", "exp_avg_sq.rsqrt", "exp_avg.mul_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "adafactor.Adafactor._rms"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.adafactor.Adafactor._get_options", "home.repos.pwc.inspect_result.reneeye_const.optim.adafactor.Adafactor._rms", "home.repos.pwc.inspect_result.reneeye_const.optim.adafactor.Adafactor._get_lr", "home.repos.pwc.inspect_result.reneeye_const.optim.adafactor.Adafactor._approx_sq_grad", "home.repos.pwc.inspect_result.reneeye_const.optim.adafactor.Adafactor._rms"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "\"params\"", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "dtype", "in", "{", "torch", ".", "float16", ",", "torch", ".", "bfloat16", "}", ":", "\n", "                    ", "grad", "=", "grad", ".", "float", "(", ")", "\n", "", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\"Adafactor does not support sparse gradients.\"", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "grad_shape", "=", "grad", ".", "shape", "\n", "\n", "factored", ",", "use_first_moment", "=", "self", ".", "_get_options", "(", "group", ",", "grad_shape", ")", "\n", "# State Initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "\"step\"", "]", "=", "0", "\n", "\n", "if", "use_first_moment", ":", "\n", "# Exponential moving average of gradient values", "\n", "                        ", "state", "[", "\"exp_avg\"", "]", "=", "torch", ".", "zeros_like", "(", "grad", ")", "\n", "", "if", "factored", ":", "\n", "                        ", "state", "[", "\"exp_avg_sq_row\"", "]", "=", "torch", ".", "zeros", "(", "grad_shape", "[", ":", "-", "1", "]", ")", ".", "to", "(", "grad", ")", "\n", "state", "[", "\"exp_avg_sq_col\"", "]", "=", "torch", ".", "zeros", "(", "\n", "grad_shape", "[", ":", "-", "2", "]", "+", "grad_shape", "[", "-", "1", ":", "]", "\n", ")", ".", "to", "(", "grad", ")", "\n", "", "else", ":", "\n", "                        ", "state", "[", "\"exp_avg_sq\"", "]", "=", "torch", ".", "zeros_like", "(", "grad", ")", "\n", "\n", "", "state", "[", "\"RMS\"", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "if", "use_first_moment", ":", "\n", "                        ", "state", "[", "\"exp_avg\"", "]", "=", "state", "[", "\"exp_avg\"", "]", ".", "to", "(", "grad", ")", "\n", "", "if", "factored", ":", "\n", "                        ", "state", "[", "\"exp_avg_sq_row\"", "]", "=", "state", "[", "\"exp_avg_sq_row\"", "]", ".", "to", "(", "grad", ")", "\n", "state", "[", "\"exp_avg_sq_col\"", "]", "=", "state", "[", "\"exp_avg_sq_col\"", "]", ".", "to", "(", "grad", ")", "\n", "", "else", ":", "\n", "                        ", "state", "[", "\"exp_avg_sq\"", "]", "=", "state", "[", "\"exp_avg_sq\"", "]", ".", "to", "(", "grad", ")", "\n", "\n", "", "", "p_data_fp32", "=", "p", ".", "data", "\n", "if", "p", ".", "data", ".", "dtype", "in", "{", "torch", ".", "float16", ",", "torch", ".", "bfloat16", "}", ":", "\n", "                    ", "p_data_fp32", "=", "p_data_fp32", ".", "float", "(", ")", "\n", "\n", "", "state", "[", "\"step\"", "]", "+=", "1", "\n", "state", "[", "\"RMS\"", "]", "=", "self", ".", "_rms", "(", "p_data_fp32", ")", "\n", "group", "[", "\"lr\"", "]", "=", "self", ".", "_get_lr", "(", "group", ",", "state", ")", "\n", "\n", "beta2t", "=", "1.0", "-", "math", ".", "pow", "(", "state", "[", "\"step\"", "]", ",", "group", "[", "\"decay_rate\"", "]", ")", "\n", "update", "=", "(", "grad", "**", "2", ")", "+", "group", "[", "\"eps\"", "]", "[", "0", "]", "\n", "if", "factored", ":", "\n", "                    ", "exp_avg_sq_row", "=", "state", "[", "\"exp_avg_sq_row\"", "]", "\n", "exp_avg_sq_col", "=", "state", "[", "\"exp_avg_sq_col\"", "]", "\n", "\n", "exp_avg_sq_row", ".", "mul_", "(", "beta2t", ")", ".", "add_", "(", "\n", "update", ".", "mean", "(", "dim", "=", "-", "1", ")", ",", "alpha", "=", "1.0", "-", "beta2t", "\n", ")", "\n", "exp_avg_sq_col", ".", "mul_", "(", "beta2t", ")", ".", "add_", "(", "\n", "update", ".", "mean", "(", "dim", "=", "-", "2", ")", ",", "alpha", "=", "1.0", "-", "beta2t", "\n", ")", "\n", "\n", "# Approximation of exponential moving average of square of gradient", "\n", "update", "=", "self", ".", "_approx_sq_grad", "(", "exp_avg_sq_row", ",", "exp_avg_sq_col", ")", "\n", "update", ".", "mul_", "(", "grad", ")", "\n", "", "else", ":", "\n", "                    ", "exp_avg_sq", "=", "state", "[", "\"exp_avg_sq\"", "]", "\n", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2t", ")", ".", "add_", "(", "update", ",", "alpha", "=", "1.0", "-", "beta2t", ")", "\n", "update", "=", "exp_avg_sq", ".", "rsqrt", "(", ")", ".", "mul_", "(", "grad", ")", "\n", "\n", "", "update", ".", "div_", "(", "\n", "(", "self", ".", "_rms", "(", "update", ")", "/", "group", "[", "\"clip_threshold\"", "]", ")", ".", "clamp_", "(", "min", "=", "1.0", ")", "\n", ")", "\n", "update", ".", "mul_", "(", "group", "[", "\"lr\"", "]", ")", "\n", "\n", "if", "use_first_moment", ":", "\n", "                    ", "exp_avg", "=", "state", "[", "\"exp_avg\"", "]", "\n", "exp_avg", ".", "mul_", "(", "group", "[", "\"beta1\"", "]", ")", ".", "add_", "(", "update", ",", "alpha", "=", "1", "-", "group", "[", "\"beta1\"", "]", ")", "\n", "update", "=", "exp_avg", "\n", "\n", "", "if", "group", "[", "\"weight_decay\"", "]", "!=", "0", ":", "\n", "                    ", "p_data_fp32", ".", "add_", "(", "\n", "p_data_fp32", ",", "alpha", "=", "-", "group", "[", "\"weight_decay\"", "]", "*", "group", "[", "\"lr\"", "]", "\n", ")", "\n", "\n", "", "p_data_fp32", ".", "add_", "(", "-", "update", ")", "\n", "\n", "if", "p", ".", "data", ".", "dtype", "in", "{", "torch", ".", "float16", ",", "torch", ".", "bfloat16", "}", ":", "\n", "                    ", "p", ".", "data", ".", "copy_", "(", "p_data_fp32", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.reduce_lr_on_plateau.ReduceLROnPlateau.__init__": [[29, 60], ["LegacyFairseqLRScheduler.__init__", "torch.optim.lr_scheduler.ReduceLROnPlateau", "reduce_lr_on_plateau.ReduceLROnPlateau.optimizer.set_lr", "len", "ValueError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["def", "__init__", "(", "self", ",", "args", ",", "optimizer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "optimizer", ")", "\n", "if", "len", "(", "args", ".", "lr", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Cannot use a fixed learning rate schedule with reduce_lr_on_plateau.\"", "\n", "\" Consider --lr-scheduler=fixed instead.\"", "\n", ")", "\n", "", "self", ".", "lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "\n", "self", ".", "optimizer", ".", "optimizer", ",", "\n", "patience", "=", "args", ".", "lr_patience", ",", "\n", "factor", "=", "args", ".", "lr_shrink", ",", "\n", "mode", "=", "\"max\"", "if", "args", ".", "maximize_best_checkpoint_metric", "else", "\"min\"", ",", "\n", "threshold", "=", "args", ".", "lr_threshold", ",", "\n", ")", "\n", "warmup_end_lr", "=", "args", ".", "lr", "[", "0", "]", "\n", "# if no warm up, sets initial lr to be args.lr[0]", "\n", "if", "args", ".", "warmup_init_lr", "<", "0", ":", "\n", "            ", "args", ".", "warmup_init_lr", "=", "0", "if", "args", ".", "warmup_updates", ">", "0", "else", "warmup_end_lr", "\n", "\n", "# linearly warmup for the first args.warmup_updates", "\n", "", "if", "args", ".", "warmup_updates", ">", "0", ":", "\n", "            ", "self", ".", "lr_step", "=", "(", "warmup_end_lr", "-", "args", ".", "warmup_init_lr", ")", "/", "args", ".", "warmup_updates", "\n", "\n", "# this flag is either set from arg when no warm up, or set by", "\n", "# step_update() when warmup finishes", "\n", "", "self", ".", "warmup_end", "=", "True", "if", "args", ".", "warmup_updates", "<=", "0", "else", "False", "\n", "\n", "# initial learning rate", "\n", "# this self.lr is used only during init and/or warm up period", "\n", "self", ".", "lr", "=", "args", ".", "warmup_init_lr", "\n", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.reduce_lr_on_plateau.ReduceLROnPlateau.add_args": [[61, 77], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add arguments to the parser for this LR scheduler.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--lr-shrink'", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "metavar", "=", "'LS'", ",", "\n", "help", "=", "'shrink factor for annealing, lr_new = (lr * lr_shrink)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr-threshold'", ",", "default", "=", "1e-4", ",", "type", "=", "float", ",", "metavar", "=", "'LT'", ",", "\n", "help", "=", "'threshold for measuring the new optimum, '", "\n", "'to only focus on significant changes'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr-patience'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of epochs with no improvement after which '", "\n", "'learning rate will be reduced'", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup-updates'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'warmup the learning rate linearly for the first N updates'", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup-init-lr'", ",", "default", "=", "-", "1", ",", "type", "=", "float", ",", "metavar", "=", "'LR'", ",", "\n", "help", "=", "'initial learning rate during warmup phase; default is args.lr'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.reduce_lr_on_plateau.ReduceLROnPlateau.state_dict": [[79, 84], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the LR scheduler state dict.\"\"\"", "\n", "return", "{", "\n", "\"best\"", ":", "self", ".", "lr_scheduler", ".", "best", ",", "\n", "\"last_epoch\"", ":", "self", ".", "lr_scheduler", ".", "last_epoch", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.reduce_lr_on_plateau.ReduceLROnPlateau.load_state_dict": [[86, 91], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Load an LR scheduler state dict.\"\"\"", "\n", "self", ".", "lr_scheduler", ".", "best", "=", "state_dict", "[", "\"best\"", "]", "\n", "if", "\"last_epoch\"", "in", "state_dict", ":", "\n", "            ", "self", ".", "lr_scheduler", ".", "last_epoch", "=", "state_dict", "[", "\"last_epoch\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.reduce_lr_on_plateau.ReduceLROnPlateau.step": [[92, 102], ["reduce_lr_on_plateau.ReduceLROnPlateau.optimizer.get_lr", "reduce_lr_on_plateau.ReduceLROnPlateau.lr_scheduler.step"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr", "home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step"], ["", "", "def", "step", "(", "self", ",", "epoch", ",", "val_loss", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Update the learning rate at the end of the given epoch if warmup\n        finishes otherwise no update of lr on epoch boundaries\n        \"\"\"", "\n", "if", "val_loss", "is", "not", "None", "and", "self", ".", "warmup_end", "is", "True", ":", "\n", "            ", "self", ".", "lr_scheduler", ".", "step", "(", "val_loss", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "lr_scheduler", ".", "last_epoch", "=", "epoch", "\n", "", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.reduce_lr_on_plateau.ReduceLROnPlateau.step_update": [[103, 116], ["reduce_lr_on_plateau.ReduceLROnPlateau.optimizer.get_lr", "reduce_lr_on_plateau.ReduceLROnPlateau.optimizer.set_lr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["", "def", "step_update", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"\n        Update the learning rate after each update.\"\"\"", "\n", "# if there is warmup", "\n", "if", "self", ".", "args", ".", "warmup_updates", ">", "0", ":", "\n", "            ", "if", "num_updates", "<=", "self", ".", "args", ".", "warmup_updates", ":", "\n", "                ", "self", ".", "lr", "=", "self", ".", "args", ".", "warmup_init_lr", "+", "num_updates", "*", "self", ".", "lr_step", "\n", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "lr", ")", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "warmup_end", "is", "False", ":", "\n", "                    ", "self", ".", "warmup_end", "=", "True", "\n", "# else do nothing", "\n", "", "", "", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.inverse_square_root_schedule.InverseSquareRootSchedule.__init__": [[52, 80], ["FairseqLRScheduler.__init__", "inverse_square_root_schedule.InverseSquareRootSchedule.optimizer.set_lr", "isinstance", "ValueError", "isinstance", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "optimizer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "optimizer", ")", "\n", "if", "isinstance", "(", "cfg", ".", "lr", ",", "Collection", ")", "and", "len", "(", "cfg", ".", "lr", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Cannot use a fixed learning rate schedule with inverse_sqrt.\"", "\n", "\" Consider --lr-scheduler=fixed instead.\"", "\n", ")", "\n", "", "warmup_end_lr", "=", "(", "\n", "cfg", ".", "lr", "[", "0", "]", "\n", "if", "isinstance", "(", "cfg", ".", "lr", ",", "Collection", ")", "\n", "else", "cfg", ".", "lr", "\n", ")", "\n", "if", "cfg", ".", "warmup_init_lr", "<", "0", ":", "\n", "            ", "cfg", ".", "warmup_init_lr", "=", "(", "\n", "0", "if", "cfg", ".", "warmup_updates", ">", "0", "else", "warmup_end_lr", "\n", ")", "\n", "\n", "# linearly warmup for the first args.warmup_updates", "\n", "", "self", ".", "lr_step", "=", "(", "\n", "warmup_end_lr", "-", "cfg", ".", "warmup_init_lr", "\n", ")", "/", "cfg", ".", "warmup_updates", "\n", "\n", "# then, decay prop. to the inverse square root of the update number", "\n", "self", ".", "decay_factor", "=", "warmup_end_lr", "*", "cfg", ".", "warmup_updates", "**", "0.5", "\n", "\n", "# initial learning rate", "\n", "self", ".", "lr", "=", "cfg", ".", "warmup_init_lr", "\n", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.inverse_square_root_schedule.InverseSquareRootSchedule.step": [[81, 86], ["super().step", "inverse_square_root_schedule.InverseSquareRootSchedule.optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "step", "(", "self", ",", "epoch", ",", "val_loss", "=", "None", ")", ":", "\n", "        ", "\"\"\"Update the learning rate at the end of the given epoch.\"\"\"", "\n", "super", "(", ")", ".", "step", "(", "epoch", ",", "val_loss", ")", "\n", "# we don't change the learning rate at epoch boundaries", "\n", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.inverse_square_root_schedule.InverseSquareRootSchedule.step_update": [[87, 95], ["inverse_square_root_schedule.InverseSquareRootSchedule.optimizer.set_lr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["", "def", "step_update", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Update the learning rate after each update.\"\"\"", "\n", "if", "num_updates", "<", "self", ".", "cfg", ".", "warmup_updates", ":", "\n", "            ", "self", ".", "lr", "=", "self", ".", "cfg", ".", "warmup_init_lr", "+", "num_updates", "*", "self", ".", "lr_step", "\n", "", "else", ":", "\n", "            ", "self", ".", "lr", "=", "self", ".", "decay_factor", "*", "num_updates", "**", "-", "0.5", "\n", "", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "lr", ")", "\n", "return", "self", ".", "lr", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.fairseq_lr_scheduler.FairseqLRScheduler.__init__": [[14, 21], ["object.__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "optimizer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "not", "isinstance", "(", "optimizer", ",", "FairseqOptimizer", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"optimizer must be an instance of FairseqOptimizer\"", ")", "\n", "", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "best", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.fairseq_lr_scheduler.FairseqLRScheduler.add_args": [[22, 28], ["getattr", "fairseq.dataclass.utils.gen_parser_from_dataclass", "getattr."], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.gen_parser_from_dataclass"], ["", "@", "classmethod", "\n", "def", "add_args", "(", "cls", ",", "parser", ")", ":", "\n", "        ", "\"\"\"Add arguments to the parser for this LR scheduler.\"\"\"", "\n", "dc", "=", "getattr", "(", "cls", ",", "\"__dataclass\"", ",", "None", ")", "\n", "if", "dc", "is", "not", "None", ":", "\n", "            ", "gen_parser_from_dataclass", "(", "parser", ",", "dc", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.fairseq_lr_scheduler.FairseqLRScheduler.state_dict": [[29, 32], ["None"], "methods", ["None"], ["", "", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the LR scheduler state dict.\"\"\"", "\n", "return", "{", "\"best\"", ":", "self", ".", "best", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.fairseq_lr_scheduler.FairseqLRScheduler.load_state_dict": [[33, 36], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Load an LR scheduler state dict.\"\"\"", "\n", "self", ".", "best", "=", "state_dict", "[", "\"best\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.fairseq_lr_scheduler.FairseqLRScheduler.step_begin_epoch": [[37, 40], ["None"], "methods", ["None"], ["", "def", "step_begin_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Update the learning rate at the beginning of the given epoch.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.fairseq_lr_scheduler.FairseqLRScheduler.step": [[41, 48], ["min"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "epoch", ",", "val_loss", "=", "None", ")", ":", "\n", "        ", "\"\"\"Update the learning rate at the end of the given epoch.\"\"\"", "\n", "if", "val_loss", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "best", "is", "None", ":", "\n", "                ", "self", ".", "best", "=", "val_loss", "\n", "", "else", ":", "\n", "                ", "self", ".", "best", "=", "min", "(", "self", ".", "best", ",", "val_loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.fairseq_lr_scheduler.FairseqLRScheduler.step_update": [[49, 52], ["fairseq_lr_scheduler.FairseqLRScheduler.optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "", "", "def", "step_update", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Update the learning rate after each update.\"\"\"", "\n", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.fairseq_lr_scheduler.LegacyFairseqLRScheduler.__init__": [[55, 61], ["isinstance", "ValueError"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ":", "Namespace", ",", "optimizer", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "optimizer", ",", "FairseqOptimizer", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"optimizer must be an instance of FairseqOptimizer\"", ")", "\n", "", "self", ".", "args", "=", "args", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "best", "=", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.fixed_schedule.FixedSchedule.__init__": [[13, 24], ["LegacyFairseqLRScheduler.__init__", "getattr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "args", ",", "optimizer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "optimizer", ")", "\n", "\n", "# set defaults", "\n", "args", ".", "warmup_updates", "=", "getattr", "(", "args", ",", "\"warmup_updates\"", ",", "0", ")", "or", "0", "\n", "\n", "self", ".", "lr", "=", "args", ".", "lr", "[", "0", "]", "\n", "if", "args", ".", "warmup_updates", ">", "0", ":", "\n", "            ", "self", ".", "warmup_factor", "=", "1.0", "/", "args", ".", "warmup_updates", "\n", "", "else", ":", "\n", "            ", "self", ".", "warmup_factor", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.fixed_schedule.FixedSchedule.add_args": [[25, 35], ["parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add arguments to the parser for this LR scheduler.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--force-anneal'", ",", "'--fa'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'force annealing at specified epoch (epochs start at 1)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr-shrink'", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "metavar", "=", "'LS'", ",", "\n", "help", "=", "'shrink factor for annealing, lr_new = (lr * lr_shrink)'", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup-updates'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'warmup the learning rate linearly for the first N updates'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.fixed_schedule.FixedSchedule.state_dict": [[37, 39], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "\"lr\"", ":", "self", ".", "lr", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.fixed_schedule.FixedSchedule.load_state_dict": [[40, 43], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "if", "\"lr\"", "in", "state_dict", ":", "\n", "            ", "self", ".", "lr", "=", "state_dict", "[", "\"lr\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.fixed_schedule.FixedSchedule.get_next_lr": [[44, 55], ["min", "len"], "methods", ["None"], ["", "", "def", "get_next_lr", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "lrs", "=", "self", ".", "args", ".", "lr", "\n", "if", "self", ".", "args", ".", "force_anneal", "is", "None", "or", "epoch", "<", "self", ".", "args", ".", "force_anneal", ":", "\n", "# use fixed LR schedule", "\n", "            ", "next_lr", "=", "lrs", "[", "min", "(", "epoch", "-", "1", ",", "len", "(", "lrs", ")", "-", "1", ")", "]", "\n", "", "else", ":", "\n", "# annneal based on lr_shrink", "\n", "            ", "next_lr", "=", "lrs", "[", "-", "1", "]", "*", "self", ".", "args", ".", "lr_shrink", "**", "(", "\n", "epoch", "+", "1", "-", "self", ".", "args", ".", "force_anneal", "\n", ")", "\n", "", "return", "next_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.fixed_schedule.FixedSchedule.step_begin_epoch": [[56, 61], ["fixed_schedule.FixedSchedule.get_next_lr", "fixed_schedule.FixedSchedule.optimizer.set_lr", "fixed_schedule.FixedSchedule.optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.get_next_lr", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "step_begin_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Update the learning rate at the beginning of the given epoch.\"\"\"", "\n", "self", ".", "lr", "=", "self", ".", "get_next_lr", "(", "epoch", ")", "\n", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "warmup_factor", "*", "self", ".", "lr", ")", "\n", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.fixed_schedule.FixedSchedule.step_update": [[62, 70], ["fixed_schedule.FixedSchedule.optimizer.get_lr", "fixed_schedule.FixedSchedule.optimizer.set_lr", "fixed_schedule.FixedSchedule.optimizer.set_lr", "float"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["", "def", "step_update", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Update the learning rate after each update.\"\"\"", "\n", "if", "self", ".", "args", ".", "warmup_updates", ">", "0", "and", "num_updates", "<", "self", ".", "args", ".", "warmup_updates", ":", "\n", "            ", "self", ".", "warmup_factor", "=", "(", "num_updates", "+", "1", ")", "/", "float", "(", "self", ".", "args", ".", "warmup_updates", ")", "\n", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "warmup_factor", "*", "self", ".", "lr", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "lr", ")", "\n", "", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.__init__.build_lr_scheduler": [[28, 30], ["build_lr_scheduler_"], "function", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.triangular_lr_scheduler.TriangularSchedule.__init__": [[18, 38], ["LegacyFairseqLRScheduler.__init__", "triangular_lr_scheduler.TriangularSchedule.optimizer.set_lr", "len", "ValueError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["def", "__init__", "(", "self", ",", "args", ",", "optimizer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "optimizer", ")", "\n", "if", "len", "(", "args", ".", "lr", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Cannot use a fixed learning rate schedule with triangular.\"", "\n", "\" Consider --lr-scheduler=fixed instead.\"", "\n", ")", "\n", "\n", "", "lr", "=", "args", ".", "lr", "[", "0", "]", "\n", "\n", "assert", "args", ".", "max_lr", ">", "lr", ",", "\"max_lr must be more than lr\"", "\n", "self", ".", "min_lr", "=", "lr", "\n", "self", ".", "max_lr", "=", "args", ".", "max_lr", "\n", "self", ".", "stepsize", "=", "args", ".", "lr_period_updates", "//", "2", "\n", "self", ".", "lr_shrink", "=", "args", ".", "lr_shrink", "\n", "self", ".", "shrink_min", "=", "args", ".", "shrink_min", "\n", "\n", "# initial learning rate", "\n", "self", ".", "lr", "=", "self", ".", "min_lr", "\n", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.triangular_lr_scheduler.TriangularSchedule.add_args": [[39, 51], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add arguments to the parser for this LR scheduler.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--max-lr'", ",", "required", "=", "True", ",", "type", "=", "float", ",", "metavar", "=", "'LR'", ",", "\n", "help", "=", "'max learning rate, must be more than args.lr'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr-period-updates'", ",", "default", "=", "5000", ",", "type", "=", "float", ",", "metavar", "=", "'LR'", ",", "\n", "help", "=", "'initial number of updates per period (cycle length)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr-shrink'", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "metavar", "=", "'LS'", ",", "\n", "help", "=", "'shrink factor for annealing'", ")", "\n", "parser", ".", "add_argument", "(", "'--shrink-min'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'if set, also shrinks min lr'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.triangular_lr_scheduler.TriangularSchedule.step": [[53, 58], ["super().step", "triangular_lr_scheduler.TriangularSchedule.optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "step", "(", "self", ",", "epoch", ",", "val_loss", "=", "None", ")", ":", "\n", "        ", "\"\"\"Update the learning rate at the end of the given epoch.\"\"\"", "\n", "super", "(", ")", ".", "step", "(", "epoch", ",", "val_loss", ")", "\n", "# we don't change the learning rate at epoch boundaries", "\n", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.triangular_lr_scheduler.TriangularSchedule.step_update": [[59, 75], ["math.floor", "abs", "triangular_lr_scheduler.TriangularSchedule.optimizer.set_lr", "max"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["", "def", "step_update", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Update the learning rate after each update.\"\"\"", "\n", "cycle", "=", "math", ".", "floor", "(", "num_updates", "/", "(", "2", "*", "self", ".", "stepsize", ")", ")", "\n", "\n", "lr_shrink", "=", "self", ".", "lr_shrink", "**", "cycle", "\n", "max_lr", "=", "self", ".", "max_lr", "*", "lr_shrink", "\n", "if", "self", ".", "shrink_min", ":", "\n", "            ", "min_lr", "=", "self", ".", "min_lr", "*", "lr_shrink", "\n", "", "else", ":", "\n", "            ", "min_lr", "=", "self", ".", "min_lr", "\n", "\n", "", "x", "=", "abs", "(", "num_updates", "/", "self", ".", "stepsize", "-", "2", "*", "(", "cycle", "+", "1", ")", "+", "1", ")", "\n", "self", ".", "lr", "=", "min_lr", "+", "(", "max_lr", "-", "min_lr", ")", "*", "max", "(", "0", ",", "(", "1", "-", "x", ")", ")", "\n", "\n", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "lr", ")", "\n", "return", "self", ".", "lr", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.tri_stage_lr_scheduler.TriStageLRScheduleConfig.__init__": [[86, 121], ["FairseqLRScheduler.__init__", "tri_stage_lr_scheduler.TriStageLRScheduleConfig.optimizer.set_lr", "len", "ValueError", "int", "int", "int", "sum", "math.log"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log"], ["def", "__init__", "(", "self", ",", "cfg", ":", "TriStageLRScheduleConfig", ",", "optimizer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "optimizer", ")", "\n", "if", "len", "(", "cfg", ".", "lr", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Cannot use a fixed learning rate schedule with tri-stage lr.\"", "\n", "\" Consider --lr-scheduler=fixed instead.\"", "\n", ")", "\n", "\n", "# calculate LR at each point", "\n", "", "self", ".", "peak_lr", "=", "cfg", ".", "lr", "[", "0", "]", "\n", "self", ".", "init_lr", "=", "cfg", ".", "init_lr_scale", "*", "cfg", ".", "lr", "[", "0", "]", "\n", "self", ".", "final_lr", "=", "cfg", ".", "final_lr_scale", "*", "cfg", ".", "lr", "[", "0", "]", "\n", "\n", "if", "cfg", ".", "phase_ratio", "is", "not", "None", ":", "\n", "            ", "assert", "sum", "(", "cfg", ".", "phase_ratio", ")", "==", "1", ",", "'phase ratios must add up to 1'", "\n", "self", ".", "warmup_steps", "=", "int", "(", "cfg", ".", "max_update", "*", "cfg", ".", "phase_ratio", "[", "0", "]", ")", "\n", "self", ".", "hold_steps", "=", "int", "(", "cfg", ".", "max_update", "*", "cfg", ".", "phase_ratio", "[", "1", "]", ")", "\n", "self", ".", "decay_steps", "=", "int", "(", "cfg", ".", "max_update", "*", "cfg", ".", "phase_ratio", "[", "2", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "warmup_steps", "=", "cfg", ".", "warmup_steps", "\n", "self", ".", "hold_steps", "=", "cfg", ".", "hold_steps", "\n", "self", ".", "decay_steps", "=", "cfg", ".", "decay_steps", "\n", "\n", "", "assert", "self", ".", "warmup_steps", "+", "self", ".", "hold_steps", "+", "self", ".", "decay_steps", ">", "0", ",", "\"please specify steps or phase_ratio\"", "\n", "\n", "self", ".", "warmup_rate", "=", "(", "\n", "(", "self", ".", "peak_lr", "-", "self", ".", "init_lr", ")", "/", "self", ".", "warmup_steps", "\n", "if", "self", ".", "warmup_steps", "!=", "0", "\n", "else", "0", "\n", ")", "\n", "self", ".", "decay_factor", "=", "-", "math", ".", "log", "(", "cfg", ".", "final_lr_scale", ")", "/", "self", ".", "decay_steps", "\n", "\n", "# initial learning rate", "\n", "self", ".", "lr", "=", "self", ".", "init_lr", "\n", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.tri_stage_lr_scheduler.TriStageLRScheduleConfig._decide_stage": [[122, 146], ["None"], "methods", ["None"], ["", "def", "_decide_stage", "(", "self", ",", "update_step", ")", ":", "\n", "        ", "\"\"\"\n        return stage, and the corresponding steps within the current stage\n        \"\"\"", "\n", "if", "update_step", "<", "self", ".", "warmup_steps", ":", "\n", "# warmup state", "\n", "            ", "return", "0", ",", "update_step", "\n", "\n", "", "offset", "=", "self", ".", "warmup_steps", "\n", "\n", "if", "update_step", "<", "offset", "+", "self", ".", "hold_steps", ":", "\n", "# hold stage", "\n", "            ", "return", "1", ",", "update_step", "-", "offset", "\n", "\n", "", "offset", "+=", "self", ".", "hold_steps", "\n", "\n", "if", "update_step", "<=", "offset", "+", "self", ".", "decay_steps", ":", "\n", "# decay stage", "\n", "            ", "return", "2", ",", "update_step", "-", "offset", "\n", "\n", "", "offset", "+=", "self", ".", "decay_steps", "\n", "\n", "# still here ? constant lr stage", "\n", "return", "3", ",", "update_step", "-", "offset", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.tri_stage_lr_scheduler.TriStageLRScheduleConfig.step": [[147, 152], ["super().step", "tri_stage_lr_scheduler.TriStageLRScheduleConfig.optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "step", "(", "self", ",", "epoch", ",", "val_loss", "=", "None", ")", ":", "\n", "        ", "\"\"\"Update the learning rate at the end of the given epoch.\"\"\"", "\n", "super", "(", ")", ".", "step", "(", "epoch", ",", "val_loss", ")", "\n", "# we don't change the learning rate at epoch boundaries", "\n", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.tri_stage_lr_scheduler.TriStageLRScheduleConfig.step_update": [[153, 170], ["tri_stage_lr_scheduler.TriStageLRScheduleConfig._decide_stage", "tri_stage_lr_scheduler.TriStageLRScheduleConfig.optimizer.set_lr", "math.exp", "ValueError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.tri_stage_lr_scheduler.TriStageLRScheduleConfig._decide_stage", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["", "def", "step_update", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Update the learning rate after each update.\"\"\"", "\n", "stage", ",", "steps_in_stage", "=", "self", ".", "_decide_stage", "(", "num_updates", ")", "\n", "if", "stage", "==", "0", ":", "\n", "            ", "self", ".", "lr", "=", "self", ".", "init_lr", "+", "self", ".", "warmup_rate", "*", "steps_in_stage", "\n", "", "elif", "stage", "==", "1", ":", "\n", "            ", "self", ".", "lr", "=", "self", ".", "peak_lr", "\n", "", "elif", "stage", "==", "2", ":", "\n", "            ", "self", ".", "lr", "=", "self", ".", "peak_lr", "*", "math", ".", "exp", "(", "-", "self", ".", "decay_factor", "*", "steps_in_stage", ")", "\n", "", "elif", "stage", "==", "3", ":", "\n", "            ", "self", ".", "lr", "=", "self", ".", "final_lr", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Undefined stage\"", ")", "\n", "\n", "", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "lr", ")", "\n", "\n", "return", "self", ".", "lr", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.cosine_lr_scheduler.CosineSchedule.__init__": [[70, 116], ["FairseqLRScheduler.__init__", "cosine_lr_scheduler.CosineSchedule.optimizer.set_lr", "isinstance", "ValueError", "isinstance", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["def", "__init__", "(", "\n", "self", ",", "cfg", ":", "DictConfig", ",", "fairseq_optimizer", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "fairseq_optimizer", ")", "\n", "if", "isinstance", "(", "cfg", ".", "lr", ",", "Collection", ")", "and", "len", "(", "cfg", ".", "lr", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Cannot use a fixed learning rate schedule with cosine.\"", "\n", "f\" Consider --lr-scheduler=fixed instead. ({cfg.lr})\"", "\n", ")", "\n", "\n", "", "warmup_end_lr", "=", "cfg", ".", "max_lr", "\n", "lr", "=", "(", "\n", "cfg", ".", "lr", "[", "0", "]", "\n", "if", "isinstance", "(", "cfg", ".", "lr", ",", "Collection", ")", "\n", "else", "cfg", ".", "lr", "\n", ")", "\n", "if", "cfg", ".", "warmup_init_lr", "<", "0", ":", "\n", "            ", "cfg", ".", "warmup_init_lr", "=", "lr", "\n", "\n", "", "self", ".", "min_lr", "=", "lr", "\n", "self", ".", "max_lr", "=", "cfg", ".", "max_lr", "\n", "assert", "self", ".", "max_lr", ">", "self", ".", "min_lr", ",", "\"max_lr must be more than lr\"", "\n", "\n", "self", ".", "t_mult", "=", "cfg", ".", "t_mult", "\n", "self", ".", "period", "=", "cfg", ".", "lr_period_updates", "\n", "\n", "if", "self", ".", "period", "<=", "0", ":", "\n", "            ", "assert", "(", "\n", "cfg", ".", "max_update", ">=", "0", "\n", ")", ",", "\"Either --max_update or --lr-period-updates must be set\"", "\n", "self", ".", "period", "=", "cfg", ".", "max_update", "-", "cfg", ".", "warmup_updates", "\n", "\n", "", "if", "cfg", ".", "warmup_updates", ">", "0", ":", "\n", "# linearly warmup for the first args.warmup_updates", "\n", "            ", "self", ".", "lr_step", "=", "(", "\n", "warmup_end_lr", "-", "cfg", ".", "warmup_init_lr", "\n", ")", "/", "cfg", ".", "warmup_updates", "\n", "", "else", ":", "\n", "            ", "self", ".", "lr_step", "=", "1", "\n", "\n", "", "self", ".", "warmup_updates", "=", "cfg", ".", "warmup_updates", "\n", "self", ".", "lr_shrink", "=", "cfg", ".", "lr_shrink", "\n", "\n", "# initial learning rate", "\n", "self", ".", "lr", "=", "cfg", ".", "warmup_init_lr", "\n", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.cosine_lr_scheduler.CosineSchedule.step": [[117, 122], ["super().step", "cosine_lr_scheduler.CosineSchedule.optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "step", "(", "self", ",", "epoch", ",", "val_loss", "=", "None", ")", ":", "\n", "        ", "\"\"\"Update the learning rate at the end of the given epoch.\"\"\"", "\n", "super", "(", ")", ".", "step", "(", "epoch", ",", "val_loss", ")", "\n", "# we don't change the learning rate at epoch boundaries", "\n", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.cosine_lr_scheduler.CosineSchedule.step_update": [[123, 155], ["cosine_lr_scheduler.CosineSchedule.optimizer.set_lr", "math.floor", "math.floor", "math.log", "math.cos"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log"], ["", "def", "step_update", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Update the learning rate after each update.\"\"\"", "\n", "if", "num_updates", "<", "self", ".", "cfg", ".", "warmup_updates", ":", "\n", "            ", "self", ".", "lr", "=", "self", ".", "cfg", ".", "warmup_init_lr", "+", "num_updates", "*", "self", ".", "lr_step", "\n", "", "else", ":", "\n", "            ", "curr_updates", "=", "num_updates", "-", "self", ".", "cfg", ".", "warmup_updates", "\n", "if", "self", ".", "t_mult", "!=", "1", ":", "\n", "                ", "i", "=", "math", ".", "floor", "(", "\n", "math", ".", "log", "(", "\n", "1", "-", "curr_updates", "/", "self", ".", "period", "*", "(", "1", "-", "self", ".", "t_mult", ")", ",", "self", ".", "t_mult", "\n", ")", "\n", ")", "\n", "t_i", "=", "self", ".", "t_mult", "**", "i", "*", "self", ".", "period", "\n", "t_curr", "=", "(", "\n", "curr_updates", "\n", "-", "(", "1", "-", "self", ".", "t_mult", "**", "i", ")", "/", "(", "1", "-", "self", ".", "t_mult", ")", "*", "self", ".", "period", "\n", ")", "\n", "", "else", ":", "\n", "                ", "i", "=", "math", ".", "floor", "(", "curr_updates", "/", "self", ".", "period", ")", "\n", "t_i", "=", "self", ".", "period", "\n", "t_curr", "=", "curr_updates", "-", "(", "self", ".", "period", "*", "i", ")", "\n", "\n", "", "lr_shrink", "=", "self", ".", "lr_shrink", "**", "i", "\n", "min_lr", "=", "self", ".", "min_lr", "*", "lr_shrink", "\n", "max_lr", "=", "self", ".", "max_lr", "*", "lr_shrink", "\n", "\n", "self", ".", "lr", "=", "min_lr", "+", "0.5", "*", "(", "max_lr", "-", "min_lr", ")", "*", "(", "\n", "1", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "t_curr", "/", "t_i", ")", "\n", ")", "\n", "\n", "", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "lr", ")", "\n", "return", "self", ".", "lr", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.__init__": [[42, 56], ["FairseqLRScheduler.__init__", "polynomial_decay_schedule.PolynomialDecaySchedule.optimizer.set_lr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr"], ["def", "__init__", "(", "self", ",", "cfg", ":", "PolynomialDecayScheduleConfig", ",", "optimizer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "optimizer", ")", "\n", "\n", "assert", "cfg", ".", "total_num_update", ">", "0", "\n", "\n", "self", ".", "lr", "=", "cfg", ".", "lr", "[", "0", "]", "\n", "if", "cfg", ".", "warmup_updates", ">", "0", ":", "\n", "            ", "self", ".", "warmup_factor", "=", "1.0", "/", "cfg", ".", "warmup_updates", "\n", "", "else", ":", "\n", "            ", "self", ".", "warmup_factor", "=", "1", "\n", "", "self", ".", "end_learning_rate", "=", "cfg", ".", "end_learning_rate", "\n", "self", ".", "total_num_update", "=", "cfg", ".", "total_num_update", "\n", "self", ".", "power", "=", "cfg", ".", "power", "\n", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "warmup_factor", "*", "self", ".", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.get_next_lr": [[57, 66], ["polynomial_decay_schedule.PolynomialDecaySchedule.optimizer.get_lr", "min", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "get_next_lr", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "lrs", "=", "self", ".", "cfg", ".", "lr", "\n", "if", "self", ".", "cfg", ".", "force_anneal", "is", "None", "or", "epoch", "<", "self", ".", "cfg", ".", "force_anneal", ":", "\n", "# use fixed LR schedule", "\n", "            ", "next_lr", "=", "lrs", "[", "min", "(", "epoch", ",", "len", "(", "lrs", ")", "-", "1", ")", "]", "\n", "", "else", ":", "\n", "# annneal based on lr_shrink", "\n", "            ", "next_lr", "=", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "", "return", "next_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step_begin_epoch": [[67, 72], ["polynomial_decay_schedule.PolynomialDecaySchedule.get_next_lr", "polynomial_decay_schedule.PolynomialDecaySchedule.optimizer.set_lr", "polynomial_decay_schedule.PolynomialDecaySchedule.optimizer.get_lr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.get_next_lr", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "step_begin_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Update the learning rate at the beginning of the given epoch.\"\"\"", "\n", "self", ".", "lr", "=", "self", ".", "get_next_lr", "(", "epoch", ")", "\n", "self", ".", "optimizer", ".", "set_lr", "(", "self", ".", "warmup_factor", "*", "self", ".", "lr", ")", "\n", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lr_scheduler.polynomial_decay_schedule.PolynomialDecaySchedule.step_update": [[73, 89], ["polynomial_decay_schedule.PolynomialDecaySchedule.optimizer.set_lr", "polynomial_decay_schedule.PolynomialDecaySchedule.optimizer.get_lr", "float"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.set_lr", "home.repos.pwc.inspect_result.reneeye_const.optim.fp16_optimizer.MemoryEfficientFP16Optimizer.get_lr"], ["", "def", "step_update", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Update the learning rate after each update.\"\"\"", "\n", "if", "self", ".", "cfg", ".", "warmup_updates", ">", "0", "and", "num_updates", "<=", "self", ".", "cfg", ".", "warmup_updates", ":", "\n", "            ", "self", ".", "warmup_factor", "=", "num_updates", "/", "float", "(", "self", ".", "cfg", ".", "warmup_updates", ")", "\n", "lr", "=", "self", ".", "warmup_factor", "*", "self", ".", "lr", "\n", "", "elif", "num_updates", ">=", "self", ".", "total_num_update", ":", "\n", "            ", "lr", "=", "self", ".", "end_learning_rate", "\n", "", "else", ":", "\n", "            ", "warmup", "=", "self", ".", "cfg", ".", "warmup_updates", "\n", "lr_range", "=", "self", ".", "lr", "-", "self", ".", "end_learning_rate", "\n", "pct_remaining", "=", "1", "-", "(", "num_updates", "-", "warmup", ")", "/", "(", "\n", "self", ".", "total_num_update", "-", "warmup", "\n", ")", "\n", "lr", "=", "lr_range", "*", "pct_remaining", "**", "(", "self", ".", "power", ")", "+", "self", ".", "end_learning_rate", "\n", "", "self", ".", "optimizer", ".", "set_lr", "(", "lr", ")", "\n", "return", "self", ".", "optimizer", ".", "get_lr", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.scoring.chrf.ChrFScorer.__init__": [[11, 16], ["fairseq.scoring.BaseScorer.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "ChrFScorer", ",", "self", ")", ".", "__init__", "(", "args", ")", "\n", "import", "sacrebleu", "\n", "\n", "self", ".", "sacrebleu", "=", "sacrebleu", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scoring.chrf.ChrFScorer.add_string": [[17, 20], ["chrf.ChrFScorer.ref.append", "chrf.ChrFScorer.pred.append"], "methods", ["None"], ["", "def", "add_string", "(", "self", ",", "ref", ",", "pred", ")", ":", "\n", "        ", "self", ".", "ref", ".", "append", "(", "ref", ")", "\n", "self", ".", "pred", ".", "append", "(", "pred", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scoring.chrf.ChrFScorer.score": [[21, 23], ["chrf.ChrFScorer.result_string"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scoring.__init__.BaseScorer.result_string"], ["", "def", "score", "(", "self", ",", "order", "=", "4", ")", ":", "\n", "        ", "return", "self", ".", "result_string", "(", "order", ")", ".", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scoring.chrf.ChrFScorer.result_string": [[24, 28], ["chrf.ChrFScorer.sacrebleu.corpus_chrf().format", "chrf.ChrFScorer.sacrebleu.corpus_chrf"], "methods", ["None"], ["", "def", "result_string", "(", "self", ",", "order", "=", "4", ")", ":", "\n", "        ", "if", "order", "!=", "4", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "return", "self", ".", "sacrebleu", ".", "corpus_chrf", "(", "self", ".", "pred", ",", "[", "self", ".", "ref", "]", ")", ".", "format", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.scoring.tokenizer.EvaluationTokenizer.__init__": [[29, 43], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.scoring.tokenizer.EvaluationTokenizer.remove_punctuation": [[44, 51], ["cls.SPACE.join", "sent.split", "all", "unicodedata.category"], "methods", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.scoring.tokenizer.EvaluationTokenizer.tokenize": [[53, 68], ["tokenizer.EvaluationTokenizer.tokenizer", "tokenizer.EvaluationTokenizer.remove_punctuation", "tokenizer.EvaluationTokenizer.SPACE.join", "tokenized.lower.lower.lower", "list", "tokenized.lower.lower.replace"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scoring.tokenizer.EvaluationTokenizer.remove_punctuation"], []], "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.SacrebleuScorer.__init__": [[47, 56], ["fairseq.scoring.BaseScorer.__init__", "fairseq.scoring.tokenizer.EvaluationTokenizer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", "SacrebleuScorer", ",", "self", ")", ".", "__init__", "(", "cfg", ")", "\n", "import", "sacrebleu", "\n", "\n", "self", ".", "sacrebleu", "=", "sacrebleu", "\n", "self", ".", "tokenizer", "=", "EvaluationTokenizer", "(", "\n", "tokenizer_type", "=", "cfg", ".", "sacrebleu_tokenizer", ",", "\n", "lowercase", "=", "cfg", ".", "sacrebleu_lowercase", ",", "\n", "character_tokenization", "=", "cfg", ".", "sacrebleu_char_level", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.SacrebleuScorer.add_string": [[58, 61], ["bleu.SacrebleuScorer.ref.append", "bleu.SacrebleuScorer.pred.append", "bleu.SacrebleuScorer.tokenizer.tokenize", "bleu.SacrebleuScorer.tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scoring.tokenizer.EvaluationTokenizer.tokenize", "home.repos.pwc.inspect_result.reneeye_const.scoring.tokenizer.EvaluationTokenizer.tokenize"], ["", "def", "add_string", "(", "self", ",", "ref", ",", "pred", ")", ":", "\n", "        ", "self", ".", "ref", ".", "append", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "ref", ")", ")", "\n", "self", ".", "pred", ".", "append", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "pred", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.SacrebleuScorer.score": [[62, 64], ["bleu.SacrebleuScorer.result_string"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scoring.__init__.BaseScorer.result_string"], ["", "def", "score", "(", "self", ",", "order", "=", "4", ")", ":", "\n", "        ", "return", "self", ".", "result_string", "(", "order", ")", ".", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.SacrebleuScorer.result_string": [[65, 71], ["bleu.SacrebleuScorer.sacrebleu.corpus_bleu().format", "bleu.SacrebleuScorer.sacrebleu.corpus_bleu"], "methods", ["None"], ["", "def", "result_string", "(", "self", ",", "order", "=", "4", ")", ":", "\n", "        ", "if", "order", "!=", "4", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "# tokenization and lowercasing are performed by self.tokenizer instead.", "\n", "", "return", "self", ".", "sacrebleu", ".", "corpus_bleu", "(", "\n", "self", ".", "pred", ",", "[", "self", ".", "ref", "]", ",", "tokenize", "=", "\"none\"", "\n", ")", ".", "format", "(", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.__init__": [[83, 100], ["bleu.BleuStat", "ctypes.cdll.LoadLibrary", "bleu.Scorer.reset", "sys.stderr.write"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.reset"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "self", ".", "stat", "=", "BleuStat", "(", ")", "\n", "self", ".", "pad", "=", "cfg", ".", "pad", "\n", "self", ".", "eos", "=", "cfg", ".", "eos", "\n", "self", ".", "unk", "=", "cfg", ".", "unk", "\n", "\n", "try", ":", "\n", "            ", "from", "fairseq", "import", "libbleu", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "            ", "sys", ".", "stderr", ".", "write", "(", "\n", "\"ERROR: missing libbleu.so. run `pip install --editable .`\\n\"", "\n", ")", "\n", "raise", "e", "\n", "\n", "", "self", ".", "C", "=", "ctypes", ".", "cdll", ".", "LoadLibrary", "(", "libbleu", ".", "__file__", ")", "\n", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.reset": [[101, 106], ["bleu.Scorer.C.bleu_one_init", "bleu.Scorer.C.bleu_zero_init", "ctypes.byref", "ctypes.byref"], "methods", ["None"], ["", "def", "reset", "(", "self", ",", "one_init", "=", "False", ")", ":", "\n", "        ", "if", "one_init", ":", "\n", "            ", "self", ".", "C", ".", "bleu_one_init", "(", "ctypes", ".", "byref", "(", "self", ".", "stat", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "C", ".", "bleu_zero_init", "(", "ctypes", ".", "byref", "(", "self", ".", "stat", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add": [[107, 129], ["ref.clone", "rref.contiguous().view.contiguous().view.contiguous().view", "pred.contiguous().view.contiguous().view.contiguous().view", "bleu.Scorer.C.bleu_add", "isinstance", "TypeError", "isinstance", "TypeError", "rref.contiguous().view.contiguous().view.lt().any", "ctypes.byref", "ctypes.c_size_t", "ctypes.c_void_p", "ctypes.c_size_t", "ctypes.c_void_p", "ctypes.c_int", "ctypes.c_int", "rref.contiguous().view.contiguous().view.eq", "rref.contiguous().view.contiguous().view.contiguous", "pred.contiguous().view.contiguous().view.contiguous", "rref.contiguous().view.contiguous().view.size", "rref.contiguous().view.contiguous().view.data_ptr", "pred.contiguous().view.contiguous().view.size", "pred.contiguous().view.contiguous().view.data_ptr", "type", "type", "rref.contiguous().view.contiguous().view.lt"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "", "def", "add", "(", "self", ",", "ref", ",", "pred", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "ref", ",", "torch", ".", "IntTensor", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"ref must be a torch.IntTensor (got {})\"", ".", "format", "(", "type", "(", "ref", ")", ")", ")", "\n", "", "if", "not", "isinstance", "(", "pred", ",", "torch", ".", "IntTensor", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"pred must be a torch.IntTensor(got {})\"", ".", "format", "(", "type", "(", "pred", ")", ")", ")", "\n", "\n", "# don't match unknown words", "\n", "", "rref", "=", "ref", ".", "clone", "(", ")", "\n", "assert", "not", "rref", ".", "lt", "(", "0", ")", ".", "any", "(", ")", "\n", "rref", "[", "rref", ".", "eq", "(", "self", ".", "unk", ")", "]", "=", "-", "999", "\n", "\n", "rref", "=", "rref", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "pred", "=", "pred", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "self", ".", "C", ".", "bleu_add", "(", "\n", "ctypes", ".", "byref", "(", "self", ".", "stat", ")", ",", "\n", "ctypes", ".", "c_size_t", "(", "rref", ".", "size", "(", "0", ")", ")", ",", "\n", "ctypes", ".", "c_void_p", "(", "rref", ".", "data_ptr", "(", ")", ")", ",", "\n", "ctypes", ".", "c_size_t", "(", "pred", ".", "size", "(", "0", ")", ")", ",", "\n", "ctypes", ".", "c_void_p", "(", "pred", ".", "data_ptr", "(", ")", ")", ",", "\n", "ctypes", ".", "c_int", "(", "self", ".", "pad", ")", ",", "\n", "ctypes", ".", "c_int", "(", "self", ".", "eos", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.score": [[131, 136], ["sum", "bleu.Scorer.brevity", "math.exp", "math.log", "float", "bleu.Scorer.precision"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.brevity", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.precision"], ["", "def", "score", "(", "self", ",", "order", "=", "4", ")", ":", "\n", "        ", "psum", "=", "sum", "(", "\n", "math", ".", "log", "(", "p", ")", "if", "p", ">", "0", "else", "float", "(", "\"-Inf\"", ")", "for", "p", "in", "self", ".", "precision", "(", ")", "[", ":", "order", "]", "\n", ")", "\n", "return", "self", ".", "brevity", "(", ")", "*", "math", ".", "exp", "(", "psum", "/", "order", ")", "*", "100", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.precision": [[137, 146], ["bleu.Scorer.precision.ratio"], "methods", ["None"], ["", "def", "precision", "(", "self", ")", ":", "\n", "        ", "def", "ratio", "(", "a", ",", "b", ")", ":", "\n", "            ", "return", "a", "/", "b", "if", "b", ">", "0", "else", "0", "\n", "\n", "", "return", "[", "\n", "ratio", "(", "self", ".", "stat", ".", "match1", ",", "self", ".", "stat", ".", "count1", ")", ",", "\n", "ratio", "(", "self", ".", "stat", ".", "match2", ",", "self", ".", "stat", ".", "count2", ")", ",", "\n", "ratio", "(", "self", ".", "stat", ".", "match3", ",", "self", ".", "stat", ".", "count3", ")", ",", "\n", "ratio", "(", "self", ".", "stat", ".", "match4", ",", "self", ".", "stat", ".", "count4", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.brevity": [[148, 151], ["min", "math.exp"], "methods", ["None"], ["", "def", "brevity", "(", "self", ")", ":", "\n", "        ", "r", "=", "self", ".", "stat", ".", "reflen", "/", "self", ".", "stat", ".", "predlen", "\n", "return", "min", "(", "1", ",", "math", ".", "exp", "(", "1", "-", "r", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.result_string": [[152, 167], ["range", "fmt.format", "bleu.Scorer.score", "bleu.Scorer.brevity", "bleu.Scorer.precision"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scoring.__init__.BaseScorer.score", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.brevity", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.precision"], ["", "def", "result_string", "(", "self", ",", "order", "=", "4", ")", ":", "\n", "        ", "assert", "order", "<=", "4", ",", "\"BLEU scores for order > 4 aren't supported\"", "\n", "fmt", "=", "\"BLEU{} = {:2.2f}, {:2.1f}\"", "\n", "for", "_", "in", "range", "(", "1", ",", "order", ")", ":", "\n", "            ", "fmt", "+=", "\"/{:2.1f}\"", "\n", "", "fmt", "+=", "\" (BP={:.3f}, ratio={:.3f}, syslen={}, reflen={})\"", "\n", "bleup", "=", "[", "p", "*", "100", "for", "p", "in", "self", ".", "precision", "(", ")", "[", ":", "order", "]", "]", "\n", "return", "fmt", ".", "format", "(", "\n", "order", ",", "\n", "self", ".", "score", "(", "order", "=", "order", ")", ",", "\n", "*", "bleup", ",", "\n", "self", ".", "brevity", "(", ")", ",", "\n", "self", ".", "stat", ".", "predlen", "/", "self", ".", "stat", ".", "reflen", ",", "\n", "self", ".", "stat", ".", "predlen", ",", "\n", "self", ".", "stat", ".", "reflen", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scoring.wer.WerScorer.__init__": [[29, 42], ["fairseq.scoring.BaseScorer.__init__", "wer.WerScorer.reset", "fairseq.scoring.tokenizer.EvaluationTokenizer", "ImportError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.reset"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ")", "\n", "self", ".", "reset", "(", ")", "\n", "try", ":", "\n", "            ", "import", "editdistance", "as", "ed", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install editdistance to use WER scorer\"", ")", "\n", "", "self", ".", "ed", "=", "ed", "\n", "self", ".", "tokenizer", "=", "EvaluationTokenizer", "(", "\n", "tokenizer_type", "=", "self", ".", "cfg", ".", "wer_tokenizer", ",", "\n", "lowercase", "=", "self", ".", "cfg", ".", "wer_lowercase", ",", "\n", "punctuation_removal", "=", "self", ".", "cfg", ".", "wer_remove_punct", ",", "\n", "character_tokenization", "=", "self", ".", "cfg", ".", "wer_char_level", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scoring.wer.WerScorer.reset": [[44, 47], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "distance", "=", "0", "\n", "self", ".", "ref_length", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scoring.wer.WerScorer.add_string": [[48, 53], ["wer.WerScorer.tokenizer.tokenize().split", "wer.WerScorer.tokenizer.tokenize().split", "wer.WerScorer.ed.eval", "len", "wer.WerScorer.tokenizer.tokenize", "wer.WerScorer.tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scoring.tokenizer.EvaluationTokenizer.tokenize", "home.repos.pwc.inspect_result.reneeye_const.scoring.tokenizer.EvaluationTokenizer.tokenize"], ["", "def", "add_string", "(", "self", ",", "ref", ",", "pred", ")", ":", "\n", "        ", "ref_items", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "ref", ")", ".", "split", "(", ")", "\n", "pred_items", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "pred", ")", ".", "split", "(", ")", "\n", "self", ".", "distance", "+=", "self", ".", "ed", ".", "eval", "(", "ref_items", ",", "pred_items", ")", "\n", "self", ".", "ref_length", "+=", "len", "(", "ref_items", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scoring.wer.WerScorer.result_string": [[54, 56], ["wer.WerScorer.score"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scoring.__init__.BaseScorer.score"], ["", "def", "result_string", "(", "self", ")", ":", "\n", "        ", "return", "f\"WER: {self.score():.2f}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scoring.wer.WerScorer.score": [[57, 59], ["None"], "methods", ["None"], ["", "def", "score", "(", "self", ")", ":", "\n", "        ", "return", "100.0", "*", "self", ".", "distance", "/", "self", ".", "ref_length", "if", "self", ".", "ref_length", ">", "0", "else", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.scoring.__init__.BaseScorer.__init__": [[16, 20], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.scoring.__init__.BaseScorer.add_string": [[21, 24], ["__init__.BaseScorer.ref.append", "__init__.BaseScorer.pred.append"], "methods", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.scoring.__init__.BaseScorer.score": [[25, 28], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.scoring.__init__.BaseScorer.result_string": [[29, 32], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.scoring.__init__.build_scorer": [[39, 50], ["isinstance", "_build_scorer", "bleu.Scorer", "bleu.BleuConfig", "tgt_dict.pad", "tgt_dict.eos", "tgt_dict.unk"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk"], []], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.BaseProgressBar.__init__": [[113, 122], ["getattr"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "iterable", ",", "epoch", "=", "None", ",", "prefix", "=", "None", ")", ":", "\n", "        ", "self", ".", "iterable", "=", "iterable", "\n", "self", ".", "n", "=", "getattr", "(", "iterable", ",", "\"n\"", ",", "0", ")", "\n", "self", ".", "epoch", "=", "epoch", "\n", "self", ".", "prefix", "=", "\"\"", "\n", "if", "epoch", "is", "not", "None", ":", "\n", "            ", "self", ".", "prefix", "+=", "\"epoch {:03d}\"", ".", "format", "(", "epoch", ")", "\n", "", "if", "prefix", "is", "not", "None", ":", "\n", "            ", "self", ".", "prefix", "+=", "\" | {}\"", ".", "format", "(", "prefix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.BaseProgressBar.__len__": [[123, 125], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "iterable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.BaseProgressBar.__enter__": [[126, 128], ["None"], "methods", ["None"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.BaseProgressBar.__exit__": [[129, 131], ["None"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "*", "exc", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.BaseProgressBar.__iter__": [[132, 134], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.BaseProgressBar.log": [[135, 138], ["None"], "methods", ["None"], ["", "def", "log", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log intermediate stats according to log_interval.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.BaseProgressBar.print": [[139, 142], ["None"], "methods", ["None"], ["", "def", "print", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print end-of-epoch stats.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.BaseProgressBar._str_commas": [[143, 145], ["stats[].strip", "stats.keys"], "methods", ["None"], ["", "def", "_str_commas", "(", "self", ",", "stats", ")", ":", "\n", "        ", "return", "\", \"", ".", "join", "(", "key", "+", "\"=\"", "+", "stats", "[", "key", "]", ".", "strip", "(", ")", "for", "key", "in", "stats", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.BaseProgressBar._str_pipes": [[146, 148], ["stats[].strip", "stats.keys"], "methods", ["None"], ["", "def", "_str_pipes", "(", "self", ",", "stats", ")", ":", "\n", "        ", "return", "\" | \"", ".", "join", "(", "key", "+", "\" \"", "+", "stats", "[", "key", "]", ".", "strip", "(", ")", "for", "key", "in", "stats", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.BaseProgressBar._format_stats": [[149, 155], ["collections.OrderedDict", "collections.OrderedDict.keys", "str", "progress_bar.format_stat"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.format_stat"], ["", "def", "_format_stats", "(", "self", ",", "stats", ")", ":", "\n", "        ", "postfix", "=", "OrderedDict", "(", "stats", ")", "\n", "# Preprocess stats according to datatype", "\n", "for", "key", "in", "postfix", ".", "keys", "(", ")", ":", "\n", "            ", "postfix", "[", "key", "]", "=", "str", "(", "format_stat", "(", "postfix", "[", "key", "]", ")", ")", "\n", "", "return", "postfix", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.JsonProgressBar.__init__": [[169, 174], ["progress_bar.BaseProgressBar.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "iterable", ",", "epoch", "=", "None", ",", "prefix", "=", "None", ",", "log_interval", "=", "1000", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "iterable", ",", "epoch", ",", "prefix", ")", "\n", "self", ".", "log_interval", "=", "log_interval", "\n", "self", ".", "i", "=", "None", "\n", "self", ".", "size", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.JsonProgressBar.__iter__": [[175, 180], ["len", "enumerate"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "size", "=", "len", "(", "self", ".", "iterable", ")", "\n", "for", "i", ",", "obj", "in", "enumerate", "(", "self", ".", "iterable", ",", "start", "=", "self", ".", "n", ")", ":", "\n", "            ", "self", ".", "i", "=", "i", "\n", "yield", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.JsonProgressBar.log": [[181, 193], ["progress_bar.JsonProgressBar._format_stats", "progress_bar.rename_logger", "logger.info", "json.dumps", "float"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.JsonProgressBar._format_stats", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.rename_logger"], ["", "", "def", "log", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log intermediate stats according to log_interval.\"\"\"", "\n", "step", "=", "step", "or", "self", ".", "i", "or", "0", "\n", "if", "step", ">", "0", "and", "self", ".", "log_interval", "is", "not", "None", "and", "step", "%", "self", ".", "log_interval", "==", "0", ":", "\n", "            ", "update", "=", "(", "\n", "self", ".", "epoch", "-", "1", "+", "(", "self", ".", "i", "+", "1", ")", "/", "float", "(", "self", ".", "size", ")", "\n", "if", "self", ".", "epoch", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "stats", "=", "self", ".", "_format_stats", "(", "stats", ",", "epoch", "=", "self", ".", "epoch", ",", "update", "=", "update", ")", "\n", "with", "rename_logger", "(", "logger", ",", "tag", ")", ":", "\n", "                ", "logger", ".", "info", "(", "json", ".", "dumps", "(", "stats", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.JsonProgressBar.print": [[194, 204], ["progress_bar.JsonProgressBar._format_stats", "collections.OrderedDict", "progress_bar.rename_logger", "logger.info", "json.dumps", "progress_bar.JsonProgressBar.stats.items"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.JsonProgressBar._format_stats", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.rename_logger"], ["", "", "", "def", "print", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print end-of-epoch stats.\"\"\"", "\n", "self", ".", "stats", "=", "stats", "\n", "if", "tag", "is", "not", "None", ":", "\n", "            ", "self", ".", "stats", "=", "OrderedDict", "(", "\n", "[", "(", "tag", "+", "\"_\"", "+", "k", ",", "v", ")", "for", "k", ",", "v", "in", "self", ".", "stats", ".", "items", "(", ")", "]", "\n", ")", "\n", "", "stats", "=", "self", ".", "_format_stats", "(", "self", ".", "stats", ",", "epoch", "=", "self", ".", "epoch", ")", "\n", "with", "rename_logger", "(", "logger", ",", "tag", ")", ":", "\n", "            ", "logger", ".", "info", "(", "json", ".", "dumps", "(", "stats", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.JsonProgressBar._format_stats": [[205, 215], ["collections.OrderedDict", "stats.keys", "round", "progress_bar.format_stat"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.format_stat"], ["", "", "def", "_format_stats", "(", "self", ",", "stats", ",", "epoch", "=", "None", ",", "update", "=", "None", ")", ":", "\n", "        ", "postfix", "=", "OrderedDict", "(", ")", "\n", "if", "epoch", "is", "not", "None", ":", "\n", "            ", "postfix", "[", "\"epoch\"", "]", "=", "epoch", "\n", "", "if", "update", "is", "not", "None", ":", "\n", "            ", "postfix", "[", "\"update\"", "]", "=", "round", "(", "update", ",", "3", ")", "\n", "# Preprocess stats according to datatype", "\n", "", "for", "key", "in", "stats", ".", "keys", "(", ")", ":", "\n", "            ", "postfix", "[", "key", "]", "=", "format_stat", "(", "stats", "[", "key", "]", ")", "\n", "", "return", "postfix", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.NoopProgressBar.__init__": [[220, 222], ["progress_bar.BaseProgressBar.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "iterable", ",", "epoch", "=", "None", ",", "prefix", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "iterable", ",", "epoch", ",", "prefix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.NoopProgressBar.__iter__": [[223, 226], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "obj", "in", "self", ".", "iterable", ":", "\n", "            ", "yield", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.NoopProgressBar.log": [[227, 230], ["None"], "methods", ["None"], ["", "", "def", "log", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log intermediate stats according to log_interval.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.NoopProgressBar.print": [[231, 234], ["None"], "methods", ["None"], ["", "def", "print", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print end-of-epoch stats.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.SimpleProgressBar.__init__": [[239, 244], ["progress_bar.BaseProgressBar.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "iterable", ",", "epoch", "=", "None", ",", "prefix", "=", "None", ",", "log_interval", "=", "1000", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "iterable", ",", "epoch", ",", "prefix", ")", "\n", "self", ".", "log_interval", "=", "log_interval", "\n", "self", ".", "i", "=", "None", "\n", "self", ".", "size", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.SimpleProgressBar.__iter__": [[245, 250], ["len", "enumerate"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "size", "=", "len", "(", "self", ".", "iterable", ")", "\n", "for", "i", ",", "obj", "in", "enumerate", "(", "self", ".", "iterable", ",", "start", "=", "self", ".", "n", ")", ":", "\n", "            ", "self", ".", "i", "=", "i", "\n", "yield", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.SimpleProgressBar.log": [[251, 261], ["progress_bar.SimpleProgressBar._format_stats", "progress_bar.SimpleProgressBar._str_commas", "progress_bar.rename_logger", "logger.info"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.JsonProgressBar._format_stats", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.BaseProgressBar._str_commas", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.rename_logger"], ["", "", "def", "log", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log intermediate stats according to log_interval.\"\"\"", "\n", "step", "=", "step", "or", "self", ".", "i", "or", "0", "\n", "if", "step", ">", "0", "and", "self", ".", "log_interval", "is", "not", "None", "and", "step", "%", "self", ".", "log_interval", "==", "0", ":", "\n", "            ", "stats", "=", "self", ".", "_format_stats", "(", "stats", ")", "\n", "postfix", "=", "self", ".", "_str_commas", "(", "stats", ")", "\n", "with", "rename_logger", "(", "logger", ",", "tag", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"{}:  {:5d} / {:d} {}\"", ".", "format", "(", "\n", "self", ".", "prefix", ",", "self", ".", "i", "+", "1", ",", "self", ".", "size", ",", "postfix", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.SimpleProgressBar.print": [[264, 269], ["progress_bar.SimpleProgressBar._str_pipes", "progress_bar.SimpleProgressBar._format_stats", "progress_bar.rename_logger", "logger.info"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.BaseProgressBar._str_pipes", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.JsonProgressBar._format_stats", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.rename_logger"], ["", "", "", "def", "print", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print end-of-epoch stats.\"\"\"", "\n", "postfix", "=", "self", ".", "_str_pipes", "(", "self", ".", "_format_stats", "(", "stats", ")", ")", "\n", "with", "rename_logger", "(", "logger", ",", "tag", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"{} | {}\"", ".", "format", "(", "self", ".", "prefix", ",", "postfix", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.TqdmProgressBar.__init__": [[274, 283], ["progress_bar.BaseProgressBar.__init__", "tqdm", "logger.getEffectiveLevel"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "iterable", ",", "epoch", "=", "None", ",", "prefix", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "iterable", ",", "epoch", ",", "prefix", ")", "\n", "from", "tqdm", "import", "tqdm", "\n", "\n", "self", ".", "tqdm", "=", "tqdm", "(", "\n", "iterable", ",", "\n", "self", ".", "prefix", ",", "\n", "leave", "=", "False", ",", "\n", "disable", "=", "(", "logger", ".", "getEffectiveLevel", "(", ")", ">", "logging", ".", "INFO", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.TqdmProgressBar.__iter__": [[285, 287], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "tqdm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.TqdmProgressBar.log": [[288, 291], ["progress_bar.TqdmProgressBar.tqdm.set_postfix", "progress_bar.TqdmProgressBar._format_stats"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.JsonProgressBar._format_stats"], ["", "def", "log", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log intermediate stats according to log_interval.\"\"\"", "\n", "self", ".", "tqdm", ".", "set_postfix", "(", "self", ".", "_format_stats", "(", "stats", ")", ",", "refresh", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.TqdmProgressBar.print": [[292, 297], ["progress_bar.TqdmProgressBar._str_pipes", "progress_bar.TqdmProgressBar._format_stats", "progress_bar.rename_logger", "logger.info"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.BaseProgressBar._str_pipes", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.JsonProgressBar._format_stats", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.rename_logger"], ["", "def", "print", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print end-of-epoch stats.\"\"\"", "\n", "postfix", "=", "self", ".", "_str_pipes", "(", "self", ".", "_format_stats", "(", "stats", ")", ")", "\n", "with", "rename_logger", "(", "logger", ",", "tag", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"{} | {}\"", ".", "format", "(", "self", ".", "prefix", ",", "postfix", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.TensorboardProgressBarWrapper.__init__": [[317, 324], ["logger.warning"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "wrapped_bar", ",", "tensorboard_logdir", ")", ":", "\n", "        ", "self", ".", "wrapped_bar", "=", "wrapped_bar", "\n", "self", ".", "tensorboard_logdir", "=", "tensorboard_logdir", "\n", "\n", "if", "SummaryWriter", "is", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"tensorboard not found, please install with: pip install tensorboardX\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.TensorboardProgressBarWrapper._writer": [[326, 334], ["SummaryWriter", "_writers[].add_text", "os.path.join"], "methods", ["None"], ["", "", "def", "_writer", "(", "self", ",", "key", ")", ":", "\n", "        ", "if", "SummaryWriter", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "_writers", "=", "_tensorboard_writers", "\n", "if", "key", "not", "in", "_writers", ":", "\n", "            ", "_writers", "[", "key", "]", "=", "SummaryWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "tensorboard_logdir", ",", "key", ")", ")", "\n", "_writers", "[", "key", "]", ".", "add_text", "(", "\"sys.argv\"", ",", "\" \"", ".", "join", "(", "sys", ".", "argv", ")", ")", "\n", "", "return", "_writers", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.TensorboardProgressBarWrapper.__iter__": [[335, 337], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "wrapped_bar", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.TensorboardProgressBarWrapper.log": [[338, 342], ["progress_bar.TensorboardProgressBarWrapper._log_to_tensorboard", "progress_bar.TensorboardProgressBarWrapper.wrapped_bar.log"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.TensorboardProgressBarWrapper._log_to_tensorboard", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log"], ["", "def", "log", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log intermediate stats to tensorboard.\"\"\"", "\n", "self", ".", "_log_to_tensorboard", "(", "stats", ",", "tag", ",", "step", ")", "\n", "self", ".", "wrapped_bar", ".", "log", "(", "stats", ",", "tag", "=", "tag", ",", "step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.TensorboardProgressBarWrapper.print": [[343, 347], ["progress_bar.TensorboardProgressBarWrapper._log_to_tensorboard", "progress_bar.TensorboardProgressBarWrapper.wrapped_bar.print"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.TensorboardProgressBarWrapper._log_to_tensorboard", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print"], ["", "def", "print", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print end-of-epoch stats.\"\"\"", "\n", "self", ".", "_log_to_tensorboard", "(", "stats", ",", "tag", ",", "step", ")", "\n", "self", ".", "wrapped_bar", ".", "print", "(", "stats", ",", "tag", "=", "tag", ",", "step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.TensorboardProgressBarWrapper._log_to_tensorboard": [[348, 360], ["progress_bar.TensorboardProgressBarWrapper._writer", "progress_bar.TensorboardProgressBarWrapper.flush", "stats.keys", "isinstance", "progress_bar.TensorboardProgressBarWrapper.add_scalar", "isinstance", "progress_bar.TensorboardProgressBarWrapper.add_scalar"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.TensorboardProgressBarWrapper._writer", "home.repos.pwc.inspect_result.reneeye_const.prepare_data.data_utils.S2TDataConfigWriter.flush"], ["", "def", "_log_to_tensorboard", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "writer", "=", "self", ".", "_writer", "(", "tag", "or", "\"\"", ")", "\n", "if", "writer", "is", "None", ":", "\n", "            ", "return", "\n", "", "if", "step", "is", "None", ":", "\n", "            ", "step", "=", "stats", "[", "\"num_updates\"", "]", "\n", "", "for", "key", "in", "stats", ".", "keys", "(", ")", "-", "{", "\"num_updates\"", "}", ":", "\n", "            ", "if", "isinstance", "(", "stats", "[", "key", "]", ",", "AverageMeter", ")", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "key", ",", "stats", "[", "key", "]", ".", "val", ",", "step", ")", "\n", "", "elif", "isinstance", "(", "stats", "[", "key", "]", ",", "Number", ")", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "key", ",", "stats", "[", "key", "]", ",", "step", ")", "\n", "", "", "writer", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.__init__": [[371, 380], ["wandb.init", "logger.warning"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "wrapped_bar", ",", "wandb_project", ")", ":", "\n", "        ", "self", ".", "wrapped_bar", "=", "wrapped_bar", "\n", "if", "wandb", "is", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "'wandb not found, pip install wandb'", ")", "\n", "return", "\n", "\n", "# reinit=False to ensure if wandb.init() is called multiple times", "\n", "# within one process it still references the same run", "\n", "", "wandb", ".", "init", "(", "project", "=", "wandb_project", ",", "reinit", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.__iter__": [[381, 383], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "wrapped_bar", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log": [[384, 388], ["progress_bar.WandBProgressBarWrapper._log_to_wandb", "progress_bar.WandBProgressBarWrapper.wrapped_bar.log"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper._log_to_wandb", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log"], ["", "def", "log", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log intermediate stats to tensorboard.\"\"\"", "\n", "self", ".", "_log_to_wandb", "(", "stats", ",", "tag", ",", "step", ")", "\n", "self", ".", "wrapped_bar", ".", "log", "(", "stats", ",", "tag", "=", "tag", ",", "step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print": [[389, 393], ["progress_bar.WandBProgressBarWrapper._log_to_wandb", "progress_bar.WandBProgressBarWrapper.wrapped_bar.print"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper._log_to_wandb", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print"], ["", "def", "print", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Print end-of-epoch stats.\"\"\"", "\n", "self", ".", "_log_to_wandb", "(", "stats", ",", "tag", ",", "step", ")", "\n", "self", ".", "wrapped_bar", ".", "print", "(", "stats", ",", "tag", "=", "tag", ",", "step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper._log_to_wandb": [[394, 407], ["stats.keys", "isinstance", "wandb.log", "isinstance", "wandb.log"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log"], ["", "def", "_log_to_wandb", "(", "self", ",", "stats", ",", "tag", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "if", "wandb", "is", "None", ":", "\n", "            ", "return", "\n", "", "if", "step", "is", "None", ":", "\n", "            ", "step", "=", "stats", "[", "'num_updates'", "]", "\n", "\n", "", "prefix", "=", "''", "if", "tag", "is", "None", "else", "tag", "+", "'/'", "\n", "\n", "for", "key", "in", "stats", ".", "keys", "(", ")", "-", "{", "'num_updates'", "}", ":", "\n", "            ", "if", "isinstance", "(", "stats", "[", "key", "]", ",", "AverageMeter", ")", ":", "\n", "                ", "wandb", ".", "log", "(", "{", "prefix", "+", "key", ":", "stats", "[", "key", "]", ".", "val", "}", ",", "step", "=", "step", ")", "\n", "", "elif", "isinstance", "(", "stats", "[", "key", "]", ",", "Number", ")", ":", "\n", "                ", "wandb", ".", "log", "(", "{", "prefix", "+", "key", ":", "stats", "[", "key", "]", "}", ",", "step", "=", "step", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.progress_bar": [[28, 68], ["progress_bar.JsonProgressBar", "progress_bar.WandBProgressBarWrapper", "sys.stderr.isatty", "progress_bar.NoopProgressBar", "FbTbmfWrapper", "progress_bar.SimpleProgressBar", "progress_bar.TensorboardProgressBarWrapper", "progress_bar.TqdmProgressBar", "ValueError"], "function", ["None"], ["def", "progress_bar", "(", "\n", "iterator", ",", "\n", "log_format", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "log_interval", ":", "int", "=", "100", ",", "\n", "epoch", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "prefix", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "tensorboard_logdir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "default_log_format", ":", "str", "=", "\"tqdm\"", ",", "\n", "wandb_project", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", ":", "\n", "    ", "if", "log_format", "is", "None", ":", "\n", "        ", "log_format", "=", "default_log_format", "\n", "", "if", "log_format", "==", "\"tqdm\"", "and", "not", "sys", ".", "stderr", ".", "isatty", "(", ")", ":", "\n", "        ", "log_format", "=", "\"simple\"", "\n", "\n", "", "if", "log_format", "==", "\"json\"", ":", "\n", "        ", "bar", "=", "JsonProgressBar", "(", "iterator", ",", "epoch", ",", "prefix", ",", "log_interval", ")", "\n", "", "elif", "log_format", "==", "\"none\"", ":", "\n", "        ", "bar", "=", "NoopProgressBar", "(", "iterator", ",", "epoch", ",", "prefix", ")", "\n", "", "elif", "log_format", "==", "\"simple\"", ":", "\n", "        ", "bar", "=", "SimpleProgressBar", "(", "iterator", ",", "epoch", ",", "prefix", ",", "log_interval", ")", "\n", "", "elif", "log_format", "==", "\"tqdm\"", ":", "\n", "        ", "bar", "=", "TqdmProgressBar", "(", "iterator", ",", "epoch", ",", "prefix", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown log format: {}\"", ".", "format", "(", "log_format", ")", ")", "\n", "\n", "", "if", "tensorboard_logdir", ":", "\n", "        ", "try", ":", "\n", "# [FB only] custom wrapper for TensorBoard", "\n", "            ", "import", "palaas", "# noqa", "\n", "from", ".", "fb_tbmf_wrapper", "import", "FbTbmfWrapper", "\n", "\n", "bar", "=", "FbTbmfWrapper", "(", "bar", ",", "log_interval", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "bar", "=", "TensorboardProgressBarWrapper", "(", "bar", ",", "tensorboard_logdir", ")", "\n", "\n", "", "", "if", "wandb_project", ":", "\n", "        ", "bar", "=", "WandBProgressBarWrapper", "(", "bar", ",", "wandb_project", ")", "\n", "\n", "", "return", "bar", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.build_progress_bar": [[70, 93], ["getattr", "progress_bar.progress_bar", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.progress_bar"], ["", "def", "build_progress_bar", "(", "\n", "args", ",", "\n", "iterator", ",", "\n", "epoch", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "prefix", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "default", ":", "str", "=", "\"tqdm\"", ",", "\n", "no_progress_bar", ":", "str", "=", "\"none\"", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Legacy wrapper that takes an argparse.Namespace.\"\"\"", "\n", "if", "getattr", "(", "args", ",", "\"no_progress_bar\"", ",", "False", ")", ":", "\n", "        ", "default", "=", "no_progress_bar", "\n", "", "if", "getattr", "(", "args", ",", "\"distributed_rank\"", ",", "0", ")", "==", "0", ":", "\n", "        ", "tensorboard_logdir", "=", "getattr", "(", "args", ",", "\"tensorboard_logdir\"", ",", "None", ")", "\n", "", "else", ":", "\n", "        ", "tensorboard_logdir", "=", "None", "\n", "", "return", "progress_bar", "(", "\n", "iterator", ",", "\n", "log_format", "=", "args", ".", "log_format", ",", "\n", "log_interval", "=", "args", ".", "log_interval", ",", "\n", "epoch", "=", "epoch", ",", "\n", "prefix", "=", "prefix", ",", "\n", "tensorboard_logdir", "=", "tensorboard_logdir", ",", "\n", "default_log_format", "=", "default", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.format_stat": [[96, 108], ["isinstance", "isinstance", "isinstance", "isinstance", "round", "torch.is_tensor", "round", "stat.tolist.tolist"], "function", ["None"], ["", "def", "format_stat", "(", "stat", ")", ":", "\n", "    ", "if", "isinstance", "(", "stat", ",", "Number", ")", ":", "\n", "        ", "stat", "=", "\"{:g}\"", ".", "format", "(", "stat", ")", "\n", "", "elif", "isinstance", "(", "stat", ",", "AverageMeter", ")", ":", "\n", "        ", "stat", "=", "\"{:.3f}\"", ".", "format", "(", "stat", ".", "avg", ")", "\n", "", "elif", "isinstance", "(", "stat", ",", "TimeMeter", ")", ":", "\n", "        ", "stat", "=", "\"{:g}\"", ".", "format", "(", "round", "(", "stat", ".", "avg", ")", ")", "\n", "", "elif", "isinstance", "(", "stat", ",", "StopwatchMeter", ")", ":", "\n", "        ", "stat", "=", "\"{:g}\"", ".", "format", "(", "round", "(", "stat", ".", "sum", ")", ")", "\n", "", "elif", "torch", ".", "is_tensor", "(", "stat", ")", ":", "\n", "        ", "stat", "=", "stat", ".", "tolist", "(", ")", "\n", "", "return", "stat", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.rename_logger": [[157, 164], ["None"], "function", ["None"], ["", "", "@", "contextmanager", "\n", "def", "rename_logger", "(", "logger", ",", "new_name", ")", ":", "\n", "    ", "old_name", "=", "logger", ".", "name", "\n", "if", "new_name", "is", "not", "None", ":", "\n", "        ", "logger", ".", "name", "=", "new_name", "\n", "", "yield", "logger", "\n", "logger", ".", "name", "=", "old_name", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar._close_writers": [[306, 309], ["_tensorboard_writers.values", "w.close"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.close"], ["", "def", "_close_writers", "(", ")", ":", "\n", "    ", "for", "w", "in", "_tensorboard_writers", ".", "values", "(", ")", ":", "\n", "        ", "w", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.reset": [[30, 40], ["_aggregators.clear", "_active_aggregators.clear", "_active_aggregators_cnt.clear", "meters.MetersDict"], "function", ["None"], ["def", "reset", "(", ")", "->", "None", ":", "\n", "    ", "\"\"\"Reset all metrics aggregators.\"\"\"", "\n", "_aggregators", ".", "clear", "(", ")", "\n", "_active_aggregators", ".", "clear", "(", ")", "\n", "_active_aggregators_cnt", ".", "clear", "(", ")", "\n", "\n", "# The \"default\" aggregator observes all logged values.", "\n", "_aggregators", "[", "\"default\"", "]", "=", "MetersDict", "(", ")", "\n", "_active_aggregators", "[", "\"default\"", "]", "=", "_aggregators", "[", "\"default\"", "]", "\n", "_active_aggregators_cnt", "[", "\"default\"", "]", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.aggregate": [[45, 106], ["str", "meters.MetersDict", "_aggregators.setdefault", "_active_aggregators.copy", "_active_aggregators.clear", "_active_aggregators_cnt.copy", "_active_aggregators_cnt.clear", "_active_aggregators.clear", "_active_aggregators.update", "_active_aggregators_cnt.clear", "_active_aggregators_cnt.update", "uuid.uuid4", "meters.MetersDict"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.copy", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.copy", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update"], ["@", "contextlib", ".", "contextmanager", "\n", "def", "aggregate", "(", "name", ":", "Optional", "[", "str", "]", "=", "None", ",", "new_root", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Context manager to aggregate metrics under a given name.\n\n    Aggregations can be nested. If *new_root* is ``False``, then logged\n    metrics will be recorded along the entire stack of nested\n    aggregators, including a global \"default\" aggregator. If *new_root*\n    is ``True``, then this aggregator will be the root of a new\n    aggregation stack, thus bypassing any parent aggregators.\n\n    Note that aggregation contexts are uniquely identified by their\n    *name* (e.g., train, valid). Creating a context with an existing\n    name will reuse the corresponding :class:`MetersDict` instance.\n    If no name is given, then a temporary aggregator will be created.\n\n    Usage::\n\n        with metrics.aggregate(\"train\"):\n            for step, batch in enumerate(epoch):\n                with metrics.aggregate(\"train_inner\") as agg:\n                    metrics.log_scalar(\"loss\", get_loss(batch))\n                    if step % log_interval == 0:\n                        print(agg.get_smoothed_value(\"loss\"))\n                        agg.reset()\n        print(metrics.get_smoothed_values(\"train\")[\"loss\"])\n\n    Args:\n        name (str): name of the aggregation. Defaults to a\n            random/temporary name if not given explicitly.\n        new_root (bool): make this aggregation the root of a new\n            aggregation stack.\n    \"\"\"", "\n", "if", "name", "is", "None", ":", "\n", "# generate a temporary name", "\n", "        ", "name", "=", "str", "(", "uuid", ".", "uuid4", "(", ")", ")", "\n", "assert", "name", "not", "in", "_aggregators", "\n", "agg", "=", "MetersDict", "(", ")", "\n", "", "else", ":", "\n", "        ", "assert", "name", "!=", "\"default\"", "\n", "agg", "=", "_aggregators", ".", "setdefault", "(", "name", ",", "MetersDict", "(", ")", ")", "\n", "\n", "", "if", "new_root", ":", "\n", "        ", "backup_aggregators", "=", "_active_aggregators", ".", "copy", "(", ")", "\n", "_active_aggregators", ".", "clear", "(", ")", "\n", "backup_aggregators_cnt", "=", "_active_aggregators_cnt", ".", "copy", "(", ")", "\n", "_active_aggregators_cnt", ".", "clear", "(", ")", "\n", "\n", "", "_active_aggregators", "[", "name", "]", "=", "agg", "\n", "_active_aggregators_cnt", "[", "name", "]", "+=", "1", "\n", "\n", "yield", "agg", "\n", "\n", "_active_aggregators_cnt", "[", "name", "]", "-=", "1", "\n", "if", "_active_aggregators_cnt", "[", "name", "]", "==", "0", "and", "name", "in", "_active_aggregators", ":", "\n", "        ", "del", "_active_aggregators", "[", "name", "]", "\n", "\n", "", "if", "new_root", ":", "\n", "        ", "_active_aggregators", ".", "clear", "(", ")", "\n", "_active_aggregators", ".", "update", "(", "backup_aggregators", ")", "\n", "_active_aggregators_cnt", ".", "clear", "(", ")", "\n", "_active_aggregators_cnt", ".", "update", "(", "backup_aggregators_cnt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.get_active_aggregators": [[108, 110], ["list", "_active_aggregators.values"], "function", ["None"], ["", "", "def", "get_active_aggregators", "(", ")", "->", "List", "[", "MetersDict", "]", ":", "\n", "    ", "return", "list", "(", "_active_aggregators", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar": [[112, 133], ["metrics.get_active_aggregators", "agg[].update", "agg.add_meter", "meters.AverageMeter"], "function", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.get_active_aggregators", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.add_meter"], ["", "def", "log_scalar", "(", "\n", "key", ":", "str", ",", "\n", "value", ":", "float", ",", "\n", "weight", ":", "float", "=", "1", ",", "\n", "priority", ":", "int", "=", "10", ",", "\n", "round", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Log a scalar value.\n\n    Args:\n        key (str): name of the field to log\n        value (float): value to log\n        weight (float): weight that this value contributes to the average.\n            A weight of 0 will always log the latest value.\n        priority (int): smaller values are logged earlier in the output\n        round (Optional[int]): number of digits to round to when displaying\n    \"\"\"", "\n", "for", "agg", "in", "get_active_aggregators", "(", ")", ":", "\n", "        ", "if", "key", "not", "in", "agg", ":", "\n", "            ", "agg", ".", "add_meter", "(", "key", ",", "AverageMeter", "(", "round", "=", "round", ")", ",", "priority", ")", "\n", "", "agg", "[", "key", "]", ".", "update", "(", "value", ",", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived": [[135, 147], ["metrics.get_active_aggregators", "agg.add_meter", "meters.MetersDict._DerivedMeter"], "function", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.get_active_aggregators", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.add_meter"], ["", "", "def", "log_derived", "(", "key", ":", "str", ",", "fn", ":", "Callable", "[", "[", "MetersDict", "]", ",", "float", "]", ",", "priority", ":", "int", "=", "20", ")", ":", "\n", "    ", "\"\"\"Log a scalar value derived from other meters.\n\n    Args:\n        key (str): name of the field to log\n        fn (Callable[[MetersDict], float]): function that takes a single\n            argument *meters* and returns the derived value\n        priority (int): smaller values are logged earlier in the output\n    \"\"\"", "\n", "for", "agg", "in", "get_active_aggregators", "(", ")", ":", "\n", "        ", "if", "key", "not", "in", "agg", ":", "\n", "            ", "agg", ".", "add_meter", "(", "key", ",", "MetersDict", ".", "_DerivedMeter", "(", "fn", ")", ",", "priority", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_speed": [[149, 169], ["metrics.get_active_aggregators", "agg.add_meter", "agg[].reset", "agg[].update", "meters.TimeMeter"], "function", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.get_active_aggregators", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.add_meter", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.reset", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update"], ["", "", "", "def", "log_speed", "(", "\n", "key", ":", "str", ",", "\n", "value", ":", "float", ",", "\n", "priority", ":", "int", "=", "30", ",", "\n", "round", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Log the rate of some quantity per second.\n\n    Args:\n        key (str): name of the field to log\n        value (float): value to log\n        priority (int): smaller values are logged earlier in the output\n        round (Optional[int]): number of digits to round to when displaying\n    \"\"\"", "\n", "for", "agg", "in", "get_active_aggregators", "(", ")", ":", "\n", "        ", "if", "key", "not", "in", "agg", ":", "\n", "            ", "agg", ".", "add_meter", "(", "key", ",", "TimeMeter", "(", "round", "=", "round", ")", ",", "priority", ")", "\n", "agg", "[", "key", "]", ".", "reset", "(", ")", "# reset meter on the first call", "\n", "", "else", ":", "\n", "            ", "agg", "[", "key", "]", ".", "update", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_start_time": [[171, 185], ["metrics.get_active_aggregators", "agg[].start", "agg.add_meter", "meters.StopwatchMeter"], "function", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.get_active_aggregators", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.start", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.add_meter"], ["", "", "", "def", "log_start_time", "(", "key", ":", "str", ",", "priority", ":", "int", "=", "40", ",", "round", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"Log the duration of some event in seconds.\n\n    The duration will be computed once :func:`log_stop_time` is called.\n\n    Args:\n        key (str): name of the field to log\n        priority (int): smaller values are logged earlier in the output\n        round (Optional[int]): number of digits to round to when displaying\n    \"\"\"", "\n", "for", "agg", "in", "get_active_aggregators", "(", ")", ":", "\n", "        ", "if", "key", "not", "in", "agg", ":", "\n", "            ", "agg", ".", "add_meter", "(", "key", ",", "StopwatchMeter", "(", "round", "=", "round", ")", ",", "priority", ")", "\n", "", "agg", "[", "key", "]", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_stop_time": [[187, 203], ["metrics.get_active_aggregators", "agg[].stop"], "function", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.get_active_aggregators", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.stop"], ["", "", "def", "log_stop_time", "(", "key", ":", "str", ",", "weight", ":", "float", "=", "0.0", ",", "prehook", "=", "None", ")", ":", "\n", "    ", "\"\"\"Log the duration of some event in seconds.\n\n    The duration will be computed since :func:`log_start_time` was called.\n    Set weight > 0 to report the average time instead of the sum.\n\n    Args:\n        key (str): name of the field to log\n        weight (float): weight that this time contributes to the average\n        prehook (function, no arguments): will be called before the timer\n        is stopped. For example, use prehook=torch.cuda.synchronize to\n        make sure all gpu operations are done before timer is stopped.\n    \"\"\"", "\n", "for", "agg", "in", "get_active_aggregators", "(", ")", ":", "\n", "        ", "if", "key", "in", "agg", ":", "\n", "            ", "agg", "[", "key", "]", ".", "stop", "(", "weight", ",", "prehook", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_custom": [[205, 227], ["metrics.get_active_aggregators", "agg[].update", "agg.add_meter", "new_meter_fn"], "function", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.get_active_aggregators", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.add_meter"], ["", "", "", "def", "log_custom", "(", "\n", "new_meter_fn", ":", "Callable", "[", "[", "]", ",", "Meter", "]", ",", "\n", "key", ":", "str", ",", "\n", "*", "args", ",", "\n", "priority", ":", "int", "=", "50", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Log using a custom Meter.\n\n    Any extra *args* or *kwargs* will be passed through to the Meter's\n    *update* method.\n\n    Args:\n        new_meter_fn (Callable[[], Meter]): function that returns a new\n            Meter instance\n        key (str): name of the field to log\n        priority (int): smaller values are logged earlier in the output\n    \"\"\"", "\n", "for", "agg", "in", "get_active_aggregators", "(", ")", ":", "\n", "        ", "if", "key", "not", "in", "agg", ":", "\n", "            ", "agg", ".", "add_meter", "(", "key", ",", "new_meter_fn", "(", ")", ",", "priority", ")", "\n", "", "agg", "[", "key", "]", ".", "update", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.reset_meter": [[229, 234], ["metrics.get_meter", "get_meter.reset"], "function", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.get_meter", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.reset"], ["", "", "def", "reset_meter", "(", "name", ":", "str", ",", "key", ":", "str", ")", "->", "None", ":", "\n", "    ", "\"\"\"Reset Meter instance aggregated under a given *name* and *key*.\"\"\"", "\n", "meter", "=", "get_meter", "(", "name", ",", "key", ")", "\n", "if", "meter", "is", "not", "None", ":", "\n", "        ", "meter", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.reset_meters": [[236, 241], ["metrics.get_meters", "get_meters.reset"], "function", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.get_meters", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.reset"], ["", "", "def", "reset_meters", "(", "name", ":", "str", ")", "->", "None", ":", "\n", "    ", "\"\"\"Reset Meter instances aggregated under a given *name*.\"\"\"", "\n", "meters", "=", "get_meters", "(", "name", ")", "\n", "if", "meters", "is", "not", "None", ":", "\n", "        ", "meters", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.get_meter": [[243, 252], ["_aggregators[].get"], "function", ["None"], ["", "", "def", "get_meter", "(", "name", ":", "str", ",", "key", ":", "str", ")", "->", "Meter", ":", "\n", "    ", "\"\"\"Get a single Meter instance aggregated under *name* and *key*.\n\n    Returns:\n        Meter or None if no metrics have been logged under *name* and *key*.\n    \"\"\"", "\n", "if", "name", "not", "in", "_aggregators", ":", "\n", "        ", "return", "None", "\n", "", "return", "_aggregators", "[", "name", "]", ".", "get", "(", "key", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.get_meters": [[254, 261], ["_aggregators.get"], "function", ["None"], ["", "def", "get_meters", "(", "name", ":", "str", ")", "->", "MetersDict", ":", "\n", "    ", "\"\"\"Get Meter instances aggregated under a given *name*.\n\n    Returns:\n        MetersDict or None if no metrics have been logged under *name*.\n    \"\"\"", "\n", "return", "_aggregators", ".", "get", "(", "name", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.get_smoothed_value": [[263, 270], ["_aggregators[].get_smoothed_value"], "function", ["home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.get_smoothed_value"], ["", "def", "get_smoothed_value", "(", "name", ":", "str", ",", "key", ":", "str", ")", "->", "float", ":", "\n", "    ", "\"\"\"Get a single smoothed value.\n\n    Raises:\n        KeyError: if no metrics have been logged under *name* and *key*.\n    \"\"\"", "\n", "return", "_aggregators", "[", "name", "]", ".", "get_smoothed_value", "(", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.get_smoothed_values": [[272, 279], ["_aggregators[].get_smoothed_values"], "function", ["home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.get_smoothed_values"], ["", "def", "get_smoothed_values", "(", "name", ":", "str", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "    ", "\"\"\"Get smoothed values aggregated under a given *name*.\n\n    Raises:\n        KeyError: if no metrics have been logged under *name*.\n    \"\"\"", "\n", "return", "_aggregators", "[", "name", "]", ".", "get_smoothed_values", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.state_dict": [[281, 283], ["collections.OrderedDict", "agg.state_dict", "_aggregators.items"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.state_dict"], ["", "def", "state_dict", "(", ")", ":", "\n", "    ", "return", "OrderedDict", "(", "[", "(", "name", ",", "agg", ".", "state_dict", "(", ")", ")", "for", "name", ",", "agg", "in", "_aggregators", ".", "items", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.load_state_dict": [[285, 289], ["state_dict.items", "meters.MetersDict", "_aggregators[].load_state_dict"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict"], ["", "def", "load_state_dict", "(", "state_dict", ")", ":", "\n", "    ", "for", "name", ",", "agg_state", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "        ", "_aggregators", "[", "name", "]", "=", "MetersDict", "(", ")", "\n", "_aggregators", "[", "name", "]", ".", "load_state_dict", "(", "agg_state", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.Meter.__init__": [[38, 40], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.Meter.state_dict": [[41, 43], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.Meter.load_state_dict": [[44, 46], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.Meter.reset": [[47, 49], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.Meter.smoothed_value": [[50, 54], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "smoothed_value", "(", "self", ")", "->", "float", ":", "\n", "        ", "\"\"\"Smoothed value used for logging.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.AverageMeter.__init__": [[70, 73], ["meters.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.reset"], ["def", "__init__", "(", "self", ",", "round", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "        ", "self", ".", "round", "=", "round", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.AverageMeter.reset": [[74, 78], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "None", "# most recent update", "\n", "self", ".", "sum", "=", "0", "# sum from all updates", "\n", "self", ".", "count", "=", "0", "# total n from all updates", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.AverageMeter.update": [[79, 85], ["type_as", "type_as"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "if", "val", "is", "not", "None", ":", "\n", "            ", "self", ".", "val", "=", "val", "\n", "if", "n", ">", "0", ":", "\n", "                ", "self", ".", "sum", "=", "type_as", "(", "self", ".", "sum", ",", "val", ")", "+", "(", "val", "*", "n", ")", "\n", "self", ".", "count", "=", "type_as", "(", "self", ".", "count", ",", "n", ")", "+", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.AverageMeter.state_dict": [[86, 92], ["None"], "methods", ["None"], ["", "", "", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"val\"", ":", "self", ".", "val", ",", "\n", "\"sum\"", ":", "self", ".", "sum", ",", "\n", "\"count\"", ":", "self", ".", "count", ",", "\n", "\"round\"", ":", "self", ".", "round", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.AverageMeter.load_state_dict": [[94, 99], ["state_dict.get"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "val", "=", "state_dict", "[", "\"val\"", "]", "\n", "self", ".", "sum", "=", "state_dict", "[", "\"sum\"", "]", "\n", "self", ".", "count", "=", "state_dict", "[", "\"count\"", "]", "\n", "self", ".", "round", "=", "state_dict", ".", "get", "(", "\"round\"", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.AverageMeter.avg": [[100, 103], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "avg", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sum", "/", "self", ".", "count", "if", "self", ".", "count", ">", "0", "else", "self", ".", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.AverageMeter.smoothed_value": [[104, 110], ["meters.safe_round"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.meters.safe_round"], ["", "@", "property", "\n", "def", "smoothed_value", "(", "self", ")", "->", "float", ":", "\n", "        ", "val", "=", "self", ".", "avg", "\n", "if", "self", ".", "round", "is", "not", "None", "and", "val", "is", "not", "None", ":", "\n", "            ", "val", "=", "safe_round", "(", "val", ",", "self", ".", "round", ")", "\n", "", "return", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.TimeMeter.__init__": [[115, 123], ["meters.TimeMeter.reset"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.reset"], ["def", "__init__", "(", "\n", "self", ",", "\n", "init", ":", "int", "=", "0", ",", "\n", "n", ":", "int", "=", "0", ",", "\n", "round", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "round", "=", "round", "\n", "self", ".", "reset", "(", "init", ",", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.TimeMeter.reset": [[124, 129], ["time.perf_counter"], "methods", ["None"], ["", "def", "reset", "(", "self", ",", "init", "=", "0", ",", "n", "=", "0", ")", ":", "\n", "        ", "self", ".", "init", "=", "init", "\n", "self", ".", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "i", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.TimeMeter.update": [[130, 133], ["type_as"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", "=", "1", ")", ":", "\n", "        ", "self", ".", "n", "=", "type_as", "(", "self", ".", "n", ",", "val", ")", "+", "val", "\n", "self", ".", "i", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.TimeMeter.state_dict": [[134, 139], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"init\"", ":", "self", ".", "elapsed_time", ",", "\n", "\"n\"", ":", "self", ".", "n", ",", "\n", "\"round\"", ":", "self", ".", "round", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.TimeMeter.load_state_dict": [[141, 148], ["meters.TimeMeter.reset", "meters.TimeMeter.reset", "state_dict.get"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.reset", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.reset"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "if", "\"start\"", "in", "state_dict", ":", "\n", "# backwards compatibility for old state_dicts", "\n", "            ", "self", ".", "reset", "(", "init", "=", "state_dict", "[", "\"init\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "reset", "(", "init", "=", "state_dict", "[", "\"init\"", "]", ",", "n", "=", "state_dict", "[", "\"n\"", "]", ")", "\n", "self", ".", "round", "=", "state_dict", ".", "get", "(", "\"round\"", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.TimeMeter.avg": [[149, 152], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "avg", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n", "/", "self", ".", "elapsed_time", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.TimeMeter.elapsed_time": [[153, 156], ["time.perf_counter"], "methods", ["None"], ["", "@", "property", "\n", "def", "elapsed_time", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "init", "+", "(", "time", ".", "perf_counter", "(", ")", "-", "self", ".", "start", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.TimeMeter.smoothed_value": [[157, 163], ["meters.safe_round"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.meters.safe_round"], ["", "@", "property", "\n", "def", "smoothed_value", "(", "self", ")", "->", "float", ":", "\n", "        ", "val", "=", "self", ".", "avg", "\n", "if", "self", ".", "round", "is", "not", "None", "and", "val", "is", "not", "None", ":", "\n", "            ", "val", "=", "safe_round", "(", "val", ",", "self", ".", "round", ")", "\n", "", "return", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.__init__": [[168, 173], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "round", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "        ", "self", ".", "round", "=", "round", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "n", "=", "0", "\n", "self", ".", "start_time", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.start": [[174, 176], ["time.perf_counter"], "methods", ["None"], ["", "def", "start", "(", "self", ")", ":", "\n", "        ", "self", ".", "start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.stop": [[177, 184], ["prehook", "time.perf_counter", "type_as"], "methods", ["None"], ["", "def", "stop", "(", "self", ",", "n", "=", "1", ",", "prehook", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "start_time", "is", "not", "None", ":", "\n", "            ", "if", "prehook", "is", "not", "None", ":", "\n", "                ", "prehook", "(", ")", "\n", "", "delta", "=", "time", ".", "perf_counter", "(", ")", "-", "self", ".", "start_time", "\n", "self", ".", "sum", "=", "self", ".", "sum", "+", "delta", "\n", "self", ".", "n", "=", "type_as", "(", "self", ".", "n", ",", "n", ")", "+", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.reset": [[185, 189], ["meters.StopwatchMeter.start"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.start"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "sum", "=", "0", "# cumulative time during which stopwatch was active", "\n", "self", ".", "n", "=", "0", "# total n across all start/stop", "\n", "self", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.state_dict": [[190, 195], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"sum\"", ":", "self", ".", "sum", ",", "\n", "\"n\"", ":", "self", ".", "n", ",", "\n", "\"round\"", ":", "self", ".", "round", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.load_state_dict": [[197, 202], ["state_dict.get"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "sum", "=", "state_dict", "[", "\"sum\"", "]", "\n", "self", ".", "n", "=", "state_dict", "[", "\"n\"", "]", "\n", "self", ".", "start_time", "=", "None", "\n", "self", ".", "round", "=", "state_dict", ".", "get", "(", "\"round\"", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.avg": [[203, 206], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "avg", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sum", "/", "self", ".", "n", "if", "self", ".", "n", ">", "0", "else", "self", ".", "sum", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.elapsed_time": [[207, 212], ["time.perf_counter"], "methods", ["None"], ["", "@", "property", "\n", "def", "elapsed_time", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "start_time", "is", "None", ":", "\n", "            ", "return", "0.0", "\n", "", "return", "time", ".", "perf_counter", "(", ")", "-", "self", ".", "start_time", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.smoothed_value": [[213, 219], ["meters.safe_round"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.meters.safe_round"], ["", "@", "property", "\n", "def", "smoothed_value", "(", "self", ")", "->", "float", ":", "\n", "        ", "val", "=", "self", ".", "avg", "if", "self", ".", "sum", ">", "0", "else", "self", ".", "elapsed_time", "\n", "if", "self", ".", "round", "is", "not", "None", "and", "val", "is", "not", "None", ":", "\n", "            ", "val", "=", "safe_round", "(", "val", ",", "self", ".", "round", ")", "\n", "", "return", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.__init__": [[228, 231], ["collections.OrderedDict.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "priorities", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.__setitem__": [[232, 239], ["bisect.insort", "super().__setitem__", "meters.MetersDict.move_to_end", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.__setitem__"], ["", "def", "__setitem__", "(", "self", ",", "key", ",", "value", ")", ":", "\n", "        ", "assert", "key", "not", "in", "self", ",", "\"MetersDict doesn't support reassignment\"", "\n", "priority", ",", "value", "=", "value", "\n", "bisect", ".", "insort", "(", "self", ".", "priorities", ",", "(", "priority", ",", "len", "(", "self", ".", "priorities", ")", ",", "key", ")", ")", "\n", "super", "(", ")", ".", "__setitem__", "(", "key", ",", "value", ")", "\n", "for", "_", ",", "_", ",", "key", "in", "self", ".", "priorities", ":", "# reorder dict to match priorities", "\n", "            ", "self", ".", "move_to_end", "(", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.add_meter": [[240, 242], ["meters.MetersDict.__setitem__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.__setitem__"], ["", "", "def", "add_meter", "(", "self", ",", "key", ",", "meter", ",", "priority", ")", ":", "\n", "        ", "self", ".", "__setitem__", "(", "key", ",", "(", "priority", ",", "meter", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.state_dict": [[243, 249], ["meters.MetersDict.state_dict", "isinstance"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "(", "pri", ",", "key", ",", "self", "[", "key", "]", ".", "__class__", ".", "__name__", ",", "self", "[", "key", "]", ".", "state_dict", "(", ")", ")", "\n", "for", "pri", ",", "_", ",", "key", "in", "self", ".", "priorities", "\n", "# can't serialize DerivedMeter instances", "\n", "if", "not", "isinstance", "(", "self", "[", "key", "]", ",", "MetersDict", ".", "_DerivedMeter", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.load_state_dict": [[251, 258], ["meters.MetersDict.clear", "meters.MetersDict.priorities.clear", "meter.load_state_dict", "meters.MetersDict.add_meter", "globals"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.add_meter"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "clear", "(", ")", "\n", "self", ".", "priorities", ".", "clear", "(", ")", "\n", "for", "pri", ",", "key", ",", "meter_cls", ",", "meter_state", "in", "state_dict", ":", "\n", "            ", "meter", "=", "globals", "(", ")", "[", "meter_cls", "]", "(", ")", "\n", "meter", ".", "load_state_dict", "(", "meter_state", ")", "\n", "self", ".", "add_meter", "(", "key", ",", "meter", ",", "pri", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.get_smoothed_value": [[259, 266], ["isinstance", "meter.fn"], "methods", ["None"], ["", "", "def", "get_smoothed_value", "(", "self", ",", "key", ":", "str", ")", "->", "float", ":", "\n", "        ", "\"\"\"Get a single smoothed value.\"\"\"", "\n", "meter", "=", "self", "[", "key", "]", "\n", "if", "isinstance", "(", "meter", ",", "MetersDict", ".", "_DerivedMeter", ")", ":", "\n", "            ", "return", "meter", ".", "fn", "(", "self", ")", "\n", "", "else", ":", "\n", "            ", "return", "meter", ".", "smoothed_value", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.get_smoothed_values": [[267, 274], ["collections.OrderedDict", "meters.MetersDict.get_smoothed_value", "meters.MetersDict.keys", "key.startswith"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.get_smoothed_value"], ["", "", "def", "get_smoothed_values", "(", "self", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "\"\"\"Get all smoothed values.\"\"\"", "\n", "return", "OrderedDict", "(", "\n", "[", "\n", "(", "key", ",", "self", ".", "get_smoothed_value", "(", "key", ")", ")", "\n", "for", "key", "in", "self", ".", "keys", "(", ")", "\n", "if", "not", "key", ".", "startswith", "(", "\"_\"", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.reset": [[277, 283], ["meters.MetersDict.values", "isinstance", "meter.reset"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reset Meter instances.\"\"\"", "\n", "for", "meter", "in", "self", ".", "values", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "meter", ",", "MetersDict", ".", "_DerivedMeter", ")", ":", "\n", "                ", "continue", "\n", "", "meter", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.logging.meters.safe_round": [[56, 65], ["hasattr", "round", "torch.is_tensor", "meters.safe_round", "number.numel", "number.item", "hasattr", "meters.safe_round", "np.ndim", "number.item"], "function", ["home.repos.pwc.inspect_result.reneeye_const.logging.meters.safe_round", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.safe_round", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "", "def", "safe_round", "(", "number", ",", "ndigits", ")", ":", "\n", "    ", "if", "hasattr", "(", "number", ",", "\"__round__\"", ")", ":", "\n", "        ", "return", "round", "(", "number", ",", "ndigits", ")", "\n", "", "elif", "torch", "is", "not", "None", "and", "torch", ".", "is_tensor", "(", "number", ")", "and", "number", ".", "numel", "(", ")", "==", "1", ":", "\n", "        ", "return", "safe_round", "(", "number", ".", "item", "(", ")", ",", "ndigits", ")", "\n", "", "elif", "np", "is", "not", "None", "and", "np", ".", "ndim", "(", "number", ")", "==", "0", "and", "hasattr", "(", "number", ",", "\"item\"", ")", ":", "\n", "        ", "return", "safe_round", "(", "number", ".", "item", "(", ")", ",", "ndigits", ")", "\n", "", "else", ":", "\n", "        ", "return", "number", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.positional_embedding.PositionalEmbedding": [[12, 36], ["learned_positional_embedding.LearnedPositionalEmbedding", "torch.init.normal_", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding", "torch.init.constant_"], "function", ["None"], ["def", "PositionalEmbedding", "(", "\n", "num_embeddings", ":", "int", ",", "\n", "embedding_dim", ":", "int", ",", "\n", "padding_idx", ":", "int", ",", "\n", "learned", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "    ", "if", "learned", ":", "\n", "# if padding_idx is specified then offset the embedding ids by", "\n", "# this index and adjust num_embeddings appropriately", "\n", "# TODO: The right place for this offset would be inside", "\n", "# LearnedPositionalEmbedding. Move this there for a cleaner implementation.", "\n", "        ", "if", "padding_idx", "is", "not", "None", ":", "\n", "            ", "num_embeddings", "=", "num_embeddings", "+", "padding_idx", "+", "1", "\n", "", "m", "=", "LearnedPositionalEmbedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "embedding_dim", "**", "-", "0.5", ")", "\n", "if", "padding_idx", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "", "", "else", ":", "\n", "        ", "m", "=", "SinusoidalPositionalEmbedding", "(", "\n", "embedding_dim", ",", "\n", "padding_idx", ",", "\n", "init_size", "=", "num_embeddings", "+", "padding_idx", "+", "1", ",", "\n", ")", "\n", "", "return", "m", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.__init__": [[22, 79], ["torch.Module.__init__", "fairseq.modules.fairseq_dropout.FairseqDropout", "fairseq.modules.fairseq_dropout.FairseqDropout", "fairseq.utils.get_activation_fn", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.build_self_attention", "fairseq.modules.LayerNorm", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.build_fc1", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.build_fc2", "fairseq.modules.LayerNorm", "init_fn"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.ModelParallelTransformerDecoderLayer.build_self_attention", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.ModelParallelTransformerDecoderLayer.build_fc1", "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.ModelParallelTransformerDecoderLayer.build_fc2", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embedding_dim", ":", "int", "=", "768", ",", "\n", "ffn_embedding_dim", ":", "int", "=", "3072", ",", "\n", "num_attention_heads", ":", "int", "=", "8", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "attention_dropout", ":", "float", "=", "0.1", ",", "\n", "activation_dropout", ":", "float", "=", "0.1", ",", "\n", "activation_fn", ":", "str", "=", "\"relu\"", ",", "\n", "export", ":", "bool", "=", "False", ",", "\n", "q_noise", ":", "float", "=", "0.0", ",", "\n", "qn_block_size", ":", "int", "=", "8", ",", "\n", "init_fn", ":", "Callable", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "init_fn", "is", "not", "None", ":", "\n", "            ", "init_fn", "(", ")", "\n", "\n", "# Initialize parameters", "\n", "", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "activation_dropout_module", "=", "FairseqDropout", "(", "\n", "activation_dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "\n", "# Initialize blocks", "\n", "self", ".", "activation_fn", "=", "utils", ".", "get_activation_fn", "(", "activation_fn", ")", "\n", "self", ".", "self_attn", "=", "self", ".", "build_self_attention", "(", "\n", "self", ".", "embedding_dim", ",", "\n", "num_attention_heads", ",", "\n", "dropout", "=", "attention_dropout", ",", "\n", "self_attention", "=", "True", ",", "\n", "q_noise", "=", "q_noise", ",", "\n", "qn_block_size", "=", "qn_block_size", ",", "\n", ")", "\n", "\n", "# layer norm associated with the self attention layer", "\n", "self", ".", "self_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embedding_dim", ",", "export", "=", "export", ")", "\n", "\n", "self", ".", "fc1", "=", "self", ".", "build_fc1", "(", "\n", "self", ".", "embedding_dim", ",", "\n", "ffn_embedding_dim", ",", "\n", "q_noise", "=", "q_noise", ",", "\n", "qn_block_size", "=", "qn_block_size", ",", "\n", ")", "\n", "self", ".", "fc2", "=", "self", ".", "build_fc2", "(", "\n", "ffn_embedding_dim", ",", "\n", "self", ".", "embedding_dim", ",", "\n", "q_noise", "=", "q_noise", ",", "\n", "qn_block_size", "=", "qn_block_size", ",", "\n", ")", "\n", "\n", "# layer norm associated with the position wise feed-forward NN", "\n", "self", ".", "final_layer_norm", "=", "LayerNorm", "(", "self", ".", "embedding_dim", ",", "export", "=", "export", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.build_fc1": [[80, 82], ["fairseq.modules.quant_noise.quant_noise", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["", "def", "build_fc1", "(", "self", ",", "input_dim", ",", "output_dim", ",", "q_noise", ",", "qn_block_size", ")", ":", "\n", "        ", "return", "quant_noise", "(", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ")", ",", "q_noise", ",", "qn_block_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.build_fc2": [[83, 85], ["fairseq.modules.quant_noise.quant_noise", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["", "def", "build_fc2", "(", "self", ",", "input_dim", ",", "output_dim", ",", "q_noise", ",", "qn_block_size", ")", ":", "\n", "        ", "return", "quant_noise", "(", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ")", ",", "q_noise", ",", "qn_block_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.build_self_attention": [[86, 102], ["fairseq.modules.MultiheadAttention"], "methods", ["None"], ["", "def", "build_self_attention", "(", "\n", "self", ",", "\n", "embed_dim", ",", "\n", "num_attention_heads", ",", "\n", "dropout", ",", "\n", "self_attention", ",", "\n", "q_noise", ",", "\n", "qn_block_size", ",", "\n", ")", ":", "\n", "        ", "return", "MultiheadAttention", "(", "\n", "embed_dim", ",", "\n", "num_attention_heads", ",", "\n", "dropout", "=", "dropout", ",", "\n", "self_attention", "=", "True", ",", "\n", "q_noise", "=", "q_noise", ",", "\n", "qn_block_size", "=", "qn_block_size", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.forward": [[104, 135], ["transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.self_attn", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.dropout_module", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.self_attn_layer_norm", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.activation_fn", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.activation_dropout_module", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.fc2", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.dropout_module", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.final_layer_norm", "transformer_sentence_encoder_layer.TransformerSentenceEncoderLayer.fc1"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "x", ":", "torch", ".", "Tensor", ",", "\n", "self_attn_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "self_attn_padding_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        LayerNorm is applied either before or after the self-attention/ffn\n        modules similar to the original Transformer implementation.\n        \"\"\"", "\n", "residual", "=", "x", "\n", "x", ",", "attn", "=", "self", ".", "self_attn", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "x", ",", "\n", "value", "=", "x", ",", "\n", "key_padding_mask", "=", "self_attn_padding_mask", ",", "\n", "need_weights", "=", "False", ",", "\n", "attn_mask", "=", "self_attn_mask", ",", "\n", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "self_attn_layer_norm", "(", "x", ")", "\n", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "activation_dropout_module", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "final_layer_norm", "(", "x", ")", "\n", "return", "x", ",", "attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.layer_drop.LayerDropModuleList.__init__": [[36, 39], ["torch.ModuleList.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "p", ",", "modules", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "modules", ")", "\n", "self", ".", "p", "=", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.layer_drop.LayerDropModuleList.__iter__": [[40, 45], ["torch.empty().uniform_", "torch.empty().uniform_", "torch.empty().uniform_", "torch.empty().uniform_", "enumerate", "torch.ModuleList.__iter__", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.list_dataset.ListDataset.__iter__"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "dropout_probs", "=", "torch", ".", "empty", "(", "len", "(", "self", ")", ")", ".", "uniform_", "(", ")", "\n", "for", "i", ",", "m", "in", "enumerate", "(", "super", "(", ")", ".", "__iter__", "(", ")", ")", ":", "\n", "            ", "if", "not", "self", ".", "training", "or", "(", "dropout_probs", "[", "i", "]", ">", "self", ".", "p", ")", ":", "\n", "                ", "yield", "m", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.adaptive_input.AdaptiveInput.__init__": [[15, 65], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "range", "adaptive_input.AdaptiveInput.apply", "adaptive_input.AdaptiveInput.register_buffer", "len", "int", "torch.nn.Sequential", "adaptive_input.AdaptiveInput.embeddings.append", "isinstance", "torch.FloatTensor", "torch.nn.Embedding", "fairseq.modules.quant_noise.quant_noise", "torch.nn.init.normal_", "torch.nn.init.constant_", "hasattr", "torch.nn.Linear", "torch.nn.init.xavier_uniform_"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size", ":", "int", ",", "\n", "padding_idx", ":", "int", ",", "\n", "initial_dim", ":", "int", ",", "\n", "factor", ":", "float", ",", "\n", "output_dim", ":", "int", ",", "\n", "cutoff", ":", "List", "[", "int", "]", ",", "\n", "q_noise", ":", "float", "=", "0", ",", "\n", "qn_block_size", ":", "int", "=", "8", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "vocab_size", ">", "cutoff", "[", "-", "1", "]", ":", "\n", "            ", "cutoff", "=", "cutoff", "+", "[", "vocab_size", "]", "\n", "", "else", ":", "\n", "            ", "assert", "(", "\n", "vocab_size", "==", "cutoff", "[", "-", "1", "]", "\n", ")", ",", "\"cannot specify cutoff larger than vocab size\"", "\n", "\n", "", "self", ".", "cutoff", "=", "cutoff", "\n", "self", ".", "embedding_dim", "=", "output_dim", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "\n", "self", ".", "embeddings", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoff", ")", ")", ":", "\n", "            ", "prev", "=", "self", ".", "cutoff", "[", "i", "-", "1", "]", "if", "i", ">", "0", "else", "0", "\n", "size", "=", "self", ".", "cutoff", "[", "i", "]", "-", "prev", "\n", "dim", "=", "int", "(", "initial_dim", "//", "(", "factor", "**", "i", ")", ")", "\n", "seq", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Embedding", "(", "size", ",", "dim", ",", "self", ".", "padding_idx", ")", ",", "\n", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "dim", ",", "output_dim", ",", "bias", "=", "False", ")", ",", "q_noise", ",", "qn_block_size", "\n", ")", ",", "\n", ")", "\n", "\n", "self", ".", "embeddings", ".", "append", "(", "seq", ")", "\n", "self", ".", "padding_idx", "=", "None", "\n", "", "self", ".", "padding_idx", "=", "padding_idx", "\n", "\n", "def", "init_weights", "(", "m", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Embedding", ")", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "m", ".", "weight", ".", "shape", "[", "1", "]", "**", "-", "0.5", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "", "elif", "hasattr", "(", "m", ",", "\"weight\"", ")", ":", "\n", "                ", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "init_weights", ")", "\n", "\n", "self", ".", "register_buffer", "(", "\"_float_tensor\"", ",", "torch", ".", "FloatTensor", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.adaptive_input.AdaptiveInput.weights_for_band": [[66, 68], ["None"], "methods", ["None"], ["", "def", "weights_for_band", "(", "self", ",", "band", ":", "int", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", "[", "band", "]", "[", "0", "]", ".", "weight", ",", "self", ".", "embeddings", "[", "band", "]", "[", "1", "]", ".", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.adaptive_input.AdaptiveInput.forward": [[69, 81], ["adaptive_input.AdaptiveInput._float_tensor.new", "range", "len", "input.lt", "input.lt.any", "input.lt.mul_", "input.ge"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "result", "=", "self", ".", "_float_tensor", ".", "new", "(", "input", ".", "shape", "+", "(", "self", ".", "embedding_dim", ",", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoff", ")", ")", ":", "\n", "            ", "mask", "=", "input", ".", "lt", "(", "self", ".", "cutoff", "[", "i", "]", ")", "\n", "if", "i", ">", "0", ":", "\n", "                ", "mask", ".", "mul_", "(", "input", ".", "ge", "(", "self", ".", "cutoff", "[", "i", "-", "1", "]", ")", ")", "\n", "chunk_input", "=", "input", "[", "mask", "]", "-", "self", ".", "cutoff", "[", "i", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "chunk_input", "=", "input", "[", "mask", "]", "\n", "", "if", "mask", ".", "any", "(", ")", ":", "\n", "                ", "result", "[", "mask", "]", "=", "self", ".", "embeddings", "[", "i", "]", "(", "chunk_input", ")", "\n", "", "", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.grad_multiply.GradMultiply.forward": [[10, 15], ["x.new"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "scale", ")", ":", "\n", "        ", "ctx", ".", "scale", "=", "scale", "\n", "res", "=", "x", ".", "new", "(", "x", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.grad_multiply.GradMultiply.backward": [[16, 19], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad", ")", ":", "\n", "        ", "return", "grad", "*", "ctx", ".", "scale", ",", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.learned_positional_embedding.LearnedPositionalEmbedding.__init__": [[23, 30], ["torch.Embedding.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "num_embeddings", ":", "int", ",", "embedding_dim", ":", "int", ",", "padding_idx", ":", "int", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "if", "self", ".", "padding_idx", "is", "not", "None", ":", "\n", "            ", "self", ".", "max_positions", "=", "self", ".", "num_embeddings", "-", "self", ".", "padding_idx", "-", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "max_positions", "=", "self", ".", "num_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.learned_positional_embedding.LearnedPositionalEmbedding.forward": [[31, 61], ["torch.embedding", "torch.embedding", "torch.embedding", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "fairseq.utils.make_positions", "int", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "input.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.make_positions", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "input", ":", "Tensor", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", "=", "None", ",", "\n", "positions", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [bsz x seqlen].\"\"\"", "\n", "assert", "(", "positions", "is", "None", ")", "or", "(", "\n", "self", ".", "padding_idx", "is", "None", "\n", ")", ",", "\"If positions is pre-computed then padding_idx should not be set.\"", "\n", "\n", "if", "positions", "is", "None", ":", "\n", "            ", "if", "incremental_state", "is", "not", "None", ":", "\n", "# positions is the same for every token when decoding a single step", "\n", "# Without the int() cast, it doesn't work in some cases when exporting to ONNX", "\n", "                ", "positions", "=", "torch", ".", "zeros", "(", "\n", "(", "1", ",", "1", ")", ",", "device", "=", "input", ".", "device", ",", "dtype", "=", "input", ".", "dtype", "\n", ")", ".", "fill_", "(", "int", "(", "self", ".", "padding_idx", "+", "input", ".", "size", "(", "1", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "positions", "=", "utils", ".", "make_positions", "(", "\n", "input", ",", "self", ".", "padding_idx", ",", "onnx_trace", "=", "self", ".", "onnx_trace", "\n", ")", "\n", "", "", "return", "F", ".", "embedding", "(", "\n", "positions", ",", "\n", "self", ".", "weight", ",", "\n", "self", ".", "padding_idx", ",", "\n", "self", ".", "max_norm", ",", "\n", "self", ".", "norm_type", ",", "\n", "self", ".", "scale_grad_by_freq", ",", "\n", "self", ".", "sparse", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.MultiheadAttention.__init__": [[26, 91], ["torch.nn.Module.__init__", "fairseq.modules.fairseq_dropout.FairseqDropout", "fairseq.modules.quant_noise.quant_noise", "fairseq.modules.quant_noise.quant_noise", "fairseq.modules.quant_noise.quant_noise", "fairseq.modules.quant_noise.quant_noise", "multihead_attention.MultiheadAttention.reset_parameters", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embed_dim", ",", "\n", "num_heads", ",", "\n", "kdim", "=", "None", ",", "\n", "vdim", "=", "None", ",", "\n", "dropout", "=", "0.0", ",", "\n", "bias", "=", "True", ",", "\n", "add_bias_kv", "=", "False", ",", "\n", "add_zero_attn", "=", "False", ",", "\n", "self_attention", "=", "False", ",", "\n", "encoder_decoder_attention", "=", "False", ",", "\n", "q_noise", "=", "0.0", ",", "\n", "qn_block_size", "=", "8", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "kdim", "=", "kdim", "if", "kdim", "is", "not", "None", "else", "embed_dim", "\n", "self", ".", "vdim", "=", "vdim", "if", "vdim", "is", "not", "None", "else", "embed_dim", "\n", "self", ".", "qkv_same_dim", "=", "self", ".", "kdim", "==", "embed_dim", "and", "self", ".", "vdim", "==", "embed_dim", "\n", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "assert", "(", "\n", "self", ".", "head_dim", "*", "num_heads", "==", "self", ".", "embed_dim", "\n", ")", ",", "\"embed_dim must be divisible by num_heads\"", "\n", "self", ".", "scaling", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "self_attention", "=", "self_attention", "\n", "self", ".", "encoder_decoder_attention", "=", "encoder_decoder_attention", "\n", "\n", "assert", "not", "self", ".", "self_attention", "or", "self", ".", "qkv_same_dim", ",", "(", "\n", "\"Self-attention requires query, key and \"", "\"value to be of the same size\"", "\n", ")", "\n", "\n", "self", ".", "k_proj", "=", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "kdim", ",", "embed_dim", ",", "bias", "=", "bias", ")", ",", "q_noise", ",", "qn_block_size", "\n", ")", "\n", "self", ".", "v_proj", "=", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "vdim", ",", "embed_dim", ",", "bias", "=", "bias", ")", ",", "q_noise", ",", "qn_block_size", "\n", ")", "\n", "self", ".", "q_proj", "=", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "bias", ")", ",", "q_noise", ",", "qn_block_size", "\n", ")", "\n", "\n", "self", ".", "out_proj", "=", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "bias", ")", ",", "q_noise", ",", "qn_block_size", "\n", ")", "\n", "\n", "if", "add_bias_kv", ":", "\n", "            ", "self", ".", "bias_k", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "1", ",", "embed_dim", ")", ")", "\n", "self", ".", "bias_v", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "1", ",", "embed_dim", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias_k", "=", "self", ".", "bias_v", "=", "None", "\n", "\n", "", "self", ".", "add_zero_attn", "=", "add_zero_attn", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "self", ".", "tpu", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.MultiheadAttention.prepare_for_onnx_export_": [[92, 94], ["None"], "methods", ["None"], ["", "def", "prepare_for_onnx_export_", "(", "self", ")", ":", "\n", "        ", "self", ".", "onnx_trace", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.MultiheadAttention.prepare_for_tpu_": [[95, 97], ["None"], "methods", ["None"], ["", "def", "prepare_for_tpu_", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "tpu", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.MultiheadAttention.reset_parameters": [[98, 117], ["torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "math.sqrt", "math.sqrt", "math.sqrt"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "qkv_same_dim", ":", "\n", "# Empirically observed the convergence to be much better with", "\n", "# the scaled initialization", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "k_proj", ".", "weight", ",", "gain", "=", "1", "/", "math", ".", "sqrt", "(", "2", ")", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "v_proj", ".", "weight", ",", "gain", "=", "1", "/", "math", ".", "sqrt", "(", "2", ")", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "q_proj", ".", "weight", ",", "gain", "=", "1", "/", "math", ".", "sqrt", "(", "2", ")", ")", "\n", "", "else", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "k_proj", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "v_proj", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "q_proj", ".", "weight", ")", "\n", "\n", "", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "out_proj", ".", "weight", ")", "\n", "if", "self", ".", "out_proj", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.0", ")", "\n", "", "if", "self", ".", "bias_k", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "bias_k", ")", "\n", "", "if", "self", ".", "bias_v", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "bias_v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.MultiheadAttention.forward": [[118, 380], ["query.size", "multihead_attention.MultiheadAttention.contiguous().view().transpose", "torch.cat.size", "torch.cat.size", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "multihead_attention.MultiheadAttention.apply_sparse_mask", "fairseq.utils.softmax", "fairseq.utils.softmax.type_as", "multihead_attention.MultiheadAttention.dropout_module", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "multihead_attention.MultiheadAttention.out_proj", "list", "torch.multi_head_attention_forward", "torch.multi_head_attention_forward", "multihead_attention.MultiheadAttention._get_input_buffer", "multihead_attention.MultiheadAttention.q_proj", "multihead_attention.MultiheadAttention.k_proj", "multihead_attention.MultiheadAttention.v_proj", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.contiguous().view().transpose", "torch.cat.contiguous().view().transpose", "torch.cat.contiguous().view().transpose", "torch.cat.contiguous().view().transpose", "multihead_attention.MultiheadAttention._append_prev_key_padding_mask", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat.view", "multihead_attention.MultiheadAttention._set_input_buffer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.transpose", "torch.cat.transpose", "list", "attn_mask.repeat.repeat.unsqueeze", "attn_weights.mean.mean.view", "attn_weights.mean.mean.view", "list", "attn.transpose().contiguous().view.transpose().contiguous().view.contiguous().view", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "fairseq.utils.softmax.view().transpose", "query.size", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "multihead_attention.MultiheadAttention.q_proj", "multihead_attention.MultiheadAttention.q_proj", "multihead_attention.MultiheadAttention.k_proj", "multihead_attention.MultiheadAttention.v_proj", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "multihead_attention.MultiheadAttention.contiguous().view", "_prev_key.view", "_prev_value.view", "torch.cat.dim", "torch.cat.dim", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "attn_weights.mean.mean.size", "attn_mask.repeat.repeat.repeat", "attn_weights.mean.mean.masked_fill", "attn_weights.mean.mean.transpose", "attn_weights.mean.mean.masked_fill", "attn_weights.mean.mean.transpose", "attn.transpose().contiguous().view.transpose().contiguous().view.size", "attn.transpose().contiguous().view.transpose().contiguous().view.size", "attn_weights.mean.mean.mean", "multihead_attention.MultiheadAttention.k_proj", "multihead_attention.MultiheadAttention.v_proj", "multihead_attention.MultiheadAttention.bias_k.repeat", "multihead_attention.MultiheadAttention.bias_v.repeat", "torch.cat.contiguous().view", "torch.cat.contiguous().view", "torch.cat.contiguous().view", "torch.cat.contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "torch.cat.size", "torch.cat.new_zeros", "torch.cat.new_zeros", "torch.cat.new_zeros", "torch.cat.new_zeros", "attn_weights.mean.mean.size", "torch.cat.unsqueeze().unsqueeze().to", "torch.cat.unsqueeze().unsqueeze().to", "float", "float", "attn.transpose().contiguous().view.transpose().contiguous().view.contiguous", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "fairseq.utils.softmax.view", "attn_mask.repeat.repeat.new_zeros", "torch.cat.new_zeros", "torch.cat.new_zeros", "multihead_attention.MultiheadAttention.contiguous", "attn_mask.repeat.repeat.new_zeros", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "attn_mask.repeat.repeat.size", "torch.cat.size", "torch.cat.size", "torch.cat.contiguous", "torch.cat.contiguous", "torch.cat.contiguous", "torch.cat.contiguous", "attn_mask.repeat.repeat.size", "torch.cat.unsqueeze().unsqueeze", "torch.cat.unsqueeze().unsqueeze", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat.size", "torch.cat.size", "torch.cat.unsqueeze", "torch.cat.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.modules.sparse_multihead_attention.SparseMultiheadAttention.apply_sparse_mask", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.ModelParallelMultiheadAttention._append_prev_key_padding_mask", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "query", ",", "\n", "key", ":", "Optional", "[", "Tensor", "]", ",", "\n", "value", ":", "Optional", "[", "Tensor", "]", ",", "\n", "key_padding_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", "=", "None", ",", "\n", "need_weights", ":", "bool", "=", "True", ",", "\n", "static_kv", ":", "bool", "=", "False", ",", "\n", "attn_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "before_softmax", ":", "bool", "=", "False", ",", "\n", "need_head_weights", ":", "bool", "=", "False", ",", "\n", ")", "->", "Tuple", "[", "Tensor", ",", "Optional", "[", "Tensor", "]", "]", ":", "\n", "        ", "\"\"\"Input shape: Time x Batch x Channel\n\n        Args:\n            key_padding_mask (ByteTensor, optional): mask to exclude\n                keys that are pads, of shape `(batch, src_len)`, where\n                padding elements are indicated by 1s.\n            need_weights (bool, optional): return the attention weights,\n                averaged over heads (default: False).\n            attn_mask (ByteTensor, optional): typically used to\n                implement causal attention, where the mask prevents the\n                attention from looking forward in time (default: None).\n            before_softmax (bool, optional): return the raw attention\n                weights and values before the attention softmax.\n            need_head_weights (bool, optional): return the attention\n                weights for each head. Implies *need_weights*. Default:\n                return the average attention weights over all heads.\n        \"\"\"", "\n", "if", "need_head_weights", ":", "\n", "            ", "need_weights", "=", "True", "\n", "\n", "", "tgt_len", ",", "bsz", ",", "embed_dim", "=", "query", ".", "size", "(", ")", "\n", "assert", "embed_dim", "==", "self", ".", "embed_dim", "\n", "assert", "list", "(", "query", ".", "size", "(", ")", ")", "==", "[", "tgt_len", ",", "bsz", ",", "embed_dim", "]", "\n", "\n", "if", "(", "\n", "not", "self", ".", "onnx_trace", "\n", "and", "not", "self", ".", "tpu", "# don't use PyTorch version on TPUs", "\n", "and", "incremental_state", "is", "None", "\n", "and", "not", "static_kv", "\n", "# A workaround for quantization to work. Otherwise JIT compilation", "\n", "# treats bias in linear module as method.", "\n", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", "\n", ")", ":", "\n", "            ", "assert", "key", "is", "not", "None", "and", "value", "is", "not", "None", "\n", "return", "F", ".", "multi_head_attention_forward", "(", "\n", "query", ",", "\n", "key", ",", "\n", "value", ",", "\n", "self", ".", "embed_dim", ",", "\n", "self", ".", "num_heads", ",", "\n", "torch", ".", "empty", "(", "[", "0", "]", ")", ",", "\n", "torch", ".", "cat", "(", "(", "self", ".", "q_proj", ".", "bias", ",", "self", ".", "k_proj", ".", "bias", ",", "self", ".", "v_proj", ".", "bias", ")", ")", ",", "\n", "self", ".", "bias_k", ",", "\n", "self", ".", "bias_v", ",", "\n", "self", ".", "add_zero_attn", ",", "\n", "self", ".", "dropout_module", ".", "p", ",", "\n", "self", ".", "out_proj", ".", "weight", ",", "\n", "self", ".", "out_proj", ".", "bias", ",", "\n", "self", ".", "training", "or", "self", ".", "dropout_module", ".", "apply_during_inference", ",", "\n", "key_padding_mask", ",", "\n", "need_weights", ",", "\n", "attn_mask", ",", "\n", "use_separate_proj_weight", "=", "True", ",", "\n", "q_proj_weight", "=", "self", ".", "q_proj", ".", "weight", ",", "\n", "k_proj_weight", "=", "self", ".", "k_proj", ".", "weight", ",", "\n", "v_proj_weight", "=", "self", ".", "v_proj", ".", "weight", ",", "\n", ")", "\n", "\n", "", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "saved_state", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "saved_state", "is", "not", "None", "and", "\"prev_key\"", "in", "saved_state", ":", "\n", "# previous time steps are cached - no need to recompute", "\n", "# key and value if they are static", "\n", "                ", "if", "static_kv", ":", "\n", "                    ", "assert", "self", ".", "encoder_decoder_attention", "and", "not", "self", ".", "self_attention", "\n", "key", "=", "value", "=", "None", "\n", "", "", "", "else", ":", "\n", "            ", "saved_state", "=", "None", "\n", "\n", "", "if", "self", ".", "self_attention", ":", "\n", "            ", "q", "=", "self", ".", "q_proj", "(", "query", ")", "\n", "k", "=", "self", ".", "k_proj", "(", "query", ")", "\n", "v", "=", "self", ".", "v_proj", "(", "query", ")", "\n", "", "elif", "self", ".", "encoder_decoder_attention", ":", "\n", "# encoder-decoder attention", "\n", "            ", "q", "=", "self", ".", "q_proj", "(", "query", ")", "\n", "if", "key", "is", "None", ":", "\n", "                ", "assert", "value", "is", "None", "\n", "k", "=", "v", "=", "None", "\n", "", "else", ":", "\n", "                ", "k", "=", "self", ".", "k_proj", "(", "key", ")", "\n", "v", "=", "self", ".", "v_proj", "(", "key", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "assert", "key", "is", "not", "None", "and", "value", "is", "not", "None", "\n", "q", "=", "self", ".", "q_proj", "(", "query", ")", "\n", "k", "=", "self", ".", "k_proj", "(", "key", ")", "\n", "v", "=", "self", ".", "v_proj", "(", "value", ")", "\n", "", "q", "*=", "self", ".", "scaling", "\n", "\n", "if", "self", ".", "bias_k", "is", "not", "None", ":", "\n", "            ", "assert", "self", ".", "bias_v", "is", "not", "None", "\n", "k", "=", "torch", ".", "cat", "(", "[", "k", ",", "self", ".", "bias_k", ".", "repeat", "(", "1", ",", "bsz", ",", "1", ")", "]", ")", "\n", "v", "=", "torch", ".", "cat", "(", "[", "v", ",", "self", ".", "bias_v", ".", "repeat", "(", "1", ",", "bsz", ",", "1", ")", "]", ")", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "                ", "attn_mask", "=", "torch", ".", "cat", "(", "\n", "[", "attn_mask", ",", "attn_mask", ".", "new_zeros", "(", "attn_mask", ".", "size", "(", "0", ")", ",", "1", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "                ", "key_padding_mask", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "key_padding_mask", ",", "\n", "key_padding_mask", ".", "new_zeros", "(", "key_padding_mask", ".", "size", "(", "0", ")", ",", "1", ")", ",", "\n", "]", ",", "\n", "dim", "=", "1", ",", "\n", ")", "\n", "\n", "", "", "q", "=", "(", "\n", "q", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "tgt_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", "\n", ".", "transpose", "(", "0", ",", "1", ")", "\n", ")", "\n", "if", "k", "is", "not", "None", ":", "\n", "            ", "k", "=", "(", "\n", "k", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", "\n", ".", "transpose", "(", "0", ",", "1", ")", "\n", ")", "\n", "", "if", "v", "is", "not", "None", ":", "\n", "            ", "v", "=", "(", "\n", "v", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", "\n", ".", "transpose", "(", "0", ",", "1", ")", "\n", ")", "\n", "\n", "", "if", "saved_state", "is", "not", "None", ":", "\n", "# saved states are stored with shape (bsz, num_heads, seq_len, head_dim)", "\n", "            ", "if", "\"prev_key\"", "in", "saved_state", ":", "\n", "                ", "_prev_key", "=", "saved_state", "[", "\"prev_key\"", "]", "\n", "assert", "_prev_key", "is", "not", "None", "\n", "prev_key", "=", "_prev_key", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "if", "static_kv", ":", "\n", "                    ", "k", "=", "prev_key", "\n", "", "else", ":", "\n", "                    ", "assert", "k", "is", "not", "None", "\n", "k", "=", "torch", ".", "cat", "(", "[", "prev_key", ",", "k", "]", ",", "dim", "=", "1", ")", "\n", "", "", "if", "\"prev_value\"", "in", "saved_state", ":", "\n", "                ", "_prev_value", "=", "saved_state", "[", "\"prev_value\"", "]", "\n", "assert", "_prev_value", "is", "not", "None", "\n", "prev_value", "=", "_prev_value", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "if", "static_kv", ":", "\n", "                    ", "v", "=", "prev_value", "\n", "", "else", ":", "\n", "                    ", "assert", "v", "is", "not", "None", "\n", "v", "=", "torch", ".", "cat", "(", "[", "prev_value", ",", "v", "]", ",", "dim", "=", "1", ")", "\n", "", "", "prev_key_padding_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "if", "\"prev_key_padding_mask\"", "in", "saved_state", ":", "\n", "                ", "prev_key_padding_mask", "=", "saved_state", "[", "\"prev_key_padding_mask\"", "]", "\n", "", "assert", "k", "is", "not", "None", "and", "v", "is", "not", "None", "\n", "key_padding_mask", "=", "MultiheadAttention", ".", "_append_prev_key_padding_mask", "(", "\n", "key_padding_mask", "=", "key_padding_mask", ",", "\n", "prev_key_padding_mask", "=", "prev_key_padding_mask", ",", "\n", "batch_size", "=", "bsz", ",", "\n", "src_len", "=", "k", ".", "size", "(", "1", ")", ",", "\n", "static_kv", "=", "static_kv", ",", "\n", ")", "\n", "\n", "saved_state", "[", "\"prev_key\"", "]", "=", "k", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "saved_state", "[", "\"prev_value\"", "]", "=", "v", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "saved_state", "[", "\"prev_key_padding_mask\"", "]", "=", "key_padding_mask", "\n", "# In this branch incremental_state is never None", "\n", "assert", "incremental_state", "is", "not", "None", "\n", "incremental_state", "=", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "saved_state", ")", "\n", "", "assert", "k", "is", "not", "None", "\n", "src_len", "=", "k", ".", "size", "(", "1", ")", "\n", "\n", "# This is part of a workaround to get around fork/join parallelism", "\n", "# not supporting Optional types.", "\n", "if", "key_padding_mask", "is", "not", "None", "and", "key_padding_mask", ".", "dim", "(", ")", "==", "0", ":", "\n", "            ", "key_padding_mask", "=", "None", "\n", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "            ", "assert", "key_padding_mask", ".", "size", "(", "0", ")", "==", "bsz", "\n", "assert", "key_padding_mask", ".", "size", "(", "1", ")", "==", "src_len", "\n", "\n", "", "if", "self", ".", "add_zero_attn", ":", "\n", "            ", "assert", "v", "is", "not", "None", "\n", "src_len", "+=", "1", "\n", "k", "=", "torch", ".", "cat", "(", "[", "k", ",", "k", ".", "new_zeros", "(", "(", "k", ".", "size", "(", "0", ")", ",", "1", ")", "+", "k", ".", "size", "(", ")", "[", "2", ":", "]", ")", "]", ",", "dim", "=", "1", ")", "\n", "v", "=", "torch", ".", "cat", "(", "[", "v", ",", "v", ".", "new_zeros", "(", "(", "v", ".", "size", "(", "0", ")", ",", "1", ")", "+", "v", ".", "size", "(", ")", "[", "2", ":", "]", ")", "]", ",", "dim", "=", "1", ")", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "                ", "attn_mask", "=", "torch", ".", "cat", "(", "\n", "[", "attn_mask", ",", "attn_mask", ".", "new_zeros", "(", "attn_mask", ".", "size", "(", "0", ")", ",", "1", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "                ", "key_padding_mask", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "key_padding_mask", ",", "\n", "torch", ".", "zeros", "(", "key_padding_mask", ".", "size", "(", "0", ")", ",", "1", ")", ".", "type_as", "(", "\n", "key_padding_mask", "\n", ")", ",", "\n", "]", ",", "\n", "dim", "=", "1", ",", "\n", ")", "\n", "\n", "", "", "attn_weights", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "attn_weights", "=", "self", ".", "apply_sparse_mask", "(", "attn_weights", ",", "tgt_len", ",", "src_len", ",", "bsz", ")", "\n", "\n", "assert", "list", "(", "attn_weights", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", "]", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask", "=", "attn_mask", ".", "unsqueeze", "(", "0", ")", "\n", "if", "self", ".", "onnx_trace", ":", "\n", "                ", "attn_mask", "=", "attn_mask", ".", "repeat", "(", "attn_weights", ".", "size", "(", "0", ")", ",", "1", ",", "1", ")", "\n", "", "attn_weights", "+=", "attn_mask", "\n", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "# don't attend to padding symbols", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "if", "not", "self", ".", "tpu", ":", "\n", "                ", "attn_weights", "=", "attn_weights", ".", "masked_fill", "(", "\n", "key_padding_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", ".", "to", "(", "torch", ".", "bool", ")", ",", "\n", "float", "(", "\"-inf\"", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "attn_weights", "=", "attn_weights", ".", "transpose", "(", "0", ",", "2", ")", "\n", "attn_weights", "=", "attn_weights", ".", "masked_fill", "(", "key_padding_mask", ",", "float", "(", "\"-inf\"", ")", ")", "\n", "attn_weights", "=", "attn_weights", ".", "transpose", "(", "0", ",", "2", ")", "\n", "", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "", "if", "before_softmax", ":", "\n", "            ", "return", "attn_weights", ",", "v", "\n", "\n", "", "attn_weights_float", "=", "utils", ".", "softmax", "(", "\n", "attn_weights", ",", "dim", "=", "-", "1", ",", "onnx_trace", "=", "self", ".", "onnx_trace", "\n", ")", "\n", "attn_weights", "=", "attn_weights_float", ".", "type_as", "(", "attn_weights", ")", "\n", "attn_probs", "=", "self", ".", "dropout_module", "(", "attn_weights", ")", "\n", "\n", "assert", "v", "is", "not", "None", "\n", "attn", "=", "torch", ".", "bmm", "(", "attn_probs", ",", "v", ")", "\n", "assert", "list", "(", "attn", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "self", ".", "head_dim", "]", "\n", "if", "self", ".", "onnx_trace", "and", "attn", ".", "size", "(", "1", ")", "==", "1", ":", "\n", "# when ONNX tracing a single decoder step (sequence length == 1)", "\n", "# the transpose is a no-op copy before view, thus unnecessary", "\n", "            ", "attn", "=", "attn", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "embed_dim", ")", "\n", "", "attn", "=", "self", ".", "out_proj", "(", "attn", ")", "\n", "attn_weights", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "if", "need_weights", ":", "\n", "            ", "attn_weights", "=", "attn_weights_float", ".", "view", "(", "\n", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", "\n", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "if", "not", "need_head_weights", ":", "\n", "# average attention weights over heads", "\n", "                ", "attn_weights", "=", "attn_weights", ".", "mean", "(", "dim", "=", "0", ")", "\n", "\n", "", "", "return", "attn", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.MultiheadAttention._append_prev_key_padding_mask": [[381, 418], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "prev_key_padding_mask.float", "key_padding_mask.float", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "prev_key_padding_mask.float", "torch.zeros.float", "torch.zeros.float", "prev_key_padding_mask.size", "torch.zeros.float", "torch.zeros.float", "key_padding_mask.float", "key_padding_mask.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "@", "staticmethod", "\n", "def", "_append_prev_key_padding_mask", "(", "\n", "key_padding_mask", ":", "Optional", "[", "Tensor", "]", ",", "\n", "prev_key_padding_mask", ":", "Optional", "[", "Tensor", "]", ",", "\n", "batch_size", ":", "int", ",", "\n", "src_len", ":", "int", ",", "\n", "static_kv", ":", "bool", ",", "\n", ")", "->", "Optional", "[", "Tensor", "]", ":", "\n", "# saved key padding masks have shape (bsz, seq_len)", "\n", "        ", "if", "prev_key_padding_mask", "is", "not", "None", "and", "static_kv", ":", "\n", "            ", "new_key_padding_mask", "=", "prev_key_padding_mask", "\n", "", "elif", "prev_key_padding_mask", "is", "not", "None", "and", "key_padding_mask", "is", "not", "None", ":", "\n", "            ", "new_key_padding_mask", "=", "torch", ".", "cat", "(", "\n", "[", "prev_key_padding_mask", ".", "float", "(", ")", ",", "key_padding_mask", ".", "float", "(", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "# During incremental decoding, as the padding token enters and", "\n", "# leaves the frame, there will be a time when prev or current", "\n", "# is None", "\n", "", "elif", "prev_key_padding_mask", "is", "not", "None", ":", "\n", "            ", "filler", "=", "torch", ".", "zeros", "(", "\n", "(", "batch_size", ",", "src_len", "-", "prev_key_padding_mask", ".", "size", "(", "1", ")", ")", ",", "\n", "device", "=", "prev_key_padding_mask", ".", "device", ",", "\n", ")", "\n", "new_key_padding_mask", "=", "torch", ".", "cat", "(", "\n", "[", "prev_key_padding_mask", ".", "float", "(", ")", ",", "filler", ".", "float", "(", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "", "elif", "key_padding_mask", "is", "not", "None", ":", "\n", "            ", "filler", "=", "torch", ".", "zeros", "(", "\n", "(", "batch_size", ",", "src_len", "-", "key_padding_mask", ".", "size", "(", "1", ")", ")", ",", "\n", "device", "=", "key_padding_mask", ".", "device", ",", "\n", ")", "\n", "new_key_padding_mask", "=", "torch", ".", "cat", "(", "\n", "[", "filler", ".", "float", "(", ")", ",", "key_padding_mask", ".", "float", "(", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "", "else", ":", "\n", "            ", "new_key_padding_mask", "=", "prev_key_padding_mask", "\n", "", "return", "new_key_padding_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.MultiheadAttention.reorder_incremental_state": [[419, 438], ["multihead_attention.MultiheadAttention._get_input_buffer", "multihead_attention.MultiheadAttention.keys", "multihead_attention.MultiheadAttention._set_input_buffer", "input_buffer_k.index_select", "input_buffer_k.size", "new_order.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "reorder_incremental_state", "(", "\n", "self", ",", "\n", "incremental_state", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ",", "\n", "new_order", ":", "Tensor", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Reorder buffered internal state (for incremental generation).\"\"\"", "\n", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "not", "None", ":", "\n", "            ", "for", "k", "in", "input_buffer", ".", "keys", "(", ")", ":", "\n", "                ", "input_buffer_k", "=", "input_buffer", "[", "k", "]", "\n", "if", "input_buffer_k", "is", "not", "None", ":", "\n", "                    ", "if", "self", ".", "encoder_decoder_attention", "and", "input_buffer_k", ".", "size", "(", "\n", "0", "\n", ")", "==", "new_order", ".", "size", "(", "0", ")", ":", "\n", "                        ", "break", "\n", "", "input_buffer", "[", "k", "]", "=", "input_buffer_k", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", "", "", "incremental_state", "=", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "", "return", "incremental_state", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.MultiheadAttention._get_input_buffer": [[439, 448], ["multihead_attention.MultiheadAttention.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_incremental_state"], ["", "def", "_get_input_buffer", "(", "\n", "self", ",", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", "\n", ")", "->", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", ":", "\n", "        ", "result", "=", "self", ".", "get_incremental_state", "(", "incremental_state", ",", "\"attn_state\"", ")", "\n", "if", "result", "is", "not", "None", ":", "\n", "            ", "return", "result", "\n", "", "else", ":", "\n", "            ", "empty_result", ":", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "=", "{", "}", "\n", "return", "empty_result", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.MultiheadAttention._set_input_buffer": [[449, 455], ["multihead_attention.MultiheadAttention.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_incremental_state"], ["", "", "def", "_set_input_buffer", "(", "\n", "self", ",", "\n", "incremental_state", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ",", "\n", "buffer", ":", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", ",", "\n", ")", ":", "\n", "        ", "return", "self", ".", "set_incremental_state", "(", "incremental_state", ",", "\"attn_state\"", ",", "buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.MultiheadAttention.apply_sparse_mask": [[456, 458], ["None"], "methods", ["None"], ["", "def", "apply_sparse_mask", "(", "self", ",", "attn_weights", ",", "tgt_len", ":", "int", ",", "src_len", ":", "int", ",", "bsz", ":", "int", ")", ":", "\n", "        ", "return", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.MultiheadAttention.upgrade_state_dict_named": [[459, 489], ["state_dict.keys", "items_to_add.items", "k.endswith", "int", "keys_to_remove.append", "state_dict.keys", "int", "keys_to_remove.append"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "prefix", "=", "name", "+", "\".\"", "if", "name", "!=", "\"\"", "else", "\"\"", "\n", "items_to_add", "=", "{", "}", "\n", "keys_to_remove", "=", "[", "]", "\n", "for", "k", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "if", "k", ".", "endswith", "(", "prefix", "+", "\"in_proj_weight\"", ")", ":", "\n", "# in_proj_weight used to be q + k + v with same dimensions", "\n", "                ", "dim", "=", "int", "(", "state_dict", "[", "k", "]", ".", "shape", "[", "0", "]", "/", "3", ")", "\n", "items_to_add", "[", "prefix", "+", "\"q_proj.weight\"", "]", "=", "state_dict", "[", "k", "]", "[", ":", "dim", "]", "\n", "items_to_add", "[", "prefix", "+", "\"k_proj.weight\"", "]", "=", "state_dict", "[", "k", "]", "[", "dim", ":", "2", "*", "dim", "]", "\n", "items_to_add", "[", "prefix", "+", "\"v_proj.weight\"", "]", "=", "state_dict", "[", "k", "]", "[", "2", "*", "dim", ":", "]", "\n", "\n", "keys_to_remove", ".", "append", "(", "k", ")", "\n", "\n", "k_bias", "=", "prefix", "+", "\"in_proj_bias\"", "\n", "if", "k_bias", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "dim", "=", "int", "(", "state_dict", "[", "k", "]", ".", "shape", "[", "0", "]", "/", "3", ")", "\n", "items_to_add", "[", "prefix", "+", "\"q_proj.bias\"", "]", "=", "state_dict", "[", "k_bias", "]", "[", ":", "dim", "]", "\n", "items_to_add", "[", "prefix", "+", "\"k_proj.bias\"", "]", "=", "state_dict", "[", "k_bias", "]", "[", "\n", "dim", ":", "2", "*", "dim", "\n", "]", "\n", "items_to_add", "[", "prefix", "+", "\"v_proj.bias\"", "]", "=", "state_dict", "[", "k_bias", "]", "[", "2", "*", "dim", ":", "]", "\n", "\n", "keys_to_remove", ".", "append", "(", "prefix", "+", "\"in_proj_bias\"", ")", "\n", "\n", "", "", "", "for", "k", "in", "keys_to_remove", ":", "\n", "            ", "del", "state_dict", "[", "k", "]", "\n", "\n", "", "for", "key", ",", "value", "in", "items_to_add", ".", "items", "(", ")", ":", "\n", "            ", "state_dict", "[", "key", "]", "=", "value", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.fp32_group_norm.Fp32GroupNorm.__init__": [[14, 16], ["torch.GroupNorm.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.fp32_group_norm.Fp32GroupNorm.forward": [[17, 26], ["torch.group_norm", "torch.group_norm", "torch.group_norm.type_as", "input.float", "fp32_group_norm.Fp32GroupNorm.weight.float", "fp32_group_norm.Fp32GroupNorm.bias.float"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "output", "=", "F", ".", "group_norm", "(", "\n", "input", ".", "float", "(", ")", ",", "\n", "self", ".", "num_groups", ",", "\n", "self", ".", "weight", ".", "float", "(", ")", "if", "self", ".", "weight", "is", "not", "None", "else", "None", ",", "\n", "self", ".", "bias", ".", "float", "(", ")", "if", "self", ".", "bias", "is", "not", "None", "else", "None", ",", "\n", "self", ".", "eps", ",", "\n", ")", "\n", "return", "output", ".", "type_as", "(", "input", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.DynamicCRF.__init__": [[42, 51], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding"], ["def", "__init__", "(", "self", ",", "num_embedding", ",", "low_rank", "=", "32", ",", "beam_size", "=", "64", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "E1", "=", "nn", ".", "Embedding", "(", "num_embedding", ",", "low_rank", ")", "\n", "self", ".", "E2", "=", "nn", ".", "Embedding", "(", "num_embedding", ",", "low_rank", ")", "\n", "\n", "self", ".", "vocb", "=", "num_embedding", "\n", "self", ".", "rank", "=", "low_rank", "\n", "self", ".", "beam", "=", "beam_size", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.DynamicCRF.extra_repr": [[52, 55], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "\"vocab_size={}, low_rank={}, beam_size={}\"", ".", "format", "(", "\n", "self", ".", "vocb", ",", "self", ".", "rank", ",", "self", ".", "beam", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.DynamicCRF.forward": [[57, 74], ["dynamic_crf_layer.DynamicCRF._compute_score", "dynamic_crf_layer.DynamicCRF._compute_normalizer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.DynamicCRF._compute_score", "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.DynamicCRF._compute_normalizer"], ["", "def", "forward", "(", "self", ",", "emissions", ",", "targets", ",", "masks", ",", "beam", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Compute the conditional log-likelihood of a sequence of target tokens given emission scores\n\n        Args:\n            emissions (`~torch.Tensor`): Emission score are usually the unnormalized decoder output\n                ``(batch_size, seq_len, vocab_size)``. We assume batch-first\n            targets (`~torch.LongTensor`): Sequence of target token indices\n                ``(batch_size, seq_len)\n            masks (`~torch.ByteTensor`): Mask tensor with the same size as targets\n\n        Returns:\n            `~torch.Tensor`: approximated log-likelihood\n        \"\"\"", "\n", "numerator", "=", "self", ".", "_compute_score", "(", "emissions", ",", "targets", ",", "masks", ")", "\n", "denominator", "=", "self", ".", "_compute_normalizer", "(", "emissions", ",", "targets", ",", "masks", ",", "beam", ")", "\n", "return", "numerator", "-", "denominator", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.DynamicCRF.forward_decoder": [[75, 88], ["dynamic_crf_layer.DynamicCRF._viterbi_decode"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.DynamicCRF._viterbi_decode"], ["", "def", "forward_decoder", "(", "self", ",", "emissions", ",", "masks", "=", "None", ",", "beam", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Find the most likely output sequence using Viterbi algorithm.\n\n        Args:\n            emissions (`~torch.Tensor`): Emission score are usually the unnormalized decoder output\n                ``(batch_size, seq_len, vocab_size)``. We assume batch-first\n            masks (`~torch.ByteTensor`): Mask tensor with the same size as targets\n\n        Returns:\n            `~torch.LongTensor`: decoded sequence from the CRF model\n        \"\"\"", "\n", "return", "self", ".", "_viterbi_decode", "(", "emissions", ",", "masks", ",", "beam", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.DynamicCRF._compute_score": [[89, 100], ["targets.size", "scores.sum", "emissions.gather", "masks.type_as", "dynamic_crf_layer.DynamicCRF.E1", "dynamic_crf_layer.DynamicCRF.E2"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "_compute_score", "(", "self", ",", "emissions", ",", "targets", ",", "masks", "=", "None", ")", ":", "\n", "        ", "batch_size", ",", "seq_len", "=", "targets", ".", "size", "(", ")", "\n", "emission_scores", "=", "emissions", ".", "gather", "(", "2", ",", "targets", "[", ":", ",", ":", ",", "None", "]", ")", "[", ":", ",", ":", ",", "0", "]", "# B x T", "\n", "transition_scores", "=", "(", "self", ".", "E1", "(", "targets", "[", ":", ",", ":", "-", "1", "]", ")", "*", "self", ".", "E2", "(", "targets", "[", ":", ",", "1", ":", "]", ")", ")", ".", "sum", "(", "2", ")", "\n", "\n", "scores", "=", "emission_scores", "\n", "scores", "[", ":", ",", "1", ":", "]", "+=", "transition_scores", "\n", "\n", "if", "masks", "is", "not", "None", ":", "\n", "            ", "scores", "=", "scores", "*", "masks", ".", "type_as", "(", "scores", ")", "\n", "", "return", "scores", ".", "sum", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.DynamicCRF._compute_normalizer": [[101, 134], ["dynamic_crf_layer.DynamicCRF.E1", "dynamic_crf_layer.DynamicCRF.E2", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "beam_transition_matrix.view.view.view", "range", "dynamic_crf_layer.logsumexp", "emissions.size", "emissions.scatter", "emissions.gather", "emissions.topk", "dynamic_crf_layer.DynamicCRF.view", "dynamic_crf_layer.DynamicCRF.view().transpose", "numpy.float", "emissions.scatter.topk", "dynamic_crf_layer.logsumexp", "torch.where", "torch.where", "torch.where", "torch.where", "dynamic_crf_layer.DynamicCRF.view"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp"], ["", "def", "_compute_normalizer", "(", "self", ",", "emissions", ",", "targets", "=", "None", ",", "masks", "=", "None", ",", "beam", "=", "None", ")", ":", "\n", "# HACK: we include \"target\" which is a hueristic for training", "\n", "# HACK: we use a beam of tokens to approximate the normalizing factor (which is bad?)", "\n", "\n", "        ", "beam", "=", "beam", "if", "beam", "is", "not", "None", "else", "self", ".", "beam", "\n", "batch_size", ",", "seq_len", "=", "emissions", ".", "size", "(", ")", "[", ":", "2", "]", "\n", "if", "targets", "is", "not", "None", ":", "\n", "            ", "_emissions", "=", "emissions", ".", "scatter", "(", "2", ",", "targets", "[", ":", ",", ":", ",", "None", "]", ",", "np", ".", "float", "(", "\"inf\"", ")", ")", "\n", "beam_targets", "=", "_emissions", ".", "topk", "(", "beam", ",", "2", ")", "[", "1", "]", "\n", "beam_emission_scores", "=", "emissions", ".", "gather", "(", "2", ",", "beam_targets", ")", "\n", "", "else", ":", "\n", "            ", "beam_emission_scores", ",", "beam_targets", "=", "emissions", ".", "topk", "(", "beam", ",", "2", ")", "\n", "", "beam_transition_score1", "=", "self", ".", "E1", "(", "beam_targets", "[", ":", ",", ":", "-", "1", "]", ")", "# B x (T-1) x K x D", "\n", "beam_transition_score2", "=", "self", ".", "E2", "(", "beam_targets", "[", ":", ",", "1", ":", "]", ")", "# B x (T-1) x K x D", "\n", "beam_transition_matrix", "=", "torch", ".", "bmm", "(", "\n", "beam_transition_score1", ".", "view", "(", "-", "1", ",", "beam", ",", "self", ".", "rank", ")", ",", "\n", "beam_transition_score2", ".", "view", "(", "-", "1", ",", "beam", ",", "self", ".", "rank", ")", ".", "transpose", "(", "1", ",", "2", ")", ",", "\n", ")", "\n", "beam_transition_matrix", "=", "beam_transition_matrix", ".", "view", "(", "batch_size", ",", "-", "1", ",", "beam", ",", "beam", ")", "\n", "\n", "# compute the normalizer in the log-space", "\n", "score", "=", "beam_emission_scores", "[", ":", ",", "0", "]", "# B x K", "\n", "for", "i", "in", "range", "(", "1", ",", "seq_len", ")", ":", "\n", "            ", "next_score", "=", "score", "[", ":", ",", ":", ",", "None", "]", "+", "beam_transition_matrix", "[", ":", ",", "i", "-", "1", "]", "\n", "next_score", "=", "logsumexp", "(", "next_score", ",", "dim", "=", "1", ")", "+", "beam_emission_scores", "[", ":", ",", "i", "]", "\n", "\n", "if", "masks", "is", "not", "None", ":", "\n", "                ", "score", "=", "torch", ".", "where", "(", "masks", "[", ":", ",", "i", ":", "i", "+", "1", "]", ",", "next_score", ",", "score", ")", "\n", "", "else", ":", "\n", "                ", "score", "=", "next_score", "\n", "\n", "# Sum (log-sum-exp) over all possible tags", "\n", "", "", "return", "logsumexp", "(", "score", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.DynamicCRF._viterbi_decode": [[135, 190], ["emissions.topk", "dynamic_crf_layer.DynamicCRF.E1", "dynamic_crf_layer.DynamicCRF.E2", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "beam_transition_matrix.view.view.view", "torch.arange().expand().contiguous", "torch.arange().expand().contiguous", "torch.arange().expand().contiguous", "torch.arange().expand().contiguous", "range", "torch.where.max", "torch.where.max", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "zip", "torch.cat.reverse", "torch.cat.reverse", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.reverse", "torch.cat.reverse", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "emissions.size", "dynamic_crf_layer.DynamicCRF.view", "dynamic_crf_layer.DynamicCRF.view().transpose", "traj_scores.append", "_score.max", "traj_tokens.append", "reversed", "reversed", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "beam_targets.gather", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "idx.gather", "scs.gather", "dynamic_crf_layer.DynamicCRF.view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.where.size", "torch.where.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "_viterbi_decode", "(", "self", ",", "emissions", ",", "masks", "=", "None", ",", "beam", "=", "None", ")", ":", "\n", "# HACK: we use a beam of tokens to approximate the normalizing factor (which is bad?)", "\n", "\n", "        ", "beam", "=", "beam", "if", "beam", "is", "not", "None", "else", "self", ".", "beam", "\n", "batch_size", ",", "seq_len", "=", "emissions", ".", "size", "(", ")", "[", ":", "2", "]", "\n", "beam_emission_scores", ",", "beam_targets", "=", "emissions", ".", "topk", "(", "beam", ",", "2", ")", "\n", "beam_transition_score1", "=", "self", ".", "E1", "(", "beam_targets", "[", ":", ",", ":", "-", "1", "]", ")", "# B x (T-1) x K x D", "\n", "beam_transition_score2", "=", "self", ".", "E2", "(", "beam_targets", "[", ":", ",", "1", ":", "]", ")", "# B x (T-1) x K x D", "\n", "beam_transition_matrix", "=", "torch", ".", "bmm", "(", "\n", "beam_transition_score1", ".", "view", "(", "-", "1", ",", "beam", ",", "self", ".", "rank", ")", ",", "\n", "beam_transition_score2", ".", "view", "(", "-", "1", ",", "beam", ",", "self", ".", "rank", ")", ".", "transpose", "(", "1", ",", "2", ")", ",", "\n", ")", "\n", "beam_transition_matrix", "=", "beam_transition_matrix", ".", "view", "(", "batch_size", ",", "-", "1", ",", "beam", ",", "beam", ")", "\n", "\n", "traj_tokens", ",", "traj_scores", "=", "[", "]", ",", "[", "]", "\n", "finalized_tokens", ",", "finalized_scores", "=", "[", "]", ",", "[", "]", "\n", "\n", "# compute the normalizer in the log-space", "\n", "score", "=", "beam_emission_scores", "[", ":", ",", "0", "]", "# B x K", "\n", "dummy", "=", "(", "\n", "torch", ".", "arange", "(", "beam", ",", "device", "=", "score", ".", "device", ")", ".", "expand", "(", "*", "score", ".", "size", "(", ")", ")", ".", "contiguous", "(", ")", "\n", ")", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "seq_len", ")", ":", "\n", "            ", "traj_scores", ".", "append", "(", "score", ")", "\n", "_score", "=", "score", "[", ":", ",", ":", ",", "None", "]", "+", "beam_transition_matrix", "[", ":", ",", "i", "-", "1", "]", "\n", "_score", ",", "_index", "=", "_score", ".", "max", "(", "dim", "=", "1", ")", "\n", "_score", "=", "_score", "+", "beam_emission_scores", "[", ":", ",", "i", "]", "\n", "\n", "if", "masks", "is", "not", "None", ":", "\n", "                ", "score", "=", "torch", ".", "where", "(", "masks", "[", ":", ",", "i", ":", "i", "+", "1", "]", ",", "_score", ",", "score", ")", "\n", "index", "=", "torch", ".", "where", "(", "masks", "[", ":", ",", "i", ":", "i", "+", "1", "]", ",", "_index", ",", "dummy", ")", "\n", "", "else", ":", "\n", "                ", "score", ",", "index", "=", "_score", ",", "_index", "\n", "", "traj_tokens", ".", "append", "(", "index", ")", "\n", "\n", "# now running the back-tracing and find the best", "\n", "", "best_score", ",", "best_index", "=", "score", ".", "max", "(", "dim", "=", "1", ")", "\n", "finalized_tokens", ".", "append", "(", "best_index", "[", ":", ",", "None", "]", ")", "\n", "finalized_scores", ".", "append", "(", "best_score", "[", ":", ",", "None", "]", ")", "\n", "\n", "for", "idx", ",", "scs", "in", "zip", "(", "reversed", "(", "traj_tokens", ")", ",", "reversed", "(", "traj_scores", ")", ")", ":", "\n", "            ", "previous_index", "=", "finalized_tokens", "[", "-", "1", "]", "\n", "finalized_tokens", ".", "append", "(", "idx", ".", "gather", "(", "1", ",", "previous_index", ")", ")", "\n", "finalized_scores", ".", "append", "(", "scs", ".", "gather", "(", "1", ",", "previous_index", ")", ")", "\n", "\n", "", "finalized_tokens", ".", "reverse", "(", ")", "\n", "finalized_tokens", "=", "torch", ".", "cat", "(", "finalized_tokens", ",", "1", ")", "\n", "finalized_tokens", "=", "beam_targets", ".", "gather", "(", "2", ",", "finalized_tokens", "[", ":", ",", ":", ",", "None", "]", ")", "[", ":", ",", ":", ",", "0", "]", "\n", "\n", "finalized_scores", ".", "reverse", "(", ")", "\n", "finalized_scores", "=", "torch", ".", "cat", "(", "finalized_scores", ",", "1", ")", "\n", "finalized_scores", "[", ":", ",", "1", ":", "]", "=", "finalized_scores", "[", ":", ",", "1", ":", "]", "-", "finalized_scores", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "return", "finalized_scores", ",", "finalized_tokens", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp": [[24, 26], ["torch.logsumexp().type_as", "torch.logsumexp().type_as", "torch.logsumexp", "torch.logsumexp", "x.float"], "function", ["home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp"], ["def", "logsumexp", "(", "x", ",", "dim", "=", "1", ")", ":", "\n", "    ", "return", "torch", ".", "logsumexp", "(", "x", ".", "float", "(", ")", ",", "dim", "=", "dim", ")", ".", "type_as", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.checkpoint_activations.CheckpointFunction.forward": [[133, 159], ["torch.is_grad_enabled", "fairseq.utils.get_rng_state", "checkpoint_activations.split_non_tensors", "ctx.save_for_backward", "isinstance", "torch.utils.checkpoint.check_backward_validity", "torch.no_grad", "checkpoint_activations.unpack_kwargs", "run_function", "checkpoint_activations.split_non_tensors"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_rng_state", "home.repos.pwc.inspect_result.reneeye_const.modules.checkpoint_activations.split_non_tensors", "home.repos.pwc.inspect_result.reneeye_const.modules.checkpoint_activations.unpack_kwargs", "home.repos.pwc.inspect_result.reneeye_const.modules.checkpoint_activations.split_non_tensors"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "run_function", ",", "parent_ctx_dict", ",", "kwarg_keys", ",", "*", "args", ")", ":", "\n", "        ", "if", "torch", ".", "is_grad_enabled", "(", ")", ":", "# grad may be disabled, e.g., during validation", "\n", "            ", "torch", ".", "utils", ".", "checkpoint", ".", "check_backward_validity", "(", "args", ")", "\n", "\n", "", "ctx", ".", "run_function", "=", "run_function", "\n", "ctx", ".", "kwarg_keys", "=", "kwarg_keys", "\n", "ctx", ".", "fwd_rng_state", "=", "utils", ".", "get_rng_state", "(", ")", "\n", "\n", "tensor_inputs", ",", "packed_non_tensor_inputs", "=", "split_non_tensors", "(", "args", ")", "\n", "ctx", ".", "save_for_backward", "(", "*", "tensor_inputs", ")", "\n", "ctx", ".", "packed_non_tensor_inputs", "=", "packed_non_tensor_inputs", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "unpacked_args", ",", "unpacked_kwargs", "=", "unpack_kwargs", "(", "kwarg_keys", ",", "args", ")", "\n", "outputs", "=", "run_function", "(", "*", "unpacked_args", ",", "**", "unpacked_kwargs", ")", "\n", "\n", "", "if", "isinstance", "(", "outputs", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "outputs", "\n", "", "else", ":", "\n", "# Autograd Functions don't like non-Tensor outputs. We can split the", "\n", "# non-Tensor and Tensor outputs, returning the former by reference", "\n", "# through *parent_ctx_dict* and returning the latter directly.", "\n", "            ", "outputs", ",", "packed_non_tensor_outputs", "=", "split_non_tensors", "(", "outputs", ")", "\n", "parent_ctx_dict", "[", "\"packed_non_tensor_outputs\"", "]", "=", "packed_non_tensor_outputs", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.checkpoint_activations.CheckpointFunction.backward": [[160, 204], ["torch.utils.checkpoint.detach_variable", "checkpoint_activations.unpack_non_tensors", "fairseq.utils.get_rng_state", "fairseq.utils.set_rng_state", "fairseq.utils.set_rng_state", "range", "torch.autograd.backward", "tuple", "torch.autograd._is_checkpoint_valid", "RuntimeError", "torch.enable_grad", "checkpoint_activations.unpack_kwargs", "ctx.run_function", "checkpoint_activations.split_non_tensors", "len", "len", "RuntimeError", "outputs_with_grad.append", "args_with_grad.append", "isinstance"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.checkpoint_activations.unpack_non_tensors", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_rng_state", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_rng_state", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_rng_state", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward", "home.repos.pwc.inspect_result.reneeye_const.modules.checkpoint_activations.unpack_kwargs", "home.repos.pwc.inspect_result.reneeye_const.modules.checkpoint_activations.split_non_tensors"], ["", "", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "*", "args", ")", ":", "\n", "        ", "if", "not", "torch", ".", "autograd", ".", "_is_checkpoint_valid", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"Checkpointing is not compatible with .grad(), please use .backward() if possible\"", "\n", ")", "\n", "\n", "", "tensor_inputs", "=", "ctx", ".", "saved_tensors", "\n", "tensor_inputs", "=", "torch", ".", "utils", ".", "checkpoint", ".", "detach_variable", "(", "tensor_inputs", ")", "\n", "inputs", "=", "unpack_non_tensors", "(", "tensor_inputs", ",", "ctx", ".", "packed_non_tensor_inputs", ")", "\n", "\n", "# Store the current states.", "\n", "bwd_rng_state", "=", "utils", ".", "get_rng_state", "(", ")", "\n", "\n", "# Set the states to what it used to be before the forward pass.", "\n", "utils", ".", "set_rng_state", "(", "ctx", ".", "fwd_rng_state", ")", "\n", "\n", "with", "torch", ".", "enable_grad", "(", ")", ":", "\n", "            ", "unpacked_args", ",", "unpacked_kwargs", "=", "unpack_kwargs", "(", "ctx", ".", "kwarg_keys", ",", "inputs", ")", "\n", "outputs", "=", "ctx", ".", "run_function", "(", "*", "unpacked_args", ",", "**", "unpacked_kwargs", ")", "\n", "tensor_outputs", ",", "_", "=", "split_non_tensors", "(", "outputs", ")", "\n", "\n", "# Set the states back to what it was at the start of this function.", "\n", "", "utils", ".", "set_rng_state", "(", "bwd_rng_state", ")", "\n", "\n", "# Run backward() with only Tensors that require grad", "\n", "outputs_with_grad", "=", "[", "]", "\n", "args_with_grad", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "tensor_outputs", ")", ")", ":", "\n", "            ", "if", "tensor_outputs", "[", "i", "]", ".", "requires_grad", ":", "\n", "                ", "outputs_with_grad", ".", "append", "(", "tensor_outputs", "[", "i", "]", ")", "\n", "args_with_grad", ".", "append", "(", "args", "[", "i", "]", ")", "\n", "", "", "if", "len", "(", "outputs_with_grad", ")", "==", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"None of the outputs have requires_grad=True, \"", "\n", "\"this checkpoint() is not necessary\"", "\n", ")", "\n", "\n", "", "torch", ".", "autograd", ".", "backward", "(", "outputs_with_grad", ",", "args_with_grad", ")", "\n", "\n", "grads", "=", "tuple", "(", "\n", "inp", ".", "grad", "if", "isinstance", "(", "inp", ",", "torch", ".", "Tensor", ")", "else", "None", "for", "inp", "in", "inputs", "\n", ")", "\n", "return", "(", "None", ",", "None", ",", "None", ")", "+", "grads", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.checkpoint_activations.checkpoint_wrapper": [[13, 48], ["checkpoint_activations.pack_kwargs", "CheckpointFunction.apply", "isinstance", "checkpoint_activations.unpack_non_tensors"], "function", ["home.repos.pwc.inspect_result.reneeye_const.modules.checkpoint_activations.pack_kwargs", "home.repos.pwc.inspect_result.reneeye_const.modules.checkpoint_activations.unpack_non_tensors"], ["def", "checkpoint_wrapper", "(", "m", ")", ":", "\n", "    ", "\"\"\"\n    A friendlier wrapper for performing activation checkpointing.\n\n    Compared to the PyTorch version, this version:\n    - wraps an nn.Module, so that all subsequent calls will use checkpointing\n    - handles keyword arguments in the forward\n    - handles non-Tensor outputs from the forward\n\n    Usage::\n\n        checkpointed_module = checkpoint_wrapper(my_module)\n        a, b = checkpointed_module(x, y=3, z=torch.Tensor([1]))\n    \"\"\"", "\n", "original_forward", "=", "m", ".", "forward", "\n", "\n", "def", "_checkpointed_forward", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# Autograd Functions in PyTorch work best with positional args, since", "\n", "# the backward must return gradients (or None) for every input argument.", "\n", "# We can flatten keyword arguments to make this easier.", "\n", "        ", "kwarg_keys", ",", "flat_args", "=", "pack_kwargs", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "parent_ctx_dict", "=", "{", "}", "\n", "output", "=", "CheckpointFunction", ".", "apply", "(", "\n", "original_forward", ",", "parent_ctx_dict", ",", "kwarg_keys", ",", "*", "flat_args", "\n", ")", "\n", "if", "isinstance", "(", "output", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "output", "\n", "", "else", ":", "\n", "            ", "packed_non_tensor_outputs", "=", "parent_ctx_dict", "[", "\"packed_non_tensor_outputs\"", "]", "\n", "if", "packed_non_tensor_outputs", ":", "\n", "                ", "output", "=", "unpack_non_tensors", "(", "output", ",", "packed_non_tensor_outputs", ")", "\n", "", "return", "output", "\n", "\n", "", "", "m", ".", "forward", "=", "_checkpointed_forward", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.checkpoint_activations.pack_kwargs": [[50, 65], ["list", "kwargs.items", "kwarg_keys.append", "list.append"], "function", ["None"], ["", "def", "pack_kwargs", "(", "*", "args", ",", "**", "kwargs", ")", "->", "Tuple", "[", "List", "[", "str", "]", ",", "List", "[", "Any", "]", "]", ":", "\n", "    ", "\"\"\"\n    Usage::\n\n        kwarg_keys, flat_args = pack_kwargs(1, 2, a=3, b=4)\n        args, kwargs = unpack_kwargs(kwarg_keys, flat_args)\n        assert args == [1, 2]\n        assert kwargs == {\"a\": 3, \"b\": 4}\n    \"\"\"", "\n", "kwarg_keys", "=", "[", "]", "\n", "flat_args", "=", "list", "(", "args", ")", "\n", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "        ", "kwarg_keys", ".", "append", "(", "k", ")", "\n", "flat_args", ".", "append", "(", "v", ")", "\n", "", "return", "kwarg_keys", ",", "flat_args", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.checkpoint_activations.unpack_kwargs": [[67, 75], ["len", "zip", "len", "len"], "function", ["None"], ["", "def", "unpack_kwargs", "(", "\n", "kwarg_keys", ":", "List", "[", "str", "]", ",", "flat_args", ":", "List", "[", "Any", "]", "\n", ")", "->", "Tuple", "[", "List", "[", "Any", "]", ",", "Dict", "[", "str", ",", "Any", "]", "]", ":", "\n", "    ", "if", "len", "(", "kwarg_keys", ")", "==", "0", ":", "\n", "        ", "return", "flat_args", ",", "{", "}", "\n", "", "args", "=", "flat_args", "[", ":", "-", "len", "(", "kwarg_keys", ")", "]", "\n", "kwargs", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "kwarg_keys", ",", "flat_args", "[", "-", "len", "(", "kwarg_keys", ")", ":", "]", ")", "}", "\n", "return", "args", ",", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.checkpoint_activations.split_non_tensors": [[77, 101], ["isinstance", "isinstance", "tuple", "packed_non_tensors[].append", "tensors.append", "packed_non_tensors[].append", "packed_non_tensors[].append"], "function", ["None"], ["", "def", "split_non_tensors", "(", "\n", "mixed", ":", "Union", "[", "torch", ".", "Tensor", ",", "Tuple", "[", "Any", "]", "]", "\n", ")", "->", "Tuple", "[", "Tuple", "[", "torch", ".", "Tensor", "]", ",", "Dict", "[", "str", ",", "List", "[", "Any", "]", "]", "]", ":", "\n", "    ", "\"\"\"\n    Usage::\n\n        x = torch.Tensor([1])\n        y = torch.Tensor([2])\n        tensors, packed_non_tensors = split_non_tensors((x, y, None, 3))\n        recon = unpack_non_tensors(tensors, packed_non_tensors)\n        assert recon == (x, y, None, 3)\n    \"\"\"", "\n", "if", "isinstance", "(", "mixed", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "(", "mixed", ",", ")", ",", "None", "\n", "", "tensors", "=", "[", "]", "\n", "packed_non_tensors", "=", "{", "\"is_tensor\"", ":", "[", "]", ",", "\"objects\"", ":", "[", "]", "}", "\n", "for", "o", "in", "mixed", ":", "\n", "        ", "if", "isinstance", "(", "o", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "packed_non_tensors", "[", "\"is_tensor\"", "]", ".", "append", "(", "True", ")", "\n", "tensors", ".", "append", "(", "o", ")", "\n", "", "else", ":", "\n", "            ", "packed_non_tensors", "[", "\"is_tensor\"", "]", ".", "append", "(", "False", ")", "\n", "packed_non_tensors", "[", "\"objects\"", "]", ".", "append", "(", "o", ")", "\n", "", "", "return", "tuple", "(", "tensors", ")", ",", "packed_non_tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.checkpoint_activations.unpack_non_tensors": [[103, 123], ["isinstance", "tuple", "len", "len", "len", "mixed.append", "mixed.append"], "function", ["None"], ["", "def", "unpack_non_tensors", "(", "\n", "tensors", ":", "Tuple", "[", "torch", ".", "Tensor", "]", ",", "\n", "packed_non_tensors", ":", "Dict", "[", "str", ",", "List", "[", "Any", "]", "]", ",", "\n", ")", "->", "Tuple", "[", "Any", "]", ":", "\n", "    ", "if", "packed_non_tensors", "is", "None", ":", "\n", "        ", "return", "tensors", "\n", "", "assert", "isinstance", "(", "packed_non_tensors", ",", "dict", ")", "\n", "mixed", "=", "[", "]", "\n", "is_tensor_list", "=", "packed_non_tensors", "[", "\"is_tensor\"", "]", "\n", "objects", "=", "packed_non_tensors", "[", "\"objects\"", "]", "\n", "assert", "len", "(", "tensors", ")", "+", "len", "(", "objects", ")", "==", "len", "(", "is_tensor_list", ")", "\n", "obj_i", "=", "tnsr_i", "=", "0", "\n", "for", "is_tensor", "in", "is_tensor_list", ":", "\n", "        ", "if", "is_tensor", ":", "\n", "            ", "mixed", ".", "append", "(", "tensors", "[", "tnsr_i", "]", ")", "\n", "tnsr_i", "+=", "1", "\n", "", "else", ":", "\n", "            ", "mixed", ".", "append", "(", "objects", "[", "obj_i", "]", ")", "\n", "obj_i", "+=", "1", "\n", "", "", "return", "tuple", "(", "mixed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_convolution.DynamicConv1dTBC.__init__": [[89, 128], ["torch.Module.__init__", "fairseq.modules.fairseq_dropout.FairseqDropout", "dynamic_convolution.DynamicConv1dTBC.reset_parameters", "dynamic_convolution.Linear", "dynamic_convolution.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["def", "__init__", "(", "\n", "self", ",", "\n", "input_size", ",", "\n", "kernel_size", "=", "1", ",", "\n", "padding_l", "=", "None", ",", "\n", "num_heads", "=", "1", ",", "\n", "weight_dropout", "=", "0.0", ",", "\n", "weight_softmax", "=", "False", ",", "\n", "renorm_padding", "=", "False", ",", "\n", "bias", "=", "False", ",", "\n", "conv_bias", "=", "False", ",", "\n", "query_size", "=", "None", ",", "\n", "in_proj", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "query_size", "=", "input_size", "if", "query_size", "is", "None", "else", "query_size", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "padding_l", "=", "padding_l", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "weight_dropout_module", "=", "FairseqDropout", "(", "\n", "weight_dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "weight_softmax", "=", "weight_softmax", "\n", "self", ".", "renorm_padding", "=", "renorm_padding", "\n", "\n", "if", "in_proj", ":", "\n", "            ", "self", ".", "weight_linear", "=", "Linear", "(", "\n", "self", ".", "input_size", ",", "self", ".", "input_size", "+", "num_heads", "*", "kernel_size", "*", "1", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "weight_linear", "=", "Linear", "(", "\n", "self", ".", "query_size", ",", "num_heads", "*", "kernel_size", "*", "1", ",", "bias", "=", "bias", "\n", ")", "\n", "", "if", "conv_bias", ":", "\n", "            ", "self", ".", "conv_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "input_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv_bias", "=", "None", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_convolution.DynamicConv1dTBC.in_proj": [[129, 134], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "in_proj", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "weight_linear", ".", "out_features", "\n", "==", "self", ".", "input_size", "+", "self", ".", "num_heads", "*", "self", ".", "kernel_size", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_convolution.DynamicConv1dTBC.reset_parameters": [[136, 140], ["dynamic_convolution.DynamicConv1dTBC.weight_linear.reset_parameters", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "weight_linear", ".", "reset_parameters", "(", ")", "\n", "if", "self", ".", "conv_bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "conv_bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_convolution.DynamicConv1dTBC.forward": [[141, 165], ["dynamic_convolution.DynamicConv1dTBC._forward_unfolded", "dynamic_convolution.DynamicConv1dTBC._forward_expanded", "x.size", "dynamic_convolution.DynamicConv1dTBC.conv_bias.view"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._forward_unfolded", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._forward_expanded", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "incremental_state", "=", "None", ",", "query", "=", "None", ",", "unfold", "=", "None", ")", ":", "\n", "        ", "\"\"\"Assuming the input, x, of the shape T x B x C and producing an output in the shape T x B x C\n        args:\n            x: Input of shape T x B x C, i.e. (timesteps, batch_size, input_size)\n            incremental_state: A dict to keep the state\n            unfold: unfold the input or not. If not, we use the matrix trick instead\n            query: use the specified query to predict the conv filters\n        \"\"\"", "\n", "unfold", "=", "(", "\n", "x", ".", "size", "(", "0", ")", ">", "512", "if", "unfold", "is", "None", "else", "unfold", "\n", ")", "# use unfold mode as default for long sequence to save memory", "\n", "unfold", "=", "unfold", "or", "(", "incremental_state", "is", "not", "None", ")", "\n", "assert", "query", "is", "None", "or", "not", "self", ".", "in_proj", "\n", "\n", "if", "query", "is", "None", ":", "\n", "            ", "query", "=", "x", "\n", "", "if", "unfold", ":", "\n", "            ", "output", "=", "self", ".", "_forward_unfolded", "(", "x", ",", "incremental_state", ",", "query", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "_forward_expanded", "(", "x", ",", "incremental_state", ",", "query", ")", "\n", "\n", "", "if", "self", ".", "conv_bias", "is", "not", "None", ":", "\n", "            ", "output", "=", "output", "+", "self", ".", "conv_bias", ".", "view", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_convolution.DynamicConv1dTBC._forward_unfolded": [[166, 221], ["dynamic_convolution.DynamicConv1dTBC.narrow().contiguous.size", "weight.narrow.narrow.narrow", "dynamic_convolution.DynamicConv1dTBC.weight_dropout_module", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "output.view.view.view", "dynamic_convolution.DynamicConv1dTBC.weight_linear", "dynamic_convolution.DynamicConv1dTBC.narrow().contiguous", "dynamic_convolution.DynamicConv1dTBC.narrow().contiguous().view", "dynamic_convolution.DynamicConv1dTBC.weight_linear().view", "dynamic_convolution.DynamicConv1dTBC._get_input_buffer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_unfold.view.view.view", "unfold.unfold1d", "x_unfold.view.view.view", "torch.softmax", "torch.softmax", "torch.softmax", "weight.narrow.narrow.size", "torch.softmax", "torch.softmax", "torch.softmax", "weight.narrow.narrow.unsqueeze", "dynamic_convolution.DynamicConv1dTBC.narrow().contiguous.new", "dynamic_convolution.DynamicConv1dTBC._set_input_buffer", "weight.narrow.narrow.narrow", "dynamic_convolution.DynamicConv1dTBC.narrow", "dynamic_convolution.DynamicConv1dTBC.narrow().contiguous", "dynamic_convolution.DynamicConv1dTBC.weight_linear", "dynamic_convolution.DynamicConv1dTBC.narrow().contiguous.unsqueeze", "dynamic_convolution.DynamicConv1dTBC.narrow", "x_unfold.view.view.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.modules.unfold.unfold1d", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "_forward_unfolded", "(", "self", ",", "x", ",", "incremental_state", ",", "query", ")", ":", "\n", "        ", "\"\"\"The conventional implementation of convolutions.\n        Unfolding the input by having a window shifting to the right.\"\"\"", "\n", "T", ",", "B", ",", "C", "=", "x", ".", "size", "(", ")", "\n", "K", ",", "H", "=", "self", ".", "kernel_size", ",", "self", ".", "num_heads", "\n", "R", "=", "C", "//", "H", "\n", "assert", "R", "*", "H", "==", "C", "==", "self", ".", "input_size", "\n", "\n", "if", "self", ".", "in_proj", ":", "\n", "            ", "proj", "=", "self", ".", "weight_linear", "(", "x", ")", "\n", "x", "=", "proj", ".", "narrow", "(", "2", ",", "0", ",", "self", ".", "input_size", ")", ".", "contiguous", "(", ")", "\n", "weight", "=", "(", "\n", "proj", ".", "narrow", "(", "2", ",", "self", ".", "input_size", ",", "H", "*", "K", ")", ".", "contiguous", "(", ")", ".", "view", "(", "T", "*", "B", "*", "H", ",", "-", "1", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "weight", "=", "self", ".", "weight_linear", "(", "query", ")", ".", "view", "(", "T", "*", "B", "*", "H", ",", "-", "1", ")", "\n", "\n", "# renorm_padding is only implemented in _forward_expanded", "\n", "", "assert", "not", "self", ".", "renorm_padding", "or", "incremental_state", "is", "not", "None", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "None", ":", "\n", "                ", "input_buffer", "=", "x", ".", "new", "(", ")", "\n", "", "x_unfold", "=", "torch", ".", "cat", "(", "[", "input_buffer", ",", "x", ".", "unsqueeze", "(", "3", ")", "]", ",", "dim", "=", "3", ")", "\n", "if", "self", ".", "kernel_size", ">", "1", ":", "\n", "                ", "self", ".", "_set_input_buffer", "(", "\n", "incremental_state", ",", "x_unfold", "[", ":", ",", ":", ",", ":", ",", "-", "self", ".", "kernel_size", "+", "1", ":", "]", "\n", ")", "\n", "", "x_unfold", "=", "x_unfold", ".", "view", "(", "T", "*", "B", "*", "H", ",", "R", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "padding_l", "=", "self", ".", "padding_l", "\n", "if", "K", ">", "T", "and", "padding_l", "==", "K", "-", "1", ":", "\n", "                ", "weight", "=", "weight", ".", "narrow", "(", "1", ",", "K", "-", "T", ",", "T", ")", "\n", "K", ",", "padding_l", "=", "T", ",", "T", "-", "1", "\n", "# unfold the input: T x B x C --> T' x B x C x K", "\n", "", "x_unfold", "=", "unfold1d", "(", "x", ",", "K", ",", "padding_l", ",", "0", ")", "\n", "x_unfold", "=", "x_unfold", ".", "view", "(", "T", "*", "B", "*", "H", ",", "R", ",", "K", ")", "\n", "\n", "", "if", "self", ".", "weight_softmax", "and", "not", "self", ".", "renorm_padding", ":", "\n", "            ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "1", ")", "\n", "", "weight", "=", "weight", ".", "narrow", "(", "1", ",", "0", ",", "K", ")", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "weight", "=", "weight", "[", ":", ",", "-", "x_unfold", ".", "size", "(", "2", ")", ":", "]", "\n", "K", "=", "weight", ".", "size", "(", "1", ")", "\n", "\n", "", "if", "self", ".", "weight_softmax", "and", "self", ".", "renorm_padding", ":", "\n", "            ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "1", ")", "\n", "\n", "", "weight", "=", "self", ".", "weight_dropout_module", "(", "weight", ",", "inplace", "=", "False", ")", "\n", "\n", "output", "=", "torch", ".", "bmm", "(", "x_unfold", ",", "weight", ".", "unsqueeze", "(", "2", ")", ")", "# T*B*H x R x 1", "\n", "output", "=", "output", ".", "view", "(", "T", ",", "B", ",", "C", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_convolution.DynamicConv1dTBC._forward_expanded": [[222, 273], ["dynamic_convolution.DynamicConv1dTBC.narrow().contiguous.size", "weight.narrow.narrow.narrow().contiguous", "weight.narrow.narrow.view().transpose", "dynamic_convolution.DynamicConv1dTBC.narrow().contiguous.view().transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "output.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "dynamic_convolution.DynamicConv1dTBC.weight_linear", "dynamic_convolution.DynamicConv1dTBC.narrow().contiguous", "dynamic_convolution.DynamicConv1dTBC.narrow().contiguous().view", "dynamic_convolution.DynamicConv1dTBC.weight_linear().view", "dynamic_convolution.DynamicConv1dTBC.weight_dropout_module", "weight.narrow.narrow.new().fill_", "weight_expanded.narrow.narrow.as_strided().copy_", "weight_expanded.narrow.narrow.narrow", "torch.softmax", "torch.softmax", "torch.softmax", "dynamic_convolution.DynamicConv1dTBC.weight_dropout_module", "weight.narrow.narrow.new_zeros", "weight_expanded.narrow.narrow.as_strided().copy_", "weight_expanded.narrow.narrow.narrow", "torch.softmax", "torch.softmax", "torch.softmax", "weight.narrow.narrow.narrow", "weight.narrow.narrow.view", "dynamic_convolution.DynamicConv1dTBC.narrow().contiguous.view", "float", "weight.narrow.narrow.narrow", "output.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "dynamic_convolution.DynamicConv1dTBC.narrow", "dynamic_convolution.DynamicConv1dTBC.narrow().contiguous", "dynamic_convolution.DynamicConv1dTBC.weight_linear", "weight.narrow.narrow.new", "weight_expanded.narrow.narrow.as_strided", "weight_expanded.narrow.narrow.as_strided", "output.transpose().contiguous().view.transpose().contiguous().view.transpose", "dynamic_convolution.DynamicConv1dTBC.narrow"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax"], ["", "def", "_forward_expanded", "(", "self", ",", "x", ",", "incremental_stat", ",", "query", ")", ":", "\n", "        ", "\"\"\"Turn the convolution filters into band matrices and do matrix multiplication.\n        This is faster when the sequence is short, but less memory efficient.\n        This is not used in the decoder during inference.\n        \"\"\"", "\n", "T", ",", "B", ",", "C", "=", "x", ".", "size", "(", ")", "\n", "K", ",", "H", "=", "self", ".", "kernel_size", ",", "self", ".", "num_heads", "\n", "R", "=", "C", "//", "H", "\n", "assert", "R", "*", "H", "==", "C", "==", "self", ".", "input_size", "\n", "if", "self", ".", "in_proj", ":", "\n", "            ", "proj", "=", "self", ".", "weight_linear", "(", "x", ")", "\n", "x", "=", "proj", ".", "narrow", "(", "2", ",", "0", ",", "self", ".", "input_size", ")", ".", "contiguous", "(", ")", "\n", "weight", "=", "(", "\n", "proj", ".", "narrow", "(", "2", ",", "self", ".", "input_size", ",", "H", "*", "K", ")", ".", "contiguous", "(", ")", ".", "view", "(", "T", "*", "B", "*", "H", ",", "-", "1", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "weight", "=", "self", ".", "weight_linear", "(", "query", ")", ".", "view", "(", "T", "*", "B", "*", "H", ",", "-", "1", ")", "\n", "\n", "", "if", "not", "self", ".", "renorm_padding", ":", "\n", "            ", "if", "self", ".", "weight_softmax", ":", "\n", "                ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "1", ")", "\n", "", "weight", "=", "self", ".", "weight_dropout_module", "(", "weight", ",", "inplace", "=", "False", ")", "\n", "", "weight", "=", "weight", ".", "narrow", "(", "1", ",", "0", ",", "K", ")", ".", "contiguous", "(", ")", "\n", "weight", "=", "weight", ".", "view", "(", "T", ",", "B", "*", "H", ",", "K", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "x", "=", "x", ".", "view", "(", "T", ",", "B", "*", "H", ",", "R", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "self", ".", "weight_softmax", "and", "self", ".", "renorm_padding", ":", "\n", "# turn the convolution filters into band matrices", "\n", "            ", "weight_expanded", "=", "weight", ".", "new", "(", "B", "*", "H", ",", "T", ",", "T", "+", "K", "-", "1", ")", ".", "fill_", "(", "float", "(", "\"-inf\"", ")", ")", "\n", "weight_expanded", ".", "as_strided", "(", "\n", "(", "B", "*", "H", ",", "T", ",", "K", ")", ",", "(", "T", "*", "(", "T", "+", "K", "-", "1", ")", ",", "T", "+", "K", ",", "1", ")", "\n", ")", ".", "copy_", "(", "weight", ")", "\n", "weight_expanded", "=", "weight_expanded", ".", "narrow", "(", "2", ",", "self", ".", "padding_l", ",", "T", ")", "\n", "# normalize the weight over valid positions like self-attention", "\n", "weight_expanded", "=", "F", ".", "softmax", "(", "weight_expanded", ",", "dim", "=", "2", ")", "\n", "weight_expanded", "=", "self", ".", "weight_dropout_module", "(", "weight_expanded", ",", "inplace", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "P", "=", "self", ".", "padding_l", "\n", "# For efficieny, we cut the kernel size and reduce the padding when the kernel is larger than the length", "\n", "if", "K", ">", "T", "and", "P", "==", "K", "-", "1", ":", "\n", "                ", "weight", "=", "weight", ".", "narrow", "(", "2", ",", "K", "-", "T", ",", "T", ")", "\n", "K", ",", "P", "=", "T", ",", "T", "-", "1", "\n", "# turn the convolution filters into band matrices", "\n", "", "weight_expanded", "=", "weight", ".", "new_zeros", "(", "B", "*", "H", ",", "T", ",", "T", "+", "K", "-", "1", ",", "requires_grad", "=", "False", ")", "\n", "weight_expanded", ".", "as_strided", "(", "\n", "(", "B", "*", "H", ",", "T", ",", "K", ")", ",", "(", "T", "*", "(", "T", "+", "K", "-", "1", ")", ",", "T", "+", "K", ",", "1", ")", "\n", ")", ".", "copy_", "(", "weight", ")", "\n", "weight_expanded", "=", "weight_expanded", ".", "narrow", "(", "2", ",", "P", ",", "T", ")", "# B*H x T x T", "\n", "", "output", "=", "torch", ".", "bmm", "(", "weight_expanded", ",", "x", ")", "\n", "output", "=", "output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "T", ",", "B", ",", "C", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_convolution.DynamicConv1dTBC.reorder_incremental_state": [[274, 279], ["dynamic_convolution.DynamicConv1dTBC._get_input_buffer", "input_buffer.index_select.index_select.index_select", "dynamic_convolution.DynamicConv1dTBC._set_input_buffer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer"], ["", "def", "reorder_incremental_state", "(", "self", ",", "incremental_state", ",", "new_order", ")", ":", "\n", "        ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "not", "None", ":", "\n", "            ", "input_buffer", "=", "input_buffer", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_convolution.DynamicConv1dTBC._get_input_buffer": [[280, 282], ["fairseq.utils.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_incremental_state"], ["", "", "def", "_get_input_buffer", "(", "self", ",", "incremental_state", ")", ":", "\n", "        ", "return", "utils", ".", "get_incremental_state", "(", "self", ",", "incremental_state", ",", "\"input_buffer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_convolution.DynamicConv1dTBC._set_input_buffer": [[283, 286], ["fairseq.utils.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_incremental_state"], ["", "def", "_set_input_buffer", "(", "self", ",", "incremental_state", ",", "new_buffer", ")", ":", "\n", "        ", "return", "utils", ".", "set_incremental_state", "(", "\n", "self", ",", "incremental_state", ",", "\"input_buffer\"", ",", "new_buffer", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_convolution.DynamicConv1dTBC.extra_repr": [[288, 305], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "s", "=", "\"{}, kernel_size={}, padding_l={}, num_heads={}, weight_softmax={}, conv_bias={}, renorm_padding={}, in_proj={}\"", ".", "format", "(", "\n", "self", ".", "input_size", ",", "\n", "self", ".", "kernel_size", ",", "\n", "self", ".", "padding_l", ",", "\n", "self", ".", "num_heads", ",", "\n", "self", ".", "weight_softmax", ",", "\n", "self", ".", "conv_bias", "is", "not", "None", ",", "\n", "self", ".", "renorm_padding", ",", "\n", "self", ".", "in_proj", ",", "\n", ")", "\n", "\n", "if", "self", ".", "query_size", "!=", "self", ".", "input_size", ":", "\n", "            ", "s", "+=", "\", query_size={}\"", ".", "format", "(", "self", ".", "query_size", ")", "\n", "", "if", "self", ".", "weight_dropout_module", ".", "p", ">", "0.0", ":", "\n", "            ", "s", "+=", "\", weight_dropout={}\"", ".", "format", "(", "self", ".", "weight_dropout_module", ".", "p", ")", "\n", "", "return", "s", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_convolution.DynamicConv": [[16, 52], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "dynamic_convolution.DynamicConv1dTBC", "DynamicconvLayer", "print"], "function", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print"], ["def", "DynamicConv", "(", "\n", "input_size", ",", "\n", "kernel_size", "=", "1", ",", "\n", "padding_l", "=", "None", ",", "\n", "num_heads", "=", "1", ",", "\n", "weight_dropout", "=", "0.0", ",", "\n", "weight_softmax", "=", "False", ",", "\n", "renorm_padding", "=", "False", ",", "\n", "bias", "=", "False", ",", "\n", "conv_bias", "=", "False", ",", "\n", "query_size", "=", "None", ",", "\n", "in_proj", "=", "False", ",", "\n", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "fairseq", ".", "modules", ".", "dynamicconv_layer", "import", "DynamicconvLayer", "\n", "\n", "return", "DynamicconvLayer", "(", "\n", "input_size", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "padding_l", "=", "padding_l", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "weight_dropout", "=", "weight_dropout", ",", "\n", "weight_softmax", "=", "weight_softmax", ",", "\n", "bias", "=", "bias", ",", "\n", ")", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "            ", "print", "(", "e", ")", "\n", "", "", "return", "DynamicConv1dTBC", "(", "\n", "input_size", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "padding_l", "=", "padding_l", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "weight_dropout", "=", "weight_dropout", ",", "\n", "weight_softmax", "=", "weight_softmax", ",", "\n", "bias", "=", "bias", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_convolution.Linear": [[55, 61], ["torch.Linear", "torch.init.xavier_uniform_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["", "def", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "if", "bias", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.0", ")", "\n", "", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.adaptive_softmax.TiedLinear.__init__": [[17, 21], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "weight", ",", "transpose", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weight", "=", "weight", "\n", "self", ".", "transpose", "=", "transpose", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.adaptive_softmax.TiedLinear.forward": [[22, 24], ["torch.linear", "torch.linear", "adaptive_softmax.TiedLinear.weight.t"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "F", ".", "linear", "(", "input", ",", "self", ".", "weight", ".", "t", "(", ")", "if", "self", ".", "transpose", "else", "self", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.adaptive_softmax.TiedHeadModule.__init__": [[27, 49], ["torch.nn.Module.__init__", "tied_emb.size", "fairseq.modules.quant_noise.quant_noise", "fairseq.modules.quant_noise.quant_noise", "adaptive_softmax.TiedHeadModule.register_buffer", "adaptive_softmax.TiedLinear", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "fairseq.modules.quant_noise.quant_noise", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["    ", "def", "__init__", "(", "self", ",", "weights", ",", "input_dim", ",", "num_classes", ",", "q_noise", ",", "qn_block_size", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "tied_emb", ",", "_", "=", "weights", "\n", "self", ".", "num_words", ",", "emb_dim", "=", "tied_emb", ".", "size", "(", ")", "\n", "\n", "self", ".", "word_proj", "=", "quant_noise", "(", "\n", "TiedLinear", "(", "tied_emb", ",", "transpose", "=", "False", ")", ",", "q_noise", ",", "qn_block_size", "\n", ")", "\n", "if", "input_dim", "!=", "emb_dim", ":", "\n", "            ", "self", ".", "word_proj", "=", "nn", ".", "Sequential", "(", "\n", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "input_dim", ",", "emb_dim", ",", "bias", "=", "False", ")", ",", "q_noise", ",", "qn_block_size", "\n", ")", ",", "\n", "self", ".", "word_proj", ",", "\n", ")", "\n", "\n", "", "self", ".", "class_proj", "=", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "input_dim", ",", "num_classes", ",", "bias", "=", "False", ")", ",", "q_noise", ",", "qn_block_size", "\n", ")", "\n", "self", ".", "out_dim", "=", "self", ".", "num_words", "+", "num_classes", "\n", "\n", "self", ".", "register_buffer", "(", "\"_float_tensor\"", ",", "torch", ".", "FloatTensor", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.adaptive_softmax.TiedHeadModule.forward": [[50, 56], ["functools.reduce", "adaptive_softmax.TiedHeadModule._float_tensor.new", "adaptive_softmax.TiedHeadModule.word_proj", "adaptive_softmax.TiedHeadModule.class_proj", "input.view", "input.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "inp_sz", "=", "functools", ".", "reduce", "(", "operator", ".", "mul", ",", "input", ".", "shape", "[", ":", "-", "1", "]", ",", "1", ")", "\n", "out", "=", "self", ".", "_float_tensor", ".", "new", "(", "inp_sz", ",", "self", ".", "out_dim", ")", "\n", "out", "[", ":", ",", ":", "self", ".", "num_words", "]", "=", "self", ".", "word_proj", "(", "input", ".", "view", "(", "inp_sz", ",", "-", "1", ")", ")", "\n", "out", "[", ":", ",", "self", ".", "num_words", ":", "]", "=", "self", ".", "class_proj", "(", "input", ".", "view", "(", "inp_sz", ",", "-", "1", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.adaptive_softmax.AdaptiveSoftmax.__init__": [[65, 128], ["torch.nn.Module.__init__", "fairseq.modules.fairseq_dropout.FairseqDropout", "torch.nn.LogSoftmax", "torch.nn.LogSoftmax", "adaptive_softmax.AdaptiveSoftmax._make_tail", "adaptive_softmax.AdaptiveSoftmax.apply", "adaptive_softmax.AdaptiveSoftmax.register_buffer", "adaptive_softmax.TiedHeadModule", "fairseq.modules.quant_noise.quant_noise", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "len", "adaptive_inputs.weights_for_band", "torch.nn.Linear", "torch.nn.Linear", "hasattr", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "len", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.modules.adaptive_softmax.AdaptiveSoftmax._make_tail", "home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.modules.adaptive_input.AdaptiveInput.weights_for_band", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size", ",", "\n", "input_dim", ",", "\n", "cutoff", ",", "\n", "dropout", ",", "\n", "factor", "=", "4.0", ",", "\n", "adaptive_inputs", "=", "None", ",", "\n", "tie_proj", "=", "False", ",", "\n", "q_noise", "=", "0", ",", "\n", "qn_block_size", "=", "8", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "vocab_size", ">", "cutoff", "[", "-", "1", "]", ":", "\n", "            ", "cutoff", "=", "cutoff", "+", "[", "vocab_size", "]", "\n", "", "else", ":", "\n", "            ", "assert", "(", "\n", "vocab_size", "==", "cutoff", "[", "-", "1", "]", "\n", ")", ",", "\"cannot specify cutoff larger than vocab size\"", "\n", "\n", "", "output_dim", "=", "cutoff", "[", "0", "]", "+", "len", "(", "cutoff", ")", "-", "1", "\n", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "cutoff", "=", "cutoff", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "factor", "=", "factor", "\n", "self", ".", "q_noise", "=", "q_noise", "\n", "self", ".", "qn_block_size", "=", "qn_block_size", "\n", "\n", "self", ".", "lsm", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "1", ")", "\n", "\n", "if", "adaptive_inputs", "is", "not", "None", ":", "\n", "            ", "self", ".", "head", "=", "TiedHeadModule", "(", "\n", "adaptive_inputs", ".", "weights_for_band", "(", "0", ")", ",", "\n", "input_dim", ",", "\n", "len", "(", "cutoff", ")", "-", "1", ",", "\n", "self", ".", "q_noise", ",", "\n", "self", ".", "qn_block_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "head", "=", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ",", "bias", "=", "False", ")", ",", "\n", "self", ".", "q_noise", ",", "\n", "self", ".", "qn_block_size", ",", "\n", ")", "\n", "\n", "", "self", ".", "_make_tail", "(", "adaptive_inputs", ",", "tie_proj", ")", "\n", "\n", "def", "init_weights", "(", "m", ")", ":", "\n", "            ", "if", "(", "\n", "hasattr", "(", "m", ",", "\"weight\"", ")", "\n", "and", "not", "isinstance", "(", "m", ",", "TiedLinear", ")", "\n", "and", "not", "isinstance", "(", "m", ",", "TiedHeadModule", ")", "\n", ")", ":", "\n", "                ", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "init_weights", ")", "\n", "\n", "self", ".", "register_buffer", "(", "\"version\"", ",", "torch", ".", "LongTensor", "(", "[", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.adaptive_softmax.AdaptiveSoftmax._make_tail": [[129, 174], ["torch.nn.ModuleList", "torch.nn.ModuleList", "range", "int", "torch.nn.Sequential", "torch.nn.Sequential", "adaptive_softmax.AdaptiveSoftmax.tail.append", "len", "adaptive_inputs.weights_for_band", "fairseq.modules.quant_noise.quant_noise", "torch.nn.Linear", "torch.nn.Linear", "adaptive_softmax.TiedLinear", "torch.nn.Dropout", "torch.nn.Dropout", "fairseq.modules.quant_noise.quant_noise", "fairseq.modules.quant_noise.quant_noise", "fairseq.modules.quant_noise.quant_noise", "torch.nn.Linear", "torch.nn.Linear", "adaptive_softmax.TiedLinear", "torch.nn.Linear", "torch.nn.Linear", "tied_proj.size", "tied_proj.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.adaptive_input.AdaptiveInput.weights_for_band", "home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "_make_tail", "(", "self", ",", "adaptive_inputs", "=", "None", ",", "tie_proj", "=", "False", ")", ":", "\n", "        ", "self", ".", "tail", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoff", ")", "-", "1", ")", ":", "\n", "            ", "dim", "=", "int", "(", "self", ".", "input_dim", "//", "self", ".", "factor", "**", "(", "i", "+", "1", ")", ")", "\n", "\n", "tied_emb", ",", "tied_proj", "=", "(", "\n", "adaptive_inputs", ".", "weights_for_band", "(", "i", "+", "1", ")", "\n", "if", "adaptive_inputs", "is", "not", "None", "\n", "else", "(", "None", ",", "None", ")", "\n", ")", "\n", "\n", "if", "tied_proj", "is", "not", "None", ":", "\n", "                ", "if", "tie_proj", ":", "\n", "                    ", "proj", "=", "quant_noise", "(", "\n", "TiedLinear", "(", "tied_proj", ",", "transpose", "=", "True", ")", ",", "\n", "self", ".", "q_noise", ",", "\n", "self", ".", "qn_block_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "proj", "=", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "tied_proj", ".", "size", "(", "0", ")", ",", "tied_proj", ".", "size", "(", "1", ")", ",", "bias", "=", "False", ")", ",", "\n", "self", ".", "q_noise", ",", "\n", "self", ".", "qn_block_size", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "                ", "proj", "=", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "input_dim", ",", "dim", ",", "bias", "=", "False", ")", ",", "\n", "self", ".", "q_noise", ",", "\n", "self", ".", "qn_block_size", ",", "\n", ")", "\n", "\n", "", "if", "tied_emb", "is", "None", ":", "\n", "                ", "out_proj", "=", "nn", ".", "Linear", "(", "\n", "dim", ",", "self", ".", "cutoff", "[", "i", "+", "1", "]", "-", "self", ".", "cutoff", "[", "i", "]", ",", "bias", "=", "False", "\n", ")", "\n", "", "else", ":", "\n", "                ", "out_proj", "=", "TiedLinear", "(", "tied_emb", ",", "transpose", "=", "False", ")", "\n", "\n", "", "m", "=", "nn", ".", "Sequential", "(", "\n", "proj", ",", "\n", "nn", ".", "Dropout", "(", "self", ".", "dropout_module", ".", "p", ")", ",", "\n", "quant_noise", "(", "out_proj", ",", "self", ".", "q_noise", ",", "self", ".", "qn_block_size", ")", ",", "\n", ")", "\n", "\n", "self", ".", "tail", ".", "append", "(", "m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.adaptive_softmax.AdaptiveSoftmax.upgrade_state_dict_named": [[175, 179], ["Exception"], "methods", ["None"], ["", "", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "version_name", "=", "name", "+", "\".version\"", "\n", "if", "version_name", "not", "in", "state_dict", ":", "\n", "            ", "raise", "Exception", "(", "\"This version of the model is no longer supported\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.adaptive_softmax.AdaptiveSoftmax.adapt_target": [[180, 204], ["target.view.view.view", "range", "target.view.view.clone", "target.view.view.ge().mul", "target.view.ge().mul.any", "len", "target.view.view.lt", "target_idxs.append", "new_target.append", "target_idxs.append", "new_target.append", "target.view.view.ge", "target.view.ge().mul.nonzero().squeeze", "target[].add", "target.view.ge().mul.nonzero"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add"], ["", "", "def", "adapt_target", "(", "self", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        In order to be efficient, the AdaptiveSoftMax does not compute the\n        scores for all the word of the vocabulary for all the examples. It is\n        thus necessary to call the method adapt_target of the AdaptiveSoftMax\n        layer inside each forward pass.\n        \"\"\"", "\n", "\n", "target", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "new_target", "=", "[", "target", ".", "clone", "(", ")", "]", "\n", "target_idxs", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoff", ")", "-", "1", ")", ":", "\n", "            ", "mask", "=", "target", ".", "ge", "(", "self", ".", "cutoff", "[", "i", "]", ")", ".", "mul", "(", "target", ".", "lt", "(", "self", ".", "cutoff", "[", "i", "+", "1", "]", ")", ")", "\n", "new_target", "[", "0", "]", "[", "mask", "]", "=", "self", ".", "cutoff", "[", "0", "]", "+", "i", "\n", "\n", "if", "mask", ".", "any", "(", ")", ":", "\n", "                ", "target_idxs", ".", "append", "(", "mask", ".", "nonzero", "(", "as_tuple", "=", "False", ")", ".", "squeeze", "(", "1", ")", ")", "\n", "new_target", ".", "append", "(", "target", "[", "mask", "]", ".", "add", "(", "-", "self", ".", "cutoff", "[", "i", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "target_idxs", ".", "append", "(", "None", ")", "\n", "new_target", ".", "append", "(", "None", ")", "\n", "\n", "", "", "return", "new_target", ",", "target_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.adaptive_softmax.AdaptiveSoftmax.forward": [[205, 227], ["adaptive_softmax.AdaptiveSoftmax.contiguous().view", "adaptive_softmax.AdaptiveSoftmax.dropout_module", "adaptive_softmax.AdaptiveSoftmax.adapt_target", "range", "adaptive_softmax.AdaptiveSoftmax.size", "adaptive_softmax.AdaptiveSoftmax.head", "len", "adaptive_softmax.AdaptiveSoftmax.contiguous", "output.append", "output.append", "adaptive_softmax.AdaptiveSoftmax.index_select"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.adaptive_softmax.AdaptiveSoftmax.adapt_target", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input: (b x t x d)\n            target: (b x t)\n        Returns:\n            2 lists: output for each cutoff section and new targets by cut off\n        \"\"\"", "\n", "\n", "input", "=", "input", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "input", ".", "size", "(", "-", "1", ")", ")", "\n", "input", "=", "self", ".", "dropout_module", "(", "input", ")", "\n", "\n", "new_target", ",", "target_idxs", "=", "self", ".", "adapt_target", "(", "target", ")", "\n", "output", "=", "[", "self", ".", "head", "(", "input", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "target_idxs", ")", ")", ":", "\n", "            ", "if", "target_idxs", "[", "i", "]", "is", "not", "None", ":", "\n", "                ", "output", ".", "append", "(", "self", ".", "tail", "[", "i", "]", "(", "input", ".", "index_select", "(", "0", ",", "target_idxs", "[", "i", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "None", ")", "\n", "\n", "", "", "return", "output", ",", "new_target", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.adaptive_softmax.AdaptiveSoftmax.get_log_prob": [[228, 269], ["input.contiguous().view.contiguous().view.size", "input.contiguous().view.contiguous().view.contiguous().view", "adaptive_softmax.AdaptiveSoftmax.head", "adaptive_softmax.AdaptiveSoftmax.new_zeros", "adaptive_softmax.AdaptiveSoftmax.lsm", "log_probs[].clone", "range", "log_probs.view.view.view", "adaptive_softmax.AdaptiveSoftmax.adapt_target", "input.contiguous().view.contiguous().view.size", "len", "len", "input.contiguous().view.contiguous().view.contiguous", "tail_out.copy_", "adaptive_softmax.AdaptiveSoftmax.lsm().add_", "tail_out.copy_", "adaptive_softmax.AdaptiveSoftmax.lsm().add_", "adaptive_softmax.AdaptiveSoftmax.lsm", "adaptive_softmax.AdaptiveSoftmax.lsm"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.modules.adaptive_softmax.AdaptiveSoftmax.adapt_target", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "get_log_prob", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        Computes the log probabilities for all the words of the vocabulary,\n        given a 2D tensor of hidden vectors.\n        \"\"\"", "\n", "\n", "bsz", ",", "length", ",", "dim", "=", "input", ".", "size", "(", ")", "\n", "input", "=", "input", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "dim", ")", "\n", "\n", "if", "target", "is", "not", "None", ":", "\n", "            ", "_", ",", "target_idxs", "=", "self", ".", "adapt_target", "(", "target", ")", "\n", "", "else", ":", "\n", "            ", "target_idxs", "=", "None", "\n", "\n", "", "head_y", "=", "self", ".", "head", "(", "input", ")", "\n", "log_probs", "=", "head_y", ".", "new_zeros", "(", "input", ".", "size", "(", "0", ")", ",", "self", ".", "vocab_size", ")", "\n", "\n", "head_sz", "=", "self", ".", "cutoff", "[", "0", "]", "+", "len", "(", "self", ".", "tail", ")", "\n", "log_probs", "[", ":", ",", ":", "head_sz", "]", "=", "self", ".", "lsm", "(", "head_y", ")", "\n", "tail_priors", "=", "log_probs", "[", ":", ",", "self", ".", "cutoff", "[", "0", "]", ":", "head_sz", "]", ".", "clone", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "tail", ")", ")", ":", "\n", "            ", "start", "=", "self", ".", "cutoff", "[", "i", "]", "\n", "end", "=", "self", ".", "cutoff", "[", "i", "+", "1", "]", "\n", "\n", "if", "target_idxs", "is", "None", ":", "\n", "                ", "tail_out", "=", "log_probs", "[", ":", ",", "start", ":", "end", "]", "\n", "tail_out", ".", "copy_", "(", "self", ".", "tail", "[", "i", "]", "(", "input", ")", ")", "\n", "log_probs", "[", ":", ",", "start", ":", "end", "]", "=", "self", ".", "lsm", "(", "tail_out", ")", ".", "add_", "(", "\n", "tail_priors", "[", ":", ",", "i", ",", "None", "]", "\n", ")", "\n", "", "elif", "target_idxs", "[", "i", "]", "is", "not", "None", ":", "\n", "                ", "idxs", "=", "target_idxs", "[", "i", "]", "\n", "tail_out", "=", "log_probs", "[", "idxs", ",", "start", ":", "end", "]", "\n", "tail_out", ".", "copy_", "(", "self", ".", "tail", "[", "i", "]", "(", "input", "[", "idxs", "]", ")", ")", "\n", "log_probs", "[", "idxs", ",", "start", ":", "end", "]", "=", "self", ".", "lsm", "(", "tail_out", ")", ".", "add_", "(", "\n", "tail_priors", "[", "idxs", ",", "i", ",", "None", "]", "\n", ")", "\n", "\n", "", "", "log_probs", "=", "log_probs", ".", "view", "(", "bsz", ",", "length", ",", "-", "1", ")", "\n", "return", "log_probs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.cross_entropy._cross_entropy_pytorch": [[15, 22], ["torch.log_softmax", "torch.nll_loss"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax"], ["def", "_cross_entropy_pytorch", "(", "logits", ",", "target", ",", "ignore_index", "=", "None", ",", "reduction", "=", "\"mean\"", ")", ":", "\n", "    ", "lprobs", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "return", "F", ".", "nll_loss", "(", "\n", "lprobs", ",", "\n", "target", ",", "\n", "ignore_index", "=", "ignore_index", ",", "\n", "reduction", "=", "reduction", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.beamable_mm.BeamableMM.__init__": [[19, 22], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "beam_size", "=", "None", ")", ":", "\n", "        ", "super", "(", "BeamableMM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.beamable_mm.BeamableMM.forward": [[23, 47], ["input1[].unfold().transpose", "input1[].unfold().transpose.bmm.view", "input1[].unfold().transpose.bmm", "input1[].unfold().transpose.dim", "input1[].unfold().transpose.size", "input1[].unfold().transpose.size", "input2.unfold", "input1[].unfold().transpose.size", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "input1[].unfold().transpose.bmm", "input1[].unfold"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "forward", "(", "self", ",", "input1", ",", "input2", ")", ":", "\n", "        ", "if", "(", "\n", "not", "self", ".", "training", "\n", "and", "self", ".", "beam_size", "is", "not", "None", "# test mode", "\n", "and", "input1", ".", "dim", "(", ")", "==", "3", "# beam size is set", "\n", "and", "input1", ".", "size", "(", "1", ")", "# only support batched input", "\n", "==", "1", "# single time step update", "\n", ")", ":", "\n", "            ", "bsz", ",", "beam", "=", "input1", ".", "size", "(", "0", ")", ",", "self", ".", "beam_size", "\n", "\n", "# bsz x 1 x nhu --> bsz/beam x beam x nhu", "\n", "input1", "=", "input1", "[", ":", ",", "0", ",", ":", "]", ".", "unfold", "(", "0", ",", "beam", ",", "beam", ")", ".", "transpose", "(", "2", ",", "1", ")", "\n", "\n", "# bsz x sz2 x nhu --> bsz/beam x sz2 x nhu", "\n", "input2", "=", "input2", ".", "unfold", "(", "0", ",", "beam", ",", "beam", ")", "[", ":", ",", ":", ",", ":", ",", "0", "]", "\n", "\n", "# use non batched operation if bsz = beam", "\n", "if", "input1", ".", "size", "(", "0", ")", "==", "1", ":", "\n", "                ", "output", "=", "torch", ".", "mm", "(", "input1", "[", "0", ",", ":", ",", ":", "]", ",", "input2", "[", "0", ",", ":", ",", ":", "]", ")", "\n", "", "else", ":", "\n", "                ", "output", "=", "input1", ".", "bmm", "(", "input2", ")", "\n", "", "return", "output", ".", "view", "(", "bsz", ",", "1", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "input1", ".", "bmm", "(", "input2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.beamable_mm.BeamableMM.set_beam_size": [[48, 50], ["None"], "methods", ["None"], ["", "", "def", "set_beam_size", "(", "self", ",", "beam_size", ")", ":", "\n", "        ", "self", ".", "beam_size", "=", "beam_size", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.same_pad.SamePad.__init__": [[11, 14], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "kernel_size", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "remove", "=", "kernel_size", "%", "2", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.same_pad.SamePad.forward": [[15, 19], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "remove", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", ":", ",", ":", "-", "1", "]", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.conv_tbc.ConvTBC.__init__": [[17, 28], ["super().__init__", "torch.nn.modules.utils._single", "torch.nn.modules.utils._single", "torch.nn.Parameter", "torch.nn.Parameter", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "padding", "=", "0", ")", ":", "\n", "        ", "super", "(", "ConvTBC", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "kernel_size", "=", "_single", "(", "kernel_size", ")", "\n", "self", ".", "padding", "=", "_single", "(", "padding", ")", "\n", "\n", "self", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "self", ".", "kernel_size", "[", "0", "]", ",", "in_channels", ",", "out_channels", ")", "\n", ")", "\n", "self", ".", "bias", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.conv_tbc.ConvTBC.forward": [[29, 32], ["torch.conv_tbc", "input.contiguous"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "torch", ".", "conv_tbc", "(", "\n", "input", ".", "contiguous", "(", ")", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "self", ".", "padding", "[", "0", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.conv_tbc.ConvTBC.__repr__": [[34, 43], ["s.format"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "s", "=", "(", "\n", "\"{name}({in_channels}, {out_channels}, kernel_size={kernel_size}\"", "\n", "\", padding={padding}\"", "\n", ")", "\n", "if", "self", ".", "bias", "is", "None", ":", "\n", "            ", "s", "+=", "\", bias=False\"", "\n", "", "s", "+=", "\")\"", "\n", "return", "s", ".", "format", "(", "name", "=", "self", ".", "__class__", ".", "__name__", ",", "**", "self", ".", "__dict__", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.character_token_embedder.CharacterTokenEmbedder.__init__": [[23, 63], ["super().__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.ModuleList", "torch.nn.ModuleList", "sum", "torch.nn.Linear", "torch.nn.Linear", "character_token_embedder.CharacterTokenEmbedder.reset_parameters", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "character_token_embedder.CharacterTokenEmbedder.convolutions.append", "character_token_embedder.Highway", "character_token_embedder.CharacterTokenEmbedder.set_vocab", "torch.nn.Conv1d", "torch.nn.Conv1d"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters", "home.repos.pwc.inspect_result.reneeye_const.modules.character_token_embedder.CharacterTokenEmbedder.set_vocab"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "vocab", ":", "Dictionary", ",", "\n", "filters", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", ",", "\n", "char_embed_dim", ":", "int", ",", "\n", "word_embed_dim", ":", "int", ",", "\n", "highway_layers", ":", "int", ",", "\n", "max_char_len", ":", "int", "=", "50", ",", "\n", "char_inputs", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", "CharacterTokenEmbedder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "self", ".", "embedding_dim", "=", "word_embed_dim", "\n", "self", ".", "max_char_len", "=", "max_char_len", "\n", "self", ".", "char_embeddings", "=", "nn", ".", "Embedding", "(", "257", ",", "char_embed_dim", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "symbol_embeddings", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "2", ",", "word_embed_dim", ")", ")", "\n", "self", ".", "eos_idx", ",", "self", ".", "unk_idx", "=", "0", ",", "1", "\n", "self", ".", "char_inputs", "=", "char_inputs", "\n", "\n", "self", ".", "convolutions", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "width", ",", "out_c", "in", "filters", ":", "\n", "            ", "self", ".", "convolutions", ".", "append", "(", "\n", "nn", ".", "Conv1d", "(", "char_embed_dim", ",", "out_c", ",", "kernel_size", "=", "width", ")", "\n", ")", "\n", "\n", "", "last_dim", "=", "sum", "(", "f", "[", "1", "]", "for", "f", "in", "filters", ")", "\n", "\n", "self", ".", "highway", "=", "Highway", "(", "last_dim", ",", "highway_layers", ")", "if", "highway_layers", ">", "0", "else", "None", "\n", "\n", "self", ".", "projection", "=", "nn", ".", "Linear", "(", "last_dim", ",", "word_embed_dim", ")", "\n", "\n", "assert", "(", "\n", "vocab", "is", "not", "None", "or", "char_inputs", "\n", ")", ",", "\"vocab must be set if not using char inputs\"", "\n", "self", ".", "vocab", "=", "None", "\n", "if", "vocab", "is", "not", "None", ":", "\n", "            ", "self", ".", "set_vocab", "(", "vocab", ",", "max_char_len", ")", "\n", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.character_token_embedder.CharacterTokenEmbedder.prepare_for_onnx_export_": [[64, 66], ["None"], "methods", ["None"], ["", "def", "prepare_for_onnx_export_", "(", "self", ")", ":", "\n", "        ", "self", ".", "onnx_trace", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.character_token_embedder.CharacterTokenEmbedder.set_vocab": [[67, 92], ["torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "len", "len", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "logger.info", "vocab[].encode", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "def", "set_vocab", "(", "self", ",", "vocab", ",", "max_char_len", ")", ":", "\n", "        ", "word_to_char", "=", "torch", ".", "LongTensor", "(", "len", "(", "vocab", ")", ",", "max_char_len", ")", "\n", "\n", "truncated", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "vocab", ")", ")", ":", "\n", "            ", "if", "i", "<", "vocab", ".", "nspecial", ":", "\n", "                ", "char_idxs", "=", "[", "0", "]", "*", "max_char_len", "\n", "", "else", ":", "\n", "                ", "chars", "=", "vocab", "[", "i", "]", ".", "encode", "(", ")", "\n", "# +1 for padding", "\n", "char_idxs", "=", "[", "c", "+", "1", "for", "c", "in", "chars", "]", "+", "[", "0", "]", "*", "(", "max_char_len", "-", "len", "(", "chars", ")", ")", "\n", "", "if", "len", "(", "char_idxs", ")", ">", "max_char_len", ":", "\n", "                ", "truncated", "+=", "1", "\n", "char_idxs", "=", "char_idxs", "[", ":", "max_char_len", "]", "\n", "", "word_to_char", "[", "i", "]", "=", "torch", ".", "LongTensor", "(", "char_idxs", ")", "\n", "\n", "", "if", "truncated", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"truncated {} words longer than {} characters\"", ".", "format", "(", "\n", "truncated", ",", "max_char_len", "\n", ")", "\n", ")", "\n", "\n", "", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "word_to_char", "=", "word_to_char", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.character_token_embedder.CharacterTokenEmbedder.padding_idx": [[93, 96], ["fairseq.data.Dictionary().pad", "character_token_embedder.CharacterTokenEmbedder.vocab.pad", "fairseq.data.Dictionary"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["", "@", "property", "\n", "def", "padding_idx", "(", "self", ")", ":", "\n", "        ", "return", "Dictionary", "(", ")", ".", "pad", "(", ")", "if", "self", ".", "vocab", "is", "None", "else", "self", ".", "vocab", ".", "pad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.character_token_embedder.CharacterTokenEmbedder.reset_parameters": [[97, 106], ["torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "char_embeddings", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "symbol_embeddings", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "projection", ".", "weight", ")", "\n", "\n", "nn", ".", "init", ".", "constant_", "(", "\n", "self", ".", "char_embeddings", ".", "weight", "[", "self", ".", "char_embeddings", ".", "padding_idx", "]", ",", "0.0", "\n", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "projection", ".", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.character_token_embedder.CharacterTokenEmbedder.forward": [[107, 154], ["character_token_embedder.CharacterTokenEmbedder._convolve", "torch.where.view", "torch.where.view", "input.view", "chars[].eq", "chars[].eq", "input.view.eq.any", "input.view", "character_token_embedder.CharacterTokenEmbedder.word_to_char[].type_as", "input.view.eq", "input.view.eq", "input.view.eq", "input.view.eq.any", "input.view.eq.any", "input.view.eq.any", "input.view.eq.any", "character_token_embedder.CharacterTokenEmbedder.vocab.pad", "character_token_embedder.CharacterTokenEmbedder.vocab.eos", "character_token_embedder.CharacterTokenEmbedder.vocab.unk", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "input.view.eq.any", "torch.where", "torch.where", "torch.where", "torch.where", "input.view.eq.any", "torch.where", "torch.where", "torch.where", "torch.where", "input.view.eq.unsqueeze", "torch.where.new_zeros", "torch.where.new_zeros", "input.view.eq.unsqueeze", "input.view.eq.unsqueeze", "input.size", "input.view.eq.unsqueeze", "torch.where.new_zeros", "torch.where.new_zeros", "input.view.type_as"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.character_token_embedder.CharacterTokenEmbedder._convolve", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input", ":", "torch", ".", "Tensor", ",", "\n", ")", ":", "\n", "        ", "if", "self", ".", "char_inputs", ":", "\n", "            ", "chars", "=", "input", ".", "view", "(", "-", "1", ",", "self", ".", "max_char_len", ")", "\n", "pads", "=", "chars", "[", ":", ",", "0", "]", ".", "eq", "(", "CHAR_PAD_IDX", ")", "\n", "eos", "=", "chars", "[", ":", ",", "0", "]", ".", "eq", "(", "CHAR_EOS_IDX", ")", "\n", "if", "eos", ".", "any", "(", ")", ":", "\n", "                ", "if", "self", ".", "onnx_trace", ":", "\n", "                    ", "chars", "=", "torch", ".", "where", "(", "eos", ".", "unsqueeze", "(", "1", ")", ",", "chars", ".", "new_zeros", "(", "1", ")", ",", "chars", ")", "\n", "", "else", ":", "\n", "                    ", "chars", "[", "eos", "]", "=", "0", "\n", "\n", "", "", "unk", "=", "None", "\n", "", "else", ":", "\n", "            ", "flat_words", "=", "input", ".", "view", "(", "-", "1", ")", "\n", "chars", "=", "self", ".", "word_to_char", "[", "flat_words", ".", "type_as", "(", "self", ".", "word_to_char", ")", "]", ".", "type_as", "(", "\n", "input", "\n", ")", "\n", "pads", "=", "flat_words", ".", "eq", "(", "self", ".", "vocab", ".", "pad", "(", ")", ")", "\n", "eos", "=", "flat_words", ".", "eq", "(", "self", ".", "vocab", ".", "eos", "(", ")", ")", "\n", "unk", "=", "flat_words", ".", "eq", "(", "self", ".", "vocab", ".", "unk", "(", ")", ")", "\n", "\n", "", "word_embs", "=", "self", ".", "_convolve", "(", "chars", ")", "\n", "if", "self", ".", "onnx_trace", ":", "\n", "            ", "if", "pads", ".", "any", "(", ")", ":", "\n", "                ", "word_embs", "=", "torch", ".", "where", "(", "\n", "pads", ".", "unsqueeze", "(", "1", ")", ",", "word_embs", ".", "new_zeros", "(", "1", ")", ",", "word_embs", "\n", ")", "\n", "", "if", "eos", ".", "any", "(", ")", ":", "\n", "                ", "word_embs", "=", "torch", ".", "where", "(", "\n", "eos", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "symbol_embeddings", "[", "self", ".", "eos_idx", "]", ",", "word_embs", "\n", ")", "\n", "", "if", "unk", "is", "not", "None", "and", "unk", ".", "any", "(", ")", ":", "\n", "                ", "word_embs", "=", "torch", ".", "where", "(", "\n", "unk", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "symbol_embeddings", "[", "self", ".", "unk_idx", "]", ",", "word_embs", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "pads", ".", "any", "(", ")", ":", "\n", "                ", "word_embs", "[", "pads", "]", "=", "0", "\n", "", "if", "eos", ".", "any", "(", ")", ":", "\n", "                ", "word_embs", "[", "eos", "]", "=", "self", ".", "symbol_embeddings", "[", "self", ".", "eos_idx", "]", "\n", "", "if", "unk", "is", "not", "None", "and", "unk", ".", "any", "(", ")", ":", "\n", "                ", "word_embs", "[", "unk", "]", "=", "self", ".", "symbol_embeddings", "[", "self", ".", "unk_idx", "]", "\n", "\n", "", "", "return", "word_embs", ".", "view", "(", "input", ".", "size", "(", ")", "[", ":", "2", "]", "+", "(", "-", "1", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.character_token_embedder.CharacterTokenEmbedder._convolve": [[155, 177], ["character_token_embedder.CharacterTokenEmbedder.char_embeddings", "char_embs.transpose.transpose.transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "character_token_embedder.CharacterTokenEmbedder.projection", "conv", "torch.max", "torch.max", "torch.max", "torch.max", "torch.relu", "torch.relu", "conv_result.append", "character_token_embedder.CharacterTokenEmbedder.highway"], "methods", ["None"], ["", "def", "_convolve", "(", "\n", "self", ",", "\n", "char_idxs", ":", "torch", ".", "Tensor", ",", "\n", ")", ":", "\n", "        ", "char_embs", "=", "self", ".", "char_embeddings", "(", "char_idxs", ")", "\n", "char_embs", "=", "char_embs", ".", "transpose", "(", "1", ",", "2", ")", "# BTC -> BCT", "\n", "\n", "conv_result", "=", "[", "]", "\n", "\n", "for", "conv", "in", "self", ".", "convolutions", ":", "\n", "            ", "x", "=", "conv", "(", "char_embs", ")", "\n", "x", ",", "_", "=", "torch", ".", "max", "(", "x", ",", "-", "1", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "conv_result", ".", "append", "(", "x", ")", "\n", "\n", "", "x", "=", "torch", ".", "cat", "(", "conv_result", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "self", ".", "highway", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "highway", "(", "x", ")", "\n", "", "x", "=", "self", ".", "projection", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.character_token_embedder.Highway.__init__": [[185, 194], ["super().__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ReLU", "torch.nn.ReLU", "character_token_embedder.Highway.reset_parameters", "torch.nn.Linear", "torch.nn.Linear", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["def", "__init__", "(", "self", ",", "input_dim", ":", "int", ",", "num_layers", ":", "int", "=", "1", ")", ":", "\n", "        ", "super", "(", "Highway", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "nn", ".", "Linear", "(", "input_dim", ",", "input_dim", "*", "2", ")", "for", "_", "in", "range", "(", "num_layers", ")", "]", "\n", ")", "\n", "self", ".", "activation", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.character_token_embedder.Highway.reset_parameters": [[195, 206], ["torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layers", ":", "\n", "# As per comment in AllenNLP:", "\n", "# We should bias the highway layer to just carry its input forward.  We do that by", "\n", "# setting the bias on `B(x)` to be positive, because that means `g` will be biased to", "\n", "# be high, so we will carry the input forward.  The bias on `B(x)` is the second half", "\n", "# of the bias vector in each Linear layer.", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "layer", ".", "bias", "[", "self", ".", "input_dim", ":", "]", ",", "1", ")", "\n", "\n", "nn", ".", "init", ".", "constant_", "(", "layer", ".", "bias", "[", ":", "self", ".", "input_dim", "]", ",", "0", ")", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "layer", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.character_token_embedder.Highway.forward": [[207, 215], ["layer", "layer.chunk", "character_token_embedder.Highway.activation", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid.new_tensor", "torch.sigmoid.new_tensor"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "projection", "=", "layer", "(", "x", ")", "\n", "proj_x", ",", "gate", "=", "projection", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "proj_x", "=", "self", ".", "activation", "(", "proj_x", ")", "\n", "gate", "=", "torch", ".", "sigmoid", "(", "gate", ")", "\n", "x", "=", "gate", "*", "x", "+", "(", "gate", ".", "new_tensor", "(", "[", "1", "]", ")", "-", "gate", ")", "*", "proj_x", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.sparse_multihead_attention.SparseMultiheadAttention.__init__": [[24, 58], ["multihead_attention.MultiheadAttention.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embed_dim", ",", "\n", "num_heads", ",", "\n", "kdim", "=", "None", ",", "\n", "vdim", "=", "None", ",", "\n", "dropout", "=", "0.0", ",", "\n", "bias", "=", "True", ",", "\n", "add_bias_kv", "=", "False", ",", "\n", "add_zero_attn", "=", "False", ",", "\n", "self_attention", "=", "False", ",", "\n", "encoder_decoder_attention", "=", "False", ",", "\n", "stride", "=", "32", ",", "\n", "expressivity", "=", "8", ",", "\n", "is_bidirectional", "=", "True", ",", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "embed_dim", ",", "\n", "num_heads", ",", "\n", "kdim", ",", "\n", "vdim", ",", "\n", "dropout", ",", "\n", "bias", ",", "\n", "add_bias_kv", ",", "\n", "add_zero_attn", ",", "\n", "self_attention", ",", "\n", "encoder_decoder_attention", ",", "\n", ")", "\n", "\n", "self", ".", "is_bidirectional", "=", "is_bidirectional", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "expressivity", "=", "expressivity", "\n", "assert", "self", ".", "stride", ">", "0", "and", "self", ".", "stride", ">=", "self", ".", "expressivity", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.sparse_multihead_attention.SparseMultiheadAttention.compute_checkpoint": [[60, 70], ["math.floor"], "methods", ["None"], ["", "def", "compute_checkpoint", "(", "self", ",", "word_index", ")", ":", "\n", "        ", "if", "word_index", "%", "self", ".", "stride", "==", "0", "and", "word_index", "!=", "0", ":", "\n", "            ", "checkpoint_index", "=", "word_index", "-", "self", ".", "expressivity", "\n", "", "else", ":", "\n", "            ", "checkpoint_index", "=", "(", "\n", "math", ".", "floor", "(", "word_index", "/", "self", ".", "stride", ")", "*", "self", ".", "stride", "\n", "+", "self", ".", "stride", "\n", "-", "self", ".", "expressivity", "\n", ")", "\n", "", "return", "checkpoint_index", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.sparse_multihead_attention.SparseMultiheadAttention.compute_subset_summaries": [[72, 85], ["sparse_multihead_attention.SparseMultiheadAttention.compute_checkpoint", "set", "set", "subset_two.union.union.union", "sparse_multihead_attention.SparseMultiheadAttention.compute_checkpoint", "range", "min"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.sparse_multihead_attention.SparseMultiheadAttention.compute_checkpoint", "home.repos.pwc.inspect_result.reneeye_const.modules.sparse_multihead_attention.SparseMultiheadAttention.compute_checkpoint"], ["", "def", "compute_subset_summaries", "(", "self", ",", "absolute_max", ")", ":", "\n", "        ", "checkpoint_index", "=", "self", ".", "compute_checkpoint", "(", "0", ")", "\n", "subset_two", "=", "set", "(", ")", "\n", "while", "checkpoint_index", "<=", "absolute_max", "-", "1", ":", "\n", "            ", "summary", "=", "set", "(", "\n", "range", "(", "\n", "checkpoint_index", ",", "\n", "min", "(", "checkpoint_index", "+", "self", ".", "expressivity", "+", "1", ",", "absolute_max", ")", ",", "\n", ")", "\n", ")", "\n", "subset_two", "=", "subset_two", ".", "union", "(", "summary", ")", "\n", "checkpoint_index", "=", "self", ".", "compute_checkpoint", "(", "checkpoint_index", "+", "self", ".", "stride", ")", "\n", "", "return", "subset_two", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.sparse_multihead_attention.SparseMultiheadAttention.compute_fixed_attention_subset": [[87, 117], ["set", "set.union", "math.floor", "set", "set", "sparse_multihead_attention.SparseMultiheadAttention.compute_subset_summaries", "range", "range", "min", "max", "min"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.sparse_multihead_attention.SparseMultiheadAttention.compute_subset_summaries"], ["", "def", "compute_fixed_attention_subset", "(", "self", ",", "word_index", ",", "tgt_len", ")", ":", "\n", "# +1s account for range function; [min, max) -> [min, max]", "\n", "        ", "if", "not", "self", ".", "is_bidirectional", ":", "\n", "            ", "absolute_max", "=", "word_index", "+", "1", "\n", "", "else", ":", "\n", "            ", "absolute_max", "=", "tgt_len", "\n", "\n", "# Subset 1 - whole window", "\n", "", "rounded_index", "=", "(", "\n", "math", ".", "floor", "(", "(", "word_index", "+", "self", ".", "stride", ")", "/", "self", ".", "stride", ")", "*", "self", ".", "stride", "\n", ")", "\n", "if", "word_index", "%", "self", ".", "stride", "==", "0", "and", "word_index", "!=", "0", ":", "\n", "            ", "subset_one", "=", "set", "(", "\n", "range", "(", "word_index", "-", "self", ".", "stride", ",", "min", "(", "absolute_max", ",", "word_index", "+", "1", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "subset_one", "=", "set", "(", "\n", "range", "(", "\n", "max", "(", "0", ",", "rounded_index", "-", "self", ".", "stride", ")", ",", "\n", "min", "(", "absolute_max", ",", "rounded_index", "+", "1", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "# Subset 2 - summary per window", "\n", "# If bidirectional, subset 2 is the same for every index", "\n", "", "subset_two", "=", "set", "(", ")", "\n", "if", "not", "self", ".", "is_bidirectional", ":", "\n", "            ", "subset_two", "=", "self", ".", "compute_subset_summaries", "(", "absolute_max", ")", "\n", "\n", "", "return", "subset_one", ".", "union", "(", "subset_two", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.sparse_multihead_attention.SparseMultiheadAttention.buffered_sparse_mask": [[119, 134], ["torch.empty().float().fill_", "set", "range", "torch.empty().float().fill_.type_as", "float", "sparse_multihead_attention.SparseMultiheadAttention.compute_subset_summaries", "sparse_multihead_attention.SparseMultiheadAttention.compute_fixed_attention_subset", "fixed_attention_subset.union.union.union", "torch.LongTensor", "sparse_mask[].index_fill_", "torch.empty().float", "list", "torch.empty"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.sparse_multihead_attention.SparseMultiheadAttention.compute_subset_summaries", "home.repos.pwc.inspect_result.reneeye_const.modules.sparse_multihead_attention.SparseMultiheadAttention.compute_fixed_attention_subset"], ["", "def", "buffered_sparse_mask", "(", "self", ",", "tensor", ",", "tgt_len", ",", "src_len", ")", ":", "\n", "        ", "assert", "tgt_len", ">", "self", ".", "stride", "\n", "sparse_mask", "=", "torch", ".", "empty", "(", "(", "tgt_len", ",", "src_len", ")", ")", ".", "float", "(", ")", ".", "fill_", "(", "float", "(", "\"-inf\"", ")", ")", "\n", "\n", "# If bidirectional, subset 2 is the same for every index", "\n", "subset_summaries", "=", "set", "(", ")", "\n", "if", "self", ".", "is_bidirectional", ":", "\n", "            ", "subset_summaries", "=", "self", ".", "compute_subset_summaries", "(", "tgt_len", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "tgt_len", ")", ":", "\n", "            ", "fixed_attention_subset", "=", "self", ".", "compute_fixed_attention_subset", "(", "i", ",", "tgt_len", ")", "\n", "fixed_attention_subset", "=", "fixed_attention_subset", ".", "union", "(", "subset_summaries", ")", "\n", "included_word_indices", "=", "torch", ".", "LongTensor", "(", "list", "(", "fixed_attention_subset", ")", ")", "\n", "sparse_mask", "[", "i", "]", ".", "index_fill_", "(", "0", ",", "included_word_indices", ",", "0", ")", "\n", "", "return", "sparse_mask", ".", "type_as", "(", "tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.sparse_multihead_attention.SparseMultiheadAttention.apply_sparse_mask": [[135, 141], ["sparse_multihead_attention.SparseMultiheadAttention.buffered_sparse_mask", "sparse_mask.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "sparse_mask.unsqueeze().expand.unsqueeze().expand.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.sparse_multihead_attention.SparseMultiheadAttention.buffered_sparse_mask"], ["", "def", "apply_sparse_mask", "(", "self", ",", "attn_weights", ",", "tgt_len", ",", "src_len", ",", "bsz", ")", ":", "\n", "        ", "sparse_mask", "=", "self", ".", "buffered_sparse_mask", "(", "attn_weights", ",", "tgt_len", ",", "src_len", ")", "\n", "sparse_mask", "=", "sparse_mask", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "\n", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", "\n", ")", "\n", "attn_weights", "+=", "sparse_mask", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.__init__": [[12, 84], ["torch.GELU", "torch.GELU", "torch.GELU", "torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "isinstance", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.init.zeros_", "torch.init.zeros_", "torch.init.zeros_", "ast.literal_eval", "len", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "len", "torch.Linear", "torch.Linear", "torch.Linear", "gumbel_vector_quantizer.GumbelVectorQuantizer.__init__.block"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "dim", ",", "\n", "num_vars", ",", "\n", "temp", ",", "\n", "groups", ",", "\n", "combine_groups", ",", "\n", "vq_dim", ",", "\n", "time_first", ",", "\n", "activation", "=", "nn", ".", "GELU", "(", ")", ",", "\n", "weight_proj_depth", "=", "1", ",", "\n", "weight_proj_factor", "=", "1", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Vector quantization using gumbel softmax\n\n        Args:\n            dim: input dimension (channels)\n            num_vars: number of quantized vectors per group\n            temp: temperature for training. this should be a tuple of 3 elements: (start, stop, decay factor)\n            groups: number of groups for vector quantization\n            combine_groups: whether to use the vectors for all groups\n            vq_dim: dimensionality of the resulting quantized vector\n            time_first: if true, expect input in BxTxC format, otherwise in BxCxT\n            activation: what activation to use (should be a module). this is only used if weight_proj_depth is > 1\n            weight_proj_depth: number of layers (with activation in between) to project input before computing logits\n            weight_proj_factor: this is used only if weight_proj_depth is > 1. scales the inner dimensionality of\n                                projections by this factor\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "groups", "=", "groups", "\n", "self", ".", "combine_groups", "=", "combine_groups", "\n", "self", ".", "input_dim", "=", "dim", "\n", "self", ".", "num_vars", "=", "num_vars", "\n", "self", ".", "time_first", "=", "time_first", "\n", "\n", "assert", "(", "\n", "vq_dim", "%", "groups", "==", "0", "\n", ")", ",", "f\"dim {vq_dim} must be divisible by groups {groups} for concatenation\"", "\n", "\n", "var_dim", "=", "vq_dim", "//", "groups", "\n", "num_groups", "=", "groups", "if", "not", "combine_groups", "else", "1", "\n", "\n", "self", ".", "vars", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "1", ",", "num_groups", "*", "num_vars", ",", "var_dim", ")", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "vars", ")", "\n", "\n", "if", "weight_proj_depth", ">", "1", ":", "\n", "\n", "            ", "def", "block", "(", "input_dim", ",", "output_dim", ")", ":", "\n", "                ", "return", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ")", ",", "activation", ")", "\n", "\n", "", "inner_dim", "=", "self", ".", "input_dim", "*", "weight_proj_factor", "\n", "self", ".", "weight_proj", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "\n", "block", "(", "self", ".", "input_dim", "if", "i", "==", "0", "else", "inner_dim", ",", "inner_dim", ")", "\n", "for", "i", "in", "range", "(", "weight_proj_depth", "-", "1", ")", "\n", "]", ",", "\n", "nn", ".", "Linear", "(", "inner_dim", ",", "groups", "*", "num_vars", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "weight_proj", "=", "nn", ".", "Linear", "(", "self", ".", "input_dim", ",", "groups", "*", "num_vars", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "weight_proj", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "1", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "weight_proj", ".", "bias", ")", "\n", "\n", "", "if", "isinstance", "(", "temp", ",", "str", ")", ":", "\n", "            ", "import", "ast", "\n", "temp", "=", "ast", ".", "literal_eval", "(", "temp", ")", "\n", "", "assert", "len", "(", "temp", ")", "==", "3", ",", "f\"{temp}, {len(temp)}\"", "\n", "\n", "self", ".", "max_temp", ",", "self", ".", "min_temp", ",", "self", ".", "temp_decay", "=", "temp", "\n", "self", ".", "curr_temp", "=", "self", ".", "max_temp", "\n", "self", ".", "codebook_indices", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.set_num_updates": [[85, 88], ["max"], "methods", ["None"], ["", "def", "set_num_updates", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "self", ".", "curr_temp", "=", "max", "(", "\n", "self", ".", "max_temp", "*", "self", ".", "temp_decay", "**", "num_updates", ",", "self", ".", "min_temp", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.get_codebook_indices": [[90, 108], ["list", "torch.tensor().flatten", "torch.tensor().flatten", "torch.tensor().flatten", "torch.tensor().flatten", "torch.tensor().flatten", "torch.tensor().flatten", "torch.tensor().flatten", "torch.tensor().flatten", "torch.tensor().flatten", "product", "gumbel_vector_quantizer.GumbelVectorQuantizer.codebook_indices.view", "range", "gumbel_vector_quantizer.GumbelVectorQuantizer.codebook_indices.flatten", "range", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "get_codebook_indices", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "codebook_indices", "is", "None", ":", "\n", "            ", "from", "itertools", "import", "product", "\n", "\n", "p", "=", "[", "range", "(", "self", ".", "num_vars", ")", "]", "*", "self", ".", "groups", "\n", "inds", "=", "list", "(", "product", "(", "*", "p", ")", ")", "\n", "self", ".", "codebook_indices", "=", "torch", ".", "tensor", "(", "\n", "inds", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "vars", ".", "device", "\n", ")", ".", "flatten", "(", ")", "\n", "\n", "if", "not", "self", ".", "combine_groups", ":", "\n", "                ", "self", ".", "codebook_indices", "=", "self", ".", "codebook_indices", ".", "view", "(", "\n", "self", ".", "num_vars", "**", "self", ".", "groups", ",", "-", "1", "\n", ")", "\n", "for", "b", "in", "range", "(", "1", ",", "self", ".", "groups", ")", ":", "\n", "                    ", "self", ".", "codebook_indices", "[", ":", ",", "b", "]", "+=", "self", ".", "num_vars", "*", "b", "\n", "", "self", ".", "codebook_indices", "=", "self", ".", "codebook_indices", ".", "flatten", "(", ")", "\n", "", "", "return", "self", ".", "codebook_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.codebook": [[109, 115], ["gumbel_vector_quantizer.GumbelVectorQuantizer.get_codebook_indices", "gumbel_vector_quantizer.GumbelVectorQuantizer.vars.squeeze().index_select().view", "gumbel_vector_quantizer.GumbelVectorQuantizer.vars.squeeze().index_select", "gumbel_vector_quantizer.GumbelVectorQuantizer.vars.squeeze"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.get_codebook_indices"], ["", "def", "codebook", "(", "self", ")", ":", "\n", "        ", "indices", "=", "self", ".", "get_codebook_indices", "(", ")", "\n", "return", "(", "\n", "self", ".", "vars", ".", "squeeze", "(", "0", ")", "\n", ".", "index_select", "(", "0", ",", "indices", ")", "\n", ".", "view", "(", "self", ".", "num_vars", "**", "self", ".", "groups", ",", "-", "1", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.sample_from_codebook": [[117, 129], ["gumbel_vector_quantizer.GumbelVectorQuantizer.get_codebook_indices", "indices.view.view.view", "indices.view.view.size", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "gumbel_vector_quantizer.GumbelVectorQuantizer.vars.squeeze().index_select().view", "gumbel_vector_quantizer.GumbelVectorQuantizer.vars.squeeze().index_select", "indices.view.view.flatten", "gumbel_vector_quantizer.GumbelVectorQuantizer.vars.squeeze"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.get_codebook_indices", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "sample_from_codebook", "(", "self", ",", "b", ",", "n", ")", ":", "\n", "        ", "indices", "=", "self", ".", "get_codebook_indices", "(", ")", "\n", "indices", "=", "indices", ".", "view", "(", "-", "1", ",", "self", ".", "groups", ")", "\n", "cb_size", "=", "indices", ".", "size", "(", "0", ")", "\n", "assert", "(", "\n", "n", "<", "cb_size", "\n", ")", ",", "f\"sample size {n} is greater than size of codebook {cb_size}\"", "\n", "sample_idx", "=", "torch", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "cb_size", ",", "size", "=", "(", "b", "*", "n", ",", ")", ")", "\n", "indices", "=", "indices", "[", "sample_idx", "]", "\n", "\n", "z", "=", "self", ".", "vars", ".", "squeeze", "(", "0", ")", ".", "index_select", "(", "0", ",", "indices", ".", "flatten", "(", ")", ")", ".", "view", "(", "b", ",", "n", ",", "-", "1", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.to_codebook_index": [[130, 136], ["indices.new_full", "range"], "methods", ["None"], ["", "def", "to_codebook_index", "(", "self", ",", "indices", ")", ":", "\n", "        ", "res", "=", "indices", ".", "new_full", "(", "indices", ".", "shape", "[", ":", "-", "1", "]", ",", "0", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "groups", ")", ":", "\n", "            ", "exponent", "=", "self", ".", "groups", "-", "i", "-", "1", "\n", "res", "+=", "indices", "[", "...", ",", "i", "]", "*", "(", "self", ".", "num_vars", "**", "exponent", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.forward_idx": [[137, 140], ["gumbel_vector_quantizer.GumbelVectorQuantizer.forward"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.forward"], ["", "def", "forward_idx", "(", "self", ",", "x", ")", ":", "\n", "        ", "res", "=", "self", ".", "forward", "(", "x", ",", "produce_targets", "=", "True", ")", "\n", "return", "res", "[", "\"x\"", "]", ",", "res", "[", "\"targets\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.forward": [[141, 203], ["x.transpose.transpose.reshape", "gumbel_vector_quantizer.GumbelVectorQuantizer.weight_proj", "x.transpose.transpose.view", "x.transpose.transpose.max", "x.transpose.transpose.new_zeros().scatter_().view", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.softmax().mean", "torch.softmax().mean", "torch.softmax().mean", "torch.softmax().mean", "torch.softmax().mean", "torch.softmax().mean", "torch.softmax().mean", "torch.softmax().mean", "torch.softmax().mean", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "x.transpose.transpose.view", "x.transpose.transpose.view", "x.transpose.transpose.sum", "x.transpose.transpose.view", "x.transpose.transpose.transpose", "x.transpose.new_zeros().scatter_().view.float", "torch.gumbel_softmax().type_as", "torch.gumbel_softmax().type_as", "torch.gumbel_softmax().type_as", "vars.repeat.repeat.repeat", "x.transpose.transpose.view().argmax().view().detach", "x.transpose.transpose.unsqueeze", "x.transpose.transpose.transpose", "x.transpose.transpose.new_zeros().scatter_", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "k.view", "x.transpose.transpose.view().float", "torch.gumbel_softmax", "torch.gumbel_softmax", "torch.gumbel_softmax", "x.transpose.transpose.view().argmax().view", "x.transpose.transpose.new_zeros", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "x.transpose.transpose.float", "x.transpose.transpose.view", "x.transpose.transpose.view().argmax", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "x.transpose.transpose.view"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log"], ["", "def", "forward", "(", "self", ",", "x", ",", "produce_targets", "=", "False", ")", ":", "\n", "\n", "        ", "result", "=", "{", "\"num_vars\"", ":", "self", ".", "num_vars", "*", "self", ".", "groups", "}", "\n", "\n", "if", "not", "self", ".", "time_first", ":", "\n", "            ", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "", "bsz", ",", "tsz", ",", "fsz", "=", "x", ".", "shape", "\n", "x", "=", "x", ".", "reshape", "(", "-", "1", ",", "fsz", ")", "\n", "x", "=", "self", ".", "weight_proj", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "bsz", "*", "tsz", "*", "self", ".", "groups", ",", "-", "1", ")", "\n", "\n", "_", ",", "k", "=", "x", ".", "max", "(", "-", "1", ")", "\n", "hard_x", "=", "(", "\n", "x", ".", "new_zeros", "(", "*", "x", ".", "shape", ")", "\n", ".", "scatter_", "(", "-", "1", ",", "k", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1.0", ")", "\n", ".", "view", "(", "bsz", "*", "tsz", ",", "self", ".", "groups", ",", "-", "1", ")", "\n", ")", "\n", "hard_probs", "=", "torch", ".", "mean", "(", "hard_x", ".", "float", "(", ")", ",", "dim", "=", "0", ")", "\n", "result", "[", "\"code_perplexity\"", "]", "=", "torch", ".", "exp", "(", "\n", "-", "torch", ".", "sum", "(", "hard_probs", "*", "torch", ".", "log", "(", "hard_probs", "+", "1e-7", ")", ",", "dim", "=", "-", "1", ")", "\n", ")", ".", "sum", "(", ")", "\n", "\n", "avg_probs", "=", "torch", ".", "softmax", "(", "\n", "x", ".", "view", "(", "bsz", "*", "tsz", ",", "self", ".", "groups", ",", "-", "1", ")", ".", "float", "(", ")", ",", "dim", "=", "-", "1", "\n", ")", ".", "mean", "(", "dim", "=", "0", ")", "\n", "result", "[", "\"prob_perplexity\"", "]", "=", "torch", ".", "exp", "(", "\n", "-", "torch", ".", "sum", "(", "avg_probs", "*", "torch", ".", "log", "(", "avg_probs", "+", "1e-7", ")", ",", "dim", "=", "-", "1", ")", "\n", ")", ".", "sum", "(", ")", "\n", "\n", "result", "[", "\"temp\"", "]", "=", "self", ".", "curr_temp", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "x", "=", "F", ".", "gumbel_softmax", "(", "x", ".", "float", "(", ")", ",", "tau", "=", "self", ".", "curr_temp", ",", "hard", "=", "True", ")", ".", "type_as", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "hard_x", "\n", "\n", "", "x", "=", "x", ".", "view", "(", "bsz", "*", "tsz", ",", "-", "1", ")", "\n", "\n", "vars", "=", "self", ".", "vars", "\n", "if", "self", ".", "combine_groups", ":", "\n", "            ", "vars", "=", "vars", ".", "repeat", "(", "1", ",", "self", ".", "groups", ",", "1", ")", "\n", "\n", "", "if", "produce_targets", ":", "\n", "            ", "result", "[", "\"targets\"", "]", "=", "(", "\n", "x", ".", "view", "(", "bsz", "*", "tsz", "*", "self", ".", "groups", ",", "-", "1", ")", "\n", ".", "argmax", "(", "dim", "=", "-", "1", ")", "\n", ".", "view", "(", "bsz", ",", "tsz", ",", "self", ".", "groups", ")", "\n", ".", "detach", "(", ")", "\n", ")", "\n", "\n", "", "x", "=", "x", ".", "unsqueeze", "(", "-", "1", ")", "*", "vars", "\n", "x", "=", "x", ".", "view", "(", "bsz", "*", "tsz", ",", "self", ".", "groups", ",", "self", ".", "num_vars", ",", "-", "1", ")", "\n", "x", "=", "x", ".", "sum", "(", "-", "2", ")", "\n", "x", "=", "x", ".", "view", "(", "bsz", ",", "tsz", ",", "-", "1", ")", "\n", "\n", "if", "not", "self", ".", "time_first", ":", "\n", "            ", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "# BTC -> BCT", "\n", "\n", "", "result", "[", "\"x\"", "]", "=", "x", "\n", "\n", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.sparse_transformer_sentence_encoder_layer.SparseTransformerSentenceEncoderLayer.__init__": [[15, 51], ["fairseq.modules.TransformerSentenceEncoderLayer.__init__", "fairseq.modules.sparse_multihead_attention.SparseMultiheadAttention"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embedding_dim", ":", "int", "=", "768", ",", "\n", "ffn_embedding_dim", ":", "int", "=", "3072", ",", "\n", "num_attention_heads", ":", "int", "=", "8", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "attention_dropout", ":", "float", "=", "0.1", ",", "\n", "activation_dropout", ":", "float", "=", "0.1", ",", "\n", "activation_fn", ":", "str", "=", "\"relu\"", ",", "\n", "export", ":", "bool", "=", "False", ",", "\n", "is_bidirectional", ":", "bool", "=", "True", ",", "\n", "stride", ":", "int", "=", "32", ",", "\n", "expressivity", ":", "int", "=", "8", ",", "\n", ")", "->", "None", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "embedding_dim", ",", "\n", "ffn_embedding_dim", ",", "\n", "num_attention_heads", ",", "\n", "dropout", ",", "\n", "attention_dropout", ",", "\n", "activation_dropout", ",", "\n", "activation_fn", ",", "\n", "export", ",", "\n", ")", "\n", "\n", "self", ".", "self_attn", "=", "SparseMultiheadAttention", "(", "\n", "self", ".", "embedding_dim", ",", "\n", "num_attention_heads", ",", "\n", "dropout", "=", "attention_dropout", ",", "\n", "add_bias_kv", "=", "False", ",", "\n", "add_zero_attn", "=", "False", ",", "\n", "self_attention", "=", "True", ",", "\n", "is_bidirectional", "=", "is_bidirectional", ",", "\n", "stride", "=", "stride", ",", "\n", "expressivity", "=", "expressivity", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.__init__": [[21, 31], ["torch.nn.Module.__init__", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.get_embedding", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.register_buffer", "int", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.modules.sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.get_embedding"], ["def", "__init__", "(", "self", ",", "embedding_dim", ",", "padding_idx", ",", "init_size", "=", "1024", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "init_size", ",", "embedding_dim", ",", "padding_idx", "\n", ")", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "self", ".", "register_buffer", "(", "\"_float_tensor\"", ",", "torch", ".", "FloatTensor", "(", "1", ")", ")", "\n", "self", ".", "max_positions", "=", "int", "(", "1e5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.prepare_for_onnx_export_": [[32, 34], ["None"], "methods", ["None"], ["", "def", "prepare_for_onnx_export_", "(", "self", ")", ":", "\n", "        ", "self", ".", "onnx_trace", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.get_embedding": [[35, 59], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "math.log", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log"], ["", "@", "staticmethod", "\n", "def", "get_embedding", "(", "\n", "num_embeddings", ":", "int", ",", "embedding_dim", ":", "int", ",", "padding_idx", ":", "Optional", "[", "int", "]", "=", "None", "\n", ")", ":", "\n", "        ", "\"\"\"Build sinusoidal embeddings.\n\n        This matches the implementation in tensor2tensor, but differs slightly\n        from the description in Section 3.5 of \"Attention Is All You Need\".\n        \"\"\"", "\n", "half_dim", "=", "embedding_dim", "//", "2", "\n", "emb", "=", "math", ".", "log", "(", "10000", ")", "/", "(", "half_dim", "-", "1", ")", "\n", "emb", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "half_dim", ",", "dtype", "=", "torch", ".", "float", ")", "*", "-", "emb", ")", "\n", "emb", "=", "torch", ".", "arange", "(", "num_embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ".", "unsqueeze", "(", "\n", "1", "\n", ")", "*", "emb", ".", "unsqueeze", "(", "0", ")", "\n", "emb", "=", "torch", ".", "cat", "(", "[", "torch", ".", "sin", "(", "emb", ")", ",", "torch", ".", "cos", "(", "emb", ")", "]", ",", "dim", "=", "1", ")", ".", "view", "(", "\n", "num_embeddings", ",", "-", "1", "\n", ")", "\n", "if", "embedding_dim", "%", "2", "==", "1", ":", "\n", "# zero pad", "\n", "            ", "emb", "=", "torch", ".", "cat", "(", "[", "emb", ",", "torch", ".", "zeros", "(", "num_embeddings", ",", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "if", "padding_idx", "is", "not", "None", ":", "\n", "            ", "emb", "[", "padding_idx", ",", ":", "]", "=", "0", "\n", "", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.forward": [[60, 104], ["torch.onnx.operators.shape_as_tensor", "torch.onnx.operators.shape_as_tensor", "torch.onnx.operators.shape_as_tensor", "torch.onnx.operators.shape_as_tensor", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.to", "fairseq.utils.make_positions", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.index_select().view().detach", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.get_embedding", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights[].expand", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.detach().index_select", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.onnx.operators.reshape_from_tensor_shape", "torch.onnx.operators.reshape_from_tensor_shape", "torch.onnx.operators.reshape_from_tensor_shape", "torch.onnx.operators.reshape_from_tensor_shape", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.size", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze().repeat", "fairseq.utils.make_positions.view", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.index_select().view", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.detach", "bsz.view", "seq_len.view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "timestep.view", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.index_select", "fairseq.utils.make_positions.view", "sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.weights.index_select"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.make_positions", "home.repos.pwc.inspect_result.reneeye_const.modules.sinusoidal_positional_embedding.SinusoidalPositionalEmbedding.get_embedding", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input", ",", "\n", "incremental_state", ":", "Optional", "[", "Any", "]", "=", "None", ",", "\n", "timestep", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "positions", ":", "Optional", "[", "Any", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [bsz x seqlen].\"\"\"", "\n", "bspair", "=", "torch", ".", "onnx", ".", "operators", ".", "shape_as_tensor", "(", "input", ")", "\n", "bsz", ",", "seq_len", "=", "bspair", "[", "0", "]", ",", "bspair", "[", "1", "]", "\n", "max_pos", "=", "self", ".", "padding_idx", "+", "1", "+", "seq_len", "\n", "if", "self", ".", "weights", "is", "None", "or", "max_pos", ">", "self", ".", "weights", ".", "size", "(", "0", ")", ":", "\n", "# recompute/expand embeddings if needed", "\n", "            ", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "max_pos", ",", "self", ".", "embedding_dim", ",", "self", ".", "padding_idx", "\n", ")", "\n", "", "self", ".", "weights", "=", "self", ".", "weights", ".", "to", "(", "self", ".", "_float_tensor", ")", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "# positions is the same for every token when decoding a single step", "\n", "            ", "pos", "=", "timestep", ".", "view", "(", "-", "1", ")", "[", "0", "]", "+", "1", "if", "timestep", "is", "not", "None", "else", "seq_len", "\n", "if", "self", ".", "onnx_trace", ":", "\n", "                ", "return", "(", "\n", "self", ".", "weights", ".", "index_select", "(", "index", "=", "self", ".", "padding_idx", "+", "pos", ",", "dim", "=", "0", ")", "\n", ".", "unsqueeze", "(", "1", ")", "\n", ".", "repeat", "(", "bsz", ",", "1", ",", "1", ")", "\n", ")", "\n", "", "return", "self", ".", "weights", "[", "self", ".", "padding_idx", "+", "pos", ",", ":", "]", ".", "expand", "(", "bsz", ",", "1", ",", "-", "1", ")", "\n", "\n", "", "positions", "=", "utils", ".", "make_positions", "(", "\n", "input", ",", "self", ".", "padding_idx", ",", "onnx_trace", "=", "self", ".", "onnx_trace", "\n", ")", "\n", "if", "self", ".", "onnx_trace", ":", "\n", "            ", "flat_embeddings", "=", "self", ".", "weights", ".", "detach", "(", ")", ".", "index_select", "(", "0", ",", "positions", ".", "view", "(", "-", "1", ")", ")", "\n", "embedding_shape", "=", "torch", ".", "cat", "(", "\n", "(", "bsz", ".", "view", "(", "1", ")", ",", "seq_len", ".", "view", "(", "1", ")", ",", "torch", ".", "tensor", "(", "[", "-", "1", "]", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", ")", "\n", "embeddings", "=", "torch", ".", "onnx", ".", "operators", ".", "reshape_from_tensor_shape", "(", "\n", "flat_embeddings", ",", "embedding_shape", "\n", ")", "\n", "return", "embeddings", "\n", "", "return", "(", "\n", "self", ".", "weights", ".", "index_select", "(", "0", ",", "positions", ".", "view", "(", "-", "1", ")", ")", "\n", ".", "view", "(", "bsz", ",", "seq_len", ",", "-", "1", ")", "\n", ".", "detach", "(", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.Fp32LayerNorm.__init__": [[39, 41], ["torch.LayerNorm.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.Fp32LayerNorm.forward": [[42, 51], ["torch.layer_norm", "torch.layer_norm", "torch.layer_norm", "torch.layer_norm.type_as", "input.float", "layer_norm.Fp32LayerNorm.weight.float", "layer_norm.Fp32LayerNorm.bias.float"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "output", "=", "F", ".", "layer_norm", "(", "\n", "input", ".", "float", "(", ")", ",", "\n", "self", ".", "normalized_shape", ",", "\n", "self", ".", "weight", ".", "float", "(", ")", "if", "self", ".", "weight", "is", "not", "None", "else", "None", ",", "\n", "self", ".", "bias", ".", "float", "(", ")", "if", "self", ".", "bias", "is", "not", "None", "else", "None", ",", "\n", "self", ".", "eps", ",", "\n", ")", "\n", "return", "output", ".", "type_as", "(", "input", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm": [[30, 36], ["torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "FusedLayerNorm"], "function", ["home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm"], ["", "def", "LayerNorm", "(", "normalized_shape", ",", "eps", "=", "1e-5", ",", "elementwise_affine", "=", "True", ",", "export", "=", "False", ")", ":", "\n", "    ", "if", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "        ", "export", "=", "True", "\n", "", "if", "not", "export", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "has_fused_layernorm", ":", "\n", "        ", "return", "FusedLayerNorm", "(", "normalized_shape", ",", "eps", ",", "elementwise_affine", ")", "\n", "", "return", "torch", ".", "nn", ".", "LayerNorm", "(", "normalized_shape", ",", "eps", ",", "elementwise_affine", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.lightweight_convolution.LightweightConv1d.__init__": [[73, 99], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "fairseq.modules.fairseq_dropout.FairseqDropout", "lightweight_convolution.LightweightConv1d.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters"], ["def", "__init__", "(", "\n", "self", ",", "\n", "input_size", ",", "\n", "kernel_size", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "num_heads", "=", "1", ",", "\n", "weight_softmax", "=", "False", ",", "\n", "bias", "=", "False", ",", "\n", "weight_dropout", "=", "0.0", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "weight_softmax", "=", "weight_softmax", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_heads", ",", "1", ",", "kernel_size", ")", ")", "\n", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "input_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", "=", "None", "\n", "", "self", ".", "weight_dropout_module", "=", "FairseqDropout", "(", "\n", "weight_dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.lightweight_convolution.LightweightConv1d.reset_parameters": [[100, 104], ["torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "weight", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.lightweight_convolution.LightweightConv1d.forward": [[105, 129], ["input.view.view.size", "lightweight_convolution.LightweightConv1d.weight_dropout_module", "input.view.view.view", "torch.conv1d", "torch.conv1d", "torch.conv1d", "output.view.view.view", "torch.softmax", "torch.softmax", "torch.softmax", "lightweight_convolution.LightweightConv1d.bias.view"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"\n        input size: B x C x T\n        output size: B x C x T\n        \"\"\"", "\n", "B", ",", "C", ",", "T", "=", "input", ".", "size", "(", ")", "\n", "H", "=", "self", ".", "num_heads", "\n", "\n", "weight", "=", "self", ".", "weight", "\n", "if", "self", ".", "weight_softmax", ":", "\n", "            ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "weight", "=", "self", ".", "weight_dropout_module", "(", "weight", ")", "\n", "# Merge every C/H entries into the batch dimension (C = self.input_size)", "\n", "# B x C x T -> (B * C/H) x H x T", "\n", "# One can also expand the weight to C x 1 x K by a factor of C/H", "\n", "# and do not reshape the input instead, which is slow though", "\n", "input", "=", "input", ".", "view", "(", "-", "1", ",", "H", ",", "T", ")", "\n", "output", "=", "F", ".", "conv1d", "(", "input", ",", "weight", ",", "padding", "=", "self", ".", "padding", ",", "groups", "=", "self", ".", "num_heads", ")", "\n", "output", "=", "output", ".", "view", "(", "B", ",", "C", ",", "T", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "output", "=", "output", "+", "self", ".", "bias", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.lightweight_convolution.LightweightConv1dTBC.__init__": [[153, 181], ["torch.Module.__init__", "fairseq.modules.fairseq_dropout.FairseqDropout", "torch.Parameter", "torch.Parameter", "torch.Parameter", "lightweight_convolution.LightweightConv1dTBC.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters"], ["def", "__init__", "(", "\n", "self", ",", "\n", "input_size", ",", "\n", "kernel_size", "=", "1", ",", "\n", "padding_l", "=", "None", ",", "\n", "num_heads", "=", "1", ",", "\n", "weight_dropout", "=", "0.0", ",", "\n", "weight_softmax", "=", "False", ",", "\n", "bias", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "padding_l", "=", "padding_l", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "weight_dropout_module", "=", "FairseqDropout", "(", "\n", "weight_dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "weight_softmax", "=", "weight_softmax", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_heads", ",", "1", ",", "kernel_size", ")", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "input_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", "=", "None", "\n", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.lightweight_convolution.LightweightConv1dTBC.reset_parameters": [[182, 186], ["torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "weight", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.lightweight_convolution.LightweightConv1dTBC.forward": [[187, 204], ["lightweight_convolution.LightweightConv1dTBC._forward_unfolded", "lightweight_convolution.LightweightConv1dTBC._forward_expanded", "lightweight_convolution.LightweightConv1dTBC.bias.view"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._forward_unfolded", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._forward_expanded"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "incremental_state", "=", "None", ",", "unfold", "=", "False", ")", ":", "\n", "        ", "\"\"\"Assuming the input, x, of the shape T x B x C and producing an output in the shape T x B x C\n        args:\n            x: Input of shape T x B x C, i.e. (timesteps, batch_size, input_size)\n            incremental_state: A dict to keep the state\n            unfold: unfold the input or not. If not, we use the matrix trick instead\n        \"\"\"", "\n", "unfold", "=", "unfold", "or", "(", "incremental_state", "is", "not", "None", ")", "\n", "\n", "if", "unfold", ":", "\n", "            ", "output", "=", "self", ".", "_forward_unfolded", "(", "x", ",", "incremental_state", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "_forward_expanded", "(", "x", ",", "incremental_state", ")", "\n", "\n", "", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "output", "=", "output", "+", "self", ".", "bias", ".", "view", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.lightweight_convolution.LightweightConv1dTBC.prepare_for_onnx_export_": [[205, 207], ["None"], "methods", ["None"], ["", "def", "prepare_for_onnx_export_", "(", "self", ")", ":", "\n", "        ", "self", ".", "onnx_trace", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.lightweight_convolution.LightweightConv1dTBC._forward_unfolded": [[208, 249], ["x.size", "lightweight_convolution.LightweightConv1dTBC.weight.view", "fairseq.utils.softmax().type_as.view().expand().contiguous().view", "lightweight_convolution.LightweightConv1dTBC.weight_dropout_module", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "output.view.view.view", "lightweight_convolution.LightweightConv1dTBC._get_input_buffer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_unfold.view.view.view", "fairseq.modules.unfold.unfold1d", "x_unfold.view.view.view", "fairseq.utils.softmax().type_as", "fairseq.utils.softmax().type_as.size", "x.new", "lightweight_convolution.LightweightConv1dTBC._set_input_buffer", "fairseq.utils.softmax().type_as.view().expand().contiguous", "x.unsqueeze", "fairseq.utils.softmax", "fairseq.utils.softmax().type_as.view().expand", "x_unfold.view.view.size", "fairseq.utils.softmax().type_as.view"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.modules.unfold.unfold1d", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "_forward_unfolded", "(", "self", ",", "x", ",", "incremental_state", ")", ":", "\n", "        ", "\"\"\"The conventional implementation of convolutions.\n        Unfolding the input by having a window shifting to the right.\"\"\"", "\n", "T", ",", "B", ",", "C", "=", "x", ".", "size", "(", ")", "\n", "K", ",", "H", "=", "self", ".", "kernel_size", ",", "self", ".", "num_heads", "\n", "R", "=", "C", "//", "H", "\n", "assert", "R", "*", "H", "==", "C", "==", "self", ".", "input_size", "\n", "\n", "weight", "=", "self", ".", "weight", ".", "view", "(", "H", ",", "K", ")", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "None", ":", "\n", "                ", "input_buffer", "=", "x", ".", "new", "(", ")", "\n", "", "x_unfold", "=", "torch", ".", "cat", "(", "[", "input_buffer", ",", "x", ".", "unsqueeze", "(", "3", ")", "]", ",", "dim", "=", "3", ")", "\n", "if", "self", ".", "kernel_size", ">", "1", ":", "\n", "                ", "self", ".", "_set_input_buffer", "(", "\n", "incremental_state", ",", "x_unfold", "[", ":", ",", ":", ",", ":", ",", "-", "self", ".", "kernel_size", "+", "1", ":", "]", "\n", ")", "\n", "", "x_unfold", "=", "x_unfold", ".", "view", "(", "T", "*", "B", "*", "H", ",", "R", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "# unfold the input: T x B x C --> T' x B x C x K", "\n", "            ", "x_unfold", "=", "unfold1d", "(", "x", ",", "self", ".", "kernel_size", ",", "self", ".", "padding_l", ",", "0", ")", "\n", "x_unfold", "=", "x_unfold", ".", "view", "(", "T", "*", "B", "*", "H", ",", "R", ",", "K", ")", "\n", "\n", "", "if", "self", ".", "weight_softmax", ":", "\n", "            ", "weight", "=", "utils", ".", "softmax", "(", "weight", ",", "dim", "=", "1", ",", "onnx_trace", "=", "self", ".", "onnx_trace", ")", ".", "type_as", "(", "\n", "weight", "\n", ")", "\n", "\n", "", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "weight", "=", "weight", "[", ":", ",", "-", "x_unfold", ".", "size", "(", "2", ")", ":", "]", "\n", "K", "=", "weight", ".", "size", "(", "1", ")", "\n", "\n", "", "weight", "=", "(", "\n", "weight", ".", "view", "(", "1", ",", "H", ",", "K", ")", ".", "expand", "(", "T", "*", "B", ",", "H", ",", "K", ")", ".", "contiguous", "(", ")", ".", "view", "(", "T", "*", "B", "*", "H", ",", "K", ",", "1", ")", "\n", ")", "\n", "\n", "weight", "=", "self", ".", "weight_dropout_module", "(", "weight", ")", "\n", "output", "=", "torch", ".", "bmm", "(", "x_unfold", ",", "weight", ")", "# T*B*H x R x 1", "\n", "output", "=", "output", ".", "view", "(", "T", ",", "B", ",", "C", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.lightweight_convolution.LightweightConv1dTBC._forward_expanded": [[250, 284], ["x.view().transpose.view().transpose.size", "lightweight_convolution.LightweightConv1dTBC.weight.view", "weight.narrow.narrow.view().expand().contiguous", "weight.narrow.narrow.view().transpose", "x.view().transpose.view().transpose.view().transpose", "weight.narrow.narrow.new_zeros", "lightweight_convolution.LightweightConv1dTBC.as_strided().copy_", "lightweight_convolution.LightweightConv1dTBC.narrow", "lightweight_convolution.LightweightConv1dTBC.weight_dropout_module", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "output.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "fairseq.utils.softmax().type_as", "weight.narrow.narrow.narrow", "weight.narrow.narrow.view().expand", "weight.narrow.narrow.view", "x.view().transpose.view().transpose.view", "lightweight_convolution.LightweightConv1dTBC.as_strided", "output.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "fairseq.utils.softmax", "weight.narrow.narrow.view", "output.transpose().contiguous().view.transpose().contiguous().view.transpose"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax"], ["", "def", "_forward_expanded", "(", "self", ",", "x", ",", "incremental_state", ")", ":", "\n", "        ", "\"\"\"Turn the convolution filters into band matrices and do matrix multiplication.\n        This is faster when the sequence is short, but less memory efficient.\n        This is not used in the decoder during inference.\n        \"\"\"", "\n", "T", ",", "B", ",", "C", "=", "x", ".", "size", "(", ")", "\n", "K", ",", "H", "=", "self", ".", "kernel_size", ",", "self", ".", "num_heads", "\n", "R", "=", "C", "//", "H", "\n", "assert", "R", "*", "H", "==", "C", "==", "self", ".", "input_size", "\n", "\n", "weight", "=", "self", ".", "weight", ".", "view", "(", "H", ",", "K", ")", "\n", "if", "self", ".", "weight_softmax", ":", "\n", "            ", "weight", "=", "utils", ".", "softmax", "(", "weight", ",", "dim", "=", "1", ",", "onnx_trace", "=", "self", ".", "onnx_trace", ")", ".", "type_as", "(", "\n", "weight", "\n", ")", "\n", "", "weight", "=", "weight", ".", "view", "(", "1", ",", "H", ",", "K", ")", ".", "expand", "(", "T", "*", "B", ",", "H", ",", "K", ")", ".", "contiguous", "(", ")", "\n", "weight", "=", "weight", ".", "view", "(", "T", ",", "B", "*", "H", ",", "K", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "x", "=", "x", ".", "view", "(", "T", ",", "B", "*", "H", ",", "R", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "P", "=", "self", ".", "padding_l", "\n", "if", "K", ">", "T", "and", "P", "==", "K", "-", "1", ":", "\n", "            ", "weight", "=", "weight", ".", "narrow", "(", "2", ",", "K", "-", "T", ",", "T", ")", "\n", "K", ",", "P", "=", "T", ",", "T", "-", "1", "\n", "# turn the convolution filters into band matrices", "\n", "", "weight_expanded", "=", "weight", ".", "new_zeros", "(", "B", "*", "H", ",", "T", ",", "T", "+", "K", "-", "1", ",", "requires_grad", "=", "False", ")", "\n", "weight_expanded", ".", "as_strided", "(", "(", "B", "*", "H", ",", "T", ",", "K", ")", ",", "(", "T", "*", "(", "T", "+", "K", "-", "1", ")", ",", "T", "+", "K", ",", "1", ")", ")", ".", "copy_", "(", "\n", "weight", "\n", ")", "\n", "weight_expanded", "=", "weight_expanded", ".", "narrow", "(", "2", ",", "P", ",", "T", ")", "\n", "weight_expanded", "=", "self", ".", "weight_dropout_module", "(", "weight_expanded", ")", "\n", "\n", "output", "=", "torch", ".", "bmm", "(", "weight_expanded", ",", "x", ")", "\n", "output", "=", "output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "T", ",", "B", ",", "C", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.lightweight_convolution.LightweightConv1dTBC.reorder_incremental_state": [[285, 290], ["lightweight_convolution.LightweightConv1dTBC._get_input_buffer", "input_buffer.index_select.index_select.index_select", "lightweight_convolution.LightweightConv1dTBC._set_input_buffer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer"], ["", "def", "reorder_incremental_state", "(", "self", ",", "incremental_state", ",", "new_order", ")", ":", "\n", "        ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "not", "None", ":", "\n", "            ", "input_buffer", "=", "input_buffer", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.lightweight_convolution.LightweightConv1dTBC._get_input_buffer": [[291, 293], ["fairseq.utils.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_incremental_state"], ["", "", "def", "_get_input_buffer", "(", "self", ",", "incremental_state", ")", ":", "\n", "        ", "return", "utils", ".", "get_incremental_state", "(", "self", ",", "incremental_state", ",", "\"input_buffer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.lightweight_convolution.LightweightConv1dTBC._set_input_buffer": [[294, 297], ["fairseq.utils.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_incremental_state"], ["", "def", "_set_input_buffer", "(", "self", ",", "incremental_state", ",", "new_buffer", ")", ":", "\n", "        ", "return", "utils", ".", "set_incremental_state", "(", "\n", "self", ",", "incremental_state", ",", "\"input_buffer\"", ",", "new_buffer", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.lightweight_convolution.LightweightConv1dTBC.extra_repr": [[299, 311], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "s", "=", "\"{}, kernel_size={}, padding_l={}, num_heads={}, weight_softmax={}, bias={}\"", ".", "format", "(", "\n", "self", ".", "input_size", ",", "\n", "self", ".", "kernel_size", ",", "\n", "self", ".", "padding_l", ",", "\n", "self", ".", "num_heads", ",", "\n", "self", ".", "weight_softmax", ",", "\n", "self", ".", "bias", "is", "not", "None", ",", "\n", ")", "\n", "if", "self", ".", "weight_dropout_module", ".", "p", ">", "0.0", ":", "\n", "            ", "s", "+=", "\", weight_dropout={}\"", ".", "format", "(", "self", ".", "weight_dropout_module", ".", "p", ")", "\n", "", "return", "s", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.lightweight_convolution.LightweightConv": [[15, 47], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "lightweight_convolution.LightweightConv1dTBC", "LightconvLayer", "print"], "function", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print"], ["def", "LightweightConv", "(", "\n", "input_size", ",", "\n", "kernel_size", "=", "1", ",", "\n", "padding_l", "=", "None", ",", "\n", "num_heads", "=", "1", ",", "\n", "weight_dropout", "=", "0.0", ",", "\n", "weight_softmax", "=", "False", ",", "\n", "bias", "=", "False", ",", "\n", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "fairseq", ".", "modules", ".", "lightconv_layer", "import", "LightconvLayer", "\n", "\n", "return", "LightconvLayer", "(", "\n", "input_size", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "padding_l", "=", "padding_l", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "weight_dropout", "=", "weight_dropout", ",", "\n", "weight_softmax", "=", "weight_softmax", ",", "\n", "bias", "=", "bias", ",", "\n", ")", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "            ", "print", "(", "e", ")", "\n", "", "", "return", "LightweightConv1dTBC", "(", "\n", "input_size", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "padding_l", "=", "padding_l", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "weight_dropout", "=", "weight_dropout", ",", "\n", "weight_softmax", "=", "weight_softmax", ",", "\n", "bias", "=", "bias", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.fairseq_dropout.FairseqDropout.__init__": [[17, 22], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "p", ",", "module_name", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "p", "=", "p", "\n", "self", ".", "module_name", "=", "module_name", "\n", "self", ".", "apply_during_inference", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.fairseq_dropout.FairseqDropout.forward": [[23, 28], ["torch.dropout", "torch.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "inplace", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "training", "or", "self", ".", "apply_during_inference", ":", "\n", "            ", "return", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "p", ",", "training", "=", "True", ",", "inplace", "=", "inplace", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.fairseq_dropout.FairseqDropout.make_generation_fast_": [[29, 52], ["logger.warning", "logger.info", "logger.info"], "methods", ["None"], ["", "", "def", "make_generation_fast_", "(", "\n", "self", ",", "\n", "name", ":", "str", ",", "\n", "retain_dropout", ":", "bool", "=", "False", ",", "\n", "retain_dropout_modules", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "if", "retain_dropout", ":", "\n", "            ", "if", "retain_dropout_modules", "is", "not", "None", "and", "self", ".", "module_name", "is", "None", ":", "\n", "                ", "logger", ".", "warning", "(", "\n", "\"Cannot enable dropout during inference for module {} \"", "\n", "\"because module_name was not set\"", ".", "format", "(", "name", ")", "\n", ")", "\n", "", "elif", "(", "\n", "retain_dropout_modules", "is", "None", "# if None, apply to all modules", "\n", "or", "self", ".", "module_name", "in", "retain_dropout_modules", "\n", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"Enabling dropout during inference for module: {}\"", ".", "format", "(", "name", ")", "\n", ")", "\n", "self", ".", "apply_during_inference", "=", "True", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"Disabling dropout for module: {}\"", ".", "format", "(", "name", ")", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.scalar_bias.ScalarBias.forward": [[16, 24], ["list", "input.new().fill_", "input.new().fill_.narrow().copy_", "input.size", "input.new", "input.new().fill_.narrow"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ",", "dim", ",", "bias_init", ")", ":", "\n", "        ", "size", "=", "list", "(", "input", ".", "size", "(", ")", ")", "\n", "size", "[", "dim", "]", "+=", "1", "\n", "output", "=", "input", ".", "new", "(", "*", "size", ")", ".", "fill_", "(", "bias_init", ")", "\n", "output", ".", "narrow", "(", "dim", ",", "1", ",", "size", "[", "dim", "]", "-", "1", ")", ".", "copy_", "(", "input", ")", "\n", "ctx", ".", "dim", "=", "dim", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.scalar_bias.ScalarBias.backward": [[25, 28], ["grad.narrow", "grad.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad", ")", ":", "\n", "        ", "return", "grad", ".", "narrow", "(", "ctx", ".", "dim", ",", "1", ",", "grad", ".", "size", "(", "ctx", ".", "dim", ")", "-", "1", ")", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.scalar_bias.scalar_bias": [[30, 32], ["ScalarBias.apply"], "function", ["None"], ["", "", "def", "scalar_bias", "(", "input", ",", "dim", ",", "bias_init", "=", "0", ")", ":", "\n", "    ", "return", "ScalarBias", ".", "apply", "(", "input", ",", "dim", ",", "bias_init", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.linearized_convolution.LinearizedConvolution.__init__": [[24, 28], ["conv_tbc.ConvTBC.__init__", "linearized_convolution.LinearizedConvolution.register_backward_hook"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "**", "kwargs", ")", "\n", "self", ".", "_linearized_weight", "=", "None", "\n", "self", ".", "register_backward_hook", "(", "self", ".", "_clear_linearized_weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.linearized_convolution.LinearizedConvolution.state_dict": [[29, 35], ["conv_tbc.ConvTBC.state_dict"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.state_dict"], ["", "def", "state_dict", "(", "self", ",", "destination", "=", "None", ",", "prefix", "=", "\"\"", ",", "keep_vars", "=", "False", ")", ":", "\n", "        ", "state", "=", "ConvTBC", ".", "state_dict", "(", "self", ",", "destination", ",", "prefix", ",", "keep_vars", "=", "keep_vars", ")", "\n", "# don't store redundant _linearized_weight in checkpoints", "\n", "if", "prefix", "+", "\"_linearized_weight\"", "in", "state", ":", "\n", "            ", "del", "state", "[", "prefix", "+", "\"_linearized_weight\"", "]", "\n", "", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.linearized_convolution.LinearizedConvolution.upgrade_state_dict_named": [[36, 40], ["None"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "prefix", "=", "name", "+", "\".\"", "if", "name", "!=", "\"\"", "else", "\"\"", "\n", "if", "prefix", "+", "\"_linearized_weight\"", "in", "state_dict", ":", "\n", "            ", "del", "state_dict", "[", "prefix", "+", "\"_linearized_weight\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.linearized_convolution.LinearizedConvolution.forward": [[41, 78], ["linearized_convolution.LinearizedConvolution._get_linearized_weight", "input.size", "torch.linear.view", "super().forward", "linearized_convolution.LinearizedConvolution._get_input_buffer", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.linear", "torch.linear", "input.new().zero_", "linearized_convolution.LinearizedConvolution._set_input_buffer", "input_buffer[].clone", "input.view", "input.new", "input.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.linearized_convolution.LinearizedConvolution._get_linearized_weight", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.forward", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "incremental_state", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            incremental_state: Used to buffer signal; if not None, then input is\n                expected to contain a single frame. If the input order changes\n                between time steps, call reorder_incremental_state.\n        Input:\n            Time x Batch x Channel during training\n            Batch x Time x Channel during inference\n        \"\"\"", "\n", "if", "incremental_state", "is", "None", ":", "\n", "            ", "output", "=", "super", "(", ")", ".", "forward", "(", "input", ")", "\n", "if", "self", ".", "kernel_size", "[", "0", "]", ">", "1", "and", "self", ".", "padding", "[", "0", "]", ">", "0", ":", "\n", "# remove future timesteps added by padding", "\n", "                ", "output", "=", "output", "[", ":", "-", "self", ".", "padding", "[", "0", "]", ",", ":", ",", ":", "]", "\n", "", "return", "output", "\n", "\n", "# reshape weight", "\n", "", "weight", "=", "self", ".", "_get_linearized_weight", "(", ")", "\n", "kw", "=", "self", ".", "kernel_size", "[", "0", "]", "\n", "\n", "bsz", "=", "input", ".", "size", "(", "0", ")", "# input: bsz x len x dim", "\n", "if", "kw", ">", "1", ":", "\n", "            ", "input", "=", "input", ".", "data", "\n", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "None", ":", "\n", "                ", "input_buffer", "=", "input", ".", "new", "(", "bsz", ",", "kw", ",", "input", ".", "size", "(", "2", ")", ")", ".", "zero_", "(", ")", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "", "else", ":", "\n", "# shift buffer", "\n", "                ", "input_buffer", "[", ":", ",", ":", "-", "1", ",", ":", "]", "=", "input_buffer", "[", ":", ",", "1", ":", ",", ":", "]", ".", "clone", "(", ")", "\n", "# append next input", "\n", "", "input_buffer", "[", ":", ",", "-", "1", ",", ":", "]", "=", "input", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "input", "=", "input_buffer", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "output", "=", "F", ".", "linear", "(", "input", ".", "view", "(", "bsz", ",", "-", "1", ")", ",", "weight", ",", "self", ".", "bias", ")", "\n", "", "return", "output", ".", "view", "(", "bsz", ",", "1", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.linearized_convolution.LinearizedConvolution.reorder_incremental_state": [[79, 84], ["linearized_convolution.LinearizedConvolution._get_input_buffer", "input_buffer.index_select.index_select.index_select", "linearized_convolution.LinearizedConvolution._set_input_buffer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer"], ["", "def", "reorder_incremental_state", "(", "self", ",", "incremental_state", ",", "new_order", ")", ":", "\n", "        ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "not", "None", ":", "\n", "            ", "input_buffer", "=", "input_buffer", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.linearized_convolution.LinearizedConvolution._get_input_buffer": [[85, 87], ["fairseq.utils.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_incremental_state"], ["", "", "def", "_get_input_buffer", "(", "self", ",", "incremental_state", ")", ":", "\n", "        ", "return", "utils", ".", "get_incremental_state", "(", "self", ",", "incremental_state", ",", "\"input_buffer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.linearized_convolution.LinearizedConvolution._set_input_buffer": [[88, 91], ["fairseq.utils.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_incremental_state"], ["", "def", "_set_input_buffer", "(", "self", ",", "incremental_state", ",", "new_buffer", ")", ":", "\n", "        ", "return", "utils", ".", "set_incremental_state", "(", "\n", "self", ",", "incremental_state", ",", "\"input_buffer\"", ",", "new_buffer", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.linearized_convolution.LinearizedConvolution._get_linearized_weight": [[93, 102], ["linearized_convolution.LinearizedConvolution.weight.transpose().transpose().contiguous", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "linearized_convolution.LinearizedConvolution.size", "linearized_convolution.LinearizedConvolution.view", "linearized_convolution.LinearizedConvolution.weight.transpose().transpose", "linearized_convolution.LinearizedConvolution.weight.transpose"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "_get_linearized_weight", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_linearized_weight", "is", "None", ":", "\n", "            ", "kw", "=", "self", ".", "kernel_size", "[", "0", "]", "\n", "weight", "=", "self", ".", "weight", ".", "transpose", "(", "2", ",", "1", ")", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "assert", "weight", ".", "size", "(", ")", "==", "(", "self", ".", "out_channels", ",", "kw", ",", "self", ".", "in_channels", ")", "\n", "self", ".", "_linearized_weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "\n", "weight", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", "\n", ")", "\n", "", "return", "self", ".", "_linearized_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.linearized_convolution.LinearizedConvolution._clear_linearized_weight": [[103, 105], ["None"], "methods", ["None"], ["", "def", "_clear_linearized_weight", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "self", ".", "_linearized_weight", "=", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise": [[10, 108], ["isinstance", "module.register_forward_pre_hook", "mask.unsqueeze().unsqueeze().repeat.to", "module.weight.size", "weight.size", "weight.size", "torch.zeros", "torch.zeros", "mask.unsqueeze().unsqueeze().repeat.bernoulli_", "mask.unsqueeze().unsqueeze().repeat.repeat_interleave().view", "weight.masked_fill", "torch.zeros", "torch.zeros", "mask.unsqueeze().unsqueeze().repeat.bernoulli_", "mask.unsqueeze().unsqueeze().repeat.repeat_interleave().view", "torch.zeros", "torch.zeros", "mask.unsqueeze().unsqueeze().repeat.bernoulli_", "mask.unsqueeze().unsqueeze().repeat.unsqueeze().unsqueeze().repeat", "mask.unsqueeze().unsqueeze().repeat.repeat_interleave", "int", "weight.size", "weight.size", "mask.unsqueeze().unsqueeze().repeat.repeat_interleave", "mask.unsqueeze().unsqueeze().repeat.unsqueeze().unsqueeze", "mask.unsqueeze().unsqueeze().repeat.unsqueeze"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["def", "quant_noise", "(", "module", ",", "p", ",", "block_size", ")", ":", "\n", "    ", "\"\"\"\n    Wraps modules and applies quantization noise to the weights for\n    subsequent quantization with Iterative Product Quantization as\n    described in \"Training with Quantization Noise for Extreme Model Compression\"\n\n    Args:\n        - module: nn.Module\n        - p: amount of Quantization Noise\n        - block_size: size of the blocks for subsequent quantization with iPQ\n\n    Remarks:\n        - Module weights must have the right sizes wrt the block size\n        - Only Linear, Embedding and Conv2d modules are supported for the moment\n        - For more detail on how to quantize by blocks with convolutional weights,\n          see \"And the Bit Goes Down: Revisiting the Quantization of Neural Networks\"\n        - We implement the simplest form of noise here as stated in the paper\n          which consists in randomly dropping blocks\n    \"\"\"", "\n", "\n", "# if no quantization noise, don't register hook", "\n", "if", "p", "<=", "0", ":", "\n", "        ", "return", "module", "\n", "\n", "# supported modules", "\n", "", "assert", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ",", "nn", ".", "Conv2d", ")", ")", "\n", "\n", "# test whether module.weight has the right sizes wrt block_size", "\n", "is_conv", "=", "module", ".", "weight", ".", "ndim", "==", "4", "\n", "\n", "# 2D matrix", "\n", "if", "not", "is_conv", ":", "\n", "        ", "assert", "(", "\n", "module", ".", "weight", ".", "size", "(", "1", ")", "%", "block_size", "==", "0", "\n", ")", ",", "\"Input features must be a multiple of block sizes\"", "\n", "\n", "# 4D matrix", "\n", "", "else", ":", "\n", "# 1x1 convolutions", "\n", "        ", "if", "module", ".", "kernel_size", "==", "(", "1", ",", "1", ")", ":", "\n", "            ", "assert", "(", "\n", "module", ".", "in_channels", "%", "block_size", "==", "0", "\n", ")", ",", "\"Input channels must be a multiple of block sizes\"", "\n", "# regular convolutions", "\n", "", "else", ":", "\n", "            ", "k", "=", "module", ".", "kernel_size", "[", "0", "]", "*", "module", ".", "kernel_size", "[", "1", "]", "\n", "assert", "k", "%", "block_size", "==", "0", ",", "\"Kernel size must be a multiple of block size\"", "\n", "\n", "", "", "def", "_forward_pre_hook", "(", "mod", ",", "input", ")", ":", "\n", "# no noise for evaluation", "\n", "        ", "if", "mod", ".", "training", ":", "\n", "            ", "if", "not", "is_conv", ":", "\n", "# gather weight and sizes", "\n", "                ", "weight", "=", "mod", ".", "weight", "\n", "in_features", "=", "weight", ".", "size", "(", "1", ")", "\n", "out_features", "=", "weight", ".", "size", "(", "0", ")", "\n", "\n", "# split weight matrix into blocks and randomly drop selected blocks", "\n", "mask", "=", "torch", ".", "zeros", "(", "\n", "in_features", "//", "block_size", "*", "out_features", ",", "device", "=", "weight", ".", "device", "\n", ")", "\n", "mask", ".", "bernoulli_", "(", "p", ")", "\n", "mask", "=", "mask", ".", "repeat_interleave", "(", "block_size", ",", "-", "1", ")", ".", "view", "(", "-", "1", ",", "in_features", ")", "\n", "\n", "", "else", ":", "\n", "# gather weight and sizes", "\n", "                ", "weight", "=", "mod", ".", "weight", "\n", "in_channels", "=", "mod", ".", "in_channels", "\n", "out_channels", "=", "mod", ".", "out_channels", "\n", "\n", "# split weight matrix into blocks and randomly drop selected blocks", "\n", "if", "mod", ".", "kernel_size", "==", "(", "1", ",", "1", ")", ":", "\n", "                    ", "mask", "=", "torch", ".", "zeros", "(", "\n", "int", "(", "in_channels", "//", "block_size", "*", "out_channels", ")", ",", "\n", "device", "=", "weight", ".", "device", ",", "\n", ")", "\n", "mask", ".", "bernoulli_", "(", "p", ")", "\n", "mask", "=", "mask", ".", "repeat_interleave", "(", "block_size", ",", "-", "1", ")", ".", "view", "(", "-", "1", ",", "in_channels", ")", "\n", "", "else", ":", "\n", "                    ", "mask", "=", "torch", ".", "zeros", "(", "\n", "weight", ".", "size", "(", "0", ")", ",", "weight", ".", "size", "(", "1", ")", ",", "device", "=", "weight", ".", "device", "\n", ")", "\n", "mask", ".", "bernoulli_", "(", "p", ")", "\n", "mask", "=", "(", "\n", "mask", ".", "unsqueeze", "(", "2", ")", "\n", ".", "unsqueeze", "(", "3", ")", "\n", ".", "repeat", "(", "1", ",", "1", ",", "mod", ".", "kernel_size", "[", "0", "]", ",", "mod", ".", "kernel_size", "[", "1", "]", ")", "\n", ")", "\n", "\n", "# scale weights and apply mask", "\n", "", "", "mask", "=", "mask", ".", "to", "(", "\n", "torch", ".", "bool", "\n", ")", "# x.bool() is not currently supported in TorchScript", "\n", "s", "=", "1", "/", "(", "1", "-", "p", ")", "\n", "mod", ".", "weight", ".", "data", "=", "s", "*", "weight", ".", "masked_fill", "(", "mask", ",", "0", ")", "\n", "\n", "", "", "module", ".", "register_forward_pre_hook", "(", "_forward_pre_hook", ")", "\n", "return", "module", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock.VGGBlock.__init__": [[60, 111], ["super().__init__", "vggblock._pair", "vggblock._pair", "vggblock._pair", "torch.ModuleList", "torch.ModuleList", "range", "tuple", "vggblock._pair", "torch.Conv2d", "torch.Conv2d", "vggblock.VGGBlock.layers.append", "vggblock.VGGBlock.layers.append", "torch.MaxPool2d", "torch.MaxPool2d", "vggblock.VGGBlock.layers.append", "vggblock.infer_conv_output_dim", "vggblock.infer_conv_output_dim", "vggblock.VGGBlock.layers.append", "torch.ReLU", "torch.ReLU", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock.infer_conv_output_dim", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock.infer_conv_output_dim", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "conv_kernel_size", ",", "\n", "pooling_kernel_size", ",", "\n", "num_conv_layers", ",", "\n", "input_dim", ",", "\n", "conv_stride", "=", "1", ",", "\n", "padding", "=", "None", ",", "\n", "layer_norm", "=", "False", ",", "\n", ")", ":", "\n", "        ", "assert", "(", "\n", "input_dim", "is", "not", "None", "\n", ")", ",", "\"Need input_dim for LayerNorm and infer_conv_output_dim\"", "\n", "super", "(", "VGGBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "conv_kernel_size", "=", "_pair", "(", "conv_kernel_size", ")", "\n", "self", ".", "pooling_kernel_size", "=", "_pair", "(", "pooling_kernel_size", ")", "\n", "self", ".", "num_conv_layers", "=", "num_conv_layers", "\n", "self", ".", "padding", "=", "(", "\n", "tuple", "(", "e", "//", "2", "for", "e", "in", "self", ".", "conv_kernel_size", ")", "\n", "if", "padding", "is", "None", "\n", "else", "_pair", "(", "padding", ")", "\n", ")", "\n", "self", ".", "conv_stride", "=", "_pair", "(", "conv_stride", ")", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "layer", "in", "range", "(", "num_conv_layers", ")", ":", "\n", "            ", "conv_op", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", "if", "layer", "==", "0", "else", "out_channels", ",", "\n", "out_channels", ",", "\n", "self", ".", "conv_kernel_size", ",", "\n", "stride", "=", "self", ".", "conv_stride", ",", "\n", "padding", "=", "self", ".", "padding", ",", "\n", ")", "\n", "self", ".", "layers", ".", "append", "(", "conv_op", ")", "\n", "if", "layer_norm", ":", "\n", "                ", "conv_output_dim", ",", "per_channel_dim", "=", "infer_conv_output_dim", "(", "\n", "conv_op", ",", "input_dim", ",", "in_channels", "if", "layer", "==", "0", "else", "out_channels", "\n", ")", "\n", "self", ".", "layers", ".", "append", "(", "nn", ".", "LayerNorm", "(", "per_channel_dim", ")", ")", "\n", "input_dim", "=", "per_channel_dim", "\n", "", "self", ".", "layers", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n", "", "if", "self", ".", "pooling_kernel_size", "is", "not", "None", ":", "\n", "            ", "pool_op", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "self", ".", "pooling_kernel_size", ",", "ceil_mode", "=", "True", ")", "\n", "self", ".", "layers", ".", "append", "(", "pool_op", ")", "\n", "self", ".", "total_output_dim", ",", "self", ".", "output_dim", "=", "infer_conv_output_dim", "(", "\n", "pool_op", ",", "input_dim", ",", "out_channels", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock.VGGBlock.forward": [[113, 117], ["enumerate"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "i", ",", "_", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "x", "=", "self", ".", "layers", "[", "i", "]", "(", "x", ")", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair": [[15, 20], ["isinstance", "tuple", "itertools.repeat", "len"], "function", ["None"], ["def", "_pair", "(", "v", ")", ":", "\n", "    ", "if", "isinstance", "(", "v", ",", "Iterable", ")", ":", "\n", "        ", "assert", "len", "(", "v", ")", "==", "2", ",", "\"len(v) != 2\"", "\n", "return", "v", "\n", "", "return", "tuple", "(", "repeat", "(", "v", ",", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock.infer_conv_output_dim": [[22, 36], ["torch.randn", "torch.randn", "conv_op", "x.transpose.transpose", "x.transpose.size", "x.transpose.size", "x.transpose.contiguous().view().size", "x.transpose.contiguous().view", "x.transpose.contiguous"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "infer_conv_output_dim", "(", "conv_op", ",", "input_dim", ",", "sample_inchannel", ")", ":", "\n", "    ", "sample_seq_len", "=", "200", "\n", "sample_bsz", "=", "10", "\n", "x", "=", "torch", ".", "randn", "(", "sample_bsz", ",", "sample_inchannel", ",", "sample_seq_len", ",", "input_dim", ")", "\n", "# N x C x H x W", "\n", "# N: sample_bsz, C: sample_inchannel, H: sample_seq_len, W: input_dim", "\n", "x", "=", "conv_op", "(", "x", ")", "\n", "# N x C x H x W", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# N x H x C x W", "\n", "bsz", ",", "seq", "=", "x", ".", "size", "(", ")", "[", ":", "2", "]", "\n", "per_channel_dim", "=", "x", ".", "size", "(", ")", "[", "3", "]", "\n", "# bsz: N, seq: H, CxW the rest", "\n", "return", "x", ".", "contiguous", "(", ")", ".", "view", "(", "bsz", ",", "seq", ",", "-", "1", ")", ".", "size", "(", "-", "1", ")", ",", "per_channel_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_sentence_encoder.TransformerSentenceEncoder.__init__": [[73, 193], ["torch.Module.__init__", "fairseq.modules.FairseqDropout", "transformer_sentence_encoder.TransformerSentenceEncoder.build_embedding", "transformer_sentence_encoder.TransformerSentenceEncoder.layers.extend", "range", "fairseq.modules.quant_noise.quant_noise", "torch.Embedding", "torch.Embedding", "fairseq.modules.PositionalEmbedding", "fairseq.modules.LayerDropModuleList", "torch.ModuleList", "torch.ModuleList", "fairseq.modules.LayerNorm", "transformer_sentence_encoder.TransformerSentenceEncoder.apply", "transformer_sentence_encoder.TransformerSentenceEncoder.__init__.freeze_module_params"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.build_embedding", "home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.PositionalEmbedding", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "\n", "self", ",", "\n", "padding_idx", ":", "int", ",", "\n", "vocab_size", ":", "int", ",", "\n", "num_encoder_layers", ":", "int", "=", "6", ",", "\n", "embedding_dim", ":", "int", "=", "768", ",", "\n", "ffn_embedding_dim", ":", "int", "=", "3072", ",", "\n", "num_attention_heads", ":", "int", "=", "8", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "attention_dropout", ":", "float", "=", "0.1", ",", "\n", "activation_dropout", ":", "float", "=", "0.1", ",", "\n", "layerdrop", ":", "float", "=", "0.0", ",", "\n", "max_seq_len", ":", "int", "=", "256", ",", "\n", "num_segments", ":", "int", "=", "2", ",", "\n", "use_position_embeddings", ":", "bool", "=", "True", ",", "\n", "offset_positions_by_padding", ":", "bool", "=", "True", ",", "\n", "encoder_normalize_before", ":", "bool", "=", "False", ",", "\n", "apply_bert_init", ":", "bool", "=", "False", ",", "\n", "activation_fn", ":", "str", "=", "\"relu\"", ",", "\n", "learned_pos_embedding", ":", "bool", "=", "True", ",", "\n", "embed_scale", ":", "float", "=", "None", ",", "\n", "freeze_embeddings", ":", "bool", "=", "False", ",", "\n", "n_trans_layers_to_freeze", ":", "int", "=", "0", ",", "\n", "export", ":", "bool", "=", "False", ",", "\n", "traceable", ":", "bool", "=", "False", ",", "\n", "q_noise", ":", "float", "=", "0.0", ",", "\n", "qn_block_size", ":", "int", "=", "8", ",", "\n", ")", "->", "None", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "layerdrop", "=", "layerdrop", "\n", "self", ".", "max_seq_len", "=", "max_seq_len", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "num_segments", "=", "num_segments", "\n", "self", ".", "use_position_embeddings", "=", "use_position_embeddings", "\n", "self", ".", "apply_bert_init", "=", "apply_bert_init", "\n", "self", ".", "learned_pos_embedding", "=", "learned_pos_embedding", "\n", "self", ".", "traceable", "=", "traceable", "\n", "self", ".", "tpu", "=", "False", "# whether we're on TPU", "\n", "\n", "self", ".", "embed_tokens", "=", "self", ".", "build_embedding", "(", "\n", "self", ".", "vocab_size", ",", "self", ".", "embedding_dim", ",", "self", ".", "padding_idx", "\n", ")", "\n", "self", ".", "embed_scale", "=", "embed_scale", "\n", "\n", "if", "q_noise", ">", "0", ":", "\n", "            ", "self", ".", "quant_noise", "=", "apply_quant_noise_", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "embedding_dim", ",", "self", ".", "embedding_dim", ",", "bias", "=", "False", ")", ",", "\n", "q_noise", ",", "\n", "qn_block_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "quant_noise", "=", "None", "\n", "\n", "", "self", ".", "segment_embeddings", "=", "(", "\n", "nn", ".", "Embedding", "(", "self", ".", "num_segments", ",", "self", ".", "embedding_dim", ",", "padding_idx", "=", "None", ")", "\n", "if", "self", ".", "num_segments", ">", "0", "\n", "else", "None", "\n", ")", "\n", "\n", "self", ".", "embed_positions", "=", "(", "\n", "PositionalEmbedding", "(", "\n", "self", ".", "max_seq_len", ",", "\n", "self", ".", "embedding_dim", ",", "\n", "padding_idx", "=", "(", "self", ".", "padding_idx", "if", "offset_positions_by_padding", "else", "None", ")", ",", "\n", "learned", "=", "self", ".", "learned_pos_embedding", ",", "\n", ")", "\n", "if", "self", ".", "use_position_embeddings", "\n", "else", "None", "\n", ")", "\n", "\n", "if", "self", ".", "layerdrop", ">", "0.0", ":", "\n", "            ", "self", ".", "layers", "=", "LayerDropModuleList", "(", "p", "=", "self", ".", "layerdrop", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "", "self", ".", "layers", ".", "extend", "(", "\n", "[", "\n", "self", ".", "build_transformer_sentence_encoder_layer", "(", "\n", "embedding_dim", "=", "self", ".", "embedding_dim", ",", "\n", "ffn_embedding_dim", "=", "ffn_embedding_dim", ",", "\n", "num_attention_heads", "=", "num_attention_heads", ",", "\n", "dropout", "=", "self", ".", "dropout_module", ".", "p", ",", "\n", "attention_dropout", "=", "attention_dropout", ",", "\n", "activation_dropout", "=", "activation_dropout", ",", "\n", "activation_fn", "=", "activation_fn", ",", "\n", "export", "=", "export", ",", "\n", "q_noise", "=", "q_noise", ",", "\n", "qn_block_size", "=", "qn_block_size", ",", "\n", ")", "\n", "for", "_", "in", "range", "(", "num_encoder_layers", ")", "\n", "]", "\n", ")", "\n", "\n", "if", "encoder_normalize_before", ":", "\n", "            ", "self", ".", "emb_layer_norm", "=", "LayerNorm", "(", "self", ".", "embedding_dim", ",", "export", "=", "export", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "emb_layer_norm", "=", "None", "\n", "\n", "# Apply initialization of model params after building the model", "\n", "", "if", "self", ".", "apply_bert_init", ":", "\n", "            ", "self", ".", "apply", "(", "init_bert_params", ")", "\n", "\n", "", "def", "freeze_module_params", "(", "m", ")", ":", "\n", "            ", "if", "m", "is", "not", "None", ":", "\n", "                ", "for", "p", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                    ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "", "if", "freeze_embeddings", ":", "\n", "            ", "freeze_module_params", "(", "self", ".", "embed_tokens", ")", "\n", "freeze_module_params", "(", "self", ".", "segment_embeddings", ")", "\n", "freeze_module_params", "(", "self", ".", "embed_positions", ")", "\n", "freeze_module_params", "(", "self", ".", "emb_layer_norm", ")", "\n", "\n", "", "for", "layer", "in", "range", "(", "n_trans_layers_to_freeze", ")", ":", "\n", "            ", "freeze_module_params", "(", "self", ".", "layers", "[", "layer", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_sentence_encoder.TransformerSentenceEncoder.build_embedding": [[194, 196], ["torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding"], ["", "", "def", "build_embedding", "(", "self", ",", "vocab_size", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "        ", "return", "nn", ".", "Embedding", "(", "vocab_size", ",", "embedding_dim", ",", "padding_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_sentence_encoder.TransformerSentenceEncoder.build_transformer_sentence_encoder_layer": [[197, 221], ["fairseq.modules.TransformerSentenceEncoderLayer"], "methods", ["None"], ["", "def", "build_transformer_sentence_encoder_layer", "(", "\n", "self", ",", "\n", "embedding_dim", ",", "\n", "ffn_embedding_dim", ",", "\n", "num_attention_heads", ",", "\n", "dropout", ",", "\n", "attention_dropout", ",", "\n", "activation_dropout", ",", "\n", "activation_fn", ",", "\n", "export", ",", "\n", "q_noise", ",", "\n", "qn_block_size", ",", "\n", ")", ":", "\n", "        ", "return", "TransformerSentenceEncoderLayer", "(", "\n", "embedding_dim", "=", "embedding_dim", ",", "\n", "ffn_embedding_dim", "=", "ffn_embedding_dim", ",", "\n", "num_attention_heads", "=", "num_attention_heads", ",", "\n", "dropout", "=", "dropout", ",", "\n", "attention_dropout", "=", "attention_dropout", ",", "\n", "activation_dropout", "=", "activation_dropout", ",", "\n", "activation_fn", "=", "activation_fn", ",", "\n", "export", "=", "export", ",", "\n", "q_noise", "=", "q_noise", ",", "\n", "qn_block_size", "=", "qn_block_size", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_sentence_encoder.TransformerSentenceEncoder.prepare_for_tpu_": [[223, 225], ["None"], "methods", ["None"], ["", "def", "prepare_for_tpu_", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "tpu", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_sentence_encoder.TransformerSentenceEncoder.forward": [[226, 287], ["tokens.eq", "transformer_sentence_encoder.TransformerSentenceEncoder.dropout_module", "transformer_sentence_encoder.TransformerSentenceEncoder.transpose", "transformer_sentence_encoder.TransformerSentenceEncoder.embed_tokens", "transformer_sentence_encoder.TransformerSentenceEncoder.quant_noise", "transformer_sentence_encoder.TransformerSentenceEncoder.emb_layer_norm", "inner_states.append", "layer", "tokens.eq.any", "transformer_sentence_encoder.TransformerSentenceEncoder.embed_positions", "transformer_sentence_encoder.TransformerSentenceEncoder.segment_embeddings", "inner_states.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "tokens.eq.unsqueeze().type_as", "tokens.eq.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "tokens", ":", "torch", ".", "Tensor", ",", "\n", "segment_labels", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "last_state_only", ":", "bool", "=", "False", ",", "\n", "positions", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "token_embeddings", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "\n", "# compute padding mask. This is needed for multi-head attention", "\n", "        ", "padding_mask", "=", "tokens", ".", "eq", "(", "self", ".", "padding_idx", ")", "\n", "if", "not", "self", ".", "traceable", "and", "not", "self", ".", "tpu", "and", "not", "padding_mask", ".", "any", "(", ")", ":", "\n", "            ", "padding_mask", "=", "None", "\n", "\n", "", "if", "token_embeddings", "is", "not", "None", ":", "\n", "            ", "x", "=", "token_embeddings", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "embed_tokens", "(", "tokens", ")", "\n", "\n", "", "if", "self", ".", "embed_scale", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "*", "self", ".", "embed_scale", "\n", "\n", "", "if", "self", ".", "embed_positions", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "embed_positions", "(", "tokens", ",", "positions", "=", "positions", ")", "\n", "\n", "", "if", "self", ".", "segment_embeddings", "is", "not", "None", "and", "segment_labels", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "segment_embeddings", "(", "segment_labels", ")", "\n", "\n", "", "if", "self", ".", "quant_noise", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "quant_noise", "(", "x", ")", "\n", "\n", "", "if", "self", ".", "emb_layer_norm", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "emb_layer_norm", "(", "x", ")", "\n", "\n", "", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "\n", "# account for padding while computing the representation", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "*", "(", "1", "-", "padding_mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "type_as", "(", "x", ")", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "inner_states", "=", "[", "]", "\n", "if", "not", "last_state_only", ":", "\n", "            ", "inner_states", ".", "append", "(", "x", ")", "\n", "\n", "", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "x", ",", "_", "=", "layer", "(", "x", ",", "self_attn_padding_mask", "=", "padding_mask", ")", "\n", "if", "not", "last_state_only", ":", "\n", "                ", "inner_states", ".", "append", "(", "x", ")", "\n", "\n", "", "", "sentence_rep", "=", "x", "[", "0", ",", ":", ",", ":", "]", "\n", "\n", "if", "last_state_only", ":", "\n", "            ", "inner_states", "=", "[", "x", "]", "\n", "\n", "", "if", "self", ".", "traceable", ":", "\n", "            ", "return", "torch", ".", "stack", "(", "inner_states", ")", ",", "sentence_rep", "\n", "", "else", ":", "\n", "            ", "return", "inner_states", ",", "sentence_rep", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_sentence_encoder.init_bert_params": [[21, 47], ["isinstance", "isinstance", "isinstance", "module.weight.data.normal_", "module.weight.data.normal_", "module.q_proj.weight.data.normal_", "module.k_proj.weight.data.normal_", "module.v_proj.weight.data.normal_", "module.bias.data.zero_", "module.weight.data[].zero_"], "function", ["None"], ["def", "init_bert_params", "(", "module", ")", ":", "\n", "    ", "\"\"\"\n    Initialize the weights specific to the BERT Model.\n    This overrides the default initializations depending on the specified arguments.\n        1. If normal_init_linear_weights is set then weights of linear\n           layer will be initialized using the normal distribution and\n           bais will be set to the specified value.\n        2. If normal_init_embed_weights is set then weights of embedding\n           layer will be initialized using the normal distribution.\n        3. If normal_init_proj_weights is set then weights of\n           in_project_weight for MultiHeadAttention initialized using\n           the normal distribution (to be validated).\n    \"\"\"", "\n", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ":", "\n", "        ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "if", "module", ".", "padding_idx", "is", "not", "None", ":", "\n", "            ", "module", ".", "weight", ".", "data", "[", "module", ".", "padding_idx", "]", ".", "zero_", "(", ")", "\n", "", "", "if", "isinstance", "(", "module", ",", "MultiheadAttention", ")", ":", "\n", "        ", "module", ".", "q_proj", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "module", ".", "k_proj", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "module", ".", "v_proj", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.downsampled_multihead_attention.SingleHeadAttention.__init__": [[21, 73], ["torch.Module.__init__", "fairseq.modules.fairseq_dropout.FairseqDropout", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "k_layers.append", "v_layers.append", "k_layers.append", "downsampled_multihead_attention.GatedLinear", "v_layers.append", "k_layers.append", "downsampled_multihead_attention.Linear", "v_layers.append", "downsampled_multihead_attention.Linear", "downsampled_multihead_attention.Linear", "downsampled_multihead_attention.Downsample", "downsampled_multihead_attention.Downsample", "downsampled_multihead_attention.GatedLinear", "downsampled_multihead_attention.GatedLinear", "downsampled_multihead_attention.Linear", "downsampled_multihead_attention.Linear"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.modules.downsampled_multihead_attention.GatedLinear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.modules.downsampled_multihead_attention.GatedLinear", "home.repos.pwc.inspect_result.reneeye_const.modules.downsampled_multihead_attention.GatedLinear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["def", "__init__", "(", "\n", "self", ",", "\n", "out_channels", ",", "\n", "embed_dim", ",", "\n", "head_dim", ",", "\n", "head_index", ",", "\n", "dropout", "=", "0.0", ",", "\n", "bias", "=", "True", ",", "\n", "project_input", "=", "True", ",", "\n", "gated", "=", "False", ",", "\n", "downsample", "=", "False", ",", "\n", "num_heads", "=", "1", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "head_index", "=", "head_index", "\n", "self", ".", "head_dim", "=", "head_dim", "\n", "self", ".", "project_input", "=", "project_input", "\n", "self", ".", "gated", "=", "gated", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "projection", "=", "None", "\n", "\n", "k_layers", "=", "[", "]", "\n", "v_layers", "=", "[", "]", "\n", "if", "self", ".", "downsample", ":", "\n", "            ", "k_layers", ".", "append", "(", "Downsample", "(", "self", ".", "head_index", ")", ")", "\n", "v_layers", ".", "append", "(", "Downsample", "(", "self", ".", "head_index", ")", ")", "\n", "out_proj_size", "=", "self", ".", "head_dim", "\n", "", "else", ":", "\n", "            ", "out_proj_size", "=", "self", ".", "head_dim", "*", "self", ".", "num_heads", "\n", "", "if", "self", ".", "gated", ":", "\n", "            ", "k_layers", ".", "append", "(", "GatedLinear", "(", "self", ".", "embed_dim", ",", "out_proj_size", ",", "bias", "=", "bias", ")", ")", "\n", "self", ".", "in_proj_q", "=", "GatedLinear", "(", "self", ".", "embed_dim", ",", "out_proj_size", ",", "bias", "=", "bias", ")", "\n", "v_layers", ".", "append", "(", "GatedLinear", "(", "self", ".", "embed_dim", ",", "out_proj_size", ",", "bias", "=", "bias", ")", ")", "\n", "", "else", ":", "\n", "            ", "k_layers", ".", "append", "(", "Linear", "(", "self", ".", "embed_dim", ",", "out_proj_size", ",", "bias", "=", "bias", ")", ")", "\n", "self", ".", "in_proj_q", "=", "Linear", "(", "self", ".", "embed_dim", ",", "out_proj_size", ",", "bias", "=", "bias", ")", "\n", "v_layers", ".", "append", "(", "Linear", "(", "self", ".", "embed_dim", ",", "out_proj_size", ",", "bias", "=", "bias", ")", ")", "\n", "\n", "", "self", ".", "in_proj_k", "=", "nn", ".", "Sequential", "(", "*", "k_layers", ")", "\n", "self", ".", "in_proj_v", "=", "nn", ".", "Sequential", "(", "*", "v_layers", ")", "\n", "\n", "if", "self", ".", "downsample", ":", "\n", "            ", "self", ".", "out_proj", "=", "Linear", "(", "out_proj_size", ",", "self", ".", "head_dim", ",", "bias", "=", "bias", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "out_proj", "=", "Linear", "(", "out_proj_size", ",", "out_channels", ",", "bias", "=", "bias", ")", "\n", "\n", "", "self", ".", "scaling", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.downsampled_multihead_attention.SingleHeadAttention.forward": [[74, 168], ["key.size", "query.size", "q.view.view.transpose", "k.view.view.transpose", "fairseq.modules.scalar_bias.scalar_bias.transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.softmax", "downsampled_multihead_attention.SingleHeadAttention.dropout_module", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "downsampled_multihead_attention.SingleHeadAttention.out_proj", "list", "key.size", "value.size", "downsampled_multihead_attention.SingleHeadAttention.in_proj_q", "downsampled_multihead_attention.SingleHeadAttention.in_proj_k", "downsampled_multihead_attention.SingleHeadAttention.in_proj_v", "q.view.view.view", "k.view.view.view", "fairseq.modules.scalar_bias.scalar_bias.view", "k.view.view.transpose", "[].unsqueeze", "[].unsqueeze", "fairseq.modules.scalar_bias.scalar_bias", "fairseq.modules.scalar_bias.scalar_bias", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "query.size", "key_padding_mask.size", "key_padding_mask.size", "k.view.view.size", "query.size", "key.size", "key_padding_mask.max", "attn_weights.view.view.masked_fill", "attn_weights.view.view.view", "attn_weights.view.view.view", "attn_weights.view.view.view", "key_padding_mask.unsqueeze().unsqueeze", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "attn_weights.view.view.data.new().expand().clone", "attn_weights.view.view.data.new().expand().clone", "key_padding_mask.unsqueeze", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose", "attn_weights.view.view.data.new().expand", "attn_weights.view.view.data.new().expand", "attn_weights.view.view.data.new", "attn_weights.view.view.data.new"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.modules.scalar_bias.scalar_bias", "home.repos.pwc.inspect_result.reneeye_const.modules.scalar_bias.scalar_bias", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "query", ",", "\n", "key", ",", "\n", "value", ",", "\n", "mask_future_timesteps", "=", "False", ",", "\n", "key_padding_mask", "=", "None", ",", "\n", "use_scalar_bias", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Input shape: Time x Batch x Channel\n        Self-attention can be implemented by passing in the same arguments for\n        query, key and value. Future timesteps can be masked with the\n        `mask_future_timesteps` argument. Padding elements can be excluded from\n        the key by passing a binary ByteTensor (`key_padding_mask`) with shape:\n        batch x src_len, where padding elements are indicated by 1s.\n        \"\"\"", "\n", "src_len", ",", "bsz", ",", "out_channels", "=", "key", ".", "size", "(", ")", "\n", "tgt_len", "=", "query", ".", "size", "(", "0", ")", "\n", "assert", "list", "(", "query", ".", "size", "(", ")", ")", "==", "[", "tgt_len", ",", "bsz", ",", "out_channels", "]", "\n", "assert", "key", ".", "size", "(", ")", "==", "value", ".", "size", "(", ")", "\n", "\n", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "            ", "assert", "key_padding_mask", ".", "size", "(", "0", ")", "==", "bsz", "\n", "assert", "key_padding_mask", ".", "size", "(", "1", ")", "==", "src_len", "\n", "\n", "", "if", "self", ".", "downsample", ":", "\n", "            ", "size", "=", "bsz", "\n", "", "else", ":", "\n", "            ", "size", "=", "bsz", "*", "self", ".", "num_heads", "\n", "\n", "", "k", "=", "key", "\n", "v", "=", "value", "\n", "q", "=", "query", "\n", "if", "self", ".", "project_input", ":", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "q", ")", "\n", "k", "=", "self", ".", "in_proj_k", "(", "k", ")", "\n", "v", "=", "self", ".", "in_proj_v", "(", "v", ")", "\n", "src_len", "=", "k", ".", "size", "(", ")", "[", "0", "]", "\n", "", "q", "*=", "self", ".", "scaling", "\n", "\n", "if", "not", "self", ".", "downsample", ":", "\n", "            ", "q", "=", "q", ".", "view", "(", "tgt_len", ",", "size", ",", "self", ".", "head_dim", ")", "\n", "k", "=", "k", ".", "view", "(", "src_len", ",", "size", ",", "self", ".", "head_dim", ")", "\n", "v", "=", "v", ".", "view", "(", "src_len", ",", "size", ",", "self", ".", "head_dim", ")", "\n", "\n", "", "q", "=", "q", ".", "transpose", "(", "0", ",", "1", ")", "\n", "k", "=", "k", ".", "transpose", "(", "0", ",", "1", ")", "\n", "v", "=", "v", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "attn_weights", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "if", "mask_future_timesteps", ":", "\n", "            ", "assert", "(", "\n", "query", ".", "size", "(", ")", "==", "key", ".", "size", "(", ")", "\n", ")", ",", "\"mask_future_timesteps only applies to self-attention\"", "\n", "attn_weights", "*=", "torch", ".", "tril", "(", "\n", "attn_weights", ".", "data", ".", "new", "(", "[", "1", "]", ")", ".", "expand", "(", "tgt_len", ",", "tgt_len", ")", ".", "clone", "(", ")", ",", "\n", "diagonal", "=", "-", "1", ",", "\n", ")", "[", ":", ",", ":", ":", "self", ".", "head_index", "+", "1", "if", "self", ".", "downsample", "else", "1", "]", ".", "unsqueeze", "(", "0", ")", "\n", "attn_weights", "+=", "torch", ".", "triu", "(", "\n", "attn_weights", ".", "data", ".", "new", "(", "[", "-", "math", ".", "inf", "]", ")", ".", "expand", "(", "tgt_len", ",", "tgt_len", ")", ".", "clone", "(", ")", ",", "\n", "diagonal", "=", "0", ",", "\n", ")", "[", ":", ",", ":", ":", "self", ".", "head_index", "+", "1", "if", "self", ".", "downsample", "else", "1", "]", ".", "unsqueeze", "(", "0", ")", "\n", "", "tgt_size", "=", "tgt_len", "\n", "if", "use_scalar_bias", ":", "\n", "            ", "attn_weights", "=", "scalar_bias", "(", "attn_weights", ",", "2", ")", "\n", "v", "=", "scalar_bias", "(", "v", ",", "1", ")", "\n", "tgt_size", "+=", "1", "\n", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "# don't attend to padding symbols", "\n", "            ", "if", "key_padding_mask", ".", "max", "(", ")", ">", "0", ":", "\n", "                ", "if", "self", ".", "downsample", ":", "\n", "                    ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "1", ",", "tgt_len", ",", "src_len", ")", "\n", "", "else", ":", "\n", "                    ", "attn_weights", "=", "attn_weights", ".", "view", "(", "\n", "size", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", "\n", ")", "\n", "", "attn_weights", "=", "attn_weights", ".", "masked_fill", "(", "\n", "key_padding_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", ",", "\n", "-", "math", ".", "inf", ",", "\n", ")", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "size", ",", "tgt_len", ",", "src_len", ")", "\n", "", "", "attn_weights", "=", "F", ".", "softmax", "(", "attn_weights", ",", "dim", "=", "-", "1", ")", "\n", "attn_weights", "=", "self", ".", "dropout_module", "(", "attn_weights", ")", "\n", "\n", "attn", "=", "torch", ".", "bmm", "(", "attn_weights", ",", "v", ")", "\n", "if", "self", ".", "downsample", ":", "\n", "            ", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "self", ".", "head_dim", ")", "\n", "", "else", ":", "\n", "            ", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "self", ".", "embed_dim", ")", "\n", "\n", "", "attn", "=", "self", ".", "out_proj", "(", "attn", ")", "\n", "\n", "return", "attn", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.downsampled_multihead_attention.DownsampledMultiHeadAttention.__init__": [[175, 228], ["range", "torch.ModuleList.__init__", "downsampled_multihead_attention.Linear", "torch.ModuleList.__init__", "downsampled_multihead_attention.SingleHeadAttention", "attention_heads.append", "downsampled_multihead_attention.SingleHeadAttention"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "out_channels", ",", "\n", "embed_dim", ",", "\n", "num_heads", ",", "\n", "dropout", "=", "0.0", ",", "\n", "bias", "=", "True", ",", "\n", "project_input", "=", "True", ",", "\n", "gated", "=", "False", ",", "\n", "downsample", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "gated", "=", "gated", "\n", "self", ".", "project_input", "=", "project_input", "\n", "assert", "self", ".", "head_dim", "*", "num_heads", "==", "embed_dim", "\n", "\n", "if", "self", ".", "downsample", ":", "\n", "            ", "attention_heads", "=", "[", "]", "\n", "for", "index", "in", "range", "(", "self", ".", "num_heads", ")", ":", "\n", "                ", "attention_heads", ".", "append", "(", "\n", "SingleHeadAttention", "(", "\n", "out_channels", ",", "\n", "self", ".", "embed_dim", ",", "\n", "self", ".", "head_dim", ",", "\n", "index", ",", "\n", "dropout", ",", "\n", "bias", ",", "\n", "self", ".", "project_input", ",", "\n", "self", ".", "gated", ",", "\n", "self", ".", "downsample", ",", "\n", "self", ".", "num_heads", ",", "\n", ")", "\n", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "modules", "=", "attention_heads", ")", "\n", "self", ".", "out_proj", "=", "Linear", "(", "embed_dim", ",", "out_channels", ",", "bias", "=", "bias", ")", "\n", "", "else", ":", "\n", "# either we have a list of attention heads, or just one attention head", "\n", "# if not being downsampled, we can do the heads with one linear layer instead of separate ones", "\n", "            ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention_module", "=", "SingleHeadAttention", "(", "\n", "out_channels", ",", "\n", "self", ".", "embed_dim", ",", "\n", "self", ".", "head_dim", ",", "\n", "1", ",", "\n", "dropout", ",", "\n", "bias", ",", "\n", "self", ".", "project_input", ",", "\n", "self", ".", "gated", ",", "\n", "self", ".", "downsample", ",", "\n", "self", ".", "num_heads", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.downsampled_multihead_attention.DownsampledMultiHeadAttention.forward": [[230, 285], ["key.size", "query.size", "list", "key.size", "value.size", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "downsampled_multihead_attention.DownsampledMultiHeadAttention.out_proj", "downsampled_multihead_attention.DownsampledMultiHeadAttention.attention_module", "attn.append", "attn_weights.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "full_attn_weights.view.view.view", "query.size", "attn.append", "attn_weights.append", "attn_weights[].clone", "full_attn_weights.view.view.sum"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "query", ",", "\n", "key", ",", "\n", "value", ",", "\n", "mask_future_timesteps", "=", "False", ",", "\n", "key_padding_mask", "=", "None", ",", "\n", "use_scalar_bias", "=", "False", ",", "\n", ")", ":", "\n", "        ", "src_len", ",", "bsz", ",", "embed_dim", "=", "key", ".", "size", "(", ")", "\n", "tgt_len", "=", "query", ".", "size", "(", "0", ")", "\n", "assert", "embed_dim", "==", "self", ".", "embed_dim", "\n", "assert", "list", "(", "query", ".", "size", "(", ")", ")", "==", "[", "tgt_len", ",", "bsz", ",", "embed_dim", "]", "\n", "assert", "key", ".", "size", "(", ")", "==", "value", ".", "size", "(", ")", "\n", "\n", "tgt_size", "=", "tgt_len", "\n", "if", "use_scalar_bias", ":", "\n", "            ", "tgt_size", "+=", "1", "\n", "\n", "", "attn", "=", "[", "]", "\n", "attn_weights", "=", "[", "]", "\n", "if", "self", ".", "downsample", ":", "\n", "            ", "for", "attention_head_number", "in", "range", "(", "self", ".", "num_heads", ")", ":", "\n", "# call the forward of each attention head", "\n", "                ", "_attn", ",", "_attn_weight", "=", "self", "[", "attention_head_number", "]", "(", "\n", "query", ",", "\n", "key", ",", "\n", "value", ",", "\n", "mask_future_timesteps", ",", "\n", "key_padding_mask", ",", "\n", "use_scalar_bias", ",", "\n", ")", "\n", "attn", ".", "append", "(", "_attn", ")", "\n", "attn_weights", ".", "append", "(", "_attn_weight", ")", "\n", "", "full_attn", "=", "torch", ".", "cat", "(", "attn", ",", "dim", "=", "2", ")", "\n", "full_attn", "=", "self", ".", "out_proj", "(", "full_attn", ")", "\n", "return", "full_attn", ",", "attn_weights", "[", "0", "]", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "            ", "_attn", ",", "_attn_weight", "=", "self", ".", "attention_module", "(", "\n", "query", ",", "\n", "key", ",", "\n", "value", ",", "\n", "mask_future_timesteps", ",", "\n", "key_padding_mask", ",", "\n", "use_scalar_bias", ",", "\n", ")", "\n", "attn", ".", "append", "(", "_attn", ")", "\n", "attn_weights", ".", "append", "(", "_attn_weight", ")", "\n", "full_attn", "=", "torch", ".", "cat", "(", "attn", ",", "dim", "=", "2", ")", "\n", "full_attn_weights", "=", "torch", ".", "cat", "(", "attn_weights", ")", "\n", "full_attn_weights", "=", "full_attn_weights", ".", "view", "(", "\n", "bsz", ",", "self", ".", "num_heads", ",", "tgt_size", ",", "src_len", "\n", ")", "\n", "full_attn_weights", "=", "full_attn_weights", ".", "sum", "(", "dim", "=", "1", ")", "/", "self", ".", "num_heads", "\n", "return", "full_attn", ",", "full_attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.downsampled_multihead_attention.Downsample.__init__": [[292, 295], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "index", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "index", "=", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.downsampled_multihead_attention.Downsample.forward": [[296, 298], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "[", ":", ":", "self", ".", "index", "+", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.downsampled_multihead_attention.Linear": [[300, 306], ["torch.Linear", "nn.Linear.weight.data.normal_", "nn.Linear.bias.data.zero_", "torch.utils.weight_norm", "math.sqrt"], "function", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["", "", "def", "Linear", "(", "in_features", ",", "out_features", ",", "dropout", "=", "0.0", ",", "bias", "=", "True", ")", ":", "\n", "    ", "\"\"\"Weight-normalized Linear layer (input: B x T x C)\"\"\"", "\n", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "bias", ")", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0", ",", "std", "=", "math", ".", "sqrt", "(", "(", "1", "-", "dropout", ")", "/", "in_features", ")", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "return", "nn", ".", "utils", ".", "weight_norm", "(", "m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.downsampled_multihead_attention.GatedLinear": [[308, 316], ["torch.Sequential", "downsampled_multihead_attention.Linear", "torch.GLU", "downsampled_multihead_attention.Linear", "torch.GLU", "downsampled_multihead_attention.Linear"], "function", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["", "def", "GatedLinear", "(", "in_features", ",", "out_features", ",", "dropout", "=", "0.0", ",", "bias", "=", "True", ")", ":", "\n", "    ", "\"\"\"Weight-normalized Linear layer (input: B x T x C) with interspersed GLU units\"\"\"", "\n", "return", "nn", ".", "Sequential", "(", "\n", "Linear", "(", "in_features", ",", "out_features", "*", "4", ",", "dropout", ",", "bias", ")", ",", "\n", "nn", ".", "GLU", "(", ")", ",", "\n", "Linear", "(", "out_features", "*", "2", ",", "out_features", "*", "2", ",", "dropout", ",", "bias", ")", ",", "\n", "nn", ".", "GLU", "(", ")", ",", "\n", "Linear", "(", "out_features", ",", "out_features", ",", "dropout", ",", "bias", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.kmeans_vector_quantizer.KmeansVectorQuantizer.__init__": [[12, 51], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Sequential", "torch.Sequential", "torch.MSELoss", "torch.MSELoss", "torch.Conv1d", "torch.Conv1d", "fairseq.modules.Fp32GroupNorm", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "dim", ",", "num_vars", ",", "groups", ",", "combine_groups", ",", "vq_dim", ",", "time_first", ",", "gamma", "=", "0.25", "\n", ")", ":", "\n", "        ", "\"\"\"Vector quantization using straight pass-through estimator (i.e. kmeans)\n\n        Args:\n            dim: input dimension (channels)\n            num_vars: number of quantized vectors per group\n            groups: number of groups for vector quantization\n            combine_groups: whether to use the vectors for all groups\n            vq_dim: dimensionality of the resulting quantized vector\n            time_first: if true, expect input in BxTxC format, otherwise in BxCxT\n            gamma: commitment loss coefficient\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "groups", "=", "groups", "\n", "self", ".", "combine_groups", "=", "combine_groups", "\n", "self", ".", "input_dim", "=", "dim", "\n", "self", ".", "num_vars", "=", "num_vars", "\n", "self", ".", "vq_dim", "=", "vq_dim", "\n", "self", ".", "time_first", "=", "time_first", "\n", "\n", "assert", "(", "\n", "vq_dim", "%", "groups", "==", "0", "\n", ")", ",", "f\"dim {vq_dim} must be divisible by groups {groups} for concatenation\"", "\n", "\n", "self", ".", "var_dim", "=", "vq_dim", "//", "groups", "\n", "num_groups", "=", "groups", "if", "not", "combine_groups", "else", "1", "\n", "\n", "self", ".", "embedding", "=", "nn", ".", "Parameter", "(", "\n", "0.01", "*", "torch", ".", "randn", "(", "num_vars", ",", "num_groups", ",", "self", ".", "var_dim", ")", "\n", ")", "\n", "self", ".", "projection", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "dim", ",", "dim", ",", "kernel_size", "=", "1", ",", "groups", "=", "groups", ",", "bias", "=", "False", ")", ",", "\n", "Fp32GroupNorm", "(", "groups", ",", "dim", ")", ",", "\n", ")", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "mse_mean", "=", "nn", ".", "MSELoss", "(", "reduction", "=", "\"mean\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.kmeans_vector_quantizer.KmeansVectorQuantizer._pass_grad": [[52, 61], ["y.detach", "x.detach"], "methods", ["None"], ["", "def", "_pass_grad", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "\"\"\"Manually set gradient for backward pass.\n        for y = f(x), ensure that during the backward pass,\n        dL/dy = dL/dx regardless of f(x).\n        Returns:\n            y, with the gradient forced to be dL/dy = dL/dx.\n        \"\"\"", "\n", "\n", "return", "y", ".", "detach", "(", ")", "+", "(", "x", "-", "x", ".", "detach", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.kmeans_vector_quantizer.KmeansVectorQuantizer.expand_embedding": [[62, 67], ["kmeans_vector_quantizer.KmeansVectorQuantizer.embedding.expand"], "methods", ["None"], ["", "@", "property", "\n", "def", "expand_embedding", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "combine_groups", ":", "\n", "            ", "return", "self", ".", "embedding", ".", "expand", "(", "self", ".", "num_vars", ",", "self", ".", "groups", ",", "self", ".", "var_dim", ")", "\n", "", "return", "self", ".", "embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.kmeans_vector_quantizer.KmeansVectorQuantizer.forward_idx": [[68, 71], ["kmeans_vector_quantizer.KmeansVectorQuantizer.forward"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.forward"], ["", "def", "forward_idx", "(", "self", ",", "x", ")", ":", "\n", "        ", "res", "=", "self", ".", "forward", "(", "x", ",", "produce_targets", "=", "True", ")", "\n", "return", "res", "[", "\"x\"", "]", ",", "res", "[", "\"targets\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.kmeans_vector_quantizer.KmeansVectorQuantizer.forward": [[72, 128], ["kmeans_vector_quantizer.KmeansVectorQuantizer.projection", "ze.float.float.view().permute", "d.argmin", "torch.stack().view().permute", "torch.stack().view().permute", "torch.stack().view().permute", "torch.stack().view().permute", "kmeans_vector_quantizer.KmeansVectorQuantizer._pass_grad", "d.argmin.new_zeros().scatter_().view", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "torch.exp().sum", "ze.float.float.float", "zq.float.float.float", "kmeans_vector_quantizer.KmeansVectorQuantizer.mse_mean", "kmeans_vector_quantizer.KmeansVectorQuantizer.mse_mean", "x.transpose.transpose.transpose", "d.argmin.new_zeros().scatter_().view.float", "x.transpose.transpose.transpose", "ze.float.float.detach", "zq.float.float.detach", "ze.float.float.view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack().view", "d.argmin.new_zeros().scatter_", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "d.argmin.view", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "d.argmin.new_zeros", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "ze.float.view().permute.unsqueeze", "kmeans_vector_quantizer.KmeansVectorQuantizer.expand_embedding.unsqueeze().unsqueeze", "torch.log", "torch.log", "torch.log", "torch.log", "kmeans_vector_quantizer.KmeansVectorQuantizer.expand_embedding.unsqueeze", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.kmeans_vector_quantizer.KmeansVectorQuantizer._pass_grad", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log"], ["", "def", "forward", "(", "self", ",", "x", ",", "produce_targets", "=", "False", ")", ":", "\n", "\n", "        ", "result", "=", "{", "\"num_vars\"", ":", "self", ".", "num_vars", "}", "\n", "\n", "if", "self", ".", "time_first", ":", "\n", "            ", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "", "bsz", ",", "fsz", ",", "tsz", "=", "x", ".", "shape", "\n", "\n", "ze", "=", "self", ".", "projection", "(", "x", ")", "\n", "ze_", "=", "ze", ".", "view", "(", "bsz", ",", "self", ".", "groups", ",", "self", ".", "var_dim", ",", "tsz", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "d", "=", "(", "\n", "(", "ze_", ".", "unsqueeze", "(", "0", ")", "-", "self", ".", "expand_embedding", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", ".", "view", "(", "self", ".", "num_vars", ",", "bsz", ",", "tsz", ",", "self", ".", "groups", ",", "-", "1", ")", "\n", ".", "norm", "(", "dim", "=", "-", "1", ",", "p", "=", "2", ")", "\n", ")", "\n", "idx", "=", "d", ".", "argmin", "(", "dim", "=", "0", ")", "\n", "zq", "=", "(", "\n", "torch", ".", "stack", "(", "\n", "[", "\n", "self", ".", "expand_embedding", "[", "idx", "[", "...", ",", "group", "]", ",", "group", "]", "\n", "for", "group", "in", "range", "(", "self", ".", "groups", ")", "\n", "]", ",", "\n", "dim", "=", "-", "2", ",", "\n", ")", "\n", ".", "view", "(", "bsz", ",", "tsz", ",", "self", ".", "groups", "*", "self", ".", "var_dim", ")", "\n", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", ")", "\n", "assert", "ze", ".", "shape", "==", "zq", ".", "shape", ",", "(", "ze", ".", "shape", ",", "zq", ".", "shape", ")", "\n", "x", "=", "self", ".", "_pass_grad", "(", "ze", ",", "zq", ")", "\n", "\n", "hard_x", "=", "(", "\n", "idx", ".", "new_zeros", "(", "bsz", "*", "tsz", "*", "self", ".", "groups", ",", "self", ".", "num_vars", ")", "\n", ".", "scatter_", "(", "-", "1", ",", "idx", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1.0", ")", "\n", ".", "view", "(", "bsz", "*", "tsz", ",", "self", ".", "groups", ",", "-", "1", ")", "\n", ")", "\n", "hard_probs", "=", "torch", ".", "mean", "(", "hard_x", ".", "float", "(", ")", ",", "dim", "=", "0", ")", "\n", "result", "[", "\"code_perplexity\"", "]", "=", "torch", ".", "exp", "(", "\n", "-", "torch", ".", "sum", "(", "hard_probs", "*", "torch", ".", "log", "(", "hard_probs", "+", "1e-7", ")", ",", "dim", "=", "-", "1", ")", "\n", ")", ".", "sum", "(", ")", "\n", "\n", "if", "produce_targets", ":", "\n", "            ", "result", "[", "\"targets\"", "]", "=", "idx", "\n", "\n", "", "if", "self", ".", "time_first", ":", "\n", "            ", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "# BCT -> BTC", "\n", "", "result", "[", "\"x\"", "]", "=", "x", "\n", "\n", "ze", "=", "ze", ".", "float", "(", ")", "\n", "zq", "=", "zq", ".", "float", "(", ")", "\n", "latent_loss", "=", "self", ".", "mse_mean", "(", "zq", ",", "ze", ".", "detach", "(", ")", ")", "\n", "commitment_loss", "=", "self", ".", "mse_mean", "(", "ze", ",", "zq", ".", "detach", "(", ")", ")", "\n", "\n", "result", "[", "\"kmeans_loss\"", "]", "=", "latent_loss", "+", "self", ".", "gamma", "*", "commitment_loss", "\n", "\n", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.TransformerEncoderLayer.__init__": [[32, 67], ["torch.Module.__init__", "getattr", "transformer_layer.TransformerEncoderLayer.build_self_attention", "fairseq.modules.LayerNorm", "fairseq.modules.fairseq_dropout.FairseqDropout", "fairseq.utils.get_activation_fn", "fairseq.modules.fairseq_dropout.FairseqDropout", "transformer_layer.TransformerEncoderLayer.build_fc1", "transformer_layer.TransformerEncoderLayer.build_fc2", "fairseq.modules.LayerNorm", "getattr", "getattr", "float", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.ModelParallelTransformerDecoderLayer.build_self_attention", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.ModelParallelTransformerDecoderLayer.build_fc1", "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.ModelParallelTransformerDecoderLayer.build_fc2", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "args", ".", "encoder_embed_dim", "\n", "self", ".", "quant_noise", "=", "getattr", "(", "args", ",", "'quant_noise_pq'", ",", "0", ")", "\n", "self", ".", "quant_noise_block_size", "=", "getattr", "(", "args", ",", "'quant_noise_pq_block_size'", ",", "8", ")", "or", "8", "\n", "self", ".", "self_attn", "=", "self", ".", "build_self_attention", "(", "self", ".", "embed_dim", ",", "args", ")", "\n", "self", ".", "self_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "args", ".", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "activation_fn", "=", "utils", ".", "get_activation_fn", "(", "\n", "activation", "=", "getattr", "(", "args", ",", "'activation_fn'", ",", "'relu'", ")", "or", "\"relu\"", "\n", ")", "\n", "activation_dropout_p", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "0", ")", "or", "0", "\n", "if", "activation_dropout_p", "==", "0", ":", "\n", "# for backwards compatibility with models that use args.relu_dropout", "\n", "            ", "activation_dropout_p", "=", "getattr", "(", "args", ",", "\"relu_dropout\"", ",", "0", ")", "or", "0", "\n", "", "self", ".", "activation_dropout_module", "=", "FairseqDropout", "(", "\n", "float", "(", "activation_dropout_p", ")", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "normalize_before", "=", "args", ".", "encoder_normalize_before", "\n", "self", ".", "fc1", "=", "self", ".", "build_fc1", "(", "\n", "self", ".", "embed_dim", ",", "\n", "args", ".", "encoder_ffn_embed_dim", ",", "\n", "self", ".", "quant_noise", ",", "\n", "self", ".", "quant_noise_block_size", ",", "\n", ")", "\n", "self", ".", "fc2", "=", "self", ".", "build_fc2", "(", "\n", "args", ".", "encoder_ffn_embed_dim", ",", "\n", "self", ".", "embed_dim", ",", "\n", "self", ".", "quant_noise", ",", "\n", "self", ".", "quant_noise_block_size", ",", "\n", ")", "\n", "\n", "self", ".", "final_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.TransformerEncoderLayer.build_fc1": [[68, 71], ["fairseq.modules.quant_noise.quant_noise", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["", "def", "build_fc1", "(", "self", ",", "input_dim", ",", "output_dim", ",", "q_noise", ",", "qn_block_size", ")", ":", "\n", "        ", "return", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ")", ",", "p", "=", "q_noise", ",", "block_size", "=", "qn_block_size", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.TransformerEncoderLayer.build_fc2": [[73, 76], ["fairseq.modules.quant_noise.quant_noise", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["", "def", "build_fc2", "(", "self", ",", "input_dim", ",", "output_dim", ",", "q_noise", ",", "qn_block_size", ")", ":", "\n", "        ", "return", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ")", ",", "p", "=", "q_noise", ",", "block_size", "=", "qn_block_size", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.TransformerEncoderLayer.build_self_attention": [[78, 86], ["fairseq.modules.MultiheadAttention"], "methods", ["None"], ["", "def", "build_self_attention", "(", "self", ",", "embed_dim", ",", "args", ")", ":", "\n", "        ", "return", "MultiheadAttention", "(", "\n", "embed_dim", ",", "\n", "args", ".", "encoder_attention_heads", ",", "\n", "dropout", "=", "args", ".", "attention_dropout", ",", "\n", "self_attention", "=", "True", ",", "\n", "q_noise", "=", "self", ".", "quant_noise", ",", "\n", "qn_block_size", "=", "self", ".", "quant_noise_block_size", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.TransformerEncoderLayer.residual_connection": [[88, 90], ["None"], "methods", ["None"], ["", "def", "residual_connection", "(", "self", ",", "x", ",", "residual", ")", ":", "\n", "        ", "return", "residual", "+", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.TransformerEncoderLayer.upgrade_state_dict_named": [[91, 104], ["layer_norm_map.items"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "\"\"\"\n        Rename layer norm states from `...layer_norms.0.weight` to\n        `...self_attn_layer_norm.weight` and `...layer_norms.1.weight` to\n        `...final_layer_norm.weight`\n        \"\"\"", "\n", "layer_norm_map", "=", "{", "\"0\"", ":", "\"self_attn_layer_norm\"", ",", "\"1\"", ":", "\"final_layer_norm\"", "}", "\n", "for", "old", ",", "new", "in", "layer_norm_map", ".", "items", "(", ")", ":", "\n", "            ", "for", "m", "in", "(", "\"weight\"", ",", "\"bias\"", ")", ":", "\n", "                ", "k", "=", "\"{}.layer_norms.{}.{}\"", ".", "format", "(", "name", ",", "old", ",", "m", ")", "\n", "if", "k", "in", "state_dict", ":", "\n", "                    ", "state_dict", "[", "\"{}.{}.{}\"", ".", "format", "(", "name", ",", "new", ",", "m", ")", "]", "=", "state_dict", "[", "k", "]", "\n", "del", "state_dict", "[", "k", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.TransformerEncoderLayer.forward": [[105, 155], ["transformer_layer.TransformerEncoderLayer.self_attn", "transformer_layer.TransformerEncoderLayer.dropout_module", "transformer_layer.TransformerEncoderLayer.residual_connection", "transformer_layer.TransformerEncoderLayer.activation_fn", "transformer_layer.TransformerEncoderLayer.activation_dropout_module", "transformer_layer.TransformerEncoderLayer.fc2", "transformer_layer.TransformerEncoderLayer.dropout_module", "transformer_layer.TransformerEncoderLayer.residual_connection", "attn_mask.masked_fill.masked_fill.masked_fill", "transformer_layer.TransformerEncoderLayer.self_attn_layer_norm", "transformer_layer.TransformerEncoderLayer.self_attn_layer_norm", "transformer_layer.TransformerEncoderLayer.final_layer_norm", "transformer_layer.TransformerEncoderLayer.fc1", "transformer_layer.TransformerEncoderLayer.final_layer_norm", "attn_mask.masked_fill.masked_fill.to"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.TransformerDecoderLayer.residual_connection", "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.TransformerDecoderLayer.residual_connection"], ["", "", "", "", "def", "forward", "(", "self", ",", "x", ",", "encoder_padding_mask", ",", "attn_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (Tensor): input to the layer of shape `(seq_len, batch, embed_dim)`\n            encoder_padding_mask (ByteTensor): binary ByteTensor of shape\n                `(batch, seq_len)` where padding elements are indicated by ``1``.\n            attn_mask (ByteTensor): binary tensor of shape `(tgt_len, src_len)`,\n                where `tgt_len` is the length of output and `src_len` is the\n                length of input, though here both are equal to `seq_len`.\n                `attn_mask[tgt_i, src_j] = 1` means that when calculating the\n                embedding for `tgt_i`, we exclude (mask out) `src_j`. This is\n                useful for strided self-attention.\n\n        Returns:\n            encoded output of shape `(seq_len, batch, embed_dim)`\n        \"\"\"", "\n", "# anything in original attn_mask = 1, becomes -1e8", "\n", "# anything in original attn_mask = 0, becomes 0", "\n", "# Note that we cannot use -inf here, because at some edge cases,", "\n", "# the attention weight (before softmax) for some padded element in query", "\n", "# will become -inf, which results in NaN in model parameters", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask", "=", "attn_mask", ".", "masked_fill", "(", "attn_mask", ".", "to", "(", "torch", ".", "bool", ")", ",", "-", "1e8", ")", "\n", "\n", "", "residual", "=", "x", "\n", "if", "self", ".", "normalize_before", ":", "\n", "            ", "x", "=", "self", ".", "self_attn_layer_norm", "(", "x", ")", "\n", "", "x", ",", "_", "=", "self", ".", "self_attn", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "x", ",", "\n", "value", "=", "x", ",", "\n", "key_padding_mask", "=", "encoder_padding_mask", ",", "\n", "attn_mask", "=", "attn_mask", ",", "\n", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "self", ".", "residual_connection", "(", "x", ",", "residual", ")", "\n", "if", "not", "self", ".", "normalize_before", ":", "\n", "            ", "x", "=", "self", ".", "self_attn_layer_norm", "(", "x", ")", "\n", "\n", "", "residual", "=", "x", "\n", "if", "self", ".", "normalize_before", ":", "\n", "            ", "x", "=", "self", ".", "final_layer_norm", "(", "x", ")", "\n", "", "x", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "activation_dropout_module", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "self", ".", "residual_connection", "(", "x", ",", "residual", ")", "\n", "if", "not", "self", ".", "normalize_before", ":", "\n", "            ", "x", "=", "self", ".", "final_layer_norm", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.TransformerDecoderLayer.__init__": [[174, 238], ["torch.Module.__init__", "fairseq.modules.fairseq_dropout.FairseqDropout", "getattr", "getattr", "getattr", "transformer_layer.TransformerDecoderLayer.build_self_attention", "fairseq.utils.get_activation_fn", "fairseq.modules.fairseq_dropout.FairseqDropout", "getattr", "fairseq.modules.LayerNorm", "transformer_layer.TransformerDecoderLayer.build_fc1", "transformer_layer.TransformerDecoderLayer.build_fc2", "fairseq.modules.LayerNorm", "getattr", "float", "transformer_layer.TransformerDecoderLayer.build_encoder_attention", "fairseq.modules.LayerNorm", "getattr", "str", "getattr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.ModelParallelTransformerDecoderLayer.build_self_attention", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.ModelParallelTransformerDecoderLayer.build_fc1", "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.ModelParallelTransformerDecoderLayer.build_fc2", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.ModelParallelTransformerDecoderLayer.build_encoder_attention", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "\n", "self", ",", "args", ",", "no_encoder_attn", "=", "False", ",", "add_bias_kv", "=", "False", ",", "add_zero_attn", "=", "False", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "args", ".", "decoder_embed_dim", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "args", ".", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "quant_noise", "=", "getattr", "(", "args", ",", "\"quant_noise_pq\"", ",", "0", ")", "\n", "self", ".", "quant_noise_block_size", "=", "getattr", "(", "args", ",", "\"quant_noise_pq_block_size\"", ",", "8", ")", "\n", "\n", "self", ".", "cross_self_attention", "=", "getattr", "(", "args", ",", "\"cross_self_attention\"", ",", "False", ")", "\n", "\n", "self", ".", "self_attn", "=", "self", ".", "build_self_attention", "(", "\n", "self", ".", "embed_dim", ",", "\n", "args", ",", "\n", "add_bias_kv", "=", "add_bias_kv", ",", "\n", "add_zero_attn", "=", "add_zero_attn", ",", "\n", ")", "\n", "\n", "self", ".", "activation_fn", "=", "utils", ".", "get_activation_fn", "(", "\n", "activation", "=", "str", "(", "args", ".", "activation_fn", ")", "\n", "if", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "None", ")", "is", "not", "None", "\n", "else", "\"relu\"", "\n", ")", "\n", "activation_dropout_p", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "0", ")", "or", "0", "\n", "if", "activation_dropout_p", "==", "0", ":", "\n", "# for backwards compatibility with models that use args.relu_dropout", "\n", "            ", "activation_dropout_p", "=", "getattr", "(", "args", ",", "\"relu_dropout\"", ",", "0", ")", "or", "0", "\n", "", "self", ".", "activation_dropout_module", "=", "FairseqDropout", "(", "\n", "float", "(", "activation_dropout_p", ")", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "normalize_before", "=", "args", ".", "decoder_normalize_before", "\n", "\n", "# use layerNorm rather than FusedLayerNorm for exporting.", "\n", "# char_inputs can be used to determint this.", "\n", "# TODO  remove this once we update apex with the fix", "\n", "export", "=", "getattr", "(", "args", ",", "\"char_inputs\"", ",", "False", ")", "\n", "self", ".", "self_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ",", "export", "=", "export", ")", "\n", "\n", "if", "no_encoder_attn", ":", "\n", "            ", "self", ".", "encoder_attn", "=", "None", "\n", "self", ".", "encoder_attn_layer_norm", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "encoder_attn", "=", "self", ".", "build_encoder_attention", "(", "self", ".", "embed_dim", ",", "args", ")", "\n", "self", ".", "encoder_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ",", "export", "=", "export", ")", "\n", "\n", "", "self", ".", "fc1", "=", "self", ".", "build_fc1", "(", "\n", "self", ".", "embed_dim", ",", "\n", "args", ".", "decoder_ffn_embed_dim", ",", "\n", "self", ".", "quant_noise", ",", "\n", "self", ".", "quant_noise_block_size", ",", "\n", ")", "\n", "self", ".", "fc2", "=", "self", ".", "build_fc2", "(", "\n", "args", ".", "decoder_ffn_embed_dim", ",", "\n", "self", ".", "embed_dim", ",", "\n", "self", ".", "quant_noise", ",", "\n", "self", ".", "quant_noise_block_size", ",", "\n", ")", "\n", "\n", "self", ".", "final_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ",", "export", "=", "export", ")", "\n", "self", ".", "need_attn", "=", "True", "\n", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.TransformerDecoderLayer.build_fc1": [[239, 241], ["fairseq.modules.quant_noise.quant_noise", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["", "def", "build_fc1", "(", "self", ",", "input_dim", ",", "output_dim", ",", "q_noise", ",", "qn_block_size", ")", ":", "\n", "        ", "return", "quant_noise", "(", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ")", ",", "q_noise", ",", "qn_block_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.TransformerDecoderLayer.build_fc2": [[242, 244], ["fairseq.modules.quant_noise.quant_noise", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["", "def", "build_fc2", "(", "self", ",", "input_dim", ",", "output_dim", ",", "q_noise", ",", "qn_block_size", ")", ":", "\n", "        ", "return", "quant_noise", "(", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ")", ",", "q_noise", ",", "qn_block_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.TransformerDecoderLayer.build_self_attention": [[245, 257], ["fairseq.modules.MultiheadAttention", "getattr"], "methods", ["None"], ["", "def", "build_self_attention", "(", "\n", "self", ",", "embed_dim", ",", "args", ",", "add_bias_kv", "=", "False", ",", "add_zero_attn", "=", "False", "\n", ")", ":", "\n", "        ", "return", "MultiheadAttention", "(", "\n", "embed_dim", ",", "\n", "args", ".", "decoder_attention_heads", ",", "\n", "dropout", "=", "args", ".", "attention_dropout", ",", "\n", "add_bias_kv", "=", "add_bias_kv", ",", "\n", "add_zero_attn", "=", "add_zero_attn", ",", "\n", "self_attention", "=", "not", "getattr", "(", "args", ",", "\"cross_self_attention\"", ",", "False", ")", ",", "\n", "q_noise", "=", "self", ".", "quant_noise", ",", "\n", "qn_block_size", "=", "self", ".", "quant_noise_block_size", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.TransformerDecoderLayer.build_encoder_attention": [[259, 269], ["fairseq.modules.MultiheadAttention", "getattr", "getattr"], "methods", ["None"], ["", "def", "build_encoder_attention", "(", "self", ",", "embed_dim", ",", "args", ")", ":", "\n", "        ", "return", "MultiheadAttention", "(", "\n", "embed_dim", ",", "\n", "args", ".", "decoder_attention_heads", ",", "\n", "kdim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "None", ")", ",", "\n", "vdim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "None", ")", ",", "\n", "dropout", "=", "args", ".", "attention_dropout", ",", "\n", "encoder_decoder_attention", "=", "True", ",", "\n", "q_noise", "=", "self", ".", "quant_noise", ",", "\n", "qn_block_size", "=", "self", ".", "quant_noise_block_size", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.TransformerDecoderLayer.prepare_for_onnx_export_": [[271, 273], ["None"], "methods", ["None"], ["", "def", "prepare_for_onnx_export_", "(", "self", ")", ":", "\n", "        ", "self", ".", "onnx_trace", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.TransformerDecoderLayer.residual_connection": [[274, 276], ["None"], "methods", ["None"], ["", "def", "residual_connection", "(", "self", ",", "x", ",", "residual", ")", ":", "\n", "        ", "return", "residual", "+", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.TransformerDecoderLayer.forward": [[277, 412], ["transformer_layer.TransformerDecoderLayer.self_attn._get_input_buffer", "transformer_layer.TransformerDecoderLayer.self_attn", "transformer_layer.TransformerDecoderLayer.dropout_module", "transformer_layer.TransformerDecoderLayer.residual_connection", "transformer_layer.TransformerDecoderLayer.activation_fn", "transformer_layer.TransformerDecoderLayer.activation_dropout_module", "transformer_layer.TransformerDecoderLayer.fc2", "transformer_layer.TransformerDecoderLayer.dropout_module", "transformer_layer.TransformerDecoderLayer.residual_connection", "transformer_layer.TransformerDecoderLayer.self_attn_layer_norm", "transformer_layer.TransformerDecoderLayer.self_attn._set_input_buffer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "transformer_layer.TransformerDecoderLayer.self_attn_layer_norm", "transformer_layer.TransformerDecoderLayer.encoder_attn", "transformer_layer.TransformerDecoderLayer.dropout_module", "transformer_layer.TransformerDecoderLayer.residual_connection", "transformer_layer.TransformerDecoderLayer.final_layer_norm", "transformer_layer.TransformerDecoderLayer.fc1", "transformer_layer.TransformerDecoderLayer.final_layer_norm", "transformer_layer.TransformerDecoderLayer.self_attn._get_input_buffer", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "transformer_layer.TransformerDecoderLayer.encoder_attn_layer_norm", "transformer_layer.TransformerDecoderLayer.encoder_attn._set_input_buffer", "transformer_layer.TransformerDecoderLayer.encoder_attn_layer_norm", "torch.cat.new_zeros", "torch.cat.new_zeros", "len", "transformer_layer.TransformerDecoderLayer.new_zeros", "encoder_out.size", "encoder_out.size", "transformer_layer.TransformerDecoderLayer.size", "encoder_out.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.TransformerDecoderLayer.residual_connection", "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.TransformerDecoderLayer.residual_connection", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.TransformerDecoderLayer.residual_connection", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "x", ",", "\n", "encoder_out", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "encoder_padding_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", "=", "None", ",", "\n", "prev_self_attn_state", ":", "Optional", "[", "List", "[", "torch", ".", "Tensor", "]", "]", "=", "None", ",", "\n", "prev_attn_state", ":", "Optional", "[", "List", "[", "torch", ".", "Tensor", "]", "]", "=", "None", ",", "\n", "self_attn_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "self_attn_padding_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "need_attn", ":", "bool", "=", "False", ",", "\n", "need_head_weights", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (Tensor): input to the layer of shape `(seq_len, batch, embed_dim)`\n            encoder_padding_mask (ByteTensor, optional): binary\n                ByteTensor of shape `(batch, src_len)` where padding\n                elements are indicated by ``1``.\n            need_attn (bool, optional): return attention weights\n            need_head_weights (bool, optional): return attention weights\n                for each head (default: return average over heads).\n\n        Returns:\n            encoded output of shape `(seq_len, batch, embed_dim)`\n        \"\"\"", "\n", "if", "need_head_weights", ":", "\n", "            ", "need_attn", "=", "True", "\n", "\n", "", "residual", "=", "x", "\n", "if", "self", ".", "normalize_before", ":", "\n", "            ", "x", "=", "self", ".", "self_attn_layer_norm", "(", "x", ")", "\n", "", "if", "prev_self_attn_state", "is", "not", "None", ":", "\n", "            ", "prev_key", ",", "prev_value", "=", "prev_self_attn_state", "[", ":", "2", "]", "\n", "saved_state", ":", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "=", "{", "\n", "\"prev_key\"", ":", "prev_key", ",", "\n", "\"prev_value\"", ":", "prev_value", ",", "\n", "}", "\n", "if", "len", "(", "prev_self_attn_state", ")", ">=", "3", ":", "\n", "                ", "saved_state", "[", "\"prev_key_padding_mask\"", "]", "=", "prev_self_attn_state", "[", "2", "]", "\n", "", "assert", "incremental_state", "is", "not", "None", "\n", "self", ".", "self_attn", ".", "_set_input_buffer", "(", "incremental_state", ",", "saved_state", ")", "\n", "", "_self_attn_input_buffer", "=", "self", ".", "self_attn", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "self", ".", "cross_self_attention", "and", "not", "(", "\n", "incremental_state", "is", "not", "None", "\n", "and", "_self_attn_input_buffer", "is", "not", "None", "\n", "and", "\"prev_key\"", "in", "_self_attn_input_buffer", "\n", ")", ":", "\n", "            ", "if", "self_attn_mask", "is", "not", "None", ":", "\n", "                ", "assert", "encoder_out", "is", "not", "None", "\n", "self_attn_mask", "=", "torch", ".", "cat", "(", "\n", "(", "x", ".", "new_zeros", "(", "x", ".", "size", "(", "0", ")", ",", "encoder_out", ".", "size", "(", "0", ")", ")", ",", "self_attn_mask", ")", ",", "dim", "=", "1", "\n", ")", "\n", "", "if", "self_attn_padding_mask", "is", "not", "None", ":", "\n", "                ", "if", "encoder_padding_mask", "is", "None", ":", "\n", "                    ", "assert", "encoder_out", "is", "not", "None", "\n", "encoder_padding_mask", "=", "self_attn_padding_mask", ".", "new_zeros", "(", "\n", "encoder_out", ".", "size", "(", "1", ")", ",", "encoder_out", ".", "size", "(", "0", ")", "\n", ")", "\n", "", "self_attn_padding_mask", "=", "torch", ".", "cat", "(", "\n", "(", "encoder_padding_mask", ",", "self_attn_padding_mask", ")", ",", "dim", "=", "1", "\n", ")", "\n", "", "assert", "encoder_out", "is", "not", "None", "\n", "y", "=", "torch", ".", "cat", "(", "(", "encoder_out", ",", "x", ")", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "y", "=", "x", "\n", "\n", "", "x", ",", "attn", "=", "self", ".", "self_attn", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "y", ",", "\n", "value", "=", "y", ",", "\n", "key_padding_mask", "=", "self_attn_padding_mask", ",", "\n", "incremental_state", "=", "incremental_state", ",", "\n", "need_weights", "=", "False", ",", "\n", "attn_mask", "=", "self_attn_mask", ",", "\n", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "self", ".", "residual_connection", "(", "x", ",", "residual", ")", "\n", "if", "not", "self", ".", "normalize_before", ":", "\n", "            ", "x", "=", "self", ".", "self_attn_layer_norm", "(", "x", ")", "\n", "\n", "", "if", "self", ".", "encoder_attn", "is", "not", "None", "and", "encoder_out", "is", "not", "None", ":", "\n", "            ", "residual", "=", "x", "\n", "if", "self", ".", "normalize_before", ":", "\n", "                ", "x", "=", "self", ".", "encoder_attn_layer_norm", "(", "x", ")", "\n", "", "if", "prev_attn_state", "is", "not", "None", ":", "\n", "                ", "prev_key", ",", "prev_value", "=", "prev_attn_state", "[", ":", "2", "]", "\n", "saved_state", ":", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "=", "{", "\n", "\"prev_key\"", ":", "prev_key", ",", "\n", "\"prev_value\"", ":", "prev_value", ",", "\n", "}", "\n", "if", "len", "(", "prev_attn_state", ")", ">=", "3", ":", "\n", "                    ", "saved_state", "[", "\"prev_key_padding_mask\"", "]", "=", "prev_attn_state", "[", "2", "]", "\n", "", "assert", "incremental_state", "is", "not", "None", "\n", "self", ".", "encoder_attn", ".", "_set_input_buffer", "(", "incremental_state", ",", "saved_state", ")", "\n", "\n", "", "x", ",", "attn", "=", "self", ".", "encoder_attn", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "encoder_out", ",", "\n", "value", "=", "encoder_out", ",", "\n", "key_padding_mask", "=", "encoder_padding_mask", ",", "\n", "incremental_state", "=", "incremental_state", ",", "\n", "static_kv", "=", "True", ",", "\n", "need_weights", "=", "need_attn", "or", "(", "not", "self", ".", "training", "and", "self", ".", "need_attn", ")", ",", "\n", "need_head_weights", "=", "need_head_weights", ",", "\n", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "self", ".", "residual_connection", "(", "x", ",", "residual", ")", "\n", "if", "not", "self", ".", "normalize_before", ":", "\n", "                ", "x", "=", "self", ".", "encoder_attn_layer_norm", "(", "x", ")", "\n", "\n", "", "", "residual", "=", "x", "\n", "if", "self", ".", "normalize_before", ":", "\n", "            ", "x", "=", "self", ".", "final_layer_norm", "(", "x", ")", "\n", "\n", "", "x", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "activation_dropout_module", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "self", ".", "residual_connection", "(", "x", ",", "residual", ")", "\n", "if", "not", "self", ".", "normalize_before", ":", "\n", "            ", "x", "=", "self", ".", "final_layer_norm", "(", "x", ")", "\n", "", "if", "self", ".", "onnx_trace", "and", "incremental_state", "is", "not", "None", ":", "\n", "            ", "saved_state", "=", "self", ".", "self_attn", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "assert", "saved_state", "is", "not", "None", "\n", "if", "self_attn_padding_mask", "is", "not", "None", ":", "\n", "                ", "self_attn_state", "=", "[", "\n", "saved_state", "[", "\"prev_key\"", "]", ",", "\n", "saved_state", "[", "\"prev_value\"", "]", ",", "\n", "saved_state", "[", "\"prev_key_padding_mask\"", "]", ",", "\n", "]", "\n", "", "else", ":", "\n", "                ", "self_attn_state", "=", "[", "saved_state", "[", "\"prev_key\"", "]", ",", "saved_state", "[", "\"prev_value\"", "]", "]", "\n", "", "return", "x", ",", "attn", ",", "self_attn_state", "\n", "", "return", "x", ",", "attn", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.TransformerDecoderLayer.make_generation_fast_": [[413, 415], ["None"], "methods", ["None"], ["", "def", "make_generation_fast_", "(", "self", ",", "need_attn", ":", "bool", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "need_attn", "=", "need_attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.gelu.gelu_accurate": [[16, 21], ["hasattr", "math.sqrt", "torch.tanh", "torch.tanh", "torch.pow", "torch.pow"], "function", ["None"], ["def", "gelu_accurate", "(", "x", ")", ":", "\n", "    ", "if", "not", "hasattr", "(", "gelu_accurate", ",", "\"_a\"", ")", ":", "\n", "        ", "gelu_accurate", ".", "_a", "=", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "\n", "", "return", "(", "\n", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "gelu_accurate", ".", "_a", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.gelu.gelu": [[24, 26], ["torch.nn.functional.gelu().type_as", "torch.nn.functional.gelu().type_as", "torch.nn.functional.gelu", "torch.nn.functional.gelu", "x.float"], "function", ["home.repos.pwc.inspect_result.reneeye_const.modules.gelu.gelu", "home.repos.pwc.inspect_result.reneeye_const.modules.gelu.gelu"], ["", "def", "gelu", "(", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "return", "torch", ".", "nn", ".", "functional", ".", "gelu", "(", "x", ".", "float", "(", ")", ")", ".", "type_as", "(", "x", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.unfold.unfold1d": [[9, 20], ["x.unsqueeze.size", "torch.pad", "x.unsqueeze.as_strided", "x.unsqueeze.unsqueeze"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["def", "unfold1d", "(", "x", ",", "kernel_size", ",", "padding_l", ",", "pad_value", "=", "0", ")", ":", "\n", "    ", "\"\"\"unfold T x B x C to T x B x C x K\"\"\"", "\n", "if", "kernel_size", ">", "1", ":", "\n", "        ", "T", ",", "B", ",", "C", "=", "x", ".", "size", "(", ")", "\n", "x", "=", "F", ".", "pad", "(", "\n", "x", ",", "(", "0", ",", "0", ",", "0", ",", "0", ",", "padding_l", ",", "kernel_size", "-", "1", "-", "padding_l", ")", ",", "value", "=", "pad_value", "\n", ")", "\n", "x", "=", "x", ".", "as_strided", "(", "(", "T", ",", "B", ",", "C", ",", "kernel_size", ")", ",", "(", "B", "*", "C", ",", "C", ",", "1", ",", "B", "*", "C", ")", ")", "\n", "", "else", ":", "\n", "        ", "x", "=", "x", ".", "unsqueeze", "(", "3", ")", "\n", "", "return", "x", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.sparse_transformer_sentence_encoder.SparseTransformerSentenceEncoder.__init__": [[19, 97], ["fairseq.modules.TransformerSentenceEncoder.__init__", "torch.ModuleList", "range", "sparse_transformer_sentence_encoder.SparseTransformerSentenceEncoder.__init__.freeze_module_params"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "padding_idx", ":", "int", ",", "\n", "vocab_size", ":", "int", ",", "\n", "num_encoder_layers", ":", "int", "=", "6", ",", "\n", "embedding_dim", ":", "int", "=", "768", ",", "\n", "ffn_embedding_dim", ":", "int", "=", "3072", ",", "\n", "num_attention_heads", ":", "int", "=", "8", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "attention_dropout", ":", "float", "=", "0.1", ",", "\n", "activation_dropout", ":", "float", "=", "0.1", ",", "\n", "max_seq_len", ":", "int", "=", "256", ",", "\n", "num_segments", ":", "int", "=", "2", ",", "\n", "use_position_embeddings", ":", "bool", "=", "True", ",", "\n", "offset_positions_by_padding", ":", "bool", "=", "True", ",", "\n", "encoder_normalize_before", ":", "bool", "=", "False", ",", "\n", "apply_bert_init", ":", "bool", "=", "False", ",", "\n", "activation_fn", ":", "str", "=", "\"relu\"", ",", "\n", "learned_pos_embedding", ":", "bool", "=", "True", ",", "\n", "embed_scale", ":", "float", "=", "None", ",", "\n", "freeze_embeddings", ":", "bool", "=", "False", ",", "\n", "n_trans_layers_to_freeze", ":", "int", "=", "0", ",", "\n", "export", ":", "bool", "=", "False", ",", "\n", "is_bidirectional", ":", "bool", "=", "True", ",", "\n", "stride", ":", "int", "=", "32", ",", "\n", "expressivity", ":", "int", "=", "8", ",", "\n", ")", "->", "None", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "padding_idx", ",", "\n", "vocab_size", ",", "\n", "num_encoder_layers", ",", "\n", "embedding_dim", ",", "\n", "ffn_embedding_dim", ",", "\n", "num_attention_heads", ",", "\n", "dropout", ",", "\n", "attention_dropout", ",", "\n", "activation_dropout", ",", "\n", "max_seq_len", ",", "\n", "num_segments", ",", "\n", "use_position_embeddings", ",", "\n", "offset_positions_by_padding", ",", "\n", "encoder_normalize_before", ",", "\n", "apply_bert_init", ",", "\n", "activation_fn", ",", "\n", "learned_pos_embedding", ",", "\n", "embed_scale", ",", "\n", "freeze_embeddings", ",", "\n", "n_trans_layers_to_freeze", ",", "\n", "export", ",", "\n", ")", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "SparseTransformerSentenceEncoderLayer", "(", "\n", "embedding_dim", "=", "self", ".", "embedding_dim", ",", "\n", "ffn_embedding_dim", "=", "ffn_embedding_dim", ",", "\n", "num_attention_heads", "=", "num_attention_heads", ",", "\n", "dropout", "=", "dropout", ",", "\n", "attention_dropout", "=", "attention_dropout", ",", "\n", "activation_dropout", "=", "activation_dropout", ",", "\n", "activation_fn", "=", "activation_fn", ",", "\n", "export", "=", "export", ",", "\n", "is_bidirectional", "=", "is_bidirectional", ",", "\n", "stride", "=", "stride", ",", "\n", "expressivity", "=", "expressivity", ",", "\n", ")", "\n", "for", "_", "in", "range", "(", "num_encoder_layers", ")", "\n", "]", "\n", ")", "\n", "\n", "def", "freeze_module_params", "(", "m", ")", ":", "\n", "            ", "if", "m", "is", "not", "None", ":", "\n", "                ", "for", "p", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                    ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "", "for", "layer", "in", "range", "(", "n_trans_layers_to_freeze", ")", ":", "\n", "            ", "freeze_module_params", "(", "self", ".", "layers", "[", "layer", "]", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.transpose_last.TransposeLast.__init__": [[13, 16], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "deconstruct_idx", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "deconstruct_idx", "=", "deconstruct_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transpose_last.TransposeLast.forward": [[17, 21], ["x.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "deconstruct_idx", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "[", "self", ".", "deconstruct_idx", "]", "\n", "", "return", "x", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.qact.ActivationQuantizer.__init__": [[36, 54], ["qact.ActivationQuantizer.register_hook"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.qact.ActivationQuantizer.register_hook"], ["def", "__init__", "(", "\n", "self", ",", "\n", "module", ",", "\n", "p", "=", "1", ",", "\n", "update_step", "=", "1000", ",", "\n", "bits", "=", "8", ",", "\n", "method", "=", "\"histogram\"", ",", "\n", "clamp_threshold", "=", "5", ",", "\n", ")", ":", "\n", "        ", "self", ".", "module", "=", "module", "\n", "self", ".", "p", "=", "p", "\n", "self", ".", "update_step", "=", "update_step", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "bits", "=", "bits", "\n", "self", ".", "method", "=", "method", "\n", "self", ".", "clamp_threshold", "=", "clamp_threshold", "\n", "self", ".", "handle", "=", "None", "\n", "self", ".", "register_hook", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qact.ActivationQuantizer.register_hook": [[55, 89], ["qact.ActivationQuantizer.module.register_forward_hook", "ops.emulate_int", "torch.zeros_like", "torch.zeros_like.bernoulli_", "y.detach", "torch.zeros_like.bool", "torch.clamp", "noise.detach", "clamp_low.item", "clamp_high.item"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scalar.ops.emulate_int", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "def", "register_hook", "(", "self", ")", ":", "\n", "# forward hook", "\n", "        ", "def", "quantize_hook", "(", "module", ",", "x", ",", "y", ")", ":", "\n", "\n", "# update parameters every 1000 iterations", "\n", "            ", "if", "self", ".", "counter", "%", "self", ".", "update_step", "==", "0", ":", "\n", "                ", "self", ".", "scale", "=", "None", "\n", "self", ".", "zero_point", "=", "None", "\n", "", "self", ".", "counter", "+=", "1", "\n", "\n", "# train with QuantNoise and evaluate the fully quantized network", "\n", "p", "=", "self", ".", "p", "if", "self", ".", "module", ".", "training", "else", "1", "\n", "\n", "# quantize activations", "\n", "y_q", ",", "self", ".", "scale", ",", "self", ".", "zero_point", "=", "emulate_int", "(", "\n", "y", ".", "detach", "(", ")", ",", "\n", "bits", "=", "self", ".", "bits", ",", "\n", "method", "=", "self", ".", "method", ",", "\n", "scale", "=", "self", ".", "scale", ",", "\n", "zero_point", "=", "self", ".", "zero_point", ",", "\n", ")", "\n", "\n", "# mask to apply noise", "\n", "mask", "=", "torch", ".", "zeros_like", "(", "y", ")", "\n", "mask", ".", "bernoulli_", "(", "1", "-", "p", ")", "\n", "noise", "=", "(", "y_q", "-", "y", ")", ".", "masked_fill", "(", "mask", ".", "bool", "(", ")", ",", "0", ")", "\n", "\n", "# using straight-through estimator (STE)", "\n", "clamp_low", "=", "-", "self", ".", "scale", "*", "self", ".", "zero_point", "\n", "clamp_high", "=", "self", ".", "scale", "*", "(", "2", "**", "self", ".", "bits", "-", "1", "-", "self", ".", "zero_point", ")", "\n", "return", "torch", ".", "clamp", "(", "y", ",", "clamp_low", ".", "item", "(", ")", ",", "clamp_high", ".", "item", "(", ")", ")", "+", "noise", ".", "detach", "(", ")", "\n", "\n", "# register hook", "\n", "", "self", ".", "handle", "=", "self", ".", "module", ".", "register_forward_hook", "(", "quantize_hook", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.qlinear.IntLinear.__init__": [[35, 62], ["torch.Module.__init__", "int", "int", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "qlinear.IntLinear.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "qlinear.IntLinear.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_features", ",", "\n", "out_features", ",", "\n", "bias", "=", "True", ",", "\n", "p", "=", "0", ",", "\n", "update_step", "=", "3000", ",", "\n", "bits", "=", "8", ",", "\n", "method", "=", "\"histogram\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", "IntLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "int", "(", "in_features", ")", "\n", "self", ".", "out_features", "=", "int", "(", "out_features", ")", "\n", "self", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ",", "in_features", ")", ")", "\n", "self", ".", "chosen_bias", "=", "bias", "\n", "if", "self", ".", "chosen_bias", ":", "\n", "            ", "self", ".", "bias", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "\"bias\"", ",", "None", ")", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n", "# quantization parameters", "\n", "self", ".", "p", "=", "p", "\n", "self", ".", "bits", "=", "bits", "\n", "self", ".", "method", "=", "method", "\n", "self", ".", "update_step", "=", "update_step", "\n", "self", ".", "counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qlinear.IntLinear.reset_parameters": [[63, 68], ["torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "weight", ")", "\n", "if", "self", ".", "chosen_bias", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0.0", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qlinear.IntLinear.forward": [[69, 104], ["ops.emulate_int", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like.bernoulli_", "torch.zeros_like.bernoulli_", "torch.zeros_like.bernoulli_", "torch.linear", "torch.linear", "torch.linear", "qlinear.IntLinear.weight.detach", "torch.zeros_like.bool", "torch.zeros_like.bool", "torch.zeros_like.bool", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "noise.detach", "clamp_low.item", "clamp_high.item"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scalar.ops.emulate_int", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# train with QuantNoise and evaluate the fully quantized network", "\n", "        ", "p", "=", "self", ".", "p", "if", "self", ".", "training", "else", "1", "\n", "\n", "# update parameters every 100 iterations", "\n", "if", "self", ".", "counter", "%", "self", ".", "update_step", "==", "0", ":", "\n", "            ", "self", ".", "scale", "=", "None", "\n", "self", ".", "zero_point", "=", "None", "\n", "", "self", ".", "counter", "+=", "1", "\n", "\n", "# quantize weight", "\n", "weight_quantized", ",", "self", ".", "scale", ",", "self", ".", "zero_point", "=", "emulate_int", "(", "\n", "self", ".", "weight", ".", "detach", "(", ")", ",", "\n", "bits", "=", "self", ".", "bits", ",", "\n", "method", "=", "self", ".", "method", ",", "\n", "scale", "=", "self", ".", "scale", ",", "\n", "zero_point", "=", "self", ".", "zero_point", ",", "\n", ")", "\n", "\n", "# mask to apply noise", "\n", "mask", "=", "torch", ".", "zeros_like", "(", "self", ".", "weight", ")", "\n", "mask", ".", "bernoulli_", "(", "1", "-", "p", ")", "\n", "noise", "=", "(", "weight_quantized", "-", "self", ".", "weight", ")", ".", "masked_fill", "(", "mask", ".", "bool", "(", ")", ",", "0", ")", "\n", "\n", "# using straight-through estimator (STE)", "\n", "clamp_low", "=", "-", "self", ".", "scale", "*", "self", ".", "zero_point", "\n", "clamp_high", "=", "self", ".", "scale", "*", "(", "2", "**", "self", ".", "bits", "-", "1", "-", "self", ".", "zero_point", ")", "\n", "weight", "=", "(", "\n", "torch", ".", "clamp", "(", "self", ".", "weight", ",", "clamp_low", ".", "item", "(", ")", ",", "clamp_high", ".", "item", "(", ")", ")", "\n", "+", "noise", ".", "detach", "(", ")", "\n", ")", "\n", "\n", "# return output", "\n", "output", "=", "F", ".", "linear", "(", "input", ",", "weight", ",", "self", ".", "bias", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qlinear.IntLinear.extra_repr": [[105, 113], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "\"in_features={}, out_features={}, bias={}, quant_noise={}, bits={}, method={}\"", ".", "format", "(", "\n", "self", ".", "in_features", ",", "\n", "self", ".", "out_features", ",", "\n", "self", ".", "bias", "is", "not", "None", ",", "\n", "self", ".", "p", ",", "\n", "self", ".", "bits", ",", "\n", "self", ".", "method", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qconv.IntConv2d.__init__": [[34, 74], ["torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.conv._ConvNd.__init__", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "bias", "=", "True", ",", "\n", "padding_mode", "=", "\"zeros\"", ",", "\n", "p", "=", "0", ",", "\n", "bits", "=", "8", ",", "\n", "method", "=", "\"histogram\"", ",", "\n", "update_step", "=", "1000", ",", "\n", ")", ":", "\n", "        ", "kernel_size", "=", "_pair", "(", "kernel_size", ")", "\n", "stride", "=", "_pair", "(", "stride", ")", "\n", "padding", "=", "_pair", "(", "padding", ")", "\n", "dilation", "=", "_pair", "(", "dilation", ")", "\n", "super", "(", "IntConv2d", ",", "self", ")", ".", "__init__", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "stride", ",", "\n", "padding", ",", "\n", "dilation", ",", "\n", "False", ",", "\n", "_pair", "(", "0", ")", ",", "\n", "groups", ",", "\n", "bias", ",", "\n", "padding_mode", ",", "\n", ")", "\n", "\n", "# quantization parameters", "\n", "self", ".", "p", "=", "p", "\n", "self", ".", "bits", "=", "bits", "\n", "self", ".", "method", "=", "method", "\n", "self", ".", "update_step", "=", "update_step", "\n", "self", ".", "counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qconv.IntConv2d._conv_forward": [[75, 94], ["torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.pad", "torch.pad", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair"], ["", "def", "_conv_forward", "(", "self", ",", "input", ",", "weight", ")", ":", "\n", "        ", "if", "self", ".", "padding_mode", "!=", "\"zeros\"", ":", "\n", "            ", "return", "F", ".", "conv2d", "(", "\n", "F", ".", "pad", "(", "input", ",", "self", ".", "_padding_repeated_twice", ",", "mode", "=", "self", ".", "padding_mode", ")", ",", "\n", "weight", ",", "\n", "self", ".", "bias", ",", "\n", "self", ".", "stride", ",", "\n", "_pair", "(", "0", ")", ",", "\n", "self", ".", "dilation", ",", "\n", "self", ".", "groups", ",", "\n", ")", "\n", "", "return", "F", ".", "conv2d", "(", "\n", "input", ",", "\n", "weight", ",", "\n", "self", ".", "bias", ",", "\n", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "\n", "self", ".", "dilation", ",", "\n", "self", ".", "groups", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qconv.IntConv2d.forward": [[96, 131], ["ops.emulate_int", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like.bernoulli_", "torch.zeros_like.bernoulli_", "qconv.IntConv2d._conv_forward", "qconv.IntConv2d.weight.detach", "torch.zeros_like.bool", "torch.zeros_like.bool", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "noise.detach", "clamp_low.item", "clamp_high.item"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scalar.ops.emulate_int", "home.repos.pwc.inspect_result.reneeye_const.modules.qconv.IntConv2d._conv_forward", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# train with QuantNoise and evaluate the fully quantized network", "\n", "        ", "p", "=", "self", ".", "p", "if", "self", ".", "training", "else", "1", "\n", "\n", "# update parameters every 100 iterations", "\n", "if", "self", ".", "counter", "%", "self", ".", "update_step", "==", "0", ":", "\n", "            ", "self", ".", "scale", "=", "None", "\n", "self", ".", "zero_point", "=", "None", "\n", "", "self", ".", "counter", "+=", "1", "\n", "\n", "# quantize weight", "\n", "weight_quantized", ",", "self", ".", "scale", ",", "self", ".", "zero_point", "=", "emulate_int", "(", "\n", "self", ".", "weight", ".", "detach", "(", ")", ",", "\n", "bits", "=", "self", ".", "bits", ",", "\n", "method", "=", "self", ".", "method", ",", "\n", "scale", "=", "self", ".", "scale", ",", "\n", "zero_point", "=", "self", ".", "zero_point", ",", "\n", ")", "\n", "\n", "# mask to apply noise", "\n", "mask", "=", "torch", ".", "zeros_like", "(", "self", ".", "weight", ")", "\n", "mask", ".", "bernoulli_", "(", "1", "-", "p", ")", "\n", "noise", "=", "(", "weight_quantized", "-", "self", ".", "weight", ")", ".", "masked_fill", "(", "mask", ".", "bool", "(", ")", ",", "0", ")", "\n", "\n", "# using straight-through estimator (STE)", "\n", "clamp_low", "=", "-", "self", ".", "scale", "*", "self", ".", "zero_point", "\n", "clamp_high", "=", "self", ".", "scale", "*", "(", "2", "**", "self", ".", "bits", "-", "1", "-", "self", ".", "zero_point", ")", "\n", "weight", "=", "(", "\n", "torch", ".", "clamp", "(", "self", ".", "weight", ",", "clamp_low", ".", "item", "(", ")", ",", "clamp_high", ".", "item", "(", ")", ")", "\n", "+", "noise", ".", "detach", "(", ")", "\n", ")", "\n", "\n", "# return output", "\n", "output", "=", "self", ".", "_conv_forward", "(", "input", ",", "weight", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qconv.IntConv2d.extra_repr": [[132, 148], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "\"in_channels={}, out_channels={}, kernel_size={}, stride={}, \"", "\n", "\"padding={}, dilation={}, groups={}, bias={}, quant_noise={}, \"", "\n", "\"bits={}, method={}\"", ".", "format", "(", "\n", "self", ".", "in_channels", ",", "\n", "self", ".", "out_channels", ",", "\n", "self", ".", "kernel_size", ",", "\n", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "\n", "self", ".", "dilation", ",", "\n", "self", ".", "groups", ",", "\n", "self", ".", "bias", "is", "not", "None", ",", "\n", "self", ".", "p", ",", "\n", "self", ".", "bits", ",", "\n", "self", ".", "method", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qemb.IntEmbedding.__init__": [[34, 83], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "qemb.IntEmbedding.reset_parameters", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "list"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters"], ["def", "__init__", "(", "\n", "self", ",", "\n", "num_embeddings", ",", "\n", "embedding_dim", ",", "\n", "padding_idx", "=", "None", ",", "\n", "max_norm", "=", "None", ",", "\n", "norm_type", "=", "2.0", ",", "\n", "scale_grad_by_freq", "=", "False", ",", "\n", "sparse", "=", "False", ",", "\n", "_weight", "=", "None", ",", "\n", "p", "=", "0", ",", "\n", "update_step", "=", "1000", ",", "\n", "bits", "=", "8", ",", "\n", "method", "=", "\"histogram\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", "IntEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_embeddings", "=", "num_embeddings", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "if", "padding_idx", "is", "not", "None", ":", "\n", "            ", "if", "padding_idx", ">", "0", ":", "\n", "                ", "assert", "(", "\n", "padding_idx", "<", "self", ".", "num_embeddings", "\n", ")", ",", "\"Padding_idx must be within num_embeddings\"", "\n", "", "elif", "padding_idx", "<", "0", ":", "\n", "                ", "assert", "(", "\n", "padding_idx", ">=", "-", "self", ".", "num_embeddings", "\n", ")", ",", "\"Padding_idx must be within num_embeddings\"", "\n", "padding_idx", "=", "self", ".", "num_embeddings", "+", "padding_idx", "\n", "", "", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "max_norm", "=", "max_norm", "\n", "self", ".", "norm_type", "=", "norm_type", "\n", "self", ".", "scale_grad_by_freq", "=", "scale_grad_by_freq", "\n", "if", "_weight", "is", "None", ":", "\n", "            ", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_embeddings", ",", "embedding_dim", ")", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "", "else", ":", "\n", "            ", "assert", "list", "(", "_weight", ".", "shape", ")", "==", "[", "\n", "num_embeddings", ",", "\n", "embedding_dim", ",", "\n", "]", ",", "\"Shape of weight does not match num_embeddings and embedding_dim\"", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "_weight", ")", "\n", "", "self", ".", "sparse", "=", "sparse", "\n", "\n", "# quantization parameters", "\n", "self", ".", "p", "=", "p", "\n", "self", ".", "bits", "=", "bits", "\n", "self", ".", "method", "=", "method", "\n", "self", ".", "update_step", "=", "update_step", "\n", "self", ".", "counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qemb.IntEmbedding.reset_parameters": [[84, 89], ["torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "qemb.IntEmbedding.weight[].fill_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "weight", ")", "\n", "if", "self", ".", "padding_idx", "is", "not", "None", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "weight", "[", "self", ".", "padding_idx", "]", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qemb.IntEmbedding.forward": [[90, 133], ["ops.emulate_int", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like.bernoulli_", "torch.zeros_like.bernoulli_", "torch.zeros_like.bernoulli_", "torch.embedding", "torch.embedding", "torch.embedding", "qemb.IntEmbedding.weight.detach", "torch.zeros_like.bool", "torch.zeros_like.bool", "torch.zeros_like.bool", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "noise.detach", "clamp_low.item", "clamp_high.item"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scalar.ops.emulate_int", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# train with QuantNoise and evaluate the fully quantized network", "\n", "        ", "p", "=", "self", ".", "p", "if", "self", ".", "training", "else", "1", "\n", "\n", "# update parameters every 1000 iterations", "\n", "if", "self", ".", "counter", "%", "self", ".", "update_step", "==", "0", ":", "\n", "            ", "self", ".", "scale", "=", "None", "\n", "self", ".", "zero_point", "=", "None", "\n", "", "self", ".", "counter", "+=", "1", "\n", "\n", "# quantize weight", "\n", "weight_quantized", ",", "self", ".", "scale", ",", "self", ".", "zero_point", "=", "emulate_int", "(", "\n", "self", ".", "weight", ".", "detach", "(", ")", ",", "\n", "bits", "=", "self", ".", "bits", ",", "\n", "method", "=", "self", ".", "method", ",", "\n", "scale", "=", "self", ".", "scale", ",", "\n", "zero_point", "=", "self", ".", "zero_point", ",", "\n", ")", "\n", "\n", "# mask to apply noise", "\n", "mask", "=", "torch", ".", "zeros_like", "(", "self", ".", "weight", ")", "\n", "mask", ".", "bernoulli_", "(", "1", "-", "p", ")", "\n", "noise", "=", "(", "weight_quantized", "-", "self", ".", "weight", ")", ".", "masked_fill", "(", "mask", ".", "bool", "(", ")", ",", "0", ")", "\n", "\n", "# using straight-through estimator (STE)", "\n", "clamp_low", "=", "-", "self", ".", "scale", "*", "self", ".", "zero_point", "\n", "clamp_high", "=", "self", ".", "scale", "*", "(", "2", "**", "self", ".", "bits", "-", "1", "-", "self", ".", "zero_point", ")", "\n", "weight", "=", "(", "\n", "torch", ".", "clamp", "(", "self", ".", "weight", ",", "clamp_low", ".", "item", "(", ")", ",", "clamp_high", ".", "item", "(", ")", ")", "\n", "+", "noise", ".", "detach", "(", ")", "\n", ")", "\n", "\n", "# return output", "\n", "output", "=", "F", ".", "embedding", "(", "\n", "input", ",", "\n", "weight", ",", "\n", "self", ".", "padding_idx", ",", "\n", "self", ".", "max_norm", ",", "\n", "self", ".", "norm_type", ",", "\n", "self", ".", "scale_grad_by_freq", ",", "\n", "self", ".", "sparse", ",", "\n", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qemb.IntEmbedding.extra_repr": [[134, 148], ["s.format"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "s", "=", "\"{num_embeddings}, {embedding_dim}\"", "\n", "if", "self", ".", "padding_idx", "is", "not", "None", ":", "\n", "            ", "s", "+=", "\", padding_idx={padding_idx}\"", "\n", "", "if", "self", ".", "max_norm", "is", "not", "None", ":", "\n", "            ", "s", "+=", "\", max_norm={max_norm}\"", "\n", "", "if", "self", ".", "norm_type", "!=", "2", ":", "\n", "            ", "s", "+=", "\", norm_type={norm_type}\"", "\n", "", "if", "self", ".", "scale_grad_by_freq", "is", "not", "False", ":", "\n", "            ", "s", "+=", "\", scale_grad_by_freq={scale_grad_by_freq}\"", "\n", "", "if", "self", ".", "sparse", "is", "not", "False", ":", "\n", "            ", "s", "+=", "\", sparse=True\"", "\n", "", "s", "+=", "\"quant_noise={p}, bits={bits}, method={method}\"", "\n", "return", "s", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.modules.qlinear.PQLinear.__init__": [[30, 49], ["torch.Module.__init__", "centroids.size", "centroids.size", "torch.Parameter", "torch.Parameter", "torch.Parameter", "qlinear.PQLinear.register_buffer", "qlinear.PQLinear.register_buffer", "ValueError", "ValueError", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.Parameter", "torch.Parameter", "torch.Parameter", "qlinear.PQLinear.register_parameter", "len", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "in_features", ",", "\n", "out_features", ",", "\n", "bias", "=", "True", ",", "\n", "p", "=", "0", ",", "\n", "update_step", "=", "3000", ",", "\n", "bits", "=", "8", ",", "\n", "method", "=", "\"histogram\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", "IntLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "int", "(", "in_features", ")", "\n", "self", ".", "out_features", "=", "int", "(", "out_features", ")", "\n", "self", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ",", "in_features", ")", ")", "\n", "self", ".", "chosen_bias", "=", "bias", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qlinear.PQLinear.weight": [[50, 57], ["qlinear.PQLinear.centroids[].reshape().permute().flatten", "qlinear.PQLinear.centroids[].reshape().permute", "qlinear.PQLinear.centroids[].reshape"], "methods", ["None"], ["if", "self", ".", "chosen_bias", ":", "\n", "            ", "self", ".", "bias", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "\"bias\"", ",", "None", ")", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n", "# quantization parameters", "\n", "self", ".", "p", "=", "p", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qlinear.PQLinear.forward": [[59, 64], ["torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["self", ".", "method", "=", "method", "\n", "self", ".", "update_step", "=", "update_step", "\n", "self", ".", "counter", "=", "0", "\n", "\n", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "weight", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qlinear.PQLinear.extra_repr": [[66, 72], ["None"], "methods", ["None"], ["            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0.0", ")", "\n", "", "return", "\n", "\n", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# train with QuantNoise and evaluate the fully quantized network", "\n", "        ", "p", "=", "self", ".", "p", "if", "self", ".", "training", "else", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qconv.PQConv2d.__init__": [[35, 79], ["torch.Module.__init__", "centroids.size", "centroids.size", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.Parameter", "torch.Parameter", "torch.Parameter", "qconv.PQConv2d.register_buffer", "qconv.PQConv2d.register_buffer", "qconv.PQConv2d.centroids.register_hook", "ValueError", "ValueError", "ValueError", "ValueError", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.Parameter", "torch.Parameter", "torch.Parameter", "qconv.PQConv2d.register_parameter", "len", "numpy.prod", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.vggblock._pair", "home.repos.pwc.inspect_result.reneeye_const.modules.qact.ActivationQuantizer.register_hook"], ["self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "bias", "=", "True", ",", "\n", "padding_mode", "=", "\"zeros\"", ",", "\n", "p", "=", "0", ",", "\n", "bits", "=", "8", ",", "\n", "method", "=", "\"histogram\"", ",", "\n", "update_step", "=", "1000", ",", "\n", ")", ":", "\n", "        ", "kernel_size", "=", "_pair", "(", "kernel_size", ")", "\n", "stride", "=", "_pair", "(", "stride", ")", "\n", "padding", "=", "_pair", "(", "padding", ")", "\n", "dilation", "=", "_pair", "(", "dilation", ")", "\n", "super", "(", "IntConv2d", ",", "self", ")", ".", "__init__", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "stride", ",", "\n", "padding", ",", "\n", "dilation", ",", "\n", "False", ",", "\n", "_pair", "(", "0", ")", ",", "\n", "groups", ",", "\n", "bias", ",", "\n", "padding_mode", ",", "\n", ")", "\n", "\n", "# quantization parameters", "\n", "self", ".", "p", "=", "p", "\n", "self", ".", "bits", "=", "bits", "\n", "self", ".", "method", "=", "method", "\n", "self", ".", "update_step", "=", "update_step", "\n", "self", ".", "counter", "=", "0", "\n", "\n", "", "def", "_conv_forward", "(", "self", ",", "input", ",", "weight", ")", ":", "\n", "        ", "if", "self", ".", "padding_mode", "!=", "\"zeros\"", ":", "\n", "            ", "return", "F", ".", "conv2d", "(", "\n", "F", ".", "pad", "(", "input", ",", "self", ".", "_padding_repeated_twice", ",", "mode", "=", "self", ".", "padding_mode", ")", ",", "\n", "weight", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qconv.PQConv2d.weight": [[80, 88], ["qconv.PQConv2d.centroids[].reshape().permute().reshape", "qconv.PQConv2d.centroids[].reshape().permute", "qconv.PQConv2d.centroids[].reshape"], "methods", ["None"], ["self", ".", "bias", ",", "\n", "self", ".", "stride", ",", "\n", "_pair", "(", "0", ")", ",", "\n", "self", ".", "dilation", ",", "\n", "self", ".", "groups", ",", "\n", ")", "\n", "", "return", "F", ".", "conv2d", "(", "\n", "input", ",", "\n", "weight", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qconv.PQConv2d.forward": [[91, 100], ["torch.conv2d", "torch.conv2d", "torch.conv2d"], "methods", ["None"], ["self", ".", "padding", ",", "\n", "self", ".", "dilation", ",", "\n", "self", ".", "groups", ",", "\n", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# train with QuantNoise and evaluate the fully quantized network", "\n", "        ", "p", "=", "self", ".", "p", "if", "self", ".", "training", "else", "1", "\n", "\n", "# update parameters every 100 iterations", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qconv.PQConv2d.extra_repr": [[102, 116], ["s.format", "len", "len"], "methods", ["None"], ["            ", "self", ".", "scale", "=", "None", "\n", "self", ".", "zero_point", "=", "None", "\n", "", "self", ".", "counter", "+=", "1", "\n", "\n", "# quantize weight", "\n", "weight_quantized", ",", "self", ".", "scale", ",", "self", ".", "zero_point", "=", "emulate_int", "(", "\n", "self", ".", "weight", ".", "detach", "(", ")", ",", "\n", "bits", "=", "self", ".", "bits", ",", "\n", "method", "=", "self", ".", "method", ",", "\n", "scale", "=", "self", ".", "scale", ",", "\n", "zero_point", "=", "self", ".", "zero_point", ",", "\n", ")", "\n", "\n", "# mask to apply noise", "\n", "mask", "=", "torch", ".", "zeros_like", "(", "self", ".", "weight", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qemb.PQEmbedding.__init__": [[30, 72], ["torch.Module.__init__", "centroids.size", "centroids.size", "torch.Parameter", "torch.Parameter", "torch.Parameter", "qemb.PQEmbedding.register_buffer", "qemb.PQEmbedding.register_buffer", "ValueError", "ValueError", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "torch.bincount().type_as", "len", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "num_embeddings", ",", "\n", "embedding_dim", ",", "\n", "padding_idx", "=", "None", ",", "\n", "max_norm", "=", "None", ",", "\n", "norm_type", "=", "2.0", ",", "\n", "scale_grad_by_freq", "=", "False", ",", "\n", "sparse", "=", "False", ",", "\n", "_weight", "=", "None", ",", "\n", "p", "=", "0", ",", "\n", "update_step", "=", "1000", ",", "\n", "bits", "=", "8", ",", "\n", "method", "=", "\"histogram\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", "IntEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_embeddings", "=", "num_embeddings", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "if", "padding_idx", "is", "not", "None", ":", "\n", "            ", "if", "padding_idx", ">", "0", ":", "\n", "                ", "assert", "(", "\n", "padding_idx", "<", "self", ".", "num_embeddings", "\n", ")", ",", "\"Padding_idx must be within num_embeddings\"", "\n", "", "elif", "padding_idx", "<", "0", ":", "\n", "                ", "assert", "(", "\n", "padding_idx", ">=", "-", "self", ".", "num_embeddings", "\n", ")", ",", "\"Padding_idx must be within num_embeddings\"", "\n", "padding_idx", "=", "self", ".", "num_embeddings", "+", "padding_idx", "\n", "", "", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "max_norm", "=", "max_norm", "\n", "self", ".", "norm_type", "=", "norm_type", "\n", "self", ".", "scale_grad_by_freq", "=", "scale_grad_by_freq", "\n", "if", "_weight", "is", "None", ":", "\n", "            ", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_embeddings", ",", "embedding_dim", ")", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "", "else", ":", "\n", "            ", "assert", "list", "(", "_weight", ".", "shape", ")", "==", "[", "\n", "num_embeddings", ",", "\n", "embedding_dim", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qemb.PQEmbedding.weight": [[73, 80], ["qemb.PQEmbedding.centroids[].reshape().permute().flatten", "qemb.PQEmbedding.centroids[].reshape().permute", "qemb.PQEmbedding.centroids[].reshape"], "methods", ["None"], ["]", ",", "\"Shape of weight does not match num_embeddings and embedding_dim\"", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "_weight", ")", "\n", "", "self", ".", "sparse", "=", "sparse", "\n", "\n", "# quantization parameters", "\n", "self", ".", "p", "=", "p", "\n", "self", ".", "bits", "=", "bits", "\n", "self", ".", "method", "=", "method", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qemb.PQEmbedding.forward": [[82, 91], ["torch.embedding", "torch.embedding", "torch.embedding"], "methods", ["None"], ["self", ".", "counter", "=", "0", "\n", "\n", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "weight", ")", "\n", "if", "self", ".", "padding_idx", "is", "not", "None", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "weight", "[", "self", ".", "padding_idx", "]", ".", "fill_", "(", "0", ")", "\n", "\n", "", "", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# train with QuantNoise and evaluate the fully quantized network", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.qemb.PQEmbedding.extra_repr": [[93, 108], ["s.format"], "methods", ["None"], ["\n", "# update parameters every 1000 iterations", "\n", "if", "self", ".", "counter", "%", "self", ".", "update_step", "==", "0", ":", "\n", "            ", "self", ".", "scale", "=", "None", "\n", "self", ".", "zero_point", "=", "None", "\n", "", "self", ".", "counter", "+=", "1", "\n", "\n", "# quantize weight", "\n", "weight_quantized", ",", "self", ".", "scale", ",", "self", ".", "zero_point", "=", "emulate_int", "(", "\n", "self", ".", "weight", ".", "detach", "(", ")", ",", "\n", "bits", "=", "self", ".", "bits", ",", "\n", "method", "=", "self", ".", "method", ",", "\n", "scale", "=", "self", ".", "scale", ",", "\n", "zero_point", "=", "self", ".", "zero_point", ",", "\n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_sentence_encoder_layer.ModelParallelTransformerSentenceEncoderLayer.build_fc1": [[30, 32], ["ColumnParallelLinear"], "methods", ["None"], ["activation_fn", ":", "str", "=", "\"relu\"", ",", "\n", "export", ":", "bool", "=", "False", ",", "\n", "q_noise", ":", "float", "=", "0.0", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_sentence_encoder_layer.ModelParallelTransformerSentenceEncoderLayer.build_fc2": [[33, 35], ["RowParallelLinear"], "methods", ["None"], ["qn_block_size", ":", "int", "=", "8", ",", "\n", "init_fn", ":", "Callable", "=", "None", ",", "\n", ")", "->", "None", ":", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_sentence_encoder_layer.ModelParallelTransformerSentenceEncoderLayer.build_self_attention": [[36, 45], ["fairseq.model_parallel.modules.ModelParallelMultiheadAttention"], "methods", ["None"], ["        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "init_fn", "is", "not", "None", ":", "\n", "            ", "init_fn", "(", ")", "\n", "\n", "# Initialize parameters", "\n", "", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_sentence_encoder_layer.ModelParallelTransformerSentenceEncoderLayer.forward": [[47, 78], ["transformer_sentence_encoder_layer.ModelParallelTransformerSentenceEncoderLayer.self_attn_layer_norm", "transformer_sentence_encoder_layer.ModelParallelTransformerSentenceEncoderLayer.self_attn", "transformer_sentence_encoder_layer.ModelParallelTransformerSentenceEncoderLayer.dropout_module", "transformer_sentence_encoder_layer.ModelParallelTransformerSentenceEncoderLayer.final_layer_norm", "transformer_sentence_encoder_layer.ModelParallelTransformerSentenceEncoderLayer.activation_fn", "transformer_sentence_encoder_layer.ModelParallelTransformerSentenceEncoderLayer.activation_dropout_module", "transformer_sentence_encoder_layer.ModelParallelTransformerSentenceEncoderLayer.fc2", "transformer_sentence_encoder_layer.ModelParallelTransformerSentenceEncoderLayer.dropout_module", "transformer_sentence_encoder_layer.ModelParallelTransformerSentenceEncoderLayer.fc1"], "methods", ["None"], ["activation_dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "\n", "# Initialize blocks", "\n", "self", ".", "activation_fn", "=", "utils", ".", "get_activation_fn", "(", "activation_fn", ")", "\n", "self", ".", "self_attn", "=", "self", ".", "build_self_attention", "(", "\n", "self", ".", "embedding_dim", ",", "\n", "num_attention_heads", ",", "\n", "dropout", "=", "attention_dropout", ",", "\n", "self_attention", "=", "True", ",", "\n", "q_noise", "=", "q_noise", ",", "\n", "qn_block_size", "=", "qn_block_size", ",", "\n", ")", "\n", "\n", "# layer norm associated with the self attention layer", "\n", "self", ".", "self_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embedding_dim", ",", "export", "=", "export", ")", "\n", "\n", "self", ".", "fc1", "=", "self", ".", "build_fc1", "(", "\n", "self", ".", "embedding_dim", ",", "\n", "ffn_embedding_dim", ",", "\n", "q_noise", "=", "q_noise", ",", "\n", "qn_block_size", "=", "qn_block_size", ",", "\n", ")", "\n", "self", ".", "fc2", "=", "self", ".", "build_fc2", "(", "\n", "ffn_embedding_dim", ",", "\n", "self", ".", "embedding_dim", ",", "\n", "q_noise", "=", "q_noise", ",", "\n", "qn_block_size", "=", "qn_block_size", ",", "\n", ")", "\n", "\n", "# layer norm associated with the position wise feed-forward NN", "\n", "self", ".", "final_layer_norm", "=", "LayerNorm", "(", "self", ".", "embedding_dim", ",", "export", "=", "export", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.ModelParallelMultiheadAttention.__init__": [[37, 97], ["torch.nn.Module.__init__", "get_model_parallel_world_size", "fairseq.modules.fairseq_dropout.FairseqDropout", "ColumnParallelLinear", "ColumnParallelLinear", "ColumnParallelLinear", "RowParallelLinear", "ImportError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_model_parallel_world_size"], ["encoder_decoder_attention", "=", "False", ",", "\n", "q_noise", "=", "0.0", ",", "\n", "qn_block_size", "=", "8", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "kdim", "=", "kdim", "if", "kdim", "is", "not", "None", "else", "embed_dim", "\n", "self", ".", "vdim", "=", "vdim", "if", "vdim", "is", "not", "None", "else", "embed_dim", "\n", "self", ".", "qkv_same_dim", "=", "self", ".", "kdim", "==", "embed_dim", "and", "self", ".", "vdim", "==", "embed_dim", "\n", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "assert", "(", "\n", "self", ".", "head_dim", "*", "num_heads", "==", "self", ".", "embed_dim", "\n", ")", ",", "\"embed_dim must be divisible by num_heads\"", "\n", "self", ".", "scaling", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "self_attention", "=", "self_attention", "\n", "self", ".", "encoder_decoder_attention", "=", "encoder_decoder_attention", "\n", "\n", "assert", "not", "self", ".", "self_attention", "or", "self", ".", "qkv_same_dim", ",", "(", "\n", "\"Self-attention requires query, key and \"", "\"value to be of the same size\"", "\n", ")", "\n", "\n", "self", ".", "k_proj", "=", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "kdim", ",", "embed_dim", ",", "bias", "=", "bias", ")", ",", "q_noise", ",", "qn_block_size", "\n", ")", "\n", "self", ".", "v_proj", "=", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "vdim", ",", "embed_dim", ",", "bias", "=", "bias", ")", ",", "q_noise", ",", "qn_block_size", "\n", ")", "\n", "self", ".", "q_proj", "=", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "bias", ")", ",", "q_noise", ",", "qn_block_size", "\n", ")", "\n", "\n", "self", ".", "out_proj", "=", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "bias", ")", ",", "q_noise", ",", "qn_block_size", "\n", ")", "\n", "\n", "if", "add_bias_kv", ":", "\n", "            ", "self", ".", "bias_k", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "1", ",", "embed_dim", ")", ")", "\n", "self", ".", "bias_v", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "1", ",", "embed_dim", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias_k", "=", "self", ".", "bias_v", "=", "None", "\n", "\n", "", "self", ".", "add_zero_attn", "=", "add_zero_attn", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "self", ".", "tpu", "=", "False", "\n", "\n", "", "def", "prepare_for_onnx_export_", "(", "self", ")", ":", "\n", "        ", "self", ".", "onnx_trace", "=", "True", "\n", "\n", "", "def", "prepare_for_tpu_", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "tpu", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.ModelParallelMultiheadAttention.prepare_for_tpu_": [[98, 100], ["None"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "qkv_same_dim", ":", "\n", "# Empirically observed the convergence to be much better with", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.ModelParallelMultiheadAttention.forward": [[101, 287], ["query.size", "multihead_attention.ModelParallelMultiheadAttention.contiguous().view().transpose", "torch.cat.size", "torch.cat.size", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "fairseq.utils.softmax", "fairseq.utils.softmax.type_as", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "multihead_attention.ModelParallelMultiheadAttention.transpose().contiguous().view", "multihead_attention.ModelParallelMultiheadAttention.out_proj", "list", "multihead_attention.ModelParallelMultiheadAttention._get_input_buffer", "multihead_attention.ModelParallelMultiheadAttention.q_proj", "multihead_attention.ModelParallelMultiheadAttention.k_proj", "multihead_attention.ModelParallelMultiheadAttention.v_proj", "torch.cat.contiguous().view().transpose", "torch.cat.contiguous().view().transpose", "torch.cat.contiguous().view().transpose", "torch.cat.contiguous().view().transpose", "multihead_attention.ModelParallelMultiheadAttention._append_prev_key_padding_mask", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat.view", "multihead_attention.ModelParallelMultiheadAttention._set_input_buffer", "torch.cat.transpose", "torch.cat.transpose", "list", "attn_mask.unsqueeze.unsqueeze.unsqueeze", "attn_weights.transpose.transpose.view", "attn_weights.transpose.transpose.view", "get_cuda_rng_tracker().fork", "multihead_attention.ModelParallelMultiheadAttention.dropout_module", "list", "query.size", "multihead_attention.ModelParallelMultiheadAttention.q_proj", "multihead_attention.ModelParallelMultiheadAttention.q_proj", "multihead_attention.ModelParallelMultiheadAttention.k_proj", "multihead_attention.ModelParallelMultiheadAttention.v_proj", "multihead_attention.ModelParallelMultiheadAttention.contiguous().view", "_prev_key.view", "_prev_value.view", "multihead_attention.ModelParallelMultiheadAttention._append_prev_key_padding_mask", "multihead_attention.ModelParallelMultiheadAttention._append_prev_key_padding_mask", "multihead_attention.ModelParallelMultiheadAttention._append_prev_key_padding_mask", "attn_weights.transpose.transpose.size", "attn_weights.transpose.transpose.masked_fill", "attn_weights.transpose.transpose.transpose", "attn_weights.transpose.transpose.masked_fill", "attn_weights.transpose.transpose.transpose", "multihead_attention.ModelParallelMultiheadAttention.size", "multihead_attention.ModelParallelMultiheadAttention.transpose().contiguous", "multihead_attention.ModelParallelMultiheadAttention.k_proj", "multihead_attention.ModelParallelMultiheadAttention.v_proj", "torch.cat.contiguous().view", "torch.cat.contiguous().view", "torch.cat.contiguous().view", "torch.cat.contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "torch.cat.size", "multihead_attention.ModelParallelMultiheadAttention._append_prev_key_padding_mask", "float", "float", "get_cuda_rng_tracker", "multihead_attention.ModelParallelMultiheadAttention.contiguous", "multihead_attention.ModelParallelMultiheadAttention.transpose", "torch.cat.contiguous", "torch.cat.contiguous", "torch.cat.contiguous", "torch.cat.contiguous", "multihead_attention.ModelParallelMultiheadAttention._append_prev_key_padding_mask", "multihead_attention.ModelParallelMultiheadAttention._append_prev_key_padding_mask"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.ModelParallelMultiheadAttention._append_prev_key_padding_mask", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.ModelParallelMultiheadAttention._append_prev_key_padding_mask", "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.ModelParallelMultiheadAttention._append_prev_key_padding_mask", "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.ModelParallelMultiheadAttention._append_prev_key_padding_mask", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.ModelParallelMultiheadAttention._append_prev_key_padding_mask", "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.ModelParallelMultiheadAttention._append_prev_key_padding_mask", "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.ModelParallelMultiheadAttention._append_prev_key_padding_mask"], ["# the scaled initialization", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "k_proj", ".", "weight", ",", "gain", "=", "1", "/", "math", ".", "sqrt", "(", "2", ")", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "v_proj", ".", "weight", ",", "gain", "=", "1", "/", "math", ".", "sqrt", "(", "2", ")", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "q_proj", ".", "weight", ",", "gain", "=", "1", "/", "math", ".", "sqrt", "(", "2", ")", ")", "\n", "", "else", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "k_proj", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "v_proj", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "q_proj", ".", "weight", ")", "\n", "\n", "", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "out_proj", ".", "weight", ")", "\n", "if", "self", ".", "out_proj", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.0", ")", "\n", "", "if", "self", ".", "bias_k", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "bias_k", ")", "\n", "", "if", "self", ".", "bias_v", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "bias_v", ")", "\n", "\n", "", "", "def", "forward", "(", "\n", "self", ",", "\n", "query", ",", "\n", "key", ":", "Optional", "[", "Tensor", "]", ",", "\n", "value", ":", "Optional", "[", "Tensor", "]", ",", "\n", "key_padding_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", "=", "None", ",", "\n", "need_weights", ":", "bool", "=", "True", ",", "\n", "static_kv", ":", "bool", "=", "False", ",", "\n", "attn_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "before_softmax", ":", "bool", "=", "False", ",", "\n", "need_head_weights", ":", "bool", "=", "False", ",", "\n", ")", "->", "Tuple", "[", "Tensor", ",", "Optional", "[", "Tensor", "]", "]", ":", "\n", "        ", "\"\"\"Input shape: Time x Batch x Channel\n\n        Args:\n            key_padding_mask (ByteTensor, optional): mask to exclude\n                keys that are pads, of shape `(batch, src_len)`, where\n                padding elements are indicated by 1s.\n            need_weights (bool, optional): return the attention weights,\n                averaged over heads (default: False).\n            attn_mask (ByteTensor, optional): typically used to\n                implement causal attention, where the mask prevents the\n                attention from looking forward in time (default: None).\n            before_softmax (bool, optional): return the raw attention\n                weights and values before the attention softmax.\n            need_head_weights (bool, optional): return the attention\n                weights for each head. Implies *need_weights*. Default:\n                return the average attention weights over all heads.\n        \"\"\"", "\n", "if", "need_head_weights", ":", "\n", "            ", "need_weights", "=", "True", "\n", "\n", "", "tgt_len", ",", "bsz", ",", "embed_dim", "=", "query", ".", "size", "(", ")", "\n", "assert", "embed_dim", "==", "self", ".", "embed_dim", "\n", "assert", "list", "(", "query", ".", "size", "(", ")", ")", "==", "[", "tgt_len", ",", "bsz", ",", "embed_dim", "]", "\n", "\n", "if", "(", "\n", "not", "self", ".", "onnx_trace", "\n", "and", "not", "self", ".", "tpu", "# don't use PyTorch version on TPUs", "\n", "and", "incremental_state", "is", "None", "\n", "and", "not", "static_kv", "\n", "# A workaround for quantization to work. Otherwise JIT compilation", "\n", "# treats bias in linear module as method.", "\n", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", "\n", ")", ":", "\n", "            ", "assert", "key", "is", "not", "None", "and", "value", "is", "not", "None", "\n", "return", "F", ".", "multi_head_attention_forward", "(", "\n", "query", ",", "\n", "key", ",", "\n", "value", ",", "\n", "self", ".", "embed_dim", ",", "\n", "self", ".", "num_heads", ",", "\n", "torch", ".", "empty", "(", "[", "0", "]", ")", ",", "\n", "torch", ".", "cat", "(", "(", "self", ".", "q_proj", ".", "bias", ",", "self", ".", "k_proj", ".", "bias", ",", "self", ".", "v_proj", ".", "bias", ")", ")", ",", "\n", "self", ".", "bias_k", ",", "\n", "self", ".", "bias_v", ",", "\n", "self", ".", "add_zero_attn", ",", "\n", "self", ".", "dropout_module", ".", "p", ",", "\n", "self", ".", "out_proj", ".", "weight", ",", "\n", "self", ".", "out_proj", ".", "bias", ",", "\n", "self", ".", "training", "or", "self", ".", "dropout_module", ".", "apply_during_inference", ",", "\n", "key_padding_mask", ",", "\n", "need_weights", ",", "\n", "attn_mask", ",", "\n", "use_separate_proj_weight", "=", "True", ",", "\n", "q_proj_weight", "=", "self", ".", "q_proj", ".", "weight", ",", "\n", "k_proj_weight", "=", "self", ".", "k_proj", ".", "weight", ",", "\n", "v_proj_weight", "=", "self", ".", "v_proj", ".", "weight", ",", "\n", ")", "\n", "\n", "", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "saved_state", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "saved_state", "is", "not", "None", "and", "\"prev_key\"", "in", "saved_state", ":", "\n", "# previous time steps are cached - no need to recompute", "\n", "# key and value if they are static", "\n", "                ", "if", "static_kv", ":", "\n", "                    ", "assert", "self", ".", "encoder_decoder_attention", "and", "not", "self", ".", "self_attention", "\n", "key", "=", "value", "=", "None", "\n", "", "", "", "else", ":", "\n", "            ", "saved_state", "=", "None", "\n", "\n", "", "if", "self", ".", "self_attention", ":", "\n", "            ", "q", "=", "self", ".", "q_proj", "(", "query", ")", "\n", "k", "=", "self", ".", "k_proj", "(", "query", ")", "\n", "v", "=", "self", ".", "v_proj", "(", "query", ")", "\n", "", "elif", "self", ".", "encoder_decoder_attention", ":", "\n", "# encoder-decoder attention", "\n", "            ", "q", "=", "self", ".", "q_proj", "(", "query", ")", "\n", "if", "key", "is", "None", ":", "\n", "                ", "assert", "value", "is", "None", "\n", "k", "=", "v", "=", "None", "\n", "", "else", ":", "\n", "                ", "k", "=", "self", ".", "k_proj", "(", "key", ")", "\n", "v", "=", "self", ".", "v_proj", "(", "key", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "assert", "key", "is", "not", "None", "and", "value", "is", "not", "None", "\n", "q", "=", "self", ".", "q_proj", "(", "query", ")", "\n", "k", "=", "self", ".", "k_proj", "(", "key", ")", "\n", "v", "=", "self", ".", "v_proj", "(", "value", ")", "\n", "", "q", "*=", "self", ".", "scaling", "\n", "\n", "if", "self", ".", "bias_k", "is", "not", "None", ":", "\n", "            ", "assert", "self", ".", "bias_v", "is", "not", "None", "\n", "k", "=", "torch", ".", "cat", "(", "[", "k", ",", "self", ".", "bias_k", ".", "repeat", "(", "1", ",", "bsz", ",", "1", ")", "]", ")", "\n", "v", "=", "torch", ".", "cat", "(", "[", "v", ",", "self", ".", "bias_v", ".", "repeat", "(", "1", ",", "bsz", ",", "1", ")", "]", ")", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "                ", "attn_mask", "=", "torch", ".", "cat", "(", "\n", "[", "attn_mask", ",", "attn_mask", ".", "new_zeros", "(", "attn_mask", ".", "size", "(", "0", ")", ",", "1", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "                ", "key_padding_mask", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "key_padding_mask", ",", "\n", "key_padding_mask", ".", "new_zeros", "(", "key_padding_mask", ".", "size", "(", "0", ")", ",", "1", ")", ",", "\n", "]", ",", "\n", "dim", "=", "1", ",", "\n", ")", "\n", "\n", "", "", "q", "=", "(", "\n", "q", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "tgt_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", "\n", ".", "transpose", "(", "0", ",", "1", ")", "\n", ")", "\n", "if", "k", "is", "not", "None", ":", "\n", "            ", "k", "=", "(", "\n", "k", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", "\n", ".", "transpose", "(", "0", ",", "1", ")", "\n", ")", "\n", "", "if", "v", "is", "not", "None", ":", "\n", "            ", "v", "=", "(", "\n", "v", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", "\n", ".", "transpose", "(", "0", ",", "1", ")", "\n", ")", "\n", "\n", "", "if", "saved_state", "is", "not", "None", ":", "\n", "# saved states are stored with shape (bsz, num_heads, seq_len, head_dim)", "\n", "            ", "if", "\"prev_key\"", "in", "saved_state", ":", "\n", "                ", "_prev_key", "=", "saved_state", "[", "\"prev_key\"", "]", "\n", "assert", "_prev_key", "is", "not", "None", "\n", "prev_key", "=", "_prev_key", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "if", "static_kv", ":", "\n", "                    ", "k", "=", "prev_key", "\n", "", "else", ":", "\n", "                    ", "assert", "k", "is", "not", "None", "\n", "k", "=", "torch", ".", "cat", "(", "[", "prev_key", ",", "k", "]", ",", "dim", "=", "1", ")", "\n", "", "", "if", "\"prev_value\"", "in", "saved_state", ":", "\n", "                ", "_prev_value", "=", "saved_state", "[", "\"prev_value\"", "]", "\n", "assert", "_prev_value", "is", "not", "None", "\n", "prev_value", "=", "_prev_value", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "if", "static_kv", ":", "\n", "                    ", "v", "=", "prev_value", "\n", "", "else", ":", "\n", "                    ", "assert", "v", "is", "not", "None", "\n", "v", "=", "torch", ".", "cat", "(", "[", "prev_value", ",", "v", "]", ",", "dim", "=", "1", ")", "\n", "", "", "prev_key_padding_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "if", "\"prev_key_padding_mask\"", "in", "saved_state", ":", "\n", "                ", "prev_key_padding_mask", "=", "saved_state", "[", "\"prev_key_padding_mask\"", "]", "\n", "", "assert", "k", "is", "not", "None", "and", "v", "is", "not", "None", "\n", "key_padding_mask", "=", "MultiheadAttention", ".", "_append_prev_key_padding_mask", "(", "\n", "key_padding_mask", "=", "key_padding_mask", ",", "\n", "prev_key_padding_mask", "=", "prev_key_padding_mask", ",", "\n", "batch_size", "=", "bsz", ",", "\n", "src_len", "=", "k", ".", "size", "(", "1", ")", ",", "\n", "static_kv", "=", "static_kv", ",", "\n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.ModelParallelMultiheadAttention._append_prev_key_padding_mask": [[288, 324], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "prev_key_padding_mask.float", "key_padding_mask.float", "filler.cuda.cuda.cuda", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "prev_key_padding_mask.size", "prev_key_padding_mask.float", "filler.cuda.cuda.float", "filler.cuda.cuda.cuda", "key_padding_mask.size", "filler.cuda.cuda.float", "key_padding_mask.float"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.cuda", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.cuda", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["saved_state", "[", "\"prev_key\"", "]", "=", "k", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "saved_state", "[", "\"prev_value\"", "]", "=", "v", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "saved_state", "[", "\"prev_key_padding_mask\"", "]", "=", "key_padding_mask", "\n", "# In this branch incremental_state is never None", "\n", "assert", "incremental_state", "is", "not", "None", "\n", "incremental_state", "=", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "saved_state", ")", "\n", "", "assert", "k", "is", "not", "None", "\n", "src_len", "=", "k", ".", "size", "(", "1", ")", "\n", "\n", "# This is part of a workaround to get around fork/join parallelism", "\n", "# not supporting Optional types.", "\n", "if", "key_padding_mask", "is", "not", "None", "and", "key_padding_mask", ".", "dim", "(", ")", "==", "0", ":", "\n", "            ", "key_padding_mask", "=", "None", "\n", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "            ", "assert", "key_padding_mask", ".", "size", "(", "0", ")", "==", "bsz", "\n", "assert", "key_padding_mask", ".", "size", "(", "1", ")", "==", "src_len", "\n", "\n", "", "if", "self", ".", "add_zero_attn", ":", "\n", "            ", "assert", "v", "is", "not", "None", "\n", "src_len", "+=", "1", "\n", "k", "=", "torch", ".", "cat", "(", "[", "k", ",", "k", ".", "new_zeros", "(", "(", "k", ".", "size", "(", "0", ")", ",", "1", ")", "+", "k", ".", "size", "(", ")", "[", "2", ":", "]", ")", "]", ",", "dim", "=", "1", ")", "\n", "v", "=", "torch", ".", "cat", "(", "[", "v", ",", "v", ".", "new_zeros", "(", "(", "v", ".", "size", "(", "0", ")", ",", "1", ")", "+", "v", ".", "size", "(", ")", "[", "2", ":", "]", ")", "]", ",", "dim", "=", "1", ")", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "                ", "attn_mask", "=", "torch", ".", "cat", "(", "\n", "[", "attn_mask", ",", "attn_mask", ".", "new_zeros", "(", "attn_mask", ".", "size", "(", "0", ")", ",", "1", ")", "]", ",", "dim", "=", "1", "\n", ")", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "                ", "key_padding_mask", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "key_padding_mask", ",", "\n", "torch", ".", "zeros", "(", "key_padding_mask", ".", "size", "(", "0", ")", ",", "1", ")", ".", "type_as", "(", "\n", "key_padding_mask", "\n", ")", ",", "\n", "]", ",", "\n", "dim", "=", "1", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.ModelParallelMultiheadAttention.reorder_incremental_state": [[325, 336], ["multihead_attention.ModelParallelMultiheadAttention._get_input_buffer", "multihead_attention.ModelParallelMultiheadAttention.keys", "multihead_attention.ModelParallelMultiheadAttention._set_input_buffer", "input_buffer[].index_select"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer"], ["\n", "", "", "attn_weights", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "attn_weights", "=", "self", ".", "apply_sparse_mask", "(", "attn_weights", ",", "tgt_len", ",", "src_len", ",", "bsz", ")", "\n", "\n", "assert", "list", "(", "attn_weights", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", "]", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask", "=", "attn_mask", ".", "unsqueeze", "(", "0", ")", "\n", "if", "self", ".", "onnx_trace", ":", "\n", "                ", "attn_mask", "=", "attn_mask", ".", "repeat", "(", "attn_weights", ".", "size", "(", "0", ")", ",", "1", ",", "1", ")", "\n", "", "attn_weights", "+=", "attn_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.ModelParallelMultiheadAttention._get_input_buffer": [[337, 346], ["multihead_attention.ModelParallelMultiheadAttention.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_incremental_state"], ["", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "# don't attend to padding symbols", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "if", "not", "self", ".", "tpu", ":", "\n", "                ", "attn_weights", "=", "attn_weights", ".", "masked_fill", "(", "\n", "key_padding_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", ".", "to", "(", "torch", ".", "bool", ")", ",", "\n", "float", "(", "\"-inf\"", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "attn_weights", "=", "attn_weights", ".", "transpose", "(", "0", ",", "2", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.multihead_attention.ModelParallelMultiheadAttention._set_input_buffer": [[347, 353], ["multihead_attention.ModelParallelMultiheadAttention.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_incremental_state"], ["attn_weights", "=", "attn_weights", ".", "masked_fill", "(", "key_padding_mask", ",", "float", "(", "\"-inf\"", ")", ")", "\n", "attn_weights", "=", "attn_weights", ".", "transpose", "(", "0", ",", "2", ")", "\n", "", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "", "if", "before_softmax", ":", "\n", "            ", "return", "attn_weights", ",", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_sentence_encoder.ModelParallelTransformerSentenceEncoder.build_embedding": [[35, 37], ["VocabParallelEmbedding"], "methods", ["None"], ["if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_sentence_encoder.ModelParallelTransformerSentenceEncoder.build_transformer_sentence_encoder_layer": [[38, 59], ["fairseq.model_parallel.modules.ModelParallelTransformerSentenceEncoderLayer"], "methods", ["None"], ["            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ":", "\n", "        ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "if", "module", ".", "padding_idx", "is", "not", "None", ":", "\n", "            ", "module", ".", "weight", ".", "data", "[", "module", ".", "padding_idx", "]", ".", "zero_", "(", ")", "\n", "", "", "if", "isinstance", "(", "module", ",", "MultiheadAttention", ")", ":", "\n", "        ", "module", ".", "q_proj", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "module", ".", "k_proj", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "module", ".", "v_proj", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "\n", "\n", "", "", "class", "TransformerSentenceEncoder", "(", "nn", ".", "Module", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.ModelParallelTransformerEncoderLayer.build_fc1": [[27, 31], ["ColumnParallelLinear"], "methods", ["None"], ["\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.ModelParallelTransformerEncoderLayer.build_fc2": [[32, 36], ["RowParallelLinear"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "args", ".", "encoder_embed_dim", "\n", "self", ".", "quant_noise", "=", "getattr", "(", "args", ",", "'quant_noise_pq'", ",", "0", ")", "\n", "self", ".", "quant_noise_block_size", "=", "getattr", "(", "args", ",", "'quant_noise_pq_block_size'", ",", "8", ")", "or", "8", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.ModelParallelTransformerEncoderLayer.build_self_attention": [[37, 43], ["fairseq.model_parallel.modules.ModelParallelMultiheadAttention"], "methods", ["None"], ["self", ".", "self_attn", "=", "self", ".", "build_self_attention", "(", "self", ".", "embed_dim", ",", "args", ")", "\n", "self", ".", "self_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "args", ".", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "activation_fn", "=", "utils", ".", "get_activation_fn", "(", "\n", "activation", "=", "getattr", "(", "args", ",", "'activation_fn'", ",", "'relu'", ")", "or", "\"relu\"", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.ModelParallelTransformerDecoderLayer.build_fc1": [[52, 56], ["ColumnParallelLinear"], "methods", ["None"], ["self", ".", "normalize_before", "=", "args", ".", "encoder_normalize_before", "\n", "self", ".", "fc1", "=", "self", ".", "build_fc1", "(", "\n", "self", ".", "embed_dim", ",", "\n", "args", ".", "encoder_ffn_embed_dim", ",", "\n", "self", ".", "quant_noise", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.ModelParallelTransformerDecoderLayer.build_fc2": [[57, 61], ["RowParallelLinear"], "methods", ["None"], ["self", ".", "quant_noise_block_size", ",", "\n", ")", "\n", "self", ".", "fc2", "=", "self", ".", "build_fc2", "(", "\n", "args", ".", "encoder_ffn_embed_dim", ",", "\n", "self", ".", "embed_dim", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.ModelParallelTransformerDecoderLayer.build_self_attention": [[62, 68], ["fairseq.model_parallel.modules.ModelParallelMultiheadAttention", "getattr"], "methods", ["None"], ["self", ".", "quant_noise", ",", "\n", "self", ".", "quant_noise_block_size", ",", "\n", ")", "\n", "\n", "self", ".", "final_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n", "", "def", "build_fc1", "(", "self", ",", "input_dim", ",", "output_dim", ",", "q_noise", ",", "qn_block_size", ")", ":", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.modules.transformer_layer.ModelParallelTransformerDecoderLayer.build_encoder_attention": [[70, 78], ["fairseq.model_parallel.modules.ModelParallelMultiheadAttention", "getattr", "getattr"], "methods", ["None"], ["nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ")", ",", "p", "=", "q_noise", ",", "block_size", "=", "qn_block_size", "\n", ")", "\n", "\n", "", "def", "build_fc2", "(", "self", ",", "input_dim", ",", "output_dim", ",", "q_noise", ",", "qn_block_size", ")", ":", "\n", "        ", "return", "quant_noise", "(", "\n", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ")", ",", "p", "=", "q_noise", ",", "block_size", "=", "qn_block_size", "\n", ")", "\n", "\n", "", "def", "build_self_attention", "(", "self", ",", "embed_dim", ",", "args", ")", ":", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lightconv_layer.lightconv_layer.lightconvFunction.forward": [[17, 24], ["lightconv_cuda.forward", "ctx.save_for_backward"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.forward"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "weights", ",", "padding_l", ")", ":", "\n", "        ", "ctx", ".", "padding_l", "=", "padding_l", "\n", "outputs", "=", "lightconv_cuda", ".", "forward", "(", "x", ",", "weights", ",", "padding_l", ")", "\n", "variables", "=", "[", "x", ",", "weights", "]", "\n", "ctx", ".", "save_for_backward", "(", "*", "variables", ")", "\n", "return", "outputs", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lightconv_layer.lightconv_layer.lightconvFunction.backward": [[25, 32], ["lightconv_cuda.backward", "grad_output.contiguous"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "outputs", "=", "lightconv_cuda", ".", "backward", "(", "\n", "grad_output", ".", "contiguous", "(", ")", ",", "ctx", ".", "padding_l", ",", "*", "ctx", ".", "saved_tensors", "\n", ")", "\n", "grad_input", ",", "grad_weights", "=", "outputs", "\n", "return", "grad_input", ",", "grad_weights", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lightconv_layer.lightconv_layer.LightconvLayer.__init__": [[36, 62], ["torch.nn.Module.__init__", "fairseq.modules.fairseq_dropout.FairseqDropout", "torch.nn.Parameter", "torch.nn.Parameter", "lightconv_layer.LightconvLayer.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.Parameter", "torch.nn.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "input_size", ",", "\n", "kernel_size", "=", "1", ",", "\n", "padding_l", "=", "None", ",", "\n", "weight_softmax", "=", "False", ",", "\n", "num_heads", "=", "1", ",", "\n", "weight_dropout", "=", "0.0", ",", "\n", "bias", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", "LightconvLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "padding_l", "=", "padding_l", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "weight_softmax", "=", "weight_softmax", "\n", "self", ".", "weight_dropout_module", "=", "FairseqDropout", "(", "\n", "weight_dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_heads", ",", "kernel_size", ")", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "input_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", "=", "None", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lightconv_layer.lightconv_layer.LightconvLayer.upgrade_state_dict_named": [[63, 69], ["state_dict.items", "k.endswith", "v.squeeze", "v.dim", "v.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "prefix", "=", "name", "+", "\".\"", "if", "name", "!=", "\"\"", "else", "\"\"", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", ".", "endswith", "(", "prefix", "+", "\"weight\"", ")", ":", "\n", "                ", "if", "v", ".", "dim", "(", ")", "==", "3", "and", "v", ".", "size", "(", "1", ")", "==", "1", ":", "\n", "                    ", "state_dict", "[", "k", "]", "=", "v", ".", "squeeze", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lightconv_layer.lightconv_layer.LightconvLayer.reset_parameters": [[70, 74], ["torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "", "", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "weight", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lightconv_layer.lightconv_layer.LightconvLayer.forward": [[75, 121], ["x.permute().contiguous.permute().contiguous.size", "lightconv_layer.LightconvLayer._get_input_buffer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_unfold.view.view.view", "lightconv_layer.LightconvLayer.size", "lightconv_layer.LightconvLayer.view().expand().contiguous().view", "lightconv_layer.LightconvLayer.weight_dropout_module", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "output.view.view.view", "x.permute().contiguous.permute().contiguous.permute().contiguous", "lightconvFunction.apply().permute", "x.permute().contiguous.permute().contiguous.new", "lightconv_layer.LightconvLayer._set_input_buffer", "torch.softmax().type_as", "torch.softmax().type_as", "torch.softmax", "torch.softmax", "lightconv_layer.LightconvLayer.weight_dropout_module", "x.permute().contiguous.permute().contiguous.unsqueeze", "lightconv_layer.LightconvLayer.view().expand().contiguous", "x.permute().contiguous.permute().contiguous.permute", "lightconvFunction.apply", "torch.softmax", "torch.softmax", "lightconv_layer.LightconvLayer.float", "x_unfold.view.view.size", "lightconv_layer.LightconvLayer.view().expand", "lightconv_layer.LightconvLayer.view"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "incremental_state", "=", "None", ")", ":", "\n", "\n", "# during inference time, incremental BMM is faster", "\n", "        ", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "T", ",", "B", ",", "C", "=", "x", ".", "size", "(", ")", "\n", "K", ",", "H", "=", "self", ".", "kernel_size", ",", "self", ".", "num_heads", "\n", "R", "=", "C", "//", "H", "\n", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "None", ":", "\n", "                ", "input_buffer", "=", "x", ".", "new", "(", ")", "\n", "", "x_unfold", "=", "torch", ".", "cat", "(", "[", "input_buffer", ",", "x", ".", "unsqueeze", "(", "3", ")", "]", ",", "dim", "=", "3", ")", "\n", "if", "self", ".", "kernel_size", ">", "1", ":", "\n", "                ", "self", ".", "_set_input_buffer", "(", "\n", "incremental_state", ",", "x_unfold", "[", ":", ",", ":", ",", ":", ",", "-", "self", ".", "kernel_size", "+", "1", ":", "]", "\n", ")", "\n", "", "x_unfold", "=", "x_unfold", ".", "view", "(", "T", "*", "B", "*", "H", ",", "R", ",", "-", "1", ")", "\n", "\n", "weight", "=", "self", ".", "weight", "\n", "if", "self", ".", "weight_softmax", ":", "\n", "                ", "weight", "=", "F", ".", "softmax", "(", "weight", ".", "float", "(", ")", ",", "dim", "=", "1", ")", ".", "type_as", "(", "weight", ")", "\n", "\n", "", "weight", "=", "weight", "[", ":", ",", "-", "x_unfold", ".", "size", "(", "2", ")", ":", "]", "\n", "\n", "K", "=", "weight", ".", "size", "(", "1", ")", "\n", "\n", "weight", "=", "(", "\n", "weight", ".", "view", "(", "1", ",", "H", ",", "K", ")", "\n", ".", "expand", "(", "T", "*", "B", ",", "H", ",", "K", ")", "\n", ".", "contiguous", "(", ")", "\n", ".", "view", "(", "T", "*", "B", "*", "H", ",", "K", ",", "1", ")", "\n", ")", "\n", "\n", "weight", "=", "self", ".", "weight_dropout_module", "(", "weight", ")", "\n", "output", "=", "torch", ".", "bmm", "(", "x_unfold", ",", "weight", ")", "# T*B*H x R x 1", "\n", "output", "=", "output", ".", "view", "(", "T", ",", "B", ",", "C", ")", "\n", "return", "output", "\n", "\n", "# during training time, use CUDA kernel", "\n", "", "else", ":", "\n", "            ", "x", "=", "x", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "weight", "=", "self", ".", "weight", "\n", "if", "self", ".", "weight_softmax", ":", "\n", "                ", "weight", "=", "F", ".", "softmax", "(", "self", ".", "weight", ",", "-", "1", ")", "\n", "", "if", "self", ".", "weight_dropout_module", ".", "p", ":", "\n", "                ", "weight", "=", "self", ".", "weight_dropout_module", "(", "weight", ")", "\n", "", "return", "lightconvFunction", ".", "apply", "(", "x", ",", "weight", ",", "self", ".", "padding_l", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lightconv_layer.lightconv_layer.LightconvLayer.reorder_incremental_state": [[122, 127], ["lightconv_layer.LightconvLayer._get_input_buffer", "input_buffer.index_select.index_select.index_select", "lightconv_layer.LightconvLayer._set_input_buffer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer"], ["", "", "def", "reorder_incremental_state", "(", "self", ",", "incremental_state", ",", "new_order", ")", ":", "\n", "        ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "not", "None", ":", "\n", "            ", "input_buffer", "=", "input_buffer", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lightconv_layer.lightconv_layer.LightconvLayer._get_input_buffer": [[128, 130], ["fairseq.utils.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_incremental_state"], ["", "", "def", "_get_input_buffer", "(", "self", ",", "incremental_state", ")", ":", "\n", "        ", "return", "utils", ".", "get_incremental_state", "(", "self", ",", "incremental_state", ",", "\"input_buffer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lightconv_layer.lightconv_layer.LightconvLayer._set_input_buffer": [[131, 134], ["fairseq.utils.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_incremental_state"], ["", "def", "_set_input_buffer", "(", "self", ",", "incremental_state", ",", "new_buffer", ")", ":", "\n", "        ", "return", "utils", ".", "set_incremental_state", "(", "\n", "self", ",", "incremental_state", ",", "\"input_buffer\"", ",", "new_buffer", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lightconv_layer.lightconv_layer.LightconvLayer.half": [[136, 138], ["lightconv_layer.LightconvLayer._apply", "t.is_floating_point", "t.half"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector._apply", "home.repos.pwc.inspect_result.reneeye_const.lightconv_layer.lightconv_layer.LightconvLayer.half"], ["", "def", "half", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_apply", "(", "lambda", "t", ":", "t", ".", "half", "(", ")", "if", "t", ".", "is_floating_point", "(", ")", "else", "t", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.lightconv_layer.cuda_function_gen.gen_forward": [[7, 114], ["open", "forward.write", "forward.write", "forward.write", "forward.write", "forward.write", "forward.write", "forward.write", "forward.write", "forward.write", "sequence_if.format", "forward.write", "forward.write", "case_k.format", "forward.write", "case_k.format", "forward.write", "main_block.format", "main_block.format"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["def", "gen_forward", "(", ")", ":", "\n", "\n", "    ", "kernels", "=", "[", "3", ",", "5", ",", "7", ",", "15", ",", "31", ",", "63", ",", "127", ",", "255", "]", "\n", "seqs", "=", "[", "32", "*", "x", "for", "x", "in", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", ",", "11", ",", "12", ",", "13", ",", "14", ",", "15", ",", "16", "]", "]", "\n", "\n", "head", "=", "\"\"\"\n/**\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n#include \"lightconv_cuda.cuh\"\n\nstd::vector<at::Tensor> lightconv_cuda_forward(at::Tensor input, at::Tensor filters, int padding_l) {\n\n    at::DeviceGuard g(input.device());\n    const auto minibatch = input.size(0);\n    const auto numFeatures = input.size(1);\n    const auto sequenceLength = input.size(2);\n\n    const auto numHeads = filters.size(0);\n    const auto filterSize = filters.size(1);\n\n    const auto numFiltersInBlock = numFeatures / numHeads;\n\n    const dim3 blocks(minibatch, numFeatures);\n\n    auto output = at::zeros_like(input);\n    auto stream = at::cuda::getCurrentCUDAStream();\n\"\"\"", "\n", "\n", "sequence_if", "=", "\"\"\"\n    if (sequenceLength <= {seq}) {{\n        switch(filterSize) {{\n\"\"\"", "\n", "\n", "case_k", "=", "\"\"\"\n            case {k}:\n\"\"\"", "\n", "\n", "main_block", "=", "\"\"\"\n                if (padding_l == {pad}) {{\n                    AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.scalar_type(), \"lightconv_forward\", ([&] {{\n                        lightconv_forward_kernel<{k}, {b_size}, {pad}, scalar_t>\n                        <<<blocks, {b_size}, 0, stream>>>(\n                                input.data<scalar_t>(),\n                                filters.data<scalar_t>(),\n                                minibatch,\n                                sequenceLength,\n                                numFeatures,\n                                numFiltersInBlock,\n                                output.data<scalar_t>());\n                    }}));\n                }} else\n\"\"\"", "\n", "\n", "bad_padding", "=", "\"\"\"\n                {\n                    std::cout << \"WARNING: Unsupported padding size - skipping forward pass\" << std::endl;\n                }\n                break;\n\"\"\"", "\n", "\n", "bad_filter", "=", "\"\"\"\n            default:\n                std::cout << \"WARNING: Unsupported filter length passed - skipping forward pass\" << std::endl;\n        }\n\"\"\"", "\n", "\n", "con_else", "=", "\"\"\"\n    } else\n\"\"\"", "\n", "\n", "final_else", "=", "\"\"\"\n    {\n        switch(filterSize) {\n\"\"\"", "\n", "\n", "final_return", "=", "\"\"\"\n    }\n\n    return {output};\n}\n\"\"\"", "\n", "\n", "with", "open", "(", "\"lightconv_cuda_forward.cu\"", ",", "\"w\"", ")", "as", "forward", ":", "\n", "        ", "forward", ".", "write", "(", "head", ")", "\n", "for", "seq", "in", "seqs", ":", "\n", "            ", "forward", ".", "write", "(", "sequence_if", ".", "format", "(", "seq", "=", "seq", ")", ")", "\n", "for", "k", "in", "kernels", ":", "\n", "                ", "forward", ".", "write", "(", "case_k", ".", "format", "(", "k", "=", "k", ")", ")", "\n", "for", "pad", "in", "[", "k", "//", "2", ",", "k", "-", "1", "]", ":", "\n", "                    ", "forward", ".", "write", "(", "main_block", ".", "format", "(", "k", "=", "k", ",", "b_size", "=", "seq", ",", "pad", "=", "pad", ")", ")", "\n", "", "forward", ".", "write", "(", "bad_padding", ")", "\n", "", "forward", ".", "write", "(", "bad_filter", ")", "\n", "forward", ".", "write", "(", "con_else", ")", "\n", "\n", "", "forward", ".", "write", "(", "final_else", ")", "\n", "for", "k", "in", "kernels", ":", "\n", "            ", "forward", ".", "write", "(", "case_k", ".", "format", "(", "k", "=", "k", ")", ")", "\n", "for", "pad", "in", "[", "k", "//", "2", ",", "k", "-", "1", "]", ":", "\n", "                ", "forward", ".", "write", "(", "main_block", ".", "format", "(", "k", "=", "k", ",", "b_size", "=", "seq", ",", "pad", "=", "pad", ")", ")", "\n", "", "forward", ".", "write", "(", "bad_padding", ")", "\n", "", "forward", ".", "write", "(", "bad_filter", ")", "\n", "forward", ".", "write", "(", "final_return", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.lightconv_layer.cuda_function_gen.gen_backward": [[116, 285], ["open", "backward.write", "zip", "backward.write", "backward.write", "backward.write", "case_k.format", "backward.write", "backward.write", "backward.write", "backward.write", "backward.write", "sequence_if.format", "backward.write", "backward.write", "backward.write", "backward.write", "main_block.format", "weight_grad_short.format", "main_block.format", "weight_grad.format"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["", "", "def", "gen_backward", "(", ")", ":", "\n", "\n", "    ", "head", "=", "\"\"\"\n/**\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n#include \"lightconv_cuda.cuh\"\n\nstd::vector<at::Tensor> lightconv_cuda_backward(\n        at::Tensor gradOutput,\n        int padding_l,\n        at::Tensor input,\n        at::Tensor filters) {\n\n    // gradWrtInput\n    const int minibatch = input.size(0);\n    const int numFeatures = input.size(1);\n    const int sequenceLength = input.size(2);\n\n    const int numHeads = filters.size(0);\n    const int filterSize = filters.size(1);\n\n    const dim3 gradBlocks(minibatch, numFeatures);\n    const dim3 weightGradFirstpassShortBlocks(minibatch, numHeads);\n    const dim3 weightGradSecondpassBlocks(numHeads, filterSize);\n\n    const int numFiltersInBlock = numFeatures / numHeads;\n\n    auto gradInput = at::zeros_like(input);\n    auto gradFilters = at::zeros_like(filters);\n\n    at::DeviceGuard g(input.device());\n    auto stream = at::cuda::getCurrentCUDAStream();\n\n    switch(filterSize) {\n\"\"\"", "\n", "\n", "sequence_if", "=", "\"\"\"\n            if (sequenceLength <= {seq}) {{\n\"\"\"", "\n", "\n", "case_k", "=", "\"\"\"\n        case {k}:\n\"\"\"", "\n", "\n", "main_block", "=", "\"\"\"\n                if (padding_l == {p}) {{\n                    AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.scalar_type(), \"lightconv_backward\", ([&] {{\n                        lightconv_grad_wrt_input_kernel<{k}, {b_size}, {p}, scalar_t>\n                        <<<gradBlocks, {b_size}, 0, stream>>>(\n                                gradOutput.data<scalar_t>(),\n                                filters.data<scalar_t>(),\n                                minibatch,\n                                sequenceLength,\n                                numFeatures,\n                                numFiltersInBlock,\n                                gradInput.data<scalar_t>());\n\n\"\"\"", "\n", "\n", "weight_grad_short", "=", "\"\"\"\n                        at::Tensor tempSumGradFilters = at::zeros({{minibatch, numHeads, filterSize}}, input.options().dtype(at::kFloat));\n                        lightconv_grad_wrt_weights_firstpass_short_kernel<{k}, {b_size}, {p}, scalar_t>\n                        <<<weightGradFirstpassShortBlocks, {b_size}, 0, stream>>>(\n                                input.data<scalar_t>(),\n                                gradOutput.data<scalar_t>(),\n                                minibatch,\n                                sequenceLength,\n                                numFeatures,\n                                numFiltersInBlock,\n                                numHeads,\n                                tempSumGradFilters.data<float>()\n                        );\n\n                        lightconv_grad_wrt_weights_secondpass_short_kernel<{k}, {b_size}, scalar_t>\n                        <<<weightGradSecondpassBlocks, {b_size}, 0, stream>>>(\n                                tempSumGradFilters.data<float>(),\n                                minibatch,\n                                numFiltersInBlock,\n                                gradFilters.data<scalar_t>()\n                        );\n                    }}));\n                }} else\n\"\"\"", "\n", "\n", "weight_grad", "=", "\"\"\"\n                        at::Tensor tempSumGradFilters = at::zeros({{minibatch, numFeatures, filterSize}}, input.options().dtype(at::kFloat));\n                        lightconv_grad_wrt_weights_firstpass_kernel<{k}, {b_size}, {p}, scalar_t>\n                        <<<gradBlocks, {b_size}, 0, stream>>>(\n                                input.data<scalar_t>(),\n                                gradOutput.data<scalar_t>(),\n                                minibatch,\n                                sequenceLength,\n                                numFeatures,\n                                numFiltersInBlock,\n                                tempSumGradFilters.data<float>()\n                        );\n\n                        lightconv_grad_wrt_weights_secondpass_kernel<{k}, {b_size}, scalar_t>\n                        <<<weightGradSecondpassBlocks, {b_size}, 0, stream>>>(\n                                tempSumGradFilters.data<float>(),\n                                minibatch,\n                                numFiltersInBlock,\n                                gradFilters.data<scalar_t>()\n                        );\n                    }}));\n                }} else\n\"\"\"", "\n", "\n", "bad_padding", "=", "\"\"\"\n                {\n                    std::cout << \"WARNING: Unsupported padding size - skipping backward pass\" << std::endl;\n                }\n\"\"\"", "\n", "\n", "breakout", "=", "\"\"\"\n                break;\n\"\"\"", "\n", "\n", "bad_filter", "=", "\"\"\"\n        default:\n            std::cout << \"WARNING: Unsupported filter length passed - skipping backward pass\" << std::endl;\n\"\"\"", "\n", "\n", "con_else", "=", "\"\"\"\n            } else\n\"\"\"", "\n", "\n", "final_else", "=", "\"\"\"\n    {\n        switch(filterSize) {\n\"\"\"", "\n", "\n", "last_return", "=", "\"\"\"\n    }\n    return {gradInput, gradFilters};\n}\n\"\"\"", "\n", "\n", "kernels", "=", "[", "3", ",", "5", ",", "7", ",", "15", ",", "31", ",", "63", ",", "127", ",", "255", "]", "\n", "seqs", "=", "[", "32", "*", "x", "for", "x", "in", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", ",", "11", ",", "12", ",", "13", ",", "14", ",", "15", ",", "16", "]", "]", "\n", "thresh", "=", "[", "32", ",", "32", ",", "64", ",", "128", ",", "256", ",", "-", "1", ",", "-", "1", ",", "-", "1", "]", "\n", "max_mem", "=", "[", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "192", ",", "96", ",", "64", "]", "\n", "\n", "with", "open", "(", "\"lightconv_cuda_backward.cu\"", ",", "\"w\"", ")", "as", "backward", ":", "\n", "        ", "backward", ".", "write", "(", "head", ")", "\n", "for", "(", "k", ",", "t", ",", "mem", ")", "in", "zip", "(", "kernels", ",", "thresh", ",", "max_mem", ")", ":", "\n", "            ", "backward", ".", "write", "(", "case_k", ".", "format", "(", "k", "=", "k", ")", ")", "\n", "for", "seq", "in", "seqs", ":", "\n", "                ", "if", "(", "t", "==", "-", "1", "or", "seq", "<=", "t", ")", "and", "(", "mem", "==", "-", "1", "or", "seq", "<", "mem", ")", ":", "\n", "                    ", "backward", ".", "write", "(", "sequence_if", ".", "format", "(", "seq", "=", "seq", ")", ")", "\n", "for", "p", "in", "[", "k", "//", "2", ",", "k", "-", "1", "]", ":", "\n", "                        ", "backward", ".", "write", "(", "main_block", ".", "format", "(", "k", "=", "k", ",", "b_size", "=", "seq", ",", "p", "=", "p", ")", ")", "\n", "backward", ".", "write", "(", "weight_grad_short", ".", "format", "(", "k", "=", "k", ",", "b_size", "=", "seq", ",", "p", "=", "p", ")", ")", "\n", "", "backward", ".", "write", "(", "bad_padding", ")", "\n", "", "else", ":", "\n", "                    ", "for", "p", "in", "[", "k", "//", "2", ",", "k", "-", "1", "]", ":", "\n", "                        ", "backward", ".", "write", "(", "main_block", ".", "format", "(", "k", "=", "k", ",", "b_size", "=", "32", ",", "p", "=", "p", ")", ")", "\n", "backward", ".", "write", "(", "weight_grad", ".", "format", "(", "k", "=", "k", ",", "b_size", "=", "32", ",", "p", "=", "p", ")", ")", "\n", "", "backward", ".", "write", "(", "bad_padding", ")", "\n", "backward", ".", "write", "(", "breakout", ")", "\n", "break", "\n", "", "backward", ".", "write", "(", "con_else", ")", "\n", "", "", "backward", ".", "write", "(", "bad_filter", ")", "\n", "backward", ".", "write", "(", "last_return", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.quantization.quantization_options.parse_config_yaml": [[7, 39], ["quantization_options.convert_yaml_to_tuple", "quantization_options.convert_yaml_to_tuple", "yaml_data[].items", "yaml_data[].items"], "function", ["home.repos.pwc.inspect_result.reneeye_const.quantization.quantization_options.convert_yaml_to_tuple", "home.repos.pwc.inspect_result.reneeye_const.quantization.quantization_options.convert_yaml_to_tuple"], ["def", "parse_config_yaml", "(", "yaml_data", ")", ":", "\n", "# Initialize to default options.", "\n", "    ", "quantization_options", "=", "{", "\n", "\"n_centroids\"", ":", "{", "\n", "\"Linear\"", ":", "[", "\"in_features\"", ",", "{", "\"*\"", ":", "256", "}", "]", ",", "\n", "\"Embedding\"", ":", "[", "\"embedding_dim\"", ",", "{", "\"*\"", ":", "256", "}", "]", ",", "\n", "}", ",", "\n", "\"block_sizes\"", ":", "{", "\n", "\"Linear\"", ":", "[", "\"fuzzy_name\"", ",", "{", "\"fc\"", ":", "8", ",", "\"attn\"", ":", "4", ",", "\"emb\"", ":", "4", "}", "]", ",", "\n", "\"Embedding\"", ":", "[", "\"fuzzy_name\"", ",", "{", "\"emb\"", ":", "8", "}", "]", ",", "\n", "}", ",", "\n", "\"layers_to_quantize\"", ":", "[", "\n", "\"decoder\\\\.layers\\\\.\\\\d+\\\\.fc[12]\"", ",", "\n", "\"decoder\\\\.embed_tokens\\\\.embeddings\\\\.[012]\\\\.[01]\"", ",", "\n", "\"decoder\\\\.layers\\\\.\\\\d+\\\\.self_attn\\\\.(k_proj|v_proj|q_proj|out_proj)\"", ",", "\n", "]", ",", "\n", "}", "\n", "\n", "if", "\"n_centroids\"", "in", "yaml_data", ":", "\n", "        ", "quantization_options", "[", "\"n_centroids\"", "]", "=", "{", "\n", "layer", ":", "convert_yaml_to_tuple", "(", "layer_data", ")", "\n", "for", "layer", ",", "layer_data", "in", "yaml_data", "[", "\"n_centroids\"", "]", ".", "items", "(", ")", "\n", "}", "\n", "", "if", "\"block_sizes\"", "in", "yaml_data", ":", "\n", "        ", "quantization_options", "[", "\"block_sizes\"", "]", "=", "{", "\n", "layer", ":", "convert_yaml_to_tuple", "(", "layer_data", ")", "\n", "for", "layer", ",", "layer_data", "in", "yaml_data", "[", "\"block_sizes\"", "]", ".", "items", "(", ")", "\n", "}", "\n", "", "if", "\"layers_to_quantize\"", "in", "yaml_data", ":", "\n", "        ", "quantization_options", "[", "\"layers_to_quantize\"", "]", "=", "yaml_data", "[", "\"layers_to_quantize\"", "]", "\n", "\n", "", "return", "quantization_options", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.quantization.quantization_options.convert_yaml_to_tuple": [[41, 45], ["None"], "function", ["None"], ["", "def", "convert_yaml_to_tuple", "(", "yaml_dictionary", ")", ":", "\n", "    ", "\"\"\"Converts a yaml dictionary with two keys: `key` and `value` into a two\n    argument tuple of those values.\"\"\"", "\n", "return", "(", "yaml_dictionary", "[", "\"key\"", "]", ",", "yaml_dictionary", "[", "\"value\"", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.scalar.ops.emulate_int": [[9, 12], ["q", "globals"], "function", ["None"], ["def", "emulate_int", "(", "w", ",", "bits", ",", "method", ",", "scale", "=", "None", ",", "zero_point", "=", "None", ")", ":", "\n", "    ", "q", "=", "globals", "(", ")", "[", "f\"emulate_int{bits}_{method}\"", "]", "\n", "return", "q", "(", "w", ",", "scale", "=", "scale", ",", "zero_point", "=", "zero_point", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scalar.ops.quantize": [[14, 18], ["torch.clamp", "torch.round"], "function", ["None"], ["", "def", "quantize", "(", "w", ",", "scale", ",", "zero_point", ")", ":", "\n", "    ", "return", "(", "\n", "torch", ".", "clamp", "(", "torch", ".", "round", "(", "w", "/", "scale", "+", "zero_point", ")", ",", "0", ",", "255", ")", "-", "zero_point", "\n", ")", "*", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scalar.ops.emulate_int8_histogram": [[20, 28], ["torch.quantization.observer.HistogramObserver", "torch.quantization.observer.HistogramObserver.", "torch.quantization.observer.HistogramObserver.calculate_qparams", "scale.cuda().type_as.cuda().type_as", "zero_point.cuda().type_as.cuda().type_as", "ops.quantize", "w.float", "scale.cuda().type_as.cuda", "zero_point.cuda().type_as.cuda"], "function", ["home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.Wav2Vec2Model.quantize", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.cuda", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.cuda"], ["", "def", "emulate_int8_histogram", "(", "w", ",", "scale", "=", "None", ",", "zero_point", "=", "None", ")", ":", "\n", "    ", "if", "scale", "is", "None", ":", "\n", "        ", "obs", "=", "torch", ".", "quantization", ".", "observer", ".", "HistogramObserver", "(", ")", "\n", "_", "=", "obs", "(", "w", ".", "float", "(", ")", ")", "\n", "scale", ",", "zero_point", "=", "obs", ".", "calculate_qparams", "(", ")", "\n", "scale", "=", "scale", ".", "cuda", "(", ")", ".", "type_as", "(", "w", ")", "\n", "zero_point", "=", "zero_point", ".", "cuda", "(", ")", ".", "type_as", "(", "w", ")", "\n", "", "return", "quantize", "(", "w", ",", "scale", ",", "zero_point", ")", ",", "scale", ",", "zero_point", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scalar.ops.emulate_int8_channel": [[30, 40], ["torch.quantization.observer.PerChannelMinMaxObserver", "torch.quantization.observer.PerChannelMinMaxObserver.", "torch.quantization.observer.PerChannelMinMaxObserver.get_qparams", "scale.cuda().type_as.cuda().type_as", "zero_point.cuda().type_as.cuda().type_as", "ops.quantize", "scale.cuda().type_as.cuda", "zero_point.cuda().type_as.cuda"], "function", ["home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.Wav2Vec2Model.quantize", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.cuda", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.cuda"], ["", "def", "emulate_int8_channel", "(", "w", ",", "scale", "=", "None", ",", "zero_point", "=", "None", ")", ":", "\n", "    ", "if", "scale", "is", "None", ":", "\n", "        ", "obs", "=", "torch", ".", "quantization", ".", "observer", ".", "PerChannelMinMaxObserver", "(", "\n", "ch_axis", "=", "-", "1", ",", "qscheme", "=", "torch", ".", "per_channel_symmetric", "\n", ")", "\n", "_", "=", "obs", "(", "w", ")", "\n", "scale", ",", "zero_point", ",", "ch_axis", "=", "obs", ".", "get_qparams", "(", ")", "\n", "scale", "=", "scale", ".", "cuda", "(", ")", ".", "type_as", "(", "w", ")", "\n", "zero_point", "=", "zero_point", ".", "cuda", "(", ")", ".", "type_as", "(", "w", ")", "\n", "", "return", "quantize", "(", "w", ",", "scale", ",", "zero_point", ")", ",", "scale", ",", "zero_point", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.scalar.ops.emulate_int8_tensor": [[42, 50], ["torch.quantization.observer.MinMaxObserver", "torch.quantization.observer.MinMaxObserver.", "torch.quantization.observer.MinMaxObserver.calculate_qparams", "scale.cuda().type_as.cuda().type_as", "zero_point.cuda().type_as.cuda().type_as", "ops.quantize", "scale.cuda().type_as.cuda", "zero_point.cuda().type_as.cuda"], "function", ["home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.Wav2Vec2Model.quantize", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.cuda", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.cuda"], ["", "def", "emulate_int8_tensor", "(", "w", ",", "scale", "=", "None", ",", "zero_point", "=", "None", ")", ":", "\n", "    ", "if", "scale", "is", "None", ":", "\n", "        ", "obs", "=", "torch", ".", "quantization", ".", "observer", ".", "MinMaxObserver", "(", ")", "\n", "_", "=", "obs", "(", "w", ")", "\n", "scale", ",", "zero_point", "=", "obs", ".", "calculate_qparams", "(", ")", "\n", "scale", "=", "scale", ".", "cuda", "(", ")", ".", "type_as", "(", "w", ")", "\n", "zero_point", "=", "zero_point", ".", "cuda", "(", ")", ".", "type_as", "(", "w", ")", "\n", "", "return", "quantize", "(", "w", ",", "scale", ",", "zero_point", ")", ",", "scale", ",", "zero_point", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.scalar.utils.quantize_model_": [[19, 78], ["pq.utils.get_layers", "isinstance", "modules.ActivationQuantizer", "operator.attrgetter", "logging.info", "tuple", "QuantizedModule.__new__", "params.update", "QuantizedModule.__new__.__dict__.update", "pq.utils.attrsetter", "torch.is_initialized", "torch.is_initialized", "MAPPING.keys", "logging.info", "torch.get_rank"], "function", ["home.repos.pwc.inspect_result.reneeye_const.pq.utils.get_layers", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.reneeye_const.pq.utils.attrsetter", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_rank"], ["import", "torch", ".", "nn", ".", "functional", "as", "F", "\n", "from", "fairseq", ".", "data", "import", "iterators", "\n", "from", "fairseq", ".", "file_io", "import", "PathManager", "\n", "from", "fairseq", ".", "logging", ".", "meters", "import", "safe_round", "\n", "from", "fairseq", ".", "modules", "import", "gelu", ",", "gelu_accurate", "\n", "from", "fairseq", ".", "modules", ".", "multihead_attention", "import", "MultiheadAttention", "\n", "from", "torch", "import", "Tensor", "\n", "\n", "\n", "try", ":", "\n", "    ", "from", "amp_C", "import", "multi_tensor_l2norm", "\n", "\n", "multi_tensor_l2norm_available", "=", "True", "\n", "", "except", "ImportError", ":", "\n", "    ", "multi_tensor_l2norm_available", "=", "False", "\n", "\n", "", "try", ":", "\n", "    ", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "\n", "", "except", "ImportError", ":", "\n", "    ", "xm", "=", "None", "\n", "\n", "\n", "", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "\n", "MANIFOLD_PATH_SEP", "=", "\"|\"", "\n", "\n", "\n", "class", "FileContentsAction", "(", "argparse", ".", "Action", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "nargs", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "nargs", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"nargs not allowed\"", ")", "\n", "", "super", "(", "FileContentsAction", ",", "self", ")", ".", "__init__", "(", "option_strings", ",", "dest", ",", "**", "kwargs", ")", "\n", "\n", "", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "option_string", "=", "None", ")", ":", "\n", "        ", "if", "PathManager", ".", "isfile", "(", "values", ")", ":", "\n", "            ", "with", "PathManager", ".", "open", "(", "values", ")", "as", "f", ":", "\n", "                ", "argument", "=", "f", ".", "read", "(", ")", ".", "strip", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "argument", "=", "values", "\n", "", "setattr", "(", "namespace", ",", "self", ".", "dest", ",", "argument", ")", "\n", "\n", "\n", "", "", "def", "split_paths", "(", "paths", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "return", "(", "\n", "paths", ".", "split", "(", "os", ".", "pathsep", ")", "\n", "if", "\"://\"", "not", "in", "paths", "\n", "else", "paths", ".", "split", "(", "MANIFOLD_PATH_SEP", ")", "\n", ")", "\n", "\n", "\n", "", "def", "load_ensemble_for_inference", "(", "filenames", ",", "task", ",", "model_arg_overrides", "=", "None", ")", ":", "\n", "    ", "from", "fairseq", "import", "checkpoint_utils", "\n", "\n", "deprecation_warning", "(", "\n", "\"utils.load_ensemble_for_inference is deprecated. \"", "\n", "\"Please use checkpoint_utils.load_model_ensemble instead.\"", "\n", ")", "\n", "return", "checkpoint_utils", ".", "load_model_ensemble", "(", "\n", "filenames", ",", "arg_overrides", "=", "model_arg_overrides", ",", "task", "=", "task", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pq.pq.PQ.__init__": [[39, 58], ["pq.PQ._reshape", "em.EM.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pq.pq.PQ._reshape", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "W", ",", "\n", "block_size", ",", "\n", "n_centroids", "=", "256", ",", "\n", "n_iter", "=", "20", ",", "\n", "eps", "=", "1e-6", ",", "\n", "max_tentatives", "=", "30", ",", "\n", "verbose", "=", "True", ",", "\n", ")", ":", "\n", "        ", "self", ".", "block_size", "=", "block_size", "\n", "W_reshaped", "=", "self", ".", "_reshape", "(", "W", ")", "\n", "super", "(", "PQ", ",", "self", ")", ".", "__init__", "(", "\n", "W_reshaped", ",", "\n", "n_centroids", "=", "n_centroids", ",", "\n", "n_iter", "=", "n_iter", ",", "\n", "eps", "=", "eps", ",", "\n", "max_tentatives", "=", "max_tentatives", ",", "\n", "verbose", "=", "verbose", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pq.pq.PQ._reshape": [[60, 93], ["len", "W.size", "W.reshape().permute().flatten", "W.size", "len", "W.size", "W.reshape().permute().flatten", "NotImplementedError", "W.reshape().permute", "W.size", "W.size", "W.reshape().permute", "W.reshape", "W.reshape"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "_reshape", "(", "self", ",", "W", ")", ":", "\n", "        ", "\"\"\"\n        Reshapes the matrix W as expained in step (1).\n        \"\"\"", "\n", "\n", "# fully connected: by convention the weight has size out_features x in_features", "\n", "if", "len", "(", "W", ".", "size", "(", ")", ")", "==", "2", ":", "\n", "            ", "self", ".", "out_features", ",", "self", ".", "in_features", "=", "W", ".", "size", "(", ")", "\n", "assert", "(", "\n", "self", ".", "in_features", "%", "self", ".", "block_size", "==", "0", "\n", ")", ",", "\"Linear: n_blocks must be a multiple of in_features\"", "\n", "return", "(", "\n", "W", ".", "reshape", "(", "self", ".", "out_features", ",", "-", "1", ",", "self", ".", "block_size", ")", "\n", ".", "permute", "(", "2", ",", "1", ",", "0", ")", "\n", ".", "flatten", "(", "1", ",", "2", ")", "\n", ")", "\n", "\n", "# convolutional: we reshape along the spatial dimension", "\n", "", "elif", "len", "(", "W", ".", "size", "(", ")", ")", "==", "4", ":", "\n", "            ", "self", ".", "out_channels", ",", "self", ".", "in_channels", ",", "self", ".", "k_h", ",", "self", ".", "k_w", "=", "W", ".", "size", "(", ")", "\n", "assert", "(", "\n", "self", ".", "in_channels", "*", "self", ".", "k_h", "*", "self", ".", "k_w", "\n", ")", "%", "self", ".", "block_size", "==", "0", ",", "(", "\n", "\"Conv2d: n_blocks must be a multiple of in_channels * k_h * k_w\"", "\n", ")", "\n", "return", "(", "\n", "W", ".", "reshape", "(", "self", ".", "out_channels", ",", "-", "1", ",", "self", ".", "block_size", ")", "\n", ".", "permute", "(", "2", ",", "1", ",", "0", ")", "\n", ".", "flatten", "(", "1", ",", "2", ")", "\n", ")", "\n", "# not implemented", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "W", ".", "size", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pq.pq.PQ.encode": [[94, 105], ["pq.PQ.initialize_centroids", "range", "pq.PQ.step"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.initialize_centroids", "home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step"], ["", "", "def", "encode", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Performs self.n_iter EM steps.\n        \"\"\"", "\n", "\n", "self", ".", "initialize_centroids", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_iter", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "step", "(", "i", ")", "\n", "", "except", "EmptyClusterResolveError", ":", "\n", "                ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pq.pq.PQ.decode": [[106, 128], ["pq.PQ.centroids[].reshape().permute().flatten", "pq.PQ.centroids[].reshape().permute().reshape", "pq.PQ.centroids[].reshape().permute", "pq.PQ.centroids[].reshape().permute", "pq.PQ.centroids[].reshape", "pq.PQ.centroids[].reshape"], "methods", ["None"], ["", "", "", "def", "decode", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns the encoded full weight matrix. Must be called after\n        the encode function.\n        \"\"\"", "\n", "\n", "# fully connected case", "\n", "if", "\"k_h\"", "not", "in", "self", ".", "__dict__", ":", "\n", "            ", "return", "(", "\n", "self", ".", "centroids", "[", "self", ".", "assignments", "]", "\n", ".", "reshape", "(", "-", "1", ",", "self", ".", "out_features", ",", "self", ".", "block_size", ")", "\n", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", ".", "flatten", "(", "1", ",", "2", ")", "\n", ")", "\n", "\n", "# convolutional case", "\n", "", "else", ":", "\n", "            ", "return", "(", "\n", "self", ".", "centroids", "[", "self", ".", "assignments", "]", "\n", ".", "reshape", "(", "-", "1", ",", "self", ".", "out_channels", ",", "self", ".", "block_size", ")", "\n", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", ".", "reshape", "(", "self", ".", "out_channels", ",", "self", ".", "in_channels", ",", "self", ".", "k_h", ",", "self", ".", "k_w", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.__init__": [[34, 46], ["torch.Tensor", "torch.Tensor"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "W", ",", "n_centroids", "=", "256", ",", "n_iter", "=", "20", ",", "eps", "=", "1e-6", ",", "max_tentatives", "=", "30", ",", "verbose", "=", "True", "\n", ")", ":", "\n", "        ", "self", ".", "W", "=", "W", "\n", "self", ".", "n_centroids", "=", "n_centroids", "\n", "self", ".", "n_iter", "=", "n_iter", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "max_tentatives", "=", "max_tentatives", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "centroids", "=", "torch", ".", "Tensor", "(", ")", "\n", "self", ".", "assignments", "=", "torch", ".", "Tensor", "(", ")", "\n", "self", ".", "objective", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.initialize_centroids": [[47, 57], ["em.EM.W.size", "torch.randint().long", "em.EM.W[].t", "torch.randint"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "initialize_centroids", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Initializes the centroids by sampling random columns from W.\n        \"\"\"", "\n", "\n", "in_features", ",", "out_features", "=", "self", ".", "W", ".", "size", "(", ")", "\n", "indices", "=", "torch", ".", "randint", "(", "\n", "low", "=", "0", ",", "high", "=", "out_features", ",", "size", "=", "(", "self", ".", "n_centroids", ",", ")", "\n", ")", ".", "long", "(", ")", "\n", "self", ".", "centroids", "=", "self", ".", "W", "[", ":", ",", "indices", "]", ".", "t", "(", ")", "# (n_centroids x in_features)", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.step": [[58, 89], ["em.EM.compute_distances", "torch.argmin", "em.EM.resolve_empty_clusters", "range", "em.EM.objective.append", "W_k.mean", "logging.info", "em.EM.centroids[].t"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.compute_distances", "home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.resolve_empty_clusters"], ["", "def", "step", "(", "self", ",", "i", ")", ":", "\n", "        ", "\"\"\"\n        There are two standard steps for each iteration: expectation (E) and\n        minimization (M). The E-step (assignment) is performed with an exhaustive\n        search and the M-step (centroid computation) is performed with\n        the exact solution.\n\n        Args:\n            - i: step number\n\n        Remarks:\n            - The E-step heavily uses PyTorch broadcasting to speed up computations\n              and reduce the memory overhead\n        \"\"\"", "\n", "\n", "# assignments (E-step)", "\n", "distances", "=", "self", ".", "compute_distances", "(", ")", "# (n_centroids x out_features)", "\n", "self", ".", "assignments", "=", "torch", ".", "argmin", "(", "distances", ",", "dim", "=", "0", ")", "# (out_features)", "\n", "n_empty_clusters", "=", "self", ".", "resolve_empty_clusters", "(", ")", "\n", "\n", "# centroids (M-step)", "\n", "for", "k", "in", "range", "(", "self", ".", "n_centroids", ")", ":", "\n", "            ", "W_k", "=", "self", ".", "W", "[", ":", ",", "self", ".", "assignments", "==", "k", "]", "# (in_features x size_of_cluster_k)", "\n", "self", ".", "centroids", "[", "k", "]", "=", "W_k", ".", "mean", "(", "dim", "=", "1", ")", "# (in_features)", "\n", "\n", "# book-keeping", "\n", "", "obj", "=", "(", "self", ".", "centroids", "[", "self", ".", "assignments", "]", ".", "t", "(", ")", "-", "self", ".", "W", ")", ".", "norm", "(", "p", "=", "2", ")", ".", "item", "(", ")", "\n", "self", ".", "objective", ".", "append", "(", "obj", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "logging", ".", "info", "(", "\n", "f\"Iteration: {i},\\t\"", "\n", "f\"objective: {obj:.6f},\\t\"", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.resolve_empty_clusters": [[93, 132], ["collections.Counter", "len", "map", "set", "set", "len", "random.choice", "em.EM.centroids[].clone", "em.EM.compute_distances", "torch.argmin", "collections.Counter", "range", "collections.Counter.keys", "list", "torch.randn_like", "map", "set", "set", "logging.info", "x.item", "collections.Counter.most_common", "range", "collections.Counter.keys", "x.item", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.compute_distances", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "", "def", "resolve_empty_clusters", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        If one cluster is empty, the most populated cluster is split into\n        two clusters by shifting the respective centroids. This is done\n        iteratively for a fixed number of tentatives.\n        \"\"\"", "\n", "\n", "# empty clusters", "\n", "counts", "=", "Counter", "(", "map", "(", "lambda", "x", ":", "x", ".", "item", "(", ")", ",", "self", ".", "assignments", ")", ")", "\n", "empty_clusters", "=", "set", "(", "range", "(", "self", ".", "n_centroids", ")", ")", "-", "set", "(", "counts", ".", "keys", "(", ")", ")", "\n", "n_empty_clusters", "=", "len", "(", "empty_clusters", ")", "\n", "\n", "tentatives", "=", "0", "\n", "while", "len", "(", "empty_clusters", ")", ">", "0", ":", "\n", "# given an empty cluster, find most populated cluster and split it into two", "\n", "            ", "k", "=", "random", ".", "choice", "(", "list", "(", "empty_clusters", ")", ")", "\n", "m", "=", "counts", ".", "most_common", "(", "1", ")", "[", "0", "]", "[", "0", "]", "\n", "e", "=", "torch", ".", "randn_like", "(", "self", ".", "centroids", "[", "m", "]", ")", "*", "self", ".", "eps", "\n", "self", ".", "centroids", "[", "k", "]", "=", "self", ".", "centroids", "[", "m", "]", ".", "clone", "(", ")", "\n", "self", ".", "centroids", "[", "k", "]", "+=", "e", "\n", "self", ".", "centroids", "[", "m", "]", "-=", "e", "\n", "\n", "# recompute assignments", "\n", "distances", "=", "self", ".", "compute_distances", "(", ")", "# (n_centroids x out_features)", "\n", "self", ".", "assignments", "=", "torch", ".", "argmin", "(", "distances", ",", "dim", "=", "0", ")", "# (out_features)", "\n", "\n", "# check for empty clusters", "\n", "counts", "=", "Counter", "(", "map", "(", "lambda", "x", ":", "x", ".", "item", "(", ")", ",", "self", ".", "assignments", ")", ")", "\n", "empty_clusters", "=", "set", "(", "range", "(", "self", ".", "n_centroids", ")", ")", "-", "set", "(", "counts", ".", "keys", "(", ")", ")", "\n", "\n", "# increment tentatives", "\n", "if", "tentatives", "==", "self", ".", "max_tentatives", ":", "\n", "                ", "logging", ".", "info", "(", "\n", "f\"Could not resolve all empty clusters, {len(empty_clusters)} remaining\"", "\n", ")", "\n", "raise", "EmptyClusterResolveError", "\n", "", "tentatives", "+=", "1", "\n", "\n", "", "return", "n_empty_clusters", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.compute_distances": [[133, 163], ["torch.cat", "em.EM.centroids.chunk"], "methods", ["None"], ["", "def", "compute_distances", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        For every centroid m, computes\n\n                          ||M - m[None, :]||_2\n\n        Remarks:\n            - We rely on PyTorch's broadcasting to speed up computations\n              and reduce the memory overhead\n            - Without chunking, the sizes in the broadcasting are modified as:\n              (n_centroids x n_samples x out_features) -> (n_centroids x out_features)\n            - The broadcasting computation is automatically chunked so that\n              the tensors fit into the memory of the GPU\n        \"\"\"", "\n", "\n", "nb_centroids_chunks", "=", "1", "\n", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "return", "torch", ".", "cat", "(", "\n", "[", "\n", "(", "self", ".", "W", "[", "None", ",", ":", ",", ":", "]", "-", "centroids_c", "[", ":", ",", ":", ",", "None", "]", ")", ".", "norm", "(", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "for", "centroids_c", "in", "self", ".", "centroids", ".", "chunk", "(", "\n", "nb_centroids_chunks", ",", "dim", "=", "0", "\n", ")", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "", "except", "RuntimeError", ":", "\n", "                ", "nb_centroids_chunks", "*=", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.assign": [[164, 176], ["em.EM.compute_distances", "torch.argmin"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.compute_distances"], ["", "", "", "def", "assign", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Assigns each column of W to its closest centroid, thus essentially\n        performing the E-step in train().\n\n        Remarks:\n            - The function must be called after train() or after loading\n              centroids using self.load(), otherwise it will return empty tensors\n        \"\"\"", "\n", "\n", "distances", "=", "self", ".", "compute_distances", "(", ")", "# (n_centroids x out_features)", "\n", "self", ".", "assignments", "=", "torch", ".", "argmin", "(", "distances", ",", "dim", "=", "0", ")", "# (out_features)", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.save": [[177, 190], ["torch.save", "torch.save", "torch.save", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.save", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.save", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.save"], ["", "def", "save", "(", "self", ",", "path", ",", "layer", ")", ":", "\n", "        ", "\"\"\"\n        Saves centroids and assignments.\n\n        Args:\n            - path: folder used to save centroids and assignments\n        \"\"\"", "\n", "\n", "torch", ".", "save", "(", "self", ".", "centroids", ",", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}_centroids.pth\"", ".", "format", "(", "layer", ")", ")", ")", "\n", "torch", ".", "save", "(", "\n", "self", ".", "assignments", ",", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}_assignments.pth\"", ".", "format", "(", "layer", ")", ")", "\n", ")", "\n", "torch", ".", "save", "(", "self", ".", "objective", ",", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}_objective.pth\"", ".", "format", "(", "layer", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pq.em.EM.load": [[191, 207], ["torch.load", "torch.load", "torch.load", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load"], ["", "def", "load", "(", "self", ",", "path", ",", "layer", ")", ":", "\n", "        ", "\"\"\"\n        Loads centroids and assignments from a given path\n\n        Args:\n            - path: folder use to load centroids and assignments\n        \"\"\"", "\n", "\n", "self", ".", "centroids", "=", "torch", ".", "load", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}_centroids.pth\"", ".", "format", "(", "layer", ")", ")", "\n", ")", "\n", "self", ".", "assignments", "=", "torch", ".", "load", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}_assignments.pth\"", ".", "format", "(", "layer", ")", ")", "\n", ")", "\n", "self", ".", "objective", "=", "torch", ".", "load", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}_objective.pth\"", ".", "format", "(", "layer", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pq.utils.SizeTracker.__init__": [[269, 276], ["utils.SizeTracker.compute_size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pq.utils.SizeTracker.compute_size"], ["    ", "assert", "right_to_left", "^", "left_to_right", "\n", "pad_mask", "=", "src_tokens", ".", "eq", "(", "padding_idx", ")", "\n", "if", "not", "pad_mask", ".", "any", "(", ")", ":", "\n", "# no padding, return early", "\n", "        ", "return", "src_tokens", "\n", "", "if", "left_to_right", "and", "not", "pad_mask", "[", ":", ",", "0", "]", ".", "any", "(", ")", ":", "\n", "# already right padded", "\n", "        ", "return", "src_tokens", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pq.utils.SizeTracker.compute_size": [[277, 286], ["utils.SizeTracker.model.named_parameters", "p.numel"], "methods", ["None"], ["", "if", "right_to_left", "and", "not", "pad_mask", "[", ":", ",", "-", "1", "]", ".", "any", "(", ")", ":", "\n", "# already left padded", "\n", "        ", "return", "src_tokens", "\n", "", "max_len", "=", "src_tokens", ".", "size", "(", "1", ")", "\n", "buffered", "=", "torch", ".", "empty", "(", "0", ")", ".", "long", "(", ")", "\n", "if", "max_len", ">", "0", ":", "\n", "        ", "torch", ".", "arange", "(", "max_len", ",", "out", "=", "buffered", ")", "\n", "", "range", "=", "buffered", ".", "type_as", "(", "src_tokens", ")", ".", "expand_as", "(", "src_tokens", ")", "\n", "num_pads", "=", "pad_mask", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "if", "right_to_left", ":", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pq.utils.SizeTracker.update": [[287, 307], ["numpy.log2", "W.numel", "W.numel"], "methods", ["None"], ["        ", "index", "=", "torch", ".", "remainder", "(", "range", "-", "num_pads", ",", "max_len", ")", "\n", "", "else", ":", "\n", "        ", "index", "=", "torch", ".", "remainder", "(", "range", "+", "num_pads", ",", "max_len", ")", "\n", "", "return", "src_tokens", ".", "gather", "(", "1", ",", "index", ")", "\n", "\n", "\n", "", "def", "item", "(", "tensor", ")", ":", "\n", "    ", "if", "hasattr", "(", "tensor", ",", "\"item\"", ")", ":", "\n", "        ", "return", "tensor", ".", "item", "(", ")", "\n", "", "if", "hasattr", "(", "tensor", ",", "\"__getitem__\"", ")", ":", "\n", "        ", "return", "tensor", "[", "0", "]", "\n", "", "return", "tensor", "\n", "\n", "\n", "", "def", "multi_tensor_total_norm", "(", "grads", ",", "chunk_size", "=", "2048", "*", "32", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "per_device_grads", "=", "{", "}", "\n", "norms", "=", "[", "]", "\n", "for", "grad", "in", "grads", ":", "\n", "        ", "device", "=", "grad", ".", "device", "\n", "cur_device_grads", "=", "per_device_grads", ".", "get", "(", "device", ")", "\n", "if", "cur_device_grads", "is", "None", ":", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pq.utils.SizeTracker.__repr__": [[308, 315], ["None"], "methods", ["None"], ["            ", "cur_device_grads", "=", "[", "]", "\n", "per_device_grads", "[", "device", "]", "=", "cur_device_grads", "\n", "", "cur_device_grads", ".", "append", "(", "grad", ")", "\n", "", "for", "device", "in", "per_device_grads", ".", "keys", "(", ")", ":", "\n", "        ", "cur_device_grads", "=", "per_device_grads", "[", "device", "]", "\n", "if", "device", ".", "type", "==", "\"cuda\"", ":", "\n", "# TODO(msb) return has_inf", "\n", "            ", "has_inf", "=", "torch", ".", "zeros", "(", "(", "1", ",", "1", ")", ",", "dtype", "=", "torch", ".", "int", ",", "device", "=", "device", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pq.utils.quantize_model_": [[18, 153], ["utils.get_layers", "utils.get_param", "utils.get_param", "module.weight.data.clone", "pq.PQ", "pq.PQ.encode", "pq.PQ.centroids.contiguous", "pq.PQ.assignments.contiguous", "torch.is_initialized", "isinstance", "size_tracker.update", "operator.attrgetter", "logging.info", "module.bias.data.clone", "torch.broadcast", "torch.broadcast", "map", "modules.PQLinear", "isinstance", "utils.attrsetter", "torch.is_initialized", "torch.is_initialized", "map", "modules.PQEmbedding", "isinstance", "torch.get_rank", "module.named_parameters", "map", "map", "modules.PQConv2d", "ValueError"], "function", ["home.repos.pwc.inspect_result.reneeye_const.pq.utils.get_layers", "home.repos.pwc.inspect_result.reneeye_const.pq.utils.get_param", "home.repos.pwc.inspect_result.reneeye_const.pq.utils.get_param", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.broadcast", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.broadcast", "home.repos.pwc.inspect_result.reneeye_const.pq.utils.attrsetter", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_rank"], ["import", "torch", "\n", "import", "torch", ".", "nn", ".", "functional", "as", "F", "\n", "from", "fairseq", ".", "data", "import", "iterators", "\n", "from", "fairseq", ".", "file_io", "import", "PathManager", "\n", "from", "fairseq", ".", "logging", ".", "meters", "import", "safe_round", "\n", "from", "fairseq", ".", "modules", "import", "gelu", ",", "gelu_accurate", "\n", "from", "fairseq", ".", "modules", ".", "multihead_attention", "import", "MultiheadAttention", "\n", "from", "torch", "import", "Tensor", "\n", "\n", "\n", "try", ":", "\n", "    ", "from", "amp_C", "import", "multi_tensor_l2norm", "\n", "\n", "multi_tensor_l2norm_available", "=", "True", "\n", "", "except", "ImportError", ":", "\n", "    ", "multi_tensor_l2norm_available", "=", "False", "\n", "\n", "", "try", ":", "\n", "    ", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "\n", "", "except", "ImportError", ":", "\n", "    ", "xm", "=", "None", "\n", "\n", "\n", "", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "\n", "MANIFOLD_PATH_SEP", "=", "\"|\"", "\n", "\n", "\n", "class", "FileContentsAction", "(", "argparse", ".", "Action", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "nargs", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "nargs", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"nargs not allowed\"", ")", "\n", "", "super", "(", "FileContentsAction", ",", "self", ")", ".", "__init__", "(", "option_strings", ",", "dest", ",", "**", "kwargs", ")", "\n", "\n", "", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "option_string", "=", "None", ")", ":", "\n", "        ", "if", "PathManager", ".", "isfile", "(", "values", ")", ":", "\n", "            ", "with", "PathManager", ".", "open", "(", "values", ")", "as", "f", ":", "\n", "                ", "argument", "=", "f", ".", "read", "(", ")", ".", "strip", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "argument", "=", "values", "\n", "", "setattr", "(", "namespace", ",", "self", ".", "dest", ",", "argument", ")", "\n", "\n", "\n", "", "", "def", "split_paths", "(", "paths", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "return", "(", "\n", "paths", ".", "split", "(", "os", ".", "pathsep", ")", "\n", "if", "\"://\"", "not", "in", "paths", "\n", "else", "paths", ".", "split", "(", "MANIFOLD_PATH_SEP", ")", "\n", ")", "\n", "\n", "\n", "", "def", "load_ensemble_for_inference", "(", "filenames", ",", "task", ",", "model_arg_overrides", "=", "None", ")", ":", "\n", "    ", "from", "fairseq", "import", "checkpoint_utils", "\n", "\n", "deprecation_warning", "(", "\n", "\"utils.load_ensemble_for_inference is deprecated. \"", "\n", "\"Please use checkpoint_utils.load_model_ensemble instead.\"", "\n", ")", "\n", "return", "checkpoint_utils", ".", "load_model_ensemble", "(", "\n", "filenames", ",", "arg_overrides", "=", "model_arg_overrides", ",", "task", "=", "task", "\n", ")", "\n", "\n", "\n", "", "def", "apply_to_sample", "(", "f", ",", "sample", ")", ":", "\n", "    ", "if", "hasattr", "(", "sample", ",", "\"__len__\"", ")", "and", "len", "(", "sample", ")", "==", "0", ":", "\n", "        ", "return", "{", "}", "\n", "\n", "", "def", "_apply", "(", "x", ")", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "x", ")", ":", "\n", "            ", "return", "f", "(", "x", ")", "\n", "", "elif", "isinstance", "(", "x", ",", "dict", ")", ":", "\n", "            ", "return", "{", "key", ":", "_apply", "(", "value", ")", "for", "key", ",", "value", "in", "x", ".", "items", "(", ")", "}", "\n", "", "elif", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "            ", "return", "[", "_apply", "(", "x", ")", "for", "x", "in", "x", "]", "\n", "", "elif", "isinstance", "(", "x", ",", "tuple", ")", ":", "\n", "            ", "return", "tuple", "(", "_apply", "(", "x", ")", "for", "x", "in", "x", ")", "\n", "", "elif", "isinstance", "(", "x", ",", "set", ")", ":", "\n", "            ", "return", "{", "_apply", "(", "x", ")", "for", "x", "in", "x", "}", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n", "", "", "return", "_apply", "(", "sample", ")", "\n", "\n", "\n", "", "def", "move_to_cuda", "(", "sample", ",", "device", "=", "None", ")", ":", "\n", "    ", "device", "=", "device", "or", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "\n", "def", "_move_to_cuda", "(", "tensor", ")", ":", "\n", "# non_blocking is ignored if tensor is not pinned, so we can always set", "\n", "# to True (see github.com/PyTorchLightning/pytorch-lightning/issues/620)", "\n", "        ", "return", "tensor", ".", "cuda", "(", "device", "=", "device", ",", "non_blocking", "=", "True", ")", "\n", "\n", "", "return", "apply_to_sample", "(", "_move_to_cuda", ",", "sample", ")", "\n", "\n", "\n", "", "def", "move_to_cpu", "(", "sample", ")", ":", "\n", "    ", "def", "_move_to_cpu", "(", "tensor", ")", ":", "\n", "# PyTorch has poor support for half tensors (float16) on CPU.", "\n", "# Move any such tensors to float32.", "\n", "        ", "if", "tensor", ".", "dtype", "in", "{", "torch", ".", "bfloat16", ",", "torch", ".", "float16", "}", ":", "\n", "            ", "tensor", "=", "tensor", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", "\n", "", "return", "tensor", ".", "cpu", "(", ")", "\n", "\n", "", "return", "apply_to_sample", "(", "_move_to_cpu", ",", "sample", ")", "\n", "\n", "\n", "", "def", "get_incremental_state", "(", "\n", "module", ":", "MultiheadAttention", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "key", ":", "str", ",", "\n", ")", "->", "Optional", "[", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ":", "\n", "    ", "\"\"\"Helper for getting incremental state for an nn.Module.\"\"\"", "\n", "return", "module", ".", "get_incremental_state", "(", "incremental_state", ",", "key", ")", "\n", "\n", "\n", "", "def", "set_incremental_state", "(", "\n", "module", ":", "MultiheadAttention", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ",", "\n", "key", ":", "str", ",", "\n", "value", ":", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", ",", "\n", ")", "->", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", ":", "\n", "    ", "\"\"\"Helper for setting incremental state for an nn.Module.\"\"\"", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "        ", "result", "=", "module", ".", "set_incremental_state", "(", "incremental_state", ",", "key", ",", "value", ")", "\n", "if", "result", "is", "not", "None", ":", "\n", "            ", "incremental_state", "=", "result", "\n", "", "", "return", "incremental_state", "\n", "\n", "\n", "", "def", "load_align_dict", "(", "replace_unk", ")", ":", "\n", "    ", "if", "replace_unk", "is", "None", ":", "\n", "        ", "align_dict", "=", "None", "\n", "", "elif", "isinstance", "(", "replace_unk", ",", "str", ")", "and", "len", "(", "replace_unk", ")", ">", "0", ":", "\n", "# Load alignment dictionary for unknown word replacement if it was passed as an argument.", "\n", "        ", "align_dict", "=", "{", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pq.utils.get_layers": [[155, 191], ["map", "filter", "map", "map", "re.compile", "list", "operator.itemgetter", "model.named_parameters", "filter", "x.replace", "x.replace"], "function", ["None"], ["            ", "for", "line", "in", "f", ":", "\n", "                ", "cols", "=", "line", ".", "split", "(", ")", "\n", "align_dict", "[", "cols", "[", "0", "]", "]", "=", "cols", "[", "1", "]", "\n", "", "", "", "else", ":", "\n", "# No alignment dictionary provided but we still want to perform unknown word replacement by copying the", "\n", "# original source word.", "\n", "        ", "align_dict", "=", "{", "}", "\n", "", "return", "align_dict", "\n", "\n", "\n", "", "def", "print_embed_overlap", "(", "embed_dict", ",", "vocab_dict", ")", ":", "\n", "    ", "embed_keys", "=", "set", "(", "embed_dict", ".", "keys", "(", ")", ")", "\n", "vocab_keys", "=", "set", "(", "vocab_dict", ".", "symbols", ")", "\n", "overlap", "=", "len", "(", "embed_keys", "&", "vocab_keys", ")", "\n", "logger", ".", "info", "(", "\"found {}/{} types in embedding file\"", ".", "format", "(", "overlap", ",", "len", "(", "vocab_dict", ")", ")", ")", "\n", "\n", "\n", "", "def", "parse_embedding", "(", "embed_path", ")", ":", "\n", "    ", "\"\"\"Parse embedding text file into a dictionary of word and embedding tensors.\n\n    The first line can have vocabulary size and dimension. The following lines\n    should contain word and embedding separated by spaces.\n\n    Example:\n        2 5\n        the -0.0230 -0.0264  0.0287  0.0171  0.1403\n        at -0.0395 -0.1286  0.0275  0.0254 -0.0932\n    \"\"\"", "\n", "embed_dict", "=", "{", "}", "\n", "with", "open", "(", "embed_path", ")", "as", "f_embed", ":", "\n", "        ", "next", "(", "f_embed", ")", "# skip header", "\n", "for", "line", "in", "f_embed", ":", "\n", "            ", "pieces", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "embed_dict", "[", "pieces", "[", "0", "]", "]", "=", "torch", ".", "Tensor", "(", "\n", "[", "float", "(", "weight", ")", "for", "weight", "in", "pieces", "[", "1", ":", "]", "]", "\n", ")", "\n", "", "", "return", "embed_dict", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pq.utils.get_param": [[193, 250], ["KeyError", "str", "getattr", "len", "KeyError", "KeyError"], "function", ["None"], ["\n", "", "def", "load_embedding", "(", "embed_dict", ",", "vocab", ",", "embedding", ")", ":", "\n", "    ", "for", "idx", "in", "range", "(", "len", "(", "vocab", ")", ")", ":", "\n", "        ", "token", "=", "vocab", "[", "idx", "]", "\n", "if", "token", "in", "embed_dict", ":", "\n", "            ", "embedding", ".", "weight", ".", "data", "[", "idx", "]", "=", "embed_dict", "[", "token", "]", "\n", "", "", "return", "embedding", "\n", "\n", "\n", "", "def", "replace_unk", "(", "hypo_str", ",", "src_str", ",", "alignment", ",", "align_dict", ",", "unk", ")", ":", "\n", "    ", "from", "fairseq", "import", "tokenizer", "\n", "\n", "# Tokens are strings here", "\n", "hypo_tokens", "=", "tokenizer", ".", "tokenize_line", "(", "hypo_str", ")", "\n", "# TODO: Very rare cases where the replacement is '<eos>' should be handled gracefully", "\n", "src_tokens", "=", "tokenizer", ".", "tokenize_line", "(", "src_str", ")", "+", "[", "\"<eos>\"", "]", "\n", "for", "i", ",", "ht", "in", "enumerate", "(", "hypo_tokens", ")", ":", "\n", "        ", "if", "ht", "==", "unk", ":", "\n", "            ", "src_token", "=", "src_tokens", "[", "alignment", "[", "i", "]", "]", "\n", "# Either take the corresponding value in the aligned dictionary or just copy the original value.", "\n", "hypo_tokens", "[", "i", "]", "=", "align_dict", ".", "get", "(", "src_token", ",", "src_token", ")", "\n", "", "", "return", "\" \"", ".", "join", "(", "hypo_tokens", ")", "\n", "\n", "\n", "", "def", "post_process_prediction", "(", "\n", "hypo_tokens", ",", "\n", "src_str", ",", "\n", "alignment", ",", "\n", "align_dict", ",", "\n", "tgt_dict", ",", "\n", "remove_bpe", "=", "None", ",", "\n", "extra_symbols_to_ignore", "=", "None", ",", "\n", ")", ":", "\n", "    ", "hypo_str", "=", "tgt_dict", ".", "string", "(", "\n", "hypo_tokens", ",", "remove_bpe", ",", "extra_symbols_to_ignore", "=", "extra_symbols_to_ignore", "\n", ")", "\n", "if", "align_dict", "is", "not", "None", ":", "\n", "        ", "hypo_str", "=", "replace_unk", "(", "\n", "hypo_str", ",", "src_str", ",", "alignment", ",", "align_dict", ",", "tgt_dict", ".", "unk_string", "(", ")", "\n", ")", "\n", "", "if", "align_dict", "is", "not", "None", "or", "remove_bpe", "is", "not", "None", ":", "\n", "# Convert back to tokens for evaluating with unk replacement or without BPE", "\n", "# Note that the dictionary can be modified inside the method.", "\n", "        ", "hypo_tokens", "=", "tgt_dict", ".", "encode_line", "(", "hypo_str", ",", "add_if_not_exist", "=", "True", ")", "\n", "", "return", "hypo_tokens", ",", "hypo_str", ",", "alignment", "\n", "\n", "\n", "", "def", "make_positions", "(", "tensor", ",", "padding_idx", ":", "int", ",", "onnx_trace", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Replace non-padding symbols with their position numbers.\n\n    Position numbers begin at padding_idx+1. Padding symbols are ignored.\n    \"\"\"", "\n", "# The series of casts and type-conversions here are carefully", "\n", "# balanced to both work with ONNX export and XLA. In particular XLA", "\n", "# prefers ints, cumsum defaults to output longs, and ONNX doesn't know", "\n", "# how to handle the dtype kwarg in cumsum.", "\n", "mask", "=", "tensor", ".", "ne", "(", "padding_idx", ")", ".", "int", "(", ")", "\n", "return", "(", "torch", ".", "cumsum", "(", "mask", ",", "dim", "=", "1", ")", ".", "type_as", "(", "mask", ")", "*", "mask", ")", ".", "long", "(", ")", "+", "padding_idx", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pq.utils.attrsetter": [[322, 338], ["attr.split", "getattr", "utils.attrsetter.resolve_attr"], "function", ["None"], ["            ", "norms", "+=", "[", "torch", ".", "norm", "(", "g", ",", "p", "=", "2", ",", "dtype", "=", "torch", ".", "float32", ")", "for", "g", "in", "cur_device_grads", "]", "\n", "", "", "total_norm", "=", "torch", ".", "norm", "(", "torch", ".", "stack", "(", "norms", ")", ")", "\n", "return", "total_norm", "\n", "\n", "\n", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "clip_grad_norm_", "(", "params", ",", "max_norm", ",", "aggregate_norm_fn", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "if", "isinstance", "(", "params", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "params", "=", "[", "params", "]", "\n", "", "params", "=", "list", "(", "params", ")", "\n", "grads", "=", "[", "p", ".", "grad", ".", "detach", "(", ")", "for", "p", "in", "filter", "(", "lambda", "p", ":", "p", ".", "grad", "is", "not", "None", ",", "params", ")", "]", "\n", "if", "len", "(", "grads", ")", "==", "0", ":", "\n", "        ", "if", "len", "(", "params", ")", ">", "0", ":", "\n", "            ", "return", "params", "[", "0", "]", ".", "new_tensor", "(", "0.0", ")", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "tensor", "(", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.forward": [[18, 25], ["dynamicconv_cuda.forward", "ctx.save_for_backward"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.forward"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "weights", ",", "padding_l", ")", ":", "\n", "        ", "ctx", ".", "padding_l", "=", "padding_l", "\n", "outputs", "=", "dynamicconv_cuda", ".", "forward", "(", "x", ",", "weights", ",", "padding_l", ")", "\n", "variables", "=", "[", "x", ",", "weights", "]", "\n", "ctx", ".", "save_for_backward", "(", "*", "variables", ")", "\n", "return", "outputs", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward": [[26, 33], ["dynamicconv_cuda.backward", "grad_output.contiguous"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "outputs", "=", "dynamicconv_cuda", ".", "backward", "(", "\n", "grad_output", ".", "contiguous", "(", ")", ",", "ctx", ".", "padding_l", ",", "*", "ctx", ".", "saved_tensors", "\n", ")", "\n", "grad_input", ",", "grad_weights", "=", "outputs", "\n", "return", "grad_input", ",", "grad_weights", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.__init__": [[37, 70], ["torch.nn.Module.__init__", "fairseq.modules.fairseq_dropout.FairseqDropout", "torch.nn.Linear", "torch.nn.Linear", "dynamicconv_layer.DynamicconvLayer.reset_parameters", "torch.nn.Parameter", "torch.nn.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "input_size", ",", "\n", "kernel_size", "=", "1", ",", "\n", "padding_l", "=", "None", ",", "\n", "weight_softmax", "=", "False", ",", "\n", "num_heads", "=", "1", ",", "\n", "weight_dropout", "=", "0.0", ",", "\n", "bias", "=", "False", ",", "\n", "renorm_padding", "=", "False", ",", "\n", "conv_bias", "=", "False", ",", "\n", "query_size", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "super", "(", "DynamicconvLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "query_size", "=", "input_size", "if", "query_size", "is", "None", "else", "query_size", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "padding_l", "=", "padding_l", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "weight_softmax", "=", "weight_softmax", "\n", "self", ".", "weight_dropout_module", "=", "FairseqDropout", "(", "\n", "weight_dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "renorm_padding", "=", "renorm_padding", "\n", "self", ".", "bias", "=", "bias", "\n", "\n", "self", ".", "weight_linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "num_heads", "*", "kernel_size", ",", "bias", ")", "\n", "if", "conv_bias", ":", "\n", "            ", "self", ".", "conv_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "input_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv_bias", "=", "None", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reset_parameters": [[71, 76], ["torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "weight_linear", ".", "weight", ")", "\n", "if", "self", ".", "conv_bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "conv_bias", ",", "0.0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "weight_linaer", ".", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.forward": [[77, 120], ["x.permute().contiguous.permute().contiguous.size", "dynamicconv_layer.DynamicconvLayer.weight_linear().view", "dynamicconv_layer.DynamicconvLayer.permute().contiguous", "x.permute().contiguous.permute().contiguous.permute().contiguous", "dynamicconvFunction.apply().permute", "dynamicconv_layer.DynamicconvLayer._forward_unfolded", "dynamicconv_layer.DynamicconvLayer._forward_expanded", "torch.softmax", "torch.softmax", "dynamicconv_layer.DynamicconvLayer.weight_dropout_module", "x.permute().contiguous.permute().contiguous.size", "dynamicconv_layer.DynamicconvLayer.conv_bias.view", "dynamicconv_layer.DynamicconvLayer.weight_linear", "dynamicconv_layer.DynamicconvLayer.permute", "x.permute().contiguous.permute().contiguous.permute", "dynamicconvFunction.apply", "dynamicconv_layer.DynamicconvLayer.conv_bias.view"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._forward_unfolded", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._forward_expanded", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "incremental_state", "=", "None", ",", "query", "=", "None", ",", "unfold", "=", "None", ")", ":", "\n", "\n", "        ", "T", ",", "B", ",", "C", "=", "x", ".", "size", "(", ")", "\n", "K", ",", "H", "=", "self", ".", "kernel_size", ",", "self", ".", "num_heads", "\n", "# R = C // H", "\n", "\n", "# during inference time, incremental BMM is faster", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "unfold", "=", "(", "\n", "x", ".", "size", "(", "0", ")", ">", "512", "if", "unfold", "is", "None", "else", "unfold", "\n", ")", "# use unfold mode as default for long sequence to save memory", "\n", "unfold", "=", "unfold", "or", "(", "incremental_state", "is", "not", "None", ")", "\n", "assert", "query", "is", "None", "\n", "\n", "if", "query", "is", "None", ":", "\n", "                ", "query", "=", "x", "\n", "", "if", "unfold", ":", "\n", "                ", "output", "=", "self", ".", "_forward_unfolded", "(", "x", ",", "incremental_state", ",", "query", ")", "\n", "", "else", ":", "\n", "                ", "output", "=", "self", ".", "_forward_expanded", "(", "x", ",", "incremental_state", ",", "query", ")", "\n", "\n", "", "if", "self", ".", "conv_bias", "is", "not", "None", ":", "\n", "                ", "output", "=", "output", "+", "self", ".", "conv_bias", ".", "view", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "\n", "", "return", "output", "\n", "\n", "# during training time, use CUDA kernel", "\n", "", "else", ":", "\n", "            ", "weight", "=", "self", ".", "weight_linear", "(", "x", ")", ".", "view", "(", "T", ",", "B", ",", "H", ",", "K", ")", "\n", "if", "self", ".", "weight_softmax", ":", "\n", "                ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "-", "1", ")", "\n", "", "if", "self", ".", "weight_dropout_module", ".", "p", ":", "\n", "                ", "weight", "=", "self", ".", "weight_dropout_module", "(", "weight", ")", "\n", "\n", "", "weight", "=", "weight", ".", "permute", "(", "1", ",", "2", ",", "3", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "self", ".", "filters", "=", "weight", "\n", "x", "=", "x", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "output", "=", "dynamicconvFunction", ".", "apply", "(", "x", ",", "weight", ",", "self", ".", "padding_l", ")", ".", "permute", "(", "\n", "2", ",", "0", ",", "1", "\n", ")", "\n", "if", "self", ".", "conv_bias", "is", "not", "None", ":", "\n", "                ", "output", "=", "output", "+", "self", ".", "conv_bias", ".", "view", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer.reorder_incremental_state": [[121, 126], ["dynamicconv_layer.DynamicconvLayer._get_input_buffer", "input_buffer.index_select.index_select.index_select", "dynamicconv_layer.DynamicconvLayer._set_input_buffer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer"], ["", "", "def", "reorder_incremental_state", "(", "self", ",", "incremental_state", ",", "new_order", ")", ":", "\n", "        ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "not", "None", ":", "\n", "            ", "input_buffer", "=", "input_buffer", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer": [[127, 129], ["fairseq.utils.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_incremental_state"], ["", "", "def", "_get_input_buffer", "(", "self", ",", "incremental_state", ")", ":", "\n", "        ", "return", "utils", ".", "get_incremental_state", "(", "self", ",", "incremental_state", ",", "\"input_buffer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer": [[130, 133], ["fairseq.utils.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_incremental_state"], ["", "def", "_set_input_buffer", "(", "self", ",", "incremental_state", ",", "new_buffer", ")", ":", "\n", "        ", "return", "utils", ".", "set_incremental_state", "(", "\n", "self", ",", "incremental_state", ",", "\"input_buffer\"", ",", "new_buffer", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._forward_unfolded": [[135, 183], ["x.size", "dynamicconv_layer.DynamicconvLayer.weight_linear().view", "weight.narrow.narrow.narrow", "dynamicconv_layer.DynamicconvLayer.weight_dropout_module", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "output.view.view.view", "dynamicconv_layer.DynamicconvLayer._get_input_buffer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_unfold.view.view.view", "fairseq.modules.unfold.unfold1d", "x_unfold.view.view.view", "torch.softmax", "torch.softmax", "weight.narrow.narrow.size", "torch.softmax", "torch.softmax", "weight.narrow.narrow.unsqueeze", "dynamicconv_layer.DynamicconvLayer.weight_linear", "x.new", "dynamicconv_layer.DynamicconvLayer._set_input_buffer", "weight.narrow.narrow.narrow", "x.unsqueeze", "x_unfold.view.view.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._get_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.modules.unfold.unfold1d", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "_forward_unfolded", "(", "self", ",", "x", ",", "incremental_state", ",", "query", ")", ":", "\n", "        ", "\"\"\"The conventional implementation of convolutions.\n        Unfolding the input by having a window shifting to the right.\"\"\"", "\n", "T", ",", "B", ",", "C", "=", "x", ".", "size", "(", ")", "\n", "K", ",", "H", "=", "self", ".", "kernel_size", ",", "self", ".", "num_heads", "\n", "R", "=", "C", "//", "H", "\n", "assert", "R", "*", "H", "==", "C", "==", "self", ".", "input_size", "\n", "\n", "weight", "=", "self", ".", "weight_linear", "(", "query", ")", ".", "view", "(", "T", "*", "B", "*", "H", ",", "-", "1", ")", "\n", "\n", "# renorm_padding is only implemented in _forward_expanded", "\n", "assert", "not", "self", ".", "renorm_padding", "or", "incremental_state", "is", "not", "None", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "None", ":", "\n", "                ", "input_buffer", "=", "x", ".", "new", "(", ")", "\n", "", "x_unfold", "=", "torch", ".", "cat", "(", "[", "input_buffer", ",", "x", ".", "unsqueeze", "(", "3", ")", "]", ",", "dim", "=", "3", ")", "\n", "if", "self", ".", "kernel_size", ">", "1", ":", "\n", "                ", "self", ".", "_set_input_buffer", "(", "\n", "incremental_state", ",", "x_unfold", "[", ":", ",", ":", ",", ":", ",", "-", "self", ".", "kernel_size", "+", "1", ":", "]", "\n", ")", "\n", "", "x_unfold", "=", "x_unfold", ".", "view", "(", "T", "*", "B", "*", "H", ",", "R", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "padding_l", "=", "self", ".", "padding_l", "\n", "if", "K", ">", "T", "and", "padding_l", "==", "K", "-", "1", ":", "\n", "                ", "weight", "=", "weight", ".", "narrow", "(", "1", ",", "K", "-", "T", ",", "T", ")", "\n", "K", ",", "padding_l", "=", "T", ",", "T", "-", "1", "\n", "# unfold the input: T x B x C --> T' x B x C x K", "\n", "", "x_unfold", "=", "unfold1d", "(", "x", ",", "K", ",", "padding_l", ",", "0", ")", "\n", "x_unfold", "=", "x_unfold", ".", "view", "(", "T", "*", "B", "*", "H", ",", "R", ",", "K", ")", "\n", "\n", "", "if", "self", ".", "weight_softmax", "and", "not", "self", ".", "renorm_padding", ":", "\n", "            ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "1", ")", "\n", "", "weight", "=", "weight", ".", "narrow", "(", "1", ",", "0", ",", "K", ")", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "weight", "=", "weight", "[", ":", ",", "-", "x_unfold", ".", "size", "(", "2", ")", ":", "]", "\n", "K", "=", "weight", ".", "size", "(", "1", ")", "\n", "\n", "", "if", "self", ".", "weight_softmax", "and", "self", ".", "renorm_padding", ":", "\n", "            ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "1", ")", "\n", "\n", "", "weight", "=", "self", ".", "weight_dropout_module", "(", "weight", ",", "inplace", "=", "False", ")", "\n", "\n", "output", "=", "torch", ".", "bmm", "(", "x_unfold", ",", "weight", ".", "unsqueeze", "(", "2", ")", ")", "# T*B*H x R x 1", "\n", "output", "=", "output", ".", "view", "(", "T", ",", "B", ",", "C", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._forward_expanded": [[184, 228], ["x.view().transpose.view().transpose.size", "dynamicconv_layer.DynamicconvLayer.weight_linear().view", "weight.narrow.narrow.narrow().contiguous", "weight.narrow.narrow.view().transpose", "x.view().transpose.view().transpose.view().transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "output.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "dynamicconv_layer.DynamicconvLayer.weight_dropout_module", "weight.narrow.narrow.new().fill_", "weight_expanded.narrow.narrow.as_strided().copy_", "weight_expanded.narrow.narrow.narrow", "torch.softmax", "torch.softmax", "dynamicconv_layer.DynamicconvLayer.weight_dropout_module", "weight.narrow.narrow.new_zeros", "weight_expanded.narrow.narrow.as_strided().copy_", "weight_expanded.narrow.narrow.narrow", "dynamicconv_layer.DynamicconvLayer.weight_linear", "torch.softmax", "torch.softmax", "weight.narrow.narrow.narrow", "weight.narrow.narrow.view", "x.view().transpose.view().transpose.view", "float", "weight.narrow.narrow.narrow", "output.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "weight.narrow.narrow.new", "weight_expanded.narrow.narrow.as_strided", "weight_expanded.narrow.narrow.as_strided", "output.transpose().contiguous().view.transpose().contiguous().view.transpose"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax"], ["", "def", "_forward_expanded", "(", "self", ",", "x", ",", "incremental_stat", ",", "query", ")", ":", "\n", "        ", "\"\"\"Turn the convolution filters into band matrices and do matrix multiplication.\n        This is faster when the sequence is short, but less memory efficient.\n        This is not used in the decoder during inference.\n        \"\"\"", "\n", "T", ",", "B", ",", "C", "=", "x", ".", "size", "(", ")", "\n", "K", ",", "H", "=", "self", ".", "kernel_size", ",", "self", ".", "num_heads", "\n", "R", "=", "C", "//", "H", "\n", "assert", "R", "*", "H", "==", "C", "==", "self", ".", "input_size", "\n", "weight", "=", "self", ".", "weight_linear", "(", "query", ")", ".", "view", "(", "T", "*", "B", "*", "H", ",", "-", "1", ")", "\n", "\n", "if", "not", "self", ".", "renorm_padding", ":", "\n", "            ", "if", "self", ".", "weight_softmax", ":", "\n", "                ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "1", ")", "\n", "", "weight", "=", "self", ".", "weight_dropout_module", "(", "weight", ",", "inplace", "=", "False", ")", "\n", "", "weight", "=", "weight", ".", "narrow", "(", "1", ",", "0", ",", "K", ")", ".", "contiguous", "(", ")", "\n", "weight", "=", "weight", ".", "view", "(", "T", ",", "B", "*", "H", ",", "K", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "x", "=", "x", ".", "view", "(", "T", ",", "B", "*", "H", ",", "R", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "self", ".", "weight_softmax", "and", "self", ".", "renorm_padding", ":", "\n", "# turn the convolution filters into band matrices", "\n", "            ", "weight_expanded", "=", "weight", ".", "new", "(", "B", "*", "H", ",", "T", ",", "T", "+", "K", "-", "1", ")", ".", "fill_", "(", "float", "(", "\"-inf\"", ")", ")", "\n", "weight_expanded", ".", "as_strided", "(", "\n", "(", "B", "*", "H", ",", "T", ",", "K", ")", ",", "(", "T", "*", "(", "T", "+", "K", "-", "1", ")", ",", "T", "+", "K", ",", "1", ")", "\n", ")", ".", "copy_", "(", "weight", ")", "\n", "weight_expanded", "=", "weight_expanded", ".", "narrow", "(", "2", ",", "self", ".", "padding_l", ",", "T", ")", "\n", "# normalize the weight over valid positions like self-attention", "\n", "weight_expanded", "=", "F", ".", "softmax", "(", "weight_expanded", ",", "dim", "=", "2", ")", "\n", "weight_expanded", "=", "self", ".", "weight_dropout_module", "(", "weight_expanded", ",", "inplace", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "P", "=", "self", ".", "padding_l", "\n", "# For efficieny, we cut the kernel size and reduce the padding when the kernel is larger than the length", "\n", "if", "K", ">", "T", "and", "P", "==", "K", "-", "1", ":", "\n", "                ", "weight", "=", "weight", ".", "narrow", "(", "2", ",", "K", "-", "T", ",", "T", ")", "\n", "K", ",", "P", "=", "T", ",", "T", "-", "1", "\n", "# turn the convolution filters into band matrices", "\n", "", "weight_expanded", "=", "weight", ".", "new_zeros", "(", "B", "*", "H", ",", "T", ",", "T", "+", "K", "-", "1", ",", "requires_grad", "=", "False", ")", "\n", "weight_expanded", ".", "as_strided", "(", "\n", "(", "B", "*", "H", ",", "T", ",", "K", ")", ",", "(", "T", "*", "(", "T", "+", "K", "-", "1", ")", ",", "T", "+", "K", ",", "1", ")", "\n", ")", ".", "copy_", "(", "weight", ")", "\n", "weight_expanded", "=", "weight_expanded", ".", "narrow", "(", "2", ",", "P", ",", "T", ")", "# B*H x T x T", "\n", "", "output", "=", "torch", ".", "bmm", "(", "weight_expanded", ",", "x", ")", "\n", "output", "=", "output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "T", ",", "B", ",", "C", ")", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.cuda_function_gen.gen_forward": [[7, 94], ["open", "forward.write", "forward.write", "forward.write", "forward.write", "forward.write", "case_k.format", "forward.write", "main_block.format"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["def", "gen_forward", "(", ")", ":", "\n", "\n", "    ", "kernels", "=", "[", "3", ",", "5", ",", "7", ",", "15", ",", "31", ",", "63", ",", "127", ",", "255", "]", "\n", "seqs", "=", "[", "32", "*", "x", "for", "x", "in", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", ",", "11", ",", "12", ",", "13", ",", "14", ",", "15", ",", "16", "]", "]", "\n", "\n", "head", "=", "\"\"\"\n/**\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n#include \"lightconv_cuda.cuh\"\n\nstd::vector<at::Tensor> lightconv_cuda_forward(at::Tensor input, at::Tensor filters, int padding_l) {\n\n    at::DeviceGuard g(input.device());\n    const auto minibatch = input.size(0);\n    const auto numFeatures = input.size(1);\n    const auto sequenceLength = input.size(2);\n\n    const auto numHeads = filters.size(0);\n    const auto filterSize = filters.size(1);\n\n    const auto numFiltersInBlock = numFeatures / numHeads;\n\n    const dim3 blocks(minibatch, numFeatures);\n\n    auto output = at::zeros_like(input);\n    auto stream = at::cuda::getCurrentCUDAStream();\n\"\"\"", "\n", "\n", "sequence_if", "=", "\"\"\"\n    if (sequenceLength <= {seq}) {{\n        switch(filterSize) {{\n\"\"\"", "\n", "\n", "case_k", "=", "\"\"\"\n            case {k}:\n\"\"\"", "\n", "\n", "main_block", "=", "\"\"\"\n                if (padding_l == {pad}) {{\n                    AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.scalar_type(), \"lightconv_forward\", ([&] {{\n                        lightconv_forward_kernel<{k}, {b_size}, {pad}, scalar_t>\n                        <<<blocks, {b_size}, 0, stream>>>(\n                                input.data<scalar_t>(),\n                                filters.data<scalar_t>(),\n                                minibatch,\n                                sequenceLength,\n                                numFeatures,\n                                numFiltersInBlock,\n                                output.data<scalar_t>());\n                    }}));\n                }} else\n\"\"\"", "\n", "\n", "bad_padding", "=", "\"\"\"\n                {\n                    std::cout << \"WARNING: Unsupported padding size - skipping forward pass\" << std::endl;\n                }\n                break;\n\"\"\"", "\n", "\n", "bad_filter", "=", "\"\"\"\n            default:\n                std::cout << \"WARNING: Unsupported filter length passed - skipping forward pass\" << std::endl;\n        }\n\"\"\"", "\n", "\n", "con_else", "=", "\"\"\"\n    } else\n\"\"\"", "\n", "\n", "final_else", "=", "\"\"\"\n    {\n        switch(filterSize) {\n\"\"\"", "\n", "\n", "final_return", "=", "\"\"\"\n    }\n\n    return {output};\n}\n\"\"\"", "\n", "\n", "with", "open", "(", "\"lightconv_cuda_forward.cu\"", ",", "\"w\"", ")", "as", "forward", ":", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.cuda_function_gen.gen_backward": [[96, 219], ["open", "backward.write", "backward.write", "zip", "backward.write", "backward.write", "backward.write", "zip", "backward.write", "backward.write", "backward.write", "backward.write", "backward.write", "sequence_if.format", "backward.write", "backward.write", "case_k.format", "chunks_reset.format", "backward.write", "case_k.format", "backward.write", "backward.write", "main_block.format", "chunks_reset.format", "main_block.format"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["for", "seq", "in", "seqs", ":", "\n", "            ", "forward", ".", "write", "(", "sequence_if", ".", "format", "(", "seq", "=", "seq", ")", ")", "\n", "for", "k", "in", "kernels", ":", "\n", "                ", "forward", ".", "write", "(", "case_k", ".", "format", "(", "k", "=", "k", ")", ")", "\n", "for", "pad", "in", "[", "k", "//", "2", ",", "k", "-", "1", "]", ":", "\n", "                    ", "forward", ".", "write", "(", "main_block", ".", "format", "(", "k", "=", "k", ",", "b_size", "=", "seq", ",", "pad", "=", "pad", ")", ")", "\n", "", "forward", ".", "write", "(", "bad_padding", ")", "\n", "", "forward", ".", "write", "(", "bad_filter", ")", "\n", "forward", ".", "write", "(", "con_else", ")", "\n", "\n", "", "forward", ".", "write", "(", "final_else", ")", "\n", "for", "k", "in", "kernels", ":", "\n", "            ", "forward", ".", "write", "(", "case_k", ".", "format", "(", "k", "=", "k", ")", ")", "\n", "for", "pad", "in", "[", "k", "//", "2", ",", "k", "-", "1", "]", ":", "\n", "                ", "forward", ".", "write", "(", "main_block", ".", "format", "(", "k", "=", "k", ",", "b_size", "=", "seq", ",", "pad", "=", "pad", ")", ")", "\n", "", "forward", ".", "write", "(", "bad_padding", ")", "\n", "", "forward", ".", "write", "(", "bad_filter", ")", "\n", "forward", ".", "write", "(", "final_return", ")", "\n", "\n", "\n", "", "", "def", "gen_backward", "(", ")", ":", "\n", "\n", "    ", "head", "=", "\"\"\"\n/**\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n#include \"lightconv_cuda.cuh\"\n\nstd::vector<at::Tensor> lightconv_cuda_backward(\n        at::Tensor gradOutput,\n        int padding_l,\n        at::Tensor input,\n        at::Tensor filters) {\n\n    // gradWrtInput\n    const int minibatch = input.size(0);\n    const int numFeatures = input.size(1);\n    const int sequenceLength = input.size(2);\n\n    const int numHeads = filters.size(0);\n    const int filterSize = filters.size(1);\n\n    const dim3 gradBlocks(minibatch, numFeatures);\n    const dim3 weightGradFirstpassShortBlocks(minibatch, numHeads);\n    const dim3 weightGradSecondpassBlocks(numHeads, filterSize);\n\n    const int numFiltersInBlock = numFeatures / numHeads;\n\n    auto gradInput = at::zeros_like(input);\n    auto gradFilters = at::zeros_like(filters);\n\n    at::DeviceGuard g(input.device());\n    auto stream = at::cuda::getCurrentCUDAStream();\n\n    switch(filterSize) {\n\"\"\"", "\n", "\n", "sequence_if", "=", "\"\"\"\n            if (sequenceLength <= {seq}) {{\n\"\"\"", "\n", "\n", "case_k", "=", "\"\"\"\n        case {k}:\n\"\"\"", "\n", "\n", "main_block", "=", "\"\"\"\n                if (padding_l == {p}) {{\n                    AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.scalar_type(), \"lightconv_backward\", ([&] {{\n                        lightconv_grad_wrt_input_kernel<{k}, {b_size}, {p}, scalar_t>\n                        <<<gradBlocks, {b_size}, 0, stream>>>(\n                                gradOutput.data<scalar_t>(),\n                                filters.data<scalar_t>(),\n                                minibatch,\n                                sequenceLength,\n                                numFeatures,\n                                numFiltersInBlock,\n                                gradInput.data<scalar_t>());\n\n\"\"\"", "\n", "\n", "weight_grad_short", "=", "\"\"\"\n                        at::Tensor tempSumGradFilters = at::zeros({{minibatch, numHeads, filterSize}}, input.options().dtype(at::kFloat));\n                        lightconv_grad_wrt_weights_firstpass_short_kernel<{k}, {b_size}, {p}, scalar_t>\n                        <<<weightGradFirstpassShortBlocks, {b_size}, 0, stream>>>(\n                                input.data<scalar_t>(),\n                                gradOutput.data<scalar_t>(),\n                                minibatch,\n                                sequenceLength,\n                                numFeatures,\n                                numFiltersInBlock,\n                                numHeads,\n                                tempSumGradFilters.data<float>()\n                        );\n\n                        lightconv_grad_wrt_weights_secondpass_short_kernel<{k}, {b_size}, scalar_t>\n                        <<<weightGradSecondpassBlocks, {b_size}, 0, stream>>>(\n                                tempSumGradFilters.data<float>(),\n                                minibatch,\n                                numFiltersInBlock,\n                                gradFilters.data<scalar_t>()\n                        );\n                    }}));\n                }} else\n\"\"\"", "\n", "\n", "weight_grad", "="]], "home.repos.pwc.inspect_result.reneeye_const.tasks.semisupervised_translation.SemisupervisedTranslationTask.add_args": [[87, 121], ["multilingual_translation.MultilingualTranslationTask.add_args", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args"], ["@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "MultilingualTranslationTask", ".", "add_args", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda-parallel-config'", ",", "default", "=", "\"1.0\"", ",", "type", "=", "str", ",", "metavar", "=", "'CONFIG'", ",", "\n", "help", "=", "'cross-entropy reconstruction coefficient (parallel data). '", "\n", "'use fixed weight during training if set to floating point number. '", "\n", "'use piecewise linear function over number of updates to schedule the '", "\n", "'weight with the format: w0:step0,w1:step1,...'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda-denoising-config'", ",", "default", "=", "\"0.0\"", ",", "type", "=", "str", ",", "metavar", "=", "'CONFIG'", ",", "\n", "help", "=", "'Cross-entropy reconstruction coefficient (denoising autoencoding)'", "\n", "'use fixed weight during training if set to floating point number. '", "\n", "'use piecewise linear function over number of updates to schedule the '", "\n", "'weight with the format: w0:step0,w1:step1,...'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda-otf-bt-config'", ",", "default", "=", "\"0.0\"", ",", "type", "=", "str", ",", "metavar", "=", "'CONFIG'", ",", "\n", "help", "=", "'cross-entropy reconstruction coefficient (on-the-fly back-translation parallel data)'", "\n", "'use fixed weight during training if set to floating point number. '", "\n", "'use piecewise linear function over number of updates to schedule the '", "\n", "'weight with the format: w0:step0,w1:step1,...'", ")", "\n", "parser", ".", "add_argument", "(", "'--bt-max-len-a'", ",", "default", "=", "1.1", ",", "type", "=", "float", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'generate back-translated sequences of maximum length ax + b, where x is the '", "\n", "'source length'", ")", "\n", "parser", ".", "add_argument", "(", "'--bt-max-len-b'", ",", "default", "=", "10.0", ",", "type", "=", "float", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'generate back-translated sequences of maximum length ax + b, where x is the '", "\n", "'source length'", ")", "\n", "parser", ".", "add_argument", "(", "'--bt-beam-size'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'beam size used in beam search of online back-translation'", ")", "\n", "parser", ".", "add_argument", "(", "'--max-word-shuffle-distance'", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'maximum word shuffle distance for denoising autoencoding data generation'", ")", "\n", "parser", ".", "add_argument", "(", "'--word-dropout-prob'", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'word dropout probability for denoising autoencoding data generation'", ")", "\n", "parser", ".", "add_argument", "(", "'--word-blanking-prob'", ",", "default", "=", "0.2", ",", "type", "=", "float", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'word blanking probability for denoising autoencoding data generation'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.semisupervised_translation.SemisupervisedTranslationTask.__init__": [[123, 142], ["multilingual_translation.MultilingualTranslationTask.__init__", "semisupervised_translation.parse_lambda_config", "semisupervised_translation.parse_lambda_config", "semisupervised_translation.parse_lambda_config", "lang_pair.split"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.tasks.semisupervised_translation.parse_lambda_config", "home.repos.pwc.inspect_result.reneeye_const.tasks.semisupervised_translation.parse_lambda_config", "home.repos.pwc.inspect_result.reneeye_const.tasks.semisupervised_translation.parse_lambda_config"], ["", "def", "__init__", "(", "self", ",", "args", ",", "dicts", ",", "training", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "dicts", ",", "training", ")", "\n", "self", ".", "lambda_parallel", ",", "self", ".", "lambda_parallel_steps", "=", "parse_lambda_config", "(", "\n", "args", ".", "lambda_parallel_config", "\n", ")", "\n", "self", ".", "lambda_otf_bt", ",", "self", ".", "lambda_otf_bt_steps", "=", "parse_lambda_config", "(", "\n", "args", ".", "lambda_otf_bt_config", "\n", ")", "\n", "self", ".", "lambda_denoising", ",", "self", ".", "lambda_denoising_steps", "=", "parse_lambda_config", "(", "\n", "args", ".", "lambda_denoising_config", "\n", ")", "\n", "if", "self", ".", "lambda_denoising", ">", "0.0", "or", "self", ".", "lambda_denoising_steps", "is", "not", "None", ":", "\n", "            ", "denoising_lang_pairs", "=", "[", "\n", "\"%s-%s\"", "%", "(", "tgt", ",", "tgt", ")", "\n", "for", "tgt", "in", "{", "lang_pair", ".", "split", "(", "\"-\"", ")", "[", "1", "]", "for", "lang_pair", "in", "args", ".", "lang_pairs", "}", "\n", "]", "\n", "self", ".", "model_lang_pairs", "=", "self", ".", "model_lang_pairs", "+", "denoising_lang_pairs", "\n", "", "self", ".", "backtranslate_datasets", "=", "{", "}", "\n", "self", ".", "backtranslators", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.semisupervised_translation.SemisupervisedTranslationTask.setup_task": [[143, 147], ["multilingual_translation.MultilingualTranslationTask.prepare", "cls"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.prepare", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "dicts", ",", "training", "=", "MultilingualTranslationTask", ".", "prepare", "(", "args", ",", "**", "kwargs", ")", "\n", "return", "cls", "(", "args", ",", "dicts", ",", "training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.semisupervised_translation.SemisupervisedTranslationTask.load_dataset": [[148, 354], ["fairseq.utils.split_paths", "fairseq.data.RoundRobinZipDatasets", "len", "fairseq.data.indexed_dataset.dataset_exists", "fairseq.data.data_utils.load_indexed_dataset", "split.startswith", "split.startswith", "lang_pair.split", "semisupervised_translation.SemisupervisedTranslationTask.alter_dataset_langtok", "collections.OrderedDict", "os.path.join", "os.path.join", "split.startswith", "lang_pair.split", "semisupervised_translation.SemisupervisedTranslationTask.load_dataset.split_exists"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.dataset_exists", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.load_indexed_dataset", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.alter_dataset_langtok", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.split_exists"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a dataset split.\"\"\"", "\n", "paths", "=", "utils", ".", "split_paths", "(", "self", ".", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "data_path", "=", "paths", "[", "(", "epoch", "-", "1", ")", "%", "len", "(", "paths", ")", "]", "\n", "\n", "def", "split_exists", "(", "split", ",", "src", ",", "tgt", ",", "lang", ")", ":", "\n", "            ", "if", "src", "is", "not", "None", ":", "\n", "                ", "filename", "=", "os", ".", "path", ".", "join", "(", "\n", "data_path", ",", "\"{}.{}-{}.{}\"", ".", "format", "(", "split", ",", "src", ",", "tgt", ",", "lang", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "filename", "=", "os", ".", "path", ".", "join", "(", "\n", "data_path", ",", "\"{}.{}-None.{}\"", ".", "format", "(", "split", ",", "src", ",", "tgt", ")", "\n", ")", "\n", "", "return", "indexed_dataset", ".", "dataset_exists", "(", "filename", ",", "impl", "=", "self", ".", "args", ".", "dataset_impl", ")", "\n", "\n", "", "def", "load_indexed_dataset", "(", "path", ",", "dictionary", ")", ":", "\n", "            ", "return", "data_utils", ".", "load_indexed_dataset", "(", "\n", "path", ",", "dictionary", ",", "self", ".", "args", ".", "dataset_impl", "\n", ")", "\n", "\n", "# load parallel datasets", "\n", "", "src_datasets", ",", "tgt_datasets", "=", "{", "}", ",", "{", "}", "\n", "if", "(", "\n", "self", ".", "lambda_parallel", ">", "0.0", "\n", "or", "self", ".", "lambda_parallel_steps", "is", "not", "None", "\n", "or", "not", "split", ".", "startswith", "(", "\"train\"", ")", "\n", ")", ":", "\n", "            ", "for", "lang_pair", "in", "self", ".", "lang_pairs", ":", "\n", "                ", "src", ",", "tgt", "=", "lang_pair", ".", "split", "(", "\"-\"", ")", "\n", "if", "split_exists", "(", "split", ",", "src", ",", "tgt", ",", "src", ")", ":", "\n", "                    ", "prefix", "=", "os", ".", "path", ".", "join", "(", "\n", "data_path", ",", "\"{}.{}-{}.\"", ".", "format", "(", "split", ",", "src", ",", "tgt", ")", "\n", ")", "\n", "", "elif", "split_exists", "(", "split", ",", "tgt", ",", "src", ",", "src", ")", ":", "\n", "                    ", "prefix", "=", "os", ".", "path", ".", "join", "(", "\n", "data_path", ",", "\"{}.{}-{}.\"", ".", "format", "(", "split", ",", "tgt", ",", "src", ")", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "continue", "\n", "", "src_datasets", "[", "lang_pair", "]", "=", "load_indexed_dataset", "(", "\n", "prefix", "+", "src", ",", "self", ".", "dicts", "[", "src", "]", "\n", ")", "\n", "tgt_datasets", "[", "lang_pair", "]", "=", "load_indexed_dataset", "(", "\n", "prefix", "+", "tgt", ",", "self", ".", "dicts", "[", "tgt", "]", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"parallel-{} {} {} examples\"", ".", "format", "(", "\n", "data_path", ",", "split", ",", "len", "(", "src_datasets", "[", "lang_pair", "]", ")", "\n", ")", "\n", ")", "\n", "", "if", "len", "(", "src_datasets", ")", "==", "0", ":", "\n", "                ", "raise", "FileNotFoundError", "(", "\n", "\"Dataset not found: {} ({})\"", ".", "format", "(", "split", ",", "data_path", ")", "\n", ")", "\n", "\n", "# back translation datasets", "\n", "", "", "backtranslate_datasets", "=", "{", "}", "\n", "if", "(", "\n", "self", ".", "lambda_otf_bt", ">", "0.0", "or", "self", ".", "lambda_otf_bt_steps", "is", "not", "None", "\n", ")", "and", "split", ".", "startswith", "(", "\"train\"", ")", ":", "\n", "            ", "for", "lang_pair", "in", "self", ".", "lang_pairs", ":", "\n", "                ", "src", ",", "tgt", "=", "lang_pair", ".", "split", "(", "\"-\"", ")", "\n", "if", "not", "split_exists", "(", "split", ",", "tgt", ",", "None", ",", "tgt", ")", ":", "\n", "                    ", "raise", "FileNotFoundError", "(", "\n", "\"Dataset not found: backtranslation {} ({})\"", ".", "format", "(", "\n", "split", ",", "data_path", "\n", ")", "\n", ")", "\n", "", "filename", "=", "os", ".", "path", ".", "join", "(", "\n", "data_path", ",", "\"{}.{}-None.{}\"", ".", "format", "(", "split", ",", "tgt", ",", "tgt", ")", "\n", ")", "\n", "dataset", "=", "load_indexed_dataset", "(", "filename", ",", "self", ".", "dicts", "[", "tgt", "]", ")", "\n", "lang_pair_dataset_tgt", "=", "LanguagePairDataset", "(", "\n", "dataset", ",", "\n", "dataset", ".", "sizes", ",", "\n", "self", ".", "dicts", "[", "tgt", "]", ",", "\n", "left_pad_source", "=", "self", ".", "args", ".", "left_pad_source", ",", "\n", "left_pad_target", "=", "self", ".", "args", ".", "left_pad_target", ",", "\n", ")", "\n", "lang_pair_dataset", "=", "LanguagePairDataset", "(", "\n", "dataset", ",", "\n", "dataset", ".", "sizes", ",", "\n", "src_dict", "=", "self", ".", "dicts", "[", "src", "]", ",", "\n", "tgt", "=", "dataset", ",", "\n", "tgt_sizes", "=", "dataset", ".", "sizes", ",", "\n", "tgt_dict", "=", "self", ".", "dicts", "[", "tgt", "]", ",", "\n", "left_pad_source", "=", "self", ".", "args", ".", "left_pad_source", ",", "\n", "left_pad_target", "=", "self", ".", "args", ".", "left_pad_target", ",", "\n", ")", "\n", "backtranslate_datasets", "[", "lang_pair", "]", "=", "BacktranslationDataset", "(", "\n", "tgt_dataset", "=", "self", ".", "alter_dataset_langtok", "(", "\n", "lang_pair_dataset_tgt", ",", "\n", "src_eos", "=", "self", ".", "dicts", "[", "tgt", "]", ".", "eos", "(", ")", ",", "\n", "src_lang", "=", "tgt", ",", "\n", "tgt_lang", "=", "src", ",", "\n", ")", ",", "\n", "backtranslation_fn", "=", "self", ".", "backtranslators", "[", "lang_pair", "]", ",", "\n", "src_dict", "=", "self", ".", "dicts", "[", "src", "]", ",", "\n", "tgt_dict", "=", "self", ".", "dicts", "[", "tgt", "]", ",", "\n", "output_collater", "=", "self", ".", "alter_dataset_langtok", "(", "\n", "lang_pair_dataset", "=", "lang_pair_dataset", ",", "\n", "src_eos", "=", "self", ".", "dicts", "[", "src", "]", ".", "eos", "(", ")", ",", "\n", "src_lang", "=", "src", ",", "\n", "tgt_eos", "=", "self", ".", "dicts", "[", "tgt", "]", ".", "eos", "(", ")", ",", "\n", "tgt_lang", "=", "tgt", ",", "\n", ")", ".", "collater", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"backtranslate-{}: {} {} {} examples\"", ".", "format", "(", "\n", "tgt", ",", "\n", "data_path", ",", "\n", "split", ",", "\n", "len", "(", "backtranslate_datasets", "[", "lang_pair", "]", ")", ",", "\n", ")", "\n", ")", "\n", "self", ".", "backtranslate_datasets", "[", "lang_pair", "]", "=", "backtranslate_datasets", "[", "\n", "lang_pair", "\n", "]", "\n", "\n", "# denoising autoencoder", "\n", "", "", "noising_datasets", "=", "{", "}", "\n", "if", "(", "\n", "self", ".", "lambda_denoising", ">", "0.0", "or", "self", ".", "lambda_denoising_steps", "is", "not", "None", "\n", ")", "and", "split", ".", "startswith", "(", "\"train\"", ")", ":", "\n", "            ", "for", "lang_pair", "in", "self", ".", "lang_pairs", ":", "\n", "                ", "_", ",", "tgt", "=", "lang_pair", ".", "split", "(", "\"-\"", ")", "\n", "if", "not", "split_exists", "(", "split", ",", "tgt", ",", "None", ",", "tgt", ")", ":", "\n", "                    ", "continue", "\n", "", "filename", "=", "os", ".", "path", ".", "join", "(", "\n", "data_path", ",", "\"{}.{}-None.{}\"", ".", "format", "(", "split", ",", "tgt", ",", "tgt", ")", "\n", ")", "\n", "tgt_dataset1", "=", "load_indexed_dataset", "(", "filename", ",", "self", ".", "dicts", "[", "tgt", "]", ")", "\n", "tgt_dataset2", "=", "load_indexed_dataset", "(", "filename", ",", "self", ".", "dicts", "[", "tgt", "]", ")", "\n", "noising_dataset", "=", "NoisingDataset", "(", "\n", "tgt_dataset1", ",", "\n", "self", ".", "dicts", "[", "tgt", "]", ",", "\n", "seed", "=", "1", ",", "\n", "max_word_shuffle_distance", "=", "self", ".", "args", ".", "max_word_shuffle_distance", ",", "\n", "word_dropout_prob", "=", "self", ".", "args", ".", "word_dropout_prob", ",", "\n", "word_blanking_prob", "=", "self", ".", "args", ".", "word_blanking_prob", ",", "\n", ")", "\n", "noising_datasets", "[", "lang_pair", "]", "=", "self", ".", "alter_dataset_langtok", "(", "\n", "LanguagePairDataset", "(", "\n", "noising_dataset", ",", "\n", "tgt_dataset1", ".", "sizes", ",", "\n", "self", ".", "dicts", "[", "tgt", "]", ",", "\n", "tgt_dataset2", ",", "\n", "tgt_dataset2", ".", "sizes", ",", "\n", "self", ".", "dicts", "[", "tgt", "]", ",", "\n", "left_pad_source", "=", "self", ".", "args", ".", "left_pad_source", ",", "\n", "left_pad_target", "=", "self", ".", "args", ".", "left_pad_target", ",", "\n", ")", ",", "\n", "src_eos", "=", "self", ".", "dicts", "[", "tgt", "]", ".", "eos", "(", ")", ",", "\n", "src_lang", "=", "tgt", ",", "\n", "tgt_eos", "=", "self", ".", "dicts", "[", "tgt", "]", ".", "eos", "(", ")", ",", "\n", "tgt_lang", "=", "tgt", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"denoising-{}: {} {} {} examples\"", ".", "format", "(", "\n", "tgt", ",", "\n", "data_path", ",", "\n", "split", ",", "\n", "len", "(", "noising_datasets", "[", "lang_pair", "]", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "", "", "def", "language_pair_dataset", "(", "lang_pair", ")", ":", "\n", "            ", "src", ",", "tgt", "=", "lang_pair", ".", "split", "(", "\"-\"", ")", "\n", "src_dataset", ",", "tgt_dataset", "=", "src_datasets", "[", "lang_pair", "]", ",", "tgt_datasets", "[", "lang_pair", "]", "\n", "return", "self", ".", "alter_dataset_langtok", "(", "\n", "LanguagePairDataset", "(", "\n", "src_dataset", ",", "\n", "src_dataset", ".", "sizes", ",", "\n", "self", ".", "dicts", "[", "src", "]", ",", "\n", "tgt_dataset", ",", "\n", "tgt_dataset", ".", "sizes", ",", "\n", "self", ".", "dicts", "[", "tgt", "]", ",", "\n", "left_pad_source", "=", "self", ".", "args", ".", "left_pad_source", ",", "\n", "left_pad_target", "=", "self", ".", "args", ".", "left_pad_target", ",", "\n", ")", ",", "\n", "self", ".", "dicts", "[", "src", "]", ".", "eos", "(", ")", ",", "\n", "src", ",", "\n", "self", ".", "dicts", "[", "tgt", "]", ".", "eos", "(", ")", ",", "\n", "tgt", ",", "\n", ")", "\n", "\n", "", "self", ".", "datasets", "[", "split", "]", "=", "RoundRobinZipDatasets", "(", "\n", "OrderedDict", "(", "\n", "[", "\n", "(", "lang_pair", ",", "language_pair_dataset", "(", "lang_pair", ")", ")", "\n", "for", "lang_pair", "in", "src_datasets", ".", "keys", "(", ")", "\n", "]", "\n", "+", "[", "\n", "(", "_get_bt_dataset_key", "(", "lang_pair", ")", ",", "dataset", ")", "\n", "for", "lang_pair", ",", "dataset", "in", "backtranslate_datasets", ".", "items", "(", ")", "\n", "]", "\n", "+", "[", "\n", "(", "_get_denoising_dataset_key", "(", "lang_pair", ")", ",", "dataset", ")", "\n", "for", "lang_pair", ",", "dataset", "in", "noising_datasets", ".", "items", "(", ")", "\n", "]", "\n", ")", ",", "\n", "eval_key", "=", "None", "\n", "if", "self", ".", "training", "\n", "else", "\"%s-%s\"", "%", "(", "self", ".", "args", ".", "source_lang", ",", "self", ".", "args", ".", "target_lang", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.semisupervised_translation.SemisupervisedTranslationTask.build_model": [[356, 397], ["models.build_model", "isinstance", "ValueError", "lang_pair.split", "fairseq.sequence_generator.SequenceGenerator", "semisupervised_translation.SemisupervisedTranslationTask.get_decoder_langtok", "sequence_generator.generate"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_decoder_langtok", "home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.generate"], ["", "def", "build_model", "(", "self", ",", "args", ")", ":", "\n", "        ", "from", "fairseq", "import", "models", "\n", "\n", "model", "=", "models", ".", "build_model", "(", "args", ",", "self", ")", "\n", "if", "not", "isinstance", "(", "model", ",", "FairseqMultiModel", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"SemisupervisedTranslationTask requires a FairseqMultiModel architecture\"", "\n", ")", "\n", "\n", "# create SequenceGenerator for each model that has backtranslation dependency on it", "\n", "", "self", ".", "sequence_generators", "=", "{", "}", "\n", "if", "(", "\n", "self", ".", "lambda_otf_bt", ">", "0.0", "or", "self", ".", "lambda_otf_bt_steps", "is", "not", "None", "\n", ")", "and", "self", ".", "training", ":", "\n", "            ", "for", "lang_pair", "in", "self", ".", "lang_pairs", ":", "\n", "                ", "src", ",", "tgt", "=", "lang_pair", ".", "split", "(", "\"-\"", ")", "\n", "key", "=", "\"{}-{}\"", ".", "format", "(", "tgt", ",", "src", ")", "\n", "self", ".", "sequence_generators", "[", "key", "]", "=", "SequenceGenerator", "(", "\n", "[", "model", ".", "models", "[", "key", "]", "]", ",", "\n", "tgt_dict", "=", "self", ".", "dicts", "[", "src", "]", ",", "\n", "beam_size", "=", "args", ".", "bt_beam_size", ",", "\n", "max_len_a", "=", "args", ".", "bt_max_len_a", ",", "\n", "max_len_b", "=", "args", ".", "bt_max_len_b", ",", "\n", ")", "\n", "decoder_lang_tok_idx", "=", "self", ".", "get_decoder_langtok", "(", "src", ")", "\n", "\n", "def", "backtranslate_fn", "(", "\n", "sample", ",", "\n", "model", "=", "model", ".", "models", "[", "key", "]", ",", "\n", "bos_token", "=", "decoder_lang_tok_idx", ",", "\n", "sequence_generator", "=", "self", ".", "sequence_generators", "[", "key", "]", ",", "\n", ")", ":", "\n", "                    ", "return", "sequence_generator", ".", "generate", "(", "\n", "[", "model", "]", ",", "\n", "sample", ",", "\n", "bos_token", "=", "bos_token", ",", "\n", ")", "\n", "\n", "", "self", ".", "backtranslators", "[", "lang_pair", "]", "=", "backtranslate_fn", "\n", "\n", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.semisupervised_translation.SemisupervisedTranslationTask.train_step": [[398, 456], ["model.train", "semisupervised_translation.SemisupervisedTranslationTask.update_step", "criterion", "optimizer.backward", "loss.detach().item", "semisupervised_translation.SemisupervisedTranslationTask.train_step.forward_backward"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.train", "home.repos.pwc.inspect_result.reneeye_const.tasks.semisupervised_translation.SemisupervisedTranslationTask.update_step", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.criterion", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "def", "train_step", "(", "\n", "self", ",", "sample", ",", "model", ",", "criterion", ",", "optimizer", ",", "update_num", ",", "ignore_grad", "=", "False", "\n", ")", ":", "\n", "        ", "model", ".", "train", "(", ")", "\n", "\n", "if", "update_num", ">", "0", ":", "\n", "            ", "self", ".", "update_step", "(", "update_num", ")", "\n", "\n", "", "agg_loss", ",", "agg_sample_size", ",", "agg_logging_output", "=", "0.0", ",", "0.0", ",", "{", "}", "\n", "\n", "def", "forward_backward", "(", "model", ",", "samples", ",", "logging_output_key", ",", "weight", ")", ":", "\n", "            ", "nonlocal", "agg_loss", ",", "agg_sample_size", ",", "agg_logging_output", "\n", "if", "samples", "is", "None", "or", "len", "(", "samples", ")", "==", "0", ":", "\n", "                ", "return", "\n", "", "loss", ",", "sample_size", ",", "logging_output", "=", "criterion", "(", "model", ",", "samples", ")", "\n", "if", "ignore_grad", ":", "\n", "                ", "loss", "*=", "0", "\n", "", "else", ":", "\n", "                ", "loss", "*=", "weight", "\n", "", "optimizer", ".", "backward", "(", "loss", ")", "\n", "agg_loss", "+=", "loss", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "# TODO make summing of the sample sizes configurable", "\n", "agg_sample_size", "+=", "sample_size", "\n", "for", "k", "in", "logging_output", ":", "\n", "                ", "agg_logging_output", "[", "k", "]", "+=", "logging_output", "[", "k", "]", "\n", "agg_logging_output", "[", "logging_output_key", "]", "+=", "logging_output", "[", "k", "]", "\n", "\n", "", "", "if", "self", ".", "lambda_parallel", ">", "0.0", ":", "\n", "            ", "for", "lang_pair", "in", "self", ".", "lang_pairs", ":", "\n", "                ", "forward_backward", "(", "\n", "model", ".", "models", "[", "lang_pair", "]", ",", "\n", "sample", "[", "lang_pair", "]", ",", "\n", "lang_pair", ",", "\n", "self", ".", "lambda_parallel", ",", "\n", ")", "\n", "\n", "", "", "if", "self", ".", "lambda_otf_bt", ">", "0.0", ":", "\n", "            ", "for", "lang_pair", "in", "self", ".", "lang_pairs", ":", "\n", "                ", "sample_key", "=", "_get_bt_dataset_key", "(", "lang_pair", ")", "\n", "forward_backward", "(", "\n", "model", ".", "models", "[", "lang_pair", "]", ",", "\n", "sample", "[", "sample_key", "]", ",", "\n", "sample_key", ",", "\n", "self", ".", "lambda_otf_bt", ",", "\n", ")", "\n", "\n", "", "", "if", "self", ".", "lambda_denoising", ">", "0.0", ":", "\n", "            ", "for", "lang_pair", "in", "self", ".", "lang_pairs", ":", "\n", "                ", "_", ",", "tgt", "=", "lang_pair", ".", "split", "(", "\"-\"", ")", "\n", "sample_key", "=", "_get_denoising_dataset_key", "(", "lang_pair", ")", "\n", "forward_backward", "(", "\n", "model", ".", "models", "[", "\"{0}-{0}\"", ".", "format", "(", "tgt", ")", "]", ",", "\n", "sample", "[", "sample_key", "]", ",", "\n", "sample_key", ",", "\n", "self", ".", "lambda_denoising", ",", "\n", ")", "\n", "\n", "", "", "return", "agg_loss", ",", "agg_sample_size", ",", "agg_logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.semisupervised_translation.SemisupervisedTranslationTask.update_step": [[457, 486], ["semisupervised_translation.SemisupervisedTranslationTask.update_step.lambda_step_func"], "methods", ["None"], ["", "def", "update_step", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "def", "lambda_step_func", "(", "config", ",", "n_iter", ")", ":", "\n", "            ", "\"\"\"\n            Update a lambda value according to its schedule configuration.\n            \"\"\"", "\n", "ranges", "=", "[", "\n", "i", "\n", "for", "i", "in", "range", "(", "len", "(", "config", ")", "-", "1", ")", "\n", "if", "config", "[", "i", "]", "[", "0", "]", "<=", "n_iter", "<", "config", "[", "i", "+", "1", "]", "[", "0", "]", "\n", "]", "\n", "if", "len", "(", "ranges", ")", "==", "0", ":", "\n", "                ", "assert", "n_iter", ">=", "config", "[", "-", "1", "]", "[", "0", "]", "\n", "return", "config", "[", "-", "1", "]", "[", "1", "]", "\n", "", "assert", "len", "(", "ranges", ")", "==", "1", "\n", "i", "=", "ranges", "[", "0", "]", "\n", "x_a", ",", "y_a", "=", "config", "[", "i", "]", "\n", "x_b", ",", "y_b", "=", "config", "[", "i", "+", "1", "]", "\n", "return", "y_a", "+", "(", "n_iter", "-", "x_a", ")", "*", "float", "(", "y_b", "-", "y_a", ")", "/", "float", "(", "x_b", "-", "x_a", ")", "\n", "\n", "", "if", "self", ".", "lambda_parallel_steps", "is", "not", "None", ":", "\n", "            ", "self", ".", "lambda_parallel", "=", "lambda_step_func", "(", "\n", "self", ".", "lambda_parallel_steps", ",", "num_updates", "\n", ")", "\n", "", "if", "self", ".", "lambda_denoising_steps", "is", "not", "None", ":", "\n", "            ", "self", ".", "lambda_denoising", "=", "lambda_step_func", "(", "\n", "self", ".", "lambda_denoising_steps", ",", "num_updates", "\n", ")", "\n", "", "if", "self", ".", "lambda_otf_bt_steps", "is", "not", "None", ":", "\n", "            ", "self", ".", "lambda_otf_bt", "=", "lambda_step_func", "(", "self", ".", "lambda_otf_bt_steps", ",", "num_updates", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.tasks.semisupervised_translation._get_bt_dataset_key": [[32, 34], ["None"], "function", ["None"], ["def", "_get_bt_dataset_key", "(", "lang_pair", ")", ":", "\n", "    ", "return", "\"bt:\"", "+", "lang_pair", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.semisupervised_translation._get_denoising_dataset_key": [[36, 38], ["None"], "function", ["None"], ["", "def", "_get_denoising_dataset_key", "(", "lang_pair", ")", ":", "\n", "    ", "return", "\"denoising:\"", "+", "lang_pair", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.semisupervised_translation.parse_lambda_config": [[41, 61], ["x.split", "len", "all", "all", "all", "float", "s.split", "float", "k.isdigit", "len", "int", "int", "range", "int", "float", "len"], "function", ["None"], ["", "def", "parse_lambda_config", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    Parse the configuration of lambda coefficient (for scheduling).\n    x = \"3\"                  # lambda will be a constant equal to x\n    x = \"0:1,1000:0\"         # lambda will start from 1 and linearly decrease\n                             # to 0 during the first 1000 iterations\n    x = \"0:0,1000:0,2000:1\"  # lambda will be equal to 0 for the first 1000\n                             # iterations, then will linearly increase to 1 until iteration 2000\n    \"\"\"", "\n", "split", "=", "x", ".", "split", "(", "\",\"", ")", "\n", "if", "len", "(", "split", ")", "==", "1", ":", "\n", "        ", "return", "float", "(", "x", ")", ",", "None", "\n", "", "else", ":", "\n", "        ", "split", "=", "[", "s", ".", "split", "(", "os", ".", "pathsep", ")", "for", "s", "in", "split", "]", "\n", "assert", "all", "(", "len", "(", "s", ")", "==", "2", "for", "s", "in", "split", ")", "\n", "assert", "all", "(", "k", ".", "isdigit", "(", ")", "for", "k", ",", "_", "in", "split", ")", "\n", "assert", "all", "(", "\n", "int", "(", "split", "[", "i", "]", "[", "0", "]", ")", "<", "int", "(", "split", "[", "i", "+", "1", "]", "[", "0", "]", ")", "for", "i", "in", "range", "(", "len", "(", "split", ")", "-", "1", ")", "\n", ")", "\n", "return", "float", "(", "split", "[", "0", "]", "[", "1", "]", ")", ",", "[", "(", "int", "(", "k", ")", ",", "float", "(", "v", ")", ")", "for", "k", ",", "v", "in", "split", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask.add_args": [[65, 92], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'data'", ",", "metavar", "=", "'DIR'", ",", "help", "=", "'path to data directory'", ")", "\n", "parser", ".", "add_argument", "(", "'--lang-pairs'", ",", "default", "=", "None", ",", "metavar", "=", "'PAIRS'", ",", "\n", "help", "=", "'comma-separated list of language pairs (in training order): en-de,en-fr,de-fr'", ")", "\n", "parser", ".", "add_argument", "(", "'-s'", ",", "'--source-lang'", ",", "default", "=", "None", ",", "metavar", "=", "'SRC'", ",", "\n", "help", "=", "'source language (only needed for inference)'", ")", "\n", "parser", ".", "add_argument", "(", "'-t'", ",", "'--target-lang'", ",", "default", "=", "None", ",", "metavar", "=", "'TARGET'", ",", "\n", "help", "=", "'target language (only needed for inference)'", ")", "\n", "parser", ".", "add_argument", "(", "'--left-pad-source'", ",", "default", "=", "'True'", ",", "type", "=", "str", ",", "metavar", "=", "'BOOL'", ",", "\n", "help", "=", "'pad the source on the left (default: True)'", ")", "\n", "parser", ".", "add_argument", "(", "'--left-pad-target'", ",", "default", "=", "'False'", ",", "type", "=", "str", ",", "metavar", "=", "'BOOL'", ",", "\n", "help", "=", "'pad the target on the left (default: False)'", ")", "\n", "parser", ".", "add_argument", "(", "'--max-source-positions'", ",", "default", "=", "1024", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'max number of tokens in the source sequence'", ")", "\n", "parser", ".", "add_argument", "(", "'--max-target-positions'", ",", "default", "=", "1024", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'max number of tokens in the target sequence'", ")", "\n", "parser", ".", "add_argument", "(", "'--upsample-primary'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'amount to upsample primary dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-langtok'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "choices", "=", "[", "'src'", ",", "'tgt'", "]", ",", "\n", "metavar", "=", "'SRCTGT'", ",", "\n", "help", "=", "'replace beginning-of-sentence in source sentence with source or target '", "\n", "'language token. (src/tgt)'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-langtok'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'replace beginning-of-sentence in target sentence with target language token'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask.__init__": [[94, 113], ["LegacyFairseqTask.__init__", "list", "dicts.keys"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["", "def", "__init__", "(", "self", ",", "args", ",", "dicts", ",", "training", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "dicts", "=", "dicts", "\n", "self", ".", "training", "=", "training", "\n", "if", "training", ":", "\n", "            ", "self", ".", "lang_pairs", "=", "args", ".", "lang_pairs", "\n", "", "else", ":", "\n", "            ", "self", ".", "lang_pairs", "=", "[", "\"{}-{}\"", ".", "format", "(", "args", ".", "source_lang", ",", "args", ".", "target_lang", ")", "]", "\n", "# eval_lang_pairs for multilingual translation is usually all of the", "\n", "# lang_pairs. However for other multitask settings or when we want to", "\n", "# optimize for certain languages we want to use a different subset. Thus", "\n", "# the eval_lang_pairs class variable is provided for classes that extend", "\n", "# this class.", "\n", "", "self", ".", "eval_lang_pairs", "=", "self", ".", "lang_pairs", "\n", "# model_lang_pairs will be used to build encoder-decoder model pairs in", "\n", "# models.build_model(). This allows multitask type of sub-class can", "\n", "# build models other than the input lang_pairs", "\n", "self", ".", "model_lang_pairs", "=", "self", ".", "lang_pairs", "\n", "self", ".", "langs", "=", "list", "(", "dicts", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask.setup_task": [[114, 118], ["cls.prepare", "cls"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.prepare", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "dicts", ",", "training", "=", "cls", ".", "prepare", "(", "args", ",", "**", "kwargs", ")", "\n", "return", "cls", "(", "args", ",", "dicts", ",", "training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask.update_args": [[119, 130], ["fairseq.utils.eval_bool", "fairseq.utils.eval_bool", "isinstance", "ValueError", "args.lang_pairs.split"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.eval_bool", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.eval_bool"], ["", "@", "classmethod", "\n", "def", "update_args", "(", "cls", ",", "args", ")", ":", "\n", "        ", "args", ".", "left_pad_source", "=", "utils", ".", "eval_bool", "(", "args", ".", "left_pad_source", ")", "\n", "args", ".", "left_pad_target", "=", "utils", ".", "eval_bool", "(", "args", ".", "left_pad_target", ")", "\n", "\n", "if", "args", ".", "lang_pairs", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"--lang-pairs is required. List all the language pairs in the training objective.\"", "\n", ")", "\n", "", "if", "isinstance", "(", "args", ".", "lang_pairs", ",", "str", ")", ":", "\n", "            ", "args", ".", "lang_pairs", "=", "args", ".", "lang_pairs", ".", "split", "(", "\",\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask.prepare": [[131, 159], ["cls.update_args", "sorted", "collections.OrderedDict", "list", "fairseq.utils.split_paths", "cls.load_dictionary", "logger.info", "len", "os.path.join", "len", "dicts[].pad", "dicts[].pad", "dicts[].eos", "dicts[].eos", "dicts[].unk", "dicts[].unk", "dicts[].add_symbol", "len", "lang_pair.split", "multilingual_translation._lang_token"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask.update_args", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_prediction.SentencePredictionTask.load_dictionary", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol", "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation._lang_token"], ["", "", "@", "classmethod", "\n", "def", "prepare", "(", "cls", ",", "args", ",", "**", "kargs", ")", ":", "\n", "        ", "cls", ".", "update_args", "(", "args", ")", "\n", "sorted_langs", "=", "sorted", "(", "\n", "list", "(", "{", "x", "for", "lang_pair", "in", "args", ".", "lang_pairs", "for", "x", "in", "lang_pair", ".", "split", "(", "\"-\"", ")", "}", ")", "\n", ")", "\n", "if", "args", ".", "source_lang", "is", "not", "None", "or", "args", ".", "target_lang", "is", "not", "None", ":", "\n", "            ", "training", "=", "False", "\n", "", "else", ":", "\n", "            ", "training", "=", "True", "\n", "\n", "# load dictionaries", "\n", "", "dicts", "=", "OrderedDict", "(", ")", "\n", "for", "lang", "in", "sorted_langs", ":", "\n", "            ", "paths", "=", "utils", ".", "split_paths", "(", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "dicts", "[", "lang", "]", "=", "cls", ".", "load_dictionary", "(", "\n", "os", ".", "path", ".", "join", "(", "paths", "[", "0", "]", ",", "\"dict.{}.txt\"", ".", "format", "(", "lang", ")", ")", "\n", ")", "\n", "if", "len", "(", "dicts", ")", ">", "0", ":", "\n", "                ", "assert", "dicts", "[", "lang", "]", ".", "pad", "(", ")", "==", "dicts", "[", "sorted_langs", "[", "0", "]", "]", ".", "pad", "(", ")", "\n", "assert", "dicts", "[", "lang", "]", ".", "eos", "(", ")", "==", "dicts", "[", "sorted_langs", "[", "0", "]", "]", ".", "eos", "(", ")", "\n", "assert", "dicts", "[", "lang", "]", ".", "unk", "(", ")", "==", "dicts", "[", "sorted_langs", "[", "0", "]", "]", ".", "unk", "(", ")", "\n", "", "if", "args", ".", "encoder_langtok", "is", "not", "None", "or", "args", ".", "decoder_langtok", ":", "\n", "                ", "for", "lang_to_add", "in", "sorted_langs", ":", "\n", "                    ", "dicts", "[", "lang", "]", ".", "add_symbol", "(", "_lang_token", "(", "lang_to_add", ")", ")", "\n", "", "", "logger", ".", "info", "(", "\"[{}] dictionary: {} types\"", ".", "format", "(", "lang", ",", "len", "(", "dicts", "[", "lang", "]", ")", ")", ")", "\n", "", "return", "dicts", ",", "training", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask.get_encoder_langtok": [[160, 167], ["multilingual_translation.MultilingualTranslationTask.dicts[].eos", "multilingual_translation._lang_token_index", "multilingual_translation._lang_token_index"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation._lang_token_index", "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation._lang_token_index"], ["", "def", "get_encoder_langtok", "(", "self", ",", "src_lang", ",", "tgt_lang", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "encoder_langtok", "is", "None", ":", "\n", "            ", "return", "self", ".", "dicts", "[", "src_lang", "]", ".", "eos", "(", ")", "\n", "", "if", "self", ".", "args", ".", "encoder_langtok", "==", "\"src\"", ":", "\n", "            ", "return", "_lang_token_index", "(", "self", ".", "dicts", "[", "src_lang", "]", ",", "src_lang", ")", "\n", "", "else", ":", "\n", "            ", "return", "_lang_token_index", "(", "self", ".", "dicts", "[", "src_lang", "]", ",", "tgt_lang", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask.get_decoder_langtok": [[168, 172], ["multilingual_translation._lang_token_index", "multilingual_translation.MultilingualTranslationTask.dicts[].eos"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation._lang_token_index", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "", "def", "get_decoder_langtok", "(", "self", ",", "tgt_lang", ")", ":", "\n", "        ", "if", "not", "self", ".", "args", ".", "decoder_langtok", ":", "\n", "            ", "return", "self", ".", "dicts", "[", "tgt_lang", "]", ".", "eos", "(", ")", "\n", "", "return", "_lang_token_index", "(", "self", ".", "dicts", "[", "tgt_lang", "]", ",", "tgt_lang", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask.alter_dataset_langtok": [[173, 207], ["fairseq.data.TransformEosLangPairDataset", "multilingual_translation.MultilingualTranslationTask.get_encoder_langtok", "multilingual_translation.MultilingualTranslationTask.get_decoder_langtok"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_encoder_langtok", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_decoder_langtok"], ["", "def", "alter_dataset_langtok", "(", "\n", "self", ",", "\n", "lang_pair_dataset", ",", "\n", "src_eos", "=", "None", ",", "\n", "src_lang", "=", "None", ",", "\n", "tgt_eos", "=", "None", ",", "\n", "tgt_lang", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "encoder_langtok", "is", "None", "and", "not", "self", ".", "args", ".", "decoder_langtok", ":", "\n", "            ", "return", "lang_pair_dataset", "\n", "\n", "", "new_src_eos", "=", "None", "\n", "if", "(", "\n", "self", ".", "args", ".", "encoder_langtok", "is", "not", "None", "\n", "and", "src_eos", "is", "not", "None", "\n", "and", "src_lang", "is", "not", "None", "\n", "and", "tgt_lang", "is", "not", "None", "\n", ")", ":", "\n", "            ", "new_src_eos", "=", "self", ".", "get_encoder_langtok", "(", "src_lang", ",", "tgt_lang", ")", "\n", "", "else", ":", "\n", "            ", "src_eos", "=", "None", "\n", "\n", "", "new_tgt_bos", "=", "None", "\n", "if", "self", ".", "args", ".", "decoder_langtok", "and", "tgt_eos", "is", "not", "None", "and", "tgt_lang", "is", "not", "None", ":", "\n", "            ", "new_tgt_bos", "=", "self", ".", "get_decoder_langtok", "(", "tgt_lang", ")", "\n", "", "else", ":", "\n", "            ", "tgt_eos", "=", "None", "\n", "\n", "", "return", "TransformEosLangPairDataset", "(", "\n", "lang_pair_dataset", ",", "\n", "src_eos", "=", "src_eos", ",", "\n", "new_src_eos", "=", "new_src_eos", ",", "\n", "tgt_bos", "=", "tgt_eos", ",", "\n", "new_tgt_bos", "=", "new_tgt_bos", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask.load_dataset": [[209, 250], ["fairseq.utils.split_paths", "fairseq.data.RoundRobinZipDatasets", "len", "lang_pair.split", "fairseq.tasks.translation.load_langpair_dataset", "multilingual_translation.MultilingualTranslationTask.alter_dataset_langtok", "collections.OrderedDict", "len", "multilingual_translation.MultilingualTranslationTask.dicts[].eos", "multilingual_translation.MultilingualTranslationTask.dicts[].eos", "multilingual_translation.MultilingualTranslationTask.load_dataset.language_pair_dataset"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_langpair_dataset", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.alter_dataset_langtok", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a dataset split.\"\"\"", "\n", "paths", "=", "utils", ".", "split_paths", "(", "self", ".", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "data_path", "=", "paths", "[", "(", "epoch", "-", "1", ")", "%", "len", "(", "paths", ")", "]", "\n", "\n", "def", "language_pair_dataset", "(", "lang_pair", ")", ":", "\n", "            ", "src", ",", "tgt", "=", "lang_pair", ".", "split", "(", "\"-\"", ")", "\n", "langpair_dataset", "=", "load_langpair_dataset", "(", "\n", "data_path", ",", "\n", "split", ",", "\n", "src", ",", "\n", "self", ".", "dicts", "[", "src", "]", ",", "\n", "tgt", ",", "\n", "self", ".", "dicts", "[", "tgt", "]", ",", "\n", "combine", "=", "True", ",", "\n", "dataset_impl", "=", "self", ".", "args", ".", "dataset_impl", ",", "\n", "upsample_primary", "=", "self", ".", "args", ".", "upsample_primary", ",", "\n", "left_pad_source", "=", "self", ".", "args", ".", "left_pad_source", ",", "\n", "left_pad_target", "=", "self", ".", "args", ".", "left_pad_target", ",", "\n", "max_source_positions", "=", "self", ".", "args", ".", "max_source_positions", ",", "\n", "max_target_positions", "=", "self", ".", "args", ".", "max_target_positions", ",", "\n", ")", "\n", "return", "self", ".", "alter_dataset_langtok", "(", "\n", "langpair_dataset", ",", "\n", "src_eos", "=", "self", ".", "dicts", "[", "src", "]", ".", "eos", "(", ")", ",", "\n", "src_lang", "=", "src", ",", "\n", "tgt_eos", "=", "self", ".", "dicts", "[", "tgt", "]", ".", "eos", "(", ")", ",", "\n", "tgt_lang", "=", "tgt", ",", "\n", ")", "\n", "\n", "", "self", ".", "datasets", "[", "split", "]", "=", "RoundRobinZipDatasets", "(", "\n", "OrderedDict", "(", "\n", "[", "\n", "(", "lang_pair", ",", "language_pair_dataset", "(", "lang_pair", ")", ")", "\n", "for", "lang_pair", "in", "self", ".", "lang_pairs", "\n", "]", "\n", ")", ",", "\n", "eval_key", "=", "None", "\n", "if", "self", ".", "training", "\n", "else", "\"%s-%s\"", "%", "(", "self", ".", "args", ".", "source_lang", ",", "self", ".", "args", ".", "target_lang", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask.build_dataset_for_inference": [[252, 277], ["fairseq.data.RoundRobinZipDatasets", "NotImplementedError", "collections.OrderedDict", "multilingual_translation.MultilingualTranslationTask.alter_dataset_langtok", "fairseq.data.LanguagePairDataset", "multilingual_translation.MultilingualTranslationTask.source_dictionary.eos", "multilingual_translation.MultilingualTranslationTask.target_dictionary.eos"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.alter_dataset_langtok", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "def", "build_dataset_for_inference", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "constraints", "=", "None", ")", ":", "\n", "        ", "if", "constraints", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Constrained decoding with the multilingual_translation task is not supported\"", "\n", ")", "\n", "\n", "", "lang_pair", "=", "\"%s-%s\"", "%", "(", "self", ".", "args", ".", "source_lang", ",", "self", ".", "args", ".", "target_lang", ")", "\n", "return", "RoundRobinZipDatasets", "(", "\n", "OrderedDict", "(", "\n", "[", "\n", "(", "\n", "lang_pair", ",", "\n", "self", ".", "alter_dataset_langtok", "(", "\n", "LanguagePairDataset", "(", "\n", "src_tokens", ",", "src_lengths", ",", "self", ".", "source_dictionary", "\n", ")", ",", "\n", "src_eos", "=", "self", ".", "source_dictionary", ".", "eos", "(", ")", ",", "\n", "src_lang", "=", "self", ".", "args", ".", "source_lang", ",", "\n", "tgt_eos", "=", "self", ".", "target_dictionary", ".", "eos", "(", ")", ",", "\n", "tgt_lang", "=", "self", ".", "args", ".", "target_lang", ",", "\n", ")", ",", "\n", ")", "\n", "]", "\n", ")", ",", "\n", "eval_key", "=", "lang_pair", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask.build_model": [[279, 320], ["multilingual_translation.MultilingualTranslationTask.update_args", "multilingual_translation.MultilingualTranslationTask.build_model.check_args"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask.update_args"], ["", "def", "build_model", "(", "self", ",", "args", ")", ":", "\n", "        ", "def", "check_args", "(", ")", ":", "\n", "            ", "messages", "=", "[", "]", "\n", "if", "(", "\n", "len", "(", "set", "(", "self", ".", "args", ".", "lang_pairs", ")", ".", "symmetric_difference", "(", "args", ".", "lang_pairs", ")", ")", "\n", "!=", "0", "\n", ")", ":", "\n", "                ", "messages", ".", "append", "(", "\n", "\"--lang-pairs should include all the language pairs {}.\"", ".", "format", "(", "\n", "args", ".", "lang_pairs", "\n", ")", "\n", ")", "\n", "", "if", "self", ".", "args", ".", "encoder_langtok", "!=", "args", ".", "encoder_langtok", ":", "\n", "                ", "messages", ".", "append", "(", "\n", "\"--encoder-langtok should be {}.\"", ".", "format", "(", "args", ".", "encoder_langtok", ")", "\n", ")", "\n", "", "if", "self", ".", "args", ".", "decoder_langtok", "!=", "args", ".", "decoder_langtok", ":", "\n", "                ", "messages", ".", "append", "(", "\n", "\"--decoder-langtok should {} be set.\"", ".", "format", "(", "\n", "\"\"", "if", "args", ".", "decoder_langtok", "else", "\"not\"", "\n", ")", "\n", ")", "\n", "\n", "", "if", "len", "(", "messages", ")", ">", "0", ":", "\n", "                ", "raise", "ValueError", "(", "\" \"", ".", "join", "(", "messages", ")", ")", "\n", "\n", "# Update args -> the fact that the constructor here", "\n", "# changes the args object doesn't mean you get the same one here", "\n", "", "", "self", ".", "update_args", "(", "args", ")", "\n", "\n", "# Check if task args are consistant with model args", "\n", "check_args", "(", ")", "\n", "\n", "from", "fairseq", "import", "models", "\n", "\n", "model", "=", "models", ".", "build_model", "(", "args", ",", "self", ")", "\n", "if", "not", "isinstance", "(", "model", ",", "FairseqMultiModel", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"MultilingualTranslationTask requires a FairseqMultiModel architecture\"", "\n", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask._per_lang_pair_train_loss": [[321, 331], ["criterion", "optimizer.backward"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.criterion", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward"], ["", "def", "_per_lang_pair_train_loss", "(", "\n", "self", ",", "lang_pair", ",", "model", ",", "update_num", ",", "criterion", ",", "sample", ",", "optimizer", ",", "ignore_grad", "\n", ")", ":", "\n", "        ", "loss", ",", "sample_size", ",", "logging_output", "=", "criterion", "(", "\n", "model", ".", "models", "[", "lang_pair", "]", ",", "sample", "[", "lang_pair", "]", "\n", ")", "\n", "if", "ignore_grad", ":", "\n", "            ", "loss", "*=", "0", "\n", "", "optimizer", ".", "backward", "(", "loss", ")", "\n", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask.train_step": [[332, 374], ["model.train", "enumerate", "defaultdict", "loss.detach().item", "multilingual_translation.MultilingualTranslationTask.train_step.maybe_no_sync"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.train", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "def", "train_step", "(", "\n", "self", ",", "sample", ",", "model", ",", "criterion", ",", "optimizer", ",", "update_num", ",", "ignore_grad", "=", "False", "\n", ")", ":", "\n", "        ", "model", ".", "train", "(", ")", "\n", "from", "collections", "import", "defaultdict", "\n", "\n", "agg_loss", ",", "agg_sample_size", ",", "agg_logging_output", "=", "0.0", ",", "0.0", ",", "defaultdict", "(", "float", ")", "\n", "curr_lang_pairs", "=", "[", "\n", "lang_pair", "\n", "for", "lang_pair", "in", "self", ".", "model_lang_pairs", "\n", "if", "sample", "[", "lang_pair", "]", "is", "not", "None", "and", "len", "(", "sample", "[", "lang_pair", "]", ")", "!=", "0", "\n", "]", "\n", "\n", "for", "idx", ",", "lang_pair", "in", "enumerate", "(", "curr_lang_pairs", ")", ":", "\n", "\n", "            ", "def", "maybe_no_sync", "(", ")", ":", "\n", "                ", "if", "(", "\n", "self", ".", "args", ".", "distributed_world_size", ">", "1", "\n", "and", "hasattr", "(", "model", ",", "\"no_sync\"", ")", "\n", "and", "idx", "<", "len", "(", "curr_lang_pairs", ")", "-", "1", "\n", ")", ":", "\n", "                    ", "return", "model", ".", "no_sync", "(", ")", "\n", "", "else", ":", "\n", "                    ", "return", "contextlib", ".", "ExitStack", "(", ")", "# dummy contextmanager", "\n", "\n", "", "", "with", "maybe_no_sync", "(", ")", ":", "\n", "                ", "loss", ",", "sample_size", ",", "logging_output", "=", "self", ".", "_per_lang_pair_train_loss", "(", "\n", "lang_pair", ",", "\n", "model", ",", "\n", "update_num", ",", "\n", "criterion", ",", "\n", "sample", ",", "\n", "optimizer", ",", "\n", "ignore_grad", ",", "\n", ")", "\n", "", "agg_loss", "+=", "loss", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "# TODO make summing of the sample sizes configurable", "\n", "agg_sample_size", "+=", "sample_size", "\n", "for", "k", "in", "logging_output", ":", "\n", "                ", "agg_logging_output", "[", "k", "]", "+=", "logging_output", "[", "k", "]", "\n", "agg_logging_output", "[", "f\"{lang_pair}:{k}\"", "]", "+=", "logging_output", "[", "k", "]", "\n", "", "", "return", "agg_loss", ",", "agg_sample_size", ",", "agg_logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask._per_lang_pair_valid_loss": [[375, 377], ["criterion"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.criterion"], ["", "def", "_per_lang_pair_valid_loss", "(", "self", ",", "lang_pair", ",", "model", ",", "criterion", ",", "sample", ")", ":", "\n", "        ", "return", "criterion", "(", "model", ".", "models", "[", "lang_pair", "]", ",", "sample", "[", "lang_pair", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask.valid_step": [[378, 401], ["model.eval", "torch.no_grad", "defaultdict", "multilingual_translation.MultilingualTranslationTask._per_lang_pair_valid_loss", "loss.data.item", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask._per_lang_pair_valid_loss", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "def", "valid_step", "(", "self", ",", "sample", ",", "model", ",", "criterion", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "from", "collections", "import", "defaultdict", "\n", "\n", "agg_loss", ",", "agg_sample_size", ",", "agg_logging_output", "=", "0.0", ",", "0.0", ",", "defaultdict", "(", "float", ")", "\n", "for", "lang_pair", "in", "self", ".", "eval_lang_pairs", ":", "\n", "                ", "if", "(", "\n", "lang_pair", "not", "in", "sample", "\n", "or", "sample", "[", "lang_pair", "]", "is", "None", "\n", "or", "len", "(", "sample", "[", "lang_pair", "]", ")", "==", "0", "\n", ")", ":", "\n", "                    ", "continue", "\n", "", "loss", ",", "sample_size", ",", "logging_output", "=", "self", ".", "_per_lang_pair_valid_loss", "(", "\n", "lang_pair", ",", "model", ",", "criterion", ",", "sample", "\n", ")", "\n", "agg_loss", "+=", "loss", ".", "data", ".", "item", "(", ")", "\n", "# TODO make summing of the sample sizes configurable", "\n", "agg_sample_size", "+=", "sample_size", "\n", "for", "k", "in", "logging_output", ":", "\n", "                    ", "agg_logging_output", "[", "k", "]", "+=", "logging_output", "[", "k", "]", "\n", "agg_logging_output", "[", "f\"{lang_pair}:{k}\"", "]", "+=", "logging_output", "[", "k", "]", "\n", "", "", "", "return", "agg_loss", ",", "agg_sample_size", ",", "agg_logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask.inference_step": [[402, 418], ["torch.no_grad", "generator.generate", "multilingual_translation._lang_token_index", "multilingual_translation.MultilingualTranslationTask.target_dictionary.eos"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.generate", "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation._lang_token_index", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "def", "inference_step", "(", "\n", "self", ",", "generator", ",", "models", ",", "sample", ",", "prefix_tokens", "=", "None", ",", "constraints", "=", "None", "\n", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "self", ".", "args", ".", "decoder_langtok", ":", "\n", "                ", "bos_token", "=", "_lang_token_index", "(", "\n", "self", ".", "target_dictionary", ",", "self", ".", "args", ".", "target_lang", "\n", ")", "\n", "", "else", ":", "\n", "                ", "bos_token", "=", "self", ".", "target_dictionary", ".", "eos", "(", ")", "\n", "", "return", "generator", ".", "generate", "(", "\n", "models", ",", "\n", "sample", ",", "\n", "prefix_tokens", "=", "prefix_tokens", ",", "\n", "constraints", "=", "constraints", ",", "\n", "bos_token", "=", "bos_token", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask.reduce_metrics": [[420, 426], ["fairseq.metrics.aggregate", "super().reduce_metrics", "fairseq.metrics.log_scalar", "sum"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.aggregate", "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.reduce_metrics", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar"], ["", "", "def", "reduce_metrics", "(", "self", ",", "logging_outputs", ",", "criterion", ")", ":", "\n", "        ", "with", "metrics", ".", "aggregate", "(", ")", ":", "\n", "# pass 'sample_size', 'nsentences', 'ntokens' stats to fairseq_task", "\n", "            ", "super", "(", ")", ".", "reduce_metrics", "(", "logging_outputs", ",", "criterion", ")", "\n", "for", "k", "in", "[", "\"sample_size\"", ",", "\"nsentences\"", ",", "\"ntokens\"", "]", ":", "\n", "                ", "metrics", ".", "log_scalar", "(", "k", ",", "sum", "(", "l", "[", "k", "]", "for", "l", "in", "logging_outputs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask.source_dictionary": [[427, 433], ["next", "iter", "multilingual_translation.MultilingualTranslationTask.dicts.values"], "methods", ["None"], ["", "", "", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "return", "next", "(", "iter", "(", "self", ".", "dicts", ".", "values", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "dicts", "[", "self", ".", "args", ".", "source_lang", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask.target_dictionary": [[434, 440], ["next", "iter", "multilingual_translation.MultilingualTranslationTask.dicts.values"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "return", "next", "(", "iter", "(", "self", ".", "dicts", ".", "values", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "dicts", "[", "self", ".", "args", ".", "target_lang", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation.MultilingualTranslationTask.max_positions": [[441, 456], ["collections.OrderedDict", "len", "multilingual_translation.MultilingualTranslationTask.datasets.values", "multilingual_translation.MultilingualTranslationTask.datasets.keys", "multilingual_translation.MultilingualTranslationTask.datasets[].datasets.keys"], "methods", ["None"], ["", "", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the max sentence length allowed by the task.\"\"\"", "\n", "if", "len", "(", "self", ".", "datasets", ".", "values", "(", ")", ")", "==", "0", ":", "\n", "            ", "return", "{", "\n", "\"%s-%s\"", "\n", "%", "(", "self", ".", "args", ".", "source_lang", ",", "self", ".", "args", ".", "target_lang", ")", ":", "(", "\n", "self", ".", "args", ".", "max_source_positions", ",", "\n", "self", ".", "args", ".", "max_target_positions", ",", "\n", ")", "\n", "}", "\n", "", "return", "OrderedDict", "(", "\n", "[", "\n", "(", "key", ",", "(", "self", ".", "args", ".", "max_source_positions", ",", "self", ".", "args", ".", "max_target_positions", ")", ")", "\n", "for", "split", "in", "self", ".", "datasets", ".", "keys", "(", ")", "\n", "for", "key", "in", "self", ".", "datasets", "[", "split", "]", ".", "datasets", ".", "keys", "(", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation._lang_token": [[28, 30], ["None"], "function", ["None"], ["def", "_lang_token", "(", "lang", ":", "str", ")", ":", "\n", "    ", "return", "\"__{}__\"", ".", "format", "(", "lang", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation._lang_token_index": [[32, 37], ["dic.index", "multilingual_translation._lang_token"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.index", "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_translation._lang_token"], ["", "def", "_lang_token_index", "(", "dic", ":", "Dictionary", ",", "lang", ":", "str", ")", ":", "\n", "    ", "\"\"\"Return language token index.\"\"\"", "\n", "idx", "=", "dic", ".", "index", "(", "_lang_token", "(", "lang", ")", ")", "\n", "assert", "idx", "!=", "dic", ".", "unk_index", ",", "\"cannot find language token for lang {}\"", ".", "format", "(", "lang", ")", "\n", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.legacy_masked_lm.LegacyMaskedLMTask.add_args": [[30, 49], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "parser", ".", "add_argument", "(", "\n", "\"data\"", ",", "\n", "help", "=", "\"colon separated path to data directories list, \\\n                            will be iterated upon during epochs in round-robin manner\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokens-per-sample\"", ",", "\n", "default", "=", "512", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"max number of total tokens over all segments\"", "\n", "\" per sample for BERT dataset\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--break-mode\"", ",", "default", "=", "\"doc\"", ",", "type", "=", "str", ",", "help", "=", "\"mode for breaking sentence\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--shuffle-dataset\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.legacy_masked_lm.LegacyMaskedLMTask.__init__": [[50, 54], ["fairseq.tasks.LegacyFairseqTask.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["", "def", "__init__", "(", "self", ",", "args", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "self", ".", "seed", "=", "args", ".", "seed", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.legacy_masked_lm.LegacyMaskedLMTask.load_dictionary": [[55, 58], ["fairseq.data.legacy.masked_lm_dictionary.BertDictionary.load"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load"], ["", "@", "classmethod", "\n", "def", "load_dictionary", "(", "cls", ",", "filename", ")", ":", "\n", "        ", "return", "BertDictionary", ".", "load", "(", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.legacy_masked_lm.LegacyMaskedLMTask.build_dictionary": [[59, 70], ["fairseq.data.legacy.masked_lm_dictionary.BertDictionary", "fairseq.data.legacy.masked_lm_dictionary.BertDictionary.finalize", "fairseq.data.Dictionary.add_file_to_dictionary"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDatasetBuilder.finalize", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_file_to_dictionary"], ["", "@", "classmethod", "\n", "def", "build_dictionary", "(", "\n", "cls", ",", "filenames", ",", "workers", "=", "1", ",", "threshold", "=", "-", "1", ",", "nwords", "=", "-", "1", ",", "padding_factor", "=", "8", "\n", ")", ":", "\n", "        ", "d", "=", "BertDictionary", "(", ")", "\n", "for", "filename", "in", "filenames", ":", "\n", "            ", "Dictionary", ".", "add_file_to_dictionary", "(", "\n", "filename", ",", "d", ",", "tokenizer", ".", "tokenize_line", ",", "workers", "\n", ")", "\n", "", "d", ".", "finalize", "(", "threshold", "=", "threshold", ",", "nwords", "=", "nwords", ",", "padding_factor", "=", "padding_factor", ")", "\n", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.legacy_masked_lm.LegacyMaskedLMTask.target_dictionary": [[71, 74], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.legacy_masked_lm.LegacyMaskedLMTask.setup_task": [[75, 84], ["fairseq.utils.split_paths", "fairseq.data.legacy.masked_lm_dictionary.BertDictionary.load", "logger.info", "cls", "len", "os.path.join", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Setup the task.\"\"\"", "\n", "paths", "=", "utils", ".", "split_paths", "(", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "dictionary", "=", "BertDictionary", ".", "load", "(", "os", ".", "path", ".", "join", "(", "paths", "[", "0", "]", ",", "\"dict.txt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"dictionary: {} types\"", ".", "format", "(", "len", "(", "dictionary", ")", ")", ")", "\n", "\n", "return", "cls", "(", "args", ",", "dictionary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.legacy_masked_lm.LegacyMaskedLMTask.load_dataset": [[85, 152], ["fairseq.utils.split_paths", "logger.info", "itertools.count", "fairseq.data.legacy.masked_lm_dataset.MaskedLMDataset", "len", "os.path.join", "fairseq.data.indexed_dataset.make_dataset", "logger.info", "len", "fairseq.data.ConcatDataset", "numpy.concatenate", "fairseq.data.data_utils.numpy_seed", "loaded_datasets.append", "legacy_masked_lm.LegacyMaskedLMTask.dictionary.pad", "legacy_masked_lm.LegacyMaskedLMTask.dictionary.mask", "legacy_masked_lm.LegacyMaskedLMTask.dictionary.cls", "legacy_masked_lm.LegacyMaskedLMTask.dictionary.sep", "len", "str", "FileNotFoundError", "fairseq.data.legacy.block_pair_dataset.BlockPairDataset", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.make_dataset", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.numpy_seed", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.MaskedLMDictionary.mask", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.sep"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "1", ",", "combine", "=", "False", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n        \"\"\"", "\n", "loaded_datasets", "=", "[", "]", "\n", "\n", "paths", "=", "utils", ".", "split_paths", "(", "self", ".", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "data_path", "=", "paths", "[", "(", "epoch", "-", "1", ")", "%", "len", "(", "paths", ")", "]", "\n", "logger", ".", "info", "(", "\"data_path\"", ",", "data_path", ")", "\n", "\n", "for", "k", "in", "itertools", ".", "count", "(", ")", ":", "\n", "            ", "split_k", "=", "split", "+", "(", "str", "(", "k", ")", "if", "k", ">", "0", "else", "\"\"", ")", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "split_k", ")", "\n", "ds", "=", "indexed_dataset", ".", "make_dataset", "(", "\n", "path", ",", "\n", "impl", "=", "self", ".", "args", ".", "dataset_impl", ",", "\n", "fix_lua_indexing", "=", "True", ",", "\n", "dictionary", "=", "self", ".", "dictionary", ",", "\n", ")", "\n", "\n", "if", "ds", "is", "None", ":", "\n", "                ", "if", "k", ">", "0", ":", "\n", "                    ", "break", "\n", "", "else", ":", "\n", "                    ", "raise", "FileNotFoundError", "(", "\n", "\"Dataset not found: {} ({})\"", ".", "format", "(", "split", ",", "data_path", ")", "\n", ")", "\n", "\n", "", "", "with", "data_utils", ".", "numpy_seed", "(", "self", ".", "seed", "+", "k", ")", ":", "\n", "                ", "loaded_datasets", ".", "append", "(", "\n", "BlockPairDataset", "(", "\n", "ds", ",", "\n", "self", ".", "dictionary", ",", "\n", "ds", ".", "sizes", ",", "\n", "self", ".", "args", ".", "tokens_per_sample", ",", "\n", "break_mode", "=", "self", ".", "args", ".", "break_mode", ",", "\n", "doc_break_size", "=", "1", ",", "\n", ")", "\n", ")", "\n", "\n", "", "logger", ".", "info", "(", "\n", "\"{} {} {} examples\"", ".", "format", "(", "data_path", ",", "split_k", ",", "len", "(", "loaded_datasets", "[", "-", "1", "]", ")", ")", "\n", ")", "\n", "\n", "if", "not", "combine", ":", "\n", "                ", "break", "\n", "\n", "", "", "if", "len", "(", "loaded_datasets", ")", "==", "1", ":", "\n", "            ", "dataset", "=", "loaded_datasets", "[", "0", "]", "\n", "sizes", "=", "dataset", ".", "sizes", "\n", "", "else", ":", "\n", "            ", "dataset", "=", "ConcatDataset", "(", "loaded_datasets", ")", "\n", "sizes", "=", "np", ".", "concatenate", "(", "[", "ds", ".", "sizes", "for", "ds", "in", "loaded_datasets", "]", ")", "\n", "\n", "", "self", ".", "datasets", "[", "split", "]", "=", "MaskedLMDataset", "(", "\n", "dataset", "=", "dataset", ",", "\n", "sizes", "=", "sizes", ",", "\n", "vocab", "=", "self", ".", "dictionary", ",", "\n", "pad_idx", "=", "self", ".", "dictionary", ".", "pad", "(", ")", ",", "\n", "mask_idx", "=", "self", ".", "dictionary", ".", "mask", "(", ")", ",", "\n", "classif_token_idx", "=", "self", ".", "dictionary", ".", "cls", "(", ")", ",", "\n", "sep_token_idx", "=", "self", ".", "dictionary", ".", "sep", "(", ")", ",", "\n", "shuffle", "=", "self", ".", "args", ".", "shuffle_dataset", ",", "\n", "seed", "=", "self", ".", "seed", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_lev.TranslationLevenshteinTask.add_args": [[23, 32], ["fairseq.tasks.translation.TranslationTask.add_args", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args"], ["@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "TranslationTask", ".", "add_args", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--noise'", ",", "\n", "default", "=", "'random_delete'", ",", "\n", "choices", "=", "[", "'random_delete'", ",", "'random_mask'", ",", "'no_noise'", ",", "'full_mask'", "]", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_lev.TranslationLevenshteinTask.load_dataset": [[34, 62], ["fairseq.utils.split_paths", "fairseq.tasks.translation.load_langpair_dataset", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_langpair_dataset"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "1", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n        \"\"\"", "\n", "paths", "=", "utils", ".", "split_paths", "(", "self", ".", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "data_path", "=", "paths", "[", "(", "epoch", "-", "1", ")", "%", "len", "(", "paths", ")", "]", "\n", "\n", "# infer langcode", "\n", "src", ",", "tgt", "=", "self", ".", "args", ".", "source_lang", ",", "self", ".", "args", ".", "target_lang", "\n", "\n", "self", ".", "datasets", "[", "split", "]", "=", "load_langpair_dataset", "(", "\n", "data_path", ",", "\n", "split", ",", "\n", "src", ",", "\n", "self", ".", "src_dict", ",", "\n", "tgt", ",", "\n", "self", ".", "tgt_dict", ",", "\n", "combine", "=", "combine", ",", "\n", "dataset_impl", "=", "self", ".", "args", ".", "dataset_impl", ",", "\n", "upsample_primary", "=", "self", ".", "args", ".", "upsample_primary", ",", "\n", "left_pad_source", "=", "self", ".", "args", ".", "left_pad_source", ",", "\n", "left_pad_target", "=", "self", ".", "args", ".", "left_pad_target", ",", "\n", "max_source_positions", "=", "self", ".", "args", ".", "max_source_positions", ",", "\n", "max_target_positions", "=", "self", ".", "args", ".", "max_target_positions", ",", "\n", "prepend_bos", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_lev.TranslationLevenshteinTask.inject_noise": [[64, 146], ["translation_lev.TranslationLevenshteinTask.tgt_dict.pad", "translation_lev.TranslationLevenshteinTask.tgt_dict.bos", "translation_lev.TranslationLevenshteinTask.tgt_dict.eos", "target_tokens.size", "target_tokens.eq", "target_tokens.clone().float().uniform_", "target_tokens.clone().float().uniform_.masked_fill_", "target_tokens.clone().float().uniform_.masked_fill_", "target_tokens.clone().float().uniform_.sort", "target_tokens.gather().masked_fill_().gather", "translation_lev.TranslationLevenshteinTask.tgt_dict.pad", "translation_lev.TranslationLevenshteinTask.tgt_dict.bos", "translation_lev.TranslationLevenshteinTask.tgt_dict.eos", "translation_lev.TranslationLevenshteinTask.tgt_dict.unk", "target_tokens.clone().float().uniform_", "target_tokens.clone().float().uniform_.masked_fill_", "target_masks.sum().float", "target_tokens.clone().float().uniform_.sort", "target_tokens.masked_fill", "translation_lev.TranslationLevenshteinTask.tgt_dict.pad", "translation_lev.TranslationLevenshteinTask.tgt_dict.bos", "translation_lev.TranslationLevenshteinTask.tgt_dict.eos", "translation_lev.TranslationLevenshteinTask.tgt_dict.unk", "target_tokens.masked_fill", "translation_lev.TranslationLevenshteinTask.inject_noise._random_delete"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk"], ["", "def", "inject_noise", "(", "self", ",", "target_tokens", ")", ":", "\n", "        ", "def", "_random_delete", "(", "target_tokens", ")", ":", "\n", "            ", "pad", "=", "self", ".", "tgt_dict", ".", "pad", "(", ")", "\n", "bos", "=", "self", ".", "tgt_dict", ".", "bos", "(", ")", "\n", "eos", "=", "self", ".", "tgt_dict", ".", "eos", "(", ")", "\n", "\n", "max_len", "=", "target_tokens", ".", "size", "(", "1", ")", "\n", "target_mask", "=", "target_tokens", ".", "eq", "(", "pad", ")", "\n", "target_score", "=", "target_tokens", ".", "clone", "(", ")", ".", "float", "(", ")", ".", "uniform_", "(", ")", "\n", "target_score", ".", "masked_fill_", "(", "\n", "target_tokens", ".", "eq", "(", "bos", ")", "|", "target_tokens", ".", "eq", "(", "eos", ")", ",", "0.0", "\n", ")", "\n", "target_score", ".", "masked_fill_", "(", "target_mask", ",", "1", ")", "\n", "target_score", ",", "target_rank", "=", "target_score", ".", "sort", "(", "1", ")", "\n", "target_length", "=", "target_mask", ".", "size", "(", "1", ")", "-", "target_mask", ".", "float", "(", ")", ".", "sum", "(", "\n", "1", ",", "keepdim", "=", "True", "\n", ")", "\n", "\n", "# do not delete <bos> and <eos> (we assign 0 score for them)", "\n", "target_cutoff", "=", "(", "\n", "2", "\n", "+", "(", "\n", "(", "target_length", "-", "2", ")", "\n", "*", "target_score", ".", "new_zeros", "(", "target_score", ".", "size", "(", "0", ")", ",", "1", ")", ".", "uniform_", "(", ")", "\n", ")", ".", "long", "(", ")", "\n", ")", "\n", "target_cutoff", "=", "target_score", ".", "sort", "(", "1", ")", "[", "1", "]", ">=", "target_cutoff", "\n", "\n", "prev_target_tokens", "=", "(", "\n", "target_tokens", ".", "gather", "(", "1", ",", "target_rank", ")", "\n", ".", "masked_fill_", "(", "target_cutoff", ",", "pad", ")", "\n", ".", "gather", "(", "1", ",", "target_rank", ".", "masked_fill_", "(", "target_cutoff", ",", "max_len", ")", ".", "sort", "(", "1", ")", "[", "1", "]", ")", "\n", ")", "\n", "prev_target_tokens", "=", "prev_target_tokens", "[", "\n", ":", ",", ":", "prev_target_tokens", ".", "ne", "(", "pad", ")", ".", "sum", "(", "1", ")", ".", "max", "(", ")", "\n", "]", "\n", "\n", "return", "prev_target_tokens", "\n", "\n", "", "def", "_random_mask", "(", "target_tokens", ")", ":", "\n", "            ", "pad", "=", "self", ".", "tgt_dict", ".", "pad", "(", ")", "\n", "bos", "=", "self", ".", "tgt_dict", ".", "bos", "(", ")", "\n", "eos", "=", "self", ".", "tgt_dict", ".", "eos", "(", ")", "\n", "unk", "=", "self", ".", "tgt_dict", ".", "unk", "(", ")", "\n", "\n", "target_masks", "=", "(", "\n", "target_tokens", ".", "ne", "(", "pad", ")", "&", "target_tokens", ".", "ne", "(", "bos", ")", "&", "target_tokens", ".", "ne", "(", "eos", ")", "\n", ")", "\n", "target_score", "=", "target_tokens", ".", "clone", "(", ")", ".", "float", "(", ")", ".", "uniform_", "(", ")", "\n", "target_score", ".", "masked_fill_", "(", "~", "target_masks", ",", "2.0", ")", "\n", "target_length", "=", "target_masks", ".", "sum", "(", "1", ")", ".", "float", "(", ")", "\n", "target_length", "=", "target_length", "*", "target_length", ".", "clone", "(", ")", ".", "uniform_", "(", ")", "\n", "target_length", "=", "target_length", "+", "1", "# make sure to mask at least one token.", "\n", "\n", "_", ",", "target_rank", "=", "target_score", ".", "sort", "(", "1", ")", "\n", "target_cutoff", "=", "new_arange", "(", "target_rank", ")", "<", "target_length", "[", ":", ",", "None", "]", ".", "long", "(", ")", "\n", "prev_target_tokens", "=", "target_tokens", ".", "masked_fill", "(", "\n", "target_cutoff", ".", "scatter", "(", "1", ",", "target_rank", ",", "target_cutoff", ")", ",", "unk", "\n", ")", "\n", "return", "prev_target_tokens", "\n", "\n", "", "def", "_full_mask", "(", "target_tokens", ")", ":", "\n", "            ", "pad", "=", "self", ".", "tgt_dict", ".", "pad", "(", ")", "\n", "bos", "=", "self", ".", "tgt_dict", ".", "bos", "(", ")", "\n", "eos", "=", "self", ".", "tgt_dict", ".", "eos", "(", ")", "\n", "unk", "=", "self", ".", "tgt_dict", ".", "unk", "(", ")", "\n", "\n", "target_mask", "=", "(", "\n", "target_tokens", ".", "eq", "(", "bos", ")", "|", "target_tokens", ".", "eq", "(", "eos", ")", "|", "target_tokens", ".", "eq", "(", "pad", ")", "\n", ")", "\n", "return", "target_tokens", ".", "masked_fill", "(", "~", "target_mask", ",", "unk", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "noise", "==", "\"random_delete\"", ":", "\n", "            ", "return", "_random_delete", "(", "target_tokens", ")", "\n", "", "elif", "self", ".", "args", ".", "noise", "==", "\"random_mask\"", ":", "\n", "            ", "return", "_random_mask", "(", "target_tokens", ")", "\n", "", "elif", "self", ".", "args", ".", "noise", "==", "\"full_mask\"", ":", "\n", "            ", "return", "_full_mask", "(", "target_tokens", ")", "\n", "", "elif", "self", ".", "args", ".", "noise", "==", "\"no_noise\"", ":", "\n", "            ", "return", "target_tokens", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_lev.TranslationLevenshteinTask.build_generator": [[147, 160], ["IterativeRefinementGenerator", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "methods", ["None"], ["", "", "def", "build_generator", "(", "self", ",", "models", ",", "args", ",", "**", "unused", ")", ":", "\n", "# add models input to match the API for SequenceGenerator", "\n", "        ", "from", "fairseq", ".", "iterative_refinement_generator", "import", "IterativeRefinementGenerator", "\n", "\n", "return", "IterativeRefinementGenerator", "(", "\n", "self", ".", "target_dictionary", ",", "\n", "eos_penalty", "=", "getattr", "(", "args", ",", "\"iter_decode_eos_penalty\"", ",", "0.0", ")", ",", "\n", "max_iter", "=", "getattr", "(", "args", ",", "\"iter_decode_max_iter\"", ",", "10", ")", ",", "\n", "beam_size", "=", "getattr", "(", "args", ",", "\"iter_decode_with_beam\"", ",", "1", ")", ",", "\n", "reranking", "=", "getattr", "(", "args", ",", "\"iter_decode_with_external_reranker\"", ",", "False", ")", ",", "\n", "decoding_format", "=", "getattr", "(", "args", ",", "\"decoding_format\"", ",", "None", ")", ",", "\n", "adaptive", "=", "not", "getattr", "(", "args", ",", "\"iter_decode_force_max_iter\"", ",", "False", ")", ",", "\n", "retain_history", "=", "getattr", "(", "args", ",", "\"retain_iter_history\"", ",", "False", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_lev.TranslationLevenshteinTask.build_dataset_for_inference": [[162, 171], ["fairseq.data.LanguagePairDataset", "NotImplementedError"], "methods", ["None"], ["", "def", "build_dataset_for_inference", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "constraints", "=", "None", ")", ":", "\n", "        ", "if", "constraints", "is", "not", "None", ":", "\n", "# Though see Susanto et al. (ACL 2020): https://www.aclweb.org/anthology/2020.acl-main.325/", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Constrained decoding with the translation_lev task is not supported\"", "\n", ")", "\n", "\n", "", "return", "LanguagePairDataset", "(", "\n", "src_tokens", ",", "src_lengths", ",", "self", ".", "source_dictionary", ",", "append_bos", "=", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_lev.TranslationLevenshteinTask.train_step": [[173, 183], ["model.train", "translation_lev.TranslationLevenshteinTask.inject_noise", "criterion", "optimizer.backward"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.train", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_lev.TranslationLevenshteinTask.inject_noise", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.criterion", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward"], ["", "def", "train_step", "(", "\n", "self", ",", "sample", ",", "model", ",", "criterion", ",", "optimizer", ",", "update_num", ",", "ignore_grad", "=", "False", "\n", ")", ":", "\n", "        ", "model", ".", "train", "(", ")", "\n", "sample", "[", "\"prev_target\"", "]", "=", "self", ".", "inject_noise", "(", "sample", "[", "\"target\"", "]", ")", "\n", "loss", ",", "sample_size", ",", "logging_output", "=", "criterion", "(", "model", ",", "sample", ")", "\n", "if", "ignore_grad", ":", "\n", "            ", "loss", "*=", "0", "\n", "", "optimizer", ".", "backward", "(", "loss", ")", "\n", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_lev.TranslationLevenshteinTask.valid_step": [[184, 190], ["model.eval", "torch.no_grad", "translation_lev.TranslationLevenshteinTask.inject_noise", "criterion"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.translation_lev.TranslationLevenshteinTask.inject_noise", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.criterion"], ["", "def", "valid_step", "(", "self", ",", "sample", ",", "model", ",", "criterion", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "sample", "[", "\"prev_target\"", "]", "=", "self", ".", "inject_noise", "(", "sample", "[", "\"target\"", "]", ")", "\n", "loss", ",", "sample_size", ",", "logging_output", "=", "criterion", "(", "model", ",", "sample", ")", "\n", "", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.tasks.cross_lingual_lm.CrossLingualLMTask.add_args": [[34, 59], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "parser", ".", "add_argument", "(", "\n", "\"data\"", ",", "\n", "help", "=", "\"colon separated path to data directories list, \\\n                            will be iterated upon during epochs in round-robin manner\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokens-per-sample\"", ",", "\n", "default", "=", "512", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"max number of total tokens over all segments\"", "\" per sample\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--monolingual-langs\"", ",", "\n", "default", "=", "\"en\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"comma separated list of languages for which we\"", "\n", "\" want to train XLM on\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--shuffle\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"shuffle each monolingual dataset while\"", "\" training\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.cross_lingual_lm.CrossLingualLMTask.__init__": [[61, 67], ["fairseq.tasks.LegacyFairseqTask.__init__", "cross_lingual_lm.CrossLingualLMTask._lang_to_id"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.tasks.cross_lingual_lm.CrossLingualLMTask._lang_to_id"], ["", "def", "__init__", "(", "self", ",", "args", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "self", ".", "seed", "=", "args", ".", "seed", "\n", "self", ".", "distributed_world_size", "=", "args", ".", "distributed_world_size", "\n", "self", ".", "langs2id", "=", "self", ".", "_lang_to_id", "(", "args", ".", "monolingual_langs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.cross_lingual_lm.CrossLingualLMTask._lang_to_id": [[68, 78], ["enumerate", "l.strip", "languages.split"], "methods", ["None"], ["", "def", "_lang_to_id", "(", "self", ",", "languages", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        Build a map from languages to ids. These ids are used as segment labels\n        for cross-lingual LM training.\n        \"\"\"", "\n", "lang2id", "=", "{", "}", "\n", "langs", "=", "[", "l", ".", "strip", "(", ")", "for", "l", "in", "languages", ".", "split", "(", "\",\"", ")", "]", "\n", "for", "id", ",", "lang", "in", "enumerate", "(", "langs", ")", ":", "\n", "            ", "lang2id", "[", "lang", "]", "=", "id", "\n", "", "return", "lang2id", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.cross_lingual_lm.CrossLingualLMTask.load_dictionary": [[79, 82], ["fairseq.data.legacy.masked_lm_dictionary.MaskedLMDictionary.load"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load"], ["", "@", "classmethod", "\n", "def", "load_dictionary", "(", "cls", ",", "filename", ")", ":", "\n", "        ", "return", "MaskedLMDictionary", ".", "load", "(", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.cross_lingual_lm.CrossLingualLMTask.build_dictionary": [[83, 94], ["fairseq.data.legacy.masked_lm_dictionary.MaskedLMDictionary", "fairseq.data.legacy.masked_lm_dictionary.MaskedLMDictionary.finalize", "fairseq.data.Dictionary.add_file_to_dictionary"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDatasetBuilder.finalize", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_file_to_dictionary"], ["", "@", "classmethod", "\n", "def", "build_dictionary", "(", "\n", "cls", ",", "filenames", ",", "workers", "=", "1", ",", "threshold", "=", "-", "1", ",", "nwords", "=", "-", "1", ",", "padding_factor", "=", "8", "\n", ")", ":", "\n", "        ", "d", "=", "MaskedLMDictionary", "(", ")", "\n", "for", "filename", "in", "filenames", ":", "\n", "            ", "Dictionary", ".", "add_file_to_dictionary", "(", "\n", "filename", ",", "d", ",", "tokenizer", ".", "tokenize_line", ",", "workers", "\n", ")", "\n", "", "d", ".", "finalize", "(", "threshold", "=", "threshold", ",", "nwords", "=", "nwords", ",", "padding_factor", "=", "padding_factor", ")", "\n", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.cross_lingual_lm.CrossLingualLMTask.target_dictionary": [[95, 98], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.cross_lingual_lm.CrossLingualLMTask.setup_task": [[99, 105], ["fairseq.data.legacy.masked_lm_dictionary.MaskedLMDictionary.load", "logger.info", "cls", "os.path.join", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Setup the task.\"\"\"", "\n", "dictionary", "=", "MaskedLMDictionary", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data", ",", "\"dict.txt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"dictionary: {} types\"", ".", "format", "(", "len", "(", "dictionary", ")", ")", ")", "\n", "return", "cls", "(", "args", ",", "dictionary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.cross_lingual_lm.CrossLingualLMTask._load_single_lang_dataset": [[106, 153], ["fairseq.utils.split_paths", "itertools.count", "len", "os.path.join", "fairseq.data.data_utils.load_indexed_dataset", "loaded_datasets.append", "logger.info", "len", "fairseq.data.ConcatDataset", "numpy.concatenate", "fairseq.data.TokenBlockDataset", "len", "str", "FileNotFoundError", "len", "cross_lingual_lm.CrossLingualLMTask.dictionary.pad", "cross_lingual_lm.CrossLingualLMTask.dictionary.eos"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.load_indexed_dataset", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "def", "_load_single_lang_dataset", "(", "self", ",", "split", ",", "epoch", ")", ":", "\n", "        ", "loaded_datasets", "=", "[", "]", "\n", "\n", "paths", "=", "utils", ".", "split_paths", "(", "self", ".", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "data_path", "=", "paths", "[", "(", "epoch", "-", "1", ")", "%", "len", "(", "paths", ")", "]", "\n", "\n", "for", "k", "in", "itertools", ".", "count", "(", ")", ":", "\n", "            ", "split_k", "=", "split", "+", "(", "str", "(", "k", ")", "if", "k", ">", "0", "else", "\"\"", ")", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "split_k", ")", "\n", "\n", "ds", "=", "data_utils", ".", "load_indexed_dataset", "(", "\n", "path", ",", "self", ".", "dictionary", ",", "self", ".", "args", ".", "dataset_impl", "\n", ")", "\n", "if", "ds", "is", "None", ":", "\n", "                ", "if", "k", ">", "0", ":", "\n", "                    ", "break", "\n", "", "else", ":", "\n", "                    ", "raise", "FileNotFoundError", "(", "\n", "\"Dataset not found: {} ({})\"", ".", "format", "(", "split", ",", "data_path", ")", "\n", ")", "\n", "\n", "# Since we append each block with the classification_token,", "\n", "# we need to effectively create blocks of length", "\n", "# tokens_per_sample-1", "\n", "", "", "loaded_datasets", ".", "append", "(", "\n", "TokenBlockDataset", "(", "\n", "ds", ",", "\n", "ds", ".", "sizes", ",", "\n", "self", ".", "args", ".", "tokens_per_sample", "-", "1", ",", "\n", "pad", "=", "self", ".", "dictionary", ".", "pad", "(", ")", ",", "\n", "eos", "=", "self", ".", "dictionary", ".", "eos", "(", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "\n", "\"{} {} {} examples\"", ".", "format", "(", "data_path", ",", "split_k", ",", "len", "(", "loaded_datasets", "[", "-", "1", "]", ")", ")", "\n", ")", "\n", "\n", "", "if", "len", "(", "loaded_datasets", ")", "==", "1", ":", "\n", "            ", "dataset", "=", "loaded_datasets", "[", "0", "]", "\n", "sizes", "=", "dataset", ".", "sizes", "\n", "", "else", ":", "\n", "            ", "dataset", "=", "ConcatDataset", "(", "loaded_datasets", ")", "\n", "sizes", "=", "np", ".", "concatenate", "(", "[", "ds", ".", "sizes", "for", "ds", "in", "loaded_datasets", "]", ")", "\n", "\n", "", "return", "dataset", ",", "sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.cross_lingual_lm.CrossLingualLMTask.load_dataset": [[154, 190], ["collections.OrderedDict", "cross_lingual_lm.CrossLingualLMTask.langs2id.keys", "fairseq.data.multi_corpus_sampled_dataset.MultiCorpusSampledDataset", "logger.info", "cross_lingual_lm.CrossLingualLMTask._load_single_lang_dataset", "fairseq.data.legacy.masked_lm_dataset.MaskedLMDataset", "len", "cross_lingual_lm.CrossLingualLMTask.dictionary.pad", "cross_lingual_lm.CrossLingualLMTask.dictionary.mask", "cross_lingual_lm.CrossLingualLMTask.dictionary.eos", "cross_lingual_lm.CrossLingualLMTask.dictionary.eos", "getattr", "fairseq.utils.split_paths"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.cross_lingual_lm.CrossLingualLMTask._load_single_lang_dataset", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.MaskedLMDictionary.mask", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "1", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n        \"\"\"", "\n", "dataset_map", "=", "OrderedDict", "(", ")", "\n", "\n", "for", "lang", "in", "self", ".", "langs2id", ".", "keys", "(", ")", ":", "\n", "# Datasets are expected to be in \"split.lang\" format (Eg: train.en)", "\n", "            ", "language_split", "=", "\"{}.{}\"", ".", "format", "(", "split", ",", "lang", ")", "\n", "\n", "block_dataset", ",", "sizes", "=", "self", ".", "_load_single_lang_dataset", "(", "\n", "split", "=", "language_split", ",", "epoch", "=", "epoch", "\n", ")", "\n", "\n", "dataset_map", "[", "lang", "]", "=", "MaskedLMDataset", "(", "\n", "dataset", "=", "block_dataset", ",", "\n", "sizes", "=", "sizes", ",", "\n", "vocab", "=", "self", ".", "dictionary", ",", "\n", "pad_idx", "=", "self", ".", "dictionary", ".", "pad", "(", ")", ",", "\n", "mask_idx", "=", "self", ".", "dictionary", ".", "mask", "(", ")", ",", "\n", "classif_token_idx", "=", "self", ".", "dictionary", ".", "eos", "(", ")", ",", "\n", "sep_token_idx", "=", "self", ".", "dictionary", ".", "eos", "(", ")", ",", "\n", "shuffle", "=", "getattr", "(", "self", ".", "args", ",", "\"shuffle\"", ",", "False", ")", ",", "\n", "has_pairs", "=", "False", ",", "\n", "segment_id", "=", "self", ".", "langs2id", "[", "lang", "]", ",", "\n", "seed", "=", "self", ".", "seed", ",", "\n", ")", "\n", "\n", "", "self", ".", "datasets", "[", "split", "]", "=", "MultiCorpusSampledDataset", "(", "dataset_map", ")", "\n", "logger", ".", "info", "(", "\n", "\"{} {} {} examples\"", ".", "format", "(", "\n", "utils", ".", "split_paths", "(", "self", ".", "args", ".", "data", ")", "[", "epoch", "-", "1", "]", ",", "\n", "split", ",", "\n", "len", "(", "self", ".", "datasets", "[", "split", "]", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation.TranslationTask.add_args": [[186, 241], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'data'", ",", "help", "=", "'colon separated path to data directories list, \\\n                            will be iterated upon during epochs in round-robin manner; \\\n                            however, valid and test data are always in the first directory to \\\n                            avoid the need for repeating them in all directories'", ")", "\n", "parser", ".", "add_argument", "(", "'-s'", ",", "'--source-lang'", ",", "default", "=", "None", ",", "metavar", "=", "'SRC'", ",", "\n", "help", "=", "'source language'", ")", "\n", "parser", ".", "add_argument", "(", "'-t'", ",", "'--target-lang'", ",", "default", "=", "None", ",", "metavar", "=", "'TARGET'", ",", "\n", "help", "=", "'target language'", ")", "\n", "parser", ".", "add_argument", "(", "'--load-alignments'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'load the binarized alignments'", ")", "\n", "parser", ".", "add_argument", "(", "'--left-pad-source'", ",", "default", "=", "'True'", ",", "type", "=", "str", ",", "metavar", "=", "'BOOL'", ",", "\n", "help", "=", "'pad the source on the left'", ")", "\n", "parser", ".", "add_argument", "(", "'--left-pad-target'", ",", "default", "=", "'False'", ",", "type", "=", "str", ",", "metavar", "=", "'BOOL'", ",", "\n", "help", "=", "'pad the target on the left'", ")", "\n", "parser", ".", "add_argument", "(", "'--max-source-positions'", ",", "default", "=", "1024", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'max number of tokens in the source sequence'", ")", "\n", "parser", ".", "add_argument", "(", "'--max-target-positions'", ",", "default", "=", "1024", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'max number of tokens in the target sequence'", ")", "\n", "parser", ".", "add_argument", "(", "'--upsample-primary'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'amount to upsample primary dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--truncate-source'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'truncate source to max-source-positions'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-batch-buckets'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'if >0, then bucket source and target lengths into N '", "\n", "'buckets and pad accordingly; this is useful on TPUs '", "\n", "'to minimize the number of compilations'", ")", "\n", "\n", "# options for reporting BLEU during validation", "\n", "parser", ".", "add_argument", "(", "'--eval-bleu'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'evaluation with BLEU scores'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-bleu-detok'", ",", "type", "=", "str", ",", "default", "=", "\"space\"", ",", "\n", "help", "=", "'detokenize before computing BLEU (e.g., \"moses\"); '", "\n", "'required if using --eval-bleu; use \"space\" to '", "\n", "'disable detokenization; see fairseq.data.encoders '", "\n", "'for other options'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-bleu-detok-args'", ",", "type", "=", "str", ",", "metavar", "=", "'JSON'", ",", "\n", "help", "=", "'args for building the tokenizer, if needed'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-tokenized-bleu'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'compute tokenized BLEU instead of sacrebleu'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-bleu-remove-bpe'", ",", "nargs", "=", "'?'", ",", "const", "=", "'@@ '", ",", "default", "=", "None", ",", "\n", "help", "=", "'remove BPE before computing BLEU'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-bleu-args'", ",", "type", "=", "str", ",", "metavar", "=", "'JSON'", ",", "\n", "help", "=", "'generation args for BLUE scoring, '", "\n", "'e.g., \\'{\"beam\": 4, \"lenpen\": 0.6}\\''", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-bleu-print-samples'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'print sample generations during validation'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-bleu-bpe'", ",", "type", "=", "str", ",", "metavar", "=", "'BPE'", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "'args for building the bpe, if needed'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-bleu-bpe-path'", ",", "type", "=", "str", ",", "metavar", "=", "'BPE'", ",", "\n", "help", "=", "'args for building the bpe, if needed'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation.TranslationTask.__init__": [[243, 247], ["fairseq.tasks.LegacyFairseqTask.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["", "def", "__init__", "(", "self", ",", "args", ",", "src_dict", ",", "tgt_dict", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "src_dict", "=", "src_dict", "\n", "self", ".", "tgt_dict", "=", "tgt_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation.TranslationTask.setup_task": [[248, 284], ["fairseq.utils.eval_bool", "fairseq.utils.eval_bool", "fairseq.utils.split_paths", "cls.load_dictionary", "cls.load_dictionary", "logger.info", "logger.info", "cls", "len", "fairseq.data.data_utils.infer_language_pair", "Exception", "os.path.join", "os.path.join", "cls.load_dictionary.pad", "cls.load_dictionary.pad", "cls.load_dictionary.eos", "cls.load_dictionary.eos", "cls.load_dictionary.unk", "cls.load_dictionary.unk", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.eval_bool", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.eval_bool", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_prediction.SentencePredictionTask.load_dictionary", "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_prediction.SentencePredictionTask.load_dictionary", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.infer_language_pair", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Setup the task (e.g., load dictionaries).\n\n        Args:\n            args (argparse.Namespace): parsed command-line arguments\n        \"\"\"", "\n", "args", ".", "left_pad_source", "=", "utils", ".", "eval_bool", "(", "args", ".", "left_pad_source", ")", "\n", "args", ".", "left_pad_target", "=", "utils", ".", "eval_bool", "(", "args", ".", "left_pad_target", ")", "\n", "\n", "paths", "=", "utils", ".", "split_paths", "(", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "# find language pair automatically", "\n", "if", "args", ".", "source_lang", "is", "None", "or", "args", ".", "target_lang", "is", "None", ":", "\n", "            ", "args", ".", "source_lang", ",", "args", ".", "target_lang", "=", "data_utils", ".", "infer_language_pair", "(", "\n", "paths", "[", "0", "]", "\n", ")", "\n", "", "if", "args", ".", "source_lang", "is", "None", "or", "args", ".", "target_lang", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"Could not infer language pair, please provide it explicitly\"", "\n", ")", "\n", "\n", "# load dictionaries", "\n", "", "src_dict", "=", "cls", ".", "load_dictionary", "(", "\n", "os", ".", "path", ".", "join", "(", "paths", "[", "0", "]", ",", "\"dict.{}.txt\"", ".", "format", "(", "args", ".", "source_lang", ")", ")", "\n", ")", "\n", "tgt_dict", "=", "cls", ".", "load_dictionary", "(", "\n", "os", ".", "path", ".", "join", "(", "paths", "[", "0", "]", ",", "\"dict.{}.txt\"", ".", "format", "(", "args", ".", "target_lang", ")", ")", "\n", ")", "\n", "assert", "src_dict", ".", "pad", "(", ")", "==", "tgt_dict", ".", "pad", "(", ")", "\n", "assert", "src_dict", ".", "eos", "(", ")", "==", "tgt_dict", ".", "eos", "(", ")", "\n", "assert", "src_dict", ".", "unk", "(", ")", "==", "tgt_dict", ".", "unk", "(", ")", "\n", "logger", ".", "info", "(", "\"[{}] dictionary: {} types\"", ".", "format", "(", "args", ".", "source_lang", ",", "len", "(", "src_dict", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"[{}] dictionary: {} types\"", ".", "format", "(", "args", ".", "target_lang", ",", "len", "(", "tgt_dict", ")", ")", ")", "\n", "\n", "return", "cls", "(", "args", ",", "src_dict", ",", "tgt_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation.TranslationTask.load_dataset": [[285, 320], ["fairseq.utils.split_paths", "translation.load_langpair_dataset", "len", "getattr", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_langpair_dataset"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "1", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n        \"\"\"", "\n", "paths", "=", "utils", ".", "split_paths", "(", "self", ".", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "if", "split", "!=", "getattr", "(", "self", ".", "args", ",", "\"train_subset\"", ",", "None", ")", ":", "\n", "# if not training data set, use the first shard for valid and test", "\n", "            ", "paths", "=", "paths", "[", ":", "1", "]", "\n", "", "data_path", "=", "paths", "[", "(", "epoch", "-", "1", ")", "%", "len", "(", "paths", ")", "]", "\n", "\n", "# infer langcode", "\n", "src", ",", "tgt", "=", "self", ".", "args", ".", "source_lang", ",", "self", ".", "args", ".", "target_lang", "\n", "\n", "self", ".", "datasets", "[", "split", "]", "=", "load_langpair_dataset", "(", "\n", "data_path", ",", "\n", "split", ",", "\n", "src", ",", "\n", "self", ".", "src_dict", ",", "\n", "tgt", ",", "\n", "self", ".", "tgt_dict", ",", "\n", "combine", "=", "combine", ",", "\n", "dataset_impl", "=", "self", ".", "args", ".", "dataset_impl", ",", "\n", "upsample_primary", "=", "self", ".", "args", ".", "upsample_primary", ",", "\n", "left_pad_source", "=", "self", ".", "args", ".", "left_pad_source", ",", "\n", "left_pad_target", "=", "self", ".", "args", ".", "left_pad_target", ",", "\n", "max_source_positions", "=", "self", ".", "args", ".", "max_source_positions", ",", "\n", "max_target_positions", "=", "self", ".", "args", ".", "max_target_positions", ",", "\n", "load_alignments", "=", "self", ".", "args", ".", "load_alignments", ",", "\n", "truncate_source", "=", "self", ".", "args", ".", "truncate_source", ",", "\n", "num_buckets", "=", "self", ".", "args", ".", "num_batch_buckets", ",", "\n", "shuffle", "=", "(", "split", "!=", "\"test\"", ")", ",", "\n", "pad_to_multiple", "=", "self", ".", "args", ".", "required_seq_len_multiple", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation.TranslationTask.build_dataset_for_inference": [[322, 329], ["fairseq.data.LanguagePairDataset"], "methods", ["None"], ["", "def", "build_dataset_for_inference", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "constraints", "=", "None", ")", ":", "\n", "        ", "return", "LanguagePairDataset", "(", "\n", "src_tokens", ",", "\n", "src_lengths", ",", "\n", "self", ".", "source_dictionary", ",", "\n", "tgt_dict", "=", "self", ".", "target_dictionary", ",", "\n", "constraints", "=", "constraints", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation.TranslationTask.build_model": [[331, 361], ["super().build_model", "getattr", "json.loads", "fairseq.data.encoders.build_tokenizer", "json.loads", "translation.TranslationTask.build_generator", "getattr", "argparse.Namespace", "fairseq.data.encoders.build_bpe", "argparse.Namespace", "getattr", "argparse.Namespace", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model", "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.build_tokenizer", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.build_generator", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.build_bpe"], ["", "def", "build_model", "(", "self", ",", "args", ")", ":", "\n", "        ", "model", "=", "super", "(", ")", ".", "build_model", "(", "args", ")", "\n", "if", "getattr", "(", "args", ",", "\"eval_bleu\"", ",", "False", ")", ":", "\n", "            ", "assert", "getattr", "(", "args", ",", "\"eval_bleu_detok\"", ",", "None", ")", "is", "not", "None", ",", "(", "\n", "\"--eval-bleu-detok is required if using --eval-bleu; \"", "\n", "\"try --eval-bleu-detok=moses (or --eval-bleu-detok=space \"", "\n", "\"to disable detokenization, e.g., when using sentencepiece)\"", "\n", ")", "\n", "detok_args", "=", "json", ".", "loads", "(", "getattr", "(", "args", ",", "\"eval_bleu_detok_args\"", ",", "\"{}\"", ")", "or", "\"{}\"", ")", "\n", "self", ".", "tokenizer", "=", "encoders", ".", "build_tokenizer", "(", "\n", "Namespace", "(", "\n", "tokenizer", "=", "getattr", "(", "args", ",", "\"eval_bleu_detok\"", ",", "None", ")", ",", "**", "detok_args", "\n", ")", "\n", ")", "\n", "\n", "if", "args", ".", "eval_bleu_bpe", "is", "None", ":", "\n", "                ", "self", ".", "bpe", "=", "None", "\n", "", "else", ":", "\n", "                ", "self", ".", "bpe", "=", "encoders", ".", "build_bpe", "(", "\n", "Namespace", "(", "\n", "bpe", "=", "args", ".", "eval_bleu_bpe", ",", "\n", "sentencepiece_model", "=", "args", ".", "eval_bleu_bpe_path", "\n", ")", "\n", ")", "\n", "\n", "", "gen_args", "=", "json", ".", "loads", "(", "getattr", "(", "args", ",", "\"eval_bleu_args\"", ",", "\"{}\"", ")", "or", "\"{}\"", ")", "\n", "self", ".", "sequence_generator", "=", "self", ".", "build_generator", "(", "\n", "[", "model", "]", ",", "Namespace", "(", "**", "gen_args", ")", "\n", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation.TranslationTask.valid_step": [[362, 375], ["super().valid_step", "translation.TranslationTask._inference_with_bleu", "range", "len", "str", "str"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.valid_step", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag._inference_with_bleu"], ["", "def", "valid_step", "(", "self", ",", "sample", ",", "model", ",", "criterion", ")", ":", "\n", "        ", "loss", ",", "sample_size", ",", "logging_output", "=", "super", "(", ")", ".", "valid_step", "(", "sample", ",", "model", ",", "criterion", ")", "\n", "if", "self", ".", "args", ".", "eval_bleu", ":", "\n", "            ", "bleu", "=", "self", ".", "_inference_with_bleu", "(", "self", ".", "sequence_generator", ",", "sample", ",", "model", ")", "\n", "logging_output", "[", "\"_bleu_sys_len\"", "]", "=", "bleu", ".", "sys_len", "\n", "logging_output", "[", "\"_bleu_ref_len\"", "]", "=", "bleu", ".", "ref_len", "\n", "# we split counts into separate entries so that they can be", "\n", "# summed efficiently across workers using fast-stat-sync", "\n", "assert", "len", "(", "bleu", ".", "counts", ")", "==", "EVAL_BLEU_ORDER", "\n", "for", "i", "in", "range", "(", "EVAL_BLEU_ORDER", ")", ":", "\n", "                ", "logging_output", "[", "\"_bleu_counts_\"", "+", "str", "(", "i", ")", "]", "=", "bleu", ".", "counts", "[", "i", "]", "\n", "logging_output", "[", "\"_bleu_totals_\"", "+", "str", "(", "i", ")", "]", "=", "bleu", ".", "totals", "[", "i", "]", "\n", "", "", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation.TranslationTask.reduce_metrics": [[376, 416], ["super().reduce_metrics", "range", "sum", "counts.append", "totals.append", "max", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_derived", "sum", "translation.TranslationTask.reduce_metrics.sum_logs"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.reduce_metrics", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived"], ["", "def", "reduce_metrics", "(", "self", ",", "logging_outputs", ",", "criterion", ")", ":", "\n", "        ", "super", "(", ")", ".", "reduce_metrics", "(", "logging_outputs", ",", "criterion", ")", "\n", "if", "self", ".", "args", ".", "eval_bleu", ":", "\n", "\n", "            ", "def", "sum_logs", "(", "key", ")", ":", "\n", "                ", "if", "key", "in", "logging_outputs", "[", "0", "]", ":", "\n", "                    ", "return", "sum", "(", "log", "[", "key", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "for", "log", "in", "logging_outputs", ")", "\n", "", "return", "sum", "(", "log", ".", "get", "(", "key", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "\n", "", "counts", ",", "totals", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "EVAL_BLEU_ORDER", ")", ":", "\n", "                ", "counts", ".", "append", "(", "sum_logs", "(", "\"_bleu_counts_\"", "+", "str", "(", "i", ")", ")", ")", "\n", "totals", ".", "append", "(", "sum_logs", "(", "\"_bleu_totals_\"", "+", "str", "(", "i", ")", ")", ")", "\n", "\n", "", "if", "max", "(", "totals", ")", ">", "0", ":", "\n", "# log counts as numpy arrays -- log_scalar will sum them correctly", "\n", "                ", "metrics", ".", "log_scalar", "(", "\"_bleu_counts\"", ",", "np", ".", "array", "(", "counts", ")", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_bleu_totals\"", ",", "np", ".", "array", "(", "totals", ")", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_bleu_sys_len\"", ",", "sum_logs", "(", "\"_bleu_sys_len\"", ")", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_bleu_ref_len\"", ",", "sum_logs", "(", "\"_bleu_ref_len\"", ")", ")", "\n", "\n", "def", "compute_bleu", "(", "meters", ")", ":", "\n", "                    ", "import", "inspect", "\n", "import", "sacrebleu", "\n", "\n", "fn_sig", "=", "inspect", ".", "getfullargspec", "(", "sacrebleu", ".", "compute_bleu", ")", "[", "0", "]", "\n", "if", "\"smooth_method\"", "in", "fn_sig", ":", "\n", "                        ", "smooth", "=", "{", "\"smooth_method\"", ":", "\"exp\"", "}", "\n", "", "else", ":", "\n", "                        ", "smooth", "=", "{", "\"smooth\"", ":", "\"exp\"", "}", "\n", "", "bleu", "=", "sacrebleu", ".", "compute_bleu", "(", "\n", "correct", "=", "meters", "[", "\"_bleu_counts\"", "]", ".", "sum", ",", "\n", "total", "=", "meters", "[", "\"_bleu_totals\"", "]", ".", "sum", ",", "\n", "sys_len", "=", "meters", "[", "\"_bleu_sys_len\"", "]", ".", "sum", ",", "\n", "ref_len", "=", "meters", "[", "\"_bleu_ref_len\"", "]", ".", "sum", ",", "\n", "**", "smooth", "\n", ")", "\n", "return", "round", "(", "bleu", ".", "score", ",", "2", ")", "\n", "\n", "", "metrics", ".", "log_derived", "(", "\"bleu\"", ",", "compute_bleu", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation.TranslationTask.max_positions": [[417, 420], ["None"], "methods", ["None"], ["", "", "", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the max sentence length allowed by the task.\"\"\"", "\n", "return", "(", "self", ".", "args", ".", "max_source_positions", ",", "self", ".", "args", ".", "max_target_positions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation.TranslationTask.source_dictionary": [[421, 425], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the source :class:`~fairseq.data.Dictionary`.\"\"\"", "\n", "return", "self", ".", "src_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation.TranslationTask.target_dictionary": [[426, 430], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the target :class:`~fairseq.data.Dictionary`.\"\"\"", "\n", "return", "self", ".", "tgt_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation.TranslationTask._inference_with_bleu": [[431, 468], ["translation.TranslationTask.inference_step", "range", "translation.TranslationTask.tgt_dict.string", "len", "hyps.append", "refs.append", "logger.info", "logger.info", "sacrebleu.corpus_bleu", "sacrebleu.corpus_bleu", "toks.int().cpu", "translation.TranslationTask.bpe.decode", "translation.TranslationTask.tokenizer.decode", "translation.TranslationTask._inference_with_bleu.decode"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.inference_step", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "_inference_with_bleu", "(", "self", ",", "generator", ",", "sample", ",", "model", ")", ":", "\n", "        ", "import", "sacrebleu", "\n", "\n", "def", "decode", "(", "toks", ",", "escape_unk", "=", "False", ")", ":", "\n", "            ", "s", "=", "self", ".", "tgt_dict", ".", "string", "(", "\n", "toks", ".", "int", "(", ")", ".", "cpu", "(", ")", ",", "\n", "self", ".", "args", ".", "eval_bleu_remove_bpe", ",", "\n", "# The default unknown string in fairseq is `<unk>`, but", "\n", "# this is tokenized by sacrebleu as `< unk >`, inflating", "\n", "# BLEU scores. Instead, we use a somewhat more verbose", "\n", "# alternative that is unlikely to appear in the real", "\n", "# reference, but doesn't get split into multiple tokens.", "\n", "unk_string", "=", "(", "\"UNKNOWNTOKENINREF\"", "if", "escape_unk", "else", "\"UNKNOWNTOKENINHYP\"", ")", ",", "\n", ")", "\n", "if", "self", ".", "bpe", "is", "not", "None", ":", "\n", "                ", "s", "=", "self", ".", "bpe", ".", "decode", "(", "s", ")", "\n", "", "if", "self", ".", "tokenizer", ":", "\n", "                ", "s", "=", "self", ".", "tokenizer", ".", "decode", "(", "s", ")", "\n", "", "return", "s", "\n", "\n", "", "gen_out", "=", "self", ".", "inference_step", "(", "generator", ",", "[", "model", "]", ",", "sample", ",", "prefix_tokens", "=", "None", ")", "\n", "hyps", ",", "refs", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "gen_out", ")", ")", ":", "\n", "            ", "hyps", ".", "append", "(", "decode", "(", "gen_out", "[", "i", "]", "[", "0", "]", "[", "\"tokens\"", "]", ")", ")", "\n", "refs", ".", "append", "(", "\n", "decode", "(", "\n", "utils", ".", "strip_pad", "(", "sample", "[", "\"target\"", "]", "[", "i", "]", ",", "self", ".", "tgt_dict", ".", "pad", "(", ")", ")", ",", "\n", "escape_unk", "=", "True", ",", "# don't count <unk> as matches to the hypo", "\n", ")", "\n", ")", "\n", "", "if", "self", ".", "args", ".", "eval_bleu_print_samples", ":", "\n", "            ", "logger", ".", "info", "(", "\"example hypothesis: \"", "+", "hyps", "[", "0", "]", ")", "\n", "logger", ".", "info", "(", "\"example reference: \"", "+", "refs", "[", "0", "]", ")", "\n", "", "if", "self", ".", "args", ".", "eval_tokenized_bleu", ":", "\n", "            ", "return", "sacrebleu", ".", "corpus_bleu", "(", "hyps", ",", "[", "refs", "]", ",", "tokenize", "=", "\"none\"", ")", "\n", "", "else", ":", "\n", "            ", "return", "sacrebleu", ".", "corpus_bleu", "(", "hyps", ",", "[", "refs", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation.TranslationTask.build_bpe": [[469, 473], ["logger.info"], "methods", ["None"], ["", "", "def", "build_bpe", "(", "self", ",", "args", ")", ":", "\n", "# ignore args, no one is really using it", "\n", "        ", "logger", ".", "info", "(", "f\"tokenizer: {self.bpe}\"", ")", "\n", "return", "self", ".", "bpe", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation.load_langpair_dataset": [[34, 161], ["itertools.count", "fairseq.data.LanguagePairDataset", "os.path.join", "fairseq.data.indexed_dataset.dataset_exists", "translation.load_langpair_dataset.split_exists"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.dataset_exists", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.split_exists"], ["def", "load_langpair_dataset", "(", "\n", "data_path", ",", "\n", "split", ",", "\n", "src", ",", "\n", "src_dict", ",", "\n", "tgt", ",", "\n", "tgt_dict", ",", "\n", "combine", ",", "\n", "dataset_impl", ",", "\n", "upsample_primary", ",", "\n", "left_pad_source", ",", "\n", "left_pad_target", ",", "\n", "max_source_positions", ",", "\n", "max_target_positions", ",", "\n", "prepend_bos", "=", "False", ",", "\n", "load_alignments", "=", "False", ",", "\n", "truncate_source", "=", "False", ",", "\n", "append_source_id", "=", "False", ",", "\n", "num_buckets", "=", "0", ",", "\n", "shuffle", "=", "True", ",", "\n", "pad_to_multiple", "=", "1", ",", "\n", ")", ":", "\n", "    ", "def", "split_exists", "(", "split", ",", "src", ",", "tgt", ",", "lang", ",", "data_path", ")", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"{}.{}-{}.{}\"", ".", "format", "(", "split", ",", "src", ",", "tgt", ",", "lang", ")", ")", "\n", "return", "indexed_dataset", ".", "dataset_exists", "(", "filename", ",", "impl", "=", "dataset_impl", ")", "\n", "\n", "", "src_datasets", "=", "[", "]", "\n", "tgt_datasets", "=", "[", "]", "\n", "\n", "for", "k", "in", "itertools", ".", "count", "(", ")", ":", "\n", "        ", "split_k", "=", "split", "+", "(", "str", "(", "k", ")", "if", "k", ">", "0", "else", "\"\"", ")", "\n", "\n", "# infer langcode", "\n", "if", "split_exists", "(", "split_k", ",", "src", ",", "tgt", ",", "src", ",", "data_path", ")", ":", "\n", "            ", "prefix", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"{}.{}-{}.\"", ".", "format", "(", "split_k", ",", "src", ",", "tgt", ")", ")", "\n", "", "elif", "split_exists", "(", "split_k", ",", "tgt", ",", "src", ",", "src", ",", "data_path", ")", ":", "\n", "            ", "prefix", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"{}.{}-{}.\"", ".", "format", "(", "split_k", ",", "tgt", ",", "src", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "k", ">", "0", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "raise", "FileNotFoundError", "(", "\n", "\"Dataset not found: {} ({})\"", ".", "format", "(", "split", ",", "data_path", ")", "\n", ")", "\n", "\n", "", "", "src_dataset", "=", "data_utils", ".", "load_indexed_dataset", "(", "\n", "prefix", "+", "src", ",", "src_dict", ",", "dataset_impl", "\n", ")", "\n", "if", "truncate_source", ":", "\n", "            ", "src_dataset", "=", "AppendTokenDataset", "(", "\n", "TruncateDataset", "(", "\n", "StripTokenDataset", "(", "src_dataset", ",", "src_dict", ".", "eos", "(", ")", ")", ",", "\n", "max_source_positions", "-", "1", ",", "\n", ")", ",", "\n", "src_dict", ".", "eos", "(", ")", ",", "\n", ")", "\n", "", "src_datasets", ".", "append", "(", "src_dataset", ")", "\n", "\n", "tgt_dataset", "=", "data_utils", ".", "load_indexed_dataset", "(", "\n", "prefix", "+", "tgt", ",", "tgt_dict", ",", "dataset_impl", "\n", ")", "\n", "if", "tgt_dataset", "is", "not", "None", ":", "\n", "            ", "tgt_datasets", ".", "append", "(", "tgt_dataset", ")", "\n", "\n", "", "logger", ".", "info", "(", "\n", "\"{} {} {}-{} {} examples\"", ".", "format", "(", "\n", "data_path", ",", "split_k", ",", "src", ",", "tgt", ",", "len", "(", "src_datasets", "[", "-", "1", "]", ")", "\n", ")", "\n", ")", "\n", "\n", "if", "not", "combine", ":", "\n", "            ", "break", "\n", "\n", "", "", "assert", "len", "(", "src_datasets", ")", "==", "len", "(", "tgt_datasets", ")", "or", "len", "(", "tgt_datasets", ")", "==", "0", "\n", "\n", "if", "len", "(", "src_datasets", ")", "==", "1", ":", "\n", "        ", "src_dataset", "=", "src_datasets", "[", "0", "]", "\n", "tgt_dataset", "=", "tgt_datasets", "[", "0", "]", "if", "len", "(", "tgt_datasets", ")", ">", "0", "else", "None", "\n", "", "else", ":", "\n", "        ", "sample_ratios", "=", "[", "1", "]", "*", "len", "(", "src_datasets", ")", "\n", "sample_ratios", "[", "0", "]", "=", "upsample_primary", "\n", "src_dataset", "=", "ConcatDataset", "(", "src_datasets", ",", "sample_ratios", ")", "\n", "if", "len", "(", "tgt_datasets", ")", ">", "0", ":", "\n", "            ", "tgt_dataset", "=", "ConcatDataset", "(", "tgt_datasets", ",", "sample_ratios", ")", "\n", "", "else", ":", "\n", "            ", "tgt_dataset", "=", "None", "\n", "\n", "", "", "if", "prepend_bos", ":", "\n", "        ", "assert", "hasattr", "(", "src_dict", ",", "\"bos_index\"", ")", "and", "hasattr", "(", "tgt_dict", ",", "\"bos_index\"", ")", "\n", "src_dataset", "=", "PrependTokenDataset", "(", "src_dataset", ",", "src_dict", ".", "bos", "(", ")", ")", "\n", "if", "tgt_dataset", "is", "not", "None", ":", "\n", "            ", "tgt_dataset", "=", "PrependTokenDataset", "(", "tgt_dataset", ",", "tgt_dict", ".", "bos", "(", ")", ")", "\n", "\n", "", "", "eos", "=", "None", "\n", "if", "append_source_id", ":", "\n", "        ", "src_dataset", "=", "AppendTokenDataset", "(", "\n", "src_dataset", ",", "src_dict", ".", "index", "(", "\"[{}]\"", ".", "format", "(", "src", ")", ")", "\n", ")", "\n", "if", "tgt_dataset", "is", "not", "None", ":", "\n", "            ", "tgt_dataset", "=", "AppendTokenDataset", "(", "\n", "tgt_dataset", ",", "tgt_dict", ".", "index", "(", "\"[{}]\"", ".", "format", "(", "tgt", ")", ")", "\n", ")", "\n", "", "eos", "=", "tgt_dict", ".", "index", "(", "\"[{}]\"", ".", "format", "(", "tgt", ")", ")", "\n", "\n", "", "align_dataset", "=", "None", "\n", "if", "load_alignments", ":", "\n", "        ", "align_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"{}.align.{}-{}\"", ".", "format", "(", "split", ",", "src", ",", "tgt", ")", ")", "\n", "if", "indexed_dataset", ".", "dataset_exists", "(", "align_path", ",", "impl", "=", "dataset_impl", ")", ":", "\n", "            ", "align_dataset", "=", "data_utils", ".", "load_indexed_dataset", "(", "\n", "align_path", ",", "None", ",", "dataset_impl", "\n", ")", "\n", "\n", "", "", "tgt_dataset_sizes", "=", "tgt_dataset", ".", "sizes", "if", "tgt_dataset", "is", "not", "None", "else", "None", "\n", "return", "LanguagePairDataset", "(", "\n", "src_dataset", ",", "\n", "src_dataset", ".", "sizes", ",", "\n", "src_dict", ",", "\n", "tgt_dataset", ",", "\n", "tgt_dataset_sizes", ",", "\n", "tgt_dict", ",", "\n", "left_pad_source", "=", "left_pad_source", ",", "\n", "left_pad_target", "=", "left_pad_target", ",", "\n", "align_dataset", "=", "align_dataset", ",", "\n", "eos", "=", "eos", ",", "\n", "num_buckets", "=", "num_buckets", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "pad_to_multiple", "=", "pad_to_multiple", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_masked_lm.MultiLingualMaskedLMTask.add_args": [[39, 98], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "parser", ".", "add_argument", "(", "\n", "\"data\"", ",", "\n", "help", "=", "\"colon separated path to data directories list, \\\n                            will be iterated upon during epochs in round-robin manner\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--sample-break-mode\"", ",", "\n", "default", "=", "\"complete\"", ",", "\n", "choices", "=", "[", "\"none\"", ",", "\"complete\"", ",", "\"complete_doc\"", ",", "\"eos\"", "]", ",", "\n", "help", "=", "'If omitted or \"none\", fills each sample with tokens-per-sample '", "\n", "'tokens. If set to \"complete\", splits samples only at the end '", "\n", "\"of sentence, but may include multiple sentences per sample. \"", "\n", "'\"complete_doc\" is similar but respects doc boundaries. '", "\n", "'If set to \"eos\", includes only one sentence per sample.'", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokens-per-sample\"", ",", "\n", "default", "=", "512", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"max number of total tokens over all segments \"", "\n", "\"per sample for BERT dataset\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-prob\"", ",", "\n", "default", "=", "0.15", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"probability of replacing a token with mask\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--leave-unmasked-prob\"", ",", "\n", "default", "=", "0.1", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"probability that a masked token is unmasked\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--random-token-prob\"", ",", "\n", "default", "=", "0.1", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"probability of replacing a token with a random token\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--freq-weighted-replacement\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"sample random replacement words based on word frequencies\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-whole-words\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"mask whole words; you may also want to set --bpe\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--multilang-sampling-alpha\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "1.0", ",", "\n", "help", "=", "\"smoothing alpha for sample rations across multiple datasets\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_masked_lm.MultiLingualMaskedLMTask.__init__": [[100, 107], ["fairseq.tasks.LegacyFairseqTask.__init__", "dictionary.add_symbol"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol"], ["", "def", "__init__", "(", "self", ",", "args", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "self", ".", "seed", "=", "args", ".", "seed", "\n", "\n", "# add mask token", "\n", "self", ".", "mask_idx", "=", "dictionary", ".", "add_symbol", "(", "\"<mask>\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_masked_lm.MultiLingualMaskedLMTask.setup_task": [[108, 115], ["fairseq.utils.split_paths", "fairseq.data.Dictionary.load", "logger.info", "cls", "len", "os.path.join", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "paths", "=", "utils", ".", "split_paths", "(", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "dictionary", "=", "Dictionary", ".", "load", "(", "os", ".", "path", ".", "join", "(", "paths", "[", "0", "]", ",", "\"dict.txt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"dictionary: {} types\"", ".", "format", "(", "len", "(", "dictionary", ")", ")", ")", "\n", "return", "cls", "(", "args", ",", "dictionary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_masked_lm.MultiLingualMaskedLMTask._get_whole_word_mask": [[116, 140], ["fairseq.data.encoders.build_bpe", "torch.ByteTensor", "tok.startswith", "list", "fairseq.data.encoders.build_bpe.is_beginning_of_word", "map", "range", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.build_bpe", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.is_beginning_of_word"], ["", "def", "_get_whole_word_mask", "(", "self", ")", ":", "\n", "# create masked input and targets", "\n", "        ", "if", "self", ".", "args", ".", "mask_whole_words", ":", "\n", "            ", "bpe", "=", "encoders", ".", "build_bpe", "(", "self", ".", "args", ")", "\n", "if", "bpe", "is", "not", "None", ":", "\n", "\n", "                ", "def", "is_beginning_of_word", "(", "i", ")", ":", "\n", "                    ", "if", "i", "<", "self", ".", "source_dictionary", ".", "nspecial", ":", "\n", "# special elements are always considered beginnings", "\n", "                        ", "return", "True", "\n", "", "tok", "=", "self", ".", "source_dictionary", "[", "i", "]", "\n", "if", "tok", ".", "startswith", "(", "\"madeupword\"", ")", ":", "\n", "                        ", "return", "True", "\n", "", "try", ":", "\n", "                        ", "return", "bpe", ".", "is_beginning_of_word", "(", "tok", ")", "\n", "", "except", "ValueError", ":", "\n", "                        ", "return", "True", "\n", "\n", "", "", "mask_whole_words", "=", "torch", ".", "ByteTensor", "(", "\n", "list", "(", "map", "(", "is_beginning_of_word", ",", "range", "(", "len", "(", "self", ".", "source_dictionary", ")", ")", ")", ")", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "mask_whole_words", "=", "None", "\n", "", "return", "mask_whole_words", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_masked_lm.MultiLingualMaskedLMTask._get_sample_prob": [[141, 150], ["dataset_lens.sum", "smoothed_prob.sum"], "methods", ["None"], ["", "def", "_get_sample_prob", "(", "self", ",", "dataset_lens", ")", ":", "\n", "        ", "\"\"\"\n        Get smoothed sampling porbability by languages. This helps low resource\n        languages by upsampling them.\n        \"\"\"", "\n", "prob", "=", "dataset_lens", "/", "dataset_lens", ".", "sum", "(", ")", "\n", "smoothed_prob", "=", "prob", "**", "self", ".", "args", ".", "multilang_sampling_alpha", "\n", "smoothed_prob", "=", "smoothed_prob", "/", "smoothed_prob", ".", "sum", "(", ")", "\n", "return", "smoothed_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_masked_lm.MultiLingualMaskedLMTask.load_dataset": [[151, 301], ["fairseq.utils.split_paths", "sorted", "logger.info", "logger.info", "multilingual_masked_lm.MultiLingualMaskedLMTask._get_whole_word_mask", "enumerate", "numpy.array", "logger.info", "fairseq.data.SortDataset", "len", "os.path.join", "fairseq.data.data_utils.load_indexed_dataset", "fairseq.data.TokenBlockDataset", "logger.info", "fairseq.data.PrependTokenDataset", "fairseq.data.MaskTokensDataset.apply_mask", "fairseq.data.NestedDictionaryDataset", "lang_datasets.append", "multilingual_masked_lm.MultiLingualMaskedLMTask._get_sample_prob", "logger.info", "logger.info", "fairseq.data.ConcatDataset", "fairseq.data.ConcatDataset", "enumerate", "fairseq.data.data_utils.numpy_seed", "numpy.random.permutation", "len", "FileNotFoundError", "multilingual_masked_lm.MultiLingualMaskedLMTask.source_dictionary.bos", "len", "numpy.array.sum", "fairseq.data.ResamplingDataset", "lang_splits.append", "multilingual_masked_lm.MultiLingualMaskedLMTask.args.valid_subset.replace", "len", "len", "os.listdir", "os.path.isdir", "enumerate", "multilingual_masked_lm.MultiLingualMaskedLMTask.source_dictionary.pad", "multilingual_masked_lm.MultiLingualMaskedLMTask.source_dictionary.eos", "len", "multilingual_masked_lm.MultiLingualMaskedLMTask.source_dictionary.pad", "fairseq.data.PadDataset", "fairseq.data.NumSamplesDataset", "fairseq.data.NumelDataset", "fairseq.data.RawLabelDataset", "numpy.array.sum", "enumerate", "os.path.join", "fairseq.data.PadDataset", "fairseq.data.NumelDataset", "enumerate", "enumerate", "multilingual_masked_lm.MultiLingualMaskedLMTask.source_dictionary.pad", "multilingual_masked_lm.MultiLingualMaskedLMTask.source_dictionary.pad"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_masked_lm.MultiLingualMaskedLMTask._get_whole_word_mask", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.load_indexed_dataset", "home.repos.pwc.inspect_result.reneeye_const.data.mask_tokens_dataset.MaskTokensDataset.apply_mask", "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_denoising.MultilingualDenoisingTask._get_sample_prob", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.numpy_seed", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "1", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n        \"\"\"", "\n", "paths", "=", "utils", ".", "split_paths", "(", "self", ".", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "data_path", "=", "paths", "[", "(", "epoch", "-", "1", ")", "%", "len", "(", "paths", ")", "]", "\n", "\n", "languages", "=", "sorted", "(", "\n", "name", "\n", "for", "name", "in", "os", ".", "listdir", "(", "data_path", ")", "\n", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "name", ")", ")", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training on {0} languages: {1}\"", ".", "format", "(", "len", "(", "languages", ")", ",", "languages", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"Language to id mapping: \"", ",", "{", "lang", ":", "id", "for", "id", ",", "lang", "in", "enumerate", "(", "languages", ")", "}", "\n", ")", "\n", "\n", "mask_whole_words", "=", "self", ".", "_get_whole_word_mask", "(", ")", "\n", "lang_datasets", "=", "[", "]", "\n", "for", "lang_id", ",", "language", "in", "enumerate", "(", "languages", ")", ":", "\n", "            ", "split_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "language", ",", "split", ")", "\n", "\n", "dataset", "=", "data_utils", ".", "load_indexed_dataset", "(", "\n", "split_path", ",", "\n", "self", ".", "source_dictionary", ",", "\n", "self", ".", "args", ".", "dataset_impl", ",", "\n", "combine", "=", "combine", ",", "\n", ")", "\n", "if", "dataset", "is", "None", ":", "\n", "                ", "raise", "FileNotFoundError", "(", "\n", "\"Dataset not found: {} ({})\"", ".", "format", "(", "split", ",", "split_path", ")", "\n", ")", "\n", "\n", "# create continuous blocks of tokens", "\n", "", "dataset", "=", "TokenBlockDataset", "(", "\n", "dataset", ",", "\n", "dataset", ".", "sizes", ",", "\n", "self", ".", "args", ".", "tokens_per_sample", "-", "1", ",", "# one less for <s>", "\n", "pad", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", "eos", "=", "self", ".", "source_dictionary", ".", "eos", "(", ")", ",", "\n", "break_mode", "=", "self", ".", "args", ".", "sample_break_mode", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"loaded {} blocks from: {}\"", ".", "format", "(", "len", "(", "dataset", ")", ",", "split_path", ")", ")", "\n", "\n", "# prepend beginning-of-sentence token (<s>, equiv. to [CLS] in BERT)", "\n", "dataset", "=", "PrependTokenDataset", "(", "dataset", ",", "self", ".", "source_dictionary", ".", "bos", "(", ")", ")", "\n", "\n", "src_dataset", ",", "tgt_dataset", "=", "MaskTokensDataset", ".", "apply_mask", "(", "\n", "dataset", ",", "\n", "self", ".", "source_dictionary", ",", "\n", "pad_idx", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", "mask_idx", "=", "self", ".", "mask_idx", ",", "\n", "seed", "=", "self", ".", "args", ".", "seed", ",", "\n", "mask_prob", "=", "self", ".", "args", ".", "mask_prob", ",", "\n", "leave_unmasked_prob", "=", "self", ".", "args", ".", "leave_unmasked_prob", ",", "\n", "random_token_prob", "=", "self", ".", "args", ".", "random_token_prob", ",", "\n", "freq_weighted_replacement", "=", "self", ".", "args", ".", "freq_weighted_replacement", ",", "\n", "mask_whole_words", "=", "mask_whole_words", ",", "\n", ")", "\n", "\n", "lang_dataset", "=", "NestedDictionaryDataset", "(", "\n", "{", "\n", "\"net_input\"", ":", "{", "\n", "\"src_tokens\"", ":", "PadDataset", "(", "\n", "src_dataset", ",", "\n", "pad_idx", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", "left_pad", "=", "False", ",", "\n", ")", ",", "\n", "\"src_lengths\"", ":", "NumelDataset", "(", "src_dataset", ",", "reduce", "=", "False", ")", ",", "\n", "}", ",", "\n", "\"target\"", ":", "PadDataset", "(", "\n", "tgt_dataset", ",", "\n", "pad_idx", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", "left_pad", "=", "False", ",", "\n", ")", ",", "\n", "\"nsentences\"", ":", "NumSamplesDataset", "(", ")", ",", "\n", "\"ntokens\"", ":", "NumelDataset", "(", "src_dataset", ",", "reduce", "=", "True", ")", ",", "\n", "\"lang_id\"", ":", "RawLabelDataset", "(", "[", "lang_id", "]", "*", "src_dataset", ".", "sizes", ".", "shape", "[", "0", "]", ")", ",", "\n", "}", ",", "\n", "sizes", "=", "[", "src_dataset", ".", "sizes", "]", ",", "\n", ")", "\n", "lang_datasets", ".", "append", "(", "lang_dataset", ")", "\n", "\n", "", "dataset_lengths", "=", "np", ".", "array", "(", "\n", "[", "len", "(", "d", ")", "for", "d", "in", "lang_datasets", "]", ",", "\n", "dtype", "=", "float", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"loaded total {} blocks for all languages\"", ".", "format", "(", "\n", "dataset_lengths", ".", "sum", "(", ")", ",", "\n", ")", "\n", ")", "\n", "if", "split", "==", "self", ".", "args", ".", "train_subset", ":", "\n", "# For train subset, additionally up or down sample languages.", "\n", "            ", "sample_probs", "=", "self", ".", "_get_sample_prob", "(", "dataset_lengths", ")", "\n", "logger", ".", "info", "(", "\n", "\"Sample probability by language: \"", ",", "\n", "{", "\n", "lang", ":", "\"{0:.4f}\"", ".", "format", "(", "sample_probs", "[", "id", "]", ")", "\n", "for", "id", ",", "lang", "in", "enumerate", "(", "languages", ")", "\n", "}", ",", "\n", ")", "\n", "size_ratio", "=", "(", "sample_probs", "*", "dataset_lengths", ".", "sum", "(", ")", ")", "/", "dataset_lengths", "\n", "logger", ".", "info", "(", "\n", "\"Up/Down Sampling ratio by language: \"", ",", "\n", "{", "\n", "lang", ":", "\"{0:.2f}\"", ".", "format", "(", "size_ratio", "[", "id", "]", ")", "\n", "for", "id", ",", "lang", "in", "enumerate", "(", "languages", ")", "\n", "}", ",", "\n", ")", "\n", "\n", "resampled_lang_datasets", "=", "[", "\n", "ResamplingDataset", "(", "\n", "lang_datasets", "[", "i", "]", ",", "\n", "size_ratio", "=", "size_ratio", "[", "i", "]", ",", "\n", "seed", "=", "self", ".", "args", ".", "seed", ",", "\n", "epoch", "=", "epoch", ",", "\n", "replace", "=", "size_ratio", "[", "i", "]", ">=", "1.0", ",", "\n", ")", "\n", "for", "i", ",", "d", "in", "enumerate", "(", "lang_datasets", ")", "\n", "]", "\n", "dataset", "=", "ConcatDataset", "(", "resampled_lang_datasets", ")", "\n", "", "else", ":", "\n", "            ", "dataset", "=", "ConcatDataset", "(", "lang_datasets", ")", "\n", "lang_splits", "=", "[", "split", "]", "\n", "for", "lang_id", ",", "lang_dataset", "in", "enumerate", "(", "lang_datasets", ")", ":", "\n", "                ", "split_name", "=", "split", "+", "\"_\"", "+", "languages", "[", "lang_id", "]", "\n", "lang_splits", ".", "append", "(", "split_name", ")", "\n", "self", ".", "datasets", "[", "split_name", "]", "=", "lang_dataset", "\n", "\n", "# [TODO]: This is hacky for now to print validation ppl for each", "\n", "# language individually. Maybe need task API changes to allow it", "\n", "# in more generic ways.", "\n", "", "if", "split", "in", "self", ".", "args", ".", "valid_subset", ":", "\n", "                ", "self", ".", "args", ".", "valid_subset", "=", "self", ".", "args", ".", "valid_subset", ".", "replace", "(", "\n", "split", ",", "\",\"", ".", "join", "(", "lang_splits", ")", "\n", ")", "\n", "\n", "", "", "with", "data_utils", ".", "numpy_seed", "(", "self", ".", "args", ".", "seed", "+", "epoch", ")", ":", "\n", "            ", "shuffle", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "dataset", ")", ")", "\n", "\n", "", "self", ".", "datasets", "[", "split", "]", "=", "SortDataset", "(", "\n", "dataset", ",", "\n", "sort_order", "=", "[", "\n", "shuffle", ",", "\n", "dataset", ".", "sizes", ",", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_masked_lm.MultiLingualMaskedLMTask.build_dataset_for_inference": [[304, 331], ["fairseq.data.PadDataset", "fairseq.data.PrependTokenDataset", "fairseq.data.NestedDictionaryDataset", "fairseq.data.TokenBlockDataset", "multilingual_masked_lm.MultiLingualMaskedLMTask.source_dictionary.bos", "fairseq.data.SortDataset", "multilingual_masked_lm.MultiLingualMaskedLMTask.source_dictionary.pad", "fairseq.data.IdDataset", "multilingual_masked_lm.MultiLingualMaskedLMTask.source_dictionary.pad", "multilingual_masked_lm.MultiLingualMaskedLMTask.source_dictionary.eos", "fairseq.data.NumelDataset"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "def", "build_dataset_for_inference", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "sort", "=", "True", ")", ":", "\n", "        ", "src_dataset", "=", "PadDataset", "(", "\n", "TokenBlockDataset", "(", "\n", "src_tokens", ",", "\n", "src_lengths", ",", "\n", "self", ".", "args", ".", "tokens_per_sample", "-", "1", ",", "# one less for <s>", "\n", "pad", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", "eos", "=", "self", ".", "source_dictionary", ".", "eos", "(", ")", ",", "\n", "break_mode", "=", "\"eos\"", ",", "\n", ")", ",", "\n", "pad_idx", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", "left_pad", "=", "False", ",", "\n", ")", "\n", "src_dataset", "=", "PrependTokenDataset", "(", "src_dataset", ",", "self", ".", "source_dictionary", ".", "bos", "(", ")", ")", "\n", "src_dataset", "=", "NestedDictionaryDataset", "(", "\n", "{", "\n", "\"id\"", ":", "IdDataset", "(", ")", ",", "\n", "\"net_input\"", ":", "{", "\n", "\"src_tokens\"", ":", "src_dataset", ",", "\n", "\"src_lengths\"", ":", "NumelDataset", "(", "src_dataset", ",", "reduce", "=", "False", ")", ",", "\n", "}", ",", "\n", "}", ",", "\n", "sizes", "=", "src_lengths", ",", "\n", ")", "\n", "if", "sort", ":", "\n", "            ", "src_dataset", "=", "SortDataset", "(", "src_dataset", ",", "sort_order", "=", "[", "src_lengths", "]", ")", "\n", "", "return", "src_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_masked_lm.MultiLingualMaskedLMTask.source_dictionary": [[332, 335], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_masked_lm.MultiLingualMaskedLMTask.target_dictionary": [[336, 339], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.add_args": [[29, 35], ["getattr", "fairseq.dataclass.utils.gen_parser_from_dataclass", "getattr."], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.gen_parser_from_dataclass"], ["@", "classmethod", "\n", "def", "add_args", "(", "cls", ",", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "dc", "=", "getattr", "(", "cls", ",", "\"__dataclass\"", ",", "None", ")", "\n", "if", "dc", "is", "not", "None", ":", "\n", "            ", "gen_parser_from_dataclass", "(", "parser", ",", "dc", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.logging_outputs_can_be_summed": [[36, 44], ["criterion.logging_outputs_can_be_summed"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.criterions.sentence_prediction.SentencePredictionCriterion.logging_outputs_can_be_summed"], ["", "", "@", "staticmethod", "\n", "def", "logging_outputs_can_be_summed", "(", "criterion", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Whether the logging outputs returned by `train_step` and `valid_step` can\n        be summed across workers prior to calling `aggregate_logging_outputs`.\n        Setting this to True will improves distributed training speed.\n        \"\"\"", "\n", "return", "criterion", ".", "logging_outputs_can_be_summed", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.__init__": [[45, 49], ["None"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "cfg", ":", "FairseqDataclass", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "datasets", "=", "{", "}", "\n", "self", ".", "dataset_to_epoch_iter", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.load_dictionary": [[50, 58], ["fairseq.data.Dictionary.load"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load"], ["", "@", "classmethod", "\n", "def", "load_dictionary", "(", "cls", ",", "filename", ")", ":", "\n", "        ", "\"\"\"Load the dictionary from the filename\n\n        Args:\n            filename (str): the filename\n        \"\"\"", "\n", "return", "Dictionary", ".", "load", "(", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.build_dictionary": [[59, 82], ["fairseq.data.Dictionary", "fairseq.data.Dictionary.finalize", "fairseq.data.Dictionary.add_file_to_dictionary"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDatasetBuilder.finalize", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_file_to_dictionary"], ["", "@", "classmethod", "\n", "def", "build_dictionary", "(", "\n", "cls", ",", "filenames", ",", "workers", "=", "1", ",", "threshold", "=", "-", "1", ",", "nwords", "=", "-", "1", ",", "padding_factor", "=", "8", "\n", ")", ":", "\n", "        ", "\"\"\"Build the dictionary\n\n        Args:\n            filenames (list): list of filenames\n            workers (int): number of concurrent workers\n            threshold (int): defines the minimum word count\n            nwords (int): defines the total number of words in the final dictionary,\n                including special symbols\n            padding_factor (int): can be used to pad the dictionary size to be a\n                multiple of 8, which is important on some hardware (e.g., Nvidia\n                Tensor Cores).\n        \"\"\"", "\n", "d", "=", "Dictionary", "(", ")", "\n", "for", "filename", "in", "filenames", ":", "\n", "            ", "Dictionary", ".", "add_file_to_dictionary", "(", "\n", "filename", ",", "d", ",", "tokenizer", ".", "tokenize_line", ",", "workers", "\n", ")", "\n", "", "d", ".", "finalize", "(", "threshold", "=", "threshold", ",", "nwords", "=", "nwords", ",", "padding_factor", "=", "padding_factor", ")", "\n", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.setup_task": [[83, 91], ["cls"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "cfg", ":", "DictConfig", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Setup the task (e.g., load dictionaries).\n\n        Args:\n            cfg (omegaconf.DictConfig): parsed command-line arguments\n        \"\"\"", "\n", "return", "cls", "(", "cfg", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.has_sharded_data": [[92, 94], ["getattr"], "methods", ["None"], ["", "def", "has_sharded_data", "(", "self", ",", "split", ")", ":", "\n", "        ", "return", "os", ".", "pathsep", "in", "getattr", "(", "self", ".", "cfg", ",", "\"data\"", ",", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.load_dataset": [[95, 111], ["None"], "methods", ["None"], ["", "def", "load_dataset", "(", "\n", "self", ",", "\n", "split", ":", "str", ",", "\n", "combine", ":", "bool", "=", "False", ",", "\n", "task_cfg", ":", "FairseqDataclass", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n            combine (bool): combines a split segmented into pieces into one dataset\n            task_cfg (FairseqDataclass): optional task configuration stored in the checkpoint that can be used\n                                         to load datasets\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.dataset": [[112, 129], ["KeyError", "isinstance", "TypeError"], "methods", ["None"], ["", "def", "dataset", "(", "self", ",", "split", ")", ":", "\n", "        ", "\"\"\"\n        Return a loaded dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n\n        Returns:\n            a :class:`~fairseq.data.FairseqDataset` corresponding to *split*\n        \"\"\"", "\n", "from", "fairseq", ".", "data", "import", "FairseqDataset", "\n", "\n", "if", "split", "not", "in", "self", ".", "datasets", ":", "\n", "            ", "raise", "KeyError", "(", "\"Dataset not loaded: \"", "+", "split", ")", "\n", "", "if", "not", "isinstance", "(", "self", ".", "datasets", "[", "split", "]", ",", "FairseqDataset", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Datasets are expected to be of type FairseqDataset\"", ")", "\n", "", "return", "self", ".", "datasets", "[", "split", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.filter_indices_by_size": [[130, 162], ["dataset.filter_indices_by_size", "len", "logger.warning", "Exception", "len", "dataset.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.filter_indices_by_size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "filter_indices_by_size", "(", "\n", "self", ",", "indices", ",", "dataset", ",", "max_positions", "=", "None", ",", "ignore_invalid_inputs", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Filter examples that are too large\n\n        Args:\n            indices (np.array): original array of sample indices\n            dataset (~fairseq.data.FairseqDataset): dataset to batch\n            max_positions (optional): max sentence length supported by the\n                model (default: None).\n            ignore_invalid_inputs (bool, optional): don't raise Exception for\n                sentences that are too long (default: False).\n        Returns:\n            np.array: array of filtered sample indices\n        \"\"\"", "\n", "indices", ",", "ignored", "=", "dataset", ".", "filter_indices_by_size", "(", "indices", ",", "max_positions", ")", "\n", "if", "len", "(", "ignored", ")", ">", "0", ":", "\n", "            ", "if", "not", "ignore_invalid_inputs", ":", "\n", "                ", "raise", "Exception", "(", "\n", "(", "\n", "\"Size of sample #{} is invalid (={}) since max_positions={}, \"", "\n", "\"skip this example with --skip-invalid-size-inputs-valid-test\"", "\n", ")", ".", "format", "(", "ignored", "[", "0", "]", ",", "dataset", ".", "size", "(", "ignored", "[", "0", "]", ")", ",", "max_positions", ")", "\n", ")", "\n", "", "logger", ".", "warning", "(", "\n", "(", "\n", "\"{} samples have invalid sizes and will be skipped, \"", "\n", "\"max_positions={}, first few sample ids={}\"", "\n", ")", ".", "format", "(", "len", "(", "ignored", ")", ",", "max_positions", ",", "ignored", "[", ":", "10", "]", ")", "\n", ")", "\n", "", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.can_reuse_epoch_itr": [[163, 169], ["getattr"], "methods", ["None"], ["", "def", "can_reuse_epoch_itr", "(", "self", ",", "dataset", ")", ":", "\n", "# We can reuse the epoch iterator across epochs as long as the dataset", "\n", "# hasn't disabled it. We default to ``False`` here, although in practice", "\n", "# this will be ``True`` for most datasets that inherit from", "\n", "# ``FairseqDataset`` due to the base implementation there.", "\n", "        ", "return", "getattr", "(", "dataset", ",", "\"can_reuse_epoch_itr_across_epochs\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.get_batch_iterator": [[170, 268], ["isinstance", "dataset.set_epoch", "dataset.batch_by_size", "fairseq.data.iterators.EpochBatchIterator", "fairseq_task.FairseqTask.can_reuse_epoch_itr", "logger.debug", "fairseq.data.data_utils.numpy_seed", "dataset.ordered_indices", "fairseq_task.FairseqTask.filter_indices_by_size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch", "home.repos.pwc.inspect_result.reneeye_const.data.base_wrapper_dataset.BaseWrapperDataset.batch_by_size", "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.can_reuse_epoch_itr", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.numpy_seed", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.ordered_indices", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.filter_indices_by_size"], ["", "def", "get_batch_iterator", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "max_tokens", "=", "None", ",", "\n", "max_sentences", "=", "None", ",", "\n", "max_positions", "=", "None", ",", "\n", "ignore_invalid_inputs", "=", "False", ",", "\n", "required_batch_size_multiple", "=", "1", ",", "\n", "seed", "=", "1", ",", "\n", "num_shards", "=", "1", ",", "\n", "shard_id", "=", "0", ",", "\n", "num_workers", "=", "0", ",", "\n", "epoch", "=", "1", ",", "\n", "data_buffer_size", "=", "0", ",", "\n", "disable_iterator_cache", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Get an iterator that yields batches of data from the given dataset.\n\n        Args:\n            dataset (~fairseq.data.FairseqDataset): dataset to batch\n            max_tokens (int, optional): max number of tokens in each batch\n                (default: None).\n            max_sentences (int, optional): max number of sentences in each\n                batch (default: None).\n            max_positions (optional): max sentence length supported by the\n                model (default: None).\n            ignore_invalid_inputs (bool, optional): don't raise Exception for\n                sentences that are too long (default: False).\n            required_batch_size_multiple (int, optional): require batch size to\n                be a multiple of N (default: 1).\n            seed (int, optional): seed for random number generator for\n                reproducibility (default: 1).\n            num_shards (int, optional): shard the data iterator into N\n                shards (default: 1).\n            shard_id (int, optional): which shard of the data iterator to\n                return (default: 0).\n            num_workers (int, optional): how many subprocesses to use for data\n                loading. 0 means the data will be loaded in the main process\n                (default: 0).\n            epoch (int, optional): the epoch to start the iterator from\n                (default: 1).\n            data_buffer_size (int, optional): number of batches to\n                preload (default: 0).\n            disable_iterator_cache (bool, optional): don't cache the\n                EpochBatchIterator (ignores `FairseqTask::can_reuse_epoch_itr`)\n                (default: False).\n        Returns:\n            ~fairseq.iterators.EpochBatchIterator: a batched iterator over the\n                given dataset split\n        \"\"\"", "\n", "can_reuse_epoch_itr", "=", "not", "disable_iterator_cache", "and", "self", ".", "can_reuse_epoch_itr", "(", "\n", "dataset", "\n", ")", "\n", "if", "can_reuse_epoch_itr", "and", "dataset", "in", "self", ".", "dataset_to_epoch_iter", ":", "\n", "            ", "logger", ".", "debug", "(", "\"reusing EpochBatchIterator for epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "return", "self", ".", "dataset_to_epoch_iter", "[", "dataset", "]", "\n", "\n", "", "assert", "isinstance", "(", "dataset", ",", "FairseqDataset", ")", "\n", "\n", "# initialize the dataset with the correct starting epoch", "\n", "dataset", ".", "set_epoch", "(", "epoch", ")", "\n", "\n", "# get indices ordered by example size", "\n", "with", "data_utils", ".", "numpy_seed", "(", "seed", ")", ":", "\n", "            ", "indices", "=", "dataset", ".", "ordered_indices", "(", ")", "\n", "\n", "# filter examples that are too large", "\n", "", "if", "max_positions", "is", "not", "None", ":", "\n", "            ", "indices", "=", "self", ".", "filter_indices_by_size", "(", "\n", "indices", ",", "dataset", ",", "max_positions", ",", "ignore_invalid_inputs", "\n", ")", "\n", "\n", "# create mini-batches with given size constraints", "\n", "", "batch_sampler", "=", "dataset", ".", "batch_by_size", "(", "\n", "indices", ",", "\n", "max_tokens", "=", "max_tokens", ",", "\n", "max_sentences", "=", "max_sentences", ",", "\n", "required_batch_size_multiple", "=", "required_batch_size_multiple", ",", "\n", ")", "\n", "\n", "# return a reusable, sharded iterator", "\n", "epoch_iter", "=", "iterators", ".", "EpochBatchIterator", "(", "\n", "dataset", "=", "dataset", ",", "\n", "collate_fn", "=", "dataset", ".", "collater", ",", "\n", "batch_sampler", "=", "batch_sampler", ",", "\n", "seed", "=", "seed", ",", "\n", "num_shards", "=", "num_shards", ",", "\n", "shard_id", "=", "shard_id", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "epoch", "=", "epoch", ",", "\n", "buffer_size", "=", "data_buffer_size", ",", "\n", ")", "\n", "\n", "if", "can_reuse_epoch_itr", ":", "\n", "            ", "self", ".", "dataset_to_epoch_iter", "[", "dataset", "]", "=", "epoch_iter", "\n", "\n", "", "return", "epoch_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.build_model": [[269, 287], ["models.build_model", "getattr", "quantization_utils.quantize_model_scalar", "quantization_utils.quantize_model_scalar.prepare_for_tpu_"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model", "home.repos.pwc.inspect_result.reneeye_const.fairseq.quantization_utils.quantize_model_scalar", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.prepare_for_tpu_"], ["", "def", "build_model", "(", "self", ",", "cfg", ":", "FairseqDataclass", ")", ":", "\n", "        ", "\"\"\"\n        Build the :class:`~fairseq.models.BaseFairseqModel` instance for this\n        task.\n\n        Args:\n            cfg (FairseqDataclass): configuration object\n\n        Returns:\n            a :class:`~fairseq.models.BaseFairseqModel` instance\n        \"\"\"", "\n", "from", "fairseq", "import", "models", ",", "quantization_utils", "\n", "\n", "model", "=", "models", ".", "build_model", "(", "cfg", ",", "self", ")", "\n", "if", "getattr", "(", "cfg", ",", "\"tpu\"", ",", "False", ")", ":", "\n", "            ", "model", ".", "prepare_for_tpu_", "(", ")", "\n", "", "model", "=", "quantization_utils", ".", "quantize_model_scalar", "(", "model", ",", "cfg", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.build_criterion": [[288, 302], ["criterions.build_criterion"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.criterions.composite_loss.CompositeLoss.build_criterion"], ["", "def", "build_criterion", "(", "self", ",", "cfg", ":", "DictConfig", ")", ":", "\n", "        ", "\"\"\"\n        Build the :class:`~fairseq.criterions.FairseqCriterion` instance for\n        this task.\n\n        Args:\n            cfg (omegaconf.DictConfig): configration object\n\n        Returns:\n            a :class:`~fairseq.criterions.FairseqCriterion` instance\n        \"\"\"", "\n", "from", "fairseq", "import", "criterions", "\n", "\n", "return", "criterions", ".", "build_criterion", "(", "cfg", ",", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.build_generator": [[303, 400], ["getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "seq_gen_cls", "SequenceScorer", "sum", "ValueError", "fairseq.search.Sampling", "getattr", "fairseq.search.DiverseBeamSearch", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "int", "fairseq.search.LengthConstrainedBeamSearch", "getattr", "fairseq.search.DiverseSiblingsSearch", "fairseq.search.LexicallyConstrainedBeamSearch", "fairseq.search.PrefixConstrainedBeamSearch", "fairseq.search.BeamSearch"], "methods", ["None"], ["", "def", "build_generator", "(", "\n", "self", ",", "models", ",", "args", ",", "seq_gen_cls", "=", "None", ",", "extra_gen_cls_kwargs", "=", "None", "\n", ")", ":", "\n", "        ", "if", "getattr", "(", "args", ",", "\"score_reference\"", ",", "False", ")", ":", "\n", "            ", "from", "fairseq", ".", "sequence_scorer", "import", "SequenceScorer", "\n", "\n", "return", "SequenceScorer", "(", "\n", "self", ".", "target_dictionary", ",", "\n", "compute_alignment", "=", "getattr", "(", "args", ",", "\"print_alignment\"", ",", "False", ")", ",", "\n", ")", "\n", "\n", "", "from", "fairseq", ".", "sequence_generator", "import", "(", "\n", "SequenceGenerator", ",", "\n", "SequenceGeneratorWithAlignment", ",", "\n", ")", "\n", "\n", "# Choose search strategy. Defaults to Beam Search.", "\n", "sampling", "=", "getattr", "(", "args", ",", "\"sampling\"", ",", "False", ")", "\n", "sampling_topk", "=", "getattr", "(", "args", ",", "\"sampling_topk\"", ",", "-", "1", ")", "\n", "sampling_topp", "=", "getattr", "(", "args", ",", "\"sampling_topp\"", ",", "-", "1.0", ")", "\n", "diverse_beam_groups", "=", "getattr", "(", "args", ",", "\"diverse_beam_groups\"", ",", "-", "1", ")", "\n", "diverse_beam_strength", "=", "getattr", "(", "args", ",", "\"diverse_beam_strength\"", ",", "0.5", ")", "\n", "match_source_len", "=", "getattr", "(", "args", ",", "\"match_source_len\"", ",", "False", ")", "\n", "diversity_rate", "=", "getattr", "(", "args", ",", "\"diversity_rate\"", ",", "-", "1", ")", "\n", "constrained", "=", "getattr", "(", "args", ",", "\"constraints\"", ",", "False", ")", "\n", "prefix_allowed_tokens_fn", "=", "getattr", "(", "args", ",", "\"prefix_allowed_tokens_fn\"", ",", "None", ")", "\n", "if", "(", "\n", "sum", "(", "\n", "int", "(", "cond", ")", "\n", "for", "cond", "in", "[", "\n", "sampling", ",", "\n", "diverse_beam_groups", ">", "0", ",", "\n", "match_source_len", ",", "\n", "diversity_rate", ">", "0", ",", "\n", "]", "\n", ")", "\n", ">", "1", "\n", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Provided Search parameters are mutually exclusive.\"", ")", "\n", "", "assert", "sampling_topk", "<", "0", "or", "sampling", ",", "\"--sampling-topk requires --sampling\"", "\n", "assert", "sampling_topp", "<", "0", "or", "sampling", ",", "\"--sampling-topp requires --sampling\"", "\n", "\n", "if", "sampling", ":", "\n", "            ", "search_strategy", "=", "search", ".", "Sampling", "(", "\n", "self", ".", "target_dictionary", ",", "sampling_topk", ",", "sampling_topp", "\n", ")", "\n", "", "elif", "diverse_beam_groups", ">", "0", ":", "\n", "            ", "search_strategy", "=", "search", ".", "DiverseBeamSearch", "(", "\n", "self", ".", "target_dictionary", ",", "diverse_beam_groups", ",", "diverse_beam_strength", "\n", ")", "\n", "", "elif", "match_source_len", ":", "\n", "# this is useful for tagging applications where the output", "\n", "# length should match the input length, so we hardcode the", "\n", "# length constraints for simplicity", "\n", "            ", "search_strategy", "=", "search", ".", "LengthConstrainedBeamSearch", "(", "\n", "self", ".", "target_dictionary", ",", "\n", "min_len_a", "=", "1", ",", "\n", "min_len_b", "=", "0", ",", "\n", "max_len_a", "=", "1", ",", "\n", "max_len_b", "=", "0", ",", "\n", ")", "\n", "", "elif", "diversity_rate", ">", "-", "1", ":", "\n", "            ", "search_strategy", "=", "search", ".", "DiverseSiblingsSearch", "(", "\n", "self", ".", "target_dictionary", ",", "diversity_rate", "\n", ")", "\n", "", "elif", "constrained", ":", "\n", "            ", "search_strategy", "=", "search", ".", "LexicallyConstrainedBeamSearch", "(", "\n", "self", ".", "target_dictionary", ",", "args", ".", "constraints", "\n", ")", "\n", "", "elif", "prefix_allowed_tokens_fn", ":", "\n", "            ", "search_strategy", "=", "search", ".", "PrefixConstrainedBeamSearch", "(", "\n", "self", ".", "target_dictionary", ",", "prefix_allowed_tokens_fn", "\n", ")", "\n", "", "else", ":", "\n", "            ", "search_strategy", "=", "search", ".", "BeamSearch", "(", "self", ".", "target_dictionary", ")", "\n", "\n", "", "if", "seq_gen_cls", "is", "None", ":", "\n", "            ", "if", "getattr", "(", "args", ",", "\"print_alignment\"", ",", "False", ")", ":", "\n", "                ", "seq_gen_cls", "=", "SequenceGeneratorWithAlignment", "\n", "", "else", ":", "\n", "                ", "seq_gen_cls", "=", "SequenceGenerator", "\n", "", "", "extra_gen_cls_kwargs", "=", "extra_gen_cls_kwargs", "or", "{", "}", "\n", "return", "seq_gen_cls", "(", "\n", "models", ",", "\n", "self", ".", "target_dictionary", ",", "\n", "beam_size", "=", "getattr", "(", "args", ",", "\"beam\"", ",", "5", ")", ",", "\n", "max_len_a", "=", "getattr", "(", "args", ",", "\"max_len_a\"", ",", "0", ")", ",", "\n", "max_len_b", "=", "getattr", "(", "args", ",", "\"max_len_b\"", ",", "200", ")", ",", "\n", "min_len", "=", "getattr", "(", "args", ",", "\"min_len\"", ",", "1", ")", ",", "\n", "normalize_scores", "=", "(", "not", "getattr", "(", "args", ",", "\"unnormalized\"", ",", "False", ")", ")", ",", "\n", "len_penalty", "=", "getattr", "(", "args", ",", "\"lenpen\"", ",", "1", ")", ",", "\n", "unk_penalty", "=", "getattr", "(", "args", ",", "\"unkpen\"", ",", "0", ")", ",", "\n", "temperature", "=", "getattr", "(", "args", ",", "\"temperature\"", ",", "1.0", ")", ",", "\n", "match_source_len", "=", "getattr", "(", "args", ",", "\"match_source_len\"", ",", "False", ")", ",", "\n", "no_repeat_ngram_size", "=", "getattr", "(", "args", ",", "\"no_repeat_ngram_size\"", ",", "0", ")", ",", "\n", "search_strategy", "=", "search_strategy", ",", "\n", "**", "extra_gen_cls_kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.train_step": [[402, 434], ["model.train", "model.set_num_updates", "torch.autograd.profiler.record_function", "criterion", "torch.autograd.profiler.record_function", "optimizer.backward"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq_cli.train.train", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.Wav2VecEncoder.set_num_updates", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.criterion", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.dynamicconvFunction.backward"], ["", "def", "train_step", "(", "\n", "self", ",", "sample", ",", "model", ",", "criterion", ",", "optimizer", ",", "update_num", ",", "ignore_grad", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Do forward and backward, and return the loss as computed by *criterion*\n        for the given *model* and *sample*.\n\n        Args:\n            sample (dict): the mini-batch. The format is defined by the\n                :class:`~fairseq.data.FairseqDataset`.\n            model (~fairseq.models.BaseFairseqModel): the model\n            criterion (~fairseq.criterions.FairseqCriterion): the criterion\n            optimizer (~fairseq.optim.FairseqOptimizer): the optimizer\n            update_num (int): the current update\n            ignore_grad (bool): multiply loss by 0 if this is set to True\n\n        Returns:\n            tuple:\n                - the loss\n                - the sample size, which is used as the denominator for the\n                  gradient\n                - logging outputs to display while training\n        \"\"\"", "\n", "model", ".", "train", "(", ")", "\n", "model", ".", "set_num_updates", "(", "update_num", ")", "\n", "with", "torch", ".", "autograd", ".", "profiler", ".", "record_function", "(", "\"forward\"", ")", ":", "\n", "            ", "loss", ",", "sample_size", ",", "logging_output", "=", "criterion", "(", "model", ",", "sample", ")", "\n", "", "if", "ignore_grad", ":", "\n", "            ", "loss", "*=", "0", "\n", "", "with", "torch", ".", "autograd", ".", "profiler", ".", "record_function", "(", "\"backward\"", ")", ":", "\n", "            ", "optimizer", ".", "backward", "(", "loss", ")", "\n", "", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.valid_step": [[435, 440], ["model.eval", "torch.no_grad", "criterion"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.criterion"], ["", "def", "valid_step", "(", "self", ",", "sample", ",", "model", ",", "criterion", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "loss", ",", "sample_size", ",", "logging_output", "=", "criterion", "(", "model", ",", "sample", ")", "\n", "", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.build_dataset_for_inference": [[441, 445], ["None"], "methods", ["None"], ["", "def", "build_dataset_for_inference", "(", "\n", "self", ",", "src_tokens", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "src_lengths", ":", "List", "[", "int", "]", ",", "**", "kwargs", "\n", ")", "->", "torch", ".", "utils", ".", "data", ".", "Dataset", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.inference_step": [[446, 452], ["torch.no_grad", "generator.generate"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.generate"], ["", "def", "inference_step", "(", "\n", "self", ",", "generator", ",", "models", ",", "sample", ",", "prefix_tokens", "=", "None", ",", "constraints", "=", "None", "\n", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "generator", ".", "generate", "(", "\n", "models", ",", "sample", ",", "prefix_tokens", "=", "prefix_tokens", ",", "constraints", "=", "constraints", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.begin_epoch": [[454, 457], ["None"], "methods", ["None"], ["", "", "def", "begin_epoch", "(", "self", ",", "epoch", ",", "model", ")", ":", "\n", "        ", "\"\"\"Hook function called before the start of each epoch.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.begin_valid_epoch": [[458, 461], ["None"], "methods", ["None"], ["", "def", "begin_valid_epoch", "(", "self", ",", "epoch", ",", "model", ")", ":", "\n", "        ", "\"\"\"Hook function called before the start of each validation epoch.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.aggregate_logging_outputs": [[462, 471], ["fairseq.utils.deprecation_warning", "fairseq.metrics.aggregate", "fairseq_task.FairseqTask.reduce_metrics", "agg.get_smoothed_values"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.deprecation_warning", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.aggregate", "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.reduce_metrics", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.MetersDict.get_smoothed_values"], ["", "def", "aggregate_logging_outputs", "(", "self", ",", "logging_outputs", ",", "criterion", ")", ":", "\n", "        ", "\"\"\"[deprecated] Aggregate logging outputs from data parallel training.\"\"\"", "\n", "utils", ".", "deprecation_warning", "(", "\n", "\"The aggregate_logging_outputs API is deprecated. \"", "\n", "\"Please use the reduce_metrics API instead.\"", "\n", ")", "\n", "with", "metrics", ".", "aggregate", "(", ")", "as", "agg", ":", "\n", "            ", "self", ".", "reduce_metrics", "(", "logging_outputs", ",", "criterion", ")", "\n", "return", "agg", ".", "get_smoothed_values", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.reduce_metrics": [[472, 507], ["criterion.__class__.reduce_metrics", "getattr", "fairseq.utils.deprecation_warning", "fairseq_task.FairseqTask.aggregate_logging_outputs", "fairseq_task.FairseqTask.items", "any", "warnings.warn", "sum", "fairseq.metrics.log_scalar", "fairseq.metrics.log_speed", "any", "warnings.warn", "sum", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "log.get", "log.get"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.reduce_metrics", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.deprecation_warning", "home.repos.pwc.inspect_result.reneeye_const.criterions.fairseq_criterion.FairseqCriterion.aggregate_logging_outputs", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_speed", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar"], ["", "", "def", "reduce_metrics", "(", "self", ",", "logging_outputs", ",", "criterion", ")", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "# backward compatibility for tasks that override aggregate_logging_outputs", "\n", "base_func", "=", "FairseqTask", ".", "aggregate_logging_outputs", "\n", "self_func", "=", "getattr", "(", "self", ",", "\"aggregate_logging_outputs\"", ")", ".", "__func__", "\n", "if", "self_func", "is", "not", "base_func", ":", "\n", "            ", "utils", ".", "deprecation_warning", "(", "\n", "\"Tasks should implement the reduce_metrics API. \"", "\n", "\"Falling back to deprecated aggregate_logging_outputs API.\"", "\n", ")", "\n", "agg_logging_outputs", "=", "self", ".", "aggregate_logging_outputs", "(", "\n", "logging_outputs", ",", "criterion", "\n", ")", "\n", "for", "k", ",", "v", "in", "agg_logging_outputs", ".", "items", "(", ")", ":", "\n", "                ", "metrics", ".", "log_scalar", "(", "k", ",", "v", ")", "\n", "", "return", "\n", "\n", "", "if", "not", "any", "(", "\"ntokens\"", "in", "log", "for", "log", "in", "logging_outputs", ")", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"ntokens not found in Criterion logging outputs, cannot log wpb or wps\"", "\n", ")", "\n", "", "else", ":", "\n", "            ", "ntokens", "=", "sum", "(", "log", ".", "get", "(", "\"ntokens\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"wpb\"", ",", "ntokens", ",", "priority", "=", "180", ",", "round", "=", "1", ")", "\n", "metrics", ".", "log_speed", "(", "\"wps\"", ",", "ntokens", ",", "priority", "=", "90", ",", "round", "=", "1", ")", "\n", "\n", "", "if", "not", "any", "(", "\"nsentences\"", "in", "log", "for", "log", "in", "logging_outputs", ")", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"nsentences not found in Criterion logging outputs, cannot log bsz\"", "\n", ")", "\n", "", "else", ":", "\n", "            ", "nsentences", "=", "sum", "(", "log", ".", "get", "(", "\"nsentences\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"bsz\"", ",", "nsentences", ",", "priority", "=", "190", ",", "round", "=", "1", ")", "\n", "\n", "", "criterion", ".", "__class__", ".", "reduce_metrics", "(", "logging_outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.max_positions": [[508, 511], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the max input length allowed by the task.\"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.source_dictionary": [[512, 517], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the source :class:`~fairseq.data.Dictionary` (if applicable\n        for this task).\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.target_dictionary": [[518, 523], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the target :class:`~fairseq.data.Dictionary` (if applicable\n        for this task).\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.build_tokenizer": [[524, 527], ["fairseq.data.encoders.build_tokenizer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.build_tokenizer"], ["", "def", "build_tokenizer", "(", "self", ",", "args", ")", ":", "\n", "        ", "\"\"\"Build the pre-tokenizer for this task.\"\"\"", "\n", "return", "encoders", ".", "build_tokenizer", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.FairseqTask.build_bpe": [[528, 531], ["fairseq.data.encoders.build_bpe"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.build_bpe"], ["", "def", "build_bpe", "(", "self", ",", "args", ")", ":", "\n", "        ", "\"\"\"Build the tokenizer for this task.\"\"\"", "\n", "return", "encoders", ".", "build_bpe", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.LegacyFairseqTask.__init__": [[534, 538], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ":", "Namespace", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "datasets", "=", "{", "}", "\n", "self", ".", "dataset_to_epoch_iter", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.LegacyFairseqTask.setup_task": [[539, 547], ["cls"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ":", "Namespace", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Setup the task (e.g., load dictionaries).\n\n        Args:\n            args (argparse.Namespace): parsed command-line arguments\n        \"\"\"", "\n", "return", "cls", "(", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.LegacyFairseqTask.has_sharded_data": [[548, 550], ["getattr"], "methods", ["None"], ["", "def", "has_sharded_data", "(", "self", ",", "split", ")", ":", "\n", "        ", "return", "os", ".", "pathsep", "in", "getattr", "(", "self", ".", "args", ",", "\"data\"", ",", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.LegacyFairseqTask.build_model": [[551, 569], ["models.build_model", "getattr", "quantization_utils.quantize_model_scalar", "quantization_utils.quantize_model_scalar.prepare_for_tpu_"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model", "home.repos.pwc.inspect_result.reneeye_const.fairseq.quantization_utils.quantize_model_scalar", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.prepare_for_tpu_"], ["", "def", "build_model", "(", "self", ",", "args", ":", "Namespace", ")", ":", "\n", "        ", "\"\"\"\n        Build the :class:`~fairseq.models.BaseFairseqModel` instance for this\n        task.\n\n        Args:\n            args (argparse.Namespace): parsed command-line arguments\n\n        Returns:\n            a :class:`~fairseq.models.BaseFairseqModel` instance\n        \"\"\"", "\n", "from", "fairseq", "import", "models", ",", "quantization_utils", "\n", "\n", "model", "=", "models", ".", "build_model", "(", "args", ",", "self", ")", "\n", "if", "getattr", "(", "args", ",", "\"tpu\"", ",", "False", ")", ":", "\n", "            ", "model", ".", "prepare_for_tpu_", "(", ")", "\n", "", "model", "=", "quantization_utils", ".", "quantize_model_scalar", "(", "model", ",", "args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.fairseq_task.LegacyFairseqTask.build_criterion": [[570, 584], ["criterions.build_criterion"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.criterions.composite_loss.CompositeLoss.build_criterion"], ["", "def", "build_criterion", "(", "self", ",", "args", ":", "Namespace", ")", ":", "\n", "        ", "\"\"\"\n        Build the :class:`~fairseq.criterions.FairseqCriterion` instance for\n        this task.\n\n        Args:\n            args (argparse.Namespace): parsed command-line arguments\n\n        Returns:\n            a :class:`~fairseq.criterions.FairseqCriterion` instance\n        \"\"\"", "\n", "from", "fairseq", "import", "criterions", "\n", "\n", "return", "criterions", ".", "build_criterion", "(", "args", ",", "self", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.tasks.language_modeling.LanguageModelingTask.__init__": [[125, 133], ["fairseq.tasks.LegacyFairseqTask.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "args", ",", "dictionary", ",", "output_dictionary", "=", "None", ",", "targets", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "self", ".", "output_dictionary", "=", "output_dictionary", "or", "dictionary", "\n", "\n", "if", "targets", "is", "None", ":", "\n", "            ", "targets", "=", "[", "\"future\"", "]", "\n", "", "self", ".", "targets", "=", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.language_modeling.LanguageModelingTask.setup_dictionary": [[134, 149], ["fairseq.utils.split_paths", "fairseq.data.Dictionary.load", "logger.info", "len", "os.path.join", "fairseq.data.TruncatedDictionary", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load"], ["", "@", "classmethod", "\n", "def", "setup_dictionary", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "dictionary", "=", "None", "\n", "output_dictionary", "=", "None", "\n", "if", "args", ".", "data", ":", "\n", "            ", "paths", "=", "utils", ".", "split_paths", "(", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "dictionary", "=", "Dictionary", ".", "load", "(", "os", ".", "path", ".", "join", "(", "paths", "[", "0", "]", ",", "\"dict.txt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"dictionary: {} types\"", ".", "format", "(", "len", "(", "dictionary", ")", ")", ")", "\n", "output_dictionary", "=", "dictionary", "\n", "if", "args", ".", "output_dictionary_size", ">=", "0", ":", "\n", "                ", "output_dictionary", "=", "TruncatedDictionary", "(", "\n", "dictionary", ",", "args", ".", "output_dictionary_size", "\n", ")", "\n", "", "", "return", "(", "dictionary", ",", "output_dictionary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.language_modeling.LanguageModelingTask.setup_task": [[150, 175], ["cls.setup_dictionary", "getattr", "getattr", "getattr", "getattr", "cls", "targets.append", "targets.append", "targets.append", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.language_modeling.LanguageModelingTask.setup_dictionary", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Setup the task (e.g., load dictionaries).\n\n        Args:\n            args (argparse.Namespace): parsed command-line arguments\n        \"\"\"", "\n", "dictionary", ",", "output_dictionary", "=", "cls", ".", "setup_dictionary", "(", "args", ",", "**", "kwargs", ")", "\n", "\n", "# upgrade old checkpoints", "\n", "if", "getattr", "(", "args", ",", "\"exclude_self_target\"", ",", "False", ")", ":", "\n", "            ", "args", ".", "self_target", "=", "False", "\n", "\n", "", "targets", "=", "[", "]", "\n", "if", "getattr", "(", "args", ",", "\"self_target\"", ",", "False", ")", ":", "\n", "            ", "targets", ".", "append", "(", "\"self\"", ")", "\n", "", "if", "getattr", "(", "args", ",", "\"future_target\"", ",", "False", ")", ":", "\n", "            ", "targets", ".", "append", "(", "\"future\"", ")", "\n", "", "if", "getattr", "(", "args", ",", "\"past_target\"", ",", "False", ")", ":", "\n", "            ", "targets", ".", "append", "(", "\"past\"", ")", "\n", "", "if", "len", "(", "targets", ")", "==", "0", ":", "\n", "# standard language modeling", "\n", "            ", "targets", "=", "[", "\"future\"", "]", "\n", "\n", "", "return", "cls", "(", "args", ",", "dictionary", ",", "output_dictionary", ",", "targets", "=", "targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.language_modeling.LanguageModelingTask.build_model": [[176, 185], ["super().build_model", "ValueError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model"], ["", "def", "build_model", "(", "self", ",", "args", ")", ":", "\n", "        ", "model", "=", "super", "(", ")", ".", "build_model", "(", "args", ")", "\n", "for", "target", "in", "self", ".", "targets", ":", "\n", "            ", "if", "target", "not", "in", "model", ".", "supported_targets", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Unsupported language modeling target: {}\"", ".", "format", "(", "target", ")", "\n", ")", "\n", "\n", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.language_modeling.LanguageModelingTask.load_dataset": [[186, 239], ["fairseq.utils.split_paths", "os.path.join", "fairseq.data.data_utils.load_indexed_dataset", "fairseq.data.shorten_dataset.maybe_shorten_dataset", "fairseq.data.TokenBlockDataset", "language_modeling.LanguageModelingTask._initialize_dataset", "len", "FileNotFoundError", "language_modeling.LanguageModelingTask.dictionary.pad", "language_modeling.LanguageModelingTask.dictionary.eos", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.load_indexed_dataset", "home.repos.pwc.inspect_result.reneeye_const.data.shorten_dataset.maybe_shorten_dataset", "home.repos.pwc.inspect_result.reneeye_const.tasks.language_modeling.LanguageModelingTask._initialize_dataset", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "1", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n        \"\"\"", "\n", "paths", "=", "utils", ".", "split_paths", "(", "self", ".", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "\n", "data_path", "=", "paths", "[", "(", "epoch", "-", "1", ")", "%", "len", "(", "paths", ")", "]", "\n", "split_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "split", ")", "\n", "\n", "dataset", "=", "data_utils", ".", "load_indexed_dataset", "(", "\n", "split_path", ",", "self", ".", "dictionary", ",", "self", ".", "args", ".", "dataset_impl", ",", "combine", "=", "combine", "\n", ")", "\n", "if", "dataset", "is", "None", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "\n", "\"Dataset not found: {} ({})\"", ".", "format", "(", "split", ",", "split_path", ")", "\n", ")", "\n", "\n", "", "dataset", "=", "maybe_shorten_dataset", "(", "\n", "dataset", ",", "\n", "split", ",", "\n", "self", ".", "args", ".", "shorten_data_split_list", ",", "\n", "self", ".", "args", ".", "shorten_method", ",", "\n", "self", ".", "args", ".", "tokens_per_sample", ",", "\n", "self", ".", "args", ".", "seed", ",", "\n", ")", "\n", "\n", "dataset", "=", "TokenBlockDataset", "(", "\n", "dataset", ",", "\n", "dataset", ".", "sizes", ",", "\n", "self", ".", "args", ".", "tokens_per_sample", ",", "\n", "pad", "=", "self", ".", "dictionary", ".", "pad", "(", ")", ",", "\n", "eos", "=", "self", ".", "dictionary", ".", "eos", "(", ")", ",", "\n", "break_mode", "=", "self", ".", "args", ".", "sample_break_mode", ",", "\n", "include_targets", "=", "True", ",", "\n", ")", "\n", "\n", "add_eos_for_other_targets", "=", "(", "\n", "self", ".", "args", ".", "sample_break_mode", "is", "not", "None", "\n", "and", "self", ".", "args", ".", "sample_break_mode", "!=", "\"none\"", "\n", ")", "\n", "\n", "self", ".", "datasets", "[", "split", "]", "=", "self", ".", "_initialize_dataset", "(", "\n", "dataset", "=", "dataset", ",", "\n", "sizes", "=", "dataset", ".", "sizes", ",", "\n", "src_vocab", "=", "self", ".", "dictionary", ",", "\n", "tgt_vocab", "=", "self", ".", "output_dictionary", ",", "\n", "add_eos_for_other_targets", "=", "add_eos_for_other_targets", ",", "\n", "shuffle", "=", "True", ",", "\n", "targets", "=", "self", ".", "targets", ",", "\n", "add_bos_token", "=", "self", ".", "args", ".", "add_bos_token", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.language_modeling.LanguageModelingTask._initialize_dataset": [[241, 243], ["fairseq.data.MonolingualDataset"], "methods", ["None"], ["", "def", "_initialize_dataset", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "MonolingualDataset", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.language_modeling.LanguageModelingTask.build_dataset_for_inference": [[244, 287], ["fairseq.data.StripTokenDataset", "fairseq.data.PrependTokenDataset", "fairseq.data.AppendTokenDataset", "fairseq.data.NestedDictionaryDataset", "fairseq.data.TokenBlockDataset", "language_modeling.LanguageModelingTask.source_dictionary.eos", "language_modeling.LanguageModelingTask.source_dictionary.pad", "fairseq.data.IdDataset", "fairseq.data.PadDataset", "language_modeling.LanguageModelingTask.source_dictionary.pad", "language_modeling.LanguageModelingTask.source_dictionary.eos", "getattr", "language_modeling.LanguageModelingTask.source_dictionary.bos", "language_modeling.LanguageModelingTask.source_dictionary.eos", "fairseq.data.PadDataset", "fairseq.data.NumelDataset", "numpy.array", "language_modeling.LanguageModelingTask.source_dictionary.pad", "language_modeling.LanguageModelingTask.source_dictionary.pad"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["", "def", "build_dataset_for_inference", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Generate batches for inference. We prepend an eos token to src_tokens\n        (or bos if `--add-bos-token` is set) and we append a <pad> to target.\n        This is convenient both for generation with a prefix and LM scoring.\n        \"\"\"", "\n", "dataset", "=", "StripTokenDataset", "(", "\n", "TokenBlockDataset", "(", "\n", "src_tokens", ",", "\n", "src_lengths", ",", "\n", "block_size", "=", "None", ",", "# ignored for \"eos\" break mode", "\n", "pad", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", "eos", "=", "self", ".", "source_dictionary", ".", "eos", "(", ")", ",", "\n", "break_mode", "=", "\"eos\"", ",", "\n", ")", ",", "\n", "# remove eos from (end of) target sequence", "\n", "self", ".", "source_dictionary", ".", "eos", "(", ")", ",", "\n", ")", "\n", "src_dataset", "=", "PrependTokenDataset", "(", "\n", "dataset", ",", "\n", "token", "=", "(", "\n", "self", ".", "source_dictionary", ".", "bos", "(", ")", "\n", "if", "getattr", "(", "self", ".", "args", ",", "\"add_bos_token\"", ",", "False", ")", "\n", "else", "self", ".", "source_dictionary", ".", "eos", "(", ")", "\n", ")", ",", "\n", ")", "\n", "tgt_dataset", "=", "AppendTokenDataset", "(", "dataset", ",", "token", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ")", "\n", "return", "NestedDictionaryDataset", "(", "\n", "{", "\n", "\"id\"", ":", "IdDataset", "(", ")", ",", "\n", "\"net_input\"", ":", "{", "\n", "\"src_tokens\"", ":", "PadDataset", "(", "\n", "src_dataset", ",", "\n", "pad_idx", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", "left_pad", "=", "False", ",", "\n", ")", ",", "\n", "\"src_lengths\"", ":", "NumelDataset", "(", "src_dataset", ",", "reduce", "=", "False", ")", ",", "\n", "}", ",", "\n", "\"target\"", ":", "PadDataset", "(", "\n", "tgt_dataset", ",", "pad_idx", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "left_pad", "=", "False", "\n", ")", ",", "\n", "}", ",", "\n", "sizes", "=", "[", "np", ".", "array", "(", "src_lengths", ")", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.language_modeling.LanguageModelingTask.inference_step": [[289, 313], ["torch.no_grad", "getattr", "generator.generate", "language_modeling.LanguageModelingTask.source_dictionary.bos", "language_modeling.LanguageModelingTask.source_dictionary.eos", "NotImplementedError", "[].nelement", "prefix_tokens[].eq().all", "prefix_tokens[].eq"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.generate", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "def", "inference_step", "(", "\n", "self", ",", "generator", ",", "models", ",", "sample", ",", "prefix_tokens", "=", "None", ",", "constraints", "=", "None", "\n", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Generation will always be conditioned on bos_token", "\n", "            ", "if", "getattr", "(", "self", ".", "args", ",", "\"add_bos_token\"", ",", "False", ")", ":", "\n", "                ", "bos_token", "=", "self", ".", "source_dictionary", ".", "bos", "(", ")", "\n", "", "else", ":", "\n", "                ", "bos_token", "=", "self", ".", "source_dictionary", ".", "eos", "(", ")", "\n", "\n", "", "if", "constraints", "is", "not", "None", ":", "\n", "                ", "raise", "NotImplementedError", "(", "\n", "\"Constrained decoding with the language_modeling task is not supported\"", "\n", ")", "\n", "\n", "# SequenceGenerator doesn't use src_tokens directly, we need to", "\n", "# pass the `prefix_tokens` argument instead", "\n", "", "if", "prefix_tokens", "is", "None", "and", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", ".", "nelement", "(", ")", ":", "\n", "                ", "prefix_tokens", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "\n", "if", "prefix_tokens", "[", ":", ",", "0", "]", ".", "eq", "(", "bos_token", ")", ".", "all", "(", ")", ":", "\n", "                    ", "prefix_tokens", "=", "prefix_tokens", "[", ":", ",", "1", ":", "]", "\n", "\n", "", "", "return", "generator", ".", "generate", "(", "\n", "models", ",", "sample", ",", "prefix_tokens", "=", "prefix_tokens", ",", "bos_token", "=", "bos_token", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.language_modeling.LanguageModelingTask.source_dictionary": [[315, 320], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the :class:`~fairseq.data.Dictionary` for the language\n        model.\"\"\"", "\n", "return", "self", ".", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.language_modeling.LanguageModelingTask.target_dictionary": [[321, 326], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the :class:`~fairseq.data.Dictionary` for the language\n        model.\"\"\"", "\n", "return", "self", ".", "output_dictionary", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_from_pretrained_xlm.TranslationFromPretrainedXLMTask.load_dictionary": [[24, 32], ["fairseq.data.legacy.masked_lm_dictionary.MaskedLMDictionary.load"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load"], ["@", "classmethod", "\n", "def", "load_dictionary", "(", "cls", ",", "filename", ")", ":", "\n", "        ", "\"\"\"Load the masked LM dictionary from the filename\n\n        Args:\n            filename (str): the filename\n        \"\"\"", "\n", "return", "MaskedLMDictionary", ".", "load", "(", "filename", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_from_pretrained_bart.TranslationFromPretrainedBARTTask.add_args": [[36, 49], ["translation.TranslationTask.add_args", "parser.add_argument", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args"], ["@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "TranslationTask", ".", "add_args", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "'--langs'", ",", "required", "=", "True", ",", "metavar", "=", "'LANG'", ",", "\n", "help", "=", "'comma-separated list of monolingual language, '", "\n", "'for example, \"en,de,fr\". These should match the '", "\n", "'langs from pretraining (and be in the same order). '", "\n", "'You should always add all pretraining language idx '", "\n", "'during finetuning.'", ")", "\n", "parser", ".", "add_argument", "(", "'--prepend-bos'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'prepend bos token to each sentence, which matches '", "\n", "'mBART pretraining'", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_from_pretrained_bart.TranslationFromPretrainedBARTTask.__init__": [[52, 59], ["translation.TranslationTask.__init__", "args.langs.split", "d.add_symbol", "d.add_symbol"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol"], ["", "def", "__init__", "(", "self", ",", "args", ",", "src_dict", ",", "tgt_dict", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "src_dict", ",", "tgt_dict", ")", "\n", "self", ".", "langs", "=", "args", ".", "langs", ".", "split", "(", "\",\"", ")", "\n", "for", "d", "in", "[", "src_dict", ",", "tgt_dict", "]", ":", "\n", "            ", "for", "l", "in", "self", ".", "langs", ":", "\n", "                ", "d", ".", "add_symbol", "(", "\"[{}]\"", ".", "format", "(", "l", ")", ")", "\n", "", "d", ".", "add_symbol", "(", "\"<mask>\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_from_pretrained_bart.TranslationFromPretrainedBARTTask.load_dataset": [[60, 90], ["fairseq.utils.split_paths", "translation.load_langpair_dataset", "len", "getattr", "getattr", "getattr", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_langpair_dataset"], ["", "", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "1", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n        \"\"\"", "\n", "paths", "=", "utils", ".", "split_paths", "(", "self", ".", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "data_path", "=", "paths", "[", "(", "epoch", "-", "1", ")", "%", "len", "(", "paths", ")", "]", "\n", "\n", "# infer langcode", "\n", "src", ",", "tgt", "=", "self", ".", "args", ".", "source_lang", ",", "self", ".", "args", ".", "target_lang", "\n", "\n", "self", ".", "datasets", "[", "split", "]", "=", "load_langpair_dataset", "(", "\n", "data_path", ",", "\n", "split", ",", "\n", "src", ",", "\n", "self", ".", "src_dict", ",", "\n", "tgt", ",", "\n", "self", ".", "tgt_dict", ",", "\n", "combine", "=", "combine", ",", "\n", "dataset_impl", "=", "self", ".", "args", ".", "dataset_impl", ",", "\n", "upsample_primary", "=", "self", ".", "args", ".", "upsample_primary", ",", "\n", "left_pad_source", "=", "self", ".", "args", ".", "left_pad_source", ",", "\n", "left_pad_target", "=", "self", ".", "args", ".", "left_pad_target", ",", "\n", "max_source_positions", "=", "getattr", "(", "self", ".", "args", ",", "\"max_source_positions\"", ",", "1024", ")", ",", "\n", "max_target_positions", "=", "getattr", "(", "self", ".", "args", ",", "\"max_target_positions\"", ",", "1024", ")", ",", "\n", "load_alignments", "=", "self", ".", "args", ".", "load_alignments", ",", "\n", "prepend_bos", "=", "getattr", "(", "self", ".", "args", ",", "\"prepend_bos\"", ",", "False", ")", ",", "\n", "append_source_id", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_from_pretrained_bart.TranslationFromPretrainedBARTTask.build_generator": [[92, 117], ["getattr", "SequenceScorer", "SequenceGenerator", "translation_from_pretrained_bart.TranslationFromPretrainedBARTTask.tgt_dict.index", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "translation_from_pretrained_bart.TranslationFromPretrainedBARTTask.tgt_dict.index", "getattr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.index", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.index"], ["", "def", "build_generator", "(", "self", ",", "models", ",", "args", ",", "**", "unused", ")", ":", "\n", "        ", "if", "getattr", "(", "args", ",", "\"score_reference\"", ",", "False", ")", ":", "\n", "            ", "from", "fairseq", ".", "sequence_scorer", "import", "SequenceScorer", "\n", "\n", "return", "SequenceScorer", "(", "\n", "self", ".", "target_dictionary", ",", "\n", "eos", "=", "self", ".", "tgt_dict", ".", "index", "(", "\"[{}]\"", ".", "format", "(", "self", ".", "args", ".", "target_lang", ")", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "from", "fairseq", ".", "sequence_generator", "import", "SequenceGenerator", "\n", "\n", "return", "SequenceGenerator", "(", "\n", "models", ",", "\n", "self", ".", "target_dictionary", ",", "\n", "beam_size", "=", "getattr", "(", "args", ",", "\"beam\"", ",", "5", ")", ",", "\n", "max_len_a", "=", "getattr", "(", "args", ",", "\"max_len_a\"", ",", "0", ")", ",", "\n", "max_len_b", "=", "getattr", "(", "args", ",", "\"max_len_b\"", ",", "200", ")", ",", "\n", "min_len", "=", "getattr", "(", "args", ",", "\"min_len\"", ",", "1", ")", ",", "\n", "normalize_scores", "=", "(", "not", "getattr", "(", "args", ",", "\"unnormalized\"", ",", "False", ")", ")", ",", "\n", "len_penalty", "=", "getattr", "(", "args", ",", "\"lenpen\"", ",", "1", ")", ",", "\n", "unk_penalty", "=", "getattr", "(", "args", ",", "\"unkpen\"", ",", "0", ")", ",", "\n", "temperature", "=", "getattr", "(", "args", ",", "\"temperature\"", ",", "1.0", ")", ",", "\n", "match_source_len", "=", "getattr", "(", "args", ",", "\"match_source_len\"", ",", "False", ")", ",", "\n", "no_repeat_ngram_size", "=", "getattr", "(", "args", ",", "\"no_repeat_ngram_size\"", ",", "0", ")", ",", "\n", "eos", "=", "self", ".", "tgt_dict", ".", "index", "(", "\"[{}]\"", ".", "format", "(", "self", ".", "args", ".", "target_lang", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_from_pretrained_bart.TranslationFromPretrainedBARTTask.build_dataset_for_inference": [[119, 133], ["translation_from_pretrained_bart.TranslationFromPretrainedBARTTask.source_dictionary.index", "fairseq.data.LanguagePairDataset", "torch.cat", "source_tokens.append", "torch.cat.new().fill_", "torch.cat.new"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.index"], ["", "", "def", "build_dataset_for_inference", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "constraints", "=", "None", ")", ":", "\n", "        ", "src_lang_id", "=", "self", ".", "source_dictionary", ".", "index", "(", "\"[{}]\"", ".", "format", "(", "self", ".", "args", ".", "source_lang", ")", ")", "\n", "source_tokens", "=", "[", "]", "\n", "for", "s_t", "in", "src_tokens", ":", "\n", "            ", "s_t", "=", "torch", ".", "cat", "(", "[", "s_t", ",", "s_t", ".", "new", "(", "1", ")", ".", "fill_", "(", "src_lang_id", ")", "]", ")", "\n", "source_tokens", ".", "append", "(", "s_t", ")", "\n", "", "dataset", "=", "LanguagePairDataset", "(", "\n", "source_tokens", ",", "\n", "src_lengths", ",", "\n", "self", ".", "source_dictionary", ",", "\n", "tgt_dict", "=", "self", ".", "target_dictionary", ",", "\n", "constraints", "=", "constraints", ",", "\n", ")", "\n", "return", "dataset", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.add_args": [[36, 84], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "\"data\"", ",", "help", "=", "\"manifest root path\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--config-yaml\"", ",", "type", "=", "str", ",", "default", "=", "\"config.yaml\"", ",", "\n", "help", "=", "\"Configuration YAML filename (absolute path)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max-audio-tokens\"", ",", "default", "=", "1000000", ",", "type", "=", "int", ",", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"max batch of tokens in audio sequences\"", ")", ",", "\n", "parser", ".", "add_argument", "(", "\"--max-text-tokens\"", ",", "default", "=", "4000", ",", "type", "=", "int", ",", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"max batch of tokens in text sequences\"", ")", ",", "\n", "parser", ".", "add_argument", "(", "\"--max-audio-positions\"", ",", "default", "=", "6000", ",", "type", "=", "int", ",", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"max number of tokens in the source audio sequence\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max-source-positions\"", ",", "default", "=", "1024", ",", "type", "=", "int", ",", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"max number of tokens in the source text sequence\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max-target-positions\"", ",", "default", "=", "1024", ",", "type", "=", "int", ",", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"max number of tokens in the target sequence\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--langpairs\"", ",", "default", "=", "None", ",", "metavar", "=", "\"S\"", ",", "\n", "help", "=", "'language pairs for text training, eg: `en-de`'", ")", "\n", "parser", ".", "add_argument", "(", "'--lang-prefix-tok'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"starting token in decoder, eg: `<lang:de>`\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--external-parallel-mt-data\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"path to the external parallel mt data, tsv file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--text-data-sample-ratio\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"define MT data sample ratio in one batch\"", ")", "\n", "\n", "# options for reporting BLEU during validation", "\n", "parser", ".", "add_argument", "(", "'--eval-bleu'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'evaluation with BLEU scores'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-bleu-detok'", ",", "type", "=", "str", ",", "default", "=", "\"space\"", ",", "\n", "help", "=", "'detokenize before computing BLEU (e.g., \"moses\"); '", "\n", "'required if using --eval-bleu; use \"space\" to '", "\n", "'disable detokenization; see fairseq.data.encoders '", "\n", "'for other options'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-bleu-detok-args'", ",", "type", "=", "str", ",", "metavar", "=", "'JSON'", ",", "\n", "help", "=", "'args for building the tokenizer, if needed'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-tokenized-bleu'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'compute tokenized BLEU instead of sacrebleu'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-bleu-remove-bpe'", ",", "nargs", "=", "'?'", ",", "const", "=", "'@@ '", ",", "default", "=", "None", ",", "\n", "help", "=", "'remove BPE before computing BLEU'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-bleu-args'", ",", "type", "=", "str", ",", "metavar", "=", "'JSON'", ",", "\n", "help", "=", "'generation args for BLUE scoring, '", "\n", "'e.g., \\'{\"beam\": 4, \"lenpen\": 0.6}\\''", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-bleu-print-samples'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'print sample generations during validation'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-bleu-bpe'", ",", "type", "=", "str", ",", "metavar", "=", "'BPE'", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "'args for building the bpe, if needed'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-bleu-bpe-path'", ",", "type", "=", "str", ",", "metavar", "=", "'BPE'", ",", "\n", "help", "=", "'args for building the bpe, if needed'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.__init__": [[85, 89], ["fairseq.tasks.LegacyFairseqTask.__init__", "fairseq.data.audio.speech_to_text_dataset.S2TDataConfig", "os.join"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["", "def", "__init__", "(", "self", ",", "args", ",", "tgt_dict", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "tgt_dict", "=", "tgt_dict", "\n", "self", ".", "data_cfg", "=", "S2TDataConfig", "(", "op", ".", "join", "(", "args", ".", "data", ",", "args", ".", "config_yaml", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.setup_task": [[90, 109], ["fairseq.data.audio.speech_to_text_dataset.S2TDataConfig", "os.join", "fairseq.data.Dictionary.load", "logger.info", "cls", "os.join", "os.isfile", "FileNotFoundError", "getattr", "Exception", "all", "ValueError", "os.isabs", "os.join", "len", "s.startswith", "args.train_subset.split"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.isfile"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "data_cfg", "=", "S2TDataConfig", "(", "op", ".", "join", "(", "args", ".", "data", ",", "args", ".", "config_yaml", ")", ")", "\n", "dict_path", "=", "op", ".", "join", "(", "args", ".", "data", ",", "data_cfg", ".", "vocab_filename", ")", "\n", "if", "not", "op", ".", "isfile", "(", "dict_path", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "f\"Dict not found: {dict_path}\"", ")", "\n", "", "tgt_dict", "=", "Dictionary", ".", "load", "(", "dict_path", ")", "\n", "logger", ".", "info", "(", "f\"dictionary size ({data_cfg.vocab_filename}): \"", "f\"{len(tgt_dict):,}\"", ")", "\n", "if", "getattr", "(", "args", ",", "\"train_subset\"", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "if", "not", "all", "(", "s", ".", "startswith", "(", "\"train\"", ")", "for", "s", "in", "args", ".", "train_subset", ".", "split", "(", "\",\"", ")", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'Train splits should be named like \"train*\".'", ")", "\n", "", "", "if", "args", ".", "external_parallel_mt_data", "is", "not", "None", ":", "\n", "            ", "if", "not", "op", ".", "isabs", "(", "args", ".", "external_parallel_mt_data", ")", ":", "\n", "                ", "args", ".", "external_parallel_mt_data", "=", "op", ".", "join", "(", "args", ".", "data", ",", "args", ".", "external_parallel_mt_data", ")", "\n", "", "", "if", "args", ".", "langpairs", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"Could not infer language pair, please provide it explicitly\"", "\n", ")", "\n", "", "return", "cls", "(", "args", ",", "tgt_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.build_criterion": [[110, 124], ["criterions.build_criterion", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.criterions.composite_loss.CompositeLoss.build_criterion"], ["", "def", "build_criterion", "(", "self", ",", "args", ")", ":", "\n", "        ", "from", "fairseq", "import", "criterions", "\n", "\n", "if", "self", ".", "data_cfg", ".", "prepend_tgt_lang_tag", "and", "args", ".", "ignore_prefix_size", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Please set \"--ignore-prefix-size 1\" since '", "\n", "\"target language ID token is prepended as BOS.\"", "\n", ")", "\n", "", "if", "self", ".", "data_cfg", ".", "prepend_src_lang_tag", "and", "args", ".", "ignore_prefix_size", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Please set \"--ignore-prefix-size 1\" since '", "\n", "\"source language ID token is prepended as BOS.\"", "\n", ")", "\n", "", "return", "criterions", ".", "build_criterion", "(", "args", ",", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.load_langpair_dataset": [[125, 147], ["speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.args.langpairs.split", "fairseq.tasks.translation.load_langpair_dataset"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_langpair_dataset"], ["", "def", "load_langpair_dataset", "(", "self", ")", ":", "\n", "        ", "split", "=", "\"train\"", "\n", "src", ",", "tgt", "=", "self", ".", "args", ".", "langpairs", ".", "split", "(", "\"-\"", ")", "\n", "text_dataset", "=", "load_langpair_dataset", "(", "\n", "self", ".", "args", ".", "external_parallel_mt_data", ",", "\n", "split", ",", "\n", "src", ",", "\n", "self", ".", "tgt_dict", ",", "\n", "tgt", ",", "\n", "self", ".", "tgt_dict", ",", "\n", "combine", "=", "False", ",", "\n", "dataset_impl", "=", "None", ",", "\n", "upsample_primary", "=", "1", ",", "\n", "left_pad_source", "=", "False", ",", "\n", "left_pad_target", "=", "False", ",", "\n", "max_source_positions", "=", "self", ".", "args", ".", "max_source_positions", ",", "\n", "max_target_positions", "=", "self", ".", "args", ".", "max_target_positions", ",", "\n", "load_alignments", "=", "False", ",", "\n", "truncate_source", "=", "False", ",", "\n", "shuffle", "=", "True", ",", "\n", ")", "\n", "return", "text_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.load_dataset": [[148, 186], ["split.startswith", "speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.build_tokenizer", "speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.build_bpe", "fairseq.data.audio.speech_text_triple_dataset.SpeechTextTripleDatasetCreator.from_tsv", "speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.load_langpair_dataset", "fairseq.data.multi_modality_dataset.MultiModalityDataset", "fairseq.data.multi_modality_dataset.ModalityDatasetItem", "fairseq.data.multi_modality_dataset.ModalityDatasetItem"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.build_tokenizer", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.build_bpe", "home.repos.pwc.inspect_result.reneeye_const.audio.speech_text_triple_dataset.SpeechTextTripleDatasetCreator.from_tsv", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_langpair_dataset"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "1", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "is_train_split", "=", "split", ".", "startswith", "(", "\"train\"", ")", "\n", "pre_tokenizer", "=", "self", ".", "build_tokenizer", "(", "self", ".", "args", ")", "\n", "bpe_tokenizer", "=", "self", ".", "build_bpe", "(", "self", ".", "args", ")", "\n", "st_dataset", "=", "SpeechTextTripleDatasetCreator", ".", "from_tsv", "(", "\n", "self", ".", "args", ".", "data", ",", "\n", "self", ".", "data_cfg", ",", "\n", "split", ",", "\n", "self", ".", "tgt_dict", ",", "\n", "pre_tokenizer", ",", "\n", "bpe_tokenizer", ",", "\n", "is_train_split", "=", "is_train_split", ",", "\n", "epoch", "=", "epoch", ",", "\n", "seed", "=", "self", ".", "args", ".", "seed", "\n", ")", "\n", "text_dataset", "=", "None", "\n", "if", "self", ".", "args", ".", "external_parallel_mt_data", "is", "not", "None", "and", "is_train_split", ":", "\n", "            ", "text_dataset", "=", "self", ".", "load_langpair_dataset", "(", ")", "\n", "", "if", "text_dataset", "is", "not", "None", ":", "\n", "            ", "mdsets", "=", "[", "\n", "ModalityDatasetItem", "(", "\n", "\"speech_to_text\"", ",", "\n", "st_dataset", ",", "\n", "[", "self", ".", "args", ".", "max_audio_positions", ",", "self", ".", "args", ".", "max_target_positions", "]", ",", "\n", "self", ".", "args", ".", "max_audio_tokens", ",", "\n", "self", ".", "args", ".", "batch_size", "\n", ")", ",", "\n", "ModalityDatasetItem", "(", "\n", "\"text_to_text\"", ",", "\n", "text_dataset", ",", "\n", "[", "self", ".", "args", ".", "max_source_positions", ",", "self", ".", "args", ".", "max_target_positions", "]", ",", "\n", "self", ".", "args", ".", "max_text_tokens", ",", "\n", "self", ".", "args", ".", "batch_size", "\n", ")", "\n", "]", "\n", "self", ".", "datasets", "[", "split", "]", "=", "MultiModalityDataset", "(", "mdsets", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "datasets", "[", "split", "]", "=", "st_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.get_batch_iterator": [[187, 241], ["isinstance", "dataset.set_epoch", "dataset.get_batch_samplers", "fairseq.data.iterators.GroupedEpochBatchIterator", "isinstance", "super().get_batch_iterator", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch", "home.repos.pwc.inspect_result.reneeye_const.data.multi_modality_dataset.MultiModalityDataset.get_batch_samplers", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.get_batch_iterator"], ["", "", "def", "get_batch_iterator", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "max_tokens", "=", "None", ",", "\n", "max_sentences", "=", "None", ",", "\n", "max_positions", "=", "None", ",", "\n", "ignore_invalid_inputs", "=", "False", ",", "\n", "required_batch_size_multiple", "=", "1", ",", "\n", "seed", "=", "1", ",", "\n", "num_shards", "=", "1", ",", "\n", "shard_id", "=", "0", ",", "\n", "num_workers", "=", "0", ",", "\n", "epoch", "=", "1", ",", "\n", "data_buffer_size", "=", "0", ",", "\n", "disable_iterator_cache", "=", "False", ",", "\n", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "dataset", ",", "MultiModalityDataset", ")", ":", "\n", "            ", "return", "super", "(", "SpeechToTextTripletWithExtraMTTask", ",", "self", ")", ".", "get_batch_iterator", "(", "\n", "dataset", ",", "\n", "max_tokens", ",", "\n", "max_sentences", ",", "\n", "max_positions", ",", "\n", "ignore_invalid_inputs", ",", "\n", "required_batch_size_multiple", ",", "\n", "seed", ",", "\n", "num_shards", ",", "\n", "shard_id", ",", "\n", "num_workers", ",", "\n", "epoch", ",", "\n", "data_buffer_size", ",", "\n", "disable_iterator_cache", "\n", ")", "\n", "", "assert", "isinstance", "(", "dataset", ",", "MultiModalityDataset", ")", "\n", "assert", "len", "(", "dataset", ".", "datasets", ")", "==", "2", "\n", "dataset", ".", "set_epoch", "(", "epoch", ")", "\n", "batch_samplers", "=", "dataset", ".", "get_batch_samplers", "(", "[", "1.0", ",", "self", ".", "args", ".", "text_data_sample_ratio", "]", ",", "\n", "required_batch_size_multiple", ",", "\n", "seed", ")", "\n", "# return a reusable, sharded iterator", "\n", "epoch_iter", "=", "iterators", ".", "GroupedEpochBatchIterator", "(", "\n", "dataset", "=", "dataset", ",", "\n", "collate_fn", "=", "dataset", ".", "collater", ",", "\n", "batch_samplers", "=", "batch_samplers", ",", "\n", "seed", "=", "seed", ",", "\n", "num_shards", "=", "num_shards", ",", "\n", "shard_id", "=", "shard_id", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "epoch", "=", "epoch", ",", "\n", "mult_rate", "=", "1", ",", "\n", "# mult_rate=1 if self.args.update_mix_data else max(self.args.update_freq),", "\n", "buffer_size", "=", "data_buffer_size", ",", "\n", ")", "\n", "self", ".", "dataset_to_epoch_iter", "[", "dataset", "]", "=", "{", "}", "# refresh it every epoch", "\n", "return", "epoch_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.target_dictionary": [[242, 245], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tgt_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.source_dictionary": [[246, 249], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.max_positions": [[250, 252], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "args", ".", "max_audio_positions", ",", "self", ".", "args", ".", "max_source_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.build_model": [[253, 276], ["super().build_model", "getattr", "json.loads", "fairseq.data.encoders.build_tokenizer", "json.loads", "speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.build_generator", "getattr", "argparse.Namespace", "speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.build_bpe", "argparse.Namespace", "getattr", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model", "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.build_tokenizer", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.build_generator", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.build_bpe"], ["", "def", "build_model", "(", "self", ",", "args", ")", ":", "\n", "        ", "args", ".", "input_feat_per_channel", "=", "self", ".", "data_cfg", ".", "input_feat_per_channel", "\n", "args", ".", "input_channels", "=", "self", ".", "data_cfg", ".", "input_channels", "\n", "model", "=", "super", "(", "SpeechToTextTripletWithExtraMTTask", ",", "self", ")", ".", "build_model", "(", "args", ")", "\n", "\n", "if", "getattr", "(", "args", ",", "\"eval_bleu\"", ",", "False", ")", ":", "\n", "            ", "assert", "getattr", "(", "args", ",", "\"eval_bleu_detok\"", ",", "None", ")", "is", "not", "None", ",", "(", "\n", "\"--eval-bleu-detok is required if using --eval-bleu; \"", "\n", "\"try --eval-bleu-detok=moses (or --eval-bleu-detok=space \"", "\n", "\"to disable detokenization, e.g., when using sentencepiece)\"", "\n", ")", "\n", "detok_args", "=", "json", ".", "loads", "(", "getattr", "(", "args", ",", "\"eval_bleu_detok_args\"", ",", "\"{}\"", ")", "or", "\"{}\"", ")", "\n", "self", ".", "tokenizer", "=", "encoders", ".", "build_tokenizer", "(", "\n", "Namespace", "(", "tokenizer", "=", "getattr", "(", "args", ",", "\"eval_bleu_detok\"", ",", "None", ")", ",", "**", "detok_args", ")", ")", "\n", "if", "args", ".", "eval_bleu_bpe", "is", "None", ":", "\n", "                ", "self", ".", "bpe", "=", "None", "\n", "", "else", ":", "\n", "                ", "self", ".", "bpe", "=", "self", ".", "build_bpe", "(", "self", ".", "args", ")", "\n", "\n", "", "gen_args", "=", "json", ".", "loads", "(", "getattr", "(", "args", ",", "\"eval_bleu_args\"", ",", "\"{}\"", ")", "or", "\"{}\"", ")", "\n", "self", ".", "sequence_generator", "=", "self", ".", "build_generator", "(", "[", "model", "]", ",", "Namespace", "(", "**", "gen_args", ")", ")", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.build_generator": [[277, 297], ["super().build_generator", "ValueError", "speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.tgt_dict.indices.items", "fairseq.data.audio.speech_text_triple_dataset.SpeechTextTripleDataset.is_lang_tag"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.build_generator", "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDataset.is_lang_tag"], ["", "def", "build_generator", "(", "\n", "self", ",", "\n", "models", ",", "\n", "args", ",", "\n", "seq_gen_cls", "=", "None", ",", "\n", "extra_gen_cls_kwargs", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "self", ".", "data_cfg", ".", "prepend_tgt_lang_tag", "and", "args", ".", "prefix_size", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Please set \"--prefix-size 1\" since '", "\n", "\"target language ID token is prepended as BOS.\"", "\n", ")", "\n", "", "lang_token_ids", "=", "{", "\n", "i", "\n", "for", "s", ",", "i", "in", "self", ".", "tgt_dict", ".", "indices", ".", "items", "(", ")", "\n", "if", "SpeechTextTripleDataset", ".", "is_lang_tag", "(", "s", ")", "\n", "}", "\n", "extra_gen_cls_kwargs", "=", "{", "\"symbols_to_strip_from_output\"", ":", "lang_token_ids", "}", "\n", "return", "super", "(", ")", ".", "build_generator", "(", "\n", "models", ",", "args", ",", "seq_gen_cls", "=", "None", ",", "extra_gen_cls_kwargs", "=", "extra_gen_cls_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.build_tokenizer": [[299, 302], ["logger.info", "fairseq.data.encoders.build_tokenizer", "argparse.Namespace"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.build_tokenizer"], ["", "def", "build_tokenizer", "(", "self", ",", "args", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"pre-tokenizer: {self.data_cfg.pre_tokenizer}\"", ")", "\n", "return", "encoders", ".", "build_tokenizer", "(", "Namespace", "(", "**", "self", ".", "data_cfg", ".", "pre_tokenizer", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.build_bpe": [[303, 306], ["logger.info", "fairseq.data.encoders.build_bpe", "argparse.Namespace"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.build_bpe"], ["", "def", "build_bpe", "(", "self", ",", "args", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"tokenizer: {self.data_cfg.bpe_tokenizer}\"", ")", "\n", "return", "encoders", ".", "build_bpe", "(", "Namespace", "(", "**", "self", ".", "data_cfg", ".", "bpe_tokenizer", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.get_interactive_tokens_and_lengths": [[307, 310], ["fairseq.data.audio.speech_to_text_dataset.get_features_or_waveform"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.get_features_or_waveform"], ["", "def", "get_interactive_tokens_and_lengths", "(", "self", ",", "lines", ",", "encode_fn", ")", ":", "\n", "        ", "n_frames", "=", "[", "get_features_or_waveform", "(", "p", ")", ".", "shape", "[", "0", "]", "for", "p", "in", "lines", "]", "\n", "return", "lines", ",", "n_frames", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.build_dataset_for_inference": [[311, 314], ["fairseq.data.audio.speech_text_triple_dataset.SpeechTextTripleDataset"], "methods", ["None"], ["", "def", "build_dataset_for_inference", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "SpeechTextTripleDataset", "(", "\n", "\"interactive\"", ",", "False", ",", "self", ".", "data_cfg", ",", "src_tokens", ",", "src_lengths", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.valid_step": [[316, 329], ["super().valid_step", "speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask._inference_with_bleu", "range", "len", "str", "str"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.valid_step", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag._inference_with_bleu"], ["", "def", "valid_step", "(", "self", ",", "sample", ",", "model", ",", "criterion", ")", ":", "\n", "        ", "loss", ",", "sample_size", ",", "logging_output", "=", "super", "(", ")", ".", "valid_step", "(", "sample", ",", "model", ",", "criterion", ")", "\n", "if", "self", ".", "args", ".", "eval_bleu", ":", "\n", "            ", "bleu", "=", "self", ".", "_inference_with_bleu", "(", "self", ".", "sequence_generator", ",", "sample", ",", "model", ")", "\n", "logging_output", "[", "\"_bleu_sys_len\"", "]", "=", "bleu", ".", "sys_len", "\n", "logging_output", "[", "\"_bleu_ref_len\"", "]", "=", "bleu", ".", "ref_len", "\n", "# we split counts into separate entries so that they can be", "\n", "# summed efficiently across workers using fast-stat-sync", "\n", "assert", "len", "(", "bleu", ".", "counts", ")", "==", "EVAL_BLEU_ORDER", "\n", "for", "i", "in", "range", "(", "EVAL_BLEU_ORDER", ")", ":", "\n", "                ", "logging_output", "[", "\"_bleu_counts_\"", "+", "str", "(", "i", ")", "]", "=", "bleu", ".", "counts", "[", "i", "]", "\n", "logging_output", "[", "\"_bleu_totals_\"", "+", "str", "(", "i", ")", "]", "=", "bleu", ".", "totals", "[", "i", "]", "\n", "", "", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.reduce_metrics": [[330, 369], ["super().reduce_metrics", "range", "sum", "counts.append", "totals.append", "max", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_derived", "sum", "speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.reduce_metrics.sum_logs"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.reduce_metrics", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived"], ["", "def", "reduce_metrics", "(", "self", ",", "logging_outputs", ",", "criterion", ")", ":", "\n", "        ", "super", "(", ")", ".", "reduce_metrics", "(", "logging_outputs", ",", "criterion", ")", "\n", "if", "self", ".", "args", ".", "eval_bleu", ":", "\n", "            ", "def", "sum_logs", "(", "key", ")", ":", "\n", "                ", "if", "key", "in", "logging_outputs", "[", "0", "]", ":", "\n", "                    ", "return", "sum", "(", "log", "[", "key", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "for", "log", "in", "logging_outputs", ")", "\n", "", "return", "sum", "(", "log", ".", "get", "(", "key", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "\n", "", "counts", ",", "totals", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "EVAL_BLEU_ORDER", ")", ":", "\n", "                ", "counts", ".", "append", "(", "sum_logs", "(", "\"_bleu_counts_\"", "+", "str", "(", "i", ")", ")", ")", "\n", "totals", ".", "append", "(", "sum_logs", "(", "\"_bleu_totals_\"", "+", "str", "(", "i", ")", ")", ")", "\n", "\n", "", "if", "max", "(", "totals", ")", ">", "0", ":", "\n", "# log counts as numpy arrays -- log_scalar will sum them correctly", "\n", "                ", "metrics", ".", "log_scalar", "(", "\"_bleu_counts\"", ",", "np", ".", "array", "(", "counts", ")", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_bleu_totals\"", ",", "np", ".", "array", "(", "totals", ")", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_bleu_sys_len\"", ",", "sum_logs", "(", "\"_bleu_sys_len\"", ")", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_bleu_ref_len\"", ",", "sum_logs", "(", "\"_bleu_ref_len\"", ")", ")", "\n", "\n", "def", "compute_bleu", "(", "meters", ")", ":", "\n", "                    ", "import", "inspect", "\n", "import", "sacrebleu", "\n", "\n", "fn_sig", "=", "inspect", ".", "getfullargspec", "(", "sacrebleu", ".", "compute_bleu", ")", "[", "0", "]", "\n", "if", "\"smooth_method\"", "in", "fn_sig", ":", "\n", "                        ", "smooth", "=", "{", "\"smooth_method\"", ":", "\"exp\"", "}", "\n", "", "else", ":", "\n", "                        ", "smooth", "=", "{", "\"smooth\"", ":", "\"exp\"", "}", "\n", "", "bleu", "=", "sacrebleu", ".", "compute_bleu", "(", "\n", "correct", "=", "meters", "[", "\"_bleu_counts\"", "]", ".", "sum", ",", "\n", "total", "=", "meters", "[", "\"_bleu_totals\"", "]", ".", "sum", ",", "\n", "sys_len", "=", "meters", "[", "\"_bleu_sys_len\"", "]", ".", "sum", ",", "\n", "ref_len", "=", "meters", "[", "\"_bleu_ref_len\"", "]", ".", "sum", ",", "\n", "**", "smooth", "\n", ")", "\n", "return", "round", "(", "bleu", ".", "score", ",", "2", ")", "\n", "\n", "", "metrics", ".", "log_derived", "(", "\"bleu\"", ",", "compute_bleu", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.inference_step": [[370, 396], ["speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.tgt_dict.index", "torch.no_grad", "generator.generate", "Exception", "src_tokens.size", "isinstance", "torch.LongTensor().unsqueeze", "prefix_tokens.expand().to.expand().to.expand().to", "torch.LongTensor", "prefix_tokens.expand().to.expand().to.expand"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.index", "home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.generate", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "", "", "def", "inference_step", "(", "\n", "self", ",", "generator", ",", "models", ",", "sample", ",", "prefix_tokens", "=", "None", ",", "constraints", "=", "None", "\n", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "lang_prefix_tok", "is", "None", ":", "\n", "            ", "prefix_tokens", "=", "None", "\n", "", "else", ":", "\n", "            ", "prefix_tokens", "=", "self", ".", "tgt_dict", ".", "index", "(", "self", ".", "args", ".", "lang_prefix_tok", ")", "\n", "assert", "prefix_tokens", "!=", "self", ".", "tgt_dict", ".", "unk_index", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "net_input", "=", "sample", "[", "\"net_input\"", "]", "\n", "if", "\"src_tokens\"", "in", "net_input", ":", "\n", "                ", "src_tokens", "=", "net_input", "[", "\"src_tokens\"", "]", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"net_input must have `src_tokens`.\"", ")", "\n", "", "bsz", ",", "_", "=", "src_tokens", ".", "size", "(", ")", "[", ":", "2", "]", "\n", "\n", "if", "prefix_tokens", "is", "not", "None", ":", "\n", "                ", "if", "isinstance", "(", "prefix_tokens", ",", "int", ")", ":", "\n", "                    ", "prefix_tokens", "=", "torch", ".", "LongTensor", "(", "[", "prefix_tokens", "]", ")", ".", "unsqueeze", "(", "1", ")", "\n", "prefix_tokens", "=", "prefix_tokens", ".", "expand", "(", "bsz", ",", "-", "1", ")", ".", "to", "(", "src_tokens", ".", "device", ")", "\n", "\n", "", "", "return", "generator", ".", "generate", "(", "\n", "models", ",", "\n", "sample", ",", "\n", "prefix_tokens", "=", "prefix_tokens", ",", "\n", "constraints", "=", "constraints", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask._inference_with_bleu": [[398, 434], ["speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.inference_step", "range", "speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask.tgt_dict.string", "len", "speech_to_text_triplet_with_extra_mt.SpeechToTextTripletWithExtraMTTask._inference_with_bleu.decode"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.inference_step", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "", "def", "_inference_with_bleu", "(", "self", ",", "generator", ",", "sample", ",", "model", ")", ":", "\n", "        ", "import", "sacrebleu", "\n", "\n", "def", "decode", "(", "toks", ",", "escape_unk", "=", "False", ")", ":", "\n", "            ", "s", "=", "self", ".", "tgt_dict", ".", "string", "(", "\n", "toks", ".", "int", "(", ")", ".", "cpu", "(", ")", ",", "\n", "self", ".", "args", ".", "eval_bleu_remove_bpe", ",", "\n", "unk_string", "=", "(", "\"UNKNOWNTOKENINREF\"", "if", "escape_unk", "else", "\"UNKNOWNTOKENINHYP\"", ")", ",", "\n", ")", "\n", "if", "self", ".", "bpe", "is", "not", "None", ":", "\n", "                ", "s", "=", "self", ".", "bpe", ".", "decode", "(", "s", ")", "\n", "", "if", "self", ".", "tokenizer", ":", "\n", "                ", "s", "=", "self", ".", "tokenizer", ".", "decode", "(", "s", ")", "\n", "", "return", "s", "\n", "\n", "", "gen_out", "=", "self", ".", "inference_step", "(", "generator", ",", "[", "model", "]", ",", "sample", ",", "prefix_tokens", "=", "None", ")", "\n", "hyps", ",", "refs", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "gen_out", ")", ")", ":", "\n", "            ", "hyp", "=", "decode", "(", "gen_out", "[", "i", "]", "[", "0", "]", "[", "\"tokens\"", "]", ")", "\n", "ref", "=", "decode", "(", "\n", "utils", ".", "strip_pad", "(", "sample", "[", "\"target\"", "]", "[", "i", "]", ",", "self", ".", "tgt_dict", ".", "pad", "(", ")", ")", ",", "\n", "escape_unk", "=", "True", ",", "# don't count <unk> as matches to the hypo", "\n", ")", "\n", "if", "self", ".", "args", ".", "lang_prefix_tok", "is", "not", "None", ":", "\n", "                ", "hyp", "=", "hyp", ".", "replace", "(", "self", ".", "args", ".", "lang_prefix_tok", ",", "\"\"", ")", "\n", "ref", "=", "ref", ".", "replace", "(", "self", ".", "args", ".", "lang_prefix_tok", ",", "\"\"", ")", "\n", "", "hyps", ".", "append", "(", "hyp", ")", "\n", "refs", ".", "append", "(", "ref", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "eval_bleu_print_samples", ":", "\n", "            ", "logger", ".", "info", "(", "\"example hypothesis: \"", "+", "hyps", "[", "0", "]", ")", "\n", "logger", ".", "info", "(", "\"example reference: \"", "+", "refs", "[", "0", "]", ")", "\n", "", "if", "self", ".", "args", ".", "eval_tokenized_bleu", ":", "\n", "            ", "return", "sacrebleu", ".", "corpus_bleu", "(", "hyps", ",", "[", "refs", "]", ",", "tokenize", "=", "\"none\"", ")", "\n", "", "else", ":", "\n", "            ", "return", "sacrebleu", ".", "corpus_bleu", "(", "hyps", ",", "[", "refs", "]", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.add_args": [[24, 46], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "\"data\"", ",", "help", "=", "\"manifest root path\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config-yaml\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"config.yaml\"", ",", "\n", "help", "=", "\"Configuration YAML filename (under manifest root)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max-source-positions\"", ",", "\n", "default", "=", "6000", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"max number of tokens in the source sequence\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max-target-positions\"", ",", "\n", "default", "=", "1024", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"max number of tokens in the target sequence\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.__init__": [[48, 52], ["fairseq.tasks.LegacyFairseqTask.__init__", "fairseq.data.audio.speech_to_text_dataset.S2TDataConfig", "os.join"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["", "def", "__init__", "(", "self", ",", "args", ",", "tgt_dict", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "tgt_dict", "=", "tgt_dict", "\n", "self", ".", "data_cfg", "=", "S2TDataConfig", "(", "op", ".", "join", "(", "args", ".", "data", ",", "args", ".", "config_yaml", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.setup_task": [[53, 68], ["fairseq.data.audio.speech_to_text_dataset.S2TDataConfig", "os.join", "fairseq.data.Dictionary.load", "logger.info", "cls", "os.join", "os.isfile", "FileNotFoundError", "getattr", "all", "ValueError", "len", "s.startswith", "args.train_subset.split"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.isfile"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "data_cfg", "=", "S2TDataConfig", "(", "op", ".", "join", "(", "args", ".", "data", ",", "args", ".", "config_yaml", ")", ")", "\n", "dict_path", "=", "op", ".", "join", "(", "args", ".", "data", ",", "data_cfg", ".", "vocab_filename", ")", "\n", "if", "not", "op", ".", "isfile", "(", "dict_path", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "f\"Dict not found: {dict_path}\"", ")", "\n", "", "tgt_dict", "=", "Dictionary", ".", "load", "(", "dict_path", ")", "\n", "logger", ".", "info", "(", "\n", "f\"dictionary size ({data_cfg.vocab_filename}): \"", "f\"{len(tgt_dict):,}\"", "\n", ")", "\n", "\n", "if", "getattr", "(", "args", ",", "\"train_subset\"", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "if", "not", "all", "(", "s", ".", "startswith", "(", "\"train\"", ")", "for", "s", "in", "args", ".", "train_subset", ".", "split", "(", "\",\"", ")", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'Train splits should be named like \"train*\".'", ")", "\n", "", "", "return", "cls", "(", "args", ",", "tgt_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.build_criterion": [[69, 78], ["criterions.build_criterion", "ValueError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.criterions.composite_loss.CompositeLoss.build_criterion"], ["", "def", "build_criterion", "(", "self", ",", "args", ")", ":", "\n", "        ", "from", "fairseq", "import", "criterions", "\n", "\n", "if", "self", ".", "data_cfg", ".", "prepend_tgt_lang_tag", "and", "args", ".", "ignore_prefix_size", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Please set \"--ignore-prefix-size 1\" since '", "\n", "\"target language ID token is prepended as BOS.\"", "\n", ")", "\n", "", "return", "criterions", ".", "build_criterion", "(", "args", ",", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.load_dataset": [[79, 93], ["split.startswith", "speech_to_text.SpeechToTextTask.build_tokenizer", "speech_to_text.SpeechToTextTask.build_bpe", "fairseq.data.audio.speech_to_text_dataset.SpeechToTextDatasetCreator.from_tsv"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.build_tokenizer", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.build_bpe", "home.repos.pwc.inspect_result.reneeye_const.audio.speech_text_triple_dataset.SpeechTextTripleDatasetCreator.from_tsv"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "1", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "is_train_split", "=", "split", ".", "startswith", "(", "\"train\"", ")", "\n", "pre_tokenizer", "=", "self", ".", "build_tokenizer", "(", "self", ".", "args", ")", "\n", "bpe_tokenizer", "=", "self", ".", "build_bpe", "(", "self", ".", "args", ")", "\n", "self", ".", "datasets", "[", "split", "]", "=", "SpeechToTextDatasetCreator", ".", "from_tsv", "(", "\n", "self", ".", "args", ".", "data", ",", "\n", "self", ".", "data_cfg", ",", "\n", "split", ",", "\n", "self", ".", "tgt_dict", ",", "\n", "pre_tokenizer", ",", "\n", "bpe_tokenizer", ",", "\n", "is_train_split", "=", "is_train_split", ",", "\n", "epoch", "=", "epoch", ",", "\n", "seed", "=", "self", ".", "args", ".", "seed", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.target_dictionary": [[95, 98], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tgt_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.source_dictionary": [[99, 102], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.max_positions": [[103, 105], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "args", ".", "max_source_positions", ",", "self", ".", "args", ".", "max_target_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.build_model": [[106, 110], ["super().build_model"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model"], ["", "def", "build_model", "(", "self", ",", "args", ")", ":", "\n", "        ", "args", ".", "input_feat_per_channel", "=", "self", ".", "data_cfg", ".", "input_feat_per_channel", "\n", "args", ".", "input_channels", "=", "self", ".", "data_cfg", ".", "input_channels", "\n", "return", "super", "(", "SpeechToTextTask", ",", "self", ")", ".", "build_model", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.build_generator": [[111, 131], ["super().build_generator", "ValueError", "speech_to_text.SpeechToTextTask.tgt_dict.indices.items", "fairseq.data.audio.speech_to_text_dataset.SpeechToTextDataset.is_lang_tag"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.build_generator", "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDataset.is_lang_tag"], ["", "def", "build_generator", "(", "\n", "self", ",", "\n", "models", ",", "\n", "args", ",", "\n", "seq_gen_cls", "=", "None", ",", "\n", "extra_gen_cls_kwargs", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "self", ".", "data_cfg", ".", "prepend_tgt_lang_tag", "and", "args", ".", "prefix_size", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Please set \"--prefix-size 1\" since '", "\n", "\"target language ID token is prepended as BOS.\"", "\n", ")", "\n", "", "lang_token_ids", "=", "{", "\n", "i", "\n", "for", "s", ",", "i", "in", "self", ".", "tgt_dict", ".", "indices", ".", "items", "(", ")", "\n", "if", "SpeechToTextDataset", ".", "is_lang_tag", "(", "s", ")", "\n", "}", "\n", "extra_gen_cls_kwargs", "=", "{", "\"symbols_to_strip_from_output\"", ":", "lang_token_ids", "}", "\n", "return", "super", "(", ")", ".", "build_generator", "(", "\n", "models", ",", "args", ",", "seq_gen_cls", "=", "None", ",", "extra_gen_cls_kwargs", "=", "extra_gen_cls_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.build_tokenizer": [[133, 136], ["logger.info", "fairseq.data.encoders.build_tokenizer", "argparse.Namespace"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.build_tokenizer"], ["", "def", "build_tokenizer", "(", "self", ",", "args", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"pre-tokenizer: {self.data_cfg.pre_tokenizer}\"", ")", "\n", "return", "encoders", ".", "build_tokenizer", "(", "Namespace", "(", "**", "self", ".", "data_cfg", ".", "pre_tokenizer", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.build_bpe": [[137, 140], ["logger.info", "fairseq.data.encoders.build_bpe", "argparse.Namespace"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.build_bpe"], ["", "def", "build_bpe", "(", "self", ",", "args", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"tokenizer: {self.data_cfg.bpe_tokenizer}\"", ")", "\n", "return", "encoders", ".", "build_bpe", "(", "Namespace", "(", "**", "self", ".", "data_cfg", ".", "bpe_tokenizer", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.build_dataset_for_inference": [[141, 144], ["fairseq.data.audio.speech_to_text_dataset.SpeechToTextDataset"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_dataset_for_inference", "(", "cls", ",", "audio_paths", ",", "n_frames", ")", ":", "\n", "        ", "return", "SpeechToTextDataset", "(", "\"interactive\"", ",", "False", ",", "{", "}", ",", "audio_paths", ",", "n_frames", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.tasks.denoising.DenoisingTask.add_args": [[37, 122], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "parser", ".", "add_argument", "(", "\"data\"", ",", "help", "=", "\"path to data directory\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokens-per-sample\"", ",", "\n", "default", "=", "512", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"max number of total tokens over all segments\"", "\n", "\" per sample for dataset\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--sample-break-mode\"", ",", "\n", "default", "=", "\"complete_doc\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"mode for breaking sentence\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask\"", ",", "\n", "default", "=", "0.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"fraction of words/subwords that will be masked\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-random\"", ",", "\n", "default", "=", "0.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"instead of using [MASK], use random token this often\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--insert\"", ",", "\n", "default", "=", "0.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"insert this percentage of additional random tokens\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--permute\"", ",", "\n", "default", "=", "0.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"take this proportion of subwords and permute them\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--rotate\"", ",", "\n", "default", "=", "0.5", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"rotate this proportion of inputs\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--poisson-lambda\"", ",", "\n", "default", "=", "3.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"randomly shuffle sentences for this proportion of inputs\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--permute-sentences\"", ",", "\n", "default", "=", "0.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"shuffle this proportion of sentences in all inputs\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-length\"", ",", "\n", "default", "=", "\"subword\"", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "[", "\"subword\"", ",", "\"word\"", ",", "\"span-poisson\"", "]", ",", "\n", "help", "=", "\"mask length to choose\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--replace-length\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"when masking N tokens, replace with 0, 1, or N tokens (use -1 for N)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max-source-positions\"", ",", "\n", "default", "=", "1024", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"max number of tokens in the source sequence\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max-target-positions\"", ",", "\n", "default", "=", "1024", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"max number of tokens in the target sequence\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.denoising.DenoisingTask.__init__": [[124, 131], ["fairseq.tasks.LegacyFairseqTask.__init__", "denoising.DenoisingTask.dictionary.add_symbol"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol"], ["", "def", "__init__", "(", "self", ",", "args", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "self", ".", "seed", "=", "args", ".", "seed", "\n", "\n", "# add mask token", "\n", "self", ".", "mask_idx", "=", "self", ".", "dictionary", ".", "add_symbol", "(", "\"<mask>\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.denoising.DenoisingTask.setup_task": [[132, 140], ["fairseq.data.Dictionary.load", "logger.info", "cls", "os.path.join", "hasattr", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Setup the task.\"\"\"", "\n", "dictionary", "=", "Dictionary", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data", ",", "\"dict.txt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"dictionary: {} types\"", ".", "format", "(", "len", "(", "dictionary", ")", ")", ")", "\n", "if", "not", "hasattr", "(", "args", ",", "\"shuffle_instance\"", ")", ":", "\n", "            ", "args", ".", "shuffle_instance", "=", "False", "\n", "", "return", "cls", "(", "args", ",", "dictionary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.denoising.DenoisingTask.load_dataset": [[141, 200], ["fairseq.utils.split_paths", "os.path.join", "fairseq.data.data_utils.load_indexed_dataset", "fairseq.data.StripTokenDataset", "fairseq.data.TokenBlockDataset", "fairseq.data.PrependTokenDataset", "fairseq.data.AppendTokenDataset", "fairseq.data.DenoisingDataset", "logger.info", "len", "FileNotFoundError", "denoising.DenoisingTask.dictionary.eos", "denoising.DenoisingTask.source_dictionary.bos", "denoising.DenoisingTask.source_dictionary.eos", "fairseq.data.encoders.utils.get_whole_word_mask", "denoising.DenoisingTask.dictionary.pad", "denoising.DenoisingTask.dictionary.eos", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.load_indexed_dataset", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.encoders.utils.get_whole_word_mask", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "1", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n        \"\"\"", "\n", "paths", "=", "utils", ".", "split_paths", "(", "self", ".", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "data_path", "=", "paths", "[", "(", "epoch", "-", "1", ")", "%", "len", "(", "paths", ")", "]", "\n", "split_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "split", ")", "\n", "\n", "dataset", "=", "data_utils", ".", "load_indexed_dataset", "(", "\n", "split_path", ",", "\n", "self", ".", "dictionary", ",", "\n", "self", ".", "args", ".", "dataset_impl", ",", "\n", "combine", "=", "combine", ",", "\n", ")", "\n", "if", "dataset", "is", "None", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "\n", "\"Dataset not found: {} ({})\"", ".", "format", "(", "split", ",", "split_path", ")", "\n", ")", "\n", "\n", "", "dataset", "=", "StripTokenDataset", "(", "dataset", ",", "self", ".", "dictionary", ".", "eos", "(", ")", ")", "\n", "\n", "# create continuous blocks of tokens", "\n", "dataset", "=", "TokenBlockDataset", "(", "\n", "dataset", ",", "\n", "dataset", ".", "sizes", ",", "\n", "self", ".", "args", ".", "tokens_per_sample", "-", "2", ",", "# one less for <s> and one for </s>", "\n", "pad", "=", "self", ".", "dictionary", ".", "pad", "(", ")", ",", "\n", "eos", "=", "self", ".", "dictionary", ".", "eos", "(", ")", ",", "\n", "break_mode", "=", "self", ".", "args", ".", "sample_break_mode", ",", "\n", "document_sep_len", "=", "0", ",", "\n", ")", "\n", "\n", "# prepend beginning-of-sentence token (<s>, equiv. to [CLS] in BERT)", "\n", "dataset", "=", "PrependTokenDataset", "(", "dataset", ",", "self", ".", "source_dictionary", ".", "bos", "(", ")", ")", "\n", "dataset", "=", "AppendTokenDataset", "(", "dataset", ",", "self", ".", "source_dictionary", ".", "eos", "(", ")", ")", "\n", "\n", "mask_whole_words", "=", "(", "\n", "get_whole_word_mask", "(", "self", ".", "args", ",", "self", ".", "source_dictionary", ")", "\n", "if", "self", ".", "args", ".", "mask_length", "!=", "\"subword\"", "\n", "else", "None", "\n", ")", "\n", "\n", "self", ".", "datasets", "[", "split", "]", "=", "DenoisingDataset", "(", "\n", "dataset", ",", "\n", "dataset", ".", "sizes", ",", "\n", "self", ".", "dictionary", ",", "\n", "self", ".", "mask_idx", ",", "\n", "mask_whole_words", ",", "\n", "shuffle", "=", "self", ".", "args", ".", "shuffle_instance", ",", "\n", "seed", "=", "self", ".", "seed", ",", "\n", "args", "=", "self", ".", "args", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"Split: {0}, Loaded {1} samples of denoising_dataset\"", ".", "format", "(", "\n", "split", ",", "\n", "len", "(", "self", ".", "datasets", "[", "split", "]", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.denoising.DenoisingTask.build_dataset_for_inference": [[203, 236], ["denoising.DenoisingTask.source_dictionary.pad", "denoising.DenoisingTask.source_dictionary.eos", "fairseq.data.TokenBlockDataset", "fairseq.data.PrependTokenDataset", "fairseq.data.PadDataset", "fairseq.data.NestedDictionaryDataset", "fairseq.data.StripTokenDataset", "fairseq.data.IdDataset", "fairseq.data.NumelDataset", "fairseq.data.PadDataset", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "def", "build_dataset_for_inference", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Generate batches for inference. We assume that the input begins with a\n        bos symbol (`<s>`) and ends with an eos symbol (`</s>`).\n        \"\"\"", "\n", "pad", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", "\n", "eos", "=", "self", ".", "source_dictionary", ".", "eos", "(", ")", "\n", "src_dataset", "=", "TokenBlockDataset", "(", "\n", "src_tokens", ",", "\n", "src_lengths", ",", "\n", "block_size", "=", "self", ".", "args", ".", "tokens_per_sample", "-", "2", ",", "# for <s> and </s>", "\n", "pad", "=", "pad", ",", "\n", "eos", "=", "eos", ",", "\n", "break_mode", "=", "self", ".", "args", ".", "sample_break_mode", ",", "\n", "document_sep_len", "=", "0", ",", "\n", ")", "\n", "prev_output_tokens", "=", "PrependTokenDataset", "(", "\n", "StripTokenDataset", "(", "src_dataset", ",", "eos", ")", ",", "eos", "\n", ")", "\n", "src_dataset", "=", "PadDataset", "(", "src_dataset", ",", "pad_idx", "=", "pad", ",", "left_pad", "=", "False", ")", "\n", "return", "NestedDictionaryDataset", "(", "\n", "{", "\n", "\"id\"", ":", "IdDataset", "(", ")", ",", "\n", "\"net_input\"", ":", "{", "\n", "\"src_tokens\"", ":", "src_dataset", ",", "\n", "\"src_lengths\"", ":", "NumelDataset", "(", "src_dataset", ",", "reduce", "=", "False", ")", ",", "\n", "\"prev_output_tokens\"", ":", "PadDataset", "(", "\n", "prev_output_tokens", ",", "pad_idx", "=", "pad", ",", "left_pad", "=", "False", "\n", ")", ",", "\n", "}", ",", "\n", "\"target\"", ":", "src_dataset", ",", "\n", "}", ",", "\n", "sizes", "=", "[", "np", ".", "array", "(", "src_lengths", ")", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.denoising.DenoisingTask.max_positions": [[238, 241], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the max sentence length allowed by the task.\"\"\"", "\n", "return", "(", "self", ".", "args", ".", "max_source_positions", ",", "self", ".", "args", ".", "max_target_positions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.denoising.DenoisingTask.source_dictionary": [[242, 246], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the source :class:`~fairseq.data.Dictionary`.\"\"\"", "\n", "return", "self", ".", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.denoising.DenoisingTask.target_dictionary": [[247, 251], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the target :class:`~fairseq.data.Dictionary`.\"\"\"", "\n", "return", "self", ".", "dictionary", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.tasks.masked_lm.MaskedLMTask.add_args": [[36, 101], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "parser", ".", "add_argument", "(", "\n", "\"data\"", ",", "\n", "help", "=", "\"colon separated path to data directories list, \\\n                            will be iterated upon during epochs in round-robin manner\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--sample-break-mode\"", ",", "\n", "default", "=", "\"complete\"", ",", "\n", "choices", "=", "[", "\"none\"", ",", "\"complete\"", ",", "\"complete_doc\"", ",", "\"eos\"", "]", ",", "\n", "help", "=", "'If omitted or \"none\", fills each sample with tokens-per-sample '", "\n", "'tokens. If set to \"complete\", splits samples only at the end '", "\n", "\"of sentence, but may include multiple sentences per sample. \"", "\n", "'\"complete_doc\" is similar but respects doc boundaries. '", "\n", "'If set to \"eos\", includes only one sentence per sample.'", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokens-per-sample\"", ",", "\n", "default", "=", "512", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"max number of total tokens over all segments \"", "\n", "\"per sample for BERT dataset\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-prob\"", ",", "\n", "default", "=", "0.15", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"probability of replacing a token with mask\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--leave-unmasked-prob\"", ",", "\n", "default", "=", "0.1", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"probability that a masked token is unmasked\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--random-token-prob\"", ",", "\n", "default", "=", "0.1", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"probability of replacing a token with a random token\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--freq-weighted-replacement\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"sample random replacement words based on word frequencies\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-whole-words\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"mask whole words; you may also want to set --bpe\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--shorten-method\"", ",", "\n", "default", "=", "\"none\"", ",", "\n", "choices", "=", "[", "\"none\"", ",", "\"truncate\"", ",", "\"random_crop\"", "]", ",", "\n", "help", "=", "\"if not none, shorten sequences that exceed --tokens-per-sample\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--shorten-data-split-list\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "help", "=", "\"comma-separated list of dataset splits to apply shortening to, \"", "\n", "'e.g., \"train,valid\" (default: all dataset splits)'", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.masked_lm.MaskedLMTask.__init__": [[104, 111], ["fairseq.tasks.LegacyFairseqTask.__init__", "dictionary.add_symbol"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol"], ["", "def", "__init__", "(", "self", ",", "args", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "self", ".", "seed", "=", "args", ".", "seed", "\n", "\n", "# add mask token", "\n", "self", ".", "mask_idx", "=", "dictionary", ".", "add_symbol", "(", "\"<mask>\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.masked_lm.MaskedLMTask.setup_task": [[112, 119], ["fairseq.utils.split_paths", "fairseq.data.Dictionary.load", "logger.info", "cls", "len", "os.path.join", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "paths", "=", "utils", ".", "split_paths", "(", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "dictionary", "=", "Dictionary", ".", "load", "(", "os", ".", "path", ".", "join", "(", "paths", "[", "0", "]", ",", "\"dict.txt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"dictionary: {} types\"", ".", "format", "(", "len", "(", "dictionary", ")", ")", ")", "\n", "return", "cls", "(", "args", ",", "dictionary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.masked_lm.MaskedLMTask.load_dataset": [[120, 211], ["fairseq.utils.split_paths", "os.path.join", "fairseq.data.data_utils.load_indexed_dataset", "fairseq.data.shorten_dataset.maybe_shorten_dataset", "fairseq.data.TokenBlockDataset", "logger.info", "fairseq.data.PrependTokenDataset", "fairseq.data.MaskTokensDataset.apply_mask", "fairseq.data.SortDataset", "len", "FileNotFoundError", "masked_lm.MaskedLMTask.source_dictionary.bos", "fairseq.data.encoders.utils.get_whole_word_mask", "fairseq.data.data_utils.numpy_seed", "numpy.random.permutation", "fairseq.data.NestedDictionaryDataset", "masked_lm.MaskedLMTask.source_dictionary.pad", "masked_lm.MaskedLMTask.source_dictionary.eos", "len", "masked_lm.MaskedLMTask.source_dictionary.pad", "len", "len", "fairseq.data.IdDataset", "fairseq.data.RightPadDataset", "fairseq.data.NumSamplesDataset", "fairseq.data.NumelDataset", "fairseq.data.RightPadDataset", "fairseq.data.NumelDataset", "masked_lm.MaskedLMTask.source_dictionary.pad", "masked_lm.MaskedLMTask.source_dictionary.pad"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.load_indexed_dataset", "home.repos.pwc.inspect_result.reneeye_const.data.shorten_dataset.maybe_shorten_dataset", "home.repos.pwc.inspect_result.reneeye_const.data.mask_tokens_dataset.MaskTokensDataset.apply_mask", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.encoders.utils.get_whole_word_mask", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.numpy_seed", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "1", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n        \"\"\"", "\n", "paths", "=", "utils", ".", "split_paths", "(", "self", ".", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "data_path", "=", "paths", "[", "(", "epoch", "-", "1", ")", "%", "len", "(", "paths", ")", "]", "\n", "split_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "split", ")", "\n", "\n", "dataset", "=", "data_utils", ".", "load_indexed_dataset", "(", "\n", "split_path", ",", "\n", "self", ".", "source_dictionary", ",", "\n", "self", ".", "args", ".", "dataset_impl", ",", "\n", "combine", "=", "combine", ",", "\n", ")", "\n", "if", "dataset", "is", "None", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "\n", "\"Dataset not found: {} ({})\"", ".", "format", "(", "split", ",", "split_path", ")", "\n", ")", "\n", "\n", "", "dataset", "=", "maybe_shorten_dataset", "(", "\n", "dataset", ",", "\n", "split", ",", "\n", "self", ".", "args", ".", "shorten_data_split_list", ",", "\n", "self", ".", "args", ".", "shorten_method", ",", "\n", "self", ".", "args", ".", "tokens_per_sample", ",", "\n", "self", ".", "args", ".", "seed", ",", "\n", ")", "\n", "\n", "# create continuous blocks of tokens", "\n", "dataset", "=", "TokenBlockDataset", "(", "\n", "dataset", ",", "\n", "dataset", ".", "sizes", ",", "\n", "self", ".", "args", ".", "tokens_per_sample", "-", "1", ",", "# one less for <s>", "\n", "pad", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", "eos", "=", "self", ".", "source_dictionary", ".", "eos", "(", ")", ",", "\n", "break_mode", "=", "self", ".", "args", ".", "sample_break_mode", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"loaded {} blocks from: {}\"", ".", "format", "(", "len", "(", "dataset", ")", ",", "split_path", ")", ")", "\n", "\n", "# prepend beginning-of-sentence token (<s>, equiv. to [CLS] in BERT)", "\n", "dataset", "=", "PrependTokenDataset", "(", "dataset", ",", "self", ".", "source_dictionary", ".", "bos", "(", ")", ")", "\n", "\n", "# create masked input and targets", "\n", "mask_whole_words", "=", "(", "\n", "get_whole_word_mask", "(", "self", ".", "args", ",", "self", ".", "source_dictionary", ")", "\n", "if", "self", ".", "args", ".", "mask_whole_words", "\n", "else", "None", "\n", ")", "\n", "\n", "src_dataset", ",", "tgt_dataset", "=", "MaskTokensDataset", ".", "apply_mask", "(", "\n", "dataset", ",", "\n", "self", ".", "source_dictionary", ",", "\n", "pad_idx", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", "mask_idx", "=", "self", ".", "mask_idx", ",", "\n", "seed", "=", "self", ".", "args", ".", "seed", ",", "\n", "mask_prob", "=", "self", ".", "args", ".", "mask_prob", ",", "\n", "leave_unmasked_prob", "=", "self", ".", "args", ".", "leave_unmasked_prob", ",", "\n", "random_token_prob", "=", "self", ".", "args", ".", "random_token_prob", ",", "\n", "freq_weighted_replacement", "=", "self", ".", "args", ".", "freq_weighted_replacement", ",", "\n", "mask_whole_words", "=", "mask_whole_words", ",", "\n", ")", "\n", "\n", "with", "data_utils", ".", "numpy_seed", "(", "self", ".", "args", ".", "seed", "+", "epoch", ")", ":", "\n", "            ", "shuffle", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "src_dataset", ")", ")", "\n", "\n", "", "self", ".", "datasets", "[", "split", "]", "=", "SortDataset", "(", "\n", "NestedDictionaryDataset", "(", "\n", "{", "\n", "\"id\"", ":", "IdDataset", "(", ")", ",", "\n", "\"net_input\"", ":", "{", "\n", "\"src_tokens\"", ":", "RightPadDataset", "(", "\n", "src_dataset", ",", "\n", "pad_idx", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", ")", ",", "\n", "\"src_lengths\"", ":", "NumelDataset", "(", "src_dataset", ",", "reduce", "=", "False", ")", ",", "\n", "}", ",", "\n", "\"target\"", ":", "RightPadDataset", "(", "\n", "tgt_dataset", ",", "\n", "pad_idx", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", ")", ",", "\n", "\"nsentences\"", ":", "NumSamplesDataset", "(", ")", ",", "\n", "\"ntokens\"", ":", "NumelDataset", "(", "src_dataset", ",", "reduce", "=", "True", ")", ",", "\n", "}", ",", "\n", "sizes", "=", "[", "src_dataset", ".", "sizes", "]", ",", "\n", ")", ",", "\n", "sort_order", "=", "[", "\n", "shuffle", ",", "\n", "src_dataset", ".", "sizes", ",", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.masked_lm.MaskedLMTask.build_dataset_for_inference": [[214, 240], ["fairseq.data.RightPadDataset", "fairseq.data.PrependTokenDataset", "fairseq.data.NestedDictionaryDataset", "fairseq.data.TokenBlockDataset", "masked_lm.MaskedLMTask.source_dictionary.bos", "fairseq.data.SortDataset", "masked_lm.MaskedLMTask.source_dictionary.pad", "fairseq.data.IdDataset", "masked_lm.MaskedLMTask.source_dictionary.pad", "masked_lm.MaskedLMTask.source_dictionary.eos", "fairseq.data.NumelDataset"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "def", "build_dataset_for_inference", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "sort", "=", "True", ")", ":", "\n", "        ", "src_dataset", "=", "RightPadDataset", "(", "\n", "TokenBlockDataset", "(", "\n", "src_tokens", ",", "\n", "src_lengths", ",", "\n", "self", ".", "args", ".", "tokens_per_sample", "-", "1", ",", "# one less for <s>", "\n", "pad", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", "eos", "=", "self", ".", "source_dictionary", ".", "eos", "(", ")", ",", "\n", "break_mode", "=", "\"eos\"", ",", "\n", ")", ",", "\n", "pad_idx", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", ")", "\n", "src_dataset", "=", "PrependTokenDataset", "(", "src_dataset", ",", "self", ".", "source_dictionary", ".", "bos", "(", ")", ")", "\n", "src_dataset", "=", "NestedDictionaryDataset", "(", "\n", "{", "\n", "\"id\"", ":", "IdDataset", "(", ")", ",", "\n", "\"net_input\"", ":", "{", "\n", "\"src_tokens\"", ":", "src_dataset", ",", "\n", "\"src_lengths\"", ":", "NumelDataset", "(", "src_dataset", ",", "reduce", "=", "False", ")", ",", "\n", "}", ",", "\n", "}", ",", "\n", "sizes", "=", "src_lengths", ",", "\n", ")", "\n", "if", "sort", ":", "\n", "            ", "src_dataset", "=", "SortDataset", "(", "src_dataset", ",", "sort_order", "=", "[", "src_lengths", "]", ")", "\n", "", "return", "src_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.masked_lm.MaskedLMTask.source_dictionary": [[241, 244], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.masked_lm.MaskedLMTask.target_dictionary": [[245, 248], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_denoising.MultilingualDenoisingTask.add_args": [[32, 51], ["denoising.DenoisingTask.add_args", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args"], ["    ", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "DenoisingTask", ".", "add_args", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--multilang-sampling-alpha\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "1.0", ",", "\n", "help", "=", "\"smoothing alpha for sample ratios across multiple datasets\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--add-lang-token\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--langs\"", ",", "type", "=", "str", ",", "help", "=", "\"language ids we are considering\"", ",", "default", "=", "None", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no-whole-word-mask-langs\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"\"", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"languages without spacing between words dont support whole word masking\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_denoising.MultilingualDenoisingTask.setup_task": [[53, 80], ["args.data.split", "fairseq.data.Dictionary.load", "logger.info", "cls", "len", "os.path.join", "sorted", "args.langs.split", "hasattr", "fairseq.data.Dictionary.load.add_symbol", "len", "os.listdir", "os.path.isdir", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Setup the task.\"\"\"", "\n", "paths", "=", "args", ".", "data", ".", "split", "(", "\":\"", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "dictionary", "=", "Dictionary", ".", "load", "(", "os", ".", "path", ".", "join", "(", "paths", "[", "0", "]", ",", "\"dict.txt\"", ")", ")", "\n", "\n", "data_path", "=", "paths", "[", "0", "]", "\n", "if", "args", ".", "langs", "is", "None", ":", "\n", "            ", "languages", "=", "sorted", "(", "\n", "[", "\n", "name", "\n", "for", "name", "in", "os", ".", "listdir", "(", "data_path", ")", "\n", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "name", ")", ")", "\n", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "languages", "=", "args", ".", "langs", ".", "split", "(", "\",\"", ")", "\n", "\n", "", "if", "args", ".", "add_lang_token", ":", "\n", "            ", "for", "lang", "in", "languages", ":", "\n", "                ", "dictionary", ".", "add_symbol", "(", "\"[{}]\"", ".", "format", "(", "lang", ")", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"dictionary: {} types\"", ".", "format", "(", "len", "(", "dictionary", ")", ")", ")", "\n", "if", "not", "hasattr", "(", "args", ",", "\"shuffle_instance\"", ")", ":", "\n", "            ", "args", ".", "shuffle_instance", "=", "False", "\n", "", "return", "cls", "(", "args", ",", "dictionary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_denoising.MultilingualDenoisingTask.__init__": [[81, 90], ["denoising.DenoisingTask.__init__", "multilingual_denoising.MultilingualDenoisingTask.dictionary.add_symbol"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol"], ["", "def", "__init__", "(", "self", ",", "args", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "dictionary", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "self", ".", "seed", "=", "args", ".", "seed", "\n", "\n", "# add mask token", "\n", "self", ".", "mask_idx", "=", "self", ".", "dictionary", ".", "add_symbol", "(", "\"<mask>\"", ")", "\n", "self", ".", "langs", "=", "args", ".", "langs", "\n", "self", ".", "args", "=", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_denoising.MultilingualDenoisingTask._get_sample_prob": [[91, 100], ["dataset_lens.sum", "smoothed_prob.sum"], "methods", ["None"], ["", "def", "_get_sample_prob", "(", "self", ",", "dataset_lens", ")", ":", "\n", "        ", "\"\"\"\n        Get smoothed sampling porbability by languages. This helps low resource\n        languages by upsampling them.\n        \"\"\"", "\n", "prob", "=", "dataset_lens", "/", "dataset_lens", ".", "sum", "(", ")", "\n", "smoothed_prob", "=", "prob", "**", "self", ".", "args", ".", "multilang_sampling_alpha", "\n", "smoothed_prob", "=", "smoothed_prob", "/", "smoothed_prob", ".", "sum", "(", ")", "\n", "return", "smoothed_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_denoising.MultilingualDenoisingTask.load_dataset": [[101, 253], ["multilingual_denoising.MultilingualDenoisingTask.args.data.split", "os.path.join", "logger.info", "logger.info", "fairseq.data.encoders.utils.get_whole_word_mask", "multilingual_denoising.MultilingualDenoisingTask.args.no_whole_word_mask_langs.split", "numpy.array", "logger.info", "fairseq.data.SortDataset", "len", "sorted", "multilingual_denoising.MultilingualDenoisingTask.langs.split", "os.path.join", "fairseq.data.data_utils.load_indexed_dataset", "fairseq.data.TokenBlockDataset", "logger.info", "fairseq.data.PrependTokenDataset", "fairseq.data.AppendTokenDataset", "fairseq.data.DenoisingDataset", "lang_datasets.append", "multilingual_denoising.MultilingualDenoisingTask._get_sample_prob", "logger.info", "logger.info", "fairseq.data.ConcatDataset", "fairseq.data.ConcatDataset", "enumerate", "fairseq.data.data_utils.numpy_seed", "numpy.random.permutation", "os.path.join", "os.path.exists", "len", "FileNotFoundError", "multilingual_denoising.MultilingualDenoisingTask.source_dictionary.index", "multilingual_denoising.MultilingualDenoisingTask.source_dictionary.eos", "multilingual_denoising.MultilingualDenoisingTask.source_dictionary.bos", "len", "int", "fairseq.data.ResamplingDataset", "lang_splits.append", "multilingual_denoising.MultilingualDenoisingTask.args.valid_subset.replace", "len", "len", "enumerate", "multilingual_denoising.MultilingualDenoisingTask.source_dictionary.pad", "len", "numpy.array.sum", "numpy.array.sum", "enumerate", "os.listdir", "os.path.isdir", "multilingual_denoising.MultilingualDenoisingTask.source_dictionary.index", "os.path.join", "enumerate", "enumerate"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.utils.get_whole_word_mask", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.load_indexed_dataset", "home.repos.pwc.inspect_result.reneeye_const.tasks.multilingual_denoising.MultilingualDenoisingTask._get_sample_prob", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.numpy_seed", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.index", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.index"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "1", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n        \"\"\"", "\n", "paths", "=", "self", ".", "args", ".", "data", ".", "split", "(", "\":\"", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "data_path", "=", "paths", "[", "(", "epoch", "-", "1", ")", "%", "len", "(", "paths", ")", "]", "\n", "split_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "split", ")", "\n", "\n", "if", "self", ".", "langs", "is", "None", ":", "\n", "            ", "languages", "=", "sorted", "(", "\n", "[", "\n", "name", "\n", "for", "name", "in", "os", ".", "listdir", "(", "data_path", ")", "\n", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "name", ")", ")", "\n", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "languages", "=", "self", ".", "langs", ".", "split", "(", "\",\"", ")", "\n", "for", "name", "in", "languages", ":", "\n", "                ", "p", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "name", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "p", ")", ",", "\"data not found: {}\"", ".", "format", "(", "p", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"Training on {0} languages: {1}\"", ".", "format", "(", "len", "(", "languages", ")", ",", "languages", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"Language to id mapping: \"", ",", "{", "lang", ":", "id", "for", "id", ",", "lang", "in", "enumerate", "(", "languages", ")", "}", "\n", ")", "\n", "\n", "mask_whole_words", "=", "get_whole_word_mask", "(", "self", ".", "args", ",", "self", ".", "dictionary", ")", "\n", "language_without_segmentations", "=", "self", ".", "args", ".", "no_whole_word_mask_langs", ".", "split", "(", "\",\"", ")", "\n", "lang_datasets", "=", "[", "]", "\n", "for", "language", "in", "languages", ":", "\n", "            ", "split_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "language", ",", "split", ")", "\n", "\n", "dataset", "=", "data_utils", ".", "load_indexed_dataset", "(", "\n", "split_path", ",", "\n", "self", ".", "source_dictionary", ",", "\n", "self", ".", "args", ".", "dataset_impl", ",", "\n", "combine", "=", "combine", ",", "\n", ")", "\n", "if", "dataset", "is", "None", ":", "\n", "                ", "raise", "FileNotFoundError", "(", "\n", "\"Dataset not found: {} ({})\"", ".", "format", "(", "split", ",", "split_path", ")", "\n", ")", "\n", "\n", "", "end_token", "=", "(", "\n", "self", ".", "source_dictionary", ".", "index", "(", "\"[{}]\"", ".", "format", "(", "language", ")", ")", "\n", "if", "self", ".", "args", ".", "add_lang_token", "\n", "else", "self", ".", "source_dictionary", ".", "eos", "(", ")", "\n", ")", "\n", "\n", "# create continuous blocks of tokens", "\n", "dataset", "=", "TokenBlockDataset", "(", "\n", "dataset", ",", "\n", "dataset", ".", "sizes", ",", "\n", "self", ".", "args", ".", "tokens_per_sample", "-", "2", ",", "# one less for <s>", "\n", "pad", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", "eos", "=", "end_token", ",", "\n", "break_mode", "=", "self", ".", "args", ".", "sample_break_mode", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"loaded {} blocks from: {}\"", ".", "format", "(", "len", "(", "dataset", ")", ",", "split_path", ")", ")", "\n", "\n", "# prepend beginning-of-sentence token (<s>, equiv. to [CLS] in BERT)", "\n", "dataset", "=", "PrependTokenDataset", "(", "dataset", ",", "self", ".", "source_dictionary", ".", "bos", "(", ")", ")", "\n", "dataset", "=", "AppendTokenDataset", "(", "dataset", ",", "end_token", ")", "\n", "\n", "lang_mask_whole_words", "=", "(", "\n", "mask_whole_words", "\n", "if", "language", "not", "in", "language_without_segmentations", "\n", "else", "None", "\n", ")", "\n", "lang_dataset", "=", "DenoisingDataset", "(", "\n", "dataset", ",", "\n", "dataset", ".", "sizes", ",", "\n", "self", ".", "dictionary", ",", "\n", "self", ".", "mask_idx", ",", "\n", "lang_mask_whole_words", ",", "\n", "shuffle", "=", "self", ".", "args", ".", "shuffle_instance", ",", "\n", "seed", "=", "self", ".", "seed", ",", "\n", "args", "=", "self", ".", "args", ",", "\n", "eos", "=", "None", "\n", "if", "not", "self", ".", "args", ".", "add_lang_token", "\n", "else", "self", ".", "source_dictionary", ".", "index", "(", "\"[{}]\"", ".", "format", "(", "language", ")", ")", ",", "\n", ")", "\n", "lang_datasets", ".", "append", "(", "lang_dataset", ")", "\n", "\n", "", "dataset_lengths", "=", "np", ".", "array", "(", "\n", "[", "len", "(", "d", ")", "for", "d", "in", "lang_datasets", "]", ",", "\n", "dtype", "=", "float", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"loaded total {} blocks for all languages\"", ".", "format", "(", "\n", "int", "(", "dataset_lengths", ".", "sum", "(", ")", ")", ",", "\n", ")", "\n", ")", "\n", "if", "split", "==", "self", ".", "args", ".", "train_subset", ":", "\n", "# For train subset, additionally up or down sample languages.", "\n", "            ", "sample_probs", "=", "self", ".", "_get_sample_prob", "(", "dataset_lengths", ")", "\n", "logger", ".", "info", "(", "\n", "\"Sample probability by language: {}\"", ".", "format", "(", "\n", "{", "\n", "lang", ":", "\"{0:.4f}\"", ".", "format", "(", "sample_probs", "[", "id", "]", ")", "\n", "for", "id", ",", "lang", "in", "enumerate", "(", "languages", ")", "\n", "}", "\n", ")", "\n", ")", "\n", "size_ratio", "=", "(", "sample_probs", "*", "dataset_lengths", ".", "sum", "(", ")", ")", "/", "dataset_lengths", "\n", "logger", ".", "info", "(", "\n", "\"Up/Down Sampling ratio by language: {}\"", ".", "format", "(", "\n", "{", "\n", "lang", ":", "\"{0:.2f}\"", ".", "format", "(", "size_ratio", "[", "id", "]", ")", "\n", "for", "id", ",", "lang", "in", "enumerate", "(", "languages", ")", "\n", "}", "\n", ")", "\n", ")", "\n", "\n", "resampled_lang_datasets", "=", "[", "\n", "ResamplingDataset", "(", "\n", "lang_datasets", "[", "i", "]", ",", "\n", "size_ratio", "=", "size_ratio", "[", "i", "]", ",", "\n", "seed", "=", "self", ".", "args", ".", "seed", ",", "\n", "epoch", "=", "epoch", ",", "\n", "replace", "=", "size_ratio", "[", "i", "]", ">=", "1.0", ",", "\n", ")", "\n", "for", "i", ",", "d", "in", "enumerate", "(", "lang_datasets", ")", "\n", "]", "\n", "dataset", "=", "ConcatDataset", "(", "\n", "resampled_lang_datasets", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "dataset", "=", "ConcatDataset", "(", "lang_datasets", ")", "\n", "lang_splits", "=", "[", "split", "]", "\n", "for", "lang_id", ",", "lang_dataset", "in", "enumerate", "(", "lang_datasets", ")", ":", "\n", "                ", "split_name", "=", "split", "+", "\"_\"", "+", "languages", "[", "lang_id", "]", "\n", "lang_splits", ".", "append", "(", "split_name", ")", "\n", "self", ".", "datasets", "[", "split_name", "]", "=", "lang_dataset", "\n", "\n", "", "if", "split", "in", "self", ".", "args", ".", "valid_subset", ":", "\n", "                ", "self", ".", "args", ".", "valid_subset", "=", "self", ".", "args", ".", "valid_subset", ".", "replace", "(", "\n", "split", ",", "\",\"", ".", "join", "(", "lang_splits", ")", "\n", ")", "\n", "\n", "", "", "with", "data_utils", ".", "numpy_seed", "(", "self", ".", "args", ".", "seed", "+", "epoch", ")", ":", "\n", "            ", "shuffle", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "dataset", ")", ")", "\n", "\n", "", "self", ".", "datasets", "[", "split", "]", "=", "SortDataset", "(", "\n", "dataset", ",", "\n", "sort_order", "=", "[", "\n", "shuffle", ",", "\n", "dataset", ".", "sizes", ",", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.audio_pretraining.LabelEncoder.__init__": [[28, 30], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dictionary", ")", ":", "\n", "        ", "self", ".", "dictionary", "=", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.audio_pretraining.LabelEncoder.__call__": [[31, 34], ["audio_pretraining.LabelEncoder.dictionary.encode_line"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.encode_line"], ["", "def", "__call__", "(", "self", ",", "label", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", ".", "encode_line", "(", "\n", "label", ",", "append_eos", "=", "False", ",", "add_if_not_exist", "=", "False", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.audio_pretraining.AudioPretrainingTask.__init__": [[98, 109], ["FairseqTask.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "cfg", ":", "AudioPretrainingConfig", ",", "\n", "source_dictionary", "=", "None", ",", "\n", "target_dictionary", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ")", "\n", "self", ".", "_target_dictionary", "=", "target_dictionary", "\n", "self", ".", "_source_dictionary", "=", "source_dictionary", "\n", "if", "cfg", ".", "eval_wer", ":", "\n", "            ", "assert", "cfg", ".", "labels", "is", "not", "None", ",", "\"eval_wer can only be set during fine-tuning\"", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.audio_pretraining.AudioPretrainingTask.setup_task": [[110, 125], ["cls", "os.path.join", "fairseq.data.Dictionary.load"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load"], ["", "", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "cfg", ":", "AudioPretrainingConfig", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Setup the task (e.g., load dictionaries).\n\n        Args:\n            cfg (AudioPretrainingConfig): configuration of this task\n        \"\"\"", "\n", "\n", "if", "cfg", ".", "labels", ":", "\n", "            ", "dict_path", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "data", ",", "f\"dict.{cfg.labels}.txt\"", ")", "\n", "target_dictionary", "=", "Dictionary", ".", "load", "(", "dict_path", ")", "\n", "", "else", ":", "\n", "            ", "target_dictionary", "=", "None", "\n", "\n", "", "return", "cls", "(", "cfg", ",", "target_dictionary", "=", "target_dictionary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.audio_pretraining.AudioPretrainingTask.load_dataset": [[126, 163], ["isinstance", "os.path.join", "fairseq.data.FileAudioDataset", "os.path.join", "audio_pretraining.LabelEncoder", "fairseq.data.AddTargetDataset", "hasattr", "open", "labels.append", "audio_pretraining.AudioPretrainingTask.target_dictionary.pad", "audio_pretraining.AudioPretrainingTask.target_dictionary.eos"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "def", "load_dataset", "(", "self", ",", "split", ":", "str", ",", "task_cfg", ":", "FairseqDataclass", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "data_path", "=", "self", ".", "cfg", ".", "data", "\n", "task_cfg", "=", "task_cfg", "or", "self", ".", "cfg", "\n", "\n", "# upgrade old task", "\n", "if", "isinstance", "(", "task_cfg", ",", "Namespace", ")", ":", "\n", "            ", "if", "not", "hasattr", "(", "task_cfg", ",", "\"autoregressive\"", ")", ":", "\n", "                ", "task_cfg", ".", "autoregressive", "=", "not", "task_cfg", ".", "criterion", "==", "'ctc'", "\n", "\n", "", "", "manifest", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"{}.tsv\"", ".", "format", "(", "split", ")", ")", "\n", "self", ".", "datasets", "[", "split", "]", "=", "FileAudioDataset", "(", "\n", "manifest", ",", "\n", "sample_rate", "=", "task_cfg", ".", "sample_rate", ",", "\n", "max_sample_size", "=", "self", ".", "cfg", ".", "max_sample_size", ",", "\n", "min_sample_size", "=", "self", ".", "cfg", ".", "max_sample_size", ",", "\n", "min_length", "=", "self", ".", "cfg", ".", "min_sample_size", ",", "\n", "pad", "=", "task_cfg", ".", "labels", "is", "not", "None", "or", "task_cfg", ".", "enable_padding", ",", "\n", "normalize", "=", "task_cfg", ".", "normalize", ",", "\n", ")", "\n", "\n", "if", "task_cfg", ".", "labels", ":", "\n", "            ", "label_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "f\"{split}.{task_cfg.labels}\"", ")", "\n", "labels", "=", "[", "]", "\n", "with", "open", "(", "label_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "for", "line", "in", "f", ":", "\n", "                    ", "labels", ".", "append", "(", "line", ")", "\n", "\n", "", "", "process_label", "=", "LabelEncoder", "(", "self", ".", "target_dictionary", ")", "\n", "\n", "self", ".", "datasets", "[", "split", "]", "=", "AddTargetDataset", "(", "\n", "self", ".", "datasets", "[", "split", "]", ",", "\n", "labels", ",", "\n", "pad", "=", "self", ".", "target_dictionary", ".", "pad", "(", ")", ",", "\n", "eos", "=", "self", ".", "target_dictionary", ".", "eos", "(", ")", ",", "\n", "batch_targets", "=", "True", ",", "\n", "process_label", "=", "process_label", ",", "\n", "add_to_input", "=", "task_cfg", ".", "autoregressive", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.audio_pretraining.AudioPretrainingTask.source_dictionary": [[165, 168], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_source_dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.audio_pretraining.AudioPretrainingTask.target_dictionary": [[169, 174], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the :class:`~fairseq.data.Dictionary` for the language\n        model.\"\"\"", "\n", "return", "self", ".", "_target_dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.audio_pretraining.AudioPretrainingTask.max_positions": [[175, 178], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum input length supported by the encoder.\"\"\"", "\n", "return", "(", "sys", ".", "maxsize", ",", "sys", ".", "maxsize", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.audio_pretraining.AudioPretrainingTask.filter_indices_by_size": [[179, 188], ["None"], "methods", ["None"], ["", "def", "filter_indices_by_size", "(", "\n", "self", ",", "\n", "indices", ",", "\n", "dataset", ",", "\n", "max_positions", "=", "None", ",", "\n", "ignore_invalid_inputs", "=", "False", ",", "\n", ")", ":", "\n", "# we do not need to filter by size in this task as dataloaders take care of this", "\n", "        ", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.audio_pretraining.AudioPretrainingTask.valid_step": [[189, 198], ["super().valid_step", "audio_pretraining.AudioPretrainingTask._inference_with_wer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.valid_step", "home.repos.pwc.inspect_result.reneeye_const.tasks.audio_pretraining.AudioPretrainingTask._inference_with_wer"], ["", "def", "valid_step", "(", "self", ",", "sample", ",", "model", ",", "criterion", ")", ":", "\n", "        ", "loss", ",", "sample_size", ",", "logging_output", "=", "super", "(", ")", ".", "valid_step", "(", "sample", ",", "model", ",", "criterion", ")", "\n", "if", "self", ".", "cfg", ".", "eval_wer", "and", "self", ".", "cfg", ".", "autoregressive", ":", "\n", "            ", "metrics", "=", "self", ".", "_inference_with_wer", "(", "self", ".", "sequence_generator", ",", "sample", ",", "model", ")", "\n", "logging_output", "[", "\"_num_char_errors\"", "]", "=", "metrics", "[", "\"num_char_errors\"", "]", "\n", "logging_output", "[", "\"_num_chars\"", "]", "=", "metrics", "[", "\"num_chars\"", "]", "\n", "logging_output", "[", "\"_num_word_errors\"", "]", "=", "metrics", "[", "\"num_word_errors\"", "]", "\n", "logging_output", "[", "\"_num_words\"", "]", "=", "metrics", "[", "\"num_words\"", "]", "\n", "", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.audio_pretraining.AudioPretrainingTask.build_model": [[199, 212], ["super().build_model", "audio_pretraining.AudioPretrainingTask.build_generator", "fairseq.data.encoders.build_tokenizer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.build_generator", "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.build_tokenizer"], ["", "def", "build_model", "(", "self", ",", "model_cfg", ":", "FairseqDataclass", ")", ":", "\n", "        ", "model", "=", "super", "(", ")", ".", "build_model", "(", "model_cfg", ")", "\n", "\n", "if", "self", ".", "cfg", ".", "eval_wer", "and", "self", ".", "cfg", ".", "autoregressive", ":", "\n", "            ", "self", ".", "sequence_generator", "=", "self", ".", "build_generator", "(", "\n", "[", "model", "]", ",", "\n", "self", ".", "cfg", ".", "eval_wer_config", ",", "\n", ")", "\n", "if", "self", ".", "cfg", ".", "eval_wer_tokenizer", ":", "\n", "                ", "self", ".", "tokenizer", "=", "encoders", ".", "build_tokenizer", "(", "self", ".", "cfg", ".", "eval_wer_tokenizer", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "tokenizer", "=", "None", "\n", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.audio_pretraining.AudioPretrainingTask._inference_with_wer": [[213, 246], ["audio_pretraining.AudioPretrainingTask.inference_step", "range", "audio_pretraining.AudioPretrainingTask.target_dictionary.string", "len", "audio_pretraining.AudioPretrainingTask._inference_with_wer.decode"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.inference_step", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "_inference_with_wer", "(", "self", ",", "generator", ",", "sample", ",", "model", ")", ":", "\n", "        ", "import", "editdistance", "\n", "\n", "def", "decode", "(", "toks", ")", ":", "\n", "            ", "s", "=", "self", ".", "target_dictionary", ".", "string", "(", "\n", "toks", ".", "int", "(", ")", ".", "cpu", "(", ")", ",", "\n", "self", ".", "cfg", ".", "eval_wer_post_process", ",", "\n", "escape_unk", "=", "True", ",", "\n", ")", "\n", "if", "self", ".", "tokenizer", ":", "\n", "                ", "s", "=", "self", ".", "tokenizer", ".", "decode", "(", "s", ")", "\n", "", "return", "s", "\n", "\n", "", "num_word_errors", ",", "num_char_errors", "=", "0", ",", "0", "\n", "num_chars", ",", "num_words", "=", "0", ",", "0", "\n", "gen_out", "=", "self", ".", "inference_step", "(", "generator", ",", "[", "model", "]", ",", "sample", ",", "None", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "gen_out", ")", ")", ":", "\n", "            ", "hyp", "=", "decode", "(", "gen_out", "[", "i", "]", "[", "0", "]", "[", "\"tokens\"", "]", ")", "\n", "ref", "=", "decode", "(", "\n", "utils", ".", "strip_pad", "(", "sample", "[", "\"target\"", "]", "[", "i", "]", ",", "self", ".", "target_dictionary", ".", "pad", "(", ")", ")", ",", "\n", ")", "\n", "num_char_errors", "+=", "editdistance", ".", "eval", "(", "hyp", ",", "ref", ")", "\n", "num_chars", "+=", "len", "(", "ref", ")", "\n", "hyp_words", "=", "hyp", ".", "split", "(", ")", "\n", "ref_words", "=", "ref", ".", "split", "(", ")", "\n", "num_word_errors", "+=", "editdistance", ".", "eval", "(", "hyp_words", ",", "ref_words", ")", "\n", "num_words", "+=", "len", "(", "ref_words", ")", "\n", "\n", "", "return", "{", "\n", "\"num_char_errors\"", ":", "num_char_errors", ",", "\n", "\"num_chars\"", ":", "num_chars", ",", "\n", "\"num_word_errors\"", ":", "num_word_errors", ",", "\n", "\"num_words\"", ":", "num_words", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.audio_pretraining.AudioPretrainingTask.reduce_metrics": [[248, 280], ["super().reduce_metrics", "torch.scalar_tensor", "sum", "sum", "sum", "sum", "logging.metrics.log_scalar", "logging.metrics.log_scalar", "logging.metrics.log_scalar", "logging.metrics.log_scalar", "logging.metrics.log_derived", "logging.metrics.log_derived", "log.get", "log.get", "log.get", "log.get", "float", "float"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.reduce_metrics", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived"], ["", "def", "reduce_metrics", "(", "self", ",", "logging_outputs", ",", "criterion", ")", ":", "\n", "        ", "super", "(", ")", ".", "reduce_metrics", "(", "logging_outputs", ",", "criterion", ")", "\n", "\n", "zero", "=", "torch", ".", "scalar_tensor", "(", "0.0", ")", "\n", "num_char_errors", "=", "sum", "(", "\n", "log", ".", "get", "(", "\"_num_char_errors\"", ",", "zero", ")", "for", "log", "in", "logging_outputs", "\n", ")", "\n", "num_chars", "=", "sum", "(", "log", ".", "get", "(", "\"_num_chars\"", ",", "zero", ")", "for", "log", "in", "logging_outputs", ")", "\n", "num_word_errors", "=", "sum", "(", "\n", "log", ".", "get", "(", "\"_num_word_errors\"", ",", "zero", ")", "for", "log", "in", "logging_outputs", "\n", ")", "\n", "num_words", "=", "sum", "(", "log", ".", "get", "(", "\"_num_words\"", ",", "zero", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_num_char_errors\"", ",", "num_char_errors", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_num_chars\"", ",", "num_chars", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_num_word_errors\"", ",", "num_word_errors", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_num_words\"", ",", "num_words", ")", "\n", "if", "num_words", ">", "0", ":", "\n", "            ", "metrics", ".", "log_derived", "(", "\n", "\"uer\"", ",", "\n", "lambda", "meters", ":", "meters", "[", "\"_num_char_errors\"", "]", ".", "sum", "\n", "*", "100.0", "\n", "/", "meters", "[", "\"_num_chars\"", "]", ".", "sum", "\n", "if", "meters", "[", "\"_num_chars\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", "\n", "metrics", ".", "log_derived", "(", "\n", "\"wer\"", ",", "\n", "lambda", "meters", ":", "meters", "[", "\"_num_word_errors\"", "]", ".", "sum", "\n", "*", "100.0", "\n", "/", "meters", "[", "\"_num_words\"", "]", ".", "sum", "\n", "if", "meters", "[", "\"_num_words\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_ranking.SentenceRankingTask.add_args": [[41, 71], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "parser", ".", "add_argument", "(", "\"data\"", ",", "metavar", "=", "\"FILE\"", ",", "help", "=", "\"file prefix for data\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num-classes\"", ",", "type", "=", "int", ",", "help", "=", "\"number of sentences to be ranked\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--init-token\"", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"add token at the beginning of each batch item\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--separator-token\"", ",", "type", "=", "int", ",", "help", "=", "\"add separator token between inputs\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--no-shuffle\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--shorten-method\"", ",", "\n", "default", "=", "\"none\"", ",", "\n", "choices", "=", "[", "\"none\"", ",", "\"truncate\"", ",", "\"random_crop\"", "]", ",", "\n", "help", "=", "\"if not none, shorten sequences that exceed --tokens-per-sample\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--shorten-data-split-list\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "help", "=", "\"comma-separated list of dataset splits to apply shortening to, \"", "\n", "'e.g., \"train,valid\" (default: all dataset splits)'", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max-option-length\"", ",", "type", "=", "int", ",", "help", "=", "\"max length for each option\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_ranking.SentenceRankingTask.__init__": [[73, 76], ["fairseq.tasks.LegacyFairseqTask.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["", "def", "__init__", "(", "self", ",", "args", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_ranking.SentenceRankingTask.load_dictionary": [[77, 87], ["fairseq.data.Dictionary.load", "fairseq.data.Dictionary.load.add_symbol"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol"], ["", "@", "classmethod", "\n", "def", "load_dictionary", "(", "cls", ",", "args", ",", "filename", ",", "source", "=", "True", ")", ":", "\n", "        ", "\"\"\"Load the dictionary from the filename\n\n        Args:\n            filename (str): the filename\n        \"\"\"", "\n", "dictionary", "=", "Dictionary", ".", "load", "(", "filename", ")", "\n", "dictionary", ".", "add_symbol", "(", "\"<mask>\"", ")", "\n", "return", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_ranking.SentenceRankingTask.setup_task": [[88, 102], ["cls.load_dictionary", "logger.info", "sentence_ranking.SentenceRankingTask", "os.path.join", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_prediction.SentencePredictionTask.load_dictionary"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "(", "\n", "args", ".", "criterion", "==", "\"sentence_ranking\"", "\n", ")", ",", "\"Must set --criterion=sentence_ranking\"", "\n", "\n", "# load data dictionary", "\n", "data_dict", "=", "cls", ".", "load_dictionary", "(", "\n", "args", ",", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "data", ",", "\"input0\"", ",", "\"dict.txt\"", ")", ",", "\n", "source", "=", "True", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"[input] dictionary: {} types\"", ".", "format", "(", "len", "(", "data_dict", ")", ")", ")", "\n", "return", "SentenceRankingTask", "(", "args", ",", "data_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_ranking.SentenceRankingTask.load_dataset": [[103, 197], ["sentence_ranking.SentenceRankingTask.load_dataset.make_dataset"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.make_dataset"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split (e.g., train, valid, test).\"\"\"", "\n", "\n", "def", "get_path", "(", "type", ",", "split", ")", ":", "\n", "            ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "data", ",", "type", ",", "split", ")", "\n", "\n", "", "def", "make_dataset", "(", "type", ",", "dictionary", ")", ":", "\n", "            ", "split_path", "=", "get_path", "(", "type", ",", "split", ")", "\n", "\n", "dataset", "=", "data_utils", ".", "load_indexed_dataset", "(", "\n", "split_path", ",", "\n", "self", ".", "source_dictionary", ",", "\n", "self", ".", "args", ".", "dataset_impl", ",", "\n", "combine", "=", "combine", ",", "\n", ")", "\n", "return", "dataset", "\n", "\n", "", "input0", "=", "make_dataset", "(", "\"input0\"", ",", "self", ".", "source_dictionary", ")", "\n", "input_options", "=", "[", "\n", "make_dataset", "(", "\"input{idx}\"", ".", "format", "(", "idx", "=", "idx", "+", "1", ")", ",", "self", ".", "source_dictionary", ")", "\n", "for", "idx", "in", "range", "(", "self", ".", "args", ".", "num_classes", ")", "\n", "]", "\n", "\n", "if", "self", ".", "args", ".", "separator_token", "is", "not", "None", ":", "\n", "            ", "input0", "=", "PrependTokenDataset", "(", "input0", ",", "self", ".", "args", ".", "separator_token", ")", "\n", "\n", "", "src_tokens", "=", "[", "]", "\n", "for", "input_option", "in", "input_options", ":", "\n", "            ", "if", "self", ".", "args", ".", "init_token", "is", "not", "None", ":", "\n", "                ", "input_option", "=", "PrependTokenDataset", "(", "input_option", ",", "self", ".", "args", ".", "init_token", ")", "\n", "", "if", "self", ".", "args", ".", "max_option_length", "is", "not", "None", ":", "\n", "                ", "input_option", "=", "TruncateDataset", "(", "\n", "input_option", ",", "self", ".", "args", ".", "max_option_length", "\n", ")", "\n", "", "src_token", "=", "ConcatSentencesDataset", "(", "input_option", ",", "input0", ")", "\n", "src_token", "=", "maybe_shorten_dataset", "(", "\n", "src_token", ",", "\n", "split", ",", "\n", "self", ".", "args", ".", "shorten_data_split_list", ",", "\n", "self", ".", "args", ".", "shorten_method", ",", "\n", "self", ".", "args", ".", "max_positions", ",", "\n", "self", ".", "args", ".", "seed", ",", "\n", ")", "\n", "src_tokens", ".", "append", "(", "src_token", ")", "\n", "\n", "", "with", "data_utils", ".", "numpy_seed", "(", "self", ".", "args", ".", "seed", ")", ":", "\n", "            ", "shuffle", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "src_tokens", "[", "0", "]", ")", ")", "\n", "\n", "", "dataset", "=", "{", "\n", "\"id\"", ":", "IdDataset", "(", ")", ",", "\n", "\"nsentences\"", ":", "NumSamplesDataset", "(", ")", ",", "\n", "\"ntokens\"", ":", "NumelDataset", "(", "src_tokens", "[", "0", "]", ",", "reduce", "=", "True", ")", ",", "\n", "}", "\n", "\n", "for", "src_token_idx", "in", "range", "(", "len", "(", "src_tokens", ")", ")", ":", "\n", "            ", "dataset", ".", "update", "(", "\n", "{", "\n", "\"net_input{idx}\"", ".", "format", "(", "idx", "=", "src_token_idx", "+", "1", ")", ":", "{", "\n", "\"src_tokens\"", ":", "RightPadDataset", "(", "\n", "src_tokens", "[", "src_token_idx", "]", ",", "\n", "pad_idx", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", ")", ",", "\n", "\"src_lengths\"", ":", "NumelDataset", "(", "\n", "src_tokens", "[", "src_token_idx", "]", ",", "reduce", "=", "False", "\n", ")", ",", "\n", "}", "\n", "}", "\n", ")", "\n", "\n", "", "label_path", "=", "\"{}.label\"", ".", "format", "(", "get_path", "(", "\"label\"", ",", "split", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "label_path", ")", ":", "\n", "            ", "with", "open", "(", "label_path", ")", "as", "h", ":", "\n", "                ", "dataset", ".", "update", "(", "\n", "target", "=", "RawLabelDataset", "(", "[", "int", "(", "x", ".", "strip", "(", ")", ")", "for", "x", "in", "h", ".", "readlines", "(", ")", "]", ")", "\n", ")", "\n", "\n", "", "", "nested_dataset", "=", "NestedDictionaryDataset", "(", "\n", "dataset", ",", "\n", "sizes", "=", "[", "np", ".", "maximum", ".", "reduce", "(", "[", "src_token", ".", "sizes", "for", "src_token", "in", "src_tokens", "]", ")", "]", ",", "\n", ")", "\n", "\n", "if", "self", ".", "args", ".", "no_shuffle", ":", "\n", "            ", "dataset", "=", "nested_dataset", "\n", "", "else", ":", "\n", "            ", "dataset", "=", "SortDataset", "(", "\n", "nested_dataset", ",", "\n", "# shuffle", "\n", "sort_order", "=", "[", "shuffle", "]", ",", "\n", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Loaded {0} with #samples: {1}\"", ".", "format", "(", "split", ",", "len", "(", "dataset", ")", ")", ")", "\n", "\n", "self", ".", "datasets", "[", "split", "]", "=", "dataset", "\n", "return", "self", ".", "datasets", "[", "split", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_ranking.SentenceRankingTask.build_model": [[198, 209], ["models.build_model", "models.build_model.register_classification_head", "getattr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model", "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaModel.register_classification_head"], ["", "def", "build_model", "(", "self", ",", "args", ")", ":", "\n", "        ", "from", "fairseq", "import", "models", "\n", "\n", "model", "=", "models", ".", "build_model", "(", "args", ",", "self", ")", "\n", "\n", "model", ".", "register_classification_head", "(", "\n", "getattr", "(", "args", ",", "\"ranking_head_name\"", ",", "\"sentence_classification_head\"", ")", ",", "\n", "num_classes", "=", "1", ",", "\n", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_ranking.SentenceRankingTask.max_positions": [[210, 212], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "args", ".", "max_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_ranking.SentenceRankingTask.source_dictionary": [[213, 216], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_ranking.SentenceRankingTask.target_dictionary": [[217, 220], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.tasks.__init__.setup_task": [[24, 45], ["getattr", "isinstance", "task.setup_task", "getattr", "fairseq.dataclass.utils.populate_dataclass", "fairseq.dataclass.utils.merge_with_parent", "dc", "dc"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyMTTask.setup_task", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.populate_dataclass", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.merge_with_parent"], []], "home.repos.pwc.inspect_result.reneeye_const.tasks.__init__.register_task": [[47, 100], ["TASK_CLASS_NAMES.add", "ValueError", "issubclass", "ValueError", "ValueError", "ValueError", "hydra.core.config_store.ConfigStore.instance", "dataclass", "ConfigStore.instance.store", "issubclass"], "function", ["home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add"], []], "home.repos.pwc.inspect_result.reneeye_const.tasks.__init__.get_task": [[102, 104], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_prediction.SentencePredictionTask.add_args": [[43, 84], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "parser", ".", "add_argument", "(", "\"data\"", ",", "metavar", "=", "\"FILE\"", ",", "help", "=", "\"file prefix for data\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num-classes\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "-", "1", ",", "\n", "help", "=", "\"number of classes or regression targets\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--init-token\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"add token at the beginning of each batch item\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--separator-token\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"add separator token between inputs\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--regression-target\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--no-shuffle\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--shorten-method\"", ",", "\n", "default", "=", "\"none\"", ",", "\n", "choices", "=", "[", "\"none\"", ",", "\"truncate\"", ",", "\"random_crop\"", "]", ",", "\n", "help", "=", "\"if not none, shorten sequences that exceed --tokens-per-sample\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--shorten-data-split-list\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "help", "=", "\"comma-separated list of dataset splits to apply shortening to, \"", "\n", "'e.g., \"train,valid\" (default: all dataset splits)'", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--add-prev-output-tokens\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"add prev_output_tokens to sample, used for encoder-decoder arch\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_prediction.SentencePredictionTask.__init__": [[86, 98], ["fairseq.tasks.LegacyFairseqTask.__init__", "hasattr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["", "def", "__init__", "(", "self", ",", "args", ",", "data_dictionary", ",", "label_dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "dictionary", "=", "data_dictionary", "\n", "self", ".", "_label_dictionary", "=", "label_dictionary", "\n", "if", "not", "hasattr", "(", "args", ",", "\"max_positions\"", ")", ":", "\n", "            ", "self", ".", "_max_positions", "=", "(", "\n", "args", ".", "max_source_positions", ",", "\n", "args", ".", "max_target_positions", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_max_positions", "=", "args", ".", "max_positions", "\n", "", "args", ".", "tokens_per_sample", "=", "self", ".", "_max_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_prediction.SentencePredictionTask.load_dictionary": [[99, 109], ["fairseq.data.Dictionary.load", "fairseq.data.Dictionary.load.add_symbol"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol"], ["", "@", "classmethod", "\n", "def", "load_dictionary", "(", "cls", ",", "args", ",", "filename", ",", "source", "=", "True", ")", ":", "\n", "        ", "\"\"\"Load the dictionary from the filename\n\n        Args:\n            filename (str): the filename\n        \"\"\"", "\n", "dictionary", "=", "Dictionary", ".", "load", "(", "filename", ")", "\n", "dictionary", ".", "add_symbol", "(", "\"<mask>\"", ")", "\n", "return", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_prediction.SentencePredictionTask.setup_task": [[110, 134], ["cls.load_dictionary", "logger.info", "cls", "os.path.join", "cls.load_dictionary", "logger.info", "len", "os.path.join", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_prediction.SentencePredictionTask.load_dictionary", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls", "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_prediction.SentencePredictionTask.load_dictionary"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "args", ".", "num_classes", ">", "0", ",", "\"Must set --num-classes\"", "\n", "\n", "# load data dictionary", "\n", "data_dict", "=", "cls", ".", "load_dictionary", "(", "\n", "args", ",", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "data", ",", "\"input0\"", ",", "\"dict.txt\"", ")", ",", "\n", "source", "=", "True", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"[input] dictionary: {} types\"", ".", "format", "(", "len", "(", "data_dict", ")", ")", ")", "\n", "\n", "label_dict", "=", "None", "\n", "if", "not", "args", ".", "regression_target", ":", "\n", "# load label dictionary", "\n", "            ", "label_dict", "=", "cls", ".", "load_dictionary", "(", "\n", "args", ",", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "data", ",", "\"label\"", ",", "\"dict.txt\"", ")", ",", "\n", "source", "=", "False", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"[label] dictionary: {} types\"", ".", "format", "(", "len", "(", "label_dict", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "label_dict", "=", "data_dict", "\n", "", "return", "cls", "(", "args", ",", "data_dict", ",", "label_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_prediction.SentencePredictionTask.load_dataset": [[135, 254], ["sentence_prediction.SentencePredictionTask.load_dataset.make_dataset"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.make_dataset"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split (e.g., train, valid, test).\"\"\"", "\n", "\n", "def", "get_path", "(", "key", ",", "split", ")", ":", "\n", "            ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "data", ",", "key", ",", "split", ")", "\n", "\n", "", "def", "make_dataset", "(", "key", ",", "dictionary", ")", ":", "\n", "            ", "split_path", "=", "get_path", "(", "key", ",", "split", ")", "\n", "\n", "dataset", "=", "data_utils", ".", "load_indexed_dataset", "(", "\n", "split_path", ",", "\n", "dictionary", ",", "\n", "self", ".", "args", ".", "dataset_impl", ",", "\n", "combine", "=", "combine", ",", "\n", ")", "\n", "return", "dataset", "\n", "\n", "", "input0", "=", "make_dataset", "(", "\"input0\"", ",", "self", ".", "source_dictionary", ")", "\n", "assert", "input0", "is", "not", "None", ",", "\"could not find dataset: {}\"", ".", "format", "(", "\n", "get_path", "(", "\"input0\"", ",", "split", ")", "\n", ")", "\n", "input1", "=", "make_dataset", "(", "\"input1\"", ",", "self", ".", "source_dictionary", ")", "\n", "\n", "if", "self", ".", "args", ".", "init_token", "is", "not", "None", ":", "\n", "            ", "input0", "=", "PrependTokenDataset", "(", "input0", ",", "self", ".", "args", ".", "init_token", ")", "\n", "\n", "", "if", "input1", "is", "None", ":", "\n", "            ", "src_tokens", "=", "input0", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "args", ".", "separator_token", "is", "not", "None", ":", "\n", "                ", "input1", "=", "PrependTokenDataset", "(", "input1", ",", "self", ".", "args", ".", "separator_token", ")", "\n", "\n", "", "src_tokens", "=", "ConcatSentencesDataset", "(", "input0", ",", "input1", ")", "\n", "\n", "", "with", "data_utils", ".", "numpy_seed", "(", "self", ".", "args", ".", "seed", ")", ":", "\n", "            ", "shuffle", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "src_tokens", ")", ")", "\n", "\n", "", "src_tokens", "=", "maybe_shorten_dataset", "(", "\n", "src_tokens", ",", "\n", "split", ",", "\n", "self", ".", "args", ".", "shorten_data_split_list", ",", "\n", "self", ".", "args", ".", "shorten_method", ",", "\n", "self", ".", "args", ".", "max_positions", ",", "\n", "self", ".", "args", ".", "seed", ",", "\n", ")", "\n", "\n", "dataset", "=", "{", "\n", "\"id\"", ":", "IdDataset", "(", ")", ",", "\n", "\"net_input\"", ":", "{", "\n", "\"src_tokens\"", ":", "RightPadDataset", "(", "\n", "src_tokens", ",", "\n", "pad_idx", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", ")", ",", "\n", "\"src_lengths\"", ":", "NumelDataset", "(", "src_tokens", ",", "reduce", "=", "False", ")", ",", "\n", "}", ",", "\n", "\"nsentences\"", ":", "NumSamplesDataset", "(", ")", ",", "\n", "\"ntokens\"", ":", "NumelDataset", "(", "src_tokens", ",", "reduce", "=", "True", ")", ",", "\n", "}", "\n", "\n", "if", "self", ".", "args", ".", "add_prev_output_tokens", ":", "\n", "            ", "prev_tokens_dataset", "=", "RightPadDataset", "(", "\n", "RollDataset", "(", "src_tokens", ",", "1", ")", ",", "\n", "pad_idx", "=", "self", ".", "dictionary", ".", "pad", "(", ")", ",", "\n", ")", "\n", "dataset", "[", "\"net_input\"", "]", ".", "update", "(", "\n", "prev_output_tokens", "=", "prev_tokens_dataset", ",", "\n", ")", "\n", "\n", "", "if", "not", "self", ".", "args", ".", "regression_target", ":", "\n", "            ", "label_dataset", "=", "make_dataset", "(", "\"label\"", ",", "self", ".", "label_dictionary", ")", "\n", "if", "label_dataset", "is", "not", "None", ":", "\n", "                ", "dataset", ".", "update", "(", "\n", "target", "=", "OffsetTokensDataset", "(", "\n", "StripTokenDataset", "(", "\n", "label_dataset", ",", "\n", "id_to_strip", "=", "self", ".", "label_dictionary", ".", "eos", "(", ")", ",", "\n", ")", ",", "\n", "offset", "=", "-", "self", ".", "label_dictionary", ".", "nspecial", ",", "\n", ")", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "label_path", "=", "\"{0}.label\"", ".", "format", "(", "get_path", "(", "\"label\"", ",", "split", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "label_path", ")", ":", "\n", "\n", "                ", "def", "parse_regression_target", "(", "i", ",", "line", ")", ":", "\n", "                    ", "values", "=", "line", ".", "split", "(", ")", "\n", "assert", "(", "\n", "len", "(", "values", ")", "==", "self", ".", "args", ".", "num_classes", "\n", ")", ",", "f'expected num_classes={self.args.num_classes} regression target values on line {i}, found: \"{line}\"'", "\n", "return", "[", "float", "(", "x", ")", "for", "x", "in", "values", "]", "\n", "\n", "", "with", "open", "(", "label_path", ")", "as", "h", ":", "\n", "                    ", "dataset", ".", "update", "(", "\n", "target", "=", "RawLabelDataset", "(", "\n", "[", "\n", "parse_regression_target", "(", "i", ",", "line", ".", "strip", "(", ")", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "h", ".", "readlines", "(", ")", ")", "\n", "]", "\n", ")", "\n", ")", "\n", "\n", "", "", "", "nested_dataset", "=", "NestedDictionaryDataset", "(", "\n", "dataset", ",", "\n", "sizes", "=", "[", "src_tokens", ".", "sizes", "]", ",", "\n", ")", "\n", "\n", "if", "self", ".", "args", ".", "no_shuffle", ":", "\n", "            ", "dataset", "=", "nested_dataset", "\n", "", "else", ":", "\n", "            ", "dataset", "=", "SortDataset", "(", "\n", "nested_dataset", ",", "\n", "# shuffle", "\n", "sort_order", "=", "[", "shuffle", "]", ",", "\n", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Loaded {0} with #samples: {1}\"", ".", "format", "(", "split", ",", "len", "(", "dataset", ")", ")", ")", "\n", "\n", "self", ".", "datasets", "[", "split", "]", "=", "dataset", "\n", "return", "self", ".", "datasets", "[", "split", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_prediction.SentencePredictionTask.build_model": [[255, 266], ["models.build_model", "models.build_model.register_classification_head", "getattr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model", "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaModel.register_classification_head"], ["", "def", "build_model", "(", "self", ",", "args", ")", ":", "\n", "        ", "from", "fairseq", "import", "models", "\n", "\n", "model", "=", "models", ".", "build_model", "(", "args", ",", "self", ")", "\n", "\n", "model", ".", "register_classification_head", "(", "\n", "getattr", "(", "args", ",", "\"classification_head_name\"", ",", "\"sentence_classification_head\"", ")", ",", "\n", "num_classes", "=", "self", ".", "args", ".", "num_classes", ",", "\n", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_prediction.SentencePredictionTask.max_positions": [[267, 269], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_max_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_prediction.SentencePredictionTask.source_dictionary": [[270, 273], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_prediction.SentencePredictionTask.target_dictionary": [[274, 277], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.sentence_prediction.SentencePredictionTask.label_dictionary": [[278, 281], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "label_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_label_dictionary", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.add_args": [[62, 78], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "fairseq.data.multilingual.sampling_method.SamplingMethod.add_arguments", "fairseq.data.multilingual.multilingual_data_manager.MultilingualDatasetManager.add_args"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampling_method.SamplingMethod.add_arguments", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args"], ["@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'-s'", ",", "'--source-lang'", ",", "default", "=", "None", ",", "metavar", "=", "'SRC'", ",", "\n", "help", "=", "'inference source language'", ")", "\n", "parser", ".", "add_argument", "(", "'-t'", ",", "'--target-lang'", ",", "default", "=", "None", ",", "metavar", "=", "'TARGET'", ",", "\n", "help", "=", "'inference target language'", ")", "\n", "parser", ".", "add_argument", "(", "'--lang-pairs'", ",", "default", "=", "None", ",", "metavar", "=", "'PAIRS'", ",", "\n", "help", "=", "'comma-separated list of language pairs (in training order): en-de,en-fr,de-fr'", ",", "\n", "action", "=", "FileContentsAction", ")", "\n", "parser", ".", "add_argument", "(", "'--keep-inference-langtok'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'keep language tokens in inference output (e.g. for analysis or debugging)'", ")", "\n", "\n", "SamplingMethod", ".", "add_arguments", "(", "parser", ")", "\n", "MultilingualDatasetManager", ".", "add_args", "(", "parser", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.__init__": [[80, 106], ["fairseq.tasks.LegacyFairseqTask.__init__", "translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.check_dicts", "fairseq.data.multilingual.sampling_method.SamplingMethod.build_sampler", "fairseq.data.multilingual.multilingual_data_manager.MultilingualDatasetManager.setup_data_manager", "d.split", "d.split"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.check_dicts", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampling_method.SamplingMethod.build_sampler", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.setup_data_manager"], ["", "def", "__init__", "(", "self", ",", "args", ",", "langs", ",", "dicts", ",", "training", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "langs", "=", "langs", "\n", "self", ".", "dicts", "=", "dicts", "\n", "self", ".", "training", "=", "training", "\n", "if", "training", ":", "\n", "            ", "self", ".", "lang_pairs", "=", "args", ".", "lang_pairs", "\n", "", "else", ":", "\n", "            ", "self", ".", "lang_pairs", "=", "[", "\"{}-{}\"", ".", "format", "(", "args", ".", "source_lang", ",", "args", ".", "target_lang", ")", "]", "\n", "# eval_lang_pairs for multilingual translation is usually all of the", "\n", "# lang_pairs. However for other multitask settings or when we want to", "\n", "# optimize for certain languages we want to use a different subset. Thus", "\n", "# the eval_lang_pairs class variable is provided for classes that extend", "\n", "# this class.", "\n", "", "self", ".", "eval_lang_pairs", "=", "self", ".", "lang_pairs", "\n", "# model_lang_pairs will be used to build encoder-decoder model pairs in", "\n", "# models.build_model(). This allows multitask type of sub-class can", "\n", "# build models other than the input lang_pairs", "\n", "self", ".", "model_lang_pairs", "=", "self", ".", "lang_pairs", "\n", "self", ".", "source_langs", "=", "[", "d", ".", "split", "(", "\"-\"", ")", "[", "0", "]", "for", "d", "in", "self", ".", "lang_pairs", "]", "\n", "self", ".", "target_langs", "=", "[", "d", ".", "split", "(", "\"-\"", ")", "[", "1", "]", "for", "d", "in", "self", ".", "lang_pairs", "]", "\n", "self", ".", "check_dicts", "(", "self", ".", "dicts", ",", "self", ".", "source_langs", ",", "self", ".", "target_langs", ")", "\n", "\n", "self", ".", "sampling_method", "=", "SamplingMethod", ".", "build_sampler", "(", "args", ",", "self", ")", "\n", "self", ".", "data_manager", "=", "MultilingualDatasetManager", ".", "setup_data_manager", "(", "\n", "args", ",", "self", ".", "lang_pairs", ",", "langs", ",", "dicts", ",", "self", ".", "sampling_method", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.check_dicts": [[108, 122], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "check_dicts", "(", "cls", ",", "dicts", ",", "source_langs", ",", "target_langs", ")", ":", "\n", "        ", "src_dict", "=", "dicts", "[", "source_langs", "[", "0", "]", "]", "\n", "tgt_dict", "=", "dicts", "[", "target_langs", "[", "0", "]", "]", "\n", "for", "src_lang", "in", "source_langs", ":", "\n", "            ", "assert", "(", "\n", "src_dict", "==", "dicts", "[", "src_lang", "]", "\n", ")", ",", "\"Diffrent dictionary are specified for different source languages; \"", "\n", "\"TranslationMultiSimpleEpochTask only supports one shared dictionary across all source languages\"", "\n", "", "for", "tgt_lang", "in", "target_langs", ":", "\n", "            ", "assert", "(", "\n", "tgt_dict", "==", "dicts", "[", "tgt_lang", "]", "\n", ")", ",", "\"Diffrent dictionary are specified for different target languages; \"", "\n", "\"TranslationMultiSimpleEpochTask only supports one shared dictionary across all target languages\"", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.setup_task": [[123, 129], ["fairseq.data.multilingual.multilingual_data_manager.MultilingualDatasetManager.prepare", "cls"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.prepare", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "langs", ",", "dicts", ",", "training", "=", "MultilingualDatasetManager", ".", "prepare", "(", "\n", "cls", ".", "load_dictionary", ",", "args", ",", "**", "kwargs", "\n", ")", "\n", "return", "cls", "(", "args", ",", "langs", ",", "dicts", ",", "training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.has_sharded_data": [[130, 132], ["translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.data_manager.has_sharded_data"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.has_sharded_data"], ["", "def", "has_sharded_data", "(", "self", ",", "split", ")", ":", "\n", "        ", "return", "self", ".", "data_manager", ".", "has_sharded_data", "(", "split", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.load_dataset": [[133, 167], ["logger.info", "logger.info", "translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.data_manager.load_dataset", "translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.has_sharded_data", "translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.data_manager.estimate_global_pass_epoch", "logger.info", "logger.info", "fairseq.data.data_utils.get_mem_usage", "fairseq.data.data_utils.get_mem_usage"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyMTTask.load_dataset", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.has_sharded_data", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.estimate_global_pass_epoch", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.get_mem_usage", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.get_mem_usage"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "1", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n        \"\"\"", "\n", "if", "split", "in", "self", ".", "datasets", ":", "\n", "            ", "dataset", "=", "self", ".", "datasets", "[", "split", "]", "\n", "if", "self", ".", "has_sharded_data", "(", "split", ")", ":", "\n", "                ", "if", "self", ".", "args", ".", "virtual_epoch_size", "is", "not", "None", ":", "\n", "                    ", "if", "dataset", ".", "load_next_shard", ":", "\n", "                        ", "shard_epoch", "=", "dataset", ".", "shard_epoch", "\n", "", "else", ":", "\n", "# no need to load next shard so skip loading", "\n", "# also this avoid always loading from beginning of the data", "\n", "                        ", "return", "\n", "", "", "else", ":", "\n", "                    ", "shard_epoch", "=", "epoch", "\n", "", "", "", "else", ":", "\n", "# estimate the shard epoch from virtual data size and virtual epoch size", "\n", "            ", "shard_epoch", "=", "self", ".", "data_manager", ".", "estimate_global_pass_epoch", "(", "epoch", ")", "\n", "", "logger", ".", "info", "(", "f\"loading data for {split} epoch={epoch}/{shard_epoch}\"", ")", "\n", "logger", ".", "info", "(", "f\"mem usage: {data_utils.get_mem_usage()}\"", ")", "\n", "if", "split", "in", "self", ".", "datasets", ":", "\n", "            ", "del", "self", ".", "datasets", "[", "split", "]", "\n", "logger", ".", "info", "(", "\"old dataset deleted manually\"", ")", "\n", "logger", ".", "info", "(", "f\"mem usage: {data_utils.get_mem_usage()}\"", ")", "\n", "", "self", ".", "datasets", "[", "split", "]", "=", "self", ".", "data_manager", ".", "load_dataset", "(", "\n", "split", ",", "\n", "self", ".", "training", ",", "\n", "epoch", "=", "epoch", ",", "\n", "combine", "=", "combine", ",", "\n", "shard_epoch", "=", "shard_epoch", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.build_dataset_for_inference": [[169, 196], ["fairseq.data.ListDataset", "fairseq.data.LanguagePairDataset", "NotImplementedError", "translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.data_manager.alter_dataset_langtok", "translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.data_manager.src_dataset_tranform_func", "translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.source_dictionary.eos", "translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.target_dictionary.eos"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.alter_dataset_langtok", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.src_dataset_tranform_func", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "def", "build_dataset_for_inference", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "constraints", "=", "None", ")", ":", "\n", "        ", "if", "constraints", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Constrained decoding with the multilingual_translation task is not supported\"", "\n", ")", "\n", "\n", "", "src_data", "=", "ListDataset", "(", "src_tokens", ",", "src_lengths", ")", "\n", "dataset", "=", "LanguagePairDataset", "(", "src_data", ",", "src_lengths", ",", "self", ".", "source_dictionary", ")", "\n", "src_langtok_spec", ",", "tgt_langtok_spec", "=", "self", ".", "args", ".", "langtoks", "[", "\"main\"", "]", "\n", "if", "self", ".", "args", ".", "lang_tok_replacing_bos_eos", ":", "\n", "            ", "dataset", "=", "self", ".", "data_manager", ".", "alter_dataset_langtok", "(", "\n", "dataset", ",", "\n", "src_eos", "=", "self", ".", "source_dictionary", ".", "eos", "(", ")", ",", "\n", "src_lang", "=", "self", ".", "args", ".", "source_lang", ",", "\n", "tgt_eos", "=", "self", ".", "target_dictionary", ".", "eos", "(", ")", ",", "\n", "tgt_lang", "=", "self", ".", "args", ".", "target_lang", ",", "\n", "src_langtok_spec", "=", "src_langtok_spec", ",", "\n", "tgt_langtok_spec", "=", "tgt_langtok_spec", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "dataset", ".", "src", "=", "self", ".", "data_manager", ".", "src_dataset_tranform_func", "(", "\n", "self", ".", "args", ".", "source_lang", ",", "\n", "self", ".", "args", ".", "target_lang", ",", "\n", "dataset", "=", "dataset", ".", "src", ",", "\n", "spec", "=", "src_langtok_spec", ",", "\n", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.build_generator": [[197, 215], ["super().build_generator", "getattr", "translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.data_manager.get_decoder_langtok"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.build_generator", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_decoder_langtok"], ["", "def", "build_generator", "(", "\n", "self", ",", "\n", "models", ",", "\n", "args", ",", "\n", "seq_gen_cls", "=", "None", ",", "\n", "extra_gen_cls_kwargs", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "not", "getattr", "(", "args", ",", "\"keep_inference_langtok\"", ",", "False", ")", ":", "\n", "            ", "_", ",", "tgt_langtok_spec", "=", "self", ".", "args", ".", "langtoks", "[", "\"main\"", "]", "\n", "if", "tgt_langtok_spec", ":", "\n", "                ", "tgt_lang_tok", "=", "self", ".", "data_manager", ".", "get_decoder_langtok", "(", "\n", "self", ".", "args", ".", "target_lang", ",", "tgt_langtok_spec", "\n", ")", "\n", "extra_gen_cls_kwargs", "=", "extra_gen_cls_kwargs", "or", "{", "}", "\n", "extra_gen_cls_kwargs", "[", "\"symbols_to_strip_from_output\"", "]", "=", "{", "tgt_lang_tok", "}", "\n", "\n", "", "", "return", "super", "(", ")", ".", "build_generator", "(", "\n", "models", ",", "args", ",", "seq_gen_cls", "=", "None", ",", "extra_gen_cls_kwargs", "=", "extra_gen_cls_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.build_model": [[217, 219], ["super().build_model"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model"], ["", "def", "build_model", "(", "self", ",", "args", ")", ":", "\n", "        ", "return", "super", "(", ")", ".", "build_model", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.valid_step": [[220, 223], ["super().valid_step"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.valid_step"], ["", "def", "valid_step", "(", "self", ",", "sample", ",", "model", ",", "criterion", ")", ":", "\n", "        ", "loss", ",", "sample_size", ",", "logging_output", "=", "super", "(", ")", ".", "valid_step", "(", "sample", ",", "model", ",", "criterion", ")", "\n", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.inference_step": [[224, 255], ["torch.no_grad", "generator.generate", "generator.generate", "translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.data_manager.get_decoder_langtok", "src_tokens.size", "torch.LongTensor().expand().to", "torch.LongTensor().expand", "translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.data_manager.get_decoder_langtok", "translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.target_dictionary.eos", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.generate", "home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.generate", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_decoder_langtok", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_decoder_langtok", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "def", "inference_step", "(", "\n", "self", ",", "generator", ",", "models", ",", "sample", ",", "prefix_tokens", "=", "None", ",", "constraints", "=", "None", "\n", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "_", ",", "tgt_langtok_spec", "=", "self", ".", "args", ".", "langtoks", "[", "\"main\"", "]", "\n", "if", "not", "self", ".", "args", ".", "lang_tok_replacing_bos_eos", ":", "\n", "                ", "if", "prefix_tokens", "is", "None", "and", "tgt_langtok_spec", ":", "\n", "                    ", "tgt_lang_tok", "=", "self", ".", "data_manager", ".", "get_decoder_langtok", "(", "\n", "self", ".", "args", ".", "target_lang", ",", "tgt_langtok_spec", "\n", ")", "\n", "src_tokens", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "\n", "bsz", "=", "src_tokens", ".", "size", "(", "0", ")", "\n", "prefix_tokens", "=", "(", "\n", "torch", ".", "LongTensor", "(", "[", "[", "tgt_lang_tok", "]", "]", ")", ".", "expand", "(", "bsz", ",", "1", ")", ".", "to", "(", "src_tokens", ")", "\n", ")", "\n", "", "return", "generator", ".", "generate", "(", "\n", "models", ",", "\n", "sample", ",", "\n", "prefix_tokens", "=", "prefix_tokens", ",", "\n", "constraints", "=", "constraints", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "return", "generator", ".", "generate", "(", "\n", "models", ",", "\n", "sample", ",", "\n", "prefix_tokens", "=", "prefix_tokens", ",", "\n", "bos_token", "=", "self", ".", "data_manager", ".", "get_decoder_langtok", "(", "\n", "self", ".", "args", ".", "target_lang", ",", "tgt_langtok_spec", "\n", ")", "\n", "if", "tgt_langtok_spec", "\n", "else", "self", ".", "target_dictionary", ".", "eos", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.reduce_metrics": [[257, 259], ["super().reduce_metrics"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.reduce_metrics"], ["", "", "", "def", "reduce_metrics", "(", "self", ",", "logging_outputs", ",", "criterion", ")", ":", "\n", "        ", "super", "(", ")", ".", "reduce_metrics", "(", "logging_outputs", ",", "criterion", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.max_positions": [[260, 263], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the max sentence length allowed by the task.\"\"\"", "\n", "return", "(", "self", ".", "args", ".", "max_source_positions", ",", "self", ".", "args", ".", "max_target_positions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.source_dictionary": [[264, 267], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dicts", "[", "self", ".", "source_langs", "[", "0", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.target_dictionary": [[268, 271], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dicts", "[", "self", ".", "target_langs", "[", "0", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.create_batch_sampler_func": [[272, 333], ["time.time", "logger.info", "logger.info", "logger.info", "time.time", "dataset.batch_by_size", "logger.info", "logger.info", "logger.info", "dataset.set_epoch", "fairseq.data.data_utils.numpy_seed", "dataset.ordered_indices", "time.time", "translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.filter_indices_by_size", "logger.info", "logger.info", "translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.datasets.items", "len", "fairseq.data.data_utils.get_mem_usage", "translation_multi_simple_epoch.get_time_gap", "fairseq.data.data_utils.get_mem_usage", "translation_multi_simple_epoch.get_time_gap", "translation_multi_simple_epoch.get_time_gap", "fairseq.data.data_utils.get_mem_usage", "time.time", "translation_multi_simple_epoch.get_time_gap", "fairseq.data.data_utils.get_mem_usage", "time.time", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.base_wrapper_dataset.BaseWrapperDataset.batch_by_size", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.numpy_seed", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.ordered_indices", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.filter_indices_by_size", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.get_mem_usage", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.get_time_gap", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.get_mem_usage", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.get_time_gap", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.get_time_gap", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.get_mem_usage", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.get_time_gap", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.get_mem_usage"], ["", "def", "create_batch_sampler_func", "(", "\n", "self", ",", "\n", "max_positions", ",", "\n", "ignore_invalid_inputs", ",", "\n", "max_tokens", ",", "\n", "max_sentences", ",", "\n", "required_batch_size_multiple", "=", "1", ",", "\n", "seed", "=", "1", ",", "\n", ")", ":", "\n", "        ", "def", "construct_batch_sampler", "(", "dataset", ",", "epoch", ")", ":", "\n", "            ", "splits", "=", "[", "\n", "s", "for", "s", ",", "_", "in", "self", ".", "datasets", ".", "items", "(", ")", "if", "self", ".", "datasets", "[", "s", "]", "==", "dataset", "\n", "]", "\n", "split", "=", "splits", "[", "0", "]", "if", "len", "(", "splits", ")", ">", "0", "else", "None", "\n", "# NEW implementation", "\n", "if", "epoch", "is", "not", "None", ":", "\n", "# initialize the dataset with the correct starting epoch", "\n", "                ", "dataset", ".", "set_epoch", "(", "epoch", ")", "\n", "\n", "# get indices ordered by example size", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "f\"start batch sampler: mem usage: {data_utils.get_mem_usage()}\"", ")", "\n", "\n", "with", "data_utils", ".", "numpy_seed", "(", "seed", ")", ":", "\n", "                ", "indices", "=", "dataset", ".", "ordered_indices", "(", ")", "\n", "", "logger", ".", "info", "(", "\n", "f\"[{split}] @batch_sampler order indices time: {get_time_gap(start_time, time.time())}\"", "\n", ")", "\n", "logger", ".", "info", "(", "f\"mem usage: {data_utils.get_mem_usage()}\"", ")", "\n", "\n", "# filter examples that are too large", "\n", "if", "max_positions", "is", "not", "None", ":", "\n", "                ", "my_time", "=", "time", ".", "time", "(", ")", "\n", "indices", "=", "self", ".", "filter_indices_by_size", "(", "\n", "indices", ",", "dataset", ",", "max_positions", ",", "ignore_invalid_inputs", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "f\"[{split}] @batch_sampler filter_by_size time: {get_time_gap(my_time, time.time())}\"", "\n", ")", "\n", "logger", ".", "info", "(", "f\"mem usage: {data_utils.get_mem_usage()}\"", ")", "\n", "\n", "# create mini-batches with given size constraints", "\n", "", "my_time", "=", "time", ".", "time", "(", ")", "\n", "batch_sampler", "=", "dataset", ".", "batch_by_size", "(", "\n", "indices", ",", "\n", "max_tokens", "=", "max_tokens", ",", "\n", "max_sentences", "=", "max_sentences", ",", "\n", "required_batch_size_multiple", "=", "required_batch_size_multiple", ",", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "\n", "f\"[{split}] @batch_sampler batch_by_size time: {get_time_gap(my_time, time.time())}\"", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "f\"[{split}] per epoch batch_sampler set-up time: {get_time_gap(start_time, time.time())}\"", "\n", ")", "\n", "logger", ".", "info", "(", "f\"mem usage: {data_utils.get_mem_usage()}\"", ")", "\n", "\n", "return", "batch_sampler", "\n", "\n", "", "return", "construct_batch_sampler", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.get_batch_iterator": [[335, 429], ["isinstance", "translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.create_batch_sampler_func", "fairseq.data.iterators.EpochBatchIterator", "super().get_batch_iterator"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.create_batch_sampler_func", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.get_batch_iterator"], ["", "def", "get_batch_iterator", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "max_tokens", "=", "None", ",", "\n", "max_sentences", "=", "None", ",", "\n", "max_positions", "=", "None", ",", "\n", "ignore_invalid_inputs", "=", "False", ",", "\n", "required_batch_size_multiple", "=", "1", ",", "\n", "seed", "=", "1", ",", "\n", "num_shards", "=", "1", ",", "\n", "shard_id", "=", "0", ",", "\n", "num_workers", "=", "0", ",", "\n", "epoch", "=", "1", ",", "\n", "data_buffer_size", "=", "0", ",", "\n", "disable_iterator_cache", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Get an iterator that yields batches of data from the given dataset.\n\n        Args:\n            dataset (~fairseq.data.FairseqDataset): dataset to batch\n            max_tokens (int, optional): max number of tokens in each batch\n                (default: None).\n            max_sentences (int, optional): max number of sentences in each\n                batch (default: None).\n            max_positions (optional): max sentence length supported by the\n                model (default: None).\n            ignore_invalid_inputs (bool, optional): don't raise Exception for\n                sentences that are too long (default: False).\n            required_batch_size_multiple (int, optional): require batch size to\n                be a multiple of N (default: 1).\n            seed (int, optional): seed for random number generator for\n                reproducibility (default: 1).\n            num_shards (int, optional): shard the data iterator into N\n                shards (default: 1).\n            shard_id (int, optional): which shard of the data iterator to\n                return (default: 0).\n            num_workers (int, optional): how many subprocesses to use for data\n                loading. 0 means the data will be loaded in the main process\n                (default: 0).\n            epoch (int, optional): the epoch to start the iterator from\n                (default: 0).\n            data_buffer_size (int, optional): number of batches to\n                preload (default: 0).\n            disable_iterator_cache (bool, optional): don't cache the\n                EpochBatchIterator (ignores `FairseqTask::can_reuse_epoch_itr`)\n                (default: False).\n        Returns:\n            ~fairseq.iterators.EpochBatchIterator: a batched iterator over the\n                given dataset split\n        \"\"\"", "\n", "# initialize the dataset with the correct starting epoch", "\n", "assert", "isinstance", "(", "dataset", ",", "FairseqDataset", ")", "\n", "if", "dataset", "in", "self", ".", "dataset_to_epoch_iter", ":", "\n", "            ", "return", "self", ".", "dataset_to_epoch_iter", "[", "dataset", "]", "\n", "", "if", "self", ".", "args", ".", "sampling_method", "==", "\"RoundRobin\"", ":", "\n", "            ", "batch_iter", "=", "super", "(", ")", ".", "get_batch_iterator", "(", "\n", "dataset", ",", "\n", "max_tokens", "=", "max_tokens", ",", "\n", "max_sentences", "=", "max_sentences", ",", "\n", "max_positions", "=", "max_positions", ",", "\n", "ignore_invalid_inputs", "=", "ignore_invalid_inputs", ",", "\n", "required_batch_size_multiple", "=", "required_batch_size_multiple", ",", "\n", "seed", "=", "seed", ",", "\n", "num_shards", "=", "num_shards", ",", "\n", "shard_id", "=", "shard_id", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "epoch", "=", "epoch", ",", "\n", "data_buffer_size", "=", "data_buffer_size", ",", "\n", "disable_iterator_cache", "=", "disable_iterator_cache", ",", "\n", ")", "\n", "self", ".", "dataset_to_epoch_iter", "[", "dataset", "]", "=", "batch_iter", "\n", "return", "batch_iter", "\n", "\n", "", "construct_batch_sampler", "=", "self", ".", "create_batch_sampler_func", "(", "\n", "max_positions", ",", "\n", "ignore_invalid_inputs", ",", "\n", "max_tokens", ",", "\n", "max_sentences", ",", "\n", "required_batch_size_multiple", "=", "required_batch_size_multiple", ",", "\n", "seed", "=", "seed", ",", "\n", ")", "\n", "\n", "epoch_iter", "=", "iterators", ".", "EpochBatchIterator", "(", "\n", "dataset", "=", "dataset", ",", "\n", "collate_fn", "=", "dataset", ".", "collater", ",", "\n", "batch_sampler", "=", "construct_batch_sampler", ",", "\n", "seed", "=", "seed", ",", "\n", "num_shards", "=", "num_shards", ",", "\n", "shard_id", "=", "shard_id", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "epoch", "=", "epoch", ",", "\n", ")", "\n", "return", "epoch_iter", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.get_time_gap": [[27, 30], ["datetime.datetime.fromtimestamp", "datetime.datetime.fromtimestamp"], "function", ["None"], ["def", "get_time_gap", "(", "s", ",", "e", ")", ":", "\n", "    ", "return", "(", "\n", "datetime", ".", "datetime", ".", "fromtimestamp", "(", "e", ")", "-", "datetime", ".", "datetime", ".", "fromtimestamp", "(", "s", ")", "\n", ")", ".", "__str__", "(", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.__init__": [[53, 55], ["fairseq.tasks.translation.TranslationTask.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "args", ",", "src_dict", ",", "tgt_dict", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "src_dict", ",", "tgt_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.add_args": [[56, 61], ["fairseq.tasks.translation.TranslationTask.add_args", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "TranslationTask", ".", "add_args", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "'--lang-prefix-tok'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"starting token in decoder\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.build_model": [[62, 94], ["super().build_model", "hasattr", "getattr", "super().build_model.set_mt_only", "json.loads", "fairseq.data.encoders.build_tokenizer", "json.loads", "translation_with_langtag.TranslationTaskWithLangtag.build_generator", "getattr", "argparse.Namespace", "fairseq.data.encoders.build_bpe", "argparse.Namespace", "getattr", "argparse.Namespace", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.set_mt_only", "home.repos.pwc.inspect_result.reneeye_const.tasks.speech_to_text.SpeechToTextTask.build_tokenizer", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.build_generator", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.build_bpe"], ["", "def", "build_model", "(", "self", ",", "args", ")", ":", "\n", "        ", "model", "=", "super", "(", ")", ".", "build_model", "(", "args", ")", "\n", "if", "hasattr", "(", "model", ",", "\"set_mt_only\"", ")", ":", "\n", "            ", "model", ".", "set_mt_only", "(", ")", "\n", "\n", "", "if", "getattr", "(", "args", ",", "\"eval_bleu\"", ",", "False", ")", ":", "\n", "            ", "assert", "getattr", "(", "args", ",", "\"eval_bleu_detok\"", ",", "None", ")", "is", "not", "None", ",", "(", "\n", "\"--eval-bleu-detok is required if using --eval-bleu; \"", "\n", "\"try --eval-bleu-detok=moses (or --eval-bleu-detok=space \"", "\n", "\"to disable detokenization, e.g., when using sentencepiece)\"", "\n", ")", "\n", "detok_args", "=", "json", ".", "loads", "(", "getattr", "(", "args", ",", "\"eval_bleu_detok_args\"", ",", "\"{}\"", ")", "or", "\"{}\"", ")", "\n", "self", ".", "tokenizer", "=", "encoders", ".", "build_tokenizer", "(", "\n", "Namespace", "(", "\n", "tokenizer", "=", "getattr", "(", "args", ",", "\"eval_bleu_detok\"", ",", "None", ")", ",", "**", "detok_args", "\n", ")", "\n", ")", "\n", "if", "args", ".", "eval_bleu_bpe", "is", "None", ":", "\n", "                ", "self", ".", "bpe", "=", "None", "\n", "", "else", ":", "\n", "                ", "self", ".", "bpe", "=", "encoders", ".", "build_bpe", "(", "\n", "Namespace", "(", "\n", "bpe", "=", "args", ".", "eval_bleu_bpe", ",", "\n", "sentencepiece_model", "=", "args", ".", "eval_bleu_bpe_path", "\n", ")", "\n", ")", "\n", "\n", "", "gen_args", "=", "json", ".", "loads", "(", "getattr", "(", "args", ",", "\"eval_bleu_args\"", ",", "\"{}\"", ")", "or", "\"{}\"", ")", "\n", "self", ".", "sequence_generator", "=", "self", ".", "build_generator", "(", "\n", "[", "model", "]", ",", "Namespace", "(", "**", "gen_args", ")", "\n", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.load_dataset": [[95, 132], ["fairseq.utils.split_paths", "fairseq.tasks.translation.load_langpair_dataset", "len", "getattr", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_langpair_dataset"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "1", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n        \"\"\"", "\n", "paths", "=", "utils", ".", "split_paths", "(", "self", ".", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "if", "split", "!=", "getattr", "(", "self", ".", "args", ",", "\"train_subset\"", ",", "None", ")", ":", "\n", "# if not training data set, use the first shard for valid and test", "\n", "            ", "paths", "=", "paths", "[", ":", "1", "]", "\n", "", "data_path", "=", "paths", "[", "(", "epoch", "-", "1", ")", "%", "len", "(", "paths", ")", "]", "\n", "\n", "# infer langcode", "\n", "src", ",", "tgt", "=", "self", ".", "args", ".", "source_lang", ",", "self", ".", "args", ".", "target_lang", "\n", "\n", "text_dataset", "=", "load_langpair_dataset", "(", "\n", "data_path", ",", "\n", "split", ",", "\n", "src", ",", "\n", "self", ".", "src_dict", ",", "\n", "tgt", ",", "\n", "self", ".", "tgt_dict", ",", "\n", "combine", "=", "combine", ",", "\n", "dataset_impl", "=", "self", ".", "args", ".", "dataset_impl", ",", "\n", "upsample_primary", "=", "self", ".", "args", ".", "upsample_primary", ",", "\n", "left_pad_source", "=", "self", ".", "args", ".", "left_pad_source", ",", "\n", "left_pad_target", "=", "self", ".", "args", ".", "left_pad_target", ",", "\n", "max_source_positions", "=", "self", ".", "args", ".", "max_source_positions", ",", "\n", "max_target_positions", "=", "self", ".", "args", ".", "max_target_positions", ",", "\n", "load_alignments", "=", "self", ".", "args", ".", "load_alignments", ",", "\n", "truncate_source", "=", "self", ".", "args", ".", "truncate_source", ",", "\n", "num_buckets", "=", "self", ".", "args", ".", "num_batch_buckets", ",", "\n", "shuffle", "=", "(", "split", "!=", "\"test\"", ")", ",", "\n", "pad_to_multiple", "=", "self", ".", "args", ".", "required_seq_len_multiple", ",", "\n", ")", "\n", "self", ".", "datasets", "[", "split", "]", "=", "text_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.inference_step": [[133, 168], ["hasattr", "translation_with_langtag.TranslationTaskWithLangtag.tgt_dict.index", "torch.no_grad", "generator.generate", "model.set_mt_only", "new_models.append", "src_tokens.size", "isinstance", "Exception", "torch.LongTensor().unsqueeze", "prefix_tokens.expand().to.expand().to.expand().to", "torch.LongTensor", "prefix_tokens.expand().to.expand().to.expand"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.index", "home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.generate", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.set_mt_only", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "inference_step", "(", "\n", "self", ",", "generator", ",", "models", ",", "sample", ",", "prefix_tokens", "=", "None", ",", "constraints", "=", "None", "\n", ")", ":", "\n", "        ", "if", "hasattr", "(", "models", "[", "0", "]", ",", "\"set_mt_only\"", ")", ":", "\n", "            ", "new_models", "=", "[", "]", "\n", "for", "model", "in", "models", ":", "\n", "                ", "model", ".", "set_mt_only", "(", ")", "\n", "new_models", ".", "append", "(", "model", ")", "\n", "", "models", "=", "new_models", "\n", "\n", "", "if", "self", ".", "args", ".", "lang_prefix_tok", "is", "None", ":", "\n", "            ", "prefix_tokens", "=", "None", "\n", "", "else", ":", "\n", "            ", "prefix_tokens", "=", "self", ".", "tgt_dict", ".", "index", "(", "self", ".", "args", ".", "lang_prefix_tok", ")", "\n", "assert", "prefix_tokens", "!=", "self", ".", "tgt_dict", ".", "unk_index", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "net_input", "=", "sample", "[", "\"net_input\"", "]", "\n", "if", "\"src_tokens\"", "in", "net_input", ":", "\n", "                ", "src_tokens", "=", "net_input", "[", "\"src_tokens\"", "]", "\n", "", "elif", "\"source\"", "in", "net_input", ":", "\n", "                ", "src_tokens", "=", "net_input", "[", "\"source\"", "]", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"net_input must have `src_tokens` or `source`.\"", ")", "\n", "", "bsz", ",", "_", "=", "src_tokens", ".", "size", "(", ")", "[", ":", "2", "]", "\n", "\n", "if", "prefix_tokens", "is", "not", "None", ":", "\n", "                ", "if", "isinstance", "(", "prefix_tokens", ",", "int", ")", ":", "\n", "                    ", "prefix_tokens", "=", "torch", ".", "LongTensor", "(", "[", "prefix_tokens", "]", ")", ".", "unsqueeze", "(", "1", ")", "\n", "prefix_tokens", "=", "prefix_tokens", ".", "expand", "(", "bsz", ",", "-", "1", ")", ".", "to", "(", "src_tokens", ".", "device", ")", "\n", "\n", "", "", "return", "generator", ".", "generate", "(", "\n", "models", ",", "\n", "sample", ",", "\n", "prefix_tokens", "=", "prefix_tokens", ",", "\n", "constraints", "=", "constraints", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag._inference_with_bleu": [[170, 211], ["translation_with_langtag.TranslationTaskWithLangtag.inference_step", "range", "translation_with_langtag.TranslationTaskWithLangtag.tgt_dict.string", "len", "translation_with_langtag.TranslationTaskWithLangtag._inference_with_bleu.decode"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.inference_step", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "", "def", "_inference_with_bleu", "(", "self", ",", "generator", ",", "sample", ",", "model", ")", ":", "\n", "        ", "import", "sacrebleu", "\n", "\n", "def", "decode", "(", "toks", ",", "escape_unk", "=", "False", ")", ":", "\n", "            ", "s", "=", "self", ".", "tgt_dict", ".", "string", "(", "\n", "toks", ".", "int", "(", ")", ".", "cpu", "(", ")", ",", "\n", "self", ".", "args", ".", "eval_bleu_remove_bpe", ",", "\n", "# The default unknown string in fairseq is `<unk>`, but", "\n", "# this is tokenized by sacrebleu as `< unk >`, inflating", "\n", "# BLEU scores. Instead, we use a somewhat more verbose", "\n", "# alternative that is unlikely to appear in the real", "\n", "# reference, but doesn't get split into multiple tokens.", "\n", "unk_string", "=", "(", "\"UNKNOWNTOKENINREF\"", "if", "escape_unk", "else", "\"UNKNOWNTOKENINHYP\"", ")", ",", "\n", ")", "\n", "if", "self", ".", "bpe", "is", "not", "None", ":", "\n", "                ", "s", "=", "self", ".", "bpe", ".", "decode", "(", "s", ")", "\n", "", "if", "self", ".", "tokenizer", ":", "\n", "                ", "s", "=", "self", ".", "tokenizer", ".", "decode", "(", "s", ")", "\n", "", "return", "s", "\n", "\n", "", "gen_out", "=", "self", ".", "inference_step", "(", "generator", ",", "[", "model", "]", ",", "sample", ",", "prefix_tokens", "=", "None", ")", "\n", "hyps", ",", "refs", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "gen_out", ")", ")", ":", "\n", "            ", "hyp", "=", "decode", "(", "gen_out", "[", "i", "]", "[", "0", "]", "[", "\"tokens\"", "]", ")", "\n", "ref", "=", "decode", "(", "\n", "utils", ".", "strip_pad", "(", "sample", "[", "\"target\"", "]", "[", "i", "]", "[", "1", ":", "]", ",", "self", ".", "tgt_dict", ".", "pad", "(", ")", ")", ",", "\n", "escape_unk", "=", "True", ",", "# don't count <unk> as matches to the hypo", "\n", ")", "\n", "if", "self", ".", "args", ".", "lang_prefix_tok", "is", "not", "None", ":", "\n", "                ", "hyp", "=", "hyp", ".", "replace", "(", "self", ".", "args", ".", "lang_prefix_tok", ",", "\"\"", ")", "\n", "ref", "=", "ref", ".", "replace", "(", "self", ".", "args", ".", "lang_prefix_tok", ",", "\"\"", ")", "\n", "", "hyps", ".", "append", "(", "hyp", ")", "\n", "refs", ".", "append", "(", "ref", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "eval_bleu_print_samples", ":", "\n", "            ", "logger", ".", "info", "(", "\"example hypothesis: \"", "+", "hyps", "[", "0", "]", ")", "\n", "logger", ".", "info", "(", "\"example reference: \"", "+", "refs", "[", "0", "]", ")", "\n", "", "if", "self", ".", "args", ".", "eval_tokenized_bleu", ":", "\n", "            ", "return", "sacrebleu", ".", "corpus_bleu", "(", "hyps", ",", "[", "refs", "]", ",", "tokenize", "=", "\"none\"", ")", "\n", "", "else", ":", "\n", "            ", "return", "sacrebleu", ".", "corpus_bleu", "(", "hyps", ",", "[", "refs", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.build_bpe": [[212, 216], ["logger.info"], "methods", ["None"], ["", "", "def", "build_bpe", "(", "self", ",", "args", ")", ":", "\n", "# ignore args, no one is really using it", "\n", "        ", "logger", ".", "info", "(", "f\"tokenizer: {self.bpe}\"", ")", "\n", "return", "self", ".", "bpe", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_lm.FConvLanguageModel.__init__": [[17, 19], ["fairseq.models.FairseqLanguageModel.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_lm.FConvLanguageModel.add_args": [[20, 61], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dropout\"", ",", "type", "=", "float", ",", "metavar", "=", "\"D\"", ",", "help", "=", "\"dropout probability\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-embed-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"decoder embedding dimension\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-layers\"", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"EXPR\"", ",", "\n", "help", "=", "\"decoder layers [(dim, kernel_size), ...]\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-out-embed-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"decoder output embedding dimension\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--adaptive-softmax-cutoff\"", ",", "\n", "metavar", "=", "\"EXPR\"", ",", "\n", "help", "=", "\"comma separated list of adaptive softmax cutoff points. \"", "\n", "\"Must be used with adaptive_loss criterion\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--adaptive-softmax-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"sets adaptive softmax dropout for the tail projections\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-attention\"", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"EXPR\"", ",", "\n", "help", "=", "\"decoder attention [True, ...]\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_lm.FConvLanguageModel.build_model": [[63, 92], ["fconv_lm.base_lm_architecture", "fairseq.models.fconv.FConvDecoder", "fconv_lm.FConvLanguageModel", "hasattr", "hasattr", "eval", "eval", "fairseq.utils.eval_str_list"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.lightconv_lm.base_lm_architecture", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.eval_str_list"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "# make sure all arguments are present in older models", "\n", "base_lm_architecture", "(", "args", ")", "\n", "\n", "if", "hasattr", "(", "args", ",", "\"max_target_positions\"", ")", "and", "not", "hasattr", "(", "\n", "args", ",", "\"tokens_per_sample\"", "\n", ")", ":", "\n", "            ", "args", ".", "tokens_per_sample", "=", "args", ".", "max_target_positions", "\n", "\n", "", "decoder", "=", "FConvDecoder", "(", "\n", "dictionary", "=", "task", ".", "target_dictionary", ",", "\n", "embed_dim", "=", "args", ".", "decoder_embed_dim", ",", "\n", "convolutions", "=", "eval", "(", "args", ".", "decoder_layers", ")", ",", "\n", "out_embed_dim", "=", "args", ".", "decoder_embed_dim", ",", "\n", "attention", "=", "eval", "(", "args", ".", "decoder_attention", ")", ",", "\n", "dropout", "=", "args", ".", "dropout", ",", "\n", "max_positions", "=", "args", ".", "tokens_per_sample", ",", "\n", "share_embed", "=", "False", ",", "\n", "positional_embeddings", "=", "False", ",", "\n", "adaptive_softmax_cutoff", "=", "(", "\n", "utils", ".", "eval_str_list", "(", "args", ".", "adaptive_softmax_cutoff", ",", "type", "=", "int", ")", "\n", "if", "args", ".", "criterion", "==", "\"adaptive_loss\"", "\n", "else", "None", "\n", ")", ",", "\n", "adaptive_softmax_dropout", "=", "args", ".", "adaptive_softmax_dropout", ",", "\n", ")", "\n", "return", "FConvLanguageModel", "(", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_lm.base_lm_architecture": [[94, 102], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "", "@", "register_model_architecture", "(", "\"fconv_lm\"", ",", "\"fconv_lm\"", ")", "\n", "def", "base_lm_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "128", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "\"[(1268, 4)] * 13\"", ")", "\n", "args", ".", "decoder_attention", "=", "getattr", "(", "args", ",", "\"decoder_attention\"", ",", "\"False\"", ")", "\n", "args", ".", "adaptive_softmax_cutoff", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_cutoff\"", ",", "None", ")", "\n", "args", ".", "adaptive_softmax_dropout", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_dropout\"", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_lm.fconv_lm_dauphin_wikitext103": [[104, 120], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "fconv_lm.base_lm_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.lightconv_lm.base_lm_architecture"], ["", "@", "register_model_architecture", "(", "\"fconv_lm\"", ",", "\"fconv_lm_dauphin_wikitext103\"", ")", "\n", "def", "fconv_lm_dauphin_wikitext103", "(", "args", ")", ":", "\n", "    ", "layers", "=", "\"[(850, 6)] * 3\"", "\n", "layers", "+=", "\" + [(850, 1)] * 1\"", "\n", "layers", "+=", "\" + [(850, 5)] * 4\"", "\n", "layers", "+=", "\" + [(850, 1)] * 1\"", "\n", "layers", "+=", "\" + [(850, 4)] * 3\"", "\n", "layers", "+=", "\" + [(1024, 4)] * 1\"", "\n", "layers", "+=", "\" + [(2048, 4)] * 1\"", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "280", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "layers", ")", "\n", "args", ".", "decoder_attention", "=", "getattr", "(", "args", ",", "\"decoder_attention\"", ",", "\"False\"", ")", "\n", "args", ".", "adaptive_softmax_cutoff", "=", "getattr", "(", "\n", "args", ",", "\"adaptive_softmax_cutoff\"", ",", "\"10000,20000,200000\"", "\n", ")", "\n", "base_lm_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_lm.fconv_lm_dauphin_gbw": [[122, 136], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "fconv_lm.base_lm_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.lightconv_lm.base_lm_architecture"], ["", "@", "register_model_architecture", "(", "\"fconv_lm\"", ",", "\"fconv_lm_dauphin_gbw\"", ")", "\n", "def", "fconv_lm_dauphin_gbw", "(", "args", ")", ":", "\n", "    ", "layers", "=", "\"[(512, 5)]\"", "\n", "layers", "+=", "\" + [(128, 1, 0), (128, 5, 0), (512, 1, 3)] * 3\"", "\n", "layers", "+=", "\" + [(512, 1, 0), (512, 5, 0), (1024, 1, 3)] * 3\"", "\n", "layers", "+=", "\" + [(1024, 1, 0), (1024, 5, 0), (2048, 1, 3)] * 6\"", "\n", "layers", "+=", "\" + [(1024, 1, 0), (1024, 5, 0), (4096, 1, 3)]\"", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "128", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "layers", ")", "\n", "args", ".", "decoder_attention", "=", "getattr", "(", "args", ",", "\"decoder_attention\"", ",", "\"False\"", ")", "\n", "args", ".", "adaptive_softmax_cutoff", "=", "getattr", "(", "\n", "args", ",", "\"adaptive_softmax_cutoff\"", ",", "\"10000,50000,200000\"", "\n", ")", "\n", "base_lm_architecture", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_from_pretrained_xlm.TransformerFromPretrainedXLMModel.add_args": [[22, 41], ["fairseq.models.transformer.TransformerModel.add_args", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args"], ["    ", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "TransformerModel", ".", "add_args", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pretrained-xlm-checkpoint\"", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"STR\"", ",", "\n", "help", "=", "\"XLM model to use for initializing transformer encoder and/or decoder\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--init-encoder-only\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if set, don't load the XLM weights and embeddings into decoder\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--init-decoder-only\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if set, don't load the XLM weights and embeddings into encoder\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_from_pretrained_xlm.TransformerFromPretrainedXLMModel.build_model": [[43, 63], ["hasattr", "super().build_model", "isinstance", "isinstance", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "self", ",", "args", ",", "task", ",", "cls_dictionary", "=", "MaskedLMDictionary", ")", ":", "\n", "        ", "assert", "hasattr", "(", "args", ",", "\"pretrained_xlm_checkpoint\"", ")", ",", "(", "\n", "\"You must specify a path for --pretrained-xlm-checkpoint to use \"", "\n", "\"--arch transformer_from_pretrained_xlm\"", "\n", ")", "\n", "assert", "isinstance", "(", "task", ".", "source_dictionary", ",", "cls_dictionary", ")", "and", "isinstance", "(", "\n", "task", ".", "target_dictionary", ",", "cls_dictionary", "\n", ")", ",", "(", "\n", "\"You should use a MaskedLMDictionary when using --arch \"", "\n", "\"transformer_from_pretrained_xlm because the pretrained XLM model \"", "\n", "\"was trained using data binarized with MaskedLMDictionary. \"", "\n", "\"For translation, you may want to use --task \"", "\n", "\"translation_from_pretrained_xlm\"", "\n", ")", "\n", "assert", "not", "(", "\n", "getattr", "(", "args", ",", "\"init_encoder_only\"", ",", "False", ")", "\n", "and", "getattr", "(", "args", ",", "\"init_decoder_only\"", ",", "False", ")", "\n", ")", ",", "\"Only one of --init-encoder-only and --init-decoder-only can be set.\"", "\n", "return", "super", "(", ")", ".", "build_model", "(", "args", ",", "task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_from_pretrained_xlm.TransformerFromPretrainedXLMModel.build_encoder": [[64, 67], ["transformer_from_pretrained_xlm.TransformerEncoderFromPretrainedXLM"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_encoder", "(", "cls", ",", "args", ",", "src_dict", ",", "embed_tokens", ")", ":", "\n", "        ", "return", "TransformerEncoderFromPretrainedXLM", "(", "args", ",", "src_dict", ",", "embed_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_from_pretrained_xlm.TransformerFromPretrainedXLMModel.build_decoder": [[68, 71], ["transformer_from_pretrained_xlm.TransformerDecoderFromPretrainedXLM"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_decoder", "(", "cls", ",", "args", ",", "tgt_dict", ",", "embed_tokens", ")", ":", "\n", "        ", "return", "TransformerDecoderFromPretrainedXLM", "(", "args", ",", "tgt_dict", ",", "embed_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_from_pretrained_xlm.TransformerEncoderFromPretrainedXLM.__init__": [[113, 128], ["fairseq.models.transformer.TransformerEncoder.__init__", "getattr", "hasattr", "transformer_from_pretrained_xlm.upgrade_state_dict_with_xlm_weights", "transformer_from_pretrained_xlm.TransformerEncoderFromPretrainedXLM.load_state_dict", "transformer_from_pretrained_xlm.TransformerEncoderFromPretrainedXLM.state_dict"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.models.transformer_from_pretrained_xlm.upgrade_state_dict_with_xlm_weights", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.state_dict"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "dictionary", ",", "embed_tokens", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "dictionary", ",", "embed_tokens", ")", "\n", "if", "getattr", "(", "args", ",", "\"init_decoder_only\"", ",", "False", ")", ":", "\n", "# Don't load XLM weights for encoder if --init-decoder-only", "\n", "            ", "return", "\n", "\n", "", "assert", "hasattr", "(", "args", ",", "\"pretrained_xlm_checkpoint\"", ")", ",", "(", "\n", "\"--pretrained-xlm-checkpoint must be specified to load Transformer \"", "\n", "\"encoder from pretrained XLM\"", "\n", ")", "\n", "xlm_loaded_state_dict", "=", "upgrade_state_dict_with_xlm_weights", "(", "\n", "state_dict", "=", "self", ".", "state_dict", "(", ")", ",", "\n", "pretrained_xlm_checkpoint", "=", "args", ".", "pretrained_xlm_checkpoint", ",", "\n", ")", "\n", "self", ".", "load_state_dict", "(", "xlm_loaded_state_dict", ",", "strict", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_from_pretrained_xlm.TransformerDecoderFromPretrainedXLM.__init__": [[131, 146], ["fairseq.models.transformer.TransformerDecoder.__init__", "getattr", "hasattr", "transformer_from_pretrained_xlm.upgrade_state_dict_with_xlm_weights", "transformer_from_pretrained_xlm.TransformerDecoderFromPretrainedXLM.load_state_dict", "transformer_from_pretrained_xlm.TransformerDecoderFromPretrainedXLM.state_dict"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.models.transformer_from_pretrained_xlm.upgrade_state_dict_with_xlm_weights", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.state_dict"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "dictionary", ",", "embed_tokens", ",", "no_encoder_attn", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "dictionary", ",", "embed_tokens", ",", "no_encoder_attn", ")", "\n", "if", "getattr", "(", "args", ",", "\"init_encoder_only\"", ",", "False", ")", ":", "\n", "# Don't load XLM weights for decoder if --init-encoder-only", "\n", "            ", "return", "\n", "", "assert", "hasattr", "(", "args", ",", "\"pretrained_xlm_checkpoint\"", ")", ",", "(", "\n", "\"--pretrained-xlm-checkpoint must be specified to load Transformer \"", "\n", "\"decoder from pretrained XLM\"", "\n", ")", "\n", "\n", "xlm_loaded_state_dict", "=", "upgrade_state_dict_with_xlm_weights", "(", "\n", "state_dict", "=", "self", ".", "state_dict", "(", ")", ",", "\n", "pretrained_xlm_checkpoint", "=", "args", ".", "pretrained_xlm_checkpoint", ",", "\n", ")", "\n", "self", ".", "load_state_dict", "(", "xlm_loaded_state_dict", ",", "strict", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_from_pretrained_xlm.upgrade_state_dict_with_xlm_weights": [[73, 110], ["fairseq.checkpoint_utils.load_checkpoint_to_cpu", "xlm_state_dict.keys", "os.path.exists", "IOError", "str", "key.find", "state_dict.keys"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_checkpoint_to_cpu", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists"], ["", "", "def", "upgrade_state_dict_with_xlm_weights", "(", "\n", "state_dict", ":", "Dict", "[", "str", ",", "Any", "]", ",", "pretrained_xlm_checkpoint", ":", "str", "\n", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "    ", "\"\"\"\n    Load XLM weights into a Transformer encoder or decoder model.\n\n    Args:\n        state_dict: state dict for either TransformerEncoder or\n            TransformerDecoder\n        pretrained_xlm_checkpoint: checkpoint to load XLM weights from\n\n    Raises:\n        AssertionError: If architecture (num layers, attention heads, etc.)\n            does not match between the current Transformer encoder or\n            decoder and the pretrained_xlm_checkpoint\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "pretrained_xlm_checkpoint", ")", ":", "\n", "        ", "raise", "IOError", "(", "\"Model file not found: {}\"", ".", "format", "(", "pretrained_xlm_checkpoint", ")", ")", "\n", "\n", "", "state", "=", "checkpoint_utils", ".", "load_checkpoint_to_cpu", "(", "pretrained_xlm_checkpoint", ")", "\n", "xlm_state_dict", "=", "state", "[", "\"model\"", "]", "\n", "for", "key", "in", "xlm_state_dict", ".", "keys", "(", ")", ":", "\n", "\n", "        ", "for", "search_key", "in", "[", "\"embed_tokens\"", ",", "\"embed_positions\"", ",", "\"layers\"", "]", ":", "\n", "            ", "if", "search_key", "in", "key", ":", "\n", "                ", "subkey", "=", "key", "[", "key", ".", "find", "(", "search_key", ")", ":", "]", "\n", "assert", "subkey", "in", "state_dict", ",", "(", "\n", "\"{} Transformer encoder / decoder \"", "\n", "\"state_dict does not contain {}. Cannot \"", "\n", "\"load {} from pretrained XLM checkpoint \"", "\n", "\"{} into Transformer.\"", ".", "format", "(", "\n", "str", "(", "state_dict", ".", "keys", "(", ")", ")", ",", "subkey", ",", "key", ",", "pretrained_xlm_checkpoint", "\n", ")", "\n", ")", "\n", "\n", "state_dict", "[", "subkey", "]", "=", "xlm_state_dict", "[", "key", "]", "\n", "", "", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_from_pretrained_xlm.base_architecture": [[148, 153], ["fairseq.models.register_model_architecture", "fairseq.models.transformer.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "", "@", "register_model_architecture", "(", "\n", "\"transformer_from_pretrained_xlm\"", ",", "\"transformer_from_pretrained_xlm\"", "\n", ")", "\n", "def", "base_architecture", "(", "args", ")", ":", "\n", "    ", "transformer_base_architecture", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.FConvModelSelfAtt.hub_models": [[38, 55], ["None"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "hub_models", "(", "cls", ")", ":", "\n", "        ", "return", "{", "\n", "\"conv.stories.pretrained\"", ":", "{", "\n", "\"path\"", ":", "\"https://dl.fbaipublicfiles.com/fairseq/models/stories_checkpoint.tar.gz\"", ",", "\n", "\"checkpoint_file\"", ":", "\"pretrained_checkpoint.pt\"", ",", "\n", "\"tokenizer\"", ":", "\"nltk\"", ",", "\n", "}", ",", "\n", "\"conv.stories\"", ":", "{", "\n", "\"path\"", ":", "\"https://dl.fbaipublicfiles.com/fairseq/models/stories_checkpoint.tar.gz\"", ",", "\n", "\"checkpoint_file\"", ":", "\"fusion_checkpoint.pt\"", ",", "\n", "\"tokenizer\"", ":", "\"nltk\"", ",", "\n", "\"pretrained\"", ":", "\"True\"", ",", "\n", "\"pretrained_checkpoint\"", ":", "\"./pretrained_checkpoint.pt\"", ",", "\n", "}", ",", "\n", "# Test set containing dictionaries", "\n", "\"data.stories\"", ":", "\"https://dl.fbaipublicfiles.com/fairseq/data/stories_test.tar.bz2\"", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.FConvModelSelfAtt.__init__": [[57, 70], ["fairseq.models.FairseqEncoderDecoderModel.__init__", "sum", "fairseq.models.CompositeEncoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["", "def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ",", "pretrained_encoder", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "encoder", ",", "decoder", ")", "\n", "self", ".", "encoder", ".", "num_attention_layers", "=", "sum", "(", "\n", "layer", "is", "not", "None", "for", "layer", "in", "decoder", ".", "attention", "\n", ")", "\n", "self", ".", "pretrained_encoder", "=", "pretrained_encoder", "\n", "if", "self", ".", "pretrained_encoder", "is", "None", ":", "\n", "            ", "encoders", "=", "{", "\"encoder\"", ":", "encoder", "}", "\n", "", "else", ":", "\n", "            ", "encoders", "=", "{", "\"encoder\"", ":", "encoder", ",", "\"pretrained\"", ":", "self", ".", "pretrained_encoder", "}", "\n", "# for fusion model, CompositeEncoder contains both pretrained and training encoders", "\n", "# these are forwarded and then combined in the decoder", "\n", "", "self", ".", "encoder", "=", "CompositeEncoder", "(", "encoders", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.FConvModelSelfAtt.add_args": [[71, 109], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'encoder embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-layers'", ",", "type", "=", "str", ",", "metavar", "=", "'EXPR'", ",", "\n", "help", "=", "'encoder layers [(dim, kernel_size), ...]'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-layers'", ",", "type", "=", "str", ",", "metavar", "=", "'EXPR'", ",", "\n", "help", "=", "'decoder layers [(dim, kernel_size), ...]'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-out-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder output embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-attention'", ",", "type", "=", "str", ",", "metavar", "=", "'EXPR'", ",", "\n", "help", "=", "'decoder attention [True, ...]'", ")", "\n", "parser", ".", "add_argument", "(", "'--self-attention'", ",", "type", "=", "str", ",", "metavar", "=", "'EXPR'", ",", "\n", "help", "=", "'decoder self-attention layers, ex: [True] + [False]*5'", ")", "\n", "parser", ".", "add_argument", "(", "'--multihead-attention-nheads'", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of heads to use in attention'", ")", "\n", "parser", ".", "add_argument", "(", "'--multihead-self-attention-nheads'", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of heads to use in self-attention'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-attention'", ",", "type", "=", "str", ",", "metavar", "=", "'EXPR'", ",", "\n", "help", "=", "'encoder attention [True, ...]'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-attention-nheads'", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of heads to use in encoder attention'", ")", "\n", "parser", ".", "add_argument", "(", "'--project-input'", ",", "type", "=", "str", ",", "metavar", "=", "'EXPR'", ",", "\n", "help", "=", "'Use projections in self-attention [True, ...]'", ")", "\n", "parser", ".", "add_argument", "(", "'--gated-attention'", ",", "type", "=", "str", ",", "metavar", "=", "'EXPR'", ",", "\n", "help", "=", "'Use GLU layers in self-attention projections [True, ...]'", ")", "\n", "parser", ".", "add_argument", "(", "'--downsample'", ",", "type", "=", "str", ",", "metavar", "=", "'EXPR'", ",", "\n", "help", "=", "'Use downsampling in self-attention [True, ...]'", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrained-checkpoint'", ",", "metavar", "=", "'DIR'", ",", "\n", "help", "=", "'path to load checkpoint from pretrained model'", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrained'", ",", "type", "=", "str", ",", "metavar", "=", "'EXPR'", ",", "\n", "help", "=", "'use pretrained model when training [True, ...]'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.FConvModelSelfAtt.build_model": [[111, 167], ["eval", "fconv_self_att.FConvModelSelfAtt.FConvEncoder", "fconv_self_att.FConvModelSelfAtt.FConvDecoder", "fconv_self_att.FConvModelSelfAtt.FConvModelSelfAtt", "logger.info", "trained_decoder.parameters", "trained_encoder.parameters", "os.path.exists", "os.path.join", "os.path.exists", "list", "list", "eval", "eval", "eval", "eval", "eval", "eval", "eval", "eval", "fairseq.checkpoint_utils.load_model_ensemble", "trained_model.children", "trained_model.children"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_model_ensemble"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "trained_encoder", ",", "trained_decoder", "=", "None", ",", "None", "\n", "pretrained", "=", "eval", "(", "args", ".", "pretrained", ")", "\n", "if", "pretrained", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading pretrained model\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "pretrained_checkpoint", ")", ":", "\n", "                ", "new_pretrained_checkpoint", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "data", ",", "args", ".", "pretrained_checkpoint", "\n", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "new_pretrained_checkpoint", ")", ":", "\n", "                    ", "args", ".", "pretrained_checkpoint", "=", "new_pretrained_checkpoint", "\n", "", "", "trained_model", "=", "checkpoint_utils", ".", "load_model_ensemble", "(", "\n", "filenames", "=", "[", "args", ".", "pretrained_checkpoint", "]", ",", "\n", "task", "=", "task", ",", "\n", ")", "[", "0", "]", "[", "0", "]", "\n", "trained_decoder", "=", "list", "(", "trained_model", ".", "children", "(", ")", ")", "[", "1", "]", "\n", "trained_encoder", "=", "list", "(", "trained_model", ".", "children", "(", ")", ")", "[", "0", "]", "\n", "\n", "# freeze pretrained model", "\n", "for", "param", "in", "trained_decoder", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "for", "param", "in", "trained_encoder", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "encoder", "=", "FConvEncoder", "(", "\n", "task", ".", "source_dictionary", ",", "\n", "embed_dim", "=", "args", ".", "encoder_embed_dim", ",", "\n", "convolutions", "=", "eval", "(", "args", ".", "encoder_layers", ")", ",", "\n", "dropout", "=", "args", ".", "dropout", ",", "\n", "max_positions", "=", "args", ".", "max_source_positions", ",", "\n", "attention", "=", "eval", "(", "args", ".", "encoder_attention", ")", ",", "\n", "attention_nheads", "=", "args", ".", "encoder_attention_nheads", ",", "\n", ")", "\n", "\n", "decoder", "=", "FConvDecoder", "(", "\n", "task", ".", "target_dictionary", ",", "\n", "embed_dim", "=", "args", ".", "decoder_embed_dim", ",", "\n", "convolutions", "=", "eval", "(", "args", ".", "decoder_layers", ")", ",", "\n", "out_embed_dim", "=", "args", ".", "decoder_out_embed_dim", ",", "\n", "attention", "=", "eval", "(", "args", ".", "decoder_attention", ")", ",", "\n", "dropout", "=", "args", ".", "dropout", ",", "\n", "max_positions", "=", "args", ".", "max_target_positions", ",", "\n", "selfattention", "=", "eval", "(", "args", ".", "self_attention", ")", ",", "\n", "attention_nheads", "=", "args", ".", "multihead_attention_nheads", ",", "\n", "selfattention_nheads", "=", "args", ".", "multihead_self_attention_nheads", ",", "\n", "project_input", "=", "eval", "(", "args", ".", "project_input", ")", ",", "\n", "gated_attention", "=", "eval", "(", "args", ".", "gated_attention", ")", ",", "\n", "downsample", "=", "eval", "(", "args", ".", "downsample", ")", ",", "\n", "pretrained", "=", "pretrained", ",", "\n", "trained_decoder", "=", "trained_decoder", ",", "\n", ")", "\n", "model", "=", "FConvModelSelfAtt", "(", "encoder", ",", "decoder", ",", "trained_encoder", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.FConvModelSelfAtt.pretrained": [[168, 171], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "pretrained", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pretrained_encoder", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.FConvEncoder.__init__": [[176, 233], ["fairseq.models.FairseqEncoder.__init__", "fairseq.modules.FairseqDropout", "len", "dictionary.pad", "fconv_self_att.Embedding", "fconv_self_att.PositionalEmbedding", "fconv_self_att.FConvEncoder.FConvEncoder.__init__.expand_bool_array"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.PositionalEmbedding"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dictionary", ",", "\n", "embed_dim", "=", "512", ",", "\n", "max_positions", "=", "1024", ",", "\n", "convolutions", "=", "(", "(", "512", ",", "3", ")", ",", ")", "*", "20", ",", "\n", "dropout", "=", "0.1", ",", "\n", "attention", "=", "False", ",", "\n", "attention_nheads", "=", "1", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "num_attention_layers", "=", "None", "\n", "\n", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "self", ".", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "self", ".", "embed_tokens", "=", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "self", ".", "padding_idx", ")", "\n", "self", ".", "embed_positions", "=", "PositionalEmbedding", "(", "\n", "max_positions", ",", "\n", "embed_dim", ",", "\n", "self", ".", "padding_idx", ",", "\n", ")", "\n", "\n", "def", "expand_bool_array", "(", "val", ")", ":", "\n", "            ", "if", "isinstance", "(", "val", ",", "bool", ")", ":", "\n", "# expand True into [True, True, ...] and do the same with False", "\n", "                ", "return", "[", "val", "]", "*", "len", "(", "convolutions", ")", "\n", "", "return", "val", "\n", "\n", "", "attention", "=", "expand_bool_array", "(", "attention", ")", "\n", "\n", "in_channels", "=", "convolutions", "[", "0", "]", "[", "0", "]", "\n", "self", ".", "fc1", "=", "Linear", "(", "embed_dim", ",", "in_channels", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "projections", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "convolutions", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "attention", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "attproj", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", ",", "(", "out_channels", ",", "kernel_size", ")", "in", "enumerate", "(", "convolutions", ")", ":", "\n", "            ", "self", ".", "projections", ".", "append", "(", "\n", "Linear", "(", "in_channels", ",", "out_channels", ")", "\n", "if", "in_channels", "!=", "out_channels", "\n", "else", "None", "\n", ")", "\n", "self", ".", "convolutions", ".", "append", "(", "\n", "ConvTBC", "(", "in_channels", ",", "out_channels", "*", "2", ",", "kernel_size", ",", "dropout", "=", "dropout", ")", "\n", ")", "\n", "\n", "self", ".", "attention", ".", "append", "(", "\n", "SelfAttention", "(", "out_channels", ",", "embed_dim", ",", "attention_nheads", ")", "\n", "if", "attention", "[", "i", "]", "\n", "else", "None", "\n", ")", "\n", "in_channels", "=", "out_channels", "\n", "\n", "", "self", ".", "fc2", "=", "Linear", "(", "in_channels", ",", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.FConvEncoder.forward": [[234, 288], ["fconv_self_att.FConvEncoder.FConvEncoder.dropout_module", "attention.transpose", "fconv_self_att.FConvEncoder.FConvEncoder.fc1", "src_tokens.eq().t", "attention.transpose", "zip", "attention.transpose", "fconv_self_att.FConvEncoder.FConvEncoder.fc2", "fairseq.modules.GradMultiply.apply", "fconv_self_att.FConvEncoder.FConvEncoder.embed_tokens", "fconv_self_att.FConvEncoder.FConvEncoder.embed_positions", "encoder_padding_mask.t.t.any", "fconv_self_att.FConvEncoder.FConvEncoder.dropout_module", "torch.pad", "torch.pad", "torch.pad", "conv", "torch.glu", "torch.glu", "torch.glu", "encoder_padding_mask.t.t.t", "attention.masked_fill", "math.sqrt", "src_tokens.eq", "proj", "attention.masked_fill", "attention", "math.sqrt", "encoder_padding_mask.t.t.unsqueeze", "attention.transpose.transpose", "encoder_padding_mask.t.t.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ")", ":", "\n", "# embed tokens and positions", "\n", "        ", "x", "=", "self", ".", "embed_tokens", "(", "src_tokens", ")", "+", "self", ".", "embed_positions", "(", "src_tokens", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "input_embedding", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# project to size of convolution", "\n", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "\n", "encoder_padding_mask", "=", "src_tokens", ".", "eq", "(", "self", ".", "padding_idx", ")", ".", "t", "(", ")", "# -> T x B", "\n", "if", "not", "encoder_padding_mask", ".", "any", "(", ")", ":", "\n", "            ", "encoder_padding_mask", "=", "None", "\n", "\n", "# B x T x C -> T x B x C", "\n", "", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# temporal convolutions", "\n", "for", "proj", ",", "conv", ",", "attention", "in", "zip", "(", "\n", "self", ".", "projections", ",", "self", ".", "convolutions", ",", "self", ".", "attention", "\n", ")", ":", "\n", "            ", "residual", "=", "x", "if", "proj", "is", "None", "else", "proj", "(", "x", ")", "\n", "\n", "if", "encoder_padding_mask", "is", "not", "None", ":", "\n", "                ", "x", "=", "x", ".", "masked_fill", "(", "encoder_padding_mask", ".", "unsqueeze", "(", "-", "1", ")", ",", "0", ")", "\n", "\n", "", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "padding_l", "=", "(", "conv", ".", "kernel_size", "[", "0", "]", "-", "1", ")", "//", "2", "\n", "padding_r", "=", "conv", ".", "kernel_size", "[", "0", "]", "//", "2", "\n", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "0", ",", "0", ",", "0", ",", "padding_l", ",", "padding_r", ")", ")", "\n", "x", "=", "conv", "(", "x", ")", "\n", "x", "=", "F", ".", "glu", "(", "x", ",", "dim", "=", "2", ")", "\n", "if", "attention", "is", "not", "None", ":", "\n", "                ", "x", "=", "attention", "(", "x", ")", "\n", "", "x", "=", "(", "x", "+", "residual", ")", "*", "math", ".", "sqrt", "(", "0.5", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "", "x", "=", "x", ".", "transpose", "(", "1", ",", "0", ")", "\n", "\n", "# project back to size of embedding", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "\n", "if", "encoder_padding_mask", "is", "not", "None", ":", "\n", "            ", "encoder_padding_mask", "=", "encoder_padding_mask", ".", "t", "(", ")", "# -> B x T", "\n", "x", "=", "x", ".", "masked_fill", "(", "encoder_padding_mask", ".", "unsqueeze", "(", "-", "1", ")", ",", "0", ")", "\n", "\n", "# scale gradients (this only affects backward, not forward)", "\n", "", "x", "=", "GradMultiply", ".", "apply", "(", "x", ",", "1.0", "/", "(", "2.0", "*", "self", ".", "num_attention_layers", ")", ")", "\n", "\n", "# add output to input embedding for attention", "\n", "y", "=", "(", "x", "+", "input_embedding", ".", "transpose", "(", "0", ",", "1", ")", ")", "*", "math", ".", "sqrt", "(", "0.5", ")", "\n", "\n", "return", "{", "\n", "\"encoder_out\"", ":", "(", "x", ",", "y", ")", ",", "\n", "\"encoder_padding_mask\"", ":", "encoder_padding_mask", ",", "# B x T", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.FConvEncoder.reorder_encoder_out": [[290, 307], ["tuple", "encoder_out[].index_select", "tuple", "eo.index_select", "eo.index_select"], "methods", ["None"], ["", "def", "reorder_encoder_out", "(", "self", ",", "encoder_out", ",", "new_order", ")", ":", "\n", "        ", "encoder_out", "[", "\"encoder_out\"", "]", "=", "tuple", "(", "\n", "eo", ".", "index_select", "(", "0", ",", "new_order", ")", "for", "eo", "in", "encoder_out", "[", "\"encoder_out\"", "]", "\n", ")", "\n", "\n", "if", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "is", "not", "None", ":", "\n", "            ", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "=", "encoder_out", "[", "\n", "\"encoder_padding_mask\"", "\n", "]", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", "\n", "", "if", "\"pretrained\"", "in", "encoder_out", ":", "\n", "            ", "encoder_out", "[", "\"pretrained\"", "]", "[", "\"encoder_out\"", "]", "=", "tuple", "(", "\n", "eo", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", "for", "eo", "in", "encoder_out", "[", "\"pretrained\"", "]", "[", "\"encoder_out\"", "]", "\n", ")", "\n", "\n", "", "return", "encoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.FConvEncoder.max_positions": [[308, 311], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum input length supported by the encoder.\"\"\"", "\n", "return", "self", ".", "embed_positions", ".", "max_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.FConvDecoder.__init__": [[317, 459], ["fairseq.models.FairseqDecoder.__init__", "fconv_self_att.FConvDecoder.FConvDecoder.register_buffer", "fairseq.modules.FairseqDropout", "fconv_self_att.FConvDecoder.FConvDecoder.__init__.expand_bool_array"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dictionary", ",", "\n", "embed_dim", "=", "512", ",", "\n", "out_embed_dim", "=", "256", ",", "\n", "max_positions", "=", "1024", ",", "\n", "convolutions", "=", "(", "(", "512", ",", "3", ")", ",", ")", "*", "8", ",", "\n", "attention", "=", "True", ",", "\n", "dropout", "=", "0.1", ",", "\n", "selfattention", "=", "False", ",", "\n", "attention_nheads", "=", "1", ",", "\n", "selfattention_nheads", "=", "1", ",", "\n", "project_input", "=", "False", ",", "\n", "gated_attention", "=", "False", ",", "\n", "downsample", "=", "False", ",", "\n", "pretrained", "=", "False", ",", "\n", "trained_decoder", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "self", ".", "register_buffer", "(", "\"version\"", ",", "torch", ".", "Tensor", "(", "[", "2", "]", ")", ")", "\n", "self", ".", "pretrained", "=", "pretrained", "\n", "self", ".", "pretrained_decoder", "=", "trained_decoder", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "need_attn", "=", "True", "\n", "in_channels", "=", "convolutions", "[", "0", "]", "[", "0", "]", "\n", "\n", "def", "expand_bool_array", "(", "val", ")", ":", "\n", "            ", "if", "isinstance", "(", "val", ",", "bool", ")", ":", "\n", "# expand True into [True, True, ...] and do the same with False", "\n", "                ", "return", "[", "val", "]", "*", "len", "(", "convolutions", ")", "\n", "", "return", "val", "\n", "\n", "", "attention", "=", "expand_bool_array", "(", "attention", ")", "\n", "selfattention", "=", "expand_bool_array", "(", "selfattention", ")", "\n", "\n", "if", "not", "isinstance", "(", "attention", ",", "list", ")", "or", "len", "(", "attention", ")", "!=", "len", "(", "convolutions", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Attention is expected to be a list of booleans of \"", "\n", "\"length equal to the number of layers.\"", "\n", ")", "\n", "\n", "", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "self", ".", "embed_tokens", "=", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "padding_idx", ")", "\n", "\n", "self", ".", "embed_positions", "=", "PositionalEmbedding", "(", "\n", "max_positions", ",", "\n", "embed_dim", ",", "\n", "padding_idx", ",", "\n", ")", "\n", "\n", "self", ".", "fc1", "=", "Linear", "(", "embed_dim", ",", "in_channels", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "projections", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "convolutions", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "attention", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "selfattention", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "attproj", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", ",", "(", "out_channels", ",", "kernel_size", ")", "in", "enumerate", "(", "convolutions", ")", ":", "\n", "            ", "self", ".", "projections", ".", "append", "(", "\n", "Linear", "(", "in_channels", ",", "out_channels", ")", "\n", "if", "in_channels", "!=", "out_channels", "\n", "else", "None", "\n", ")", "\n", "self", ".", "convolutions", ".", "append", "(", "\n", "LinearizedConv1d", "(", "\n", "in_channels", ",", "\n", "out_channels", "*", "2", ",", "\n", "kernel_size", ",", "\n", "padding", "=", "(", "kernel_size", "-", "1", ")", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", ")", "\n", "\n", "self", ".", "attention", ".", "append", "(", "\n", "DownsampledMultiHeadAttention", "(", "\n", "out_channels", ",", "\n", "embed_dim", ",", "\n", "attention_nheads", ",", "\n", "project_input", "=", "project_input", ",", "\n", "gated", "=", "False", ",", "\n", "downsample", "=", "False", ",", "\n", ")", "\n", "if", "attention", "[", "i", "]", "\n", "else", "None", "\n", ")", "\n", "\n", "self", ".", "attproj", ".", "append", "(", "\n", "Linear", "(", "out_channels", ",", "embed_dim", ",", "dropout", "=", "dropout", ")", "\n", "if", "attention", "[", "i", "]", "\n", "else", "None", "\n", ")", "\n", "self", ".", "selfattention", ".", "append", "(", "\n", "SelfAttention", "(", "\n", "out_channels", ",", "\n", "embed_dim", ",", "\n", "selfattention_nheads", ",", "\n", "project_input", "=", "project_input", ",", "\n", "gated", "=", "gated_attention", ",", "\n", "downsample", "=", "downsample", ",", "\n", ")", "\n", "if", "selfattention", "[", "i", "]", "\n", "else", "None", "\n", ")", "\n", "in_channels", "=", "out_channels", "\n", "\n", "", "self", ".", "fc2", "=", "Linear", "(", "in_channels", ",", "out_embed_dim", ")", "\n", "self", ".", "fc3", "=", "Linear", "(", "out_embed_dim", ",", "num_embeddings", ",", "dropout", "=", "dropout", ")", "\n", "\n", "# model fusion", "\n", "if", "self", ".", "pretrained", ":", "\n", "# independent gates are learned from the concatenated input", "\n", "            ", "self", ".", "gate1", "=", "nn", ".", "Sequential", "(", "\n", "Linear", "(", "out_embed_dim", "*", "2", ",", "out_embed_dim", ")", ",", "nn", ".", "Sigmoid", "(", ")", "\n", ")", "\n", "self", ".", "gate2", "=", "nn", ".", "Sequential", "(", "\n", "Linear", "(", "out_embed_dim", "*", "2", ",", "out_embed_dim", ")", ",", "nn", ".", "Sigmoid", "(", ")", "\n", ")", "\n", "# pretrained and trained models are joined", "\n", "self", ".", "joining", "=", "nn", ".", "Sequential", "(", "\n", "Linear", "(", "out_embed_dim", "*", "2", ",", "out_embed_dim", "*", "2", ")", ",", "\n", "LayerNorm", "(", "out_embed_dim", "*", "2", ")", ",", "\n", "nn", ".", "GLU", "(", ")", ",", "\n", "Linear", "(", "out_embed_dim", ",", "out_embed_dim", "*", "2", ")", ",", "\n", "LayerNorm", "(", "out_embed_dim", "*", "2", ")", ",", "\n", "nn", ".", "GLU", "(", ")", ",", "\n", "Linear", "(", "out_embed_dim", ",", "out_embed_dim", ")", ",", "\n", "LayerNorm", "(", "out_embed_dim", ")", ",", "\n", ")", "\n", "# pretrained model contains an output layer that is nhid -> vocab size", "\n", "# but the models are combined in their hidden state", "\n", "# the hook stores the output of the pretrained model forward", "\n", "self", ".", "pretrained_outputs", "=", "{", "}", "\n", "\n", "def", "save_output", "(", ")", ":", "\n", "                ", "def", "hook", "(", "a", ",", "b", ",", "output", ")", ":", "\n", "                    ", "self", ".", "pretrained_outputs", "[", "\"out\"", "]", "=", "output", "\n", "\n", "", "return", "hook", "\n", "\n", "", "self", ".", "pretrained_decoder", ".", "fc2", ".", "register_forward_hook", "(", "save_output", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.FConvDecoder.forward": [[460, 538], ["fconv_self_att.FConvDecoder.FConvDecoder._split_encoder_out", "fconv_self_att.FConvDecoder.FConvDecoder.embed_positions", "fconv_self_att.FConvDecoder.FConvDecoder.dropout_module", "fconv_self_att.FConvDecoder.FConvDecoder.transpose", "fconv_self_att.FConvDecoder.FConvDecoder.fc1", "fconv_self_att.FConvDecoder.FConvDecoder.transpose", "zip", "fconv_self_att.FConvDecoder.FConvDecoder.transpose", "fconv_self_att.FConvDecoder.FConvDecoder.fc2", "fconv_self_att.FConvDecoder.FConvDecoder.dropout_module", "fconv_self_att.FConvDecoder.FConvDecoder.embed_tokens", "fconv_self_att.FConvDecoder.FConvDecoder.dropout_module", "conv", "torch.glu", "torch.glu", "torch.glu", "fconv_self_att.FConvDecoder.FConvDecoder.fc3", "fconv_self_att.FConvDecoder.FConvDecoder.pretrained_decoder.forward", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "fconv_self_att.FConvDecoder.FConvDecoder.gate1", "fconv_self_att.FConvDecoder.FConvDecoder.gate2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "fconv_self_att.FConvDecoder.FConvDecoder.joining", "fconv_self_att.FConvDecoder.FConvDecoder.fc3", "proj", "attention", "fconv_self_att.FConvDecoder.FConvDecoder.", "math.sqrt", "attproj", "avg_attn_scores.add_"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvDecoder._split_encoder_out", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.forward"], ["", "", "def", "forward", "(", "self", ",", "prev_output_tokens", ",", "encoder_out", ")", ":", "\n", "        ", "trained_encoder_out", "=", "encoder_out", "[", "\"pretrained\"", "]", "if", "self", ".", "pretrained", "else", "None", "\n", "encoder_out", "=", "encoder_out", "[", "\"encoder\"", "]", "[", "\"encoder_out\"", "]", "\n", "\n", "encoder_a", ",", "encoder_b", "=", "self", ".", "_split_encoder_out", "(", "encoder_out", ")", "\n", "\n", "# embed positions", "\n", "positions", "=", "self", ".", "embed_positions", "(", "prev_output_tokens", ")", "\n", "\n", "# embed tokens and positions", "\n", "x", "=", "self", ".", "embed_tokens", "(", "prev_output_tokens", ")", "+", "positions", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "target_embedding", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# project to size of convolution", "\n", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# temporal convolutions", "\n", "avg_attn_scores", "=", "None", "\n", "for", "proj", ",", "conv", ",", "attention", ",", "selfattention", ",", "attproj", "in", "zip", "(", "\n", "self", ".", "projections", ",", "\n", "self", ".", "convolutions", ",", "\n", "self", ".", "attention", ",", "\n", "self", ".", "selfattention", ",", "\n", "self", ".", "attproj", ",", "\n", ")", ":", "\n", "            ", "residual", "=", "x", "if", "proj", "is", "None", "else", "proj", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "conv", "(", "x", ")", "\n", "x", "=", "F", ".", "glu", "(", "x", ",", "dim", "=", "2", ")", "\n", "\n", "# attention", "\n", "if", "attention", "is", "not", "None", ":", "\n", "                ", "r", "=", "x", "\n", "x", ",", "attn_scores", "=", "attention", "(", "\n", "attproj", "(", "x", ")", "+", "target_embedding", ",", "encoder_a", ",", "encoder_b", "\n", ")", "\n", "x", "=", "x", "+", "r", "\n", "if", "not", "self", ".", "training", "and", "self", ".", "need_attn", ":", "\n", "                    ", "if", "avg_attn_scores", "is", "None", ":", "\n", "                        ", "avg_attn_scores", "=", "attn_scores", "\n", "", "else", ":", "\n", "                        ", "avg_attn_scores", ".", "add_", "(", "attn_scores", ")", "\n", "\n", "", "", "", "if", "selfattention", "is", "not", "None", ":", "\n", "                ", "x", "=", "selfattention", "(", "x", ")", "\n", "\n", "", "x", "=", "(", "x", "+", "residual", ")", "*", "math", ".", "sqrt", "(", "0.5", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# project back to size of vocabulary", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "if", "not", "self", ".", "pretrained", ":", "\n", "            ", "x", "=", "self", ".", "fc3", "(", "x", ")", "\n", "\n", "# fusion gating", "\n", "", "if", "self", ".", "pretrained", ":", "\n", "            ", "trained_x", ",", "_", "=", "self", ".", "pretrained_decoder", ".", "forward", "(", "\n", "prev_output_tokens", ",", "trained_encoder_out", "\n", ")", "\n", "y", "=", "torch", ".", "cat", "(", "[", "x", ",", "self", ".", "pretrained_outputs", "[", "\"out\"", "]", "]", ",", "dim", "=", "-", "1", ")", "\n", "gate1", "=", "self", ".", "gate1", "(", "y", ")", "\n", "gate2", "=", "self", ".", "gate2", "(", "y", ")", "\n", "gated_x1", "=", "gate1", "*", "x", "\n", "gated_x2", "=", "gate2", "*", "self", ".", "pretrained_outputs", "[", "\"out\"", "]", "\n", "fusion", "=", "torch", ".", "cat", "(", "[", "gated_x1", ",", "gated_x2", "]", ",", "dim", "=", "-", "1", ")", "\n", "fusion", "=", "self", ".", "joining", "(", "fusion", ")", "\n", "fusion_output", "=", "self", ".", "fc3", "(", "fusion", ")", "\n", "return", "fusion_output", ",", "avg_attn_scores", "\n", "", "else", ":", "\n", "            ", "return", "x", ",", "avg_attn_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.FConvDecoder.max_positions": [[539, 542], ["None"], "methods", ["None"], ["", "", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum output length supported by the decoder.\"\"\"", "\n", "return", "self", ".", "embed_positions", ".", "max_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.FConvDecoder.make_generation_fast_": [[543, 545], ["None"], "methods", ["None"], ["", "def", "make_generation_fast_", "(", "self", ",", "need_attn", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "need_attn", "=", "need_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.FConvDecoder._split_encoder_out": [[546, 554], ["encoder_a.transpose().contiguous.transpose().contiguous.transpose().contiguous", "encoder_b.transpose().contiguous.transpose().contiguous.transpose().contiguous", "encoder_a.transpose().contiguous.transpose().contiguous.transpose", "encoder_b.transpose().contiguous.transpose().contiguous.transpose"], "methods", ["None"], ["", "def", "_split_encoder_out", "(", "self", ",", "encoder_out", ")", ":", "\n", "        ", "\"\"\"Split and transpose encoder outputs.\"\"\"", "\n", "# transpose only once to speed up attention layers", "\n", "encoder_a", ",", "encoder_b", "=", "encoder_out", "\n", "encoder_a", "=", "encoder_a", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "encoder_b", "=", "encoder_b", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "result", "=", "(", "encoder_a", ",", "encoder_b", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.SelfAttention.__init__": [[557, 581], ["torch.Module.__init__", "fairseq.modules.DownsampledMultiHeadAttention", "fconv_self_att.Linear", "fconv_self_att.Linear", "fconv_self_att.Linear", "fairseq.modules.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "out_channels", ",", "\n", "embed_dim", ",", "\n", "num_heads", ",", "\n", "project_input", "=", "False", ",", "\n", "gated", "=", "False", ",", "\n", "downsample", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention", "=", "DownsampledMultiHeadAttention", "(", "\n", "out_channels", ",", "\n", "embed_dim", ",", "\n", "num_heads", ",", "\n", "dropout", "=", "0", ",", "\n", "bias", "=", "True", ",", "\n", "project_input", "=", "project_input", ",", "\n", "gated", "=", "gated", ",", "\n", "downsample", "=", "downsample", ",", "\n", ")", "\n", "self", ".", "in_proj_q", "=", "Linear", "(", "out_channels", ",", "embed_dim", ")", "\n", "self", ".", "in_proj_k", "=", "Linear", "(", "out_channels", ",", "embed_dim", ")", "\n", "self", ".", "in_proj_v", "=", "Linear", "(", "out_channels", ",", "embed_dim", ")", "\n", "self", ".", "ln", "=", "LayerNorm", "(", "out_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.SelfAttention.forward": [[582, 591], ["fconv_self_att.SelfAttention.SelfAttention.in_proj_q", "fconv_self_att.SelfAttention.SelfAttention.in_proj_k", "fconv_self_att.SelfAttention.SelfAttention.in_proj_v", "fconv_self_att.SelfAttention.SelfAttention.attention", "fconv_self_att.SelfAttention.SelfAttention.ln"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "query", "=", "self", ".", "in_proj_q", "(", "x", ")", "\n", "key", "=", "self", ".", "in_proj_k", "(", "x", ")", "\n", "value", "=", "self", ".", "in_proj_v", "(", "x", ")", "\n", "x", ",", "_", "=", "self", ".", "attention", "(", "\n", "query", ",", "key", ",", "value", ",", "mask_future_timesteps", "=", "True", ",", "use_scalar_bias", "=", "True", "\n", ")", "\n", "return", "self", ".", "ln", "(", "x", "+", "residual", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.Embedding": [[593, 597], ["torch.Embedding", "nn.Embedding.weight.data.normal_"], "function", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding"], ["", "", "def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.1", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.PositionalEmbedding": [[599, 603], ["fairseq.modules.LearnedPositionalEmbedding", "fairseq.modules.LearnedPositionalEmbedding.weight.data.normal_"], "function", ["None"], ["", "def", "PositionalEmbedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "LearnedPositionalEmbedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.1", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.Linear": [[605, 611], ["torch.Linear", "nn.Linear.weight.data.normal_", "nn.Linear.bias.data.zero_", "math.sqrt"], "function", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["", "def", "Linear", "(", "in_features", ",", "out_features", ",", "dropout", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"Weight-normalized Linear layer (input: N x T x C)\"\"\"", "\n", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ")", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0", ",", "std", "=", "math", ".", "sqrt", "(", "(", "1", "-", "dropout", ")", "/", "in_features", ")", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.LinearizedConv1d": [[613, 620], ["fairseq.modules.LinearizedConvolution", "math.sqrt", "fairseq.modules.LinearizedConvolution.weight.data.normal_", "fairseq.modules.LinearizedConvolution.bias.data.zero_"], "function", ["None"], ["", "def", "LinearizedConv1d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "dropout", "=", "0.0", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Weight-normalized Conv1d layer optimized for decoding\"\"\"", "\n", "m", "=", "LinearizedConvolution", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "**", "kwargs", ")", "\n", "std", "=", "math", ".", "sqrt", "(", "(", "4", "*", "(", "1.0", "-", "dropout", ")", ")", "/", "(", "m", ".", "kernel_size", "[", "0", "]", "*", "in_channels", ")", ")", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0", ",", "std", "=", "std", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.ConvTBC": [[622, 631], ["fconv_self_att.ConvTBC", "math.sqrt", "ConvTBC.weight.data.normal_", "ConvTBC.bias.data.zero_"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.fconv.ConvTBC"], ["", "def", "ConvTBC", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "dropout", "=", "0.0", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Weight-normalized Conv1d layer\"\"\"", "\n", "from", "fairseq", ".", "modules", "import", "ConvTBC", "\n", "\n", "m", "=", "ConvTBC", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "**", "kwargs", ")", "\n", "std", "=", "math", ".", "sqrt", "(", "(", "4", "*", "(", "1.0", "-", "dropout", ")", ")", "/", "(", "m", ".", "kernel_size", "[", "0", "]", "*", "in_channels", ")", ")", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0", ",", "std", "=", "std", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.base_architecture": [[633, 654], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "@", "register_model_architecture", "(", "\"fconv_self_att\"", ",", "\"fconv_self_att\"", ")", "\n", "def", "base_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "\"[(512, 3)] * 3\"", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "\"[(512, 3)] * 8\"", ")", "\n", "args", ".", "decoder_out_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_out_embed_dim\"", ",", "256", ")", "\n", "args", ".", "decoder_attention", "=", "getattr", "(", "args", ",", "\"decoder_attention\"", ",", "\"True\"", ")", "\n", "args", ".", "self_attention", "=", "getattr", "(", "args", ",", "\"self_attention\"", ",", "\"False\"", ")", "\n", "args", ".", "encoder_attention", "=", "getattr", "(", "args", ",", "\"encoder_attention\"", ",", "\"False\"", ")", "\n", "args", ".", "multihead_attention_nheads", "=", "getattr", "(", "args", ",", "\"multihead_attention_nheads\"", ",", "1", ")", "\n", "args", ".", "multihead_self_attention_nheads", "=", "getattr", "(", "\n", "args", ",", "\"multihead_self_attention_nheads\"", ",", "1", "\n", ")", "\n", "args", ".", "encoder_attention_nheads", "=", "getattr", "(", "args", ",", "\"encoder_attention_nheads\"", ",", "1", ")", "\n", "args", ".", "project_input", "=", "getattr", "(", "args", ",", "\"project_input\"", ",", "\"False\"", ")", "\n", "args", ".", "gated_attention", "=", "getattr", "(", "args", ",", "\"gated_attention\"", ",", "\"False\"", ")", "\n", "args", ".", "downsample", "=", "getattr", "(", "args", ",", "\"downsample\"", ",", "\"False\"", ")", "\n", "args", ".", "pretrained_checkpoint", "=", "getattr", "(", "args", ",", "\"pretrained_checkpoint\"", ",", "\"\"", ")", "\n", "args", ".", "pretrained", "=", "getattr", "(", "args", ",", "\"pretrained\"", ",", "\"False\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv_self_att.fconv_self_att_wp": [[656, 675], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "fconv_self_att.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "@", "register_model_architecture", "(", "\"fconv_self_att\"", ",", "\"fconv_self_att_wp\"", ")", "\n", "def", "fconv_self_att_wp", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "256", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "\n", "args", ",", "\"encoder_layers\"", ",", "\"[(128, 3)] * 2 + [(512,3)] * 1\"", "\n", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "256", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "\n", "args", ",", "\"decoder_layers\"", ",", "\"[(512, 4)] * 4 + [(768, 4)] * 2 + [(1024, 4)] * 1\"", "\n", ")", "\n", "args", ".", "decoder_out_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_out_embed_dim\"", ",", "256", ")", "\n", "args", ".", "self_attention", "=", "getattr", "(", "args", ",", "\"self_attention\"", ",", "\"True\"", ")", "\n", "args", ".", "multihead_self_attention_nheads", "=", "getattr", "(", "\n", "args", ",", "\"multihead_self_attention_nheads\"", ",", "4", "\n", ")", "\n", "args", ".", "project_input", "=", "getattr", "(", "args", ",", "\"project_input\"", ",", "\"True\"", ")", "\n", "args", ".", "gated_attention", "=", "getattr", "(", "args", ",", "\"gated_attention\"", ",", "\"True\"", ")", "\n", "args", ".", "downsample", "=", "getattr", "(", "args", ",", "\"downsample\"", ",", "\"True\"", ")", "\n", "base_architecture", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_encoder.FairseqEncoder.__init__": [[30, 33], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_encoder.FairseqEncoder.forward": [[34, 43], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            src_tokens (LongTensor): tokens in the source language of shape\n                `(batch, src_len)`\n            src_lengths (LongTensor): lengths of each source sentence of shape\n                `(batch)`\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_encoder.FairseqEncoder.forward_torchscript": [[44, 57], ["torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "fairseq_encoder.FairseqEncoder.forward", "fairseq_encoder.FairseqEncoder.forward_non_torchscript"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.forward", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_encoder.FairseqEncoder.forward_non_torchscript"], ["", "def", "forward_torchscript", "(", "self", ",", "net_input", ":", "Dict", "[", "str", ",", "Tensor", "]", ")", ":", "\n", "        ", "\"\"\"A TorchScript-compatible version of forward.\n\n        Encoders which use additional arguments may want to override\n        this method for TorchScript compatibility.\n        \"\"\"", "\n", "if", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "            ", "return", "self", ".", "forward", "(", "\n", "src_tokens", "=", "net_input", "[", "\"src_tokens\"", "]", ",", "\n", "src_lengths", "=", "net_input", "[", "\"src_lengths\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "forward_non_torchscript", "(", "net_input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_encoder.FairseqEncoder.forward_non_torchscript": [[58, 64], ["fairseq_encoder.FairseqEncoder.forward", "net_input.items"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.forward"], ["", "", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "forward_non_torchscript", "(", "self", ",", "net_input", ":", "Dict", "[", "str", ",", "Tensor", "]", ")", ":", "\n", "        ", "encoder_input", "=", "{", "\n", "k", ":", "v", "for", "k", ",", "v", "in", "net_input", ".", "items", "(", ")", "if", "k", "!=", "\"prev_output_tokens\"", "\n", "}", "\n", "return", "self", ".", "forward", "(", "**", "encoder_input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_encoder.FairseqEncoder.reorder_encoder_out": [[65, 77], ["None"], "methods", ["None"], ["", "def", "reorder_encoder_out", "(", "self", ",", "encoder_out", ",", "new_order", ")", ":", "\n", "        ", "\"\"\"\n        Reorder encoder output according to `new_order`.\n\n        Args:\n            encoder_out: output from the ``forward()`` method\n            new_order (LongTensor): desired order\n\n        Returns:\n            `encoder_out` rearranged according to `new_order`\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_encoder.FairseqEncoder.max_positions": [[78, 81], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum input length supported by the encoder.\"\"\"", "\n", "return", "1e6", "# an arbitrary large number", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_encoder.FairseqEncoder.upgrade_state_dict": [[82, 85], ["None"], "methods", ["None"], ["", "def", "upgrade_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Upgrade a (possibly old) state dict for new versions of fairseq.\"\"\"", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_encoder.FairseqEncoder.set_num_updates": [[86, 94], ["fairseq_encoder.FairseqEncoder.apply", "hasattr", "m.set_num_updates"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.Wav2VecEncoder.set_num_updates"], ["", "def", "set_num_updates", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"State from trainer to pass along to model at every update.\"\"\"", "\n", "\n", "def", "_apply", "(", "m", ")", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "\"set_num_updates\"", ")", "and", "m", "!=", "self", ":", "\n", "                ", "m", ".", "set_num_updates", "(", "num_updates", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "_apply", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.models.model_utils.script_skip_tensor_list": [[12, 22], ["enumerate", "t.numel", "outputs.append", "outputs.append", "xi.size", "mask.size"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["@", "torch", ".", "jit", ".", "script", "\n", "def", "script_skip_tensor_list", "(", "x", ":", "List", "[", "Tensor", "]", ",", "mask", ")", ":", "\n", "    ", "res", "=", "[", "xi", "[", "mask", "]", "if", "xi", ".", "size", "(", "0", ")", "==", "mask", ".", "size", "(", "0", ")", "else", "xi", "[", ":", ",", "mask", "]", "for", "xi", "in", "x", "]", "\n", "outputs", "=", "[", "]", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "res", ")", ":", "\n", "        ", "if", "t", ".", "numel", "(", ")", "!=", "0", ":", "\n", "            ", "outputs", ".", "append", "(", "t", ")", "\n", "", "else", ":", "\n", "            ", "outputs", ".", "append", "(", "x", "[", "i", "]", ")", "\n", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.model_utils.script_skip_tensor": [[24, 34], ["x.size", "res.numel", "x.size", "mask.size"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "@", "torch", ".", "jit", ".", "script", "\n", "def", "script_skip_tensor", "(", "x", ":", "Tensor", ",", "mask", ")", ":", "\n", "# None case", "\n", "    ", "if", "x", ".", "size", "(", "0", ")", "==", "0", ":", "\n", "        ", "return", "x", "\n", "", "res", "=", "x", "[", "mask", "]", "if", "x", ".", "size", "(", "0", ")", "==", "mask", ".", "size", "(", "0", ")", "else", "x", "[", ":", ",", "mask", "]", "\n", "if", "res", ".", "numel", "(", ")", "==", "0", ":", "\n", "        ", "return", "x", "\n", "", "else", ":", "\n", "        ", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.model_utils.expand_2d_or_3d_tensor": [[36, 55], ["torch.cat", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.dim", "dims.append", "torch.cat.dim", "torch.cat.dim", "torch.cat.size", "torch.cat.size", "torch.zeros().to().fill_", "torch.zeros().to", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "", "@", "torch", ".", "jit", ".", "script", "\n", "def", "expand_2d_or_3d_tensor", "(", "x", ",", "trg_dim", ":", "int", ",", "padding_idx", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    Expand 2D/3D tensor on dim=1\n    \"\"\"", "\n", "if", "x", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "assert", "x", ".", "dim", "(", ")", "==", "2", "or", "x", ".", "dim", "(", ")", "==", "3", "\n", "assert", "trg_dim", ">=", "x", ".", "size", "(", "1", ")", ",", "(", "trg_dim", ",", "x", ".", "size", "(", ")", ")", "\n", "if", "trg_dim", "==", "x", ".", "size", "(", "1", ")", ":", "\n", "        ", "return", "x", "\n", "\n", "", "dims", "=", "[", "x", ".", "size", "(", "0", ")", ",", "trg_dim", "-", "x", ".", "size", "(", "1", ")", "]", "\n", "if", "x", ".", "dim", "(", ")", "==", "3", ":", "\n", "        ", "dims", ".", "append", "(", "x", ".", "size", "(", "2", ")", ")", "\n", "", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "torch", ".", "zeros", "(", "dims", ")", ".", "to", "(", "x", ")", ".", "fill_", "(", "padding_idx", ")", "]", ",", "1", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.model_utils.coalesce": [[57, 60], ["None"], "function", ["None"], ["", "@", "torch", ".", "jit", ".", "script", "\n", "def", "coalesce", "(", "x", ":", "Optional", "[", "Tensor", "]", ",", "y", ":", "Tensor", ")", "->", "Tensor", ":", "\n", "    ", "return", "x", "if", "x", "is", "not", "None", "else", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.model_utils.fill_tensors": [[62, 93], ["mask.sum", "y.size", "expand_2d_or_3d_tensor.size", "expand_2d_or_3d_tensor.size", "y.size", "model_utils.expand_2d_or_3d_tensor", "expand_2d_or_3d_tensor.dim", "y.dim", "mask.size", "expand_2d_or_3d_tensor.size", "expand_2d_or_3d_tensor.dim", "y.size", "expand_2d_or_3d_tensor.size", "y.size", "torch.tensor().type_as", "expand_2d_or_3d_tensor.size", "expand_2d_or_3d_tensor.dim", "expand_2d_or_3d_tensor.size", "y.size", "expand_2d_or_3d_tensor.dim", "torch.tensor", "y.size", "y.size"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.models.model_utils.expand_2d_or_3d_tensor", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "@", "torch", ".", "jit", ".", "script", "\n", "def", "fill_tensors", "(", "\n", "x", ":", "Optional", "[", "Tensor", "]", ",", "mask", ",", "y", ":", "Optional", "[", "Tensor", "]", ",", "padding_idx", ":", "int", "\n", ")", "->", "Optional", "[", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n    Filling tensor x with y at masked positions (dim=0).\n    \"\"\"", "\n", "if", "x", "is", "None", "or", "x", ".", "size", "(", ")", "[", "0", "]", "==", "0", "or", "y", "is", "None", ":", "\n", "        ", "return", "x", "\n", "", "assert", "x", ".", "dim", "(", ")", "==", "y", ".", "dim", "(", ")", "and", "mask", ".", "size", "(", "0", ")", "==", "x", ".", "size", "(", "0", ")", "\n", "assert", "x", ".", "dim", "(", ")", "==", "2", "or", "(", "x", ".", "dim", "(", ")", "==", "3", "and", "x", ".", "size", "(", "2", ")", "==", "y", ".", "size", "(", "2", ")", ")", "\n", "\n", "n_selected", "=", "mask", ".", "sum", "(", ")", "\n", "if", "n_selected", "==", "0", ":", "\n", "        ", "return", "x", "\n", "", "assert", "n_selected", "==", "y", ".", "size", "(", "0", ")", "\n", "if", "n_selected", "==", "x", ".", "size", "(", "0", ")", ":", "\n", "        ", "return", "y", "\n", "\n", "", "if", "x", ".", "size", "(", "1", ")", "<", "y", ".", "size", "(", "1", ")", ":", "\n", "        ", "x", "=", "expand_2d_or_3d_tensor", "(", "x", ",", "y", ".", "size", "(", "1", ")", ",", "padding_idx", ")", "\n", "x", "[", "mask", "]", "=", "y", "\n", "", "elif", "x", ".", "size", "(", "1", ")", ">", "y", ".", "size", "(", "1", ")", ":", "\n", "        ", "x", "[", "mask", "]", "=", "torch", ".", "tensor", "(", "padding_idx", ")", ".", "type_as", "(", "x", ")", "\n", "if", "x", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "x", "[", "mask", ",", ":", "y", ".", "size", "(", "1", ")", "]", "=", "y", "\n", "", "else", ":", "\n", "            ", "x", "[", "mask", ",", ":", "y", ".", "size", "(", "1", ")", ",", ":", "]", "=", "y", "\n", "", "", "else", ":", "\n", "        ", "x", "[", "mask", "]", "=", "y", "\n", "", "return", "x", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.__init__": [[40, 42], ["fairseq.models.FairseqDecoder.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.forward": [[43, 61], ["None"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "prev_output_tokens", ",", "encoder_out", "=", "None", ",", "incremental_state", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            prev_output_tokens (LongTensor): shifted output tokens of shape\n                `(batch, tgt_len)`, for teacher forcing\n            encoder_out (dict, optional): output from the encoder, used for\n                encoder-side attention\n            incremental_state (dict, optional): dictionary used for storing\n                state during :ref:`Incremental decoding`\n\n        Returns:\n            tuple:\n                - the decoder's output of shape `(batch, tgt_len, vocab)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.extract_features": [[62, 72], ["None"], "methods", ["None"], ["", "def", "extract_features", "(", "\n", "self", ",", "prev_output_tokens", ",", "encoder_out", "=", "None", ",", "incremental_state", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            tuple:\n                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.reorder_incremental_state": [[73, 85], ["None"], "methods", ["None"], ["", "def", "reorder_incremental_state", "(", "\n", "self", ",", "\n", "incremental_state", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ",", "\n", "new_order", ":", "Tensor", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Reorder incremental state.\n\n        This will be called when the order of the input has changed from the\n        previous time step. A typical use case is beam search, where the input\n        order changes between time steps based on the selection of beams.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.reorder_incremental_state_scripting": [[86, 102], ["fairseq_incremental_decoder.FairseqIncrementalDecoder.modules", "hasattr", "module.reorder_incremental_state"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.LSTMDecoder.reorder_incremental_state"], ["", "def", "reorder_incremental_state_scripting", "(", "\n", "self", ",", "\n", "incremental_state", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ",", "\n", "new_order", ":", "Tensor", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Main entry point for reordering the incremental state.\n\n        Due to limitations in TorchScript, we call this function in\n        :class:`fairseq.sequence_generator.SequenceGenerator` instead of\n        calling :func:`reorder_incremental_state` directly.\n        \"\"\"", "\n", "for", "module", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "hasattr", "(", "module", ",", "\"reorder_incremental_state\"", ")", ":", "\n", "                ", "result", "=", "module", ".", "reorder_incremental_state", "(", "incremental_state", ",", "new_order", ")", "\n", "if", "result", "is", "not", "None", ":", "\n", "                    ", "incremental_state", "=", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.set_beam_size": [[103, 119], ["getattr", "set", "fairseq_incremental_decoder.FairseqIncrementalDecoder.apply", "hasattr", "set.add", "module.set_beam_size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_incremental_decoder.FairseqIncrementalDecoder.set_beam_size"], ["", "", "", "", "def", "set_beam_size", "(", "self", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\"Sets the beam size in the decoder and all children.\"\"\"", "\n", "if", "getattr", "(", "self", ",", "\"_beam_size\"", ",", "-", "1", ")", "!=", "beam_size", ":", "\n", "            ", "seen", "=", "set", "(", ")", "\n", "\n", "def", "apply_set_beam_size", "(", "module", ")", ":", "\n", "                ", "if", "(", "\n", "module", "!=", "self", "\n", "and", "hasattr", "(", "module", ",", "\"set_beam_size\"", ")", "\n", "and", "module", "not", "in", "seen", "\n", ")", ":", "\n", "                    ", "seen", ".", "add", "(", "module", ")", "\n", "module", ".", "set_beam_size", "(", "beam_size", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "apply_set_beam_size", ")", "\n", "self", ".", "_beam_size", "=", "beam_size", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm_lm.LSTMLanguageModel.__init__": [[20, 22], ["fairseq.models.FairseqLanguageModel.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm_lm.LSTMLanguageModel.add_args": [[23, 56], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-embed-path'", ",", "type", "=", "str", ",", "metavar", "=", "'STR'", ",", "\n", "help", "=", "'path to pre-trained decoder embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-hidden-size'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder hidden size'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-layers'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'number of decoder layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-out-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder output embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-attention'", ",", "type", "=", "str", ",", "metavar", "=", "'BOOL'", ",", "\n", "help", "=", "'decoder attention'", ")", "\n", "parser", ".", "add_argument", "(", "'--adaptive-softmax-cutoff'", ",", "metavar", "=", "'EXPR'", ",", "\n", "help", "=", "'comma separated list of adaptive softmax cutoff points. '", "\n", "'Must be used with adaptive_loss criterion'", ")", "\n", "parser", ".", "add_argument", "(", "'--residuals'", ",", "default", "=", "False", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'applying residuals between LSTM layers'", ")", "\n", "\n", "# Granular dropout settings (if not specified these default to --dropout)", "\n", "parser", ".", "add_argument", "(", "'--decoder-dropout-in'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability for decoder input embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-dropout-out'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability for decoder output'", ")", "\n", "parser", ".", "add_argument", "(", "'--share-decoder-input-output-embed'", ",", "default", "=", "False", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'share decoder input and output embeddings'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm_lm.LSTMLanguageModel.build_model": [[58, 121], ["lstm_lm.base_architecture", "fairseq.models.lstm.LSTMDecoder", "cls", "getattr", "getattr", "len", "dictionary.pad", "fairseq.models.lstm.Embedding", "fairseq.utils.parse_embedding", "fairseq.utils.print_embed_overlap", "fairseq.utils.load_embedding", "lstm_lm.LSTMLanguageModel.build_model.load_pretrained_embedding_from_file"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.parse_embedding", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.print_embed_overlap", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.load_embedding"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "\n", "# make sure all arguments are present in older models", "\n", "base_architecture", "(", "args", ")", "\n", "\n", "if", "getattr", "(", "args", ",", "\"max_target_positions\"", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "max_target_positions", "=", "args", ".", "max_target_positions", "\n", "", "else", ":", "\n", "            ", "max_target_positions", "=", "getattr", "(", "\n", "args", ",", "\"tokens_per_sample\"", ",", "DEFAULT_MAX_TARGET_POSITIONS", "\n", ")", "\n", "\n", "", "def", "load_pretrained_embedding_from_file", "(", "embed_path", ",", "dictionary", ",", "embed_dim", ")", ":", "\n", "            ", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "embed_tokens", "=", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "padding_idx", ")", "\n", "embed_dict", "=", "utils", ".", "parse_embedding", "(", "embed_path", ")", "\n", "utils", ".", "print_embed_overlap", "(", "embed_dict", ",", "dictionary", ")", "\n", "return", "utils", ".", "load_embedding", "(", "embed_dict", ",", "dictionary", ",", "embed_tokens", ")", "\n", "\n", "", "pretrained_decoder_embed", "=", "None", "\n", "if", "args", ".", "decoder_embed_path", ":", "\n", "            ", "pretrained_decoder_embed", "=", "load_pretrained_embedding_from_file", "(", "\n", "args", ".", "decoder_embed_path", ",", "task", ".", "target_dictionary", ",", "args", ".", "decoder_embed_dim", "\n", ")", "\n", "\n", "", "if", "args", ".", "share_decoder_input_output_embed", ":", "\n", "# double check all parameters combinations are valid", "\n", "            ", "if", "task", ".", "source_dictionary", "!=", "task", ".", "target_dictionary", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"--share-decoder-input-output-embeddings requires a joint dictionary\"", "\n", ")", "\n", "\n", "", "if", "args", ".", "decoder_embed_dim", "!=", "args", ".", "decoder_out_embed_dim", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"--share-decoder-input-output-embeddings requires \"", "\n", "\"--decoder-embed-dim to match --decoder-out-embed-dim\"", "\n", ")", "\n", "\n", "", "", "decoder", "=", "LSTMDecoder", "(", "\n", "dictionary", "=", "task", ".", "dictionary", ",", "\n", "embed_dim", "=", "args", ".", "decoder_embed_dim", ",", "\n", "hidden_size", "=", "args", ".", "decoder_hidden_size", ",", "\n", "out_embed_dim", "=", "args", ".", "decoder_out_embed_dim", ",", "\n", "num_layers", "=", "args", ".", "decoder_layers", ",", "\n", "dropout_in", "=", "args", ".", "decoder_dropout_in", ",", "\n", "dropout_out", "=", "args", ".", "decoder_dropout_out", ",", "\n", "attention", "=", "False", ",", "# decoder-only language model doesn't support attention", "\n", "encoder_output_units", "=", "0", ",", "\n", "pretrained_embed", "=", "pretrained_decoder_embed", ",", "\n", "share_input_output_embed", "=", "args", ".", "share_decoder_input_output_embed", ",", "\n", "adaptive_softmax_cutoff", "=", "(", "\n", "utils", ".", "eval_str_list", "(", "args", ".", "adaptive_softmax_cutoff", ",", "type", "=", "int", ")", "\n", "if", "args", ".", "criterion", "==", "\"adaptive_loss\"", "\n", "else", "None", "\n", ")", ",", "\n", "max_target_positions", "=", "max_target_positions", ",", "\n", "residuals", "=", "args", ".", "residuals", ",", "\n", ")", "\n", "\n", "return", "cls", "(", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm_lm.base_architecture": [[123, 143], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "", "@", "register_model_architecture", "(", "\"lstm_lm\"", ",", "\"lstm_lm\"", ")", "\n", "def", "base_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "decoder_embed_path", "=", "getattr", "(", "args", ",", "\"decoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "decoder_hidden_size", "=", "getattr", "(", "\n", "args", ",", "\"decoder_hidden_size\"", ",", "args", ".", "decoder_embed_dim", "\n", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "1", ")", "\n", "args", ".", "decoder_out_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_out_embed_dim\"", ",", "512", ")", "\n", "args", ".", "decoder_attention", "=", "getattr", "(", "args", ",", "\"decoder_attention\"", ",", "\"0\"", ")", "\n", "args", ".", "decoder_dropout_in", "=", "getattr", "(", "args", ",", "\"decoder_dropout_in\"", ",", "args", ".", "dropout", ")", "\n", "args", ".", "decoder_dropout_out", "=", "getattr", "(", "args", ",", "\"decoder_dropout_out\"", ",", "args", ".", "dropout", ")", "\n", "args", ".", "share_decoder_input_output_embed", "=", "getattr", "(", "\n", "args", ",", "\"share_decoder_input_output_embed\"", ",", "False", "\n", ")", "\n", "args", ".", "adaptive_softmax_cutoff", "=", "getattr", "(", "\n", "args", ",", "\"adaptive_softmax_cutoff\"", ",", "\"10000,50000,200000\"", "\n", ")", "\n", "args", ".", "residuals", "=", "getattr", "(", "args", ",", "\"residuals\"", ",", "False", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMModel.__init__": [[29, 31], ["fairseq.models.FairseqEncoderDecoderModel.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "encoder", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMModel.add_args": [[32, 83], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'encoder embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-embed-path'", ",", "type", "=", "str", ",", "metavar", "=", "'STR'", ",", "\n", "help", "=", "'path to pre-trained encoder embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-freeze-embed'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'freeze encoder embeddings'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-hidden-size'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'encoder hidden size'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-layers'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'number of encoder layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-bidirectional'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'make all layers of encoder bidirectional'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-embed-path'", ",", "type", "=", "str", ",", "metavar", "=", "'STR'", ",", "\n", "help", "=", "'path to pre-trained decoder embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-freeze-embed'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'freeze decoder embeddings'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-hidden-size'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder hidden size'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-layers'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'number of decoder layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-out-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder output embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-attention'", ",", "type", "=", "str", ",", "metavar", "=", "'BOOL'", ",", "\n", "help", "=", "'decoder attention'", ")", "\n", "parser", ".", "add_argument", "(", "'--adaptive-softmax-cutoff'", ",", "metavar", "=", "'EXPR'", ",", "\n", "help", "=", "'comma separated list of adaptive softmax cutoff points. '", "\n", "'Must be used with adaptive_loss criterion'", ")", "\n", "parser", ".", "add_argument", "(", "'--share-decoder-input-output-embed'", ",", "default", "=", "False", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'share decoder input and output embeddings'", ")", "\n", "parser", ".", "add_argument", "(", "'--share-all-embeddings'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'share encoder, decoder and output embeddings'", "\n", "' (requires shared dictionary and embed dim)'", ")", "\n", "\n", "# Granular dropout settings (if not specified these default to --dropout)", "\n", "parser", ".", "add_argument", "(", "'--encoder-dropout-in'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability for encoder input embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-dropout-out'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability for encoder output'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-dropout-in'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability for decoder input embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-dropout-out'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability for decoder output'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMModel.build_model": [[85, 191], ["lstm.base_architecture", "getattr", "getattr", "lstm.LSTMEncoder", "lstm.LSTMDecoder", "cls", "ValueError", "len", "dictionary.pad", "lstm.Embedding", "fairseq.utils.parse_embedding", "fairseq.utils.print_embed_overlap", "fairseq.utils.load_embedding", "lstm.LSTMModel.build_model.load_pretrained_embedding_from_file"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.parse_embedding", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.print_embed_overlap", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.load_embedding"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "# make sure that all args are properly defaulted (in case there are any new ones)", "\n", "base_architecture", "(", "args", ")", "\n", "\n", "if", "args", ".", "encoder_layers", "!=", "args", ".", "decoder_layers", ":", "\n", "            ", "raise", "ValueError", "(", "\"--encoder-layers must match --decoder-layers\"", ")", "\n", "\n", "", "max_source_positions", "=", "getattr", "(", "\n", "args", ",", "\"max_source_positions\"", ",", "DEFAULT_MAX_SOURCE_POSITIONS", "\n", ")", "\n", "max_target_positions", "=", "getattr", "(", "\n", "args", ",", "\"max_target_positions\"", ",", "DEFAULT_MAX_TARGET_POSITIONS", "\n", ")", "\n", "\n", "def", "load_pretrained_embedding_from_file", "(", "embed_path", ",", "dictionary", ",", "embed_dim", ")", ":", "\n", "            ", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "embed_tokens", "=", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "padding_idx", ")", "\n", "embed_dict", "=", "utils", ".", "parse_embedding", "(", "embed_path", ")", "\n", "utils", ".", "print_embed_overlap", "(", "embed_dict", ",", "dictionary", ")", "\n", "return", "utils", ".", "load_embedding", "(", "embed_dict", ",", "dictionary", ",", "embed_tokens", ")", "\n", "\n", "", "if", "args", ".", "encoder_embed_path", ":", "\n", "            ", "pretrained_encoder_embed", "=", "load_pretrained_embedding_from_file", "(", "\n", "args", ".", "encoder_embed_path", ",", "task", ".", "source_dictionary", ",", "args", ".", "encoder_embed_dim", "\n", ")", "\n", "", "else", ":", "\n", "            ", "num_embeddings", "=", "len", "(", "task", ".", "source_dictionary", ")", "\n", "pretrained_encoder_embed", "=", "Embedding", "(", "\n", "num_embeddings", ",", "args", ".", "encoder_embed_dim", ",", "task", ".", "source_dictionary", ".", "pad", "(", ")", "\n", ")", "\n", "\n", "", "if", "args", ".", "share_all_embeddings", ":", "\n", "# double check all parameters combinations are valid", "\n", "            ", "if", "task", ".", "source_dictionary", "!=", "task", ".", "target_dictionary", ":", "\n", "                ", "raise", "ValueError", "(", "\"--share-all-embeddings requires a joint dictionary\"", ")", "\n", "", "if", "args", ".", "decoder_embed_path", "and", "(", "\n", "args", ".", "decoder_embed_path", "!=", "args", ".", "encoder_embed_path", "\n", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"--share-all-embed not compatible with --decoder-embed-path\"", "\n", ")", "\n", "", "if", "args", ".", "encoder_embed_dim", "!=", "args", ".", "decoder_embed_dim", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"--share-all-embeddings requires --encoder-embed-dim to \"", "\n", "\"match --decoder-embed-dim\"", "\n", ")", "\n", "", "pretrained_decoder_embed", "=", "pretrained_encoder_embed", "\n", "args", ".", "share_decoder_input_output_embed", "=", "True", "\n", "", "else", ":", "\n", "# separate decoder input embeddings", "\n", "            ", "pretrained_decoder_embed", "=", "None", "\n", "if", "args", ".", "decoder_embed_path", ":", "\n", "                ", "pretrained_decoder_embed", "=", "load_pretrained_embedding_from_file", "(", "\n", "args", ".", "decoder_embed_path", ",", "\n", "task", ".", "target_dictionary", ",", "\n", "args", ".", "decoder_embed_dim", ",", "\n", ")", "\n", "# one last double check of parameter combinations", "\n", "", "", "if", "args", ".", "share_decoder_input_output_embed", "and", "(", "\n", "args", ".", "decoder_embed_dim", "!=", "args", ".", "decoder_out_embed_dim", "\n", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"--share-decoder-input-output-embeddings requires \"", "\n", "\"--decoder-embed-dim to match --decoder-out-embed-dim\"", "\n", ")", "\n", "\n", "", "if", "args", ".", "encoder_freeze_embed", ":", "\n", "            ", "pretrained_encoder_embed", ".", "weight", ".", "requires_grad", "=", "False", "\n", "", "if", "args", ".", "decoder_freeze_embed", ":", "\n", "            ", "pretrained_decoder_embed", ".", "weight", ".", "requires_grad", "=", "False", "\n", "\n", "", "encoder", "=", "LSTMEncoder", "(", "\n", "dictionary", "=", "task", ".", "source_dictionary", ",", "\n", "embed_dim", "=", "args", ".", "encoder_embed_dim", ",", "\n", "hidden_size", "=", "args", ".", "encoder_hidden_size", ",", "\n", "num_layers", "=", "args", ".", "encoder_layers", ",", "\n", "dropout_in", "=", "args", ".", "encoder_dropout_in", ",", "\n", "dropout_out", "=", "args", ".", "encoder_dropout_out", ",", "\n", "bidirectional", "=", "args", ".", "encoder_bidirectional", ",", "\n", "pretrained_embed", "=", "pretrained_encoder_embed", ",", "\n", "max_source_positions", "=", "max_source_positions", ",", "\n", ")", "\n", "decoder", "=", "LSTMDecoder", "(", "\n", "dictionary", "=", "task", ".", "target_dictionary", ",", "\n", "embed_dim", "=", "args", ".", "decoder_embed_dim", ",", "\n", "hidden_size", "=", "args", ".", "decoder_hidden_size", ",", "\n", "out_embed_dim", "=", "args", ".", "decoder_out_embed_dim", ",", "\n", "num_layers", "=", "args", ".", "decoder_layers", ",", "\n", "dropout_in", "=", "args", ".", "decoder_dropout_in", ",", "\n", "dropout_out", "=", "args", ".", "decoder_dropout_out", ",", "\n", "attention", "=", "utils", ".", "eval_bool", "(", "args", ".", "decoder_attention", ")", ",", "\n", "encoder_output_units", "=", "encoder", ".", "output_units", ",", "\n", "pretrained_embed", "=", "pretrained_decoder_embed", ",", "\n", "share_input_output_embed", "=", "args", ".", "share_decoder_input_output_embed", ",", "\n", "adaptive_softmax_cutoff", "=", "(", "\n", "utils", ".", "eval_str_list", "(", "args", ".", "adaptive_softmax_cutoff", ",", "type", "=", "int", ")", "\n", "if", "args", ".", "criterion", "==", "\"adaptive_loss\"", "\n", "else", "None", "\n", ")", ",", "\n", "max_target_positions", "=", "max_target_positions", ",", "\n", "residuals", "=", "False", ",", "\n", ")", "\n", "return", "cls", "(", "encoder", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMModel.forward": [[192, 206], ["lstm.LSTMModel.encoder", "lstm.LSTMModel.decoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "src_tokens", ",", "\n", "src_lengths", ",", "\n", "prev_output_tokens", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "encoder_out", "=", "self", ".", "encoder", "(", "src_tokens", ",", "src_lengths", "=", "src_lengths", ")", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "\n", "prev_output_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", "incremental_state", "=", "incremental_state", ",", "\n", ")", "\n", "return", "decoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMEncoder.__init__": [[211, 256], ["fairseq.models.FairseqEncoder.__init__", "fairseq.modules.FairseqDropout", "fairseq.modules.FairseqDropout", "len", "lstm.LSTM", "dictionary.pad", "lstm.Embedding"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTM", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dictionary", ",", "\n", "embed_dim", "=", "512", ",", "\n", "hidden_size", "=", "512", ",", "\n", "num_layers", "=", "1", ",", "\n", "dropout_in", "=", "0.1", ",", "\n", "dropout_out", "=", "0.1", ",", "\n", "bidirectional", "=", "False", ",", "\n", "left_pad", "=", "True", ",", "\n", "pretrained_embed", "=", "None", ",", "\n", "padding_idx", "=", "None", ",", "\n", "max_source_positions", "=", "DEFAULT_MAX_SOURCE_POSITIONS", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "dropout_in_module", "=", "FairseqDropout", "(", "\n", "dropout_in", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "dropout_out_module", "=", "FairseqDropout", "(", "\n", "dropout_out", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "max_source_positions", "=", "max_source_positions", "\n", "\n", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "self", ".", "padding_idx", "=", "padding_idx", "if", "padding_idx", "is", "not", "None", "else", "dictionary", ".", "pad", "(", ")", "\n", "if", "pretrained_embed", "is", "None", ":", "\n", "            ", "self", ".", "embed_tokens", "=", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "self", ".", "padding_idx", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embed_tokens", "=", "pretrained_embed", "\n", "\n", "", "self", ".", "lstm", "=", "LSTM", "(", "\n", "input_size", "=", "embed_dim", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "self", ".", "dropout_out_module", ".", "p", "if", "num_layers", ">", "1", "else", "0.0", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", ")", "\n", "self", ".", "left_pad", "=", "left_pad", "\n", "\n", "self", ".", "output_units", "=", "hidden_size", "\n", "if", "bidirectional", ":", "\n", "            ", "self", ".", "output_units", "*=", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMEncoder.forward": [[257, 325], ["fairseq.utils.convert_padding_direction.size", "lstm.LSTMEncoder.embed_tokens", "lstm.LSTMEncoder.dropout_in_module", "lstm.LSTMEncoder.transpose", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "lstm.LSTMEncoder.new_zeros", "lstm.LSTMEncoder.new_zeros", "lstm.LSTMEncoder.lstm", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "lstm.LSTMEncoder.dropout_out_module", "fairseq.utils.convert_padding_direction.eq().t", "tuple", "fairseq.utils.convert_padding_direction", "src_lengths.cpu", "list", "lstm.LSTMEncoder.combine_bidir", "lstm.LSTMEncoder.combine_bidir", "torch.zeros_like().fill_", "torch.zeros_like().fill_", "torch.zeros_like().fill_", "torch.zeros_like().fill_", "torch.zeros_like().fill_", "torch.zeros_like().fill_", "torch.zeros_like().fill_", "torch.zeros_like().fill_", "torch.zeros_like().fill_", "lstm.LSTMEncoder.size", "fairseq.utils.convert_padding_direction.eq", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.convert_padding_direction", "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMEncoder.combine_bidir", "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMEncoder.combine_bidir", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "src_tokens", ":", "Tensor", ",", "\n", "src_lengths", ":", "Tensor", ",", "\n", "enforce_sorted", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            src_tokens (LongTensor): tokens in the source language of\n                shape `(batch, src_len)`\n            src_lengths (LongTensor): lengths of each source sentence of\n                shape `(batch)`\n            enforce_sorted (bool, optional): if True, `src_tokens` is\n                expected to contain sequences sorted by length in a\n                decreasing order. If False, this condition is not\n                required. Default: True.\n        \"\"\"", "\n", "if", "self", ".", "left_pad", ":", "\n", "# nn.utils.rnn.pack_padded_sequence requires right-padding;", "\n", "# convert left-padding to right-padding", "\n", "            ", "src_tokens", "=", "utils", ".", "convert_padding_direction", "(", "\n", "src_tokens", ",", "\n", "torch", ".", "zeros_like", "(", "src_tokens", ")", ".", "fill_", "(", "self", ".", "padding_idx", ")", ",", "\n", "left_to_right", "=", "True", ",", "\n", ")", "\n", "\n", "", "bsz", ",", "seqlen", "=", "src_tokens", ".", "size", "(", ")", "\n", "\n", "# embed tokens", "\n", "x", "=", "self", ".", "embed_tokens", "(", "src_tokens", ")", "\n", "x", "=", "self", ".", "dropout_in_module", "(", "x", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# pack embedded source tokens into a PackedSequence", "\n", "packed_x", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "\n", "x", ",", "src_lengths", ".", "cpu", "(", ")", ",", "enforce_sorted", "=", "enforce_sorted", "\n", ")", "\n", "\n", "# apply LSTM", "\n", "if", "self", ".", "bidirectional", ":", "\n", "            ", "state_size", "=", "2", "*", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "hidden_size", "\n", "", "else", ":", "\n", "            ", "state_size", "=", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "hidden_size", "\n", "", "h0", "=", "x", ".", "new_zeros", "(", "*", "state_size", ")", "\n", "c0", "=", "x", ".", "new_zeros", "(", "*", "state_size", ")", "\n", "packed_outs", ",", "(", "final_hiddens", ",", "final_cells", ")", "=", "self", ".", "lstm", "(", "packed_x", ",", "(", "h0", ",", "c0", ")", ")", "\n", "\n", "# unpack outputs and apply dropout", "\n", "x", ",", "_", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "\n", "packed_outs", ",", "padding_value", "=", "self", ".", "padding_idx", "*", "1.0", "\n", ")", "\n", "x", "=", "self", ".", "dropout_out_module", "(", "x", ")", "\n", "assert", "list", "(", "x", ".", "size", "(", ")", ")", "==", "[", "seqlen", ",", "bsz", ",", "self", ".", "output_units", "]", "\n", "\n", "if", "self", ".", "bidirectional", ":", "\n", "            ", "final_hiddens", "=", "self", ".", "combine_bidir", "(", "final_hiddens", ",", "bsz", ")", "\n", "final_cells", "=", "self", ".", "combine_bidir", "(", "final_cells", ",", "bsz", ")", "\n", "\n", "", "encoder_padding_mask", "=", "src_tokens", ".", "eq", "(", "self", ".", "padding_idx", ")", ".", "t", "(", ")", "\n", "\n", "return", "tuple", "(", "\n", "(", "\n", "x", ",", "# seq_len x batch x hidden", "\n", "final_hiddens", ",", "# num_layers x batch x num_directions*hidden", "\n", "final_cells", ",", "# num_layers x batch x num_directions*hidden", "\n", "encoder_padding_mask", ",", "# seq_len x batch", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMEncoder.combine_bidir": [[328, 331], ["outs.view().transpose().contiguous", "outs.view().transpose().contiguous.view", "outs.view().transpose", "outs.view"], "methods", ["None"], ["", "def", "combine_bidir", "(", "self", ",", "outs", ",", "bsz", ":", "int", ")", ":", "\n", "        ", "out", "=", "outs", ".", "view", "(", "self", ".", "num_layers", ",", "2", ",", "bsz", ",", "-", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "return", "out", ".", "view", "(", "self", ".", "num_layers", ",", "bsz", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMEncoder.reorder_encoder_out": [[332, 339], ["tuple", "encoder_out[].index_select", "encoder_out[].index_select", "encoder_out[].index_select", "encoder_out[].index_select"], "methods", ["None"], ["", "def", "reorder_encoder_out", "(", "self", ",", "encoder_out", ",", "new_order", ")", ":", "\n", "        ", "return", "tuple", "(", "\n", "(", "\n", "encoder_out", "[", "0", "]", ".", "index_select", "(", "1", ",", "new_order", ")", ",", "\n", "encoder_out", "[", "1", "]", ".", "index_select", "(", "1", ",", "new_order", ")", ",", "\n", "encoder_out", "[", "2", "]", ".", "index_select", "(", "1", ",", "new_order", ")", ",", "\n", "encoder_out", "[", "3", "]", ".", "index_select", "(", "1", ",", "new_order", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMEncoder.max_positions": [[342, 345], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum input length supported by the encoder.\"\"\"", "\n", "return", "self", ".", "max_source_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.AttentionLayer.__init__": [[348, 354], ["torch.Module.__init__", "lstm.Linear", "lstm.Linear"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["    ", "def", "__init__", "(", "self", ",", "input_embed_dim", ",", "source_embed_dim", ",", "output_embed_dim", ",", "bias", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_proj", "=", "Linear", "(", "input_embed_dim", ",", "source_embed_dim", ",", "bias", "=", "bias", ")", "\n", "self", ".", "output_proj", "=", "Linear", "(", "\n", "input_embed_dim", "+", "source_embed_dim", ",", "output_embed_dim", ",", "bias", "=", "bias", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.AttentionLayer.forward": [[356, 381], ["lstm.AttentionLayer.input_proj", "torch.softmax", "torch.softmax", "torch.softmax", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "attn_scores.float().masked_fill_().type_as.float().masked_fill_().type_as.float().masked_fill_().type_as", "lstm.AttentionLayer.output_proj", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.tanh.unsqueeze", "torch.tanh.unsqueeze", "torch.tanh.unsqueeze", "attn_scores.float().masked_fill_().type_as.float().masked_fill_().type_as.float().masked_fill_", "attn_scores.float().masked_fill_().type_as.float().masked_fill_().type_as.unsqueeze", "float", "attn_scores.float().masked_fill_().type_as.float().masked_fill_().type_as.float"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax"], ["", "def", "forward", "(", "self", ",", "input", ",", "source_hids", ",", "encoder_padding_mask", ")", ":", "\n", "# input: bsz x input_embed_dim", "\n", "# source_hids: srclen x bsz x source_embed_dim", "\n", "\n", "# x: bsz x source_embed_dim", "\n", "        ", "x", "=", "self", ".", "input_proj", "(", "input", ")", "\n", "\n", "# compute attention", "\n", "attn_scores", "=", "(", "source_hids", "*", "x", ".", "unsqueeze", "(", "0", ")", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "\n", "# don't attend over padding", "\n", "if", "encoder_padding_mask", "is", "not", "None", ":", "\n", "            ", "attn_scores", "=", "(", "\n", "attn_scores", ".", "float", "(", ")", "\n", ".", "masked_fill_", "(", "encoder_padding_mask", ",", "float", "(", "\"-inf\"", ")", ")", "\n", ".", "type_as", "(", "attn_scores", ")", "\n", ")", "# FP16 support: cast to float and back", "\n", "\n", "", "attn_scores", "=", "F", ".", "softmax", "(", "attn_scores", ",", "dim", "=", "0", ")", "# srclen x bsz", "\n", "\n", "# sum weighted sources", "\n", "x", "=", "(", "attn_scores", ".", "unsqueeze", "(", "2", ")", "*", "source_hids", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "\n", "x", "=", "torch", ".", "tanh", "(", "self", ".", "output_proj", "(", "torch", ".", "cat", "(", "(", "x", ",", "input", ")", ",", "dim", "=", "1", ")", ")", ")", "\n", "return", "x", ",", "attn_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMDecoder.__init__": [[386, 468], ["fairseq.models.FairseqIncrementalDecoder.__init__", "fairseq.modules.FairseqDropout", "fairseq.modules.FairseqDropout", "len", "dictionary.pad", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "lstm.Embedding", "lstm.Linear", "lstm.Linear", "lstm.AttentionLayer", "lstm.Linear", "fairseq.modules.AdaptiveSoftmax", "lstm.LSTMCell", "lstm.Linear", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMCell", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dictionary", ",", "\n", "embed_dim", "=", "512", ",", "\n", "hidden_size", "=", "512", ",", "\n", "out_embed_dim", "=", "512", ",", "\n", "num_layers", "=", "1", ",", "\n", "dropout_in", "=", "0.1", ",", "\n", "dropout_out", "=", "0.1", ",", "\n", "attention", "=", "True", ",", "\n", "encoder_output_units", "=", "512", ",", "\n", "pretrained_embed", "=", "None", ",", "\n", "share_input_output_embed", "=", "False", ",", "\n", "adaptive_softmax_cutoff", "=", "None", ",", "\n", "max_target_positions", "=", "DEFAULT_MAX_TARGET_POSITIONS", ",", "\n", "residuals", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "self", ".", "dropout_in_module", "=", "FairseqDropout", "(", "\n", "dropout_in", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "dropout_out_module", "=", "FairseqDropout", "(", "\n", "dropout_out", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "share_input_output_embed", "=", "share_input_output_embed", "\n", "self", ".", "need_attn", "=", "True", "\n", "self", ".", "max_target_positions", "=", "max_target_positions", "\n", "self", ".", "residuals", "=", "residuals", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "\n", "self", ".", "adaptive_softmax", "=", "None", "\n", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "if", "pretrained_embed", "is", "None", ":", "\n", "            ", "self", ".", "embed_tokens", "=", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "padding_idx", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embed_tokens", "=", "pretrained_embed", "\n", "\n", "", "self", ".", "encoder_output_units", "=", "encoder_output_units", "\n", "if", "encoder_output_units", "!=", "hidden_size", "and", "encoder_output_units", "!=", "0", ":", "\n", "            ", "self", ".", "encoder_hidden_proj", "=", "Linear", "(", "encoder_output_units", ",", "hidden_size", ")", "\n", "self", ".", "encoder_cell_proj", "=", "Linear", "(", "encoder_output_units", ",", "hidden_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "encoder_hidden_proj", "=", "self", ".", "encoder_cell_proj", "=", "None", "\n", "\n", "# disable input feeding if there is no encoder", "\n", "# input feeding is described in arxiv.org/abs/1508.04025", "\n", "", "input_feed_size", "=", "0", "if", "encoder_output_units", "==", "0", "else", "hidden_size", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "LSTMCell", "(", "\n", "input_size", "=", "input_feed_size", "+", "embed_dim", "\n", "if", "layer", "==", "0", "\n", "else", "hidden_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", ")", "\n", "for", "layer", "in", "range", "(", "num_layers", ")", "\n", "]", "\n", ")", "\n", "\n", "if", "attention", ":", "\n", "# TODO make bias configurable", "\n", "            ", "self", ".", "attention", "=", "AttentionLayer", "(", "\n", "hidden_size", ",", "encoder_output_units", ",", "hidden_size", ",", "bias", "=", "False", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "attention", "=", "None", "\n", "\n", "", "if", "hidden_size", "!=", "out_embed_dim", ":", "\n", "            ", "self", ".", "additional_fc", "=", "Linear", "(", "hidden_size", ",", "out_embed_dim", ")", "\n", "\n", "", "if", "adaptive_softmax_cutoff", "is", "not", "None", ":", "\n", "# setting adaptive_softmax dropout to dropout_out for now but can be redefined", "\n", "            ", "self", ".", "adaptive_softmax", "=", "AdaptiveSoftmax", "(", "\n", "num_embeddings", ",", "\n", "hidden_size", ",", "\n", "adaptive_softmax_cutoff", ",", "\n", "dropout", "=", "dropout_out", ",", "\n", ")", "\n", "", "elif", "not", "self", ".", "share_input_output_embed", ":", "\n", "            ", "self", ".", "fc_out", "=", "Linear", "(", "out_embed_dim", ",", "num_embeddings", ",", "dropout", "=", "dropout_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMDecoder.forward": [[469, 480], ["lstm.LSTMDecoder.extract_features", "lstm.LSTMDecoder.output_layer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.output_layer"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "prev_output_tokens", ",", "\n", "encoder_out", ":", "Optional", "[", "Tuple", "[", "Tensor", ",", "Tensor", ",", "Tensor", ",", "Tensor", "]", "]", "=", "None", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", "=", "None", ",", "\n", "src_lengths", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "x", ",", "attn_scores", "=", "self", ".", "extract_features", "(", "\n", "prev_output_tokens", ",", "encoder_out", ",", "incremental_state", "\n", ")", "\n", "return", "self", ".", "output_layer", "(", "x", ")", ",", "attn_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMDecoder.extract_features": [[481, 608], ["torch.empty.size", "torch.empty.size", "torch.empty.size", "prev_output_tokens.size", "lstm.LSTMDecoder.embed_tokens", "lstm.LSTMDecoder.dropout_in_module", "lstm.LSTMDecoder.transpose", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "lstm.LSTMDecoder.set_incremental_state", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "lstm.LSTMDecoder.transpose", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "lstm.LSTMDecoder.get_cached_state", "lstm.LSTMDecoder.new_zeros", "enumerate", "lstm.LSTMDecoder.dropout_out_module", "outs.append", "hasattr", "lstm.LSTMDecoder.additional_fc", "lstm.LSTMDecoder.dropout_out_module", "attn_scores.transpose.transpose.transpose", "len", "len", "lstm.LSTMDecoder.new_zeros", "lstm.LSTMDecoder.new_zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "rnn", "lstm.LSTMDecoder.dropout_out_module", "lstm.LSTMDecoder.attention", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "range", "lstm.LSTMDecoder.encoder_hidden_proj", "lstm.LSTMDecoder.encoder_cell_proj", "range", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_incremental_state", "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMDecoder.get_cached_state"], ["", "def", "extract_features", "(", "\n", "self", ",", "\n", "prev_output_tokens", ",", "\n", "encoder_out", ":", "Optional", "[", "Tuple", "[", "Tensor", ",", "Tensor", ",", "Tensor", ",", "Tensor", "]", "]", "=", "None", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Similar to *forward* but only return features.\n        \"\"\"", "\n", "# get outputs from encoder", "\n", "if", "encoder_out", "is", "not", "None", ":", "\n", "            ", "encoder_outs", "=", "encoder_out", "[", "0", "]", "\n", "encoder_hiddens", "=", "encoder_out", "[", "1", "]", "\n", "encoder_cells", "=", "encoder_out", "[", "2", "]", "\n", "encoder_padding_mask", "=", "encoder_out", "[", "3", "]", "\n", "", "else", ":", "\n", "            ", "encoder_outs", "=", "torch", ".", "empty", "(", "0", ")", "\n", "encoder_hiddens", "=", "torch", ".", "empty", "(", "0", ")", "\n", "encoder_cells", "=", "torch", ".", "empty", "(", "0", ")", "\n", "encoder_padding_mask", "=", "torch", ".", "empty", "(", "0", ")", "\n", "", "srclen", "=", "encoder_outs", ".", "size", "(", "0", ")", "\n", "\n", "if", "incremental_state", "is", "not", "None", "and", "len", "(", "incremental_state", ")", ">", "0", ":", "\n", "            ", "prev_output_tokens", "=", "prev_output_tokens", "[", ":", ",", "-", "1", ":", "]", "\n", "\n", "", "bsz", ",", "seqlen", "=", "prev_output_tokens", ".", "size", "(", ")", "\n", "\n", "# embed tokens", "\n", "x", "=", "self", ".", "embed_tokens", "(", "prev_output_tokens", ")", "\n", "x", "=", "self", ".", "dropout_in_module", "(", "x", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# initialize previous states (or get from cache during incremental generation)", "\n", "if", "incremental_state", "is", "not", "None", "and", "len", "(", "incremental_state", ")", ">", "0", ":", "\n", "            ", "prev_hiddens", ",", "prev_cells", ",", "input_feed", "=", "self", ".", "get_cached_state", "(", "\n", "incremental_state", "\n", ")", "\n", "", "elif", "encoder_out", "is", "not", "None", ":", "\n", "# setup recurrent cells", "\n", "            ", "prev_hiddens", "=", "[", "encoder_hiddens", "[", "i", "]", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", "]", "\n", "prev_cells", "=", "[", "encoder_cells", "[", "i", "]", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", "]", "\n", "if", "self", ".", "encoder_hidden_proj", "is", "not", "None", ":", "\n", "                ", "prev_hiddens", "=", "[", "self", ".", "encoder_hidden_proj", "(", "y", ")", "for", "y", "in", "prev_hiddens", "]", "\n", "prev_cells", "=", "[", "self", ".", "encoder_cell_proj", "(", "y", ")", "for", "y", "in", "prev_cells", "]", "\n", "", "input_feed", "=", "x", ".", "new_zeros", "(", "bsz", ",", "self", ".", "hidden_size", ")", "\n", "", "else", ":", "\n", "# setup zero cells, since there is no encoder", "\n", "            ", "zero_state", "=", "x", ".", "new_zeros", "(", "bsz", ",", "self", ".", "hidden_size", ")", "\n", "prev_hiddens", "=", "[", "zero_state", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", "]", "\n", "prev_cells", "=", "[", "zero_state", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", "]", "\n", "input_feed", "=", "None", "\n", "\n", "", "assert", "(", "\n", "srclen", ">", "0", "or", "self", ".", "attention", "is", "None", "\n", ")", ",", "\"attention is not supported if there are no encoder outputs\"", "\n", "attn_scores", "=", "(", "\n", "x", ".", "new_zeros", "(", "srclen", ",", "seqlen", ",", "bsz", ")", "if", "self", ".", "attention", "is", "not", "None", "else", "None", "\n", ")", "\n", "outs", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "seqlen", ")", ":", "\n", "# input feeding: concatenate context vector from previous time step", "\n", "            ", "if", "input_feed", "is", "not", "None", ":", "\n", "                ", "input", "=", "torch", ".", "cat", "(", "(", "x", "[", "j", ",", ":", ",", ":", "]", ",", "input_feed", ")", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "input", "=", "x", "[", "j", "]", "\n", "\n", "", "for", "i", ",", "rnn", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "# recurrent cell", "\n", "                ", "hidden", ",", "cell", "=", "rnn", "(", "input", ",", "(", "prev_hiddens", "[", "i", "]", ",", "prev_cells", "[", "i", "]", ")", ")", "\n", "\n", "# hidden state becomes the input to the next layer", "\n", "input", "=", "self", ".", "dropout_out_module", "(", "hidden", ")", "\n", "if", "self", ".", "residuals", ":", "\n", "                    ", "input", "=", "input", "+", "prev_hiddens", "[", "i", "]", "\n", "\n", "# save state for next time step", "\n", "", "prev_hiddens", "[", "i", "]", "=", "hidden", "\n", "prev_cells", "[", "i", "]", "=", "cell", "\n", "\n", "# apply attention using the last layer's hidden state", "\n", "", "if", "self", ".", "attention", "is", "not", "None", ":", "\n", "                ", "assert", "attn_scores", "is", "not", "None", "\n", "out", ",", "attn_scores", "[", ":", ",", "j", ",", ":", "]", "=", "self", ".", "attention", "(", "\n", "hidden", ",", "encoder_outs", ",", "encoder_padding_mask", "\n", ")", "\n", "", "else", ":", "\n", "                ", "out", "=", "hidden", "\n", "", "out", "=", "self", ".", "dropout_out_module", "(", "out", ")", "\n", "\n", "# input feeding", "\n", "if", "input_feed", "is", "not", "None", ":", "\n", "                ", "input_feed", "=", "out", "\n", "\n", "# save final output", "\n", "", "outs", ".", "append", "(", "out", ")", "\n", "\n", "# Stack all the necessary tensors together and store", "\n", "", "prev_hiddens_tensor", "=", "torch", ".", "stack", "(", "prev_hiddens", ")", "\n", "prev_cells_tensor", "=", "torch", ".", "stack", "(", "prev_cells", ")", "\n", "cache_state", "=", "torch", ".", "jit", ".", "annotate", "(", "\n", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", ",", "\n", "{", "\n", "\"prev_hiddens\"", ":", "prev_hiddens_tensor", ",", "\n", "\"prev_cells\"", ":", "prev_cells_tensor", ",", "\n", "\"input_feed\"", ":", "input_feed", ",", "\n", "}", ",", "\n", ")", "\n", "self", ".", "set_incremental_state", "(", "incremental_state", ",", "\"cached_state\"", ",", "cache_state", ")", "\n", "\n", "# collect outputs across time steps", "\n", "x", "=", "torch", ".", "cat", "(", "outs", ",", "dim", "=", "0", ")", ".", "view", "(", "seqlen", ",", "bsz", ",", "self", ".", "hidden_size", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "0", ")", "\n", "\n", "if", "hasattr", "(", "self", ",", "\"additional_fc\"", ")", "and", "self", ".", "adaptive_softmax", "is", "None", ":", "\n", "            ", "x", "=", "self", ".", "additional_fc", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout_out_module", "(", "x", ")", "\n", "# srclen x tgtlen x bsz -> bsz x tgtlen x srclen", "\n", "", "if", "not", "self", ".", "training", "and", "self", ".", "need_attn", "and", "self", ".", "attention", "is", "not", "None", ":", "\n", "            ", "assert", "attn_scores", "is", "not", "None", "\n", "attn_scores", "=", "attn_scores", ".", "transpose", "(", "0", ",", "2", ")", "\n", "", "else", ":", "\n", "            ", "attn_scores", "=", "None", "\n", "", "return", "x", ",", "attn_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMDecoder.output_layer": [[609, 617], ["torch.linear", "torch.linear", "torch.linear", "lstm.LSTMDecoder.fc_out"], "methods", ["None"], ["", "def", "output_layer", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Project features to the vocabulary size.\"\"\"", "\n", "if", "self", ".", "adaptive_softmax", "is", "None", ":", "\n", "            ", "if", "self", ".", "share_input_output_embed", ":", "\n", "                ", "x", "=", "F", ".", "linear", "(", "x", ",", "self", ".", "embed_tokens", ".", "weight", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "self", ".", "fc_out", "(", "x", ")", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMDecoder.get_cached_state": [[618, 634], ["lstm.LSTMDecoder.get_incremental_state", "range", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_incremental_state"], ["", "def", "get_cached_state", "(", "\n", "self", ",", "\n", "incremental_state", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ",", "\n", ")", "->", "Tuple", "[", "List", "[", "Tensor", "]", ",", "List", "[", "Tensor", "]", ",", "Optional", "[", "Tensor", "]", "]", ":", "\n", "        ", "cached_state", "=", "self", ".", "get_incremental_state", "(", "incremental_state", ",", "\"cached_state\"", ")", "\n", "assert", "cached_state", "is", "not", "None", "\n", "prev_hiddens_", "=", "cached_state", "[", "\"prev_hiddens\"", "]", "\n", "assert", "prev_hiddens_", "is", "not", "None", "\n", "prev_cells_", "=", "cached_state", "[", "\"prev_cells\"", "]", "\n", "assert", "prev_cells_", "is", "not", "None", "\n", "prev_hiddens", "=", "[", "prev_hiddens_", "[", "i", "]", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", "]", "\n", "prev_cells", "=", "[", "prev_cells_", "[", "j", "]", "for", "j", "in", "range", "(", "self", ".", "num_layers", ")", "]", "\n", "input_feed", "=", "cached_state", "[", "\n", "\"input_feed\"", "\n", "]", "# can be None for decoder-only language models", "\n", "return", "prev_hiddens", ",", "prev_cells", ",", "input_feed", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMDecoder.reorder_incremental_state": [[635, 657], ["lstm.LSTMDecoder.get_cached_state", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "torch.jit.annotate", "p.index_select", "p.index_select", "input_feed.index_select.index_select.index_select", "lstm.LSTMDecoder.set_incremental_state", "len", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMDecoder.get_cached_state", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_incremental_state"], ["", "def", "reorder_incremental_state", "(", "\n", "self", ",", "\n", "incremental_state", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", ",", "\n", "new_order", ":", "Tensor", ",", "\n", ")", ":", "\n", "        ", "if", "incremental_state", "is", "None", "or", "len", "(", "incremental_state", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "prev_hiddens", ",", "prev_cells", ",", "input_feed", "=", "self", ".", "get_cached_state", "(", "incremental_state", ")", "\n", "prev_hiddens", "=", "[", "p", ".", "index_select", "(", "0", ",", "new_order", ")", "for", "p", "in", "prev_hiddens", "]", "\n", "prev_cells", "=", "[", "p", ".", "index_select", "(", "0", ",", "new_order", ")", "for", "p", "in", "prev_cells", "]", "\n", "if", "input_feed", "is", "not", "None", ":", "\n", "            ", "input_feed", "=", "input_feed", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", "", "cached_state_new", "=", "torch", ".", "jit", ".", "annotate", "(", "\n", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", ",", "\n", "{", "\n", "\"prev_hiddens\"", ":", "torch", ".", "stack", "(", "prev_hiddens", ")", ",", "\n", "\"prev_cells\"", ":", "torch", ".", "stack", "(", "prev_cells", ")", ",", "\n", "\"input_feed\"", ":", "input_feed", ",", "\n", "}", ",", "\n", ")", "\n", "self", ".", "set_incremental_state", "(", "incremental_state", ",", "\"cached_state\"", ",", "cached_state_new", ")", ",", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMDecoder.max_positions": [[658, 661], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum output length supported by the decoder.\"\"\"", "\n", "return", "self", ".", "max_target_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMDecoder.make_generation_fast_": [[662, 664], ["None"], "methods", ["None"], ["", "def", "make_generation_fast_", "(", "self", ",", "need_attn", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "need_attn", "=", "need_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.Embedding": [[666, 671], ["torch.Embedding", "torch.init.uniform_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding"], ["", "", "def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "m", ".", "weight", ",", "-", "0.1", ",", "0.1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTM": [[673, 679], ["torch.LSTM", "nn.LSTM.named_parameters", "param.data.uniform_"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTM"], ["", "def", "LSTM", "(", "input_size", ",", "hidden_size", ",", "**", "kwargs", ")", ":", "\n", "    ", "m", "=", "nn", ".", "LSTM", "(", "input_size", ",", "hidden_size", ",", "**", "kwargs", ")", "\n", "for", "name", ",", "param", "in", "m", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "\"weight\"", "in", "name", "or", "\"bias\"", "in", "name", ":", "\n", "            ", "param", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "", "", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMCell": [[681, 687], ["torch.LSTMCell", "nn.LSTMCell.named_parameters", "param.data.uniform_"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMCell"], ["", "def", "LSTMCell", "(", "input_size", ",", "hidden_size", ",", "**", "kwargs", ")", ":", "\n", "    ", "m", "=", "nn", ".", "LSTMCell", "(", "input_size", ",", "hidden_size", ",", "**", "kwargs", ")", "\n", "for", "name", ",", "param", "in", "m", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "\"weight\"", "in", "name", "or", "\"bias\"", "in", "name", ":", "\n", "            ", "param", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "", "", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.Linear": [[689, 696], ["torch.Linear", "nn.Linear.weight.data.uniform_", "nn.Linear.bias.data.uniform_"], "function", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["", "def", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "True", ",", "dropout", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"Linear layer (input: N x T x C)\"\"\"", "\n", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "bias", ")", "\n", "m", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "if", "bias", ":", "\n", "        ", "m", ".", "bias", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.base_architecture": [[698, 728], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "@", "register_model_architecture", "(", "\"lstm\"", ",", "\"lstm\"", ")", "\n", "def", "base_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "encoder_embed_path", "=", "getattr", "(", "args", ",", "\"encoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "encoder_freeze_embed", "=", "getattr", "(", "args", ",", "\"encoder_freeze_embed\"", ",", "False", ")", "\n", "args", ".", "encoder_hidden_size", "=", "getattr", "(", "\n", "args", ",", "\"encoder_hidden_size\"", ",", "args", ".", "encoder_embed_dim", "\n", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "1", ")", "\n", "args", ".", "encoder_bidirectional", "=", "getattr", "(", "args", ",", "\"encoder_bidirectional\"", ",", "False", ")", "\n", "args", ".", "encoder_dropout_in", "=", "getattr", "(", "args", ",", "\"encoder_dropout_in\"", ",", "args", ".", "dropout", ")", "\n", "args", ".", "encoder_dropout_out", "=", "getattr", "(", "args", ",", "\"encoder_dropout_out\"", ",", "args", ".", "dropout", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "decoder_embed_path", "=", "getattr", "(", "args", ",", "\"decoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "decoder_freeze_embed", "=", "getattr", "(", "args", ",", "\"decoder_freeze_embed\"", ",", "False", ")", "\n", "args", ".", "decoder_hidden_size", "=", "getattr", "(", "\n", "args", ",", "\"decoder_hidden_size\"", ",", "args", ".", "decoder_embed_dim", "\n", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "1", ")", "\n", "args", ".", "decoder_out_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_out_embed_dim\"", ",", "512", ")", "\n", "args", ".", "decoder_attention", "=", "getattr", "(", "args", ",", "\"decoder_attention\"", ",", "\"1\"", ")", "\n", "args", ".", "decoder_dropout_in", "=", "getattr", "(", "args", ",", "\"decoder_dropout_in\"", ",", "args", ".", "dropout", ")", "\n", "args", ".", "decoder_dropout_out", "=", "getattr", "(", "args", ",", "\"decoder_dropout_out\"", ",", "args", ".", "dropout", ")", "\n", "args", ".", "share_decoder_input_output_embed", "=", "getattr", "(", "\n", "args", ",", "\"share_decoder_input_output_embed\"", ",", "False", "\n", ")", "\n", "args", ".", "share_all_embeddings", "=", "getattr", "(", "args", ",", "\"share_all_embeddings\"", ",", "False", ")", "\n", "args", ".", "adaptive_softmax_cutoff", "=", "getattr", "(", "\n", "args", ",", "\"adaptive_softmax_cutoff\"", ",", "\"10000,50000,200000\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.lstm_wiseman_iwslt_de_en": [[731, 742], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "lstm.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "@", "register_model_architecture", "(", "\"lstm\"", ",", "\"lstm_wiseman_iwslt_de_en\"", ")", "\n", "def", "lstm_wiseman_iwslt_de_en", "(", "args", ")", ":", "\n", "    ", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "256", ")", "\n", "args", ".", "encoder_dropout_in", "=", "getattr", "(", "args", ",", "\"encoder_dropout_in\"", ",", "0", ")", "\n", "args", ".", "encoder_dropout_out", "=", "getattr", "(", "args", ",", "\"encoder_dropout_out\"", ",", "0", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "256", ")", "\n", "args", ".", "decoder_out_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_out_embed_dim\"", ",", "256", ")", "\n", "args", ".", "decoder_dropout_in", "=", "getattr", "(", "args", ",", "\"decoder_dropout_in\"", ",", "0", ")", "\n", "args", ".", "decoder_dropout_out", "=", "getattr", "(", "args", ",", "\"decoder_dropout_out\"", ",", "args", ".", "dropout", ")", "\n", "base_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lstm.lstm_luong_wmt_en_de": [[744, 754], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "lstm.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "@", "register_model_architecture", "(", "\"lstm\"", ",", "\"lstm_luong_wmt_en_de\"", ")", "\n", "def", "lstm_luong_wmt_en_de", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "1000", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "4", ")", "\n", "args", ".", "encoder_dropout_out", "=", "getattr", "(", "args", ",", "\"encoder_dropout_out\"", ",", "0", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "1000", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "4", ")", "\n", "args", ".", "decoder_out_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_out_embed_dim\"", ",", "1000", ")", "\n", "args", ".", "decoder_dropout_out", "=", "getattr", "(", "args", ",", "\"decoder_dropout_out\"", ",", "0", ")", "\n", "base_architecture", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.LightConvModel.hub_models": [[50, 74], ["lightconv.LightConvModel.hub_models.moses_subword"], "methods", ["None"], ["@", "classmethod", "\n", "def", "hub_models", "(", "cls", ")", ":", "\n", "# fmt: off", "\n", "\n", "        ", "def", "moses_subword", "(", "path", ")", ":", "\n", "            ", "return", "{", "\n", "'path'", ":", "path", ",", "\n", "'tokenizer'", ":", "'moses'", ",", "\n", "'bpe'", ":", "'subword_nmt'", ",", "\n", "}", "\n", "\n", "", "return", "{", "\n", "'lightconv.no_glu.iwslt14.de-en'", ":", "moses_subword", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/iwslt14.de-en.lightconv.tar.gz'", ")", ",", "\n", "'dynamicconv.no_glu.iwslt14.de-en'", ":", "moses_subword", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/iwslt14.de-en.dynamicconv.tar.gz'", ")", ",", "\n", "'lightconv.no_glu.wmt16.en-de'", ":", "moses_subword", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/wmt16.en-de.joined-dict.lightconv.tar.gz'", ")", ",", "\n", "'dynamicconv.no_glu.wmt16.en-de'", ":", "moses_subword", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/wmt16.en-de.joined-dict.dynamicconv.tar.gz'", ")", ",", "\n", "'lightconv.glu.wmt16.en-de'", ":", "moses_subword", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/wmt16.en-de.joined-dict.lightconv-glu.tar.gz'", ")", ",", "\n", "'dynamicconv.glu.wmt16.en-de'", ":", "moses_subword", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/wmt16.en-de.joined-dict.dynamicconv-glu.tar.gz'", ")", ",", "\n", "'lightconv.glu.wmt17.en-de'", ":", "moses_subword", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/wmt16.en-de.joined-dict.lightconv-glu.tar.gz'", ")", ",", "\n", "'dynamicconv.glu.wmt17.en-de'", ":", "moses_subword", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/wmt16.en-de.joined-dict.dynamicconv-glu.tar.gz'", ")", ",", "\n", "'lightconv.glu.wmt14.en-fr'", ":", "moses_subword", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/wmt14.en-fr.joined-dict.lightconv-glu.tar.gz'", ")", ",", "\n", "'dynamicconv.glu.wmt14.en-fr'", ":", "moses_subword", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/wmt14.en-fr.joined-dict.dynamicconv-glu.tar.gz'", ")", ",", "\n", "'lightconv.glu.wmt17.zh-en'", ":", "moses_subword", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/wmt17.zh-en.lightconv-glu.tar.gz'", ")", ",", "\n", "'dynamicconv.glu.wmt17.zh-en'", ":", "moses_subword", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/dynamicconv/wmt17.zh-en.dynamicconv-glu.tar.gz'", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.LightConvModel.__init__": [[77, 79], ["fairseq.models.FairseqEncoderDecoderModel.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["", "def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "encoder", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.LightConvModel.add_args": [[80, 251], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "fairseq.utils.eval_str_list", "fairseq.utils.eval_str_list"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.eval_str_list", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.eval_str_list"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dropout\"", ",", "type", "=", "float", ",", "metavar", "=", "\"D\"", ",", "help", "=", "\"dropout probability\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--attention-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability for attention weights\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--relu-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability after ReLU in FFN\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--input-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability of the inputs\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-embed-path\"", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"STR\"", ",", "\n", "help", "=", "\"path to pre-trained encoder embedding\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-embed-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"encoder embedding dimension\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-conv-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"encoder embedding dimension\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-ffn-embed-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"encoder embedding dimension for FFN\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-layers\"", ",", "type", "=", "int", ",", "metavar", "=", "\"N\"", ",", "help", "=", "\"num encoder layers\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-attention-heads\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"num encoder attention heads or LightConv/DynamicConv heads\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-normalize-before\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"apply layernorm before each encoder block\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-learned-pos\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"use learned positional embeddings in the encoder\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-embed-path\"", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"STR\"", ",", "\n", "help", "=", "\"path to pre-trained decoder embedding\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-embed-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"decoder embedding dimension\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-conv-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"decoder embedding dimension\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-ffn-embed-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"decoder embedding dimension for FFN\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-layers\"", ",", "type", "=", "int", ",", "metavar", "=", "\"N\"", ",", "help", "=", "\"num decoder layers\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-attention-heads\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"num decoder attention heads or LightConv/DynamicConv heads\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-learned-pos\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"use learned positional embeddings in the decoder\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-normalize-before\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"apply layernorm before each decoder block\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--share-decoder-input-output-embed\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"share decoder input and output embeddings\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--share-all-embeddings\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"share encoder, decoder and output embeddings\"", "\n", "\" (requires shared dictionary and embed dim)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--adaptive-softmax-cutoff\"", ",", "\n", "metavar", "=", "\"EXPR\"", ",", "\n", "help", "=", "\"comma separated list of adaptive softmax cutoff points. \"", "\n", "\"Must be used with adaptive_loss criterion\"", ",", "\n", ")", ",", "\n", "parser", ".", "add_argument", "(", "\n", "\"--adaptive-softmax-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"sets adaptive softmax dropout for the tail projections\"", ",", "\n", ")", "\n", "\n", "\"\"\"LightConv and DynamicConv arguments\"\"\"", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-kernel-size-list\"", ",", "\n", "type", "=", "lambda", "x", ":", "utils", ".", "eval_str_list", "(", "x", ",", "int", ")", ",", "\n", "help", "=", "'list of kernel size (default: \"[3,7,15,31,31,31,31]\")'", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-kernel-size-list\"", ",", "\n", "type", "=", "lambda", "x", ":", "utils", ".", "eval_str_list", "(", "x", ",", "int", ")", ",", "\n", "help", "=", "'list of kernel size (default: \"[3,7,15,31,31,31]\")'", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-glu\"", ",", "type", "=", "utils", ".", "eval_bool", ",", "help", "=", "\"glu after in proj\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-glu\"", ",", "type", "=", "utils", ".", "eval_bool", ",", "help", "=", "\"glu after in proj\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-conv-type\"", ",", "\n", "default", "=", "\"dynamic\"", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "[", "\"dynamic\"", ",", "\"lightweight\"", "]", ",", "\n", "help", "=", "\"type of convolution\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-conv-type\"", ",", "\n", "default", "=", "\"dynamic\"", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "[", "\"dynamic\"", ",", "\"lightweight\"", "]", ",", "\n", "help", "=", "\"type of convolution\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight-softmax\"", ",", "default", "=", "True", ",", "type", "=", "utils", ".", "eval_bool", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--weight-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability for conv weights\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.LightConvModel.build_model": [[253, 308], ["lightconv.base_architecture", "lightconv.LightConvEncoder", "lightconv.LightConvDecoder", "lightconv.LightConvModel", "hasattr", "hasattr", "len", "dictionary.pad", "lightconv.Embedding", "lightconv.LightConvModel.build_model.build_embedding"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.build_embedding"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "\n", "# make sure all arguments are present in older models", "\n", "base_architecture", "(", "args", ")", "\n", "\n", "if", "not", "hasattr", "(", "args", ",", "\"max_source_positions\"", ")", ":", "\n", "            ", "args", ".", "max_source_positions", "=", "1024", "\n", "", "if", "not", "hasattr", "(", "args", ",", "\"max_target_positions\"", ")", ":", "\n", "            ", "args", ".", "max_target_positions", "=", "1024", "\n", "\n", "", "src_dict", ",", "tgt_dict", "=", "task", ".", "source_dictionary", ",", "task", ".", "target_dictionary", "\n", "\n", "def", "build_embedding", "(", "dictionary", ",", "embed_dim", ",", "path", "=", "None", ")", ":", "\n", "            ", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "emb", "=", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "padding_idx", ")", "\n", "# if provided, load from preloaded dictionaries", "\n", "if", "path", ":", "\n", "                ", "embed_dict", "=", "utils", ".", "parse_embedding", "(", "path", ")", "\n", "utils", ".", "load_embedding", "(", "embed_dict", ",", "dictionary", ",", "emb", ")", "\n", "", "return", "emb", "\n", "\n", "", "if", "args", ".", "share_all_embeddings", ":", "\n", "            ", "if", "src_dict", "!=", "tgt_dict", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "\"--share-all-embeddings requires a joined dictionary\"", "\n", ")", "\n", "", "if", "args", ".", "encoder_embed_dim", "!=", "args", ".", "decoder_embed_dim", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "\"--share-all-embeddings requires --encoder-embed-dim to match --decoder-embed-dim\"", "\n", ")", "\n", "", "if", "args", ".", "decoder_embed_path", "and", "(", "\n", "args", ".", "decoder_embed_path", "!=", "args", ".", "encoder_embed_path", "\n", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "\"--share-all-embeddings not compatible with --decoder-embed-path\"", "\n", ")", "\n", "", "encoder_embed_tokens", "=", "build_embedding", "(", "\n", "src_dict", ",", "args", ".", "encoder_embed_dim", ",", "args", ".", "encoder_embed_path", "\n", ")", "\n", "decoder_embed_tokens", "=", "encoder_embed_tokens", "\n", "args", ".", "share_decoder_input_output_embed", "=", "True", "\n", "", "else", ":", "\n", "            ", "encoder_embed_tokens", "=", "build_embedding", "(", "\n", "src_dict", ",", "args", ".", "encoder_embed_dim", ",", "args", ".", "encoder_embed_path", "\n", ")", "\n", "decoder_embed_tokens", "=", "build_embedding", "(", "\n", "tgt_dict", ",", "args", ".", "decoder_embed_dim", ",", "args", ".", "decoder_embed_path", "\n", ")", "\n", "\n", "", "encoder", "=", "LightConvEncoder", "(", "args", ",", "src_dict", ",", "encoder_embed_tokens", ")", "\n", "decoder", "=", "LightConvDecoder", "(", "args", ",", "tgt_dict", ",", "decoder_embed_tokens", ")", "\n", "return", "LightConvModel", "(", "encoder", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.LightConvEncoder.__init__": [[321, 357], ["fairseq.models.FairseqEncoder.__init__", "fairseq.modules.FairseqDropout", "math.sqrt", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "lightconv.LightConvEncoder.layers.extend", "lightconv.LightConvEncoder.register_buffer", "fairseq.modules.PositionalEmbedding", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "fairseq.modules.LayerNorm", "lightconv.LightConvEncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.PositionalEmbedding", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "self", ",", "args", ",", "dictionary", ",", "embed_tokens", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "args", ".", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "\n", "embed_dim", "=", "embed_tokens", ".", "embedding_dim", "\n", "self", ".", "padding_idx", "=", "embed_tokens", ".", "padding_idx", "\n", "self", ".", "max_source_positions", "=", "args", ".", "max_source_positions", "\n", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "self", ".", "embed_scale", "=", "math", ".", "sqrt", "(", "embed_dim", ")", "\n", "self", ".", "embed_positions", "=", "(", "\n", "PositionalEmbedding", "(", "\n", "args", ".", "max_source_positions", ",", "\n", "embed_dim", ",", "\n", "self", ".", "padding_idx", ",", "\n", "learned", "=", "args", ".", "encoder_learned_pos", ",", "\n", ")", "\n", "if", "not", "args", ".", "no_token_positional_embeddings", "\n", "else", "None", "\n", ")", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "layers", ".", "extend", "(", "\n", "[", "\n", "LightConvEncoderLayer", "(", "\n", "args", ",", "kernel_size", "=", "args", ".", "encoder_kernel_size_list", "[", "i", "]", "\n", ")", "\n", "for", "i", "in", "range", "(", "args", ".", "encoder_layers", ")", "\n", "]", "\n", ")", "\n", "self", ".", "register_buffer", "(", "\"version\"", ",", "torch", ".", "Tensor", "(", "[", "2", "]", ")", ")", "\n", "self", ".", "normalize", "=", "args", ".", "encoder_normalize_before", "\n", "if", "self", ".", "normalize", ":", "\n", "            ", "self", ".", "layer_norm", "=", "LayerNorm", "(", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.LightConvEncoder.forward": [[358, 395], ["lightconv.LightConvEncoder.dropout_module", "lightconv.LightConvEncoder.transpose", "src_tokens.eq", "lightconv.LightConvEncoder.embed_tokens", "lightconv.LightConvEncoder.embed_positions", "src_tokens.eq.any", "layer", "lightconv.LightConvEncoder.layer_norm"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "src_tokens", ",", "**", "unused", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            src_tokens (LongTensor): tokens in the source language of shape\n                `(batch, src_len)`\n\n        Returns:\n            dict:\n                - **encoder_out** (Tensor): the last encoder layer's output of\n                  shape `(src_len, batch, embed_dim)`\n                - **encoder_padding_mask** (ByteTensor): the positions of\n                  padding elements of shape `(batch, src_len)`\n        \"\"\"", "\n", "# embed tokens and positions", "\n", "x", "=", "self", ".", "embed_scale", "*", "self", ".", "embed_tokens", "(", "src_tokens", ")", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", ":", "\n", "            ", "x", "+=", "self", ".", "embed_positions", "(", "src_tokens", ")", "\n", "", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# compute padding mask", "\n", "encoder_padding_mask", "=", "src_tokens", ".", "eq", "(", "self", ".", "padding_idx", ")", "\n", "if", "not", "encoder_padding_mask", ".", "any", "(", ")", ":", "\n", "            ", "encoder_padding_mask", "=", "None", "\n", "\n", "# encoder layers", "\n", "", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "layer", "(", "x", ",", "encoder_padding_mask", ")", "\n", "\n", "", "if", "self", ".", "normalize", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "", "return", "{", "\n", "\"encoder_out\"", ":", "x", ",", "# T x B x C", "\n", "\"encoder_padding_mask\"", ":", "encoder_padding_mask", ",", "# B x T", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.LightConvEncoder.reorder_encoder_out": [[397, 417], ["encoder_out[].index_select", "encoder_out[].index_select"], "methods", ["None"], ["", "def", "reorder_encoder_out", "(", "self", ",", "encoder_out", ",", "new_order", ")", ":", "\n", "        ", "\"\"\"\n        Reorder encoder output according to *new_order*.\n\n        Args:\n            encoder_out: output from the ``forward()`` method\n            new_order (LongTensor): desired order\n\n        Returns:\n            *encoder_out* rearranged according to *new_order*\n        \"\"\"", "\n", "if", "encoder_out", "[", "\"encoder_out\"", "]", "is", "not", "None", ":", "\n", "            ", "encoder_out", "[", "\"encoder_out\"", "]", "=", "encoder_out", "[", "\"encoder_out\"", "]", ".", "index_select", "(", "\n", "1", ",", "new_order", "\n", ")", "\n", "", "if", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "is", "not", "None", ":", "\n", "            ", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "=", "encoder_out", "[", "\n", "\"encoder_padding_mask\"", "\n", "]", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", "", "return", "encoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.LightConvEncoder.max_positions": [[418, 423], ["min"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum input length supported by the encoder.\"\"\"", "\n", "if", "self", ".", "embed_positions", "is", "None", ":", "\n", "            ", "return", "self", ".", "max_source_positions", "\n", "", "return", "min", "(", "self", ".", "max_source_positions", ",", "self", ".", "embed_positions", ".", "max_positions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.LightConvDecoder.__init__": [[438, 511], ["fairseq.models.FairseqIncrementalDecoder.__init__", "fairseq.modules.FairseqDropout", "math.sqrt", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "lightconv.LightConvDecoder.layers.extend", "lightconv.LightConvDecoder.register_buffer", "lightconv.Linear", "fairseq.modules.PositionalEmbedding", "lightconv.Linear", "fairseq.modules.AdaptiveSoftmax", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "fairseq.modules.LayerNorm", "lightconv.LightConvDecoderLayer", "len", "fairseq.utils.eval_str_list", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "range", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.PositionalEmbedding", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.eval_str_list"], ["def", "__init__", "(", "\n", "self", ",", "args", ",", "dictionary", ",", "embed_tokens", ",", "no_encoder_attn", "=", "False", ",", "final_norm", "=", "True", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "args", ".", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "share_input_output_embed", "=", "args", ".", "share_decoder_input_output_embed", "\n", "\n", "input_embed_dim", "=", "embed_tokens", ".", "embedding_dim", "\n", "embed_dim", "=", "args", ".", "decoder_embed_dim", "\n", "output_embed_dim", "=", "args", ".", "decoder_output_dim", "\n", "\n", "padding_idx", "=", "embed_tokens", ".", "padding_idx", "\n", "self", ".", "max_target_positions", "=", "args", ".", "max_target_positions", "\n", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "self", ".", "embed_scale", "=", "math", ".", "sqrt", "(", "embed_dim", ")", "# todo: try with input_embed_dim", "\n", "\n", "self", ".", "project_in_dim", "=", "(", "\n", "Linear", "(", "input_embed_dim", ",", "embed_dim", ",", "bias", "=", "False", ")", "\n", "if", "embed_dim", "!=", "input_embed_dim", "\n", "else", "None", "\n", ")", "\n", "\n", "self", ".", "embed_positions", "=", "(", "\n", "PositionalEmbedding", "(", "\n", "args", ".", "max_target_positions", ",", "\n", "embed_dim", ",", "\n", "padding_idx", ",", "\n", "learned", "=", "args", ".", "decoder_learned_pos", ",", "\n", ")", "\n", "if", "not", "args", ".", "no_token_positional_embeddings", "\n", "else", "None", "\n", ")", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "layers", ".", "extend", "(", "\n", "[", "\n", "LightConvDecoderLayer", "(", "\n", "args", ",", "no_encoder_attn", ",", "kernel_size", "=", "args", ".", "decoder_kernel_size_list", "[", "i", "]", "\n", ")", "\n", "for", "i", "in", "range", "(", "args", ".", "decoder_layers", ")", "\n", "]", "\n", ")", "\n", "\n", "self", ".", "adaptive_softmax", "=", "None", "\n", "\n", "self", ".", "project_out_dim", "=", "(", "\n", "Linear", "(", "embed_dim", ",", "output_embed_dim", ",", "bias", "=", "False", ")", "\n", "if", "embed_dim", "!=", "output_embed_dim", "and", "not", "args", ".", "tie_adaptive_weights", "\n", "else", "None", "\n", ")", "\n", "\n", "if", "args", ".", "adaptive_softmax_cutoff", "is", "not", "None", ":", "\n", "            ", "self", ".", "adaptive_softmax", "=", "AdaptiveSoftmax", "(", "\n", "len", "(", "dictionary", ")", ",", "\n", "output_embed_dim", ",", "\n", "utils", ".", "eval_str_list", "(", "args", ".", "adaptive_softmax_cutoff", ",", "type", "=", "int", ")", ",", "\n", "dropout", "=", "args", ".", "adaptive_softmax_dropout", ",", "\n", "adaptive_inputs", "=", "embed_tokens", "if", "args", ".", "tie_adaptive_weights", "else", "None", ",", "\n", "factor", "=", "args", ".", "adaptive_softmax_factor", ",", "\n", "tie_proj", "=", "args", ".", "tie_adaptive_proj", ",", "\n", ")", "\n", "", "elif", "not", "self", ".", "share_input_output_embed", ":", "\n", "            ", "self", ".", "embed_out", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "len", "(", "dictionary", ")", ",", "output_embed_dim", ")", "\n", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "embed_out", ",", "mean", "=", "0", ",", "std", "=", "output_embed_dim", "**", "-", "0.5", ")", "\n", "", "self", ".", "register_buffer", "(", "\"version\"", ",", "torch", ".", "Tensor", "(", "[", "2", "]", ")", ")", "\n", "self", ".", "normalize", "=", "args", ".", "decoder_normalize_before", "and", "final_norm", "\n", "if", "self", ".", "normalize", ":", "\n", "            ", "self", ".", "layer_norm", "=", "LayerNorm", "(", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.LightConvDecoder.forward": [[512, 591], ["lightconv.LightConvDecoder.dropout_module", "torch.linear.transpose", "torch.linear.transpose", "lightconv.LightConvDecoder.embed_positions", "lightconv.LightConvDecoder.embed_tokens", "lightconv.LightConvDecoder.project_in_dim", "layer", "inner_states.append", "lightconv.LightConvDecoder.layer_norm", "lightconv.LightConvDecoder.project_out_dim", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["", "", "def", "forward", "(", "\n", "self", ",", "prev_output_tokens", ",", "encoder_out", "=", "None", ",", "incremental_state", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            prev_output_tokens (LongTensor): previous decoder outputs of shape\n                `(batch, tgt_len)`, for teacher forcing\n            encoder_out (Tensor, optional): output from the encoder, used for\n                encoder-side attention\n            incremental_state (dict): dictionary used for storing state during\n                :ref:`Incremental decoding`\n\n        Returns:\n            tuple:\n                - the last decoder layer's output of shape `(batch, tgt_len,\n                  vocab)`\n                - the last decoder layer's attention weights of shape `(batch,\n                  tgt_len, src_len)`\n        \"\"\"", "\n", "# embed positions", "\n", "positions", "=", "(", "\n", "self", ".", "embed_positions", "(", "\n", "prev_output_tokens", ",", "\n", "incremental_state", "=", "incremental_state", ",", "\n", ")", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "prev_output_tokens", "=", "prev_output_tokens", "[", ":", ",", "-", "1", ":", "]", "\n", "if", "positions", "is", "not", "None", ":", "\n", "                ", "positions", "=", "positions", "[", ":", ",", "-", "1", ":", "]", "\n", "\n", "# embed tokens and positions", "\n", "", "", "x", "=", "self", ".", "embed_scale", "*", "self", ".", "embed_tokens", "(", "prev_output_tokens", ")", "\n", "\n", "if", "self", ".", "project_in_dim", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "project_in_dim", "(", "x", ")", "\n", "\n", "", "if", "positions", "is", "not", "None", ":", "\n", "            ", "x", "+=", "positions", "\n", "", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "attn", "=", "None", "\n", "\n", "inner_states", "=", "[", "x", "]", "\n", "\n", "# decoder layers", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "x", ",", "attn", "=", "layer", "(", "\n", "x", ",", "\n", "encoder_out", "[", "\"encoder_out\"", "]", "if", "encoder_out", "is", "not", "None", "else", "None", ",", "\n", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "\n", "if", "encoder_out", "is", "not", "None", "\n", "else", "None", ",", "\n", "incremental_state", ",", "\n", ")", "\n", "inner_states", ".", "append", "(", "x", ")", "\n", "\n", "", "if", "self", ".", "normalize", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "if", "self", ".", "project_out_dim", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "project_out_dim", "(", "x", ")", "\n", "\n", "", "if", "self", ".", "adaptive_softmax", "is", "None", ":", "\n", "# project back to size of vocabulary", "\n", "            ", "if", "self", ".", "share_input_output_embed", ":", "\n", "                ", "x", "=", "F", ".", "linear", "(", "x", ",", "self", ".", "embed_tokens", ".", "weight", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "F", ".", "linear", "(", "x", ",", "self", ".", "embed_out", ")", "\n", "\n", "", "", "return", "x", ",", "{", "\"attn\"", ":", "attn", ",", "\"inner_states\"", ":", "inner_states", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.LightConvDecoder.max_positions": [[592, 597], ["min"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum output length supported by the decoder.\"\"\"", "\n", "if", "self", ".", "embed_positions", "is", "None", ":", "\n", "            ", "return", "self", ".", "max_target_positions", "\n", "", "return", "min", "(", "self", ".", "max_target_positions", ",", "self", ".", "embed_positions", ".", "max_positions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.LightConvDecoder.buffered_future_mask": [[598, 613], ["tensor.size", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "lightconv.LightConvDecoder._future_mask.size", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "hasattr", "fairseq.utils.fill_with_neg_inf", "fairseq.utils.fill_with_neg_inf", "tensor.new", "lightconv.LightConvDecoder._future_mask.resize_"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.fill_with_neg_inf", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.fill_with_neg_inf"], ["", "def", "buffered_future_mask", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "dim", "=", "tensor", ".", "size", "(", "0", ")", "\n", "if", "(", "\n", "not", "hasattr", "(", "self", ",", "\"_future_mask\"", ")", "\n", "or", "self", ".", "_future_mask", "is", "None", "\n", "or", "self", ".", "_future_mask", ".", "device", "!=", "tensor", ".", "device", "\n", ")", ":", "\n", "            ", "self", ".", "_future_mask", "=", "torch", ".", "triu", "(", "\n", "utils", ".", "fill_with_neg_inf", "(", "tensor", ".", "new", "(", "dim", ",", "dim", ")", ")", ",", "1", "\n", ")", "\n", "", "if", "self", ".", "_future_mask", ".", "size", "(", "0", ")", "<", "dim", ":", "\n", "            ", "self", ".", "_future_mask", "=", "torch", ".", "triu", "(", "\n", "utils", ".", "fill_with_neg_inf", "(", "self", ".", "_future_mask", ".", "resize_", "(", "dim", ",", "dim", ")", ")", ",", "1", "\n", ")", "\n", "", "return", "self", ".", "_future_mask", "[", ":", "dim", ",", ":", "dim", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.LightConvEncoderLayer.__init__": [[623, 674], ["torch.Module.__init__", "lightconv.Linear", "fairseq.modules.FairseqDropout", "fairseq.modules.FairseqDropout", "fairseq.modules.FairseqDropout", "lightconv.Linear", "lightconv.Linear", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "lightconv.Linear", "torch.GLU", "torch.GLU", "torch.GLU", "lightconv.Linear", "fairseq.modules.LightweightConv", "fairseq.modules.DynamicConv", "fairseq.modules.LayerNorm", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.modules.lightweight_convolution.LightweightConv", "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_convolution.DynamicConv", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "self", ",", "args", ",", "kernel_size", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "args", ".", "encoder_embed_dim", "\n", "self", ".", "conv_dim", "=", "args", ".", "encoder_conv_dim", "\n", "padding_l", "=", "(", "\n", "kernel_size", "//", "2", "\n", "if", "kernel_size", "%", "2", "==", "1", "\n", "else", "(", "(", "kernel_size", "-", "1", ")", "//", "2", ",", "kernel_size", "//", "2", ")", "\n", ")", "\n", "\n", "if", "args", ".", "encoder_glu", ":", "\n", "            ", "self", ".", "linear1", "=", "Linear", "(", "self", ".", "embed_dim", ",", "2", "*", "self", ".", "conv_dim", ")", "\n", "self", ".", "act", "=", "nn", ".", "GLU", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "linear1", "=", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "conv_dim", ")", "\n", "self", ".", "act", "=", "None", "\n", "", "if", "args", ".", "encoder_conv_type", "==", "\"lightweight\"", ":", "\n", "            ", "self", ".", "conv", "=", "LightweightConv", "(", "\n", "self", ".", "conv_dim", ",", "\n", "kernel_size", ",", "\n", "padding_l", "=", "padding_l", ",", "\n", "weight_softmax", "=", "args", ".", "weight_softmax", ",", "\n", "num_heads", "=", "args", ".", "encoder_attention_heads", ",", "\n", "weight_dropout", "=", "args", ".", "weight_dropout", ",", "\n", ")", "\n", "", "elif", "args", ".", "encoder_conv_type", "==", "\"dynamic\"", ":", "\n", "            ", "self", ".", "conv", "=", "DynamicConv", "(", "\n", "self", ".", "conv_dim", ",", "\n", "kernel_size", ",", "\n", "padding_l", "=", "padding_l", ",", "\n", "weight_softmax", "=", "args", ".", "weight_softmax", ",", "\n", "num_heads", "=", "args", ".", "encoder_attention_heads", ",", "\n", "weight_dropout", "=", "args", ".", "weight_dropout", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "self", ".", "linear2", "=", "Linear", "(", "self", ".", "conv_dim", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "args", ".", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "relu_dropout_module", "=", "FairseqDropout", "(", "\n", "args", ".", "relu_dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "input_dropout_module", "=", "FairseqDropout", "(", "\n", "args", ".", "input_dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "normalize_before", "=", "args", ".", "encoder_normalize_before", "\n", "self", ".", "fc1", "=", "Linear", "(", "self", ".", "embed_dim", ",", "args", ".", "encoder_ffn_embed_dim", ")", "\n", "self", ".", "fc2", "=", "Linear", "(", "args", ".", "encoder_ffn_embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "layer_norms", "=", "nn", ".", "ModuleList", "(", "[", "LayerNorm", "(", "self", ".", "embed_dim", ")", "for", "_", "in", "range", "(", "2", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.LightConvEncoderLayer.forward": [[675, 708], ["lightconv.LightConvEncoderLayer.maybe_layer_norm", "lightconv.LightConvEncoderLayer.input_dropout_module", "lightconv.LightConvEncoderLayer.linear1", "lightconv.LightConvEncoderLayer.conv", "lightconv.LightConvEncoderLayer.linear2", "lightconv.LightConvEncoderLayer.dropout_module", "lightconv.LightConvEncoderLayer.maybe_layer_norm", "lightconv.LightConvEncoderLayer.maybe_layer_norm", "torch.relu", "torch.relu", "torch.relu", "lightconv.LightConvEncoderLayer.relu_dropout_module", "lightconv.LightConvEncoderLayer.fc2", "lightconv.LightConvEncoderLayer.dropout_module", "lightconv.LightConvEncoderLayer.maybe_layer_norm", "lightconv.LightConvEncoderLayer.act", "x.masked_fill.masked_fill.masked_fill", "lightconv.LightConvEncoderLayer.fc1", "encoder_padding_mask.transpose().unsqueeze", "encoder_padding_mask.transpose"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm"], ["", "def", "forward", "(", "self", ",", "x", ",", "encoder_padding_mask", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (Tensor): input to the layer of shape `(seq_len, batch, embed_dim)`\n            encoder_padding_mask (ByteTensor): binary ByteTensor of shape\n                `(batch, src_len)` where padding elements are indicated by ``1``.\n\n        Returns:\n            encoded output of shape `(batch, src_len, embed_dim)`\n        \"\"\"", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "0", ",", "x", ",", "before", "=", "True", ")", "\n", "x", "=", "self", ".", "input_dropout_module", "(", "x", ")", "\n", "x", "=", "self", ".", "linear1", "(", "x", ")", "\n", "if", "self", ".", "act", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "", "if", "encoder_padding_mask", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", ".", "masked_fill", "(", "encoder_padding_mask", ".", "transpose", "(", "0", ",", "1", ")", ".", "unsqueeze", "(", "2", ")", ",", "0", ")", "\n", "", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "x", "=", "self", ".", "linear2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "0", ",", "x", ",", "after", "=", "True", ")", "\n", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "1", ",", "x", ",", "before", "=", "True", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "relu_dropout_module", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "1", ",", "x", ",", "after", "=", "True", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.LightConvEncoderLayer.maybe_layer_norm": [[709, 715], ["None"], "methods", ["None"], ["", "def", "maybe_layer_norm", "(", "self", ",", "i", ",", "x", ",", "before", "=", "False", ",", "after", "=", "False", ")", ":", "\n", "        ", "assert", "before", "^", "after", "\n", "if", "after", "^", "self", ".", "normalize_before", ":", "\n", "            ", "return", "self", ".", "layer_norms", "[", "i", "]", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.LightConvEncoderLayer.extra_repr": [[716, 723], ["None"], "methods", ["None"], ["", "", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "\"dropout={}, relu_dropout={}, input_dropout={}, normalize_before={}\"", ".", "format", "(", "\n", "self", ".", "dropout_module", ".", "p", ",", "\n", "self", ".", "relu_dropout_module", ".", "p", ",", "\n", "self", ".", "input_dropout_module", ".", "p", ",", "\n", "self", ".", "normalize_before", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.LightConvDecoderLayer.__init__": [[737, 799], ["torch.Module.__init__", "lightconv.Linear", "fairseq.modules.FairseqDropout", "fairseq.modules.FairseqDropout", "fairseq.modules.FairseqDropout", "fairseq.modules.LayerNorm", "lightconv.Linear", "lightconv.Linear", "fairseq.modules.LayerNorm", "lightconv.Linear", "torch.GLU", "torch.GLU", "torch.GLU", "lightconv.Linear", "fairseq.modules.LightweightConv", "fairseq.modules.MultiheadAttention", "fairseq.modules.LayerNorm", "fairseq.modules.DynamicConv"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.modules.lightweight_convolution.LightweightConv", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_convolution.DynamicConv"], ["def", "__init__", "(", "self", ",", "args", ",", "no_encoder_attn", "=", "False", ",", "kernel_size", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "args", ".", "decoder_embed_dim", "\n", "self", ".", "conv_dim", "=", "args", ".", "decoder_conv_dim", "\n", "if", "args", ".", "decoder_glu", ":", "\n", "            ", "self", ".", "linear1", "=", "Linear", "(", "self", ".", "embed_dim", ",", "2", "*", "self", ".", "conv_dim", ")", "\n", "self", ".", "act", "=", "nn", ".", "GLU", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "linear1", "=", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "conv_dim", ")", "\n", "self", ".", "act", "=", "None", "\n", "", "if", "args", ".", "decoder_conv_type", "==", "\"lightweight\"", ":", "\n", "            ", "self", ".", "conv", "=", "LightweightConv", "(", "\n", "self", ".", "conv_dim", ",", "\n", "kernel_size", ",", "\n", "padding_l", "=", "kernel_size", "-", "1", ",", "\n", "weight_softmax", "=", "args", ".", "weight_softmax", ",", "\n", "num_heads", "=", "args", ".", "decoder_attention_heads", ",", "\n", "weight_dropout", "=", "args", ".", "weight_dropout", ",", "\n", ")", "\n", "", "elif", "args", ".", "decoder_conv_type", "==", "\"dynamic\"", ":", "\n", "            ", "self", ".", "conv", "=", "DynamicConv", "(", "\n", "self", ".", "conv_dim", ",", "\n", "kernel_size", ",", "\n", "padding_l", "=", "kernel_size", "-", "1", ",", "\n", "weight_softmax", "=", "args", ".", "weight_softmax", ",", "\n", "num_heads", "=", "args", ".", "decoder_attention_heads", ",", "\n", "weight_dropout", "=", "args", ".", "weight_dropout", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "self", ".", "linear2", "=", "Linear", "(", "self", ".", "conv_dim", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "args", ".", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "relu_dropout_module", "=", "FairseqDropout", "(", "\n", "args", ".", "relu_dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "input_dropout_module", "=", "FairseqDropout", "(", "\n", "args", ".", "input_dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "normalize_before", "=", "args", ".", "decoder_normalize_before", "\n", "\n", "self", ".", "conv_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n", "if", "no_encoder_attn", ":", "\n", "            ", "self", ".", "encoder_attn", "=", "None", "\n", "self", ".", "encoder_attn_layer_norm", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "encoder_attn", "=", "MultiheadAttention", "(", "\n", "self", ".", "embed_dim", ",", "\n", "args", ".", "decoder_attention_heads", ",", "\n", "dropout", "=", "args", ".", "attention_dropout", ",", "\n", "encoder_decoder_attention", "=", "True", ",", "\n", ")", "\n", "self", ".", "encoder_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n", "", "self", ".", "fc1", "=", "Linear", "(", "self", ".", "embed_dim", ",", "args", ".", "decoder_ffn_embed_dim", ")", "\n", "self", ".", "fc2", "=", "Linear", "(", "args", ".", "decoder_ffn_embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "final_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "need_attn", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.LightConvDecoderLayer.forward": [[800, 868], ["lightconv.LightConvDecoderLayer.maybe_layer_norm", "lightconv.LightConvDecoderLayer.input_dropout_module", "lightconv.LightConvDecoderLayer.linear1", "lightconv.LightConvDecoderLayer.conv", "lightconv.LightConvDecoderLayer.linear2", "lightconv.LightConvDecoderLayer.dropout_module", "lightconv.LightConvDecoderLayer.maybe_layer_norm", "lightconv.LightConvDecoderLayer.maybe_layer_norm", "torch.relu", "torch.relu", "torch.relu", "lightconv.LightConvDecoderLayer.relu_dropout_module", "lightconv.LightConvDecoderLayer.fc2", "lightconv.LightConvDecoderLayer.dropout_module", "lightconv.LightConvDecoderLayer.maybe_layer_norm", "lightconv.LightConvDecoderLayer.conv._set_input_buffer", "lightconv.LightConvDecoderLayer.act", "lightconv.LightConvDecoderLayer.maybe_layer_norm", "lightconv.LightConvDecoderLayer.encoder_attn", "lightconv.LightConvDecoderLayer.dropout_module", "lightconv.LightConvDecoderLayer.maybe_layer_norm", "lightconv.LightConvDecoderLayer.fc1", "lightconv.LightConvDecoderLayer.encoder_attn._set_input_buffer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "x", ",", "\n", "encoder_out", ",", "\n", "encoder_padding_mask", ",", "\n", "incremental_state", ",", "\n", "prev_conv_state", "=", "None", ",", "\n", "prev_attn_state", "=", "None", ",", "\n", "conv_mask", "=", "None", ",", "\n", "conv_padding_mask", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (Tensor): input to the layer of shape `(seq_len, batch, embed_dim)`\n            encoder_padding_mask (ByteTensor): binary ByteTensor of shape\n                `(batch, src_len)` where padding elements are indicated by ``1``.\n\n        Returns:\n            encoded output of shape `(batch, src_len, embed_dim)`\n        \"\"\"", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "conv_layer_norm", ",", "x", ",", "before", "=", "True", ")", "\n", "if", "prev_conv_state", "is", "not", "None", ":", "\n", "            ", "if", "incremental_state", "is", "None", ":", "\n", "                ", "incremental_state", "=", "{", "}", "\n", "", "self", ".", "conv", ".", "_set_input_buffer", "(", "incremental_state", ",", "prev_conv_state", ")", "\n", "", "x", "=", "self", ".", "input_dropout_module", "(", "x", ")", "\n", "x", "=", "self", ".", "linear1", "(", "x", ")", "\n", "if", "self", ".", "act", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "", "x", "=", "self", ".", "conv", "(", "x", ",", "incremental_state", "=", "incremental_state", ")", "\n", "x", "=", "self", ".", "linear2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "conv_layer_norm", ",", "x", ",", "after", "=", "True", ")", "\n", "\n", "attn", "=", "None", "\n", "if", "self", ".", "encoder_attn", "is", "not", "None", ":", "\n", "            ", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "encoder_attn_layer_norm", ",", "x", ",", "before", "=", "True", ")", "\n", "if", "prev_attn_state", "is", "not", "None", ":", "\n", "                ", "if", "incremental_state", "is", "None", ":", "\n", "                    ", "incremental_state", "=", "{", "}", "\n", "", "prev_key", ",", "prev_value", "=", "prev_attn_state", "\n", "saved_state", "=", "{", "\"prev_key\"", ":", "prev_key", ",", "\"prev_value\"", ":", "prev_value", "}", "\n", "self", ".", "encoder_attn", ".", "_set_input_buffer", "(", "incremental_state", ",", "saved_state", ")", "\n", "", "x", ",", "attn", "=", "self", ".", "encoder_attn", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "encoder_out", ",", "\n", "value", "=", "encoder_out", ",", "\n", "key_padding_mask", "=", "encoder_padding_mask", ",", "\n", "incremental_state", "=", "incremental_state", ",", "\n", "static_kv", "=", "True", ",", "\n", "need_weights", "=", "(", "not", "self", ".", "training", "and", "self", ".", "need_attn", ")", ",", "\n", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "encoder_attn_layer_norm", ",", "x", ",", "after", "=", "True", ")", "\n", "\n", "", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "x", ",", "before", "=", "True", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "relu_dropout_module", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "x", ",", "after", "=", "True", ")", "\n", "return", "x", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.LightConvDecoderLayer.maybe_layer_norm": [[869, 875], ["layer_norm"], "methods", ["None"], ["", "def", "maybe_layer_norm", "(", "self", ",", "layer_norm", ",", "x", ",", "before", "=", "False", ",", "after", "=", "False", ")", ":", "\n", "        ", "assert", "before", "^", "after", "\n", "if", "after", "^", "self", ".", "normalize_before", ":", "\n", "            ", "return", "layer_norm", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.LightConvDecoderLayer.make_generation_fast_": [[876, 878], ["None"], "methods", ["None"], ["", "", "def", "make_generation_fast_", "(", "self", ",", "need_attn", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "need_attn", "=", "need_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.LightConvDecoderLayer.extra_repr": [[879, 886], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "\"dropout={}, relu_dropout={}, input_dropout={}, normalize_before={}\"", ".", "format", "(", "\n", "self", ".", "dropout_module", ".", "p", ",", "\n", "self", ".", "relu_dropout_module", ".", "p", ",", "\n", "self", ".", "input_dropout_module", ".", "p", ",", "\n", "self", ".", "normalize_before", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.Embedding": [[890, 895], ["torch.Embedding", "torch.init.normal_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding"], ["", "", "def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "embedding_dim", "**", "-", "0.5", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.Linear": [[897, 903], ["torch.Linear", "torch.init.xavier_uniform_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["", "def", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "if", "bias", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.0", ")", "\n", "", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.base_architecture": [[905, 968], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "@", "register_model_architecture", "(", "\"lightconv\"", ",", "\"lightconv\"", ")", "\n", "def", "base_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_path", "=", "getattr", "(", "args", ",", "\"encoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "2048", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "7", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "encoder_normalize_before", "=", "getattr", "(", "args", ",", "\"encoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "encoder_learned_pos", "=", "getattr", "(", "args", ",", "\"encoder_learned_pos\"", ",", "False", ")", "\n", "args", ".", "decoder_embed_path", "=", "getattr", "(", "args", ",", "\"decoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "args", ".", "encoder_embed_dim", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "args", ".", "encoder_ffn_embed_dim", "\n", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "6", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "decoder_normalize_before", "=", "getattr", "(", "args", ",", "\"decoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "decoder_learned_pos", "=", "getattr", "(", "args", ",", "\"decoder_learned_pos\"", ",", "False", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.0", ")", "\n", "args", ".", "relu_dropout", "=", "getattr", "(", "args", ",", "\"relu_dropout\"", ",", "0.0", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "adaptive_softmax_cutoff", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_cutoff\"", ",", "None", ")", "\n", "args", ".", "adaptive_softmax_dropout", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_dropout\"", ",", "0", ")", "\n", "args", ".", "share_decoder_input_output_embed", "=", "getattr", "(", "\n", "args", ",", "\"share_decoder_input_output_embed\"", ",", "False", "\n", ")", "\n", "args", ".", "share_all_embeddings", "=", "getattr", "(", "args", ",", "\"share_all_embeddings\"", ",", "False", ")", "\n", "args", ".", "no_token_positional_embeddings", "=", "getattr", "(", "\n", "args", ",", "\"no_token_positional_embeddings\"", ",", "False", "\n", ")", "\n", "\n", "args", ".", "decoder_output_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_output_dim\"", ",", "args", ".", "decoder_embed_dim", "\n", ")", "\n", "args", ".", "decoder_input_dim", "=", "getattr", "(", "args", ",", "\"decoder_input_dim\"", ",", "args", ".", "decoder_embed_dim", ")", "\n", "\n", "args", ".", "encoder_conv_dim", "=", "getattr", "(", "args", ",", "\"encoder_conv_dim\"", ",", "args", ".", "encoder_embed_dim", ")", "\n", "args", ".", "decoder_conv_dim", "=", "getattr", "(", "args", ",", "\"decoder_conv_dim\"", ",", "args", ".", "decoder_embed_dim", ")", "\n", "\n", "args", ".", "encoder_kernel_size_list", "=", "getattr", "(", "\n", "args", ",", "\"encoder_kernel_size_list\"", ",", "[", "3", ",", "7", ",", "15", ",", "31", ",", "31", ",", "31", ",", "31", "]", "\n", ")", "\n", "args", ".", "decoder_kernel_size_list", "=", "getattr", "(", "\n", "args", ",", "\"decoder_kernel_size_list\"", ",", "[", "3", ",", "7", ",", "15", ",", "31", ",", "31", ",", "31", "]", "\n", ")", "\n", "if", "len", "(", "args", ".", "encoder_kernel_size_list", ")", "==", "1", ":", "\n", "        ", "args", ".", "encoder_kernel_size_list", "=", "(", "\n", "args", ".", "encoder_kernel_size_list", "*", "args", ".", "encoder_layers", "\n", ")", "\n", "", "if", "len", "(", "args", ".", "decoder_kernel_size_list", ")", "==", "1", ":", "\n", "        ", "args", ".", "decoder_kernel_size_list", "=", "(", "\n", "args", ".", "decoder_kernel_size_list", "*", "args", ".", "decoder_layers", "\n", ")", "\n", "", "assert", "(", "\n", "len", "(", "args", ".", "encoder_kernel_size_list", ")", "==", "args", ".", "encoder_layers", "\n", ")", ",", "\"encoder_kernel_size_list doesn't match encoder_layers\"", "\n", "assert", "(", "\n", "len", "(", "args", ".", "decoder_kernel_size_list", ")", "==", "args", ".", "decoder_layers", "\n", ")", ",", "\"decoder_kernel_size_list doesn't match decoder_layers\"", "\n", "args", ".", "encoder_glu", "=", "getattr", "(", "args", ",", "\"encoder_glu\"", ",", "True", ")", "\n", "args", ".", "decoder_glu", "=", "getattr", "(", "args", ",", "\"decoder_glu\"", ",", "True", ")", "\n", "args", ".", "input_dropout", "=", "getattr", "(", "args", ",", "\"input_dropout\"", ",", "0.1", ")", "\n", "args", ".", "weight_dropout", "=", "getattr", "(", "args", ",", "\"weight_dropout\"", ",", "args", ".", "attention_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.lightconv_iwslt_de_en": [[970, 986], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "lightconv.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "@", "register_model_architecture", "(", "\"lightconv\"", ",", "\"lightconv_iwslt_de_en\"", ")", "\n", "def", "lightconv_iwslt_de_en", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "1024", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "4", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "7", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "1024", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "4", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "6", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.1", ")", "\n", "args", ".", "weight_dropout", "=", "getattr", "(", "args", ",", "\"weight_dropout\"", ",", "0.1", ")", "\n", "args", ".", "encoder_glu", "=", "getattr", "(", "args", ",", "\"encoder_glu\"", ",", "False", ")", "\n", "args", ".", "decoder_glu", "=", "getattr", "(", "args", ",", "\"decoder_glu\"", ",", "False", ")", "\n", "args", ".", "input_dropout", "=", "getattr", "(", "args", ",", "\"input_dropout\"", ",", "0.0", ")", "\n", "base_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.lightconv_wmt_en_de": [[988, 991], ["fairseq.models.register_model_architecture", "lightconv.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "@", "register_model_architecture", "(", "\"lightconv\"", ",", "\"lightconv_wmt_en_de\"", ")", "\n", "def", "lightconv_wmt_en_de", "(", "args", ")", ":", "\n", "    ", "base_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.lightconv_wmt_en_de_big": [[993, 1005], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "lightconv.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "@", "register_model_architecture", "(", "\"lightconv\"", ",", "\"lightconv_wmt_en_de_big\"", ")", "\n", "def", "lightconv_wmt_en_de_big", "(", "args", ")", ":", "\n", "    ", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.1", ")", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "1024", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "4096", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "16", ")", "\n", "args", ".", "encoder_normalize_before", "=", "getattr", "(", "args", ",", "\"encoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "1024", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "4096", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "16", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.3", ")", "\n", "base_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.lightconv_wmt_en_fr_big": [[1007, 1011], ["fairseq.models.register_model_architecture", "getattr", "lightconv.lightconv_wmt_en_de_big"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.lightconv_wmt_en_de_big"], ["", "@", "register_model_architecture", "(", "\"lightconv\"", ",", "\"lightconv_wmt_en_fr_big\"", ")", "\n", "def", "lightconv_wmt_en_fr_big", "(", "args", ")", ":", "\n", "    ", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "lightconv_wmt_en_de_big", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.lightconv_wmt_zh_en_big": [[1013, 1019], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "lightconv.lightconv_wmt_en_de_big"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.lightconv.lightconv_wmt_en_de_big"], ["", "@", "register_model_architecture", "(", "\"lightconv\"", ",", "\"lightconv_wmt_zh_en_big\"", ")", "\n", "def", "lightconv_wmt_zh_en_big", "(", "args", ")", ":", "\n", "    ", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.2", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.2", ")", "\n", "args", ".", "weight_dropout", "=", "getattr", "(", "args", ",", "\"weight_dropout\"", ",", "0.2", ")", "\n", "lightconv_wmt_en_de_big", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_align.TransformerAlignModel.__init__": [[21, 26], ["fairseq.models.transformer.TransformerModel.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "encoder", ",", "decoder", ")", "\n", "self", ".", "alignment_heads", "=", "args", ".", "alignment_heads", "\n", "self", ".", "alignment_layer", "=", "args", ".", "alignment_layer", "\n", "self", ".", "full_context_alignment", "=", "args", ".", "full_context_alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_align.TransformerAlignModel.add_args": [[27, 37], ["super().add_args", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "# fmt: off", "\n", "        ", "super", "(", "TransformerAlignModel", ",", "TransformerAlignModel", ")", ".", "add_args", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "'--alignment-heads'", ",", "type", "=", "int", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'Number of cross attention heads per layer to supervised with alignments'", ")", "\n", "parser", ".", "add_argument", "(", "'--alignment-layer'", ",", "type", "=", "int", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'Layer number which has to be supervised. 0 corresponding to the bottommost layer.'", ")", "\n", "parser", ".", "add_argument", "(", "'--full-context-alignment'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Whether or not alignment is supervised conditioned on the full target context.'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_align.TransformerAlignModel.build_model": [[39, 47], ["transformer_align.transformer_align", "fairseq.models.transformer.TransformerModel.build_model", "transformer_align.TransformerAlignModel"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.transformer_align.transformer_align", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "# set any default arguments", "\n", "        ", "transformer_align", "(", "args", ")", "\n", "\n", "transformer_model", "=", "TransformerModel", ".", "build_model", "(", "args", ",", "task", ")", "\n", "return", "TransformerAlignModel", "(", "\n", "transformer_model", ".", "encoder", ",", "transformer_model", ".", "decoder", ",", "args", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_align.TransformerAlignModel.forward": [[49, 52], ["transformer_align.TransformerAlignModel.encoder", "transformer_align.TransformerAlignModel.forward_decoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_decoder"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ")", ":", "\n", "        ", "encoder_out", "=", "self", ".", "encoder", "(", "src_tokens", ",", "src_lengths", ")", "\n", "return", "self", ".", "forward_decoder", "(", "prev_output_tokens", ",", "encoder_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_align.TransformerAlignModel.forward_decoder": [[53, 79], ["transformer_align.TransformerAlignModel.decoder", "transformer_align.TransformerAlignModel.decoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward_decoder", "(", "\n", "self", ",", "\n", "prev_output_tokens", ",", "\n", "encoder_out", "=", "None", ",", "\n", "incremental_state", "=", "None", ",", "\n", "features_only", "=", "False", ",", "\n", "**", "extra_args", ",", "\n", ")", ":", "\n", "        ", "attn_args", "=", "{", "\n", "\"alignment_layer\"", ":", "self", ".", "alignment_layer", ",", "\n", "\"alignment_heads\"", ":", "self", ".", "alignment_heads", ",", "\n", "}", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "prev_output_tokens", ",", "encoder_out", ",", "**", "attn_args", ")", "\n", "\n", "if", "self", ".", "full_context_alignment", ":", "\n", "            ", "attn_args", "[", "\"full_context_alignment\"", "]", "=", "self", ".", "full_context_alignment", "\n", "_", ",", "alignment_out", "=", "self", ".", "decoder", "(", "\n", "prev_output_tokens", ",", "\n", "encoder_out", ",", "\n", "features_only", "=", "True", ",", "\n", "**", "attn_args", ",", "\n", "**", "extra_args", ",", "\n", ")", "\n", "decoder_out", "[", "1", "]", "[", "\"attn\"", "]", "=", "alignment_out", "[", "\"attn\"", "]", "\n", "\n", "", "return", "decoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_align.transformer_align": [[81, 87], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "fairseq.models.transformer.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "", "@", "register_model_architecture", "(", "\"transformer_align\"", ",", "\"transformer_align\"", ")", "\n", "def", "transformer_align", "(", "args", ")", ":", "\n", "    ", "args", ".", "alignment_heads", "=", "getattr", "(", "args", ",", "\"alignment_heads\"", ",", "1", ")", "\n", "args", ".", "alignment_layer", "=", "getattr", "(", "args", ",", "\"alignment_layer\"", ",", "4", ")", "\n", "args", ".", "full_context_alignment", "=", "getattr", "(", "args", ",", "\"full_context_alignment\"", ",", "False", ")", "\n", "base_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_align.transformer_wmt_en_de_big_align": [[89, 94], ["fairseq.models.register_model_architecture", "getattr", "getattr", "fairseq.models.transformer.transformer_wmt_en_de_big"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.transformer.transformer_wmt_en_de_big"], ["", "@", "register_model_architecture", "(", "\"transformer_align\"", ",", "\"transformer_wmt_en_de_big_align\"", ")", "\n", "def", "transformer_wmt_en_de_big_align", "(", "args", ")", ":", "\n", "    ", "args", ".", "alignment_heads", "=", "getattr", "(", "args", ",", "\"alignment_heads\"", ",", "1", ")", "\n", "args", ".", "alignment_layer", "=", "getattr", "(", "args", ",", "\"alignment_layer\"", ",", "4", ")", "\n", "transformer_wmt_en_de_big", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvModel.hub_models": [[48, 66], ["fconv.FConvModel.hub_models.moses_subword"], "methods", ["None"], ["@", "classmethod", "\n", "def", "hub_models", "(", "cls", ")", ":", "\n", "        ", "def", "moses_subword", "(", "path", ")", ":", "\n", "            ", "return", "{", "\n", "\"path\"", ":", "path", ",", "\n", "\"tokenizer\"", ":", "\"moses\"", ",", "\n", "\"bpe\"", ":", "\"subword_nmt\"", ",", "\n", "}", "\n", "\n", "", "return", "{", "\n", "\"conv.wmt14.en-fr\"", ":", "moses_subword", "(", "\n", "\"https://dl.fbaipublicfiles.com/fairseq/models/wmt14.v2.en-fr.fconv-py.tar.bz2\"", "\n", ")", ",", "\n", "\"conv.wmt14.en-de\"", ":", "moses_subword", "(", "\n", "\"https://dl.fbaipublicfiles.com/fairseq/models/wmt14.en-de.fconv-py.tar.bz2\"", "\n", ")", ",", "\n", "\"conv.wmt17.en-de\"", ":", "moses_subword", "(", "\n", "\"https://dl.fbaipublicfiles.com/fairseq/models/wmt17.v2.en-de.fconv-py.tar.bz2\"", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvModel.__init__": [[69, 73], ["fairseq.models.FairseqEncoderDecoderModel.__init__", "sum"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["", "def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "encoder", ",", "decoder", ")", "\n", "self", ".", "encoder", ".", "num_attention_layers", "=", "sum", "(", "\n", "layer", "is", "not", "None", "for", "layer", "in", "decoder", ".", "attention", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvModel.add_args": [[75, 99], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'encoder embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-embed-path'", ",", "type", "=", "str", ",", "metavar", "=", "'STR'", ",", "\n", "help", "=", "'path to pre-trained encoder embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-layers'", ",", "type", "=", "str", ",", "metavar", "=", "'EXPR'", ",", "\n", "help", "=", "'encoder layers [(dim, kernel_size), ...]'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-embed-path'", ",", "type", "=", "str", ",", "metavar", "=", "'STR'", ",", "\n", "help", "=", "'path to pre-trained decoder embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-layers'", ",", "type", "=", "str", ",", "metavar", "=", "'EXPR'", ",", "\n", "help", "=", "'decoder layers [(dim, kernel_size), ...]'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-out-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder output embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-attention'", ",", "type", "=", "str", ",", "metavar", "=", "'EXPR'", ",", "\n", "help", "=", "'decoder attention [True, ...]'", ")", "\n", "parser", ".", "add_argument", "(", "'--share-input-output-embed'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'share input and output embeddings (requires'", "\n", "' --decoder-out-embed-dim and --decoder-embed-dim'", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvModel.build_model": [[103, 139], ["fconv.base_architecture", "fconv.FConvEncoder", "fconv.FConvDecoder", "fconv.FConvModel", "fairseq.utils.parse_embedding", "fairseq.utils.print_embed_overlap", "fairseq.utils.parse_embedding", "fairseq.utils.print_embed_overlap", "eval", "eval", "eval"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.parse_embedding", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.print_embed_overlap", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.parse_embedding", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.print_embed_overlap"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "# make sure that all args are properly defaulted (in case there are any new ones)", "\n", "base_architecture", "(", "args", ")", "\n", "\n", "encoder_embed_dict", "=", "None", "\n", "if", "args", ".", "encoder_embed_path", ":", "\n", "            ", "encoder_embed_dict", "=", "utils", ".", "parse_embedding", "(", "args", ".", "encoder_embed_path", ")", "\n", "utils", ".", "print_embed_overlap", "(", "encoder_embed_dict", ",", "task", ".", "source_dictionary", ")", "\n", "\n", "", "decoder_embed_dict", "=", "None", "\n", "if", "args", ".", "decoder_embed_path", ":", "\n", "            ", "decoder_embed_dict", "=", "utils", ".", "parse_embedding", "(", "args", ".", "decoder_embed_path", ")", "\n", "utils", ".", "print_embed_overlap", "(", "decoder_embed_dict", ",", "task", ".", "target_dictionary", ")", "\n", "\n", "", "encoder", "=", "FConvEncoder", "(", "\n", "dictionary", "=", "task", ".", "source_dictionary", ",", "\n", "embed_dim", "=", "args", ".", "encoder_embed_dim", ",", "\n", "embed_dict", "=", "encoder_embed_dict", ",", "\n", "convolutions", "=", "eval", "(", "args", ".", "encoder_layers", ")", ",", "\n", "dropout", "=", "args", ".", "dropout", ",", "\n", "max_positions", "=", "args", ".", "max_source_positions", ",", "\n", ")", "\n", "decoder", "=", "FConvDecoder", "(", "\n", "dictionary", "=", "task", ".", "target_dictionary", ",", "\n", "embed_dim", "=", "args", ".", "decoder_embed_dim", ",", "\n", "embed_dict", "=", "decoder_embed_dict", ",", "\n", "convolutions", "=", "eval", "(", "args", ".", "decoder_layers", ")", ",", "\n", "out_embed_dim", "=", "args", ".", "decoder_out_embed_dim", ",", "\n", "attention", "=", "eval", "(", "args", ".", "decoder_attention", ")", ",", "\n", "dropout", "=", "args", ".", "dropout", ",", "\n", "max_positions", "=", "args", ".", "max_target_positions", ",", "\n", "share_embed", "=", "args", ".", "share_input_output_embed", ",", "\n", ")", "\n", "return", "FConvModel", "(", "encoder", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvEncoder.__init__": [[159, 223], ["fairseq.models.FairseqEncoder.__init__", "fairseq.modules.FairseqDropout", "len", "dictionary.pad", "fconv.Embedding", "fconv.PositionalEmbedding", "fconv.extend_conv_spec", "fconv.Linear", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "enumerate", "fconv.Linear", "fairseq.utils.load_embedding", "fconv.FConvEncoder.projections.append", "fconv.FConvEncoder.convolutions.append", "fconv.FConvEncoder.residuals.append", "layer_in_channels.append", "fconv.ConvTBC", "fconv.Linear"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.PositionalEmbedding", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.extend_conv_spec", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.load_embedding", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.ConvTBC", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dictionary", ",", "\n", "embed_dim", "=", "512", ",", "\n", "embed_dict", "=", "None", ",", "\n", "max_positions", "=", "1024", ",", "\n", "convolutions", "=", "(", "(", "512", ",", "3", ")", ",", ")", "*", "20", ",", "\n", "dropout", "=", "0.1", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "num_attention_layers", "=", "None", "\n", "\n", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "self", ".", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "self", ".", "embed_tokens", "=", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "self", ".", "padding_idx", ")", "\n", "if", "embed_dict", ":", "\n", "            ", "self", ".", "embed_tokens", "=", "utils", ".", "load_embedding", "(", "\n", "embed_dict", ",", "self", ".", "dictionary", ",", "self", ".", "embed_tokens", "\n", ")", "\n", "\n", "", "self", ".", "embed_positions", "=", "PositionalEmbedding", "(", "\n", "max_positions", ",", "\n", "embed_dim", ",", "\n", "self", ".", "padding_idx", ",", "\n", ")", "\n", "\n", "convolutions", "=", "extend_conv_spec", "(", "convolutions", ")", "\n", "in_channels", "=", "convolutions", "[", "0", "]", "[", "0", "]", "\n", "self", ".", "fc1", "=", "Linear", "(", "embed_dim", ",", "in_channels", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "projections", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "convolutions", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "residuals", "=", "[", "]", "\n", "\n", "layer_in_channels", "=", "[", "in_channels", "]", "\n", "for", "_", ",", "(", "out_channels", ",", "kernel_size", ",", "residual", ")", "in", "enumerate", "(", "convolutions", ")", ":", "\n", "            ", "if", "residual", "==", "0", ":", "\n", "                ", "residual_dim", "=", "out_channels", "\n", "", "else", ":", "\n", "                ", "residual_dim", "=", "layer_in_channels", "[", "-", "residual", "]", "\n", "", "self", ".", "projections", ".", "append", "(", "\n", "Linear", "(", "residual_dim", ",", "out_channels", ")", "\n", "if", "residual_dim", "!=", "out_channels", "\n", "else", "None", "\n", ")", "\n", "if", "kernel_size", "%", "2", "==", "1", ":", "\n", "                ", "padding", "=", "kernel_size", "//", "2", "\n", "", "else", ":", "\n", "                ", "padding", "=", "0", "\n", "", "self", ".", "convolutions", ".", "append", "(", "\n", "ConvTBC", "(", "\n", "in_channels", ",", "\n", "out_channels", "*", "2", ",", "\n", "kernel_size", ",", "\n", "dropout", "=", "dropout", ",", "\n", "padding", "=", "padding", ",", "\n", ")", "\n", ")", "\n", "self", ".", "residuals", ".", "append", "(", "residual", ")", "\n", "in_channels", "=", "out_channels", "\n", "layer_in_channels", ".", "append", "(", "out_channels", ")", "\n", "", "self", ".", "fc2", "=", "Linear", "(", "in_channels", ",", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvEncoder.forward": [[224, 306], ["fconv.FConvEncoder.dropout_module", "fconv.FConvEncoder.fc1", "src_tokens.eq().t", "conv.transpose", "zip", "conv.transpose", "fconv.FConvEncoder.fc2", "fairseq.modules.GradMultiply.apply", "fconv.FConvEncoder.embed_tokens", "fconv.FConvEncoder.embed_positions", "encoder_padding_mask.t.t.any", "fconv.FConvEncoder.dropout_module", "torch.glu", "torch.glu", "torch.glu", "residuals.append", "encoder_padding_mask.t.t.t", "conv.masked_fill", "math.sqrt", "src_tokens.eq", "conv.masked_fill", "conv", "torch.pad", "torch.pad", "torch.pad", "conv", "encoder_padding_mask.t.t.unsqueeze", "proj", "encoder_padding_mask.t.t.unsqueeze", "math.sqrt"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            src_tokens (LongTensor): tokens in the source language of shape\n                `(batch, src_len)`\n            src_lengths (LongTensor): lengths of each source sentence of shape\n                `(batch)`\n\n        Returns:\n            dict:\n                - **encoder_out** (tuple): a tuple with two elements, where the\n                  first element is the last encoder layer's output and the\n                  second element is the same quantity summed with the input\n                  embedding (used for attention). The shape of both tensors is\n                  `(batch, src_len, embed_dim)`.\n                - **encoder_padding_mask** (ByteTensor): the positions of\n                  padding elements of shape `(batch, src_len)`\n        \"\"\"", "\n", "# embed tokens and positions", "\n", "x", "=", "self", ".", "embed_tokens", "(", "src_tokens", ")", "+", "self", ".", "embed_positions", "(", "src_tokens", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "input_embedding", "=", "x", "\n", "\n", "# project to size of convolution", "\n", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "\n", "# used to mask padding in input", "\n", "encoder_padding_mask", "=", "src_tokens", ".", "eq", "(", "self", ".", "padding_idx", ")", ".", "t", "(", ")", "# -> T x B", "\n", "if", "not", "encoder_padding_mask", ".", "any", "(", ")", ":", "\n", "            ", "encoder_padding_mask", "=", "None", "\n", "\n", "# B x T x C -> T x B x C", "\n", "", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "residuals", "=", "[", "x", "]", "\n", "# temporal convolutions", "\n", "for", "proj", ",", "conv", ",", "res_layer", "in", "zip", "(", "\n", "self", ".", "projections", ",", "self", ".", "convolutions", ",", "self", ".", "residuals", "\n", ")", ":", "\n", "            ", "if", "res_layer", ">", "0", ":", "\n", "                ", "residual", "=", "residuals", "[", "-", "res_layer", "]", "\n", "residual", "=", "residual", "if", "proj", "is", "None", "else", "proj", "(", "residual", ")", "\n", "", "else", ":", "\n", "                ", "residual", "=", "None", "\n", "\n", "", "if", "encoder_padding_mask", "is", "not", "None", ":", "\n", "                ", "x", "=", "x", ".", "masked_fill", "(", "encoder_padding_mask", ".", "unsqueeze", "(", "-", "1", ")", ",", "0", ")", "\n", "\n", "", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "if", "conv", ".", "kernel_size", "[", "0", "]", "%", "2", "==", "1", ":", "\n", "# padding is implicit in the conv", "\n", "                ", "x", "=", "conv", "(", "x", ")", "\n", "", "else", ":", "\n", "                ", "padding_l", "=", "(", "conv", ".", "kernel_size", "[", "0", "]", "-", "1", ")", "//", "2", "\n", "padding_r", "=", "conv", ".", "kernel_size", "[", "0", "]", "//", "2", "\n", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "0", ",", "0", ",", "0", ",", "padding_l", ",", "padding_r", ")", ")", "\n", "x", "=", "conv", "(", "x", ")", "\n", "", "x", "=", "F", ".", "glu", "(", "x", ",", "dim", "=", "2", ")", "\n", "\n", "if", "residual", "is", "not", "None", ":", "\n", "                ", "x", "=", "(", "x", "+", "residual", ")", "*", "math", ".", "sqrt", "(", "0.5", ")", "\n", "", "residuals", ".", "append", "(", "x", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "", "x", "=", "x", ".", "transpose", "(", "1", ",", "0", ")", "\n", "\n", "# project back to size of embedding", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "\n", "if", "encoder_padding_mask", "is", "not", "None", ":", "\n", "            ", "encoder_padding_mask", "=", "encoder_padding_mask", ".", "t", "(", ")", "# -> B x T", "\n", "x", "=", "x", ".", "masked_fill", "(", "encoder_padding_mask", ".", "unsqueeze", "(", "-", "1", ")", ",", "0", ")", "\n", "\n", "# scale gradients (this only affects backward, not forward)", "\n", "", "x", "=", "GradMultiply", ".", "apply", "(", "x", ",", "1.0", "/", "(", "2.0", "*", "self", ".", "num_attention_layers", ")", ")", "\n", "\n", "# add output to input embedding for attention", "\n", "y", "=", "(", "x", "+", "input_embedding", ")", "*", "math", ".", "sqrt", "(", "0.5", ")", "\n", "\n", "return", "{", "\n", "\"encoder_out\"", ":", "(", "x", ",", "y", ")", ",", "\n", "\"encoder_padding_mask\"", ":", "encoder_padding_mask", ",", "# B x T", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvEncoder.reorder_encoder_out": [[308, 319], ["encoder_out[].index_select", "[].index_select", "[].index_select"], "methods", ["None"], ["", "def", "reorder_encoder_out", "(", "self", ",", "encoder_out", ",", "new_order", ")", ":", "\n", "        ", "if", "encoder_out", "[", "\"encoder_out\"", "]", "is", "not", "None", ":", "\n", "            ", "encoder_out", "[", "\"encoder_out\"", "]", "=", "(", "\n", "encoder_out", "[", "\"encoder_out\"", "]", "[", "0", "]", ".", "index_select", "(", "0", ",", "new_order", ")", ",", "\n", "encoder_out", "[", "\"encoder_out\"", "]", "[", "1", "]", ".", "index_select", "(", "0", ",", "new_order", ")", ",", "\n", ")", "\n", "", "if", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "is", "not", "None", ":", "\n", "            ", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "=", "encoder_out", "[", "\n", "\"encoder_padding_mask\"", "\n", "]", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", "", "return", "encoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvEncoder.max_positions": [[320, 323], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum input length supported by the encoder.\"\"\"", "\n", "return", "self", ".", "embed_positions", ".", "max_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.AttentionLayer.__init__": [[326, 334], ["torch.Module.__init__", "fconv.Linear", "fconv.Linear"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["    ", "def", "__init__", "(", "self", ",", "conv_channels", ",", "embed_dim", ",", "bmm", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# projects from output of convolution to embedding dimension", "\n", "self", ".", "in_projection", "=", "Linear", "(", "conv_channels", ",", "embed_dim", ")", "\n", "# projects from embedding dimension to convolution size", "\n", "self", ".", "out_projection", "=", "Linear", "(", "embed_dim", ",", "conv_channels", ")", "\n", "\n", "self", ".", "bmm", "=", "bmm", "if", "bmm", "is", "not", "None", "else", "torch", ".", "bmm", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.AttentionLayer.forward": [[335, 372], ["fconv.AttentionLayer.bmm", "x.float().masked_fill().type_as.float().masked_fill().type_as.size", "torch.softmax", "torch.softmax", "torch.softmax", "x.float().masked_fill().type_as.float().masked_fill().type_as.view", "fconv.AttentionLayer.bmm", "encoder_out[].size", "math.sqrt", "x.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill().type_as", "x.float().masked_fill().type_as.float().masked_fill().type_as.view", "s.unsqueeze.unsqueeze.unsqueeze", "math.sqrt", "fconv.AttentionLayer.in_projection", "encoder_padding_mask.type_as().sum", "fconv.AttentionLayer.out_projection", "x.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill", "math.sqrt", "s.unsqueeze.unsqueeze.rsqrt", "encoder_padding_mask.unsqueeze", "float", "encoder_padding_mask.type_as", "x.float().masked_fill().type_as.float().masked_fill().type_as.float"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "forward", "(", "self", ",", "x", ",", "target_embedding", ",", "encoder_out", ",", "encoder_padding_mask", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "# attention", "\n", "x", "=", "(", "self", ".", "in_projection", "(", "x", ")", "+", "target_embedding", ")", "*", "math", ".", "sqrt", "(", "0.5", ")", "\n", "x", "=", "self", ".", "bmm", "(", "x", ",", "encoder_out", "[", "0", "]", ")", "\n", "\n", "# don't attend over padding", "\n", "if", "encoder_padding_mask", "is", "not", "None", ":", "\n", "            ", "x", "=", "(", "\n", "x", ".", "float", "(", ")", "\n", ".", "masked_fill", "(", "encoder_padding_mask", ".", "unsqueeze", "(", "1", ")", ",", "float", "(", "\"-inf\"", ")", ")", "\n", ".", "type_as", "(", "x", ")", "\n", ")", "# FP16 support: cast to float and back", "\n", "\n", "# softmax over last dim", "\n", "", "sz", "=", "x", ".", "size", "(", ")", "\n", "x", "=", "F", ".", "softmax", "(", "x", ".", "view", "(", "sz", "[", "0", "]", "*", "sz", "[", "1", "]", ",", "sz", "[", "2", "]", ")", ",", "dim", "=", "1", ")", "\n", "x", "=", "x", ".", "view", "(", "sz", ")", "\n", "attn_scores", "=", "x", "\n", "\n", "x", "=", "self", ".", "bmm", "(", "x", ",", "encoder_out", "[", "1", "]", ")", "\n", "\n", "# scale attention output (respecting potentially different lengths)", "\n", "s", "=", "encoder_out", "[", "1", "]", ".", "size", "(", "1", ")", "\n", "if", "encoder_padding_mask", "is", "None", ":", "\n", "            ", "x", "=", "x", "*", "(", "s", "*", "math", ".", "sqrt", "(", "1.0", "/", "s", ")", ")", "\n", "", "else", ":", "\n", "            ", "s", "=", "s", "-", "encoder_padding_mask", ".", "type_as", "(", "x", ")", ".", "sum", "(", "\n", "dim", "=", "1", ",", "keepdim", "=", "True", "\n", ")", "# exclude padding", "\n", "s", "=", "s", ".", "unsqueeze", "(", "-", "1", ")", "\n", "x", "=", "x", "*", "(", "s", "*", "s", ".", "rsqrt", "(", ")", ")", "\n", "\n", "# project back", "\n", "", "x", "=", "(", "self", ".", "out_projection", "(", "x", ")", "+", "residual", ")", "*", "math", ".", "sqrt", "(", "0.5", ")", "\n", "return", "x", ",", "attn_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.AttentionLayer.make_generation_fast_": [[373, 378], ["fconv.AttentionLayer.add_module", "fairseq.modules.BeamableMM"], "methods", ["None"], ["", "def", "make_generation_fast_", "(", "self", ",", "beamable_mm_beam_size", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Replace torch.bmm with BeamableMM.\"\"\"", "\n", "if", "beamable_mm_beam_size", "is", "not", "None", ":", "\n", "            ", "del", "self", ".", "bmm", "\n", "self", ".", "add_module", "(", "\"bmm\"", ",", "BeamableMM", "(", "beamable_mm_beam_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvDecoder.__init__": [[383, 489], ["fairseq.models.FairseqIncrementalDecoder.__init__", "fconv.FConvDecoder.register_buffer", "fairseq.modules.FairseqDropout", "fconv.extend_conv_spec", "isinstance", "len", "dictionary.pad", "fconv.Embedding", "fconv.Linear", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "enumerate", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "ValueError", "fairseq.utils.load_embedding", "fconv.PositionalEmbedding", "fconv.FConvDecoder.projections.append", "fconv.FConvDecoder.convolutions.append", "fconv.FConvDecoder.attention.append", "fconv.FConvDecoder.residuals.append", "layer_in_channels.append", "fairseq.modules.AdaptiveSoftmax", "fconv.Linear", "len", "isinstance", "len", "len", "fconv.LinearizedConv1d", "torch.Linear", "torch.Linear", "torch.Linear", "fconv.Linear", "fconv.Linear", "fconv.AttentionLayer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.extend_conv_spec", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.load_embedding", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.PositionalEmbedding", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.LinearizedConv1d", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dictionary", ",", "\n", "embed_dim", "=", "512", ",", "\n", "embed_dict", "=", "None", ",", "\n", "out_embed_dim", "=", "256", ",", "\n", "max_positions", "=", "1024", ",", "\n", "convolutions", "=", "(", "(", "512", ",", "3", ")", ",", ")", "*", "20", ",", "\n", "attention", "=", "True", ",", "\n", "dropout", "=", "0.1", ",", "\n", "share_embed", "=", "False", ",", "\n", "positional_embeddings", "=", "True", ",", "\n", "adaptive_softmax_cutoff", "=", "None", ",", "\n", "adaptive_softmax_dropout", "=", "0.0", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "self", ".", "register_buffer", "(", "\"version\"", ",", "torch", ".", "Tensor", "(", "[", "2", "]", ")", ")", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "need_attn", "=", "True", "\n", "\n", "convolutions", "=", "extend_conv_spec", "(", "convolutions", ")", "\n", "in_channels", "=", "convolutions", "[", "0", "]", "[", "0", "]", "\n", "if", "isinstance", "(", "attention", ",", "bool", ")", ":", "\n", "# expand True into [True, True, ...] and do the same with False", "\n", "            ", "attention", "=", "[", "attention", "]", "*", "len", "(", "convolutions", ")", "\n", "", "if", "not", "isinstance", "(", "attention", ",", "list", ")", "or", "len", "(", "attention", ")", "!=", "len", "(", "convolutions", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Attention is expected to be a list of booleans of \"", "\n", "\"length equal to the number of layers.\"", "\n", ")", "\n", "\n", "", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "self", ".", "embed_tokens", "=", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "padding_idx", ")", "\n", "if", "embed_dict", ":", "\n", "            ", "self", ".", "embed_tokens", "=", "utils", ".", "load_embedding", "(", "\n", "embed_dict", ",", "self", ".", "dictionary", ",", "self", ".", "embed_tokens", "\n", ")", "\n", "\n", "", "self", ".", "embed_positions", "=", "(", "\n", "PositionalEmbedding", "(", "\n", "max_positions", ",", "\n", "embed_dim", ",", "\n", "padding_idx", ",", "\n", ")", "\n", "if", "positional_embeddings", "\n", "else", "None", "\n", ")", "\n", "\n", "self", ".", "fc1", "=", "Linear", "(", "embed_dim", ",", "in_channels", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "projections", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "convolutions", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "attention", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "residuals", "=", "[", "]", "\n", "\n", "layer_in_channels", "=", "[", "in_channels", "]", "\n", "for", "i", ",", "(", "out_channels", ",", "kernel_size", ",", "residual", ")", "in", "enumerate", "(", "convolutions", ")", ":", "\n", "            ", "if", "residual", "==", "0", ":", "\n", "                ", "residual_dim", "=", "out_channels", "\n", "", "else", ":", "\n", "                ", "residual_dim", "=", "layer_in_channels", "[", "-", "residual", "]", "\n", "", "self", ".", "projections", ".", "append", "(", "\n", "Linear", "(", "residual_dim", ",", "out_channels", ")", "\n", "if", "residual_dim", "!=", "out_channels", "\n", "else", "None", "\n", ")", "\n", "self", ".", "convolutions", ".", "append", "(", "\n", "LinearizedConv1d", "(", "\n", "in_channels", ",", "\n", "out_channels", "*", "2", ",", "\n", "kernel_size", ",", "\n", "padding", "=", "(", "kernel_size", "-", "1", ")", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", ")", "\n", "self", ".", "attention", ".", "append", "(", "\n", "AttentionLayer", "(", "out_channels", ",", "embed_dim", ")", "if", "attention", "[", "i", "]", "else", "None", "\n", ")", "\n", "self", ".", "residuals", ".", "append", "(", "residual", ")", "\n", "in_channels", "=", "out_channels", "\n", "layer_in_channels", ".", "append", "(", "out_channels", ")", "\n", "\n", "", "self", ".", "adaptive_softmax", "=", "None", "\n", "self", ".", "fc2", "=", "self", ".", "fc3", "=", "None", "\n", "\n", "if", "adaptive_softmax_cutoff", "is", "not", "None", ":", "\n", "            ", "assert", "not", "share_embed", "\n", "self", ".", "adaptive_softmax", "=", "AdaptiveSoftmax", "(", "\n", "num_embeddings", ",", "\n", "in_channels", ",", "\n", "adaptive_softmax_cutoff", ",", "\n", "dropout", "=", "adaptive_softmax_dropout", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "fc2", "=", "Linear", "(", "in_channels", ",", "out_embed_dim", ")", "\n", "if", "share_embed", ":", "\n", "                ", "assert", "out_embed_dim", "==", "embed_dim", ",", "(", "\n", "\"Shared embed weights implies same dimensions \"", "\n", "\" out_embed_dim={} vs embed_dim={}\"", ".", "format", "(", "out_embed_dim", ",", "embed_dim", ")", "\n", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "out_embed_dim", ",", "num_embeddings", ")", "\n", "self", ".", "fc3", ".", "weight", "=", "self", ".", "embed_tokens", ".", "weight", "\n", "", "else", ":", "\n", "                ", "self", ".", "fc3", "=", "Linear", "(", "out_embed_dim", ",", "num_embeddings", ",", "dropout", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvDecoder.forward": [[490, 571], ["fconv.FConvDecoder._embed_tokens", "fconv.FConvDecoder.dropout_module", "fconv.FConvDecoder.fc1", "fconv.FConvDecoder._transpose_if_training", "len", "zip", "fconv.FConvDecoder._transpose_if_training", "fconv.FConvDecoder._split_encoder_out", "fconv.FConvDecoder.embed_positions", "fconv.FConvDecoder.dropout_module", "conv", "torch.glu", "torch.glu", "torch.glu", "residuals.append", "fconv.FConvDecoder.fc2", "fconv.FConvDecoder.dropout_module", "fconv.FConvDecoder.fc3", "fconv.FConvDecoder._transpose_if_training", "attention", "fconv.FConvDecoder._transpose_if_training", "proj", "math.sqrt", "avg_attn_scores.add_"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvDecoder._embed_tokens", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvDecoder._transpose_if_training", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvDecoder._transpose_if_training", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvDecoder._split_encoder_out", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvDecoder._transpose_if_training", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvDecoder._transpose_if_training"], ["", "", "", "def", "forward", "(", "\n", "self", ",", "prev_output_tokens", ",", "encoder_out", "=", "None", ",", "incremental_state", "=", "None", ",", "**", "unused", "\n", ")", ":", "\n", "        ", "if", "encoder_out", "is", "not", "None", ":", "\n", "            ", "encoder_padding_mask", "=", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "\n", "encoder_out", "=", "encoder_out", "[", "\"encoder_out\"", "]", "\n", "\n", "# split and transpose encoder outputs", "\n", "encoder_a", ",", "encoder_b", "=", "self", ".", "_split_encoder_out", "(", "\n", "encoder_out", ",", "incremental_state", "\n", ")", "\n", "\n", "", "if", "self", ".", "embed_positions", "is", "not", "None", ":", "\n", "            ", "pos_embed", "=", "self", ".", "embed_positions", "(", "prev_output_tokens", ",", "incremental_state", ")", "\n", "", "else", ":", "\n", "            ", "pos_embed", "=", "0", "\n", "\n", "", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "prev_output_tokens", "=", "prev_output_tokens", "[", ":", ",", "-", "1", ":", "]", "\n", "", "x", "=", "self", ".", "_embed_tokens", "(", "prev_output_tokens", ",", "incremental_state", ")", "\n", "\n", "# embed tokens and combine with positional embeddings", "\n", "x", "+=", "pos_embed", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "target_embedding", "=", "x", "\n", "\n", "# project to size of convolution", "\n", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "self", ".", "_transpose_if_training", "(", "x", ",", "incremental_state", ")", "\n", "\n", "# temporal convolutions", "\n", "avg_attn_scores", "=", "None", "\n", "num_attn_layers", "=", "len", "(", "self", ".", "attention", ")", "\n", "residuals", "=", "[", "x", "]", "\n", "for", "proj", ",", "conv", ",", "attention", ",", "res_layer", "in", "zip", "(", "\n", "self", ".", "projections", ",", "self", ".", "convolutions", ",", "self", ".", "attention", ",", "self", ".", "residuals", "\n", ")", ":", "\n", "            ", "if", "res_layer", ">", "0", ":", "\n", "                ", "residual", "=", "residuals", "[", "-", "res_layer", "]", "\n", "residual", "=", "residual", "if", "proj", "is", "None", "else", "proj", "(", "residual", ")", "\n", "", "else", ":", "\n", "                ", "residual", "=", "None", "\n", "\n", "", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "conv", "(", "x", ",", "incremental_state", ")", "\n", "x", "=", "F", ".", "glu", "(", "x", ",", "dim", "=", "2", ")", "\n", "\n", "# attention", "\n", "if", "attention", "is", "not", "None", ":", "\n", "                ", "x", "=", "self", ".", "_transpose_if_training", "(", "x", ",", "incremental_state", ")", "\n", "\n", "x", ",", "attn_scores", "=", "attention", "(", "\n", "x", ",", "target_embedding", ",", "(", "encoder_a", ",", "encoder_b", ")", ",", "encoder_padding_mask", "\n", ")", "\n", "\n", "if", "not", "self", ".", "training", "and", "self", ".", "need_attn", ":", "\n", "                    ", "attn_scores", "=", "attn_scores", "/", "num_attn_layers", "\n", "if", "avg_attn_scores", "is", "None", ":", "\n", "                        ", "avg_attn_scores", "=", "attn_scores", "\n", "", "else", ":", "\n", "                        ", "avg_attn_scores", ".", "add_", "(", "attn_scores", ")", "\n", "\n", "", "", "x", "=", "self", ".", "_transpose_if_training", "(", "x", ",", "incremental_state", ")", "\n", "\n", "# residual", "\n", "", "if", "residual", "is", "not", "None", ":", "\n", "                ", "x", "=", "(", "x", "+", "residual", ")", "*", "math", ".", "sqrt", "(", "0.5", ")", "\n", "", "residuals", ".", "append", "(", "x", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "", "x", "=", "self", ".", "_transpose_if_training", "(", "x", ",", "incremental_state", ")", "\n", "\n", "# project back to size of vocabulary if not using adaptive softmax", "\n", "if", "self", ".", "fc2", "is", "not", "None", "and", "self", ".", "fc3", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "self", ".", "fc3", "(", "x", ")", "\n", "\n", "", "return", "x", ",", "avg_attn_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvDecoder.reorder_incremental_state": [[572, 581], ["super().reorder_incremental_state", "fairseq.utils.get_incremental_state", "tuple", "fairseq.utils.set_incremental_state", "eo.index_select"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.LSTMDecoder.reorder_incremental_state", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_incremental_state", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_incremental_state"], ["", "def", "reorder_incremental_state", "(", "self", ",", "incremental_state", ",", "new_order", ")", ":", "\n", "        ", "super", "(", ")", ".", "reorder_incremental_state", "(", "incremental_state", ",", "new_order", ")", "\n", "encoder_out", "=", "utils", ".", "get_incremental_state", "(", "\n", "self", ",", "incremental_state", ",", "\"encoder_out\"", "\n", ")", "\n", "if", "encoder_out", "is", "not", "None", ":", "\n", "            ", "encoder_out", "=", "tuple", "(", "eo", ".", "index_select", "(", "0", ",", "new_order", ")", "for", "eo", "in", "encoder_out", ")", "\n", "utils", ".", "set_incremental_state", "(", "\n", "self", ",", "incremental_state", ",", "\"encoder_out\"", ",", "encoder_out", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvDecoder.max_positions": [[583, 589], ["float"], "methods", ["None"], ["", "", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum output length supported by the decoder.\"\"\"", "\n", "return", "(", "\n", "self", ".", "embed_positions", ".", "max_positions", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", "\n", "else", "float", "(", "\"inf\"", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvDecoder.upgrade_state_dict": [[591, 600], ["fairseq.utils.item", "enumerate", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.utils.remove_weight_norm", "torch.utils.remove_weight_norm", "torch.utils.remove_weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm", "state_dict.get", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "def", "upgrade_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "if", "utils", ".", "item", "(", "state_dict", ".", "get", "(", "\"decoder.version\"", ",", "torch", ".", "Tensor", "(", "[", "1", "]", ")", ")", "[", "0", "]", ")", "<", "2", ":", "\n", "# old models use incorrect weight norm dimension", "\n", "            ", "for", "i", ",", "conv", "in", "enumerate", "(", "self", ".", "convolutions", ")", ":", "\n", "# reconfigure weight norm", "\n", "                ", "nn", ".", "utils", ".", "remove_weight_norm", "(", "conv", ")", "\n", "self", ".", "convolutions", "[", "i", "]", "=", "nn", ".", "utils", ".", "weight_norm", "(", "conv", ",", "dim", "=", "0", ")", "\n", "", "state_dict", "[", "\"decoder.version\"", "]", "=", "torch", ".", "Tensor", "(", "[", "1", "]", ")", "\n", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvDecoder.make_generation_fast_": [[601, 603], ["None"], "methods", ["None"], ["", "def", "make_generation_fast_", "(", "self", ",", "need_attn", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "need_attn", "=", "need_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvDecoder._embed_tokens": [[604, 609], ["fconv.FConvDecoder.embed_tokens"], "methods", ["None"], ["", "def", "_embed_tokens", "(", "self", ",", "tokens", ",", "incremental_state", ")", ":", "\n", "        ", "if", "incremental_state", "is", "not", "None", ":", "\n", "# keep only the last token for incremental forward pass", "\n", "            ", "tokens", "=", "tokens", "[", ":", ",", "-", "1", ":", "]", "\n", "", "return", "self", ".", "embed_tokens", "(", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvDecoder._split_encoder_out": [[610, 629], ["fairseq.utils.get_incremental_state", "encoder_a.transpose().contiguous.transpose().contiguous.transpose().contiguous", "fairseq.utils.set_incremental_state", "encoder_a.transpose().contiguous.transpose().contiguous.transpose"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_incremental_state", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_incremental_state"], ["", "def", "_split_encoder_out", "(", "self", ",", "encoder_out", ",", "incremental_state", ")", ":", "\n", "        ", "\"\"\"Split and transpose encoder outputs.\n\n        This is cached when doing incremental inference.\n        \"\"\"", "\n", "cached_result", "=", "utils", ".", "get_incremental_state", "(", "\n", "self", ",", "incremental_state", ",", "\"encoder_out\"", "\n", ")", "\n", "if", "cached_result", "is", "not", "None", ":", "\n", "            ", "return", "cached_result", "\n", "\n", "# transpose only once to speed up attention layers", "\n", "", "encoder_a", ",", "encoder_b", "=", "encoder_out", "\n", "encoder_a", "=", "encoder_a", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "result", "=", "(", "encoder_a", ",", "encoder_b", ")", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "utils", ".", "set_incremental_state", "(", "self", ",", "incremental_state", ",", "\"encoder_out\"", ",", "result", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.FConvDecoder._transpose_if_training": [[630, 634], ["x.transpose.transpose.transpose"], "methods", ["None"], ["", "def", "_transpose_if_training", "(", "self", ",", "x", ",", "incremental_state", ")", ":", "\n", "        ", "if", "incremental_state", "is", "None", ":", "\n", "            ", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.extend_conv_spec": [[636, 655], ["tuple", "len", "extended.append", "len", "extended.append", "Exception", "str"], "function", ["None"], ["", "", "def", "extend_conv_spec", "(", "convolutions", ")", ":", "\n", "    ", "\"\"\"\n    Extends convolutional spec that is a list of tuples of 2 or 3 parameters\n    (kernel size, dim size and optionally how many layers behind to look for residual)\n    to default the residual propagation param if it is not specified\n    \"\"\"", "\n", "extended", "=", "[", "]", "\n", "for", "spec", "in", "convolutions", ":", "\n", "        ", "if", "len", "(", "spec", ")", "==", "3", ":", "\n", "            ", "extended", ".", "append", "(", "spec", ")", "\n", "", "elif", "len", "(", "spec", ")", "==", "2", ":", "\n", "            ", "extended", ".", "append", "(", "spec", "+", "(", "1", ",", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"invalid number of parameters in convolution spec \"", "\n", "+", "str", "(", "spec", ")", "\n", "+", "\". expected 2 or 3\"", "\n", ")", "\n", "", "", "return", "tuple", "(", "extended", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.Embedding": [[657, 662], ["torch.Embedding", "torch.init.normal_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding"], ["", "def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "0", ",", "0.1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.PositionalEmbedding": [[664, 669], ["fairseq.modules.LearnedPositionalEmbedding", "torch.init.normal_", "torch.init.constant_"], "function", ["None"], ["", "def", "PositionalEmbedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "LearnedPositionalEmbedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "0", ",", "0.1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.Linear": [[671, 677], ["torch.Linear", "torch.init.normal_", "torch.init.constant_", "torch.utils.weight_norm", "math.sqrt"], "function", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["", "def", "Linear", "(", "in_features", ",", "out_features", ",", "dropout", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"Weight-normalized Linear layer (input: N x T x C)\"\"\"", "\n", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "math", ".", "sqrt", "(", "(", "1", "-", "dropout", ")", "/", "in_features", ")", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "return", "nn", ".", "utils", ".", "weight_norm", "(", "m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.LinearizedConv1d": [[679, 686], ["fairseq.modules.LinearizedConvolution", "math.sqrt", "torch.init.normal_", "torch.init.constant_", "torch.utils.weight_norm"], "function", ["None"], ["", "def", "LinearizedConv1d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "dropout", "=", "0.0", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Weight-normalized Conv1d layer optimized for decoding\"\"\"", "\n", "m", "=", "LinearizedConvolution", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "**", "kwargs", ")", "\n", "std", "=", "math", ".", "sqrt", "(", "(", "4", "*", "(", "1.0", "-", "dropout", ")", ")", "/", "(", "m", ".", "kernel_size", "[", "0", "]", "*", "in_channels", ")", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "std", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "return", "nn", ".", "utils", ".", "weight_norm", "(", "m", ",", "dim", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.ConvTBC": [[688, 697], ["fconv.ConvTBC", "math.sqrt", "torch.init.normal_", "torch.init.constant_", "torch.utils.weight_norm"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.fconv.ConvTBC"], ["", "def", "ConvTBC", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "dropout", "=", "0.0", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Weight-normalized Conv1d layer\"\"\"", "\n", "from", "fairseq", ".", "modules", "import", "ConvTBC", "\n", "\n", "m", "=", "ConvTBC", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "**", "kwargs", ")", "\n", "std", "=", "math", ".", "sqrt", "(", "(", "4", "*", "(", "1.0", "-", "dropout", ")", ")", "/", "(", "m", ".", "kernel_size", "[", "0", "]", "*", "in_channels", ")", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "std", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "return", "nn", ".", "utils", ".", "weight_norm", "(", "m", ",", "dim", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.base_architecture": [[699, 711], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "@", "register_model_architecture", "(", "\"fconv\"", ",", "\"fconv\"", ")", "\n", "def", "base_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "encoder_embed_path", "=", "getattr", "(", "args", ",", "\"encoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "\"[(512, 3)] * 20\"", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "decoder_embed_path", "=", "getattr", "(", "args", ",", "\"decoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "\"[(512, 3)] * 20\"", ")", "\n", "args", ".", "decoder_out_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_out_embed_dim\"", ",", "256", ")", "\n", "args", ".", "decoder_attention", "=", "getattr", "(", "args", ",", "\"decoder_attention\"", ",", "\"True\"", ")", "\n", "args", ".", "share_input_output_embed", "=", "getattr", "(", "args", ",", "\"share_input_output_embed\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.fconv_iwslt_de_en": [[713, 721], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "fconv.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "@", "register_model_architecture", "(", "\"fconv\"", ",", "\"fconv_iwslt_de_en\"", ")", "\n", "def", "fconv_iwslt_de_en", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "256", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "\"[(256, 3)] * 4\"", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "256", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "\"[(256, 3)] * 3\"", ")", "\n", "args", ".", "decoder_out_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_out_embed_dim\"", ",", "256", ")", "\n", "base_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.fconv_wmt_en_ro": [[723, 727], ["fairseq.models.register_model_architecture", "getattr", "fconv.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "@", "register_model_architecture", "(", "\"fconv\"", ",", "\"fconv_wmt_en_ro\"", ")", "\n", "def", "fconv_wmt_en_ro", "(", "args", ")", ":", "\n", "    ", "args", ".", "decoder_out_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_out_embed_dim\"", ",", "512", ")", "\n", "base_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.fconv_wmt_en_de": [[729, 741], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "fconv.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "@", "register_model_architecture", "(", "\"fconv\"", ",", "\"fconv_wmt_en_de\"", ")", "\n", "def", "fconv_wmt_en_de", "(", "args", ")", ":", "\n", "    ", "convs", "=", "\"[(512, 3)] * 9\"", "# first 9 layers have 512 units", "\n", "convs", "+=", "\" + [(1024, 3)] * 4\"", "# next 4 layers have 1024 units", "\n", "convs", "+=", "\" + [(2048, 1)] * 2\"", "# final 2 layers use 1x1 convolutions", "\n", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "768", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "convs", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "768", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "convs", ")", "\n", "args", ".", "decoder_out_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_out_embed_dim\"", ",", "512", ")", "\n", "base_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fconv.fconv_wmt_en_fr": [[743, 757], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "fconv.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "@", "register_model_architecture", "(", "\"fconv\"", ",", "\"fconv_wmt_en_fr\"", ")", "\n", "def", "fconv_wmt_en_fr", "(", "args", ")", ":", "\n", "    ", "convs", "=", "\"[(512, 3)] * 6\"", "# first 6 layers have 512 units", "\n", "convs", "+=", "\" + [(768, 3)] * 4\"", "# next 4 layers have 768 units", "\n", "convs", "+=", "\" + [(1024, 3)] * 3\"", "# next 3 layers have 1024 units", "\n", "convs", "+=", "\" + [(2048, 1)] * 1\"", "# next 1 layer uses 1x1 convolutions", "\n", "convs", "+=", "\" + [(4096, 1)] * 1\"", "# final 1 layer uses 1x1 convolutions", "\n", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "768", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "convs", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "768", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "convs", ")", "\n", "args", ".", "decoder_out_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_out_embed_dim\"", ",", "512", ")", "\n", "base_architecture", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.models.masked_lm.MaskedLMModel.__init__": [[36, 45], ["fairseq.models.FairseqEncoderModel.__init__", "getattr", "masked_lm.MaskedLMModel.apply"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "parser", ".", "add_argument", "(", "\n", "\"data\"", ",", "\n", "help", "=", "\"colon separated path to data directories list, \\\n                            will be iterated upon during epochs in round-robin manner\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--sample-break-mode\"", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.masked_lm.MaskedLMModel.add_args": [[46, 147], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "fairseq.utils.get_available_activation_fns", "fairseq.utils.get_available_activation_fns"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_available_activation_fns", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_available_activation_fns"], ["default", "=", "\"complete\"", ",", "\n", "choices", "=", "[", "\"none\"", ",", "\"complete\"", ",", "\"complete_doc\"", ",", "\"eos\"", "]", ",", "\n", "help", "=", "'If omitted or \"none\", fills each sample with tokens-per-sample '", "\n", "'tokens. If set to \"complete\", splits samples only at the end '", "\n", "\"of sentence, but may include multiple sentences per sample. \"", "\n", "'\"complete_doc\" is similar but respects doc boundaries. '", "\n", "'If set to \"eos\", includes only one sentence per sample.'", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokens-per-sample\"", ",", "\n", "default", "=", "512", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"max number of total tokens over all segments \"", "\n", "\"per sample for BERT dataset\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-prob\"", ",", "\n", "default", "=", "0.15", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"probability of replacing a token with mask\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--leave-unmasked-prob\"", ",", "\n", "default", "=", "0.1", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"probability that a masked token is unmasked\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--random-token-prob\"", ",", "\n", "default", "=", "0.1", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"probability of replacing a token with a random token\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--freq-weighted-replacement\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"sample random replacement words based on word frequencies\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-whole-words\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"mask whole words; you may also want to set --bpe\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--shorten-method\"", ",", "\n", "default", "=", "\"none\"", ",", "\n", "choices", "=", "[", "\"none\"", ",", "\"truncate\"", ",", "\"random_crop\"", "]", ",", "\n", "help", "=", "\"if not none, shorten sequences that exceed --tokens-per-sample\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--shorten-data-split-list\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "help", "=", "\"comma-separated list of dataset splits to apply shortening to, \"", "\n", "'e.g., \"train,valid\" (default: all dataset splits)'", ",", "\n", ")", "\n", "\n", "", "def", "__init__", "(", "self", ",", "args", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "self", ".", "seed", "=", "args", ".", "seed", "\n", "\n", "# add mask token", "\n", "self", ".", "mask_idx", "=", "dictionary", ".", "add_symbol", "(", "\"<mask>\"", ")", "\n", "\n", "", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "paths", "=", "utils", ".", "split_paths", "(", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "dictionary", "=", "Dictionary", ".", "load", "(", "os", ".", "path", ".", "join", "(", "paths", "[", "0", "]", ",", "\"dict.txt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"dictionary: {} types\"", ".", "format", "(", "len", "(", "dictionary", ")", ")", ")", "\n", "return", "cls", "(", "args", ",", "dictionary", ")", "\n", "\n", "", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "1", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n        \"\"\"", "\n", "paths", "=", "utils", ".", "split_paths", "(", "self", ".", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "data_path", "=", "paths", "[", "(", "epoch", "-", "1", ")", "%", "len", "(", "paths", ")", "]", "\n", "split_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "split", ")", "\n", "\n", "dataset", "=", "data_utils", ".", "load_indexed_dataset", "(", "\n", "split_path", ",", "\n", "self", ".", "source_dictionary", ",", "\n", "self", ".", "args", ".", "dataset_impl", ",", "\n", "combine", "=", "combine", ",", "\n", ")", "\n", "if", "dataset", "is", "None", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "\n", "\"Dataset not found: {} ({})\"", ".", "format", "(", "split", ",", "split_path", ")", "\n", ")", "\n", "\n", "", "dataset", "=", "maybe_shorten_dataset", "(", "\n", "dataset", ",", "\n", "split", ",", "\n", "self", ".", "args", ".", "shorten_data_split_list", ",", "\n", "self", ".", "args", ".", "shorten_method", ",", "\n", "self", ".", "args", ".", "tokens_per_sample", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.masked_lm.MaskedLMModel.forward": [[149, 151], ["masked_lm.MaskedLMModel.encoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder"], [")", "\n", "\n", "# create continuous blocks of tokens", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.masked_lm.MaskedLMModel.max_positions": [[152, 154], ["None"], "methods", ["None"], ["dataset", "=", "TokenBlockDataset", "(", "\n", "dataset", ",", "\n", "dataset", ".", "sizes", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.masked_lm.MaskedLMModel.build_model": [[155, 168], ["masked_lm.base_architecture", "logger.info", "masked_lm.MaskedLMEncoder", "cls", "hasattr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["self", ".", "args", ".", "tokens_per_sample", "-", "1", ",", "# one less for <s>", "\n", "pad", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", "eos", "=", "self", ".", "source_dictionary", ".", "eos", "(", ")", ",", "\n", "break_mode", "=", "self", ".", "args", ".", "sample_break_mode", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"loaded {} blocks from: {}\"", ".", "format", "(", "len", "(", "dataset", ")", ",", "split_path", ")", ")", "\n", "\n", "# prepend beginning-of-sentence token (<s>, equiv. to [CLS] in BERT)", "\n", "dataset", "=", "PrependTokenDataset", "(", "dataset", ",", "self", ".", "source_dictionary", ".", "bos", "(", ")", ")", "\n", "\n", "# create masked input and targets", "\n", "mask_whole_words", "=", "(", "\n", "get_whole_word_mask", "(", "self", ".", "args", ",", "self", ".", "source_dictionary", ")", "\n", "if", "self", ".", "args", ".", "mask_whole_words", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.masked_lm.MaskedLMEncoder.__init__": [[175, 233], ["fairseq.models.FairseqEncoder.__init__", "dictionary.pad", "dictionary.__len__", "fairseq.modules.TransformerSentenceEncoder", "torch.Linear", "torch.Linear", "torch.Linear", "fairseq.utils.get_activation_fn", "torch.Linear", "torch.Linear", "torch.Linear", "fairseq.utils.get_activation_fn", "fairseq.modules.LayerNorm", "getattr", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.__len__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["pad_idx", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", "mask_idx", "=", "self", ".", "mask_idx", ",", "\n", "seed", "=", "self", ".", "args", ".", "seed", ",", "\n", "mask_prob", "=", "self", ".", "args", ".", "mask_prob", ",", "\n", "leave_unmasked_prob", "=", "self", ".", "args", ".", "leave_unmasked_prob", ",", "\n", "random_token_prob", "=", "self", ".", "args", ".", "random_token_prob", ",", "\n", "freq_weighted_replacement", "=", "self", ".", "args", ".", "freq_weighted_replacement", ",", "\n", "mask_whole_words", "=", "mask_whole_words", ",", "\n", ")", "\n", "\n", "with", "data_utils", ".", "numpy_seed", "(", "self", ".", "args", ".", "seed", "+", "epoch", ")", ":", "\n", "            ", "shuffle", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "src_dataset", ")", ")", "\n", "\n", "", "self", ".", "datasets", "[", "split", "]", "=", "SortDataset", "(", "\n", "NestedDictionaryDataset", "(", "\n", "{", "\n", "\"id\"", ":", "IdDataset", "(", ")", ",", "\n", "\"net_input\"", ":", "{", "\n", "\"src_tokens\"", ":", "RightPadDataset", "(", "\n", "src_dataset", ",", "\n", "pad_idx", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", ")", ",", "\n", "\"src_lengths\"", ":", "NumelDataset", "(", "src_dataset", ",", "reduce", "=", "False", ")", ",", "\n", "}", ",", "\n", "\"target\"", ":", "RightPadDataset", "(", "\n", "tgt_dataset", ",", "\n", "pad_idx", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", ")", ",", "\n", "\"nsentences\"", ":", "NumSamplesDataset", "(", ")", ",", "\n", "\"ntokens\"", ":", "NumelDataset", "(", "src_dataset", ",", "reduce", "=", "True", ")", ",", "\n", "}", ",", "\n", "sizes", "=", "[", "src_dataset", ".", "sizes", "]", ",", "\n", ")", ",", "\n", "sort_order", "=", "[", "\n", "shuffle", ",", "\n", "src_dataset", ".", "sizes", ",", "\n", "]", ",", "\n", ")", "\n", "\n", "", "def", "build_dataset_for_inference", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "sort", "=", "True", ")", ":", "\n", "        ", "src_dataset", "=", "RightPadDataset", "(", "\n", "TokenBlockDataset", "(", "\n", "src_tokens", ",", "\n", "src_lengths", ",", "\n", "self", ".", "args", ".", "tokens_per_sample", "-", "1", ",", "# one less for <s>", "\n", "pad", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", "eos", "=", "self", ".", "source_dictionary", ".", "eos", "(", ")", ",", "\n", "break_mode", "=", "\"eos\"", ",", "\n", ")", ",", "\n", "pad_idx", "=", "self", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", ")", "\n", "src_dataset", "=", "PrependTokenDataset", "(", "src_dataset", ",", "self", ".", "source_dictionary", ".", "bos", "(", ")", ")", "\n", "src_dataset", "=", "NestedDictionaryDataset", "(", "\n", "{", "\n", "\"id\"", ":", "IdDataset", "(", ")", ",", "\n", "\"net_input\"", ":", "{", "\n", "\"src_tokens\"", ":", "src_dataset", ",", "\n", "\"src_lengths\"", ":", "NumelDataset", "(", "src_dataset", ",", "reduce", "=", "False", ")", ",", "\n", "}", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.masked_lm.MaskedLMEncoder.forward": [[235, 289], ["masked_lm.MaskedLMEncoder.sentence_encoder", "inner_states[].transpose", "masked_lm.MaskedLMEncoder.layer_norm", "masked_lm.MaskedLMEncoder.pooler_activation", "masked_lm.MaskedLMEncoder.activation_fn", "masked_lm.MaskedLMEncoder.masked_lm_pooler", "hasattr", "torch.linear", "torch.linear", "torch.linear", "masked_lm.MaskedLMEncoder.sentence_projection_layer", "masked_lm.MaskedLMEncoder.lm_head_transform_weight", "masked_lm.MaskedLMEncoder.embed_out"], "methods", ["None"], ["sizes", "=", "src_lengths", ",", "\n", ")", "\n", "if", "sort", ":", "\n", "            ", "src_dataset", "=", "SortDataset", "(", "src_dataset", ",", "sort_order", "=", "[", "src_lengths", "]", ")", "\n", "", "return", "src_dataset", "\n", "\n", "", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", "\n", "\n", "", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.models.masked_lm.MaskedLMEncoder.max_positions": [[291, 294], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.models.masked_lm.MaskedLMEncoder.upgrade_state_dict_named": [[295, 311], ["isinstance", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "list", "state_dict.keys"], "methods", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.models.masked_lm.base_architecture": [[313, 341], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], []], "home.repos.pwc.inspect_result.reneeye_const.models.masked_lm.bert_base_architecture": [[343, 369], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "masked_lm.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], []], "home.repos.pwc.inspect_result.reneeye_const.models.masked_lm.bert_large_architecture": [[371, 378], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "masked_lm.bert_base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.masked_lm.bert_base_architecture"], []], "home.repos.pwc.inspect_result.reneeye_const.models.masked_lm.xlm_architecture": [[380, 404], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "masked_lm.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], []], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.__init__": [[34, 37], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_is_generation_fast", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.add_args": [[38, 45], ["getattr", "fairseq.dataclass.utils.gen_parser_from_dataclass", "getattr."], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.gen_parser_from_dataclass"], ["", "@", "classmethod", "\n", "def", "add_args", "(", "cls", ",", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "dc", "=", "getattr", "(", "cls", ",", "\"__dataclass\"", ",", "None", ")", "\n", "if", "dc", "is", "not", "None", ":", "\n", "# do not set defaults so that settings defaults from various architectures still works", "\n", "            ", "gen_parser_from_dataclass", "(", "parser", ",", "dc", "(", ")", ",", "delete_default", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.build_model": [[46, 50], ["NotImplementedError"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "raise", "NotImplementedError", "(", "\"Model must implement the build_model method\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.get_targets": [[51, 54], ["None"], "methods", ["None"], ["", "def", "get_targets", "(", "self", ",", "sample", ",", "net_output", ")", ":", "\n", "        ", "\"\"\"Get targets from either the sample or the net's output.\"\"\"", "\n", "return", "sample", "[", "\"target\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.get_normalized_probs": [[55, 63], ["fairseq_model.BaseFairseqModel.get_normalized_probs_scriptable"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.get_normalized_probs_scriptable"], ["", "def", "get_normalized_probs", "(", "\n", "self", ",", "\n", "net_output", ":", "Tuple", "[", "Tensor", ",", "Optional", "[", "Dict", "[", "str", ",", "List", "[", "Optional", "[", "Tensor", "]", "]", "]", "]", "]", ",", "\n", "log_probs", ":", "bool", ",", "\n", "sample", ":", "Optional", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"", "\n", "return", "self", ".", "get_normalized_probs_scriptable", "(", "net_output", ",", "log_probs", ",", "sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.get_normalized_probs_scriptable": [[68, 86], ["hasattr", "fairseq_model.BaseFairseqModel.decoder.get_normalized_probs", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "net_output.float", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.get_normalized_probs", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax"], ["", "def", "get_normalized_probs_scriptable", "(", "\n", "self", ",", "\n", "net_output", ":", "Tuple", "[", "Tensor", ",", "Optional", "[", "Dict", "[", "str", ",", "List", "[", "Optional", "[", "Tensor", "]", "]", "]", "]", "]", ",", "\n", "log_probs", ":", "bool", ",", "\n", "sample", ":", "Optional", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Scriptable helper function for get_normalized_probs in ~BaseFairseqModel\"\"\"", "\n", "if", "hasattr", "(", "self", ",", "\"decoder\"", ")", ":", "\n", "            ", "return", "self", ".", "decoder", ".", "get_normalized_probs", "(", "net_output", ",", "log_probs", ",", "sample", ")", "\n", "", "elif", "torch", ".", "is_tensor", "(", "net_output", ")", ":", "\n", "# syntactic sugar for simple models which don't have a decoder", "\n", "# (e.g., the classification tutorial)", "\n", "            ", "logits", "=", "net_output", ".", "float", "(", ")", "\n", "if", "log_probs", ":", "\n", "                ", "return", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "return", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "", "", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.extract_features": [[87, 90], ["fairseq_model.BaseFairseqModel."], "methods", ["None"], ["", "def", "extract_features", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Similar to *forward* but only return features.\"\"\"", "\n", "return", "self", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.max_positions": [[91, 94], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the model.\"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.load_state_dict": [[95, 116], ["fairseq_model.BaseFairseqModel.upgrade_state_dict", "fairseq.checkpoint_utils.prune_state_dict", "super().load_state_dict", "logger.warn", "fairseq.dataclass.utils.convert_namespace_to_omegaconf"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_decoder.FairseqDecoder.upgrade_state_dict", "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.prune_state_dict", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.convert_namespace_to_omegaconf"], ["", "def", "load_state_dict", "(", "\n", "self", ",", "\n", "state_dict", ",", "\n", "strict", "=", "True", ",", "\n", "model_cfg", ":", "Optional", "[", "DictConfig", "]", "=", "None", ",", "\n", "args", ":", "Optional", "[", "Namespace", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Copies parameters and buffers from *state_dict* into this module and\n        its descendants.\n\n        Overrides the method in :class:`nn.Module`. Compared with that method\n        this additionally \"upgrades\" *state_dicts* from old checkpoints.\n        \"\"\"", "\n", "\n", "if", "model_cfg", "is", "None", "and", "args", "is", "not", "None", ":", "\n", "            ", "logger", ".", "warn", "(", "\"using 'args' is deprecated, please update your code to use dataclass config\"", ")", "\n", "model_cfg", "=", "convert_namespace_to_omegaconf", "(", "args", ")", ".", "model", "\n", "\n", "", "self", ".", "upgrade_state_dict", "(", "state_dict", ")", "\n", "new_state_dict", "=", "prune_state_dict", "(", "state_dict", ",", "model_cfg", ")", "\n", "return", "super", "(", ")", ".", "load_state_dict", "(", "new_state_dict", ",", "strict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.upgrade_state_dict": [[117, 120], ["fairseq_model.BaseFairseqModel.upgrade_state_dict_named"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.upgrade_state_dict_named"], ["", "def", "upgrade_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Upgrade old state dicts to work with newer code.\"\"\"", "\n", "self", ".", "upgrade_state_dict_named", "(", "state_dict", ",", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.upgrade_state_dict_named": [[121, 143], ["fairseq_model.BaseFairseqModel.upgrade_state_dict_named.do_upgrade"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "\"\"\"Upgrade old state dicts to work with newer code.\n\n        Args:\n            state_dict (dict): state dictionary to upgrade, in place\n            name (str): the state dict key corresponding to the current module\n        \"\"\"", "\n", "assert", "state_dict", "is", "not", "None", "\n", "\n", "def", "do_upgrade", "(", "m", ",", "prefix", ")", ":", "\n", "            ", "if", "len", "(", "prefix", ")", ">", "0", ":", "\n", "                ", "prefix", "+=", "\".\"", "\n", "\n", "", "for", "n", ",", "c", "in", "m", ".", "named_children", "(", ")", ":", "\n", "                ", "name", "=", "prefix", "+", "n", "\n", "if", "hasattr", "(", "c", ",", "\"upgrade_state_dict_named\"", ")", ":", "\n", "                    ", "c", ".", "upgrade_state_dict_named", "(", "state_dict", ",", "name", ")", "\n", "", "elif", "hasattr", "(", "c", ",", "\"upgrade_state_dict\"", ")", ":", "\n", "                    ", "c", ".", "upgrade_state_dict", "(", "state_dict", ")", "\n", "", "do_upgrade", "(", "c", ",", "name", ")", "\n", "\n", "", "", "do_upgrade", "(", "self", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.set_num_updates": [[144, 152], ["fairseq_model.BaseFairseqModel.apply", "hasattr", "m.set_num_updates"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.Wav2VecEncoder.set_num_updates"], ["", "def", "set_num_updates", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"State from trainer to pass along to model at every update.\"\"\"", "\n", "\n", "def", "_apply", "(", "m", ")", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "\"set_num_updates\"", ")", "and", "m", "!=", "self", ":", "\n", "                ", "m", ".", "set_num_updates", "(", "num_updates", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "_apply", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.prepare_for_inference_": [[153, 166], ["getattr", "getattr", "fairseq_model.BaseFairseqModel.make_generation_fast_", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.make_generation_fast_"], ["", "def", "prepare_for_inference_", "(", "self", ",", "cfg", ":", "DictConfig", ")", ":", "\n", "        ", "\"\"\"Prepare model for inference.\"\"\"", "\n", "kwargs", "=", "{", "}", "\n", "kwargs", "[", "\"beamable_mm_beam_size\"", "]", "=", "(", "\n", "None", "\n", "if", "getattr", "(", "cfg", ".", "generation", ",", "\"no_beamable_mm\"", ",", "False", ")", "\n", "else", "getattr", "(", "cfg", ".", "generation", ",", "\"beam\"", ",", "5", ")", "\n", ")", "\n", "kwargs", "[", "\"need_attn\"", "]", "=", "getattr", "(", "cfg", ".", "generation", ",", "\"print_alignment\"", ",", "False", ")", "\n", "if", "getattr", "(", "cfg", ".", "generation", ",", "\"retain_dropout\"", ",", "False", ")", ":", "\n", "            ", "kwargs", "[", "\"retain_dropout\"", "]", "=", "cfg", ".", "generation", ".", "retain_dropout", "\n", "kwargs", "[", "\"retain_dropout_modules\"", "]", "=", "cfg", ".", "generation", ".", "retain_dropout_modules", "\n", "", "self", ".", "make_generation_fast_", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.make_generation_fast_": [[167, 210], ["fairseq_model.BaseFairseqModel.apply", "fairseq_model.BaseFairseqModel.make_generation_fast_.apply_make_generation_fast_"], "methods", ["None"], ["", "def", "make_generation_fast_", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Legacy entry point to optimize model for faster generation.\n        Prefer prepare_for_inference_.\n        \"\"\"", "\n", "if", "self", ".", "_is_generation_fast", ":", "\n", "            ", "return", "# only apply once", "\n", "", "self", ".", "_is_generation_fast", "=", "True", "\n", "\n", "# remove weight norm from all modules in the network", "\n", "def", "apply_remove_weight_norm", "(", "module", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "nn", ".", "utils", ".", "remove_weight_norm", "(", "module", ")", "\n", "", "except", "(", "AttributeError", ",", "ValueError", ")", ":", "# this module didn't have weight norm", "\n", "                ", "return", "\n", "\n", "", "", "self", ".", "apply", "(", "apply_remove_weight_norm", ")", "\n", "\n", "def", "apply_make_generation_fast_", "(", "module", ",", "prefix", ")", ":", "\n", "            ", "if", "len", "(", "prefix", ")", ">", "0", ":", "\n", "                ", "prefix", "+=", "\".\"", "\n", "\n", "", "base_func", "=", "BaseFairseqModel", ".", "make_generation_fast_", "\n", "for", "n", ",", "m", "in", "module", ".", "named_modules", "(", ")", ":", "\n", "                ", "if", "(", "\n", "m", "!=", "self", "\n", "and", "hasattr", "(", "m", ",", "\"make_generation_fast_\"", ")", "\n", "# don't call this implementation again, e.g., if", "\n", "# children modules also inherit from BaseFairseqModel", "\n", "and", "m", ".", "make_generation_fast_", ".", "__func__", "is", "not", "base_func", "\n", ")", ":", "\n", "                    ", "name", "=", "prefix", "+", "n", "\n", "m", ".", "make_generation_fast_", "(", "name", "=", "name", ",", "**", "kwargs", ")", "\n", "\n", "", "", "", "apply_make_generation_fast_", "(", "self", ",", "\"\"", ")", "\n", "\n", "def", "train", "(", "mode", "=", "True", ")", ":", "\n", "            ", "if", "mode", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"cannot train after make_generation_fast\"", ")", "\n", "\n", "# this model should no longer be used for training", "\n", "", "", "self", ".", "eval", "(", ")", "\n", "self", ".", "train", "=", "train", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.prepare_for_onnx_export_": [[211, 225], ["set", "fairseq_model.BaseFairseqModel.apply", "hasattr", "set.add", "module.prepare_for_onnx_export_"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.prepare_for_onnx_export_"], ["", "def", "prepare_for_onnx_export_", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Make model exportable via ONNX trace.\"\"\"", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "def", "apply_prepare_for_onnx_export_", "(", "module", ")", ":", "\n", "            ", "if", "(", "\n", "module", "!=", "self", "\n", "and", "hasattr", "(", "module", ",", "\"prepare_for_onnx_export_\"", ")", "\n", "and", "module", "not", "in", "seen", "\n", ")", ":", "\n", "                ", "seen", ".", "add", "(", "module", ")", "\n", "module", ".", "prepare_for_onnx_export_", "(", "**", "kwargs", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "apply_prepare_for_onnx_export_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.prepare_for_tpu_": [[226, 240], ["set", "fairseq_model.BaseFairseqModel.apply", "hasattr", "set.add", "module.prepare_for_tpu_"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.prepare_for_tpu_"], ["", "def", "prepare_for_tpu_", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Optionally modify model for use on TPUs.\"\"\"", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "def", "apply_prepare_for_tpu_", "(", "module", ")", ":", "\n", "            ", "if", "(", "\n", "module", "!=", "self", "\n", "and", "hasattr", "(", "module", ",", "\"prepare_for_tpu_\"", ")", "\n", "and", "module", "not", "in", "seen", "\n", ")", ":", "\n", "                ", "seen", ".", "add", "(", "module", ")", "\n", "module", ".", "prepare_for_tpu_", "(", "**", "kwargs", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "apply_prepare_for_tpu_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.from_pretrained": [[241, 281], ["hub_utils.from_pretrained", "logger.info", "hub_utils.GeneratorHubInterface", "cls.hub_models"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model_xlmr.XLMRModel.from_pretrained", "home.repos.pwc.inspect_result.reneeye_const.roberta.model_xlmr.XLMRModel.hub_models"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "\n", "cls", ",", "\n", "model_name_or_path", ",", "\n", "checkpoint_file", "=", "\"model.pt\"", ",", "\n", "data_name_or_path", "=", "\".\"", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Load a :class:`~fairseq.models.FairseqModel` from a pre-trained model\n        file. Downloads and caches the pre-trained model file if needed.\n\n        The base implementation returns a\n        :class:`~fairseq.hub_utils.GeneratorHubInterface`, which can be used to\n        generate translations or sample from language models. The underlying\n        :class:`~fairseq.models.FairseqModel` can be accessed via the\n        *generator.models* attribute.\n\n        Other models may override this to implement custom hub interfaces.\n\n        Args:\n            model_name_or_path (str): either the name of a pre-trained model to\n                load or a path/URL to a pre-trained model state dict\n            checkpoint_file (str, optional): colon-separated list of checkpoint\n                files in the model archive to ensemble (default: 'model.pt')\n            data_name_or_path (str, optional): point args.data to the archive\n                at the given path/URL. Can start with '.' or './' to reuse the\n                model archive path.\n        \"\"\"", "\n", "from", "fairseq", "import", "hub_utils", "\n", "\n", "x", "=", "hub_utils", ".", "from_pretrained", "(", "\n", "model_name_or_path", ",", "\n", "checkpoint_file", ",", "\n", "data_name_or_path", ",", "\n", "archive_map", "=", "cls", ".", "hub_models", "(", ")", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "logger", ".", "info", "(", "x", "[", "\"args\"", "]", ")", "\n", "return", "hub_utils", ".", "GeneratorHubInterface", "(", "x", "[", "\"args\"", "]", ",", "x", "[", "\"task\"", "]", ",", "x", "[", "\"models\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.hub_models": [[282, 285], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "hub_models", "(", "cls", ")", ":", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqEncoderDecoderModel.__init__": [[295, 302], ["fairseq_model.BaseFairseqModel.__init__", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "assert", "isinstance", "(", "self", ".", "encoder", ",", "FairseqEncoder", ")", "\n", "assert", "isinstance", "(", "self", ".", "decoder", ",", "FairseqDecoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqEncoderDecoderModel.forward": [[303, 331], ["fairseq_model.FairseqEncoderDecoderModel.encoder", "fairseq_model.FairseqEncoderDecoderModel.decoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Run the forward pass for an encoder-decoder model.\n\n        First feed a batch of source tokens through the encoder. Then, feed the\n        encoder output and previous decoder outputs (i.e., teacher forcing) to\n        the decoder to produce the next outputs::\n\n            encoder_out = self.encoder(src_tokens, src_lengths)\n            return self.decoder(prev_output_tokens, encoder_out)\n\n        Args:\n            src_tokens (LongTensor): tokens in the source language of shape\n                `(batch, src_len)`\n            src_lengths (LongTensor): source sentence lengths of shape `(batch)`\n            prev_output_tokens (LongTensor): previous decoder outputs of shape\n                `(batch, tgt_len)`, for teacher forcing\n\n        Returns:\n            tuple:\n                - the decoder's output of shape `(batch, tgt_len, vocab)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "encoder_out", "=", "self", ".", "encoder", "(", "src_tokens", ",", "src_lengths", "=", "src_lengths", ",", "**", "kwargs", ")", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "\n", "prev_output_tokens", ",", "encoder_out", "=", "encoder_out", ",", "**", "kwargs", "\n", ")", "\n", "return", "decoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqEncoderDecoderModel.forward_decoder": [[332, 334], ["fairseq_model.FairseqEncoderDecoderModel.decoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward_decoder", "(", "self", ",", "prev_output_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "decoder", "(", "prev_output_tokens", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqEncoderDecoderModel.extract_features": [[335, 349], ["fairseq_model.FairseqEncoderDecoderModel.encoder", "fairseq_model.FairseqEncoderDecoderModel.decoder.extract_features"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features"], ["", "def", "extract_features", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Similar to *forward* but only return features.\n\n        Returns:\n            tuple:\n                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "encoder_out", "=", "self", ".", "encoder", "(", "src_tokens", ",", "src_lengths", "=", "src_lengths", ",", "**", "kwargs", ")", "\n", "features", "=", "self", ".", "decoder", ".", "extract_features", "(", "\n", "prev_output_tokens", ",", "encoder_out", "=", "encoder_out", ",", "**", "kwargs", "\n", ")", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqEncoderDecoderModel.output_layer": [[350, 353], ["fairseq_model.FairseqEncoderDecoderModel.decoder.output_layer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.output_layer"], ["", "def", "output_layer", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Project features to the default output size (typically vocabulary size).\"\"\"", "\n", "return", "self", ".", "decoder", ".", "output_layer", "(", "features", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqEncoderDecoderModel.max_positions": [[354, 357], ["fairseq_model.FairseqEncoderDecoderModel.encoder.max_positions", "fairseq_model.FairseqEncoderDecoderModel.decoder.max_positions"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the model.\"\"\"", "\n", "return", "(", "self", ".", "encoder", ".", "max_positions", "(", ")", ",", "self", ".", "decoder", ".", "max_positions", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqEncoderDecoderModel.max_decoder_positions": [[358, 361], ["fairseq_model.FairseqEncoderDecoderModel.decoder.max_positions"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions"], ["", "def", "max_decoder_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the decoder.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "max_positions", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqModel.__init__": [[364, 370], ["fairseq_model.FairseqEncoderDecoderModel.__init__", "fairseq.utils.deprecation_warning"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.deprecation_warning"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "utils", ".", "deprecation_warning", "(", "\n", "\"FairseqModel is deprecated, please use FairseqEncoderDecoderModel \"", "\n", "\"or BaseFairseqModel instead\"", ",", "\n", "stacklevel", "=", "4", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.__init__": [[376, 388], ["fairseq_model.BaseFairseqModel.__init__", "list", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "encoders.keys", "decoders.keys", "encoders.keys", "isinstance", "isinstance", "fairseq_model.FairseqEncoderDecoderModel"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "encoders", ",", "decoders", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "encoders", ".", "keys", "(", ")", "==", "decoders", ".", "keys", "(", ")", "\n", "self", ".", "keys", "=", "list", "(", "encoders", ".", "keys", "(", ")", ")", "\n", "for", "key", "in", "self", ".", "keys", ":", "\n", "            ", "assert", "isinstance", "(", "encoders", "[", "key", "]", ",", "FairseqEncoder", ")", "\n", "assert", "isinstance", "(", "decoders", "[", "key", "]", ",", "FairseqDecoder", ")", "\n", "\n", "", "self", ".", "models", "=", "nn", ".", "ModuleDict", "(", "\n", "{", "\n", "key", ":", "FairseqEncoderDecoderModel", "(", "encoders", "[", "key", "]", ",", "decoders", "[", "key", "]", ")", "\n", "for", "key", "in", "self", ".", "keys", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.build_shared_embeddings": [[391, 420], ["any", "build_embedding", "ValueError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.build_embedding"], ["", "@", "staticmethod", "\n", "def", "build_shared_embeddings", "(", "\n", "dicts", ":", "Dict", "[", "str", ",", "Dictionary", "]", ",", "\n", "langs", ":", "List", "[", "str", "]", ",", "\n", "embed_dim", ":", "int", ",", "\n", "build_embedding", ":", "callable", ",", "\n", "pretrained_embed_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Helper function to build shared embeddings for a set of languages after\n        checking that all dicts corresponding to those languages are equivalent.\n\n        Args:\n            dicts: Dict of lang_id to its corresponding Dictionary\n            langs: languages that we want to share embeddings for\n            embed_dim: embedding dimension\n            build_embedding: callable function to actually build the embedding\n            pretrained_embed_path: Optional path to load pretrained embeddings\n        \"\"\"", "\n", "shared_dict", "=", "dicts", "[", "langs", "[", "0", "]", "]", "\n", "if", "any", "(", "dicts", "[", "lang", "]", "!=", "shared_dict", "for", "lang", "in", "langs", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"--share-*-embeddings requires a joined dictionary: \"", "\n", "\"--share-encoder-embeddings requires a joined source \"", "\n", "\"dictionary, --share-decoder-embeddings requires a joined \"", "\n", "\"target dictionary, and --share-all-embeddings requires a \"", "\n", "\"joint source + target dictionary.\"", "\n", ")", "\n", "", "return", "build_embedding", "(", "shared_dict", ",", "embed_dim", ",", "pretrained_embed_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.forward": [[421, 423], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.max_positions": [[424, 432], ["fairseq_model.FairseqMultiModel.models[].encoder.max_positions", "fairseq_model.FairseqMultiModel.models[].decoder.max_positions"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the model.\"\"\"", "\n", "return", "{", "\n", "key", ":", "(", "\n", "self", ".", "models", "[", "key", "]", ".", "encoder", ".", "max_positions", "(", ")", ",", "\n", "self", ".", "models", "[", "key", "]", ".", "decoder", ".", "max_positions", "(", ")", ",", "\n", ")", "\n", "for", "key", "in", "self", ".", "keys", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.max_decoder_positions": [[434, 437], ["min", "model.decoder.max_positions", "fairseq_model.FairseqMultiModel.models.values"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions"], ["", "def", "max_decoder_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the decoder.\"\"\"", "\n", "return", "min", "(", "model", ".", "decoder", ".", "max_positions", "(", ")", "for", "model", "in", "self", ".", "models", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder": [[438, 441], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "encoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "models", "[", "self", ".", "keys", "[", "0", "]", "]", ".", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder": [[442, 445], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "decoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "models", "[", "self", ".", "keys", "[", "0", "]", "]", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.forward_decoder": [[446, 448], ["fairseq_model.FairseqMultiModel.decoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward_decoder", "(", "self", ",", "prev_output_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "decoder", "(", "prev_output_tokens", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.load_state_dict": [[449, 470], ["fairseq_model.FairseqMultiModel.upgrade_state_dict", "fairseq.checkpoint_utils.prune_state_dict", "fairseq_model.BaseFairseqModel.load_state_dict", "logger.warn", "fairseq.dataclass.utils.convert_namespace_to_omegaconf"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_decoder.FairseqDecoder.upgrade_state_dict", "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.prune_state_dict", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.convert_namespace_to_omegaconf"], ["", "def", "load_state_dict", "(", "\n", "self", ",", "\n", "state_dict", ",", "\n", "strict", "=", "True", ",", "\n", "model_cfg", "=", "None", ",", "\n", "args", ":", "Optional", "[", "Namespace", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Copies parameters and buffers from *state_dict* into this module and\n        its descendants.\n\n        Overrides the method in :class:`nn.Module`. Compared with that method\n        this additionally \"upgrades\" *state_dicts* from old checkpoints.\n        \"\"\"", "\n", "\n", "if", "model_cfg", "is", "None", "and", "args", "is", "not", "None", ":", "\n", "            ", "logger", ".", "warn", "(", "\"using 'args' is deprecated, please update your code to use dataclass config\"", ")", "\n", "model_cfg", "=", "convert_namespace_to_omegaconf", "(", "args", ")", ".", "model", "\n", "\n", "", "self", ".", "upgrade_state_dict", "(", "state_dict", ")", "\n", "new_state_dict", "=", "prune_state_dict", "(", "state_dict", ",", "model_cfg", ")", "\n", "return", "super", "(", ")", ".", "load_state_dict", "(", "new_state_dict", ",", "strict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqLanguageModel.__init__": [[479, 483], ["fairseq_model.BaseFairseqModel.__init__", "isinstance"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "decoder", "=", "decoder", "\n", "assert", "isinstance", "(", "self", ".", "decoder", ",", "FairseqDecoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqLanguageModel.forward": [[484, 501], ["fairseq_model.FairseqLanguageModel.decoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Run the forward pass for a decoder-only model.\n\n        Feeds a batch of tokens through the decoder to predict the next tokens.\n\n        Args:\n            src_tokens (LongTensor): tokens on which to condition the decoder,\n                of shape `(batch, tgt_len)`\n            src_lengths (LongTensor): source sentence lengths of shape `(batch)`\n\n        Returns:\n            tuple:\n                - the decoder's output of shape `(batch, seq_len, vocab)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "return", "self", ".", "decoder", "(", "src_tokens", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqLanguageModel.forward_decoder": [[502, 504], ["fairseq_model.FairseqLanguageModel.decoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward_decoder", "(", "self", ",", "prev_output_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "decoder", "(", "prev_output_tokens", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqLanguageModel.extract_features": [[505, 515], ["fairseq_model.FairseqLanguageModel.decoder.extract_features"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features"], ["", "def", "extract_features", "(", "self", ",", "src_tokens", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Similar to *forward* but only return features.\n\n        Returns:\n            tuple:\n                - the decoder's features of shape `(batch, seq_len, embed_dim)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "return", "self", ".", "decoder", ".", "extract_features", "(", "src_tokens", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqLanguageModel.output_layer": [[516, 519], ["fairseq_model.FairseqLanguageModel.decoder.output_layer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.output_layer"], ["", "def", "output_layer", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Project features to the default output size (typically vocabulary size).\"\"\"", "\n", "return", "self", ".", "decoder", ".", "output_layer", "(", "features", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqLanguageModel.max_positions": [[520, 523], ["fairseq_model.FairseqLanguageModel.decoder.max_positions"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the model.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "max_positions", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqLanguageModel.max_decoder_positions": [[524, 527], ["fairseq_model.FairseqLanguageModel.decoder.max_positions"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions"], ["", "def", "max_decoder_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the decoder.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "max_positions", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqLanguageModel.supported_targets": [[528, 531], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supported_targets", "(", "self", ")", ":", "\n", "        ", "return", "{", "\"future\"", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqEncoderModel.__init__": [[540, 544], ["fairseq_model.BaseFairseqModel.__init__", "isinstance"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "assert", "isinstance", "(", "self", ".", "encoder", ",", "FairseqEncoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqEncoderModel.forward": [[545, 559], ["fairseq_model.FairseqEncoderModel.encoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Run the forward pass for a encoder-only model.\n\n        Feeds a batch of tokens through the encoder to generate features.\n\n        Args:\n            src_tokens (LongTensor): input tokens of shape `(batch, src_len)`\n            src_lengths (LongTensor): source sentence lengths of shape `(batch)`\n\n        Returns:\n            the encoder's output, typically of shape `(batch, src_len, features)`\n        \"\"\"", "\n", "return", "self", ".", "encoder", "(", "src_tokens", ",", "src_lengths", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqEncoderModel.get_normalized_probs": [[560, 570], ["torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "encoder_out.float", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax"], ["", "def", "get_normalized_probs", "(", "self", ",", "net_output", ",", "log_probs", ",", "sample", "=", "None", ")", ":", "\n", "        ", "\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"", "\n", "encoder_out", "=", "net_output", "[", "\"encoder_out\"", "]", "\n", "if", "torch", ".", "is_tensor", "(", "encoder_out", ")", ":", "\n", "            ", "logits", "=", "encoder_out", ".", "float", "(", ")", "\n", "if", "log_probs", ":", "\n", "                ", "return", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "return", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "", "", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqEncoderModel.max_positions": [[571, 574], ["fairseq_model.FairseqEncoderModel.encoder.max_positions"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the model.\"\"\"", "\n", "return", "self", ".", "encoder", ".", "max_positions", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_lm.TransformerLanguageModel.hub_models": [[170, 186], ["transformer_lm.TransformerLanguageModel.hub_models.moses_fastbpe"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "hub_models", "(", "cls", ")", ":", "\n", "        ", "def", "moses_fastbpe", "(", "path", ")", ":", "\n", "            ", "return", "{", "\"path\"", ":", "path", ",", "\"tokenizer\"", ":", "\"moses\"", ",", "\"bpe\"", ":", "\"fastbpe\"", "}", "\n", "\n", "", "return", "{", "\n", "\"transformer_lm.gbw.adaptive_huge\"", ":", "\"https://dl.fbaipublicfiles.com/fairseq/models/lm/adaptive_lm_gbw_huge.tar.bz2\"", ",", "\n", "\"transformer_lm.wiki103.adaptive\"", ":", "\"https://dl.fbaipublicfiles.com/fairseq/models/lm/adaptive_lm_wiki103.v2.tar.bz2\"", ",", "\n", "\"transformer_lm.wmt19.en\"", ":", "moses_fastbpe", "(", "\n", "\"https://dl.fbaipublicfiles.com/fairseq/models/lm/wmt19.en.tar.bz2\"", "\n", ")", ",", "\n", "\"transformer_lm.wmt19.de\"", ":", "moses_fastbpe", "(", "\n", "\"https://dl.fbaipublicfiles.com/fairseq/models/lm/wmt19.de.tar.bz2\"", "\n", ")", ",", "\n", "\"transformer_lm.wmt19.ru\"", ":", "moses_fastbpe", "(", "\n", "\"https://dl.fbaipublicfiles.com/fairseq/models/lm/wmt19.ru.tar.bz2\"", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_lm.TransformerLanguageModel.__init__": [[189, 191], ["fairseq.models.FairseqLanguageModel.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["", "def", "__init__", "(", "self", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_lm.TransformerLanguageModel.build_model": [[192, 245], ["transformer_lm.base_lm_architecture", "fairseq.models.transformer.TransformerDecoder", "cls", "len", "getattr", "getattr", "fairseq.modules.CharacterTokenEmbedder", "args.decoder_layers_to_keep.split", "eval", "fairseq.modules.AdaptiveInput", "cls.build_embedding", "len", "task.source_dictionary.pad", "fairseq.options.eval_str_list"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.lightconv_lm.base_lm_architecture", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.build_embedding", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.eval_str_list"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "\n", "# make sure all arguments are present in older models", "\n", "base_lm_architecture", "(", "args", ")", "\n", "\n", "if", "args", ".", "decoder_layers_to_keep", ":", "\n", "            ", "args", ".", "decoder_layers", "=", "len", "(", "args", ".", "decoder_layers_to_keep", ".", "split", "(", "\",\"", ")", ")", "\n", "\n", "", "if", "getattr", "(", "args", ",", "\"max_target_positions\"", ",", "None", ")", "is", "None", ":", "\n", "            ", "args", ".", "max_target_positions", "=", "getattr", "(", "\n", "args", ",", "\"tokens_per_sample\"", ",", "DEFAULT_MAX_TARGET_POSITIONS", "\n", ")", "\n", "\n", "", "if", "args", ".", "character_embeddings", ":", "\n", "            ", "embed_tokens", "=", "CharacterTokenEmbedder", "(", "\n", "task", ".", "source_dictionary", ",", "\n", "eval", "(", "args", ".", "character_filters", ")", ",", "\n", "args", ".", "character_embedding_dim", ",", "\n", "args", ".", "decoder_embed_dim", ",", "\n", "args", ".", "char_embedder_highway_layers", ",", "\n", ")", "\n", "", "elif", "args", ".", "adaptive_input", ":", "\n", "            ", "embed_tokens", "=", "AdaptiveInput", "(", "\n", "len", "(", "task", ".", "source_dictionary", ")", ",", "\n", "task", ".", "source_dictionary", ".", "pad", "(", ")", ",", "\n", "args", ".", "decoder_input_dim", ",", "\n", "args", ".", "adaptive_input_factor", ",", "\n", "args", ".", "decoder_embed_dim", ",", "\n", "options", ".", "eval_str_list", "(", "args", ".", "adaptive_input_cutoff", ",", "type", "=", "int", ")", ",", "\n", "args", ".", "quant_noise_pq", ",", "\n", "args", ".", "quant_noise_pq_block_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "embed_tokens", "=", "cls", ".", "build_embedding", "(", "\n", "args", ",", "task", ".", "source_dictionary", ",", "args", ".", "decoder_input_dim", "\n", ")", "\n", "\n", "", "if", "args", ".", "tie_adaptive_weights", ":", "\n", "            ", "assert", "args", ".", "adaptive_input", "\n", "assert", "args", ".", "adaptive_input_factor", "==", "args", ".", "adaptive_softmax_factor", "\n", "assert", "(", "\n", "args", ".", "adaptive_softmax_cutoff", "==", "args", ".", "adaptive_input_cutoff", "\n", ")", ",", "\"{} != {}\"", ".", "format", "(", "\n", "args", ".", "adaptive_softmax_cutoff", ",", "args", ".", "adaptive_input_cutoff", "\n", ")", "\n", "assert", "args", ".", "decoder_input_dim", "==", "args", ".", "decoder_output_dim", "\n", "\n", "", "decoder", "=", "TransformerDecoder", "(", "\n", "args", ",", "task", ".", "target_dictionary", ",", "embed_tokens", ",", "no_encoder_attn", "=", "True", "\n", ")", "\n", "return", "cls", "(", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_lm.TransformerLanguageModel.build_embedding": [[246, 250], ["fairseq.models.transformer.Embedding", "len", "dictionary.pad"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["", "@", "classmethod", "\n", "def", "build_embedding", "(", "cls", ",", "args", ",", "dictionary", ",", "embed_dim", ",", "path", "=", "None", ")", ":", "\n", "        ", "embed_tokens", "=", "Embedding", "(", "len", "(", "dictionary", ")", ",", "embed_dim", ",", "dictionary", ".", "pad", "(", ")", ")", "\n", "return", "embed_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_lm.base_lm_architecture": [[91, 149], ["hasattr", "hasattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["None"], [")", "\n", "character_filters", ":", "str", "=", "field", "(", "\n", "default", "=", "\"[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]\"", ",", "\n", "metadata", "=", "{", "\"help\"", ":", "\"size of character embeddings\"", "}", ",", "\n", ")", "\n", "character_embedding_dim", ":", "int", "=", "field", "(", "\n", "default", "=", "4", ",", "metadata", "=", "{", "\"help\"", ":", "\"size of character embeddings\"", "}", "\n", ")", "\n", "char_embedder_highway_layers", ":", "int", "=", "field", "(", "\n", "default", "=", "2", ",", "\n", "metadata", "=", "{", "\"help\"", ":", "\"number of highway layers for character token embeddder\"", "}", ",", "\n", ")", "\n", "adaptive_input", ":", "bool", "=", "field", "(", "\n", "default", "=", "False", ",", "metadata", "=", "{", "\"help\"", ":", "\"if set, uses adaptive input\"", "}", "\n", ")", "\n", "adaptive_input_factor", ":", "float", "=", "field", "(", "\n", "default", "=", "4", ",", "metadata", "=", "{", "\"help\"", ":", "\"adaptive input factor\"", "}", "\n", ")", "\n", "adaptive_input_cutoff", ":", "Optional", "[", "str", "]", "=", "field", "(", "\n", "default", "=", "None", ",", "\n", "metadata", "=", "{", "\"help\"", ":", "\"comma separated list of adaptive input cutoff points.\"", "}", ",", "\n", ")", "\n", "tie_adaptive_weights", ":", "bool", "=", "field", "(", "\n", "default", "=", "False", ",", "\n", "metadata", "=", "{", "\n", "\"help\"", ":", "\"if set, ties the weights of adaptive softmax and adaptive input\"", "\n", "}", ",", "\n", ")", "\n", "tie_adaptive_proj", ":", "bool", "=", "field", "(", "\n", "default", "=", "False", ",", "\n", "metadata", "=", "{", "\n", "\"help\"", ":", "\"if set, ties the projection weights of adaptive softmax and adaptive input\"", "\n", "}", ",", "\n", ")", "\n", "decoder_learned_pos", ":", "bool", "=", "field", "(", "\n", "default", "=", "False", ",", "\n", "metadata", "=", "{", "\"help\"", ":", "\"use learned positional embeddings in the decoder\"", "}", ",", "\n", ")", "\n", "decoder_layerdrop", ":", "float", "=", "field", "(", "\n", "default", "=", "0.0", ",", "metadata", "=", "{", "\"help\"", ":", "\"LayerDrop probability for decoder\"", "}", "\n", ")", "\n", "decoder_layers_to_keep", ":", "Optional", "[", "str", "]", "=", "field", "(", "\n", "default", "=", "None", ",", "\n", "metadata", "=", "{", "\n", "\"help\"", ":", "\"which layers to *keep* when pruning as a comma-separated list\"", "\n", "}", ",", "\n", ")", "\n", "layernorm_embedding", ":", "bool", "=", "field", "(", "\n", "default", "=", "False", ",", "metadata", "=", "{", "\"help\"", ":", "\"add layernorm to embedding\"", "}", "\n", ")", "\n", "no_scale_embedding", ":", "bool", "=", "field", "(", "\n", "default", "=", "False", ",", "metadata", "=", "{", "\"help\"", ":", "\"if True, dont scale embeddings\"", "}", "\n", ")", "\n", "checkpoint_activations", ":", "bool", "=", "field", "(", "\n", "default", "=", "False", ",", "metadata", "=", "{", "\"help\"", ":", "\"checkpoint activations at each layer\"", "}", "\n", ")", "\n", "quant_noise_pq", ":", "float", "=", "field", "(", "\n", "default", "=", "0.0", ",", "\n", "metadata", "=", "{", "\"help\"", ":", "\"iterative PQ quantization noise at training time\"", "}", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_lm.transformer_lm_big": [[312, 319], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "transformer_lm.base_lm_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.lightconv_lm.base_lm_architecture"], ["", "@", "register_model_architecture", "(", "\"transformer_lm\"", ",", "\"transformer_lm_big\"", ")", "\n", "def", "transformer_lm_big", "(", "args", ")", ":", "\n", "    ", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "12", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "1024", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "4096", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "16", ")", "\n", "base_lm_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_lm.transformer_lm_baevski_wiki103": [[321, 339], ["fairseq.models.register_model_architecture", "fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "transformer_lm.transformer_lm_big"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.transformer_lm.transformer_lm_big"], ["", "@", "register_model_architecture", "(", "\"transformer_lm\"", ",", "\"transformer_lm_wiki103\"", ")", "\n", "@", "register_model_architecture", "(", "\"transformer_lm\"", ",", "\"transformer_lm_baevski_wiki103\"", ")", "\n", "def", "transformer_lm_baevski_wiki103", "(", "args", ")", ":", "\n", "    ", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "16", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.3", ")", "\n", "args", ".", "adaptive_input", "=", "getattr", "(", "args", ",", "\"adaptive_input\"", ",", "True", ")", "\n", "args", ".", "tie_adaptive_weights", "=", "getattr", "(", "args", ",", "\"tie_adaptive_weights\"", ",", "True", ")", "\n", "args", ".", "adaptive_input_cutoff", "=", "getattr", "(", "args", ",", "\"adaptive_input_cutoff\"", ",", "\"20000,60000\"", ")", "\n", "args", ".", "adaptive_softmax_cutoff", "=", "getattr", "(", "\n", "args", ",", "\"adaptive_softmax_cutoff\"", ",", "\"20000,60000\"", "\n", ")", "\n", "args", ".", "adaptive_softmax_dropout", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_dropout\"", ",", "0.2", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.1", ")", "\n", "args", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "0.1", ")", "\n", "args", ".", "no_decoder_final_norm", "=", "getattr", "(", "args", ",", "\"no_decoder_final_norm\"", ",", "True", ")", "\n", "args", ".", "tie_adaptive_proj", "=", "getattr", "(", "args", ",", "\"tie_adaptive_proj\"", ",", "True", ")", "\n", "transformer_lm_big", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_lm.transformer_lm_baevski_gbw": [[341, 349], ["fairseq.models.register_model_architecture", "fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "transformer_lm.transformer_lm_big"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.transformer_lm.transformer_lm_big"], ["", "@", "register_model_architecture", "(", "\"transformer_lm\"", ",", "\"transformer_lm_gbw\"", ")", "\n", "@", "register_model_architecture", "(", "\"transformer_lm\"", ",", "\"transformer_lm_baevski_gbw\"", ")", "\n", "def", "transformer_lm_baevski_gbw", "(", "args", ")", ":", "\n", "    ", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.1", ")", "\n", "args", ".", "no_decoder_final_norm", "=", "getattr", "(", "args", ",", "\"no_decoder_final_norm\"", ",", "True", ")", "\n", "transformer_lm_big", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_lm.transformer_lm_gpt": [[351, 361], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "transformer_lm.base_lm_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.lightconv_lm.base_lm_architecture"], ["", "@", "register_model_architecture", "(", "\"transformer_lm\"", ",", "\"transformer_lm_gpt\"", ")", "\n", "def", "transformer_lm_gpt", "(", "args", ")", ":", "\n", "    ", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "768", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "3072", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "12", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "12", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.1", ")", "\n", "args", ".", "activation_fn", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"gelu\"", ")", "\n", "base_lm_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_lm.transformer_lm_gpt2_small": [[363, 373], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "transformer_lm.base_lm_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.lightconv_lm.base_lm_architecture"], ["", "@", "register_model_architecture", "(", "\"transformer_lm\"", ",", "\"transformer_lm_gpt2_small\"", ")", "\n", "def", "transformer_lm_gpt2_small", "(", "args", ")", ":", "\n", "    ", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "1024", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "4096", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "24", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "16", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.1", ")", "\n", "args", ".", "activation_fn", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"gelu\"", ")", "\n", "base_lm_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_lm.transformer_lm_gpt2_medium": [[375, 385], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "transformer_lm.base_lm_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.lightconv_lm.base_lm_architecture"], ["", "@", "register_model_architecture", "(", "\"transformer_lm\"", ",", "\"transformer_lm_gpt2_medium\"", ")", "\n", "def", "transformer_lm_gpt2_medium", "(", "args", ")", ":", "\n", "    ", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "1280", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "5120", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "36", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "20", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.1", ")", "\n", "args", ".", "activation_fn", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"gelu\"", ")", "\n", "base_lm_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_lm.transformer_lm_gpt2_big": [[387, 397], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "transformer_lm.base_lm_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.lightconv_lm.base_lm_architecture"], ["", "@", "register_model_architecture", "(", "\"transformer_lm\"", ",", "\"transformer_lm_gpt2_big\"", ")", "\n", "def", "transformer_lm_gpt2_big", "(", "args", ")", ":", "\n", "    ", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "1600", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "6400", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "48", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "25", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.1", ")", "\n", "args", ".", "activation_fn", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"gelu\"", ")", "\n", "base_lm_architecture", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.models.__init__.build_model": [[53, 87], ["model.build_model", "getattr", "getattr", "next", "isinstance", "len", "iter", "Exception", "fairseq.dataclass.utils.populate_dataclass", "fairseq.dataclass.utils.merge_with_parent", "dc", "dc"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.populate_dataclass", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.merge_with_parent"], []], "home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model": [[89, 138], ["ValueError", "issubclass", "ValueError", "ValueError", "hydra.core.config_store.ConfigStore.instance", "dataclass", "ConfigStore.instance.store", "__init__.register_model_architecture", "issubclass"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], []], "home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture": [[140, 186], ["ARCH_MODEL_INV_REGISTRY.setdefault().append", "ValueError", "ValueError", "callable", "ValueError", "ARCH_MODEL_INV_REGISTRY.setdefault"], "function", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.models.composite_encoder.CompositeEncoder.__init__": [[20, 25], ["fairseq_encoder.FairseqEncoder.__init__", "composite_encoder.CompositeEncoder.add_module", "next", "iter", "encoders.values"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "encoders", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "next", "(", "iter", "(", "encoders", ".", "values", "(", ")", ")", ")", ".", "dictionary", ")", "\n", "self", ".", "encoders", "=", "encoders", "\n", "for", "key", "in", "self", ".", "encoders", ":", "\n", "            ", "self", ".", "add_module", "(", "key", ",", "self", ".", "encoders", "[", "key", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.composite_encoder.CompositeEncoder.forward": [[26, 42], ["None"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            src_tokens (LongTensor): tokens in the source language of shape\n                `(batch, src_len)`\n            src_lengths (LongTensor): lengths of each source sentence of shape\n                `(batch)`\n\n        Returns:\n            dict:\n                the outputs from each Encoder\n        \"\"\"", "\n", "encoder_out", "=", "{", "}", "\n", "for", "key", "in", "self", ".", "encoders", ":", "\n", "            ", "encoder_out", "[", "key", "]", "=", "self", ".", "encoders", "[", "key", "]", "(", "src_tokens", ",", "src_lengths", ")", "\n", "", "return", "encoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.composite_encoder.CompositeEncoder.reorder_encoder_out": [[43, 50], ["composite_encoder.CompositeEncoder.encoders[].reorder_encoder_out"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerEncoder.reorder_encoder_out"], ["", "def", "reorder_encoder_out", "(", "self", ",", "encoder_out", ",", "new_order", ")", ":", "\n", "        ", "\"\"\"Reorder encoder output according to new_order.\"\"\"", "\n", "for", "key", "in", "self", ".", "encoders", ":", "\n", "            ", "encoder_out", "[", "key", "]", "=", "self", ".", "encoders", "[", "key", "]", ".", "reorder_encoder_out", "(", "\n", "encoder_out", "[", "key", "]", ",", "new_order", "\n", ")", "\n", "", "return", "encoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.composite_encoder.CompositeEncoder.max_positions": [[51, 53], ["min", "composite_encoder.CompositeEncoder.encoders[].max_positions"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "return", "min", "(", "self", ".", "encoders", "[", "key", "]", ".", "max_positions", "(", ")", "for", "key", "in", "self", ".", "encoders", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.composite_encoder.CompositeEncoder.upgrade_state_dict": [[54, 58], ["composite_encoder.CompositeEncoder.encoders[].upgrade_state_dict"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_decoder.FairseqDecoder.upgrade_state_dict"], ["", "def", "upgrade_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "for", "key", "in", "self", ".", "encoders", ":", "\n", "            ", "self", ".", "encoders", "[", "key", "]", ".", "upgrade_state_dict", "(", "state_dict", ")", "\n", "", "return", "state_dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_decoder.FairseqDecoder.__init__": [[16, 20], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_decoder.FairseqDecoder.forward": [[21, 39], ["fairseq_decoder.FairseqDecoder.extract_features", "fairseq_decoder.FairseqDecoder.output_layer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.output_layer"], ["", "def", "forward", "(", "self", ",", "prev_output_tokens", ",", "encoder_out", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            prev_output_tokens (LongTensor): shifted output tokens of shape\n                `(batch, tgt_len)`, for teacher forcing\n            encoder_out (dict, optional): output from the encoder, used for\n                encoder-side attention\n\n        Returns:\n            tuple:\n                - the decoder's output of shape `(batch, tgt_len, vocab)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "x", ",", "extra", "=", "self", ".", "extract_features", "(", "\n", "prev_output_tokens", ",", "encoder_out", "=", "encoder_out", ",", "**", "kwargs", "\n", ")", "\n", "x", "=", "self", ".", "output_layer", "(", "x", ")", "\n", "return", "x", ",", "extra", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_decoder.FairseqDecoder.extract_features": [[40, 48], ["None"], "methods", ["None"], ["", "def", "extract_features", "(", "self", ",", "prev_output_tokens", ",", "encoder_out", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            tuple:\n                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_decoder.FairseqDecoder.output_layer": [[49, 57], ["None"], "methods", ["None"], ["", "def", "output_layer", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Project features to the default output size, e.g., vocabulary size.\n\n        Args:\n            features (Tensor): features returned by *extract_features*.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_decoder.FairseqDecoder.get_normalized_probs": [[58, 80], ["hasattr", "fairseq_decoder.FairseqDecoder.adaptive_softmax.get_log_prob", "fairseq.utils.log_softmax", "fairseq.utils.softmax", "fairseq_decoder.FairseqDecoder.exp_"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.adaptive_softmax.AdaptiveSoftmax.get_log_prob", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax"], ["", "def", "get_normalized_probs", "(", "\n", "self", ",", "\n", "net_output", ":", "Tuple", "[", "Tensor", ",", "Optional", "[", "Dict", "[", "str", ",", "List", "[", "Optional", "[", "Tensor", "]", "]", "]", "]", "]", ",", "\n", "log_probs", ":", "bool", ",", "\n", "sample", ":", "Optional", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"", "\n", "\n", "if", "hasattr", "(", "self", ",", "\"adaptive_softmax\"", ")", "and", "self", ".", "adaptive_softmax", "is", "not", "None", ":", "\n", "            ", "if", "sample", "is", "not", "None", ":", "\n", "                ", "assert", "\"target\"", "in", "sample", "\n", "target", "=", "sample", "[", "\"target\"", "]", "\n", "", "else", ":", "\n", "                ", "target", "=", "None", "\n", "", "out", "=", "self", ".", "adaptive_softmax", ".", "get_log_prob", "(", "net_output", "[", "0", "]", ",", "target", "=", "target", ")", "\n", "return", "out", ".", "exp_", "(", ")", "if", "not", "log_probs", "else", "out", "\n", "\n", "", "logits", "=", "net_output", "[", "0", "]", "\n", "if", "log_probs", ":", "\n", "            ", "return", "utils", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ",", "onnx_trace", "=", "self", ".", "onnx_trace", ")", "\n", "", "else", ":", "\n", "            ", "return", "utils", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ",", "onnx_trace", "=", "self", ".", "onnx_trace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_decoder.FairseqDecoder.max_positions": [[81, 84], ["None"], "methods", ["None"], ["", "", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum input length supported by the decoder.\"\"\"", "\n", "return", "1e6", "# an arbitrary large number", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_decoder.FairseqDecoder.upgrade_state_dict": [[85, 88], ["None"], "methods", ["None"], ["", "def", "upgrade_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Upgrade a (possibly old) state dict for new versions of fairseq.\"\"\"", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_decoder.FairseqDecoder.prepare_for_onnx_export_": [[89, 91], ["None"], "methods", ["None"], ["", "def", "prepare_for_onnx_export_", "(", "self", ")", ":", "\n", "        ", "self", ".", "onnx_trace", "=", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerModel.hub_models": [[56, 86], ["transformer.TransformerModel.hub_models.moses_subword"], "methods", ["None"], ["@", "classmethod", "\n", "def", "hub_models", "(", "cls", ")", ":", "\n", "# fmt: off", "\n", "\n", "        ", "def", "moses_subword", "(", "path", ")", ":", "\n", "            ", "return", "{", "\n", "'path'", ":", "path", ",", "\n", "'tokenizer'", ":", "'moses'", ",", "\n", "'bpe'", ":", "'subword_nmt'", ",", "\n", "}", "\n", "\n", "", "def", "moses_fastbpe", "(", "path", ")", ":", "\n", "            ", "return", "{", "\n", "'path'", ":", "path", ",", "\n", "'tokenizer'", ":", "'moses'", ",", "\n", "'bpe'", ":", "'fastbpe'", ",", "\n", "}", "\n", "\n", "", "return", "{", "\n", "'transformer.wmt14.en-fr'", ":", "moses_subword", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/wmt14.en-fr.joined-dict.transformer.tar.bz2'", ")", ",", "\n", "'transformer.wmt16.en-de'", ":", "'https://dl.fbaipublicfiles.com/fairseq/models/wmt16.en-de.joined-dict.transformer.tar.bz2'", ",", "\n", "'transformer.wmt18.en-de'", ":", "moses_subword", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/wmt18.en-de.ensemble.tar.gz'", ")", ",", "\n", "'transformer.wmt19.en-de'", ":", "moses_fastbpe", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/wmt19.en-de.joined-dict.ensemble.tar.gz'", ")", ",", "\n", "'transformer.wmt19.en-ru'", ":", "moses_fastbpe", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/wmt19.en-ru.ensemble.tar.gz'", ")", ",", "\n", "'transformer.wmt19.de-en'", ":", "moses_fastbpe", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/wmt19.de-en.joined-dict.ensemble.tar.gz'", ")", ",", "\n", "'transformer.wmt19.ru-en'", ":", "moses_fastbpe", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/wmt19.ru-en.ensemble.tar.gz'", ")", ",", "\n", "'transformer.wmt19.en-de.single_model'", ":", "moses_fastbpe", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/wmt19.en-de.joined-dict.single_model.tar.gz'", ")", ",", "\n", "'transformer.wmt19.en-ru.single_model'", ":", "moses_fastbpe", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/wmt19.en-ru.single_model.tar.gz'", ")", ",", "\n", "'transformer.wmt19.de-en.single_model'", ":", "moses_fastbpe", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/wmt19.de-en.joined-dict.single_model.tar.gz'", ")", ",", "\n", "'transformer.wmt19.ru-en.single_model'", ":", "moses_fastbpe", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/wmt19.ru-en.single_model.tar.gz'", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerModel.__init__": [[89, 93], ["fairseq.models.FairseqEncoderDecoderModel.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["", "def", "__init__", "(", "self", ",", "args", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "encoder", ",", "decoder", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "supports_align_args", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerModel.add_args": [[94, 175], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "fairseq.utils.get_available_activation_fns"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_available_activation_fns"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--activation-fn'", ",", "\n", "choices", "=", "utils", ".", "get_available_activation_fns", "(", ")", ",", "\n", "help", "=", "'activation function to use'", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability'", ")", "\n", "parser", ".", "add_argument", "(", "'--attention-dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability for attention weights'", ")", "\n", "parser", ".", "add_argument", "(", "'--activation-dropout'", ",", "'--relu-dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability after activation in FFN.'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-embed-path'", ",", "type", "=", "str", ",", "metavar", "=", "'STR'", ",", "\n", "help", "=", "'path to pre-trained encoder embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'encoder embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-ffn-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'encoder embedding dimension for FFN'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-layers'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'num encoder layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-attention-heads'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'num encoder attention heads'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-normalize-before'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'apply layernorm before each encoder block'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-learned-pos'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use learned positional embeddings in the encoder'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-embed-path'", ",", "type", "=", "str", ",", "metavar", "=", "'STR'", ",", "\n", "help", "=", "'path to pre-trained decoder embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-ffn-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder embedding dimension for FFN'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-layers'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'num decoder layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-attention-heads'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'num decoder attention heads'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-learned-pos'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use learned positional embeddings in the decoder'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-normalize-before'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'apply layernorm before each decoder block'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-output-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'decoder output dimension (extra linear layer '", "\n", "'if different from decoder embed dim'", ")", "\n", "parser", ".", "add_argument", "(", "'--share-decoder-input-output-embed'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'share decoder input and output embeddings'", ")", "\n", "parser", ".", "add_argument", "(", "'--share-all-embeddings'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'share encoder, decoder and output embeddings'", "\n", "' (requires shared dictionary and embed dim)'", ")", "\n", "parser", ".", "add_argument", "(", "'--no-token-positional-embeddings'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'if set, disables positional embeddings (outside self attention)'", ")", "\n", "parser", ".", "add_argument", "(", "'--adaptive-softmax-cutoff'", ",", "metavar", "=", "'EXPR'", ",", "\n", "help", "=", "'comma separated list of adaptive softmax cutoff points. '", "\n", "'Must be used with adaptive_loss criterion'", ")", ",", "\n", "parser", ".", "add_argument", "(", "'--adaptive-softmax-dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'sets adaptive softmax dropout for the tail projections'", ")", "\n", "parser", ".", "add_argument", "(", "'--layernorm-embedding'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'add layernorm to embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--no-scale-embedding'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'if True, dont scale embeddings'", ")", "\n", "# args for \"Cross+Self-Attention for Transformer Models\" (Peitz et al., 2019)", "\n", "parser", ".", "add_argument", "(", "'--no-cross-attention'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'do not perform cross-attention'", ")", "\n", "parser", ".", "add_argument", "(", "'--cross-self-attention'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'perform cross+self-attention'", ")", "\n", "# args for \"Reducing Transformer Depth on Demand with Structured Dropout\" (Fan et al., 2019)", "\n", "parser", ".", "add_argument", "(", "'--encoder-layerdrop'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "default", "=", "0", ",", "\n", "help", "=", "'LayerDrop probability for encoder'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-layerdrop'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "default", "=", "0", ",", "\n", "help", "=", "'LayerDrop probability for decoder'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-layers-to-keep'", ",", "default", "=", "None", ",", "\n", "help", "=", "'which layers to *keep* when pruning as a comma-separated list'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder-layers-to-keep'", ",", "default", "=", "None", ",", "\n", "help", "=", "'which layers to *keep* when pruning as a comma-separated list'", ")", "\n", "# args for Training with Quantization Noise for Extreme Model Compression ({Fan*, Stock*} et al., 2020)", "\n", "parser", ".", "add_argument", "(", "'--quant-noise-pq'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "default", "=", "0", ",", "\n", "help", "=", "'iterative PQ quantization noise at training time'", ")", "\n", "parser", ".", "add_argument", "(", "'--quant-noise-pq-block-size'", ",", "type", "=", "int", ",", "metavar", "=", "'D'", ",", "default", "=", "8", ",", "\n", "help", "=", "'block size of quantization noise at training time'", ")", "\n", "parser", ".", "add_argument", "(", "'--quant-noise-scalar'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "default", "=", "0", ",", "\n", "help", "=", "'scalar quantization noise and scalar quantization at training time'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerModel.build_model": [[177, 225], ["transformer.base_architecture", "cls.build_encoder", "cls.build_decoder", "cls", "len", "len", "getattr", "getattr", "cls.build_embedding", "cls.build_embedding", "cls.build_embedding", "args.encoder_layers_to_keep.split", "args.decoder_layers_to_keep.split", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.build_encoder", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.build_decoder", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.build_embedding", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.build_embedding", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.build_embedding"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "\n", "# make sure all arguments are present in older models", "\n", "base_architecture", "(", "args", ")", "\n", "\n", "if", "args", ".", "encoder_layers_to_keep", ":", "\n", "            ", "args", ".", "encoder_layers", "=", "len", "(", "args", ".", "encoder_layers_to_keep", ".", "split", "(", "\",\"", ")", ")", "\n", "", "if", "args", ".", "decoder_layers_to_keep", ":", "\n", "            ", "args", ".", "decoder_layers", "=", "len", "(", "args", ".", "decoder_layers_to_keep", ".", "split", "(", "\",\"", ")", ")", "\n", "\n", "", "if", "getattr", "(", "args", ",", "\"max_source_positions\"", ",", "None", ")", "is", "None", ":", "\n", "            ", "args", ".", "max_source_positions", "=", "DEFAULT_MAX_SOURCE_POSITIONS", "\n", "", "if", "getattr", "(", "args", ",", "\"max_target_positions\"", ",", "None", ")", "is", "None", ":", "\n", "            ", "args", ".", "max_target_positions", "=", "DEFAULT_MAX_TARGET_POSITIONS", "\n", "\n", "", "src_dict", ",", "tgt_dict", "=", "task", ".", "source_dictionary", ",", "task", ".", "target_dictionary", "\n", "\n", "if", "args", ".", "share_all_embeddings", ":", "\n", "            ", "if", "src_dict", "!=", "tgt_dict", ":", "\n", "                ", "raise", "ValueError", "(", "\"--share-all-embeddings requires a joined dictionary\"", ")", "\n", "", "if", "args", ".", "encoder_embed_dim", "!=", "args", ".", "decoder_embed_dim", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"--share-all-embeddings requires --encoder-embed-dim to match --decoder-embed-dim\"", "\n", ")", "\n", "", "if", "args", ".", "decoder_embed_path", "and", "(", "\n", "args", ".", "decoder_embed_path", "!=", "args", ".", "encoder_embed_path", "\n", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"--share-all-embeddings not compatible with --decoder-embed-path\"", "\n", ")", "\n", "", "encoder_embed_tokens", "=", "cls", ".", "build_embedding", "(", "\n", "args", ",", "src_dict", ",", "args", ".", "encoder_embed_dim", ",", "args", ".", "encoder_embed_path", "\n", ")", "\n", "decoder_embed_tokens", "=", "encoder_embed_tokens", "\n", "args", ".", "share_decoder_input_output_embed", "=", "True", "\n", "", "else", ":", "\n", "            ", "encoder_embed_tokens", "=", "cls", ".", "build_embedding", "(", "\n", "args", ",", "src_dict", ",", "args", ".", "encoder_embed_dim", ",", "args", ".", "encoder_embed_path", "\n", ")", "\n", "decoder_embed_tokens", "=", "cls", ".", "build_embedding", "(", "\n", "args", ",", "tgt_dict", ",", "args", ".", "decoder_embed_dim", ",", "args", ".", "decoder_embed_path", "\n", ")", "\n", "\n", "", "encoder", "=", "cls", ".", "build_encoder", "(", "args", ",", "src_dict", ",", "encoder_embed_tokens", ")", "\n", "decoder", "=", "cls", ".", "build_decoder", "(", "args", ",", "tgt_dict", ",", "decoder_embed_tokens", ")", "\n", "return", "cls", "(", "args", ",", "encoder", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerModel.build_embedding": [[226, 237], ["len", "dictionary.pad", "transformer.Embedding", "fairseq.utils.parse_embedding", "fairseq.utils.load_embedding"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.parse_embedding", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.load_embedding"], ["", "@", "classmethod", "\n", "def", "build_embedding", "(", "cls", ",", "args", ",", "dictionary", ",", "embed_dim", ",", "path", "=", "None", ")", ":", "\n", "        ", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "\n", "emb", "=", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "padding_idx", ")", "\n", "# if provided, load from preloaded dictionaries", "\n", "if", "path", ":", "\n", "            ", "embed_dict", "=", "utils", ".", "parse_embedding", "(", "path", ")", "\n", "utils", ".", "load_embedding", "(", "embed_dict", ",", "dictionary", ",", "emb", ")", "\n", "", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerModel.build_encoder": [[238, 241], ["transformer.TransformerEncoder"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_encoder", "(", "cls", ",", "args", ",", "src_dict", ",", "embed_tokens", ")", ":", "\n", "        ", "return", "TransformerEncoder", "(", "args", ",", "src_dict", ",", "embed_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerModel.build_decoder": [[242, 249], ["transformer.TransformerDecoder", "getattr"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_decoder", "(", "cls", ",", "args", ",", "tgt_dict", ",", "embed_tokens", ")", ":", "\n", "        ", "return", "TransformerDecoder", "(", "\n", "args", ",", "\n", "tgt_dict", ",", "\n", "embed_tokens", ",", "\n", "no_encoder_attn", "=", "getattr", "(", "args", ",", "\"no_cross_attention\"", ",", "False", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerModel.forward": [[253, 282], ["transformer.TransformerModel.encoder", "transformer.TransformerModel.decoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "src_tokens", ",", "\n", "src_lengths", ",", "\n", "prev_output_tokens", ",", "\n", "return_all_hiddens", ":", "bool", "=", "True", ",", "\n", "features_only", ":", "bool", "=", "False", ",", "\n", "alignment_layer", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "alignment_heads", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Run the forward pass for an encoder-decoder model.\n\n        Copied from the base class, but without ``**kwargs``,\n        which are not supported by TorchScript.\n        \"\"\"", "\n", "encoder_out", "=", "self", ".", "encoder", "(", "\n", "src_tokens", ",", "src_lengths", "=", "src_lengths", ",", "return_all_hiddens", "=", "return_all_hiddens", "\n", ")", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "\n", "prev_output_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", "features_only", "=", "features_only", ",", "\n", "alignment_layer", "=", "alignment_layer", ",", "\n", "alignment_heads", "=", "alignment_heads", ",", "\n", "src_lengths", "=", "src_lengths", ",", "\n", "return_all_hiddens", "=", "return_all_hiddens", ",", "\n", ")", "\n", "return", "decoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerModel.get_normalized_probs": [[286, 295], ["transformer.TransformerModel.get_normalized_probs_scriptable"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.get_normalized_probs_scriptable"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "get_normalized_probs", "(", "\n", "self", ",", "\n", "net_output", ":", "Tuple", "[", "Tensor", ",", "Optional", "[", "Dict", "[", "str", ",", "List", "[", "Optional", "[", "Tensor", "]", "]", "]", "]", "]", ",", "\n", "log_probs", ":", "bool", ",", "\n", "sample", ":", "Optional", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"", "\n", "return", "self", ".", "get_normalized_probs_scriptable", "(", "net_output", ",", "log_probs", ",", "sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerEncoder.__init__": [[308, 363], ["fairseq.models.FairseqEncoder.__init__", "transformer.TransformerEncoder.register_buffer", "fairseq.modules.FairseqDropout", "getattr", "transformer.TransformerEncoder.layers.extend", "len", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "math.sqrt", "fairseq.modules.PositionalEmbedding", "fairseq.modules.LayerNorm", "fairseq.modules.quant_noise.quant_noise", "fairseq.modules.LayerDropModuleList", "torch.ModuleList", "torch.ModuleList", "fairseq.modules.LayerNorm", "torch.Linear", "torch.Linear", "transformer.TransformerEncoder.build_encoder_layer", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.PositionalEmbedding", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.models.transformer.ModelParallelTransformerEncoder.build_encoder_layer"], ["def", "__init__", "(", "self", ",", "args", ",", "dictionary", ",", "embed_tokens", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "self", ".", "register_buffer", "(", "\"version\"", ",", "torch", ".", "Tensor", "(", "[", "3", "]", ")", ")", "\n", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "args", ".", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "encoder_layerdrop", "=", "args", ".", "encoder_layerdrop", "\n", "\n", "embed_dim", "=", "embed_tokens", ".", "embedding_dim", "\n", "self", ".", "padding_idx", "=", "embed_tokens", ".", "padding_idx", "\n", "self", ".", "max_source_positions", "=", "args", ".", "max_source_positions", "\n", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "\n", "self", ".", "embed_scale", "=", "1.0", "if", "args", ".", "no_scale_embedding", "else", "math", ".", "sqrt", "(", "embed_dim", ")", "\n", "\n", "self", ".", "embed_positions", "=", "(", "\n", "PositionalEmbedding", "(", "\n", "args", ".", "max_source_positions", ",", "\n", "embed_dim", ",", "\n", "self", ".", "padding_idx", ",", "\n", "learned", "=", "args", ".", "encoder_learned_pos", ",", "\n", ")", "\n", "if", "not", "args", ".", "no_token_positional_embeddings", "\n", "else", "None", "\n", ")", "\n", "\n", "if", "getattr", "(", "args", ",", "\"layernorm_embedding\"", ",", "False", ")", ":", "\n", "            ", "self", ".", "layernorm_embedding", "=", "LayerNorm", "(", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layernorm_embedding", "=", "None", "\n", "\n", "", "if", "not", "args", ".", "adaptive_input", "and", "args", ".", "quant_noise_pq", ">", "0", ":", "\n", "            ", "self", ".", "quant_noise", "=", "apply_quant_noise_", "(", "\n", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "False", ")", ",", "\n", "args", ".", "quant_noise_pq", ",", "\n", "args", ".", "quant_noise_pq_block_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "quant_noise", "=", "None", "\n", "\n", "", "if", "self", ".", "encoder_layerdrop", ">", "0.0", ":", "\n", "            ", "self", ".", "layers", "=", "LayerDropModuleList", "(", "p", "=", "self", ".", "encoder_layerdrop", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "", "self", ".", "layers", ".", "extend", "(", "\n", "[", "self", ".", "build_encoder_layer", "(", "args", ")", "for", "i", "in", "range", "(", "args", ".", "encoder_layers", ")", "]", "\n", ")", "\n", "self", ".", "num_layers", "=", "len", "(", "self", ".", "layers", ")", "\n", "\n", "if", "args", ".", "encoder_normalize_before", ":", "\n", "            ", "self", ".", "layer_norm", "=", "LayerNorm", "(", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer_norm", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerEncoder.build_encoder_layer": [[364, 366], ["fairseq.modules.TransformerEncoderLayer"], "methods", ["None"], ["", "", "def", "build_encoder_layer", "(", "self", ",", "args", ")", ":", "\n", "        ", "return", "TransformerEncoderLayer", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerEncoder.forward_embedding": [[367, 382], ["transformer.TransformerEncoder.dropout_module", "transformer.TransformerEncoder.embed_tokens", "transformer.TransformerEncoder.layernorm_embedding", "transformer.TransformerEncoder.quant_noise", "transformer.TransformerEncoder.embed_positions"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise"], ["", "def", "forward_embedding", "(", "\n", "self", ",", "src_tokens", ",", "token_embedding", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", "\n", ")", ":", "\n", "# embed tokens and positions", "\n", "        ", "if", "token_embedding", "is", "None", ":", "\n", "            ", "token_embedding", "=", "self", ".", "embed_tokens", "(", "src_tokens", ")", "\n", "", "x", "=", "embed", "=", "self", ".", "embed_scale", "*", "token_embedding", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", ":", "\n", "            ", "x", "=", "embed", "+", "self", ".", "embed_positions", "(", "src_tokens", ")", "\n", "", "if", "self", ".", "layernorm_embedding", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "layernorm_embedding", "(", "x", ")", "\n", "", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "if", "self", ".", "quant_noise", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "quant_noise", "(", "x", ")", "\n", "", "return", "x", ",", "embed", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerEncoder.forward": [[383, 441], ["transformer.TransformerEncoder.forward_embedding", "transformer.TransformerEncoder.transpose", "src_tokens.eq", "fairseq.models.fairseq_encoder.EncoderOut", "layer", "transformer.TransformerEncoder.layer_norm", "encoder_states.append"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerDecoder.forward_embedding"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "src_tokens", ",", "\n", "src_lengths", ",", "\n", "return_all_hiddens", ":", "bool", "=", "False", ",", "\n", "token_embeddings", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            src_tokens (LongTensor): tokens in the source language of shape\n                `(batch, src_len)`\n            src_lengths (torch.LongTensor): lengths of each source sentence of\n                shape `(batch)`\n            return_all_hiddens (bool, optional): also return all of the\n                intermediate hidden states (default: False).\n            token_embeddings (torch.Tensor, optional): precomputed embeddings\n                default `None` will recompute embeddings\n\n        Returns:\n            namedtuple:\n                - **encoder_out** (Tensor): the last encoder layer's output of\n                  shape `(src_len, batch, embed_dim)`\n                - **encoder_padding_mask** (ByteTensor): the positions of\n                  padding elements of shape `(batch, src_len)`\n                - **encoder_embedding** (Tensor): the (scaled) embedding lookup\n                  of shape `(batch, src_len, embed_dim)`\n                - **encoder_states** (List[Tensor]): all intermediate\n                  hidden states of shape `(src_len, batch, embed_dim)`.\n                  Only populated if *return_all_hiddens* is True.\n        \"\"\"", "\n", "x", ",", "encoder_embedding", "=", "self", ".", "forward_embedding", "(", "src_tokens", ",", "token_embeddings", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# compute padding mask", "\n", "encoder_padding_mask", "=", "src_tokens", ".", "eq", "(", "self", ".", "padding_idx", ")", "\n", "\n", "encoder_states", "=", "[", "]", "if", "return_all_hiddens", "else", "None", "\n", "\n", "# encoder layers", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "layer", "(", "x", ",", "encoder_padding_mask", ")", "\n", "if", "return_all_hiddens", ":", "\n", "                ", "assert", "encoder_states", "is", "not", "None", "\n", "encoder_states", ".", "append", "(", "x", ")", "\n", "\n", "", "", "if", "self", ".", "layer_norm", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "", "return", "EncoderOut", "(", "\n", "encoder_out", "=", "x", ",", "# T x B x C", "\n", "encoder_padding_mask", "=", "encoder_padding_mask", ",", "# B x T", "\n", "encoder_embedding", "=", "encoder_embedding", ",", "# B x T x C", "\n", "encoder_states", "=", "encoder_states", ",", "# List[T x B x C]", "\n", "src_tokens", "=", "None", ",", "\n", "src_lengths", "=", "None", ",", "\n", "output_encoder_lengths", "=", "None", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerEncoder.reorder_encoder_out": [[443, 499], ["fairseq.models.fairseq_encoder.EncoderOut", "encoder_out.encoder_out.index_select", "encoder_padding_mask.index_select", "encoder_embedding.index_select", "src_tokens.index_select.index_select.index_select", "src_lengths.index_select.index_select.index_select", "enumerate", "state.index_select"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "reorder_encoder_out", "(", "self", ",", "encoder_out", ":", "EncoderOut", ",", "new_order", ")", ":", "\n", "        ", "\"\"\"\n        Reorder encoder output according to *new_order*.\n\n        Args:\n            encoder_out: output from the ``forward()`` method\n            new_order (LongTensor): desired order\n\n        Returns:\n            *encoder_out* rearranged according to *new_order*\n        \"\"\"", "\n", "\"\"\"\n        Since encoder_padding_mask and encoder_embedding are both of type\n        Optional[Tensor] in EncoderOut, they need to be copied as local\n        variables for Torchscript Optional refinement\n        \"\"\"", "\n", "encoder_padding_mask", ":", "Optional", "[", "Tensor", "]", "=", "encoder_out", ".", "encoder_padding_mask", "\n", "encoder_embedding", ":", "Optional", "[", "Tensor", "]", "=", "encoder_out", ".", "encoder_embedding", "\n", "\n", "new_encoder_out", "=", "(", "\n", "encoder_out", ".", "encoder_out", "\n", "if", "encoder_out", ".", "encoder_out", "is", "None", "\n", "else", "encoder_out", ".", "encoder_out", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", ")", "\n", "new_encoder_padding_mask", "=", "(", "\n", "encoder_padding_mask", "\n", "if", "encoder_padding_mask", "is", "None", "\n", "else", "encoder_padding_mask", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", ")", "\n", "new_encoder_embedding", "=", "(", "\n", "encoder_embedding", "\n", "if", "encoder_embedding", "is", "None", "\n", "else", "encoder_embedding", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", ")", "\n", "src_tokens", "=", "encoder_out", ".", "src_tokens", "\n", "if", "src_tokens", "is", "not", "None", ":", "\n", "            ", "src_tokens", "=", "src_tokens", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", "\n", "", "src_lengths", "=", "encoder_out", ".", "src_lengths", "\n", "if", "src_lengths", "is", "not", "None", ":", "\n", "            ", "src_lengths", "=", "src_lengths", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", "\n", "", "encoder_states", "=", "encoder_out", ".", "encoder_states", "\n", "if", "encoder_states", "is", "not", "None", ":", "\n", "            ", "for", "idx", ",", "state", "in", "enumerate", "(", "encoder_states", ")", ":", "\n", "                ", "encoder_states", "[", "idx", "]", "=", "state", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", "\n", "", "", "return", "EncoderOut", "(", "\n", "encoder_out", "=", "new_encoder_out", ",", "# T x B x C", "\n", "encoder_padding_mask", "=", "new_encoder_padding_mask", ",", "# B x T", "\n", "encoder_embedding", "=", "new_encoder_embedding", ",", "# B x T x C", "\n", "encoder_states", "=", "encoder_states", ",", "# List[T x B x C]", "\n", "src_tokens", "=", "src_tokens", ",", "# B x T", "\n", "src_lengths", "=", "src_lengths", ",", "# B x 1", "\n", "output_encoder_lengths", "=", "None", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerEncoder.max_positions": [[501, 506], ["min"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum input length supported by the encoder.\"\"\"", "\n", "if", "self", ".", "embed_positions", "is", "None", ":", "\n", "            ", "return", "self", ".", "max_source_positions", "\n", "", "return", "min", "(", "self", ".", "max_source_positions", ",", "self", ".", "embed_positions", ".", "max_positions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerEncoder.upgrade_state_dict_named": [[507, 530], ["isinstance", "range", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "transformer.TransformerEncoder.layers[].upgrade_state_dict_named", "fairseq.utils.item", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "print", "state_dict.get", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.upgrade_state_dict_named", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "\"\"\"Upgrade a (possibly old) state dict for new versions of fairseq.\"\"\"", "\n", "if", "isinstance", "(", "self", ".", "embed_positions", ",", "SinusoidalPositionalEmbedding", ")", ":", "\n", "            ", "weights_key", "=", "\"{}.embed_positions.weights\"", ".", "format", "(", "name", ")", "\n", "if", "weights_key", "in", "state_dict", ":", "\n", "                ", "print", "(", "\"deleting {0}\"", ".", "format", "(", "weights_key", ")", ")", "\n", "del", "state_dict", "[", "weights_key", "]", "\n", "", "state_dict", "[", "\n", "\"{}.embed_positions._float_tensor\"", ".", "format", "(", "name", ")", "\n", "]", "=", "torch", ".", "FloatTensor", "(", "1", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "# update layer norms", "\n", "            ", "self", ".", "layers", "[", "i", "]", ".", "upgrade_state_dict_named", "(", "\n", "state_dict", ",", "\"{}.layers.{}\"", ".", "format", "(", "name", ",", "i", ")", "\n", ")", "\n", "\n", "", "version_key", "=", "\"{}.version\"", ".", "format", "(", "name", ")", "\n", "if", "utils", ".", "item", "(", "state_dict", ".", "get", "(", "version_key", ",", "torch", ".", "Tensor", "(", "[", "1", "]", ")", ")", "[", "0", "]", ")", "<", "2", ":", "\n", "# earlier checkpoints did not normalize after the stack of layers", "\n", "            ", "self", ".", "layer_norm", "=", "None", "\n", "self", ".", "normalize", "=", "False", "\n", "state_dict", "[", "version_key", "]", "=", "torch", ".", "Tensor", "(", "[", "1", "]", ")", "\n", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerDecoder.__init__": [[545, 651], ["fairseq.models.FairseqIncrementalDecoder.__init__", "transformer.TransformerDecoder.register_buffer", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "fairseq.modules.FairseqDropout", "getattr", "getattr", "transformer.TransformerDecoder.layers.extend", "len", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "math.sqrt", "fairseq.modules.quant_noise.quant_noise", "transformer.Linear", "fairseq.modules.PositionalEmbedding", "fairseq.modules.LayerNorm", "fairseq.modules.LayerDropModuleList", "torch.ModuleList", "torch.ModuleList", "fairseq.modules.LayerNorm", "transformer.Linear", "fairseq.modules.AdaptiveSoftmax", "torch.Linear", "torch.Linear", "transformer.TransformerDecoder.build_decoder_layer", "getattr", "len", "fairseq.utils.eval_str_list", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.init.normal_", "torch.init.normal_", "range", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.PositionalEmbedding", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.models.transformer.ModelParallelTransformerDecoder.build_decoder_layer", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.eval_str_list", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["def", "__init__", "(", "self", ",", "args", ",", "dictionary", ",", "embed_tokens", ",", "no_encoder_attn", "=", "False", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "self", ".", "register_buffer", "(", "\"version\"", ",", "torch", ".", "Tensor", "(", "[", "3", "]", ")", ")", "\n", "self", ".", "_future_mask", "=", "torch", ".", "empty", "(", "0", ")", "\n", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "args", ".", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "decoder_layerdrop", "=", "args", ".", "decoder_layerdrop", "\n", "self", ".", "share_input_output_embed", "=", "args", ".", "share_decoder_input_output_embed", "\n", "\n", "input_embed_dim", "=", "embed_tokens", ".", "embedding_dim", "\n", "embed_dim", "=", "args", ".", "decoder_embed_dim", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "output_embed_dim", "=", "args", ".", "decoder_output_dim", "\n", "\n", "self", ".", "padding_idx", "=", "embed_tokens", ".", "padding_idx", "\n", "self", ".", "max_target_positions", "=", "args", ".", "max_target_positions", "\n", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "\n", "self", ".", "embed_scale", "=", "1.0", "if", "args", ".", "no_scale_embedding", "else", "math", ".", "sqrt", "(", "embed_dim", ")", "\n", "\n", "if", "not", "args", ".", "adaptive_input", "and", "args", ".", "quant_noise_pq", ">", "0", ":", "\n", "            ", "self", ".", "quant_noise", "=", "apply_quant_noise_", "(", "\n", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "False", ")", ",", "\n", "args", ".", "quant_noise_pq", ",", "\n", "args", ".", "quant_noise_pq_block_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "quant_noise", "=", "None", "\n", "\n", "", "self", ".", "project_in_dim", "=", "(", "\n", "Linear", "(", "input_embed_dim", ",", "embed_dim", ",", "bias", "=", "False", ")", "\n", "if", "embed_dim", "!=", "input_embed_dim", "\n", "else", "None", "\n", ")", "\n", "self", ".", "embed_positions", "=", "(", "\n", "PositionalEmbedding", "(", "\n", "self", ".", "max_target_positions", ",", "\n", "embed_dim", ",", "\n", "self", ".", "padding_idx", ",", "\n", "learned", "=", "args", ".", "decoder_learned_pos", ",", "\n", ")", "\n", "if", "not", "args", ".", "no_token_positional_embeddings", "\n", "else", "None", "\n", ")", "\n", "\n", "if", "getattr", "(", "args", ",", "\"layernorm_embedding\"", ",", "False", ")", ":", "\n", "            ", "self", ".", "layernorm_embedding", "=", "LayerNorm", "(", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layernorm_embedding", "=", "None", "\n", "\n", "", "self", ".", "cross_self_attention", "=", "getattr", "(", "args", ",", "\"cross_self_attention\"", ",", "False", ")", "\n", "\n", "if", "self", ".", "decoder_layerdrop", ">", "0.0", ":", "\n", "            ", "self", ".", "layers", "=", "LayerDropModuleList", "(", "p", "=", "self", ".", "decoder_layerdrop", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "", "self", ".", "layers", ".", "extend", "(", "\n", "[", "\n", "self", ".", "build_decoder_layer", "(", "args", ",", "no_encoder_attn", ")", "\n", "for", "_", "in", "range", "(", "args", ".", "decoder_layers", ")", "\n", "]", "\n", ")", "\n", "self", ".", "num_layers", "=", "len", "(", "self", ".", "layers", ")", "\n", "\n", "if", "args", ".", "decoder_normalize_before", "and", "not", "getattr", "(", "\n", "args", ",", "\"no_decoder_final_norm\"", ",", "False", "\n", ")", ":", "\n", "            ", "self", ".", "layer_norm", "=", "LayerNorm", "(", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer_norm", "=", "None", "\n", "\n", "", "self", ".", "project_out_dim", "=", "(", "\n", "Linear", "(", "embed_dim", ",", "self", ".", "output_embed_dim", ",", "bias", "=", "False", ")", "\n", "if", "embed_dim", "!=", "self", ".", "output_embed_dim", "and", "not", "args", ".", "tie_adaptive_weights", "\n", "else", "None", "\n", ")", "\n", "\n", "self", ".", "adaptive_softmax", "=", "None", "\n", "self", ".", "output_projection", "=", "None", "\n", "if", "args", ".", "adaptive_softmax_cutoff", "is", "not", "None", ":", "\n", "            ", "self", ".", "adaptive_softmax", "=", "AdaptiveSoftmax", "(", "\n", "len", "(", "dictionary", ")", ",", "\n", "self", ".", "output_embed_dim", ",", "\n", "utils", ".", "eval_str_list", "(", "args", ".", "adaptive_softmax_cutoff", ",", "type", "=", "int", ")", ",", "\n", "dropout", "=", "args", ".", "adaptive_softmax_dropout", ",", "\n", "adaptive_inputs", "=", "embed_tokens", "if", "args", ".", "tie_adaptive_weights", "else", "None", ",", "\n", "factor", "=", "args", ".", "adaptive_softmax_factor", ",", "\n", "tie_proj", "=", "args", ".", "tie_adaptive_proj", ",", "\n", ")", "\n", "", "elif", "self", ".", "share_input_output_embed", ":", "\n", "            ", "self", ".", "output_projection", "=", "nn", ".", "Linear", "(", "\n", "self", ".", "embed_tokens", ".", "weight", ".", "shape", "[", "1", "]", ",", "\n", "self", ".", "embed_tokens", ".", "weight", ".", "shape", "[", "0", "]", ",", "\n", "bias", "=", "False", ",", "\n", ")", "\n", "self", ".", "output_projection", ".", "weight", "=", "self", ".", "embed_tokens", ".", "weight", "\n", "", "else", ":", "\n", "            ", "self", ".", "output_projection", "=", "nn", ".", "Linear", "(", "\n", "self", ".", "output_embed_dim", ",", "len", "(", "dictionary", ")", ",", "bias", "=", "False", "\n", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "\n", "self", ".", "output_projection", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "self", ".", "output_embed_dim", "**", "-", "0.5", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerDecoder.build_decoder_layer": [[653, 655], ["fairseq.modules.TransformerDecoderLayer"], "methods", ["None"], ["", "", "def", "build_decoder_layer", "(", "self", ",", "args", ",", "no_encoder_attn", "=", "False", ")", ":", "\n", "        ", "return", "TransformerDecoderLayer", "(", "args", ",", "no_encoder_attn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerDecoder.forward": [[656, 697], ["transformer.TransformerDecoder.extract_features", "transformer.TransformerDecoder.output_layer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.output_layer"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "prev_output_tokens", ",", "\n", "encoder_out", ":", "Optional", "[", "EncoderOut", "]", "=", "None", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", "=", "None", ",", "\n", "features_only", ":", "bool", "=", "False", ",", "\n", "full_context_alignment", ":", "bool", "=", "False", ",", "\n", "alignment_layer", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "alignment_heads", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "src_lengths", ":", "Optional", "[", "Any", "]", "=", "None", ",", "\n", "return_all_hiddens", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            prev_output_tokens (LongTensor): previous decoder outputs of shape\n                `(batch, tgt_len)`, for teacher forcing\n            encoder_out (optional): output from the encoder, used for\n                encoder-side attention\n            incremental_state (dict): dictionary used for storing state during\n                :ref:`Incremental decoding`\n            features_only (bool, optional): only return features without\n                applying output layer (default: False).\n            full_context_alignment (bool, optional): don't apply\n                auto-regressive mask to self-attention (default: False).\n\n        Returns:\n            tuple:\n                - the decoder's output of shape `(batch, tgt_len, vocab)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "x", ",", "extra", "=", "self", ".", "extract_features", "(", "\n", "prev_output_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", "incremental_state", "=", "incremental_state", ",", "\n", "full_context_alignment", "=", "full_context_alignment", ",", "\n", "alignment_layer", "=", "alignment_layer", ",", "\n", "alignment_heads", "=", "alignment_heads", ",", "\n", ")", "\n", "if", "not", "features_only", ":", "\n", "            ", "x", "=", "self", ".", "output_layer", "(", "x", ")", "\n", "", "return", "x", ",", "extra", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerDecoder.extract_features": [[698, 714], ["transformer.TransformerDecoder.extract_features_scriptable"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerDecoder.extract_features_scriptable"], ["", "def", "extract_features", "(", "\n", "self", ",", "\n", "prev_output_tokens", ",", "\n", "encoder_out", ":", "Optional", "[", "EncoderOut", "]", "=", "None", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", "=", "None", ",", "\n", "full_context_alignment", ":", "bool", "=", "False", ",", "\n", "alignment_layer", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "alignment_heads", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "return", "self", ".", "extract_features_scriptable", "(", "\n", "prev_output_tokens", ",", "\n", "encoder_out", ",", "\n", "incremental_state", ",", "\n", "full_context_alignment", ",", "\n", "alignment_layer", ",", "\n", "alignment_heads", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerDecoder.extract_features_scriptable": [[722, 831], ["transformer.TransformerDecoder.dropout_module", "transformer.TransformerDecoder.transpose", "enumerate", "transformer.TransformerDecoder.transpose", "transformer.TransformerDecoder.embed_positions", "transformer.TransformerDecoder.embed_tokens", "transformer.TransformerDecoder.quant_noise", "transformer.TransformerDecoder.project_in_dim", "transformer.TransformerDecoder.layernorm_embedding", "prev_output_tokens.eq().any", "prev_output_tokens.eq", "layer", "inner_states.append", "layer_attn.float().to.mean", "transformer.TransformerDecoder.layer_norm", "transformer.TransformerDecoder.project_out_dim", "transformer.TransformerDecoder.buffered_future_mask", "layer_attn.float().to", "prev_output_tokens.eq", "bool", "bool", "layer_attn.float"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.buffered_future_mask"], ["def", "extract_features_scriptable", "(", "\n", "self", ",", "\n", "prev_output_tokens", ",", "\n", "encoder_out", ":", "Optional", "[", "EncoderOut", "]", "=", "None", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", "=", "None", ",", "\n", "full_context_alignment", ":", "bool", "=", "False", ",", "\n", "alignment_layer", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "alignment_heads", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Similar to *forward* but only return features.\n\n        Includes several features from \"Jointly Learning to Align and\n        Translate with Transformer Models\" (Garg et al., EMNLP 2019).\n\n        Args:\n            full_context_alignment (bool, optional): don't apply\n                auto-regressive mask to self-attention (default: False).\n            alignment_layer (int, optional): return mean alignment over\n                heads at this layer (default: last layer).\n            alignment_heads (int, optional): only average alignment over\n                this many heads (default: all heads).\n\n        Returns:\n            tuple:\n                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "if", "alignment_layer", "is", "None", ":", "\n", "            ", "alignment_layer", "=", "self", ".", "num_layers", "-", "1", "\n", "\n", "# embed positions", "\n", "", "positions", "=", "(", "\n", "self", ".", "embed_positions", "(", "\n", "prev_output_tokens", ",", "incremental_state", "=", "incremental_state", "\n", ")", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "prev_output_tokens", "=", "prev_output_tokens", "[", ":", ",", "-", "1", ":", "]", "\n", "if", "positions", "is", "not", "None", ":", "\n", "                ", "positions", "=", "positions", "[", ":", ",", "-", "1", ":", "]", "\n", "\n", "# embed tokens and positions", "\n", "", "", "x", "=", "self", ".", "embed_scale", "*", "self", ".", "embed_tokens", "(", "prev_output_tokens", ")", "\n", "\n", "if", "self", ".", "quant_noise", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "quant_noise", "(", "x", ")", "\n", "\n", "", "if", "self", ".", "project_in_dim", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "project_in_dim", "(", "x", ")", "\n", "\n", "", "if", "positions", "is", "not", "None", ":", "\n", "            ", "x", "+=", "positions", "\n", "\n", "", "if", "self", ".", "layernorm_embedding", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "layernorm_embedding", "(", "x", ")", "\n", "\n", "", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "self_attn_padding_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "if", "self", ".", "cross_self_attention", "or", "prev_output_tokens", ".", "eq", "(", "self", ".", "padding_idx", ")", ".", "any", "(", ")", ":", "\n", "            ", "self_attn_padding_mask", "=", "prev_output_tokens", ".", "eq", "(", "self", ".", "padding_idx", ")", "\n", "\n", "# decoder layers", "\n", "", "attn", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "inner_states", ":", "List", "[", "Optional", "[", "Tensor", "]", "]", "=", "[", "x", "]", "\n", "for", "idx", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "if", "incremental_state", "is", "None", "and", "not", "full_context_alignment", ":", "\n", "                ", "self_attn_mask", "=", "self", ".", "buffered_future_mask", "(", "x", ")", "\n", "", "else", ":", "\n", "                ", "self_attn_mask", "=", "None", "\n", "\n", "", "x", ",", "layer_attn", ",", "_", "=", "layer", "(", "\n", "x", ",", "\n", "encoder_out", ".", "encoder_out", "if", "encoder_out", "is", "not", "None", "else", "None", ",", "\n", "encoder_out", ".", "encoder_padding_mask", "if", "encoder_out", "is", "not", "None", "else", "None", ",", "\n", "incremental_state", ",", "\n", "self_attn_mask", "=", "self_attn_mask", ",", "\n", "self_attn_padding_mask", "=", "self_attn_padding_mask", ",", "\n", "need_attn", "=", "bool", "(", "(", "idx", "==", "alignment_layer", ")", ")", ",", "\n", "need_head_weights", "=", "bool", "(", "(", "idx", "==", "alignment_layer", ")", ")", ",", "\n", ")", "\n", "inner_states", ".", "append", "(", "x", ")", "\n", "if", "layer_attn", "is", "not", "None", "and", "idx", "==", "alignment_layer", ":", "\n", "                ", "attn", "=", "layer_attn", ".", "float", "(", ")", ".", "to", "(", "x", ")", "\n", "\n", "", "", "if", "attn", "is", "not", "None", ":", "\n", "            ", "if", "alignment_heads", "is", "not", "None", ":", "\n", "                ", "attn", "=", "attn", "[", ":", "alignment_heads", "]", "\n", "\n", "# average probabilities over heads", "\n", "", "attn", "=", "attn", ".", "mean", "(", "dim", "=", "0", ")", "\n", "\n", "", "if", "self", ".", "layer_norm", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "if", "self", ".", "project_out_dim", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "project_out_dim", "(", "x", ")", "\n", "\n", "", "return", "x", ",", "{", "\"attn\"", ":", "[", "attn", "]", ",", "\"inner_states\"", ":", "inner_states", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerDecoder.output_layer": [[832, 839], ["transformer.TransformerDecoder.output_projection"], "methods", ["None"], ["", "def", "output_layer", "(", "self", ",", "features", ")", ":", "\n", "        ", "\"\"\"Project features to the vocabulary size.\"\"\"", "\n", "if", "self", ".", "adaptive_softmax", "is", "None", ":", "\n", "# project back to size of vocabulary", "\n", "            ", "return", "self", ".", "output_projection", "(", "features", ")", "\n", "", "else", ":", "\n", "            ", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerDecoder.max_positions": [[840, 845], ["min"], "methods", ["None"], ["", "", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum output length supported by the decoder.\"\"\"", "\n", "if", "self", ".", "embed_positions", "is", "None", ":", "\n", "            ", "return", "self", ".", "max_target_positions", "\n", "", "return", "min", "(", "self", ".", "max_target_positions", ",", "self", ".", "embed_positions", ".", "max_positions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerDecoder.buffered_future_mask": [[846, 859], ["tensor.size", "transformer.TransformerDecoder._future_mask.to", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "transformer.TransformerDecoder._future_mask.size", "transformer.TransformerDecoder._future_mask.size", "fairseq.utils.fill_with_neg_inf", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.fill_with_neg_inf"], ["", "def", "buffered_future_mask", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "dim", "=", "tensor", ".", "size", "(", "0", ")", "\n", "# self._future_mask.device != tensor.device is not working in TorchScript. This is a workaround.", "\n", "if", "(", "\n", "self", ".", "_future_mask", ".", "size", "(", "0", ")", "==", "0", "\n", "or", "(", "not", "self", ".", "_future_mask", ".", "device", "==", "tensor", ".", "device", ")", "\n", "or", "self", ".", "_future_mask", ".", "size", "(", "0", ")", "<", "dim", "\n", ")", ":", "\n", "            ", "self", ".", "_future_mask", "=", "torch", ".", "triu", "(", "\n", "utils", ".", "fill_with_neg_inf", "(", "torch", ".", "zeros", "(", "[", "dim", ",", "dim", "]", ")", ")", ",", "1", "\n", ")", "\n", "", "self", ".", "_future_mask", "=", "self", ".", "_future_mask", ".", "to", "(", "tensor", ")", "\n", "return", "self", ".", "_future_mask", "[", ":", "dim", ",", ":", "dim", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerDecoder.upgrade_state_dict_named": [[860, 906], ["isinstance", "range", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "layer_norm_map.items", "fairseq.utils.item", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "state_dict.get", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "\"\"\"Upgrade a (possibly old) state dict for new versions of fairseq.\"\"\"", "\n", "if", "isinstance", "(", "self", ".", "embed_positions", ",", "SinusoidalPositionalEmbedding", ")", ":", "\n", "            ", "weights_key", "=", "\"{}.embed_positions.weights\"", ".", "format", "(", "name", ")", "\n", "if", "weights_key", "in", "state_dict", ":", "\n", "                ", "del", "state_dict", "[", "weights_key", "]", "\n", "", "state_dict", "[", "\n", "\"{}.embed_positions._float_tensor\"", ".", "format", "(", "name", ")", "\n", "]", "=", "torch", ".", "FloatTensor", "(", "1", ")", "\n", "\n", "", "if", "f\"{name}.output_projection.weight\"", "not", "in", "state_dict", ":", "\n", "            ", "if", "self", ".", "share_input_output_embed", ":", "\n", "                ", "embed_out_key", "=", "f\"{name}.embed_tokens.weight\"", "\n", "", "else", ":", "\n", "                ", "embed_out_key", "=", "f\"{name}.embed_out\"", "\n", "", "if", "embed_out_key", "in", "state_dict", ":", "\n", "                ", "state_dict", "[", "f\"{name}.output_projection.weight\"", "]", "=", "state_dict", "[", "\n", "embed_out_key", "\n", "]", "\n", "if", "not", "self", ".", "share_input_output_embed", ":", "\n", "                    ", "del", "state_dict", "[", "embed_out_key", "]", "\n", "\n", "", "", "", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "# update layer norms", "\n", "            ", "layer_norm_map", "=", "{", "\n", "\"0\"", ":", "\"self_attn_layer_norm\"", ",", "\n", "\"1\"", ":", "\"encoder_attn_layer_norm\"", ",", "\n", "\"2\"", ":", "\"final_layer_norm\"", ",", "\n", "}", "\n", "for", "old", ",", "new", "in", "layer_norm_map", ".", "items", "(", ")", ":", "\n", "                ", "for", "m", "in", "(", "\"weight\"", ",", "\"bias\"", ")", ":", "\n", "                    ", "k", "=", "\"{}.layers.{}.layer_norms.{}.{}\"", ".", "format", "(", "name", ",", "i", ",", "old", ",", "m", ")", "\n", "if", "k", "in", "state_dict", ":", "\n", "                        ", "state_dict", "[", "\n", "\"{}.layers.{}.{}.{}\"", ".", "format", "(", "name", ",", "i", ",", "new", ",", "m", ")", "\n", "]", "=", "state_dict", "[", "k", "]", "\n", "del", "state_dict", "[", "k", "]", "\n", "\n", "", "", "", "", "version_key", "=", "\"{}.version\"", ".", "format", "(", "name", ")", "\n", "if", "utils", ".", "item", "(", "state_dict", ".", "get", "(", "version_key", ",", "torch", ".", "Tensor", "(", "[", "1", "]", ")", ")", "[", "0", "]", ")", "<=", "2", ":", "\n", "# earlier checkpoints did not normalize after the stack of layers", "\n", "            ", "self", ".", "layer_norm", "=", "None", "\n", "self", ".", "normalize", "=", "False", "\n", "state_dict", "[", "version_key", "]", "=", "torch", ".", "Tensor", "(", "[", "1", "]", ")", "\n", "\n", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.Embedding": [[908, 913], ["torch.Embedding", "torch.init.normal_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding"], ["", "", "def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "embedding_dim", "**", "-", "0.5", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.Linear": [[915, 921], ["torch.Linear", "torch.init.xavier_uniform_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["", "def", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "if", "bias", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.0", ")", "\n", "", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.base_architecture": [[923, 974], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "@", "register_model_architecture", "(", "\"transformer\"", ",", "\"transformer\"", ")", "\n", "def", "base_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_path", "=", "getattr", "(", "args", ",", "\"encoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "2048", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "6", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "encoder_normalize_before", "=", "getattr", "(", "args", ",", "\"encoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "encoder_learned_pos", "=", "getattr", "(", "args", ",", "\"encoder_learned_pos\"", ",", "False", ")", "\n", "args", ".", "decoder_embed_path", "=", "getattr", "(", "args", ",", "\"decoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "args", ".", "encoder_embed_dim", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "args", ".", "encoder_ffn_embed_dim", "\n", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "6", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "decoder_normalize_before", "=", "getattr", "(", "args", ",", "\"decoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "decoder_learned_pos", "=", "getattr", "(", "args", ",", "\"decoder_learned_pos\"", ",", "False", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.0", ")", "\n", "args", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "0.0", ")", "\n", "args", ".", "activation_fn", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"relu\"", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "adaptive_softmax_cutoff", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_cutoff\"", ",", "None", ")", "\n", "args", ".", "adaptive_softmax_dropout", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_dropout\"", ",", "0", ")", "\n", "args", ".", "share_decoder_input_output_embed", "=", "getattr", "(", "\n", "args", ",", "\"share_decoder_input_output_embed\"", ",", "False", "\n", ")", "\n", "args", ".", "share_all_embeddings", "=", "getattr", "(", "args", ",", "\"share_all_embeddings\"", ",", "False", ")", "\n", "args", ".", "no_token_positional_embeddings", "=", "getattr", "(", "\n", "args", ",", "\"no_token_positional_embeddings\"", ",", "False", "\n", ")", "\n", "args", ".", "adaptive_input", "=", "getattr", "(", "args", ",", "\"adaptive_input\"", ",", "False", ")", "\n", "args", ".", "no_cross_attention", "=", "getattr", "(", "args", ",", "\"no_cross_attention\"", ",", "False", ")", "\n", "args", ".", "cross_self_attention", "=", "getattr", "(", "args", ",", "\"cross_self_attention\"", ",", "False", ")", "\n", "\n", "args", ".", "decoder_output_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_output_dim\"", ",", "args", ".", "decoder_embed_dim", "\n", ")", "\n", "args", ".", "decoder_input_dim", "=", "getattr", "(", "args", ",", "\"decoder_input_dim\"", ",", "args", ".", "decoder_embed_dim", ")", "\n", "\n", "args", ".", "no_scale_embedding", "=", "getattr", "(", "args", ",", "\"no_scale_embedding\"", ",", "False", ")", "\n", "args", ".", "layernorm_embedding", "=", "getattr", "(", "args", ",", "\"layernorm_embedding\"", ",", "False", ")", "\n", "args", ".", "tie_adaptive_weights", "=", "getattr", "(", "args", ",", "\"tie_adaptive_weights\"", ",", "False", ")", "\n", "\n", "args", ".", "encoder_layers_to_keep", "=", "getattr", "(", "args", ",", "\"encoder_layers_to_keep\"", ",", "None", ")", "\n", "args", ".", "decoder_layers_to_keep", "=", "getattr", "(", "args", ",", "\"decoder_layers_to_keep\"", ",", "None", ")", "\n", "args", ".", "encoder_layerdrop", "=", "getattr", "(", "args", ",", "\"encoder_layerdrop\"", ",", "0", ")", "\n", "args", ".", "decoder_layerdrop", "=", "getattr", "(", "args", ",", "\"decoder_layerdrop\"", ",", "0", ")", "\n", "args", ".", "quant_noise_pq", "=", "getattr", "(", "args", ",", "\"quant_noise_pq\"", ",", "0", ")", "\n", "args", ".", "quant_noise_pq_block_size", "=", "getattr", "(", "args", ",", "\"quant_noise_pq_block_size\"", ",", "8", ")", "\n", "args", ".", "quant_noise_scalar", "=", "getattr", "(", "args", ",", "\"quant_noise_scalar\"", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.transformer_iwslt_de_en": [[976, 987], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "transformer.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "@", "register_model_architecture", "(", "\"transformer\"", ",", "\"transformer_iwslt_de_en\"", ")", "\n", "def", "transformer_iwslt_de_en", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "1024", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "4", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "6", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "1024", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "4", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "6", ")", "\n", "base_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.transformer_wmt_en_de": [[989, 992], ["fairseq.models.register_model_architecture", "transformer.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "@", "register_model_architecture", "(", "\"transformer\"", ",", "\"transformer_wmt_en_de\"", ")", "\n", "def", "transformer_wmt_en_de", "(", "args", ")", ":", "\n", "    ", "base_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.transformer_vaswani_wmt_en_de_big": [[995, 1006], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "transformer.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "@", "register_model_architecture", "(", "\"transformer\"", ",", "\"transformer_vaswani_wmt_en_de_big\"", ")", "\n", "def", "transformer_vaswani_wmt_en_de_big", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "1024", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "4096", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "16", ")", "\n", "args", ".", "encoder_normalize_before", "=", "getattr", "(", "args", ",", "\"encoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "1024", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "4096", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "16", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.3", ")", "\n", "base_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.transformer_vaswani_wmt_en_fr_big": [[1008, 1012], ["fairseq.models.register_model_architecture", "getattr", "transformer.transformer_vaswani_wmt_en_de_big"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.transformer.transformer_vaswani_wmt_en_de_big"], ["", "@", "register_model_architecture", "(", "\"transformer\"", ",", "\"transformer_vaswani_wmt_en_fr_big\"", ")", "\n", "def", "transformer_vaswani_wmt_en_fr_big", "(", "args", ")", ":", "\n", "    ", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "transformer_vaswani_wmt_en_de_big", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.transformer_wmt_en_de_big": [[1014, 1018], ["fairseq.models.register_model_architecture", "getattr", "transformer.transformer_vaswani_wmt_en_de_big"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.transformer.transformer_vaswani_wmt_en_de_big"], ["", "@", "register_model_architecture", "(", "\"transformer\"", ",", "\"transformer_wmt_en_de_big\"", ")", "\n", "def", "transformer_wmt_en_de_big", "(", "args", ")", ":", "\n", "    ", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.1", ")", "\n", "transformer_vaswani_wmt_en_de_big", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.transformer_wmt_en_de_big_t2t": [[1021, 1028], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "transformer.transformer_vaswani_wmt_en_de_big"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.transformer.transformer_vaswani_wmt_en_de_big"], ["", "@", "register_model_architecture", "(", "\"transformer\"", ",", "\"transformer_wmt_en_de_big_t2t\"", ")", "\n", "def", "transformer_wmt_en_de_big_t2t", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_normalize_before", "=", "getattr", "(", "args", ",", "\"encoder_normalize_before\"", ",", "True", ")", "\n", "args", ".", "decoder_normalize_before", "=", "getattr", "(", "args", ",", "\"decoder_normalize_before\"", ",", "True", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.1", ")", "\n", "args", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "0.1", ")", "\n", "transformer_vaswani_wmt_en_de_big", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.models.multilingual_transformer.MultilingualTransformerModel.__init__": [[40, 42], ["fairseq.models.FairseqMultiModel.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "encoders", ",", "decoders", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "encoders", ",", "decoders", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.multilingual_transformer.MultilingualTransformerModel.add_args": [[43, 66], ["fairseq.models.transformer.TransformerModel.add_args", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "TransformerModel", ".", "add_args", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--share-encoder-embeddings\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"share encoder embeddings across languages\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--share-decoder-embeddings\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"share decoder embeddings across languages\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--share-encoders\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"share encoders across languages\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--share-decoders\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"share decoders across languages\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.multilingual_transformer.MultilingualTransformerModel.build_model": [[68, 191], ["isinstance", "multilingual_transformer.base_multilingual_architecture", "zip", "multilingual_transformer.MultilingualTransformerModel", "hasattr", "hasattr", "len", "dictionary.pad", "fairseq.models.transformer.Embedding", "fairseq.models.FairseqMultiModel.build_shared_embeddings", "multilingual_transformer.MultilingualTransformerModel.build_model.get_encoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.multilingual_transformer.base_multilingual_architecture", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.build_shared_embeddings", "home.repos.pwc.inspect_result.reneeye_const.encoders.gpt2_bpe_utils.get_encoder"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "from", "fairseq", ".", "tasks", ".", "multilingual_translation", "import", "MultilingualTranslationTask", "\n", "\n", "assert", "isinstance", "(", "task", ",", "MultilingualTranslationTask", ")", "\n", "\n", "# make sure all arguments are present in older models", "\n", "base_multilingual_architecture", "(", "args", ")", "\n", "\n", "if", "not", "hasattr", "(", "args", ",", "\"max_source_positions\"", ")", ":", "\n", "            ", "args", ".", "max_source_positions", "=", "1024", "\n", "", "if", "not", "hasattr", "(", "args", ",", "\"max_target_positions\"", ")", ":", "\n", "            ", "args", ".", "max_target_positions", "=", "1024", "\n", "\n", "", "src_langs", "=", "[", "lang_pair", ".", "split", "(", "\"-\"", ")", "[", "0", "]", "for", "lang_pair", "in", "task", ".", "model_lang_pairs", "]", "\n", "tgt_langs", "=", "[", "lang_pair", ".", "split", "(", "\"-\"", ")", "[", "1", "]", "for", "lang_pair", "in", "task", ".", "model_lang_pairs", "]", "\n", "\n", "if", "args", ".", "share_encoders", ":", "\n", "            ", "args", ".", "share_encoder_embeddings", "=", "True", "\n", "", "if", "args", ".", "share_decoders", ":", "\n", "            ", "args", ".", "share_decoder_embeddings", "=", "True", "\n", "\n", "", "def", "build_embedding", "(", "dictionary", ",", "embed_dim", ",", "path", "=", "None", ")", ":", "\n", "            ", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "emb", "=", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "padding_idx", ")", "\n", "# if provided, load from preloaded dictionaries", "\n", "if", "path", ":", "\n", "                ", "embed_dict", "=", "utils", ".", "parse_embedding", "(", "path", ")", "\n", "utils", ".", "load_embedding", "(", "embed_dict", ",", "dictionary", ",", "emb", ")", "\n", "", "return", "emb", "\n", "\n", "# build shared embeddings (if applicable)", "\n", "", "shared_encoder_embed_tokens", ",", "shared_decoder_embed_tokens", "=", "None", ",", "None", "\n", "if", "args", ".", "share_all_embeddings", ":", "\n", "            ", "if", "args", ".", "encoder_embed_dim", "!=", "args", ".", "decoder_embed_dim", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"--share-all-embeddings requires --encoder-embed-dim to match --decoder-embed-dim\"", "\n", ")", "\n", "", "if", "args", ".", "decoder_embed_path", "and", "(", "\n", "args", ".", "decoder_embed_path", "!=", "args", ".", "encoder_embed_path", "\n", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"--share-all-embeddings not compatible with --decoder-embed-path\"", "\n", ")", "\n", "", "shared_encoder_embed_tokens", "=", "FairseqMultiModel", ".", "build_shared_embeddings", "(", "\n", "dicts", "=", "task", ".", "dicts", ",", "\n", "langs", "=", "task", ".", "langs", ",", "\n", "embed_dim", "=", "args", ".", "encoder_embed_dim", ",", "\n", "build_embedding", "=", "build_embedding", ",", "\n", "pretrained_embed_path", "=", "args", ".", "encoder_embed_path", ",", "\n", ")", "\n", "shared_decoder_embed_tokens", "=", "shared_encoder_embed_tokens", "\n", "args", ".", "share_decoder_input_output_embed", "=", "True", "\n", "", "else", ":", "\n", "            ", "if", "args", ".", "share_encoder_embeddings", ":", "\n", "                ", "shared_encoder_embed_tokens", "=", "FairseqMultiModel", ".", "build_shared_embeddings", "(", "\n", "dicts", "=", "task", ".", "dicts", ",", "\n", "langs", "=", "src_langs", ",", "\n", "embed_dim", "=", "args", ".", "encoder_embed_dim", ",", "\n", "build_embedding", "=", "build_embedding", ",", "\n", "pretrained_embed_path", "=", "args", ".", "encoder_embed_path", ",", "\n", ")", "\n", "", "if", "args", ".", "share_decoder_embeddings", ":", "\n", "                ", "shared_decoder_embed_tokens", "=", "FairseqMultiModel", ".", "build_shared_embeddings", "(", "\n", "dicts", "=", "task", ".", "dicts", ",", "\n", "langs", "=", "tgt_langs", ",", "\n", "embed_dim", "=", "args", ".", "decoder_embed_dim", ",", "\n", "build_embedding", "=", "build_embedding", ",", "\n", "pretrained_embed_path", "=", "args", ".", "decoder_embed_path", ",", "\n", ")", "\n", "\n", "# encoders/decoders for each language", "\n", "", "", "lang_encoders", ",", "lang_decoders", "=", "{", "}", ",", "{", "}", "\n", "\n", "def", "get_encoder", "(", "lang", ")", ":", "\n", "            ", "if", "lang", "not", "in", "lang_encoders", ":", "\n", "                ", "if", "shared_encoder_embed_tokens", "is", "not", "None", ":", "\n", "                    ", "encoder_embed_tokens", "=", "shared_encoder_embed_tokens", "\n", "", "else", ":", "\n", "                    ", "encoder_embed_tokens", "=", "build_embedding", "(", "\n", "task", ".", "dicts", "[", "lang", "]", ",", "\n", "args", ".", "encoder_embed_dim", ",", "\n", "args", ".", "encoder_embed_path", ",", "\n", ")", "\n", "", "lang_encoders", "[", "lang", "]", "=", "cls", ".", "_get_module_class", "(", "\n", "True", ",", "args", ",", "task", ".", "dicts", "[", "lang", "]", ",", "encoder_embed_tokens", ",", "src_langs", "\n", ")", "\n", "", "return", "lang_encoders", "[", "lang", "]", "\n", "\n", "", "def", "get_decoder", "(", "lang", ")", ":", "\n", "            ", "if", "lang", "not", "in", "lang_decoders", ":", "\n", "                ", "if", "shared_decoder_embed_tokens", "is", "not", "None", ":", "\n", "                    ", "decoder_embed_tokens", "=", "shared_decoder_embed_tokens", "\n", "", "else", ":", "\n", "                    ", "decoder_embed_tokens", "=", "build_embedding", "(", "\n", "task", ".", "dicts", "[", "lang", "]", ",", "\n", "args", ".", "decoder_embed_dim", ",", "\n", "args", ".", "decoder_embed_path", ",", "\n", ")", "\n", "", "lang_decoders", "[", "lang", "]", "=", "cls", ".", "_get_module_class", "(", "\n", "False", ",", "args", ",", "task", ".", "dicts", "[", "lang", "]", ",", "decoder_embed_tokens", ",", "tgt_langs", "\n", ")", "\n", "", "return", "lang_decoders", "[", "lang", "]", "\n", "\n", "# shared encoders/decoders (if applicable)", "\n", "", "shared_encoder", ",", "shared_decoder", "=", "None", ",", "None", "\n", "if", "args", ".", "share_encoders", ":", "\n", "            ", "shared_encoder", "=", "get_encoder", "(", "src_langs", "[", "0", "]", ")", "\n", "", "if", "args", ".", "share_decoders", ":", "\n", "            ", "shared_decoder", "=", "get_decoder", "(", "tgt_langs", "[", "0", "]", ")", "\n", "\n", "", "encoders", ",", "decoders", "=", "OrderedDict", "(", ")", ",", "OrderedDict", "(", ")", "\n", "for", "lang_pair", ",", "src", ",", "tgt", "in", "zip", "(", "task", ".", "model_lang_pairs", ",", "src_langs", ",", "tgt_langs", ")", ":", "\n", "            ", "encoders", "[", "lang_pair", "]", "=", "(", "\n", "shared_encoder", "if", "shared_encoder", "is", "not", "None", "else", "get_encoder", "(", "src", ")", "\n", ")", "\n", "decoders", "[", "lang_pair", "]", "=", "(", "\n", "shared_decoder", "if", "shared_decoder", "is", "not", "None", "else", "get_decoder", "(", "tgt", ")", "\n", ")", "\n", "\n", "", "return", "MultilingualTransformerModel", "(", "encoders", ",", "decoders", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.multilingual_transformer.MultilingualTransformerModel._get_module_class": [[192, 196], ["module_class"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_get_module_class", "(", "cls", ",", "is_encoder", ",", "args", ",", "lang_dict", ",", "embed_tokens", ",", "langs", ")", ":", "\n", "        ", "module_class", "=", "TransformerEncoder", "if", "is_encoder", "else", "TransformerDecoder", "\n", "return", "module_class", "(", "args", ",", "lang_dict", ",", "embed_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.multilingual_transformer.MultilingualTransformerModel.load_state_dict": [[197, 205], ["state_dict.copy", "state_dict.items", "super().load_state_dict", "k.startswith", "k.split"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.copy", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "strict", "=", "True", ",", "model_cfg", "=", "None", ")", ":", "\n", "        ", "state_dict_subset", "=", "state_dict", ".", "copy", "(", ")", "\n", "for", "k", ",", "_", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "            ", "assert", "k", ".", "startswith", "(", "\"models.\"", ")", "\n", "lang_pair", "=", "k", ".", "split", "(", "\".\"", ")", "[", "1", "]", "\n", "if", "lang_pair", "not", "in", "self", ".", "models", ":", "\n", "                ", "del", "state_dict_subset", "[", "k", "]", "\n", "", "", "super", "(", ")", ".", "load_state_dict", "(", "state_dict_subset", ",", "strict", "=", "strict", ",", "model_cfg", "=", "model_cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.multilingual_transformer.base_multilingual_architecture": [[207, 214], ["fairseq.models.register_model_architecture", "fairseq.models.transformer.base_architecture", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "", "@", "register_model_architecture", "(", "\"multilingual_transformer\"", ",", "\"multilingual_transformer\"", ")", "\n", "def", "base_multilingual_architecture", "(", "args", ")", ":", "\n", "    ", "base_architecture", "(", "args", ")", "\n", "args", ".", "share_encoder_embeddings", "=", "getattr", "(", "args", ",", "\"share_encoder_embeddings\"", ",", "False", ")", "\n", "args", ".", "share_decoder_embeddings", "=", "getattr", "(", "args", ",", "\"share_decoder_embeddings\"", ",", "False", ")", "\n", "args", ".", "share_encoders", "=", "getattr", "(", "args", ",", "\"share_encoders\"", ",", "False", ")", "\n", "args", ".", "share_decoders", "=", "getattr", "(", "args", ",", "\"share_decoders\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.multilingual_transformer.multilingual_transformer_iwslt_de_en": [[216, 229], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "multilingual_transformer.base_multilingual_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.multilingual_transformer.base_multilingual_architecture"], ["", "@", "register_model_architecture", "(", "\n", "\"multilingual_transformer\"", ",", "\"multilingual_transformer_iwslt_de_en\"", "\n", ")", "\n", "def", "multilingual_transformer_iwslt_de_en", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "1024", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "4", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "6", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "1024", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "4", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "6", ")", "\n", "base_multilingual_architecture", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv_lm.LightConvLanguageModel.__init__": [[18, 20], ["fairseq.models.FairseqLanguageModel.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv_lm.LightConvLanguageModel.add_args": [[21, 199], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "fairseq.utils.eval_str_list"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.eval_str_list"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dropout\"", ",", "\n", "default", "=", "0.1", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--attention-dropout\"", ",", "\n", "default", "=", "0.0", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability for attention weights\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--relu-dropout\"", ",", "\n", "default", "=", "0.0", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability after ReLU in FFN\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--input-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability of the inputs\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-embed-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"decoder embedding dimension\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-output-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"decoder output dimension\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-input-dim\"", ",", "type", "=", "int", ",", "metavar", "=", "\"N\"", ",", "help", "=", "\"decoder input dimension\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-ffn-embed-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"decoder embedding dimension for FFN\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-layers\"", ",", "type", "=", "int", ",", "metavar", "=", "\"N\"", ",", "help", "=", "\"num decoder layers\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-attention-heads\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"num decoder attention heads or LightConv/DynamicConv heads\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-normalize-before\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"apply layernorm before each decoder block\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--adaptive-softmax-cutoff\"", ",", "\n", "metavar", "=", "\"EXPR\"", ",", "\n", "help", "=", "\"comma separated list of adaptive softmax cutoff points. \"", "\n", "\"Must be used with adaptive_loss criterion\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--adaptive-softmax-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"sets adaptive softmax dropout for the tail projections\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--adaptive-softmax-factor\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"adaptive input factor\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no-token-positional-embeddings\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if set, disables positional embeddings (outside self attention)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--share-decoder-input-output-embed\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"share decoder input and output embeddings\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--character-embeddings\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if set, uses character embedding convolutions to produce token embeddings\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--character-filters\"", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"LIST\"", ",", "\n", "default", "=", "\"[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]\"", ",", "\n", "help", "=", "\"size of character embeddings\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--character-embedding-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "default", "=", "4", ",", "\n", "help", "=", "\"size of character embeddings\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--char-embedder-highway-layers\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "default", "=", "2", ",", "\n", "help", "=", "\"number of highway layers for character token embeddder\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--adaptive-input\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if set, uses adaptive input\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--adaptive-input-factor\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"adaptive input factor\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--adaptive-input-cutoff\"", ",", "\n", "metavar", "=", "\"EXPR\"", ",", "\n", "help", "=", "\"comma separated list of adaptive input cutoff points.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tie-adaptive-weights\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if set, ties the weights of adaptive softmax and adaptive input\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tie-adaptive-proj\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if set, ties the projection weights of adaptive softmax and adaptive input\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-learned-pos\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"use learned positional embeddings in the decoder\"", ",", "\n", ")", "\n", "\n", "\"\"\"LightConv and DynamicConv arguments\"\"\"", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-kernel-size-list\"", ",", "\n", "type", "=", "lambda", "x", ":", "utils", ".", "eval_str_list", "(", "x", ",", "int", ")", ",", "\n", "help", "=", "'list of kernel size (default: \"[3,7,15,31,31,31]\")'", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-glu\"", ",", "type", "=", "utils", ".", "eval_bool", ",", "help", "=", "\"glu after in proj\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-conv-type\"", ",", "\n", "default", "=", "\"dynamic\"", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "[", "\"dynamic\"", ",", "\"lightweight\"", "]", ",", "\n", "help", "=", "\"type of convolution\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight-softmax\"", ",", "default", "=", "True", ",", "type", "=", "utils", ".", "eval_bool", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--weight-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability for conv weights\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv_lm.LightConvLanguageModel.build_model": [[201, 253], ["lightconv_lm.base_lm_architecture", "fairseq.models.lightconv.LightConvDecoder", "lightconv_lm.LightConvLanguageModel", "getattr", "getattr", "fairseq.modules.CharacterTokenEmbedder", "eval", "fairseq.modules.AdaptiveInput", "fairseq.models.lightconv.Embedding", "len", "task.dictionary.pad", "fairseq.utils.eval_str_list", "len", "task.dictionary.pad"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.lightconv_lm.base_lm_architecture", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.eval_str_list", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "\n", "# make sure all arguments are present in older models", "\n", "base_lm_architecture", "(", "args", ")", "\n", "\n", "if", "getattr", "(", "args", ",", "\"max_source_positions\"", ",", "None", ")", "is", "None", ":", "\n", "            ", "args", ".", "max_source_positions", "=", "args", ".", "tokens_per_sample", "\n", "", "if", "getattr", "(", "args", ",", "\"max_target_positions\"", ",", "None", ")", "is", "None", ":", "\n", "            ", "args", ".", "max_target_positions", "=", "args", ".", "tokens_per_sample", "\n", "\n", "", "if", "args", ".", "character_embeddings", ":", "\n", "            ", "embed_tokens", "=", "CharacterTokenEmbedder", "(", "\n", "task", ".", "dictionary", ",", "\n", "eval", "(", "args", ".", "character_filters", ")", ",", "\n", "args", ".", "character_embedding_dim", ",", "\n", "args", ".", "decoder_embed_dim", ",", "\n", "args", ".", "char_embedder_highway_layers", ",", "\n", ")", "\n", "", "elif", "args", ".", "adaptive_input", ":", "\n", "            ", "embed_tokens", "=", "AdaptiveInput", "(", "\n", "len", "(", "task", ".", "dictionary", ")", ",", "\n", "task", ".", "dictionary", ".", "pad", "(", ")", ",", "\n", "args", ".", "decoder_input_dim", ",", "\n", "args", ".", "adaptive_input_factor", ",", "\n", "args", ".", "decoder_embed_dim", ",", "\n", "utils", ".", "eval_str_list", "(", "args", ".", "adaptive_input_cutoff", ",", "type", "=", "int", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "embed_tokens", "=", "Embedding", "(", "\n", "len", "(", "task", ".", "dictionary", ")", ",", "args", ".", "decoder_input_dim", ",", "task", ".", "dictionary", ".", "pad", "(", ")", "\n", ")", "\n", "\n", "", "if", "args", ".", "tie_adaptive_weights", ":", "\n", "            ", "assert", "args", ".", "adaptive_input", "\n", "assert", "args", ".", "adaptive_input_factor", "==", "args", ".", "adaptive_softmax_factor", "\n", "assert", "(", "\n", "args", ".", "adaptive_softmax_cutoff", "==", "args", ".", "adaptive_input_cutoff", "\n", ")", ",", "\"{} != {}\"", ".", "format", "(", "\n", "args", ".", "adaptive_softmax_cutoff", ",", "args", ".", "adaptive_input_cutoff", "\n", ")", "\n", "assert", "args", ".", "decoder_input_dim", "==", "args", ".", "decoder_output_dim", "\n", "\n", "", "decoder", "=", "LightConvDecoder", "(", "\n", "args", ",", "\n", "task", ".", "output_dictionary", ",", "\n", "embed_tokens", ",", "\n", "no_encoder_attn", "=", "True", ",", "\n", "final_norm", "=", "False", ",", "\n", ")", "\n", "return", "LightConvLanguageModel", "(", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv_lm.base_lm_architecture": [[255, 297], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "len", "len"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "", "@", "register_model_architecture", "(", "\"lightconv_lm\"", ",", "\"lightconv_lm\"", ")", "\n", "def", "base_lm_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "2048", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "6", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "adaptive_softmax_cutoff", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_cutoff\"", ",", "None", ")", "\n", "args", ".", "adaptive_softmax_dropout", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_dropout\"", ",", "0", ")", "\n", "args", ".", "adaptive_softmax_factor", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_factor\"", ",", "4", ")", "\n", "args", ".", "decoder_learned_pos", "=", "getattr", "(", "args", ",", "\"decoder_learned_pos\"", ",", "False", ")", "\n", "\n", "args", ".", "character_embeddings", "=", "getattr", "(", "args", ",", "\"character_embeddings\"", ",", "False", ")", "\n", "\n", "args", ".", "decoder_output_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_output_dim\"", ",", "args", ".", "decoder_embed_dim", "\n", ")", "\n", "args", ".", "decoder_input_dim", "=", "getattr", "(", "args", ",", "\"decoder_input_dim\"", ",", "args", ".", "decoder_embed_dim", ")", "\n", "args", ".", "decoder_conv_dim", "=", "getattr", "(", "args", ",", "\"decoder_conv_dim\"", ",", "args", ".", "decoder_embed_dim", ")", "\n", "\n", "# The model training is not stable without this", "\n", "args", ".", "decoder_normalize_before", "=", "True", "\n", "\n", "args", ".", "adaptive_input", "=", "getattr", "(", "args", ",", "\"adaptive_input\"", ",", "False", ")", "\n", "args", ".", "adaptive_input_factor", "=", "getattr", "(", "args", ",", "\"adaptive_input_factor\"", ",", "4", ")", "\n", "args", ".", "adaptive_input_cutoff", "=", "getattr", "(", "args", ",", "\"adaptive_input_cutoff\"", ",", "None", ")", "\n", "\n", "args", ".", "tie_adaptive_weights", "=", "getattr", "(", "args", ",", "\"tie_adaptive_weights\"", ",", "False", ")", "\n", "args", ".", "tie_adaptive_proj", "=", "getattr", "(", "args", ",", "\"tie_adaptive_proj\"", ",", "False", ")", "\n", "\n", "args", ".", "decoder_kernel_size_list", "=", "getattr", "(", "\n", "args", ",", "\"decoder_kernel_size_list\"", ",", "[", "3", ",", "7", ",", "15", ",", "31", ",", "31", ",", "31", "]", "\n", ")", "\n", "if", "len", "(", "args", ".", "decoder_kernel_size_list", ")", "==", "1", ":", "\n", "        ", "args", ".", "decoder_kernel_size_list", "=", "(", "\n", "args", ".", "decoder_kernel_size_list", "*", "args", ".", "decoder_layers", "\n", ")", "\n", "", "assert", "(", "\n", "len", "(", "args", ".", "decoder_kernel_size_list", ")", "==", "args", ".", "decoder_layers", "\n", ")", ",", "\"decoder_kernel_size_list doesn't match decoder_layers\"", "\n", "args", ".", "decoder_glu", "=", "getattr", "(", "args", ",", "\"decoder_glu\"", ",", "True", ")", "\n", "args", ".", "input_dropout", "=", "getattr", "(", "args", ",", "\"input_dropout\"", ",", "0.1", ")", "\n", "args", ".", "weight_dropout", "=", "getattr", "(", "args", ",", "\"weight_dropout\"", ",", "args", ".", "attention_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.lightconv_lm.lightconv_lm_gbw": [[299, 307], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "lightconv_lm.base_lm_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.lightconv_lm.base_lm_architecture"], ["", "@", "register_model_architecture", "(", "\"lightconv_lm\"", ",", "\"lightconv_lm_gbw\"", ")", "\n", "def", "lightconv_lm_gbw", "(", "args", ")", ":", "\n", "    ", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.1", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "4096", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "16", ")", "\n", "base_lm_architecture", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.models.distributed_fairseq_model.TPUDistributedDataParallel.__init__": [[118, 123], ["torch.Module.__init__", "fairseq.distributed_utils.get_world_size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_world_size"], ["    ", "def", "__init__", "(", "self", ",", "module", ",", "process_group", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "module", "=", "module", "\n", "self", ".", "process_group", "=", "process_group", "\n", "self", ".", "world_size", "=", "distributed_utils", ".", "get_world_size", "(", "self", ".", "process_group", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.distributed_fairseq_model.TPUDistributedDataParallel.forward": [[124, 126], ["distributed_fairseq_model.TPUDistributedDataParallel.module"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "module", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.distributed_fairseq_model.TPUDistributedDataParallel.all_reduce_grads": [[127, 147], ["distributed_fairseq_model.TPUDistributedDataParallel.parameters", "xm.all_reduce", "gradients.append", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce"], ["", "def", "all_reduce_grads", "(", "self", ")", ":", "\n", "        ", "gradients", "=", "[", "]", "\n", "for", "p", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "not", "p", ".", "requires_grad", ":", "\n", "                ", "continue", "\n", "", "if", "p", ".", "grad", "is", "None", ":", "\n", "                ", "p", ".", "grad", "=", "torch", ".", "zeros_like", "(", "p", ")", "\n", "", "if", "p", ".", "grad", ".", "requires_grad", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "\"TPUDistributedDataParallel only works with gradients that don't \"", "\n", "\"require grad\"", "\n", ")", "\n", "", "gradients", ".", "append", "(", "p", ".", "grad", ")", "\n", "\n", "", "import", "torch_xla", ".", "core", ".", "xla_model", "as", "xm", "\n", "xm", ".", "all_reduce", "(", "\n", "'sum'", ",", "\n", "gradients", ",", "\n", "scale", "=", "1.", "/", "self", ".", "world_size", ",", "\n", "groups", "=", "self", ".", "process_group", "[", "1", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.distributed_fairseq_model.DistributedFairseqModel": [[22, 114], ["isinstance", "_DistributedFairseqModel", "dict", "dict", "super().__init__", "super().__getattr__", "hasattr", "super().__getattr__", "dict", "getattr", "inspect.getargspec", "inspect.getargspec", "dict", "ValueError", "ImportError"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["", "def", "DistributedFairseqModel", "(", "args", ",", "model", ",", "process_group", ")", ":", "\n", "    ", "\"\"\"\n    Wrap a *model* to support distributed data parallel training.\n\n    This is similar to the built-in DistributedDataParallel, but allows\n    additional configuration of the DistributedDataParallel class to\n    use, and also provides easier access to the wrapped model by\n    forwarding requests for missing attributes to the wrapped model.\n\n    Args:\n        args (argparse.Namespace): fairseq args\n        model (BaseFairseqModel): model to wrap\n        process_group: the c10d process group to be used for distributed data\n            parallel all-reduction.\n    \"\"\"", "\n", "# determine which DDP class to extend", "\n", "assert", "isinstance", "(", "model", ",", "nn", ".", "Module", ")", "\n", "if", "args", ".", "tpu", ":", "\n", "        ", "ddp_class", "=", "TPUDistributedDataParallel", "\n", "init_kwargs", "=", "dict", "(", "\n", "module", "=", "model", ",", "\n", "process_group", "=", "process_group", ",", "\n", ")", "\n", "", "elif", "args", ".", "distributed_wrapper", "==", "\"DDP\"", "and", "args", ".", "ddp_backend", "==", "\"c10d\"", ":", "\n", "        ", "ddp_class", "=", "nn", ".", "parallel", ".", "DistributedDataParallel", "\n", "init_kwargs", "=", "dict", "(", "\n", "module", "=", "model", ",", "\n", "device_ids", "=", "[", "args", ".", "device_id", "]", ",", "\n", "output_device", "=", "args", ".", "device_id", ",", "\n", "broadcast_buffers", "=", "args", ".", "broadcast_buffers", ",", "\n", "bucket_cap_mb", "=", "args", ".", "bucket_cap_mb", ",", "\n", "process_group", "=", "process_group", ",", "\n", ")", "\n", "# Maintain backward compatibility", "\n", "if", "\"check_reduction\"", "in", "inspect", ".", "getargspec", "(", "ddp_class", ")", "[", "0", "]", ":", "\n", "            ", "init_kwargs", "[", "\"check_reduction\"", "]", "=", "True", "\n", "", "if", "\"find_unused_parameters\"", "in", "inspect", ".", "getargspec", "(", "ddp_class", ")", "[", "0", "]", ":", "\n", "            ", "init_kwargs", "[", "\"find_unused_parameters\"", "]", "=", "args", ".", "find_unused_parameters", "\n", "", "", "elif", "args", ".", "distributed_wrapper", "==", "\"DDP\"", "and", "args", ".", "ddp_backend", "==", "\"no_c10d\"", ":", "\n", "        ", "ddp_class", "=", "LegacyDistributedDataParallel", "\n", "init_kwargs", "=", "dict", "(", "\n", "module", "=", "model", ",", "\n", "buffer_size", "=", "2", "**", "28", ",", "\n", "process_group", "=", "process_group", ",", "\n", ")", "\n", "", "elif", "args", ".", "distributed_wrapper", "==", "\"SlowMo\"", ":", "\n", "        ", "if", "_GOSSIP_DISABLED", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Cannot find gossip library. Please install from: \"", "\n", "\"github.com/facebookresearch/stochastic_gradient_push\"", "\n", ")", "\n", "", "ddp_class", "=", "gossip", ".", "GossipDataParallel", "\n", "\n", "# The values of slowmo_momentum below were obtained by tuning on the", "\n", "# En-De 16 dataset by training the transformer_wmt_en_de_large model", "\n", "if", "args", ".", "slowmo_momentum", "is", "None", ":", "\n", "            ", "if", "args", ".", "distributed_world_size", "<=", "16", ":", "\n", "                ", "args", ".", "slowmo_momentum", "=", "0.0", "\n", "", "elif", "args", ".", "distributed_world_size", "<=", "32", ":", "\n", "                ", "args", ".", "slowmo_momentum", "=", "0.2", "\n", "", "elif", "args", ".", "distributed_world_size", "<=", "64", ":", "\n", "                ", "args", ".", "slowmo_momentum", "=", "0.5", "\n", "", "else", ":", "\n", "                ", "args", ".", "slowmo_momentum", "=", "0.6", "\n", "\n", "", "", "init_kwargs", "=", "dict", "(", "\n", "module", "=", "model", ",", "\n", "device_ids", "=", "[", "args", ".", "device_id", "]", ",", "\n", "output_device", "=", "args", ".", "device_id", ",", "\n", "broadcast_buffers", "=", "args", ".", "broadcast_buffers", ",", "\n", "nprocs_per_node", "=", "args", ".", "nprocs_per_node", ",", "\n", "slowmo_momentum", "=", "args", ".", "slowmo_momentum", ",", "\n", "localsgd", "=", "(", "args", ".", "slowmo_algorithm", "==", "\"LocalSGD\"", ")", ",", "\n", "localsgd_frequency", "=", "args", ".", "localsgd_frequency", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown --ddp-backend: \"", "+", "args", ".", "ddp_backend", ")", "\n", "\n", "", "class", "_DistributedFairseqModel", "(", "ddp_class", ")", ":", "\n", "        ", "\"\"\"Extend DistributedDataParallel to check for missing\n        attributes in the wrapped module.\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "            ", "wrapped_module", "=", "super", "(", ")", ".", "__getattr__", "(", "\"module\"", ")", "\n", "if", "hasattr", "(", "wrapped_module", ",", "name", ")", ":", "\n", "                ", "return", "getattr", "(", "wrapped_module", ",", "name", ")", "\n", "", "return", "super", "(", ")", ".", "__getattr__", "(", "name", ")", "\n", "\n", "", "", "return", "_DistributedFairseqModel", "(", "**", "init_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_lm.ModelParallelTransformerLanguageModel.add_args": [[75, 78], ["fairseq.models.transformer_lm.TransformerLanguageModel.add_args"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args"], ["default", "=", "4", ",", "metadata", "=", "{", "\"help\"", ":", "\"adaptive input factor\"", "}", "\n", ")", "\n", "no_token_positional_embeddings", ":", "bool", "=", "field", "(", "\n", "default", "=", "False", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_lm.ModelParallelTransformerLanguageModel.build_model": [[30, 74], ["transformer_lm.base_lm_architecture", "task.source_dictionary.pad_to_multiple_", "task.target_dictionary.pad_to_multiple_", "fairseq.model_parallel.models.transformer.ModelParallelTransformerDecoder", "cls", "ImportError", "len", "getattr", "getattr", "NotImplementedError", "args.decoder_layers_to_keep.split", "NotImplementedError", "cls.build_embedding"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.lightconv_lm.base_lm_architecture", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad_to_multiple_", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad_to_multiple_", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.build_embedding"], ["dropout", ":", "float", "=", "field", "(", "default", "=", "0.1", ",", "metadata", "=", "{", "\"help\"", ":", "\"dropout probability\"", "}", ")", "\n", "attention_dropout", ":", "float", "=", "field", "(", "\n", "default", "=", "0.0", ",", "metadata", "=", "{", "\"help\"", ":", "\"dropout probability for attention weights\"", "}", "\n", ")", "\n", "activation_dropout", ":", "float", "=", "field", "(", "\n", "default", "=", "0.0", ",", "metadata", "=", "{", "\"help\"", ":", "\"dropout probability after activation in FFN.\"", "}", "\n", ")", "\n", "relu_dropout", ":", "float", "=", "field", "(", "\n", "default", "=", "0.0", ",", "metadata", "=", "{", "\"help\"", ":", "\"dropout probability after activation in FFN.\"", "}", "\n", ")", "\n", "decoder_embed_dim", ":", "int", "=", "field", "(", "\n", "default", "=", "512", ",", "metadata", "=", "{", "\"help\"", ":", "\"decoder embedding dimension\"", "}", "\n", ")", "\n", "decoder_output_dim", ":", "int", "=", "field", "(", "\n", "default", "=", "512", ",", "metadata", "=", "{", "\"help\"", ":", "\"decoder output dimension\"", "}", "\n", ")", "\n", "decoder_input_dim", ":", "int", "=", "field", "(", "\n", "default", "=", "512", ",", "metadata", "=", "{", "\"help\"", ":", "\"decoder input dimension\"", "}", "\n", ")", "\n", "decoder_ffn_embed_dim", ":", "int", "=", "field", "(", "\n", "default", "=", "2048", ",", "metadata", "=", "{", "\"help\"", ":", "\"decoder embedding dimension for FFN\"", "}", "\n", ")", "\n", "decoder_layers", ":", "int", "=", "field", "(", "default", "=", "6", ",", "metadata", "=", "{", "\"help\"", ":", "\"num decoder layers\"", "}", ")", "\n", "decoder_attention_heads", ":", "int", "=", "field", "(", "\n", "default", "=", "8", ",", "metadata", "=", "{", "\"help\"", ":", "\"num decoder attention heads\"", "}", "\n", ")", "\n", "decoder_normalize_before", ":", "bool", "=", "field", "(", "\n", "default", "=", "False", ",", "metadata", "=", "{", "\"help\"", ":", "\"apply layernorm before each decoder block\"", "}", "\n", ")", "\n", "no_decoder_final_norm", ":", "bool", "=", "field", "(", "\n", "default", "=", "False", ",", "\n", "metadata", "=", "{", "\"help\"", ":", "\"don't add an extra layernorm after the last decoder block\"", "}", ",", "\n", ")", "\n", "adaptive_softmax_cutoff", ":", "Optional", "[", "str", "]", "=", "field", "(", "\n", "default", "=", "None", ",", "\n", "metadata", "=", "{", "\n", "\"help\"", ":", "\"comma separated list of adaptive softmax cutoff points. \"", "\n", "\"Must be used with adaptive_loss criterion\"", "\n", "}", ",", "\n", ")", "\n", "adaptive_softmax_dropout", ":", "float", "=", "field", "(", "\n", "default", "=", "0", ",", "\n", "metadata", "=", "{", "\"help\"", ":", "\"sets adaptive softmax dropout for the tail projections\"", "}", ",", "\n", ")", "\n", "adaptive_softmax_factor", ":", "float", "=", "field", "(", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_lm.ModelParallelTransformerLanguageModel.build_embedding": [[79, 89], ["VocabParallelEmbedding", "torch.init.normal_", "torch.init.constant_", "len", "dictionary.pad"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["metadata", "=", "{", "\n", "\"help\"", ":", "\"if set, disables positional embeddings (outside self attention)\"", "\n", "}", ",", "\n", ")", "\n", "share_decoder_input_output_embed", ":", "bool", "=", "field", "(", "\n", "default", "=", "False", ",", "metadata", "=", "{", "\"help\"", ":", "\"share decoder input and output embeddings\"", "}", "\n", ")", "\n", "character_embeddings", ":", "bool", "=", "field", "(", "\n", "default", "=", "False", ",", "\n", "metadata", "=", "{", "\n", "\"help\"", ":", "\"if set, uses character embedding convolutions to produce token embeddings\"", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_lm.transformer_lm_megatron": [[151, 161], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "transformer_lm.base_lm_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.lightconv_lm.base_lm_architecture"], ["quant_noise_pq_block_size", ":", "int", "=", "field", "(", "\n", "default", "=", "8", ",", "\n", "metadata", "=", "{", "\"help\"", ":", "\"block size of quantization noise at training time\"", "}", ",", "\n", ")", "\n", "# TODO common var add to parent", "\n", "quant_noise_scalar", ":", "float", "=", "field", "(", "\n", "default", "=", "0.0", ",", "\n", "metadata", "=", "{", "\n", "\"help\"", ":", "\"scalar quantization noise and scalar quantization at training time\"", "\n", "}", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer_lm.transformer_lm_megatron_11b": [[163, 175], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "transformer_lm.base_lm_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.lightconv_lm.base_lm_architecture"], ["tokens_per_sample", ":", "int", "=", "II", "(", "\"task.tokens_per_sample\"", ")", "\n", "max_target_positions", ":", "Optional", "[", "int", "]", "=", "II", "(", "\"task.max_target_positions\"", ")", "\n", "tpu", ":", "bool", "=", "II", "(", "\"common.tpu\"", ")", "\n", "\n", "\n", "", "@", "register_model", "(", "\"transformer_lm\"", ",", "dataclass", "=", "TransformerLanguageModelConfig", ")", "\n", "class", "TransformerLanguageModel", "(", "FairseqLanguageModel", ")", ":", "\n", "    ", "@", "classmethod", "\n", "def", "hub_models", "(", "cls", ")", ":", "\n", "        ", "def", "moses_fastbpe", "(", "path", ")", ":", "\n", "            ", "return", "{", "\"path\"", ":", "path", ",", "\"tokenizer\"", ":", "\"moses\"", ",", "\"bpe\"", ":", "\"fastbpe\"", "}", "\n", "\n", "", "return", "{", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.ModelParallelTransformerModel.build_embedding": [[43, 68], ["dictionary.pad_to_multiple_", "len", "dictionary.pad", "VocabParallelEmbedding", "ImportError", "torch.init.normal_", "torch.init.normal_", "torch.init.constant_", "torch.init.constant_", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad_to_multiple_", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["\n", "\n", "@", "classmethod", "\n", "def", "hub_models", "(", "cls", ")", ":", "\n", "# fmt: off", "\n", "\n", "        ", "def", "moses_subword", "(", "path", ")", ":", "\n", "            ", "return", "{", "\n", "'path'", ":", "path", ",", "\n", "'tokenizer'", ":", "'moses'", ",", "\n", "'bpe'", ":", "'subword_nmt'", ",", "\n", "}", "\n", "\n", "", "def", "moses_fastbpe", "(", "path", ")", ":", "\n", "            ", "return", "{", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.ModelParallelTransformerModel.build_encoder": [[69, 72], ["transformer.ModelParallelTransformerEncoder"], "methods", ["None"], ["'path'", ":", "path", ",", "\n", "'tokenizer'", ":", "'moses'", ",", "\n", "'bpe'", ":", "'fastbpe'", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.ModelParallelTransformerModel.build_decoder": [[73, 80], ["transformer.ModelParallelTransformerDecoder", "getattr"], "methods", ["None"], ["\n", "", "return", "{", "\n", "'transformer.wmt14.en-fr'", ":", "moses_subword", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/wmt14.en-fr.joined-dict.transformer.tar.bz2'", ")", ",", "\n", "'transformer.wmt16.en-de'", ":", "'https://dl.fbaipublicfiles.com/fairseq/models/wmt16.en-de.joined-dict.transformer.tar.bz2'", ",", "\n", "'transformer.wmt18.en-de'", ":", "moses_subword", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/wmt18.en-de.ensemble.tar.gz'", ")", ",", "\n", "'transformer.wmt19.en-de'", ":", "moses_fastbpe", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/wmt19.en-de.joined-dict.ensemble.tar.gz'", ")", ",", "\n", "'transformer.wmt19.en-ru'", ":", "moses_fastbpe", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/wmt19.en-ru.ensemble.tar.gz'", ")", ",", "\n", "'transformer.wmt19.de-en'", ":", "moses_fastbpe", "(", "'https://dl.fbaipublicfiles.com/fairseq/models/wmt19.de-en.joined-dict.ensemble.tar.gz'", ")", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.ModelParallelTransformerEncoder.build_encoder_layer": [[89, 91], ["fairseq.model_parallel.modules.ModelParallelTransformerEncoderLayer"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "args", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "encoder", ",", "decoder", ")", "\n", "self", ".", "args", "=", "args", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.ModelParallelTransformerDecoder.build_decoder_layer": [[99, 101], ["fairseq.model_parallel.modules.ModelParallelTransformerDecoderLayer"], "methods", ["None"], ["choices", "=", "utils", ".", "get_available_activation_fns", "(", ")", ",", "\n", "help", "=", "'activation function to use'", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.models.transformer.ModelParallelTransformerDecoder.output_layer": [[102, 117], ["copy_to_model_parallel_region", "transformer.ModelParallelTransformerDecoder.output_projection", "NotImplementedError", "getattr", "gather_from_model_parallel_region().contiguous", "gather_from_model_parallel_region"], "methods", ["None"], ["help", "=", "'dropout probability'", ")", "\n", "parser", ".", "add_argument", "(", "'--attention-dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability for attention weights'", ")", "\n", "parser", ".", "add_argument", "(", "'--activation-dropout'", ",", "'--relu-dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability after activation in FFN.'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-embed-path'", ",", "type", "=", "str", ",", "metavar", "=", "'STR'", ",", "\n", "help", "=", "'path to pre-trained encoder embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'encoder embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-ffn-embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'encoder embedding dimension for FFN'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-layers'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'num encoder layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-attention-heads'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'num encoder attention heads'", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder-normalize-before'", ",", "action", "=", "'store_true'", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.Conv1dSubsampler.__init__": [[43, 61], ["torch.Module.__init__", "len", "torch.ModuleList", "torch.ModuleList", "torch.Conv1d", "torch.Conv1d", "enumerate"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "mid_channels", ":", "int", ",", "\n", "out_channels", ":", "int", ",", "\n", "kernel_sizes", ":", "List", "[", "int", "]", "=", "(", "3", ",", "3", ")", ",", "\n", ")", ":", "\n", "        ", "super", "(", "Conv1dSubsampler", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_layers", "=", "len", "(", "kernel_sizes", ")", "\n", "self", ".", "conv_layers", "=", "nn", ".", "ModuleList", "(", "\n", "nn", ".", "Conv1d", "(", "\n", "in_channels", "if", "i", "==", "0", "else", "mid_channels", "//", "2", ",", "\n", "mid_channels", "if", "i", "<", "self", ".", "n_layers", "-", "1", "else", "out_channels", "*", "2", ",", "\n", "k", ",", "\n", "stride", "=", "2", ",", "\n", "padding", "=", "k", "//", "2", ",", "\n", ")", "\n", "for", "i", ",", "k", "in", "enumerate", "(", "kernel_sizes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.Conv1dSubsampler.get_out_seq_lens_tensor": [[63, 70], ["in_seq_lens_tensor.clone", "range", "in_seq_lens_tensor.clone.float"], "methods", ["None"], ["", "def", "get_out_seq_lens_tensor", "(", "self", ",", "in_seq_lens_tensor", ")", ":", "\n", "        ", "if", "in_seq_lens_tensor", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "out", "=", "in_seq_lens_tensor", ".", "clone", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "n_layers", ")", ":", "\n", "            ", "out", "=", "(", "(", "out", ".", "float", "(", ")", "-", "1", ")", "/", "2", "+", "1", ")", ".", "floor", "(", ")", ".", "long", "(", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.Conv1dSubsampler.forward": [[71, 80], ["src_tokens.size", "src_tokens.transpose().contiguous", "torch.functional.glu.size", "torch.functional.glu.transpose().transpose().contiguous", "conv", "torch.functional.glu", "torch.functional.glu", "s2t_transformer.Conv1dSubsampler.get_out_seq_lens_tensor", "src_tokens.transpose", "torch.functional.glu.transpose().transpose", "torch.functional.glu.transpose"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.Conv1dSubsampler.get_out_seq_lens_tensor"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ")", ":", "\n", "        ", "bsz", ",", "in_seq_len", ",", "_", "=", "src_tokens", ".", "size", "(", ")", "# B x T x (C x D)", "\n", "x", "=", "src_tokens", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "# -> B x (C x D) x T", "\n", "for", "conv", "in", "self", ".", "conv_layers", ":", "\n", "            ", "x", "=", "conv", "(", "x", ")", "\n", "x", "=", "nn", ".", "functional", ".", "glu", "(", "x", ",", "dim", "=", "1", ")", "\n", "", "_", ",", "_", ",", "out_seq_len", "=", "x", ".", "size", "(", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "# -> T x B x (C x D)", "\n", "return", "x", ",", "self", ".", "get_out_seq_lens_tensor", "(", "src_lengths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.S2TTransformerModel.__init__": [[90, 92], ["fairseq.models.FairseqEncoderDecoderModel.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "encoder", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.S2TTransformerModel.add_args": [[93, 205], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "fairseq.utils.get_available_activation_fns"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_available_activation_fns"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "# input", "\n", "parser", ".", "add_argument", "(", "\n", "\"--conv-kernel-sizes\"", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"kernel sizes of Conv1d subsampling layers\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--conv-channels\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"# of channels in Conv1d subsampling layers\"", ",", "\n", ")", "\n", "# Transformer", "\n", "parser", ".", "add_argument", "(", "\n", "\"--activation-fn\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"relu\"", ",", "\n", "choices", "=", "utils", ".", "get_available_activation_fns", "(", ")", ",", "\n", "help", "=", "\"activation function to use\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dropout\"", ",", "type", "=", "float", ",", "metavar", "=", "\"D\"", ",", "help", "=", "\"dropout probability\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--attention-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability for attention weights\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--activation-dropout\"", ",", "\n", "\"--relu-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability after activation in FFN.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-embed-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"encoder embedding dimension\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-ffn-embed-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"encoder embedding dimension for FFN\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-layers\"", ",", "type", "=", "int", ",", "metavar", "=", "\"N\"", ",", "help", "=", "\"num encoder layers\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-attention-heads\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"num encoder attention heads\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-normalize-before\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"apply layernorm before each encoder block\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-embed-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"decoder embedding dimension\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-ffn-embed-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"decoder embedding dimension for FFN\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-layers\"", ",", "type", "=", "int", ",", "metavar", "=", "\"N\"", ",", "help", "=", "\"num decoder layers\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-attention-heads\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"num decoder attention heads\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-normalize-before\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"apply layernorm before each decoder block\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--share-decoder-input-output-embed\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"share decoder input and output embeddings\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--layernorm-embedding\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"add layernorm to embedding\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no-scale-embedding\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if True, dont scale embeddings\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--load-pretrained-encoder-from\"", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"STR\"", ",", "\n", "help", "=", "\"model to take encoder weights from (for initialization)\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.S2TTransformerModel.build_encoder": [[207, 219], ["s2t_transformer.S2TTransformerEncoder", "getattr", "fairseq.checkpoint_utils.load_pretrained_component_from_model", "logger.info"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_pretrained_component_from_model"], ["", "@", "classmethod", "\n", "def", "build_encoder", "(", "cls", ",", "args", ")", ":", "\n", "        ", "encoder", "=", "S2TTransformerEncoder", "(", "args", ")", "\n", "if", "getattr", "(", "args", ",", "\"load_pretrained_encoder_from\"", ",", "None", ")", ":", "\n", "            ", "encoder", "=", "checkpoint_utils", ".", "load_pretrained_component_from_model", "(", "\n", "component", "=", "encoder", ",", "checkpoint", "=", "args", ".", "load_pretrained_encoder_from", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "f\"loaded pretrained encoder from: \"", "\n", "f\"{args.load_pretrained_encoder_from}\"", "\n", ")", "\n", "", "return", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.S2TTransformerModel.build_decoder": [[220, 223], ["s2t_transformer.TransformerDecoderScriptable"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_decoder", "(", "cls", ",", "args", ",", "task", ",", "embed_tokens", ")", ":", "\n", "        ", "return", "TransformerDecoderScriptable", "(", "args", ",", "task", ".", "target_dictionary", ",", "embed_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.S2TTransformerModel.build_model": [[224, 242], ["s2t_transformer.base_architecture", "s2t_transformer.S2TTransformerModel.build_model.build_embedding"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.build_embedding"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "\n", "# make sure all arguments are present in older models", "\n", "base_architecture", "(", "args", ")", "\n", "\n", "def", "build_embedding", "(", "dictionary", ",", "embed_dim", ")", ":", "\n", "            ", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "return", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "padding_idx", ")", "\n", "\n", "", "decoder_embed_tokens", "=", "build_embedding", "(", "\n", "task", ".", "target_dictionary", ",", "args", ".", "decoder_embed_dim", "\n", ")", "\n", "encoder", "=", "cls", ".", "build_encoder", "(", "args", ")", "\n", "decoder", "=", "cls", ".", "build_decoder", "(", "args", ",", "task", ",", "decoder_embed_tokens", ")", "\n", "return", "cls", "(", "encoder", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.S2TTransformerModel.get_normalized_probs": [[243, 253], ["s2t_transformer.S2TTransformerModel.get_normalized_probs_scriptable"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.get_normalized_probs_scriptable"], ["", "def", "get_normalized_probs", "(", "\n", "self", ",", "\n", "net_output", ":", "Tuple", "[", "Tensor", ",", "Optional", "[", "Dict", "[", "str", ",", "List", "[", "Optional", "[", "Tensor", "]", "]", "]", "]", "]", ",", "\n", "log_probs", ":", "bool", ",", "\n", "sample", ":", "Optional", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "# net_output['encoder_out'] is a (B, T, D) tensor", "\n", "        ", "lprobs", "=", "self", ".", "get_normalized_probs_scriptable", "(", "net_output", ",", "log_probs", ",", "sample", ")", "\n", "lprobs", ".", "batch_first", "=", "True", "\n", "return", "lprobs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.S2TTransformerModel.forward": [[254, 265], ["s2t_transformer.S2TTransformerModel.encoder", "s2t_transformer.S2TTransformerModel.decoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ")", ":", "\n", "        ", "\"\"\"\n        The forward method inherited from the base class has a **kwargs\n        argument in its input, which is not supported in torchscript. This\n        method overrites the forward method definition without **kwargs.\n        \"\"\"", "\n", "encoder_out", "=", "self", ".", "encoder", "(", "src_tokens", "=", "src_tokens", ",", "src_lengths", "=", "src_lengths", ")", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "\n", "prev_output_tokens", "=", "prev_output_tokens", ",", "encoder_out", "=", "encoder_out", "\n", ")", "\n", "return", "decoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.S2TTransformerEncoder.__init__": [[271, 300], ["fairseq.models.FairseqEncoder.__init__", "fairseq.modules.FairseqDropout", "math.sqrt", "s2t_transformer.Conv1dSubsampler", "fairseq.modules.PositionalEmbedding", "torch.ModuleList", "torch.ModuleList", "fairseq.modules.LayerNorm", "int", "fairseq.modules.TransformerEncoderLayer", "args.conv_kernel_sizes.split", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.PositionalEmbedding", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "None", ")", "\n", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "p", "=", "args", ".", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "embed_scale", "=", "math", ".", "sqrt", "(", "args", ".", "encoder_embed_dim", ")", "\n", "if", "args", ".", "no_scale_embedding", ":", "\n", "            ", "self", ".", "embed_scale", "=", "1.0", "\n", "", "self", ".", "padding_idx", "=", "1", "\n", "\n", "self", ".", "subsample", "=", "Conv1dSubsampler", "(", "\n", "args", ".", "input_feat_per_channel", "*", "args", ".", "input_channels", ",", "\n", "args", ".", "conv_channels", ",", "\n", "args", ".", "encoder_embed_dim", ",", "\n", "[", "int", "(", "k", ")", "for", "k", "in", "args", ".", "conv_kernel_sizes", ".", "split", "(", "\",\"", ")", "]", ",", "\n", ")", "\n", "\n", "self", ".", "embed_positions", "=", "PositionalEmbedding", "(", "\n", "args", ".", "max_source_positions", ",", "args", ".", "encoder_embed_dim", ",", "self", ".", "padding_idx", "\n", ")", "\n", "\n", "self", ".", "transformer_layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "TransformerEncoderLayer", "(", "args", ")", "for", "_", "in", "range", "(", "args", ".", "encoder_layers", ")", "]", "\n", ")", "\n", "if", "args", ".", "encoder_normalize_before", ":", "\n", "            ", "self", ".", "layer_norm", "=", "LayerNorm", "(", "args", ".", "encoder_embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer_norm", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.S2TTransformerEncoder.forward": [[301, 326], ["s2t_transformer.S2TTransformerEncoder.subsample", "fairseq.data.data_utils.lengths_to_padding_mask", "s2t_transformer.S2TTransformerEncoder.embed_positions().transpose", "s2t_transformer.S2TTransformerEncoder.dropout_module", "fairseq.models.fairseq_encoder.EncoderOut", "layer", "fairseq.data.data_utils.lengths_to_padding_mask.any", "s2t_transformer.S2TTransformerEncoder.layer_norm", "s2t_transformer.S2TTransformerEncoder.embed_positions"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils.lengths_to_padding_mask"], ["", "", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ")", ":", "\n", "        ", "x", ",", "input_lengths", "=", "self", ".", "subsample", "(", "src_tokens", ",", "src_lengths", ")", "\n", "x", "=", "self", ".", "embed_scale", "*", "x", "\n", "\n", "encoder_padding_mask", "=", "lengths_to_padding_mask", "(", "input_lengths", ")", "\n", "positions", "=", "self", ".", "embed_positions", "(", "encoder_padding_mask", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "x", "+=", "positions", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "\n", "for", "layer", "in", "self", ".", "transformer_layers", ":", "\n", "            ", "x", "=", "layer", "(", "x", ",", "encoder_padding_mask", ")", "\n", "\n", "", "if", "not", "encoder_padding_mask", ".", "any", "(", ")", ":", "\n", "            ", "encoder_padding_mask", "=", "None", "\n", "\n", "", "if", "self", ".", "layer_norm", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "", "return", "EncoderOut", "(", "\n", "encoder_out", "=", "x", ",", "\n", "encoder_padding_mask", "=", "encoder_padding_mask", ",", "\n", "encoder_embedding", "=", "None", ",", "\n", "encoder_states", "=", "None", ",", "\n", "src_tokens", "=", "None", ",", "\n", "src_lengths", "=", "None", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.S2TTransformerEncoder.reorder_encoder_out": [[328, 369], ["fairseq.models.fairseq_encoder.EncoderOut", "encoder_out.encoder_out.index_select", "encoder_padding_mask.index_select", "encoder_embedding.index_select", "enumerate", "state.index_select"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "reorder_encoder_out", "(", "self", ",", "encoder_out", ":", "EncoderOut", ",", "new_order", ")", ":", "\n", "        ", "\"\"\"\n        Since encoder_padding_mask and encoder_embedding are both of type\n        Optional[Tensor] in EncoderOut, they need to be copied as local\n        variables for Torchscript Optional refinement\n        \"\"\"", "\n", "\n", "encoder_padding_mask", ":", "Optional", "[", "Tensor", "]", "=", "encoder_out", ".", "encoder_padding_mask", "\n", "encoder_embedding", ":", "Optional", "[", "Tensor", "]", "=", "encoder_out", ".", "encoder_embedding", "\n", "\n", "new_encoder_out", "=", "(", "\n", "encoder_out", ".", "encoder_out", "\n", "if", "encoder_out", ".", "encoder_out", "is", "None", "\n", "else", "encoder_out", ".", "encoder_out", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", ")", "\n", "\n", "new_encoder_padding_mask", "=", "(", "\n", "encoder_padding_mask", "\n", "if", "encoder_padding_mask", "is", "None", "\n", "else", "encoder_padding_mask", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", ")", "\n", "\n", "new_encoder_embedding", "=", "(", "\n", "encoder_embedding", "\n", "if", "encoder_embedding", "is", "None", "\n", "else", "encoder_embedding", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", ")", "\n", "\n", "encoder_states", "=", "encoder_out", ".", "encoder_states", "\n", "if", "encoder_states", "is", "not", "None", ":", "\n", "            ", "for", "idx", ",", "state", "in", "enumerate", "(", "encoder_states", ")", ":", "\n", "                ", "encoder_states", "[", "idx", "]", "=", "state", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", "\n", "", "", "return", "EncoderOut", "(", "\n", "encoder_out", "=", "new_encoder_out", ",", "# T x B x C", "\n", "encoder_padding_mask", "=", "new_encoder_padding_mask", ",", "# B x T", "\n", "encoder_embedding", "=", "new_encoder_embedding", ",", "# B x T x C", "\n", "encoder_states", "=", "encoder_states", ",", "# List[T x B x C]", "\n", "src_tokens", "=", "None", ",", "\n", "src_lengths", "=", "None", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.TransformerDecoderScriptable.extract_features": [[373, 392], ["s2t_transformer.TransformerDecoderScriptable.extract_features_scriptable"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.transformer.TransformerDecoder.extract_features_scriptable"], ["    ", "def", "extract_features", "(", "\n", "self", ",", "\n", "prev_output_tokens", ",", "\n", "encoder_out", ":", "Optional", "[", "EncoderOut", "]", "=", "None", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", "=", "None", ",", "\n", "full_context_alignment", ":", "bool", "=", "False", ",", "\n", "alignment_layer", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "alignment_heads", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "# call scriptable method from parent class", "\n", "        ", "x", ",", "_", "=", "self", ".", "extract_features_scriptable", "(", "\n", "prev_output_tokens", ",", "\n", "encoder_out", ",", "\n", "incremental_state", ",", "\n", "full_context_alignment", ",", "\n", "alignment_layer", ",", "\n", "alignment_heads", ",", "\n", ")", "\n", "return", "x", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.base_architecture": [[394, 433], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "", "@", "register_model_architecture", "(", "model_name", "=", "\"s2t_transformer\"", ",", "arch_name", "=", "\"s2t_transformer\"", ")", "\n", "def", "base_architecture", "(", "args", ")", ":", "\n", "# Convolutional subsampler", "\n", "    ", "args", ".", "conv_kernel_sizes", "=", "getattr", "(", "args", ",", "\"conv_kernel_sizes\"", ",", "\"5,5\"", ")", "\n", "args", ".", "conv_channels", "=", "getattr", "(", "args", ",", "\"conv_channels\"", ",", "1024", ")", "\n", "# Transformer", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "2048", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "12", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "encoder_normalize_before", "=", "getattr", "(", "args", ",", "\"encoder_normalize_before\"", ",", "True", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "args", ".", "encoder_embed_dim", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "args", ".", "encoder_ffn_embed_dim", "\n", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "6", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "decoder_normalize_before", "=", "getattr", "(", "args", ",", "\"decoder_normalize_before\"", ",", "True", ")", "\n", "args", ".", "decoder_learned_pos", "=", "getattr", "(", "args", ",", "\"decoder_learned_pos\"", ",", "False", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "args", ".", "dropout", ")", "\n", "args", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "args", ".", "dropout", ")", "\n", "args", ".", "activation_fn", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"relu\"", ")", "\n", "args", ".", "adaptive_softmax_cutoff", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_cutoff\"", ",", "None", ")", "\n", "args", ".", "adaptive_softmax_dropout", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_dropout\"", ",", "0", ")", "\n", "args", ".", "share_decoder_input_output_embed", "=", "getattr", "(", "\n", "args", ",", "\"share_decoder_input_output_embed\"", ",", "True", "\n", ")", "\n", "args", ".", "no_token_positional_embeddings", "=", "getattr", "(", "\n", "args", ",", "\"no_token_positional_embeddings\"", ",", "False", "\n", ")", "\n", "args", ".", "adaptive_input", "=", "getattr", "(", "args", ",", "\"adaptive_input\"", ",", "False", ")", "\n", "args", ".", "decoder_layerdrop", "=", "getattr", "(", "args", ",", "\"decoder_layerdrop\"", ",", "0.0", ")", "\n", "args", ".", "decoder_output_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_output_dim\"", ",", "args", ".", "decoder_embed_dim", "\n", ")", "\n", "args", ".", "decoder_input_dim", "=", "getattr", "(", "args", ",", "\"decoder_input_dim\"", ",", "args", ".", "decoder_embed_dim", ")", "\n", "args", ".", "no_scale_embedding", "=", "getattr", "(", "args", ",", "\"no_scale_embedding\"", ",", "False", ")", "\n", "args", ".", "quant_noise_pq", "=", "getattr", "(", "args", ",", "\"quant_noise_pq\"", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.s2t_transformer_s": [[435, 443], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "s2t_transformer.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "@", "register_model_architecture", "(", "\"s2t_transformer\"", ",", "\"s2t_transformer_s\"", ")", "\n", "def", "s2t_transformer_s", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "256", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "256", "*", "8", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "4", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "4", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "base_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.s2t_transformer_sp": [[445, 449], ["fairseq.models.register_model_architecture", "getattr", "s2t_transformer.s2t_transformer_s"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.s2t_transformer_s"], ["", "@", "register_model_architecture", "(", "\"s2t_transformer\"", ",", "\"s2t_transformer_sp\"", ")", "\n", "def", "s2t_transformer_sp", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "16", ")", "\n", "s2t_transformer_s", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.s2t_transformer_m": [[451, 459], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "s2t_transformer.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "@", "register_model_architecture", "(", "\"s2t_transformer\"", ",", "\"s2t_transformer_m\"", ")", "\n", "def", "s2t_transformer_m", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "512", "*", "4", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.15", ")", "\n", "base_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.s2t_transformer_mp": [[461, 465], ["fairseq.models.register_model_architecture", "getattr", "s2t_transformer.s2t_transformer_m"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.s2t_transformer_m"], ["", "@", "register_model_architecture", "(", "\"s2t_transformer\"", ",", "\"s2t_transformer_mp\"", ")", "\n", "def", "s2t_transformer_mp", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "16", ")", "\n", "s2t_transformer_m", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.s2t_transformer_l": [[467, 475], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "s2t_transformer.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "@", "register_model_architecture", "(", "\"s2t_transformer\"", ",", "\"s2t_transformer_l\"", ")", "\n", "def", "s2t_transformer_l", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "1024", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "1024", "*", "4", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "16", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "16", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.2", ")", "\n", "base_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.s2t_transformer_lp": [[477, 481], ["fairseq.models.register_model_architecture", "getattr", "s2t_transformer.s2t_transformer_l"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_transformer.s2t_transformer_l"], ["", "@", "register_model_architecture", "(", "\"s2t_transformer\"", ",", "\"s2t_transformer_lp\"", ")", "\n", "def", "s2t_transformer_lp", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "16", ")", "\n", "s2t_transformer_l", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.BerardModel.__init__": [[37, 39], ["fairseq.models.FairseqEncoderDecoderModel.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "encoder", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.BerardModel.add_args": [[40, 121], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "\n", "\"--input-layers\"", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"EXPR\"", ",", "\n", "help", "=", "\"List of linear layer dimensions. These \"", "\n", "\"layers are applied to the input features and \"", "\n", "\"are followed by tanh and possibly dropout.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"Dropout probability to use in the encoder/decoder. \"", "\n", "\"Note that this parameters control dropout in various places, \"", "\n", "\"there is no fine-grained control for dropout for embeddings \"", "\n", "\"vs LSTM layers for example.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--in-channels\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"Number of encoder input channels. \"", "\"Typically value is 1.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--conv-layers\"", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"EXPR\"", ",", "\n", "help", "=", "\"List of conv layers \"", "\"(format: (channels, kernel, stride)).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num-blstm-layers\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"Number of encoder bi-LSTM layers.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lstm-size\"", ",", "type", "=", "int", ",", "metavar", "=", "\"N\"", ",", "help", "=", "\"LSTM hidden size.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-embed-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"Embedding dimension of the decoder target tokens.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-hidden-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"Decoder LSTM hidden dimension.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-num-layers\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"Number of decoder LSTM layers.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--attention-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"Hidden layer dimension in MLP attention.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output-layer-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"Hidden layer dim for linear layer prior to output projection.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--load-pretrained-encoder-from\"", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"STR\"", ",", "\n", "help", "=", "\"model to take encoder weights from (for initialization)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--load-pretrained-decoder-from\"", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"STR\"", ",", "\n", "help", "=", "\"model to take decoder weights from (for initialization)\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.BerardModel.build_encoder": [[123, 139], ["berard.BerardEncoder", "getattr", "fairseq.checkpoint_utils.load_pretrained_component_from_model", "ast.literal_eval", "ast.literal_eval"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_pretrained_component_from_model"], ["", "@", "classmethod", "\n", "def", "build_encoder", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "encoder", "=", "BerardEncoder", "(", "\n", "input_layers", "=", "literal_eval", "(", "args", ".", "input_layers", ")", ",", "\n", "conv_layers", "=", "literal_eval", "(", "args", ".", "conv_layers", ")", ",", "\n", "in_channels", "=", "args", ".", "input_channels", ",", "\n", "input_feat_per_channel", "=", "args", ".", "input_feat_per_channel", ",", "\n", "num_blstm_layers", "=", "args", ".", "num_blstm_layers", ",", "\n", "lstm_size", "=", "args", ".", "lstm_size", ",", "\n", "dropout", "=", "args", ".", "dropout", ",", "\n", ")", "\n", "if", "getattr", "(", "args", ",", "\"load_pretrained_encoder_from\"", ",", "None", ")", ":", "\n", "            ", "encoder", "=", "checkpoint_utils", ".", "load_pretrained_component_from_model", "(", "\n", "component", "=", "encoder", ",", "checkpoint", "=", "args", ".", "load_pretrained_encoder_from", "\n", ")", "\n", "", "return", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.BerardModel.build_decoder": [[140, 157], ["berard.LSTMDecoder", "getattr", "fairseq.checkpoint_utils.load_pretrained_component_from_model"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_pretrained_component_from_model"], ["", "@", "classmethod", "\n", "def", "build_decoder", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "decoder", "=", "LSTMDecoder", "(", "\n", "dictionary", "=", "task", ".", "target_dictionary", ",", "\n", "embed_dim", "=", "args", ".", "decoder_embed_dim", ",", "\n", "num_layers", "=", "args", ".", "decoder_num_layers", ",", "\n", "hidden_size", "=", "args", ".", "decoder_hidden_dim", ",", "\n", "dropout", "=", "args", ".", "dropout", ",", "\n", "encoder_output_dim", "=", "2", "*", "args", ".", "lstm_size", ",", "# bidirectional", "\n", "attention_dim", "=", "args", ".", "attention_dim", ",", "\n", "output_layer_dim", "=", "args", ".", "output_layer_dim", ",", "\n", ")", "\n", "if", "getattr", "(", "args", ",", "\"load_pretrained_decoder_from\"", ",", "None", ")", ":", "\n", "            ", "decoder", "=", "checkpoint_utils", ".", "load_pretrained_component_from_model", "(", "\n", "component", "=", "decoder", ",", "checkpoint", "=", "args", ".", "load_pretrained_decoder_from", "\n", ")", "\n", "", "return", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.BerardModel.build_model": [[158, 165], ["cls.build_encoder", "cls.build_decoder", "cls"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.build_encoder", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.build_decoder", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "encoder", "=", "cls", ".", "build_encoder", "(", "args", ",", "task", ")", "\n", "decoder", "=", "cls", ".", "build_decoder", "(", "args", ",", "task", ")", "\n", "\n", "return", "cls", "(", "encoder", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.BerardModel.get_normalized_probs": [[166, 172], ["super().get_normalized_probs"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.get_normalized_probs"], ["", "def", "get_normalized_probs", "(", "self", ",", "net_output", ",", "log_probs", ",", "sample", "=", "None", ")", ":", "\n", "# net_output['encoder_out'] is a (B, T, D) tensor", "\n", "        ", "lprobs", "=", "super", "(", ")", ".", "get_normalized_probs", "(", "net_output", ",", "log_probs", ",", "sample", ")", "\n", "# lprobs is a (B, T, D) tensor", "\n", "lprobs", ".", "batch_first", "=", "True", "\n", "return", "lprobs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.BerardEncoder.__init__": [[175, 251], ["fairseq.models.FairseqEncoder.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.LSTM", "torch.LSTM", "torch.LSTM", "berard.BerardEncoder.conv_layers.append", "berard.BerardEncoder.conv_kernel_sizes_and_strides.append", "torch.Dropout", "torch.Dropout", "torch.Dropout", "berard.BerardEncoder.input_layers.append", "berard.BerardEncoder.input_layers.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTM", "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTM", "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTM", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "input_layers", ":", "List", "[", "int", "]", ",", "\n", "conv_layers", ":", "List", "[", "Tuple", "[", "int", "]", "]", ",", "\n", "in_channels", ":", "int", ",", "\n", "input_feat_per_channel", ":", "int", ",", "\n", "num_blstm_layers", ":", "int", ",", "\n", "lstm_size", ":", "int", ",", "\n", "dropout", ":", "float", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input_layers: list of linear layer dimensions. These layers are\n                applied to the input features and are followed by tanh and\n                possibly dropout.\n            conv_layers: list of conv2d layer configurations. A configuration is\n                a tuple (out_channels, conv_kernel_size, stride).\n            in_channels: number of input channels.\n            input_feat_per_channel: number of input features per channel. These\n                are speech features, typically 40 or 80.\n            num_blstm_layers: number of bidirectional LSTM layers.\n            lstm_size: size of the LSTM hidden (and cell) size.\n            dropout: dropout probability. Dropout can be applied after the\n                linear layers and LSTM layers but not to the convolutional\n                layers.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "None", ")", "\n", "\n", "self", ".", "input_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "in_features", "=", "input_feat_per_channel", "\n", "for", "out_features", "in", "input_layers", ":", "\n", "            ", "if", "dropout", ">", "0", ":", "\n", "                ", "self", ".", "input_layers", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ")", ",", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "input_layers", ".", "append", "(", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ")", ")", "\n", "", "in_features", "=", "out_features", "\n", "\n", "", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "input_dim", "=", "input_feat_per_channel", "\n", "self", ".", "conv_kernel_sizes_and_strides", "=", "[", "]", "\n", "self", ".", "conv_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "lstm_input_dim", "=", "input_layers", "[", "-", "1", "]", "\n", "for", "conv_layer", "in", "conv_layers", ":", "\n", "            ", "out_channels", ",", "conv_kernel_size", ",", "conv_stride", "=", "conv_layer", "\n", "self", ".", "conv_layers", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "conv_kernel_size", ",", "\n", "stride", "=", "conv_stride", ",", "\n", "padding", "=", "conv_kernel_size", "//", "2", ",", "\n", ")", "\n", ")", "\n", "self", ".", "conv_kernel_sizes_and_strides", ".", "append", "(", "(", "conv_kernel_size", ",", "conv_stride", ")", ")", "\n", "in_channels", "=", "out_channels", "\n", "lstm_input_dim", "//=", "conv_stride", "\n", "\n", "", "lstm_input_dim", "*=", "conv_layers", "[", "-", "1", "]", "[", "0", "]", "\n", "self", ".", "lstm_size", "=", "lstm_size", "\n", "self", ".", "num_blstm_layers", "=", "num_blstm_layers", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "\n", "input_size", "=", "lstm_input_dim", ",", "\n", "hidden_size", "=", "lstm_size", ",", "\n", "num_layers", "=", "num_blstm_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bidirectional", "=", "True", ",", "\n", ")", "\n", "self", ".", "output_dim", "=", "2", "*", "lstm_size", "# bidirectional", "\n", "if", "dropout", ">", "0", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.BerardEncoder.forward": [[252, 303], ["src_tokens.size", "src_tokens.view().transpose().contiguous", "berard.BerardEncoder.size", "berard.BerardEncoder.transpose().transpose().contiguous().view", "src_lengths.clone", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "berard.BerardEncoder.new().zero_", "berard.BerardEncoder.new().zero_", "berard.BerardEncoder.lstm", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "fairseq.data.data_utils.lengths_to_padding_mask().to().t", "input_layer", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "conv_layer", "input_lengths.floor().long.floor().long.floor().long", "berard.BerardEncoder.dropout", "src_tokens.view().transpose", "berard.BerardEncoder.transpose().transpose().contiguous", "berard.BerardEncoder.new", "berard.BerardEncoder.new", "fairseq.data.data_utils.lengths_to_padding_mask().to", "input_lengths.floor().long.floor().long.floor", "src_tokens.view", "berard.BerardEncoder.transpose().transpose", "fairseq.data.data_utils.lengths_to_padding_mask", "input_lengths.floor().long.floor().long.float", "berard.BerardEncoder.transpose"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.lengths_to_padding_mask"], ["", "", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args\n            src_tokens: padded tensor (B, T, C * feat)\n            src_lengths: tensor of original lengths of input utterances (B,)\n        \"\"\"", "\n", "bsz", ",", "max_seq_len", ",", "_", "=", "src_tokens", ".", "size", "(", ")", "\n", "# (B, C, T, feat)", "\n", "x", "=", "(", "\n", "src_tokens", ".", "view", "(", "bsz", ",", "max_seq_len", ",", "self", ".", "in_channels", ",", "self", ".", "input_dim", ")", "\n", ".", "transpose", "(", "1", ",", "2", ")", "\n", ".", "contiguous", "(", ")", "\n", ")", "\n", "\n", "for", "input_layer", "in", "self", ".", "input_layers", ":", "\n", "            ", "x", "=", "input_layer", "(", "x", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "\n", "", "for", "conv_layer", "in", "self", ".", "conv_layers", ":", "\n", "            ", "x", "=", "conv_layer", "(", "x", ")", "\n", "\n", "", "bsz", ",", "_", ",", "output_seq_len", ",", "_", "=", "x", ".", "size", "(", ")", "\n", "\n", "# (B, C, T, feat) -> (B, T, C, feat) -> (T, B, C, feat) ->", "\n", "# (T, B, C * feat)", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "output_seq_len", ",", "bsz", ",", "-", "1", ")", "\n", "\n", "input_lengths", "=", "src_lengths", ".", "clone", "(", ")", "\n", "for", "k", ",", "s", "in", "self", ".", "conv_kernel_sizes_and_strides", ":", "\n", "            ", "p", "=", "k", "//", "2", "\n", "input_lengths", "=", "(", "input_lengths", ".", "float", "(", ")", "+", "2", "*", "p", "-", "k", ")", "/", "s", "+", "1", "\n", "input_lengths", "=", "input_lengths", ".", "floor", "(", ")", ".", "long", "(", ")", "\n", "\n", "", "packed_x", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "x", ",", "input_lengths", ")", "\n", "\n", "h0", "=", "x", ".", "new", "(", "2", "*", "self", ".", "num_blstm_layers", ",", "bsz", ",", "self", ".", "lstm_size", ")", ".", "zero_", "(", ")", "\n", "c0", "=", "x", ".", "new", "(", "2", "*", "self", ".", "num_blstm_layers", ",", "bsz", ",", "self", ".", "lstm_size", ")", ".", "zero_", "(", ")", "\n", "packed_outs", ",", "_", "=", "self", ".", "lstm", "(", "packed_x", ",", "(", "h0", ",", "c0", ")", ")", "\n", "\n", "# unpack outputs and apply dropout", "\n", "x", ",", "output_lengths", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "packed_outs", ")", "\n", "if", "self", ".", "dropout", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "\n", "", "encoder_padding_mask", "=", "(", "\n", "lengths_to_padding_mask", "(", "output_lengths", ")", ".", "to", "(", "src_tokens", ".", "device", ")", ".", "t", "(", ")", "\n", ")", "\n", "\n", "return", "{", "\n", "\"encoder_out\"", ":", "x", ",", "# (T, B, C)", "\n", "\"encoder_padding_mask\"", ":", "encoder_padding_mask", ",", "# (T, B)", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.BerardEncoder.reorder_encoder_out": [[305, 313], ["encoder_out[].index_select", "encoder_out[].index_select"], "methods", ["None"], ["", "def", "reorder_encoder_out", "(", "self", ",", "encoder_out", ",", "new_order", ")", ":", "\n", "        ", "encoder_out", "[", "\"encoder_out\"", "]", "=", "encoder_out", "[", "\"encoder_out\"", "]", ".", "index_select", "(", "\n", "1", ",", "new_order", "\n", ")", "\n", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "=", "encoder_out", "[", "\n", "\"encoder_padding_mask\"", "\n", "]", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", "return", "encoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.MLPAttention.__init__": [[323, 336], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["def", "__init__", "(", "self", ",", "decoder_hidden_state_dim", ",", "context_dim", ",", "attention_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "context_dim", "=", "context_dim", "\n", "self", ".", "attention_dim", "=", "attention_dim", "\n", "# W_ae and b_a", "\n", "self", ".", "encoder_proj", "=", "nn", ".", "Linear", "(", "context_dim", ",", "self", ".", "attention_dim", ",", "bias", "=", "True", ")", "\n", "# W_ad", "\n", "self", ".", "decoder_proj", "=", "nn", ".", "Linear", "(", "\n", "decoder_hidden_state_dim", ",", "self", ".", "attention_dim", ",", "bias", "=", "False", "\n", ")", "\n", "# V_a", "\n", "self", ".", "to_scores", "=", "nn", ".", "Linear", "(", "self", ".", "attention_dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.MLPAttention.forward": [[337, 376], ["source_hids.size", "source_hids.view", "berard.MLPAttention.encoder_proj", "encoder_component.view.view.view", "berard.MLPAttention.decoder_proj().unsqueeze", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "berard.MLPAttention.to_scores().view", "torch.softmax", "torch.softmax", "torch.softmax", "attn_scores.float().masked_fill_().type_as.float().masked_fill_().type_as.float().masked_fill_().type_as", "berard.MLPAttention.decoder_proj", "berard.MLPAttention.to_scores", "attn_scores.float().masked_fill_().type_as.float().masked_fill_().type_as.float().masked_fill_", "torch.softmax.unsqueeze", "float", "attn_scores.float().masked_fill_().type_as.float().masked_fill_().type_as.float"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax"], ["", "def", "forward", "(", "self", ",", "decoder_state", ",", "source_hids", ",", "encoder_padding_mask", ")", ":", "\n", "        ", "\"\"\"The expected input dimensions are:\n        decoder_state: bsz x decoder_hidden_state_dim\n        source_hids: src_len x bsz x context_dim\n        encoder_padding_mask: src_len x bsz\n        \"\"\"", "\n", "src_len", ",", "bsz", ",", "_", "=", "source_hids", ".", "size", "(", ")", "\n", "# (src_len*bsz) x context_dim (to feed through linear)", "\n", "flat_source_hids", "=", "source_hids", ".", "view", "(", "-", "1", ",", "self", ".", "context_dim", ")", "\n", "# (src_len*bsz) x attention_dim", "\n", "encoder_component", "=", "self", ".", "encoder_proj", "(", "flat_source_hids", ")", "\n", "# src_len x bsz x attention_dim", "\n", "encoder_component", "=", "encoder_component", ".", "view", "(", "src_len", ",", "bsz", ",", "self", ".", "attention_dim", ")", "\n", "# 1 x bsz x attention_dim", "\n", "decoder_component", "=", "self", ".", "decoder_proj", "(", "decoder_state", ")", ".", "unsqueeze", "(", "0", ")", "\n", "# Sum with broadcasting and apply the non linearity", "\n", "# src_len x bsz x attention_dim", "\n", "hidden_att", "=", "torch", ".", "tanh", "(", "\n", "(", "decoder_component", "+", "encoder_component", ")", ".", "view", "(", "-", "1", ",", "self", ".", "attention_dim", ")", "\n", ")", "\n", "# Project onto the reals to get attentions scores (src_len x bsz)", "\n", "attn_scores", "=", "self", ".", "to_scores", "(", "hidden_att", ")", ".", "view", "(", "src_len", ",", "bsz", ")", "\n", "\n", "# Mask + softmax (src_len x bsz)", "\n", "if", "encoder_padding_mask", "is", "not", "None", ":", "\n", "            ", "attn_scores", "=", "(", "\n", "attn_scores", ".", "float", "(", ")", "\n", ".", "masked_fill_", "(", "encoder_padding_mask", ",", "float", "(", "\"-inf\"", ")", ")", "\n", ".", "type_as", "(", "attn_scores", ")", "\n", ")", "# FP16 support: cast to float and back", "\n", "# srclen x bsz", "\n", "", "normalized_masked_attn_scores", "=", "F", ".", "softmax", "(", "attn_scores", ",", "dim", "=", "0", ")", "\n", "\n", "# Sum weighted sources (bsz x context_dim)", "\n", "attn_weighted_context", "=", "(", "\n", "source_hids", "*", "normalized_masked_attn_scores", ".", "unsqueeze", "(", "2", ")", "\n", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "\n", "return", "attn_weighted_context", ",", "normalized_masked_attn_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.LSTMDecoder.__init__": [[379, 433], ["fairseq.models.FairseqIncrementalDecoder.__init__", "len", "dictionary.pad", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "berard.MLPAttention", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "berard.LSTMDecoder.layers.append", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMCell", "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMCell", "home.repos.pwc.inspect_result.reneeye_const.models.lstm.LSTMCell"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "dictionary", ",", "\n", "embed_dim", ",", "\n", "num_layers", ",", "\n", "hidden_size", ",", "\n", "dropout", ",", "\n", "encoder_output_dim", ",", "\n", "attention_dim", ",", "\n", "output_layer_dim", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dictionary: target text dictionary.\n            embed_dim: embedding dimension for target tokens.\n            num_layers: number of LSTM layers.\n            hidden_size: hidden size for LSTM layers.\n            dropout: dropout probability. Dropout can be applied to the\n                embeddings, the LSTM layers, and the context vector.\n            encoder_output_dim: encoder output dimension (hidden size of\n                encoder LSTM).\n            attention_dim: attention dimension for MLP attention.\n            output_layer_dim: size of the linear layer prior to output\n                projection.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "self", ".", "embed_tokens", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "padding_idx", ")", "\n", "if", "dropout", ">", "0", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "None", "\n", "\n", "", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "layer_id", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "input_size", "=", "embed_dim", "if", "layer_id", "==", "0", "else", "encoder_output_dim", "\n", "self", ".", "layers", ".", "append", "(", "\n", "nn", ".", "LSTMCell", "(", "input_size", "=", "input_size", ",", "hidden_size", "=", "hidden_size", ")", "\n", ")", "\n", "\n", "", "self", ".", "context_dim", "=", "encoder_output_dim", "\n", "self", ".", "attention", "=", "MLPAttention", "(", "\n", "decoder_hidden_state_dim", "=", "hidden_size", ",", "\n", "context_dim", "=", "encoder_output_dim", ",", "\n", "attention_dim", "=", "attention_dim", ",", "\n", ")", "\n", "\n", "self", ".", "deep_output_layer", "=", "nn", ".", "Linear", "(", "\n", "hidden_size", "+", "encoder_output_dim", "+", "embed_dim", ",", "output_layer_dim", "\n", ")", "\n", "self", ".", "output_projection", "=", "nn", ".", "Linear", "(", "output_layer_dim", ",", "num_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.LSTMDecoder.forward": [[434, 528], ["prev_output_tokens.size", "encoder_outs.size", "berard.LSTMDecoder.embed_tokens", "berard.LSTMDecoder.transpose", "fairseq.utils.get_incremental_state", "berard.LSTMDecoder.new_zeros", "range", "fairseq.utils.set_incremental_state", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "berard.LSTMDecoder.transpose", "attention_outs_concat.transpose.transpose.transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "berard.LSTMDecoder.deep_output_layer", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "berard.LSTMDecoder.output_projection", "berard.LSTMDecoder.dropout", "enumerate", "outs.append", "berard.LSTMDecoder.dropout", "layer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "encoder_out[].mean", "berard.LSTMDecoder.new_zeros", "berard.LSTMDecoder.dropout", "berard.LSTMDecoder.attention", "attention_outs.append", "berard.LSTMDecoder.dropout"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_incremental_state", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_incremental_state"], ["", "def", "forward", "(", "\n", "self", ",", "prev_output_tokens", ",", "encoder_out", "=", "None", ",", "incremental_state", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "encoder_padding_mask", "=", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "\n", "encoder_outs", "=", "encoder_out", "[", "\"encoder_out\"", "]", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "prev_output_tokens", "=", "prev_output_tokens", "[", ":", ",", "-", "1", ":", "]", "\n", "", "bsz", ",", "seqlen", "=", "prev_output_tokens", ".", "size", "(", ")", "\n", "\n", "srclen", "=", "encoder_outs", ".", "size", "(", "0", ")", "\n", "\n", "# embed tokens", "\n", "embeddings", "=", "self", ".", "embed_tokens", "(", "prev_output_tokens", ")", "\n", "x", "=", "embeddings", "\n", "if", "self", ".", "dropout", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# initialize previous states (or get from cache during incremental", "\n", "# generation)", "\n", "cached_state", "=", "utils", ".", "get_incremental_state", "(", "\n", "self", ",", "incremental_state", ",", "\"cached_state\"", "\n", ")", "\n", "if", "cached_state", "is", "not", "None", ":", "\n", "            ", "prev_hiddens", ",", "prev_cells", "=", "cached_state", "\n", "", "else", ":", "\n", "            ", "prev_hiddens", "=", "[", "encoder_out", "[", "\"encoder_out\"", "]", ".", "mean", "(", "dim", "=", "0", ")", "]", "*", "self", ".", "num_layers", "\n", "prev_cells", "=", "[", "x", ".", "new_zeros", "(", "bsz", ",", "self", ".", "hidden_size", ")", "]", "*", "self", ".", "num_layers", "\n", "\n", "", "attn_scores", "=", "x", ".", "new_zeros", "(", "bsz", ",", "srclen", ")", "\n", "attention_outs", "=", "[", "]", "\n", "outs", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "seqlen", ")", ":", "\n", "            ", "input", "=", "x", "[", "j", ",", ":", ",", ":", "]", "\n", "attention_out", "=", "None", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "# the previous state is one layer below except for the bottom", "\n", "# layer where the previous state is the state emitted by the", "\n", "# top layer", "\n", "                ", "hidden", ",", "cell", "=", "layer", "(", "\n", "input", ",", "\n", "(", "\n", "prev_hiddens", "[", "(", "i", "-", "1", ")", "%", "self", ".", "num_layers", "]", ",", "\n", "prev_cells", "[", "(", "i", "-", "1", ")", "%", "self", ".", "num_layers", "]", ",", "\n", ")", ",", "\n", ")", "\n", "if", "self", ".", "dropout", "is", "not", "None", ":", "\n", "                    ", "hidden", "=", "self", ".", "dropout", "(", "hidden", ")", "\n", "", "prev_hiddens", "[", "i", "]", "=", "hidden", "\n", "prev_cells", "[", "i", "]", "=", "cell", "\n", "if", "attention_out", "is", "None", ":", "\n", "                    ", "attention_out", ",", "attn_scores", "=", "self", ".", "attention", "(", "\n", "hidden", ",", "encoder_outs", ",", "encoder_padding_mask", "\n", ")", "\n", "if", "self", ".", "dropout", "is", "not", "None", ":", "\n", "                        ", "attention_out", "=", "self", ".", "dropout", "(", "attention_out", ")", "\n", "", "attention_outs", ".", "append", "(", "attention_out", ")", "\n", "", "input", "=", "attention_out", "\n", "\n", "# collect the output of the top layer", "\n", "", "outs", ".", "append", "(", "hidden", ")", "\n", "\n", "# cache previous states (no-op except during incremental generation)", "\n", "", "utils", ".", "set_incremental_state", "(", "\n", "self", ",", "incremental_state", ",", "\"cached_state\"", ",", "(", "prev_hiddens", ",", "prev_cells", ")", "\n", ")", "\n", "\n", "# collect outputs across time steps", "\n", "x", "=", "torch", ".", "cat", "(", "outs", ",", "dim", "=", "0", ")", ".", "view", "(", "seqlen", ",", "bsz", ",", "self", ".", "hidden_size", ")", "\n", "attention_outs_concat", "=", "torch", ".", "cat", "(", "attention_outs", ",", "dim", "=", "0", ")", ".", "view", "(", "\n", "seqlen", ",", "bsz", ",", "self", ".", "context_dim", "\n", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "attention_outs_concat", "=", "attention_outs_concat", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# concat LSTM output, attention output and embedding", "\n", "# before output projection", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "attention_outs_concat", ",", "embeddings", ")", ",", "dim", "=", "2", ")", "\n", "x", "=", "self", ".", "deep_output_layer", "(", "x", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "if", "self", ".", "dropout", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "# project back to size of vocabulary", "\n", "", "x", "=", "self", ".", "output_projection", "(", "x", ")", "\n", "\n", "# to return the full attn_scores tensor, we need to fix the decoder", "\n", "# to account for subsampling input frames", "\n", "# return x, attn_scores", "\n", "return", "x", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.LSTMDecoder.reorder_incremental_state": [[529, 544], ["super().reorder_incremental_state", "fairseq.utils.get_incremental_state", "tuple", "fairseq.utils.set_incremental_state", "isinstance", "state.index_select", "map", "berard.LSTMDecoder.reorder_incremental_state.reorder_state"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.LSTMDecoder.reorder_incremental_state", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_incremental_state", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_incremental_state"], ["", "def", "reorder_incremental_state", "(", "self", ",", "incremental_state", ",", "new_order", ")", ":", "\n", "        ", "super", "(", ")", ".", "reorder_incremental_state", "(", "incremental_state", ",", "new_order", ")", "\n", "cached_state", "=", "utils", ".", "get_incremental_state", "(", "\n", "self", ",", "incremental_state", ",", "\"cached_state\"", "\n", ")", "\n", "if", "cached_state", "is", "None", ":", "\n", "            ", "return", "\n", "\n", "", "def", "reorder_state", "(", "state", ")", ":", "\n", "            ", "if", "isinstance", "(", "state", ",", "list", ")", ":", "\n", "                ", "return", "[", "reorder_state", "(", "state_i", ")", "for", "state_i", "in", "state", "]", "\n", "", "return", "state", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", "\n", "", "new_state", "=", "tuple", "(", "map", "(", "reorder_state", ",", "cached_state", ")", ")", "\n", "utils", ".", "set_incremental_state", "(", "self", ",", "incremental_state", ",", "\"cached_state\"", ",", "new_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.berard": [[546, 566], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "", "@", "register_model_architecture", "(", "model_name", "=", "\"s2t_berard\"", ",", "arch_name", "=", "\"s2t_berard\"", ")", "\n", "def", "berard", "(", "args", ")", ":", "\n", "    ", "\"\"\"The original version: \"End-to-End Automatic Speech Translation of\n    Audiobooks\" (https://arxiv.org/abs/1802.04200)\n    \"\"\"", "\n", "args", ".", "input_layers", "=", "getattr", "(", "args", ",", "\"input_layers\"", ",", "\"[256, 128]\"", ")", "\n", "args", ".", "conv_layers", "=", "getattr", "(", "args", ",", "\"conv_layers\"", ",", "\"[(16, 3, 2), (16, 3, 2)]\"", ")", "\n", "args", ".", "num_blstm_layers", "=", "getattr", "(", "args", ",", "\"num_blstm_layers\"", ",", "3", ")", "\n", "args", ".", "lstm_size", "=", "getattr", "(", "args", ",", "\"lstm_size\"", ",", "256", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.2", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "128", ")", "\n", "args", ".", "decoder_num_layers", "=", "getattr", "(", "args", ",", "\"decoder_num_layers\"", ",", "2", ")", "\n", "args", ".", "decoder_hidden_dim", "=", "getattr", "(", "args", ",", "\"decoder_hidden_dim\"", ",", "512", ")", "\n", "args", ".", "attention_dim", "=", "getattr", "(", "args", ",", "\"attention_dim\"", ",", "512", ")", "\n", "args", ".", "output_layer_dim", "=", "getattr", "(", "args", ",", "\"output_layer_dim\"", ",", "128", ")", "\n", "args", ".", "load_pretrained_encoder_from", "=", "getattr", "(", "\n", "args", ",", "\"load_pretrained_encoder_from\"", ",", "None", "\n", ")", "\n", "args", ".", "load_pretrained_decoder_from", "=", "getattr", "(", "\n", "args", ",", "\"load_pretrained_decoder_from\"", ",", "None", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.berard_256_3_3": [[569, 581], ["fairseq.models.register_model_architecture", "getattr", "berard.berard"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.berard"], ["", "@", "register_model_architecture", "(", "model_name", "=", "\"s2t_berard\"", ",", "arch_name", "=", "\"s2t_berard_256_3_3\"", ")", "\n", "def", "berard_256_3_3", "(", "args", ")", ":", "\n", "    ", "\"\"\"Used in\n    * \"Harnessing Indirect Training Data for End-to-End Automatic Speech\n    Translation: Tricks of the Trade\" (https://arxiv.org/abs/1909.06515)\n    * \"CoVoST: A Diverse Multilingual Speech-To-Text Translation Corpus\"\n    (https://arxiv.org/pdf/2002.01320.pdf)\n    * \"Self-Supervised Representations Improve End-to-End Speech Translation\"\n    (https://arxiv.org/abs/2006.12124)\n    \"\"\"", "\n", "args", ".", "decoder_num_layers", "=", "getattr", "(", "args", ",", "\"decoder_num_layers\"", ",", "3", ")", "\n", "berard", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.berard_512_3_2": [[583, 594], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "berard.berard"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.berard"], ["", "@", "register_model_architecture", "(", "model_name", "=", "\"s2t_berard\"", ",", "arch_name", "=", "\"s2t_berard_512_3_2\"", ")", "\n", "def", "berard_512_3_2", "(", "args", ")", ":", "\n", "    ", "args", ".", "num_blstm_layers", "=", "getattr", "(", "args", ",", "\"num_blstm_layers\"", ",", "3", ")", "\n", "args", ".", "lstm_size", "=", "getattr", "(", "args", ",", "\"lstm_size\"", ",", "512", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.3", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "256", ")", "\n", "args", ".", "decoder_num_layers", "=", "getattr", "(", "args", ",", "\"decoder_num_layers\"", ",", "2", ")", "\n", "args", ".", "decoder_hidden_dim", "=", "getattr", "(", "args", ",", "\"decoder_hidden_dim\"", ",", "1024", ")", "\n", "args", ".", "attention_dim", "=", "getattr", "(", "args", ",", "\"attention_dim\"", ",", "512", ")", "\n", "args", ".", "output_layer_dim", "=", "getattr", "(", "args", ",", "\"output_layer_dim\"", ",", "256", ")", "\n", "berard", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.berard_512_5_3": [[596, 607], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "berard.berard"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.berard.berard"], ["", "@", "register_model_architecture", "(", "model_name", "=", "\"s2t_berard\"", ",", "arch_name", "=", "\"s2t_berard_512_5_3\"", ")", "\n", "def", "berard_512_5_3", "(", "args", ")", ":", "\n", "    ", "args", ".", "num_blstm_layers", "=", "getattr", "(", "args", ",", "\"num_blstm_layers\"", ",", "5", ")", "\n", "args", ".", "lstm_size", "=", "getattr", "(", "args", ",", "\"lstm_size\"", ",", "512", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.3", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "256", ")", "\n", "args", ".", "decoder_num_layers", "=", "getattr", "(", "args", ",", "\"decoder_num_layers\"", ",", "3", ")", "\n", "args", ".", "decoder_hidden_dim", "=", "getattr", "(", "args", ",", "\"decoder_hidden_dim\"", ",", "1024", ")", "\n", "args", ".", "attention_dim", "=", "getattr", "(", "args", ",", "\"attention_dim\"", ",", "512", ")", "\n", "args", ".", "output_layer_dim", "=", "getattr", "(", "args", ",", "\"output_layer_dim\"", ",", "256", ")", "\n", "berard", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_w2v2_transformer.S2TTransformerModelW2V2.__init__": [[44, 46], ["fairseq.models.FairseqEncoderDecoderModel.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "encoder", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_w2v2_transformer.S2TTransformerModelW2V2.add_args": [[47, 165], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "fairseq.utils.get_available_activation_fns"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_available_activation_fns"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "# input", "\n", "parser", ".", "add_argument", "(", "\"--w2v2-model-path\"", ",", "type", "=", "str", ",", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"path/to/wav2vec/model, support hdfs\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--freeze-w2v\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if we want to freeze the w2v features\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use-asr-finetune-w2v\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if we want to load wav2vec2.0 asr finetuned data\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--conv-kernel-sizes\"", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"kernel sizes of Conv1d subsampling layers\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--conv-channels\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"# of channels in Conv1d subsampling layers\"", ",", "\n", ")", "\n", "# Transformer", "\n", "parser", ".", "add_argument", "(", "\n", "\"--activation-fn\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"relu\"", ",", "\n", "choices", "=", "utils", ".", "get_available_activation_fns", "(", ")", ",", "\n", "help", "=", "\"activation function to use\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dropout\"", ",", "type", "=", "float", ",", "metavar", "=", "\"D\"", ",", "help", "=", "\"dropout probability\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--attention-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability for attention weights\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--activation-dropout\"", ",", "\n", "\"--relu-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability after activation in FFN.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-embed-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"encoder embedding dimension\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-ffn-embed-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"encoder embedding dimension for FFN\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-layers\"", ",", "type", "=", "int", ",", "metavar", "=", "\"N\"", ",", "help", "=", "\"num encoder layers\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-attention-heads\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"num encoder attention heads\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-normalize-before\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"apply layernorm before each encoder block\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-embed-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"decoder embedding dimension\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-ffn-embed-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"decoder embedding dimension for FFN\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-layers\"", ",", "type", "=", "int", ",", "metavar", "=", "\"N\"", ",", "help", "=", "\"num decoder layers\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-attention-heads\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"num decoder attention heads\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-normalize-before\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"apply layernorm before each decoder block\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--share-decoder-input-output-embed\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"share decoder input and output embeddings\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--layernorm-embedding\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"add layernorm to embedding\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no-scale-embedding\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if True, dont scale embeddings\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--load-pretrained-encoder-from\"", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"STR\"", ",", "\n", "help", "=", "\"model to take encoder weights from (for initialization)\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_w2v2_transformer.S2TTransformerModelW2V2.build_encoder": [[167, 179], ["s2t_w2v2_transformer.S2T_W2V2_TransformerEncoder", "getattr", "fairseq.checkpoint_utils.load_pretrained_component_from_model", "logger.info"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_pretrained_component_from_model"], ["", "@", "classmethod", "\n", "def", "build_encoder", "(", "cls", ",", "args", ")", ":", "\n", "        ", "encoder", "=", "S2T_W2V2_TransformerEncoder", "(", "args", ")", "\n", "if", "getattr", "(", "args", ",", "\"load_pretrained_encoder_from\"", ",", "None", ")", ":", "\n", "            ", "encoder", "=", "checkpoint_utils", ".", "load_pretrained_component_from_model", "(", "\n", "component", "=", "encoder", ",", "checkpoint", "=", "args", ".", "load_pretrained_encoder_from", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "f\"loaded pretrained encoder from: \"", "\n", "f\"{args.load_pretrained_encoder_from}\"", "\n", ")", "\n", "", "return", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_w2v2_transformer.S2TTransformerModelW2V2.build_decoder": [[180, 183], ["fairseq.models.speech_to_text.s2t_transformer.TransformerDecoderScriptable"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_decoder", "(", "cls", ",", "args", ",", "task", ",", "embed_tokens", ")", ":", "\n", "        ", "return", "TransformerDecoderScriptable", "(", "args", ",", "task", ".", "target_dictionary", ",", "embed_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_w2v2_transformer.S2TTransformerModelW2V2.build_model": [[184, 202], ["s2t_w2v2_transformer.base_architecture", "s2t_w2v2_transformer.S2TTransformerModelW2V2.build_model.build_embedding"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.build_embedding"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "\n", "# make sure all arguments are present in older models", "\n", "base_architecture", "(", "args", ")", "\n", "\n", "def", "build_embedding", "(", "dictionary", ",", "embed_dim", ")", ":", "\n", "            ", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "return", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "padding_idx", ")", "\n", "\n", "", "decoder_embed_tokens", "=", "build_embedding", "(", "\n", "task", ".", "target_dictionary", ",", "args", ".", "decoder_embed_dim", "\n", ")", "\n", "encoder", "=", "cls", ".", "build_encoder", "(", "args", ")", "\n", "decoder", "=", "cls", ".", "build_decoder", "(", "args", ",", "task", ",", "decoder_embed_tokens", ")", "\n", "return", "cls", "(", "encoder", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_w2v2_transformer.S2TTransformerModelW2V2.get_normalized_probs": [[203, 213], ["s2t_w2v2_transformer.S2TTransformerModelW2V2.get_normalized_probs_scriptable"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.get_normalized_probs_scriptable"], ["", "def", "get_normalized_probs", "(", "\n", "self", ",", "\n", "net_output", ":", "Tuple", "[", "Tensor", ",", "Optional", "[", "Dict", "[", "str", ",", "List", "[", "Optional", "[", "Tensor", "]", "]", "]", "]", "]", ",", "\n", "log_probs", ":", "bool", ",", "\n", "sample", ":", "Optional", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "# net_output['encoder_out'] is a (B, T, D) tensor", "\n", "        ", "lprobs", "=", "self", ".", "get_normalized_probs_scriptable", "(", "net_output", ",", "log_probs", ",", "sample", ")", "\n", "lprobs", ".", "batch_first", "=", "True", "\n", "return", "lprobs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_w2v2_transformer.S2TTransformerModelW2V2.forward": [[214, 228], ["s2t_w2v2_transformer.S2TTransformerModelW2V2.encoder", "s2t_w2v2_transformer.S2TTransformerModelW2V2.decoder", "s2t_w2v2_transformer.S2TTransformerModelW2V2._asdict"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ")", ":", "\n", "        ", "\"\"\"\n        The forward method inherited from the base class has a **kwargs\n        argument in its input, which is not supported in torchscript. This\n        method overrites the forward method definition without **kwargs.\n        \"\"\"", "\n", "encoder_out", "=", "self", ".", "encoder", "(", "src_tokens", "=", "src_tokens", ",", "src_lengths", "=", "src_lengths", ")", "\n", "# print(\"encoder out is ...\",encoder_out)", "\n", "# print(encoder_out.encoder_out.size())", "\n", "# print(type(encoder_out))", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "\n", "prev_output_tokens", "=", "prev_output_tokens", ",", "encoder_out", "=", "encoder_out", ".", "_asdict", "(", ")", "\n", ")", "\n", "return", "decoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_w2v2_transformer.S2T_W2V2_TransformerEncoder.__init__": [[234, 285], ["fairseq.models.FairseqEncoder.__init__", "torch.load", "torch.load", "torch.load", "torch.load", "fairseq.modules.FairseqDropout", "math.sqrt", "fairseq.models.speech_to_text.s2t_transformer.Conv1dSubsampler", "fairseq.modules.PositionalEmbedding", "torch.ModuleList", "torch.ModuleList", "fairseq.models.wav2vec.Wav2Vec2Model.build_model", "s2t_w2v2_transformer.S2T_W2V2_TransformerEncoder.wav2vec_model.load_state_dict", "fairseq.tasks.setup_task", "fairseq.models.wav2vec.Wav2VecCtc.build_model", "fairseq.models.wav2vec.Wav2VecCtc.build_model.load_state_dict", "fairseq.modules.LayerNorm", "os.path.exists", "os.system", "int", "fairseq.modules.TransformerEncoderLayer", "os.path.join", "args.conv_kernel_sizes.split", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.PositionalEmbedding", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyMTTask.setup_task", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists"], ["def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "None", ")", "\n", "\n", "assert", "args", ".", "w2v2_model_path", "is", "not", "None", "\n", "self", ".", "w2v2_model_path", "=", "args", ".", "w2v2_model_path", "\n", "self", ".", "use_asr_finetune_w2v", "=", "args", ".", "use_asr_finetune_w2v", "\n", "\n", "ckpt", "=", "torch", ".", "load", "(", "self", ".", "w2v2_model_path", ")", "\n", "self", ".", "w2v_args", "=", "ckpt", "[", "\"args\"", "]", "\n", "\n", "if", "not", "self", ".", "use_asr_finetune_w2v", ":", "# if use ssl-trained only", "\n", "            ", "self", ".", "w2v_args", "=", "ckpt", "[", "\"args\"", "]", "\n", "self", ".", "wav2vec_model", "=", "Wav2Vec2Model", ".", "build_model", "(", "ckpt", "[", "'args'", "]", ",", "task", "=", "None", ")", "\n", "self", ".", "wav2vec_model", ".", "load_state_dict", "(", "ckpt", "[", "'model'", "]", ")", "\n", "", "else", ":", "# wav2vec-ctc model", "\n", "            ", "ckpt", "[", "\"args\"", "]", ".", "data", "=", "args", ".", "data", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "ckpt", "[", "\"args\"", "]", ".", "data", ",", "f\"dict.{ckpt['args'].labels}.txt\"", ")", ")", ":", "\n", "                ", "os", ".", "system", "(", "f\"wget -P {ckpt['args'].data} https://dl.fbaipublicfiles.com/fairseq/wav2vec/dict.ltr.txt\"", ")", "\n", "\n", "", "task", "=", "tasks", ".", "setup_task", "(", "ckpt", "[", "\"args\"", "]", ")", "\n", "model_finetuned", "=", "Wav2VecCtc", ".", "build_model", "(", "ckpt", "[", "\"args\"", "]", ",", "task", "=", "task", ")", "\n", "model_finetuned", ".", "load_state_dict", "(", "ckpt", "[", "'model'", "]", ")", "\n", "self", ".", "wav2vec_model", "=", "model_finetuned", ".", "w2v_encoder", ".", "w2v_model", "\n", "self", ".", "w2v_args", "=", "ckpt", "[", "\"args\"", "]", ".", "w2v_args", "[", "\"model\"", "]", "\n", "\n", "", "self", ".", "freeze_w2v", "=", "args", ".", "freeze_w2v", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "p", "=", "args", ".", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "embed_scale", "=", "math", ".", "sqrt", "(", "args", ".", "encoder_embed_dim", ")", "\n", "if", "args", ".", "no_scale_embedding", ":", "\n", "            ", "self", ".", "embed_scale", "=", "1.0", "\n", "", "self", ".", "padding_idx", "=", "1", "\n", "# w2v_output_dim = 512", "\n", "w2v_output_dim", "=", "self", ".", "w2v_args", ".", "encoder_embed_dim", "\n", "self", ".", "subsample", "=", "Conv1dSubsampler", "(", "\n", "w2v_output_dim", ",", "\n", "args", ".", "conv_channels", ",", "\n", "args", ".", "encoder_embed_dim", ",", "\n", "[", "int", "(", "k", ")", "for", "k", "in", "args", ".", "conv_kernel_sizes", ".", "split", "(", "\",\"", ")", "]", ",", "\n", ")", "\n", "self", ".", "embed_positions", "=", "PositionalEmbedding", "(", "\n", "args", ".", "max_source_positions", ",", "args", ".", "encoder_embed_dim", ",", "self", ".", "padding_idx", "\n", ")", "\n", "self", ".", "transformer_layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "TransformerEncoderLayer", "(", "args", ")", "for", "_", "in", "range", "(", "args", ".", "encoder_layers", ")", "]", "\n", ")", "\n", "if", "args", ".", "encoder_normalize_before", ":", "\n", "            ", "self", ".", "layer_norm", "=", "LayerNorm", "(", "args", ".", "encoder_embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer_norm", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_w2v2_transformer.S2T_W2V2_TransformerEncoder._get_w2v_feature": [[286, 304], ["fairseq.data.data_utils.lengths_to_padding_mask", "s2t_w2v2_transformer.S2T_W2V2_TransformerEncoder.wav2vec_model.extract_features", "fairseq.data.data_utils.lengths_to_padding_mask.int"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils.lengths_to_padding_mask", "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features"], ["", "", "def", "_get_w2v_feature", "(", "self", ",", "src_tokens", ",", "src_lengths", ")", ":", "\n", "        ", "\"\"\"\n        :param src_tokens: b x frames\n        :param src_lengths: b-dim length\n        :return: w2v_feature: b x short_frames x feature-dim;\n                w2v_lengths: b-dim tensor\n                w2v_padding_mask: b x short_frames x feature-dim T/F tensor\n        \"\"\"", "\n", "padding_mask", "=", "lengths_to_padding_mask", "(", "src_lengths", ")", "\n", "# print(\"padding mask:\", padding_mask.size())", "\n", "# print(padding_mask)", "\n", "# w2v_feature = self.wav2vec_model.feature_extractor(src_tokens).transpose(1,2)", "\n", "w2v_feature", ",", "padding_mask", "=", "self", ".", "wav2vec_model", ".", "extract_features", "(", "src_tokens", ",", "padding_mask", ")", "\n", "# print(\"after extraction, padding:\", padding_mask)", "\n", "output_length", "=", "(", "1", "-", "padding_mask", ".", "int", "(", ")", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "# output_length = (torch.ones(padding_mask.size()) - padding_mask.int()).sum(dim=1)", "\n", "\n", "return", "w2v_feature", ",", "padding_mask", ",", "output_length", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_w2v2_transformer.S2T_W2V2_TransformerEncoder.forward": [[305, 343], ["s2t_w2v2_transformer.S2T_W2V2_TransformerEncoder.subsample", "fairseq.data.data_utils.lengths_to_padding_mask", "s2t_w2v2_transformer.S2T_W2V2_TransformerEncoder.embed_positions().transpose", "s2t_w2v2_transformer.S2T_W2V2_TransformerEncoder.dropout_module", "fairseq.models.fairseq_encoder.EncoderOut", "s2t_w2v2_transformer.S2T_W2V2_TransformerEncoder._get_w2v_feature", "layer", "fairseq.data.data_utils.lengths_to_padding_mask.any", "s2t_w2v2_transformer.S2T_W2V2_TransformerEncoder.layer_norm", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "s2t_w2v2_transformer.S2T_W2V2_TransformerEncoder._get_w2v_feature", "s2t_w2v2_transformer.S2T_W2V2_TransformerEncoder.embed_positions"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils.lengths_to_padding_mask", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNetEncoder._get_w2v_feature", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNetEncoder._get_w2v_feature"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ")", ":", "\n", "# 1. wav2vec", "\n", "# print(src_tokens.size(), src_lengths.size())", "\n", "        ", "if", "self", ".", "freeze_w2v", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "w2v_feature", ",", "encoder_padding_mask", ",", "input_lengths", "=", "self", ".", "_get_w2v_feature", "(", "\n", "src_tokens", ",", "src_lengths", ")", "\n", "", "", "else", ":", "\n", "            ", "w2v_feature", ",", "encoder_padding_mask", ",", "input_lengths", "=", "self", ".", "_get_w2v_feature", "(", "\n", "src_tokens", ",", "src_lengths", ")", "\n", "\n", "# 2. conv-layers", "\n", "# print(\"after w2v extract, x:\", w2v_feature.size())", "\n", "", "x", ",", "input_lengths", "=", "self", ".", "subsample", "(", "w2v_feature", ",", "input_lengths", ")", "\n", "# x, input_lengths = self.subsample(src_tokens, src_lengths)", "\n", "# print(\"after convs-2, x\", x.size())", "\n", "x", "=", "self", ".", "embed_scale", "*", "x", "\n", "encoder_padding_mask", "=", "lengths_to_padding_mask", "(", "input_lengths", ")", "\n", "# x = w2v_feature", "\n", "positions", "=", "self", ".", "embed_positions", "(", "encoder_padding_mask", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# print(positions.size())", "\n", "x", "+=", "positions", "\n", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "\n", "# 3. Transformer-layers", "\n", "for", "layer", "in", "self", ".", "transformer_layers", ":", "\n", "            ", "x", "=", "layer", "(", "x", ",", "encoder_padding_mask", ")", "\n", "", "if", "not", "encoder_padding_mask", ".", "any", "(", ")", ":", "\n", "            ", "encoder_padding_mask", "=", "None", "\n", "", "if", "self", ".", "layer_norm", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "", "return", "EncoderOut", "(", "\n", "encoder_out", "=", "x", ",", "\n", "encoder_padding_mask", "=", "encoder_padding_mask", ",", "\n", "encoder_embedding", "=", "None", ",", "\n", "encoder_states", "=", "None", ",", "\n", "src_tokens", "=", "None", ",", "\n", "src_lengths", "=", "None", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_w2v2_transformer.S2T_W2V2_TransformerEncoder.reorder_encoder_out": [[345, 386], ["fairseq.models.fairseq_encoder.EncoderOut", "encoder_out.encoder_out.index_select", "encoder_padding_mask.index_select", "encoder_embedding.index_select", "enumerate", "state.index_select"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "reorder_encoder_out", "(", "self", ",", "encoder_out", ":", "EncoderOut", ",", "new_order", ")", ":", "\n", "        ", "\"\"\"\n        Since encoder_padding_mask and encoder_embedding are both of type\n        Optional[Tensor] in EncoderOut, they need to be copied as local\n        variables for Torchscript Optional refinement\n        \"\"\"", "\n", "\n", "encoder_padding_mask", ":", "Optional", "[", "Tensor", "]", "=", "encoder_out", ".", "encoder_padding_mask", "\n", "encoder_embedding", ":", "Optional", "[", "Tensor", "]", "=", "encoder_out", ".", "encoder_embedding", "\n", "\n", "new_encoder_out", "=", "(", "\n", "encoder_out", ".", "encoder_out", "\n", "if", "encoder_out", ".", "encoder_out", "is", "None", "\n", "else", "encoder_out", ".", "encoder_out", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", ")", "\n", "\n", "new_encoder_padding_mask", "=", "(", "\n", "encoder_padding_mask", "\n", "if", "encoder_padding_mask", "is", "None", "\n", "else", "encoder_padding_mask", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", ")", "\n", "\n", "new_encoder_embedding", "=", "(", "\n", "encoder_embedding", "\n", "if", "encoder_embedding", "is", "None", "\n", "else", "encoder_embedding", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", ")", "\n", "\n", "encoder_states", "=", "encoder_out", ".", "encoder_states", "\n", "if", "encoder_states", "is", "not", "None", ":", "\n", "            ", "for", "idx", ",", "state", "in", "enumerate", "(", "encoder_states", ")", ":", "\n", "                ", "encoder_states", "[", "idx", "]", "=", "state", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", "\n", "", "", "return", "EncoderOut", "(", "\n", "encoder_out", "=", "new_encoder_out", ",", "# T x B x C", "\n", "encoder_padding_mask", "=", "new_encoder_padding_mask", ",", "# B x T", "\n", "encoder_embedding", "=", "new_encoder_embedding", ",", "# B x T x C", "\n", "encoder_states", "=", "encoder_states", ",", "# List[T x B x C]", "\n", "src_tokens", "=", "None", ",", "\n", "src_lengths", "=", "None", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_w2v2_transformer.base_architecture": [[389, 432], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "", "@", "register_model_architecture", "(", "model_name", "=", "\"s2t_transformer_w2v2\"", ",", "arch_name", "=", "\"s2t_transformer_w2v2\"", ")", "\n", "def", "base_architecture", "(", "args", ")", ":", "\n", "# Wav2vec2.0 feature-extractor", "\n", "    ", "args", ".", "w2v2_model_path", "=", "getattr", "(", "args", ",", "\"w2v2_model_path\"", ",", "\"./wav2vec_small_100h.pt\"", ")", "\n", "args", ".", "freeze_w2v", "=", "getattr", "(", "args", ",", "\"freeze_w2v\"", ",", "False", ")", "# default is false, 'store_true'", "\n", "\n", "# Convolutional subsampler", "\n", "args", ".", "conv_kernel_sizes", "=", "getattr", "(", "args", ",", "\"conv_kernel_sizes\"", ",", "\"5,5\"", ")", "\n", "args", ".", "conv_channels", "=", "getattr", "(", "args", ",", "\"conv_channels\"", ",", "1024", ")", "\n", "# Transformer", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "2048", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "12", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "encoder_normalize_before", "=", "getattr", "(", "args", ",", "\"encoder_normalize_before\"", ",", "True", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "args", ".", "encoder_embed_dim", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "args", ".", "encoder_ffn_embed_dim", "\n", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "6", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "decoder_normalize_before", "=", "getattr", "(", "args", ",", "\"decoder_normalize_before\"", ",", "True", ")", "\n", "args", ".", "decoder_learned_pos", "=", "getattr", "(", "args", ",", "\"decoder_learned_pos\"", ",", "False", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "args", ".", "dropout", ")", "\n", "args", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "args", ".", "dropout", ")", "\n", "args", ".", "activation_fn", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"relu\"", ")", "\n", "args", ".", "adaptive_softmax_cutoff", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_cutoff\"", ",", "None", ")", "\n", "args", ".", "adaptive_softmax_dropout", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_dropout\"", ",", "0", ")", "\n", "args", ".", "share_decoder_input_output_embed", "=", "getattr", "(", "\n", "args", ",", "\"share_decoder_input_output_embed\"", ",", "True", "\n", ")", "\n", "args", ".", "no_token_positional_embeddings", "=", "getattr", "(", "\n", "args", ",", "\"no_token_positional_embeddings\"", ",", "False", "\n", ")", "\n", "args", ".", "adaptive_input", "=", "getattr", "(", "args", ",", "\"adaptive_input\"", ",", "False", ")", "\n", "args", ".", "decoder_layerdrop", "=", "getattr", "(", "args", ",", "\"decoder_layerdrop\"", ",", "0.0", ")", "\n", "args", ".", "decoder_output_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_output_dim\"", ",", "args", ".", "decoder_embed_dim", "\n", ")", "\n", "args", ".", "decoder_input_dim", "=", "getattr", "(", "args", ",", "\"decoder_input_dim\"", ",", "args", ".", "decoder_embed_dim", ")", "\n", "args", ".", "no_scale_embedding", "=", "getattr", "(", "args", ",", "\"no_scale_embedding\"", ",", "False", ")", "\n", "args", ".", "quant_noise_pq", "=", "getattr", "(", "args", ",", "\"quant_noise_pq\"", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_w2v2_transformer.s2t_transformer_w2v2_s": [[434, 443], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "s2t_w2v2_transformer.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "@", "register_model_architecture", "(", "\"s2t_transformer_w2v2\"", ",", "\"s2t_transformer_w2v2_s\"", ")", "\n", "def", "s2t_transformer_w2v2_s", "(", "args", ")", ":", "\n", "    ", "args", ".", "use_asr_finetune_w2v", "=", "getattr", "(", "args", ",", "\"use_asr_finetune_w2v\"", ",", "False", ")", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "256", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "256", "*", "8", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "4", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "4", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "base_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_w2v2_transformer.s2t_transformer_w2v2_sp": [[445, 450], ["fairseq.models.register_model_architecture", "getattr", "getattr", "s2t_w2v2_transformer.s2t_transformer_w2v2_s"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_w2v2_transformer.s2t_transformer_w2v2_s"], ["", "@", "register_model_architecture", "(", "\"s2t_transformer_w2v2\"", ",", "\"s2t_transformer_w2v2_sp\"", ")", "\n", "def", "s2t_transformer_w2v2_sp", "(", "args", ")", ":", "\n", "    ", "args", ".", "use_asr_finetune_w2v", "=", "getattr", "(", "args", ",", "\"use_asr_finetune_w2v\"", ",", "False", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "16", ")", "\n", "s2t_transformer_w2v2_s", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_w2v2_transformer.s2t_transformer_w2v2asr_s": [[452, 456], ["fairseq.models.register_model_architecture", "getattr", "s2t_w2v2_transformer.s2t_transformer_w2v2_s"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.s2t_w2v2_transformer.s2t_transformer_w2v2_s"], ["", "@", "register_model_architecture", "(", "\"s2t_transformer_w2v2\"", ",", "\"s2t_transformer_w2v2asr_s\"", ")", "\n", "def", "s2t_transformer_w2v2asr_s", "(", "args", ")", ":", "\n", "    ", "args", ".", "use_asr_finetune_w2v", "=", "getattr", "(", "args", ",", "\"use_asr_finetune_w2v\"", ",", "True", ")", "\n", "s2t_transformer_w2v2_s", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.__init__": [[39, 42], ["fairseq.models.FairseqEncoderDecoderModel.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "encoder", ",", "decoder", ")", "\n", "self", ".", "is_text_input", "=", "False", "# default", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.add_args": [[43, 48], ["fairseq.models.speech_to_text.s2t_w2v2_transformer.S2TTransformerModelW2V2.add_args", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "S2TTransformerModelW2V2", ".", "add_args", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "\"--textual-encoder-embed-dim\"", ",", "type", "=", "int", ",", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"encoder embded dim for text input\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.build_encoder": [[49, 61], ["xstnet.XSTNetEncoder", "getattr", "fairseq.checkpoint_utils.load_pretrained_component_from_model", "logger.info"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_pretrained_component_from_model"], ["", "@", "classmethod", "\n", "def", "build_encoder", "(", "cls", ",", "args", ",", "dict", ",", "embed_tokens", ")", ":", "\n", "        ", "encoder", "=", "XSTNetEncoder", "(", "args", ",", "dict", ",", "embed_tokens", ")", "\n", "if", "getattr", "(", "args", ",", "\"load_pretrained_encoder_from\"", ",", "None", ")", ":", "\n", "            ", "encoder", "=", "checkpoint_utils", ".", "load_pretrained_component_from_model", "(", "\n", "component", "=", "encoder", ",", "checkpoint", "=", "args", ".", "load_pretrained_encoder_from", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "f\"loaded pretrained encoder from: \"", "\n", "f\"{args.load_pretrained_encoder_from}\"", "\n", ")", "\n", "", "return", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.build_decoder": [[62, 65], ["fairseq.models.speech_to_text.s2t_transformer.TransformerDecoderScriptable"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_decoder", "(", "cls", ",", "args", ",", "dict", ",", "embed_tokens", ")", ":", "\n", "        ", "return", "TransformerDecoderScriptable", "(", "args", ",", "dict", ",", "embed_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.build_embedding": [[66, 77], ["len", "dictionary.pad", "fairseq.models.transformer.Embedding", "fairseq.utils.parse_embedding", "fairseq.utils.load_embedding"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.parse_embedding", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.load_embedding"], ["", "@", "classmethod", "\n", "def", "build_embedding", "(", "cls", ",", "args", ",", "dictionary", ",", "embed_dim", ",", "path", "=", "None", ")", ":", "\n", "        ", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "\n", "emb", "=", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "padding_idx", ")", "\n", "# if provided, load from preloaded dictionaries", "\n", "if", "path", ":", "\n", "            ", "embed_dict", "=", "utils", ".", "parse_embedding", "(", "path", ")", "\n", "utils", ".", "load_embedding", "(", "embed_dict", ",", "dictionary", ",", "emb", ")", "\n", "", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.build_model": [[78, 87], ["xstnet.base_architecture", "cls.build_embedding", "cls.build_encoder", "cls.build_decoder", "cls"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.build_embedding", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.build_encoder", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.build_decoder", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "# make sure all arguments are present in older models", "\n", "base_architecture", "(", "args", ")", "\n", "decoder_embed_tokens", "=", "cls", ".", "build_embedding", "(", "args", ",", "task", ".", "target_dictionary", ",", "args", ".", "decoder_embed_dim", ")", "\n", "encoder", "=", "cls", ".", "build_encoder", "(", "args", ",", "task", ".", "target_dictionary", ",", "decoder_embed_tokens", ")", "\n", "decoder", "=", "cls", ".", "build_decoder", "(", "args", ",", "task", ".", "target_dictionary", ",", "decoder_embed_tokens", ")", "\n", "return", "cls", "(", "encoder", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.get_normalized_probs": [[88, 98], ["xstnet.XSTNet.get_normalized_probs_scriptable"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.BaseFairseqModel.get_normalized_probs_scriptable"], ["", "def", "get_normalized_probs", "(", "\n", "self", ",", "\n", "net_output", ":", "Tuple", "[", "Tensor", ",", "Optional", "[", "Dict", "[", "str", ",", "List", "[", "Optional", "[", "Tensor", "]", "]", "]", "]", "]", ",", "\n", "log_probs", ":", "bool", ",", "\n", "sample", ":", "Optional", "[", "Dict", "[", "str", ",", "Tensor", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "# net_output['encoder_out'] is a (B, T, D) tensor", "\n", "        ", "lprobs", "=", "self", ".", "get_normalized_probs_scriptable", "(", "net_output", ",", "log_probs", ",", "sample", ")", "\n", "lprobs", ".", "batch_first", "=", "True", "\n", "return", "lprobs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.set_mt_only": [[99, 102], ["None"], "methods", ["None"], ["", "def", "set_mt_only", "(", "self", ")", ":", "\n", "        ", "self", ".", "is_text_input", "=", "True", "\n", "self", ".", "encoder", ".", "is_text_input", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.forward": [[103, 113], ["xstnet.XSTNet.encoder", "xstnet.XSTNet.decoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "\n", "is_text_input", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "is_text_input", ":", "\n", "            ", "is_text_input", "=", "True", "\n", "", "encoder_out", "=", "self", ".", "encoder", "(", "src_tokens", ",", "src_lengths", ",", "is_text_input", "=", "is_text_input", ")", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "prev_output_tokens", "=", "prev_output_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "decoder_out", ",", "encoder_out", "\n", "", "return", "decoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNetEncoder.__init__": [[116, 152], ["fairseq.models.FairseqEncoder.__init__", "fairseq.modules.FairseqDropout", "xstnet.XSTNetEncoder._build_acoustic_encoder", "xstnet.XSTNetEncoder._build_textual_encoder", "math.sqrt", "torch.Softmax", "torch.Softmax", "torch.Linear", "torch.Linear", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "torch.Linear", "torch.Linear", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNetEncoder._build_acoustic_encoder", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNetEncoder._build_textual_encoder", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "dictionary", ",", "embed_tokens", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "self", ".", "dropout_module", "=", "FairseqDropout", "(", "\n", "args", ".", "dropout", ",", "module_name", "=", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", "self", ".", "padding_idx", "=", "embed_tokens", ".", "padding_idx", "\n", "self", ".", "textual_encoder_embed_dim", "=", "embed_tokens", ".", "embedding_dim", "\n", "self", ".", "embed_scale", "=", "1.0", "if", "args", ".", "no_scale_embedding", "else", "math", ".", "sqrt", "(", "self", ".", "textual_encoder_embed_dim", ")", "\n", "\n", "self", ".", "_build_acoustic_encoder", "(", "args", ")", "\n", "self", ".", "_build_textual_encoder", "(", "args", ")", "\n", "self", ".", "is_text_input", "=", "False", "\n", "\n", "# CTC module", "\n", "self", ".", "use_ctc", "=", "(", "(", "\"ctc\"", "in", "getattr", "(", "args", ",", "\"ablation_type\"", ",", "\"\"", ")", ")", "and", "(", "getattr", "(", "args", ",", "\"ablation_weight\"", ",", "0.0", ")", ">", "0", ")", ")", "or", "(", "(", "\"ctc\"", "in", "getattr", "(", "args", ",", "\"criterion\"", ",", "\"\"", ")", ")", "and", "(", "getattr", "(", "args", ",", "\"ctc_weight\"", ",", "0.0", ")", ">", "0", ")", ")", "\n", "if", "self", ".", "use_ctc", ":", "\n", "            ", "if", "(", "getattr", "(", "args", ",", "\"ablation_type\"", ",", "False", ")", "==", "\"ctc_cnn\"", ")", "or", "(", "getattr", "(", "args", ",", "\"ctc_type\"", ",", "False", ")", "==", "\"ctc_cnn\"", ")", ":", "\n", "                ", "self", ".", "ctc_type", "=", "\"ctc_cnn\"", "\n", "self", ".", "ctc_projection", "=", "nn", ".", "Linear", "(", "\n", "embed_tokens", ".", "embedding_dim", ",", "\n", "embed_tokens", ".", "weight", ".", "shape", "[", "0", "]", ",", "\n", "bias", "=", "False", ",", "\n", ")", "\n", "self", ".", "ctc_projection", ".", "weight", "=", "embed_tokens", ".", "weight", "\n", "", "elif", "(", "getattr", "(", "args", ",", "\"ablation_type\"", ",", "False", ")", "==", "\"ctc_w2v\"", ")", "or", "(", "getattr", "(", "args", ",", "\"ctc_type\"", ",", "False", ")", "==", "\"ctc_w2v\"", ")", ":", "\n", "                ", "self", ".", "ctc_type", "=", "\"ctc_w2v\"", "\n", "self", ".", "ctc_projection", "=", "nn", ".", "Linear", "(", "\n", "self", ".", "w2v_args", ".", "encoder_embed_dim", ",", "\n", "embed_tokens", ".", "weight", ".", "shape", "[", "0", "]", ",", "\n", ")", "\n", "", "self", ".", "ctc_softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNetEncoder._build_acoustic_encoder": [[153, 185], ["fairseq.models.speech_to_text.s2t_transformer.Conv1dSubsampler", "torch.load", "torch.load", "torch.load", "torch.load", "fairseq.models.wav2vec.Wav2Vec2Model.build_model", "xstnet.XSTNetEncoder.wav2vec_model.load_state_dict", "fairseq.tasks.setup_task", "fairseq.models.wav2vec.Wav2VecCtc.build_model", "fairseq.models.wav2vec.Wav2VecCtc.build_model.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "os.path.exists", "os.system", "int", "os.path.exists", "os.system", "os.path.join", "args.conv_kernel_sizes.split"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyMTTask.setup_task", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists"], ["", "", "def", "_build_acoustic_encoder", "(", "self", ",", "args", ")", ":", "\n", "        ", "assert", "args", ".", "w2v2_model_path", "is", "not", "None", "\n", "self", ".", "w2v2_model_path", "=", "args", ".", "w2v2_model_path", "\n", "self", ".", "use_asr_finetune_w2v", "=", "args", ".", "use_asr_finetune_w2v", "\n", "try", ":", "\n", "            ", "ckpt", "=", "torch", ".", "load", "(", "self", ".", "w2v2_model_path", ")", "\n", "", "except", "FileNotFoundError", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "\"wav2vec_small.pt\"", ")", ":", "\n", "                ", "os", ".", "system", "(", "f\"wget https://dl.fbaipublicfiles.com/fairseq/wav2vec/wav2vec_small.pt\"", ")", "\n", "", "ckpt", "=", "torch", ".", "load", "(", "\"wav2vec_small.pt\"", ")", "\n", "", "self", ".", "w2v_args", "=", "ckpt", "[", "\"args\"", "]", "\n", "if", "not", "self", ".", "use_asr_finetune_w2v", ":", "# if use ssl-trained only", "\n", "            ", "self", ".", "w2v_args", "=", "ckpt", "[", "\"args\"", "]", "\n", "self", ".", "wav2vec_model", "=", "Wav2Vec2Model", ".", "build_model", "(", "ckpt", "[", "'args'", "]", ",", "task", "=", "None", ")", "\n", "self", ".", "wav2vec_model", ".", "load_state_dict", "(", "ckpt", "[", "'model'", "]", ")", "\n", "", "else", ":", "# wav2vec-ctc model", "\n", "            ", "ckpt", "[", "\"args\"", "]", ".", "data", "=", "args", ".", "data", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "ckpt", "[", "\"args\"", "]", ".", "data", ",", "f\"dict.{ckpt['args'].labels}.txt\"", ")", ")", ":", "\n", "                ", "os", ".", "system", "(", "f\"wget -P {ckpt['args'].data} https://dl.fbaipublicfiles.com/fairseq/wav2vec/dict.ltr.txt\"", ")", "\n", "", "task", "=", "tasks", ".", "setup_task", "(", "ckpt", "[", "\"args\"", "]", ")", "\n", "model_finetuned", "=", "Wav2VecCtc", ".", "build_model", "(", "ckpt", "[", "\"args\"", "]", ",", "task", "=", "task", ")", "\n", "model_finetuned", ".", "load_state_dict", "(", "ckpt", "[", "'model'", "]", ")", "\n", "self", ".", "wav2vec_model", "=", "model_finetuned", ".", "w2v_encoder", ".", "w2v_model", "\n", "self", ".", "w2v_args", "=", "ckpt", "[", "\"args\"", "]", ".", "w2v_args", "[", "\"model\"", "]", "\n", "", "self", ".", "freeze_w2v", "=", "args", ".", "freeze_w2v", "\n", "\n", "w2v_output_dim", "=", "self", ".", "w2v_args", ".", "encoder_embed_dim", "\n", "self", ".", "subsample_audio", "=", "Conv1dSubsampler", "(", "\n", "w2v_output_dim", ",", "\n", "args", ".", "conv_channels", ",", "\n", "self", ".", "textual_encoder_embed_dim", ",", "\n", "[", "int", "(", "k", ")", "for", "k", "in", "args", ".", "conv_kernel_sizes", ".", "split", "(", "\",\"", ")", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNetEncoder._build_textual_encoder": [[187, 210], ["getattr", "torch.ModuleList", "torch.ModuleList", "fairseq.modules.PositionalEmbedding", "fairseq.modules.LayerNorm", "fairseq.modules.LayerNorm", "fairseq.modules.TransformerEncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fconv.PositionalEmbedding", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm"], ["", "def", "_build_textual_encoder", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "max_source_positions", "=", "args", ".", "max_source_positions", "\n", "self", ".", "embed_positions", "=", "(", "\n", "PositionalEmbedding", "(", "\n", "args", ".", "max_source_positions", ",", "\n", "self", ".", "textual_encoder_embed_dim", ",", "\n", "self", ".", "padding_idx", ",", "\n", "learned", "=", "args", ".", "encoder_learned_pos", ",", "\n", ")", "\n", "if", "not", "args", ".", "no_token_positional_embeddings", "\n", "else", "None", "\n", ")", "\n", "if", "getattr", "(", "args", ",", "\"layernorm_embedding\"", ",", "False", ")", ":", "\n", "            ", "self", ".", "layernorm_embedding", "=", "LayerNorm", "(", "self", ".", "textual_encoder_embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layernorm_embedding", "=", "None", "\n", "", "self", ".", "transformer_layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "TransformerEncoderLayer", "(", "args", ")", "for", "_", "in", "range", "(", "args", ".", "encoder_layers", ")", "]", "\n", ")", "\n", "if", "args", ".", "encoder_normalize_before", ":", "\n", "            ", "self", ".", "layer_norm", "=", "LayerNorm", "(", "self", ".", "textual_encoder_embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer_norm", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNetEncoder._get_w2v_feature": [[211, 216], ["fairseq.data.data_utils.lengths_to_padding_mask", "xstnet.XSTNetEncoder.wav2vec_model.extract_features", "fairseq.data.data_utils.lengths_to_padding_mask.int"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils.lengths_to_padding_mask", "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features"], ["", "", "def", "_get_w2v_feature", "(", "self", ",", "src_tokens", ",", "src_lengths", ")", ":", "\n", "        ", "padding_mask", "=", "lengths_to_padding_mask", "(", "src_lengths", ")", "\n", "w2v_feature", ",", "padding_mask", "=", "self", ".", "wav2vec_model", ".", "extract_features", "(", "src_tokens", ",", "padding_mask", ")", "\n", "output_length", "=", "(", "1", "-", "padding_mask", ".", "int", "(", ")", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "return", "w2v_feature", ",", "padding_mask", ",", "output_length", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNetEncoder.embedding_mask_audio_seq": [[217, 254], ["fairseq.data.data_utils.lengths_to_padding_mask", "src_tokens.clone", "src_tokens.clone.size", "xstnet.XSTNetEncoder.wav2vec_model.extract_features", "xstnet.XSTNetEncoder.subsample_audio", "fairseq.data.data_utils.lengths_to_padding_mask", "xstnet.XSTNetEncoder.dropout_module", "mask_configs.get", "mask_configs.get", "mask_configs.get", "mask_configs.get", "fairseq.data.data_utils.compute_mask_indices", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "xstnet.XSTNetEncoder.embed_positions().transpose", "mask_configs.get", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "fairseq.data.data_utils.lengths_to_padding_mask.int", "xstnet.XSTNetEncoder.embed_positions"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils.lengths_to_padding_mask", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.lengths_to_padding_mask", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.compute_mask_indices"], ["", "def", "embedding_mask_audio_seq", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "mask_configs", "=", "None", ",", "\n", "return_short_audio_len", "=", "False", ")", ":", "\n", "# src_tokens: b x frame, original audio_src_tokens", "\n", "        ", "padding_mask", "=", "lengths_to_padding_mask", "(", "src_lengths", ")", "\n", "masked_src_tokens", "=", "src_tokens", ".", "clone", "(", ")", "\n", "B", ",", "T", "=", "masked_src_tokens", ".", "size", "(", ")", "\n", "if", "(", "mask_configs", "is", "not", "None", ")", "and", "(", "mask_configs", ".", "get", "(", "\"mask_seq_prob\"", ",", "0.0", ")", ">", "0", ")", ":", "\n", "            ", "mask_seq_prob", "=", "mask_configs", ".", "get", "(", "\"mask_seq_prob\"", ",", "0.0", ")", "\n", "mask_length", "=", "mask_configs", ".", "get", "(", "\"mask_length\"", ",", "3600", ")", "\n", "mask_selection", "=", "mask_configs", ".", "get", "(", "\"mask_type\"", ",", "\"static\"", ")", "\n", "no_mask_overlap", "=", "mask_configs", ".", "get", "(", "\"no_mask_overlap\"", ",", "False", ")", "\n", "mask_indices", "=", "compute_mask_indices", "(", "\n", "(", "B", ",", "T", ")", ",", "\n", "padding_mask", ",", "\n", "mask_seq_prob", ",", "\n", "mask_length", ",", "\n", "mask_selection", ",", "\n", "0.0", ",", "\n", "min_masks", "=", "2", ",", "\n", "no_overlap", "=", "no_mask_overlap", ",", "\n", "min_space", "=", "0", "\n", ")", "\n", "mask_indices", "=", "torch", ".", "from_numpy", "(", "mask_indices", ")", ".", "to", "(", "masked_src_tokens", ".", "device", ")", "\n", "masked_src_tokens", "[", "mask_indices", "]", "=", "0", "\n", "", "w2v_feature", ",", "padding_mask", "=", "self", ".", "wav2vec_model", ".", "extract_features", "(", "masked_src_tokens", ",", "padding_mask", ")", "\n", "output_length", "=", "(", "1", "-", "padding_mask", ".", "int", "(", ")", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n", "x", ",", "output_length", "=", "self", ".", "subsample_audio", "(", "w2v_feature", ",", "output_length", ")", "\n", "x", "=", "self", ".", "embed_scale", "*", "x", "\n", "encoder_padding_mask", "=", "lengths_to_padding_mask", "(", "output_length", ")", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", ":", "\n", "            ", "positions", "=", "self", ".", "embed_positions", "(", "encoder_padding_mask", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "x", "+=", "positions", "\n", "", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "if", "return_short_audio_len", ":", "\n", "            ", "return", "x", ",", "encoder_padding_mask", ",", "output_length", "\n", "", "return", "x", ",", "encoder_padding_mask", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNetEncoder.embedding_audio": [[255, 275], ["xstnet.XSTNetEncoder.subsample_audio", "fairseq.data.data_utils.lengths_to_padding_mask", "xstnet.XSTNetEncoder.dropout_module", "xstnet.XSTNetEncoder._get_w2v_feature", "xstnet.XSTNetEncoder.embed_positions().transpose", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "xstnet.XSTNetEncoder._get_w2v_feature", "xstnet.XSTNetEncoder.embed_positions"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils.lengths_to_padding_mask", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNetEncoder._get_w2v_feature", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNetEncoder._get_w2v_feature"], ["", "def", "embedding_audio", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "\n", "return_short_audio_len", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "freeze_w2v", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "w2v_feature", ",", "encoder_padding_mask", ",", "input_lengths", "=", "self", ".", "_get_w2v_feature", "(", "\n", "src_tokens", ",", "src_lengths", ")", "\n", "", "", "else", ":", "\n", "            ", "w2v_feature", ",", "encoder_padding_mask", ",", "input_lengths", "=", "self", ".", "_get_w2v_feature", "(", "\n", "src_tokens", ",", "src_lengths", ")", "\n", "\n", "", "x", ",", "input_lengths", "=", "self", ".", "subsample_audio", "(", "w2v_feature", ",", "input_lengths", ")", "\n", "x", "=", "self", ".", "embed_scale", "*", "x", "\n", "encoder_padding_mask", "=", "lengths_to_padding_mask", "(", "input_lengths", ")", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", ":", "\n", "            ", "positions", "=", "self", ".", "embed_positions", "(", "encoder_padding_mask", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "x", "+=", "positions", "\n", "", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "if", "return_short_audio_len", ":", "\n", "            ", "return", "x", ",", "encoder_padding_mask", ",", "input_lengths", "\n", "", "return", "x", ",", "encoder_padding_mask", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNetEncoder.embedding_text": [[276, 287], ["xstnet.XSTNetEncoder.embed_tokens", "xstnet.XSTNetEncoder.dropout_module", "xstnet.XSTNetEncoder.transpose", "src_tokens.eq", "xstnet.XSTNetEncoder.embed_positions", "xstnet.XSTNetEncoder.layernorm_embedding"], "methods", ["None"], ["", "def", "embedding_text", "(", "self", ",", "src_tokens", ",", "src_lengths", ")", ":", "\n", "        ", "token_embedding", "=", "self", ".", "embed_tokens", "(", "src_tokens", ")", "\n", "x", "=", "self", ".", "embed_scale", "*", "token_embedding", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", ":", "\n", "            ", "x", "+=", "self", ".", "embed_positions", "(", "src_tokens", ")", "\n", "", "if", "self", ".", "layernorm_embedding", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "layernorm_embedding", "(", "x", ")", "\n", "", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "# B x T x C -> T x B x C", "\n", "encoder_padding_mask", "=", "src_tokens", ".", "eq", "(", "self", ".", "padding_idx", ")", "\n", "return", "x", ",", "encoder_padding_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNetEncoder.forward": [[288, 316], ["fairseq.models.fairseq_encoder.EncoderOut", "xstnet.XSTNetEncoder.embedding_text", "xstnet.XSTNetEncoder.embedding_audio", "layer", "xstnet.XSTNetEncoder.layer_norm"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNetEncoder.embedding_text", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNetEncoder.embedding_audio"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "src_lengths", ",", "is_text_input", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        src_tokens: b x seq, float tensor if it is audio input, LongTensor if it is text input\n        src_lengths: b-dim LongTensor\n        \"\"\"", "\n", "short_audio_len", "=", "None", "\n", "if", "self", ".", "is_text_input", ":", "\n", "            ", "is_text_input", "=", "True", "\n", "", "if", "is_text_input", ":", "\n", "            ", "x", ",", "encoder_padding_mask", "=", "self", ".", "embedding_text", "(", "src_tokens", ",", "src_lengths", ")", "\n", "", "else", ":", "\n", "            ", "x", ",", "encoder_padding_mask", ",", "short_audio_len", "=", "self", ".", "embedding_audio", "(", "src_tokens", ",", "src_lengths", ",", "\n", "return_short_audio_len", "=", "True", ")", "\n", "", "encoder_embedding", "=", "x", "\n", "# 3. Transformer-layers", "\n", "for", "layer", "in", "self", ".", "transformer_layers", ":", "\n", "            ", "x", "=", "layer", "(", "x", ",", "encoder_padding_mask", ")", "\n", "", "if", "self", ".", "layer_norm", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "", "return", "EncoderOut", "(", "\n", "encoder_out", "=", "x", ",", "\n", "encoder_padding_mask", "=", "encoder_padding_mask", ",", "\n", "encoder_embedding", "=", "encoder_embedding", ",", "\n", "encoder_states", "=", "None", ",", "\n", "src_tokens", "=", "None", ",", "\n", "src_lengths", "=", "None", ",", "\n", "output_encoder_lengths", "=", "short_audio_len", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNetEncoder.reorder_encoder_out": [[318, 348], ["fairseq.models.fairseq_encoder.EncoderOut", "encoder_out.encoder_out.index_select", "encoder_padding_mask.index_select"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "reorder_encoder_out", "(", "self", ",", "encoder_out", ":", "EncoderOut", ",", "new_order", ")", ":", "\n", "        ", "\"\"\"\n        Since encoder_padding_mask and encoder_embedding are both of type\n        Optional[Tensor] in EncoderOut, they need to be copied as local\n        variables for Torchscript Optional refinement\n        \"\"\"", "\n", "\n", "encoder_padding_mask", ":", "Optional", "[", "Tensor", "]", "=", "encoder_out", ".", "encoder_padding_mask", "\n", "\n", "new_encoder_out", "=", "(", "\n", "encoder_out", ".", "encoder_out", "\n", "if", "encoder_out", ".", "encoder_out", "is", "None", "\n", "else", "encoder_out", ".", "encoder_out", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", ")", "\n", "\n", "new_encoder_padding_mask", "=", "(", "\n", "encoder_padding_mask", "\n", "if", "encoder_padding_mask", "is", "None", "\n", "else", "encoder_padding_mask", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", ")", "\n", "\n", "return", "EncoderOut", "(", "\n", "encoder_out", "=", "new_encoder_out", ",", "# T x B x C", "\n", "encoder_padding_mask", "=", "new_encoder_padding_mask", ",", "# B x T", "\n", "encoder_embedding", "=", "None", ",", "\n", "encoder_states", "=", "None", ",", "\n", "src_tokens", "=", "None", ",", "\n", "src_lengths", "=", "None", ",", "\n", "output_encoder_lengths", "=", "None", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNetEncoder.compute_ctc_logit_and_logprob": [[350, 369], ["xstnet.XSTNetEncoder._get_w2v_feature", "xstnet.XSTNetEncoder.dropout_module", "xstnet.XSTNetEncoder.ctc_projection", "xstnet.XSTNetEncoder.float", "torch.functional.log_softmax", "torch.functional.log_softmax", "log_probs.transpose.transpose.transpose", "xstnet.XSTNetEncoder.subsample_audio", "encoder_state.transpose.transpose.transpose", "fairseq.data.data_utils.lengths_to_padding_mask"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNetEncoder._get_w2v_feature", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.lengths_to_padding_mask"], ["", "def", "compute_ctc_logit_and_logprob", "(", "self", ",", "src_tokens", ",", "src_lengths", ")", ":", "\n", "        ", "assert", "self", ".", "use_ctc", ",", "\"CTC is not available!\"", "\n", "w2v_feature", ",", "encoder_padding_mask", ",", "input_lengths", "=", "self", ".", "_get_w2v_feature", "(", "\n", "src_tokens", ",", "src_lengths", "\n", ")", "\n", "encoder_state", "=", "w2v_feature", "# b x seq x 768", "\n", "if", "self", ".", "ctc_type", "==", "\"ctc_cnn\"", ":", "\n", "            ", "encoder_state", ",", "input_lengths", "=", "self", ".", "subsample_audio", "(", "w2v_feature", ",", "input_lengths", ")", "# seq x b x 512", "\n", "encoder_state", "=", "encoder_state", ".", "transpose", "(", "0", ",", "1", ")", "# b x seq x 512", "\n", "encoder_state", "=", "self", ".", "embed_scale", "*", "encoder_state", "\n", "encoder_padding_mask", "=", "lengths_to_padding_mask", "(", "input_lengths", ")", "\n", "", "else", ":", "\n", "            ", "assert", "self", ".", "ctc_type", "==", "\"ctc_w2v\"", ",", "\"ctc type should be ctc_w2v or ctc_cnn\"", "\n", "", "encoder_state", "=", "self", ".", "dropout_module", "(", "encoder_state", ")", "\n", "ctc_logit", "=", "self", ".", "ctc_projection", "(", "encoder_state", ")", "# b x seq x voc", "\n", "logits", "=", "ctc_logit", ".", "float", "(", ")", "\n", "log_probs", "=", "nn", ".", "functional", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "log_probs", "=", "log_probs", ".", "transpose", "(", "0", ",", "1", ")", "# seq x b x voc", "\n", "return", "ctc_logit", ",", "encoder_padding_mask", ",", "log_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.base_architecture": [[371, 417], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "", "@", "register_model_architecture", "(", "model_name", "=", "\"xstnet\"", ",", "arch_name", "=", "\"xstnet_base\"", ")", "\n", "def", "base_architecture", "(", "args", ")", ":", "\n", "# Wav2vec2.0 feature-extractor", "\n", "    ", "args", ".", "w2v2_model_path", "=", "getattr", "(", "args", ",", "\"w2v2_model_path\"", ",", "\"./wav2vec_small_100h.pt\"", ")", "\n", "args", ".", "freeze_w2v", "=", "getattr", "(", "args", ",", "\"freeze_w2v\"", ",", "False", ")", "# default is false, 'store_true'", "\n", "args", ".", "use_asr_finetune_w2v", "=", "getattr", "(", "args", ",", "\"use_asr_finetune_w2v\"", ",", "False", ")", "\n", "\n", "# Convolutional subsampler", "\n", "args", ".", "conv_kernel_sizes", "=", "getattr", "(", "args", ",", "\"conv_kernel_sizes\"", ",", "\"5,5\"", ")", "\n", "args", ".", "conv_channels", "=", "getattr", "(", "args", ",", "\"conv_channels\"", ",", "1024", ")", "\n", "# Transformer", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"textual_encoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "2048", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "6", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "encoder_normalize_before", "=", "getattr", "(", "args", ",", "\"encoder_normalize_before\"", ",", "True", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "args", ".", "encoder_embed_dim", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "args", ".", "encoder_ffn_embed_dim", "\n", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "6", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "decoder_normalize_before", "=", "getattr", "(", "args", ",", "\"decoder_normalize_before\"", ",", "True", ")", "\n", "args", ".", "decoder_learned_pos", "=", "getattr", "(", "args", ",", "\"decoder_learned_pos\"", ",", "False", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "args", ".", "dropout", ")", "\n", "args", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "args", ".", "dropout", ")", "\n", "args", ".", "activation_fn", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"relu\"", ")", "\n", "args", ".", "adaptive_softmax_cutoff", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_cutoff\"", ",", "None", ")", "\n", "args", ".", "adaptive_softmax_dropout", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_dropout\"", ",", "0", ")", "\n", "args", ".", "share_decoder_input_output_embed", "=", "getattr", "(", "\n", "args", ",", "\"share_decoder_input_output_embed\"", ",", "True", "\n", ")", "\n", "args", ".", "no_token_positional_embeddings", "=", "getattr", "(", "\n", "args", ",", "\"no_token_positional_embeddings\"", ",", "False", "\n", ")", "\n", "args", ".", "encoder_learned_pos", "=", "getattr", "(", "args", ",", "\"encoder_learned_pos\"", ",", "False", ")", "\n", "args", ".", "adaptive_input", "=", "getattr", "(", "args", ",", "\"adaptive_input\"", ",", "False", ")", "\n", "args", ".", "decoder_layerdrop", "=", "getattr", "(", "args", ",", "\"decoder_layerdrop\"", ",", "0.0", ")", "\n", "args", ".", "decoder_output_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_output_dim\"", ",", "args", ".", "decoder_embed_dim", "\n", ")", "\n", "args", ".", "decoder_input_dim", "=", "getattr", "(", "args", ",", "\"decoder_input_dim\"", ",", "args", ".", "decoder_embed_dim", ")", "\n", "args", ".", "no_scale_embedding", "=", "getattr", "(", "args", ",", "\"no_scale_embedding\"", ",", "False", ")", "\n", "args", ".", "quant_noise_pq", "=", "getattr", "(", "args", ",", "\"quant_noise_pq\"", ",", "0", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.Wav2Vec2Model.add_args": [[33, 298], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "fairseq.utils.get_available_activation_fns"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_available_activation_fns"], ["    ", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--extractor-mode\"", ",", "\n", "choices", "=", "[", "\"default\"", ",", "\"layer_norm\"", "]", ",", "\n", "help", "=", "\"mode for feature extractor. default has a single group norm with d groups in the first conv block, whereas layer_norm has layer norms in every block (meant to use with --normalize)\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-layers\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"L\"", ",", "\n", "help", "=", "\"num encoder layers in the transformer\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-embed-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"H\"", ",", "\n", "help", "=", "\"encoder embedding dimension\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-ffn-embed-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"F\"", ",", "\n", "help", "=", "\"encoder embedding dimension for FFN\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-attention-heads\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"A\"", ",", "\n", "help", "=", "\"num encoder attention heads\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--activation-fn\"", ",", "\n", "choices", "=", "utils", ".", "get_available_activation_fns", "(", ")", ",", "\n", "help", "=", "\"activation function to use\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability for the transformer\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--attention-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability for attention weights\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--activation-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability after activation in FFN\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--final-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"project final representations and targets to this many dimensions\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--layer-norm-first\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"apply layernorm first in the transformer\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-layerdrop\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"probability of dropping a tarnsformer layer\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--conv-feature-layers\"", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"EXPR\"", ",", "\n", "help", "=", "\"convolutional feature extraction layers [(dim, kernel_size, stride), ...]\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--logit-temp\"", ",", "type", "=", "float", ",", "help", "=", "\"temperature to divide logits by\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--quantize-targets\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"use quantized targets\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--quantize-input\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"use quantized inputs\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--same-quantizer\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"use same quantizer for inputs and targets\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--feature-grad-mult\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"multiply feature extractor var grads by this\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--latent-vars\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"number of latent variables V in each group of the codebook\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--latent-groups\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"number of groups G of latent variables in the codebook\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--latent-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"if set, uses this dimensionality for latent variables. otherwise uses final_dim / latent_groups\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--mask-length\"", ",", "type", "=", "int", ",", "help", "=", "\"mask length\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-prob\"", ",", "type", "=", "float", ",", "help", "=", "\"probability of replacing a token with mask\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-selection\"", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "[", "\"static\"", ",", "\"uniform\"", ",", "\"normal\"", ",", "\"poisson\"", "]", ",", "\n", "help", "=", "\"how to choose masks\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-other\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"secondary mask argument (used for more complex distributions), see help in compute_mask_indices\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no-mask-overlap\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"whether to allow masks to overlap\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-min-space\"", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"min space between spans (if no overlap is enabled)\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-channel-length\"", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"repeat the mask indices multiple times\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-channel-prob\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"probability of replacing a token with mask\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-channel-selection\"", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "[", "\"static\"", ",", "\"uniform\"", ",", "\"normal\"", ",", "\"poisson\"", "]", ",", "\n", "help", "=", "\"how to choose masks\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-channel-other\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"secondary mask argument (used for more complex distributions), see help in compute_mask_indices\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no-mask-channel-overlap\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"whether to allow masks to overlap\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-channel-min-space\"", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"min space between spans (if no overlap is enabled)\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dropout-input\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout to apply to the input (after feat extr)\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dropout-features\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout to apply to the features (after feat extr)\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num-negatives\"", ",", "type", "=", "int", ",", "metavar", "=", "\"N\"", ",", "help", "=", "\"number of negative examples\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--negatives-from-everywhere\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"sample negatives from everywhere, not just masked states\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cross-sample-negatives\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"num of cross sampled negatives\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--codebook-negatives\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"num of codebook sampled negatives\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--conv-pos\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"number of filters for convolutional positional embeddings\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--conv-pos-groups\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"number of groups for convolutional positional embedding\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--latent-temp\"", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"temperature for latent variable sampling. can be tuple of 3 values (start, end, decay)\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--target-glu\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"adds projection + glu to targets\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--conv-bias\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"include bias in conv encoder\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.Wav2Vec2Model.__init__": [[300, 399], ["fairseq.models.BaseFairseqModel.__init__", "eval", "wav2vec2.ConvFeatureExtractionModel", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Parameter", "torch.Parameter", "torch.Parameter", "wav2vec2.TransformerEncoder", "fairseq.modules.LayerNorm", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "fairseq.modules.GumbelVectorQuantizer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.Sequential", "torch.Sequential", "torch.Sequential", "fairseq.modules.GumbelVectorQuantizer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.GLU", "torch.GLU", "torch.GLU", "eval", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "eval"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n", "feature_enc_layers", "=", "eval", "(", "args", ".", "conv_feature_layers", ")", "\n", "self", ".", "embed", "=", "feature_enc_layers", "[", "-", "1", "]", "[", "0", "]", "\n", "\n", "self", ".", "feature_extractor", "=", "ConvFeatureExtractionModel", "(", "\n", "conv_layers", "=", "feature_enc_layers", ",", "\n", "dropout", "=", "0.0", ",", "\n", "mode", "=", "args", ".", "extractor_mode", ",", "\n", "conv_bias", "=", "args", ".", "conv_bias", ",", "\n", ")", "\n", "\n", "self", ".", "post_extract_proj", "=", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "embed", ",", "args", ".", "encoder_embed_dim", ")", "\n", "if", "self", ".", "embed", "!=", "args", ".", "encoder_embed_dim", "and", "not", "args", ".", "quantize_input", "\n", "else", "None", "\n", ")", "\n", "\n", "self", ".", "mask_prob", "=", "args", ".", "mask_prob", "\n", "self", ".", "mask_selection", "=", "args", ".", "mask_selection", "\n", "self", ".", "mask_other", "=", "args", ".", "mask_other", "\n", "self", ".", "mask_length", "=", "args", ".", "mask_length", "\n", "self", ".", "no_mask_overlap", "=", "args", ".", "no_mask_overlap", "\n", "self", ".", "mask_min_space", "=", "args", ".", "mask_min_space", "\n", "\n", "self", ".", "mask_channel_prob", "=", "args", ".", "mask_channel_prob", "\n", "self", ".", "mask_channel_selection", "=", "args", ".", "mask_channel_selection", "\n", "self", ".", "mask_channel_other", "=", "args", ".", "mask_channel_other", "\n", "self", ".", "mask_channel_length", "=", "args", ".", "mask_channel_length", "\n", "self", ".", "no_mask_channel_overlap", "=", "args", ".", "no_mask_channel_overlap", "\n", "self", ".", "mask_channel_min_space", "=", "args", ".", "mask_channel_min_space", "\n", "\n", "self", ".", "dropout_input", "=", "nn", ".", "Dropout", "(", "args", ".", "dropout_input", ")", "\n", "self", ".", "dropout_features", "=", "nn", ".", "Dropout", "(", "args", ".", "dropout_features", ")", "\n", "\n", "self", ".", "feature_grad_mult", "=", "args", ".", "feature_grad_mult", "\n", "\n", "self", ".", "quantizer", "=", "None", "\n", "self", ".", "input_quantizer", "=", "None", "\n", "\n", "self", ".", "n_negatives", "=", "args", ".", "num_negatives", "\n", "self", ".", "cross_sample_negatives", "=", "args", ".", "cross_sample_negatives", "\n", "self", ".", "codebook_negatives", "=", "args", ".", "codebook_negatives", "\n", "self", ".", "negatives_from_everywhere", "=", "args", ".", "negatives_from_everywhere", "\n", "\n", "self", ".", "logit_temp", "=", "args", ".", "logit_temp", "\n", "\n", "final_dim", "=", "args", ".", "final_dim", "if", "args", ".", "final_dim", ">", "0", "else", "args", ".", "encoder_embed_dim", "\n", "\n", "if", "args", ".", "quantize_targets", ":", "\n", "            ", "vq_dim", "=", "args", ".", "latent_dim", "if", "args", ".", "latent_dim", ">", "0", "else", "final_dim", "\n", "self", ".", "quantizer", "=", "GumbelVectorQuantizer", "(", "\n", "dim", "=", "self", ".", "embed", ",", "\n", "num_vars", "=", "args", ".", "latent_vars", ",", "\n", "temp", "=", "eval", "(", "args", ".", "latent_temp", ")", ",", "\n", "groups", "=", "args", ".", "latent_groups", ",", "\n", "combine_groups", "=", "False", ",", "\n", "vq_dim", "=", "vq_dim", ",", "\n", "time_first", "=", "True", ",", "\n", ")", "\n", "self", ".", "project_q", "=", "nn", ".", "Linear", "(", "vq_dim", ",", "final_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "project_q", "=", "nn", ".", "Linear", "(", "self", ".", "embed", ",", "final_dim", ")", "\n", "\n", "", "if", "args", ".", "quantize_input", ":", "\n", "            ", "if", "args", ".", "same_quantizer", "and", "self", ".", "quantizer", "is", "not", "None", ":", "\n", "                ", "vq_dim", "=", "final_dim", "\n", "self", ".", "input_quantizer", "=", "self", ".", "quantizer", "\n", "", "else", ":", "\n", "                ", "vq_dim", "=", "(", "\n", "args", ".", "latent_dim", "if", "args", ".", "latent_dim", ">", "0", "else", "args", ".", "encoder_embed_dim", "\n", ")", "\n", "self", ".", "input_quantizer", "=", "GumbelVectorQuantizer", "(", "\n", "dim", "=", "self", ".", "embed", ",", "\n", "num_vars", "=", "args", ".", "latent_vars", ",", "\n", "temp", "=", "eval", "(", "args", ".", "latent_temp", ")", ",", "\n", "groups", "=", "args", ".", "latent_groups", ",", "\n", "combine_groups", "=", "False", ",", "\n", "vq_dim", "=", "vq_dim", ",", "\n", "time_first", "=", "True", ",", "\n", ")", "\n", "", "self", ".", "project_inp", "=", "nn", ".", "Linear", "(", "vq_dim", ",", "args", ".", "encoder_embed_dim", ")", "\n", "\n", "", "self", ".", "mask_emb", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "FloatTensor", "(", "args", ".", "encoder_embed_dim", ")", ".", "uniform_", "(", ")", "\n", ")", "\n", "\n", "self", ".", "encoder", "=", "TransformerEncoder", "(", "args", ")", "\n", "self", ".", "layer_norm", "=", "LayerNorm", "(", "self", ".", "embed", ")", "\n", "\n", "self", ".", "target_glu", "=", "None", "\n", "if", "args", ".", "target_glu", ":", "\n", "            ", "self", ".", "target_glu", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "final_dim", ",", "final_dim", "*", "2", ")", ",", "nn", ".", "GLU", "(", ")", "\n", ")", "\n", "\n", "", "self", ".", "final_proj", "=", "nn", ".", "Linear", "(", "args", ".", "encoder_embed_dim", ",", "final_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.Wav2Vec2Model.upgrade_state_dict_named": [[400, 404], ["super().upgrade_state_dict_named"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.upgrade_state_dict_named"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "super", "(", ")", ".", "upgrade_state_dict_named", "(", "state_dict", ",", "name", ")", "\n", "\"\"\"Upgrade a (possibly old) state dict for new versions of fairseq.\"\"\"", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.Wav2Vec2Model.build_model": [[405, 413], ["wav2vec2.base_architecture", "cls"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", "=", "None", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "\n", "# make sure all arguments are present", "\n", "base_architecture", "(", "args", ")", "\n", "\n", "return", "cls", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.Wav2Vec2Model.apply_mask": [[414, 453], ["fairseq.data.data_utils.compute_mask_indices", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "fairseq.data.data_utils.compute_mask_indices", "torch.from_numpy().to().unsqueeze().expand", "torch.from_numpy().to().unsqueeze().expand", "torch.from_numpy().to().unsqueeze().expand", "torch.from_numpy().to().unsqueeze().expand", "torch.from_numpy().to().unsqueeze().expand", "torch.from_numpy().to().unsqueeze().expand", "torch.from_numpy().to().unsqueeze().expand", "torch.from_numpy().to().unsqueeze().expand", "torch.from_numpy().to().unsqueeze().expand", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().to().unsqueeze", "torch.from_numpy().to().unsqueeze", "torch.from_numpy().to().unsqueeze", "torch.from_numpy().to().unsqueeze", "torch.from_numpy().to().unsqueeze", "torch.from_numpy().to().unsqueeze", "torch.from_numpy().to().unsqueeze", "torch.from_numpy().to().unsqueeze", "torch.from_numpy().to().unsqueeze", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils.compute_mask_indices", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.compute_mask_indices"], ["", "def", "apply_mask", "(", "self", ",", "x", ",", "padding_mask", ")", ":", "\n", "        ", "B", ",", "T", ",", "C", "=", "x", ".", "shape", "\n", "if", "self", ".", "mask_prob", ">", "0", ":", "\n", "            ", "mask_indices", "=", "compute_mask_indices", "(", "\n", "(", "B", ",", "T", ")", ",", "\n", "padding_mask", ",", "\n", "self", ".", "mask_prob", ",", "\n", "self", ".", "mask_length", ",", "\n", "self", ".", "mask_selection", ",", "\n", "self", ".", "mask_other", ",", "\n", "min_masks", "=", "2", ",", "\n", "no_overlap", "=", "self", ".", "no_mask_overlap", ",", "\n", "min_space", "=", "self", ".", "mask_min_space", ",", "\n", ")", "\n", "mask_indices", "=", "torch", ".", "from_numpy", "(", "mask_indices", ")", ".", "to", "(", "x", ".", "device", ")", "\n", "x", "[", "mask_indices", "]", "=", "self", ".", "mask_emb", "\n", "", "else", ":", "\n", "            ", "mask_indices", "=", "None", "\n", "\n", "", "if", "self", ".", "mask_channel_prob", ">", "0", ":", "\n", "            ", "mask_channel_indices", "=", "compute_mask_indices", "(", "\n", "(", "B", ",", "C", ")", ",", "\n", "None", ",", "\n", "self", ".", "mask_channel_prob", ",", "\n", "self", ".", "mask_channel_length", ",", "\n", "self", ".", "mask_channel_selection", ",", "\n", "self", ".", "mask_channel_other", ",", "\n", "no_overlap", "=", "self", ".", "no_mask_channel_overlap", ",", "\n", "min_space", "=", "self", ".", "mask_channel_min_space", ",", "\n", ")", "\n", "mask_channel_indices", "=", "(", "\n", "torch", ".", "from_numpy", "(", "mask_channel_indices", ")", "\n", ".", "to", "(", "x", ".", "device", ")", "\n", ".", "unsqueeze", "(", "1", ")", "\n", ".", "expand", "(", "-", "1", ",", "T", ",", "-", "1", ")", "\n", ")", "\n", "x", "[", "mask_channel_indices", "]", "=", "0", "\n", "\n", "", "return", "x", ",", "mask_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.Wav2Vec2Model.sample_negatives": [[454, 511], ["y.view.view.view", "negs.view().permute.view().permute.view().permute", "y.view.view.new", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "fairseq.utils.buffered_arange().unsqueeze().expand().flatten", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "fairseq.utils.buffered_arange().unsqueeze().expand().flatten", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint.view", "torch.randint.view", "torch.randint.view", "negs.view().permute.view().permute.view", "fairseq.utils.buffered_arange().unsqueeze().expand", "fairseq.utils.buffered_arange().unsqueeze().expand", "fairseq.utils.buffered_arange().unsqueeze", "fairseq.utils.buffered_arange().unsqueeze", "fairseq.utils.buffered_arange", "fairseq.utils.buffered_arange"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.buffered_arange", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.buffered_arange"], ["", "def", "sample_negatives", "(", "self", ",", "y", ",", "num", ")", ":", "\n", "\n", "        ", "if", "self", ".", "n_negatives", "==", "0", "and", "self", ".", "cross_sample_negatives", "==", "0", ":", "\n", "            ", "return", "y", ".", "new", "(", "0", ")", "\n", "\n", "", "bsz", ",", "tsz", ",", "fsz", "=", "y", ".", "shape", "\n", "y", "=", "y", ".", "view", "(", "-", "1", ",", "fsz", ")", "# BTC => (BxT)C", "\n", "\n", "cross_high", "=", "tsz", "*", "bsz", "\n", "high", "=", "tsz", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "assert", "high", ">", "1", ",", "f\"{bsz,tsz,fsz}\"", "\n", "\n", "if", "self", ".", "n_negatives", ">", "0", ":", "\n", "                ", "tszs", "=", "(", "\n", "buffered_arange", "(", "num", ")", "\n", ".", "unsqueeze", "(", "-", "1", ")", "\n", ".", "expand", "(", "-", "1", ",", "self", ".", "n_negatives", ")", "\n", ".", "flatten", "(", ")", "\n", ")", "\n", "\n", "neg_idxs", "=", "torch", ".", "randint", "(", "\n", "low", "=", "0", ",", "high", "=", "high", "-", "1", ",", "size", "=", "(", "bsz", ",", "self", ".", "n_negatives", "*", "num", ")", "\n", ")", "\n", "neg_idxs", "[", "neg_idxs", ">=", "tszs", "]", "+=", "1", "\n", "\n", "", "if", "self", ".", "cross_sample_negatives", ">", "0", ":", "\n", "                ", "tszs", "=", "(", "\n", "buffered_arange", "(", "num", ")", "\n", ".", "unsqueeze", "(", "-", "1", ")", "\n", ".", "expand", "(", "-", "1", ",", "self", ".", "cross_sample_negatives", ")", "\n", ".", "flatten", "(", ")", "\n", ")", "\n", "\n", "cross_neg_idxs", "=", "torch", ".", "randint", "(", "\n", "low", "=", "0", ",", "\n", "high", "=", "cross_high", "-", "1", ",", "\n", "size", "=", "(", "bsz", ",", "self", ".", "cross_sample_negatives", "*", "num", ")", ",", "\n", ")", "\n", "cross_neg_idxs", "[", "cross_neg_idxs", ">=", "tszs", "]", "+=", "1", "\n", "\n", "", "", "if", "self", ".", "n_negatives", ">", "0", ":", "\n", "            ", "for", "i", "in", "range", "(", "1", ",", "bsz", ")", ":", "\n", "                ", "neg_idxs", "[", "i", "]", "+=", "i", "*", "high", "\n", "", "", "else", ":", "\n", "            ", "neg_idxs", "=", "cross_neg_idxs", "\n", "\n", "", "if", "self", ".", "cross_sample_negatives", ">", "0", "and", "self", ".", "n_negatives", ">", "0", ":", "\n", "            ", "neg_idxs", "=", "torch", ".", "cat", "(", "[", "neg_idxs", ",", "cross_neg_idxs", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "negs", "=", "y", "[", "neg_idxs", ".", "view", "(", "-", "1", ")", "]", "\n", "negs", "=", "negs", ".", "view", "(", "\n", "bsz", ",", "num", ",", "self", ".", "n_negatives", "+", "self", ".", "cross_sample_negatives", ",", "fsz", "\n", ")", ".", "permute", "(", "\n", "2", ",", "0", ",", "1", ",", "3", "\n", ")", "# to NxBxTxC", "\n", "return", "negs", ",", "neg_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.Wav2Vec2Model.compute_preds": [[512, 526], ["y.unsqueeze.unsqueeze.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cosine_similarity().type_as", "torch.cosine_similarity().type_as", "torch.cosine_similarity().type_as", "torch.cosine_similarity().type_as", "torch.cosine_similarity().type_as", "torch.cosine_similarity().type_as", "torch.cosine_similarity().type_as", "torch.cosine_similarity().type_as", "torch.cosine_similarity().type_as", "neg_is_pos.any", "float", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "x.float", "torch.cat.float", "torch.cat.float", "torch.cat.float"], "methods", ["None"], ["", "def", "compute_preds", "(", "self", ",", "x", ",", "y", ",", "negatives", ")", ":", "\n", "\n", "        ", "neg_is_pos", "=", "(", "y", "==", "negatives", ")", ".", "all", "(", "-", "1", ")", "\n", "y", "=", "y", ".", "unsqueeze", "(", "0", ")", "\n", "targets", "=", "torch", ".", "cat", "(", "[", "y", ",", "negatives", "]", ",", "dim", "=", "0", ")", "\n", "\n", "logits", "=", "torch", ".", "cosine_similarity", "(", "x", ".", "float", "(", ")", ",", "targets", ".", "float", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "type_as", "(", "x", ")", "\n", "\n", "logits", "/=", "self", ".", "logit_temp", "\n", "\n", "if", "neg_is_pos", ".", "any", "(", ")", ":", "\n", "            ", "logits", "[", "1", ":", "]", "[", "neg_is_pos", "]", "=", "float", "(", "\"-inf\"", ")", "\n", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.Wav2Vec2Model.forward": [[527, 642], ["wav2vec2.Wav2Vec2Model.float().pow().mean", "wav2vec2.Wav2Vec2Model.transpose", "wav2vec2.Wav2Vec2Model.layer_norm", "wav2vec2.Wav2Vec2Model.clone", "wav2vec2.Wav2Vec2Model.dropout_input", "wav2vec2.Wav2Vec2Model.dropout_features", "wav2vec2.Wav2Vec2Model.encoder", "x[].view", "wav2vec2.Wav2Vec2Model.final_proj", "wav2vec2.Wav2Vec2Model.compute_preds", "wav2vec2.Wav2Vec2Model.feature_extractor", "padding_mask.all.all.view", "padding_mask.all.all.all", "wav2vec2.Wav2Vec2Model.post_extract_proj", "wav2vec2.Wav2Vec2Model.input_quantizer", "wav2vec2.Wav2Vec2Model.project_inp", "wav2vec2.Wav2Vec2Model.apply_mask", "wav2vec2.Wav2Vec2Model.quantizer", "wav2vec2.Wav2Vec2Model.project_q", "wav2vec2.Wav2Vec2Model.project_q", "wav2vec2.Wav2Vec2Model.size", "wav2vec2.Wav2Vec2Model.size", "wav2vec2.Wav2Vec2Model.target_glu", "wav2vec2.Wav2Vec2Model.target_glu", "fairseq.modules.GradMultiply.apply", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "wav2vec2.Wav2Vec2Model.feature_extractor", "wav2vec2.Wav2Vec2Model.float().pow", "padding_mask.all.all.size", "wav2vec2.Wav2Vec2Model.size", "padding_mask.all.all.size", "wav2vec2.Wav2Vec2Model.size", "unmasked_features[].view", "wav2vec2.Wav2Vec2Model.quantizer", "wav2vec2.Wav2Vec2Model.sample_negatives", "wav2vec2.Wav2Vec2Model.project_q", "wav2vec2.Wav2Vec2Model.sample_negatives", "wav2vec2.Wav2Vec2Model.quantizer.sample_from_codebook", "wav2vec2.Wav2Vec2Model.view", "wav2vec2.Wav2Vec2Model.project_q", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "wav2vec2.Wav2Vec2Model.sample_negatives", "wav2vec2.Wav2Vec2Model.project_q", "wav2vec2.Wav2Vec2Model.sample_negatives", "wav2vec2.Wav2Vec2Model.size", "wav2vec2.Wav2Vec2Model.size", "unmasked_features[].view.size", "unmasked_features[].view.size", "unmasked_features[].view.size", "unmasked_features[].view.size", "unmasked_features[].view.size", "unmasked_features[].view.size", "wav2vec2.Wav2Vec2Model.float", "unmasked_features[].view.size", "unmasked_features[].view.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.Wav2Vec2Model.compute_preds", "home.repos.pwc.inspect_result.reneeye_const.data.mask_tokens_dataset.MaskTokensDataset.apply_mask", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecPredictionsModel.sample_negatives", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecPredictionsModel.sample_negatives", "home.repos.pwc.inspect_result.reneeye_const.modules.gumbel_vector_quantizer.GumbelVectorQuantizer.sample_from_codebook", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecPredictionsModel.sample_negatives", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecPredictionsModel.sample_negatives", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "forward", "(", "self", ",", "source", ",", "padding_mask", "=", "None", ",", "mask", "=", "True", ",", "features_only", "=", "False", ")", ":", "\n", "\n", "        ", "if", "self", ".", "feature_grad_mult", ">", "0", ":", "\n", "            ", "features", "=", "self", ".", "feature_extractor", "(", "source", ")", "\n", "if", "self", ".", "feature_grad_mult", "!=", "1.0", ":", "\n", "                ", "features", "=", "GradMultiply", ".", "apply", "(", "features", ",", "self", ".", "feature_grad_mult", ")", "\n", "", "", "else", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "features", "=", "self", ".", "feature_extractor", "(", "source", ")", "\n", "\n", "", "", "features_pen", "=", "features", ".", "float", "(", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "\n", "features", "=", "features", ".", "transpose", "(", "1", ",", "2", ")", "\n", "features", "=", "self", ".", "layer_norm", "(", "features", ")", "\n", "unmasked_features", "=", "features", ".", "clone", "(", ")", "\n", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "            ", "extra", "=", "padding_mask", ".", "size", "(", "1", ")", "%", "features", ".", "size", "(", "1", ")", "\n", "if", "extra", ">", "0", ":", "\n", "                ", "padding_mask", "=", "padding_mask", "[", ":", ",", ":", "-", "extra", "]", "\n", "", "padding_mask", "=", "padding_mask", ".", "view", "(", "padding_mask", ".", "size", "(", "0", ")", ",", "features", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "padding_mask", "=", "padding_mask", ".", "all", "(", "-", "1", ")", "\n", "\n", "", "if", "self", ".", "post_extract_proj", "is", "not", "None", ":", "\n", "            ", "features", "=", "self", ".", "post_extract_proj", "(", "features", ")", "\n", "\n", "", "features", "=", "self", ".", "dropout_input", "(", "features", ")", "\n", "unmasked_features", "=", "self", ".", "dropout_features", "(", "unmasked_features", ")", "\n", "\n", "num_vars", "=", "None", "\n", "code_ppl", "=", "None", "\n", "prob_ppl", "=", "None", "\n", "curr_temp", "=", "None", "\n", "\n", "if", "self", ".", "input_quantizer", ":", "\n", "            ", "q", "=", "self", ".", "input_quantizer", "(", "features", ",", "produce_targets", "=", "False", ")", "\n", "features", "=", "q", "[", "\"x\"", "]", "\n", "num_vars", "=", "q", "[", "\"num_vars\"", "]", "\n", "code_ppl", "=", "q", "[", "\"code_perplexity\"", "]", "\n", "prob_ppl", "=", "q", "[", "\"prob_perplexity\"", "]", "\n", "curr_temp", "=", "q", "[", "\"temp\"", "]", "\n", "features", "=", "self", ".", "project_inp", "(", "features", ")", "\n", "\n", "", "if", "mask", ":", "\n", "            ", "x", ",", "mask_indices", "=", "self", ".", "apply_mask", "(", "features", ",", "padding_mask", ")", "\n", "if", "mask_indices", "is", "not", "None", ":", "\n", "                ", "y", "=", "unmasked_features", "[", "mask_indices", "]", ".", "view", "(", "\n", "unmasked_features", ".", "size", "(", "0", ")", ",", "-", "1", ",", "unmasked_features", ".", "size", "(", "-", "1", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "y", "=", "unmasked_features", "\n", "", "", "else", ":", "\n", "            ", "x", "=", "features", "\n", "y", "=", "unmasked_features", "\n", "mask_indices", "=", "None", "\n", "\n", "", "x", "=", "self", ".", "encoder", "(", "x", ",", "padding_mask", "=", "padding_mask", ")", "\n", "\n", "if", "features_only", ":", "\n", "            ", "return", "{", "\"x\"", ":", "x", ",", "\"padding_mask\"", ":", "padding_mask", "}", "\n", "\n", "", "if", "self", ".", "quantizer", ":", "\n", "            ", "q", "=", "self", ".", "quantizer", "(", "y", ",", "produce_targets", "=", "False", ")", "\n", "y", "=", "q", "[", "\"x\"", "]", "\n", "num_vars", "=", "q", "[", "\"num_vars\"", "]", "\n", "code_ppl", "=", "q", "[", "\"code_perplexity\"", "]", "\n", "prob_ppl", "=", "q", "[", "\"prob_perplexity\"", "]", "\n", "curr_temp", "=", "q", "[", "\"temp\"", "]", "\n", "\n", "y", "=", "self", ".", "project_q", "(", "y", ")", "\n", "\n", "if", "self", ".", "negatives_from_everywhere", ":", "\n", "                ", "neg_cands", ",", "*", "_", "=", "self", ".", "quantizer", "(", "unmasked_features", ",", "produce_targets", "=", "False", ")", "\n", "negs", ",", "_", "=", "self", ".", "sample_negatives", "(", "neg_cands", ",", "y", ".", "size", "(", "1", ")", ")", "\n", "negs", "=", "self", ".", "project_q", "(", "negs", ")", "\n", "\n", "", "else", ":", "\n", "                ", "negs", ",", "_", "=", "self", ".", "sample_negatives", "(", "y", ",", "y", ".", "size", "(", "1", ")", ")", "\n", "\n", "", "if", "self", ".", "codebook_negatives", ">", "0", ":", "\n", "                ", "cb_negs", "=", "self", ".", "quantizer", ".", "sample_from_codebook", "(", "\n", "y", ".", "size", "(", "0", ")", "*", "y", ".", "size", "(", "1", ")", ",", "self", ".", "codebook_negatives", "\n", ")", "\n", "cb_negs", "=", "cb_negs", ".", "view", "(", "\n", "self", ".", "codebook_negatives", ",", "y", ".", "size", "(", "0", ")", ",", "y", ".", "size", "(", "1", ")", ",", "-", "1", "\n", ")", "# order doesnt matter", "\n", "cb_negs", "=", "self", ".", "project_q", "(", "cb_negs", ")", "\n", "negs", "=", "torch", ".", "cat", "(", "[", "negs", ",", "cb_negs", "]", ",", "dim", "=", "0", ")", "\n", "", "", "else", ":", "\n", "            ", "y", "=", "self", ".", "project_q", "(", "y", ")", "\n", "\n", "if", "self", ".", "negatives_from_everywhere", ":", "\n", "                ", "negs", ",", "_", "=", "self", ".", "sample_negatives", "(", "unmasked_features", ",", "y", ".", "size", "(", "1", ")", ")", "\n", "negs", "=", "self", ".", "project_q", "(", "negs", ")", "\n", "", "else", ":", "\n", "                ", "negs", ",", "_", "=", "self", ".", "sample_negatives", "(", "y", ",", "y", ".", "size", "(", "1", ")", ")", "\n", "\n", "", "", "x", "=", "x", "[", "mask_indices", "]", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "if", "self", ".", "target_glu", ":", "\n", "            ", "y", "=", "self", ".", "target_glu", "(", "y", ")", "\n", "negs", "=", "self", ".", "target_glu", "(", "negs", ")", "\n", "\n", "", "x", "=", "self", ".", "final_proj", "(", "x", ")", "\n", "x", "=", "self", ".", "compute_preds", "(", "x", ",", "y", ",", "negs", ")", "\n", "\n", "result", "=", "{", "\"x\"", ":", "x", ",", "\"padding_mask\"", ":", "padding_mask", ",", "\"features_pen\"", ":", "features_pen", "}", "\n", "\n", "if", "prob_ppl", "is", "not", "None", ":", "\n", "            ", "result", "[", "\"prob_perplexity\"", "]", "=", "prob_ppl", "\n", "result", "[", "\"code_perplexity\"", "]", "=", "code_ppl", "\n", "result", "[", "\"num_vars\"", "]", "=", "num_vars", "\n", "result", "[", "\"temp\"", "]", "=", "curr_temp", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.Wav2Vec2Model.quantize": [[643, 649], ["wav2vec2.Wav2Vec2Model.feature_extractor", "wav2vec2.Wav2Vec2Model.transpose", "wav2vec2.Wav2Vec2Model.layer_norm", "wav2vec2.Wav2Vec2Model.quantizer.forward_idx"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.kmeans_vector_quantizer.KmeansVectorQuantizer.forward_idx"], ["", "def", "quantize", "(", "self", ",", "x", ")", ":", "\n", "        ", "assert", "self", ".", "quantizer", "is", "not", "None", "\n", "x", "=", "self", ".", "feature_extractor", "(", "x", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "return", "self", ".", "quantizer", ".", "forward_idx", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.Wav2Vec2Model.extract_features": [[650, 653], ["wav2vec2.Wav2Vec2Model.forward"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.forward"], ["", "def", "extract_features", "(", "self", ",", "source", ",", "padding_mask", ",", "mask", "=", "False", ")", ":", "\n", "        ", "res", "=", "self", ".", "forward", "(", "source", ",", "padding_mask", ",", "mask", "=", "mask", ",", "features_only", "=", "True", ")", "\n", "return", "res", "[", "\"x\"", "]", ",", "res", "[", "\"padding_mask\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.Wav2Vec2Model.get_logits": [[654, 659], ["logits.reshape.reshape.transpose", "logits.reshape.reshape.reshape", "logits.reshape.reshape.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "get_logits", "(", "self", ",", "net_output", ")", ":", "\n", "        ", "logits", "=", "net_output", "[", "\"x\"", "]", "\n", "logits", "=", "logits", ".", "transpose", "(", "0", ",", "2", ")", "\n", "logits", "=", "logits", ".", "reshape", "(", "-", "1", ",", "logits", ".", "size", "(", "-", "1", ")", ")", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.Wav2Vec2Model.get_targets": [[660, 663], ["x.new_zeros", "x.size", "x.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "get_targets", "(", "self", ",", "sample", ",", "net_output", ",", "expand_steps", "=", "True", ")", ":", "\n", "        ", "x", "=", "net_output", "[", "\"x\"", "]", "\n", "return", "x", ".", "new_zeros", "(", "x", ".", "size", "(", "1", ")", "*", "x", ".", "size", "(", "2", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.Wav2Vec2Model.get_extra_losses": [[664, 677], ["pen.append", "pen.append"], "methods", ["None"], ["", "def", "get_extra_losses", "(", "self", ",", "net_output", ")", ":", "\n", "        ", "pen", "=", "[", "]", "\n", "\n", "if", "\"prob_perplexity\"", "in", "net_output", ":", "\n", "            ", "pen", ".", "append", "(", "\n", "(", "net_output", "[", "\"num_vars\"", "]", "-", "net_output", "[", "\"prob_perplexity\"", "]", ")", "\n", "/", "net_output", "[", "\"num_vars\"", "]", "\n", ")", "\n", "\n", "", "if", "\"features_pen\"", "in", "net_output", ":", "\n", "            ", "pen", ".", "append", "(", "net_output", "[", "\"features_pen\"", "]", ")", "\n", "\n", "", "return", "pen", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.Wav2Vec2Model.remove_pretraining_modules": [[678, 683], ["None"], "methods", ["None"], ["", "def", "remove_pretraining_modules", "(", "self", ")", ":", "\n", "        ", "self", ".", "quantizer", "=", "None", "\n", "self", ".", "project_q", "=", "None", "\n", "self", ".", "target_glu", "=", "None", "\n", "self", ".", "final_proj", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.ConvFeatureExtractionModel.__init__": [[686, 754], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "enumerate", "wav2vec2.ConvFeatureExtractionModel.conv_layers.append", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.Sequential", "torch.Sequential", "torch.Sequential", "len", "str", "wav2vec2.ConvFeatureExtractionModel.__init__.block"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "conv_layers", ":", "List", "[", "Tuple", "[", "int", ",", "int", ",", "int", "]", "]", ",", "\n", "dropout", ":", "float", "=", "0.0", ",", "\n", "mode", ":", "str", "=", "\"default\"", ",", "\n", "conv_bias", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "mode", "in", "{", "\"default\"", ",", "\"layer_norm\"", "}", "\n", "\n", "def", "block", "(", "\n", "n_in", ",", "\n", "n_out", ",", "\n", "k", ",", "\n", "stride", ",", "\n", "is_layer_norm", "=", "False", ",", "\n", "is_group_norm", "=", "False", ",", "\n", "conv_bias", "=", "False", ",", "\n", ")", ":", "\n", "            ", "def", "make_conv", "(", ")", ":", "\n", "                ", "conv", "=", "nn", ".", "Conv1d", "(", "n_in", ",", "n_out", ",", "k", ",", "stride", "=", "stride", ",", "bias", "=", "conv_bias", ")", "\n", "nn", ".", "init", ".", "kaiming_normal_", "(", "conv", ".", "weight", ")", "\n", "return", "conv", "\n", "\n", "", "assert", "(", "\n", "is_layer_norm", "and", "is_group_norm", "\n", ")", "==", "False", ",", "\"layer norm and group norm are exclusive\"", "\n", "\n", "if", "is_layer_norm", ":", "\n", "                ", "return", "nn", ".", "Sequential", "(", "\n", "make_conv", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ",", "\n", "nn", ".", "Sequential", "(", "\n", "TransposeLast", "(", ")", ",", "\n", "Fp32LayerNorm", "(", "dim", ",", "elementwise_affine", "=", "True", ")", ",", "\n", "TransposeLast", "(", ")", ",", "\n", ")", ",", "\n", "nn", ".", "GELU", "(", ")", ",", "\n", ")", "\n", "", "elif", "is_group_norm", ":", "\n", "                ", "return", "nn", ".", "Sequential", "(", "\n", "make_conv", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ",", "\n", "Fp32GroupNorm", "(", "dim", ",", "dim", ",", "affine", "=", "True", ")", ",", "\n", "nn", ".", "GELU", "(", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "return", "nn", ".", "Sequential", "(", "make_conv", "(", ")", ",", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ",", "nn", ".", "GELU", "(", ")", ")", "\n", "\n", "", "", "in_d", "=", "1", "\n", "self", ".", "conv_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", ",", "cl", "in", "enumerate", "(", "conv_layers", ")", ":", "\n", "            ", "assert", "len", "(", "cl", ")", "==", "3", ",", "\"invalid conv definition: \"", "+", "str", "(", "cl", ")", "\n", "(", "dim", ",", "k", ",", "stride", ")", "=", "cl", "\n", "\n", "self", ".", "conv_layers", ".", "append", "(", "\n", "block", "(", "\n", "in_d", ",", "\n", "dim", ",", "\n", "k", ",", "\n", "stride", ",", "\n", "is_layer_norm", "=", "mode", "==", "\"layer_norm\"", ",", "\n", "is_group_norm", "=", "mode", "==", "\"default\"", "and", "i", "==", "0", ",", "\n", "conv_bias", "=", "conv_bias", ",", "\n", ")", "\n", ")", "\n", "in_d", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.ConvFeatureExtractionModel.forward": [[755, 764], ["conv.unsqueeze", "conv"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "# BxT -> BxCxT", "\n", "        ", "x", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "for", "conv", "in", "self", ".", "conv_layers", ":", "\n", "            ", "x", "=", "conv", "(", "x", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.TransformerEncoder.__init__": [[767, 809], ["torch.Module.__init__", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "math.sqrt", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "fairseq.modules.LayerNorm", "wav2vec2.TransformerEncoder.apply", "fairseq.modules.SamePad", "torch.GELU", "torch.GELU", "torch.GELU", "wav2vec2.TransformerSentenceEncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dropout", "=", "args", ".", "dropout", "\n", "self", ".", "embedding_dim", "=", "args", ".", "encoder_embed_dim", "\n", "\n", "self", ".", "pos_conv", "=", "nn", ".", "Conv1d", "(", "\n", "self", ".", "embedding_dim", ",", "\n", "self", ".", "embedding_dim", ",", "\n", "kernel_size", "=", "args", ".", "conv_pos", ",", "\n", "padding", "=", "args", ".", "conv_pos", "//", "2", ",", "\n", "groups", "=", "args", ".", "conv_pos_groups", ",", "\n", ")", "\n", "dropout", "=", "0", "\n", "std", "=", "math", ".", "sqrt", "(", "(", "4", "*", "(", "1.0", "-", "dropout", ")", ")", "/", "(", "args", ".", "conv_pos", "*", "self", ".", "embedding_dim", ")", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "pos_conv", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "std", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "pos_conv", ".", "bias", ",", "0", ")", "\n", "\n", "self", ".", "pos_conv", "=", "nn", ".", "utils", ".", "weight_norm", "(", "self", ".", "pos_conv", ",", "name", "=", "\"weight\"", ",", "dim", "=", "2", ")", "\n", "self", ".", "pos_conv", "=", "nn", ".", "Sequential", "(", "self", ".", "pos_conv", ",", "SamePad", "(", "args", ".", "conv_pos", ")", ",", "nn", ".", "GELU", "(", ")", ")", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "TransformerSentenceEncoderLayer", "(", "\n", "embedding_dim", "=", "self", ".", "embedding_dim", ",", "\n", "ffn_embedding_dim", "=", "args", ".", "encoder_ffn_embed_dim", ",", "\n", "num_attention_heads", "=", "args", ".", "encoder_attention_heads", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "attention_dropout", "=", "args", ".", "attention_dropout", ",", "\n", "activation_dropout", "=", "args", ".", "activation_dropout", ",", "\n", "activation_fn", "=", "args", ".", "activation_fn", ",", "\n", "layer_norm_first", "=", "args", ".", "layer_norm_first", ",", "\n", ")", "\n", "for", "_", "in", "range", "(", "args", ".", "encoder_layers", ")", "\n", "]", "\n", ")", "\n", "\n", "self", ".", "layer_norm_first", "=", "args", ".", "layer_norm_first", "\n", "self", ".", "layer_norm", "=", "LayerNorm", "(", "self", ".", "embedding_dim", ")", "\n", "self", ".", "layerdrop", "=", "args", ".", "encoder_layerdrop", "\n", "\n", "self", ".", "apply", "(", "init_bert_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.TransformerEncoder.forward": [[810, 817], ["wav2vec2.TransformerEncoder.extract_features", "wav2vec2.TransformerEncoder.layer_norm"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features"], ["", "def", "forward", "(", "self", ",", "x", ",", "padding_mask", "=", "None", ")", ":", "\n", "        ", "x", "=", "self", ".", "extract_features", "(", "x", ",", "padding_mask", ")", "\n", "\n", "if", "self", ".", "layer_norm_first", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.TransformerEncoder.extract_features": [[818, 846], ["wav2vec2.TransformerEncoder.pos_conv", "x_conv.transpose.transpose.transpose", "torch.dropout", "torch.dropout", "torch.dropout", "wav2vec2.TransformerEncoder.transpose", "enumerate", "wav2vec2.TransformerEncoder.transpose", "wav2vec2.TransformerEncoder.transpose", "wav2vec2.TransformerEncoder.layer_norm", "numpy.random.random", "layer", "layer_results.append"], "methods", ["None"], ["", "def", "extract_features", "(", "self", ",", "x", ",", "padding_mask", "=", "None", ")", ":", "\n", "\n", "        ", "if", "padding_mask", "is", "not", "None", ":", "\n", "            ", "x", "[", "padding_mask", "]", "=", "0", "\n", "\n", "", "x_conv", "=", "self", ".", "pos_conv", "(", "x", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "x_conv", "=", "x_conv", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x", "=", "x", "+", "x_conv", "\n", "\n", "if", "not", "self", ".", "layer_norm_first", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "layer_results", "=", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "dropout_probability", "=", "np", ".", "random", ".", "random", "(", ")", "\n", "if", "not", "self", ".", "training", "or", "(", "dropout_probability", ">", "self", ".", "layerdrop", ")", ":", "\n", "                ", "x", ",", "z", "=", "layer", "(", "x", ",", "self_attn_padding_mask", "=", "padding_mask", ",", "need_weights", "=", "False", ")", "\n", "layer_results", ".", "append", "(", "x", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "", "", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.TransformerEncoder.max_positions": [[847, 850], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum output length supported by the encoder.\"\"\"", "\n", "return", "self", ".", "args", ".", "max_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.TransformerEncoder.upgrade_state_dict_named": [[851, 854], ["None"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "\"\"\"Upgrade a (possibly old) state dict for new versions of fairseq.\"\"\"", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.TransformerSentenceEncoderLayer.__init__": [[862, 902], ["torch.Module.__init__", "fairseq.utils.get_activation_fn", "fairseq.modules.MultiheadAttention", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "fairseq.modules.LayerNorm", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "fairseq.modules.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embedding_dim", ":", "float", "=", "768", ",", "\n", "ffn_embedding_dim", ":", "float", "=", "3072", ",", "\n", "num_attention_heads", ":", "float", "=", "8", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "attention_dropout", ":", "float", "=", "0.1", ",", "\n", "activation_dropout", ":", "float", "=", "0.1", ",", "\n", "activation_fn", ":", "str", "=", "\"relu\"", ",", "\n", "layer_norm_first", ":", "bool", "=", "False", ",", "\n", ")", "->", "None", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# Initialize parameters", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "activation_dropout", "=", "activation_dropout", "\n", "\n", "# Initialize blocks", "\n", "self", ".", "activation_fn", "=", "utils", ".", "get_activation_fn", "(", "activation_fn", ")", "\n", "self", ".", "self_attn", "=", "MultiheadAttention", "(", "\n", "self", ".", "embedding_dim", ",", "\n", "num_attention_heads", ",", "\n", "dropout", "=", "attention_dropout", ",", "\n", "self_attention", "=", "True", ",", "\n", ")", "\n", "\n", "self", ".", "dropout1", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropout2", "=", "nn", ".", "Dropout", "(", "self", ".", "activation_dropout", ")", "\n", "self", ".", "dropout3", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "self", ".", "layer_norm_first", "=", "layer_norm_first", "\n", "\n", "# layer norm associated with the self attention layer", "\n", "self", ".", "self_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embedding_dim", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "self", ".", "embedding_dim", ",", "ffn_embedding_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "ffn_embedding_dim", ",", "self", ".", "embedding_dim", ")", "\n", "\n", "# layer norm associated with the position wise feed-forward NN", "\n", "self", ".", "final_layer_norm", "=", "LayerNorm", "(", "self", ".", "embedding_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.TransformerSentenceEncoderLayer.forward": [[903, 960], ["wav2vec2.TransformerSentenceEncoderLayer.self_attn_layer_norm", "wav2vec2.TransformerSentenceEncoderLayer.self_attn", "wav2vec2.TransformerSentenceEncoderLayer.dropout1", "wav2vec2.TransformerSentenceEncoderLayer.final_layer_norm", "wav2vec2.TransformerSentenceEncoderLayer.activation_fn", "wav2vec2.TransformerSentenceEncoderLayer.dropout2", "wav2vec2.TransformerSentenceEncoderLayer.fc2", "wav2vec2.TransformerSentenceEncoderLayer.dropout3", "wav2vec2.TransformerSentenceEncoderLayer.self_attn", "wav2vec2.TransformerSentenceEncoderLayer.dropout1", "wav2vec2.TransformerSentenceEncoderLayer.self_attn_layer_norm", "wav2vec2.TransformerSentenceEncoderLayer.activation_fn", "wav2vec2.TransformerSentenceEncoderLayer.dropout2", "wav2vec2.TransformerSentenceEncoderLayer.fc2", "wav2vec2.TransformerSentenceEncoderLayer.dropout3", "wav2vec2.TransformerSentenceEncoderLayer.final_layer_norm", "wav2vec2.TransformerSentenceEncoderLayer.fc1", "wav2vec2.TransformerSentenceEncoderLayer.fc1"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "x", ":", "torch", ".", "Tensor", ",", "\n", "self_attn_mask", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "self_attn_padding_mask", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "need_weights", ":", "bool", "=", "False", ",", "\n", "att_args", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        LayerNorm is applied either before or after the self-attention/ffn\n        modules similar to the original Transformer imlementation.\n        \"\"\"", "\n", "residual", "=", "x", "\n", "\n", "if", "self", ".", "layer_norm_first", ":", "\n", "            ", "x", "=", "self", ".", "self_attn_layer_norm", "(", "x", ")", "\n", "x", ",", "attn", "=", "self", ".", "self_attn", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "x", ",", "\n", "value", "=", "x", ",", "\n", "key_padding_mask", "=", "self_attn_padding_mask", ",", "\n", "need_weights", "=", "False", ",", "\n", "attn_mask", "=", "self_attn_mask", ",", "\n", ")", "\n", "x", "=", "self", ".", "dropout1", "(", "x", ")", "\n", "x", "=", "residual", "+", "x", "\n", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "final_layer_norm", "(", "x", ")", "\n", "x", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "dropout2", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout3", "(", "x", ")", "\n", "x", "=", "residual", "+", "x", "\n", "", "else", ":", "\n", "            ", "x", ",", "attn", "=", "self", ".", "self_attn", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "x", ",", "\n", "value", "=", "x", ",", "\n", "key_padding_mask", "=", "self_attn_padding_mask", ",", "\n", "need_weights", "=", "need_weights", ",", "\n", ")", "\n", "\n", "x", "=", "self", ".", "dropout1", "(", "x", ")", "\n", "x", "=", "residual", "+", "x", "\n", "\n", "x", "=", "self", ".", "self_attn_layer_norm", "(", "x", ")", "\n", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "dropout2", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout3", "(", "x", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "final_layer_norm", "(", "x", ")", "\n", "\n", "", "return", "x", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.base_architecture": [[962, 1030], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "", "@", "register_model_architecture", "(", "\"wav2vec2\"", ",", "\"wav2vec2\"", ")", "\n", "def", "base_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "extractor_mode", "=", "getattr", "(", "args", ",", "\"extractor_mode\"", ",", "\"default\"", ")", "\n", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "12", ")", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "768", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "3072", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "12", ")", "\n", "\n", "args", ".", "activation_fn", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"gelu\"", ")", "\n", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.1", ")", "\n", "args", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "0.0", ")", "\n", "\n", "args", ".", "final_dim", "=", "getattr", "(", "args", ",", "\"final_dim\"", ",", "0", ")", "\n", "\n", "args", ".", "layer_norm_first", "=", "getattr", "(", "args", ",", "\"layer_norm_first\"", ",", "False", ")", "\n", "args", ".", "encoder_layerdrop", "=", "getattr", "(", "args", ",", "\"encoder_layerdrop\"", ",", "0.0", ")", "\n", "\n", "conv_feature_layers", "=", "\"[(512, 10, 5)]\"", "\n", "conv_feature_layers", "+=", "\" + [(512, 8, 4)]\"", "\n", "conv_feature_layers", "+=", "\" + [(512, 4, 2)] * 3\"", "\n", "conv_feature_layers", "+=", "\" + [(512, 1, 1)]\"", "\n", "args", ".", "conv_feature_layers", "=", "getattr", "(", "args", ",", "\"conv_feature_layers\"", ",", "conv_feature_layers", ")", "\n", "\n", "args", ".", "logit_temp", "=", "getattr", "(", "args", ",", "\"logit_temp\"", ",", "0.1", ")", "\n", "\n", "args", ".", "quantize_targets", "=", "getattr", "(", "args", ",", "\"quantize_targets\"", ",", "False", ")", "\n", "args", ".", "quantize_input", "=", "getattr", "(", "args", ",", "\"quantize_input\"", ",", "False", ")", "\n", "args", ".", "same_quantizer", "=", "getattr", "(", "args", ",", "\"same_quantizer\"", ",", "False", ")", "\n", "\n", "args", ".", "feature_grad_mult", "=", "getattr", "(", "args", ",", "\"feature_grad_mult\"", ",", "1.0", ")", "\n", "\n", "args", ".", "latent_vars", "=", "getattr", "(", "args", ",", "\"latent_vars\"", ",", "320", ")", "\n", "args", ".", "latent_groups", "=", "getattr", "(", "args", ",", "\"latent_groups\"", ",", "2", ")", "\n", "args", ".", "latent_dim", "=", "getattr", "(", "args", ",", "\"latent_dim\"", ",", "0", ")", "\n", "\n", "args", ".", "mask_length", "=", "getattr", "(", "args", ",", "\"mask_length\"", ",", "10", ")", "\n", "args", ".", "mask_prob", "=", "getattr", "(", "args", ",", "\"mask_prob\"", ",", "0.65", ")", "\n", "args", ".", "mask_selection", "=", "getattr", "(", "args", ",", "\"mask_selection\"", ",", "\"static\"", ")", "\n", "args", ".", "mask_other", "=", "getattr", "(", "args", ",", "\"mask_other\"", ",", "0", ")", "\n", "args", ".", "no_mask_overlap", "=", "getattr", "(", "args", ",", "\"no_mask_overlap\"", ",", "False", ")", "\n", "args", ".", "mask_min_space", "=", "getattr", "(", "args", ",", "\"mask_min_space\"", ",", "1", ")", "\n", "\n", "args", ".", "mask_channel_length", "=", "getattr", "(", "args", ",", "\"mask_channel_length\"", ",", "10", ")", "\n", "args", ".", "mask_channel_prob", "=", "getattr", "(", "args", ",", "\"mask_channel_prob\"", ",", "0", ")", "\n", "args", ".", "mask_channel_selection", "=", "getattr", "(", "args", ",", "\"mask_channel_selection\"", ",", "\"static\"", ")", "\n", "args", ".", "mask_channel_other", "=", "getattr", "(", "args", ",", "\"mask_channel_other\"", ",", "0", ")", "\n", "args", ".", "no_mask_channel_overlap", "=", "getattr", "(", "args", ",", "\"no_mask_channel_overlap\"", ",", "False", ")", "\n", "args", ".", "mask_channel_min_space", "=", "getattr", "(", "args", ",", "\"mask_channel_min_space\"", ",", "1", ")", "\n", "\n", "args", ".", "dropout_input", "=", "getattr", "(", "args", ",", "\"dropout_input\"", ",", "0", ")", "\n", "args", ".", "dropout_features", "=", "getattr", "(", "args", ",", "\"dropout_features\"", ",", "0", ")", "\n", "\n", "args", ".", "num_negatives", "=", "getattr", "(", "args", ",", "\"num_negatives\"", ",", "100", ")", "\n", "args", ".", "negatives_from_everywhere", "=", "getattr", "(", "args", ",", "\"negatives_from_everywhere\"", ",", "False", ")", "\n", "args", ".", "cross_sample_negatives", "=", "getattr", "(", "args", ",", "\"cross_sample_negatives\"", ",", "0", ")", "\n", "args", ".", "codebook_negatives", "=", "getattr", "(", "args", ",", "\"codebook_negatives\"", ",", "0", ")", "\n", "\n", "args", ".", "conv_pos", "=", "getattr", "(", "args", ",", "\"conv_pos\"", ",", "128", ")", "\n", "args", ".", "conv_pos_groups", "=", "getattr", "(", "args", ",", "\"conv_pos_groups\"", ",", "16", ")", "\n", "\n", "args", ".", "latent_temp", "=", "getattr", "(", "args", ",", "\"latent_temp\"", ",", "\"(2,0.5,0.999995)\"", ")", "\n", "\n", "args", ".", "target_glu", "=", "getattr", "(", "args", ",", "\"target_glu\"", ",", "False", ")", "\n", "\n", "args", ".", "conv_bias", "=", "getattr", "(", "args", ",", "\"conv_bias\"", ",", "False", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecModel.add_args": [[29, 207], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "parser", ".", "add_argument", "(", "\n", "\"--prediction-steps\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"number of steps ahead to predict\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--sample-distance\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"sample distance from target. does not work properly with cross-sampling\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cross-sample-negatives\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"num of cross sampled negatives\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num-negatives\"", ",", "type", "=", "int", ",", "metavar", "=", "\"N\"", ",", "help", "=", "\"number of negative examples\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--conv-feature-layers\"", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"EXPR\"", ",", "\n", "help", "=", "\"convolutional feature extraction layers [(dim, kernel_size, stride), ...]\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--conv-aggregator-layers\"", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"EXPR\"", ",", "\n", "help", "=", "\"convolutional feature extraction layers [(dim, kernel_size, stride), ...]\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout to apply within the model\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dropout-features\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout to apply to the features\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dropout-agg\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout to apply after aggregation step\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder\"", ",", "type", "=", "str", ",", "choices", "=", "[", "\"cnn\"", "]", ",", "help", "=", "\"type of encoder to use\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--aggregator\"", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "[", "\"cnn\"", ",", "\"gru\"", "]", ",", "\n", "help", "=", "\"type of aggregator to use\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gru-dim\"", ",", "type", "=", "int", ",", "metavar", "=", "\"N\"", ",", "help", "=", "\"GRU dimensionality\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no-conv-bias\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if set, does not learn bias for conv layers\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--agg-zero-pad\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if set, zero pads in aggregator instead of repl pad\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--skip-connections-feat\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if set, adds skip connections to the feature extractor\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--skip-connections-agg\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if set, adds skip connections to the aggregator\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--residual-scale\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"scales residual by sqrt(value)\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--log-compression\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if set, adds a log compression to feature extractor\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--balanced-classes\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if set, loss is scaled to balance for number of negatives\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--project-features\"", ",", "\n", "choices", "=", "[", "\"none\"", ",", "\"same\"", ",", "\"new\"", "]", ",", "\n", "help", "=", "\"if not none, features are projected using the (same or new) aggregator\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--non-affine-group-norm\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if set, group norm is not affine\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--offset\"", ",", "\n", "help", "=", "\"if set, introduces an offset from target to predictions. \"", "\n", "'if set to \"auto\", it is computed automatically from the receptive field'", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--activation\"", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "[", "\"relu\"", ",", "\"gelu\"", "]", ",", "\n", "help", "=", "\"which activation function to use\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--vq-type\"", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "[", "\"none\"", ",", "\"gumbel\"", ",", "\"kmeans\"", "]", ",", "\n", "help", "=", "\"which type of quantizer to use\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--vq-vars\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"if set, project to this many vector quantized variables per group\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--vq-groups\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"number of groups of latent variables\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--vq-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"uses this dimensionality for quantized vectors\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--vq-depth\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"number of layers for vq weight projection\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--combine-groups\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if set, variables are shared among groups\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--vq-temp\"", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"TEMP\"", ",", "\n", "help", "=", "\"temperature for latent variable sampling with gumbel softmax. should be a tuple of 3 values (start, end, decay)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--vq-gamma\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"gamma parameter for kmeans style vector quantization\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecModel.build_model": [[209, 219], ["wav2vec.base_wav2vec_architecture", "wav2vec.Wav2VecModel", "logger.info"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.base_wav2vec_architecture"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "\n", "# make sure all arguments are present in older models", "\n", "base_wav2vec_architecture", "(", "args", ")", "\n", "\n", "model", "=", "Wav2VecModel", "(", "args", ")", "\n", "logger", ".", "info", "(", "model", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecModel.__init__": [[220, 349], ["fairseq.models.BaseFairseqModel.__init__", "int", "wav2vec.Wav2VecModel.__init__.make_aggregator"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "prediction_steps", "=", "args", ".", "prediction_steps", "\n", "offset", "=", "args", ".", "offset", "\n", "\n", "if", "args", ".", "activation", "==", "\"relu\"", ":", "\n", "            ", "activation", "=", "nn", ".", "ReLU", "(", ")", "\n", "", "elif", "args", ".", "activation", "==", "\"gelu\"", ":", "\n", "            ", "activation", "=", "nn", ".", "GELU", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"unknown activation \"", "+", "args", ".", "activation", ")", "\n", "\n", "", "if", "args", ".", "encoder", "==", "\"cnn\"", ":", "\n", "            ", "feature_enc_layers", "=", "eval", "(", "args", ".", "conv_feature_layers", ")", "\n", "self", ".", "feature_extractor", "=", "ConvFeatureExtractionModel", "(", "\n", "conv_layers", "=", "feature_enc_layers", ",", "\n", "dropout", "=", "0.0", ",", "\n", "log_compression", "=", "args", ".", "log_compression", ",", "\n", "skip_connections", "=", "args", ".", "skip_connections_feat", ",", "\n", "residual_scale", "=", "args", ".", "residual_scale", ",", "\n", "non_affine_group_norm", "=", "args", ".", "non_affine_group_norm", ",", "\n", "activation", "=", "activation", ",", "\n", ")", "\n", "embed", "=", "feature_enc_layers", "[", "-", "1", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"unknown encoder type \"", "+", "args", ".", "encoder", ")", "\n", "\n", "", "self", ".", "vector_quantizer", "=", "None", "\n", "if", "args", ".", "vq_type", "==", "\"gumbel\"", ":", "\n", "            ", "self", ".", "vector_quantizer", "=", "GumbelVectorQuantizer", "(", "\n", "dim", "=", "embed", ",", "\n", "num_vars", "=", "args", ".", "vq_vars", ",", "\n", "temp", "=", "eval", "(", "args", ".", "vq_temp", ")", ",", "\n", "groups", "=", "args", ".", "vq_groups", ",", "\n", "combine_groups", "=", "args", ".", "combine_groups", ",", "\n", "vq_dim", "=", "args", ".", "vq_dim", "if", "args", ".", "vq_dim", ">", "0", "else", "embed", ",", "\n", "time_first", "=", "False", ",", "\n", "activation", "=", "activation", ",", "\n", "weight_proj_depth", "=", "args", ".", "vq_depth", ",", "\n", "weight_proj_factor", "=", "2", ",", "\n", ")", "\n", "", "elif", "args", ".", "vq_type", "==", "\"kmeans\"", ":", "\n", "            ", "self", ".", "vector_quantizer", "=", "KmeansVectorQuantizer", "(", "\n", "dim", "=", "embed", ",", "\n", "num_vars", "=", "args", ".", "vq_vars", ",", "\n", "groups", "=", "args", ".", "vq_groups", ",", "\n", "combine_groups", "=", "args", ".", "combine_groups", ",", "\n", "vq_dim", "=", "args", ".", "vq_dim", "if", "args", ".", "vq_dim", ">", "0", "else", "embed", ",", "\n", "time_first", "=", "False", ",", "\n", "gamma", "=", "args", ".", "vq_gamma", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "assert", "(", "\n", "args", ".", "vq_type", "==", "\"none\"", "or", "args", ".", "vq_type", "is", "None", "\n", ")", ",", "\"Unknown quantizer type\"", "\n", "\n", "", "if", "args", ".", "offset", "==", "\"auto\"", ":", "\n", "            ", "assert", "args", ".", "encoder", "==", "\"cnn\"", "\n", "jin", "=", "0", "\n", "rin", "=", "0", "\n", "for", "_", ",", "k", ",", "stride", "in", "feature_enc_layers", ":", "\n", "                ", "if", "rin", "==", "0", ":", "\n", "                    ", "rin", "=", "k", "\n", "", "rin", "=", "rin", "+", "(", "k", "-", "1", ")", "*", "jin", "\n", "if", "jin", "==", "0", ":", "\n", "                    ", "jin", "=", "stride", "\n", "", "else", ":", "\n", "                    ", "jin", "*=", "stride", "\n", "", "", "offset", "=", "math", ".", "ceil", "(", "rin", "/", "jin", ")", "\n", "\n", "", "offset", "=", "int", "(", "offset", ")", "\n", "\n", "def", "make_aggregator", "(", ")", ":", "\n", "            ", "if", "args", ".", "aggregator", "==", "\"cnn\"", ":", "\n", "                ", "agg_layers", "=", "eval", "(", "args", ".", "conv_aggregator_layers", ")", "\n", "agg_dim", "=", "agg_layers", "[", "-", "1", "]", "[", "0", "]", "\n", "feature_aggregator", "=", "ConvAggegator", "(", "\n", "conv_layers", "=", "agg_layers", ",", "\n", "embed", "=", "embed", ",", "\n", "dropout", "=", "args", ".", "dropout", ",", "\n", "skip_connections", "=", "args", ".", "skip_connections_agg", ",", "\n", "residual_scale", "=", "args", ".", "residual_scale", ",", "\n", "non_affine_group_norm", "=", "args", ".", "non_affine_group_norm", ",", "\n", "conv_bias", "=", "not", "args", ".", "no_conv_bias", ",", "\n", "zero_pad", "=", "args", ".", "agg_zero_pad", ",", "\n", "activation", "=", "activation", ",", "\n", ")", "\n", "", "elif", "args", ".", "aggregator", "==", "\"gru\"", ":", "\n", "                ", "agg_dim", "=", "args", ".", "gru_dim", "\n", "feature_aggregator", "=", "nn", ".", "Sequential", "(", "\n", "TransposeLast", "(", ")", ",", "\n", "nn", ".", "GRU", "(", "\n", "input_size", "=", "embed", ",", "\n", "hidden_size", "=", "agg_dim", ",", "\n", "num_layers", "=", "1", ",", "\n", "dropout", "=", "args", ".", "dropout", ",", "\n", ")", ",", "\n", "TransposeLast", "(", "deconstruct_idx", "=", "0", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"unknown aggregator type \"", "+", "args", ".", "aggregator", ")", "\n", "\n", "", "return", "feature_aggregator", ",", "agg_dim", "\n", "\n", "", "self", ".", "feature_aggregator", ",", "agg_dim", "=", "make_aggregator", "(", ")", "\n", "\n", "self", ".", "wav2vec_predictions", "=", "Wav2VecPredictionsModel", "(", "\n", "in_dim", "=", "agg_dim", ",", "\n", "out_dim", "=", "embed", ",", "\n", "prediction_steps", "=", "args", ".", "prediction_steps", ",", "\n", "n_negatives", "=", "args", ".", "num_negatives", ",", "\n", "cross_sample_negatives", "=", "args", ".", "cross_sample_negatives", ",", "\n", "sample_distance", "=", "args", ".", "sample_distance", ",", "\n", "dropout", "=", "args", ".", "dropout", ",", "\n", "offset", "=", "offset", ",", "\n", "balanced_classes", "=", "args", ".", "balanced_classes", ",", "\n", "infonce", "=", "args", ".", "infonce", ",", "\n", ")", "\n", "\n", "self", ".", "dropout_feats", "=", "nn", ".", "Dropout", "(", "p", "=", "args", ".", "dropout_features", ")", "\n", "self", ".", "dropout_agg", "=", "nn", ".", "Dropout", "(", "p", "=", "args", ".", "dropout_agg", ")", "\n", "\n", "if", "args", ".", "project_features", "==", "\"none\"", ":", "\n", "            ", "self", ".", "project_features", "=", "None", "\n", "", "elif", "args", ".", "project_features", "==", "\"same\"", ":", "\n", "            ", "self", ".", "project_features", "=", "self", ".", "feature_aggregator", "\n", "", "elif", "args", ".", "project_features", "==", "\"new\"", ":", "\n", "            ", "self", ".", "project_features", ",", "_", "=", "make_aggregator", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecModel.forward": [[350, 372], ["wav2vec.Wav2VecModel.feature_extractor", "wav2vec.Wav2VecModel.dropout_feats", "wav2vec.Wav2VecModel.feature_aggregator", "wav2vec.Wav2VecModel.dropout_agg", "wav2vec.Wav2VecModel.wav2vec_predictions", "wav2vec.Wav2VecModel.vector_quantizer", "wav2vec.Wav2VecModel.keys", "wav2vec.Wav2VecModel.project_features"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "source", ")", ":", "\n", "        ", "result", "=", "{", "}", "\n", "\n", "features", "=", "self", ".", "feature_extractor", "(", "source", ")", "\n", "if", "self", ".", "vector_quantizer", ":", "\n", "            ", "q_res", "=", "self", ".", "vector_quantizer", "(", "features", ")", "\n", "features", "=", "q_res", "[", "\"x\"", "]", "\n", "for", "k", "in", "q_res", ".", "keys", "(", ")", ":", "\n", "                ", "if", "k", "!=", "\"x\"", ":", "\n", "                    ", "result", "[", "k", "]", "=", "q_res", "[", "k", "]", "\n", "\n", "", "", "", "x", "=", "self", ".", "dropout_feats", "(", "features", ")", "\n", "x", "=", "self", ".", "feature_aggregator", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout_agg", "(", "x", ")", "\n", "\n", "if", "self", ".", "project_features", "is", "not", "None", ":", "\n", "            ", "features", "=", "self", ".", "project_features", "(", "features", ")", "\n", "", "x", ",", "targets", "=", "self", ".", "wav2vec_predictions", "(", "x", ",", "features", ")", "\n", "result", "[", "\"cpc_logits\"", "]", "=", "x", "\n", "result", "[", "\"cpc_targets\"", "]", "=", "targets", "\n", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecModel.upgrade_state_dict_named": [[373, 375], ["super().upgrade_state_dict_named"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.upgrade_state_dict_named"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "super", "(", ")", ".", "upgrade_state_dict_named", "(", "state_dict", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecModel.max_positions": [[376, 379], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum length supported by the model.\"\"\"", "\n", "return", "sys", ".", "maxsize", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecModel.get_logits": [[380, 383], ["None"], "methods", ["None"], ["", "def", "get_logits", "(", "self", ",", "net_output", ")", ":", "\n", "        ", "logits", "=", "net_output", "[", "\"cpc_logits\"", "]", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecModel.get_targets": [[384, 389], ["isinstance", "t.contiguous"], "methods", ["None"], ["", "def", "get_targets", "(", "self", ",", "sample", ",", "net_output", ")", ":", "\n", "        ", "t", "=", "net_output", "[", "\"cpc_targets\"", "]", "\n", "if", "isinstance", "(", "t", ",", "tuple", ")", ":", "\n", "            ", "t", "=", "t", "[", "0", "]", "\n", "", "return", "t", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecModel.get_target_weights": [[390, 395], ["isinstance"], "methods", ["None"], ["", "def", "get_target_weights", "(", "self", ",", "targets", ",", "net_output", ")", ":", "\n", "        ", "targets", "=", "net_output", "[", "\"cpc_targets\"", "]", "\n", "if", "isinstance", "(", "targets", ",", "tuple", ")", "and", "targets", "[", "-", "1", "]", "is", "not", "None", ":", "\n", "            ", "return", "targets", "[", "-", "1", "]", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecModel.get_extra_losses": [[396, 404], ["None"], "methods", ["None"], ["", "def", "get_extra_losses", "(", "self", ",", "net_output", ")", ":", "\n", "        ", "loss", "=", "None", "\n", "if", "\"prob_perplexity\"", "in", "net_output", ":", "\n", "            ", "loss", "=", "net_output", "[", "\"num_vars\"", "]", "-", "net_output", "[", "\"prob_perplexity\"", "]", "\n", "", "elif", "\"kmeans_loss\"", "in", "net_output", ":", "\n", "            ", "loss", "=", "net_output", "[", "\"kmeans_loss\"", "]", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.ConvFeatureExtractionModel.__init__": [[420, 451], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "math.sqrt", "torch.Sequential", "torch.Sequential", "torch.Sequential", "wav2vec.ConvFeatureExtractionModel.conv_layers.append", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Dropout", "torch.Dropout", "torch.Dropout", "wav2vec.norm_block", "wav2vec.ConvFeatureExtractionModel.__init__.block"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.norm_block"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "conv_layers", ",", "\n", "dropout", ",", "\n", "log_compression", ",", "\n", "skip_connections", ",", "\n", "residual_scale", ",", "\n", "non_affine_group_norm", ",", "\n", "activation", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "def", "block", "(", "n_in", ",", "n_out", ",", "k", ",", "stride", ")", ":", "\n", "            ", "return", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "n_in", ",", "n_out", ",", "k", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ",", "\n", "norm_block", "(", "\n", "is_layer_norm", "=", "False", ",", "dim", "=", "n_out", ",", "affine", "=", "not", "non_affine_group_norm", "\n", ")", ",", "\n", "activation", ",", "\n", ")", "\n", "\n", "", "in_d", "=", "1", "\n", "self", ".", "conv_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "dim", ",", "k", ",", "stride", "in", "conv_layers", ":", "\n", "            ", "self", ".", "conv_layers", ".", "append", "(", "block", "(", "in_d", ",", "dim", ",", "k", ",", "stride", ")", ")", "\n", "in_d", "=", "dim", "\n", "\n", "", "self", ".", "log_compression", "=", "log_compression", "\n", "self", ".", "skip_connections", "=", "skip_connections", "\n", "self", ".", "residual_scale", "=", "math", ".", "sqrt", "(", "residual_scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.ConvFeatureExtractionModel.forward": [[452, 471], ["x.log.log.unsqueeze", "conv", "x.log.log.abs", "x.log.log.log", "x.log.log.size", "residual.size", "x.log.log.size", "residual.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# BxT -> BxCxT", "\n", "        ", "x", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "for", "conv", "in", "self", ".", "conv_layers", ":", "\n", "            ", "residual", "=", "x", "\n", "x", "=", "conv", "(", "x", ")", "\n", "if", "self", ".", "skip_connections", "and", "x", ".", "size", "(", "1", ")", "==", "residual", ".", "size", "(", "1", ")", ":", "\n", "                ", "tsz", "=", "x", ".", "size", "(", "2", ")", "\n", "r_tsz", "=", "residual", ".", "size", "(", "2", ")", "\n", "residual", "=", "residual", "[", "...", ",", ":", ":", "r_tsz", "//", "tsz", "]", "[", "...", ",", ":", "tsz", "]", "\n", "x", "=", "(", "x", "+", "residual", ")", "*", "self", ".", "residual_scale", "\n", "\n", "", "", "if", "self", ".", "log_compression", ":", "\n", "            ", "x", "=", "x", ".", "abs", "(", ")", "\n", "x", "=", "x", "+", "1", "\n", "x", "=", "x", ".", "log", "(", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.ZeroPad1d.__init__": [[474, 478], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "pad_left", ",", "pad_right", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pad_left", "=", "pad_left", "\n", "self", ".", "pad_right", "=", "pad_right", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.ZeroPad1d.forward": [[479, 481], ["torch.pad", "torch.pad", "torch.pad"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "F", ".", "pad", "(", "x", ",", "(", "self", ".", "pad_left", ",", "self", ".", "pad_right", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.ConvAggegator.__init__": [[484, 529], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Sequential", "torch.Sequential", "torch.Sequential", "math.sqrt", "torch.Sequential", "torch.Sequential", "torch.Sequential", "wav2vec.ConvAggegator.conv_layers.append", "wav2vec.ZeroPad1d", "torch.ReplicationPad1d", "torch.ReplicationPad1d", "torch.ReplicationPad1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Dropout", "torch.Dropout", "torch.Dropout", "wav2vec.norm_block", "wav2vec.ConvAggegator.residual_proj.append", "wav2vec.ConvAggegator.residual_proj.append", "wav2vec.ConvAggegator.__init__.block"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.norm_block"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "conv_layers", ",", "\n", "embed", ",", "\n", "dropout", ",", "\n", "skip_connections", ",", "\n", "residual_scale", ",", "\n", "non_affine_group_norm", ",", "\n", "conv_bias", ",", "\n", "zero_pad", ",", "\n", "activation", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "def", "block", "(", "n_in", ",", "n_out", ",", "k", ",", "stride", ")", ":", "\n", "# padding dims only really make sense for stride = 1", "\n", "            ", "ka", "=", "k", "//", "2", "\n", "kb", "=", "ka", "-", "1", "if", "k", "%", "2", "==", "0", "else", "ka", "\n", "\n", "pad", "=", "(", "\n", "ZeroPad1d", "(", "ka", "+", "kb", ",", "0", ")", "if", "zero_pad", "else", "nn", ".", "ReplicationPad1d", "(", "(", "ka", "+", "kb", ",", "0", ")", ")", "\n", ")", "\n", "\n", "return", "nn", ".", "Sequential", "(", "\n", "pad", ",", "\n", "nn", ".", "Conv1d", "(", "n_in", ",", "n_out", ",", "k", ",", "stride", "=", "stride", ",", "bias", "=", "conv_bias", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ",", "\n", "norm_block", "(", "False", ",", "n_out", ",", "affine", "=", "not", "non_affine_group_norm", ")", ",", "\n", "activation", ",", "\n", ")", "\n", "\n", "", "in_d", "=", "embed", "\n", "self", ".", "conv_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "residual_proj", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "dim", ",", "k", ",", "stride", "in", "conv_layers", ":", "\n", "            ", "if", "in_d", "!=", "dim", "and", "skip_connections", ":", "\n", "                ", "self", ".", "residual_proj", ".", "append", "(", "nn", ".", "Conv1d", "(", "in_d", ",", "dim", ",", "1", ",", "bias", "=", "False", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "residual_proj", ".", "append", "(", "None", ")", "\n", "\n", "", "self", ".", "conv_layers", ".", "append", "(", "block", "(", "in_d", ",", "dim", ",", "k", ",", "stride", ")", ")", "\n", "in_d", "=", "dim", "\n", "", "self", ".", "conv_layers", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "conv_layers", ")", "\n", "self", ".", "skip_connections", "=", "skip_connections", "\n", "self", ".", "residual_scale", "=", "math", ".", "sqrt", "(", "residual_scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.ConvAggegator.forward": [[530, 539], ["zip", "conv", "rproj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "rproj", ",", "conv", "in", "zip", "(", "self", ".", "residual_proj", ",", "self", ".", "conv_layers", ")", ":", "\n", "            ", "residual", "=", "x", "\n", "x", "=", "conv", "(", "x", ")", "\n", "if", "self", ".", "skip_connections", ":", "\n", "                ", "if", "rproj", "is", "not", "None", ":", "\n", "                    ", "residual", "=", "rproj", "(", "residual", ")", "\n", "", "x", "=", "(", "x", "+", "residual", ")", "*", "self", ".", "residual_scale", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecPredictionsModel.__init__": [[542, 567], ["torch.Module.__init__", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_dim", ",", "\n", "out_dim", ",", "\n", "prediction_steps", ",", "\n", "n_negatives", ",", "\n", "cross_sample_negatives", ",", "\n", "sample_distance", ",", "\n", "dropout", ",", "\n", "offset", ",", "\n", "balanced_classes", ",", "\n", "infonce", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_negatives", "=", "n_negatives", "\n", "self", ".", "cross_sample_negatives", "=", "cross_sample_negatives", "\n", "self", ".", "sample_distance", "=", "sample_distance", "\n", "self", ".", "project_to_steps", "=", "nn", ".", "ConvTranspose2d", "(", "\n", "in_dim", ",", "out_dim", ",", "(", "1", ",", "prediction_steps", ")", "\n", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "offset", "=", "offset", "\n", "self", ".", "balanced_classes", "=", "balanced_classes", "\n", "self", ".", "infonce", "=", "infonce", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecPredictionsModel.sample_negatives": [[568, 626], ["y.contiguous().view.contiguous().view.transpose", "y.contiguous().view.contiguous().view.contiguous().view", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "negs.view().permute.view().permute.view().permute", "min", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "y.contiguous().view.contiguous().view.contiguous", "fairseq.utils.buffered_arange().unsqueeze().expand().flatten", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "fairseq.utils.buffered_arange().unsqueeze().expand().flatten", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "negs.view().permute.view().permute.view", "torch.randint.view", "torch.randint.view", "torch.randint.view", "fairseq.utils.buffered_arange().unsqueeze().expand", "fairseq.utils.buffered_arange().unsqueeze().expand", "fairseq.utils.buffered_arange().unsqueeze", "fairseq.utils.buffered_arange().unsqueeze", "fairseq.utils.buffered_arange", "fairseq.utils.buffered_arange"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.buffered_arange", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.buffered_arange"], ["", "def", "sample_negatives", "(", "self", ",", "y", ")", ":", "\n", "        ", "bsz", ",", "fsz", ",", "tsz", "=", "y", ".", "shape", "\n", "\n", "y", "=", "y", ".", "transpose", "(", "0", ",", "1", ")", "# BCT -> CBT", "\n", "y", "=", "y", ".", "contiguous", "(", ")", ".", "view", "(", "fsz", ",", "-", "1", ")", "# CBT => C(BxT)", "\n", "\n", "cross_high", "=", "tsz", "*", "bsz", "\n", "high", "=", "tsz", "if", "self", ".", "sample_distance", "is", "None", "else", "min", "(", "tsz", ",", "self", ".", "sample_distance", ")", "\n", "assert", "high", ">", "1", "\n", "\n", "neg_idxs", "=", "torch", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "high", ",", "size", "=", "(", "bsz", ",", "self", ".", "n_negatives", "*", "tsz", ")", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "self", ".", "n_negatives", ">", "0", ":", "\n", "                ", "tszs", "=", "(", "\n", "buffered_arange", "(", "tsz", ")", "\n", ".", "unsqueeze", "(", "-", "1", ")", "\n", ".", "expand", "(", "-", "1", ",", "self", ".", "n_negatives", ")", "\n", ".", "flatten", "(", ")", "\n", ")", "\n", "\n", "neg_idxs", "=", "torch", ".", "randint", "(", "\n", "low", "=", "0", ",", "high", "=", "high", "-", "1", ",", "size", "=", "(", "bsz", ",", "self", ".", "n_negatives", "*", "tsz", ")", "\n", ")", "\n", "neg_idxs", "[", "neg_idxs", ">=", "tszs", "]", "+=", "1", "\n", "\n", "", "if", "self", ".", "cross_sample_negatives", ">", "0", ":", "\n", "                ", "tszs", "=", "(", "\n", "buffered_arange", "(", "tsz", ")", "\n", ".", "unsqueeze", "(", "-", "1", ")", "\n", ".", "expand", "(", "-", "1", ",", "self", ".", "cross_sample_negatives", ")", "\n", ".", "flatten", "(", ")", "\n", ")", "\n", "\n", "cross_neg_idxs", "=", "torch", ".", "randint", "(", "\n", "low", "=", "0", ",", "\n", "high", "=", "cross_high", "-", "1", ",", "\n", "size", "=", "(", "bsz", ",", "self", ".", "cross_sample_negatives", "*", "tsz", ")", ",", "\n", ")", "\n", "cross_neg_idxs", "[", "cross_neg_idxs", ">=", "tszs", "]", "+=", "1", "\n", "\n", "", "", "if", "self", ".", "n_negatives", ">", "0", ":", "\n", "            ", "for", "i", "in", "range", "(", "1", ",", "bsz", ")", ":", "\n", "                ", "neg_idxs", "[", "i", "]", "+=", "i", "*", "high", "\n", "", "", "else", ":", "\n", "            ", "neg_idxs", "=", "cross_neg_idxs", "\n", "\n", "", "if", "self", ".", "cross_sample_negatives", ">", "0", "and", "self", ".", "n_negatives", ">", "0", ":", "\n", "            ", "neg_idxs", "=", "torch", ".", "cat", "(", "[", "neg_idxs", ",", "cross_neg_idxs", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "negs", "=", "y", "[", "...", ",", "neg_idxs", ".", "view", "(", "-", "1", ")", "]", "\n", "negs", "=", "negs", ".", "view", "(", "\n", "fsz", ",", "bsz", ",", "self", ".", "n_negatives", "+", "self", ".", "cross_sample_negatives", ",", "tsz", "\n", ")", ".", "permute", "(", "\n", "2", ",", "1", ",", "0", ",", "3", "\n", ")", "# to NxBxCxT", "\n", "\n", "return", "negs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecPredictionsModel.forward": [[627, 683], ["wav2vec.Wav2VecPredictionsModel.unsqueeze", "wav2vec.Wav2VecPredictionsModel.project_to_steps", "wav2vec.Wav2VecPredictionsModel.dropout", "wav2vec.Wav2VecPredictionsModel.sample_negatives", "y.unsqueeze.unsqueeze.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "torch.cat.size", "torch.cat.size", "min", "wav2vec.Wav2VecPredictionsModel.new", "range", "predictions.view.view.new_full", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "predictions.view.view.numel", "predictions.view.view.numel", "predictions.view.view.view", "torch.einsum().flatten", "torch.einsum().flatten", "torch.einsum().flatten", "torch.einsum().flatten", "torch.einsum().flatten", "torch.einsum().flatten", "torch.einsum().flatten", "torch.einsum().flatten", "torch.einsum().flatten", "torch.einsum().flatten", "torch.einsum().flatten", "torch.einsum().flatten", "torch.einsum().flatten", "torch.einsum().flatten", "torch.einsum().flatten", "torch.einsum().flatten", "torch.einsum().flatten", "torch.einsum().flatten", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecPredictionsModel.sample_negatives", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "\n", "        ", "x", "=", "x", ".", "unsqueeze", "(", "-", "1", ")", "\n", "x", "=", "self", ".", "project_to_steps", "(", "x", ")", "# BxCxTxS", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "\n", "negatives", "=", "self", ".", "sample_negatives", "(", "y", ")", "\n", "y", "=", "y", ".", "unsqueeze", "(", "0", ")", "\n", "targets", "=", "torch", ".", "cat", "(", "[", "y", ",", "negatives", "]", ",", "dim", "=", "0", ")", "# Copies x B x C x T", "\n", "\n", "copies", "=", "targets", ".", "size", "(", "0", ")", "\n", "bsz", ",", "dim", ",", "tsz", ",", "steps", "=", "x", ".", "shape", "\n", "steps", "=", "min", "(", "steps", ",", "tsz", "-", "self", ".", "offset", ")", "\n", "\n", "predictions", "=", "x", ".", "new", "(", "\n", "bsz", "*", "copies", "*", "(", "tsz", "-", "self", ".", "offset", "+", "1", ")", "*", "steps", "\n", "-", "(", "(", "steps", "+", "1", ")", "*", "steps", "//", "2", ")", "*", "copies", "*", "bsz", "\n", ")", "\n", "if", "self", ".", "infonce", ":", "\n", "            ", "labels", "=", "predictions", ".", "new_full", "(", "\n", "(", "predictions", ".", "shape", "[", "0", "]", "//", "copies", ",", ")", ",", "0", ",", "dtype", "=", "torch", ".", "long", "\n", ")", "\n", "", "else", ":", "\n", "            ", "labels", "=", "torch", ".", "zeros_like", "(", "predictions", ")", "\n", "", "weights", "=", "(", "\n", "torch", ".", "full_like", "(", "labels", ",", "1", "/", "self", ".", "n_negatives", ")", "\n", "if", "self", ".", "balanced_classes", "and", "not", "self", ".", "infonce", "\n", "else", "None", "\n", ")", "\n", "\n", "start", "=", "end", "=", "0", "\n", "for", "i", "in", "range", "(", "steps", ")", ":", "\n", "            ", "offset", "=", "i", "+", "self", ".", "offset", "\n", "end", "=", "start", "+", "(", "tsz", "-", "offset", ")", "*", "bsz", "*", "copies", "\n", "if", "self", ".", "infonce", ":", "\n", "                ", "predictions", "[", "start", ":", "end", "]", "=", "torch", ".", "einsum", "(", "\n", "\"bct,nbct->tbn\"", ",", "x", "[", "...", ",", ":", "-", "offset", ",", "i", "]", ",", "targets", "[", "...", ",", "offset", ":", "]", "\n", ")", ".", "flatten", "(", ")", "\n", "", "else", ":", "\n", "                ", "pos_num", "=", "(", "end", "-", "start", ")", "//", "copies", "\n", "predictions", "[", "start", ":", "end", "]", "=", "torch", ".", "einsum", "(", "\n", "\"bct,nbct->nbt\"", ",", "x", "[", "...", ",", ":", "-", "offset", ",", "i", "]", ",", "targets", "[", "...", ",", "offset", ":", "]", "\n", ")", ".", "flatten", "(", ")", "\n", "labels", "[", "start", ":", "start", "+", "pos_num", "]", "=", "1.0", "\n", "if", "weights", "is", "not", "None", ":", "\n", "                    ", "weights", "[", "start", ":", "start", "+", "pos_num", "]", "=", "1.0", "\n", "", "", "start", "=", "end", "\n", "", "assert", "end", "==", "predictions", ".", "numel", "(", ")", ",", "\"{} != {}\"", ".", "format", "(", "end", ",", "predictions", ".", "numel", "(", ")", ")", "\n", "\n", "if", "self", ".", "infonce", ":", "\n", "            ", "predictions", "=", "predictions", ".", "view", "(", "-", "1", ",", "copies", ")", "\n", "", "else", ":", "\n", "            ", "if", "weights", "is", "not", "None", ":", "\n", "                ", "labels", "=", "(", "labels", ",", "weights", ")", "\n", "\n", "", "", "return", "predictions", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.norm_block": [[406, 417], ["torch.Sequential", "fairseq.modules.Fp32GroupNorm", "fairseq.modules.TransposeLast", "fairseq.modules.Fp32LayerNorm", "fairseq.modules.TransposeLast"], "function", ["None"], ["", "", "def", "norm_block", "(", "is_layer_norm", ",", "dim", ",", "affine", "=", "True", ")", ":", "\n", "    ", "if", "is_layer_norm", ":", "\n", "        ", "mod", "=", "nn", ".", "Sequential", "(", "\n", "TransposeLast", "(", ")", ",", "\n", "Fp32LayerNorm", "(", "dim", ",", "elementwise_affine", "=", "affine", ")", ",", "\n", "TransposeLast", "(", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "mod", "=", "Fp32GroupNorm", "(", "1", ",", "dim", ",", "affine", "=", "affine", ")", "\n", "\n", "", "return", "mod", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.base_wav2vec_architecture": [[685, 736], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "", "@", "register_model_architecture", "(", "\"wav2vec\"", ",", "\"wav2vec\"", ")", "\n", "def", "base_wav2vec_architecture", "(", "args", ")", ":", "\n", "    ", "conv_feature_layers", "=", "\"[(512, 10, 5)]\"", "\n", "conv_feature_layers", "+=", "\" + [(512, 8, 4)]\"", "\n", "conv_feature_layers", "+=", "\" + [(512, 4, 2)] * 3\"", "\n", "args", ".", "conv_feature_layers", "=", "getattr", "(", "args", ",", "\"conv_feature_layers\"", ",", "conv_feature_layers", ")", "\n", "\n", "args", ".", "conv_aggregator_layers", "=", "getattr", "(", "\n", "args", ",", "\"conv_aggregator_layers\"", ",", "\"[(512, 3, 1)] * 9\"", "\n", ")", "\n", "\n", "args", ".", "prediction_steps", "=", "getattr", "(", "args", ",", "\"prediction_steps\"", ",", "12", ")", "\n", "args", ".", "num_negatives", "=", "getattr", "(", "args", ",", "\"num_negatives\"", ",", "1", ")", "\n", "args", ".", "sample_distance", "=", "getattr", "(", "args", ",", "\"sample_distance\"", ",", "None", ")", "\n", "args", ".", "cross_sample_negatives", "=", "getattr", "(", "args", ",", "\"cross_sample_negatives\"", ",", "0", ")", "\n", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.0", ")", "\n", "args", ".", "dropout_features", "=", "getattr", "(", "args", ",", "\"dropout_features\"", ",", "0.0", ")", "\n", "args", ".", "dropout_agg", "=", "getattr", "(", "args", ",", "\"dropout_agg\"", ",", "0.0", ")", "\n", "args", ".", "encoder", "=", "getattr", "(", "args", ",", "\"encoder\"", ",", "\"cnn\"", ")", "\n", "args", ".", "aggregator", "=", "getattr", "(", "args", ",", "\"aggregator\"", ",", "\"cnn\"", ")", "\n", "\n", "args", ".", "skip_connections_feat", "=", "getattr", "(", "args", ",", "\"skip_connections_feat\"", ",", "False", ")", "\n", "args", ".", "skip_connections_agg", "=", "getattr", "(", "args", ",", "\"skip_connections_agg\"", ",", "False", ")", "\n", "args", ".", "residual_scale", "=", "getattr", "(", "args", ",", "\"residual_scale\"", ",", "0.5", ")", "\n", "\n", "args", ".", "gru_dim", "=", "getattr", "(", "args", ",", "\"gru_dim\"", ",", "512", ")", "\n", "\n", "args", ".", "no_conv_bias", "=", "getattr", "(", "args", ",", "\"no_conv_bias\"", ",", "False", ")", "\n", "args", ".", "agg_zero_pad", "=", "getattr", "(", "args", ",", "\"agg_zero_pad\"", ",", "False", ")", "\n", "\n", "args", ".", "log_compression", "=", "getattr", "(", "args", ",", "\"log_compression\"", ",", "False", ")", "\n", "\n", "args", ".", "balanced_classes", "=", "getattr", "(", "args", ",", "\"balanced_classes\"", ",", "False", ")", "\n", "args", ".", "infonce", "=", "getattr", "(", "args", ",", "\"infonce\"", ",", "False", ")", "\n", "args", ".", "project_features", "=", "getattr", "(", "args", ",", "\"project_features\"", ",", "\"none\"", ")", "\n", "\n", "args", ".", "non_affine_group_norm", "=", "getattr", "(", "args", ",", "\"non_affine_group_norm\"", ",", "False", ")", "\n", "\n", "args", ".", "offset", "=", "getattr", "(", "args", ",", "\"offset\"", ",", "\"auto\"", ")", "\n", "\n", "args", ".", "activation", "=", "getattr", "(", "args", ",", "\"activation\"", ",", "\"relu\"", ")", "\n", "\n", "args", ".", "vq_type", "=", "getattr", "(", "args", ",", "\"vq_type\"", ",", "\"none\"", ")", "\n", "args", ".", "vq_vars", "=", "getattr", "(", "args", ",", "\"vq_vars\"", ",", "320", ")", "\n", "args", ".", "vq_groups", "=", "getattr", "(", "args", ",", "\"vq_groups\"", ",", "2", ")", "\n", "args", ".", "vq_dim", "=", "getattr", "(", "args", ",", "\"vq_dim\"", ",", "0", ")", "\n", "args", ".", "vq_depth", "=", "getattr", "(", "args", ",", "\"vq_depth\"", ",", "1", ")", "\n", "args", ".", "combine_groups", "=", "getattr", "(", "args", ",", "\"combine_groups\"", ",", "False", ")", "\n", "args", ".", "vq_temp", "=", "getattr", "(", "args", ",", "\"vq_temp\"", ",", "\"(2.0, 0.5, 0.999995)\"", ")", "\n", "args", ".", "vq_gamma", "=", "getattr", "(", "args", ",", "\"vq_gamma\"", ",", "0.25", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.Wav2VecCtc.add_args": [[150, 154], ["wav2vec2_asr.add_common_args"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.add_common_args"], ["    ", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "add_common_args", "(", "parser", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.Wav2VecCtc.__init__": [[155, 159], ["fairseq.models.BaseFairseqModel.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["", "def", "__init__", "(", "self", ",", "w2v_encoder", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w2v_encoder", "=", "w2v_encoder", "\n", "self", ".", "args", "=", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.Wav2VecCtc.upgrade_state_dict_named": [[160, 163], ["super().upgrade_state_dict_named"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.upgrade_state_dict_named"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "super", "(", ")", ".", "upgrade_state_dict_named", "(", "state_dict", ",", "name", ")", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.Wav2VecCtc.build_model": [[164, 170], ["wav2vec2_asr.base_architecture", "wav2vec2_asr.Wav2VecEncoder", "cls"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "base_architecture", "(", "args", ")", "\n", "w2v_encoder", "=", "Wav2VecEncoder", "(", "args", ",", "task", ".", "target_dictionary", ")", "\n", "return", "cls", "(", "w2v_encoder", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.Wav2VecCtc.get_normalized_probs": [[171, 179], ["fairseq.utils.log_softmax", "fairseq.utils.softmax", "logits.float", "logits.float"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax"], ["", "def", "get_normalized_probs", "(", "self", ",", "net_output", ",", "log_probs", ")", ":", "\n", "        ", "\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"", "\n", "\n", "logits", "=", "net_output", "[", "\"encoder_out\"", "]", "\n", "if", "log_probs", ":", "\n", "            ", "return", "utils", ".", "log_softmax", "(", "logits", ".", "float", "(", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "utils", ".", "softmax", "(", "logits", ".", "float", "(", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.Wav2VecCtc.forward": [[180, 183], ["wav2vec2_asr.Wav2VecCtc.w2v_encoder"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "self", ".", "w2v_encoder", "(", "**", "kwargs", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.TransformerModel.__init__": [[190, 192], ["fairseq.models.FairseqEncoderDecoderModel.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "encoder", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.TransformerModel.add_args": [[193, 258], ["wav2vec2_asr.add_common_args", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.add_common_args"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "add_common_args", "(", "parser", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-embed-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"decoder embedding dimension\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-ffn-embed-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"decoder embedding dimension for FFN\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-layers\"", ",", "type", "=", "int", ",", "metavar", "=", "\"N\"", ",", "help", "=", "\"num decoder layers\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-layerdrop\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"decoder layerdrop chance\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-attention-heads\"", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"num decoder attention heads\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-learned-pos\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"use learned positional embeddings in the decoder\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-normalize-before\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"apply layernorm before each decoder block\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no-token-positional-embeddings\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if set, disables positional embeddings (outside self attention)\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability in the decoder\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-attention-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability for attention weights inside the decoder\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-activation-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability after activation in FFN inside the decoder\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.TransformerModel.build_model": [[262, 287], ["wav2vec2_asr.base_architecture", "wav2vec2_asr.TransformerModel.build_model.build_embedding"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.build_embedding"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "\n", "# make sure all arguments are present in older models", "\n", "base_architecture", "(", "args", ")", "\n", "\n", "if", "not", "hasattr", "(", "args", ",", "\"max_source_positions\"", ")", ":", "\n", "            ", "args", ".", "max_source_positions", "=", "2048", "\n", "", "if", "not", "hasattr", "(", "args", ",", "\"max_target_positions\"", ")", ":", "\n", "            ", "args", ".", "max_target_positions", "=", "2048", "\n", "\n", "", "src_dict", ",", "tgt_dict", "=", "task", ".", "source_dictionary", ",", "task", ".", "target_dictionary", "\n", "\n", "def", "build_embedding", "(", "dictionary", ",", "embed_dim", ")", ":", "\n", "            ", "num_embeddings", "=", "len", "(", "dictionary", ")", "\n", "padding_idx", "=", "dictionary", ".", "pad", "(", ")", "\n", "emb", "=", "Embedding", "(", "num_embeddings", ",", "embed_dim", ",", "padding_idx", ")", "\n", "return", "emb", "\n", "\n", "", "decoder_embed_tokens", "=", "build_embedding", "(", "tgt_dict", ",", "args", ".", "decoder_embed_dim", ")", "\n", "\n", "encoder", "=", "cls", ".", "build_encoder", "(", "args", ")", "\n", "decoder", "=", "cls", ".", "build_decoder", "(", "args", ",", "tgt_dict", ",", "decoder_embed_tokens", ")", "\n", "return", "TransformerModel", "(", "args", ",", "encoder", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.TransformerModel.build_encoder": [[288, 291], ["wav2vec2_asr.Wav2VecEncoder"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_encoder", "(", "cls", ",", "args", ")", ":", "\n", "        ", "return", "Wav2VecEncoder", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.TransformerModel.build_decoder": [[292, 295], ["wav2vec2_asr.TransformerDecoder"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_decoder", "(", "cls", ",", "args", ",", "tgt_dict", ",", "embed_tokens", ")", ":", "\n", "        ", "return", "TransformerDecoder", "(", "args", ",", "tgt_dict", ",", "embed_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.TransformerModel.forward": [[296, 300], ["wav2vec2_asr.TransformerModel.encoder", "wav2vec2_asr.TransformerModel.decoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "encoder_out", "=", "self", ".", "encoder", "(", "tbc", "=", "False", ",", "**", "kwargs", ")", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "encoder_out", "=", "encoder_out", ",", "**", "kwargs", ")", "\n", "return", "decoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.TransformerModel.upgrade_state_dict_named": [[301, 304], ["super().upgrade_state_dict_named"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.upgrade_state_dict_named"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "super", "(", ")", ".", "upgrade_state_dict_named", "(", "state_dict", ",", "name", ")", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.Wav2VecEncoder.__init__": [[307, 373], ["fairseq.tasks.setup_task", "fairseq.tasks.setup_task.build_model", "tasks.setup_task.build_model.remove_pretraining_modules", "fairseq.models.FairseqEncoder.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "getattr", "fairseq.checkpoint_utils.load_checkpoint_to_cpu", "fairseq.checkpoint_utils.load_checkpoint_to_cpu.get", "isinstance", "tasks.setup_task.build_model.load_state_dict", "wav2vec2_asr.Linear", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "fairseq.dataclass.utils.convert_namespace_to_omegaconf", "len", "getattr", "wav2vec2_asr.Linear"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyMTTask.setup_task", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2.Wav2Vec2Model.remove_pretraining_modules", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.fairseq.checkpoint_utils.load_checkpoint_to_cpu", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.convert_namespace_to_omegaconf", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "tgt_dict", "=", "None", ")", ":", "\n", "        ", "self", ".", "apply_mask", "=", "args", ".", "apply_mask", "\n", "\n", "arg_overrides", "=", "{", "\n", "\"dropout\"", ":", "args", ".", "dropout", ",", "\n", "\"activation_dropout\"", ":", "args", ".", "activation_dropout", ",", "\n", "\"dropout_input\"", ":", "args", ".", "dropout_input", ",", "\n", "\"attention_dropout\"", ":", "args", ".", "attention_dropout", ",", "\n", "\"mask_length\"", ":", "args", ".", "mask_length", ",", "\n", "\"mask_prob\"", ":", "args", ".", "mask_prob", ",", "\n", "\"mask_selection\"", ":", "args", ".", "mask_selection", ",", "\n", "\"mask_other\"", ":", "args", ".", "mask_other", ",", "\n", "\"no_mask_overlap\"", ":", "args", ".", "no_mask_overlap", ",", "\n", "\"mask_channel_length\"", ":", "args", ".", "mask_channel_length", ",", "\n", "\"mask_channel_prob\"", ":", "args", ".", "mask_channel_prob", ",", "\n", "\"mask_channel_selection\"", ":", "args", ".", "mask_channel_selection", ",", "\n", "\"mask_channel_other\"", ":", "args", ".", "mask_channel_other", ",", "\n", "\"no_mask_channel_overlap\"", ":", "args", ".", "no_mask_channel_overlap", ",", "\n", "\"encoder_layerdrop\"", ":", "args", ".", "layerdrop", ",", "\n", "\"feature_grad_mult\"", ":", "args", ".", "feature_grad_mult", ",", "\n", "}", "\n", "\n", "if", "getattr", "(", "args", ",", "\"w2v_args\"", ",", "None", ")", "is", "None", ":", "\n", "            ", "state", "=", "checkpoint_utils", ".", "load_checkpoint_to_cpu", "(", "\n", "args", ".", "w2v_path", ",", "arg_overrides", "\n", ")", "\n", "w2v_args", "=", "state", ".", "get", "(", "\"cfg\"", ",", "None", ")", "\n", "if", "w2v_args", "is", "None", ":", "\n", "                ", "w2v_args", "=", "convert_namespace_to_omegaconf", "(", "state", "[", "\"args\"", "]", ")", "\n", "", "args", ".", "w2v_args", "=", "w2v_args", "\n", "", "else", ":", "\n", "            ", "state", "=", "None", "\n", "w2v_args", "=", "args", ".", "w2v_args", "\n", "if", "isinstance", "(", "w2v_args", ",", "Namespace", ")", ":", "\n", "                ", "args", ".", "w2v_args", "=", "w2v_args", "=", "convert_namespace_to_omegaconf", "(", "w2v_args", ")", "\n", "\n", "", "", "assert", "(", "\n", "args", ".", "normalize", "==", "w2v_args", ".", "task", ".", "normalize", "\n", ")", ",", "\"Fine-tuning works best when data normalization is the same. \"", "\"Please check that --normalize is set or unset for both\"", "\n", "\n", "w2v_args", ".", "task", ".", "data", "=", "args", ".", "data", "\n", "task", "=", "tasks", ".", "setup_task", "(", "w2v_args", ".", "task", ")", "\n", "model", "=", "task", ".", "build_model", "(", "w2v_args", ".", "model", ")", "\n", "\n", "if", "state", "is", "not", "None", "and", "not", "args", ".", "no_pretrained_weights", ":", "\n", "            ", "model", ".", "load_state_dict", "(", "state", "[", "\"model\"", "]", ",", "strict", "=", "True", ")", "\n", "\n", "", "model", ".", "remove_pretraining_modules", "(", ")", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "task", ".", "source_dictionary", ")", "\n", "\n", "d", "=", "w2v_args", ".", "model", ".", "encoder_embed_dim", "\n", "\n", "self", ".", "w2v_model", "=", "model", "\n", "\n", "self", ".", "final_dropout", "=", "nn", ".", "Dropout", "(", "args", ".", "final_dropout", ")", "\n", "self", ".", "freeze_finetune_updates", "=", "args", ".", "freeze_finetune_updates", "\n", "self", ".", "num_updates", "=", "0", "\n", "\n", "if", "tgt_dict", "is", "not", "None", ":", "\n", "            ", "self", ".", "proj", "=", "Linear", "(", "d", ",", "len", "(", "tgt_dict", ")", ")", "\n", "", "elif", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "d", ")", "!=", "d", ":", "\n", "            ", "self", ".", "proj", "=", "Linear", "(", "d", ",", "args", ".", "decoder_embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "proj", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.Wav2VecEncoder.set_num_updates": [[374, 378], ["super().set_num_updates"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.Wav2VecEncoder.set_num_updates"], ["", "", "def", "set_num_updates", "(", "self", ",", "num_updates", ")", ":", "\n", "        ", "\"\"\"Set the number of parameters updates.\"\"\"", "\n", "super", "(", ")", ".", "set_num_updates", "(", "num_updates", ")", "\n", "self", ".", "num_updates", "=", "num_updates", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.Wav2VecEncoder.forward": [[379, 405], ["wav2vec2_asr.Wav2VecEncoder.final_dropout", "wav2vec2_asr.Wav2VecEncoder.w2v_model.extract_features", "wav2vec2_asr.Wav2VecEncoder.proj", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "contextlib.ExitStack", "x.transpose.transpose.transpose"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features"], ["", "def", "forward", "(", "self", ",", "source", ",", "padding_mask", ",", "tbc", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "w2v_args", "=", "{", "\n", "\"source\"", ":", "source", ",", "\n", "\"padding_mask\"", ":", "padding_mask", ",", "\n", "\"mask\"", ":", "self", ".", "apply_mask", "and", "self", ".", "training", ",", "\n", "}", "\n", "\n", "ft", "=", "self", ".", "freeze_finetune_updates", "<=", "self", ".", "num_updates", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", "if", "not", "ft", "else", "contextlib", ".", "ExitStack", "(", ")", ":", "\n", "            ", "x", ",", "padding_mask", "=", "self", ".", "w2v_model", ".", "extract_features", "(", "**", "w2v_args", ")", "\n", "\n", "if", "tbc", ":", "\n", "# B x T x C -> T x B x C", "\n", "                ", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "", "", "x", "=", "self", ".", "final_dropout", "(", "x", ")", "\n", "\n", "if", "self", ".", "proj", ":", "\n", "            ", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "\n", "", "return", "{", "\n", "\"encoder_out\"", ":", "x", ",", "# T x B x C", "\n", "\"encoder_padding_mask\"", ":", "padding_mask", ",", "# B x T", "\n", "\"padding_mask\"", ":", "padding_mask", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.Wav2VecEncoder.reorder_encoder_out": [[407, 417], ["encoder_out[].index_select", "encoder_out[].index_select"], "methods", ["None"], ["", "def", "reorder_encoder_out", "(", "self", ",", "encoder_out", ",", "new_order", ")", ":", "\n", "        ", "if", "encoder_out", "[", "\"encoder_out\"", "]", "is", "not", "None", ":", "\n", "            ", "encoder_out", "[", "\"encoder_out\"", "]", "=", "encoder_out", "[", "\"encoder_out\"", "]", ".", "index_select", "(", "\n", "1", ",", "new_order", "\n", ")", "\n", "", "if", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "is", "not", "None", ":", "\n", "            ", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "=", "encoder_out", "[", "\n", "\"encoder_padding_mask\"", "\n", "]", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", "", "return", "encoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.Wav2VecEncoder.max_positions": [[418, 421], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum input length supported by the encoder.\"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.Wav2VecEncoder.upgrade_state_dict_named": [[422, 424], ["None"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.TransformerDecoder.__init__": [[439, 500], ["fairseq.models.FairseqIncrementalDecoder.__init__", "math.sqrt", "copy.deepcopy", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "wav2vec2_asr.TransformerDecoder.layers.extend", "wav2vec2_asr.Linear", "fairseq.modules.PositionalEmbedding", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "fairseq.modules.LayerNorm", "fairseq.modules.TransformerDecoderLayer", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "getattr", "range", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.PositionalEmbedding", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "self", ",", "args", ",", "dictionary", ",", "embed_tokens", ",", "no_encoder_attn", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "\n", "self", ".", "dropout", "=", "args", ".", "decoder_dropout", "\n", "self", ".", "share_input_output_embed", "=", "args", ".", "share_decoder_input_output_embed", "\n", "\n", "input_embed_dim", "=", "embed_tokens", ".", "embedding_dim", "\n", "embed_dim", "=", "args", ".", "decoder_embed_dim", "\n", "self", ".", "output_embed_dim", "=", "args", ".", "decoder_embed_dim", "\n", "args", ".", "encoder_embed_dim", "=", "embed_dim", "\n", "\n", "self", ".", "layerdrop", "=", "args", ".", "decoder_layerdrop", "\n", "\n", "padding_idx", "=", "embed_tokens", ".", "padding_idx", "\n", "self", ".", "max_target_positions", "=", "args", ".", "max_target_positions", "\n", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "self", ".", "embed_scale", "=", "math", ".", "sqrt", "(", "embed_dim", ")", "# todo: try with input_embed_dim", "\n", "\n", "self", ".", "project_in_dim", "=", "(", "\n", "Linear", "(", "input_embed_dim", ",", "embed_dim", ",", "bias", "=", "False", ")", "\n", "if", "embed_dim", "!=", "input_embed_dim", "\n", "else", "None", "\n", ")", "\n", "\n", "self", ".", "embed_positions", "=", "(", "\n", "PositionalEmbedding", "(", "\n", "args", ".", "max_target_positions", ",", "\n", "embed_dim", ",", "\n", "padding_idx", ",", "\n", "learned", "=", "args", ".", "decoder_learned_pos", ",", "\n", ")", "\n", "if", "not", "args", ".", "no_token_positional_embeddings", "\n", "else", "None", "\n", ")", "\n", "\n", "args", "=", "copy", ".", "deepcopy", "(", "args", ")", "\n", "args", ".", "dropout", "=", "args", ".", "decoder_dropout", "\n", "args", ".", "attention_dropout", "=", "args", ".", "decoder_attention_dropout", "\n", "args", ".", "activation_dropout", "=", "args", ".", "decoder_activation_dropout", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "layers", ".", "extend", "(", "\n", "[", "\n", "TransformerDecoderLayer", "(", "args", ",", "no_encoder_attn", ")", "\n", "for", "_", "in", "range", "(", "args", ".", "decoder_layers", ")", "\n", "]", "\n", ")", "\n", "\n", "if", "not", "self", ".", "share_input_output_embed", ":", "\n", "            ", "self", ".", "embed_out", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "len", "(", "dictionary", ")", ",", "self", ".", "output_embed_dim", ")", "\n", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "embed_out", ",", "mean", "=", "0", ",", "std", "=", "self", ".", "output_embed_dim", "**", "-", "0.5", ")", "\n", "\n", "", "if", "args", ".", "decoder_normalize_before", "and", "not", "getattr", "(", "\n", "args", ",", "\"no_decoder_final_norm\"", ",", "False", "\n", ")", ":", "\n", "            ", "self", ".", "layer_norm", "=", "LayerNorm", "(", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer_norm", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.TransformerDecoder.forward": [[501, 524], ["prev_output_tokens.long.long.long", "wav2vec2_asr.TransformerDecoder.extract_features", "wav2vec2_asr.TransformerDecoder.output_layer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.output_layer"], ["", "", "def", "forward", "(", "\n", "self", ",", "prev_output_tokens", ",", "encoder_out", "=", "None", ",", "incremental_state", "=", "None", ",", "**", "unused", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            prev_output_tokens (LongTensor): previous decoder outputs of shape\n                `(batch, tgt_len)`, for teacher forcing\n            encoder_out (Tensor, optional): output from the encoder, used for\n                encoder-side attention\n            incremental_state (dict): dictionary used for storing state during\n                :ref:`Incremental decoding`\n\n        Returns:\n            tuple:\n                - the decoder's output of shape `(batch, tgt_len, vocab)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "prev_output_tokens", "=", "prev_output_tokens", ".", "long", "(", ")", "\n", "x", ",", "extra", "=", "self", ".", "extract_features", "(", "\n", "prev_output_tokens", ",", "encoder_out", ",", "incremental_state", "\n", ")", "\n", "x", "=", "self", ".", "output_layer", "(", "x", ")", "\n", "return", "x", ",", "extra", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.TransformerDecoder.extract_features": [[525, 591], ["torch.dropout", "torch.dropout", "torch.dropout", "wav2vec2_asr.TransformerDecoder.transpose", "wav2vec2_asr.TransformerDecoder.transpose", "wav2vec2_asr.TransformerDecoder.embed_positions", "wav2vec2_asr.TransformerDecoder.embed_tokens", "wav2vec2_asr.TransformerDecoder.project_in_dim", "numpy.random.random", "wav2vec2_asr.TransformerDecoder.layer_norm", "layer", "inner_states.append", "wav2vec2_asr.TransformerDecoder.buffered_future_mask"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.buffered_future_mask"], ["", "def", "extract_features", "(", "\n", "self", ",", "prev_output_tokens", ",", "encoder_out", "=", "None", ",", "incremental_state", "=", "None", ",", "**", "unused", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Similar to *forward* but only return features.\n\n        Returns:\n            tuple:\n                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\n                - a dictionary with any model-specific outputs\n        \"\"\"", "\n", "\n", "# embed positions", "\n", "positions", "=", "(", "\n", "self", ".", "embed_positions", "(", "\n", "prev_output_tokens", ",", "incremental_state", "=", "incremental_state", "\n", ")", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "prev_output_tokens", "=", "prev_output_tokens", "[", ":", ",", "-", "1", ":", "]", "\n", "if", "positions", "is", "not", "None", ":", "\n", "                ", "positions", "=", "positions", "[", ":", ",", "-", "1", ":", "]", "\n", "\n", "# embed tokens and positions", "\n", "", "", "x", "=", "self", ".", "embed_scale", "*", "self", ".", "embed_tokens", "(", "prev_output_tokens", ")", "\n", "\n", "if", "self", ".", "project_in_dim", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "project_in_dim", "(", "x", ")", "\n", "\n", "", "if", "positions", "is", "not", "None", ":", "\n", "            ", "x", "+=", "positions", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "attn", "=", "None", "\n", "\n", "inner_states", "=", "[", "x", "]", "\n", "\n", "# decoder layers", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "dropout_probability", "=", "np", ".", "random", ".", "random", "(", ")", "\n", "if", "not", "self", ".", "training", "or", "(", "dropout_probability", ">", "self", ".", "layerdrop", ")", ":", "\n", "                ", "x", ",", "attn", ",", "_", "=", "layer", "(", "\n", "x", ",", "\n", "encoder_out", "[", "\"encoder_out\"", "]", "if", "encoder_out", "is", "not", "None", "else", "None", ",", "\n", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "\n", "if", "encoder_out", "is", "not", "None", "\n", "else", "None", ",", "\n", "incremental_state", ",", "\n", "self_attn_mask", "=", "self", ".", "buffered_future_mask", "(", "x", ")", "\n", "if", "incremental_state", "is", "None", "\n", "else", "None", ",", "\n", ")", "\n", "inner_states", ".", "append", "(", "x", ")", "\n", "\n", "", "", "if", "self", ".", "layer_norm", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "return", "x", ",", "{", "\"attn\"", ":", "attn", ",", "\"inner_states\"", ":", "inner_states", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.TransformerDecoder.output_layer": [[592, 599], ["torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["", "def", "output_layer", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Project features to the vocabulary size.\"\"\"", "\n", "# project back to size of vocabulary", "\n", "if", "self", ".", "share_input_output_embed", ":", "\n", "            ", "return", "F", ".", "linear", "(", "features", ",", "self", ".", "embed_tokens", ".", "weight", ")", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "linear", "(", "features", ",", "self", ".", "embed_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.TransformerDecoder.max_positions": [[600, 605], ["min"], "methods", ["None"], ["", "", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum output length supported by the decoder.\"\"\"", "\n", "if", "self", ".", "embed_positions", "is", "None", ":", "\n", "            ", "return", "self", ".", "max_target_positions", "\n", "", "return", "min", "(", "self", ".", "max_target_positions", ",", "self", ".", "embed_positions", ".", "max_positions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.TransformerDecoder.buffered_future_mask": [[606, 618], ["tensor.size", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "hasattr", "wav2vec2_asr.TransformerDecoder._future_mask.size", "fairseq.utils.fill_with_neg_inf", "tensor.new"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.fill_with_neg_inf"], ["", "def", "buffered_future_mask", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "dim", "=", "tensor", ".", "size", "(", "0", ")", "\n", "if", "(", "\n", "not", "hasattr", "(", "self", ",", "\"_future_mask\"", ")", "\n", "or", "self", ".", "_future_mask", "is", "None", "\n", "or", "self", ".", "_future_mask", ".", "device", "!=", "tensor", ".", "device", "\n", "or", "self", ".", "_future_mask", ".", "size", "(", "0", ")", "<", "dim", "\n", ")", ":", "\n", "            ", "self", ".", "_future_mask", "=", "torch", ".", "triu", "(", "\n", "utils", ".", "fill_with_neg_inf", "(", "tensor", ".", "new", "(", "dim", ",", "dim", ")", ")", ",", "1", "\n", ")", "\n", "", "return", "self", ".", "_future_mask", "[", ":", "dim", ",", ":", "dim", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.TransformerDecoder.upgrade_state_dict_named": [[619, 621], ["None"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.add_common_args": [[28, 145], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["def", "add_common_args", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "\"--w2v-path\"", ",", "help", "=", "\"path to wav2vec 2.0 model\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no-pretrained-weights\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if true, does not load pretrained weights\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dropout-input\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout to apply to the input (after feat extr)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--final-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout after transformer and before final projection\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--apply-mask\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"apply masking during fine-tuning\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability inside wav2vec 2.0 model\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--attention-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability for attention weights inside wav2vec 2.0 model\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--activation-dropout\"", ",", "\n", "\"--relu-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability after activation in FFN inside wav2vec 2.0 model\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-length\"", ",", "type", "=", "int", ",", "help", "=", "\"repeat the mask indices multiple times\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-prob\"", ",", "type", "=", "float", ",", "help", "=", "\"probability of replacing a token with mask\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-selection\"", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "[", "\"static\"", ",", "\"uniform\"", ",", "\"normal\"", ",", "\"poisson\"", "]", ",", "\n", "help", "=", "\"how to choose masks\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-other\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"stdev of the mask length in case of 'normal' selection strategy\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no-mask-overlap\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"whether to allow masks to overlap\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-channel-length\"", ",", "type", "=", "int", ",", "help", "=", "\"repeat the mask indices multiple times\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-channel-prob\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"probability of replacing a token with mask\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-channel-selection\"", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "[", "\"static\"", ",", "\"uniform\"", ",", "\"normal\"", ",", "\"poisson\"", "]", ",", "\n", "help", "=", "\"how to choose masks\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-channel-other\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"stdev of the mask length in case of 'normal' selection strategy\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no-mask-channel-overlap\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"whether to allow masks to overlap\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--freeze-finetune-updates\"", ",", "\n", "default", "=", "0", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"dont finetune wav2vec for this many updates\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--feature-grad-mult\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"reset feature grad mult in wav2vec 2.0 to this\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--layerdrop\"", ",", "\n", "default", "=", "0.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"probability of dropping a layer in wav2vec 2.0\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.Embedding": [[623, 628], ["torch.Embedding", "torch.init.normal_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding"], ["", "", "def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "embedding_dim", "**", "-", "0.5", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.Linear": [[630, 636], ["torch.Linear", "torch.init.xavier_uniform_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["", "def", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "if", "bias", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.0", ")", "\n", "", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.base_architecture": [[638, 662], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "@", "register_model_architecture", "(", "\"wav2vec_ctc\"", ",", "\"wav2vec_ctc\"", ")", "\n", "def", "base_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "no_pretrained_weights", "=", "getattr", "(", "args", ",", "\"no_pretrained_weights\"", ",", "False", ")", "\n", "args", ".", "dropout_input", "=", "getattr", "(", "args", ",", "\"dropout_input\"", ",", "0", ")", "\n", "args", ".", "final_dropout", "=", "getattr", "(", "args", ",", "\"final_dropout\"", ",", "0", ")", "\n", "args", ".", "apply_mask", "=", "getattr", "(", "args", ",", "\"apply_mask\"", ",", "False", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0", ")", "\n", "args", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "0", ")", "\n", "\n", "args", ".", "mask_length", "=", "getattr", "(", "args", ",", "\"mask_length\"", ",", "10", ")", "\n", "args", ".", "mask_prob", "=", "getattr", "(", "args", ",", "\"mask_prob\"", ",", "0.5", ")", "\n", "args", ".", "mask_selection", "=", "getattr", "(", "args", ",", "\"mask_selection\"", ",", "\"static\"", ")", "\n", "args", ".", "mask_other", "=", "getattr", "(", "args", ",", "\"mask_other\"", ",", "0", ")", "\n", "args", ".", "no_mask_overlap", "=", "getattr", "(", "args", ",", "\"no_mask_overlap\"", ",", "False", ")", "\n", "args", ".", "mask_channel_length", "=", "getattr", "(", "args", ",", "\"mask_channel_length\"", ",", "10", ")", "\n", "args", ".", "mask_channel_prob", "=", "getattr", "(", "args", ",", "\"mask_channel_prob\"", ",", "0.5", ")", "\n", "args", ".", "mask_channel_selection", "=", "getattr", "(", "args", ",", "\"mask_channel_selection\"", ",", "\"static\"", ")", "\n", "args", ".", "mask_channel_other", "=", "getattr", "(", "args", ",", "\"mask_channel_other\"", ",", "0", ")", "\n", "args", ".", "no_mask_channel_overlap", "=", "getattr", "(", "args", ",", "\"no_mask_channel_overlap\"", ",", "False", ")", "\n", "\n", "args", ".", "freeze_finetune_updates", "=", "getattr", "(", "args", ",", "\"freeze_finetune_updates\"", ",", "0", ")", "\n", "args", ".", "feature_grad_mult", "=", "getattr", "(", "args", ",", "\"feature_grad_mult\"", ",", "0", ")", "\n", "args", ".", "layerdrop", "=", "getattr", "(", "args", ",", "\"layerdrop\"", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec2_asr.seq2seq_architecture": [[664, 684], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "wav2vec2_asr.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "@", "register_model_architecture", "(", "\"wav2vec_seq2seq\"", ",", "\"wav2vec_seq2seq\"", ")", "\n", "def", "seq2seq_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "1024", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "4096", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "10", ")", "\n", "args", ".", "decoder_layerdrop", "=", "getattr", "(", "args", ",", "\"decoder_layerdrop\"", ",", "0", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "16", ")", "\n", "args", ".", "decoder_learned_pos", "=", "getattr", "(", "args", ",", "\"decoder_learned_pos\"", ",", "False", ")", "\n", "args", ".", "decoder_normalize_before", "=", "getattr", "(", "args", ",", "\"decoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "no_token_positional_embeddings", "=", "getattr", "(", "\n", "args", ",", "\"no_token_positional_embeddings\"", ",", "False", "\n", ")", "\n", "args", ".", "decoder_dropout", "=", "getattr", "(", "args", ",", "\"decoder_dropout\"", ",", "0", ")", "\n", "args", ".", "decoder_attention_dropout", "=", "getattr", "(", "args", ",", "\"decoder_attention_dropout\"", ",", "0", ")", "\n", "args", ".", "decoder_activation_dropout", "=", "getattr", "(", "args", ",", "\"decoder_activation_dropout\"", ",", "0", ")", "\n", "args", ".", "share_decoder_input_output_embed", "=", "getattr", "(", "\n", "args", ",", "\"share_decoder_input_output_embed\"", ",", "False", "\n", ")", "\n", "\n", "base_architecture", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.__init__": [[29, 32], ["fairseq.hub_utils.GeneratorHubInterface.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ",", "task", ",", "model", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "task", ",", "[", "model", "]", ")", "\n", "self", ".", "model", "=", "self", ".", "models", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.encode": [[33, 64], ["hub_interface.BARTHubInterface.bpe.encode", "hub_interface.BARTHubInterface.task.source_dictionary.encode_line", "hub_interface.BARTHubInterface.long", "len", "hub_interface.BARTHubInterface.split", "min", "hub_interface.BARTHubInterface.split", "hub_interface.BARTHubInterface.bpe.encode", "min"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.encode_line", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "def", "encode", "(", "\n", "self", ",", "sentence", ":", "str", ",", "*", "addl_sentences", ",", "no_separator", "=", "True", "\n", ")", "->", "torch", ".", "LongTensor", ":", "\n", "        ", "\"\"\"\n        BPE-encode a sentence (or multiple sentences).\n\n        Every sequence begins with a beginning-of-sentence (`<s>`) symbol.\n        Every sentence ends with an end-of-sentence (`</s>`).\n\n        Example (single sentence): `<s> a b c </s>`\n        Example (sentence pair): `<s> d e f </s> 1 2 3 </s>`\n\n        The BPE encoding follows GPT-2. One subtle detail is that the GPT-2 BPE\n        requires leading spaces. For example::\n\n            >>> bart.encode('Hello world').tolist()\n            [0, 31414, 232, 2]\n            >>> bart.encode(' world').tolist()\n            [0, 232, 2]\n            >>> bart.encode('world').tolist()\n            [0, 8331, 2]\n        \"\"\"", "\n", "tokens", "=", "self", ".", "bpe", ".", "encode", "(", "sentence", ")", "\n", "if", "len", "(", "tokens", ".", "split", "(", "\" \"", ")", ")", ">", "min", "(", "self", ".", "max_positions", ")", "-", "2", ":", "\n", "            ", "tokens", "=", "\" \"", ".", "join", "(", "tokens", ".", "split", "(", "\" \"", ")", "[", ":", "min", "(", "self", ".", "max_positions", ")", "-", "2", "]", ")", "\n", "", "bpe_sentence", "=", "\"<s> \"", "+", "tokens", "+", "\" </s>\"", "\n", "for", "s", "in", "addl_sentences", ":", "\n", "            ", "bpe_sentence", "+=", "\" </s>\"", "if", "not", "no_separator", "else", "\"\"", "\n", "bpe_sentence", "+=", "\" \"", "+", "self", ".", "bpe", ".", "encode", "(", "s", ")", "+", "\" </s>\"", "\n", "", "tokens", "=", "self", ".", "task", ".", "source_dictionary", ".", "encode_line", "(", "bpe_sentence", ",", "append_eos", "=", "False", ")", "\n", "return", "tokens", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.decode": [[65, 79], ["tokens.cpu().numpy.cpu().numpy.cpu().numpy", "numpy.split", "tokens.cpu().numpy.cpu().numpy.dim", "hub_interface.BARTHubInterface.task.source_dictionary.bos", "hub_interface.BARTHubInterface.task.source_dictionary.eos", "hub_interface.BARTHubInterface.bpe.decode", "len", "tokens.cpu().numpy.cpu().numpy.cpu", "hub_interface.BARTHubInterface.task.source_dictionary.string", "doc_mask.nonzero"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.string"], ["", "def", "decode", "(", "self", ",", "tokens", ":", "torch", ".", "LongTensor", ")", ":", "\n", "        ", "assert", "tokens", ".", "dim", "(", ")", "==", "1", "\n", "tokens", "=", "tokens", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "tokens", "[", "0", "]", "==", "self", ".", "task", ".", "source_dictionary", ".", "bos", "(", ")", ":", "\n", "            ", "tokens", "=", "tokens", "[", "1", ":", "]", "# remove <s>", "\n", "", "eos_mask", "=", "tokens", "==", "self", ".", "task", ".", "source_dictionary", ".", "eos", "(", ")", "\n", "doc_mask", "=", "eos_mask", "[", "1", ":", "]", "&", "eos_mask", "[", ":", "-", "1", "]", "\n", "sentences", "=", "np", ".", "split", "(", "tokens", ",", "doc_mask", ".", "nonzero", "(", ")", "[", "0", "]", "+", "1", ")", "\n", "sentences", "=", "[", "\n", "self", ".", "bpe", ".", "decode", "(", "self", ".", "task", ".", "source_dictionary", ".", "string", "(", "s", ")", ")", "for", "s", "in", "sentences", "\n", "]", "\n", "if", "len", "(", "sentences", ")", "==", "1", ":", "\n", "            ", "return", "sentences", "[", "0", "]", "\n", "", "return", "sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface._build_sample": [[80, 89], ["hub_interface.BARTHubInterface.task.build_dataset_for_inference", "hub_interface.BARTHubInterface.collater", "fairseq.utils.apply_to_sample", "x.numel", "tensor.to"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask.build_dataset_for_inference", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.collater", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.apply_to_sample"], ["", "def", "_build_sample", "(", "self", ",", "src_tokens", ":", "List", "[", "torch", ".", "LongTensor", "]", ")", ":", "\n", "# assert torch.is_tensor(src_tokens)", "\n", "        ", "dataset", "=", "self", ".", "task", ".", "build_dataset_for_inference", "(", "\n", "src_tokens", ",", "\n", "[", "x", ".", "numel", "(", ")", "for", "x", "in", "src_tokens", "]", ",", "\n", ")", "\n", "sample", "=", "dataset", ".", "collater", "(", "dataset", ")", "\n", "sample", "=", "utils", ".", "apply_to_sample", "(", "lambda", "tensor", ":", "tensor", ".", "to", "(", "self", ".", "device", ")", ",", "sample", ")", "\n", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.generate": [[90, 110], ["super().generate", "NotImplementedError", "len", "tokenized_sentences[].new_full().to", "tokenized_sentences[].new_full", "hub_interface.BARTHubInterface.task.source_dictionary.bos"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.generate", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos"], ["", "def", "generate", "(", "\n", "self", ",", "\n", "tokenized_sentences", ":", "List", "[", "torch", ".", "LongTensor", "]", ",", "\n", "*", "args", ",", "\n", "inference_step_args", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", "->", "List", "[", "List", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", "]", ":", "\n", "        ", "inference_step_args", "=", "inference_step_args", "or", "{", "}", "\n", "if", "\"prefix_tokens\"", "in", "inference_step_args", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"prefix generation not implemented for BART\"", ")", "\n", "", "else", ":", "\n", "            ", "bsz", "=", "len", "(", "tokenized_sentences", ")", "\n", "inference_step_args", "[", "\"prefix_tokens\"", "]", "=", "tokenized_sentences", "[", "0", "]", ".", "new_full", "(", "\n", "(", "bsz", ",", "1", ")", ",", "fill_value", "=", "self", ".", "task", ".", "source_dictionary", ".", "bos", "(", ")", "\n", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "", "return", "super", "(", ")", ".", "generate", "(", "\n", "tokenized_sentences", ",", "\n", "*", "args", ",", "\n", "inference_step_args", "=", "inference_step_args", ",", "\n", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.extract_features": [[112, 145], ["tokens.unsqueeze.unsqueeze.clone", "tokens.unsqueeze.unsqueeze.gather().squeeze", "hub_interface.BARTHubInterface.model", "tokens.unsqueeze.unsqueeze.dim", "tokens.unsqueeze.unsqueeze.unsqueeze", "tokens.unsqueeze.unsqueeze.size", "min", "ValueError", "tokens.unsqueeze.unsqueeze.to", "hub_interface.BARTHubInterface.model.max_positions", "tokens.unsqueeze.unsqueeze.gather", "inner_state.transpose", "tokens.unsqueeze.unsqueeze.size", "hub_interface.BARTHubInterface.model.max_positions", "tokens.unsqueeze.unsqueeze.ne().sum", "tokens.unsqueeze.unsqueeze.ne", "hub_interface.BARTHubInterface.task.source_dictionary.pad"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["", "def", "extract_features", "(", "\n", "self", ",", "tokens", ":", "torch", ".", "LongTensor", ",", "return_all_hiddens", ":", "bool", "=", "False", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "if", "tokens", ".", "dim", "(", ")", "==", "1", ":", "\n", "            ", "tokens", "=", "tokens", ".", "unsqueeze", "(", "0", ")", "\n", "", "if", "tokens", ".", "size", "(", "-", "1", ")", ">", "min", "(", "self", ".", "model", ".", "max_positions", "(", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"tokens exceeds maximum length: {} > {}\"", ".", "format", "(", "\n", "tokens", ".", "size", "(", "-", "1", ")", ",", "self", ".", "model", ".", "max_positions", "(", ")", "\n", ")", "\n", ")", "\n", "", "tokens", ".", "to", "(", "device", "=", "self", ".", "device", ")", ",", "\n", "prev_output_tokens", "=", "tokens", ".", "clone", "(", ")", "\n", "\n", "prev_output_tokens", "[", ":", ",", "0", "]", "=", "tokens", ".", "gather", "(", "\n", "1", ",", "\n", "(", "tokens", ".", "ne", "(", "self", ".", "task", ".", "source_dictionary", ".", "pad", "(", ")", ")", ".", "sum", "(", "dim", "=", "1", ")", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", ")", ".", "squeeze", "(", ")", "\n", "\n", "prev_output_tokens", "[", ":", ",", "1", ":", "]", "=", "tokens", "[", ":", ",", ":", "-", "1", "]", "\n", "features", ",", "extra", "=", "self", ".", "model", "(", "\n", "src_tokens", "=", "tokens", ",", "\n", "src_lengths", "=", "None", ",", "\n", "prev_output_tokens", "=", "prev_output_tokens", ",", "\n", "features_only", "=", "True", ",", "\n", "return_all_hiddens", "=", "return_all_hiddens", ",", "\n", ")", "\n", "if", "return_all_hiddens", ":", "\n", "# convert from T x B x C -> B x T x C", "\n", "            ", "inner_states", "=", "extra", "[", "\"inner_states\"", "]", "\n", "return", "[", "inner_state", ".", "transpose", "(", "0", ",", "1", ")", "for", "inner_state", "in", "inner_states", "]", "\n", "", "else", ":", "\n", "            ", "return", "features", "# just the last layer's features", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.register_classification_head": [[146, 151], ["hub_interface.BARTHubInterface.model.register_classification_head"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaModel.register_classification_head"], ["", "", "def", "register_classification_head", "(", "\n", "self", ",", "name", ":", "str", ",", "num_classes", ":", "int", "=", "None", ",", "embedding_size", ":", "int", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "self", ".", "model", ".", "register_classification_head", "(", "\n", "name", ",", "num_classes", "=", "num_classes", ",", "embedding_size", "=", "embedding_size", ",", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.predict": [[153, 165], ["hub_interface.BARTHubInterface.extract_features", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "tokens.unsqueeze.unsqueeze.dim", "tokens.unsqueeze.unsqueeze.unsqueeze", "tokens.unsqueeze.unsqueeze.to", "features[].view", "hub_interface.BARTHubInterface.size", "hub_interface.BARTHubInterface.size", "tokens.unsqueeze.unsqueeze.eq", "hub_interface.BARTHubInterface.task.source_dictionary.eos"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "def", "predict", "(", "self", ",", "head", ":", "str", ",", "tokens", ":", "torch", ".", "LongTensor", ",", "return_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "tokens", ".", "dim", "(", ")", "==", "1", ":", "\n", "            ", "tokens", "=", "tokens", ".", "unsqueeze", "(", "0", ")", "\n", "", "features", "=", "self", ".", "extract_features", "(", "tokens", ".", "to", "(", "device", "=", "self", ".", "device", ")", ")", "\n", "sentence_representation", "=", "features", "[", "\n", "tokens", ".", "eq", "(", "self", ".", "task", ".", "source_dictionary", ".", "eos", "(", ")", ")", ",", ":", "\n", "]", ".", "view", "(", "features", ".", "size", "(", "0", ")", ",", "-", "1", ",", "features", ".", "size", "(", "-", "1", ")", ")", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "\n", "logits", "=", "self", ".", "model", ".", "classification_heads", "[", "head", "]", "(", "sentence_representation", ")", "\n", "if", "return_logits", ":", "\n", "            ", "return", "logits", "\n", "", "return", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.fill_mask": [[166, 201], ["max", "hub_interface.BARTHubInterface.generate", "masked_input.split", "hub_interface.BARTHubInterface.task.source_dictionary.encode_line().long", "batch_tokens.append", "generate_kwargs.get", "hub_interface.BARTHubInterface.task.source_dictionary.encode_line", "hub_interface.BARTHubInterface.decode", "hub_interface.BARTHubInterface.bpe.encode", "text_span.rstrip"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.bart.hub_interface.BARTHubInterface.generate", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.encode_line", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "def", "fill_mask", "(", "\n", "self", ",", "\n", "masked_inputs", ":", "List", "[", "str", "]", ",", "\n", "topk", ":", "int", "=", "5", ",", "\n", "match_source_len", ":", "bool", "=", "True", ",", "\n", "**", "generate_kwargs", "\n", ")", ":", "\n", "        ", "masked_token", "=", "'<mask>'", "\n", "batch_tokens", "=", "[", "]", "\n", "for", "masked_input", "in", "masked_inputs", ":", "\n", "            ", "assert", "masked_token", "in", "masked_input", ",", "\"please add one {} token for the input\"", ".", "format", "(", "masked_token", ")", "\n", "\n", "text_spans", "=", "masked_input", ".", "split", "(", "masked_token", ")", "\n", "text_spans_bpe", "=", "(", "' {0} '", ".", "format", "(", "masked_token", ")", ")", ".", "join", "(", "\n", "[", "self", ".", "bpe", ".", "encode", "(", "text_span", ".", "rstrip", "(", ")", ")", "for", "text_span", "in", "text_spans", "]", "\n", ")", ".", "strip", "(", ")", "\n", "tokens", "=", "self", ".", "task", ".", "source_dictionary", ".", "encode_line", "(", "\n", "'<s> '", "+", "text_spans_bpe", "+", "' </s>'", ",", "\n", "append_eos", "=", "False", ",", "\n", "add_if_not_exist", "=", "False", ",", "\n", ")", ".", "long", "(", ")", "\n", "batch_tokens", ".", "append", "(", "tokens", ")", "\n", "\n", "# ensure beam size is at least as big as topk", "\n", "", "generate_kwargs", "[", "'beam'", "]", "=", "max", "(", "\n", "topk", ",", "\n", "generate_kwargs", ".", "get", "(", "'beam'", ",", "-", "1", ")", ",", "\n", ")", "\n", "generate_kwargs", "[", "'match_source_len'", "]", "=", "match_source_len", "\n", "batch_hypos", "=", "self", ".", "generate", "(", "batch_tokens", ",", "**", "generate_kwargs", ")", "\n", "\n", "return", "[", "\n", "[", "(", "self", ".", "decode", "(", "hypo", "[", "'tokens'", "]", ")", ",", "hypo", "[", "'score'", "]", ")", "for", "hypo", "in", "hypos", "[", ":", "topk", "]", "]", "\n", "for", "hypos", "in", "batch_hypos", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.model.BARTModel.hub_models": [[30, 38], ["None"], "methods", ["None"], ["@", "classmethod", "\n", "def", "hub_models", "(", "cls", ")", ":", "\n", "        ", "return", "{", "\n", "\"bart.base\"", ":", "\"http://dl.fbaipublicfiles.com/fairseq/models/bart.base.tar.gz\"", ",", "\n", "\"bart.large\"", ":", "\"http://dl.fbaipublicfiles.com/fairseq/models/bart.large.tar.gz\"", ",", "\n", "\"bart.large.mnli\"", ":", "\"http://dl.fbaipublicfiles.com/fairseq/models/bart.large.mnli.tar.gz\"", ",", "\n", "\"bart.large.cnn\"", ":", "\"http://dl.fbaipublicfiles.com/fairseq/models/bart.large.cnn.tar.gz\"", ",", "\n", "\"bart.large.xsum\"", ":", "\"http://dl.fbaipublicfiles.com/fairseq/models/bart.large.xsum.tar.gz\"", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.model.BARTModel.__init__": [[40, 49], ["fairseq.models.transformer.TransformerModel.__init__", "model.BARTModel.apply", "torch.ModuleDict", "torch.ModuleDict", "hasattr", "model.BARTModel.encoder.dictionary.eos"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "def", "__init__", "(", "self", ",", "args", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "encoder", ",", "decoder", ")", "\n", "\n", "# We follow BERT's random weight initialization", "\n", "self", ".", "apply", "(", "init_bert_params", ")", "\n", "\n", "self", ".", "classification_heads", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "if", "hasattr", "(", "self", ".", "encoder", ",", "\"dictionary\"", ")", ":", "\n", "            ", "self", ".", "eos", ":", "int", "=", "self", ".", "encoder", ".", "dictionary", ".", "eos", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.model.BARTModel.add_args": [[50, 68], ["super().add_args", "parser.add_argument", "parser.add_argument", "parser.add_argument", "fairseq.utils.get_available_activation_fns"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_available_activation_fns"], ["", "", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "super", "(", "BARTModel", ",", "BARTModel", ")", ".", "add_args", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pooler-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability in the masked_lm pooler layers\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pooler-activation-fn\"", ",", "\n", "choices", "=", "utils", ".", "get_available_activation_fns", "(", ")", ",", "\n", "help", "=", "\"activation function to use for pooler layer\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--spectral-norm-classification-head\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Apply spectral normalization on the classification head\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.model.BARTModel.supported_targets": [[70, 73], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supported_targets", "(", "self", ")", ":", "\n", "        ", "return", "{", "\"self\"", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.model.BARTModel.forward": [[74, 115], ["model.BARTModel.encoder", "model.BARTModel.decoder", "model.BARTModel.classification_heads.items", "x[].view", "head.size", "head.size", "head", "src_tokens.eq"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "src_tokens", ",", "\n", "src_lengths", ",", "\n", "prev_output_tokens", ",", "\n", "features_only", ":", "bool", "=", "False", ",", "\n", "classification_head_name", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "token_embeddings", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "return_all_hiddens", ":", "bool", "=", "True", ",", "\n", "alignment_layer", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "alignment_heads", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "classification_head_name", "is", "not", "None", ":", "\n", "            ", "features_only", "=", "True", "\n", "\n", "", "encoder_out", "=", "self", ".", "encoder", "(", "\n", "src_tokens", ",", "\n", "src_lengths", "=", "src_lengths", ",", "\n", "token_embeddings", "=", "token_embeddings", ",", "\n", "return_all_hiddens", "=", "return_all_hiddens", "\n", ")", "\n", "x", ",", "extra", "=", "self", ".", "decoder", "(", "\n", "prev_output_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", "features_only", "=", "features_only", ",", "\n", "alignment_layer", "=", "alignment_layer", ",", "\n", "alignment_heads", "=", "alignment_heads", ",", "\n", "src_lengths", "=", "src_lengths", ",", "\n", "return_all_hiddens", "=", "return_all_hiddens", ",", "\n", ")", "\n", "eos", ":", "int", "=", "self", ".", "eos", "\n", "if", "classification_head_name", "is", "not", "None", ":", "\n", "            ", "sentence_representation", "=", "x", "[", "\n", "src_tokens", ".", "eq", "(", "eos", ")", ",", ":", "\n", "]", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "for", "k", ",", "head", "in", "self", ".", "classification_heads", ".", "items", "(", ")", ":", "\n", "# for torch script only supports iteration", "\n", "                ", "if", "k", "==", "classification_head_name", ":", "\n", "                    ", "x", "=", "head", "(", "sentence_representation", ")", "\n", "break", "\n", "", "", "", "return", "x", ",", "extra", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.model.BARTModel.from_pretrained": [[116, 139], ["hub_utils.from_pretrained", "hub_interface.BARTHubInterface", "cls.hub_models"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model_xlmr.XLMRModel.from_pretrained", "home.repos.pwc.inspect_result.reneeye_const.roberta.model_xlmr.XLMRModel.hub_models"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "\n", "cls", ",", "\n", "model_name_or_path", ",", "\n", "checkpoint_file", "=", "\"model.pt\"", ",", "\n", "data_name_or_path", "=", "\".\"", ",", "\n", "bpe", "=", "\"gpt2\"", ",", "\n", "sample_break_mode", "=", "\"eos\"", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "from", "fairseq", "import", "hub_utils", "\n", "\n", "x", "=", "hub_utils", ".", "from_pretrained", "(", "\n", "model_name_or_path", ",", "\n", "checkpoint_file", ",", "\n", "data_name_or_path", ",", "\n", "archive_map", "=", "cls", ".", "hub_models", "(", ")", ",", "\n", "bpe", "=", "bpe", ",", "\n", "load_checkpoint_heads", "=", "True", ",", "\n", "sample_break_mode", "=", "sample_break_mode", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "return", "BARTHubInterface", "(", "x", "[", "\"args\"", "]", ",", "x", "[", "\"task\"", "]", ",", "x", "[", "\"models\"", "]", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.model.BARTModel.register_classification_head": [[140, 163], ["logger.info", "model.BARTClassificationHead", "logger.warning", "getattr"], "methods", ["None"], ["", "def", "register_classification_head", "(", "\n", "self", ",", "name", ",", "num_classes", "=", "None", ",", "inner_dim", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Register a classification head.\"\"\"", "\n", "logger", ".", "info", "(", "\"Registering classification head: {0}\"", ".", "format", "(", "name", ")", ")", "\n", "if", "name", "in", "self", ".", "classification_heads", ":", "\n", "            ", "prev_num_classes", "=", "self", ".", "classification_heads", "[", "name", "]", ".", "out_proj", ".", "out_features", "\n", "prev_inner_dim", "=", "self", ".", "classification_heads", "[", "name", "]", ".", "dense", ".", "out_features", "\n", "if", "num_classes", "!=", "prev_num_classes", "or", "inner_dim", "!=", "prev_inner_dim", ":", "\n", "                ", "logger", ".", "warning", "(", "\n", "'re-registering head \"{}\" with num_classes {} (prev: {}) '", "\n", "\"and inner_dim {} (prev: {})\"", ".", "format", "(", "\n", "name", ",", "num_classes", ",", "prev_num_classes", ",", "inner_dim", ",", "prev_inner_dim", "\n", ")", "\n", ")", "\n", "", "", "self", ".", "classification_heads", "[", "name", "]", "=", "BARTClassificationHead", "(", "\n", "input_dim", "=", "self", ".", "args", ".", "encoder_embed_dim", ",", "\n", "inner_dim", "=", "inner_dim", "or", "self", ".", "args", ".", "encoder_embed_dim", ",", "\n", "num_classes", "=", "num_classes", ",", "\n", "activation_fn", "=", "self", ".", "args", ".", "pooler_activation_fn", ",", "\n", "pooler_dropout", "=", "self", ".", "args", ".", "pooler_dropout", ",", "\n", "do_spectral_norm", "=", "getattr", "(", "\n", "self", ".", "args", ",", "\"spectral_norm_classification_head\"", ",", "False", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.model.BARTModel.upgrade_state_dict_named": [[166, 282], ["super().upgrade_state_dict_named", "state_dict.keys", "state_dict[].size", "hasattr", "model.BARTModel.classification_heads.keys", "state_dict[].size", "state_dict[].size", "getattr", "model.BARTModel.upgrade_state_dict_named.truncate_emb"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.upgrade_state_dict_named", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "super", "(", ")", ".", "upgrade_state_dict_named", "(", "state_dict", ",", "name", ")", "\n", "\n", "prefix", "=", "name", "+", "\".\"", "if", "name", "!=", "\"\"", "else", "\"\"", "\n", "current_head_names", "=", "(", "\n", "[", "]", "\n", "if", "not", "hasattr", "(", "self", ",", "\"classification_heads\"", ")", "\n", "else", "self", ".", "classification_heads", ".", "keys", "(", ")", "\n", ")", "\n", "\n", "# Handle new classification heads present in the state dict.", "\n", "keys_to_delete", "=", "[", "]", "\n", "for", "k", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "if", "not", "k", ".", "startswith", "(", "prefix", "+", "\"classification_heads.\"", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "head_name", "=", "k", "[", "len", "(", "prefix", "+", "\"classification_heads.\"", ")", ":", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", "\n", "num_classes", "=", "state_dict", "[", "\n", "prefix", "+", "\"classification_heads.\"", "+", "head_name", "+", "\".out_proj.weight\"", "\n", "]", ".", "size", "(", "0", ")", "\n", "inner_dim", "=", "state_dict", "[", "\n", "prefix", "+", "\"classification_heads.\"", "+", "head_name", "+", "\".dense.weight\"", "\n", "]", ".", "size", "(", "0", ")", "\n", "\n", "if", "getattr", "(", "self", ".", "args", ",", "\"load_checkpoint_heads\"", ",", "False", ")", ":", "\n", "                ", "if", "head_name", "not", "in", "current_head_names", ":", "\n", "                    ", "self", ".", "register_classification_head", "(", "head_name", ",", "num_classes", ",", "inner_dim", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "head_name", "not", "in", "current_head_names", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "\"deleting classification head ({}) from checkpoint \"", "\n", "\"not present in current model: {}\"", ".", "format", "(", "head_name", ",", "k", ")", "\n", ")", "\n", "keys_to_delete", ".", "append", "(", "k", ")", "\n", "", "elif", "(", "\n", "num_classes", "\n", "!=", "self", ".", "classification_heads", "[", "head_name", "]", ".", "out_proj", ".", "out_features", "\n", "or", "inner_dim", "\n", "!=", "self", ".", "classification_heads", "[", "head_name", "]", ".", "dense", ".", "out_features", "\n", ")", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "\"deleting classification head ({}) from checkpoint \"", "\n", "\"with different dimensions than current model: {}\"", ".", "format", "(", "\n", "head_name", ",", "k", "\n", ")", "\n", ")", "\n", "keys_to_delete", ".", "append", "(", "k", ")", "\n", "", "", "", "for", "k", "in", "keys_to_delete", ":", "\n", "            ", "del", "state_dict", "[", "k", "]", "\n", "\n", "", "def", "truncate_emb", "(", "key", ")", ":", "\n", "            ", "if", "key", "in", "state_dict", ":", "\n", "                ", "state_dict", "[", "key", "]", "=", "state_dict", "[", "key", "]", "[", ":", "-", "1", ",", ":", "]", "\n", "\n", "# When finetuning on translation task, remove last row of", "\n", "# embedding matrix that corresponds to mask_idx token.", "\n", "", "", "loaded_dict_size", "=", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", ".", "size", "(", "0", ")", "\n", "if", "(", "\n", "loaded_dict_size", "==", "len", "(", "self", ".", "encoder", ".", "dictionary", ")", "+", "1", "\n", "and", "\"<mask>\"", "not", "in", "self", ".", "encoder", ".", "dictionary", "\n", ")", ":", "\n", "            ", "truncate_emb", "(", "\"encoder.embed_tokens.weight\"", ")", "\n", "truncate_emb", "(", "\"decoder.embed_tokens.weight\"", ")", "\n", "truncate_emb", "(", "\"encoder.output_projection.weight\"", ")", "\n", "truncate_emb", "(", "\"decoder.output_projection.weight\"", ")", "\n", "\n", "# When continued pretraining on new set of languages for mbart,", "\n", "# add extra lang embeddings at the end of embed_tokens.", "\n", "# Note: newly added languages are assumed to have been added at the end.", "\n", "", "if", "self", ".", "args", ".", "task", "==", "\"multilingual_denoising\"", "and", "loaded_dict_size", "<", "len", "(", "\n", "self", ".", "encoder", ".", "dictionary", "\n", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Adding extra language embeddings not found in pretrained model for \"", "\n", "\"continued pretraining of MBART on new set of languages.\"", "\n", ")", "\n", "loaded_mask_token_embedding", "=", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", "[", "\n", "-", "1", ",", ":", "\n", "]", "\n", "\n", "num_langids_to_add", "=", "len", "(", "self", ".", "encoder", ".", "dictionary", ")", "-", "loaded_dict_size", "\n", "embed_dim", "=", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", ".", "size", "(", "1", ")", "\n", "\n", "new_lang_embed_to_add", "=", "torch", ".", "zeros", "(", "num_langids_to_add", ",", "embed_dim", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "new_lang_embed_to_add", ",", "mean", "=", "0", ",", "std", "=", "embed_dim", "**", "-", "0.5", ")", "\n", "new_lang_embed_to_add", "=", "new_lang_embed_to_add", ".", "to", "(", "\n", "dtype", "=", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", ".", "dtype", ",", "\n", ")", "\n", "\n", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", "[", "\n", ":", "loaded_dict_size", "-", "1", ",", ":", "\n", "]", ",", "\n", "new_lang_embed_to_add", ",", "\n", "loaded_mask_token_embedding", ".", "unsqueeze", "(", "0", ")", ",", "\n", "]", "\n", ")", "\n", "state_dict", "[", "\"decoder.embed_tokens.weight\"", "]", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "state_dict", "[", "\"decoder.embed_tokens.weight\"", "]", "[", "\n", ":", "loaded_dict_size", "-", "1", ",", ":", "\n", "]", ",", "\n", "new_lang_embed_to_add", ",", "\n", "loaded_mask_token_embedding", ".", "unsqueeze", "(", "0", ")", ",", "\n", "]", "\n", ")", "\n", "\n", "# Copy any newly-added classification heads into the state dict", "\n", "# with their current weights.", "\n", "", "if", "hasattr", "(", "self", ",", "\"classification_heads\"", ")", ":", "\n", "            ", "cur_state", "=", "self", ".", "classification_heads", ".", "state_dict", "(", ")", "\n", "for", "k", ",", "v", "in", "cur_state", ".", "items", "(", ")", ":", "\n", "                ", "if", "prefix", "+", "\"classification_heads.\"", "+", "k", "not", "in", "state_dict", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Overwriting\"", ",", "prefix", "+", "\"classification_heads.\"", "+", "k", ")", "\n", "state_dict", "[", "prefix", "+", "\"classification_heads.\"", "+", "k", "]", "=", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.model.BARTClassificationHead.__init__": [[287, 304], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "fairseq.utils.get_activation_fn", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.nn.utils.spectral_norm", "torch.nn.utils.spectral_norm", "torch.nn.utils.spectral_norm", "torch.nn.utils.spectral_norm"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["def", "__init__", "(", "\n", "self", ",", "\n", "input_dim", ",", "\n", "inner_dim", ",", "\n", "num_classes", ",", "\n", "activation_fn", ",", "\n", "pooler_dropout", ",", "\n", "do_spectral_norm", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "input_dim", ",", "inner_dim", ")", "\n", "self", ".", "activation_fn", "=", "utils", ".", "get_activation_fn", "(", "activation_fn", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "pooler_dropout", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "inner_dim", ",", "num_classes", ")", "\n", "\n", "if", "do_spectral_norm", ":", "\n", "            ", "self", ".", "out_proj", "=", "torch", ".", "nn", ".", "utils", ".", "spectral_norm", "(", "self", ".", "out_proj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.model.BARTClassificationHead.forward": [[305, 313], ["model.BARTClassificationHead.dropout", "model.BARTClassificationHead.dense", "model.BARTClassificationHead.activation_fn", "model.BARTClassificationHead.dropout", "model.BARTClassificationHead.out_proj"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "features", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "self", ".", "activation_fn", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.model.bart_large_architecture": [[315, 356], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "", "@", "register_model_architecture", "(", "\"bart\"", ",", "\"bart_large\"", ")", "\n", "def", "bart_large_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_path", "=", "getattr", "(", "args", ",", "\"encoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "1024", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "4", "*", "1024", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "12", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "16", ")", "\n", "args", ".", "encoder_normalize_before", "=", "getattr", "(", "args", ",", "\"encoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "encoder_learned_pos", "=", "getattr", "(", "args", ",", "\"encoder_learned_pos\"", ",", "True", ")", "\n", "args", ".", "decoder_embed_path", "=", "getattr", "(", "args", ",", "\"decoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "args", ".", "encoder_embed_dim", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "args", ".", "encoder_ffn_embed_dim", "\n", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "12", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "16", ")", "\n", "args", ".", "decoder_normalize_before", "=", "getattr", "(", "args", ",", "\"decoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "decoder_learned_pos", "=", "getattr", "(", "args", ",", "\"decoder_learned_pos\"", ",", "True", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.0", ")", "\n", "args", ".", "relu_dropout", "=", "getattr", "(", "args", ",", "\"relu_dropout\"", ",", "0.0", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "max_target_positions", "=", "getattr", "(", "args", ",", "\"max_target_positions\"", ",", "1024", ")", "\n", "args", ".", "max_source_positions", "=", "getattr", "(", "args", ",", "\"max_source_positions\"", ",", "1024", ")", "\n", "args", ".", "adaptive_softmax_cutoff", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_cutoff\"", ",", "None", ")", "\n", "args", ".", "adaptive_softmax_dropout", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_dropout\"", ",", "0", ")", "\n", "args", ".", "share_decoder_input_output_embed", "=", "getattr", "(", "\n", "args", ",", "\"share_decoder_input_output_embed\"", ",", "True", "\n", ")", "\n", "args", ".", "share_all_embeddings", "=", "getattr", "(", "args", ",", "\"share_all_embeddings\"", ",", "True", ")", "\n", "\n", "args", ".", "decoder_output_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_output_dim\"", ",", "args", ".", "decoder_embed_dim", "\n", ")", "\n", "args", ".", "decoder_input_dim", "=", "getattr", "(", "args", ",", "\"decoder_input_dim\"", ",", "args", ".", "decoder_embed_dim", ")", "\n", "\n", "args", ".", "no_scale_embedding", "=", "getattr", "(", "args", ",", "\"no_scale_embedding\"", ",", "True", ")", "\n", "args", ".", "layernorm_embedding", "=", "getattr", "(", "args", ",", "\"layernorm_embedding\"", ",", "True", ")", "\n", "\n", "args", ".", "activation_fn", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"gelu\"", ")", "\n", "args", ".", "pooler_activation_fn", "=", "getattr", "(", "args", ",", "\"pooler_activation_fn\"", ",", "\"tanh\"", ")", "\n", "args", ".", "pooler_dropout", "=", "getattr", "(", "args", ",", "\"pooler_dropout\"", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.model.bart_base_architecture": [[358, 367], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "model.bart_large_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.bart.model.bart_large_architecture"], ["", "@", "register_model_architecture", "(", "\"bart\"", ",", "\"bart_base\"", ")", "\n", "def", "bart_base_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "768", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "4", "*", "768", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "6", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "12", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "6", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "12", ")", "\n", "bart_large_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.model.mbart_large_architecture": [[369, 373], ["fairseq.models.register_model_architecture", "getattr", "model.bart_large_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.bart.model.bart_large_architecture"], ["", "@", "register_model_architecture", "(", "\"bart\"", ",", "\"mbart_large\"", ")", "\n", "def", "mbart_large_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "no_scale_embedding", "=", "getattr", "(", "args", ",", "\"no_scale_embedding\"", ",", "False", ")", "\n", "bart_large_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.model.mbart_base_architecture": [[375, 379], ["fairseq.models.register_model_architecture", "getattr", "model.bart_base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.bart.model.bart_base_architecture"], ["", "@", "register_model_architecture", "(", "\"bart\"", ",", "\"mbart_base\"", ")", "\n", "def", "mbart_base_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "no_scale_embedding", "=", "getattr", "(", "args", ",", "\"no_scale_embedding\"", ",", "False", ")", "\n", "bart_base_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.bart.model.mbart_base_wmt20_architecture": [[381, 385], ["fairseq.models.register_model_architecture", "getattr", "model.mbart_base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.bart.model.mbart_base_architecture"], ["", "@", "register_model_architecture", "(", "\"bart\"", ",", "\"mbart_base_wmt20\"", ")", "\n", "def", "mbart_base_wmt20_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "layernorm_embedding", "=", "getattr", "(", "args", ",", "\"layernorm_embedding\"", ",", "False", ")", "\n", "mbart_base_architecture", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerModel.allow_length_beam": [[45, 48], ["None"], "methods", ["None"], ["    ", "@", "property", "\n", "def", "allow_length_beam", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerModel.add_args": [[49, 73], ["fairseq.models.nat.FairseqNATModel.add_args", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "FairseqNATModel", ".", "add_args", "(", "parser", ")", "\n", "\n", "# length prediction", "\n", "parser", ".", "add_argument", "(", "\n", "\"--src-embedding-copy\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"copy encoder word embeddings as the initial input of the decoder\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pred-length-offset\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"predicting the length difference between the target and source sentences\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--sg-length-pred\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"stop the gradients back-propagated from the length predictor\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--length-loss-factor\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"weights on the length prediction loss\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerModel.build_decoder": [[75, 81], ["nonautoregressive_transformer.NATransformerDecoder", "getattr", "NATransformerDecoder.apply"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_decoder", "(", "cls", ",", "args", ",", "tgt_dict", ",", "embed_tokens", ")", ":", "\n", "        ", "decoder", "=", "NATransformerDecoder", "(", "args", ",", "tgt_dict", ",", "embed_tokens", ")", "\n", "if", "getattr", "(", "args", ",", "\"apply_bert_init\"", ",", "False", ")", ":", "\n", "            ", "decoder", ".", "apply", "(", "init_bert_params", ")", "\n", "", "return", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerModel.forward": [[82, 115], ["nonautoregressive_transformer.NATransformerModel.encoder", "nonautoregressive_transformer.NATransformerModel.decoder.forward_length", "nonautoregressive_transformer.NATransformerModel.decoder.forward_length_prediction", "nonautoregressive_transformer.NATransformerModel.decoder", "tgt_tokens.ne"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerDecoder.forward_length", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerDecoder.forward_length_prediction", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward", "(", "\n", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "tgt_tokens", ",", "**", "kwargs", "\n", ")", ":", "\n", "# encoding", "\n", "        ", "encoder_out", "=", "self", ".", "encoder", "(", "src_tokens", ",", "src_lengths", "=", "src_lengths", ",", "**", "kwargs", ")", "\n", "\n", "# length prediction", "\n", "length_out", "=", "self", ".", "decoder", ".", "forward_length", "(", "\n", "normalize", "=", "False", ",", "encoder_out", "=", "encoder_out", "\n", ")", "\n", "length_tgt", "=", "self", ".", "decoder", ".", "forward_length_prediction", "(", "\n", "length_out", ",", "encoder_out", ",", "tgt_tokens", "\n", ")", "\n", "\n", "# decoding", "\n", "word_ins_out", "=", "self", ".", "decoder", "(", "\n", "normalize", "=", "False", ",", "\n", "prev_output_tokens", "=", "prev_output_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", ")", "\n", "\n", "return", "{", "\n", "\"word_ins\"", ":", "{", "\n", "\"out\"", ":", "word_ins_out", ",", "\n", "\"tgt\"", ":", "tgt_tokens", ",", "\n", "\"mask\"", ":", "tgt_tokens", ".", "ne", "(", "self", ".", "pad", ")", ",", "\n", "\"ls\"", ":", "self", ".", "args", ".", "label_smoothing", ",", "\n", "\"nll_loss\"", ":", "True", ",", "\n", "}", ",", "\n", "\"length\"", ":", "{", "\n", "\"out\"", ":", "length_out", ",", "\n", "\"tgt\"", ":", "length_tgt", ",", "\n", "\"factor\"", ":", "self", ".", "decoder", ".", "length_loss_factor", ",", "\n", "}", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerModel.forward_decoder": [[118, 143], ["output_tokens.ne", "nonautoregressive_transformer.NATransformerModel.decoder().max", "output_tokens.masked_scatter_", "output_scores.masked_scatter_", "decoder_out._replace", "history.append", "nonautoregressive_transformer.NATransformerModel.decoder", "output_tokens.clone"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward_decoder", "(", "self", ",", "decoder_out", ",", "encoder_out", ",", "decoding_format", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "step", "=", "decoder_out", ".", "step", "\n", "output_tokens", "=", "decoder_out", ".", "output_tokens", "\n", "output_scores", "=", "decoder_out", ".", "output_scores", "\n", "history", "=", "decoder_out", ".", "history", "\n", "\n", "# execute the decoder", "\n", "output_masks", "=", "output_tokens", ".", "ne", "(", "self", ".", "pad", ")", "\n", "_scores", ",", "_tokens", "=", "self", ".", "decoder", "(", "\n", "normalize", "=", "True", ",", "\n", "prev_output_tokens", "=", "output_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", "step", "=", "step", ",", "\n", ")", ".", "max", "(", "-", "1", ")", "\n", "\n", "output_tokens", ".", "masked_scatter_", "(", "output_masks", ",", "_tokens", "[", "output_masks", "]", ")", "\n", "output_scores", ".", "masked_scatter_", "(", "output_masks", ",", "_scores", "[", "output_masks", "]", ")", "\n", "if", "history", "is", "not", "None", ":", "\n", "            ", "history", ".", "append", "(", "output_tokens", ".", "clone", "(", ")", ")", "\n", "\n", "", "return", "decoder_out", ".", "_replace", "(", "\n", "output_tokens", "=", "output_tokens", ",", "\n", "output_scores", "=", "output_scores", ",", "\n", "attn", "=", "None", ",", "\n", "history", "=", "history", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerModel.initialize_output_tokens": [[145, 175], ["nonautoregressive_transformer.NATransformerModel.decoder.forward_length_prediction", "nonautoregressive_transformer.NATransformerModel.clamp_().max", "fairseq.utils.new_arange", "src_tokens.new_zeros().fill_", "src_tokens.new_zeros().fill_.masked_fill_", "src_tokens.new_zeros().fill_.scatter_", "src_tokens.new_zeros().fill_.new_zeros().type_as", "fairseq.iterative_refinement_generator.DecoderOut", "nonautoregressive_transformer.NATransformerModel.decoder.forward_length", "nonautoregressive_transformer.NATransformerModel.clamp_", "src_tokens.new_zeros", "src_tokens.new_zeros().fill_.new_zeros", "src_tokens.size", "src_tokens.new_zeros().fill_.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerDecoder.forward_length_prediction", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.new_arange", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerDecoder.forward_length", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "initialize_output_tokens", "(", "self", ",", "encoder_out", ",", "src_tokens", ")", ":", "\n", "# length prediction", "\n", "        ", "length_tgt", "=", "self", ".", "decoder", ".", "forward_length_prediction", "(", "\n", "self", ".", "decoder", ".", "forward_length", "(", "normalize", "=", "True", ",", "encoder_out", "=", "encoder_out", ")", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", ")", "\n", "\n", "max_length", "=", "length_tgt", ".", "clamp_", "(", "min", "=", "2", ")", ".", "max", "(", ")", "\n", "idx_length", "=", "utils", ".", "new_arange", "(", "src_tokens", ",", "max_length", ")", "\n", "\n", "initial_output_tokens", "=", "src_tokens", ".", "new_zeros", "(", "\n", "src_tokens", ".", "size", "(", "0", ")", ",", "max_length", "\n", ")", ".", "fill_", "(", "self", ".", "pad", ")", "\n", "initial_output_tokens", ".", "masked_fill_", "(", "\n", "idx_length", "[", "None", ",", ":", "]", "<", "length_tgt", "[", ":", ",", "None", "]", ",", "self", ".", "unk", "\n", ")", "\n", "initial_output_tokens", "[", ":", ",", "0", "]", "=", "self", ".", "bos", "\n", "initial_output_tokens", ".", "scatter_", "(", "1", ",", "length_tgt", "[", ":", ",", "None", "]", "-", "1", ",", "self", ".", "eos", ")", "\n", "\n", "initial_output_scores", "=", "initial_output_tokens", ".", "new_zeros", "(", "\n", "*", "initial_output_tokens", ".", "size", "(", ")", "\n", ")", ".", "type_as", "(", "encoder_out", "[", "\"encoder_out\"", "]", "[", "0", "]", ")", "\n", "\n", "return", "DecoderOut", "(", "\n", "output_tokens", "=", "initial_output_tokens", ",", "\n", "output_scores", "=", "initial_output_scores", ",", "\n", "attn", "=", "None", ",", "\n", "step", "=", "0", ",", "\n", "max_step", "=", "0", ",", "\n", "history", "=", "None", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerModel.regenerate_length_beam": [[177, 204], ["output_tokens.ne().sum", "length_tgt.view().clamp_.view().clamp_.view().clamp_", "length_tgt.view().clamp_.view().clamp_.max", "fairseq.utils.new_arange", "output_tokens.new_zeros().fill_", "output_tokens.new_zeros().fill_.masked_fill_", "output_tokens.new_zeros().fill_.scatter_", "output_tokens.new_zeros().fill_.new_zeros().type_as", "decoder_out._replace", "output_tokens.ne", "fairseq.utils.new_arange", "length_tgt.view().clamp_.view().clamp_.view", "output_tokens.new_zeros", "output_tokens.new_zeros().fill_.new_zeros", "length_tgt.view().clamp_.view().clamp_.size", "output_tokens.new_zeros().fill_.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.new_arange", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.new_arange", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "regenerate_length_beam", "(", "self", ",", "decoder_out", ",", "beam_size", ")", ":", "\n", "        ", "output_tokens", "=", "decoder_out", ".", "output_tokens", "\n", "length_tgt", "=", "output_tokens", ".", "ne", "(", "self", ".", "pad", ")", ".", "sum", "(", "1", ")", "\n", "length_tgt", "=", "(", "\n", "length_tgt", "[", ":", ",", "None", "]", "\n", "+", "utils", ".", "new_arange", "(", "length_tgt", ",", "1", ",", "beam_size", ")", "\n", "-", "beam_size", "//", "2", "\n", ")", "\n", "length_tgt", "=", "length_tgt", ".", "view", "(", "-", "1", ")", ".", "clamp_", "(", "min", "=", "2", ")", "\n", "max_length", "=", "length_tgt", ".", "max", "(", ")", "\n", "idx_length", "=", "utils", ".", "new_arange", "(", "length_tgt", ",", "max_length", ")", "\n", "\n", "initial_output_tokens", "=", "output_tokens", ".", "new_zeros", "(", "\n", "length_tgt", ".", "size", "(", "0", ")", ",", "max_length", "\n", ")", ".", "fill_", "(", "self", ".", "pad", ")", "\n", "initial_output_tokens", ".", "masked_fill_", "(", "\n", "idx_length", "[", "None", ",", ":", "]", "<", "length_tgt", "[", ":", ",", "None", "]", ",", "self", ".", "unk", "\n", ")", "\n", "initial_output_tokens", "[", ":", ",", "0", "]", "=", "self", ".", "bos", "\n", "initial_output_tokens", ".", "scatter_", "(", "1", ",", "length_tgt", "[", ":", ",", "None", "]", "-", "1", ",", "self", ".", "eos", ")", "\n", "\n", "initial_output_scores", "=", "initial_output_tokens", ".", "new_zeros", "(", "\n", "*", "initial_output_tokens", ".", "size", "(", ")", "\n", ")", ".", "type_as", "(", "decoder_out", ".", "output_scores", ")", "\n", "\n", "return", "decoder_out", ".", "_replace", "(", "\n", "output_tokens", "=", "initial_output_tokens", ",", "output_scores", "=", "initial_output_scores", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerDecoder.__init__": [[208, 223], ["fairseq.models.nat.FairseqNATDecoder.__init__", "dictionary.bos", "dictionary.unk", "dictionary.eos", "getattr", "getattr", "getattr", "getattr", "fairseq.models.transformer.Embedding"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "dictionary", ",", "embed_tokens", ",", "no_encoder_attn", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "args", ",", "dictionary", ",", "embed_tokens", ",", "no_encoder_attn", "=", "no_encoder_attn", "\n", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "self", ".", "bos", "=", "dictionary", ".", "bos", "(", ")", "\n", "self", ".", "unk", "=", "dictionary", ".", "unk", "(", ")", "\n", "self", ".", "eos", "=", "dictionary", ".", "eos", "(", ")", "\n", "\n", "self", ".", "encoder_embed_dim", "=", "args", ".", "encoder_embed_dim", "\n", "self", ".", "sg_length_pred", "=", "getattr", "(", "args", ",", "\"sg_length_pred\"", ",", "False", ")", "\n", "self", ".", "pred_length_offset", "=", "getattr", "(", "args", ",", "\"pred_length_offset\"", ",", "False", ")", "\n", "self", ".", "length_loss_factor", "=", "getattr", "(", "args", ",", "\"length_loss_factor\"", ",", "0.1", ")", "\n", "self", ".", "src_embedding_copy", "=", "getattr", "(", "args", ",", "\"src_embedding_copy\"", ",", "False", ")", "\n", "self", ".", "embed_length", "=", "Embedding", "(", "256", ",", "self", ".", "encoder_embed_dim", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerDecoder.forward": [[224, 233], ["nonautoregressive_transformer.NATransformerDecoder.extract_features", "nonautoregressive_transformer.NATransformerDecoder.output_layer", "torch.log_softmax", "torch.log_softmax"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.output_layer", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax"], ["", "@", "ensemble_decoder", "\n", "def", "forward", "(", "self", ",", "normalize", ",", "encoder_out", ",", "prev_output_tokens", ",", "step", "=", "0", ",", "**", "unused", ")", ":", "\n", "        ", "features", ",", "_", "=", "self", ".", "extract_features", "(", "\n", "prev_output_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", "embedding_copy", "=", "(", "step", "==", "0", ")", "&", "self", ".", "src_embedding_copy", ",", "\n", ")", "\n", "decoder_out", "=", "self", ".", "output_layer", "(", "features", ")", "\n", "return", "F", ".", "log_softmax", "(", "decoder_out", ",", "-", "1", ")", "if", "normalize", "else", "decoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerDecoder.forward_length": [[234, 246], ["nonautoregressive_transformer._mean_pooling", "torch.linear", "torch.linear", "len", "enc_feats.detach.detach.detach", "torch.log_softmax", "torch.log_softmax"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer._mean_pooling", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax"], ["", "@", "ensemble_decoder", "\n", "def", "forward_length", "(", "self", ",", "normalize", ",", "encoder_out", ")", ":", "\n", "        ", "enc_feats", "=", "encoder_out", "[", "\"encoder_out\"", "]", "[", "0", "]", "# T x B x C", "\n", "if", "len", "(", "encoder_out", "[", "\"encoder_padding_mask\"", "]", ")", ">", "0", ":", "\n", "            ", "src_masks", "=", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "[", "0", "]", "# B x T", "\n", "", "else", ":", "\n", "            ", "src_masks", "=", "None", "\n", "", "enc_feats", "=", "_mean_pooling", "(", "enc_feats", ",", "src_masks", ")", "\n", "if", "self", ".", "sg_length_pred", ":", "\n", "            ", "enc_feats", "=", "enc_feats", ".", "detach", "(", ")", "\n", "", "length_out", "=", "F", ".", "linear", "(", "enc_feats", ",", "self", ".", "embed_length", ".", "weight", ")", "\n", "return", "F", ".", "log_softmax", "(", "length_out", ",", "-", "1", ")", "if", "normalize", "else", "length_out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerDecoder.extract_features": [[247, 330], ["nonautoregressive_transformer.NATransformerDecoder.transpose", "enumerate", "nonautoregressive_transformer.NATransformerDecoder.transpose", "nonautoregressive_transformer.NATransformerDecoder.forward_embedding", "nonautoregressive_transformer.NATransformerDecoder.forward_embedding", "layer", "inner_states.append", "nonautoregressive_transformer.NATransformerDecoder.layer_norm", "nonautoregressive_transformer.NATransformerDecoder.project_out_dim", "len", "prev_output_tokens.new_ones().bool", "nonautoregressive_transformer.NATransformerDecoder.forward_copying_source", "prev_output_tokens.ne", "prev_output_tokens.new_ones", "len", "len", "src_embd.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerDecoder.forward_embedding", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerDecoder.forward_embedding", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerDecoder.forward_copying_source", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "extract_features", "(", "\n", "self", ",", "\n", "prev_output_tokens", ",", "\n", "encoder_out", "=", "None", ",", "\n", "early_exit", "=", "None", ",", "\n", "embedding_copy", "=", "False", ",", "\n", "**", "unused", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Similar to *forward* but only return features.\n\n        Inputs:\n            prev_output_tokens: Tensor(B, T)\n            encoder_out: a dictionary of hidden states and masks\n\n        Returns:\n            tuple:\n                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\n                - a dictionary with any model-specific outputs\n            the LevenshteinTransformer decoder has full-attention to all generated tokens\n        \"\"\"", "\n", "# embedding", "\n", "if", "embedding_copy", ":", "\n", "            ", "src_embd", "=", "encoder_out", "[", "\"encoder_embedding\"", "]", "[", "0", "]", "\n", "if", "len", "(", "encoder_out", "[", "\"encoder_padding_mask\"", "]", ")", ">", "0", ":", "\n", "                ", "src_mask", "=", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "src_mask", "=", "None", "\n", "", "src_mask", "=", "(", "\n", "~", "src_mask", "\n", "if", "src_mask", "is", "not", "None", "\n", "else", "prev_output_tokens", ".", "new_ones", "(", "*", "src_embd", ".", "size", "(", ")", "[", ":", "2", "]", ")", ".", "bool", "(", ")", "\n", ")", "\n", "\n", "x", ",", "decoder_padding_mask", "=", "self", ".", "forward_embedding", "(", "\n", "prev_output_tokens", ",", "\n", "self", ".", "forward_copying_source", "(", "\n", "src_embd", ",", "src_mask", ",", "prev_output_tokens", ".", "ne", "(", "self", ".", "padding_idx", ")", "\n", ")", ",", "\n", ")", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "x", ",", "decoder_padding_mask", "=", "self", ".", "forward_embedding", "(", "prev_output_tokens", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "attn", "=", "None", "\n", "inner_states", "=", "[", "x", "]", "\n", "\n", "# decoder layers", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "\n", "# early exit from the decoder.", "\n", "            ", "if", "(", "early_exit", "is", "not", "None", ")", "and", "(", "i", ">=", "early_exit", ")", ":", "\n", "                ", "break", "\n", "\n", "", "x", ",", "attn", ",", "_", "=", "layer", "(", "\n", "x", ",", "\n", "encoder_out", "[", "\"encoder_out\"", "]", "[", "0", "]", "\n", "if", "(", "encoder_out", "is", "not", "None", "and", "len", "(", "encoder_out", "[", "\"encoder_out\"", "]", ")", ">", "0", ")", "\n", "else", "None", ",", "\n", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "[", "0", "]", "\n", "if", "(", "\n", "encoder_out", "is", "not", "None", "\n", "and", "len", "(", "encoder_out", "[", "\"encoder_padding_mask\"", "]", ")", ">", "0", "\n", ")", "\n", "else", "None", ",", "\n", "self_attn_mask", "=", "None", ",", "\n", "self_attn_padding_mask", "=", "decoder_padding_mask", ",", "\n", ")", "\n", "inner_states", ".", "append", "(", "x", ")", "\n", "\n", "", "if", "self", ".", "layer_norm", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "if", "self", ".", "project_out_dim", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "project_out_dim", "(", "x", ")", "\n", "\n", "", "return", "x", ",", "{", "\"attn\"", ":", "attn", ",", "\"inner_states\"", ":", "inner_states", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerDecoder.forward_embedding": [[331, 352], ["nonautoregressive_transformer.NATransformerDecoder.dropout_module", "prev_output_tokens.eq", "nonautoregressive_transformer.NATransformerDecoder.embed_positions", "nonautoregressive_transformer.NATransformerDecoder.embed_tokens", "nonautoregressive_transformer.NATransformerDecoder.project_in_dim"], "methods", ["None"], ["", "def", "forward_embedding", "(", "self", ",", "prev_output_tokens", ",", "states", "=", "None", ")", ":", "\n", "# embed positions", "\n", "        ", "positions", "=", "(", "\n", "self", ".", "embed_positions", "(", "prev_output_tokens", ")", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "\n", "# embed tokens and positions", "\n", "if", "states", "is", "None", ":", "\n", "            ", "x", "=", "self", ".", "embed_scale", "*", "self", ".", "embed_tokens", "(", "prev_output_tokens", ")", "\n", "if", "self", ".", "project_in_dim", "is", "not", "None", ":", "\n", "                ", "x", "=", "self", ".", "project_in_dim", "(", "x", ")", "\n", "", "", "else", ":", "\n", "            ", "x", "=", "states", "\n", "\n", "", "if", "positions", "is", "not", "None", ":", "\n", "            ", "x", "+=", "positions", "\n", "", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "decoder_padding_mask", "=", "prev_output_tokens", ".", "eq", "(", "self", ".", "padding_idx", ")", "\n", "return", "x", ",", "decoder_padding_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerDecoder.forward_copying_source": [[353, 367], ["src_masks.sum", "tgt_masks.sum", "_uniform_assignment().masked_fill", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "_uniform_assignment().masked_fill.unsqueeze().expand", "nonautoregressive_transformer._uniform_assignment", "src_embeds.size", "_uniform_assignment().masked_fill.unsqueeze", "_uniform_assignment().masked_fill.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer._uniform_assignment", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "forward_copying_source", "(", "self", ",", "src_embeds", ",", "src_masks", ",", "tgt_masks", ")", ":", "\n", "        ", "length_sources", "=", "src_masks", ".", "sum", "(", "1", ")", "\n", "length_targets", "=", "tgt_masks", ".", "sum", "(", "1", ")", "\n", "mapped_inputs", "=", "_uniform_assignment", "(", "length_sources", ",", "length_targets", ")", ".", "masked_fill", "(", "\n", "~", "tgt_masks", ",", "0", "\n", ")", "\n", "copied_embedding", "=", "torch", ".", "gather", "(", "\n", "src_embeds", ",", "\n", "1", ",", "\n", "mapped_inputs", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "\n", "*", "mapped_inputs", ".", "size", "(", ")", ",", "src_embeds", ".", "size", "(", "-", "1", ")", "\n", ")", ",", "\n", ")", "\n", "return", "copied_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerDecoder.forward_length_prediction": [[368, 402], ["len", "enc_feats.new_ones().fill_.long", "tgt_tokens.ne().sum().long", "length_tgt.clamp.clamp.clamp", "enc_feats.new_ones().fill_", "length_out.max", "enc_feats.size", "tgt_tokens.ne().sum", "enc_feats.new_ones", "enc_feats.size", "tgt_tokens.ne"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "forward_length_prediction", "(", "self", ",", "length_out", ",", "encoder_out", ",", "tgt_tokens", "=", "None", ")", ":", "\n", "        ", "enc_feats", "=", "encoder_out", "[", "\"encoder_out\"", "]", "[", "0", "]", "# T x B x C", "\n", "if", "len", "(", "encoder_out", "[", "\"encoder_padding_mask\"", "]", ")", ">", "0", ":", "\n", "            ", "src_masks", "=", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "[", "0", "]", "# B x T", "\n", "", "else", ":", "\n", "            ", "src_masks", "=", "None", "\n", "", "if", "self", ".", "pred_length_offset", ":", "\n", "            ", "if", "src_masks", "is", "None", ":", "\n", "                ", "src_lengs", "=", "enc_feats", ".", "new_ones", "(", "enc_feats", ".", "size", "(", "1", ")", ")", ".", "fill_", "(", "\n", "enc_feats", ".", "size", "(", "0", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "src_lengs", "=", "(", "~", "src_masks", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "type_as", "(", "enc_feats", ")", ".", "sum", "(", "0", ")", "\n", "", "src_lengs", "=", "src_lengs", ".", "long", "(", ")", "\n", "\n", "", "if", "tgt_tokens", "is", "not", "None", ":", "\n", "# obtain the length target", "\n", "            ", "tgt_lengs", "=", "tgt_tokens", ".", "ne", "(", "self", ".", "padding_idx", ")", ".", "sum", "(", "1", ")", ".", "long", "(", ")", "\n", "if", "self", ".", "pred_length_offset", ":", "\n", "                ", "length_tgt", "=", "tgt_lengs", "-", "src_lengs", "+", "128", "\n", "", "else", ":", "\n", "                ", "length_tgt", "=", "tgt_lengs", "\n", "", "length_tgt", "=", "length_tgt", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "255", ")", "\n", "\n", "", "else", ":", "\n", "# predict the length target (greedy for now)", "\n", "# TODO: implementing length-beam", "\n", "            ", "pred_lengs", "=", "length_out", ".", "max", "(", "-", "1", ")", "[", "1", "]", "\n", "if", "self", ".", "pred_length_offset", ":", "\n", "                ", "length_tgt", "=", "pred_lengs", "-", "128", "+", "src_lengs", "\n", "", "else", ":", "\n", "                ", "length_tgt", "=", "pred_lengs", "\n", "\n", "", "", "return", "length_tgt", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer._mean_pooling": [[16, 27], ["enc_feats.mean.mean", "src_masks.sum"], "function", ["None"], ["def", "_mean_pooling", "(", "enc_feats", ",", "src_masks", ")", ":", "\n", "# enc_feats: T x B x C", "\n", "# src_masks: B x T or None", "\n", "    ", "if", "src_masks", "is", "None", ":", "\n", "        ", "enc_feats", "=", "enc_feats", ".", "mean", "(", "0", ")", "\n", "", "else", ":", "\n", "        ", "src_masks", "=", "(", "~", "src_masks", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "type_as", "(", "enc_feats", ")", "\n", "enc_feats", "=", "(", "\n", "(", "enc_feats", "/", "src_masks", ".", "sum", "(", "0", ")", "[", "None", ",", ":", ",", "None", "]", ")", "*", "src_masks", "[", ":", ",", ":", ",", "None", "]", "\n", ")", ".", "sum", "(", "0", ")", "\n", "", "return", "enc_feats", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer._argmax": [[29, 31], ["x.max"], "function", ["None"], ["", "def", "_argmax", "(", "x", ",", "dim", ")", ":", "\n", "    ", "return", "(", "x", "==", "x", ".", "max", "(", "dim", ",", "keepdim", "=", "True", ")", "[", "0", "]", ")", ".", "type_as", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer._uniform_assignment": [[33, 41], ["trg_lens.max", "fairseq.utils.new_arange().float", "torch.round().long().detach", "torch.round().long().detach", "src_lens.float", "trg_lens.float", "fairseq.utils.new_arange", "torch.round().long", "torch.round().long", "torch.round", "torch.round"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.new_arange"], ["", "def", "_uniform_assignment", "(", "src_lens", ",", "trg_lens", ")", ":", "\n", "    ", "max_trg_len", "=", "trg_lens", ".", "max", "(", ")", "\n", "steps", "=", "(", "src_lens", ".", "float", "(", ")", "-", "1", ")", "/", "(", "trg_lens", ".", "float", "(", ")", "-", "1", ")", "# step-size", "\n", "# max_trg_len", "\n", "index_t", "=", "utils", ".", "new_arange", "(", "trg_lens", ",", "max_trg_len", ")", ".", "float", "(", ")", "\n", "index_t", "=", "steps", "[", ":", ",", "None", "]", "*", "index_t", "[", "None", ",", ":", "]", "# batch_size X max_trg_len", "\n", "index_t", "=", "torch", ".", "round", "(", "index_t", ")", ".", "long", "(", ")", ".", "detach", "(", ")", "\n", "return", "index_t", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.base_architecture": [[404, 450], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "", "@", "register_model_architecture", "(", "\n", "\"nonautoregressive_transformer\"", ",", "\"nonautoregressive_transformer\"", "\n", ")", "\n", "def", "base_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_path", "=", "getattr", "(", "args", ",", "\"encoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "2048", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "6", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "encoder_normalize_before", "=", "getattr", "(", "args", ",", "\"encoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "encoder_learned_pos", "=", "getattr", "(", "args", ",", "\"encoder_learned_pos\"", ",", "False", ")", "\n", "args", ".", "decoder_embed_path", "=", "getattr", "(", "args", ",", "\"decoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "args", ".", "encoder_embed_dim", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "args", ".", "encoder_ffn_embed_dim", "\n", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "6", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "decoder_normalize_before", "=", "getattr", "(", "args", ",", "\"decoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "decoder_learned_pos", "=", "getattr", "(", "args", ",", "\"decoder_learned_pos\"", ",", "False", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.0", ")", "\n", "args", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "0.0", ")", "\n", "args", ".", "activation_fn", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"relu\"", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "adaptive_softmax_cutoff", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_cutoff\"", ",", "None", ")", "\n", "args", ".", "adaptive_softmax_dropout", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_dropout\"", ",", "0", ")", "\n", "args", ".", "share_decoder_input_output_embed", "=", "getattr", "(", "\n", "args", ",", "\"share_decoder_input_output_embed\"", ",", "False", "\n", ")", "\n", "args", ".", "share_all_embeddings", "=", "getattr", "(", "args", ",", "\"share_all_embeddings\"", ",", "False", ")", "\n", "args", ".", "no_token_positional_embeddings", "=", "getattr", "(", "\n", "args", ",", "\"no_token_positional_embeddings\"", ",", "False", "\n", ")", "\n", "args", ".", "adaptive_input", "=", "getattr", "(", "args", ",", "\"adaptive_input\"", ",", "False", ")", "\n", "args", ".", "apply_bert_init", "=", "getattr", "(", "args", ",", "\"apply_bert_init\"", ",", "False", ")", "\n", "\n", "args", ".", "decoder_output_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_output_dim\"", ",", "args", ".", "decoder_embed_dim", "\n", ")", "\n", "args", ".", "decoder_input_dim", "=", "getattr", "(", "args", ",", "\"decoder_input_dim\"", ",", "args", ".", "decoder_embed_dim", ")", "\n", "\n", "# --- special arguments ---", "\n", "args", ".", "sg_length_pred", "=", "getattr", "(", "args", ",", "\"sg_length_pred\"", ",", "False", ")", "\n", "args", ".", "pred_length_offset", "=", "getattr", "(", "args", ",", "\"pred_length_offset\"", ",", "False", ")", "\n", "args", ".", "length_loss_factor", "=", "getattr", "(", "args", ",", "\"length_loss_factor\"", ",", "0.1", ")", "\n", "args", ".", "src_embedding_copy", "=", "getattr", "(", "args", ",", "\"src_embedding_copy\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.nonautoregressive_transformer_wmt_en_de": [[452, 457], ["fairseq.models.register_model_architecture", "nonautoregressive_transformer.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "@", "register_model_architecture", "(", "\n", "\"nonautoregressive_transformer\"", ",", "\"nonautoregressive_transformer_wmt_en_de\"", "\n", ")", "\n", "def", "nonautoregressive_transformer_wmt_en_de", "(", "args", ")", ":", "\n", "    ", "base_architecture", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.nat.nat_crf_transformer.NACRFTransformerModel.__init__": [[14, 20], ["fairseq.models.nat.NATransformerModel.__init__", "fairseq.modules.DynamicCRF", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "encoder", ",", "decoder", ")", "\n", "self", ".", "crf_layer", "=", "DynamicCRF", "(", "\n", "num_embedding", "=", "len", "(", "self", ".", "tgt_dict", ")", ",", "\n", "low_rank", "=", "args", ".", "crf_lowrank_approx", ",", "\n", "beam_size", "=", "args", ".", "crf_beam_approx", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nat_crf_transformer.NACRFTransformerModel.allow_ensemble": [[22, 25], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "allow_ensemble", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nat_crf_transformer.NACRFTransformerModel.add_args": [[26, 43], ["fairseq.models.nat.NATransformerModel.add_args", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "NATransformerModel", ".", "add_args", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--crf-lowrank-approx\"", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"the dimension of low-rank approximation of transition\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--crf-beam-approx\"", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"the beam size for apporixmating the normalizing factor\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--word-ins-loss-factor\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"weights on NAT loss used to co-training with CRF loss.\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nat_crf_transformer.NACRFTransformerModel.forward": [[45, 85], ["nat_crf_transformer.NACRFTransformerModel.encoder", "nat_crf_transformer.NACRFTransformerModel.decoder.forward_length", "nat_crf_transformer.NACRFTransformerModel.decoder.forward_length_prediction", "nat_crf_transformer.NACRFTransformerModel.decoder", "tgt_tokens.ne", "nat_crf_transformer.NACRFTransformerModel.crf_layer", "word_ins_mask.type_as().sum", "word_ins_mask.type_as"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerDecoder.forward_length", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerDecoder.forward_length_prediction", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward", "(", "\n", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "tgt_tokens", ",", "**", "kwargs", "\n", ")", ":", "\n", "# encoding", "\n", "        ", "encoder_out", "=", "self", ".", "encoder", "(", "src_tokens", ",", "src_lengths", "=", "src_lengths", ",", "**", "kwargs", ")", "\n", "\n", "# length prediction", "\n", "length_out", "=", "self", ".", "decoder", ".", "forward_length", "(", "\n", "normalize", "=", "False", ",", "encoder_out", "=", "encoder_out", "\n", ")", "\n", "length_tgt", "=", "self", ".", "decoder", ".", "forward_length_prediction", "(", "\n", "length_out", ",", "encoder_out", ",", "tgt_tokens", "\n", ")", "\n", "\n", "# decoding", "\n", "word_ins_out", "=", "self", ".", "decoder", "(", "\n", "normalize", "=", "False", ",", "\n", "prev_output_tokens", "=", "prev_output_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", ")", "\n", "word_ins_tgt", ",", "word_ins_mask", "=", "tgt_tokens", ",", "tgt_tokens", ".", "ne", "(", "self", ".", "pad", ")", "\n", "\n", "# compute the log-likelihood of CRF", "\n", "crf_nll", "=", "-", "self", ".", "crf_layer", "(", "word_ins_out", ",", "word_ins_tgt", ",", "word_ins_mask", ")", "\n", "crf_nll", "=", "(", "crf_nll", "/", "word_ins_mask", ".", "type_as", "(", "crf_nll", ")", ".", "sum", "(", "-", "1", ")", ")", ".", "mean", "(", ")", "\n", "\n", "return", "{", "\n", "\"word_ins\"", ":", "{", "\n", "\"out\"", ":", "word_ins_out", ",", "\n", "\"tgt\"", ":", "word_ins_tgt", ",", "\n", "\"mask\"", ":", "word_ins_mask", ",", "\n", "\"ls\"", ":", "self", ".", "args", ".", "label_smoothing", ",", "\n", "\"nll_loss\"", ":", "True", ",", "\n", "\"factor\"", ":", "self", ".", "args", ".", "word_ins_loss_factor", ",", "\n", "}", ",", "\n", "\"word_crf\"", ":", "{", "\"loss\"", ":", "crf_nll", "}", ",", "\n", "\"length\"", ":", "{", "\n", "\"out\"", ":", "length_out", ",", "\n", "\"tgt\"", ":", "length_tgt", ",", "\n", "\"factor\"", ":", "self", ".", "decoder", ".", "length_loss_factor", ",", "\n", "}", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nat_crf_transformer.NACRFTransformerModel.forward_decoder": [[88, 111], ["output_tokens.ne", "nat_crf_transformer.NACRFTransformerModel.decoder", "nat_crf_transformer.NACRFTransformerModel.crf_layer.forward_decoder", "output_tokens.masked_scatter_", "output_scores.masked_scatter_", "decoder_out._replace", "history.append", "output_tokens.clone"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_decoder"], ["", "def", "forward_decoder", "(", "self", ",", "decoder_out", ",", "encoder_out", ",", "decoding_format", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "output_tokens", "=", "decoder_out", ".", "output_tokens", "\n", "output_scores", "=", "decoder_out", ".", "output_scores", "\n", "history", "=", "decoder_out", ".", "history", "\n", "\n", "# execute the decoder and get emission scores", "\n", "output_masks", "=", "output_tokens", ".", "ne", "(", "self", ".", "pad", ")", "\n", "word_ins_out", "=", "self", ".", "decoder", "(", "\n", "normalize", "=", "False", ",", "prev_output_tokens", "=", "output_tokens", ",", "encoder_out", "=", "encoder_out", "\n", ")", "\n", "\n", "# run viterbi decoding through CRF", "\n", "_scores", ",", "_tokens", "=", "self", ".", "crf_layer", ".", "forward_decoder", "(", "word_ins_out", ",", "output_masks", ")", "\n", "output_tokens", ".", "masked_scatter_", "(", "output_masks", ",", "_tokens", "[", "output_masks", "]", ")", "\n", "output_scores", ".", "masked_scatter_", "(", "output_masks", ",", "_scores", "[", "output_masks", "]", ")", "\n", "if", "history", "is", "not", "None", ":", "\n", "            ", "history", ".", "append", "(", "output_tokens", ".", "clone", "(", ")", ")", "\n", "\n", "", "return", "decoder_out", ".", "_replace", "(", "\n", "output_tokens", "=", "output_tokens", ",", "\n", "output_scores", "=", "output_scores", ",", "\n", "attn", "=", "None", ",", "\n", "history", "=", "history", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nat_crf_transformer.nacrf_base_architecture": [[114, 122], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "fairseq.models.nat.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "", "@", "register_model_architecture", "(", "\"nacrf_transformer\"", ",", "\"nacrf_transformer\"", ")", "\n", "def", "nacrf_base_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "crf_lowrank_approx", "=", "getattr", "(", "args", ",", "\"crf_lowrank_approx\"", ",", "32", ")", "\n", "args", ".", "crf_beam_approx", "=", "getattr", "(", "args", ",", "\"crf_beam_approx\"", ",", "64", ")", "\n", "args", ".", "word_ins_loss_factor", "=", "getattr", "(", "args", ",", "\"word_ins_loss_factor\"", ",", "0.5", ")", "\n", "args", ".", "encoder_normalize_before", "=", "getattr", "(", "args", ",", "\"encoder_normalize_before\"", ",", "True", ")", "\n", "args", ".", "decoder_normalize_before", "=", "getattr", "(", "args", ",", "\"decoder_normalize_before\"", ",", "True", ")", "\n", "base_architecture", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_transformer.LevenshteinTransformerModel.allow_length_beam": [[29, 32], ["None"], "methods", ["None"], ["    ", "@", "property", "\n", "def", "allow_length_beam", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_transformer.LevenshteinTransformerModel.add_args": [[33, 61], ["fairseq.models.nat.FairseqNATModel.add_args", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "FairseqNATModel", ".", "add_args", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--early-exit\"", ",", "\n", "default", "=", "\"6,6,6\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"number of decoder layers before word_del, mask_ins, word_ins\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no-share-discriminator\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"separate parameters for discriminator\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no-share-maskpredictor\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"separate parameters for mask-predictor\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--share-discriminator-maskpredictor\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"share the parameters for both mask-predictor and discriminator\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--sampling-for-deletion\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"instead of argmax, use sampling to predict the tokens\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_transformer.LevenshteinTransformerModel.build_decoder": [[63, 69], ["levenshtein_transformer.LevenshteinTransformerDecoder", "getattr", "LevenshteinTransformerDecoder.apply"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_decoder", "(", "cls", ",", "args", ",", "tgt_dict", ",", "embed_tokens", ")", ":", "\n", "        ", "decoder", "=", "LevenshteinTransformerDecoder", "(", "args", ",", "tgt_dict", ",", "embed_tokens", ")", "\n", "if", "getattr", "(", "args", ",", "\"apply_bert_init\"", ",", "False", ")", ":", "\n", "            ", "decoder", ".", "apply", "(", "init_bert_params", ")", "\n", "", "return", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_transformer.LevenshteinTransformerModel.forward": [[70, 136], ["levenshtein_transformer.LevenshteinTransformerModel.encoder", "levenshtein_utils._get_ins_targets", "mask_ins_targets.clamp.clamp.clamp", "prev_output_tokens[].ne", "levenshtein_transformer.LevenshteinTransformerModel.decoder.forward_mask_ins", "levenshtein_transformer.LevenshteinTransformerModel.decoder.forward_word_ins", "torch.multinomial().view.masked_scatter_", "torch.multinomial().view.masked_scatter_", "torch.multinomial().view.masked_scatter_", "levenshtein_utils._get_del_targets", "levenshtein_transformer.LevenshteinTransformerModel.decoder.forward_word_del", "torch.multinomial().view.ne", "torch.multinomial().view.ne", "torch.multinomial().view.ne", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "word_ins_out.size", "torch.log_softmax().max", "torch.log_softmax().max", "torch.log_softmax().max", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.softmax().view", "torch.softmax().view", "torch.softmax().view", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "word_ins_out.size", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._get_ins_targets", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_mask_ins", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_word_ins", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._get_del_targets", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_word_del", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax"], ["", "def", "forward", "(", "\n", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "tgt_tokens", ",", "**", "kwargs", "\n", ")", ":", "\n", "\n", "        ", "assert", "tgt_tokens", "is", "not", "None", ",", "\"forward function only supports training.\"", "\n", "\n", "# encoding", "\n", "encoder_out", "=", "self", ".", "encoder", "(", "src_tokens", ",", "src_lengths", "=", "src_lengths", ",", "**", "kwargs", ")", "\n", "\n", "# generate training labels for insertion", "\n", "masked_tgt_masks", ",", "masked_tgt_tokens", ",", "mask_ins_targets", "=", "_get_ins_targets", "(", "\n", "prev_output_tokens", ",", "tgt_tokens", ",", "self", ".", "pad", ",", "self", ".", "unk", "\n", ")", "\n", "mask_ins_targets", "=", "mask_ins_targets", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "255", ")", "# for safe prediction", "\n", "mask_ins_masks", "=", "prev_output_tokens", "[", ":", ",", "1", ":", "]", ".", "ne", "(", "self", ".", "pad", ")", "\n", "\n", "mask_ins_out", ",", "_", "=", "self", ".", "decoder", ".", "forward_mask_ins", "(", "\n", "normalize", "=", "False", ",", "\n", "prev_output_tokens", "=", "prev_output_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", ")", "\n", "word_ins_out", ",", "_", "=", "self", ".", "decoder", ".", "forward_word_ins", "(", "\n", "normalize", "=", "False", ",", "\n", "prev_output_tokens", "=", "masked_tgt_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", ")", "\n", "\n", "# make online prediction", "\n", "if", "self", ".", "decoder", ".", "sampling_for_deletion", ":", "\n", "            ", "word_predictions", "=", "torch", ".", "multinomial", "(", "\n", "F", ".", "softmax", "(", "word_ins_out", ",", "-", "1", ")", ".", "view", "(", "-", "1", ",", "word_ins_out", ".", "size", "(", "-", "1", ")", ")", ",", "1", "\n", ")", ".", "view", "(", "word_ins_out", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "word_predictions", "=", "F", ".", "log_softmax", "(", "word_ins_out", ",", "dim", "=", "-", "1", ")", ".", "max", "(", "2", ")", "[", "1", "]", "\n", "\n", "", "word_predictions", ".", "masked_scatter_", "(", "\n", "~", "masked_tgt_masks", ",", "tgt_tokens", "[", "~", "masked_tgt_masks", "]", "\n", ")", "\n", "\n", "# generate training labels for deletion", "\n", "word_del_targets", "=", "_get_del_targets", "(", "word_predictions", ",", "tgt_tokens", ",", "self", ".", "pad", ")", "\n", "word_del_out", ",", "_", "=", "self", ".", "decoder", ".", "forward_word_del", "(", "\n", "normalize", "=", "False", ",", "\n", "prev_output_tokens", "=", "word_predictions", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", ")", "\n", "word_del_masks", "=", "word_predictions", ".", "ne", "(", "self", ".", "pad", ")", "\n", "\n", "return", "{", "\n", "\"mask_ins\"", ":", "{", "\n", "\"out\"", ":", "mask_ins_out", ",", "\n", "\"tgt\"", ":", "mask_ins_targets", ",", "\n", "\"mask\"", ":", "mask_ins_masks", ",", "\n", "\"ls\"", ":", "0.01", ",", "\n", "}", ",", "\n", "\"word_ins\"", ":", "{", "\n", "\"out\"", ":", "word_ins_out", ",", "\n", "\"tgt\"", ":", "tgt_tokens", ",", "\n", "\"mask\"", ":", "masked_tgt_masks", ",", "\n", "\"ls\"", ":", "self", ".", "args", ".", "label_smoothing", ",", "\n", "\"nll_loss\"", ":", "True", ",", "\n", "}", ",", "\n", "\"word_del\"", ":", "{", "\n", "\"out\"", ":", "word_del_out", ",", "\n", "\"tgt\"", ":", "word_del_targets", ",", "\n", "\"mask\"", ":", "word_del_masks", ",", "\n", "}", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_transformer.LevenshteinTransformerModel.forward_decoder": [[139, 250], ["levenshtein_utils._fill.size", "levenshtein_utils._fill.ne().sum().max", "decoder_out._replace", "torch.zeros_like().fill_", "torch.zeros_like().fill_", "torch.zeros_like().fill_", "torch.zeros_like().fill_", "torch.zeros_like().fill_", "torch.zeros_like().fill_", "torch.zeros_like().fill_", "torch.zeros_like().fill_", "torch.zeros_like().fill_", "levenshtein_utils._fill.ne().sum", "can_del_word.sum", "levenshtein_transformer.LevenshteinTransformerModel.decoder.forward_word_del", "[].bool", "levenshtein_utils._apply_del_words", "levenshtein_utils._fill", "levenshtein_utils._fill", "levenshtein_utils._fill", "levenshtein_utils._fill.ne().sum", "can_ins_mask.sum", "levenshtein_transformer.LevenshteinTransformerModel.decoder.forward_mask_ins", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "levenshtein_utils._apply_ins_masks", "levenshtein_utils._fill", "levenshtein_utils._fill", "levenshtein_utils._fill.eq().sum", "can_ins_word.sum", "levenshtein_transformer.LevenshteinTransformerModel.decoder.forward_word_ins", "word_ins_score.max", "levenshtein_utils._apply_ins_words", "levenshtein_utils._fill", "levenshtein_utils._fill", "levenshtein_utils._fill", "encoder_out.encoder_out.size", "encoder_out.encoder_out.new().fill_", "history.append", "mask_ins_score.max", "max_lens[].expand_as", "history.append", "history.append", "levenshtein_utils._fill.ne().sum", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "levenshtein_utils._fill.ne", "levenshtein_utils._skip", "levenshtein_utils._skip_encoder_out", "levenshtein_utils._fill.clone", "levenshtein_utils._fill.ne", "levenshtein_utils._skip", "levenshtein_utils._skip_encoder_out", "levenshtein_utils._fill.clone", "levenshtein_utils._fill.eq", "levenshtein_utils._skip", "levenshtein_utils._skip_encoder_out", "levenshtein_utils._fill.clone", "encoder_out.encoder_out.new", "word_del_score.max", "levenshtein_utils._fill.ne"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_word_del", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._apply_del_words", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._fill", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._fill", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._fill", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_mask_ins", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._apply_ins_masks", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._fill", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._fill", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_word_ins", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._apply_ins_words", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._fill", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._fill", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._fill", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._skip", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._skip_encoder_out", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._skip", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._skip_encoder_out", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._skip", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._skip_encoder_out"], ["", "def", "forward_decoder", "(", "\n", "self", ",", "decoder_out", ",", "encoder_out", ",", "eos_penalty", "=", "0.0", ",", "max_ratio", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "\n", "        ", "output_tokens", "=", "decoder_out", ".", "output_tokens", "\n", "output_scores", "=", "decoder_out", ".", "output_scores", "\n", "attn", "=", "decoder_out", ".", "attn", "\n", "history", "=", "decoder_out", ".", "history", "\n", "\n", "bsz", "=", "output_tokens", ".", "size", "(", "0", ")", "\n", "if", "max_ratio", "is", "None", ":", "\n", "            ", "max_lens", "=", "torch", ".", "zeros_like", "(", "output_tokens", ")", ".", "fill_", "(", "255", ")", "\n", "", "else", ":", "\n", "            ", "if", "encoder_out", ".", "encoder_padding_mask", "is", "None", ":", "\n", "                ", "max_src_len", "=", "encoder_out", ".", "encoder_out", ".", "size", "(", "0", ")", "\n", "src_lens", "=", "encoder_out", ".", "encoder_out", ".", "new", "(", "bsz", ")", ".", "fill_", "(", "max_src_len", ")", "\n", "", "else", ":", "\n", "                ", "src_lens", "=", "(", "~", "encoder_out", ".", "encoder_padding_mask", ")", ".", "sum", "(", "1", ")", "\n", "", "max_lens", "=", "(", "src_lens", "*", "max_ratio", ")", ".", "clamp", "(", "min", "=", "10", ")", ".", "long", "(", ")", "\n", "\n", "# delete words", "\n", "# do not delete tokens if it is <s> </s>", "\n", "", "can_del_word", "=", "output_tokens", ".", "ne", "(", "self", ".", "pad", ")", ".", "sum", "(", "1", ")", ">", "2", "\n", "if", "can_del_word", ".", "sum", "(", ")", "!=", "0", ":", "# we cannot delete, skip", "\n", "            ", "word_del_score", ",", "word_del_attn", "=", "self", ".", "decoder", ".", "forward_word_del", "(", "\n", "normalize", "=", "True", ",", "\n", "prev_output_tokens", "=", "_skip", "(", "output_tokens", ",", "can_del_word", ")", ",", "\n", "encoder_out", "=", "_skip_encoder_out", "(", "self", ".", "encoder", ",", "encoder_out", ",", "can_del_word", ")", ",", "\n", ")", "\n", "word_del_pred", "=", "word_del_score", ".", "max", "(", "-", "1", ")", "[", "1", "]", ".", "bool", "(", ")", "\n", "\n", "_tokens", ",", "_scores", ",", "_attn", "=", "_apply_del_words", "(", "\n", "output_tokens", "[", "can_del_word", "]", ",", "\n", "output_scores", "[", "can_del_word", "]", ",", "\n", "word_del_attn", ",", "\n", "word_del_pred", ",", "\n", "self", ".", "pad", ",", "\n", "self", ".", "bos", ",", "\n", "self", ".", "eos", ",", "\n", ")", "\n", "output_tokens", "=", "_fill", "(", "output_tokens", ",", "can_del_word", ",", "_tokens", ",", "self", ".", "pad", ")", "\n", "output_scores", "=", "_fill", "(", "output_scores", ",", "can_del_word", ",", "_scores", ",", "0", ")", "\n", "attn", "=", "_fill", "(", "attn", ",", "can_del_word", ",", "_attn", ",", "0.0", ")", "\n", "\n", "if", "history", "is", "not", "None", ":", "\n", "                ", "history", ".", "append", "(", "output_tokens", ".", "clone", "(", ")", ")", "\n", "\n", "# insert placeholders", "\n", "", "", "can_ins_mask", "=", "output_tokens", ".", "ne", "(", "self", ".", "pad", ")", ".", "sum", "(", "1", ")", "<", "max_lens", "\n", "if", "can_ins_mask", ".", "sum", "(", ")", "!=", "0", ":", "\n", "            ", "mask_ins_score", ",", "_", "=", "self", ".", "decoder", ".", "forward_mask_ins", "(", "\n", "normalize", "=", "True", ",", "\n", "prev_output_tokens", "=", "_skip", "(", "output_tokens", ",", "can_ins_mask", ")", ",", "\n", "encoder_out", "=", "_skip_encoder_out", "(", "self", ".", "encoder", ",", "encoder_out", ",", "can_ins_mask", ")", ",", "\n", ")", "\n", "if", "eos_penalty", ">", "0.0", ":", "\n", "                ", "mask_ins_score", "[", ":", ",", ":", ",", "0", "]", "=", "mask_ins_score", "[", ":", ",", ":", ",", "0", "]", "-", "eos_penalty", "\n", "", "mask_ins_pred", "=", "mask_ins_score", ".", "max", "(", "-", "1", ")", "[", "1", "]", "\n", "mask_ins_pred", "=", "torch", ".", "min", "(", "\n", "mask_ins_pred", ",", "max_lens", "[", "can_ins_mask", ",", "None", "]", ".", "expand_as", "(", "mask_ins_pred", ")", "\n", ")", "\n", "\n", "_tokens", ",", "_scores", "=", "_apply_ins_masks", "(", "\n", "output_tokens", "[", "can_ins_mask", "]", ",", "\n", "output_scores", "[", "can_ins_mask", "]", ",", "\n", "mask_ins_pred", ",", "\n", "self", ".", "pad", ",", "\n", "self", ".", "unk", ",", "\n", "self", ".", "eos", ",", "\n", ")", "\n", "output_tokens", "=", "_fill", "(", "output_tokens", ",", "can_ins_mask", ",", "_tokens", ",", "self", ".", "pad", ")", "\n", "output_scores", "=", "_fill", "(", "output_scores", ",", "can_ins_mask", ",", "_scores", ",", "0", ")", "\n", "\n", "if", "history", "is", "not", "None", ":", "\n", "                ", "history", ".", "append", "(", "output_tokens", ".", "clone", "(", ")", ")", "\n", "\n", "# insert words", "\n", "", "", "can_ins_word", "=", "output_tokens", ".", "eq", "(", "self", ".", "unk", ")", ".", "sum", "(", "1", ")", ">", "0", "\n", "if", "can_ins_word", ".", "sum", "(", ")", "!=", "0", ":", "\n", "            ", "word_ins_score", ",", "word_ins_attn", "=", "self", ".", "decoder", ".", "forward_word_ins", "(", "\n", "normalize", "=", "True", ",", "\n", "prev_output_tokens", "=", "_skip", "(", "output_tokens", ",", "can_ins_word", ")", ",", "\n", "encoder_out", "=", "_skip_encoder_out", "(", "self", ".", "encoder", ",", "encoder_out", ",", "can_ins_word", ")", ",", "\n", ")", "\n", "word_ins_score", ",", "word_ins_pred", "=", "word_ins_score", ".", "max", "(", "-", "1", ")", "\n", "_tokens", ",", "_scores", "=", "_apply_ins_words", "(", "\n", "output_tokens", "[", "can_ins_word", "]", ",", "\n", "output_scores", "[", "can_ins_word", "]", ",", "\n", "word_ins_pred", ",", "\n", "word_ins_score", ",", "\n", "self", ".", "unk", ",", "\n", ")", "\n", "\n", "output_tokens", "=", "_fill", "(", "output_tokens", ",", "can_ins_word", ",", "_tokens", ",", "self", ".", "pad", ")", "\n", "output_scores", "=", "_fill", "(", "output_scores", ",", "can_ins_word", ",", "_scores", ",", "0", ")", "\n", "attn", "=", "_fill", "(", "attn", ",", "can_ins_word", ",", "word_ins_attn", ",", "0.0", ")", "\n", "\n", "if", "history", "is", "not", "None", ":", "\n", "                ", "history", ".", "append", "(", "output_tokens", ".", "clone", "(", ")", ")", "\n", "\n", "# delete some unnecessary paddings", "\n", "", "", "cut_off", "=", "output_tokens", ".", "ne", "(", "self", ".", "pad", ")", ".", "sum", "(", "1", ")", ".", "max", "(", ")", "\n", "output_tokens", "=", "output_tokens", "[", ":", ",", ":", "cut_off", "]", "\n", "output_scores", "=", "output_scores", "[", ":", ",", ":", "cut_off", "]", "\n", "attn", "=", "None", "if", "attn", "is", "None", "else", "attn", "[", ":", ",", ":", "cut_off", ",", ":", "]", "\n", "\n", "return", "decoder_out", ".", "_replace", "(", "\n", "output_tokens", "=", "output_tokens", ",", "\n", "output_scores", "=", "output_scores", ",", "\n", "attn", "=", "attn", ",", "\n", "history", "=", "history", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_transformer.LevenshteinTransformerModel.initialize_output_tokens": [[252, 268], ["src_tokens.new_zeros", "src_tokens.new_zeros.new_zeros().type_as", "fairseq.iterative_refinement_generator.DecoderOut", "src_tokens.size", "src_tokens.new_zeros.new_zeros", "src_tokens.new_zeros.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "initialize_output_tokens", "(", "self", ",", "encoder_out", ",", "src_tokens", ")", ":", "\n", "        ", "initial_output_tokens", "=", "src_tokens", ".", "new_zeros", "(", "src_tokens", ".", "size", "(", "0", ")", ",", "2", ")", "\n", "initial_output_tokens", "[", ":", ",", "0", "]", "=", "self", ".", "bos", "\n", "initial_output_tokens", "[", ":", ",", "1", "]", "=", "self", ".", "eos", "\n", "\n", "initial_output_scores", "=", "initial_output_tokens", ".", "new_zeros", "(", "\n", "*", "initial_output_tokens", ".", "size", "(", ")", "\n", ")", ".", "type_as", "(", "encoder_out", "[", "\"encoder_out\"", "]", "[", "0", "]", ")", "\n", "\n", "return", "DecoderOut", "(", "\n", "output_tokens", "=", "initial_output_tokens", ",", "\n", "output_scores", "=", "initial_output_scores", ",", "\n", "attn", "=", "None", ",", "\n", "step", "=", "0", ",", "\n", "max_step", "=", "0", ",", "\n", "history", "=", "None", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_transformer.LevenshteinTransformerDecoder.__init__": [[272, 311], ["fairseq.models.nat.FairseqNATDecoder.__init__", "dictionary.bos", "dictionary.unk", "dictionary.eos", "getattr", "fairseq.models.transformer.Embedding", "fairseq.models.transformer.Embedding", "getattr", "getattr", "getattr", "int", "len", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "getattr", "args.early_exit.split", "fairseq.models.transformer.TransformerDecoderLayer", "fairseq.models.transformer.TransformerDecoderLayer", "range", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "dictionary", ",", "embed_tokens", ",", "no_encoder_attn", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "args", ",", "dictionary", ",", "embed_tokens", ",", "no_encoder_attn", "=", "no_encoder_attn", "\n", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "self", ".", "bos", "=", "dictionary", ".", "bos", "(", ")", "\n", "self", ".", "unk", "=", "dictionary", ".", "unk", "(", ")", "\n", "self", ".", "eos", "=", "dictionary", ".", "eos", "(", ")", "\n", "self", ".", "sampling_for_deletion", "=", "getattr", "(", "args", ",", "\"sampling_for_deletion\"", ",", "False", ")", "\n", "self", ".", "embed_mask_ins", "=", "Embedding", "(", "256", ",", "self", ".", "output_embed_dim", "*", "2", ",", "None", ")", "\n", "self", ".", "embed_word_del", "=", "Embedding", "(", "2", ",", "self", ".", "output_embed_dim", ",", "None", ")", "\n", "\n", "# del_word, ins_mask, ins_word", "\n", "self", ".", "early_exit", "=", "[", "int", "(", "i", ")", "for", "i", "in", "args", ".", "early_exit", ".", "split", "(", "\",\"", ")", "]", "\n", "assert", "len", "(", "self", ".", "early_exit", ")", "==", "3", "\n", "\n", "# copy layers for mask-predict/deletion", "\n", "self", ".", "layers_msk", "=", "None", "\n", "if", "getattr", "(", "args", ",", "\"no_share_maskpredictor\"", ",", "False", ")", ":", "\n", "            ", "self", ".", "layers_msk", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "TransformerDecoderLayer", "(", "args", ",", "no_encoder_attn", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "early_exit", "[", "1", "]", ")", "\n", "]", "\n", ")", "\n", "", "self", ".", "layers_del", "=", "None", "\n", "if", "getattr", "(", "args", ",", "\"no_share_discriminator\"", ",", "False", ")", ":", "\n", "            ", "self", ".", "layers_del", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "TransformerDecoderLayer", "(", "args", ",", "no_encoder_attn", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "early_exit", "[", "0", "]", ")", "\n", "]", "\n", ")", "\n", "\n", "", "if", "getattr", "(", "args", ",", "\"share_discriminator_maskpredictor\"", ",", "False", ")", ":", "\n", "            ", "assert", "getattr", "(", "\n", "args", ",", "\"no_share_discriminator\"", ",", "False", "\n", ")", ",", "\"must set saperate discriminator\"", "\n", "self", ".", "layers_msk", "=", "self", ".", "layers_del", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_transformer.LevenshteinTransformerDecoder.extract_features": [[312, 384], ["levenshtein_transformer.LevenshteinTransformerDecoder.dropout_module", "levenshtein_transformer.LevenshteinTransformerDecoder.transpose", "prev_output_tokens.eq", "enumerate", "levenshtein_transformer.LevenshteinTransformerDecoder.transpose", "levenshtein_transformer.LevenshteinTransformerDecoder.embed_positions", "levenshtein_transformer.LevenshteinTransformerDecoder.embed_tokens", "levenshtein_transformer.LevenshteinTransformerDecoder.project_in_dim", "len", "layer", "inner_states.append", "levenshtein_transformer.LevenshteinTransformerDecoder.layer_norm", "levenshtein_transformer.LevenshteinTransformerDecoder.project_out_dim", "len", "len"], "methods", ["None"], ["", "", "def", "extract_features", "(", "\n", "self", ",", "\n", "prev_output_tokens", ",", "\n", "encoder_out", "=", "None", ",", "\n", "early_exit", "=", "None", ",", "\n", "layers", "=", "None", ",", "\n", "**", "unused", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Similar to *forward* but only return features.\n        Inputs:\n            prev_output_tokens: Tensor(B, T)\n            encoder_out: a dictionary of hidden states and masks\n\n        Returns:\n            tuple:\n                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\n                - a dictionary with any model-specific outputs\n            the LevenshteinTransformer decoder has full-attention to all generated tokens\n        \"\"\"", "\n", "# embed positions", "\n", "positions", "=", "(", "\n", "self", ".", "embed_positions", "(", "prev_output_tokens", ")", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "\n", "# embed tokens and positions", "\n", "x", "=", "self", ".", "embed_scale", "*", "self", ".", "embed_tokens", "(", "prev_output_tokens", ")", "\n", "if", "self", ".", "project_in_dim", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "project_in_dim", "(", "x", ")", "\n", "\n", "", "if", "positions", "is", "not", "None", ":", "\n", "            ", "x", "+=", "positions", "\n", "", "x", "=", "self", ".", "dropout_module", "(", "x", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "attn", "=", "None", "\n", "inner_states", "=", "[", "x", "]", "\n", "\n", "# decoder layers", "\n", "decoder_padding_mask", "=", "prev_output_tokens", ".", "eq", "(", "self", ".", "padding_idx", ")", "\n", "layers", "=", "self", ".", "layers", "if", "layers", "is", "None", "else", "layers", "\n", "early_exit", "=", "len", "(", "layers", ")", "if", "early_exit", "is", "None", "else", "early_exit", "\n", "for", "_", ",", "layer", "in", "enumerate", "(", "layers", "[", ":", "early_exit", "]", ")", ":", "\n", "            ", "x", ",", "attn", ",", "_", "=", "layer", "(", "\n", "x", ",", "\n", "encoder_out", "[", "\"encoder_out\"", "]", "[", "0", "]", "\n", "if", "(", "encoder_out", "is", "not", "None", "and", "len", "(", "encoder_out", "[", "\"encoder_out\"", "]", ")", ">", "0", ")", "\n", "else", "None", ",", "\n", "encoder_out", "[", "\"encoder_padding_mask\"", "]", "[", "0", "]", "\n", "if", "(", "\n", "encoder_out", "is", "not", "None", "\n", "and", "len", "(", "encoder_out", "[", "\"encoder_padding_mask\"", "]", ")", ">", "0", "\n", ")", "\n", "else", "None", ",", "\n", "self_attn_mask", "=", "None", ",", "\n", "self_attn_padding_mask", "=", "decoder_padding_mask", ",", "\n", ")", "\n", "inner_states", ".", "append", "(", "x", ")", "\n", "\n", "", "if", "self", ".", "layer_norm", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "if", "self", ".", "project_out_dim", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "project_out_dim", "(", "x", ")", "\n", "\n", "", "return", "x", ",", "{", "\"attn\"", ":", "attn", ",", "\"inner_states\"", ":", "inner_states", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_transformer.LevenshteinTransformerDecoder.forward_mask_ins": [[385, 399], ["levenshtein_transformer.LevenshteinTransformerDecoder.extract_features", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.linear", "torch.linear", "torch.linear", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax"], ["", "@", "ensemble_decoder", "\n", "def", "forward_mask_ins", "(", "self", ",", "normalize", ",", "encoder_out", ",", "prev_output_tokens", ",", "**", "unused", ")", ":", "\n", "        ", "features", ",", "extra", "=", "self", ".", "extract_features", "(", "\n", "prev_output_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", "early_exit", "=", "self", ".", "early_exit", "[", "1", "]", ",", "\n", "layers", "=", "self", ".", "layers_msk", ",", "\n", "**", "unused", "\n", ")", "\n", "features_cat", "=", "torch", ".", "cat", "(", "[", "features", "[", ":", ",", ":", "-", "1", ",", ":", "]", ",", "features", "[", ":", ",", "1", ":", ",", ":", "]", "]", ",", "2", ")", "\n", "decoder_out", "=", "F", ".", "linear", "(", "features_cat", ",", "self", ".", "embed_mask_ins", ".", "weight", ")", "\n", "if", "normalize", ":", "\n", "            ", "return", "F", ".", "log_softmax", "(", "decoder_out", ",", "-", "1", ")", ",", "extra", "[", "\"attn\"", "]", "\n", "", "return", "decoder_out", ",", "extra", "[", "\"attn\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_transformer.LevenshteinTransformerDecoder.forward_word_ins": [[400, 413], ["levenshtein_transformer.LevenshteinTransformerDecoder.extract_features", "levenshtein_transformer.LevenshteinTransformerDecoder.output_layer", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.output_layer", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax"], ["", "@", "ensemble_decoder", "\n", "def", "forward_word_ins", "(", "self", ",", "normalize", ",", "encoder_out", ",", "prev_output_tokens", ",", "**", "unused", ")", ":", "\n", "        ", "features", ",", "extra", "=", "self", ".", "extract_features", "(", "\n", "prev_output_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", "early_exit", "=", "self", ".", "early_exit", "[", "2", "]", ",", "\n", "layers", "=", "self", ".", "layers", ",", "\n", "**", "unused", "\n", ")", "\n", "decoder_out", "=", "self", ".", "output_layer", "(", "features", ")", "\n", "if", "normalize", ":", "\n", "            ", "return", "F", ".", "log_softmax", "(", "decoder_out", ",", "-", "1", ")", ",", "extra", "[", "\"attn\"", "]", "\n", "", "return", "decoder_out", ",", "extra", "[", "\"attn\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_transformer.LevenshteinTransformerDecoder.forward_word_del": [[414, 427], ["levenshtein_transformer.LevenshteinTransformerDecoder.extract_features", "torch.linear", "torch.linear", "torch.linear", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax"], ["", "@", "ensemble_decoder", "\n", "def", "forward_word_del", "(", "self", ",", "normalize", ",", "encoder_out", ",", "prev_output_tokens", ",", "**", "unused", ")", ":", "\n", "        ", "features", ",", "extra", "=", "self", ".", "extract_features", "(", "\n", "prev_output_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", "early_exit", "=", "self", ".", "early_exit", "[", "0", "]", ",", "\n", "layers", "=", "self", ".", "layers_del", ",", "\n", "**", "unused", "\n", ")", "\n", "decoder_out", "=", "F", ".", "linear", "(", "features", ",", "self", ".", "embed_word_del", ".", "weight", ")", "\n", "if", "normalize", ":", "\n", "            ", "return", "F", ".", "log_softmax", "(", "decoder_out", ",", "-", "1", ")", ",", "extra", "[", "\"attn\"", "]", "\n", "", "return", "decoder_out", ",", "extra", "[", "\"attn\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_transformer.levenshtein_base_architecture": [[429, 475], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "", "@", "register_model_architecture", "(", "\"levenshtein_transformer\"", ",", "\"levenshtein_transformer\"", ")", "\n", "def", "levenshtein_base_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_path", "=", "getattr", "(", "args", ",", "\"encoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "2048", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "6", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "encoder_normalize_before", "=", "getattr", "(", "args", ",", "\"encoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "encoder_learned_pos", "=", "getattr", "(", "args", ",", "\"encoder_learned_pos\"", ",", "False", ")", "\n", "args", ".", "decoder_embed_path", "=", "getattr", "(", "args", ",", "\"decoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "args", ".", "encoder_embed_dim", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "args", ".", "encoder_ffn_embed_dim", "\n", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "6", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "decoder_normalize_before", "=", "getattr", "(", "args", ",", "\"decoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "decoder_learned_pos", "=", "getattr", "(", "args", ",", "\"decoder_learned_pos\"", ",", "False", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.0", ")", "\n", "args", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "0.0", ")", "\n", "args", ".", "activation_fn", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"relu\"", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "adaptive_softmax_cutoff", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_cutoff\"", ",", "None", ")", "\n", "args", ".", "adaptive_softmax_dropout", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_dropout\"", ",", "0", ")", "\n", "args", ".", "share_decoder_input_output_embed", "=", "getattr", "(", "\n", "args", ",", "\"share_decoder_input_output_embed\"", ",", "False", "\n", ")", "\n", "args", ".", "share_all_embeddings", "=", "getattr", "(", "args", ",", "\"share_all_embeddings\"", ",", "False", ")", "\n", "args", ".", "no_token_positional_embeddings", "=", "getattr", "(", "\n", "args", ",", "\"no_token_positional_embeddings\"", ",", "False", "\n", ")", "\n", "args", ".", "adaptive_input", "=", "getattr", "(", "args", ",", "\"adaptive_input\"", ",", "False", ")", "\n", "args", ".", "apply_bert_init", "=", "getattr", "(", "args", ",", "\"apply_bert_init\"", ",", "False", ")", "\n", "\n", "args", ".", "decoder_output_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_output_dim\"", ",", "args", ".", "decoder_embed_dim", "\n", ")", "\n", "args", ".", "sampling_for_deletion", "=", "getattr", "(", "args", ",", "\"sampling_for_deletion\"", ",", "False", ")", "\n", "args", ".", "decoder_input_dim", "=", "getattr", "(", "args", ",", "\"decoder_input_dim\"", ",", "args", ".", "decoder_embed_dim", ")", "\n", "args", ".", "early_exit", "=", "getattr", "(", "args", ",", "\"early_exit\"", ",", "\"6,6,6\"", ")", "\n", "args", ".", "no_share_discriminator", "=", "getattr", "(", "args", ",", "\"no_share_discriminator\"", ",", "False", ")", "\n", "args", ".", "no_share_maskpredictor", "=", "getattr", "(", "args", ",", "\"no_share_maskpredictor\"", ",", "False", ")", "\n", "args", ".", "share_discriminator_maskpredictor", "=", "getattr", "(", "\n", "args", ",", "\"share_discriminator_maskpredictor\"", ",", "False", "\n", ")", "\n", "args", ".", "no_share_last_layer", "=", "getattr", "(", "args", ",", "\"no_share_last_layer\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_transformer.levenshtein_transformer_wmt_en_de": [[477, 482], ["fairseq.models.register_model_architecture", "levenshtein_transformer.levenshtein_base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_transformer.levenshtein_base_architecture"], ["", "@", "register_model_architecture", "(", "\n", "\"levenshtein_transformer\"", ",", "\"levenshtein_transformer_wmt_en_de\"", "\n", ")", "\n", "def", "levenshtein_transformer_wmt_en_de", "(", "args", ")", ":", "\n", "    ", "levenshtein_base_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_transformer.levenshtein_transformer_vaswani_wmt_en_de_big": [[485, 498], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "levenshtein_transformer.levenshtein_base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_transformer.levenshtein_base_architecture"], ["", "@", "register_model_architecture", "(", "\n", "\"levenshtein_transformer\"", ",", "\"levenshtein_transformer_vaswani_wmt_en_de_big\"", "\n", ")", "\n", "def", "levenshtein_transformer_vaswani_wmt_en_de_big", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "1024", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "4096", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "16", ")", "\n", "args", ".", "encoder_normalize_before", "=", "getattr", "(", "args", ",", "\"encoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "1024", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "4096", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "16", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.3", ")", "\n", "levenshtein_base_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_transformer.levenshtein_transformer_wmt_en_de_big_t2t": [[501, 510], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "levenshtein_transformer.levenshtein_transformer_vaswani_wmt_en_de_big"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_transformer.levenshtein_transformer_vaswani_wmt_en_de_big"], ["", "@", "register_model_architecture", "(", "\n", "\"levenshtein_transformer\"", ",", "\"levenshtein_transformer_wmt_en_de_big\"", "\n", ")", "\n", "def", "levenshtein_transformer_wmt_en_de_big_t2t", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_normalize_before", "=", "getattr", "(", "args", ",", "\"encoder_normalize_before\"", ",", "True", ")", "\n", "args", ".", "decoder_normalize_before", "=", "getattr", "(", "args", ",", "\"decoder_normalize_before\"", ",", "True", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.1", ")", "\n", "args", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "0.1", ")", "\n", "levenshtein_transformer_vaswani_wmt_en_de_big", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.nat.insertion_transformer.NegativeDistanceScore.__init__": [[22, 30], ["insertion_transformer.NegativeDistanceScore.compute_score_full", "insertion_transformer.NegativeDistanceScore.compute_score_full", "insertion_transformer.NegativeDistanceScore.compute_score_full"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.nat.insertion_transformer.NegativeDistanceScore.compute_score_full", "home.repos.pwc.inspect_result.reneeye_const.nat.insertion_transformer.NegativeDistanceScore.compute_score_full", "home.repos.pwc.inspect_result.reneeye_const.nat.insertion_transformer.NegativeDistanceScore.compute_score_full"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "\n", "# pre-compute some values", "\n", "        ", "self", ".", "scores", "=", "{", "}", "\n", "\n", "self", ".", "scores", "[", "0.5", "]", "=", "self", ".", "compute_score_full", "(", "50", ",", "0.5", ")", "\n", "self", ".", "scores", "[", "1.0", "]", "=", "self", ".", "compute_score_full", "(", "50", ",", "1.0", ")", "\n", "self", ".", "scores", "[", "2.0", "]", "=", "self", ".", "compute_score_full", "(", "50", ",", "2.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.insertion_transformer.NegativeDistanceScore.__call__": [[31, 39], ["insertion_transformer.NegativeDistanceScore.compute_score"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.nat.insertion_transformer.NegativeDistanceScore.compute_score"], ["", "def", "__call__", "(", "self", ",", "i", ",", "L", ",", "tau", ")", ":", "\n", "        ", "if", "(", "tau", "is", "None", ")", "or", "(", "tau", ">", "1000", ")", ":", "\n", "            ", "return", "1", "/", "L", "\n", "\n", "", "if", "tau", "in", "self", ".", "scores", ":", "\n", "            ", "if", "L", "<", "self", ".", "scores", "[", "tau", "]", ".", "shape", "[", "0", "]", ":", "\n", "                ", "return", "self", ".", "scores", "[", "tau", "]", "[", "L", "-", "1", ",", "i", "]", "\n", "", "", "return", "self", ".", "compute_score", "(", "L", ",", "tau", ")", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.insertion_transformer.NegativeDistanceScore.compute_score": [[40, 44], ["numpy.array", "numpy.exp", "numpy.exp.sum", "numpy.exp.max", "range", "abs"], "methods", ["None"], ["", "def", "compute_score", "(", "self", ",", "L", ",", "tau", ")", ":", "\n", "        ", "s", "=", "np", ".", "array", "(", "[", "-", "abs", "(", "L", "/", "2", "-", "i", ")", "/", "tau", "for", "i", "in", "range", "(", "L", ")", "]", ")", "\n", "s", "=", "np", ".", "exp", "(", "s", "-", "s", ".", "max", "(", ")", ")", "\n", "return", "s", "/", "s", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.insertion_transformer.NegativeDistanceScore.compute_score_full": [[45, 50], ["numpy.exp", "numpy.tril", "numpy.triu", "numpy.exp.sum", "abs", "numpy.exp.max", "float", "numpy.arange", "numpy.arange"], "methods", ["None"], ["", "def", "compute_score_full", "(", "self", ",", "L", ",", "tau", ")", ":", "\n", "        ", "s", "=", "-", "abs", "(", "np", ".", "arange", "(", "0", ",", "L", "-", "1", ")", "[", ":", ",", "None", "]", "/", "2", "-", "np", ".", "arange", "(", "L", ")", "[", "None", ",", ":", "]", ")", "/", "tau", "\n", "s", "=", "np", ".", "tril", "(", "s", ",", "0", ")", "+", "np", ".", "triu", "(", "s", "-", "float", "(", "\"inf\"", ")", ",", "1", ")", "\n", "s", "=", "np", ".", "exp", "(", "s", "-", "s", ".", "max", "(", "1", ",", "keepdims", "=", "True", ")", ")", "\n", "return", "s", "/", "s", ".", "sum", "(", "1", ",", "keepdims", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.insertion_transformer.InsertionTransformerModel.__init__": [[122, 124], ["fairseq.models.nat.LevenshteinTransformerModel.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "encoder", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.insertion_transformer.InsertionTransformerModel.add_args": [[125, 129], ["fairseq.models.nat.FairseqNATModel.add_args", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "FairseqNATModel", ".", "add_args", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "\"--label-tau\"", ",", "default", "=", "None", ",", "type", "=", "float", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.insertion_transformer.InsertionTransformerModel.build_decoder": [[130, 136], ["insertion_transformer.InsertionTransformerDecoder", "getattr", "InsertionTransformerDecoder.apply"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_decoder", "(", "cls", ",", "args", ",", "tgt_dict", ",", "embed_tokens", ")", ":", "\n", "        ", "decoder", "=", "InsertionTransformerDecoder", "(", "args", ",", "tgt_dict", ",", "embed_tokens", ")", "\n", "if", "getattr", "(", "args", ",", "\"apply_bert_init\"", ",", "False", ")", ":", "\n", "            ", "decoder", ".", "apply", "(", "init_bert_params", ")", "\n", "", "return", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.insertion_transformer.InsertionTransformerModel.forward": [[137, 170], ["insertion_transformer.InsertionTransformerModel.encoder", "insertion_transformer.InsertionTransformerModel.decoder.forward_word_ins", "_get_ins_targets().type_as", "prev_output_tokens[].ne", "insertion_transformer._get_ins_targets", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_word_ins", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._get_ins_targets"], ["", "def", "forward", "(", "\n", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "tgt_tokens", ",", "**", "kwargs", "\n", ")", ":", "\n", "\n", "        ", "assert", "tgt_tokens", "is", "not", "None", ",", "\"forward function only supports training.\"", "\n", "\n", "# encoding", "\n", "encoder_out", "=", "self", ".", "encoder", "(", "src_tokens", ",", "src_lengths", "=", "src_lengths", ",", "**", "kwargs", ")", "\n", "\n", "# generate training labels for insertion", "\n", "word_ins_out", "=", "self", ".", "decoder", ".", "forward_word_ins", "(", "\n", "normalize", "=", "False", ",", "\n", "prev_output_tokens", "=", "prev_output_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", ")", "\n", "\n", "word_ins_tgt", "=", "_get_ins_targets", "(", "\n", "prev_output_tokens", ",", "\n", "tgt_tokens", ",", "\n", "self", ".", "pad", ",", "\n", "self", ".", "unk", ",", "\n", "len", "(", "self", ".", "tgt_dict", ")", ",", "\n", "tau", "=", "self", ".", "decoder", ".", "label_tau", ",", "\n", ")", ".", "type_as", "(", "word_ins_out", ")", "\n", "word_ins_masks", "=", "prev_output_tokens", "[", ":", ",", "1", ":", "]", ".", "ne", "(", "self", ".", "pad", ")", "\n", "\n", "return", "{", "\n", "\"word_ins\"", ":", "{", "\n", "\"out\"", ":", "word_ins_out", ",", "\n", "\"tgt\"", ":", "word_ins_tgt", ",", "\n", "\"mask\"", ":", "word_ins_masks", ",", "\n", "\"ls\"", ":", "self", ".", "args", ".", "label_smoothing", ",", "\n", "\"nll_loss\"", ":", "True", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.insertion_transformer.InsertionTransformerModel.forward_decoder": [[173, 206], ["insertion_transformer.InsertionTransformerModel.decoder.forward_word_ins", "insertion_transformer.InsertionTransformerModel.max", "insertion_transformer._apply_ins_words", "output_tokens.ne().sum().max", "decoder_out._replace", "history.append", "output_tokens.ne().sum", "output_tokens.clone", "output_tokens.ne"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_word_ins", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._apply_ins_words"], ["", "def", "forward_decoder", "(", "\n", "self", ",", "decoder_out", ",", "encoder_out", ",", "eos_penalty", "=", "0.0", ",", "max_ratio", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "\n", "        ", "output_tokens", "=", "decoder_out", ".", "output_tokens", "\n", "output_scores", "=", "decoder_out", ".", "output_scores", "\n", "history", "=", "decoder_out", ".", "history", "\n", "\n", "# TODO: decoding for InsertionTransformer", "\n", "word_ins_score", "=", "self", ".", "decoder", ".", "forward_word_ins", "(", "\n", "normalize", "=", "True", ",", "prev_output_tokens", "=", "output_tokens", ",", "encoder_out", "=", "encoder_out", "\n", ")", "\n", "\n", "if", "eos_penalty", ">", "0.0", ":", "\n", "            ", "word_ins_score", "[", ":", ",", ":", ",", "self", ".", "pad", "]", "-=", "eos_penalty", "\n", "", "word_ins_score", ",", "word_ins_pred", "=", "word_ins_score", ".", "max", "(", "-", "1", ")", "\n", "output_tokens", ",", "output_scores", "=", "_apply_ins_words", "(", "\n", "output_tokens", ",", "output_scores", ",", "word_ins_pred", ",", "word_ins_score", ",", "self", ".", "pad", "\n", ")", "\n", "\n", "# delete some unnecessary paddings", "\n", "cut_off", "=", "output_tokens", ".", "ne", "(", "self", ".", "pad", ")", ".", "sum", "(", "1", ")", ".", "max", "(", ")", "\n", "output_tokens", "=", "output_tokens", "[", ":", ",", ":", "cut_off", "]", "\n", "output_scores", "=", "output_scores", "[", ":", ",", ":", "cut_off", "]", "\n", "\n", "if", "history", "is", "not", "None", ":", "\n", "            ", "history", ".", "append", "(", "output_tokens", ".", "clone", "(", ")", ")", "\n", "\n", "", "return", "decoder_out", ".", "_replace", "(", "\n", "output_tokens", "=", "output_tokens", ",", "\n", "output_scores", "=", "output_scores", ",", "\n", "attn", "=", "None", ",", "\n", "history", "=", "history", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.insertion_transformer.InsertionTransformerDecoder.__init__": [[210, 223], ["fairseq.models.nat.LevenshteinTransformerDecoder.__init__", "dictionary.bos", "dictionary.unk", "dictionary.eos", "fairseq.models.transformer.Linear", "getattr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "dictionary", ",", "embed_tokens", ",", "no_encoder_attn", "=", "False", ")", ":", "\n", "# use the TransformerDecoder's __init__", "\n", "        ", "super", "(", "LevenshteinTransformerDecoder", ",", "self", ")", ".", "__init__", "(", "\n", "args", ",", "dictionary", ",", "embed_tokens", ",", "no_encoder_attn", "=", "no_encoder_attn", "\n", ")", "\n", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "self", ".", "bos", "=", "dictionary", ".", "bos", "(", ")", "\n", "self", ".", "unk", "=", "dictionary", ".", "unk", "(", ")", "\n", "self", ".", "eos", "=", "dictionary", ".", "eos", "(", ")", "\n", "self", ".", "pool_out", "=", "Linear", "(", "self", ".", "output_embed_dim", "*", "2", ",", "self", ".", "output_embed_dim", ")", "\n", "\n", "self", ".", "label_tau", "=", "getattr", "(", "args", ",", "\"label_tau\"", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.insertion_transformer.InsertionTransformerDecoder.forward_word_ins": [[224, 232], ["insertion_transformer.InsertionTransformerDecoder.pool_out", "insertion_transformer.InsertionTransformerDecoder.output_layer", "insertion_transformer.InsertionTransformerDecoder.extract_features", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.log_softmax", "torch.log_softmax"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.output_layer", "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax"], ["", "@", "ensemble_decoder", "\n", "def", "forward_word_ins", "(", "self", ",", "normalize", ",", "encoder_out", ",", "prev_output_tokens", ")", ":", "\n", "        ", "features", "=", "self", ".", "extract_features", "(", "prev_output_tokens", ",", "encoder_out", "=", "encoder_out", ")", "[", "0", "]", "\n", "features", "=", "self", ".", "pool_out", "(", "\n", "torch", ".", "cat", "(", "[", "features", "[", ":", ",", ":", "-", "1", ",", ":", "]", ",", "features", "[", ":", ",", "1", ":", ",", ":", "]", "]", ",", "2", ")", "\n", ")", "\n", "decoder_out", "=", "self", ".", "output_layer", "(", "features", ")", "\n", "return", "F", ".", "log_softmax", "(", "decoder_out", ",", "-", "1", ")", "if", "normalize", "else", "decoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.insertion_transformer.InsertionTransformerDecoder.forward_mask_ins": [[233, 235], ["None"], "methods", ["None"], ["", "def", "forward_mask_ins", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.insertion_transformer.InsertionTransformerDecoder.forward_word_del": [[236, 238], ["None"], "methods", ["None"], ["", "def", "forward_word_del", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.insertion_transformer._get_ins_targets": [[55, 100], ["in_tokens.size", "in_tokens.size", "libnat.suggested_ed2_path", "in_tokens.new_zeros().float", "zip", "insert_label_tensors.view.scatter_", "insert_label_tensors.view.view", "torch.cuda.device_of", "torch.cuda.device_of", "torch.tensor", "torch.tensor", "insert_index.long", "sys.stderr.write", "in_tokens.new_zeros", "list", "enumerate", "enumerate", "in_tokens.tolist", "out_tokens.tolist", "neg_scorer", "enumerate", "enumerate", "enumerate", "len"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["def", "_get_ins_targets", "(", "in_tokens", ",", "out_tokens", ",", "padding_idx", ",", "unk_idx", ",", "vocab_size", ",", "tau", "=", "None", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "from", "fairseq", "import", "libnat", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "        ", "import", "sys", "\n", "\n", "sys", ".", "stderr", ".", "write", "(", "\"ERROR: missing libnat. run `pip install --editable .`\\n\"", ")", "\n", "raise", "e", "\n", "\n", "", "B", "=", "in_tokens", ".", "size", "(", "0", ")", "\n", "T", "=", "in_tokens", ".", "size", "(", "1", ")", "\n", "V", "=", "vocab_size", "\n", "\n", "with", "torch", ".", "cuda", ".", "device_of", "(", "in_tokens", ")", ":", "\n", "        ", "in_tokens_list", "=", "[", "\n", "[", "t", "for", "t", "in", "s", "if", "t", "!=", "padding_idx", "]", "for", "i", ",", "s", "in", "enumerate", "(", "in_tokens", ".", "tolist", "(", ")", ")", "\n", "]", "\n", "out_tokens_list", "=", "[", "\n", "[", "t", "for", "t", "in", "s", "if", "t", "!=", "padding_idx", "]", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "out_tokens", ".", "tolist", "(", ")", ")", "\n", "]", "\n", "\n", "", "full_labels", "=", "libnat", ".", "suggested_ed2_path", "(", "\n", "in_tokens_list", ",", "out_tokens_list", ",", "padding_idx", "\n", ")", "\n", "insert_labels", "=", "[", "a", "[", ":", "-", "1", "]", "for", "a", "in", "full_labels", "]", "\n", "\n", "# numericalize1", "\n", "insert_label_tensors", "=", "in_tokens", ".", "new_zeros", "(", "B", "*", "(", "T", "-", "1", ")", "*", "V", ")", ".", "float", "(", ")", "\n", "insert_index", ",", "insert_labels", "=", "zip", "(", "\n", "*", "[", "\n", "(", "w", "+", "(", "j", "+", "i", "*", "(", "T", "-", "1", ")", ")", "*", "V", ",", "neg_scorer", "(", "k", ",", "len", "(", "label", ")", ",", "tau", ")", ")", "\n", "for", "i", ",", "labels", "in", "enumerate", "(", "insert_labels", ")", "\n", "for", "j", ",", "label", "in", "enumerate", "(", "labels", "[", "1", ":", "-", "1", "]", ")", "\n", "for", "k", ",", "w", "in", "enumerate", "(", "label", ")", "\n", "]", "\n", ")", "# HACK 1:-1", "\n", "insert_index", ",", "insert_labels", "=", "[", "\n", "torch", ".", "tensor", "(", "list", "(", "a", ")", ",", "device", "=", "in_tokens", ".", "device", ")", "\n", "for", "a", "in", "[", "insert_index", ",", "insert_labels", "]", "\n", "]", "\n", "insert_label_tensors", ".", "scatter_", "(", "0", ",", "insert_index", ".", "long", "(", ")", ",", "insert_labels", ")", "\n", "insert_label_tensors", "=", "insert_label_tensors", ".", "view", "(", "B", ",", "T", "-", "1", ",", "V", ")", "\n", "\n", "return", "insert_label_tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.insertion_transformer._apply_ins_words": [[102, 118], ["in_tokens[].eq", "word_ins_scores.masked_fill_", "word_ins_pred.masked_fill_", "fairseq.utils.new_arange().type_as", "torch.cat().gather", "torch.cat().gather", "torch.cat().gather", "torch.cat().gather", "word_ins_pred.eq", "float", "torch.cat().sort", "torch.cat().sort", "fairseq.utils.new_arange", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.new_arange"], ["", "def", "_apply_ins_words", "(", "in_tokens", ",", "in_scores", ",", "word_ins_pred", ",", "word_ins_scores", ",", "padding_idx", ")", ":", "\n", "\n", "    ", "padding_masks", "=", "in_tokens", "[", ":", ",", "1", ":", "]", ".", "eq", "(", "padding_idx", ")", "\n", "word_ins_scores", ".", "masked_fill_", "(", "padding_masks", ",", "0.0", ")", "\n", "word_ins_pred", ".", "masked_fill_", "(", "padding_masks", ",", "padding_idx", ")", "\n", "\n", "in_coords", "=", "new_arange", "(", "in_tokens", ")", ".", "type_as", "(", "in_scores", ")", "\n", "\n", "# shift all padding predictions to infinite", "\n", "out_coords", "=", "(", "in_coords", "[", ":", ",", "1", ":", "]", "-", "0.5", ")", ".", "masked_fill", "(", "\n", "word_ins_pred", ".", "eq", "(", "padding_idx", ")", ",", "float", "(", "\"inf\"", ")", "\n", ")", "\n", "out_coords", "=", "torch", ".", "cat", "(", "[", "in_coords", ",", "out_coords", "]", ",", "1", ")", ".", "sort", "(", "-", "1", ")", "[", "1", "]", "\n", "out_tokens", "=", "torch", ".", "cat", "(", "[", "in_tokens", ",", "word_ins_pred", "]", ",", "1", ")", ".", "gather", "(", "1", ",", "out_coords", ")", "\n", "out_scores", "=", "torch", ".", "cat", "(", "[", "in_scores", ",", "word_ins_scores", "]", ",", "1", ")", ".", "gather", "(", "1", ",", "out_coords", ")", "\n", "return", "out_tokens", ",", "out_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.insertion_transformer.insertion_base_architecture": [[240, 281], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "", "@", "register_model_architecture", "(", "\"insertion_transformer\"", ",", "\"insertion_transformer\"", ")", "\n", "def", "insertion_base_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_path", "=", "getattr", "(", "args", ",", "\"encoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "2048", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "6", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "encoder_normalize_before", "=", "getattr", "(", "args", ",", "\"encoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "encoder_learned_pos", "=", "getattr", "(", "args", ",", "\"encoder_learned_pos\"", ",", "False", ")", "\n", "args", ".", "decoder_embed_path", "=", "getattr", "(", "args", ",", "\"decoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "args", ".", "encoder_embed_dim", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "args", ".", "encoder_ffn_embed_dim", "\n", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "6", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "decoder_normalize_before", "=", "getattr", "(", "args", ",", "\"decoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "decoder_learned_pos", "=", "getattr", "(", "args", ",", "\"decoder_learned_pos\"", ",", "False", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.0", ")", "\n", "args", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "0.0", ")", "\n", "args", ".", "activation_fn", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"relu\"", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "adaptive_softmax_cutoff", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_cutoff\"", ",", "None", ")", "\n", "args", ".", "adaptive_softmax_dropout", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_dropout\"", ",", "0", ")", "\n", "args", ".", "share_decoder_input_output_embed", "=", "getattr", "(", "\n", "args", ",", "\"share_decoder_input_output_embed\"", ",", "False", "\n", ")", "\n", "args", ".", "share_all_embeddings", "=", "getattr", "(", "args", ",", "\"share_all_embeddings\"", ",", "False", ")", "\n", "args", ".", "no_token_positional_embeddings", "=", "getattr", "(", "\n", "args", ",", "\"no_token_positional_embeddings\"", ",", "False", "\n", ")", "\n", "args", ".", "adaptive_input", "=", "getattr", "(", "args", ",", "\"adaptive_input\"", ",", "False", ")", "\n", "args", ".", "apply_bert_init", "=", "getattr", "(", "args", ",", "\"apply_bert_init\"", ",", "False", ")", "\n", "\n", "args", ".", "decoder_output_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_output_dim\"", ",", "args", ".", "decoder_embed_dim", "\n", ")", "\n", "args", ".", "decoder_input_dim", "=", "getattr", "(", "args", ",", "\"decoder_input_dim\"", ",", "args", ".", "decoder_embed_dim", ")", "\n", "\n", "# special for insertion transformer", "\n", "args", ".", "label_tau", "=", "getattr", "(", "args", ",", "\"label_tau\"", ",", "None", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.nat.cmlm_transformer.CMLMNATransformerModel.add_args": [[29, 32], ["fairseq.models.nat.NATransformerModel.add_args"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args"], ["    ", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "NATransformerModel", ".", "add_args", "(", "parser", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.cmlm_transformer.CMLMNATransformerModel.forward": [[33, 68], ["cmlm_transformer.CMLMNATransformerModel.encoder", "cmlm_transformer.CMLMNATransformerModel.decoder.forward_length", "cmlm_transformer.CMLMNATransformerModel.decoder.forward_length_prediction", "cmlm_transformer.CMLMNATransformerModel.decoder", "prev_output_tokens.eq"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerDecoder.forward_length", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerDecoder.forward_length_prediction", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward", "(", "\n", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "tgt_tokens", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "assert", "not", "self", ".", "decoder", ".", "src_embedding_copy", ",", "\"do not support embedding copy.\"", "\n", "\n", "# encoding", "\n", "encoder_out", "=", "self", ".", "encoder", "(", "src_tokens", ",", "src_lengths", "=", "src_lengths", ",", "**", "kwargs", ")", "\n", "# length prediction", "\n", "length_out", "=", "self", ".", "decoder", ".", "forward_length", "(", "\n", "normalize", "=", "False", ",", "encoder_out", "=", "encoder_out", "\n", ")", "\n", "length_tgt", "=", "self", ".", "decoder", ".", "forward_length_prediction", "(", "\n", "length_out", ",", "encoder_out", ",", "tgt_tokens", "\n", ")", "\n", "\n", "# decoding", "\n", "word_ins_out", "=", "self", ".", "decoder", "(", "\n", "normalize", "=", "False", ",", "\n", "prev_output_tokens", "=", "prev_output_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", ")", "\n", "word_ins_mask", "=", "prev_output_tokens", ".", "eq", "(", "self", ".", "unk", ")", "\n", "\n", "return", "{", "\n", "\"word_ins\"", ":", "{", "\n", "\"out\"", ":", "word_ins_out", ",", "\n", "\"tgt\"", ":", "tgt_tokens", ",", "\n", "\"mask\"", ":", "word_ins_mask", ",", "\n", "\"ls\"", ":", "self", ".", "args", ".", "label_smoothing", ",", "\n", "\"nll_loss\"", ":", "True", ",", "\n", "}", ",", "\n", "\"length\"", ":", "{", "\n", "\"out\"", ":", "length_out", ",", "\n", "\"tgt\"", ":", "length_tgt", ",", "\n", "\"factor\"", ":", "self", ".", "decoder", ".", "length_loss_factor", ",", "\n", "}", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.cmlm_transformer.CMLMNATransformerModel.forward_decoder": [[71, 110], ["output_tokens.eq", "cmlm_transformer.CMLMNATransformerModel.decoder().max", "output_tokens.masked_scatter_", "output_scores.masked_scatter_", "decoder_out._replace", "history.append", "cmlm_transformer._skeptical_unmasking", "output_tokens.masked_fill_", "output_scores.masked_fill_", "cmlm_transformer.CMLMNATransformerModel.decoder", "output_tokens.clone", "output_tokens.ne", "history.append", "output_tokens.clone"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.nat.cmlm_transformer._skeptical_unmasking", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward_decoder", "(", "self", ",", "decoder_out", ",", "encoder_out", ",", "decoding_format", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "step", "=", "decoder_out", ".", "step", "\n", "max_step", "=", "decoder_out", ".", "max_step", "\n", "\n", "output_tokens", "=", "decoder_out", ".", "output_tokens", "\n", "output_scores", "=", "decoder_out", ".", "output_scores", "\n", "history", "=", "decoder_out", ".", "history", "\n", "\n", "# execute the decoder", "\n", "output_masks", "=", "output_tokens", ".", "eq", "(", "self", ".", "unk", ")", "\n", "_scores", ",", "_tokens", "=", "self", ".", "decoder", "(", "\n", "normalize", "=", "True", ",", "\n", "prev_output_tokens", "=", "output_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", ")", ".", "max", "(", "-", "1", ")", "\n", "output_tokens", ".", "masked_scatter_", "(", "output_masks", ",", "_tokens", "[", "output_masks", "]", ")", "\n", "output_scores", ".", "masked_scatter_", "(", "output_masks", ",", "_scores", "[", "output_masks", "]", ")", "\n", "\n", "if", "history", "is", "not", "None", ":", "\n", "            ", "history", ".", "append", "(", "output_tokens", ".", "clone", "(", ")", ")", "\n", "\n", "# skeptical decoding (depend on the maximum decoding steps.)", "\n", "", "if", "(", "step", "+", "1", ")", "<", "max_step", ":", "\n", "            ", "skeptical_mask", "=", "_skeptical_unmasking", "(", "\n", "output_scores", ",", "output_tokens", ".", "ne", "(", "self", ".", "pad", ")", ",", "1", "-", "(", "step", "+", "1", ")", "/", "max_step", "\n", ")", "\n", "\n", "output_tokens", ".", "masked_fill_", "(", "skeptical_mask", ",", "self", ".", "unk", ")", "\n", "output_scores", ".", "masked_fill_", "(", "skeptical_mask", ",", "0.0", ")", "\n", "\n", "if", "history", "is", "not", "None", ":", "\n", "                ", "history", ".", "append", "(", "output_tokens", ".", "clone", "(", ")", ")", "\n", "\n", "", "", "return", "decoder_out", ".", "_replace", "(", "\n", "output_tokens", "=", "output_tokens", ",", "\n", "output_scores", "=", "output_scores", ",", "\n", "attn", "=", "None", ",", "\n", "history", "=", "history", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.cmlm_transformer._skeptical_unmasking": [[18, 25], ["skeptical_mask.scatter", "output_scores.sort", "fairseq.utils.new_arange", "output_masks.sum().type_as", "output_masks.sum"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.new_arange"], ["def", "_skeptical_unmasking", "(", "output_scores", ",", "output_masks", ",", "p", ")", ":", "\n", "    ", "sorted_index", "=", "output_scores", ".", "sort", "(", "-", "1", ")", "[", "1", "]", "\n", "boundary_len", "=", "(", "\n", "(", "output_masks", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ".", "type_as", "(", "output_scores", ")", "-", "2", ")", "*", "p", "\n", ")", ".", "long", "(", ")", "\n", "skeptical_mask", "=", "new_arange", "(", "output_masks", ")", "<", "boundary_len", "\n", "return", "skeptical_mask", ".", "scatter", "(", "1", ",", "sorted_index", ",", "skeptical_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.cmlm_transformer.cmlm_base_architecture": [[113, 158], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "", "@", "register_model_architecture", "(", "\"cmlm_transformer\"", ",", "\"cmlm_transformer\"", ")", "\n", "def", "cmlm_base_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_path", "=", "getattr", "(", "args", ",", "\"encoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "2048", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "6", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "encoder_normalize_before", "=", "getattr", "(", "args", ",", "\"encoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "encoder_learned_pos", "=", "getattr", "(", "args", ",", "\"encoder_learned_pos\"", ",", "False", ")", "\n", "args", ".", "decoder_embed_path", "=", "getattr", "(", "args", ",", "\"decoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "args", ".", "encoder_embed_dim", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "args", ".", "encoder_ffn_embed_dim", "\n", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "6", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "decoder_normalize_before", "=", "getattr", "(", "args", ",", "\"decoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "decoder_learned_pos", "=", "getattr", "(", "args", ",", "\"decoder_learned_pos\"", ",", "False", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.0", ")", "\n", "args", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "0.0", ")", "\n", "args", ".", "activation_fn", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"relu\"", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "adaptive_softmax_cutoff", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_cutoff\"", ",", "None", ")", "\n", "args", ".", "adaptive_softmax_dropout", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_dropout\"", ",", "0", ")", "\n", "args", ".", "share_decoder_input_output_embed", "=", "getattr", "(", "\n", "args", ",", "\"share_decoder_input_output_embed\"", ",", "False", "\n", ")", "\n", "args", ".", "share_all_embeddings", "=", "getattr", "(", "args", ",", "\"share_all_embeddings\"", ",", "True", ")", "\n", "args", ".", "no_token_positional_embeddings", "=", "getattr", "(", "\n", "args", ",", "\"no_token_positional_embeddings\"", ",", "False", "\n", ")", "\n", "args", ".", "adaptive_input", "=", "getattr", "(", "args", ",", "\"adaptive_input\"", ",", "False", ")", "\n", "args", ".", "apply_bert_init", "=", "getattr", "(", "args", ",", "\"apply_bert_init\"", ",", "False", ")", "\n", "\n", "args", ".", "decoder_output_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_output_dim\"", ",", "args", ".", "decoder_embed_dim", "\n", ")", "\n", "args", ".", "decoder_input_dim", "=", "getattr", "(", "args", ",", "\"decoder_input_dim\"", ",", "args", ".", "decoder_embed_dim", ")", "\n", "\n", "# --- special arguments ---", "\n", "args", ".", "sg_length_pred", "=", "getattr", "(", "args", ",", "\"sg_length_pred\"", ",", "False", ")", "\n", "args", ".", "pred_length_offset", "=", "getattr", "(", "args", ",", "\"pred_length_offset\"", ",", "False", ")", "\n", "args", ".", "length_loss_factor", "=", "getattr", "(", "args", ",", "\"length_loss_factor\"", ",", "0.1", ")", "\n", "args", ".", "ngram_predictor", "=", "getattr", "(", "args", ",", "\"ngram_predictor\"", ",", "1", ")", "\n", "args", ".", "src_embedding_copy", "=", "getattr", "(", "args", ",", "\"src_embedding_copy\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.cmlm_transformer.cmlm_wmt_en_de": [[160, 163], ["fairseq.models.register_model_architecture", "cmlm_transformer.cmlm_base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.nat.cmlm_transformer.cmlm_base_architecture"], ["", "@", "register_model_architecture", "(", "\"cmlm_transformer\"", ",", "\"cmlm_transformer_wmt_en_de\"", ")", "\n", "def", "cmlm_wmt_en_de", "(", "args", ")", ":", "\n", "    ", "cmlm_base_architecture", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.nat.fairseq_nat_model.FairseqNATModel.__init__": [[88, 97], ["fairseq.models.transformer.TransformerModel.__init__", "decoder.dictionary.bos", "decoder.dictionary.eos", "decoder.dictionary.pad", "decoder.dictionary.unk"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk"], ["def", "__init__", "(", "self", ",", "args", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "encoder", ",", "decoder", ")", "\n", "self", ".", "tgt_dict", "=", "decoder", ".", "dictionary", "\n", "self", ".", "bos", "=", "decoder", ".", "dictionary", ".", "bos", "(", ")", "\n", "self", ".", "eos", "=", "decoder", ".", "dictionary", ".", "eos", "(", ")", "\n", "self", ".", "pad", "=", "decoder", ".", "dictionary", ".", "pad", "(", ")", "\n", "self", ".", "unk", "=", "decoder", ".", "dictionary", ".", "unk", "(", ")", "\n", "\n", "self", ".", "ensemble_models", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.fairseq_nat_model.FairseqNATModel.allow_length_beam": [[98, 101], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "allow_length_beam", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.fairseq_nat_model.FairseqNATModel.allow_ensemble": [[102, 105], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "allow_ensemble", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.fairseq_nat_model.FairseqNATModel.enable_ensemble": [[106, 109], ["None"], "methods", ["None"], ["", "def", "enable_ensemble", "(", "self", ",", "models", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "ensemble_models", "=", "[", "m", ".", "encoder", "for", "m", "in", "models", "]", "\n", "self", ".", "decoder", ".", "ensemble_models", "=", "[", "m", ".", "decoder", "for", "m", "in", "models", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.fairseq_nat_model.FairseqNATModel.add_args": [[110, 117], ["fairseq.models.transformer.TransformerModel.add_args", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "TransformerModel", ".", "add_args", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--apply-bert-init\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"use custom param initialization for BERT\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.fairseq_nat_model.FairseqNATModel.build_decoder": [[119, 125], ["fairseq_nat_model.FairseqNATDecoder", "getattr", "FairseqNATDecoder.apply"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_decoder", "(", "cls", ",", "args", ",", "tgt_dict", ",", "embed_tokens", ")", ":", "\n", "        ", "decoder", "=", "FairseqNATDecoder", "(", "args", ",", "tgt_dict", ",", "embed_tokens", ")", "\n", "if", "getattr", "(", "args", ",", "\"apply_bert_init\"", ",", "False", ")", ":", "\n", "            ", "decoder", ".", "apply", "(", "init_bert_params", ")", "\n", "", "return", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.fairseq_nat_model.FairseqNATModel.build_encoder": [[126, 132], ["fairseq_nat_model.FairseqNATEncoder", "getattr", "FairseqNATEncoder.apply"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_encoder", "(", "cls", ",", "args", ",", "src_dict", ",", "embed_tokens", ")", ":", "\n", "        ", "encoder", "=", "FairseqNATEncoder", "(", "args", ",", "src_dict", ",", "embed_tokens", ")", "\n", "if", "getattr", "(", "args", ",", "\"apply_bert_init\"", ",", "False", ")", ":", "\n", "            ", "encoder", ".", "apply", "(", "init_bert_params", ")", "\n", "", "return", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.fairseq_nat_model.FairseqNATModel.forward_encoder": [[133, 135], ["fairseq_nat_model.FairseqNATModel.encoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder"], ["", "def", "forward_encoder", "(", "self", ",", "encoder_inputs", ")", ":", "\n", "        ", "return", "self", ".", "encoder", "(", "*", "encoder_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.fairseq_nat_model.FairseqNATModel.forward_decoder": [[136, 138], ["None"], "methods", ["None"], ["", "def", "forward_decoder", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.fairseq_nat_model.FairseqNATModel.initialize_output_tokens": [[139, 141], ["None"], "methods", ["None"], ["", "def", "initialize_output_tokens", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.fairseq_nat_model.FairseqNATModel.forward": [[142, 144], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.fairseq_nat_model.FairseqNATEncoder.__init__": [[147, 150], ["fairseq.models.transformer.TransformerEncoder.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "dictionary", ",", "embed_tokens", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "dictionary", ",", "embed_tokens", ")", "\n", "self", ".", "ensemble_models", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.fairseq_nat_model.FairseqNATEncoder.forward": [[151, 154], ["super().forward"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.forward"], ["", "@", "ensemble_encoder", "\n", "def", "forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "super", "(", ")", ".", "forward", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.fairseq_nat_model.FairseqNATDecoder.__init__": [[157, 160], ["fairseq.models.transformer.TransformerDecoder.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "dictionary", ",", "embed_tokens", ",", "no_encoder_attn", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "dictionary", ",", "embed_tokens", ",", "no_encoder_attn", ")", "\n", "self", ".", "ensemble_models", "=", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.nat.fairseq_nat_model.ensemble_encoder": [[17, 35], ["_encoder_out._replace", "func", "func", "len", "getattr", "torch.stack", "stack"], "function", ["None"], ["def", "ensemble_encoder", "(", "func", ")", ":", "\n", "    ", "def", "wrapper", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "ensemble_models", "is", "None", "or", "len", "(", "self", ".", "ensemble_models", ")", "==", "1", ":", "\n", "            ", "return", "func", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "encoder_outs", "=", "[", "func", "(", "model", ",", "*", "args", ",", "**", "kwargs", ")", "for", "model", "in", "self", ".", "ensemble_models", "]", "\n", "_encoder_out", "=", "encoder_outs", "[", "0", "]", "\n", "\n", "def", "stack", "(", "key", ")", ":", "\n", "            ", "outs", "=", "[", "getattr", "(", "e", ",", "key", ")", "for", "e", "in", "encoder_outs", "]", "\n", "return", "torch", ".", "stack", "(", "outs", ",", "-", "1", ")", "if", "outs", "[", "0", "]", "is", "not", "None", "else", "None", "\n", "\n", "", "return", "_encoder_out", ".", "_replace", "(", "\n", "encoder_out", "=", "stack", "(", "\"encoder_out\"", ")", ",", "\n", "encoder_embedding", "=", "stack", "(", "\"encoder_embedding\"", ")", ",", "\n", "encoder_states", "=", "stack", "(", "\"encoder_states\"", ")", ",", "\n", ")", "\n", "\n", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.fairseq_nat_model.ensemble_decoder": [[37, 81], ["range", "tuple", "func", "func", "isinstance", "len", "len", "len", "enumerate", "list", "encoder_out._replace", "torch.logsumexp", "math.log", "torch.stack", "torch.stack", "len"], "function", ["home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log"], ["", "def", "ensemble_decoder", "(", "func", ")", ":", "\n", "    ", "def", "wrapper", "(", "self", ",", "normalize", "=", "False", ",", "encoder_out", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "ensemble_models", "is", "None", "or", "len", "(", "self", ".", "ensemble_models", ")", "==", "1", ":", "\n", "            ", "return", "func", "(", "\n", "self", ",", "normalize", "=", "normalize", ",", "encoder_out", "=", "encoder_out", ",", "*", "args", ",", "**", "kwargs", "\n", ")", "\n", "\n", "", "action_outs", "=", "[", "\n", "func", "(", "\n", "model", ",", "\n", "normalize", "=", "normalize", ",", "\n", "encoder_out", "=", "encoder_out", ".", "_replace", "(", "\n", "encoder_out", "=", "encoder_out", ".", "encoder_out", "[", ":", ",", ":", ",", ":", ",", "i", "]", "\n", ")", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", "\n", ")", "\n", "for", "i", ",", "model", "in", "enumerate", "(", "self", ".", "ensemble_models", ")", "\n", "]", "\n", "\n", "if", "not", "isinstance", "(", "action_outs", "[", "0", "]", ",", "tuple", ")", ":", "# return multiple values", "\n", "            ", "action_outs", "=", "[", "[", "a", "]", "for", "a", "in", "action_outs", "]", "\n", "", "else", ":", "\n", "            ", "action_outs", "=", "[", "list", "(", "a", ")", "for", "a", "in", "action_outs", "]", "\n", "\n", "", "ensembled_outs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "action_outs", "[", "0", "]", ")", ")", ":", "\n", "            ", "if", "i", "==", "0", "and", "normalize", ":", "\n", "                ", "ensembled_outs", "+=", "[", "\n", "torch", ".", "logsumexp", "(", "\n", "torch", ".", "stack", "(", "[", "a", "[", "i", "]", "for", "a", "in", "action_outs", "]", ",", "-", "1", ")", ",", "dim", "=", "-", "1", "\n", ")", "\n", "-", "math", ".", "log", "(", "len", "(", "self", ".", "ensemble_models", ")", ")", "\n", "]", "\n", "", "elif", "action_outs", "[", "0", "]", "[", "i", "]", "is", "not", "None", ":", "\n", "                ", "ensembled_outs", "+=", "[", "torch", ".", "stack", "(", "[", "a", "[", "i", "]", "for", "a", "in", "action_outs", "]", ",", "-", "1", ")", "]", "\n", "", "else", ":", "\n", "                ", "ensembled_outs", "+=", "[", "None", "]", "\n", "\n", "", "", "if", "len", "(", "ensembled_outs", ")", "==", "1", ":", "\n", "            ", "return", "ensembled_outs", "[", "0", "]", "\n", "", "return", "tuple", "(", "ensembled_outs", ")", "\n", "\n", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles._EnsembleModelEncoder.__init__": [[21, 23], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "models", ")", ":", "\n", "        ", "self", ".", "models", "=", "models", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles._EnsembleModelEncoder.reorder_encoder_out": [[24, 30], ["model.encoder.reorder_encoder_out", "zip"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerEncoder.reorder_encoder_out"], ["", "def", "reorder_encoder_out", "(", "self", ",", "encoder_outs", ",", "new_order", ")", ":", "\n", "        ", "encoder_outs", "=", "[", "\n", "model", ".", "encoder", ".", "reorder_encoder_out", "(", "encoder_out", ",", "new_order", ")", "\n", "for", "model", ",", "encoder_out", "in", "zip", "(", "self", ".", "models", ",", "encoder_outs", ")", "\n", "]", "\n", "return", "encoder_outs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.BasicEnsembleModel.__init__": [[35, 43], ["super().__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "nonautoregressive_ensembles.BasicEnsembleModel.models[].decoder.dictionary.bos", "nonautoregressive_ensembles.BasicEnsembleModel.models[].decoder.dictionary.eos", "nonautoregressive_ensembles.BasicEnsembleModel.models[].decoder.dictionary.pad", "nonautoregressive_ensembles.BasicEnsembleModel.models[].decoder.dictionary.unk", "nonautoregressive_ensembles._EnsembleModelEncoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk"], ["def", "__init__", "(", "self", ",", "models", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "models", "=", "torch", ".", "nn", ".", "ModuleList", "(", "models", ")", "\n", "self", ".", "bos", "=", "self", ".", "models", "[", "0", "]", ".", "decoder", ".", "dictionary", ".", "bos", "(", ")", "\n", "self", ".", "eos", "=", "self", ".", "models", "[", "0", "]", ".", "decoder", ".", "dictionary", ".", "eos", "(", ")", "\n", "self", ".", "pad", "=", "self", ".", "models", "[", "0", "]", ".", "decoder", ".", "dictionary", ".", "pad", "(", ")", "\n", "self", ".", "unk", "=", "self", ".", "models", "[", "0", "]", ".", "decoder", ".", "dictionary", ".", "unk", "(", ")", "\n", "self", ".", "encoder", "=", "_EnsembleModelEncoder", "(", "self", ".", "models", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.BasicEnsembleModel.has_encoder": [[44, 46], ["hasattr"], "methods", ["None"], ["", "def", "has_encoder", "(", "self", ")", ":", "\n", "        ", "return", "hasattr", "(", "self", ".", "models", "[", "0", "]", ",", "\"encoder\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.BasicEnsembleModel.max_decoder_positions": [[47, 49], ["min", "m.max_decoder_positions"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.max_decoder_positions"], ["", "def", "max_decoder_positions", "(", "self", ")", ":", "\n", "        ", "return", "min", "(", "m", ".", "max_decoder_positions", "(", ")", "for", "m", "in", "self", ".", "models", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.BasicEnsembleModel.forward_encoder": [[50, 55], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "nonautoregressive_ensembles.BasicEnsembleModel.has_encoder", "model.forward_encoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.BasicEnsembleModel.has_encoder", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.BasicEnsembleModel.forward_encoder"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "forward_encoder", "(", "self", ",", "encoder_input", ")", ":", "\n", "        ", "if", "not", "self", ".", "has_encoder", "(", ")", ":", "\n", "            ", "return", "None", "\n", "", "return", "[", "model", ".", "forward_encoder", "(", "encoder_input", ")", "for", "model", "in", "self", ".", "models", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.BasicEnsembleModel.forward_decoder": [[56, 59], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "forward_decoder", "(", "self", ",", "*", "inputs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.BasicEnsembleModel.initialize_output_tokens": [[60, 62], ["None"], "methods", ["None"], ["", "def", "initialize_output_tokens", "(", "self", ",", "*", "inputs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.__init__": [[67, 69], ["nonautoregressive_ensembles.BasicEnsembleModel.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "models", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "models", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_decoder": [[70, 141], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "output_tokens.size", "output_tokens.ne().sum().max", "decoder_out._replace", "output_tokens.new().fill_", "output_tokens.ne().sum", "can_del_word.sum", "nonautoregressive_ensembles.EnsembleLevT.forward_word_del", "output_tokens.ne().sum", "can_ins_mask.sum", "nonautoregressive_ensembles.EnsembleLevT.forward_mask_ins", "output_tokens.eq().sum", "can_ins_word.sum", "nonautoregressive_ensembles.EnsembleLevT.forward_word_ins", "encoder_outs[].encoder_out.new().fill_", "output_tokens.ne().sum", "output_tokens.new", "encoder_outs[].encoder_out.size", "output_tokens.ne", "output_tokens.ne", "output_tokens.eq", "encoder_outs[].encoder_out.new", "output_tokens.ne"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_word_del", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_mask_ins", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_word_ins", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "forward_decoder", "(", "\n", "self", ",", "decoder_out", ",", "encoder_outs", ",", "eos_penalty", "=", "0.0", ",", "max_ratio", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "# LevT ensembling", "\n", "# A pipeline of three steps: deletion, placeholder, and word insertion.", "\n", "# We need to average scores in each step in a pipeline way because of dependence.", "\n", "# deletion", "\n", "        ", "output_tokens", "=", "decoder_out", ".", "output_tokens", "\n", "output_scores", "=", "decoder_out", ".", "output_scores", "\n", "attn", "=", "decoder_out", ".", "attn", "\n", "\n", "bsz", "=", "output_tokens", ".", "size", "(", "0", ")", "\n", "if", "max_ratio", "is", "None", ":", "\n", "            ", "max_lens", "=", "output_tokens", ".", "new", "(", ")", ".", "fill_", "(", "255", ")", "\n", "", "else", ":", "\n", "            ", "if", "encoder_outs", "[", "0", "]", ".", "encoder_padding_mask", "is", "None", ":", "\n", "                ", "src_lens", "=", "(", "\n", "encoder_outs", "[", "0", "]", "\n", ".", "encoder_out", ".", "new", "(", "bsz", ")", "\n", ".", "fill_", "(", "encoder_outs", "[", "0", "]", ".", "encoder_out", ".", "size", "(", "1", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "src_lens", "=", "(", "~", "encoder_outs", "[", "0", "]", ".", "encoder_padding_mask", ")", ".", "sum", "(", "1", ")", "\n", "", "max_lens", "=", "(", "src_lens", "*", "max_ratio", ")", ".", "clamp", "(", "min", "=", "10", ")", ".", "long", "(", ")", "\n", "\n", "# delete words", "\n", "# do not delete tokens if it is <s> </s>", "\n", "", "can_del_word", "=", "output_tokens", ".", "ne", "(", "self", ".", "pad", ")", ".", "sum", "(", "1", ")", ">", "2", "\n", "if", "can_del_word", ".", "sum", "(", ")", "!=", "0", ":", "# we cannot delete, skip", "\n", "            ", "output_tokens", ",", "output_scores", ",", "attn", "=", "self", ".", "forward_word_del", "(", "\n", "encoder_outs", ",", "\n", "output_tokens", ",", "\n", "output_scores", ",", "\n", "attn", ",", "\n", "can_del_word", ",", "\n", ")", "\n", "\n", "# insert placeholders", "\n", "", "can_ins_mask", "=", "output_tokens", ".", "ne", "(", "self", ".", "pad", ")", ".", "sum", "(", "1", ")", "<", "max_lens", "\n", "if", "can_ins_mask", ".", "sum", "(", ")", "!=", "0", ":", "\n", "            ", "output_tokens", ",", "output_scores", "=", "self", ".", "forward_mask_ins", "(", "\n", "encoder_outs", ",", "\n", "output_tokens", ",", "\n", "output_scores", ",", "\n", "can_ins_mask", ",", "\n", "eos_penalty", ",", "\n", "max_lens", ",", "\n", ")", "\n", "\n", "# insert words", "\n", "", "can_ins_word", "=", "output_tokens", ".", "eq", "(", "self", ".", "unk", ")", ".", "sum", "(", "1", ")", ">", "0", "\n", "if", "can_ins_word", ".", "sum", "(", ")", "!=", "0", ":", "\n", "            ", "output_tokens", ",", "output_scores", ",", "attn", "=", "self", ".", "forward_word_ins", "(", "\n", "encoder_outs", ",", "\n", "output_tokens", ",", "\n", "output_scores", ",", "\n", "attn", ",", "\n", "can_ins_word", ",", "\n", ")", "\n", "\n", "# delete some unnecessary paddings", "\n", "", "cut_off", "=", "output_tokens", ".", "ne", "(", "self", ".", "pad", ")", ".", "sum", "(", "1", ")", ".", "max", "(", ")", "\n", "output_tokens", "=", "output_tokens", "[", ":", ",", ":", "cut_off", "]", "\n", "output_scores", "=", "output_scores", "[", ":", ",", ":", "cut_off", "]", "\n", "attn", "=", "None", "if", "attn", "is", "None", "else", "attn", "[", ":", ",", ":", "cut_off", ",", ":", "]", "\n", "return", "decoder_out", ".", "_replace", "(", "\n", "output_tokens", "=", "output_tokens", ",", "\n", "output_scores", "=", "output_scores", ",", "\n", "attn", "=", "attn", ",", "\n", "history", "=", "None", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_word_del": [[143, 178], ["zip", "[].bool", "fairseq.models.nat._apply_del_words", "fairseq.models.nat._fill", "fairseq.models.nat._fill", "fairseq.models.nat._fill", "model.decoder.forward_word_del", "torch.log_softmax", "torch.log_softmax", "word_del_score_avg.append", "word_del_attn_avg.append", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "math.log", "fairseq.models.nat._skip", "fairseq.models.nat._skip_encoder_out", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "len", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "len", "word_del_score_avg.max"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._apply_del_words", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._fill", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._fill", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._fill", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_word_del", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._skip", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._skip_encoder_out"], ["", "def", "forward_word_del", "(", "\n", "self", ",", "encoder_outs", ",", "output_tokens", ",", "output_scores", ",", "attn", ",", "can_del_word", "\n", ")", ":", "\n", "        ", "word_del_score_avg", "=", "[", "]", "\n", "word_del_attn_avg", "=", "[", "]", "\n", "for", "model", ",", "encoder_out", "in", "zip", "(", "self", ".", "models", ",", "encoder_outs", ")", ":", "\n", "            ", "word_del_out", ",", "word_del_attn", "=", "model", ".", "decoder", ".", "forward_word_del", "(", "\n", "_skip", "(", "output_tokens", ",", "can_del_word", ")", ",", "\n", "_skip_encoder_out", "(", "model", ".", "encoder", ",", "encoder_out", ",", "can_del_word", ")", ",", "\n", ")", "\n", "word_del_score", "=", "F", ".", "log_softmax", "(", "word_del_out", ",", "2", ")", "\n", "word_del_score_avg", ".", "append", "(", "word_del_score", ")", "\n", "word_del_attn_avg", ".", "append", "(", "word_del_attn", ")", "\n", "", "word_del_score_avg", "=", "torch", ".", "logsumexp", "(", "\n", "torch", ".", "stack", "(", "word_del_score_avg", ",", "dim", "=", "0", ")", ",", "dim", "=", "0", "\n", ")", "-", "math", ".", "log", "(", "len", "(", "self", ".", "models", ")", ")", "\n", "word_del_pred", "=", "word_del_score_avg", ".", "max", "(", "-", "1", ")", "[", "1", "]", ".", "bool", "(", ")", "\n", "if", "word_del_attn_avg", "[", "0", "]", "is", "not", "None", ":", "\n", "            ", "word_del_attn_avg", "=", "torch", ".", "stack", "(", "word_del_attn_avg", ",", "dim", "=", "0", ")", "/", "len", "(", "self", ".", "models", ")", "\n", "", "else", ":", "\n", "            ", "word_del_attn_avg", "=", "None", "\n", "\n", "", "_tokens", ",", "_scores", ",", "_attn", "=", "_apply_del_words", "(", "\n", "output_tokens", "[", "can_del_word", "]", ",", "\n", "output_scores", "[", "can_del_word", "]", ",", "\n", "word_del_attn_avg", ",", "\n", "word_del_pred", ",", "\n", "self", ".", "pad", ",", "\n", "self", ".", "bos", ",", "\n", "self", ".", "eos", ",", "\n", ")", "\n", "output_tokens", "=", "_fill", "(", "output_tokens", ",", "can_del_word", ",", "_tokens", ",", "self", ".", "pad", ")", "\n", "output_scores", "=", "_fill", "(", "output_scores", ",", "can_del_word", ",", "_scores", ",", "0", ")", "\n", "attn", "=", "_fill", "(", "attn", ",", "can_del_word", ",", "_attn", ",", "0.0", ")", "\n", "return", "output_tokens", ",", "output_scores", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_mask_ins": [[179, 216], ["zip", "torch.min", "torch.min", "torch.min", "torch.min", "fairseq.models.nat._apply_ins_masks", "fairseq.models.nat._fill", "fairseq.models.nat._fill", "model.decoder.forward_mask_ins", "torch.log_softmax", "torch.log_softmax", "mask_ins_score_avg.append", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "math.log", "mask_ins_score_avg.max", "max_lens[].expand_as", "fairseq.models.nat._skip", "fairseq.models.nat._skip_encoder_out", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._apply_ins_masks", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._fill", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._fill", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_mask_ins", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._skip", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._skip_encoder_out"], ["", "def", "forward_mask_ins", "(", "\n", "self", ",", "\n", "encoder_outs", ",", "\n", "output_tokens", ",", "\n", "output_scores", ",", "\n", "can_ins_mask", ",", "\n", "eos_penalty", ",", "\n", "max_lens", ",", "\n", ")", ":", "\n", "        ", "mask_ins_score_avg", "=", "[", "]", "\n", "for", "model", ",", "encoder_out", "in", "zip", "(", "self", ".", "models", ",", "encoder_outs", ")", ":", "\n", "            ", "mask_ins_out", ",", "_", "=", "model", ".", "decoder", ".", "forward_mask_ins", "(", "\n", "_skip", "(", "output_tokens", ",", "can_ins_mask", ")", ",", "\n", "_skip_encoder_out", "(", "model", ".", "encoder", ",", "encoder_out", ",", "can_ins_mask", ")", ",", "\n", ")", "\n", "mask_ins_score", "=", "F", ".", "log_softmax", "(", "mask_ins_out", ",", "2", ")", "\n", "if", "eos_penalty", ">", "0.0", ":", "\n", "                ", "mask_ins_score", "[", ":", ",", ":", ",", "0", "]", "-=", "eos_penalty", "\n", "", "mask_ins_score_avg", ".", "append", "(", "mask_ins_score", ")", "\n", "", "mask_ins_score_avg", "=", "torch", ".", "logsumexp", "(", "\n", "torch", ".", "stack", "(", "mask_ins_score_avg", ",", "dim", "=", "0", ")", ",", "dim", "=", "0", "\n", ")", "-", "math", ".", "log", "(", "len", "(", "self", ".", "models", ")", ")", "\n", "mask_ins_pred", "=", "mask_ins_score_avg", ".", "max", "(", "-", "1", ")", "[", "1", "]", "\n", "mask_ins_pred", "=", "torch", ".", "min", "(", "\n", "mask_ins_pred", ",", "max_lens", "[", "can_ins_mask", ",", "None", "]", ".", "expand_as", "(", "mask_ins_pred", ")", "\n", ")", "\n", "_tokens", ",", "_scores", "=", "_apply_ins_masks", "(", "\n", "output_tokens", "[", "can_ins_mask", "]", ",", "\n", "output_scores", "[", "can_ins_mask", "]", ",", "\n", "mask_ins_pred", ",", "\n", "self", ".", "pad", ",", "\n", "self", ".", "unk", ",", "\n", "self", ".", "eos", ",", "\n", ")", "\n", "output_tokens", "=", "_fill", "(", "output_tokens", ",", "can_ins_mask", ",", "_tokens", ",", "self", ".", "pad", ")", "\n", "output_scores", "=", "_fill", "(", "output_scores", ",", "can_ins_mask", ",", "_scores", ",", "0", ")", "\n", "return", "output_tokens", ",", "output_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_word_ins": [[217, 251], ["zip", "word_ins_score_avg.max", "fairseq.models.nat._apply_ins_words", "fairseq.models.nat._fill", "fairseq.models.nat._fill", "fairseq.models.nat._fill", "model.decoder.forward_word_ins", "torch.log_softmax", "torch.log_softmax", "word_ins_score_avg.append", "word_ins_attn_avg.append", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "math.log", "fairseq.models.nat._skip", "fairseq.models.nat._skip_encoder_out", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "len", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._apply_ins_words", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._fill", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._fill", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._fill", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.forward_word_ins", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.reneeye_const.modules.dynamic_crf_layer.logsumexp", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._skip", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._skip_encoder_out"], ["", "def", "forward_word_ins", "(", "\n", "self", ",", "encoder_outs", ",", "output_tokens", ",", "output_scores", ",", "attn", ",", "can_ins_word", "\n", ")", ":", "\n", "        ", "word_ins_score_avg", "=", "[", "]", "\n", "word_ins_attn_avg", "=", "[", "]", "\n", "for", "model", ",", "encoder_out", "in", "zip", "(", "self", ".", "models", ",", "encoder_outs", ")", ":", "\n", "            ", "word_ins_out", ",", "word_ins_attn", "=", "model", ".", "decoder", ".", "forward_word_ins", "(", "\n", "_skip", "(", "output_tokens", ",", "can_ins_word", ")", ",", "\n", "_skip_encoder_out", "(", "model", ".", "encoder", ",", "encoder_out", ",", "can_ins_word", ")", ",", "\n", ")", "\n", "word_ins_score", "=", "F", ".", "log_softmax", "(", "word_ins_out", ",", "2", ")", "\n", "word_ins_score_avg", ".", "append", "(", "word_ins_score", ")", "\n", "word_ins_attn_avg", ".", "append", "(", "word_ins_attn", ")", "\n", "", "word_ins_score_avg", "=", "torch", ".", "logsumexp", "(", "\n", "torch", ".", "stack", "(", "word_ins_score_avg", ",", "dim", "=", "0", ")", ",", "dim", "=", "0", "\n", ")", "-", "math", ".", "log", "(", "len", "(", "self", ".", "models", ")", ")", "\n", "if", "word_ins_attn_avg", "[", "0", "]", "is", "not", "None", ":", "\n", "            ", "word_ins_attn_avg", "=", "torch", ".", "stack", "(", "word_ins_attn_avg", ",", "dim", "=", "0", ")", "/", "len", "(", "self", ".", "models", ")", "\n", "", "else", ":", "\n", "            ", "word_ins_attn_avg", "=", "None", "\n", "", "word_ins_score_max", ",", "word_ins_pred", "=", "word_ins_score_avg", ".", "max", "(", "-", "1", ")", "\n", "\n", "_tokens", ",", "_scores", "=", "_apply_ins_words", "(", "\n", "output_tokens", "[", "can_ins_word", "]", ",", "\n", "output_scores", "[", "can_ins_word", "]", ",", "\n", "word_ins_pred", ",", "\n", "word_ins_score_max", ",", "\n", "self", ".", "unk", ",", "\n", ")", "\n", "\n", "output_tokens", "=", "_fill", "(", "output_tokens", ",", "can_ins_word", ",", "_tokens", ",", "self", ".", "pad", ")", "\n", "output_scores", "=", "_fill", "(", "output_scores", ",", "can_ins_word", ",", "_scores", ",", "0", ")", "\n", "attn", "=", "_fill", "(", "attn", ",", "can_ins_word", ",", "word_ins_attn", ",", "0.0", ")", "\n", "return", "output_tokens", ",", "output_scores", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.initialize_output_tokens": [[252, 255], ["nonautoregressive_ensembles.EnsembleLevT.models[].initialize_output_tokens"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_ensembles.EnsembleLevT.initialize_output_tokens"], ["", "def", "initialize_output_tokens", "(", "self", ",", "encoder_outs", ",", "src_tokens", ")", ":", "\n", "# LevT doesn't do length prediction.", "\n", "        ", "return", "self", ".", "models", "[", "0", "]", ".", "initialize_output_tokens", "(", "encoder_outs", "[", "0", "]", ",", "src_tokens", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils.load_libnat": [[13, 34], ["print", "str", "sys.stderr.write"], "function", ["home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print"], ["def", "load_libnat", "(", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "from", "fairseq", "import", "libnat_cuda", "\n", "\n", "return", "libnat_cuda", ",", "True", "\n", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "        ", "print", "(", "str", "(", "e", ")", "+", "\"... fall back to CPU version\"", ")", "\n", "\n", "try", ":", "\n", "            ", "from", "fairseq", "import", "libnat", "\n", "\n", "return", "libnat", ",", "False", "\n", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "            ", "import", "sys", "\n", "\n", "sys", ".", "stderr", ".", "write", "(", "\n", "\"ERROR: missing libnat_cuda. run `python setup.py build_ext --inplace`\\n\"", "\n", ")", "\n", "raise", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._get_ins_targets": [[36, 102], ["levenshtein_utils.load_libnat", "levenshtein_utils._get_ins_targets._get_ins_targets_cpu"], "function", ["home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils.load_libnat"], ["", "", "", "def", "_get_ins_targets", "(", "in_tokens", ",", "out_tokens", ",", "padding_idx", ",", "unk_idx", ")", ":", "\n", "    ", "libnat", ",", "use_cuda", "=", "load_libnat", "(", ")", "\n", "\n", "def", "_get_ins_targets_cuda", "(", "in_tokens", ",", "out_tokens", ",", "padding_idx", ",", "unk_idx", ")", ":", "\n", "        ", "in_masks", "=", "in_tokens", ".", "ne", "(", "padding_idx", ")", "\n", "out_masks", "=", "out_tokens", ".", "ne", "(", "padding_idx", ")", "\n", "mask_ins_targets", ",", "masked_tgt_masks", "=", "libnat", ".", "generate_insertion_labels", "(", "\n", "out_tokens", ".", "int", "(", ")", ",", "\n", "libnat", ".", "levenshtein_distance", "(", "\n", "in_tokens", ".", "int", "(", ")", ",", "\n", "out_tokens", ".", "int", "(", ")", ",", "\n", "in_masks", ".", "sum", "(", "1", ")", ".", "int", "(", ")", ",", "\n", "out_masks", ".", "sum", "(", "1", ")", ".", "int", "(", ")", ",", "\n", ")", ",", "\n", ")", "\n", "masked_tgt_masks", "=", "masked_tgt_masks", ".", "bool", "(", ")", "&", "out_masks", "\n", "mask_ins_targets", "=", "mask_ins_targets", ".", "type_as", "(", "in_tokens", ")", "[", "\n", ":", ",", "1", ":", "in_masks", ".", "size", "(", "1", ")", "\n", "]", ".", "masked_fill_", "(", "~", "in_masks", "[", ":", ",", "1", ":", "]", ",", "0", ")", "\n", "masked_tgt_tokens", "=", "out_tokens", ".", "masked_fill", "(", "masked_tgt_masks", ",", "unk_idx", ")", "\n", "return", "masked_tgt_masks", ",", "masked_tgt_tokens", ",", "mask_ins_targets", "\n", "\n", "", "def", "_get_ins_targets_cpu", "(", "in_tokens", ",", "out_tokens", ",", "padding_idx", ",", "unk_idx", ")", ":", "\n", "        ", "in_seq_len", ",", "out_seq_len", "=", "in_tokens", ".", "size", "(", "1", ")", ",", "out_tokens", ".", "size", "(", "1", ")", "\n", "\n", "in_tokens_list", "=", "[", "\n", "[", "t", "for", "t", "in", "s", "if", "t", "!=", "padding_idx", "]", "for", "i", ",", "s", "in", "enumerate", "(", "in_tokens", ".", "tolist", "(", ")", ")", "\n", "]", "\n", "out_tokens_list", "=", "[", "\n", "[", "t", "for", "t", "in", "s", "if", "t", "!=", "padding_idx", "]", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "out_tokens", ".", "tolist", "(", ")", ")", "\n", "]", "\n", "\n", "full_labels", "=", "libnat", ".", "suggested_ed2_path", "(", "\n", "in_tokens_list", ",", "out_tokens_list", ",", "padding_idx", "\n", ")", "\n", "mask_inputs", "=", "[", "\n", "[", "len", "(", "c", ")", "if", "c", "[", "0", "]", "!=", "padding_idx", "else", "0", "for", "c", "in", "a", "[", ":", "-", "1", "]", "]", "for", "a", "in", "full_labels", "\n", "]", "\n", "\n", "# generate labels", "\n", "masked_tgt_masks", "=", "[", "]", "\n", "for", "mask_input", "in", "mask_inputs", ":", "\n", "            ", "mask_label", "=", "[", "]", "\n", "for", "beam_size", "in", "mask_input", "[", "1", ":", "-", "1", "]", ":", "# HACK 1:-1", "\n", "                ", "mask_label", "+=", "[", "0", "]", "+", "[", "1", "for", "_", "in", "range", "(", "beam_size", ")", "]", "\n", "", "masked_tgt_masks", ".", "append", "(", "\n", "mask_label", "+", "[", "0", "for", "_", "in", "range", "(", "out_seq_len", "-", "len", "(", "mask_label", ")", ")", "]", "\n", ")", "\n", "", "mask_ins_targets", "=", "[", "\n", "mask_input", "[", "1", ":", "-", "1", "]", "\n", "+", "[", "0", "for", "_", "in", "range", "(", "in_seq_len", "-", "1", "-", "len", "(", "mask_input", "[", "1", ":", "-", "1", "]", ")", ")", "]", "\n", "for", "mask_input", "in", "mask_inputs", "\n", "]", "\n", "\n", "# transform to tensor", "\n", "masked_tgt_masks", "=", "torch", ".", "tensor", "(", "\n", "masked_tgt_masks", ",", "device", "=", "out_tokens", ".", "device", "\n", ")", ".", "bool", "(", ")", "\n", "mask_ins_targets", "=", "torch", ".", "tensor", "(", "mask_ins_targets", ",", "device", "=", "in_tokens", ".", "device", ")", "\n", "masked_tgt_tokens", "=", "out_tokens", ".", "masked_fill", "(", "masked_tgt_masks", ",", "unk_idx", ")", "\n", "return", "masked_tgt_masks", ",", "masked_tgt_tokens", ",", "mask_ins_targets", "\n", "\n", "", "if", "use_cuda", ":", "\n", "        ", "return", "_get_ins_targets_cuda", "(", "in_tokens", ",", "out_tokens", ",", "padding_idx", ",", "unk_idx", ")", "\n", "", "return", "_get_ins_targets_cpu", "(", "in_tokens", ",", "out_tokens", ",", "padding_idx", ",", "unk_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._get_del_targets": [[104, 153], ["levenshtein_utils.load_libnat", "levenshtein_utils._get_del_targets._get_del_targets_cpu"], "function", ["home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils.load_libnat"], ["", "def", "_get_del_targets", "(", "in_tokens", ",", "out_tokens", ",", "padding_idx", ")", ":", "\n", "    ", "libnat", ",", "use_cuda", "=", "load_libnat", "(", ")", "\n", "\n", "def", "_get_del_targets_cuda", "(", "in_tokens", ",", "out_tokens", ",", "padding_idx", ")", ":", "\n", "        ", "in_masks", "=", "in_tokens", ".", "ne", "(", "padding_idx", ")", "\n", "out_masks", "=", "out_tokens", ".", "ne", "(", "padding_idx", ")", "\n", "\n", "word_del_targets", "=", "libnat", ".", "generate_deletion_labels", "(", "\n", "in_tokens", ".", "int", "(", ")", ",", "\n", "libnat", ".", "levenshtein_distance", "(", "\n", "in_tokens", ".", "int", "(", ")", ",", "\n", "out_tokens", ".", "int", "(", ")", ",", "\n", "in_masks", ".", "sum", "(", "1", ")", ".", "int", "(", ")", ",", "\n", "out_masks", ".", "sum", "(", "1", ")", ".", "int", "(", ")", ",", "\n", ")", ",", "\n", ")", "\n", "word_del_targets", "=", "word_del_targets", ".", "type_as", "(", "in_tokens", ")", ".", "masked_fill_", "(", "\n", "~", "in_masks", ",", "0", "\n", ")", "\n", "return", "word_del_targets", "\n", "\n", "", "def", "_get_del_targets_cpu", "(", "in_tokens", ",", "out_tokens", ",", "padding_idx", ")", ":", "\n", "        ", "out_seq_len", "=", "out_tokens", ".", "size", "(", "1", ")", "\n", "with", "torch", ".", "cuda", ".", "device_of", "(", "in_tokens", ")", ":", "\n", "            ", "in_tokens_list", "=", "[", "\n", "[", "t", "for", "t", "in", "s", "if", "t", "!=", "padding_idx", "]", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "in_tokens", ".", "tolist", "(", ")", ")", "\n", "]", "\n", "out_tokens_list", "=", "[", "\n", "[", "t", "for", "t", "in", "s", "if", "t", "!=", "padding_idx", "]", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "out_tokens", ".", "tolist", "(", ")", ")", "\n", "]", "\n", "\n", "", "full_labels", "=", "libnat", ".", "suggested_ed2_path", "(", "\n", "in_tokens_list", ",", "out_tokens_list", ",", "padding_idx", "\n", ")", "\n", "word_del_targets", "=", "[", "b", "[", "-", "1", "]", "for", "b", "in", "full_labels", "]", "\n", "word_del_targets", "=", "[", "\n", "labels", "+", "[", "0", "for", "_", "in", "range", "(", "out_seq_len", "-", "len", "(", "labels", ")", ")", "]", "\n", "for", "labels", "in", "word_del_targets", "\n", "]", "\n", "\n", "# transform to tensor", "\n", "word_del_targets", "=", "torch", ".", "tensor", "(", "word_del_targets", ",", "device", "=", "out_tokens", ".", "device", ")", "\n", "return", "word_del_targets", "\n", "\n", "", "if", "use_cuda", ":", "\n", "        ", "return", "_get_del_targets_cuda", "(", "in_tokens", ",", "out_tokens", ",", "padding_idx", ")", "\n", "", "return", "_get_del_targets_cpu", "(", "in_tokens", ",", "out_tokens", ",", "padding_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._apply_ins_masks": [[155, 187], ["in_tokens.ne", "in_tokens.ne.sum", "in_tokens.masked_fill_", "mask_ins_pred.masked_fill_", "out_lengths.max", "in_tokens.new_zeros().fill_().masked_fill_", "in_tokens.new_zeros().fill_().masked_fill_.scatter_", "mask_ins_pred.sum", "in_scores.masked_fill_", "in_scores.new_zeros", "in_scores.new_zeros.scatter_", "fairseq.utils.new_arange", "in_tokens.new_zeros().fill_", "in_masks[].long", "in_tokens.new_zeros().fill_().masked_fill_.size", "in_tokens.new_zeros", "in_tokens.size"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.new_arange", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "_apply_ins_masks", "(", "\n", "in_tokens", ",", "in_scores", ",", "mask_ins_pred", ",", "padding_idx", ",", "unk_idx", ",", "eos_idx", "\n", ")", ":", "\n", "\n", "    ", "in_masks", "=", "in_tokens", ".", "ne", "(", "padding_idx", ")", "\n", "in_lengths", "=", "in_masks", ".", "sum", "(", "1", ")", "\n", "\n", "# HACK: hacky way to shift all the paddings to eos first.", "\n", "in_tokens", ".", "masked_fill_", "(", "~", "in_masks", ",", "eos_idx", ")", "\n", "mask_ins_pred", ".", "masked_fill_", "(", "~", "in_masks", "[", ":", ",", "1", ":", "]", ",", "0", ")", "\n", "\n", "out_lengths", "=", "in_lengths", "+", "mask_ins_pred", ".", "sum", "(", "1", ")", "\n", "out_max_len", "=", "out_lengths", ".", "max", "(", ")", "\n", "out_masks", "=", "new_arange", "(", "out_lengths", ",", "out_max_len", ")", "[", "None", ",", ":", "]", "<", "out_lengths", "[", ":", ",", "None", "]", "\n", "\n", "reordering", "=", "(", "mask_ins_pred", "+", "in_masks", "[", ":", ",", "1", ":", "]", ".", "long", "(", ")", ")", ".", "cumsum", "(", "1", ")", "\n", "out_tokens", "=", "(", "\n", "in_tokens", ".", "new_zeros", "(", "in_tokens", ".", "size", "(", "0", ")", ",", "out_max_len", ")", "\n", ".", "fill_", "(", "padding_idx", ")", "\n", ".", "masked_fill_", "(", "out_masks", ",", "unk_idx", ")", "\n", ")", "\n", "out_tokens", "[", ":", ",", "0", "]", "=", "in_tokens", "[", ":", ",", "0", "]", "\n", "out_tokens", ".", "scatter_", "(", "1", ",", "reordering", ",", "in_tokens", "[", ":", ",", "1", ":", "]", ")", "\n", "\n", "out_scores", "=", "None", "\n", "if", "in_scores", "is", "not", "None", ":", "\n", "        ", "in_scores", ".", "masked_fill_", "(", "~", "in_masks", ",", "0", ")", "\n", "out_scores", "=", "in_scores", ".", "new_zeros", "(", "*", "out_tokens", ".", "size", "(", ")", ")", "\n", "out_scores", "[", ":", ",", "0", "]", "=", "in_scores", "[", ":", ",", "0", "]", "\n", "out_scores", ".", "scatter_", "(", "1", ",", "reordering", ",", "in_scores", "[", ":", ",", "1", ":", "]", ")", "\n", "\n", "", "return", "out_tokens", ",", "out_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._apply_ins_words": [[189, 201], ["in_tokens.eq", "in_tokens.masked_scatter", "in_scores.masked_scatter"], "function", ["None"], ["", "def", "_apply_ins_words", "(", "in_tokens", ",", "in_scores", ",", "word_ins_pred", ",", "word_ins_scores", ",", "unk_idx", ")", ":", "\n", "    ", "word_ins_masks", "=", "in_tokens", ".", "eq", "(", "unk_idx", ")", "\n", "out_tokens", "=", "in_tokens", ".", "masked_scatter", "(", "word_ins_masks", ",", "word_ins_pred", "[", "word_ins_masks", "]", ")", "\n", "\n", "if", "in_scores", "is", "not", "None", ":", "\n", "        ", "out_scores", "=", "in_scores", ".", "masked_scatter", "(", "\n", "word_ins_masks", ",", "word_ins_scores", "[", "word_ins_masks", "]", "\n", ")", "\n", "", "else", ":", "\n", "        ", "out_scores", "=", "None", "\n", "\n", "", "return", "out_tokens", ",", "out_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._apply_del_words": [[203, 229], ["in_tokens.ne", "in_tokens.size", "word_del_pred.masked_fill_", "word_del_pred.masked_fill_", "in_tokens.masked_fill().gather", "in_tokens.eq", "in_tokens.eq", "fairseq.utils.new_arange().masked_fill_().sort", "in_scores.masked_fill().gather", "word_del_pred[].expand_as", "reordering[].expand_as", "in_attn.masked_fill().gather", "in_tokens.masked_fill", "fairseq.utils.new_arange().masked_fill_", "in_scores.masked_fill", "in_attn.masked_fill", "fairseq.utils.new_arange"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.new_arange"], ["", "def", "_apply_del_words", "(", "\n", "in_tokens", ",", "in_scores", ",", "in_attn", ",", "word_del_pred", ",", "padding_idx", ",", "bos_idx", ",", "eos_idx", "\n", ")", ":", "\n", "# apply deletion to a tensor", "\n", "    ", "in_masks", "=", "in_tokens", ".", "ne", "(", "padding_idx", ")", "\n", "bos_eos_masks", "=", "in_tokens", ".", "eq", "(", "bos_idx", ")", "|", "in_tokens", ".", "eq", "(", "eos_idx", ")", "\n", "\n", "max_len", "=", "in_tokens", ".", "size", "(", "1", ")", "\n", "word_del_pred", ".", "masked_fill_", "(", "~", "in_masks", ",", "1", ")", "\n", "word_del_pred", ".", "masked_fill_", "(", "bos_eos_masks", ",", "0", ")", "\n", "\n", "reordering", "=", "new_arange", "(", "in_tokens", ")", ".", "masked_fill_", "(", "word_del_pred", ",", "max_len", ")", ".", "sort", "(", "1", ")", "[", "1", "]", "\n", "\n", "out_tokens", "=", "in_tokens", ".", "masked_fill", "(", "word_del_pred", ",", "padding_idx", ")", ".", "gather", "(", "1", ",", "reordering", ")", "\n", "\n", "out_scores", "=", "None", "\n", "if", "in_scores", "is", "not", "None", ":", "\n", "        ", "out_scores", "=", "in_scores", ".", "masked_fill", "(", "word_del_pred", ",", "0", ")", ".", "gather", "(", "1", ",", "reordering", ")", "\n", "\n", "", "out_attn", "=", "None", "\n", "if", "in_attn", "is", "not", "None", ":", "\n", "        ", "_mask", "=", "word_del_pred", "[", ":", ",", ":", ",", "None", "]", ".", "expand_as", "(", "in_attn", ")", "\n", "_reordering", "=", "reordering", "[", ":", ",", ":", ",", "None", "]", ".", "expand_as", "(", "in_attn", ")", "\n", "out_attn", "=", "in_attn", ".", "masked_fill", "(", "_mask", ",", "0.0", ")", ".", "gather", "(", "1", ",", "_reordering", ")", "\n", "\n", "", "return", "out_tokens", ",", "out_scores", ",", "out_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._skip": [[231, 254], ["isinstance", "isinstance", "isinstance", "isinstance", "x.size", "mask.size", "levenshtein_utils._skip", "levenshtein_utils._skip", "x.size", "mask.size", "x.items"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._skip", "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._skip", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "_skip", "(", "x", ",", "mask", ")", ":", "\n", "    ", "\"\"\"\n    Getting sliced (dim=0) tensor by mask. Supporting tensor and list/dict of tensors.\n    \"\"\"", "\n", "if", "isinstance", "(", "x", ",", "int", ")", ":", "\n", "        ", "return", "x", "\n", "\n", "", "if", "x", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "if", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "if", "x", ".", "size", "(", "0", ")", "==", "mask", ".", "size", "(", "0", ")", ":", "\n", "            ", "return", "x", "[", "mask", "]", "\n", "", "elif", "x", ".", "size", "(", "1", ")", "==", "mask", ".", "size", "(", "0", ")", ":", "\n", "            ", "return", "x", "[", ":", ",", "mask", "]", "\n", "\n", "", "", "if", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "        ", "return", "[", "_skip", "(", "x_i", ",", "mask", ")", "for", "x_i", "in", "x", "]", "\n", "\n", "", "if", "isinstance", "(", "x", ",", "dict", ")", ":", "\n", "        ", "return", "{", "k", ":", "_skip", "(", "v", ",", "mask", ")", "for", "k", ",", "v", "in", "x", ".", "items", "(", ")", "}", "\n", "\n", "", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._skip_encoder_out": [[256, 262], ["mask.any", "encoder.reorder_encoder_out", "mask.nonzero().squeeze", "mask.nonzero"], "function", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerEncoder.reorder_encoder_out"], ["", "def", "_skip_encoder_out", "(", "encoder", ",", "encoder_out", ",", "mask", ")", ":", "\n", "    ", "if", "not", "mask", ".", "any", "(", ")", ":", "\n", "        ", "return", "encoder_out", "\n", "", "else", ":", "\n", "        ", "return", "encoder", ".", "reorder_encoder_out", "(", "\n", "encoder_out", ",", "mask", ".", "nonzero", "(", "as_tuple", "=", "False", ")", ".", "squeeze", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.levenshtein_utils._fill": [[265, 294], ["mask.sum", "y.size", "torch.cat.size", "torch.cat.size", "y.size", "torch.cat", "torch.cat.dim", "y.dim", "mask.size", "torch.cat.size", "torch.cat.dim", "torch.cat.size", "torch.cat.dim", "dims.append", "torch.cat.size", "y.size", "torch.cat.dim", "torch.cat.size", "y.size", "y.size", "torch.cat.size", "torch.cat.size", "torch.cat.new_zeros().fill_", "torch.cat.dim", "torch.cat.new_zeros", "y.size", "y.size"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "", "def", "_fill", "(", "x", ",", "mask", ",", "y", ",", "padding_idx", ")", ":", "\n", "    ", "\"\"\"\n    Filling tensor x with y at masked positions (dim=0).\n    \"\"\"", "\n", "if", "x", "is", "None", ":", "\n", "        ", "return", "y", "\n", "", "assert", "x", ".", "dim", "(", ")", "==", "y", ".", "dim", "(", ")", "and", "mask", ".", "size", "(", "0", ")", "==", "x", ".", "size", "(", "0", ")", "\n", "assert", "x", ".", "dim", "(", ")", "==", "2", "or", "(", "x", ".", "dim", "(", ")", "==", "3", "and", "x", ".", "size", "(", "2", ")", "==", "y", ".", "size", "(", "2", ")", ")", "\n", "n_selected", "=", "mask", ".", "sum", "(", ")", "\n", "assert", "n_selected", "==", "y", ".", "size", "(", "0", ")", "\n", "\n", "if", "n_selected", "==", "x", ".", "size", "(", "0", ")", ":", "\n", "        ", "return", "y", "\n", "\n", "", "if", "x", ".", "size", "(", "1", ")", "<", "y", ".", "size", "(", "1", ")", ":", "\n", "        ", "dims", "=", "[", "x", ".", "size", "(", "0", ")", ",", "y", ".", "size", "(", "1", ")", "-", "x", ".", "size", "(", "1", ")", "]", "\n", "if", "x", ".", "dim", "(", ")", "==", "3", ":", "\n", "            ", "dims", ".", "append", "(", "x", ".", "size", "(", "2", ")", ")", "\n", "", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "x", ".", "new_zeros", "(", "*", "dims", ")", ".", "fill_", "(", "padding_idx", ")", "]", ",", "1", ")", "\n", "x", "[", "mask", "]", "=", "y", "\n", "", "elif", "x", ".", "size", "(", "1", ")", ">", "y", ".", "size", "(", "1", ")", ":", "\n", "        ", "x", "[", "mask", "]", "=", "padding_idx", "\n", "if", "x", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "x", "[", "mask", ",", ":", "y", ".", "size", "(", "1", ")", "]", "=", "y", "\n", "", "else", ":", "\n", "            ", "x", "[", "mask", ",", ":", "y", ".", "size", "(", "1", ")", ",", ":", "]", "=", "y", "\n", "", "", "else", ":", "\n", "        ", "x", "[", "mask", "]", "=", "y", "\n", "", "return", "x", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.nat.iterative_nonautoregressive_transformer.IterNATransformerModel.add_args": [[60, 77], ["fairseq.models.nat.NATransformerModel.add_args", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args"], ["    ", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "NATransformerModel", ".", "add_args", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--train-step\"", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"number of refinement iterations during training\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dae-ratio\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"the probability of switching to the denoising auto-encoder loss\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--stochastic-approx\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"sampling from the decoder as the inputs for next iteration\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.iterative_nonautoregressive_transformer.IterNATransformerModel.build_model": [[79, 86], ["super().build_model", "getattr", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "model", "=", "super", "(", ")", ".", "build_model", "(", "args", ",", "task", ")", "\n", "model", ".", "train_step", "=", "getattr", "(", "args", ",", "\"train_step\"", ",", "4", ")", "\n", "model", ".", "dae_ratio", "=", "getattr", "(", "args", ",", "\"dae_ratio\"", ",", "0.5", ")", "\n", "model", ".", "stochastic_approx", "=", "getattr", "(", "args", ",", "\"stochastic_approx\"", ",", "False", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.iterative_nonautoregressive_transformer.IterNATransformerModel.forward": [[87, 166], ["prev_output_tokens.masked_scatter.masked_scatter.size", "iterative_nonautoregressive_transformer.IterNATransformerModel.encoder", "iterative_nonautoregressive_transformer.IterNATransformerModel.decoder.forward_length", "iterative_nonautoregressive_transformer.IterNATransformerModel.decoder.forward_length_prediction", "range", "torch.cat", "torch.cat", "torch.cat", "iterative_nonautoregressive_transformer.IterNATransformerModel.decoder", "torch.cat.ne", "word_ins_outs.append", "word_ins_tgts.append", "word_ins_masks.append", "prev_output_tokens.masked_scatter.masked_scatter.masked_scatter", "iterative_nonautoregressive_transformer._sequential_poisoning", "iterative_nonautoregressive_transformer.IterNATransformerModel.max", "torch.rand", "len", "iterative_nonautoregressive_transformer.gumbel_noise"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerDecoder.forward_length", "home.repos.pwc.inspect_result.reneeye_const.nat.nonautoregressive_transformer.NATransformerDecoder.forward_length_prediction", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder", "home.repos.pwc.inspect_result.reneeye_const.nat.iterative_nonautoregressive_transformer._sequential_poisoning", "home.repos.pwc.inspect_result.reneeye_const.nat.iterative_nonautoregressive_transformer.gumbel_noise"], ["", "def", "forward", "(", "\n", "self", ",", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "tgt_tokens", ",", "**", "kwargs", "\n", ")", ":", "\n", "\n", "        ", "B", ",", "T", "=", "prev_output_tokens", ".", "size", "(", ")", "\n", "\n", "# encoding", "\n", "encoder_out", "=", "self", ".", "encoder", "(", "src_tokens", ",", "src_lengths", "=", "src_lengths", ",", "**", "kwargs", ")", "\n", "\n", "# length prediction", "\n", "length_out", "=", "self", ".", "decoder", ".", "forward_length", "(", "\n", "normalize", "=", "False", ",", "encoder_out", "=", "encoder_out", "\n", ")", "\n", "length_tgt", "=", "self", ".", "decoder", ".", "forward_length_prediction", "(", "\n", "length_out", ",", "encoder_out", ",", "tgt_tokens", "\n", ")", "\n", "\n", "# decoding", "\n", "word_ins_outs", ",", "word_ins_tgts", ",", "word_ins_masks", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "t", "in", "range", "(", "self", ".", "train_step", ")", ":", "\n", "            ", "word_ins_out", "=", "self", ".", "decoder", "(", "\n", "normalize", "=", "False", ",", "\n", "prev_output_tokens", "=", "prev_output_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", "step", "=", "t", ",", "\n", ")", "\n", "word_ins_tgt", "=", "tgt_tokens", "\n", "word_ins_mask", "=", "word_ins_tgt", ".", "ne", "(", "self", ".", "pad", ")", "\n", "\n", "word_ins_outs", ".", "append", "(", "word_ins_out", ")", "\n", "word_ins_tgts", ".", "append", "(", "word_ins_tgt", ")", "\n", "word_ins_masks", ".", "append", "(", "word_ins_mask", ")", "\n", "\n", "if", "t", "<", "(", "self", ".", "train_step", "-", "1", ")", ":", "\n", "# prediction for next iteration", "\n", "                ", "if", "self", ".", "stochastic_approx", ":", "\n", "                    ", "word_ins_prediction", "=", "(", "\n", "word_ins_out", "+", "gumbel_noise", "(", "word_ins_out", ")", "\n", ")", ".", "max", "(", "-", "1", ")", "[", "1", "]", "\n", "", "else", ":", "\n", "                    ", "word_ins_prediction", "=", "word_ins_out", ".", "max", "(", "-", "1", ")", "[", "1", "]", "\n", "\n", "", "prev_output_tokens", "=", "prev_output_tokens", ".", "masked_scatter", "(", "\n", "word_ins_mask", ",", "word_ins_prediction", "[", "word_ins_mask", "]", "\n", ")", "\n", "\n", "if", "self", ".", "dae_ratio", ">", "0", ":", "\n", "# we do not perform denoising for the first iteration", "\n", "                    ", "corrputed", "=", "(", "\n", "torch", ".", "rand", "(", "size", "=", "(", "B", ",", ")", ",", "device", "=", "prev_output_tokens", ".", "device", ")", "\n", "<", "self", ".", "dae_ratio", "\n", ")", "\n", "corrputed_tokens", "=", "_sequential_poisoning", "(", "\n", "tgt_tokens", "[", "corrputed", "]", ",", "\n", "len", "(", "self", ".", "tgt_dict", ")", ",", "\n", "0.33", ",", "\n", "self", ".", "bos", ",", "\n", "self", ".", "eos", ",", "\n", "self", ".", "pad", ",", "\n", ")", "\n", "prev_output_tokens", "[", "corrputed", "]", "=", "corrputed_tokens", "\n", "\n", "# concat everything", "\n", "", "", "", "word_ins_out", "=", "torch", ".", "cat", "(", "word_ins_outs", ",", "0", ")", "\n", "word_ins_tgt", "=", "torch", ".", "cat", "(", "word_ins_tgts", ",", "0", ")", "\n", "word_ins_mask", "=", "torch", ".", "cat", "(", "word_ins_masks", ",", "0", ")", "\n", "\n", "return", "{", "\n", "\"word_ins\"", ":", "{", "\n", "\"out\"", ":", "word_ins_out", ",", "\n", "\"tgt\"", ":", "word_ins_tgt", ",", "\n", "\"mask\"", ":", "word_ins_mask", ",", "\n", "\"ls\"", ":", "self", ".", "args", ".", "label_smoothing", ",", "\n", "\"nll_loss\"", ":", "True", ",", "\n", "}", ",", "\n", "\"length\"", ":", "{", "\n", "\"out\"", ":", "length_out", ",", "\n", "\"tgt\"", ":", "length_tgt", ",", "\n", "\"factor\"", ":", "self", ".", "decoder", ".", "length_loss_factor", ",", "\n", "}", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.iterative_nonautoregressive_transformer._sequential_poisoning": [[11, 43], ["torch.randint", "torch.rand", "torch.rand.masked_fill_", "range", "s.size", "s.size", "s.size", "replace_i.long", "swap_i.long"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["def", "_sequential_poisoning", "(", "s", ",", "V", ",", "beta", "=", "0.33", ",", "bos", "=", "2", ",", "eos", "=", "3", ",", "pad", "=", "1", ")", ":", "\n", "# s: input batch", "\n", "# V: vocabulary size", "\n", "    ", "rand_words", "=", "torch", ".", "randint", "(", "low", "=", "4", ",", "high", "=", "V", ",", "size", "=", "s", ".", "size", "(", ")", ",", "device", "=", "s", ".", "device", ")", "\n", "choices", "=", "torch", ".", "rand", "(", "size", "=", "s", ".", "size", "(", ")", ",", "device", "=", "s", ".", "device", ")", "\n", "choices", ".", "masked_fill_", "(", "(", "s", "==", "pad", ")", "|", "(", "s", "==", "bos", ")", "|", "(", "s", "==", "eos", ")", ",", "1", ")", "\n", "\n", "replace", "=", "choices", "<", "beta", "/", "3", "\n", "repeat", "=", "(", "choices", ">=", "beta", "/", "3", ")", "&", "(", "choices", "<", "beta", "*", "2", "/", "3", ")", "\n", "swap", "=", "(", "choices", ">=", "beta", "*", "2", "/", "3", ")", "&", "(", "choices", "<", "beta", ")", "\n", "safe", "=", "choices", ">=", "beta", "\n", "\n", "for", "i", "in", "range", "(", "s", ".", "size", "(", "1", ")", "-", "1", ")", ":", "\n", "        ", "rand_word", "=", "rand_words", "[", ":", ",", "i", "]", "\n", "next_word", "=", "s", "[", ":", ",", "i", "+", "1", "]", "\n", "self_word", "=", "s", "[", ":", ",", "i", "]", "\n", "\n", "replace_i", "=", "replace", "[", ":", ",", "i", "]", "\n", "swap_i", "=", "swap", "[", ":", ",", "i", "]", "&", "(", "next_word", "!=", "3", ")", "\n", "repeat_i", "=", "repeat", "[", ":", ",", "i", "]", "&", "(", "next_word", "!=", "3", ")", "\n", "safe_i", "=", "safe", "[", ":", ",", "i", "]", "|", "(", "(", "next_word", "==", "3", ")", "&", "(", "~", "replace_i", ")", ")", "\n", "\n", "s", "[", ":", ",", "i", "]", "=", "(", "\n", "self_word", "*", "(", "safe_i", "|", "repeat_i", ")", ".", "long", "(", ")", "\n", "+", "next_word", "*", "swap_i", ".", "long", "(", ")", "\n", "+", "rand_word", "*", "replace_i", ".", "long", "(", ")", "\n", ")", "\n", "s", "[", ":", ",", "i", "+", "1", "]", "=", "(", "\n", "next_word", "*", "(", "safe_i", "|", "replace_i", ")", ".", "long", "(", ")", "\n", "+", "self_word", "*", "(", "swap_i", "|", "repeat_i", ")", ".", "long", "(", ")", "\n", ")", "\n", "", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.iterative_nonautoregressive_transformer.gumbel_noise": [[45, 53], ["input.new_zeros().uniform_().add_().log_().neg_().add_().log_().neg_", "input.new_zeros().uniform_().add_().log_().neg_().add_().log_", "input.new_zeros().uniform_().add_().log_().neg_().add_", "input.new_zeros().uniform_().add_().log_().neg_", "input.new_zeros().uniform_().add_().log_", "input.new_zeros().uniform_().add_", "input.new_zeros().uniform_", "input.new_zeros", "input.size"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "gumbel_noise", "(", "input", ",", "TINY", "=", "1e-8", ")", ":", "\n", "    ", "return", "(", "\n", "input", ".", "new_zeros", "(", "*", "input", ".", "size", "(", ")", ")", "\n", ".", "uniform_", "(", ")", "\n", ".", "add_", "(", "TINY", ")", "\n", ".", "log_", "(", ")", "\n", ".", "neg_", "(", ")", "\n", ".", "add_", "(", "TINY", ")", "\n", ".", "log_", "(", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.iterative_nonautoregressive_transformer.inat_base_architecture": [[170, 221], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "", "@", "register_model_architecture", "(", "\n", "\"iterative_nonautoregressive_transformer\"", ",", "\"iterative_nonautoregressive_transformer\"", "\n", ")", "\n", "def", "inat_base_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_path", "=", "getattr", "(", "args", ",", "\"encoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "512", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "2048", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "6", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "encoder_normalize_before", "=", "getattr", "(", "args", ",", "\"encoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "encoder_learned_pos", "=", "getattr", "(", "args", ",", "\"encoder_learned_pos\"", ",", "False", ")", "\n", "args", ".", "decoder_embed_path", "=", "getattr", "(", "args", ",", "\"decoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "args", ".", "encoder_embed_dim", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "args", ".", "encoder_ffn_embed_dim", "\n", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "6", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "8", ")", "\n", "args", ".", "decoder_normalize_before", "=", "getattr", "(", "args", ",", "\"decoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "decoder_learned_pos", "=", "getattr", "(", "args", ",", "\"decoder_learned_pos\"", ",", "False", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.0", ")", "\n", "args", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "0.0", ")", "\n", "args", ".", "activation_fn", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"relu\"", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "adaptive_softmax_cutoff", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_cutoff\"", ",", "None", ")", "\n", "args", ".", "adaptive_softmax_dropout", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_dropout\"", ",", "0", ")", "\n", "args", ".", "share_decoder_input_output_embed", "=", "getattr", "(", "\n", "args", ",", "\"share_decoder_input_output_embed\"", ",", "False", "\n", ")", "\n", "args", ".", "share_all_embeddings", "=", "getattr", "(", "args", ",", "\"share_all_embeddings\"", ",", "False", ")", "\n", "args", ".", "no_token_positional_embeddings", "=", "getattr", "(", "\n", "args", ",", "\"no_token_positional_embeddings\"", ",", "False", "\n", ")", "\n", "args", ".", "adaptive_input", "=", "getattr", "(", "args", ",", "\"adaptive_input\"", ",", "False", ")", "\n", "args", ".", "apply_bert_init", "=", "getattr", "(", "args", ",", "\"apply_bert_init\"", ",", "False", ")", "\n", "\n", "args", ".", "decoder_output_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_output_dim\"", ",", "args", ".", "decoder_embed_dim", "\n", ")", "\n", "args", ".", "decoder_input_dim", "=", "getattr", "(", "args", ",", "\"decoder_input_dim\"", ",", "args", ".", "decoder_embed_dim", ")", "\n", "\n", "# --- special arguments ---", "\n", "args", ".", "sg_length_pred", "=", "getattr", "(", "args", ",", "\"sg_length_pred\"", ",", "False", ")", "\n", "args", ".", "pred_length_offset", "=", "getattr", "(", "args", ",", "\"pred_length_offset\"", ",", "False", ")", "\n", "args", ".", "length_loss_factor", "=", "getattr", "(", "args", ",", "\"length_loss_factor\"", ",", "0.1", ")", "\n", "args", ".", "ngram_predictor", "=", "getattr", "(", "args", ",", "\"ngram_predictor\"", ",", "1", ")", "\n", "args", ".", "src_embedding_copy", "=", "getattr", "(", "args", ",", "\"src_embedding_copy\"", ",", "False", ")", "\n", "\n", "args", ".", "train_step", "=", "getattr", "(", "args", ",", "\"train_step\"", ",", "4", ")", "\n", "args", ".", "dae_ratio", "=", "getattr", "(", "args", ",", "\"dae_ratio\"", ",", "0.5", ")", "\n", "args", ".", "stochastic_approx", "=", "getattr", "(", "args", ",", "\"stochastic_approx\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.nat.iterative_nonautoregressive_transformer.iter_nat_wmt_en_de": [[223, 229], ["fairseq.models.register_model_architecture", "iterative_nonautoregressive_transformer.inat_base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.nat.iterative_nonautoregressive_transformer.inat_base_architecture"], ["", "@", "register_model_architecture", "(", "\n", "\"iterative_nonautoregressive_transformer\"", ",", "\n", "\"iterative_nonautoregressive_transformer_wmt_en_de\"", ",", "\n", ")", "\n", "def", "iter_nat_wmt_en_de", "(", "args", ")", ":", "\n", "    ", "inat_base_architecture", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.huggingface.hf_gpt2.HuggingFaceGPT2LanguageModel.__init__": [[28, 30], ["fairseq.models.FairseqLanguageModel.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.huggingface.hf_gpt2.HuggingFaceGPT2LanguageModel.add_args": [[31, 46], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add model-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--embed-dim'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-attention-heads'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'num attention heads'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-layers'", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'num layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability for all fully connected layers '", "\n", "'in the embeddings, encoder, and pooler'", ")", "\n", "parser", ".", "add_argument", "(", "'--attention-dropout'", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'dropout probability for attention weights'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.huggingface.hf_gpt2.HuggingFaceGPT2LanguageModel.build_model": [[48, 53], ["hf_gpt2.default_architecture", "cls", "hf_gpt2.HuggingFaceGPT2Decoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.huggingface.hf_gpt2.default_architecture", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Build a new model instance.\"\"\"", "\n", "default_architecture", "(", "args", ")", "\n", "return", "cls", "(", "HuggingFaceGPT2Decoder", "(", "args", ",", "task", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.huggingface.hf_gpt2.HuggingFaceGPT2Decoder.__init__": [[56, 85], ["fairseq.models.FairseqIncrementalDecoder.__init__", "GPT2Config", "GPT2LMHeadModel", "task.target_dictionary.pad", "hf_gpt2.HuggingFaceGPT2Decoder.model.transformer.wte.weight.data[].zero_", "hf_gpt2.HuggingFaceGPT2Decoder.model.transformer.wpe.weight.data[].zero_", "ImportError", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "task", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "transformers", "import", "GPT2Config", ",", "GPT2LMHeadModel", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"\\n\\nPlease install huggingface/transformers with:\"", "\n", "\"\\n\\n  pip install transformers\"", "\n", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "task", ".", "target_dictionary", ")", "\n", "\n", "config", "=", "GPT2Config", "(", "\n", "vocab_size", "=", "len", "(", "task", ".", "target_dictionary", ")", ",", "\n", "n_positions", "=", "args", ".", "max_target_positions", "+", "1", ",", "\n", "n_ctx", "=", "args", ".", "max_target_positions", ",", "\n", "n_embd", "=", "args", ".", "embed_dim", ",", "\n", "n_layer", "=", "args", ".", "num_layers", ",", "\n", "n_head", "=", "args", ".", "num_attention_heads", ",", "\n", "resid_pdrop", "=", "args", ".", "dropout", ",", "\n", "embd_pdrop", "=", "args", ".", "dropout", ",", "\n", "attn_pdrop", "=", "args", ".", "attention_dropout", ",", "\n", "layer_norm_epsilon", "=", "1e-6", ",", "\n", ")", "\n", "self", ".", "model", "=", "GPT2LMHeadModel", "(", "config", ")", "\n", "\n", "# set zero embedding for padding symbol", "\n", "self", ".", "pad_idx", "=", "task", ".", "target_dictionary", ".", "pad", "(", ")", "\n", "self", ".", "model", ".", "transformer", ".", "wte", ".", "weight", ".", "data", "[", "self", ".", "pad_idx", "]", ".", "zero_", "(", ")", "\n", "self", ".", "model", ".", "transformer", ".", "wpe", ".", "weight", ".", "data", "[", "0", "]", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.huggingface.hf_gpt2.HuggingFaceGPT2Decoder.forward": [[86, 96], ["hf_gpt2.HuggingFaceGPT2Decoder.extract_features", "hf_gpt2.HuggingFaceGPT2Decoder.model.lm_head"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "prev_output_tokens", ",", "\n", "src_lengths", "=", "None", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "List", "[", "torch", ".", "Tensor", "]", "]", "]", "=", "None", ",", "\n", "encoder_out", "=", "None", ",", "\n", ")", ":", "\n", "        ", "features", "=", "self", ".", "extract_features", "(", "prev_output_tokens", ",", "incremental_state", ")", "\n", "lm_logits", "=", "self", ".", "model", ".", "lm_head", "(", "features", ")", "\n", "return", "(", "lm_logits", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.huggingface.hf_gpt2.HuggingFaceGPT2Decoder.extract_features": [[97, 129], ["prev_output_tokens.ne().int", "hf_gpt2.HuggingFaceGPT2Decoder.model.transformer", "hf_gpt2.HuggingFaceGPT2Decoder.get_incremental_state", "torch.arange().to().repeat", "hf_gpt2.HuggingFaceGPT2Decoder.set_incremental_state", "prev_output_tokens.ne", "prev_output_tokens.size", "torch.arange().to", "torch.arange", "prev_output_tokens.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_incremental_state", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.set_incremental_state", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "extract_features", "(", "\n", "self", ",", "\n", "prev_output_tokens", ",", "\n", "incremental_state", ":", "Optional", "[", "Dict", "[", "str", ",", "List", "[", "torch", ".", "Tensor", "]", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "incremental_state", ":", "\n", "            ", "past", "=", "self", ".", "get_incremental_state", "(", "\"past\"", ")", "\n", "", "else", ":", "\n", "            ", "past", "=", "None", "\n", "\n", "# don't attend to padding symbols", "\n", "", "attention_mask", "=", "prev_output_tokens", ".", "ne", "(", "self", ".", "pad_idx", ")", ".", "int", "(", ")", "\n", "\n", "# set position ids to exclude padding symbols", "\n", "position_ids", "=", "attention_mask", "*", "(", "\n", "torch", ".", "arange", "(", "1", ",", "1", "+", "prev_output_tokens", ".", "size", "(", "1", ")", ")", "\n", ".", "to", "(", "prev_output_tokens", ")", "\n", ".", "repeat", "(", "prev_output_tokens", ".", "size", "(", "0", ")", ",", "1", ")", "\n", ")", "\n", "\n", "outputs", "=", "self", ".", "model", ".", "transformer", "(", "\n", "input_ids", "=", "prev_output_tokens", ",", "\n", "past", "=", "past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", ")", "\n", "last_hidden_states", "=", "outputs", "[", "0", "]", "\n", "\n", "if", "incremental_state", ":", "\n", "            ", "self", ".", "set_incremental_state", "(", "incremental_state", ",", "\"past\"", ",", "outputs", "[", "1", "]", ")", "\n", "\n", "", "return", "last_hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.huggingface.hf_gpt2.HuggingFaceGPT2Decoder.max_positions": [[130, 132], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "config", ".", "n_positions", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.huggingface.hf_gpt2.default_architecture": [[134, 145], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "", "@", "register_model_architecture", "(", "\"hf_gpt2\"", ",", "\"hf_gpt2\"", ")", "\n", "def", "default_architecture", "(", "args", ")", ":", "\n", "    ", "if", "getattr", "(", "args", ",", "\"max_target_positions\"", ",", "None", ")", "is", "None", ":", "\n", "        ", "args", ".", "max_target_positions", "=", "getattr", "(", "\n", "args", ",", "\"tokens_per_sample\"", ",", "DEFAULT_MAX_TARGET_POSITIONS", "\n", ")", "\n", "", "args", ".", "embed_dim", "=", "getattr", "(", "args", ",", "\"embed_dim\"", ",", "768", ")", "\n", "args", ".", "num_attention_heads", "=", "getattr", "(", "args", ",", "\"num_attention_heads\"", ",", "12", ")", "\n", "args", ".", "num_layers", "=", "getattr", "(", "args", ",", "\"num_layers\"", ",", "12", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.huggingface.hf_gpt2.hf_gpt2_medium": [[147, 153], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "hf_gpt2.default_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.huggingface.hf_gpt2.default_architecture"], ["", "@", "register_model_architecture", "(", "\"hf_gpt2\"", ",", "\"hf_gpt2_medium\"", ")", "\n", "def", "hf_gpt2_medium", "(", "args", ")", ":", "\n", "    ", "args", ".", "embed_dim", "=", "getattr", "(", "args", ",", "\"embed_dim\"", ",", "1024", ")", "\n", "args", ".", "num_attention_heads", "=", "getattr", "(", "args", ",", "\"num_attention_heads\"", ",", "16", ")", "\n", "args", ".", "num_layers", "=", "getattr", "(", "args", ",", "\"num_layers\"", ",", "24", ")", "\n", "default_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.huggingface.hf_gpt2.hf_gpt2_large": [[155, 161], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "hf_gpt2.default_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.huggingface.hf_gpt2.default_architecture"], ["", "@", "register_model_architecture", "(", "\"hf_gpt2\"", ",", "\"hf_gpt2_large\"", ")", "\n", "def", "hf_gpt2_large", "(", "args", ")", ":", "\n", "    ", "args", ".", "embed_dim", "=", "getattr", "(", "args", ",", "\"embed_dim\"", ",", "1280", ")", "\n", "args", ".", "num_attention_heads", "=", "getattr", "(", "args", ",", "\"num_attention_heads\"", ",", "20", ")", "\n", "args", ".", "num_layers", "=", "getattr", "(", "args", ",", "\"num_layers\"", ",", "36", ")", "\n", "default_architecture", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.huggingface.hf_gpt2.hf_gpt2_xl": [[163, 169], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "hf_gpt2.default_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.huggingface.hf_gpt2.default_architecture"], ["", "@", "register_model_architecture", "(", "\"hf_gpt2\"", ",", "\"hf_gpt2_xl\"", ")", "\n", "def", "hf_gpt2_xl", "(", "args", ")", ":", "\n", "    ", "args", ".", "embed_dim", "=", "getattr", "(", "args", ",", "\"embed_dim\"", ",", "1600", ")", "\n", "args", ".", "num_attention_heads", "=", "getattr", "(", "args", ",", "\"num_attention_heads\"", ",", "25", ")", "\n", "args", ".", "num_layers", "=", "getattr", "(", "args", ",", "\"num_layers\"", ",", "48", ")", "\n", "default_architecture", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.__init__": [[20, 30], ["torch.Module.__init__", "fairseq.data.encoders.build_bpe", "hub_interface.RobertaHubInterface.register_buffer", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.build_bpe"], ["logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "\n", "class", "BARTHubInterface", "(", "GeneratorHubInterface", ")", ":", "\n", "    ", "\"\"\"A simple PyTorch Hub interface to BART.\n\n    Usage: https://github.com/pytorch/fairseq/tree/master/examples/bart\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "cfg", ",", "task", ",", "model", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "task", ",", "[", "model", "]", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.device": [[31, 34], ["None"], "methods", ["None"], ["self", ".", "model", "=", "self", ".", "models", "[", "0", "]", "\n", "\n", "", "def", "encode", "(", "\n", "self", ",", "sentence", ":", "str", ",", "*", "addl_sentences", ",", "no_separator", "=", "True", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.encode": [[35, 66], ["hub_interface.RobertaHubInterface.task.source_dictionary.encode_line", "hub_interface.RobertaHubInterface.long", "hub_interface.RobertaHubInterface.bpe.encode", "hub_interface.RobertaHubInterface.bpe.encode"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.encode_line", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], [")", "->", "torch", ".", "LongTensor", ":", "\n", "        ", "\"\"\"\n        BPE-encode a sentence (or multiple sentences).\n\n        Every sequence begins with a beginning-of-sentence (`<s>`) symbol.\n        Every sentence ends with an end-of-sentence (`</s>`).\n\n        Example (single sentence): `<s> a b c </s>`\n        Example (sentence pair): `<s> d e f </s> 1 2 3 </s>`\n\n        The BPE encoding follows GPT-2. One subtle detail is that the GPT-2 BPE\n        requires leading spaces. For example::\n\n            >>> bart.encode('Hello world').tolist()\n            [0, 31414, 232, 2]\n            >>> bart.encode(' world').tolist()\n            [0, 232, 2]\n            >>> bart.encode('world').tolist()\n            [0, 8331, 2]\n        \"\"\"", "\n", "tokens", "=", "self", ".", "bpe", ".", "encode", "(", "sentence", ")", "\n", "if", "len", "(", "tokens", ".", "split", "(", "\" \"", ")", ")", ">", "min", "(", "self", ".", "max_positions", ")", "-", "2", ":", "\n", "            ", "tokens", "=", "\" \"", ".", "join", "(", "tokens", ".", "split", "(", "\" \"", ")", "[", ":", "min", "(", "self", ".", "max_positions", ")", "-", "2", "]", ")", "\n", "", "bpe_sentence", "=", "\"<s> \"", "+", "tokens", "+", "\" </s>\"", "\n", "for", "s", "in", "addl_sentences", ":", "\n", "            ", "bpe_sentence", "+=", "\" </s>\"", "if", "not", "no_separator", "else", "\"\"", "\n", "bpe_sentence", "+=", "\" \"", "+", "self", ".", "bpe", ".", "encode", "(", "s", ")", "+", "\" </s>\"", "\n", "", "tokens", "=", "self", ".", "task", ".", "source_dictionary", ".", "encode_line", "(", "bpe_sentence", ",", "append_eos", "=", "False", ")", "\n", "return", "tokens", ".", "long", "(", ")", "\n", "\n", "", "def", "decode", "(", "self", ",", "tokens", ":", "torch", ".", "LongTensor", ")", ":", "\n", "        ", "assert", "tokens", ".", "dim", "(", ")", "==", "1", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.decode": [[67, 81], ["tokens.numpy.numpy.numpy", "numpy.split", "tokens.numpy.numpy.dim", "hub_interface.RobertaHubInterface.task.source_dictionary.bos", "hub_interface.RobertaHubInterface.task.source_dictionary.eos", "hub_interface.RobertaHubInterface.bpe.decode", "len", "hub_interface.RobertaHubInterface.task.source_dictionary.string", "doc_mask.nonzero"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.string"], ["tokens", "=", "tokens", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "tokens", "[", "0", "]", "==", "self", ".", "task", ".", "source_dictionary", ".", "bos", "(", ")", ":", "\n", "            ", "tokens", "=", "tokens", "[", "1", ":", "]", "# remove <s>", "\n", "", "eos_mask", "=", "tokens", "==", "self", ".", "task", ".", "source_dictionary", ".", "eos", "(", ")", "\n", "doc_mask", "=", "eos_mask", "[", "1", ":", "]", "&", "eos_mask", "[", ":", "-", "1", "]", "\n", "sentences", "=", "np", ".", "split", "(", "tokens", ",", "doc_mask", ".", "nonzero", "(", ")", "[", "0", "]", "+", "1", ")", "\n", "sentences", "=", "[", "\n", "self", ".", "bpe", ".", "decode", "(", "self", ".", "task", ".", "source_dictionary", ".", "string", "(", "s", ")", ")", "for", "s", "in", "sentences", "\n", "]", "\n", "if", "len", "(", "sentences", ")", "==", "1", ":", "\n", "            ", "return", "sentences", "[", "0", "]", "\n", "", "return", "sentences", "\n", "\n", "", "def", "_build_sample", "(", "self", ",", "src_tokens", ":", "List", "[", "torch", ".", "LongTensor", "]", ")", ":", "\n", "# assert torch.is_tensor(src_tokens)", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.extract_features": [[82, 104], ["hub_interface.RobertaHubInterface.model", "tokens.unsqueeze.unsqueeze.dim", "tokens.unsqueeze.unsqueeze.unsqueeze", "tokens.unsqueeze.unsqueeze.size", "hub_interface.RobertaHubInterface.model.max_positions", "ValueError", "tokens.unsqueeze.unsqueeze.to", "inner_state.transpose", "tokens.unsqueeze.unsqueeze.size", "hub_interface.RobertaHubInterface.model.max_positions"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions"], ["        ", "dataset", "=", "self", ".", "task", ".", "build_dataset_for_inference", "(", "\n", "src_tokens", ",", "\n", "[", "x", ".", "numel", "(", ")", "for", "x", "in", "src_tokens", "]", ",", "\n", ")", "\n", "sample", "=", "dataset", ".", "collater", "(", "dataset", ")", "\n", "sample", "=", "utils", ".", "apply_to_sample", "(", "lambda", "tensor", ":", "tensor", ".", "to", "(", "self", ".", "device", ")", ",", "sample", ")", "\n", "return", "sample", "\n", "\n", "", "def", "generate", "(", "\n", "self", ",", "\n", "tokenized_sentences", ":", "List", "[", "torch", ".", "LongTensor", "]", ",", "\n", "*", "args", ",", "\n", "inference_step_args", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", "->", "List", "[", "List", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", "]", ":", "\n", "        ", "inference_step_args", "=", "inference_step_args", "or", "{", "}", "\n", "if", "\"prefix_tokens\"", "in", "inference_step_args", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"prefix generation not implemented for BART\"", ")", "\n", "", "else", ":", "\n", "            ", "bsz", "=", "len", "(", "tokenized_sentences", ")", "\n", "inference_step_args", "[", "\"prefix_tokens\"", "]", "=", "tokenized_sentences", "[", "0", "]", ".", "new_full", "(", "\n", "(", "bsz", ",", "1", ")", ",", "fill_value", "=", "self", ".", "task", ".", "source_dictionary", ".", "bos", "(", ")", "\n", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.register_classification_head": [[105, 110], ["hub_interface.RobertaHubInterface.model.register_classification_head"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaModel.register_classification_head"], ["", "return", "super", "(", ")", ".", "generate", "(", "\n", "tokenized_sentences", ",", "\n", "*", "args", ",", "\n", "inference_step_args", "=", "inference_step_args", ",", "\n", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.predict": [[112, 118], ["hub_interface.RobertaHubInterface.extract_features", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "tokens.to"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax"], ["", "def", "extract_features", "(", "\n", "self", ",", "tokens", ":", "torch", ".", "LongTensor", ",", "return_all_hiddens", ":", "bool", "=", "False", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "if", "tokens", ".", "dim", "(", ")", "==", "1", ":", "\n", "            ", "tokens", "=", "tokens", ".", "unsqueeze", "(", "0", ")", "\n", "", "if", "tokens", ".", "size", "(", "-", "1", ")", ">", "min", "(", "self", ".", "model", ".", "max_positions", "(", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.extract_features_aligned_to_words": [[119, 155], ["alignment_utils.spacy_nlp", "alignment_utils.spacy_tokenizer", "hub_interface.RobertaHubInterface.encode", "alignment_utils.spacy_tokenizer.", "alignment_utils.align_bpe_to_words", "hub_interface.RobertaHubInterface.extract_features", "features.squeeze.squeeze.squeeze", "alignment_utils.align_features_to_words", "Doc", "len", "alignment_utils.align_features_to_words.size", "alignment_utils.spacy_tokenizer.", "x.endswith"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.alignment_utils.spacy_nlp", "home.repos.pwc.inspect_result.reneeye_const.roberta.alignment_utils.spacy_tokenizer", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode", "home.repos.pwc.inspect_result.reneeye_const.roberta.alignment_utils.align_bpe_to_words", "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features", "home.repos.pwc.inspect_result.reneeye_const.roberta.alignment_utils.align_features_to_words", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["\"tokens exceeds maximum length: {} > {}\"", ".", "format", "(", "\n", "tokens", ".", "size", "(", "-", "1", ")", ",", "self", ".", "model", ".", "max_positions", "(", ")", "\n", ")", "\n", ")", "\n", "", "tokens", ".", "to", "(", "device", "=", "self", ".", "device", ")", ",", "\n", "prev_output_tokens", "=", "tokens", ".", "clone", "(", ")", "\n", "\n", "prev_output_tokens", "[", ":", ",", "0", "]", "=", "tokens", ".", "gather", "(", "\n", "1", ",", "\n", "(", "tokens", ".", "ne", "(", "self", ".", "task", ".", "source_dictionary", ".", "pad", "(", ")", ")", ".", "sum", "(", "dim", "=", "1", ")", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", ")", ".", "squeeze", "(", ")", "\n", "\n", "prev_output_tokens", "[", ":", ",", "1", ":", "]", "=", "tokens", "[", ":", ",", ":", "-", "1", "]", "\n", "features", ",", "extra", "=", "self", ".", "model", "(", "\n", "src_tokens", "=", "tokens", ",", "\n", "src_lengths", "=", "None", ",", "\n", "prev_output_tokens", "=", "prev_output_tokens", ",", "\n", "features_only", "=", "True", ",", "\n", "return_all_hiddens", "=", "return_all_hiddens", ",", "\n", ")", "\n", "if", "return_all_hiddens", ":", "\n", "# convert from T x B x C -> B x T x C", "\n", "            ", "inner_states", "=", "extra", "[", "\"inner_states\"", "]", "\n", "return", "[", "inner_state", ".", "transpose", "(", "0", ",", "1", ")", "for", "inner_state", "in", "inner_states", "]", "\n", "", "else", ":", "\n", "            ", "return", "features", "# just the last layer's features", "\n", "\n", "", "", "def", "register_classification_head", "(", "\n", "self", ",", "name", ":", "str", ",", "num_classes", ":", "int", "=", "None", ",", "embedding_size", ":", "int", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "self", ".", "model", ".", "register_classification_head", "(", "\n", "name", ",", "num_classes", "=", "num_classes", ",", "embedding_size", "=", "embedding_size", ",", "**", "kwargs", "\n", ")", "\n", "\n", "", "def", "predict", "(", "self", ",", "head", ":", "str", ",", "tokens", ":", "torch", ".", "LongTensor", ",", "return_logits", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "tokens", ".", "dim", "(", ")", "==", "1", ":", "\n", "            ", "tokens", "=", "tokens", ".", "unsqueeze", "(", "0", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.fill_mask": [[156, 218], ["masked_input.split", "hub_interface.RobertaHubInterface.task.source_dictionary.encode_line", "features[].squeeze", "features[].squeeze.softmax", "features[].squeeze.softmax.topk", "hub_interface.RobertaHubInterface.task.source_dictionary.string", "enumerate", "tokens.unsqueeze.unsqueeze.dim", "tokens.unsqueeze.unsqueeze.unsqueeze", "fairseq.utils.model_eval", "hub_interface.RobertaHubInterface.model", "hub_interface.RobertaHubInterface.split", "hub_interface.RobertaHubInterface.bpe.decode", "predicted_token_bpe.startswith", "masked_input.count", "tokens.unsqueeze.unsqueeze.long().to", "topk_filled_outputs.append", "topk_filled_outputs.append", "hub_interface.RobertaHubInterface.bpe.encode", "tokens.unsqueeze.unsqueeze.long", "masked_input.replace", "values[].item", "masked_input.replace", "values[].item", "text_span.rstrip"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.encode_line", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.model_eval", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "features", "=", "self", ".", "extract_features", "(", "tokens", ".", "to", "(", "device", "=", "self", ".", "device", ")", ")", "\n", "sentence_representation", "=", "features", "[", "\n", "tokens", ".", "eq", "(", "self", ".", "task", ".", "source_dictionary", ".", "eos", "(", ")", ")", ",", ":", "\n", "]", ".", "view", "(", "features", ".", "size", "(", "0", ")", ",", "-", "1", ",", "features", ".", "size", "(", "-", "1", ")", ")", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "\n", "logits", "=", "self", ".", "model", ".", "classification_heads", "[", "head", "]", "(", "sentence_representation", ")", "\n", "if", "return_logits", ":", "\n", "            ", "return", "logits", "\n", "", "return", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "def", "fill_mask", "(", "\n", "self", ",", "\n", "masked_inputs", ":", "List", "[", "str", "]", ",", "\n", "topk", ":", "int", "=", "5", ",", "\n", "match_source_len", ":", "bool", "=", "True", ",", "\n", "**", "generate_kwargs", "\n", ")", ":", "\n", "        ", "masked_token", "=", "'<mask>'", "\n", "batch_tokens", "=", "[", "]", "\n", "for", "masked_input", "in", "masked_inputs", ":", "\n", "            ", "assert", "masked_token", "in", "masked_input", ",", "\"please add one {} token for the input\"", ".", "format", "(", "masked_token", ")", "\n", "\n", "text_spans", "=", "masked_input", ".", "split", "(", "masked_token", ")", "\n", "text_spans_bpe", "=", "(", "' {0} '", ".", "format", "(", "masked_token", ")", ")", ".", "join", "(", "\n", "[", "self", ".", "bpe", ".", "encode", "(", "text_span", ".", "rstrip", "(", ")", ")", "for", "text_span", "in", "text_spans", "]", "\n", ")", ".", "strip", "(", ")", "\n", "tokens", "=", "self", ".", "task", ".", "source_dictionary", ".", "encode_line", "(", "\n", "'<s> '", "+", "text_spans_bpe", "+", "' </s>'", ",", "\n", "append_eos", "=", "False", ",", "\n", "add_if_not_exist", "=", "False", ",", "\n", ")", ".", "long", "(", ")", "\n", "batch_tokens", ".", "append", "(", "tokens", ")", "\n", "\n", "# ensure beam size is at least as big as topk", "\n", "", "generate_kwargs", "[", "'beam'", "]", "=", "max", "(", "\n", "topk", ",", "\n", "generate_kwargs", ".", "get", "(", "'beam'", ",", "-", "1", ")", ",", "\n", ")", "\n", "generate_kwargs", "[", "'match_source_len'", "]", "=", "match_source_len", "\n", "batch_hypos", "=", "self", ".", "generate", "(", "batch_tokens", ",", "**", "generate_kwargs", ")", "\n", "\n", "return", "[", "\n", "[", "(", "self", ".", "decode", "(", "hypo", "[", "'tokens'", "]", ")", ",", "hypo", "[", "'score'", "]", ")", "for", "hypo", "in", "hypos", "[", ":", "topk", "]", "]", "\n", "for", "hypos", "in", "batch_hypos", "\n", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.disambiguate_pronoun": [[219, 235], ["hasattr", "fairseq.utils.model_eval", "hub_interface.RobertaHubInterface.task.disambiguate_pronoun"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.model_eval", "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.disambiguate_pronoun"], []], "home.repos.pwc.inspect_result.reneeye_const.roberta.model_camembert.CamembertModel.hub_models": [[17, 28], ["None"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "hub_models", "(", "cls", ")", ":", "\n", "        ", "return", "{", "\n", "\"camembert\"", ":", "\"http://dl.fbaipublicfiles.com/fairseq/models/camembert-base.tar.gz\"", ",", "\n", "\"camembert.v0\"", ":", "\"http://dl.fbaipublicfiles.com/fairseq/models/camembert-base.tar.gz\"", ",", "\n", "\"camembert-base\"", ":", "\"http://dl.fbaipublicfiles.com/fairseq/models/camembert-base.tar.gz\"", ",", "\n", "\"camembert-large\"", ":", "\"http://dl.fbaipublicfiles.com/fairseq/models/camembert-large.tar.gz\"", ",", "\n", "\"camembert-base-ccnet\"", ":", "\"http://dl.fbaipublicfiles.com/fairseq/models/camembert-base-ccnet.tar.gz\"", ",", "\n", "\"camembert-base-ccnet-4gb\"", ":", "\"http://dl.fbaipublicfiles.com/fairseq/models/camembert-base-ccnet-4gb.tar.gz\"", ",", "\n", "\"camembert-base-wikipedia-4gb\"", ":", "\"http://dl.fbaipublicfiles.com/fairseq/models/camembert-base-wikipedia-4gb.tar.gz\"", ",", "\n", "\"camembert-base-oscar-4gb\"", ":", "\"http://dl.fbaipublicfiles.com/fairseq/models/camembert-base-oscar-4gb.tar.gz\"", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model_camembert.CamembertModel.from_pretrained": [[30, 51], ["hub_utils.from_pretrained", "hub_interface.RobertaHubInterface", "cls.hub_models"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model_xlmr.XLMRModel.from_pretrained", "home.repos.pwc.inspect_result.reneeye_const.roberta.model_xlmr.XLMRModel.hub_models"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "\n", "cls", ",", "\n", "model_name_or_path", ",", "\n", "checkpoint_file", "=", "\"model.pt\"", ",", "\n", "data_name_or_path", "=", "\".\"", ",", "\n", "bpe", "=", "\"sentencepiece\"", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "from", "fairseq", "import", "hub_utils", "\n", "\n", "x", "=", "hub_utils", ".", "from_pretrained", "(", "\n", "model_name_or_path", ",", "\n", "checkpoint_file", ",", "\n", "data_name_or_path", ",", "\n", "archive_map", "=", "cls", ".", "hub_models", "(", ")", ",", "\n", "bpe", "=", "bpe", ",", "\n", "load_checkpoint_heads", "=", "True", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "return", "RobertaHubInterface", "(", "x", "[", "\"args\"", "]", ",", "x", "[", "\"task\"", "]", ",", "x", "[", "\"models\"", "]", "[", "0", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.RobertaModel.hub_models": [[33, 40], ["None"], "methods", ["None"], ["\"bart.base\"", ":", "\"http://dl.fbaipublicfiles.com/fairseq/models/bart.base.tar.gz\"", ",", "\n", "\"bart.large\"", ":", "\"http://dl.fbaipublicfiles.com/fairseq/models/bart.large.tar.gz\"", ",", "\n", "\"bart.large.mnli\"", ":", "\"http://dl.fbaipublicfiles.com/fairseq/models/bart.large.mnli.tar.gz\"", ",", "\n", "\"bart.large.cnn\"", ":", "\"http://dl.fbaipublicfiles.com/fairseq/models/bart.large.cnn.tar.gz\"", ",", "\n", "\"bart.large.xsum\"", ":", "\"http://dl.fbaipublicfiles.com/fairseq/models/bart.large.xsum.tar.gz\"", ",", "\n", "}", "\n", "\n", "", "def", "__init__", "(", "self", ",", "args", ",", "encoder", ",", "decoder", ")", ":", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.RobertaModel.__init__": [[42, 50], ["fairseq.models.FairseqEncoderModel.__init__", "model.RobertaModel.apply", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["\n", "# We follow BERT's random weight initialization", "\n", "self", ".", "apply", "(", "init_bert_params", ")", "\n", "\n", "self", ".", "classification_heads", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "if", "hasattr", "(", "self", ".", "encoder", ",", "\"dictionary\"", ")", ":", "\n", "            ", "self", ".", "eos", ":", "int", "=", "self", ".", "encoder", ".", "dictionary", ".", "eos", "(", ")", "\n", "\n", "", "", "@", "staticmethod", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.RobertaModel.add_args": [[51, 164], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "fairseq.utils.get_available_activation_fns", "fairseq.utils.get_available_activation_fns"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_available_activation_fns", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_available_activation_fns"], ["def", "add_args", "(", "parser", ")", ":", "\n", "        ", "super", "(", "BARTModel", ",", "BARTModel", ")", ".", "add_args", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pooler-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability in the masked_lm pooler layers\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pooler-activation-fn\"", ",", "\n", "choices", "=", "utils", ".", "get_available_activation_fns", "(", ")", ",", "\n", "help", "=", "\"activation function to use for pooler layer\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--spectral-norm-classification-head\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Apply spectral normalization on the classification head\"", ",", "\n", ")", "\n", "\n", "", "@", "property", "\n", "def", "supported_targets", "(", "self", ")", ":", "\n", "        ", "return", "{", "\"self\"", "}", "\n", "\n", "", "def", "forward", "(", "\n", "self", ",", "\n", "src_tokens", ",", "\n", "src_lengths", ",", "\n", "prev_output_tokens", ",", "\n", "features_only", ":", "bool", "=", "False", ",", "\n", "classification_head_name", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "token_embeddings", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "return_all_hiddens", ":", "bool", "=", "True", ",", "\n", "alignment_layer", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "alignment_heads", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "classification_head_name", "is", "not", "None", ":", "\n", "            ", "features_only", "=", "True", "\n", "\n", "", "encoder_out", "=", "self", ".", "encoder", "(", "\n", "src_tokens", ",", "\n", "src_lengths", "=", "src_lengths", ",", "\n", "token_embeddings", "=", "token_embeddings", ",", "\n", "return_all_hiddens", "=", "return_all_hiddens", "\n", ")", "\n", "x", ",", "extra", "=", "self", ".", "decoder", "(", "\n", "prev_output_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", "features_only", "=", "features_only", ",", "\n", "alignment_layer", "=", "alignment_layer", ",", "\n", "alignment_heads", "=", "alignment_heads", ",", "\n", "src_lengths", "=", "src_lengths", ",", "\n", "return_all_hiddens", "=", "return_all_hiddens", ",", "\n", ")", "\n", "eos", ":", "int", "=", "self", ".", "eos", "\n", "if", "classification_head_name", "is", "not", "None", ":", "\n", "            ", "sentence_representation", "=", "x", "[", "\n", "src_tokens", ".", "eq", "(", "eos", ")", ",", ":", "\n", "]", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "for", "k", ",", "head", "in", "self", ".", "classification_heads", ".", "items", "(", ")", ":", "\n", "# for torch script only supports iteration", "\n", "                ", "if", "k", "==", "classification_head_name", ":", "\n", "                    ", "x", "=", "head", "(", "sentence_representation", ")", "\n", "break", "\n", "", "", "", "return", "x", ",", "extra", "\n", "\n", "", "@", "classmethod", "\n", "def", "from_pretrained", "(", "\n", "cls", ",", "\n", "model_name_or_path", ",", "\n", "checkpoint_file", "=", "\"model.pt\"", ",", "\n", "data_name_or_path", "=", "\".\"", ",", "\n", "bpe", "=", "\"gpt2\"", ",", "\n", "sample_break_mode", "=", "\"eos\"", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "from", "fairseq", "import", "hub_utils", "\n", "\n", "x", "=", "hub_utils", ".", "from_pretrained", "(", "\n", "model_name_or_path", ",", "\n", "checkpoint_file", ",", "\n", "data_name_or_path", ",", "\n", "archive_map", "=", "cls", ".", "hub_models", "(", ")", ",", "\n", "bpe", "=", "bpe", ",", "\n", "load_checkpoint_heads", "=", "True", ",", "\n", "sample_break_mode", "=", "sample_break_mode", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "return", "BARTHubInterface", "(", "x", "[", "\"args\"", "]", ",", "x", "[", "\"task\"", "]", ",", "x", "[", "\"models\"", "]", "[", "0", "]", ")", "\n", "\n", "", "def", "register_classification_head", "(", "\n", "self", ",", "name", ",", "num_classes", "=", "None", ",", "inner_dim", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Register a classification head.\"\"\"", "\n", "logger", ".", "info", "(", "\"Registering classification head: {0}\"", ".", "format", "(", "name", ")", ")", "\n", "if", "name", "in", "self", ".", "classification_heads", ":", "\n", "            ", "prev_num_classes", "=", "self", ".", "classification_heads", "[", "name", "]", ".", "out_proj", ".", "out_features", "\n", "prev_inner_dim", "=", "self", ".", "classification_heads", "[", "name", "]", ".", "dense", ".", "out_features", "\n", "if", "num_classes", "!=", "prev_num_classes", "or", "inner_dim", "!=", "prev_inner_dim", ":", "\n", "                ", "logger", ".", "warning", "(", "\n", "'re-registering head \"{}\" with num_classes {} (prev: {}) '", "\n", "\"and inner_dim {} (prev: {})\"", ".", "format", "(", "\n", "name", ",", "num_classes", ",", "prev_num_classes", ",", "inner_dim", ",", "prev_inner_dim", "\n", ")", "\n", ")", "\n", "", "", "self", ".", "classification_heads", "[", "name", "]", "=", "BARTClassificationHead", "(", "\n", "input_dim", "=", "self", ".", "args", ".", "encoder_embed_dim", ",", "\n", "inner_dim", "=", "inner_dim", "or", "self", ".", "args", ".", "encoder_embed_dim", ",", "\n", "num_classes", "=", "num_classes", ",", "\n", "activation_fn", "=", "self", ".", "args", ".", "pooler_activation_fn", ",", "\n", "pooler_dropout", "=", "self", ".", "args", ".", "pooler_dropout", ",", "\n", "do_spectral_norm", "=", "getattr", "(", "\n", "self", ".", "args", ",", "\"spectral_norm_classification_head\"", ",", "False", "\n", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.RobertaModel.build_model": [[166, 178], ["model.base_architecture", "model.RobertaEncoder", "cls", "hasattr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "super", "(", ")", ".", "upgrade_state_dict_named", "(", "state_dict", ",", "name", ")", "\n", "\n", "prefix", "=", "name", "+", "\".\"", "if", "name", "!=", "\"\"", "else", "\"\"", "\n", "current_head_names", "=", "(", "\n", "[", "]", "\n", "if", "not", "hasattr", "(", "self", ",", "\"classification_heads\"", ")", "\n", "else", "self", ".", "classification_heads", ".", "keys", "(", ")", "\n", ")", "\n", "\n", "# Handle new classification heads present in the state dict.", "\n", "keys_to_delete", "=", "[", "]", "\n", "for", "k", "in", "state_dict", ".", "keys", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.RobertaModel.forward": [[179, 195], ["model.RobertaModel.encoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder"], ["            ", "if", "not", "k", ".", "startswith", "(", "prefix", "+", "\"classification_heads.\"", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "head_name", "=", "k", "[", "len", "(", "prefix", "+", "\"classification_heads.\"", ")", ":", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", "\n", "num_classes", "=", "state_dict", "[", "\n", "prefix", "+", "\"classification_heads.\"", "+", "head_name", "+", "\".out_proj.weight\"", "\n", "]", ".", "size", "(", "0", ")", "\n", "inner_dim", "=", "state_dict", "[", "\n", "prefix", "+", "\"classification_heads.\"", "+", "head_name", "+", "\".dense.weight\"", "\n", "]", ".", "size", "(", "0", ")", "\n", "\n", "if", "getattr", "(", "self", ".", "args", ",", "\"load_checkpoint_heads\"", ",", "False", ")", ":", "\n", "                ", "if", "head_name", "not", "in", "current_head_names", ":", "\n", "                    ", "self", ".", "register_classification_head", "(", "head_name", ",", "num_classes", ",", "inner_dim", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "head_name", "not", "in", "current_head_names", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.RobertaModel.get_normalized_probs": [[196, 203], ["net_output[].float", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax"], ["\"deleting classification head ({}) from checkpoint \"", "\n", "\"not present in current model: {}\"", ".", "format", "(", "head_name", ",", "k", ")", "\n", ")", "\n", "keys_to_delete", ".", "append", "(", "k", ")", "\n", "", "elif", "(", "\n", "num_classes", "\n", "!=", "self", ".", "classification_heads", "[", "head_name", "]", ".", "out_proj", ".", "out_features", "\n", "or", "inner_dim", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.RobertaModel.register_classification_head": [[204, 227], ["model.RobertaClassificationHead", "logger.warning"], "methods", ["None"], ["!=", "self", ".", "classification_heads", "[", "head_name", "]", ".", "dense", ".", "out_features", "\n", ")", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "\"deleting classification head ({}) from checkpoint \"", "\n", "\"with different dimensions than current model: {}\"", ".", "format", "(", "\n", "head_name", ",", "k", "\n", ")", "\n", ")", "\n", "keys_to_delete", ".", "append", "(", "k", ")", "\n", "", "", "", "for", "k", "in", "keys_to_delete", ":", "\n", "            ", "del", "state_dict", "[", "k", "]", "\n", "\n", "", "def", "truncate_emb", "(", "key", ")", ":", "\n", "            ", "if", "key", "in", "state_dict", ":", "\n", "                ", "state_dict", "[", "key", "]", "=", "state_dict", "[", "key", "]", "[", ":", "-", "1", ",", ":", "]", "\n", "\n", "# When finetuning on translation task, remove last row of", "\n", "# embedding matrix that corresponds to mask_idx token.", "\n", "", "", "loaded_dict_size", "=", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", ".", "size", "(", "0", ")", "\n", "if", "(", "\n", "loaded_dict_size", "==", "len", "(", "self", ".", "encoder", ".", "dictionary", ")", "+", "1", "\n", "and", "\"<mask>\"", "not", "in", "self", ".", "encoder", ".", "dictionary", "\n", ")", ":", "\n", "            ", "truncate_emb", "(", "\"encoder.embed_tokens.weight\"", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.RobertaModel.supported_targets": [[229, 232], ["None"], "methods", ["None"], ["truncate_emb", "(", "\"encoder.output_projection.weight\"", ")", "\n", "truncate_emb", "(", "\"decoder.output_projection.weight\"", ")", "\n", "\n", "# When continued pretraining on new set of languages for mbart,", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.RobertaModel.from_pretrained": [[233, 256], ["hub_utils.from_pretrained", "logger.info", "hub_interface.RobertaHubInterface", "cls.hub_models"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model_xlmr.XLMRModel.from_pretrained", "home.repos.pwc.inspect_result.reneeye_const.roberta.model_xlmr.XLMRModel.hub_models"], ["# add extra lang embeddings at the end of embed_tokens.", "\n", "# Note: newly added languages are assumed to have been added at the end.", "\n", "", "if", "self", ".", "args", ".", "task", "==", "\"multilingual_denoising\"", "and", "loaded_dict_size", "<", "len", "(", "\n", "self", ".", "encoder", ".", "dictionary", "\n", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Adding extra language embeddings not found in pretrained model for \"", "\n", "\"continued pretraining of MBART on new set of languages.\"", "\n", ")", "\n", "loaded_mask_token_embedding", "=", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", "[", "\n", "-", "1", ",", ":", "\n", "]", "\n", "\n", "num_langids_to_add", "=", "len", "(", "self", ".", "encoder", ".", "dictionary", ")", "-", "loaded_dict_size", "\n", "embed_dim", "=", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", ".", "size", "(", "1", ")", "\n", "\n", "new_lang_embed_to_add", "=", "torch", ".", "zeros", "(", "num_langids_to_add", ",", "embed_dim", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "new_lang_embed_to_add", ",", "mean", "=", "0", ",", "std", "=", "embed_dim", "**", "-", "0.5", ")", "\n", "new_lang_embed_to_add", "=", "new_lang_embed_to_add", ".", "to", "(", "\n", "dtype", "=", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", ".", "dtype", ",", "\n", ")", "\n", "\n", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", "=", "torch", ".", "cat", "(", "\n", "[", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.RobertaModel.upgrade_state_dict_named": [[257, 323], ["list", "super().upgrade_state_dict_named", "state_dict.keys", "hasattr", "state_dict.keys", "k.startswith", "model.RobertaModel.classification_heads.keys", "state_dict[].size", "state_dict[].size", "getattr", "model.RobertaModel.classification_heads.state_dict", "model.RobertaModel.items", "hasattr", "k.startswith", "k[].split", "model.RobertaModel.register_classification_head", "logger.warning", "keys_to_delete.append", "logger.info", "logger.warning", "keys_to_delete.append", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.upgrade_state_dict_named", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.state_dict", "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaModel.register_classification_head"], ["state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", "[", "\n", ":", "loaded_dict_size", "-", "1", ",", ":", "\n", "]", ",", "\n", "new_lang_embed_to_add", ",", "\n", "loaded_mask_token_embedding", ".", "unsqueeze", "(", "0", ")", ",", "\n", "]", "\n", ")", "\n", "state_dict", "[", "\"decoder.embed_tokens.weight\"", "]", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "state_dict", "[", "\"decoder.embed_tokens.weight\"", "]", "[", "\n", ":", "loaded_dict_size", "-", "1", ",", ":", "\n", "]", ",", "\n", "new_lang_embed_to_add", ",", "\n", "loaded_mask_token_embedding", ".", "unsqueeze", "(", "0", ")", ",", "\n", "]", "\n", ")", "\n", "\n", "# Copy any newly-added classification heads into the state dict", "\n", "# with their current weights.", "\n", "", "if", "hasattr", "(", "self", ",", "\"classification_heads\"", ")", ":", "\n", "            ", "cur_state", "=", "self", ".", "classification_heads", ".", "state_dict", "(", ")", "\n", "for", "k", ",", "v", "in", "cur_state", ".", "items", "(", ")", ":", "\n", "                ", "if", "prefix", "+", "\"classification_heads.\"", "+", "k", "not", "in", "state_dict", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Overwriting\"", ",", "prefix", "+", "\"classification_heads.\"", "+", "k", ")", "\n", "state_dict", "[", "prefix", "+", "\"classification_heads.\"", "+", "k", "]", "=", "v", "\n", "\n", "\n", "", "", "", "", "", "class", "BARTClassificationHead", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Head for sentence-level classification tasks.\"\"\"", "\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "input_dim", ",", "\n", "inner_dim", ",", "\n", "num_classes", ",", "\n", "activation_fn", ",", "\n", "pooler_dropout", ",", "\n", "do_spectral_norm", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "input_dim", ",", "inner_dim", ")", "\n", "self", ".", "activation_fn", "=", "utils", ".", "get_activation_fn", "(", "activation_fn", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "pooler_dropout", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "inner_dim", ",", "num_classes", ")", "\n", "\n", "if", "do_spectral_norm", ":", "\n", "            ", "self", ".", "out_proj", "=", "torch", ".", "nn", ".", "utils", ".", "spectral_norm", "(", "self", ".", "out_proj", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "features", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "self", ".", "activation_fn", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "return", "x", "\n", "\n", "\n", "", "", "@", "register_model_architecture", "(", "\"bart\"", ",", "\"bart_large\"", ")", "\n", "def", "bart_large_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_path", "=", "getattr", "(", "args", ",", "\"encoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "1024", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "4", "*", "1024", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "12", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "16", ")", "\n", "args", ".", "encoder_normalize_before", "=", "getattr", "(", "args", ",", "\"encoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "encoder_learned_pos", "=", "getattr", "(", "args", ",", "\"encoder_learned_pos\"", ",", "True", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.RobertaLMHead.__init__": [[328, 338], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "fairseq.utils.get_activation_fn", "fairseq.modules.LayerNorm", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], [")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "12", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "16", ")", "\n", "args", ".", "decoder_normalize_before", "=", "getattr", "(", "args", ",", "\"decoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "decoder_learned_pos", "=", "getattr", "(", "args", ",", "\"decoder_learned_pos\"", ",", "True", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.0", ")", "\n", "args", ".", "relu_dropout", "=", "getattr", "(", "args", ",", "\"relu_dropout\"", ",", "0.0", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n", "args", ".", "max_target_positions", "=", "getattr", "(", "args", ",", "\"max_target_positions\"", ",", "1024", ")", "\n", "args", ".", "max_source_positions", "=", "getattr", "(", "args", ",", "\"max_source_positions\"", ",", "1024", ")", "\n", "args", ".", "adaptive_softmax_cutoff", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_cutoff\"", ",", "None", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.RobertaLMHead.forward": [[339, 351], ["model.RobertaLMHead.dense", "model.RobertaLMHead.activation_fn", "model.RobertaLMHead.layer_norm", "torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["args", ".", "adaptive_softmax_dropout", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_dropout\"", ",", "0", ")", "\n", "args", ".", "share_decoder_input_output_embed", "=", "getattr", "(", "\n", "args", ",", "\"share_decoder_input_output_embed\"", ",", "True", "\n", ")", "\n", "args", ".", "share_all_embeddings", "=", "getattr", "(", "args", ",", "\"share_all_embeddings\"", ",", "True", ")", "\n", "\n", "args", ".", "decoder_output_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_output_dim\"", ",", "args", ".", "decoder_embed_dim", "\n", ")", "\n", "args", ".", "decoder_input_dim", "=", "getattr", "(", "args", ",", "\"decoder_input_dim\"", ",", "args", ".", "decoder_embed_dim", ")", "\n", "\n", "args", ".", "no_scale_embedding", "=", "getattr", "(", "args", ",", "\"no_scale_embedding\"", ",", "True", ")", "\n", "args", ".", "layernorm_embedding", "=", "getattr", "(", "args", ",", "\"layernorm_embedding\"", ",", "True", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.RobertaClassificationHead.__init__": [[356, 380], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "fairseq.utils.get_activation_fn", "torch.Dropout", "torch.Dropout", "torch.Dropout", "fairseq.modules.quant_noise.quant_noise", "torch.Linear", "torch.Linear", "torch.Linear", "torch.nn.utils.spectral_norm", "torch.nn.utils.spectral_norm", "torch.nn.utils.spectral_norm", "torch.nn.utils.spectral_norm", "torch.nn.utils.spectral_norm", "torch.nn.utils.spectral_norm", "torch.nn.utils.spectral_norm", "torch.nn.utils.spectral_norm", "torch.nn.utils.spectral_norm", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.reneeye_const.modules.quant_noise.quant_noise", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["\n", "\n", "", "@", "register_model_architecture", "(", "\"bart\"", ",", "\"bart_base\"", ")", "\n", "def", "bart_base_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "768", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "4", "*", "768", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "6", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "12", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "6", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "12", ")", "\n", "bart_large_architecture", "(", "args", ")", "\n", "\n", "\n", "", "@", "register_model_architecture", "(", "\"bart\"", ",", "\"mbart_large\"", ")", "\n", "def", "mbart_large_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "no_scale_embedding", "=", "getattr", "(", "args", ",", "\"no_scale_embedding\"", ",", "False", ")", "\n", "bart_large_architecture", "(", "args", ")", "\n", "\n", "\n", "", "@", "register_model_architecture", "(", "\"bart\"", ",", "\"mbart_base\"", ")", "\n", "def", "mbart_base_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "no_scale_embedding", "=", "getattr", "(", "args", ",", "\"no_scale_embedding\"", ",", "False", ")", "\n", "bart_base_architecture", "(", "args", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.RobertaClassificationHead.forward": [[381, 389], ["model.RobertaClassificationHead.dropout", "model.RobertaClassificationHead.dense", "model.RobertaClassificationHead.activation_fn", "model.RobertaClassificationHead.dropout", "model.RobertaClassificationHead.out_proj"], "methods", ["None"], ["", "@", "register_model_architecture", "(", "\"bart\"", ",", "\"mbart_base_wmt20\"", ")", "\n", "def", "mbart_base_wmt20_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "layernorm_embedding", "=", "getattr", "(", "args", ",", "\"layernorm_embedding\"", ",", "False", ")", "\n", "mbart_base_architecture", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.RobertaEncoder.__init__": [[394, 432], ["fairseq.models.FairseqEncoder.__init__", "model.base_architecture", "fairseq.modules.TransformerSentenceEncoder", "model.RobertaLMHead", "len", "args.encoder_layers_to_keep.split", "dictionary.pad", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], []], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.RobertaEncoder.forward": [[435, 465], ["model.RobertaEncoder.extract_features", "model.RobertaEncoder.output_layer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.output_layer"], []], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.RobertaEncoder.extract_features": [[466, 474], ["model.RobertaEncoder.sentence_encoder", "inner_states[].transpose", "kwargs.get"], "methods", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.RobertaEncoder.output_layer": [[475, 477], ["model.RobertaEncoder.lm_head"], "methods", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.RobertaEncoder.max_positions": [[478, 481], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.base_architecture": [[258, 274], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], [":", "loaded_dict_size", "-", "1", ",", ":", "\n", "]", ",", "\n", "new_lang_embed_to_add", ",", "\n", "loaded_mask_token_embedding", ".", "unsqueeze", "(", "0", ")", ",", "\n", "]", "\n", ")", "\n", "state_dict", "[", "\"decoder.embed_tokens.weight\"", "]", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "state_dict", "[", "\"decoder.embed_tokens.weight\"", "]", "[", "\n", ":", "loaded_dict_size", "-", "1", ",", ":", "\n", "]", ",", "\n", "new_lang_embed_to_add", ",", "\n", "loaded_mask_token_embedding", ".", "unsqueeze", "(", "0", ")", ",", "\n", "]", "\n", ")", "\n", "\n", "# Copy any newly-added classification heads into the state dict", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.roberta_base_architecture": [[276, 279], ["fairseq.models.register_model_architecture", "model.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["", "if", "hasattr", "(", "self", ",", "\"classification_heads\"", ")", ":", "\n", "            ", "cur_state", "=", "self", ".", "classification_heads", ".", "state_dict", "(", ")", "\n", "for", "k", ",", "v", "in", "cur_state", ".", "items", "(", ")", ":", "\n", "                ", "if", "prefix", "+", "\"classification_heads.\"", "+", "k", "not", "in", "state_dict", ":", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.roberta_large_architecture": [[281, 288], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "model.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], ["state_dict", "[", "prefix", "+", "\"classification_heads.\"", "+", "k", "]", "=", "v", "\n", "\n", "\n", "", "", "", "", "", "class", "BARTClassificationHead", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Head for sentence-level classification tasks.\"\"\"", "\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.xlm_architecture": [[519, 526], ["fairseq.models.register_model_architecture", "getattr", "getattr", "getattr", "getattr", "model.base_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture"], []], "home.repos.pwc.inspect_result.reneeye_const.roberta.alignment_utils.align_bpe_to_words": [[12, 69], ["filter", "next", "bpe_tokens.dim", "text.strip", "roberta.task.source_dictionary.string", "alignment_utils.align_bpe_to_words.clean"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.string"], ["def", "align_bpe_to_words", "(", "roberta", ",", "bpe_tokens", ":", "torch", ".", "LongTensor", ",", "other_tokens", ":", "List", "[", "str", "]", ")", ":", "\n", "    ", "\"\"\"\n    Helper to align GPT-2 BPE to other tokenization formats (e.g., spaCy).\n\n    Args:\n        roberta (RobertaHubInterface): RoBERTa instance\n        bpe_tokens (torch.LongTensor): GPT-2 BPE tokens of shape `(T_bpe)`\n        other_tokens (List[str]): other tokens of shape `(T_words)`\n\n    Returns:\n        List[str]: mapping from *other_tokens* to corresponding *bpe_tokens*.\n    \"\"\"", "\n", "assert", "bpe_tokens", ".", "dim", "(", ")", "==", "1", "\n", "assert", "bpe_tokens", "[", "0", "]", "==", "0", "\n", "\n", "def", "clean", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "strip", "(", ")", "\n", "\n", "# remove whitespaces to simplify alignment", "\n", "", "bpe_tokens", "=", "[", "roberta", ".", "task", ".", "source_dictionary", ".", "string", "(", "[", "x", "]", ")", "for", "x", "in", "bpe_tokens", "]", "\n", "bpe_tokens", "=", "[", "\n", "clean", "(", "roberta", ".", "bpe", ".", "decode", "(", "x", ")", "if", "x", "not", "in", "{", "\"<s>\"", ",", "\"\"", "}", "else", "x", ")", "for", "x", "in", "bpe_tokens", "\n", "]", "\n", "other_tokens", "=", "[", "clean", "(", "str", "(", "o", ")", ")", "for", "o", "in", "other_tokens", "]", "\n", "\n", "# strip leading <s>", "\n", "bpe_tokens", "=", "bpe_tokens", "[", "1", ":", "]", "\n", "assert", "\"\"", ".", "join", "(", "bpe_tokens", ")", "==", "\"\"", ".", "join", "(", "other_tokens", ")", "\n", "\n", "# create alignment from every word to a list of BPE tokens", "\n", "alignment", "=", "[", "]", "\n", "bpe_toks", "=", "filter", "(", "lambda", "item", ":", "item", "[", "1", "]", "!=", "\"\"", ",", "enumerate", "(", "bpe_tokens", ",", "start", "=", "1", ")", ")", "\n", "j", ",", "bpe_tok", "=", "next", "(", "bpe_toks", ")", "\n", "for", "other_tok", "in", "other_tokens", ":", "\n", "        ", "bpe_indices", "=", "[", "]", "\n", "while", "True", ":", "\n", "            ", "if", "other_tok", ".", "startswith", "(", "bpe_tok", ")", ":", "\n", "                ", "bpe_indices", ".", "append", "(", "j", ")", "\n", "other_tok", "=", "other_tok", "[", "len", "(", "bpe_tok", ")", ":", "]", "\n", "try", ":", "\n", "                    ", "j", ",", "bpe_tok", "=", "next", "(", "bpe_toks", ")", "\n", "", "except", "StopIteration", ":", "\n", "                    ", "j", ",", "bpe_tok", "=", "None", ",", "None", "\n", "", "", "elif", "bpe_tok", ".", "startswith", "(", "other_tok", ")", ":", "\n", "# other_tok spans multiple BPE tokens", "\n", "                ", "bpe_indices", ".", "append", "(", "j", ")", "\n", "bpe_tok", "=", "bpe_tok", "[", "len", "(", "other_tok", ")", ":", "]", "\n", "other_tok", "=", "\"\"", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "'Cannot align \"{}\" and \"{}\"'", ".", "format", "(", "other_tok", ",", "bpe_tok", ")", ")", "\n", "", "if", "other_tok", "==", "\"\"", ":", "\n", "                ", "break", "\n", "", "", "assert", "len", "(", "bpe_indices", ")", ">", "0", "\n", "alignment", ".", "append", "(", "bpe_indices", ")", "\n", "", "assert", "len", "(", "alignment", ")", "==", "len", "(", "other_tokens", ")", "\n", "\n", "return", "alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.alignment_utils.align_features_to_words": [[71, 98], ["collections.Counter", "features.new", "range", "torch.stack", "torch.all", "features.dim", "features.new.unsqueeze", "torch.stack.append", "max", "len", "torch.stack.append", "collections.Counter.get", "weighted_features[].sum", "torch.abs", "range", "len", "torch.stack.sum", "features.sum"], "function", ["None"], ["", "def", "align_features_to_words", "(", "roberta", ",", "features", ",", "alignment", ")", ":", "\n", "    ", "\"\"\"\n    Align given features to words.\n\n    Args:\n        roberta (RobertaHubInterface): RoBERTa instance\n        features (torch.Tensor): features to align of shape `(T_bpe x C)`\n        alignment: alignment between BPE tokens and words returned by\n            func:`align_bpe_to_words`.\n    \"\"\"", "\n", "assert", "features", ".", "dim", "(", ")", "==", "2", "\n", "\n", "bpe_counts", "=", "Counter", "(", "j", "for", "bpe_indices", "in", "alignment", "for", "j", "in", "bpe_indices", ")", "\n", "assert", "bpe_counts", "[", "0", "]", "==", "0", "# <s> shouldn't be aligned", "\n", "denom", "=", "features", ".", "new", "(", "[", "bpe_counts", ".", "get", "(", "j", ",", "1", ")", "for", "j", "in", "range", "(", "len", "(", "features", ")", ")", "]", ")", "\n", "weighted_features", "=", "features", "/", "denom", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "output", "=", "[", "weighted_features", "[", "0", "]", "]", "\n", "largest_j", "=", "-", "1", "\n", "for", "bpe_indices", "in", "alignment", ":", "\n", "        ", "output", ".", "append", "(", "weighted_features", "[", "bpe_indices", "]", ".", "sum", "(", "dim", "=", "0", ")", ")", "\n", "largest_j", "=", "max", "(", "largest_j", ",", "*", "bpe_indices", ")", "\n", "", "for", "j", "in", "range", "(", "largest_j", "+", "1", ",", "len", "(", "features", ")", ")", ":", "\n", "        ", "output", ".", "append", "(", "weighted_features", "[", "j", "]", ")", "\n", "", "output", "=", "torch", ".", "stack", "(", "output", ")", "\n", "assert", "torch", ".", "all", "(", "torch", ".", "abs", "(", "output", ".", "sum", "(", "dim", "=", "0", ")", "-", "features", ".", "sum", "(", "dim", "=", "0", ")", ")", "<", "1e-4", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.alignment_utils.spacy_nlp": [[100, 109], ["getattr", "English", "ImportError"], "function", ["None"], ["", "def", "spacy_nlp", "(", ")", ":", "\n", "    ", "if", "getattr", "(", "spacy_nlp", ",", "\"_nlp\"", ",", "None", ")", "is", "None", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "spacy", ".", "lang", ".", "en", "import", "English", "\n", "\n", "spacy_nlp", ".", "_nlp", "=", "English", "(", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install spacy with: pip install spacy\"", ")", "\n", "", "", "return", "spacy_nlp", ".", "_nlp", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.alignment_utils.spacy_tokenizer": [[111, 119], ["getattr", "alignment_utils.spacy_nlp", "spacy_nlp.Defaults.create_tokenizer", "ImportError"], "function", ["home.repos.pwc.inspect_result.reneeye_const.roberta.alignment_utils.spacy_nlp"], ["", "def", "spacy_tokenizer", "(", ")", ":", "\n", "    ", "if", "getattr", "(", "spacy_tokenizer", ",", "\"_tokenizer\"", ",", "None", ")", "is", "None", ":", "\n", "        ", "try", ":", "\n", "            ", "nlp", "=", "spacy_nlp", "(", ")", "\n", "spacy_tokenizer", ".", "_tokenizer", "=", "nlp", ".", "Defaults", ".", "create_tokenizer", "(", "nlp", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install spacy with: pip install spacy\"", ")", "\n", "", "", "return", "spacy_tokenizer", ".", "_tokenizer", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model_xlmr.XLMRModel.hub_models": [[17, 22], ["None"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "hub_models", "(", "cls", ")", ":", "\n", "        ", "return", "{", "\n", "\"xlmr.base\"", ":", "\"http://dl.fbaipublicfiles.com/fairseq/models/xlmr.base.tar.gz\"", ",", "\n", "\"xlmr.large\"", ":", "\"http://dl.fbaipublicfiles.com/fairseq/models/xlmr.large.tar.gz\"", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model_xlmr.XLMRModel.from_pretrained": [[24, 45], ["hub_utils.from_pretrained", "hub_interface.RobertaHubInterface", "cls.hub_models"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model_xlmr.XLMRModel.from_pretrained", "home.repos.pwc.inspect_result.reneeye_const.roberta.model_xlmr.XLMRModel.hub_models"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "\n", "cls", ",", "\n", "model_name_or_path", ",", "\n", "checkpoint_file", "=", "\"model.pt\"", ",", "\n", "data_name_or_path", "=", "\".\"", ",", "\n", "bpe", "=", "\"sentencepiece\"", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "from", "fairseq", "import", "hub_utils", "\n", "\n", "x", "=", "hub_utils", ".", "from_pretrained", "(", "\n", "model_name_or_path", ",", "\n", "checkpoint_file", ",", "\n", "data_name_or_path", ",", "\n", "archive_map", "=", "cls", ".", "hub_models", "(", ")", ",", "\n", "bpe", "=", "bpe", ",", "\n", "load_checkpoint_heads", "=", "True", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "return", "RobertaHubInterface", "(", "x", "[", "\"args\"", "]", ",", "x", "[", "\"task\"", "]", ",", "x", "[", "\"models\"", "]", "[", "0", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaModel.__init__": [[44, 48], ["fairseq.models.roberta.RobertaModel.__init__", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["self", ".", "apply", "(", "init_bert_params", ")", "\n", "\n", "self", ".", "classification_heads", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "if", "hasattr", "(", "self", ".", "encoder", ",", "\"dictionary\"", ")", ":", "\n", "            ", "self", ".", "eos", ":", "int", "=", "self", ".", "encoder", ".", "dictionary", ".", "eos", "(", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaModel.add_args": [[49, 52], ["super().add_args"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args"], ["\n", "", "", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "super", "(", "BARTModel", ",", "BARTModel", ")", ".", "add_args", "(", "parser", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaModel.build_model": [[53, 73], ["model.base_architecture", "task.source_dictionary.pad_to_multiple_", "task.target_dictionary.pad_to_multiple_", "getattr", "model.ModelParallelRobertaEncoder", "cls", "hasattr", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad_to_multiple_", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad_to_multiple_", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["parser", ".", "add_argument", "(", "\n", "\"--pooler-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability in the masked_lm pooler layers\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pooler-activation-fn\"", ",", "\n", "choices", "=", "utils", ".", "get_available_activation_fns", "(", ")", ",", "\n", "help", "=", "\"activation function to use for pooler layer\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--spectral-norm-classification-head\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Apply spectral normalization on the classification head\"", ",", "\n", ")", "\n", "\n", "", "@", "property", "\n", "def", "supported_targets", "(", "self", ")", ":", "\n", "        ", "return", "{", "\"self\"", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaModel.forward": [[74, 90], ["model.ModelParallelRobertaModel.encoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "src_tokens", ",", "\n", "src_lengths", ",", "\n", "prev_output_tokens", ",", "\n", "features_only", ":", "bool", "=", "False", ",", "\n", "classification_head_name", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "token_embeddings", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "return_all_hiddens", ":", "bool", "=", "True", ",", "\n", "alignment_layer", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "alignment_heads", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "classification_head_name", "is", "not", "None", ":", "\n", "            ", "features_only", "=", "True", "\n", "\n", "", "encoder_out", "=", "self", ".", "encoder", "(", "\n", "src_tokens", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaModel.register_classification_head": [[91, 111], ["model.ModelParallelRobertaClassificationHead", "logger.warning"], "methods", ["None"], ["src_lengths", "=", "src_lengths", ",", "\n", "token_embeddings", "=", "token_embeddings", ",", "\n", "return_all_hiddens", "=", "return_all_hiddens", "\n", ")", "\n", "x", ",", "extra", "=", "self", ".", "decoder", "(", "\n", "prev_output_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", "features_only", "=", "features_only", ",", "\n", "alignment_layer", "=", "alignment_layer", ",", "\n", "alignment_heads", "=", "alignment_heads", ",", "\n", "src_lengths", "=", "src_lengths", ",", "\n", "return_all_hiddens", "=", "return_all_hiddens", ",", "\n", ")", "\n", "eos", ":", "int", "=", "self", ".", "eos", "\n", "if", "classification_head_name", "is", "not", "None", ":", "\n", "            ", "sentence_representation", "=", "x", "[", "\n", "src_tokens", ".", "eq", "(", "eos", ")", ",", ":", "\n", "]", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "for", "k", ",", "head", "in", "self", ".", "classification_heads", ".", "items", "(", ")", ":", "\n", "# for torch script only supports iteration", "\n", "                ", "if", "k", "==", "classification_head_name", ":", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaLMHead.__init__": [[117, 127], ["torch.Module.__init__", "ColumnParallelLinear", "fairseq.utils.get_activation_fn", "fairseq.modules.LayerNorm", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["def", "from_pretrained", "(", "\n", "cls", ",", "\n", "model_name_or_path", ",", "\n", "checkpoint_file", "=", "\"model.pt\"", ",", "\n", "data_name_or_path", "=", "\".\"", ",", "\n", "bpe", "=", "\"gpt2\"", ",", "\n", "sample_break_mode", "=", "\"eos\"", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "from", "fairseq", "import", "hub_utils", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaLMHead.forward": [[128, 144], ["model.ModelParallelRobertaLMHead.dense", "model.ModelParallelRobertaLMHead.activation_fn", "model.ModelParallelRobertaLMHead.layer_norm", "copy_to_model_parallel_region", "torch.linear", "torch.linear", "torch.linear", "gather_from_model_parallel_region().contiguous", "gather_from_model_parallel_region"], "methods", ["None"], ["x", "=", "hub_utils", ".", "from_pretrained", "(", "\n", "model_name_or_path", ",", "\n", "checkpoint_file", ",", "\n", "data_name_or_path", ",", "\n", "archive_map", "=", "cls", ".", "hub_models", "(", ")", ",", "\n", "bpe", "=", "bpe", ",", "\n", "load_checkpoint_heads", "=", "True", ",", "\n", "sample_break_mode", "=", "sample_break_mode", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "return", "BARTHubInterface", "(", "x", "[", "\"args\"", "]", ",", "x", "[", "\"task\"", "]", ",", "x", "[", "\"models\"", "]", "[", "0", "]", ")", "\n", "\n", "", "def", "register_classification_head", "(", "\n", "self", ",", "name", ",", "num_classes", "=", "None", ",", "inner_dim", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Register a classification head.\"\"\"", "\n", "logger", ".", "info", "(", "\"Registering classification head: {0}\"", ".", "format", "(", "name", ")", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaClassificationHead.__init__": [[149, 157], ["torch.Module.__init__", "ColumnParallelLinear", "fairseq.utils.get_activation_fn", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["                ", "logger", ".", "warning", "(", "\n", "'re-registering head \"{}\" with num_classes {} (prev: {}) '", "\n", "\"and inner_dim {} (prev: {})\"", ".", "format", "(", "\n", "name", ",", "num_classes", ",", "prev_num_classes", ",", "inner_dim", ",", "prev_inner_dim", "\n", ")", "\n", ")", "\n", "", "", "self", ".", "classification_heads", "[", "name", "]", "=", "BARTClassificationHead", "(", "\n", "input_dim", "=", "self", ".", "args", ".", "encoder_embed_dim", ",", "\n", "inner_dim", "=", "inner_dim", "or", "self", ".", "args", ".", "encoder_embed_dim", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaClassificationHead.forward": [[158, 166], ["model.ModelParallelRobertaClassificationHead.dropout", "model.ModelParallelRobertaClassificationHead.dense", "model.ModelParallelRobertaClassificationHead.activation_fn", "model.ModelParallelRobertaClassificationHead.dropout", "model.ModelParallelRobertaClassificationHead.out_proj"], "methods", ["None"], ["num_classes", "=", "num_classes", ",", "\n", "activation_fn", "=", "self", ".", "args", ".", "pooler_activation_fn", ",", "\n", "pooler_dropout", "=", "self", ".", "args", ".", "pooler_dropout", ",", "\n", "do_spectral_norm", "=", "getattr", "(", "\n", "self", ".", "args", ",", "\"spectral_norm_classification_head\"", ",", "False", "\n", ")", ",", "\n", ")", "\n", "\n", "", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.__init__": [[175, 209], ["fairseq.models.FairseqEncoder.__init__", "fairseq.model_parallel.modules.ModelParallelTransformerSentenceEncoder", "model.ModelParallelRobertaLMHead", "len", "args.encoder_layers_to_keep.split", "dictionary.pad", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["\n", "# Handle new classification heads present in the state dict.", "\n", "keys_to_delete", "=", "[", "]", "\n", "for", "k", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "if", "not", "k", ".", "startswith", "(", "prefix", "+", "\"classification_heads.\"", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "head_name", "=", "k", "[", "len", "(", "prefix", "+", "\"classification_heads.\"", ")", ":", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", "\n", "num_classes", "=", "state_dict", "[", "\n", "prefix", "+", "\"classification_heads.\"", "+", "head_name", "+", "\".out_proj.weight\"", "\n", "]", ".", "size", "(", "0", ")", "\n", "inner_dim", "=", "state_dict", "[", "\n", "prefix", "+", "\"classification_heads.\"", "+", "head_name", "+", "\".dense.weight\"", "\n", "]", ".", "size", "(", "0", ")", "\n", "\n", "if", "getattr", "(", "self", ".", "args", ",", "\"load_checkpoint_heads\"", ",", "False", ")", ":", "\n", "                ", "if", "head_name", "not", "in", "current_head_names", ":", "\n", "                    ", "self", ".", "register_classification_head", "(", "head_name", ",", "num_classes", ",", "inner_dim", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "head_name", "not", "in", "current_head_names", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "\"deleting classification head ({}) from checkpoint \"", "\n", "\"not present in current model: {}\"", ".", "format", "(", "head_name", ",", "k", ")", "\n", ")", "\n", "keys_to_delete", ".", "append", "(", "k", ")", "\n", "", "elif", "(", "\n", "num_classes", "\n", "!=", "self", ".", "classification_heads", "[", "head_name", "]", ".", "out_proj", ".", "out_features", "\n", "or", "inner_dim", "\n", "!=", "self", ".", "classification_heads", "[", "head_name", "]", ".", "dense", ".", "out_features", "\n", ")", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "\"deleting classification head ({}) from checkpoint \"", "\n", "\"with different dimensions than current model: {}\"", ".", "format", "(", "\n", "head_name", ",", "k", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.forward": [[211, 241], ["model.ModelParallelRobertaEncoder.extract_features", "model.ModelParallelRobertaEncoder.output_layer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.output_layer"], [")", "\n", "keys_to_delete", ".", "append", "(", "k", ")", "\n", "", "", "", "for", "k", "in", "keys_to_delete", ":", "\n", "            ", "del", "state_dict", "[", "k", "]", "\n", "\n", "", "def", "truncate_emb", "(", "key", ")", ":", "\n", "            ", "if", "key", "in", "state_dict", ":", "\n", "                ", "state_dict", "[", "key", "]", "=", "state_dict", "[", "key", "]", "[", ":", "-", "1", ",", ":", "]", "\n", "\n", "# When finetuning on translation task, remove last row of", "\n", "# embedding matrix that corresponds to mask_idx token.", "\n", "", "", "loaded_dict_size", "=", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", ".", "size", "(", "0", ")", "\n", "if", "(", "\n", "loaded_dict_size", "==", "len", "(", "self", ".", "encoder", ".", "dictionary", ")", "+", "1", "\n", "and", "\"<mask>\"", "not", "in", "self", ".", "encoder", ".", "dictionary", "\n", ")", ":", "\n", "            ", "truncate_emb", "(", "\"encoder.embed_tokens.weight\"", ")", "\n", "truncate_emb", "(", "\"decoder.embed_tokens.weight\"", ")", "\n", "truncate_emb", "(", "\"encoder.output_projection.weight\"", ")", "\n", "truncate_emb", "(", "\"decoder.output_projection.weight\"", ")", "\n", "\n", "# When continued pretraining on new set of languages for mbart,", "\n", "# add extra lang embeddings at the end of embed_tokens.", "\n", "# Note: newly added languages are assumed to have been added at the end.", "\n", "", "if", "self", ".", "args", ".", "task", "==", "\"multilingual_denoising\"", "and", "loaded_dict_size", "<", "len", "(", "\n", "self", ".", "encoder", ".", "dictionary", "\n", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Adding extra language embeddings not found in pretrained model for \"", "\n", "\"continued pretraining of MBART on new set of languages.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.extract_features": [[242, 249], ["model.ModelParallelRobertaEncoder.sentence_encoder", "inner_states[].transpose"], "methods", ["None"], ["loaded_mask_token_embedding", "=", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", "[", "\n", "-", "1", ",", ":", "\n", "]", "\n", "\n", "num_langids_to_add", "=", "len", "(", "self", ".", "encoder", ".", "dictionary", ")", "-", "loaded_dict_size", "\n", "embed_dim", "=", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", ".", "size", "(", "1", ")", "\n", "\n", "new_lang_embed_to_add", "=", "torch", ".", "zeros", "(", "num_langids_to_add", ",", "embed_dim", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.output_layer": [[250, 252], ["model.ModelParallelRobertaEncoder.lm_head"], "methods", ["None"], ["nn", ".", "init", ".", "normal_", "(", "new_lang_embed_to_add", ",", "mean", "=", "0", ",", "std", "=", "embed_dim", "**", "-", "0.5", ")", "\n", "new_lang_embed_to_add", "=", "new_lang_embed_to_add", ".", "to", "(", "\n", "dtype", "=", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", ".", "dtype", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.roberta.model.ModelParallelRobertaEncoder.max_positions": [[253, 256], ["None"], "methods", ["None"], [")", "\n", "\n", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", "=", "torch", ".", "cat", "(", "\n", "[", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.model_parallel.megatron_trainer.MegatronTrainer.__init__": [[30, 38], ["fairseq.trainer.Trainer.__init__", "ImportError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ":", "FairseqConfig", ",", "task", ",", "model", ",", "criterion", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "has_megatron_submodule", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"\\n\\nPlease install the megatron submodule:\"", "\n", "\"\\n\\n  git submodule update --init \"", "\n", "\"fairseq/model_parallel/megatron\"", "\n", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "task", ",", "model", ",", "criterion", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.model_parallel.megatron_trainer.MegatronTrainer.clip_grad_norm": [[39, 51], ["megatron_trainer.MegatronTrainer.optimizer.clip_grad_norm", "fairseq.distributed_utils.all_reduce", "fairseq.distributed_utils.get_model_parallel_group"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.model_parallel.megatron_trainer.MegatronTrainer.clip_grad_norm", "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_model_parallel_group"], ["", "def", "clip_grad_norm", "(", "self", ",", "clip_norm", ")", ":", "\n", "        ", "def", "_aggregate_model_parallel_grad_norm", "(", "total_norm", ")", ":", "\n", "            ", "total_norm", "=", "total_norm", "**", "2", "\n", "distributed_utils", ".", "all_reduce", "(", "\n", "total_norm", ",", "group", "=", "distributed_utils", ".", "get_model_parallel_group", "(", ")", "\n", ")", "\n", "total_norm", "=", "total_norm", "**", "0.5", "\n", "return", "total_norm", "\n", "\n", "", "return", "self", ".", "optimizer", ".", "clip_grad_norm", "(", "\n", "clip_norm", ",", "\n", "aggregate_norm_fn", "=", "_aggregate_model_parallel_grad_norm", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.model_parallel.megatron_trainer.MegatronTrainer.save_checkpoint": [[53, 58], ["get_cuda_rng_tracker().get_states", "super().save_checkpoint", "get_cuda_rng_tracker"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.model_parallel.megatron_trainer.MegatronTrainer.save_checkpoint"], ["", "def", "save_checkpoint", "(", "self", ",", "filename", ",", "extra_state", ")", ":", "\n", "        ", "\"\"\"Save all training state in a checkpoint file.\"\"\"", "\n", "extra_state", "[", "'rng_tracker_states'", "]", "=", "get_cuda_rng_tracker", "(", ")", ".", "get_states", "(", ")", "\n", "super", "(", ")", ".", "save_checkpoint", "(", "filename", ",", "extra_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.model_parallel.megatron_trainer.MegatronTrainer.load_checkpoint": [[59, 72], ["super().load_checkpoint", "get_cuda_rng_tracker().set_states", "get_cuda_rng_tracker"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.model_parallel.megatron_trainer.MegatronTrainer.load_checkpoint"], ["", "def", "load_checkpoint", "(", "\n", "self", ",", "\n", "filename", ",", "\n", "reset_optimizer", "=", "False", ",", "\n", "reset_lr_scheduler", "=", "False", ",", "\n", "optimizer_overrides", "=", "None", ",", "\n", "reset_meters", "=", "False", ",", "\n", ")", ":", "\n", "        ", "extra_state", "=", "super", "(", ")", ".", "load_checkpoint", "(", "filename", ",", "reset_optimizer", "=", "reset_optimizer", ",", "reset_lr_scheduler", "=", "reset_lr_scheduler", ",", "optimizer_overrides", "=", "optimizer_overrides", ",", "reset_meters", "=", "reset_meters", ")", "\n", "if", "extra_state", "is", "not", "None", "and", "'rng_tracker_states'", "in", "extra_state", ":", "\n", "            ", "get_cuda_rng_tracker", "(", ")", ".", "set_states", "(", "\n", "extra_state", "[", "'rng_tracker_states'", "]", ")", "\n", "", "return", "extra_state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerEncoderEmbedding.__init__": [[35, 61], ["torch.Module.__init__", "isinstance", "math.sqrt", "getattr", "sum", "fairseq.modules.PositionalEmbedding", "fairseq.modules.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.PositionalEmbedding", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "self", ",", "args", ",", "embed_tokens", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "args", ".", "dropout", "\n", "self", ".", "max_source_positions", "=", "args", ".", "max_source_positions", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "if", "isinstance", "(", "embed_tokens", ",", "nn", ".", "ModuleList", ")", ":", "\n", "            ", "self", ".", "padding_idx", "=", "embed_tokens", "[", "0", "]", ".", "padding_idx", "\n", "embed_dim", "=", "sum", "(", "e", ".", "embedding_dim", "for", "e", "in", "embed_tokens", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "padding_idx", "=", "embed_tokens", ".", "padding_idx", "\n", "embed_dim", "=", "embed_tokens", ".", "embedding_dim", "\n", "", "self", ".", "embed_scale", "=", "math", ".", "sqrt", "(", "embed_dim", ")", "\n", "self", ".", "embed_positions", "=", "(", "\n", "PositionalEmbedding", "(", "\n", "args", ".", "max_source_positions", ",", "\n", "embed_dim", ",", "\n", "self", ".", "padding_idx", ",", "\n", "learned", "=", "args", ".", "encoder_learned_pos", ",", "\n", ")", "\n", "if", "not", "args", ".", "no_token_positional_embeddings", "\n", "else", "None", "\n", ")", "\n", "if", "getattr", "(", "args", ",", "\"layernorm_embedding\"", ",", "False", ")", ":", "\n", "            ", "self", ".", "layernorm_embedding", "=", "LayerNorm", "(", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layernorm_embedding", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerEncoderEmbedding.forward": [[62, 86], ["isinstance", "torch.dropout", "torch.dropout", "torch.dropout", "layers.TransformerEncoderEmbedding.transpose", "src_tokens.eq", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "layers.TransformerEncoderEmbedding.embed_tokens", "layers.TransformerEncoderEmbedding.layernorm_embedding", "x_embed_list.append", "layers.TransformerEncoderEmbedding.embed_positions", "embed_tokens_part"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# embed tokens and positions", "\n", "        ", "src_tokens", "=", "input", "[", "0", "]", "\n", "prev_output_tokens", "=", "input", "[", "2", "]", "\n", "if", "isinstance", "(", "self", ".", "embed_tokens", ",", "nn", ".", "ModuleList", ")", ":", "\n", "            ", "x_embed_list", "=", "[", "]", "\n", "for", "embed_tokens_part", "in", "self", ".", "embed_tokens", ":", "\n", "                ", "x_embed_list", ".", "append", "(", "embed_tokens_part", "(", "src_tokens", ")", ")", "\n", "\n", "", "embedded", "=", "torch", ".", "cat", "(", "x_embed_list", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "embedded", "=", "self", ".", "embed_tokens", "(", "src_tokens", ")", "\n", "", "x", "=", "embed", "=", "self", ".", "embed_scale", "*", "embedded", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", ":", "\n", "            ", "x", "=", "embed", "+", "self", ".", "embed_positions", "(", "src_tokens", ")", "\n", "", "if", "self", ".", "layernorm_embedding", ":", "\n", "            ", "x", "=", "self", ".", "layernorm_embedding", "(", "x", ")", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# compute padding mask", "\n", "encoder_padding_mask", "=", "src_tokens", ".", "eq", "(", "self", ".", "padding_idx", ")", "\n", "return", "(", "x", ",", "encoder_padding_mask", ",", "prev_output_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerEncoderLayerNorm.__init__": [[94, 100], ["torch.Module.__init__", "fairseq.modules.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "self", ",", "args", ",", "embed_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "args", ".", "encoder_normalize_before", ":", "\n", "            ", "self", ".", "layer_norm", "=", "LayerNorm", "(", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer_norm", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerEncoderLayerNorm.forward": [[101, 109], ["layers.TransformerEncoderLayerNorm.layer_norm"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "x", "=", "input", "[", "0", "]", "\n", "encoder_padding_mask", "=", "input", "[", "1", "]", "\n", "prev_output_tokens", "=", "input", "[", "2", "]", "\n", "if", "self", ".", "layer_norm", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "# keeping track of the incremental_state is not supported yet", "\n", "", "return", "(", "x", ",", "encoder_padding_mask", ",", "prev_output_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderEmbedding.__init__": [[114, 151], ["torch.Module.__init__", "math.sqrt", "isinstance", "sum", "isinstance", "layers.Linear", "fairseq.modules.PositionalEmbedding"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.models.fconv.PositionalEmbedding"], ["def", "__init__", "(", "self", ",", "args", ",", "embed_tokens", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "args", ".", "dropout", "\n", "self", ".", "share_input_output_embed", "=", "args", ".", "share_decoder_input_output_embed", "\n", "input_embed_dim", "=", "(", "\n", "sum", "(", "e", ".", "embedding_dim", "for", "e", "in", "embed_tokens", ")", "\n", "if", "isinstance", "(", "embed_tokens", ",", "nn", ".", "ModuleList", ")", "\n", "else", "embed_tokens", ".", "embedding_dim", "\n", ")", "\n", "embed_dim", "=", "args", ".", "decoder_embed_dim", "\n", "self", ".", "output_embed_dim", "=", "args", ".", "decoder_output_dim", "\n", "\n", "padding_idx", "=", "(", "\n", "embed_tokens", "[", "0", "]", ".", "padding_idx", "\n", "if", "isinstance", "(", "embed_tokens", ",", "nn", ".", "ModuleList", ")", "\n", "else", "embed_tokens", ".", "padding_idx", "\n", ")", "\n", "self", ".", "max_target_positions", "=", "args", ".", "max_target_positions", "\n", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "self", ".", "embed_scale", "=", "math", ".", "sqrt", "(", "embed_dim", ")", "# todo: try with input_embed_dim", "\n", "\n", "self", ".", "project_in_dim", "=", "(", "\n", "Linear", "(", "input_embed_dim", ",", "embed_dim", ",", "bias", "=", "False", ")", "\n", "if", "embed_dim", "!=", "input_embed_dim", "\n", "else", "None", "\n", ")", "\n", "\n", "self", ".", "embed_positions", "=", "(", "\n", "PositionalEmbedding", "(", "\n", "args", ".", "max_target_positions", ",", "\n", "embed_dim", ",", "\n", "padding_idx", ",", "\n", "learned", "=", "args", ".", "decoder_learned_pos", ",", "\n", ")", "\n", "if", "not", "args", ".", "no_token_positional_embeddings", "\n", "else", "None", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderEmbedding.forward": [[153, 213], ["isinstance", "isinstance", "torch.dropout", "torch.dropout", "torch.dropout", "layers.TransformerDecoderEmbedding.transpose", "layers.TransformerDecoderEmbedding.embed_positions", "layers.TransformerDecoderEmbedding.project_in_dim", "len", "x_embed_list.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "layers.TransformerDecoderEmbedding.embed_tokens", "embed_tokens_part"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "mt_task", "=", "False", "\n", "if", "isinstance", "(", "input", ",", "tuple", ")", ":", "\n", "            ", "if", "len", "(", "input", ")", "==", "3", ":", "\n", "                ", "encoder_out", "=", "input", "[", "0", "]", "\n", "encoder_padding_mask", "=", "input", "[", "1", "]", "\n", "prev_output_tokens", "=", "input", "[", "2", "]", "\n", "incremental_state", "=", "None", "# Hardcoding to avoid passing of None objects", "\n", "mt_task", "=", "True", "\n", "", "else", ":", "\n", "# HACK for now, need to fix (TODO sidgoyal)", "\n", "                ", "prev_output_tokens", "=", "input", "[", "0", "]", "\n", "# discard \"src_lengths\"", "\n", "encoder_out", "=", "None", "\n", "encoder_padding_mask", "=", "None", "\n", "incremental_state", "=", "None", "\n", "\n", "", "", "else", ":", "\n", "            ", "prev_output_tokens", "=", "input", "\n", "encoder_out", "=", "None", "\n", "encoder_padding_mask", "=", "None", "\n", "incremental_state", "=", "None", "\n", "\n", "", "positions", "=", "(", "\n", "self", ".", "embed_positions", "(", "\n", "prev_output_tokens", ",", "\n", "incremental_state", "=", "incremental_state", ",", "\n", ")", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "prev_output_tokens", "=", "prev_output_tokens", "[", ":", ",", "-", "1", ":", "]", "\n", "if", "positions", "is", "not", "None", ":", "\n", "                ", "positions", "=", "positions", "[", ":", ",", "-", "1", ":", "]", "\n", "\n", "# embed tokens and positions", "\n", "\n", "", "", "if", "isinstance", "(", "self", ".", "embed_tokens", ",", "nn", ".", "ModuleList", ")", ":", "\n", "            ", "x_embed_list", "=", "[", "]", "\n", "for", "embed_tokens_part", "in", "self", ".", "embed_tokens", ":", "\n", "                ", "x_embed_list", ".", "append", "(", "embed_tokens_part", "(", "prev_output_tokens", ")", ")", "\n", "\n", "", "x", "=", "self", ".", "embed_scale", "*", "torch", ".", "cat", "(", "x_embed_list", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "embed_scale", "*", "self", ".", "embed_tokens", "(", "prev_output_tokens", ")", "\n", "\n", "", "if", "self", ".", "project_in_dim", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "project_in_dim", "(", "x", ")", "\n", "\n", "", "if", "positions", "is", "not", "None", ":", "\n", "            ", "x", "+=", "positions", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "mt_task", ":", "\n", "            ", "return", "(", "x", ",", "encoder_out", ",", "encoder_padding_mask", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderOutputLayer.__init__": [[216, 254], ["torch.Module.__init__", "layers.Linear", "fairseq.modules.AdaptiveSoftmax", "fairseq.modules.LayerNorm", "isinstance", "len", "fairseq.options.eval_str_list", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "getattr", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.eval_str_list"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "embed_tokens", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "share_input_output_embed", "=", "args", ".", "share_decoder_input_output_embed", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "self", ".", "output_embed_dim", "=", "args", ".", "decoder_output_dim", "\n", "embed_dim", "=", "args", ".", "decoder_embed_dim", "\n", "\n", "self", ".", "project_out_dim", "=", "(", "\n", "Linear", "(", "embed_dim", ",", "self", ".", "output_embed_dim", ",", "bias", "=", "False", ")", "\n", "if", "embed_dim", "!=", "self", ".", "output_embed_dim", "and", "not", "args", ".", "tie_adaptive_weights", "\n", "else", "None", "\n", ")", "\n", "self", ".", "adaptive_softmax", "=", "None", "\n", "if", "args", ".", "adaptive_softmax_cutoff", "is", "not", "None", ":", "\n", "            ", "assert", "not", "isinstance", "(", "embed_tokens", ",", "nn", ".", "ModuleList", ")", "\n", "self", ".", "adaptive_softmax", "=", "AdaptiveSoftmax", "(", "\n", "len", "(", "dictionary", ")", ",", "\n", "self", ".", "output_embed_dim", ",", "\n", "options", ".", "eval_str_list", "(", "args", ".", "adaptive_softmax_cutoff", ",", "type", "=", "int", ")", ",", "\n", "dropout", "=", "args", ".", "adaptive_softmax_dropout", ",", "\n", "adaptive_inputs", "=", "embed_tokens", "if", "args", ".", "tie_adaptive_weights", "else", "None", ",", "\n", "factor", "=", "args", ".", "adaptive_softmax_factor", ",", "\n", "tie_proj", "=", "args", ".", "tie_adaptive_proj", ",", "\n", ")", "\n", "", "elif", "not", "self", ".", "share_input_output_embed", ":", "\n", "            ", "self", ".", "embed_tokens", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "len", "(", "dictionary", ")", ",", "self", ".", "output_embed_dim", ")", "\n", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "\n", "self", ".", "embed_tokens", ",", "mean", "=", "0", ",", "std", "=", "self", ".", "output_embed_dim", "**", "-", "0.5", "\n", ")", "\n", "\n", "", "if", "args", ".", "decoder_normalize_before", "and", "not", "getattr", "(", "\n", "args", ",", "\"no_decoder_final_norm\"", ",", "False", "\n", ")", ":", "\n", "            ", "self", ".", "layer_norm", "=", "LayerNorm", "(", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer_norm", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderOutputLayer.forward": [[255, 272], ["isinstance", "layers.TransformerDecoderOutputLayer.transpose", "layers.TransformerDecoderOutputLayer.layer_norm", "layers.TransformerDecoderOutputLayer.project_out_dim", "layers.TransformerDecoderOutputLayer.output_layer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.output_layer"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "apply_final_proj", "=", "True", ")", ":", "\n", "        ", "if", "isinstance", "(", "input", ",", "tuple", ")", ":", "\n", "            ", "x", "=", "input", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "x", "=", "input", "\n", "\n", "", "if", "self", ".", "layer_norm", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "if", "self", ".", "project_out_dim", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "project_out_dim", "(", "x", ")", "\n", "", "if", "apply_final_proj", ":", "\n", "            ", "x", "=", "self", ".", "output_layer", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderOutputLayer.output_layer": [[273, 295], ["isinstance", "torch.linear", "torch.linear", "torch.linear", "enumerate", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["", "def", "output_layer", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Project features to the vocabulary size.\"\"\"", "\n", "if", "self", ".", "adaptive_softmax", "is", "None", ":", "\n", "# project back to size of vocabulary", "\n", "            ", "if", "self", ".", "share_input_output_embed", ":", "\n", "                ", "if", "isinstance", "(", "self", ".", "embed_tokens", ",", "nn", ".", "ModuleList", ")", ":", "\n", "                    ", "output", "=", "None", "\n", "for", "i", ",", "emb", "in", "enumerate", "(", "self", ".", "embed_tokens", ")", ":", "\n", "                        ", "sidx", "=", "i", "*", "emb", ".", "embedding_dim", "\n", "eidx", "=", "(", "i", "+", "1", ")", "*", "emb", ".", "embedding_dim", "\n", "if", "output", "is", "None", ":", "\n", "                            ", "output", "=", "F", ".", "linear", "(", "features", "[", ":", ",", ":", ",", "sidx", ":", "eidx", "]", ",", "emb", ".", "weight", ")", "\n", "", "else", ":", "\n", "                            ", "output", "+=", "F", ".", "linear", "(", "features", "[", ":", ",", ":", ",", "sidx", ":", "eidx", "]", ",", "emb", ".", "weight", ")", "\n", "\n", "", "", "return", "output", "\n", "", "else", ":", "\n", "                    ", "return", "F", ".", "linear", "(", "features", ",", "self", ".", "embed_tokens", ".", "weight", ")", "\n", "", "", "else", ":", "\n", "                ", "return", "F", ".", "linear", "(", "features", ",", "self", ".", "embed_tokens", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerEncoderLayer.__init__": [[311, 333], ["torch.Module.__init__", "fairseq.modules.MultiheadAttention", "fairseq.modules.LayerNorm", "fairseq.utils.get_activation_fn", "getattr", "layers.Linear", "layers.Linear", "fairseq.modules.LayerNorm", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "args", ".", "encoder_embed_dim", "\n", "self", ".", "self_attn", "=", "MultiheadAttention", "(", "\n", "self", ".", "embed_dim", ",", "\n", "args", ".", "encoder_attention_heads", ",", "\n", "dropout", "=", "args", ".", "attention_dropout", ",", "\n", "self_attention", "=", "True", ",", "\n", ")", "\n", "self", ".", "self_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "dropout", "=", "args", ".", "dropout", "\n", "self", ".", "activation_fn", "=", "utils", ".", "get_activation_fn", "(", "\n", "activation", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"relu\"", ")", "\n", ")", "\n", "self", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "0", ")", "\n", "if", "self", ".", "activation_dropout", "==", "0", ":", "\n", "# for backwards compatibility with models that use args.relu_dropout", "\n", "            ", "self", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"relu_dropout\"", ",", "0", ")", "\n", "", "self", ".", "normalize_before", "=", "args", ".", "encoder_normalize_before", "\n", "self", ".", "fc1", "=", "Linear", "(", "self", ".", "embed_dim", ",", "args", ".", "encoder_ffn_embed_dim", ")", "\n", "self", ".", "fc2", "=", "Linear", "(", "args", ".", "encoder_ffn_embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "final_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerEncoderLayer.upgrade_state_dict_named": [[334, 347], ["layer_norm_map.items"], "methods", ["None"], ["", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "\"\"\"\n        Rename layer norm states from `...layer_norms.0.weight` to\n        `...self_attn_layer_norm.weight` and `...layer_norms.1.weight` to\n        `...final_layer_norm.weight`\n        \"\"\"", "\n", "layer_norm_map", "=", "{", "\"0\"", ":", "\"self_attn_layer_norm\"", ",", "\"1\"", ":", "\"final_layer_norm\"", "}", "\n", "for", "old", ",", "new", "in", "layer_norm_map", ".", "items", "(", ")", ":", "\n", "            ", "for", "m", "in", "(", "\"weight\"", ",", "\"bias\"", ")", ":", "\n", "                ", "k", "=", "\"{}.layer_norms.{}.{}\"", ".", "format", "(", "name", ",", "old", ",", "m", ")", "\n", "if", "k", "in", "state_dict", ":", "\n", "                    ", "state_dict", "[", "\"{}.{}.{}\"", ".", "format", "(", "name", ",", "new", ",", "m", ")", "]", "=", "state_dict", "[", "k", "]", "\n", "del", "state_dict", "[", "k", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerEncoderLayer.forward": [[348, 385], ["layers.TransformerEncoderLayer.maybe_layer_norm", "layers.TransformerEncoderLayer.self_attn", "torch.dropout", "torch.dropout", "torch.dropout", "layers.TransformerEncoderLayer.maybe_layer_norm", "layers.TransformerEncoderLayer.maybe_layer_norm", "layers.TransformerEncoderLayer.activation_fn", "torch.dropout", "torch.dropout", "torch.dropout", "layers.TransformerEncoderLayer.fc2", "torch.dropout", "torch.dropout", "torch.dropout", "layers.TransformerEncoderLayer.maybe_layer_norm", "layers.TransformerEncoderLayer.fc1"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm"], ["", "", "", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input (Tuple):\n                input[0] (Tensor): input to the layer of shape `(seq_len, batch, embed_dim)`\n                input[1] (ByteTensor/FloatTensor): encoder padding mask -\n                    binary ByteTensor of shape `(batch, src_len)` where padding elements\n                    are indicated by ``1``.\n                input[2] (LongTensor): previous decoder outputs of shape\n                    `(batch, tgt_len)`, for teacher forcing)\n        Returns:\n            output (Tuple):\n                output[0] (Tensor): encoded output of shape `(batch, src_len, embed_dim)`\n                output[1] (ByteTensor/FloatTensor): encoder padding mask\n                output[2] (LongTensor): previous decoder outputs\n        \"\"\"", "\n", "x", "=", "input", "[", "0", "]", "\n", "encoder_padding_mask", "=", "input", "[", "1", "]", "\n", "prev_output_tokens", "=", "input", "[", "2", "]", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "self_attn_layer_norm", ",", "x", ",", "before", "=", "True", ")", "\n", "x", ",", "_", "=", "self", ".", "self_attn", "(", "\n", "query", "=", "x", ",", "key", "=", "x", ",", "value", "=", "x", ",", "key_padding_mask", "=", "encoder_padding_mask", "\n", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "self_attn_layer_norm", ",", "x", ",", "after", "=", "True", ")", "\n", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "x", ",", "before", "=", "True", ")", "\n", "x", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "activation_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "x", ",", "after", "=", "True", ")", "\n", "return", "(", "x", ",", "encoder_padding_mask", ",", "prev_output_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerEncoderLayer.maybe_layer_norm": [[386, 392], ["layer_norm"], "methods", ["None"], ["", "def", "maybe_layer_norm", "(", "self", ",", "layer_norm", ",", "x", ",", "before", "=", "False", ",", "after", "=", "False", ")", ":", "\n", "        ", "assert", "before", "^", "after", "\n", "if", "after", "^", "self", ".", "normalize_before", ":", "\n", "            ", "return", "layer_norm", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.__init__": [[411, 461], ["torch.Module.__init__", "fairseq.modules.MultiheadAttention", "fairseq.utils.get_activation_fn", "getattr", "getattr", "fairseq.modules.LayerNorm", "layers.Linear", "layers.Linear", "fairseq.modules.LayerNorm", "getattr", "fairseq.modules.MultiheadAttention", "fairseq.modules.LayerNorm", "getattr", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_activation_fn", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm"], ["def", "__init__", "(", "\n", "self", ",", "args", ",", "no_encoder_attn", "=", "False", ",", "add_bias_kv", "=", "False", ",", "add_zero_attn", "=", "False", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "args", ".", "decoder_embed_dim", "\n", "self", ".", "self_attn", "=", "MultiheadAttention", "(", "\n", "embed_dim", "=", "self", ".", "embed_dim", ",", "\n", "num_heads", "=", "args", ".", "decoder_attention_heads", ",", "\n", "dropout", "=", "args", ".", "attention_dropout", ",", "\n", "add_bias_kv", "=", "add_bias_kv", ",", "\n", "add_zero_attn", "=", "add_zero_attn", ",", "\n", "self_attention", "=", "True", ",", "\n", ")", "\n", "self", ".", "dropout", "=", "args", ".", "dropout", "\n", "self", ".", "activation_fn", "=", "utils", ".", "get_activation_fn", "(", "\n", "activation", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"relu\"", ")", "\n", ")", "\n", "self", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"activation_dropout\"", ",", "0", ")", "\n", "if", "self", ".", "activation_dropout", "==", "0", ":", "\n", "# for backwards compatibility with models that use args.relu_dropout", "\n", "            ", "self", ".", "activation_dropout", "=", "getattr", "(", "args", ",", "\"relu_dropout\"", ",", "0", ")", "\n", "", "self", ".", "normalize_before", "=", "args", ".", "decoder_normalize_before", "\n", "\n", "# use layerNorm rather than FusedLayerNorm for exporting.", "\n", "# char_inputs can be used to determint this.", "\n", "# TODO  remove this once we update apex with the fix", "\n", "export", "=", "getattr", "(", "args", ",", "\"char_inputs\"", ",", "False", ")", "\n", "self", ".", "self_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ",", "export", "=", "export", ")", "\n", "\n", "if", "no_encoder_attn", ":", "\n", "            ", "self", ".", "encoder_attn", "=", "None", "\n", "self", ".", "encoder_attn_layer_norm", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "encoder_attn", "=", "MultiheadAttention", "(", "\n", "self", ".", "embed_dim", ",", "\n", "args", ".", "decoder_attention_heads", ",", "\n", "kdim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "None", ")", ",", "\n", "vdim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "None", ")", ",", "\n", "dropout", "=", "args", ".", "attention_dropout", ",", "\n", "encoder_decoder_attention", "=", "True", ",", "\n", ")", "\n", "self", ".", "encoder_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ",", "export", "=", "export", ")", "\n", "\n", "", "self", ".", "fc1", "=", "Linear", "(", "self", ".", "embed_dim", ",", "args", ".", "decoder_ffn_embed_dim", ")", "\n", "self", ".", "fc2", "=", "Linear", "(", "args", ".", "decoder_ffn_embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "final_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ",", "export", "=", "export", ")", "\n", "self", ".", "need_attn", "=", "True", "\n", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.prepare_for_onnx_export_": [[462, 464], ["None"], "methods", ["None"], ["", "def", "prepare_for_onnx_export_", "(", "self", ")", ":", "\n", "        ", "self", ".", "onnx_trace", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.forward": [[465, 560], ["isinstance", "layers.TransformerDecoderLayer.maybe_layer_norm", "layers.TransformerDecoderLayer.self_attn", "torch.dropout", "torch.dropout", "torch.dropout", "layers.TransformerDecoderLayer.maybe_layer_norm", "layers.TransformerDecoderLayer.maybe_layer_norm", "layers.TransformerDecoderLayer.activation_fn", "torch.dropout", "torch.dropout", "torch.dropout", "layers.TransformerDecoderLayer.fc2", "torch.dropout", "torch.dropout", "torch.dropout", "layers.TransformerDecoderLayer.maybe_layer_norm", "layers.TransformerDecoderLayer.buffered_future_mask", "layers.TransformerDecoderLayer.self_attn._set_input_buffer", "layers.TransformerDecoderLayer.maybe_layer_norm", "layers.TransformerDecoderLayer.encoder_attn", "torch.dropout", "torch.dropout", "torch.dropout", "layers.TransformerDecoderLayer.maybe_layer_norm", "layers.TransformerDecoderLayer.fc1", "layers.TransformerDecoderLayer.encoder_attn._set_input_buffer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.buffered_future_mask", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.reneeye_const.dynamicconv_layer.dynamicconv_layer.DynamicconvLayer._set_input_buffer"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input (Tuple):\n                input[0] (Tensor): input to the layer of shape `(seq_len, batch, embed_dim)`\n                input[1] (Tensor): encoder output of shape `(batch, src_len, embed_dim)`\n                input[2] (ByteTensor/FloatTensor): encoder padding mask -\n                    binary ByteTensor of shape `(batch, src_len)` where padding elements\n                    are indicated by ``1``.\n        Returns:\n            output (Tuple):\n                output[0] (Tensor): encoded output of shape `(batch, src_len, embed_dim)`\n                output[1] (ByteTensor/FloatTensor): encoder padding mask\n                output[2] (LongTensor): previous decoder outputs\n        \"\"\"", "\n", "# Note: incremental state is not yet supported", "\n", "mt_task", "=", "False", "\n", "if", "isinstance", "(", "input", ",", "tuple", ")", ":", "\n", "            ", "x", "=", "input", "[", "0", "]", "\n", "encoder_out", "=", "input", "[", "1", "]", "\n", "encoder_padding_mask", "=", "input", "[", "2", "]", "\n", "incremental_state", "=", "None", "\n", "mt_task", "=", "True", "\n", "", "else", ":", "\n", "            ", "x", "=", "input", "\n", "encoder_out", "=", "None", "\n", "encoder_padding_mask", "=", "None", "\n", "incremental_state", "=", "None", "\n", "\n", "", "if", "incremental_state", "is", "None", ":", "\n", "            ", "self_attn_mask", "=", "self", ".", "buffered_future_mask", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "self_attn_mask", "=", "None", "\n", "\n", "# TODO: add back prev_self_attn_state, prev_attn_state,", "\n", "# self_attn_padding_mask", "\n", "", "prev_self_attn_state", "=", "None", "\n", "prev_attn_state", "=", "None", "\n", "self_attn_padding_mask", "=", "None", "\n", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "self_attn_layer_norm", ",", "x", ",", "before", "=", "True", ")", "\n", "if", "prev_self_attn_state", "is", "not", "None", ":", "\n", "            ", "if", "incremental_state", "is", "None", ":", "\n", "                ", "incremental_state", "=", "{", "}", "\n", "", "prev_key", ",", "prev_value", "=", "prev_self_attn_state", "\n", "saved_state", "=", "{", "\"prev_key\"", ":", "prev_key", ",", "\"prev_value\"", ":", "prev_value", "}", "\n", "self", ".", "self_attn", ".", "_set_input_buffer", "(", "incremental_state", ",", "saved_state", ")", "\n", "", "x", ",", "attn", "=", "self", ".", "self_attn", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "x", ",", "\n", "value", "=", "x", ",", "\n", "key_padding_mask", "=", "self_attn_padding_mask", ",", "\n", "incremental_state", "=", "incremental_state", ",", "\n", "need_weights", "=", "False", ",", "\n", "attn_mask", "=", "self_attn_mask", ",", "\n", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "self_attn_layer_norm", ",", "x", ",", "after", "=", "True", ")", "\n", "\n", "if", "self", ".", "encoder_attn", "is", "not", "None", ":", "\n", "            ", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "encoder_attn_layer_norm", ",", "x", ",", "before", "=", "True", ")", "\n", "if", "prev_attn_state", "is", "not", "None", ":", "\n", "                ", "if", "incremental_state", "is", "None", ":", "\n", "                    ", "incremental_state", "=", "{", "}", "\n", "", "prev_key", ",", "prev_value", "=", "prev_attn_state", "\n", "saved_state", "=", "{", "\"prev_key\"", ":", "prev_key", ",", "\"prev_value\"", ":", "prev_value", "}", "\n", "self", ".", "encoder_attn", ".", "_set_input_buffer", "(", "incremental_state", ",", "saved_state", ")", "\n", "", "x", ",", "attn", "=", "self", ".", "encoder_attn", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "encoder_out", ",", "\n", "value", "=", "encoder_out", ",", "\n", "key_padding_mask", "=", "encoder_padding_mask", ",", "\n", "incremental_state", "=", "incremental_state", ",", "\n", "static_kv", "=", "True", ",", "\n", "need_weights", "=", "(", "not", "self", ".", "training", "and", "self", ".", "need_attn", ")", ",", "\n", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "encoder_attn_layer_norm", ",", "x", ",", "after", "=", "True", ")", "\n", "\n", "", "residual", "=", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "x", ",", "before", "=", "True", ")", "\n", "x", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "activation_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "x", ",", "after", "=", "True", ")", "\n", "\n", "if", "mt_task", ":", "\n", "            ", "return", "(", "x", ",", "encoder_out", ",", "encoder_padding_mask", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.buffered_future_mask": [[561, 576], ["tensor.size", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "layers.TransformerDecoderLayer._future_mask.size", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "hasattr", "fairseq.utils.fill_with_neg_inf", "fairseq.utils.fill_with_neg_inf", "tensor.new", "layers.TransformerDecoderLayer._future_mask.resize_"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.fill_with_neg_inf", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.fill_with_neg_inf"], ["", "def", "buffered_future_mask", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "dim", "=", "tensor", ".", "size", "(", "0", ")", "\n", "if", "(", "\n", "not", "hasattr", "(", "self", ",", "\"_future_mask\"", ")", "\n", "or", "self", ".", "_future_mask", "is", "None", "\n", "or", "self", ".", "_future_mask", ".", "device", "!=", "tensor", ".", "device", "\n", ")", ":", "\n", "            ", "self", ".", "_future_mask", "=", "torch", ".", "triu", "(", "\n", "utils", ".", "fill_with_neg_inf", "(", "tensor", ".", "new", "(", "dim", ",", "dim", ")", ")", ",", "1", "\n", ")", "\n", "", "if", "self", ".", "_future_mask", ".", "size", "(", "0", ")", "<", "dim", ":", "\n", "            ", "self", ".", "_future_mask", "=", "torch", ".", "triu", "(", "\n", "utils", ".", "fill_with_neg_inf", "(", "self", ".", "_future_mask", ".", "resize_", "(", "dim", ",", "dim", ")", ")", ",", "1", "\n", ")", "\n", "", "return", "self", ".", "_future_mask", "[", ":", "dim", ",", ":", "dim", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.maybe_layer_norm": [[577, 583], ["layer_norm"], "methods", ["None"], ["", "def", "maybe_layer_norm", "(", "self", ",", "layer_norm", ",", "x", ",", "before", "=", "False", ",", "after", "=", "False", ")", ":", "\n", "        ", "assert", "before", "^", "after", "\n", "if", "after", "^", "self", ".", "normalize_before", ":", "\n", "            ", "return", "layer_norm", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.TransformerDecoderLayer.make_generation_fast_": [[584, 586], ["None"], "methods", ["None"], ["", "", "def", "make_generation_fast_", "(", "self", ",", "need_attn", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "need_attn", "=", "need_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding": [[588, 593], ["torch.Embedding", "torch.init.normal_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding"], ["", "", "def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "embedding_dim", "**", "-", "0.5", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear": [[595, 601], ["torch.Linear", "torch.init.xavier_uniform_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["", "def", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "if", "bias", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.0", ")", "\n", "", "return", "m", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.__init__": [[46, 85], ["fairseq.models.BaseFairseqModel.__init__", "isinstance", "isinstance", "len", "len", "Pipe", "model.PipelineParallelTransformerModel.max_positions_helper", "model.PipelineParallelTransformerModel.max_positions_helper", "getattr", "torch.Sequential", "torch.Sequential", "torch.Sequential", "ImportError", "list", "list"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.max_positions_helper", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.max_positions_helper"], ["self", ".", "classification_heads", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "if", "hasattr", "(", "self", ".", "encoder", ",", "\"dictionary\"", ")", ":", "\n", "            ", "self", ".", "eos", ":", "int", "=", "self", ".", "encoder", ".", "dictionary", ".", "eos", "(", ")", "\n", "\n", "", "", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "super", "(", "BARTModel", ",", "BARTModel", ")", ".", "add_args", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pooler-dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"dropout probability in the masked_lm pooler layers\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pooler-activation-fn\"", ",", "\n", "choices", "=", "utils", ".", "get_available_activation_fns", "(", ")", ",", "\n", "help", "=", "\"activation function to use for pooler layer\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--spectral-norm-classification-head\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Apply spectral normalization on the classification head\"", ",", "\n", ")", "\n", "\n", "", "@", "property", "\n", "def", "supported_targets", "(", "self", ")", ":", "\n", "        ", "return", "{", "\"self\"", "}", "\n", "\n", "", "def", "forward", "(", "\n", "self", ",", "\n", "src_tokens", ",", "\n", "src_lengths", ",", "\n", "prev_output_tokens", ",", "\n", "features_only", ":", "bool", "=", "False", ",", "\n", "classification_head_name", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "token_embeddings", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "return_all_hiddens", ":", "bool", "=", "True", ",", "\n", "alignment_layer", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "alignment_heads", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.forward": [[86, 98], ["tuple", "model.PipelineParallelTransformerModel.model", "model.PipelineParallelTransformerModel.encoder", "model.PipelineParallelTransformerModel.decoder", "i.to"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.encoder", "home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder"], ["        ", "if", "classification_head_name", "is", "not", "None", ":", "\n", "            ", "features_only", "=", "True", "\n", "\n", "", "encoder_out", "=", "self", ".", "encoder", "(", "\n", "src_tokens", ",", "\n", "src_lengths", "=", "src_lengths", ",", "\n", "token_embeddings", "=", "token_embeddings", ",", "\n", "return_all_hiddens", "=", "return_all_hiddens", "\n", ")", "\n", "x", ",", "extra", "=", "self", ".", "decoder", "(", "\n", "prev_output_tokens", ",", "\n", "encoder_out", "=", "encoder_out", ",", "\n", "features_only", "=", "features_only", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.prepare_for_inference_": [[99, 117], ["model.TransformerEncoder", "model.TransformerDecoder", "logger.info", "encoder_module_list.append", "decoder_module_list.append"], "methods", ["None"], ["alignment_layer", "=", "alignment_layer", ",", "\n", "alignment_heads", "=", "alignment_heads", ",", "\n", "src_lengths", "=", "src_lengths", ",", "\n", "return_all_hiddens", "=", "return_all_hiddens", ",", "\n", ")", "\n", "eos", ":", "int", "=", "self", ".", "eos", "\n", "if", "classification_head_name", "is", "not", "None", ":", "\n", "            ", "sentence_representation", "=", "x", "[", "\n", "src_tokens", ".", "eq", "(", "eos", ")", ",", ":", "\n", "]", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "for", "k", ",", "head", "in", "self", ".", "classification_heads", ".", "items", "(", ")", ":", "\n", "# for torch script only supports iteration", "\n", "                ", "if", "k", "==", "classification_head_name", ":", "\n", "                    ", "x", "=", "head", "(", "sentence_representation", ")", "\n", "break", "\n", "", "", "", "return", "x", ",", "extra", "\n", "\n", "", "@", "classmethod", "\n", "def", "from_pretrained", "(", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.add_args": [[119, 174], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "fairseq.utils.get_available_activation_fns"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_available_activation_fns"], ["model_name_or_path", ",", "\n", "checkpoint_file", "=", "\"model.pt\"", ",", "\n", "data_name_or_path", "=", "\".\"", ",", "\n", "bpe", "=", "\"gpt2\"", ",", "\n", "sample_break_mode", "=", "\"eos\"", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "from", "fairseq", "import", "hub_utils", "\n", "\n", "x", "=", "hub_utils", ".", "from_pretrained", "(", "\n", "model_name_or_path", ",", "\n", "checkpoint_file", ",", "\n", "data_name_or_path", ",", "\n", "archive_map", "=", "cls", ".", "hub_models", "(", ")", ",", "\n", "bpe", "=", "bpe", ",", "\n", "load_checkpoint_heads", "=", "True", ",", "\n", "sample_break_mode", "=", "sample_break_mode", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "return", "BARTHubInterface", "(", "x", "[", "\"args\"", "]", ",", "x", "[", "\"task\"", "]", ",", "x", "[", "\"models\"", "]", "[", "0", "]", ")", "\n", "\n", "", "def", "register_classification_head", "(", "\n", "self", ",", "name", ",", "num_classes", "=", "None", ",", "inner_dim", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Register a classification head.\"\"\"", "\n", "logger", ".", "info", "(", "\"Registering classification head: {0}\"", ".", "format", "(", "name", ")", ")", "\n", "if", "name", "in", "self", ".", "classification_heads", ":", "\n", "            ", "prev_num_classes", "=", "self", ".", "classification_heads", "[", "name", "]", ".", "out_proj", ".", "out_features", "\n", "prev_inner_dim", "=", "self", ".", "classification_heads", "[", "name", "]", ".", "dense", ".", "out_features", "\n", "if", "num_classes", "!=", "prev_num_classes", "or", "inner_dim", "!=", "prev_inner_dim", ":", "\n", "                ", "logger", ".", "warning", "(", "\n", "'re-registering head \"{}\" with num_classes {} (prev: {}) '", "\n", "\"and inner_dim {} (prev: {})\"", ".", "format", "(", "\n", "name", ",", "num_classes", ",", "prev_num_classes", ",", "inner_dim", ",", "prev_inner_dim", "\n", ")", "\n", ")", "\n", "", "", "self", ".", "classification_heads", "[", "name", "]", "=", "BARTClassificationHead", "(", "\n", "input_dim", "=", "self", ".", "args", ".", "encoder_embed_dim", ",", "\n", "inner_dim", "=", "inner_dim", "or", "self", ".", "args", ".", "encoder_embed_dim", ",", "\n", "num_classes", "=", "num_classes", ",", "\n", "activation_fn", "=", "self", ".", "args", ".", "pooler_activation_fn", ",", "\n", "pooler_dropout", "=", "self", ".", "args", ".", "pooler_dropout", ",", "\n", "do_spectral_norm", "=", "getattr", "(", "\n", "self", ".", "args", ",", "\"spectral_norm_classification_head\"", ",", "False", "\n", ")", ",", "\n", ")", "\n", "\n", "", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "super", "(", ")", ".", "upgrade_state_dict_named", "(", "state_dict", ",", "name", ")", "\n", "\n", "prefix", "=", "name", "+", "\".\"", "if", "name", "!=", "\"\"", "else", "\"\"", "\n", "current_head_names", "=", "(", "\n", "[", "]", "\n", "if", "not", "hasattr", "(", "self", ",", "\"classification_heads\"", ")", "\n", "else", "self", ".", "classification_heads", ".", "keys", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.build_model_base": [[179, 259], ["fairseq.models.transformer.base_architecture", "cls.build_encoder", "cls.build_decoder", "hasattr", "hasattr", "len", "dictionary.pad", "model.PipelineParallelTransformerModel.build_model_base.build_embedding"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.build_encoder", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.build_decoder", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNet.build_embedding"], ["            ", "if", "not", "k", ".", "startswith", "(", "prefix", "+", "\"classification_heads.\"", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "head_name", "=", "k", "[", "len", "(", "prefix", "+", "\"classification_heads.\"", ")", ":", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", "\n", "num_classes", "=", "state_dict", "[", "\n", "prefix", "+", "\"classification_heads.\"", "+", "head_name", "+", "\".out_proj.weight\"", "\n", "]", ".", "size", "(", "0", ")", "\n", "inner_dim", "=", "state_dict", "[", "\n", "prefix", "+", "\"classification_heads.\"", "+", "head_name", "+", "\".dense.weight\"", "\n", "]", ".", "size", "(", "0", ")", "\n", "\n", "if", "getattr", "(", "self", ".", "args", ",", "\"load_checkpoint_heads\"", ",", "False", ")", ":", "\n", "                ", "if", "head_name", "not", "in", "current_head_names", ":", "\n", "                    ", "self", ".", "register_classification_head", "(", "head_name", ",", "num_classes", ",", "inner_dim", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "head_name", "not", "in", "current_head_names", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "\"deleting classification head ({}) from checkpoint \"", "\n", "\"not present in current model: {}\"", ".", "format", "(", "head_name", ",", "k", ")", "\n", ")", "\n", "keys_to_delete", ".", "append", "(", "k", ")", "\n", "", "elif", "(", "\n", "num_classes", "\n", "!=", "self", ".", "classification_heads", "[", "head_name", "]", ".", "out_proj", ".", "out_features", "\n", "or", "inner_dim", "\n", "!=", "self", ".", "classification_heads", "[", "head_name", "]", ".", "dense", ".", "out_features", "\n", ")", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "\"deleting classification head ({}) from checkpoint \"", "\n", "\"with different dimensions than current model: {}\"", ".", "format", "(", "\n", "head_name", ",", "k", "\n", ")", "\n", ")", "\n", "keys_to_delete", ".", "append", "(", "k", ")", "\n", "", "", "", "for", "k", "in", "keys_to_delete", ":", "\n", "            ", "del", "state_dict", "[", "k", "]", "\n", "\n", "", "def", "truncate_emb", "(", "key", ")", ":", "\n", "            ", "if", "key", "in", "state_dict", ":", "\n", "                ", "state_dict", "[", "key", "]", "=", "state_dict", "[", "key", "]", "[", ":", "-", "1", ",", ":", "]", "\n", "\n", "# When finetuning on translation task, remove last row of", "\n", "# embedding matrix that corresponds to mask_idx token.", "\n", "", "", "loaded_dict_size", "=", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", ".", "size", "(", "0", ")", "\n", "if", "(", "\n", "loaded_dict_size", "==", "len", "(", "self", ".", "encoder", ".", "dictionary", ")", "+", "1", "\n", "and", "\"<mask>\"", "not", "in", "self", ".", "encoder", ".", "dictionary", "\n", ")", ":", "\n", "            ", "truncate_emb", "(", "\"encoder.embed_tokens.weight\"", ")", "\n", "truncate_emb", "(", "\"decoder.embed_tokens.weight\"", ")", "\n", "truncate_emb", "(", "\"encoder.output_projection.weight\"", ")", "\n", "truncate_emb", "(", "\"decoder.output_projection.weight\"", ")", "\n", "\n", "# When continued pretraining on new set of languages for mbart,", "\n", "# add extra lang embeddings at the end of embed_tokens.", "\n", "# Note: newly added languages are assumed to have been added at the end.", "\n", "", "if", "self", ".", "args", ".", "task", "==", "\"multilingual_denoising\"", "and", "loaded_dict_size", "<", "len", "(", "\n", "self", ".", "encoder", ".", "dictionary", "\n", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Adding extra language embeddings not found in pretrained model for \"", "\n", "\"continued pretraining of MBART on new set of languages.\"", "\n", ")", "\n", "loaded_mask_token_embedding", "=", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", "[", "\n", "-", "1", ",", ":", "\n", "]", "\n", "\n", "num_langids_to_add", "=", "len", "(", "self", ".", "encoder", ".", "dictionary", ")", "-", "loaded_dict_size", "\n", "embed_dim", "=", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", ".", "size", "(", "1", ")", "\n", "\n", "new_lang_embed_to_add", "=", "torch", ".", "zeros", "(", "num_langids_to_add", ",", "embed_dim", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "new_lang_embed_to_add", ",", "mean", "=", "0", ",", "std", "=", "embed_dim", "**", "-", "0.5", ")", "\n", "new_lang_embed_to_add", "=", "new_lang_embed_to_add", ".", "to", "(", "\n", "dtype", "=", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", ".", "dtype", ",", "\n", ")", "\n", "\n", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "state_dict", "[", "\"encoder.embed_tokens.weight\"", "]", "[", "\n", ":", "loaded_dict_size", "-", "1", ",", ":", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.build_encoder": [[260, 263], ["model.TransformerEncoder"], "methods", ["None"], ["new_lang_embed_to_add", ",", "\n", "loaded_mask_token_embedding", ".", "unsqueeze", "(", "0", ")", ",", "\n", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.build_decoder": [[264, 267], ["model.TransformerDecoder"], "methods", ["None"], ["state_dict", "[", "\"decoder.embed_tokens.weight\"", "]", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "state_dict", "[", "\"decoder.embed_tokens.weight\"", "]", "[", "\n", ":", "loaded_dict_size", "-", "1", ",", ":", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.build_model": [[268, 278], ["cls.build_model_base", "model.PipelineParallelTransformerModel", "fairseq.utils.eval_str_list", "fairseq.utils.eval_str_list"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.build_model_base", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.eval_str_list", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.eval_str_list"], ["]", ",", "\n", "new_lang_embed_to_add", ",", "\n", "loaded_mask_token_embedding", ".", "unsqueeze", "(", "0", ")", ",", "\n", "]", "\n", ")", "\n", "\n", "# Copy any newly-added classification heads into the state dict", "\n", "# with their current weights.", "\n", "", "if", "hasattr", "(", "self", ",", "\"classification_heads\"", ")", ":", "\n", "            ", "cur_state", "=", "self", ".", "classification_heads", ".", "state_dict", "(", ")", "\n", "for", "k", ",", "v", "in", "cur_state", ".", "items", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.output_layer": [[280, 283], ["model.PipelineParallelTransformerModel.decoder.output_layer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.output_layer"], ["                    ", "logger", ".", "info", "(", "\"Overwriting\"", ",", "prefix", "+", "\"classification_heads.\"", "+", "k", ")", "\n", "state_dict", "[", "prefix", "+", "\"classification_heads.\"", "+", "k", "]", "=", "v", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.max_positions": [[284, 287], ["None"], "methods", ["None"], ["", "", "", "", "", "class", "BARTClassificationHead", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Head for sentence-level classification tasks.\"\"\"", "\n", "\n", "def", "__init__", "(", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.max_positions_helper": [[288, 297], ["min", "getattr", "getattr"], "methods", ["None"], ["self", ",", "\n", "input_dim", ",", "\n", "inner_dim", ",", "\n", "num_classes", ",", "\n", "activation_fn", ",", "\n", "pooler_dropout", ",", "\n", "do_spectral_norm", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "input_dim", ",", "inner_dim", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.get_normalized_probs": [[299, 318], ["hasattr", "model.PipelineParallelTransformerModel.adaptive_softmax.get_log_prob", "isinstance", "fairseq.utils.log_softmax", "fairseq.utils.softmax", "model.PipelineParallelTransformerModel.exp_"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.modules.adaptive_softmax.AdaptiveSoftmax.get_log_prob", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax"], ["self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "pooler_dropout", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "inner_dim", ",", "num_classes", ")", "\n", "\n", "if", "do_spectral_norm", ":", "\n", "            ", "self", ".", "out_proj", "=", "torch", ".", "nn", ".", "utils", ".", "spectral_norm", "(", "self", ".", "out_proj", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "features", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "self", ".", "activation_fn", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "return", "x", "\n", "\n", "\n", "", "", "@", "register_model_architecture", "(", "\"bart\"", ",", "\"bart_large\"", ")", "\n", "def", "bart_large_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_path", "=", "getattr", "(", "args", ",", "\"encoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "1024", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.max_decoder_positions": [[319, 322], ["None"], "methods", ["None"], ["args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "4", "*", "1024", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "12", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "16", ")", "\n", "args", ".", "encoder_normalize_before", "=", "getattr", "(", "args", ",", "\"encoder_normalize_before\"", ",", "False", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.load_state_dict": [[323, 335], ["model.PipelineParallelTransformerModel.upgrade_state_dict", "super().load_state_dict", "any", "model.PipelineParallelTransformerModel.convert_to_pipeline_parallel_state_dict"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_decoder.FairseqDecoder.upgrade_state_dict", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.convert_to_pipeline_parallel_state_dict"], ["args", ".", "encoder_learned_pos", "=", "getattr", "(", "args", ",", "\"encoder_learned_pos\"", ",", "True", ")", "\n", "args", ".", "decoder_embed_path", "=", "getattr", "(", "args", ",", "\"decoder_embed_path\"", ",", "None", ")", "\n", "args", ".", "decoder_embed_dim", "=", "getattr", "(", "args", ",", "\"decoder_embed_dim\"", ",", "args", ".", "encoder_embed_dim", ")", "\n", "args", ".", "decoder_ffn_embed_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_ffn_embed_dim\"", ",", "args", ".", "encoder_ffn_embed_dim", "\n", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "12", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "16", ")", "\n", "args", ".", "decoder_normalize_before", "=", "getattr", "(", "args", ",", "\"decoder_normalize_before\"", ",", "False", ")", "\n", "args", ".", "decoder_learned_pos", "=", "getattr", "(", "args", ",", "\"decoder_learned_pos\"", ",", "True", ")", "\n", "args", ".", "attention_dropout", "=", "getattr", "(", "args", ",", "\"attention_dropout\"", ",", "0.0", ")", "\n", "args", ".", "relu_dropout", "=", "getattr", "(", "args", ",", "\"relu_dropout\"", ",", "0.0", ")", "\n", "args", ".", "dropout", "=", "getattr", "(", "args", ",", "\"dropout\"", ",", "0.1", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.PipelineParallelTransformerModel.convert_to_pipeline_parallel_state_dict": [[336, 412], ["model.PipelineParallelTransformerModel.state_dict", "enumerate", "logger.info", "enumerate", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.state_dict"], ["args", ".", "max_target_positions", "=", "getattr", "(", "args", ",", "\"max_target_positions\"", ",", "1024", ")", "\n", "args", ".", "max_source_positions", "=", "getattr", "(", "args", ",", "\"max_source_positions\"", ",", "1024", ")", "\n", "args", ".", "adaptive_softmax_cutoff", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_cutoff\"", ",", "None", ")", "\n", "args", ".", "adaptive_softmax_dropout", "=", "getattr", "(", "args", ",", "\"adaptive_softmax_dropout\"", ",", "0", ")", "\n", "args", ".", "share_decoder_input_output_embed", "=", "getattr", "(", "\n", "args", ",", "\"share_decoder_input_output_embed\"", ",", "True", "\n", ")", "\n", "args", ".", "share_all_embeddings", "=", "getattr", "(", "args", ",", "\"share_all_embeddings\"", ",", "True", ")", "\n", "\n", "args", ".", "decoder_output_dim", "=", "getattr", "(", "\n", "args", ",", "\"decoder_output_dim\"", ",", "args", ".", "decoder_embed_dim", "\n", ")", "\n", "args", ".", "decoder_input_dim", "=", "getattr", "(", "args", ",", "\"decoder_input_dim\"", ",", "args", ".", "decoder_embed_dim", ")", "\n", "\n", "args", ".", "no_scale_embedding", "=", "getattr", "(", "args", ",", "\"no_scale_embedding\"", ",", "True", ")", "\n", "args", ".", "layernorm_embedding", "=", "getattr", "(", "args", ",", "\"layernorm_embedding\"", ",", "True", ")", "\n", "\n", "args", ".", "activation_fn", "=", "getattr", "(", "args", ",", "\"activation_fn\"", ",", "\"gelu\"", ")", "\n", "args", ".", "pooler_activation_fn", "=", "getattr", "(", "args", ",", "\"pooler_activation_fn\"", ",", "\"tanh\"", ")", "\n", "args", ".", "pooler_dropout", "=", "getattr", "(", "args", ",", "\"pooler_dropout\"", ",", "0.0", ")", "\n", "\n", "\n", "", "@", "register_model_architecture", "(", "\"bart\"", ",", "\"bart_base\"", ")", "\n", "def", "bart_base_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "encoder_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_embed_dim\"", ",", "768", ")", "\n", "args", ".", "encoder_ffn_embed_dim", "=", "getattr", "(", "args", ",", "\"encoder_ffn_embed_dim\"", ",", "4", "*", "768", ")", "\n", "args", ".", "encoder_layers", "=", "getattr", "(", "args", ",", "\"encoder_layers\"", ",", "6", ")", "\n", "args", ".", "encoder_attention_heads", "=", "getattr", "(", "args", ",", "\"encoder_attention_heads\"", ",", "12", ")", "\n", "args", ".", "decoder_layers", "=", "getattr", "(", "args", ",", "\"decoder_layers\"", ",", "6", ")", "\n", "args", ".", "decoder_attention_heads", "=", "getattr", "(", "args", ",", "\"decoder_attention_heads\"", ",", "12", ")", "\n", "bart_large_architecture", "(", "args", ")", "\n", "\n", "\n", "", "@", "register_model_architecture", "(", "\"bart\"", ",", "\"mbart_large\"", ")", "\n", "def", "mbart_large_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "no_scale_embedding", "=", "getattr", "(", "args", ",", "\"no_scale_embedding\"", ",", "False", ")", "\n", "bart_large_architecture", "(", "args", ")", "\n", "\n", "\n", "", "@", "register_model_architecture", "(", "\"bart\"", ",", "\"mbart_base\"", ")", "\n", "def", "mbart_base_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "no_scale_embedding", "=", "getattr", "(", "args", ",", "\"no_scale_embedding\"", ",", "False", ")", "\n", "bart_base_architecture", "(", "args", ")", "\n", "\n", "\n", "", "@", "register_model_architecture", "(", "\"bart\"", ",", "\"mbart_base_wmt20\"", ")", "\n", "def", "mbart_base_wmt20_architecture", "(", "args", ")", ":", "\n", "    ", "args", ".", "layernorm_embedding", "=", "getattr", "(", "args", ",", "\"layernorm_embedding\"", ",", "False", ")", "\n", "mbart_base_architecture", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerEncoder.__init__": [[425, 458], ["fairseq.models.FairseqEncoder.__init__", "model.TransformerEncoder.register_buffer", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "fairseq.model_parallel.models.pipeline_parallel_transformer.layers.TransformerEncoderEmbedding", "torch.Sequential", "torch.Sequential", "torch.Sequential", "isinstance", "fairseq.model_parallel.models.pipeline_parallel_transformer.layers.TransformerEncoderLayerNorm", "fairseq.utils.eval_str_list", "fairseq.utils.eval_str_list", "Pipe", "ImportError", "sum", "sum", "len", "torch.Sequential", "torch.Sequential", "torch.Sequential", "fairseq.model_parallel.models.pipeline_parallel_transformer.layers.TransformerEncoderLayer", "len", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.eval_str_list", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.eval_str_list"], []], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerEncoder.forward": [[460, 498], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "fairseq.models.fairseq_encoder.EncoderOut", "tuple", "model.TransformerEncoder.model", "model.TransformerEncoder.embedding_layer", "model.TransformerEncoder.encoder_layers", "model.TransformerEncoder.final_layer_norm", "i.to"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model"], []], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerEncoder.reorder_encoder_out": [[499, 530], ["encoder_out._replace._replace._replace", "encoder_out._replace._replace._replace", "encoder_out._replace._replace._replace", "enumerate", "state.index_select", "encoder_out._replace._replace.encoder_out.index_select", "encoder_out._replace._replace.encoder_padding_mask.index_select", "encoder_out._replace._replace.encoder_embedding.index_select"], "methods", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerEncoder.max_positions": [[531, 538], ["min"], "methods", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.__init__": [[554, 595], ["fairseq.models.FairseqDecoder.__init__", "model.TransformerDecoder.register_buffer", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "fairseq.model_parallel.models.pipeline_parallel_transformer.layers.TransformerDecoderEmbedding", "torch.Sequential", "torch.Sequential", "torch.Sequential", "fairseq.model_parallel.models.pipeline_parallel_transformer.layers.TransformerDecoderOutputLayer", "fairseq.utils.eval_str_list", "fairseq.utils.eval_str_list", "Pipe", "ImportError", "sum", "len", "torch.Sequential", "torch.Sequential", "torch.Sequential", "fairseq.model_parallel.models.pipeline_parallel_transformer.layers.TransformerDecoderLayer", "len", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.eval_str_list", "home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.eval_str_list"], []], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.forward": [[597, 630], ["tuple", "model.TransformerDecoder.embedding_layer", "model.TransformerDecoder.decoder_layers", "model.TransformerDecoder.model", "model.TransformerDecoder.decoder_output_layer", "i.to"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model"], []], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.output_layer": [[631, 641], ["torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.max_positions": [[642, 649], ["min"], "methods", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.buffered_future_mask": [[651, 663], ["tensor.size", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "hasattr", "model.TransformerDecoder._future_mask.size", "fairseq.utils.fill_with_neg_inf", "tensor.new"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.fill_with_neg_inf"], []], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.TransformerDecoder.upgrade_state_dict_named": [[664, 698], ["isinstance", "range", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "len", "layer_norm_map.items", "fairseq.utils.item", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "state_dict.get", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], []], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.transformer_iwslt_de_en_dist": [[700, 705], ["fairseq.models.register_model_architecture", "fairseq.models.transformer.transformer_iwslt_de_en"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.transformer.transformer_iwslt_de_en"], []], "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.model.transformer_wmt_en_de_big_dist": [[707, 712], ["fairseq.models.register_model_architecture", "fairseq.models.transformer.transformer_wmt_en_de_big"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture", "home.repos.pwc.inspect_result.reneeye_const.models.transformer.transformer_wmt_en_de_big"], []], "home.repos.pwc.inspect_result.reneeye_const.criterions.vocab_parallel_cross_entropy.VocabParallelCrossEntropyCriterion.__init__": [[24, 30], ["fairseq.criterions.FairseqCriterion.__init__", "ImportError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "task", ",", "sentence_avg", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "task", ")", "\n", "self", ".", "sentence_avg", "=", "sentence_avg", "\n", "if", "not", "has_megatron_submodule", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"\\n\\nPlease install the megatron submodule:\"", "\n", "\"\\n\\n  git submodule update --init \"", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.vocab_parallel_cross_entropy.VocabParallelCrossEntropyCriterion.forward": [[34, 57], ["model", "vocab_parallel_cross_entropy", "net_output[].float", "sample[].size", "sample[].size", "fairseq.utils.item"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "", "def", "forward", "(", "self", ",", "model", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "\"\"\"Compute the loss for the given sample.\n\n        Returns a tuple with three elements:\n        1) the loss\n        2) the sample size, which is used as the denominator for the gradient\n        3) logging outputs to display while training\n        \"\"\"", "\n", "net_output", "=", "model", "(", "**", "sample", "[", "\"net_input\"", "]", ")", "\n", "target", "=", "sample", "[", "\"target\"", "]", "\n", "\n", "loss", "=", "vocab_parallel_cross_entropy", "(", "net_output", "[", "0", "]", ".", "float", "(", ")", ",", "target", ")", "\n", "loss", "=", "(", "loss", "*", "(", "target", "!=", "self", ".", "padding_idx", ")", ")", ".", "sum", "(", ")", "\n", "sample_size", "=", "(", "\n", "sample", "[", "\"target\"", "]", ".", "size", "(", "0", ")", "if", "self", ".", "sentence_avg", "else", "sample", "[", "\"ntokens\"", "]", "\n", ")", "\n", "logging_output", "=", "{", "\n", "\"loss\"", ":", "utils", ".", "item", "(", "loss", ".", "data", ")", "if", "reduce", "else", "loss", ".", "data", ",", "\n", "\"ntokens\"", ":", "sample", "[", "\"ntokens\"", "]", ",", "\n", "\"nsentences\"", ":", "sample", "[", "\"target\"", "]", ".", "size", "(", "0", ")", ",", "\n", "\"sample_size\"", ":", "sample_size", ",", "\n", "}", "\n", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.vocab_parallel_cross_entropy.VocabParallelCrossEntropyCriterion.reduce_metrics": [[58, 78], ["sum", "sum", "sum", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_derived", "fairseq.metrics.log_derived", "log.get", "log.get", "log.get", "math.log", "math.log", "fairseq.utils.get_perplexity", "fairseq.utils.get_perplexity"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_perplexity", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_perplexity"], ["", "@", "staticmethod", "\n", "def", "reduce_metrics", "(", "logging_outputs", ")", "->", "None", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "loss_sum", "=", "sum", "(", "log", ".", "get", "(", "\"loss\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "ntokens", "=", "sum", "(", "log", ".", "get", "(", "\"ntokens\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "sample_size", "=", "sum", "(", "log", ".", "get", "(", "\"sample_size\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "\n", "metrics", ".", "log_scalar", "(", "\n", "\"loss\"", ",", "loss_sum", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", ",", "sample_size", ",", "round", "=", "3", "\n", ")", "\n", "if", "sample_size", "!=", "ntokens", ":", "\n", "            ", "metrics", ".", "log_scalar", "(", "\n", "\"nll_loss\"", ",", "loss_sum", "/", "ntokens", "/", "math", ".", "log", "(", "2", ")", ",", "ntokens", ",", "round", "=", "3", "\n", ")", "\n", "metrics", ".", "log_derived", "(", "\n", "\"ppl\"", ",", "lambda", "meters", ":", "utils", ".", "get_perplexity", "(", "meters", "[", "\"nll_loss\"", "]", ".", "avg", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "metrics", ".", "log_derived", "(", "\n", "\"ppl\"", ",", "lambda", "meters", ":", "utils", ".", "get_perplexity", "(", "meters", "[", "\"loss\"", "]", ".", "avg", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.vocab_parallel_cross_entropy.VocabParallelCrossEntropyCriterion.logging_outputs_can_be_summed": [[80, 88], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "logging_outputs_can_be_summed", "(", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Whether the logging outputs returned by `forward` can be summed\n        across workers prior to calling `reduce_metrics`. Setting this\n        to True will improves distributed training speed.\n        \"\"\"", "\n", "return", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.criterions.wav2vec_criterion.Wav2vecCriterion.__init__": [[38, 43], ["fairseq.criterions.FairseqCriterion.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "task", ",", "infonce", "=", "False", ",", "loss_weights", "=", "None", ",", "log_keys", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "task", ")", "\n", "self", ".", "infonce", "=", "infonce", "\n", "self", ".", "loss_weights", "=", "loss_weights", "\n", "self", ".", "log_keys", "=", "[", "]", "if", "log_keys", "is", "None", "else", "log_keys", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.wav2vec_criterion.Wav2vecCriterion.forward": [[44, 132], ["model", "model.get_logits().float", "model.get_targets", "losses.append", "hasattr", "model.get_target_weights", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.cross_entropy", "torch.cross_entropy", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "model.get_targets.numel", "model.get_targets.long().sum().item", "torch.binary_cross_entropy_with_logits.detach().clone", "hasattr", "model.get_extra_losses", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "zip", "sample[].numel", "len", "enumerate", "model.get_logits().float.cpu().numpy", "model.get_targets.cpu().numpy", "model.get_logits", "weights.float.float.float", "model.get_targets.float", "len", "len", "torch.binary_cross_entropy_with_logits.item", "float", "l.item", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model.get_targets.long().sum", "torch.binary_cross_entropy_with_logits.detach", "len", "len", "len", "len", "len", "losses.append", "model.get_logits().float.numel", "max.numel", "model.get_logits().float.cpu", "model.get_targets.cpu", "model.get_logits().float.dim", "model.get_logits().float.argmax", "model.get_logits().float.argmin", "max.long().sum().item", "both.long().sum().item", "model.get_targets.long", "p.float", "max.long().sum", "both.long().sum", "max.long", "both.long"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecModel.get_targets", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecModel.get_target_weights", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecModel.get_extra_losses", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecModel.get_logits", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "def", "forward", "(", "self", ",", "model", ",", "sample", ",", "reduce", "=", "True", ",", "log_pred", "=", "False", ")", ":", "\n", "        ", "\"\"\"Compute the loss for the given sample.\n\n        Returns a tuple with three elements:\n        1) the loss\n        2) the sample size, which is used as the denominator for the gradient\n        3) logging outputs to display while training\n        \"\"\"", "\n", "net_output", "=", "model", "(", "**", "sample", "[", "\"net_input\"", "]", ")", "\n", "logits", "=", "model", ".", "get_logits", "(", "net_output", ")", ".", "float", "(", ")", "\n", "target", "=", "model", ".", "get_targets", "(", "sample", ",", "net_output", ")", "\n", "\n", "weights", "=", "None", "\n", "if", "hasattr", "(", "model", ",", "\"get_target_weights\"", ")", "and", "not", "self", ".", "infonce", ":", "\n", "            ", "weights", "=", "model", ".", "get_target_weights", "(", "target", ",", "net_output", ")", "\n", "if", "torch", ".", "is_tensor", "(", "weights", ")", ":", "\n", "                ", "weights", "=", "weights", ".", "float", "(", ")", "\n", "\n", "", "", "losses", "=", "[", "]", "\n", "\n", "if", "self", ".", "infonce", ":", "\n", "            ", "loss", "=", "F", ".", "cross_entropy", "(", "\n", "logits", ",", "\n", "target", ",", "\n", "reduction", "=", "\"sum\"", "if", "reduce", "else", "\"none\"", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "logits", ",", "\n", "target", ".", "float", "(", ")", ",", "\n", "weights", ",", "\n", "reduction", "=", "\"sum\"", "if", "reduce", "else", "\"none\"", ",", "\n", ")", "\n", "\n", "", "sample_size", "=", "target", ".", "numel", "(", ")", "if", "self", ".", "infonce", "else", "target", ".", "long", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "losses", ".", "append", "(", "loss", ".", "detach", "(", ")", ".", "clone", "(", ")", ")", "\n", "\n", "if", "self", ".", "loss_weights", "is", "not", "None", ":", "\n", "            ", "assert", "hasattr", "(", "model", ",", "\"get_extra_losses\"", ")", "\n", "extra_losses", "=", "model", ".", "get_extra_losses", "(", "net_output", ")", "\n", "if", "torch", ".", "is_tensor", "(", "extra_losses", ")", ":", "\n", "                ", "extra_losses", "=", "[", "extra_losses", "]", "\n", "", "if", "len", "(", "self", ".", "loss_weights", ")", "==", "1", "and", "len", "(", "extra_losses", ")", "!=", "1", ":", "\n", "                ", "self", ".", "loss_weights", "=", "[", "self", ".", "loss_weights", "[", "0", "]", "]", "*", "len", "(", "extra_losses", ")", "\n", "", "assert", "len", "(", "extra_losses", ")", "==", "len", "(", "\n", "self", ".", "loss_weights", "\n", ")", ",", "f\"{len(extra_losses)}, {len(self.loss_weights)}\"", "\n", "for", "p", ",", "coef", "in", "zip", "(", "extra_losses", ",", "self", ".", "loss_weights", ")", ":", "\n", "                ", "if", "coef", "!=", "0", "and", "p", "is", "not", "None", ":", "\n", "                    ", "p", "=", "coef", "*", "p", ".", "float", "(", ")", "*", "sample_size", "\n", "loss", "+=", "p", "\n", "losses", ".", "append", "(", "p", ")", "\n", "\n", "", "", "", "logging_output", "=", "{", "\n", "\"loss\"", ":", "loss", ".", "item", "(", ")", "if", "reduce", "else", "loss", ",", "\n", "\"ntokens\"", ":", "sample_size", ",", "\n", "\"nsentences\"", ":", "sample", "[", "\"id\"", "]", ".", "numel", "(", ")", ",", "\n", "\"sample_size\"", ":", "sample_size", ",", "\n", "}", "\n", "\n", "for", "lk", "in", "self", ".", "log_keys", ":", "\n", "            ", "if", "lk", "in", "net_output", ":", "\n", "                ", "logging_output", "[", "lk", "]", "=", "float", "(", "(", "net_output", "[", "lk", "]", ")", ")", "\n", "\n", "", "", "if", "len", "(", "losses", ")", ">", "1", ":", "\n", "            ", "for", "i", ",", "l", "in", "enumerate", "(", "losses", ")", ":", "\n", "                ", "logging_output", "[", "f\"loss_{i}\"", "]", "=", "l", ".", "item", "(", ")", "\n", "\n", "", "", "if", "self", ".", "infonce", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "if", "logits", ".", "numel", "(", ")", "==", "0", ":", "\n", "                    ", "corr", "=", "0", "\n", "count", "=", "0", "\n", "", "else", ":", "\n", "                    ", "assert", "logits", ".", "dim", "(", ")", ">", "1", ",", "logits", ".", "shape", "\n", "max", "=", "logits", ".", "argmax", "(", "-", "1", ")", "==", "0", "\n", "min", "=", "logits", ".", "argmin", "(", "-", "1", ")", "==", "0", "\n", "both", "=", "max", "&", "min", "\n", "corr", "=", "max", ".", "long", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "-", "both", ".", "long", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "count", "=", "max", ".", "numel", "(", ")", "\n", "\n", "", "logging_output", "[", "\"correct\"", "]", "=", "corr", "\n", "logging_output", "[", "\"count\"", "]", "=", "count", "\n", "\n", "", "", "if", "log_pred", ":", "\n", "            ", "logging_output", "[", "\"logits\"", "]", "=", "logits", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "logging_output", "[", "\"target\"", "]", "=", "target", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.wav2vec_criterion.Wav2vecCriterion.reduce_metrics": [[133, 185], ["fairseq.utils.item", "fairseq.utils.item", "fairseq.utils.item", "fairseq.utils.item", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "sum", "sum", "sum", "fairseq.metrics.log_derived", "math.log", "log.get", "log.get", "k.startswith", "log.get", "log.get", "log.get", "log.get", "sum", "len", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.logging.meters.safe_round", "float", "log.get", "math.log"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.safe_round", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log"], ["", "@", "staticmethod", "\n", "def", "reduce_metrics", "(", "logging_outputs", ")", "->", "None", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "loss_sum", "=", "utils", ".", "item", "(", "sum", "(", "log", ".", "get", "(", "\"loss\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", ")", "\n", "ntokens", "=", "utils", ".", "item", "(", "sum", "(", "log", ".", "get", "(", "\"ntokens\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", ")", "\n", "nsentences", "=", "utils", ".", "item", "(", "\n", "sum", "(", "log", ".", "get", "(", "\"nsentences\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", ")", "\n", "sample_size", "=", "utils", ".", "item", "(", "\n", "sum", "(", "log", ".", "get", "(", "\"sample_size\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", ")", "\n", "\n", "metrics", ".", "log_scalar", "(", "\n", "\"loss\"", ",", "loss_sum", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", ",", "sample_size", ",", "round", "=", "3", "\n", ")", "\n", "metrics", ".", "log_scalar", "(", "\"ntokens\"", ",", "ntokens", ")", "\n", "metrics", ".", "log_scalar", "(", "\"nsentences\"", ",", "nsentences", ")", "\n", "\n", "correct", "=", "sum", "(", "log", ".", "get", "(", "\"correct\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_correct\"", ",", "correct", ")", "\n", "\n", "total", "=", "sum", "(", "log", ".", "get", "(", "\"count\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_total\"", ",", "total", ")", "\n", "\n", "if", "total", ">", "0", ":", "\n", "            ", "metrics", ".", "log_derived", "(", "\n", "\"accuracy\"", ",", "\n", "lambda", "meters", ":", "safe_round", "(", "\n", "meters", "[", "\"_correct\"", "]", ".", "sum", "/", "meters", "[", "\"_total\"", "]", ".", "sum", ",", "5", "\n", ")", "\n", "if", "meters", "[", "\"_total\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", "\n", "\n", "", "builtin_keys", "=", "{", "\n", "\"loss\"", ",", "\n", "\"ntokens\"", ",", "\n", "\"nsentences\"", ",", "\n", "\"sample_size\"", ",", "\n", "\"correct\"", ",", "\n", "\"count\"", ",", "\n", "}", "\n", "\n", "for", "k", "in", "logging_outputs", "[", "0", "]", ":", "\n", "            ", "if", "k", "not", "in", "builtin_keys", ":", "\n", "                ", "val", "=", "sum", "(", "log", ".", "get", "(", "k", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "/", "len", "(", "\n", "logging_outputs", "\n", ")", "\n", "if", "k", ".", "startswith", "(", "\"loss\"", ")", ":", "\n", "                    ", "metrics", ".", "log_scalar", "(", "k", ",", "val", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", ",", "sample_size", ")", "\n", "", "else", ":", "\n", "                    ", "metrics", ".", "log_scalar", "(", "k", ",", "val", ",", "round", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.wav2vec_criterion.Wav2vecCriterion.logging_outputs_can_be_summed": [[186, 194], ["None"], "methods", ["None"], ["", "", "", "", "@", "staticmethod", "\n", "def", "logging_outputs_can_be_summed", "(", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Whether the logging outputs returned by `forward` can be summed\n        across workers prior to calling `reduce_metrics`. Setting this\n        to True will improves distributed training speed.\n        \"\"\"", "\n", "return", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.criterions.legacy_masked_lm.LegacyMaskedLmLoss.__init__": [[51, 55], ["fairseq.criterions.FairseqCriterion.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "self", ".", "seed", "=", "args", ".", "seed", "\n", "\n", "", "@", "classmethod", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.legacy_masked_lm.LegacyMaskedLmLoss.add_args": [[56, 71], ["parser.add_argument", "parser.add_argument"], "methods", ["None"], ["def", "load_dictionary", "(", "cls", ",", "filename", ")", ":", "\n", "        ", "return", "BertDictionary", ".", "load", "(", "filename", ")", "\n", "\n", "", "@", "classmethod", "\n", "def", "build_dictionary", "(", "\n", "cls", ",", "filenames", ",", "workers", "=", "1", ",", "threshold", "=", "-", "1", ",", "nwords", "=", "-", "1", ",", "padding_factor", "=", "8", "\n", ")", ":", "\n", "        ", "d", "=", "BertDictionary", "(", ")", "\n", "for", "filename", "in", "filenames", ":", "\n", "            ", "Dictionary", ".", "add_file_to_dictionary", "(", "\n", "filename", ",", "d", ",", "tokenizer", ".", "tokenize_line", ",", "workers", "\n", ")", "\n", "", "d", ".", "finalize", "(", "threshold", "=", "threshold", ",", "nwords", "=", "nwords", ",", "padding_factor", "=", "padding_factor", ")", "\n", "return", "d", "\n", "\n", "", "@", "property", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.legacy_masked_lm.LegacyMaskedLmLoss.forward": [[73, 134], ["model", "lm_logits.view.view.view", "sample[].view", "legacy_masked_lm.compute_cross_entropy_loss", "fairseq.utils.strip_pad().numel", "lm_logits.view.view.size", "sample[].view", "sample[].view.size", "fairseq.utils.strip_pad", "legacy_masked_lm.compute_cross_entropy_loss", "fairseq.utils.item", "fairseq.utils.item", "fairseq.utils.item"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.reneeye_const.criterions.legacy_masked_lm.compute_cross_entropy_loss", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.strip_pad", "home.repos.pwc.inspect_result.reneeye_const.criterions.legacy_masked_lm.compute_cross_entropy_loss", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["        ", "return", "self", ".", "dictionary", "\n", "\n", "", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Setup the task.\"\"\"", "\n", "paths", "=", "utils", ".", "split_paths", "(", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "dictionary", "=", "BertDictionary", ".", "load", "(", "os", ".", "path", ".", "join", "(", "paths", "[", "0", "]", ",", "\"dict.txt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"dictionary: {} types\"", ".", "format", "(", "len", "(", "dictionary", ")", ")", ")", "\n", "\n", "return", "cls", "(", "args", ",", "dictionary", ")", "\n", "\n", "", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "1", ",", "combine", "=", "False", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n        \"\"\"", "\n", "loaded_datasets", "=", "[", "]", "\n", "\n", "paths", "=", "utils", ".", "split_paths", "(", "self", ".", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "data_path", "=", "paths", "[", "(", "epoch", "-", "1", ")", "%", "len", "(", "paths", ")", "]", "\n", "logger", ".", "info", "(", "\"data_path\"", ",", "data_path", ")", "\n", "\n", "for", "k", "in", "itertools", ".", "count", "(", ")", ":", "\n", "            ", "split_k", "=", "split", "+", "(", "str", "(", "k", ")", "if", "k", ">", "0", "else", "\"\"", ")", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "split_k", ")", "\n", "ds", "=", "indexed_dataset", ".", "make_dataset", "(", "\n", "path", ",", "\n", "impl", "=", "self", ".", "args", ".", "dataset_impl", ",", "\n", "fix_lua_indexing", "=", "True", ",", "\n", "dictionary", "=", "self", ".", "dictionary", ",", "\n", ")", "\n", "\n", "if", "ds", "is", "None", ":", "\n", "                ", "if", "k", ">", "0", ":", "\n", "                    ", "break", "\n", "", "else", ":", "\n", "                    ", "raise", "FileNotFoundError", "(", "\n", "\"Dataset not found: {} ({})\"", ".", "format", "(", "split", ",", "data_path", ")", "\n", ")", "\n", "\n", "", "", "with", "data_utils", ".", "numpy_seed", "(", "self", ".", "seed", "+", "k", ")", ":", "\n", "                ", "loaded_datasets", ".", "append", "(", "\n", "BlockPairDataset", "(", "\n", "ds", ",", "\n", "self", ".", "dictionary", ",", "\n", "ds", ".", "sizes", ",", "\n", "self", ".", "args", ".", "tokens_per_sample", ",", "\n", "break_mode", "=", "self", ".", "args", ".", "break_mode", ",", "\n", "doc_break_size", "=", "1", ",", "\n", ")", "\n", ")", "\n", "\n", "", "logger", ".", "info", "(", "\n", "\"{} {} {} examples\"", ".", "format", "(", "data_path", ",", "split_k", ",", "len", "(", "loaded_datasets", "[", "-", "1", "]", ")", ")", "\n", ")", "\n", "\n", "if", "not", "combine", ":", "\n", "                ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.legacy_masked_lm.LegacyMaskedLmLoss.reduce_metrics": [[135, 168], ["sum", "sum", "sum", "sum", "sum", "sum", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "math.log", "math.log", "math.log", "math.log"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log"], ["", "", "if", "len", "(", "loaded_datasets", ")", "==", "1", ":", "\n", "            ", "dataset", "=", "loaded_datasets", "[", "0", "]", "\n", "sizes", "=", "dataset", ".", "sizes", "\n", "", "else", ":", "\n", "            ", "dataset", "=", "ConcatDataset", "(", "loaded_datasets", ")", "\n", "sizes", "=", "np", ".", "concatenate", "(", "[", "ds", ".", "sizes", "for", "ds", "in", "loaded_datasets", "]", ")", "\n", "\n", "", "self", ".", "datasets", "[", "split", "]", "=", "MaskedLMDataset", "(", "\n", "dataset", "=", "dataset", ",", "\n", "sizes", "=", "sizes", ",", "\n", "vocab", "=", "self", ".", "dictionary", ",", "\n", "pad_idx", "=", "self", ".", "dictionary", ".", "pad", "(", ")", ",", "\n", "mask_idx", "=", "self", ".", "dictionary", ".", "mask", "(", ")", ",", "\n", "classif_token_idx", "=", "self", ".", "dictionary", ".", "cls", "(", ")", ",", "\n", "sep_token_idx", "=", "self", ".", "dictionary", ".", "sep", "(", ")", ",", "\n", "shuffle", "=", "self", ".", "args", ".", "shuffle_dataset", ",", "\n", "seed", "=", "self", ".", "seed", ",", "\n", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.criterions.legacy_masked_lm.LegacyMaskedLmLoss.logging_outputs_can_be_summed": [[170, 178], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.criterions.legacy_masked_lm.compute_cross_entropy_loss": [[14, 31], ["torch.nll_loss", "logits.size", "targets.size", "torch.log_softmax"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax"], ["from", "fairseq", ".", "data", ".", "legacy", ".", "masked_lm_dataset", "import", "MaskedLMDataset", "\n", "from", "fairseq", ".", "data", ".", "legacy", ".", "masked_lm_dictionary", "import", "BertDictionary", "\n", "from", "fairseq", ".", "tasks", "import", "LegacyFairseqTask", ",", "register_task", "\n", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "\n", "@", "register_task", "(", "\"legacy_masked_lm\"", ")", "\n", "class", "LegacyMaskedLMTask", "(", "LegacyFairseqTask", ")", ":", "\n", "    ", "\"\"\"\n    Task for training Masked LM (BERT) model.\n    Args:\n        dictionary (Dictionary): the dictionary for the input of the task\n    \"\"\"", "\n", "\n", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.fairseq_criterion.FairseqCriterion.__init__": [[16, 22], ["torch.nn.modules.loss._Loss.__init__", "hasattr", "tgt_dict.pad"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["    ", "def", "__init__", "(", "self", ",", "task", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "task", "=", "task", "\n", "if", "hasattr", "(", "task", ",", "\"target_dictionary\"", ")", ":", "\n", "            ", "tgt_dict", "=", "task", ".", "target_dictionary", "\n", "self", ".", "padding_idx", "=", "tgt_dict", ".", "pad", "(", ")", "if", "tgt_dict", "is", "not", "None", "else", "-", "100", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.fairseq_criterion.FairseqCriterion.add_args": [[23, 29], ["getattr", "fairseq.dataclass.utils.gen_parser_from_dataclass", "getattr."], "methods", ["home.repos.pwc.inspect_result.reneeye_const.dataclass.utils.gen_parser_from_dataclass"], ["", "", "@", "classmethod", "\n", "def", "add_args", "(", "cls", ",", "parser", ")", ":", "\n", "        ", "\"\"\"Add criterion-specific arguments to the parser.\"\"\"", "\n", "dc", "=", "getattr", "(", "cls", ",", "\"__dataclass\"", ",", "None", ")", "\n", "if", "dc", "is", "not", "None", ":", "\n", "            ", "gen_parser_from_dataclass", "(", "parser", ",", "dc", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.fairseq_criterion.FairseqCriterion.build_criterion": [[30, 61], ["inspect.signature().parameters.values", "cls", "NotImplementedError", "inspect.signature", "hasattr", "getattr", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "", "@", "classmethod", "\n", "def", "build_criterion", "(", "cls", ",", "cfg", ":", "FairseqDataclass", ",", "task", ")", ":", "\n", "        ", "\"\"\"Construct a criterion from command-line args.\"\"\"", "\n", "# arguments in the __init__.", "\n", "init_args", "=", "{", "}", "\n", "for", "p", "in", "inspect", ".", "signature", "(", "cls", ")", ".", "parameters", ".", "values", "(", ")", ":", "\n", "            ", "if", "(", "\n", "p", ".", "kind", "==", "p", ".", "POSITIONAL_ONLY", "\n", "or", "p", ".", "kind", "==", "p", ".", "VAR_POSITIONAL", "\n", "or", "p", ".", "kind", "==", "p", ".", "VAR_KEYWORD", "\n", ")", ":", "\n", "# we haven't implemented inference for these argument types,", "\n", "# but PRs welcome :)", "\n", "                ", "raise", "NotImplementedError", "(", "\"{} not supported\"", ".", "format", "(", "p", ".", "kind", ")", ")", "\n", "\n", "", "assert", "p", ".", "kind", "in", "{", "p", ".", "POSITIONAL_OR_KEYWORD", ",", "p", ".", "KEYWORD_ONLY", "}", "\n", "\n", "if", "p", ".", "name", "==", "\"task\"", ":", "\n", "                ", "init_args", "[", "\"task\"", "]", "=", "task", "\n", "", "elif", "p", ".", "name", "==", "\"cfg\"", ":", "\n", "                ", "init_args", "[", "\"cfg\"", "]", "=", "cfg", "\n", "", "elif", "hasattr", "(", "cfg", ",", "p", ".", "name", ")", ":", "\n", "                ", "init_args", "[", "p", ".", "name", "]", "=", "getattr", "(", "cfg", ",", "p", ".", "name", ")", "\n", "", "elif", "p", ".", "default", "!=", "p", ".", "empty", ":", "\n", "                ", "pass", "# we'll use the default value", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "\n", "\"Unable to infer Criterion arguments, please implement \"", "\n", "\"{}.build_criterion\"", ".", "format", "(", "cls", ".", "__name__", ")", "\n", ")", "\n", "", "", "return", "cls", "(", "**", "init_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.fairseq_criterion.FairseqCriterion.forward": [[62, 71], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "model", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "\"\"\"Compute the loss for the given sample.\n\n        Returns a tuple with three elements:\n        1) the loss\n        2) the sample size, which is used as the denominator for the gradient\n        3) logging outputs to display while training\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.fairseq_criterion.FairseqCriterion.aggregate_logging_outputs": [[72, 82], ["fairseq.utils.deprecation_warning"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.deprecation_warning"], ["", "@", "staticmethod", "\n", "def", "aggregate_logging_outputs", "(", "\n", "logging_outputs", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "\n", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "utils", ".", "deprecation_warning", "(", "\n", "\"The aggregate_logging_outputs API is deprecated. \"", "\n", "\"Please use the reduce_metrics API instead.\"", "\n", ")", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.fairseq_criterion.FairseqCriterion.reduce_metrics": [[83, 95], ["fairseq.utils.deprecation_warning", "cls.aggregate_logging_outputs", "cls.aggregate_logging_outputs.items", "fairseq.metrics.log_scalar"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.deprecation_warning", "home.repos.pwc.inspect_result.reneeye_const.criterions.fairseq_criterion.FairseqCriterion.aggregate_logging_outputs", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar"], ["", "@", "classmethod", "\n", "def", "reduce_metrics", "(", "cls", ",", "logging_outputs", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "utils", ".", "deprecation_warning", "(", "\n", "\"Criterions should implement the reduce_metrics API. \"", "\n", "\"Falling back to deprecated aggregate_logging_outputs API.\"", "\n", ")", "\n", "agg_logging_outputs", "=", "cls", ".", "aggregate_logging_outputs", "(", "logging_outputs", ")", "\n", "for", "k", ",", "v", "in", "agg_logging_outputs", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "in", "{", "\"nsentences\"", ",", "\"ntokens\"", ",", "\"sample_size\"", "}", ":", "\n", "                ", "continue", "\n", "", "metrics", ".", "log_scalar", "(", "k", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.fairseq_criterion.FairseqCriterion.logging_outputs_can_be_summed": [[96, 104], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "logging_outputs_can_be_summed", "(", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Whether the logging outputs returned by `forward` can be summed\n        across workers prior to calling `reduce_metrics`. Setting this\n        to True will improves distributed training speed.\n        \"\"\"", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.fairseq_criterion.LegacyFairseqCriterion.__init__": [[107, 113], ["fairseq_criterion.FairseqCriterion.__init__", "fairseq.utils.deprecation_warning"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.deprecation_warning"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "task", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "task", "=", "task", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n", "utils", ".", "deprecation_warning", "(", "\n", "\"Criterions should take explicit arguments instead of an \"", "\n", "\"argparse.Namespace object, please update your criterion by \"", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.fairseq_criterion.LegacyFairseqCriterion.build_criterion": [[117, 121], ["cls"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "@", "classmethod", "\n", "def", "build_criterion", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "\"\"\"Construct a criterion from command-line args.\"\"\"", "\n", "return", "cls", "(", "args", ",", "task", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.criterions.cross_entropy.CrossEntropyCriterion.__init__": [[23, 26], ["fairseq.criterions.FairseqCriterion.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["\n", "\n", "", "try", ":", "\n", "    ", "import", "xentropy_cuda", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.cross_entropy.CrossEntropyCriterion.forward": [[27, 47], ["model", "cross_entropy.CrossEntropyCriterion.compute_loss", "sample[].size", "sample[].size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.compute_loss", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["from", "apex", ".", "contrib", "import", "xentropy", "\n", "\n", "logger", ".", "info", "(", "\"using fused cross entropy\"", ")", "\n", "\n", "def", "cross_entropy", "(", "logits", ",", "target", ",", "ignore_index", "=", "-", "100", ",", "reduction", "=", "\"mean\"", ")", ":", "\n", "        ", "if", "logits", ".", "device", "==", "torch", ".", "device", "(", "\"cpu\"", ")", ":", "\n", "            ", "return", "_cross_entropy_pytorch", "(", "logits", ",", "target", ",", "ignore_index", ",", "reduction", ")", "\n", "", "else", ":", "\n", "            ", "half_to_float", "=", "logits", ".", "dtype", "==", "torch", ".", "half", "\n", "losses", "=", "xentropy", ".", "SoftmaxCrossEntropyLoss", ".", "apply", "(", "\n", "logits", ",", "\n", "target", ",", "\n", "0.0", ",", "\n", "ignore_index", ",", "\n", "half_to_float", ",", "\n", ")", "\n", "if", "reduction", "==", "\"sum\"", ":", "\n", "                ", "return", "losses", ".", "sum", "(", ")", "\n", "", "elif", "reduction", "==", "\"mean\"", ":", "\n", "                ", "if", "ignore_index", ">=", "0", ":", "\n", "                    ", "return", "losses", ".", "sum", "(", ")", "/", "target", ".", "ne", "(", "ignore_index", ")", ".", "sum", "(", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.cross_entropy.CrossEntropyCriterion.compute_loss": [[48, 59], ["model.get_normalized_probs", "lprobs.view.view.view", "model.get_targets().view", "torch.nll_loss", "lprobs.view.view.size", "model.get_targets"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.get_normalized_probs", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecModel.get_targets"], ["", "else", ":", "\n", "                    ", "return", "losses", ".", "mean", "(", ")", "\n", "", "", "elif", "reduction", "==", "\"none\"", ":", "\n", "                ", "return", "losses", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "\n", "", "", "", "", "except", "ImportError", ":", "\n", "\n", "    ", "def", "cross_entropy", "(", "logits", ",", "target", ",", "ignore_index", "=", "-", "100", ",", "reduction", "=", "\"mean\"", ")", ":", "\n", "        ", "return", "_cross_entropy_pytorch", "(", "logits", ",", "target", ",", "ignore_index", ",", "reduction", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.cross_entropy.CrossEntropyCriterion.reduce_metrics": [[60, 81], ["sum", "sum", "sum", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_derived", "fairseq.metrics.log_derived", "log.get", "log.get", "log.get", "math.log", "math.log", "fairseq.utils.get_perplexity", "fairseq.utils.get_perplexity"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_perplexity", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_perplexity"], ["", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.criterions.cross_entropy.CrossEntropyCriterion.logging_outputs_can_be_summed": [[83, 91], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.criterions.adaptive_loss.AdaptiveLoss.__init__": [[29, 32], ["fairseq.criterions.FairseqCriterion.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "task", ",", "sentence_avg", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "task", ")", "\n", "self", ".", "sentence_avg", "=", "sentence_avg", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.adaptive_loss.AdaptiveLoss.build_criterion": [[33, 42], ["cls", "Exception"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "@", "classmethod", "\n", "def", "build_criterion", "(", "cls", ",", "cfg", ":", "AdaptiveLossConfig", ",", "task", ")", ":", "\n", "        ", "if", "cfg", ".", "ddp_backend", "==", "\"c10d\"", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"AdaptiveLoss is not compatible with the c10d \"", "\n", "\"version of DistributedDataParallel. Please use \"", "\n", "\"`--ddp-backend=no_c10d` instead.\"", "\n", ")", "\n", "", "return", "cls", "(", "task", ",", "cfg", ".", "sentence_avg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.adaptive_loss.AdaptiveLoss.forward": [[43, 91], ["model", "model.get_targets", "orig_target.view.view.size", "orig_target.view.view.view", "orig_target.view.view.size", "adaptive_softmax", "net_output[].new().zero_", "range", "fairseq.utils.strip_pad", "fairseq.utils.strip_pad.numel", "hasattr", "len", "len", "len", "sample[].size", "net_output[].new", "torch.cross_entropy", "target[].min", "target[].max", "logits[].size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecModel.get_targets", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.strip_pad", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "forward", "(", "self", ",", "model", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "\"\"\"Compute the loss for the given sample.\n\n        Returns a tuple with three elements:\n        1) the loss\n        2) the sample size, which is used as the denominator for the gradient\n        3) logging outputs to display while training\n        \"\"\"", "\n", "\n", "assert", "(", "\n", "hasattr", "(", "model", ".", "decoder", ",", "\"adaptive_softmax\"", ")", "\n", "and", "model", ".", "decoder", ".", "adaptive_softmax", "is", "not", "None", "\n", ")", "\n", "adaptive_softmax", "=", "model", ".", "decoder", ".", "adaptive_softmax", "\n", "\n", "net_output", "=", "model", "(", "**", "sample", "[", "\"net_input\"", "]", ")", "\n", "orig_target", "=", "model", ".", "get_targets", "(", "sample", ",", "net_output", ")", "\n", "\n", "nsentences", "=", "orig_target", ".", "size", "(", "0", ")", "\n", "orig_target", "=", "orig_target", ".", "view", "(", "-", "1", ")", "\n", "\n", "bsz", "=", "orig_target", ".", "size", "(", "0", ")", "\n", "\n", "logits", ",", "target", "=", "adaptive_softmax", "(", "net_output", "[", "0", "]", ",", "orig_target", ")", "\n", "assert", "len", "(", "target", ")", "==", "len", "(", "logits", ")", "\n", "\n", "loss", "=", "net_output", "[", "0", "]", ".", "new", "(", "1", "if", "reduce", "else", "bsz", ")", ".", "zero_", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "target", ")", ")", ":", "\n", "            ", "if", "target", "[", "i", "]", "is", "not", "None", ":", "\n", "                ", "assert", "target", "[", "i", "]", ".", "min", "(", ")", ">=", "0", "and", "target", "[", "i", "]", ".", "max", "(", ")", "<=", "logits", "[", "i", "]", ".", "size", "(", "1", ")", "\n", "loss", "+=", "F", ".", "cross_entropy", "(", "\n", "logits", "[", "i", "]", ",", "\n", "target", "[", "i", "]", ",", "\n", "ignore_index", "=", "self", ".", "padding_idx", ",", "\n", "reduction", "=", "\"sum\"", "if", "reduce", "else", "\"none\"", ",", "\n", ")", "\n", "\n", "", "", "orig", "=", "utils", ".", "strip_pad", "(", "orig_target", ",", "self", ".", "padding_idx", ")", "\n", "ntokens", "=", "orig", ".", "numel", "(", ")", "\n", "sample_size", "=", "sample", "[", "\"target\"", "]", ".", "size", "(", "0", ")", "if", "self", ".", "sentence_avg", "else", "ntokens", "\n", "logging_output", "=", "{", "\n", "\"loss\"", ":", "loss", ".", "data", ",", "\n", "\"ntokens\"", ":", "ntokens", ",", "\n", "\"nsentences\"", ":", "nsentences", ",", "\n", "\"sample_size\"", ":", "sample_size", ",", "\n", "}", "\n", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.adaptive_loss.AdaptiveLoss.reduce_metrics": [[92, 114], ["fairseq.utils.item", "fairseq.utils.item", "fairseq.utils.item", "fairseq.metrics.log_scalar", "sum", "sum", "sum", "fairseq.metrics.log_scalar", "fairseq.metrics.log_derived", "fairseq.metrics.log_derived", "math.log", "log.get", "log.get", "log.get", "math.log", "fairseq.utils.get_perplexity", "fairseq.utils.get_perplexity"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_perplexity", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_perplexity"], ["", "@", "staticmethod", "\n", "def", "reduce_metrics", "(", "logging_outputs", ")", "->", "None", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "loss_sum", "=", "utils", ".", "item", "(", "sum", "(", "log", ".", "get", "(", "\"loss\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", ")", "\n", "ntokens", "=", "utils", ".", "item", "(", "sum", "(", "log", ".", "get", "(", "\"ntokens\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", ")", "\n", "sample_size", "=", "utils", ".", "item", "(", "\n", "sum", "(", "log", ".", "get", "(", "\"sample_size\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", ")", "\n", "\n", "metrics", ".", "log_scalar", "(", "\n", "\"loss\"", ",", "loss_sum", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", ",", "sample_size", ",", "round", "=", "3", "\n", ")", "\n", "if", "sample_size", "!=", "ntokens", ":", "\n", "            ", "metrics", ".", "log_scalar", "(", "\n", "\"nll_loss\"", ",", "loss_sum", "/", "ntokens", "/", "math", ".", "log", "(", "2", ")", ",", "ntokens", ",", "round", "=", "3", "\n", ")", "\n", "metrics", ".", "log_derived", "(", "\n", "\"ppl\"", ",", "lambda", "meters", ":", "utils", ".", "get_perplexity", "(", "meters", "[", "\"nll_loss\"", "]", ".", "avg", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "metrics", ".", "log_derived", "(", "\n", "\"ppl\"", ",", "lambda", "meters", ":", "utils", ".", "get_perplexity", "(", "meters", "[", "\"loss\"", "]", ".", "avg", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.adaptive_loss.AdaptiveLoss.logging_outputs_can_be_summed": [[116, 124], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "logging_outputs_can_be_summed", "(", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Whether the logging outputs returned by `forward` can be summed\n        across workers prior to calling `reduce_metrics`. Setting this\n        to True will improves distributed training speed.\n        \"\"\"", "\n", "return", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.criterions.multitask_crossentropy_with_contrastive_with_extra_mt.MultiTaskCrossEntropyWithContrastiveWithExtraMT.__init__": [[18, 30], ["fairseq.criterions.label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "task", ",", "\n", "sentence_avg", ",", "\n", "label_smoothing", ",", "\n", "ignore_prefix_size", "=", "0", ",", "\n", "report_accuracy", "=", "False", ",", "\n", "contrastive_weight", "=", "0.0", ",", "\n", "contrastive_temperature", "=", "1.0", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "task", ",", "sentence_avg", ",", "label_smoothing", ",", "ignore_prefix_size", ",", "report_accuracy", ",", "\n", "contrastive_weight", ",", "contrastive_temperature", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.multitask_crossentropy_with_contrastive_with_extra_mt.MultiTaskCrossEntropyWithContrastiveWithExtraMT.forward": [[31, 112], ["model", "sample[].size", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "multitask_crossentropy_with_contrastive_with_extra_mt.MultiTaskCrossEntropyWithContrastiveWithExtraMT.compute_accuracy", "fairseq.utils.item", "fairseq.utils.item", "multitask_crossentropy_with_contrastive_with_extra_mt.MultiTaskCrossEntropyWithContrastiveWithExtraMT.compute_contrastive_loss", "multitask_crossentropy_with_contrastive_with_extra_mt.MultiTaskCrossEntropyWithContrastiveWithExtraMT.compute_loss", "multitask_crossentropy_with_contrastive_with_extra_mt.MultiTaskCrossEntropyWithContrastiveWithExtraMT.compute_loss_asr", "multitask_crossentropy_with_contrastive_with_extra_mt.MultiTaskCrossEntropyWithContrastiveWithExtraMT.compute_loss_mt", "multitask_crossentropy_with_contrastive_with_extra_mt.MultiTaskCrossEntropyWithContrastiveWithExtraMT.compute_loss", "sample[].size", "sample[].size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.compute_accuracy", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.compute_contrastive_loss", "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.compute_loss", "home.repos.pwc.inspect_result.reneeye_const.criterions.multitask_crossentropy_with_contrastive_with_extra_mt.MultiTaskCrossEntropyWithContrastiveWithExtraMT.compute_loss_asr", "home.repos.pwc.inspect_result.reneeye_const.criterions.multitask_crossentropy_with_contrastive_with_extra_mt.MultiTaskCrossEntropyWithContrastiveWithExtraMT.compute_loss_mt", "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.compute_loss", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "forward", "(", "self", ",", "model", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "\"\"\"Compute the loss for the given sample.\n\n        Returns a tuple with three elements:\n        1) the loss\n        2) the sample size, which is used as the denominator for the gradient\n        3) logging outputs to display while training\n        \"\"\"", "\n", "label_smoothed_nll_loss", ",", "nll_loss", "=", "torch", ".", "tensor", "(", "0.0", ")", ",", "torch", ".", "tensor", "(", "0.0", ")", "\n", "label_smoothed_nll_loss_asr", ",", "nll_loss_asr", "=", "torch", ".", "tensor", "(", "0.0", ")", ",", "torch", ".", "tensor", "(", "0.0", ")", "\n", "label_smoothed_nll_loss_mt", ",", "nll_loss_mt", "=", "torch", ".", "tensor", "(", "0.0", ")", ",", "torch", ".", "tensor", "(", "0.0", ")", "\n", "contrastive_loss", ",", "short_audio_len", "=", "torch", ".", "tensor", "(", "0.0", ")", ",", "None", "\n", "\n", "if", "\"mode\"", "in", "sample", "[", "\"net_input\"", "]", "and", "sample", "[", "\"net_input\"", "]", "[", "\"mode\"", "]", "==", "\"text_to_text\"", ":", "\n", "            ", "sample", "[", "\"dataset_type\"", "]", "=", "\"mt\"", "\n", "sample", "[", "\"net_input\"", "]", "[", "\"is_text_input\"", "]", "=", "True", "\n", "", "else", ":", "\n", "            ", "sample", "[", "\"net_input\"", "]", "[", "\"is_text_input\"", "]", "=", "False", "\n", "\n", "", "_net_output", "=", "model", "(", "**", "sample", "[", "\"net_input\"", "]", ")", "# (x, extra)", "\n", "if", "model", ".", "training", ":", "\n", "            ", "net_output", ",", "encoder_out", "=", "_net_output", "\n", "if", "(", "sample", "[", "\"dataset_type\"", "]", "!=", "\"mt\"", ")", "and", "(", "self", ".", "contrastive_weight", ">", "0", ")", ":", "\n", "                ", "contrastive_loss", ",", "short_audio_len", "=", "self", ".", "compute_contrastive_loss", "(", "\n", "model", ",", "sample", ",", "encoder_out", ",", "\n", "reduce", "=", "reduce", ",", "return_short_audio_len", "=", "True", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "net_output", "=", "_net_output", "\n", "\n", "", "if", "sample", "[", "\"target\"", "]", "is", "not", "None", ":", "\n", "            ", "if", "sample", "[", "\"dataset_type\"", "]", "==", "\"st\"", "and", "model", ".", "training", ":", "\n", "                ", "label_smoothed_nll_loss", ",", "nll_loss", "=", "self", ".", "compute_loss", "(", "model", ",", "net_output", ",", "sample", ",", "reduce", "=", "reduce", ")", "\n", "label_smoothed_nll_loss_asr", ",", "nll_loss_asr", "=", "self", ".", "compute_loss_asr", "(", "model", ",", "sample", ",", "reduce", "=", "reduce", ")", "\n", "label_smoothed_nll_loss_mt", ",", "nll_loss_mt", "=", "self", ".", "compute_loss_mt", "(", "model", ",", "sample", ",", "reduce", "=", "reduce", ")", "\n", "\n", "", "else", ":", "# mt type compute CE_mt loss", "\n", "                ", "label_smoothed_nll_loss_mt", ",", "nll_loss_mt", "=", "self", ".", "compute_loss", "(", "model", ",", "net_output", ",", "sample", ",", "reduce", "=", "reduce", ")", "\n", "\n", "", "", "if", "sample", "[", "\"dataset_type\"", "]", "==", "\"st\"", ":", "\n", "            ", "source_ntokens", "=", "sample", "[", "\"source_ntokens\"", "]", "\n", "target_ntokens", "=", "sample", "[", "\"target_ntokens\"", "]", "\n", "target_ntokens_st", "=", "target_ntokens", "\n", "target_ntokens_mt", "=", "0", "\n", "sample_size", "=", "sample", "[", "\"target\"", "]", ".", "size", "(", "0", ")", "if", "self", ".", "sentence_avg", "else", "sample", "[", "\"target_ntokens\"", "]", "\n", "", "else", ":", "\n", "            ", "source_ntokens", "=", "0", "\n", "target_ntokens", "=", "sample", "[", "\"ntokens\"", "]", "\n", "target_ntokens_mt", "=", "target_ntokens", "\n", "target_ntokens_st", "=", "0", "\n", "sample_size", "=", "sample", "[", "\"target\"", "]", ".", "size", "(", "0", ")", "if", "self", ".", "sentence_avg", "else", "sample", "[", "\"ntokens\"", "]", "\n", "\n", "", "nsentences", "=", "sample", "[", "\"target\"", "]", ".", "size", "(", "0", ")", "\n", "if", "sample", "[", "\"dataset_type\"", "]", "==", "\"st\"", ":", "\n", "            ", "multi_ce_loss", "=", "label_smoothed_nll_loss", "+", "label_smoothed_nll_loss_asr", "+", "label_smoothed_nll_loss_mt", "\n", "loss", "=", "multi_ce_loss", "+", "self", ".", "contrastive_weight", "*", "contrastive_loss", "\n", "", "else", ":", "\n", "            ", "loss", "=", "label_smoothed_nll_loss_mt", "\n", "\n", "", "logging_output", "=", "{", "\n", "\"loss\"", ":", "loss", ".", "data", ",", "\n", "\"nll_loss\"", ":", "nll_loss", ".", "data", ",", "\n", "\"contrastive_loss\"", ":", "contrastive_loss", ".", "data", ",", "\n", "\"source_ntokens\"", ":", "source_ntokens", ",", "\n", "\"target_ntokens\"", ":", "target_ntokens", ",", "\n", "\"target_ntokens_mt\"", ":", "target_ntokens_mt", ",", "\n", "\"target_ntokens_st\"", ":", "target_ntokens_st", ",", "\n", "\"ntokens\"", ":", "target_ntokens", ",", "\n", "\"nsentences\"", ":", "nsentences", ",", "\n", "\"sample_size\"", ":", "sample_size", ",", "\n", "\"nll_loss_asr\"", ":", "nll_loss_asr", ".", "data", ",", "\n", "\"nll_loss_mt\"", ":", "nll_loss_mt", ".", "data", ",", "\n", "\"st_nsentences\"", ":", "nsentences", "if", "sample", "[", "\"dataset_type\"", "]", "!=", "\"mt\"", "else", "0", ",", "\n", "\"mt_nsentences\"", ":", "nsentences", "if", "sample", "[", "\"dataset_type\"", "]", "==", "\"mt\"", "else", "0", "\n", "}", "\n", "\n", "if", "self", ".", "report_accuracy", ":", "\n", "            ", "n_correct", ",", "total", "=", "self", ".", "compute_accuracy", "(", "model", ",", "net_output", ",", "sample", ")", "\n", "logging_output", "[", "\"n_correct\"", "]", "=", "utils", ".", "item", "(", "n_correct", ".", "data", ")", "\n", "logging_output", "[", "\"total\"", "]", "=", "utils", ".", "item", "(", "total", ".", "data", ")", "\n", "", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.multitask_crossentropy_with_contrastive_with_extra_mt.MultiTaskCrossEntropyWithContrastiveWithExtraMT.compute_loss_asr": [[113, 136], ["model", "model.get_normalized_probs", "lprobs[].contiguous.view", "target[].contiguous.view", "fairseq.criterions.label_smoothed_cross_entropy.label_smoothed_nll_loss", "getattr", "lprobs[].contiguous.size", "lprobs[].contiguous", "target[].contiguous", "lprobs[].contiguous", "target[].contiguous"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.get_normalized_probs", "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.label_smoothed_nll_loss", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "compute_loss_asr", "(", "self", ",", "model", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "net_output", ",", "_", "=", "model", "(", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", ",", "\n", "sample", "[", "\"net_input\"", "]", "[", "\"src_lengths\"", "]", ",", "\n", "sample", "[", "\"prev_output_src_tokens\"", "]", ")", "\n", "lprobs", "=", "model", ".", "get_normalized_probs", "(", "net_output", ",", "log_probs", "=", "True", ")", "\n", "target", "=", "sample", "[", "\"source\"", "]", "\n", "if", "self", ".", "ignore_prefix_size", ">", "0", ":", "\n", "            ", "if", "getattr", "(", "lprobs", ",", "\"batch_first\"", ",", "False", ")", ":", "\n", "                ", "lprobs", "=", "lprobs", "[", ":", ",", "self", ".", "ignore_prefix_size", ":", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "target", "=", "target", "[", ":", ",", "self", ".", "ignore_prefix_size", ":", "]", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "                ", "lprobs", "=", "lprobs", "[", "self", ".", "ignore_prefix_size", ":", ",", ":", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "target", "=", "target", "[", "self", ".", "ignore_prefix_size", ":", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "", "", "lprobs", "=", "lprobs", ".", "view", "(", "-", "1", ",", "lprobs", ".", "size", "(", "-", "1", ")", ")", "\n", "target", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "loss", ",", "nll_loss", "=", "label_smoothed_nll_loss", "(", "\n", "lprobs", ",", "\n", "target", ",", "\n", "self", ".", "eps", ",", "\n", "ignore_index", "=", "self", ".", "padding_idx", ",", "\n", "reduce", "=", "reduce", ",", "\n", ")", "\n", "return", "loss", ",", "nll_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.multitask_crossentropy_with_contrastive_with_extra_mt.MultiTaskCrossEntropyWithContrastiveWithExtraMT.compute_loss_mt": [[137, 160], ["model", "model.get_normalized_probs", "model.get_targets", "lprobs[].contiguous.view", "target[].contiguous.view", "fairseq.criterions.label_smoothed_cross_entropy.label_smoothed_nll_loss", "getattr", "lprobs[].contiguous.size", "lprobs[].contiguous", "target[].contiguous", "lprobs[].contiguous", "target[].contiguous"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.get_normalized_probs", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecModel.get_targets", "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.label_smoothed_nll_loss", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "compute_loss_mt", "(", "self", ",", "model", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "net_output", ",", "_", "=", "model", "(", "sample", "[", "\"source\"", "]", ",", "sample", "[", "\"source_lengths\"", "]", ",", "\n", "sample", "[", "\"net_input\"", "]", "[", "\"prev_output_tokens\"", "]", ",", "is_text_input", "=", "True", ")", "\n", "\n", "lprobs", "=", "model", ".", "get_normalized_probs", "(", "net_output", ",", "log_probs", "=", "True", ")", "\n", "target", "=", "model", ".", "get_targets", "(", "sample", ",", "net_output", ")", "\n", "if", "self", ".", "ignore_prefix_size", ">", "0", ":", "\n", "            ", "if", "getattr", "(", "lprobs", ",", "\"batch_first\"", ",", "False", ")", ":", "\n", "                ", "lprobs", "=", "lprobs", "[", ":", ",", "self", ".", "ignore_prefix_size", ":", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "target", "=", "target", "[", ":", ",", "self", ".", "ignore_prefix_size", ":", "]", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "                ", "lprobs", "=", "lprobs", "[", "self", ".", "ignore_prefix_size", ":", ",", ":", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "target", "=", "target", "[", "self", ".", "ignore_prefix_size", ":", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "", "", "lprobs", "=", "lprobs", ".", "view", "(", "-", "1", ",", "lprobs", ".", "size", "(", "-", "1", ")", ")", "\n", "target", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "loss", ",", "nll_loss", "=", "label_smoothed_nll_loss", "(", "\n", "lprobs", ",", "\n", "target", ",", "\n", "self", ".", "eps", ",", "\n", "ignore_index", "=", "self", ".", "padding_idx", ",", "\n", "reduce", "=", "reduce", ",", "\n", ")", "\n", "return", "loss", ",", "nll_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.multitask_crossentropy_with_contrastive_with_extra_mt.MultiTaskCrossEntropyWithContrastiveWithExtraMT.reduce_metrics": [[161, 207], ["sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.utils.item", "sum", "fairseq.metrics.log_scalar", "fairseq.utils.item", "fairseq.metrics.log_scalar", "fairseq.metrics.log_derived", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "math.log", "math.log", "math.log", "math.log", "math.log", "sum", "log.get", "log.get", "round", "float"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log"], ["", "@", "classmethod", "\n", "def", "reduce_metrics", "(", "cls", ",", "logging_outputs", ")", "->", "None", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "loss_sum", "=", "sum", "(", "log", ".", "get", "(", "\"loss\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "nll_loss_sum", "=", "sum", "(", "log", ".", "get", "(", "\"nll_loss\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "contrastive_loss_sum", "=", "sum", "(", "log", ".", "get", "(", "\"contrastive_loss\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "target_ntokens", "=", "sum", "(", "log", ".", "get", "(", "\"target_ntokens\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "source_ntokens", "=", "sum", "(", "log", ".", "get", "(", "\"source_ntokens\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "target_ntokens_mt", "=", "sum", "(", "log", ".", "get", "(", "\"target_ntokens_mt\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "target_ntokens_st", "=", "sum", "(", "log", ".", "get", "(", "\"target_ntokens_st\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "ntokens", "=", "sum", "(", "log", ".", "get", "(", "\"ntokens\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "nsentences", "=", "sum", "(", "log", ".", "get", "(", "\"nsentences\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "mt_nsentences", "=", "sum", "(", "log", ".", "get", "(", "\"mt_nsentences\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "st_nsentences", "=", "sum", "(", "log", ".", "get", "(", "\"st_nsentences\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "sample_size", "=", "sum", "(", "log", ".", "get", "(", "\"sample_size\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "\n", "nll_loss_sum_asr", "=", "sum", "(", "log", ".", "get", "(", "\"nll_loss_asr\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "nll_loss_sum_mt", "=", "sum", "(", "log", ".", "get", "(", "\"nll_loss_mt\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "\n", "metrics", ".", "log_scalar", "(", "\"loss\"", ",", "\n", "loss_sum", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", ",", "sample_size", ",", "round", "=", "3", ")", "\n", "metrics", ".", "log_scalar", "(", "\"nll_loss\"", ",", "\n", "nll_loss_sum", "/", "target_ntokens_st", "/", "math", ".", "log", "(", "2", ")", ",", "target_ntokens_st", ",", "round", "=", "3", ")", "\n", "metrics", ".", "log_scalar", "(", "\"contrasitve_loss\"", ",", "\n", "contrastive_loss_sum", "/", "st_nsentences", "/", "math", ".", "log", "(", "2", ")", ",", "st_nsentences", ",", "round", "=", "3", ")", "\n", "metrics", ".", "log_scalar", "(", "\"nll_loss_asr\"", ",", "\n", "nll_loss_sum_asr", "/", "source_ntokens", "/", "math", ".", "log", "(", "2", ")", ",", "source_ntokens", ",", "round", "=", "3", ")", "\n", "metrics", ".", "log_scalar", "(", "\"nll_loss_mt\"", ",", "\n", "nll_loss_sum_mt", "/", "target_ntokens", "/", "math", ".", "log", "(", "2", ")", ",", "target_ntokens", ",", "round", "=", "3", ")", "\n", "metrics", ".", "log_scalar", "(", "\"bsz_st\"", ",", "st_nsentences", ",", "priority", "=", "190", ",", "round", "=", "1", ")", "\n", "metrics", ".", "log_scalar", "(", "\"bsz_mt\"", ",", "mt_nsentences", ",", "priority", "=", "190", ",", "round", "=", "1", ")", "\n", "\n", "total", "=", "utils", ".", "item", "(", "sum", "(", "log", ".", "get", "(", "\"total\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", ")", "\n", "if", "total", ">", "0", ":", "\n", "            ", "metrics", ".", "log_scalar", "(", "\"total\"", ",", "total", ")", "\n", "n_correct", "=", "utils", ".", "item", "(", "\n", "sum", "(", "log", ".", "get", "(", "\"n_correct\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", ")", "\n", "metrics", ".", "log_scalar", "(", "\"n_correct\"", ",", "n_correct", ")", "\n", "metrics", ".", "log_derived", "(", "\n", "\"accuracy\"", ",", "\n", "lambda", "meters", ":", "round", "(", "\n", "meters", "[", "\"n_correct\"", "]", ".", "sum", "*", "100.0", "/", "meters", "[", "\"total\"", "]", ".", "sum", ",", "3", "\n", ")", "\n", "if", "meters", "[", "\"total\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", ""]], "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.__init__": [[35, 48], ["fairseq.criterions.FairseqCriterion.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "task", ",", "\n", "sentence_avg", ",", "\n", "label_smoothing", ",", "\n", "ignore_prefix_size", "=", "0", ",", "\n", "report_accuracy", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "task", ")", "\n", "self", ".", "sentence_avg", "=", "sentence_avg", "\n", "self", ".", "eps", "=", "label_smoothing", "\n", "self", ".", "ignore_prefix_size", "=", "ignore_prefix_size", "\n", "self", ".", "report_accuracy", "=", "report_accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.add_args": [[49, 59], ["parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add criterion-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--label-smoothing'", ",", "default", "=", "0.", ",", "type", "=", "float", ",", "metavar", "=", "'D'", ",", "\n", "help", "=", "'epsilon for label smoothing, 0 means no label smoothing'", ")", "\n", "parser", ".", "add_argument", "(", "'--report-accuracy'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'report accuracy metric'", ")", "\n", "parser", ".", "add_argument", "(", "'--ignore-prefix-size'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "'Ignore first N tokens'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.forward": [[61, 101], ["label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.compute_loss", "model", "sample[].size", "label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.compute_accuracy", "fairseq.utils.item", "fairseq.utils.item", "model", "len", "sample[].size", "sample[].size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.compute_loss", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.compute_accuracy", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "forward", "(", "self", ",", "model", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "\"\"\"Compute the loss for the given sample.\n\n        Returns a tuple with three elements:\n        1) the loss\n        2) the sample size, which is used as the denominator for the gradient\n        3) logging outputs to display while training\n        \"\"\"", "\n", "try", ":", "\n", "            ", "net_output", "=", "model", "(", "**", "sample", "[", "\"net_input\"", "]", ")", "\n", "", "except", ":", "\n", "            ", "net_output", "=", "model", "(", "**", "sample", "[", "\"net_input\"", "]", ",", "is_text_input", "=", "True", ")", "\n", "", "if", "model", ".", "training", "and", "len", "(", "net_output", ")", ">", "1", ":", "\n", "            ", "net_output", "=", "net_output", "[", "0", "]", "\n", "", "loss", ",", "nll_loss", "=", "self", ".", "compute_loss", "(", "model", ",", "net_output", ",", "sample", ",", "reduce", "=", "reduce", ")", "\n", "# sample_size = (", "\n", "#     sample[\"target\"].size(0) if self.sentence_avg else sample[\"ntokens\"]", "\n", "# )", "\n", "if", "\"ntokens\"", "not", "in", "sample", ":", "\n", "            ", "sample_size", "=", "(", "\n", "sample", "[", "\"target\"", "]", ".", "size", "(", "0", ")", "if", "self", ".", "sentence_avg", "else", "sample", "[", "\"target_ntokens\"", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "sample_size", "=", "(", "\n", "sample", "[", "\"target\"", "]", ".", "size", "(", "0", ")", "if", "self", ".", "sentence_avg", "else", "sample", "[", "\"ntokens\"", "]", "\n", ")", "\n", "\n", "", "logging_output", "=", "{", "\n", "\"loss\"", ":", "loss", ".", "data", ",", "\n", "\"nll_loss\"", ":", "nll_loss", ".", "data", ",", "\n", "# \"ntokens\": sample[\"ntokens\"],", "\n", "\"ntokens\"", ":", "sample", "[", "\"target_ntokens\"", "]", "if", "\"ntokens\"", "not", "in", "sample", "else", "sample", "[", "\"ntokens\"", "]", ",", "\n", "\"nsentences\"", ":", "sample", "[", "\"target\"", "]", ".", "size", "(", "0", ")", ",", "\n", "\"sample_size\"", ":", "sample_size", ",", "\n", "}", "\n", "if", "self", ".", "report_accuracy", ":", "\n", "            ", "n_correct", ",", "total", "=", "self", ".", "compute_accuracy", "(", "model", ",", "net_output", ",", "sample", ")", "\n", "logging_output", "[", "\"n_correct\"", "]", "=", "utils", ".", "item", "(", "n_correct", ".", "data", ")", "\n", "logging_output", "[", "\"total\"", "]", "=", "utils", ".", "item", "(", "total", ".", "data", ")", "\n", "", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.get_lprobs_and_target": [[102, 113], ["model.get_normalized_probs", "model.get_targets", "getattr", "lprobs[].contiguous.view", "target[].contiguous.view", "lprobs[].contiguous", "target[].contiguous", "lprobs[].contiguous", "target[].contiguous", "lprobs[].contiguous.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.get_normalized_probs", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecModel.get_targets", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "get_lprobs_and_target", "(", "self", ",", "model", ",", "net_output", ",", "sample", ")", ":", "\n", "        ", "lprobs", "=", "model", ".", "get_normalized_probs", "(", "net_output", ",", "log_probs", "=", "True", ")", "\n", "target", "=", "model", ".", "get_targets", "(", "sample", ",", "net_output", ")", "\n", "if", "self", ".", "ignore_prefix_size", ">", "0", ":", "\n", "            ", "if", "getattr", "(", "lprobs", ",", "\"batch_first\"", ",", "False", ")", ":", "\n", "                ", "lprobs", "=", "lprobs", "[", ":", ",", "self", ".", "ignore_prefix_size", ":", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "target", "=", "target", "[", ":", ",", "self", ".", "ignore_prefix_size", ":", "]", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "                ", "lprobs", "=", "lprobs", "[", "self", ".", "ignore_prefix_size", ":", ",", ":", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "target", "=", "target", "[", "self", ".", "ignore_prefix_size", ":", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "", "", "return", "lprobs", ".", "view", "(", "-", "1", ",", "lprobs", ".", "size", "(", "-", "1", ")", ")", ",", "target", ".", "view", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.compute_loss": [[114, 124], ["label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.get_lprobs_and_target", "label_smoothed_cross_entropy.label_smoothed_nll_loss"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.get_lprobs_and_target", "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.label_smoothed_nll_loss"], ["", "def", "compute_loss", "(", "self", ",", "model", ",", "net_output", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "lprobs", ",", "target", "=", "self", ".", "get_lprobs_and_target", "(", "model", ",", "net_output", ",", "sample", ")", "\n", "loss", ",", "nll_loss", "=", "label_smoothed_nll_loss", "(", "\n", "lprobs", ",", "\n", "target", ",", "\n", "self", ".", "eps", ",", "\n", "ignore_index", "=", "self", ".", "padding_idx", ",", "\n", "reduce", "=", "reduce", ",", "\n", ")", "\n", "return", "loss", ",", "nll_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.compute_accuracy": [[125, 133], ["label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.get_lprobs_and_target", "target.ne", "torch.sum", "torch.sum", "lprobs.argmax().masked_select().eq", "target.masked_select", "lprobs.argmax().masked_select", "lprobs.argmax"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.get_lprobs_and_target"], ["", "def", "compute_accuracy", "(", "self", ",", "model", ",", "net_output", ",", "sample", ")", ":", "\n", "        ", "lprobs", ",", "target", "=", "self", ".", "get_lprobs_and_target", "(", "model", ",", "net_output", ",", "sample", ")", "\n", "mask", "=", "target", ".", "ne", "(", "self", ".", "padding_idx", ")", "\n", "n_correct", "=", "torch", ".", "sum", "(", "\n", "lprobs", ".", "argmax", "(", "1", ")", ".", "masked_select", "(", "mask", ")", ".", "eq", "(", "target", ".", "masked_select", "(", "mask", ")", ")", "\n", ")", "\n", "total", "=", "torch", ".", "sum", "(", "mask", ")", "\n", "return", "n_correct", ",", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.reduce_metrics": [[134, 166], ["sum", "sum", "sum", "sum", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_derived", "fairseq.utils.item", "sum", "fairseq.metrics.log_scalar", "fairseq.utils.item", "fairseq.metrics.log_scalar", "fairseq.metrics.log_derived", "log.get", "log.get", "log.get", "log.get", "math.log", "math.log", "fairseq.utils.get_perplexity", "sum", "log.get", "log.get", "round", "float"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_perplexity"], ["", "@", "classmethod", "\n", "def", "reduce_metrics", "(", "cls", ",", "logging_outputs", ")", "->", "None", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "loss_sum", "=", "sum", "(", "log", ".", "get", "(", "\"loss\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "nll_loss_sum", "=", "sum", "(", "log", ".", "get", "(", "\"nll_loss\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "ntokens", "=", "sum", "(", "log", ".", "get", "(", "\"ntokens\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "sample_size", "=", "sum", "(", "log", ".", "get", "(", "\"sample_size\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "\n", "metrics", ".", "log_scalar", "(", "\n", "\"loss\"", ",", "loss_sum", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", ",", "sample_size", ",", "round", "=", "3", "\n", ")", "\n", "metrics", ".", "log_scalar", "(", "\n", "\"nll_loss\"", ",", "nll_loss_sum", "/", "ntokens", "/", "math", ".", "log", "(", "2", ")", ",", "ntokens", ",", "round", "=", "3", "\n", ")", "\n", "metrics", ".", "log_derived", "(", "\n", "\"ppl\"", ",", "lambda", "meters", ":", "utils", ".", "get_perplexity", "(", "meters", "[", "\"nll_loss\"", "]", ".", "avg", ")", "\n", ")", "\n", "\n", "total", "=", "utils", ".", "item", "(", "sum", "(", "log", ".", "get", "(", "\"total\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", ")", "\n", "if", "total", ">", "0", ":", "\n", "            ", "metrics", ".", "log_scalar", "(", "\"total\"", ",", "total", ")", "\n", "n_correct", "=", "utils", ".", "item", "(", "\n", "sum", "(", "log", ".", "get", "(", "\"n_correct\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", ")", "\n", "metrics", ".", "log_scalar", "(", "\"n_correct\"", ",", "n_correct", ")", "\n", "metrics", ".", "log_derived", "(", "\n", "\"accuracy\"", ",", "\n", "lambda", "meters", ":", "round", "(", "\n", "meters", "[", "\"n_correct\"", "]", ".", "sum", "*", "100.0", "/", "meters", "[", "\"total\"", "]", ".", "sum", ",", "3", "\n", ")", "\n", "if", "meters", "[", "\"total\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.logging_outputs_can_be_summed": [[168, 176], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "logging_outputs_can_be_summed", "(", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Whether the logging outputs returned by `forward` can be summed\n        across workers prior to calling `reduce_metrics`. Setting this\n        to True will improves distributed training speed.\n        \"\"\"", "\n", "return", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.label_smoothed_nll_loss": [[13, 31], ["target.unsqueeze.dim", "target.unsqueeze.unsqueeze", "lprobs.gather", "lprobs.sum", "target.unsqueeze.eq", "nll_loss.sum.masked_fill_", "smooth_loss.sum.masked_fill_", "nll_loss.sum.squeeze", "smooth_loss.sum.squeeze", "nll_loss.sum.sum", "smooth_loss.sum.sum", "lprobs.size", "lprobs.dim"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["def", "label_smoothed_nll_loss", "(", "lprobs", ",", "target", ",", "epsilon", ",", "ignore_index", "=", "None", ",", "reduce", "=", "True", ")", ":", "\n", "    ", "if", "target", ".", "dim", "(", ")", "==", "lprobs", ".", "dim", "(", ")", "-", "1", ":", "\n", "        ", "target", "=", "target", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "nll_loss", "=", "-", "lprobs", ".", "gather", "(", "dim", "=", "-", "1", ",", "index", "=", "target", ")", "\n", "smooth_loss", "=", "-", "lprobs", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "if", "ignore_index", "is", "not", "None", ":", "\n", "        ", "pad_mask", "=", "target", ".", "eq", "(", "ignore_index", ")", "\n", "nll_loss", ".", "masked_fill_", "(", "pad_mask", ",", "0.0", ")", "\n", "smooth_loss", ".", "masked_fill_", "(", "pad_mask", ",", "0.0", ")", "\n", "", "else", ":", "\n", "        ", "nll_loss", "=", "nll_loss", ".", "squeeze", "(", "-", "1", ")", "\n", "smooth_loss", "=", "smooth_loss", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "reduce", ":", "\n", "        ", "nll_loss", "=", "nll_loss", ".", "sum", "(", ")", "\n", "smooth_loss", "=", "smooth_loss", ".", "sum", "(", ")", "\n", "", "eps_i", "=", "epsilon", "/", "lprobs", ".", "size", "(", "-", "1", ")", "\n", "loss", "=", "(", "1.0", "-", "epsilon", ")", "*", "nll_loss", "+", "eps_i", "*", "smooth_loss", "\n", "return", "loss", ",", "nll_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.masked_lm.MaskedLmLoss.__init__": [[20, 23], ["fairseq.criterions.FairseqCriterion.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["SortDataset", ",", "\n", "TokenBlockDataset", ",", "\n", "data_utils", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.masked_lm.MaskedLmLoss.forward": [[24, 70], ["sample[].ne", "torch.where.int().sum", "torch.where.int().sum", "model.get_targets", "fairseq.modules.cross_entropy", "model", "logits.view", "model.get_targets.view", "torch.where.int", "torch.where.int", "torch.device", "torch.device", "torch.device", "torch.device", "torch.where", "torch.where", "torch.where", "torch.where", "logits.size", "torch.where.any", "torch.where.any", "torch.where.any", "torch.where.any", "torch.where.new", "torch.where.new"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecModel.get_targets", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.device", "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.device", "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.device", "home.repos.pwc.inspect_result.reneeye_const.roberta.hub_interface.RobertaHubInterface.device", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["from", "fairseq", ".", "data", ".", "encoders", ".", "utils", "import", "get_whole_word_mask", "\n", "from", "fairseq", ".", "data", ".", "shorten_dataset", "import", "maybe_shorten_dataset", "\n", "from", "fairseq", ".", "tasks", "import", "LegacyFairseqTask", ",", "register_task", "\n", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "\n", "@", "register_task", "(", "\"masked_lm\"", ")", "\n", "class", "MaskedLMTask", "(", "LegacyFairseqTask", ")", ":", "\n", "    ", "\"\"\"Task for training masked language models (e.g., BERT, RoBERTa).\"\"\"", "\n", "\n", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "parser", ".", "add_argument", "(", "\n", "\"data\"", ",", "\n", "help", "=", "\"colon separated path to data directories list, \\\n                            will be iterated upon during epochs in round-robin manner\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--sample-break-mode\"", ",", "\n", "default", "=", "\"complete\"", ",", "\n", "choices", "=", "[", "\"none\"", ",", "\"complete\"", ",", "\"complete_doc\"", ",", "\"eos\"", "]", ",", "\n", "help", "=", "'If omitted or \"none\", fills each sample with tokens-per-sample '", "\n", "'tokens. If set to \"complete\", splits samples only at the end '", "\n", "\"of sentence, but may include multiple sentences per sample. \"", "\n", "'\"complete_doc\" is similar but respects doc boundaries. '", "\n", "'If set to \"eos\", includes only one sentence per sample.'", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokens-per-sample\"", ",", "\n", "default", "=", "512", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"max number of total tokens over all segments \"", "\n", "\"per sample for BERT dataset\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-prob\"", ",", "\n", "default", "=", "0.15", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"probability of replacing a token with mask\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--leave-unmasked-prob\"", ",", "\n", "default", "=", "0.1", ",", "\n", "type", "=", "float", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.masked_lm.MaskedLmLoss.reduce_metrics": [[71, 82], ["sum", "sum", "fairseq.metrics.log_scalar", "fairseq.metrics.log_derived", "log.get", "log.get", "math.log", "fairseq.utils.get_perplexity"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_perplexity"], ["help", "=", "\"probability that a masked token is unmasked\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--random-token-prob\"", ",", "\n", "default", "=", "0.1", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"probability of replacing a token with a random token\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--freq-weighted-replacement\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.masked_lm.MaskedLmLoss.logging_outputs_can_be_summed": [[84, 92], ["None"], "methods", ["None"], [")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask-whole-words\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"mask whole words; you may also want to set --bpe\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--shorten-method\"", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.nat_loss.LabelSmoothedDualImitationCriterion.__init__": [[17, 20], ["fairseq.criterions.FairseqCriterion.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "task", ",", "label_smoothing", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "task", ")", "\n", "self", ".", "label_smoothing", "=", "label_smoothing", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.nat_loss.LabelSmoothedDualImitationCriterion.add_args": [[21, 30], ["parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add criterion-specific arguments to the parser.\"\"\"", "\n", "parser", ".", "add_argument", "(", "\n", "\"--label-smoothing\"", ",", "\n", "default", "=", "0.0", ",", "\n", "type", "=", "float", ",", "\n", "metavar", "=", "\"D\"", ",", "\n", "help", "=", "\"epsilon for label smoothing, 0 means no label smoothing\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.nat_loss.LabelSmoothedDualImitationCriterion._compute_loss": [[32, 76], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.log_softmax", "torch.log_softmax", "nat_loss.LabelSmoothedDualImitationCriterion._compute_loss.mean_ds"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax"], ["", "def", "_compute_loss", "(", "\n", "self", ",", "outputs", ",", "targets", ",", "masks", "=", "None", ",", "label_smoothing", "=", "0.0", ",", "name", "=", "\"loss\"", ",", "factor", "=", "1.0", "\n", ")", ":", "\n", "        ", "\"\"\"\n        outputs: batch x len x d_model\n        targets: batch x len\n        masks:   batch x len\n\n        policy_logprob: if there is some policy\n            depends on the likelihood score as rewards.\n        \"\"\"", "\n", "\n", "def", "mean_ds", "(", "x", ":", "Tensor", ",", "dim", "=", "None", ")", "->", "Tensor", ":", "\n", "            ", "return", "(", "\n", "x", ".", "float", "(", ")", ".", "mean", "(", ")", ".", "type_as", "(", "x", ")", "\n", "if", "dim", "is", "None", "\n", "else", "x", ".", "float", "(", ")", ".", "mean", "(", "dim", ")", ".", "type_as", "(", "x", ")", "\n", ")", "\n", "\n", "", "if", "masks", "is", "not", "None", ":", "\n", "            ", "outputs", ",", "targets", "=", "outputs", "[", "masks", "]", ",", "targets", "[", "masks", "]", "\n", "\n", "", "if", "masks", "is", "not", "None", "and", "not", "masks", ".", "any", "(", ")", ":", "\n", "            ", "nll_loss", "=", "torch", ".", "tensor", "(", "0", ")", "\n", "loss", "=", "nll_loss", "\n", "", "else", ":", "\n", "            ", "logits", "=", "F", ".", "log_softmax", "(", "outputs", ",", "dim", "=", "-", "1", ")", "\n", "if", "targets", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "losses", "=", "F", ".", "nll_loss", "(", "logits", ",", "targets", ".", "to", "(", "logits", ".", "device", ")", ",", "reduction", "=", "\"none\"", ")", "\n", "\n", "", "else", ":", "# soft-labels", "\n", "                ", "losses", "=", "F", ".", "kl_div", "(", "logits", ",", "targets", ".", "to", "(", "logits", ".", "device", ")", ",", "reduction", "=", "\"none\"", ")", "\n", "losses", "=", "losses", ".", "sum", "(", "-", "1", ")", "\n", "\n", "", "nll_loss", "=", "mean_ds", "(", "losses", ")", "\n", "if", "label_smoothing", ">", "0", ":", "\n", "                ", "loss", "=", "(", "\n", "nll_loss", "*", "(", "1", "-", "label_smoothing", ")", "-", "mean_ds", "(", "logits", ")", "*", "label_smoothing", "\n", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "nll_loss", "\n", "\n", "", "", "loss", "=", "loss", "*", "factor", "\n", "return", "{", "\"name\"", ":", "name", ",", "\"loss\"", ":", "loss", ",", "\"nll_loss\"", ":", "nll_loss", ",", "\"factor\"", ":", "factor", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.nat_loss.LabelSmoothedDualImitationCriterion._custom_loss": [[77, 79], ["None"], "methods", ["None"], ["", "def", "_custom_loss", "(", "self", ",", "loss", ",", "name", "=", "\"loss\"", ",", "factor", "=", "1.0", ")", ":", "\n", "        ", "return", "{", "\"name\"", ":", "name", ",", "\"loss\"", ":", "loss", ",", "\"factor\"", ":", "factor", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.nat_loss.LabelSmoothedDualImitationCriterion.forward": [[80, 143], ["model", "sum", "outputs[].get", "sum", "sum.new_tensor", "outputs[].get", "nat_loss.LabelSmoothedDualImitationCriterion._compute_loss", "nat_loss.LabelSmoothedDualImitationCriterion._custom_loss", "len", "fairseq.utils.item", "outputs[].get", "outputs[].get", "outputs[].get", "outputs[].get", "outputs[].get", "nat_loss.LabelSmoothedDualImitationCriterion.get", "outputs[].get", "outputs[].get"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.reneeye_const.criterions.nat_loss.LabelSmoothedDualImitationCriterion._compute_loss", "home.repos.pwc.inspect_result.reneeye_const.criterions.nat_loss.LabelSmoothedDualImitationCriterion._custom_loss", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "def", "forward", "(", "self", ",", "model", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "\"\"\"Compute the loss for the given sample.\n        Returns a tuple with three elements:\n        1) the loss\n        2) the sample size, which is used as the denominator for the gradient\n        3) logging outputs to display while training\n        \"\"\"", "\n", "nsentences", ",", "ntokens", "=", "sample", "[", "\"nsentences\"", "]", ",", "sample", "[", "\"ntokens\"", "]", "\n", "\n", "# B x T", "\n", "src_tokens", ",", "src_lengths", "=", "(", "\n", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", ",", "\n", "sample", "[", "\"net_input\"", "]", "[", "\"src_lengths\"", "]", ",", "\n", ")", "\n", "tgt_tokens", ",", "prev_output_tokens", "=", "sample", "[", "\"target\"", "]", ",", "sample", "[", "\"prev_target\"", "]", "\n", "\n", "outputs", "=", "model", "(", "src_tokens", ",", "src_lengths", ",", "prev_output_tokens", ",", "tgt_tokens", ")", "\n", "losses", ",", "nll_loss", "=", "[", "]", ",", "[", "]", "\n", "\n", "for", "obj", "in", "outputs", ":", "\n", "            ", "if", "outputs", "[", "obj", "]", ".", "get", "(", "\"loss\"", ",", "None", ")", "is", "None", ":", "\n", "                ", "_losses", "=", "self", ".", "_compute_loss", "(", "\n", "outputs", "[", "obj", "]", ".", "get", "(", "\"out\"", ")", ",", "\n", "outputs", "[", "obj", "]", ".", "get", "(", "\"tgt\"", ")", ",", "\n", "outputs", "[", "obj", "]", ".", "get", "(", "\"mask\"", ",", "None", ")", ",", "\n", "outputs", "[", "obj", "]", ".", "get", "(", "\"ls\"", ",", "0.0", ")", ",", "\n", "name", "=", "obj", "+", "\"-loss\"", ",", "\n", "factor", "=", "outputs", "[", "obj", "]", ".", "get", "(", "\"factor\"", ",", "1.0", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "_losses", "=", "self", ".", "_custom_loss", "(", "\n", "outputs", "[", "obj", "]", ".", "get", "(", "\"loss\"", ")", ",", "\n", "name", "=", "obj", "+", "\"-loss\"", ",", "\n", "factor", "=", "outputs", "[", "obj", "]", ".", "get", "(", "\"factor\"", ",", "1.0", ")", ",", "\n", ")", "\n", "\n", "", "losses", "+=", "[", "_losses", "]", "\n", "if", "outputs", "[", "obj", "]", ".", "get", "(", "\"nll_loss\"", ",", "False", ")", ":", "\n", "                ", "nll_loss", "+=", "[", "_losses", ".", "get", "(", "\"nll_loss\"", ",", "0.0", ")", "]", "\n", "\n", "", "", "loss", "=", "sum", "(", "l", "[", "\"loss\"", "]", "for", "l", "in", "losses", ")", "\n", "nll_loss", "=", "sum", "(", "l", "for", "l", "in", "nll_loss", ")", "if", "len", "(", "nll_loss", ")", ">", "0", "else", "loss", ".", "new_tensor", "(", "0", ")", "\n", "\n", "# NOTE:", "\n", "# we don't need to use sample_size as denominator for the gradient", "\n", "# here sample_size is just used for logging", "\n", "sample_size", "=", "1", "\n", "logging_output", "=", "{", "\n", "\"loss\"", ":", "loss", ".", "data", ",", "\n", "\"nll_loss\"", ":", "nll_loss", ".", "data", ",", "\n", "\"ntokens\"", ":", "ntokens", ",", "\n", "\"nsentences\"", ":", "nsentences", ",", "\n", "\"sample_size\"", ":", "sample_size", ",", "\n", "}", "\n", "\n", "for", "l", "in", "losses", ":", "\n", "            ", "logging_output", "[", "l", "[", "\"name\"", "]", "]", "=", "(", "\n", "utils", ".", "item", "(", "l", "[", "\"loss\"", "]", ".", "data", "/", "l", "[", "\"factor\"", "]", ")", "\n", "if", "reduce", "\n", "else", "l", "[", "[", "\"loss\"", "]", "]", ".", "data", "/", "l", "[", "\"factor\"", "]", "\n", ")", "\n", "\n", "", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.nat_loss.LabelSmoothedDualImitationCriterion.reduce_metrics": [[144, 171], ["fairseq.utils.item", "fairseq.utils.item", "fairseq.utils.item", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_derived", "sum", "sum", "sum", "math.log", "math.log", "fairseq.utils.get_perplexity", "sum", "fairseq.metrics.log_scalar", "log.get", "log.get", "log.get", "log.get", "math.log"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_perplexity", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log"], ["", "@", "staticmethod", "\n", "def", "reduce_metrics", "(", "logging_outputs", ")", "->", "None", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "sample_size", "=", "utils", ".", "item", "(", "\n", "sum", "(", "log", ".", "get", "(", "\"sample_size\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", ")", "\n", "loss", "=", "utils", ".", "item", "(", "sum", "(", "log", ".", "get", "(", "\"loss\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", ")", "\n", "nll_loss", "=", "utils", ".", "item", "(", "sum", "(", "log", ".", "get", "(", "\"nll_loss\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", ")", "\n", "\n", "metrics", ".", "log_scalar", "(", "\n", "\"loss\"", ",", "loss", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", ",", "sample_size", ",", "round", "=", "3", "\n", ")", "\n", "metrics", ".", "log_scalar", "(", "\n", "\"nll_loss\"", ",", "nll_loss", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", ",", "sample_size", ",", "round", "=", "3", "\n", ")", "\n", "metrics", ".", "log_derived", "(", "\n", "\"ppl\"", ",", "lambda", "meters", ":", "utils", ".", "get_perplexity", "(", "meters", "[", "\"loss\"", "]", ".", "avg", ")", "\n", ")", "\n", "\n", "for", "key", "in", "logging_outputs", "[", "0", "]", ":", "\n", "            ", "if", "key", "[", "-", "5", ":", "]", "==", "\"-loss\"", ":", "\n", "                ", "val", "=", "sum", "(", "log", ".", "get", "(", "key", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\n", "key", "[", ":", "-", "5", "]", ",", "\n", "val", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", "if", "sample_size", ">", "0", "else", "0.0", ",", "\n", "sample_size", ",", "\n", "round", "=", "3", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.nat_loss.LabelSmoothedDualImitationCriterion.logging_outputs_can_be_summed": [[173, 181], ["None"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "logging_outputs_can_be_summed", "(", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Whether the logging outputs returned by `forward` can be summed\n        across workers prior to calling `reduce_metrics`. Setting this\n        to True will improves distributed training speed.\n        \"\"\"", "\n", "return", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.criterions.ctc.CtcCriterion.__init__": [[67, 104], ["fairseq.criterions.FairseqCriterion.__init__", "task.target_dictionary.bos", "task.target_dictionary.pad", "task.target_dictionary.eos", "eval", "argparse.Namespace", "min", "min", "W2lKenLMDecoder", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ":", "CtcCriterionConfig", ",", "task", ":", "FairseqTask", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "task", ")", "\n", "self", ".", "blank_idx", "=", "task", ".", "target_dictionary", ".", "bos", "(", ")", "\n", "self", ".", "pad_idx", "=", "task", ".", "target_dictionary", ".", "pad", "(", ")", "\n", "self", ".", "eos_idx", "=", "task", ".", "target_dictionary", ".", "eos", "(", ")", "\n", "self", ".", "post_process", "=", "cfg", ".", "post_process", "\n", "\n", "if", "cfg", ".", "wer_args", "is", "not", "None", ":", "\n", "            ", "(", "\n", "cfg", ".", "wer_kenlm_model", ",", "\n", "cfg", ".", "wer_lexicon", ",", "\n", "cfg", ".", "wer_lm_weight", ",", "\n", "cfg", ".", "wer_word_score", ",", "\n", ")", "=", "eval", "(", "cfg", ".", "wer_args", ")", "\n", "\n", "", "if", "cfg", ".", "wer_kenlm_model", "is", "not", "None", ":", "\n", "            ", "from", "examples", ".", "speech_recognition", ".", "w2l_decoder", "import", "W2lKenLMDecoder", "\n", "\n", "dec_args", "=", "Namespace", "(", ")", "\n", "dec_args", ".", "nbest", "=", "1", "\n", "dec_args", ".", "criterion", "=", "\"ctc\"", "\n", "dec_args", ".", "kenlm_model", "=", "cfg", ".", "wer_kenlm_model", "\n", "dec_args", ".", "lexicon", "=", "cfg", ".", "wer_lexicon", "\n", "dec_args", ".", "beam", "=", "50", "\n", "dec_args", ".", "beam_size_token", "=", "min", "(", "50", ",", "len", "(", "task", ".", "target_dictionary", ")", ")", "\n", "dec_args", ".", "beam_threshold", "=", "min", "(", "50", ",", "len", "(", "task", ".", "target_dictionary", ")", ")", "\n", "dec_args", ".", "lm_weight", "=", "cfg", ".", "wer_lm_weight", "\n", "dec_args", ".", "word_score", "=", "cfg", ".", "wer_word_score", "\n", "dec_args", ".", "unk_weight", "=", "-", "math", ".", "inf", "\n", "dec_args", ".", "sil_weight", "=", "0", "\n", "\n", "self", ".", "w2l_decoder", "=", "W2lKenLMDecoder", "(", "dec_args", ",", "task", ".", "target_dictionary", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "w2l_decoder", "=", "None", "\n", "\n", "", "self", ".", "zero_infinity", "=", "cfg", ".", "zero_infinity", "\n", "self", ".", "sentence_avg", "=", "cfg", ".", "sentence_avg", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.ctc.CtcCriterion.forward": [[105, 214], ["model", "model.get_normalized_probs().contiguous", "sample[].masked_select", "non_padding_mask.long().sum", "torch.backends.cudnn.flags", "torch.backends.cudnn.flags", "torch.backends.cudnn.flags", "torch.backends.cudnn.flags", "torch.ctc_loss", "torch.ctc_loss", "target_lengths.sum().item", "sample[].size", "fairseq.utils.item", "sample[].numel", "model.get_normalized_probs", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model.get_normalized_probs().contiguous.transpose().float().contiguous().cpu", "zip", "non_padding_mask.long", "target_lengths.sum", "lp[].unsqueeze", "ctc.CtcCriterion.task.target_dictionary.string", "targ.tolist", "lp[].unsqueeze.argmax().unique_consecutive", "toks[].tolist", "editdistance.eval", "len", "fairseq.data.data_utils.post_process().split", "ctc.CtcCriterion.task.target_dictionary.string", "fairseq.data.data_utils.post_process().split", "len", "model.get_normalized_probs().contiguous.transpose().float().contiguous", "ctc.CtcCriterion.w2l_decoder.decode", "editdistance.eval", "editdistance.eval", "editdistance.eval", "len", "ctc.CtcCriterion.task.target_dictionary.pad", "ctc.CtcCriterion.task.target_dictionary.eos", "lp[].unsqueeze.argmax", "fairseq.data.data_utils.post_process", "fairseq.data.data_utils.post_process", "model.get_normalized_probs().contiguous.transpose().float", "len", "model.get_normalized_probs().contiguous.transpose"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.get_normalized_probs", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.string", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.post_process", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.post_process"], ["", "def", "forward", "(", "self", ",", "model", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "net_output", "=", "model", "(", "**", "sample", "[", "\"net_input\"", "]", ")", "\n", "lprobs", "=", "model", ".", "get_normalized_probs", "(", "\n", "net_output", ",", "log_probs", "=", "True", "\n", ")", ".", "contiguous", "(", ")", "# (T, B, C) from the encoder", "\n", "\n", "if", "\"src_lengths\"", "in", "sample", "[", "\"net_input\"", "]", ":", "\n", "            ", "input_lengths", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_lengths\"", "]", "\n", "", "else", ":", "\n", "            ", "non_padding_mask", "=", "~", "net_output", "[", "\"padding_mask\"", "]", "\n", "input_lengths", "=", "non_padding_mask", ".", "long", "(", ")", ".", "sum", "(", "-", "1", ")", "\n", "\n", "", "pad_mask", "=", "(", "sample", "[", "\"target\"", "]", "!=", "self", ".", "pad_idx", ")", "&", "(", "\n", "sample", "[", "\"target\"", "]", "!=", "self", ".", "eos_idx", "\n", ")", "\n", "targets_flat", "=", "sample", "[", "\"target\"", "]", ".", "masked_select", "(", "pad_mask", ")", "\n", "target_lengths", "=", "sample", "[", "\"target_lengths\"", "]", "\n", "\n", "with", "torch", ".", "backends", ".", "cudnn", ".", "flags", "(", "enabled", "=", "False", ")", ":", "\n", "            ", "loss", "=", "F", ".", "ctc_loss", "(", "\n", "lprobs", ",", "\n", "targets_flat", ",", "\n", "input_lengths", ",", "\n", "target_lengths", ",", "\n", "blank", "=", "self", ".", "blank_idx", ",", "\n", "reduction", "=", "\"sum\"", ",", "\n", "zero_infinity", "=", "self", ".", "zero_infinity", ",", "\n", ")", "\n", "\n", "", "ntokens", "=", "(", "\n", "sample", "[", "\"ntokens\"", "]", "if", "\"ntokens\"", "in", "sample", "else", "target_lengths", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", ")", "\n", "\n", "sample_size", "=", "sample", "[", "\"target\"", "]", ".", "size", "(", "0", ")", "if", "self", ".", "sentence_avg", "else", "ntokens", "\n", "logging_output", "=", "{", "\n", "\"loss\"", ":", "utils", ".", "item", "(", "loss", ".", "data", ")", ",", "# * sample['ntokens'],", "\n", "\"ntokens\"", ":", "ntokens", ",", "\n", "\"nsentences\"", ":", "sample", "[", "\"id\"", "]", ".", "numel", "(", ")", ",", "\n", "\"sample_size\"", ":", "sample_size", ",", "\n", "}", "\n", "\n", "if", "not", "model", ".", "training", ":", "\n", "            ", "import", "editdistance", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "lprobs_t", "=", "lprobs", ".", "transpose", "(", "0", ",", "1", ")", ".", "float", "(", ")", ".", "contiguous", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "c_err", "=", "0", "\n", "c_len", "=", "0", "\n", "w_errs", "=", "0", "\n", "w_len", "=", "0", "\n", "wv_errs", "=", "0", "\n", "for", "lp", ",", "t", ",", "inp_l", "in", "zip", "(", "\n", "lprobs_t", ",", "\n", "sample", "[", "\"target_label\"", "]", "\n", "if", "\"target_label\"", "in", "sample", "\n", "else", "sample", "[", "\"target\"", "]", ",", "\n", "input_lengths", ",", "\n", ")", ":", "\n", "                    ", "lp", "=", "lp", "[", ":", "inp_l", "]", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "decoded", "=", "None", "\n", "if", "self", ".", "w2l_decoder", "is", "not", "None", ":", "\n", "                        ", "decoded", "=", "self", ".", "w2l_decoder", ".", "decode", "(", "lp", ")", "\n", "if", "len", "(", "decoded", ")", "<", "1", ":", "\n", "                            ", "decoded", "=", "None", "\n", "", "else", ":", "\n", "                            ", "decoded", "=", "decoded", "[", "0", "]", "\n", "if", "len", "(", "decoded", ")", "<", "1", ":", "\n", "                                ", "decoded", "=", "None", "\n", "", "else", ":", "\n", "                                ", "decoded", "=", "decoded", "[", "0", "]", "\n", "\n", "", "", "", "p", "=", "(", "t", "!=", "self", ".", "task", ".", "target_dictionary", ".", "pad", "(", ")", ")", "&", "(", "\n", "t", "!=", "self", ".", "task", ".", "target_dictionary", ".", "eos", "(", ")", "\n", ")", "\n", "targ", "=", "t", "[", "p", "]", "\n", "targ_units", "=", "self", ".", "task", ".", "target_dictionary", ".", "string", "(", "targ", ")", "\n", "targ_units_arr", "=", "targ", ".", "tolist", "(", ")", "\n", "\n", "toks", "=", "lp", ".", "argmax", "(", "dim", "=", "-", "1", ")", ".", "unique_consecutive", "(", ")", "\n", "pred_units_arr", "=", "toks", "[", "toks", "!=", "self", ".", "blank_idx", "]", ".", "tolist", "(", ")", "\n", "\n", "c_err", "+=", "editdistance", ".", "eval", "(", "pred_units_arr", ",", "targ_units_arr", ")", "\n", "c_len", "+=", "len", "(", "targ_units_arr", ")", "\n", "\n", "targ_words", "=", "post_process", "(", "targ_units", ",", "self", ".", "post_process", ")", ".", "split", "(", ")", "\n", "\n", "pred_units", "=", "self", ".", "task", ".", "target_dictionary", ".", "string", "(", "pred_units_arr", ")", "\n", "pred_words_raw", "=", "post_process", "(", "pred_units", ",", "self", ".", "post_process", ")", ".", "split", "(", ")", "\n", "\n", "if", "decoded", "is", "not", "None", "and", "\"words\"", "in", "decoded", ":", "\n", "                        ", "pred_words", "=", "decoded", "[", "\"words\"", "]", "\n", "w_errs", "+=", "editdistance", ".", "eval", "(", "pred_words", ",", "targ_words", ")", "\n", "wv_errs", "+=", "editdistance", ".", "eval", "(", "pred_words_raw", ",", "targ_words", ")", "\n", "", "else", ":", "\n", "                        ", "dist", "=", "editdistance", ".", "eval", "(", "pred_words_raw", ",", "targ_words", ")", "\n", "w_errs", "+=", "dist", "\n", "wv_errs", "+=", "dist", "\n", "\n", "", "w_len", "+=", "len", "(", "targ_words", ")", "\n", "\n", "", "logging_output", "[", "\"wv_errors\"", "]", "=", "wv_errs", "\n", "logging_output", "[", "\"w_errors\"", "]", "=", "w_errs", "\n", "logging_output", "[", "\"w_total\"", "]", "=", "w_len", "\n", "logging_output", "[", "\"c_errors\"", "]", "=", "c_err", "\n", "logging_output", "[", "\"c_total\"", "]", "=", "c_len", "\n", "\n", "", "", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.ctc.CtcCriterion.reduce_metrics": [[215, 274], ["fairseq.utils.item", "fairseq.utils.item", "fairseq.utils.item", "fairseq.utils.item", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "sum", "sum", "sum", "sum", "fairseq.metrics.log_scalar", "fairseq.metrics.log_derived", "fairseq.metrics.log_derived", "fairseq.metrics.log_derived", "math.log", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "math.log", "fairseq.logging.meters.safe_round", "float", "fairseq.logging.meters.safe_round", "float", "fairseq.logging.meters.safe_round", "float"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.safe_round", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.safe_round", "home.repos.pwc.inspect_result.reneeye_const.logging.meters.safe_round"], ["", "@", "staticmethod", "\n", "def", "reduce_metrics", "(", "logging_outputs", ")", "->", "None", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "\n", "loss_sum", "=", "utils", ".", "item", "(", "sum", "(", "log", ".", "get", "(", "\"loss\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", ")", "\n", "ntokens", "=", "utils", ".", "item", "(", "sum", "(", "log", ".", "get", "(", "\"ntokens\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", ")", "\n", "nsentences", "=", "utils", ".", "item", "(", "\n", "sum", "(", "log", ".", "get", "(", "\"nsentences\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", ")", "\n", "sample_size", "=", "utils", ".", "item", "(", "\n", "sum", "(", "log", ".", "get", "(", "\"sample_size\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", ")", "\n", "\n", "metrics", ".", "log_scalar", "(", "\n", "\"loss\"", ",", "loss_sum", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", ",", "sample_size", ",", "round", "=", "3", "\n", ")", "\n", "metrics", ".", "log_scalar", "(", "\"ntokens\"", ",", "ntokens", ")", "\n", "metrics", ".", "log_scalar", "(", "\"nsentences\"", ",", "nsentences", ")", "\n", "if", "sample_size", "!=", "ntokens", ":", "\n", "            ", "metrics", ".", "log_scalar", "(", "\n", "\"nll_loss\"", ",", "loss_sum", "/", "ntokens", "/", "math", ".", "log", "(", "2", ")", ",", "ntokens", ",", "round", "=", "3", "\n", ")", "\n", "\n", "", "c_errors", "=", "sum", "(", "log", ".", "get", "(", "\"c_errors\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_c_errors\"", ",", "c_errors", ")", "\n", "c_total", "=", "sum", "(", "log", ".", "get", "(", "\"c_total\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_c_total\"", ",", "c_total", ")", "\n", "w_errors", "=", "sum", "(", "log", ".", "get", "(", "\"w_errors\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_w_errors\"", ",", "w_errors", ")", "\n", "wv_errors", "=", "sum", "(", "log", ".", "get", "(", "\"wv_errors\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_wv_errors\"", ",", "wv_errors", ")", "\n", "w_total", "=", "sum", "(", "log", ".", "get", "(", "\"w_total\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "metrics", ".", "log_scalar", "(", "\"_w_total\"", ",", "w_total", ")", "\n", "\n", "if", "c_total", ">", "0", ":", "\n", "            ", "metrics", ".", "log_derived", "(", "\n", "\"uer\"", ",", "\n", "lambda", "meters", ":", "safe_round", "(", "\n", "meters", "[", "\"_c_errors\"", "]", ".", "sum", "*", "100.0", "/", "meters", "[", "\"_c_total\"", "]", ".", "sum", ",", "3", "\n", ")", "\n", "if", "meters", "[", "\"_c_total\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", "\n", "", "if", "w_total", ">", "0", ":", "\n", "            ", "metrics", ".", "log_derived", "(", "\n", "\"wer\"", ",", "\n", "lambda", "meters", ":", "safe_round", "(", "\n", "meters", "[", "\"_w_errors\"", "]", ".", "sum", "*", "100.0", "/", "meters", "[", "\"_w_total\"", "]", ".", "sum", ",", "3", "\n", ")", "\n", "if", "meters", "[", "\"_w_total\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", "\n", "metrics", ".", "log_derived", "(", "\n", "\"raw_wer\"", ",", "\n", "lambda", "meters", ":", "safe_round", "(", "\n", "meters", "[", "\"_wv_errors\"", "]", ".", "sum", "*", "100.0", "/", "meters", "[", "\"_w_total\"", "]", ".", "sum", ",", "3", "\n", ")", "\n", "if", "meters", "[", "\"_w_total\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.ctc.CtcCriterion.logging_outputs_can_be_summed": [[276, 284], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "logging_outputs_can_be_summed", "(", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Whether the logging outputs returned by `forward` can be summed\n        across workers prior to calling `reduce_metrics`. Setting this\n        to True will improves distributed training speed.\n        \"\"\"", "\n", "return", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.criterions.sentence_ranking.SentenceRankingCriterion.__init__": [[16, 24], ["fairseq.criterions.FairseqCriterion.__init__", "open"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["NumelDataset", ",", "\n", "NumSamplesDataset", ",", "\n", "PrependTokenDataset", ",", "\n", "RawLabelDataset", ",", "\n", "RightPadDataset", ",", "\n", "SortDataset", ",", "\n", "TruncateDataset", ",", "\n", "data_utils", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.sentence_ranking.SentenceRankingCriterion.__del__": [[25, 28], ["sentence_ranking.SentenceRankingCriterion.prediction_h.close"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.close"], ["from", "fairseq", ".", "data", ".", "shorten_dataset", "import", "maybe_shorten_dataset", "\n", "from", "fairseq", ".", "tasks", "import", "LegacyFairseqTask", ",", "register_task", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.sentence_ranking.SentenceRankingCriterion.add_args": [[29, 37], ["parser.add_argument", "parser.add_argument"], "methods", ["None"], ["logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "\n", "@", "register_task", "(", "\"sentence_ranking\"", ")", "\n", "class", "SentenceRankingTask", "(", "LegacyFairseqTask", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.reneeye_const.criterions.sentence_ranking.SentenceRankingCriterion.forward": [[39, 90], ["range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "torch.cat.size", "hasattr", "model", "scores.append", "model.get_targets().view", "torch.log_softmax", "torch.log_softmax", "torch.nll_loss", "torch.nll_loss", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.cat.argmax", "torch.cat.argmax", "enumerate", "zip", "model.get_targets", "sample[].tolist", "torch.cat.argmax.tolist", "targets[].item", "print", "print", "torch.cat.argmax", "torch.cat.argmax"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecModel.get_targets", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print"], ["\n", "\n", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "parser", ".", "add_argument", "(", "\"data\"", ",", "metavar", "=", "\"FILE\"", ",", "help", "=", "\"file prefix for data\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num-classes\"", ",", "type", "=", "int", ",", "help", "=", "\"number of sentences to be ranked\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--init-token\"", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"add token at the beginning of each batch item\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--separator-token\"", ",", "type", "=", "int", ",", "help", "=", "\"add separator token between inputs\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--no-shuffle\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--shorten-method\"", ",", "\n", "default", "=", "\"none\"", ",", "\n", "choices", "=", "[", "\"none\"", ",", "\"truncate\"", ",", "\"random_crop\"", "]", ",", "\n", "help", "=", "\"if not none, shorten sequences that exceed --tokens-per-sample\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--shorten-data-split-list\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "help", "=", "\"comma-separated list of dataset splits to apply shortening to, \"", "\n", "'e.g., \"train,valid\" (default: all dataset splits)'", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max-option-length\"", ",", "type", "=", "int", ",", "help", "=", "\"max length for each option\"", "\n", ")", "\n", "\n", "", "def", "__init__", "(", "self", ",", "args", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "\n", "", "@", "classmethod", "\n", "def", "load_dictionary", "(", "cls", ",", "args", ",", "filename", ",", "source", "=", "True", ")", ":", "\n", "        ", "\"\"\"Load the dictionary from the filename\n\n        Args:\n            filename (str): the filename\n        \"\"\"", "\n", "dictionary", "=", "Dictionary", ".", "load", "(", "filename", ")", "\n", "dictionary", ".", "add_symbol", "(", "\"<mask>\"", ")", "\n", "return", "dictionary", "\n", "\n", "", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "(", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.sentence_ranking.SentenceRankingCriterion.reduce_metrics": [[91, 111], ["sum", "sum", "sum", "sum", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "log.get", "log.get", "log.get", "log.get", "math.log", "len", "math.log", "log.get"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log"], ["args", ".", "criterion", "==", "\"sentence_ranking\"", "\n", ")", ",", "\"Must set --criterion=sentence_ranking\"", "\n", "\n", "# load data dictionary", "\n", "data_dict", "=", "cls", ".", "load_dictionary", "(", "\n", "args", ",", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "data", ",", "\"input0\"", ",", "\"dict.txt\"", ")", ",", "\n", "source", "=", "True", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"[input] dictionary: {} types\"", ".", "format", "(", "len", "(", "data_dict", ")", ")", ")", "\n", "return", "SentenceRankingTask", "(", "args", ",", "data_dict", ")", "\n", "\n", "", "def", "load_dataset", "(", "self", ",", "split", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split (e.g., train, valid, test).\"\"\"", "\n", "\n", "def", "get_path", "(", "type", ",", "split", ")", ":", "\n", "            ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "data", ",", "type", ",", "split", ")", "\n", "\n", "", "def", "make_dataset", "(", "type", ",", "dictionary", ")", ":", "\n", "            ", "split_path", "=", "get_path", "(", "type", ",", "split", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.sentence_ranking.SentenceRankingCriterion.logging_outputs_can_be_summed": [[113, 121], ["None"], "methods", ["None"], ["split_path", ",", "\n", "self", ".", "source_dictionary", ",", "\n", "self", ".", "args", ".", "dataset_impl", ",", "\n", "combine", "=", "combine", ",", "\n", ")", "\n", "return", "dataset", "\n", "\n", "", "input0", "=", "make_dataset", "(", "\"input0\"", ",", "self", ".", "source_dictionary", ")", "\n", "input_options", "=", "[", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.__init__.build_criterion": [[28, 30], ["build_criterion_"], "function", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.criterions.sentence_prediction.SentencePredictionCriterion.__init__": [[16, 20], ["fairseq.criterions.FairseqCriterion.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["NumelDataset", ",", "\n", "NumSamplesDataset", ",", "\n", "OffsetTokensDataset", ",", "\n", "PrependTokenDataset", ",", "\n", "RawLabelDataset", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.sentence_prediction.SentencePredictionCriterion.add_args": [[21, 27], ["parser.add_argument"], "methods", ["None"], ["RightPadDataset", ",", "\n", "RollDataset", ",", "\n", "SortDataset", ",", "\n", "StripTokenDataset", ",", "\n", "data_utils", ",", "\n", ")", "\n", "from", "fairseq", ".", "data", ".", "shorten_dataset", "import", "maybe_shorten_dataset", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.sentence_prediction.SentencePredictionCriterion.forward": [[29, 69], ["model", "model.get_targets().view", "targets.float.float.numel", "hasattr", "torch.log_softmax", "torch.log_softmax", "torch.nll_loss", "torch.nll_loss", "logits.view().float.view().float.view().float", "targets.float.float.float", "torch.mse_loss", "torch.mse_loss", "logits.view().float.view().float.argmax", "model.get_targets", "logits.view().float.view().float.view"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.wav2vec.wav2vec.Wav2VecModel.get_targets"], ["\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "\n", "@", "register_task", "(", "\"sentence_prediction\"", ")", "\n", "class", "SentencePredictionTask", "(", "LegacyFairseqTask", ")", ":", "\n", "    ", "\"\"\"\n    Sentence (or sentence pair) prediction (classification or regression) task.\n\n    Args:\n        dictionary (Dictionary): the dictionary for the input of the task\n    \"\"\"", "\n", "\n", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "parser", ".", "add_argument", "(", "\"data\"", ",", "metavar", "=", "\"FILE\"", ",", "help", "=", "\"file prefix for data\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num-classes\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "-", "1", ",", "\n", "help", "=", "\"number of classes or regression targets\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--init-token\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"add token at the beginning of each batch item\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--separator-token\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"add separator token between inputs\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--regression-target\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--no-shuffle\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--shorten-method\"", ",", "\n", "default", "=", "\"none\"", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.sentence_prediction.SentencePredictionCriterion.reduce_metrics": [[70, 90], ["sum", "sum", "sum", "sum", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "sum", "fairseq.metrics.log_scalar", "log.get", "log.get", "log.get", "log.get", "math.log", "len", "math.log", "log.get"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log"], ["choices", "=", "[", "\"none\"", ",", "\"truncate\"", ",", "\"random_crop\"", "]", ",", "\n", "help", "=", "\"if not none, shorten sequences that exceed --tokens-per-sample\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--shorten-data-split-list\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "help", "=", "\"comma-separated list of dataset splits to apply shortening to, \"", "\n", "'e.g., \"train,valid\" (default: all dataset splits)'", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--add-prev-output-tokens\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"add prev_output_tokens to sample, used for encoder-decoder arch\"", ",", "\n", ")", "\n", "\n", "", "def", "__init__", "(", "self", ",", "args", ",", "data_dictionary", ",", "label_dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "dictionary", "=", "data_dictionary", "\n", "self", ".", "_label_dictionary", "=", "label_dictionary", "\n", "if", "not", "hasattr", "(", "args", ",", "\"max_positions\"", ")", ":", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.sentence_prediction.SentencePredictionCriterion.logging_outputs_can_be_summed": [[92, 100], ["None"], "methods", ["None"], ["args", ".", "max_source_positions", ",", "\n", "args", ".", "max_target_positions", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_max_positions", "=", "args", ".", "max_positions", "\n", "", "args", ".", "tokens_per_sample", "=", "self", ".", "_max_positions", "\n", "\n", "", "@", "classmethod", "\n", "def", "load_dictionary", "(", "cls", ",", "args", ",", "filename", ",", "source", "=", "True", ")", ":", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.__init__": [[15, 37], ["fairseq.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "task", ",", "\n", "sentence_avg", ",", "\n", "label_smoothing", ",", "\n", "ignore_prefix_size", "=", "0", ",", "\n", "report_accuracy", "=", "False", ",", "\n", "contrastive_weight", "=", "0.0", ",", "\n", "contrastive_temperature", "=", "1.0", ",", "\n", "use_dual_ctr", "=", "False", ",", "\n", "ctr_dropout_rate", "=", "0.0", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "task", ",", "sentence_avg", ",", "label_smoothing", ",", "ignore_prefix_size", ",", "report_accuracy", ")", "\n", "self", ".", "sentence_avg", "=", "sentence_avg", "\n", "self", ".", "eps", "=", "label_smoothing", "\n", "self", ".", "ignore_prefix_size", "=", "ignore_prefix_size", "\n", "self", ".", "report_accuracy", "=", "report_accuracy", "\n", "self", ".", "contrastive_weight", "=", "contrastive_weight", "\n", "self", ".", "contrastive_temperature", "=", "contrastive_temperature", "\n", "\n", "self", ".", "use_dual_ctr", "=", "use_dual_ctr", "\n", "self", ".", "ctr_dropout_rate", "=", "ctr_dropout_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.add_args": [[38, 55], ["fairseq.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.add_args", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add criterion-specific arguments to the parser.\"\"\"", "\n", "LabelSmoothedCrossEntropyCriterion", ".", "add_args", "(", "parser", ")", "\n", "parser", ".", "add_argument", "(", "'--contrastive-weight'", ",", "default", "=", "0.", ",", "type", "=", "float", ",", "\n", "help", "=", "'the weight of contrastive loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--contrastive-temperature'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "'the temperature in the contrastive loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--contrastive-seqlen-type'", ",", "default", "=", "'src_text'", ",", "type", "=", "str", ",", "\n", "choices", "=", "[", "'src_text'", ",", "'transcript'", ",", "\n", "'audio_short'", ",", "'none'", "]", ",", "\n", "help", "=", "'which type of length to times to the contrastive loss'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--use-dual-ctr\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if we want to use dual contrastive loss\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--ctr-dropout-rate\"", ",", "default", "=", "0.", ",", "type", "=", "float", ",", "\n", "help", "=", "'the dropout rate of hidden units'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.forward": [[56, 104], ["model", "label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.compute_contrastive_loss", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.compute_loss", "sample[].size", "sample[].size", "label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.compute_accuracy", "fairseq.utils.item", "fairseq.utils.item", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.compute_contrastive_loss", "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.compute_loss", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy.LabelSmoothedCrossEntropyCriterion.compute_accuracy", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "def", "forward", "(", "self", ",", "model", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "\"\"\"Compute the loss for the given sample.\n\n        Returns a tuple with three elements:\n        1) the loss\n        2) the sample size, which is used as the denominator for the gradient\n        3) logging outputs to display while training\n        \"\"\"", "\n", "_net_output", "=", "model", "(", "**", "sample", "[", "\"net_input\"", "]", ")", "# (x, extra)", "\n", "if", "model", ".", "training", ":", "\n", "            ", "net_output", ",", "encoder_out", "=", "_net_output", "\n", "contrastive_loss", ",", "short_audio_len", "=", "self", ".", "compute_contrastive_loss", "(", "\n", "model", ",", "sample", ",", "encoder_out", ",", "\n", "reduce", "=", "reduce", ",", "return_short_audio_len", "=", "True", "\n", ")", "\n", "", "else", ":", "\n", "            ", "net_output", "=", "_net_output", "\n", "contrastive_loss", ",", "short_audio_len", "=", "torch", ".", "tensor", "(", "0.0", ")", ",", "None", "\n", "", "label_smoothed_nll_loss", ",", "nll_loss", "=", "torch", ".", "tensor", "(", "0.0", ")", ",", "torch", ".", "tensor", "(", "0.0", ")", "\n", "if", "sample", "[", "\"target\"", "]", "is", "not", "None", ":", "# ST triple dataset", "\n", "            ", "label_smoothed_nll_loss", ",", "nll_loss", "=", "self", ".", "compute_loss", "(", "model", ",", "net_output", ",", "sample", ",", "reduce", "=", "reduce", ")", "\n", "", "sample_size", "=", "(", "\n", "sample", "[", "\"target\"", "]", ".", "size", "(", "0", ")", "if", "self", ".", "sentence_avg", "else", "sample", "[", "\"target_ntokens\"", "]", "\n", ")", "\n", "source_ntokens", "=", "sample", "[", "\"source_ntokens\"", "]", "\n", "if", "label_smoothed_nll_loss", "is", "not", "None", ":", "\n", "            ", "loss", "=", "label_smoothed_nll_loss", "+", "self", ".", "contrastive_weight", "*", "contrastive_loss", "\n", "", "else", ":", "\n", "            ", "loss", "=", "contrastive_loss", "\n", "\n", "", "logging_output", "=", "{", "\n", "\"loss\"", ":", "loss", ".", "data", ",", "\n", "\"label_smoothed_nll_loss\"", ":", "label_smoothed_nll_loss", ".", "data", ",", "\n", "\"nll_loss\"", ":", "nll_loss", ".", "data", ",", "\n", "\"contrastive_loss\"", ":", "contrastive_loss", ".", "data", ",", "\n", "\"source_ntokens\"", ":", "source_ntokens", ",", "\n", "\"target_ntokens\"", ":", "sample", "[", "\"target_ntokens\"", "]", ",", "\n", "\"nsentences\"", ":", "sample", "[", "\"target\"", "]", ".", "size", "(", "0", ")", ",", "\n", "\"sample_size\"", ":", "sample_size", ",", "\n", "}", "\n", "if", "nll_loss", "!=", "0", ":", "\n", "            ", "logging_output", "[", "\"ntokens\"", "]", "=", "sample", "[", "\"target_ntokens\"", "]", "\n", "\n", "", "if", "self", ".", "report_accuracy", ":", "\n", "            ", "n_correct", ",", "total", "=", "self", ".", "compute_accuracy", "(", "model", ",", "net_output", ",", "sample", ")", "\n", "logging_output", "[", "\"n_correct\"", "]", "=", "utils", ".", "item", "(", "n_correct", ".", "data", ")", "\n", "logging_output", "[", "\"total\"", "]", "=", "utils", ".", "item", "(", "total", ".", "data", ")", "\n", "", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.get_sequence_hidden": [[105, 119], ["encoder_out.transpose.transpose.transpose", "model.encoder.embedding_text", "encoder_padding_mask.sum().unsqueeze", "encoder_padding_mask.sum", "encoder_padding_mask.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.speech_to_text.xstnet.XSTNetEncoder.embedding_text"], ["", "def", "get_sequence_hidden", "(", "self", ",", "model", ",", "sample", ",", "packed_encoder_out", ",", "\n", "is_text", "=", "False", ",", "return_short_audio_len", "=", "False", ")", ":", "\n", "        ", "short_audio_len", "=", "None", "\n", "if", "is_text", ":", "\n", "            ", "encoder_out", ",", "encoder_padding_mask", "=", "model", ".", "encoder", ".", "embedding_text", "(", "\n", "sample", "[", "\"source\"", "]", ",", "sample", "[", "\"source_lengths\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "encoder_out", "=", "packed_encoder_out", ".", "encoder_embedding", "\n", "encoder_padding_mask", "=", "packed_encoder_out", ".", "encoder_padding_mask", "\n", "short_audio_len", "=", "packed_encoder_out", ".", "output_encoder_lengths", "\n", "", "encoder_out", "=", "encoder_out", ".", "transpose", "(", "0", ",", "1", ")", "# T x B x hid -> B x T x hid", "\n", "encoder_padding_mask", "=", "(", "~", "encoder_padding_mask", ")", ".", "float", "(", ")", "\n", "seq_hidden", "=", "(", "encoder_out", "*", "encoder_padding_mask", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "sum", "(", "dim", "=", "1", ")", "/", "encoder_padding_mask", ".", "sum", "(", "dim", "=", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "return", "seq_hidden", ",", "short_audio_len", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.compute_contrastive_loss": [[120, 143], ["label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.get_sequence_hidden", "label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.get_sequence_hidden", "audio_seq_hidden.size", "torch.cosine_similarity", "torch.cosine_similarity", "audio_seq_hidden.expand", "text_seq_hidden.expand().transpose", "loss.sum.sum.sum", "text_seq_hidden.expand", "torch.nn.LogSoftmax", "torch.nn.LogSoftmax", "torch.nn.LogSoftmax", "torch.nn.LogSoftmax", "torch.nn.LogSoftmax", "torch.nn.LogSoftmax", "torch.nn.LogSoftmax", "torch.nn.LogSoftmax", "torch.nn.LogSoftmax", "torch.nn.LogSoftmax", "torch.nn.LogSoftmax", "torch.nn.LogSoftmax"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.get_sequence_hidden", "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.get_sequence_hidden", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "compute_contrastive_loss", "(", "self", ",", "model", ",", "sample", ",", "encoder_out", ",", "\n", "reduce", "=", "True", ",", "return_short_audio_len", "=", "True", ")", ":", "\n", "        ", "audio_seq_hidden", ",", "short_audio_len", "=", "self", ".", "get_sequence_hidden", "(", "model", ",", "sample", ",", "encoder_out", ",", "\n", "is_text", "=", "False", ",", "\n", "return_short_audio_len", "=", "return_short_audio_len", ")", "# B x h", "\n", "\n", "text_seq_hidden", ",", "_", "=", "self", ".", "get_sequence_hidden", "(", "model", ",", "sample", ",", "encoder_out", ",", "is_text", "=", "True", ")", "# B x h", "\n", "batch_size", ",", "hidden_size", "=", "audio_seq_hidden", ".", "size", "(", ")", "\n", "logits", "=", "F", ".", "cosine_similarity", "(", "audio_seq_hidden", ".", "expand", "(", "(", "batch_size", ",", "batch_size", ",", "hidden_size", ")", ")", ",", "\n", "text_seq_hidden", ".", "expand", "(", "(", "batch_size", ",", "batch_size", ",", "hidden_size", ")", ")", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "dim", "=", "-", "1", ")", "\n", "logits", "/=", "self", ".", "contrastive_temperature", "\n", "\n", "if", "self", ".", "use_dual_ctr", ":", "\n", "            ", "loss_audio", "=", "-", "torch", ".", "nn", ".", "LogSoftmax", "(", "0", ")", "(", "logits", ")", ".", "diag", "(", ")", "\n", "loss_text", "=", "-", "torch", ".", "nn", ".", "LogSoftmax", "(", "1", ")", "(", "logits", ")", ".", "diag", "(", ")", "\n", "loss", "=", "loss_audio", "+", "loss_text", "\n", "", "else", ":", "\n", "            ", "loss", "=", "-", "torch", ".", "nn", ".", "LogSoftmax", "(", "0", ")", "(", "logits", ")", ".", "diag", "(", ")", "\n", "\n", "", "if", "reduce", ":", "\n", "            ", "loss", "=", "loss", ".", "sum", "(", ")", "\n", "", "return", "loss", ",", "short_audio_len", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.label_smoothed_cross_entropy_with_contrastive_loss.LabelSmoothedCrossEntropyWithContrastiveCriterion.reduce_metrics": [[144, 187], ["sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "sum", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_scalar", "fairseq.metrics.log_derived", "fairseq.utils.item", "sum", "fairseq.metrics.log_scalar", "fairseq.utils.item", "fairseq.metrics.log_scalar", "fairseq.metrics.log_derived", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "log.get", "math.log", "math.log", "math.log", "math.log", "fairseq.utils.get_perplexity", "sum", "log.get", "log.get", "round", "float"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_scalar", "home.repos.pwc.inspect_result.reneeye_const.logging.metrics.log_derived", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.log", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.get_perplexity"], ["", "@", "classmethod", "\n", "def", "reduce_metrics", "(", "cls", ",", "logging_outputs", ")", "->", "None", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "loss_sum", "=", "sum", "(", "log", ".", "get", "(", "\"loss\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "label_smoothed_nll_loss_sum", "=", "sum", "(", "log", ".", "get", "(", "\"label_smoothed_nll_loss\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "nll_loss_sum", "=", "sum", "(", "log", ".", "get", "(", "\"nll_loss\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "contrastive_loss_sum", "=", "sum", "(", "log", ".", "get", "(", "\"contrastive_loss\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "target_ntokens", "=", "sum", "(", "log", ".", "get", "(", "\"target_ntokens\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "source_ntokens", "=", "sum", "(", "log", ".", "get", "(", "\"source_ntokens\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "ntokens", "=", "sum", "(", "log", ".", "get", "(", "\"ntokens\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "nsentences", "=", "sum", "(", "log", ".", "get", "(", "\"nsentences\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "sample_size", "=", "sum", "(", "log", ".", "get", "(", "\"sample_size\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "\n", "metrics", ".", "log_scalar", "(", "\n", "\"loss\"", ",", "loss_sum", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", ",", "sample_size", ",", "round", "=", "3", "\n", ")", "\n", "metrics", ".", "log_scalar", "(", "\n", "\"label_smoothed_nll_loss\"", ",", "label_smoothed_nll_loss_sum", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", ",", "sample_size", ",", "round", "=", "3", "\n", ")", "\n", "metrics", ".", "log_scalar", "(", "\n", "\"nll_loss\"", ",", "nll_loss_sum", "/", "target_ntokens", "/", "math", ".", "log", "(", "2", ")", ",", "target_ntokens", ",", "round", "=", "3", "\n", ")", "\n", "metrics", ".", "log_scalar", "(", "\n", "\"contrasitve_loss\"", ",", "contrastive_loss_sum", "/", "nsentences", "/", "math", ".", "log", "(", "2", ")", ",", "nsentences", ",", "round", "=", "3", "\n", ")", "\n", "metrics", ".", "log_derived", "(", "\n", "\"ppl\"", ",", "lambda", "meters", ":", "utils", ".", "get_perplexity", "(", "meters", "[", "\"nll_loss\"", "]", ".", "avg", ")", "\n", ")", "\n", "\n", "total", "=", "utils", ".", "item", "(", "sum", "(", "log", ".", "get", "(", "\"total\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", ")", "\n", "if", "total", ">", "0", ":", "\n", "            ", "metrics", ".", "log_scalar", "(", "\"total\"", ",", "total", ")", "\n", "n_correct", "=", "utils", ".", "item", "(", "\n", "sum", "(", "log", ".", "get", "(", "\"n_correct\"", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", ")", "\n", "metrics", ".", "log_scalar", "(", "\"n_correct\"", ",", "n_correct", ")", "\n", "metrics", ".", "log_derived", "(", "\n", "\"accuracy\"", ",", "\n", "lambda", "meters", ":", "round", "(", "\n", "meters", "[", "\"n_correct\"", "]", ".", "sum", "*", "100.0", "/", "meters", "[", "\"total\"", "]", ".", "sum", ",", "3", "\n", ")", "\n", "if", "meters", "[", "\"total\"", "]", ".", "sum", ">", "0", "\n", "else", "float", "(", "\"nan\"", ")", ",", "\n", ")", ""]], "home.repos.pwc.inspect_result.reneeye_const.criterions.composite_loss.CompositeLoss.__init__": [[16, 19], ["fairseq.criterions.LegacyFairseqCriterion.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "args", ",", "task", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "task", ")", "\n", "self", ".", "underlying_criterion", "=", "args", ".", "underlying_criterion", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.composite_loss.CompositeLoss.add_args": [[20, 26], ["parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add criterion-specific arguments to the parser.\"\"\"", "\n", "# fmt: off", "\n", "parser", ".", "add_argument", "(", "'--underlying-criterion'", ",", "type", "=", "str", ",", "metavar", "=", "'VAL'", ",", "required", "=", "True", ",", "\n", "help", "=", "'underlying criterion to use for the composite loss'", ")", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.composite_loss.CompositeLoss.build_underlying_criterion": [[28, 36], ["task.build_criterion"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.criterions.composite_loss.CompositeLoss.build_criterion"], ["", "@", "staticmethod", "\n", "def", "build_underlying_criterion", "(", "args", ",", "task", ")", ":", "\n", "        ", "saved_criterion", "=", "args", ".", "criterion", "\n", "args", ".", "criterion", "=", "args", ".", "underlying_criterion", "\n", "assert", "saved_criterion", "!=", "args", ".", "underlying_criterion", "\n", "underlying_criterion", "=", "task", ".", "build_criterion", "(", "args", ")", "\n", "args", ".", "criterion", "=", "saved_criterion", "\n", "return", "underlying_criterion", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.criterions.composite_loss.CompositeLoss.build_criterion": [[37, 101], ["composite_loss.CompositeLoss.build_underlying_criterion", "_CompositeLoss", "fairseq.criterions.LegacyFairseqCriterion.__init__", "composite_loss.CompositeLoss.model.get_normalized_probs", "fairseq.criterions.LegacyFairseqCriterion.__init__", "model", "targets[].size", "[].new().float().zero_", "zip", "[].new().float().zero_.div_", "len", "composite_loss.CompositeLoss.build_underlying_criterion", "composite_loss.CompositeLoss.build_underlying_criterion", "FakeModel", "composite_loss.CompositeLoss.underlying_criterion", "len", "fairseq.utils.item", "[].new().float", "[].new"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.criterions.composite_loss.CompositeLoss.build_underlying_criterion", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.get_normalized_probs", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.fairseq.trainer.Trainer.model", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.criterions.composite_loss.CompositeLoss.build_underlying_criterion", "home.repos.pwc.inspect_result.reneeye_const.criterions.composite_loss.CompositeLoss.build_underlying_criterion", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "@", "classmethod", "\n", "def", "build_criterion", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "underlying_criterion", "=", "CompositeLoss", ".", "build_underlying_criterion", "(", "args", ",", "task", ")", "\n", "\n", "class", "FakeModel", "(", "nn", ".", "Module", ")", ":", "\n", "            ", "def", "__init__", "(", "self", ",", "model", ",", "net_out", ",", "target", ")", ":", "\n", "                ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "net_out", "=", "net_out", "\n", "self", ".", "target", "=", "target", "\n", "\n", "", "def", "forward", "(", "self", ",", "**", "unused", ")", ":", "\n", "                ", "return", "self", ".", "net_out", "\n", "\n", "", "def", "get_normalized_probs", "(", "self", ",", "net_output", ",", "log_probs", ",", "sample", "=", "None", ")", ":", "\n", "                ", "return", "self", ".", "model", ".", "get_normalized_probs", "(", "\n", "net_output", ",", "log_probs", ",", "sample", "=", "sample", "\n", ")", "\n", "\n", "", "def", "get_targets", "(", "self", ",", "*", "unused", ")", ":", "\n", "                ", "return", "self", ".", "target", "\n", "\n", "", "@", "property", "\n", "def", "decoder", "(", "self", ")", ":", "\n", "                ", "return", "self", ".", "model", ".", "decoder", "\n", "\n", "", "", "class", "_CompositeLoss", "(", "LegacyFairseqCriterion", ")", ":", "\n", "            ", "def", "__init__", "(", "self", ",", "args", ",", "task", ",", "underlying_criterion", ")", ":", "\n", "                ", "super", "(", ")", ".", "__init__", "(", "args", ",", "task", ")", "\n", "self", ".", "underlying_criterion", "=", "underlying_criterion", "\n", "\n", "", "def", "forward", "(", "self", ",", "model", ",", "sample", ",", "reduce", "=", "True", ")", ":", "\n", "                ", "net_outputs", "=", "model", "(", "**", "sample", "[", "\"net_input\"", "]", ")", "\n", "targets", "=", "sample", "[", "\"target\"", "]", "\n", "\n", "bsz", "=", "targets", "[", "0", "]", ".", "size", "(", "0", ")", "\n", "loss", "=", "net_outputs", "[", "0", "]", "[", "0", "]", ".", "new", "(", "1", "if", "reduce", "else", "bsz", ")", ".", "float", "(", ")", ".", "zero_", "(", ")", "\n", "\n", "sample_size", "=", "0", "\n", "logging_output", "=", "{", "}", "\n", "for", "o", ",", "t", "in", "zip", "(", "net_outputs", "[", "0", "]", ",", "targets", ")", ":", "\n", "                    ", "m", "=", "FakeModel", "(", "model", ",", "(", "o", ",", "net_outputs", "[", "1", "]", ")", ",", "t", ")", "\n", "sample", "[", "\"target\"", "]", "=", "t", "\n", "l", ",", "ss", ",", "logging_output", "=", "self", ".", "underlying_criterion", "(", "m", ",", "sample", ",", "reduce", ")", "\n", "loss", "+=", "l", "\n", "sample_size", "+=", "ss", "\n", "\n", "", "loss", ".", "div_", "(", "len", "(", "targets", ")", ")", "\n", "sample_size", "/=", "len", "(", "targets", ")", "\n", "\n", "logging_output", "[", "\"loss\"", "]", "=", "utils", ".", "item", "(", "loss", ".", "data", ")", "if", "reduce", "else", "loss", ".", "data", "\n", "return", "loss", ",", "sample_size", ",", "logging_output", "\n", "\n", "", "@", "staticmethod", "\n", "def", "aggregate_logging_outputs", "(", "logging_outputs", ")", ":", "\n", "                ", "return", "underlying_criterion", ".", "__class__", ".", "aggregate_logging_outputs", "(", "\n", "logging_outputs", "\n", ")", "\n", "\n", "", "@", "staticmethod", "\n", "def", "reduce_metrics", "(", "logging_outputs", ")", "->", "None", ":", "\n", "                ", "underlying_criterion", ".", "__class__", ".", "reduce_metrics", "(", "logging_outputs", ")", "\n", "\n", "", "", "return", "_CompositeLoss", "(", "args", ",", "task", ",", "underlying_criterion", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_sentences_dataset.ConcatSentencesDataset.__init__": [[12, 18], ["FairseqDataset.__init__", "all", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "datasets", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "datasets", "=", "datasets", "\n", "assert", "all", "(", "\n", "len", "(", "ds", ")", "==", "len", "(", "datasets", "[", "0", "]", ")", "for", "ds", "in", "datasets", "\n", ")", ",", "\"datasets must have the same length\"", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_sentences_dataset.ConcatSentencesDataset.__getitem__": [[19, 21], ["torch.cat"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "torch", ".", "cat", "(", "[", "ds", "[", "index", "]", "for", "ds", "in", "self", ".", "datasets", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_sentences_dataset.ConcatSentencesDataset.__len__": [[22, 24], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "datasets", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_sentences_dataset.ConcatSentencesDataset.collater": [[25, 27], ["concat_sentences_dataset.ConcatSentencesDataset.datasets[].collater"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.collater"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "return", "self", ".", "datasets", "[", "0", "]", ".", "collater", "(", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_sentences_dataset.ConcatSentencesDataset.sizes": [[28, 31], ["sum"], "methods", ["None"], ["", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "return", "sum", "(", "ds", ".", "sizes", "for", "ds", "in", "self", ".", "datasets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_sentences_dataset.ConcatSentencesDataset.num_tokens": [[32, 34], ["sum", "ds.num_tokens"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.num_tokens"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "sum", "(", "ds", ".", "num_tokens", "(", "index", ")", "for", "ds", "in", "self", ".", "datasets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_sentences_dataset.ConcatSentencesDataset.size": [[35, 37], ["sum", "ds.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "sum", "(", "ds", ".", "size", "(", "index", ")", "for", "ds", "in", "self", ".", "datasets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_sentences_dataset.ConcatSentencesDataset.ordered_indices": [[38, 40], ["concat_sentences_dataset.ConcatSentencesDataset.datasets[].ordered_indices"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.ordered_indices"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "datasets", "[", "0", "]", ".", "ordered_indices", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_sentences_dataset.ConcatSentencesDataset.supports_prefetch": [[41, 44], ["any", "getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "any", "(", "getattr", "(", "ds", ",", "\"supports_prefetch\"", ",", "False", ")", "for", "ds", "in", "self", ".", "datasets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_sentences_dataset.ConcatSentencesDataset.prefetch": [[45, 49], ["getattr", "ds.prefetch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "for", "ds", "in", "self", ".", "datasets", ":", "\n", "            ", "if", "getattr", "(", "ds", ",", "\"supports_prefetch\"", ",", "False", ")", ":", "\n", "                ", "ds", ".", "prefetch", "(", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_sentences_dataset.ConcatSentencesDataset.set_epoch": [[50, 55], ["super().set_epoch", "hasattr", "ds.set_epoch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch"], ["", "", "", "def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "super", "(", ")", ".", "set_epoch", "(", "epoch", ")", "\n", "for", "ds", "in", "self", ".", "datasets", ":", "\n", "            ", "if", "hasattr", "(", "ds", ",", "\"set_epoch\"", ")", ":", "\n", "                ", "ds", ".", "set_epoch", "(", "epoch", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.offset_tokens_dataset.OffsetTokensDataset.__init__": [[10, 13], ["BaseWrapperDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "offset", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ")", "\n", "self", ".", "offset", "=", "offset", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.offset_tokens_dataset.OffsetTokensDataset.__getitem__": [[14, 16], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "dataset", "[", "idx", "]", "+", "self", ".", "offset", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.fairseq_dataset.EpochListening.can_reuse_epoch_itr_across_epochs": [[14, 26], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "can_reuse_epoch_itr_across_epochs", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Whether we can reuse the :class:`fairseq.data.EpochBatchIterator` for\n        this dataset across epochs.\n\n        This needs to return ``False`` if the sample sizes can change across\n        epochs, in which case we may need to regenerate batches at each epoch.\n        If your dataset relies in ``set_epoch`` then you should consider setting\n        this to ``False``.\n        \"\"\"", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fairseq_dataset.EpochListening.set_epoch": [[27, 30], ["None"], "methods", ["None"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Will receive the updated epoch number at the beginning of the epoch.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fairseq_dataset.FairseqDataset.__getitem__": [[35, 37], ["None"], "methods", ["None"], ["def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fairseq_dataset.FairseqDataset.__len__": [[38, 40], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fairseq_dataset.FairseqDataset.collater": [[41, 51], ["None"], "methods", ["None"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Merge a list of samples to form a mini-batch.\n\n        Args:\n            samples (List[dict]): samples to collate\n\n        Returns:\n            dict: a mini-batch suitable for forwarding with a Model\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fairseq_dataset.FairseqDataset.num_tokens": [[52, 56], ["None"], "methods", ["None"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return the number of tokens in a sample. This value is used to\n        enforce ``--max-tokens`` during batching.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fairseq_dataset.FairseqDataset.size": [[57, 61], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return an example's size as a float or tuple. This value is used when\n        filtering a dataset with ``--max-positions``.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fairseq_dataset.FairseqDataset.ordered_indices": [[62, 66], ["numpy.arange", "len"], "methods", ["None"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return an ordered list of indices. Batches will be constructed based\n        on this order.\"\"\"", "\n", "return", "np", ".", "arange", "(", "len", "(", "self", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fairseq_dataset.FairseqDataset.supports_prefetch": [[67, 71], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "\"\"\"Whether this dataset supports prefetching.\"\"\"", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fairseq_dataset.FairseqDataset.attr": [[72, 74], ["getattr"], "methods", ["None"], ["", "def", "attr", "(", "self", ",", "attr", ":", "str", ",", "index", ":", "int", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ",", "attr", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fairseq_dataset.FairseqDataset.prefetch": [[75, 78], ["None"], "methods", ["None"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "\"\"\"Prefetch the data required for this epoch.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fairseq_dataset.FairseqDataset.get_batch_shapes": [[79, 95], ["None"], "methods", ["None"], ["", "def", "get_batch_shapes", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a list of valid batch shapes, for example::\n\n            [(8, 512), (16, 256), (32, 128)]\n\n        The first dimension of each tuple is the batch size and can be ``None``\n        to automatically infer the max batch size based on ``--max-tokens``.\n        The second dimension of each tuple is the max supported length as given\n        by :func:`fairseq.data.FairseqDataset.num_tokens`.\n\n        This will be used by :func:`fairseq.data.FairseqDataset.batch_by_size`\n        to restrict batch shapes. This is useful on TPUs to avoid too many\n        dynamic shapes (and recompilations).\n        \"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fairseq_dataset.FairseqDataset.batch_by_size": [[96, 139], ["fairseq_dataset.FairseqDataset.get_batch_shapes", "fairseq.data.data_utils.batch_by_size", "numpy.array", "min", "fairseq_dataset.FairseqDataset.batch_by_size.adjust_bsz"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.language_pair_dataset.LanguagePairDataset.get_batch_shapes", "home.repos.pwc.inspect_result.reneeye_const.data.base_wrapper_dataset.BaseWrapperDataset.batch_by_size"], ["", "def", "batch_by_size", "(", "\n", "self", ",", "\n", "indices", ",", "\n", "max_tokens", "=", "None", ",", "\n", "max_sentences", "=", "None", ",", "\n", "required_batch_size_multiple", "=", "1", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Given an ordered set of indices, return batches according to\n        *max_tokens*, *max_sentences* and *required_batch_size_multiple*.\n        \"\"\"", "\n", "from", "fairseq", ".", "data", "import", "data_utils", "\n", "\n", "fixed_shapes", "=", "self", ".", "get_batch_shapes", "(", ")", "\n", "if", "fixed_shapes", "is", "not", "None", ":", "\n", "\n", "            ", "def", "adjust_bsz", "(", "bsz", ",", "num_tokens", ")", ":", "\n", "                ", "if", "bsz", "is", "None", ":", "\n", "                    ", "assert", "max_tokens", "is", "not", "None", ",", "\"Must specify --max-tokens\"", "\n", "bsz", "=", "max_tokens", "//", "num_tokens", "\n", "", "if", "max_sentences", "is", "not", "None", ":", "\n", "                    ", "bsz", "=", "min", "(", "bsz", ",", "max_sentences", ")", "\n", "", "elif", "(", "\n", "bsz", ">=", "required_batch_size_multiple", "\n", "and", "bsz", "%", "required_batch_size_multiple", "!=", "0", "\n", ")", ":", "\n", "                    ", "bsz", "-=", "bsz", "%", "required_batch_size_multiple", "\n", "", "return", "bsz", "\n", "\n", "", "fixed_shapes", "=", "np", ".", "array", "(", "\n", "[", "\n", "[", "adjust_bsz", "(", "bsz", ",", "num_tokens", ")", ",", "num_tokens", "]", "\n", "for", "(", "bsz", ",", "num_tokens", ")", "in", "fixed_shapes", "\n", "]", "\n", ")", "\n", "\n", "", "return", "data_utils", ".", "batch_by_size", "(", "\n", "indices", ",", "\n", "num_tokens_fn", "=", "self", ".", "num_tokens", ",", "\n", "max_tokens", "=", "max_tokens", ",", "\n", "max_sentences", "=", "max_sentences", ",", "\n", "required_batch_size_multiple", "=", "required_batch_size_multiple", ",", "\n", "fixed_shapes", "=", "fixed_shapes", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fairseq_dataset.FairseqDataset.filter_indices_by_size": [[141, 177], ["isinstance", "isinstance", "fairseq.data.data_utils._filter_by_size_dynamic", "hasattr", "isinstance", "indices[].tolist", "hasattr", "isinstance", "indices[].tolist", "fairseq.data.data_utils._filter_by_size_dynamic", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils._filter_by_size_dynamic", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils._filter_by_size_dynamic"], ["", "def", "filter_indices_by_size", "(", "self", ",", "indices", ",", "max_sizes", ")", ":", "\n", "        ", "\"\"\"\n        Filter a list of sample indices. Remove those that are longer than\n        specified in *max_sizes*.\n\n        WARNING: don't update, override method in child classes\n\n        Args:\n            indices (np.array): original array of sample indices\n            max_sizes (int or list[int] or tuple[int]): max sample size,\n                can be defined separately for src and tgt (then list or tuple)\n\n        Returns:\n            np.array: filtered sample array\n            list: list of removed indices\n        \"\"\"", "\n", "if", "isinstance", "(", "max_sizes", ",", "float", ")", "or", "isinstance", "(", "max_sizes", ",", "int", ")", ":", "\n", "            ", "if", "hasattr", "(", "self", ",", "\"sizes\"", ")", "and", "isinstance", "(", "self", ".", "sizes", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "ignored", "=", "indices", "[", "self", ".", "sizes", "[", "indices", "]", ">", "max_sizes", "]", ".", "tolist", "(", ")", "\n", "indices", "=", "indices", "[", "self", ".", "sizes", "[", "indices", "]", "<=", "max_sizes", "]", "\n", "", "elif", "(", "\n", "hasattr", "(", "self", ",", "\"sizes\"", ")", "\n", "and", "isinstance", "(", "self", ".", "sizes", ",", "list", ")", "\n", "and", "len", "(", "self", ".", "sizes", ")", "==", "1", "\n", ")", ":", "\n", "                ", "ignored", "=", "indices", "[", "self", ".", "sizes", "[", "0", "]", "[", "indices", "]", ">", "max_sizes", "]", ".", "tolist", "(", ")", "\n", "indices", "=", "indices", "[", "self", ".", "sizes", "[", "0", "]", "[", "indices", "]", "<=", "max_sizes", "]", "\n", "", "else", ":", "\n", "                ", "indices", ",", "ignored", "=", "data_utils", ".", "_filter_by_size_dynamic", "(", "\n", "indices", ",", "self", ".", "size", ",", "max_sizes", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "indices", ",", "ignored", "=", "data_utils", ".", "_filter_by_size_dynamic", "(", "\n", "indices", ",", "self", ".", "size", ",", "max_sizes", "\n", ")", "\n", "", "return", "indices", ",", "ignored", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fairseq_dataset.FairseqDataset.supports_fetch_outside_dataloader": [[178, 182], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_fetch_outside_dataloader", "(", "self", ")", ":", "\n", "        ", "\"\"\"Whether this dataset supports fetching outside the workers of the dataloader.\"\"\"", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fairseq_dataset.FairseqIterableDataset.__iter__": [[190, 192], ["None"], "methods", ["None"], ["def", "__iter__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.id_dataset.IdDataset.__getitem__": [[12, 14], ["None"], "methods", ["None"], ["    ", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.id_dataset.IdDataset.__len__": [[15, 17], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.id_dataset.IdDataset.collater": [[18, 20], ["torch.tensor"], "methods", ["None"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "samples", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.backtranslation_dataset.BacktranslationDataset.__init__": [[79, 97], ["torch.cuda.is_available"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "tgt_dataset", ",", "\n", "src_dict", ",", "\n", "tgt_dict", "=", "None", ",", "\n", "backtranslation_fn", "=", "None", ",", "\n", "output_collater", "=", "None", ",", "\n", "cuda", "=", "True", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "self", ".", "tgt_dataset", "=", "tgt_dataset", "\n", "self", ".", "backtranslation_fn", "=", "backtranslation_fn", "\n", "self", ".", "output_collater", "=", "(", "\n", "output_collater", "if", "output_collater", "is", "not", "None", "else", "tgt_dataset", ".", "collater", "\n", ")", "\n", "self", ".", "cuda", "=", "cuda", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "False", "\n", "self", ".", "src_dict", "=", "src_dict", "\n", "self", ".", "tgt_dict", "=", "tgt_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.backtranslation_dataset.BacktranslationDataset.__getitem__": [[98, 105], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Returns a single sample from *tgt_dataset*. Note that backtranslation is\n        not applied in this step; use :func:`collater` instead to backtranslate\n        a batch of samples.\n        \"\"\"", "\n", "return", "self", ".", "tgt_dataset", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.backtranslation_dataset.BacktranslationDataset.__len__": [[106, 108], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "tgt_dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.backtranslation_dataset.BacktranslationDataset.set_backtranslation_fn": [[109, 111], ["None"], "methods", ["None"], ["", "def", "set_backtranslation_fn", "(", "self", ",", "backtranslation_fn", ")", ":", "\n", "        ", "self", ".", "backtranslation_fn", "=", "backtranslation_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.backtranslation_dataset.BacktranslationDataset.collater": [[112, 140], ["samples[].get", "backtranslation_dataset.backtranslate_samples", "backtranslation_dataset.BacktranslationDataset.output_collater", "backtranslation_dataset.BacktranslationDataset.backtranslation_fn"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.backtranslation_dataset.backtranslate_samples"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Merge and backtranslate a list of samples to form a mini-batch.\n\n        Using the samples from *tgt_dataset*, load a collated target sample to\n        feed to the backtranslation model. Then take the backtranslation with\n        the best score as the source and the original input as the target.\n\n        Note: we expect *tgt_dataset* to provide a function `collater()` that\n        will collate samples into the format expected by *backtranslation_fn*.\n        After backtranslation, we will feed the new list of samples (i.e., the\n        `(backtranslated source, original source)` pairs) to *output_collater*\n        and return the result.\n\n        Args:\n            samples (List[dict]): samples to backtranslate and collate\n\n        Returns:\n            dict: a mini-batch with keys coming from *output_collater*\n        \"\"\"", "\n", "if", "samples", "[", "0", "]", ".", "get", "(", "\"is_dummy\"", ",", "False", ")", ":", "\n", "            ", "return", "samples", "\n", "", "samples", "=", "backtranslate_samples", "(", "\n", "samples", "=", "samples", ",", "\n", "collate_fn", "=", "self", ".", "tgt_dataset", ".", "collater", ",", "\n", "generate_fn", "=", "(", "lambda", "net_input", ":", "self", ".", "backtranslation_fn", "(", "net_input", ")", ")", ",", "\n", "cuda", "=", "self", ".", "cuda", ",", "\n", ")", "\n", "return", "self", ".", "output_collater", "(", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.backtranslation_dataset.BacktranslationDataset.num_tokens": [[141, 144], ["backtranslation_dataset.BacktranslationDataset.tgt_dataset.num_tokens"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.num_tokens"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Just use the tgt dataset num_tokens\"\"\"", "\n", "return", "self", ".", "tgt_dataset", ".", "num_tokens", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.backtranslation_dataset.BacktranslationDataset.ordered_indices": [[145, 148], ["backtranslation_dataset.BacktranslationDataset.tgt_dataset.ordered_indices"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.ordered_indices"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "\"\"\"Just use the tgt dataset ordered_indices\"\"\"", "\n", "return", "self", ".", "tgt_dataset", ".", "ordered_indices", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.backtranslation_dataset.BacktranslationDataset.size": [[149, 159], ["backtranslation_dataset.BacktranslationDataset.tgt_dataset.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return an example's size as a float or tuple. This value is used\n        when filtering a dataset with ``--max-positions``.\n\n        Note: we use *tgt_dataset* to approximate the length of the source\n        sentence, since we do not know the actual length until after\n        backtranslation.\n        \"\"\"", "\n", "tgt_size", "=", "self", ".", "tgt_dataset", ".", "size", "(", "index", ")", "[", "0", "]", "\n", "return", "(", "tgt_size", ",", "tgt_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.backtranslation_dataset.BacktranslationDataset.supports_prefetch": [[160, 163], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ".", "tgt_dataset", ",", "\"supports_prefetch\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.backtranslation_dataset.BacktranslationDataset.prefetch": [[164, 166], ["backtranslation_dataset.BacktranslationDataset.tgt_dataset.prefetch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "return", "self", ".", "tgt_dataset", ".", "prefetch", "(", "indices", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.backtranslation_dataset.backtranslate_samples": [[12, 50], ["collate_fn", "generate_fn", "fairseq.utils.move_to_cuda", "id.item", "[].cpu", "zip", "id.item"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.move_to_cuda", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["def", "backtranslate_samples", "(", "samples", ",", "collate_fn", ",", "generate_fn", ",", "cuda", "=", "True", ")", ":", "\n", "    ", "\"\"\"Backtranslate a list of samples.\n\n    Given an input (*samples*) of the form:\n\n        [{'id': 1, 'source': 'hallo welt'}]\n\n    this will return:\n\n        [{'id': 1, 'source': 'hello world', 'target': 'hallo welt'}]\n\n    Args:\n        samples (List[dict]): samples to backtranslate. Individual samples are\n            expected to have a 'source' key, which will become the 'target'\n            after backtranslation.\n        collate_fn (callable): function to collate samples into a mini-batch\n        generate_fn (callable): function to generate backtranslations\n        cuda (bool): use GPU for generation (default: ``True``)\n\n    Returns:\n        List[dict]: an updated list of samples with a backtranslated source\n    \"\"\"", "\n", "collated_samples", "=", "collate_fn", "(", "samples", ")", "\n", "s", "=", "utils", ".", "move_to_cuda", "(", "collated_samples", ")", "if", "cuda", "else", "collated_samples", "\n", "generated_sources", "=", "generate_fn", "(", "s", ")", "\n", "\n", "id_to_src", "=", "{", "sample", "[", "\"id\"", "]", ":", "sample", "[", "\"source\"", "]", "for", "sample", "in", "samples", "}", "\n", "\n", "# Go through each tgt sentence in batch and its corresponding best", "\n", "# generated hypothesis and create a backtranslation data pair", "\n", "# {id: id, source: generated backtranslation, target: original tgt}", "\n", "return", "[", "\n", "{", "\n", "\"id\"", ":", "id", ".", "item", "(", ")", ",", "\n", "\"target\"", ":", "id_to_src", "[", "id", ".", "item", "(", ")", "]", ",", "\n", "\"source\"", ":", "hypos", "[", "0", "]", "[", "\"tokens\"", "]", ".", "cpu", "(", ")", ",", "\n", "}", "\n", "for", "id", ",", "hypos", "in", "zip", "(", "collated_samples", "[", "\"id\"", "]", ",", "generated_sources", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.lru_cache_dataset.LRUCacheDataset.__init__": [[12, 14], ["BaseWrapperDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "token", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.lru_cache_dataset.LRUCacheDataset.__getitem__": [[15, 18], ["functools.lru_cache"], "methods", ["None"], ["", "@", "lru_cache", "(", "maxsize", "=", "8", ")", "\n", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "dataset", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.lru_cache_dataset.LRUCacheDataset.collater": [[19, 22], ["functools.lru_cache", "lru_cache_dataset.LRUCacheDataset.dataset.collater"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.collater"], ["", "@", "lru_cache", "(", "maxsize", "=", "8", ")", "\n", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "collater", "(", "samples", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.token_block_dataset.TokenBlockDataset.__init__": [[34, 104], ["fairseq.data.FairseqDataset.__init__", "isinstance", "_get_slice_indices_fast", "fairseq.data.plasma_utils.PlasmaArray", "fairseq.data.plasma_utils.PlasmaArray", "fairseq.data.plasma_utils.PlasmaArray", "len", "len", "len", "numpy.array", "torch.is_tensor", "sizes.numpy.numpy.astype", "str", "numpy.stack", "_get_block_to_dataset_index_fast", "ImportError", "sizes.numpy.numpy.numpy", "numpy.arange", "numpy.zeros", "numpy.arange", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "sizes", ",", "\n", "block_size", ",", "\n", "pad", ",", "\n", "eos", ",", "\n", "break_mode", "=", "None", ",", "\n", "include_targets", "=", "False", ",", "\n", "document_sep_len", "=", "1", ",", "\n", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "fairseq", ".", "data", ".", "token_block_utils_fast", "import", "(", "\n", "_get_slice_indices_fast", ",", "\n", "_get_block_to_dataset_index_fast", ",", "\n", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Please build Cython components with: `pip install --editable .` \"", "\n", "\"or `python setup.py build_ext --inplace`\"", "\n", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "pad", "=", "pad", "\n", "self", ".", "eos", "=", "eos", "\n", "self", ".", "include_targets", "=", "include_targets", "\n", "\n", "assert", "len", "(", "dataset", ")", "==", "len", "(", "sizes", ")", "\n", "assert", "len", "(", "dataset", ")", ">", "0", "\n", "\n", "if", "isinstance", "(", "sizes", ",", "list", ")", ":", "\n", "            ", "sizes", "=", "np", ".", "array", "(", "sizes", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "", "else", ":", "\n", "            ", "if", "torch", ".", "is_tensor", "(", "sizes", ")", ":", "\n", "                ", "sizes", "=", "sizes", ".", "numpy", "(", ")", "\n", "", "sizes", "=", "sizes", ".", "astype", "(", "np", ".", "int64", ")", "\n", "\n", "", "break_mode", "=", "break_mode", "if", "break_mode", "is", "not", "None", "else", "\"none\"", "\n", "\n", "# For \"eos\" break-mode, block_size is not required parameters.", "\n", "if", "break_mode", "==", "\"eos\"", "and", "block_size", "is", "None", ":", "\n", "            ", "block_size", "=", "0", "\n", "\n", "", "slice_indices", "=", "_get_slice_indices_fast", "(", "\n", "sizes", ",", "str", "(", "break_mode", ")", ",", "block_size", ",", "document_sep_len", "\n", ")", "\n", "self", ".", "_sizes", "=", "slice_indices", "[", ":", ",", "1", "]", "-", "slice_indices", "[", ":", ",", "0", "]", "\n", "\n", "# build index mapping block indices to the underlying dataset indices", "\n", "if", "break_mode", "==", "\"eos\"", ":", "\n", "# much faster version for eos break mode", "\n", "            ", "block_to_dataset_index", "=", "np", ".", "stack", "(", "\n", "[", "\n", "np", ".", "arange", "(", "len", "(", "sizes", ")", ")", ",", "# starting index in dataset", "\n", "np", ".", "zeros", "(", "\n", "len", "(", "sizes", ")", ",", "dtype", "=", "np", ".", "long", "\n", ")", ",", "# starting offset within starting index", "\n", "np", ".", "arange", "(", "len", "(", "sizes", ")", ")", ",", "# ending index in dataset", "\n", "]", ",", "\n", "1", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "block_to_dataset_index", "=", "_get_block_to_dataset_index_fast", "(", "\n", "sizes", ",", "\n", "slice_indices", ",", "\n", ")", "\n", "", "self", ".", "_slice_indices", "=", "plasma_utils", ".", "PlasmaArray", "(", "slice_indices", ")", "\n", "self", ".", "_sizes", "=", "plasma_utils", ".", "PlasmaArray", "(", "self", ".", "_sizes", ")", "\n", "self", ".", "_block_to_dataset_index", "=", "plasma_utils", ".", "PlasmaArray", "(", "block_to_dataset_index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.token_block_dataset.TokenBlockDataset.slice_indices": [[105, 108], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "slice_indices", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_slice_indices", ".", "array", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.token_block_dataset.TokenBlockDataset.sizes": [[109, 112], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_sizes", ".", "array", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.token_block_dataset.TokenBlockDataset.block_to_dataset_index": [[113, 116], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "block_to_dataset_index", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_block_to_dataset_index", ".", "array", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.token_block_dataset.TokenBlockDataset.attr": [[117, 120], ["token_block_dataset.TokenBlockDataset.dataset.attr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.attr"], ["", "def", "attr", "(", "self", ",", "attr", ":", "str", ",", "index", ":", "int", ")", ":", "\n", "        ", "start_ds_idx", ",", "_", ",", "_", "=", "self", ".", "block_to_dataset_index", "[", "index", "]", "\n", "return", "self", ".", "dataset", ".", "attr", "(", "attr", ",", "start_ds_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.token_block_dataset.TokenBlockDataset.__getitem__": [[121, 152], ["torch.cat", "torch.cat", "torch.cat", "range", "torch.cat", "item.new", "item.new", "item.new"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "start_ds_idx", ",", "start_offset", ",", "end_ds_idx", "=", "self", ".", "block_to_dataset_index", "[", "index", "]", "\n", "\n", "buffer", "=", "torch", ".", "cat", "(", "\n", "[", "self", ".", "dataset", "[", "idx", "]", "for", "idx", "in", "range", "(", "start_ds_idx", ",", "end_ds_idx", "+", "1", ")", "]", "\n", ")", "\n", "\n", "slice_s", ",", "slice_e", "=", "self", ".", "slice_indices", "[", "index", "]", "\n", "length", "=", "slice_e", "-", "slice_s", "\n", "s", ",", "e", "=", "start_offset", ",", "start_offset", "+", "length", "\n", "item", "=", "buffer", "[", "s", ":", "e", "]", "\n", "\n", "if", "self", ".", "include_targets", ":", "\n", "# *target* is the original sentence (=item)", "\n", "# *source* is shifted right by 1 (maybe left-padded with eos)", "\n", "# *past_target* is shifted right by 2 (left-padded as needed)", "\n", "            ", "if", "s", "==", "0", ":", "\n", "                ", "source", "=", "torch", ".", "cat", "(", "[", "item", ".", "new", "(", "[", "self", ".", "eos", "]", ")", ",", "buffer", "[", "0", ":", "e", "-", "1", "]", "]", ")", "\n", "past_target", "=", "torch", ".", "cat", "(", "\n", "[", "item", ".", "new", "(", "[", "self", ".", "pad", ",", "self", ".", "eos", "]", ")", ",", "buffer", "[", "0", ":", "e", "-", "2", "]", "]", "\n", ")", "\n", "", "else", ":", "\n", "                ", "source", "=", "buffer", "[", "s", "-", "1", ":", "e", "-", "1", "]", "\n", "if", "s", "==", "1", ":", "\n", "                    ", "past_target", "=", "torch", ".", "cat", "(", "[", "item", ".", "new", "(", "[", "self", ".", "eos", "]", ")", ",", "buffer", "[", "0", ":", "e", "-", "2", "]", "]", ")", "\n", "", "else", ":", "\n", "                    ", "past_target", "=", "buffer", "[", "s", "-", "2", ":", "e", "-", "2", "]", "\n", "\n", "", "", "return", "source", ",", "item", ",", "past_target", "\n", "\n", "", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.token_block_dataset.TokenBlockDataset.__len__": [[153, 155], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "slice_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.token_block_dataset.TokenBlockDataset.supports_prefetch": [[156, 159], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ".", "dataset", ",", "\"supports_prefetch\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.token_block_dataset.TokenBlockDataset.prefetch": [[160, 167], ["token_block_dataset.TokenBlockDataset.dataset.prefetch", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "self", ".", "dataset", ".", "prefetch", "(", "\n", "{", "\n", "ds_idx", "\n", "for", "index", "in", "indices", "\n", "for", "start_ds_idx", ",", "_", ",", "end_ds_idx", "in", "[", "self", ".", "block_to_dataset_index", "[", "index", "]", "]", "\n", "for", "ds_idx", "in", "range", "(", "start_ds_idx", ",", "end_ds_idx", "+", "1", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.lm_context_window_dataset.LMContextWindowDataset.__init__": [[16, 24], ["isinstance", "numpy.empty"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "tokens_per_sample", ",", "context_window", ",", "pad_idx", ")", ":", "\n", "        ", "assert", "isinstance", "(", "dataset", ",", "MonolingualDataset", ")", "\n", "assert", "context_window", ">", "0", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "tokens_per_sample", "=", "tokens_per_sample", "\n", "self", ".", "context_window", "=", "context_window", "\n", "self", ".", "pad_idx", "=", "pad_idx", "\n", "self", ".", "prev_tokens", "=", "np", ".", "empty", "(", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.lm_context_window_dataset.LMContextWindowDataset.__getitem__": [[25, 27], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "dataset", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.lm_context_window_dataset.LMContextWindowDataset.__len__": [[28, 30], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.lm_context_window_dataset.LMContextWindowDataset.collater": [[31, 63], ["lm_context_window_dataset.LMContextWindowDataset.dataset.collater", "numpy.empty", "numpy.full", "toks.ne().long().sum().cpu", "range", "torch.from_numpy", "torch.from_numpy", "numpy.full", "numpy.concatenate", "len", "len", "toks.ne().long().sum", "len", "len", "toks[].numpy", "toks.ne().long", "len", "len", "len", "toks.ne"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.collater"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "sample", "=", "self", ".", "dataset", ".", "collater", "(", "samples", ")", "\n", "\n", "pad", "=", "self", ".", "pad_idx", "\n", "max_sample_len", "=", "self", ".", "tokens_per_sample", "+", "self", ".", "context_window", "\n", "\n", "bsz", ",", "tsz", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", ".", "shape", "\n", "start_idxs", "=", "[", "0", "]", "*", "bsz", "\n", "toks", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "\n", "lengths", "=", "sample", "[", "\"net_input\"", "]", "[", "\"src_lengths\"", "]", "\n", "tgt", "=", "sample", "[", "\"target\"", "]", "\n", "new_toks", "=", "np", ".", "empty", "(", "[", "bsz", ",", "tsz", "+", "self", ".", "context_window", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "new_tgt", "=", "np", ".", "full", "(", "[", "bsz", ",", "tsz", "+", "self", ".", "context_window", "]", ",", "pad", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "sample_lens", "=", "toks", ".", "ne", "(", "pad", ")", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "cpu", "(", ")", "\n", "for", "i", "in", "range", "(", "bsz", ")", ":", "\n", "            ", "sample_len", "=", "sample_lens", "[", "i", "]", "\n", "extra", "=", "len", "(", "self", ".", "prev_tokens", ")", "+", "sample_len", "-", "max_sample_len", "\n", "if", "extra", ">", "0", ":", "\n", "                ", "self", ".", "prev_tokens", "=", "self", ".", "prev_tokens", "[", "extra", ":", "]", "\n", "", "pads", "=", "np", ".", "full", "(", "self", ".", "context_window", "-", "len", "(", "self", ".", "prev_tokens", ")", ",", "pad", ")", "\n", "new_toks", "[", "i", "]", "=", "np", ".", "concatenate", "(", "[", "self", ".", "prev_tokens", ",", "toks", "[", "i", "]", ".", "numpy", "(", ")", ",", "pads", "]", ")", "\n", "new_tgt", "[", "\n", "i", ",", "len", "(", "self", ".", "prev_tokens", ")", ":", "len", "(", "self", ".", "prev_tokens", ")", "+", "len", "(", "tgt", "[", "i", "]", ")", "\n", "]", "=", "tgt", "[", "i", "]", "\n", "start_idxs", "[", "i", "]", "=", "len", "(", "self", ".", "prev_tokens", ")", "\n", "lengths", "[", "i", "]", "+=", "len", "(", "self", ".", "prev_tokens", ")", "\n", "self", ".", "prev_tokens", "=", "new_toks", "[", "i", "]", "[", "new_toks", "[", "i", "]", "!=", "pad", "]", "[", "-", "self", ".", "context_window", ":", "]", "\n", "", "sample", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "=", "torch", ".", "from_numpy", "(", "new_toks", ")", "\n", "sample", "[", "\"target\"", "]", "=", "torch", ".", "from_numpy", "(", "new_tgt", ")", "\n", "sample", "[", "\"start_indices\"", "]", "=", "start_idxs", "\n", "\n", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.lm_context_window_dataset.LMContextWindowDataset.num_tokens": [[64, 66], ["lm_context_window_dataset.LMContextWindowDataset.dataset.num_tokens"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.num_tokens"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "num_tokens", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.lm_context_window_dataset.LMContextWindowDataset.size": [[67, 69], ["lm_context_window_dataset.LMContextWindowDataset.dataset.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "size", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.lm_context_window_dataset.LMContextWindowDataset.ordered_indices": [[70, 73], ["numpy.arange", "len"], "methods", ["None"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "# NOTE we don't shuffle the data to retain access to the previous dataset elements", "\n", "        ", "return", "np", ".", "arange", "(", "len", "(", "self", ".", "dataset", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.lm_context_window_dataset.LMContextWindowDataset.supports_prefetch": [[74, 77], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ".", "dataset", ",", "\"supports_prefetch\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.lm_context_window_dataset.LMContextWindowDataset.prefetch": [[78, 80], ["lm_context_window_dataset.LMContextWindowDataset.dataset.prefetch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "prefetch", "(", "indices", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.CountingIterator.__init__": [[41, 54], ["iter", "getattr", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "iterable", ",", "start", "=", "None", ",", "total", "=", "None", ")", ":", "\n", "        ", "self", ".", "iterable", "=", "iterable", "\n", "self", ".", "itr", "=", "iter", "(", "self", ")", "\n", "\n", "if", "start", "is", "None", ":", "\n", "            ", "self", ".", "n", "=", "getattr", "(", "iterable", ",", "\"n\"", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "n", "=", "start", "\n", "\n", "", "if", "total", "is", "None", ":", "\n", "            ", "self", ".", "total", "=", "self", ".", "n", "+", "len", "(", "iterable", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "total", "=", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.CountingIterator.__len__": [[55, 57], ["None"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.CountingIterator.__iter__": [[58, 71], ["RuntimeError"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "x", "in", "self", ".", "iterable", ":", "\n", "            ", "if", "self", ".", "n", ">=", "self", ".", "total", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "\"Mismatch between actual and expected iterable length. \"", "\n", "\"This may be caused by resuming training from a checkpoint using \"", "\n", "\"a different number of GPUs, in which case you can try the \"", "\n", "\"--reset-dataloader option. Alternatively you may have a train or \"", "\n", "\"validation set that is smaller than the number of GPUs. If none \"", "\n", "\"of these apply, please report this to the fairseq developers.\"", "\n", ")", "\n", "", "self", ".", "n", "+=", "1", "\n", "yield", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.CountingIterator.__next__": [[72, 74], ["next"], "methods", ["None"], ["", "", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "return", "next", "(", "self", ".", "itr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.CountingIterator.has_next": [[75, 78], ["len"], "methods", ["None"], ["", "def", "has_next", "(", "self", ")", ":", "\n", "        ", "\"\"\"Whether the iterator has been exhausted.\"\"\"", "\n", "return", "self", ".", "n", "<", "len", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.CountingIterator.skip": [[79, 83], ["next", "itertools.islice"], "methods", ["None"], ["", "def", "skip", "(", "self", ",", "num_to_skip", ")", ":", "\n", "        ", "\"\"\"Fast-forward the iterator by skipping *num_to_skip* elements.\"\"\"", "\n", "next", "(", "itertools", ".", "islice", "(", "self", ".", "itr", ",", "num_to_skip", ",", "num_to_skip", ")", ",", "None", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.CountingIterator.take": [[84, 102], ["min", "max", "hasattr", "iterators.CountingIterator.iterable.take", "itertools.islice"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.BufferedIterator.take"], ["", "def", "take", "(", "self", ",", "n", ")", ":", "\n", "        ", "\"\"\"\n        Truncates the iterator to n elements at most.\n        \"\"\"", "\n", "self", ".", "total", "=", "min", "(", "self", ".", "total", ",", "n", ")", "\n", "\n", "# Propagate this change to the underlying iterator", "\n", "# Only take after what we have already consumed (i.e. after restarting", "\n", "# from checkpoint mid epoch, we have to subtract self.n which is the", "\n", "# starting point)", "\n", "#", "\n", "# This to maintain the invariant self.total = self.n + len(iterable),", "\n", "# before calling __next__ or __iter__", "\n", "propagated_take", "=", "max", "(", "n", "-", "self", ".", "n", ",", "0", ")", "\n", "if", "hasattr", "(", "self", ".", "iterable", ",", "\"take\"", ")", ":", "\n", "            ", "self", ".", "iterable", ".", "take", "(", "propagated_take", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "iterable", "=", "itertools", ".", "islice", "(", "self", ".", "iterable", ",", "propagated_take", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterating.__len__": [[105, 107], ["None"], "methods", ["None"], ["    ", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterating.next_epoch_idx": [[108, 111], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "next_epoch_idx", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterating.next_epoch_itr": [[112, 123], ["None"], "methods", ["None"], ["", "def", "next_epoch_itr", "(", "self", ",", "shuffle", "=", "True", ",", "fix_batches_to_gpus", "=", "False", ")", ":", "\n", "        ", "\"\"\"Return a new iterator over the dataset.\n\n        Args:\n            shuffle (bool, optional): shuffle batches before returning the\n                iterator (default: True).\n            fix_batches_to_gpus: ensure that batches are always\n                allocated to the same shards across epochs. Requires\n                that :attr:`dataset` supports prefetching (default: False).\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterating.end_of_epoch": [[124, 127], ["None"], "methods", ["None"], ["", "def", "end_of_epoch", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"Returns whether the most recent epoch iterator has been exhausted\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterating.iterations_in_epoch": [[128, 132], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "iterations_in_epoch", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"The number of consumed batches in the current epoch.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterating.state_dict": [[133, 136], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary containing a whole state of the iterator.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterating.load_state_dict": [[137, 140], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Copies the state of the iterator from the given *state_dict*.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.StreamingEpochBatchIterator.__init__": [[143, 156], ["isinstance", "max"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "epoch", "=", "1", ",", "\n", "num_shards", "=", "1", ",", "\n", "shard_id", "=", "0", ",", "\n", ")", ":", "\n", "        ", "assert", "isinstance", "(", "dataset", ",", "torch", ".", "utils", ".", "data", ".", "IterableDataset", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "epoch", "=", "max", "(", "epoch", ",", "1", ")", "# we use 1-based indexing for epochs", "\n", "self", ".", "_current_epoch_iterator", "=", "None", "\n", "self", ".", "num_shards", "=", "num_shards", "\n", "self", ".", "shard_id", "=", "shard_id", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.StreamingEpochBatchIterator.next_epoch_idx": [[157, 164], ["iterators.StreamingEpochBatchIterator.end_of_epoch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.end_of_epoch"], ["", "@", "property", "\n", "def", "next_epoch_idx", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the epoch index after *next_epoch_itr* is called.\"\"\"", "\n", "if", "self", ".", "_current_epoch_iterator", "is", "not", "None", "and", "self", ".", "end_of_epoch", "(", ")", ":", "\n", "            ", "return", "self", ".", "epoch", "+", "1", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.StreamingEpochBatchIterator.next_epoch_itr": [[165, 177], ["hasattr", "iterators.CountingIterator", "iterators.StreamingEpochBatchIterator.dataset.set_epoch", "iterators.ShardedIterator"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch"], ["", "", "def", "next_epoch_itr", "(", "self", ",", "shuffle", "=", "True", ",", "fix_batches_to_gpus", "=", "False", ")", ":", "\n", "        ", "self", ".", "epoch", "=", "self", ".", "next_epoch_idx", "\n", "if", "hasattr", "(", "self", ".", "dataset", ",", "\"set_epoch\"", ")", ":", "\n", "            ", "self", ".", "dataset", ".", "set_epoch", "(", "self", ".", "epoch", ")", "\n", "", "self", ".", "_current_epoch_iterator", "=", "CountingIterator", "(", "\n", "iterable", "=", "ShardedIterator", "(", "\n", "iterable", "=", "self", ".", "dataset", ",", "\n", "num_shards", "=", "self", ".", "num_shards", ",", "\n", "shard_id", "=", "self", ".", "shard_id", ",", "\n", ")", ",", "\n", ")", "\n", "return", "self", ".", "_current_epoch_iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.StreamingEpochBatchIterator.end_of_epoch": [[178, 180], ["iterators.StreamingEpochBatchIterator._current_epoch_iterator.has_next"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.CountingIterator.has_next"], ["", "def", "end_of_epoch", "(", "self", ")", "->", "bool", ":", "\n", "        ", "return", "not", "self", ".", "_current_epoch_iterator", ".", "has_next", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.StreamingEpochBatchIterator.iterations_in_epoch": [[181, 186], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "iterations_in_epoch", "(", "self", ")", "->", "int", ":", "\n", "        ", "if", "self", ".", "_current_epoch_iterator", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_current_epoch_iterator", ".", "n", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.StreamingEpochBatchIterator.state_dict": [[187, 190], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"epoch\"", ":", "self", ".", "epoch", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.StreamingEpochBatchIterator.load_state_dict": [[192, 194], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "epoch", "=", "state_dict", "[", "\"epoch\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.__init__": [[234, 270], ["isinstance", "min", "max", "getattr", "tuple", "callable"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "collate_fn", ",", "\n", "batch_sampler", ",", "\n", "seed", "=", "1", ",", "\n", "num_shards", "=", "1", ",", "\n", "shard_id", "=", "0", ",", "\n", "num_workers", "=", "0", ",", "\n", "epoch", "=", "1", ",", "\n", "buffer_size", "=", "0", ",", "\n", "timeout", "=", "0", ",", "\n", "disable_shuffling", "=", "False", ",", "\n", ")", ":", "\n", "        ", "assert", "isinstance", "(", "dataset", ",", "torch", ".", "utils", ".", "data", ".", "Dataset", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "collate_fn", "=", "collate_fn", "\n", "self", ".", "batch_sampler", "=", "batch_sampler", "\n", "self", ".", "_frozen_batches", "=", "(", "\n", "tuple", "(", "batch_sampler", ")", "if", "not", "callable", "(", "batch_sampler", ")", "else", "None", "\n", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "num_shards", "=", "num_shards", "\n", "self", ".", "shard_id", "=", "shard_id", "\n", "self", ".", "num_workers", "=", "num_workers", "\n", "# This upper limit here is to prevent people from abusing this feature", "\n", "# in a shared computing environment.", "\n", "self", ".", "buffer_size", "=", "min", "(", "buffer_size", ",", "20", ")", "\n", "self", ".", "timeout", "=", "timeout", "\n", "self", ".", "disable_shuffling", "=", "disable_shuffling", "\n", "\n", "self", ".", "epoch", "=", "max", "(", "epoch", ",", "1", ")", "# we use 1-based indexing for epochs", "\n", "self", ".", "shuffle", "=", "not", "disable_shuffling", "\n", "self", ".", "_cur_epoch_itr", "=", "None", "\n", "self", ".", "_next_epoch_itr", "=", "None", "\n", "self", ".", "_supports_prefetch", "=", "getattr", "(", "dataset", ",", "\"supports_prefetch\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.frozen_batches": [[271, 276], ["tuple", "iterators.EpochBatchIterator.batch_sampler"], "methods", ["None"], ["", "@", "property", "\n", "def", "frozen_batches", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_frozen_batches", "is", "None", ":", "\n", "            ", "self", ".", "_frozen_batches", "=", "tuple", "(", "self", ".", "batch_sampler", "(", "self", ".", "dataset", ",", "self", ".", "epoch", ")", ")", "\n", "", "return", "self", ".", "_frozen_batches", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.first_batch": [[277, 291], ["getattr", "len", "Exception", "iterators.EpochBatchIterator.collate_fn"], "methods", ["None"], ["", "@", "property", "\n", "def", "first_batch", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "frozen_batches", ")", "==", "0", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"The dataset is empty. This could indicate \"", "\n", "\"that all elements in the dataset have been skipped. \"", "\n", "\"Try increasing the max number of allowed tokens or using \"", "\n", "\"a larger dataset.\"", "\n", ")", "\n", "\n", "", "if", "getattr", "(", "self", ".", "dataset", ",", "\"supports_fetch_outside_dataloader\"", ",", "True", ")", ":", "\n", "            ", "return", "self", ".", "collate_fn", "(", "[", "self", ".", "dataset", "[", "i", "]", "for", "i", "in", "self", ".", "frozen_batches", "[", "0", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "\"DUMMY\"", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.__len__": [[292, 294], ["int", "math.ceil", "len", "float"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "int", "(", "math", ".", "ceil", "(", "len", "(", "self", ".", "frozen_batches", ")", "/", "float", "(", "self", ".", "num_shards", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.n": [[295, 298], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "n", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "iterations_in_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.next_epoch_idx": [[299, 308], ["iterators.EpochBatchIterator.end_of_epoch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.end_of_epoch"], ["", "@", "property", "\n", "def", "next_epoch_idx", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the epoch index after *next_epoch_itr* is called.\"\"\"", "\n", "if", "self", ".", "_next_epoch_itr", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "epoch", "\n", "", "elif", "self", ".", "_cur_epoch_itr", "is", "not", "None", "and", "self", ".", "end_of_epoch", "(", ")", ":", "\n", "            ", "return", "self", ".", "epoch", "+", "1", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.next_epoch_itr": [[309, 338], ["hasattr", "iterators.EpochBatchIterator.dataset.set_epoch", "callable", "iterators.EpochBatchIterator._get_iterator_for_epoch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch", "home.repos.pwc.inspect_result.reneeye_const.data.iterators.GroupedEpochBatchIterator._get_iterator_for_epoch"], ["", "", "def", "next_epoch_itr", "(", "self", ",", "shuffle", "=", "True", ",", "fix_batches_to_gpus", "=", "False", ")", ":", "\n", "        ", "\"\"\"Return a new iterator over the dataset.\n\n        Args:\n            shuffle (bool, optional): shuffle batches before returning the\n                iterator (default: True).\n            fix_batches_to_gpus: ensure that batches are always\n                allocated to the same shards across epochs. Requires\n                that :attr:`dataset` supports prefetching (default: False).\n        \"\"\"", "\n", "if", "self", ".", "disable_shuffling", ":", "\n", "            ", "shuffle", "=", "False", "\n", "", "self", ".", "epoch", "=", "self", ".", "next_epoch_idx", "\n", "if", "hasattr", "(", "self", ".", "dataset", ",", "\"set_epoch\"", ")", ":", "\n", "            ", "self", ".", "dataset", ".", "set_epoch", "(", "self", ".", "epoch", ")", "\n", "", "if", "self", ".", "_next_epoch_itr", "is", "not", "None", ":", "\n", "            ", "self", ".", "_cur_epoch_itr", "=", "self", ".", "_next_epoch_itr", "\n", "self", ".", "_next_epoch_itr", "=", "None", "\n", "", "else", ":", "\n", "            ", "if", "callable", "(", "self", ".", "batch_sampler", ")", ":", "\n", "# reset _frozen_batches to refresh the next epoch", "\n", "                ", "self", ".", "_frozen_batches", "=", "None", "\n", "", "self", ".", "_cur_epoch_itr", "=", "self", ".", "_get_iterator_for_epoch", "(", "\n", "self", ".", "epoch", ",", "\n", "shuffle", ",", "\n", "fix_batches_to_gpus", "=", "fix_batches_to_gpus", ",", "\n", ")", "\n", "", "self", ".", "shuffle", "=", "shuffle", "\n", "return", "self", ".", "_cur_epoch_itr", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.end_of_epoch": [[339, 342], ["iterators.EpochBatchIterator._cur_epoch_itr.has_next"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.CountingIterator.has_next"], ["", "def", "end_of_epoch", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"Returns whether the most recent epoch iterator has been exhausted\"\"\"", "\n", "return", "not", "self", ".", "_cur_epoch_itr", ".", "has_next", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.iterations_in_epoch": [[343, 351], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "iterations_in_epoch", "(", "self", ")", ":", "\n", "        ", "\"\"\"The number of consumed batches in the current epoch.\"\"\"", "\n", "if", "self", ".", "_cur_epoch_itr", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_cur_epoch_itr", ".", "n", "\n", "", "elif", "self", ".", "_next_epoch_itr", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_next_epoch_itr", ".", "n", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.state_dict": [[352, 365], ["iterators.EpochBatchIterator.end_of_epoch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.end_of_epoch"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns a dictionary containing a whole state of the iterator.\"\"\"", "\n", "if", "self", ".", "end_of_epoch", "(", ")", ":", "\n", "            ", "epoch", "=", "self", ".", "epoch", "+", "1", "\n", "iter_in_epoch", "=", "0", "\n", "", "else", ":", "\n", "            ", "epoch", "=", "self", ".", "epoch", "\n", "iter_in_epoch", "=", "self", ".", "iterations_in_epoch", "\n", "", "return", "{", "\n", "\"version\"", ":", "2", ",", "\n", "\"epoch\"", ":", "epoch", ",", "\n", "\"iterations_in_epoch\"", ":", "iter_in_epoch", ",", "\n", "\"shuffle\"", ":", "self", ".", "shuffle", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator.load_state_dict": [[367, 391], ["state_dict.get", "state_dict.get", "iterators.EpochBatchIterator._get_iterator_for_epoch", "state_dict.get", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.GroupedEpochBatchIterator._get_iterator_for_epoch"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Copies the state of the iterator from the given *state_dict*.\"\"\"", "\n", "self", ".", "epoch", "=", "state_dict", "[", "\"epoch\"", "]", "\n", "itr_pos", "=", "state_dict", ".", "get", "(", "\"iterations_in_epoch\"", ",", "0", ")", "\n", "version", "=", "state_dict", ".", "get", "(", "\"version\"", ",", "1", ")", "\n", "if", "itr_pos", ">", "0", ":", "\n", "# fast-forward epoch iterator", "\n", "            ", "self", ".", "_next_epoch_itr", "=", "self", ".", "_get_iterator_for_epoch", "(", "\n", "self", ".", "epoch", ",", "\n", "shuffle", "=", "state_dict", ".", "get", "(", "\"shuffle\"", ",", "True", ")", ",", "\n", "offset", "=", "itr_pos", ",", "\n", ")", "\n", "if", "self", ".", "_next_epoch_itr", "is", "None", ":", "\n", "                ", "if", "version", "==", "1", ":", "\n", "# legacy behavior: we finished the epoch, increment epoch counter", "\n", "                    ", "self", ".", "epoch", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\n", "\"Cannot resume training due to dataloader mismatch, please \"", "\n", "\"report this to the fairseq developers. You can relaunch \"", "\n", "\"training with `--reset-dataloader` and it should work.\"", "\n", ")", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "_next_epoch_itr", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.EpochBatchIterator._get_iterator_for_epoch": [[392, 444], ["torch.utils.data.DataLoader", "iterators.CountingIterator", "list", "iterators.EpochBatchIterator.dataset.prefetch", "list", "iterators.BufferedIterator", "fairseq.data.data_utils.numpy_seed", "numpy.random.shuffle", "iterators.EpochBatchIterator._get_iterator_for_epoch.shuffle_batches"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.numpy_seed", "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.S2TDataConfig.shuffle"], ["", "", "def", "_get_iterator_for_epoch", "(", "\n", "self", ",", "epoch", ",", "shuffle", ",", "fix_batches_to_gpus", "=", "False", ",", "offset", "=", "0", "\n", ")", ":", "\n", "        ", "def", "shuffle_batches", "(", "batches", ",", "seed", ")", ":", "\n", "            ", "with", "data_utils", ".", "numpy_seed", "(", "seed", ")", ":", "\n", "                ", "np", ".", "random", ".", "shuffle", "(", "batches", ")", "\n", "", "return", "batches", "\n", "\n", "", "if", "self", ".", "_supports_prefetch", ":", "\n", "            ", "batches", "=", "self", ".", "frozen_batches", "\n", "\n", "if", "shuffle", "and", "not", "fix_batches_to_gpus", ":", "\n", "                ", "batches", "=", "shuffle_batches", "(", "list", "(", "batches", ")", ",", "self", ".", "seed", "+", "epoch", ")", "\n", "\n", "", "batches", "=", "list", "(", "\n", "ShardedIterator", "(", "batches", ",", "self", ".", "num_shards", ",", "self", ".", "shard_id", ",", "fill_value", "=", "[", "]", ")", "\n", ")", "\n", "self", ".", "dataset", ".", "prefetch", "(", "[", "i", "for", "s", "in", "batches", "for", "i", "in", "s", "]", ")", "\n", "\n", "if", "shuffle", "and", "fix_batches_to_gpus", ":", "\n", "                ", "batches", "=", "shuffle_batches", "(", "batches", ",", "self", ".", "seed", "+", "epoch", "+", "self", ".", "shard_id", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "shuffle", ":", "\n", "                ", "batches", "=", "shuffle_batches", "(", "list", "(", "self", ".", "frozen_batches", ")", ",", "self", ".", "seed", "+", "epoch", ")", "\n", "", "else", ":", "\n", "                ", "batches", "=", "self", ".", "frozen_batches", "\n", "", "batches", "=", "list", "(", "\n", "ShardedIterator", "(", "batches", ",", "self", ".", "num_shards", ",", "self", ".", "shard_id", ",", "fill_value", "=", "[", "]", ")", "\n", ")", "\n", "\n", "", "if", "offset", ">", "0", "and", "offset", ">=", "len", "(", "batches", ")", ":", "\n", "            ", "return", "None", "\n", "\n", "", "if", "self", ".", "num_workers", ">", "0", ":", "\n", "            ", "os", ".", "environ", "[", "\"PYTHONWARNINGS\"", "]", "=", "\"ignore:semaphore_tracker:UserWarning\"", "\n", "\n", "# Create data loader", "\n", "", "itr", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "self", ".", "dataset", ",", "\n", "collate_fn", "=", "self", ".", "collate_fn", ",", "\n", "batch_sampler", "=", "batches", "[", "offset", ":", "]", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "timeout", "=", "self", ".", "timeout", ",", "\n", ")", "\n", "\n", "# Wrap with a BufferedIterator if needed", "\n", "if", "self", ".", "buffer_size", ">", "0", ":", "\n", "            ", "itr", "=", "BufferedIterator", "(", "self", ".", "buffer_size", ",", "itr", ")", "\n", "\n", "# Wrap with CoutingIterator", "\n", "", "itr", "=", "CountingIterator", "(", "itr", ",", "start", "=", "offset", ")", "\n", "return", "itr", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.GroupedIterator.__init__": [[457, 465], ["iterators._chunk_iterator", "iterators.CountingIterator.__init__", "int", "int", "math.ceil", "math.ceil", "getattr", "float", "len", "float"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators._chunk_iterator", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "iterable", ",", "chunk_size", ")", ":", "\n", "        ", "itr", "=", "_chunk_iterator", "(", "iterable", ",", "chunk_size", ")", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "itr", ",", "\n", "start", "=", "int", "(", "math", ".", "ceil", "(", "getattr", "(", "iterable", ",", "\"n\"", ",", "0", ")", "/", "float", "(", "chunk_size", ")", ")", ")", ",", "\n", "total", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "iterable", ")", "/", "float", "(", "chunk_size", ")", ")", ")", ",", "\n", ")", "\n", "self", ".", "chunk_size", "=", "chunk_size", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.ShardedIterator.__init__": [[492, 508], ["int", "map", "iterators.CountingIterator.__init__", "ValueError", "math.ceil", "operator.itemgetter", "itertools.zip_longest", "range", "itertools.islice", "int", "len", "float", "len", "math.ceil", "getattr", "float"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "iterable", ",", "num_shards", ",", "shard_id", ",", "fill_value", "=", "None", ")", ":", "\n", "        ", "if", "shard_id", "<", "0", "or", "shard_id", ">=", "num_shards", ":", "\n", "            ", "raise", "ValueError", "(", "\"shard_id must be between 0 and num_shards\"", ")", "\n", "", "sharded_len", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "iterable", ")", "/", "float", "(", "num_shards", ")", ")", ")", "\n", "itr", "=", "map", "(", "\n", "operator", ".", "itemgetter", "(", "1", ")", ",", "\n", "itertools", ".", "zip_longest", "(", "\n", "range", "(", "sharded_len", ")", ",", "\n", "itertools", ".", "islice", "(", "iterable", ",", "shard_id", ",", "len", "(", "iterable", ")", ",", "num_shards", ")", ",", "\n", "fillvalue", "=", "fill_value", ",", "\n", ")", ",", "\n", ")", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "itr", ",", "\n", "start", "=", "int", "(", "math", ".", "ceil", "(", "getattr", "(", "iterable", ",", "\"n\"", ",", "0", ")", "/", "float", "(", "num_shards", ")", ")", ")", ",", "\n", "total", "=", "sharded_len", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.BackgroundConsumer.__init__": [[512, 519], ["threading.Thread.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "queue", ",", "source", ",", "max_len", ")", ":", "\n", "        ", "Thread", ".", "__init__", "(", "self", ")", "\n", "\n", "self", ".", "_queue", "=", "queue", "\n", "self", ".", "_source", "=", "source", "\n", "self", ".", "_max_len", "=", "max_len", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.BackgroundConsumer.run": [[520, 534], ["iterators.BackgroundConsumer._queue.put", "iterators.BackgroundConsumer._queue.put", "iterators.BackgroundConsumer._queue.put"], "methods", ["None"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "for", "item", "in", "self", ".", "_source", ":", "\n", "                ", "self", ".", "_queue", ".", "put", "(", "item", ")", "\n", "\n", "# Stop if we reached the maximum length", "\n", "self", ".", "count", "+=", "1", "\n", "if", "self", ".", "_max_len", "is", "not", "None", "and", "self", ".", "count", ">=", "self", ".", "_max_len", ":", "\n", "                    ", "break", "\n", "\n", "# Signal the consumer we are done.", "\n", "", "", "self", ".", "_queue", ".", "put", "(", "_sentinel", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "self", ".", "_queue", ".", "put", "(", "e", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.BufferedIterator.__init__": [[537, 546], ["queue.Queue", "time.time", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "iterable", ")", ":", "\n", "        ", "self", ".", "_queue", "=", "queue", ".", "Queue", "(", "size", ")", "\n", "self", ".", "_iterable", "=", "iterable", "\n", "self", ".", "_consumer", "=", "None", "\n", "\n", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "warning_time", "=", "None", "\n", "\n", "self", ".", "total", "=", "len", "(", "iterable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.BufferedIterator._create_consumer": [[547, 555], ["iterators.BackgroundConsumer", "iterators.BufferedIterator._consumer.start"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.logging.meters.StopwatchMeter.start"], ["", "def", "_create_consumer", "(", "self", ")", ":", "\n", "        ", "self", ".", "_consumer", "=", "BackgroundConsumer", "(", "\n", "self", ".", "_queue", ",", "\n", "self", ".", "_iterable", ",", "\n", "self", ".", "total", ",", "\n", ")", "\n", "self", ".", "_consumer", ".", "daemon", "=", "True", "\n", "self", ".", "_consumer", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.BufferedIterator.__iter__": [[556, 558], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.BufferedIterator.__len__": [[559, 561], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.BufferedIterator.take": [[562, 568], ["min", "hasattr", "iterators.BufferedIterator._iterable.take"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.BufferedIterator.take"], ["", "def", "take", "(", "self", ",", "n", ")", ":", "\n", "        ", "self", ".", "total", "=", "min", "(", "self", ".", "total", ",", "n", ")", "\n", "\n", "# Propagate this change to the underlying iterator", "\n", "if", "hasattr", "(", "self", ".", "_iterable", ",", "\"take\"", ")", ":", "\n", "            ", "self", ".", "_iterable", ".", "take", "(", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.BufferedIterator.__next__": [[569, 595], ["iterators.BufferedIterator._queue.get", "isinstance", "iterators.BufferedIterator._create_consumer", "iterators.BufferedIterator._queue.qsize", "min", "StopIteration", "max", "time.time", "logger.debug", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.iterators.BufferedIterator._create_consumer"], ["", "", "def", "__next__", "(", "self", ")", ":", "\n", "# Create consumer if not created yet", "\n", "        ", "if", "self", ".", "_consumer", "is", "None", ":", "\n", "            ", "self", ".", "_create_consumer", "(", ")", "\n", "\n", "# Notify the user if there is a data loading bottleneck", "\n", "", "if", "self", ".", "_queue", ".", "qsize", "(", ")", "<", "min", "(", "2", ",", "max", "(", "1", ",", "self", ".", "_queue", ".", "maxsize", "//", "2", ")", ")", ":", "\n", "            ", "if", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", ">", "5", "*", "60", ":", "\n", "                ", "if", "(", "\n", "self", ".", "warning_time", "is", "None", "\n", "or", "time", ".", "time", "(", ")", "-", "self", ".", "warning_time", ">", "15", "*", "60", "\n", ")", ":", "\n", "                    ", "logger", ".", "debug", "(", "\n", "\"Data loading buffer is empty or nearly empty. This may \"", "\n", "\"indicate a data loading bottleneck, and increasing the \"", "\n", "\"number of workers (--num-workers) may help.\"", "\n", ")", "\n", "self", ".", "warning_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Get next example", "\n", "", "", "", "item", "=", "self", ".", "_queue", ".", "get", "(", "True", ")", "\n", "if", "isinstance", "(", "item", ",", "Exception", ")", ":", "\n", "            ", "raise", "item", "\n", "", "if", "item", "is", "_sentinel", ":", "\n", "            ", "raise", "StopIteration", "(", ")", "\n", "", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.GroupedEpochBatchIterator.__init__": [[611, 641], ["iterators.EpochBatchIterator.__init__", "tuple", "tuple", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "collate_fn", ",", "\n", "batch_samplers", ",", "\n", "seed", "=", "1", ",", "\n", "num_shards", "=", "1", ",", "\n", "shard_id", "=", "0", ",", "\n", "num_workers", "=", "0", ",", "\n", "epoch", "=", "0", ",", "\n", "mult_rate", "=", "1", ",", "\n", "buffer_size", "=", "0", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "dataset", ",", "\n", "collate_fn", ",", "\n", "batch_samplers", ",", "\n", "seed", ",", "\n", "num_shards", ",", "\n", "shard_id", ",", "\n", "num_workers", ",", "\n", "epoch", ",", "\n", "buffer_size", ",", "\n", ")", "\n", "# level 0: sub-samplers 1: batch_idx 2: batches", "\n", "self", ".", "_frozen_batches", "=", "tuple", "(", "[", "tuple", "(", "sub_batch", ")", "for", "sub_batch", "in", "batch_samplers", "]", ")", "\n", "self", ".", "step_size", "=", "mult_rate", "*", "num_shards", "\n", "\n", "self", ".", "lengths", "=", "[", "\n", "(", "len", "(", "x", ")", "//", "self", ".", "step_size", ")", "*", "self", ".", "step_size", "for", "x", "in", "self", ".", "frozen_batches", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.GroupedEpochBatchIterator.__len__": [[643, 645], ["sum"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "sum", "(", "self", ".", "lengths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.GroupedEpochBatchIterator.first_batch": [[646, 660], ["len", "Exception", "iterators.GroupedEpochBatchIterator.collate_fn"], "methods", ["None"], ["", "@", "property", "\n", "def", "first_batch", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "frozen_batches", ")", "==", "0", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"The dataset is empty. This could indicate \"", "\n", "\"that all elements in the dataset have been skipped. \"", "\n", "\"Try increasing the max number of allowed tokens or using \"", "\n", "\"a larger dataset.\"", "\n", ")", "\n", "\n", "", "if", "self", ".", "dataset", ".", "supports_fetch_outside_dataloader", ":", "\n", "            ", "return", "self", ".", "collate_fn", "(", "[", "self", ".", "dataset", "[", "i", "]", "for", "i", "in", "self", ".", "frozen_batches", "[", "0", "]", "[", "0", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "\"DUMMY\"", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators.GroupedEpochBatchIterator._get_iterator_for_epoch": [[661, 721], ["torch.utils.data.DataLoader", "iterators.CountingIterator", "list", "NotImplementedError", "iterators.GroupedEpochBatchIterator._get_iterator_for_epoch.return_full_batches"], "methods", ["None"], ["", "", "def", "_get_iterator_for_epoch", "(", "\n", "self", ",", "epoch", ",", "shuffle", ",", "fix_batches_to_gpus", "=", "False", ",", "offset", "=", "0", "\n", ")", ":", "\n", "        ", "def", "shuffle_batches", "(", "batches", ",", "seed", ")", ":", "\n", "            ", "with", "data_utils", ".", "numpy_seed", "(", "seed", ")", ":", "\n", "                ", "np", ".", "random", ".", "shuffle", "(", "batches", ")", "\n", "", "return", "batches", "\n", "\n", "", "def", "return_full_batches", "(", "batch_sets", ",", "seed", ",", "shuffle", ")", ":", "\n", "            ", "if", "shuffle", ":", "\n", "                ", "batch_sets", "=", "[", "shuffle_batches", "(", "list", "(", "x", ")", ",", "seed", ")", "for", "x", "in", "batch_sets", "]", "\n", "\n", "", "batch_sets", "=", "[", "\n", "batch_sets", "[", "i", "]", "[", ":", "self", ".", "lengths", "[", "i", "]", "]", "for", "i", "in", "range", "(", "len", "(", "batch_sets", ")", ")", "\n", "]", "\n", "batches", "=", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "batch_sets", ")", ")", "\n", "\n", "if", "shuffle", ":", "\n", "                ", "with", "data_utils", ".", "numpy_seed", "(", "seed", ")", ":", "\n", "                    ", "idx", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "batches", ")", "//", "self", ".", "step_size", ")", "\n", "if", "len", "(", "idx", ")", "*", "self", ".", "step_size", "!=", "len", "(", "batches", ")", ":", "\n", "                        ", "raise", "ValueError", "(", "\n", "\"ERROR: %d %d %d %d\"", "\n", "%", "(", "len", "(", "idx", ")", ",", "self", ".", "step_size", ",", "len", "(", "batches", ")", ",", "self", ".", "shard_id", ")", ",", "\n", "\":\"", ".", "join", "(", "[", "\"%d\"", "%", "x", "for", "x", "in", "self", ".", "lengths", "]", ")", ",", "\n", ")", "\n", "", "mini_shards", "=", "[", "\n", "batches", "[", "i", "*", "self", ".", "step_size", ":", "(", "i", "+", "1", ")", "*", "self", ".", "step_size", "]", "\n", "for", "i", "in", "idx", "\n", "]", "\n", "batches", "=", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "mini_shards", ")", ")", "\n", "\n", "", "", "return", "batches", "\n", "\n", "", "if", "self", ".", "_supports_prefetch", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"To be implemented\"", ")", "\n", "", "else", ":", "\n", "            ", "batches", "=", "return_full_batches", "(", "\n", "self", ".", "frozen_batches", ",", "self", ".", "seed", "+", "epoch", ",", "shuffle", "\n", ")", "\n", "batches", "=", "list", "(", "\n", "ShardedIterator", "(", "batches", ",", "self", ".", "num_shards", ",", "self", ".", "shard_id", ",", "fill_value", "=", "[", "]", ")", "\n", ")", "\n", "\n", "", "if", "offset", ">", "0", "and", "offset", ">=", "len", "(", "batches", ")", ":", "\n", "            ", "return", "None", "\n", "\n", "", "if", "self", ".", "num_workers", ">", "0", ":", "\n", "            ", "os", ".", "environ", "[", "\"PYTHONWARNINGS\"", "]", "=", "\"ignore:semaphore_tracker:UserWarning\"", "\n", "\n", "", "itr", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "self", ".", "dataset", ",", "\n", "collate_fn", "=", "self", ".", "collate_fn", ",", "\n", "batch_sampler", "=", "batches", "[", "offset", ":", "]", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", ")", "\n", "if", "self", ".", "buffer_size", ">", "0", ":", "\n", "            ", "itr", "=", "BufferedIterator", "(", "self", ".", "buffer_size", ",", "itr", ")", "\n", "\n", "", "return", "CountingIterator", "(", "itr", ",", "start", "=", "offset", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.iterators._chunk_iterator": [[467, 476], ["chunk.append", "len", "len"], "function", ["None"], ["", "", "def", "_chunk_iterator", "(", "itr", ",", "chunk_size", ")", ":", "\n", "    ", "chunk", "=", "[", "]", "\n", "for", "x", "in", "itr", ":", "\n", "        ", "chunk", ".", "append", "(", "x", ")", "\n", "if", "len", "(", "chunk", ")", "==", "chunk_size", ":", "\n", "            ", "yield", "chunk", "\n", "chunk", "=", "[", "]", "\n", "", "", "if", "len", "(", "chunk", ")", ">", "0", ":", "\n", "        ", "yield", "chunk", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.infer_language_pair": [[24, 32], ["os.listdir", "filename.split", "parts[].split", "len", "len", "parts[].split"], "function", ["None"], ["accept_language", "=", "None", ",", "\n", "user_defined_symbols", "=", "None", "\n", ")", ":", "\n", "# Train SentencePiece Model", "\n", "    ", "sp", ".", "SentencePieceTrainer", ".", "train", "(", "input", "=", "input_path", ",", "\n", "model_prefix", "=", "output_path_prefix", ",", "\n", "model_type", "=", "model_type", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "accept_language", "=", "accept_language", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.collate_tokens": [[34, 65], ["max", "values[].new().fill_", "enumerate", "max", "int", "data_utils.collate_tokens.copy_tensor"], "function", ["None"], ["unk_piece", "=", "UNK_TOKEN", ",", "unk_id", "=", "UNK_TOKEN_ID", ",", "\n", "bos_piece", "=", "BOS_TOKEN", ",", "bos_id", "=", "BOS_TOKEN_ID", ",", "\n", "eos_piece", "=", "EOS_TOKEN", ",", "eos_id", "=", "EOS_TOKEN_ID", ",", "\n", "pad_piece", "=", "PAD_TOKEN", ",", "pad_id", "=", "PAD_TOKEN_ID", ")", "\n", "# Export fairseq dictionary", "\n", "spm", "=", "sp", ".", "SentencePieceProcessor", "(", ")", "\n", "spm", ".", "Load", "(", "output_path_prefix", "+", "\".model\"", ")", "\n", "vocab", "=", "{", "i", ":", "spm", ".", "IdToPiece", "(", "i", ")", "for", "i", "in", "range", "(", "spm", ".", "GetPieceSize", "(", ")", ")", "}", "\n", "assert", "(", "\n", "vocab", ".", "get", "(", "UNK_TOKEN_ID", ")", "==", "UNK_TOKEN", "\n", "and", "vocab", ".", "get", "(", "PAD_TOKEN_ID", ")", "==", "PAD_TOKEN", "\n", "and", "vocab", ".", "get", "(", "BOS_TOKEN_ID", ")", "==", "BOS_TOKEN", "\n", "and", "vocab", ".", "get", "(", "EOS_TOKEN_ID", ")", "==", "EOS_TOKEN", "\n", ")", "\n", "vocab", "=", "{", "\n", "i", ":", "s", "\n", "for", "i", ",", "s", "in", "vocab", ".", "items", "(", ")", "\n", "if", "s", "not", "in", "{", "UNK_TOKEN", ",", "BOS_TOKEN", ",", "EOS_TOKEN", ",", "PAD_TOKEN", "}", "\n", "}", "\n", "with", "open", "(", "output_path_prefix", "+", "\".txt\"", ",", "\"w\"", ")", "as", "f_out", ":", "\n", "        ", "for", "_", ",", "s", "in", "sorted", "(", "vocab", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", ":", "\n", "            ", "f_out", ".", "write", "(", "f\"{s} 1\\n\"", ")", "\n", "\n", "\n", "", "", "", "def", "gen_config_yaml", "(", "\n", "data_root", ",", "\n", "spm_filename", ",", "\n", "yaml_filename", "=", "\"config.yaml\"", ",", "\n", "prepend_tgt_lang_tag", "=", "True", ",", "\n", "prepend_src_lang_tag", "=", "True", "\n", ")", ":", "\n", "    ", "data_root", "=", "op", ".", "abspath", "(", "data_root", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.load_indexed_dataset": [[67, 112], ["itertools.count", "indexed_dataset.get_indexed_dataset_to_local", "indexed_dataset.make_dataset", "logger.info", "datasets.append", "len", "indexed_dataset.infer_dataset_impl", "len", "ConcatDataset", "str", "len"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.get_indexed_dataset_to_local", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.make_dataset", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.infer_dataset_impl"], ["writer", ".", "set_audio_root", "(", "op", ".", "abspath", "(", "data_root", ")", ")", "\n", "writer", ".", "set_vocab_filename", "(", "spm_filename", ".", "replace", "(", "\".model\"", ",", "\".txt\"", ")", ")", "\n", "writer", ".", "set_input_channels", "(", "1", ")", "\n", "writer", ".", "set_bpe_tokenizer", "(", "\n", "{", "\n", "\"bpe\"", ":", "\"sentencepiece\"", ",", "\n", "\"sentencepiece_model\"", ":", "op", ".", "join", "(", "data_root", ",", "spm_filename", ")", ",", "\n", "}", "\n", ")", "\n", "writer", ".", "set_prepend_tgt_lang_tag", "(", "prepend_tgt_lang_tag", ")", "\n", "writer", ".", "set_prepend_src_lang_tag", "(", "prepend_src_lang_tag", ")", "\n", "writer", ".", "set_use_audio_input", "(", "True", ")", "\n", "writer", ".", "set_shuffle_dataset", "(", "True", ")", "\n", "writer", ".", "flush", "(", ")", "\n", "\n", "\n", "", "def", "load_df_from_tsv", "(", "path", ":", "str", ")", ":", "\n", "    ", "return", "pd", ".", "read_csv", "(", "\n", "path", ",", "\n", "sep", "=", "\"\\t\"", ",", "\n", "header", "=", "0", ",", "\n", "encoding", "=", "\"utf-8\"", ",", "\n", "escapechar", "=", "\"\\\\\"", ",", "\n", "quoting", "=", "csv", ".", "QUOTE_NONE", ",", "\n", "na_filter", "=", "False", ",", "\n", ")", "\n", "\n", "\n", "", "def", "save_df_to_tsv", "(", "dataframe", ",", "path", ")", ":", "\n", "    ", "dataframe", ".", "to_csv", "(", "\n", "path", ",", "\n", "sep", "=", "\"\\t\"", ",", "\n", "header", "=", "True", ",", "\n", "index", "=", "False", ",", "\n", "encoding", "=", "\"utf-8\"", ",", "\n", "escapechar", "=", "\"\\\\\"", ",", "\n", "quoting", "=", "csv", ".", "QUOTE_NONE", ",", "\n", ")", "\n", "\n", "\n", "", "def", "filter_manifest_df", "(", "\n", "df", ",", "is_train_split", "=", "False", ",", "extra_filters", "=", "None", ",", "min_n_frames", "=", "5", ",", "max_n_frames", "=", "3000", "\n", ")", ":", "\n", "    ", "filters", "=", "{", "\n", "\"no speech\"", ":", "df", "[", "\"audio\"", "]", "==", "\"\"", ",", "\n", "f\"short speech (<{min_n_frames} frames)\"", ":", "df", "[", "\"n_frames\"", "]", "<", "min_n_frames", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.numpy_seed": [[114, 129], ["numpy.random.get_state", "numpy.random.seed", "len", "int", "numpy.random.set_state", "hash"], "function", ["None"], ["}", "\n", "if", "is_train_split", ":", "\n", "        ", "filters", "[", "f\"long speech (>{max_n_frames} frames)\"", "]", "=", "df", "[", "\"n_frames\"", "]", ">", "max_n_frames", "\n", "", "if", "extra_filters", "is", "not", "None", ":", "\n", "        ", "filters", ".", "update", "(", "extra_filters", ")", "\n", "", "invalid", "=", "reduce", "(", "lambda", "x", ",", "y", ":", "x", "|", "y", ",", "filters", ".", "values", "(", ")", ")", "\n", "valid", "=", "~", "invalid", "\n", "print", "(", "\n", "\"| \"", "\n", "+", "\", \"", ".", "join", "(", "f\"{n}: {f.sum()}\"", "for", "n", ",", "f", "in", "filters", ".", "items", "(", ")", ")", "\n", "+", "f\", total {invalid.sum()} filtered, {valid.sum()} remained.\"", "\n", ")", "\n", "return", "df", "[", "valid", "]", "\n", "\n", "\n", "", "class", "S2TDataConfigWriter", "(", "object", ")", ":", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.collect_filtered": [[131, 146], ["function", "filtered.append"], "function", ["None"], ["DEFAULT_INPUT_FEAT_PER_CHANNEL", "=", "80", "\n", "DEFAULT_INPUT_CHANNELS", "=", "1", "\n", "\n", "def", "__init__", "(", "self", ",", "yaml_path", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "yaml", "\n", "", "except", "ImportError", ":", "\n", "            ", "print", "(", "\"Please install PyYAML to load YAML files for S2T data config\"", ")", "\n", "", "self", ".", "yaml", "=", "yaml", "\n", "self", ".", "yaml_path", "=", "yaml_path", "\n", "self", ".", "config", "=", "{", "}", "\n", "\n", "", "def", "flush", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "yaml_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "self", ".", "yaml", ".", "dump", "(", "self", ".", "config", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.data_utils._filter_by_size_dynamic": [[148, 185], ["data_utils.collect_filtered", "numpy.fromiter", "isinstance", "isinstance", "isinstance", "isinstance", "max", "size_fn", "size_fn", "isinstance", "all", "all", "set", "set", "isinstance", "isinstance", "all", "isinstance", "all", "max_positions.keys", "size_fn.keys", "all", "size_fn", "size_fn", "zip", "data_utils._filter_by_size_dynamic.compare_leq"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils.collect_filtered"], ["        ", "self", ".", "config", "[", "\"audio_root\"", "]", "=", "audio_root", "\n", "\n", "", "def", "set_vocab_filename", "(", "self", ",", "vocab_filename", "=", "\"dict.txt\"", ")", ":", "\n", "        ", "self", ".", "config", "[", "\"vocab_filename\"", "]", "=", "vocab_filename", "\n", "\n", "", "def", "set_specaugment", "(", "\n", "self", ",", "\n", "time_wrap_w", ":", "int", ",", "\n", "freq_mask_n", ":", "int", ",", "\n", "freq_mask_f", ":", "int", ",", "\n", "time_mask_n", ":", "int", ",", "\n", "time_mask_t", ":", "int", ",", "\n", "time_mask_p", ":", "float", ",", "\n", ")", ":", "\n", "        ", "self", ".", "config", "[", "\"specaugment\"", "]", "=", "{", "\n", "\"time_wrap_W\"", ":", "time_wrap_w", ",", "\n", "\"freq_mask_N\"", ":", "freq_mask_n", ",", "\n", "\"freq_mask_F\"", ":", "freq_mask_f", ",", "\n", "\"time_mask_N\"", ":", "time_mask_n", ",", "\n", "\"time_mask_T\"", ":", "time_mask_t", ",", "\n", "\"time_mask_p\"", ":", "time_mask_p", ",", "\n", "}", "\n", "\n", "", "def", "set_specaugment_lb_policy", "(", "self", ")", ":", "\n", "        ", "self", ".", "set_specaugment", "(", "\n", "time_wrap_w", "=", "0", ",", "\n", "freq_mask_n", "=", "1", ",", "\n", "freq_mask_f", "=", "27", ",", "\n", "time_mask_n", "=", "1", ",", "\n", "time_mask_t", "=", "100", ",", "\n", "time_mask_p", "=", "1.0", ",", "\n", ")", "\n", "\n", "", "def", "set_specaugment_ld_policy", "(", "self", ")", ":", "\n", "        ", "self", ".", "set_specaugment", "(", "\n", "time_wrap_w", "=", "0", ",", "\n", "freq_mask_n", "=", "2", ",", "\n", "freq_mask_f", "=", "27", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.filter_by_size": [[187, 238], ["warnings.warn", "isinstance", "isinstance", "data_utils._filter_by_size_dynamic", "Exception", "len", "logger.warning", "hasattr", "isinstance", "indices[].tolist", "len", "hasattr", "isinstance", "indices[].tolist", "data_utils._filter_by_size_dynamic", "dataset.size", "len", "len"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils._filter_by_size_dynamic", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils._filter_by_size_dynamic", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["time_mask_t", "=", "100", ",", "\n", "time_mask_p", "=", "1.0", ",", "\n", ")", "\n", "\n", "", "def", "set_specaugment_sm_policy", "(", "self", ")", ":", "\n", "        ", "self", ".", "set_specaugment", "(", "\n", "time_wrap_w", "=", "0", ",", "\n", "freq_mask_n", "=", "2", ",", "\n", "freq_mask_f", "=", "15", ",", "\n", "time_mask_n", "=", "2", ",", "\n", "time_mask_t", "=", "70", ",", "\n", "time_mask_p", "=", "0.2", ",", "\n", ")", "\n", "\n", "", "def", "set_specaugment_ss_policy", "(", "self", ")", ":", "\n", "        ", "self", ".", "set_specaugment", "(", "\n", "time_wrap_w", "=", "0", ",", "\n", "freq_mask_n", "=", "2", ",", "\n", "freq_mask_f", "=", "27", ",", "\n", "time_mask_n", "=", "2", ",", "\n", "time_mask_t", "=", "70", ",", "\n", "time_mask_p", "=", "0.2", ",", "\n", ")", "\n", "\n", "", "def", "set_input_channels", "(", "self", ",", "input_channels", "=", "1", ")", ":", "\n", "        ", "self", ".", "config", "[", "\"input_channels\"", "]", "=", "input_channels", "\n", "\n", "", "def", "set_input_feat_per_channel", "(", "self", ",", "input_feat_per_channel", "=", "80", ")", ":", "\n", "        ", "self", ".", "config", "[", "\"input_feat_per_channel\"", "]", "=", "input_feat_per_channel", "\n", "\n", "", "def", "set_bpe_tokenizer", "(", "self", ",", "bpe_tokenizer", ":", "Dict", "[", "str", ",", "Any", "]", ")", ":", "\n", "        ", "self", ".", "config", "[", "\"bpe_tokenizer\"", "]", "=", "bpe_tokenizer", "\n", "\n", "", "def", "set_feature_transforms", "(", "self", ",", "split", ",", "transforms", ":", "List", "[", "str", "]", ")", ":", "\n", "        ", "if", "\"transforms\"", "not", "in", "self", ".", "config", ":", "\n", "            ", "self", ".", "config", "[", "\"transforms\"", "]", "=", "{", "}", "\n", "", "self", ".", "config", "[", "\"transforms\"", "]", "[", "split", "]", "=", "transforms", "\n", "\n", "", "def", "set_prepend_tgt_lang_tag", "(", "self", ",", "flag", "=", "True", ")", ":", "\n", "        ", "self", ".", "config", "[", "\"prepend_tgt_lang_tag\"", "]", "=", "flag", "\n", "\n", "", "def", "set_prepend_src_lang_tag", "(", "self", ",", "flag", "=", "True", ")", ":", "\n", "        ", "self", ".", "config", "[", "\"prepend_src_lang_tag\"", "]", "=", "flag", "\n", "\n", "", "def", "set_sampling_alpha", "(", "self", ",", "sampling_alpha", "=", "1.0", ")", ":", "\n", "        ", "self", ".", "config", "[", "\"sampling_alpha\"", "]", "=", "sampling_alpha", "\n", "\n", "", "def", "set_use_audio_input", "(", "self", ",", "flag", "=", "True", ")", ":", "\n", "        ", "self", ".", "config", "[", "\"use_audio_input\"", "]", "=", "flag", "\n", "\n", "", "def", "set_shuffle_dataset", "(", "self", ",", "flag", "=", "True", ")", ":", "\n", "        ", "self", ".", "config", "[", "\"shuffle\"", "]", "=", "flag", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.filter_paired_dataset_indices_by_size": [[240, 274], ["type", "len", "ignored.tolist"], "function", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.batch_by_size": [[276, 338], ["isinstance", "numpy.fromiter", "batch_by_size_fast", "numpy.array", "numpy.lexsort", "batch_fixed_shapes_fast", "ImportError", "fixed_shapes[].argsort", "fixed_shapes[].argsort"], "function", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.post_process": [[340, 352], ["sentence.replace().replace().strip.replace().replace().strip", "sentence.replace().replace().strip.replace().replace().strip", "sentence.replace().replace().strip.replace().replace", "sentence.replace().replace().strip.replace().replace().strip", "sentence.replace().replace().strip.replace().replace", "sentence.replace().replace().strip.replace().replace().strip", "sentence.replace().replace().strip.replace", "sentence.replace().replace().strip.replace().replace", "sentence.replace().replace().strip.replace", "sentence.replace().replace().strip.replace().replace", "sentence.replace().replace().strip.replace", "sentence.replace().replace().strip.replace"], "function", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.compute_mask_indices": [[354, 479], ["numpy.full", "int", "max", "range", "min", "enumerate", "mask_idcs.append", "numpy.random.rand", "int", "max", "numpy.full", "sum", "min", "min", "sorted", "numpy.asarray", "min", "numpy.random.choice", "numpy.asarray", "numpy.unique", "len", "len", "numpy.random.choice", "float", "padding_mask[].long().sum().item", "numpy.random.randint", "numpy.random.randint", "np.random.choice.extend", "numpy.fromiter", "numpy.sum", "numpy.random.choice", "parts.pop", "parts.extend", "numpy.random.rand", "numpy.random.normal", "new_parts.append", "new_parts.append", "numpy.sum", "len", "data_utils.compute_mask_indices.arrange"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], []], "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.get_mem_usage": [[481, 489], ["psutil.virtual_memory", "psutil.virtual_memory"], "function", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.lengths_to_padding_mask": [[491, 496], ["torch.arange().to().view", "lens.size", "torch.max().item", "torch.arange().to().view.expand", "lens.view().expand", "torch.arange().to", "torch.max", "lens.view", "torch.arange"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], []], "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.lengths_to_mask": [[498, 500], ["data_utils.lengths_to_padding_mask"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils.lengths_to_padding_mask"], []], "home.repos.pwc.inspect_result.reneeye_const.data.add_target_dataset.AddTargetDataset.__init__": [[12, 29], ["BaseWrapperDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "labels", ",", "\n", "pad", ",", "\n", "eos", ",", "\n", "batch_targets", ",", "\n", "process_label", "=", "None", ",", "\n", "add_to_input", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ")", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "batch_targets", "=", "batch_targets", "\n", "self", ".", "pad", "=", "pad", "\n", "self", ".", "eos", "=", "eos", "\n", "self", ".", "process_label", "=", "process_label", "\n", "self", ".", "add_to_input", "=", "add_to_input", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.add_target_dataset.AddTargetDataset.get_label": [[30, 35], ["add_target_dataset.AddTargetDataset.process_label"], "methods", ["None"], ["", "def", "get_label", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "labels", "[", "index", "]", "\n", "if", "self", ".", "process_label", "is", "None", "\n", "else", "self", ".", "process_label", "(", "self", ".", "labels", "[", "index", "]", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.add_target_dataset.AddTargetDataset.__getitem__": [[37, 41], ["add_target_dataset.AddTargetDataset.get_label"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.add_target_dataset.AddTargetDataset.get_label"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "item", "=", "self", ".", "dataset", "[", "index", "]", "\n", "item", "[", "\"label\"", "]", "=", "self", ".", "get_label", "(", "index", ")", "\n", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.add_target_dataset.AddTargetDataset.size": [[42, 46], ["add_target_dataset.AddTargetDataset.dataset.size", "len", "add_target_dataset.AddTargetDataset.get_label"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.data.add_target_dataset.AddTargetDataset.get_label"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "sz", "=", "self", ".", "dataset", ".", "size", "(", "index", ")", "\n", "own_sz", "=", "len", "(", "self", ".", "get_label", "(", "index", ")", ")", "\n", "return", "(", "sz", ",", "own_sz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.add_target_dataset.AddTargetDataset.collater": [[47, 71], ["add_target_dataset.AddTargetDataset.dataset.collater", "set", "len", "collated[].tolist", "torch.LongTensor", "data_utils.collate_tokens", "collated[].sum().item", "sum", "data_utils.collate_tokens.new_full", "torch.cat().long", "torch.cat().long", "data_utils.collate_tokens.size", "len", "collated[].sum", "len", "data_utils.collate_tokens.size", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.collater", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.collate_tokens", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "collated", "=", "self", ".", "dataset", ".", "collater", "(", "samples", ")", "\n", "if", "len", "(", "collated", ")", "==", "0", ":", "\n", "            ", "return", "collated", "\n", "", "indices", "=", "set", "(", "collated", "[", "\"id\"", "]", ".", "tolist", "(", ")", ")", "\n", "target", "=", "[", "s", "[", "\"label\"", "]", "for", "s", "in", "samples", "if", "s", "[", "\"id\"", "]", "in", "indices", "]", "\n", "\n", "if", "self", ".", "batch_targets", ":", "\n", "            ", "collated", "[", "\"target_lengths\"", "]", "=", "torch", ".", "LongTensor", "(", "[", "len", "(", "t", ")", "for", "t", "in", "target", "]", ")", "\n", "target", "=", "data_utils", ".", "collate_tokens", "(", "target", ",", "pad_idx", "=", "self", ".", "pad", ",", "left_pad", "=", "False", ")", "\n", "collated", "[", "\"ntokens\"", "]", "=", "collated", "[", "\"target_lengths\"", "]", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "            ", "collated", "[", "\"ntokens\"", "]", "=", "sum", "(", "[", "len", "(", "t", ")", "for", "t", "in", "target", "]", ")", "\n", "\n", "", "collated", "[", "\"target\"", "]", "=", "target", "\n", "\n", "if", "self", ".", "add_to_input", ":", "\n", "            ", "eos", "=", "target", ".", "new_full", "(", "(", "target", ".", "size", "(", "0", ")", ",", "1", ")", ",", "self", ".", "eos", ")", "\n", "collated", "[", "\"target\"", "]", "=", "torch", ".", "cat", "(", "[", "target", ",", "eos", "]", ",", "dim", "=", "-", "1", ")", ".", "long", "(", ")", "\n", "collated", "[", "\"net_input\"", "]", "[", "\"prev_output_tokens\"", "]", "=", "torch", ".", "cat", "(", "\n", "[", "eos", ",", "target", "]", ",", "dim", "=", "-", "1", "\n", ")", ".", "long", "(", ")", "\n", "collated", "[", "\"ntokens\"", "]", "+=", "target", ".", "size", "(", "0", ")", "\n", "", "return", "collated", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.append_token_dataset.AppendTokenDataset.__init__": [[13, 20], ["BaseWrapperDataset.__init__", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "token", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ")", "\n", "self", ".", "token", "=", "token", "\n", "if", "token", "is", "not", "None", ":", "\n", "            ", "self", ".", "_sizes", "=", "np", ".", "array", "(", "dataset", ".", "sizes", ")", "+", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "_sizes", "=", "dataset", ".", "sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.append_token_dataset.AppendTokenDataset.__getitem__": [[21, 26], ["torch.cat", "torch.cat.new"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "item", "=", "self", ".", "dataset", "[", "idx", "]", "\n", "if", "self", ".", "token", "is", "not", "None", ":", "\n", "            ", "item", "=", "torch", ".", "cat", "(", "[", "item", ",", "item", ".", "new", "(", "[", "self", ".", "token", "]", ")", "]", ")", "\n", "", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.append_token_dataset.AppendTokenDataset.sizes": [[27, 30], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.append_token_dataset.AppendTokenDataset.num_tokens": [[31, 36], ["append_token_dataset.AppendTokenDataset.dataset.num_tokens"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.num_tokens"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "n", "=", "self", ".", "dataset", ".", "num_tokens", "(", "index", ")", "\n", "if", "self", ".", "token", "is", "not", "None", ":", "\n", "            ", "n", "+=", "1", "\n", "", "return", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.append_token_dataset.AppendTokenDataset.size": [[37, 42], ["append_token_dataset.AppendTokenDataset.dataset.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "n", "=", "self", ".", "dataset", ".", "size", "(", "index", ")", "\n", "if", "self", ".", "token", "is", "not", "None", ":", "\n", "            ", "n", "+=", "1", "\n", "", "return", "n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.__init__": [[21, 42], ["dictionary.Dictionary.add_symbol", "dictionary.Dictionary.add_symbol", "dictionary.Dictionary.add_symbol", "dictionary.Dictionary.add_symbol", "len", "dictionary.Dictionary.add_symbol"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol"], ["def", "__init__", "(", "\n", "self", ",", "\n", "*", ",", "# begin keyword-only arguments", "\n", "bos", "=", "\"<s>\"", ",", "\n", "pad", "=", "\"<pad>\"", ",", "\n", "eos", "=", "\"</s>\"", ",", "\n", "unk", "=", "\"<unk>\"", ",", "\n", "extra_special_symbols", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "bos_word", ",", "self", ".", "unk_word", ",", "self", ".", "pad_word", ",", "self", ".", "eos_word", "=", "bos", ",", "unk", ",", "pad", ",", "eos", "\n", "self", ".", "symbols", "=", "[", "]", "\n", "self", ".", "count", "=", "[", "]", "\n", "self", ".", "indices", "=", "{", "}", "\n", "self", ".", "bos_index", "=", "self", ".", "add_symbol", "(", "bos", ")", "\n", "self", ".", "pad_index", "=", "self", ".", "add_symbol", "(", "pad", ")", "\n", "self", ".", "eos_index", "=", "self", ".", "add_symbol", "(", "eos", ")", "\n", "self", ".", "unk_index", "=", "self", ".", "add_symbol", "(", "unk", ")", "\n", "if", "extra_special_symbols", ":", "\n", "            ", "for", "s", "in", "extra_special_symbols", ":", "\n", "                ", "self", ".", "add_symbol", "(", "s", ")", "\n", "", "", "self", ".", "nspecial", "=", "len", "(", "self", ".", "symbols", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.__eq__": [[43, 45], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "indices", "==", "other", ".", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.__getitem__": [[46, 50], ["len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "idx", "<", "len", "(", "self", ".", "symbols", ")", ":", "\n", "            ", "return", "self", ".", "symbols", "[", "idx", "]", "\n", "", "return", "self", ".", "unk_word", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.__len__": [[51, 54], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the number of symbols in the dictionary\"\"\"", "\n", "return", "len", "(", "self", ".", "symbols", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.__contains__": [[55, 57], ["None"], "methods", ["None"], ["", "def", "__contains__", "(", "self", ",", "sym", ")", ":", "\n", "        ", "return", "sym", "in", "self", ".", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.index": [[58, 64], ["isinstance"], "methods", ["None"], ["", "def", "index", "(", "self", ",", "sym", ")", ":", "\n", "        ", "\"\"\"Returns the index of the specified symbol\"\"\"", "\n", "assert", "isinstance", "(", "sym", ",", "str", ")", "\n", "if", "sym", "in", "self", ".", "indices", ":", "\n", "            ", "return", "self", ".", "indices", "[", "sym", "]", "\n", "", "return", "self", ".", "unk_index", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.string": [[65, 106], ["set", "set.add", "hasattr", "fairseq.data.data_utils.post_process", "torch.is_tensor", "dictionary.Dictionary.eos", "set.add", "tensor.dim", "dictionary.Dictionary.unk", "dictionary.Dictionary.bos", "dictionary.Dictionary.string.token_string"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.post_process", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos"], ["", "def", "string", "(", "\n", "self", ",", "\n", "tensor", ",", "\n", "bpe_symbol", "=", "None", ",", "\n", "escape_unk", "=", "False", ",", "\n", "extra_symbols_to_ignore", "=", "None", ",", "\n", "unk_string", "=", "None", ",", "\n", "include_eos", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Helper for converting a tensor of token indices to a string.\n\n        Can optionally remove BPE symbols or escape <unk> words.\n        \"\"\"", "\n", "if", "torch", ".", "is_tensor", "(", "tensor", ")", "and", "tensor", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "return", "\"\\n\"", ".", "join", "(", "\n", "self", ".", "string", "(", "t", ",", "bpe_symbol", ",", "escape_unk", ",", "extra_symbols_to_ignore", ",", "include_eos", "=", "include_eos", ")", "\n", "for", "t", "in", "tensor", "\n", ")", "\n", "\n", "", "extra_symbols_to_ignore", "=", "set", "(", "extra_symbols_to_ignore", "or", "[", "]", ")", "\n", "extra_symbols_to_ignore", ".", "add", "(", "self", ".", "eos", "(", ")", ")", "\n", "\n", "def", "token_string", "(", "i", ")", ":", "\n", "            ", "if", "i", "==", "self", ".", "unk", "(", ")", ":", "\n", "                ", "if", "unk_string", "is", "not", "None", ":", "\n", "                    ", "return", "unk_string", "\n", "", "else", ":", "\n", "                    ", "return", "self", ".", "unk_string", "(", "escape_unk", ")", "\n", "", "", "else", ":", "\n", "                ", "return", "self", "[", "i", "]", "\n", "\n", "", "", "if", "hasattr", "(", "self", ",", "\"bos_index\"", ")", ":", "\n", "            ", "extra_symbols_to_ignore", ".", "add", "(", "self", ".", "bos", "(", ")", ")", "\n", "\n", "", "sent", "=", "\" \"", ".", "join", "(", "\n", "token_string", "(", "i", ")", "\n", "for", "i", "in", "tensor", "\n", "if", "utils", ".", "item", "(", "i", ")", "not", "in", "extra_symbols_to_ignore", "\n", ")", "\n", "\n", "return", "data_utils", ".", "post_process", "(", "sent", ",", "bpe_symbol", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk_string": [[107, 113], ["None"], "methods", ["None"], ["", "def", "unk_string", "(", "self", ",", "escape", "=", "False", ")", ":", "\n", "        ", "\"\"\"Return unknown string, optionally escaped as: <<unk>>\"\"\"", "\n", "if", "escape", ":", "\n", "            ", "return", "\"<{}>\"", ".", "format", "(", "self", ".", "unk_word", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "unk_word", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol": [[114, 126], ["len", "dictionary.Dictionary.symbols.append", "dictionary.Dictionary.count.append"], "methods", ["None"], ["", "", "def", "add_symbol", "(", "self", ",", "word", ",", "n", "=", "1", ",", "overwrite", "=", "False", ")", ":", "\n", "        ", "\"\"\"Adds a word to the dictionary\"\"\"", "\n", "if", "word", "in", "self", ".", "indices", "and", "not", "overwrite", ":", "\n", "            ", "idx", "=", "self", ".", "indices", "[", "word", "]", "\n", "self", ".", "count", "[", "idx", "]", "=", "self", ".", "count", "[", "idx", "]", "+", "n", "\n", "return", "idx", "\n", "", "else", ":", "\n", "            ", "idx", "=", "len", "(", "self", ".", "symbols", ")", "\n", "self", ".", "indices", "[", "word", "]", "=", "idx", "\n", "self", ".", "symbols", ".", "append", "(", "word", ")", "\n", "self", ".", "count", ".", "append", "(", "n", ")", "\n", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update": [[127, 139], ["len", "dictionary.Dictionary.symbols.append", "dictionary.Dictionary.count.append"], "methods", ["None"], ["", "", "def", "update", "(", "self", ",", "new_dict", ")", ":", "\n", "        ", "\"\"\"Updates counts from new dictionary.\"\"\"", "\n", "for", "word", "in", "new_dict", ".", "symbols", ":", "\n", "            ", "idx2", "=", "new_dict", ".", "indices", "[", "word", "]", "\n", "if", "word", "in", "self", ".", "indices", ":", "\n", "                ", "idx", "=", "self", ".", "indices", "[", "word", "]", "\n", "self", ".", "count", "[", "idx", "]", "=", "self", ".", "count", "[", "idx", "]", "+", "new_dict", ".", "count", "[", "idx2", "]", "\n", "", "else", ":", "\n", "                ", "idx", "=", "len", "(", "self", ".", "symbols", ")", "\n", "self", ".", "indices", "[", "word", "]", "=", "idx", "\n", "self", ".", "symbols", ".", "append", "(", "word", ")", "\n", "self", ".", "count", ".", "append", "(", "new_dict", ".", "count", "[", "idx2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.finalize": [[140, 178], ["dict", "collections.Counter", "collections.Counter.most_common", "list", "list", "dictionary.Dictionary.pad_to_multiple_", "len", "zip", "dict", "len", "len", "range", "sorted", "len", "new_symbols.append", "new_count.append", "zip"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad_to_multiple_"], ["", "", "", "def", "finalize", "(", "self", ",", "threshold", "=", "-", "1", ",", "nwords", "=", "-", "1", ",", "padding_factor", "=", "8", ")", ":", "\n", "        ", "\"\"\"Sort symbols by frequency in descending order, ignoring special ones.\n\n        Args:\n            - threshold defines the minimum word count\n            - nwords defines the total number of words in the final dictionary,\n                including special symbols\n            - padding_factor can be used to pad the dictionary size to be a\n                multiple of 8, which is important on some hardware (e.g., Nvidia\n                Tensor Cores).\n        \"\"\"", "\n", "if", "nwords", "<=", "0", ":", "\n", "            ", "nwords", "=", "len", "(", "self", ")", "\n", "\n", "", "new_indices", "=", "dict", "(", "zip", "(", "self", ".", "symbols", "[", ":", "self", ".", "nspecial", "]", ",", "range", "(", "self", ".", "nspecial", ")", ")", ")", "\n", "new_symbols", "=", "self", ".", "symbols", "[", ":", "self", ".", "nspecial", "]", "\n", "new_count", "=", "self", ".", "count", "[", ":", "self", ".", "nspecial", "]", "\n", "\n", "c", "=", "Counter", "(", "\n", "dict", "(", "\n", "sorted", "(", "zip", "(", "self", ".", "symbols", "[", "self", ".", "nspecial", ":", "]", ",", "self", ".", "count", "[", "self", ".", "nspecial", ":", "]", ")", ")", "\n", ")", "\n", ")", "\n", "for", "symbol", ",", "count", "in", "c", ".", "most_common", "(", "nwords", "-", "self", ".", "nspecial", ")", ":", "\n", "            ", "if", "count", ">=", "threshold", ":", "\n", "                ", "new_indices", "[", "symbol", "]", "=", "len", "(", "new_symbols", ")", "\n", "new_symbols", ".", "append", "(", "symbol", ")", "\n", "new_count", ".", "append", "(", "count", ")", "\n", "", "else", ":", "\n", "                ", "break", "\n", "\n", "", "", "assert", "len", "(", "new_symbols", ")", "==", "len", "(", "new_indices", ")", "\n", "\n", "self", ".", "count", "=", "list", "(", "new_count", ")", "\n", "self", ".", "symbols", "=", "list", "(", "new_symbols", ")", "\n", "self", ".", "indices", "=", "new_indices", "\n", "\n", "self", ".", "pad_to_multiple_", "(", "padding_factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad_to_multiple_": [[179, 187], ["dictionary.Dictionary.add_symbol", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol"], ["", "def", "pad_to_multiple_", "(", "self", ",", "padding_factor", ")", ":", "\n", "        ", "\"\"\"Pad Dictionary size to be a multiple of *padding_factor*.\"\"\"", "\n", "if", "padding_factor", ">", "1", ":", "\n", "            ", "i", "=", "0", "\n", "while", "len", "(", "self", ")", "%", "padding_factor", "!=", "0", ":", "\n", "                ", "symbol", "=", "\"madeupword{:04d}\"", ".", "format", "(", "i", ")", "\n", "self", ".", "add_symbol", "(", "symbol", ",", "n", "=", "0", ")", "\n", "i", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos": [[188, 191], ["None"], "methods", ["None"], ["", "", "", "def", "bos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Helper to get index of beginning-of-sentence symbol\"\"\"", "\n", "return", "self", ".", "bos_index", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad": [[192, 195], ["None"], "methods", ["None"], ["", "def", "pad", "(", "self", ")", ":", "\n", "        ", "\"\"\"Helper to get index of pad symbol\"\"\"", "\n", "return", "self", ".", "pad_index", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos": [[196, 199], ["None"], "methods", ["None"], ["", "def", "eos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Helper to get index of end-of-sentence symbol\"\"\"", "\n", "return", "self", ".", "eos_index", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk": [[200, 203], ["None"], "methods", ["None"], ["", "def", "unk", "(", "self", ")", ":", "\n", "        ", "\"\"\"Helper to get index of unk symbol\"\"\"", "\n", "return", "self", ".", "unk_index", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load": [[204, 217], ["cls", "cls.add_from_file"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_from_file"], ["", "@", "classmethod", "\n", "def", "load", "(", "cls", ",", "f", ")", ":", "\n", "        ", "\"\"\"Loads the dictionary from a text file with the format:\n\n        ```\n        <symbol0> <count0>\n        <symbol1> <count1>\n        ...\n        ```\n        \"\"\"", "\n", "d", "=", "cls", "(", ")", "\n", "d", ".", "add_from_file", "(", "f", ")", "\n", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_from_file": [[218, 261], ["isinstance", "f.readlines", "dictionary.Dictionary._load_meta", "line.rstrip().rsplit", "int", "dictionary.Dictionary.add_symbol", "open", "dictionary.Dictionary.add_from_file", "Exception", "line.rsplit", "RuntimeError", "ValueError", "fairseq.file_io.PathManager.get_local_path", "line.rstrip"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary._load_meta", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_from_file", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.get_local_path"], ["", "def", "add_from_file", "(", "self", ",", "f", ")", ":", "\n", "        ", "\"\"\"\n        Loads a pre-existing dictionary from a text file and adds its symbols\n        to this instance.\n        \"\"\"", "\n", "if", "isinstance", "(", "f", ",", "str", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "with", "open", "(", "PathManager", ".", "get_local_path", "(", "f", ")", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fd", ":", "\n", "                    ", "self", ".", "add_from_file", "(", "fd", ")", "\n", "", "", "except", "FileNotFoundError", "as", "fnfe", ":", "\n", "                ", "raise", "fnfe", "\n", "", "except", "UnicodeError", ":", "\n", "                ", "raise", "Exception", "(", "\n", "\"Incorrect encoding detected in {}, please \"", "\n", "\"rebuild the dataset\"", ".", "format", "(", "f", ")", "\n", ")", "\n", "", "return", "\n", "\n", "", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "indices_start_line", "=", "self", ".", "_load_meta", "(", "lines", ")", "\n", "\n", "for", "line", "in", "lines", "[", "indices_start_line", ":", "]", ":", "\n", "            ", "try", ":", "\n", "                ", "line", ",", "field", "=", "line", ".", "rstrip", "(", ")", ".", "rsplit", "(", "\" \"", ",", "1", ")", "\n", "if", "field", "==", "\"#fairseq:overwrite\"", ":", "\n", "                    ", "overwrite", "=", "True", "\n", "line", ",", "field", "=", "line", ".", "rsplit", "(", "\" \"", ",", "1", ")", "\n", "", "else", ":", "\n", "                    ", "overwrite", "=", "False", "\n", "", "count", "=", "int", "(", "field", ")", "\n", "word", "=", "line", "\n", "if", "word", "in", "self", "and", "not", "overwrite", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\n", "\"Duplicate word found when loading Dictionary: '{}'. \"", "\n", "\"Duplicate words can overwrite earlier ones by adding the \"", "\n", "\"#fairseq:overwrite flag at the end of the corresponding row \"", "\n", "\"in the dictionary file. If using the Camembert model, please \"", "\n", "\"download an updated copy of the model file.\"", ".", "format", "(", "word", ")", "\n", ")", "\n", "", "self", ".", "add_symbol", "(", "word", ",", "n", "=", "count", ",", "overwrite", "=", "overwrite", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Incorrect dictionary format, expected '<token> <cnt> [flags]'\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary._save": [[263, 270], ["isinstance", "fairseq.file_io.PathManager.mkdirs", "print", "os.path.dirname", "fairseq.file_io.PathManager.open", "dictionary.Dictionary.save"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.mkdirs", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.save"], ["", "", "", "def", "_save", "(", "self", ",", "f", ",", "kv_iterator", ")", ":", "\n", "        ", "if", "isinstance", "(", "f", ",", "str", ")", ":", "\n", "            ", "PathManager", ".", "mkdirs", "(", "os", ".", "path", ".", "dirname", "(", "f", ")", ")", "\n", "with", "PathManager", ".", "open", "(", "f", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fd", ":", "\n", "                ", "return", "self", ".", "save", "(", "fd", ")", "\n", "", "", "for", "k", ",", "v", "in", "kv_iterator", ":", "\n", "            ", "print", "(", "\"{} {}\"", ".", "format", "(", "k", ",", "v", ")", ",", "file", "=", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary._get_meta": [[271, 273], ["None"], "methods", ["None"], ["", "", "def", "_get_meta", "(", "self", ")", ":", "\n", "        ", "return", "[", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary._load_meta": [[274, 276], ["None"], "methods", ["None"], ["", "def", "_load_meta", "(", "self", ",", "lines", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.save": [[277, 285], ["dictionary.Dictionary._get_meta", "dictionary.Dictionary._save", "zip"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary._get_meta", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary._save"], ["", "def", "save", "(", "self", ",", "f", ")", ":", "\n", "        ", "\"\"\"Stores dictionary into a text file\"\"\"", "\n", "ex_keys", ",", "ex_vals", "=", "self", ".", "_get_meta", "(", ")", "\n", "self", ".", "_save", "(", "\n", "f", ",", "\n", "zip", "(", "\n", "ex_keys", "+", "self", ".", "symbols", "[", "self", ".", "nspecial", ":", "]", ",", "\n", "ex_vals", "+", "self", ".", "count", "[", "self", ".", "nspecial", ":", "]", ",", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.dummy_sentence": [[288, 292], ["torch.Tensor().uniform_().long", "dictionary.Dictionary.eos", "torch.Tensor().uniform_", "len", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "def", "dummy_sentence", "(", "self", ",", "length", ")", ":", "\n", "        ", "t", "=", "torch", ".", "Tensor", "(", "length", ")", ".", "uniform_", "(", "self", ".", "nspecial", "+", "1", ",", "len", "(", "self", ")", ")", ".", "long", "(", ")", "\n", "t", "[", "-", "1", "]", "=", "self", ".", "eos", "(", ")", "\n", "return", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.encode_line": [[293, 319], ["line_tokenizer", "len", "torch.IntTensor", "enumerate", "list", "reversed", "dictionary.Dictionary.add_symbol", "dictionary.Dictionary.index", "consumer"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.index"], ["", "def", "encode_line", "(", "\n", "self", ",", "\n", "line", ",", "\n", "line_tokenizer", "=", "tokenize_line", ",", "\n", "add_if_not_exist", "=", "True", ",", "\n", "consumer", "=", "None", ",", "\n", "append_eos", "=", "True", ",", "\n", "reverse_order", "=", "False", ",", "\n", ")", ":", "\n", "        ", "words", "=", "line_tokenizer", "(", "line", ")", "\n", "if", "reverse_order", ":", "\n", "            ", "words", "=", "list", "(", "reversed", "(", "words", ")", ")", "\n", "", "nwords", "=", "len", "(", "words", ")", "\n", "ids", "=", "torch", ".", "IntTensor", "(", "nwords", "+", "1", "if", "append_eos", "else", "nwords", ")", "\n", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "words", ")", ":", "\n", "            ", "if", "add_if_not_exist", ":", "\n", "                ", "idx", "=", "self", ".", "add_symbol", "(", "word", ")", "\n", "", "else", ":", "\n", "                ", "idx", "=", "self", ".", "index", "(", "word", ")", "\n", "", "if", "consumer", "is", "not", "None", ":", "\n", "                ", "consumer", "(", "word", ",", "idx", ")", "\n", "", "ids", "[", "i", "]", "=", "idx", "\n", "", "if", "append_eos", ":", "\n", "            ", "ids", "[", "nwords", "]", "=", "self", ".", "eos_index", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary._add_file_to_dictionary_single_worker": [[320, 342], ["collections.Counter", "open", "f.seek", "f.readline", "fairseq.file_io.PathManager.get_local_path", "os.fstat", "fairseq.binarizer.safe_readline", "tokenize", "collections.Counter.update", "f.readline", "f.fileno", "collections.Counter.update", "f.tell"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.get_local_path", "home.repos.pwc.inspect_result.reneeye_const.fairseq.binarizer.safe_readline", "home.repos.pwc.inspect_result.reneeye_const.scoring.tokenizer.EvaluationTokenizer.tokenize", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update"], ["", "@", "staticmethod", "\n", "def", "_add_file_to_dictionary_single_worker", "(", "\n", "filename", ",", "tokenize", ",", "eos_word", ",", "worker_id", "=", "0", ",", "num_workers", "=", "1", "\n", ")", ":", "\n", "        ", "counter", "=", "Counter", "(", ")", "\n", "with", "open", "(", "PathManager", ".", "get_local_path", "(", "filename", ")", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "size", "=", "os", ".", "fstat", "(", "f", ".", "fileno", "(", ")", ")", ".", "st_size", "\n", "chunk_size", "=", "size", "//", "num_workers", "\n", "offset", "=", "worker_id", "*", "chunk_size", "\n", "end", "=", "offset", "+", "chunk_size", "\n", "f", ".", "seek", "(", "offset", ")", "\n", "if", "offset", ">", "0", ":", "\n", "                ", "safe_readline", "(", "f", ")", "# drop first incomplete line", "\n", "", "line", "=", "f", ".", "readline", "(", ")", "\n", "while", "line", ":", "\n", "                ", "for", "word", "in", "tokenize", "(", "line", ")", ":", "\n", "                    ", "counter", ".", "update", "(", "[", "word", "]", ")", "\n", "", "counter", ".", "update", "(", "[", "eos_word", "]", ")", "\n", "if", "f", ".", "tell", "(", ")", ">", "end", ":", "\n", "                    ", "break", "\n", "", "line", "=", "f", ".", "readline", "(", ")", "\n", "", "", "return", "counter", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_file_to_dictionary": [[343, 367], ["sorted", "multiprocessing.Pool", "range", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "dictionary.Dictionary.add_file_to_dictionary.merge_result"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.close"], ["", "@", "staticmethod", "\n", "def", "add_file_to_dictionary", "(", "filename", ",", "dict", ",", "tokenize", ",", "num_workers", ")", ":", "\n", "        ", "def", "merge_result", "(", "counter", ")", ":", "\n", "            ", "for", "w", ",", "c", "in", "sorted", "(", "counter", ".", "items", "(", ")", ")", ":", "\n", "                ", "dict", ".", "add_symbol", "(", "w", ",", "c", ")", "\n", "\n", "", "", "if", "num_workers", ">", "1", ":", "\n", "            ", "pool", "=", "Pool", "(", "processes", "=", "num_workers", ")", "\n", "results", "=", "[", "]", "\n", "for", "worker_id", "in", "range", "(", "num_workers", ")", ":", "\n", "                ", "results", ".", "append", "(", "\n", "pool", ".", "apply_async", "(", "\n", "Dictionary", ".", "_add_file_to_dictionary_single_worker", ",", "\n", "(", "filename", ",", "tokenize", ",", "dict", ".", "eos_word", ",", "worker_id", ",", "num_workers", ")", ",", "\n", ")", "\n", ")", "\n", "", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "for", "r", "in", "results", ":", "\n", "                ", "merge_result", "(", "r", ".", "get", "(", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "merge_result", "(", "\n", "Dictionary", ".", "_add_file_to_dictionary_single_worker", "(", "\n", "filename", ",", "tokenize", ",", "dict", ".", "eos_word", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.TruncatedDictionary.__init__": [[372, 381], ["type", "min", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "wrapped_dict", ",", "length", ")", ":", "\n", "        ", "self", ".", "__class__", "=", "type", "(", "\n", "wrapped_dict", ".", "__class__", ".", "__name__", ",", "\n", "(", "self", ".", "__class__", ",", "wrapped_dict", ".", "__class__", ")", ",", "\n", "{", "}", ",", "\n", ")", "\n", "self", ".", "__dict__", "=", "wrapped_dict", ".", "__dict__", "\n", "self", ".", "wrapped_dict", "=", "wrapped_dict", "\n", "self", ".", "length", "=", "min", "(", "len", "(", "self", ".", "wrapped_dict", ")", ",", "length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.TruncatedDictionary.__len__": [[382, 384], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.TruncatedDictionary.__getitem__": [[385, 389], ["dictionary.TruncatedDictionary.wrapped_dict.unk"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "if", "i", "<", "self", ".", "length", ":", "\n", "            ", "return", "self", ".", "wrapped_dict", "[", "i", "]", "\n", "", "return", "self", ".", "wrapped_dict", ".", "unk", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.subsample_dataset.SubsampleDataset.__init__": [[24, 35], ["BaseWrapperDataset.__init__", "numpy.ceil().astype", "numpy.random.choice", "logger.info", "list", "numpy.ceil", "range", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "dataset", ",", "size_ratio", ",", "shuffle", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ")", "\n", "assert", "size_ratio", "<", "1", "\n", "self", ".", "actual_size", "=", "np", ".", "ceil", "(", "len", "(", "dataset", ")", "*", "size_ratio", ")", ".", "astype", "(", "int", ")", "\n", "self", ".", "indices", "=", "np", ".", "random", ".", "choice", "(", "\n", "list", "(", "range", "(", "len", "(", "self", ".", "dataset", ")", ")", ")", ",", "self", ".", "actual_size", ",", "replace", "=", "False", "\n", ")", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "logger", ".", "info", "(", "\n", "\"subsampled dataset from {} to {} (ratio={})\"", ".", "format", "(", "\n", "len", "(", "self", ".", "dataset", ")", ",", "self", ".", "actual_size", ",", "size_ratio", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.subsample_dataset.SubsampleDataset.__getitem__": [[38, 40], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "dataset", "[", "self", ".", "indices", "[", "index", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.subsample_dataset.SubsampleDataset.__len__": [[41, 43], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "actual_size", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.subsample_dataset.SubsampleDataset.collater": [[44, 46], ["subsample_dataset.SubsampleDataset.dataset.collater"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.collater"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "collater", "(", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.subsample_dataset.SubsampleDataset.sizes": [[47, 50], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "sizes", "[", "self", ".", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.subsample_dataset.SubsampleDataset.name": [[51, 54], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.subsample_dataset.SubsampleDataset.num_tokens": [[55, 57], ["subsample_dataset.SubsampleDataset.dataset.num_tokens"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.num_tokens"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "num_tokens", "(", "self", ".", "indices", "[", "index", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.subsample_dataset.SubsampleDataset.size": [[58, 60], ["subsample_dataset.SubsampleDataset.dataset.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "size", "(", "self", ".", "indices", "[", "index", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.subsample_dataset.SubsampleDataset.ordered_indices": [[61, 70], ["order.append", "numpy.lexsort", "numpy.random.permutation", "numpy.arange", "len", "len"], "methods", ["None"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return an ordered list of indices. Batches will be constructed based\n        on this order.\"\"\"", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "order", "=", "[", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ")", ")", "]", "\n", "", "else", ":", "\n", "            ", "order", "=", "[", "np", ".", "arange", "(", "len", "(", "self", ")", ")", "]", "\n", "", "order", ".", "append", "(", "self", ".", "sizes", ")", "\n", "return", "np", ".", "lexsort", "(", "order", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.subsample_dataset.SubsampleDataset.prefetch": [[71, 73], ["subsample_dataset.SubsampleDataset.dataset.prefetch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "self", ".", "dataset", ".", "prefetch", "(", "self", ".", "indices", "[", "indices", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.prepend_token_dataset.PrependTokenDataset.__init__": [[13, 20], ["BaseWrapperDataset.__init__", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "token", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ")", "\n", "self", ".", "token", "=", "token", "\n", "if", "token", "is", "not", "None", ":", "\n", "            ", "self", ".", "_sizes", "=", "np", ".", "array", "(", "dataset", ".", "sizes", ")", "+", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "_sizes", "=", "dataset", ".", "sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.prepend_token_dataset.PrependTokenDataset.__getitem__": [[21, 26], ["torch.cat", "torch.cat.new"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "item", "=", "self", ".", "dataset", "[", "idx", "]", "\n", "if", "self", ".", "token", "is", "not", "None", ":", "\n", "            ", "item", "=", "torch", ".", "cat", "(", "[", "item", ".", "new", "(", "[", "self", ".", "token", "]", ")", ",", "item", "]", ")", "\n", "", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.prepend_token_dataset.PrependTokenDataset.sizes": [[27, 30], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.prepend_token_dataset.PrependTokenDataset.num_tokens": [[31, 36], ["prepend_token_dataset.PrependTokenDataset.dataset.num_tokens"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.num_tokens"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "n", "=", "self", ".", "dataset", ".", "num_tokens", "(", "index", ")", "\n", "if", "self", ".", "token", "is", "not", "None", ":", "\n", "            ", "n", "+=", "1", "\n", "", "return", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.prepend_token_dataset.PrependTokenDataset.size": [[37, 42], ["prepend_token_dataset.PrependTokenDataset.dataset.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "n", "=", "self", ".", "dataset", ".", "size", "(", "index", ")", "\n", "if", "self", ".", "token", "is", "not", "None", ":", "\n", "            ", "n", "+=", "1", "\n", "", "return", "n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_dataset.TransformEosDataset.__init__": [[25, 60], ["torch.LongTensor", "isinstance", "ValueError", "ValueError", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "eos", ",", "\n", "append_eos_to_src", "=", "False", ",", "\n", "remove_eos_from_src", "=", "False", ",", "\n", "append_eos_to_tgt", "=", "False", ",", "\n", "remove_eos_from_tgt", "=", "False", ",", "\n", "has_target", "=", "True", ",", "\n", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "dataset", ",", "FairseqDataset", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"dataset must be an instance of FairseqDataset\"", ")", "\n", "", "if", "append_eos_to_src", "and", "remove_eos_from_src", ":", "\n", "            ", "raise", "ValueError", "(", "\"cannot combine append_eos_to_src and remove_eos_from_src\"", ")", "\n", "", "if", "append_eos_to_tgt", "and", "remove_eos_from_tgt", ":", "\n", "            ", "raise", "ValueError", "(", "\"cannot combine append_eos_to_tgt and remove_eos_from_tgt\"", ")", "\n", "\n", "", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "eos", "=", "torch", ".", "LongTensor", "(", "[", "eos", "]", ")", "\n", "self", ".", "append_eos_to_src", "=", "append_eos_to_src", "\n", "self", ".", "remove_eos_from_src", "=", "remove_eos_from_src", "\n", "self", ".", "append_eos_to_tgt", "=", "append_eos_to_tgt", "\n", "self", ".", "remove_eos_from_tgt", "=", "remove_eos_from_tgt", "\n", "self", ".", "has_target", "=", "has_target", "\n", "\n", "# precompute how we should adjust the reported sizes", "\n", "self", ".", "_src_delta", "=", "0", "\n", "self", ".", "_src_delta", "+=", "1", "if", "append_eos_to_src", "else", "0", "\n", "self", ".", "_src_delta", "-=", "1", "if", "remove_eos_from_src", "else", "0", "\n", "self", ".", "_tgt_delta", "=", "0", "\n", "self", ".", "_tgt_delta", "+=", "1", "if", "append_eos_to_tgt", "else", "0", "\n", "self", ".", "_tgt_delta", "-=", "1", "if", "remove_eos_from_tgt", "else", "0", "\n", "\n", "self", ".", "_checked_src", "=", "False", "\n", "self", ".", "_checked_tgt", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_dataset.TransformEosDataset._check_src": [[61, 65], ["None"], "methods", ["None"], ["", "def", "_check_src", "(", "self", ",", "src", ",", "expect_eos", ")", ":", "\n", "        ", "if", "not", "self", ".", "_checked_src", ":", "\n", "            ", "assert", "(", "src", "[", "-", "1", "]", "==", "self", ".", "eos", "[", "0", "]", ")", "==", "expect_eos", "\n", "self", ".", "_checked_src", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_dataset.TransformEosDataset._check_tgt": [[66, 70], ["None"], "methods", ["None"], ["", "", "def", "_check_tgt", "(", "self", ",", "tgt", ",", "expect_eos", ")", ":", "\n", "        ", "if", "self", ".", "has_target", "and", "not", "self", ".", "_checked_tgt", ":", "\n", "            ", "assert", "(", "tgt", "[", "-", "1", "]", "==", "self", ".", "eos", "[", "0", "]", ")", "==", "expect_eos", "\n", "self", ".", "_checked_tgt", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_dataset.TransformEosDataset.__getitem__": [[71, 73], ["None"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "dataset", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_dataset.TransformEosDataset.__len__": [[74, 76], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_dataset.TransformEosDataset.collater": [[77, 99], ["list", "transform_eos_dataset.TransformEosDataset.dataset.collater", "map", "transform_eos_dataset.TransformEosDataset.eos.to", "transform_eos_dataset.TransformEosDataset._check_src", "torch.cat", "transform_eos_dataset.TransformEosDataset.eos.to", "transform_eos_dataset.TransformEosDataset._check_src", "transform_eos_dataset.TransformEosDataset.eos.to", "transform_eos_dataset.TransformEosDataset._check_tgt", "torch.cat", "transform_eos_dataset.TransformEosDataset.eos.to", "transform_eos_dataset.TransformEosDataset._check_tgt"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.collater", "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_dataset.TransformEosDataset._check_src", "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_dataset.TransformEosDataset._check_src", "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_dataset.TransformEosDataset._check_tgt", "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_dataset.TransformEosDataset._check_tgt"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "def", "transform", "(", "item", ")", ":", "\n", "            ", "if", "self", ".", "append_eos_to_src", ":", "\n", "                ", "self", ".", "eos", "=", "self", ".", "eos", ".", "to", "(", "device", "=", "item", "[", "\"source\"", "]", ".", "device", ")", "\n", "self", ".", "_check_src", "(", "item", "[", "\"source\"", "]", ",", "expect_eos", "=", "False", ")", "\n", "item", "[", "\"source\"", "]", "=", "torch", ".", "cat", "(", "[", "item", "[", "\"source\"", "]", ",", "self", ".", "eos", "]", ")", "\n", "", "if", "self", ".", "remove_eos_from_src", ":", "\n", "                ", "self", ".", "eos", "=", "self", ".", "eos", ".", "to", "(", "device", "=", "item", "[", "\"source\"", "]", ".", "device", ")", "\n", "self", ".", "_check_src", "(", "item", "[", "\"source\"", "]", ",", "expect_eos", "=", "True", ")", "\n", "item", "[", "\"source\"", "]", "=", "item", "[", "\"source\"", "]", "[", ":", "-", "1", "]", "\n", "", "if", "self", ".", "append_eos_to_tgt", ":", "\n", "                ", "self", ".", "eos", "=", "self", ".", "eos", ".", "to", "(", "device", "=", "item", "[", "\"target\"", "]", ".", "device", ")", "\n", "self", ".", "_check_tgt", "(", "item", "[", "\"target\"", "]", ",", "expect_eos", "=", "False", ")", "\n", "item", "[", "\"target\"", "]", "=", "torch", ".", "cat", "(", "[", "item", "[", "\"target\"", "]", ",", "self", ".", "eos", "]", ")", "\n", "", "if", "self", ".", "remove_eos_from_tgt", ":", "\n", "                ", "self", ".", "eos", "=", "self", ".", "eos", ".", "to", "(", "device", "=", "item", "[", "\"target\"", "]", ".", "device", ")", "\n", "self", ".", "_check_tgt", "(", "item", "[", "\"target\"", "]", ",", "expect_eos", "=", "True", ")", "\n", "item", "[", "\"target\"", "]", "=", "item", "[", "\"target\"", "]", "[", ":", "-", "1", "]", "\n", "", "return", "item", "\n", "\n", "", "samples", "=", "list", "(", "map", "(", "transform", ",", "samples", ")", ")", "\n", "return", "self", ".", "dataset", ".", "collater", "(", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_dataset.TransformEosDataset.num_tokens": [[100, 102], ["transform_eos_dataset.TransformEosDataset.dataset.num_tokens"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.num_tokens"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "num_tokens", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_dataset.TransformEosDataset.size": [[103, 109], ["transform_eos_dataset.TransformEosDataset.dataset.size", "transform_eos_dataset.TransformEosDataset.dataset.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "self", ".", "has_target", ":", "\n", "            ", "src_len", ",", "tgt_len", "=", "self", ".", "dataset", ".", "size", "(", "index", ")", "\n", "return", "(", "src_len", "+", "self", ".", "_src_delta", ",", "tgt_len", "+", "self", ".", "_tgt_delta", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "dataset", ".", "size", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_dataset.TransformEosDataset.ordered_indices": [[110, 114], ["transform_eos_dataset.TransformEosDataset.dataset.ordered_indices"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.ordered_indices"], ["", "", "def", "ordered_indices", "(", "self", ")", ":", "\n", "# NOTE: we assume that the ordering does not change based on the", "\n", "# addition or removal of eos", "\n", "        ", "return", "self", ".", "dataset", ".", "ordered_indices", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_dataset.TransformEosDataset.supports_prefetch": [[115, 118], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ".", "dataset", ",", "\"supports_prefetch\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_dataset.TransformEosDataset.prefetch": [[119, 121], ["transform_eos_dataset.TransformEosDataset.dataset.prefetch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "prefetch", "(", "indices", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.fasta_dataset.FastaDataset.__init__": [[24, 36], ["fasta_dataset.fasta_file_path", "threading.local", "pathlib.Path", "fasta_dataset.FastaDataset.cache.exists", "fasta_dataset.FastaDataset._build_index", "numpy.load", "fasta_dataset.FastaDataset._build_index", "numpy.save", "numpy.stack"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.fasta_dataset.fasta_file_path", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.fasta_dataset.FastaDataset._build_index", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.data.fasta_dataset.FastaDataset._build_index", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.save"], ["def", "__init__", "(", "self", ",", "path", ":", "str", ",", "cache_indices", "=", "False", ")", ":", "\n", "        ", "self", ".", "fn", "=", "fasta_file_path", "(", "path", ")", "\n", "self", ".", "threadlocal", "=", "threading", ".", "local", "(", ")", "\n", "self", ".", "cache", "=", "Path", "(", "f\"{path}.fasta.idx.npy\"", ")", "\n", "if", "cache_indices", ":", "\n", "            ", "if", "self", ".", "cache", ".", "exists", "(", ")", ":", "\n", "                ", "self", ".", "offsets", ",", "self", ".", "sizes", "=", "np", ".", "load", "(", "self", ".", "cache", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "offsets", ",", "self", ".", "sizes", "=", "self", ".", "_build_index", "(", "path", ")", "\n", "np", ".", "save", "(", "self", ".", "cache", ",", "np", ".", "stack", "(", "[", "self", ".", "offsets", ",", "self", ".", "sizes", "]", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "offsets", ",", "self", ".", "sizes", "=", "self", ".", "_build_index", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fasta_dataset.FastaDataset._get_file": [[37, 41], ["hasattr", "open"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["", "", "def", "_get_file", "(", "self", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ".", "threadlocal", ",", "\"f\"", ")", ":", "\n", "            ", "self", ".", "threadlocal", ".", "f", "=", "open", "(", "self", ".", "fn", ",", "\"r\"", ")", "\n", "", "return", "self", ".", "threadlocal", ".", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fasta_dataset.FastaDataset.__getitem__": [[42, 52], ["fasta_dataset.FastaDataset._get_file", "fasta_dataset.FastaDataset.seek", "fasta_dataset.FastaDataset.readline().strip", "fasta_dataset.FastaDataset.readline", "fasta_dataset.FastaDataset.readline.strip", "fasta_dataset.FastaDataset.readline", "fasta_dataset.FastaDataset.readline"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.fasta_dataset.FastaDataset._get_file"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "f", "=", "self", ".", "_get_file", "(", ")", "\n", "f", ".", "seek", "(", "self", ".", "offsets", "[", "idx", "]", ")", "\n", "desc", "=", "f", ".", "readline", "(", ")", ".", "strip", "(", ")", "\n", "line", "=", "f", ".", "readline", "(", ")", "\n", "seq", "=", "\"\"", "\n", "while", "line", "!=", "\"\"", "and", "line", "[", "0", "]", "!=", "\">\"", ":", "\n", "            ", "seq", "+=", "line", ".", "strip", "(", ")", "\n", "line", "=", "f", ".", "readline", "(", ")", "\n", "", "return", "desc", ",", "seq", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fasta_dataset.FastaDataset.__len__": [[53, 55], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "offsets", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fasta_dataset.FastaDataset._build_index": [[56, 73], ["fasta_dataset.fasta_file_path", "subprocess.check_output", "subprocess.check_output", "numpy.fromstring", "numpy.fromstring"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.fasta_dataset.fasta_file_path"], ["", "def", "_build_index", "(", "self", ",", "path", ":", "str", ")", ":", "\n", "# Use grep and awk to get 100M/s on local SSD.", "\n", "# Should process your enormous 100G fasta in ~10 min single core...", "\n", "        ", "path", "=", "fasta_file_path", "(", "path", ")", "\n", "bytes_offsets", "=", "subprocess", ".", "check_output", "(", "\n", "f\"cat {path} | tqdm --bytes --total $(wc -c < {path})\"", "\n", "\"| grep --byte-offset '^>' -o | cut -d: -f1\"", ",", "\n", "shell", "=", "True", ",", "\n", ")", "\n", "fasta_lengths", "=", "subprocess", ".", "check_output", "(", "\n", "f\"cat {path} | tqdm --bytes --total $(wc -c < {path})\"", "\n", "\"| awk '/^>/ {print \\\"\\\";next;} { printf(\\\"%s\\\",$0);}' | tail -n+2 | awk '{print length($1)}'\"", ",", "\n", "shell", "=", "True", ",", "\n", ")", "\n", "bytes_np", "=", "np", ".", "fromstring", "(", "bytes_offsets", ",", "dtype", "=", "np", ".", "int64", ",", "sep", "=", "\" \"", ")", "\n", "sizes_np", "=", "np", ".", "fromstring", "(", "fasta_lengths", ",", "dtype", "=", "np", ".", "int64", ",", "sep", "=", "\" \"", ")", "\n", "return", "bytes_np", ",", "sizes_np", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fasta_dataset.FastaDataset.__setstate__": [[74, 77], ["threading.local"], "methods", ["None"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "self", ".", "__dict__", "=", "state", "\n", "self", ".", "threadlocal", "=", "threading", ".", "local", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fasta_dataset.FastaDataset.__getstate__": [[78, 84], ["fasta_dataset.FastaDataset.__dict__.items"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "d", "=", "{", "}", "\n", "for", "i", ",", "v", "in", "self", ".", "__dict__", ".", "items", "(", ")", ":", "\n", "            ", "if", "i", "!=", "\"threadlocal\"", ":", "\n", "                ", "d", "[", "i", "]", "=", "v", "\n", "", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fasta_dataset.FastaDataset.__del__": [[85, 89], ["hasattr", "fasta_dataset.FastaDataset.threadlocal.f.close"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.close"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "threadlocal", ",", "\"f\"", ")", ":", "\n", "            ", "self", ".", "threadlocal", ".", "f", ".", "close", "(", ")", "\n", "del", "self", ".", "threadlocal", ".", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fasta_dataset.FastaDataset.exists": [[90, 93], ["os.path.exists", "fasta_dataset.fasta_file_path"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.fasta_dataset.fasta_file_path"], ["", "", "@", "staticmethod", "\n", "def", "exists", "(", "path", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "exists", "(", "fasta_file_path", "(", "path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fasta_dataset.EncodedFastaDataset.__init__": [[101, 104], ["fasta_dataset.FastaDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "path", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "path", ",", "cache_indices", "=", "True", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.fasta_dataset.EncodedFastaDataset.__getitem__": [[105, 108], ["fasta_dataset.FastaDataset.__getitem__", "fasta_dataset.EncodedFastaDataset.dictionary.encode_line().long", "fasta_dataset.EncodedFastaDataset.dictionary.encode_line"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.__getitem__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.encode_line"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "desc", ",", "seq", "=", "super", "(", ")", ".", "__getitem__", "(", "idx", ")", "\n", "return", "self", ".", "dictionary", ".", "encode_line", "(", "seq", ",", "line_tokenizer", "=", "list", ")", ".", "long", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.fasta_dataset.fasta_file_path": [[15, 17], ["None"], "function", ["None"], ["def", "fasta_file_path", "(", "prefix_path", ")", ":", "\n", "    ", "return", "prefix_path", "+", "\".fasta\"", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.noising.WordNoising.__init__": [[14, 34], ["numpy.array", "numpy.array", "noising.WordNoising.dictionary[].endswith", "range", "noising.WordNoising.dictionary[].endswith", "len", "range", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dictionary", ",", "bpe_cont_marker", "=", "\"@@\"", ",", "bpe_end_marker", "=", "None", ")", ":", "\n", "        ", "self", ".", "dictionary", "=", "dictionary", "\n", "self", ".", "bpe_end", "=", "None", "\n", "if", "bpe_cont_marker", ":", "\n", "            ", "self", ".", "bpe_end", "=", "np", ".", "array", "(", "\n", "[", "\n", "not", "self", ".", "dictionary", "[", "i", "]", ".", "endswith", "(", "bpe_cont_marker", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "dictionary", ")", ")", "\n", "]", "\n", ")", "\n", "", "elif", "bpe_end_marker", ":", "\n", "            ", "self", ".", "bpe_end", "=", "np", ".", "array", "(", "\n", "[", "\n", "self", ".", "dictionary", "[", "i", "]", ".", "endswith", "(", "bpe_end_marker", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "dictionary", ")", ")", "\n", "]", "\n", ")", "\n", "\n", "", "self", ".", "get_word_idx", "=", "(", "\n", "self", ".", "_get_bpe_word_idx", "if", "self", ".", "bpe_end", "is", "not", "None", "else", "self", ".", "_get_token_idx", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.noising.WordNoising.noising": [[36, 38], ["NotImplementedError"], "methods", ["None"], ["", "def", "noising", "(", "self", ",", "x", ",", "lengths", ",", "noising_prob", "=", "0.0", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.noising.WordNoising._get_bpe_word_idx": [[39, 59], ["numpy.array", "bpe_end[].cumsum", "x.size", "x.size", "word_idx.max"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.cumsum", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "_get_bpe_word_idx", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Given a list of BPE tokens, for every index in the tokens list,\n        return the index of the word grouping that it belongs to.\n        For example, for input x corresponding to [\"how\", \"are\", \"y@@\", \"ou\"],\n        return [[0], [1], [2], [2]].\n        \"\"\"", "\n", "# x: (T x B)", "\n", "bpe_end", "=", "self", ".", "bpe_end", "[", "x", "]", "\n", "\n", "if", "x", ".", "size", "(", "0", ")", "==", "1", "and", "x", ".", "size", "(", "1", ")", "==", "1", ":", "\n", "# Special case when we only have one word in x. If x = [[N]],", "\n", "# bpe_end is a scalar (bool) instead of a 2-dim array of bools,", "\n", "# which makes the sum operation below fail.", "\n", "            ", "return", "np", ".", "array", "(", "[", "[", "0", "]", "]", ")", "\n", "\n", "# do a reduce front sum to generate word ids", "\n", "", "word_idx", "=", "bpe_end", "[", ":", ":", "-", "1", "]", ".", "cumsum", "(", "0", ")", "[", ":", ":", "-", "1", "]", "\n", "word_idx", "=", "word_idx", ".", "max", "(", "0", ")", "[", "None", ",", ":", "]", "-", "word_idx", "\n", "return", "word_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.noising.WordNoising._get_token_idx": [[60, 68], ["torch.t", "numpy.array", "numpy.transpose", "range", "len"], "methods", ["None"], ["", "def", "_get_token_idx", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        This is to extend noising functions to be able to apply to non-bpe\n        tokens, e.g. word or characters.\n        \"\"\"", "\n", "x", "=", "torch", ".", "t", "(", "x", ")", "\n", "word_idx", "=", "np", ".", "array", "(", "[", "range", "(", "len", "(", "x_i", ")", ")", "for", "x_i", "in", "x", "]", ")", "\n", "return", "np", ".", "transpose", "(", "word_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.noising.WordDropout.__init__": [[75, 84], ["noising.WordNoising.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dictionary", ",", "\n", "default_dropout_prob", "=", "0.1", ",", "\n", "bpe_cont_marker", "=", "\"@@\"", ",", "\n", "bpe_end_marker", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ",", "bpe_cont_marker", ",", "bpe_end_marker", ")", "\n", "self", ".", "default_dropout_prob", "=", "default_dropout_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.noising.WordDropout.noising": [[85, 148], ["noising.WordDropout.get_word_idx", "range", "torch.LongTensor", "torch.LongTensor().fill_", "range", "lengths.size", "x[].tolist", "sentences.append", "torch.LongTensor.append", "noising.WordDropout.dictionary.pad", "torch.LongTensor.size", "modified_x[].copy_", "max", "noising.WordDropout.dictionary.eos", "numpy.append", "len", "new_s.insert", "len", "torch.LongTensor", "torch.LongTensor", "numpy.random.rand", "numpy.random.rand", "enumerate", "len", "torch.LongTensor.max", "torch.LongTensor.size", "numpy.random.randint", "len", "noising.WordDropout.dictionary.eos", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "def", "noising", "(", "self", ",", "x", ",", "lengths", ",", "dropout_prob", "=", "None", ",", "blank_idx", "=", "None", ")", ":", "\n", "        ", "if", "dropout_prob", "is", "None", ":", "\n", "            ", "dropout_prob", "=", "self", ".", "default_dropout_prob", "\n", "# x: (T x B), lengths: B", "\n", "", "if", "dropout_prob", "==", "0", ":", "\n", "            ", "return", "x", ",", "lengths", "\n", "\n", "", "assert", "0", "<", "dropout_prob", "<", "1", "\n", "\n", "# be sure to drop entire words", "\n", "word_idx", "=", "self", ".", "get_word_idx", "(", "x", ")", "\n", "sentences", "=", "[", "]", "\n", "modified_lengths", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "lengths", ".", "size", "(", "0", ")", ")", ":", "\n", "# Since dropout probabilities need to apply over non-pad tokens,", "\n", "# it is not trivial to generate the keep mask without consider", "\n", "# input lengths; otherwise, this could be done outside the loop", "\n", "\n", "# We want to drop whole words based on word_idx grouping", "\n", "            ", "num_words", "=", "max", "(", "word_idx", "[", ":", ",", "i", "]", ")", "+", "1", "\n", "\n", "# ith example: [x0, x1, ..., eos, pad, ..., pad]", "\n", "# We should only generate keep probs for non-EOS tokens. Thus if the", "\n", "# input sentence ends in EOS, the last word idx is not included in", "\n", "# the dropout mask generation and we append True to always keep EOS.", "\n", "# Otherwise, just generate the dropout mask for all word idx", "\n", "# positions.", "\n", "has_eos", "=", "x", "[", "lengths", "[", "i", "]", "-", "1", ",", "i", "]", "==", "self", ".", "dictionary", ".", "eos", "(", ")", "\n", "if", "has_eos", ":", "# has eos?", "\n", "                ", "keep", "=", "np", ".", "random", ".", "rand", "(", "num_words", "-", "1", ")", ">=", "dropout_prob", "\n", "keep", "=", "np", ".", "append", "(", "keep", ",", "[", "True", "]", ")", "# keep EOS symbol", "\n", "", "else", ":", "\n", "                ", "keep", "=", "np", ".", "random", ".", "rand", "(", "num_words", ")", ">=", "dropout_prob", "\n", "\n", "", "words", "=", "x", "[", ":", "lengths", "[", "i", "]", ",", "i", "]", ".", "tolist", "(", ")", "\n", "\n", "# TODO: speed up the following loop", "\n", "# drop words from the input according to keep", "\n", "new_s", "=", "[", "\n", "w", "if", "keep", "[", "word_idx", "[", "j", ",", "i", "]", "]", "else", "blank_idx", "for", "j", ",", "w", "in", "enumerate", "(", "words", ")", "\n", "]", "\n", "new_s", "=", "[", "w", "for", "w", "in", "new_s", "if", "w", "is", "not", "None", "]", "\n", "# we need to have at least one word in the sentence (more than the", "\n", "# start / end sentence symbols)", "\n", "if", "len", "(", "new_s", ")", "<=", "1", ":", "\n", "# insert at beginning in case the only token left is EOS", "\n", "# EOS should be at end of list.", "\n", "                ", "new_s", ".", "insert", "(", "0", ",", "words", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "words", ")", ")", "]", ")", "\n", "", "assert", "len", "(", "new_s", ")", ">=", "1", "and", "(", "\n", "not", "has_eos", "# Either don't have EOS at end or last token is EOS", "\n", "or", "(", "len", "(", "new_s", ")", ">=", "2", "and", "new_s", "[", "-", "1", "]", "==", "self", ".", "dictionary", ".", "eos", "(", ")", ")", "\n", ")", ",", "\"New sentence is invalid.\"", "\n", "sentences", ".", "append", "(", "new_s", ")", "\n", "modified_lengths", ".", "append", "(", "len", "(", "new_s", ")", ")", "\n", "# re-construct input", "\n", "", "modified_lengths", "=", "torch", ".", "LongTensor", "(", "modified_lengths", ")", "\n", "modified_x", "=", "torch", ".", "LongTensor", "(", "\n", "modified_lengths", ".", "max", "(", ")", ",", "modified_lengths", ".", "size", "(", "0", ")", "\n", ")", ".", "fill_", "(", "self", ".", "dictionary", ".", "pad", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "modified_lengths", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "modified_x", "[", ":", "modified_lengths", "[", "i", "]", ",", "i", "]", ".", "copy_", "(", "torch", ".", "LongTensor", "(", "sentences", "[", "i", "]", ")", ")", "\n", "\n", "", "return", "modified_x", ",", "modified_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.noising.WordShuffle.__init__": [[153, 162], ["noising.WordNoising.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dictionary", ",", "\n", "default_max_shuffle_distance", "=", "3", ",", "\n", "bpe_cont_marker", "=", "\"@@\"", ",", "\n", "bpe_end_marker", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ",", "bpe_cont_marker", ",", "bpe_end_marker", ")", "\n", "self", ".", "default_max_shuffle_distance", "=", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.noising.WordShuffle.noising": [[163, 197], ["numpy.random.uniform", "noising.WordShuffle.get_word_idx", "x.clone", "range", "lengths.size", "scores.argsort", "x2[].copy_", "noising.WordShuffle.dictionary.eos", "numpy.arange", "x.size", "x.size", "length_no_eos.item", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampling_method.uniform", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["", "def", "noising", "(", "self", ",", "x", ",", "lengths", ",", "max_shuffle_distance", "=", "None", ")", ":", "\n", "        ", "if", "max_shuffle_distance", "is", "None", ":", "\n", "            ", "max_shuffle_distance", "=", "self", ".", "default_max_shuffle_distance", "\n", "# x: (T x B), lengths: B", "\n", "", "if", "max_shuffle_distance", "==", "0", ":", "\n", "            ", "return", "x", ",", "lengths", "\n", "\n", "# max_shuffle_distance < 1 will return the same sequence", "\n", "", "assert", "max_shuffle_distance", ">", "1", "\n", "\n", "# define noise word scores", "\n", "noise", "=", "np", ".", "random", ".", "uniform", "(", "\n", "0", ",", "\n", "max_shuffle_distance", ",", "\n", "size", "=", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ")", ",", "\n", ")", "\n", "noise", "[", "0", "]", "=", "-", "1", "# do not move start sentence symbol", "\n", "# be sure to shuffle entire words", "\n", "word_idx", "=", "self", ".", "get_word_idx", "(", "x", ")", "\n", "x2", "=", "x", ".", "clone", "(", ")", "\n", "for", "i", "in", "range", "(", "lengths", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "length_no_eos", "=", "lengths", "[", "i", "]", "\n", "if", "x", "[", "lengths", "[", "i", "]", "-", "1", ",", "i", "]", "==", "self", ".", "dictionary", ".", "eos", "(", ")", ":", "\n", "                ", "length_no_eos", "=", "lengths", "[", "i", "]", "-", "1", "\n", "# generate a random permutation", "\n", "", "scores", "=", "word_idx", "[", ":", "length_no_eos", ",", "i", "]", "+", "noise", "[", "word_idx", "[", ":", "length_no_eos", ",", "i", "]", ",", "i", "]", "\n", "# ensure no reordering inside a word", "\n", "scores", "+=", "1e-6", "*", "np", ".", "arange", "(", "length_no_eos", ".", "item", "(", ")", ")", "\n", "permutation", "=", "scores", ".", "argsort", "(", ")", "\n", "# shuffle words", "\n", "x2", "[", ":", "length_no_eos", ",", "i", "]", ".", "copy_", "(", "\n", "x2", "[", ":", "length_no_eos", ",", "i", "]", "[", "torch", ".", "from_numpy", "(", "permutation", ")", "]", "\n", ")", "\n", "", "return", "x2", ",", "lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.noising.UnsupervisedMTNoising.__init__": [[205, 228], ["noising.WordNoising.__init__", "noising.WordDropout", "noising.WordShuffle"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dictionary", ",", "\n", "max_word_shuffle_distance", ",", "\n", "word_dropout_prob", ",", "\n", "word_blanking_prob", ",", "\n", "bpe_cont_marker", "=", "\"@@\"", ",", "\n", "bpe_end_marker", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dictionary", ")", "\n", "self", ".", "max_word_shuffle_distance", "=", "max_word_shuffle_distance", "\n", "self", ".", "word_dropout_prob", "=", "word_dropout_prob", "\n", "self", ".", "word_blanking_prob", "=", "word_blanking_prob", "\n", "\n", "self", ".", "word_dropout", "=", "WordDropout", "(", "\n", "dictionary", "=", "dictionary", ",", "\n", "bpe_cont_marker", "=", "bpe_cont_marker", ",", "\n", "bpe_end_marker", "=", "bpe_end_marker", ",", "\n", ")", "\n", "self", ".", "word_shuffle", "=", "WordShuffle", "(", "\n", "dictionary", "=", "dictionary", ",", "\n", "bpe_cont_marker", "=", "bpe_cont_marker", ",", "\n", "bpe_end_marker", "=", "bpe_end_marker", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.noising.UnsupervisedMTNoising.noising": [[230, 252], ["noising.UnsupervisedMTNoising.word_shuffle.noising", "noising.UnsupervisedMTNoising.word_dropout.noising", "noising.UnsupervisedMTNoising.word_dropout.noising", "noising.UnsupervisedMTNoising.dictionary.unk"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.noising.UnsupervisedMTNoising.noising", "home.repos.pwc.inspect_result.reneeye_const.data.noising.UnsupervisedMTNoising.noising", "home.repos.pwc.inspect_result.reneeye_const.data.noising.UnsupervisedMTNoising.noising", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk"], ["", "def", "noising", "(", "self", ",", "x", ",", "lengths", ")", ":", "\n", "# 1. Word Shuffle", "\n", "        ", "noisy_src_tokens", ",", "noisy_src_lengths", "=", "self", ".", "word_shuffle", ".", "noising", "(", "\n", "x", "=", "x", ",", "\n", "lengths", "=", "lengths", ",", "\n", "max_shuffle_distance", "=", "self", ".", "max_word_shuffle_distance", ",", "\n", ")", "\n", "# 2. Word Dropout", "\n", "noisy_src_tokens", ",", "noisy_src_lengths", "=", "self", ".", "word_dropout", ".", "noising", "(", "\n", "x", "=", "noisy_src_tokens", ",", "\n", "lengths", "=", "noisy_src_lengths", ",", "\n", "dropout_prob", "=", "self", ".", "word_dropout_prob", ",", "\n", ")", "\n", "# 3. Word Blanking", "\n", "noisy_src_tokens", ",", "noisy_src_lengths", "=", "self", ".", "word_dropout", ".", "noising", "(", "\n", "x", "=", "noisy_src_tokens", ",", "\n", "lengths", "=", "noisy_src_lengths", ",", "\n", "dropout_prob", "=", "self", ".", "word_blanking_prob", ",", "\n", "blank_idx", "=", "self", ".", "dictionary", ".", "unk", "(", ")", ",", "\n", ")", "\n", "\n", "return", "noisy_src_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.noising.NoisingDataset.__init__": [[255, 297], ["noising_class"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "src_dataset", ",", "\n", "src_dict", ",", "\n", "seed", ",", "\n", "noiser", "=", "None", ",", "\n", "noising_class", "=", "UnsupervisedMTNoising", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Wrap a :class:`~torch.utils.data.Dataset` and apply noise to the\n        samples based on the supplied noising configuration.\n\n        Args:\n            src_dataset (~torch.utils.data.Dataset): dataset to wrap.\n                to build self.src_dataset --\n                a LanguagePairDataset with src dataset as the source dataset and\n                None as the target dataset. Should NOT have padding so that\n                src_lengths are accurately calculated by language_pair_dataset\n                collate function.\n                We use language_pair_dataset here to encapsulate the tgt_dataset\n                so we can re-use the LanguagePairDataset collater to format the\n                batches in the structure that SequenceGenerator expects.\n            src_dict (~fairseq.data.Dictionary): source dictionary\n            seed (int): seed to use when generating random noise\n            noiser (WordNoising): a pre-initialized :class:`WordNoising`\n                instance. If this is None, a new instance will be created using\n                *noising_class* and *kwargs*.\n            noising_class (class, optional): class to use to initialize a\n                default :class:`WordNoising` instance.\n            kwargs (dict, optional): arguments to initialize the default\n                :class:`WordNoising` instance given by *noiser*.\n        \"\"\"", "\n", "self", ".", "src_dataset", "=", "src_dataset", "\n", "self", ".", "src_dict", "=", "src_dict", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "noiser", "=", "(", "\n", "noiser", "\n", "if", "noiser", "is", "not", "None", "\n", "else", "noising_class", "(", "\n", "dictionary", "=", "src_dict", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.noising.NoisingDataset.__getitem__": [[300, 320], ["torch.LongTensor", "src_tokens.unsqueeze.unsqueeze.unsqueeze", "torch.t", "torch.t", "fairseq.data.data_utils.numpy_seed", "noising.NoisingDataset.noiser.noising", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils.numpy_seed", "home.repos.pwc.inspect_result.reneeye_const.data.noising.UnsupervisedMTNoising.noising"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Returns a single noisy sample. Multiple samples are fed to the collater\n        create a noising dataset batch.\n        \"\"\"", "\n", "src_tokens", "=", "self", ".", "src_dataset", "[", "index", "]", "\n", "src_lengths", "=", "torch", ".", "LongTensor", "(", "[", "len", "(", "src_tokens", ")", "]", ")", "\n", "src_tokens", "=", "src_tokens", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "# Transpose src tokens to fit expected shape of x in noising function", "\n", "# (batch size, sequence length) -> (sequence length, batch size)", "\n", "src_tokens_t", "=", "torch", ".", "t", "(", "src_tokens", ")", "\n", "\n", "with", "data_utils", ".", "numpy_seed", "(", "self", ".", "seed", "+", "index", ")", ":", "\n", "            ", "noisy_src_tokens", "=", "self", ".", "noiser", ".", "noising", "(", "src_tokens_t", ",", "src_lengths", ")", "\n", "\n", "# Transpose back to expected src_tokens format", "\n", "# (sequence length, 1) -> (1, sequence length)", "\n", "", "noisy_src_tokens", "=", "torch", ".", "t", "(", "noisy_src_tokens", ")", "\n", "return", "noisy_src_tokens", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.noising.NoisingDataset.__len__": [[321, 326], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        The length of the noising dataset is the length of src.\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "src_dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.noising.NoisingDataset.supports_prefetch": [[327, 330], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "src_dataset", ".", "supports_prefetch", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.noising.NoisingDataset.prefetch": [[331, 334], ["noising.NoisingDataset.src_dataset.prefetch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "if", "self", ".", "src_dataset", ".", "supports_prefetch", ":", "\n", "            ", "self", ".", "src_dataset", ".", "prefetch", "(", "indices", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedDataset.__init__": [[127, 133], ["FairseqDataset.__init__", "indexed_dataset.IndexedDataset.read_index"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedDataset.read_index"], ["def", "__init__", "(", "self", ",", "path", ",", "fix_lua_indexing", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "path", "=", "path", "\n", "self", ".", "fix_lua_indexing", "=", "fix_lua_indexing", "\n", "self", ".", "data_file", "=", "None", "\n", "self", ".", "read_index", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedDataset.read_index": [[134, 149], ["open", "f.read", "f.read", "struct.unpack", "struct.unpack", "indexed_dataset.read_longs", "indexed_dataset.read_longs", "indexed_dataset.read_longs", "indexed_dataset.index_file_path", "struct.unpack", "f.read", "f.read"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.read_longs", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.read_longs", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.read_longs", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.index_file_path"], ["", "def", "read_index", "(", "self", ",", "path", ")", ":", "\n", "        ", "with", "open", "(", "index_file_path", "(", "path", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "magic", "=", "f", ".", "read", "(", "8", ")", "\n", "assert", "magic", "==", "self", ".", "_HDR_MAGIC", ",", "(", "\n", "\"Index file doesn't match expected format. \"", "\n", "\"Make sure that --dataset-impl is configured properly.\"", "\n", ")", "\n", "version", "=", "f", ".", "read", "(", "8", ")", "\n", "assert", "struct", ".", "unpack", "(", "\"<Q\"", ",", "version", ")", "==", "(", "1", ",", ")", "\n", "code", ",", "self", ".", "element_size", "=", "struct", ".", "unpack", "(", "\"<QQ\"", ",", "f", ".", "read", "(", "16", ")", ")", "\n", "self", ".", "dtype", "=", "dtypes", "[", "code", "]", "\n", "self", ".", "_len", ",", "self", ".", "s", "=", "struct", ".", "unpack", "(", "\"<QQ\"", ",", "f", ".", "read", "(", "16", ")", ")", "\n", "self", ".", "dim_offsets", "=", "read_longs", "(", "f", ",", "self", ".", "_len", "+", "1", ")", "\n", "self", ".", "data_offsets", "=", "read_longs", "(", "f", ",", "self", ".", "_len", "+", "1", ")", "\n", "self", ".", "sizes", "=", "read_longs", "(", "f", ",", "self", ".", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedDataset.read_data": [[150, 152], ["open", "indexed_dataset.data_file_path"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.data_file_path"], ["", "", "def", "read_data", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "data_file", "=", "open", "(", "data_file_path", "(", "path", ")", ",", "\"rb\"", ",", "buffering", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedDataset.check_index": [[153, 156], ["IndexError"], "methods", ["None"], ["", "def", "check_index", "(", "self", ",", "i", ")", ":", "\n", "        ", "if", "i", "<", "0", "or", "i", ">=", "self", ".", "_len", ":", "\n", "            ", "raise", "IndexError", "(", "\"index out of range\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedDataset.__del__": [[157, 160], ["indexed_dataset.IndexedDataset.data_file.close"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.close"], ["", "", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "data_file", ":", "\n", "            ", "self", ".", "data_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedDataset.__getitem__": [[161, 174], ["functools.lru_cache", "indexed_dataset.IndexedDataset.check_index", "numpy.empty", "indexed_dataset.IndexedDataset.data_file.seek", "indexed_dataset.IndexedDataset.data_file.readinto", "torch.from_numpy().long", "indexed_dataset.IndexedDataset.read_data", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedRawTextDataset.check_index", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedRawTextDataset.read_data"], ["", "", "@", "lru_cache", "(", "maxsize", "=", "8", ")", "\n", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "if", "not", "self", ".", "data_file", ":", "\n", "            ", "self", ".", "read_data", "(", "self", ".", "path", ")", "\n", "", "self", ".", "check_index", "(", "i", ")", "\n", "tensor_size", "=", "self", ".", "sizes", "[", "self", ".", "dim_offsets", "[", "i", "]", ":", "self", ".", "dim_offsets", "[", "i", "+", "1", "]", "]", "\n", "a", "=", "np", ".", "empty", "(", "tensor_size", ",", "dtype", "=", "self", ".", "dtype", ")", "\n", "self", ".", "data_file", ".", "seek", "(", "self", ".", "data_offsets", "[", "i", "]", "*", "self", ".", "element_size", ")", "\n", "self", ".", "data_file", ".", "readinto", "(", "a", ")", "\n", "item", "=", "torch", ".", "from_numpy", "(", "a", ")", ".", "long", "(", ")", "\n", "if", "self", ".", "fix_lua_indexing", ":", "\n", "            ", "item", "-=", "1", "# subtract 1 for 0-based indexing", "\n", "", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedDataset.__len__": [[175, 177], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_len", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedDataset.num_tokens": [[178, 180], ["None"], "methods", ["None"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "sizes", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedDataset.size": [[181, 183], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "sizes", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedDataset.exists": [[184, 188], ["fairseq.file_io.PathManager.exists", "fairseq.file_io.PathManager.exists", "indexed_dataset.index_file_path", "indexed_dataset.data_file_path"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.index_file_path", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.data_file_path"], ["", "@", "staticmethod", "\n", "def", "exists", "(", "path", ")", ":", "\n", "        ", "return", "PathManager", ".", "exists", "(", "index_file_path", "(", "path", ")", ")", "and", "PathManager", ".", "exists", "(", "\n", "data_file_path", "(", "path", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedDataset.supports_prefetch": [[190, 193], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "False", "# avoid prefetching to save memory", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedCachedDataset.__init__": [[196, 200], ["indexed_dataset.IndexedDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "fix_lua_indexing", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "path", ",", "fix_lua_indexing", "=", "fix_lua_indexing", ")", "\n", "self", ".", "cache", "=", "None", "\n", "self", ".", "cache_index", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedCachedDataset.supports_prefetch": [[201, 204], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedCachedDataset.prefetch": [[205, 228], ["all", "sorted", "numpy.empty", "indexed_dataset.IndexedCachedDataset.cache_index.clear", "indexed_dataset.IndexedCachedDataset.read_data", "set", "indexed_dataset.IndexedCachedDataset.data_file.seek", "indexed_dataset.IndexedCachedDataset.data_file.readinto", "indexed_dataset.IndexedCachedDataset.data_file.close"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedRawTextDataset.read_data", "home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.close"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "if", "all", "(", "i", "in", "self", ".", "cache_index", "for", "i", "in", "indices", ")", ":", "\n", "            ", "return", "\n", "", "if", "not", "self", ".", "data_file", ":", "\n", "            ", "self", ".", "read_data", "(", "self", ".", "path", ")", "\n", "", "indices", "=", "sorted", "(", "set", "(", "indices", ")", ")", "\n", "total_size", "=", "0", "\n", "for", "i", "in", "indices", ":", "\n", "            ", "total_size", "+=", "self", ".", "data_offsets", "[", "i", "+", "1", "]", "-", "self", ".", "data_offsets", "[", "i", "]", "\n", "", "self", ".", "cache", "=", "np", ".", "empty", "(", "total_size", ",", "dtype", "=", "self", ".", "dtype", ")", "\n", "ptx", "=", "0", "\n", "self", ".", "cache_index", ".", "clear", "(", ")", "\n", "for", "i", "in", "indices", ":", "\n", "            ", "self", ".", "cache_index", "[", "i", "]", "=", "ptx", "\n", "size", "=", "self", ".", "data_offsets", "[", "i", "+", "1", "]", "-", "self", ".", "data_offsets", "[", "i", "]", "\n", "a", "=", "self", ".", "cache", "[", "ptx", ":", "ptx", "+", "size", "]", "\n", "self", ".", "data_file", ".", "seek", "(", "self", ".", "data_offsets", "[", "i", "]", "*", "self", ".", "element_size", ")", "\n", "self", ".", "data_file", ".", "readinto", "(", "a", ")", "\n", "ptx", "+=", "size", "\n", "", "if", "self", ".", "data_file", ":", "\n", "# close and delete data file after prefetch so we can pickle", "\n", "            ", "self", ".", "data_file", ".", "close", "(", ")", "\n", "self", ".", "data_file", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedCachedDataset.__getitem__": [[229, 240], ["functools.lru_cache", "indexed_dataset.IndexedCachedDataset.check_index", "numpy.empty", "numpy.copyto", "torch.from_numpy().long", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedRawTextDataset.check_index"], ["", "", "@", "lru_cache", "(", "maxsize", "=", "8", ")", "\n", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "self", ".", "check_index", "(", "i", ")", "\n", "tensor_size", "=", "self", ".", "sizes", "[", "self", ".", "dim_offsets", "[", "i", "]", ":", "self", ".", "dim_offsets", "[", "i", "+", "1", "]", "]", "\n", "a", "=", "np", ".", "empty", "(", "tensor_size", ",", "dtype", "=", "self", ".", "dtype", ")", "\n", "ptx", "=", "self", ".", "cache_index", "[", "i", "]", "\n", "np", ".", "copyto", "(", "a", ",", "self", ".", "cache", "[", "ptx", ":", "ptx", "+", "a", ".", "size", "]", ")", "\n", "item", "=", "torch", ".", "from_numpy", "(", "a", ")", ".", "long", "(", ")", "\n", "if", "self", ".", "fix_lua_indexing", ":", "\n", "            ", "item", "-=", "1", "# subtract 1 for 0-based indexing", "\n", "", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedRawTextDataset.__init__": [[246, 254], ["indexed_dataset.IndexedRawTextDataset.read_data", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedRawTextDataset.read_data"], ["def", "__init__", "(", "self", ",", "path", ",", "dictionary", ",", "append_eos", "=", "True", ",", "reverse_order", "=", "False", ")", ":", "\n", "        ", "self", ".", "tokens_list", "=", "[", "]", "\n", "self", ".", "lines", "=", "[", "]", "\n", "self", ".", "sizes", "=", "[", "]", "\n", "self", ".", "append_eos", "=", "append_eos", "\n", "self", ".", "reverse_order", "=", "reverse_order", "\n", "self", ".", "read_data", "(", "path", ",", "dictionary", ")", "\n", "self", ".", "size", "=", "len", "(", "self", ".", "tokens_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedRawTextDataset.read_data": [[255, 268], ["numpy.array", "open", "indexed_dataset.IndexedRawTextDataset.lines.append", "dictionary.encode_line().long", "indexed_dataset.IndexedRawTextDataset.tokens_list.append", "indexed_dataset.IndexedRawTextDataset.sizes.append", "line.strip", "len", "dictionary.encode_line"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.encode_line"], ["", "def", "read_data", "(", "self", ",", "path", ",", "dictionary", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "self", ".", "lines", ".", "append", "(", "line", ".", "strip", "(", "\"\\n\"", ")", ")", "\n", "tokens", "=", "dictionary", ".", "encode_line", "(", "\n", "line", ",", "\n", "add_if_not_exist", "=", "False", ",", "\n", "append_eos", "=", "self", ".", "append_eos", ",", "\n", "reverse_order", "=", "self", ".", "reverse_order", ",", "\n", ")", ".", "long", "(", ")", "\n", "self", ".", "tokens_list", ".", "append", "(", "tokens", ")", "\n", "self", ".", "sizes", ".", "append", "(", "len", "(", "tokens", ")", ")", "\n", "", "", "self", ".", "sizes", "=", "np", ".", "array", "(", "self", ".", "sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedRawTextDataset.check_index": [[269, 272], ["IndexError"], "methods", ["None"], ["", "def", "check_index", "(", "self", ",", "i", ")", ":", "\n", "        ", "if", "i", "<", "0", "or", "i", ">=", "self", ".", "size", ":", "\n", "            ", "raise", "IndexError", "(", "\"index out of range\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedRawTextDataset.__getitem__": [[273, 277], ["functools.lru_cache", "indexed_dataset.IndexedRawTextDataset.check_index"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedRawTextDataset.check_index"], ["", "", "@", "lru_cache", "(", "maxsize", "=", "8", ")", "\n", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "self", ".", "check_index", "(", "i", ")", "\n", "return", "self", ".", "tokens_list", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedRawTextDataset.get_original_text": [[278, 281], ["indexed_dataset.IndexedRawTextDataset.check_index"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedRawTextDataset.check_index"], ["", "def", "get_original_text", "(", "self", ",", "i", ")", ":", "\n", "        ", "self", ".", "check_index", "(", "i", ")", "\n", "return", "self", ".", "lines", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedRawTextDataset.__del__": [[282, 284], ["None"], "methods", ["None"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedRawTextDataset.__len__": [[285, 287], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedRawTextDataset.num_tokens": [[288, 290], ["None"], "methods", ["None"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "sizes", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedRawTextDataset.size": [[291, 293], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "sizes", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedRawTextDataset.exists": [[294, 297], ["fairseq.file_io.PathManager.exists"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists"], ["", "@", "staticmethod", "\n", "def", "exists", "(", "path", ")", ":", "\n", "        ", "return", "PathManager", ".", "exists", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedDatasetBuilder.__init__": [[310, 317], ["open"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["def", "__init__", "(", "self", ",", "out_file", ",", "dtype", "=", "np", ".", "int32", ")", ":", "\n", "        ", "self", ".", "out_file", "=", "open", "(", "out_file", ",", "\"wb\"", ")", "\n", "self", ".", "dtype", "=", "dtype", "\n", "self", ".", "data_offsets", "=", "[", "0", "]", "\n", "self", ".", "dim_offsets", "=", "[", "0", "]", "\n", "self", ".", "sizes", "=", "[", "]", "\n", "self", ".", "element_size", "=", "self", ".", "element_sizes", "[", "self", ".", "dtype", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedDatasetBuilder.add_item": [[318, 325], ["indexed_dataset.IndexedDatasetBuilder.out_file.write", "indexed_dataset.IndexedDatasetBuilder.data_offsets.append", "tensor.size", "indexed_dataset.IndexedDatasetBuilder.dim_offsets.append", "numpy.array", "indexed_dataset.IndexedDatasetBuilder.sizes.append", "len", "tensor.numpy", "tensor.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "add_item", "(", "self", ",", "tensor", ")", ":", "\n", "# +1 for Lua compatibility", "\n", "        ", "bytes", "=", "self", ".", "out_file", ".", "write", "(", "np", ".", "array", "(", "tensor", ".", "numpy", "(", ")", "+", "1", ",", "dtype", "=", "self", ".", "dtype", ")", ")", "\n", "self", ".", "data_offsets", ".", "append", "(", "self", ".", "data_offsets", "[", "-", "1", "]", "+", "bytes", "/", "self", ".", "element_size", ")", "\n", "for", "s", "in", "tensor", ".", "size", "(", ")", ":", "\n", "            ", "self", ".", "sizes", ".", "append", "(", "s", ")", "\n", "", "self", ".", "dim_offsets", ".", "append", "(", "self", ".", "dim_offsets", "[", "-", "1", "]", "+", "len", "(", "tensor", ".", "size", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedDatasetBuilder.merge_file_": [[326, 345], ["indexed_dataset.IndexedDataset", "indexed_dataset.IndexedDatasetBuilder.sizes.extend", "indexed_dataset.IndexedDatasetBuilder.data_offsets.append", "indexed_dataset.IndexedDatasetBuilder.dim_offsets.append", "open", "indexed_dataset.data_file_path", "f.read", "indexed_dataset.IndexedDatasetBuilder.out_file.write"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.data_file_path"], ["", "def", "merge_file_", "(", "self", ",", "another_file", ")", ":", "\n", "        ", "index", "=", "IndexedDataset", "(", "another_file", ")", "\n", "assert", "index", ".", "dtype", "==", "self", ".", "dtype", "\n", "\n", "begin", "=", "self", ".", "data_offsets", "[", "-", "1", "]", "\n", "for", "offset", "in", "index", ".", "data_offsets", "[", "1", ":", "]", ":", "\n", "            ", "self", ".", "data_offsets", ".", "append", "(", "begin", "+", "offset", ")", "\n", "", "self", ".", "sizes", ".", "extend", "(", "index", ".", "sizes", ")", "\n", "begin", "=", "self", ".", "dim_offsets", "[", "-", "1", "]", "\n", "for", "dim_offset", "in", "index", ".", "dim_offsets", "[", "1", ":", "]", ":", "\n", "            ", "self", ".", "dim_offsets", ".", "append", "(", "begin", "+", "dim_offset", ")", "\n", "\n", "", "with", "open", "(", "data_file_path", "(", "another_file", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "data", "=", "f", ".", "read", "(", "1024", ")", "\n", "if", "data", ":", "\n", "                    ", "self", ".", "out_file", ".", "write", "(", "data", ")", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.IndexedDatasetBuilder.finalize": [[346, 357], ["indexed_dataset.IndexedDatasetBuilder.out_file.close", "open", "open.write", "open.write", "open.write", "open.write", "indexed_dataset.write_longs", "indexed_dataset.write_longs", "indexed_dataset.write_longs", "open.close", "struct.pack", "struct.pack", "struct.pack", "indexed_dataset.code", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.close", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.write_longs", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.write_longs", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.write_longs", "home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.close", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.code"], ["", "", "", "", "def", "finalize", "(", "self", ",", "index_file", ")", ":", "\n", "        ", "self", ".", "out_file", ".", "close", "(", ")", "\n", "index", "=", "open", "(", "index_file", ",", "\"wb\"", ")", "\n", "index", ".", "write", "(", "b\"TNTIDX\\x00\\x00\"", ")", "\n", "index", ".", "write", "(", "struct", ".", "pack", "(", "\"<Q\"", ",", "1", ")", ")", "\n", "index", ".", "write", "(", "struct", ".", "pack", "(", "\"<QQ\"", ",", "code", "(", "self", ".", "dtype", ")", ",", "self", ".", "element_size", ")", ")", "\n", "index", ".", "write", "(", "struct", ".", "pack", "(", "\"<QQ\"", ",", "len", "(", "self", ".", "data_offsets", ")", "-", "1", ",", "len", "(", "self", ".", "sizes", ")", ")", ")", "\n", "write_longs", "(", "index", ",", "self", ".", "dim_offsets", ")", "\n", "write_longs", "(", "index", ",", "self", ".", "data_offsets", ")", "\n", "write_longs", "(", "index", ",", "self", ".", "sizes", ")", "\n", "index", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.__init__": [[461, 469], ["super().__init__", "indexed_dataset.MMapIndexedDataset._do_init"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset._do_init"], ["", "", "def", "__init__", "(", "self", ",", "path", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "_path", "=", "None", "\n", "self", ".", "_index", "=", "None", "\n", "self", ".", "_bin_buffer", "=", "None", "\n", "\n", "self", ".", "_do_init", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.__getstate__": [[470, 472], ["None"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_path", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.__setstate__": [[473, 475], ["indexed_dataset.MMapIndexedDataset._do_init"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset._do_init"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "self", ".", "_do_init", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset._do_init": [[476, 485], ["indexed_dataset.MMapIndexedDataset.Index", "indexed_dataset._warmup_mmap_file", "numpy.memmap", "memoryview", "indexed_dataset.index_file_path", "indexed_dataset.data_file_path", "indexed_dataset.data_file_path"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset._warmup_mmap_file", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.index_file_path", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.data_file_path", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.data_file_path"], ["", "def", "_do_init", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "_path", "=", "path", "\n", "self", ".", "_index", "=", "self", ".", "Index", "(", "index_file_path", "(", "self", ".", "_path", ")", ")", "\n", "\n", "_warmup_mmap_file", "(", "data_file_path", "(", "self", ".", "_path", ")", ")", "\n", "self", ".", "_bin_buffer_mmap", "=", "np", ".", "memmap", "(", "\n", "data_file_path", "(", "self", ".", "_path", ")", ",", "mode", "=", "\"r\"", ",", "order", "=", "\"C\"", "\n", ")", "\n", "self", ".", "_bin_buffer", "=", "memoryview", "(", "self", ".", "_bin_buffer_mmap", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.__del__": [[486, 490], ["indexed_dataset.MMapIndexedDataset._bin_buffer_mmap._mmap.close"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.close"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_bin_buffer_mmap", ".", "_mmap", ".", "close", "(", ")", "\n", "del", "self", ".", "_bin_buffer_mmap", "\n", "del", "self", ".", "_index", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.__len__": [[491, 493], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.__getitem__": [[494, 504], ["functools.lru_cache", "numpy.frombuffer", "torch.from_numpy", "np_array.astype.astype.astype"], "methods", ["None"], ["", "@", "lru_cache", "(", "maxsize", "=", "8", ")", "\n", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "ptr", ",", "size", "=", "self", ".", "_index", "[", "i", "]", "\n", "np_array", "=", "np", ".", "frombuffer", "(", "\n", "self", ".", "_bin_buffer", ",", "dtype", "=", "self", ".", "_index", ".", "dtype", ",", "count", "=", "size", ",", "offset", "=", "ptr", "\n", ")", "\n", "if", "self", ".", "_index", ".", "dtype", "!=", "np", ".", "int64", ":", "\n", "            ", "np_array", "=", "np_array", ".", "astype", "(", "np", ".", "int64", ")", "\n", "\n", "", "return", "torch", ".", "from_numpy", "(", "np_array", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.sizes": [[505, 508], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_index", ".", "sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.supports_prefetch": [[509, 512], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists": [[513, 517], ["fairseq.file_io.PathManager.exists", "fairseq.file_io.PathManager.exists", "indexed_dataset.index_file_path", "indexed_dataset.data_file_path"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.index_file_path", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.data_file_path"], ["", "@", "staticmethod", "\n", "def", "exists", "(", "path", ")", ":", "\n", "        ", "return", "PathManager", ".", "exists", "(", "index_file_path", "(", "path", ")", ")", "and", "PathManager", ".", "exists", "(", "\n", "data_file_path", "(", "path", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDatasetBuilder.__init__": [[535, 539], ["open"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["    ", "def", "__init__", "(", "self", ",", "out_file", ",", "dtype", "=", "np", ".", "int64", ")", ":", "\n", "        ", "self", ".", "_data_file", "=", "open", "(", "out_file", ",", "\"wb\"", ")", "\n", "self", ".", "_dtype", "=", "dtype", "\n", "self", ".", "_sizes", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDatasetBuilder.add_item": [[540, 544], ["numpy.array", "indexed_dataset.MMapIndexedDatasetBuilder._data_file.write", "indexed_dataset.MMapIndexedDatasetBuilder._sizes.append", "tensor.numpy", "numpy.array.tobytes"], "methods", ["None"], ["", "def", "add_item", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "np_array", "=", "np", ".", "array", "(", "tensor", ".", "numpy", "(", ")", ",", "dtype", "=", "self", ".", "_dtype", ")", "\n", "self", ".", "_data_file", ".", "write", "(", "np_array", ".", "tobytes", "(", "order", "=", "\"C\"", ")", ")", "\n", "self", ".", "_sizes", ".", "append", "(", "np_array", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDatasetBuilder.merge_file_": [[545, 556], ["MMapIndexedDataset.Index", "indexed_dataset.index_file_path", "indexed_dataset.MMapIndexedDatasetBuilder._sizes.append", "open", "shutil.copyfileobj", "indexed_dataset.data_file_path"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.index_file_path", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.data_file_path"], ["", "def", "merge_file_", "(", "self", ",", "another_file", ")", ":", "\n", "# Concatenate index", "\n", "        ", "index", "=", "MMapIndexedDataset", ".", "Index", "(", "index_file_path", "(", "another_file", ")", ")", "\n", "assert", "index", ".", "dtype", "==", "self", ".", "_dtype", "\n", "\n", "for", "size", "in", "index", ".", "sizes", ":", "\n", "            ", "self", ".", "_sizes", ".", "append", "(", "size", ")", "\n", "\n", "# Concatenate data", "\n", "", "with", "open", "(", "data_file_path", "(", "another_file", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "shutil", ".", "copyfileobj", "(", "f", ",", "self", ".", "_data_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDatasetBuilder.finalize": [[557, 562], ["indexed_dataset.MMapIndexedDatasetBuilder._data_file.close", "MMapIndexedDataset.Index.writer", "index.write"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.close"], ["", "", "def", "finalize", "(", "self", ",", "index_file", ")", ":", "\n", "        ", "self", ".", "_data_file", ".", "close", "(", ")", "\n", "\n", "with", "MMapIndexedDataset", ".", "Index", ".", "writer", "(", "index_file", ",", "self", ".", "_dtype", ")", "as", "index", ":", "\n", "            ", "index", ".", "write", "(", "self", ".", "_sizes", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.__best_fitting_dtype": [[19, 24], ["None"], "function", ["None"], ["def", "__best_fitting_dtype", "(", "vocab_size", "=", "None", ")", ":", "\n", "    ", "if", "vocab_size", "is", "not", "None", "and", "vocab_size", "<", "65500", ":", "\n", "        ", "return", "np", ".", "uint16", "\n", "", "else", ":", "\n", "        ", "return", "np", ".", "int32", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.get_available_dataset_impl": [[26, 28], ["list", "map"], "function", ["None"], ["", "", "def", "get_available_dataset_impl", "(", ")", ":", "\n", "    ", "return", "list", "(", "map", "(", "str", ",", "DATASET_IMPL_CHOICES", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.infer_dataset_impl": [[30, 46], ["indexed_dataset.IndexedRawTextDataset.exists", "indexed_dataset.IndexedDataset.exists", "fairseq.data.fasta_dataset.FastaDataset.exists", "open", "f.read", "indexed_dataset.index_file_path"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.index_file_path"], ["", "def", "infer_dataset_impl", "(", "path", ")", ":", "\n", "    ", "if", "IndexedRawTextDataset", ".", "exists", "(", "path", ")", ":", "\n", "        ", "return", "\"raw\"", "\n", "", "elif", "IndexedDataset", ".", "exists", "(", "path", ")", ":", "\n", "        ", "with", "open", "(", "index_file_path", "(", "path", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "magic", "=", "f", ".", "read", "(", "8", ")", "\n", "if", "magic", "==", "IndexedDataset", ".", "_HDR_MAGIC", ":", "\n", "                ", "return", "\"cached\"", "\n", "", "elif", "magic", "==", "MMapIndexedDataset", ".", "Index", ".", "_HDR_MAGIC", "[", ":", "8", "]", ":", "\n", "                ", "return", "\"mmap\"", "\n", "", "else", ":", "\n", "                ", "return", "None", "\n", "", "", "", "elif", "FastaDataset", ".", "exists", "(", "path", ")", ":", "\n", "        ", "return", "\"fasta\"", "\n", "", "else", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.make_builder": [[48, 57], ["indexed_dataset.MMapIndexedDatasetBuilder", "indexed_dataset.IndexedDatasetBuilder", "indexed_dataset.__best_fitting_dtype"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.__best_fitting_dtype"], ["", "", "def", "make_builder", "(", "out_file", ",", "impl", ",", "vocab_size", "=", "None", ")", ":", "\n", "    ", "if", "impl", "==", "\"mmap\"", ":", "\n", "        ", "return", "MMapIndexedDatasetBuilder", "(", "\n", "out_file", ",", "dtype", "=", "__best_fitting_dtype", "(", "vocab_size", ")", "\n", ")", "\n", "", "elif", "impl", "==", "\"fasta\"", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "        ", "return", "IndexedDatasetBuilder", "(", "out_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.make_dataset": [[59, 74], ["indexed_dataset.IndexedRawTextDataset.exists", "indexed_dataset.IndexedRawTextDataset", "indexed_dataset.IndexedDataset.exists", "indexed_dataset.IndexedDataset", "indexed_dataset.IndexedDataset.exists", "indexed_dataset.IndexedCachedDataset", "indexed_dataset.MMapIndexedDataset.exists", "indexed_dataset.MMapIndexedDataset", "fairseq.data.fasta_dataset.FastaDataset.exists", "EncodedFastaDataset"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists"], ["", "", "def", "make_dataset", "(", "path", ",", "impl", ",", "fix_lua_indexing", "=", "False", ",", "dictionary", "=", "None", ")", ":", "\n", "    ", "if", "impl", "==", "\"raw\"", "and", "IndexedRawTextDataset", ".", "exists", "(", "path", ")", ":", "\n", "        ", "assert", "dictionary", "is", "not", "None", "\n", "return", "IndexedRawTextDataset", "(", "path", ",", "dictionary", ")", "\n", "", "elif", "impl", "==", "\"lazy\"", "and", "IndexedDataset", ".", "exists", "(", "path", ")", ":", "\n", "        ", "return", "IndexedDataset", "(", "path", ",", "fix_lua_indexing", "=", "fix_lua_indexing", ")", "\n", "", "elif", "impl", "==", "\"cached\"", "and", "IndexedDataset", ".", "exists", "(", "path", ")", ":", "\n", "        ", "return", "IndexedCachedDataset", "(", "path", ",", "fix_lua_indexing", "=", "fix_lua_indexing", ")", "\n", "", "elif", "impl", "==", "\"mmap\"", "and", "MMapIndexedDataset", ".", "exists", "(", "path", ")", ":", "\n", "        ", "return", "MMapIndexedDataset", "(", "path", ")", "\n", "", "elif", "impl", "==", "\"fasta\"", "and", "FastaDataset", ".", "exists", "(", "path", ")", ":", "\n", "        ", "from", "fairseq", ".", "data", ".", "fasta_dataset", "import", "EncodedFastaDataset", "\n", "\n", "return", "EncodedFastaDataset", "(", "path", ",", "dictionary", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.dataset_exists": [[76, 83], ["indexed_dataset.IndexedRawTextDataset.exists", "indexed_dataset.MMapIndexedDataset.exists", "indexed_dataset.IndexedDataset.exists"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists"], ["", "def", "dataset_exists", "(", "path", ",", "impl", ")", ":", "\n", "    ", "if", "impl", "==", "\"raw\"", ":", "\n", "        ", "return", "IndexedRawTextDataset", ".", "exists", "(", "path", ")", "\n", "", "elif", "impl", "==", "\"mmap\"", ":", "\n", "        ", "return", "MMapIndexedDataset", ".", "exists", "(", "path", ")", "\n", "", "else", ":", "\n", "        ", "return", "IndexedDataset", ".", "exists", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.read_longs": [[85, 89], ["numpy.empty", "f.readinto"], "function", ["None"], ["", "", "def", "read_longs", "(", "f", ",", "n", ")", ":", "\n", "    ", "a", "=", "np", ".", "empty", "(", "n", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "f", ".", "readinto", "(", "a", ")", "\n", "return", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.write_longs": [[91, 93], ["f.write", "numpy.array"], "function", ["None"], ["", "def", "write_longs", "(", "f", ",", "a", ")", ":", "\n", "    ", "f", ".", "write", "(", "np", ".", "array", "(", "a", ",", "dtype", "=", "np", ".", "int64", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.code": [[107, 112], ["dtypes.keys", "ValueError"], "function", ["None"], ["def", "code", "(", "dtype", ")", ":", "\n", "    ", "for", "k", "in", "dtypes", ".", "keys", "(", ")", ":", "\n", "        ", "if", "dtypes", "[", "k", "]", "==", "dtype", ":", "\n", "            ", "return", "k", "\n", "", "", "raise", "ValueError", "(", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.index_file_path": [[114, 116], ["None"], "function", ["None"], ["", "def", "index_file_path", "(", "prefix_path", ")", ":", "\n", "    ", "return", "prefix_path", "+", "\".idx\"", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.data_file_path": [[118, 120], ["None"], "function", ["None"], ["", "def", "data_file_path", "(", "prefix_path", ")", ":", "\n", "    ", "return", "prefix_path", "+", "\".bin\"", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset._warmup_mmap_file": [[359, 363], ["open", "stream.read"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["", "", "def", "_warmup_mmap_file", "(", "path", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "\"rb\"", ")", "as", "stream", ":", "\n", "        ", "while", "stream", ".", "read", "(", "100", "*", "1024", "*", "1024", ")", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.get_indexed_dataset_to_local": [[520, 532], ["fairseq.file_io.PathManager.get_local_path", "fairseq.file_io.PathManager.get_local_path", "indexed_dataset.index_file_path", "indexed_dataset.data_file_path", "PathManager.get_local_path.endswith", "PathManager.get_local_path.endswith"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.get_local_path", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.get_local_path", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.index_file_path", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.data_file_path"], ["", "", "def", "get_indexed_dataset_to_local", "(", "path", ")", ":", "\n", "    ", "local_index_path", "=", "PathManager", ".", "get_local_path", "(", "index_file_path", "(", "path", ")", ")", "\n", "local_data_path", "=", "PathManager", ".", "get_local_path", "(", "data_file_path", "(", "path", ")", ")", "\n", "\n", "assert", "local_index_path", ".", "endswith", "(", "\".idx\"", ")", "and", "local_data_path", ".", "endswith", "(", "\".bin\"", ")", ",", "(", "\n", "\"PathManager.get_local_path does not return files with expected patterns: \"", "\n", "f\"{local_index_path} and {local_data_path}\"", "\n", ")", "\n", "\n", "local_path", "=", "local_data_path", "[", ":", "-", "4", "]", "# stripping surfix \".bin\"", "\n", "assert", "local_path", "==", "local_index_path", "[", ":", "-", "4", "]", "# stripping surfix \".idx\"", "\n", "return", "local_path", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.replace_dataset.ReplaceDataset.__init__": [[19, 24], ["BaseWrapperDataset.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "dataset", ",", "replace_map", ",", "offsets", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ")", "\n", "assert", "len", "(", "replace_map", ")", ">", "0", "\n", "self", ".", "replace_map", "=", "replace_map", "\n", "self", ".", "offsets", "=", "offsets", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.replace_dataset.ReplaceDataset.__getitem__": [[25, 37], ["isinstance", "zip", "replace_dataset.ReplaceDataset.replace_map.items", "src_off.masked_fill_"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "item", "=", "self", ".", "dataset", "[", "index", "]", "\n", "is_tuple", "=", "isinstance", "(", "item", ",", "tuple", ")", "\n", "srcs", "=", "item", "if", "is_tuple", "else", "[", "item", "]", "\n", "\n", "for", "offset", ",", "src", "in", "zip", "(", "self", ".", "offsets", ",", "srcs", ")", ":", "\n", "            ", "for", "k", ",", "v", "in", "self", ".", "replace_map", ".", "items", "(", ")", ":", "\n", "                ", "src_off", "=", "src", "[", "offset", ":", "]", "if", "offset", ">=", "0", "else", "src", "[", ":", "offset", "]", "\n", "src_off", ".", "masked_fill_", "(", "src_off", "==", "k", ",", "v", ")", "\n", "\n", "", "", "item", "=", "srcs", "if", "is_tuple", "else", "srcs", "[", "0", "]", "\n", "return", "item", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.base_wrapper_dataset.BaseWrapperDataset.__init__": [[12, 15], ["FairseqDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.base_wrapper_dataset.BaseWrapperDataset.__getitem__": [[16, 18], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "dataset", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.base_wrapper_dataset.BaseWrapperDataset.__len__": [[19, 21], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.base_wrapper_dataset.BaseWrapperDataset.collater": [[22, 27], ["hasattr", "base_wrapper_dataset.BaseWrapperDataset.dataset.collater", "torch.utils.data.dataloader.default_collate"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.collater"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "dataset", ",", "\"collater\"", ")", ":", "\n", "            ", "return", "self", ".", "dataset", ".", "collater", "(", "samples", ")", "\n", "", "else", ":", "\n", "            ", "return", "default_collate", "(", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.base_wrapper_dataset.BaseWrapperDataset.sizes": [[28, 31], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.base_wrapper_dataset.BaseWrapperDataset.num_tokens": [[32, 34], ["base_wrapper_dataset.BaseWrapperDataset.dataset.num_tokens"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.num_tokens"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "num_tokens", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.base_wrapper_dataset.BaseWrapperDataset.size": [[35, 37], ["base_wrapper_dataset.BaseWrapperDataset.dataset.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "size", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.base_wrapper_dataset.BaseWrapperDataset.ordered_indices": [[38, 40], ["base_wrapper_dataset.BaseWrapperDataset.dataset.ordered_indices"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.ordered_indices"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "ordered_indices", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.base_wrapper_dataset.BaseWrapperDataset.supports_prefetch": [[41, 44], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ".", "dataset", ",", "\"supports_prefetch\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.base_wrapper_dataset.BaseWrapperDataset.attr": [[45, 47], ["base_wrapper_dataset.BaseWrapperDataset.dataset.attr"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.attr"], ["", "def", "attr", "(", "self", ",", "attr", ":", "str", ",", "index", ":", "int", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "attr", "(", "attr", ",", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.base_wrapper_dataset.BaseWrapperDataset.prefetch": [[48, 50], ["base_wrapper_dataset.BaseWrapperDataset.dataset.prefetch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "self", ".", "dataset", ".", "prefetch", "(", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.base_wrapper_dataset.BaseWrapperDataset.get_batch_shapes": [[51, 53], ["base_wrapper_dataset.BaseWrapperDataset.dataset.get_batch_shapes"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.language_pair_dataset.LanguagePairDataset.get_batch_shapes"], ["", "def", "get_batch_shapes", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "get_batch_shapes", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.base_wrapper_dataset.BaseWrapperDataset.batch_by_size": [[54, 66], ["base_wrapper_dataset.BaseWrapperDataset.dataset.batch_by_size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.base_wrapper_dataset.BaseWrapperDataset.batch_by_size"], ["", "def", "batch_by_size", "(", "\n", "self", ",", "\n", "indices", ",", "\n", "max_tokens", "=", "None", ",", "\n", "max_sentences", "=", "None", ",", "\n", "required_batch_size_multiple", "=", "1", ",", "\n", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "batch_by_size", "(", "\n", "indices", ",", "\n", "max_tokens", "=", "max_tokens", ",", "\n", "max_sentences", "=", "max_sentences", ",", "\n", "required_batch_size_multiple", "=", "required_batch_size_multiple", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.base_wrapper_dataset.BaseWrapperDataset.filter_indices_by_size": [[68, 70], ["base_wrapper_dataset.BaseWrapperDataset.dataset.filter_indices_by_size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.filter_indices_by_size"], ["", "def", "filter_indices_by_size", "(", "self", ",", "indices", ",", "max_sizes", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "filter_indices_by_size", "(", "indices", ",", "max_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.base_wrapper_dataset.BaseWrapperDataset.can_reuse_epoch_itr_across_epochs": [[71, 74], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "can_reuse_epoch_itr_across_epochs", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "can_reuse_epoch_itr_across_epochs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.base_wrapper_dataset.BaseWrapperDataset.set_epoch": [[75, 79], ["super().set_epoch", "hasattr", "base_wrapper_dataset.BaseWrapperDataset.dataset.set_epoch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "super", "(", ")", ".", "set_epoch", "(", "epoch", ")", "\n", "if", "hasattr", "(", "self", ".", "dataset", ",", "\"set_epoch\"", ")", ":", "\n", "            ", "self", ".", "dataset", ".", "set_epoch", "(", "epoch", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.strip_token_dataset.StripTokenDataset.__init__": [[10, 13], ["BaseWrapperDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "id_to_strip", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ")", "\n", "self", ".", "id_to_strip", "=", "id_to_strip", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.strip_token_dataset.StripTokenDataset.__getitem__": [[14, 21], ["len", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "item", "=", "self", ".", "dataset", "[", "index", "]", "\n", "while", "len", "(", "item", ")", ">", "0", "and", "item", "[", "-", "1", "]", "==", "self", ".", "id_to_strip", ":", "\n", "            ", "item", "=", "item", "[", ":", "-", "1", "]", "\n", "", "while", "len", "(", "item", ")", ">", "0", "and", "item", "[", "0", "]", "==", "self", ".", "id_to_strip", ":", "\n", "            ", "item", "=", "item", "[", "1", ":", "]", "\n", "", "return", "item", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_lang_pair_dataset.TransformEosLangPairDataset.__init__": [[30, 43], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ":", "FairseqDataset", ",", "\n", "src_eos", ":", "int", ",", "\n", "new_src_eos", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "tgt_bos", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "new_tgt_bos", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "src_eos", "=", "src_eos", "\n", "self", ".", "new_src_eos", "=", "new_src_eos", "\n", "self", ".", "tgt_bos", "=", "tgt_bos", "\n", "self", ".", "new_tgt_bos", "=", "new_tgt_bos", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_lang_pair_dataset.TransformEosLangPairDataset.__getitem__": [[44, 46], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "dataset", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_lang_pair_dataset.TransformEosLangPairDataset.__len__": [[47, 49], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_lang_pair_dataset.TransformEosLangPairDataset.collater": [[50, 89], ["transform_eos_lang_pair_dataset.TransformEosLangPairDataset.dataset.collater", "len", "eos_idx.resize_.resize_.resize_", "[].scatter_", "NotImplementedError", "len", "torch.arange", "eos_idx.resize_.resize_.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.collater", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "collater", "(", "self", ",", "samples", ",", "**", "extra_args", ")", ":", "\n", "        ", "samples", "=", "self", ".", "dataset", ".", "collater", "(", "samples", ",", "**", "extra_args", ")", "\n", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "            ", "return", "{", "}", "\n", "", "if", "self", ".", "new_src_eos", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "dataset", ".", "left_pad_source", ":", "\n", "                ", "assert", "(", "\n", "samples", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "[", ":", ",", "-", "1", "]", "!=", "self", ".", "src_eos", "\n", ")", ".", "sum", "(", ")", "==", "0", "\n", "samples", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "[", ":", ",", "-", "1", "]", "=", "self", ".", "new_src_eos", "\n", "", "else", ":", "\n", "                ", "eos_idx", "=", "samples", "[", "\"net_input\"", "]", "[", "\"src_lengths\"", "]", "-", "1", "\n", "assert", "(", "\n", "samples", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "[", "\n", "torch", ".", "arange", "(", "eos_idx", ".", "size", "(", "0", ")", ")", ",", "eos_idx", "\n", "]", "\n", "!=", "self", ".", "src_eos", "\n", ")", ".", "sum", "(", ")", "==", "0", "\n", "eos_idx", "=", "eos_idx", ".", "resize_", "(", "len", "(", "samples", "[", "\"net_input\"", "]", "[", "\"src_lengths\"", "]", ")", ",", "1", ")", "\n", "samples", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", ".", "scatter_", "(", "\n", "1", ",", "eos_idx", ",", "self", ".", "new_src_eos", "\n", ")", "\n", "\n", "", "", "if", "(", "\n", "self", ".", "new_tgt_bos", "is", "not", "None", "\n", "and", "\"prev_output_tokens\"", "in", "samples", "[", "\"net_input\"", "]", "\n", ")", ":", "\n", "            ", "if", "self", ".", "dataset", ".", "left_pad_target", ":", "\n", "# TODO: support different padding direction on target side", "\n", "                ", "raise", "NotImplementedError", "(", "\n", "\"TransformEosLangPairDataset does not implement --left-pad-target True option\"", "\n", ")", "\n", "", "else", ":", "\n", "                ", "assert", "(", "\n", "samples", "[", "\"net_input\"", "]", "[", "\"prev_output_tokens\"", "]", "[", ":", ",", "0", "]", "!=", "self", ".", "tgt_bos", "\n", ")", ".", "sum", "(", ")", "==", "0", "\n", "samples", "[", "\"net_input\"", "]", "[", "\"prev_output_tokens\"", "]", "[", ":", ",", "0", "]", "=", "self", ".", "new_tgt_bos", "\n", "", "", "samples", "[", "\"dataset_type\"", "]", "=", "\"mt\"", "\n", "return", "samples", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_lang_pair_dataset.TransformEosLangPairDataset.num_tokens": [[90, 92], ["transform_eos_lang_pair_dataset.TransformEosLangPairDataset.dataset.num_tokens"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.num_tokens"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "num_tokens", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_lang_pair_dataset.TransformEosLangPairDataset.size": [[93, 95], ["transform_eos_lang_pair_dataset.TransformEosLangPairDataset.dataset.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "size", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_lang_pair_dataset.TransformEosLangPairDataset.sizes": [[96, 100], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "# dataset.sizes can be a dynamically computed sizes:", "\n", "        ", "return", "self", ".", "dataset", ".", "sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_lang_pair_dataset.TransformEosLangPairDataset.ordered_indices": [[101, 103], ["transform_eos_lang_pair_dataset.TransformEosLangPairDataset.dataset.ordered_indices"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.ordered_indices"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "ordered_indices", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_lang_pair_dataset.TransformEosLangPairDataset.supports_prefetch": [[104, 107], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ".", "dataset", ",", "\"supports_prefetch\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.transform_eos_lang_pair_dataset.TransformEosLangPairDataset.prefetch": [[108, 110], ["transform_eos_lang_pair_dataset.TransformEosLangPairDataset.dataset.prefetch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "prefetch", "(", "indices", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.num_samples_dataset.NumSamplesDataset.__getitem__": [[10, 12], ["None"], "methods", ["None"], ["    ", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.num_samples_dataset.NumSamplesDataset.__len__": [[13, 15], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.num_samples_dataset.NumSamplesDataset.collater": [[16, 18], ["sum"], "methods", ["None"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "return", "sum", "(", "samples", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.sort_dataset.SortDataset.__init__": [[12, 19], ["BaseWrapperDataset.__init__", "all", "isinstance", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "sort_order", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ")", "\n", "if", "not", "isinstance", "(", "sort_order", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "sort_order", "=", "[", "sort_order", "]", "\n", "", "self", ".", "sort_order", "=", "sort_order", "\n", "\n", "assert", "all", "(", "len", "(", "so", ")", "==", "len", "(", "dataset", ")", "for", "so", "in", "sort_order", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.sort_dataset.SortDataset.ordered_indices": [[20, 22], ["numpy.lexsort"], "methods", ["None"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "lexsort", "(", "self", ".", "sort_order", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_sampled_dataset.MultiCorpusSampledDataset.__init__": [[31, 49], ["FairseqDataset.__init__", "isinstance", "datasets.items", "isinstance", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "datasets", ":", "Dict", "[", "str", ",", "FairseqDataset", "]", ",", "\n", "sampling_func", ":", "Callable", "[", "[", "List", "]", ",", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "datasets", ",", "OrderedDict", ")", "\n", "self", ".", "datasets", "=", "datasets", "\n", "if", "sampling_func", "is", "None", ":", "\n", "            ", "sampling_func", "=", "uniform_sampler", "\n", "", "self", ".", "sampling_func", "=", "sampling_func", "\n", "\n", "self", ".", "total_num_instances", "=", "0", "\n", "for", "_", ",", "dataset", "in", "datasets", ".", "items", "(", ")", ":", "\n", "            ", "assert", "isinstance", "(", "dataset", ",", "FairseqDataset", ")", "\n", "self", ".", "total_num_instances", "+=", "len", "(", "dataset", ")", "\n", "\n", "", "self", ".", "_ordered_indices", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_sampled_dataset.MultiCorpusSampledDataset.__len__": [[50, 55], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Length of this dataset is the sum of individual datasets\n        \"\"\"", "\n", "return", "self", ".", "total_num_instances", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_sampled_dataset.MultiCorpusSampledDataset.ordered_indices": [[56, 70], ["numpy.arange", "collections.OrderedDict", "len", "dataset.ordered_indices", "multi_corpus_sampled_dataset.MultiCorpusSampledDataset.datasets.items"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.ordered_indices"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Ordered indices for batching. Here we call the underlying\n        dataset's ordered_indices() so that we get the same random ordering\n        as we would have from using the underlying dataset directly.\n        \"\"\"", "\n", "if", "self", ".", "_ordered_indices", "is", "None", ":", "\n", "            ", "self", ".", "_ordered_indices", "=", "OrderedDict", "(", "\n", "[", "\n", "(", "key", ",", "dataset", ".", "ordered_indices", "(", ")", ")", "\n", "for", "key", ",", "dataset", "in", "self", ".", "datasets", ".", "items", "(", ")", "\n", "]", "\n", ")", "\n", "", "return", "np", ".", "arange", "(", "len", "(", "self", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_sampled_dataset.MultiCorpusSampledDataset._map_index_to_dataset": [[71, 83], ["len"], "methods", ["None"], ["", "def", "_map_index_to_dataset", "(", "self", ",", "key", ":", "int", ",", "index", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Different underlying datasets have different lengths. In order to ensure\n        we are not accessing an index outside the range of the current dataset\n        size, we wrap around. This function should be called after we have\n        created an ordering for this and all underlying datasets.\n        \"\"\"", "\n", "assert", "(", "\n", "self", ".", "_ordered_indices", "is", "not", "None", "\n", ")", ",", "\"Must call MultiCorpusSampledDataset.ordered_indices() first\"", "\n", "mapped_index", "=", "index", "%", "len", "(", "self", ".", "datasets", "[", "key", "]", ")", "\n", "return", "self", ".", "_ordered_indices", "[", "key", "]", "[", "mapped_index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_sampled_dataset.MultiCorpusSampledDataset.__getitem__": [[84, 94], ["collections.OrderedDict", "multi_corpus_sampled_dataset.MultiCorpusSampledDataset.datasets.items", "multi_corpus_sampled_dataset.MultiCorpusSampledDataset._map_index_to_dataset"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_sampled_dataset.MultiCorpusSampledDataset._map_index_to_dataset"], ["", "def", "__getitem__", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Get the item associated with index from each underlying dataset.\n        Since index is in the range of [0, TotalNumInstances], we need to\n        map the index to the dataset before retrieving the item.\n        \"\"\"", "\n", "return", "OrderedDict", "(", "\n", "[", "\n", "(", "key", ",", "dataset", "[", "self", ".", "_map_index_to_dataset", "(", "key", ",", "index", ")", "]", ")", "\n", "for", "key", ",", "dataset", "in", "self", ".", "datasets", ".", "items", "(", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_sampled_dataset.MultiCorpusSampledDataset.collater": [[97, 111], ["multi_corpus_sampled_dataset.MultiCorpusSampledDataset.sampling_func", "multi_corpus_sampled_dataset.MultiCorpusSampledDataset.datasets[].collater", "len", "list", "multi_corpus_sampled_dataset.MultiCorpusSampledDataset.datasets.keys"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.collater"], ["", "def", "collater", "(", "self", ",", "samples", ":", "List", "[", "Dict", "]", ")", ":", "\n", "        ", "\"\"\"\n        Generate a mini-batch for this dataset.\n        To convert this into a regular mini-batch we use the following\n        logic:\n            1. Select a dataset using the specified probability distribution.\n            2. Call the collater function of the selected dataset.\n        \"\"\"", "\n", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "", "selected_key", "=", "self", ".", "sampling_func", "(", "list", "(", "self", ".", "datasets", ".", "keys", "(", ")", ")", ")", "\n", "selected_samples", "=", "[", "sample", "[", "selected_key", "]", "for", "sample", "in", "samples", "]", "\n", "return", "self", ".", "datasets", "[", "selected_key", "]", ".", "collater", "(", "selected_samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_sampled_dataset.MultiCorpusSampledDataset.num_tokens": [[112, 121], ["max", "dataset.num_tokens", "multi_corpus_sampled_dataset.MultiCorpusSampledDataset._map_index_to_dataset", "multi_corpus_sampled_dataset.MultiCorpusSampledDataset.datasets.items"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.num_tokens", "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_sampled_dataset.MultiCorpusSampledDataset._map_index_to_dataset"], ["", "def", "num_tokens", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Return an example's length (number of tokens), used for batching. Here\n        we return the max across all examples at index across all underlying\n        datasets.\n        \"\"\"", "\n", "return", "max", "(", "\n", "dataset", ".", "num_tokens", "(", "self", ".", "_map_index_to_dataset", "(", "key", ",", "index", ")", ")", "\n", "for", "key", ",", "dataset", "in", "self", ".", "datasets", ".", "items", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_sampled_dataset.MultiCorpusSampledDataset.size": [[123, 132], ["max", "dataset.size", "multi_corpus_sampled_dataset.MultiCorpusSampledDataset._map_index_to_dataset", "multi_corpus_sampled_dataset.MultiCorpusSampledDataset.datasets.items"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_sampled_dataset.MultiCorpusSampledDataset._map_index_to_dataset"], ["", "def", "size", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Return an example's size as a float or tuple. Here we return the max\n        across all underlying datasets. This value is used when filtering a\n        dataset with max-positions.\n        \"\"\"", "\n", "return", "max", "(", "\n", "dataset", ".", "size", "(", "self", ".", "_map_index_to_dataset", "(", "key", ",", "index", ")", ")", "\n", "for", "key", ",", "dataset", "in", "self", ".", "datasets", ".", "items", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_sampled_dataset.MultiCorpusSampledDataset.supports_prefetch": [[134, 139], ["all", "getattr", "multi_corpus_sampled_dataset.MultiCorpusSampledDataset.datasets.values"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "all", "(", "\n", "getattr", "(", "dataset", ",", "\"supports_prefetch\"", ",", "False", ")", "\n", "for", "dataset", "in", "self", ".", "datasets", ".", "values", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_sampled_dataset.MultiCorpusSampledDataset.prefetch": [[141, 145], ["multi_corpus_sampled_dataset.MultiCorpusSampledDataset.datasets.items", "dataset.prefetch", "multi_corpus_sampled_dataset.MultiCorpusSampledDataset._map_index_to_dataset"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch", "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_sampled_dataset.MultiCorpusSampledDataset._map_index_to_dataset"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "for", "key", ",", "dataset", "in", "self", ".", "datasets", ".", "items", "(", ")", ":", "\n", "            ", "dataset", ".", "prefetch", "(", "\n", "[", "self", ".", "_map_index_to_dataset", "(", "key", ",", "index", ")", "for", "index", "in", "indices", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_sampled_dataset.MultiCorpusSampledDataset.supports_fetch_outside_dataloader": [[147, 152], ["all"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "supports_fetch_outside_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "all", "(", "\n", "self", ".", "datasets", "[", "key", "]", ".", "supports_fetch_outside_dataloader", "\n", "for", "key", "in", "self", ".", "datasets", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_sampled_dataset.uniform_sampler": [[14, 17], ["numpy.random.choice().item", "numpy.random.choice"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.item"], ["def", "uniform_sampler", "(", "x", ")", ":", "\n", "# Sample from uniform distribution", "\n", "    ", "return", "np", ".", "random", ".", "choice", "(", "x", ",", "1", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.mask_tokens_dataset.MaskTokensDataset.apply_mask": [[44, 51], ["LRUCacheDataset", "LRUCacheDataset", "LRUCacheDataset", "cls", "cls"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["@", "classmethod", "\n", "def", "apply_mask", "(", "cls", ",", "dataset", ":", "torch", ".", "utils", ".", "data", ".", "Dataset", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Return the source and target datasets for masked LM training.\"\"\"", "\n", "dataset", "=", "LRUCacheDataset", "(", "dataset", ")", "\n", "return", "(", "\n", "LRUCacheDataset", "(", "cls", "(", "dataset", ",", "*", "args", ",", "**", "kwargs", ",", "return_masked_tokens", "=", "False", ")", ")", ",", "\n", "LRUCacheDataset", "(", "cls", "(", "dataset", ",", "*", "args", ",", "**", "kwargs", ",", "return_masked_tokens", "=", "True", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.mask_tokens_dataset.MaskTokensDataset.__init__": [[53, 92], ["numpy.array", "numpy.ones", "numpy.ones.sum", "len"], "methods", ["None"], ["", "def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ":", "torch", ".", "utils", ".", "data", ".", "Dataset", ",", "\n", "vocab", ":", "Dictionary", ",", "\n", "pad_idx", ":", "int", ",", "\n", "mask_idx", ":", "int", ",", "\n", "return_masked_tokens", ":", "bool", "=", "False", ",", "\n", "seed", ":", "int", "=", "1", ",", "\n", "mask_prob", ":", "float", "=", "0.15", ",", "\n", "leave_unmasked_prob", ":", "float", "=", "0.1", ",", "\n", "random_token_prob", ":", "float", "=", "0.1", ",", "\n", "freq_weighted_replacement", ":", "bool", "=", "False", ",", "\n", "mask_whole_words", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", ")", ":", "\n", "        ", "assert", "0.0", "<", "mask_prob", "<", "1.0", "\n", "assert", "0.0", "<=", "random_token_prob", "<=", "1.0", "\n", "assert", "0.0", "<=", "leave_unmasked_prob", "<=", "1.0", "\n", "assert", "random_token_prob", "+", "leave_unmasked_prob", "<=", "1.0", "\n", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "pad_idx", "=", "pad_idx", "\n", "self", ".", "mask_idx", "=", "mask_idx", "\n", "self", ".", "return_masked_tokens", "=", "return_masked_tokens", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "mask_prob", "=", "mask_prob", "\n", "self", ".", "leave_unmasked_prob", "=", "leave_unmasked_prob", "\n", "self", ".", "random_token_prob", "=", "random_token_prob", "\n", "self", ".", "mask_whole_words", "=", "mask_whole_words", "\n", "\n", "if", "random_token_prob", ">", "0.0", ":", "\n", "            ", "if", "freq_weighted_replacement", ":", "\n", "                ", "weights", "=", "np", ".", "array", "(", "self", ".", "vocab", ".", "count", ")", "\n", "", "else", ":", "\n", "                ", "weights", "=", "np", ".", "ones", "(", "len", "(", "self", ".", "vocab", ")", ")", "\n", "", "weights", "[", ":", "self", ".", "vocab", ".", "nspecial", "]", "=", "0", "\n", "self", ".", "weights", "=", "weights", "/", "weights", ".", "sum", "(", ")", "\n", "\n", "", "self", ".", "epoch", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.mask_tokens_dataset.MaskTokensDataset.can_reuse_epoch_itr_across_epochs": [[93, 96], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "can_reuse_epoch_itr_across_epochs", "(", "self", ")", ":", "\n", "        ", "return", "True", "# only the noise changes, not item sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.mask_tokens_dataset.MaskTokensDataset.set_epoch": [[97, 100], ["super().set_epoch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ",", "**", "unused", ")", ":", "\n", "        ", "super", "(", ")", ".", "set_epoch", "(", "epoch", ")", "\n", "self", ".", "epoch", "=", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.mask_tokens_dataset.MaskTokensDataset.__getitem__": [[101, 179], ["functools.lru_cache", "fairseq.data.data_utils.numpy_seed", "len", "numpy.full", "int", "numpy.copy", "torch.from_numpy", "mask_tokens_dataset.MaskTokensDataset.mask_whole_words.gather", "mask_tokens_dataset.MaskTokensDataset.nonzero().view", "len", "list", "numpy.full", "torch.from_numpy", "numpy.repeat", "numpy.repeat.sum", "numpy.split", "len", "map", "numpy.random.rand", "numpy.random.choice", "numpy.repeat", "len", "numpy.random.choice", "mask_tokens_dataset.MaskTokensDataset.nonzero", "numpy.random.rand", "numpy.repeat", "numpy.repeat.sum", "len", "torch.from_numpy", "numpy.random.rand", "numpy.repeat.astype"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils.numpy_seed", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.copy"], ["", "@", "lru_cache", "(", "maxsize", "=", "8", ")", "\n", "def", "__getitem__", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "with", "data_utils", ".", "numpy_seed", "(", "self", ".", "seed", ",", "self", ".", "epoch", ",", "index", ")", ":", "\n", "            ", "item", "=", "self", ".", "dataset", "[", "index", "]", "\n", "sz", "=", "len", "(", "item", ")", "\n", "\n", "assert", "(", "\n", "self", ".", "mask_idx", "not", "in", "item", "\n", ")", ",", "\"Dataset contains mask_idx (={}), this is not expected!\"", ".", "format", "(", "\n", "self", ".", "mask_idx", ",", "\n", ")", "\n", "\n", "if", "self", ".", "mask_whole_words", "is", "not", "None", ":", "\n", "                ", "word_begins_mask", "=", "self", ".", "mask_whole_words", ".", "gather", "(", "0", ",", "item", ")", "\n", "word_begins_idx", "=", "word_begins_mask", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "sz", "=", "len", "(", "word_begins_idx", ")", "\n", "words", "=", "np", ".", "split", "(", "word_begins_mask", ",", "word_begins_idx", ")", "[", "1", ":", "]", "\n", "assert", "len", "(", "words", ")", "==", "sz", "\n", "word_lens", "=", "list", "(", "map", "(", "len", ",", "words", ")", ")", "\n", "\n", "# decide elements to mask", "\n", "", "mask", "=", "np", ".", "full", "(", "sz", ",", "False", ")", "\n", "num_mask", "=", "int", "(", "\n", "# add a random number for probabilistic rounding", "\n", "self", ".", "mask_prob", "*", "sz", "\n", "+", "np", ".", "random", ".", "rand", "(", ")", "\n", ")", "\n", "mask", "[", "np", ".", "random", ".", "choice", "(", "sz", ",", "num_mask", ",", "replace", "=", "False", ")", "]", "=", "True", "\n", "\n", "if", "self", ".", "return_masked_tokens", ":", "\n", "# exit early if we're just returning the masked tokens", "\n", "# (i.e., the targets for masked LM training)", "\n", "                ", "if", "self", ".", "mask_whole_words", "is", "not", "None", ":", "\n", "                    ", "mask", "=", "np", ".", "repeat", "(", "mask", ",", "word_lens", ")", "\n", "", "new_item", "=", "np", ".", "full", "(", "len", "(", "mask", ")", ",", "self", ".", "pad_idx", ")", "\n", "new_item", "[", "mask", "]", "=", "item", "[", "torch", ".", "from_numpy", "(", "mask", ".", "astype", "(", "np", ".", "uint8", ")", ")", "==", "1", "]", "\n", "return", "torch", ".", "from_numpy", "(", "new_item", ")", "\n", "\n", "# decide unmasking and random replacement", "\n", "", "rand_or_unmask_prob", "=", "self", ".", "random_token_prob", "+", "self", ".", "leave_unmasked_prob", "\n", "if", "rand_or_unmask_prob", ">", "0.0", ":", "\n", "                ", "rand_or_unmask", "=", "mask", "&", "(", "np", ".", "random", ".", "rand", "(", "sz", ")", "<", "rand_or_unmask_prob", ")", "\n", "if", "self", ".", "random_token_prob", "==", "0.0", ":", "\n", "                    ", "unmask", "=", "rand_or_unmask", "\n", "rand_mask", "=", "None", "\n", "", "elif", "self", ".", "leave_unmasked_prob", "==", "0.0", ":", "\n", "                    ", "unmask", "=", "None", "\n", "rand_mask", "=", "rand_or_unmask", "\n", "", "else", ":", "\n", "                    ", "unmask_prob", "=", "self", ".", "leave_unmasked_prob", "/", "rand_or_unmask_prob", "\n", "decision", "=", "np", ".", "random", ".", "rand", "(", "sz", ")", "<", "unmask_prob", "\n", "unmask", "=", "rand_or_unmask", "&", "decision", "\n", "rand_mask", "=", "rand_or_unmask", "&", "(", "~", "decision", ")", "\n", "", "", "else", ":", "\n", "                ", "unmask", "=", "rand_mask", "=", "None", "\n", "\n", "", "if", "unmask", "is", "not", "None", ":", "\n", "                ", "mask", "=", "mask", "^", "unmask", "\n", "\n", "", "if", "self", ".", "mask_whole_words", "is", "not", "None", ":", "\n", "                ", "mask", "=", "np", ".", "repeat", "(", "mask", ",", "word_lens", ")", "\n", "\n", "", "new_item", "=", "np", ".", "copy", "(", "item", ")", "\n", "new_item", "[", "mask", "]", "=", "self", ".", "mask_idx", "\n", "if", "rand_mask", "is", "not", "None", ":", "\n", "                ", "num_rand", "=", "rand_mask", ".", "sum", "(", ")", "\n", "if", "num_rand", ">", "0", ":", "\n", "                    ", "if", "self", ".", "mask_whole_words", "is", "not", "None", ":", "\n", "                        ", "rand_mask", "=", "np", ".", "repeat", "(", "rand_mask", ",", "word_lens", ")", "\n", "num_rand", "=", "rand_mask", ".", "sum", "(", ")", "\n", "\n", "", "new_item", "[", "rand_mask", "]", "=", "np", ".", "random", ".", "choice", "(", "\n", "len", "(", "self", ".", "vocab", ")", ",", "\n", "num_rand", ",", "\n", "p", "=", "self", ".", "weights", ",", "\n", ")", "\n", "\n", "", "", "return", "torch", ".", "from_numpy", "(", "new_item", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.raw_label_dataset.RawLabelDataset.__init__": [[12, 15], ["FairseqDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "labels", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.raw_label_dataset.RawLabelDataset.__getitem__": [[16, 18], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "labels", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.raw_label_dataset.RawLabelDataset.__len__": [[19, 21], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.raw_label_dataset.RawLabelDataset.collater": [[22, 24], ["torch.tensor"], "methods", ["None"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "samples", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.monolingual_dataset.MonolingualDataset.__init__": [[68, 93], ["numpy.array", "all", "len"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "sizes", ",", "\n", "src_vocab", ",", "\n", "tgt_vocab", ",", "\n", "add_eos_for_other_targets", ",", "\n", "shuffle", ",", "\n", "targets", "=", "None", ",", "\n", "add_bos_token", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "sizes", "=", "np", ".", "array", "(", "sizes", ")", "\n", "self", ".", "vocab", "=", "src_vocab", "\n", "self", ".", "tgt_vocab", "=", "tgt_vocab", "\n", "self", ".", "add_eos_for_other_targets", "=", "add_eos_for_other_targets", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "add_bos_token", "=", "add_bos_token", "\n", "\n", "assert", "targets", "is", "None", "or", "all", "(", "\n", "t", "in", "{", "\"self\"", ",", "\"future\"", ",", "\"past\"", "}", "for", "t", "in", "targets", "\n", ")", ",", "\"targets must be none or one of 'self', 'future', 'past'\"", "\n", "if", "targets", "is", "not", "None", "and", "len", "(", "targets", ")", "==", "0", ":", "\n", "            ", "targets", "=", "None", "\n", "", "self", ".", "targets", "=", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.monolingual_dataset.MonolingualDataset.__getitem__": [[94, 113], ["monolingual_dataset.MonolingualDataset._maybe_add_bos", "monolingual_dataset.MonolingualDataset._make_source_target"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.monolingual_dataset.MonolingualDataset._maybe_add_bos", "home.repos.pwc.inspect_result.reneeye_const.data.monolingual_dataset.MonolingualDataset._make_source_target"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "self", ".", "targets", "is", "not", "None", ":", "\n", "# *future_target* is the original sentence", "\n", "# *source* is shifted right by 1 (maybe left-padded with eos)", "\n", "# *past_target* is shifted right by 2 (left-padded as needed)", "\n", "#", "\n", "# Left-to-right language models should condition on *source* and", "\n", "# predict *future_target*.", "\n", "# Right-to-left language models should condition on *source* and", "\n", "# predict *past_target*.", "\n", "            ", "source", ",", "future_target", ",", "past_target", "=", "self", ".", "dataset", "[", "index", "]", "\n", "source", ",", "target", "=", "self", ".", "_make_source_target", "(", "\n", "source", ",", "future_target", ",", "past_target", "\n", ")", "\n", "", "else", ":", "\n", "            ", "source", "=", "self", ".", "dataset", "[", "index", "]", "\n", "target", "=", "None", "\n", "", "source", ",", "target", "=", "self", ".", "_maybe_add_bos", "(", "source", ",", "target", ")", "\n", "return", "{", "\"id\"", ":", "index", ",", "\"source\"", ":", "source", ",", "\"target\"", ":", "target", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.monolingual_dataset.MonolingualDataset.__len__": [[114, 116], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.monolingual_dataset.MonolingualDataset._make_source_target": [[117, 160], ["monolingual_dataset.MonolingualDataset._filter_vocab", "torch.cat", "len", "monolingual_dataset.MonolingualDataset.vocab.eos", "torch.cat", "torch.cat", "target.append", "torch.cat.new", "target.append", "torch.cat.new", "torch.cat.new", "target.append", "Exception", "monolingual_dataset.MonolingualDataset.vocab.eos", "monolingual_dataset.MonolingualDataset.vocab.pad", "monolingual_dataset.MonolingualDataset.vocab.pad"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.monolingual_dataset.MonolingualDataset._filter_vocab", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["", "def", "_make_source_target", "(", "self", ",", "source", ",", "future_target", ",", "past_target", ")", ":", "\n", "        ", "if", "self", ".", "targets", "is", "not", "None", ":", "\n", "            ", "target", "=", "[", "]", "\n", "\n", "if", "(", "\n", "self", ".", "add_eos_for_other_targets", "\n", "and", "(", "(", "\"self\"", "in", "self", ".", "targets", ")", "or", "(", "\"past\"", "in", "self", ".", "targets", ")", ")", "\n", "and", "source", "[", "-", "1", "]", "!=", "self", ".", "vocab", ".", "eos", "(", ")", "\n", ")", ":", "\n", "# append eos at the end of source", "\n", "                ", "source", "=", "torch", ".", "cat", "(", "[", "source", ",", "source", ".", "new", "(", "[", "self", ".", "vocab", ".", "eos", "(", ")", "]", ")", "]", ")", "\n", "\n", "if", "\"future\"", "in", "self", ".", "targets", ":", "\n", "                    ", "future_target", "=", "torch", ".", "cat", "(", "\n", "[", "future_target", ",", "future_target", ".", "new", "(", "[", "self", ".", "vocab", ".", "pad", "(", ")", "]", ")", "]", "\n", ")", "\n", "", "if", "\"past\"", "in", "self", ".", "targets", ":", "\n", "# first token is before the start of sentence which is only used in \"none\" break mode when", "\n", "# add_eos_for_other_targets is False", "\n", "                    ", "past_target", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "past_target", ".", "new", "(", "[", "self", ".", "vocab", ".", "pad", "(", ")", "]", ")", ",", "\n", "past_target", "[", "1", ":", "]", ",", "\n", "source", "[", "-", "2", ",", "None", "]", ",", "\n", "]", "\n", ")", "\n", "\n", "", "", "for", "t", "in", "self", ".", "targets", ":", "\n", "                ", "if", "t", "==", "\"self\"", ":", "\n", "                    ", "target", ".", "append", "(", "source", ")", "\n", "", "elif", "t", "==", "\"future\"", ":", "\n", "                    ", "target", ".", "append", "(", "future_target", ")", "\n", "", "elif", "t", "==", "\"past\"", ":", "\n", "                    ", "target", ".", "append", "(", "past_target", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "Exception", "(", "\"invalid target \"", "+", "t", ")", "\n", "\n", "", "", "if", "len", "(", "target", ")", "==", "1", ":", "\n", "                ", "target", "=", "target", "[", "0", "]", "\n", "", "", "else", ":", "\n", "            ", "target", "=", "future_target", "\n", "\n", "", "return", "source", ",", "self", ".", "_filter_vocab", "(", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.monolingual_dataset.MonolingualDataset._maybe_add_bos": [[161, 167], ["torch.cat", "torch.cat", "torch.cat.new", "torch.cat.new", "monolingual_dataset.MonolingualDataset.vocab.bos", "monolingual_dataset.MonolingualDataset.tgt_vocab.bos"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos"], ["", "def", "_maybe_add_bos", "(", "self", ",", "source", ",", "target", ")", ":", "\n", "        ", "if", "self", ".", "add_bos_token", ":", "\n", "            ", "source", "=", "torch", ".", "cat", "(", "[", "source", ".", "new", "(", "[", "self", ".", "vocab", ".", "bos", "(", ")", "]", ")", ",", "source", "]", ")", "\n", "if", "target", "is", "not", "None", ":", "\n", "                ", "target", "=", "torch", ".", "cat", "(", "[", "target", ".", "new", "(", "[", "self", ".", "tgt_vocab", ".", "bos", "(", ")", "]", ")", ",", "target", "]", ")", "\n", "", "", "return", "source", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.monolingual_dataset.MonolingualDataset._filter_vocab": [[168, 181], ["len", "len", "isinstance", "monolingual_dataset.MonolingualDataset._filter_vocab._filter"], "methods", ["None"], ["", "def", "_filter_vocab", "(", "self", ",", "target", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "tgt_vocab", ")", "!=", "len", "(", "self", ".", "vocab", ")", ":", "\n", "\n", "            ", "def", "_filter", "(", "target", ")", ":", "\n", "                ", "mask", "=", "target", ".", "ge", "(", "len", "(", "self", ".", "tgt_vocab", ")", ")", "\n", "if", "mask", ".", "any", "(", ")", ":", "\n", "                    ", "target", "[", "mask", "]", "=", "self", ".", "tgt_vocab", ".", "unk", "(", ")", "\n", "", "return", "target", "\n", "\n", "", "if", "isinstance", "(", "target", ",", "list", ")", ":", "\n", "                ", "return", "[", "_filter", "(", "t", ")", "for", "t", "in", "target", "]", "\n", "", "return", "_filter", "(", "target", ")", "\n", "", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.monolingual_dataset.MonolingualDataset.collater": [[182, 204], ["monolingual_dataset.collate", "monolingual_dataset.MonolingualDataset.vocab.pad", "monolingual_dataset.MonolingualDataset.vocab.eos"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.collate", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Merge a list of samples to form a mini-batch.\n\n        Args:\n            samples (List[dict]): samples to collate\n\n        Returns:\n            dict: a mini-batch with the following keys:\n\n                - `id` (LongTensor): example IDs in the original input order\n                - `ntokens` (int): total number of tokens in the batch\n                - `net_input` (dict): the input to the Model, containing keys:\n\n                  - `src_tokens` (LongTensor): a padded 2D Tensor of tokens in\n                    the source sentence of shape `(bsz, src_len)`. Padding will\n                    appear on the right.\n\n                - `target` (LongTensor): a padded 2D Tensor of tokens in the\n                  target sentence of shape `(bsz, tgt_len)`. Padding will appear\n                  on the right.\n        \"\"\"", "\n", "return", "collate", "(", "samples", ",", "self", ".", "vocab", ".", "pad", "(", ")", ",", "self", ".", "vocab", ".", "eos", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.monolingual_dataset.MonolingualDataset.num_tokens": [[205, 209], ["None"], "methods", ["None"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return the number of tokens in a sample. This value is used to\n        enforce ``--max-tokens`` during batching.\"\"\"", "\n", "return", "self", ".", "sizes", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.monolingual_dataset.MonolingualDataset.size": [[210, 214], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return an example's size as a float or tuple. This value is used when\n        filtering a dataset with ``--max-positions``.\"\"\"", "\n", "return", "self", ".", "sizes", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.monolingual_dataset.MonolingualDataset.ordered_indices": [[215, 224], ["order.append", "numpy.lexsort", "numpy.random.permutation", "numpy.arange", "len", "len"], "methods", ["None"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return an ordered list of indices. Batches will be constructed based\n        on this order.\"\"\"", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "order", "=", "[", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ")", ")", "]", "\n", "", "else", ":", "\n", "            ", "order", "=", "[", "np", ".", "arange", "(", "len", "(", "self", ")", ")", "]", "\n", "", "order", ".", "append", "(", "self", ".", "sizes", ")", "\n", "return", "np", ".", "lexsort", "(", "order", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.monolingual_dataset.MonolingualDataset.supports_prefetch": [[225, 228], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ".", "dataset", ",", "\"supports_prefetch\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.monolingual_dataset.MonolingualDataset.prefetch": [[229, 231], ["monolingual_dataset.MonolingualDataset.dataset.prefetch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "self", ".", "dataset", ".", "prefetch", "(", "indices", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.monolingual_dataset.collate": [[12, 53], ["monolingual_dataset.collate.merge"], "function", ["None"], ["def", "collate", "(", "samples", ",", "pad_idx", ",", "eos_idx", ")", ":", "\n", "    ", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "        ", "return", "{", "}", "\n", "\n", "", "def", "merge", "(", "key", ",", "is_list", "=", "False", ")", ":", "\n", "        ", "if", "is_list", ":", "\n", "            ", "res", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "samples", "[", "0", "]", "[", "key", "]", ")", ")", ":", "\n", "                ", "res", ".", "append", "(", "\n", "data_utils", ".", "collate_tokens", "(", "\n", "[", "s", "[", "key", "]", "[", "i", "]", "for", "s", "in", "samples", "]", ",", "\n", "pad_idx", ",", "\n", "eos_idx", ",", "\n", "left_pad", "=", "False", ",", "\n", ")", "\n", ")", "\n", "", "return", "res", "\n", "", "else", ":", "\n", "            ", "return", "data_utils", ".", "collate_tokens", "(", "\n", "[", "s", "[", "key", "]", "for", "s", "in", "samples", "]", ",", "\n", "pad_idx", ",", "\n", "eos_idx", ",", "\n", "left_pad", "=", "False", ",", "\n", ")", "\n", "\n", "", "", "src_tokens", "=", "merge", "(", "\"source\"", ")", "\n", "if", "samples", "[", "0", "]", "[", "\"target\"", "]", "is", "not", "None", ":", "\n", "        ", "is_target_list", "=", "isinstance", "(", "samples", "[", "0", "]", "[", "\"target\"", "]", ",", "list", ")", "\n", "target", "=", "merge", "(", "\"target\"", ",", "is_target_list", ")", "\n", "", "else", ":", "\n", "        ", "target", "=", "src_tokens", "\n", "\n", "", "return", "{", "\n", "\"id\"", ":", "torch", ".", "LongTensor", "(", "[", "s", "[", "\"id\"", "]", "for", "s", "in", "samples", "]", ")", ",", "\n", "\"nsentences\"", ":", "len", "(", "samples", ")", ",", "\n", "\"ntokens\"", ":", "sum", "(", "len", "(", "s", "[", "\"source\"", "]", ")", "for", "s", "in", "samples", ")", ",", "\n", "\"net_input\"", ":", "{", "\n", "\"src_tokens\"", ":", "src_tokens", ",", "\n", "\"src_lengths\"", ":", "torch", ".", "LongTensor", "(", "[", "s", "[", "\"source\"", "]", ".", "numel", "(", ")", "for", "s", "in", "samples", "]", ")", ",", "\n", "}", ",", "\n", "\"target\"", ":", "target", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.roll_dataset.RollDataset.__init__": [[12, 15], ["BaseWrapperDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "shifts", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ")", "\n", "self", ".", "shifts", "=", "shifts", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.roll_dataset.RollDataset.__getitem__": [[16, 19], ["torch.roll"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "item", "=", "self", ".", "dataset", "[", "index", "]", "\n", "return", "torch", ".", "roll", "(", "item", ",", "self", ".", "shifts", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_modality_dataset.MultiModalityDataset.__init__": [[35, 55], ["fairseq.data.ConcatDataset.__init__", "id_to_mode.append", "dsets.append", "max_tokens.append", "max_positions.append", "max_sentences.append"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "datasets", ":", "List", "[", "ModalityDatasetItem", "]", ")", ":", "\n", "        ", "id_to_mode", "=", "[", "]", "\n", "dsets", "=", "[", "]", "\n", "max_tokens", "=", "[", "]", "\n", "max_sentences", "=", "[", "]", "\n", "max_positions", "=", "[", "]", "\n", "for", "dset", "in", "datasets", ":", "\n", "            ", "id_to_mode", ".", "append", "(", "dset", ".", "datasetname", ")", "\n", "dsets", ".", "append", "(", "dset", ".", "dataset", ")", "\n", "max_tokens", ".", "append", "(", "dset", ".", "max_tokens", ")", "\n", "max_positions", ".", "append", "(", "dset", ".", "max_positions", ")", "\n", "max_sentences", ".", "append", "(", "dset", ".", "max_sentences", ")", "\n", "", "weights", "=", "[", "1.0", "for", "s", "in", "dsets", "]", "\n", "super", "(", ")", ".", "__init__", "(", "dsets", ",", "weights", ")", "\n", "self", ".", "max_tokens", "=", "max_tokens", "\n", "self", ".", "max_positions", "=", "max_positions", "\n", "self", ".", "max_sentences", "=", "max_sentences", "\n", "self", ".", "id_to_mode", "=", "id_to_mode", "\n", "self", ".", "raw_sub_batch_samplers", "=", "[", "]", "\n", "self", ".", "_cur_epoch", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_modality_dataset.MultiModalityDataset.set_epoch": [[56, 59], ["super().set_epoch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "super", "(", ")", ".", "set_epoch", "(", "epoch", ")", "\n", "self", ".", "_cur_epoch", "=", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_modality_dataset.MultiModalityDataset.__getitem__": [[60, 64], ["multi_modality_dataset.MultiModalityDataset._get_dataset_and_sample_index"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset._get_dataset_and_sample_index"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "dataset_idx", ",", "sample_idx", "=", "self", ".", "_get_dataset_and_sample_index", "(", "idx", ")", "\n", "sample", "=", "self", ".", "datasets", "[", "dataset_idx", "]", "[", "sample_idx", "]", "\n", "return", "(", "dataset_idx", ",", "sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_modality_dataset.MultiModalityDataset.collater": [[65, 76], ["multi_modality_dataset.MultiModalityDataset.datasets[].collater", "len", "sum"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.collater"], ["", "def", "collater", "(", "self", ",", "samples", ",", "**", "extra_args", ")", ":", "\n", "        ", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "            ", "return", "{", "}", "\n", "", "dataset_idx", "=", "samples", "[", "0", "]", "[", "0", "]", "\n", "# make sure all samples in samples are from same dataset", "\n", "assert", "sum", "(", "[", "0", "if", "dataset_idx", "==", "s", "[", "0", "]", "else", "1", "for", "s", "in", "samples", "]", ")", "==", "0", "\n", "samples", "=", "self", ".", "datasets", "[", "dataset_idx", "]", ".", "collater", "(", "[", "x", "[", "1", "]", "for", "x", "in", "samples", "]", ")", "\n", "# add mode", "\n", "samples", "[", "\"net_input\"", "]", "[", "\"mode\"", "]", "=", "self", ".", "id_to_mode", "[", "dataset_idx", "]", "\n", "\n", "return", "samples", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_modality_dataset.MultiModalityDataset.size": [[77, 81], ["super().size", "len", "multi_modality_dataset.MultiModalityDataset.datasets[].size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "size", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "datasets", ")", "==", "1", ":", "\n", "            ", "return", "self", ".", "datasets", "[", "0", "]", ".", "size", "(", "index", ")", "\n", "", "return", "super", "(", ")", ".", "size", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_modality_dataset.MultiModalityDataset.sizes": [[82, 87], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "datasets", ")", "==", "1", ":", "\n", "            ", "return", "self", ".", "datasets", "[", "0", "]", ".", "sizes", "\n", "", "super", "(", ")", ".", "sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_modality_dataset.MultiModalityDataset.ordered_indices": [[88, 102], ["enumerate", "len", "multi_modality_dataset.MultiModalityDataset.datasets[].ordered_indices", "indices_group.append", "len", "ds.ordered_indices"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.ordered_indices", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.ordered_indices"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns indices sorted by length. So less padding is needed.\n        \"\"\"", "\n", "if", "len", "(", "self", ".", "datasets", ")", "==", "1", ":", "\n", "            ", "return", "self", ".", "datasets", "[", "0", "]", ".", "ordered_indices", "(", ")", "\n", "", "indices_group", "=", "[", "]", "\n", "for", "d_idx", ",", "ds", "in", "enumerate", "(", "self", ".", "datasets", ")", ":", "\n", "            ", "sample_num", "=", "self", ".", "cumulative_sizes", "[", "d_idx", "]", "\n", "if", "d_idx", ">", "0", ":", "\n", "                ", "sample_num", "=", "sample_num", "-", "self", ".", "cumulative_sizes", "[", "d_idx", "-", "1", "]", "\n", "", "assert", "sample_num", "==", "len", "(", "ds", ")", "\n", "indices_group", ".", "append", "(", "ds", ".", "ordered_indices", "(", ")", ")", "\n", "", "return", "indices_group", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_modality_dataset.MultiModalityDataset.get_raw_batch_samplers": [[103, 121], ["enumerate", "len", "logger.info", "fairseq.data.data_utils.numpy_seed", "multi_modality_dataset.MultiModalityDataset.ordered_indices", "ds.batch_by_size", "multi_modality_dataset.MultiModalityDataset.raw_sub_batch_samplers.append", "ds.filter_indices_by_size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils.numpy_seed", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.ordered_indices", "home.repos.pwc.inspect_result.reneeye_const.data.base_wrapper_dataset.BaseWrapperDataset.batch_by_size", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.filter_indices_by_size"], ["", "def", "get_raw_batch_samplers", "(", "self", ",", "required_batch_size_multiple", ",", "seed", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "raw_sub_batch_samplers", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\" raw_sub_batch_samplers exists. No action is taken\"", ")", "\n", "return", "\n", "", "with", "data_utils", ".", "numpy_seed", "(", "seed", ")", ":", "\n", "            ", "indices", "=", "self", ".", "ordered_indices", "(", ")", "\n", "", "for", "i", ",", "ds", "in", "enumerate", "(", "self", ".", "datasets", ")", ":", "\n", "            ", "indices", "[", "i", "]", "=", "ds", ".", "filter_indices_by_size", "(", "\n", "indices", "[", "i", "]", ",", "\n", "self", ".", "max_positions", "[", "i", "]", ",", "\n", ")", "[", "0", "]", "\n", "sub_batch_sampler", "=", "ds", ".", "batch_by_size", "(", "\n", "indices", "[", "i", "]", ",", "\n", "max_tokens", "=", "self", ".", "max_tokens", "[", "i", "]", ",", "\n", "max_sentences", "=", "self", ".", "max_sentences", "[", "i", "]", ",", "\n", "required_batch_size_multiple", "=", "required_batch_size_multiple", ",", "\n", ")", "\n", "self", ".", "raw_sub_batch_samplers", ".", "append", "(", "sub_batch_sampler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_modality_dataset.MultiModalityDataset.get_batch_samplers": [[122, 164], ["multi_modality_dataset.MultiModalityDataset.get_raw_batch_samplers", "enumerate", "batch_samplers.append", "list", "logger.info", "range", "logger.info", "math.floor", "math.floor", "len", "int", "fairseq.data.data_utils.numpy_seed", "numpy.random.shuffle", "int", "len", "len", "len", "math.floor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.multi_modality_dataset.MultiModalityDataset.get_raw_batch_samplers", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.numpy_seed", "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.S2TDataConfig.shuffle"], ["", "", "def", "get_batch_samplers", "(", "self", ",", "mult_ratios", ",", "required_batch_size_multiple", ",", "seed", ")", ":", "\n", "        ", "self", ".", "get_raw_batch_samplers", "(", "required_batch_size_multiple", ",", "seed", ")", "\n", "batch_samplers", "=", "[", "]", "\n", "for", "i", ",", "_", "in", "enumerate", "(", "self", ".", "datasets", ")", ":", "\n", "            ", "if", "i", ">", "0", ":", "\n", "                ", "sub_batch_sampler", "=", "[", "\n", "[", "y", "+", "self", ".", "cumulative_sizes", "[", "i", "-", "1", "]", "for", "y", "in", "x", "]", "\n", "for", "x", "in", "self", ".", "raw_sub_batch_samplers", "[", "i", "]", "\n", "]", "\n", "", "else", ":", "\n", "                ", "sub_batch_sampler", "=", "list", "(", "self", ".", "raw_sub_batch_samplers", "[", "i", "]", ")", "\n", "", "smp_r", "=", "mult_ratios", "[", "i", "]", "\n", "if", "smp_r", "!=", "1", ":", "\n", "                ", "is_increase", "=", "\"increased\"", "if", "smp_r", ">", "1", "else", "\"decreased\"", "\n", "logger", ".", "info", "(", "\n", "\"number of batch for the dataset {} is {} from {} to {}\"", ".", "format", "(", "\n", "self", ".", "id_to_mode", "[", "i", "]", ",", "\n", "is_increase", ",", "\n", "len", "(", "sub_batch_sampler", ")", ",", "\n", "int", "(", "len", "(", "sub_batch_sampler", ")", "*", "smp_r", ")", ",", "\n", ")", "\n", ")", "\n", "mul_samplers", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "math", ".", "floor", "(", "smp_r", ")", ")", ":", "\n", "                    ", "mul_samplers", "=", "mul_samplers", "+", "sub_batch_sampler", "\n", "", "if", "math", ".", "floor", "(", "smp_r", ")", "!=", "smp_r", ":", "\n", "                    ", "with", "data_utils", ".", "numpy_seed", "(", "seed", "+", "self", ".", "_cur_epoch", ")", ":", "\n", "                        ", "np", ".", "random", ".", "shuffle", "(", "sub_batch_sampler", ")", "\n", "smp_num", "=", "int", "(", "\n", "(", "smp_r", "-", "math", ".", "floor", "(", "smp_r", ")", ")", "*", "len", "(", "sub_batch_sampler", ")", "\n", ")", "\n", "", "mul_samplers", "=", "mul_samplers", "+", "sub_batch_sampler", "[", ":", "smp_num", "]", "\n", "", "sub_batch_sampler", "=", "mul_samplers", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"dataset {} batch number is {} \"", ".", "format", "(", "\n", "self", ".", "id_to_mode", "[", "i", "]", ",", "len", "(", "sub_batch_sampler", ")", "\n", ")", "\n", ")", "\n", "", "batch_samplers", ".", "append", "(", "sub_batch_sampler", ")", "\n", "\n", "", "return", "batch_samplers", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.list_dataset.ListDataset.__init__": [[10, 13], ["BaseWrapperDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "sizes", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ")", "\n", "self", ".", "_sizes", "=", "sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.list_dataset.ListDataset.__iter__": [[14, 17], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "x", "in", "self", ".", "dataset", ":", "\n", "            ", "yield", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.list_dataset.ListDataset.collater": [[18, 20], ["None"], "methods", ["None"], ["", "", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "return", "samples", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.list_dataset.ListDataset.sizes": [[21, 24], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.list_dataset.ListDataset.num_tokens": [[25, 27], ["None"], "methods", ["None"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "sizes", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.list_dataset.ListDataset.size": [[28, 30], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "sizes", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.list_dataset.ListDataset.set_epoch": [[31, 33], ["None"], "methods", ["None"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.nested_dictionary_dataset.NestedDictionaryDataset.__init__": [[48, 68], ["FairseqDataset.__init__", "nested_dictionary_dataset._flatten", "nested_dictionary_dataset.NestedDictionaryDataset.defn.values", "len", "isinstance", "isinstance", "ValueError", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.nested_dictionary_dataset._flatten"], ["    ", "def", "__init__", "(", "self", ",", "defn", ",", "sizes", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "defn", "=", "_flatten", "(", "defn", ")", "\n", "self", ".", "sizes", "=", "[", "sizes", "]", "if", "not", "isinstance", "(", "sizes", ",", "(", "list", ",", "tuple", ")", ")", "else", "sizes", "\n", "\n", "first", "=", "None", "\n", "for", "v", "in", "self", ".", "defn", ".", "values", "(", ")", ":", "\n", "            ", "if", "not", "isinstance", "(", "\n", "v", ",", "\n", "(", "\n", "FairseqDataset", ",", "\n", "torch", ".", "utils", ".", "data", ".", "Dataset", ",", "\n", ")", ",", "\n", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"Expected Dataset but found: {}\"", ".", "format", "(", "v", ".", "__class__", ")", ")", "\n", "", "first", "=", "first", "or", "v", "\n", "if", "len", "(", "v", ")", ">", "0", ":", "\n", "                ", "assert", "len", "(", "v", ")", "==", "len", "(", "first", ")", ",", "\"dataset lengths must match\"", "\n", "\n", "", "", "self", ".", "_len", "=", "len", "(", "first", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.nested_dictionary_dataset.NestedDictionaryDataset.__getitem__": [[69, 71], ["collections.OrderedDict", "nested_dictionary_dataset.NestedDictionaryDataset.defn.items"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "OrderedDict", "(", "(", "k", ",", "ds", "[", "index", "]", ")", "for", "k", ",", "ds", "in", "self", ".", "defn", ".", "items", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.nested_dictionary_dataset.NestedDictionaryDataset.__len__": [[72, 74], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_len", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.nested_dictionary_dataset.NestedDictionaryDataset.collater": [[75, 93], ["collections.OrderedDict", "nested_dictionary_dataset.NestedDictionaryDataset.defn.items", "nested_dictionary_dataset._unflatten", "len", "ds.collater", "torch.utils.data.dataloader.default_collate"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.nested_dictionary_dataset._unflatten", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.collater"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Merge a list of samples to form a mini-batch.\n\n        Args:\n            samples (List[dict]): samples to collate\n\n        Returns:\n            dict: a mini-batch suitable for forwarding with a Model\n        \"\"\"", "\n", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "            ", "return", "{", "}", "\n", "", "sample", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "ds", "in", "self", ".", "defn", ".", "items", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "sample", "[", "k", "]", "=", "ds", ".", "collater", "(", "[", "s", "[", "k", "]", "for", "s", "in", "samples", "]", ")", "\n", "", "except", "NotImplementedError", ":", "\n", "                ", "sample", "[", "k", "]", "=", "default_collate", "(", "[", "s", "[", "k", "]", "for", "s", "in", "samples", "]", ")", "\n", "", "", "return", "_unflatten", "(", "sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.nested_dictionary_dataset.NestedDictionaryDataset.num_tokens": [[94, 98], ["max"], "methods", ["None"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return the number of tokens in a sample. This value is used to\n        enforce ``--max-tokens`` during batching.\"\"\"", "\n", "return", "max", "(", "s", "[", "index", "]", "for", "s", "in", "self", ".", "sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.nested_dictionary_dataset.NestedDictionaryDataset.size": [[99, 106], ["len"], "methods", ["None"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return an example's size as a float or tuple. This value is used when\n        filtering a dataset with ``--max-positions``.\"\"\"", "\n", "if", "len", "(", "self", ".", "sizes", ")", "==", "1", ":", "\n", "            ", "return", "self", ".", "sizes", "[", "0", "]", "[", "index", "]", "\n", "", "else", ":", "\n", "            ", "return", "(", "s", "[", "index", "]", "for", "s", "in", "self", ".", "sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.nested_dictionary_dataset.NestedDictionaryDataset.supports_prefetch": [[107, 111], ["any", "nested_dictionary_dataset.NestedDictionaryDataset.defn.values"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "\"\"\"Whether this dataset supports prefetching.\"\"\"", "\n", "return", "any", "(", "ds", ".", "supports_prefetch", "for", "ds", "in", "self", ".", "defn", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.nested_dictionary_dataset.NestedDictionaryDataset.prefetch": [[112, 117], ["nested_dictionary_dataset.NestedDictionaryDataset.defn.values", "getattr", "ds.prefetch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "\"\"\"Prefetch the data required for this epoch.\"\"\"", "\n", "for", "ds", "in", "self", ".", "defn", ".", "values", "(", ")", ":", "\n", "            ", "if", "getattr", "(", "ds", ",", "\"supports_prefetch\"", ",", "False", ")", ":", "\n", "                ", "ds", ".", "prefetch", "(", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.nested_dictionary_dataset.NestedDictionaryDataset.can_reuse_epoch_itr_across_epochs": [[118, 121], ["all", "nested_dictionary_dataset.NestedDictionaryDataset.defn.values"], "methods", ["None"], ["", "", "", "@", "property", "\n", "def", "can_reuse_epoch_itr_across_epochs", "(", "self", ")", ":", "\n", "        ", "return", "all", "(", "ds", ".", "can_reuse_epoch_itr_across_epochs", "for", "ds", "in", "self", ".", "defn", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.nested_dictionary_dataset.NestedDictionaryDataset.set_epoch": [[122, 126], ["super().set_epoch", "nested_dictionary_dataset.NestedDictionaryDataset.defn.values", "ds.set_epoch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "super", "(", ")", ".", "set_epoch", "(", "epoch", ")", "\n", "for", "ds", "in", "self", ".", "defn", ".", "values", "(", ")", ":", "\n", "            ", "ds", ".", "set_epoch", "(", "epoch", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.nested_dictionary_dataset._flatten": [[14, 29], ["collections.OrderedDict", "isinstance", "dico.items", "isinstance", "collections.OrderedDict.update", "enumerate", "collections.OrderedDict", "nested_dictionary_dataset._flatten", "collections.OrderedDict.update", "nested_dictionary_dataset._flatten", "str"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.reneeye_const.data.nested_dictionary_dataset._flatten", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.reneeye_const.data.nested_dictionary_dataset._flatten"], ["def", "_flatten", "(", "dico", ",", "prefix", "=", "None", ")", ":", "\n", "    ", "\"\"\"Flatten a nested dictionary.\"\"\"", "\n", "new_dico", "=", "OrderedDict", "(", ")", "\n", "if", "isinstance", "(", "dico", ",", "dict", ")", ":", "\n", "        ", "prefix", "=", "prefix", "+", "\".\"", "if", "prefix", "is", "not", "None", "else", "\"\"", "\n", "for", "k", ",", "v", "in", "dico", ".", "items", "(", ")", ":", "\n", "            ", "if", "v", "is", "None", ":", "\n", "                ", "continue", "\n", "", "new_dico", ".", "update", "(", "_flatten", "(", "v", ",", "prefix", "+", "k", ")", ")", "\n", "", "", "elif", "isinstance", "(", "dico", ",", "list", ")", ":", "\n", "        ", "for", "i", ",", "v", "in", "enumerate", "(", "dico", ")", ":", "\n", "            ", "new_dico", ".", "update", "(", "_flatten", "(", "v", ",", "prefix", "+", "\".[\"", "+", "str", "(", "i", ")", "+", "\"]\"", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "new_dico", "=", "OrderedDict", "(", "{", "prefix", ":", "dico", "}", ")", "\n", "", "return", "new_dico", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.nested_dictionary_dataset._unflatten": [[31, 45], ["collections.OrderedDict", "dico.items", "full_k.split.split", "int.startswith", "int.endswith", "int", "collections.OrderedDict"], "function", ["None"], ["", "def", "_unflatten", "(", "dico", ")", ":", "\n", "    ", "\"\"\"Unflatten a flattened dictionary into a nested dictionary.\"\"\"", "\n", "new_dico", "=", "OrderedDict", "(", ")", "\n", "for", "full_k", ",", "v", "in", "dico", ".", "items", "(", ")", ":", "\n", "        ", "full_k", "=", "full_k", ".", "split", "(", "\".\"", ")", "\n", "node", "=", "new_dico", "\n", "for", "k", "in", "full_k", "[", ":", "-", "1", "]", ":", "\n", "            ", "if", "k", ".", "startswith", "(", "\"[\"", ")", "and", "k", ".", "endswith", "(", "\"]\"", ")", ":", "\n", "                ", "k", "=", "int", "(", "k", "[", "1", ":", "-", "1", "]", ")", "\n", "", "if", "k", "not", "in", "node", ":", "\n", "                ", "node", "[", "k", "]", "=", "OrderedDict", "(", ")", "\n", "", "node", "=", "node", "[", "k", "]", "\n", "", "node", "[", "full_k", "[", "-", "1", "]", "]", "=", "v", "\n", "", "return", "new_dico", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.plasma_utils.PlasmaArray.__init__": [[18, 30], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "array", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "array", "=", "array", "\n", "self", ".", "disable", "=", "array", ".", "nbytes", "<", "134217728", "# disable for arrays <128MB", "\n", "self", ".", "object_id", "=", "None", "\n", "self", ".", "path", "=", "None", "\n", "\n", "# variables with underscores shouldn't be pickled", "\n", "self", ".", "_client", "=", "None", "\n", "self", ".", "_server", "=", "None", "\n", "self", ".", "_server_tmp", "=", "None", "\n", "self", ".", "_plasma", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.plasma_utils.PlasmaArray.plasma": [[31, 41], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "plasma", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_plasma", "is", "None", "and", "not", "self", ".", "disable", ":", "\n", "            ", "try", ":", "\n", "                ", "import", "pyarrow", ".", "plasma", "as", "plasma", "\n", "\n", "self", ".", "_plasma", "=", "plasma", "\n", "", "except", "ImportError", ":", "\n", "                ", "self", ".", "_plasma", "=", "None", "\n", "", "", "return", "self", ".", "_plasma", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.plasma_utils.PlasmaArray.start_server": [[42, 56], ["tempfile.NamedTemporaryFile", "subprocess.Popen", "str", "int"], "methods", ["None"], ["", "def", "start_server", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "plasma", "is", "None", "or", "self", ".", "_server", "is", "not", "None", ":", "\n", "            ", "return", "\n", "", "assert", "self", ".", "object_id", "is", "None", "\n", "assert", "self", ".", "path", "is", "None", "\n", "self", ".", "_server_tmp", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "self", ".", "path", "=", "self", ".", "_server_tmp", ".", "name", "\n", "self", ".", "_server", "=", "subprocess", ".", "Popen", "(", "\n", "[", "\n", "\"plasma_store\"", ",", "\n", "\"-m\"", ",", "\n", "str", "(", "int", "(", "1.05", "*", "self", ".", "array", ".", "nbytes", ")", ")", ",", "\n", "\"-s\"", ",", "\n", "self", ".", "path", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.plasma_utils.PlasmaArray.client": [[59, 65], ["plasma_utils.PlasmaArray.plasma.connect"], "methods", ["None"], ["", "@", "property", "\n", "def", "client", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_client", "is", "None", ":", "\n", "            ", "assert", "self", ".", "path", "is", "not", "None", "\n", "self", ".", "_client", "=", "self", ".", "plasma", ".", "connect", "(", "self", ".", "path", ")", "\n", "", "return", "self", ".", "_client", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.plasma_utils.PlasmaArray.__getstate__": [[66, 79], ["plasma_utils.PlasmaArray.__dict__.copy", "plasma_utils.PlasmaArray.start_server", "plasma_utils.PlasmaArray.client.put"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.copy", "home.repos.pwc.inspect_result.reneeye_const.data.plasma_utils.PlasmaArray.start_server"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "plasma", "is", "None", ":", "\n", "            ", "return", "self", ".", "__dict__", "\n", "", "if", "self", ".", "object_id", "is", "None", ":", "\n", "            ", "self", ".", "start_server", "(", ")", "\n", "self", ".", "object_id", "=", "self", ".", "client", ".", "put", "(", "self", ".", "array", ")", "\n", "", "state", "=", "self", ".", "__dict__", ".", "copy", "(", ")", "\n", "del", "state", "[", "\"array\"", "]", "\n", "state", "[", "\"_client\"", "]", "=", "None", "\n", "state", "[", "\"_server\"", "]", "=", "None", "\n", "state", "[", "\"_server_tmp\"", "]", "=", "None", "\n", "state", "[", "\"_plasma\"", "]", "=", "None", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.plasma_utils.PlasmaArray.__setstate__": [[80, 85], ["plasma_utils.PlasmaArray.__dict__.update", "plasma_utils.PlasmaArray.client.get"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "self", ".", "__dict__", ".", "update", "(", "state", ")", "\n", "if", "self", ".", "plasma", "is", "None", ":", "\n", "            ", "return", "\n", "", "self", ".", "array", "=", "self", ".", "client", ".", "get", "(", "self", ".", "object_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.plasma_utils.PlasmaArray.__del__": [[86, 92], ["plasma_utils.PlasmaArray._server.kill", "plasma_utils.PlasmaArray._server_tmp.close"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.nan_detector.NanDetector.close"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_server", "is", "not", "None", ":", "\n", "            ", "self", ".", "_server", ".", "kill", "(", ")", "\n", "self", ".", "_server", "=", "None", "\n", "self", ".", "_server_tmp", ".", "close", "(", ")", "\n", "self", ".", "_server_tmp", "=", "None", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.cumsum": [[15, 23], ["zip", "int", "r.append", "len"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "cumsum", "(", "sequence", ",", "sample_ratios", ")", ":", "\n", "        ", "r", ",", "s", "=", "[", "]", ",", "0", "\n", "for", "e", ",", "ratio", "in", "zip", "(", "sequence", ",", "sample_ratios", ")", ":", "\n", "            ", "curr_len", "=", "int", "(", "ratio", "*", "len", "(", "e", ")", ")", "\n", "r", ".", "append", "(", "curr_len", "+", "s", ")", "\n", "s", "+=", "curr_len", "\n", "", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.__init__": [[24, 33], ["FairseqDataset.__init__", "list", "isinstance", "concat_dataset.ConcatDataset.cumsum", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.cumsum"], ["", "def", "__init__", "(", "self", ",", "datasets", ",", "sample_ratios", "=", "1", ")", ":", "\n", "        ", "super", "(", "ConcatDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "len", "(", "datasets", ")", ">", "0", ",", "\"datasets should not be an empty iterable\"", "\n", "self", ".", "datasets", "=", "list", "(", "datasets", ")", "\n", "if", "isinstance", "(", "sample_ratios", ",", "int", ")", ":", "\n", "            ", "sample_ratios", "=", "[", "sample_ratios", "]", "*", "len", "(", "self", ".", "datasets", ")", "\n", "", "self", ".", "sample_ratios", "=", "sample_ratios", "\n", "self", ".", "cumulative_sizes", "=", "self", ".", "cumsum", "(", "self", ".", "datasets", ",", "sample_ratios", ")", "\n", "self", ".", "real_sizes", "=", "[", "len", "(", "d", ")", "for", "d", "in", "self", ".", "datasets", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.__len__": [[34, 36], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cumulative_sizes", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.__getitem__": [[37, 40], ["concat_dataset.ConcatDataset._get_dataset_and_sample_index"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset._get_dataset_and_sample_index"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "dataset_idx", ",", "sample_idx", "=", "self", ".", "_get_dataset_and_sample_index", "(", "idx", ")", "\n", "return", "self", ".", "datasets", "[", "dataset_idx", "]", "[", "sample_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset._get_dataset_and_sample_index": [[41, 49], ["bisect.bisect_right"], "methods", ["None"], ["", "def", "_get_dataset_and_sample_index", "(", "self", ",", "idx", ":", "int", ")", ":", "\n", "        ", "dataset_idx", "=", "bisect", ".", "bisect_right", "(", "self", ".", "cumulative_sizes", ",", "idx", ")", "\n", "if", "dataset_idx", "==", "0", ":", "\n", "            ", "sample_idx", "=", "idx", "\n", "", "else", ":", "\n", "            ", "sample_idx", "=", "idx", "-", "self", ".", "cumulative_sizes", "[", "dataset_idx", "-", "1", "]", "\n", "", "sample_idx", "=", "sample_idx", "%", "self", ".", "real_sizes", "[", "dataset_idx", "]", "\n", "return", "dataset_idx", ",", "sample_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.collater": [[50, 56], ["hasattr", "concat_dataset.ConcatDataset.datasets[].collater", "torch.utils.data.dataloader.default_collate"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.collater"], ["", "def", "collater", "(", "self", ",", "samples", ",", "**", "extra_args", ")", ":", "\n", "# For now only supports datasets with same underlying collater implementations", "\n", "        ", "if", "hasattr", "(", "self", ".", "datasets", "[", "0", "]", ",", "\"collater\"", ")", ":", "\n", "            ", "return", "self", ".", "datasets", "[", "0", "]", ".", "collater", "(", "samples", ",", "**", "extra_args", ")", "\n", "", "else", ":", "\n", "            ", "return", "default_collate", "(", "samples", ",", "**", "extra_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.size": [[57, 63], ["concat_dataset.ConcatDataset._get_dataset_and_sample_index", "concat_dataset.ConcatDataset.datasets[].size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset._get_dataset_and_sample_index", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "", "def", "size", "(", "self", ",", "idx", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Return an example's size as a float or tuple.\n        \"\"\"", "\n", "dataset_idx", ",", "sample_idx", "=", "self", ".", "_get_dataset_and_sample_index", "(", "idx", ")", "\n", "return", "self", ".", "datasets", "[", "dataset_idx", "]", ".", "size", "(", "sample_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.num_tokens": [[64, 66], ["numpy.max", "concat_dataset.ConcatDataset.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "num_tokens", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "return", "np", ".", "max", "(", "self", ".", "size", "(", "index", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.attr": [[67, 70], ["bisect.bisect_right", "getattr"], "methods", ["None"], ["", "def", "attr", "(", "self", ",", "attr", ":", "str", ",", "index", ":", "int", ")", ":", "\n", "        ", "dataset_idx", "=", "bisect", ".", "bisect_right", "(", "self", ".", "cumulative_sizes", ",", "index", ")", "\n", "return", "getattr", "(", "self", ".", "datasets", "[", "dataset_idx", "]", ",", "attr", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.sizes": [[71, 82], ["zip", "numpy.concatenate", "isinstance", "_dataset_sizes.append", "isinstance", "_dataset_sizes.append", "numpy.tile", "numpy.tile"], "methods", ["None"], ["", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "_dataset_sizes", "=", "[", "]", "\n", "for", "ds", ",", "sr", "in", "zip", "(", "self", ".", "datasets", ",", "self", ".", "sample_ratios", ")", ":", "\n", "            ", "if", "isinstance", "(", "ds", ".", "sizes", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "_dataset_sizes", ".", "append", "(", "np", ".", "tile", "(", "ds", ".", "sizes", ",", "sr", ")", ")", "\n", "", "else", ":", "\n", "# Only support underlying dataset with single size array.", "\n", "                ", "assert", "isinstance", "(", "ds", ".", "sizes", ",", "list", ")", "\n", "_dataset_sizes", ".", "append", "(", "np", ".", "tile", "(", "ds", ".", "sizes", "[", "0", "]", ",", "sr", ")", ")", "\n", "", "", "return", "np", ".", "concatenate", "(", "_dataset_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.supports_prefetch": [[83, 86], ["all"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "all", "(", "d", ".", "supports_prefetch", "for", "d", "in", "self", ".", "datasets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.ordered_indices": [[87, 107], ["isinstance", "numpy.arange", "numpy.argsort", "len", "len", "numpy.argsort", "len", "len", "numpy.argsort"], "methods", ["None"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns indices sorted by length. So less padding is needed.\n        \"\"\"", "\n", "if", "isinstance", "(", "self", ".", "sizes", ",", "np", ".", "ndarray", ")", "and", "len", "(", "self", ".", "sizes", ".", "shape", ")", ">", "1", ":", "\n", "# special handling for concatenating lang_pair_datasets", "\n", "            ", "indices", "=", "np", ".", "arange", "(", "len", "(", "self", ")", ")", "\n", "sizes", "=", "self", ".", "sizes", "\n", "tgt_sizes", "=", "(", "\n", "sizes", "[", ":", ",", "1", "]", "if", "len", "(", "sizes", ".", "shape", ")", ">", "0", "and", "sizes", ".", "shape", "[", "1", "]", ">", "1", "else", "None", "\n", ")", "\n", "src_sizes", "=", "(", "\n", "sizes", "[", ":", ",", "0", "]", "if", "len", "(", "sizes", ".", "shape", ")", ">", "0", "and", "sizes", ".", "shape", "[", "1", "]", ">", "1", "else", "sizes", "\n", ")", "\n", "# sort by target length, then source length", "\n", "if", "tgt_sizes", "is", "not", "None", ":", "\n", "                ", "indices", "=", "indices", "[", "np", ".", "argsort", "(", "tgt_sizes", "[", "indices", "]", ",", "kind", "=", "\"mergesort\"", ")", "]", "\n", "", "return", "indices", "[", "np", ".", "argsort", "(", "src_sizes", "[", "indices", "]", ",", "kind", "=", "\"mergesort\"", ")", "]", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "argsort", "(", "self", ".", "sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.prefetch": [[108, 115], ["zip", "len", "getattr", "ds.prefetch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch"], ["", "", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "frm", "=", "0", "\n", "for", "to", ",", "ds", "in", "zip", "(", "self", ".", "cumulative_sizes", ",", "self", ".", "datasets", ")", ":", "\n", "            ", "real_size", "=", "len", "(", "ds", ")", "\n", "if", "getattr", "(", "ds", ",", "\"supports_prefetch\"", ",", "False", ")", ":", "\n", "                ", "ds", ".", "prefetch", "(", "[", "(", "i", "-", "frm", ")", "%", "real_size", "for", "i", "in", "indices", "if", "frm", "<=", "i", "<", "to", "]", ")", "\n", "", "frm", "=", "to", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.can_reuse_epoch_itr_across_epochs": [[116, 119], ["all"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "can_reuse_epoch_itr_across_epochs", "(", "self", ")", ":", "\n", "        ", "return", "all", "(", "d", ".", "can_reuse_epoch_itr_across_epochs", "for", "d", "in", "self", ".", "datasets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.set_epoch": [[120, 125], ["super().set_epoch", "hasattr", "ds.set_epoch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "super", "(", ")", ".", "set_epoch", "(", "epoch", ")", "\n", "for", "ds", "in", "self", ".", "datasets", ":", "\n", "            ", "if", "hasattr", "(", "ds", ",", "\"set_epoch\"", ")", ":", "\n", "                ", "ds", ".", "set_epoch", "(", "epoch", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.language_pair_dataset.LanguagePairDataset.__init__": [[207, 300], ["numpy.array", "numpy.array", "src_dict.eos", "BucketPadLengthDataset", "logger.info", "numpy.vectorize", "numpy.vectorize.", "src_dict.pad", "tgt_dict.pad", "src_dict.eos", "tgt_dict.eos", "src_dict.unk", "tgt_dict.unk", "len", "len", "numpy.vstack", "BucketPadLengthDataset", "logger.info", "numpy.arange", "language_pair_dataset.LanguagePairDataset.src_dict.pad", "list", "len", "numpy.unique", "language_pair_dataset.LanguagePairDataset.tgt_dict.pad", "list"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.unk", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["def", "__init__", "(", "\n", "self", ",", "\n", "src", ",", "\n", "src_sizes", ",", "\n", "src_dict", ",", "\n", "tgt", "=", "None", ",", "\n", "tgt_sizes", "=", "None", ",", "\n", "tgt_dict", "=", "None", ",", "\n", "left_pad_source", "=", "True", ",", "\n", "left_pad_target", "=", "False", ",", "\n", "shuffle", "=", "True", ",", "\n", "input_feeding", "=", "True", ",", "\n", "remove_eos_from_source", "=", "False", ",", "\n", "append_eos_to_target", "=", "False", ",", "\n", "align_dataset", "=", "None", ",", "\n", "constraints", "=", "None", ",", "\n", "append_bos", "=", "False", ",", "\n", "eos", "=", "None", ",", "\n", "num_buckets", "=", "0", ",", "\n", "src_lang_id", "=", "None", ",", "\n", "tgt_lang_id", "=", "None", ",", "\n", "pad_to_multiple", "=", "1", ",", "\n", ")", ":", "\n", "        ", "if", "tgt_dict", "is", "not", "None", ":", "\n", "            ", "assert", "src_dict", ".", "pad", "(", ")", "==", "tgt_dict", ".", "pad", "(", ")", "\n", "assert", "src_dict", ".", "eos", "(", ")", "==", "tgt_dict", ".", "eos", "(", ")", "\n", "assert", "src_dict", ".", "unk", "(", ")", "==", "tgt_dict", ".", "unk", "(", ")", "\n", "", "if", "tgt", "is", "not", "None", ":", "\n", "            ", "assert", "len", "(", "src", ")", "==", "len", "(", "\n", "tgt", "\n", ")", ",", "\"Source and target must contain the same number of examples\"", "\n", "", "self", ".", "src", "=", "src", "\n", "self", ".", "tgt", "=", "tgt", "\n", "self", ".", "src_sizes", "=", "np", ".", "array", "(", "src_sizes", ")", "\n", "self", ".", "tgt_sizes", "=", "np", ".", "array", "(", "tgt_sizes", ")", "if", "tgt_sizes", "is", "not", "None", "else", "None", "\n", "self", ".", "sizes", "=", "(", "\n", "np", ".", "vstack", "(", "(", "self", ".", "src_sizes", ",", "self", ".", "tgt_sizes", ")", ")", ".", "T", "\n", "if", "self", ".", "tgt_sizes", "is", "not", "None", "\n", "else", "self", ".", "src_sizes", "\n", ")", "\n", "self", ".", "src_dict", "=", "src_dict", "\n", "self", ".", "tgt_dict", "=", "tgt_dict", "\n", "self", ".", "left_pad_source", "=", "left_pad_source", "\n", "self", ".", "left_pad_target", "=", "left_pad_target", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "input_feeding", "=", "input_feeding", "\n", "self", ".", "remove_eos_from_source", "=", "remove_eos_from_source", "\n", "self", ".", "append_eos_to_target", "=", "append_eos_to_target", "\n", "self", ".", "align_dataset", "=", "align_dataset", "\n", "if", "self", ".", "align_dataset", "is", "not", "None", ":", "\n", "            ", "assert", "(", "\n", "self", ".", "tgt_sizes", "is", "not", "None", "\n", ")", ",", "\"Both source and target needed when alignments are provided\"", "\n", "", "self", ".", "constraints", "=", "constraints", "\n", "self", ".", "append_bos", "=", "append_bos", "\n", "self", ".", "eos", "=", "eos", "if", "eos", "is", "not", "None", "else", "src_dict", ".", "eos", "(", ")", "\n", "self", ".", "src_lang_id", "=", "src_lang_id", "\n", "self", ".", "tgt_lang_id", "=", "tgt_lang_id", "\n", "if", "num_buckets", ">", "0", ":", "\n", "            ", "from", "fairseq", ".", "data", "import", "BucketPadLengthDataset", "\n", "\n", "self", ".", "src", "=", "BucketPadLengthDataset", "(", "\n", "self", ".", "src", ",", "\n", "sizes", "=", "self", ".", "src_sizes", ",", "\n", "num_buckets", "=", "num_buckets", ",", "\n", "pad_idx", "=", "self", ".", "src_dict", ".", "pad", "(", ")", ",", "\n", "left_pad", "=", "self", ".", "left_pad_source", ",", "\n", ")", "\n", "self", ".", "src_sizes", "=", "self", ".", "src", ".", "sizes", "\n", "logger", ".", "info", "(", "\"bucketing source lengths: {}\"", ".", "format", "(", "list", "(", "self", ".", "src", ".", "buckets", ")", ")", ")", "\n", "if", "self", ".", "tgt", "is", "not", "None", ":", "\n", "                ", "self", ".", "tgt", "=", "BucketPadLengthDataset", "(", "\n", "self", ".", "tgt", ",", "\n", "sizes", "=", "self", ".", "tgt_sizes", ",", "\n", "num_buckets", "=", "num_buckets", ",", "\n", "pad_idx", "=", "self", ".", "tgt_dict", ".", "pad", "(", ")", ",", "\n", "left_pad", "=", "self", ".", "left_pad_target", ",", "\n", ")", "\n", "self", ".", "tgt_sizes", "=", "self", ".", "tgt", ".", "sizes", "\n", "logger", ".", "info", "(", "\n", "\"bucketing target lengths: {}\"", ".", "format", "(", "list", "(", "self", ".", "tgt", ".", "buckets", ")", ")", "\n", ")", "\n", "\n", "# determine bucket sizes using self.num_tokens, which will return", "\n", "# the padded lengths (thanks to BucketPadLengthDataset)", "\n", "", "num_tokens", "=", "np", ".", "vectorize", "(", "self", ".", "num_tokens", ",", "otypes", "=", "[", "np", ".", "long", "]", ")", "\n", "self", ".", "bucketed_num_tokens", "=", "num_tokens", "(", "np", ".", "arange", "(", "len", "(", "self", ".", "src", ")", ")", ")", "\n", "self", ".", "buckets", "=", "[", "\n", "(", "None", ",", "num_tokens", ")", "for", "num_tokens", "in", "np", ".", "unique", "(", "self", ".", "bucketed_num_tokens", ")", "\n", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "buckets", "=", "None", "\n", "", "self", ".", "pad_to_multiple", "=", "pad_to_multiple", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.language_pair_dataset.LanguagePairDataset.get_batch_shapes": [[301, 303], ["None"], "methods", ["None"], ["", "def", "get_batch_shapes", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "buckets", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.language_pair_dataset.LanguagePairDataset.__getitem__": [[304, 340], ["language_pair_dataset.LanguagePairDataset.src_dict.bos", "language_pair_dataset.LanguagePairDataset.src_dict.eos", "language_pair_dataset.LanguagePairDataset.tgt_dict.eos", "language_pair_dataset.LanguagePairDataset.src_dict.eos", "torch.cat", "language_pair_dataset.LanguagePairDataset.tgt_dict.bos", "language_pair_dataset.LanguagePairDataset.src_dict.bos", "torch.cat", "torch.cat", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "tgt_item", "=", "self", ".", "tgt", "[", "index", "]", "if", "self", ".", "tgt", "is", "not", "None", "else", "None", "\n", "src_item", "=", "self", ".", "src", "[", "index", "]", "\n", "# Append EOS to end of tgt sentence if it does not have an EOS and remove", "\n", "# EOS from end of src sentence if it exists. This is useful when we use", "\n", "# use existing datasets for opposite directions i.e., when we want to", "\n", "# use tgt_dataset as src_dataset and vice versa", "\n", "if", "self", ".", "append_eos_to_target", ":", "\n", "            ", "eos", "=", "self", ".", "tgt_dict", ".", "eos", "(", ")", "if", "self", ".", "tgt_dict", "else", "self", ".", "src_dict", ".", "eos", "(", ")", "\n", "if", "self", ".", "tgt", "and", "self", ".", "tgt", "[", "index", "]", "[", "-", "1", "]", "!=", "eos", ":", "\n", "                ", "tgt_item", "=", "torch", ".", "cat", "(", "[", "self", ".", "tgt", "[", "index", "]", ",", "torch", ".", "LongTensor", "(", "[", "eos", "]", ")", "]", ")", "\n", "\n", "", "", "if", "self", ".", "append_bos", ":", "\n", "            ", "bos", "=", "self", ".", "tgt_dict", ".", "bos", "(", ")", "if", "self", ".", "tgt_dict", "else", "self", ".", "src_dict", ".", "bos", "(", ")", "\n", "if", "self", ".", "tgt", "and", "self", ".", "tgt", "[", "index", "]", "[", "0", "]", "!=", "bos", ":", "\n", "                ", "tgt_item", "=", "torch", ".", "cat", "(", "[", "torch", ".", "LongTensor", "(", "[", "bos", "]", ")", ",", "self", ".", "tgt", "[", "index", "]", "]", ")", "\n", "\n", "", "bos", "=", "self", ".", "src_dict", ".", "bos", "(", ")", "\n", "if", "self", ".", "src", "[", "index", "]", "[", "0", "]", "!=", "bos", ":", "\n", "                ", "src_item", "=", "torch", ".", "cat", "(", "[", "torch", ".", "LongTensor", "(", "[", "bos", "]", ")", ",", "self", ".", "src", "[", "index", "]", "]", ")", "\n", "\n", "", "", "if", "self", ".", "remove_eos_from_source", ":", "\n", "            ", "eos", "=", "self", ".", "src_dict", ".", "eos", "(", ")", "\n", "if", "self", ".", "src", "[", "index", "]", "[", "-", "1", "]", "==", "eos", ":", "\n", "                ", "src_item", "=", "self", ".", "src", "[", "index", "]", "[", ":", "-", "1", "]", "\n", "\n", "", "", "example", "=", "{", "\n", "\"id\"", ":", "index", ",", "\n", "\"source\"", ":", "src_item", ",", "\n", "\"target\"", ":", "tgt_item", ",", "\n", "}", "\n", "if", "self", ".", "align_dataset", "is", "not", "None", ":", "\n", "            ", "example", "[", "\"alignment\"", "]", "=", "self", ".", "align_dataset", "[", "index", "]", "\n", "", "if", "self", ".", "constraints", "is", "not", "None", ":", "\n", "            ", "example", "[", "\"constraints\"", "]", "=", "self", ".", "constraints", "[", "index", "]", "\n", "", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.language_pair_dataset.LanguagePairDataset.__len__": [[341, 343], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "src", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.language_pair_dataset.LanguagePairDataset.collater": [[344, 402], ["language_pair_dataset.collate", "src_tokens.size", "language_pair_dataset.LanguagePairDataset.src_dict.pad", "torch.LongTensor().expand().to", "torch.LongTensor().expand().to", "torch.LongTensor().expand", "torch.LongTensor().expand", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.collate", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["", "def", "collater", "(", "self", ",", "samples", ",", "pad_to_length", "=", "None", ")", ":", "\n", "        ", "\"\"\"Merge a list of samples to form a mini-batch.\n\n        Args:\n            samples (List[dict]): samples to collate\n            pad_to_length (dict, optional): a dictionary of\n                {'source': source_pad_to_length, 'target': target_pad_to_length}\n                to indicate the max length to pad to in source and target respectively.\n\n        Returns:\n            dict: a mini-batch with the following keys:\n\n                - `id` (LongTensor): example IDs in the original input order\n                - `ntokens` (int): total number of tokens in the batch\n                - `net_input` (dict): the input to the Model, containing keys:\n\n                  - `src_tokens` (LongTensor): a padded 2D Tensor of tokens in\n                    the source sentence of shape `(bsz, src_len)`. Padding will\n                    appear on the left if *left_pad_source* is ``True``.\n                  - `src_lengths` (LongTensor): 1D Tensor of the unpadded\n                    lengths of each source sentence of shape `(bsz)`\n                  - `prev_output_tokens` (LongTensor): a padded 2D Tensor of\n                    tokens in the target sentence, shifted right by one\n                    position for teacher forcing, of shape `(bsz, tgt_len)`.\n                    This key will not be present if *input_feeding* is\n                    ``False``.  Padding will appear on the left if\n                    *left_pad_target* is ``True``.\n                  - `src_lang_id` (LongTensor): a long Tensor which contains source\n                    language IDs of each sample in the batch\n\n                - `target` (LongTensor): a padded 2D Tensor of tokens in the\n                  target sentence of shape `(bsz, tgt_len)`. Padding will appear\n                  on the left if *left_pad_target* is ``True``.\n                - `tgt_lang_id` (LongTensor): a long Tensor which contains target language\n                   IDs of each sample in the batch\n        \"\"\"", "\n", "res", "=", "collate", "(", "\n", "samples", ",", "\n", "pad_idx", "=", "self", ".", "src_dict", ".", "pad", "(", ")", ",", "\n", "eos_idx", "=", "self", ".", "eos", ",", "\n", "left_pad_source", "=", "self", ".", "left_pad_source", ",", "\n", "left_pad_target", "=", "self", ".", "left_pad_target", ",", "\n", "input_feeding", "=", "self", ".", "input_feeding", ",", "\n", "pad_to_length", "=", "pad_to_length", ",", "\n", "pad_to_multiple", "=", "self", ".", "pad_to_multiple", ",", "\n", ")", "\n", "if", "self", ".", "src_lang_id", "is", "not", "None", "or", "self", ".", "tgt_lang_id", "is", "not", "None", ":", "\n", "            ", "src_tokens", "=", "res", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "\n", "bsz", "=", "src_tokens", ".", "size", "(", "0", ")", "\n", "if", "self", ".", "src_lang_id", "is", "not", "None", ":", "\n", "                ", "res", "[", "\"net_input\"", "]", "[", "\"src_lang_id\"", "]", "=", "(", "\n", "torch", ".", "LongTensor", "(", "[", "[", "self", ".", "src_lang_id", "]", "]", ")", ".", "expand", "(", "bsz", ",", "1", ")", ".", "to", "(", "src_tokens", ")", "\n", ")", "\n", "", "if", "self", ".", "tgt_lang_id", "is", "not", "None", ":", "\n", "                ", "res", "[", "\"tgt_lang_id\"", "]", "=", "(", "\n", "torch", ".", "LongTensor", "(", "[", "[", "self", ".", "tgt_lang_id", "]", "]", ")", ".", "expand", "(", "bsz", ",", "1", ")", ".", "to", "(", "src_tokens", ")", "\n", ")", "\n", "", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.language_pair_dataset.LanguagePairDataset.num_tokens": [[403, 409], ["max"], "methods", ["None"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return the number of tokens in a sample. This value is used to\n        enforce ``--max-tokens`` during batching.\"\"\"", "\n", "return", "max", "(", "\n", "self", ".", "src_sizes", "[", "index", "]", ",", "\n", "self", ".", "tgt_sizes", "[", "index", "]", "if", "self", ".", "tgt_sizes", "is", "not", "None", "else", "0", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.language_pair_dataset.LanguagePairDataset.size": [[411, 417], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return an example's size as a float or tuple. This value is used when\n        filtering a dataset with ``--max-positions``.\"\"\"", "\n", "return", "(", "\n", "self", ".", "src_sizes", "[", "index", "]", ",", "\n", "self", ".", "tgt_sizes", "[", "index", "]", "if", "self", ".", "tgt_sizes", "is", "not", "None", "else", "0", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.language_pair_dataset.LanguagePairDataset.ordered_indices": [[419, 436], ["numpy.random.permutation().astype", "numpy.arange", "len", "numpy.random.permutation", "numpy.argsort", "numpy.argsort", "len", "numpy.argsort"], "methods", ["None"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return an ordered list of indices. Batches will be constructed based\n        on this order.\"\"\"", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "indices", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ")", ")", ".", "astype", "(", "np", ".", "int64", ")", "\n", "", "else", ":", "\n", "            ", "indices", "=", "np", ".", "arange", "(", "len", "(", "self", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "", "if", "self", ".", "buckets", "is", "None", ":", "\n", "# sort by target length, then source length", "\n", "            ", "if", "self", ".", "tgt_sizes", "is", "not", "None", ":", "\n", "                ", "indices", "=", "indices", "[", "np", ".", "argsort", "(", "self", ".", "tgt_sizes", "[", "indices", "]", ",", "kind", "=", "\"mergesort\"", ")", "]", "\n", "", "return", "indices", "[", "np", ".", "argsort", "(", "self", ".", "src_sizes", "[", "indices", "]", ",", "kind", "=", "\"mergesort\"", ")", "]", "\n", "", "else", ":", "\n", "# sort by bucketed_num_tokens, which is:", "\n", "#   max(padded_src_len, padded_tgt_len)", "\n", "            ", "return", "indices", "[", "\n", "np", ".", "argsort", "(", "self", ".", "bucketed_num_tokens", "[", "indices", "]", ",", "kind", "=", "\"mergesort\"", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.language_pair_dataset.LanguagePairDataset.supports_prefetch": [[438, 442], ["getattr", "getattr"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ".", "src", ",", "\"supports_prefetch\"", ",", "False", ")", "and", "(", "\n", "getattr", "(", "self", ".", "tgt", ",", "\"supports_prefetch\"", ",", "False", ")", "or", "self", ".", "tgt", "is", "None", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.language_pair_dataset.LanguagePairDataset.prefetch": [[444, 450], ["language_pair_dataset.LanguagePairDataset.src.prefetch", "language_pair_dataset.LanguagePairDataset.tgt.prefetch", "language_pair_dataset.LanguagePairDataset.align_dataset.prefetch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "self", ".", "src", ".", "prefetch", "(", "indices", ")", "\n", "if", "self", ".", "tgt", "is", "not", "None", ":", "\n", "            ", "self", ".", "tgt", ".", "prefetch", "(", "indices", ")", "\n", "", "if", "self", ".", "align_dataset", "is", "not", "None", ":", "\n", "            ", "self", ".", "align_dataset", ".", "prefetch", "(", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.language_pair_dataset.LanguagePairDataset.filter_indices_by_size": [[451, 469], ["fairseq.data.data_utils.filter_paired_dataset_indices_by_size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils.filter_paired_dataset_indices_by_size"], ["", "", "def", "filter_indices_by_size", "(", "self", ",", "indices", ",", "max_sizes", ")", ":", "\n", "        ", "\"\"\"Filter a list of sample indices. Remove those that are longer\n            than specified in max_sizes.\n\n        Args:\n            indices (np.array): original array of sample indices\n            max_sizes (int or list[int] or tuple[int]): max sample size,\n                can be defined separately for src and tgt (then list or tuple)\n\n        Returns:\n            np.array: filtered sample array\n            list: list of removed indices\n        \"\"\"", "\n", "return", "data_utils", ".", "filter_paired_dataset_indices_by_size", "(", "\n", "self", ".", "src_sizes", ",", "\n", "self", ".", "tgt_sizes", ",", "\n", "indices", ",", "\n", "max_sizes", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.language_pair_dataset.collate": [[16, 166], ["torch.LongTensor", "language_pair_dataset.collate.merge"], "function", ["None"], ["def", "collate", "(", "\n", "samples", ",", "\n", "pad_idx", ",", "\n", "eos_idx", ",", "\n", "left_pad_source", "=", "True", ",", "\n", "left_pad_target", "=", "False", ",", "\n", "input_feeding", "=", "True", ",", "\n", "pad_to_length", "=", "None", ",", "\n", "pad_to_multiple", "=", "1", ",", "\n", ")", ":", "\n", "    ", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "        ", "return", "{", "}", "\n", "\n", "", "def", "merge", "(", "key", ",", "left_pad", ",", "move_eos_to_beginning", "=", "False", ",", "pad_to_length", "=", "None", ")", ":", "\n", "        ", "return", "data_utils", ".", "collate_tokens", "(", "\n", "[", "s", "[", "key", "]", "for", "s", "in", "samples", "]", ",", "\n", "pad_idx", ",", "\n", "eos_idx", ",", "\n", "left_pad", ",", "\n", "move_eos_to_beginning", ",", "\n", "pad_to_length", "=", "pad_to_length", ",", "\n", "pad_to_multiple", "=", "pad_to_multiple", ",", "\n", ")", "\n", "\n", "", "def", "check_alignment", "(", "alignment", ",", "src_len", ",", "tgt_len", ")", ":", "\n", "        ", "if", "alignment", "is", "None", "or", "len", "(", "alignment", ")", "==", "0", ":", "\n", "            ", "return", "False", "\n", "", "if", "(", "\n", "alignment", "[", ":", ",", "0", "]", ".", "max", "(", ")", ".", "item", "(", ")", ">=", "src_len", "-", "1", "\n", "or", "alignment", "[", ":", ",", "1", "]", ".", "max", "(", ")", ".", "item", "(", ")", ">=", "tgt_len", "-", "1", "\n", ")", ":", "\n", "            ", "logger", ".", "warning", "(", "\"alignment size mismatch found, skipping alignment!\"", ")", "\n", "return", "False", "\n", "", "return", "True", "\n", "\n", "", "def", "compute_alignment_weights", "(", "alignments", ")", ":", "\n", "        ", "\"\"\"\n        Given a tensor of shape [:, 2] containing the source-target indices\n        corresponding to the alignments, a weight vector containing the\n        inverse frequency of each target index is computed.\n        For e.g. if alignments = [[5, 7], [2, 3], [1, 3], [4, 2]], then\n        a tensor containing [1., 0.5, 0.5, 1] should be returned (since target\n        index 3 is repeated twice)\n        \"\"\"", "\n", "align_tgt", "=", "alignments", "[", ":", ",", "1", "]", "\n", "_", ",", "align_tgt_i", ",", "align_tgt_c", "=", "torch", ".", "unique", "(", "\n", "align_tgt", ",", "return_inverse", "=", "True", ",", "return_counts", "=", "True", "\n", ")", "\n", "align_weights", "=", "align_tgt_c", "[", "align_tgt_i", "[", "np", ".", "arange", "(", "len", "(", "align_tgt", ")", ")", "]", "]", "\n", "return", "1.0", "/", "align_weights", ".", "float", "(", ")", "\n", "\n", "", "id", "=", "torch", ".", "LongTensor", "(", "[", "s", "[", "\"id\"", "]", "for", "s", "in", "samples", "]", ")", "\n", "src_tokens", "=", "merge", "(", "\n", "\"source\"", ",", "\n", "left_pad", "=", "left_pad_source", ",", "\n", "pad_to_length", "=", "pad_to_length", "[", "\"source\"", "]", "if", "pad_to_length", "is", "not", "None", "else", "None", ",", "\n", ")", "\n", "# sort by descending source length", "\n", "src_lengths", "=", "torch", ".", "LongTensor", "(", "\n", "[", "s", "[", "\"source\"", "]", ".", "ne", "(", "pad_idx", ")", ".", "long", "(", ")", ".", "sum", "(", ")", "for", "s", "in", "samples", "]", "\n", ")", "\n", "src_lengths", ",", "sort_order", "=", "src_lengths", ".", "sort", "(", "descending", "=", "True", ")", "\n", "id", "=", "id", ".", "index_select", "(", "0", ",", "sort_order", ")", "\n", "src_tokens", "=", "src_tokens", ".", "index_select", "(", "0", ",", "sort_order", ")", "\n", "\n", "prev_output_tokens", "=", "None", "\n", "target", "=", "None", "\n", "if", "samples", "[", "0", "]", ".", "get", "(", "\"target\"", ",", "None", ")", "is", "not", "None", ":", "\n", "        ", "target", "=", "merge", "(", "\n", "\"target\"", ",", "\n", "left_pad", "=", "left_pad_target", ",", "\n", "pad_to_length", "=", "pad_to_length", "[", "\"target\"", "]", "\n", "if", "pad_to_length", "is", "not", "None", "\n", "else", "None", ",", "\n", ")", "\n", "target", "=", "target", ".", "index_select", "(", "0", ",", "sort_order", ")", "\n", "tgt_lengths", "=", "torch", ".", "LongTensor", "(", "\n", "[", "s", "[", "\"target\"", "]", ".", "ne", "(", "pad_idx", ")", ".", "long", "(", ")", ".", "sum", "(", ")", "for", "s", "in", "samples", "]", "\n", ")", ".", "index_select", "(", "0", ",", "sort_order", ")", "\n", "ntokens", "=", "tgt_lengths", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "if", "samples", "[", "0", "]", ".", "get", "(", "\"prev_output_tokens\"", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "prev_output_tokens", "=", "merge", "(", "\"prev_output_tokens\"", ",", "left_pad", "=", "left_pad_target", ")", "\n", "", "elif", "input_feeding", ":", "\n", "# we create a shifted version of targets for feeding the", "\n", "# previous output token(s) into the next decoder step", "\n", "            ", "prev_output_tokens", "=", "merge", "(", "\n", "\"target\"", ",", "\n", "left_pad", "=", "left_pad_target", ",", "\n", "move_eos_to_beginning", "=", "True", ",", "\n", "pad_to_length", "=", "pad_to_length", "[", "\"target\"", "]", "\n", "if", "pad_to_length", "is", "not", "None", "\n", "else", "None", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "        ", "ntokens", "=", "src_lengths", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "batch", "=", "{", "\n", "\"id\"", ":", "id", ",", "\n", "\"nsentences\"", ":", "len", "(", "samples", ")", ",", "\n", "\"ntokens\"", ":", "ntokens", ",", "\n", "\"net_input\"", ":", "{", "\n", "\"src_tokens\"", ":", "src_tokens", ",", "\n", "\"src_lengths\"", ":", "src_lengths", ",", "\n", "}", ",", "\n", "\"target\"", ":", "target", ",", "\n", "}", "\n", "if", "prev_output_tokens", "is", "not", "None", ":", "\n", "        ", "batch", "[", "\"net_input\"", "]", "[", "\"prev_output_tokens\"", "]", "=", "prev_output_tokens", ".", "index_select", "(", "\n", "0", ",", "sort_order", "\n", ")", "\n", "\n", "", "if", "samples", "[", "0", "]", ".", "get", "(", "\"alignment\"", ",", "None", ")", "is", "not", "None", ":", "\n", "        ", "bsz", ",", "tgt_sz", "=", "batch", "[", "\"target\"", "]", ".", "shape", "\n", "src_sz", "=", "batch", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", ".", "shape", "[", "1", "]", "\n", "\n", "offsets", "=", "torch", ".", "zeros", "(", "(", "len", "(", "sort_order", ")", ",", "2", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "offsets", "[", ":", ",", "1", "]", "+=", "torch", ".", "arange", "(", "len", "(", "sort_order", ")", ",", "dtype", "=", "torch", ".", "long", ")", "*", "tgt_sz", "\n", "if", "left_pad_source", ":", "\n", "            ", "offsets", "[", ":", ",", "0", "]", "+=", "src_sz", "-", "src_lengths", "\n", "", "if", "left_pad_target", ":", "\n", "            ", "offsets", "[", ":", ",", "1", "]", "+=", "tgt_sz", "-", "tgt_lengths", "\n", "\n", "", "alignments", "=", "[", "\n", "alignment", "+", "offset", "\n", "for", "align_idx", ",", "offset", ",", "src_len", ",", "tgt_len", "in", "zip", "(", "\n", "sort_order", ",", "offsets", ",", "src_lengths", ",", "tgt_lengths", "\n", ")", "\n", "for", "alignment", "in", "[", "samples", "[", "align_idx", "]", "[", "\"alignment\"", "]", ".", "view", "(", "-", "1", ",", "2", ")", "]", "\n", "if", "check_alignment", "(", "alignment", ",", "src_len", ",", "tgt_len", ")", "\n", "]", "\n", "\n", "if", "len", "(", "alignments", ")", ">", "0", ":", "\n", "            ", "alignments", "=", "torch", ".", "cat", "(", "alignments", ",", "dim", "=", "0", ")", "\n", "align_weights", "=", "compute_alignment_weights", "(", "alignments", ")", "\n", "\n", "batch", "[", "\"alignments\"", "]", "=", "alignments", "\n", "batch", "[", "\"align_weights\"", "]", "=", "align_weights", "\n", "\n", "", "", "if", "samples", "[", "0", "]", ".", "get", "(", "\"constraints\"", ",", "None", ")", "is", "not", "None", ":", "\n", "# Collate the packed constraints across the samples, padding to", "\n", "# the length of the longest sample.", "\n", "        ", "lens", "=", "[", "sample", ".", "get", "(", "\"constraints\"", ")", ".", "size", "(", "0", ")", "for", "sample", "in", "samples", "]", "\n", "max_len", "=", "max", "(", "lens", ")", "\n", "constraints", "=", "torch", ".", "zeros", "(", "(", "len", "(", "samples", ")", ",", "max", "(", "lens", ")", ")", ")", ".", "long", "(", ")", "\n", "for", "i", ",", "sample", "in", "enumerate", "(", "samples", ")", ":", "\n", "            ", "constraints", "[", "i", ",", "0", ":", "lens", "[", "i", "]", "]", "=", "samples", "[", "i", "]", ".", "get", "(", "\"constraints\"", ")", "\n", "", "batch", "[", "\"constraints\"", "]", "=", "constraints", "\n", "\n", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.colorize_dataset.ColorizeDataset.__init__": [[14, 17], ["BaseWrapperDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "dataset", ",", "color_getter", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ")", "\n", "self", ".", "color_getter", "=", "color_getter", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.colorize_dataset.ColorizeDataset.collater": [[18, 26], ["super().collater", "len", "torch.tensor", "list", "colorize_dataset.ColorizeDataset.color_getter"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.collater"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "base_collate", "=", "super", "(", ")", ".", "collater", "(", "samples", ")", "\n", "if", "len", "(", "base_collate", ")", ">", "0", ":", "\n", "            ", "base_collate", "[", "\"net_input\"", "]", "[", "\"colors\"", "]", "=", "torch", ".", "tensor", "(", "\n", "list", "(", "self", ".", "color_getter", "(", "self", ".", "dataset", ",", "s", "[", "\"id\"", "]", ")", "for", "s", "in", "samples", ")", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "\n", ")", "\n", "", "return", "base_collate", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.bucket_pad_length_dataset.BucketPadLengthDataset.__init__": [[25, 57], ["fairseq.data.BaseWrapperDataset.__init__", "numpy.unique", "bucket_pad_length_dataset.BucketPadLengthDataset.__init__.get_bucketed_sizes"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "sizes", ",", "\n", "num_buckets", ",", "\n", "pad_idx", ",", "\n", "left_pad", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ")", "\n", "self", ".", "pad_idx", "=", "pad_idx", "\n", "self", ".", "left_pad", "=", "left_pad", "\n", "\n", "assert", "num_buckets", ">", "0", "\n", "self", ".", "buckets", "=", "np", ".", "unique", "(", "\n", "np", ".", "percentile", "(", "\n", "sizes", ",", "\n", "np", ".", "linspace", "(", "0", ",", "100", ",", "num_buckets", "+", "1", ")", ",", "\n", "interpolation", "=", "\"lower\"", ",", "\n", ")", "[", "1", ":", "]", "\n", ")", "\n", "\n", "def", "get_bucketed_sizes", "(", "orig_sizes", ",", "buckets", ")", ":", "\n", "            ", "sizes", "=", "np", ".", "copy", "(", "orig_sizes", ")", "\n", "assert", "np", ".", "min", "(", "sizes", ")", ">=", "0", "\n", "start_val", "=", "-", "1", "\n", "for", "end_val", "in", "buckets", ":", "\n", "                ", "mask", "=", "(", "sizes", ">", "start_val", ")", "&", "(", "sizes", "<=", "end_val", ")", "\n", "sizes", "[", "mask", "]", "=", "end_val", "\n", "start_val", "=", "end_val", "\n", "", "return", "sizes", "\n", "\n", "", "self", ".", "_bucketed_sizes", "=", "get_bucketed_sizes", "(", "sizes", ",", "self", ".", "buckets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.bucket_pad_length_dataset.BucketPadLengthDataset.__getitem__": [[58, 66], ["torch.pad", "item.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "item", "=", "self", ".", "dataset", "[", "index", "]", "\n", "bucket_size", "=", "self", ".", "_bucketed_sizes", "[", "index", "]", "\n", "num_pad", "=", "bucket_size", "-", "item", ".", "size", "(", "-", "1", ")", "\n", "return", "F", ".", "pad", "(", "\n", "item", ",", "\n", "(", "num_pad", "if", "self", ".", "left_pad", "else", "0", ",", "0", "if", "self", ".", "left_pad", "else", "num_pad", ")", ",", "\n", "value", "=", "self", ".", "pad_idx", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.bucket_pad_length_dataset.BucketPadLengthDataset.sizes": [[68, 71], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_bucketed_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.bucket_pad_length_dataset.BucketPadLengthDataset.num_tokens": [[72, 74], ["None"], "methods", ["None"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "_bucketed_sizes", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.bucket_pad_length_dataset.BucketPadLengthDataset.size": [[75, 77], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "_bucketed_sizes", "[", "index", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.numel_dataset.NumelDataset.__init__": [[13, 16], ["BaseWrapperDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "reduce", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ")", "\n", "self", ".", "reduce", "=", "reduce", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.numel_dataset.NumelDataset.__getitem__": [[17, 23], ["torch.is_tensor", "torch.numel", "numpy.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "item", "=", "self", ".", "dataset", "[", "index", "]", "\n", "if", "torch", ".", "is_tensor", "(", "item", ")", ":", "\n", "            ", "return", "torch", ".", "numel", "(", "item", ")", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "size", "(", "item", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.numel_dataset.NumelDataset.__len__": [[24, 26], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.numel_dataset.NumelDataset.collater": [[27, 32], ["sum", "torch.tensor"], "methods", ["None"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "if", "self", ".", "reduce", ":", "\n", "            ", "return", "sum", "(", "samples", ")", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "tensor", "(", "samples", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.resampling_dataset.ResamplingDataset.__init__": [[41, 77], ["fairseq.data.BaseWrapperDataset.__init__", "float", "numpy.ceil().astype", "resampling_dataset.ResamplingDataset.set_epoch", "numpy.array", "numpy.array.sum", "fairseq.data.plasma_utils.PlasmaArray", "len", "len", "numpy.ceil", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "weights", "=", "None", ",", "\n", "replace", "=", "True", ",", "\n", "size_ratio", "=", "1.0", ",", "\n", "batch_by_size", "=", "True", ",", "\n", "seed", "=", "0", ",", "\n", "epoch", "=", "1", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ")", "\n", "\n", "if", "weights", "is", "None", ":", "\n", "            ", "self", ".", "weights", "=", "None", "\n", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "weights", ")", "==", "len", "(", "dataset", ")", "\n", "weights_arr", "=", "np", ".", "array", "(", "weights", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "weights_arr", "/=", "weights_arr", ".", "sum", "(", ")", "\n", "self", ".", "weights", "=", "plasma_utils", ".", "PlasmaArray", "(", "weights_arr", ")", "\n", "\n", "", "self", ".", "replace", "=", "replace", "\n", "\n", "assert", "size_ratio", ">", "0.0", "\n", "if", "not", "self", ".", "replace", ":", "\n", "            ", "assert", "size_ratio", "<", "1.0", "\n", "", "self", ".", "size_ratio", "=", "float", "(", "size_ratio", ")", "\n", "self", ".", "actual_size", "=", "np", ".", "ceil", "(", "len", "(", "dataset", ")", "*", "self", ".", "size_ratio", ")", ".", "astype", "(", "int", ")", "\n", "\n", "self", ".", "batch_by_size", "=", "batch_by_size", "\n", "self", ".", "seed", "=", "seed", "\n", "\n", "self", ".", "_cur_epoch", "=", "None", "\n", "self", ".", "_cur_indices", "=", "None", "\n", "\n", "self", ".", "set_epoch", "(", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.resampling_dataset.ResamplingDataset.__getitem__": [[78, 80], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "dataset", "[", "self", ".", "_cur_indices", ".", "array", "[", "index", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.resampling_dataset.ResamplingDataset.__len__": [[81, 83], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "actual_size", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.resampling_dataset.ResamplingDataset.sizes": [[84, 89], ["isinstance"], "methods", ["None"], ["", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "dataset", ".", "sizes", ",", "list", ")", ":", "\n", "            ", "return", "[", "s", "[", "self", ".", "_cur_indices", ".", "array", "]", "for", "s", "in", "self", ".", "dataset", ".", "sizes", "]", "\n", "", "return", "self", ".", "dataset", ".", "sizes", "[", "self", ".", "_cur_indices", ".", "array", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.resampling_dataset.ResamplingDataset.num_tokens": [[90, 92], ["resampling_dataset.ResamplingDataset.dataset.num_tokens"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.num_tokens"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "num_tokens", "(", "self", ".", "_cur_indices", ".", "array", "[", "index", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.resampling_dataset.ResamplingDataset.size": [[93, 95], ["resampling_dataset.ResamplingDataset.dataset.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "size", "(", "self", ".", "_cur_indices", ".", "array", "[", "index", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.resampling_dataset.ResamplingDataset.ordered_indices": [[96, 105], ["numpy.lexsort", "numpy.arange", "numpy.arange", "len", "len"], "methods", ["None"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "batch_by_size", ":", "\n", "            ", "order", "=", "[", "\n", "np", ".", "arange", "(", "len", "(", "self", ")", ")", ",", "\n", "self", ".", "sizes", ",", "\n", "]", "# No need to handle `self.shuffle == True`", "\n", "return", "np", ".", "lexsort", "(", "order", ")", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "arange", "(", "len", "(", "self", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.resampling_dataset.ResamplingDataset.prefetch": [[106, 108], ["resampling_dataset.ResamplingDataset.dataset.prefetch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch"], ["", "", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "self", ".", "dataset", ".", "prefetch", "(", "self", ".", "_cur_indices", ".", "array", "[", "indices", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.resampling_dataset.ResamplingDataset.can_reuse_epoch_itr_across_epochs": [[109, 112], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "can_reuse_epoch_itr_across_epochs", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.resampling_dataset.ResamplingDataset.set_epoch": [[113, 138], ["logger.debug", "super().set_epoch", "numpy.random.RandomState", "fairseq.data.plasma_utils.PlasmaArray", "numpy.random.RandomState.choice", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "logger", ".", "debug", "(", "\"ResamplingDataset.set_epoch: {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "super", "(", ")", ".", "set_epoch", "(", "epoch", ")", "\n", "\n", "if", "epoch", "==", "self", ".", "_cur_epoch", ":", "\n", "            ", "return", "\n", "\n", "", "self", ".", "_cur_epoch", "=", "epoch", "\n", "\n", "# Generate a weighted sample of indices as a function of the", "\n", "# random seed and the current epoch.", "\n", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "\n", "[", "\n", "42", ",", "# magic number", "\n", "self", ".", "seed", "%", "(", "2", "**", "32", ")", ",", "# global seed", "\n", "self", ".", "_cur_epoch", ",", "# epoch index", "\n", "]", "\n", ")", "\n", "self", ".", "_cur_indices", "=", "plasma_utils", ".", "PlasmaArray", "(", "\n", "rng", ".", "choice", "(", "\n", "len", "(", "self", ".", "dataset", ")", ",", "\n", "self", ".", "actual_size", ",", "\n", "replace", "=", "self", ".", "replace", ",", "\n", "p", "=", "(", "None", "if", "self", ".", "weights", "is", "None", "else", "self", ".", "weights", ".", "array", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.shorten_dataset.TruncateDataset.__init__": [[15, 20], ["BaseWrapperDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "dataset", ",", "truncation_length", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ")", "\n", "assert", "truncation_length", "is", "not", "None", "\n", "self", ".", "truncation_length", "=", "truncation_length", "\n", "self", ".", "dataset", "=", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.shorten_dataset.TruncateDataset.__getitem__": [[21, 27], ["item.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "item", "=", "self", ".", "dataset", "[", "index", "]", "\n", "item_len", "=", "item", ".", "size", "(", "0", ")", "\n", "if", "item_len", ">", "self", ".", "truncation_length", ":", "\n", "            ", "item", "=", "item", "[", ":", "self", ".", "truncation_length", "]", "\n", "", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.shorten_dataset.TruncateDataset.sizes": [[28, 31], ["numpy.minimum"], "methods", ["None"], ["", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "minimum", "(", "self", ".", "dataset", ".", "sizes", ",", "self", ".", "truncation_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.shorten_dataset.TruncateDataset.__len__": [[32, 34], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.shorten_dataset.RandomCropDataset.__init__": [[39, 43], ["shorten_dataset.TruncateDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "dataset", ",", "truncation_length", ",", "seed", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ",", "truncation_length", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "epoch", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.shorten_dataset.RandomCropDataset.can_reuse_epoch_itr_across_epochs": [[44, 47], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "can_reuse_epoch_itr_across_epochs", "(", "self", ")", ":", "\n", "        ", "return", "True", "# only the crop changes, not item sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.shorten_dataset.RandomCropDataset.set_epoch": [[48, 51], ["super().set_epoch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ",", "**", "unused", ")", ":", "\n", "        ", "super", "(", ")", ".", "set_epoch", "(", "epoch", ")", "\n", "self", ".", "epoch", "=", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.shorten_dataset.RandomCropDataset.__getitem__": [[52, 61], ["fairseq.data.data_utils.numpy_seed", "item.size", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils.numpy_seed", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "with", "data_utils", ".", "numpy_seed", "(", "self", ".", "seed", ",", "self", ".", "epoch", ",", "index", ")", ":", "\n", "            ", "item", "=", "self", ".", "dataset", "[", "index", "]", "\n", "item_len", "=", "item", ".", "size", "(", "0", ")", "\n", "excess", "=", "item_len", "-", "self", ".", "truncation_length", "\n", "if", "excess", ">", "0", ":", "\n", "                ", "start_idx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "excess", ")", "\n", "item", "=", "item", "[", "start_idx", ":", "start_idx", "+", "self", ".", "truncation_length", "]", "\n", "", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.shorten_dataset.maybe_shorten_dataset": [[63, 79], ["shorten_dataset.TruncateDataset", "shorten_data_split_list.split", "len", "shorten_dataset.RandomCropDataset"], "function", ["None"], ["", "", "", "def", "maybe_shorten_dataset", "(", "\n", "dataset", ",", "\n", "split", ",", "\n", "shorten_data_split_list", ",", "\n", "shorten_method", ",", "\n", "tokens_per_sample", ",", "\n", "seed", ",", "\n", ")", ":", "\n", "    ", "truncate_split", "=", "(", "\n", "split", "in", "shorten_data_split_list", ".", "split", "(", "\",\"", ")", "or", "len", "(", "shorten_data_split_list", ")", "==", "0", "\n", ")", "\n", "if", "shorten_method", "==", "\"truncate\"", "and", "truncate_split", ":", "\n", "        ", "dataset", "=", "TruncateDataset", "(", "dataset", ",", "tokens_per_sample", ")", "\n", "", "elif", "shorten_method", "==", "\"random_crop\"", "and", "truncate_split", ":", "\n", "        ", "dataset", "=", "RandomCropDataset", "(", "dataset", ",", "tokens_per_sample", ",", "seed", ")", "\n", "", "return", "dataset", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.prepend_dataset.PrependDataset.__init__": [[13, 17], ["BaseWrapperDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "prepend_getter", ",", "ensure_first_token_is", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ")", "\n", "self", ".", "prepend_getter", "=", "prepend_getter", "\n", "self", ".", "ensure_first_token", "=", "ensure_first_token_is", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.prepend_dataset.PrependDataset.__getitem__": [[18, 29], ["isinstance", "prepend_dataset.PrependDataset.prepend_getter", "isinstance", "tuple"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "item", "=", "self", ".", "dataset", "[", "idx", "]", "\n", "is_tuple", "=", "isinstance", "(", "item", ",", "tuple", ")", "\n", "src", "=", "item", "[", "0", "]", "if", "is_tuple", "else", "item", "\n", "\n", "assert", "self", ".", "ensure_first_token", "is", "None", "or", "src", "[", "0", "]", "==", "self", ".", "ensure_first_token", "\n", "prepend_idx", "=", "self", ".", "prepend_getter", "(", "self", ".", "dataset", ",", "idx", ")", "\n", "assert", "isinstance", "(", "prepend_idx", ",", "int", ")", "\n", "src", "[", "0", "]", "=", "prepend_idx", "\n", "item", "=", "tuple", "(", "(", "src", ",", ")", "+", "item", "[", "1", ":", "]", ")", "if", "is_tuple", "else", "src", "\n", "return", "item", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.round_robin_zip_datasets.RoundRobinZipDatasets.__init__": [[26, 41], ["FairseqDataset.__init__", "isinstance", "datasets.items", "isinstance", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "self", ",", "datasets", ",", "eval_key", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "datasets", ",", "OrderedDict", ")", "\n", "self", ".", "datasets", "=", "datasets", "\n", "self", ".", "eval_key", "=", "eval_key", "\n", "\n", "self", ".", "longest_dataset", "=", "None", "\n", "self", ".", "longest_dataset_key", "=", "None", "\n", "for", "key", ",", "dataset", "in", "datasets", ".", "items", "(", ")", ":", "\n", "            ", "assert", "isinstance", "(", "dataset", ",", "FairseqDataset", ")", "\n", "if", "self", ".", "longest_dataset", "is", "None", "or", "len", "(", "dataset", ")", ">", "len", "(", "self", ".", "longest_dataset", ")", ":", "\n", "                ", "self", ".", "longest_dataset", "=", "dataset", "\n", "self", ".", "longest_dataset_key", "=", "key", "\n", "\n", "", "", "self", ".", "_ordered_indices", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.round_robin_zip_datasets.RoundRobinZipDatasets._map_index": [[42, 47], ["len"], "methods", ["None"], ["", "def", "_map_index", "(", "self", ",", "key", ",", "index", ")", ":", "\n", "        ", "assert", "(", "\n", "self", ".", "_ordered_indices", "is", "not", "None", "\n", ")", ",", "\"Must call RoundRobinZipDatasets.ordered_indices() first\"", "\n", "return", "self", ".", "_ordered_indices", "[", "key", "]", "[", "index", "%", "len", "(", "self", ".", "datasets", "[", "key", "]", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.round_robin_zip_datasets.RoundRobinZipDatasets.__getitem__": [[48, 59], ["collections.OrderedDict", "round_robin_zip_datasets.RoundRobinZipDatasets._map_index", "round_robin_zip_datasets.RoundRobinZipDatasets.datasets.items", "round_robin_zip_datasets.RoundRobinZipDatasets._map_index"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset._map_index", "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset._map_index"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "self", ".", "eval_key", "is", "None", ":", "\n", "            ", "return", "OrderedDict", "(", "\n", "[", "\n", "(", "key", ",", "dataset", "[", "self", ".", "_map_index", "(", "key", ",", "index", ")", "]", ")", "\n", "for", "key", ",", "dataset", "in", "self", ".", "datasets", ".", "items", "(", ")", "\n", "]", "\n", ")", "\n", "", "else", ":", "\n", "# at evaluation time it's useful to pass-through batches from a single key", "\n", "            ", "return", "self", ".", "datasets", "[", "self", ".", "eval_key", "]", "[", "self", ".", "_map_index", "(", "self", ".", "eval_key", ",", "index", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.round_robin_zip_datasets.RoundRobinZipDatasets.__len__": [[60, 62], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "longest_dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.round_robin_zip_datasets.RoundRobinZipDatasets.collater": [[63, 77], ["len", "collections.OrderedDict", "round_robin_zip_datasets.RoundRobinZipDatasets.datasets[].collater", "dataset.collater", "round_robin_zip_datasets.RoundRobinZipDatasets.datasets.items"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.collater", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.collater"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"Merge a list of samples to form a mini-batch.\"\"\"", "\n", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "", "if", "self", ".", "eval_key", "is", "None", ":", "\n", "            ", "return", "OrderedDict", "(", "\n", "[", "\n", "(", "key", ",", "dataset", ".", "collater", "(", "[", "sample", "[", "key", "]", "for", "sample", "in", "samples", "]", ")", ")", "\n", "for", "key", ",", "dataset", "in", "self", ".", "datasets", ".", "items", "(", ")", "\n", "]", "\n", ")", "\n", "", "else", ":", "\n", "# at evaluation time it's useful to pass-through batches from a single key", "\n", "            ", "return", "self", ".", "datasets", "[", "self", ".", "eval_key", "]", ".", "collater", "(", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.round_robin_zip_datasets.RoundRobinZipDatasets.num_tokens": [[78, 84], ["max", "dataset.num_tokens", "round_robin_zip_datasets.RoundRobinZipDatasets._map_index", "round_robin_zip_datasets.RoundRobinZipDatasets.datasets.items"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.num_tokens", "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset._map_index"], ["", "", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return an example's length (number of tokens), used for batching.\"\"\"", "\n", "# TODO make it configurable whether to use max() or sum() here", "\n", "return", "max", "(", "\n", "dataset", ".", "num_tokens", "(", "self", ".", "_map_index", "(", "key", ",", "index", ")", ")", "\n", "for", "key", ",", "dataset", "in", "self", ".", "datasets", ".", "items", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.round_robin_zip_datasets.RoundRobinZipDatasets.size": [[86, 92], ["dataset.size", "round_robin_zip_datasets.RoundRobinZipDatasets._map_index", "round_robin_zip_datasets.RoundRobinZipDatasets.datasets.items"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset._map_index"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return an example's size as a float or tuple. This value is used when\n        filtering a dataset with ``--max-positions``.\"\"\"", "\n", "return", "{", "\n", "key", ":", "dataset", ".", "size", "(", "self", ".", "_map_index", "(", "key", ",", "index", ")", ")", "\n", "for", "key", ",", "dataset", "in", "self", ".", "datasets", ".", "items", "(", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.round_robin_zip_datasets.RoundRobinZipDatasets.ordered_indices": [[94, 107], ["numpy.arange", "collections.OrderedDict", "len", "dataset.ordered_indices", "round_robin_zip_datasets.RoundRobinZipDatasets.datasets.items"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.ordered_indices"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "\"\"\"Ordered indices for batching.\"\"\"", "\n", "if", "self", ".", "_ordered_indices", "is", "None", ":", "\n", "# Call the underlying dataset's ordered_indices() here, so that we", "\n", "# get the same random ordering as we would have from using the", "\n", "# underlying dataset directly.", "\n", "            ", "self", ".", "_ordered_indices", "=", "OrderedDict", "(", "\n", "[", "\n", "(", "key", ",", "dataset", ".", "ordered_indices", "(", ")", ")", "\n", "for", "key", ",", "dataset", "in", "self", ".", "datasets", ".", "items", "(", ")", "\n", "]", "\n", ")", "\n", "", "return", "np", ".", "arange", "(", "len", "(", "self", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.round_robin_zip_datasets.RoundRobinZipDatasets.supports_prefetch": [[108, 113], ["all", "getattr", "round_robin_zip_datasets.RoundRobinZipDatasets.datasets.values"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "all", "(", "\n", "getattr", "(", "dataset", ",", "\"supports_prefetch\"", ",", "False", ")", "\n", "for", "dataset", "in", "self", ".", "datasets", ".", "values", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.round_robin_zip_datasets.RoundRobinZipDatasets.prefetch": [[115, 118], ["round_robin_zip_datasets.RoundRobinZipDatasets.datasets.items", "dataset.prefetch", "round_robin_zip_datasets.RoundRobinZipDatasets._map_index"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch", "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset._map_index"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "for", "key", ",", "dataset", "in", "self", ".", "datasets", ".", "items", "(", ")", ":", "\n", "            ", "dataset", ".", "prefetch", "(", "[", "self", ".", "_map_index", "(", "key", ",", "index", ")", "for", "index", "in", "indices", "]", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.__init__": [[113, 175], ["vocab.eos", "denoising_dataset.DenoisingDataset.vocab.eos", "denoising_dataset.DenoisingDataset.vocab.index", "ValueError", "ValueError", "ValueError", "math.exp", "range", "torch.FloatTensor", "torch.distributions.Categorical", "torch.FloatTensor.append"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.index"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "sizes", ",", "\n", "vocab", ",", "\n", "mask_idx", ",", "\n", "mask_whole_words", ",", "\n", "shuffle", ",", "\n", "seed", ",", "\n", "args", ",", "\n", "eos", "=", "None", ",", "\n", "item_transform_func", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "\n", "self", ".", "sizes", "=", "sizes", "\n", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "mask_idx", "=", "mask_idx", "\n", "self", ".", "mask_whole_word", "=", "mask_whole_words", "\n", "self", ".", "mask_ratio", "=", "args", ".", "mask", "\n", "self", ".", "random_ratio", "=", "args", ".", "mask_random", "\n", "self", ".", "insert_ratio", "=", "args", ".", "insert", "\n", "self", ".", "rotate_ratio", "=", "args", ".", "rotate", "\n", "self", ".", "permute_sentence_ratio", "=", "args", ".", "permute_sentences", "\n", "self", ".", "eos", "=", "eos", "if", "eos", "is", "not", "None", "else", "vocab", ".", "eos", "(", ")", "\n", "self", ".", "item_transform_func", "=", "item_transform_func", "\n", "\n", "if", "args", ".", "bpe", "!=", "\"gpt2\"", ":", "\n", "            ", "self", ".", "full_stop_index", "=", "self", ".", "vocab", ".", "eos", "(", ")", "\n", "", "else", ":", "\n", "            ", "assert", "args", ".", "bpe", "==", "\"gpt2\"", "\n", "self", ".", "full_stop_index", "=", "self", ".", "vocab", ".", "index", "(", "\"13\"", ")", "\n", "\n", "", "self", ".", "replace_length", "=", "args", ".", "replace_length", "\n", "if", "self", ".", "replace_length", "not", "in", "[", "-", "1", ",", "0", ",", "1", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f\"invalid arg: replace_length={self.replace_length}\"", ")", "\n", "", "if", "args", ".", "mask_length", "not", "in", "[", "\"subword\"", ",", "\"word\"", ",", "\"span-poisson\"", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f\"invalid arg: mask-length={args.mask_length}\"", ")", "\n", "", "if", "args", ".", "mask_length", "==", "\"subword\"", "and", "args", ".", "replace_length", "not", "in", "[", "0", ",", "1", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f\"if using subwords, use replace-length=1 or 0\"", ")", "\n", "\n", "", "self", ".", "mask_span_distribution", "=", "None", "\n", "if", "args", ".", "mask_length", "==", "\"span-poisson\"", ":", "\n", "            ", "_lambda", "=", "args", ".", "poisson_lambda", "\n", "\n", "lambda_to_the_k", "=", "1", "\n", "e_to_the_minus_lambda", "=", "math", ".", "exp", "(", "-", "_lambda", ")", "\n", "k_factorial", "=", "1", "\n", "ps", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "0", ",", "128", ")", ":", "\n", "                ", "ps", ".", "append", "(", "e_to_the_minus_lambda", "*", "lambda_to_the_k", "/", "k_factorial", ")", "\n", "lambda_to_the_k", "*=", "_lambda", "\n", "k_factorial", "*=", "k", "+", "1", "\n", "if", "ps", "[", "-", "1", "]", "<", "0.0000001", ":", "\n", "                    ", "break", "\n", "", "", "ps", "=", "torch", ".", "FloatTensor", "(", "ps", ")", "\n", "self", ".", "mask_span_distribution", "=", "torch", ".", "distributions", ".", "Categorical", "(", "ps", ")", "\n", "\n", "", "self", ".", "epoch", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.can_reuse_epoch_itr_across_epochs": [[176, 179], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "can_reuse_epoch_itr_across_epochs", "(", "self", ")", ":", "\n", "        ", "return", "True", "# only the noise changes, not item sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.set_epoch": [[180, 182], ["None"], "methods", ["None"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ",", "**", "unused", ")", ":", "\n", "        ", "self", ".", "epoch", "=", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.__getitem__": [[183, 213], ["data_utils.numpy_seed", "denoising_dataset.DenoisingDataset.item_transform_func", "denoising_dataset.DenoisingDataset.vocab.bos", "tokens.clone", "denoising_dataset.DenoisingDataset.permute_sentences", "denoising_dataset.DenoisingDataset.add_whole_word_mask", "denoising_dataset.DenoisingDataset.add_insertion_noise", "denoising_dataset.DenoisingDataset.add_rolling_noise", "numpy.random.random", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils.numpy_seed", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.permute_sentences", "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.add_whole_word_mask", "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.add_insertion_noise", "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.add_rolling_noise"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "with", "data_utils", ".", "numpy_seed", "(", "self", ".", "seed", ",", "self", ".", "epoch", ",", "index", ")", ":", "\n", "            ", "tokens", "=", "self", ".", "dataset", "[", "index", "]", "\n", "assert", "tokens", "[", "-", "1", "]", "==", "self", ".", "eos", "\n", "source", ",", "target", "=", "tokens", ",", "tokens", ".", "clone", "(", ")", "\n", "\n", "if", "self", ".", "permute_sentence_ratio", ">", "0.0", ":", "\n", "                ", "source", "=", "self", ".", "permute_sentences", "(", "source", ",", "self", ".", "permute_sentence_ratio", ")", "\n", "\n", "", "if", "self", ".", "mask_ratio", ">", "0", ":", "\n", "                ", "source", "=", "self", ".", "add_whole_word_mask", "(", "source", ",", "self", ".", "mask_ratio", ")", "\n", "\n", "", "if", "self", ".", "insert_ratio", ">", "0", ":", "\n", "                ", "source", "=", "self", ".", "add_insertion_noise", "(", "source", ",", "self", ".", "insert_ratio", ")", "\n", "\n", "", "if", "self", ".", "rotate_ratio", ">", "0.0", "and", "np", ".", "random", ".", "random", "(", ")", "<", "self", ".", "rotate_ratio", ":", "\n", "                ", "source", "=", "self", ".", "add_rolling_noise", "(", "source", ")", "\n", "# there can additional changes to make:", "\n", "", "", "if", "self", ".", "item_transform_func", "is", "not", "None", ":", "\n", "            ", "source", ",", "target", "=", "self", ".", "item_transform_func", "(", "source", ",", "target", ")", "\n", "\n", "", "assert", "(", "source", ">=", "0", ")", ".", "all", "(", ")", "\n", "assert", "(", "source", "[", "1", ":", "-", "1", "]", ">=", "1", ")", ".", "all", "(", ")", "\n", "assert", "(", "source", "<=", "len", "(", "self", ".", "vocab", ")", ")", ".", "all", "(", ")", "\n", "assert", "source", "[", "0", "]", "==", "self", ".", "vocab", ".", "bos", "(", ")", "\n", "assert", "source", "[", "-", "1", "]", "==", "self", ".", "eos", "\n", "return", "{", "\n", "\"id\"", ":", "index", ",", "\n", "\"source\"", ":", "source", ",", "\n", "\"target\"", ":", "target", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.__len__": [[215, 217], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.permute_sentences": [[218, 240], ["source.clone", "sentence_ends.size", "math.ceil", "torch.arange", "torch.randperm", "sentence.size", "torch.randperm", "sentence.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "permute_sentences", "(", "self", ",", "source", ",", "p", "=", "1.0", ")", ":", "\n", "        ", "full_stops", "=", "source", "==", "self", ".", "full_stop_index", "\n", "# Pretend it ends with a full stop so last span is a sentence", "\n", "full_stops", "[", "-", "2", "]", "=", "1", "\n", "\n", "# Tokens that are full stops, where the previous token is not", "\n", "sentence_ends", "=", "(", "full_stops", "[", "1", ":", "]", "*", "~", "full_stops", "[", ":", "-", "1", "]", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", "+", "2", "\n", "result", "=", "source", ".", "clone", "(", ")", "\n", "\n", "num_sentences", "=", "sentence_ends", ".", "size", "(", "0", ")", "\n", "num_to_permute", "=", "math", ".", "ceil", "(", "(", "num_sentences", "*", "2", "*", "p", ")", "/", "2.0", ")", "\n", "substitutions", "=", "torch", ".", "randperm", "(", "num_sentences", ")", "[", ":", "num_to_permute", "]", "\n", "ordering", "=", "torch", ".", "arange", "(", "0", ",", "num_sentences", ")", "\n", "ordering", "[", "substitutions", "]", "=", "substitutions", "[", "torch", ".", "randperm", "(", "num_to_permute", ")", "]", "\n", "\n", "# Ignore <bos> at start", "\n", "index", "=", "1", "\n", "for", "i", "in", "ordering", ":", "\n", "            ", "sentence", "=", "source", "[", "(", "sentence_ends", "[", "i", "-", "1", "]", "if", "i", ">", "0", "else", "1", ")", ":", "sentence_ends", "[", "i", "]", "]", "\n", "result", "[", "index", ":", "index", "+", "sentence", ".", "size", "(", "0", ")", "]", "=", "sentence", "\n", "index", "+=", "sentence", ".", "size", "(", "0", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.word_starts": [[241, 249], ["denoising_dataset.DenoisingDataset.mask_whole_word.gather", "torch.ones", "source.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "word_starts", "(", "self", ",", "source", ")", ":", "\n", "        ", "if", "self", ".", "mask_whole_word", "is", "not", "None", ":", "\n", "            ", "is_word_start", "=", "self", ".", "mask_whole_word", ".", "gather", "(", "0", ",", "source", ")", "\n", "", "else", ":", "\n", "            ", "is_word_start", "=", "torch", ".", "ones", "(", "source", ".", "size", "(", ")", ")", "\n", "", "is_word_start", "[", "0", "]", "=", "0", "\n", "is_word_start", "[", "-", "1", "]", "=", "0", "\n", "return", "is_word_start", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.add_whole_word_mask": [[250, 356], ["denoising_dataset.DenoisingDataset.word_starts", "int", "denoising_dataset.DenoisingDataset.nonzero", "word_starts[].squeeze", "denoising_dataset.DenoisingDataset.size", "torch.ones", "math.ceil", "denoising_dataset.DenoisingDataset.mask_span_distribution.sample", "torch.cumsum", "torch.ones().long", "torch.FloatTensor().uniform_", "torch.randint", "denoising_dataset.DenoisingDataset.add_insertion_noise", "torch.cat", "torch.cumsum", "torch.cat.size", "denoising_dataset.DenoisingDataset.add_insertion_noise", "len", "len", "torch.cat.size", "word_starts[].squeeze.size", "word_starts[].squeeze.size", "is_word_start[].long", "word_starts[].squeeze.size", "denoising_dataset.DenoisingDataset.float().sum", "torch.ones", "torch.FloatTensor", "torch.cat.size", "torch.cat.size", "word_starts[].squeeze.size", "torch.randint", "torch.randint", "denoising_dataset.DenoisingDataset.size", "denoising_dataset.DenoisingDataset.mask_span_distribution.sample", "denoising_dataset.DenoisingDataset.size", "mask_random.sum", "len", "len", "denoising_dataset.DenoisingDataset.float", "torch.randperm", "denoising_dataset.DenoisingDataset.nonzero.size", "mask_random.sum", "mask_random.sum"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.word_starts", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.sample", "home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.cumsum", "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.add_insertion_noise", "home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.cumsum", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.add_insertion_noise", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.sample", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "add_whole_word_mask", "(", "self", ",", "source", ",", "p", ")", ":", "\n", "        ", "is_word_start", "=", "self", ".", "word_starts", "(", "source", ")", "\n", "num_to_mask", "=", "int", "(", "math", ".", "ceil", "(", "is_word_start", ".", "float", "(", ")", ".", "sum", "(", ")", "*", "p", ")", ")", "\n", "num_inserts", "=", "0", "\n", "if", "num_to_mask", "==", "0", ":", "\n", "            ", "return", "source", "\n", "\n", "", "if", "self", ".", "mask_span_distribution", "is", "not", "None", ":", "\n", "            ", "lengths", "=", "self", ".", "mask_span_distribution", ".", "sample", "(", "sample_shape", "=", "(", "num_to_mask", ",", ")", ")", "\n", "\n", "# Make sure we have enough to mask", "\n", "cum_length", "=", "torch", ".", "cumsum", "(", "lengths", ",", "0", ")", "\n", "while", "cum_length", "[", "-", "1", "]", "<", "num_to_mask", ":", "\n", "                ", "lengths", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "lengths", ",", "\n", "self", ".", "mask_span_distribution", ".", "sample", "(", "sample_shape", "=", "(", "num_to_mask", ",", ")", ")", ",", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "cum_length", "=", "torch", ".", "cumsum", "(", "lengths", ",", "0", ")", "\n", "\n", "# Trim to masking budget", "\n", "", "i", "=", "0", "\n", "while", "cum_length", "[", "i", "]", "<", "num_to_mask", ":", "\n", "                ", "i", "+=", "1", "\n", "", "lengths", "[", "i", "]", "=", "num_to_mask", "-", "(", "0", "if", "i", "==", "0", "else", "cum_length", "[", "i", "-", "1", "]", ")", "\n", "num_to_mask", "=", "i", "+", "1", "\n", "lengths", "=", "lengths", "[", ":", "num_to_mask", "]", "\n", "\n", "# Handle 0-length mask (inserts) separately", "\n", "lengths", "=", "lengths", "[", "lengths", ">", "0", "]", "\n", "num_inserts", "=", "num_to_mask", "-", "lengths", ".", "size", "(", "0", ")", "\n", "num_to_mask", "-=", "num_inserts", "\n", "if", "num_to_mask", "==", "0", ":", "\n", "                ", "return", "self", ".", "add_insertion_noise", "(", "source", ",", "num_inserts", "/", "source", ".", "size", "(", "0", ")", ")", "\n", "\n", "", "assert", "(", "lengths", ">", "0", ")", ".", "all", "(", ")", "\n", "", "else", ":", "\n", "            ", "lengths", "=", "torch", ".", "ones", "(", "(", "num_to_mask", ",", ")", ")", ".", "long", "(", ")", "\n", "", "assert", "is_word_start", "[", "-", "1", "]", "==", "0", "\n", "word_starts", "=", "is_word_start", ".", "nonzero", "(", "as_tuple", "=", "False", ")", "\n", "indices", "=", "word_starts", "[", "\n", "torch", ".", "randperm", "(", "word_starts", ".", "size", "(", "0", ")", ")", "[", ":", "num_to_mask", "]", "\n", "]", ".", "squeeze", "(", "1", ")", "\n", "mask_random", "=", "torch", ".", "FloatTensor", "(", "num_to_mask", ")", ".", "uniform_", "(", ")", "<", "self", ".", "random_ratio", "\n", "\n", "source_length", "=", "source", ".", "size", "(", "0", ")", "\n", "assert", "source_length", "-", "1", "not", "in", "indices", "\n", "to_keep", "=", "torch", ".", "ones", "(", "source_length", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "is_word_start", "[", "\n", "-", "1", "\n", "]", "=", "255", "# acts as a long length, so spans don't go over the end of doc", "\n", "if", "self", ".", "replace_length", "==", "0", ":", "\n", "            ", "to_keep", "[", "indices", "]", "=", "0", "\n", "", "else", ":", "\n", "# keep index, but replace it with [MASK]", "\n", "            ", "source", "[", "indices", "]", "=", "self", ".", "mask_idx", "\n", "source", "[", "indices", "[", "mask_random", "]", "]", "=", "torch", ".", "randint", "(", "\n", "1", ",", "len", "(", "self", ".", "vocab", ")", ",", "size", "=", "(", "mask_random", ".", "sum", "(", ")", ",", ")", "\n", ")", "\n", "\n", "", "if", "self", ".", "mask_span_distribution", "is", "not", "None", ":", "\n", "            ", "assert", "len", "(", "lengths", ".", "size", "(", ")", ")", "==", "1", "\n", "assert", "lengths", ".", "size", "(", ")", "==", "indices", ".", "size", "(", ")", "\n", "lengths", "-=", "1", "\n", "while", "indices", ".", "size", "(", "0", ")", ">", "0", ":", "\n", "                ", "assert", "lengths", ".", "size", "(", ")", "==", "indices", ".", "size", "(", ")", "\n", "lengths", "-=", "is_word_start", "[", "indices", "+", "1", "]", ".", "long", "(", ")", "\n", "uncompleted", "=", "lengths", ">=", "0", "\n", "indices", "=", "indices", "[", "uncompleted", "]", "+", "1", "\n", "mask_random", "=", "mask_random", "[", "uncompleted", "]", "\n", "lengths", "=", "lengths", "[", "uncompleted", "]", "\n", "if", "self", ".", "replace_length", "!=", "-", "1", ":", "\n", "# delete token", "\n", "                    ", "to_keep", "[", "indices", "]", "=", "0", "\n", "", "else", ":", "\n", "# keep index, but replace it with [MASK]", "\n", "                    ", "source", "[", "indices", "]", "=", "self", ".", "mask_idx", "\n", "source", "[", "indices", "[", "mask_random", "]", "]", "=", "torch", ".", "randint", "(", "\n", "1", ",", "len", "(", "self", ".", "vocab", ")", ",", "size", "=", "(", "mask_random", ".", "sum", "(", ")", ",", ")", "\n", ")", "\n", "", "", "", "else", ":", "\n", "# A bit faster when all lengths are 1", "\n", "            ", "while", "indices", ".", "size", "(", "0", ")", ">", "0", ":", "\n", "                ", "uncompleted", "=", "is_word_start", "[", "indices", "+", "1", "]", "==", "0", "\n", "indices", "=", "indices", "[", "uncompleted", "]", "+", "1", "\n", "mask_random", "=", "mask_random", "[", "uncompleted", "]", "\n", "if", "self", ".", "replace_length", "!=", "-", "1", ":", "\n", "# delete token", "\n", "                    ", "to_keep", "[", "indices", "]", "=", "0", "\n", "", "else", ":", "\n", "# keep index, but replace it with [MASK]", "\n", "                    ", "source", "[", "indices", "]", "=", "self", ".", "mask_idx", "\n", "source", "[", "indices", "[", "mask_random", "]", "]", "=", "torch", ".", "randint", "(", "\n", "1", ",", "len", "(", "self", ".", "vocab", ")", ",", "size", "=", "(", "mask_random", ".", "sum", "(", ")", ",", ")", "\n", ")", "\n", "\n", "", "assert", "source_length", "-", "1", "not", "in", "indices", "\n", "\n", "", "", "source", "=", "source", "[", "to_keep", "]", "\n", "\n", "if", "num_inserts", ">", "0", ":", "\n", "            ", "source", "=", "self", ".", "add_insertion_noise", "(", "source", ",", "num_inserts", "/", "source", ".", "size", "(", "0", ")", ")", "\n", "\n", "", "return", "source", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.add_permuted_noise": [[357, 363], ["len", "math.ceil", "torch.randperm", "torch.randperm"], "methods", ["None"], ["", "def", "add_permuted_noise", "(", "self", ",", "tokens", ",", "p", ")", ":", "\n", "        ", "num_words", "=", "len", "(", "tokens", ")", "\n", "num_to_permute", "=", "math", ".", "ceil", "(", "(", "(", "num_words", "*", "2", ")", "*", "p", ")", "/", "2.0", ")", "\n", "substitutions", "=", "torch", ".", "randperm", "(", "num_words", "-", "2", ")", "[", ":", "num_to_permute", "]", "+", "1", "\n", "tokens", "[", "substitutions", "]", "=", "tokens", "[", "substitutions", "[", "torch", ".", "randperm", "(", "num_to_permute", ")", "]", "]", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.add_rolling_noise": [[364, 371], ["numpy.random.randint", "torch.cat", "max", "torch.cat.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "add_rolling_noise", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "offset", "=", "np", ".", "random", ".", "randint", "(", "1", ",", "max", "(", "1", ",", "tokens", ".", "size", "(", "-", "1", ")", "-", "1", ")", "+", "1", ")", "\n", "tokens", "=", "torch", ".", "cat", "(", "\n", "(", "tokens", "[", "0", ":", "1", "]", ",", "tokens", "[", "offset", ":", "-", "1", "]", ",", "tokens", "[", "1", ":", "offset", "]", ",", "tokens", "[", "-", "1", ":", "]", ")", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.add_insertion_noise": [[372, 394], ["len", "int", "torch.zeros", "torch.LongTensor().fill_", "int", "torch.randint", "math.ceil", "math.ceil", "torch.randperm", "torch.LongTensor", "len", "len"], "methods", ["None"], ["", "def", "add_insertion_noise", "(", "self", ",", "tokens", ",", "p", ")", ":", "\n", "        ", "if", "p", "==", "0.0", ":", "\n", "            ", "return", "tokens", "\n", "\n", "", "num_tokens", "=", "len", "(", "tokens", ")", "\n", "n", "=", "int", "(", "math", ".", "ceil", "(", "num_tokens", "*", "p", ")", ")", "\n", "\n", "noise_indices", "=", "torch", ".", "randperm", "(", "num_tokens", "+", "n", "-", "2", ")", "[", ":", "n", "]", "+", "1", "\n", "noise_mask", "=", "torch", ".", "zeros", "(", "size", "=", "(", "num_tokens", "+", "n", ",", ")", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "noise_mask", "[", "noise_indices", "]", "=", "1", "\n", "result", "=", "torch", ".", "LongTensor", "(", "n", "+", "len", "(", "tokens", ")", ")", ".", "fill_", "(", "-", "1", ")", "\n", "\n", "num_random", "=", "int", "(", "math", ".", "ceil", "(", "n", "*", "self", ".", "random_ratio", ")", ")", "\n", "result", "[", "noise_indices", "[", "num_random", ":", "]", "]", "=", "self", ".", "mask_idx", "\n", "result", "[", "noise_indices", "[", ":", "num_random", "]", "]", "=", "torch", ".", "randint", "(", "\n", "low", "=", "1", ",", "high", "=", "len", "(", "self", ".", "vocab", ")", ",", "size", "=", "(", "num_random", ",", ")", "\n", ")", "\n", "\n", "result", "[", "~", "noise_mask", "]", "=", "tokens", "\n", "\n", "assert", "(", "result", ">=", "0", ")", ".", "all", "(", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.collater": [[395, 404], ["denoising_dataset.collate", "denoising_dataset.DenoisingDataset.vocab.pad"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.collate", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["", "def", "collater", "(", "self", ",", "samples", ",", "pad_to_length", "=", "None", ")", ":", "\n", "        ", "\"\"\"Merge a list of samples to form a mini-batch.\n        Args:\n            samples (List[dict]): samples to collate\n        Returns:\n            dict: a mini-batch of data\n        \"\"\"", "\n", "return", "collate", "(", "\n", "samples", ",", "self", ".", "vocab", ".", "pad", "(", ")", ",", "self", ".", "eos", ",", "self", ".", "vocab", ",", "pad_to_length", "=", "pad_to_length", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.num_tokens": [[406, 410], ["None"], "methods", ["None"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return the number of tokens in a sample. This value is used to\n        enforce ``--max-tokens`` during batching.\"\"\"", "\n", "return", "self", ".", "sizes", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.size": [[411, 415], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return an example's size as a float or tuple. This value is used when\n        filtering a dataset with ``--max-positions``.\"\"\"", "\n", "return", "self", ".", "sizes", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.ordered_indices": [[416, 424], ["numpy.random.permutation", "numpy.arange", "len", "len", "numpy.argsort"], "methods", ["None"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return an ordered list of indices. Batches will be constructed based\n        on this order.\"\"\"", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "indices", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ")", ")", "\n", "", "else", ":", "\n", "            ", "indices", "=", "np", ".", "arange", "(", "len", "(", "self", ")", ")", "\n", "", "return", "indices", "[", "np", ".", "argsort", "(", "self", ".", "sizes", "[", "indices", "]", ",", "kind", "=", "\"mergesort\"", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.prefetch": [[425, 428], ["denoising_dataset.DenoisingDataset.src.prefetch", "denoising_dataset.DenoisingDataset.tgt.prefetch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "self", ".", "src", ".", "prefetch", "(", "indices", ")", "\n", "self", ".", "tgt", ".", "prefetch", "(", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.DenoisingDataset.supports_prefetch": [[429, 436], ["hasattr", "hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "hasattr", "(", "self", ".", "src", ",", "\"supports_prefetch\"", ")", "\n", "and", "self", ".", "src", ".", "supports_prefetch", "\n", "and", "hasattr", "(", "self", ".", "tgt", ",", "\"supports_prefetch\"", ")", "\n", "and", "self", ".", "tgt", ".", "supports_prefetch", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.denoising_dataset.collate": [[14, 93], ["torch.LongTensor", "denoising_dataset.collate.merge"], "function", ["None"], ["def", "collate", "(", "\n", "samples", ",", "\n", "pad_idx", ",", "\n", "eos_idx", ",", "\n", "vocab", ",", "\n", "left_pad_source", "=", "False", ",", "\n", "left_pad_target", "=", "False", ",", "\n", "input_feeding", "=", "True", ",", "\n", "pad_to_length", "=", "None", ",", "\n", ")", ":", "\n", "    ", "assert", "input_feeding", "\n", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "        ", "return", "{", "}", "\n", "\n", "", "def", "merge", "(", "key", ",", "left_pad", ",", "move_eos_to_beginning", "=", "False", ",", "pad_to_length", "=", "None", ")", ":", "\n", "        ", "return", "data_utils", ".", "collate_tokens", "(", "\n", "[", "s", "[", "key", "]", "for", "s", "in", "samples", "]", ",", "\n", "pad_idx", ",", "\n", "eos_idx", "=", "None", ",", "# use eos_idx of each sample instead of vocab.eos()", "\n", "left_pad", "=", "left_pad", ",", "\n", "move_eos_to_beginning", "=", "move_eos_to_beginning", ",", "\n", "pad_to_length", "=", "pad_to_length", ",", "\n", ")", "\n", "\n", "", "id", "=", "torch", ".", "LongTensor", "(", "[", "s", "[", "\"id\"", "]", "for", "s", "in", "samples", "]", ")", "\n", "src_tokens", "=", "merge", "(", "\n", "\"source\"", ",", "\n", "left_pad", "=", "left_pad_source", ",", "\n", "pad_to_length", "=", "pad_to_length", "[", "\"source\"", "]", "if", "pad_to_length", "is", "not", "None", "else", "None", ",", "\n", ")", "\n", "# sort by descending source length", "\n", "src_lengths", "=", "torch", ".", "LongTensor", "(", "[", "s", "[", "\"source\"", "]", ".", "numel", "(", ")", "for", "s", "in", "samples", "]", ")", "\n", "src_lengths", ",", "sort_order", "=", "src_lengths", ".", "sort", "(", "descending", "=", "True", ")", "\n", "id", "=", "id", ".", "index_select", "(", "0", ",", "sort_order", ")", "\n", "src_tokens", "=", "src_tokens", ".", "index_select", "(", "0", ",", "sort_order", ")", "\n", "\n", "prev_output_tokens", "=", "None", "\n", "target", "=", "None", "\n", "if", "samples", "[", "0", "]", ".", "get", "(", "\"target\"", ",", "None", ")", "is", "not", "None", ":", "\n", "        ", "target", "=", "merge", "(", "\n", "\"target\"", ",", "\n", "left_pad", "=", "left_pad_target", ",", "\n", "pad_to_length", "=", "pad_to_length", "[", "\"target\"", "]", "\n", "if", "pad_to_length", "is", "not", "None", "\n", "else", "None", ",", "\n", ")", "\n", "target", "=", "target", ".", "index_select", "(", "0", ",", "sort_order", ")", "\n", "ntokens", "=", "sum", "(", "len", "(", "s", "[", "\"target\"", "]", ")", "for", "s", "in", "samples", ")", "\n", "\n", "if", "input_feeding", ":", "\n", "# we create a shifted version of targets for feeding the", "\n", "# previous output token(s) into the next decoder step", "\n", "            ", "prev_output_tokens", "=", "merge", "(", "\n", "\"target\"", ",", "\n", "left_pad", "=", "left_pad_target", ",", "\n", "move_eos_to_beginning", "=", "True", ",", "\n", "pad_to_length", "=", "pad_to_length", "[", "\"target\"", "]", "\n", "if", "pad_to_length", "is", "not", "None", "\n", "else", "None", ",", "\n", ")", "\n", "prev_output_tokens", "=", "prev_output_tokens", ".", "index_select", "(", "0", ",", "sort_order", ")", "\n", "", "", "else", ":", "\n", "        ", "ntokens", "=", "sum", "(", "len", "(", "s", "[", "\"source\"", "]", ")", "for", "s", "in", "samples", ")", "\n", "\n", "", "batch", "=", "{", "\n", "\"id\"", ":", "id", ",", "\n", "\"ntokens\"", ":", "ntokens", ",", "\n", "\"net_input\"", ":", "{", "\n", "\"src_tokens\"", ":", "src_tokens", ",", "\n", "\"src_lengths\"", ":", "src_lengths", ",", "\n", "}", ",", "\n", "\"target\"", ":", "target", ",", "\n", "\"nsentences\"", ":", "samples", "[", "0", "]", "[", "\"source\"", "]", ".", "size", "(", "0", ")", ",", "\n", "\"sort_order\"", ":", "sort_order", ",", "\n", "}", "\n", "if", "prev_output_tokens", "is", "not", "None", ":", "\n", "        ", "batch", "[", "\"net_input\"", "]", "[", "\"prev_output_tokens\"", "]", "=", "prev_output_tokens", "\n", "\n", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset.__init__": [[40, 67], ["FairseqDataset.__init__", "isinstance", "list", "datasets.values", "len", "len", "datasets.values", "list", "isinstance", "multi_corpus_dataset.MultiCorpusDataset.dataset_offsets.append", "len", "multi_corpus_dataset.MultiCorpusDataset.datasets.values", "type", "type"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "datasets", ":", "Dict", "[", "str", ",", "FairseqDataset", "]", ",", "\n", "distribution", ":", "List", "[", "float", "]", ",", "\n", "seed", ":", "int", ",", "\n", "sort_indices", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "datasets", ",", "OrderedDict", ")", "\n", "assert", "len", "(", "datasets", ")", "==", "len", "(", "distribution", ")", "\n", "self", ".", "datasets", "=", "datasets", "\n", "self", ".", "distribution", "=", "distribution", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "sort_indices", "=", "sort_indices", "\n", "\n", "# Avoid repeated conversions to list later", "\n", "self", ".", "dataset_list", "=", "list", "(", "datasets", ".", "values", "(", ")", ")", "\n", "self", ".", "total_num_instances", "=", "0", "\n", "\n", "first_dataset", "=", "list", "(", "self", ".", "datasets", ".", "values", "(", ")", ")", "[", "0", "]", "\n", "\n", "self", ".", "dataset_offsets", "=", "[", "]", "\n", "for", "dataset", "in", "datasets", ".", "values", "(", ")", ":", "\n", "            ", "assert", "isinstance", "(", "dataset", ",", "FairseqDataset", ")", "\n", "assert", "type", "(", "dataset", ")", "is", "type", "(", "first_dataset", ")", "\n", "self", ".", "dataset_offsets", ".", "append", "(", "self", ".", "total_num_instances", ")", "\n", "self", ".", "total_num_instances", "+=", "len", "(", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset.ordered_indices": [[68, 84], ["fairseq.data.data_utils.numpy_seed", "numpy.array", "numpy.random.permutation", "multi_corpus_dataset.MultiCorpusDataset._sample", "sampled_indices.sort", "len", "multi_corpus_dataset.MultiCorpusDataset.datasets.values", "range", "multi_corpus_dataset.MultiCorpusDataset.num_tokens"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils.numpy_seed", "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset._sample", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.num_tokens"], ["", "", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "with", "data_utils", ".", "numpy_seed", "(", "self", ".", "seed", ",", "self", ".", "epoch", ")", ":", "\n", "# Used to store the order of indices of each dataset to use", "\n", "            ", "indices", "=", "[", "\n", "np", ".", "random", ".", "permutation", "(", "len", "(", "dataset", ")", ")", "\n", "for", "dataset", "in", "self", ".", "datasets", ".", "values", "(", ")", "\n", "]", "\n", "# Keep track of which samples we've  used for each dataset", "\n", "counters", "=", "[", "0", "for", "_", "in", "self", ".", "datasets", "]", "\n", "\n", "sampled_indices", "=", "[", "\n", "self", ".", "_sample", "(", "indices", ",", "counters", ")", "for", "_", "in", "range", "(", "self", ".", "total_num_instances", ")", "\n", "]", "\n", "if", "self", ".", "sort_indices", ":", "\n", "                ", "sampled_indices", ".", "sort", "(", "key", "=", "lambda", "i", ":", "self", ".", "num_tokens", "(", "i", ")", ")", "\n", "", "return", "np", ".", "array", "(", "sampled_indices", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset._sample": [[85, 105], ["numpy.random.choice", "len", "len", "numpy.random.permutation", "len"], "methods", ["None"], ["", "", "def", "_sample", "(", "self", ",", "indices", ",", "counters", ")", ":", "\n", "# First pick dataset", "\n", "        ", "dataset_idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "self", ".", "distribution", ")", ",", "p", "=", "self", ".", "distribution", ")", "\n", "\n", "# Then get dataset internal index", "\n", "idx", "=", "indices", "[", "dataset_idx", "]", "[", "counters", "[", "dataset_idx", "]", "]", "\n", "\n", "# Convert to multi-datasets index", "\n", "idx", "+=", "self", ".", "dataset_offsets", "[", "dataset_idx", "]", "\n", "\n", "counters", "[", "dataset_idx", "]", "+=", "1", "\n", "\n", "# Reset if we reach end", "\n", "if", "counters", "[", "dataset_idx", "]", "==", "len", "(", "self", ".", "dataset_list", "[", "dataset_idx", "]", ")", ":", "\n", "            ", "counters", "[", "dataset_idx", "]", "=", "0", "\n", "indices", "[", "dataset_idx", "]", "=", "np", ".", "random", ".", "permutation", "(", "\n", "len", "(", "self", ".", "dataset_list", "[", "dataset_idx", "]", ")", "\n", ")", "\n", "\n", "", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset._map_index": [[106, 119], ["multi_corpus_dataset.MultiCorpusDataset.datasets.items", "ValueError", "len", "len"], "methods", ["None"], ["", "def", "_map_index", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        If dataset A has length N and dataset B has length M\n        then index 1 maps to index 1 of dataset A, and index N + 1\n        maps to index 1 of B.\n        \"\"\"", "\n", "counter", "=", "0", "\n", "for", "key", ",", "dataset", "in", "self", ".", "datasets", ".", "items", "(", ")", ":", "\n", "            ", "if", "index", "<", "counter", "+", "len", "(", "dataset", ")", ":", "\n", "                ", "return", "index", "-", "counter", ",", "key", "\n", "", "counter", "+=", "len", "(", "dataset", ")", "\n", "", "raise", "ValueError", "(", "\n", "\"Invalid index: {}, max: {}\"", ".", "format", "(", "index", ",", "self", ".", "total_num_instances", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset.__len__": [[121, 126], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Length of this dataset is the sum of individual datasets\n        \"\"\"", "\n", "return", "self", ".", "total_num_instances", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset.__getitem__": [[127, 130], ["multi_corpus_dataset.MultiCorpusDataset._map_index"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset._map_index"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "index", ",", "key", "=", "self", ".", "_map_index", "(", "index", ")", "\n", "return", "self", ".", "datasets", "[", "key", "]", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset.collater": [[131, 140], ["[].collater", "len", "list", "multi_corpus_dataset.MultiCorpusDataset.datasets.values"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.collater"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "\"\"\"\n        Since we enforce all datsets to be the same, collating is just\n        picking the first one and doing collate.\n        \"\"\"", "\n", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "", "return", "list", "(", "self", ".", "datasets", ".", "values", "(", ")", ")", "[", "0", "]", ".", "collater", "(", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset.num_tokens": [[141, 144], ["multi_corpus_dataset.MultiCorpusDataset._map_index", "multi_corpus_dataset.MultiCorpusDataset.datasets[].num_tokens"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset._map_index", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.num_tokens"], ["", "def", "num_tokens", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "index", ",", "key", "=", "self", ".", "_map_index", "(", "index", ")", "\n", "return", "self", ".", "datasets", "[", "key", "]", ".", "num_tokens", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset.size": [[145, 148], ["multi_corpus_dataset.MultiCorpusDataset._map_index", "multi_corpus_dataset.MultiCorpusDataset.datasets[].size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset._map_index", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "size", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "index", ",", "key", "=", "self", ".", "_map_index", "(", "index", ")", "\n", "return", "self", ".", "datasets", "[", "key", "]", ".", "size", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset.can_reuse_epoch_itr_across_epochs": [[149, 152], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "can_reuse_epoch_itr_across_epochs", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset.set_epoch": [[153, 156], ["super().set_epoch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ",", "**", "unused", ")", ":", "\n", "        ", "super", "(", ")", ".", "set_epoch", "(", "epoch", ")", "\n", "self", ".", "epoch", "=", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset.supports_prefetch": [[157, 160], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.multi_corpus_dataset.MultiCorpusDataset.supports_fetch_outside_dataloader": [[161, 166], ["all"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_fetch_outside_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "all", "(", "\n", "self", ".", "datasets", "[", "key", "]", ".", "supports_fetch_outside_dataloader", "\n", "for", "key", "in", "self", ".", "datasets", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.pad_dataset.PadDataset.__init__": [[12, 16], ["BaseWrapperDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "pad_idx", ",", "left_pad", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ")", "\n", "self", ".", "pad_idx", "=", "pad_idx", "\n", "self", ".", "left_pad", "=", "left_pad", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.pad_dataset.PadDataset.collater": [[17, 19], ["fairseq.data.data_utils.collate_tokens"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils.collate_tokens"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "return", "data_utils", ".", "collate_tokens", "(", "samples", ",", "self", ".", "pad_idx", ",", "left_pad", "=", "self", ".", "left_pad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.pad_dataset.LeftPadDataset.__init__": [[22, 24], ["pad_dataset.PadDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "pad_idx", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ",", "pad_idx", ",", "left_pad", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.data.pad_dataset.RightPadDataset.__init__": [[27, 29], ["pad_dataset.PadDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "pad_idx", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ",", "pad_idx", ",", "left_pad", "=", "False", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.MaskedLMDictionary.__init__": [[15, 26], ["fairseq.data.Dictionary.__init__", "masked_lm_dictionary.MaskedLMDictionary.add_symbol", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol"], ["def", "__init__", "(", "\n", "self", ",", "\n", "pad", "=", "\"<pad>\"", ",", "\n", "eos", "=", "\"</s>\"", ",", "\n", "unk", "=", "\"<unk>\"", ",", "\n", "mask", "=", "\"<mask>\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "pad", "=", "pad", ",", "eos", "=", "eos", ",", "unk", "=", "unk", ")", "\n", "self", ".", "mask_word", "=", "mask", "\n", "self", ".", "mask_index", "=", "self", ".", "add_symbol", "(", "mask", ")", "\n", "self", ".", "nspecial", "=", "len", "(", "self", ".", "symbols", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.MaskedLMDictionary.mask": [[27, 30], ["None"], "methods", ["None"], ["", "def", "mask", "(", "self", ")", ":", "\n", "        ", "\"\"\"Helper to get index of mask symbol\"\"\"", "\n", "return", "self", ".", "mask_index", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.__init__": [[38, 53], ["masked_lm_dictionary.MaskedLMDictionary.__init__", "masked_lm_dictionary.BertDictionary.add_symbol", "masked_lm_dictionary.BertDictionary.add_symbol", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol"], ["def", "__init__", "(", "\n", "self", ",", "\n", "pad", "=", "\"<pad>\"", ",", "\n", "eos", "=", "\"</s>\"", ",", "\n", "unk", "=", "\"<unk>\"", ",", "\n", "mask", "=", "\"<mask>\"", ",", "\n", "cls", "=", "\"<cls>\"", ",", "\n", "sep", "=", "\"<sep>\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "pad", "=", "pad", ",", "eos", "=", "eos", ",", "unk", "=", "unk", ",", "mask", "=", "mask", ")", "\n", "self", ".", "cls_word", "=", "cls", "\n", "self", ".", "sep_word", "=", "sep", "\n", "self", ".", "cls_index", "=", "self", ".", "add_symbol", "(", "cls", ")", "\n", "self", ".", "sep_index", "=", "self", ".", "add_symbol", "(", "sep", ")", "\n", "self", ".", "nspecial", "=", "len", "(", "self", ".", "symbols", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls": [[54, 57], ["None"], "methods", ["None"], ["", "def", "cls", "(", "self", ")", ":", "\n", "        ", "\"\"\"Helper to get index of cls symbol\"\"\"", "\n", "return", "self", ".", "cls_index", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.sep": [[58, 61], ["None"], "methods", ["None"], ["", "def", "sep", "(", "self", ")", ":", "\n", "        ", "\"\"\"Helper to get index of sep symbol\"\"\"", "\n", "return", "self", ".", "sep_index", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dataset.MaskedLMDataset.__init__": [[53, 99], ["numpy.array", "isinstance", "isinstance", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ":", "FairseqDataset", ",", "\n", "sizes", ":", "np", ".", "ndarray", ",", "\n", "vocab", ":", "Dictionary", ",", "\n", "pad_idx", ":", "int", ",", "\n", "mask_idx", ":", "int", ",", "\n", "classif_token_idx", ":", "int", ",", "\n", "sep_token_idx", ":", "int", ",", "\n", "seed", ":", "int", "=", "1", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "has_pairs", ":", "bool", "=", "True", ",", "\n", "segment_id", ":", "int", "=", "0", ",", "\n", "masking_ratio", ":", "float", "=", "0.15", ",", "\n", "masking_prob", ":", "float", "=", "0.8", ",", "\n", "random_token_prob", ":", "float", "=", "0.1", ",", "\n", ")", ":", "\n", "# Make sure the input datasets are the ones supported", "\n", "        ", "assert", "(", "\n", "isinstance", "(", "dataset", ",", "TokenBlockDataset", ")", "\n", "or", "isinstance", "(", "dataset", ",", "BlockPairDataset", ")", "\n", "or", "isinstance", "(", "dataset", ",", "ConcatDataset", ")", "\n", ")", ",", "(", "\n", "\"MaskedLMDataset only wraps TokenBlockDataset or BlockPairDataset or \"", "\n", "\"ConcatDataset\"", "\n", ")", "\n", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "sizes", "=", "np", ".", "array", "(", "sizes", ")", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "pad_idx", "=", "pad_idx", "\n", "self", ".", "mask_idx", "=", "mask_idx", "\n", "self", ".", "classif_token_idx", "=", "classif_token_idx", "\n", "self", ".", "sep_token_idx", "=", "sep_token_idx", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "has_pairs", "=", "has_pairs", "\n", "self", ".", "segment_id", "=", "segment_id", "\n", "self", ".", "masking_ratio", "=", "masking_ratio", "\n", "self", ".", "masking_prob", "=", "masking_prob", "\n", "self", ".", "random_token_prob", "=", "random_token_prob", "\n", "\n", "# If we have only one block then sizes needs to be updated to include", "\n", "# the classification token", "\n", "if", "not", "has_pairs", ":", "\n", "            ", "self", ".", "sizes", "=", "self", ".", "sizes", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dataset.MaskedLMDataset.__getitem__": [[100, 112], ["None"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "# if has_pairs, then expect 2 blocks and a sentence target", "\n", "        ", "if", "self", ".", "has_pairs", ":", "\n", "            ", "(", "block_one", ",", "block_two", ",", "sentence_target", ")", "=", "self", ".", "dataset", "[", "index", "]", "\n", "", "else", ":", "\n", "            ", "block_one", "=", "self", ".", "dataset", "[", "index", "]", "\n", "\n", "", "return", "{", "\n", "\"id\"", ":", "index", ",", "\n", "\"block_one\"", ":", "block_one", ",", "\n", "\"block_two\"", ":", "block_two", "if", "self", ".", "has_pairs", "else", "None", ",", "\n", "\"sentence_target\"", ":", "sentence_target", "if", "self", ".", "has_pairs", "else", "None", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dataset.MaskedLMDataset.__len__": [[114, 116], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dataset.MaskedLMDataset._mask_block": [[117, 171], ["numpy.copy", "len", "math.ceil", "numpy.random.choice", "numpy.copy", "range", "numpy.random.random", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.copy", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.copy"], ["", "def", "_mask_block", "(", "\n", "self", ",", "\n", "sentence", ":", "np", ".", "ndarray", ",", "\n", "mask_idx", ":", "int", ",", "\n", "pad_idx", ":", "int", ",", "\n", "dictionary_token_range", ":", "Tuple", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Mask tokens for Masked Language Model training\n        Samples mask_ratio tokens that will be predicted by LM.\n\n        Note:This function may not be efficient enough since we had multiple\n        conversions between np and torch, we can replace them with torch\n        operators later.\n\n        Args:\n            sentence: 1d tensor to be masked\n            mask_idx: index to use for masking the sentence\n            pad_idx: index to use for masking the target for tokens we aren't\n                predicting\n            dictionary_token_range: range of indices in dictionary which can\n                be used for random word replacement\n                (e.g. without special characters)\n        Return:\n            masked_sent: masked sentence\n            target: target with words which we are not predicting replaced\n                by pad_idx\n        \"\"\"", "\n", "masked_sent", "=", "np", ".", "copy", "(", "sentence", ")", "\n", "sent_length", "=", "len", "(", "sentence", ")", "\n", "mask_num", "=", "math", ".", "ceil", "(", "sent_length", "*", "self", ".", "masking_ratio", ")", "\n", "mask", "=", "np", ".", "random", ".", "choice", "(", "sent_length", ",", "mask_num", ",", "replace", "=", "False", ")", "\n", "target", "=", "np", ".", "copy", "(", "sentence", ")", "\n", "\n", "for", "i", "in", "range", "(", "sent_length", ")", ":", "\n", "            ", "if", "i", "in", "mask", ":", "\n", "                ", "rand", "=", "np", ".", "random", ".", "random", "(", ")", "\n", "\n", "# replace with mask if probability is less than masking_prob", "\n", "# (Eg: 0.8)", "\n", "if", "rand", "<", "self", ".", "masking_prob", ":", "\n", "                    ", "masked_sent", "[", "i", "]", "=", "mask_idx", "\n", "\n", "# replace with random token if probability is less than", "\n", "# masking_prob + random_token_prob (Eg: 0.9)", "\n", "", "elif", "rand", "<", "(", "self", ".", "masking_prob", "+", "self", ".", "random_token_prob", ")", ":", "\n", "# sample random token from dictionary", "\n", "                    ", "masked_sent", "[", "i", "]", "=", "np", ".", "random", ".", "randint", "(", "\n", "dictionary_token_range", "[", "0", "]", ",", "dictionary_token_range", "[", "1", "]", "\n", ")", "\n", "", "", "else", ":", "\n", "                ", "target", "[", "i", "]", "=", "pad_idx", "\n", "\n", "", "", "return", "masked_sent", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dataset.MaskedLMDataset._collate": [[172, 259], ["len", "fairseq.data.data_utils.numpy_seed", "fairseq.data.data_utils.collate_tokens", "torch.LongTensor", "sum", "masked_lm_dataset.MaskedLMDataset._collate.merge"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils.numpy_seed", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.collate_tokens"], ["", "def", "_collate", "(", "self", ",", "samples", ":", "List", "[", "Dict", "]", ",", "pad_idx", ":", "int", ",", "eos_idx", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Does the heavy lifting for creating a batch from the input list of\n        examples. The logic is as follows:\n            1. Mask the input blocks. In case has_pair is True then we have 2\n               blocks to mask.\n            2. Prepend the first masked block tensor with the special token\n               used as sentence embedding. Eg: CLS in BERT. This happens\n               irrespective of the value of has_pair.\n            3. If has_pair is True, then append the first masked block with the\n               special separator token (eg: SEP for BERT) and compute segment\n               label accordingly. In this case, also append the second masked\n               block with this special separator token and compute its segment\n               label.\n            4. For the targets tensor, prepend and append with padding index\n               accordingly.\n            5. Concatenate all tensors.\n        \"\"\"", "\n", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "            ", "return", "{", "}", "\n", "# To ensure determinism, we reset the state of the PRNG after every", "\n", "# batch based on the seed and the first id of the batch. This ensures", "\n", "# that across epochs we get the same mask for the same example. This", "\n", "# is needed for reproducibility and is how BERT does masking", "\n", "# TODO: Can we add deteminism without this constraint?", "\n", "", "with", "data_utils", ".", "numpy_seed", "(", "self", ".", "seed", "+", "samples", "[", "0", "]", "[", "\"id\"", "]", ")", ":", "\n", "            ", "for", "s", "in", "samples", ":", "\n", "\n", "# token range is needed for replacing with random token during", "\n", "# masking", "\n", "                ", "token_range", "=", "(", "self", ".", "vocab", ".", "nspecial", ",", "len", "(", "self", ".", "vocab", ")", ")", "\n", "\n", "# mask according to specified probabilities.", "\n", "masked_blk_one", ",", "masked_tgt_one", "=", "self", ".", "_mask_block", "(", "\n", "s", "[", "\"block_one\"", "]", ",", "\n", "self", ".", "mask_idx", ",", "\n", "self", ".", "pad_idx", ",", "\n", "token_range", ",", "\n", ")", "\n", "\n", "tokens", "=", "np", ".", "concatenate", "(", "[", "[", "self", ".", "classif_token_idx", "]", ",", "masked_blk_one", "]", ")", "\n", "targets", "=", "np", ".", "concatenate", "(", "[", "[", "self", ".", "pad_idx", "]", ",", "masked_tgt_one", "]", ")", "\n", "segments", "=", "np", ".", "ones", "(", "len", "(", "tokens", ")", ")", "*", "self", ".", "segment_id", "\n", "\n", "# if has_pairs is True then we need to add the SEP token to both", "\n", "# the blocks after masking and re-compute segments based on the new", "\n", "# lengths.", "\n", "if", "self", ".", "has_pairs", ":", "\n", "                    ", "tokens_one", "=", "np", ".", "concatenate", "(", "[", "tokens", ",", "[", "self", ".", "sep_token_idx", "]", "]", ")", "\n", "targets_one", "=", "np", ".", "concatenate", "(", "[", "targets", ",", "[", "self", ".", "pad_idx", "]", "]", ")", "\n", "\n", "masked_blk_two", ",", "masked_tgt_two", "=", "self", ".", "_mask_block", "(", "\n", "s", "[", "\"block_two\"", "]", ",", "self", ".", "mask_idx", ",", "self", ".", "pad_idx", ",", "token_range", "\n", ")", "\n", "tokens_two", "=", "np", ".", "concatenate", "(", "[", "masked_blk_two", ",", "[", "self", ".", "sep_token_idx", "]", "]", ")", "\n", "targets_two", "=", "np", ".", "concatenate", "(", "[", "masked_tgt_two", ",", "[", "self", ".", "pad_idx", "]", "]", ")", "\n", "\n", "# block + 1 sep + 1 special (CLS)", "\n", "segments_one", "=", "np", ".", "zeros", "(", "len", "(", "tokens_one", ")", ")", "\n", "# block + 1 sep", "\n", "segments_two", "=", "np", ".", "ones", "(", "len", "(", "tokens_two", ")", ")", "\n", "\n", "tokens", "=", "np", ".", "concatenate", "(", "[", "tokens_one", ",", "tokens_two", "]", ")", "\n", "targets", "=", "np", ".", "concatenate", "(", "[", "targets_one", ",", "targets_two", "]", ")", "\n", "segments", "=", "np", ".", "concatenate", "(", "[", "segments_one", ",", "segments_two", "]", ")", "\n", "\n", "", "s", "[", "\"source\"", "]", "=", "torch", ".", "LongTensor", "(", "tokens", ")", "\n", "s", "[", "\"segment_labels\"", "]", "=", "torch", ".", "LongTensor", "(", "segments", ")", "\n", "s", "[", "\"lm_target\"", "]", "=", "torch", ".", "LongTensor", "(", "targets", ")", "\n", "\n", "", "", "def", "merge", "(", "key", ")", ":", "\n", "            ", "return", "data_utils", ".", "collate_tokens", "(", "\n", "[", "s", "[", "key", "]", "for", "s", "in", "samples", "]", ",", "pad_idx", ",", "eos_idx", ",", "left_pad", "=", "False", "\n", ")", "\n", "\n", "", "return", "{", "\n", "\"id\"", ":", "torch", ".", "LongTensor", "(", "[", "s", "[", "\"id\"", "]", "for", "s", "in", "samples", "]", ")", ",", "\n", "\"ntokens\"", ":", "sum", "(", "len", "(", "s", "[", "\"source\"", "]", ")", "for", "s", "in", "samples", ")", ",", "\n", "\"net_input\"", ":", "{", "\n", "\"src_tokens\"", ":", "merge", "(", "\"source\"", ")", ",", "\n", "\"segment_labels\"", ":", "merge", "(", "\"segment_labels\"", ")", ",", "\n", "}", ",", "\n", "\"lm_target\"", ":", "merge", "(", "\"lm_target\"", ")", ",", "\n", "\"sentence_target\"", ":", "torch", ".", "LongTensor", "(", "[", "s", "[", "\"sentence_target\"", "]", "for", "s", "in", "samples", "]", ")", "\n", "if", "self", ".", "has_pairs", "\n", "else", "None", ",", "\n", "\"nsentences\"", ":", "len", "(", "samples", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dataset.MaskedLMDataset.collater": [[261, 271], ["masked_lm_dataset.MaskedLMDataset._collate", "masked_lm_dataset.MaskedLMDataset.vocab.pad", "masked_lm_dataset.MaskedLMDataset.vocab.eos"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dataset.MaskedLMDataset._collate", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "def", "collater", "(", "self", ",", "samples", ":", "List", "[", "Dict", "]", ")", ":", "\n", "        ", "\"\"\"Merge a list of samples to form a mini-batch.\n\n        Args:\n            samples (List[dict]): samples to collate\n\n        Returns:\n            dict: a mini-batch of data\n        \"\"\"", "\n", "return", "self", ".", "_collate", "(", "samples", ",", "self", ".", "vocab", ".", "pad", "(", ")", ",", "self", ".", "vocab", ".", "eos", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dataset.MaskedLMDataset.num_tokens": [[272, 278], ["None"], "methods", ["None"], ["", "def", "num_tokens", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Return the number of tokens in a sample. This value is used to\n        enforce max-tokens during batching.\n        \"\"\"", "\n", "return", "self", ".", "sizes", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dataset.MaskedLMDataset.size": [[279, 285], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Return an example's size as a float or tuple. This value is used when\n        filtering a dataset with max-positions.\n        \"\"\"", "\n", "return", "self", ".", "sizes", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dataset.MaskedLMDataset.ordered_indices": [[286, 297], ["numpy.random.permutation", "order.append", "numpy.lexsort", "len", "numpy.arange", "len"], "methods", ["None"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return an ordered list of indices. Batches will be constructed based\n        on this order.\n        \"\"\"", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "return", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ")", ")", "\n", "", "else", ":", "\n", "            ", "order", "=", "[", "np", ".", "arange", "(", "len", "(", "self", ")", ")", "]", "\n", "order", ".", "append", "(", "self", ".", "sizes", ")", "\n", "return", "np", ".", "lexsort", "(", "order", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dataset.MaskedLMDataset.supports_prefetch": [[298, 301], ["getattr"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ".", "dataset", ",", "\"supports_prefetch\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dataset.MaskedLMDataset.prefetch": [[302, 304], ["masked_lm_dataset.MaskedLMDataset.dataset.prefetch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "self", ".", "dataset", ".", "prefetch", "(", "indices", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset.__init__": [[36, 99], ["fairseq.data.FairseqDataset.__init__", "dictionary.pad", "dictionary.eos", "dictionary.cls", "dictionary.mask", "dictionary.sep", "len", "len", "enumerate", "enumerate", "block_pair_dataset.BlockPairDataset._generate_sentence_pair", "sum", "math.ceil", "numpy.array", "numpy.array", "block_pair_dataset.BlockPairDataset._sent_to_dataset_index", "block_pair_dataset.BlockPairDataset._pair_sentences", "ValueError", "block_pair_dataset.BlockPairDataset.block_indices.append", "cur_doc.append", "min", "len", "block_pair_dataset.BlockPairDataset.__init__.block_at"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.MaskedLMDictionary.mask", "home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.sep", "home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset._generate_sentence_pair", "home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset._sent_to_dataset_index", "home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset._pair_sentences"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "dictionary", ",", "\n", "sizes", ",", "\n", "block_size", ",", "\n", "break_mode", "=", "\"doc\"", ",", "\n", "short_seq_prob", "=", "0.1", ",", "\n", "doc_break_size", "=", "1", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "pad", "=", "dictionary", ".", "pad", "(", ")", "\n", "self", ".", "eos", "=", "dictionary", ".", "eos", "(", ")", "\n", "self", ".", "cls", "=", "dictionary", ".", "cls", "(", ")", "\n", "self", ".", "mask", "=", "dictionary", ".", "mask", "(", ")", "\n", "self", ".", "sep", "=", "dictionary", ".", "sep", "(", ")", "\n", "self", ".", "break_mode", "=", "break_mode", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "self", ".", "short_seq_prob", "=", "short_seq_prob", "\n", "self", ".", "block_indices", "=", "[", "]", "\n", "\n", "assert", "len", "(", "dataset", ")", "==", "len", "(", "sizes", ")", "\n", "\n", "if", "break_mode", "==", "\"doc\"", ":", "\n", "            ", "cur_doc", "=", "[", "]", "\n", "for", "sent_id", ",", "sz", "in", "enumerate", "(", "sizes", ")", ":", "\n", "                ", "assert", "doc_break_size", "==", "0", "or", "sz", "!=", "0", ",", "(", "\n", "\"when doc_break_size is non-zero, we expect documents to be\"", "\n", "\"separated by a blank line with a single eos.\"", "\n", ")", "\n", "# empty line as document separator", "\n", "if", "sz", "==", "doc_break_size", ":", "\n", "                    ", "if", "len", "(", "cur_doc", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "", "self", ".", "block_indices", ".", "append", "(", "cur_doc", ")", "\n", "cur_doc", "=", "[", "]", "\n", "", "else", ":", "\n", "                    ", "cur_doc", ".", "append", "(", "sent_id", ")", "\n", "", "", "max_num_tokens", "=", "block_size", "-", "3", "# Account for [CLS], [SEP], [SEP]", "\n", "self", ".", "sent_pairs", "=", "[", "]", "\n", "self", ".", "sizes", "=", "[", "]", "\n", "for", "doc_id", ",", "doc", "in", "enumerate", "(", "self", ".", "block_indices", ")", ":", "\n", "                ", "self", ".", "_generate_sentence_pair", "(", "doc", ",", "doc_id", ",", "max_num_tokens", ",", "sizes", ")", "\n", "", "", "elif", "break_mode", "is", "None", "or", "break_mode", "==", "\"none\"", ":", "\n", "# each block should have half of the block size since we are constructing block pair", "\n", "            ", "sent_length", "=", "(", "block_size", "-", "3", ")", "//", "2", "\n", "total_len", "=", "sum", "(", "dataset", ".", "sizes", ")", "\n", "length", "=", "math", ".", "ceil", "(", "total_len", "/", "sent_length", ")", "\n", "\n", "def", "block_at", "(", "i", ")", ":", "\n", "                ", "start", "=", "i", "*", "sent_length", "\n", "end", "=", "min", "(", "start", "+", "sent_length", ",", "total_len", ")", "\n", "return", "(", "start", ",", "end", ")", "\n", "\n", "", "sent_indices", "=", "np", ".", "array", "(", "[", "block_at", "(", "i", ")", "for", "i", "in", "range", "(", "length", ")", "]", ")", "\n", "sent_sizes", "=", "np", ".", "array", "(", "[", "e", "-", "s", "for", "s", ",", "e", "in", "sent_indices", "]", ")", "\n", "dataset_index", "=", "self", ".", "_sent_to_dataset_index", "(", "sent_sizes", ")", "\n", "\n", "# pair sentences", "\n", "self", ".", "_pair_sentences", "(", "dataset_index", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid break_mode: \"", "+", "break_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset._pair_sentences": [[100, 122], ["enumerate", "block_pair_dataset.BlockPairDataset.sent_pairs.append", "block_pair_dataset.BlockPairDataset.sizes.append", "numpy.random.rand", "block_pair_dataset.BlockPairDataset._skip_sampling", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset._skip_sampling"], ["", "", "def", "_pair_sentences", "(", "self", ",", "dataset_index", ")", ":", "\n", "        ", "\"\"\"\n        Give a list of evenly cut blocks/sentences, pair these sentences with 50%\n        consecutive sentences and 50% random sentences.\n        This is used for none break mode\n        \"\"\"", "\n", "# pair sentences", "\n", "for", "sent_id", ",", "sent", "in", "enumerate", "(", "dataset_index", ")", ":", "\n", "            ", "next_sent_label", "=", "(", "\n", "1", "if", "np", ".", "random", ".", "rand", "(", ")", ">", "0.5", "and", "sent_id", "!=", "len", "(", "dataset_index", ")", "-", "1", "else", "0", "\n", ")", "\n", "if", "next_sent_label", ":", "\n", "                ", "next_sent", "=", "dataset_index", "[", "sent_id", "+", "1", "]", "\n", "", "else", ":", "\n", "                ", "next_sent", "=", "dataset_index", "[", "\n", "self", ".", "_skip_sampling", "(", "len", "(", "dataset_index", ")", ",", "[", "sent_id", ",", "sent_id", "+", "1", "]", ")", "\n", "]", "\n", "", "self", ".", "sent_pairs", ".", "append", "(", "(", "sent", ",", "next_sent", ",", "next_sent_label", ")", ")", "\n", "\n", "# The current blocks don't include the special tokens but the", "\n", "# sizes already account for this", "\n", "self", ".", "sizes", ".", "append", "(", "3", "+", "sent", "[", "3", "]", "+", "next_sent", "[", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset._sent_to_dataset_index": [[123, 152], ["dataset_index.append", "len"], "methods", ["None"], ["", "", "def", "_sent_to_dataset_index", "(", "self", ",", "sent_sizes", ")", ":", "\n", "        ", "\"\"\"\n        Build index mapping block indices to the underlying dataset indices\n        \"\"\"", "\n", "dataset_index", "=", "[", "]", "\n", "ds_idx", ",", "ds_remaining", "=", "-", "1", ",", "0", "\n", "for", "to_consume", "in", "sent_sizes", ":", "\n", "            ", "sent_size", "=", "to_consume", "\n", "if", "ds_remaining", "==", "0", ":", "\n", "                ", "ds_idx", "+=", "1", "\n", "ds_remaining", "=", "sent_sizes", "[", "ds_idx", "]", "\n", "", "start_ds_idx", "=", "ds_idx", "\n", "start_offset", "=", "sent_sizes", "[", "ds_idx", "]", "-", "ds_remaining", "\n", "while", "to_consume", ">", "ds_remaining", ":", "\n", "                ", "to_consume", "-=", "ds_remaining", "\n", "ds_idx", "+=", "1", "\n", "ds_remaining", "=", "sent_sizes", "[", "ds_idx", "]", "\n", "", "ds_remaining", "-=", "to_consume", "\n", "dataset_index", ".", "append", "(", "\n", "(", "\n", "start_ds_idx", ",", "# starting index in dataset", "\n", "start_offset", ",", "# starting offset within starting index", "\n", "ds_idx", ",", "# ending index in dataset", "\n", "sent_size", ",", "# sentence length", "\n", ")", "\n", ")", "\n", "", "assert", "ds_remaining", "==", "0", "\n", "assert", "ds_idx", "==", "len", "(", "self", ".", "dataset", ")", "-", "1", "\n", "return", "dataset_index", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset._generate_sentence_pair": [[153, 214], ["numpy.random.random", "numpy.random.randint", "len", "current_chunk.append", "sum", "sum", "block_pair_dataset.BlockPairDataset._truncate_sentences", "block_pair_dataset.BlockPairDataset.sent_pairs.append", "block_pair_dataset.BlockPairDataset.sizes.append", "len", "numpy.random.randint", "block_pair_dataset.BlockPairDataset._skip_sampling", "numpy.random.randint", "range", "sum", "len", "len", "len", "len", "sent_b.append", "sum", "len", "len", "numpy.random.rand", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset._truncate_sentences", "home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset._skip_sampling"], ["", "def", "_generate_sentence_pair", "(", "self", ",", "doc", ",", "doc_id", ",", "max_num_tokens", ",", "sizes", ")", ":", "\n", "        ", "\"\"\"\n        Go through a single document and genrate sentence paris from it\n        \"\"\"", "\n", "current_chunk", "=", "[", "]", "\n", "current_length", "=", "0", "\n", "curr", "=", "0", "\n", "# To provide more randomness, we decrease target seq length for parts of", "\n", "# samples (10% by default). Note that max_num_tokens is the hard threshold", "\n", "# for batching and will never be changed.", "\n", "target_seq_length", "=", "max_num_tokens", "\n", "if", "np", ".", "random", ".", "random", "(", ")", "<", "self", ".", "short_seq_prob", ":", "\n", "            ", "target_seq_length", "=", "np", ".", "random", ".", "randint", "(", "2", ",", "max_num_tokens", ")", "\n", "# loop through all sentences in document", "\n", "", "while", "curr", "<", "len", "(", "doc", ")", ":", "\n", "            ", "sent_id", "=", "doc", "[", "curr", "]", "\n", "current_chunk", ".", "append", "(", "sent_id", ")", "\n", "current_length", "=", "sum", "(", "sizes", "[", "current_chunk", "]", ")", "\n", "# split chunk and generate pair when exceed target_seq_length or", "\n", "# finish the loop", "\n", "if", "curr", "==", "len", "(", "doc", ")", "-", "1", "or", "current_length", ">=", "target_seq_length", ":", "\n", "# split the chunk into 2 parts", "\n", "                ", "a_end", "=", "1", "\n", "if", "len", "(", "current_chunk", ")", ">", "2", ":", "\n", "                    ", "a_end", "=", "np", ".", "random", ".", "randint", "(", "1", ",", "len", "(", "current_chunk", ")", "-", "1", ")", "\n", "", "sent_a", "=", "current_chunk", "[", ":", "a_end", "]", "\n", "len_a", "=", "sum", "(", "sizes", "[", "sent_a", "]", ")", "\n", "# generate next sentence label, note that if there is only 1 sentence", "\n", "# in current chunk, label is always 0", "\n", "next_sent_label", "=", "(", "\n", "1", "if", "np", ".", "random", ".", "rand", "(", ")", ">", "0.5", "and", "len", "(", "current_chunk", ")", "!=", "1", "else", "0", "\n", ")", "\n", "if", "not", "next_sent_label", ":", "\n", "# if next sentence label is 0, sample sent_b from a random doc", "\n", "                    ", "target_b_length", "=", "target_seq_length", "-", "len_a", "\n", "rand_doc_id", "=", "self", ".", "_skip_sampling", "(", "len", "(", "self", ".", "block_indices", ")", ",", "[", "doc_id", "]", ")", "\n", "random_doc", "=", "self", ".", "block_indices", "[", "rand_doc_id", "]", "\n", "random_start", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "random_doc", ")", ")", "\n", "sent_b", "=", "[", "]", "\n", "len_b", "=", "0", "\n", "for", "j", "in", "range", "(", "random_start", ",", "len", "(", "random_doc", ")", ")", ":", "\n", "                        ", "sent_b", ".", "append", "(", "random_doc", "[", "j", "]", ")", "\n", "len_b", "=", "sum", "(", "sizes", "[", "sent_b", "]", ")", "\n", "if", "len_b", ">=", "target_b_length", ":", "\n", "                            ", "break", "\n", "# return the second part of the chunk since it's not used", "\n", "", "", "num_unused_segments", "=", "len", "(", "current_chunk", ")", "-", "a_end", "\n", "curr", "-=", "num_unused_segments", "\n", "", "else", ":", "\n", "# if next sentence label is 1, use the second part of chunk as sent_B", "\n", "                    ", "sent_b", "=", "current_chunk", "[", "a_end", ":", "]", "\n", "len_b", "=", "sum", "(", "sizes", "[", "sent_b", "]", ")", "\n", "# currently sent_a and sent_B may be longer than max_num_tokens,", "\n", "# truncate them and return block idx and offsets for them", "\n", "", "sent_a", ",", "sent_b", "=", "self", ".", "_truncate_sentences", "(", "\n", "sent_a", ",", "sent_b", ",", "max_num_tokens", "\n", ")", "\n", "self", ".", "sent_pairs", ".", "append", "(", "(", "sent_a", ",", "sent_b", ",", "next_sent_label", ")", ")", "\n", "self", ".", "sizes", ".", "append", "(", "3", "+", "sent_a", "[", "3", "]", "+", "sent_b", "[", "3", "]", ")", "\n", "current_chunk", "=", "[", "]", "\n", "", "curr", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset._skip_sampling": [[215, 222], ["numpy.random.randint", "len", "min", "len"], "methods", ["None"], ["", "", "def", "_skip_sampling", "(", "self", ",", "total", ",", "skip_ids", ")", ":", "\n", "        ", "\"\"\"\n        Generate a random integer which is not in skip_ids. Sample range is [0, total)\n        TODO: ids in skip_ids should be consecutive, we can extend it to more generic version later\n        \"\"\"", "\n", "rand_id", "=", "np", ".", "random", ".", "randint", "(", "total", "-", "len", "(", "skip_ids", ")", ")", "\n", "return", "rand_id", "if", "rand_id", "<", "min", "(", "skip_ids", ")", "else", "rand_id", "+", "len", "(", "skip_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset._truncate_sentences": [[223, 257], ["block_pair_dataset.BlockPairDataset._cut_sentence", "block_pair_dataset.BlockPairDataset._cut_sentence", "sum", "sum", "numpy.random.rand", "numpy.random.rand"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset._cut_sentence", "home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset._cut_sentence"], ["", "def", "_truncate_sentences", "(", "self", ",", "sent_a", ",", "sent_b", ",", "max_num_tokens", ")", ":", "\n", "        ", "\"\"\"\n        Trancate a pair of sentence to limit total length under max_num_tokens\n        Logics:\n            1. Truncate longer sentence\n            2. Tokens to be truncated could be at the beginning or the end of the sentnce\n        Returns:\n            Truncated sentences represented by dataset idx\n        \"\"\"", "\n", "len_a", ",", "len_b", "=", "sum", "(", "self", ".", "dataset", ".", "sizes", "[", "sent_a", "]", ")", ",", "sum", "(", "self", ".", "dataset", ".", "sizes", "[", "sent_b", "]", ")", "\n", "front_cut_a", "=", "front_cut_b", "=", "end_cut_a", "=", "end_cut_b", "=", "0", "\n", "\n", "while", "True", ":", "\n", "            ", "total_length", "=", "(", "\n", "len_a", "+", "len_b", "-", "front_cut_a", "-", "front_cut_b", "-", "end_cut_a", "-", "end_cut_b", "\n", ")", "\n", "if", "total_length", "<=", "max_num_tokens", ":", "\n", "                ", "break", "\n", "\n", "", "if", "len_a", "-", "front_cut_a", "-", "end_cut_a", ">", "len_b", "-", "front_cut_b", "-", "end_cut_b", ":", "\n", "                ", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "0.5", ":", "\n", "                    ", "front_cut_a", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "end_cut_a", "+=", "1", "\n", "", "", "else", ":", "\n", "                ", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "0.5", ":", "\n", "                    ", "front_cut_b", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "end_cut_b", "+=", "1", "\n", "\n", "# calculate ds indices as well as offsets and return", "\n", "", "", "", "truncated_sent_a", "=", "self", ".", "_cut_sentence", "(", "sent_a", ",", "front_cut_a", ",", "end_cut_a", ")", "\n", "truncated_sent_b", "=", "self", ".", "_cut_sentence", "(", "sent_b", ",", "front_cut_b", ",", "end_cut_b", ")", "\n", "return", "truncated_sent_a", ",", "truncated_sent_b", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset._cut_sentence": [[258, 279], ["sum"], "methods", ["None"], ["", "def", "_cut_sentence", "(", "self", ",", "sent", ",", "front_cut", ",", "end_cut", ")", ":", "\n", "        ", "\"\"\"\n        Cut a sentence based on the numbers of tokens to be cut from beginning and end\n        Represent the sentence as dataset idx and return\n        \"\"\"", "\n", "start_ds_idx", ",", "end_ds_idx", ",", "offset", "=", "sent", "[", "0", "]", ",", "sent", "[", "-", "1", "]", ",", "0", "\n", "target_len", "=", "sum", "(", "self", ".", "dataset", ".", "sizes", "[", "sent", "]", ")", "-", "front_cut", "-", "end_cut", "\n", "while", "front_cut", ">", "0", ":", "\n", "            ", "if", "self", ".", "dataset", ".", "sizes", "[", "start_ds_idx", "]", ">", "front_cut", ":", "\n", "                ", "offset", "+=", "front_cut", "\n", "break", "\n", "", "else", ":", "\n", "                ", "front_cut", "-=", "self", ".", "dataset", ".", "sizes", "[", "start_ds_idx", "]", "\n", "start_ds_idx", "+=", "1", "\n", "", "", "while", "end_cut", ">", "0", ":", "\n", "            ", "if", "self", ".", "dataset", ".", "sizes", "[", "end_ds_idx", "]", ">", "end_cut", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "end_cut", "-=", "self", ".", "dataset", ".", "sizes", "[", "end_ds_idx", "]", "\n", "end_ds_idx", "-=", "1", "\n", "", "", "return", "start_ds_idx", ",", "offset", ",", "end_ds_idx", ",", "target_len", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset._fetch_block": [[280, 289], ["torch.cat", "range"], "methods", ["None"], ["", "def", "_fetch_block", "(", "self", ",", "start_ds_idx", ",", "offset", ",", "end_ds_idx", ",", "length", ")", ":", "\n", "        ", "\"\"\"\n        Fetch a block of tokens based on its dataset idx\n        \"\"\"", "\n", "buffer", "=", "torch", ".", "cat", "(", "\n", "[", "self", ".", "dataset", "[", "idx", "]", "for", "idx", "in", "range", "(", "start_ds_idx", ",", "end_ds_idx", "+", "1", ")", "]", "\n", ")", "\n", "s", ",", "e", "=", "offset", ",", "offset", "+", "length", "\n", "return", "buffer", "[", "s", ":", "e", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset.__getitem__": [[290, 295], ["block_pair_dataset.BlockPairDataset._fetch_block", "block_pair_dataset.BlockPairDataset._fetch_block"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset._fetch_block", "home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset._fetch_block"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "block1", ",", "block2", ",", "next_sent_label", "=", "self", ".", "sent_pairs", "[", "index", "]", "\n", "block1", "=", "self", ".", "_fetch_block", "(", "*", "block1", ")", "\n", "block2", "=", "self", ".", "_fetch_block", "(", "*", "block2", ")", "\n", "return", "block1", ",", "block2", ",", "next_sent_label", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset.__len__": [[296, 298], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset.supports_prefetch": [[299, 302], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ".", "dataset", ",", "\"supports_prefetch\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.legacy.block_pair_dataset.BlockPairDataset.prefetch": [[303, 312], ["set", "block_pair_dataset.BlockPairDataset.dataset.prefetch", "range", "range", "set.add", "set.add"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "prefetch_idx", "=", "set", "(", ")", "\n", "for", "index", "in", "indices", ":", "\n", "            ", "for", "block1", ",", "block2", ",", "_", "in", "[", "self", ".", "sent_pairs", "[", "index", "]", "]", ":", "\n", "                ", "for", "ds_idx", "in", "range", "(", "block1", "[", "0", "]", ",", "block1", "[", "2", "]", "+", "1", ")", ":", "\n", "                    ", "prefetch_idx", ".", "add", "(", "ds_idx", ")", "\n", "", "for", "ds_idx", "in", "range", "(", "block2", "[", "0", "]", ",", "block2", "[", "2", "]", "+", "1", ")", ":", "\n", "                    ", "prefetch_idx", ".", "add", "(", "ds_idx", ")", "\n", "", "", "", "self", ".", "dataset", ".", "prefetch", "(", "prefetch_idx", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.audio.raw_audio_dataset.RawAudioDataset.__init__": [[22, 44], ["FairseqDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "sample_rate", ",", "\n", "max_sample_size", "=", "None", ",", "\n", "min_sample_size", "=", "None", ",", "\n", "shuffle", "=", "True", ",", "\n", "min_length", "=", "0", ",", "\n", "pad", "=", "False", ",", "\n", "normalize", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "self", ".", "sizes", "=", "[", "]", "\n", "self", ".", "max_sample_size", "=", "(", "\n", "max_sample_size", "if", "max_sample_size", "is", "not", "None", "else", "sys", ".", "maxsize", "\n", ")", "\n", "self", ".", "min_sample_size", "=", "min_sample_size", "\n", "self", ".", "min_length", "=", "min_length", "\n", "self", ".", "pad", "=", "pad", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "normalize", "=", "normalize", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.raw_audio_dataset.RawAudioDataset.__getitem__": [[45, 47], ["NotImplementedError"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.raw_audio_dataset.RawAudioDataset.__len__": [[48, 50], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.raw_audio_dataset.RawAudioDataset.postprocess": [[51, 64], ["torch.layer_norm.dim", "torch.layer_norm.dim", "torch.layer_norm.mean", "Exception", "torch.layer_norm.dim", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.layer_norm", "torch.layer_norm"], "methods", ["None"], ["", "def", "postprocess", "(", "self", ",", "feats", ",", "curr_sample_rate", ")", ":", "\n", "        ", "if", "feats", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "feats", "=", "feats", ".", "mean", "(", "-", "1", ")", "\n", "\n", "", "if", "curr_sample_rate", "!=", "self", ".", "sample_rate", ":", "\n", "            ", "raise", "Exception", "(", "f\"sample rate: {curr_sample_rate}, need {self.sample_rate}\"", ")", "\n", "\n", "", "assert", "feats", ".", "dim", "(", ")", "==", "1", ",", "feats", ".", "dim", "(", ")", "\n", "\n", "if", "self", ".", "normalize", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "feats", "=", "F", ".", "layer_norm", "(", "feats", ",", "feats", ".", "shape", ")", "\n", "", "", "return", "feats", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.raw_audio_dataset.RawAudioDataset.crop_to_max_size": [[65, 74], ["len", "numpy.random.randint"], "methods", ["None"], ["", "def", "crop_to_max_size", "(", "self", ",", "wav", ",", "target_size", ")", ":", "\n", "        ", "size", "=", "len", "(", "wav", ")", "\n", "diff", "=", "size", "-", "target_size", "\n", "if", "diff", "<=", "0", ":", "\n", "            ", "return", "wav", "\n", "\n", "", "start", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "diff", "+", "1", ")", "\n", "end", "=", "size", "-", "diff", "+", "start", "\n", "return", "wav", "[", "start", ":", "end", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.raw_audio_dataset.RawAudioDataset.collater": [[75, 109], ["sources[].new_zeros", "enumerate", "len", "len", "min", "min", "len", "torch.BoolTensor().fill_", "torch.BoolTensor().fill_", "torch.BoolTensor().fill_", "torch.BoolTensor().fill_", "zip", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "max", "min", "torch.BoolTensor", "torch.BoolTensor", "torch.BoolTensor", "torch.BoolTensor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "raw_audio_dataset.RawAudioDataset.crop_to_max_size", "source.new_full"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.audio.raw_audio_dataset.RawAudioDataset.crop_to_max_size"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "samples", "=", "[", "s", "for", "s", "in", "samples", "if", "s", "[", "\"source\"", "]", "is", "not", "None", "]", "\n", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "            ", "return", "{", "}", "\n", "\n", "", "sources", "=", "[", "s", "[", "\"source\"", "]", "for", "s", "in", "samples", "]", "\n", "sizes", "=", "[", "len", "(", "s", ")", "for", "s", "in", "sources", "]", "\n", "\n", "if", "self", ".", "pad", ":", "\n", "            ", "target_size", "=", "min", "(", "max", "(", "sizes", ")", ",", "self", ".", "max_sample_size", ")", "\n", "", "else", ":", "\n", "            ", "target_size", "=", "min", "(", "min", "(", "sizes", ")", ",", "self", ".", "max_sample_size", ")", "\n", "\n", "", "collated_sources", "=", "sources", "[", "0", "]", ".", "new_zeros", "(", "len", "(", "sources", ")", ",", "target_size", ")", "\n", "padding_mask", "=", "(", "\n", "torch", ".", "BoolTensor", "(", "collated_sources", ".", "shape", ")", ".", "fill_", "(", "False", ")", "if", "self", ".", "pad", "else", "None", "\n", ")", "\n", "for", "i", ",", "(", "source", ",", "size", ")", "in", "enumerate", "(", "zip", "(", "sources", ",", "sizes", ")", ")", ":", "\n", "            ", "diff", "=", "size", "-", "target_size", "\n", "if", "diff", "==", "0", ":", "\n", "                ", "collated_sources", "[", "i", "]", "=", "source", "\n", "", "elif", "diff", "<", "0", ":", "\n", "                ", "assert", "self", ".", "pad", "\n", "collated_sources", "[", "i", "]", "=", "torch", ".", "cat", "(", "\n", "[", "source", ",", "source", ".", "new_full", "(", "(", "-", "diff", ",", ")", ",", "0.0", ")", "]", "\n", ")", "\n", "padding_mask", "[", "i", ",", "diff", ":", "]", "=", "True", "\n", "", "else", ":", "\n", "                ", "collated_sources", "[", "i", "]", "=", "self", ".", "crop_to_max_size", "(", "source", ",", "target_size", ")", "\n", "\n", "", "", "input", "=", "{", "\"source\"", ":", "collated_sources", "}", "\n", "if", "self", ".", "pad", ":", "\n", "            ", "input", "[", "\"padding_mask\"", "]", "=", "padding_mask", "\n", "", "return", "{", "\"id\"", ":", "torch", ".", "LongTensor", "(", "[", "s", "[", "\"id\"", "]", "for", "s", "in", "samples", "]", ")", ",", "\"net_input\"", ":", "input", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.raw_audio_dataset.RawAudioDataset.num_tokens": [[110, 112], ["raw_audio_dataset.RawAudioDataset.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "size", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.raw_audio_dataset.RawAudioDataset.size": [[113, 119], ["min"], "methods", ["None"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return an example's size as a float or tuple. This value is used when\n        filtering a dataset with ``--max-positions``.\"\"\"", "\n", "if", "self", ".", "pad", ":", "\n", "            ", "return", "self", ".", "sizes", "[", "index", "]", "\n", "", "return", "min", "(", "self", ".", "sizes", "[", "index", "]", ",", "self", ".", "max_sample_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.raw_audio_dataset.RawAudioDataset.ordered_indices": [[120, 131], ["order.append", "numpy.lexsort", "numpy.random.permutation", "numpy.arange", "len", "len"], "methods", ["None"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return an ordered list of indices. Batches will be constructed based\n        on this order.\"\"\"", "\n", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "order", "=", "[", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ")", ")", "]", "\n", "", "else", ":", "\n", "            ", "order", "=", "[", "np", ".", "arange", "(", "len", "(", "self", ")", ")", "]", "\n", "\n", "", "order", ".", "append", "(", "self", ".", "sizes", ")", "\n", "return", "np", ".", "lexsort", "(", "order", ")", "[", ":", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.raw_audio_dataset.FileAudioDataset.__init__": [[134, 170], ["raw_audio_dataset.RawAudioDataset.__init__", "logger.info", "open", "f.readline().strip", "line.strip().split", "int", "raw_audio_dataset.FileAudioDataset.fnames.append", "raw_audio_dataset.FileAudioDataset.sizes.append", "f.readline", "len", "len", "line.strip"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "manifest_path", ",", "\n", "sample_rate", ",", "\n", "max_sample_size", "=", "None", ",", "\n", "min_sample_size", "=", "None", ",", "\n", "shuffle", "=", "True", ",", "\n", "min_length", "=", "0", ",", "\n", "pad", "=", "False", ",", "\n", "normalize", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "sample_rate", "=", "sample_rate", ",", "\n", "max_sample_size", "=", "max_sample_size", ",", "\n", "min_sample_size", "=", "min_sample_size", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "min_length", "=", "min_length", ",", "\n", "pad", "=", "pad", ",", "\n", "normalize", "=", "normalize", ",", "\n", ")", "\n", "\n", "self", ".", "fnames", "=", "[", "]", "\n", "\n", "skipped", "=", "0", "\n", "with", "open", "(", "manifest_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "self", ".", "root_dir", "=", "f", ".", "readline", "(", ")", ".", "strip", "(", ")", "\n", "for", "line", "in", "f", ":", "\n", "                ", "items", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "assert", "len", "(", "items", ")", "==", "2", ",", "line", "\n", "sz", "=", "int", "(", "items", "[", "1", "]", ")", "\n", "if", "min_length", "is", "not", "None", "and", "sz", "<", "min_length", ":", "\n", "                    ", "skipped", "+=", "1", "\n", "continue", "\n", "", "self", ".", "fnames", ".", "append", "(", "items", "[", "0", "]", ")", "\n", "self", ".", "sizes", ".", "append", "(", "sz", ")", "\n", "", "", "logger", ".", "info", "(", "f\"loaded {len(self.fnames)}, skipped {skipped} samples\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.raw_audio_dataset.FileAudioDataset.__getitem__": [[171, 179], ["os.path.join", "sf.read", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "raw_audio_dataset.FileAudioDataset.postprocess", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.audio.raw_audio_dataset.RawAudioDataset.postprocess"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "import", "soundfile", "as", "sf", "\n", "\n", "fname", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_dir", ",", "self", ".", "fnames", "[", "index", "]", ")", "\n", "wav", ",", "curr_sample_rate", "=", "sf", ".", "read", "(", "fname", ")", "\n", "feats", "=", "torch", ".", "from_numpy", "(", "wav", ")", ".", "float", "(", ")", "\n", "feats", "=", "self", ".", "postprocess", "(", "feats", ",", "curr_sample_rate", ")", "\n", "return", "{", "\"id\"", ":", "index", ",", "\"source\"", ":", "feats", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.S2TDataConfig.__init__": [[32, 46], ["os.isfile", "logger.info", "print", "open", "yaml.load", "logger.info"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.isfile", "home.repos.pwc.inspect_result.reneeye_const.logging.progress_bar.WandBProgressBarWrapper.print", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load"], ["def", "__init__", "(", "self", ",", "yaml_path", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "yaml", "\n", "", "except", "ImportError", ":", "\n", "            ", "print", "(", "\"Please install PyYAML to load YAML files for \"", "\"S2T data config\"", ")", "\n", "", "self", ".", "config", "=", "{", "}", "\n", "if", "op", ".", "isfile", "(", "yaml_path", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "with", "open", "(", "yaml_path", ")", "as", "f", ":", "\n", "                    ", "self", ".", "config", "=", "yaml", ".", "load", "(", "f", ",", "Loader", "=", "yaml", ".", "FullLoader", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "                ", "logger", ".", "info", "(", "f\"Failed to load config from {yaml_path}: {e}\"", ")", "\n", "", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Cannot find {yaml_path}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.S2TDataConfig.vocab_filename": [[47, 51], ["speech_to_text_dataset.S2TDataConfig.config.get"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "vocab_filename", "(", "self", ")", ":", "\n", "        ", "\"\"\"fairseq vocabulary file under data root\"\"\"", "\n", "return", "self", ".", "config", ".", "get", "(", "\"vocab_filename\"", ",", "\"dict.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.S2TDataConfig.shuffle": [[52, 56], ["speech_to_text_dataset.S2TDataConfig.config.get"], "methods", ["None"], ["", "@", "property", "\n", "def", "shuffle", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"Shuffle dataset samples before batching\"\"\"", "\n", "return", "self", ".", "config", ".", "get", "(", "\"shuffle\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.S2TDataConfig.pre_tokenizer": [[57, 64], ["speech_to_text_dataset.S2TDataConfig.config.get"], "methods", ["None"], ["", "@", "property", "\n", "def", "pre_tokenizer", "(", "self", ")", "->", "Dict", ":", "\n", "        ", "\"\"\"Pre-tokenizer to apply before subword tokenization. Returning\n        a dictionary with `tokenizer` providing the tokenizer name and\n        the other items providing the tokenizer-specific arguments.\n        Tokenizers are defined in `fairseq.data.encoders.*`\"\"\"", "\n", "return", "self", ".", "config", ".", "get", "(", "\"pre_tokenizer\"", ",", "{", "\"tokenizer\"", ":", "None", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.S2TDataConfig.bpe_tokenizer": [[65, 72], ["speech_to_text_dataset.S2TDataConfig.config.get"], "methods", ["None"], ["", "@", "property", "\n", "def", "bpe_tokenizer", "(", "self", ")", "->", "Dict", ":", "\n", "        ", "\"\"\"Subword tokenizer to apply after pre-tokenization. Returning\n        a dictionary with `bpe` providing the tokenizer name and\n        the other items providing the tokenizer-specific arguments.\n        Tokenizers are defined in `fairseq.data.encoders.*`\"\"\"", "\n", "return", "self", ".", "config", ".", "get", "(", "\"bpe_tokenizer\"", ",", "{", "\"bpe\"", ":", "None", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.S2TDataConfig.prepend_src_lang_tag": [[73, 79], ["speech_to_text_dataset.S2TDataConfig.config.get"], "methods", ["None"], ["", "@", "property", "\n", "def", "prepend_src_lang_tag", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"Prepend source lang ID token as the target BOS (e.g. for to-many\n        multilingual setting). During inference, this requires `--prefix-size 1`\n        to force BOS to be lang ID token.\"\"\"", "\n", "return", "self", ".", "config", ".", "get", "(", "\"prepend_src_lang_tag\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.S2TDataConfig.prepend_tgt_lang_tag": [[80, 86], ["speech_to_text_dataset.S2TDataConfig.config.get"], "methods", ["None"], ["", "@", "property", "\n", "def", "prepend_tgt_lang_tag", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"Prepend target lang ID token as the target BOS (e.g. for to-many\n        multilingual setting). During inference, this requires `--prefix-size 1`\n        to force BOS to be lang ID token.\"\"\"", "\n", "return", "self", ".", "config", ".", "get", "(", "\"prepend_tgt_lang_tag\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.S2TDataConfig.input_feat_per_channel": [[87, 91], ["speech_to_text_dataset.S2TDataConfig.config.get"], "methods", ["None"], ["", "@", "property", "\n", "def", "input_feat_per_channel", "(", "self", ")", ":", "\n", "        ", "\"\"\"The dimension of input features (per audio channel)\"\"\"", "\n", "return", "self", ".", "config", ".", "get", "(", "\"input_feat_per_channel\"", ",", "80", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.S2TDataConfig.input_channels": [[92, 96], ["speech_to_text_dataset.S2TDataConfig.config.get"], "methods", ["None"], ["", "@", "property", "\n", "def", "input_channels", "(", "self", ")", ":", "\n", "        ", "\"\"\"The number of channels in the input audio\"\"\"", "\n", "return", "self", ".", "config", ".", "get", "(", "\"input_channels\"", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.S2TDataConfig.sampling_alpha": [[97, 102], ["speech_to_text_dataset.S2TDataConfig.config.get"], "methods", ["None"], ["", "@", "property", "\n", "def", "sampling_alpha", "(", "self", ")", ":", "\n", "        ", "\"\"\"Hyper-parameter alpha = 1/T for temperature-based resampling.\n        (alpha = 1 for no resampling)\"\"\"", "\n", "return", "self", ".", "config", ".", "get", "(", "\"sampling_alpha\"", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.S2TDataConfig.use_audio_input": [[103, 108], ["speech_to_text_dataset.S2TDataConfig.config.get"], "methods", ["None"], ["", "@", "property", "\n", "def", "use_audio_input", "(", "self", ")", ":", "\n", "        ", "\"\"\"Needed by the dataset loader to see if the model requires\n        raw audio as inputs.\"\"\"", "\n", "return", "self", ".", "config", ".", "get", "(", "\"use_audio_input\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.S2TDataConfig.audio_root": [[109, 114], ["speech_to_text_dataset.S2TDataConfig.config.get"], "methods", ["None"], ["", "@", "property", "\n", "def", "audio_root", "(", "self", ")", ":", "\n", "        ", "\"\"\"Audio paths in the manifest TSV can be relative and this provides\n        the root path. Set this to empty string when using absolute paths.\"\"\"", "\n", "return", "self", ".", "config", ".", "get", "(", "\"audio_root\"", ",", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.S2TDataConfig.get_feature_transforms": [[115, 128], ["deepcopy", "deepcopy.get", "deepcopy.get.get", "deepcopy.get.get", "deepcopy.get.get", "deepcopy.get.get"], "methods", ["None"], ["", "def", "get_feature_transforms", "(", "self", ",", "split", ",", "is_train", ")", ":", "\n", "        ", "\"\"\"Split-specific feature transforms. Allowing train set wildcard `_train`,\n        evaluation set wildcard `_eval` and general wildcard `*` for matching.\"\"\"", "\n", "from", "copy", "import", "deepcopy", "\n", "\n", "cfg", "=", "deepcopy", "(", "self", ".", "config", ")", "\n", "_cur", "=", "cfg", ".", "get", "(", "\"transforms\"", ",", "{", "}", ")", "\n", "cur", "=", "_cur", ".", "get", "(", "split", ")", "\n", "cur", "=", "_cur", ".", "get", "(", "\"_train\"", ")", "if", "cur", "is", "None", "and", "is_train", "else", "cur", "\n", "cur", "=", "_cur", ".", "get", "(", "\"_eval\"", ")", "if", "cur", "is", "None", "and", "not", "is_train", "else", "cur", "\n", "cur", "=", "_cur", ".", "get", "(", "\"*\"", ")", "if", "cur", "is", "None", "else", "cur", "\n", "cfg", "[", "\"transforms\"", "]", "=", "cur", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDataset.__init__": [[233, 279], ["len", "speech_to_text_dataset.SpeechToTextDataset.check_tgt_lang_tag", "fairseq.data.audio.feature_transforms.CompositeAudioFeatureTransform.from_config_dict", "logger.info", "len", "speech_to_text_dataset.SpeechToTextDataset.data_cfg.get_feature_transforms", "speech_to_text_dataset.SpeechToTextDataset.__repr__", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDataset.check_tgt_lang_tag", "home.repos.pwc.inspect_result.reneeye_const.feature_transforms.specaugment.SpecAugmentTransform.from_config_dict", "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.S2TDataConfig.get_feature_transforms", "home.repos.pwc.inspect_result.reneeye_const.feature_transforms.specaugment.SpecAugmentTransform.__repr__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "split", ":", "str", ",", "\n", "is_train_split", ":", "bool", ",", "\n", "data_cfg", ":", "S2TDataConfig", ",", "\n", "audio_paths", ":", "List", "[", "str", "]", ",", "\n", "n_frames", ":", "List", "[", "int", "]", ",", "\n", "src_texts", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "tgt_texts", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "speakers", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "src_langs", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "tgt_langs", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "ids", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "tgt_dict", ":", "Optional", "[", "Dictionary", "]", "=", "None", ",", "\n", "pre_tokenizer", "=", "None", ",", "\n", "bpe_tokenizer", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "split", ",", "self", ".", "is_train_split", "=", "split", ",", "is_train_split", "\n", "self", ".", "data_cfg", "=", "data_cfg", "\n", "self", ".", "audio_paths", ",", "self", ".", "n_frames", "=", "audio_paths", ",", "n_frames", "\n", "self", ".", "n_samples", "=", "len", "(", "audio_paths", ")", "\n", "assert", "len", "(", "n_frames", ")", "==", "self", ".", "n_samples", ">", "0", "\n", "assert", "src_texts", "is", "None", "or", "len", "(", "src_texts", ")", "==", "self", ".", "n_samples", "\n", "assert", "tgt_texts", "is", "None", "or", "len", "(", "tgt_texts", ")", "==", "self", ".", "n_samples", "\n", "assert", "speakers", "is", "None", "or", "len", "(", "speakers", ")", "==", "self", ".", "n_samples", "\n", "assert", "src_langs", "is", "None", "or", "len", "(", "src_langs", ")", "==", "self", ".", "n_samples", "\n", "assert", "tgt_langs", "is", "None", "or", "len", "(", "tgt_langs", ")", "==", "self", ".", "n_samples", "\n", "assert", "ids", "is", "None", "or", "len", "(", "ids", ")", "==", "self", ".", "n_samples", "\n", "assert", "(", "tgt_dict", "is", "None", "and", "tgt_texts", "is", "None", ")", "or", "(", "\n", "tgt_dict", "is", "not", "None", "and", "tgt_texts", "is", "not", "None", "\n", ")", "\n", "self", ".", "src_texts", ",", "self", ".", "tgt_texts", "=", "src_texts", ",", "tgt_texts", "\n", "self", ".", "src_langs", ",", "self", ".", "tgt_langs", "=", "src_langs", ",", "tgt_langs", "\n", "self", ".", "tgt_dict", "=", "tgt_dict", "\n", "self", ".", "check_tgt_lang_tag", "(", ")", "\n", "self", ".", "ids", "=", "ids", "\n", "self", ".", "shuffle", "=", "data_cfg", ".", "shuffle", "if", "is_train_split", "else", "False", "\n", "\n", "self", ".", "feature_transforms", "=", "CompositeAudioFeatureTransform", ".", "from_config_dict", "(", "\n", "self", ".", "data_cfg", ".", "get_feature_transforms", "(", "split", ",", "is_train_split", ")", "\n", ")", "\n", "\n", "self", ".", "pre_tokenizer", "=", "pre_tokenizer", "\n", "self", ".", "bpe_tokenizer", "=", "bpe_tokenizer", "\n", "\n", "logger", ".", "info", "(", "self", ".", "__repr__", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDataset.__repr__": [[280, 284], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "__class__", ".", "__name__", "\n", "+", "f'(split=\"{self.split}\", n_samples={self.n_samples}, '", "\n", "f\"prepend_tgt_lang_tag={self.data_cfg.prepend_tgt_lang_tag}, \"", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDataset.is_lang_tag": [[288, 292], ["cls.LANG_TAG_TEMPLATE.replace", "re.match"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "is_lang_tag", "(", "cls", ",", "token", ")", ":", "\n", "        ", "pattern", "=", "cls", ".", "LANG_TAG_TEMPLATE", ".", "replace", "(", "\"{}\"", ",", "\"(.*)\"", ")", "\n", "return", "re", ".", "match", "(", "pattern", ",", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDataset.check_tgt_lang_tag": [[293, 300], ["all", "speech_to_text_dataset.SpeechToTextDataset.LANG_TAG_TEMPLATE.format", "set"], "methods", ["None"], ["", "def", "check_tgt_lang_tag", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "data_cfg", ".", "prepend_tgt_lang_tag", ":", "\n", "            ", "assert", "self", ".", "tgt_langs", "is", "not", "None", "and", "self", ".", "tgt_dict", "is", "not", "None", "\n", "tgt_lang_tags", "=", "[", "\n", "self", ".", "LANG_TAG_TEMPLATE", ".", "format", "(", "t", ")", "for", "t", "in", "set", "(", "self", ".", "tgt_langs", ")", "\n", "]", "\n", "assert", "all", "(", "t", "in", "self", ".", "tgt_dict", "for", "t", "in", "tgt_lang_tags", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDataset.tokenize_text": [[301, 307], ["speech_to_text_dataset.SpeechToTextDataset.pre_tokenizer.encode", "speech_to_text_dataset.SpeechToTextDataset.bpe_tokenizer.encode"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "", "def", "tokenize_text", "(", "self", ",", "text", ":", "str", ")", ":", "\n", "        ", "if", "self", ".", "pre_tokenizer", "is", "not", "None", ":", "\n", "            ", "text", "=", "self", ".", "pre_tokenizer", ".", "encode", "(", "text", ")", "\n", "", "if", "self", ".", "bpe_tokenizer", "is", "not", "None", ":", "\n", "            ", "text", "=", "self", ".", "bpe_tokenizer", ".", "encode", "(", "text", ")", "\n", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDataset.__getitem__": [[308, 334], ["speech_to_text_dataset.get_features_or_waveform", "isinstance", "speech_to_text_dataset.SpeechToTextDataset.feature_transforms", "torch.from_numpy().float", "source.squeeze.squeeze.squeeze", "speech_to_text_dataset.SpeechToTextDataset.tokenize_text", "speech_to_text_dataset.SpeechToTextDataset.tgt_dict.encode_line().long", "speech_to_text_dataset.SpeechToTextDataset.LANG_TAG_TEMPLATE.format", "speech_to_text_dataset.SpeechToTextDataset.tgt_dict.index", "torch.cat", "torch.from_numpy", "speech_to_text_dataset.SpeechToTextDataset.tgt_dict.encode_line", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.get_features_or_waveform", "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDataset.tokenize_text", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.index", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.encode_line"], ["", "def", "__getitem__", "(", "\n", "self", ",", "index", ":", "int", "\n", ")", "->", "Tuple", "[", "int", ",", "torch", ".", "Tensor", ",", "Optional", "[", "torch", ".", "Tensor", "]", "]", ":", "\n", "        ", "source", "=", "get_features_or_waveform", "(", "\n", "self", ".", "audio_paths", "[", "index", "]", ",", "need_waveform", "=", "self", ".", "data_cfg", ".", "use_audio_input", "\n", ")", "\n", "if", "self", ".", "feature_transforms", "is", "not", "None", ":", "\n", "            ", "assert", "not", "self", ".", "data_cfg", ".", "use_audio_input", "\n", "source", "=", "self", ".", "feature_transforms", "(", "source", ")", "\n", "", "if", "isinstance", "(", "source", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "source", "=", "torch", ".", "from_numpy", "(", "source", ")", ".", "float", "(", ")", "\n", "", "if", "self", ".", "data_cfg", ".", "use_audio_input", ":", "\n", "            ", "source", "=", "source", ".", "squeeze", "(", "0", ")", "\n", "\n", "", "target", "=", "None", "\n", "if", "self", ".", "tgt_texts", "is", "not", "None", ":", "\n", "            ", "tokenized", "=", "self", ".", "tokenize_text", "(", "self", ".", "tgt_texts", "[", "index", "]", ")", "\n", "target", "=", "self", ".", "tgt_dict", ".", "encode_line", "(", "\n", "tokenized", ",", "add_if_not_exist", "=", "False", ",", "append_eos", "=", "True", "\n", ")", ".", "long", "(", ")", "\n", "if", "self", ".", "data_cfg", ".", "prepend_tgt_lang_tag", ":", "\n", "                ", "lang_tag", "=", "self", ".", "LANG_TAG_TEMPLATE", ".", "format", "(", "self", ".", "tgt_langs", "[", "index", "]", ")", "\n", "lang_tag_idx", "=", "self", ".", "tgt_dict", ".", "index", "(", "lang_tag", ")", "\n", "target", "=", "torch", ".", "cat", "(", "(", "torch", ".", "LongTensor", "(", "[", "lang_tag_idx", "]", ")", ",", "target", ")", ",", "0", ")", "\n", "# print(\"__get_item__:\", index, source.size(), target)", "\n", "", "", "return", "index", ",", "source", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDataset.__len__": [[335, 337], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDataset.collater": [[338, 389], ["torch.tensor", "speech_to_text_dataset._collate_frames", "torch.tensor", "torch.tensor.sort", "indices.index_select.index_select.index_select", "frames.index_select.index_select.index_select", "len", "fairseq.data.data_utils.collate_tokens", "target.index_select.index_select.index_select", "torch.tensor().index_select", "fairseq.data.data_utils.collate_tokens", "prev_output_tokens.index_select.index_select.index_select", "sum", "len", "s.size", "speech_to_text_dataset.SpeechToTextDataset.tgt_dict.pad", "speech_to_text_dataset.SpeechToTextDataset.tgt_dict.eos", "speech_to_text_dataset.SpeechToTextDataset.tgt_dict.pad", "speech_to_text_dataset.SpeechToTextDataset.tgt_dict.eos", "torch.tensor", "t.size", "t.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset._collate_frames", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.collate_tokens", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.collate_tokens", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "collater", "(", "self", ",", "samples", ":", "List", "[", "Tuple", "[", "int", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", "]", ")", "->", "Dict", ":", "\n", "        ", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "            ", "return", "{", "}", "\n", "", "indices", "=", "torch", ".", "tensor", "(", "[", "i", "for", "i", ",", "_", ",", "_", "in", "samples", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "frames", "=", "_collate_frames", "(", "\n", "[", "s", "for", "_", ",", "s", ",", "_", "in", "samples", "]", ",", "self", ".", "data_cfg", ".", "use_audio_input", "\n", ")", "\n", "# sort samples by descending number of frames", "\n", "n_frames", "=", "torch", ".", "tensor", "(", "[", "s", ".", "size", "(", "0", ")", "for", "_", ",", "s", ",", "_", "in", "samples", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "n_frames", ",", "order", "=", "n_frames", ".", "sort", "(", "descending", "=", "True", ")", "\n", "indices", "=", "indices", ".", "index_select", "(", "0", ",", "order", ")", "\n", "frames", "=", "frames", ".", "index_select", "(", "0", ",", "order", ")", "\n", "\n", "target", ",", "target_lengths", "=", "None", ",", "None", "\n", "prev_output_tokens", "=", "None", "\n", "ntokens", "=", "None", "\n", "if", "self", ".", "tgt_texts", "is", "not", "None", ":", "\n", "            ", "target", "=", "fairseq_data_utils", ".", "collate_tokens", "(", "\n", "[", "t", "for", "_", ",", "_", ",", "t", "in", "samples", "]", ",", "\n", "self", ".", "tgt_dict", ".", "pad", "(", ")", ",", "\n", "self", ".", "tgt_dict", ".", "eos", "(", ")", ",", "\n", "left_pad", "=", "False", ",", "\n", "move_eos_to_beginning", "=", "False", ",", "\n", ")", "\n", "target", "=", "target", ".", "index_select", "(", "0", ",", "order", ")", "\n", "target_lengths", "=", "torch", ".", "tensor", "(", "\n", "[", "t", ".", "size", "(", "0", ")", "for", "_", ",", "_", ",", "t", "in", "samples", "]", ",", "dtype", "=", "torch", ".", "long", "\n", ")", ".", "index_select", "(", "0", ",", "order", ")", "\n", "prev_output_tokens", "=", "fairseq_data_utils", ".", "collate_tokens", "(", "\n", "[", "t", "for", "_", ",", "_", ",", "t", "in", "samples", "]", ",", "\n", "self", ".", "tgt_dict", ".", "pad", "(", ")", ",", "\n", "self", ".", "tgt_dict", ".", "eos", "(", ")", ",", "\n", "left_pad", "=", "False", ",", "\n", "move_eos_to_beginning", "=", "True", ",", "\n", ")", "\n", "prev_output_tokens", "=", "prev_output_tokens", ".", "index_select", "(", "0", ",", "order", ")", "\n", "ntokens", "=", "sum", "(", "t", ".", "size", "(", "0", ")", "for", "_", ",", "_", ",", "t", "in", "samples", ")", "\n", "\n", "", "out", "=", "{", "\n", "\"id\"", ":", "indices", ",", "\n", "\"net_input\"", ":", "{", "\n", "\"src_tokens\"", ":", "frames", ",", "\n", "\"src_lengths\"", ":", "n_frames", ",", "\n", "\"prev_output_tokens\"", ":", "prev_output_tokens", ",", "\n", "}", ",", "\n", "\"target\"", ":", "target", ",", "\n", "\"target_lengths\"", ":", "target_lengths", ",", "\n", "\"ntokens\"", ":", "ntokens", ",", "\n", "\"nsentences\"", ":", "len", "(", "samples", ")", ",", "\n", "}", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDataset.num_tokens": [[390, 392], ["None"], "methods", ["None"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "n_frames", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDataset.size": [[393, 399], ["speech_to_text_dataset.SpeechToTextDataset.tokenize_text", "len", "speech_to_text_dataset.SpeechToTextDataset.split"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDataset.tokenize_text"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "t_len", "=", "0", "\n", "if", "self", ".", "tgt_texts", "is", "not", "None", ":", "\n", "            ", "tokenized", "=", "self", ".", "tokenize_text", "(", "self", ".", "tgt_texts", "[", "index", "]", ")", "\n", "t_len", "=", "len", "(", "tokenized", ".", "split", "(", "\" \"", ")", ")", "\n", "", "return", "self", ".", "n_frames", "[", "index", "]", ",", "t_len", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDataset.sizes": [[400, 403], ["numpy.array"], "methods", ["None"], ["", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "array", "(", "self", ".", "n_frames", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDataset.can_reuse_epoch_itr_across_epochs": [[404, 407], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "can_reuse_epoch_itr_across_epochs", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDataset.ordered_indices": [[408, 416], ["order.append", "numpy.lexsort", "numpy.random.permutation", "numpy.arange", "len", "len"], "methods", ["None"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "shuffle", ":", "\n", "            ", "order", "=", "[", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ")", ")", "]", "\n", "", "else", ":", "\n", "            ", "order", "=", "[", "np", ".", "arange", "(", "len", "(", "self", ")", ")", "]", "\n", "# first by descending order of # of frames then by original/random order", "\n", "", "order", ".", "append", "(", "[", "-", "n", "for", "n", "in", "self", ".", "n_frames", "]", ")", "\n", "return", "np", ".", "lexsort", "(", "order", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDataset.prefetch": [[417, 419], ["None"], "methods", ["None"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "raise", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDatasetCreator._from_list": [[431, 472], ["speech_to_text_dataset.SpeechToTextDataset", "ids.extend", "audio_paths.extend", "n_frames.extend", "tgt_texts.extend", "src_texts.extend", "speakers.extend", "src_langs.extend", "tgt_langs.extend", "os.join", "int", "ss.get", "ss.get", "ss.get", "ss.get"], "methods", ["None"], ["@", "classmethod", "\n", "def", "_from_list", "(", "\n", "cls", ",", "\n", "split_name", ":", "str", ",", "\n", "is_train_split", ",", "\n", "samples", ":", "List", "[", "List", "[", "Dict", "]", "]", ",", "\n", "data_cfg", ":", "S2TDataConfig", ",", "\n", "tgt_dict", ",", "\n", "pre_tokenizer", ",", "\n", "bpe_tokenizer", ",", "\n", ")", "->", "SpeechToTextDataset", ":", "\n", "        ", "audio_paths", ",", "n_frames", ",", "src_texts", ",", "tgt_texts", ",", "ids", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "speakers", ",", "src_langs", ",", "tgt_langs", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "s", "in", "samples", ":", "\n", "            ", "ids", ".", "extend", "(", "[", "ss", "[", "cls", ".", "KEY_ID", "]", "for", "ss", "in", "s", "]", ")", "\n", "audio_paths", ".", "extend", "(", "\n", "[", "op", ".", "join", "(", "data_cfg", ".", "audio_root", ",", "ss", "[", "cls", ".", "KEY_AUDIO", "]", ")", "for", "ss", "in", "s", "]", "\n", ")", "\n", "n_frames", ".", "extend", "(", "[", "int", "(", "ss", "[", "cls", ".", "KEY_N_FRAMES", "]", ")", "for", "ss", "in", "s", "]", ")", "\n", "tgt_texts", ".", "extend", "(", "[", "ss", "[", "cls", ".", "KEY_TGT_TEXT", "]", "for", "ss", "in", "s", "]", ")", "\n", "src_texts", ".", "extend", "(", "\n", "[", "ss", ".", "get", "(", "cls", ".", "KEY_SRC_TEXT", ",", "cls", ".", "DEFAULT_SRC_TEXT", ")", "for", "ss", "in", "s", "]", "\n", ")", "\n", "speakers", ".", "extend", "(", "[", "ss", ".", "get", "(", "cls", ".", "KEY_SPEAKER", ",", "cls", ".", "DEFAULT_SPEAKER", ")", "for", "ss", "in", "s", "]", ")", "\n", "src_langs", ".", "extend", "(", "[", "ss", ".", "get", "(", "cls", ".", "KEY_SRC_LANG", ",", "cls", ".", "DEFAULT_LANG", ")", "for", "ss", "in", "s", "]", ")", "\n", "tgt_langs", ".", "extend", "(", "[", "ss", ".", "get", "(", "cls", ".", "KEY_TGT_LANG", ",", "cls", ".", "DEFAULT_LANG", ")", "for", "ss", "in", "s", "]", ")", "\n", "", "return", "SpeechToTextDataset", "(", "\n", "split_name", ",", "\n", "is_train_split", ",", "\n", "data_cfg", ",", "\n", "audio_paths", ",", "\n", "n_frames", ",", "\n", "src_texts", ",", "\n", "tgt_texts", ",", "\n", "speakers", ",", "\n", "src_langs", ",", "\n", "tgt_langs", ",", "\n", "ids", ",", "\n", "tgt_dict", ",", "\n", "pre_tokenizer", ",", "\n", "bpe_tokenizer", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDatasetCreator._get_size_ratios": [[474, 491], ["numpy.array", "str", "logger.info", "str", "logger.info", "str", "logger.info", "size_ratio.tolist", "numpy.array.sum", "smoothed_prob.sum", "numpy.array.sum", "enumerate", "enumerate", "enumerate"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_get_size_ratios", "(", "cls", ",", "ids", ":", "List", "[", "str", "]", ",", "sizes", ":", "List", "[", "int", "]", ",", "alpha", ":", "float", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"Size ratios for temperature-based sampling\n        (https://arxiv.org/abs/1907.05019)\"\"\"", "\n", "_sizes", "=", "np", ".", "array", "(", "sizes", ")", "\n", "prob", "=", "_sizes", "/", "_sizes", ".", "sum", "(", ")", "\n", "smoothed_prob", "=", "prob", "**", "alpha", "\n", "smoothed_prob", "=", "smoothed_prob", "/", "smoothed_prob", ".", "sum", "(", ")", "\n", "size_ratio", "=", "(", "smoothed_prob", "*", "_sizes", ".", "sum", "(", ")", ")", "/", "_sizes", "\n", "\n", "o_str", "=", "str", "(", "{", "_i", ":", "f\"{prob[i]:.3f}\"", "for", "i", ",", "_i", "in", "enumerate", "(", "ids", ")", "}", ")", "\n", "logger", ".", "info", "(", "f\"original sampling probability: {o_str}\"", ")", "\n", "p_str", "=", "str", "(", "{", "_i", ":", "f\"{smoothed_prob[i]:.3f}\"", "for", "i", ",", "_i", "in", "enumerate", "(", "ids", ")", "}", ")", "\n", "logger", ".", "info", "(", "f\"balanced sampling probability: {p_str}\"", ")", "\n", "sr_str", "=", "str", "(", "{", "_id", ":", "f\"{size_ratio[i]:.3f}\"", "for", "i", ",", "_id", "in", "enumerate", "(", "ids", ")", "}", ")", "\n", "logger", ".", "info", "(", "f\"balanced sampling size ratio: {sr_str}\"", ")", "\n", "return", "size_ratio", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDatasetCreator.from_tsv": [[492, 548], ["splits.split", "fairseq.data.ConcatDataset", "os.join", "cls._from_list", "cls._get_size_ratios", "os.isfile", "FileNotFoundError", "open", "csv.DictReader", "samples.append", "zip", "len", "fairseq.data.ResamplingDataset", "len", "len", "zip", "dict"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.audio.speech_text_triple_dataset.SpeechTextTripleDatasetCreator._from_list", "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDatasetCreator._get_size_ratios", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.isfile", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["", "@", "classmethod", "\n", "def", "from_tsv", "(", "\n", "cls", ",", "\n", "root", ":", "str", ",", "\n", "data_cfg", ":", "S2TDataConfig", ",", "\n", "splits", ":", "str", ",", "\n", "tgt_dict", ",", "\n", "pre_tokenizer", ",", "\n", "bpe_tokenizer", ",", "\n", "is_train_split", ":", "bool", ",", "\n", "epoch", ":", "int", ",", "\n", "seed", ":", "int", ",", "\n", ")", "->", "SpeechToTextDataset", ":", "\n", "        ", "samples", "=", "[", "]", "\n", "_splits", "=", "splits", ".", "split", "(", "\",\"", ")", "\n", "for", "split", "in", "_splits", ":", "\n", "            ", "tsv_path", "=", "op", ".", "join", "(", "root", ",", "f\"{split}.tsv\"", ")", "\n", "if", "not", "op", ".", "isfile", "(", "tsv_path", ")", ":", "\n", "                ", "raise", "FileNotFoundError", "(", "f\"Dataset not found: {tsv_path}\"", ")", "\n", "", "with", "open", "(", "tsv_path", ")", "as", "f", ":", "\n", "                ", "reader", "=", "csv", ".", "DictReader", "(", "\n", "f", ",", "\n", "delimiter", "=", "\"\\t\"", ",", "\n", "quotechar", "=", "None", ",", "\n", "doublequote", "=", "False", ",", "\n", "lineterminator", "=", "\"\\n\"", ",", "\n", "quoting", "=", "csv", ".", "QUOTE_NONE", ",", "\n", ")", "\n", "samples", ".", "append", "(", "[", "dict", "(", "e", ")", "for", "e", "in", "reader", "]", ")", "\n", "assert", "len", "(", "samples", ")", ">", "0", "\n", "\n", "", "", "datasets", "=", "[", "\n", "cls", ".", "_from_list", "(", "\n", "name", ",", "\n", "is_train_split", ",", "\n", "[", "s", "]", ",", "\n", "data_cfg", ",", "\n", "tgt_dict", ",", "\n", "pre_tokenizer", ",", "\n", "bpe_tokenizer", ",", "\n", ")", "\n", "for", "name", ",", "s", "in", "zip", "(", "_splits", ",", "samples", ")", "\n", "]", "\n", "\n", "if", "is_train_split", "and", "len", "(", "_splits", ")", ">", "1", "and", "data_cfg", ".", "sampling_alpha", "!=", "1.0", ":", "\n", "# temperature-based sampling", "\n", "            ", "size_ratios", "=", "cls", ".", "_get_size_ratios", "(", "\n", "_splits", ",", "[", "len", "(", "s", ")", "for", "s", "in", "samples", "]", ",", "alpha", "=", "data_cfg", ".", "sampling_alpha", "\n", ")", "\n", "datasets", "=", "[", "\n", "ResamplingDataset", "(", "\n", "d", ",", "size_ratio", "=", "r", ",", "seed", "=", "seed", ",", "epoch", "=", "epoch", ",", "replace", "=", "(", "r", ">=", "1.0", ")", "\n", ")", "\n", "for", "d", ",", "r", "in", "zip", "(", "datasets", ",", "size_ratios", ")", "\n", "]", "\n", "", "return", "ConcatDataset", "(", "datasets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.is_npy_data": [[130, 132], ["None"], "function", ["None"], ["", "", "def", "is_npy_data", "(", "data", ":", "bytes", ")", "->", "bool", ":", "\n", "    ", "return", "data", "[", "0", "]", "==", "147", "and", "data", "[", "1", "]", "==", "78", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.is_flac_or_wav_data": [[134, 138], ["None"], "function", ["None"], ["", "def", "is_flac_or_wav_data", "(", "data", ":", "bytes", ")", "->", "bool", ":", "\n", "    ", "is_flac", "=", "data", "[", "0", "]", "==", "102", "and", "data", "[", "1", "]", "==", "76", "\n", "is_wav", "=", "data", "[", "0", "]", "==", "82", "and", "data", "[", "1", "]", "==", "73", "\n", "return", "is_flac", "or", "is_wav", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.read_from_uncompressed_zip": [[140, 145], ["open", "f.seek", "f.read"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["", "def", "read_from_uncompressed_zip", "(", "file_path", ",", "offset", ",", "file_size", ")", "->", "bytes", ":", "\n", "    ", "with", "open", "(", "file_path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "seek", "(", "offset", ")", "\n", "data", "=", "f", ".", "read", "(", "file_size", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.get_features_from_npy_or_audio": [[147, 152], ["os.splitext", "ValueError", "numpy.load", "fairseq.data.audio.audio_utils.get_fbank", "os.basename"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.audio.audio_utils.get_fbank"], ["", "def", "get_features_from_npy_or_audio", "(", "path", ")", ":", "\n", "    ", "ext", "=", "op", ".", "splitext", "(", "op", ".", "basename", "(", "path", ")", ")", "[", "1", "]", "\n", "if", "ext", "not", "in", "{", "\".npy\"", ",", "\".flac\"", ",", "\".wav\"", "}", ":", "\n", "        ", "raise", "ValueError", "(", "f'Unsupported file format for \"{path}\"'", ")", "\n", "", "return", "np", ".", "load", "(", "path", ")", "if", "ext", "==", "\".npy\"", "else", "get_fbank", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.get_features_or_waveform_from_uncompressed_zip": [[154, 167], ["path.endswith", "speech_to_text_dataset.read_from_uncompressed_zip", "io.BytesIO", "speech_to_text_dataset.is_npy_data", "numpy.load", "speech_to_text_dataset.is_flac_or_wav_data", "ValueError", "fairseq.data.audio.audio_utils.get_fbank", "fairseq.data.audio.audio_utils.get_waveform"], "function", ["home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.read_from_uncompressed_zip", "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.is_npy_data", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.is_flac_or_wav_data", "home.repos.pwc.inspect_result.reneeye_const.audio.audio_utils.get_fbank", "home.repos.pwc.inspect_result.reneeye_const.audio.audio_utils.get_waveform"], ["", "def", "get_features_or_waveform_from_uncompressed_zip", "(", "\n", "path", ",", "byte_offset", ",", "byte_size", ",", "need_waveform", "=", "False", "\n", ")", ":", "\n", "    ", "assert", "path", ".", "endswith", "(", "\".zip\"", ")", "\n", "data", "=", "read_from_uncompressed_zip", "(", "path", ",", "byte_offset", ",", "byte_size", ")", "\n", "f", "=", "io", ".", "BytesIO", "(", "data", ")", "\n", "if", "is_npy_data", "(", "data", ")", ":", "\n", "        ", "features_or_waveform", "=", "np", ".", "load", "(", "f", ")", "\n", "", "elif", "is_flac_or_wav_data", "(", "data", ")", ":", "\n", "        ", "features_or_waveform", "=", "get_waveform", "(", "f", ")", "[", "0", "]", "if", "need_waveform", "else", "get_fbank", "(", "f", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f'Unknown file format for \"{path}\"'", ")", "\n", "", "return", "features_or_waveform", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.get_raw_waveform_from_audio": [[169, 172], ["fairseq.data.audio.audio_utils.get_segment_waveform"], "function", ["home.repos.pwc.inspect_result.reneeye_const.audio.audio_utils.get_segment_waveform"], ["", "def", "get_raw_waveform_from_audio", "(", "\n", "path", ",", "byte_offset", ",", "byte_size", ")", ":", "\n", "    ", "return", "get_segment_waveform", "(", "path", ",", "byte_offset", ",", "byte_size", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.get_features_or_waveform": [[174, 207], ["path.split", "os.exists", "FileNotFoundError", "len", "speech_to_text_dataset.get_features_from_npy_or_audio", "len", "_path.endswith", "ValueError", "fairseq.data.audio.audio_utils.get_waveform", "int", "speech_to_text_dataset.get_features_or_waveform_from_uncompressed_zip", "speech_to_text_dataset.get_raw_waveform_from_audio"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.MMapIndexedDataset.exists", "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.get_features_from_npy_or_audio", "home.repos.pwc.inspect_result.reneeye_const.audio.audio_utils.get_waveform", "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.get_features_or_waveform_from_uncompressed_zip", "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.get_raw_waveform_from_audio"], ["", "def", "get_features_or_waveform", "(", "path", ":", "str", ",", "need_waveform", "=", "False", ")", ":", "\n", "    ", "\"\"\"Get speech features from .npy file or waveform from .wav/.flac file.\n    The file may be inside an uncompressed ZIP file and is accessed via byte\n    offset and length.\n\n    Args:\n        path (str): File path in the format of \"<.npy/.wav/.flac path>\" or\n        \"<zip path>:<byte offset>:<byte length>\".\n        need_waveform (bool): return waveform instead of features.\n\n    Returns:\n        features_or_waveform (numpy.ndarray): speech features or waveform.\n    \"\"\"", "\n", "_path", ",", "*", "extra", "=", "path", ".", "split", "(", "\":\"", ")", "\n", "if", "not", "op", ".", "exists", "(", "_path", ")", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "f\"File not found: {_path}\"", ")", "\n", "", "if", "len", "(", "extra", ")", "==", "0", ":", "\n", "        ", "if", "need_waveform", ":", "\n", "            ", "return", "get_waveform", "(", "_path", ")", "[", "0", "]", "\n", "", "return", "get_features_from_npy_or_audio", "(", "_path", ")", "\n", "", "elif", "len", "(", "extra", ")", "==", "2", ":", "\n", "        ", "extra", "=", "[", "int", "(", "i", ")", "for", "i", "in", "extra", "]", "\n", "if", "_path", ".", "endswith", "(", "\".zip\"", ")", ":", "\n", "            ", "features_or_waveform", "=", "get_features_or_waveform_from_uncompressed_zip", "(", "\n", "_path", ",", "extra", "[", "0", "]", ",", "extra", "[", "1", "]", ",", "need_waveform", "=", "need_waveform", "\n", ")", "\n", "", "else", ":", "# _path.endswith(\".wav\")", "\n", "            ", "features_or_waveform", "=", "get_raw_waveform_from_audio", "(", "\n", "_path", ",", "extra", "[", "0", "]", ",", "extra", "[", "1", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Invalid path: {path}\"", ")", "\n", "\n", "", "return", "features_or_waveform", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset._collate_frames": [[209, 228], ["max", "enumerate", "frames[].new_zeros", "frames[].new_zeros", "frame.size", "len", "len", "frames[].size", "v.size"], "function", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "_collate_frames", "(", "\n", "frames", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "is_audio_input", ":", "bool", "=", "False", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Convert a list of 2D frames into a padded 3D tensor\n    Args:\n        frames (list): list of 2D frames of size L[i]*f_dim. Where L[i] is\n            length of i-th frame and f_dim is static dimension of features\n    Returns:\n        3D tensor of size len(frames)*len_max*f_dim where len_max is max of L[i]\n    \"\"\"", "\n", "max_len", "=", "max", "(", "frame", ".", "size", "(", "0", ")", "for", "frame", "in", "frames", ")", "\n", "if", "is_audio_input", ":", "\n", "        ", "out", "=", "frames", "[", "0", "]", ".", "new_zeros", "(", "(", "len", "(", "frames", ")", ",", "max_len", ")", ")", "\n", "", "else", ":", "\n", "        ", "out", "=", "frames", "[", "0", "]", ".", "new_zeros", "(", "(", "len", "(", "frames", ")", ",", "max_len", ",", "frames", "[", "0", "]", ".", "size", "(", "1", ")", ")", ")", "\n", "", "for", "i", ",", "v", "in", "enumerate", "(", "frames", ")", ":", "\n", "        ", "out", "[", "i", ",", ":", "v", ".", "size", "(", "0", ")", "]", "=", "v", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.audio_utils.get_waveform": [[7, 37], ["isinstance", "sf.read", "torchaudio.load", "os.splitext", "ValueError", "ImportError", "torchaudio.transforms.Resample", "torchaudio.transforms.Resample.view().numpy", "os.basename", "torchaudio.transforms.Resample.view", "torchaudio.transforms.Resample."], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load"], ["def", "get_waveform", "(", "\n", "path_or_fp", ":", "Union", "[", "str", ",", "BinaryIO", "]", ",", "normalization", "=", "True", "\n", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "int", "]", ":", "\n", "    ", "\"\"\"Get the waveform and sample rate of a 16-bit mono-channel WAV or FLAC.\n\n    Args:\n        path_or_fp (str or BinaryIO): the path or file-like object\n        normalization (bool): Normalize values to [-1, 1] (Default: True)\n    \"\"\"", "\n", "ext", "=", "\".wav\"", "\n", "if", "isinstance", "(", "path_or_fp", ",", "str", ")", ":", "\n", "        ", "ext", "=", "op", ".", "splitext", "(", "op", ".", "basename", "(", "path_or_fp", ")", ")", "[", "1", "]", "\n", "if", "ext", "not", "in", "{", "\".flac\"", ",", "\".wav\"", ",", "\".mp3\"", "}", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Unsupported audio format: {ext}\"", ")", "\n", "\n", "", "", "try", ":", "\n", "        ", "import", "soundfile", "as", "sf", "\n", "", "except", "ImportError", ":", "\n", "        ", "raise", "ImportError", "(", "\"Please install soundfile to load WAV/FLAC file\"", ")", "\n", "", "if", "ext", "in", "{", "\".flac\"", ",", "\".wav\"", "}", ":", "\n", "        ", "waveform", ",", "sample_rate", "=", "sf", ".", "read", "(", "path_or_fp", ",", "dtype", "=", "\"float32\"", ")", "\n", "", "else", ":", "# mp3 file, eg. commonvoice", "\n", "        ", "waveform", ",", "sr", "=", "torchaudio", ".", "load", "(", "path_or_fp", ")", "\n", "if", "sr", "!=", "16000", ":", "\n", "            ", "resample", "=", "torchaudio", ".", "transforms", ".", "Resample", "(", "orig_freq", "=", "sr", ",", "new_freq", "=", "16000", ")", "\n", "waveform", "=", "resample", "(", "waveform", ")", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", "\n", "sample_rate", "=", "16000", "\n", "", "", "if", "not", "normalization", ":", "\n", "        ", "waveform", "*=", "2", "**", "15", "# denormalized to 16-bit signed integers", "\n", "", "return", "waveform", ",", "sample_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.audio_utils.get_segment_waveform": [[39, 51], ["isinstance", "torchaudio.load", "os.splitext", "ValueError", "os.basename"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load"], ["", "def", "get_segment_waveform", "(", "\n", "path_or_fp", ",", "offset", ",", "n_frames", ",", "normalization", "=", "True", "\n", ")", ":", "\n", "    ", "if", "isinstance", "(", "path_or_fp", ",", "str", ")", ":", "\n", "        ", "ext", "=", "op", ".", "splitext", "(", "op", ".", "basename", "(", "path_or_fp", ")", ")", "[", "1", "]", "\n", "if", "ext", "not", "in", "{", "\".flac\"", ",", "\".wav\"", "}", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Unsupported audio format: {ext}\"", ")", "\n", "\n", "", "", "waveform", ",", "sample_rate", "=", "torchaudio", ".", "load", "(", "path_or_fp", ",", "frame_offset", "=", "offset", ",", "num_frames", "=", "n_frames", ")", "\n", "if", "not", "normalization", ":", "\n", "        ", "waveform", "*=", "2", "**", "15", "\n", "", "return", "waveform", ",", "sample_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.audio_utils._get_kaldi_fbank": [[53, 73], ["MelBanksOptions", "FrameExtractionOptions", "FbankOptions", "Fbank", "Fbank.compute().numpy", "Fbank.compute", "Vector"], "function", ["None"], ["", "def", "_get_kaldi_fbank", "(", "waveform", ",", "sample_rate", ",", "n_bins", "=", "80", ")", "->", "Optional", "[", "np", ".", "ndarray", "]", ":", "\n", "    ", "\"\"\"Get mel-filter bank features via PyKaldi.\"\"\"", "\n", "try", ":", "\n", "        ", "from", "kaldi", ".", "feat", ".", "mel", "import", "MelBanksOptions", "\n", "from", "kaldi", ".", "feat", ".", "fbank", "import", "FbankOptions", ",", "Fbank", "\n", "from", "kaldi", ".", "feat", ".", "window", "import", "FrameExtractionOptions", "\n", "from", "kaldi", ".", "matrix", "import", "Vector", "\n", "\n", "mel_opts", "=", "MelBanksOptions", "(", ")", "\n", "mel_opts", ".", "num_bins", "=", "n_bins", "\n", "frame_opts", "=", "FrameExtractionOptions", "(", ")", "\n", "frame_opts", ".", "samp_freq", "=", "sample_rate", "\n", "opts", "=", "FbankOptions", "(", ")", "\n", "opts", ".", "mel_opts", "=", "mel_opts", "\n", "opts", ".", "frame_opts", "=", "frame_opts", "\n", "fbank", "=", "Fbank", "(", "opts", "=", "opts", ")", "\n", "features", "=", "fbank", ".", "compute", "(", "Vector", "(", "waveform", ")", ",", "1.0", ")", ".", "numpy", "(", ")", "\n", "return", "features", "\n", "", "except", "ImportError", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.audio_utils._get_torchaudio_fbank": [[75, 88], ["torch.from_numpy().unsqueeze", "ta_kaldi.fbank", "ta_kaldi.fbank.numpy", "torch.from_numpy"], "function", ["None"], ["", "", "def", "_get_torchaudio_fbank", "(", "waveform", ",", "sample_rate", ",", "n_bins", "=", "80", ")", "->", "Optional", "[", "np", ".", "ndarray", "]", ":", "\n", "    ", "\"\"\"Get mel-filter bank features via TorchAudio.\"\"\"", "\n", "try", ":", "\n", "        ", "import", "torch", "\n", "import", "torchaudio", ".", "compliance", ".", "kaldi", "as", "ta_kaldi", "\n", "\n", "waveform", "=", "torch", ".", "from_numpy", "(", "waveform", ")", ".", "unsqueeze", "(", "0", ")", "\n", "features", "=", "ta_kaldi", ".", "fbank", "(", "\n", "waveform", ",", "num_mel_bins", "=", "n_bins", ",", "sample_frequency", "=", "sample_rate", "\n", ")", "\n", "return", "features", ".", "numpy", "(", ")", "\n", "", "except", "ImportError", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.audio_utils.get_fbank": [[90, 107], ["audio_utils.get_waveform", "audio_utils._get_kaldi_fbank", "audio_utils._get_torchaudio_fbank", "ImportError"], "function", ["home.repos.pwc.inspect_result.reneeye_const.audio.audio_utils.get_waveform", "home.repos.pwc.inspect_result.reneeye_const.audio.audio_utils._get_kaldi_fbank", "home.repos.pwc.inspect_result.reneeye_const.audio.audio_utils._get_torchaudio_fbank"], ["", "", "def", "get_fbank", "(", "path_or_fp", ":", "Union", "[", "str", ",", "BinaryIO", "]", ",", "n_bins", "=", "80", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"Get mel-filter bank features via PyKaldi or TorchAudio. Prefer PyKaldi\n    (faster CPP implementation) to TorchAudio (Python implementation). Note that\n    Kaldi/TorchAudio requires 16-bit signed integers as inputs and hence the\n    waveform should not be normalized.\"\"\"", "\n", "sound", ",", "sample_rate", "=", "get_waveform", "(", "path_or_fp", ",", "normalization", "=", "False", ")", "\n", "\n", "features", "=", "_get_kaldi_fbank", "(", "sound", ",", "sample_rate", ",", "n_bins", ")", "\n", "if", "features", "is", "None", ":", "\n", "        ", "features", "=", "_get_torchaudio_fbank", "(", "sound", ",", "sample_rate", ",", "n_bins", ")", "\n", "", "if", "features", "is", "None", ":", "\n", "        ", "raise", "ImportError", "(", "\n", "\"Please install pyKaldi or torchaudio to enable \"", "\n", "\"online filterbank feature extraction\"", "\n", ")", "\n", "\n", "", "return", "features", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_text_triple_dataset.SpeechTextTripleDataset.__init__": [[34, 59], ["fairseq.data.audio.speech_to_text_dataset.SpeechToTextDataset.__init__", "speech_text_triple_dataset.SpeechTextTripleDataset.check_src_lang_tag"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.audio.speech_text_triple_dataset.SpeechTextTripleDataset.check_src_lang_tag"], ["def", "__init__", "(", "\n", "self", ",", "\n", "split", ":", "str", ",", "\n", "is_train_split", ":", "bool", ",", "\n", "data_cfg", ":", "S2TDataConfig", ",", "\n", "audio_paths", ":", "List", "[", "str", "]", ",", "\n", "n_frames", ":", "List", "[", "int", "]", ",", "\n", "src_texts", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "tgt_texts", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "speakers", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "src_langs", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "tgt_langs", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "ids", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "tgt_dict", ":", "Optional", "[", "Dictionary", "]", "=", "None", ",", "\n", "pre_tokenizer", "=", "None", ",", "\n", "bpe_tokenizer", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "split", ",", "is_train_split", ",", "\n", "data_cfg", ",", "audio_paths", ",", "n_frames", ",", "\n", "src_texts", ",", "tgt_texts", ",", "speakers", ",", "src_langs", ",", "tgt_langs", ",", "\n", "ids", ",", "tgt_dict", ",", "pre_tokenizer", ",", "bpe_tokenizer", ")", "\n", "self", ".", "dataset_type", "=", "\"st\"", "# default", "\n", "if", "\"mt\"", "in", "split", ":", "\n", "            ", "self", ".", "dataset_type", "=", "\"mt\"", "\n", "", "self", ".", "check_src_lang_tag", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_text_triple_dataset.SpeechTextTripleDataset.check_src_lang_tag": [[60, 67], ["all", "speech_text_triple_dataset.SpeechTextTripleDataset.LANG_TAG_TEMPLATE.format", "set"], "methods", ["None"], ["", "def", "check_src_lang_tag", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "data_cfg", ".", "prepend_src_lang_tag", ":", "\n", "            ", "assert", "self", ".", "src_langs", "is", "not", "None", "and", "self", ".", "tgt_dict", "is", "not", "None", "\n", "src_lang_tags", "=", "[", "\n", "self", ".", "LANG_TAG_TEMPLATE", ".", "format", "(", "t", ")", "for", "t", "in", "set", "(", "self", ".", "src_langs", ")", "\n", "]", "\n", "assert", "all", "(", "t", "in", "self", ".", "tgt_dict", "for", "t", "in", "src_lang_tags", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_text_triple_dataset.SpeechTextTripleDataset.__getitem__": [[68, 108], ["fairseq.data.audio.speech_to_text_dataset.get_features_or_waveform", "isinstance", "speech_text_triple_dataset.SpeechTextTripleDataset.tokenize_text", "speech_text_triple_dataset.SpeechTextTripleDataset.tgt_dict.encode_line().long", "speech_text_triple_dataset.SpeechTextTripleDataset.tokenize_text", "speech_text_triple_dataset.SpeechTextTripleDataset.tgt_dict.encode_line().long", "speech_text_triple_dataset.SpeechTextTripleDataset.feature_transforms", "torch.from_numpy().float", "audio.squeeze.squeeze.squeeze", "speech_text_triple_dataset.SpeechTextTripleDataset.LANG_TAG_TEMPLATE.format", "speech_text_triple_dataset.SpeechTextTripleDataset.tgt_dict.index", "torch.cat", "speech_text_triple_dataset.SpeechTextTripleDataset.LANG_TAG_TEMPLATE.format", "speech_text_triple_dataset.SpeechTextTripleDataset.tgt_dict.index", "torch.cat", "speech_text_triple_dataset.SpeechTextTripleDataset.tgt_dict.encode_line", "speech_text_triple_dataset.SpeechTextTripleDataset.tgt_dict.encode_line", "torch.from_numpy", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.get_features_or_waveform", "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDataset.tokenize_text", "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDataset.tokenize_text", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.index", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.index", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.encode_line", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.encode_line"], ["", "", "def", "__getitem__", "(", "\n", "self", ",", "index", ":", "int", "\n", ")", "->", "Tuple", "[", "int", ",", "torch", ".", "Tensor", ",", "Optional", "[", "torch", ".", "Tensor", "]", ",", "Optional", "[", "torch", ".", "Tensor", "]", "]", ":", "\n", "\n", "        ", "audio", "=", "None", "\n", "if", "self", ".", "dataset_type", "==", "\"st\"", ":", "\n", "            ", "audio", "=", "get_features_or_waveform", "(", "\n", "self", ".", "audio_paths", "[", "index", "]", ",", "need_waveform", "=", "self", ".", "data_cfg", ".", "use_audio_input", "\n", ")", "\n", "if", "self", ".", "feature_transforms", "is", "not", "None", ":", "\n", "                ", "assert", "not", "self", ".", "data_cfg", ".", "use_audio_input", "\n", "audio", "=", "self", ".", "feature_transforms", "(", "audio", ")", "\n", "", "if", "isinstance", "(", "audio", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "audio", "=", "torch", ".", "from_numpy", "(", "audio", ")", ".", "float", "(", ")", "\n", "", "if", "self", ".", "data_cfg", ".", "use_audio_input", ":", "\n", "                ", "audio", "=", "audio", ".", "squeeze", "(", "0", ")", "\n", "\n", "", "", "src_text", "=", "None", "\n", "if", "self", ".", "src_texts", "is", "not", "None", ":", "\n", "            ", "tokenized", "=", "self", ".", "tokenize_text", "(", "self", ".", "src_texts", "[", "index", "]", ")", "\n", "src_text", "=", "self", ".", "tgt_dict", ".", "encode_line", "(", "\n", "tokenized", ",", "add_if_not_exist", "=", "False", ",", "append_eos", "=", "True", "\n", ")", ".", "long", "(", ")", "\n", "if", "self", ".", "data_cfg", ".", "prepend_src_lang_tag", ":", "\n", "                ", "lang_tag", "=", "self", ".", "LANG_TAG_TEMPLATE", ".", "format", "(", "self", ".", "src_langs", "[", "index", "]", ")", "\n", "lang_tag_idx", "=", "self", ".", "tgt_dict", ".", "index", "(", "lang_tag", ")", "\n", "src_text", "=", "torch", ".", "cat", "(", "(", "torch", ".", "LongTensor", "(", "[", "lang_tag_idx", "]", ")", ",", "src_text", ")", ",", "0", ")", "\n", "\n", "", "", "tgt_text", "=", "None", "\n", "if", "self", ".", "tgt_texts", "is", "not", "None", ":", "\n", "            ", "tokenized", "=", "self", ".", "tokenize_text", "(", "self", ".", "tgt_texts", "[", "index", "]", ")", "\n", "tgt_text", "=", "self", ".", "tgt_dict", ".", "encode_line", "(", "\n", "tokenized", ",", "add_if_not_exist", "=", "False", ",", "append_eos", "=", "True", "\n", ")", ".", "long", "(", ")", "\n", "if", "self", ".", "data_cfg", ".", "prepend_tgt_lang_tag", ":", "\n", "                ", "lang_tag", "=", "self", ".", "LANG_TAG_TEMPLATE", ".", "format", "(", "self", ".", "tgt_langs", "[", "index", "]", ")", "\n", "lang_tag_idx", "=", "self", ".", "tgt_dict", ".", "index", "(", "lang_tag", ")", "\n", "tgt_text", "=", "torch", ".", "cat", "(", "(", "torch", ".", "LongTensor", "(", "[", "lang_tag_idx", "]", ")", ",", "tgt_text", ")", ",", "0", ")", "\n", "\n", "", "", "return", "index", ",", "audio", ",", "src_text", ",", "tgt_text", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_text_triple_dataset.SpeechTextTripleDataset.collater": [[109, 199], ["torch.tensor", "len", "fairseq.data.audio.speech_to_text_dataset._collate_frames", "torch.tensor", "torch.tensor.sort", "indices.index_select.index_select.index_select", "frames.index_select.index_select.index_select", "fairseq.data.data_utils.collate_tokens", "source.index_select.index_select.index_select", "sum", "fairseq.data.data_utils.collate_tokens", "prev_output_source_tokens.index_select.index_select.index_select", "fairseq.data.data_utils.collate_tokens", "target.index_select.index_select.index_select", "torch.tensor().index_select", "fairseq.data.data_utils.collate_tokens", "prev_output_target_tokens.index_select.index_select.index_select", "sum", "len", "speech_text_triple_dataset.SpeechTextTripleDataset.tgt_dict.pad", "speech_text_triple_dataset.SpeechTextTripleDataset.tgt_dict.eos", "torch.tensor", "torch.tensor().index_select.sort", "torch.tensor().index_select", "speech_text_triple_dataset.SpeechTextTripleDataset.tgt_dict.pad", "speech_text_triple_dataset.SpeechTextTripleDataset.tgt_dict.eos", "speech_text_triple_dataset.SpeechTextTripleDataset.tgt_dict.pad", "speech_text_triple_dataset.SpeechTextTripleDataset.tgt_dict.eos", "speech_text_triple_dataset.SpeechTextTripleDataset.tgt_dict.pad", "speech_text_triple_dataset.SpeechTextTripleDataset.tgt_dict.eos", "s.size", "s.size", "torch.tensor", "t.size", "s.size", "torch.tensor", "t.size", "s.size"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset._collate_frames", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.collate_tokens", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.collate_tokens", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.collate_tokens", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.collate_tokens", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size", "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size"], ["", "def", "collater", "(", "self", ",", "samples", ":", "List", "[", "Tuple", "[", "int", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", "]", ")", "->", "Dict", ":", "\n", "        ", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "            ", "return", "{", "}", "\n", "", "indices", "=", "torch", ".", "tensor", "(", "[", "i", "for", "i", ",", "_", ",", "_", ",", "_", "in", "samples", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "self", ".", "dataset_type", "==", "\"st\"", ":", "\n", "            ", "frames", "=", "_collate_frames", "(", "\n", "[", "s", "for", "_", ",", "s", ",", "_", ",", "_", "in", "samples", "]", ",", "self", ".", "data_cfg", ".", "use_audio_input", "\n", ")", "\n", "# sort samples by descending number of frames", "\n", "n_frames", "=", "torch", ".", "tensor", "(", "[", "s", ".", "size", "(", "0", ")", "for", "_", ",", "s", ",", "_", ",", "_", "in", "samples", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "n_frames", ",", "order", "=", "n_frames", ".", "sort", "(", "descending", "=", "True", ")", "\n", "indices", "=", "indices", ".", "index_select", "(", "0", ",", "order", ")", "\n", "frames", "=", "frames", ".", "index_select", "(", "0", ",", "order", ")", "\n", "", "else", ":", "\n", "            ", "frames", ",", "n_frames", "=", "None", ",", "None", "\n", "order", "=", "indices", "\n", "# process source text", "\n", "", "source", ",", "source_lengths", "=", "None", ",", "None", "\n", "prev_output_source_tokens", "=", "None", "\n", "src_ntokens", "=", "None", "\n", "if", "self", ".", "src_texts", "is", "not", "None", ":", "\n", "            ", "source", "=", "fairseq_data_utils", ".", "collate_tokens", "(", "\n", "[", "s", "for", "_", ",", "_", ",", "s", ",", "_", "in", "samples", "]", ",", "\n", "self", ".", "tgt_dict", ".", "pad", "(", ")", ",", "self", ".", "tgt_dict", ".", "eos", "(", ")", ",", "\n", "left_pad", "=", "False", ",", "\n", "move_eos_to_beginning", "=", "False", ",", "\n", ")", "\n", "\n", "if", "self", ".", "dataset_type", "==", "\"mt\"", ":", "\n", "                ", "source_lengths", "=", "torch", ".", "tensor", "(", "[", "s", ".", "size", "(", "0", ")", "for", "_", ",", "_", ",", "s", ",", "_", "in", "samples", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "source_lengths", ",", "order", "=", "source_lengths", ".", "sort", "(", "descending", "=", "True", ")", "\n", "\n", "", "source", "=", "source", ".", "index_select", "(", "0", ",", "order", ")", "\n", "if", "self", ".", "dataset_type", "==", "\"st\"", ":", "\n", "                ", "source_lengths", "=", "torch", ".", "tensor", "(", "\n", "[", "s", ".", "size", "(", ")", "for", "_", ",", "_", ",", "s", ",", "_", "in", "samples", "]", ",", "dtype", "=", "torch", ".", "long", "\n", ")", ".", "index_select", "(", "0", ",", "order", ")", "\n", "", "src_ntokens", "=", "sum", "(", "s", ".", "size", "(", "0", ")", "for", "_", ",", "_", ",", "s", ",", "_", "in", "samples", ")", "\n", "prev_output_source_tokens", "=", "fairseq_data_utils", ".", "collate_tokens", "(", "\n", "[", "s", "for", "_", ",", "_", ",", "s", ",", "_", "in", "samples", "]", ",", "\n", "self", ".", "tgt_dict", ".", "pad", "(", ")", ",", "\n", "self", ".", "tgt_dict", ".", "eos", "(", ")", ",", "\n", "left_pad", "=", "False", ",", "\n", "move_eos_to_beginning", "=", "True", ",", "\n", ")", "\n", "prev_output_source_tokens", "=", "prev_output_source_tokens", ".", "index_select", "(", "0", ",", "order", ")", "\n", "# process target text", "\n", "", "target", ",", "target_lengths", "=", "None", ",", "None", "\n", "prev_output_target_tokens", "=", "None", "\n", "tgt_ntokens", "=", "None", "\n", "if", "self", ".", "tgt_texts", "is", "not", "None", ":", "\n", "            ", "target", "=", "fairseq_data_utils", ".", "collate_tokens", "(", "\n", "[", "t", "for", "_", ",", "_", ",", "_", ",", "t", "in", "samples", "]", ",", "\n", "self", ".", "tgt_dict", ".", "pad", "(", ")", ",", "\n", "self", ".", "tgt_dict", ".", "eos", "(", ")", ",", "\n", "left_pad", "=", "False", ",", "\n", "move_eos_to_beginning", "=", "False", ",", "\n", ")", "\n", "target", "=", "target", ".", "index_select", "(", "0", ",", "order", ")", "\n", "target_lengths", "=", "torch", ".", "tensor", "(", "\n", "[", "t", ".", "size", "(", "0", ")", "for", "_", ",", "_", ",", "_", ",", "t", "in", "samples", "]", ",", "dtype", "=", "torch", ".", "long", "\n", ")", ".", "index_select", "(", "0", ",", "order", ")", "\n", "prev_output_target_tokens", "=", "fairseq_data_utils", ".", "collate_tokens", "(", "\n", "[", "t", "for", "_", ",", "_", ",", "_", ",", "t", "in", "samples", "]", ",", "\n", "self", ".", "tgt_dict", ".", "pad", "(", ")", ",", "\n", "self", ".", "tgt_dict", ".", "eos", "(", ")", ",", "\n", "left_pad", "=", "False", ",", "\n", "move_eos_to_beginning", "=", "True", ",", "\n", ")", "\n", "prev_output_target_tokens", "=", "prev_output_target_tokens", ".", "index_select", "(", "0", ",", "order", ")", "\n", "tgt_ntokens", "=", "sum", "(", "t", ".", "size", "(", "0", ")", "for", "_", ",", "_", ",", "_", ",", "t", "in", "samples", ")", "\n", "\n", "", "out", "=", "{", "\n", "\"id\"", ":", "indices", ",", "\n", "\"net_input\"", ":", "{", "\n", "\"src_tokens\"", ":", "frames", ",", "\n", "\"src_lengths\"", ":", "n_frames", ",", "\n", "\"prev_output_tokens\"", ":", "prev_output_target_tokens", ",", "\n", "}", ",", "\n", "\"target\"", ":", "target", ",", "\n", "\"target_lengths\"", ":", "target_lengths", ",", "\n", "\"target_ntokens\"", ":", "tgt_ntokens", ",", "\n", "\"nsentences\"", ":", "len", "(", "samples", ")", ",", "\n", "\"source\"", ":", "source", ",", "\n", "\"source_lengths\"", ":", "source_lengths", ",", "\n", "\"source_ntokens\"", ":", "src_ntokens", ",", "\n", "\"prev_output_src_tokens\"", ":", "prev_output_source_tokens", ",", "\n", "\"dataset_type\"", ":", "self", ".", "dataset_type", "\n", "}", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_text_triple_dataset.SpeechTextTripleDatasetCreator._from_list": [[203, 244], ["speech_text_triple_dataset.SpeechTextTripleDataset", "ids.extend", "audio_paths.extend", "n_frames.extend", "tgt_texts.extend", "src_texts.extend", "speakers.extend", "src_langs.extend", "tgt_langs.extend", "ss.get", "os.path.join", "int", "ss.get", "ss.get", "ss.get", "ss.get", "ss.get", "ss.get"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "_from_list", "(", "\n", "cls", ",", "\n", "split_name", ":", "str", ",", "\n", "is_train_split", ",", "\n", "samples", ":", "List", "[", "List", "[", "Dict", "]", "]", ",", "\n", "data_cfg", ":", "S2TDataConfig", ",", "\n", "tgt_dict", ",", "\n", "pre_tokenizer", ",", "\n", "bpe_tokenizer", ",", "\n", ")", "->", "SpeechTextTripleDataset", ":", "\n", "        ", "audio_paths", ",", "n_frames", ",", "src_texts", ",", "tgt_texts", ",", "ids", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "speakers", ",", "src_langs", ",", "tgt_langs", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "s", "in", "samples", ":", "\n", "            ", "ids", ".", "extend", "(", "[", "ss", ".", "get", "(", "cls", ".", "KEY_ID", ",", "None", ")", "for", "ss", "in", "s", "]", ")", "\n", "audio_paths", ".", "extend", "(", "\n", "[", "os", ".", "path", ".", "join", "(", "data_cfg", ".", "audio_root", ",", "ss", ".", "get", "(", "cls", ".", "KEY_AUDIO", ",", "\"\"", ")", ")", "for", "ss", "in", "s", "]", "\n", ")", "\n", "n_frames", ".", "extend", "(", "[", "int", "(", "ss", ".", "get", "(", "cls", ".", "KEY_N_FRAMES", ",", "0", ")", ")", "for", "ss", "in", "s", "]", ")", "\n", "tgt_texts", ".", "extend", "(", "[", "ss", "[", "cls", ".", "KEY_TGT_TEXT", "]", "for", "ss", "in", "s", "]", ")", "\n", "src_texts", ".", "extend", "(", "\n", "[", "ss", ".", "get", "(", "cls", ".", "KEY_SRC_TEXT", ",", "cls", ".", "DEFAULT_SRC_TEXT", ")", "for", "ss", "in", "s", "]", "\n", ")", "\n", "speakers", ".", "extend", "(", "[", "ss", ".", "get", "(", "cls", ".", "KEY_SPEAKER", ",", "cls", ".", "DEFAULT_SPEAKER", ")", "for", "ss", "in", "s", "]", ")", "\n", "src_langs", ".", "extend", "(", "[", "ss", ".", "get", "(", "cls", ".", "KEY_SRC_LANG", ",", "cls", ".", "DEFAULT_LANG", ")", "for", "ss", "in", "s", "]", ")", "\n", "tgt_langs", ".", "extend", "(", "[", "ss", ".", "get", "(", "cls", ".", "KEY_TGT_LANG", ",", "cls", ".", "DEFAULT_LANG", ")", "for", "ss", "in", "s", "]", ")", "\n", "", "return", "SpeechTextTripleDataset", "(", "\n", "split_name", ",", "\n", "is_train_split", ",", "\n", "data_cfg", ",", "\n", "audio_paths", ",", "\n", "n_frames", ",", "\n", "src_texts", ",", "\n", "tgt_texts", ",", "\n", "speakers", ",", "\n", "src_langs", ",", "\n", "tgt_langs", ",", "\n", "ids", ",", "\n", "tgt_dict", ",", "\n", "pre_tokenizer", ",", "\n", "bpe_tokenizer", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.audio.speech_text_triple_dataset.SpeechTextTripleDatasetCreator.from_tsv": [[246, 296], ["splits.split", "fairseq.data.ConcatDataset", "os.path.join", "cls._from_list", "cls._get_size_ratios", "os.path.isfile", "FileNotFoundError", "open", "csv.DictReader", "samples.append", "zip", "len", "fairseq.data.ResamplingDataset", "len", "len", "zip", "dict"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.audio.speech_text_triple_dataset.SpeechTextTripleDatasetCreator._from_list", "home.repos.pwc.inspect_result.reneeye_const.audio.speech_to_text_dataset.SpeechToTextDatasetCreator._get_size_ratios", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.isfile", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["", "@", "classmethod", "\n", "def", "from_tsv", "(", "\n", "cls", ",", "\n", "root", ":", "str", ",", "\n", "data_cfg", ":", "S2TDataConfig", ",", "\n", "splits", ":", "str", ",", "\n", "tgt_dict", ",", "\n", "pre_tokenizer", ",", "\n", "bpe_tokenizer", ",", "\n", "is_train_split", ":", "bool", ",", "\n", "epoch", ":", "int", ",", "\n", "seed", ":", "int", ",", "\n", ")", "->", "SpeechTextTripleDataset", ":", "\n", "        ", "samples", "=", "[", "]", "\n", "_splits", "=", "splits", ".", "split", "(", "\",\"", ")", "\n", "for", "split", "in", "_splits", ":", "\n", "            ", "tsv_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "f\"{split}.tsv\"", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "tsv_path", ")", ":", "\n", "                ", "raise", "FileNotFoundError", "(", "f\"Dataset not found: {tsv_path}\"", ")", "\n", "", "with", "open", "(", "tsv_path", ")", "as", "f", ":", "\n", "                ", "reader", "=", "csv", ".", "DictReader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "None", ",", "\n", "doublequote", "=", "False", ",", "lineterminator", "=", "\"\\n\"", ",", "\n", "quoting", "=", "csv", ".", "QUOTE_NONE", ")", "\n", "samples", ".", "append", "(", "[", "dict", "(", "e", ")", "for", "e", "in", "reader", "]", ")", "\n", "assert", "len", "(", "samples", ")", ">", "0", "\n", "\n", "", "", "datasets", "=", "[", "\n", "cls", ".", "_from_list", "(", "\n", "name", ",", "\n", "is_train_split", ",", "\n", "[", "s", "]", ",", "\n", "data_cfg", ",", "\n", "tgt_dict", ",", "\n", "pre_tokenizer", ",", "\n", "bpe_tokenizer", ",", "\n", ")", "\n", "for", "name", ",", "s", "in", "zip", "(", "_splits", ",", "samples", ")", "\n", "]", "\n", "\n", "if", "is_train_split", "and", "len", "(", "_splits", ")", ">", "1", "and", "data_cfg", ".", "sampling_alpha", "!=", "1.0", ":", "\n", "            ", "size_ratios", "=", "cls", ".", "_get_size_ratios", "(", "\n", "_splits", ",", "[", "len", "(", "s", ")", "for", "s", "in", "samples", "]", ",", "alpha", "=", "data_cfg", ".", "sampling_alpha", "\n", ")", "\n", "datasets", "=", "[", "\n", "ResamplingDataset", "(", "\n", "d", ",", "size_ratio", "=", "r", ",", "seed", "=", "seed", ",", "epoch", "=", "epoch", ",", "replace", "=", "(", "r", ">=", "1.0", ")", "\n", ")", "\n", "for", "d", ",", "r", "in", "zip", "(", "datasets", ",", "size_ratios", ")", "\n", "]", "\n", "", "return", "ConcatDataset", "(", "datasets", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.feature_transforms.global_cmvn.GlobalCMVN.from_config_dict": [[13, 17], ["global_cmvn.GlobalCMVN", "_config.get"], "methods", ["None"], ["@", "classmethod", "\n", "def", "from_config_dict", "(", "cls", ",", "config", "=", "None", ")", ":", "\n", "        ", "_config", "=", "{", "}", "if", "config", "is", "None", "else", "config", "\n", "return", "GlobalCMVN", "(", "_config", ".", "get", "(", "\"stats_npz_path\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.feature_transforms.global_cmvn.GlobalCMVN.__init__": [[18, 21], ["numpy.load"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load"], ["", "def", "__init__", "(", "self", ",", "stats_npz_path", ")", ":", "\n", "        ", "stats", "=", "np", ".", "load", "(", "stats_npz_path", ")", "\n", "self", ".", "mean", ",", "self", ".", "std", "=", "stats", "[", "\"mean\"", "]", ",", "stats", "[", "\"std\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.feature_transforms.global_cmvn.GlobalCMVN.__call__": [[22, 26], ["numpy.subtract", "numpy.divide"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "np", ".", "subtract", "(", "x", ",", "self", ".", "mean", ")", "\n", "x", "=", "np", ".", "divide", "(", "x", ",", "self", ".", "std", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.feature_transforms.__init__.AudioFeatureTransform.from_config_dict": [[8, 12], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.feature_transforms.__init__.CompositeAudioFeatureTransform.from_config_dict": [[56, 67], ["_config.get", "__init__.CompositeAudioFeatureTransform", "get_audio_feature_transform().from_config_dict", "_config.get", "__init__.get_audio_feature_transform"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.feature_transforms.specaugment.SpecAugmentTransform.from_config_dict", "home.repos.pwc.inspect_result.reneeye_const.feature_transforms.__init__.get_audio_feature_transform"], []], "home.repos.pwc.inspect_result.reneeye_const.feature_transforms.__init__.CompositeAudioFeatureTransform.__init__": [[68, 70], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.feature_transforms.__init__.CompositeAudioFeatureTransform.__call__": [[71, 75], ["t"], "methods", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.feature_transforms.__init__.CompositeAudioFeatureTransform.__repr__": [[76, 83], ["t.__repr__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.feature_transforms.specaugment.SpecAugmentTransform.__repr__"], []], "home.repos.pwc.inspect_result.reneeye_const.feature_transforms.__init__.register_audio_feature_transform": [[18, 37], ["AUDIO_FEATURE_TRANSFORM_CLASS_NAMES.add", "ValueError", "issubclass", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add"], []], "home.repos.pwc.inspect_result.reneeye_const.feature_transforms.__init__.get_audio_feature_transform": [[39, 41], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.reneeye_const.feature_transforms.utterance_cmvn.UtteranceCMVN.from_config_dict": [[12, 18], ["utterance_cmvn.UtteranceCMVN", "_config.get", "_config.get"], "methods", ["None"], ["@", "classmethod", "\n", "def", "from_config_dict", "(", "cls", ",", "config", "=", "None", ")", ":", "\n", "        ", "_config", "=", "{", "}", "if", "config", "is", "None", "else", "config", "\n", "return", "UtteranceCMVN", "(", "\n", "_config", ".", "get", "(", "\"norm_means\"", ",", "True", ")", ",", "\n", "_config", ".", "get", "(", "\"norm_vars\"", ",", "True", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.feature_transforms.utterance_cmvn.UtteranceCMVN.__init__": [[20, 22], ["None"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "norm_means", "=", "True", ",", "norm_vars", "=", "True", ")", ":", "\n", "        ", "self", ".", "norm_means", ",", "self", ".", "norm_vars", "=", "norm_means", ",", "norm_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.feature_transforms.utterance_cmvn.UtteranceCMVN.__repr__": [[23, 27], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "__class__", ".", "__name__", "\n", "+", "f\"(norm_means={self.norm_means}, norm_vars={self.norm_vars})\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.feature_transforms.utterance_cmvn.UtteranceCMVN.__call__": [[29, 41], ["numpy.divide.mean", "numpy.subtract", "numpy.sqrt", "numpy.divide", "numpy.maximum"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "mean", "=", "x", ".", "mean", "(", "axis", "=", "0", ")", "\n", "square_sums", "=", "(", "x", "**", "2", ")", ".", "sum", "(", "axis", "=", "0", ")", "\n", "\n", "if", "self", ".", "norm_means", ":", "\n", "            ", "x", "=", "np", ".", "subtract", "(", "x", ",", "mean", ")", "\n", "", "if", "self", ".", "norm_vars", ":", "\n", "            ", "var", "=", "square_sums", "/", "x", ".", "shape", "[", "0", "]", "-", "mean", "**", "2", "\n", "std", "=", "np", ".", "sqrt", "(", "np", ".", "maximum", "(", "var", ",", "1e-10", ")", ")", "\n", "x", "=", "np", ".", "divide", "(", "x", ",", "std", ")", "\n", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.feature_transforms.specaugment.SpecAugmentTransform.from_config_dict": [[16, 27], ["specaugment.SpecAugmentTransform", "_config.get", "_config.get", "_config.get", "_config.get", "_config.get", "_config.get", "_config.get"], "methods", ["None"], ["@", "classmethod", "\n", "def", "from_config_dict", "(", "cls", ",", "config", "=", "None", ")", ":", "\n", "        ", "_config", "=", "{", "}", "if", "config", "is", "None", "else", "config", "\n", "return", "SpecAugmentTransform", "(", "\n", "_config", ".", "get", "(", "\"time_warp_W\"", ",", "0", ")", ",", "\n", "_config", ".", "get", "(", "\"freq_mask_N\"", ",", "0", ")", ",", "\n", "_config", ".", "get", "(", "\"freq_mask_F\"", ",", "0", ")", ",", "\n", "_config", ".", "get", "(", "\"time_mask_N\"", ",", "0", ")", ",", "\n", "_config", ".", "get", "(", "\"time_mask_T\"", ",", "0", ")", ",", "\n", "_config", ".", "get", "(", "\"time_mask_p\"", ",", "0.0", ")", ",", "\n", "_config", ".", "get", "(", "\"mask_value\"", ",", "None", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.feature_transforms.specaugment.SpecAugmentTransform.__init__": [[29, 61], ["isinstance", "type"], "methods", ["None"], ["", "def", "__init__", "(", "\n", "self", ",", "\n", "time_warp_w", ":", "int", "=", "0", ",", "\n", "freq_mask_n", ":", "int", "=", "0", ",", "\n", "freq_mask_f", ":", "int", "=", "0", ",", "\n", "time_mask_n", ":", "int", "=", "0", ",", "\n", "time_mask_t", ":", "int", "=", "0", ",", "\n", "time_mask_p", ":", "float", "=", "0.0", ",", "\n", "mask_value", ":", "Optional", "[", "float", "]", "=", "0.0", ",", "\n", ")", ":", "\n", "# Sanity checks", "\n", "        ", "assert", "mask_value", "is", "None", "or", "isinstance", "(", "\n", "mask_value", ",", "numbers", ".", "Number", "\n", ")", ",", "f\"mask_value (type: {type(mask_value)}) must be None or a number\"", "\n", "if", "freq_mask_n", ">", "0", ":", "\n", "            ", "assert", "freq_mask_f", ">", "0", ",", "(", "\n", "f\"freq_mask_F ({freq_mask_f}) \"", "\n", "f\"must be larger than 0 when doing freq masking.\"", "\n", ")", "\n", "", "if", "time_mask_n", ">", "0", ":", "\n", "            ", "assert", "time_mask_t", ">", "0", ",", "(", "\n", "f\"time_mask_T ({time_mask_t}) must be larger than 0 when \"", "\n", "f\"doing time masking.\"", "\n", ")", "\n", "\n", "", "self", ".", "time_warp_w", "=", "time_warp_w", "\n", "self", ".", "freq_mask_n", "=", "freq_mask_n", "\n", "self", ".", "freq_mask_f", "=", "freq_mask_f", "\n", "self", ".", "time_mask_n", "=", "time_mask_n", "\n", "self", ".", "time_mask_t", "=", "time_mask_t", "\n", "self", ".", "time_mask_p", "=", "time_mask_p", "\n", "self", ".", "mask_value", "=", "mask_value", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.feature_transforms.specaugment.SpecAugmentTransform.__repr__": [[62, 77], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "__class__", ".", "__name__", "\n", "+", "\"(\"", "\n", "+", "\", \"", ".", "join", "(", "\n", "[", "\n", "f\"time_warp_w={self.time_warp_w}\"", ",", "\n", "f\"freq_mask_n={self.freq_mask_n}\"", ",", "\n", "f\"freq_mask_f={self.freq_mask_f}\"", ",", "\n", "f\"time_mask_n={self.time_mask_n}\"", ",", "\n", "f\"time_mask_t={self.time_mask_t}\"", ",", "\n", "f\"time_mask_p={self.time_mask_p}\"", ",", "\n", "]", "\n", ")", "\n", "+", "\")\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.feature_transforms.specaugment.SpecAugmentTransform.__call__": [[79, 132], ["spectrogram.copy", "range", "min", "range", "len", "spectrogram.mean", "numpy.random.randint", "numpy.random.randint", "math.floor", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "cv2.resize", "cv2.resize", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.copy"], ["", "def", "__call__", "(", "self", ",", "spectrogram", ")", ":", "\n", "        ", "assert", "len", "(", "spectrogram", ".", "shape", ")", "==", "2", ",", "\"spectrogram must be a 2-D tensor.\"", "\n", "\n", "distorted", "=", "spectrogram", ".", "copy", "(", ")", "# make a copy of input spectrogram.", "\n", "num_frames", "=", "spectrogram", ".", "shape", "[", "0", "]", "# or 'tau' in the paper.", "\n", "num_freqs", "=", "spectrogram", ".", "shape", "[", "1", "]", "# or 'miu' in the paper.", "\n", "mask_value", "=", "self", ".", "mask_value", "\n", "\n", "if", "mask_value", "is", "None", ":", "# if no value was specified, use local mean.", "\n", "            ", "mask_value", "=", "spectrogram", ".", "mean", "(", ")", "\n", "\n", "", "if", "num_frames", "==", "0", ":", "\n", "            ", "return", "spectrogram", "\n", "\n", "", "if", "num_freqs", "<", "self", ".", "freq_mask_f", ":", "\n", "            ", "return", "spectrogram", "\n", "\n", "", "if", "self", ".", "time_warp_w", ">", "0", ":", "\n", "            ", "if", "2", "*", "self", ".", "time_warp_w", "<", "num_frames", ":", "\n", "                ", "import", "cv2", "\n", "\n", "w0", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "time_warp_w", ",", "num_frames", "-", "self", ".", "time_warp_w", ")", "\n", "w", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "time_warp_w", ")", "\n", "upper", ",", "lower", "=", "distorted", "[", ":", "w0", ",", ":", "]", ",", "distorted", "[", "w0", ":", ",", ":", "]", "\n", "upper", "=", "cv2", ".", "resize", "(", "\n", "upper", ",", "dsize", "=", "(", "num_freqs", ",", "w0", "+", "w", ")", ",", "interpolation", "=", "cv2", ".", "INTER_LINEAR", "\n", ")", "\n", "lower", "=", "cv2", ".", "resize", "(", "\n", "lower", ",", "\n", "dsize", "=", "(", "num_freqs", ",", "num_frames", "-", "w0", "-", "w", ")", ",", "\n", "interpolation", "=", "cv2", ".", "INTER_LINEAR", ",", "\n", ")", "\n", "distorted", "=", "np", ".", "concatenate", "(", "(", "upper", ",", "lower", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "for", "_i", "in", "range", "(", "self", ".", "freq_mask_n", ")", ":", "\n", "            ", "f", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "freq_mask_f", ")", "\n", "f0", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "num_freqs", "-", "f", ")", "\n", "if", "f", "!=", "0", ":", "\n", "                ", "distorted", "[", ":", ",", "f0", ":", "f0", "+", "f", "]", "=", "mask_value", "\n", "\n", "", "", "max_time_mask_t", "=", "min", "(", "\n", "self", ".", "time_mask_t", ",", "math", ".", "floor", "(", "num_frames", "*", "self", ".", "time_mask_p", ")", "\n", ")", "\n", "if", "max_time_mask_t", "<", "1", ":", "\n", "            ", "return", "distorted", "\n", "\n", "", "for", "_i", "in", "range", "(", "self", ".", "time_mask_n", ")", ":", "\n", "            ", "t", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "max_time_mask_t", ")", "\n", "t0", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "num_frames", "-", "t", ")", "\n", "if", "t", "!=", "0", ":", "\n", "                ", "distorted", "[", "t0", ":", "t0", "+", "t", ",", ":", "]", "=", "mask_value", "\n", "\n", "", "", "return", "distorted", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.encoders.nltk_tokenizer.NLTKTokenizer.__init__": [[11, 18], ["ImportError"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "*", "unused", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "nltk", ".", "tokenize", "import", "word_tokenize", "\n", "\n", "self", ".", "word_tokenize", "=", "word_tokenize", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install nltk with: pip install nltk\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.nltk_tokenizer.NLTKTokenizer.encode": [[19, 21], ["nltk_tokenizer.NLTKTokenizer.word_tokenize"], "methods", ["None"], ["", "", "def", "encode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "\" \"", ".", "join", "(", "self", ".", "word_tokenize", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.nltk_tokenizer.NLTKTokenizer.decode": [[22, 24], ["None"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.encoders.gpt2_bpe.GPT2BPE.__init__": [[31, 35], ["fairseq.file_utils.cached_path", "fairseq.file_utils.cached_path", "gpt2_bpe_utils.get_encoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.cached_path", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.cached_path", "home.repos.pwc.inspect_result.reneeye_const.encoders.gpt2_bpe_utils.get_encoder"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "encoder_json", "=", "file_utils", ".", "cached_path", "(", "cfg", ".", "gpt2_encoder_json", ")", "\n", "vocab_bpe", "=", "file_utils", ".", "cached_path", "(", "cfg", ".", "gpt2_vocab_bpe", ")", "\n", "self", ".", "bpe", "=", "get_encoder", "(", "encoder_json", ",", "vocab_bpe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.gpt2_bpe.GPT2BPE.encode": [[36, 38], ["map", "gpt2_bpe.GPT2BPE.bpe.encode"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "def", "encode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "\" \"", ".", "join", "(", "map", "(", "str", ",", "self", ".", "bpe", ".", "encode", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.gpt2_bpe.GPT2BPE.decode": [[39, 42], ["gpt2_bpe.GPT2BPE.bpe.decode", "int", "x.split"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "decode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "bpe", ".", "decode", "(", "\n", "[", "int", "(", "tok", ")", "if", "tok", "not", "in", "{", "\"<unk>\"", ",", "\"<mask>\"", "}", "else", "tok", "for", "tok", "in", "x", ".", "split", "(", ")", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.gpt2_bpe.GPT2BPE.is_beginning_of_word": [[44, 46], ["gpt2_bpe.GPT2BPE.decode().startswith", "gpt2_bpe.GPT2BPE.decode"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "is_beginning_of_word", "(", "self", ",", "x", ":", "str", ")", "->", "bool", ":", "\n", "        ", "return", "self", ".", "decode", "(", "x", ")", ".", "startswith", "(", "\" \"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.encoders.subword_nmt_bpe.SubwordNMTBPE.__init__": [[21, 48], ["fairseq.file_utils.cached_path", "ValueError", "apply_bpe.create_parser", "apply_bpe.create_parser.parse_args", "apply_bpe.BPE", "ImportError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.cached_path"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "if", "cfg", ".", "bpe_codes", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"--bpe-codes is required for --bpe=subword_nmt\"", ")", "\n", "", "codes", "=", "file_utils", ".", "cached_path", "(", "cfg", ".", "bpe_codes", ")", "\n", "try", ":", "\n", "            ", "from", "subword_nmt", "import", "apply_bpe", "\n", "\n", "bpe_parser", "=", "apply_bpe", ".", "create_parser", "(", ")", "\n", "bpe_args", "=", "bpe_parser", ".", "parse_args", "(", "\n", "[", "\n", "\"--codes\"", ",", "\n", "codes", ",", "\n", "\"--separator\"", ",", "\n", "cfg", ".", "bpe_separator", ",", "\n", "]", "\n", ")", "\n", "self", ".", "bpe", "=", "apply_bpe", ".", "BPE", "(", "\n", "bpe_args", ".", "codes", ",", "\n", "bpe_args", ".", "merges", ",", "\n", "bpe_args", ".", "separator", ",", "\n", "None", ",", "\n", "bpe_args", ".", "glossaries", ",", "\n", ")", "\n", "self", ".", "bpe_symbol", "=", "bpe_args", ".", "separator", "+", "\" \"", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Please install subword_nmt with: pip install subword-nmt\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.subword_nmt_bpe.SubwordNMTBPE.encode": [[50, 52], ["subword_nmt_bpe.SubwordNMTBPE.bpe.process_line"], "methods", ["None"], ["", "", "def", "encode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "bpe", ".", "process_line", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.subword_nmt_bpe.SubwordNMTBPE.decode": [[53, 55], ["None"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "(", "x", "+", "\" \"", ")", ".", "replace", "(", "self", ".", "bpe_symbol", ",", "\"\"", ")", ".", "rstrip", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.encoders.byte_bpe.ByteBPE.__init__": [[29, 39], ["fairseq.file_utils.cached_path", "spm.SentencePieceProcessor", "byte_bpe.ByteBPE.sp.Load", "ImportError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.cached_path"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "vocab", "=", "file_utils", ".", "cached_path", "(", "cfg", ".", "sentencepiece_model_path", ")", "\n", "try", ":", "\n", "            ", "import", "sentencepiece", "as", "spm", "\n", "\n", "self", ".", "sp", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp", ".", "Load", "(", "vocab", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Please install sentencepiece with: pip install sentencepiece\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.byte_bpe.ByteBPE.encode": [[41, 44], ["fairseq.data.encoders.byte_utils.byte_encode", "fairseq.data.encoders.byte_utils.SPACE.join", "byte_bpe.ByteBPE.sp.EncodeAsPieces"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.byte_utils.byte_encode"], ["", "", "def", "encode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "byte_encoded", "=", "byte_encode", "(", "x", ")", "\n", "return", "SPACE", ".", "join", "(", "self", ".", "sp", ".", "EncodeAsPieces", "(", "byte_encoded", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.byte_bpe.ByteBPE.decode": [[45, 49], ["x.replace().replace", "fairseq.data.encoders.byte_utils.smart_byte_decode", "x.replace"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.byte_utils.smart_byte_decode"], ["", "@", "staticmethod", "\n", "def", "decode", "(", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "unescaped", "=", "x", ".", "replace", "(", "SPACE", ",", "\"\"", ")", ".", "replace", "(", "SPACE_ESCAPE", ",", "SPACE", ")", "\n", "return", "smart_byte_decode", "(", "unescaped", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.encoders.hf_bert_bpe.BertBPE.__init__": [[23, 40], ["BertTokenizer", "BertTokenizer.from_pretrained", "ImportError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.roberta.model_xlmr.XLMRModel.from_pretrained"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "transformers", "import", "BertTokenizer", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Please install transformers with: pip install transformers\"", "\n", ")", "\n", "\n", "", "if", "cfg", ".", "bpe_vocab_file", ":", "\n", "            ", "self", ".", "bert_tokenizer", "=", "BertTokenizer", "(", "\n", "cfg", ".", "bpe_vocab_file", ",", "do_lower_case", "=", "not", "cfg", ".", "bpe_cased", "\n", ")", "\n", "", "else", ":", "\n", "            ", "vocab_file_name", "=", "(", "\n", "\"bert-base-cased\"", "if", "cfg", ".", "bpe_cased", "else", "\"bert-base-uncased\"", "\n", ")", "\n", "self", ".", "bert_tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "vocab_file_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.hf_bert_bpe.BertBPE.encode": [[41, 43], ["hf_bert_bpe.BertBPE.bert_tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scoring.tokenizer.EvaluationTokenizer.tokenize"], ["", "", "def", "encode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "\" \"", ".", "join", "(", "self", ".", "bert_tokenizer", ".", "tokenize", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.hf_bert_bpe.BertBPE.decode": [[44, 47], ["hf_bert_bpe.BertBPE.bert_tokenizer.clean_up_tokenization", "hf_bert_bpe.BertBPE.bert_tokenizer.convert_tokens_to_string", "x.split"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "bert_tokenizer", ".", "clean_up_tokenization", "(", "\n", "self", ".", "bert_tokenizer", ".", "convert_tokens_to_string", "(", "x", ".", "split", "(", "\" \"", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.hf_bert_bpe.BertBPE.is_beginning_of_word": [[49, 51], ["x.startswith"], "methods", ["None"], ["", "def", "is_beginning_of_word", "(", "self", ",", "x", ":", "str", ")", "->", "bool", ":", "\n", "        ", "return", "not", "x", ".", "startswith", "(", "\"##\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.encoders.characters.Characters.__init__": [[16, 18], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "*", "unused", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.characters.Characters.add_args": [[19, 22], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.characters.Characters.encode": [[23, 27], ["x.replace", "SPACE.join", "list"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "encode", "(", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "escaped", "=", "x", ".", "replace", "(", "SPACE", ",", "SPACE_ESCAPE", ")", "\n", "return", "SPACE", ".", "join", "(", "list", "(", "escaped", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.characters.Characters.decode": [[28, 31], ["x.replace().replace", "x.replace"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "decode", "(", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "x", ".", "replace", "(", "SPACE", ",", "\"\"", ")", ".", "replace", "(", "SPACE_ESCAPE", ",", "SPACE", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.encoders.gpt2_bpe_utils.Encoder.__init__": [[52, 71], ["gpt2_bpe_utils.bytes_to_unicode", "dict", "gpt2_bpe_utils.Encoder.re.compile", "zip", "gpt2_bpe_utils.Encoder.encoder.items", "gpt2_bpe_utils.Encoder.byte_encoder.items", "range", "ImportError", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.gpt2_bpe_utils.bytes_to_unicode"], ["    ", "def", "__init__", "(", "self", ",", "encoder", ",", "bpe_merges", ",", "errors", "=", "\"replace\"", ")", ":", "\n", "        ", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "self", ".", "errors", "=", "errors", "# how to handle errors in decoding", "\n", "self", ".", "byte_encoder", "=", "bytes_to_unicode", "(", ")", "\n", "self", ".", "byte_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "byte_encoder", ".", "items", "(", ")", "}", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "bpe_merges", ",", "range", "(", "len", "(", "bpe_merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n", "try", ":", "\n", "            ", "import", "regex", "as", "re", "\n", "\n", "self", ".", "re", "=", "re", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install regex with: pip install regex\"", ")", "\n", "\n", "# Should haved added re.IGNORECASE so BPE merges can happen for capitalized versions of contractions", "\n", "", "self", ".", "pat", "=", "self", ".", "re", ".", "compile", "(", "\n", "r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.gpt2_bpe_utils.Encoder.bpe": [[73, 113], ["tuple", "gpt2_bpe_utils.get_pairs", "min", "tuple", "len", "len", "gpt2_bpe_utils.get_pairs", "tuple.index", "tuple.extend", "tuple.append", "tuple.append", "gpt2_bpe_utils.Encoder.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.gpt2_bpe_utils.get_pairs", "home.repos.pwc.inspect_result.reneeye_const.encoders.gpt2_bpe_utils.get_pairs", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.index"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "word", "=", "tuple", "(", "token", ")", "\n", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "\"inf\"", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "\" \"", ".", "join", "(", "word", ")", "\n", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.gpt2_bpe_utils.Encoder.encode": [[114, 122], ["gpt2_bpe_utils.Encoder.re.findall", "bpe_tokens.extend", "token.encode", "gpt2_bpe_utils.Encoder.bpe().split", "gpt2_bpe_utils.Encoder.bpe"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode", "home.repos.pwc.inspect_result.reneeye_const.encoders.gpt2_bpe_utils.Encoder.bpe"], ["", "def", "encode", "(", "self", ",", "text", ")", ":", "\n", "        ", "bpe_tokens", "=", "[", "]", "\n", "for", "token", "in", "self", ".", "re", ".", "findall", "(", "self", ".", "pat", ",", "text", ")", ":", "\n", "            ", "token", "=", "\"\"", ".", "join", "(", "self", ".", "byte_encoder", "[", "b", "]", "for", "b", "in", "token", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "bpe_tokens", ".", "extend", "(", "\n", "self", ".", "encoder", "[", "bpe_token", "]", "for", "bpe_token", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "\" \"", ")", "\n", ")", "\n", "", "return", "bpe_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.gpt2_bpe_utils.Encoder.decode": [[123, 129], ["bytearray().decode", "gpt2_bpe_utils.Encoder.decoder.get", "bytearray"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "decode", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "text", "=", "\"\"", ".", "join", "(", "[", "self", ".", "decoder", ".", "get", "(", "token", ",", "token", ")", "for", "token", "in", "tokens", "]", ")", "\n", "text", "=", "bytearray", "(", "[", "self", ".", "byte_decoder", "[", "c", "]", "for", "c", "in", "text", "]", ")", ".", "decode", "(", "\n", "\"utf-8\"", ",", "errors", "=", "self", ".", "errors", "\n", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.gpt2_bpe_utils.bytes_to_unicode": [[12, 37], ["functools.lru_cache", "range", "dict", "list", "chr", "zip", "list", "list", "range", "bs.append", "cs.append", "range", "range", "ord", "ord", "ord", "ord", "ord", "ord"], "function", ["None"], ["@", "lru_cache", "(", ")", "\n", "def", "bytes_to_unicode", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns list of utf-8 byte and a corresponding list of unicode strings.\n    The reversible bpe codes work on unicode strings.\n    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n    This is a signficant percentage of your normal, say, 32K bpe vocab.\n    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n    And avoids mapping to whitespace/control characters the bpe code barfs on.\n    \"\"\"", "\n", "bs", "=", "(", "\n", "list", "(", "range", "(", "ord", "(", "\"!\"", ")", ",", "ord", "(", "\"~\"", ")", "+", "1", ")", ")", "\n", "+", "list", "(", "range", "(", "ord", "(", "\"\u00a1\"", ")", ",", "ord", "(", "\"\u00ac\"", ")", "+", "1", ")", ")", "\n", "+", "list", "(", "range", "(", "ord", "(", "\"\u00ae\"", ")", ",", "ord", "(", "\"\u00ff\"", ")", "+", "1", ")", ")", "\n", ")", "\n", "cs", "=", "bs", "[", ":", "]", "\n", "n", "=", "0", "\n", "for", "b", "in", "range", "(", "2", "**", "8", ")", ":", "\n", "        ", "if", "b", "not", "in", "bs", ":", "\n", "            ", "bs", ".", "append", "(", "b", ")", "\n", "cs", ".", "append", "(", "2", "**", "8", "+", "n", ")", "\n", "n", "+=", "1", "\n", "", "", "cs", "=", "[", "chr", "(", "n", ")", "for", "n", "in", "cs", "]", "\n", "return", "dict", "(", "zip", "(", "bs", ",", "cs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.gpt2_bpe_utils.get_pairs": [[39, 49], ["set", "set.add"], "function", ["home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add"], ["", "def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"Return set of symbol pairs in a word.\n    Word is represented as tuple of symbols (symbols being variable-length strings).\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.gpt2_bpe_utils.get_encoder": [[131, 140], ["gpt2_bpe_utils.Encoder", "open", "json.load", "open", "f.read", "tuple", "merge_str.split", "f.read.split"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open"], ["", "", "def", "get_encoder", "(", "encoder_json_path", ",", "vocab_bpe_path", ")", ":", "\n", "    ", "with", "open", "(", "encoder_json_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "encoder", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "vocab_bpe_path", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "bpe_data", "=", "f", ".", "read", "(", ")", "\n", "", "bpe_merges", "=", "[", "tuple", "(", "merge_str", ".", "split", "(", ")", ")", "for", "merge_str", "in", "bpe_data", ".", "split", "(", "\"\\n\"", ")", "[", "1", ":", "-", "1", "]", "]", "\n", "return", "Encoder", "(", "\n", "encoder", "=", "encoder", ",", "\n", "bpe_merges", "=", "bpe_merges", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.hf_byte_bpe.HuggingFaceByteLevelBPE.__init__": [[23, 35], ["ByteLevelBPETokenizer", "ImportError"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "tokenizers", "import", "ByteLevelBPETokenizer", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Please install huggingface/tokenizers with: \"", "\"pip install tokenizers\"", "\n", ")", "\n", "\n", "", "self", ".", "bpe", "=", "ByteLevelBPETokenizer", "(", "\n", "cfg", ".", "bpe_vocab", ",", "\n", "cfg", ".", "bpe_merges", ",", "\n", "add_prefix_space", "=", "cfg", ".", "bpe_add_prefix_space", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.hf_byte_bpe.HuggingFaceByteLevelBPE.encode": [[37, 39], ["map", "hf_byte_bpe.HuggingFaceByteLevelBPE.bpe.encode"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "def", "encode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "\" \"", ".", "join", "(", "map", "(", "str", ",", "self", ".", "bpe", ".", "encode", "(", "x", ")", ".", "ids", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.hf_byte_bpe.HuggingFaceByteLevelBPE.decode": [[40, 43], ["hf_byte_bpe.HuggingFaceByteLevelBPE.bpe.decode", "int", "x.split"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "decode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "bpe", ".", "decode", "(", "\n", "[", "int", "(", "tok", ")", "if", "tok", "not", "in", "{", "\"<unk>\"", ",", "\"<mask>\"", "}", "else", "tok", "for", "tok", "in", "x", ".", "split", "(", ")", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.hf_byte_bpe.HuggingFaceByteLevelBPE.is_beginning_of_word": [[45, 47], ["hf_byte_bpe.HuggingFaceByteLevelBPE.decode().startswith", "hf_byte_bpe.HuggingFaceByteLevelBPE.decode"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "is_beginning_of_word", "(", "self", ",", "x", ":", "str", ")", "->", "bool", ":", "\n", "        ", "return", "self", ".", "decode", "(", "x", ")", ".", "startswith", "(", "\" \"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.encoders.moses_tokenizer.MosesTokenizer.__init__": [[27, 38], ["moses_tokenizer.MosesTokenizer", "MosesDetokenizer", "ImportError"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ":", "MosesTokenizerConfig", ")", ":", "\n", "        ", "self", ".", "cfg", "=", "cfg", "\n", "\n", "try", ":", "\n", "            ", "from", "sacremoses", "import", "MosesTokenizer", ",", "MosesDetokenizer", "\n", "\n", "self", ".", "tok", "=", "MosesTokenizer", "(", "cfg", ".", "source_lang", ")", "\n", "self", ".", "detok", "=", "MosesDetokenizer", "(", "cfg", ".", "target_lang", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Please install Moses tokenizer with: pip install sacremoses\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.moses_tokenizer.MosesTokenizer.encode": [[40, 46], ["moses_tokenizer.MosesTokenizer.tok.tokenize"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.scoring.tokenizer.EvaluationTokenizer.tokenize"], ["", "", "def", "encode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "tok", ".", "tokenize", "(", "\n", "x", ",", "\n", "aggressive_dash_splits", "=", "(", "not", "self", ".", "cfg", ".", "moses_no_dash_splits", ")", ",", "\n", "return_str", "=", "True", ",", "\n", "escape", "=", "(", "not", "self", ".", "cfg", ".", "moses_no_escape", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.moses_tokenizer.MosesTokenizer.decode": [[48, 50], ["moses_tokenizer.MosesTokenizer.detok.detokenize", "x.split"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.hub_utils.GeneratorHubInterface.detokenize"], ["", "def", "decode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "detok", ".", "detokenize", "(", "x", ".", "split", "(", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.encoders.bytes.Bytes.__init__": [[18, 20], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "*", "unused", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.bytes.Bytes.add_args": [[21, 24], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.bytes.Bytes.encode": [[25, 30], ["fairseq.data.encoders.byte_utils.byte_encode", "fairseq.data.encoders.byte_utils.byte_encode.replace", "fairseq.data.encoders.byte_utils.SPACE.join", "list"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.byte_utils.byte_encode"], ["", "@", "staticmethod", "\n", "def", "encode", "(", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "encoded", "=", "byte_encode", "(", "x", ")", "\n", "escaped", "=", "encoded", ".", "replace", "(", "SPACE", ",", "SPACE_ESCAPE", ")", "\n", "return", "SPACE", ".", "join", "(", "list", "(", "escaped", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.bytes.Bytes.decode": [[31, 35], ["x.replace().replace", "fairseq.data.encoders.byte_utils.smart_byte_decode", "x.replace"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.byte_utils.smart_byte_decode"], ["", "@", "staticmethod", "\n", "def", "decode", "(", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "unescaped", "=", "x", ".", "replace", "(", "SPACE", ",", "\"\"", ")", ".", "replace", "(", "SPACE_ESCAPE", ",", "SPACE", ")", "\n", "return", "smart_byte_decode", "(", "unescaped", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.encoders.byte_utils.byte_encode": [[22, 25], ["WHITESPACE_NORMALIZER.sub", "WHITESPACE_NORMALIZER.sub.encode"], "function", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["def", "byte_encode", "(", "x", ":", "str", ")", "->", "str", ":", "\n", "    ", "normalized", "=", "WHITESPACE_NORMALIZER", ".", "sub", "(", "SPACE", ",", "x", ")", "\n", "return", "\"\"", ".", "join", "(", "[", "BYTE_TO_BCHAR", "[", "b", "]", "for", "b", "in", "normalized", ".", "encode", "(", "\"utf-8\"", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.byte_utils.byte_decode": [[27, 32], ["bytes().decode", "bytes"], "function", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode"], ["", "def", "byte_decode", "(", "x", ":", "str", ")", "->", "str", ":", "\n", "    ", "try", ":", "\n", "        ", "return", "bytes", "(", "[", "BCHAR_TO_BYTE", "[", "bc", "]", "for", "bc", "in", "x", "]", ")", ".", "decode", "(", "\"utf-8\"", ")", "\n", "", "except", "ValueError", ":", "\n", "        ", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.byte_utils.smart_byte_decode": [[34, 52], ["byte_utils.byte_decode", "len", "range", "range", "range", "range", "min", "byte_utils.byte_decode", "len", "byte_utils.byte_decode"], "function", ["home.repos.pwc.inspect_result.reneeye_const.encoders.byte_utils.byte_decode", "home.repos.pwc.inspect_result.reneeye_const.encoders.byte_utils.byte_decode", "home.repos.pwc.inspect_result.reneeye_const.encoders.byte_utils.byte_decode"], ["", "", "def", "smart_byte_decode", "(", "x", ":", "str", ")", "->", "str", ":", "\n", "    ", "output", "=", "byte_decode", "(", "x", ")", "\n", "if", "output", "==", "\"\"", ":", "\n", "# DP the best recovery (max valid chars) if it's broken", "\n", "        ", "n_bytes", "=", "len", "(", "x", ")", "\n", "f", "=", "[", "0", "for", "_", "in", "range", "(", "n_bytes", "+", "1", ")", "]", "\n", "pt", "=", "[", "0", "for", "_", "in", "range", "(", "n_bytes", "+", "1", ")", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "n_bytes", "+", "1", ")", ":", "\n", "            ", "f", "[", "i", "]", ",", "pt", "[", "i", "]", "=", "f", "[", "i", "-", "1", "]", ",", "i", "-", "1", "\n", "for", "j", "in", "range", "(", "1", ",", "min", "(", "4", ",", "i", ")", "+", "1", ")", ":", "\n", "                ", "if", "f", "[", "i", "-", "j", "]", "+", "1", ">", "f", "[", "i", "]", "and", "len", "(", "byte_decode", "(", "x", "[", "i", "-", "j", ":", "i", "]", ")", ")", ">", "0", ":", "\n", "                    ", "f", "[", "i", "]", ",", "pt", "[", "i", "]", "=", "f", "[", "i", "-", "j", "]", "+", "1", ",", "i", "-", "j", "\n", "", "", "", "cur_pt", "=", "n_bytes", "\n", "while", "cur_pt", ">", "0", ":", "\n", "            ", "if", "f", "[", "cur_pt", "]", "==", "f", "[", "pt", "[", "cur_pt", "]", "]", "+", "1", ":", "\n", "                ", "output", "=", "byte_decode", "(", "x", "[", "pt", "[", "cur_pt", "]", ":", "cur_pt", "]", ")", "+", "output", "\n", "", "cur_pt", "=", "pt", "[", "cur_pt", "]", "\n", "", "", "return", "output", "\n", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.encoders.space_tokenizer.SpaceTokenizer.__init__": [[13, 15], ["re.compile"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "*", "unused", ")", ":", "\n", "        ", "self", ".", "space_tok", "=", "re", ".", "compile", "(", "r\"\\s+\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.space_tokenizer.SpaceTokenizer.encode": [[16, 18], ["space_tokenizer.SpaceTokenizer.space_tok.sub"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "space_tok", ".", "sub", "(", "\" \"", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.space_tokenizer.SpaceTokenizer.decode": [[19, 21], ["None"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.encoders.fastbpe.fastBPE.__init__": [[20, 31], ["fairseq.file_utils.cached_path", "ValueError", "fastBPE.fastBPE", "ImportError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.cached_path"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "if", "cfg", ".", "bpe_codes", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"--bpe-codes is required for --bpe=fastbpe\"", ")", "\n", "", "codes", "=", "file_utils", ".", "cached_path", "(", "cfg", ".", "bpe_codes", ")", "\n", "try", ":", "\n", "            ", "import", "fastBPE", "\n", "\n", "self", ".", "bpe", "=", "fastBPE", ".", "fastBPE", "(", "codes", ")", "\n", "self", ".", "bpe_symbol", "=", "\"@@ \"", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install fastBPE with: pip install fastBPE\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.fastbpe.fastBPE.encode": [[32, 34], ["fastbpe.fastBPE.bpe.apply"], "methods", ["None"], ["", "", "def", "encode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "bpe", ".", "apply", "(", "[", "x", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.fastbpe.fastBPE.decode": [[35, 37], ["None"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "(", "x", "+", "\" \"", ")", ".", "replace", "(", "self", ".", "bpe_symbol", ",", "\"\"", ")", ".", "rstrip", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.__init__": [[22, 32], ["fairseq.file_utils.cached_path", "spm.SentencePieceProcessor", "sentencepiece_bpe.SentencepieceBPE.sp.Load", "ImportError"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_utils.cached_path"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "sentencepiece_model", "=", "file_utils", ".", "cached_path", "(", "cfg", ".", "sentencepiece_model", ")", "\n", "try", ":", "\n", "            ", "import", "sentencepiece", "as", "spm", "\n", "\n", "self", ".", "sp", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp", ".", "Load", "(", "sentencepiece_model", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Please install sentencepiece with: pip install sentencepiece\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode": [[34, 36], ["sentencepiece_bpe.SentencepieceBPE.sp.EncodeAsPieces"], "methods", ["None"], ["", "", "def", "encode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "\" \"", ".", "join", "(", "self", ".", "sp", ".", "EncodeAsPieces", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.decode": [[37, 39], ["x.replace().replace().strip", "x.replace().replace", "x.replace"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "x", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "x", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ".", "replace", "(", "\"\\u2581\"", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.is_beginning_of_word": [[40, 49], ["x.startswith"], "methods", ["None"], ["", "def", "is_beginning_of_word", "(", "self", ",", "x", ":", "str", ")", "->", "bool", ":", "\n", "        ", "if", "x", "in", "[", "\"<unk>\"", ",", "\"<s>\"", ",", "\"</s>\"", ",", "\"<pad>\"", "]", ":", "\n", "# special elements are always considered beginnings", "\n", "# HACK: this logic is already present in fairseq/tasks/masked_lm.py", "\n", "# but these special tokens are also contained in the sentencepiece", "\n", "# vocabulary which causes duplicate special tokens. This hack makes", "\n", "# sure that they are all taken into account.", "\n", "            ", "return", "True", "\n", "", "return", "x", ".", "startswith", "(", "\"\\u2581\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.encoders.utils.get_whole_word_mask": [[10, 31], ["fairseq.data.encoders.build_bpe", "torch.ByteTensor", "tok.startswith", "list", "encoders.build_bpe.is_beginning_of_word", "map", "range", "len"], "function", ["home.repos.pwc.inspect_result.reneeye_const.tasks.translation_with_langtag.TranslationTaskWithLangtag.build_bpe", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.is_beginning_of_word"], ["import", "logging", "\n", "import", "os", "\n", "import", "sys", "\n", "import", "tempfile", "\n", "import", "warnings", "\n", "from", "itertools", "import", "accumulate", "\n", "from", "typing", "import", "Callable", ",", "Dict", ",", "List", ",", "Optional", "\n", "\n", "import", "torch", "\n", "import", "torch", ".", "nn", ".", "functional", "as", "F", "\n", "from", "fairseq", ".", "data", "import", "iterators", "\n", "from", "fairseq", ".", "file_io", "import", "PathManager", "\n", "from", "fairseq", ".", "logging", ".", "meters", "import", "safe_round", "\n", "from", "fairseq", ".", "modules", "import", "gelu", ",", "gelu_accurate", "\n", "from", "fairseq", ".", "modules", ".", "multihead_attention", "import", "MultiheadAttention", "\n", "from", "torch", "import", "Tensor", "\n", "\n", "\n", "try", ":", "\n", "    ", "from", "amp_C", "import", "multi_tensor_l2norm", "\n", "\n", "multi_tensor_l2norm_available", "=", "True", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_utils.get_lang_tok": [[28, 45], ["spec.endswith", "style.format", "spec.endswith"], "function", ["None"], ["", "@", "torch", ".", "jit", ".", "export", "\n", "def", "get_lang_tok", "(", "\n", "lang", ":", "str", ",", "lang_tok_style", ":", "str", ",", "spec", ":", "str", "=", "LangTokSpec", ".", "main", ".", "value", "\n", ")", "->", "str", ":", "\n", "# TOKEN_STYLES can't be defined outside this fn since it needs to be", "\n", "# TorchScriptable.", "\n", "    ", "TOKEN_STYLES", ":", "Dict", "[", "str", ",", "str", "]", "=", "{", "\n", "LangTokStyle", ".", "mbart", ".", "value", ":", "\"[{}]\"", ",", "\n", "LangTokStyle", ".", "multilingual", ".", "value", ":", "\"__{}__\"", ",", "\n", "}", "\n", "\n", "if", "spec", ".", "endswith", "(", "\"dae\"", ")", ":", "\n", "        ", "lang", "=", "f\"{lang}_dae\"", "\n", "", "elif", "spec", ".", "endswith", "(", "\"mined\"", ")", ":", "\n", "        ", "lang", "=", "f\"{lang}_mined\"", "\n", "", "style", "=", "TOKEN_STYLES", "[", "lang_tok_style", "]", "\n", "return", "style", ".", "format", "(", "lang", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_utils.augment_dictionary": [[47, 64], ["dictionary.add_symbol", "dictionary.add_symbol", "multilingual_utils.get_lang_tok"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_utils.get_lang_tok"], ["", "def", "augment_dictionary", "(", "\n", "dictionary", ":", "Dictionary", ",", "\n", "language_list", ":", "List", "[", "str", "]", ",", "\n", "lang_tok_style", ":", "str", ",", "\n", "langtoks_specs", ":", "Sequence", "[", "str", "]", "=", "(", "LangTokSpec", ".", "main", ".", "value", ",", ")", ",", "\n", "extra_data", ":", "Optional", "[", "Dict", "[", "str", ",", "str", "]", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "    ", "for", "spec", "in", "langtoks_specs", ":", "\n", "        ", "for", "language", "in", "language_list", ":", "\n", "            ", "dictionary", ".", "add_symbol", "(", "\n", "get_lang_tok", "(", "lang", "=", "language", ",", "lang_tok_style", "=", "lang_tok_style", ",", "spec", "=", "spec", ")", "\n", ")", "\n", "\n", "", "", "if", "lang_tok_style", "==", "LangTokStyle", ".", "mbart", ".", "value", "or", "(", "\n", "extra_data", "is", "not", "None", "and", "LangTokSpec", ".", "mono_dae", ".", "value", "in", "extra_data", "\n", ")", ":", "\n", "        ", "dictionary", ".", "add_symbol", "(", "\"<mask>\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampling_method.SamplingMethod.add_arguments": [[37, 56], ["parser.add_argument", "parser.add_argument"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "add_arguments", "(", "parser", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "\n", "\"--sampling-method\"", ",", "\n", "choices", "=", "[", "\n", "\"uniform\"", ",", "\n", "\"temperature\"", ",", "\n", "\"concat\"", ",", "\n", "\"RoundRobin\"", ",", "\n", "]", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"concat\"", ",", "\n", "help", "=", "\"The method to sample data per language pairs\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--sampling-temperature\"", ",", "\n", "default", "=", "1.5", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"only work with --sampling-method temperature\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampling_method.SamplingMethod.build_sampler": [[58, 61], ["sampling_method.SamplingMethod"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "build_sampler", "(", "args", ",", "task", ")", ":", "\n", "        ", "return", "SamplingMethod", "(", "args", ",", "task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampling_method.SamplingMethod.__init__": [[62, 65], ["None"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "args", ",", "task", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "task", "=", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampling_method.SamplingMethod.is_adaptive": [[66, 68], ["None"], "methods", ["None"], ["", "def", "is_adaptive", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampling_method.SamplingMethod.sampling_method_selector": [[69, 79], ["logger.info", "sampling_method.SamplingMethod.is_adaptive", "sampling_method.make_temperature_sampling", "float"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampling_method.SamplingMethod.is_adaptive", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampling_method.make_temperature_sampling"], ["", "def", "sampling_method_selector", "(", "self", ")", ":", "\n", "        ", "args", "=", "self", ".", "args", "\n", "logger", ".", "info", "(", "f\"selected sampler: {args.sampling_method}\"", ")", "\n", "if", "args", ".", "sampling_method", "==", "\"uniform\"", ":", "\n", "            ", "return", "uniform", "\n", "", "elif", "args", ".", "sampling_method", "==", "\"temperature\"", "or", "self", ".", "is_adaptive", "(", ")", ":", "\n", "            ", "return", "make_temperature_sampling", "(", "float", "(", "args", ".", "sampling_temperature", ")", ")", "\n", "", "else", ":", "\n", "# default to concating all data set together", "\n", "            ", "return", "None", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampling_method.uniform": [[13, 15], ["len"], "function", ["None"], ["def", "uniform", "(", "dataset_sizes", ":", "List", "[", "int", "]", ")", ":", "\n", "    ", "return", "[", "1.0", "]", "*", "len", "(", "dataset_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampling_method.temperature_sampling": [[17, 20], ["sum"], "function", ["None"], ["", "def", "temperature_sampling", "(", "dataset_sizes", ",", "temp", ")", ":", "\n", "    ", "total_size", "=", "sum", "(", "dataset_sizes", ")", "\n", "return", "[", "(", "size", "/", "total_size", ")", "**", "(", "1.0", "/", "temp", ")", "for", "size", "in", "dataset_sizes", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampling_method.make_temperature_sampling": [[22, 27], ["sampling_method.temperature_sampling"], "function", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampling_method.temperature_sampling"], ["", "def", "make_temperature_sampling", "(", "temp", "=", "1.0", ")", ":", "\n", "    ", "def", "sampling_func", "(", "dataset_sizes", ")", ":", "\n", "        ", "return", "temperature_sampling", "(", "dataset_sizes", ",", "temp", ")", "\n", "\n", "", "return", "sampling_func", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampling_method.make_ratio_sampling": [[29, 34], ["None"], "function", ["None"], ["", "def", "make_ratio_sampling", "(", "ratios", ")", ":", "\n", "    ", "def", "sampling_func", "(", "dataset_sizes", ")", ":", "\n", "        ", "return", "ratios", "\n", "\n", "", "return", "sampling_func", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.__init__": [[74, 122], ["fairseq.data.FairseqDataset.__init__", "isinstance", "sampled_multi_dataset.SampledMultiDataset._reset_cached_properties", "sampled_multi_dataset.SampledMultiDataset.setup_sampling", "sampled_multi_dataset.SampledMultiDataset.set_epoch", "list", "list", "isinstance", "list.keys", "list.values", "list", "AssertionError", "range", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset._reset_cached_properties", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.setup_sampling", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch"], ["def", "__init__", "(", "\n", "self", ",", "\n", "datasets", ",", "\n", "sampling_ratios", "=", "None", ",", "\n", "seed", "=", "2", ",", "\n", "epoch", "=", "1", ",", "\n", "eval_key", "=", "None", ",", "\n", "collate_format", "=", "CollateFormat", ".", "single", ",", "\n", "virtual_size", "=", "default_virtual_size_func", ",", "\n", "split", "=", "\"\"", ",", "\n", "shared_collater", "=", "False", ",", "\n", "shuffle", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "shared_collater", "=", "shared_collater", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n", "if", "isinstance", "(", "datasets", ",", "OrderedDict", ")", ":", "\n", "            ", "self", ".", "keys", "=", "list", "(", "datasets", ".", "keys", "(", ")", ")", "\n", "datasets", "=", "list", "(", "datasets", ".", "values", "(", ")", ")", "\n", "", "elif", "isinstance", "(", "datasets", ",", "List", ")", ":", "\n", "            ", "self", ".", "keys", "=", "list", "(", "range", "(", "len", "(", "datasets", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "AssertionError", "(", ")", "\n", "", "self", ".", "datasets", "=", "datasets", "\n", "self", ".", "split", "=", "split", "\n", "\n", "self", ".", "eval_key", "=", "eval_key", "\n", "if", "self", ".", "eval_key", "is", "not", "None", ":", "\n", "            ", "self", ".", "collate_format", "=", "CollateFormat", ".", "single", "\n", "", "else", ":", "\n", "            ", "self", ".", "collate_format", "=", "collate_format", "\n", "\n", "", "self", ".", "seed", "=", "seed", "\n", "self", ".", "_cur_epoch", "=", "None", "\n", "\n", "self", ".", "cumulated_sizes", "=", "None", "\n", "# self.datasets[k][self._cur_indices[i]] is the data item i in this sampled dataset", "\n", "# namely, data item i is sampled from the kth sub-dataset self.datasets[k]", "\n", "# where self.cumulated_sizes[k-1] <= i < self.cumulated_sizes[k]", "\n", "self", ".", "_cur_indices", "=", "None", "\n", "\n", "self", ".", "_sizes", "=", "None", "\n", "self", ".", "virtual_size_per_dataset", "=", "None", "\n", "# caching properties", "\n", "self", ".", "_reset_cached_properties", "(", ")", "\n", "self", ".", "setup_sampling", "(", "sampling_ratios", ",", "virtual_size", ")", "\n", "self", ".", "set_epoch", "(", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset._clean_if_not_none": [[123, 127], ["None"], "methods", ["None"], ["", "def", "_clean_if_not_none", "(", "self", ",", "var_list", ")", ":", "\n", "        ", "for", "v", "in", "var_list", ":", "\n", "            ", "if", "v", "is", "not", "None", ":", "\n", "                ", "del", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset._reset_cached_properties": [[128, 132], ["sampled_multi_dataset.SampledMultiDataset._clean_if_not_none"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset._clean_if_not_none"], ["", "", "", "def", "_reset_cached_properties", "(", "self", ")", ":", "\n", "        ", "self", ".", "_clean_if_not_none", "(", "[", "self", ".", "_sizes", ",", "self", ".", "_cur_indices", "]", ")", "\n", "self", ".", "_sizes", "=", "None", "\n", "self", ".", "_cur_indices", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.setup_sampling": [[133, 150], ["len", "sum", "isinstance", "numpy.array", "callable", "virtual_size"], "methods", ["None"], ["", "def", "setup_sampling", "(", "self", ",", "sample_ratios", ",", "virtual_size", ")", ":", "\n", "        ", "sizes", "=", "[", "len", "(", "d", ")", "for", "d", "in", "self", ".", "datasets", "]", "\n", "if", "sample_ratios", "is", "None", ":", "\n", "# default back to concating datasets", "\n", "            ", "self", ".", "sample_ratios", "=", "None", "\n", "self", ".", "virtual_size", "=", "sum", "(", "sizes", ")", "\n", "", "else", ":", "\n", "            ", "if", "not", "isinstance", "(", "sample_ratios", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "sample_ratios", "=", "np", ".", "array", "(", "sample_ratios", ")", "\n", "", "self", ".", "sample_ratios", "=", "sample_ratios", "\n", "virtual_size", "=", "(", "\n", "default_virtual_size_func", "if", "virtual_size", "is", "None", "else", "virtual_size", "\n", ")", "\n", "self", ".", "virtual_size", "=", "(", "\n", "virtual_size", "(", "self", ".", "datasets", ",", "self", ".", "sample_ratios", ")", "\n", "if", "callable", "(", "virtual_size", ")", "\n", "else", "virtual_size", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.adjust_sampling": [[152, 156], ["sampled_multi_dataset.SampledMultiDataset._sync_sample_ratios", "sampled_multi_dataset.SampledMultiDataset.setup_sampling"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset._sync_sample_ratios", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.setup_sampling"], ["", "", "def", "adjust_sampling", "(", "self", ",", "epoch", ",", "sampling_ratios", ",", "virtual_size", ")", ":", "\n", "        ", "if", "sampling_ratios", "is", "not", "None", ":", "\n", "            ", "sampling_ratios", "=", "self", ".", "_sync_sample_ratios", "(", "sampling_ratios", ")", "\n", "self", ".", "setup_sampling", "(", "sampling_ratios", ",", "virtual_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset._sync_sample_ratios": [[157, 173], ["torch.DoubleTensor", "torch.distributed.is_initialized", "torch.cuda.is_available", "torch.DoubleTensor.cpu", "ret.numpy.numpy.numpy", "fairseq.distributed_utils.all_reduce", "fairseq.distributed_utils.all_reduce", "torch.DoubleTensor.cuda", "fairseq.distributed_utils.get_data_parallel_group", "fairseq.distributed_utils.get_data_parallel_group"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce", "home.repos.pwc.inspect_result.reneeye_const.fairseq.legacy_distributed_data_parallel.LegacyDistributedDataParallel.all_reduce", "home.repos.pwc.inspect_result.reneeye_const.fairseq.sequence_generator.SequenceGenerator.cuda", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_data_parallel_group", "home.repos.pwc.inspect_result.reneeye_const.fairseq.distributed_utils.get_data_parallel_group"], ["", "", "def", "_sync_sample_ratios", "(", "self", ",", "ratios", ")", ":", "\n", "# in case the ratios are not precisely the same across processes", "\n", "# also to ensure every procresses update the ratios in the same pace", "\n", "        ", "ratios", "=", "torch", ".", "DoubleTensor", "(", "ratios", ")", "\n", "if", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "            ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "distributed_utils", ".", "all_reduce", "(", "\n", "ratios", ".", "cuda", "(", ")", ",", "group", "=", "distributed_utils", ".", "get_data_parallel_group", "(", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "distributed_utils", ".", "all_reduce", "(", "\n", "ratios", ",", "group", "=", "distributed_utils", ".", "get_data_parallel_group", "(", ")", "\n", ")", "\n", "", "ret", "=", "ratios", ".", "cpu", "(", ")", "\n", "ret", "=", "ret", ".", "numpy", "(", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.random_choice_in_dataset": [[174, 180], ["hasattr", "len", "rng.choice", "dataset.random_choice_in_dataset"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.random_choice_in_dataset"], ["", "def", "random_choice_in_dataset", "(", "self", ",", "rng", ",", "dataset", ",", "choice_size", ")", ":", "\n", "        ", "if", "hasattr", "(", "dataset", ",", "\"random_choice_in_dataset\"", ")", ":", "\n", "            ", "return", "dataset", ".", "random_choice_in_dataset", "(", "rng", ",", "choice_size", ")", "\n", "", "dataset_size", "=", "len", "(", "dataset", ")", "\n", "return", "rng", ".", "choice", "(", "\n", "dataset_size", ",", "choice_size", ",", "replace", "=", "(", "choice_size", ">", "dataset_size", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.get_virtual_indices": [[182, 226], ["numpy.array", "numpy.cumsum", "numpy.hstack", "numpy.array", "sampled_multi_dataset.SampledMultiDataset.get_virtual_indices.get_counts"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.concat_dataset.ConcatDataset.cumsum"], ["", "def", "get_virtual_indices", "(", "self", ",", "rng", ",", "datasets", ",", "sample_ratios", ",", "virtual_size", ")", ":", "\n", "        ", "def", "get_counts", "(", "sample_ratios", ")", ":", "\n", "            ", "counts", "=", "np", ".", "array", "(", "[", "virtual_size", "*", "r", "for", "r", "in", "sample_ratios", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "diff", "=", "virtual_size", "-", "counts", ".", "sum", "(", ")", "\n", "assert", "diff", ">=", "0", "\n", "# due to round-offs, the size might not match the desired sizes", "\n", "if", "diff", ">", "0", ":", "\n", "                ", "dataset_indices", "=", "rng", ".", "choice", "(", "\n", "len", "(", "sample_ratios", ")", ",", "size", "=", "diff", ",", "p", "=", "sample_ratios", "\n", ")", "\n", "for", "i", "in", "dataset_indices", ":", "\n", "                    ", "counts", "[", "i", "]", "+=", "1", "\n", "", "", "return", "counts", "\n", "\n", "", "def", "get_in_dataset_indices", "(", "datasets", ",", "sizes", ",", "sample_ratios", ")", ":", "\n", "            ", "counts", "=", "get_counts", "(", "sample_ratios", ")", "\n", "# uniformally sample desired counts for each dataset", "\n", "# if the desired counts are large, sample with replacement:", "\n", "indices", "=", "[", "\n", "self", ".", "random_choice_in_dataset", "(", "rng", ",", "d", ",", "c", ")", "\n", "for", "c", ",", "d", "in", "zip", "(", "counts", ",", "datasets", ")", "\n", "]", "\n", "return", "indices", "\n", "\n", "", "sizes", "=", "[", "len", "(", "d", ")", "for", "d", "in", "datasets", "]", "\n", "if", "sample_ratios", "is", "None", ":", "\n", "# default back to concating datasets", "\n", "            ", "in_dataset_indices", "=", "[", "list", "(", "range", "(", "s", ")", ")", "for", "s", "in", "sizes", "]", "\n", "virtual_sizes_per_dataset", "=", "sizes", "\n", "", "else", ":", "\n", "            ", "ratios", "=", "sample_ratios", "/", "sample_ratios", ".", "sum", "(", ")", "\n", "in_dataset_indices", "=", "get_in_dataset_indices", "(", "datasets", ",", "sizes", ",", "ratios", ")", "\n", "virtual_sizes_per_dataset", "=", "[", "len", "(", "d", ")", "for", "d", "in", "in_dataset_indices", "]", "\n", "", "virtual_sizes_per_dataset", "=", "np", ".", "array", "(", "virtual_sizes_per_dataset", ",", "np", ".", "int64", ")", "\n", "cumulative_sizes", "=", "np", ".", "cumsum", "(", "virtual_sizes_per_dataset", ")", "\n", "assert", "sum", "(", "virtual_sizes_per_dataset", ")", "==", "virtual_size", "\n", "assert", "cumulative_sizes", "[", "-", "1", "]", "==", "virtual_size", "\n", "if", "virtual_size", "<", "sum", "(", "sizes", ")", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "f\"virtual data size ({virtual_size}) is less than real data size ({sum(sizes)}).\"", "\n", "\" If virtual size << real data size, there could be data coverage issue.\"", "\n", ")", "\n", "", "in_dataset_indices", "=", "np", ".", "hstack", "(", "in_dataset_indices", ")", "\n", "return", "in_dataset_indices", ",", "cumulative_sizes", ",", "virtual_sizes_per_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset._get_dataset_and_index": [[227, 230], ["bisect.bisect_right"], "methods", ["None"], ["", "def", "_get_dataset_and_index", "(", "self", ",", "index", ")", ":", "\n", "        ", "i", "=", "bisect_right", "(", "self", ".", "cumulated_sizes", ",", "index", ")", "\n", "return", "i", ",", "self", ".", "_cur_indices", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.__getitem__": [[231, 237], ["sampled_multi_dataset.SampledMultiDataset._get_dataset_and_index"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset._get_dataset_and_index"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "# self.__getitem__(index) returns self.datasets[k][self._cur_indices[index]]", "\n", "# where k satisfies self.cumulated_sizes[k - 1] <= k < self.cumulated_sizes[k]", "\n", "        ", "ds_idx", ",", "ds_sample_idx", "=", "self", ".", "_get_dataset_and_index", "(", "index", ")", "\n", "ret", "=", "(", "ds_idx", ",", "self", ".", "datasets", "[", "ds_idx", "]", "[", "ds_sample_idx", "]", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.num_tokens": [[238, 240], ["sampled_multi_dataset.SampledMultiDataset.sizes[].max"], "methods", ["None"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "sizes", "[", "index", "]", ".", "max", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.size": [[241, 243], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "sizes", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.__len__": [[244, 246], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "virtual_size", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.collater": [[247, 326], ["len", "collections.OrderedDict", "collect_samples[].append", "sampled_multi_dataset.SampledMultiDataset.datasets[].collater", "collections.defaultdict", "sampled_multi_dataset.SampledMultiDataset.collater.straight_data"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.collater"], ["", "def", "collater", "(", "self", ",", "samples", ",", "**", "extra_args", ")", ":", "\n", "        ", "\"\"\"Merge a list of samples to form a mini-batch.\"\"\"", "\n", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "", "if", "self", ".", "collate_format", "==", "\"ordered_dict\"", ":", "\n", "            ", "collect_samples", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "self", ".", "datasets", ")", ")", "]", "\n", "for", "(", "i", ",", "sample", ")", "in", "samples", ":", "\n", "                ", "collect_samples", "[", "i", "]", ".", "append", "(", "sample", ")", "\n", "", "batch", "=", "OrderedDict", "(", "\n", "[", "\n", "(", "self", ".", "keys", "[", "i", "]", ",", "dataset", ".", "collater", "(", "collect_samples", "[", "i", "]", ")", ")", "\n", "for", "i", ",", "(", "key", ",", "dataset", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "keys", ",", "self", ".", "datasets", ")", ")", "\n", "if", "len", "(", "collect_samples", "[", "i", "]", ")", ">", "0", "\n", "]", "\n", ")", "\n", "", "elif", "self", ".", "shared_collater", ":", "\n", "            ", "batch", "=", "self", ".", "datasets", "[", "0", "]", ".", "collater", "(", "[", "s", "for", "_", ",", "s", "in", "samples", "]", ")", "\n", "", "else", ":", "\n", "            ", "samples_dict", "=", "defaultdict", "(", "list", ")", "\n", "pad_to_length", "=", "(", "\n", "defaultdict", "(", "int", ")", "\n", "if", "\"pad_to_length\"", "not", "in", "extra_args", "\n", "else", "extra_args", "[", "\"pad_to_length\"", "]", "\n", ")", "\n", "for", "ds_idx", ",", "s", "in", "samples", ":", "\n", "                ", "pad_to_length", "[", "\"source\"", "]", "=", "max", "(", "\n", "pad_to_length", "[", "\"source\"", "]", ",", "s", "[", "\"source\"", "]", ".", "size", "(", "0", ")", "\n", ")", "\n", "if", "s", "[", "\"target\"", "]", "is", "not", "None", ":", "\n", "                    ", "pad_to_length", "[", "\"target\"", "]", "=", "max", "(", "\n", "pad_to_length", "[", "\"target\"", "]", ",", "s", "[", "\"target\"", "]", ".", "size", "(", "0", ")", "\n", ")", "\n", "", "samples_dict", "[", "ds_idx", "]", ".", "append", "(", "s", ")", "\n", "", "batches", "=", "[", "\n", "self", ".", "datasets", "[", "i", "]", ".", "collater", "(", "samples_dict", "[", "i", "]", ",", "pad_to_length", "=", "pad_to_length", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "datasets", ")", ")", "\n", "if", "len", "(", "samples_dict", "[", "i", "]", ")", ">", "0", "\n", "]", "\n", "\n", "def", "straight_data", "(", "tensors", ")", ":", "\n", "                ", "batch", "=", "torch", ".", "cat", "(", "tensors", ",", "dim", "=", "0", ")", "\n", "return", "batch", "\n", "\n", "", "src_lengths", "=", "straight_data", "(", "\n", "[", "b", "[", "\"net_input\"", "]", "[", "\"src_lengths\"", "]", "for", "b", "in", "batches", "]", "\n", ")", "\n", "src_lengths", ",", "sort_order", "=", "src_lengths", ".", "sort", "(", "descending", "=", "True", ")", "\n", "\n", "def", "straight_order", "(", "tensors", ")", ":", "\n", "                ", "batch", "=", "straight_data", "(", "tensors", ")", "\n", "return", "batch", ".", "index_select", "(", "0", ",", "sort_order", ")", "\n", "\n", "", "batch", "=", "{", "\n", "\"id\"", ":", "straight_order", "(", "[", "b", "[", "\"id\"", "]", "for", "b", "in", "batches", "]", ")", ",", "\n", "\"nsentences\"", ":", "sum", "(", "b", "[", "\"nsentences\"", "]", "for", "b", "in", "batches", ")", ",", "\n", "\"ntokens\"", ":", "sum", "(", "b", "[", "\"ntokens\"", "]", "for", "b", "in", "batches", ")", ",", "\n", "\"net_input\"", ":", "{", "\n", "\"src_tokens\"", ":", "straight_order", "(", "\n", "[", "b", "[", "\"net_input\"", "]", "[", "\"src_tokens\"", "]", "for", "b", "in", "batches", "]", "\n", ")", ",", "\n", "\"src_lengths\"", ":", "src_lengths", ",", "\n", "}", ",", "\n", "\"target\"", ":", "straight_order", "(", "[", "b", "[", "\"target\"", "]", "for", "b", "in", "batches", "]", ")", "\n", "if", "batches", "[", "0", "]", "[", "\"target\"", "]", "is", "not", "None", "\n", "else", "None", ",", "\n", "}", "\n", "if", "\"prev_output_tokens\"", "in", "batches", "[", "0", "]", "[", "\"net_input\"", "]", ":", "\n", "                ", "batch", "[", "\"net_input\"", "]", "[", "\"prev_output_tokens\"", "]", "=", "straight_order", "(", "\n", "[", "b", "[", "\"net_input\"", "]", "[", "\"prev_output_tokens\"", "]", "for", "b", "in", "batches", "]", "\n", ")", "\n", "", "if", "\"src_lang_id\"", "in", "batches", "[", "0", "]", "[", "\"net_input\"", "]", ":", "\n", "                ", "batch", "[", "\"net_input\"", "]", "[", "\"src_lang_id\"", "]", "=", "straight_order", "(", "\n", "[", "b", "[", "\"net_input\"", "]", "[", "\"src_lang_id\"", "]", "for", "b", "in", "batches", "]", "\n", ")", "\n", "", "if", "\"tgt_lang_id\"", "in", "batches", "[", "0", "]", ":", "\n", "                ", "batch", "[", "\"tgt_lang_id\"", "]", "=", "straight_order", "(", "\n", "[", "b", "[", "\"tgt_lang_id\"", "]", "for", "b", "in", "batches", "]", "\n", ")", "\n", "", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.sizes": [[327, 345], ["time.time", "numpy.vstack", "logger.info", "range", "zip", "len", "sampled_multi_dataset.get_time_gap", "time.time"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.get_time_gap"], ["", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_sizes", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_sizes", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "in_sub_dataset_indices", "=", "[", "\n", "self", ".", "_cur_indices", "[", "\n", "0", "if", "i", "==", "0", "else", "self", ".", "cumulated_sizes", "[", "i", "-", "1", "]", ":", "self", ".", "cumulated_sizes", "[", "i", "]", "\n", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "datasets", ")", ")", "\n", "]", "\n", "sub_dataset_sizes", "=", "[", "\n", "d", ".", "sizes", "[", "indices", "]", "\n", "for", "d", ",", "indices", "in", "zip", "(", "self", ".", "datasets", ",", "in_sub_dataset_indices", ")", "\n", "]", "\n", "self", ".", "_sizes", "=", "np", ".", "vstack", "(", "sub_dataset_sizes", ")", "\n", "logger", ".", "info", "(", "f\"sizes() calling time: {get_time_gap(start_time, time.time())}\"", ")", "\n", "return", "self", ".", "_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.ordered_indices": [[346, 363], ["numpy.random.permutation", "numpy.arange", "len", "len", "numpy.argsort", "len", "len", "numpy.argsort"], "methods", ["None"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "shuffle", ":", "\n", "            ", "indices", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ")", ")", "\n", "", "else", ":", "\n", "            ", "indices", "=", "np", ".", "arange", "(", "len", "(", "self", ")", ")", "\n", "\n", "", "sizes", "=", "self", ".", "sizes", "\n", "tgt_sizes", "=", "sizes", "[", ":", ",", "1", "]", "if", "len", "(", "sizes", ".", "shape", ")", ">", "0", "and", "sizes", ".", "shape", "[", "1", "]", ">", "1", "else", "None", "\n", "src_sizes", "=", "(", "\n", "sizes", "[", ":", ",", "0", "]", "if", "len", "(", "sizes", ".", "shape", ")", ">", "0", "and", "sizes", ".", "shape", "[", "1", "]", ">", "1", "else", "sizes", "\n", ")", "\n", "\n", "# sort by target length, then source length", "\n", "if", "tgt_sizes", "is", "not", "None", ":", "\n", "            ", "indices", "=", "indices", "[", "np", ".", "argsort", "(", "tgt_sizes", "[", "indices", "]", ",", "kind", "=", "\"mergesort\"", ")", "]", "\n", "", "sort_indices", "=", "indices", "[", "np", ".", "argsort", "(", "src_sizes", "[", "indices", "]", ",", "kind", "=", "\"mergesort\"", ")", "]", "\n", "return", "sort_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch": [[364, 371], ["range", "sampled_multi_dataset.SampledMultiDataset._get_dataset_and_index", "prefetch_indices[].append", "len", "sampled_multi_dataset.SampledMultiDataset.datasets[].prefetch", "range", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset._get_dataset_and_index", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.prefetch"], ["", "def", "prefetch", "(", "self", ",", "indices", ")", ":", "\n", "        ", "prefetch_indices", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "self", ".", "datasets", ")", ")", "]", "\n", "for", "i", "in", "indices", ":", "\n", "            ", "ds_idx", ",", "ds_sample_idx", "=", "self", ".", "_get_dataset_and_index", "(", "i", ")", "\n", "prefetch_indices", "[", "ds_idx", "]", ".", "append", "(", "ds_sample_idx", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "prefetch_indices", ")", ")", ":", "\n", "            ", "self", ".", "datasets", "[", "i", "]", ".", "prefetch", "(", "prefetch_indices", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.can_reuse_epoch_itr_across_epochs": [[372, 375], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "can_reuse_epoch_itr_across_epochs", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.set_epoch": [[376, 386], ["super().set_epoch", "sampled_multi_dataset.SampledMultiDataset._establish_virtual_datasets", "hasattr", "d.set_epoch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset._establish_virtual_datasets", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "super", "(", ")", ".", "set_epoch", "(", "epoch", ")", "\n", "if", "epoch", "==", "self", ".", "_cur_epoch", ":", "\n", "# re-enter so return", "\n", "            ", "return", "\n", "", "for", "d", "in", "self", ".", "datasets", ":", "\n", "            ", "if", "hasattr", "(", "d", ",", "\"set_epoch\"", ")", ":", "\n", "                ", "d", ".", "set_epoch", "(", "epoch", ")", "\n", "", "", "self", ".", "_cur_epoch", "=", "epoch", "\n", "self", ".", "_establish_virtual_datasets", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset._establish_virtual_datasets": [[387, 439], ["sampled_multi_dataset.SampledMultiDataset._reset_cached_properties", "time.time", "numpy.random.RandomState", "sampled_multi_dataset.SampledMultiDataset._clean_if_not_none", "sampled_multi_dataset.SampledMultiDataset.get_virtual_indices", "logger.info", "logger.info", "logger.info", "len", "logger.info", "logger.info", "int", "str", "sum", "str", "sum", "sampled_multi_dataset.get_time_gap", "hashlib.sha1().hexdigest", "dict", "dict", "str", "time.time", "zip", "zip", "dict", "hashlib.sha1", "zip", "str().encode", "str"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset._reset_cached_properties", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset._clean_if_not_none", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.get_virtual_indices", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.get_time_gap", "home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "def", "_establish_virtual_datasets", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "sample_ratios", "is", "None", "and", "self", ".", "_cur_indices", "is", "not", "None", ":", "\n", "# not a samping dataset, no need to resample if indices are already established", "\n", "            ", "return", "\n", "", "self", ".", "_reset_cached_properties", "(", ")", "\n", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "# Generate a weighted sample of indices as a function of the", "\n", "# random seed and the current epoch.", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "\n", "[", "\n", "int", "(", "\n", "hashlib", ".", "sha1", "(", "\n", "str", "(", "self", ".", "__class__", ".", "__name__", ")", ".", "encode", "(", "\"utf-8\"", ")", "\n", ")", ".", "hexdigest", "(", ")", ",", "\n", "16", ",", "\n", ")", "\n", "%", "(", "2", "**", "32", ")", ",", "\n", "self", ".", "seed", "%", "(", "2", "**", "32", ")", ",", "# global seed", "\n", "self", ".", "_cur_epoch", ",", "# epoch index,", "\n", "]", "\n", ")", "\n", "self", ".", "_clean_if_not_none", "(", "\n", "[", "self", ".", "cumulated_sizes", ",", "self", ".", "virtual_size_per_dataset", ",", "self", ".", "_sizes", "]", "\n", ")", "\n", "self", ".", "_sizes", "=", "None", "\n", "\n", "indices", ",", "cumulated_sizes", ",", "virtual_size_per_dataset", "=", "self", ".", "get_virtual_indices", "(", "\n", "rng", ",", "self", ".", "datasets", ",", "self", ".", "sample_ratios", ",", "self", ".", "virtual_size", "\n", ")", "\n", "self", ".", "_cur_indices", "=", "indices", "\n", "self", ".", "cumulated_sizes", "=", "cumulated_sizes", "\n", "self", ".", "virtual_size_per_dataset", "=", "virtual_size_per_dataset", "\n", "\n", "raw_sizes", "=", "[", "len", "(", "d", ")", "for", "d", "in", "self", ".", "datasets", "]", "\n", "sampled_sizes", "=", "self", ".", "virtual_size_per_dataset", "\n", "logger", ".", "info", "(", "\n", "f\"[{self.split}] Raw sizes: {str(dict(zip(self.keys, raw_sizes)))}; \"", "\n", "f\"raw total size: {sum(raw_sizes)}\"", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "f\"[{self.split}] Resampled sizes: {str(dict(zip(self.keys, sampled_sizes)))}; \"", "\n", "f\"resampled total size: {sum(sampled_sizes)}\"", "\n", ")", "\n", "if", "self", ".", "sample_ratios", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"[{self.split}] Upsampling ratios: {str(dict(zip(self.keys, self.sample_ratios)))}\"", "\n", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "f\"[{self.split}] A concat dataset\"", ")", "\n", "", "logger", ".", "info", "(", "\n", "f\"[{self.split}] virtual dataset established time: {get_time_gap(start_time, time.time())}\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset.filter_indices_by_size": [[441, 462], ["fairseq.data.data_utils.filter_paired_dataset_indices_by_size", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils.filter_paired_dataset_indices_by_size"], ["", "def", "filter_indices_by_size", "(", "self", ",", "indices", ",", "max_sizes", ")", ":", "\n", "        ", "\"\"\"Filter a list of sample indices. Remove those that are longer\n            than specified in max_sizes.\n\n        Args:\n            indices (np.array): original array of sample indices\n            max_sizes (int or list[int] or tuple[int]): max sample size,\n                can be defined separately for src and tgt (then list or tuple)\n\n        Returns:\n            np.array: filtered sample array\n            list: list of removed indices\n        \"\"\"", "\n", "sizes", "=", "self", ".", "sizes", "\n", "tgt_sizes", "=", "sizes", "[", ":", ",", "1", "]", "if", "len", "(", "sizes", ".", "shape", ")", ">", "0", "and", "sizes", ".", "shape", "[", "1", "]", ">", "1", "else", "None", "\n", "src_sizes", "=", "(", "\n", "sizes", "[", ":", ",", "0", "]", "if", "len", "(", "sizes", ".", "shape", ")", ">", "0", "and", "sizes", ".", "shape", "[", "1", "]", ">", "1", "else", "sizes", "\n", ")", "\n", "\n", "return", "data_utils", ".", "filter_paired_dataset_indices_by_size", "(", "\n", "src_sizes", ",", "tgt_sizes", ",", "indices", ",", "max_sizes", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.get_time_gap": [[21, 24], ["datetime.datetime.fromtimestamp", "datetime.datetime.fromtimestamp"], "function", ["None"], ["def", "get_time_gap", "(", "s", ",", "e", ")", ":", "\n", "    ", "return", "(", "\n", "datetime", ".", "datetime", ".", "fromtimestamp", "(", "e", ")", "-", "datetime", ".", "datetime", ".", "fromtimestamp", "(", "s", ")", "\n", ")", ".", "__str__", "(", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.default_virtual_size_func": [[30, 42], ["numpy.argmax", "sum", "int", "len", "sum", "sum"], "function", ["None"], ["def", "default_virtual_size_func", "(", "datasets", ",", "ratios", ",", "max_scale_up", "=", "1.5", ")", ":", "\n", "    ", "sizes", "=", "[", "len", "(", "d", ")", "for", "d", "in", "datasets", "]", "\n", "if", "ratios", "is", "None", ":", "\n", "        ", "return", "sum", "(", "sizes", ")", "\n", "", "largest_idx", "=", "np", ".", "argmax", "(", "sizes", ")", "\n", "largest_r", "=", "ratios", "[", "largest_idx", "]", "\n", "largest_s", "=", "sizes", "[", "largest_idx", "]", "\n", "# set virtual sizes relative to the largest dataset", "\n", "virtual_sizes", "=", "[", "(", "r", "/", "largest_r", ")", "*", "largest_s", "for", "r", "in", "ratios", "]", "\n", "vsize", "=", "sum", "(", "virtual_sizes", ")", "\n", "max_size", "=", "sum", "(", "sizes", ")", "*", "max_scale_up", "\n", "return", "int", "(", "vsize", "if", "vsize", "<", "max_size", "else", "max_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.__init__": [[49, 81], ["fairseq.data.SampledMultiDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "datasets", ",", "\n", "sampling_ratios", "=", "None", ",", "\n", "seed", "=", "2", ",", "\n", "epoch", "=", "1", ",", "\n", "eval_key", "=", "None", ",", "\n", "collate_format", "=", "CollateFormat", ".", "single", ",", "\n", "virtual_size", "=", "default_virtual_size_func", ",", "\n", "split", "=", "\"\"", ",", "\n", "virtual_epoch_size", "=", "None", ",", "\n", "shared_collater", "=", "False", ",", "\n", "shard_epoch", "=", "1", ",", "\n", "shuffle", "=", "True", ",", "\n", ")", ":", "\n", "        ", "self", ".", "virtual_epoch_size", "=", "virtual_epoch_size", "\n", "self", ".", "_current_epoch_start_index", "=", "None", "\n", "self", ".", "_random_global_indices", "=", "None", "\n", "self", ".", "shard_epoch", "=", "shard_epoch", "if", "shard_epoch", "is", "not", "None", "else", "1", "\n", "self", ".", "load_next_shard", "=", "None", "\n", "self", ".", "_epoch_sizes", "=", "None", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "datasets", "=", "datasets", ",", "\n", "sampling_ratios", "=", "sampling_ratios", ",", "\n", "seed", "=", "seed", ",", "\n", "epoch", "=", "epoch", ",", "\n", "eval_key", "=", "eval_key", ",", "\n", "collate_format", "=", "collate_format", ",", "\n", "virtual_size", "=", "virtual_size", ",", "\n", "split", "=", "split", ",", "\n", "shared_collater", "=", "shared_collater", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset._setup": [[83, 99], ["math.ceil", "sampled_multi_epoch_dataset.SampledMultiEpochDataset._get_epoch_start_index", "logger.info", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset._get_epoch_start_index"], ["", "def", "_setup", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "self", ".", "virtual_epoch_size", "=", "(", "\n", "self", ".", "virtual_epoch_size", "\n", "if", "self", ".", "virtual_epoch_size", "is", "not", "None", "\n", "else", "self", ".", "virtual_size", "\n", ")", "\n", "if", "self", ".", "virtual_epoch_size", ">", "self", ".", "virtual_size", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "f\"virtual epoch size {self.virtual_epoch_size} \"", "\n", "f\"is greater than virtual dataset size {self.virtual_size}\"", "\n", ")", "\n", "self", ".", "virtual_epoch_size", "=", "self", ".", "virtual_size", "\n", "", "self", ".", "num_virtual_epochs", "=", "math", ".", "ceil", "(", "self", ".", "virtual_size", "/", "self", ".", "virtual_epoch_size", ")", "\n", "self", ".", "_current_epoch_start_index", "=", "self", ".", "_get_epoch_start_index", "(", "epoch", ")", "\n", "logger", ".", "info", "(", "\n", "f\"virtual epoch size {self.virtual_epoch_size}; virtual dataset size {self.virtual_size}\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset._map_epoch_index_to_global": [[101, 105], ["None"], "methods", ["None"], ["", "def", "_map_epoch_index_to_global", "(", "self", ",", "index", ")", ":", "\n", "        ", "index", "=", "self", ".", "_current_epoch_start_index", "+", "index", "\n", "# add randomness", "\n", "return", "self", ".", "_random_global_indices", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.sizes": [[106, 120], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_epoch_sizes", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_epoch_sizes", "\n", "", "_sizes", "=", "super", "(", ")", ".", "sizes", "\n", "indices", "=", "self", ".", "_random_global_indices", "[", "\n", "self", ".", "_current_epoch_start_index", ":", "self", ".", "_current_epoch_start_index", "\n", "+", "len", "(", "self", ")", "\n", "]", "\n", "self", ".", "_epoch_sizes", "=", "_sizes", "[", "indices", "]", "\n", "# del super()._sizes to save memory", "\n", "del", "self", ".", "_sizes", "\n", "self", ".", "_sizes", "=", "None", "\n", "return", "self", ".", "_epoch_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset._get_dataset_and_index": [[121, 124], ["sampled_multi_epoch_dataset.SampledMultiEpochDataset._map_epoch_index_to_global", "super()._get_dataset_and_index"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset._map_epoch_index_to_global", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset._get_dataset_and_index"], ["", "def", "_get_dataset_and_index", "(", "self", ",", "index", ")", ":", "\n", "        ", "i", "=", "self", ".", "_map_epoch_index_to_global", "(", "index", ")", "\n", "return", "super", "(", ")", ".", "_get_dataset_and_index", "(", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.__len__": [[125, 131], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "virtual_epoch_size", "\n", "if", "self", ".", "_current_epoch_start_index", "+", "self", ".", "virtual_epoch_size", "\n", "<", "self", ".", "virtual_size", "\n", "else", "self", ".", "virtual_size", "-", "self", ".", "_current_epoch_start_index", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch": [[133, 144], ["sampled_multi_epoch_dataset.SampledMultiEpochDataset._setup", "sampled_multi_epoch_dataset.SampledMultiEpochDataset._next_virtual_epoch", "sampled_multi_epoch_dataset.SampledMultiEpochDataset._next_virtual_epoch"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset._setup", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset._next_virtual_epoch", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset._next_virtual_epoch"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "if", "self", ".", "_current_epoch_start_index", "is", "None", ":", "\n", "# initializing epoch idnices of a virtual dataset", "\n", "            ", "self", ".", "_setup", "(", "epoch", ")", "\n", "self", ".", "_next_virtual_epoch", "(", "epoch", ")", "\n", "", "else", ":", "\n", "# working on already intialized epoch indices", "\n", "            ", "if", "epoch", "==", "self", ".", "_cur_epoch", ":", "\n", "# re-enter so return", "\n", "                ", "return", "\n", "", "self", ".", "_next_virtual_epoch", "(", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset._get_epoch_start_index": [[145, 148], ["None"], "methods", ["None"], ["", "", "def", "_get_epoch_start_index", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "assert", "epoch", ">=", "1", "# fairseq is using 1-based epoch everywhere", "\n", "return", "(", "(", "epoch", "-", "1", ")", "%", "self", ".", "num_virtual_epochs", ")", "*", "self", ".", "virtual_epoch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset._next_global_indices": [[149, 175], ["numpy.random.RandomState", "numpy.random.RandomState.choice", "logger.info", "int", "hashlib.sha1().hexdigest", "hashlib.sha1", "str().encode", "str"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.encoders.sentencepiece_bpe.SentencepieceBPE.encode"], ["", "def", "_next_global_indices", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "\n", "[", "\n", "int", "(", "\n", "hashlib", ".", "sha1", "(", "\n", "str", "(", "self", ".", "__class__", ".", "__name__", ")", ".", "encode", "(", "\"utf-8\"", ")", "\n", ")", ".", "hexdigest", "(", ")", ",", "\n", "16", ",", "\n", ")", "\n", "%", "(", "2", "**", "32", ")", ",", "\n", "self", ".", "seed", "%", "(", "2", "**", "32", ")", ",", "# global seed", "\n", "epoch", ",", "# epoch index,", "\n", "]", "\n", ")", "\n", "del", "self", ".", "_random_global_indices", "\n", "self", ".", "_random_global_indices", "=", "rng", ".", "choice", "(", "\n", "self", ".", "virtual_size", ",", "self", ".", "virtual_size", ",", "replace", "=", "False", "\n", ")", "\n", "if", "self", ".", "load_next_shard", "is", "None", ":", "\n", "            ", "self", ".", "load_next_shard", "=", "False", "\n", "", "else", ":", "\n", "# increase shard epoch for next loading", "\n", "            ", "self", ".", "shard_epoch", "+=", "1", "\n", "self", ".", "load_next_shard", "=", "True", "\n", "logger", ".", "info", "(", "\n", "\"to load next epoch/shard in next load_dataset: \"", "\n", "f\"epoch={epoch}/shard_epoch={self.shard_epoch}\"", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset._next_virtual_epoch": [[178, 200], ["sampled_multi_epoch_dataset.SampledMultiEpochDataset._get_epoch_start_index", "sampled_multi_epoch_dataset.SampledMultiEpochDataset._clean_if_not_none", "logger.info", "super().set_epoch", "sampled_multi_epoch_dataset.SampledMultiEpochDataset._next_global_indices"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset._get_epoch_start_index", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_dataset.SampledMultiDataset._clean_if_not_none", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset.set_epoch", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampled_multi_epoch_dataset.SampledMultiEpochDataset._next_global_indices"], ["", "", "def", "_next_virtual_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "index", "=", "self", ".", "_get_epoch_start_index", "(", "epoch", ")", "\n", "if", "index", "==", "0", "or", "self", ".", "_random_global_indices", "is", "None", ":", "\n", "# need to start from the beginning,", "\n", "# so call super().set_epoch(epoch) to establish the global virtual indices", "\n", "            ", "logger", ".", "info", "(", "\n", "\"establishing a new set of global virtual indices for \"", "\n", "f\"epoch={epoch}/shard_epoch={self.shard_epoch}\"", "\n", ")", "\n", "super", "(", ")", ".", "set_epoch", "(", "epoch", ")", "\n", "self", ".", "_next_global_indices", "(", "epoch", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_cur_epoch", "=", "epoch", "\n", "\n", "# reset cache sizes and ordered_indices for the epoch after moving to a new epoch", "\n", "", "self", ".", "_clean_if_not_none", "(", "\n", "[", "\n", "self", ".", "_epoch_sizes", ",", "\n", "]", "\n", ")", "\n", "self", ".", "_epoch_sizes", "=", "None", "\n", "self", ".", "_current_epoch_start_index", "=", "index", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.__init__": [[57, 70], ["object.__init__", "multilingual_data_manager.MultilingualDatasetManager.create_lang_dictionary", "collections.defaultdict"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.create_lang_dictionary"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "lang_pairs", ",", "langs", ",", "dicts", ",", "sampling_method", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "seed", "=", "args", ".", "seed", "\n", "self", ".", "lang_pairs", "=", "lang_pairs", "\n", "self", ".", "langs", "=", "langs", "\n", "self", ".", "dicts", "=", "dicts", "\n", "self", ".", "lang_dict", "=", "self", ".", "create_lang_dictionary", "(", "self", ".", "langs", ")", "\n", "self", ".", "sampling_method", "=", "sampling_method", "\n", "self", ".", "sampling_scheduler", "=", "None", "\n", "self", ".", "_has_sharded_data", "=", "False", "\n", "self", ".", "_num_shards_dict", "=", "{", "}", "\n", "self", ".", "_training_data_sizes", "=", "defaultdict", "(", "lambda", ":", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.setup_data_manager": [[71, 75], ["multilingual_data_manager.MultilingualDatasetManager"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "setup_data_manager", "(", "cls", ",", "args", ",", "lang_pairs", ",", "langs", ",", "dicts", ",", "sampling_method", ")", ":", "\n", "        ", "return", "MultilingualDatasetManager", "(", "\n", "args", ",", "lang_pairs", ",", "langs", ",", "dicts", ",", "sampling_method", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.add_args": [[77, 248], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "fairseq.utils.eval_str_dict", "fairseq.utils.eval_str_dict", "fairseq.utils.eval_str_dict", "fairseq.utils.eval_str_dict"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.eval_str_dict", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.eval_str_dict", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.eval_str_dict", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.eval_str_dict"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "\n", "\"data\"", ",", "\n", "help", "=", "\"colon separated path to data directories list, \\\n                            will be iterated upon during epochs in round-robin manner\"", ",", "\n", "action", "=", "FileContentsAction", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--langs\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "csv_str_list", ",", "\n", "help", "=", "\"a list of languages comma sperated languages which can appear in lang-pairs; \"", "\n", "\"note that the ordering determines language token IDs\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lang-dict\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"an external file which contains a list of \"", "\n", "\"languages which can appear in lang-pairs; \"", "\n", "\"note that the ordering determines language token IDs; \"", "\n", "\"--langs and --lang-dict are two exclusive options\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lang-tok-style\"", ",", "\n", "default", "=", "LangTokStyle", ".", "multilingual", ".", "value", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "[", "LangTokStyle", ".", "multilingual", ".", "value", ",", "LangTokStyle", ".", "mbart", ".", "value", "]", ",", "\n", "help", "=", "\"language token styles\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--load-alignments\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"load the binarized alignments\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--left-pad-source\"", ",", "\n", "default", "=", "\"True\"", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"BOOL\"", ",", "\n", "help", "=", "\"pad the source on the left\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--left-pad-target\"", ",", "\n", "default", "=", "\"False\"", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "\"BOOL\"", ",", "\n", "help", "=", "\"pad the target on the left\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max-source-positions\"", ",", "\n", "default", "=", "1024", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"max number of tokens in the source sequence\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max-target-positions\"", ",", "\n", "default", "=", "1024", ",", "\n", "type", "=", "int", ",", "\n", "metavar", "=", "\"N\"", ",", "\n", "help", "=", "\"max number of tokens in the target sequence\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--upsample-primary\"", ",", "\n", "default", "=", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"amount to upsample primary dataset\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--truncate-source\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"truncate source to max-source-positions\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder-langtok\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "[", "EncoderLangtok", ".", "src", ".", "value", ",", "EncoderLangtok", ".", "tgt", ".", "value", "]", ",", "\n", "metavar", "=", "\"SRCTGT\"", ",", "\n", "help", "=", "\"prepend to the beginning of source sentence the source or target \"", "\n", "\"language token. (src/tgt)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder-langtok\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"prepend to the beginning of target sentence the target language token\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lang-tok-replacing-bos-eos\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--enable-lang-ids\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"whether to include language IDs in samples\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--enable-reservsed-directions-shared-datasets\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"whether to allow datasets be used in reversed directions\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--extra-data\"", ",", "\n", "help", "=", "'a dictionary of data name to this path, \\\n                            e.g. {\"mined\", path_to_mined_data, \"denoised\": path_to_denoised_data}'", ",", "\n", "type", "=", "lambda", "uf", ":", "eval_str_dict", "(", "uf", ",", "type", "=", "str", ")", ",", "\n", "default", "=", "None", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--extra-lang-pairs\"", ",", "\n", "help", "=", "'a dictionary of data name to the language pairs they serve, \\\n                            e.g. {\"mined\": comma-separated-lang-pairs, \"denoised\":  comma-separated-lang-pairs}'", ",", "\n", "type", "=", "lambda", "uf", ":", "eval_str_dict", "(", "uf", ",", "type", "=", "str", ")", ",", "\n", "default", "=", "None", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fixed-dictionary\"", ",", "\n", "help", "=", "\"Fixed dictionary to use with model path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--langtoks-specs\"", ",", "\n", "help", "=", "'a list of comma separated data types that a set of language tokens to be specialized for, \\\n                            e.g. \"main,dae,mined\". There will be a set of language tokens added to the vocab to \\\n                            distinguish languages in different training data types. If not specified, default language \\\n                            tokens per languages will be added'", ",", "\n", "default", "=", "LangTokSpec", ".", "main", ".", "value", ",", "\n", "type", "=", "csv_str_list", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--langtoks\"", ",", "\n", "help", "=", "'a dictionary of how to add language tokens, \\\n                            e.g. {\"mined\": (None, \"tgt\"), \"mono_dae\": (\"src.dae\", \"tgt\"), \"main\": \\\n                            (\"src\", \"tgt\")}, or {\"mined\": (\"src.mined\", \"tgt\")}'", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "lambda", "uf", ":", "eval_str_dict", "(", "uf", ",", "type", "=", "str", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--sampling-weights-from-file\"", ",", "\n", "help", "=", "'a file contain a python dictionary of how to sample data sets, \\\n                                e.g. { \"main:en_XX-es_XX\": 0.2, \"mined:en_XX-pt_XX\": 0.5, \\\n                                    \"mono_dae:es_XX-es_XX: 0.3, \"main:en_xx-fr_XX\": 0.8 }'", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--sampling-weights\"", ",", "\n", "help", "=", "'a dictionary of how to sample data sets, \\\n                            e.g. { \"main:en_XX-es_XX\": 0.2, \"mined:en_XX-pt_XX\": 0.5, \\\n                                   \"mono_dae:es_XX-es_XX: 0.3, \"main:en_xx-fr_XX\": 0.8 }'", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "lambda", "uf", ":", "eval_str_dict", "(", "uf", ",", "type", "=", "str", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--virtual-epoch-size\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"virtual epoch size to speed up data loading\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--virtual-data-size\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"virtual data size of the whole joint dataset to speed\"", "\n", "\"up data loading and have specific dynamic sampling strategy interval\"", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_langs": [[251, 282], ["ValueError", "logger.warning", "list", "sorted", "logger.info", "open", "logger.info", "logger.info", "lang_pair.split", "fairseq.file_io.PathManager.get_local_path", "lang.strip", "f.readlines", "lang.strip"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.get_local_path"], ["", "@", "classmethod", "\n", "def", "load_langs", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "args", ".", "lang_dict", "and", "args", ".", "langs", ":", "\n", "            ", "raise", "ValueError", "(", "\"--langs and --lang-dict can not both be specified\"", ")", "\n", "", "if", "args", ".", "lang_dict", "is", "None", "and", "args", ".", "langs", "is", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"External language dictionary is not provided; \"", "\n", "\"use lang-pairs to infer the set of supported languages. \"", "\n", "\"The language ordering is not stable which might cause \"", "\n", "\"misalignment in pretraining and finetuning.\"", "\n", ")", "\n", "# infer from lang_pairs as it is", "\n", "langs", "=", "list", "(", "\n", "{", "x", "for", "lang_pair", "in", "args", ".", "lang_pairs", "for", "x", "in", "lang_pair", ".", "split", "(", "\"-\"", ")", "}", "\n", ")", "\n", "langs", "=", "sorted", "(", "langs", ")", "\n", "logger", ".", "info", "(", "f\"inferred language list: {langs}\"", ")", "\n", "", "elif", "args", ".", "lang_dict", ":", "\n", "            ", "with", "open", "(", "\n", "PathManager", ".", "get_local_path", "(", "args", ".", "lang_dict", ")", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", "\n", ")", "as", "f", ":", "\n", "                ", "langs", "=", "[", "lang", ".", "strip", "(", ")", "for", "lang", "in", "f", ".", "readlines", "(", ")", "if", "lang", ".", "strip", "(", ")", "]", "\n", "logger", ".", "info", "(", "\n", "f\"loaded language list from {args.lang_dict} as they are ordered in file\"", "\n", ")", "\n", "", "", "elif", "args", ".", "langs", ":", "\n", "            ", "langs", "=", "args", ".", "langs", "\n", "logger", ".", "info", "(", "\n", "f\"parsed the language list as they are ordered in the option: {langs}\"", "\n", ")", "\n", "", "return", "langs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.has_sharded_data": [[283, 286], ["getattr"], "methods", ["None"], ["", "def", "has_sharded_data", "(", "self", ",", "split", ")", ":", "\n", "        ", "return", "self", ".", "_has_sharded_data", "and", "split", "==", "getattr", "(", "\n", "self", ".", "args", ",", "\"train_subset\"", ",", "None", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager._shared_collater": [[288, 291], ["None"], "methods", ["None"], ["", "def", "_shared_collater", "(", "self", ")", ":", "\n", "        ", "return", "not", "(", "self", ".", "args", ".", "extra_data", "and", "\"mono_dae\"", "in", "self", ".", "args", ".", "extra_data", ")", "and", "(", "\n", "not", "self", ".", "args", ".", "lang_tok_replacing_bos_eos", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.estimate_global_pass_epoch": [[293, 303], ["math.ceil"], "methods", ["None"], ["", "def", "estimate_global_pass_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "virtual_epoch_size", "is", "None", "or", "self", ".", "args", ".", "virtual_data_size", "is", "None", ":", "\n", "            ", "return", "None", "\n", "# one epoch more for remaining data in each shard", "\n", "", "virtual_epochs_per_shard", "=", "math", ".", "ceil", "(", "\n", "self", ".", "args", ".", "virtual_data_size", "/", "self", ".", "args", ".", "virtual_epoch_size", "\n", ")", "\n", "# note that fairseq epoch / shard_epoch starts from 1", "\n", "shard_epoch", "=", "(", "epoch", "-", "1", ")", "//", "virtual_epochs_per_shard", "+", "1", "\n", "return", "shard_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.prepare": [[304, 387], ["fairseq.utils.eval_bool", "fairseq.utils.eval_bool", "isinstance", "cls.load_langs", "multilingual_data_manager.MultilingualDatasetManager.prepare.check_langs"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.eval_bool", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.eval_bool", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_langs"], ["", "@", "classmethod", "\n", "def", "prepare", "(", "cls", ",", "load_dictionary", ",", "args", ",", "**", "kargs", ")", ":", "\n", "        ", "args", ".", "left_pad_source", "=", "utils", ".", "eval_bool", "(", "args", ".", "left_pad_source", ")", "\n", "args", ".", "left_pad_target", "=", "utils", ".", "eval_bool", "(", "args", ".", "left_pad_target", ")", "\n", "\n", "if", "not", "hasattr", "(", "args", ",", "\"shuffle_instance\"", ")", ":", "\n", "            ", "args", ".", "shuffle_instance", "=", "False", "\n", "", "if", "args", ".", "langtoks", "is", "None", ":", "\n", "            ", "args", ".", "langtoks", "=", "{", "}", "\n", "", "if", "\"main\"", "not", "in", "args", ".", "langtoks", ":", "\n", "            ", "src_langtok_spec", "=", "args", ".", "encoder_langtok", "if", "args", ".", "encoder_langtok", "else", "None", "\n", "tgt_langtok_spec", "=", "\"tgt\"", "if", "args", ".", "decoder_langtok", "else", "None", "\n", "args", ".", "langtoks", "[", "\"main\"", "]", "=", "(", "src_langtok_spec", ",", "tgt_langtok_spec", ")", "\n", "\n", "", "def", "check_langs", "(", "langs", ",", "pairs", ")", ":", "\n", "            ", "messages", "=", "[", "]", "\n", "for", "src", ",", "tgt", "in", "pairs", ":", "\n", "                ", "if", "src", "not", "in", "langs", "or", "tgt", "not", "in", "langs", ":", "\n", "                    ", "messages", ".", "append", "(", "\n", "f\"language pair {src}-{tgt} contains languages \"", "\n", "\"that are not in the language dictionary\"", "\n", ")", "\n", "", "", "if", "len", "(", "messages", ")", ">", "0", ":", "\n", "                ", "raise", "ValueError", "(", "\" \"", ".", "join", "(", "messages", ")", "+", "f\"; langs: {langs}\"", ")", "\n", "\n", "", "", "if", "args", ".", "lang_pairs", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"--lang-pairs is required. List all the language pairs in the training objective.\"", "\n", ")", "\n", "", "if", "isinstance", "(", "args", ".", "lang_pairs", ",", "str", ")", ":", "\n", "            ", "args", ".", "lang_pairs", "=", "args", ".", "lang_pairs", ".", "split", "(", "\",\"", ")", "\n", "", "if", "args", ".", "source_lang", "is", "not", "None", "or", "args", ".", "target_lang", "is", "not", "None", ":", "\n", "            ", "training", "=", "False", "\n", "", "else", ":", "\n", "            ", "training", "=", "True", "\n", "", "language_list", "=", "cls", ".", "load_langs", "(", "args", ",", "**", "kargs", ")", "\n", "check_langs", "(", "\n", "language_list", ",", "\n", "(", "\n", "[", "p", ".", "split", "(", "\"-\"", ")", "for", "p", "in", "args", ".", "lang_pairs", "]", "\n", "if", "training", "\n", "else", "[", "(", "args", ".", "source_lang", ",", "args", ".", "target_lang", ")", "]", "\n", ")", ",", "\n", ")", "\n", "\n", "# load dictionaries", "\n", "if", "training", ":", "\n", "            ", "extra_lang_pairs", "=", "(", "\n", "list", "(", "\n", "{", "p", "for", "_", ",", "v", "in", "args", ".", "extra_lang_pairs", ".", "items", "(", ")", "for", "p", "in", "v", ".", "split", "(", "\",\"", ")", "}", "\n", ")", "\n", "if", "args", ".", "extra_lang_pairs", "\n", "else", "[", "]", "\n", ")", "\n", "langs_to_load_dicts", "=", "sorted", "(", "\n", "{", "x", "for", "p", "in", "args", ".", "lang_pairs", "+", "extra_lang_pairs", "for", "x", "in", "p", ".", "split", "(", "\"-\"", ")", "}", "\n", ")", "\n", "", "else", ":", "\n", "            ", "langs_to_load_dicts", "=", "sorted", "(", "[", "args", ".", "source_lang", ",", "args", ".", "target_lang", "]", ")", "\n", "\n", "", "dicts", "=", "OrderedDict", "(", ")", "\n", "paths", "=", "utils", ".", "split_paths", "(", "args", ".", "data", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "for", "lang", "in", "langs_to_load_dicts", ":", "\n", "            ", "if", "args", ".", "fixed_dictionary", "is", "not", "None", ":", "\n", "                ", "dicts", "[", "lang", "]", "=", "load_dictionary", "(", "args", ".", "fixed_dictionary", ")", "\n", "", "else", ":", "\n", "                ", "dicts", "[", "lang", "]", "=", "load_dictionary", "(", "\n", "os", ".", "path", ".", "join", "(", "paths", "[", "0", "]", ",", "\"dict.{}.txt\"", ".", "format", "(", "lang", ")", ")", "\n", ")", "\n", "augment_dictionary", "(", "\n", "dictionary", "=", "dicts", "[", "lang", "]", ",", "\n", "language_list", "=", "language_list", ",", "\n", "lang_tok_style", "=", "args", ".", "lang_tok_style", ",", "\n", "langtoks_specs", "=", "args", ".", "langtoks_specs", ",", "\n", "extra_data", "=", "args", ".", "extra_data", ",", "\n", ")", "\n", "", "if", "len", "(", "dicts", ")", ">", "0", ":", "\n", "                ", "assert", "dicts", "[", "lang", "]", ".", "pad", "(", ")", "==", "dicts", "[", "langs_to_load_dicts", "[", "0", "]", "]", ".", "pad", "(", ")", "\n", "assert", "dicts", "[", "lang", "]", ".", "eos", "(", ")", "==", "dicts", "[", "langs_to_load_dicts", "[", "0", "]", "]", ".", "eos", "(", ")", "\n", "assert", "dicts", "[", "lang", "]", ".", "unk", "(", ")", "==", "dicts", "[", "langs_to_load_dicts", "[", "0", "]", "]", ".", "unk", "(", ")", "\n", "", "logger", ".", "info", "(", "\"[{}] dictionary: {} types\"", ".", "format", "(", "lang", ",", "len", "(", "dicts", "[", "lang", "]", ")", ")", ")", "\n", "", "return", "language_list", ",", "dicts", ",", "training", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.create_lang_dictionary": [[388, 396], ["fairseq.data.Dictionary", "fairseq.data.Dictionary.add_symbol"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol"], ["", "@", "classmethod", "\n", "def", "create_lang_dictionary", "(", "cls", ",", "langs", ")", ":", "\n", "        ", "unk", "=", "\"<unk>\"", "\n", "# hack to remove symbols other than unk as they are not needed by lang dict", "\n", "lang_dict", "=", "Dictionary", "(", "pad", "=", "unk", ",", "eos", "=", "unk", ",", "unk", "=", "unk", ",", "bos", "=", "unk", ")", "\n", "for", "lang", "in", "langs", ":", "\n", "            ", "lang_dict", ".", "add_symbol", "(", "lang", ")", "\n", "", "return", "lang_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_langtok_index": [[397, 404], ["dic.index"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.index"], ["", "@", "classmethod", "\n", "def", "get_langtok_index", "(", "cls", ",", "lang_tok", ",", "dic", ")", ":", "\n", "        ", "idx", "=", "dic", ".", "index", "(", "lang_tok", ")", "\n", "assert", "(", "\n", "idx", "!=", "dic", ".", "unk_index", "\n", ")", ",", "\"cannot find language token {} in the dictionary\"", ".", "format", "(", "lang_tok", ")", "\n", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_encoder_langtok": [[405, 422], ["multilingual_data_manager.MultilingualDatasetManager.get_langtok_index", "spec.startswith", "fairseq.data.multilingual.multilingual_utils.get_lang_tok", "fairseq.data.multilingual.multilingual_utils.get_lang_tok"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_langtok_index", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_utils.get_lang_tok", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_utils.get_lang_tok"], ["", "def", "get_encoder_langtok", "(", "self", ",", "src_lang", ",", "tgt_lang", ",", "spec", "=", "None", ")", ":", "\n", "        ", "if", "spec", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "if", "spec", "and", "spec", ".", "startswith", "(", "\"src\"", ")", ":", "\n", "            ", "if", "src_lang", "is", "None", ":", "\n", "                ", "return", "None", "\n", "", "langtok", "=", "get_lang_tok", "(", "\n", "lang", "=", "src_lang", ",", "lang_tok_style", "=", "self", ".", "args", ".", "lang_tok_style", ",", "spec", "=", "spec", "\n", ")", "\n", "", "else", ":", "\n", "            ", "if", "tgt_lang", "is", "None", ":", "\n", "                ", "return", "None", "\n", "", "langtok", "=", "get_lang_tok", "(", "\n", "lang", "=", "tgt_lang", ",", "lang_tok_style", "=", "self", ".", "args", ".", "lang_tok_style", ",", "spec", "=", "spec", "\n", ")", "\n", "", "return", "self", ".", "get_langtok_index", "(", "\n", "langtok", ",", "self", ".", "dicts", "[", "src_lang", "if", "src_lang", "else", "tgt_lang", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_decoder_langtok": [[424, 431], ["fairseq.data.multilingual.multilingual_utils.get_lang_tok", "multilingual_data_manager.MultilingualDatasetManager.get_langtok_index"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_utils.get_lang_tok", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_langtok_index"], ["", "def", "get_decoder_langtok", "(", "self", ",", "tgt_lang", ",", "spec", "=", "None", ")", ":", "\n", "        ", "if", "spec", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "langtok", "=", "get_lang_tok", "(", "\n", "lang", "=", "tgt_lang", ",", "lang_tok_style", "=", "self", ".", "args", ".", "lang_tok_style", ",", "spec", "=", "spec", "\n", ")", "\n", "return", "self", ".", "get_langtok_index", "(", "langtok", ",", "self", ".", "dicts", "[", "tgt_lang", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_data": [[432, 436], ["fairseq.data.data_utils.load_indexed_dataset"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.data_utils.load_indexed_dataset"], ["", "@", "classmethod", "\n", "def", "load_data", "(", "cls", ",", "path", ",", "vdict", ",", "impl", ")", ":", "\n", "        ", "dataset", "=", "data_utils", ".", "load_indexed_dataset", "(", "path", ",", "vdict", ",", "impl", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.split_exists": [[437, 441], ["os.path.join", "fairseq.data.indexed_dataset.dataset_exists"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.dataset_exists"], ["", "@", "classmethod", "\n", "def", "split_exists", "(", "cls", ",", "split", ",", "src", ",", "tgt", ",", "lang", ",", "data_path", ",", "dataset_impl", ")", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"{}.{}-{}.{}\"", ".", "format", "(", "split", ",", "src", ",", "tgt", ",", "lang", ")", ")", "\n", "return", "indexed_dataset", ".", "dataset_exists", "(", "filename", ",", "impl", "=", "dataset_impl", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_lang_dataset": [[442, 528], ["itertools.count", "multilingual_data_manager.MultilingualDatasetManager.split_exists", "multilingual_data_manager.MultilingualDatasetManager.load_data", "src_datasets.append", "tgt_datasets.append", "logger.info", "len", "len", "len", "fairseq.data.ConcatDataset", "fairseq.data.ConcatDataset", "fairseq.data.PrependTokenDataset", "fairseq.data.PrependTokenDataset", "os.path.join", "fairseq.data.indexed_dataset.dataset_exists", "os.path.join", "multilingual_data_manager.MultilingualDatasetManager.split_exists", "fairseq.data.AppendTokenDataset", "multilingual_data_manager.MultilingualDatasetManager.load_data", "len", "hasattr", "hasattr", "src_dict.bos", "tgt_dict.bos", "fairseq.data.data_utils.load_indexed_dataset", "str", "os.path.join", "fairseq.data.TruncateDataset", "src_dict.eos", "len", "logger.error", "FileNotFoundError", "fairseq.data.StripTokenDataset", "src_dict.eos"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.split_exists", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_data", "home.repos.pwc.inspect_result.reneeye_const.data.indexed_dataset.dataset_exists", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.split_exists", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_data", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.bos", "home.repos.pwc.inspect_result.reneeye_const.data.data_utils.load_indexed_dataset", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "def", "load_lang_dataset", "(", "\n", "self", ",", "\n", "data_path", ",", "\n", "split", ",", "\n", "src", ",", "\n", "src_dict", ",", "\n", "tgt", ",", "\n", "tgt_dict", ",", "\n", "combine", ",", "\n", "dataset_impl", ",", "\n", "upsample_primary", ",", "\n", "max_source_positions", ",", "\n", "prepend_bos", "=", "False", ",", "\n", "load_alignments", "=", "False", ",", "\n", "truncate_source", "=", "False", ",", "\n", ")", ":", "\n", "\n", "        ", "src_datasets", "=", "[", "]", "\n", "tgt_datasets", "=", "[", "]", "\n", "\n", "for", "k", "in", "itertools", ".", "count", "(", ")", ":", "\n", "            ", "split_k", "=", "split", "+", "(", "str", "(", "k", ")", "if", "k", ">", "0", "else", "\"\"", ")", "\n", "\n", "# infer langcode", "\n", "if", "self", ".", "split_exists", "(", "split_k", ",", "src", ",", "tgt", ",", "src", ",", "data_path", ",", "dataset_impl", ")", ":", "\n", "                ", "prefix", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"{}.{}-{}.\"", ".", "format", "(", "split_k", ",", "src", ",", "tgt", ")", ")", "\n", "", "elif", "self", ".", "split_exists", "(", "split_k", ",", "tgt", ",", "src", ",", "src", ",", "data_path", ",", "dataset_impl", ")", ":", "\n", "                ", "prefix", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"{}.{}-{}.\"", ".", "format", "(", "split_k", ",", "tgt", ",", "src", ")", ")", "\n", "", "else", ":", "\n", "                ", "if", "k", ">", "0", ":", "\n", "                    ", "break", "\n", "", "else", ":", "\n", "                    ", "logger", ".", "error", "(", "\n", "f\"Dataset not found: {data_path}, {split_k}, {src}, {tgt}\"", "\n", ")", "\n", "raise", "FileNotFoundError", "(", "\n", "\"Dataset not found: {} ({})\"", ".", "format", "(", "split", ",", "data_path", ")", "\n", ")", "\n", "\n", "", "", "src_dataset", "=", "self", ".", "load_data", "(", "prefix", "+", "src", ",", "src_dict", ",", "dataset_impl", ")", "\n", "if", "truncate_source", ":", "\n", "                ", "src_dataset", "=", "AppendTokenDataset", "(", "\n", "TruncateDataset", "(", "\n", "StripTokenDataset", "(", "src_dataset", ",", "src_dict", ".", "eos", "(", ")", ")", ",", "\n", "max_source_positions", "-", "1", ",", "\n", ")", ",", "\n", "src_dict", ".", "eos", "(", ")", ",", "\n", ")", "\n", "", "src_datasets", ".", "append", "(", "src_dataset", ")", "\n", "tgt_datasets", ".", "append", "(", "self", ".", "load_data", "(", "prefix", "+", "tgt", ",", "tgt_dict", ",", "dataset_impl", ")", ")", "\n", "\n", "logger", ".", "info", "(", "\n", "\"{} {} {}-{} {} examples\"", ".", "format", "(", "\n", "data_path", ",", "split_k", ",", "src", ",", "tgt", ",", "len", "(", "src_datasets", "[", "-", "1", "]", ")", "\n", ")", "\n", ")", "\n", "\n", "if", "not", "combine", ":", "\n", "                ", "break", "\n", "\n", "", "", "assert", "len", "(", "src_datasets", ")", "==", "len", "(", "tgt_datasets", ")", "\n", "\n", "if", "len", "(", "src_datasets", ")", "==", "1", ":", "\n", "            ", "src_dataset", ",", "tgt_dataset", "=", "src_datasets", "[", "0", "]", ",", "tgt_datasets", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "sample_ratios", "=", "[", "1", "]", "*", "len", "(", "src_datasets", ")", "\n", "sample_ratios", "[", "0", "]", "=", "upsample_primary", "\n", "src_dataset", "=", "ConcatDataset", "(", "src_datasets", ",", "sample_ratios", ")", "\n", "tgt_dataset", "=", "ConcatDataset", "(", "tgt_datasets", ",", "sample_ratios", ")", "\n", "\n", "", "if", "prepend_bos", ":", "\n", "            ", "assert", "hasattr", "(", "src_dict", ",", "\"bos_index\"", ")", "and", "hasattr", "(", "tgt_dict", ",", "\"bos_index\"", ")", "\n", "src_dataset", "=", "PrependTokenDataset", "(", "src_dataset", ",", "src_dict", ".", "bos", "(", ")", ")", "\n", "tgt_dataset", "=", "PrependTokenDataset", "(", "tgt_dataset", ",", "tgt_dict", ".", "bos", "(", ")", ")", "\n", "\n", "", "align_dataset", "=", "None", "\n", "if", "load_alignments", ":", "\n", "            ", "align_path", "=", "os", ".", "path", ".", "join", "(", "\n", "data_path", ",", "\"{}.align.{}-{}\"", ".", "format", "(", "split", ",", "src", ",", "tgt", ")", "\n", ")", "\n", "if", "indexed_dataset", ".", "dataset_exists", "(", "align_path", ",", "impl", "=", "dataset_impl", ")", ":", "\n", "                ", "align_dataset", "=", "data_utils", ".", "load_indexed_dataset", "(", "\n", "align_path", ",", "None", ",", "dataset_impl", "\n", ")", "\n", "\n", "", "", "return", "src_dataset", ",", "tgt_dataset", ",", "align_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_langpair_dataset": [[529, 625], ["fairseq.data.LanguagePairDataset", "sorted", "langpairs_sharing_datasets.get", "langpairs_sharing_datasets.get", "langpairs_sharing_datasets.get", "multilingual_data_manager.MultilingualDatasetManager.load_lang_dataset", "src_dataset_transform_func", "tgt_dataset_transform_func", "logger.info", "getattr", "len", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_lang_dataset"], ["", "def", "load_langpair_dataset", "(", "\n", "self", ",", "\n", "data_path", ",", "\n", "split", ",", "\n", "src", ",", "\n", "src_dict", ",", "\n", "tgt", ",", "\n", "tgt_dict", ",", "\n", "combine", ",", "\n", "dataset_impl", ",", "\n", "upsample_primary", ",", "\n", "left_pad_source", ",", "\n", "left_pad_target", ",", "\n", "max_source_positions", ",", "\n", "max_target_positions", ",", "\n", "prepend_bos", "=", "False", ",", "\n", "load_alignments", "=", "False", ",", "\n", "truncate_source", "=", "False", ",", "\n", "src_dataset_transform_func", "=", "lambda", "dataset", ":", "dataset", ",", "\n", "tgt_dataset_transform_func", "=", "lambda", "dataset", ":", "dataset", ",", "\n", "src_lang_id", "=", "None", ",", "\n", "tgt_lang_id", "=", "None", ",", "\n", "langpairs_sharing_datasets", "=", "None", ",", "\n", ")", ":", "\n", "        ", "norm_direction", "=", "\"-\"", ".", "join", "(", "sorted", "(", "[", "src", ",", "tgt", "]", ")", ")", "\n", "if", "langpairs_sharing_datasets", "is", "not", "None", ":", "\n", "            ", "src_dataset", "=", "langpairs_sharing_datasets", ".", "get", "(", "\n", "(", "data_path", ",", "split", ",", "norm_direction", ",", "src", ")", ",", "\"NotInCache\"", "\n", ")", "\n", "tgt_dataset", "=", "langpairs_sharing_datasets", ".", "get", "(", "\n", "(", "data_path", ",", "split", ",", "norm_direction", ",", "tgt", ")", ",", "\"NotInCache\"", "\n", ")", "\n", "align_dataset", "=", "langpairs_sharing_datasets", ".", "get", "(", "\n", "(", "data_path", ",", "split", ",", "norm_direction", ",", "src", ",", "tgt", ")", ",", "\"NotInCache\"", "\n", ")", "\n", "\n", "# a hack: any one is not in cache, we need to reload them", "\n", "", "if", "(", "\n", "langpairs_sharing_datasets", "is", "None", "\n", "or", "src_dataset", "==", "\"NotInCache\"", "\n", "or", "tgt_dataset", "==", "\"NotInCache\"", "\n", "or", "align_dataset", "==", "\"NotInCache\"", "\n", "or", "split", "!=", "getattr", "(", "self", ".", "args", ",", "\"train_subset\"", ",", "None", ")", "\n", ")", ":", "\n", "# source and target datasets can be reused in reversed directions to save memory", "\n", "# reversed directions of valid and test data will not share source and target datasets", "\n", "            ", "src_dataset", ",", "tgt_dataset", ",", "align_dataset", "=", "self", ".", "load_lang_dataset", "(", "\n", "data_path", ",", "\n", "split", ",", "\n", "src", ",", "\n", "src_dict", ",", "\n", "tgt", ",", "\n", "tgt_dict", ",", "\n", "combine", ",", "\n", "dataset_impl", ",", "\n", "upsample_primary", ",", "\n", "max_source_positions", "=", "max_source_positions", ",", "\n", "prepend_bos", "=", "prepend_bos", ",", "\n", "load_alignments", "=", "load_alignments", ",", "\n", "truncate_source", "=", "truncate_source", ",", "\n", ")", "\n", "src_dataset", "=", "src_dataset_transform_func", "(", "src_dataset", ")", "\n", "tgt_dataset", "=", "tgt_dataset_transform_func", "(", "tgt_dataset", ")", "\n", "if", "langpairs_sharing_datasets", "is", "not", "None", ":", "\n", "                ", "langpairs_sharing_datasets", "[", "\n", "(", "data_path", ",", "split", ",", "norm_direction", ",", "src", ")", "\n", "]", "=", "src_dataset", "\n", "langpairs_sharing_datasets", "[", "\n", "(", "data_path", ",", "split", ",", "norm_direction", ",", "tgt", ")", "\n", "]", "=", "tgt_dataset", "\n", "langpairs_sharing_datasets", "[", "\n", "(", "data_path", ",", "split", ",", "norm_direction", ",", "src", ",", "tgt", ")", "\n", "]", "=", "align_dataset", "\n", "if", "align_dataset", "is", "None", ":", "\n", "# no align data so flag the reverse direction as well in sharing", "\n", "                    ", "langpairs_sharing_datasets", "[", "\n", "(", "data_path", ",", "split", ",", "norm_direction", ",", "tgt", ",", "src", ")", "\n", "]", "=", "align_dataset", "\n", "", "", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"Reusing source and target datasets of [{split}] {tgt}-{src} for reversed direction: \"", "\n", "f\"[{split}] {src}-{tgt}: src length={len(src_dataset)}; tgt length={len(tgt_dataset)}\"", "\n", ")", "\n", "\n", "", "return", "LanguagePairDataset", "(", "\n", "src_dataset", ",", "\n", "src_dataset", ".", "sizes", ",", "\n", "src_dict", ",", "\n", "tgt_dataset", ",", "\n", "tgt_dataset", ".", "sizes", "if", "tgt_dataset", "is", "not", "None", "else", "None", ",", "\n", "tgt_dict", ",", "\n", "left_pad_source", "=", "left_pad_source", ",", "\n", "left_pad_target", "=", "left_pad_target", ",", "\n", "align_dataset", "=", "align_dataset", ",", "\n", "src_lang_id", "=", "src_lang_id", ",", "\n", "tgt_lang_id", "=", "tgt_lang_id", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.src_dataset_tranform_func": [[627, 638], ["multilingual_data_manager.MultilingualDatasetManager.get_encoder_langtok", "fairseq.data.PrependTokenDataset"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_encoder_langtok"], ["", "def", "src_dataset_tranform_func", "(", "self", ",", "src_lang", ",", "tgt_lang", ",", "dataset", ",", "spec", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "lang_tok_replacing_bos_eos", ":", "\n", "# it is handled by self.alter_dataset_langtok", "\n", "# TODO: Unifiy with alter_dataset_langtok", "\n", "            ", "return", "dataset", "\n", "", "if", "spec", "is", "None", ":", "\n", "            ", "return", "dataset", "\n", "", "tok", "=", "self", ".", "get_encoder_langtok", "(", "src_lang", ",", "tgt_lang", ",", "spec", ")", "\n", "if", "tok", ":", "\n", "            ", "return", "PrependTokenDataset", "(", "dataset", ",", "tok", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.tgt_dataset_tranform_func": [[639, 656], ["multilingual_data_manager.MultilingualDatasetManager.get_decoder_langtok", "fairseq.data.PrependTokenDataset"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_decoder_langtok"], ["", "def", "tgt_dataset_tranform_func", "(", "self", ",", "source_lang", ",", "target_lang", ",", "dataset", ",", "spec", "=", "None", ")", ":", "\n", "        ", "if", "dataset", "is", "None", ":", "\n", "# note that target dataset can be None during inference time", "\n", "            ", "return", "None", "\n", "", "if", "self", ".", "args", ".", "lang_tok_replacing_bos_eos", ":", "\n", "# TODO: Unifiy with alter_dataset_langtok", "\n", "# It is handled by self.alter_dataset_langtok.", "\n", "# The complication in self.alter_dataset_langtok", "\n", "# makes a unified framework difficult.", "\n", "            ", "return", "dataset", "\n", "# if not self.args.decoder_langtok:", "\n", "", "if", "not", "spec", ":", "\n", "            ", "return", "dataset", "\n", "", "tok", "=", "self", ".", "get_decoder_langtok", "(", "target_lang", ",", "spec", ")", "\n", "if", "tok", ":", "\n", "            ", "return", "PrependTokenDataset", "(", "dataset", ",", "tok", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.alter_dataset_langtok": [[657, 692], ["fairseq.data.TransformEosLangPairDataset", "multilingual_data_manager.MultilingualDatasetManager.get_encoder_langtok", "multilingual_data_manager.MultilingualDatasetManager.get_decoder_langtok"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_encoder_langtok", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_decoder_langtok"], ["", "def", "alter_dataset_langtok", "(", "\n", "self", ",", "\n", "lang_pair_dataset", ",", "\n", "src_eos", "=", "None", ",", "\n", "src_lang", "=", "None", ",", "\n", "tgt_eos", "=", "None", ",", "\n", "tgt_lang", "=", "None", ",", "\n", "src_langtok_spec", "=", "None", ",", "\n", "tgt_langtok_spec", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "src_langtok_spec", "is", "None", "and", "tgt_langtok_spec", "is", "None", ":", "\n", "            ", "return", "lang_pair_dataset", "\n", "\n", "", "new_src_eos", "=", "None", "\n", "if", "(", "\n", "src_langtok_spec", "is", "not", "None", "\n", "and", "src_eos", "is", "not", "None", "\n", "and", "(", "src_lang", "is", "not", "None", "or", "tgt_lang", "is", "not", "None", ")", "\n", ")", ":", "\n", "            ", "new_src_eos", "=", "self", ".", "get_encoder_langtok", "(", "src_lang", ",", "tgt_lang", ",", "src_langtok_spec", ")", "\n", "", "else", ":", "\n", "            ", "src_eos", "=", "None", "\n", "\n", "", "new_tgt_bos", "=", "None", "\n", "if", "tgt_langtok_spec", "and", "tgt_eos", "is", "not", "None", "and", "tgt_lang", "is", "not", "None", ":", "\n", "            ", "new_tgt_bos", "=", "self", ".", "get_decoder_langtok", "(", "tgt_lang", ",", "tgt_langtok_spec", ")", "\n", "", "else", ":", "\n", "            ", "tgt_eos", "=", "None", "\n", "\n", "", "return", "TransformEosLangPairDataset", "(", "\n", "lang_pair_dataset", ",", "\n", "src_eos", "=", "src_eos", ",", "\n", "new_src_eos", "=", "new_src_eos", ",", "\n", "tgt_bos", "=", "tgt_eos", ",", "\n", "new_tgt_bos", "=", "new_tgt_bos", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_a_dataset": [[694, 773], ["multilingual_data_manager.MultilingualDatasetManager.get_encoder_langtok", "multilingual_data_manager.MultilingualDatasetManager.get_decoder_langtok", "logger.info", "multilingual_data_manager.MultilingualDatasetManager.load_langpair_dataset", "multilingual_data_manager.MultilingualDatasetManager.alter_dataset_langtok", "src_dataset_transform_func", "tgt_dataset_transform_func", "multilingual_data_manager._lang_id", "multilingual_data_manager._lang_id", "multilingual_data_manager.MultilingualDatasetManager.dicts[].eos", "multilingual_data_manager.MultilingualDatasetManager.dicts[].eos"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_encoder_langtok", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_decoder_langtok", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_langpair_dataset", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.alter_dataset_langtok", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager._lang_id", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager._lang_id", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.eos"], ["", "def", "load_a_dataset", "(", "\n", "self", ",", "\n", "split", ",", "\n", "data_path", ",", "\n", "src", ",", "\n", "src_dict", ",", "\n", "tgt", ",", "\n", "tgt_dict", ",", "\n", "combine", ",", "\n", "prepend_bos", "=", "False", ",", "\n", "langpairs_sharing_datasets", "=", "None", ",", "\n", "data_category", "=", "None", ",", "\n", "**", "extra_kwargs", ",", "\n", ")", ":", "\n", "        ", "dataset_impl", "=", "self", ".", "args", ".", "dataset_impl", "\n", "upsample_primary", "=", "self", ".", "args", ".", "upsample_primary", "\n", "left_pad_source", "=", "self", ".", "args", ".", "left_pad_source", "\n", "left_pad_target", "=", "self", ".", "args", ".", "left_pad_target", "\n", "max_source_positions", "=", "self", ".", "args", ".", "max_source_positions", "\n", "max_target_positions", "=", "self", ".", "args", ".", "max_target_positions", "\n", "load_alignments", "=", "self", ".", "args", ".", "load_alignments", "\n", "truncate_source", "=", "self", ".", "args", ".", "truncate_source", "\n", "src_dataset_transform_func", "=", "self", ".", "src_dataset_tranform_func", "\n", "tgt_dataset_transform_func", "=", "self", ".", "tgt_dataset_tranform_func", "\n", "enable_lang_ids", "=", "self", ".", "args", ".", "enable_lang_ids", "\n", "lang_dictionary", "=", "self", ".", "lang_dict", "\n", "src_langtok_spec", ",", "tgt_langtok_spec", "=", "extra_kwargs", "[", "\"langtok_spec\"", "]", "\n", "\n", "src_langtok", "=", "self", ".", "get_encoder_langtok", "(", "src", ",", "tgt", ",", "src_langtok_spec", ")", "\n", "tgt_langtok", "=", "self", ".", "get_decoder_langtok", "(", "tgt", ",", "tgt_langtok_spec", ")", "\n", "logger", ".", "info", "(", "\n", "f\"{data_category}:{src}-{tgt} src_langtok: {src_langtok}; tgt_langtok: {tgt_langtok}\"", "\n", ")", "\n", "\n", "langpair_ds", "=", "self", ".", "load_langpair_dataset", "(", "\n", "data_path", ",", "\n", "split", ",", "\n", "src", ",", "\n", "src_dict", ",", "\n", "tgt", ",", "\n", "tgt_dict", ",", "\n", "combine", ",", "\n", "dataset_impl", ",", "\n", "upsample_primary", ",", "\n", "left_pad_source", ",", "\n", "left_pad_target", ",", "\n", "max_source_positions", ",", "\n", "max_target_positions", ",", "\n", "prepend_bos", ",", "\n", "load_alignments", ",", "\n", "truncate_source", ",", "\n", "src_dataset_transform_func", "=", "lambda", "dataset", ":", "src_dataset_transform_func", "(", "\n", "src", ",", "tgt", ",", "dataset", ",", "src_langtok_spec", "\n", ")", ",", "\n", "tgt_dataset_transform_func", "=", "lambda", "dataset", ":", "tgt_dataset_transform_func", "(", "\n", "src", ",", "tgt", ",", "dataset", ",", "tgt_langtok_spec", "\n", ")", ",", "\n", "src_lang_id", "=", "_lang_id", "(", "lang_dictionary", ",", "src", ")", "\n", "if", "enable_lang_ids", "and", "lang_dictionary", "is", "not", "None", "\n", "else", "None", ",", "\n", "tgt_lang_id", "=", "_lang_id", "(", "lang_dictionary", ",", "tgt", ")", "\n", "if", "enable_lang_ids", "and", "lang_dictionary", "is", "not", "None", "\n", "else", "None", ",", "\n", "langpairs_sharing_datasets", "=", "langpairs_sharing_datasets", ",", "\n", ")", "\n", "# TODO: handle modified lang toks for mined data and dae data", "\n", "if", "self", ".", "args", ".", "lang_tok_replacing_bos_eos", ":", "\n", "            ", "ds", "=", "self", ".", "alter_dataset_langtok", "(", "\n", "langpair_ds", ",", "\n", "src_eos", "=", "self", ".", "dicts", "[", "src", "if", "src", "else", "tgt", "]", ".", "eos", "(", ")", ",", "\n", "src_lang", "=", "src", ",", "\n", "tgt_eos", "=", "self", ".", "dicts", "[", "tgt", "]", ".", "eos", "(", ")", ",", "\n", "tgt_lang", "=", "tgt", ",", "\n", "src_langtok_spec", "=", "src_langtok_spec", ",", "\n", "tgt_langtok_spec", "=", "tgt_langtok_spec", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "ds", "=", "langpair_ds", "\n", "", "return", "ds", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_split_langpair_datasets": [[774, 787], ["multilingual_data_manager.MultilingualDatasetManager.load_a_dataset", "datasets.append"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_a_dataset"], ["", "def", "load_split_langpair_datasets", "(", "self", ",", "split", ",", "data_param_list", ")", ":", "\n", "        ", "datasets", "=", "[", "]", "\n", "langpairs_sharing_datasets", "=", "(", "\n", "{", "}", "if", "self", ".", "args", ".", "enable_reservsed_directions_shared_datasets", "else", "None", "\n", ")", "\n", "for", "param", "in", "data_param_list", ":", "\n", "            ", "ds", "=", "self", ".", "load_a_dataset", "(", "\n", "split", "=", "split", ",", "\n", "langpairs_sharing_datasets", "=", "langpairs_sharing_datasets", ",", "\n", "**", "param", ",", "\n", ")", "\n", "datasets", ".", "append", "(", "ds", ")", "\n", "", "return", "datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_data_paths_and_lang_pairs": [[788, 802], ["getattr", "datapaths.update", "lang_pairs.update", "v.split", "multilingual_data_manager.MultilingualDatasetManager.args.extra_lang_pairs.items"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.update"], ["", "def", "get_data_paths_and_lang_pairs", "(", "self", ",", "split", ")", ":", "\n", "        ", "datapaths", "=", "{", "\"main\"", ":", "self", ".", "args", ".", "data", "}", "\n", "lang_pairs", "=", "{", "\"main\"", ":", "self", ".", "lang_pairs", "}", "\n", "if", "split", "==", "getattr", "(", "self", ".", "args", ",", "\"train_subset\"", ",", "None", ")", ":", "\n", "# only training data can have extra data and extra language pairs", "\n", "            ", "if", "self", ".", "args", ".", "extra_data", ":", "\n", "                ", "extra_datapaths", "=", "self", ".", "args", ".", "extra_data", "\n", "datapaths", ".", "update", "(", "extra_datapaths", ")", "\n", "", "if", "self", ".", "args", ".", "extra_lang_pairs", ":", "\n", "                ", "extra_lang_pairs", "=", "{", "\n", "k", ":", "v", ".", "split", "(", "\",\"", ")", "for", "k", ",", "v", "in", "self", ".", "args", ".", "extra_lang_pairs", ".", "items", "(", ")", "\n", "}", "\n", "lang_pairs", ".", "update", "(", "extra_lang_pairs", ")", "\n", "", "", "return", "datapaths", ",", "lang_pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_dataset_key": [[803, 806], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "get_dataset_key", "(", "cls", ",", "data_category", ",", "src", ",", "tgt", ")", ":", "\n", "        ", "return", "f\"{data_category}:{src}-{tgt}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager._get_shard_num_dict": [[807, 821], ["collections.defaultdict", "fairseq.file_io.PathManager.ls", "set", "f.startswith", "f.endswith", "set.add", "f.split"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.ls", "home.repos.pwc.inspect_result.reneeye_const.scoring.bleu.Scorer.add"], ["", "@", "classmethod", "\n", "def", "_get_shard_num_dict", "(", "cls", ",", "split", ",", "paths", ")", ":", "\n", "        ", "shards", "=", "defaultdict", "(", "int", ")", "\n", "for", "path", "in", "paths", ":", "\n", "            ", "files", "=", "PathManager", ".", "ls", "(", "path", ")", "\n", "directions", "=", "set", "(", ")", "\n", "for", "f", "in", "files", ":", "\n", "                ", "if", "f", ".", "startswith", "(", "split", ")", "and", "f", ".", "endswith", "(", "\".idx\"", ")", ":", "\n", "# idx files of the form \"{split}.{src}-{tgt}.{lang}.idx\"", "\n", "                    ", "direction", "=", "f", ".", "split", "(", "\".\"", ")", "[", "-", "3", "]", "\n", "directions", ".", "add", "(", "direction", ")", "\n", "", "", "for", "direction", "in", "directions", ":", "\n", "                ", "shards", "[", "direction", "]", "+=", "1", "\n", "", "", "return", "shards", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_split_num_data_shards": [[822, 855], ["multilingual_data_manager.MultilingualDatasetManager.get_data_paths_and_lang_pairs", "data_paths.items", "logger.info", "fairseq.utils.split_paths", "multilingual_data_manager.MultilingualDatasetManager._get_shard_num_dict", "lang_pair.split", "multilingual_data_manager.MultilingualDatasetManager.get_dataset_key", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_data_paths_and_lang_pairs", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager._get_shard_num_dict", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_dataset_key"], ["", "def", "get_split_num_data_shards", "(", "self", ",", "split", ")", ":", "\n", "        ", "if", "split", "in", "self", ".", "_num_shards_dict", ":", "\n", "            ", "return", "self", ".", "_num_shards_dict", "[", "split", "]", "\n", "", "num_shards_dict", "=", "{", "}", "\n", "data_paths", ",", "lang_pairs", "=", "self", ".", "get_data_paths_and_lang_pairs", "(", "split", ")", "\n", "\n", "for", "data_category", ",", "paths", "in", "data_paths", ".", "items", "(", ")", ":", "\n", "            ", "if", "data_category", "not", "in", "lang_pairs", ":", "\n", "                ", "continue", "\n", "", "paths", "=", "utils", ".", "split_paths", "(", "paths", ")", "\n", "shards_dict", "=", "self", ".", "_get_shard_num_dict", "(", "split", ",", "paths", ")", "\n", "lang_dirs", "=", "[", "\n", "lang_pair", ".", "split", "(", "\"-\"", ")", "for", "lang_pair", "in", "lang_pairs", "[", "data_category", "]", "\n", "]", "\n", "lang_dirs", "=", "[", "x", "if", "len", "(", "x", ")", ">", "1", "else", "(", "x", "[", "0", "]", ",", "x", "[", "0", "]", ")", "for", "x", "in", "lang_dirs", "]", "\n", "for", "src", ",", "tgt", "in", "lang_dirs", ":", "\n", "                ", "key", "=", "self", ".", "get_dataset_key", "(", "data_category", ",", "src", ",", "tgt", ")", "\n", "if", "\"mono_\"", "in", "data_category", ":", "\n", "# monolingual data requires tgt only", "\n", "                    ", "assert", "src", "is", "None", "or", "src", "==", "tgt", ",", "(", "\n", "f\"error: src={src}, \"", "\n", "\"tgt={tgt} for data_category={data_category}\"", "\n", ")", "\n", "num_shards_dict", "[", "key", "]", "=", "shards_dict", "[", "tgt", "]", "\n", "", "else", ":", "\n", "                    ", "if", "f\"{src}-{tgt}\"", "in", "shards_dict", ":", "\n", "                        ", "num_shards_dict", "[", "key", "]", "=", "shards_dict", "[", "f\"{src}-{tgt}\"", "]", "\n", "", "elif", "f\"{tgt}-{src}\"", "in", "shards_dict", ":", "\n", "# follow the fairseq tradition to use reversed direction data if it is not available", "\n", "                        ", "num_shards_dict", "[", "key", "]", "=", "shards_dict", "[", "f\"{tgt}-{src}\"", "]", "\n", "", "", "", "", "self", ".", "_num_shards_dict", "[", "split", "]", "=", "num_shards_dict", "\n", "logger", ".", "info", "(", "f\"[{split}] num of shards: {num_shards_dict}\"", ")", "\n", "return", "num_shards_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_shard_id": [[856, 861], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "get_shard_id", "(", "cls", ",", "num_shards", ",", "epoch", ",", "shard_epoch", "=", "None", ")", ":", "\n", "        ", "shard", "=", "epoch", "if", "shard_epoch", "is", "None", "else", "shard_epoch", "\n", "shard", "=", "(", "shard", "-", "1", ")", "%", "num_shards", "\n", "return", "shard", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_split_data_path": [[862, 865], ["multilingual_data_manager.MultilingualDatasetManager.get_shard_id"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_shard_id"], ["", "def", "get_split_data_path", "(", "self", ",", "paths", ",", "epoch", ",", "shard_epoch", ",", "num_shards", ")", ":", "\n", "        ", "path", "=", "paths", "[", "self", ".", "get_shard_id", "(", "num_shards", ",", "epoch", ",", "shard_epoch", ")", "]", "\n", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_split_data_param_list": [[866, 919], ["multilingual_data_manager.MultilingualDatasetManager.get_data_paths_and_lang_pairs", "logger.info", "multilingual_data_manager.MultilingualDatasetManager.get_split_num_data_shards", "data_paths.items", "fairseq.utils.split_paths", "len", "len", "getattr", "lang_pair.split", "multilingual_data_manager.MultilingualDatasetManager.get_dataset_key", "multilingual_data_manager.MultilingualDatasetManager.get_split_data_path", "param_list.append", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_data_paths_and_lang_pairs", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_split_num_data_shards", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.split_paths", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_dataset_key", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_split_data_path"], ["", "def", "get_split_data_param_list", "(", "self", ",", "split", ",", "epoch", ",", "shard_epoch", "=", "None", ")", ":", "\n", "# TODO: to extend with extra datasets and keys and loop over different shard data paths", "\n", "        ", "param_list", "=", "[", "]", "\n", "data_paths", ",", "lang_pairs", "=", "self", ".", "get_data_paths_and_lang_pairs", "(", "split", ")", "\n", "logger", ".", "info", "(", "f\"langtoks settings: {self.args.langtoks}\"", ")", "\n", "split_num_shards_dict", "=", "self", ".", "get_split_num_data_shards", "(", "split", ")", "\n", "for", "data_category", ",", "paths", "in", "data_paths", ".", "items", "(", ")", ":", "\n", "            ", "if", "data_category", "not", "in", "lang_pairs", ":", "\n", "                ", "continue", "\n", "", "paths", "=", "utils", ".", "split_paths", "(", "paths", ")", "\n", "assert", "len", "(", "paths", ")", ">", "0", "\n", "if", "len", "(", "paths", ")", ">", "1", ":", "\n", "                ", "self", ".", "_has_sharded_data", "=", "True", "\n", "", "if", "split", "!=", "getattr", "(", "self", ".", "args", ",", "\"train_subset\"", ",", "None", ")", ":", "\n", "# if not training data set, use the first shard for valid and test", "\n", "                ", "paths", "=", "paths", "[", ":", "1", "]", "\n", "\n", "", "if", "data_category", "in", "self", ".", "args", ".", "langtoks", ":", "\n", "                ", "lang_tok_spec", "=", "self", ".", "args", ".", "langtoks", "[", "data_category", "]", "\n", "", "else", ":", "\n", "# default to None", "\n", "                ", "lang_tok_spec", "=", "(", "None", ",", "None", ")", "\n", "\n", "# infer langcode", "\n", "", "lang_dirs", "=", "[", "\n", "lang_pair", ".", "split", "(", "\"-\"", ")", "for", "lang_pair", "in", "lang_pairs", "[", "data_category", "]", "\n", "]", "\n", "lang_dirs", "=", "[", "x", "if", "len", "(", "x", ")", ">", "1", "else", "(", "x", "[", "0", "]", ",", "x", "[", "0", "]", ")", "for", "x", "in", "lang_dirs", "]", "\n", "for", "src", ",", "tgt", "in", "lang_dirs", ":", "\n", "                ", "assert", "src", "is", "not", "None", "or", "data_category", "==", "\"mono_dae\"", ",", "(", "\n", "f\"error: src={src}, \"", "\"tgt={tgt} for data_category={data_category}\"", "\n", ")", "\n", "# logger.info(f\"preparing param for {data_category}: {src} - {tgt}\")", "\n", "key", "=", "self", ".", "get_dataset_key", "(", "data_category", ",", "src", ",", "tgt", ")", "\n", "data_path", "=", "self", ".", "get_split_data_path", "(", "\n", "paths", ",", "epoch", ",", "shard_epoch", ",", "split_num_shards_dict", "[", "key", "]", "\n", ")", "\n", "param_list", ".", "append", "(", "\n", "{", "\n", "\"key\"", ":", "key", ",", "\n", "\"data_path\"", ":", "data_path", ",", "\n", "\"split\"", ":", "split", ",", "\n", "\"src\"", ":", "src", ",", "\n", "\"src_dict\"", ":", "self", ".", "dicts", "[", "src", "]", "\n", "if", "src", "and", "data_category", "!=", "\"mono_dae\"", "\n", "else", "None", ",", "\n", "\"tgt\"", ":", "tgt", ",", "\n", "\"tgt_dict\"", ":", "self", ".", "dicts", "[", "tgt", "]", ",", "\n", "\"data_category\"", ":", "data_category", ",", "\n", "\"langtok_spec\"", ":", "lang_tok_spec", ",", "\n", "}", "\n", ")", "\n", "", "", "return", "param_list", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_train_dataset_sizes": [[920, 949], ["zip", "logger.info", "multilingual_data_manager.MultilingualDatasetManager.get_shard_id", "max", "data_sizes.append", "multilingual_data_manager.MultilingualDatasetManager.get_split_num_data_shards", "len", "my_data_sizes.values", "sum", "my_data_sizes.get", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_shard_id", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_split_num_data_shards"], ["", "def", "get_train_dataset_sizes", "(", "\n", "self", ",", "data_param_list", ",", "datasets", ",", "epoch", ",", "shard_epoch", "=", "None", "\n", ")", ":", "\n", "        ", "num_shards", "=", "[", "\n", "self", ".", "get_split_num_data_shards", "(", "param", "[", "\"split\"", "]", ")", "[", "param", "[", "\"key\"", "]", "]", "\n", "for", "param", "in", "data_param_list", "\n", "]", "\n", "data_sizes", "=", "[", "]", "\n", "for", "(", "key", ",", "d", ")", ",", "num_shard", "in", "zip", "(", "datasets", ",", "num_shards", ")", ":", "\n", "            ", "my_data_sizes", "=", "self", ".", "_training_data_sizes", "[", "key", "]", "\n", "shard_ind", "=", "self", ".", "get_shard_id", "(", "num_shard", ",", "epoch", ",", "shard_epoch", ")", "\n", "if", "shard_ind", "not", "in", "my_data_sizes", ":", "\n", "                ", "my_data_sizes", "[", "shard_ind", "]", "=", "len", "(", "d", ")", "\n", "", "known_size", "=", "max", "(", "my_data_sizes", ".", "values", "(", ")", ")", "\n", "data_sizes", ".", "append", "(", "\n", "# If we don't know the data size of the shard yet,", "\n", "# use the the max known data size to approximate.", "\n", "# Note that we preprocess shards by a designated shard size", "\n", "# and put any remaining data at the end into the last shard so", "\n", "# the max shard size approximation is almost correct before loading", "\n", "# the last shard; after loading the last shard, it will have the", "\n", "# exact data sizes of the whole data size.", "\n", "(", "key", ",", "sum", "(", "my_data_sizes", ".", "get", "(", "i", ",", "known_size", ")", "for", "i", "in", "range", "(", "num_shard", ")", ")", ")", "\n", ")", "\n", "", "logger", ".", "info", "(", "\n", "f\"estimated total data sizes of all shards used in sampling ratios: {data_sizes}. \"", "\n", "\"Note that if the data a shard has not been loaded yet, use the max known data size to approximate\"", "\n", ")", "\n", "return", "[", "s", "for", "_", ",", "s", "in", "data_sizes", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_train_sampling_ratios": [[950, 959], ["multilingual_data_manager.MultilingualDatasetManager.get_train_dataset_sizes", "multilingual_data_manager.MultilingualDatasetManager.sampling_method.sampling_method_selector", "multilingual_data_manager.MultilingualDatasetManager."], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_train_dataset_sizes", "home.repos.pwc.inspect_result.reneeye_const.multilingual.sampling_method.SamplingMethod.sampling_method_selector"], ["", "def", "get_train_sampling_ratios", "(", "\n", "self", ",", "data_param_list", ",", "datasets", ",", "epoch", "=", "1", ",", "shard_epoch", "=", "None", "\n", ")", ":", "\n", "        ", "data_sizes", "=", "self", ".", "get_train_dataset_sizes", "(", "\n", "data_param_list", ",", "datasets", ",", "epoch", ",", "shard_epoch", "\n", ")", "\n", "sampling_func", "=", "self", ".", "sampling_method", ".", "sampling_method_selector", "(", ")", "\n", "sample_ratios", "=", "sampling_func", "(", "data_sizes", ")", "if", "sampling_func", "is", "not", "None", "else", "None", "\n", "return", "sample_ratios", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_sampling_ratios": [[960, 983], ["multilingual_data_manager.load_sampling_weights", "logger.info", "logger.info", "multilingual_data_manager.MultilingualDatasetManager.get_train_sampling_ratios", "len", "len", "list", "zip", "map"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.load_sampling_weights", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_train_sampling_ratios"], ["", "def", "get_sampling_ratios", "(", "self", ",", "data_param_list", ",", "datasets", ",", "epoch", ",", "shard_epoch", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "sampling_weights_from_file", ":", "\n", "            ", "weights", "=", "load_sampling_weights", "(", "self", ".", "args", ".", "sampling_weights_from_file", ")", "\n", "sample_ratios", "=", "[", "weights", "[", "k", "]", "for", "k", ",", "_", "in", "datasets", "]", "\n", "logger", ".", "info", "(", "\n", "\"| ignoring --sampling-weights when loadding sampling weights \"", "\n", "f\"from file {self.args.sampling_weights_from_file}\"", "\n", ")", "\n", "", "elif", "self", ".", "args", ".", "sampling_weights", ":", "\n", "            ", "sample_ratios", "=", "[", "self", ".", "args", ".", "sampling_weights", "[", "k", "]", "for", "k", ",", "_", "in", "datasets", "]", "\n", "", "else", ":", "\n", "            ", "sample_ratios", "=", "self", ".", "get_train_sampling_ratios", "(", "\n", "data_param_list", ",", "datasets", ",", "epoch", ",", "shard_epoch", "\n", ")", "\n", "\n", "", "if", "sample_ratios", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"| Upsample ratios: {}\"", ".", "format", "(", "\n", "list", "(", "zip", "(", "map", "(", "lambda", "x", ":", "x", "[", "\"key\"", "]", ",", "data_param_list", ")", ",", "sample_ratios", ")", ")", "\n", ")", "\n", ")", "\n", "assert", "len", "(", "sample_ratios", ")", "==", "len", "(", "datasets", ")", "\n", "", "return", "sample_ratios", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_split_datasets": [[984, 1005], ["multilingual_data_manager.MultilingualDatasetManager.get_split_data_param_list", "multilingual_data_manager.MultilingualDatasetManager.load_a_dataset"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_split_data_param_list", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_a_dataset"], ["", "def", "load_split_datasets", "(", "\n", "self", ",", "split", ",", "training", ",", "epoch", "=", "1", ",", "combine", "=", "False", ",", "shard_epoch", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "data_param_list", "=", "self", ".", "get_split_data_param_list", "(", "\n", "split", ",", "epoch", ",", "shard_epoch", "=", "shard_epoch", "\n", ")", "\n", "langpairs_sharing_datasets", "=", "(", "\n", "{", "}", "if", "self", ".", "args", ".", "enable_reservsed_directions_shared_datasets", "else", "None", "\n", ")", "\n", "datasets", "=", "[", "\n", "(", "\n", "param", "[", "\"key\"", "]", ",", "\n", "self", ".", "load_a_dataset", "(", "\n", "combine", "=", "combine", ",", "\n", "langpairs_sharing_datasets", "=", "langpairs_sharing_datasets", ",", "\n", "**", "param", ",", "\n", ")", ",", "\n", ")", "\n", "for", "param", "in", "data_param_list", "\n", "]", "\n", "return", "datasets", ",", "data_param_list", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_into_concat_dataset": [[1006, 1018], ["fairseq.data.ConcatDataset", "fairseq.data.SampledMultiDataset", "collections.OrderedDict"], "methods", ["None"], ["", "def", "load_into_concat_dataset", "(", "self", ",", "split", ",", "datasets", ",", "data_param_list", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "lang_tok_replacing_bos_eos", ":", "\n", "# TODO: to investigate why TransformEosLangPairDataset doesn't work with ConcatDataset", "\n", "            ", "return", "SampledMultiDataset", "(", "\n", "OrderedDict", "(", "datasets", ")", ",", "\n", "sampling_ratios", "=", "None", ",", "\n", "eval_key", "=", "None", ",", "\n", "collate_format", "=", "CollateFormat", ".", "single", ",", "\n", "virtual_size", "=", "None", ",", "\n", "split", "=", "split", ",", "\n", ")", "\n", "", "return", "ConcatDataset", "(", "[", "d", "for", "_", ",", "d", "in", "datasets", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_sampled_multi_epoch_dataset": [[1019, 1043], ["multilingual_data_manager.MultilingualDatasetManager.load_split_datasets", "multilingual_data_manager.MultilingualDatasetManager.get_sampling_ratios", "fairseq.data.SampledMultiEpochDataset", "multilingual_data_manager.MultilingualDatasetManager.load_into_concat_dataset", "getattr", "collections.OrderedDict", "multilingual_data_manager.MultilingualDatasetManager._shared_collater"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_split_datasets", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_sampling_ratios", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_into_concat_dataset", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager._shared_collater"], ["", "def", "load_sampled_multi_epoch_dataset", "(", "\n", "self", ",", "split", ",", "training", ",", "epoch", "=", "0", ",", "combine", "=", "False", ",", "shard_epoch", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "datasets", ",", "data_param_list", "=", "self", ".", "load_split_datasets", "(", "\n", "split", ",", "training", ",", "epoch", ",", "combine", ",", "shard_epoch", "=", "shard_epoch", ",", "**", "kwargs", "\n", ")", "\n", "if", "training", "and", "split", "==", "getattr", "(", "self", ".", "args", ",", "\"train_subset\"", ",", "None", ")", ":", "\n", "            ", "sample_ratios", "=", "self", ".", "get_sampling_ratios", "(", "data_param_list", ",", "datasets", ",", "epoch", ")", "\n", "return", "SampledMultiEpochDataset", "(", "\n", "OrderedDict", "(", "datasets", ")", ",", "\n", "epoch", "=", "epoch", ",", "\n", "shard_epoch", "=", "shard_epoch", ",", "\n", "# valid and test datasets will be degenerate to concating datasets:", "\n", "sampling_ratios", "=", "sample_ratios", ",", "\n", "eval_key", "=", "None", ",", "\n", "collate_format", "=", "CollateFormat", ".", "single", ",", "\n", "virtual_size", "=", "self", ".", "args", ".", "virtual_data_size", ",", "\n", "split", "=", "split", ",", "\n", "virtual_epoch_size", "=", "self", ".", "args", ".", "virtual_epoch_size", ",", "\n", "# if not using lang_tok altering, simplified to use the same collater", "\n", "shared_collater", "=", "self", ".", "_shared_collater", "(", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "load_into_concat_dataset", "(", "split", ",", "datasets", ",", "data_param_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_sampled_multi_dataset": [[1044, 1066], ["multilingual_data_manager.MultilingualDatasetManager.load_split_datasets", "multilingual_data_manager.MultilingualDatasetManager.get_sampling_ratios", "fairseq.data.SampledMultiDataset", "multilingual_data_manager.MultilingualDatasetManager.load_into_concat_dataset", "getattr", "collections.OrderedDict", "multilingual_data_manager.MultilingualDatasetManager._shared_collater"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_split_datasets", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.get_sampling_ratios", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_into_concat_dataset", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager._shared_collater"], ["", "", "def", "load_sampled_multi_dataset", "(", "\n", "self", ",", "split", ",", "training", ",", "epoch", "=", "0", ",", "combine", "=", "False", ",", "shard_epoch", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "datasets", ",", "data_param_list", "=", "self", ".", "load_split_datasets", "(", "\n", "split", ",", "training", ",", "epoch", ",", "combine", ",", "shard_epoch", "=", "shard_epoch", ",", "**", "kwargs", "\n", ")", "\n", "if", "training", "and", "split", "==", "getattr", "(", "self", ".", "args", ",", "\"train_subset\"", ",", "None", ")", ":", "\n", "            ", "sample_ratios", "=", "self", ".", "get_sampling_ratios", "(", "data_param_list", ",", "datasets", ",", "epoch", ")", "\n", "return", "SampledMultiDataset", "(", "\n", "OrderedDict", "(", "datasets", ")", ",", "\n", "epoch", "=", "epoch", ",", "\n", "# valid and test datasets will be degerate to concating datasets:", "\n", "sampling_ratios", "=", "sample_ratios", ",", "\n", "eval_key", "=", "None", ",", "\n", "collate_format", "=", "CollateFormat", ".", "single", ",", "\n", "virtual_size", "=", "self", ".", "args", ".", "virtual_data_size", ",", "\n", "split", "=", "split", ",", "\n", "# if not using lang_tok altering, simplified to use the same collater", "\n", "shared_collater", "=", "self", ".", "_shared_collater", "(", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "load_into_concat_dataset", "(", "split", ",", "datasets", ",", "data_param_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_dataset": [[1067, 1077], ["multilingual_data_manager.MultilingualDatasetManager.load_sampled_multi_dataset", "multilingual_data_manager.MultilingualDatasetManager.load_sampled_multi_epoch_dataset"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_sampled_multi_dataset", "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.MultilingualDatasetManager.load_sampled_multi_epoch_dataset"], ["", "", "def", "load_dataset", "(", "\n", "self", ",", "split", ",", "training", ",", "epoch", "=", "0", ",", "combine", "=", "False", ",", "shard_epoch", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "virtual_epoch_size", "is", "None", ":", "\n", "            ", "return", "self", ".", "load_sampled_multi_dataset", "(", "\n", "split", ",", "training", ",", "epoch", ",", "combine", ",", "shard_epoch", ",", "**", "kwargs", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "load_sampled_multi_epoch_dataset", "(", "\n", "split", ",", "training", ",", "epoch", ",", "combine", ",", "shard_epoch", ",", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager._lang_id": [[43, 48], ["dic.index"], "function", ["home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.index"], ["def", "_lang_id", "(", "dic", ":", "Dictionary", ",", "lang", ":", "str", ")", ":", "\n", "    ", "\"\"\"Return language ID index.\"\"\"", "\n", "idx", "=", "dic", ".", "index", "(", "lang", ")", "\n", "assert", "idx", "!=", "dic", ".", "unk_index", ",", "\"cannot find language ID for lang {}\"", ".", "format", "(", "lang", ")", "\n", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.multilingual.multilingual_data_manager.load_sampling_weights": [[50, 54], ["open", "json.load"], "function", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.file_io.PathManager.open", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.load"], ["", "def", "load_sampling_weights", "(", "from_file", ")", ":", "\n", "    ", "with", "open", "(", "from_file", ")", "as", "f", ":", "\n", "        ", "weights", "=", "json", ".", "load", "(", "f", ")", "\n", "", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_masked_lm.DummyMaskedLMTask.add_args": [[19, 29], ["parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "parser", ".", "add_argument", "(", "\"--dict-size\"", ",", "default", "=", "49995", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset-size\"", ",", "default", "=", "100000", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokens-per-sample\"", ",", "\n", "default", "=", "512", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"max number of total tokens over all segments \"", "\n", "\"per sample for BERT dataset\"", ",", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_masked_lm.DummyMaskedLMTask.__init__": [[32, 51], ["fairseq.tasks.LegacyFairseqTask.__init__", "dictionary.add_symbol", "dictionary.pad_to_multiple_", "torch.arange", "seq.clone", "torch.full_like", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad_to_multiple_"], ["", "def", "__init__", "(", "self", ",", "args", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "\n", "# add mask token", "\n", "self", ".", "mask_idx", "=", "dictionary", ".", "add_symbol", "(", "\"<mask>\"", ")", "\n", "dictionary", ".", "pad_to_multiple_", "(", "8", ")", "# often faster if divisible by 8", "\n", "\n", "mask_idx", "=", "0", "\n", "pad_idx", "=", "1", "\n", "seq", "=", "torch", ".", "arange", "(", "args", ".", "tokens_per_sample", ")", "+", "pad_idx", "+", "1", "\n", "mask", "=", "torch", ".", "arange", "(", "2", ",", "args", ".", "tokens_per_sample", ",", "7", ")", "# ~15%", "\n", "src", "=", "seq", ".", "clone", "(", ")", "\n", "src", "[", "mask", "]", "=", "mask_idx", "\n", "tgt", "=", "torch", ".", "full_like", "(", "seq", ",", "pad_idx", ")", "\n", "tgt", "[", "mask", "]", "=", "seq", "[", "mask", "]", "\n", "\n", "self", ".", "dummy_src", "=", "src", "\n", "self", ".", "dummy_tgt", "=", "tgt", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_masked_lm.DummyMaskedLMTask.setup_task": [[52, 60], ["fairseq.data.Dictionary", "range", "logger.info", "cls", "fairseq.data.Dictionary.add_symbol", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Setup the task. \"\"\"", "\n", "dictionary", "=", "Dictionary", "(", ")", "\n", "for", "i", "in", "range", "(", "args", ".", "dict_size", ")", ":", "\n", "            ", "dictionary", ".", "add_symbol", "(", "\"word{}\"", ".", "format", "(", "i", ")", ")", "\n", "", "logger", ".", "info", "(", "\"dictionary: {} types\"", ".", "format", "(", "len", "(", "dictionary", ")", ")", ")", "\n", "return", "cls", "(", "args", ",", "dictionary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_masked_lm.DummyMaskedLMTask.load_dataset": [[61, 85], ["dummy_masked_lm.DummyDataset", "max", "torch.stack", "torch.stack", "torch.full", "range", "range"], "methods", ["None"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "1", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n        \"\"\"", "\n", "if", "self", ".", "args", ".", "batch_size", "is", "not", "None", ":", "\n", "            ", "bsz", "=", "self", ".", "args", ".", "batch_size", "\n", "", "else", ":", "\n", "            ", "bsz", "=", "max", "(", "1", ",", "self", ".", "args", ".", "max_tokens", "//", "self", ".", "args", ".", "tokens_per_sample", ")", "\n", "", "self", ".", "datasets", "[", "split", "]", "=", "DummyDataset", "(", "\n", "{", "\n", "\"id\"", ":", "1", ",", "\n", "\"net_input\"", ":", "{", "\n", "\"src_tokens\"", ":", "torch", ".", "stack", "(", "[", "self", ".", "dummy_src", "for", "_", "in", "range", "(", "bsz", ")", "]", ")", ",", "\n", "\"src_lengths\"", ":", "torch", ".", "full", "(", "\n", "(", "bsz", ",", ")", ",", "self", ".", "args", ".", "tokens_per_sample", ",", "dtype", "=", "torch", ".", "long", "\n", ")", ",", "\n", "}", ",", "\n", "\"target\"", ":", "torch", ".", "stack", "(", "[", "self", ".", "dummy_tgt", "for", "_", "in", "range", "(", "bsz", ")", "]", ")", ",", "\n", "\"nsentences\"", ":", "bsz", ",", "\n", "\"ntokens\"", ":", "bsz", "*", "self", ".", "args", ".", "tokens_per_sample", ",", "\n", "}", ",", "\n", "num_items", "=", "self", ".", "args", ".", "dataset_size", ",", "\n", "item_size", "=", "self", ".", "args", ".", "tokens_per_sample", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_masked_lm.DummyMaskedLMTask.source_dictionary": [[87, 90], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_masked_lm.DummyMaskedLMTask.target_dictionary": [[91, 94], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_masked_lm.DummyDataset.__init__": [[97, 102], ["fairseq.data.FairseqDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "batch", ",", "num_items", ",", "item_size", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "batch", "=", "batch", "\n", "self", ".", "num_items", "=", "num_items", "\n", "self", ".", "item_size", "=", "item_size", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_masked_lm.DummyDataset.__getitem__": [[103, 105], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_masked_lm.DummyDataset.__len__": [[106, 108], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_items", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_masked_lm.DummyDataset.collater": [[109, 111], ["None"], "methods", ["None"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "return", "self", ".", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_masked_lm.DummyDataset.sizes": [[112, 115], ["numpy.array"], "methods", ["None"], ["", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "array", "(", "[", "self", ".", "item_size", "]", "*", "self", ".", "num_items", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_masked_lm.DummyDataset.num_tokens": [[116, 118], ["None"], "methods", ["None"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "item_size", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_masked_lm.DummyDataset.size": [[119, 121], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "item_size", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_masked_lm.DummyDataset.ordered_indices": [[122, 124], ["numpy.arange"], "methods", ["None"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "arange", "(", "self", ".", "num_items", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_masked_lm.DummyDataset.supports_prefetch": [[125, 128], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_lm.DummyLMTask.__init__": [[37, 51], ["fairseq.tasks.FairseqTask.__init__", "fairseq.data.Dictionary", "range", "dummy_lm.DummyLMTask.dictionary.pad_to_multiple_", "logger.info", "dummy_lm.DummyLMTask.dictionary.add_symbol", "len", "torch.arange", "dummy_lm.DummyLMTask.dictionary.pad"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad_to_multiple_", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ":", "DummyLMConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ")", "\n", "\n", "# load dictionary", "\n", "self", ".", "dictionary", "=", "Dictionary", "(", ")", "\n", "for", "i", "in", "range", "(", "cfg", ".", "dict_size", ")", ":", "\n", "            ", "self", ".", "dictionary", ".", "add_symbol", "(", "\"word{}\"", ".", "format", "(", "i", ")", ")", "\n", "", "self", ".", "dictionary", ".", "pad_to_multiple_", "(", "8", ")", "# often faster if divisible by 8", "\n", "logger", ".", "info", "(", "\"dictionary: {} types\"", ".", "format", "(", "len", "(", "self", ".", "dictionary", ")", ")", ")", "\n", "\n", "seq", "=", "torch", ".", "arange", "(", "cfg", ".", "tokens_per_sample", "+", "1", ")", "+", "self", ".", "dictionary", ".", "pad", "(", ")", "+", "1", "\n", "\n", "self", ".", "dummy_src", "=", "seq", "[", ":", "-", "1", "]", "\n", "self", ".", "dummy_tgt", "=", "seq", "[", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_lm.DummyLMTask.load_dataset": [[52, 76], ["dummy_lm.DummyDataset", "max", "torch.stack", "torch.stack", "torch.full", "range", "range"], "methods", ["None"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "1", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n        \"\"\"", "\n", "if", "self", ".", "cfg", ".", "batch_size", "is", "not", "None", ":", "\n", "            ", "bsz", "=", "self", ".", "cfg", ".", "batch_size", "\n", "", "else", ":", "\n", "            ", "bsz", "=", "max", "(", "1", ",", "self", ".", "cfg", ".", "max_tokens", "//", "self", ".", "cfg", ".", "tokens_per_sample", ")", "\n", "", "self", ".", "datasets", "[", "split", "]", "=", "DummyDataset", "(", "\n", "{", "\n", "\"id\"", ":", "1", ",", "\n", "\"net_input\"", ":", "{", "\n", "\"src_tokens\"", ":", "torch", ".", "stack", "(", "[", "self", ".", "dummy_src", "for", "_", "in", "range", "(", "bsz", ")", "]", ")", ",", "\n", "\"src_lengths\"", ":", "torch", ".", "full", "(", "\n", "(", "bsz", ",", ")", ",", "self", ".", "cfg", ".", "tokens_per_sample", ",", "dtype", "=", "torch", ".", "long", "\n", ")", ",", "\n", "}", ",", "\n", "\"target\"", ":", "torch", ".", "stack", "(", "[", "self", ".", "dummy_tgt", "for", "_", "in", "range", "(", "bsz", ")", "]", ")", ",", "\n", "\"nsentences\"", ":", "bsz", ",", "\n", "\"ntokens\"", ":", "bsz", "*", "self", ".", "cfg", ".", "tokens_per_sample", ",", "\n", "}", ",", "\n", "num_items", "=", "self", ".", "cfg", ".", "dataset_size", ",", "\n", "item_size", "=", "self", ".", "cfg", ".", "tokens_per_sample", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_lm.DummyLMTask.source_dictionary": [[78, 81], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_lm.DummyLMTask.target_dictionary": [[82, 85], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_lm.DummyDataset.__init__": [[88, 93], ["fairseq.data.FairseqDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "batch", ",", "num_items", ",", "item_size", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "batch", "=", "batch", "\n", "self", ".", "num_items", "=", "num_items", "\n", "self", ".", "item_size", "=", "item_size", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_lm.DummyDataset.__getitem__": [[94, 96], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_lm.DummyDataset.__len__": [[97, 99], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_items", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_lm.DummyDataset.collater": [[100, 102], ["None"], "methods", ["None"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "return", "self", ".", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_lm.DummyDataset.sizes": [[103, 106], ["numpy.array"], "methods", ["None"], ["", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "array", "(", "[", "self", ".", "item_size", "]", "*", "self", ".", "num_items", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_lm.DummyDataset.num_tokens": [[107, 109], ["None"], "methods", ["None"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "item_size", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_lm.DummyDataset.size": [[110, 112], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "item_size", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_lm.DummyDataset.ordered_indices": [[113, 115], ["numpy.arange"], "methods", ["None"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "arange", "(", "self", ".", "num_items", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_lm.DummyDataset.supports_prefetch": [[116, 119], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyMTTask.add_args": [[19, 26], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "\"\"\"Add task-specific arguments to the parser.\"\"\"", "\n", "parser", ".", "add_argument", "(", "\"--dict-size\"", ",", "default", "=", "49996", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset-size\"", ",", "default", "=", "100000", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--src-len\"", ",", "default", "=", "30", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--tgt-len\"", ",", "default", "=", "30", ",", "type", "=", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyMTTask.__init__": [[27, 36], ["fairseq.tasks.LegacyFairseqTask.__init__", "dictionary.pad_to_multiple_", "torch.arange", "dictionary.pad", "torch.arange", "dictionary.pad"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad_to_multiple_", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["", "def", "__init__", "(", "self", ",", "args", ",", "dictionary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ")", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "self", ".", "seed", "=", "args", ".", "seed", "\n", "\n", "dictionary", ".", "pad_to_multiple_", "(", "8", ")", "# often faster if divisible by 8", "\n", "\n", "self", ".", "dummy_src", "=", "torch", ".", "arange", "(", "args", ".", "src_len", "+", "1", ")", "+", "dictionary", ".", "pad", "(", ")", "+", "1", "\n", "self", ".", "dummy_tgt", "=", "torch", ".", "arange", "(", "args", ".", "tgt_len", "+", "1", ")", "+", "dictionary", ".", "pad", "(", ")", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyMTTask.setup_task": [[37, 49], ["fairseq.data.Dictionary", "range", "logger.info", "cls", "fairseq.data.Dictionary.add_symbol", "len", "fairseq.data.Dictionary.pad", "fairseq.data.Dictionary.pad"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.add_symbol", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad", "home.repos.pwc.inspect_result.reneeye_const.data.dictionary.Dictionary.pad"], ["", "@", "classmethod", "\n", "def", "setup_task", "(", "cls", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Setup the task. \"\"\"", "\n", "dictionary", "=", "Dictionary", "(", ")", "\n", "for", "i", "in", "range", "(", "args", ".", "dict_size", ")", ":", "\n", "            ", "dictionary", ".", "add_symbol", "(", "\"word{}\"", ".", "format", "(", "i", ")", ")", "\n", "", "logger", ".", "info", "(", "\"dictionary: {} types\"", ".", "format", "(", "len", "(", "dictionary", ")", ")", ")", "\n", "\n", "args", ".", "max_source_positions", "=", "args", ".", "src_len", "+", "dictionary", ".", "pad", "(", ")", "+", "2", "\n", "args", ".", "max_target_positions", "=", "args", ".", "tgt_len", "+", "dictionary", ".", "pad", "(", ")", "+", "2", "\n", "\n", "return", "cls", "(", "args", ",", "dictionary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyMTTask.load_dataset": [[50, 77], ["max", "torch.stack", "dummy_mt.DummyDataset", "max", "range", "torch.stack", "torch.full", "torch.stack.clone", "range"], "methods", ["None"], ["", "def", "load_dataset", "(", "self", ",", "split", ",", "epoch", "=", "1", ",", "combine", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Load a given dataset split.\n        Args:\n            split (str): name of the split (e.g., train, valid, test)\n        \"\"\"", "\n", "item_size", "=", "max", "(", "self", ".", "args", ".", "src_len", ",", "self", ".", "args", ".", "tgt_len", ")", "\n", "if", "self", ".", "args", ".", "batch_size", "is", "not", "None", ":", "\n", "            ", "bsz", "=", "self", ".", "args", ".", "batch_size", "\n", "", "else", ":", "\n", "            ", "bsz", "=", "max", "(", "1", ",", "self", ".", "args", ".", "max_tokens", "//", "item_size", ")", "\n", "", "tgt", "=", "torch", ".", "stack", "(", "[", "self", ".", "dummy_tgt", "for", "_", "in", "range", "(", "bsz", ")", "]", ")", "\n", "self", ".", "datasets", "[", "split", "]", "=", "DummyDataset", "(", "\n", "{", "\n", "\"id\"", ":", "1", ",", "\n", "\"net_input\"", ":", "{", "\n", "\"src_tokens\"", ":", "torch", ".", "stack", "(", "[", "self", ".", "dummy_src", "for", "_", "in", "range", "(", "bsz", ")", "]", ")", ",", "\n", "\"src_lengths\"", ":", "torch", ".", "full", "(", "\n", "(", "bsz", ",", ")", ",", "self", ".", "args", ".", "src_len", ",", "dtype", "=", "torch", ".", "long", "\n", ")", ",", "\n", "\"prev_output_tokens\"", ":", "tgt", ".", "clone", "(", ")", ",", "\n", "}", ",", "\n", "\"target\"", ":", "tgt", ",", "\n", "\"nsentences\"", ":", "bsz", ",", "\n", "\"ntokens\"", ":", "bsz", "*", "self", ".", "args", ".", "tgt_len", ",", "\n", "}", ",", "\n", "num_items", "=", "self", ".", "args", ".", "dataset_size", ",", "\n", "item_size", "=", "item_size", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyMTTask.source_dictionary": [[79, 82], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "source_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyMTTask.target_dictionary": [[83, 86], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_dictionary", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.__init__": [[89, 94], ["fairseq.data.FairseqDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "batch", ",", "num_items", ",", "item_size", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "batch", "=", "batch", "\n", "self", ".", "num_items", "=", "num_items", "\n", "self", ".", "item_size", "=", "item_size", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.__getitem__": [[95, 97], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.__len__": [[98, 100], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_items", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.collater": [[101, 103], ["None"], "methods", ["None"], ["", "def", "collater", "(", "self", ",", "samples", ")", ":", "\n", "        ", "return", "self", ".", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.sizes": [[104, 107], ["numpy.array"], "methods", ["None"], ["", "@", "property", "\n", "def", "sizes", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "array", "(", "[", "self", ".", "item_size", "]", "*", "self", ".", "num_items", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.num_tokens": [[108, 110], ["None"], "methods", ["None"], ["", "def", "num_tokens", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "item_size", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.size": [[111, 113], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "item_size", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.ordered_indices": [[114, 116], ["numpy.arange"], "methods", ["None"], ["", "def", "ordered_indices", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "arange", "(", "self", ".", "num_items", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_mt.DummyDataset.supports_prefetch": [[117, 120], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_prefetch", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.__init__": [[19, 22], ["fairseq.models.FairseqLanguageModel.__init__"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "encoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "encoder", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.add_args": [[23, 27], ["parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "\"--num-layers\"", ",", "type", "=", "int", ",", "default", "=", "24", ")", "\n", "parser", ".", "add_argument", "(", "\"--embed-dim\"", ",", "type", "=", "int", ",", "default", "=", "1024", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.build_model": [[28, 36], ["dummy_model.DummyEncoder", "cls", "len"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.legacy.masked_lm_dictionary.BertDictionary.cls"], ["", "@", "classmethod", "\n", "def", "build_model", "(", "cls", ",", "args", ",", "task", ")", ":", "\n", "        ", "encoder", "=", "DummyEncoder", "(", "\n", "num_embed", "=", "len", "(", "task", ".", "target_dictionary", ")", ",", "\n", "embed_dim", "=", "args", ".", "embed_dim", ",", "\n", "num_layers", "=", "args", ".", "num_layers", ",", "\n", ")", "\n", "return", "cls", "(", "args", ",", "encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyModel.forward": [[37, 39], ["dummy_model.DummyModel.decoder"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.models.fairseq_model.FairseqMultiModel.decoder"], ["", "def", "forward", "(", "self", ",", "src_tokens", ",", "masked_tokens", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "decoder", "(", "src_tokens", ",", "masked_tokens", "=", "masked_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__": [[42, 72], ["fairseq.models.FairseqDecoder.__init__", "torch.Embedding", "torch.Embedding", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "fairseq.data.Dictionary", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.LayerNorm", "torch.LayerNorm", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "range", "torch.LayerNorm", "torch.LayerNorm", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "range"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.__init__", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Embedding", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.modules.layer_norm.LayerNorm", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear", "home.repos.pwc.inspect_result.reneeye_const.pipeline_parallel_transformer.layers.Linear"], ["    ", "def", "__init__", "(", "self", ",", "num_embed", "=", "50000", ",", "embed_dim", "=", "1024", ",", "num_layers", "=", "24", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "Dictionary", "(", ")", ")", "\n", "self", ".", "embed", "=", "nn", ".", "Embedding", "(", "\n", "num_embeddings", "=", "num_embed", ",", "embedding_dim", "=", "embed_dim", ",", "padding_idx", "=", "0", "\n", ")", "\n", "self", ".", "layers_a", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "nn", ".", "Sequential", "(", "\n", "nn", ".", "LayerNorm", "(", "embed_dim", ")", ",", "\n", "nn", ".", "Linear", "(", "embed_dim", ",", "3", "*", "embed_dim", ")", ",", "# q, k, v input projection", "\n", "nn", ".", "Linear", "(", "3", "*", "embed_dim", ",", "embed_dim", ")", ",", "# skip self-attention", "\n", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ")", ",", "# output projection", "\n", "nn", ".", "Dropout", "(", ")", ",", "\n", ")", "\n", "for", "i", "in", "range", "(", "num_layers", ")", "\n", "]", "\n", ")", "\n", "self", ".", "layers_b", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "nn", ".", "Sequential", "(", "\n", "nn", ".", "LayerNorm", "(", "embed_dim", ")", ",", "\n", "nn", ".", "Linear", "(", "embed_dim", ",", "4", "*", "embed_dim", ")", ",", "# FFN", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "4", "*", "embed_dim", ",", "embed_dim", ")", ",", "# FFN", "\n", "nn", ".", "Dropout", "(", "0.1", ")", ",", "\n", ")", "\n", "for", "i", "in", "range", "(", "num_layers", ")", "\n", "]", "\n", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "num_embed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.forward": [[73, 82], ["dummy_model.DummyEncoder.embed", "zip", "dummy_model.DummyEncoder.out_proj", "layer_a", "layer_b"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tokens", ",", "masked_tokens", "=", "None", ")", ":", "\n", "        ", "x", "=", "self", ".", "embed", "(", "tokens", ")", "\n", "for", "layer_a", ",", "layer_b", "in", "zip", "(", "self", ".", "layers_a", ",", "self", ".", "layers_b", ")", ":", "\n", "            ", "x", "=", "x", "+", "layer_a", "(", "x", ")", "\n", "x", "=", "x", "+", "layer_b", "(", "x", ")", "\n", "", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "if", "masked_tokens", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "[", "masked_tokens", "]", "\n", "", "return", "(", "x", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.max_positions": [[83, 85], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "return", "1024", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.DummyEncoder.get_normalized_probs": [[86, 92], ["net_output[].float", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax"], "methods", ["home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.log_softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax", "home.repos.pwc.inspect_result.reneeye_const.fairseq.utils.softmax"], ["", "def", "get_normalized_probs", "(", "self", ",", "net_output", ",", "log_probs", ",", "sample", "=", "None", ")", ":", "\n", "        ", "logits", "=", "net_output", "[", "0", "]", ".", "float", "(", ")", "\n", "if", "log_probs", ":", "\n", "            ", "return", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.reneeye_const.benchmark.dummy_model.base_architecture": [[94, 97], ["fairseq.models.register_model_architecture"], "function", ["home.repos.pwc.inspect_result.reneeye_const.models.__init__.register_model_architecture"], ["", "", "", "@", "register_model_architecture", "(", "\"dummy_model\"", ",", "\"dummy_model\"", ")", "\n", "def", "base_architecture", "(", "args", ")", ":", "\n", "    ", "pass", "\n", "", ""]]}