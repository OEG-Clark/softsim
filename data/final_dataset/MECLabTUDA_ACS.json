{"home.repos.pwc.inspect_result.MECLabTUDA_ACS.None.args._get_parser": [[5, 65], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "_get_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# general", "\n", "parser", ".", "add_argument", "(", "'--experiment-name'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'experiment name for new or resume'", ")", "\n", "parser", ".", "add_argument", "(", "'--nr-runs'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'# of runs'", ")", "\n", "\n", "# hardware", "\n", "parser", ".", "add_argument", "(", "'--device'", ",", "type", "=", "str", ",", "default", "=", "'cuda'", ",", "help", "=", "'device type cpu or cuda'", ")", "\n", "parser", ".", "add_argument", "(", "\"--device-ids\"", ",", "nargs", "=", "\"+\"", ",", "default", "=", "[", "0", "]", ",", "type", "=", "int", ",", "help", "=", "\"ID(s) of GPU device(s)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--n-workers'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "help", "=", "'# multiplied by # of GPU to get # of total workers'", ")", "\n", "\n", "# dataset", "\n", "parser", ".", "add_argument", "(", "'--test-ratio'", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "help", "=", "'ratio of data to be used for testing'", ")", "\n", "parser", ".", "add_argument", "(", "'--val-ratio'", ",", "type", "=", "float", ",", "default", "=", "0.125", ",", "help", "=", "'ratio of data to be used for validation'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_dim_c'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'input channels for images'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_dim_hw'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "'height and width for images'", ")", "\n", "parser", ".", "add_argument", "(", "'--no-resize'", ",", "action", "=", "'store_true'", ",", "help", "=", "'specify if images should not be resized'", ")", "\n", "parser", ".", "add_argument", "(", "'--augmentation'", ",", "type", "=", "str", ",", "default", "=", "'none'", ",", "help", "=", "'augmentation to be used'", ")", "\n", "parser", ".", "add_argument", "(", "'--n-samples'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "help", "=", "'# of samples per dataloader, only use when debugging'", ")", "\n", "parser", ".", "add_argument", "(", "'--sampler'", ",", "action", "=", "'store_true'", ",", "help", "=", "'sample datasets to have equal # of samples'", ")", "\n", "parser", ".", "add_argument", "(", "'--combination'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'0: ab->c, 1: ac->b, 2: bc->a'", ")", "\n", "\n", "# training", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "60", ",", "help", "=", "'# of epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "help", "=", "'batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "2e-4", ",", "help", "=", "'learning rate for training stage 1'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr-2'", ",", "type", "=", "float", ",", "default", "=", "1e-4", ",", "help", "=", "'learning rate for training stage 2'", ")", "\n", "parser", ".", "add_argument", "(", "'--domain-code-size'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'# of domains present in training stage 1'", ")", "\n", "parser", ".", "add_argument", "(", "'--cross-validation'", ",", "action", "=", "'store_true'", ",", "help", "=", "'specify if cross validation should be used'", ")", "\n", "parser", ".", "add_argument", "(", "'--d-iter'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'discriminator update iterations per epoch'", ")", "\n", "\n", "# resume training", "\n", "parser", ".", "add_argument", "(", "'--resume-epoch'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "help", "=", "'resume training at epoch, -1 for latest, select run using experiment-name argument'", ")", "\n", "\n", "# logging", "\n", "parser", ".", "add_argument", "(", "'--eval-interval'", ",", "type", "=", "int", ",", "default", "=", "7", ",", "help", "=", "'evaluation interval (on all datasets)'", ")", "\n", "parser", ".", "add_argument", "(", "'--save-interval'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'save interval'", ")", "\n", "parser", ".", "add_argument", "(", "'--display-interval'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'display/tensorboard interval'", ")", "\n", "\n", "# evaluation", "\n", "parser", ".", "add_argument", "(", "'--eval'", ",", "action", "=", "'store_true'", ",", "help", "=", "'for general evaluation (only eval on test)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda-eval'", ",", "action", "=", "'store_true'", ",", "help", "=", "'for tuning lambda (only eval on val)'", ")", "\n", "\n", "# loss weighting", "\n", "parser", ".", "add_argument", "(", "'--lambda-vae'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "help", "=", "'lambda tuning vae loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda-c-adv'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "help", "=", "'lambda tuning content adversarial loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda-lcr'", ",", "type", "=", "float", ",", "default", "=", "1e-4", ",", "help", "=", "'lambda tuning lcr loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda-seg'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "help", "=", "'lambda tuning segmentation loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda-c-recon'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "help", "=", "'lambda tuning content reconstruction loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda-gan'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "help", "=", "'lambda tuning gan loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda-d'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "help", "=", "'lambda for tuning MAS or KD loss'", ")", "\n", "\n", "# U-Net", "\n", "parser", ".", "add_argument", "(", "'--unet-only'", ",", "action", "=", "'store_true'", ",", "help", "=", "'only train UNet'", ")", "\n", "parser", ".", "add_argument", "(", "'--unet-dropout'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "help", "=", "'apply dropout to UNet'", ")", "\n", "parser", ".", "add_argument", "(", "'--unet-monte-carlo-dropout'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "help", "=", "'apply monte carlo dropout to UNet'", ")", "\n", "parser", ".", "add_argument", "(", "'--unet-preactivation'", ",", "action", "=", "'store_true'", ",", "help", "=", "'UNet preactivation; True: norm, act, conv; False:conv, norm, act'", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.None.args.parse_args": [[66, 82], ["args._get_parser", "_get_parser.parse_args", "str", "str", "print", "torch.cuda.get_device_name", "torch.cuda.is_available", "str"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.None.args._get_parser", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.None.args.parse_args"], ["", "def", "parse_args", "(", "argv", ")", ":", "\n", "    ", "\"\"\"Parses arguments passed from the console as, e.g.\n    'python ptt/main.py --epochs 3' \"\"\"", "\n", "\n", "parser", "=", "_get_parser", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", "argv", ")", "\n", "\n", "args", ".", "device", "=", "str", "(", "args", ".", "device", "+", "':'", "+", "str", "(", "args", ".", "device_ids", "[", "0", "]", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "args", ".", "device", "==", "\"cuda\"", "else", "\"cpu\"", ")", "\n", "device_name", "=", "str", "(", "torch", ".", "cuda", ".", "get_device_name", "(", "args", ".", "device", ")", "if", "args", ".", "device", "==", "\"cuda\"", "else", "args", ".", "device", ")", "\n", "print", "(", "'Device name: {}'", ".", "format", "(", "device_name", ")", ")", "\n", "args", ".", "input_shape", "=", "(", "args", ".", "input_dim_c", ",", "args", ".", "input_dim_hw", ",", "args", ".", "input_dim_hw", ")", "\n", "\n", "# add dummy class", "\n", "args", ".", "domain_code_size", "=", "args", ".", "domain_code_size", "+", "1", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.None.args.parse_args_as_dict": [[83, 86], ["vars", "args.parse_args"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.None.args.parse_args"], ["", "def", "parse_args_as_dict", "(", "argv", ")", ":", "\n", "    ", "\"\"\"Parses arguments passed from the console and returns a dictionary \"\"\"", "\n", "return", "vars", "(", "parse_args", "(", "argv", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.None.args.parse_dict_as_args": [[87, 98], ["dictionary.items", "args.parse_args", "isinstance", "argv.append", "argv.append", "argv.append", "str"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.None.args.parse_args"], ["", "def", "parse_dict_as_args", "(", "dictionary", ")", ":", "\n", "    ", "\"\"\"Parses arguments given in a dictionary form\"\"\"", "\n", "argv", "=", "[", "]", "\n", "for", "key", ",", "value", "in", "dictionary", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "value", ",", "bool", ")", ":", "\n", "            ", "if", "value", ":", "\n", "                ", "argv", ".", "append", "(", "'--'", "+", "key", ")", "\n", "", "", "else", ":", "\n", "            ", "argv", ".", "append", "(", "'--'", "+", "key", ")", "\n", "argv", ".", "append", "(", "str", "(", "value", ")", ")", "\n", "", "", "return", "parse_args", "(", "argv", ")", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.test_helper_functions.test_date_time": [[3, 8], ["mp.get_time_string", "mp.get_time_string", "len", "len"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.helper_functions.get_time_string", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.helper_functions.get_time_string"], ["def", "test_date_time", "(", ")", ":", "\n", "    ", "date", "=", "hf", ".", "get_time_string", "(", "True", ")", "\n", "assert", "len", "(", "date", ")", "==", "21", "\n", "date", "=", "hf", ".", "get_time_string", "(", "False", ")", "\n", "assert", "len", "(", "date", ")", "==", "19", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.test_introspection.test_introspection": [[4, 8], ["mp.utils.introspection.introspect"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.introspection.introspect"], ["def", "test_introspection", "(", ")", ":", "\n", "    ", "class_path", "=", "'mp.models.classification.small_cnn.SmallCNN'", "\n", "exp", "=", "introspect", "(", "class_path", ")", "(", ")", "\n", "assert", "exp", ".", "__class__", ".", "__name__", "==", "'SmallCNN'", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.introspection.introspect": [[5, 16], ["isinstance", "__import__", "getattr", "class_path.split.split", "getattr"], "function", ["None"], ["def", "introspect", "(", "class_path", ")", ":", "\n", "    ", "r\"\"\"Creates a class dynamically from a class path.\"\"\"", "\n", "if", "isinstance", "(", "class_path", ",", "str", ")", ":", "\n", "        ", "class_path", "=", "class_path", ".", "split", "(", "'.'", ")", "\n", "", "class_name", "=", "class_path", "[", "-", "1", "]", "\n", "module_path", "=", "class_path", "[", ":", "-", "1", "]", "\n", "module", "=", "__import__", "(", "'.'", ".", "join", "(", "module_path", ")", ")", "\n", "for", "m", "in", "module_path", "[", "1", ":", "]", ":", "\n", "        ", "module", "=", "getattr", "(", "module", ",", "m", ")", "\n", "", "module", "=", "getattr", "(", "module", ",", "class_name", ")", "\n", "return", "module", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.tensorboard.create_writer": [[3, 7], ["torch.utils.tensorboard.SummaryWriter"], "function", ["None"], ["def", "create_writer", "(", "path", ",", "init_epoch", "=", "0", ")", ":", "\n", "    ", "''' Creates tensorboard SummaryWriter.'''", "\n", "\n", "return", "SummaryWriter", "(", "path", ",", "purge_step", "=", "init_epoch", ")", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.pkl_dump": [[9, 15], ["os.path.join", "pickle.dump", "open"], "function", ["None"], ["def", "pkl_dump", "(", "obj", ",", "name", ",", "path", "=", "'obj'", ")", ":", "\n", "    ", "r\"\"\"Saves an object in pickle format.\"\"\"", "\n", "if", "'.p'", "not", "in", "name", ":", "\n", "        ", "name", "=", "name", "+", "'.pkl'", "\n", "", "path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", "\n", "pickle", ".", "dump", "(", "obj", ",", "open", "(", "path", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.pkl_load": [[16, 26], ["os.path.join", "pickle.load", "open"], "function", ["None"], ["", "def", "pkl_load", "(", "name", ",", "path", "=", "'obj'", ")", ":", "\n", "    ", "r\"\"\"Restores an object from a pickle file.\"\"\"", "\n", "if", "'.p'", "not", "in", "name", ":", "\n", "        ", "name", "=", "name", "+", "'.pkl'", "\n", "", "path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", "\n", "try", ":", "\n", "        ", "obj", "=", "pickle", ".", "load", "(", "open", "(", "path", ",", "'rb'", ")", ")", "\n", "", "except", "FileNotFoundError", ":", "\n", "        ", "obj", "=", "None", "\n", "", "return", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.np_dump": [[30, 36], ["os.path.join", "numpy.save"], "function", ["None"], ["def", "np_dump", "(", "obj", ",", "name", ",", "path", "=", "'obj'", ")", ":", "\n", "    ", "r\"\"\"Saves an object in npy format.\"\"\"", "\n", "if", "'.npy'", "not", "in", "name", ":", "\n", "        ", "name", "=", "name", "+", "'.npy'", "\n", "", "path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", "\n", "save", "(", "path", ",", "obj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.np_load": [[37, 47], ["os.path.join", "numpy.load"], "function", ["None"], ["", "def", "np_load", "(", "name", ",", "path", "=", "'obj'", ")", ":", "\n", "    ", "r\"\"\"Restores an object from a npy file.\"\"\"", "\n", "if", "'.npy'", "not", "in", "name", ":", "\n", "        ", "name", "=", "name", "+", "'.npy'", "\n", "", "path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", "\n", "try", ":", "\n", "        ", "obj", "=", "load", "(", "path", ")", "\n", "", "except", "FileNotFoundError", ":", "\n", "        ", "obj", "=", "None", "\n", "", "return", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.save_json": [[50, 56], ["open", "json.dump", "os.path.join"], "function", ["None"], ["def", "save_json", "(", "dict_obj", ",", "path", ",", "name", ")", ":", "\n", "    ", "r\"\"\"Saves a dictionary in json format.\"\"\"", "\n", "if", "'.json'", "not", "in", "name", ":", "\n", "        ", "name", "+=", "'.json'", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", ",", "'w'", ")", "as", "json_file", ":", "\n", "        ", "json", ".", "dump", "(", "dict_obj", ",", "json_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.load_json": [[57, 63], ["open", "json.load", "os.path.join"], "function", ["None"], ["", "", "def", "load_json", "(", "path", ",", "name", ")", ":", "\n", "    ", "r\"\"\"Restores a dictionary from a json file.\"\"\"", "\n", "if", "'.json'", "not", "in", "name", ":", "\n", "        ", "name", "+=", "'.json'", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", ",", "'r'", ")", "as", "json_file", ":", "\n", "        ", "return", "json", ".", "load", "(", "json_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.nifty_dump": [[65, 77], ["os.path.join", "sitk.WriteImage", "str", "np.moveaxis.detach().cpu().numpy", "len", "np.moveaxis", "len", "sitk.GetImageFromArray", "type", "np.moveaxis.detach().cpu", "np.moveaxis.detach"], "function", ["None"], ["", "", "def", "nifty_dump", "(", "x", ",", "name", ",", "path", ")", ":", "\n", "    ", "r\"\"\"Save a tensor of numpy array in nifty format.\"\"\"", "\n", "if", "'torch.Tensor'", "in", "str", "(", "type", "(", "x", ")", ")", ":", "\n", "        ", "x", "=", "x", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "if", "'.nii'", "not", "in", "name", ":", "\n", "        ", "name", "=", "name", "+", "'.nii.gz'", "\n", "# Remove channels dimension and rotate axis so depth first", "\n", "", "if", "len", "(", "x", ".", "shape", ")", "==", "4", ":", "\n", "        ", "x", "=", "np", ".", "moveaxis", "(", "x", "[", "0", "]", ",", "-", "1", ",", "0", ")", "\n", "", "assert", "len", "(", "x", ".", "shape", ")", "==", "3", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", "\n", "sitk", ".", "WriteImage", "(", "sitk", ".", "GetImageFromArray", "(", "x", ")", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.join_path": [[80, 83], ["functools.reduce"], "function", ["None"], ["def", "join_path", "(", "list", ")", ":", "\n", "    ", "r\"\"\"From a list of chained directories, forms a path\"\"\"", "\n", "return", "functools", ".", "reduce", "(", "os", ".", "path", ".", "join", ",", "list", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.helper_functions.f_optional_args": [[5, 11], ["f", "f"], "function", ["None"], ["def", "f_optional_args", "(", "f", ",", "args", ",", "x", ")", ":", "\n", "    ", "r\"\"\"If there are arguments, these are passed to the function.\"\"\"", "\n", "if", "args", ":", "\n", "        ", "return", "f", "(", "x", ",", "**", "args", ")", "\n", "", "else", ":", "\n", "        ", "return", "f", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.helper_functions.get_time_string": [[13, 23], ["str().replace().replace().split", "str().replace().replace", "str().replace", "str", "datetime.datetime.now"], "function", ["None"], ["def", "get_time_string", "(", "cover", "=", "False", ")", ":", "\n", "    ", "r\"\"\"\n    Returns the current time in the format YYYY-MM-DD_HH-MM, or\n    [YYYY-MM-DD_HH-MM] if 'cover' is set to 'True'.\n    \"\"\"", "\n", "date", "=", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ".", "replace", "(", "' '", ",", "'_'", ")", ".", "replace", "(", "':'", ",", "'-'", ")", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "if", "cover", ":", "\n", "        ", "return", "'['", "+", "date", "+", "']'", "\n", "", "else", ":", "\n", "        ", "return", "date", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.helper_functions.divide_path_fname": [[25, 33], ["ntpath.split", "ntpath.basename", "path_to_file.split"], "function", ["None"], ["def", "divide_path_fname", "(", "path", ")", ":", "\n", "    ", "r\"\"\"Divide path and name from a full path.\"\"\"", "\n", "path_to_file", ",", "file_name", "=", "ntpath", ".", "split", "(", "path", ")", "\n", "if", "not", "file_name", ":", "\n", "# Cease where the path ends with a slash", "\n", "        ", "file_name", "=", "ntpath", ".", "basename", "(", "path_to_file", ")", "\n", "path_to_file", "=", "path_to_file", ".", "split", "(", "file_name", ")", "[", "0", "]", "\n", "", "return", "path_to_file", ",", "file_name", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.helper_functions.seed_all": [[37, 43], ["random.seed", "numpy.random.seed", "torch.manual_seed"], "function", ["None"], ["def", "seed_all", "(", "seed", "=", "42", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "False", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.test_confusion_matrix.test_confusion_matrix": [[4, 20], ["mp.visualization.confusion_matrix.ConfusionMatrix", "mp.visualization.confusion_matrix.ConfusionMatrix.add", "mp.visualization.confusion_matrix.ConfusionMatrix.add", "mp.visualization.confusion_matrix.ConfusionMatrix.add", "mp.visualization.confusion_matrix.ConfusionMatrix.add", "mp.visualization.confusion_matrix.ConfusionMatrix.add", "os.path.join", "mp.visualization.confusion_matrix.ConfusionMatrix.plot", "os.path.isfile", "os.path.join", "mp.visualization.confusion_matrix.ConfusionMatrix.get_accuracy"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.confusion_matrix.ConfusionMatrix.plot", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.confusion_matrix.ConfusionMatrix.get_accuracy"], ["def", "test_confusion_matrix", "(", ")", ":", "\n", "# We have 3 classes", "\n", "    ", "cm", "=", "ConfusionMatrix", "(", "3", ")", "\n", "# 2 tp for each class", "\n", "cm", ".", "add", "(", "predicted", "=", "0", ",", "actual", "=", "0", ",", "count", "=", "2", ")", "\n", "cm", ".", "add", "(", "predicted", "=", "1", ",", "actual", "=", "1", ",", "count", "=", "2", ")", "\n", "cm", ".", "add", "(", "predicted", "=", "2", ",", "actual", "=", "2", ",", "count", "=", "2", ")", "\n", "# 3 exampels of class 0 were predicted as class 1", "\n", "cm", ".", "add", "(", "predicted", "=", "1", ",", "actual", "=", "0", ",", "count", "=", "3", ")", "\n", "# 1 example of class 1 was predicted as class 2", "\n", "cm", ".", "add", "(", "predicted", "=", "2", ",", "actual", "=", "1", ",", "count", "=", "1", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "'test'", ",", "'test_obj'", ")", "\n", "cm", ".", "plot", "(", "path", "=", "save_path", ",", "name", "=", "'test_confusion_matrix'", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "save_path", ",", "'test_confusion_matrix.png'", ")", ")", "\n", "assert", "cm", ".", "cm", "==", "[", "[", "2", ",", "3", ",", "0", "]", ",", "[", "0", ",", "2", ",", "1", "]", ",", "[", "0", ",", "0", ",", "2", "]", "]", "\n", "assert", "cm", ".", "get_accuracy", "(", ")", "==", "0.6", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.test_visualize_imgs.test_3d_img": [[6, 15], ["os.path.join", "SimpleITK.ReadImage", "SimpleITK.ReadImage", "SimpleITK.GetArrayFromImage", "os.path.join", "mp.plot_3d_img", "os.path.isfile", "os.path.join", "SimpleITK.GetArrayFromImage", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.plot_3d_img"], ["def", "test_3d_img", "(", ")", ":", "\n", "    ", "images_path", "=", "os", ".", "path", ".", "join", "(", "'test'", ",", "'test_obj'", ")", "\n", "x", "=", "sitk", ".", "ReadImage", "(", "os", ".", "path", ".", "join", "(", "images_path", ",", "'img_00.nii'", ")", ")", "\n", "x", "=", "sitk", ".", "GetArrayFromImage", "(", "x", ")", "[", "0", "]", "# Take only T2-weighted", "\n", "y", "=", "sitk", ".", "ReadImage", "(", "os", ".", "path", ".", "join", "(", "images_path", ",", "'mask_00.nii'", ")", ")", "\n", "y", "=", "sitk", ".", "GetArrayFromImage", "(", "y", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "'test'", ",", "'test_obj'", ")", "\n", "vi", ".", "plot_3d_img", "(", "x", ",", "save_path", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "'3dimg.png'", ")", ",", "img_size", "=", "(", "128", ",", "128", ")", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "save_path", ",", "'3dimg.png'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.test_visualize_imgs.test_3d_seg": [[16, 25], ["os.path.join", "SimpleITK.ReadImage", "SimpleITK.ReadImage", "SimpleITK.GetArrayFromImage", "os.path.join", "mp.plot_3d_segmentation", "os.path.isfile", "os.path.join", "SimpleITK.GetArrayFromImage", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.plot_3d_segmentation"], ["", "def", "test_3d_seg", "(", ")", ":", "\n", "    ", "images_path", "=", "os", ".", "path", ".", "join", "(", "'test'", ",", "'test_obj'", ")", "\n", "x", "=", "sitk", ".", "ReadImage", "(", "os", ".", "path", ".", "join", "(", "images_path", ",", "'img_00.nii'", ")", ")", "\n", "x", "=", "sitk", ".", "GetArrayFromImage", "(", "x", ")", "[", "0", "]", "# Take only T2-weighted", "\n", "y", "=", "sitk", ".", "ReadImage", "(", "os", ".", "path", ".", "join", "(", "images_path", ",", "'mask_00.nii'", ")", ")", "\n", "y", "=", "sitk", ".", "GetArrayFromImage", "(", "y", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "'test'", ",", "'test_obj'", ")", "\n", "vi", ".", "plot_3d_segmentation", "(", "x", ",", "y", ",", "save_path", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "'3dsegm.png'", ")", ",", "img_size", "=", "(", "128", ",", "128", ")", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "save_path", ",", "'3dsegm.png'", ")", ")", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.test_plot_results.test_plotting": [[6, 18], ["mp.eval.result.Result", "mp.eval.result.Result.add", "mp.eval.result.Result.add", "mp.eval.result.Result.add", "mp.eval.result.Result.add", "mp.eval.result.Result.add", "mp.eval.result.Result.add", "mp.eval.result.Result.add", "os.path.join", "mp.visualization.plot_results.plot_results", "os.path.isfile", "os.path.join"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.plot_results.plot_results"], ["def", "test_plotting", "(", ")", ":", "\n", "    ", "res", "=", "Result", "(", "name", "=", "'example_result'", ")", "\n", "res", ".", "add", "(", "1", ",", "'accuracy'", ",", "0.2", ",", "data", "=", "'train'", ")", "\n", "res", ".", "add", "(", "2", ",", "'accuracy'", ",", "0.3", ",", "data", "=", "'train'", ")", "\n", "res", ".", "add", "(", "3", ",", "'accuracy'", ",", "0.4", ",", "data", "=", "'train'", ")", "\n", "res", ".", "add", "(", "0", ",", "'F1'", ",", "0.5", ",", "data", "=", "'train'", ")", "\n", "res", ".", "add", "(", "3", ",", "'F1'", ",", "0.7", ",", "data", "=", "'train'", ")", "\n", "res", ".", "add", "(", "0", ",", "'F1'", ",", "0.3", ",", "data", "=", "'val'", ")", "\n", "res", ".", "add", "(", "3", ",", "'F1'", ",", "0.45", ",", "data", "=", "'val'", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "'test'", ",", "'test_obj'", ")", "\n", "plot_results", "(", "res", ",", "measures", "=", "[", "'accuracy'", ",", "'F1'", "]", ",", "save_path", "=", "save_path", ",", "title", "=", "'Test figure'", ",", "ending", "=", "'.png'", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "save_path", ",", "'example_result.png'", ")", ")", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.confusion_matrix.ConfusionMatrix.__init__": [[16, 22], ["list", "range", "range", "range"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "nr_classes", ",", "labels", "=", "None", ")", ":", "\n", "        ", "self", ".", "cm", "=", "[", "[", "0", "for", "i", "in", "range", "(", "nr_classes", ")", "]", "for", "i", "in", "range", "(", "nr_classes", ")", "]", "\n", "if", "labels", "is", "None", ":", "\n", "            ", "self", ".", "labels", "=", "list", "(", "range", "(", "nr_classes", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "labels", "=", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.confusion_matrix.ConfusionMatrix.add": [[23, 26], ["confusion_matrix.ConfusionMatrix.labels.index", "confusion_matrix.ConfusionMatrix.labels.index"], "methods", ["None"], ["", "", "def", "add", "(", "self", ",", "predicted", ",", "actual", ",", "count", "=", "1", ")", ":", "\n", "        ", "r\"\"\"Set an entry for the confusion matrix.\"\"\"", "\n", "self", ".", "cm", "[", "self", ".", "labels", ".", "index", "(", "actual", ")", "]", "[", "self", ".", "labels", ".", "index", "(", "predicted", ")", "]", "+=", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.confusion_matrix.ConfusionMatrix.plot": [[27, 41], ["confusion_matrix.ConfusionMatrix.cm.copy", "len", "confusion_matrix.ConfusionMatrix.insert", "pandas.DataFrame", "df.drop.drop.drop", "matplotlib.figure", "seaborn.set", "seaborn.heatmap", "seaborn.heatmap.set", "matplotlib.savefig", "os.path.join", "range"], "methods", ["None"], ["", "def", "plot", "(", "self", ",", "path", ",", "name", "=", "'confusion_matrix'", ",", "label_predicted", "=", "'Predicted'", ",", "\n", "label_actual", "=", "'Actual'", ",", "figure_size", "=", "(", "7", ",", "5", ")", ",", "annot", "=", "True", ")", ":", "\n", "        ", "r\"\"\"Plot using seaborn.\"\"\"", "\n", "cm", "=", "self", ".", "cm", ".", "copy", "(", ")", "\n", "nr_rows", "=", "len", "(", "cm", ")", "\n", "cm", ".", "insert", "(", "0", ",", "[", "0", "]", "*", "nr_rows", ")", "\n", "df", "=", "pd", ".", "DataFrame", "(", "cm", ",", "columns", "=", "[", "c", "+", "1", "for", "c", "in", "range", "(", "nr_rows", ")", "]", ")", "\n", "df", "=", "df", ".", "drop", "(", "[", "0", "]", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "sns", ".", "set", "(", "rc", "=", "{", "'figure.figsize'", ":", "figure_size", "}", ")", "\n", "ax", "=", "sns", ".", "heatmap", "(", "df", ",", "annot", "=", "annot", ")", "\n", "ax", ".", "set", "(", "xlabel", "=", "label_predicted", ",", "ylabel", "=", "label_actual", ")", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "path", ",", "name", "+", "'.png'", ")", ",", "facecolor", "=", "'w'", ",", "\n", "bbox_inches", "=", "\"tight\"", ",", "dpi", "=", "300", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.confusion_matrix.ConfusionMatrix.get_accuracy": [[42, 47], ["sum", "sum", "sum", "range", "len"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum"], ["", "def", "get_accuracy", "(", "self", ")", ":", "\n", "        ", "r\"\"\"Get the accuracy.\"\"\"", "\n", "correct", "=", "sum", "(", "[", "self", ".", "cm", "[", "i", "]", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cm", ")", ")", "]", ")", "\n", "all_instances", "=", "sum", "(", "[", "sum", "(", "x", ")", "for", "x", "in", "self", ".", "cm", "]", ")", "\n", "return", "correct", "/", "all_instances", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.plot_results.plot_results": [[10, 61], ["result.to_pandas", "matplotlib.figure", "seaborn.set", "seaborn.lineplot", "seaborn.scatterplot", "mp.utils.seaborn.legend_utils.format_legend", "sns.scatterplot.set_yscale", "sns.scatterplot.set_title", "matplotlib.savefig", "os.path.exists", "os.makedirs", "os.path.join", "df[].isin", "file_name.split"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.to_pandas", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.seaborn.legend_utils.format_legend"], ["def", "plot_results", "(", "result", ",", "measures", "=", "None", ",", "save_path", "=", "None", ",", "save_name", "=", "None", ",", "\n", "title", "=", "None", ",", "ending", "=", "'.png'", ",", "ylog", "=", "False", ",", "figsize", "=", "(", "10", ",", "5", ")", ")", ":", "\n", "    ", "\"\"\"Plots a data frame as created by mp.eval.Results\n\n    Args:\n        measures (list[str]): list of measure names\n        save_path (str): path to save plot. If None, plot is shown.\n        save_name (str): name with which plot is saved\n        title (str): the title that will appear on the plot\n        ending (str): can be '.png' or '.svg'\n        ylog (bool): apply logarithm to y axis\n        figsize (tuple[int]): figure size\n    \"\"\"", "\n", "df", "=", "result", ".", "to_pandas", "(", ")", "\n", "# Filter out measures that are not to be shown", "\n", "# The default is using all measures in the df", "\n", "if", "measures", ":", "\n", "        ", "df", "=", "df", ".", "loc", "[", "df", "[", "'Metric'", "]", ".", "isin", "(", "measures", ")", "]", "\n", "# Start a new figure so that different plots do not overlap", "\n", "", "plt", ".", "figure", "(", ")", "\n", "sns", ".", "set", "(", "rc", "=", "{", "'figure.figsize'", ":", "figsize", "}", ")", "\n", "# Plot", "\n", "ax", "=", "sns", ".", "lineplot", "(", "x", "=", "'Epoch'", ",", "\n", "y", "=", "'Value'", ",", "\n", "hue", "=", "'Metric'", ",", "\n", "style", "=", "'Data'", ",", "\n", "alpha", "=", "0.7", ",", "\n", "data", "=", "df", ")", "\n", "ax", "=", "sns", ".", "scatterplot", "(", "x", "=", "'Epoch'", ",", "\n", "y", "=", "'Value'", ",", "\n", "hue", "=", "'Metric'", ",", "\n", "style", "=", "'Data'", ",", "\n", "alpha", "=", "1.", ",", "\n", "data", "=", "df", ")", "\n", "# Optional logarithmic scale", "\n", "if", "ylog", ":", "\n", "        ", "ax", ".", "set_yscale", "(", "'log'", ")", "\n", "# Style legend", "\n", "", "titles", "=", "[", "'Metric'", ",", "'Data'", "]", "\n", "format_legend", "(", "ax", ",", "titles", ")", "\n", "# Set title", "\n", "if", "title", ":", "\n", "        ", "ax", ".", "set_title", "(", "title", ")", "\n", "# Save image", "\n", "", "if", "save_path", ":", "\n", "        ", "file_name", "=", "save_name", "if", "save_name", "is", "not", "None", "else", "result", ".", "name", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "save_path", ")", "\n", "", "file_name", "=", "file_name", ".", "split", "(", "'.'", ")", "[", "0", "]", "+", "ending", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "save_path", ",", "file_name", ")", ",", "facecolor", "=", "'w'", ",", "\n", "bbox_inches", "=", "\"tight\"", ",", "dpi", "=", "300", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.img_to_numpy_array": [[15, 28], ["str", "type", "SimpleITK.GetArrayFromImage", "x.tensor.numpy", "x.detach().cpu().numpy", "x.detach().cpu", "x.detach"], "function", ["None"], ["def", "img_to_numpy_array", "(", "x", ")", ":", "\n", "    ", "r\"\"\"Transform an image in several formats into a numpy array.\"\"\"", "\n", "type_str", "=", "str", "(", "type", "(", "x", ")", ")", "\n", "if", "'SimpleITK.SimpleITK.Image'", "in", "type_str", ":", "\n", "        ", "return", "sitk", ".", "GetArrayFromImage", "(", "x", ")", "\n", "", "elif", "'torchio.data.image.Image'", "in", "type_str", ":", "\n", "        ", "return", "x", ".", "tensor", ".", "numpy", "(", ")", "\n", "", "elif", "'torch.Tensor'", "in", "type_str", ":", "\n", "        ", "return", "x", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "elif", "'numpy.ndarray'", "in", "type_str", ":", "\n", "        ", "return", "x", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.ensure_channel_width_height_depth": [[29, 40], ["numpy.argsort", "len", "np_array.transpose.transpose", "len", "np_array.transpose.transpose"], "function", ["None"], ["", "", "def", "ensure_channel_width_height_depth", "(", "np_array", ")", ":", "\n", "    ", "r\"\"\"Ensure the dimensions go channels, width, height(, depth)\"\"\"", "\n", "# TODO keep width and height in initial dimensions, right now largest first", "\n", "axis_order", "=", "np", ".", "argsort", "(", "np_array", ".", "shape", ")", "\n", "if", "len", "(", "np_array", ".", "shape", ")", "==", "3", ":", "\n", "        ", "np_array", "=", "np_array", ".", "transpose", "(", "\n", "axis_order", "[", "0", "]", ",", "axis_order", "[", "2", "]", ",", "axis_order", "[", "1", "]", ")", "\n", "", "if", "len", "(", "np_array", ".", "shape", ")", "==", "4", ":", "\n", "        ", "np_array", "=", "np_array", ".", "transpose", "(", "\n", "axis_order", "[", "0", "]", ",", "axis_order", "[", "3", "]", ",", "axis_order", "[", "2", "]", ",", "axis_order", "[", "1", "]", ")", "\n", "", "return", "np_array", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.normalize_range": [[41, 45], ["img_array.astype", "img_array.max"], "function", ["None"], ["", "def", "normalize_range", "(", "img_array", ",", "max_value", "=", "255.", ")", ":", "\n", "    ", "r\"\"\"Normalize in range [0, 255]\"\"\"", "\n", "img_array", "/=", "(", "img_array", ".", "max", "(", ")", "/", "max_value", ")", "\n", "return", "img_array", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.overlay_images": [[46, 53], ["int", "overlay.putalpha", "PIL.Image.alpha_composite"], "function", ["None"], ["", "def", "overlay_images", "(", "base", ",", "overlay", ",", "alpha", "=", "0.5", ")", ":", "\n", "    ", "r\"\"\"Add transparency to mask, and make composition of image overlayed by \n    transparent mask.\n    \"\"\"", "\n", "alpha", "=", "int", "(", "255", "*", "alpha", ")", "\n", "overlay", ".", "putalpha", "(", "alpha", ")", "\n", "return", "Image", ".", "alpha_composite", "(", "base", ",", "overlay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.stretch_mask_range": [[54, 61], ["mask.astype.max", "mask.astype.astype", "mask.astype.max"], "function", ["None"], ["", "def", "stretch_mask_range", "(", "mask", ")", ":", "\n", "    ", "r\"\"\"Stretches the range of mask values to [0, 255] so that they are \n    differentiable, and converts to RGBA PIL Image.\n    \"\"\"", "\n", "if", "mask", ".", "max", "(", ")", "!=", "0", ":", "\n", "        ", "mask", "*=", "(", "255.0", "/", "mask", ".", "max", "(", ")", ")", "\n", "mask", "=", "mask", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.color_mask": [[69, 83], ["np.stack.astype", "numpy.stack", "segmask_colors.items", "numpy.array"], "function", ["None"], ["def", "color_mask", "(", "mask", ")", ":", "\n", "    ", "r\"\"\"Converts a mask with integer values that are typically < 5 to an RGBA\n    PIL image which each integer is a differentiable color.\n    \"\"\"", "\n", "mask", "=", "mask", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "mask", "=", "np", ".", "stack", "(", "(", "mask", ",", ")", "*", "3", ",", "axis", "=", "-", "1", ")", "\n", "red", ",", "green", ",", "blue", "=", "mask", ".", "T", "\n", "for", "seg_value", ",", "new_color", "in", "segmask_colors", ".", "items", "(", ")", ":", "\n", "        ", "to_replace", "=", "(", "red", "==", "seg_value", ")", "&", "(", "blue", "==", "seg_value", ")", "&", "(", "green", "==", "seg_value", ")", "\n", "red", "[", "to_replace", "]", "=", "new_color", "[", "'red'", "]", "\n", "green", "[", "to_replace", "]", "=", "new_color", "[", "'green'", "]", "\n", "blue", "[", "to_replace", "]", "=", "new_color", "[", "'blue'", "]", "\n", "", "mask", "=", "np", ".", "array", "(", "[", "red", ",", "green", ",", "blue", "]", ")", ".", "T", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.plot_3d_subject_gt": [[86, 91], ["visualize_imgs.plot_3d_segmentation"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.plot_3d_segmentation"], ["", "def", "plot_3d_subject_gt", "(", "subject", ",", "save_path", "=", "None", ")", ":", "\n", "    ", "r\"\"\"Plot a subject with input and ground truth\"\"\"", "\n", "inputs", "=", "subject", "[", "'x'", "]", ".", "data", "\n", "targets", "=", "subject", "[", "'y'", "]", ".", "data", "\n", "plot_3d_segmentation", "(", "inputs", ",", "targets", ",", "save_path", "=", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.plot_3d_subject_pred": [[92, 97], ["visualize_imgs.plot_3d_segmentation"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.plot_3d_segmentation"], ["", "def", "plot_3d_subject_pred", "(", "subject", ",", "pred", ",", "save_path", "=", "None", ")", ":", "\n", "    ", "r\"\"\"Plot a subject with input and prediction\"\"\"", "\n", "inputs", "=", "subject", "[", "'x'", "]", ".", "data", "\n", "assert", "pred", ".", "shape", "==", "subject", "[", "'y'", "]", ".", "data", ".", "shape", ",", "\"Prediction has the wrong size.\"", "\n", "plot_3d_segmentation", "(", "inputs", ",", "pred", ",", "save_path", "=", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.plot_3d_img": [[98, 117], ["visualize_imgs.img_to_numpy_array", "visualize_imgs.ensure_channel_width_height_depth", "numpy.moveaxis", "range", "int", "visualize_imgs.get_img_grid", "visualize_imgs.create_img_grid", "len", "numpy.expand_dims", "len", "imgs.append", "math.ceil", "len", "int", "math.sqrt", "len"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.img_to_numpy_array", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.ensure_channel_width_height_depth", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.get_img_grid", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.create_img_grid"], ["", "def", "plot_3d_img", "(", "img", ",", "save_path", "=", "None", ",", "img_size", "=", "(", "512", ",", "512", ")", ")", ":", "\n", "    ", "r\"\"\"Visualize a 3D image.\"\"\"", "\n", "img", "=", "img_to_numpy_array", "(", "img", ")", "\n", "if", "len", "(", "img", ".", "shape", ")", "==", "3", ":", "\n", "# Add channel dimension", "\n", "        ", "img", "=", "np", ".", "expand_dims", "(", "img", ",", "axis", "=", "0", ")", "\n", "# Ensure (channel, width, height, depth)", "\n", "", "img", "=", "ensure_channel_width_height_depth", "(", "img", ")", "\n", "assert", "len", "(", "img", ".", "shape", ")", "==", "4", "and", "int", "(", "img", ".", "shape", "[", "0", "]", ")", "==", "1", "\n", "# Rotate axis to (depth, 1, width, height) from (1, width, height, depth)", "\n", "img", "=", "np", ".", "moveaxis", "(", "img", ",", "-", "1", ",", "0", ")", "\n", "# Create 2D image list", "\n", "imgs", "=", "[", "]", "\n", "for", "ix", "in", "range", "(", "len", "(", "img", ")", ")", ":", "\n", "        ", "imgs", ".", "append", "(", "img", "[", "ix", "]", ")", "\n", "", "grid_side", "=", "int", "(", "math", ".", "ceil", "(", "math", ".", "sqrt", "(", "len", "(", "imgs", ")", ")", ")", ")", "\n", "img_grid", "=", "get_img_grid", "(", "imgs", ",", "grid_side", ",", "grid_side", ")", "\n", "create_img_grid", "(", "\n", "img_grid", "=", "img_grid", ",", "save_path", "=", "save_path", ",", "img_size", "=", "img_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.plot_3d_segmentation": [[118, 143], ["visualize_imgs.img_to_numpy_array", "visualize_imgs.img_to_numpy_array", "visualize_imgs.ensure_channel_width_height_depth", "visualize_imgs.ensure_channel_width_height_depth", "numpy.moveaxis", "numpy.moveaxis", "range", "int", "visualize_imgs.get_img_grid", "visualize_imgs.create_x_y_grid", "len", "numpy.expand_dims", "numpy.expand_dims", "len", "imgs.append", "math.ceil", "len", "int", "math.sqrt", "len"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.img_to_numpy_array", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.img_to_numpy_array", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.ensure_channel_width_height_depth", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.ensure_channel_width_height_depth", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.get_img_grid", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.create_x_y_grid"], ["", "def", "plot_3d_segmentation", "(", "\n", "img", ",", "segmentation", ",", "save_path", "=", "None", ",", "img_size", "=", "(", "512", ",", "512", ")", ",", "alpha", "=", "0.5", ")", ":", "\n", "    ", "r\"\"\"Visualize a 3D image with coresponding segmentation.\"\"\"", "\n", "img", "=", "img_to_numpy_array", "(", "img", ")", "\n", "segmentation", "=", "img_to_numpy_array", "(", "segmentation", ")", "\n", "assert", "img", ".", "shape", "==", "segmentation", ".", "shape", "\n", "if", "len", "(", "img", ".", "shape", ")", "==", "3", ":", "\n", "# Add channel dimension", "\n", "        ", "img", "=", "np", ".", "expand_dims", "(", "img", ",", "axis", "=", "0", ")", "\n", "segmentation", "=", "np", ".", "expand_dims", "(", "segmentation", ",", "axis", "=", "0", ")", "\n", "# Ensure (channel, width, height, depth)", "\n", "", "img", "=", "ensure_channel_width_height_depth", "(", "img", ")", "\n", "segmentation", "=", "ensure_channel_width_height_depth", "(", "segmentation", ")", "\n", "assert", "len", "(", "img", ".", "shape", ")", "==", "4", "and", "int", "(", "img", ".", "shape", "[", "0", "]", ")", "==", "1", "\n", "# Rotate axis to (depth, 1, width, height) from (1, width, height, depth)", "\n", "img", "=", "np", ".", "moveaxis", "(", "img", ",", "-", "1", ",", "0", ")", "\n", "segmentation", "=", "np", ".", "moveaxis", "(", "segmentation", ",", "-", "1", ",", "0", ")", "\n", "# Create 2D image list", "\n", "imgs", "=", "[", "]", "\n", "for", "ix", "in", "range", "(", "len", "(", "img", ")", ")", ":", "\n", "        ", "imgs", ".", "append", "(", "(", "img", "[", "ix", "]", ",", "segmentation", "[", "ix", "]", ")", ")", "\n", "", "grid_side", "=", "int", "(", "math", ".", "ceil", "(", "math", ".", "sqrt", "(", "len", "(", "imgs", ")", ")", ")", ")", "\n", "img_grid", "=", "get_img_grid", "(", "imgs", ",", "grid_side", ",", "grid_side", ")", "\n", "create_x_y_grid", "(", "\n", "img_grid", "=", "img_grid", ",", "save_path", "=", "save_path", ",", "img_size", "=", "img_size", ",", "alpha", "=", "alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.get_img_grid": [[144, 154], ["range", "random.shuffle", "range", "range", "range", "len"], "function", ["None"], ["", "def", "get_img_grid", "(", "img_list", ",", "nr_rows", ",", "nr_cols", ",", "randomize", "=", "False", ")", ":", "\n", "    ", "r\"\"\"Place list items in a gris format.\"\"\"", "\n", "if", "randomize", ":", "\n", "        ", "random", ".", "shuffle", "(", "img_list", ")", "\n", "", "img_grid", "=", "[", "[", "None", "for", "i", "in", "range", "(", "nr_cols", ")", "]", "for", "j", "in", "range", "(", "nr_rows", ")", "]", "\n", "for", "j", "in", "range", "(", "nr_rows", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "nr_cols", ")", ":", "\n", "            ", "if", "i", "+", "j", "*", "nr_cols", "<", "len", "(", "img_list", ")", ":", "\n", "                ", "img_grid", "[", "j", "]", "[", "i", "]", "=", "img_list", "[", "i", "+", "j", "*", "nr_cols", "]", "\n", "", "", "", "return", "img_grid", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.create_img_grid": [[155, 181], ["PIL.Image.new", "Image.new.show", "Image.new.save", "len", "len", "len", "len", "visualize_imgs.normalize_range", "PIL.Image.fromarray().resize().convert", "Image.new.paste", "numpy.moveaxis", "PIL.Image.fromarray().resize", "numpy.argpartition", "PIL.Image.fromarray"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.normalize_range"], ["", "def", "create_img_grid", "(", "img_grid", "=", "[", "[", "]", "]", ",", "img_size", "=", "(", "512", ",", "512", ")", ",", "\n", "margin", "=", "(", "5", ",", "5", ")", ",", "background_color", "=", "(", "255", ",", "255", ",", "255", ",", "255", ")", ",", "save_path", "=", "None", ")", ":", "\n", "    ", "r\"\"\"Visualize a grid with 2d image slices, overlayed with masks.\"\"\"", "\n", "bg_width", "=", "len", "(", "img_grid", "[", "0", "]", ")", "*", "img_size", "[", "0", "]", "+", "(", "len", "(", "img_grid", "[", "0", "]", ")", "+", "1", ")", "*", "margin", "[", "0", "]", "\n", "bg_height", "=", "len", "(", "img_grid", ")", "*", "img_size", "[", "1", "]", "+", "(", "len", "(", "img_grid", ")", "+", "1", ")", "*", "margin", "[", "1", "]", "\n", "new_img", "=", "Image", ".", "new", "(", "'RGBA'", ",", "(", "bg_width", ",", "bg_height", ")", ",", "background_color", ")", "\n", "left", "=", "margin", "[", "0", "]", "\n", "top", "=", "margin", "[", "1", "]", "\n", "for", "row", "in", "img_grid", ":", "\n", "        ", "for", "img", "in", "row", ":", "\n", "            ", "if", "img", "is", "not", "None", ":", "\n", "                ", "if", "img", ".", "shape", "[", "0", "]", "==", "1", ":", "# Grayscale images", "\n", "                    ", "img", "=", "img", "[", "0", "]", "\n", "", "else", ":", "# Colored images", "\n", "                    ", "if", "np", ".", "argpartition", "(", "img", ".", "shape", ",", "1", ")", "[", "0", "]", "==", "0", ":", "# Channels first", "\n", "                        ", "img", "=", "np", ".", "moveaxis", "(", "img", ",", "0", ",", "2", ")", "\n", "", "", "img", "=", "normalize_range", "(", "img", ")", "\n", "img", "=", "Image", ".", "fromarray", "(", "img", ")", ".", "resize", "(", "img_size", ")", ".", "convert", "(", "'RGBA'", ")", "\n", "new_img", ".", "paste", "(", "img", ",", "(", "left", ",", "top", ")", ")", "\n", "left", "+=", "img_size", "[", "0", "]", "+", "margin", "[", "0", "]", "\n", "", "", "top", "+=", "img_size", "[", "1", "]", "+", "margin", "[", "1", "]", "\n", "left", "=", "margin", "[", "0", "]", "\n", "", "if", "save_path", "is", "None", ":", "\n", "        ", "new_img", ".", "show", "(", ")", "\n", "", "else", ":", "\n", "        ", "new_img", ".", "save", "(", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.create_x_y_grid": [[182, 225], ["PIL.Image.new", "Image.new.show", "Image.new.save", "len", "len", "len", "len", "visualize_imgs.overlay_images", "Image.new.paste", "visualize_imgs.normalize_range", "PIL.Image.fromarray().resize().convert", "visualize_imgs.color_mask", "PIL.Image.fromarray", "PIL.Image.fromarray().resize", "PIL.Image.fromarray().resize().convert", "visualize_imgs.normalize_range", "PIL.Image.fromarray().resize().convert", "PIL.Image.fromarray().resize().convert", "numpy.moveaxis", "numpy.moveaxis", "PIL.Image.fromarray().resize", "PIL.Image.fromarray", "PIL.Image.fromarray().resize", "numpy.argpartition", "PIL.Image.fromarray().resize", "PIL.Image.fromarray().resize", "PIL.Image.fromarray", "PIL.Image.fromarray", "PIL.Image.fromarray", "PIL.Image.fromarray", "np.moveaxis.astype", "np.moveaxis.astype"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.overlay_images", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.normalize_range", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.color_mask", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.normalize_range"], ["", "", "def", "create_x_y_grid", "(", "img_grid", "=", "[", "[", "]", "]", ",", "img_size", "=", "(", "512", ",", "512", ")", ",", "alpha", "=", "0.5", ",", "\n", "margin", "=", "(", "5", ",", "5", ")", ",", "background_color", "=", "(", "255", ",", "255", ",", "255", ",", "255", ")", ",", "save_path", "=", "None", ")", ":", "\n", "    ", "r\"\"\"Visualize a grid with 2d image slices, overlayed with masks.\"\"\"", "\n", "bg_width", "=", "len", "(", "img_grid", "[", "0", "]", ")", "*", "img_size", "[", "0", "]", "+", "(", "len", "(", "img_grid", "[", "0", "]", ")", "+", "1", ")", "*", "margin", "[", "0", "]", "\n", "bg_height", "=", "len", "(", "img_grid", ")", "*", "img_size", "[", "1", "]", "+", "(", "len", "(", "img_grid", ")", "+", "1", ")", "*", "margin", "[", "1", "]", "\n", "new_img", "=", "Image", ".", "new", "(", "'RGBA'", ",", "(", "bg_width", ",", "bg_height", ")", ",", "background_color", ")", "\n", "left", "=", "margin", "[", "0", "]", "\n", "top", "=", "margin", "[", "1", "]", "\n", "for", "row", "in", "img_grid", ":", "\n", "        ", "for", "img_mask_pair", "in", "row", ":", "\n", "            ", "if", "img_mask_pair", "is", "not", "None", ":", "# Is None if grid to large for img nr.", "\n", "                ", "img", ",", "mask", "=", "img_mask_pair", "\n", "if", "img", ".", "shape", "[", "0", "]", "==", "1", ":", "# Grayscale images", "\n", "                    ", "img", "=", "img", "[", "0", "]", "\n", "# Normalize image values between 0 and 255", "\n", "img", "=", "normalize_range", "(", "img", ")", "\n", "img", "=", "Image", ".", "fromarray", "(", "img", ")", ".", "resize", "(", "img_size", ")", ".", "convert", "(", "'RGBA'", ")", "\n", "# Stretch the mask values between 0 and 255", "\n", "mask", "=", "mask", "[", "0", "]", "\n", "mask", "=", "color_mask", "(", "mask", ")", "\n", "Image", ".", "fromarray", "(", "mask", ")", "\n", "Image", ".", "fromarray", "(", "mask", ")", ".", "resize", "(", "img_size", ")", "\n", "mask", "=", "Image", ".", "fromarray", "(", "mask", ")", ".", "resize", "(", "img_size", ")", ".", "convert", "(", "'RGBA'", ")", "\n", "", "else", ":", "# Colored images", "\n", "                    ", "if", "np", ".", "argpartition", "(", "img", ".", "shape", ",", "1", ")", "[", "0", "]", "==", "0", ":", "# If channels first", "\n", "                        ", "img", "=", "np", ".", "moveaxis", "(", "img", ",", "0", ",", "2", ")", "\n", "mask", "=", "np", ".", "moveaxis", "(", "mask", ",", "0", ",", "2", ")", "\n", "", "img", "=", "normalize_range", "(", "img", ")", "\n", "img", "=", "Image", ".", "fromarray", "(", "\n", "(", "img", ")", ".", "astype", "(", "np", ".", "uint8", ")", ")", ".", "resize", "(", "img_size", ")", ".", "convert", "(", "'RGBA'", ")", "\n", "mask", "=", "Image", ".", "fromarray", "(", "\n", "(", "mask", ")", ".", "astype", "(", "np", ".", "uint8", ")", ")", ".", "resize", "(", "img_size", ")", ".", "convert", "(", "'RGBA'", ")", "\n", "# Overlay images", "\n", "", "x_y_img", "=", "overlay_images", "(", "img", ",", "mask", ",", "alpha", "=", "alpha", ")", "\n", "# Paste into original image", "\n", "new_img", ".", "paste", "(", "x_y_img", ",", "(", "left", ",", "top", ")", ")", "\n", "left", "+=", "img_size", "[", "0", "]", "+", "margin", "[", "0", "]", "\n", "", "", "top", "+=", "img_size", "[", "1", "]", "+", "margin", "[", "1", "]", "\n", "left", "=", "margin", "[", "0", "]", "\n", "", "if", "save_path", "is", "None", ":", "\n", "        ", "new_img", ".", "show", "(", ")", "\n", "", "else", ":", "\n", "        ", "new_img", ".", "save", "(", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.visualize_dataloader": [[226, 233], ["visualize_imgs.get_imgs_from_dataloader", "int", "visualize_imgs.get_img_grid", "visualize_imgs.create_img_grid", "math.ceil", "math.sqrt", "len"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.get_imgs_from_dataloader", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.get_img_grid", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.create_img_grid"], ["", "", "def", "visualize_dataloader", "(", "\n", "dataloader", ",", "max_nr_imgs", "=", "100", ",", "save_path", "=", "None", ",", "img_size", "=", "(", "256", ",", "256", ")", ")", ":", "\n", "    ", "r\"\"\"Visualize images (inputs) from dataloader.\"\"\"", "\n", "imgs", "=", "get_imgs_from_dataloader", "(", "dataloader", ",", "max_nr_imgs", ")", "\n", "grid_side", "=", "int", "(", "math", ".", "ceil", "(", "math", ".", "sqrt", "(", "len", "(", "imgs", ")", ")", ")", ")", "\n", "img_grid", "=", "get_img_grid", "(", "imgs", ",", "grid_side", ",", "grid_side", ")", "\n", "create_img_grid", "(", "img_grid", "=", "img_grid", ",", "save_path", "=", "save_path", ",", "img_size", "=", "img_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.get_imgs_from_dataloader": [[234, 245], ["x.cpu().detach().numpy.cpu().detach().numpy", "len", "x.cpu().detach().numpy.cpu().detach", "len", "imgs.append", "x.cpu().detach().numpy.cpu"], "function", ["None"], ["", "def", "get_imgs_from_dataloader", "(", "dataloader", ",", "nr_imgs", ")", ":", "\n", "    ", "r\"\"\"Get images (inputs) from dataloader and place in list.\"\"\"", "\n", "imgs", "=", "[", "]", "\n", "for", "x", ",", "y", "in", "dataloader", ":", "\n", "        ", "x", "=", "x", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "for", "img", "in", "x", ":", "\n", "            ", "if", "len", "(", "imgs", ")", "<", "nr_imgs", ":", "\n", "                ", "imgs", ".", "append", "(", "img", ")", "\n", "", "", "if", "len", "(", "imgs", ")", "==", "nr_imgs", ":", "\n", "            ", "break", "\n", "", "", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.visualize_dataloader_with_masks": [[246, 254], ["visualize_imgs.get_x_y_from_dataloader", "int", "visualize_imgs.get_img_grid", "visualize_imgs.create_x_y_grid", "math.ceil", "math.sqrt", "len"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.get_x_y_from_dataloader", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.get_img_grid", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.create_x_y_grid"], ["", "def", "visualize_dataloader_with_masks", "(", "dataloader", ",", "max_nr_imgs", "=", "100", ",", "save_path", "=", "None", ",", "\n", "img_size", "=", "(", "256", ",", "256", ")", ",", "alpha", "=", "0.5", ")", ":", "\n", "    ", "r\"\"\"Visualize images and masks from dataloader.\"\"\"", "\n", "imgs", "=", "get_x_y_from_dataloader", "(", "dataloader", ",", "max_nr_imgs", ")", "\n", "grid_side", "=", "int", "(", "math", ".", "ceil", "(", "math", ".", "sqrt", "(", "len", "(", "imgs", ")", ")", ")", ")", "\n", "img_grid", "=", "get_img_grid", "(", "imgs", ",", "grid_side", ",", "grid_side", ")", "\n", "create_x_y_grid", "(", "\n", "img_grid", "=", "img_grid", ",", "save_path", "=", "save_path", ",", "img_size", "=", "img_size", ",", "alpha", "=", "alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.get_x_y_from_dataloader": [[255, 282], ["np.concatenate.cpu().detach().numpy", "np.concatenate.cpu().detach().numpy", "enumerate", "mp.data.pytorch.transformation.one_output_channel", "len", "numpy.concatenate", "numpy.concatenate", "len", "len", "np.concatenate.cpu().detach", "np.concatenate.cpu().detach", "numpy.moveaxis", "numpy.moveaxis", "len", "imgs.append", "np.concatenate.cpu", "np.concatenate.cpu"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.one_output_channel"], ["", "def", "get_x_y_from_dataloader", "(", "dataloader", ",", "nr_imgs", ")", ":", "\n", "    ", "r\"\"\"Get images and masks from dataloader and place in list.\"\"\"", "\n", "imgs", "=", "[", "]", "\n", "for", "x", ",", "y", "in", "dataloader", ":", "\n", "        ", "x", "=", "x", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# If one channel per label, transform into one mask", "\n", "if", "y", ".", "shape", "[", "1", "]", ">", "1", ":", "\n", "            ", "y", "=", "one_output_channel", "(", "y", ",", "channel_dim", "=", "1", ")", "\n", "\n", "", "y", "=", "y", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "if", "len", "(", "x", ".", "shape", ")", "==", "5", ":", "# If each x or y is a batch of volumes", "\n", "# Go from shape (batch, 1, width, height, depth) to ", "\n", "# (batch*depth, 1, width, height) by shifting the depth channel to", "\n", "# the beginning and concatenating all volumes.", "\n", "            ", "x_batch", "=", "[", "np", ".", "moveaxis", "(", "volume_x", ",", "-", "1", ",", "0", ")", "for", "volume_x", "in", "x", "]", "\n", "y_batch", "=", "[", "np", ".", "moveaxis", "(", "volume_y", ",", "-", "1", ",", "0", ")", "for", "volume_y", "in", "y", "]", "\n", "x", "=", "np", ".", "concatenate", "(", "x_batch", ")", "\n", "y", "=", "np", ".", "concatenate", "(", "y_batch", ")", "\n", "", "assert", "len", "(", "x", ".", "shape", ")", "==", "4", "\n", "for", "ix", ",", "img", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "if", "len", "(", "imgs", ")", "<", "nr_imgs", ":", "\n", "                ", "imgs", ".", "append", "(", "(", "img", ",", "y", "[", "ix", "]", ")", ")", "\n", "", "", "if", "len", "(", "imgs", ")", "==", "nr_imgs", ":", "\n", "            ", "break", "\n", "", "", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.plot_overlay_mask": [[285, 302], ["matplotlib.figure", "str", "matplotlib.imshow", "matplotlib.axis", "matplotlib.imshow", "matplotlib.axis", "matplotlib.savefig", "matplotlib.show", "type", "img.cpu().detach().numpy", "mask.cpu().detach().numpy", "len", "img.cpu().detach", "mask.cpu().detach", "img.cpu", "mask.cpu"], "function", ["None"], ["", "def", "plot_overlay_mask", "(", "img", ",", "mask", ",", "save_path", "=", "None", ",", "figsize", "=", "(", "20", ",", "20", ")", ")", ":", "\n", "    ", "r\"\"\"\n    Compare two 2d imgs, one on top of the other.\n    TODO: background takes on blue tones.\n    \"\"\"", "\n", "if", "'torch.Tensor'", "in", "str", "(", "type", "(", "img", ")", ")", ":", "\n", "        ", "img", ",", "mask", "=", "img", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", "mask", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "while", "len", "(", "img", ".", "shape", ")", ">", "2", ":", "\n", "            ", "img", ",", "mask", "=", "img", "[", "0", "]", ",", "mask", "[", "0", "]", "\n", "", "", "assert", "img", ".", "shape", "==", "mask", ".", "shape", "\n", "plt", ".", "figure", "(", "figsize", "=", "figsize", ",", "frameon", "=", "False", ")", "\n", "plt", ".", "imshow", "(", "img", ",", "'gray'", ")", ",", "plt", ".", "axis", "(", "'off'", ")", "\n", "plt", ".", "imshow", "(", "mask", ",", "'jet'", ",", "alpha", "=", "0.7", ")", ",", "plt", ".", "axis", "(", "'off'", ")", "\n", "if", "save_path", ":", "\n", "        ", "plt", ".", "savefig", "(", "save_path", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.plot_2d_img": [[303, 320], ["matplotlib.figure", "str", "np.moveaxis.cpu().detach().numpy", "len", "matplotlib.imshow", "matplotlib.axis", "matplotlib.savefig", "matplotlib.show", "type", "numpy.moveaxis", "np.moveaxis.cpu().detach", "numpy.argpartition", "np.moveaxis.cpu"], "function", ["None"], ["", "", "def", "plot_2d_img", "(", "img", ",", "save_path", "=", "None", ",", "figsize", "=", "(", "20", ",", "20", ")", ")", ":", "\n", "    ", "r\"\"\"Plot a 2d image\"\"\"", "\n", "if", "'torch.Tensor'", "in", "str", "(", "type", "(", "img", ")", ")", ":", "\n", "        ", "img", "=", "img", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "", "while", "img", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "        ", "img", "=", "img", "[", "0", "]", "\n", "", "if", "len", "(", "img", ".", "shape", ")", "==", "3", ":", "\n", "# If channels first, rotate so channels last", "\n", "        ", "if", "np", ".", "argpartition", "(", "img", ".", "shape", ",", "1", ")", "[", "0", "]", "==", "0", ":", "\n", "            ", "img", "=", "np", ".", "moveaxis", "(", "img", ",", "0", ",", "2", ")", "\n", "# Plot", "\n", "", "", "plt", ".", "figure", "(", "figsize", "=", "figsize", ",", "frameon", "=", "False", ")", "\n", "plt", ".", "imshow", "(", "img", ")", ",", "plt", ".", "axis", "(", "'off'", ")", "\n", "if", "save_path", ":", "\n", "        ", "plt", ".", "savefig", "(", "save_path", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "show", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.model_state_restore.test_restore_model_state_and_eval": [[9, 50], ["mp.data.datasets.ds_mr_prostate_decathlon.DecathlonProstateT2", "dict", "mp.data.pytorch.pytorch_seg_dataset.PytorchSeg2DDataset", "mp.data.pytorch.pytorch_seg_dataset.PytorchSeg2DDataset", "mp.data.pytorch.pytorch_seg_dataset.PytorchSeg2DDataset", "torch.utils.data.DataLoader", "mp.models.segmentation.unet_fepegar.UNet2D", "mp.agents.segmentation_agent.SegmentationAgent", "mp.agents.segmentation_agent.SegmentationAgent.restore_state", "mp.eval.losses.losses_segmentation.LossDice", "mp.eval.losses.losses_segmentation.LossClassWeighted", "mp.eval.evaluate.ds_losses_metrics", "test_target_dict.items", "metric_dict.items", "abs"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.ExperimentRun.restore_state", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.ds_losses_metrics"], ["def", "test_restore_model_state_and_eval", "(", ")", ":", "\n", "    ", "device", "=", "'cpu'", "\n", "\n", "# Fetch data", "\n", "data", "=", "DecathlonProstateT2", "(", ")", "\n", "label_names", "=", "data", ".", "label_names", "\n", "nr_labels", "=", "data", ".", "nr_labels", "\n", "\n", "# Transform data to PyTorch format and build train dataloader", "\n", "input_shape", "=", "(", "1", ",", "256", ",", "256", ")", "\n", "datasets", "=", "dict", "(", ")", "\n", "datasets", "[", "'train'", "]", "=", "PytorchSeg2DDataset", "(", "data", ",", "ix_lst", "=", "[", "0", "]", ",", "size", "=", "input_shape", ",", "aug_key", "=", "'none'", ",", "resize", "=", "False", ")", "\n", "datasets", "[", "'mixed'", "]", "=", "PytorchSeg2DDataset", "(", "data", ",", "ix_lst", "=", "[", "0", ",", "1", "]", ",", "size", "=", "input_shape", ",", "aug_key", "=", "'none'", ",", "resize", "=", "False", ")", "\n", "datasets", "[", "'test'", "]", "=", "PytorchSeg2DDataset", "(", "data", ",", "ix_lst", "=", "[", "1", "]", ",", "size", "=", "input_shape", ",", "aug_key", "=", "'none'", ",", "resize", "=", "False", ")", "\n", "dl", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "datasets", "[", "'train'", "]", ",", "batch_size", "=", "8", ",", "shuffle", "=", "False", ")", "\n", "\n", "# Build model", "\n", "model", "=", "UNet2D", "(", "input_shape", ",", "nr_labels", ")", "\n", "\n", "# Define agent", "\n", "agent", "=", "SegmentationAgent", "(", "model", "=", "model", ",", "label_names", "=", "label_names", ",", "device", "=", "device", ",", "\n", "metrics", "=", "[", "'ScoreDice'", "]", ")", "\n", "\n", "# Restore model state", "\n", "agent", ".", "restore_state", "(", "states_path", "=", "'test/test_obj/agent_states_prostate_2D'", ",", "state_name", "=", "\"epoch_300\"", ")", "\n", "\n", "# Calculate metrics and compare", "\n", "loss_g", "=", "LossDice", "(", "1e-05", ")", "\n", "loss_f", "=", "LossClassWeighted", "(", "loss", "=", "loss_g", ",", "weights", "=", "(", "1.", ",", "1.", ")", ",", "device", "=", "device", ")", "\n", "eval_dict", "=", "ds_losses_metrics", "(", "datasets", "[", "'mixed'", "]", ",", "agent", ",", "loss_f", ",", "metrics", "=", "[", "'ScoreDice'", "]", ")", "\n", "\n", "test_target_dict", "=", "{", "'ScoreDice'", ":", "{", "'prostate00'", ":", "0.9280484305139076", ",", "'prostate01'", ":", "0.5375613582619043", ",", "'mean'", ":", "0.732804894387906", ",", "'std'", ":", "0.19524353612600165", "}", ",", "\n", "'ScoreDice[background]'", ":", "{", "'prostate00'", ":", "0.996721191337123", ",", "'prostate01'", ":", "0.9785040545630738", ",", "'mean'", ":", "0.9876126229500983", ",", "'std'", ":", "0.009108568387024618", "}", ",", "\n", "'ScoreDice[prostate]'", ":", "{", "'prostate00'", ":", "0.8593756696906922", ",", "'prostate01'", ":", "0.09661866196073488", ",", "'mean'", ":", "0.47799716582571355", ",", "'std'", ":", "0.3813785038649787", "}", ",", "\n", "'Loss_LossClassWeighted[loss=LossDice[smooth=1e-05]; weights=(1.0, 1.0)]'", ":", "{", "'prostate00'", ":", "0.10226414799690246", ",", "'prostate01'", ":", "0.4694981321692467", ",", "'mean'", ":", "0.2858811400830746", ",", "'std'", ":", "0.1836169920861721", "}", ",", "\n", "'Loss_LossDice[smooth=1e-05][0]'", ":", "{", "'prostate00'", ":", "0.005160685380299886", ",", "'prostate01'", ":", "0.03430714905261993", ",", "'mean'", ":", "0.01973391721645991", ",", "'std'", ":", "0.014573231836160022", "}", ",", "\n", "'Loss_LossDice[smooth=1e-05][1]'", ":", "{", "'prostate00'", ":", "0.19936761061350505", ",", "'prostate01'", ":", "0.9046891242265701", ",", "'mean'", ":", "0.5520283674200376", ",", "'std'", ":", "0.3526607568065325", "}", "}", "\n", "\n", "for", "metric_key", ",", "metric_dict", "in", "test_target_dict", ".", "items", "(", ")", ":", "\n", "        ", "for", "key", ",", "value", "in", "metric_dict", ".", "items", "(", ")", ":", "\n", "            ", "assert", "abs", "(", "value", "-", "eval_dict", "[", "metric_key", "]", "[", "key", "]", ")", "<", "0.01", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.unet_agent.UNETAgent.__init__": [[20, 24], ["mp.agents.segmentation_agent.SegmentationAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "'metrics'", "not", "in", "kwargs", ":", "\n", "            ", "kwargs", "[", "'metrics'", "]", "=", "[", "'ScoreDice'", ",", "'ScoreIoU'", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.unet_agent.UNETAgent.train": [[25, 80], ["dict", "range", "unet_agent.UNETAgent.track_metrics", "unet_agent.UNETAgent.perform_training_epoch", "unet_agent.UNETAgent.model.unet_scheduler.step", "unet_agent.UNETAgent.track_loss", "unet_agent.UNETAgent.track_visualization", "unet_agent.UNETAgent.track_visualization", "unet_agent.UNETAgent.save_state"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.track_metrics", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.perform_training_epoch", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.track_loss", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.track_visualization", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.track_visualization", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.ExperimentRun.save_state"], ["", "def", "train", "(", "self", ",", "results", ",", "loss_f", ",", "train_dataloader", ",", "test_dataloader", ",", "config", ",", "\n", "init_epoch", "=", "0", ",", "nr_epochs", "=", "100", ",", "run_loss_print_interval", "=", "1", ",", "\n", "eval_datasets", "=", "dict", "(", ")", ",", "eval_interval", "=", "2", ",", "\n", "save_path", "=", "None", ",", "save_interval", "=", "10", ",", "\n", "display_interval", "=", "1", ",", "\n", "resume_epoch", "=", "None", ",", "\n", "device_ids", "=", "[", "0", "]", ")", ":", "\n", "        ", "r\"\"\"Train a model through its agent. Performs training epochs, \n        tracks metrics and saves model states.\n\n        Args:\n            results (mp.eval.result.Result): results object to track progress\n            loss_f (mp.eval.losses.loss_abstract.LossAbstract): loss function for the segmenter\n            train_dataloader (torch.utils.data.DataLoader): dataloader of training set\n            test_dataloader (torch.utils.data.DataLoader): dataloader of test set\n            eval_datasets (torch.utils.data.DataLoader): dataloader of evaluation set\n            config (dict): configuration dictionary from parsed arguments\n            init_epoch (int): initial epoch\n            nr_epochs (int): number of epochs to train for\n            run_loss_print_interval (int) print loss every # epochs\n            eval_interval (int): evaluate model every # epochs\n            save_interval (int): save model every # epochs\n            save_path (str): save path for saving model, etc.\n            display_interval (str): log tensorboard every # epochs\n            resume_epoch (int): resume training at epoch #\n            device_ids (list) device ids of GPUs\n        \"\"\"", "\n", "\n", "self", ".", "agent_state_dict", "[", "'epoch'", "]", "=", "init_epoch", "\n", "\n", "for", "epoch", "in", "range", "(", "init_epoch", ",", "nr_epochs", ")", ":", "\n", "            ", "self", ".", "agent_state_dict", "[", "'epoch'", "]", "=", "epoch", "\n", "\n", "print_run_loss", "=", "(", "epoch", "+", "1", ")", "%", "run_loss_print_interval", "==", "0", "\n", "print_run_loss", "=", "print_run_loss", "and", "self", ".", "verbose", "\n", "acc", "=", "self", ".", "perform_training_epoch", "(", "loss_f", ",", "train_dataloader", ",", "config", ",", "\n", "print_run_loss", "=", "print_run_loss", ")", "\n", "\n", "if", "config", "[", "'continual'", "]", ":", "\n", "                ", "self", ".", "model", ".", "unet_scheduler", ".", "step", "(", ")", "\n", "\n", "# Write losses to tensorboard", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "display_interval", "==", "0", ":", "\n", "                ", "self", ".", "track_loss", "(", "acc", ",", "epoch", "+", "1", ",", "config", ")", "\n", "\n", "# Create visualizations and write them to tensorboard", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "display_interval", "==", "0", ":", "\n", "                ", "self", ".", "track_visualization", "(", "train_dataloader", ",", "save_path", ",", "epoch", "+", "1", ",", "config", ",", "'train'", ")", "\n", "self", ".", "track_visualization", "(", "test_dataloader", ",", "save_path", ",", "epoch", "+", "1", ",", "config", ",", "'test'", ")", "\n", "\n", "# Save agent and optimizer state", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "save_interval", "==", "0", "and", "save_path", "is", "not", "None", ":", "\n", "                ", "self", ".", "save_state", "(", "save_path", ",", "epoch", "+", "1", ")", "\n", "\n", "", "", "self", ".", "track_metrics", "(", "epoch", "+", "1", ",", "results", ",", "loss_f", ",", "eval_datasets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.unet_agent.UNETAgent.perform_training_epoch": [[82, 123], ["mp.eval.accumulator.Accumulator", "time.time", "tqdm.tqdm.tqdm", "unet_agent.UNETAgent.get_inputs_targets", "unet_agent.UNETAgent.get_outputs", "unet_agent.UNETAgent.model.unet_optim.zero_grad", "loss_f", "loss.backward", "unet_agent.UNETAgent.model.unet_optim.step", "mp.eval.accumulator.Accumulator.add", "mp.eval.accumulator.Accumulator.add", "print", "float", "float", "loss.detach().cpu", "len", "loss_f.detach().cpu", "len", "mp.eval.accumulator.Accumulator.mean", "round", "loss.detach", "loss_f.detach", "time.time"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.get_inputs_targets", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.get_outputs", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean"], ["", "def", "perform_training_epoch", "(", "self", ",", "loss_f", ",", "train_dataloader", ",", "config", ",", "\n", "print_run_loss", "=", "False", ")", ":", "\n", "        ", "r\"\"\"Perform a training epoch\n        \n        Args:\n            loss_f (mp.eval.losses.loss_abstract.LossAbstract): loss function for the segmenter\n            train_dataloader (torch.utils.data.DataLoader): dataloader of training set\n            config (dict): configuration dictionary from parsed arguments\n            print_run_loss (boolean): whether to print running loss\n        \n        Returns:\n            acc (mp.eval.accumulator.Accumulator): accumulator holding losses\n        \"\"\"", "\n", "acc", "=", "Accumulator", "(", "'loss'", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "data", "in", "tqdm", "(", "train_dataloader", ",", "disable", "=", "True", ")", ":", "\n", "# Get data", "\n", "            ", "inputs", ",", "targets", "=", "self", ".", "get_inputs_targets", "(", "data", ")", "\n", "\n", "# Forward pass", "\n", "outputs", "=", "self", ".", "get_outputs", "(", "inputs", ")", "\n", "\n", "# Optimization step", "\n", "self", ".", "model", ".", "unet_optim", ".", "zero_grad", "(", ")", "\n", "\n", "loss_seg", "=", "loss_f", "(", "outputs", ",", "targets", ")", "\n", "\n", "loss", "=", "loss_seg", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "self", ".", "model", ".", "unet_optim", ".", "step", "(", ")", "\n", "\n", "acc", ".", "add", "(", "'loss'", ",", "float", "(", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "inputs", ")", ")", "\n", "acc", ".", "add", "(", "'loss_seg'", ",", "float", "(", "loss_seg", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "inputs", ")", ")", "\n", "\n", "", "if", "print_run_loss", ":", "\n", "            ", "print", "(", "'\\nrunning loss: {} - time/epoch {}'", ".", "format", "(", "acc", ".", "mean", "(", "'loss'", ")", ",", "round", "(", "time", ".", "time", "(", ")", "-", "start_time", ",", "4", ")", ")", ")", "\n", "\n", "", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.unet_agent.UNETAgent.get_inputs_targets": [[124, 136], ["inputs.to", "targets.to", "targets.float"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to"], ["", "def", "get_inputs_targets", "(", "self", ",", "data", ",", "eval", "=", "True", ")", ":", "\n", "        ", "r\"\"\"Prepares a data batch.\n\n        Args:\n            data (tuple): a dataloader item, possibly in cpu\n            eval (boolean): evaluation mode, doesn't return domain code \n            \n        Returns (tuple): preprocessed data in the selected device.\n        \"\"\"", "\n", "inputs", ",", "targets", "=", "data", "\n", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "self", ".", "device", ")", ",", "targets", ".", "to", "(", "self", ".", "device", ")", "\n", "return", "inputs", ",", "targets", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.unet_agent.UNETAgent.track_metrics": [[137, 159], ["datasets.items", "mp.eval.evaluate.ds_losses_metrics", "mp.eval.evaluate.ds_losses_metrics.keys", "results.add", "results.add", "print", "mp.eval.evaluate.ds_losses_metrics.keys", "unet_agent.UNETAgent.writer_add_scalar", "print"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.ds_losses_metrics", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar"], ["", "def", "track_metrics", "(", "self", ",", "epoch", ",", "results", ",", "loss_f", ",", "datasets", ")", ":", "\n", "        ", "r\"\"\"Tracks metrics. Losses and scores are calculated for each 3D subject, \n        and averaged over the dataset.\n\n        Args:\n            epoch (int):current epoch\n            results (mp.eval.result.Result): results object to track progress\n            loss_f (mp.eval.losses.loss_abstract.LossAbstract): loss function for the segmenter\n            datasets (torch.utils.data.DataLoader): dataloader object to evaluate on\n        \"\"\"", "\n", "for", "ds_name", ",", "ds", "in", "datasets", ".", "items", "(", ")", ":", "\n", "            ", "eval_dict", "=", "ds_losses_metrics", "(", "ds", ",", "self", ",", "loss_f", ",", "self", ".", "metrics", ")", "\n", "for", "metric_key", "in", "eval_dict", ".", "keys", "(", ")", ":", "\n", "                ", "results", ".", "add", "(", "epoch", "=", "epoch", ",", "metric", "=", "'Mean_'", "+", "metric_key", ",", "data", "=", "ds_name", ",", "\n", "value", "=", "eval_dict", "[", "metric_key", "]", "[", "'mean'", "]", ")", "\n", "results", ".", "add", "(", "epoch", "=", "epoch", ",", "metric", "=", "'Std_'", "+", "metric_key", ",", "data", "=", "ds_name", ",", "\n", "value", "=", "eval_dict", "[", "metric_key", "]", "[", "'std'", "]", ")", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "'Epoch {} dataset {}'", ".", "format", "(", "epoch", ",", "ds_name", ")", ")", "\n", "for", "metric_key", "in", "eval_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "self", ".", "writer_add_scalar", "(", "f'metric/{metric_key}/{ds_name}'", ",", "eval_dict", "[", "metric_key", "]", "[", "'mean'", "]", ",", "epoch", ")", "\n", "print", "(", "'{}: {}'", ".", "format", "(", "metric_key", ",", "eval_dict", "[", "metric_key", "]", "[", "'mean'", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.unet_agent.UNETAgent.track_loss": [[160, 172], ["unet_agent.UNETAgent.writer_add_scalar", "unet_agent.UNETAgent.writer_add_scalar", "acc.mean", "acc.mean"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean"], ["", "", "", "", "def", "track_loss", "(", "self", ",", "acc", ",", "epoch", ",", "config", ",", "phase", "=", "'train'", ")", ":", "\n", "        ", "r\"\"\"Tracks loss in tensorboard.\n\n        Args:\n            acc (mp.eval.accumulator.Accumulator): accumulator holding losses\n            epoch (int): current epoch\n            config (dict): configuration dictionary from parsed arguments\n            phase (string): either \"test\" or \"train\"\n        \"\"\"", "\n", "\n", "self", ".", "writer_add_scalar", "(", "f'loss_{phase}/loss_seg'", ",", "acc", ".", "mean", "(", "'loss_seg'", ")", ",", "epoch", ")", "\n", "self", ".", "writer_add_scalar", "(", "f'loss_{phase}/loss_comb'", ",", "acc", ".", "mean", "(", "'loss'", ")", ",", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.unet_agent.UNETAgent.track_visualization": [[173, 219], ["enumerate", "x_i[].unsqueeze", "[].unsqueeze().unsqueeze", "[].unsqueeze().unsqueeze().int", "os.path.join", "os.path.join", "os.path.join", "mp.visualization.visualize_imgs.plot_3d_segmentation", "mp.visualization.visualize_imgs.plot_3d_segmentation", "PIL.Image.open", "torchvision.to_tensor", "unet_agent.UNETAgent.writer_add_image", "PIL.Image.open", "torchvision.to_tensor", "unet_agent.UNETAgent.writer_add_image", "unet_agent.UNETAgent.get_inputs_targets", "unet_agent.UNETAgent.get_outputs", "os.path.exists", "os.makedirs", "len", "[].unsqueeze", "[].unsqueeze().unsqueeze", "torch.nonzero", "[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.plot_3d_segmentation", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.plot_3d_segmentation", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_image", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_image", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.get_inputs_targets", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.get_outputs"], ["", "def", "track_visualization", "(", "self", ",", "dataloader", ",", "save_path", ",", "epoch", ",", "config", ",", "phase", "=", "'train'", ")", ":", "\n", "        ", "r\"\"\"Creates visualizations and tracks them in tensorboard.\n\n        Args:\n            dataloader (Dataloader): dataloader to draw sample from\n            save_path (string): path for the images to be saved (one folder up)\n            epoch (int): current epoch\n            config (dict): configuration dictionary from parsed arguments\n            phase (string): either \"test\" or \"train\"\n        \"\"\"", "\n", "for", "imgs", "in", "dataloader", ":", "\n", "            ", "x_i", ",", "y_i", "=", "self", ".", "get_inputs_targets", "(", "imgs", ",", "eval", "=", "False", ")", "\n", "x_i_seg", "=", "self", ".", "get_outputs", "(", "x_i", ")", "\n", "break", "\n", "\n", "# select sample with guaranteed segmentation label", "\n", "", "sample_idx", "=", "0", "\n", "for", "i", ",", "y_", "in", "enumerate", "(", "y_i", ")", ":", "\n", "            ", "if", "len", "(", "torch", ".", "nonzero", "(", "y_", "[", "1", "]", ")", ")", ">", "0", ":", "\n", "                ", "sample_idx", "=", "i", "\n", "break", "\n", "", "", "x_i_img", "=", "x_i", "[", "sample_idx", "]", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "# segmentation", "\n", "x_i_seg", "=", "x_i_seg", "[", "sample_idx", "]", "[", "1", "]", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "threshold", "=", "0.5", "\n", "x_i_seg_mask", "=", "(", "x_i_seg", ">", "threshold", ")", ".", "int", "(", ")", "\n", "y_i_seg_mask", "=", "y_i", "[", "sample_idx", "]", "[", "1", "]", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "int", "(", ")", "\n", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "'..'", ",", "'imgs'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "save_path", ")", "\n", "\n", "", "save_path_pred", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "f'e_{epoch:06d}_{phase}_pred.png'", ")", "\n", "save_path_label", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "f'e_{epoch:06d}_{phase}_label.png'", ")", "\n", "\n", "plot_3d_segmentation", "(", "x_i_img", ",", "x_i_seg_mask", ",", "save_path", "=", "save_path_pred", ",", "img_size", "=", "(", "256", ",", "256", ")", ",", "alpha", "=", "0.5", ")", "\n", "plot_3d_segmentation", "(", "x_i_img", ",", "y_i_seg_mask", ",", "save_path", "=", "save_path_label", ",", "img_size", "=", "(", "256", ",", "256", ")", ",", "alpha", "=", "0.5", ")", "\n", "\n", "image", "=", "Image", ".", "open", "(", "save_path_pred", ")", "\n", "image", "=", "TF", ".", "to_tensor", "(", "image", ")", "\n", "self", ".", "writer_add_image", "(", "f'imgs_{phase}/pred'", ",", "image", ",", "epoch", ")", "\n", "\n", "image", "=", "Image", ".", "open", "(", "save_path_label", ")", "\n", "image", "=", "TF", ".", "to_tensor", "(", "image", ")", "\n", "self", ".", "writer_add_image", "(", "f'imgs_{phase}/label'", ",", "image", ",", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.unet_agent.UNETAgent.save_state": [[220, 239], ["os.path.join", "os.path.exists", "os.makedirs", "mp.utils.pytorch.pytorch_load_restore.save_model_state_dataparallel", "mp.utils.load_restore.pkl_dump", "shutil.rmtree"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.save_model_state_dataparallel", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.pkl_dump"], ["", "def", "save_state", "(", "self", ",", "states_path", ",", "epoch", ",", "optimizer", "=", "None", ",", "overwrite", "=", "False", ")", ":", "\n", "        ", "r\"\"\"Saves an agent state. Raises an error if the directory exists and \n        overwrite=False.\n\n        Args:\n            states_path (str): save path for model states\n            epoch (int): current epoch\n            overwrite (boolean): whether to override existing files\n        \"\"\"", "\n", "if", "states_path", "is", "not", "None", ":", "\n", "            ", "state_name", "=", "f'epoch_{epoch:04d}'", "\n", "state_full_path", "=", "os", ".", "path", ".", "join", "(", "states_path", ",", "state_name", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "state_full_path", ")", ":", "\n", "                ", "if", "not", "overwrite", ":", "\n", "                    ", "raise", "FileExistsError", "\n", "", "shutil", ".", "rmtree", "(", "state_full_path", ")", "\n", "", "os", ".", "makedirs", "(", "state_full_path", ")", "\n", "save_model_state_dataparallel", "(", "self", ".", "model", ",", "'model'", ",", "state_full_path", ")", "\n", "pkl_dump", "(", "self", ".", "agent_state_dict", ",", "'agent_state_dict'", ",", "state_full_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.unet_agent.UNETAgent.restore_state": [[240, 267], ["os.path.join", "mp.utils.pytorch.pytorch_load_restore.load_model_state", "mp.utils.load_restore.pkl_load", "os.listdir", "print", "print"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.load_model_state", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.pkl_load"], ["", "", "def", "restore_state", "(", "self", ",", "states_path", ",", "epoch", ",", "optimizer", "=", "None", ")", ":", "\n", "        ", "r\"\"\"Tries to restore a previous agent state, consisting of a model \n        state and the content of agent_state_dict. Returns whether the restore \n        operation  was successful.\n        Args:\n            states_path (str): save path for model states\n            epoch (int): current epoch\n        \"\"\"", "\n", "\n", "if", "epoch", "==", "-", "1", ":", "\n", "            ", "state_name", "=", "os", ".", "listdir", "(", "states_path", ")", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "state_name", "=", "f'epoch_{epoch:04d}'", "\n", "\n", "", "state_full_path", "=", "os", ".", "path", ".", "join", "(", "states_path", ",", "state_name", ")", "\n", "try", ":", "\n", "            ", "correct_load", "=", "load_model_state", "(", "self", ".", "model", ",", "'model'", ",", "state_full_path", ",", "device", "=", "self", ".", "device", ")", "\n", "assert", "correct_load", "\n", "agent_state_dict", "=", "pkl_load", "(", "'agent_state_dict'", ",", "state_full_path", ")", "\n", "assert", "agent_state_dict", "is", "not", "None", "\n", "self", ".", "agent_state_dict", "=", "agent_state_dict", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "'State {} was restored'", ".", "format", "(", "state_name", ")", ")", "\n", "", "return", "True", "\n", "", "except", ":", "\n", "            ", "print", "(", "'State {} could not be restored'", ".", "format", "(", "state_name", ")", ")", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.unet_agent.UNETAgent.multi_class_cross_entropy_no_softmax": [[268, 279], ["torch.log"], "methods", ["None"], ["", "", "def", "multi_class_cross_entropy_no_softmax", "(", "self", ",", "prediction", ",", "target", ")", ":", "\n", "        ", "r\"\"\"Stable Multiclass Cross Entropy with Softmax\n\n        Args:\n            prediction (torch.Tensor): network outputs w/ softmax\n            target (torch.Tensor): label OHE\n\n        Returns:\n            (torch.Tensor) computed loss \n        \"\"\"", "\n", "return", "(", "-", "(", "target", "*", "torch", ".", "log", "(", "prediction", ")", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.unet_agent.UNETAgent.get_outputs_old": [[280, 293], ["unet_agent.UNETAgent.model.forward_old", "mp.eval.inference.predict.softmax().clamp", "mp.eval.inference.predict.softmax"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.kd.KD.forward_old", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predict.softmax"], ["", "def", "get_outputs_old", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "r\"\"\"Stable Multiclass Cross Entropy with Softmax\n\n        Args:\n            prediction (torch.Tensor): network outputs w/ softmax\n            target (torch.Tensor): label OHE\n\n        Returns:\n            (torch.Tensor) computed loss \n        \"\"\"", "\n", "outputs", "=", "self", ".", "model", ".", "forward_old", "(", "inputs", ")", "\n", "outputs", "=", "softmax", "(", "outputs", ")", ".", "clamp", "(", "min", "=", "1e-08", ",", "max", "=", "1.", "-", "1e-08", ")", "\n", "return", "outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.segmentation_agent.SegmentationAgent.__init__": [[10, 14], ["mp.agents.agent.Agent.__init__"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "'metrics'", "not", "in", "kwargs", ":", "\n", "            ", "kwargs", "[", "'metrics'", "]", "=", "[", "'ScoreDice'", ",", "'ScoreIoU'", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.segmentation_agent.SegmentationAgent.get_outputs": [[15, 20], ["segmentation_agent.SegmentationAgent.model", "mp.eval.inference.predict.softmax().clamp", "mp.eval.inference.predict.softmax"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predict.softmax"], ["", "def", "get_outputs", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "r\"\"\"Applies a softmax transformation to the model outputs\"\"\"", "\n", "outputs", "=", "self", ".", "model", "(", "inputs", ")", "\n", "outputs", "=", "softmax", "(", "outputs", ")", ".", "clamp", "(", "min", "=", "1e-08", ",", "max", "=", "1.", "-", "1e-08", ")", "\n", "return", "outputs", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.__init__": [[29, 40], ["dict", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model", ",", "label_names", "=", "None", ",", "metrics", "=", "[", "]", ",", "device", "=", "'cuda:0'", ",", "\n", "scores_label_weights", "=", "None", ",", "verbose", "=", "True", ",", "summary_writer", "=", "None", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "metrics", "=", "metrics", "\n", "self", ".", "label_names", "=", "label_names", "\n", "self", ".", "nr_labels", "=", "len", "(", "label_names", ")", "if", "self", ".", "label_names", "else", "0", "\n", "self", ".", "scores_label_weights", "=", "scores_label_weights", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "agent_state_dict", "=", "dict", "(", ")", "\n", "self", ".", "summary_writer", "=", "summary_writer", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.get_inputs_targets": [[41, 53], ["agent.Agent.model.preprocess_input", "agent.Agent.to", "targets.to", "targets.float"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_linear.AutoencoderLinear.preprocess_input", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to"], ["", "def", "get_inputs_targets", "(", "self", ",", "data", ")", ":", "\n", "        ", "r\"\"\"Prepares a data batch.\n\n        Args:\n            data (tuple): a dataloader item, possibly in cpu\n\n        Returns (tuple): preprocessed data in the selected device.\n        \"\"\"", "\n", "inputs", ",", "targets", "=", "data", "\n", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "self", ".", "device", ")", ",", "targets", ".", "to", "(", "self", ".", "device", ")", "\n", "inputs", "=", "self", ".", "model", ".", "preprocess_input", "(", "inputs", ")", "\n", "return", "inputs", ",", "targets", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.get_outputs": [[54, 63], ["agent.Agent.model"], "methods", ["None"], ["", "def", "get_outputs", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "r\"\"\"Returns model outputs.\n        Args:\n            data (torch.tensor): inputs\n\n        Returns (torch.tensor): model outputs, with one channel dimension per \n            label.\n        \"\"\"", "\n", "return", "self", ".", "model", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.predict_from_outputs": [[64, 74], ["mp.eval.inference.predict.arg_max"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predict.arg_max"], ["", "def", "predict_from_outputs", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "r\"\"\"Returns argmaxed outputs.\n\n        Args:\n            data (torch.tensor): model outputs, with one channel dimension per \n            label.\n\n        Returns (torch.tensor): a one-channeled prediction.\n        \"\"\"", "\n", "return", "arg_max", "(", "outputs", ",", "channel_dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.predict": [[75, 84], ["agent.Agent.get_outputs", "agent.Agent.predict_from_outputs"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.get_outputs", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.autoencoding_agent.AutoencodingAgent.predict_from_outputs"], ["", "def", "predict", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "r\"\"\"Returns model outputs.\n        Args:\n            data (torch.tensor): inputs\n\n        Returns (torch.tensor): a one-channeled prediction.\n        \"\"\"", "\n", "outputs", "=", "self", ".", "get_outputs", "(", "inputs", ")", "\n", "return", "self", ".", "predict_from_outputs", "(", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.perform_training_epoch": [[85, 110], ["mp.eval.accumulator.Accumulator", "agent.Agent.get_inputs_targets", "agent.Agent.get_outputs", "optimizer.zero_grad", "loss_f", "loss_f.backward", "optimizer.step", "mp.eval.accumulator.Accumulator.add", "print", "float", "loss_f.detach().cpu", "len", "mp.eval.accumulator.Accumulator.mean", "loss_f.detach"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.get_inputs_targets", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.get_outputs", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean"], ["", "def", "perform_training_epoch", "(", "self", ",", "optimizer", ",", "loss_f", ",", "train_dataloader", ",", "\n", "print_run_loss", "=", "False", ")", ":", "\n", "        ", "r\"\"\"Perform a training epoch\n        \n        Args:\n            print_run_loss (bool): whether a runing loss should be tracked and\n                printed.\n        \"\"\"", "\n", "acc", "=", "Accumulator", "(", "'loss'", ")", "\n", "for", "data", "in", "train_dataloader", ":", "\n", "# Get data", "\n", "            ", "inputs", ",", "targets", "=", "self", ".", "get_inputs_targets", "(", "data", ")", "\n", "\n", "# Forward pass", "\n", "outputs", "=", "self", ".", "get_outputs", "(", "inputs", ")", "\n", "\n", "# Optimization step", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", "=", "loss_f", "(", "outputs", ",", "targets", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "acc", ".", "add", "(", "'loss'", ",", "float", "(", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "inputs", ")", ")", "\n", "\n", "", "if", "print_run_loss", ":", "\n", "            ", "print", "(", "'\\nRunning loss: {}'", ".", "format", "(", "acc", ".", "mean", "(", "'loss'", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.train": [[111, 136], ["dict", "range", "agent.Agent.track_metrics", "agent.Agent.perform_training_epoch", "agent.Agent.track_metrics", "agent.Agent.save_state"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.track_metrics", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.perform_training_epoch", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.track_metrics", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.ExperimentRun.save_state"], ["", "", "def", "train", "(", "self", ",", "results", ",", "optimizer", ",", "loss_f", ",", "train_dataloader", ",", "\n", "init_epoch", "=", "0", ",", "nr_epochs", "=", "100", ",", "run_loss_print_interval", "=", "10", ",", "\n", "eval_datasets", "=", "dict", "(", ")", ",", "eval_interval", "=", "10", ",", "\n", "save_path", "=", "None", ",", "save_interval", "=", "10", ")", ":", "\n", "        ", "r\"\"\"Train a model through its agent. Performs training epochs, \n        tracks metrics and saves model states.\n        \"\"\"", "\n", "\n", "if", "init_epoch", "==", "0", ":", "\n", "            ", "self", ".", "track_metrics", "(", "init_epoch", ",", "results", ",", "loss_f", ",", "eval_datasets", ")", "\n", "\n", "", "for", "epoch", "in", "range", "(", "init_epoch", ",", "init_epoch", "+", "nr_epochs", ")", ":", "\n", "            ", "self", ".", "current_epoch", "=", "epoch", "\n", "print_run_loss", "=", "(", "epoch", "+", "1", ")", "%", "run_loss_print_interval", "==", "0", "\n", "print_run_loss", "=", "print_run_loss", "and", "self", ".", "verbose", "\n", "self", ".", "perform_training_epoch", "(", "optimizer", ",", "loss_f", ",", "train_dataloader", ",", "\n", "print_run_loss", "=", "print_run_loss", ")", "\n", "\n", "# Track statistics in results", "\n", "if", "(", "epoch", "+", "1", ")", "%", "eval_interval", "==", "0", ":", "\n", "                ", "self", ".", "track_metrics", "(", "epoch", "+", "1", ",", "results", ",", "loss_f", ",", "eval_datasets", ")", "\n", "\n", "# Save agent and optimizer state", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "save_interval", "==", "0", "and", "save_path", "is", "not", "None", ":", "\n", "                ", "self", ".", "save_state", "(", "save_path", ",", "'epoch_{}'", ".", "format", "(", "epoch", "+", "1", ")", ",", "optimizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.track_metrics": [[137, 152], ["datasets.items", "mp.eval.evaluate.ds_losses_metrics", "mp.eval.evaluate.ds_losses_metrics.keys", "results.add", "results.add", "print", "mp.eval.evaluate.ds_losses_metrics.keys", "print"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.ds_losses_metrics", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add"], ["", "", "", "def", "track_metrics", "(", "self", ",", "epoch", ",", "results", ",", "loss_f", ",", "datasets", ")", ":", "\n", "        ", "r\"\"\"Tracks metrics. Losses and scores are calculated for each 3D subject, \n        and averaged over the dataset.\n        \"\"\"", "\n", "for", "ds_name", ",", "ds", "in", "datasets", ".", "items", "(", ")", ":", "\n", "            ", "eval_dict", "=", "ds_losses_metrics", "(", "ds", ",", "self", ",", "loss_f", ",", "self", ".", "metrics", ")", "\n", "for", "metric_key", "in", "eval_dict", ".", "keys", "(", ")", ":", "\n", "                ", "results", ".", "add", "(", "epoch", "=", "epoch", ",", "metric", "=", "'Mean_'", "+", "metric_key", ",", "data", "=", "ds_name", ",", "\n", "value", "=", "eval_dict", "[", "metric_key", "]", "[", "'mean'", "]", ")", "\n", "results", ".", "add", "(", "epoch", "=", "epoch", ",", "metric", "=", "'Std_'", "+", "metric_key", ",", "data", "=", "ds_name", ",", "\n", "value", "=", "eval_dict", "[", "metric_key", "]", "[", "'std'", "]", ")", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "'Epoch {} dataset {}'", ".", "format", "(", "epoch", ",", "ds_name", ")", ")", "\n", "for", "metric_key", "in", "eval_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "print", "(", "'{}: {}'", ".", "format", "(", "metric_key", ",", "eval_dict", "[", "metric_key", "]", "[", "'mean'", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.save_state": [[153, 178], ["os.path.join", "os.path.exists", "os.makedirs", "mp.utils.pytorch.pytorch_load_restore.save_model_state", "mp.utils.load_restore.pkl_dump", "shutil.rmtree", "dir", "getattr", "mp.utils.pytorch.pytorch_load_restore.save_optimizer_state"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.save_model_state", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.pkl_dump", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.save_optimizer_state"], ["", "", "", "", "def", "save_state", "(", "self", ",", "states_path", ",", "state_name", ",", "optimizer", "=", "None", ",", "overwrite", "=", "False", ")", ":", "\n", "        ", "r\"\"\"Saves an agent state. Raises an error if the directory exists and \n        overwrite=False.\n        \"\"\"", "\n", "if", "states_path", "is", "not", "None", ":", "\n", "            ", "state_full_path", "=", "os", ".", "path", ".", "join", "(", "states_path", ",", "state_name", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "state_full_path", ")", ":", "\n", "                ", "if", "not", "overwrite", ":", "\n", "                    ", "raise", "FileExistsError", "\n", "", "shutil", ".", "rmtree", "(", "state_full_path", ")", "\n", "", "os", ".", "makedirs", "(", "state_full_path", ")", "\n", "save_model_state", "(", "self", ".", "model", ",", "'model'", ",", "state_full_path", ")", "\n", "pkl_dump", "(", "self", ".", "agent_state_dict", ",", "'agent_state_dict'", ",", "state_full_path", ")", "\n", "\n", "# if no optimizer is set, try to save _optim attributes of model", "\n", "if", "optimizer", "is", "None", ":", "\n", "                ", "attrs", "=", "dir", "(", "self", ".", "model", ")", "\n", "for", "att", "in", "attrs", ":", "\n", "                    ", "if", "'_optim'", "in", "att", ":", "\n", "                        ", "optim", "=", "getattr", "(", "self", ".", "model", ",", "att", ")", "\n", "# only save if attribute is optimizer", "\n", "try", ":", "\n", "                            ", "save_optimizer_state", "(", "optim", ",", "att", ",", "state_full_path", ")", "\n", "", "except", ":", "\n", "                            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.restore_state": [[179, 199], ["os.path.join", "mp.utils.pytorch.pytorch_load_restore.load_model_state", "mp.utils.load_restore.pkl_load", "mp.utils.pytorch.pytorch_load_restore.load_optimizer_state", "print", "print"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.load_model_state", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.pkl_load", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.load_optimizer_state"], ["", "", "", "", "", "", "def", "restore_state", "(", "self", ",", "states_path", ",", "state_name", ",", "optimizer", "=", "None", ")", ":", "\n", "        ", "r\"\"\"Tries to restore a previous agent state, consisting of a model \n        state and the content of agent_state_dict. Returns whether the restore \n        operation  was successful.\n        \"\"\"", "\n", "state_full_path", "=", "os", ".", "path", ".", "join", "(", "states_path", ",", "state_name", ")", "\n", "try", ":", "\n", "            ", "correct_load", "=", "load_model_state", "(", "self", ".", "model", ",", "'model'", ",", "state_full_path", ",", "device", "=", "self", ".", "device", ")", "\n", "assert", "correct_load", "\n", "agent_state_dict", "=", "pkl_load", "(", "'agent_state_dict'", ",", "state_full_path", ")", "\n", "assert", "agent_state_dict", "is", "not", "None", "\n", "self", ".", "agent_state_dict", "=", "agent_state_dict", "\n", "if", "optimizer", "is", "not", "None", ":", "\n", "                ", "load_optimizer_state", "(", "optimizer", ",", "'optimizer'", ",", "state_full_path", ",", "device", "=", "self", ".", "device", ")", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "'State {} was restored'", ".", "format", "(", "state_name", ")", ")", "\n", "", "return", "True", "\n", "", "except", ":", "\n", "            ", "print", "(", "'State {} could not be restored'", ".", "format", "(", "state_name", ")", ")", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar": [[201, 206], ["agent.Agent.summary_writer.add_scalar"], "methods", ["None"], ["", "", "def", "writer_add_scalar", "(", "self", ",", "key", ",", "value", ",", "epoch", ")", ":", "\n", "        ", "r\"\"\"Adds a scalar to tensorboard tracking.\n        \"\"\"", "\n", "if", "self", ".", "summary_writer", "is", "not", "None", ":", "\n", "            ", "self", ".", "summary_writer", ".", "add_scalar", "(", "key", ",", "value", ",", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_image": [[207, 212], ["agent.Agent.summary_writer.add_image"], "methods", ["None"], ["", "", "def", "writer_add_image", "(", "self", ",", "key", ",", "img", ",", "epoch", ")", ":", "\n", "        ", "r\"\"\"Adds an image to tensorboard tracking.\n        \"\"\"", "\n", "if", "self", ".", "summary_writer", "is", "not", "None", ":", "\n", "            ", "self", ".", "summary_writer", ".", "add_image", "(", "key", ",", "img", ",", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.debug_print": [[213, 218], ["print"], "methods", ["None"], ["", "", "def", "debug_print", "(", "self", ",", "msg", ",", "value", ",", "debug", "=", "False", ")", ":", "\n", "        ", "r\"\"\"Random debugging printer function ... \n        \"\"\"", "\n", "if", "debug", ":", "\n", "            ", "print", "(", "msg", ",", "value", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.acs_agent.ACSAgent.__init__": [[22, 26], ["mp.agents.segmentation_agent.SegmentationAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "'metrics'", "not", "in", "kwargs", ":", "\n", "            ", "kwargs", "[", "'metrics'", "]", "=", "[", "'ScoreDice'", ",", "'ScoreIoU'", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.acs_agent.ACSAgent.train": [[27, 87], ["dict", "print", "range", "acs_agent.ACSAgent.track_metrics", "len", "acs_agent.ACSAgent.model.set_data_parallel", "acs_agent.ACSAgent.perform_training_epoch", "acs_agent.ACSAgent.model.unet_scheduler.step", "acs_agent.ACSAgent.track_loss", "acs_agent.ACSAgent.track_visualization", "acs_agent.ACSAgent.track_visualization", "acs_agent.ACSAgent.save_state"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.track_metrics", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.set_data_parallel", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.perform_training_epoch", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.track_loss", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.track_visualization", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.track_visualization", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.ExperimentRun.save_state"], ["", "def", "train", "(", "self", ",", "results", ",", "loss_f", ",", "train_dataloader", ",", "test_dataloader", ",", "config", ",", "\n", "init_epoch", "=", "0", ",", "nr_epochs", "=", "100", ",", "run_loss_print_interval", "=", "1", ",", "\n", "eval_datasets", "=", "dict", "(", ")", ",", "eval_interval", "=", "2", ",", "\n", "save_path", "=", "None", ",", "save_interval", "=", "10", ",", "\n", "display_interval", "=", "1", ",", "\n", "resume_epoch", "=", "None", ",", "\n", "device_ids", "=", "[", "0", "]", ")", ":", "\n", "\n", "        ", "r\"\"\"Train a model through its agent. Performs training epochs, \n        tracks metrics and saves model states.\n\n        Args:\n            results (mp.eval.result.Result): results object to track progress\n            loss_f (mp.eval.losses.loss_abstract.LossAbstract): loss function for the segmenter\n            train_dataloader (torch.utils.data.DataLoader): dataloader of training set\n            test_dataloader (torch.utils.data.DataLoader): dataloader of test set\n            eval_datasets (torch.utils.data.DataLoader): dataloader of evaluation set\n            config (dict): configuration dictionary from parsed arguments\n            init_epoch (int): initial epoch\n            nr_epochs (int): number of epochs to train for\n            run_loss_print_interval (int) print loss every # epochs\n            eval_interval (int): evaluate model every # epochs\n            save_interval (int): save model every # epochs\n            save_path (str): save path for saving model, etc.\n            display_interval (str): log tensorboard every # epochs\n            resume_epoch (int): resume training at epoch #\n            device_ids (list) device ids of GPUs\n        \"\"\"", "\n", "\n", "self", ".", "agent_state_dict", "[", "'epoch'", "]", "=", "init_epoch", "\n", "\n", "if", "len", "(", "device_ids", ")", ">", "1", ":", "\n", "            ", "self", ".", "model", ".", "set_data_parallel", "(", "device_ids", ")", "\n", "", "print", "(", "'Using GPUs:'", ",", "device_ids", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "init_epoch", ",", "nr_epochs", ")", ":", "\n", "            ", "self", ".", "agent_state_dict", "[", "'epoch'", "]", "=", "epoch", "\n", "\n", "print_run_loss", "=", "(", "epoch", "+", "1", ")", "%", "run_loss_print_interval", "==", "0", "\n", "print_run_loss", "=", "print_run_loss", "and", "self", ".", "verbose", "\n", "acc", "=", "self", ".", "perform_training_epoch", "(", "loss_f", ",", "train_dataloader", ",", "config", ",", "\n", "print_run_loss", "=", "print_run_loss", ")", "\n", "\n", "if", "config", "[", "'continual'", "]", ":", "\n", "                ", "self", ".", "model", ".", "unet_scheduler", ".", "step", "(", ")", "\n", "\n", "# Write losses to tensorboard", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "display_interval", "==", "0", ":", "\n", "                ", "self", ".", "track_loss", "(", "acc", ",", "epoch", "+", "1", ",", "config", ")", "\n", "\n", "# Create visualizations and write them to tensorboard", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "display_interval", "==", "0", ":", "\n", "                ", "self", ".", "track_visualization", "(", "train_dataloader", ",", "save_path", ",", "epoch", "+", "1", ",", "config", ",", "'train'", ")", "\n", "self", ".", "track_visualization", "(", "test_dataloader", ",", "save_path", ",", "epoch", "+", "1", ",", "config", ",", "'test'", ")", "\n", "\n", "# Save agent and optimizer state", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "save_interval", "==", "0", "and", "save_path", "is", "not", "None", ":", "\n", "                ", "self", ".", "save_state", "(", "save_path", ",", "epoch", "+", "1", ")", "\n", "\n", "", "", "self", ".", "track_metrics", "(", "epoch", "+", "1", ",", "results", ",", "loss_f", ",", "eval_datasets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.acs_agent.ACSAgent.perform_training_epoch": [[88, 159], ["mp.eval.accumulator.Accumulator", "time.time", "tqdm.tqdm.tqdm", "print", "acs_agent.ACSAgent.get_inputs_targets", "acs_agent.ACSAgent.get_outputs", "acs_agent.ACSAgent.model.unet_optim.zero_grad", "loss_f", "loss_f.backward", "acs_agent.ACSAgent.model.unet_optim.step", "mp.eval.accumulator.Accumulator.add", "mp.eval.accumulator.Accumulator.add", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm", "float", "float", "acs_agent.ACSAgent.get_inputs_targets", "acs_agent.ACSAgent.model.unet_optim.zero_grad", "acs_agent.ACSAgent.update_encoder_misc", "acs_agent.ACSAgent.model.unet_optim.step", "mp.eval.accumulator.Accumulator.add", "acs_agent.ACSAgent.get_inputs_targets", "acs_agent.ACSAgent.model.zero_grad_optim_enc_misc", "acs_agent.ACSAgent.update_encoder_misc", "acs_agent.ACSAgent.model.step_optim_enc_misc", "range", "mp.eval.accumulator.Accumulator.add", "mp.eval.accumulator.Accumulator.mean", "round", "loss_f.detach().cpu", "len", "loss_f.detach().cpu", "len", "float", "acs_agent.ACSAgent.model.zero_grad_optim_disc", "acs_agent.ACSAgent.update_discriminator", "acs_agent.ACSAgent.model.step_optim_disc", "float", "loss_comb.detach().cpu", "len", "loss_comb.detach().cpu", "len", "time.time", "loss_f.detach", "loss_f.detach", "loss_comb.detach", "loss_comb.detach"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.get_inputs_targets", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.get_outputs", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.get_inputs_targets", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.acs_agent.ACSAgent.update_encoder_misc", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.get_inputs_targets", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.zero_grad_optim_enc_misc", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.acs_agent.ACSAgent.update_encoder_misc", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.step_optim_enc_misc", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.zero_grad_optim_disc", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.acs_agent.ACSAgent.update_discriminator", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.step_optim_disc"], ["", "def", "perform_training_epoch", "(", "self", ",", "loss_f", ",", "train_dataloader", ",", "config", ",", "\n", "print_run_loss", "=", "False", ")", ":", "\n", "        ", "r\"\"\"Perform a training epoch\n        \n        Args:\n            loss_f (mp.eval.losses.loss_abstract.LossAbstract): loss function for the segmenter\n            train_dataloader (torch.utils.data.DataLoader): dataloader of training set\n            config (dict): configuration dictionary from parsed arguments\n            print_run_loss (boolean): whether to print running loss\n        \n        Returns:\n            acc (mp.eval.accumulator.Accumulator): accumulator holding losses\n        \"\"\"", "\n", "acc", "=", "Accumulator", "(", "'loss'", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "config", "[", "'unet_only'", "]", ":", "\n", "            ", "for", "data", "in", "tqdm", "(", "train_dataloader", ",", "disable", "=", "True", ")", ":", "\n", "# Get data", "\n", "                ", "inputs", ",", "targets", ",", "_", "=", "self", ".", "get_inputs_targets", "(", "data", ",", "eval", "=", "False", ")", "\n", "\n", "# Forward pass", "\n", "outputs", "=", "self", ".", "get_outputs", "(", "inputs", ")", "\n", "\n", "# Optimization step", "\n", "self", ".", "model", ".", "unet_optim", ".", "zero_grad", "(", ")", "\n", "\n", "loss", "=", "loss_f", "(", "outputs", ",", "targets", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "self", ".", "model", ".", "unet_optim", ".", "step", "(", ")", "\n", "\n", "acc", ".", "add", "(", "'loss'", ",", "float", "(", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "inputs", ")", ")", "\n", "acc", ".", "add", "(", "'loss_seg'", ",", "float", "(", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "inputs", ")", ")", "\n", "\n", "", "", "elif", "config", "[", "'continual'", "]", ":", "\n", "            ", "for", "data", "in", "tqdm", "(", "train_dataloader", ",", "disable", "=", "True", ")", ":", "\n", "\n", "                ", "x", ",", "y", ",", "domain_code", "=", "self", ".", "get_inputs_targets", "(", "data", ",", "eval", "=", "False", ")", "\n", "\n", "self", ".", "model", ".", "unet_optim", ".", "zero_grad", "(", ")", "\n", "loss_vae_gen", ",", "acc", "=", "self", ".", "update_encoder_misc", "(", "x", ",", "y", ",", "domain_code", ",", "acc", ",", "config", ",", "loss_f", ")", "\n", "\n", "self", ".", "model", ".", "unet_optim", ".", "step", "(", ")", "\n", "\n", "loss_comb", "=", "loss_vae_gen", "\n", "acc", ".", "add", "(", "'loss'", ",", "float", "(", "loss_comb", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "x", ")", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "for", "data", "in", "tqdm", "(", "train_dataloader", ",", "disable", "=", "True", ")", ":", "\n", "\n", "                ", "x", ",", "y", ",", "domain_code", "=", "self", ".", "get_inputs_targets", "(", "data", ",", "eval", "=", "False", ")", "\n", "\n", "self", ".", "model", ".", "zero_grad_optim_enc_misc", "(", ")", "\n", "loss_vae_gen", ",", "acc", "=", "self", ".", "update_encoder_misc", "(", "x", ",", "y", ",", "domain_code", ",", "acc", ",", "config", ",", "loss_f", ")", "\n", "self", ".", "model", ".", "step_optim_enc_misc", "(", ")", "\n", "\n", "\n", "for", "_", "in", "range", "(", "config", "[", "'d_iter'", "]", ")", ":", "\n", "\n", "                    ", "self", ".", "model", ".", "zero_grad_optim_disc", "(", ")", "\n", "loss_dis_seg", ",", "acc", "=", "self", ".", "update_discriminator", "(", "x", ",", "y", ",", "domain_code", ",", "acc", ",", "config", ",", "loss_f", ")", "\n", "self", ".", "model", ".", "step_optim_disc", "(", ")", "\n", "\n", "", "loss_comb", "=", "loss_vae_gen", "+", "loss_dis_seg", "\n", "acc", ".", "add", "(", "'loss'", ",", "float", "(", "loss_comb", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "x", ")", ")", "\n", "\n", "", "", "if", "print_run_loss", ":", "\n", "            ", "print", "(", "'\\nrunning loss: {} - time/epoch {}'", ".", "format", "(", "acc", ".", "mean", "(", "'loss'", ")", ",", "round", "(", "time", ".", "time", "(", ")", "-", "start_time", ",", "4", ")", ")", ")", "\n", "\n", "", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.acs_agent.ACSAgent.get_inputs_targets": [[160, 177], ["inputs.to", "targets.to", "targets.float", "inputs.to", "targets.to", "domain_code.to", "targets.float"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to"], ["", "def", "get_inputs_targets", "(", "self", ",", "data", ",", "eval", "=", "True", ")", ":", "\n", "        ", "r\"\"\"Prepares a data batch.\n\n        Args:\n            data (tuple): a dataloader item, possibly in cpu\n            eval (boolean): evaluation mode, doesn't return domain code \n            \n        Returns (tuple): preprocessed data in the selected device.\n        \"\"\"", "\n", "if", "eval", ":", "\n", "            ", "inputs", ",", "targets", ",", "_", "=", "data", "\n", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "self", ".", "device", ")", ",", "targets", ".", "to", "(", "self", ".", "device", ")", "\n", "return", "inputs", ",", "targets", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "            ", "inputs", ",", "targets", ",", "domain_code", "=", "data", "\n", "inputs", ",", "targets", ",", "domain_code", "=", "inputs", ".", "to", "(", "self", ".", "device", ")", ",", "targets", ".", "to", "(", "self", ".", "device", ")", ",", "domain_code", ".", "to", "(", "self", ".", "device", ")", "\n", "return", "inputs", ",", "targets", ".", "float", "(", ")", ",", "domain_code", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.acs_agent.ACSAgent.track_metrics": [[178, 200], ["datasets.items", "mp.eval.evaluate.ds_losses_metrics", "mp.eval.evaluate.ds_losses_metrics.keys", "results.add", "results.add", "print", "mp.eval.evaluate.ds_losses_metrics.keys", "acs_agent.ACSAgent.writer_add_scalar", "print"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.ds_losses_metrics", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar"], ["", "", "def", "track_metrics", "(", "self", ",", "epoch", ",", "results", ",", "loss_f", ",", "datasets", ")", ":", "\n", "        ", "r\"\"\"Tracks metrics. Losses and scores are calculated for each 3D subject, \n        and averaged over the dataset.\n\n        Args:\n            epoch (int):current epoch\n            results (mp.eval.result.Result): results object to track progress\n            loss_f (mp.eval.losses.loss_abstract.LossAbstract): loss function for the segmenter\n            datasets (torch.utils.data.DataLoader): dataloader object to evaluate on\n        \"\"\"", "\n", "for", "ds_name", ",", "ds", "in", "datasets", ".", "items", "(", ")", ":", "\n", "            ", "eval_dict", "=", "ds_losses_metrics", "(", "ds", ",", "self", ",", "loss_f", ",", "self", ".", "metrics", ")", "\n", "for", "metric_key", "in", "eval_dict", ".", "keys", "(", ")", ":", "\n", "                ", "results", ".", "add", "(", "epoch", "=", "epoch", ",", "metric", "=", "'Mean_'", "+", "metric_key", ",", "data", "=", "ds_name", ",", "\n", "value", "=", "eval_dict", "[", "metric_key", "]", "[", "'mean'", "]", ")", "\n", "results", ".", "add", "(", "epoch", "=", "epoch", ",", "metric", "=", "'Std_'", "+", "metric_key", ",", "data", "=", "ds_name", ",", "\n", "value", "=", "eval_dict", "[", "metric_key", "]", "[", "'std'", "]", ")", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "'Epoch {} dataset {}'", ".", "format", "(", "epoch", ",", "ds_name", ")", ")", "\n", "for", "metric_key", "in", "eval_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "self", ".", "writer_add_scalar", "(", "f'metric/{metric_key}/{ds_name}'", ",", "eval_dict", "[", "metric_key", "]", "[", "'mean'", "]", ",", "epoch", ")", "\n", "print", "(", "'{}: {}'", ".", "format", "(", "metric_key", ",", "eval_dict", "[", "metric_key", "]", "[", "'mean'", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.acs_agent.ACSAgent.track_loss": [[201, 223], ["acs_agent.ACSAgent.writer_add_scalar", "acs_agent.ACSAgent.writer_add_scalar", "acs_agent.ACSAgent.writer_add_scalar", "acs_agent.ACSAgent.writer_add_scalar", "acs_agent.ACSAgent.writer_add_scalar", "acs_agent.ACSAgent.writer_add_scalar", "acs_agent.ACSAgent.writer_add_scalar", "acs_agent.ACSAgent.writer_add_scalar", "acs_agent.ACSAgent.writer_add_scalar", "acs_agent.ACSAgent.writer_add_scalar", "acs_agent.ACSAgent.writer_add_scalar", "acc.mean", "acc.mean", "acc.mean", "acc.mean", "acc.mean", "acc.mean", "acc.mean", "acc.mean", "acc.mean", "acc.mean", "acc.mean"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean"], ["", "", "", "", "def", "track_loss", "(", "self", ",", "acc", ",", "epoch", ",", "config", ",", "phase", "=", "'train'", ")", ":", "\n", "        ", "r\"\"\"Tracks loss in tensorboard.\n\n        Args:\n            acc (mp.eval.accumulator.Accumulator): accumulator holding losses\n            epoch (int): current epoch\n            config (dict): configuration dictionary from parsed arguments\n            phase (string): either \"test\" or \"train\"\n        \"\"\"", "\n", "if", "not", "config", "[", "'unet_only'", "]", "and", "not", "config", "[", "'continual'", "]", ":", "\n", "            ", "self", ".", "writer_add_scalar", "(", "f'loss_{phase}/loss_vae'", ",", "acc", ".", "mean", "(", "'loss_vae'", ")", ",", "epoch", ")", "\n", "self", ".", "writer_add_scalar", "(", "f'loss_{phase}/loss_vae_Reconstruction_Loss'", ",", "acc", ".", "mean", "(", "'loss_vae_Reconstruction_Loss'", ")", ",", "epoch", ")", "\n", "self", ".", "writer_add_scalar", "(", "f'loss_{phase}/loss_vae_KLD'", ",", "acc", ".", "mean", "(", "'loss_vae_KLD'", ")", ",", "epoch", ")", "\n", "self", ".", "writer_add_scalar", "(", "f'loss_{phase}/loss_c_adv_d'", ",", "acc", ".", "mean", "(", "'loss_c_adv_d'", ")", ",", "epoch", ")", "\n", "self", ".", "writer_add_scalar", "(", "f'loss_{phase}/loss_c_adv_e'", ",", "acc", ".", "mean", "(", "'loss_c_adv_e'", ")", ",", "epoch", ")", "\n", "self", ".", "writer_add_scalar", "(", "f'loss_{phase}/loss_c_recon'", ",", "acc", ".", "mean", "(", "'loss_c_recon'", ")", ",", "epoch", ")", "\n", "self", ".", "writer_add_scalar", "(", "f'loss_{phase}/loss_lcr'", ",", "acc", ".", "mean", "(", "'loss_lcr'", ")", ",", "epoch", ")", "\n", "self", ".", "writer_add_scalar", "(", "f'loss_{phase}/loss_gan_d'", ",", "acc", ".", "mean", "(", "'loss_gan_d'", ")", ",", "epoch", ")", "\n", "self", ".", "writer_add_scalar", "(", "f'loss_{phase}/loss_gan_g'", ",", "acc", ".", "mean", "(", "'loss_gan_g'", ")", ",", "epoch", ")", "\n", "\n", "", "self", ".", "writer_add_scalar", "(", "f'loss_{phase}/loss_seg'", ",", "acc", ".", "mean", "(", "'loss_seg'", ")", ",", "epoch", ")", "\n", "self", ".", "writer_add_scalar", "(", "f'loss_{phase}/loss_comb'", ",", "acc", ".", "mean", "(", "'loss'", ")", ",", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.acs_agent.ACSAgent.track_visualization": [[224, 293], ["enumerate", "x_i[].unsqueeze", "domain_code_i[].unsqueeze", "[].unsqueeze().unsqueeze", "[].unsqueeze().unsqueeze().int", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "mp.visualization.visualize_imgs.plot_3d_segmentation", "mp.visualization.visualize_imgs.plot_3d_segmentation", "mp.visualization.visualize_imgs.plot_3d_segmentation", "PIL.Image.open", "torchvision.to_tensor", "acs_agent.ACSAgent.writer_add_image", "PIL.Image.open", "torchvision.to_tensor", "acs_agent.ACSAgent.writer_add_image", "PIL.Image.open", "torchvision.to_tensor", "acs_agent.ACSAgent.writer_add_image", "acs_agent.ACSAgent.get_inputs_targets", "acs_agent.ACSAgent.get_outputs", "os.path.exists", "os.makedirs", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "acs_agent.ACSAgent.model.forward_enc", "acs_agent.ACSAgent.model.latent_scaler", "acs_agent.ACSAgent.model.forward_gen", "os.path.join", "mp.visualization.visualize_imgs.plot_3d_segmentation", "PIL.Image.open", "torchvision.to_tensor", "acs_agent.ACSAgent.writer_add_image", "len", "[].unsqueeze", "[].unsqueeze().unsqueeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.plot_3d_segmentation", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.plot_3d_segmentation", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.plot_3d_segmentation", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_image", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_image", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_image", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.get_inputs_targets", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.get_outputs", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_enc", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_gen", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.plot_3d_segmentation", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_image"], ["", "def", "track_visualization", "(", "self", ",", "dataloader", ",", "save_path", ",", "epoch", ",", "config", ",", "phase", "=", "'train'", ")", ":", "\n", "        ", "r\"\"\"Creates visualizations and tracks them in tensorboard.\n\n        Args:\n            dataloader (Dataloader): dataloader to draw sample from\n            save_path (string): path for the images to be saved (one folder up)\n            epoch (int): current epoch\n            config (dict): configuration dictionary from parsed arguments\n            phase (string): either \"test\" or \"train\"\n        \"\"\"", "\n", "for", "imgs", "in", "dataloader", ":", "\n", "            ", "x_i", ",", "y_i", ",", "domain_code_i", "=", "self", ".", "get_inputs_targets", "(", "imgs", ",", "eval", "=", "False", ")", "\n", "x_i_seg_all", "=", "self", ".", "get_outputs", "(", "x_i", ")", "\n", "break", "\n", "\n", "# select sample with guaranteed segmentation label", "\n", "", "sample_idx", "=", "0", "\n", "for", "i", ",", "y_", "in", "enumerate", "(", "y_i", ")", ":", "\n", "# if torch.count_nonzero(y_[1]) > 0:", "\n", "            ", "if", "len", "(", "torch", ".", "nonzero", "(", "y_", "[", "1", "]", ")", ")", ">", "0", ":", "\n", "                ", "sample_idx", "=", "i", "\n", "break", "\n", "\n", "", "", "x_i_img", "=", "x_i", "[", "sample_idx", "]", ".", "unsqueeze", "(", "0", ")", "\n", "x_i_domain", "=", "domain_code_i", "[", "sample_idx", "]", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "# segmentation", "\n", "x_i_seg", "=", "x_i_seg_all", "[", "sample_idx", "]", "[", "1", "]", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "threshold", "=", "0.5", "\n", "x_i_seg_mask", "=", "(", "x_i_seg", ">", "threshold", ")", ".", "int", "(", ")", "\n", "y_i_seg_mask", "=", "y_i", "[", "sample_idx", "]", "[", "1", "]", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "int", "(", ")", "\n", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "'..'", ",", "'imgs_batch'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "save_path", ")", "\n", "\n", "", "save_path_input", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "f'e_{epoch:06d}_{phase}_x.png'", ")", "\n", "save_path_pred", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "f'e_{epoch:06d}_{phase}_pred.png'", ")", "\n", "save_path_label", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "f'e_{epoch:06d}_{phase}_label.png'", ")", "\n", "\n", "plot_3d_segmentation", "(", "x_i_img", ",", "torch", ".", "zeros_like", "(", "x_i_img", ")", ",", "save_path", "=", "save_path_input", ",", "img_size", "=", "(", "config", "[", "'input_dim_hw'", "]", ",", "config", "[", "'input_dim_hw'", "]", ")", ",", "alpha", "=", "0.5", ")", "\n", "plot_3d_segmentation", "(", "x_i_img", ",", "x_i_seg_mask", ",", "save_path", "=", "save_path_pred", ",", "img_size", "=", "(", "config", "[", "'input_dim_hw'", "]", ",", "config", "[", "'input_dim_hw'", "]", ")", ",", "alpha", "=", "0.5", ")", "\n", "plot_3d_segmentation", "(", "x_i_img", ",", "y_i_seg_mask", ",", "save_path", "=", "save_path_label", ",", "img_size", "=", "(", "config", "[", "'input_dim_hw'", "]", ",", "config", "[", "'input_dim_hw'", "]", ")", ",", "alpha", "=", "0.5", ")", "\n", "\n", "image", "=", "Image", ".", "open", "(", "save_path_input", ")", "\n", "image", "=", "TF", ".", "to_tensor", "(", "image", ")", "\n", "self", ".", "writer_add_image", "(", "f'imgs_{phase}/input'", ",", "image", ",", "epoch", ")", "\n", "\n", "image", "=", "Image", ".", "open", "(", "save_path_pred", ")", "\n", "image", "=", "TF", ".", "to_tensor", "(", "image", ")", "\n", "self", ".", "writer_add_image", "(", "f'imgs_{phase}/pred'", ",", "image", ",", "epoch", ")", "\n", "\n", "image", "=", "Image", ".", "open", "(", "save_path_label", ")", "\n", "image", "=", "TF", ".", "to_tensor", "(", "image", ")", "\n", "self", ".", "writer_add_image", "(", "f'imgs_{phase}/label'", ",", "image", ",", "epoch", ")", "\n", "\n", "if", "not", "config", "[", "'unet_only'", "]", ":", "\n", "# gan", "\n", "            ", "skip_connections_x", ",", "content_x", ",", "style_sample_x", "=", "self", ".", "model", ".", "forward_enc", "(", "x_i_img", ")", "\n", "latent_scale_x", "=", "self", ".", "model", ".", "latent_scaler", "(", "style_sample_x", ")", "\n", "x_hat", "=", "self", ".", "model", ".", "forward_gen", "(", "content_x", ",", "latent_scale_x", ",", "x_i_domain", ")", "\n", "\n", "save_path_gan", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "f'e_{epoch:06d}_{phase}_gan.png'", ")", "\n", "\n", "plot_3d_segmentation", "(", "x_hat", ",", "torch", ".", "zeros", "(", "x_hat", ".", "shape", ")", ",", "save_path", "=", "save_path_gan", ",", "img_size", "=", "(", "config", "[", "'input_dim_hw'", "]", ",", "config", "[", "'input_dim_hw'", "]", ")", ",", "alpha", "=", "0.5", ")", "\n", "\n", "image", "=", "Image", ".", "open", "(", "save_path_gan", ")", "\n", "image", "=", "TF", ".", "to_tensor", "(", "image", ")", "\n", "self", ".", "writer_add_image", "(", "f'imgs_{phase}/gan'", ",", "image", ",", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.acs_agent.ACSAgent.save_state": [[294, 313], ["os.path.join", "os.path.exists", "os.makedirs", "mp.utils.pytorch.pytorch_load_restore.save_model_state_dataparallel", "mp.utils.load_restore.pkl_dump", "shutil.rmtree"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.save_model_state_dataparallel", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.pkl_dump"], ["", "", "def", "save_state", "(", "self", ",", "states_path", ",", "epoch", ",", "optimizer", "=", "None", ",", "overwrite", "=", "False", ")", ":", "\n", "        ", "r\"\"\"Saves an agent state. Raises an error if the directory exists and \n        overwrite=False.\n\n        Args:\n            states_path (str): save path for model states\n            epoch (int): current epoch\n            overwrite (boolean): whether to override existing files\n        \"\"\"", "\n", "if", "states_path", "is", "not", "None", ":", "\n", "            ", "state_name", "=", "f'epoch_{epoch:04d}'", "\n", "state_full_path", "=", "os", ".", "path", ".", "join", "(", "states_path", ",", "state_name", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "state_full_path", ")", ":", "\n", "                ", "if", "not", "overwrite", ":", "\n", "                    ", "raise", "FileExistsError", "\n", "", "shutil", ".", "rmtree", "(", "state_full_path", ")", "\n", "", "os", ".", "makedirs", "(", "state_full_path", ")", "\n", "save_model_state_dataparallel", "(", "self", ".", "model", ",", "'model'", ",", "state_full_path", ")", "\n", "pkl_dump", "(", "self", ".", "agent_state_dict", ",", "'agent_state_dict'", ",", "state_full_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.acs_agent.ACSAgent.restore_state": [[314, 341], ["os.path.join", "mp.utils.pytorch.pytorch_load_restore.load_model_state", "mp.utils.load_restore.pkl_load", "os.listdir", "print", "print"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.load_model_state", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.pkl_load"], ["", "", "def", "restore_state", "(", "self", ",", "states_path", ",", "epoch", ",", "optimizer", "=", "None", ")", ":", "\n", "        ", "r\"\"\"Tries to restore a previous agent state, consisting of a model \n        state and the content of agent_state_dict. Returns whether the restore \n        operation  was successful.\n        Args:\n            states_path (str): save path for model states\n            epoch (int): current epoch\n        \"\"\"", "\n", "\n", "if", "epoch", "==", "-", "1", ":", "\n", "            ", "state_name", "=", "os", ".", "listdir", "(", "states_path", ")", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "state_name", "=", "f'epoch_{epoch:04d}'", "\n", "\n", "", "state_full_path", "=", "os", ".", "path", ".", "join", "(", "states_path", ",", "state_name", ")", "\n", "try", ":", "\n", "            ", "correct_load", "=", "load_model_state", "(", "self", ".", "model", ",", "'model'", ",", "state_full_path", ",", "device", "=", "self", ".", "device", ")", "\n", "assert", "correct_load", "\n", "agent_state_dict", "=", "pkl_load", "(", "'agent_state_dict'", ",", "state_full_path", ")", "\n", "assert", "agent_state_dict", "is", "not", "None", "\n", "self", ".", "agent_state_dict", "=", "agent_state_dict", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "'State {} was restored'", ".", "format", "(", "state_name", ")", ")", "\n", "", "return", "True", "\n", "", "except", ":", "\n", "            ", "print", "(", "'State {} could not be restored'", ".", "format", "(", "state_name", ")", ")", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.acs_agent.ACSAgent.update_encoder_misc": [[342, 418], ["acs_agent.ACSAgent.model.forward_enc", "acs_agent.ACSAgent.model.latent_scaler", "acs_agent.ACSAgent.model.forward_gen", "acs_agent.ACSAgent.model.forward_style_enc", "acs_agent.ACSAgent.vae_loss", "acc.add", "acc.add", "acc.add", "acs_agent.ACSAgent.model.forward_enc", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "acc.add", "acs_agent.ACSAgent.model.sample_z", "acs_agent.ACSAgent.model.latent_scaler", "acs_agent.ACSAgent.model.forward_gen", "acs_agent.ACSAgent.model.forward_dom_dis", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.functional.binary_cross_entropy_with_logits", "torch.functional.binary_cross_entropy_with_logits", "acc.add", "acs_agent.ACSAgent.model.forward_enc", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "acc.add", "acs_agent.ACSAgent.get_outputs", "loss_f", "acc.add", "acs_agent.ACSAgent.model.forward_con_dis", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "acs_agent.ACSAgent.multi_class_cross_entropy_with_softmax", "acc.add", "loss_enc_misc.backward", "float", "float", "float", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "float", "z.to.to.to", "all_ones.to.to.to", "float", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "float", "float", "float", "loss_vae.detach().cpu", "len", "loss_dict[].detach().cpu", "len", "loss_dict[].detach().cpu", "len", "torch.mean.detach().cpu", "torch.mean.detach().cpu", "len", "style_sample_x.get_device", "acs_agent.ACSAgent.get_device", "loss_gan_g.detach().cpu", "len", "torch.mean.detach().cpu", "torch.mean.detach().cpu", "len", "loss_f.detach().cpu", "len", "acs_agent.ACSAgent.detach().cpu", "len", "loss_vae.detach", "loss_dict[].detach", "loss_dict[].detach", "torch.mean.detach", "torch.mean.detach", "loss_gan_g.detach", "torch.mean.detach", "torch.mean.detach", "loss_f.detach", "acs_agent.ACSAgent.detach"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_enc", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_gen", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_style_enc", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.acs_agent.ACSAgent.vae_loss", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_enc", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.sample_z", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_gen", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_dom_dis", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_enc", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.get_outputs", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_con_dis", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.acs_agent.ACSAgent.multi_class_cross_entropy_with_softmax", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to"], ["", "", "def", "update_encoder_misc", "(", "self", ",", "x", ",", "y", ",", "domain_code", ",", "acc", ",", "config", ",", "loss_f", ")", ":", "\n", "        ", "r\"\"\"Backward pass on VAE, reconstruction, GAN (Generator), LCR, segmentation, and content adversarial (Encoder) losses\n\n        Args:\n            x (torch.Tensor): input batch\n            y (torch.Tensor): label batch\n            domain_code (torch.Tensor) domain code batch\n            acc (mp.eval.accumulator.Accumulator): accumulator holding losses\n            config (dict): configuration dictionary from parsed arguments\n            loss_f (mp.eval.losses.loss_abstract.LossAbstract): loss function for the segmenter\n        \n        Returns:\n            acc (mp.eval.accumulator.Accumulator): accumulator holding losses\n            loss_enc_misc (torch.Tensor): encoder and misc. loss\n        \"\"\"", "\n", "\n", "# vae loss", "\n", "skip_connections_x", ",", "content_x", ",", "style_sample_x", "=", "self", ".", "model", ".", "forward_enc", "(", "x", ")", "\n", "\n", "latent_scale_x", "=", "self", ".", "model", ".", "latent_scaler", "(", "style_sample_x", ")", "\n", "x_hat", "=", "self", ".", "model", ".", "forward_gen", "(", "content_x", ",", "latent_scale_x", ",", "domain_code", ")", "\n", "mu", ",", "log_var", "=", "self", ".", "model", ".", "forward_style_enc", "(", "x", ")", "\n", "\n", "loss_dict", "=", "self", ".", "vae_loss", "(", "x_hat", ",", "x", ",", "mu", ",", "log_var", ")", "\n", "loss_vae", "=", "loss_dict", "[", "'loss'", "]", "\n", "acc", ".", "add", "(", "'loss_vae'", ",", "float", "(", "loss_vae", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "x", ")", ")", "\n", "acc", ".", "add", "(", "'loss_vae_Reconstruction_Loss'", ",", "float", "(", "loss_dict", "[", "'Reconstruction_Loss'", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "x", ")", ")", "\n", "acc", ".", "add", "(", "'loss_vae_KLD'", ",", "float", "(", "loss_dict", "[", "'KLD'", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "x", ")", ")", "\n", "\n", "# reconstruction loss", "\n", "skip_connections_x_hat", ",", "content_x_hat", ",", "style_sample_x_hat", "=", "self", ".", "model", ".", "forward_enc", "(", "x_hat", ")", "\n", "\n", "loss_c_recon", "=", "torch", ".", "mean", "(", "torch", ".", "norm", "(", "(", "content_x", "-", "content_x_hat", ")", ".", "view", "(", "-", "1", ",", "1", ")", ",", "p", "=", "1", ")", ")", "\n", "acc", ".", "add", "(", "'loss_c_recon'", ",", "float", "(", "loss_c_recon", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "x", ")", ")", "\n", "\n", "# GAN loss (Generator)", "\n", "z", "=", "self", ".", "model", ".", "sample_z", "(", "style_sample_x", ".", "shape", ")", "\n", "if", "style_sample_x", ".", "is_cuda", ":", "\n", "            ", "z", "=", "z", ".", "to", "(", "style_sample_x", ".", "get_device", "(", ")", ")", "\n", "", "latent_scale_z", "=", "self", ".", "model", ".", "latent_scaler", "(", "z", ")", "\n", "z_hat", "=", "self", ".", "model", ".", "forward_gen", "(", "content_x", ",", "latent_scale_z", ",", "domain_code", ")", "\n", "domain_z_hat", "=", "self", ".", "model", ".", "forward_dom_dis", "(", "z_hat", ",", "domain_code", ")", "\n", "\n", "all_ones", "=", "torch", ".", "ones_like", "(", "domain_z_hat", ")", "\n", "if", "domain_z_hat", ".", "is_cuda", ":", "\n", "            ", "all_ones", "=", "all_ones", ".", "to", "(", "domain_z_hat", ".", "get_device", "(", ")", ")", "\n", "", "fake_loss", "=", "nn", ".", "functional", ".", "binary_cross_entropy_with_logits", "(", "domain_z_hat", ",", "all_ones", ")", "\n", "\n", "loss_gan_g", "=", "fake_loss", "\n", "acc", ".", "add", "(", "'loss_gan_g'", ",", "float", "(", "loss_gan_g", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "x", ")", ")", "\n", "\n", "# lcr loss", "\n", "skip_connections_z_hat", ",", "z_hat_content", ",", "z_hat_sample", "=", "self", ".", "model", ".", "forward_enc", "(", "z_hat", ")", "\n", "\n", "loss_lcr", "=", "torch", ".", "mean", "(", "torch", ".", "norm", "(", "(", "z", "-", "z_hat_sample", ")", ".", "view", "(", "-", "1", ",", "1", ")", ",", "p", "=", "1", ")", ")", "\n", "acc", ".", "add", "(", "'loss_lcr'", ",", "float", "(", "loss_lcr", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "x", ")", ")", "\n", "\n", "# segmentation loss", "\n", "x_seg", "=", "self", ".", "get_outputs", "(", "x", ")", "\n", "\n", "loss_seg", "=", "loss_f", "(", "x_seg", ",", "y", ")", "\n", "acc", ".", "add", "(", "'loss_seg'", ",", "float", "(", "loss_seg", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "x", ")", ")", "\n", "\n", "# content adversarial loss (Encoder)", "\n", "domain_x", "=", "self", ".", "model", ".", "forward_con_dis", "(", "skip_connections_x", ",", "content_x", ")", "\n", "domain_dummy", "=", "torch", ".", "zeros_like", "(", "domain_x", ")", "\n", "domain_dummy", "[", "-", "1", "]", "=", "1", "\n", "\n", "loss_c_adv_e", "=", "self", ".", "multi_class_cross_entropy_with_softmax", "(", "domain_x", ",", "domain_dummy", ")", "\n", "acc", ".", "add", "(", "'loss_c_adv_e'", ",", "float", "(", "loss_c_adv_e", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "x", ")", ")", "\n", "\n", "# combine losses and weight", "\n", "loss_enc_misc", "=", "config", "[", "'lambda_c_adv'", "]", "*", "loss_c_adv_e", "*", "3", "+", "config", "[", "'lambda_vae'", "]", "*", "loss_vae", "+", "config", "[", "'lambda_c_recon'", "]", "*", "loss_c_recon", "+", "config", "[", "'lambda_gan'", "]", "*", "loss_gan_g", "+", "config", "[", "'lambda_lcr'", "]", "*", "loss_lcr", "+", "config", "[", "'lambda_seg'", "]", "*", "loss_seg", "# + loss_c_adv", "\n", "loss_enc_misc", ".", "backward", "(", ")", "\n", "\n", "return", "loss_enc_misc", ",", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.acs_agent.ACSAgent.update_discriminator": [[419, 490], ["acs_agent.ACSAgent.model.forward_enc", "acs_agent.ACSAgent.model.forward_con_dis", "torch.max", "torch.max", "torch.max", "torch.max", "acs_agent.ACSAgent.model.sample_z", "acs_agent.ACSAgent.model.forward_con_dis", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "acs_agent.ACSAgent.multi_class_cross_entropy_with_softmax", "acs_agent.ACSAgent.multi_class_cross_entropy_with_softmax", "acc.add", "acs_agent.ACSAgent.model.sample_z", "acs_agent.ACSAgent.model.latent_scaler", "acs_agent.ACSAgent.model.forward_gen", "acs_agent.ACSAgent.model.forward_dom_dis", "acs_agent.ACSAgent.model.forward_dom_dis", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.functional.binary_cross_entropy_with_logits", "torch.functional.binary_cross_entropy_with_logits", "torch.functional.binary_cross_entropy_with_logits", "torch.functional.binary_cross_entropy_with_logits", "acc.add", "loss_disc.backward", "content_z.to.to.to", "acs_agent.ACSAgent.model.sample_z", "float", "z.to.to.to", "all_ones.to.to.to", "all_zeros.to.to.to", "float", "content_x.get_device", "skip_connection_z.to.to.to", "loss_c_adv_d.detach().cpu", "len", "style_sample_x.get_device", "acs_agent.ACSAgent.get_device", "acs_agent.ACSAgent.get_device", "loss_gan_d.detach().cpu", "len", "skip_connection_x.get_device", "loss_c_adv_d.detach", "loss_gan_d.detach"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_enc", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_con_dis", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.sample_z", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_con_dis", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.acs_agent.ACSAgent.multi_class_cross_entropy_with_softmax", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.acs_agent.ACSAgent.multi_class_cross_entropy_with_softmax", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.sample_z", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_gen", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_dom_dis", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_dom_dis", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.sample_z", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to"], ["", "def", "update_discriminator", "(", "self", ",", "x", ",", "y", ",", "domain_code", ",", "acc", ",", "config", ",", "loss_f", ")", ":", "\n", "        ", "r\"\"\"Backward pass on GAN (Discriminator), and content adversarial (Discriminator) losses\n\n        Args:\n            x (torch.Tensor): input batch\n            y (torch.Tensor): label batch\n            domain_code (torch.Tensor) domain code batch\n            acc (mp.eval.accumulator.Accumulator): accumulator holding losses\n            config (dict): configuration dictionary from parsed arguments\n            loss_f (mp.eval.losses.loss_abstract.LossAbstract): loss function for the segmenter\n        \n        Returns:\n            loss_dec (torch.Tensor): discriminator loss\n            acc (mp.eval.accumulator.Accumulator): accumulator holding losses\n        \"\"\"", "\n", "\n", "# content adversarial loss (Discriminator)", "\n", "skip_connections_x", ",", "content_x", ",", "style_sample_x", "=", "self", ".", "model", ".", "forward_enc", "(", "x", ")", "\n", "domain_x", "=", "self", ".", "model", ".", "forward_con_dis", "(", "skip_connections_x", ",", "content_x", ")", "\n", "_", ",", "domain_index", "=", "torch", ".", "max", "(", "domain_code", ",", "dim", "=", "1", ")", "\n", "\n", "content_z", "=", "self", ".", "model", ".", "sample_z", "(", "content_x", ".", "shape", ")", "\n", "if", "content_x", ".", "is_cuda", ":", "\n", "            ", "content_z", "=", "content_z", ".", "to", "(", "content_x", ".", "get_device", "(", ")", ")", "\n", "\n", "", "skip_connections_z", "=", "[", "]", "\n", "for", "skip_connection_x", "in", "skip_connections_x", ":", "\n", "            ", "skip_connection_z", "=", "self", ".", "model", ".", "sample_z", "(", "skip_connection_x", ".", "shape", ")", "\n", "\n", "if", "skip_connection_x", ".", "is_cuda", ":", "\n", "                ", "skip_connection_z", "=", "skip_connection_z", ".", "to", "(", "skip_connection_x", ".", "get_device", "(", ")", ")", "\n", "\n", "", "skip_connections_z", "+=", "[", "skip_connection_z", "]", "\n", "\n", "", "domain_z", "=", "self", ".", "model", ".", "forward_con_dis", "(", "skip_connections_z", ",", "content_z", ")", "\n", "domain_dummy", "=", "torch", ".", "zeros_like", "(", "domain_x", ")", "\n", "domain_dummy", "[", "-", "1", "]", "=", "1", "\n", "loss_c_adv_d_dummy", "=", "self", ".", "multi_class_cross_entropy_with_softmax", "(", "domain_z", ",", "domain_dummy", ")", "\n", "\n", "loss_c_adv_d_real", "=", "self", ".", "multi_class_cross_entropy_with_softmax", "(", "domain_x", ",", "domain_code", ")", "\n", "\n", "loss_c_adv_d", "=", "loss_c_adv_d_real", "+", "loss_c_adv_d_dummy", "\n", "acc", ".", "add", "(", "'loss_c_adv_d'", ",", "float", "(", "loss_c_adv_d", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "x", ")", ")", "\n", "\n", "# GAN loss (Discriminator)", "\n", "z", "=", "self", ".", "model", ".", "sample_z", "(", "style_sample_x", ".", "shape", ")", "\n", "if", "style_sample_x", ".", "is_cuda", ":", "\n", "            ", "z", "=", "z", ".", "to", "(", "style_sample_x", ".", "get_device", "(", ")", ")", "\n", "", "latent_scale_z", "=", "self", ".", "model", ".", "latent_scaler", "(", "z", ")", "\n", "z_hat", "=", "self", ".", "model", ".", "forward_gen", "(", "content_x", ",", "latent_scale_z", ",", "domain_code", ")", "\n", "domain_z_hat", "=", "self", ".", "model", ".", "forward_dom_dis", "(", "z_hat", ",", "domain_code", ")", "\n", "domain_x", "=", "self", ".", "model", ".", "forward_dom_dis", "(", "x", ",", "domain_code", ")", "\n", "\n", "all_ones", "=", "torch", ".", "ones_like", "(", "domain_x", ")", "\n", "all_zeros", "=", "torch", ".", "zeros_like", "(", "domain_z_hat", ")", "\n", "if", "domain_x", ".", "is_cuda", ":", "\n", "            ", "all_ones", "=", "all_ones", ".", "to", "(", "domain_x", ".", "get_device", "(", ")", ")", "\n", "", "if", "domain_z_hat", ".", "is_cuda", ":", "\n", "            ", "all_zeros", "=", "all_zeros", ".", "to", "(", "domain_z_hat", ".", "get_device", "(", ")", ")", "\n", "\n", "", "real_loss", "=", "nn", ".", "functional", ".", "binary_cross_entropy_with_logits", "(", "domain_x", ",", "all_ones", ")", "\n", "fake_loss", "=", "nn", ".", "functional", ".", "binary_cross_entropy_with_logits", "(", "domain_z_hat", ",", "all_zeros", ")", "\n", "\n", "loss_gan_d", "=", "real_loss", "+", "fake_loss", "\n", "acc", ".", "add", "(", "'loss_gan_d'", ",", "float", "(", "loss_gan_d", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "x", ")", ")", "\n", "\n", "# combine losses", "\n", "loss_disc", "=", "config", "[", "'lambda_c_adv'", "]", "*", "loss_c_adv_d", "+", "config", "[", "'lambda_gan'", "]", "*", "loss_gan_d", "\n", "loss_disc", ".", "backward", "(", ")", "\n", "\n", "return", "loss_disc", ",", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.acs_agent.ACSAgent.vae_loss": [[491, 517], ["torch.nn.functional.mse_loss", "torch.nn.functional.mse_loss", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "log_var.exp"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum"], ["", "def", "vae_loss", "(", "self", ",", "recons", ",", "input", ",", "mu", ",", "log_var", ",", "kld_weight", "=", "5e-3", ")", ":", "\n", "        ", "r\"\"\"Computes the VAE loss function.\n        Sources: \n            https://github.com/AntixK/PyTorch-VAE/blob/20c4dfa73dfc36f42970ccc334a42f37ffe08dcc/models/vanilla_vae.py\n            https://github.com/AntixK/PyTorch-VAE/blob/20c4dfa73dfc36f42970ccc334a42f37ffe08dcc/tests/test_vae.py\n        \n        Equation:\n            KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n        \n        Args:\n            recons (torch.Tensor): reconstruction of input batch\n            input (torch.Tensor): input batch\n            mu (float): mean of VAE encoder forward pass\n            log_var (float): log variance of VAE encoder forward pass\n            kld_weight (float): weighting of KL loss w.r.t. recontruction (1.)\n\n        Returns:\n            (dict): {total loss, reconstruction loss, KL loss}\n        \"\"\"", "\n", "\n", "recons_loss", "=", "F", ".", "mse_loss", "(", "recons", ",", "input", ")", "\n", "\n", "kld_loss", "=", "torch", ".", "mean", "(", "-", "0.5", "*", "torch", ".", "sum", "(", "1", "+", "log_var", "-", "mu", "**", "2", "-", "log_var", ".", "exp", "(", ")", ",", "dim", "=", "1", ")", ",", "dim", "=", "0", ")", "\n", "\n", "loss", "=", "recons_loss", "+", "kld_weight", "*", "kld_loss", "\n", "return", "{", "'loss'", ":", "loss", ",", "'Reconstruction_Loss'", ":", "recons_loss", ",", "'KLD'", ":", "-", "kld_loss", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.acs_agent.ACSAgent.multi_class_cross_entropy_with_softmax": [[518, 530], ["torch.Softmax", "torch.Softmax", "torch.log", "torch.log", "torch.log", "torch.log", "torch.Softmax.clamp", "torch.Softmax."], "methods", ["None"], ["", "def", "multi_class_cross_entropy_with_softmax", "(", "self", ",", "prediction", ",", "target", ")", ":", "\n", "        ", "r\"\"\"Stable Multiclass Cross Entropy with Softmax\n\n        Args:\n            prediction (torch.Tensor): network outputs w/ softmax\n            target (torch.Tensor): label OHE\n\n        Returns:\n            (torch.Tensor) computed loss \n        \"\"\"", "\n", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "return", "(", "-", "(", "target", "*", "torch", ".", "log", "(", "softmax", "(", "prediction", ")", ".", "clamp", "(", "min", "=", "1e-08", ",", "max", "=", "1.", "-", "1e-08", ")", ")", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", ")", ".", "mean", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.kd_agent.KDAgent.__init__": [[20, 24], ["mp.agents.segmentation_agent.SegmentationAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "'metrics'", "not", "in", "kwargs", ":", "\n", "            ", "kwargs", "[", "'metrics'", "]", "=", "[", "'ScoreDice'", ",", "'ScoreIoU'", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.kd_agent.KDAgent.train": [[25, 80], ["dict", "range", "kd_agent.KDAgent.model.finish", "kd_agent.KDAgent.perform_training_epoch", "kd_agent.KDAgent.model.unet_scheduler.step", "kd_agent.KDAgent.track_loss", "kd_agent.KDAgent.track_visualization", "kd_agent.KDAgent.track_visualization", "kd_agent.KDAgent.save_state"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.mas.MAS.finish", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.perform_training_epoch", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.track_loss", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.track_visualization", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.track_visualization", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.ExperimentRun.save_state"], ["", "def", "train", "(", "self", ",", "results", ",", "loss_f", ",", "train_dataloader", ",", "test_dataloader", ",", "config", ",", "\n", "init_epoch", "=", "0", ",", "nr_epochs", "=", "100", ",", "run_loss_print_interval", "=", "1", ",", "\n", "eval_datasets", "=", "dict", "(", ")", ",", "eval_interval", "=", "2", ",", "\n", "save_path", "=", "None", ",", "save_interval", "=", "10", ",", "\n", "display_interval", "=", "1", ",", "\n", "resume_epoch", "=", "None", ",", "\n", "device_ids", "=", "[", "0", "]", ")", ":", "\n", "        ", "r\"\"\"Train a model through its agent. Performs training epochs, \n        tracks metrics and saves model states.\n\n        Args:\n            results (mp.eval.result.Result): results object to track progress\n            loss_f (mp.eval.losses.loss_abstract.LossAbstract): loss function for the segmenter\n            train_dataloader (torch.utils.data.DataLoader): dataloader of training set\n            test_dataloader (torch.utils.data.DataLoader): dataloader of test set\n            eval_datasets (torch.utils.data.DataLoader): dataloader of evaluation set\n            config (dict): configuration dictionary from parsed arguments\n            init_epoch (int): initial epoch\n            nr_epochs (int): number of epochs to train for\n            run_loss_print_interval (int) print loss every # epochs\n            eval_interval (int): evaluate model every # epochs\n            save_interval (int): save model every # epochs\n            save_path (str): save path for saving model, etc.\n            display_interval (str): log tensorboard every # epochs\n            resume_epoch (int): resume training at epoch #\n            device_ids (list) device ids of GPUs\n        \"\"\"", "\n", "\n", "self", ".", "agent_state_dict", "[", "'epoch'", "]", "=", "init_epoch", "\n", "\n", "for", "epoch", "in", "range", "(", "init_epoch", ",", "nr_epochs", ")", ":", "\n", "            ", "self", ".", "agent_state_dict", "[", "'epoch'", "]", "=", "epoch", "\n", "\n", "print_run_loss", "=", "(", "epoch", "+", "1", ")", "%", "run_loss_print_interval", "==", "0", "\n", "print_run_loss", "=", "print_run_loss", "and", "self", ".", "verbose", "\n", "acc", "=", "self", ".", "perform_training_epoch", "(", "loss_f", ",", "train_dataloader", ",", "config", ",", "epoch", ",", "\n", "print_run_loss", "=", "print_run_loss", ")", "\n", "\n", "if", "config", "[", "'continual'", "]", ":", "\n", "                ", "self", ".", "model", ".", "unet_scheduler", ".", "step", "(", ")", "\n", "\n", "# Write losses to tensorboard", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "display_interval", "==", "0", ":", "\n", "                ", "self", ".", "track_loss", "(", "acc", ",", "epoch", "+", "1", ",", "config", ")", "\n", "\n", "# Create visualizations and write them to tensorboard", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "display_interval", "==", "0", ":", "\n", "                ", "self", ".", "track_visualization", "(", "train_dataloader", ",", "save_path", ",", "epoch", "+", "1", ",", "config", ",", "'train'", ")", "\n", "self", ".", "track_visualization", "(", "test_dataloader", ",", "save_path", ",", "epoch", "+", "1", ",", "config", ",", "'test'", ")", "\n", "\n", "# Save agent and optimizer state", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "save_interval", "==", "0", "and", "save_path", "is", "not", "None", ":", "\n", "                ", "self", ".", "save_state", "(", "save_path", ",", "epoch", "+", "1", ")", "\n", "\n", "", "", "self", ".", "model", ".", "finish", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.kd_agent.KDAgent.perform_training_epoch": [[81, 139], ["mp.eval.accumulator.Accumulator", "time.time", "tqdm.tqdm.tqdm", "kd_agent.KDAgent.get_inputs_targets", "kd_agent.KDAgent.get_outputs", "kd_agent.KDAgent.model.unet_optim.zero_grad", "loss.backward", "kd_agent.KDAgent.model.unet_optim.step", "mp.eval.accumulator.Accumulator.add", "mp.eval.accumulator.Accumulator.add", "mp.eval.accumulator.Accumulator.add", "print", "loss_f", "kd_agent.KDAgent.get_outputs_simple", "kd_agent.KDAgent.multi_class_cross_entropy_no_softmax", "float", "float", "float", "print", "print", "print", "print", "torch.zeros().to", "torch.zeros", "loss.detach().cpu", "len", "loss_f.detach().cpu", "len", "torch.zeros.detach().cpu", "len", "mp.eval.accumulator.Accumulator.mean", "mp.eval.accumulator.Accumulator.mean", "round", "kd_agent.KDAgent.min", "kd_agent.KDAgent.max", "torch.isnan().any", "targets.min", "targets.max", "torch.isnan().any", "loss_f.get_device", "torch.zeros", "loss.detach", "loss_f.detach", "torch.zeros.detach", "time.time", "torch.isnan", "torch.isnan"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.get_inputs_targets", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.get_outputs", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.kd_agent.KDAgent.get_outputs_simple", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.multi_class_cross_entropy_no_softmax", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean"], ["", "def", "perform_training_epoch", "(", "self", ",", "loss_f", ",", "train_dataloader", ",", "config", ",", "epoch", ",", "\n", "print_run_loss", "=", "False", ")", ":", "\n", "        ", "r\"\"\"Perform a training epoch\n        \n        Args:\n            loss_f (mp.eval.losses.loss_abstract.LossAbstract): loss function for the segmenter\n            train_dataloader (torch.utils.data.DataLoader): dataloader of training set\n            config (dict): configuration dictionary from parsed arguments\n            print_run_loss (boolean): whether to print running loss\n        \n        Returns:\n            acc (mp.eval.accumulator.Accumulator): accumulator holding losses\n        \"\"\"", "\n", "acc", "=", "Accumulator", "(", "'loss'", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "data", "in", "tqdm", "(", "train_dataloader", ",", "disable", "=", "True", ")", ":", "\n", "# Get data", "\n", "            ", "inputs", ",", "targets", "=", "self", ".", "get_inputs_targets", "(", "data", ")", "\n", "\n", "# Forward pass", "\n", "outputs", "=", "self", ".", "get_outputs", "(", "inputs", ")", "\n", "\n", "# Optimization step", "\n", "self", ".", "model", ".", "unet_optim", ".", "zero_grad", "(", ")", "\n", "\n", "try", ":", "\n", "                ", "loss_seg", "=", "loss_f", "(", "outputs", ",", "targets", ")", "\n", "", "except", ":", "\n", "                ", "print", "(", "outputs", ".", "min", "(", ")", ",", "outputs", ".", "max", "(", ")", ")", "\n", "print", "(", "torch", ".", "isnan", "(", "outputs", ")", ".", "any", "(", ")", ")", "\n", "print", "(", "targets", ".", "min", "(", ")", ",", "targets", ".", "max", "(", ")", ")", "\n", "print", "(", "torch", ".", "isnan", "(", "targets", ")", ".", "any", "(", ")", ")", "\n", "\n", "", "if", "self", ".", "model", ".", "unet_old", "!=", "None", ":", "\n", "                ", "outputs_old", "=", "self", ".", "get_outputs_simple", "(", "inputs", ")", "\n", "loss_distill", "=", "self", ".", "multi_class_cross_entropy_no_softmax", "(", "outputs", ",", "outputs_old", ")", "\n", "", "else", ":", "\n", "                ", "if", "loss_seg", ".", "is_cuda", ":", "\n", "                    ", "loss_distill", "=", "torch", ".", "zeros", "(", "1", ")", ".", "to", "(", "loss_seg", ".", "get_device", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "loss_distill", "=", "torch", ".", "zeros", "(", "1", ")", "\n", "\n", "", "", "loss", "=", "loss_seg", "+", "config", "[", "'lambda_d'", "]", "*", "loss_distill", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "self", ".", "model", ".", "unet_optim", ".", "step", "(", ")", "\n", "\n", "acc", ".", "add", "(", "'loss'", ",", "float", "(", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "inputs", ")", ")", "\n", "acc", ".", "add", "(", "'loss_seg'", ",", "float", "(", "loss_seg", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "inputs", ")", ")", "\n", "acc", ".", "add", "(", "'loss_distill'", ",", "float", "(", "loss_distill", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "inputs", ")", ")", "\n", "\n", "# self.model.unet_scheduler.step()", "\n", "\n", "", "if", "print_run_loss", ":", "\n", "            ", "print", "(", "'\\nrunning loss: {} - distill {} - time/epoch {}'", ".", "format", "(", "acc", ".", "mean", "(", "'loss'", ")", ",", "acc", ".", "mean", "(", "'loss_distill'", ")", ",", "round", "(", "time", ".", "time", "(", ")", "-", "start_time", ",", "4", ")", ")", ")", "\n", "\n", "", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.kd_agent.KDAgent.get_inputs_targets": [[140, 152], ["inputs.to", "targets.to", "targets.float"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to"], ["", "def", "get_inputs_targets", "(", "self", ",", "data", ",", "eval", "=", "True", ")", ":", "\n", "        ", "r\"\"\"Prepares a data batch.\n\n        Args:\n            data (tuple): a dataloader item, possibly in cpu\n            eval (boolean): evaluation mode, doesn't return domain code \n            \n        Returns (tuple): preprocessed data in the selected device.\n        \"\"\"", "\n", "inputs", ",", "targets", "=", "data", "\n", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "self", ".", "device", ")", ",", "targets", ".", "to", "(", "self", ".", "device", ")", "\n", "return", "inputs", ",", "targets", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.kd_agent.KDAgent.track_metrics": [[153, 175], ["datasets.items", "mp.eval.evaluate.ds_losses_metrics", "mp.eval.evaluate.ds_losses_metrics.keys", "results.add", "results.add", "print", "mp.eval.evaluate.ds_losses_metrics.keys", "kd_agent.KDAgent.writer_add_scalar", "print"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.ds_losses_metrics", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar"], ["", "def", "track_metrics", "(", "self", ",", "epoch", ",", "results", ",", "loss_f", ",", "datasets", ")", ":", "\n", "        ", "r\"\"\"Tracks metrics. Losses and scores are calculated for each 3D subject, \n        and averaged over the dataset.\n\n        Args:\n            epoch (int):current epoch\n            results (mp.eval.result.Result): results object to track progress\n            loss_f (mp.eval.losses.loss_abstract.LossAbstract): loss function for the segmenter\n            datasets (torch.utils.data.DataLoader): dataloader object to evaluate on\n        \"\"\"", "\n", "for", "ds_name", ",", "ds", "in", "datasets", ".", "items", "(", ")", ":", "\n", "            ", "eval_dict", "=", "ds_losses_metrics", "(", "ds", ",", "self", ",", "loss_f", ",", "self", ".", "metrics", ")", "\n", "for", "metric_key", "in", "eval_dict", ".", "keys", "(", ")", ":", "\n", "                ", "results", ".", "add", "(", "epoch", "=", "epoch", ",", "metric", "=", "'Mean_'", "+", "metric_key", ",", "data", "=", "ds_name", ",", "\n", "value", "=", "eval_dict", "[", "metric_key", "]", "[", "'mean'", "]", ")", "\n", "results", ".", "add", "(", "epoch", "=", "epoch", ",", "metric", "=", "'Std_'", "+", "metric_key", ",", "data", "=", "ds_name", ",", "\n", "value", "=", "eval_dict", "[", "metric_key", "]", "[", "'std'", "]", ")", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "'Epoch {} dataset {}'", ".", "format", "(", "epoch", ",", "ds_name", ")", ")", "\n", "for", "metric_key", "in", "eval_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "self", ".", "writer_add_scalar", "(", "f'metric/{metric_key}/{ds_name}'", ",", "eval_dict", "[", "metric_key", "]", "[", "'mean'", "]", ",", "epoch", ")", "\n", "print", "(", "'{}: {}'", ".", "format", "(", "metric_key", ",", "eval_dict", "[", "metric_key", "]", "[", "'mean'", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.kd_agent.KDAgent.track_loss": [[176, 188], ["kd_agent.KDAgent.writer_add_scalar", "kd_agent.KDAgent.writer_add_scalar", "kd_agent.KDAgent.writer_add_scalar", "acc.mean", "acc.mean", "acc.mean"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean"], ["", "", "", "", "def", "track_loss", "(", "self", ",", "acc", ",", "epoch", ",", "config", ",", "phase", "=", "'train'", ")", ":", "\n", "        ", "r\"\"\"Tracks loss in tensorboard.\n\n        Args:\n            acc (mp.eval.accumulator.Accumulator): accumulator holding losses\n            epoch (int): current epoch\n            config (dict): configuration dictionary from parsed arguments\n            phase (string): either \"test\" or \"train\"\n        \"\"\"", "\n", "self", ".", "writer_add_scalar", "(", "f'loss_{phase}/loss_seg'", ",", "acc", ".", "mean", "(", "'loss_seg'", ")", ",", "epoch", ")", "\n", "self", ".", "writer_add_scalar", "(", "f'loss_{phase}/loss_distill'", ",", "acc", ".", "mean", "(", "'loss_distill'", ")", ",", "epoch", ")", "\n", "self", ".", "writer_add_scalar", "(", "f'loss_{phase}/loss_comb'", ",", "acc", ".", "mean", "(", "'loss'", ")", ",", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.kd_agent.KDAgent.track_visualization": [[189, 235], ["enumerate", "x_i[].unsqueeze", "[].unsqueeze().unsqueeze", "[].unsqueeze().unsqueeze().int", "os.path.join", "os.path.join", "os.path.join", "mp.visualization.visualize_imgs.plot_3d_segmentation", "mp.visualization.visualize_imgs.plot_3d_segmentation", "PIL.Image.open", "torchvision.to_tensor", "kd_agent.KDAgent.writer_add_image", "PIL.Image.open", "torchvision.to_tensor", "kd_agent.KDAgent.writer_add_image", "kd_agent.KDAgent.get_inputs_targets", "kd_agent.KDAgent.get_outputs", "os.path.exists", "os.makedirs", "len", "[].unsqueeze", "[].unsqueeze().unsqueeze", "torch.nonzero", "[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.plot_3d_segmentation", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.plot_3d_segmentation", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_image", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_image", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.get_inputs_targets", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.get_outputs"], ["", "def", "track_visualization", "(", "self", ",", "dataloader", ",", "save_path", ",", "epoch", ",", "config", ",", "phase", "=", "'train'", ")", ":", "\n", "        ", "r\"\"\"Creates visualizations and tracks them in tensorboard.\n\n        Args:\n            dataloader (Dataloader): dataloader to draw sample from\n            save_path (string): path for the images to be saved (one folder up)\n            epoch (int): current epoch\n            config (dict): configuration dictionary from parsed arguments\n            phase (string): either \"test\" or \"train\"\n        \"\"\"", "\n", "for", "imgs", "in", "dataloader", ":", "\n", "            ", "x_i", ",", "y_i", "=", "self", ".", "get_inputs_targets", "(", "imgs", ",", "eval", "=", "False", ")", "\n", "x_i_seg", "=", "self", ".", "get_outputs", "(", "x_i", ")", "\n", "break", "\n", "\n", "# select sample with guaranteed segmentation label", "\n", "", "sample_idx", "=", "0", "\n", "for", "i", ",", "y_", "in", "enumerate", "(", "y_i", ")", ":", "\n", "            ", "if", "len", "(", "torch", ".", "nonzero", "(", "y_", "[", "1", "]", ")", ")", ">", "0", ":", "\n", "                ", "sample_idx", "=", "i", "\n", "break", "\n", "", "", "x_i_img", "=", "x_i", "[", "sample_idx", "]", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "# segmentation", "\n", "x_i_seg", "=", "x_i_seg", "[", "sample_idx", "]", "[", "1", "]", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "threshold", "=", "0.5", "\n", "x_i_seg_mask", "=", "(", "x_i_seg", ">", "threshold", ")", ".", "int", "(", ")", "\n", "y_i_seg_mask", "=", "y_i", "[", "sample_idx", "]", "[", "1", "]", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "int", "(", ")", "\n", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "'..'", ",", "'imgs'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "save_path", ")", "\n", "\n", "", "save_path_pred", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "f'e_{epoch:06d}_{phase}_pred.png'", ")", "\n", "save_path_label", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "f'e_{epoch:06d}_{phase}_label.png'", ")", "\n", "\n", "plot_3d_segmentation", "(", "x_i_img", ",", "x_i_seg_mask", ",", "save_path", "=", "save_path_pred", ",", "img_size", "=", "(", "256", ",", "256", ")", ",", "alpha", "=", "0.5", ")", "\n", "plot_3d_segmentation", "(", "x_i_img", ",", "y_i_seg_mask", ",", "save_path", "=", "save_path_label", ",", "img_size", "=", "(", "256", ",", "256", ")", ",", "alpha", "=", "0.5", ")", "\n", "\n", "image", "=", "Image", ".", "open", "(", "save_path_pred", ")", "\n", "image", "=", "TF", ".", "to_tensor", "(", "image", ")", "\n", "self", ".", "writer_add_image", "(", "f'imgs_{phase}/pred'", ",", "image", ",", "epoch", ")", "\n", "\n", "image", "=", "Image", ".", "open", "(", "save_path_label", ")", "\n", "image", "=", "TF", ".", "to_tensor", "(", "image", ")", "\n", "self", ".", "writer_add_image", "(", "f'imgs_{phase}/label'", ",", "image", ",", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.kd_agent.KDAgent.save_state": [[236, 255], ["os.path.join", "os.path.exists", "os.makedirs", "mp.utils.pytorch.pytorch_load_restore.save_model_state_dataparallel", "mp.utils.load_restore.pkl_dump", "shutil.rmtree"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.save_model_state_dataparallel", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.pkl_dump"], ["", "def", "save_state", "(", "self", ",", "states_path", ",", "epoch", ",", "optimizer", "=", "None", ",", "overwrite", "=", "False", ")", ":", "\n", "        ", "r\"\"\"Saves an agent state. Raises an error if the directory exists and \n        overwrite=False.\n\n        Args:\n            states_path (str): save path for model states\n            epoch (int): current epoch\n            ove\n        \"\"\"", "\n", "if", "states_path", "is", "not", "None", ":", "\n", "            ", "state_name", "=", "f'epoch_{epoch:04d}'", "\n", "state_full_path", "=", "os", ".", "path", ".", "join", "(", "states_path", ",", "state_name", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "state_full_path", ")", ":", "\n", "                ", "if", "not", "overwrite", ":", "\n", "                    ", "raise", "FileExistsError", "\n", "", "shutil", ".", "rmtree", "(", "state_full_path", ")", "\n", "", "os", ".", "makedirs", "(", "state_full_path", ")", "\n", "save_model_state_dataparallel", "(", "self", ".", "model", ",", "'model'", ",", "state_full_path", ")", "\n", "pkl_dump", "(", "self", ".", "agent_state_dict", ",", "'agent_state_dict'", ",", "state_full_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.kd_agent.KDAgent.restore_state": [[256, 283], ["os.path.join", "mp.utils.pytorch.pytorch_load_restore.load_model_state", "mp.utils.load_restore.pkl_load", "os.listdir", "print", "print"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.load_model_state", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.pkl_load"], ["", "", "def", "restore_state", "(", "self", ",", "states_path", ",", "epoch", ",", "optimizer", "=", "None", ")", ":", "\n", "        ", "r\"\"\"Tries to restore a previous agent state, consisting of a model \n        state and the content of agent_state_dict. Returns whether the restore \n        operation  was successful.\n        Args:\n            states_path (str): save path for model states\n            epoch (int): current epoch\n        \"\"\"", "\n", "\n", "if", "epoch", "==", "-", "1", ":", "\n", "            ", "state_name", "=", "os", ".", "listdir", "(", "states_path", ")", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "state_name", "=", "f'epoch_{epoch:04d}'", "\n", "\n", "", "state_full_path", "=", "os", ".", "path", ".", "join", "(", "states_path", ",", "state_name", ")", "\n", "try", ":", "\n", "            ", "correct_load", "=", "load_model_state", "(", "self", ".", "model", ",", "'model'", ",", "state_full_path", ",", "device", "=", "self", ".", "device", ")", "\n", "assert", "correct_load", "\n", "agent_state_dict", "=", "pkl_load", "(", "'agent_state_dict'", ",", "state_full_path", ")", "\n", "assert", "agent_state_dict", "is", "not", "None", "\n", "self", ".", "agent_state_dict", "=", "agent_state_dict", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "'State {} was restored'", ".", "format", "(", "state_name", ")", ")", "\n", "", "return", "True", "\n", "", "except", ":", "\n", "            ", "print", "(", "'State {} could not be restored'", ".", "format", "(", "state_name", ")", ")", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.kd_agent.KDAgent.multi_class_cross_entropy_no_softmax": [[284, 295], ["torch.log"], "methods", ["None"], ["", "", "def", "multi_class_cross_entropy_no_softmax", "(", "self", ",", "prediction", ",", "target", ")", ":", "\n", "        ", "r\"\"\"Stable Multiclass Cross Entropy with Softmax\n\n        Args:\n            prediction (torch.Tensor): network outputs w/ softmax\n            target (torch.Tensor): label OHE\n\n        Returns:\n            (torch.Tensor) computed loss \n        \"\"\"", "\n", "return", "(", "-", "(", "target", "*", "torch", ".", "log", "(", "prediction", ")", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.kd_agent.KDAgent.get_outputs_simple": [[296, 302], ["kd_agent.KDAgent.model.forward_old", "mp.eval.inference.predict.softmax"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.kd.KD.forward_old", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predict.softmax"], ["", "def", "get_outputs_simple", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "r\"\"\"Applies a softmax transformation to the model outputs.\n        \"\"\"", "\n", "outputs", "=", "self", ".", "model", ".", "forward_old", "(", "inputs", ")", "\n", "outputs", "=", "softmax", "(", "outputs", ")", "\n", "return", "outputs", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.autoencoding_agent.AutoencodingAgent.__init__": [[9, 11], ["mp.agents.agent.Agent.__init__"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.autoencoding_agent.AutoencodingAgent.get_inputs_targets": [[12, 21], ["autoencoding_agent.AutoencodingAgent.to", "autoencoding_agent.AutoencodingAgent.model.preprocess_input", "autoencoding_agent.AutoencodingAgent.clone"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_linear.AutoencoderLinear.preprocess_input"], ["", "def", "get_inputs_targets", "(", "self", ",", "data", ")", ":", "\n", "        ", "r\"\"\"The usual dataloaders are used for autoencoders. However, these \n        ignore the target and instead treat he input as target\n        \"\"\"", "\n", "inputs", ",", "targets", "=", "data", "\n", "inputs", "=", "inputs", ".", "to", "(", "self", ".", "device", ")", "\n", "inputs", "=", "self", ".", "model", ".", "preprocess_input", "(", "inputs", ")", "\n", "targets", "=", "inputs", ".", "clone", "(", ")", "\n", "return", "inputs", ",", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.autoencoding_agent.AutoencodingAgent.predict_from_outputs": [[22, 27], ["None"], "methods", ["None"], ["", "def", "predict_from_outputs", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "r\"\"\"No transformation is performed on the outputs, as the goal is to\n        reconstruct the input. Therefore, the output should have the same dim\n        as the input.\"\"\"", "\n", "return", "outputs", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.__init__": [[20, 24], ["mp.agents.segmentation_agent.SegmentationAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "'metrics'", "not", "in", "kwargs", ":", "\n", "            ", "kwargs", "[", "'metrics'", "]", "=", "[", "'ScoreDice'", ",", "'ScoreIoU'", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.train": [[25, 84], ["dict", "range", "mas_agent.MASAgent.track_metrics", "mas_agent.MASAgent.calc_importance_weights", "mas_agent.MASAgent.model.update_importance_weights", "mas_agent.MASAgent.model.finish", "mas_agent.MASAgent.perform_training_epoch", "mas_agent.MASAgent.model.unet_scheduler.step", "mas_agent.MASAgent.track_loss", "mas_agent.MASAgent.track_visualization", "mas_agent.MASAgent.track_visualization", "mas_agent.MASAgent.save_state"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.track_metrics", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.calc_importance_weights", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.mas.MAS.update_importance_weights", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.mas.MAS.finish", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.perform_training_epoch", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.track_loss", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.track_visualization", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.track_visualization", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.ExperimentRun.save_state"], ["", "def", "train", "(", "self", ",", "results", ",", "loss_f", ",", "train_dataloader", ",", "test_dataloader", ",", "config", ",", "\n", "init_epoch", "=", "0", ",", "nr_epochs", "=", "100", ",", "run_loss_print_interval", "=", "1", ",", "\n", "eval_datasets", "=", "dict", "(", ")", ",", "eval_interval", "=", "2", ",", "\n", "save_path", "=", "None", ",", "save_interval", "=", "10", ",", "\n", "display_interval", "=", "1", ",", "\n", "resume_epoch", "=", "None", ",", "\n", "device_ids", "=", "[", "0", "]", ")", ":", "\n", "        ", "r\"\"\"Train a model through its agent. Performs training epochs, \n        tracks metrics and saves model states.\n\n        Args:\n            results (mp.eval.result.Result): results object to track progress\n            loss_f (mp.eval.losses.loss_abstract.LossAbstract): loss function for the segmenter\n            train_dataloader (torch.utils.data.DataLoader): dataloader of training set\n            test_dataloader (torch.utils.data.DataLoader): dataloader of test set\n            eval_datasets (torch.utils.data.DataLoader): dataloader of evaluation set\n            config (dict): configuration dictionary from parsed arguments\n            init_epoch (int): initial epoch\n            nr_epochs (int): number of epochs to train for\n            run_loss_print_interval (int) print loss every # epochs\n            eval_interval (int): evaluate model every # epochs\n            save_interval (int): save model every # epochs\n            save_path (str): save path for saving model, etc.\n            display_interval (str): log tensorboard every # epochs\n            resume_epoch (int): resume training at epoch #\n            device_ids (list) device ids of GPUs\n        \"\"\"", "\n", "\n", "self", ".", "agent_state_dict", "[", "'epoch'", "]", "=", "init_epoch", "\n", "\n", "for", "epoch", "in", "range", "(", "init_epoch", ",", "nr_epochs", ")", ":", "\n", "            ", "self", ".", "agent_state_dict", "[", "'epoch'", "]", "=", "epoch", "\n", "\n", "print_run_loss", "=", "(", "epoch", "+", "1", ")", "%", "run_loss_print_interval", "==", "0", "\n", "print_run_loss", "=", "print_run_loss", "and", "self", ".", "verbose", "\n", "acc", "=", "self", ".", "perform_training_epoch", "(", "loss_f", ",", "train_dataloader", ",", "config", ",", "\n", "print_run_loss", "=", "print_run_loss", ")", "\n", "\n", "if", "config", "[", "'continual'", "]", ":", "\n", "                ", "self", ".", "model", ".", "unet_scheduler", ".", "step", "(", ")", "\n", "\n", "# Write losses to tensorboard", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "display_interval", "==", "0", ":", "\n", "                ", "self", ".", "track_loss", "(", "acc", ",", "epoch", "+", "1", ",", "config", ")", "\n", "\n", "# Create visualizations and write them to tensorboard", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "display_interval", "==", "0", ":", "\n", "                ", "self", ".", "track_visualization", "(", "train_dataloader", ",", "save_path", ",", "epoch", "+", "1", ",", "config", ",", "'train'", ")", "\n", "self", ".", "track_visualization", "(", "test_dataloader", ",", "save_path", ",", "epoch", "+", "1", ",", "config", ",", "'test'", ")", "\n", "\n", "# Save agent and optimizer state", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "save_interval", "==", "0", "and", "save_path", "is", "not", "None", ":", "\n", "                ", "self", ".", "save_state", "(", "save_path", ",", "epoch", "+", "1", ")", "\n", "\n", "", "", "self", ".", "track_metrics", "(", "epoch", "+", "1", ",", "results", ",", "loss_f", ",", "eval_datasets", ")", "\n", "\n", "new_importance_weights", "=", "self", ".", "calc_importance_weights", "(", "train_dataloader", ")", "\n", "self", ".", "model", ".", "update_importance_weights", "(", "new_importance_weights", ")", "\n", "self", ".", "model", ".", "finish", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.perform_training_epoch": [[85, 140], ["mp.eval.accumulator.Accumulator", "time.time", "tqdm.tqdm.tqdm", "mas_agent.MASAgent.get_inputs_targets", "mas_agent.MASAgent.get_outputs", "mas_agent.MASAgent.model.unet_optim.zero_grad", "loss_f", "loss.backward", "mas_agent.MASAgent.model.unet_optim.step", "mp.eval.accumulator.Accumulator.add", "mp.eval.accumulator.Accumulator.add", "mp.eval.accumulator.Accumulator.add", "print", "torch.zeros().to", "torch.zeros", "filter", "filter", "zip", "float", "float", "float", "loss_f.get_device", "mas_agent.MASAgent.model.unet.parameters", "mas_agent.MASAgent.model.unet_old.parameters", "mas_agent.MASAgent.model.unet_old.parameters", "mas_agent.MASAgent.model.unet.parameters", "loss.detach().cpu", "len", "loss_f.detach().cpu", "len", "torch.zeros.detach().cpu", "len", "mp.eval.accumulator.Accumulator.mean", "mp.eval.accumulator.Accumulator.mean", "round", "torch.zeros", "torch.sum", "loss.detach", "loss_f.detach", "torch.zeros.detach", "time.time"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.get_inputs_targets", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.get_outputs", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum"], ["", "def", "perform_training_epoch", "(", "self", ",", "loss_f", ",", "train_dataloader", ",", "config", ",", "\n", "print_run_loss", "=", "False", ")", ":", "\n", "        ", "r\"\"\"Perform a training epoch\n        \n        Args:\n            loss_f (mp.eval.losses.loss_abstract.LossAbstract): loss function for the segmenter\n            train_dataloader (torch.utils.data.DataLoader): dataloader of training set\n            config (dict): configuration dictionary from parsed arguments\n            print_run_loss (boolean): whether to print running loss\n        \n        Returns:\n            acc (mp.eval.accumulator.Accumulator): accumulator holding losses\n        \"\"\"", "\n", "acc", "=", "Accumulator", "(", "'loss'", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "data", "in", "tqdm", "(", "train_dataloader", ",", "disable", "=", "True", ")", ":", "\n", "# Get data", "\n", "            ", "inputs", ",", "targets", "=", "self", ".", "get_inputs_targets", "(", "data", ")", "\n", "\n", "# Forward pass", "\n", "outputs", "=", "self", ".", "get_outputs", "(", "inputs", ")", "\n", "\n", "# Optimization step", "\n", "self", ".", "model", ".", "unet_optim", ".", "zero_grad", "(", ")", "\n", "\n", "loss_seg", "=", "loss_f", "(", "outputs", ",", "targets", ")", "\n", "\n", "if", "loss_seg", ".", "is_cuda", ":", "\n", "                ", "loss_mas", "=", "torch", ".", "zeros", "(", "1", ")", ".", "to", "(", "loss_seg", ".", "get_device", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_mas", "=", "torch", ".", "zeros", "(", "1", ")", "\n", "\n", "", "if", "self", ".", "model", ".", "importance_weights", "!=", "None", "and", "not", "config", "[", "'unet_only'", "]", ":", "\n", "                ", "model_parameters_new", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "self", ".", "model", ".", "unet", ".", "parameters", "(", ")", ")", "\n", "model_parameters_old", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "self", ".", "model", ".", "unet_old", ".", "parameters", "(", ")", ")", "\n", "\n", "for", "param_old", ",", "param_new", ",", "weights", "in", "zip", "(", "self", ".", "model", ".", "unet_old", ".", "parameters", "(", ")", ",", "self", ".", "model", ".", "unet", ".", "parameters", "(", ")", ",", "self", ".", "model", ".", "importance_weights", ")", ":", "\n", "                    ", "if", "param_new", ".", "requires_grad", ":", "\n", "                        ", "loss_mas", "+=", "torch", ".", "sum", "(", "weights", "*", "(", "param_new", "-", "param_old", ")", "**", "2", ")", "/", "self", ".", "model", ".", "n_params_unet", "\n", "\n", "", "", "", "loss", "=", "loss_seg", "+", "config", "[", "'lambda_d'", "]", "*", "loss_mas", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "self", ".", "model", ".", "unet_optim", ".", "step", "(", ")", "\n", "\n", "acc", ".", "add", "(", "'loss'", ",", "float", "(", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "inputs", ")", ")", "\n", "acc", ".", "add", "(", "'loss_seg'", ",", "float", "(", "loss_seg", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "inputs", ")", ")", "\n", "acc", ".", "add", "(", "'loss_mas'", ",", "float", "(", "loss_mas", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "count", "=", "len", "(", "inputs", ")", ")", "\n", "\n", "", "if", "print_run_loss", ":", "\n", "            ", "print", "(", "'\\nrunning loss: {} - mas: {} - time/epoch {}'", ".", "format", "(", "acc", ".", "mean", "(", "'loss'", ")", ",", "acc", ".", "mean", "(", "'loss_mas'", ")", ",", "round", "(", "time", ".", "time", "(", ")", "-", "start_time", ",", "4", ")", ")", ")", "\n", "\n", "", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.get_inputs_targets": [[141, 153], ["inputs.to", "targets.to", "targets.float"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to"], ["", "def", "get_inputs_targets", "(", "self", ",", "data", ",", "eval", "=", "True", ")", ":", "\n", "        ", "r\"\"\"Prepares a data batch.\n\n        Args:\n            data (tuple): a dataloader item, possibly in cpu\n            eval (boolean): evaluation mode, doesn't return domain code \n            \n        Returns (tuple): preprocessed data in the selected device.\n        \"\"\"", "\n", "inputs", ",", "targets", "=", "data", "\n", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "self", ".", "device", ")", ",", "targets", ".", "to", "(", "self", ".", "device", ")", "\n", "return", "inputs", ",", "targets", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.track_metrics": [[154, 176], ["datasets.items", "mp.eval.evaluate.ds_losses_metrics", "mp.eval.evaluate.ds_losses_metrics.keys", "results.add", "results.add", "print", "mp.eval.evaluate.ds_losses_metrics.keys", "mas_agent.MASAgent.writer_add_scalar", "print"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.ds_losses_metrics", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar"], ["", "def", "track_metrics", "(", "self", ",", "epoch", ",", "results", ",", "loss_f", ",", "datasets", ")", ":", "\n", "        ", "r\"\"\"Tracks metrics. Losses and scores are calculated for each 3D subject, \n        and averaged over the dataset.\n\n        Args:\n            epoch (int):current epoch\n            results (mp.eval.result.Result): results object to track progress\n            loss_f (mp.eval.losses.loss_abstract.LossAbstract): loss function for the segmenter\n            datasets (torch.utils.data.DataLoader): dataloader object to evaluate on\n        \"\"\"", "\n", "for", "ds_name", ",", "ds", "in", "datasets", ".", "items", "(", ")", ":", "\n", "            ", "eval_dict", "=", "ds_losses_metrics", "(", "ds", ",", "self", ",", "loss_f", ",", "self", ".", "metrics", ")", "\n", "for", "metric_key", "in", "eval_dict", ".", "keys", "(", ")", ":", "\n", "                ", "results", ".", "add", "(", "epoch", "=", "epoch", ",", "metric", "=", "'Mean_'", "+", "metric_key", ",", "data", "=", "ds_name", ",", "\n", "value", "=", "eval_dict", "[", "metric_key", "]", "[", "'mean'", "]", ")", "\n", "results", ".", "add", "(", "epoch", "=", "epoch", ",", "metric", "=", "'Std_'", "+", "metric_key", ",", "data", "=", "ds_name", ",", "\n", "value", "=", "eval_dict", "[", "metric_key", "]", "[", "'std'", "]", ")", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "'Epoch {} dataset {}'", ".", "format", "(", "epoch", ",", "ds_name", ")", ")", "\n", "for", "metric_key", "in", "eval_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "self", ".", "writer_add_scalar", "(", "f'metric/{metric_key}/{ds_name}'", ",", "eval_dict", "[", "metric_key", "]", "[", "'mean'", "]", ",", "epoch", ")", "\n", "print", "(", "'{}: {}'", ".", "format", "(", "metric_key", ",", "eval_dict", "[", "metric_key", "]", "[", "'mean'", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.track_loss": [[177, 190], ["mas_agent.MASAgent.writer_add_scalar", "mas_agent.MASAgent.writer_add_scalar", "mas_agent.MASAgent.writer_add_scalar", "acc.mean", "acc.mean", "acc.mean"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_scalar", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean"], ["", "", "", "", "def", "track_loss", "(", "self", ",", "acc", ",", "epoch", ",", "config", ",", "phase", "=", "'train'", ")", ":", "\n", "        ", "r\"\"\"Tracks loss in tensorboard.\n\n        Args:\n            acc (mp.eval.accumulator.Accumulator): accumulator holding losses\n            epoch (int): current epoch\n            config (dict): configuration dictionary from parsed arguments\n            phase (string): either \"test\" or \"train\"\n        \"\"\"", "\n", "\n", "self", ".", "writer_add_scalar", "(", "f'loss_{phase}/loss_seg'", ",", "acc", ".", "mean", "(", "'loss_seg'", ")", ",", "epoch", ")", "\n", "self", ".", "writer_add_scalar", "(", "f'loss_{phase}/loss_mas'", ",", "acc", ".", "mean", "(", "'loss_mas'", ")", ",", "epoch", ")", "\n", "self", ".", "writer_add_scalar", "(", "f'loss_{phase}/loss_comb'", ",", "acc", ".", "mean", "(", "'loss'", ")", ",", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.track_visualization": [[191, 237], ["enumerate", "x_i[].unsqueeze", "[].unsqueeze().unsqueeze", "[].unsqueeze().unsqueeze().int", "os.path.join", "os.path.join", "os.path.join", "mp.visualization.visualize_imgs.plot_3d_segmentation", "mp.visualization.visualize_imgs.plot_3d_segmentation", "PIL.Image.open", "torchvision.to_tensor", "mas_agent.MASAgent.writer_add_image", "PIL.Image.open", "torchvision.to_tensor", "mas_agent.MASAgent.writer_add_image", "mas_agent.MASAgent.get_inputs_targets", "mas_agent.MASAgent.get_outputs", "os.path.exists", "os.makedirs", "len", "[].unsqueeze", "[].unsqueeze().unsqueeze", "torch.nonzero", "[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.plot_3d_segmentation", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.visualize_imgs.plot_3d_segmentation", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_image", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.writer_add_image", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.get_inputs_targets", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.get_outputs"], ["", "def", "track_visualization", "(", "self", ",", "dataloader", ",", "save_path", ",", "epoch", ",", "config", ",", "phase", "=", "'train'", ")", ":", "\n", "        ", "r\"\"\"Creates visualizations and tracks them in tensorboard.\n\n        Args:\n            dataloader (Dataloader): dataloader to draw sample from\n            save_path (string): path for the images to be saved (one folder up)\n            epoch (int): current epoch\n            config (dict): configuration dictionary from parsed arguments\n            phase (string): either \"test\" or \"train\"\n        \"\"\"", "\n", "for", "imgs", "in", "dataloader", ":", "\n", "            ", "x_i", ",", "y_i", "=", "self", ".", "get_inputs_targets", "(", "imgs", ",", "eval", "=", "False", ")", "\n", "x_i_seg", "=", "self", ".", "get_outputs", "(", "x_i", ")", "\n", "break", "\n", "\n", "# select sample with guaranteed segmentation label", "\n", "", "sample_idx", "=", "0", "\n", "for", "i", ",", "y_", "in", "enumerate", "(", "y_i", ")", ":", "\n", "            ", "if", "len", "(", "torch", ".", "nonzero", "(", "y_", "[", "1", "]", ")", ")", ">", "0", ":", "\n", "                ", "sample_idx", "=", "i", "\n", "break", "\n", "", "", "x_i_img", "=", "x_i", "[", "sample_idx", "]", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "# segmentation", "\n", "x_i_seg", "=", "x_i_seg", "[", "sample_idx", "]", "[", "1", "]", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "threshold", "=", "0.5", "\n", "x_i_seg_mask", "=", "(", "x_i_seg", ">", "threshold", ")", ".", "int", "(", ")", "\n", "y_i_seg_mask", "=", "y_i", "[", "sample_idx", "]", "[", "1", "]", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "int", "(", ")", "\n", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "'..'", ",", "'imgs'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "save_path", ")", "\n", "\n", "", "save_path_pred", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "f'e_{epoch:06d}_{phase}_pred.png'", ")", "\n", "save_path_label", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "f'e_{epoch:06d}_{phase}_label.png'", ")", "\n", "\n", "plot_3d_segmentation", "(", "x_i_img", ",", "x_i_seg_mask", ",", "save_path", "=", "save_path_pred", ",", "img_size", "=", "(", "256", ",", "256", ")", ",", "alpha", "=", "0.5", ")", "\n", "plot_3d_segmentation", "(", "x_i_img", ",", "y_i_seg_mask", ",", "save_path", "=", "save_path_label", ",", "img_size", "=", "(", "256", ",", "256", ")", ",", "alpha", "=", "0.5", ")", "\n", "\n", "image", "=", "Image", ".", "open", "(", "save_path_pred", ")", "\n", "image", "=", "TF", ".", "to_tensor", "(", "image", ")", "\n", "self", ".", "writer_add_image", "(", "f'imgs_{phase}/pred'", ",", "image", ",", "epoch", ")", "\n", "\n", "image", "=", "Image", ".", "open", "(", "save_path_label", ")", "\n", "image", "=", "TF", ".", "to_tensor", "(", "image", ")", "\n", "self", ".", "writer_add_image", "(", "f'imgs_{phase}/label'", ",", "image", ",", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.save_state": [[238, 257], ["os.path.join", "os.path.exists", "os.makedirs", "mp.utils.pytorch.pytorch_load_restore.save_model_state_dataparallel", "mp.utils.load_restore.pkl_dump", "shutil.rmtree"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.save_model_state_dataparallel", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.pkl_dump"], ["", "def", "save_state", "(", "self", ",", "states_path", ",", "epoch", ",", "optimizer", "=", "None", ",", "overwrite", "=", "False", ")", ":", "\n", "        ", "r\"\"\"Saves an agent state. Raises an error if the directory exists and \n        overwrite=False.\n\n        Args:\n            states_path (str): save path for model states\n            epoch (int): current epoch\n            overwrite (boolean): whether to override existing files\n        \"\"\"", "\n", "if", "states_path", "is", "not", "None", ":", "\n", "            ", "state_name", "=", "f'epoch_{epoch:04d}'", "\n", "state_full_path", "=", "os", ".", "path", ".", "join", "(", "states_path", ",", "state_name", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "state_full_path", ")", ":", "\n", "                ", "if", "not", "overwrite", ":", "\n", "                    ", "raise", "FileExistsError", "\n", "", "shutil", ".", "rmtree", "(", "state_full_path", ")", "\n", "", "os", ".", "makedirs", "(", "state_full_path", ")", "\n", "save_model_state_dataparallel", "(", "self", ".", "model", ",", "'model'", ",", "state_full_path", ")", "\n", "pkl_dump", "(", "self", ".", "agent_state_dict", ",", "'agent_state_dict'", ",", "state_full_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.restore_state": [[258, 285], ["os.path.join", "mp.utils.pytorch.pytorch_load_restore.load_model_state", "mp.utils.load_restore.pkl_load", "os.listdir", "print", "print"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.load_model_state", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.pkl_load"], ["", "", "def", "restore_state", "(", "self", ",", "states_path", ",", "epoch", ",", "optimizer", "=", "None", ")", ":", "\n", "        ", "r\"\"\"Tries to restore a previous agent state, consisting of a model \n        state and the content of agent_state_dict. Returns whether the restore \n        operation  was successful.\n        Args:\n            states_path (str): save path for model states\n            epoch (int): current epoch\n        \"\"\"", "\n", "\n", "if", "epoch", "==", "-", "1", ":", "\n", "            ", "state_name", "=", "os", ".", "listdir", "(", "states_path", ")", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "state_name", "=", "f'epoch_{epoch:04d}'", "\n", "\n", "", "state_full_path", "=", "os", ".", "path", ".", "join", "(", "states_path", ",", "state_name", ")", "\n", "try", ":", "\n", "            ", "correct_load", "=", "load_model_state", "(", "self", ".", "model", ",", "'model'", ",", "state_full_path", ",", "device", "=", "self", ".", "device", ")", "\n", "assert", "correct_load", "\n", "agent_state_dict", "=", "pkl_load", "(", "'agent_state_dict'", ",", "state_full_path", ")", "\n", "assert", "agent_state_dict", "is", "not", "None", "\n", "self", ".", "agent_state_dict", "=", "agent_state_dict", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "'State {} was restored'", ".", "format", "(", "state_name", ")", ")", "\n", "", "return", "True", "\n", "", "except", ":", "\n", "            ", "print", "(", "'State {} could not be restored'", ".", "format", "(", "state_name", ")", ")", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.multi_class_cross_entropy_no_softmax": [[286, 297], ["torch.log"], "methods", ["None"], ["", "", "def", "multi_class_cross_entropy_no_softmax", "(", "self", ",", "prediction", ",", "target", ")", ":", "\n", "        ", "r\"\"\"Stable Multiclass Cross Entropy with Softmax\n\n        Args:\n            prediction (torch.Tensor): network outputs w/ softmax\n            target (torch.Tensor): label OHE\n\n        Returns:\n            (torch.Tensor) computed loss \n        \"\"\"", "\n", "return", "(", "-", "(", "target", "*", "torch", ".", "log", "(", "prediction", ")", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.get_outputs_old": [[298, 312], ["mas_agent.MASAgent.model.forward_old", "mp.eval.inference.predict.softmax().clamp", "mp.eval.inference.predict.softmax"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.kd.KD.forward_old", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predict.softmax"], ["", "def", "get_outputs_old", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "r\"\"\"Stable Multiclass Cross Entropy with Softmax\n\n        Args:\n            prediction (torch.Tensor): network outputs w/ softmax\n            target (torch.Tensor): label OHE\n\n        Returns:\n            (torch.Tensor) computed loss \n        \"\"\"", "\n", "outputs", "=", "self", ".", "model", ".", "forward_old", "(", "inputs", ")", "\n", "# softmax = nn.Softmax(dim=1)", "\n", "outputs", "=", "softmax", "(", "outputs", ")", ".", "clamp", "(", "min", "=", "1e-08", ",", "max", "=", "1.", "-", "1e-08", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.calc_importance_weights": [[313, 359], ["mas_agent.MASAgent.model.unet.parameters", "tqdm.tqdm.tqdm", "range", "mas_agent.MASAgent.get_inputs_targets", "mas_agent.MASAgent.get_outputs", "torch.pow", "torch.pow.mean", "mas_agent.MASAgent.model.unet.zero_grad", "torch.pow.mean.backward", "enumerate", "len", "torch.zeros_like", "torch.sqrt", "mas_agent.MASAgent.model.unet.parameters", "torch.pow", "param.grad.max", "param.grad.max", "param.grad.min", "param.grad.min", "len"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.get_inputs_targets", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.get_outputs", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean"], ["", "def", "calc_importance_weights", "(", "self", ",", "dataloader", ")", ":", "\n", "        ", "r\"\"\"Compute importance weights for MAS\n\n        Source:\n            https://github.com/GT-RIPL/Continual-Learning-Benchmark/blob/master/agents/regularization.py\n\n        Args:\n            dataloader (Dataloader): training dataloader\n        \n        Returns:\n            (torch.Tensor) parameter gradients/importance weights\n        \"\"\"", "\n", "param_grads", "=", "[", "]", "\n", "\n", "for", "param", "in", "self", ".", "model", ".", "unet", ".", "parameters", "(", ")", ":", "\n", "            ", "param_grads", "+=", "[", "torch", ".", "zeros_like", "(", "param", ")", "]", "\n", "", "min", "=", "0", "\n", "max", "=", "0", "\n", "for", "data", "in", "tqdm", "(", "dataloader", ",", "disable", "=", "True", ")", ":", "\n", "# Get data", "\n", "            ", "inputs", ",", "targets", "=", "self", ".", "get_inputs_targets", "(", "data", ")", "\n", "\n", "# Forward pass", "\n", "outputs", "=", "self", ".", "get_outputs", "(", "inputs", ")", "\n", "\n", "# Optimization step", "\n", "# squared l2 norm of outputs", "\n", "outputs", "=", "torch", ".", "pow", "(", "torch", ".", "sqrt", "(", "torch", ".", "pow", "(", "outputs", ",", "2", ")", ")", ",", "2", ")", "\n", "loss", "=", "outputs", ".", "mean", "(", ")", "\n", "\n", "self", ".", "model", ".", "unet", ".", "zero_grad", "(", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "for", "i", ",", "param", "in", "enumerate", "(", "self", ".", "model", ".", "unet", ".", "parameters", "(", ")", ")", ":", "\n", "                ", "if", "param", ".", "grad", ".", "max", "(", ")", ">", "max", ":", "\n", "                    ", "max", "=", "param", ".", "grad", ".", "max", "(", ")", "\n", "", "if", "param", ".", "grad", ".", "min", "(", ")", "<", "min", ":", "\n", "                    ", "min", "=", "param", ".", "grad", ".", "min", "(", ")", "\n", "\n", "", "param_grads", "[", "i", "]", "+=", "param", ".", "grad", "/", "len", "(", "dataloader", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "param_grads", ")", ")", ":", "\n", "            ", "param_grads", "[", "i", "]", "=", "(", "param_grads", "[", "i", "]", "-", "min", ")", "/", "(", "max", "-", "min", ")", "\n", "\n", "", "return", "param_grads", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.cuda.test_cuda.test_cuda": [[4, 11], ["torch.cuda.device_count", "torch.cuda.set_device", "torch.zeros().cuda", "str", "torch.zeros", "str"], "function", ["None"], ["def", "test_cuda", "(", ")", ":", "\n", "    ", "nr_devices", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "assert", "nr_devices", ">", "0", "\n", "device", "=", "nr_devices", "-", "1", "# Last device chosen", "\n", "torch", ".", "cuda", ".", "set_device", "(", "device", ")", "\n", "tensor", "=", "torch", ".", "zeros", "(", "(", "2", ",", "3", ")", ")", ".", "cuda", "(", ")", "\n", "assert", "str", "(", "tensor", ".", "device", ")", "==", "'cuda:'", "+", "str", "(", "device", ")", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiment.test_experiment.test_success": [[9, 25], ["mp.experiments.experiment.Experiment", "mp.experiments.experiment.Experiment.get_run", "mp.eval.result.Result", "mp.eval.result.Result.add", "mp.eval.result.Result.add", "exp.get_run.finish", "os.path.join", "mp.utils.load_restore.load_json", "mp.utils.load_restore.load_json", "os.path.join", "os.path.isfile", "shutil.rmtree", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.Experiment.get_run", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.mas.MAS.finish", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.load_json", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.load_json"], ["def", "test_success", "(", ")", ":", "\n", "    ", "notes", "=", "'A test experiment which is successful'", "\n", "exp", "=", "Experiment", "(", "{", "'test_param'", ":", "2", ",", "'nr_runs'", ":", "1", "}", ",", "name", "=", "'TEST_SUCCESS'", ",", "notes", "=", "notes", ")", "\n", "exp_run", "=", "exp", ".", "get_run", "(", "0", ")", "\n", "res", "=", "Result", "(", "name", "=", "'some_result'", ")", "\n", "res", ".", "add", "(", "1", ",", "'A'", ",", "2.0", ")", "\n", "res", ".", "add", "(", "3", ",", "'A'", ",", "10.0", ")", "\n", "exp_run", ".", "finish", "(", "results", "=", "res", ")", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "join", "(", "storage_path", ",", "'exp'", ")", ",", "'TEST_SUCCESS'", ")", "\n", "exp_review", "=", "load_json", "(", "path", ",", "'review'", ")", "\n", "assert", "exp_review", "[", "'notes'", "]", "==", "notes", "\n", "config", "=", "load_json", "(", "path", ",", "'config'", ")", "\n", "assert", "config", "[", "'test_param'", "]", "==", "2", "\n", "res_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "os", ".", "path", ".", "join", "(", "'0'", ",", "'results'", ")", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "res_path", ",", "'some_result.png'", ")", ")", "\n", "shutil", ".", "rmtree", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiment.test_experiment.test_failure": [[26, 37], ["mp.experiments.experiment.Experiment", "mp.experiments.experiment.Experiment.get_run", "exp.get_run.finish", "os.path.join", "mp.utils.load_restore.load_json", "mp.utils.load_restore.load_json", "shutil.rmtree", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.Experiment.get_run", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.mas.MAS.finish", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.load_json", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.load_json"], ["", "def", "test_failure", "(", ")", ":", "\n", "    ", "notes", "=", "'A test experiment which fails'", "\n", "exp", "=", "Experiment", "(", "{", "'test_param'", ":", "2", ",", "'nr_runs'", ":", "1", "}", ",", "name", "=", "'TEST_FAILURE'", ",", "notes", "=", "notes", ")", "\n", "exp_run", "=", "exp", ".", "get_run", "(", "0", ")", "\n", "exp_run", ".", "finish", "(", "exception", "=", "Exception", ")", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "join", "(", "storage_path", ",", "'exp'", ")", ",", "'TEST_FAILURE'", ")", "\n", "exp_review", "=", "load_json", "(", "path", ",", "'review'", ")", "\n", "assert", "exp_review", "[", "'notes'", "]", "==", "notes", "\n", "exp_run_review", "=", "load_json", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'0'", ")", ",", "'review'", ")", "\n", "assert", "'FAILURE'", "in", "exp_run_review", "[", "'state'", "]", "\n", "shutil", ".", "rmtree", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiment.test_experiment.test_reload": [[38, 49], ["mp.experiments.experiment.Experiment", "mp.eval.result.Result", "mp.experiments.experiment.Experiment", "os.path.join", "shutil.rmtree", "os.path.join"], "function", ["None"], ["", "def", "test_reload", "(", ")", ":", "\n", "    ", "notes", "=", "'A test experiment which is reloaded'", "\n", "# First experiment creation", "\n", "exp", "=", "Experiment", "(", "{", "'test_param'", ":", "2", ",", "'nr_runs'", ":", "1", "}", ",", "name", "=", "'TEST_RELOAD'", ",", "notes", "=", "notes", ")", "\n", "res", "=", "Result", "(", "name", "=", "'some_result'", ")", "\n", "# Experiment reload", "\n", "exp", "=", "Experiment", "(", "name", "=", "'TEST_RELOAD'", ",", "reload_exp", "=", "True", ")", "\n", "assert", "exp", ".", "review", "[", "'notes'", "]", "==", "notes", "\n", "assert", "exp", ".", "config", "[", "'test_param'", "]", "==", "2", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "join", "(", "storage_path", ",", "'exp'", ")", ",", "'TEST_RELOAD'", ")", "\n", "shutil", ".", "rmtree", "(", "path", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiment.test_data_splitting.test_split_instances": [[5, 39], ["instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "mp.data.datasets.dataset.Dataset", "mp.experiments.data_splitting.split_instances", "mp.data.datasets.dataset.Dataset.get_class_dist", "mp.data.datasets.dataset.Dataset.get_class_dist", "mp.experiments.data_splitting.split_instances", "mp.data.datasets.dataset.Dataset.get_class_dist", "mp.data.datasets.dataset.Dataset.get_class_dist", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.experiments.data_splitting.split_instances"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting.split_instances", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_dist", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_dist", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting.split_instances", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_dist", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_dist", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting.split_instances"], ["def", "test_split_instances", "(", ")", ":", "\n", "    ", "instances", "=", "[", "]", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0A'", ",", "y", "=", "0", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1A'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1B'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0B'", ",", "y", "=", "0", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0C'", ",", "y", "=", "0", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1C'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0D'", ",", "y", "=", "0", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0E'", ",", "y", "=", "0", ",", "x_path", "=", "''", ")", ")", "\n", "ds", "=", "Dataset", "(", "name", "=", "None", ",", "classes", "=", "(", "'0'", ",", "'1'", ")", ",", "instances", "=", "instances", ")", "\n", "# Split at 70%", "\n", "ixs_1", ",", "ixs_2", "=", "split_instances", "(", "ds", ",", "0.7", ",", "stratisfied", "=", "True", ",", "exclude_ixs", "=", "[", "3", "]", ")", "\n", "class_dictribution", "=", "ds", ".", "get_class_dist", "(", "ixs_1", ")", "\n", "assert", "class_dictribution", "[", "'0'", "]", "==", "2", "\n", "assert", "class_dictribution", "[", "'1'", "]", "==", "2", "\n", "class_dictribution", "=", "ds", ".", "get_class_dist", "(", "ixs_2", ")", "\n", "assert", "class_dictribution", "[", "'0'", "]", "==", "2", "\n", "assert", "class_dictribution", "[", "'1'", "]", "==", "1", "\n", "# Split at 80%", "\n", "ixs_1", ",", "ixs_2", "=", "split_instances", "(", "ds", ",", "0.8", ",", "stratisfied", "=", "True", ",", "exclude_ixs", "=", "[", "3", "]", ")", "\n", "class_dictribution", "=", "ds", ".", "get_class_dist", "(", "ixs_1", ")", "\n", "assert", "class_dictribution", "[", "'0'", "]", "==", "3", "\n", "assert", "class_dictribution", "[", "'1'", "]", "==", "2", "\n", "class_dictribution", "=", "ds", ".", "get_class_dist", "(", "ixs_2", ")", "\n", "assert", "class_dictribution", "[", "'0'", "]", "==", "1", "\n", "assert", "class_dictribution", "[", "'1'", "]", "==", "1", "\n", "# Split at 90%", "\n", "# not possible because of too few examples of class 0", "\n", "try", ":", "\n", "        ", "ixs_1", ",", "ixs_2", "=", "split_instances", "(", "ds", ",", "0.9", ",", "stratisfied", "=", "True", ")", "\n", "assert", "False", "\n", "", "except", "RuntimeError", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiment.test_data_splitting.test_cross_validation": [[40, 71], ["instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "mp.data.datasets.dataset.Dataset", "mp.experiments.data_splitting.create_instance_folds", "mp.experiments.data_splitting.create_instance_folds", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset.Dataset.get_class_dist", "mp.data.datasets.dataset.Dataset.get_class_dist", "mp.experiments.data_splitting.create_instance_folds", "len", "len"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting.create_instance_folds", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting.create_instance_folds", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_dist", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_dist", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting.create_instance_folds"], ["", "", "def", "test_cross_validation", "(", ")", ":", "\n", "    ", "instances", "=", "[", "]", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0A'", ",", "y", "=", "0", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1A'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1B'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0B'", ",", "y", "=", "0", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0C'", ",", "y", "=", "0", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1C'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0D'", ",", "y", "=", "0", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0E'", ",", "y", "=", "0", ",", "x_path", "=", "''", ")", ")", "\n", "ds", "=", "Dataset", "(", "name", "=", "None", ",", "classes", "=", "(", "'0'", ",", "'1'", ")", ",", "instances", "=", "instances", ")", "\n", "# Split into 2 folds", "\n", "folds", "=", "create_instance_folds", "(", "ds", ",", "k", "=", "2", ",", "exclude_ixs", "=", "[", "3", "]", ",", "stratisfied", "=", "True", ")", "\n", "for", "fold", "in", "folds", ":", "\n", "        ", "assert", "len", "(", "fold", ")", "<", "5", "\n", "class_dictribution", "=", "ds", ".", "get_class_dist", "(", "fold", ")", "\n", "assert", "class_dictribution", "[", "'1'", "]", "==", "1", "or", "class_dictribution", "[", "'1'", "]", "==", "2", "\n", "assert", "class_dictribution", "[", "'0'", "]", "==", "2", "\n", "# Split into 3 folds", "\n", "", "folds", "=", "create_instance_folds", "(", "ds", ",", "k", "=", "3", ",", "exclude_ixs", "=", "[", "3", "]", ",", "stratisfied", "=", "True", ")", "\n", "for", "fold", "in", "folds", ":", "\n", "        ", "assert", "len", "(", "fold", ")", "<", "4", "\n", "class_dictribution", "=", "ds", ".", "get_class_dist", "(", "fold", ")", "\n", "assert", "class_dictribution", "[", "'1'", "]", "==", "1", "\n", "assert", "class_dictribution", "[", "'0'", "]", "==", "1", "or", "class_dictribution", "[", "'0'", "]", "==", "2", "\n", "# Split into 4 folds", "\n", "", "try", ":", "\n", "        ", "folds", "=", "create_instance_folds", "(", "ds", ",", "k", "=", "4", ",", "exclude_ixs", "=", "[", "3", "]", ",", "stratisfied", "=", "True", ")", "\n", "assert", "False", "\n", "", "except", "RuntimeError", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiment.test_data_splitting.test_split_dataset": [[72, 126], ["instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "mp.data.datasets.dataset.Dataset", "mp.experiments.data_splitting.split_dataset", "mp.experiments.data_splitting.split_dataset", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset.Dataset.get_class_dist", "mp.data.datasets.dataset.Dataset.get_class_dist", "mp.data.datasets.dataset.Dataset.get_class_dist", "mp.data.datasets.dataset.Dataset.get_class_dist", "mp.data.datasets.dataset.Dataset.get_class_dist", "mp.data.datasets.dataset.Dataset.get_class_dist", "len", "len", "set"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting.split_dataset", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting.split_dataset", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_dist", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_dist", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_dist", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_dist", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_dist", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_dist"], ["", "", "def", "test_split_dataset", "(", ")", ":", "\n", "    ", "instances", "=", "[", "]", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0A'", ",", "y", "=", "0", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0B'", ",", "y", "=", "0", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0C'", ",", "y", "=", "0", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0D'", ",", "y", "=", "0", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0E'", ",", "y", "=", "0", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1A'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1B'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1C'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1D'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1E'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1F'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1G'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1H'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0A2'", ",", "y", "=", "0", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0B2'", ",", "y", "=", "0", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0C2'", ",", "y", "=", "0", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0D2'", ",", "y", "=", "0", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0E2'", ",", "y", "=", "0", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1A2'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1B2'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1C2'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1D2'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1E2'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1F2'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1G2'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1H2'", ",", "y", "=", "1", ",", "x_path", "=", "''", ")", ")", "\n", "ds", "=", "Dataset", "(", "name", "=", "None", ",", "classes", "=", "(", "'0'", ",", "'1'", ")", ",", "instances", "=", "instances", ")", "\n", "# Split into 2 folds. Then split into train, test and validation sets", "\n", "folds", "=", "split_dataset", "(", "ds", ",", "test_ratio", "=", "0.2", ",", "val_ratio", "=", "0.2", ",", "nr_repetitions", "=", "2", ",", "cross_validation", "=", "True", ")", "\n", "for", "fold", "in", "folds", ":", "\n", "        ", "assert", "len", "(", "set", "(", "fold", "[", "'train'", "]", "+", "fold", "[", "'val'", "]", "+", "fold", "[", "'test'", "]", ")", ")", "==", "len", "(", "fold", "[", "'train'", "]", "+", "fold", "[", "'val'", "]", "+", "fold", "[", "'test'", "]", ")", "\n", "class_dictribution", "=", "ds", ".", "get_class_dist", "(", "fold", "[", "'train'", "]", ")", "\n", "assert", "class_dictribution", "[", "'0'", "]", "==", "4", "\n", "assert", "class_dictribution", "[", "'1'", "]", "==", "6", "\n", "class_dictribution", "=", "ds", ".", "get_class_dist", "(", "fold", "[", "'val'", "]", ")", "\n", "assert", "class_dictribution", "[", "'0'", "]", "==", "1", "\n", "assert", "class_dictribution", "[", "'1'", "]", "==", "2", "\n", "class_dictribution", "=", "ds", ".", "get_class_dist", "(", "fold", "[", "'test'", "]", ")", "\n", "assert", "class_dictribution", "[", "'0'", "]", "==", "5", "\n", "assert", "class_dictribution", "[", "'1'", "]", "==", "8", "\n", "# Repetitions", "\n", "", "splits", "=", "split_dataset", "(", "ds", ",", "test_ratio", "=", "0.2", ",", "val_ratio", "=", "0.2", ",", "nr_repetitions", "=", "3", ",", "cross_validation", "=", "False", ")", "\n", "for", "split", "in", "splits", ":", "\n", "        ", "class_dictribution", "=", "ds", ".", "get_class_dist", "(", "split", "[", "'train'", "]", ")", "\n", "assert", "class_dictribution", "[", "'0'", "]", "==", "6", "\n", "assert", "class_dictribution", "[", "'1'", "]", "==", "10", "\n", "class_dictribution", "=", "ds", ".", "get_class_dist", "(", "split", "[", "'val'", "]", ")", "\n", "assert", "class_dictribution", "[", "'0'", "]", "==", "2", "\n", "assert", "class_dictribution", "[", "'1'", "]", "==", "2", "\n", "class_dictribution", "=", "ds", ".", "get_class_dist", "(", "split", "[", "'test'", "]", ")", "\n", "assert", "class_dictribution", "[", "'0'", "]", "==", "2", "\n", "assert", "class_dictribution", "[", "'1'", "]", "==", "4", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiment.test_data_splitting.test_group_id_division": [[127, 189], ["instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "instances.append", "mp.data.datasets.dataset.Dataset", "mp.experiments.data_splitting.split_dataset", "mp.experiments.data_splitting.split_dataset", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset_classification.ClassificationPathInstance", "mp.data.datasets.dataset.Dataset.get_class_dist", "mp.data.datasets.dataset.Dataset.get_class_dist", "mp.data.datasets.dataset.Dataset.get_class_dist", "mp.data.datasets.dataset.Dataset.get_class_dist", "mp.data.datasets.dataset.Dataset.get_class_dist", "mp.data.datasets.dataset.Dataset.get_class_dist", "len", "len", "set", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting.split_dataset", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting.split_dataset", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_dist", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_dist", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_dist", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_dist", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_dist", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_dist"], ["", "", "def", "test_group_id_division", "(", ")", ":", "\n", "    ", "instances", "=", "[", "]", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0Aa'", ",", "y", "=", "0", ",", "group_id", "=", "'a'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0Bc'", ",", "y", "=", "0", ",", "group_id", "=", "'c'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0Cd'", ",", "y", "=", "0", ",", "group_id", "=", "'d'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0Dd'", ",", "y", "=", "0", ",", "group_id", "=", "'d'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0Ee'", ",", "y", "=", "0", ",", "group_id", "=", "'e'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1Aa'", ",", "y", "=", "1", ",", "group_id", "=", "'a'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1Bg'", ",", "y", "=", "1", ",", "group_id", "=", "'g'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1Cf'", ",", "y", "=", "1", ",", "group_id", "=", "'f'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1Df'", ",", "y", "=", "1", ",", "group_id", "=", "'f'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1Eb'", ",", "y", "=", "1", ",", "group_id", "=", "'b'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1Fb'", ",", "y", "=", "1", ",", "group_id", "=", "'b'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1Gc'", ",", "y", "=", "1", ",", "group_id", "=", "'c'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1Ha'", ",", "y", "=", "1", ",", "group_id", "=", "'a'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0A2a'", ",", "y", "=", "0", ",", "group_id", "=", "'a'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0B2b'", ",", "y", "=", "0", ",", "group_id", "=", "'b'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0C2b'", ",", "y", "=", "0", ",", "group_id", "=", "'b'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0D2c'", ",", "y", "=", "0", ",", "group_id", "=", "'c'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'0E2e'", ",", "y", "=", "0", ",", "group_id", "=", "'e'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1A2g'", ",", "y", "=", "1", ",", "group_id", "=", "'g'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1B2h'", ",", "y", "=", "1", ",", "group_id", "=", "'h'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1C2h'", ",", "y", "=", "1", ",", "group_id", "=", "'h'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1D2e'", ",", "y", "=", "1", ",", "group_id", "=", "'e'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1E2e'", ",", "y", "=", "1", ",", "group_id", "=", "'e'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1F2d'", ",", "y", "=", "1", ",", "group_id", "=", "'d'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1G2c'", ",", "y", "=", "1", ",", "group_id", "=", "'c'", ",", "x_path", "=", "''", ")", ")", "\n", "instances", ".", "append", "(", "ClassificationPathInstance", "(", "name", "=", "'1H2d'", ",", "y", "=", "1", ",", "group_id", "=", "'d'", ",", "x_path", "=", "''", ")", ")", "\n", "ds", "=", "Dataset", "(", "name", "=", "None", ",", "classes", "=", "(", "'0'", ",", "'1'", ")", ",", "instances", "=", "instances", ")", "\n", "# Split into 2 folds. Then split into train, test and validation sets", "\n", "folds", "=", "split_dataset", "(", "ds", ",", "test_ratio", "=", "0.2", ",", "val_ratio", "=", "0.4", ",", "nr_repetitions", "=", "2", ",", "\n", "cross_validation", "=", "True", ",", "respecting_groups", "=", "True", ")", "\n", "for", "fold", "in", "folds", ":", "\n", "        ", "assert", "len", "(", "set", "(", "fold", "[", "'train'", "]", "+", "fold", "[", "'val'", "]", "+", "fold", "[", "'test'", "]", ")", ")", "==", "len", "(", "fold", "[", "'train'", "]", "+", "fold", "[", "'val'", "]", "+", "fold", "[", "'test'", "]", ")", "\n", "class_dictribution", "=", "ds", ".", "get_class_dist", "(", "fold", "[", "'train'", "]", ")", "\n", "assert", "class_dictribution", "[", "'0'", "]", ">=", "2", "\n", "assert", "class_dictribution", "[", "'1'", "]", ">=", "4", "\n", "assert", "len", "(", "[", "instances", "[", "ix", "]", ".", "group_id", "for", "ix", "in", "fold", "[", "'train'", "]", "]", ")", "%", "2", "==", "0", "\n", "class_dictribution", "=", "ds", ".", "get_class_dist", "(", "fold", "[", "'val'", "]", ")", "\n", "assert", "class_dictribution", "[", "'0'", "]", ">=", "2", "\n", "assert", "class_dictribution", "[", "'1'", "]", ">=", "2", "\n", "assert", "len", "(", "[", "instances", "[", "ix", "]", ".", "group_id", "for", "ix", "in", "fold", "[", "'val'", "]", "]", ")", "%", "2", "==", "0", "\n", "class_dictribution", "=", "ds", ".", "get_class_dist", "(", "fold", "[", "'test'", "]", ")", "\n", "assert", "class_dictribution", "[", "'0'", "]", ">=", "4", "\n", "assert", "class_dictribution", "[", "'1'", "]", ">=", "6", "\n", "assert", "len", "(", "[", "instances", "[", "ix", "]", ".", "group_id", "for", "ix", "in", "fold", "[", "'test'", "]", "]", ")", "%", "2", "==", "0", "\n", "# Repetitions", "\n", "", "splits", "=", "split_dataset", "(", "ds", ",", "test_ratio", "=", "0.2", ",", "val_ratio", "=", "0.2", ",", "nr_repetitions", "=", "3", ",", "\n", "cross_validation", "=", "False", ",", "respecting_groups", "=", "True", ")", "\n", "for", "split", "in", "splits", ":", "\n", "        ", "class_dictribution", "=", "ds", ".", "get_class_dist", "(", "split", "[", "'train'", "]", ")", "\n", "assert", "class_dictribution", "[", "'0'", "]", "==", "6", "\n", "assert", "class_dictribution", "[", "'1'", "]", "==", "10", "\n", "assert", "len", "(", "[", "instances", "[", "ix", "]", ".", "group_id", "for", "ix", "in", "fold", "[", "'train'", "]", "]", ")", "%", "2", "==", "0", "\n", "class_dictribution", "=", "ds", ".", "get_class_dist", "(", "split", "[", "'val'", "]", ")", "\n", "assert", "class_dictribution", "[", "'0'", "]", "==", "2", "\n", "assert", "class_dictribution", "[", "'1'", "]", "==", "2", "\n", "assert", "len", "(", "[", "instances", "[", "ix", "]", ".", "group_id", "for", "ix", "in", "fold", "[", "'val'", "]", "]", ")", "%", "2", "==", "0", "\n", "class_dictribution", "=", "ds", ".", "get_class_dist", "(", "split", "[", "'test'", "]", ")", "\n", "assert", "class_dictribution", "[", "'0'", "]", "==", "2", "\n", "assert", "class_dictribution", "[", "'1'", "]", "==", "4", "\n", "assert", "len", "(", "[", "instances", "[", "ix", "]", ".", "group_id", "for", "ix", "in", "fold", "[", "'test'", "]", "]", ")", "%", "2", "==", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.test_result.test_results": [[3, 14], ["mp.eval.result.Result", "mp.eval.result.Result.add", "mp.eval.result.Result.add", "mp.eval.result.Result.add", "mp.eval.result.Result.add", "mp.eval.result.Result.add", "mp.eval.result.Result.get_min_epoch", "mp.eval.result.Result.get_max_epoch", "mp.eval.result.Result.get_epoch_metric", "len", "mp.eval.result.Result.to_pandas"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.get_min_epoch", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.get_max_epoch", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.get_epoch_metric", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.to_pandas"], ["def", "test_results", "(", ")", ":", "\n", "    ", "res", "=", "Result", "(", "name", "=", "'Example'", ")", "\n", "res", ".", "add", "(", "1", ",", "'accuracy'", ",", "0.2", ",", "data", "=", "'example'", ")", "\n", "res", ".", "add", "(", "2", ",", "'accuracy'", ",", "0.3", ",", "data", "=", "'example'", ")", "\n", "res", ".", "add", "(", "3", ",", "'accuracy'", ",", "0.4", ",", "data", "=", "'example'", ")", "\n", "res", ".", "add", "(", "0", ",", "'F1'", ",", "0.5", ",", "data", "=", "'example'", ")", "\n", "res", ".", "add", "(", "3", ",", "'F1'", ",", "0.7", ",", "data", "=", "'example'", ")", "\n", "assert", "res", ".", "get_min_epoch", "(", "metric", "=", "'accuracy'", ",", "data", "=", "'example'", ")", "==", "1", "\n", "assert", "res", ".", "get_max_epoch", "(", "metric", "=", "'F1'", ",", "data", "=", "'example'", ")", "==", "3", "\n", "assert", "res", ".", "get_epoch_metric", "(", "epoch", "=", "2", ",", "metric", "=", "'accuracy'", ",", "data", "=", "'example'", ")", "==", "0.3", "\n", "assert", "len", "(", "res", ".", "to_pandas", "(", ")", ")", "==", "5", "\n", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.test_accumulator.test_acc": [[3, 9], ["mp.eval.accumulator.Accumulator", "range", "mp.eval.accumulator.Accumulator.add", "mp.eval.accumulator.Accumulator.mean", "mp.eval.accumulator.Accumulator.std", "float"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.std"], ["def", "test_acc", "(", ")", ":", "\n", "    ", "acc", "=", "Accumulator", "(", "keys", "=", "[", "'A'", "]", ")", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "        ", "acc", ".", "add", "(", "'A'", ",", "float", "(", "i", ")", ")", "\n", "", "assert", "acc", ".", "mean", "(", "'A'", ")", "==", "2.0", "\n", "assert", "1.41", "<", "acc", ".", "std", "(", "'A'", ")", "<", "1.415", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.dl_losses": [[10, 22], ["mp.eval.accumulator.Accumulator", "agent.get_inputs_targets", "agent.get_outputs", "loss_f.get_evaluation_dict", "loss_f.get_evaluation_dict.items", "mp.eval.accumulator.Accumulator.add", "len"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.get_inputs_targets", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.get_outputs", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossClassWeighted.get_evaluation_dict", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add"], ["def", "dl_losses", "(", "dl", ",", "agent", ",", "loss_f", ")", ":", "\n", "    ", "r\"\"\"Calculate components of the given loss for a Dataloader\"\"\"", "\n", "acc", "=", "Accumulator", "(", ")", "\n", "for", "data", "in", "dl", ":", "\n", "        ", "inputs", ",", "targets", "=", "agent", ".", "get_inputs_targets", "(", "data", ")", "\n", "outputs", "=", "agent", ".", "get_outputs", "(", "inputs", ")", "\n", "# Calculate losses", "\n", "loss_dict", "=", "loss_f", ".", "get_evaluation_dict", "(", "outputs", ",", "targets", ")", "\n", "# Add to the accumulator   ", "\n", "for", "key", ",", "value", "in", "loss_dict", ".", "items", "(", ")", ":", "\n", "            ", "acc", ".", "add", "(", "key", ",", "value", ",", "count", "=", "len", "(", "inputs", ")", ")", "\n", "", "", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.dl_losses_domain": [[23, 35], ["mp.eval.accumulator.Accumulator", "agent.get_inputs_targets", "agent.get_outputs", "loss_f.get_evaluation_dict", "loss_f.get_evaluation_dict.items", "mp.eval.accumulator.Accumulator.add", "len"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.get_inputs_targets", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.get_outputs", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossClassWeighted.get_evaluation_dict", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add"], ["", "def", "dl_losses_domain", "(", "dl", ",", "agent", ",", "loss_f", ")", ":", "\n", "    ", "r\"\"\"Calculate components of the given loss for a Dataloader\"\"\"", "\n", "acc", "=", "Accumulator", "(", ")", "\n", "for", "data", "in", "dl", ":", "\n", "        ", "inputs", ",", "targets", ",", "domain_code", "=", "agent", ".", "get_inputs_targets", "(", "data", ")", "\n", "outputs", "=", "agent", ".", "get_outputs", "(", "inputs", ")", "\n", "# Calculate losses", "\n", "loss_dict", "=", "loss_f", ".", "get_evaluation_dict", "(", "outputs", ",", "targets", ")", "\n", "# Add to the accumulator   ", "\n", "for", "key", ",", "value", "in", "loss_dict", ".", "items", "(", ")", ":", "\n", "            ", "acc", ".", "add", "(", "key", ",", "value", ",", "count", "=", "len", "(", "inputs", ")", ")", "\n", "", "", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.dl_metrics": [[36, 52], ["mp.eval.accumulator.Accumulator", "agent.get_inputs_targets", "agent.predict_from_outputs", "agent.get_outputs", "agent.predict_from_outputs", "mp.eval.metrics.mean_scores.get_mean_scores", "mp.eval.metrics.mean_scores.get_mean_scores.items", "mp.eval.accumulator.Accumulator.add", "len"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.get_inputs_targets", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.autoencoding_agent.AutoencodingAgent.predict_from_outputs", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.get_outputs", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.autoencoding_agent.AutoencodingAgent.predict_from_outputs", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.mean_scores.get_mean_scores", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add"], ["", "def", "dl_metrics", "(", "dl", ",", "agent", ",", "metrics", ")", ":", "\n", "    ", "r\"\"\"Calculate metrics for a Dataloader\"\"\"", "\n", "acc", "=", "Accumulator", "(", ")", "\n", "for", "data", "in", "dl", ":", "\n", "        ", "inputs", ",", "targets", "=", "agent", ".", "get_inputs_targets", "(", "data", ")", "\n", "one_channeled_target", "=", "agent", ".", "predict_from_outputs", "(", "targets", ")", "\n", "outputs", "=", "agent", ".", "get_outputs", "(", "inputs", ")", "\n", "pred", "=", "agent", ".", "predict_from_outputs", "(", "outputs", ")", "\n", "# Calculate metrics", "\n", "scores_dict", "=", "get_mean_scores", "(", "one_channeled_target", ",", "pred", ",", "metrics", "=", "metrics", ",", "\n", "label_names", "=", "agent", ".", "label_names", ",", "\n", "label_weights", "=", "agent", ".", "scores_label_weights", ")", "\n", "# Add to the accumulator      ", "\n", "for", "key", ",", "value", "in", "scores_dict", ".", "items", "(", ")", ":", "\n", "            ", "acc", ".", "add", "(", "key", ",", "value", ",", "count", "=", "len", "(", "inputs", ")", ")", "\n", "", "", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.dl_metrics_domain": [[53, 69], ["mp.eval.accumulator.Accumulator", "agent.get_inputs_targets", "agent.predict_from_outputs", "agent.get_outputs", "agent.predict_from_outputs", "mp.eval.metrics.mean_scores.get_mean_scores", "mp.eval.metrics.mean_scores.get_mean_scores.items", "mp.eval.accumulator.Accumulator.add", "len"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.mas_agent.MASAgent.get_inputs_targets", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.autoencoding_agent.AutoencodingAgent.predict_from_outputs", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.get_outputs", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.autoencoding_agent.AutoencodingAgent.predict_from_outputs", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.mean_scores.get_mean_scores", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add"], ["", "def", "dl_metrics_domain", "(", "dl", ",", "agent", ",", "metrics", ")", ":", "\n", "    ", "r\"\"\"Calculate metrics for a Dataloader\"\"\"", "\n", "acc", "=", "Accumulator", "(", ")", "\n", "for", "data", "in", "dl", ":", "\n", "        ", "inputs", ",", "targets", ",", "domain_code", "=", "agent", ".", "get_inputs_targets", "(", "data", ")", "\n", "one_channeled_target", "=", "agent", ".", "predict_from_outputs", "(", "targets", ")", "\n", "outputs", "=", "agent", ".", "get_outputs", "(", "inputs", ",", "domain_code", ")", "\n", "pred", "=", "agent", ".", "predict_from_outputs", "(", "outputs", ")", "\n", "# Calculate metrics", "\n", "scores_dict", "=", "get_mean_scores", "(", "one_channeled_target", ",", "pred", ",", "metrics", "=", "metrics", ",", "\n", "label_names", "=", "agent", ".", "label_names", ",", "\n", "label_weights", "=", "agent", ".", "scores_label_weights", ")", "\n", "# Add to the accumulator      ", "\n", "for", "key", ",", "value", "in", "scores_dict", ".", "items", "(", ")", ":", "\n", "            ", "acc", ".", "add", "(", "key", ",", "value", ",", "count", "=", "len", "(", "inputs", ")", ")", "\n", "", "", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.ds_losses": [[70, 101], ["dict", "mp.eval.accumulator.Accumulator", "enumerate", "mp.eval.accumulator.Accumulator.get_keys", "ds.get_subject_dataloader", "evaluate.dl_losses", "dl_losses.get_keys", "mp.eval.accumulator.Accumulator.mean", "mp.eval.accumulator.Accumulator.std", "dl_losses.mean", "mp.eval.accumulator.Accumulator.add", "dict"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.get_keys", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.Pytorch3DQueue.get_subject_dataloader", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.dl_losses", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.get_keys", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.std", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add"], ["", "def", "ds_losses", "(", "ds", ",", "agent", ",", "loss_f", ")", ":", "\n", "    ", "r\"\"\"Calculate components of the loss function for a Dataset.\n\n    Args:\n        ds(PytorchDataset): a PytorchDataset\n        agent(Argent): an agent\n        loss_f(LossAbstract): a loss function descending from LossAbstract\n\n    Returns (dict[str -> dict]): {loss -> {subject_name -> value}}}, with 2 \n        additional entries per loss for 'mean' and 'std'. Note that the metric \n        is calculated per dataloader per dataset. So, for instance, the scores \n        for slices in a 2D dataloader are averaged.\n    \"\"\"", "\n", "eval_dict", "=", "dict", "(", ")", "\n", "acc", "=", "Accumulator", "(", ")", "\n", "for", "instance_ix", ",", "instance", "in", "enumerate", "(", "ds", ".", "instances", ")", ":", "\n", "        ", "subject_name", "=", "instance", ".", "name", "\n", "dl", "=", "ds", ".", "get_subject_dataloader", "(", "instance_ix", ")", "\n", "subject_acc", "=", "dl_losses", "(", "dl", ",", "agent", ",", "loss_f", ")", "\n", "# Add to the accumulator and eval_dict", "\n", "for", "loss_key", "in", "subject_acc", ".", "get_keys", "(", ")", ":", "\n", "            ", "value", "=", "subject_acc", ".", "mean", "(", "loss_key", ")", "\n", "acc", ".", "add", "(", "loss_key", ",", "value", ",", "count", "=", "1", ")", "\n", "if", "loss_key", "not", "in", "eval_dict", ":", "\n", "                ", "eval_dict", "[", "loss_key", "]", "=", "dict", "(", ")", "\n", "", "eval_dict", "[", "loss_key", "]", "[", "subject_name", "]", "=", "value", "\n", "# Add mean and std values to the eval_dict", "\n", "", "", "for", "loss_key", "in", "acc", ".", "get_keys", "(", ")", ":", "\n", "        ", "eval_dict", "[", "loss_key", "]", "[", "'mean'", "]", "=", "acc", ".", "mean", "(", "loss_key", ")", "\n", "eval_dict", "[", "loss_key", "]", "[", "'std'", "]", "=", "acc", ".", "std", "(", "loss_key", ")", "\n", "", "return", "eval_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.ds_losses_domain": [[102, 133], ["dict", "mp.eval.accumulator.Accumulator", "enumerate", "mp.eval.accumulator.Accumulator.get_keys", "ds.get_subject_dataloader", "evaluate.dl_losses_domain", "dl_losses_domain.get_keys", "mp.eval.accumulator.Accumulator.mean", "mp.eval.accumulator.Accumulator.std", "dl_losses_domain.mean", "mp.eval.accumulator.Accumulator.add", "dict"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.get_keys", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.Pytorch3DQueue.get_subject_dataloader", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.dl_losses_domain", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.get_keys", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.std", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add"], ["", "def", "ds_losses_domain", "(", "ds", ",", "agent", ",", "loss_f", ")", ":", "\n", "    ", "r\"\"\"Calculate components of the loss function for a Dataset.\n\n    Args:\n        ds(PytorchDataset): a PytorchDataset\n        agent(Argent): an agent\n        loss_f(LossAbstract): a loss function descending from LossAbstract\n\n    Returns (dict[str -> dict]): {loss -> {subject_name -> value}}}, with 2 \n        additional entries per loss for 'mean' and 'std'. Note that the metric \n        is calculated per dataloader per dataset. So, for instance, the scores \n        for slices in a 2D dataloader are averaged.\n    \"\"\"", "\n", "eval_dict", "=", "dict", "(", ")", "\n", "acc", "=", "Accumulator", "(", ")", "\n", "for", "instance_ix", ",", "instance", "in", "enumerate", "(", "ds", ".", "instances", ")", ":", "\n", "        ", "subject_name", "=", "instance", ".", "name", "\n", "dl", "=", "ds", ".", "get_subject_dataloader", "(", "instance_ix", ")", "\n", "subject_acc", "=", "dl_losses_domain", "(", "dl", ",", "agent", ",", "loss_f", ")", "\n", "# Add to the accumulator and eval_dict", "\n", "for", "loss_key", "in", "subject_acc", ".", "get_keys", "(", ")", ":", "\n", "            ", "value", "=", "subject_acc", ".", "mean", "(", "loss_key", ")", "\n", "acc", ".", "add", "(", "loss_key", ",", "value", ",", "count", "=", "1", ")", "\n", "if", "loss_key", "not", "in", "eval_dict", ":", "\n", "                ", "eval_dict", "[", "loss_key", "]", "=", "dict", "(", ")", "\n", "", "eval_dict", "[", "loss_key", "]", "[", "subject_name", "]", "=", "value", "\n", "# Add mean and std values to the eval_dict", "\n", "", "", "for", "loss_key", "in", "acc", ".", "get_keys", "(", ")", ":", "\n", "        ", "eval_dict", "[", "loss_key", "]", "[", "'mean'", "]", "=", "acc", ".", "mean", "(", "loss_key", ")", "\n", "eval_dict", "[", "loss_key", "]", "[", "'std'", "]", "=", "acc", ".", "std", "(", "loss_key", ")", "\n", "", "return", "eval_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.ds_metrics": [[134, 166], ["dict", "mp.eval.accumulator.Accumulator", "enumerate", "mp.eval.accumulator.Accumulator.get_keys", "instance.y.tensor.to", "ds.predictor.get_subject_prediction", "mp.eval.metrics.mean_scores.get_mean_scores", "mp.eval.metrics.mean_scores.get_mean_scores.items", "mp.eval.accumulator.Accumulator.mean", "mp.eval.accumulator.Accumulator.std", "mp.eval.accumulator.Accumulator.add", "dict"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.get_keys", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predictor.GridPredictor.get_subject_prediction", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.mean_scores.get_mean_scores", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.std", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add"], ["", "def", "ds_metrics", "(", "ds", ",", "agent", ",", "metrics", ")", ":", "\n", "    ", "r\"\"\"Calculate metrics for a Dataset.\n\n    Args:\n        ds(PytorchDataset): a PytorchDataset\n        agent(Argent): an agent\n        metrics(list[str]): a list of metric names\n\n    Returns (dict[str -> dict]): {metric -> {subject_name -> value}}}, with 2 \n        additional entries per metric for 'mean' and 'std'.\n    \"\"\"", "\n", "eval_dict", "=", "dict", "(", ")", "\n", "acc", "=", "Accumulator", "(", ")", "\n", "for", "instance_ix", ",", "instance", "in", "enumerate", "(", "ds", ".", "instances", ")", ":", "\n", "        ", "subject_name", "=", "instance", ".", "name", "\n", "target", "=", "instance", ".", "y", ".", "tensor", ".", "to", "(", "agent", ".", "device", ")", "\n", "pred", "=", "ds", ".", "predictor", ".", "get_subject_prediction", "(", "agent", ",", "instance_ix", ")", "\n", "# Calculate metrics", "\n", "scores_dict", "=", "get_mean_scores", "(", "target", ",", "pred", ",", "metrics", "=", "metrics", ",", "\n", "label_names", "=", "agent", ".", "label_names", ",", "\n", "label_weights", "=", "agent", ".", "scores_label_weights", ")", "\n", "# Add to the accumulator and eval_dict   ", "\n", "for", "metric_key", ",", "value", "in", "scores_dict", ".", "items", "(", ")", ":", "\n", "            ", "acc", ".", "add", "(", "metric_key", ",", "value", ",", "count", "=", "1", ")", "\n", "if", "metric_key", "not", "in", "eval_dict", ":", "\n", "                ", "eval_dict", "[", "metric_key", "]", "=", "dict", "(", ")", "\n", "", "eval_dict", "[", "metric_key", "]", "[", "subject_name", "]", "=", "value", "\n", "# Add mean and std values to the eval_dict", "\n", "", "", "for", "metric_key", "in", "acc", ".", "get_keys", "(", ")", ":", "\n", "        ", "eval_dict", "[", "metric_key", "]", "[", "'mean'", "]", "=", "acc", ".", "mean", "(", "metric_key", ")", "\n", "eval_dict", "[", "metric_key", "]", "[", "'std'", "]", "=", "acc", ".", "std", "(", "metric_key", ")", "\n", "", "return", "eval_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.ds_metrics_domain": [[167, 199], ["dict", "mp.eval.accumulator.Accumulator", "enumerate", "mp.eval.accumulator.Accumulator.get_keys", "instance.y.tensor.to", "ds.predictor.get_subject_prediction", "mp.eval.metrics.mean_scores.get_mean_scores", "mp.eval.metrics.mean_scores.get_mean_scores.items", "mp.eval.accumulator.Accumulator.mean", "mp.eval.accumulator.Accumulator.std", "mp.eval.accumulator.Accumulator.add", "dict"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.get_keys", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predictor.GridPredictor.get_subject_prediction", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.mean_scores.get_mean_scores", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.std", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add"], ["", "def", "ds_metrics_domain", "(", "ds", ",", "agent", ",", "metrics", ")", ":", "\n", "    ", "r\"\"\"Calculate metrics for a Dataset.\n\n    Args:\n        ds(PytorchDataset): a PytorchDataset\n        agent(Argent): an agent\n        metrics(list[str]): a list of metric names\n\n    Returns (dict[str -> dict]): {metric -> {subject_name -> value}}}, with 2 \n        additional entries per metric for 'mean' and 'std'.\n    \"\"\"", "\n", "eval_dict", "=", "dict", "(", ")", "\n", "acc", "=", "Accumulator", "(", ")", "\n", "for", "instance_ix", ",", "instance", "in", "enumerate", "(", "ds", ".", "instances", ")", ":", "\n", "        ", "subject_name", "=", "instance", ".", "name", "\n", "target", "=", "instance", ".", "y", ".", "tensor", ".", "to", "(", "agent", ".", "device", ")", "\n", "pred", "=", "ds", ".", "predictor", ".", "get_subject_prediction", "(", "agent", ",", "instance_ix", ")", "\n", "# Calculate metrics", "\n", "scores_dict", "=", "get_mean_scores", "(", "target", ",", "pred", ",", "metrics", "=", "metrics", ",", "\n", "label_names", "=", "agent", ".", "label_names", ",", "\n", "label_weights", "=", "agent", ".", "scores_label_weights", ")", "\n", "# Add to the accumulator and eval_dict   ", "\n", "for", "metric_key", ",", "value", "in", "scores_dict", ".", "items", "(", ")", ":", "\n", "            ", "acc", ".", "add", "(", "metric_key", ",", "value", ",", "count", "=", "1", ")", "\n", "if", "metric_key", "not", "in", "eval_dict", ":", "\n", "                ", "eval_dict", "[", "metric_key", "]", "=", "dict", "(", ")", "\n", "", "eval_dict", "[", "metric_key", "]", "[", "subject_name", "]", "=", "value", "\n", "# Add mean and std values to the eval_dict", "\n", "", "", "for", "metric_key", "in", "acc", ".", "get_keys", "(", ")", ":", "\n", "        ", "eval_dict", "[", "metric_key", "]", "[", "'mean'", "]", "=", "acc", ".", "mean", "(", "metric_key", ")", "\n", "eval_dict", "[", "metric_key", "]", "[", "'std'", "]", "=", "acc", ".", "std", "(", "metric_key", ")", "\n", "", "return", "eval_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.ds_losses_metrics": [[200, 206], ["evaluate.ds_losses", "ds_losses.update", "evaluate.ds_metrics"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.ds_losses", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.update", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.ds_metrics"], ["", "def", "ds_losses_metrics", "(", "ds", ",", "agent", ",", "loss_f", ",", "metrics", ")", ":", "\n", "    ", "r\"\"\"Combination of metrics and losses into one dictionary.\"\"\"", "\n", "eval_dict", "=", "ds_losses", "(", "ds", ",", "agent", ",", "loss_f", ")", "\n", "if", "metrics", ":", "\n", "        ", "eval_dict", ".", "update", "(", "ds_metrics", "(", "ds", ",", "agent", ",", "metrics", ")", ")", "\n", "", "return", "eval_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.ds_losses_metrics_domain": [[207, 213], ["evaluate.ds_losses_domain", "ds_losses_domain.update", "evaluate.ds_metrics_domain"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.ds_losses_domain", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.update", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.evaluate.ds_metrics_domain"], ["", "def", "ds_losses_metrics_domain", "(", "ds", ",", "agent", ",", "loss_f", ",", "metrics", ")", ":", "\n", "    ", "r\"\"\"Combination of metrics and losses into one dictionary.\"\"\"", "\n", "eval_dict", "=", "ds_losses_domain", "(", "ds", ",", "agent", ",", "loss_f", ")", "\n", "if", "metrics", ":", "\n", "        ", "eval_dict", ".", "update", "(", "ds_metrics_domain", "(", "ds", ",", "agent", ",", "metrics", ")", ")", "\n", "", "return", "eval_dict", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.__init__": [[9, 13], ["dict", "accumulator.Accumulator.init"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.init"], ["    ", "def", "__init__", "(", "self", ",", "keys", "=", "None", ")", ":", "\n", "        ", "self", ".", "values", "=", "dict", "(", ")", "\n", "if", "keys", "is", "not", "None", ":", "\n", "            ", "self", ".", "init", "(", "keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.update": [[14, 18], ["acc.values.items"], "methods", ["None"], ["", "", "def", "update", "(", "self", ",", "acc", ")", ":", "\n", "        ", "for", "key", ",", "value", "in", "acc", ".", "values", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "not", "in", "self", ".", "values", ":", "\n", "                ", "self", ".", "values", "[", "key", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.init": [[19, 22], ["None"], "methods", ["None"], ["", "", "", "def", "init", "(", "self", ",", "keys", ")", ":", "\n", "        ", "for", "key", "in", "keys", ":", "\n", "            ", "self", ".", "values", "[", "key", "]", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.ensure_key": [[23, 26], ["None"], "methods", ["None"], ["", "", "def", "ensure_key", "(", "self", ",", "key", ")", ":", "\n", "        ", "if", "key", "not", "in", "self", ".", "values", ":", "\n", "            ", "self", ".", "values", "[", "key", "]", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.add": [[27, 35], ["accumulator.Accumulator.ensure_key", "isinstance", "range", "float", "accumulator.Accumulator.values[].append", "value.detach().cpu", "value.detach"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.ensure_key"], ["", "", "def", "add", "(", "self", ",", "key", ",", "value", ",", "count", "=", "1", ")", ":", "\n", "        ", "self", ".", "ensure_key", "(", "key", ")", "\n", "if", "isinstance", "(", "value", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "np_value", "=", "float", "(", "value", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "np_value", "=", "value", "\n", "", "for", "_", "in", "range", "(", "count", ")", ":", "\n", "            ", "self", ".", "values", "[", "key", "]", ".", "append", "(", "np_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean": [[36, 38], ["numpy.mean"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean"], ["", "", "def", "mean", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "np", ".", "mean", "(", "self", ".", "values", "[", "key", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.std": [[39, 41], ["numpy.std"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.std"], ["", "def", "std", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "np", ".", "std", "(", "self", ".", "values", "[", "key", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum": [[42, 44], ["accumulator.Accumulator.sum"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum"], ["", "def", "sum", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "sum", "(", "self", ".", "values", "[", "key", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.get_keys": [[45, 47], ["sorted", "list", "accumulator.Accumulator.values.keys"], "methods", ["None"], ["", "def", "get_keys", "(", "self", ")", ":", "\n", "        ", "return", "sorted", "(", "list", "(", "self", ".", "values", ".", "keys", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.ExperimentResults.__init__": [[11, 13], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "global_result_lst", ",", "epoch_result_lst", ")", ":", "\n", "        ", "pass", "\n", "# TODO", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.__init__": [[17, 20], ["dict"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "name", "=", "'Results'", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "results", "=", "dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add": [[21, 34], ["isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "dict", "dict"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "epoch", ",", "metric", ",", "value", ",", "data", "=", "'train'", ")", ":", "\n", "        ", "r\"\"\"Add a new result entry.\"\"\"", "\n", "assert", "isinstance", "(", "epoch", ",", "int", ")", "\n", "assert", "isinstance", "(", "metric", ",", "str", ")", "\n", "if", "isinstance", "(", "data", ",", "tuple", ")", ":", "\n", "            ", "data", "=", "'_'", ".", "join", "(", "data", ")", "\n", "", "assert", "isinstance", "(", "data", ",", "str", ")", "\n", "assert", "isinstance", "(", "value", ",", "float", ")", "or", "isinstance", "(", "value", ",", "int", ")", "\n", "if", "metric", "not", "in", "self", ".", "results", ":", "\n", "            ", "self", ".", "results", "[", "metric", "]", "=", "dict", "(", ")", "\n", "", "if", "epoch", "not", "in", "self", ".", "results", "[", "metric", "]", ":", "\n", "            ", "self", ".", "results", "[", "metric", "]", "[", "epoch", "]", "=", "dict", "(", ")", "\n", "", "self", ".", "results", "[", "metric", "]", "[", "epoch", "]", "[", "data", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.get_epoch_metric": [[35, 42], ["None"], "methods", ["None"], ["", "def", "get_epoch_metric", "(", "self", ",", "epoch", ",", "metric", ",", "data", "=", "'train'", ")", ":", "\n", "        ", "r\"\"\"Get the value for a metric and epoch.\"\"\"", "\n", "try", ":", "\n", "            ", "value", "=", "self", ".", "results", "[", "metric", "]", "[", "epoch", "]", "[", "data", "]", "\n", "return", "value", "\n", "", "except", "Exception", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.to_pandas": [[43, 52], ["pandas.DataFrame", "result.Result.results.keys", "result.Result.results[].keys", "[].keys"], "methods", ["None"], ["", "", "def", "to_pandas", "(", "self", ")", ":", "\n", "        ", "r\"\"\"Pandas representation of results.\"\"\"", "\n", "data", "=", "[", "[", "metric", ",", "epoch", ",", "data", ",", "\n", "self", ".", "results", "[", "metric", "]", "[", "epoch", "]", "[", "data", "]", "]", "\n", "for", "metric", "in", "self", ".", "results", ".", "keys", "(", ")", "\n", "for", "epoch", "in", "self", ".", "results", "[", "metric", "]", ".", "keys", "(", ")", "\n", "for", "data", "in", "self", ".", "results", "[", "metric", "]", "[", "epoch", "]", ".", "keys", "(", ")", "]", "\n", "df", "=", "pd", ".", "DataFrame", "(", "data", ",", "columns", "=", "[", "'Metric'", ",", "'Epoch'", ",", "'Data'", ",", "'Value'", "]", ")", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.get_min_epoch": [[53, 56], ["min", "result.Result.results[].keys"], "methods", ["None"], ["", "def", "get_min_epoch", "(", "self", ",", "metric", ",", "data", "=", "'val'", ")", ":", "\n", "        ", "r\"\"\"Get the earliest epoch for which there is an entry.\"\"\"", "\n", "return", "min", "(", "self", ".", "results", "[", "metric", "]", ".", "keys", "(", ")", ",", "key", "=", "lambda", "e", ":", "self", ".", "results", "[", "metric", "]", "[", "e", "]", "[", "data", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.get_max_epoch": [[57, 60], ["max", "result.Result.results[].keys"], "methods", ["None"], ["", "def", "get_max_epoch", "(", "self", ",", "metric", ",", "data", "=", "'val'", ")", ":", "\n", "        ", "r\"\"\"Get the latest epoch for which there is an entry.\"\"\"", "\n", "return", "max", "(", "self", ".", "results", "[", "metric", "]", ".", "keys", "(", ")", ",", "key", "=", "lambda", "e", ":", "self", ".", "results", "[", "metric", "]", "[", "e", "]", "[", "data", "]", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.test_predict.test_argmax_pred": [[5, 14], ["torch.tensor", "torch.tensor", "mp.eval.inference.predict.arg_max().numpy", "torch.tensor.numpy", "mp.eval.inference.predict.arg_max", "torch.tensor.numpy"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predict.arg_max"], ["def", "test_argmax_pred", "(", ")", ":", "\n", "    ", "output", "=", "torch", ".", "tensor", "(", "[", "[", "[", "[", "0.3", ",", "0.7", "]", ",", "[", "0.2", ",", "0.1", "]", "]", ",", "[", "[", "8.", ",", ".0", "]", ",", "[", ".03", ",", "0.4", "]", "]", ",", "\n", "[", "[", "5.7", ",", ".1", "]", ",", "[", ".55", ",", "0.45", "]", "]", "]", ",", "[", "[", "[", "0.3", ",", "0.7", "]", ",", "[", "0.2", ",", "0.1", "]", "]", ",", "[", "[", "8.", ",", ".0", "]", ",", "\n", "[", ".03", ",", "0.4", "]", "]", ",", "[", "[", "5.7", ",", ".1", "]", ",", "[", ".55", ",", "0.45", "]", "]", "]", "]", ")", "\n", "target", "=", "torch", ".", "tensor", "(", "[", "[", "[", "1", ",", "0", "]", ",", "[", "2", ",", "2", "]", "]", ",", "[", "[", "1", ",", "0", "]", ",", "[", "2", ",", "2", "]", "]", "]", ")", "\n", "assert", "output", ".", "numpy", "(", ")", ".", "shape", "==", "(", "2", ",", "3", ",", "2", ",", "2", ")", "\n", "pred", "=", "arg_max", "(", "output", ")", ".", "numpy", "(", ")", "\n", "assert", "pred", ".", "shape", "==", "(", "2", ",", "2", ",", "2", ")", "\n", "assert", "(", "pred", "==", "target", ".", "numpy", "(", ")", ")", ".", "all", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.test_predict.test_argmax_another_channel_output": [[15, 23], ["torch.tensor", "torch.tensor", "mp.eval.inference.predict.arg_max().numpy", "torch.tensor.numpy", "mp.eval.inference.predict.arg_max", "torch.tensor.numpy"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predict.arg_max"], ["", "def", "test_argmax_another_channel_output", "(", ")", ":", "\n", "    ", "output", "=", "torch", ".", "tensor", "(", "[", "[", "[", "0.3", ",", "0.7", "]", ",", "[", "0.2", ",", "0.1", "]", "]", ",", "[", "[", "8.", ",", ".0", "]", ",", "[", ".03", ",", "0.4", "]", "]", ",", "\n", "[", "[", "5.7", ",", ".1", "]", ",", "[", ".55", ",", "0.45", "]", "]", "]", ")", "\n", "target", "=", "torch", ".", "tensor", "(", "[", "[", "1", ",", "0", "]", ",", "[", "2", ",", "2", "]", "]", ")", "\n", "assert", "output", ".", "numpy", "(", ")", ".", "shape", "==", "(", "3", ",", "2", ",", "2", ")", "\n", "pred", "=", "arg_max", "(", "output", ",", "channel_dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "assert", "pred", ".", "shape", "==", "(", "2", ",", "2", ")", "\n", "assert", "(", "pred", "==", "target", ".", "numpy", "(", ")", ")", ".", "all", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.test_predict.test_softmax": [[24, 33], ["torch.tensor", "mp.eval.inference.predict.softmax().numpy", "mp.eval.inference.predict.softmax", "abs", "sum"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predict.softmax", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum"], ["", "def", "test_softmax", "(", ")", ":", "\n", "    ", "output", "=", "torch", ".", "tensor", "(", "[", "[", "[", "[", "3.", ",", "1.", "]", ",", "[", "0.2", ",", "0.05", "]", "]", ",", "[", "[", "4.", ",", ".0", "]", ",", "[", "0.8", ",", "0.4", "]", "]", ",", "\n", "[", "[", "3.", ",", "9.", "]", ",", "[", "0.", ",", "0.45", "]", "]", "]", ",", "[", "[", "[", "3.", ",", "1.", "]", ",", "[", "0.2", ",", "0.05", "]", "]", ",", "[", "[", "4.", ",", ".0", "]", ",", "[", "0.8", ",", "0.4", "]", "]", ",", "\n", "[", "[", "3.", ",", "9.", "]", ",", "[", "0.", ",", "0.45", "]", "]", "]", "]", ")", "\n", "softmaxed_output", "=", "softmax", "(", "output", ")", ".", "numpy", "(", ")", "\n", "assert", "softmaxed_output", ".", "shape", "==", "(", "2", ",", "3", ",", "2", ",", "2", ")", "\n", "for", "k", "in", "[", "0", ",", "1", "]", ":", "\n", "        ", "for", "i", ",", "j", "in", "[", "(", "0", ",", "0", ")", ",", "(", "0", ",", "1", ")", ",", "(", "1", ",", "0", ")", ",", "(", "1", ",", "1", ")", "]", ":", "\n", "            ", "assert", "abs", "(", "1", "-", "sum", "(", "x", "[", "i", "]", "[", "j", "]", "for", "x", "in", "softmaxed_output", "[", "k", "]", ")", ")", "<", "0.0001", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.test_predict.test_softmax_another_channel_output": [[34, 41], ["torch.tensor", "mp.eval.inference.predict.softmax().numpy", "mp.eval.inference.predict.softmax", "abs", "sum"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predict.softmax", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum"], ["", "", "", "def", "test_softmax_another_channel_output", "(", ")", ":", "\n", "    ", "output", "=", "torch", ".", "tensor", "(", "[", "[", "[", "3.", ",", "1.", "]", ",", "[", "0.2", ",", "0.05", "]", "]", ",", "[", "[", "4.", ",", ".0", "]", ",", "[", "0.8", ",", "0.4", "]", "]", ",", "\n", "[", "[", "3.", ",", "9.", "]", ",", "[", "0.", ",", "0.45", "]", "]", "]", ")", "\n", "softmaxed_output", "=", "softmax", "(", "output", ",", "channel_dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "assert", "softmaxed_output", ".", "shape", "==", "(", "3", ",", "2", ",", "2", ")", "\n", "for", "i", ",", "j", "in", "[", "(", "0", ",", "0", ")", ",", "(", "0", ",", "1", ")", ",", "(", "1", ",", "0", ")", ",", "(", "1", ",", "1", ")", "]", ":", "\n", "        ", "assert", "abs", "(", "1", "-", "sum", "(", "x", "[", "i", "]", "[", "j", "]", "for", "x", "in", "softmaxed_output", ")", ")", "<", "0.0001", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.test_predict.test_per_label_channel_to_pred": [[42, 64], ["torch.tensor", "a.unsqueeze.unsqueeze", "mp.data.pytorch.transformation.per_label_channel", "mp.eval.inference.predict.arg_max().numpy", "mp.eval.inference.predict.arg_max", "a.unsqueeze.numpy"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.per_label_channel", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predict.arg_max"], ["", "", "def", "test_per_label_channel_to_pred", "(", ")", ":", "\n", "    ", "A_1", "=", "[", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "1", ",", "3", ",", "3", ",", "0", ",", "1", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "3", ",", "1", ",", "1", ",", "2", ",", "2", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "1", ",", "1", ",", "2", ",", "2", "]", "]", "\n", "A_2", "=", "[", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "3", ",", "3", ",", "3", "]", ",", "\n", "[", "2", ",", "2", ",", "1", ",", "1", ",", "1", ",", "1", ",", "0", "]", "]", "\n", "A_3", "=", "[", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "2", ",", "0", ",", "1", ",", "1", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "2", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", "]", "\n", "A_4", "=", "[", "[", "1", ",", "1", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "2", ",", "2", ",", "0", "]", ",", "\n", "[", "0", ",", "2", ",", "0", ",", "0", ",", "2", ",", "2", ",", "0", "]", ",", "\n", "[", "0", ",", "2", ",", "0", ",", "0", ",", "3", ",", "3", ",", "3", "]", "]", "\n", "a", "=", "torch", ".", "tensor", "(", "[", "A_1", ",", "A_2", ",", "A_3", ",", "A_4", "]", ")", "\n", "a", "=", "a", ".", "unsqueeze", "(", "0", ")", "\n", "per_label_channel_a", "=", "per_label_channel", "(", "a", ",", "nr_labels", "=", "4", ",", "channel_dim", "=", "0", ")", "\n", "a_pred", "=", "arg_max", "(", "per_label_channel_a", ",", "channel_dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "assert", "(", "a", ".", "numpy", "(", ")", "==", "a_pred", ")", ".", "all", "(", ")", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predictor.Predictor.__init__": [[22, 27], ["len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "instances", ",", "size", "=", "(", "1", ",", "56", ",", "56", ",", "10", ")", ",", "norm", "=", "None", ")", ":", "\n", "        ", "self", ".", "instances", "=", "instances", "\n", "assert", "len", "(", "size", ")", ">", "2", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "norm", "=", "norm", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predictor.Predictor.transform_subject": [[28, 33], ["predictor.Predictor.norm"], "methods", ["None"], ["", "def", "transform_subject", "(", "self", ",", "subject", ")", ":", "\n", "        ", "r\"\"\"Apply normalization strategy to subject.\"\"\"", "\n", "if", "self", ".", "norm", "is", "not", "None", ":", "\n", "            ", "subject", "=", "self", ".", "norm", "(", "subject", ")", "\n", "", "return", "subject", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predictor.Predictor.get_subject": [[34, 40], ["copy.deepcopy", "predictor.Predictor.load", "predictor.Predictor.transform_subject", "predictor.Predictor.instances[].get_subject"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSegmnetationDataset.transform_subject", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_segmentation.SegmentationInstance.get_subject"], ["", "def", "get_subject", "(", "self", ",", "subject_ix", ")", ":", "\n", "        ", "r\"\"\"Copy and load a TorchIO subject.\"\"\"", "\n", "subject", "=", "copy", ".", "deepcopy", "(", "self", ".", "instances", "[", "subject_ix", "]", ".", "get_subject", "(", ")", ")", "\n", "subject", ".", "load", "(", ")", "\n", "subject", "=", "self", ".", "transform_subject", "(", "subject", ")", "\n", "return", "subject", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predictor.Predictor.get_subject_prediction": [[41, 44], ["None"], "methods", ["None"], ["", "def", "get_subject_prediction", "(", "self", ",", "agent", ",", "subject_ix", ")", ":", "\n", "        ", "r\"\"\"Get a prediction for a 3D subject.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predictor.Predictor2D.__init__": [[49, 52], ["predictor.Predictor.__init__"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "resize", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "resize", "=", "resize", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predictor.Predictor2D.get_subject_prediction": [[53, 82], ["predictor.Predictor2D.get_subject", "predictor.Predictor2D.x.tensor.permute", "torch.stack", "pred.permute.permute.permute", "torch.no_grad", "range", "len", "mp.resize_2d().to", "torch.unsqueeze", "agent.predict().float", "pred.permute.permute.append", "mp.centre_crop_pad_2d().to", "torch.unsqueeze", "agent.predict().float", "pred.permute.permute.append", "mp.resize_2d", "mp.centre_crop_pad_2d", "mp.resize_2d", "agent.predict", "mp.centre_crop_pad_2d", "agent.predict"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_segmentation.SegmentationInstance.get_subject", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.resize_2d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.centre_crop_pad_2d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.resize_2d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.predict", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.centre_crop_pad_2d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.predict"], ["", "def", "get_subject_prediction", "(", "self", ",", "agent", ",", "subject_ix", ")", ":", "\n", "\n", "        ", "subject", "=", "self", ".", "get_subject", "(", "subject_ix", ")", "\n", "\n", "# Slides first", "\n", "x", "=", "subject", ".", "x", ".", "tensor", ".", "permute", "(", "3", ",", "0", ",", "1", ",", "2", ")", "\n", "# Get original size", "\n", "original_size", "=", "subject", "[", "'y'", "]", ".", "data", ".", "shape", "\n", "original_size_2d", "=", "original_size", "[", ":", "3", "]", "\n", "\n", "pred", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "slice_idx", "in", "range", "(", "len", "(", "x", ")", ")", ":", "\n", "                ", "if", "self", ".", "resize", ":", "\n", "                    ", "inputs", "=", "trans", ".", "resize_2d", "(", "x", "[", "slice_idx", "]", ",", "size", "=", "self", ".", "size", ")", ".", "to", "(", "agent", ".", "device", ")", "\n", "inputs", "=", "torch", ".", "unsqueeze", "(", "inputs", ",", "0", ")", "\n", "slice_pred", "=", "agent", ".", "predict", "(", "inputs", ")", ".", "float", "(", ")", "\n", "pred", ".", "append", "(", "trans", ".", "resize_2d", "(", "slice_pred", ",", "size", "=", "original_size_2d", ",", "label", "=", "True", ")", ")", "\n", "", "else", ":", "\n", "                    ", "inputs", "=", "trans", ".", "centre_crop_pad_2d", "(", "x", "[", "slice_idx", "]", ",", "size", "=", "self", ".", "size", ")", ".", "to", "(", "agent", ".", "device", ")", "\n", "inputs", "=", "torch", ".", "unsqueeze", "(", "inputs", ",", "0", ")", "\n", "slice_pred", "=", "agent", ".", "predict", "(", "inputs", ")", ".", "float", "(", ")", "\n", "pred", ".", "append", "(", "trans", ".", "centre_crop_pad_2d", "(", "slice_pred", ",", "size", "=", "original_size_2d", ")", ")", "\n", "\n", "# Merge slices and rotate so depth last", "\n", "", "", "", "pred", "=", "torch", ".", "stack", "(", "pred", ",", "dim", "=", "0", ")", "\n", "pred", "=", "pred", ".", "permute", "(", "1", ",", "2", ",", "3", ",", "0", ")", "\n", "assert", "original_size", "==", "pred", ".", "shape", "\n", "return", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predictor.Predictor3D.__init__": [[87, 90], ["predictor.Predictor.__init__"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "resize", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "resize", "=", "resize", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predictor.Predictor3D.get_subject_prediction": [[91, 117], ["predictor.Predictor3D.get_subject", "mp.resize_3d().to", "torch.unsqueeze", "mp.resize_3d", "mp.centre_crop_pad_3d().to", "torch.unsqueeze", "mp.centre_crop_pad_3d", "torch.no_grad", "agent.predict().float", "torch.no_grad", "agent.predict().float", "mp.resize_3d", "mp.centre_crop_pad_3d", "agent.predict", "agent.predict"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_segmentation.SegmentationInstance.get_subject", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.resize_3d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.centre_crop_pad_3d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.resize_3d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.centre_crop_pad_3d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.predict", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.predict"], ["", "def", "get_subject_prediction", "(", "self", ",", "agent", ",", "subject_ix", ")", ":", "\n", "        ", "subject", "=", "self", ".", "get_subject", "(", "subject_ix", ")", "\n", "\n", "x", "=", "subject", "[", "'x'", "]", ".", "data", "\n", "# Get original label size", "\n", "original_size", "=", "subject", "[", "'y'", "]", ".", "data", ".", "shape", "\n", "\n", "\n", "if", "self", ".", "resize", ":", "\n", "# Resize to appropiate model size and make prediction", "\n", "            ", "x", "=", "trans", ".", "resize_3d", "(", "x", ",", "size", "=", "self", ".", "size", ")", ".", "to", "(", "agent", ".", "device", ")", "\n", "x", "=", "torch", ".", "unsqueeze", "(", "x", ",", "0", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "pred", "=", "agent", ".", "predict", "(", "x", ")", ".", "float", "(", ")", "\n", "# Restore prediction to original size", "\n", "", "pred", "=", "trans", ".", "resize_3d", "(", "pred", ",", "size", "=", "original_size", ",", "label", "=", "True", ")", "\n", "\n", "", "else", ":", "\n", "# Crop or pad instead of interpolating", "\n", "            ", "x", "=", "trans", ".", "centre_crop_pad_3d", "(", "x", ",", "size", "=", "self", ".", "size", ")", ".", "to", "(", "agent", ".", "device", ")", "\n", "x", "=", "torch", ".", "unsqueeze", "(", "x", ",", "0", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "pred", "=", "agent", ".", "predict", "(", "x", ")", ".", "float", "(", ")", "\n", "", "pred", "=", "trans", ".", "centre_crop_pad_3d", "(", "pred", ",", "size", "=", "original_size", ")", "\n", "", "assert", "original_size", "==", "pred", ".", "shape", "\n", "return", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predictor.GridPredictor.__init__": [[122, 127], ["predictor.Predictor.__init__"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "patch_overlap", "=", "(", "0", ",", "0", ",", "0", ")", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "assert", "patch_overlap", "[", "2", "]", "==", "0", "# Otherwise, have gotten wrong overlap", "\n", "self", ".", "patch_overlap", "=", "patch_overlap", "\n", "self", ".", "patch_size", "=", "self", ".", "size", "[", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predictor.GridPredictor.get_subject_prediction": [[128, 154], ["predictor.GridPredictor.get_subject", "torchio.inference.GridSampler", "torch.utils.data.DataLoader", "torchio.inference.GridAggregator", "torchio.inference.GridAggregator.get_output_tensor().to", "torch.no_grad", "[].to", "patches_batch[].to", "agent.predict", "torch.unsqueeze", "torchio.inference.GridAggregator.add_batch", "torchio.inference.GridAggregator.get_output_tensor"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_segmentation.SegmentationInstance.get_subject", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.agents.agent.Agent.predict"], ["", "def", "get_subject_prediction", "(", "self", ",", "agent", ",", "subject_ix", ")", ":", "\n", "\n", "        ", "subject", "=", "self", ".", "get_subject", "(", "subject_ix", ")", "\n", "original_size", "=", "subject", "[", "'y'", "]", ".", "data", ".", "shape", "\n", "\n", "grid_sampler", "=", "torchio", ".", "inference", ".", "GridSampler", "(", "\n", "sample", "=", "subject", ",", "\n", "patch_size", "=", "self", ".", "patch_size", ",", "\n", "patch_overlap", "=", "self", ".", "patch_overlap", ")", "\n", "\n", "# Make sure the correct transformations are performed before predicting", "\n", "patch_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "grid_sampler", ",", "batch_size", "=", "5", ")", "\n", "patch_aggregator", "=", "torchio", ".", "inference", ".", "GridAggregator", "(", "grid_sampler", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "patches_batch", "in", "patch_loader", ":", "\n", "                ", "input_tensor", "=", "patches_batch", "[", "'x'", "]", "[", "torchio", ".", "DATA", "]", ".", "to", "(", "agent", ".", "device", ")", "\n", "locations", "=", "patches_batch", "[", "torchio", ".", "LOCATION", "]", ".", "to", "(", "agent", ".", "device", ")", "\n", "pred", "=", "agent", ".", "predict", "(", "input_tensor", ")", "\n", "# Add dimension for channel, which is not in final output", "\n", "pred", "=", "torch", ".", "unsqueeze", "(", "pred", ",", "1", ")", "\n", "\n", "patch_aggregator", ".", "add_batch", "(", "pred", ",", "locations", ")", "\n", "", "", "output", "=", "patch_aggregator", ".", "get_output_tensor", "(", ")", ".", "to", "(", "agent", ".", "device", ")", "\n", "\n", "assert", "original_size", "==", "output", ".", "shape", "\n", "return", "output", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predict.arg_max": [[8, 11], ["torch.argmax"], "function", ["None"], ["def", "arg_max", "(", "output", ",", "channel_dim", "=", "1", ")", ":", "\n", "    ", "r\"\"\"Select the class with highest probability.\"\"\"", "\n", "return", "torch", ".", "argmax", "(", "output", ",", "dim", "=", "channel_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predict.softmax": [[12, 16], ["torch.nn.Softmax", "torch.nn.Softmax."], "function", ["None"], ["", "def", "softmax", "(", "output", ",", "channel_dim", "=", "1", ")", ":", "\n", "    ", "r\"\"\"Softmax outputs so that the vlues add up to 1.\"\"\"", "\n", "f", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "channel_dim", ")", "\n", "return", "f", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predict.confidence": [[18, 22], ["None"], "function", ["None"], ["", "def", "confidence", "(", "softmaxed_output", ",", "channel_dim", "=", "1", ")", ":", "\n", "    ", "r\"\"\"Returns the confidence for each voxel (the highest value along the \n    channel dimension).\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predict.ensable_prediction": [[23, 25], ["None"], "function", ["None"], ["", "def", "ensable_prediction", "(", ")", ":", "\n", "    ", "pass", "\n", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.test_metrics_segmentation.test_tp_tn_fn_fp": [[49, 54], ["mp.eval.metrics.mean_scores.get_tp_tn_fn_fp_segmentation", "mp.eval.metrics.mean_scores.get_tp_tn_fn_fp_segmentation", "mp.eval.metrics.mean_scores.get_tp_tn_fn_fp_segmentation", "mp.eval.metrics.mean_scores.get_tp_tn_fn_fp_segmentation"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.mean_scores.get_tp_tn_fn_fp_segmentation", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.mean_scores.get_tp_tn_fn_fp_segmentation", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.mean_scores.get_tp_tn_fn_fp_segmentation", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.mean_scores.get_tp_tn_fn_fp_segmentation"], ["def", "test_tp_tn_fn_fp", "(", ")", ":", "\n", "    ", "assert", "get_tp_tn_fn_fp_segmentation", "(", "a", ",", "b", ",", "0", ")", "==", "(", "64", ",", "20", ",", "9", ",", "19", ")", "\n", "assert", "get_tp_tn_fn_fp_segmentation", "(", "a", ",", "b", ",", "1", ")", "==", "(", "7", ",", "91", ",", "9", ",", "5", ")", "\n", "assert", "get_tp_tn_fn_fp_segmentation", "(", "a", ",", "b", ",", "2", ")", "==", "(", "8", ",", "94", ",", "6", ",", "4", ")", "\n", "assert", "get_tp_tn_fn_fp_segmentation", "(", "a", ",", "b", ",", "3", ")", "==", "(", "2", ",", "100", ",", "7", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.test_metrics_segmentation.test_dice_iou": [[55, 60], ["mp.eval.metrics.mean_scores.get_mean_scores", "target_scores.items", "abs"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.mean_scores.get_mean_scores"], ["", "def", "test_dice_iou", "(", ")", ":", "\n", "    ", "scores", "=", "get_mean_scores", "(", "a", ",", "b", ",", "metrics", "=", "[", "'ScoreDice'", ",", "'ScoreIoU'", "]", ",", "label_names", "=", "[", "'0'", ",", "'1'", ",", "'2'", ",", "'3'", "]", ")", "\n", "target_scores", "=", "{", "'ScoreDice'", ":", "0.555", ",", "'ScoreDice[0]'", ":", "0.820", ",", "'ScoreDice[1]'", ":", "0.5", ",", "'ScoreDice[2]'", ":", "0.615", ",", "'ScoreDice[3]'", ":", "0.286", ",", "'ScoreIoU'", ":", "0.410", ",", "'ScoreIoU[0]'", ":", "0.696", ",", "'ScoreIoU[1]'", ":", "0.333", ",", "'ScoreIoU[2]'", ":", "0.444", ",", "'ScoreIoU[3]'", ":", "0.167", "}", "\n", "for", "key", ",", "value", "in", "target_scores", ".", "items", "(", ")", ":", "\n", "        ", "assert", "abs", "(", "value", "-", "scores", "[", "key", "]", ")", "<=", "0.01", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.test_metrics_segmentation.test_weighted_metrics": [[61, 71], ["mp.eval.metrics.mean_scores.get_mean_scores", "target_scores.items", "mp.eval.metrics.mean_scores.get_mean_scores", "target_scores.items", "abs", "abs"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.mean_scores.get_mean_scores", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.mean_scores.get_mean_scores"], ["", "", "def", "test_weighted_metrics", "(", ")", ":", "\n", "    ", "scores", "=", "get_mean_scores", "(", "a", ",", "b", ",", "metrics", "=", "[", "'ScoreDice'", ",", "'ScoreIoU'", "]", ",", "label_names", "=", "[", "'0'", ",", "'1'", ",", "'2'", ",", "'3'", "]", ",", "label_weights", "=", "{", "'0'", ":", "2", ",", "'1'", ":", "1", ",", "'2'", ":", "0", ",", "'3'", ":", "1", "}", ")", "\n", "target_scores", "=", "{", "'ScoreDice'", ":", "0.607", ",", "'ScoreDice[0]'", ":", "0.820", ",", "'ScoreDice[1]'", ":", "0.5", ",", "'ScoreDice[2]'", ":", "0.615", ",", "'ScoreDice[3]'", ":", "0.286", ",", "'ScoreIoU'", ":", "0.473", ",", "'ScoreIoU[0]'", ":", "0.696", ",", "'ScoreIoU[1]'", ":", "0.333", ",", "'ScoreIoU[2]'", ":", "0.444", ",", "'ScoreIoU[3]'", ":", "0.167", "}", "\n", "for", "key", ",", "value", "in", "target_scores", ".", "items", "(", ")", ":", "\n", "        ", "assert", "abs", "(", "value", "-", "scores", "[", "key", "]", ")", "<=", "0.01", "\n", "\n", "", "scores", "=", "get_mean_scores", "(", "a", ",", "b", ",", "metrics", "=", "[", "'ScoreDice'", ",", "'ScoreIoU'", "]", ",", "label_names", "=", "[", "'0'", ",", "'1'", ",", "'2'", ",", "'3'", "]", ",", "label_weights", "=", "{", "'0'", ":", "0.2", ",", "'1'", ":", "0.1", ",", "'2'", ":", "0", ",", "'3'", ":", "0.1", "}", ")", "\n", "target_scores", "=", "{", "'ScoreDice'", ":", "0.607", ",", "'ScoreDice[0]'", ":", "0.820", ",", "'ScoreDice[1]'", ":", "0.5", ",", "'ScoreDice[2]'", ":", "0.615", ",", "'ScoreDice[3]'", ":", "0.286", ",", "'ScoreIoU'", ":", "0.473", ",", "'ScoreIoU[0]'", ":", "0.696", ",", "'ScoreIoU[1]'", ":", "0.333", ",", "'ScoreIoU[2]'", ":", "0.444", ",", "'ScoreIoU[3]'", ":", "0.167", "}", "\n", "for", "key", ",", "value", "in", "target_scores", ".", "items", "(", ")", ":", "\n", "        ", "assert", "abs", "(", "value", "-", "scores", "[", "key", "]", ")", "<=", "0.01", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.test_metrics_segmentation.test_batched_tp_tn_fn_fp": [[72, 77], ["mp.eval.metrics.mean_scores.get_tp_tn_fn_fp_segmentation", "mp.eval.metrics.mean_scores.get_tp_tn_fn_fp_segmentation", "mp.eval.metrics.mean_scores.get_tp_tn_fn_fp_segmentation", "mp.eval.metrics.mean_scores.get_tp_tn_fn_fp_segmentation"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.mean_scores.get_tp_tn_fn_fp_segmentation", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.mean_scores.get_tp_tn_fn_fp_segmentation", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.mean_scores.get_tp_tn_fn_fp_segmentation", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.mean_scores.get_tp_tn_fn_fp_segmentation"], ["", "", "def", "test_batched_tp_tn_fn_fp", "(", ")", ":", "\n", "    ", "assert", "get_tp_tn_fn_fp_segmentation", "(", "a_batch", ",", "b_batch", ",", "0", ")", "==", "(", "64", "*", "3", ",", "20", "*", "3", ",", "9", "*", "3", ",", "19", "*", "3", ")", "\n", "assert", "get_tp_tn_fn_fp_segmentation", "(", "a_batch", ",", "b_batch", ",", "1", ")", "==", "(", "7", "*", "3", ",", "91", "*", "3", ",", "9", "*", "3", ",", "5", "*", "3", ")", "\n", "assert", "get_tp_tn_fn_fp_segmentation", "(", "a_batch", ",", "b_batch", ",", "2", ")", "==", "(", "8", "*", "3", ",", "94", "*", "3", ",", "6", "*", "3", ",", "4", "*", "3", ")", "\n", "assert", "get_tp_tn_fn_fp_segmentation", "(", "a_batch", ",", "b_batch", ",", "3", ")", "==", "(", "2", "*", "3", ",", "100", "*", "3", ",", "7", "*", "3", ",", "3", "*", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.test_metrics_segmentation.test_batched_metrics": [[78, 93], ["mp.eval.metrics.mean_scores.get_mean_scores", "target_scores.items", "mp.eval.metrics.mean_scores.get_mean_scores", "target_scores.items", "mp.eval.metrics.mean_scores.get_mean_scores", "target_scores.items", "abs", "abs", "abs"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.mean_scores.get_mean_scores", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.mean_scores.get_mean_scores", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.mean_scores.get_mean_scores"], ["", "def", "test_batched_metrics", "(", ")", ":", "\n", "    ", "scores", "=", "get_mean_scores", "(", "a_batch", ",", "b_batch", ",", "metrics", "=", "[", "'ScoreDice'", ",", "'ScoreIoU'", "]", ",", "label_names", "=", "[", "'0'", ",", "'1'", ",", "'2'", ",", "'3'", "]", ",", "label_weights", "=", "{", "'0'", ":", "2", ",", "'1'", ":", "1", ",", "'2'", ":", "0", ",", "'3'", ":", "1", "}", ")", "\n", "target_scores", "=", "{", "'ScoreDice'", ":", "0.607", ",", "'ScoreDice[0]'", ":", "0.820", ",", "'ScoreDice[1]'", ":", "0.5", ",", "'ScoreDice[2]'", ":", "0.615", ",", "'ScoreDice[3]'", ":", "0.286", ",", "'ScoreIoU'", ":", "0.473", ",", "'ScoreIoU[0]'", ":", "0.696", ",", "'ScoreIoU[1]'", ":", "0.333", ",", "'ScoreIoU[2]'", ":", "0.444", ",", "'ScoreIoU[3]'", ":", "0.167", "}", "\n", "for", "key", ",", "value", "in", "target_scores", ".", "items", "(", ")", ":", "\n", "        ", "assert", "abs", "(", "value", "-", "scores", "[", "key", "]", ")", "<=", "0.01", "\n", "\n", "", "scores", "=", "get_mean_scores", "(", "a_batch", ",", "b_batch", ",", "metrics", "=", "[", "'ScoreDice'", ",", "'ScoreIoU'", "]", ",", "label_names", "=", "[", "'0'", ",", "'1'", ",", "'2'", ",", "'3'", "]", ",", "label_weights", "=", "{", "'0'", ":", "2", ",", "'1'", ":", "1", ",", "'2'", ":", "0", ",", "'3'", ":", "1", "}", ")", "\n", "target_scores", "=", "{", "'ScoreDice'", ":", "0.607", ",", "'ScoreDice[0]'", ":", "0.820", ",", "'ScoreDice[1]'", ":", "0.5", ",", "'ScoreDice[2]'", ":", "0.615", ",", "'ScoreDice[3]'", ":", "0.286", ",", "'ScoreIoU'", ":", "0.473", ",", "'ScoreIoU[0]'", ":", "0.696", ",", "'ScoreIoU[1]'", ":", "0.333", ",", "'ScoreIoU[2]'", ":", "0.444", ",", "'ScoreIoU[3]'", ":", "0.167", "}", "\n", "for", "key", ",", "value", "in", "target_scores", ".", "items", "(", ")", ":", "\n", "        ", "assert", "abs", "(", "value", "-", "scores", "[", "key", "]", ")", "<=", "0.01", "\n", "\n", "", "scores", "=", "get_mean_scores", "(", "a_batch", ",", "b_batch", ",", "metrics", "=", "[", "'ScoreDice'", ",", "'ScoreIoU'", "]", ",", "label_names", "=", "[", "'0'", ",", "'1'", ",", "'2'", ",", "'3'", "]", ",", "label_weights", "=", "{", "'0'", ":", "0.2", ",", "'1'", ":", "0.1", ",", "'2'", ":", "0", ",", "'3'", ":", "0.1", "}", ")", "\n", "target_scores", "=", "{", "'ScoreDice'", ":", "0.607", ",", "'ScoreDice[0]'", ":", "0.820", ",", "'ScoreDice[1]'", ":", "0.5", ",", "'ScoreDice[2]'", ":", "0.615", ",", "'ScoreDice[3]'", ":", "0.286", ",", "'ScoreIoU'", ":", "0.473", ",", "'ScoreIoU[0]'", ":", "0.696", ",", "'ScoreIoU[1]'", ":", "0.333", ",", "'ScoreIoU[2]'", ":", "0.444", ",", "'ScoreIoU[3]'", ":", "0.167", "}", "\n", "for", "key", ",", "value", "in", "target_scores", ".", "items", "(", ")", ":", "\n", "        ", "assert", "abs", "(", "value", "-", "scores", "[", "key", "]", ")", "<=", "0.01", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.mean_scores.get_tp_tn_fn_fp_segmentation": [[9, 24], ["torch.zeros().to", "torch.ones().to", "torch.where", "torch.where", "torch.where().sum", "torch.where().sum", "torch.where().sum", "torch.where().sum", "int", "int", "int", "int", "torch.zeros", "torch.ones", "torch.where", "torch.where", "torch.where", "torch.where"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum"], ["def", "get_tp_tn_fn_fp_segmentation", "(", "target", ",", "pred", ",", "class_ix", "=", "1", ")", ":", "\n", "    ", "r\"\"\"Get TP, TN, FN and FP pixel values for segmentation.\"\"\"", "\n", "assert", "target", ".", "shape", "+", "pred", ".", "shape", "\n", "device", ",", "shape", "=", "target", ".", "device", ",", "target", ".", "shape", "\n", "zeros", "=", "torch", ".", "zeros", "(", "shape", ")", ".", "to", "(", "device", ")", "\n", "ones", "=", "torch", ".", "ones", "(", "shape", ")", ".", "to", "(", "device", ")", "\n", "target_class", "=", "torch", ".", "where", "(", "target", "==", "class_ix", ",", "ones", ",", "zeros", ")", "\n", "pred_class", "=", "torch", ".", "where", "(", "pred", "==", "class_ix", ",", "ones", ",", "zeros", ")", "\n", "tp", "=", "torch", ".", "where", "(", "target_class", "==", "1", ",", "pred_class", ",", "zeros", ")", ".", "sum", "(", ")", "\n", "tn", "=", "torch", ".", "where", "(", "target_class", "==", "0", ",", "1", "-", "pred_class", ",", "zeros", ")", ".", "sum", "(", ")", "\n", "fn", "=", "torch", ".", "where", "(", "target_class", "==", "1", ",", "1", "-", "pred_class", ",", "zeros", ")", ".", "sum", "(", ")", "\n", "fp", "=", "torch", ".", "where", "(", "pred_class", "==", "1", ",", "1", "-", "target_class", ",", "zeros", ")", ".", "sum", "(", ")", "\n", "tp", ",", "tn", ",", "fn", ",", "fp", "=", "int", "(", "tp", ")", ",", "int", "(", "tn", ")", ",", "int", "(", "fn", ")", ",", "int", "(", "fp", ")", "\n", "#assert int(ones.sum()) == tp+tn+fn+fp", "\n", "return", "tp", ",", "tn", ",", "fn", ",", "fp", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.mean_scores.get_mean_scores": [[25, 52], ["enumerate", "metrics.keys", "dict", "mean_scores.get_tp_tn_fn_fp_segmentation", "metrics.items", "getattr", "metric_f.eval", "sum", "sum", "list", "label_weights.values", "scores[].items"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.mean_scores.get_tp_tn_fn_fp_segmentation", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.scores.ScoreSpecificity.eval", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum"], ["", "def", "get_mean_scores", "(", "target", ",", "pred", ",", "metrics", "=", "[", "'ScoreDice'", ",", "'ScoreIoU'", "]", ",", "\n", "label_names", "=", "[", "'background'", ",", "'class 1'", "]", ",", "label_weights", "=", "None", ",", "\n", "segmentation", "=", "True", ")", ":", "\n", "    ", "r\"\"\"Returns the scores per label, as well as the (weighted) mean, such as\n    to avoid considering \"don't care\" classes. The weights don't have to be \n    normalized.\n    \"\"\"", "\n", "scores", "=", "{", "metric", ":", "dict", "(", ")", "for", "metric", "in", "metrics", "}", "\n", "# Calculate metric values per each class", "\n", "metrics", "=", "{", "metric", ":", "getattr", "(", "score_defs", ",", "metric", ")", "(", ")", "for", "metric", "in", "metrics", "}", "\n", "for", "label_nr", ",", "label_name", "in", "enumerate", "(", "label_names", ")", ":", "\n", "# TODO: enable also for classification", "\n", "        ", "tp", ",", "tn", ",", "fn", ",", "fp", "=", "get_tp_tn_fn_fp_segmentation", "(", "target", ",", "pred", ",", "class_ix", "=", "label_nr", ")", "\n", "for", "metric_key", ",", "metric_f", "in", "metrics", ".", "items", "(", ")", ":", "\n", "            ", "score", "=", "metric_f", ".", "eval", "(", "tp", ",", "tn", ",", "fn", ",", "fp", ")", "\n", "scores", "[", "metric_key", "+", "'['", "+", "label_name", "+", "']'", "]", "=", "score", "\n", "scores", "[", "metric_key", "]", "[", "label_name", "]", "=", "score", "\n", "# Calculate metric means", "\n", "", "", "if", "label_weights", "is", "None", ":", "\n", "        ", "label_weights", "=", "{", "label_name", ":", "1", "for", "label_name", "in", "label_names", "}", "\n", "", "for", "metric_key", "in", "metrics", ".", "keys", "(", ")", ":", "\n", "# Replace the dictionary by the mean", "\n", "        ", "mean", "=", "sum", "(", "[", "\n", "label_score", "*", "label_weights", "[", "label_name", "]", "for", "label_name", ",", "label_score", "\n", "in", "scores", "[", "metric_key", "]", ".", "items", "(", ")", "]", ")", "/", "sum", "(", "list", "(", "label_weights", ".", "values", "(", ")", ")", ")", "\n", "scores", "[", "metric_key", "]", "=", "mean", "\n", "", "return", "scores", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.scores.ScoreAbstract.__init__": [[10, 12], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "name", "=", "self", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.scores.ScoreAbstract.eval": [[13, 15], ["None"], "methods", ["None"], ["", "def", "eval", "(", "self", ",", "tp", ",", "tn", ",", "fn", ",", "fp", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.scores.ScoreDice.eval": [[19, 26], ["None"], "methods", ["None"], ["def", "eval", "(", "self", ",", "tp", ",", "tn", ",", "fn", ",", "fp", ")", ":", "\n", "        ", "if", "tp", "==", "0", ":", "\n", "            ", "if", "fn", "+", "fp", ">", "0", ":", "\n", "                ", "return", "0.", "\n", "", "else", ":", "\n", "                ", "return", "1.", "\n", "", "", "return", "(", "2", "*", "tp", ")", "/", "(", "2", "*", "tp", "+", "fp", "+", "fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.scores.ScoreIoU.eval": [[29, 36], ["None"], "methods", ["None"], ["def", "eval", "(", "self", ",", "tp", ",", "tn", ",", "fn", ",", "fp", ")", ":", "\n", "        ", "if", "tp", "==", "0", ":", "\n", "            ", "if", "fn", "+", "fp", ">", "0", ":", "\n", "                ", "return", "0.", "\n", "", "else", ":", "\n", "                ", "return", "1.", "\n", "", "", "return", "tp", "/", "(", "tp", "+", "fp", "+", "fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.scores.ScorePrecision.eval": [[39, 46], ["None"], "methods", ["None"], ["def", "eval", "(", "self", ",", "tp", ",", "tn", ",", "fn", ",", "fp", ")", ":", "\n", "        ", "if", "tp", "==", "0", ":", "\n", "            ", "if", "fp", ">", "0", ":", "\n", "                ", "return", "0.", "\n", "", "else", ":", "\n", "                ", "return", "1.", "\n", "", "", "return", "tp", "/", "(", "tp", "+", "fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.scores.ScoreRecall.eval": [[53, 60], ["None"], "methods", ["None"], ["def", "eval", "(", "self", ",", "tp", ",", "tn", ",", "fn", ",", "fp", ")", ":", "\n", "        ", "if", "tp", "==", "0", ":", "\n", "            ", "if", "fp", ">", "0", ":", "\n", "                ", "return", "0.", "\n", "", "else", ":", "\n", "                ", "return", "1.", "\n", "", "", "return", "tp", "/", "(", "tp", "+", "fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.metrics.scores.ScoreSpecificity.eval": [[71, 78], ["None"], "methods", ["None"], ["def", "eval", "(", "self", ",", "tp", ",", "tn", ",", "fn", ",", "fp", ")", ":", "\n", "        ", "if", "tn", "==", "0", ":", "\n", "            ", "if", "fp", ">", "0", ":", "\n", "                ", "return", "0.", "\n", "", "else", ":", "\n", "                ", "return", "1.", "\n", "", "", "return", "tn", "/", "(", "tn", "+", "fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.test_losses_segmentation.test_bce": [[63, 73], ["mp.eval.losses.losses_segmentation.LossBCE", "float", "float", "float", "float", "float", "float", "abs", "abs", "float", "float", "float", "float", "mp.eval.losses.losses_segmentation.LossBCE.", "mp.eval.losses.losses_segmentation.LossBCE.", "mp.eval.losses.losses_segmentation.LossBCE.", "mp.eval.losses.losses_segmentation.LossBCE.", "mp.eval.losses.losses_segmentation.LossBCE.", "mp.eval.losses.losses_segmentation.LossBCE.", "mp.eval.losses.losses_segmentation.LossBCE.", "mp.eval.losses.losses_segmentation.LossBCE.", "mp.eval.losses.losses_segmentation.LossBCE.", "mp.eval.losses.losses_segmentation.LossBCE.", "mp.eval.losses.losses_segmentation.LossBCE.", "mp.eval.losses.losses_segmentation.LossBCE.", "mp.eval.losses.losses_segmentation.LossBCE.", "mp.eval.losses.losses_segmentation.LossBCE.", "float", "float", "mp.eval.losses.losses_segmentation.LossBCE.", "mp.eval.losses.losses_segmentation.LossBCE."], "function", ["None"], ["def", "test_bce", "(", ")", ":", "\n", "    ", "loss", "=", "LossBCE", "(", ")", "\n", "assert", "float", "(", "loss", "(", "a", ",", "a", ")", ")", "==", "float", "(", "loss", "(", "b", ",", "b", ")", ")", "==", "0", "\n", "assert", "float", "(", "loss", "(", "a_batch", ",", "a_batch", ")", ")", "==", "float", "(", "loss", "(", "b_batch", ",", "b_batch", ")", ")", "==", "0", "\n", "assert", "float", "(", "loss", "(", "a", ",", "b", ")", ")", "==", "float", "(", "loss", "(", "a", ",", "b", ")", ")", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "a", ",", "b", ")", ")", "-", "13.839", ")", "<", "0.01", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "a_batch", ",", "b_batch", ")", ")", "-", "13.839", ")", "<", "0.01", "\n", "assert", "float", "(", "loss", "(", "d", ",", "e", ")", ")", "==", "float", "(", "loss", "(", "e", ",", "d", ")", ")", "==", "100", "\n", "assert", "float", "(", "loss", "(", "d_batch", ",", "e_batch", ")", ")", "==", "float", "(", "loss", "(", "e_batch", ",", "d_batch", ")", ")", "==", "100", "\n", "assert", "loss", "(", "a", ",", "b", ")", "<", "loss", "(", "b", ",", "c", ")", "<", "loss", "(", "a", ",", "c", ")", "<", "loss", "(", "e", ",", "d", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.test_losses_segmentation.test_batched_dice": [[74, 83], ["mp.eval.losses.losses_segmentation.LossDice", "mp.eval.losses.losses_segmentation.LossDice", "abs", "abs", "abs", "abs", "float", "float", "float", "float", "mp.eval.losses.losses_segmentation.LossDice.", "mp.eval.losses.losses_segmentation.LossDice.", "mp.eval.losses.losses_segmentation.LossDice.", "mp.eval.losses.losses_segmentation.LossDice."], "function", ["None"], ["", "def", "test_batched_dice", "(", ")", ":", "\n", "# For higher batches, the smoothed Dice loss is higher (it pproaches the ", "\n", "# actual loss better).", "\n", "    ", "loss", "=", "LossDice", "(", "smooth", "=", ".001", ")", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "a", ",", "b", ")", ")", "-", "0.2768", ")", "<", "0.001", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "a_batch", ",", "b_batch", ")", ")", "-", "0.2768", ")", "<", "0.001", "\n", "loss", "=", "LossDice", "(", "smooth", "=", "1.", ")", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "a", ",", "b", ")", ")", "-", "0.2756", ")", "<", "0.001", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "a_batch", ",", "b_batch", ")", ")", "-", "0.2764", ")", "<", "0.001", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.test_losses_segmentation.test_weighted_dice": [[84, 101], ["mp.eval.losses.losses_segmentation.LossDice", "mp.eval.losses.losses_segmentation.LossClassWeighted", "mp.eval.losses.losses_segmentation.LossDice", "mp.eval.losses.losses_segmentation.LossClassWeighted", "mp.eval.losses.losses_segmentation.LossClassWeighted", "mp.eval.losses.losses_segmentation.LossClassWeighted", "abs", "abs", "abs", "abs", "abs", "abs", "abs", "abs", "float", "float", "float", "float", "float", "float", "float", "float", "mp.eval.losses.losses_segmentation.LossClassWeighted.", "mp.eval.losses.losses_segmentation.LossClassWeighted.", "mp.eval.losses.losses_segmentation.LossClassWeighted.", "mp.eval.losses.losses_segmentation.LossClassWeighted.", "mp.eval.losses.losses_segmentation.LossClassWeighted.", "mp.eval.losses.losses_segmentation.LossClassWeighted.", "mp.eval.losses.losses_segmentation.LossClassWeighted.", "mp.eval.losses.losses_segmentation.LossClassWeighted."], "function", ["None"], ["", "def", "test_weighted_dice", "(", ")", ":", "\n", "# The loss is lower the higher the smoothing factor. The smaller the ", "\n", "# smoothing factor, the more similar the result to the inverse Dice score.", "\n", "    ", "dice_loss", "=", "LossDice", "(", "smooth", "=", "1.", ")", "\n", "loss", "=", "LossClassWeighted", "(", "loss", "=", "dice_loss", ",", "nr_labels", "=", "4", ")", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "a", ",", "b", ")", ")", "-", "0.4245", ")", "<", "0.001", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "a", ",", "a", ")", ")", "-", "0.0", ")", "<", "0.001", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "d", ",", "e", ")", ")", "-", "0.9911", ")", "<", "0.001", "\n", "dice_loss", "=", "LossDice", "(", "smooth", "=", ".001", ")", "\n", "loss", "=", "LossClassWeighted", "(", "loss", "=", "dice_loss", ",", "nr_labels", "=", "4", ")", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "a", ",", "b", ")", ")", "-", "0.4446", ")", "<", "0.001", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "a", ",", "a", ")", ")", "-", "0.0", ")", "<", "0.001", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "d", ",", "e", ")", ")", "-", "0.9999", ")", "<", "0.001", "\n", "loss", "=", "LossClassWeighted", "(", "loss", "=", "dice_loss", ",", "weights", "=", "[", "2", ",", "1", ",", "0", ",", "1", "]", ")", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "a", ",", "b", ")", ")", "-", "0.3933", ")", "<", "0.001", "\n", "loss", "=", "LossClassWeighted", "(", "loss", "=", "dice_loss", ",", "weights", "=", "[", "0.2", ",", "0.1", ",", ".0", ",", ".1", "]", ")", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "a", ",", "b", ")", ")", "-", "0.3933", ")", "<", "0.001", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.test_losses_segmentation.test_combined_losses": [[102, 110], ["mp.eval.losses.losses_segmentation.LossDiceBCE", "mp.eval.losses.losses_segmentation.LossDiceBCE", "mp.eval.losses.losses_segmentation.LossDiceBCE", "abs", "abs", "abs", "abs", "float", "float", "float", "float", "mp.eval.losses.losses_segmentation.LossDiceBCE.", "mp.eval.losses.losses_segmentation.LossDiceBCE.", "mp.eval.losses.losses_segmentation.LossDiceBCE.", "mp.eval.losses.losses_segmentation.LossDiceBCE."], "function", ["None"], ["", "def", "test_combined_losses", "(", ")", ":", "\n", "    ", "loss", "=", "LossDiceBCE", "(", "bce_weight", "=", "1.", ",", "smooth", "=", "1.", ")", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "a", ",", "b", ")", ")", "-", "14.115", ")", "<", "0.001", "\n", "loss", "=", "LossDiceBCE", "(", "bce_weight", "=", ".5", ",", "smooth", "=", "1.", ")", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "a", ",", "b", ")", ")", "-", "7.195", ")", "<", "0.001", "\n", "loss", "=", "LossDiceBCE", "(", "bce_weight", "=", ".5", ",", "smooth", "=", ".001", ")", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "a", ",", "b", ")", ")", "-", "7.1964", ")", "<", "0.001", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "a_batch", ",", "b_batch", ")", ")", "-", "7.1964", ")", "<", "0.001", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.test_losses_segmentation.test_get_evaluation_dict": [[111, 139], ["mp.eval.losses.losses_segmentation.LossBCE", "mp.eval.losses.losses_segmentation.LossDiceBCE.get_evaluation_dict", "mp.eval.losses.losses_segmentation.LossDice", "mp.eval.losses.losses_segmentation.LossClassWeighted", "mp.eval.losses.losses_segmentation.LossDiceBCE.get_evaluation_dict", "mp.eval.losses.losses_segmentation.LossDice", "mp.eval.losses.losses_segmentation.LossClassWeighted", "mp.eval.losses.losses_segmentation.LossDiceBCE.get_evaluation_dict", "mp.eval.losses.losses_segmentation.LossDiceBCE", "mp.eval.losses.losses_segmentation.LossDiceBCE.get_evaluation_dict", "abs", "abs", "abs", "abs", "abs", "abs", "abs", "abs", "abs", "abs", "abs", "abs", "abs", "abs"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossClassWeighted.get_evaluation_dict", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossClassWeighted.get_evaluation_dict", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossClassWeighted.get_evaluation_dict", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossClassWeighted.get_evaluation_dict"], ["", "def", "test_get_evaluation_dict", "(", ")", ":", "\n", "    ", "loss", "=", "LossBCE", "(", ")", "\n", "evaluation_dict", "=", "loss", ".", "get_evaluation_dict", "(", "a", ",", "b", ")", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossBCE'", "]", "-", "13.839", ")", "<", "0.01", "\n", "\n", "dice_loss", "=", "LossDice", "(", "smooth", "=", ".001", ")", "\n", "loss", "=", "LossClassWeighted", "(", "loss", "=", "dice_loss", ",", "nr_labels", "=", "4", ")", "\n", "evaluation_dict", "=", "loss", ".", "get_evaluation_dict", "(", "a", ",", "b", ")", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossDice[smooth=0.001][0]'", "]", "-", "0.1795", ")", "<", "0.01", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossDice[smooth=0.001][1]'", "]", "-", "0.5", ")", "<", "0.01", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossDice[smooth=0.001][2]'", "]", "-", "0.3846", ")", "<", "0.01", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossDice[smooth=0.001][3]'", "]", "-", "0.7142", ")", "<", "0.01", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossClassWeighted[loss=LossDice[smooth=0.001]; weights=(1, 1, 1, 1)]'", "]", "-", "0.4446", ")", "<", "0.01", "\n", "\n", "dice_loss", "=", "LossDice", "(", "smooth", "=", ".001", ")", "\n", "loss", "=", "LossClassWeighted", "(", "loss", "=", "dice_loss", ",", "weights", "=", "[", "0.2", ",", "0.1", ",", ".0", ",", ".1", "]", ")", "\n", "evaluation_dict", "=", "loss", ".", "get_evaluation_dict", "(", "a", ",", "b", ")", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossDice[smooth=0.001][0]'", "]", "-", "0.1795", ")", "<", "0.01", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossDice[smooth=0.001][1]'", "]", "-", "0.5", ")", "<", "0.01", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossDice[smooth=0.001][2]'", "]", "-", "0.3846", ")", "<", "0.01", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossDice[smooth=0.001][3]'", "]", "-", "0.7142", ")", "<", "0.01", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossClassWeighted[loss=LossDice[smooth=0.001]; weights=(0.2, 0.1, 0.0, 0.1)]'", "]", "-", "0.3933", ")", "<", "0.01", "\n", "\n", "loss", "=", "LossDiceBCE", "(", "bce_weight", "=", ".5", ",", "smooth", "=", "1.", ")", "\n", "evaluation_dict", "=", "loss", ".", "get_evaluation_dict", "(", "a", ",", "b", ")", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossCombined[1.0xLossDice[smooth=1.0]+0.5xLossBCE]'", "]", "-", "7.195", ")", "<", "0.01", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossBCE'", "]", "-", "13.839", ")", "<", "0.01", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossDice[smooth=1.0]'", "]", "-", "0.275", ")", "<", "0.01", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.test_losses_segmentation.test_batched_weighted_dice": [[140, 156], ["mp.eval.losses.losses_segmentation.LossDice", "mp.eval.losses.losses_segmentation.LossClassWeighted", "mp.eval.losses.losses_segmentation.LossClassWeighted", "mp.eval.losses.losses_segmentation.LossClassWeighted", "mp.eval.losses.losses_segmentation.LossClassWeighted.get_evaluation_dict", "abs", "abs", "abs", "abs", "abs", "abs", "abs", "abs", "abs", "abs", "float", "float", "float", "float", "float", "mp.eval.losses.losses_segmentation.LossClassWeighted.", "mp.eval.losses.losses_segmentation.LossClassWeighted.", "mp.eval.losses.losses_segmentation.LossClassWeighted.", "mp.eval.losses.losses_segmentation.LossClassWeighted.", "mp.eval.losses.losses_segmentation.LossClassWeighted."], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossClassWeighted.get_evaluation_dict"], ["", "def", "test_batched_weighted_dice", "(", ")", ":", "\n", "    ", "dice_loss", "=", "LossDice", "(", "smooth", "=", ".001", ")", "\n", "loss", "=", "LossClassWeighted", "(", "loss", "=", "dice_loss", ",", "nr_labels", "=", "4", ")", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "a_batch", ",", "b_batch", ")", ")", "-", "0.4446", ")", "<", "0.001", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "a_batch", ",", "a_batch", ")", ")", "-", "0.0", ")", "<", "0.001", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "d_batch", ",", "e_batch", ")", ")", "-", "0.9999", ")", "<", "0.001", "\n", "loss", "=", "LossClassWeighted", "(", "loss", "=", "dice_loss", ",", "weights", "=", "[", "2", ",", "1", ",", "0", ",", "1", "]", ")", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "a_batch", ",", "b_batch", ")", ")", "-", "0.3933", ")", "<", "0.001", "\n", "loss", "=", "LossClassWeighted", "(", "loss", "=", "dice_loss", ",", "weights", "=", "[", "0.2", ",", "0.1", ",", ".0", ",", ".1", "]", ")", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "a_batch", ",", "b_batch", ")", ")", "-", "0.3933", ")", "<", "0.001", "\n", "evaluation_dict", "=", "loss", ".", "get_evaluation_dict", "(", "a_batch", ",", "b_batch", ")", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossDice[smooth=0.001][0]'", "]", "-", "0.1795", ")", "<", "0.01", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossDice[smooth=0.001][1]'", "]", "-", "0.5", ")", "<", "0.01", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossDice[smooth=0.001][2]'", "]", "-", "0.3846", ")", "<", "0.01", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossDice[smooth=0.001][3]'", "]", "-", "0.7142", ")", "<", "0.01", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossClassWeighted[loss=LossDice[smooth=0.001]; weights=(0.2, 0.1, 0.0, 0.1)]'", "]", "-", "0.3933", ")", "<", "0.01", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.test_losses_segmentation.test_batched_weighted_dice_two": [[157, 167], ["mp.eval.losses.losses_segmentation.LossDice", "mp.eval.losses.losses_segmentation.LossClassWeighted", "mp.eval.losses.losses_segmentation.LossClassWeighted.get_evaluation_dict", "abs", "abs", "abs", "abs", "abs", "abs", "float", "mp.eval.losses.losses_segmentation.LossClassWeighted."], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossClassWeighted.get_evaluation_dict"], ["", "def", "test_batched_weighted_dice_two", "(", ")", ":", "\n", "    ", "dice_loss", "=", "LossDice", "(", "smooth", "=", ".001", ")", "\n", "loss", "=", "LossClassWeighted", "(", "loss", "=", "dice_loss", ",", "weights", "=", "[", "20.", ",", "10.", ",", ".0", ",", "10.", "]", ")", "\n", "assert", "abs", "(", "float", "(", "loss", "(", "a_batch", ",", "b_batch", ")", ")", "-", "0.3933", ")", "<", "0.001", "\n", "evaluation_dict", "=", "loss", ".", "get_evaluation_dict", "(", "a_batch", ",", "b_batch", ")", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossDice[smooth=0.001][0]'", "]", "-", "0.1795", ")", "<", "0.01", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossDice[smooth=0.001][1]'", "]", "-", "0.5", ")", "<", "0.01", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossDice[smooth=0.001][2]'", "]", "-", "0.3846", ")", "<", "0.01", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossDice[smooth=0.001][3]'", "]", "-", "0.7142", ")", "<", "0.01", "\n", "assert", "abs", "(", "evaluation_dict", "[", "'LossClassWeighted[loss=LossDice[smooth=0.001]; weights=(20.0, 10.0, 0.0, 10.0)]'", "]", "-", "0.3933", ")", "<", "0.01", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_autoencoding.LossMSE.__init__": [[10, 13], ["mp.eval.losses.loss_abstract.LossAbstract.__init__", "torch.MSELoss"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "device", "=", "'cuda:0'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "device", "=", "device", ")", "\n", "self", ".", "mse", "=", "nn", ".", "MSELoss", "(", "reduction", "=", "'mean'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_autoencoding.LossMSE.forward": [[14, 16], ["losses_autoencoding.LossMSE.mse"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "output", ",", "target", ")", ":", "\n", "        ", "return", "self", ".", "mse", "(", "output", ",", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_autoencoding.LossL1.__init__": [[19, 22], ["mp.eval.losses.loss_abstract.LossAbstract.__init__", "torch.L1Loss"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "device", "=", "'cuda:0'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "device", "=", "device", ")", "\n", "self", ".", "l1", "=", "nn", ".", "L1Loss", "(", "reduction", "=", "'mean'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_autoencoding.LossL1.forward": [[23, 25], ["losses_autoencoding.LossL1.l1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "output", ",", "target", ")", ":", "\n", "        ", "return", "self", ".", "l1", "(", "output", ",", "target", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.loss_abstract.LossAbstract.__init__": [[14, 18], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "device", "=", "'cuda:0'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "name", "=", "self", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.loss_abstract.LossAbstract.get_evaluation_dict": [[19, 27], ["float", "loss_abstract.LossAbstract.forward().cpu", "loss_abstract.LossAbstract.forward"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.classification.small_cnn.SmallCNN.forward"], ["", "def", "get_evaluation_dict", "(", "self", ",", "output", ",", "target", ")", ":", "\n", "        ", "r\"\"\"Return keys and values of all components making up this loss.\n        Args:\n            output (torch.tensor): a torch tensor for a multi-channeled model \n                output\n            target (torch.tensor): a torch tensor for a multi-channeled target\n        \"\"\"", "\n", "return", "{", "self", ".", "name", ":", "float", "(", "self", ".", "forward", "(", "output", ",", "target", ")", ".", "cpu", "(", ")", ")", "}", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossDice.__init__": [[17, 22], ["mp.eval.losses.loss_abstract.LossAbstract.__init__", "str"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "smooth", "=", "1.", ",", "device", "=", "'cuda:0'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "device", "=", "device", ")", "\n", "self", ".", "smooth", "=", "smooth", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "name", "=", "'LossDice[smooth='", "+", "str", "(", "self", ".", "smooth", ")", "+", "']'", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossDice.forward": [[23, 29], ["output.view", "target.view", "output.view.sum", "target.view.sum"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum"], ["", "def", "forward", "(", "self", ",", "output", ",", "target", ")", ":", "\n", "        ", "output_flat", "=", "output", ".", "view", "(", "-", "1", ")", "\n", "target_flat", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "intersection", "=", "(", "output_flat", "*", "target_flat", ")", ".", "sum", "(", ")", "\n", "return", "1", "-", "(", "(", "2.", "*", "intersection", "+", "self", ".", "smooth", ")", "/", "\n", "(", "output_flat", ".", "sum", "(", ")", "+", "target_flat", ".", "sum", "(", ")", "+", "self", ".", "smooth", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossBCE.__init__": [[32, 36], ["mp.eval.losses.loss_abstract.LossAbstract.__init__", "torch.BCELoss", "torch.BCELoss"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "device", "=", "'cuda:0'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "device", "=", "device", ")", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "bce", "=", "nn", ".", "BCELoss", "(", "reduction", "=", "'mean'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossBCE.forward": [[37, 54], ["losses_segmentation.LossBCE.bce", "print", "print", "print", "print", "output.max", "output.min", "target.max", "target.min", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "output", ",", "target", ")", ":", "\n", "# output = output.contiguous()", "\n", "# target = target.contiguous()", "\n", "# print(output.max(), output.min())", "\n", "# print(target.max(), target.min())", "\n", "# print(output.max(), output.min())", "\n", "# print(target.max(), target.min())", "\n", "# print(torch.isnan(output).any())", "\n", "# print(torch.isnan(target).any())", "\n", "        ", "try", ":", "\n", "            ", "bce_loss", "=", "self", ".", "bce", "(", "output", ",", "target", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "output", ".", "max", "(", ")", ",", "output", ".", "min", "(", ")", ")", "\n", "print", "(", "target", ".", "max", "(", ")", ",", "target", ".", "min", "(", ")", ")", "\n", "print", "(", "torch", ".", "isnan", "(", "output", ")", ".", "any", "(", ")", ")", "\n", "print", "(", "torch", ".", "isnan", "(", "target", ")", ".", "any", "(", ")", ")", "\n", "", "return", "bce_loss", "# self.bce(output, target)", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossBCEWithLogits.__init__": [[60, 63], ["mp.eval.losses.loss_abstract.LossAbstract.__init__", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "device", "=", "'cuda:0'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "device", "=", "device", ")", "\n", "self", ".", "bce", "=", "nn", ".", "BCEWithLogitsLoss", "(", "reduction", "=", "'mean'", ")", "# BCELossWithLogits", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossBCEWithLogits.forward": [[64, 66], ["losses_segmentation.LossBCEWithLogits.bce"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "output", ",", "target", ")", ":", "\n", "        ", "return", "self", ".", "bce", "(", "output", ",", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossCombined.__init__": [[69, 78], ["mp.eval.losses.loss_abstract.LossAbstract.__init__", "zip", "str"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "losses", ",", "weights", ",", "device", "=", "'cuda:0'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "device", "=", "device", ")", "\n", "self", ".", "losses", "=", "losses", "\n", "self", ".", "weights", "=", "weights", "\n", "# Set name", "\n", "self", ".", "name", "=", "'LossCombined['", "\n", "for", "loss", ",", "weight", "in", "zip", "(", "self", ".", "losses", ",", "self", ".", "weights", ")", ":", "\n", "            ", "self", ".", "name", "+=", "str", "(", "weight", ")", "+", "'x'", "+", "loss", ".", "name", "+", "'+'", "\n", "", "self", ".", "name", "=", "self", ".", "name", "[", ":", "-", "1", "]", "+", "']'", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossCombined.forward": [[79, 84], ["torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "zip", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "loss"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to"], ["", "def", "forward", "(", "self", ",", "output", ",", "target", ")", ":", "\n", "        ", "total_loss", "=", "torch", ".", "zeros", "(", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "for", "loss", ",", "weight", "in", "zip", "(", "self", ".", "losses", ",", "self", ".", "weights", ")", ":", "\n", "            ", "total_loss", "+=", "weight", "*", "loss", "(", "output", ",", "target", ")", "\n", "", "return", "total_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossCombined.get_evaluation_dict": [[85, 92], ["super().get_evaluation_dict", "zip", "loss.get_evaluation_dict", "loss.get_evaluation_dict.items"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossClassWeighted.get_evaluation_dict", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossClassWeighted.get_evaluation_dict"], ["", "def", "get_evaluation_dict", "(", "self", ",", "output", ",", "target", ")", ":", "\n", "        ", "eval_dict", "=", "super", "(", ")", ".", "get_evaluation_dict", "(", "output", ",", "target", ")", "\n", "for", "loss", ",", "weight", "in", "zip", "(", "self", ".", "losses", ",", "self", ".", "weights", ")", ":", "\n", "            ", "loss_eval_dict", "=", "loss", ".", "get_evaluation_dict", "(", "output", ",", "target", ")", "\n", "for", "key", ",", "value", "in", "loss_eval_dict", ".", "items", "(", ")", ":", "\n", "                ", "eval_dict", "[", "key", "]", "=", "value", "\n", "", "", "return", "eval_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossDiceBCE.__init__": [[95, 98], ["losses_segmentation.LossCombined.__init__", "losses_segmentation.LossDice", "losses_segmentation.LossBCE"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "bce_weight", "=", "1.", ",", "smooth", "=", "1.", ",", "device", "=", "'cuda:0'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "losses", "=", "[", "LossDice", "(", "smooth", "=", "smooth", ")", ",", "LossBCE", "(", ")", "]", ",", "\n", "weights", "=", "[", "1.", ",", "bce_weight", "]", ",", "device", "=", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossClassWeighted.__init__": [[104, 118], ["mp.eval.losses.loss_abstract.LossAbstract.__init__", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "losses_segmentation.LossClassWeighted.class_weights.sum", "str", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "range", "tuple"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum"], ["def", "__init__", "(", "self", ",", "loss", ",", "weights", "=", "None", ",", "nr_labels", "=", "None", ",", "device", "=", "'cuda:0'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "device", ")", "\n", "\n", "self", ".", "loss", "=", "loss", "\n", "if", "weights", "is", "None", ":", "\n", "            ", "assert", "nr_labels", "is", "not", "None", ",", "\"Specify either weights or number of labels.\"", "\n", "self", ".", "class_weights", "=", "[", "1", "for", "label_nr", "in", "range", "(", "nr_labels", ")", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "class_weights", "=", "weights", "\n", "# Set name", "\n", "", "self", ".", "name", "=", "'LossClassWeighted[loss='", "+", "loss", ".", "name", "+", "'; weights='", "+", "str", "(", "tuple", "(", "self", ".", "class_weights", ")", ")", "+", "']'", "\n", "# Set tensor class weights", "\n", "self", ".", "class_weights", "=", "torch", ".", "tensor", "(", "self", ".", "class_weights", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "added_weights", "=", "self", ".", "class_weights", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossClassWeighted.forward": [[119, 128], ["torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "zip", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "zip", "len", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "losses_segmentation.LossClassWeighted.loss"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to"], ["", "def", "forward", "(", "self", ",", "output", ",", "target", ")", ":", "\n", "        ", "batch_loss", "=", "torch", ".", "zeros", "(", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "for", "instance_output", ",", "instance_target", "in", "zip", "(", "output", ",", "target", ")", ":", "\n", "            ", "instance_loss", "=", "torch", ".", "zeros", "(", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "for", "out_channel_output", ",", "out_channel_target", ",", "weight", "in", "zip", "(", "instance_output", ",", "instance_target", ",", "self", ".", "class_weights", ")", ":", "\n", "                ", "instance_loss", "+=", "weight", "*", "self", ".", "loss", "(", "out_channel_output", ",", "\n", "out_channel_target", ")", "\n", "", "batch_loss", "+=", "instance_loss", "/", "self", ".", "added_weights", "\n", "", "return", "batch_loss", "/", "len", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossClassWeighted.get_evaluation_dict": [[129, 139], ["super().get_evaluation_dict", "zip", "enumerate", "zip", "range", "losses_segmentation.LossClassWeighted.loss", "float", "len", "len", "losses_segmentation.LossClassWeighted.cpu", "str"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.losses.losses_segmentation.LossClassWeighted.get_evaluation_dict"], ["", "def", "get_evaluation_dict", "(", "self", ",", "output", ",", "target", ")", ":", "\n", "        ", "eval_dict", "=", "super", "(", ")", ".", "get_evaluation_dict", "(", "output", ",", "target", ")", "\n", "weighted_loss_values", "=", "[", "0", "for", "weight", "in", "self", ".", "class_weights", "]", "\n", "for", "instance_output", ",", "instance_target", "in", "zip", "(", "output", ",", "target", ")", ":", "\n", "            ", "for", "out_channel_output", ",", "out_channel_target", ",", "weight_ix", "in", "zip", "(", "instance_output", ",", "instance_target", ",", "range", "(", "len", "(", "weighted_loss_values", ")", ")", ")", ":", "\n", "                ", "instance_weighted_loss", "=", "self", ".", "loss", "(", "out_channel_output", ",", "out_channel_target", ")", "\n", "weighted_loss_values", "[", "weight_ix", "]", "+=", "float", "(", "instance_weighted_loss", ".", "cpu", "(", ")", ")", "\n", "", "", "for", "weight_ix", ",", "loss_value", "in", "enumerate", "(", "weighted_loss_values", ")", ":", "\n", "            ", "eval_dict", "[", "self", ".", "loss", ".", "name", "+", "'['", "+", "str", "(", "weight_ix", ")", "+", "']'", "]", "=", "loss_value", "/", "len", "(", "output", ")", "\n", "", "return", "eval_dict", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.test_transformation.test_per_label_channel": [[4, 26], ["torch.tensor", "a.unsqueeze.unsqueeze", "mp.data.pytorch.transformation.per_label_channel", "mp.data.pytorch.transformation.one_output_channel().numpy", "mp.data.pytorch.transformation.one_output_channel", "a.unsqueeze.numpy"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.per_label_channel", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.one_output_channel"], ["def", "test_per_label_channel", "(", ")", ":", "\n", "    ", "A_1", "=", "[", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "1", ",", "3", ",", "3", ",", "0", ",", "1", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "3", ",", "1", ",", "1", ",", "2", ",", "2", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "1", ",", "1", ",", "2", ",", "2", "]", "]", "\n", "A_2", "=", "[", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "3", ",", "3", ",", "3", "]", ",", "\n", "[", "2", ",", "2", ",", "1", ",", "1", ",", "1", ",", "1", ",", "0", "]", "]", "\n", "A_3", "=", "[", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "2", ",", "0", ",", "1", ",", "1", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "2", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", "]", "\n", "A_4", "=", "[", "[", "1", ",", "1", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "2", ",", "2", ",", "0", "]", ",", "\n", "[", "0", ",", "2", ",", "0", ",", "0", ",", "2", ",", "2", ",", "0", "]", ",", "\n", "[", "0", ",", "2", ",", "0", ",", "0", ",", "3", ",", "3", ",", "3", "]", "]", "\n", "a", "=", "torch", ".", "tensor", "(", "[", "A_1", ",", "A_2", ",", "A_3", ",", "A_4", "]", ")", "\n", "a", "=", "a", ".", "unsqueeze", "(", "0", ")", "\n", "per_label_channel_a", "=", "per_label_channel", "(", "a", ",", "nr_labels", "=", "4", ",", "channel_dim", "=", "0", ")", "\n", "one_output_channel_a", "=", "one_output_channel", "(", "per_label_channel_a", ",", "channel_dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "assert", "(", "a", ".", "numpy", "(", ")", "==", "one_output_channel_a", ")", ".", "all", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.compute_normalization_values.normalization_values": [[9, 26], ["torch.utils.data.DataLoader", "torch.empty", "torch.empty", "torch.sum", "torch.sum", "torch.sqrt"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum"], ["def", "normalization_values", "(", "dataset", ")", ":", "\n", "    ", "r\"\"\"Compute normalization values for a dataset.\"\"\"", "\n", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "10", ",", "shuffle", "=", "False", ")", "\n", "count", "=", "0", "\n", "mean", "=", "torch", ".", "empty", "(", "3", ")", "\n", "std", "=", "torch", ".", "empty", "(", "3", ")", "\n", "\n", "for", "data", ",", "_", "in", "dataloader", ":", "\n", "        ", "b", ",", "c", ",", "h", ",", "w", "=", "data", ".", "shape", "\n", "nb_pixels", "=", "b", "*", "h", "*", "w", "\n", "sum_", "=", "torch", ".", "sum", "(", "data", ",", "dim", "=", "[", "0", ",", "2", ",", "3", "]", ")", "\n", "sum_of_square", "=", "torch", ".", "sum", "(", "data", "**", "2", ",", "dim", "=", "[", "0", ",", "2", ",", "3", "]", ")", "\n", "mean", "=", "(", "count", "*", "mean", "+", "sum_", ")", "/", "(", "count", "+", "nb_pixels", ")", "\n", "std", "=", "(", "count", "*", "std", "+", "sum_of_square", ")", "/", "(", "count", "+", "nb_pixels", ")", "\n", "count", "+=", "nb_pixels", "\n", "\n", "", "return", "{", "'mean'", ":", "mean", ",", "'std'", ":", "torch", ".", "sqrt", "(", "std", "-", "mean", "**", "2", ")", "}", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.save_model_state_dataparallel": [[9, 20], ["os.path.join", "model.state_dict", "copy.copy", "copy.copy.keys", "torch.save", "os.path.exists", "os.makedirs", "model.state_dict.pop", "key.replace"], "function", ["None"], ["def", "save_model_state_dataparallel", "(", "model", ",", "name", ",", "path", ")", ":", "\n", "    ", "r\"\"\"Saves a pytorch model that was encapsulated in nn.DataParallel.\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "", "full_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", "\n", "state_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "state_dict_iter", "=", "copy", "(", "state_dict", ")", "\n", "# remove DataParallel specific .module ", "\n", "for", "key", "in", "state_dict_iter", ".", "keys", "(", ")", ":", "\n", "        ", "state_dict", "[", "key", ".", "replace", "(", "'.module'", ",", "''", ")", "]", "=", "state_dict", ".", "pop", "(", "key", ")", "\n", "", "torch", ".", "save", "(", "state_dict", ",", "full_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.save_model_state": [[21, 27], ["os.path.join", "torch.save", "os.path.exists", "os.makedirs", "model.state_dict"], "function", ["None"], ["", "def", "save_model_state", "(", "model", ",", "name", ",", "path", ")", ":", "\n", "    ", "r\"\"\"Saves a pytorch model.\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "", "full_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "full_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.load_model_state": [[28, 36], ["os.path.exists", "os.path.join", "os.path.isfile", "model.load_state_dict", "torch.load"], "function", ["None"], ["", "def", "load_model_state", "(", "model", ",", "name", ",", "path", ",", "device", "=", "'cpu'", ")", ":", "\n", "    ", "r\"\"\"Restores a pytorch model.\"\"\"", "\n", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "full_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "full_path", ")", ":", "\n", "            ", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "full_path", ",", "map_location", "=", "device", ")", ")", "\n", "return", "True", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.save_optimizer_state": [[37, 45], ["os.path.join", "torch.save", "optimizer.state_dict"], "function", ["None"], ["", "def", "save_optimizer_state", "(", "optimizer", ",", "name", ",", "path", ")", ":", "\n", "    ", "r\"\"\"Saves a pytorch optimizer state.\n\n    This makes sure that, for instance, if learning rate decay is used the same\n    state is restored which was left of at this point in time.\n    \"\"\"", "\n", "full_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "full_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.load_optimizer_state": [[46, 54], ["os.path.exists", "os.path.join", "os.path.isfile", "optimizer.load_state_dict", "torch.load"], "function", ["None"], ["", "def", "load_optimizer_state", "(", "optimizer", ",", "name", ",", "path", ",", "device", "=", "'cpu'", ")", ":", "\n", "    ", "r\"\"\"Restores a pytorch optimizer state.\"\"\"", "\n", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "full_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "full_path", ")", ":", "\n", "            ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "full_path", ",", "map_location", "=", "device", ")", ")", "\n", "return", "True", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.save_scheduler_state": [[55, 59], ["os.path.join", "torch.save", "scheduler.state_dict"], "function", ["None"], ["", "def", "save_scheduler_state", "(", "scheduler", ",", "name", ",", "path", ")", ":", "\n", "    ", "r\"\"\"Saves a scheduler state.\"\"\"", "\n", "full_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "full_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.load_scheduler_state": [[60, 68], ["os.path.exists", "os.path.join", "os.path.isfile", "scheduler.load_state_dict", "torch.load"], "function", ["None"], ["", "def", "load_scheduler_state", "(", "scheduler", ",", "name", ",", "path", ",", "device", "=", "'cpu'", ")", ":", "\n", "    ", "r\"\"\"Loads a scheduler state.\"\"\"", "\n", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "full_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "full_path", ")", ":", "\n", "            ", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "full_path", ",", "map_location", "=", "device", ")", ")", "\n", "return", "True", "\n", "", "", "return", "False", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSegmnetationDataset.__init__": [[24, 44], ["mp.data.pytorch.pytorch_dataset.PytorchDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "ix_lst", "=", "None", ",", "size", "=", "None", ",", "norm_key", "=", "'rescaling'", ",", "\n", "aug_key", "=", "'standard'", ",", "channel_labels", "=", "True", ")", ":", "\n", "        ", "r\"\"\"A torch.utils.data.Dataset for segmentation data.\n        Args:\n            dataset (SegmentationDataset): a SegmentationDataset\n            ix_lst (list[int)]): list specifying the instances of the dataset. \n                If 'None', all not in the hold-out dataset are incuded.\n            size (tuple[int]): size as (channels, width, height, Opt(depth))\n            norm_key (str): Normalization strategy, from \n                mp.data.pytorch.transformation\n            aug_key (str): Augmentation strategy, from \n                mp.data.pytorch.transformation\n            channel_labels (bool): if True, the output has one channel per label\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "dataset", "=", "dataset", ",", "ix_lst", "=", "ix_lst", ",", "size", "=", "size", ")", "\n", "self", ".", "norm", "=", "trans", ".", "NORMALIZATION_STRATEGIES", "[", "norm_key", "]", "\n", "self", ".", "aug", "=", "trans", ".", "AUGMENTATION_STRATEGIES", "[", "aug_key", "]", "\n", "self", ".", "nr_labels", "=", "dataset", ".", "nr_labels", "\n", "self", ".", "channel_labels", "=", "channel_labels", "\n", "self", ".", "predictor", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSegmnetationDataset.get_instance": [[45, 54], ["len"], "methods", ["None"], ["", "def", "get_instance", "(", "self", ",", "ix", "=", "None", ",", "name", "=", "None", ")", ":", "\n", "        ", "r\"\"\"Get a particular instance from the ix or name\"\"\"", "\n", "assert", "ix", "is", "None", "or", "name", "is", "None", "\n", "if", "ix", "is", "None", ":", "\n", "            ", "instance", "=", "[", "ex", "for", "ex", "in", "self", ".", "instances", "if", "ex", ".", "name", "==", "name", "]", "\n", "assert", "len", "(", "instance", ")", "==", "1", "\n", "return", "instance", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "instances", "[", "ix", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSegmnetationDataset.get_ix_from_name": [[55, 58], ["next", "enumerate"], "methods", ["None"], ["", "", "def", "get_ix_from_name", "(", "self", ",", "name", ")", ":", "\n", "        ", "r\"\"\"Get ix from name\"\"\"", "\n", "return", "next", "(", "ix", "for", "ix", ",", "ex", "in", "enumerate", "(", "self", ".", "instances", ")", "if", "ex", ".", "name", "==", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSegmnetationDataset.transform_subject": [[59, 66], ["pytorch_seg_dataset.PytorchSegmnetationDataset.norm", "pytorch_seg_dataset.PytorchSegmnetationDataset.aug"], "methods", ["None"], ["", "def", "transform_subject", "(", "self", ",", "subject", ")", ":", "\n", "        ", "r\"\"\"Transform a subject by applying normalization and augmentation ops\"\"\"", "\n", "if", "self", ".", "norm", "is", "not", "None", ":", "\n", "            ", "subject", "=", "self", ".", "norm", "(", "subject", ")", "\n", "", "if", "self", ".", "aug", "is", "not", "None", ":", "\n", "            ", "subject", "=", "self", ".", "aug", "(", "subject", ")", "\n", "", "return", "subject", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSegmnetationDataset.get_subject_dataloader": [[67, 72], ["None"], "methods", ["None"], ["", "def", "get_subject_dataloader", "(", "self", ",", "subject_ix", ")", ":", "\n", "        ", "r\"\"\"Get a list of input/target pairs equivalent to those if the dataset\n        was only of subject with index subject_ix. For evaluation purposes.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSeg2DDataset.__init__": [[77, 92], ["isinstance", "pytorch_seg_dataset.PytorchSegmnetationDataset.__init__", "mp.Predictor2D", "mp.Predictor2D", "enumerate", "len", "range", "pytorch_seg_dataset.PytorchSeg2DDataset.idxs.append"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "dataset", ",", "ix_lst", "=", "None", ",", "size", "=", "(", "1", ",", "256", ",", "256", ")", ",", "\n", "norm_key", "=", "'rescaling'", ",", "aug_key", "=", "'standard'", ",", "channel_labels", "=", "True", ",", "resize", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "int", ")", ":", "\n", "            ", "size", "=", "(", "1", ",", "size", ",", "size", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "dataset", "=", "dataset", ",", "ix_lst", "=", "ix_lst", ",", "size", "=", "size", ",", "\n", "norm_key", "=", "norm_key", ",", "aug_key", "=", "aug_key", ",", "channel_labels", "=", "channel_labels", ")", "\n", "assert", "len", "(", "self", ".", "size", ")", "==", "3", ",", "\"Size should be 2D\"", "\n", "self", ".", "resize", "=", "resize", "\n", "self", ".", "predictor", "=", "pred", ".", "Predictor2D", "(", "self", ".", "instances", ",", "size", "=", "self", ".", "size", ",", "\n", "norm", "=", "self", ".", "norm", ",", "resize", "=", "resize", ")", "\n", "\n", "self", ".", "idxs", "=", "[", "]", "\n", "for", "instance_ix", ",", "instance", "in", "enumerate", "(", "self", ".", "instances", ")", ":", "\n", "            ", "for", "slide_ix", "in", "range", "(", "instance", ".", "shape", "[", "-", "1", "]", ")", ":", "\n", "                ", "self", ".", "idxs", ".", "append", "(", "(", "instance_ix", ",", "slide_ix", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSeg2DDataset.__len__": [[93, 95], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "idxs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSeg2DDataset.__getitem__": [[96, 120], ["copy.deepcopy", "pytorch_seg_dataset.PytorchSeg2DDataset.load", "pytorch_seg_dataset.PytorchSeg2DDataset.transform_subject", "[].float", "[].float", "pytorch_seg_dataset.PytorchSeg2DDataset.instances[].get_subject", "mp.resize_2d", "mp.resize_2d", "mp.resize_2d", "mp.resize_2d", "mp.centre_crop_pad_2d", "mp.centre_crop_pad_2d", "mp.centre_crop_pad_2d", "mp.centre_crop_pad_2d", "mp.per_label_channel", "mp.per_label_channel", "pytorch_seg_dataset.PytorchSeg2DDataset.x.tensor.permute", "pytorch_seg_dataset.PytorchSeg2DDataset.y.tensor.permute"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSegmnetationDataset.transform_subject", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_segmentation.SegmentationInstance.get_subject", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.resize_2d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.resize_2d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.resize_2d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.resize_2d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.centre_crop_pad_2d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.centre_crop_pad_2d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.centre_crop_pad_2d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.centre_crop_pad_2d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.per_label_channel", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.per_label_channel"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "r\"\"\"Returns x and y values each with shape (c, w, h)\"\"\"", "\n", "instance_idx", ",", "slice_idx", "=", "self", ".", "idxs", "[", "idx", "]", "\n", "\n", "# print('reading', instance_idx, 'using copy.deepcopy and multi workers')", "\n", "subject", "=", "copy", ".", "deepcopy", "(", "self", ".", "instances", "[", "instance_idx", "]", ".", "get_subject", "(", ")", ")", "\n", "subject", ".", "load", "(", ")", "\n", "\n", "subject", "=", "self", ".", "transform_subject", "(", "subject", ")", "\n", "\n", "x", "=", "subject", ".", "x", ".", "tensor", ".", "permute", "(", "3", ",", "0", ",", "1", ",", "2", ")", "[", "slice_idx", "]", ".", "float", "(", ")", "\n", "y", "=", "subject", ".", "y", ".", "tensor", ".", "permute", "(", "3", ",", "0", ",", "1", ",", "2", ")", "[", "slice_idx", "]", ".", "float", "(", ")", "\n", "\n", "if", "self", ".", "resize", ":", "\n", "            ", "x", "=", "trans", ".", "resize_2d", "(", "x", ",", "size", "=", "self", ".", "size", ")", "\n", "y", "=", "trans", ".", "resize_2d", "(", "y", ",", "size", "=", "self", ".", "size", ",", "label", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "trans", ".", "centre_crop_pad_2d", "(", "x", ",", "size", "=", "self", ".", "size", ")", "\n", "y", "=", "trans", ".", "centre_crop_pad_2d", "(", "y", ",", "size", "=", "self", ".", "size", ")", "\n", "\n", "", "if", "self", ".", "channel_labels", ":", "\n", "            ", "y", "=", "trans", ".", "per_label_channel", "(", "y", ",", "self", ".", "nr_labels", ")", "\n", "\n", "", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSeg2DDataset.get_subject_dataloader": [[121, 129], ["pytorch_seg_dataset.PytorchSeg2DDataset.__getitem__", "dl_items.append", "enumerate", "x.unsqueeze_", "y.unsqueeze_"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.Pytorch3DQueue.__getitem__"], ["", "def", "get_subject_dataloader", "(", "self", ",", "subject_ix", ")", ":", "\n", "        ", "dl_items", "=", "[", "]", "\n", "idxs", "=", "[", "idx", "for", "idx", ",", "(", "instance_idx", ",", "slice_idx", ")", "in", "enumerate", "(", "self", ".", "idxs", ")", "\n", "if", "instance_idx", "==", "subject_ix", "]", "\n", "for", "idx", "in", "idxs", ":", "\n", "            ", "x", ",", "y", "=", "self", ".", "__getitem__", "(", "idx", ")", "\n", "dl_items", ".", "append", "(", "(", "x", ".", "unsqueeze_", "(", "0", ")", ",", "y", ".", "unsqueeze_", "(", "0", ")", ")", ")", "\n", "", "return", "dl_items", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSeg2DDatasetDomain.__init__": [[133, 142], ["torch.zeros", "pytorch_seg_dataset.PytorchSeg2DDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "dataset", ",", "ix_lst", "=", "None", ",", "size", "=", "(", "1", ",", "256", ",", "256", ")", ",", "\n", "norm_key", "=", "'rescaling'", ",", "aug_key", "=", "'standard'", ",", "channel_labels", "=", "True", ",", "resize", "=", "False", ",", "domain_code", "=", "0", ",", "domain_code_size", "=", "10", ")", ":", "\n", "\n", "        ", "domain_code_tmp", "=", "torch", ".", "zeros", "(", "domain_code_size", ")", "\n", "domain_code_tmp", "[", "domain_code", "]", "=", "1", "\n", "self", ".", "domain_code", "=", "domain_code_tmp", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "dataset", ",", "ix_lst", "=", "ix_lst", ",", "size", "=", "size", ",", "\n", "norm_key", "=", "norm_key", ",", "aug_key", "=", "aug_key", ",", "channel_labels", "=", "channel_labels", ",", "resize", "=", "resize", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSeg2DDatasetDomain.__getitem__": [[143, 147], ["pytorch_seg_dataset.PytorchSeg2DDataset.__getitem__", "pytorch_seg_dataset.PytorchSeg2DDatasetDomain.domain_code.clone"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.Pytorch3DQueue.__getitem__"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "r\"\"\"Returns x and y values each with shape (c, w, h) and one-hot encoded domain code with shape (domain_code_size,)\"\"\"", "\n", "item_super", "=", "super", "(", ")", ".", "__getitem__", "(", "idx", ")", "\n", "return", "item_super", "[", "0", "]", ",", "item_super", "[", "1", "]", ",", "self", ".", "domain_code", ".", "clone", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSeg2DDatasetDomain.get_subject_dataloader": [[148, 156], ["pytorch_seg_dataset.PytorchSeg2DDatasetDomain.__getitem__", "dl_items.append", "enumerate", "x.unsqueeze_", "y.unsqueeze_", "domain_code.unsqueeze_"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.Pytorch3DQueue.__getitem__"], ["", "def", "get_subject_dataloader", "(", "self", ",", "subject_ix", ")", ":", "\n", "        ", "dl_items", "=", "[", "]", "\n", "idxs", "=", "[", "idx", "for", "idx", ",", "(", "instance_idx", ",", "slice_idx", ")", "in", "enumerate", "(", "self", ".", "idxs", ")", "\n", "if", "instance_idx", "==", "subject_ix", "]", "\n", "for", "idx", "in", "idxs", ":", "\n", "            ", "x", ",", "y", ",", "domain_code", "=", "self", ".", "__getitem__", "(", "idx", ")", "\n", "dl_items", ".", "append", "(", "(", "x", ".", "unsqueeze_", "(", "0", ")", ",", "y", ".", "unsqueeze_", "(", "0", ")", ",", "domain_code", ".", "unsqueeze_", "(", "0", ")", ")", ")", "\n", "", "return", "dl_items", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSeg3DDataset.__init__": [[162, 172], ["isinstance", "pytorch_seg_dataset.PytorchSegmnetationDataset.__init__", "mp.Predictor3D", "mp.Predictor3D", "len"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "dataset", ",", "ix_lst", "=", "None", ",", "size", "=", "(", "1", ",", "56", ",", "56", ",", "10", ")", ",", "\n", "norm_key", "=", "'rescaling'", ",", "aug_key", "=", "'standard'", ",", "channel_labels", "=", "True", ",", "resize", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "int", ")", ":", "\n", "            ", "size", "=", "(", "1", ",", "size", ",", "size", ",", "size", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "dataset", "=", "dataset", ",", "ix_lst", "=", "ix_lst", ",", "size", "=", "size", ",", "\n", "norm_key", "=", "norm_key", ",", "aug_key", "=", "aug_key", ",", "channel_labels", "=", "channel_labels", ")", "\n", "assert", "len", "(", "self", ".", "size", ")", "==", "4", ",", "\"Size should be 3D\"", "\n", "self", ".", "resize", "=", "resize", "\n", "self", ".", "predictor", "=", "pred", ".", "Predictor3D", "(", "self", ".", "instances", ",", "size", "=", "self", ".", "size", ",", "\n", "norm", "=", "self", ".", "norm", ",", "resize", "=", "resize", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSeg3DDataset.__getitem__": [[173, 195], ["copy.deepcopy", "pytorch_seg_dataset.PytorchSeg3DDataset.load", "pytorch_seg_dataset.PytorchSeg3DDataset.transform_subject", "pytorch_seg_dataset.PytorchSeg3DDataset.instances[].get_subject", "mp.resize_3d", "mp.resize_3d", "mp.resize_3d", "mp.resize_3d", "mp.centre_crop_pad_3d", "mp.centre_crop_pad_3d", "mp.centre_crop_pad_3d", "mp.centre_crop_pad_3d", "mp.per_label_channel", "mp.per_label_channel"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSegmnetationDataset.transform_subject", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_segmentation.SegmentationInstance.get_subject", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.resize_3d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.resize_3d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.resize_3d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.resize_3d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.centre_crop_pad_3d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.centre_crop_pad_3d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.centre_crop_pad_3d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.centre_crop_pad_3d", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.per_label_channel", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.per_label_channel"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "r\"\"\"Returns x and y values each with shape (c, w, h, d)\"\"\"", "\n", "\n", "subject", "=", "copy", ".", "deepcopy", "(", "self", ".", "instances", "[", "idx", "]", ".", "get_subject", "(", ")", ")", "\n", "subject", ".", "load", "(", ")", "\n", "\n", "subject", "=", "self", ".", "transform_subject", "(", "subject", ")", "\n", "\n", "x", "=", "subject", "[", "'x'", "]", ".", "data", "\n", "y", "=", "subject", "[", "'y'", "]", ".", "data", "\n", "\n", "if", "self", ".", "resize", ":", "\n", "            ", "x", "=", "trans", ".", "resize_3d", "(", "x", ",", "size", "=", "self", ".", "size", ")", "\n", "y", "=", "trans", ".", "resize_3d", "(", "y", ",", "size", "=", "self", ".", "size", ",", "label", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "trans", ".", "centre_crop_pad_3d", "(", "x", ",", "size", "=", "self", ".", "size", ")", "\n", "y", "=", "trans", ".", "centre_crop_pad_3d", "(", "y", ",", "size", "=", "self", ".", "size", ")", "\n", "\n", "", "if", "self", ".", "channel_labels", ":", "\n", "            ", "y", "=", "trans", ".", "per_label_channel", "(", "y", ",", "self", ".", "nr_labels", ")", "\n", "\n", "", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSeg3DDataset.get_subject_dataloader": [[196, 199], ["pytorch_seg_dataset.PytorchSeg3DDataset.__getitem__", "x.unsqueeze_", "y.unsqueeze_"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.Pytorch3DQueue.__getitem__"], ["", "def", "get_subject_dataloader", "(", "self", ",", "subject_ix", ")", ":", "\n", "        ", "x", ",", "y", "=", "self", ".", "__getitem__", "(", "subject_ix", ")", "\n", "return", "[", "(", "x", ".", "unsqueeze_", "(", "0", ")", ",", "y", ".", "unsqueeze_", "(", "0", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.Pytorch3DQueue.__init__": [[204, 235], ["isinstance", "pytorch_seg_dataset.PytorchSegmnetationDataset.__init__", "mp.GridPredictor", "mp.GridPredictor", "torchio.data.SubjectsDataset", "torchio.Queue", "len", "mp.pad_3d_if_required", "mp.pad_3d_if_required", "torchio.data.UniformSampler", "instance.get_subject"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.pad_3d_if_required", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.pad_3d_if_required", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_segmentation.SegmentationInstance.get_subject"], ["def", "__init__", "(", "self", ",", "dataset", ",", "ix_lst", "=", "None", ",", "size", "=", "(", "1", ",", "56", ",", "56", ",", "10", ")", ",", "sampler", "=", "None", ",", "\n", "max_length", "=", "300", ",", "samples_per_volume", "=", "10", ",", "norm_key", "=", "'rescaling'", ",", "\n", "aug_key", "=", "'standard'", ",", "channel_labels", "=", "True", ")", ":", "\n", "        ", "r\"\"\"The number of patches is determined by samples_per_volume \"\"\"", "\n", "if", "isinstance", "(", "size", ",", "int", ")", ":", "\n", "            ", "size", "=", "(", "1", ",", "size", ",", "size", ",", "size", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "dataset", "=", "dataset", ",", "ix_lst", "=", "ix_lst", ",", "size", "=", "size", ",", "\n", "norm_key", "=", "norm_key", ",", "aug_key", "=", "aug_key", ",", "channel_labels", "=", "channel_labels", ")", "\n", "assert", "len", "(", "self", ".", "size", ")", "==", "4", ",", "\"Size should be 3D\"", "\n", "self", ".", "predictor", "=", "pred", ".", "GridPredictor", "(", "self", ".", "instances", ",", "size", "=", "self", ".", "size", ",", "norm", "=", "self", ".", "norm", ")", "\n", "\n", "# If there are subjects with less depth than self.size[-1], pad", "\n", "self", ".", "instances", "=", "[", "trans", ".", "pad_3d_if_required", "(", "instance", ",", "self", ".", "size", ")", "\n", "for", "instance", "in", "self", ".", "instances", "]", "\n", "# Create an instance of torchio.data.SubjectsDataset", "\n", "subjects_dataset", "=", "torchio", ".", "data", ".", "SubjectsDataset", "(", "\n", "[", "instance", ".", "get_subject", "(", ")", "for", "instance", "in", "self", ".", "instances", "]", ")", "\n", "\n", "# Set Sampler", "\n", "if", "sampler", "is", "None", ":", "\n", "            ", "sampler", "=", "torchio", ".", "data", ".", "UniformSampler", "(", "self", ".", "size", "[", "1", ":", "]", ")", "\n", "\n", "# Initialize queue", "\n", "", "self", ".", "queue", "=", "torchio", ".", "Queue", "(", "\n", "subjects_dataset", ",", "\n", "sampler", "=", "sampler", ",", "\n", "max_length", "=", "max_length", ",", "\n", "samples_per_volume", "=", "samples_per_volume", ",", "\n", "num_workers", "=", "0", ",", "\n", "shuffle_subjects", "=", "True", ",", "\n", "shuffle_patches", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.Pytorch3DQueue.__len__": [[237, 239], ["pytorch_seg_dataset.Pytorch3DQueue.queue.__len__"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_dataset.PytorchDataset.__len__"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "queue", ".", "__len__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.Pytorch3DQueue.__getitem__": [[240, 256], ["pytorch_seg_dataset.Pytorch3DQueue.queue.__getitem__", "pytorch_seg_dataset.Pytorch3DQueue.load", "pytorch_seg_dataset.Pytorch3DQueue.transform_subject", "mp.per_label_channel", "mp.per_label_channel"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.Pytorch3DQueue.__getitem__", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSegmnetationDataset.transform_subject", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.per_label_channel", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.per_label_channel"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "r\"\"\"Returns x and y values each with shape (c, w, h, d)\n        Class torchio.Queue descends from torch.utils.data.Dataset.\"\"\"", "\n", "\n", "subject", "=", "self", ".", "queue", ".", "__getitem__", "(", "idx", ")", "\n", "subject", ".", "load", "(", ")", "\n", "\n", "subject", "=", "self", ".", "transform_subject", "(", "subject", ")", "\n", "\n", "x", "=", "subject", "[", "'x'", "]", ".", "data", "\n", "y", "=", "subject", "[", "'y'", "]", ".", "data", "\n", "\n", "if", "self", ".", "channel_labels", ":", "\n", "            ", "y", "=", "trans", ".", "per_label_channel", "(", "y", ",", "self", ".", "nr_labels", ")", "\n", "\n", "", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.Pytorch3DQueue.get_subject_dataloader": [[257, 275], ["copy.deepcopy", "pytorch_seg_dataset.Pytorch3DQueue.load", "pytorch_seg_dataset.Pytorch3DQueue.transform_subject", "torchio.inference.GridSampler", "torch.utils.data.DataLoader", "pytorch_seg_dataset.Pytorch3DQueue.instances[].get_subject", "dl_items.append"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSegmnetationDataset.transform_subject", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_segmentation.SegmentationInstance.get_subject"], ["", "def", "get_subject_dataloader", "(", "self", ",", "subject_ix", ")", ":", "\n", "\n", "        ", "subject", "=", "copy", ".", "deepcopy", "(", "self", ".", "instances", "[", "subject_ix", "]", ".", "get_subject", "(", ")", ")", "\n", "subject", ".", "load", "(", ")", "\n", "subject", "=", "self", ".", "transform_subject", "(", "subject", ")", "\n", "\n", "grid_sampler", "=", "torchio", ".", "inference", ".", "GridSampler", "(", "\n", "sample", "=", "subject", ",", "\n", "patch_size", "=", "self", ".", "size", "[", "1", ":", "]", ",", "\n", "patch_overlap", "=", "(", "0", ",", "0", ",", "0", ")", ")", "\n", "\n", "dl_items", "=", "[", "]", "\n", "patch_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "grid_sampler", ",", "batch_size", "=", "1", ")", "\n", "for", "patches_batch", "in", "patch_loader", ":", "\n", "            ", "input_tensor", "=", "patches_batch", "[", "'x'", "]", "[", "torchio", ".", "DATA", "]", "\n", "target_tensor", "=", "patches_batch", "[", "'y'", "]", "[", "torchio", ".", "DATA", "]", "\n", "dl_items", ".", "append", "(", "(", "input_tensor", ",", "target_tensor", ")", ")", "\n", "", "return", "dl_items", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_dataset.PytorchDataset.__init__": [[9, 33], ["enumerate", "range", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "ix_lst", "=", "None", ",", "size", "=", "None", ")", ":", "\n", "        ", "r\"\"\"A dataset which is compatible with PyTorch.\n\n        Args:\n            dataset (mp.data.datasets.dataset.Dataset): a descendant of the\n                class defined internally for datasets.\n            ix_lst (list[int]): list specifying the instances of 'dataset' to \n                include. If 'None', all which are not in the hold-out dataset \n                are incuded.\n            size (tuple[int]): desired input size.\n\n        :param resize: resize images into this new size.\n        :param transform_lst: a list of torchvision transforms operations.\n        :param norm: values to normalize the dataset with the form \n        {'mean': tuple, 'std': tuple}, which can be generated by \n        mp.utils.pytorch.compute_normalization_values\n        \"\"\"", "\n", "# Indexes", "\n", "if", "ix_lst", "is", "None", ":", "\n", "            ", "ix_lst", "=", "[", "ix", "for", "ix", "in", "range", "(", "len", "(", "dataset", ".", "instances", ")", ")", "\n", "if", "ix", "not", "in", "dataset", ".", "hold_out_ixs", "]", "\n", "", "self", ".", "instances", "=", "[", "ex", "for", "ix", ",", "ex", "in", "enumerate", "(", "dataset", ".", "instances", ")", "\n", "if", "ix", "in", "ix_lst", "]", "\n", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_dataset.PytorchDataset.__len__": [[34, 36], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "instances", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.per_label_channel": [[63, 75], ["torch.zeros().to", "torch.zeros().to", "torch.ones().to", "torch.ones().to", "range", "torch.cat", "torch.cat", "torch.where", "torch.where", "masks.append", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to"], ["def", "per_label_channel", "(", "y", ",", "nr_labels", ",", "channel_dim", "=", "0", ",", "device", "=", "'cpu'", ")", ":", "\n", "    ", "r\"\"\"Trans. a one-channeled mask where the integers specify the label to a \n    multi-channel output with one channel per label, where 1 marks belonging to\n    that label.\"\"\"", "\n", "masks", "=", "[", "]", "\n", "zeros", "=", "torch", ".", "zeros", "(", "y", ".", "shape", ",", "dtype", "=", "torch", ".", "float64", ")", ".", "to", "(", "device", ")", "\n", "ones", "=", "torch", ".", "ones", "(", "y", ".", "shape", ",", "dtype", "=", "torch", ".", "float64", ")", ".", "to", "(", "device", ")", "\n", "for", "label_nr", "in", "range", "(", "nr_labels", ")", ":", "\n", "        ", "mask", "=", "torch", ".", "where", "(", "y", "==", "label_nr", ",", "ones", ",", "zeros", ")", "\n", "masks", ".", "append", "(", "mask", ")", "\n", "", "target", "=", "torch", ".", "cat", "(", "masks", ",", "dim", "=", "channel_dim", ")", "\n", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation._one_output_channel_single": [[76, 88], ["list", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.zeros.fill_", "torch.where", "torch.where"], "function", ["None"], ["", "def", "_one_output_channel_single", "(", "y", ")", ":", "\n", "    ", "r\"\"\"Helper function.\"\"\"", "\n", "channel_dim", "=", "0", "\n", "target_shape", "=", "list", "(", "y", ".", "shape", ")", "\n", "nr_labels", "=", "target_shape", "[", "channel_dim", "]", "\n", "target_shape", "[", "channel_dim", "]", "=", "1", "\n", "target", "=", "torch", ".", "zeros", "(", "target_shape", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "label_nr_mask", "=", "torch", ".", "zeros", "(", "target_shape", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "for", "label_nr", "in", "range", "(", "nr_labels", ")", ":", "\n", "        ", "label_nr_mask", ".", "fill_", "(", "label_nr", ")", "\n", "target", "=", "torch", ".", "where", "(", "y", "[", "label_nr", "]", "==", "1", ",", "label_nr_mask", ",", "target", ")", "\n", "", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.one_output_channel": [[89, 99], ["torch.stack", "torch.stack", "transformation._one_output_channel_single", "transformation._one_output_channel_single"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation._one_output_channel_single", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation._one_output_channel_single"], ["", "def", "one_output_channel", "(", "y", ",", "channel_dim", "=", "0", ")", ":", "\n", "    ", "r\"\"\"Inverses the operation of 'per_label_channel'. The output is \n    one-channelled. It is stricter than making a prediction because the content \n    must be 1 and not the largest float.\"\"\"", "\n", "if", "channel_dim", "==", "0", ":", "\n", "        ", "return", "_one_output_channel_single", "(", "y", ")", "\n", "", "else", ":", "\n", "        ", "assert", "channel_dim", "==", "1", ",", "\"Not implemented for channel_dim > 1\"", "\n", "", "batch", "=", "[", "_one_output_channel_single", "(", "x", ")", "for", "x", "in", "y", "]", "\n", "return", "torch", ".", "stack", "(", "batch", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.resize_2d": [[100, 109], ["F.interpolate.unsqueeze_", "torch.interpolate", "torch.interpolate"], "function", ["None"], ["", "def", "resize_2d", "(", "img", ",", "size", "=", "(", "1", ",", "128", ",", "128", ")", ",", "label", "=", "False", ")", ":", "\n", "    ", "r\"\"\"2D resize.\"\"\"", "\n", "img", ".", "unsqueeze_", "(", "0", ")", "# Add additional batch dimension so input is 4D", "\n", "if", "label", ":", "\n", "# Interpolation in 'nearest' mode leaves the original mask values.", "\n", "        ", "img", "=", "F", ".", "interpolate", "(", "img", ",", "size", "=", "size", "[", "1", ":", "]", ",", "mode", "=", "'nearest'", ")", "\n", "", "else", ":", "\n", "        ", "img", "=", "F", ".", "interpolate", "(", "img", ",", "size", "=", "size", "[", "1", ":", "]", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "", "return", "img", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.resize_3d": [[110, 119], ["F.interpolate.unsqueeze_", "torch.interpolate", "torch.interpolate"], "function", ["None"], ["", "def", "resize_3d", "(", "img", ",", "size", "=", "(", "1", ",", "56", ",", "56", ",", "56", ")", ",", "label", "=", "False", ")", ":", "\n", "    ", "r\"\"\"3D resize.\"\"\"", "\n", "img", ".", "unsqueeze_", "(", "0", ")", "# Add additional batch dimension so input is 5D", "\n", "if", "label", ":", "\n", "# Interpolation in 'nearest' mode leaves the original mask values.", "\n", "        ", "img", "=", "F", ".", "interpolate", "(", "img", ",", "size", "=", "size", "[", "1", ":", "]", ",", "mode", "=", "'nearest'", ")", "\n", "", "else", ":", "\n", "        ", "img", "=", "F", ".", "interpolate", "(", "img", ",", "size", "=", "size", "[", "1", ":", "]", ",", "mode", "=", "'trilinear'", ")", "\n", "", "return", "img", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.centre_crop_pad_2d": [[120, 131], ["torch.unsqueeze", "torch.unsqueeze", "torchio.transforms.CropOrPad", "torchio.transforms.CropOrPad.to", "torch.squeeze", "torch.squeeze", "torchio.transforms.CropOrPad.", "torch.squeeze.cpu"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to"], ["", "def", "centre_crop_pad_2d", "(", "img", ",", "size", "=", "(", "1", ",", "128", ",", "128", ")", ")", ":", "\n", "    ", "r\"\"\"Center-crops to the specified size, unless the image is to small in some\n    dimension, then padding takes place.\n    \"\"\"", "\n", "img", "=", "torch", ".", "unsqueeze", "(", "img", ",", "-", "1", ")", "\n", "size", "=", "(", "size", "[", "1", "]", ",", "size", "[", "2", "]", ",", "1", ")", "\n", "transform", "=", "torchio", ".", "transforms", ".", "CropOrPad", "(", "target_shape", "=", "size", ",", "padding_mode", "=", "0", ")", "\n", "device", "=", "img", ".", "device", "\n", "img", "=", "transform", "(", "img", ".", "cpu", "(", ")", ")", ".", "to", "(", "device", ")", "\n", "img", "=", "torch", ".", "squeeze", "(", "img", ",", "-", "1", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.centre_crop_pad_3d": [[132, 140], ["torchio.transforms.CropOrPad", "torchio.transforms.CropOrPad.to", "torchio.transforms.CropOrPad.", "transform().to.cpu"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to"], ["", "def", "centre_crop_pad_3d", "(", "img", ",", "size", "=", "(", "1", ",", "56", ",", "56", ",", "56", ")", ")", ":", "\n", "    ", "r\"\"\"Center-crops to the specified size, unless the image is to small in some\n    dimension, then padding takes place. For 3D data.\n    \"\"\"", "\n", "transform", "=", "torchio", ".", "transforms", ".", "CropOrPad", "(", "target_shape", "=", "size", "[", "1", ":", "]", ",", "padding_mode", "=", "0", ")", "\n", "device", "=", "img", ".", "device", "\n", "img", "=", "transform", "(", "img", ".", "cpu", "(", ")", ")", ".", "to", "(", "device", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.pad_3d_if_required": [[141, 153], ["instance.get_subject", "torchio.transforms.Pad", "torchio.transforms.Pad.", "torchio.Image", "torchio.Image"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_segmentation.SegmentationInstance.get_subject"], ["", "def", "pad_3d_if_required", "(", "instance", ",", "size", ")", ":", "\n", "    ", "r\"\"\"Pads if required in the last dimension, for 3D.\n    \"\"\"", "\n", "if", "instance", ".", "shape", "[", "-", "1", "]", "<", "size", "[", "-", "1", "]", ":", "\n", "        ", "delta", "=", "size", "[", "-", "1", "]", "-", "instance", ".", "shape", "[", "-", "1", "]", "\n", "subject", "=", "instance", ".", "get_subject", "(", ")", "\n", "transform", "=", "torchio", ".", "transforms", ".", "Pad", "(", "padding", "=", "(", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "delta", ")", ",", "padding_mode", "=", "0", ")", "\n", "subject", "=", "transform", "(", "subject", ")", "\n", "instance", ".", "x", "=", "torchio", ".", "Image", "(", "tensor", "=", "subject", ".", "x", ".", "tensor", ",", "type", "=", "torchio", ".", "INTENSITY", ")", "\n", "instance", ".", "y", "=", "torchio", ".", "Image", "(", "tensor", "=", "subject", ".", "y", ".", "tensor", ",", "type", "=", "torchio", ".", "LABEL", ")", "\n", "instance", ".", "shape", "=", "subject", ".", "shape", "\n", "", "return", "instance", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.torchvision_rescaling": [[156, 185], ["transform_ops.append", "transform_ops.append", "transform_ops.append", "torchvision.transforms.Compose", "torch.stack", "torch.stack", "torch.min", "torch.min", "torch.max", "torch.max", "transform_ops.append", "torchvision.transforms.ToPILImage", "transform_ops.append", "transform_ops.append", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "imgs.append", "torchvision.transforms.Lambda", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "transforms.Compose.to", "x.repeat", "transforms.Compose.", "img.cpu"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to"], ["def", "torchvision_rescaling", "(", "x", ",", "size", "=", "(", "3", ",", "224", ",", "224", ")", ",", "resize", "=", "False", ")", ":", "\n", "    ", "r\"\"\"To use pretrained torchvision models, three-channeled 2D images must \n    first be normalized between 0 and 1 and then noralized with predfined values\n    (see https://pytorch.org/docs/stable/torchvision/models.html)\n    \"\"\"", "\n", "device", "=", "x", ".", "device", "\n", "# Images should be normalized between 0 and 1", "\n", "assert", "torch", ".", "min", "(", "x", ")", ">=", "0.", "\n", "assert", "torch", ".", "max", "(", "x", ")", "<=", "1.", "\n", "transform_ops", "=", "[", "]", "\n", "# If images are one-channeled, triplicate", "\n", "if", "x", ".", "shape", "[", "1", "]", "==", "1", ":", "\n", "        ", "transform_ops", ".", "append", "(", "transforms", ".", "Lambda", "(", "lambda", "x", ":", "x", ".", "repeat", "(", "3", ",", "1", ",", "1", ")", ")", ")", "\n", "# Resize or crop", "\n", "", "transform_ops", ".", "append", "(", "transforms", ".", "ToPILImage", "(", ")", ")", "\n", "if", "resize", ":", "\n", "        ", "transform_ops", ".", "append", "(", "transforms", ".", "Resize", "(", "size", "=", "(", "size", "[", "1", "]", ",", "size", "[", "2", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "transform_ops", ".", "append", "(", "transforms", ".", "CenterCrop", "(", "size", "=", "(", "size", "[", "1", "]", ",", "size", "[", "2", "]", ")", ")", ")", "\n", "# Apply pre-defined normalization ", "\n", "", "transform_ops", ".", "append", "(", "transforms", ".", "ToTensor", "(", ")", ")", "\n", "transform_ops", ".", "append", "(", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ")", "\n", "# Apply transform operation", "\n", "transform", "=", "transforms", ".", "Compose", "(", "transform_ops", ")", "\n", "imgs", "=", "[", "]", "\n", "for", "img", "in", "x", ":", "\n", "        ", "imgs", ".", "append", "(", "transform", "(", "img", ".", "cpu", "(", ")", ")", ".", "to", "(", "device", ")", ")", "\n", "", "return", "torch", ".", "stack", "(", "imgs", ",", "dim", "=", "0", ")", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.test_ds_mr_prostate_decathlon.test_ds_label_merging": [[3, 10], ["mp.data.datasets.ds_mr_prostate_decathlon.DecathlonProstateT2"], "function", ["None"], ["def", "test_ds_label_merging", "(", ")", ":", "\n", "    ", "data", "=", "DecathlonProstateT2", "(", "merge_labels", "=", "True", ")", "\n", "assert", "data", ".", "label_names", "==", "[", "'background'", ",", "'prostate'", "]", "\n", "assert", "data", ".", "nr_labels", "==", "2", "\n", "assert", "data", ".", "modality", "==", "'MR'", "\n", "assert", "data", ".", "size", "==", "32", "\n", "assert", "data", ".", "name", "==", "'DecathlonProstateT2'", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.test_ds_mr_cardiac_mm.test_ds": [[4, 15], ["mp.data.datasets.ds_mr_cardiac_mm.MM_Challenge", "mp.data.pytorch.pytorch_seg_dataset.PytorchSeg2DDataset", "mp.data.pytorch.pytorch_seg_dataset.PytorchSeg2DDataset.get_instance", "mp.data.pytorch.pytorch_seg_dataset.PytorchSeg2DDataset.get_ix_from_name"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_instance", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSegmnetationDataset.get_ix_from_name"], ["def", "test_ds", "(", ")", ":", "\n", "    ", "data", "=", "MM_Challenge", "(", "subset", "=", "None", ")", "\n", "assert", "data", ".", "label_names", "==", "[", "'background'", ",", "'left ventricle'", ",", "'myocardium'", ",", "'right ventricle'", "]", "\n", "assert", "data", ".", "nr_labels", "==", "4", "\n", "assert", "data", ".", "modality", "==", "'MR'", "\n", "assert", "data", ".", "size", "==", "300", "\n", "ds", "=", "PytorchSeg2DDataset", "(", "data", ",", "size", "=", "(", "1", ",", "256", ",", "256", ")", ",", "aug_key", "=", "'none'", ",", "resize", "=", "False", ")", "\n", "instance", "=", "ds", ".", "get_instance", "(", "0", ")", "\n", "assert", "instance", ".", "name", "==", "'A0S9V9_ED'", "\n", "subject_ix", "=", "ds", ".", "get_ix_from_name", "(", "'A0S9V9_ED'", ")", "\n", "assert", "subject_ix", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.test_ds_mr_cardiac_mm.test_ds_subset": [[16, 25], ["mp.data.datasets.ds_mr_cardiac_mm.MM_Challenge", "print", "mp.data.pytorch.pytorch_seg_dataset.PytorchSeg2DDataset", "mp.data.pytorch.pytorch_seg_dataset.PytorchSeg2DDataset.get_instance", "mp.data.pytorch.pytorch_seg_dataset.PytorchSeg2DDataset.get_ix_from_name"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_instance", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_seg_dataset.PytorchSegmnetationDataset.get_ix_from_name"], ["", "def", "test_ds_subset", "(", ")", ":", "\n", "    ", "data", "=", "MM_Challenge", "(", "subset", "=", "{", "'Vendor'", ":", "'B'", "}", ")", "\n", "print", "(", "data", ".", "size", ")", "\n", "assert", "data", ".", "size", "==", "150", "\n", "ds", "=", "PytorchSeg2DDataset", "(", "data", ",", "size", "=", "(", "1", ",", "256", ",", "256", ")", ",", "aug_key", "=", "'none'", ",", "resize", "=", "False", ")", "\n", "instance", "=", "ds", ".", "get_instance", "(", "0", ")", "\n", "assert", "instance", ".", "name", "==", "'A1D0Q7_ED'", "\n", "subject_ix", "=", "ds", ".", "get_ix_from_name", "(", "'A1D0Q7_ED'", ")", "\n", "assert", "subject_ix", "==", "0", "\n", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_utils.get_original_data_path": [[9, 16], ["Exception"], "function", ["None"], ["def", "get_original_data_path", "(", "global_name", ")", ":", "\n", "    ", "r\"\"\"Get the original path from mp.paths. The global name is the key.\"\"\"", "\n", "try", ":", "\n", "        ", "data_path", "=", "original_data_paths", "[", "global_name", "]", "\n", "", "except", ":", "\n", "        ", "raise", "Exception", "(", "'Data path for {} must be set in paths.py.'", ".", "format", "(", "global_name", ")", ")", "\n", "", "return", "data_path", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_utils.get_dataset_name": [[17, 26], ["subset.items"], "function", ["None"], ["", "def", "get_dataset_name", "(", "global_name", ",", "subset", "=", "None", ")", ":", "\n", "    ", "r\"\"\"Get name of dataset by adding the global name to the subset.\"\"\"", "\n", "if", "subset", "is", "None", ":", "\n", "        ", "return", "global_name", "\n", "", "else", ":", "\n", "        ", "name", "=", "global_name", "\n", "for", "key", ",", "value", "in", "subset", ".", "items", "(", ")", ":", "\n", "            ", "name", "+=", "'['", "+", "key", "+", "':'", "+", "value", "+", "']'", "\n", "", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_utils.get_mean_std_shape": [[27, 40], ["numpy.mean", "numpy.std", "numpy.array", "tuple", "tuple", "int", "int"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.std"], ["", "", "def", "get_mean_std_shape", "(", "instances", ")", ":", "\n", "    ", "r\"\"\"Returns the mean sheap as (channels, width, heigth, depth) for a \n    list of instances.\n\n    Args:\n        instances (list[SegmentationInstance]): a list of segmentation instances.\n\n    Returns (tuple[int]) tuple with form (channels, width, heigth, depth)\n    \"\"\"", "\n", "shapes", "=", "[", "np", ".", "array", "(", "instance", ".", "shape", ")", "for", "instance", "in", "instances", "]", "\n", "mean", "=", "np", ".", "mean", "(", "shapes", ",", "axis", "=", "0", ")", "\n", "std", "=", "np", ".", "std", "(", "shapes", ",", "axis", "=", "0", ")", "\n", "return", "tuple", "(", "int", "(", "x", ")", "for", "x", "in", "mean", ")", ",", "tuple", "(", "int", "(", "x", ")", "for", "x", "in", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_utils.get_mask_labels": [[41, 57], ["set", "list", "all", "labels.union.union", "str", "numpy.unique", "range", "instance.y.tensor.numpy", "int", "int", "max"], "function", ["None"], ["", "def", "get_mask_labels", "(", "instances", ")", ":", "\n", "    ", "r\"\"\"Returns a set of integer labels which appear in segmentation masks in \n    a list of instances.\n\n    Args:\n        instances (list[SegmentationInstance)): a  list of segmentation instances.\n\n    Returns (list[str]): list of the form ['0', '1', '2', etc.] as replacement \n        for not having the real label names.\n    \"\"\"", "\n", "labels", "=", "set", "(", ")", "\n", "for", "instance", "in", "instances", ":", "\n", "        ", "instance_labels", "=", "list", "(", "np", ".", "unique", "(", "instance", ".", "y", ".", "tensor", ".", "numpy", "(", ")", ")", ")", "\n", "assert", "all", "(", "x", "==", "int", "(", "x", ")", "for", "x", "in", "instance_labels", ")", ",", "\"Mask contain non-integer values\"", "\n", "labels", "=", "labels", ".", "union", "(", "[", "int", "(", "x", ")", "for", "x", "in", "instance_labels", "]", ")", "\n", "", "return", "[", "str", "(", "nr", ")", "for", "nr", "in", "range", "(", "max", "(", "labels", ")", "+", "1", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_utils.check_correct_nr_labels": [[58, 67], ["len", "print", "dataset_utils.get_mask_labels", "len", "len", "print"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_utils.get_mask_labels"], ["", "def", "check_correct_nr_labels", "(", "labels", ",", "instances", ")", ":", "\n", "    ", "r\"\"\"Check that the number of label names manually supplied is consistent \n    with the dataset masks.\n    \"\"\"", "\n", "nr_labels", "=", "len", "(", "get_mask_labels", "(", "instances", ")", ")", "\n", "print", "(", "nr_labels", ")", "\n", "assert", "nr_labels", "<=", "len", "(", "labels", ")", ",", "\"There are mask indexes not accounted for in the manually supplied label list\"", "\n", "if", "nr_labels", "<", "len", "(", "labels", ")", ":", "\n", "        ", "print", "(", "'Warning: Some labels are not represented in the data'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_utils.get_normalization_values": [[68, 83], ["torch.empty", "torch.empty", "torch.sum", "torch.sum", "torch.sqrt"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum"], ["", "", "def", "get_normalization_values", "(", "instances", ")", ":", "\n", "    ", "r\"\"\"Get normalization values for a dataset.\"\"\"", "\n", "count", "=", "0", "\n", "mean", "=", "torch", ".", "empty", "(", "3", ")", "\n", "std", "=", "torch", ".", "empty", "(", "3", ")", "\n", "for", "instance", "in", "instances", ":", "\n", "        ", "c", ",", "w", ",", "h", ",", "d", "=", "instance", ".", "shape", "\n", "nb_pixels", "=", "d", "*", "h", "*", "w", "\n", "data", "=", "instance", ".", "x", ".", "tensor", "\n", "sum_", "=", "torch", ".", "sum", "(", "data", ",", "dim", "=", "[", "1", ",", "2", ",", "3", "]", ")", "\n", "sum_of_square", "=", "torch", ".", "sum", "(", "data", "**", "2", ",", "dim", "=", "[", "1", ",", "2", ",", "3", "]", ")", "\n", "mean", "=", "(", "count", "*", "mean", "+", "sum_", ")", "/", "(", "count", "+", "nb_pixels", ")", "\n", "std", "=", "(", "count", "*", "std", "+", "sum_of_square", ")", "/", "(", "count", "+", "nb_pixels", ")", "\n", "count", "+=", "nb_pixels", "\n", "", "return", "{", "'mean'", ":", "mean", ",", "'std'", ":", "torch", ".", "sqrt", "(", "std", "-", "mean", "**", "2", ")", "}", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.ds_mr_cardiac_mm.MM_Challenge.__init__": [[19, 63], ["mp.get_dataset_name", "os.path.join", "mp.get_original_data_path", "os.path.join", "ds_mr_cardiac_mm._get_csv_patient_info", "set", "mp.data.datasets.dataset_segmentation.SegmentationDataset.__init__", "os.path.isdir", "ds_mr_cardiac_mm._extract_segmented_slices", "all", "mp.data.datasets.dataset_segmentation.SegmentationInstance", "mp.data.datasets.dataset_segmentation.SegmentationInstance", "instances.append", "instances.append", "file_name.split", "os.listdir", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "subset.items"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_utils.get_dataset_name", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_utils.get_original_data_path", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.ds_mr_cardiac_mm._get_csv_patient_info", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.ds_mr_cardiac_mm._extract_segmented_slices"], ["def", "__init__", "(", "self", ",", "subset", "=", "{", "'Vendor'", ":", "'A'", "}", ",", "hold_out_ixs", "=", "[", "]", ")", ":", "\n", "\n", "        ", "global_name", "=", "'MM_Challenge'", "\n", "name", "=", "du", ".", "get_dataset_name", "(", "global_name", ",", "subset", ")", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "storage_data_path", ",", "global_name", ")", "\n", "original_data_path", "=", "du", ".", "get_original_data_path", "(", "global_name", ")", "\n", "\n", "# Extract ED and ES images, if not already done", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "dataset_path", ")", ":", "\n", "            ", "_extract_segmented_slices", "(", "original_data_path", ",", "dataset_path", ")", "\n", "\n", "# Fetch metadata", "\n", "", "csv_info", "=", "os", ".", "path", ".", "join", "(", "original_data_path", ",", "\"M&Ms Dataset Information.csv\"", ")", "\n", "data_info", "=", "_get_csv_patient_info", "(", "csv_info", ",", "id_ix", "=", "0", ")", "\n", "\n", "# Fetch all patient/study names in the directory (the csv includes ", "\n", "# unlabeled data)", "\n", "study_names", "=", "set", "(", "file_name", ".", "split", "(", "'_'", ")", "[", "0", "]", "for", "file_name", "\n", "in", "os", ".", "listdir", "(", "dataset_path", ")", ")", "\n", "\n", "# Fetch image and mask for each study", "\n", "instances", "=", "[", "]", "\n", "for", "study_name", "in", "study_names", ":", "\n", "# If study is part of the defined subset, add ED and ES images", "\n", "            ", "if", "subset", "is", "None", "or", "all", "(", "\n", "[", "data_info", "[", "study_name", "]", "[", "key", "]", "==", "value", "for", "key", ",", "value", "\n", "in", "subset", ".", "items", "(", ")", "]", ")", ":", "\n", "                ", "instance_ed", "=", "SegmentationInstance", "(", "\n", "x_path", "=", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "study_name", "+", "'_ED.nii.gz'", ")", ",", "\n", "y_path", "=", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "study_name", "+", "'_ED_gt.nii.gz'", ")", ",", "\n", "name", "=", "study_name", "+", "'_ED'", ",", "\n", "group_id", "=", "study_name", "\n", ")", "\n", "instance_es", "=", "SegmentationInstance", "(", "\n", "x_path", "=", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "study_name", "+", "'_ES.nii.gz'", ")", ",", "\n", "y_path", "=", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "study_name", "+", "'_ES_gt.nii.gz'", ")", ",", "\n", "name", "=", "study_name", "+", "'_ES'", ",", "\n", "group_id", "=", "study_name", "\n", ")", "\n", "instances", ".", "append", "(", "instance_ed", ")", "\n", "instances", ".", "append", "(", "instance_es", ")", "\n", "", "", "label_names", "=", "[", "'background'", ",", "'left ventricle'", ",", "'myocardium'", ",", "'right ventricle'", "]", "\n", "super", "(", ")", ".", "__init__", "(", "instances", ",", "name", "=", "name", ",", "label_names", "=", "label_names", ",", "\n", "modality", "=", "'MR'", ",", "nr_channels", "=", "1", ",", "hold_out_ixs", "=", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.ds_mr_cardiac_mm._get_csv_patient_info": [[65, 81], ["dict", "open", "csv.reader", "enumerate"], "function", ["None"], ["", "", "def", "_get_csv_patient_info", "(", "file_full_path", ",", "id_ix", "=", "0", ")", ":", "\n", "    ", "r\"\"\"From a .csv file with the description in the top row, turn into a dict \n    where the keys are the dientifier entries and the values are a dictionary \n    with all other entries.\n    \"\"\"", "\n", "file_info", "=", "dict", "(", ")", "\n", "with", "open", "(", "file_full_path", ",", "newline", "=", "''", ")", "as", "csvfile", ":", "\n", "        ", "reader", "=", "csv", ".", "reader", "(", "csvfile", ",", "delimiter", "=", "'\\t'", ")", "\n", "first_line", "=", "None", "\n", "for", "row", "in", "reader", ":", "\n", "            ", "if", "first_line", "is", "None", ":", "\n", "                ", "first_line", "=", "row", "\n", "", "else", ":", "\n", "                ", "file_info", "[", "row", "[", "id_ix", "]", "]", "=", "{", "key", ":", "row", "[", "key_ix", "]", "for", "key_ix", ",", "key", "in", "\n", "enumerate", "(", "first_line", ")", "}", "\n", "", "", "", "return", "file_info", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.ds_mr_cardiac_mm._extract_segmented_slices": [[82, 143], ["os.path.join", "ds_mr_cardiac_mm._get_csv_patient_info", "os.makedirs", "mp.utils.load_restore.join_path", "os.listdir", "mp.utils.load_restore.join_path", "mp.utils.load_restore.join_path", "SimpleITK.ReadImage", "SimpleITK.GetArrayFromImage", "SimpleITK.ReadImage", "SimpleITK.GetArrayFromImage", "int", "int", "SimpleITK.WriteImage", "SimpleITK.WriteImage", "SimpleITK.WriteImage", "SimpleITK.WriteImage", "len", "SimpleITK.GetImageFromArray", "mp.utils.load_restore.join_path", "SimpleITK.GetImageFromArray", "mp.utils.load_restore.join_path", "SimpleITK.GetImageFromArray", "mp.utils.load_restore.join_path", "SimpleITK.GetImageFromArray", "mp.utils.load_restore.join_path"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.ds_mr_cardiac_mm._get_csv_patient_info", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.join_path", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.join_path", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.join_path", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.join_path", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.join_path", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.join_path", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.join_path"], ["", "def", "_extract_segmented_slices", "(", "source_path", ",", "target_path", ")", ":", "\n", "    ", "r\"\"\"The original dataset has the following structure:\n\n    MM_Challenge_dataset\n    \u251c\u2500\u2500 Training-corrected\n    \u2502 \u251c\u2500\u2500 Labeled\n    \u2502 \u2502 \u251c\u2500\u2500 <study name>\n    \u2502 \u2502 \u2502 \u251c\u2500\u2500 <study name>_sa.nii.gz\n    \u2502 \u2502 \u2502 \u2514\u2500\u2500 <study name>_sa_gt.nii.gz\n    \u2502 \u2502 \u2514\u2500\u2500 ...\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 M&Ms Dataset Information.xlsx\n\n    The \"M&Ms Dataset Information.xlsx\" file should first be converted to csv.\n    Each image and mask have the dimension (timesteps, slices, width, height).\n    This method extracts only the segmented time steps (ED and ES). The result\n    of applying the method is:\n\n    <storage_path>\n    \u251c\u2500\u2500 data\n    \u2502 \u251c\u2500\u2500 MM_Challenge\n    \u2502 \u2502 \u251c\u2500\u2500 <study name>_ED.nii.gz\n    \u2502 \u2502 \u251c\u2500\u2500 <study name>_ED_gt.nii.gz\n    \u2502 \u2502 \u251c\u2500\u2500 <study name>_ES.nii.gz\n    \u2502 \u2502 \u251c\u2500\u2500 <study name>_ES_gt.nii.gz\n    \u2502 \u2502 \u2514\u2500\u2500 ...\n\n    Args:\n        original_data_path (str): path to MM_Challenge_dataset, where the \n        metadata file has been converted to csv.\n    \"\"\"", "\n", "# Fetch metadata", "\n", "csv_info", "=", "os", ".", "path", ".", "join", "(", "source_path", ",", "\"M&Ms Dataset Information.csv\"", ")", "\n", "data_info", "=", "_get_csv_patient_info", "(", "csv_info", ",", "id_ix", "=", "0", ")", "\n", "\n", "# Create directories", "\n", "os", ".", "makedirs", "(", "target_path", ")", "\n", "\n", "# Extract segmented timestamps (ED and ES) and save", "\n", "img_path", "=", "join_path", "(", "[", "source_path", ",", "'Training-corrected'", ",", "'Labeled'", "]", ")", "\n", "for", "study_name", "in", "os", ".", "listdir", "(", "img_path", ")", ":", "\n", "        ", "x_path", "=", "join_path", "(", "[", "img_path", ",", "study_name", ",", "study_name", "+", "\"_sa.nii.gz\"", "]", ")", "\n", "mask_path", "=", "join_path", "(", "[", "img_path", ",", "study_name", ",", "study_name", "+", "\"_sa_gt.nii.gz\"", "]", ")", "\n", "x", "=", "sitk", ".", "ReadImage", "(", "x_path", ")", "\n", "x", "=", "sitk", ".", "GetArrayFromImage", "(", "x", ")", "\n", "mask", "=", "sitk", ".", "ReadImage", "(", "mask_path", ")", "\n", "mask", "=", "sitk", ".", "GetArrayFromImage", "(", "mask", ")", "\n", "assert", "x", ".", "shape", "==", "mask", ".", "shape", "\n", "assert", "len", "(", "x", ".", "shape", ")", "==", "4", "\n", "# There are two times for which segmentation is performed, ED and ES.", "\n", "# These are specified in the metadata file", "\n", "ed_slice", "=", "int", "(", "data_info", "[", "study_name", "]", "[", "\"ED\"", "]", ")", "\n", "es_slice", "=", "int", "(", "data_info", "[", "study_name", "]", "[", "\"ES\"", "]", ")", "\n", "# Store new images", "\n", "sitk", ".", "WriteImage", "(", "sitk", ".", "GetImageFromArray", "(", "x", "[", "ed_slice", "]", ")", ",", "\n", "join_path", "(", "[", "target_path", ",", "study_name", "+", "\"_ED.nii.gz\"", "]", ")", ")", "\n", "sitk", ".", "WriteImage", "(", "sitk", ".", "GetImageFromArray", "(", "mask", "[", "ed_slice", "]", ")", ",", "\n", "join_path", "(", "[", "target_path", ",", "study_name", "+", "\"_ED_gt.nii.gz\"", "]", ")", ")", "\n", "sitk", ".", "WriteImage", "(", "sitk", ".", "GetImageFromArray", "(", "x", "[", "es_slice", "]", ")", ",", "\n", "join_path", "(", "[", "target_path", ",", "study_name", "+", "\"_ES.nii.gz\"", "]", ")", ")", "\n", "sitk", ".", "WriteImage", "(", "sitk", ".", "GetImageFromArray", "(", "mask", "[", "es_slice", "]", ")", ",", "\n", "join_path", "(", "[", "target_path", ",", "study_name", "+", "\"_ES_gt.nii.gz\"", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.ds_mr_hippocampus_dryad.DryadHippocampus.__init__": [[25, 76], ["mp.get_dataset_name", "os.path.join", "mp.get_original_data_path", "set", "mp.data.datasets.dataset_segmentation.SegmentationDataset.__init__", "default.update", "os.path.isdir", "ds_mr_hippocampus_dryad._extract_images", "instances.append", "mp.data.datasets.dataset_segmentation.SegmentationInstance", "[].split", "os.listdir", "os.path.join", "os.path.join", "file_name.split"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_utils.get_dataset_name", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_utils.get_original_data_path", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.update", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.ds_mr_hippocampus_decathlon._extract_images"], ["def", "__init__", "(", "self", ",", "subset", "=", "None", ",", "hold_out_ixs", "=", "None", ",", "merge_labels", "=", "True", ")", ":", "\n", "# Modality is either: \"T1w\" or \"T2w\"", "\n", "# Resolution is either: \"Standard\" or \"Hires\"", "\n", "# If you want to use different resolutions or modalities, please create another object with a different subset", "\n", "        ", "default", "=", "{", "\"Modality\"", ":", "\"T1w\"", ",", "\"Resolution\"", ":", "\"Standard\"", "}", "\n", "if", "subset", "is", "not", "None", ":", "\n", "            ", "default", ".", "update", "(", "subset", ")", "\n", "subset", "=", "default", "\n", "", "else", ":", "\n", "            ", "subset", "=", "default", "\n", "\n", "# Hires T2w is not available", "\n", "", "assert", "not", "(", "subset", "[", "\"Resolution\"", "]", "==", "\"Standard\"", "and", "subset", "[", "\"Modality\"", "]", "==", "\"T2w\"", ")", ",", "\"Hires T2w not available for the Dryad Hippocampus dataset\"", "\n", "\n", "if", "hold_out_ixs", "is", "None", ":", "\n", "            ", "hold_out_ixs", "=", "[", "]", "\n", "\n", "", "global_name", "=", "'DryadHippocampus'", "\n", "name", "=", "du", ".", "get_dataset_name", "(", "global_name", ",", "subset", ")", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "storage_data_path", ",", "\n", "global_name", ",", "\n", "\"Merged Labels\"", "if", "merge_labels", "else", "\"Original\"", ",", "\n", "\"\"", ".", "join", "(", "[", "f\"{key}[{subset[key]}]\"", "for", "key", "in", "[", "\"Modality\"", ",", "\"Resolution\"", "]", "]", ")", "\n", ")", "\n", "original_data_path", "=", "du", ".", "get_original_data_path", "(", "global_name", ")", "\n", "\n", "# Copy the images if not done already", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "dataset_path", ")", ":", "\n", "            ", "_extract_images", "(", "original_data_path", ",", "dataset_path", ",", "merge_labels", ",", "subset", ")", "\n", "\n", "# Fetch all patient/study names", "\n", "", "study_names", "=", "set", "(", "file_name", ".", "split", "(", "'.nii'", ")", "[", "0", "]", ".", "split", "(", "'_gt'", ")", "[", "0", "]", "for", "file_name", "in", "os", ".", "listdir", "(", "dataset_path", ")", ")", "\n", "\n", "# Build instances", "\n", "instances", "=", "[", "]", "\n", "for", "study_name", "in", "study_names", ":", "\n", "            ", "instances", ".", "append", "(", "SegmentationInstance", "(", "\n", "x_path", "=", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "study_name", "+", "'.nii.gz'", ")", ",", "\n", "y_path", "=", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "study_name", "+", "'_gt.nii.gz'", ")", ",", "\n", "name", "=", "study_name", ",", "\n", "group_id", "=", "None", "\n", ")", ")", "\n", "\n", "", "if", "merge_labels", ":", "\n", "            ", "label_names", "=", "[", "'background'", ",", "'hippocampus'", "]", "\n", "", "else", ":", "\n", "            ", "label_names", "=", "[", "'background'", ",", "'subiculum'", ",", "'CA1-3'", ",", "'CA4-DG'", "]", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "instances", ",", "name", "=", "name", ",", "label_names", "=", "label_names", ",", "\n", "modality", "=", "subset", "[", "\"Modality\"", "]", "+", "' MRI'", ",", "nr_channels", "=", "1", ",", "hold_out_ixs", "=", "hold_out_ixs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.ds_mr_hippocampus_dryad._extract_images": [[78, 153], ["os.makedirs", "filter", "numpy.any", "numpy.any", "numpy.any", "os.path.join", "os.listdir", "os.path.join", "SimpleITK.ReadImage", "SimpleITK.GetArrayFromImage", "re.match", "re.match", "os.path.join", "SimpleITK.ReadImage", "SimpleITK.GetArrayFromImage", "ds_mr_hippocampus_dryad._extract_images.bbox_3D"], "function", ["None"], ["", "", "def", "_extract_images", "(", "source_path", ",", "target_path", ",", "merge_labels", ",", "subset", ")", ":", "\n", "    ", "r\"\"\"Extracts images, merges mask labels (if specified) and saves the\n    modified images.\n    \"\"\"", "\n", "\n", "def", "bbox_3D", "(", "img", ")", ":", "\n", "        ", "r", "=", "np", ".", "any", "(", "img", ",", "axis", "=", "(", "1", ",", "2", ")", ")", "\n", "c", "=", "np", ".", "any", "(", "img", ",", "axis", "=", "(", "0", ",", "2", ")", ")", "\n", "z", "=", "np", ".", "any", "(", "img", ",", "axis", "=", "(", "0", ",", "1", ")", ")", "\n", "\n", "rmin", ",", "rmax", "=", "np", ".", "where", "(", "r", ")", "[", "0", "]", "[", "[", "0", ",", "-", "1", "]", "]", "\n", "cmin", ",", "cmax", "=", "np", ".", "where", "(", "c", ")", "[", "0", "]", "[", "[", "0", ",", "-", "1", "]", "]", "\n", "zmin", ",", "zmax", "=", "np", ".", "where", "(", "z", ")", "[", "0", "]", "[", "[", "0", ",", "-", "1", "]", "]", "\n", "\n", "return", "rmin", ",", "rmax", ",", "cmin", ",", "cmax", ",", "zmin", ",", "zmax", "\n", "\n", "# Create directories", "\n", "", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "target_path", ")", ")", "\n", "\n", "# Patient folders s01, s02, ...", "\n", "for", "patient_folder", "in", "filter", "(", "lambda", "s", ":", "re", ".", "match", "(", "r\"^s[0-9]+.*\"", ",", "s", ")", ",", "os", ".", "listdir", "(", "source_path", ")", ")", ":", "\n", "\n", "# Loading the image", "\n", "        ", "image_path", "=", "os", ".", "path", ".", "join", "(", "source_path", ",", "patient_folder", ",", "\n", "f\"{patient_folder}_{subset['Modality'].lower()}_\"", "\n", "f\"{subset['Resolution'].lower()}_defaced_MNI.nii.gz\"", ")", "\n", "x", "=", "sitk", ".", "ReadImage", "(", "image_path", ")", "\n", "x", "=", "sitk", ".", "GetArrayFromImage", "(", "x", ")", "\n", "\n", "# For each MRI, there are 2 segmentation (left and right hippocampus)", "\n", "for", "side", "in", "[", "\"L\"", ",", "\"R\"", "]", ":", "\n", "# Loading the label", "\n", "            ", "label_path", "=", "os", ".", "path", ".", "join", "(", "source_path", ",", "patient_folder", ",", "\n", "f\"{patient_folder}_hippolabels_\"", "\n", "f\"{'hres' if subset['Resolution'] == 'Hires' else 't1w_standard'}\"", "\n", "f\"_{side}_MNI.nii.gz\"", ")", "\n", "\n", "y", "=", "sitk", ".", "ReadImage", "(", "label_path", ")", "\n", "y", "=", "sitk", ".", "GetArrayFromImage", "(", "y", ")", "\n", "\n", "# We need to recover the study name of the image name to construct the name of the segmentation files", "\n", "study_name", "=", "f\"{patient_folder}_{side}\"", "\n", "\n", "# Average label shape (T1w, standard): (37.0, 36.3, 26.7)", "\n", "# Average label shape (T1w, hires): (94.1, 92.1, 68.5)", "\n", "# Average label shape (T2w, hires): (94.1, 92.1, 68.5)", "\n", "assert", "x", ".", "shape", "==", "y", ".", "shape", "\n", "\n", "# Disclaimer: next part is ugly and not many checks are made", "\n", "\n", "# So we first compute the bounding box", "\n", "rmin", ",", "rmax", ",", "cmin", ",", "cmax", ",", "zmin", ",", "zmax", "=", "bbox_3D", "(", "y", ")", "\n", "\n", "# Compute the start idx for each dim", "\n", "dr", "=", "(", "rmax", "-", "rmin", ")", "//", "4", "\n", "dc", "=", "(", "cmax", "-", "cmin", ")", "//", "4", "\n", "dz", "=", "(", "zmax", "-", "zmin", ")", "//", "4", "\n", "\n", "# Reshaping", "\n", "y", "=", "y", "[", "rmin", "-", "dr", ":", "rmax", "+", "dr", ",", "\n", "cmin", "-", "dc", ":", "cmax", "+", "dc", ",", "\n", "zmin", "-", "dz", ":", "zmax", "+", "dz", "]", "\n", "\n", "if", "merge_labels", ":", "\n", "                ", "y", "[", "y", ">", "1", "]", "=", "1", "\n", "\n", "", "x_cropped", "=", "x", "[", "rmin", "-", "dr", ":", "rmax", "+", "dr", ",", "\n", "cmin", "-", "dc", ":", "cmax", "+", "dc", ",", "\n", "zmin", "-", "dz", ":", "zmax", "+", "dz", "]", "\n", "\n", "# Save new images so they can be loaded directly", "\n", "sitk", ".", "WriteImage", "(", "sitk", ".", "GetImageFromArray", "(", "y", ")", ",", "\n", "join_path", "(", "[", "target_path", ",", "study_name", "+", "\"_gt.nii.gz\"", "]", ")", ")", "\n", "sitk", ".", "WriteImage", "(", "sitk", ".", "GetImageFromArray", "(", "x_cropped", ")", ",", "\n", "join_path", "(", "[", "target_path", ",", "study_name", "+", "\".nii.gz\"", "]", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.ds_mr_prostate_decathlon.DecathlonProstateT2.__init__": [[18, 48], ["os.path.join", "mp.get_original_data_path", "set", "mp.data.datasets.dataset_segmentation.SegmentationDataset.__init__", "os.path.isdir", "ds_mr_prostate_decathlon._extract_t2_images", "instances.append", "mp.data.datasets.dataset_segmentation.SegmentationInstance", "[].split", "os.listdir", "os.path.join", "os.path.join", "file_name.split"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_utils.get_original_data_path", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.ds_mr_prostate_decathlon._extract_t2_images"], ["def", "__init__", "(", "self", ",", "subset", "=", "None", ",", "hold_out_ixs", "=", "[", "]", ",", "merge_labels", "=", "True", ")", ":", "\n", "        ", "assert", "subset", "is", "None", ",", "\"No subsets for this dataset.\"", "\n", "\n", "global_name", "=", "'DecathlonProstateT2'", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "storage_data_path", ",", "global_name", ")", "\n", "original_data_path", "=", "du", ".", "get_original_data_path", "(", "global_name", ")", "\n", "\n", "# Separate T2 images, if not already done", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "dataset_path", ")", ":", "\n", "            ", "_extract_t2_images", "(", "original_data_path", ",", "dataset_path", ",", "merge_labels", ")", "\n", "\n", "# Fetch all patient/study names", "\n", "", "study_names", "=", "set", "(", "file_name", ".", "split", "(", "'.nii'", ")", "[", "0", "]", ".", "split", "(", "'_gt'", ")", "[", "0", "]", "for", "file_name", "\n", "in", "os", ".", "listdir", "(", "dataset_path", ")", ")", "\n", "\n", "# Build instances", "\n", "instances", "=", "[", "]", "\n", "for", "study_name", "in", "study_names", ":", "\n", "            ", "instances", ".", "append", "(", "SegmentationInstance", "(", "\n", "x_path", "=", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "study_name", "+", "'.nii.gz'", ")", ",", "\n", "y_path", "=", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "study_name", "+", "'_gt.nii.gz'", ")", ",", "\n", "name", "=", "study_name", ",", "\n", "group_id", "=", "None", "\n", ")", ")", "\n", "", "if", "merge_labels", ":", "\n", "            ", "label_names", "=", "[", "'background'", ",", "'prostate'", "]", "\n", "", "else", ":", "\n", "            ", "label_names", "=", "[", "'background'", ",", "'peripheral zone'", ",", "'central gland'", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "instances", ",", "name", "=", "global_name", ",", "label_names", "=", "label_names", ",", "\n", "modality", "=", "'MR'", ",", "nr_channels", "=", "1", ",", "hold_out_ixs", "=", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.ds_mr_prostate_decathlon._extract_t2_images": [[49, 81], ["os.path.join", "os.path.join", "os.makedirs", "SimpleITK.ReadImage", "SimpleITK.ReadImage", "SimpleITK.GetArrayFromImage", "SimpleITK.WriteImage", "SimpleITK.WriteImage", "os.listdir", "os.path.join", "SimpleITK.GetArrayFromImage", "os.path.join", "numpy.where", "filename.replace().split", "SimpleITK.GetImageFromArray", "mp.utils.load_restore.join_path", "SimpleITK.GetImageFromArray", "mp.utils.load_restore.join_path", "filename.replace"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.join_path", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.join_path"], ["", "", "def", "_extract_t2_images", "(", "source_path", ",", "target_path", ",", "merge_labels", ")", ":", "\n", "    ", "r\"\"\"Extracts T2 images, merges mask labels (if specified) and saves the\n    modified images.\n    \"\"\"", "\n", "images_path", "=", "os", ".", "path", ".", "join", "(", "source_path", ",", "'imagesTr'", ")", "\n", "labels_path", "=", "os", ".", "path", ".", "join", "(", "source_path", ",", "'labelsTr'", ")", "\n", "\n", "# Filenames have the form 'prostate_XX.nii.gz'", "\n", "filenames", "=", "[", "x", "for", "x", "in", "os", ".", "listdir", "(", "images_path", ")", "if", "x", "[", ":", "8", "]", "==", "'prostate'", "]", "\n", "\n", "# Create directories", "\n", "os", ".", "makedirs", "(", "target_path", ")", "\n", "\n", "for", "filename", "in", "filenames", ":", "\n", "\n", "# Extract only T2-weighted", "\n", "        ", "x", "=", "sitk", ".", "ReadImage", "(", "os", ".", "path", ".", "join", "(", "images_path", ",", "filename", ")", ")", "\n", "x", "=", "sitk", ".", "GetArrayFromImage", "(", "x", ")", "[", "0", "]", "\n", "y", "=", "sitk", ".", "ReadImage", "(", "os", ".", "path", ".", "join", "(", "labels_path", ",", "filename", ")", ")", "\n", "y", "=", "sitk", ".", "GetArrayFromImage", "(", "y", ")", "\n", "assert", "x", ".", "shape", "==", "y", ".", "shape", "\n", "\n", "# No longer distinguish between central and peripheral zones", "\n", "if", "merge_labels", ":", "\n", "            ", "y", "=", "np", ".", "where", "(", "y", "==", "2", ",", "1", ",", "y", ")", "\n", "\n", "# Save new images so they can be loaded directly", "\n", "", "study_name", "=", "filename", ".", "replace", "(", "'_'", ",", "''", ")", ".", "split", "(", "'.nii'", ")", "[", "0", "]", "\n", "sitk", ".", "WriteImage", "(", "sitk", ".", "GetImageFromArray", "(", "x", ")", ",", "\n", "join_path", "(", "[", "target_path", ",", "study_name", "+", "\".nii.gz\"", "]", ")", ")", "\n", "sitk", ".", "WriteImage", "(", "sitk", ".", "GetImageFromArray", "(", "y", ")", ",", "\n", "join_path", "(", "[", "target_path", ",", "study_name", "+", "\"_gt.nii.gz\"", "]", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_segmentation.SegmentationInstance.__init__": [[13, 36], ["isinstance", "isinstance", "torchio.Image", "torchio.Image", "mp.data.datasets.dataset.Instance.__init__"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["    ", "def", "__init__", "(", "self", ",", "x_path", ",", "y_path", ",", "name", "=", "None", ",", "class_ix", "=", "0", ",", "group_id", "=", "None", ")", ":", "\n", "        ", "r\"\"\"A segmentation instance, using the TorchIO library.\n\n        Args:\n        x_path (str): path to image\n        y_path (str): path to segmentation mask\n        name (str): name of instance for case-wise evaluation\n        class_ix (int): optinal \"class\" index. During splitting of the dataset, \n            the resulting subsets are stratesfied according to this value (i.e. \n            there are about as many examples from each class in each fold\n            of each class on each fold).\n        group_id (comparable): instances with same group_id (e.g. patient id)\n            are always in the same fold\n\n        Note that torchio images have the shape (channels, w, h, d)\n        \"\"\"", "\n", "assert", "isinstance", "(", "x_path", ",", "str", ")", "\n", "assert", "isinstance", "(", "y_path", ",", "str", ")", "\n", "x", "=", "torchio", ".", "Image", "(", "x_path", ",", "type", "=", "torchio", ".", "INTENSITY", ")", "\n", "y", "=", "torchio", ".", "Image", "(", "y_path", ",", "type", "=", "torchio", ".", "LABEL", ")", "\n", "self", ".", "shape", "=", "x", ".", "shape", "\n", "super", "(", ")", ".", "__init__", "(", "x", "=", "x", ",", "y", "=", "y", ",", "name", "=", "name", ",", "class_ix", "=", "class_ix", ",", "\n", "group_id", "=", "group_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_segmentation.SegmentationInstance.get_subject": [[37, 41], ["torchio.Subject"], "methods", ["None"], ["", "def", "get_subject", "(", "self", ")", ":", "\n", "        ", "return", "torchio", ".", "Subject", "(", "\n", "x", "=", "self", ".", "x", ",", "\n", "y", "=", "self", ".", "y", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_segmentation.SegmentationDataset.__init__": [[60, 82], ["print", "print", "len", "mp.data.datasets.dataset.Dataset.__init__", "mp.get_mean_std_shape", "print", "mp.get_mask_labels", "len", "mp.check_correct_nr_labels"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_utils.get_mean_std_shape", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_utils.get_mask_labels", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_utils.check_correct_nr_labels"], ["def", "__init__", "(", "self", ",", "instances", ",", "name", ",", "mean_shape", "=", "None", ",", "\n", "label_names", "=", "None", ",", "nr_channels", "=", "1", ",", "modality", "=", "'unknown'", ",", "hold_out_ixs", "=", "[", "]", ",", "\n", "check_correct_nr_labels", "=", "False", ")", ":", "\n", "# Set mean input shape and mask labels, if these are not provided", "\n", "        ", "print", "(", "'\\nDATASET: {} with {} instances'", ".", "format", "(", "name", ",", "len", "(", "instances", ")", ")", ")", "\n", "if", "mean_shape", "is", "None", ":", "\n", "            ", "mean_shape", ",", "shape_std", "=", "du", ".", "get_mean_std_shape", "(", "instances", ")", "\n", "print", "(", "'Mean shape: {}, shape std: {}'", ".", "format", "(", "mean_shape", ",", "shape_std", ")", ")", "\n", "", "if", "label_names", "is", "None", ":", "\n", "            ", "label_names", "=", "du", ".", "get_mask_labels", "(", "instances", ")", "\n", "", "else", ":", "\n", "            ", "if", "check_correct_nr_labels", ":", "\n", "                ", "du", ".", "check_correct_nr_labels", "(", "label_names", ",", "instances", ")", "\n", "", "", "print", "(", "'Mask labels: {}\\n'", ".", "format", "(", "label_names", ")", ")", "\n", "self", ".", "mean_shape", "=", "mean_shape", "\n", "self", ".", "label_names", "=", "label_names", "\n", "self", ".", "nr_labels", "=", "len", "(", "label_names", ")", "\n", "self", ".", "nr_channels", "=", "nr_channels", "\n", "self", ".", "modality", "=", "modality", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ",", "instances", "=", "instances", ",", "\n", "mean_shape", "=", "mean_shape", ",", "output_shape", "=", "mean_shape", ",", "\n", "hold_out_ixs", "=", "hold_out_ixs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.ds_mr_hippocampus_harp.HarP.__init__": [[25, 74], ["mp.get_dataset_name", "os.path.join", "mp.get_original_data_path", "mp.data.datasets.dataset_segmentation.SegmentationDataset.__init__", "default.update", "folders.append", "folders.append", "os.path.join", "set", "os.path.isdir", "ds_mr_hippocampus_harp._extract_images", "instances.append", "mp.data.datasets.dataset_segmentation.SegmentationInstance", "[].split", "os.listdir", "os.path.join", "os.path.join", "os.path.join", "file_name.split"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_utils.get_dataset_name", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_utils.get_original_data_path", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.update", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.ds_mr_hippocampus_decathlon._extract_images"], ["def", "__init__", "(", "self", ",", "subset", "=", "None", ",", "hold_out_ixs", "=", "None", ",", "merge_labels", "=", "True", ")", ":", "\n", "# Part is either: \"Training\", \"Validation\" or \"All\"", "\n", "        ", "default", "=", "{", "\"Part\"", ":", "\"All\"", "}", "\n", "if", "subset", "is", "not", "None", ":", "\n", "            ", "default", ".", "update", "(", "subset", ")", "\n", "subset", "=", "default", "\n", "", "else", ":", "\n", "            ", "subset", "=", "default", "\n", "\n", "", "if", "hold_out_ixs", "is", "None", ":", "\n", "            ", "hold_out_ixs", "=", "[", "]", "\n", "\n", "", "global_name", "=", "'HarP'", "\n", "name", "=", "du", ".", "get_dataset_name", "(", "global_name", ",", "subset", ")", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "storage_data_path", ",", "global_name", ")", "\n", "original_data_path", "=", "du", ".", "get_original_data_path", "(", "global_name", ")", "\n", "\n", "# Build instances", "\n", "instances", "=", "[", "]", "\n", "folders", "=", "[", "]", "\n", "if", "subset", "[", "\"Part\"", "]", "in", "[", "\"Training\"", ",", "\"All\"", "]", ":", "\n", "            ", "folders", ".", "append", "(", "(", "\"100\"", ",", "\"Training\"", ")", ")", "\n", "", "if", "subset", "[", "\"Part\"", "]", "in", "[", "\"Validation\"", ",", "\"All\"", "]", ":", "\n", "            ", "folders", ".", "append", "(", "(", "\"35\"", ",", "\"Validation\"", ")", ")", "\n", "\n", "", "for", "orig_folder", ",", "dst_folder", "in", "folders", ":", "\n", "# Paths with the sub-folder for the current subset", "\n", "            ", "dst_folder_path", "=", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "dst_folder", ")", "\n", "\n", "# Copy the images if not done already", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "dst_folder_path", ")", ":", "\n", "                ", "_extract_images", "(", "original_data_path", ",", "dst_folder_path", ",", "orig_folder", ")", "\n", "\n", "# Fetch all patient/study names", "\n", "", "study_names", "=", "set", "(", "file_name", ".", "split", "(", "'.nii'", ")", "[", "0", "]", ".", "split", "(", "'_gt'", ")", "[", "0", "]", "for", "file_name", "\n", "in", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "dst_folder", ")", ")", ")", "\n", "\n", "for", "study_name", "in", "study_names", ":", "\n", "                ", "instances", ".", "append", "(", "SegmentationInstance", "(", "\n", "x_path", "=", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "dst_folder", ",", "study_name", "+", "'.nii.gz'", ")", ",", "\n", "y_path", "=", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "dst_folder", ",", "study_name", "+", "'_gt.nii.gz'", ")", ",", "\n", "name", "=", "study_name", ",", "\n", "group_id", "=", "None", "\n", ")", ")", "\n", "\n", "", "", "label_names", "=", "[", "'background'", ",", "'hippocampus'", "]", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "instances", ",", "name", "=", "name", ",", "label_names", "=", "label_names", ",", "\n", "modality", "=", "'T1w MRI'", ",", "nr_channels", "=", "1", ",", "hold_out_ixs", "=", "hold_out_ixs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.ds_mr_hippocampus_harp._extract_images": [[76, 152], ["numpy.array", "os.path.join", "os.path.join", "os.makedirs", "os.listdir", "numpy.any", "numpy.any", "numpy.any", "os.path.join", "nibabel.load", "nibabel.Nifti1Image", "re.match", "os.path.join", "nib.load.get_data", "Exception", "SimpleITK.ReadImage", "SimpleITK.GetArrayFromImage", "ds_mr_hippocampus_harp._extract_images.bbox_3D"], "function", ["None"], ["", "", "def", "_extract_images", "(", "source_path", ",", "target_path", ",", "subset", ")", ":", "\n", "    ", "r\"\"\"Extracts images, merges mask labels (if specified) and saves the\n    modified images.\n    \"\"\"", "\n", "\n", "def", "bbox_3D", "(", "img", ")", ":", "\n", "        ", "r", "=", "np", ".", "any", "(", "img", ",", "axis", "=", "(", "1", ",", "2", ")", ")", "\n", "c", "=", "np", ".", "any", "(", "img", ",", "axis", "=", "(", "0", ",", "2", ")", ")", "\n", "z", "=", "np", ".", "any", "(", "img", ",", "axis", "=", "(", "0", ",", "1", ")", ")", "\n", "\n", "rmin", ",", "rmax", "=", "np", ".", "where", "(", "r", ")", "[", "0", "]", "[", "[", "0", ",", "-", "1", "]", "]", "\n", "cmin", ",", "cmax", "=", "np", ".", "where", "(", "c", ")", "[", "0", "]", "[", "[", "0", ",", "-", "1", "]", "]", "\n", "zmin", ",", "zmax", "=", "np", ".", "where", "(", "z", ")", "[", "0", "]", "[", "[", "0", ",", "-", "1", "]", "]", "\n", "\n", "return", "rmin", ",", "rmax", ",", "cmin", ",", "cmax", ",", "zmin", ",", "zmax", "\n", "\n", "# Folder 100 is for training (100 subjects), 35 subjects are left over for validation", "\n", "", "affine", "=", "np", ".", "array", "(", "[", "[", "1", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "1", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "1", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "1", "]", "]", ")", "\n", "\n", "images_path", "=", "os", ".", "path", ".", "join", "(", "source_path", ",", "subset", ")", "\n", "labels_path", "=", "os", ".", "path", ".", "join", "(", "source_path", ",", "f'Labels_{subset}_NIFTI'", ")", "\n", "\n", "# Create directories", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "target_path", ")", ")", "\n", "\n", "# For each MRI, there are 2 segmentation (left and right hippocampus)", "\n", "for", "filename", "in", "os", ".", "listdir", "(", "images_path", ")", ":", "\n", "# Loading the .mnc file and converting it to a .nii.gz file", "\n", "        ", "minc", "=", "nib", ".", "load", "(", "os", ".", "path", ".", "join", "(", "images_path", ",", "filename", ")", ")", "\n", "x", "=", "nib", ".", "Nifti1Image", "(", "minc", ".", "get_data", "(", ")", ",", "affine", "=", "affine", ")", "\n", "\n", "# We need to recover the study name of the image name to construct the name of the segmentation files", "\n", "match", "=", "re", ".", "match", "(", "r\"ADNI_[0-9]+_S_[0-9]+_[0-9]+\"", ",", "filename", ")", "\n", "if", "match", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "f\"A file ({filename}) does not match the expected file naming format\"", ")", "\n", "\n", "# For each side of the brain", "\n", "", "for", "side", "in", "[", "\"_L\"", ",", "\"_R\"", "]", ":", "\n", "            ", "study_name", "=", "match", "[", "0", "]", "+", "side", "\n", "\n", "y", "=", "sitk", ".", "ReadImage", "(", "os", ".", "path", ".", "join", "(", "labels_path", ",", "study_name", "+", "\".nii\"", ")", ")", "\n", "y", "=", "sitk", ".", "GetArrayFromImage", "(", "y", ")", "\n", "\n", "# Shape expected: (189, 233, 197)", "\n", "# Average label shape (Training): (27.1, 36.7, 22.0)", "\n", "# Average label shape (Validation): (27.7, 35.2, 21.8)", "\n", "assert", "x", ".", "shape", "==", "y", ".", "shape", "\n", "# Disclaimer: next part is ugly and not many checks are made", "\n", "# BUGFIX: Some segmentation have some weird values eg {26896.988, 26897.988} instead of {0, 1}", "\n", "y", "=", "(", "y", "-", "np", ".", "min", "(", "y", ".", "flat", ")", ")", ".", "astype", "(", "np", ".", "uint32", ")", "\n", "\n", "# So we first compute the bounding box", "\n", "rmin", ",", "rmax", ",", "cmin", ",", "cmax", ",", "zmin", ",", "zmax", "=", "bbox_3D", "(", "y", ")", "\n", "\n", "# Compute the start idx for each dim", "\n", "dr", "=", "(", "rmax", "-", "rmin", ")", "//", "4", "\n", "dc", "=", "(", "cmax", "-", "cmin", ")", "//", "4", "\n", "dz", "=", "(", "zmax", "-", "zmin", ")", "//", "4", "\n", "\n", "# Reshaping", "\n", "y", "=", "y", "[", "rmin", "-", "dr", ":", "rmax", "+", "dr", ",", "\n", "cmin", "-", "dc", ":", "cmax", "+", "dc", ",", "\n", "zmin", "-", "dz", ":", "zmax", "+", "dz", "]", "\n", "\n", "x_cropped", "=", "x", ".", "get_data", "(", ")", "[", "rmin", "-", "dr", ":", "rmax", "+", "dr", ",", "\n", "cmin", "-", "dc", ":", "cmax", "+", "dc", ",", "\n", "zmin", "-", "dz", ":", "zmax", "+", "dz", "]", "\n", "\n", "# Save new images so they can be loaded directly", "\n", "sitk", ".", "WriteImage", "(", "sitk", ".", "GetImageFromArray", "(", "y", ")", ",", "\n", "join_path", "(", "[", "target_path", ",", "study_name", "+", "\"_gt.nii.gz\"", "]", ")", ")", "\n", "sitk", ".", "WriteImage", "(", "sitk", ".", "GetImageFromArray", "(", "x_cropped", ")", ",", "\n", "join_path", "(", "[", "target_path", ",", "study_name", "+", "\".nii.gz\"", "]", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.__init__": [[19, 30], ["sorted", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "name", ",", "instances", ",", "classes", "=", "(", "'0'", ")", ",", "hold_out_ixs", "=", "[", "]", ",", "\n", "mean_shape", "=", "(", "1", ",", "32", ",", "32", ")", ",", "output_shape", "=", "(", "1", ",", "32", ",", "32", ")", ",", "x_norm", "=", "None", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "# Sort instances in terms of name", "\n", "self", ".", "instances", "=", "sorted", "(", "instances", ",", "key", "=", "lambda", "ex", ":", "ex", ".", "name", ")", "\n", "self", ".", "size", "=", "len", "(", "instances", ")", "\n", "self", ".", "classes", "=", "classes", "\n", "self", ".", "hold_out_ixs", "=", "hold_out_ixs", "\n", "self", ".", "mean_shape", "=", "mean_shape", "\n", "self", ".", "output_shape", "=", "output_shape", "\n", "self", ".", "x_norm", "=", "x_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_dist": [[31, 45], ["enumerate", "range"], "methods", ["None"], ["", "def", "get_class_dist", "(", "self", ",", "ixs", "=", "None", ")", ":", "\n", "        ", "r\"\"\"Get class (category) distribution\n\n        Args:\n            ixs (list[int]): if not None, distribution for only these indexes. \n            Otherwise distribution for all indexes not part of the hold-out.\n        \"\"\"", "\n", "if", "ixs", "is", "None", ":", "\n", "            ", "ixs", "=", "[", "ix", "for", "ix", "in", "range", "(", "self", ".", "size", ")", "if", "ix", "not", "in", "self", ".", "hold_out_ixs", "]", "\n", "", "class_dist", "=", "{", "class_ix", ":", "0", "for", "class_ix", "in", "self", ".", "classes", "}", "\n", "for", "ex_ix", ",", "ex", "in", "enumerate", "(", "self", ".", "instances", ")", ":", "\n", "            ", "if", "ex_ix", "in", "ixs", ":", "\n", "                ", "class_dist", "[", "self", ".", "classes", "[", "ex", ".", "class_ix", "]", "]", "+=", "1", "\n", "", "", "return", "class_dist", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_instance_ixs": [[46, 50], ["enumerate", "dataset.Dataset.classes.index"], "methods", ["None"], ["", "def", "get_class_instance_ixs", "(", "self", ",", "class_name", ",", "exclude_ixs", ")", ":", "\n", "        ", "r\"\"\"Get instances for a class, excluding those in exclude_ixs.\"\"\"", "\n", "return", "[", "ix", "for", "ix", ",", "ex", "in", "enumerate", "(", "self", ".", "instances", ")", "if", "\n", "ex", ".", "class_ix", "==", "self", ".", "classes", ".", "index", "(", "class_name", ")", "and", "ix", "not", "in", "exclude_ixs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_instance": [[51, 59], ["len", "len"], "methods", ["None"], ["", "def", "get_instance", "(", "self", ",", "name", ")", ":", "\n", "        ", "r\"\"\"Get an instance from a name.\"\"\"", "\n", "instances", "=", "[", "instance", "for", "instance", "in", "self", ".", "instances", "if", "instance", ".", "name", "==", "name", "]", "\n", "if", "len", "(", "instances", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "instances", ")", "==", "1", ",", "\"There are more than one instance with that name\"", "\n", "return", "instances", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_instance_ixs_from_names": [[60, 64], ["enumerate"], "methods", ["None"], ["", "", "def", "get_instance_ixs_from_names", "(", "self", ",", "name_lst", ")", ":", "\n", "        ", "r\"\"\"Get instance ixs from a list of names.\"\"\"", "\n", "ixs", "=", "[", "ix", "for", "ix", ",", "instance", "in", "enumerate", "(", "self", ".", "instances", ")", "if", "instance", ".", "name", "in", "name_lst", "]", "\n", "return", "ixs", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Instance.__init__": [[81, 87], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "x", ",", "y", ",", "name", "=", "None", ",", "class_ix", "=", "0", ",", "group_id", "=", "None", ")", ":", "\n", "        ", "self", ".", "x", "=", "x", "\n", "self", ".", "y", "=", "y", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "class_ix", "=", "class_ix", "\n", "self", ".", "group_id", "=", "group_id", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_classification.ClassificationPathInstance.__init__": [[14, 18], ["isinstance", "isinstance", "mp.data.datasets.dataset.Instance.__init__"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "x_path", ",", "y", ",", "name", "=", "None", ",", "group_id", "=", "None", ")", ":", "\n", "        ", "assert", "isinstance", "(", "x_path", ",", "str", ")", "\n", "assert", "isinstance", "(", "y", ",", "int", ")", "\n", "super", "(", ")", ".", "__init__", "(", "x", "=", "x_path", ",", "y", "=", "y", ",", "class_ix", "=", "y", ",", "name", "=", "name", ",", "group_id", "=", "group_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_classification.SplitClassImageDataset.__init__": [[24, 43], ["mp.get_original_data_path", "mp.data.datasets.dataset.Dataset.__init__", "os.path.join", "os.listdir", "len", "os.path.join", "os.listdir", "tuple", "len", "list", "classes.append", "dataset_classification.ClassificationPathInstance", "instances.append", "range", "len", "os.path.join", "classes.index"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_utils.get_original_data_path", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "name", ",", "root_path", "=", "None", ",", "input_shape", "=", "(", "1", ",", "32", ",", "32", ")", ",", "x_norm", "=", "None", ")", ":", "\n", "        ", "root_path", "=", "du", ".", "get_original_data_path", "(", "name", ")", "\n", "classes", "=", "[", "]", "\n", "instances", "=", "[", "]", "\n", "hold_out_start", "=", "None", "\n", "for", "split", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "if", "split", "==", "'test'", ":", "\n", "                ", "hold_out_start", "=", "len", "(", "instances", ")", "\n", "", "split_path", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "split", ")", "\n", "for", "class_name", "in", "os", ".", "listdir", "(", "split_path", ")", ":", "\n", "                ", "if", "class_name", "not", "in", "classes", ":", "\n", "                    ", "classes", ".", "append", "(", "class_name", ")", "\n", "", "class_path", "=", "os", ".", "path", ".", "join", "(", "split_path", ",", "class_name", ")", "\n", "for", "img_name", "in", "os", ".", "listdir", "(", "class_path", ")", ":", "\n", "                    ", "instance", "=", "ClassificationPathInstance", "(", "name", "=", "img_name", ",", "x_path", "=", "os", ".", "path", ".", "join", "(", "class_path", ",", "img_name", ")", ",", "y", "=", "classes", ".", "index", "(", "class_name", ")", ")", "\n", "instances", ".", "append", "(", "instance", ")", "\n", "", "", "", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ",", "classes", "=", "tuple", "(", "classes", ")", ",", "instances", "=", "instances", ",", "\n", "mean_shape", "=", "input_shape", ",", "output_shape", "=", "len", "(", "classes", ")", ",", "x_norm", "=", "x_norm", ",", "\n", "hold_out_ixs", "=", "list", "(", "range", "(", "hold_out_start", ",", "len", "(", "instances", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_classification.CIFAR10.__init__": [[47, 51], ["dataset_classification.SplitClassImageDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "root_path", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'Cifar10'", ",", "root_path", "=", "root_path", ",", "\n", "input_shape", "=", "(", "3", ",", "32", ",", "32", ")", ",", "\n", "x_norm", "=", "{", "'mean'", ":", "(", "0.4914", ",", "0.4822", ",", "0.4465", ")", ",", "'std'", ":", "(", "0.247", ",", "0.243", ",", "0.262", ")", "}", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.ds_mr_hippocampus_decathlon.DecathlonHippocampus.__init__": [[21, 55], ["os.path.join", "mp.get_original_data_path", "set", "mp.data.datasets.dataset_segmentation.SegmentationDataset.__init__", "os.path.isdir", "ds_mr_hippocampus_decathlon._extract_images", "instances.append", "mp.data.datasets.dataset_segmentation.SegmentationInstance", "[].split", "os.listdir", "os.path.join", "os.path.join", "file_name.split"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset_utils.get_original_data_path", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.ds_mr_hippocampus_decathlon._extract_images"], ["def", "__init__", "(", "self", ",", "subset", "=", "None", ",", "hold_out_ixs", "=", "None", ",", "merge_labels", "=", "True", ")", ":", "\n", "        ", "assert", "subset", "is", "None", ",", "\"No subsets for this dataset.\"", "\n", "\n", "if", "hold_out_ixs", "is", "None", ":", "\n", "            ", "hold_out_ixs", "=", "[", "]", "\n", "\n", "", "global_name", "=", "'DecathlonHippocampus'", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "storage_data_path", ",", "global_name", ",", "\"Merged Labels\"", "if", "merge_labels", "else", "\"Original\"", ")", "\n", "original_data_path", "=", "du", ".", "get_original_data_path", "(", "global_name", ")", "\n", "\n", "# Copy the images if not done already", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "dataset_path", ")", ":", "\n", "            ", "_extract_images", "(", "original_data_path", ",", "dataset_path", ",", "merge_labels", ")", "\n", "\n", "# Fetch all patient/study names", "\n", "", "study_names", "=", "set", "(", "file_name", ".", "split", "(", "'.nii'", ")", "[", "0", "]", ".", "split", "(", "'_gt'", ")", "[", "0", "]", "for", "file_name", "\n", "in", "os", ".", "listdir", "(", "dataset_path", ")", ")", "\n", "\n", "# Build instances", "\n", "instances", "=", "[", "]", "\n", "for", "study_name", "in", "study_names", ":", "\n", "            ", "instances", ".", "append", "(", "SegmentationInstance", "(", "\n", "x_path", "=", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "study_name", "+", "'.nii.gz'", ")", ",", "\n", "y_path", "=", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "study_name", "+", "'_gt.nii.gz'", ")", ",", "\n", "name", "=", "study_name", ",", "\n", "group_id", "=", "None", "\n", ")", ")", "\n", "\n", "", "if", "merge_labels", ":", "\n", "            ", "label_names", "=", "[", "'background'", ",", "'hippocampus'", "]", "\n", "", "else", ":", "\n", "            ", "label_names", "=", "[", "'background'", ",", "'hippocampus proper'", ",", "'subiculum'", "]", "\n", "", "super", "(", ")", ".", "__init__", "(", "instances", ",", "name", "=", "global_name", ",", "label_names", "=", "label_names", ",", "\n", "modality", "=", "'T1w MRI'", ",", "nr_channels", "=", "1", ",", "hold_out_ixs", "=", "hold_out_ixs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.ds_mr_hippocampus_decathlon._extract_images": [[57, 91], ["os.path.join", "os.path.join", "os.makedirs", "SimpleITK.ReadImage", "SimpleITK.GetArrayFromImage", "SimpleITK.ReadImage", "SimpleITK.GetArrayFromImage", "SimpleITK.WriteImage", "SimpleITK.WriteImage", "os.listdir", "os.path.join", "os.path.join", "filename.replace().split", "SimpleITK.GetImageFromArray", "mp.utils.load_restore.join_path", "SimpleITK.GetImageFromArray", "mp.utils.load_restore.join_path", "filename.replace"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.join_path", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.join_path"], ["", "", "def", "_extract_images", "(", "source_path", ",", "target_path", ",", "merge_labels", ")", ":", "\n", "    ", "r\"\"\"Extracts images, merges mask labels (if specified) and saves the\n    modified images.\n    \"\"\"", "\n", "\n", "images_path", "=", "os", ".", "path", ".", "join", "(", "source_path", ",", "'imagesTr'", ")", "\n", "labels_path", "=", "os", ".", "path", ".", "join", "(", "source_path", ",", "'labelsTr'", ")", "\n", "\n", "# Filenames have the form 'hippocampus_XX.nii.gz'", "\n", "filenames", "=", "[", "x", "for", "x", "in", "os", ".", "listdir", "(", "images_path", ")", "if", "x", "[", ":", "5", "]", "==", "'hippo'", "]", "\n", "\n", "# Create directories", "\n", "os", ".", "makedirs", "(", "target_path", ")", "\n", "\n", "for", "filename", "in", "filenames", ":", "\n", "\n", "# Extract only T2-weighted", "\n", "        ", "x", "=", "sitk", ".", "ReadImage", "(", "os", ".", "path", ".", "join", "(", "images_path", ",", "filename", ")", ")", "\n", "x", "=", "sitk", ".", "GetArrayFromImage", "(", "x", ")", "\n", "y", "=", "sitk", ".", "ReadImage", "(", "os", ".", "path", ".", "join", "(", "labels_path", ",", "filename", ")", ")", "\n", "y", "=", "sitk", ".", "GetArrayFromImage", "(", "y", ")", "\n", "\n", "# Shape expected: (35, 51, 35)", "\n", "# Average label shape: (24.5, 37.8, 21.0)", "\n", "assert", "x", ".", "shape", "==", "y", ".", "shape", "\n", "\n", "# No longer distinguish between hippocampus proper and subiculum", "\n", "if", "merge_labels", ":", "\n", "            ", "y", "[", "y", "==", "2", "]", "=", "1", "\n", "\n", "# Save new images so they can be loaded directly", "\n", "", "study_name", "=", "filename", ".", "replace", "(", "'_'", ",", "''", ")", ".", "split", "(", "'.nii'", ")", "[", "0", "]", "\n", "sitk", ".", "WriteImage", "(", "sitk", ".", "GetImageFromArray", "(", "x", ")", ",", "join_path", "(", "[", "target_path", ",", "study_name", "+", "\".nii.gz\"", "]", ")", ")", "\n", "sitk", ".", "WriteImage", "(", "sitk", ".", "GetImageFromArray", "(", "y", ")", ",", "join_path", "(", "[", "target_path", ",", "study_name", "+", "\"_gt.nii.gz\"", "]", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.connection.check_connection.run_for_mins": [[9, 14], ["range", "time.sleep", "bot.send_msg"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.update_bots.telegram_bot.TelegramBot.send_msg"], ["def", "run_for_mins", "(", "bot", ",", "nr_mins", ")", ":", "\n", "    ", "r\"\"\"Run for an many minutes, giving updates once per minute.\"\"\"", "\n", "for", "i", "in", "range", "(", "1", ",", "nr_mins", "+", "1", ")", ":", "\n", "        ", "time", ".", "sleep", "(", "60", ")", "\n", "bot", ".", "send_msg", "(", "'It has been {} minutes.'", ".", "format", "(", "i", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.connection.check_connection.run_for_hours": [[15, 20], ["range", "time.sleep", "bot.send_msg"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.update_bots.telegram_bot.TelegramBot.send_msg"], ["", "", "def", "run_for_hours", "(", "bot", ",", "nr_hours", ")", ":", "\n", "    ", "r\"\"\"Run for an many hours, giving updates once per hour.\"\"\"", "\n", "for", "i", "in", "range", "(", "1", ",", "nr_hours", "+", "1", ")", ":", "\n", "        ", "time", ".", "sleep", "(", "360", ")", "\n", "bot", ".", "send_msg", "(", "'It has been {} hours'", ".", "format", "(", "i", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.seaborn.legend_utils._remove_empyties_and_duplicates": [[7, 25], ["set", "enumerate", "set.add", "new_labels.append", "new_handles.append", "titles.remove", "len"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.result.Result.add"], ["def", "_remove_empyties_and_duplicates", "(", "handles", ",", "labels", ",", "titles", ")", ":", "\n", "    ", "r\"\"\"Removes repeated entries and titles which are not followed by entries\"\"\"", "\n", "new_labels", "=", "[", "]", "\n", "new_handles", "=", "[", "]", "\n", "appeared", "=", "set", "(", ")", "\n", "for", "ix", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "if", "label", "in", "appeared", ":", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "            ", "appeared", ".", "add", "(", "label", ")", "\n", "if", "label", "in", "titles", ":", "\n", "# label is the last entry or the next label is a title", "\n", "                ", "if", "ix", "==", "len", "(", "labels", ")", "-", "1", "or", "labels", "[", "ix", "+", "1", "]", "in", "titles", ":", "\n", "                    ", "titles", ".", "remove", "(", "label", ")", "\n", "continue", "\n", "", "", "new_labels", ".", "append", "(", "label", ")", "\n", "new_handles", ".", "append", "(", "handles", "[", "ix", "]", ")", "\n", "", "", "return", "new_handles", ",", "new_labels", ",", "titles", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.seaborn.legend_utils._bold_titles": [[26, 32], ["None"], "function", ["None"], ["", "def", "_bold_titles", "(", "labels", ",", "titles", ")", ":", "\n", "    ", "r\"\"\"Styles title labels bold.\n    \"\"\"", "\n", "labels", "=", "[", "'$\\\\bf{'", "+", "label", "+", "'}$'", "if", "label", "in", "titles", "else", "label", "for", "label", "in", "labels", "]", "\n", "titles", "=", "[", "'$\\\\bf{'", "+", "title", "+", "'}$'", "for", "title", "in", "titles", "]", "\n", "return", "labels", ",", "titles", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.seaborn.legend_utils._insert_divider_before_titles": [[33, 45], ["matplotlib.Patch", "range", "labels.index", "len", "handles.insert", "labels.insert"], "function", ["None"], ["", "def", "_insert_divider_before_titles", "(", "handles", ",", "labels", ",", "titles", ")", ":", "\n", "    ", "r\"\"\"Inserts an empty line before each new legend easthetic\n    param titles: elements of 'labels' before which a space should be inserted\n    \"\"\"", "\n", "titles", "=", "titles", "[", "1", ":", "]", "# Do not need to insert space before first title", "\n", "empty_handle", "=", "mpatches", ".", "Patch", "(", "color", "=", "'white'", ",", "alpha", "=", "0", ")", "\n", "space_indexes", "=", "[", "labels", ".", "index", "(", "title", ")", "for", "title", "in", "titles", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "space_indexes", ")", ")", ":", "\n", "        ", "handles", ".", "insert", "(", "space_indexes", "[", "i", "]", ",", "empty_handle", ")", "\n", "labels", ".", "insert", "(", "space_indexes", "[", "i", "]", ",", "''", ")", "\n", "space_indexes", "=", "[", "i", "+", "1", "for", "i", "in", "space_indexes", "]", "\n", "", "return", "handles", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.seaborn.legend_utils._add_hue_dimension": [[46, 51], ["handles.append", "labels.append", "matplotlib.Patch"], "function", ["None"], ["", "def", "_add_hue_dimension", "(", "handles", ",", "labels", ")", ":", "\n", "# TODO", "\n", "    ", "handles", ".", "append", "(", "mpatches", ".", "Patch", "(", "color", "=", "'red'", ",", "alpha", "=", "0.5", ")", ")", "\n", "labels", ".", "append", "(", "'white'", ")", "\n", "return", "handles", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.seaborn.legend_utils.format_legend": [[52, 63], ["ax.get_legend_handles_labels", "legend_utils._remove_empyties_and_duplicates", "legend_utils._bold_titles", "legend_utils._insert_divider_before_titles", "ax.legend", "str", "type", "ax.copy"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.seaborn.legend_utils._remove_empyties_and_duplicates", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.seaborn.legend_utils._bold_titles", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.seaborn.legend_utils._insert_divider_before_titles"], ["", "def", "format_legend", "(", "ax", ",", "titles", ")", ":", "\n", "    ", "r\"\"\"Format legend\"\"\"", "\n", "if", "'numpy'", "in", "str", "(", "type", "(", "ax", ")", ")", ":", "\n", "        ", "ax", "=", "ax", ".", "copy", "(", ")", "[", "-", "1", "]", "\n", "# Fetch legend labels and handles", "\n", "", "handles", ",", "labels", "=", "ax", ".", "get_legend_handles_labels", "(", ")", "\n", "handles", ",", "labels", ",", "titles", "=", "_remove_empyties_and_duplicates", "(", "handles", ",", "labels", ",", "titles", ")", "\n", "labels", ",", "titles", "=", "_bold_titles", "(", "labels", ",", "titles", ")", "\n", "handles", ",", "labels", "=", "_insert_divider_before_titles", "(", "handles", ",", "labels", ",", "titles", ")", "\n", "# Legend to the side", "\n", "ax", ".", "legend", "(", "handles", ",", "labels", ",", "bbox_to_anchor", "=", "(", "1", ",", "1", ")", ",", "loc", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.seaborn.legend_utils._add_training_legend_items": [[64, 72], ["handles.append", "handles.append", "handles.append", "labels.append", "labels.append", "labels.append", "matplotlib.Patch", "matplotlib.Patch", "matplotlib.Patch"], "function", ["None"], ["", "def", "_add_training_legend_items", "(", "handles", ",", "labels", ",", "alpha_training", ",", "alpha_not_training", ")", ":", "\n", "    ", "handles", ".", "append", "(", "mpatches", ".", "Patch", "(", "color", "=", "'white'", ",", "alpha", "=", "0", ")", ")", "\n", "handles", ".", "append", "(", "mpatches", ".", "Patch", "(", "color", "=", "'black'", ",", "alpha", "=", "alpha_training", ")", ")", "\n", "handles", ".", "append", "(", "mpatches", ".", "Patch", "(", "color", "=", "'black'", ",", "alpha", "=", "alpha_not_training", ")", ")", "\n", "labels", ".", "append", "(", "'Training'", ")", "\n", "labels", ".", "append", "(", "'On data'", ")", "\n", "labels", ".", "append", "(", "'On other data'", ")", "\n", "return", "handles", ",", "labels", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.update_bots.telegram_bot.TelegramBot.__init__": [[20, 26], ["telegram.Bot", "mp.utils.load_restore.load_json", "mp.utils.load_restore.join_path"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.load_json", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.join_path"], ["def", "__init__", "(", "self", ",", "login_data", "=", "None", ")", ":", "\n", "        ", "if", "login_data", "is", "None", ":", "\n", "            ", "login_data", "=", "load_json", "(", "path", "=", "join_path", "(", "[", "'src'", ",", "'utils'", ",", "'telegram_bot'", "]", ")", ",", "\n", "name", "=", "'telegram_login'", ")", "\n", "", "self", ".", "chat_id", "=", "login_data", "[", "'chat_id'", "]", "\n", "self", ".", "bot", "=", "tel", ".", "Bot", "(", "token", "=", "login_data", "[", "'token'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.update_bots.telegram_bot.TelegramBot.send_msg": [[27, 30], ["telegram_bot.TelegramBot.bot.send_message"], "methods", ["None"], ["", "def", "send_msg", "(", "self", ",", "msg", ")", ":", "\n", "        ", "r\"\"\"Send a message in string form\"\"\"", "\n", "self", ".", "bot", ".", "send_message", "(", "chat_id", "=", "self", ".", "chat_id", ",", "text", "=", "msg", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.Experiment.__init__": [[37, 58], ["mp.utils.helper_functions.get_time_string", "mp.utils.helper_functions.get_time_string", "print", "os.path.join", "os.path.join", "os.path.exists", "mp.load_json", "mp.load_json", "mp.load_json", "mp.load_json", "os.makedirs", "mp.save_json", "mp.save_json", "mp.save_json", "mp.save_json"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.helper_functions.get_time_string", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.helper_functions.get_time_string", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.load_json", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.load_json", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.load_json", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.load_json", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.save_json", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.save_json", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.save_json", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.save_json"], ["def", "__init__", "(", "self", ",", "config", "=", "None", ",", "name", "=", "''", ",", "notes", "=", "''", ",", "reload_exp", "=", "False", ")", ":", "\n", "        ", "self", ".", "time_str", "=", "get_time_string", "(", ")", "\n", "self", ".", "review", "=", "{", "'time_str'", ":", "self", ".", "time_str", ",", "'notes'", ":", "notes", "}", "\n", "self", ".", "splits", "=", "None", "\n", "if", "not", "name", ":", "\n", "            ", "self", ".", "name", "=", "self", ".", "time_str", "\n", "", "else", ":", "\n", "            ", "self", ".", "name", "=", "name", "\n", "", "print", "(", "'Experiment name:'", ",", "self", ".", "name", ")", "\n", "# Set path in defined storage directory", "\n", "self", ".", "path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "join", "(", "storage_path", ",", "'exp'", ")", ",", "self", ".", "name", ")", "\n", "# Restore files", "\n", "if", "reload_exp", "and", "os", ".", "path", ".", "exists", "(", "self", ".", "path", ")", ":", "\n", "            ", "assert", "name", "is", "not", "None", "\n", "self", ".", "config", "=", "lr", ".", "load_json", "(", "path", "=", "self", ".", "path", ",", "name", "=", "'config'", ")", "\n", "self", ".", "review", "=", "lr", ".", "load_json", "(", "path", "=", "self", ".", "path", ",", "name", "=", "'review'", ")", "\n", "", "else", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "path", ")", "\n", "self", ".", "config", "=", "config", "\n", "lr", ".", "save_json", "(", "self", ".", "config", ",", "path", "=", "self", ".", "path", ",", "name", "=", "'config'", ")", "\n", "lr", ".", "save_json", "(", "self", ".", "review", ",", "path", "=", "self", ".", "path", ",", "name", "=", "'review'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.Experiment.set_data_splits": [[59, 78], ["mp.load_json", "mp.load_json", "print", "isinstance", "mp.save_json", "mp.save_json", "print", "dict", "data.datasets.items", "mp.experiments.data_splitting.split_dataset", "mp.experiments.data_splitting.split_dataset", "mp.experiments.data_splitting.split_dataset", "mp.experiments.data_splitting.split_dataset", "experiment.Experiment.config.get", "experiment.Experiment.config.get"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.load_json", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.load_json", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.save_json", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.save_json", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting.split_dataset", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting.split_dataset", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting.split_dataset", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting.split_dataset"], ["", "", "def", "set_data_splits", "(", "self", ",", "data", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "self", ".", "splits", "=", "lr", ".", "load_json", "(", "path", "=", "self", ".", "path", ",", "name", "=", "'splits'", ")", "\n", "", "except", "FileNotFoundError", ":", "\n", "            ", "print", "(", "'Dividing dataset'", ")", "\n", "# If the data consists of several datasets, then the splits are a", "\n", "# dictionary with one more label, that of the dataset name.", "\n", "if", "isinstance", "(", "data", ",", "Data", ")", ":", "\n", "                ", "self", ".", "splits", "=", "dict", "(", ")", "\n", "for", "ds_name", ",", "ds", "in", "data", ".", "datasets", ".", "items", "(", ")", ":", "\n", "                    ", "self", ".", "splits", "[", "ds_name", "]", "=", "split_dataset", "(", "ds", ",", "test_ratio", "=", "self", ".", "config", ".", "get", "(", "'test_ratio'", ",", "0.0", ")", ",", "\n", "val_ratio", "=", "self", ".", "config", "[", "'val_ratio'", "]", ",", "nr_repetitions", "=", "self", ".", "config", "[", "'nr_runs'", "]", ",", "\n", "cross_validation", "=", "self", ".", "config", "[", "'cross_validation'", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "splits", "=", "split_dataset", "(", "data", ",", "test_ratio", "=", "self", ".", "config", ".", "get", "(", "'test_ratio'", ",", "0.0", ")", ",", "\n", "val_ratio", "=", "self", ".", "config", "[", "'val_ratio'", "]", ",", "nr_repetitions", "=", "self", ".", "config", "[", "'nr_runs'", "]", ",", "\n", "cross_validation", "=", "self", ".", "config", "[", "'cross_validation'", "]", ")", "\n", "", "lr", ".", "save_json", "(", "self", ".", "splits", ",", "path", "=", "self", ".", "path", ",", "name", "=", "'splits'", ")", "\n", "print", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.Experiment.get_run": [[79, 81], ["experiment.ExperimentRun"], "methods", ["None"], ["", "", "def", "get_run", "(", "self", ",", "run_ix", ",", "reload_exp_run", "=", "False", ")", ":", "\n", "        ", "return", "ExperimentRun", "(", "run_ix", ",", "self", ".", "path", ",", "reload_exp_run", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.Experiment.finish": [[82, 86], ["None"], "methods", ["None"], ["", "def", "finish", "(", "self", ",", "results", "=", "None", ")", ":", "\n", "        ", "r\"\"\"After running all runs, finish expeirment by recording averages\"\"\"", "\n", "# TODO first do eval.result.ExperimentResults", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.ExperimentRun.__init__": [[89, 94], ["experiment.ExperimentRun._set_paths", "time.time", "mp.utils.helper_functions.get_time_string", "mp.utils.helper_functions.get_time_string"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.ExperimentRun._set_paths", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.helper_functions.get_time_string", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.helper_functions.get_time_string"], ["def", "__init__", "(", "self", ",", "run_ix", ",", "exp_path", ",", "reload_exp_run", ")", ":", "\n", "        ", "self", ".", "run_ix", "=", "run_ix", "\n", "self", ".", "paths", "=", "self", ".", "_set_paths", "(", "exp_path", ",", "reload_exp_run", ")", "\n", "self", ".", "time_start", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "review", "=", "{", "'time_str'", ":", "get_time_string", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.ExperimentRun._set_paths": [[95, 109], ["dict", "os.path.join", "str", "os.path.exists", "shutil.rmtree", "os.path.exists", "os.mkdir", "os.path.join", "os.mkdir", "os.path.join"], "methods", ["None"], ["", "def", "_set_paths", "(", "self", ",", "exp_path", ",", "reload_exp_run", ")", ":", "\n", "        ", "paths", "=", "dict", "(", ")", "\n", "paths", "[", "'root'", "]", "=", "os", ".", "path", ".", "join", "(", "exp_path", ",", "str", "(", "self", ".", "run_ix", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "paths", "[", "'root'", "]", ")", "and", "not", "reload_exp_run", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "paths", "[", "'root'", "]", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "paths", "[", "'root'", "]", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "paths", "[", "'root'", "]", ")", "\n", "for", "subpath", "in", "[", "'results'", ",", "'states'", ",", "'obj'", ",", "'tmp'", "]", ":", "\n", "                ", "paths", "[", "subpath", "]", "=", "os", ".", "path", ".", "join", "(", "paths", "[", "'root'", "]", ",", "subpath", ")", "\n", "os", ".", "mkdir", "(", "paths", "[", "subpath", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "subpath", "in", "[", "'results'", ",", "'states'", ",", "'obj'", ",", "'tmp'", "]", ":", "\n", "                ", "paths", "[", "subpath", "]", "=", "os", ".", "path", ".", "join", "(", "paths", "[", "'root'", "]", ",", "subpath", ")", "\n", "", "", "return", "paths", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.ExperimentRun.finish": [[110, 130], ["mp.save_json", "mp.save_json", "time.time", "mp.pkl_dump", "mp.pkl_dump", "experiment.ExperimentRun._write_summary_measures", "isinstance", "shutil.rmtree", "experiment.ExperimentRun._plot_results", "str", "experiment.ExperimentRun._plot_results"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.save_json", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.save_json", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.pkl_dump", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.pkl_dump", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.ExperimentRun._write_summary_measures", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.ExperimentRun._plot_results", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.ExperimentRun._plot_results"], ["", "def", "finish", "(", "self", ",", "results", "=", "None", ",", "exception", "=", "None", ",", "plot_metrics", "=", "None", ")", ":", "\n", "        ", "elapsed_time", "=", "time", ".", "time", "(", ")", "-", "self", ".", "time_start", "\n", "self", ".", "review", "[", "'elapsed_time'", "]", "=", "'{0:.2f}'", ".", "format", "(", "elapsed_time", "/", "60", ")", "\n", "if", "results", ":", "\n", "            ", "self", ".", "review", "[", "'state'", "]", "=", "'SUCCESS'", "\n", "lr", ".", "pkl_dump", "(", "results", ",", "path", "=", "self", ".", "paths", "[", "'results'", "]", ",", "name", "=", "'results'", ")", "\n", "self", ".", "_write_summary_measures", "(", "results", ")", "\n", "if", "isinstance", "(", "results", ",", "list", ")", ":", "\n", "                ", "for", "result", "in", "results", ":", "\n", "                    ", "self", ".", "_plot_results", "(", "result", "=", "result", ",", "save_path", "=", "self", ".", "paths", "[", "'results'", "]", ",", "plot_metrics", "=", "plot_metrics", ")", "\n", "", "", "else", ":", "\n", "                 ", "self", ".", "_plot_results", "(", "result", "=", "results", ",", "save_path", "=", "self", ".", "paths", "[", "'results'", "]", ",", "plot_metrics", "=", "plot_metrics", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "review", "[", "'state'", "]", "=", "'FAILURE: '", "+", "str", "(", "exception", ")", "\n", "# TODO: store exception with better format, or whole error path", "\n", "", "lr", ".", "save_json", "(", "self", ".", "review", ",", "self", ".", "paths", "[", "'root'", "]", ",", "'review'", ")", "\n", "try", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "self", ".", "paths", "[", "'tmp'", "]", ")", "\n", "", "except", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.ExperimentRun.save_state": [[133, 144], ["np_dict.items", "pkl_dict.items", "mp.save_model_state", "mp.save_model_state", "mp.save_optimizer_state", "mp.save_optimizer_state", "mp.save_scheduler_state", "mp.save_scheduler_state", "mp.np_dump", "mp.np_dump", "mp.pkl_dump", "mp.pkl_dump"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.save_model_state", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.save_model_state", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.save_optimizer_state", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.save_optimizer_state", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.save_scheduler_state", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.save_scheduler_state", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.np_dump", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.np_dump", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.pkl_dump", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.pkl_dump"], ["", "", "def", "save_state", "(", "self", ",", "state_name", ",", "pytorch_dict", "=", "{", "}", ",", "np_dict", "=", "{", "}", ",", "pkl_dict", "=", "{", "}", ")", ":", "\n", "        ", "if", "'model'", "in", "pytorch_dict", ":", "\n", "            ", "ptlr", ".", "save_model_state", "(", "pytorch_dict", "[", "'model'", "]", ",", "name", "=", "state_name", "+", "'_model'", ",", "path", "=", "self", ".", "paths", "[", "'states'", "]", ")", "\n", "", "if", "'optimizer'", "in", "pytorch_dict", ":", "\n", "            ", "ptlr", ".", "save_optimizer_state", "(", "pytorch_dict", "[", "'optimizer'", "]", ",", "name", "=", "state_name", "+", "'_optimizer'", ",", "path", "=", "self", ".", "paths", "[", "'states'", "]", ")", "\n", "", "if", "'scheduler'", "in", "pytorch_dict", ":", "\n", "            ", "ptlr", ".", "save_scheduler_state", "(", "pytorch_dict", "[", "'scheduler'", "]", ",", "name", "=", "state_name", "+", "'_scheduler'", ",", "path", "=", "self", ".", "paths", "[", "'states'", "]", ")", "\n", "", "for", "key", ",", "value", "in", "np_dict", ".", "items", "(", ")", ":", "\n", "            ", "lr", ".", "np_dump", "(", "value", ",", "key", ",", "path", "=", "self", ".", "paths", "[", "'states'", "]", ")", "\n", "", "for", "key", ",", "value", "in", "pkl_dict", ".", "items", "(", ")", ":", "\n", "            ", "lr", ".", "pkl_dump", "(", "value", ",", "key", ",", "path", "=", "self", ".", "paths", "[", "'states'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.ExperimentRun.restore_state": [[145, 157], ["np_dict.keys", "pkl_dict.keys", "mp.np_load", "mp.np_load", "mp.pkl_load", "mp.pkl_load", "mp.load_model_state", "mp.load_model_state", "mp.load_optimizer_state", "mp.load_optimizer_state", "mp.load_scheduler_state", "mp.load_scheduler_state"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.np_load", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.np_load", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.pkl_load", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.utils.load_restore.pkl_load", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.load_model_state", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.load_model_state", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.load_optimizer_state", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.load_optimizer_state", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.load_scheduler_state", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.load_scheduler_state"], ["", "", "def", "restore_state", "(", "self", ",", "state_name", ",", "pytorch_dict", ",", "np_dict", ",", "pkl_dict", ",", "device", "=", "'cuda:0'", ")", ":", "\n", "        ", "success", "=", "True", "\n", "if", "'model'", "in", "pytorch_dict", ":", "\n", "            ", "success", "=", "success", "and", "ptlr", ".", "load_model_state", "(", "pytorch_dict", "[", "'model'", "]", ",", "name", "=", "state_name", "+", "'_model'", ",", "path", "=", "self", ".", "paths", "[", "'states'", "]", ",", "device", "=", "device", ")", "\n", "", "if", "'optimizer'", "in", "pytorch_dict", ":", "\n", "            ", "success", "=", "success", "and", "ptlr", ".", "load_optimizer_state", "(", "pytorch_dict", "[", "'optimizer'", "]", ",", "name", "=", "state_name", "+", "'_optimizer'", ",", "path", "=", "self", ".", "paths", "[", "'states'", "]", ",", "device", "=", "device", ")", "\n", "", "if", "'scheduler'", "in", "pytorch_dict", ":", "\n", "            ", "success", "=", "success", "and", "ptlr", ".", "load_scheduler_state", "(", "pytorch_dict", "[", "'scheduler'", "]", ",", "name", "=", "state_name", "+", "'_scheduler'", ",", "path", "=", "self", ".", "paths", "[", "'states'", "]", ",", "device", "=", "device", ")", "\n", "", "for", "key", "in", "np_dict", ".", "keys", "(", ")", ":", "\n", "            ", "np_dict", "[", "key", "]", "=", "lr", ".", "np_load", "(", "key", ",", "path", "=", "self", ".", "paths", "[", "'states'", "]", ")", "\n", "", "for", "key", "in", "pkl_dict", ".", "keys", "(", ")", ":", "\n", "            ", "pkl_dict", "[", "key", "]", "=", "lr", ".", "pkl_load", "(", "key", ",", "path", "=", "self", ".", "paths", "[", "'states'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.ExperimentRun._plot_results": [[158, 160], ["mp.visualization.plot_results.plot_results", "mp.visualization.plot_results.plot_results"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.plot_results.plot_results", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.visualization.plot_results.plot_results"], ["", "", "def", "_plot_results", "(", "self", ",", "result", ",", "save_path", ",", "plot_metrics", "=", "None", ")", ":", "\n", "        ", "plot_results", "(", "result", ",", "save_path", "=", "self", ".", "paths", "[", "'results'", "]", ",", "measures", "=", "plot_metrics", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.experiment.ExperimentRun._write_summary_measures": [[161, 163], ["None"], "methods", ["None"], ["", "def", "_write_summary_measures", "(", "self", ",", "results", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting.split_dataset": [[13, 62], ["data_splitting.create_instance_folds", "range", "range", "print", "range", "splits.append", "print", "data_splitting.split_instances", "splits.append", "data_splitting.split_instances", "data_splitting.split_instances"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting.create_instance_folds", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting.split_instances", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting.split_instances", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting.split_instances"], ["def", "split_dataset", "(", "\n", "dataset", ",", "test_ratio", "=", "0.2", ",", "val_ratio", "=", "0.2", ",", "\n", "nr_repetitions", "=", "5", ",", "cross_validation", "=", "True", ",", "\n", "respecting_groups", "=", "True", ")", ":", "\n", "    ", "r\"\"\"Splits a dataset into different index folds.\n\n    Args:\n        dataset (Dataset): a Dataset object\n        test_ratio (float): ratio of instances for testing\n        val_ratio (float): ratio of non-test instances for validation\n        nr_repetitions (int): number of times the experiment should be repeated,\n            i.e. number of index splits which are created.\n        cross_validation (bool): are the repetitions cross-val folds?\n        respecting_groups (bool): do not place examples with the same group in\n            the same fold\n    \n    Returns (list[dict[str -> list[int]]]): A list of length 'nr_repetitions' \n        where each item is a dictionary with keys 'train', 'val' and 'test'.\n    \"\"\"", "\n", "splits", "=", "[", "]", "\n", "if", "cross_validation", ":", "\n", "        ", "folds", "=", "create_instance_folds", "(", "dataset", "=", "dataset", ",", "k", "=", "nr_repetitions", ",", "\n", "exclude_ixs", "=", "dataset", ".", "hold_out_ixs", ",", "stratisfied", "=", "True", ",", "\n", "respecting_groups", "=", "respecting_groups", ")", "\n", "for", "k", "in", "range", "(", "nr_repetitions", ")", ":", "\n", "            ", "print", "(", "'Cross-validation fold k {} of {}'", ".", "format", "(", "k", "+", "1", ",", "nr_repetitions", ")", ")", "\n", "train", ",", "val", "=", "[", "]", ",", "[", "]", "\n", "for", "j", "in", "range", "(", "nr_repetitions", ")", ":", "\n", "                ", "if", "j", "!=", "k", ":", "\n", "                    ", "train", "+=", "folds", "[", "j", "]", "\n", "", "", "if", "val_ratio", ">", "0", ":", "\n", "                ", "train", ",", "val", "=", "split_instances", "(", "dataset", "=", "dataset", ",", "ratio", "=", "1", "-", "val_ratio", ",", "\n", "exclude_ixs", "=", "dataset", ".", "hold_out_ixs", "+", "folds", "[", "k", "]", ",", "\n", "stratisfied", "=", "True", ",", "respecting_groups", "=", "respecting_groups", ")", "\n", "", "splits", ".", "append", "(", "{", "'train'", ":", "train", ",", "'val'", ":", "val", ",", "'test'", ":", "folds", "[", "k", "]", "}", ")", "\n", "", "", "else", ":", "\n", "        ", "for", "k", "in", "range", "(", "nr_repetitions", ")", ":", "\n", "            ", "print", "(", "'Repetition k {} of {}'", ".", "format", "(", "k", "+", "1", ",", "nr_repetitions", ")", ")", "\n", "train_val", ",", "test", "=", "split_instances", "(", "dataset", "=", "dataset", ",", "\n", "ratio", "=", "1", "-", "test_ratio", ",", "exclude_ixs", "=", "dataset", ".", "hold_out_ixs", ",", "\n", "stratisfied", "=", "True", ",", "respecting_groups", "=", "respecting_groups", ")", "\n", "if", "val_ratio", ">", "0", ":", "\n", "                ", "train", ",", "val", "=", "split_instances", "(", "dataset", "=", "dataset", ",", "ratio", "=", "1", "-", "val_ratio", ",", "\n", "exclude_ixs", "=", "dataset", ".", "hold_out_ixs", "+", "test", ",", "stratisfied", "=", "True", ",", "\n", "respecting_groups", "=", "respecting_groups", ")", "\n", "", "else", ":", "\n", "                ", "train", ",", "val", "=", "train_val", ",", "[", "]", "\n", "", "splits", ".", "append", "(", "{", "'train'", ":", "train", ",", "'val'", ":", "val", ",", "'test'", ":", "test", "}", ")", "\n", "", "", "return", "splits", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting.split_instances": [[64, 131], ["range", "math.floor", "random.shuffle", "data_splitting._split_ixs", "list", "list.sort", "len", "len", "len", "dataset.get_class_instance_ixs", "random.shuffle", "set", "math.floor", "len", "len", "len", "print", "data_splitting._split_ixs", "len", "print", "data_splitting._split_ixs", "len"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting._split_ixs", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_instance_ixs", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting._split_ixs", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting._split_ixs"], ["", "def", "split_instances", "(", "dataset", ",", "ratio", "=", "0.7", ",", "exclude_ixs", "=", "[", "]", ",", "stratisfied", "=", "True", ",", "\n", "respecting_groups", "=", "True", ")", ":", "\n", "    ", "r\"\"\"Divides instances into two stratisfied sets. The stratification \n    operations prefers to give more examples of underrepresented classes\n    to smaller sets (when the examples in a class cannot be split without\n    a remainder).\n\n    Args:\n        ratio (float): ratio of instances which remain in the first set.\n        exclude_ixs (list[int]): exclude these indexes from the splitting\n        stratisfied (bool): should there be ca. as any examples for each class?\n        respecting_groups (bool): do not place examples with the same group in\n            the same fold\n    \n    Returns (tuple[list[int]]): 2 index lists with the indexes\n    \"\"\"", "\n", "ixs", "=", "range", "(", "dataset", ".", "size", ")", "\n", "ixs", "=", "[", "ix", "for", "ix", "in", "ixs", "if", "ix", "not", "in", "exclude_ixs", "]", "\n", "first_ds_len", "=", "math", ".", "floor", "(", "len", "(", "ixs", ")", "*", "ratio", ")", "\n", "if", "not", "stratisfied", ":", "\n", "        ", "random", ".", "shuffle", "(", "ixs", ")", "\n", "return", "_split_ixs", "(", "ixs", ",", "first_ds_len", "=", "first_ds_len", ",", "\n", "instances", "=", "dataset", ".", "instances", ",", "respecting_groups", "=", "respecting_groups", ")", "\n", "", "else", ":", "\n", "        ", "ixs_1", ",", "ixs_2", "=", "[", "]", ",", "[", "]", "\n", "class_instances", "=", "{", "class_name", ":", "dataset", ".", "get_class_instance_ixs", "(", "\n", "class_name", "=", "class_name", ",", "exclude_ixs", "=", "exclude_ixs", ")", "for", "class_name", "\n", "in", "dataset", ".", "classes", "}", "\n", "classes", "=", "list", "(", "dataset", ".", "classes", ")", "\n", "classes", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "class_instances", "[", "x", "]", ")", ")", "\n", "for", "class_name", "in", "classes", ":", "\n", "#print('Class: {}'.format(class_name))", "\n", "            ", "ixs", "=", "class_instances", "[", "class_name", "]", "\n", "random", ".", "shuffle", "(", "ixs", ")", "\n", "# The mayority class is used to fill to the desired number of ", "\n", "# examples for each split", "\n", "if", "class_name", "==", "classes", "[", "-", "1", "]", ":", "\n", "                ", "remaining_exs_nr", "=", "first_ds_len", "-", "len", "(", "ixs_1", ")", "\n", "if", "remaining_exs_nr", "==", "len", "(", "ixs", ")", ":", "\n", "# raise RuntimeError(", "\n", "#     'Not enough examples of class {}'.format(class_name))", "\n", "                    ", "print", "(", "'Using all examples for training!'", ")", "\n", "ixs_1", "+=", "ixs", "\n", "", "else", ":", "\n", "                    ", "class_ixs_1", ",", "class_ixs_2", "=", "_split_ixs", "(", "ixs", ",", "\n", "first_ds_len", "=", "remaining_exs_nr", ",", "instances", "=", "dataset", ".", "instances", ",", "\n", "respecting_groups", "=", "respecting_groups", ")", "\n", "ixs_1", "+=", "class_ixs_1", "\n", "ixs_2", "+=", "class_ixs_2", "\n", "# Otherwise, the operation makes sure less-represented classes", "\n", "# are as represented as possible in small sets", "\n", "", "", "else", ":", "\n", "                ", "nr_class_first_ds", "=", "math", ".", "floor", "(", "len", "(", "ixs", ")", "*", "ratio", ")", "\n", "if", "nr_class_first_ds", "==", "len", "(", "ixs", ")", ":", "\n", "# raise RuntimeError(", "\n", "#     'Not enough examples of class {}'.format(class_name))", "\n", "                    ", "print", "(", "'Using all examples for training!'", ")", "\n", "ixs_1", "+=", "ixs", "\n", "\n", "", "else", ":", "\n", "                    ", "class_ixs_1", ",", "class_ixs_2", "=", "_split_ixs", "(", "ixs", ",", "\n", "first_ds_len", "=", "nr_class_first_ds", ",", "instances", "=", "dataset", ".", "instances", ",", "\n", "respecting_groups", "=", "respecting_groups", ")", "\n", "ixs_1", "+=", "class_ixs_1", "\n", "ixs_2", "+=", "class_ixs_2", "\n", "", "", "", "", "assert", "len", "(", "set", "(", "ixs_1", "+", "ixs_2", "+", "exclude_ixs", ")", ")", "==", "len", "(", "dataset", ".", "instances", ")", "\n", "return", "ixs_1", ",", "ixs_2", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting.create_instance_folds": [[132, 168], ["range", "data_splitting._divide_sets_similar_length", "list", "list.sort", "len", "dataset.get_class_instance_ixs", "folds.sort", "data_splitting._divide_sets_similar_length", "range", "sum", "len", "range", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting._divide_sets_similar_length", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.datasets.dataset.Dataset.get_class_instance_ixs", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting._divide_sets_similar_length", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum"], ["", "def", "create_instance_folds", "(", "dataset", ",", "k", "=", "5", ",", "exclude_ixs", "=", "[", "]", ",", "\n", "stratisfied", "=", "True", ",", "respecting_groups", "=", "True", ")", ":", "\n", "    ", "r\"\"\"Divides instances into k stratisfied sets. Always, the most examples of \n    a class (when not divisible) are added to the fold that currently has\n    the least examples.\n\n    Args:\n        k (int): number of sets.\n        exclude_ixs (list[int]): exclude these indexes from the splitting\n        stratisfied (bool): should there be ca. as any examples for each class?\n        respecting_groups (bool): do not place examples with the same group in\n            the same fold\n    \n    Returns (tuple[list[int]]): k index lists with the indexes\n    \"\"\"", "\n", "ixs", "=", "range", "(", "dataset", ".", "size", ")", "\n", "ixs", "=", "[", "ix", "for", "ix", "in", "ixs", "if", "ix", "not", "in", "exclude_ixs", "]", "\n", "if", "not", "stratisfied", ":", "\n", "        ", "return", "_divide_sets_similar_length", "(", "dataset", ".", "instances", ",", "ixs", ",", "k", ",", "respecting_groups", ")", "\n", "", "else", ":", "\n", "        ", "folds", "=", "[", "[", "]", "for", "k_ix", "in", "range", "(", "k", ")", "]", "\n", "class_instances", "=", "{", "class_name", ":", "dataset", ".", "get_class_instance_ixs", "(", "\n", "class_name", "=", "class_name", ",", "exclude_ixs", "=", "exclude_ixs", ")", "for", "\n", "class_name", "in", "dataset", ".", "classes", "}", "\n", "classes", "=", "list", "(", "dataset", ".", "classes", ")", "\n", "classes", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "class_instances", "[", "x", "]", ")", ")", "\n", "for", "class_name", "in", "classes", ":", "\n", "#print('Class: {}'.format(class_name))", "\n", "            ", "exs", "=", "class_instances", "[", "class_name", "]", "\n", "# Sort so folds with least examples come first", "\n", "folds", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", ")", ")", "\n", "divided_exs", "=", "_divide_sets_similar_length", "(", "dataset", ".", "instances", ",", "exs", ",", "k", ",", "respecting_groups", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "divided_exs", ")", ")", ":", "\n", "                ", "folds", "[", "i", "]", "+=", "divided_exs", "[", "i", "]", "\n", "", "", "", "assert", "sum", "(", "[", "len", "(", "fold", ")", "for", "fold", "in", "folds", "]", ")", "+", "len", "(", "exclude_ixs", ")", "==", "len", "(", "dataset", ".", "instances", ")", "\n", "return", "folds", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting._divide_sets_similar_length": [[169, 225], ["random.shuffle", "divmod", "range", "dict", "divmod", "range", "dict.values", "range", "len", "RuntimeError", "nr_per_fold_final.append", "folds[].append", "ixs_groups[].append", "len", "RuntimeError", "nr_per_fold_final.append", "len", "dict.keys", "len"], "function", ["None"], ["", "def", "_divide_sets_similar_length", "(", "instances", ",", "exs", ",", "k", ",", "respecting_groups", "=", "True", ")", ":", "\n", "    ", "r\"\"\"Divides a list exs into k sets of similar length, with the initial \n    ones being longer.\n    \"\"\"", "\n", "random", ".", "shuffle", "(", "exs", ")", "\n", "folds", "=", "[", "[", "]", "for", "i", "in", "range", "(", "k", ")", "]", "\n", "# Add example indexes to folds", "\n", "if", "instances", "[", "0", "]", ".", "group_id", "==", "None", "or", "not", "respecting_groups", ":", "\n", "# Calculate number of examples per fold", "\n", "        ", "nr_per_fold", ",", "remaining", "=", "divmod", "(", "len", "(", "exs", ")", ",", "k", ")", "\n", "if", "nr_per_fold", "<", "1", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Not enough examples.'", ")", "\n", "", "nr_per_fold_final", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "k", ")", ":", "\n", "            ", "nr_exs", "=", "nr_per_fold", "\n", "if", "remaining", ">", "0", ":", "\n", "                ", "nr_exs", "+=", "1", "\n", "", "nr_per_fold_final", ".", "append", "(", "nr_exs", ")", "\n", "remaining", "-=", "1", "\n", "", "current_fold_ix", "=", "0", "\n", "for", "ix", "in", "exs", ":", "\n", "            ", "folds", "[", "current_fold_ix", "]", ".", "append", "(", "ix", ")", "\n", "if", "len", "(", "folds", "[", "current_fold_ix", "]", ")", "==", "nr_per_fold_final", "[", "current_fold_ix", "]", ":", "\n", "                ", "current_fold_ix", "+=", "1", "\n", "", "", "", "else", ":", "\n", "# Form groups", "\n", "        ", "ixs_groups", "=", "dict", "(", ")", "\n", "for", "ix", "in", "exs", ":", "\n", "            ", "group_id", "=", "instances", "[", "ix", "]", ".", "group_id", "\n", "if", "group_id", "not", "in", "ixs_groups", ":", "\n", "                ", "ixs_groups", "[", "group_id", "]", "=", "[", "]", "\n", "", "ixs_groups", "[", "group_id", "]", ".", "append", "(", "ix", ")", "\n", "# Calculate number of groups per fold", "\n", "", "nr_per_fold", ",", "remaining", "=", "divmod", "(", "len", "(", "ixs_groups", ".", "keys", "(", ")", ")", ",", "k", ")", "\n", "if", "nr_per_fold", "<", "1", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Not enough groups.'", ")", "\n", "", "nr_per_fold_final", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "k", ")", ":", "\n", "            ", "nr_exs", "=", "nr_per_fold", "\n", "if", "remaining", ">", "0", ":", "\n", "                ", "nr_exs", "+=", "1", "\n", "", "nr_per_fold_final", ".", "append", "(", "nr_exs", ")", "\n", "remaining", "-=", "1", "\n", "# Divide groups", "\n", "", "current_fold_ix", "=", "0", "\n", "nr_fold_groups", "=", "0", "\n", "for", "ix_lst", "in", "ixs_groups", ".", "values", "(", ")", ":", "\n", "            ", "folds", "[", "current_fold_ix", "]", "+=", "ix_lst", "\n", "nr_fold_groups", "+=", "1", "\n", "if", "nr_fold_groups", ">=", "nr_per_fold_final", "[", "current_fold_ix", "]", ":", "\n", "                ", "current_fold_ix", "+=", "1", "\n", "nr_fold_groups", "=", "0", "\n", "# Return divided indexes", "\n", "", "", "for", "fold", "in", "folds", ":", "\n", "            ", "assert", "len", "(", "fold", ")", ">", "0", ",", "'Not enough examples'", "\n", "", "", "return", "folds", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.experiments.data_splitting._split_ixs": [[226, 249], ["dict", "dict.values", "ixs_groups[].append", "len", "len", "len"], "function", ["None"], ["", "def", "_split_ixs", "(", "ixs", ",", "first_ds_len", ",", "instances", ",", "respecting_groups", "=", "True", ")", ":", "\n", "    ", "r\"\"\"Returns two lists of indexes, which are subsets of ixs.\n    \"\"\"", "\n", "if", "not", "respecting_groups", "or", "instances", "[", "0", "]", ".", "group_id", "==", "None", ":", "\n", "        ", "return", "ixs", "[", ":", "first_ds_len", "]", ",", "ixs", "[", "first_ds_len", ":", "]", "\n", "", "else", ":", "\n", "        ", "ixs_1", ",", "ixs_2", "=", "[", "]", ",", "[", "]", "\n", "# Form groups", "\n", "ixs_groups", "=", "dict", "(", ")", "\n", "for", "ix", "in", "ixs", ":", "\n", "            ", "group_id", "=", "instances", "[", "ix", "]", ".", "group_id", "\n", "if", "group_id", "not", "in", "ixs_groups", ":", "\n", "                ", "ixs_groups", "[", "group_id", "]", "=", "[", "]", "\n", "", "ixs_groups", "[", "group_id", "]", ".", "append", "(", "ix", ")", "\n", "# Divide groups", "\n", "", "for", "ix_lst", "in", "ixs_groups", ".", "values", "(", ")", ":", "\n", "            ", "if", "len", "(", "ixs_1", ")", ">=", "first_ds_len", ":", "\n", "                ", "ixs_2", "+=", "ix_lst", "\n", "", "else", ":", "\n", "                ", "ixs_1", "+=", "ix_lst", "\n", "# Return divided indexes", "\n", "", "", "assert", "len", "(", "ixs_1", ")", ">", "0", "and", "len", "(", "ixs_2", ")", ">", "0", ",", "'Not enough examples'", "\n", "return", "ixs_1", ",", "ixs_2", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.__init__": [[23, 27], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "input_shape", "=", "(", "1", ",", "32", ",", "32", ")", ",", "output_shape", "=", "2", ")", ":", "\n", "        ", "super", "(", "Model", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_shape", "=", "input_shape", "\n", "self", ".", "output_shape", "=", "output_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.preprocess_input": [[28, 31], ["None"], "methods", ["None"], ["", "def", "preprocess_input", "(", "self", ",", "x", ")", ":", "\n", "        ", "r\"\"\"E.g. pretrained features. Override if needed. \"\"\"", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.initialize": [[32, 43], ["os.path.split", "mp.utils.pytorch.pytorch_load_restore.load_model_state", "print", "mp.utils.pytorch.pytorch_load_restore.save_model_state", "print"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.load_model_state", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.pytorch_load_restore.save_model_state"], ["", "def", "initialize", "(", "self", ",", "weights_init_path", ",", "device", ")", ":", "\n", "        ", "r\"\"\"Tries to restore a previous model. If no model is found, the initial \n        weights are saved.\n        \"\"\"", "\n", "path", ",", "name", "=", "os", ".", "path", ".", "split", "(", "weights_init_path", ")", "\n", "restored", "=", "load_model_state", "(", "self", ",", "path", "=", "path", ",", "name", "=", "name", ",", "device", "=", "device", ")", "\n", "if", "restored", ":", "\n", "            ", "print", "(", "'Initial parameters {} were restored'", ".", "format", "(", "weights_init_path", ")", ")", "\n", "", "else", ":", "\n", "            ", "save_model_state", "(", "self", ",", "path", "=", "path", ",", "name", "=", "name", ")", "\n", "print", "(", "'Initial parameters {} were saved'", ".", "format", "(", "weights_init_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.get_param_list_static": [[44, 51], ["model.Model.state_dict().items", "numpy.concatenate", "model_params_array.append", "model.Model.state_dict", "param.reshape().cpu().numpy", "param.reshape().cpu", "param.reshape"], "methods", ["None"], ["", "", "def", "get_param_list_static", "(", "self", ")", ":", "\n", "        ", "r\"\"\"Returns a 1D array of parameter values\n        \"\"\"", "\n", "model_params_array", "=", "[", "]", "\n", "for", "_", ",", "param", "in", "self", ".", "state_dict", "(", ")", ".", "items", "(", ")", ":", "\n", "            ", "model_params_array", ".", "append", "(", "param", ".", "reshape", "(", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "return", "np", ".", "concatenate", "(", "model_params_array", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.model_summary": [[55, 61], ["str", "torchsummary.summary", "print"], "methods", ["None"], ["", "def", "model_summary", "(", "self", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "r\"\"\"Return a Keras-style summary.\"\"\"", "\n", "summary_str", "=", "str", "(", "summary", "(", "self", ",", "input_data", "=", "self", ".", "input_shape", ",", "verbose", "=", "0", ")", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "summary_str", ")", "\n", "", "return", "summary_str", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.num_flat_features": [[65, 73], ["x.size"], "methods", ["None"], ["", "def", "num_flat_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "r\"\"\"Flattened view of all dimensions except the batch size.\n        \"\"\"", "\n", "size", "=", "x", ".", "size", "(", ")", "[", "1", ":", "]", "\n", "num_features", "=", "1", "\n", "for", "s", "in", "size", ":", "\n", "            ", "num_features", "*=", "s", "\n", "", "return", "num_features", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten": [[74, 77], ["x.view", "model.Model.num_flat_features"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.num_flat_features"], ["", "def", "flatten", "(", "self", ",", "x", ")", ":", "\n", "        ", "r\"\"\"Flatten x into 1 dimension.\"\"\"", "\n", "return", "x", ".", "view", "(", "-", "1", ",", "self", ".", "num_flat_features", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.size_before_lin": [[78, 84], ["None"], "methods", ["None"], ["", "def", "size_before_lin", "(", "self", ",", "shape_input", ")", ":", "\n", "        ", "r\"\"\"Size after linearization.\n\n        Returns (int): integer of dense size\n        \"\"\"", "\n", "return", "shape_input", "[", "0", "]", "*", "shape_input", "[", "1", "]", "*", "shape_input", "[", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.size_after_conv": [[85, 91], ["None"], "methods", ["None"], ["", "def", "size_after_conv", "(", "self", ",", "shape_input", ",", "output_channels", ",", "kernel", ")", ":", "\n", "        ", "r\"\"\"Gives the number of output neurons after the conv operation.\n        The first dimension is the channel depth and the other 2 are given by\n        input volume (size - kernel size + 2*padding)/stride + 1\n        \"\"\"", "\n", "return", "(", "output_channels", ",", "shape_input", "[", "1", "]", "-", "kernel", "+", "1", ",", "shape_input", "[", "2", "]", "-", "kernel", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.size_after_pooling": [[92, 98], ["None"], "methods", ["None"], ["", "def", "size_after_pooling", "(", "self", ",", "shape_input", ",", "shape_pooling", ")", ":", "\n", "        ", "r\"\"\"Maintains the first input dimension, which is the output channels in \n        the previous conv layer. The others are divided by the shape of the \n        pooling.\n        \"\"\"", "\n", "return", "(", "shape_input", "[", "0", "]", ",", "shape_input", "[", "1", "]", "//", "shape_pooling", "[", "0", "]", ",", "shape_input", "[", "2", "]", "//", "shape_pooling", "[", "1", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.ConvolutionalBlock.__init__": [[23, 91], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "getattr", "getattr.", "torch.Sequential", "torch.Sequential", "torch.Sequential", "getattr", "getattr.", "model_utils.ConvolutionalBlock.add_if_not_none", "model_utils.ConvolutionalBlock.add_if_not_none", "model_utils.ConvolutionalBlock.add_if_not_none", "model_utils.ConvolutionalBlock.add_if_not_none", "model_utils.ConvolutionalBlock.add_if_not_none", "model_utils.ConvolutionalBlock.add_if_not_none", "getattr", "getattr.", "model_utils.ConvolutionalBlock.add_if_not_none", "normalization.capitalize", "getattr"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.ConvolutionalBlock.add_if_not_none", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.ConvolutionalBlock.add_if_not_none", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.ConvolutionalBlock.add_if_not_none", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.ConvolutionalBlock.add_if_not_none", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.ConvolutionalBlock.add_if_not_none", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.ConvolutionalBlock.add_if_not_none", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.ConvolutionalBlock.add_if_not_none"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "dimensions", ":", "int", ",", "\n", "in_channels", ":", "int", ",", "\n", "out_channels", ":", "int", ",", "\n", "normalization", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "kernel_size", ":", "int", "=", "3", ",", "\n", "activation", ":", "Optional", "[", "str", "]", "=", "'ReLU'", ",", "\n", "preactivation", ":", "bool", "=", "False", ",", "\n", "padding", ":", "int", "=", "0", ",", "\n", "padding_mode", ":", "str", "=", "'zeros'", ",", "\n", "dilation", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "dropout", ":", "float", "=", "0", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "block", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "dilation", "=", "1", "if", "dilation", "is", "None", "else", "dilation", "\n", "if", "padding", ":", "\n", "            ", "total_padding", "=", "kernel_size", "+", "2", "*", "(", "dilation", "-", "1", ")", "-", "1", "\n", "padding", "=", "total_padding", "//", "2", "\n", "\n", "", "class_name", "=", "'Conv{}d'", ".", "format", "(", "dimensions", ")", "\n", "conv_class", "=", "getattr", "(", "nn", ",", "class_name", ")", "\n", "conv_layer", "=", "conv_class", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "padding", "=", "padding", ",", "\n", "padding_mode", "=", "padding_mode", ",", "\n", "dilation", "=", "dilation", ",", "\n", ")", "\n", "\n", "norm_layer", "=", "None", "\n", "if", "normalization", "is", "not", "None", ":", "\n", "            ", "class_name", "=", "'{}Norm{}d'", ".", "format", "(", "\n", "normalization", ".", "capitalize", "(", ")", ",", "dimensions", ")", "\n", "norm_class", "=", "getattr", "(", "nn", ",", "class_name", ")", "\n", "num_features", "=", "in_channels", "if", "preactivation", "else", "out_channels", "\n", "norm_layer", "=", "norm_class", "(", "num_features", ")", "\n", "\n", "", "activation_layer", "=", "None", "\n", "if", "activation", "is", "not", "None", ":", "\n", "            ", "activation_layer", "=", "getattr", "(", "nn", ",", "activation", ")", "(", ")", "\n", "\n", "", "if", "preactivation", ":", "\n", "            ", "self", ".", "add_if_not_none", "(", "block", ",", "norm_layer", ")", "\n", "self", ".", "add_if_not_none", "(", "block", ",", "activation_layer", ")", "\n", "self", ".", "add_if_not_none", "(", "block", ",", "conv_layer", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "add_if_not_none", "(", "block", ",", "conv_layer", ")", "\n", "self", ".", "add_if_not_none", "(", "block", ",", "norm_layer", ")", "\n", "self", ".", "add_if_not_none", "(", "block", ",", "activation_layer", ")", "\n", "\n", "", "dropout_layer", "=", "None", "\n", "if", "dropout", ":", "\n", "            ", "class_name", "=", "'Dropout{}d'", ".", "format", "(", "dimensions", ")", "\n", "dropout_class", "=", "getattr", "(", "nn", ",", "class_name", ")", "\n", "dropout_layer", "=", "dropout_class", "(", "p", "=", "dropout", ")", "\n", "self", ".", "add_if_not_none", "(", "block", ",", "dropout_layer", ")", "\n", "\n", "", "self", ".", "conv_layer", "=", "conv_layer", "\n", "self", ".", "norm_layer", "=", "norm_layer", "\n", "self", ".", "activation_layer", "=", "activation_layer", "\n", "self", ".", "dropout_layer", "=", "dropout_layer", "\n", "\n", "self", ".", "block", "=", "nn", ".", "Sequential", "(", "*", "block", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.ConvolutionalBlock.forward": [[92, 94], ["model_utils.ConvolutionalBlock.block"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "block", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.ConvolutionalBlock.add_if_not_none": [[95, 99], ["module_list.append"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_if_not_none", "(", "module_list", ",", "module", ")", ":", "\n", "        ", "if", "module", "is", "not", "None", ":", "\n", "            ", "module_list", ".", "append", "(", "module", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.Decoder.__init__": [[101, 138], ["torch.Module.__init__", "model_utils.fix_upsampling_type", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "model_utils.DecodingBlock", "model_utils.Decoder.decoding_blocks.append"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.fix_upsampling_type"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels_skip_connection", ":", "int", ",", "\n", "dimensions", ":", "int", ",", "\n", "upsampling_type", ":", "str", ",", "\n", "num_decoding_blocks", ":", "int", ",", "\n", "normalization", ":", "Optional", "[", "str", "]", ",", "\n", "preactivation", ":", "bool", "=", "False", ",", "\n", "residual", ":", "bool", "=", "False", ",", "\n", "padding", ":", "int", "=", "0", ",", "\n", "padding_mode", ":", "str", "=", "'zeros'", ",", "\n", "activation", ":", "Optional", "[", "str", "]", "=", "'ReLU'", ",", "\n", "initial_dilation", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "dropout", ":", "float", "=", "0", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "upsampling_type", "=", "fix_upsampling_type", "(", "upsampling_type", ",", "dimensions", ")", "\n", "self", ".", "decoding_blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "dilation", "=", "initial_dilation", "\n", "for", "_", "in", "range", "(", "num_decoding_blocks", ")", ":", "\n", "            ", "decoding_block", "=", "DecodingBlock", "(", "\n", "in_channels_skip_connection", ",", "\n", "dimensions", ",", "\n", "upsampling_type", ",", "\n", "normalization", "=", "normalization", ",", "\n", "preactivation", "=", "preactivation", ",", "\n", "residual", "=", "residual", ",", "\n", "padding", "=", "padding", ",", "\n", "padding_mode", "=", "padding_mode", ",", "\n", "activation", "=", "activation", ",", "\n", "dilation", "=", "self", ".", "dilation", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "self", ".", "decoding_blocks", ".", "append", "(", "decoding_block", ")", "\n", "in_channels_skip_connection", "//=", "2", "\n", "if", "self", ".", "dilation", "is", "not", "None", ":", "\n", "                ", "self", ".", "dilation", "//=", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.Decoder.forward": [[139, 144], ["zip", "reversed", "decoding_block"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "skip_connections", ",", "x", ")", ":", "\n", "        ", "zipped", "=", "zip", "(", "reversed", "(", "skip_connections", ")", ",", "self", ".", "decoding_blocks", ")", "\n", "for", "skip_connection", ",", "decoding_block", "in", "zipped", ":", "\n", "            ", "x", "=", "decoding_block", "(", "skip_connection", ",", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.Encoder.__init__": [[146, 193], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "model_utils.EncodingBlock", "model_utils.Encoder.encoding_blocks.append"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "out_channels_first", ":", "int", ",", "\n", "dimensions", ":", "int", ",", "\n", "pooling_type", ":", "str", ",", "\n", "num_encoding_blocks", ":", "int", ",", "\n", "normalization", ":", "Optional", "[", "str", "]", ",", "\n", "preactivation", ":", "bool", "=", "False", ",", "\n", "residual", ":", "bool", "=", "False", ",", "\n", "padding", ":", "int", "=", "0", ",", "\n", "padding_mode", ":", "str", "=", "'zeros'", ",", "\n", "activation", ":", "Optional", "[", "str", "]", "=", "'ReLU'", ",", "\n", "initial_dilation", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "dropout", ":", "float", "=", "0", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "encoding_blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "dilation", "=", "initial_dilation", "\n", "is_first_block", "=", "True", "\n", "for", "_", "in", "range", "(", "num_encoding_blocks", ")", ":", "\n", "            ", "encoding_block", "=", "EncodingBlock", "(", "\n", "in_channels", ",", "\n", "out_channels_first", ",", "\n", "dimensions", ",", "\n", "normalization", ",", "\n", "pooling_type", ",", "\n", "preactivation", ",", "\n", "is_first_block", "=", "is_first_block", ",", "\n", "residual", "=", "residual", ",", "\n", "padding", "=", "padding", ",", "\n", "padding_mode", "=", "padding_mode", ",", "\n", "activation", "=", "activation", ",", "\n", "dilation", "=", "self", ".", "dilation", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "is_first_block", "=", "False", "\n", "self", ".", "encoding_blocks", ".", "append", "(", "encoding_block", ")", "\n", "if", "dimensions", "==", "2", ":", "\n", "                ", "in_channels", "=", "out_channels_first", "\n", "out_channels_first", "=", "in_channels", "*", "2", "\n", "", "elif", "dimensions", "==", "3", ":", "\n", "                ", "in_channels", "=", "2", "*", "out_channels_first", "\n", "out_channels_first", "=", "in_channels", "\n", "", "if", "self", ".", "dilation", "is", "not", "None", ":", "\n", "                ", "self", ".", "dilation", "*=", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.Encoder.forward": [[194, 200], ["encoding_block", "skip_connections.append"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "skip_connections", "=", "[", "]", "\n", "for", "encoding_block", "in", "self", ".", "encoding_blocks", ":", "\n", "            ", "x", ",", "skip_connnection", "=", "encoding_block", "(", "x", ")", "\n", "skip_connections", ".", "append", "(", "skip_connnection", ")", "\n", "", "return", "skip_connections", ",", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.Encoder.out_channels": [[201, 204], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "out_channels", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "encoding_blocks", "[", "-", "1", "]", ".", "out_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.EncodingBlock.__init__": [[207, 279], ["torch.Module.__init__", "model_utils.ConvolutionalBlock", "model_utils.ConvolutionalBlock", "model_utils.ConvolutionalBlock", "model_utils.get_downsampling_layer"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.get_downsampling_layer"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "out_channels_first", ":", "int", ",", "\n", "dimensions", ":", "int", ",", "\n", "normalization", ":", "Optional", "[", "str", "]", ",", "\n", "pooling_type", ":", "Optional", "[", "str", "]", ",", "\n", "preactivation", "=", "False", ",", "\n", "is_first_block", ":", "bool", "=", "False", ",", "\n", "residual", ":", "bool", "=", "False", ",", "\n", "padding", ":", "int", "=", "0", ",", "\n", "padding_mode", ":", "str", "=", "'zeros'", ",", "\n", "activation", ":", "Optional", "[", "str", "]", "=", "'ReLU'", ",", "\n", "dilation", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "dropout", ":", "float", "=", "0", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "preactivation", "=", "preactivation", "\n", "self", ".", "normalization", "=", "normalization", "\n", "\n", "self", ".", "residual", "=", "residual", "\n", "\n", "if", "is_first_block", ":", "\n", "            ", "normalization", "=", "None", "\n", "preactivation", "=", "None", "\n", "", "else", ":", "\n", "            ", "normalization", "=", "self", ".", "normalization", "\n", "preactivation", "=", "self", ".", "preactivation", "\n", "\n", "", "self", ".", "conv1", "=", "ConvolutionalBlock", "(", "\n", "dimensions", ",", "\n", "in_channels", ",", "\n", "out_channels_first", ",", "\n", "normalization", "=", "normalization", ",", "\n", "preactivation", "=", "preactivation", ",", "\n", "padding", "=", "padding", ",", "\n", "padding_mode", "=", "padding_mode", ",", "\n", "activation", "=", "activation", ",", "\n", "dilation", "=", "dilation", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "\n", "if", "dimensions", "==", "2", ":", "\n", "            ", "out_channels_second", "=", "out_channels_first", "\n", "", "elif", "dimensions", "==", "3", ":", "\n", "            ", "out_channels_second", "=", "2", "*", "out_channels_first", "\n", "", "self", ".", "conv2", "=", "ConvolutionalBlock", "(", "\n", "dimensions", ",", "\n", "out_channels_first", ",", "\n", "out_channels_second", ",", "\n", "normalization", "=", "self", ".", "normalization", ",", "\n", "preactivation", "=", "self", ".", "preactivation", ",", "\n", "padding", "=", "padding", ",", "\n", "activation", "=", "activation", ",", "\n", "dilation", "=", "dilation", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "\n", "if", "residual", ":", "\n", "            ", "self", ".", "conv_residual", "=", "ConvolutionalBlock", "(", "\n", "dimensions", ",", "\n", "in_channels", ",", "\n", "out_channels_second", ",", "\n", "kernel_size", "=", "1", ",", "\n", "normalization", "=", "None", ",", "\n", "activation", "=", "None", ",", "\n", ")", "\n", "\n", "", "self", ".", "downsample", "=", "None", "\n", "if", "pooling_type", "is", "not", "None", ":", "\n", "            ", "self", ".", "downsample", "=", "get_downsampling_layer", "(", "dimensions", ",", "pooling_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.EncodingBlock.forward": [[280, 295], ["model_utils.EncodingBlock.conv_residual", "model_utils.EncodingBlock.conv1", "model_utils.EncodingBlock.conv2", "model_utils.EncodingBlock.conv1", "model_utils.EncodingBlock.conv2", "model_utils.EncodingBlock.downsample"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "residual", ":", "\n", "            ", "connection", "=", "self", ".", "conv_residual", "(", "x", ")", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "+=", "connection", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "", "if", "self", ".", "downsample", "is", "None", ":", "\n", "            ", "return", "x", "\n", "", "else", ":", "\n", "            ", "skip_connection", "=", "x", "\n", "x", "=", "self", ".", "downsample", "(", "x", ")", "\n", "return", "x", ",", "skip_connection", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.EncodingBlock.out_channels": [[296, 299], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "out_channels", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "conv2", ".", "conv_layer", ".", "out_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.DecodingBlock.__init__": [[311, 371], ["torch.Module.__init__", "model_utils.ConvolutionalBlock", "model_utils.ConvolutionalBlock", "model_utils.get_conv_transpose_layer", "model_utils.get_upsampling_layer", "model_utils.ConvolutionalBlock"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.get_conv_transpose_layer", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.get_upsampling_layer"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels_skip_connection", ":", "int", ",", "\n", "dimensions", ":", "int", ",", "\n", "upsampling_type", ":", "str", ",", "\n", "normalization", ":", "Optional", "[", "str", "]", ",", "\n", "preactivation", ":", "bool", "=", "True", ",", "\n", "residual", ":", "bool", "=", "False", ",", "\n", "padding", ":", "int", "=", "0", ",", "\n", "padding_mode", ":", "str", "=", "'zeros'", ",", "\n", "activation", ":", "Optional", "[", "str", "]", "=", "'ReLU'", ",", "\n", "dilation", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "dropout", ":", "float", "=", "0", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "residual", "=", "residual", "\n", "\n", "if", "upsampling_type", "==", "'conv'", ":", "\n", "            ", "in_channels", "=", "out_channels", "=", "2", "*", "in_channels_skip_connection", "\n", "self", ".", "upsample", "=", "get_conv_transpose_layer", "(", "\n", "dimensions", ",", "in_channels", ",", "out_channels", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "upsample", "=", "get_upsampling_layer", "(", "upsampling_type", ")", "\n", "", "in_channels_first", "=", "in_channels_skip_connection", "*", "(", "1", "+", "2", ")", "\n", "out_channels", "=", "in_channels_skip_connection", "\n", "self", ".", "conv1", "=", "ConvolutionalBlock", "(", "\n", "dimensions", ",", "\n", "in_channels_first", ",", "\n", "out_channels", ",", "\n", "normalization", "=", "normalization", ",", "\n", "preactivation", "=", "preactivation", ",", "\n", "padding", "=", "padding", ",", "\n", "padding_mode", "=", "padding_mode", ",", "\n", "activation", "=", "activation", ",", "\n", "dilation", "=", "dilation", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "in_channels_second", "=", "out_channels", "\n", "self", ".", "conv2", "=", "ConvolutionalBlock", "(", "\n", "dimensions", ",", "\n", "in_channels_second", ",", "\n", "out_channels", ",", "\n", "normalization", "=", "normalization", ",", "\n", "preactivation", "=", "preactivation", ",", "\n", "padding", "=", "padding", ",", "\n", "padding_mode", "=", "padding_mode", ",", "\n", "activation", "=", "activation", ",", "\n", "dilation", "=", "dilation", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "\n", "if", "residual", ":", "\n", "            ", "self", ".", "conv_residual", "=", "ConvolutionalBlock", "(", "\n", "dimensions", ",", "\n", "in_channels_first", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "normalization", "=", "None", ",", "\n", "activation", "=", "None", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.DecodingBlock.forward": [[373, 389], ["model_utils.DecodingBlock.upsample", "model_utils.DecodingBlock.center_crop", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_utils.DecodingBlock.conv_residual", "model_utils.DecodingBlock.conv1", "model_utils.DecodingBlock.conv2", "model_utils.DecodingBlock.conv1", "model_utils.DecodingBlock.conv2"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.ResBlockBCIN.center_crop"], ["", "", "def", "forward", "(", "self", ",", "skip_connection", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "upsample", "(", "x", ")", "\n", "skip_connection", "=", "self", ".", "center_crop", "(", "skip_connection", ",", "x", ")", "\n", "#print(skip_connection.shape)", "\n", "#print(x.shape)", "\n", "\n", "x", "=", "torch", ".", "cat", "(", "(", "skip_connection", ",", "x", ")", ",", "dim", "=", "CHANNELS_DIMENSION", ")", "\n", "if", "self", ".", "residual", ":", "\n", "            ", "connection", "=", "self", ".", "conv_residual", "(", "x", ")", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "+=", "connection", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.DecodingBlock.center_crop": [[390, 400], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.pad", "torch.pad", "torch.pad", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "pad.tolist", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten"], ["", "def", "center_crop", "(", "self", ",", "skip_connection", ",", "x", ")", ":", "\n", "        ", "skip_shape", "=", "torch", ".", "tensor", "(", "skip_connection", ".", "shape", ")", "\n", "x_shape", "=", "torch", ".", "tensor", "(", "x", ".", "shape", ")", "\n", "crop", "=", "skip_shape", "[", "2", ":", "]", "-", "x_shape", "[", "2", ":", "]", "\n", "half_crop", "=", "crop", "//", "2", "\n", "# If skip_connection is 10, 20, 30 and x is (6, 14, 12)", "\n", "# Then pad will be (-2, -2, -3, -3, -9, -9)", "\n", "pad", "=", "-", "torch", ".", "stack", "(", "(", "half_crop", ",", "half_crop", ")", ")", ".", "t", "(", ")", ".", "flatten", "(", ")", "\n", "skip_connection", "=", "F", ".", "pad", "(", "skip_connection", ",", "pad", ".", "tolist", "(", ")", ")", "\n", "return", "skip_connection", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.get_downsampling_layer": [[301, 309], ["getattr", "getattr.", "pooling_type.capitalize"], "function", ["None"], ["", "", "def", "get_downsampling_layer", "(", "\n", "dimensions", ":", "int", ",", "\n", "pooling_type", ":", "str", ",", "\n", "kernel_size", ":", "int", "=", "2", ",", "\n", ")", "->", "nn", ".", "Module", ":", "\n", "    ", "class_name", "=", "'{}Pool{}d'", ".", "format", "(", "pooling_type", ".", "capitalize", "(", ")", ",", "dimensions", ")", "\n", "class_", "=", "getattr", "(", "nn", ",", "class_name", ")", "\n", "return", "class_", "(", "kernel_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.get_upsampling_layer": [[402, 411], ["torch.Upsample", "message.format.format", "ValueError"], "function", ["None"], ["", "", "def", "get_upsampling_layer", "(", "upsampling_type", ":", "str", ")", "->", "nn", ".", "Upsample", ":", "\n", "    ", "if", "upsampling_type", "not", "in", "UPSAMPLING_MODES", ":", "\n", "        ", "message", "=", "(", "\n", "'Upsampling type is \"{}\"'", "\n", "' but should be one of the following: {}'", "\n", ")", "\n", "message", "=", "message", ".", "format", "(", "upsampling_type", ",", "UPSAMPLING_MODES", ")", "\n", "raise", "ValueError", "(", "message", ")", "\n", "", "return", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ",", "mode", "=", "upsampling_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.get_conv_transpose_layer": [[413, 418], ["getattr", "getattr."], "function", ["None"], ["", "def", "get_conv_transpose_layer", "(", "dimensions", ",", "in_channels", ",", "out_channels", ")", ":", "\n", "    ", "class_name", "=", "'ConvTranspose{}d'", ".", "format", "(", "dimensions", ")", "\n", "conv_class", "=", "getattr", "(", "nn", ",", "class_name", ")", "\n", "conv_layer", "=", "conv_class", "(", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", "\n", "return", "conv_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.model_utils.fix_upsampling_type": [[420, 427], ["None"], "function", ["None"], ["", "def", "fix_upsampling_type", "(", "upsampling_type", ":", "str", ",", "dimensions", ":", "int", ")", ":", "\n", "    ", "if", "upsampling_type", "==", "'linear'", ":", "\n", "        ", "if", "dimensions", "==", "2", ":", "\n", "            ", "upsampling_type", "=", "'bilinear'", "\n", "", "elif", "dimensions", "==", "3", ":", "\n", "            ", "upsampling_type", "=", "'trilinear'", "\n", "", "", "return", "upsampling_type", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.unet_milesial.UNet.__init__": [[10, 27], ["mp.models.segmentation.segmentation_model.SegmentationModel.__init__", "unet_milesial.DoubleConv", "unet_milesial.Down", "unet_milesial.Down", "unet_milesial.Down", "unet_milesial.Down", "unet_milesial.Up", "unet_milesial.Up", "unet_milesial.Up", "unet_milesial.Up", "unet_milesial.OutConv"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_shape", ",", "n_classes", ",", "bilinear", "=", "True", ")", ":", "\n", "        ", "super", "(", "UNet", ",", "self", ")", ".", "__init__", "(", "input_shape", ",", "n_classes", ")", "\n", "self", ".", "n_channels", "=", "input_shape", "[", "0", "]", "\n", "self", ".", "n_classes", "=", "n_classes", "\n", "self", ".", "bilinear", "=", "bilinear", "\n", "\n", "self", ".", "inc", "=", "DoubleConv", "(", "self", ".", "n_channels", ",", "64", ")", "\n", "self", ".", "down1", "=", "Down", "(", "64", ",", "128", ")", "\n", "self", ".", "down2", "=", "Down", "(", "128", ",", "256", ")", "\n", "self", ".", "down3", "=", "Down", "(", "256", ",", "512", ")", "\n", "factor", "=", "2", "if", "bilinear", "else", "1", "\n", "self", ".", "down4", "=", "Down", "(", "512", ",", "1024", "//", "factor", ")", "\n", "self", ".", "up1", "=", "Up", "(", "1024", ",", "512", "//", "factor", ",", "bilinear", ")", "\n", "self", ".", "up2", "=", "Up", "(", "512", ",", "256", "//", "factor", ",", "bilinear", ")", "\n", "self", ".", "up3", "=", "Up", "(", "256", ",", "128", "//", "factor", ",", "bilinear", ")", "\n", "self", ".", "up4", "=", "Up", "(", "128", ",", "64", ",", "bilinear", ")", "\n", "self", ".", "outc", "=", "OutConv", "(", "64", ",", "n_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.unet_milesial.UNet.forward": [[28, 40], ["unet_milesial.UNet.inc", "unet_milesial.UNet.down1", "unet_milesial.UNet.down2", "unet_milesial.UNet.down3", "unet_milesial.UNet.down4", "unet_milesial.UNet.up1", "unet_milesial.UNet.up2", "unet_milesial.UNet.up3", "unet_milesial.UNet.up4", "unet_milesial.UNet.outc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x1", "=", "self", ".", "inc", "(", "x", ")", "\n", "x2", "=", "self", ".", "down1", "(", "x1", ")", "\n", "x3", "=", "self", ".", "down2", "(", "x2", ")", "\n", "x4", "=", "self", ".", "down3", "(", "x3", ")", "\n", "x5", "=", "self", ".", "down4", "(", "x4", ")", "\n", "x", "=", "self", ".", "up1", "(", "x5", ",", "x4", ")", "\n", "x", "=", "self", ".", "up2", "(", "x", ",", "x3", ")", "\n", "x", "=", "self", ".", "up3", "(", "x", ",", "x2", ")", "\n", "x", "=", "self", ".", "up4", "(", "x", ",", "x1", ")", "\n", "logits", "=", "self", ".", "outc", "(", "x", ")", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.unet_milesial.DoubleConv.__init__": [[46, 57], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "mid_channels", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "not", "mid_channels", ":", "\n", "            ", "mid_channels", "=", "out_channels", "\n", "", "self", ".", "double_conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_channels", ",", "mid_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "mid_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "mid_channels", ",", "out_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.unet_milesial.DoubleConv.forward": [[59, 61], ["unet_milesial.DoubleConv.double_conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "double_conv", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.unet_milesial.Down.__init__": [[66, 71], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "unet_milesial.DoubleConv"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "maxpool_conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "MaxPool2d", "(", "2", ")", ",", "\n", "DoubleConv", "(", "in_channels", ",", "out_channels", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.unet_milesial.Down.forward": [[73, 75], ["unet_milesial.Down.maxpool_conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "maxpool_conv", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.unet_milesial.Up.__init__": [[80, 90], ["torch.Module.__init__", "torch.Upsample", "torch.Upsample", "torch.Upsample", "unet_milesial.DoubleConv", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "unet_milesial.DoubleConv"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "bilinear", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# if bilinear, use the normal convolutions to reduce the number of channels", "\n", "if", "bilinear", ":", "\n", "            ", "self", ".", "up", "=", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "self", ".", "conv", "=", "DoubleConv", "(", "in_channels", ",", "out_channels", ",", "in_channels", "//", "2", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "up", "=", "nn", ".", "ConvTranspose2d", "(", "in_channels", ",", "in_channels", "//", "2", ",", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", "\n", "self", ".", "conv", "=", "DoubleConv", "(", "in_channels", ",", "out_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.unet_milesial.Up.forward": [[92, 105], ["unet_milesial.Up.up", "torch.pad", "torch.pad", "torch.pad", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "unet_milesial.Up.conv", "x2.size", "torch.pad.size", "x2.size", "torch.pad.size"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x1", ",", "x2", ")", ":", "\n", "        ", "x1", "=", "self", ".", "up", "(", "x1", ")", "\n", "# input is CHW", "\n", "diffY", "=", "x2", ".", "size", "(", ")", "[", "2", "]", "-", "x1", ".", "size", "(", ")", "[", "2", "]", "\n", "diffX", "=", "x2", ".", "size", "(", ")", "[", "3", "]", "-", "x1", ".", "size", "(", ")", "[", "3", "]", "\n", "\n", "x1", "=", "F", ".", "pad", "(", "x1", ",", "[", "diffX", "//", "2", ",", "diffX", "-", "diffX", "//", "2", ",", "\n", "diffY", "//", "2", ",", "diffY", "-", "diffY", "//", "2", "]", ")", "\n", "# if you have padding issues, see", "\n", "# https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a", "\n", "# https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x2", ",", "x1", "]", ",", "dim", "=", "1", ")", "\n", "return", "self", ".", "conv", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.unet_milesial.OutConv.__init__": [[108, 111], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ")", ":", "\n", "        ", "super", "(", "OutConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.unet_milesial.OutConv.forward": [[112, 114], ["unet_milesial.OutConv.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "conv", "(", "x", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.unet_fepegar.UNet.__init__": [[12, 117], ["mp.models.segmentation.segmentation_model.SegmentationModel.__init__", "mp.models.segmentation.model_utils.Encoder", "mp.models.segmentation.model_utils.EncodingBlock", "mp.models.segmentation.model_utils.Decoder", "mp.models.segmentation.model_utils.ConvolutionalBlock", "getattr", "getattr."], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "input_shape", ",", "\n", "nr_labels", ",", "\n", "dimensions", ":", "int", "=", "2", ",", "\n", "num_encoding_blocks", ":", "int", "=", "5", ",", "\n", "out_channels_first_layer", ":", "int", "=", "64", ",", "\n", "normalization", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "pooling_type", ":", "str", "=", "'max'", ",", "\n", "upsampling_type", ":", "str", "=", "'conv'", ",", "\n", "preactivation", ":", "bool", "=", "False", ",", "\n", "residual", ":", "bool", "=", "False", ",", "\n", "padding", ":", "int", "=", "0", ",", "\n", "padding_mode", ":", "str", "=", "'zeros'", ",", "\n", "activation", ":", "Optional", "[", "str", "]", "=", "'ReLU'", ",", "\n", "initial_dilation", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "dropout", ":", "float", "=", "0", ",", "\n", "monte_carlo_dropout", ":", "float", "=", "0", ",", "\n", ")", ":", "\n", "        ", "super", "(", "UNet", ",", "self", ")", ".", "__init__", "(", "input_shape", "=", "input_shape", ",", "nr_labels", "=", "nr_labels", ")", "\n", "\n", "in_channels", "=", "input_shape", "[", "0", "]", "\n", "\n", "depth", "=", "num_encoding_blocks", "-", "1", "\n", "\n", "# Force padding if residual blocks", "\n", "if", "residual", ":", "\n", "            ", "padding", "=", "1", "\n", "\n", "# Encoder", "\n", "", "self", ".", "encoder", "=", "Encoder", "(", "\n", "in_channels", ",", "\n", "out_channels_first_layer", ",", "\n", "dimensions", ",", "\n", "pooling_type", ",", "\n", "depth", ",", "\n", "normalization", ",", "\n", "preactivation", "=", "preactivation", ",", "\n", "residual", "=", "residual", ",", "\n", "padding", "=", "padding", ",", "\n", "padding_mode", "=", "padding_mode", ",", "\n", "activation", "=", "activation", ",", "\n", "initial_dilation", "=", "initial_dilation", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "\n", "# Bottom (last encoding block)", "\n", "in_channels", "=", "self", ".", "encoder", ".", "out_channels", "\n", "if", "dimensions", "==", "2", ":", "\n", "            ", "out_channels_first", "=", "2", "*", "in_channels", "\n", "", "else", ":", "\n", "            ", "out_channels_first", "=", "in_channels", "\n", "\n", "", "self", ".", "bottom_block", "=", "EncodingBlock", "(", "\n", "in_channels", ",", "\n", "out_channels_first", ",", "\n", "dimensions", ",", "\n", "normalization", ",", "\n", "pooling_type", "=", "None", ",", "\n", "preactivation", "=", "preactivation", ",", "\n", "residual", "=", "residual", ",", "\n", "padding", "=", "padding", ",", "\n", "padding_mode", "=", "padding_mode", ",", "\n", "activation", "=", "activation", ",", "\n", "dilation", "=", "self", ".", "encoder", ".", "dilation", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "\n", "# Decoder", "\n", "if", "dimensions", "==", "2", ":", "\n", "            ", "power", "=", "depth", "-", "1", "\n", "", "elif", "dimensions", "==", "3", ":", "\n", "            ", "power", "=", "depth", "\n", "", "in_channels", "=", "self", ".", "bottom_block", ".", "out_channels", "\n", "in_channels_skip_connection", "=", "out_channels_first_layer", "*", "2", "**", "power", "\n", "num_decoding_blocks", "=", "depth", "\n", "self", ".", "decoder", "=", "Decoder", "(", "\n", "in_channels_skip_connection", ",", "\n", "dimensions", ",", "\n", "upsampling_type", ",", "\n", "num_decoding_blocks", ",", "\n", "normalization", "=", "normalization", ",", "\n", "preactivation", "=", "preactivation", ",", "\n", "residual", "=", "residual", ",", "\n", "padding", "=", "padding", ",", "\n", "padding_mode", "=", "padding_mode", ",", "\n", "activation", "=", "activation", ",", "\n", "initial_dilation", "=", "self", ".", "encoder", ".", "dilation", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "\n", "# Monte Carlo dropout", "\n", "self", ".", "monte_carlo_layer", "=", "None", "\n", "if", "monte_carlo_dropout", ":", "\n", "            ", "dropout_class", "=", "getattr", "(", "nn", ",", "'Dropout{}d'", ".", "format", "(", "dimensions", ")", ")", "\n", "self", ".", "monte_carlo_layer", "=", "dropout_class", "(", "p", "=", "monte_carlo_dropout", ")", "\n", "\n", "# Classifier", "\n", "", "if", "dimensions", "==", "2", ":", "\n", "            ", "in_channels", "=", "out_channels_first_layer", "\n", "", "elif", "dimensions", "==", "3", ":", "\n", "            ", "in_channels", "=", "2", "*", "out_channels_first_layer", "\n", "", "self", ".", "classifier", "=", "ConvolutionalBlock", "(", "\n", "dimensions", ",", "in_channels", ",", "nr_labels", ",", "\n", "kernel_size", "=", "1", ",", "activation", "=", "None", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.unet_fepegar.UNet.forward": [[119, 126], ["unet_fepegar.UNet.encoder", "unet_fepegar.UNet.bottom_block", "unet_fepegar.UNet.decoder", "unet_fepegar.UNet.classifier", "unet_fepegar.UNet.monte_carlo_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "skip_connections", ",", "encoding", "=", "self", ".", "encoder", "(", "x", ")", "\n", "encoding", "=", "self", ".", "bottom_block", "(", "encoding", ")", "\n", "x", "=", "self", ".", "decoder", "(", "skip_connections", ",", "encoding", ")", "\n", "if", "self", ".", "monte_carlo_layer", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "monte_carlo_layer", "(", "x", ")", "\n", "", "return", "self", ".", "classifier", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.unet_fepegar.UNet2D.__init__": [[128, 143], ["predef_kwargs.update", "unet_fepegar.UNet.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.update", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "len", "(", "args", "[", "0", "]", ")", "==", "3", ",", "\"Input shape must have dimensions channels, width, height. Received: {}\"", ".", "format", "(", "args", "[", "0", "]", ")", "\n", "predef_kwargs", "=", "{", "}", "\n", "predef_kwargs", "[", "'dimensions'", "]", "=", "2", "\n", "predef_kwargs", "[", "'num_encoding_blocks'", "]", "=", "5", "\n", "predef_kwargs", "[", "'out_channels_first_layer'", "]", "=", "16", "#64", "\n", "predef_kwargs", "[", "'normalization'", "]", "=", "'batch'", "\n", "# added TODO", "\n", "# predef_kwargs['preactivation'] = True", "\n", "preactivation", "=", "True", "\n", "# Added this so there is no error between the skip connection and ", "\n", "# feature mas shapes", "\n", "predef_kwargs", "[", "'padding'", "]", "=", "True", "\n", "predef_kwargs", ".", "update", "(", "kwargs", ")", "\n", "super", "(", "UNet2D", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "predef_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.unet_fepegar.UNet3D.__init__": [[145, 156], ["predef_kwargs.update", "unet_fepegar.UNet.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.update", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "len", "(", "args", "[", "0", "]", ")", "==", "4", ",", "\"Input shape must have dimensions channels, width, height, depth. Received: {}\"", ".", "format", "(", "args", "[", "0", "]", ")", "\n", "predef_kwargs", "=", "{", "}", "\n", "predef_kwargs", "[", "'dimensions'", "]", "=", "3", "\n", "predef_kwargs", "[", "'num_encoding_blocks'", "]", "=", "4", "\n", "predef_kwargs", "[", "'out_channels_first_layer'", "]", "=", "8", "\n", "predef_kwargs", "[", "'normalization'", "]", "=", "'batch'", "\n", "predef_kwargs", "[", "'upsampling_type'", "]", "=", "'linear'", "\n", "predef_kwargs", "[", "'padding'", "]", "=", "True", "\n", "predef_kwargs", ".", "update", "(", "kwargs", ")", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "predef_kwargs", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.segmentation.segmentation_model.SegmentationModel.__init__": [[10, 17], ["tuple", "mp.models.model.Model.__init__", "len", "list"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "input_shape", ",", "nr_labels", ")", ":", "\n", "        ", "assert", "2", "<", "len", "(", "input_shape", ")", "<", "5", "\n", "# The output shae is the same as the input shape, but instead of the ", "\n", "# input channels it has the number of labels as channels", "\n", "output_shape", "=", "tuple", "(", "[", "nr_labels", "]", "+", "list", "(", "input_shape", "[", "1", ":", "]", ")", ")", "\n", "super", "(", "SegmentationModel", ",", "self", ")", ".", "__init__", "(", "input_shape", ",", "output_shape", "=", "output_shape", ")", "\n", "self", ".", "nr_labels", "=", "nr_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.kd.KD.__init__": [[9, 36], ["mp.models.model.Model.__init__", "mp.models.segmentation.unet_fepegar.UNet2D"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "\n", "input_shape", "=", "(", "1", ",", "256", ",", "256", ")", ",", "\n", "nr_labels", "=", "2", ",", "\n", "unet_dropout", "=", "0", ",", "\n", "unet_monte_carlo_dropout", "=", "0", ",", "\n", "unet_preactivation", "=", "False", "\n", ")", ":", "\n", "        ", "r\"\"\"Constructor\n        \n        Args:\n            input_shape (tuple of int): input shape of the images\n            nr_labels (int): number of labels for the segmentation\n            unet_dropout (float): dropout probability for the U-Net\n            unet_monte_carlo_dropout (float): monte carlo dropout probability for the U-Net\n            unet_preactivation (boolean): whether to use U-Net pre-activations\n        \"\"\"", "\n", "super", "(", "KD", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_shape", "=", "input_shape", "\n", "self", ".", "nr_labels", "=", "nr_labels", "\n", "\n", "self", ".", "unet_dropout", "=", "unet_dropout", "\n", "self", ".", "unet_monte_carlo_dropout", "=", "unet_monte_carlo_dropout", "\n", "self", ".", "unet_preactivation", "=", "unet_preactivation", "\n", "\n", "self", ".", "unet_new", "=", "UNet2D", "(", "self", ".", "input_shape", ",", "self", ".", "nr_labels", ",", "dropout", "=", "self", ".", "unet_dropout", ",", "monte_carlo_dropout", "=", "self", ".", "unet_monte_carlo_dropout", ",", "preactivation", "=", "self", ".", "unet_preactivation", ")", "\n", "self", ".", "unet_old", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.kd.KD.forward": [[37, 47], ["kd.KD.unet_new"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "r\"\"\"Forward pass of current U-Net\n        \n        Args:\n            x (torch.Tensor): input batch\n        \n        Returns:\n            (torch.Tensor): segmentated batch\n        \"\"\"", "\n", "return", "self", ".", "unet_new", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.kd.KD.forward_old": [[48, 58], ["kd.KD.unet_old"], "methods", ["None"], ["", "def", "forward_old", "(", "self", ",", "x", ")", ":", "\n", "        ", "r\"\"\"Forward pass of previous U-Net\n        \n        Args:\n            x (torch.Tensor): input batch\n        \n        Returns:\n            (torch.Tensor): segmentated batch\n        \"\"\"", "\n", "return", "self", ".", "unet_old", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.kd.KD.freeze_unet": [[59, 71], ["unet.parameters"], "methods", ["None"], ["", "def", "freeze_unet", "(", "self", ",", "unet", ")", ":", "\n", "        ", "r\"\"\"Freeze U-Net\n        \n        Args:\n            unet (nn.Module): U-Net\n        \n        Returns:\n            (nn.Module): U-Net with frozen weights\n        \"\"\"", "\n", "for", "param", "in", "unet", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "return", "unet", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.kd.KD.freeze_decoder": [[72, 86], ["unet.decoder.parameters", "unet.classifier.parameters"], "methods", ["None"], ["", "def", "freeze_decoder", "(", "self", ",", "unet", ")", ":", "\n", "        ", "r\"\"\"Freeze U-Net decoder\n        \n        Args:\n            unet (nn.Module): U-Net\n        \n        Returns:\n            (nn.Module): U-Net with frozen decoder weights\n        \"\"\"", "\n", "for", "param", "in", "unet", ".", "decoder", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "for", "param", "in", "unet", ".", "classifier", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "return", "unet", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.kd.KD.finish": [[87, 99], ["kd.KD.unet_new.state_dict", "mp.models.segmentation.unet_fepegar.UNet2D", "kd.KD.unet_old.load_state_dict", "kd.KD.freeze_unet", "kd.KD.unet_old.to", "next", "kd.KD.unet_new.parameters", "next", "kd.KD.unet_new.parameters"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.mas.MAS.freeze_unet", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to"], ["", "def", "finish", "(", "self", ")", ":", "\n", "        ", "r\"\"\"Finish training, store current U-Net as old U-Net\n        \"\"\"", "\n", "unet_new_state_dict", "=", "self", ".", "unet_new", ".", "state_dict", "(", ")", "\n", "if", "next", "(", "self", ".", "unet_new", ".", "parameters", "(", ")", ")", ".", "is_cuda", ":", "\n", "            ", "device", "=", "next", "(", "self", ".", "unet_new", ".", "parameters", "(", ")", ")", ".", "device", "\n", "\n", "", "self", ".", "unet_old", "=", "UNet2D", "(", "self", ".", "input_shape", ",", "self", ".", "nr_labels", ",", "dropout", "=", "self", ".", "unet_dropout", ",", "monte_carlo_dropout", "=", "self", ".", "unet_monte_carlo_dropout", ",", "preactivation", "=", "self", ".", "unet_preactivation", ")", "\n", "self", ".", "unet_old", ".", "load_state_dict", "(", "unet_new_state_dict", ")", "\n", "self", ".", "unet_old", "=", "self", ".", "freeze_unet", "(", "self", ".", "unet_old", ")", "\n", "\n", "self", ".", "unet_old", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.kd.KD.set_optimizers": [[101, 113], ["optimizer", "optimizer", "kd.KD.unet_new.parameters", "kd.KD.unet_new.parameters"], "methods", ["None"], ["", "def", "set_optimizers", "(", "self", ",", "optimizer", "=", "optim", ".", "SGD", ",", "lr", "=", "1e-4", ",", "weight_decay", "=", "1e-4", ")", ":", "\n", "        ", "r\"\"\"Set optimizers for all modules\n        \n        Args:\n            optimizer (torch.nn.optim): optimizer to use\n            lr (float): learning rate to use\n            weight_decay (float): weight decay\n        \"\"\"", "\n", "if", "optimizer", "==", "optim", ".", "SGD", ":", "\n", "            ", "self", ".", "unet_optim", "=", "optimizer", "(", "self", ".", "unet_new", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "weight_decay", "=", "weight_decay", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "unet_optim", "=", "optimizer", "(", "self", ".", "unet_new", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.UNet2D_dis.__init__": [[10, 12], ["mp.models.segmentation.unet_fepegar.UNet2D.__init__"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["import", "torch", ".", "nn", "as", "nn", "\n", "import", "torch", ".", "nn", ".", "functional", "as", "F", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.UNet2D_dis.forward_enc": [[13, 17], ["model_utils.UNet2D_dis.encoder", "model_utils.UNet2D_dis.bottom_block"], "methods", ["None"], ["CHANNELS_DIMENSION", "=", "1", "\n", "UPSAMPLING_MODES", "=", "(", "\n", "'nearest'", ",", "\n", "'linear'", ",", "\n", "'bilinear'", ",", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.UNet2D_dis.forward_dec": [[18, 23], ["model_utils.UNet2D_dis.decoder", "model_utils.UNet2D_dis.classifier", "model_utils.UNet2D_dis.monte_carlo_layer"], "methods", ["None"], ["'bicubic'", ",", "\n", "'trilinear'", ",", "\n", ")", "\n", "\n", "class", "ConvolutionalBlock", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.EncoderStyle.__init__": [[28, 47], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "model_utils.ConvBlock", "model_utils.ConvPoolBlock", "model_utils.ConvPoolBlock", "model_utils.ConvPoolBlock", "model_utils.ConvPoolBlock", "model_utils.ConvPoolBlock", "model_utils.ConvPoolBlock", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.AdaptiveMaxPool2d", "torch.AdaptiveMaxPool2d", "torch.AdaptiveMaxPool2d"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["normalization", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "kernel_size", ":", "int", "=", "3", ",", "\n", "activation", ":", "Optional", "[", "str", "]", "=", "'ReLU'", ",", "\n", "preactivation", ":", "bool", "=", "False", ",", "\n", "padding", ":", "int", "=", "0", ",", "\n", "padding_mode", ":", "str", "=", "'zeros'", ",", "\n", "dilation", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "dropout", ":", "float", "=", "0", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "block", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "dilation", "=", "1", "if", "dilation", "is", "None", "else", "dilation", "\n", "if", "padding", ":", "\n", "            ", "total_padding", "=", "kernel_size", "+", "2", "*", "(", "dilation", "-", "1", ")", "-", "1", "\n", "padding", "=", "total_padding", "//", "2", "\n", "\n", "", "class_name", "=", "'Conv{}d'", ".", "format", "(", "dimensions", ")", "\n", "conv_class", "=", "getattr", "(", "nn", ",", "class_name", ")", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.EncoderStyle.forward": [[48, 54], ["model_utils.EncoderStyle.layers", "model_utils.EncoderStyle.global_pool", "model_utils.EncoderStyle.dense_mu", "model_utils.EncoderStyle.dense_var", "model_utils.EncoderStyle.view", "model_utils.EncoderStyle.view"], "methods", ["None"], ["conv_layer", "=", "conv_class", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "padding", "=", "padding", ",", "\n", "padding_mode", "=", "padding_mode", ",", "\n", "dilation", "=", "dilation", ",", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.LatentScaler.__init__": [[58, 70], ["torch.Module.__init__", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["if", "normalization", "is", "not", "None", ":", "\n", "            ", "class_name", "=", "'{}Norm{}d'", ".", "format", "(", "\n", "normalization", ".", "capitalize", "(", ")", ",", "dimensions", ")", "\n", "norm_class", "=", "getattr", "(", "nn", ",", "class_name", ")", "\n", "num_features", "=", "in_channels", "if", "preactivation", "else", "out_channels", "\n", "norm_layer", "=", "norm_class", "(", "num_features", ")", "\n", "\n", "", "activation_layer", "=", "None", "\n", "if", "activation", "is", "not", "None", ":", "\n", "            ", "activation_layer", "=", "getattr", "(", "nn", ",", "activation", ")", "(", ")", "\n", "\n", "", "if", "preactivation", ":", "\n", "            ", "self", ".", "add_if_not_none", "(", "block", ",", "norm_layer", ")", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.LatentScaler.forward": [[71, 74], ["model_utils.LatentScaler.layers().reshape", "model_utils.LatentScaler.layers"], "methods", ["None"], ["self", ".", "add_if_not_none", "(", "block", ",", "activation_layer", ")", "\n", "self", ".", "add_if_not_none", "(", "block", ",", "conv_layer", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "add_if_not_none", "(", "block", ",", "conv_layer", ")", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.Generator.__init__": [[78, 94], ["torch.Module.__init__", "range", "model_utils.MultiInSequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "model_utils.ResBlockBCIN", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "model_utils.ResBlockBCIN"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["", "dropout_layer", "=", "None", "\n", "if", "dropout", ":", "\n", "            ", "class_name", "=", "'Dropout{}d'", ".", "format", "(", "dimensions", ")", "\n", "dropout_class", "=", "getattr", "(", "nn", ",", "class_name", ")", "\n", "dropout_layer", "=", "dropout_class", "(", "p", "=", "dropout", ")", "\n", "self", ".", "add_if_not_none", "(", "block", ",", "dropout_layer", ")", "\n", "\n", "", "self", ".", "conv_layer", "=", "conv_layer", "\n", "self", ".", "norm_layer", "=", "norm_layer", "\n", "self", ".", "activation_layer", "=", "activation_layer", "\n", "self", ".", "dropout_layer", "=", "dropout_layer", "\n", "\n", "self", ".", "block", "=", "nn", ".", "Sequential", "(", "*", "block", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "block", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.Generator.forward": [[95, 99], ["model_utils.Generator.layers_BCIN", "model_utils.Generator.layers"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_if_not_none", "(", "module_list", ",", "module", ")", ":", "\n", "        ", "if", "module", "is", "not", "None", ":", "\n", "            ", "module_list", ".", "append", "(", "module", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.DiscriminatorDomain.__init__": [[103, 115], ["torch.Module.__init__", "model_utils.MultiInSequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "model_utils.ConvBlockBCIN", "model_utils.ConvBlockBCIN", "model_utils.ConvBlockBCIN", "model_utils.ConvBlockBCIN", "model_utils.ConvBlockBCIN"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["in_channels_skip_connection", ":", "int", ",", "\n", "dimensions", ":", "int", ",", "\n", "upsampling_type", ":", "str", ",", "\n", "num_decoding_blocks", ":", "int", ",", "\n", "normalization", ":", "Optional", "[", "str", "]", ",", "\n", "preactivation", ":", "bool", "=", "False", ",", "\n", "residual", ":", "bool", "=", "False", ",", "\n", "padding", ":", "int", "=", "0", ",", "\n", "padding_mode", ":", "str", "=", "'zeros'", ",", "\n", "activation", ":", "Optional", "[", "str", "]", "=", "'ReLU'", ",", "\n", "initial_dilation", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "dropout", ":", "float", "=", "0", ",", "\n", ")", ":", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.DiscriminatorDomain.forward": [[116, 121], ["model_utils.DiscriminatorDomain.layers", "model_utils.DiscriminatorDomain.view", "model_utils.DiscriminatorDomain.linear"], "methods", ["None"], ["        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "upsampling_type", "=", "fix_upsampling_type", "(", "upsampling_type", ",", "dimensions", ")", "\n", "self", ".", "decoding_blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "dilation", "=", "initial_dilation", "\n", "for", "_", "in", "range", "(", "num_decoding_blocks", ")", ":", "\n", "            ", "decoding_block", "=", "DecodingBlock", "(", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.DiscriminatorContent.__init__": [[125, 152], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Softmax"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["normalization", "=", "normalization", ",", "\n", "preactivation", "=", "preactivation", ",", "\n", "residual", "=", "residual", ",", "\n", "padding", "=", "padding", ",", "\n", "padding_mode", "=", "padding_mode", ",", "\n", "activation", "=", "activation", ",", "\n", "dilation", "=", "self", ".", "dilation", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "self", ".", "decoding_blocks", ".", "append", "(", "decoding_block", ")", "\n", "in_channels_skip_connection", "//=", "2", "\n", "if", "self", ".", "dilation", "is", "not", "None", ":", "\n", "                ", "self", ".", "dilation", "//=", "2", "\n", "\n", "", "", "", "def", "forward", "(", "self", ",", "skip_connections", ",", "x", ")", ":", "\n", "        ", "zipped", "=", "zip", "(", "reversed", "(", "skip_connections", ")", ",", "self", ".", "decoding_blocks", ")", "\n", "for", "skip_connection", ",", "decoding_block", "in", "zipped", ":", "\n", "            ", "x", "=", "decoding_block", "(", "skip_connection", ",", "x", ")", "\n", "", "return", "x", "\n", "\n", "", "", "class", "Encoder", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "out_channels_first", ":", "int", ",", "\n", "dimensions", ":", "int", ",", "\n", "pooling_type", ":", "str", ",", "\n", "num_encoding_blocks", ":", "int", ",", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.DiscriminatorContent.forward": [[153, 172], ["model_utils.DiscriminatorContent.conv_0", "model_utils.DiscriminatorContent.norm_0", "model_utils.DiscriminatorContent.activation_0", "model_utils.DiscriminatorContent.conv_1", "model_utils.DiscriminatorContent.norm_1", "model_utils.DiscriminatorContent.activation_1", "model_utils.DiscriminatorContent.conv_2", "model_utils.DiscriminatorContent.norm_2", "model_utils.DiscriminatorContent.activation_2", "model_utils.DiscriminatorContent.conv_3", "model_utils.DiscriminatorContent.norm_3", "model_utils.DiscriminatorContent.activation_3", "model_utils.DiscriminatorContent.conv_4", "model_utils.DiscriminatorContent.norm_4", "model_utils.DiscriminatorContent.activation_4", "model_utils.DiscriminatorContent.dense", "model_utils.DiscriminatorContent.softmax", "model_utils.DiscriminatorContent.reshape"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.inference.predict.softmax"], ["normalization", ":", "Optional", "[", "str", "]", ",", "\n", "preactivation", ":", "bool", "=", "False", ",", "\n", "residual", ":", "bool", "=", "False", ",", "\n", "padding", ":", "int", "=", "0", ",", "\n", "padding_mode", ":", "str", "=", "'zeros'", ",", "\n", "activation", ":", "Optional", "[", "str", "]", "=", "'ReLU'", ",", "\n", "initial_dilation", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "dropout", ":", "float", "=", "0", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "encoding_blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "dilation", "=", "initial_dilation", "\n", "is_first_block", "=", "True", "\n", "for", "_", "in", "range", "(", "num_encoding_blocks", ")", ":", "\n", "            ", "encoding_block", "=", "EncodingBlock", "(", "\n", "in_channels", ",", "\n", "out_channels_first", ",", "\n", "dimensions", ",", "\n", "normalization", ",", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.DiscriminatorContent.center_crop": [[173, 183], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.pad", "torch.pad", "torch.pad", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "pad.tolist", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten"], ["pooling_type", ",", "\n", "preactivation", ",", "\n", "is_first_block", "=", "is_first_block", ",", "\n", "residual", "=", "residual", ",", "\n", "padding", "=", "padding", ",", "\n", "padding_mode", "=", "padding_mode", ",", "\n", "activation", "=", "activation", ",", "\n", "dilation", "=", "self", ".", "dilation", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "is_first_block", "=", "False", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.ConvBlock.__init__": [[188, 199], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "activation", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["", "elif", "dimensions", "==", "3", ":", "\n", "                ", "in_channels", "=", "2", "*", "out_channels_first", "\n", "out_channels_first", "=", "in_channels", "\n", "", "if", "self", ".", "dilation", "is", "not", "None", ":", "\n", "                ", "self", ".", "dilation", "*=", "2", "\n", "\n", "", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "skip_connections", "=", "[", "]", "\n", "for", "encoding_block", "in", "self", ".", "encoding_blocks", ":", "\n", "            ", "x", ",", "skip_connnection", "=", "encoding_block", "(", "x", ")", "\n", "skip_connections", ".", "append", "(", "skip_connnection", ")", "\n", "", "return", "skip_connections", ",", "x", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.ConvBlock.forward": [[200, 206], ["model_utils.ConvBlock.conv", "model_utils.ConvBlock.activation", "model_utils.ConvBlock.norm"], "methods", ["None"], ["\n", "", "@", "property", "\n", "def", "out_channels", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "encoding_blocks", "[", "-", "1", "]", ".", "out_channels", "\n", "\n", "\n", "", "", "class", "EncodingBlock", "(", "nn", ".", "Module", ")", ":", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.ConvPoolBlock.__init__": [[210, 219], ["torch.Module.__init__", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "activation", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["out_channels_first", ":", "int", ",", "\n", "dimensions", ":", "int", ",", "\n", "normalization", ":", "Optional", "[", "str", "]", ",", "\n", "pooling_type", ":", "Optional", "[", "str", "]", ",", "\n", "preactivation", "=", "False", ",", "\n", "is_first_block", ":", "bool", "=", "False", ",", "\n", "residual", ":", "bool", "=", "False", ",", "\n", "padding", ":", "int", "=", "0", ",", "\n", "padding_mode", ":", "str", "=", "'zeros'", ",", "\n", "activation", ":", "Optional", "[", "str", "]", "=", "'ReLU'", ",", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.ConvPoolBlock.forward": [[220, 228], ["model_utils.ConvPoolBlock.norm", "model_utils.ConvPoolBlock.activation", "model_utils.ConvPoolBlock.conv", "model_utils.ConvPoolBlock.pool"], "methods", ["None"], ["dilation", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "dropout", ":", "float", "=", "0", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "preactivation", "=", "preactivation", "\n", "self", ".", "normalization", "=", "normalization", "\n", "\n", "self", ".", "residual", "=", "residual", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.ConvBlockBCIN.__init__": [[232, 239], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "model_utils.BCIN", "activation"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["preactivation", "=", "None", "\n", "", "else", ":", "\n", "            ", "normalization", "=", "self", ".", "normalization", "\n", "preactivation", "=", "self", ".", "preactivation", "\n", "\n", "", "self", ".", "conv1", "=", "ConvolutionalBlock", "(", "\n", "dimensions", ",", "\n", "in_channels", ",", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.ConvBlockBCIN.forward": [[240, 246], ["model_utils.ConvBlockBCIN.conv", "model_utils.ConvBlockBCIN.activation", "model_utils.ConvBlockBCIN.norm"], "methods", ["None"], ["out_channels_first", ",", "\n", "normalization", "=", "normalization", ",", "\n", "preactivation", "=", "preactivation", ",", "\n", "padding", "=", "padding", ",", "\n", "padding_mode", "=", "padding_mode", ",", "\n", "activation", "=", "activation", ",", "\n", "dilation", "=", "dilation", ",", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.ResBlockIN.__init__": [[250, 258], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "activation"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["if", "dimensions", "==", "2", ":", "\n", "            ", "out_channels_second", "=", "out_channels_first", "\n", "", "elif", "dimensions", "==", "3", ":", "\n", "            ", "out_channels_second", "=", "2", "*", "out_channels_first", "\n", "", "self", ".", "conv2", "=", "ConvolutionalBlock", "(", "\n", "dimensions", ",", "\n", "out_channels_first", ",", "\n", "out_channels_second", ",", "\n", "normalization", "=", "self", ".", "normalization", ",", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.ResBlockIN.forward": [[259, 268], ["model_utils.ResBlockIN.conv0", "model_utils.ResBlockIN.norm0", "model_utils.ResBlockIN.activation", "model_utils.ResBlockIN.conv1", "model_utils.ResBlockIN.norm1", "model_utils.ResBlockIN.center_crop"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.ResBlockBCIN.center_crop"], ["preactivation", "=", "self", ".", "preactivation", ",", "\n", "padding", "=", "padding", ",", "\n", "activation", "=", "activation", ",", "\n", "dilation", "=", "dilation", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "\n", "if", "residual", ":", "\n", "            ", "self", ".", "conv_residual", "=", "ConvolutionalBlock", "(", "\n", "dimensions", ",", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.ResBlockIN.center_crop": [[269, 279], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.pad", "torch.pad", "torch.pad", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "pad.tolist", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten"], ["in_channels", ",", "\n", "out_channels_second", ",", "\n", "kernel_size", "=", "1", ",", "\n", "normalization", "=", "None", ",", "\n", "activation", "=", "None", ",", "\n", ")", "\n", "\n", "", "self", ".", "downsample", "=", "None", "\n", "if", "pooling_type", "is", "not", "None", ":", "\n", "            ", "self", ".", "downsample", "=", "get_downsampling_layer", "(", "dimensions", ",", "pooling_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.ResBlockBCIN.__init__": [[283, 293], ["torch.Module.__init__", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "model_utils.BCIN", "model_utils.BCIN", "activation"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "+=", "connection", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "", "if", "self", ".", "downsample", "is", "None", ":", "\n", "            ", "return", "x", "\n", "", "else", ":", "\n", "            ", "skip_connection", "=", "x", "\n", "x", "=", "self", ".", "downsample", "(", "x", ")", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.ResBlockBCIN.forward": [[294, 310], ["model_utils.ResBlockBCIN.conv0", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "model_utils.ResBlockBCIN.norm0", "model_utils.ResBlockBCIN.activation", "model_utils.ResBlockBCIN.conv1", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "model_utils.ResBlockBCIN.norm1", "model_utils.ResBlockBCIN.center_crop"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.ResBlockBCIN.center_crop"], ["return", "x", ",", "skip_connection", "\n", "\n", "", "", "@", "property", "\n", "def", "out_channels", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "conv2", ".", "conv_layer", ".", "out_channels", "\n", "\n", "\n", "", "", "def", "get_downsampling_layer", "(", "\n", "dimensions", ":", "int", ",", "\n", "pooling_type", ":", "str", ",", "\n", "kernel_size", ":", "int", "=", "2", ",", "\n", ")", "->", "nn", ".", "Module", ":", "\n", "    ", "class_name", "=", "'{}Pool{}d'", ".", "format", "(", "pooling_type", ".", "capitalize", "(", ")", ",", "dimensions", ")", "\n", "class_", "=", "getattr", "(", "nn", ",", "class_name", ")", "\n", "return", "class_", "(", "kernel_size", ")", "\n", "\n", "", "class", "DecodingBlock", "(", "nn", ".", "Module", ")", ":", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.ResBlockBCIN.center_crop": [[311, 321], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.pad", "torch.pad", "torch.pad", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "torch.stack().t().flatten", "pad.tolist", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack().t", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels_skip_connection", ":", "int", ",", "\n", "dimensions", ":", "int", ",", "\n", "upsampling_type", ":", "str", ",", "\n", "normalization", ":", "Optional", "[", "str", "]", ",", "\n", "preactivation", ":", "bool", "=", "True", ",", "\n", "residual", ":", "bool", "=", "False", ",", "\n", "padding", ":", "int", "=", "0", ",", "\n", "padding_mode", ":", "str", "=", "'zeros'", ",", "\n", "activation", ":", "Optional", "[", "str", "]", "=", "'ReLU'", ",", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.BCIN.__init__": [[327, 342], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.InstanceNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "print", "print"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["self", ".", "residual", "=", "residual", "\n", "\n", "if", "upsampling_type", "==", "'conv'", ":", "\n", "            ", "in_channels", "=", "out_channels", "=", "2", "*", "in_channels_skip_connection", "\n", "self", ".", "upsample", "=", "get_conv_transpose_layer", "(", "\n", "dimensions", ",", "in_channels", ",", "out_channels", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "upsample", "=", "get_upsampling_layer", "(", "upsampling_type", ")", "\n", "", "in_channels_first", "=", "in_channels_skip_connection", "*", "(", "1", "+", "2", ")", "\n", "out_channels", "=", "in_channels_skip_connection", "\n", "self", ".", "conv1", "=", "ConvolutionalBlock", "(", "\n", "dimensions", ",", "\n", "in_channels_first", ",", "\n", "out_channels", ",", "\n", "normalization", "=", "normalization", ",", "\n", "preactivation", "=", "preactivation", ",", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.BCIN.forward": [[343, 356], ["torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "model_utils.BCIN.activation", "torch.var", "torch.var", "torch.var", "torch.var", "torch.var", "torch.var", "torch.var", "torch.var", "torch.var", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "model_utils.BCIN.i_norm", "model_utils.BCIN.b_norm"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.mean"], ["padding", "=", "padding", ",", "\n", "padding_mode", "=", "padding_mode", ",", "\n", "activation", "=", "activation", ",", "\n", "dilation", "=", "dilation", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "in_channels_second", "=", "out_channels", "\n", "self", ".", "conv2", "=", "ConvolutionalBlock", "(", "\n", "dimensions", ",", "\n", "in_channels_second", ",", "\n", "out_channels", ",", "\n", "normalization", "=", "normalization", ",", "\n", "preactivation", "=", "preactivation", ",", "\n", "padding", "=", "padding", ",", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.model_utils.MultiInSequential.forward": [[361, 365], ["model_utils.MultiInSequential._modules.values", "module"], "methods", ["None"], [")", "\n", "\n", "if", "residual", ":", "\n", "            ", "self", ".", "conv_residual", "=", "ConvolutionalBlock", "(", "\n", "dimensions", ",", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.__init__": [[10, 53], ["mp.models.model.Model.__init__", "UNet2D_dis", "EncoderStyle", "DiscriminatorDomain", "DiscriminatorContent", "Generator", "LatentScaler"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "\n", "input_shape", "=", "(", "1", ",", "256", ",", "256", ")", ",", "\n", "nr_labels", "=", "2", ",", "\n", "domain_code_size", "=", "10", ",", "\n", "latent_scaler_sample_size", "=", "250", ",", "\n", "unet_dropout", "=", "0", ",", "\n", "unet_monte_carlo_dropout", "=", "0", ",", "\n", "unet_preactivation", "=", "False", "\n", ")", ":", "\n", "        ", "r\"\"\"Constructor\n        \n        Args:\n            input_shape (tuple of int): input shape of the images\n            nr_labels (int): number of labels for the segmentation\n            domain_code_size (int): size of domain code vector\n            latent_scaler_sample_size (int): number of samples to be used to generate latent scale\n            unet_dropout (float): dropout probability for the U-Net\n            unet_monte_carlo_dropout (float): monte carlo dropout probability for the U-Net\n            unet_preactivation (boolean): whether to use U-Net pre-activations\n        \"\"\"", "\n", "super", "(", "ACS", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_shape", "=", "input_shape", "\n", "self", ".", "latent_scaler_sample_size", "=", "latent_scaler_sample_size", "\n", "self", ".", "domain_code_size", "=", "domain_code_size", "\n", "\n", "# UNet -> segmentor and content encoder", "\n", "self", ".", "nr_labels", "=", "nr_labels", "\n", "self", ".", "unet", "=", "UNet2D_dis", "(", "self", ".", "input_shape", ",", "self", ".", "nr_labels", ",", "dropout", "=", "unet_dropout", ",", "monte_carlo_dropout", "=", "unet_monte_carlo_dropout", ",", "preactivation", "=", "unet_preactivation", ")", "\n", "self", ".", "enc_con_out_dim", "=", "self", ".", "unet", ".", "bottom_block", ".", "out_channels", "\n", "\n", "# encoder", "\n", "self", ".", "enc_sty", "=", "EncoderStyle", "(", "in_channels", "=", "self", ".", "input_shape", "[", "0", "]", ")", "\n", "\n", "# discriminator", "\n", "self", ".", "dis_dom", "=", "DiscriminatorDomain", "(", "in_channels", "=", "self", ".", "input_shape", "[", "0", "]", ",", "domain_code_size", "=", "self", ".", "domain_code_size", ",", "max_channels", "=", "256", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "self", ".", "dis_con", "=", "DiscriminatorContent", "(", "in_channels", "=", "self", ".", "input_shape", "[", "0", "]", ",", "domain_code_size", "=", "self", ".", "domain_code_size", ",", "max_channels", "=", "256", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "\n", "# generator", "\n", "self", ".", "gen", "=", "Generator", "(", "in_channels", "=", "self", ".", "enc_con_out_dim", ",", "out_channels", "=", "self", ".", "input_shape", "[", "0", "]", ",", "domain_code_size", "=", "self", ".", "domain_code_size", ")", "\n", "\n", "# latent scaler", "\n", "self", ".", "latent_scaler", "=", "LatentScaler", "(", "in_features", "=", "self", ".", "latent_scaler_sample_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.set_data_parallel": [[54, 72], ["nn.DataParallel", "nn.DataParallel", "nn.DataParallel", "nn.DataParallel", "nn.DataParallel", "nn.DataParallel", "nn.DataParallel", "nn.DataParallel", "nn.DataParallel", "nn.DataParallel"], "methods", ["None"], ["", "def", "set_data_parallel", "(", "self", ",", "device_ids", ")", ":", "\n", "        ", "r\"\"\"Wrap each module in data parallel structure\n\n        Args:\n            device_ids (list): device ids of the GPUs\n        \"\"\"", "\n", "self", ".", "unet", ".", "encoder", "=", "nn", ".", "DataParallel", "(", "self", ".", "unet", ".", "encoder", ",", "device_ids", ")", "\n", "self", ".", "unet", ".", "bottom_block", "=", "nn", ".", "DataParallel", "(", "self", ".", "unet", ".", "bottom_block", ",", "device_ids", ")", "\n", "self", ".", "unet", ".", "decoder", "=", "nn", ".", "DataParallel", "(", "self", ".", "unet", ".", "decoder", ",", "device_ids", ")", "\n", "self", ".", "unet", ".", "classifier", "=", "nn", ".", "DataParallel", "(", "self", ".", "unet", ".", "classifier", ",", "device_ids", ")", "\n", "if", "self", ".", "unet", ".", "monte_carlo_layer", "is", "not", "None", ":", "\n", "            ", "self", ".", "unet", ".", "monte_carlo_layer", "=", "nn", ".", "DataParallel", "(", "self", ".", "unet", ".", "monte_carlo_layer", ",", "device_ids", ")", "\n", "\n", "", "self", ".", "enc_sty", "=", "nn", ".", "DataParallel", "(", "self", ".", "enc_sty", ",", "device_ids", ")", "\n", "self", ".", "dis_con", "=", "nn", ".", "DataParallel", "(", "self", ".", "dis_con", ",", "device_ids", ")", "\n", "self", ".", "dis_dom", "=", "nn", ".", "DataParallel", "(", "self", ".", "dis_dom", ",", "device_ids", ")", "\n", "self", ".", "gen", "=", "nn", ".", "DataParallel", "(", "self", ".", "gen", ",", "device_ids", ")", "\n", "self", ".", "latent_scaler", "=", "nn", ".", "DataParallel", "(", "self", ".", "latent_scaler", ",", "device_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.set_optimizers": [[73, 90], ["optimizer", "optimizer", "optimizer", "optimizer", "optimizer", "optimizer", "optimizer", "optimizer", "acs.ACS.enc_sty.parameters", "acs.ACS.dis_con.parameters", "acs.ACS.dis_dom.parameters", "acs.ACS.gen.parameters", "acs.ACS.latent_scaler.parameters", "acs.ACS.unet.parameters", "acs.ACS.unet.decoder.parameters", "acs.ACS.unet.classifier.parameters"], "methods", ["None"], ["", "def", "set_optimizers", "(", "self", ",", "optimizer", "=", "optim", ".", "Adam", ",", "lr", "=", "1e-4", ")", ":", "\n", "        ", "r\"\"\"Set optimizers for all modules\n        \n        Args:\n            optimizer (torch.nn.optim): optimizer to use\n            lr (float): learning rate to use\n        \"\"\"", "\n", "self", ".", "enc_sty_optim", "=", "optimizer", "(", "self", ".", "enc_sty", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "self", ".", "dis_con_optim", "=", "optimizer", "(", "self", ".", "dis_con", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "self", ".", "dis_dom_optim", "=", "optimizer", "(", "self", ".", "dis_dom", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "self", ".", "gen_optim", "=", "optimizer", "(", "self", ".", "gen", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "\n", "self", ".", "ls_optim", "=", "optimizer", "(", "self", ".", "latent_scaler", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "\n", "self", ".", "unet_optim", "=", "optimizer", "(", "self", ".", "unet", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "self", ".", "unet_decoder_optim", "=", "optimizer", "(", "self", ".", "unet", ".", "decoder", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "self", ".", "unet_classifier_optim", "=", "optimizer", "(", "self", ".", "unet", ".", "classifier", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.step_optim_disc": [[91, 95], ["acs.ACS.dis_con_optim.step", "acs.ACS.dis_dom_optim.step"], "methods", ["None"], ["", "def", "step_optim_disc", "(", "self", ")", ":", "\n", "        ", "r\"\"\"Step discriminator optimizers\"\"\"", "\n", "self", ".", "dis_con_optim", ".", "step", "(", ")", "\n", "self", ".", "dis_dom_optim", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.step_optim_enc_misc": [[96, 101], ["acs.ACS.enc_sty_optim.step", "acs.ACS.gen_optim.step", "acs.ACS.unet_optim.step"], "methods", ["None"], ["", "def", "step_optim_enc_misc", "(", "self", ")", ":", "\n", "        ", "r\"\"\"Step encoder and misc. optimizers\"\"\"", "\n", "self", ".", "enc_sty_optim", ".", "step", "(", ")", "\n", "self", ".", "gen_optim", ".", "step", "(", ")", "\n", "self", ".", "unet_optim", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.zero_grad_optim_enc_misc": [[102, 107], ["acs.ACS.enc_sty_optim.zero_grad", "acs.ACS.gen_optim.zero_grad", "acs.ACS.unet_optim.zero_grad"], "methods", ["None"], ["", "def", "zero_grad_optim_enc_misc", "(", "self", ")", ":", "\n", "        ", "\"\"\"Zero grad encoder and misc. optimizers\"\"\"", "\n", "self", ".", "enc_sty_optim", ".", "zero_grad", "(", ")", "\n", "self", ".", "gen_optim", ".", "zero_grad", "(", ")", "\n", "self", ".", "unet_optim", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.zero_grad_optim_disc": [[108, 112], ["acs.ACS.dis_con_optim.zero_grad", "acs.ACS.dis_dom_optim.zero_grad"], "methods", ["None"], ["", "def", "zero_grad_optim_disc", "(", "self", ")", ":", "\n", "        ", "\"\"\"Zero grad discriminator optimizers\"\"\"", "\n", "self", ".", "dis_con_optim", ".", "zero_grad", "(", ")", "\n", "self", ".", "dis_dom_optim", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward": [[113, 125], ["acs.ACS.forward_enc", "acs.ACS.forward_dec"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_enc", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_dec"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "r\"\"\"Full forward pass (segmentation)\n        \n        Args:\n            x (torch.Tensor): input batch\n        \n        Returns:\n            (torch.Tensor): segmentated batch\n        \"\"\"", "\n", "skip_connections", ",", "content", ",", "style_sample", "=", "self", ".", "forward_enc", "(", "x", ")", "\n", "x_seg", "=", "self", ".", "forward_dec", "(", "skip_connections", ",", "content", ")", "\n", "return", "x_seg", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_enc": [[126, 153], ["acs.ACS.unet.forward_enc", "acs.ACS.enc_sty", "torch.autograd.Variable", "torch.randn", "eps.to.to.to", "len", "style_mu_var[].get_device", "torch.exp"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_enc", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to"], ["", "def", "forward_enc", "(", "self", ",", "x", ",", "sample_size", "=", "0", ")", ":", "\n", "        ", "r\"\"\"Forward encoding structure\n        \n        Args:\n            x (torch.Tensor): input batch\n            sample_size (int): how many samples to draw for the latent scale\n        Returns:\n            (torch.Tensor): skip connections of the U-Net\n            (torch.Tensor): content encoding\n            (torch.Tensor): style sample\n        \"\"\"", "\n", "\n", "# if no sample size is selected, use latent_scaler_sample_size", "\n", "if", "sample_size", "<=", "0", ":", "\n", "            ", "sample_size", "=", "self", ".", "latent_scaler_sample_size", "\n", "\n", "", "skip_connections", ",", "content", "=", "self", ".", "unet", ".", "forward_enc", "(", "x", ")", "\n", "\n", "# forward style encoder and sample from distribution", "\n", "style_mu_var", "=", "self", ".", "enc_sty", "(", "x", ")", "\n", "eps", "=", "Variable", "(", "torch", ".", "randn", "(", "len", "(", "style_mu_var", "[", "0", "]", ")", ",", "sample_size", ")", ")", "\n", "if", "style_mu_var", "[", "0", "]", ".", "is_cuda", ":", "\n", "            ", "eps", "=", "eps", ".", "to", "(", "style_mu_var", "[", "0", "]", ".", "get_device", "(", ")", ")", "\n", "\n", "", "style_sample", "=", "style_mu_var", "[", "0", "]", "+", "torch", ".", "exp", "(", "style_mu_var", "[", "1", "]", "/", "2", ")", "*", "eps", "\n", "\n", "return", "skip_connections", ",", "content", ",", "style_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_style_enc": [[154, 164], ["acs.ACS.enc_sty"], "methods", ["None"], ["", "def", "forward_style_enc", "(", "self", ",", "x", ")", ":", "\n", "        ", "r\"\"\"Forward style encoder\n        \n        Args:\n            x (torch.Tensor): input batch\n        \n        Returns:\n            (torch.Tensor): style encoding [mu, log_var]\n        \"\"\"", "\n", "return", "self", ".", "enc_sty", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_dec": [[165, 176], ["acs.ACS.unet.forward_dec"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_dec"], ["", "def", "forward_dec", "(", "self", ",", "skip_connections", ",", "content", ")", ":", "\n", "        ", "r\"\"\"Forward U-Net decoder\n        \n        Args:\n            skip_connections (torch.Tensor): skip_connections of the U-Net\n            content (torch.Tensor): content encoding\n\n        Returns:\n            (torch.Tensor): segmentation\n        \"\"\"", "\n", "return", "self", ".", "unet", ".", "forward_dec", "(", "skip_connections", ",", "content", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_gen": [[177, 189], ["acs.ACS.gen.forward"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.classification.small_cnn.SmallCNN.forward"], ["", "def", "forward_gen", "(", "self", ",", "content", ",", "latent_scale", ",", "domain_code", ")", ":", "\n", "        ", "r\"\"\"Forward generator\n        \n        Args:\n            content (torch.Tensor): content encoding\n            latent_scale (torch.Tensor): latentscale\n            domain_code (torch.Tensor): domain code\n\n        Returns:\n            (torch.Tensor): generated image\n        \"\"\"", "\n", "return", "self", ".", "gen", ".", "forward", "(", "content", ",", "latent_scale", ",", "domain_code", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_dom_dis": [[190, 202], ["acs.ACS.dis_dom"], "methods", ["None"], ["", "def", "forward_dom_dis", "(", "self", ",", "x", ",", "domain_code", ")", ":", "\n", "        ", "r\"\"\"Forward domain discriminator\n        \n        Args:\n            x (torch.Tensor): input batch\n            domain_code (torch.Tensor): domain code\n\n        Returns:\n            (torch.Tensor): decision if domain is present\n        \"\"\"", "\n", "x", "=", "self", ".", "dis_dom", "(", "x", ",", "domain_code", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.forward_con_dis": [[203, 215], ["acs.ACS.dis_con"], "methods", ["None"], ["", "def", "forward_con_dis", "(", "self", ",", "skip_connections_x", ",", "x", ")", ":", "\n", "        ", "r\"\"\"Forward content discriminator\n        \n        Args:\n            skip_connections_x (torch.Tensor): skip connections of the U-Net\n            x (torch.Tensor): input batch\n\n        Returns:\n            (torch.Tensor): decision if content is present\n        \"\"\"", "\n", "x", "=", "self", ".", "dis_con", "(", "skip_connections_x", ",", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.acs.ACS.sample_z": [[216, 219], ["torch.rand"], "methods", ["None"], ["", "def", "sample_z", "(", "self", ",", "shape", ")", ":", "\n", "        ", "r\"\"\"Sample from normal distribution\"\"\"", "\n", "return", "torch", ".", "rand", "(", "shape", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.mas.MAS.__init__": [[9, 41], ["mp.models.model.Model.__init__", "mp.models.segmentation.unet_fepegar.UNet2D", "sum", "p.numel", "mas.MAS.unet.parameters"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.eval.accumulator.Accumulator.sum"], ["def", "__init__", "(", "self", ",", "\n", "input_shape", "=", "(", "1", ",", "256", ",", "256", ")", ",", "\n", "nr_labels", "=", "2", ",", "\n", "unet_dropout", "=", "0", ",", "\n", "unet_monte_carlo_dropout", "=", "0", ",", "\n", "unet_preactivation", "=", "False", "\n", ")", ":", "\n", "        ", "r\"\"\"Constructor\n        \n        Args:\n            input_shape (tuple of int): input shape of the images\n            nr_labels (int): number of labels for the segmentation\n            unet_dropout (float): dropout probability for the U-Net\n            unet_monte_carlo_dropout (float): monte carlo dropout probability for the U-Net\n            unet_preactivation (boolean): whether to use U-Net pre-activations\n        \"\"\"", "\n", "super", "(", "MAS", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_shape", "=", "input_shape", "\n", "self", ".", "nr_labels", "=", "nr_labels", "\n", "\n", "self", ".", "unet_dropout", "=", "unet_dropout", "\n", "self", ".", "unet_monte_carlo_dropout", "=", "unet_monte_carlo_dropout", "\n", "self", ".", "unet_preactivation", "=", "unet_preactivation", "\n", "\n", "self", ".", "unet", "=", "UNet2D", "(", "self", ".", "input_shape", ",", "self", ".", "nr_labels", ",", "dropout", "=", "self", ".", "unet_dropout", ",", "monte_carlo_dropout", "=", "self", ".", "unet_monte_carlo_dropout", ",", "preactivation", "=", "self", ".", "unet_preactivation", ")", "\n", "self", ".", "unet_old", "=", "None", "\n", "\n", "self", ".", "importance_weights", "=", "None", "\n", "self", ".", "tasks", "=", "0", "\n", "\n", "self", ".", "n_params_unet", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "unet", ".", "parameters", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.mas.MAS.forward": [[43, 53], ["mas.MAS.unet"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "r\"\"\"Forward pass of current U-Net\n        \n        Args:\n            x (torch.Tensor): input batch\n        \n        Returns:\n            (torch.Tensor): segmentated batch\n        \"\"\"", "\n", "return", "self", ".", "unet", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.mas.MAS.freeze_unet": [[54, 66], ["unet.parameters"], "methods", ["None"], ["", "def", "freeze_unet", "(", "self", ",", "unet", ")", ":", "\n", "        ", "r\"\"\"Freeze U-Net\n        \n        Args:\n            unet (nn.Module): U-Net\n        \n        Returns:\n            (nn.Module): U-Net with frozen weights\n        \"\"\"", "\n", "for", "param", "in", "unet", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "return", "unet", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.mas.MAS.freeze_decoder": [[67, 81], ["unet.decoder.parameters", "unet.classifier.parameters"], "methods", ["None"], ["", "def", "freeze_decoder", "(", "self", ",", "unet", ")", ":", "\n", "        ", "r\"\"\"Freeze U-Net decoder\n        \n        Args:\n            unet (nn.Module): U-Net\n        \n        Returns:\n            (nn.Module): U-Net with frozen decoder weights\n        \"\"\"", "\n", "for", "param", "in", "unet", ".", "decoder", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "for", "param", "in", "unet", ".", "classifier", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "return", "unet", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.mas.MAS.set_optimizers": [[82, 94], ["optimizer", "optimizer", "mas.MAS.unet.parameters", "mas.MAS.unet.parameters"], "methods", ["None"], ["", "def", "set_optimizers", "(", "self", ",", "optimizer", "=", "optim", ".", "SGD", ",", "lr", "=", "1e-4", ",", "weight_decay", "=", "1e-4", ")", ":", "\n", "        ", "r\"\"\"Set optimizers for all modules\n        \n        Args:\n            optimizer (torch.nn.optim): optimizer to use\n            lr (float): learning rate to use\n            weight_decay (float): weight decay\n        \"\"\"", "\n", "if", "optimizer", "==", "optim", ".", "SGD", ":", "\n", "            ", "self", ".", "unet_optim", "=", "optimizer", "(", "self", ".", "unet", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "weight_decay", "=", "weight_decay", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "unet_optim", "=", "optimizer", "(", "self", ".", "unet", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.mas.MAS.update_importance_weights": [[95, 108], ["range", "len"], "methods", ["None"], ["", "", "def", "update_importance_weights", "(", "self", ",", "importance_weights", ")", ":", "\n", "        ", "r\"\"\"Update importance weights w/ computed ones\n\n        Args:\n            (torch.Tensor or list): importance_weights\n        \"\"\"", "\n", "if", "self", ".", "importance_weights", "==", "None", ":", "\n", "            ", "self", ".", "importance_weights", "=", "importance_weights", "\n", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "importance_weights", ")", ")", ":", "\n", "                ", "self", ".", "importance_weights", "[", "i", "]", "-=", "self", ".", "importance_weights", "[", "i", "]", "/", "self", ".", "tasks", "\n", "self", ".", "importance_weights", "[", "i", "]", "+=", "importance_weights", "[", "i", "]", "/", "self", ".", "tasks", "\n", "", "", "self", ".", "tasks", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.mas.MAS.finish": [[109, 121], ["mas.MAS.unet.state_dict", "mp.models.segmentation.unet_fepegar.UNet2D", "mas.MAS.unet_old.load_state_dict", "mas.MAS.freeze_unet", "mas.MAS.unet_old.to", "next", "mas.MAS.unet.parameters", "next", "mas.MAS.unet.parameters"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.continual.mas.MAS.freeze_unet", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to"], ["", "def", "finish", "(", "self", ")", ":", "\n", "        ", "r\"\"\"Finish training, store current U-Net as old U-Net\n        \"\"\"", "\n", "unet_new_state_dict", "=", "self", ".", "unet", ".", "state_dict", "(", ")", "\n", "if", "next", "(", "self", ".", "unet", ".", "parameters", "(", ")", ")", ".", "is_cuda", ":", "\n", "            ", "device", "=", "next", "(", "self", ".", "unet", ".", "parameters", "(", ")", ")", ".", "device", "\n", "\n", "", "self", ".", "unet_old", "=", "UNet2D", "(", "self", ".", "input_shape", ",", "self", ".", "nr_labels", ",", "dropout", "=", "self", ".", "unet_dropout", ",", "monte_carlo_dropout", "=", "self", ".", "unet_monte_carlo_dropout", ",", "preactivation", "=", "self", ".", "unet_preactivation", ")", "\n", "self", ".", "unet_old", ".", "load_state_dict", "(", "unet_new_state_dict", ")", "\n", "self", ".", "unet_old", "=", "self", ".", "freeze_unet", "(", "self", ".", "unet_old", ")", "\n", "\n", "self", ".", "unet_old", ".", "to", "(", "device", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_cnn.AutoencoderCNN.__init__": [[12, 28], ["mp.models.autoencoding.autoencoder.Autoencoder.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "input_shape", ",", "hidden_ch", "=", "[", "16", ",", "4", "]", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "input_shape", "=", "input_shape", ")", "\n", "in_channels", "=", "self", ".", "input_shape", "[", "0", "]", "\n", "\n", "# Encoder layers", "\n", "self", ".", "enc_conv1", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "hidden_ch", "[", "0", "]", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "enc_conv2", "=", "nn", ".", "Conv2d", "(", "hidden_ch", "[", "0", "]", ",", "hidden_ch", "[", "1", "]", ",", "\n", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "enc_pool", "=", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", "\n", "\n", "# Decoder layers", "\n", "self", ".", "dec_conv1", "=", "nn", ".", "ConvTranspose2d", "(", "hidden_ch", "[", "1", "]", ",", "hidden_ch", "[", "0", "]", ",", "\n", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", "\n", "self", ".", "dec_conv2", "=", "nn", ".", "ConvTranspose2d", "(", "hidden_ch", "[", "0", "]", ",", "in_channels", ",", "\n", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_cnn.AutoencoderCNN.encode": [[29, 35], ["torch.relu", "torch.relu", "autoencoder_cnn.AutoencoderCNN.enc_pool", "torch.relu", "torch.relu", "autoencoder_cnn.AutoencoderCNN.enc_pool", "autoencoder_cnn.AutoencoderCNN.enc_conv1", "autoencoder_cnn.AutoencoderCNN.enc_conv2"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "enc_conv1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "enc_pool", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "enc_conv2", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "enc_pool", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_cnn.AutoencoderCNN.decode": [[36, 40], ["torch.relu", "torch.relu", "torch.sigmoid", "torch.sigmoid", "autoencoder_cnn.AutoencoderCNN.dec_conv1", "autoencoder_cnn.AutoencoderCNN.dec_conv2"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "dec_conv1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "sigmoid", "(", "self", ".", "dec_conv2", "(", "x", ")", ")", "# Input should be normed to [0, 1]", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.__init__": [[14, 23], ["mp.models.autoencoding.autoencoder_linear.AutoencoderLinear.__init__", "autoencoder_featured.AutoencoderFeatured.get_feature_extractor"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.get_feature_extractor"], ["def", "__init__", "(", "self", ",", "input_shape", ",", "hidden_dim", "=", "[", "128", ",", "64", "]", ",", "\n", "feature_model_name", "=", "'AlexNet'", ")", ":", "\n", "\n", "        ", "extractor_size", "=", "(", "3", ",", "224", ",", "224", ")", "# For AlexNet, TODO clean up and others", "\n", "features_size", "=", "9216", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "input_shape", "=", "[", "features_size", "]", ",", "hidden_dim", "=", "hidden_dim", ")", "\n", "self", ".", "extractor_size", "=", "extractor_size", "\n", "self", ".", "feature_extractor", "=", "self", ".", "get_feature_extractor", "(", "feature_model_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.preprocess_input": [[24, 34], ["mp.data.pytorch.transformation.torchvision_rescaling", "autoencoder_featured.AutoencoderFeatured.feature_extractor.features", "autoencoder_featured.AutoencoderFeatured.feature_extractor.avgpool", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.pytorch.transformation.torchvision_rescaling", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten"], ["", "def", "preprocess_input", "(", "self", ",", "x", ")", ":", "\n", "        ", "r\"\"\"Preprocessing that is done to the input before performing the \n        autoencoding, which is to say also to the target.\"\"\"", "\n", "# Instead of doing a forward pass, we exclude the classifier", "\n", "# See https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py", "\n", "x", "=", "torchvision_rescaling", "(", "x", ",", "size", "=", "self", ".", "extractor_size", ",", "resize", "=", "False", ")", "\n", "x", "=", "self", ".", "feature_extractor", ".", "features", "(", "x", ")", "\n", "x", "=", "self", ".", "feature_extractor", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "start_dim", "=", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.get_feature_extractor": [[35, 45], ["torchvision.alexnet.parameters", "torchvision.alexnet"], "methods", ["None"], ["", "def", "get_feature_extractor", "(", "self", ",", "model_name", "=", "'AlexNet'", ")", ":", "\n", "        ", "r\"\"\"Features are extracted from the input data. These are normalized \n        with the ImageNet statistics.\"\"\"", "\n", "# Fetch pretrained model", "\n", "if", "model_name", "==", "'AlexNet'", ":", "# input_size = 224 x 224", "\n", "            ", "feature_extractor", "=", "models", ".", "alexnet", "(", "pretrained", "=", "True", ")", "\n", "# Freeze pretrained parameters", "\n", "", "for", "param", "in", "feature_extractor", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "return", "feature_extractor", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to": [[46, 49], ["super().to", "autoencoder_featured.AutoencoderFeatured.feature_extractor.to"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_featured.AutoencoderFeatured.to"], ["", "def", "to", "(", "self", ",", "device", ")", ":", "\n", "        ", "super", "(", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "feature_extractor", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder.Autoencoder.__init__": [[13, 16], ["mp.models.model.Model.__init__"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "input_shape", ")", ":", "\n", "# An autoencoder has the same input and output shapes", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "input_shape", ",", "output_shape", "=", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder.Autoencoder.encode": [[17, 20], ["None"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "x", ")", ":", "\n", "        ", "r\"\"\"Encode the input.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder.Autoencoder.decode": [[21, 24], ["None"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "x", ")", ":", "\n", "        ", "r\"\"\"Decode the features into an output.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder.Autoencoder.forward": [[25, 31], ["autoencoder.Autoencoder.encode", "autoencoder.Autoencoder.decode"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_linear.AutoencoderLinear.encode", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_linear.AutoencoderLinear.decode"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "initial_shape", "=", "x", ".", "shape", "\n", "x", "=", "self", ".", "encode", "(", "x", ")", "\n", "x", "=", "self", ".", "decode", "(", "x", ")", "\n", "assert", "x", ".", "shape", "==", "initial_shape", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_linear.AutoencoderLinear.__init__": [[14, 26], ["mp.models.autoencoding.autoencoder.Autoencoder.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "functools.reduce", "len", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "range", "reversed", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "input_shape", ",", "hidden_dim", "=", "[", "128", ",", "64", "]", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "input_shape", "=", "input_shape", ")", "\n", "in_dim", "=", "self", ".", "input_shape", "[", "0", "]", "if", "len", "(", "self", ".", "input_shape", ")", "<", "2", "else", "reduce", "(", "lambda", "x", ",", "y", ":", "x", "*", "y", ",", "self", ".", "input_shape", ")", "\n", "dims", "=", "[", "in_dim", "]", "+", "hidden_dim", "\n", "\n", "# Encoder layers", "\n", "self", ".", "enc_layers", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Linear", "(", "in_features", "=", "dims", "[", "i", "]", ",", "out_features", "=", "dims", "[", "i", "+", "1", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "dims", ")", "-", "1", ")", "]", ")", "\n", "\n", "# Decoder layers", "\n", "self", ".", "dec_layers", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Linear", "(", "in_features", "=", "dims", "[", "i", "+", "1", "]", ",", "out_features", "=", "dims", "[", "i", "]", ")", "\n", "for", "i", "in", "reversed", "(", "range", "(", "len", "(", "dims", ")", "-", "1", ")", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_linear.AutoencoderLinear.preprocess_input": [[27, 30], ["torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten", "home.repos.pwc.inspect_result.MECLabTUDA_ACS.models.model.Model.flatten"], ["", "def", "preprocess_input", "(", "self", ",", "x", ")", ":", "\n", "        ", "r\"\"\"Flatten x into one dimension.\"\"\"", "\n", "return", "torch", ".", "flatten", "(", "x", ",", "start_dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_linear.AutoencoderLinear.encode": [[31, 35], ["torch.relu", "torch.relu", "torch.relu", "layer"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "enc_layers", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "layer", "(", "x", ")", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.autoencoding.autoencoder_linear.AutoencoderLinear.decode": [[36, 40], ["torch.relu", "torch.relu", "torch.relu", "layer"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "dec_layers", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "layer", "(", "x", ")", ")", "\n", "", "return", "x", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.classification.small_cnn.SmallCNN.__init__": [[11, 19], ["mp.models.model.Model.__init__", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__"], ["def", "__init__", "(", "self", ",", "input_shape", "=", "(", "3", ",", "32", ",", "32", ")", ",", "output_shape", "=", "10", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "input_shape", ",", "output_shape", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "6", ",", "5", ")", "\n", "self", ".", "pool", "=", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "6", ",", "16", ",", "5", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "16", "*", "5", "*", "5", ",", "120", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "120", ",", "84", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "84", ",", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.classification.small_cnn.SmallCNN.forward": [[20, 28], ["small_cnn.SmallCNN.pool", "small_cnn.SmallCNN.pool", "small_cnn.SmallCNN.view", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "small_cnn.SmallCNN.fc3", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "small_cnn.SmallCNN.fc1", "small_cnn.SmallCNN.fc2", "small_cnn.SmallCNN.conv1", "small_cnn.SmallCNN.conv2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "pool", "(", "F", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "x", "=", "self", ".", "pool", "(", "F", ".", "relu", "(", "self", ".", "conv2", "(", "x", ")", ")", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "16", "*", "5", "*", "5", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc2", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "fc3", "(", "x", ")", "\n", "return", "x", "", "", "", ""]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.__init__": [[9, 13], ["dict"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "datasets", "=", "dict", "(", ")", "\n", "self", ".", "label_names", "=", "None", "\n", "self", ".", "nr_labels", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.MECLabTUDA_ACS.data.data.Data.add_dataset": [[14, 29], ["len", "data.Data.datasets.values"], "methods", ["None"], ["", "def", "add_dataset", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "r\"\"\"Saves the dataset with its name as key.\n        \n        Args:\n            dataset (mp.data.datasets.dataset.Dataset): a Dataset object\n\n        \"\"\"", "\n", "assert", "dataset", ".", "name", "not", "in", "self", ".", "datasets", "\n", "if", "len", "(", "self", ".", "datasets", ")", ">", "0", ":", "\n", "            ", "for", "other_dataset", "in", "self", ".", "datasets", ".", "values", "(", ")", ":", "\n", "                ", "assert", "dataset", ".", "label_names", "==", "other_dataset", ".", "label_names", ",", "'Datasets must have the same label names'", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "label_names", "=", "dataset", ".", "label_names", "\n", "self", ".", "nr_labels", "=", "dataset", ".", "nr_labels", "\n", "", "self", ".", "datasets", "[", "dataset", ".", "name", "]", "=", "dataset", "", "", "", ""]]}