{"home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.opts.parse_opt": [[6, 195], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "print", "os.path.join", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "os.path.join", "os.path.exists"], "function", ["None"], ["def", "parse_opt", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--id'", ",", "type", "=", "str", ",", "default", "=", "'test'", ",", "\n", "help", "=", "'an id identifying this run/job. used in cross-val and appended when writing progress files'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpus'", ",", "type", "=", "str", ",", "default", "=", "'0'", ",", "help", "=", "'set CUDA_VISIBLE_DEVICES'", ")", "\n", "# Data input settings", "\n", "parser", ".", "add_argument", "(", "'--input_json'", ",", "type", "=", "str", ",", "default", "=", "'data/cocotalk.json'", ",", "\n", "help", "=", "'path to the json file containing additional info and vocab'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_fc_dir'", ",", "type", "=", "str", ",", "default", "=", "'data/cocobu_fc'", ",", "\n", "help", "=", "'path to the directory containing the preprocessed fc feats'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_att_dir'", ",", "type", "=", "str", ",", "default", "=", "'data/cocobu_att'", ",", "\n", "help", "=", "'path to the directory containing the preprocessed att feats'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_label_h5'", ",", "type", "=", "str", ",", "default", "=", "'data/cocotalk_label.h5'", ",", "\n", "help", "=", "'path to the h5file containing the preprocessed dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--train_only'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'if true then use 80k, else use 110k'", ")", "\n", "parser", ".", "add_argument", "(", "'--cached_tokens'", ",", "type", "=", "str", ",", "default", "=", "'coco-train-idxs'", ",", "\n", "help", "=", "'Cached token file for calculating cider score during self critical training.'", ")", "\n", "parser", ".", "add_argument", "(", "'--loader_num_workers'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "\n", "help", "=", "'num of processes to use for BlobFetcher'", ")", "\n", "\n", "\n", "# load model and settings", "\n", "parser", ".", "add_argument", "(", "'--resume_from'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"continuing training from this experiment id\"", ")", "\n", "parser", ".", "add_argument", "(", "'--resume_from_best'", ",", "type", "=", "str2bool", ",", "default", "=", "False", ",", "\n", "help", "=", "'resume from best model, True: use best_model.pth, False: use model.pth'", ")", "\n", "parser", ".", "add_argument", "(", "'--load_best_score'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Do we load previous best score when resuming training.'", ")", "\n", "\n", "# Model settings", "\n", "parser", ".", "add_argument", "(", "'--caption_model'", ",", "type", "=", "str", ",", "default", "=", "\"vsua\"", ",", "\n", "help", "=", "'model type: [vsua]'", ")", "\n", "parser", ".", "add_argument", "(", "'--rnn_size'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "\n", "help", "=", "'size of the rnn in number of hidden nodes in each layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'number of layers in the RNN'", ")", "\n", "parser", ".", "add_argument", "(", "'--rnn_type'", ",", "type", "=", "str", ",", "default", "=", "'lstm'", ",", "\n", "help", "=", "'rnn, gru, or lstm'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_encoding_size'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "\n", "help", "=", "'the encoding size of each token in the vocabulary, and the image.'", ")", "\n", "parser", ".", "add_argument", "(", "'--att_hid_size'", ",", "type", "=", "int", ",", "default", "=", "512", ",", "\n", "help", "=", "'the hidden size of the attention MLP; only useful in show_attend_tell; 0 if not using hidden layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--fc_feat_size'", ",", "type", "=", "int", ",", "default", "=", "2048", ",", "\n", "help", "=", "'2048 for resnet, 4096 for vgg'", ")", "\n", "parser", ".", "add_argument", "(", "'--att_feat_size'", ",", "type", "=", "int", ",", "default", "=", "2048", ",", "\n", "help", "=", "'2048 for resnet, 512 for vgg'", ")", "\n", "parser", ".", "add_argument", "(", "'--logit_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'number of layers in the RNN'", ")", "\n", "\n", "\n", "# feature manipulation", "\n", "parser", ".", "add_argument", "(", "'--norm_att_feat'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'If normalize attention features'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_box'", ",", "type", "=", "str2bool", ",", "default", "=", "False", ",", "\n", "help", "=", "'If use box features'", ")", "\n", "parser", ".", "add_argument", "(", "'--norm_box_feat'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'If use box, do we normalize box feature'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_bn'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'If 1, then do batch_normalization first in att_embed, if 2 then do bn both in the beginning and the end of att_embed'", ")", "\n", "\n", "# Optimization: General", "\n", "parser", ".", "add_argument", "(", "'--max_epochs'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "'number of epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "'minibatch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--grad_clip'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "#5.,", "\n", "help", "=", "'clip gradients at this value'", ")", "\n", "parser", ".", "add_argument", "(", "'--drop_prob_lm'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "'strength of dropout in the Language Model RNN'", ")", "\n", "parser", ".", "add_argument", "(", "'--self_critical_after'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'After what epoch do we start finetuning the CNN? (-1 = disable; never finetune, 0 = finetune from start)'", ")", "\n", "parser", ".", "add_argument", "(", "'--seq_per_img'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "'number of captions to sample for each image during training. Done for efficiency since CNN forward pass is expensive. E.g. coco has 5 sents/image'", ")", "\n", "parser", ".", "add_argument", "(", "'--beam_size'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'used when sample_max = 1, indicates number of beams in beam search. Usually 2 or 3 works well. More is not better. Set this to 1 for faster runtime but a bit worse performance.'", ")", "\n", "\n", "# Optimization: for the Language Model", "\n", "parser", ".", "add_argument", "(", "'--optim'", ",", "type", "=", "str", ",", "default", "=", "'adam'", ",", "\n", "help", "=", "'what update to use? rmsprop|sgd|sgdmom|adagrad|adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--optim_alpha'", ",", "type", "=", "float", ",", "default", "=", "0.9", ",", "\n", "help", "=", "'alpha for adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--optim_beta'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "\n", "help", "=", "'beta used for adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--optim_epsilon'", ",", "type", "=", "float", ",", "default", "=", "1e-8", ",", "\n", "help", "=", "'epsilon that goes into denominator for smoothing'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight_decay'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "'weight_decay'", ")", "\n", "\n", "# learning rate", "\n", "parser", ".", "add_argument", "(", "'--learning_rate'", ",", "type", "=", "float", ",", "default", "=", "3e-4", ",", "\n", "help", "=", "'learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate_decay_start'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'at what epoch to start decaying learning rate? (-1 = dont)'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate_decay_every'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "'every how many iterations thereafter to drop LR?(in epoch)'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate_decay_rate'", ",", "type", "=", "float", ",", "default", "=", "0.8", ",", "\n", "help", "=", "'every how many iterations thereafter to drop LR?(in epoch)'", ")", "\n", "\n", "# scheduled sampling", "\n", "parser", ".", "add_argument", "(", "'--scheduled_sampling_start'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'at what iteration to start decay gt probability'", ")", "\n", "parser", ".", "add_argument", "(", "'--scheduled_sampling_increase_every'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "'every how many iterations thereafter to gt probability'", ")", "\n", "parser", ".", "add_argument", "(", "'--scheduled_sampling_increase_prob'", ",", "type", "=", "float", ",", "default", "=", "0.05", ",", "\n", "help", "=", "'How much to update the prob'", ")", "\n", "parser", ".", "add_argument", "(", "'--scheduled_sampling_max_prob'", ",", "type", "=", "float", ",", "default", "=", "0.25", ",", "\n", "help", "=", "'Maximum scheduled sampling prob.'", ")", "\n", "\n", "\n", "# Evaluation/Checkpointing", "\n", "parser", ".", "add_argument", "(", "'--val_images_use'", ",", "type", "=", "int", ",", "default", "=", "5000", ",", "\n", "help", "=", "'how many images to use when periodically evaluating the validation loss? (-1 = all)'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_checkpoint_every'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'how often to save a model checkpoint (in iterations)? (-1 = every epoch)'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint_root'", ",", "type", "=", "str", ",", "default", "=", "'log'", ",", "\n", "help", "=", "'root directory to store checkpointed models'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint_path'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'directory to store current checkpoint, \\\n                         if not set, it will be assigned as (args.checkpoint_root, args.id) by default. '", ")", "\n", "parser", ".", "add_argument", "(", "'--language_eval'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Evaluate language as well (1 = yes, 0 = no)? BLEU/CIDEr/METEOR/ROUGE_L/SPICE? requires coco-caption code from Github.'", ")", "\n", "parser", ".", "add_argument", "(", "'--log_loss_every'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "'How often do we snapshot losses, for inclusion in the progress dump? (0 = disable)'", ")", "\n", "\n", "# Reward", "\n", "parser", ".", "add_argument", "(", "'--cider_reward_weight'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "\n", "help", "=", "'The reward weight from cider'", ")", "\n", "parser", ".", "add_argument", "(", "'--bleu_reward_weight'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "'The reward weight from bleu4'", ")", "\n", "\n", "\n", "# VSUA related inputs", "\n", "parser", ".", "add_argument", "(", "'--sg_vocab_path'", ",", "type", "=", "str", ",", "default", "=", "'data/coco_pred_sg_rela.npy'", ",", "\n", "help", "=", "'path to the vocab file, containing vocabularies of object, attribute, relationships'", ")", "\n", "parser", ".", "add_argument", "(", "'--sg_data_dir'", ",", "type", "=", "str", ",", "default", "=", "'data/coco_img_sg/'", ",", "\n", "help", "=", "'path to the scene graph data directory, containing numpy files about the '", "\n", "'labels of object, attribute, and semantic relationships for each image'", ")", "\n", "parser", ".", "add_argument", "(", "'--sg_geometry_dir'", ",", "type", "=", "str", ",", "default", "=", "'data/geometry-iou0.2-dist0.5-undirected/'", ",", "\n", "help", "=", "'directory of geometry edges and features'", ")", "\n", "parser", ".", "add_argument", "(", "'--sg_box_info_path'", ",", "type", "=", "str", ",", "default", "=", "'data/vsua_box_info.pkl'", ",", "\n", "help", "=", "'path to the pickle file containing the width and height infos of images'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_obj_label_use'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'number of object labels to use'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_attr_label_use'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "'number of attribute labels to use'", ")", "\n", "parser", ".", "add_argument", "(", "'--geometry_rela_feat_dim'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "'dim of geometry relationship features'", ")", "\n", "\n", "\n", "# VSUA model settings", "\n", "parser", ".", "add_argument", "(", "'--vsua_use'", ",", "type", "=", "str", ",", "default", "=", "'oar'", ",", "\n", "help", "=", "'which types of visual semantic units to contain, o: obj, a: attr, r: rela'", ")", "\n", "parser", ".", "add_argument", "(", "'--geometry_relation'", ",", "type", "=", "str2bool", ",", "default", "=", "True", ",", "\n", "help", "=", "'type of relationship to use, True: geometry relationship, False: semantic relationship'", ")", "\n", "parser", ".", "add_argument", "(", "'--rela_gnn_type'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'rela gcn type'", ")", "\n", "parser", ".", "add_argument", "(", "'--sg_label_embed_size'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "\n", "help", "=", "'graph embedding_size of obj, attr, rela'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "checkpoint_path", "==", "''", ":", "\n", "        ", "args", ".", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint_root", ",", "args", ".", "id", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "checkpoint_root", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "args", ".", "checkpoint_root", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "checkpoint_path", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "args", ".", "checkpoint_path", ")", "\n", "\n", "", "if", "args", ".", "resume_from", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint_root", ",", "args", ".", "resume_from", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "path", ")", ",", "\"%s not exists\"", "%", "args", ".", "resume_from", "\n", "\n", "", "os", ".", "environ", "[", "\"CUDA_VISIBLE_DEVICES\"", "]", "=", "args", ".", "gpus", "\n", "print", "(", "\"[INFO] set CUDA_VISIBLE_DEVICES = %s\"", "%", "args", ".", "gpus", ")", "\n", "\n", "# Check if args are valid", "\n", "assert", "args", ".", "rnn_size", ">", "0", ",", "\"rnn_size should be greater than 0\"", "\n", "assert", "args", ".", "num_layers", ">", "0", ",", "\"num_layers should be greater than 0\"", "\n", "assert", "args", ".", "input_encoding_size", ">", "0", ",", "\"input_encoding_size should be greater than 0\"", "\n", "assert", "args", ".", "batch_size", ">", "0", ",", "\"batch_size should be greater than 0\"", "\n", "assert", "args", ".", "drop_prob_lm", ">=", "0", "and", "args", ".", "drop_prob_lm", "<", "1", ",", "\"drop_prob_lm should be between 0 and 1\"", "\n", "assert", "args", ".", "seq_per_img", ">", "0", ",", "\"seq_per_img should be greater than 0\"", "\n", "assert", "args", ".", "beam_size", ">", "0", ",", "\"beam_size should be greater than 0\"", "\n", "assert", "args", ".", "language_eval", "==", "0", "or", "args", ".", "language_eval", "==", "1", ",", "\"language_eval should be 0 or 1\"", "\n", "assert", "args", ".", "load_best_score", "==", "0", "or", "args", ".", "load_best_score", "==", "1", ",", "\"language_eval should be 0 or 1\"", "\n", "assert", "args", ".", "train_only", "==", "0", "or", "args", ".", "train_only", "==", "1", ",", "\"language_eval should be 0 or 1\"", "\n", "\n", "return", "args", "\n", "", ""]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.train.train": [[17, 150], ["misc.if_use_att", "misc.if_use_fc", "dataloader.DataLoader", "utils.load_save.load_info", "utils.load_save.load_info.get", "utils.load_save.load_info.get", "utils.load_save.load_info.get", "utils.load_save.load_info.get", "utils.load_save.load_info.get", "models.setup().train().cuda", "misc.LanguageModelCriterion().cuda", "misc.RewardCriterion().cuda", "misc.build_optimizer", "utils.load_save.save_nets_structure", "utils.load_save.load_checkpoint", "utils.load_save.load_info.get", "setup().train().cuda.parameters", "dataloader.DataLoader.get_batch", "torch.cuda.synchronize", "utils.build_optimizer.zero_grad", "rl_crit.backward", "misc.clip_gradient", "utils.build_optimizer.step", "rl_crit.item", "torch.cuda.synchronize", "models.setup().train", "misc.LanguageModelCriterion", "misc.RewardCriterion", "misc.set_lr", "setup().train().cuda.", "utils.LanguageModelCriterion().cuda.", "setup().train().cuda.", "train..", "utils.RewardCriterion().cuda.", "logger.info", "tb.add_values", "eval_kwargs.update", "eval_utils.eval_split", "dataloader.DataLoader.get_vocab", "utils.load_save.save_checkpoint", "min", "misc.rewards_graph.init_scorer", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().float().cuda", "vars", "logger.info", "tb.add_values", "models.setup", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().float", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.if_use_att", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.if_use_fc", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.utils.load_save.load_info", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.build_optimizer", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.utils.load_save.save_nets_structure", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.utils.load_save.load_checkpoint", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.get_batch", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.clip_gradient", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.train.train", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.set_lr", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.utils.logger.MyTensorboard.add_values", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.eval_utils.eval_split", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.get_vocab", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.utils.load_save.save_checkpoint", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.rewards_graph.init_scorer", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.utils.logger.MyTensorboard.add_values", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.__init__.setup"], ["def", "train", "(", "opt", ")", ":", "\n", "# Deal with feature things before anything", "\n", "    ", "opt", ".", "use_att", "=", "utils", ".", "if_use_att", "(", "opt", ".", "caption_model", ")", "\n", "opt", ".", "use_fc", "=", "utils", ".", "if_use_fc", "(", "opt", ".", "caption_model", ")", "\n", "\n", "loader", "=", "DataLoader", "(", "opt", ")", "\n", "opt", ".", "vocab_size", "=", "loader", ".", "vocab_size", "\n", "opt", ".", "seq_length", "=", "loader", ".", "seq_length", "\n", "\n", "\n", "infos", "=", "load_info", "(", "opt", ")", "\n", "iteration", "=", "infos", ".", "get", "(", "'iter'", ",", "0", ")", "\n", "epoch", "=", "infos", ".", "get", "(", "'epoch'", ",", "0", ")", "\n", "val_result_history", "=", "infos", ".", "get", "(", "'val_result_history'", ",", "{", "}", ")", "\n", "\n", "loader", ".", "iterators", "=", "infos", ".", "get", "(", "'iterators'", ",", "loader", ".", "iterators", ")", "\n", "loader", ".", "split_ix", "=", "infos", ".", "get", "(", "'split_ix'", ",", "loader", ".", "split_ix", ")", "\n", "\n", "if", "opt", ".", "load_best_score", "==", "1", ":", "\n", "        ", "best_val_score", "=", "infos", ".", "get", "(", "'best_val_score'", ",", "None", ")", "\n", "\n", "# Define and load model, optimizer, critics", "\n", "", "decoder", "=", "setup", "(", "opt", ")", ".", "train", "(", ")", ".", "cuda", "(", ")", "\n", "crit", "=", "utils", ".", "LanguageModelCriterion", "(", ")", ".", "cuda", "(", ")", "\n", "rl_crit", "=", "utils", ".", "RewardCriterion", "(", ")", ".", "cuda", "(", ")", "\n", "optimizer", "=", "utils", ".", "build_optimizer", "(", "decoder", ".", "parameters", "(", ")", ",", "opt", ")", "\n", "models", "=", "{", "'decoder'", ":", "decoder", "}", "\n", "optimizers", "=", "{", "'decoder'", ":", "optimizer", "}", "\n", "save_nets_structure", "(", "models", ",", "opt", ")", "\n", "load_checkpoint", "(", "models", ",", "optimizers", ",", "opt", ")", "\n", "\n", "\n", "epoch_done", "=", "True", "\n", "sc_flag", "=", "False", "\n", "while", "True", ":", "\n", "        ", "if", "epoch_done", ":", "\n", "# Assign the learning rate", "\n", "            ", "if", "epoch", ">", "opt", ".", "learning_rate_decay_start", "and", "opt", ".", "learning_rate_decay_start", ">=", "0", ":", "\n", "                ", "frac", "=", "(", "epoch", "-", "opt", ".", "learning_rate_decay_start", ")", "//", "opt", ".", "learning_rate_decay_every", "\n", "decay_factor", "=", "opt", ".", "learning_rate_decay_rate", "**", "frac", "\n", "opt", ".", "current_lr", "=", "opt", ".", "learning_rate", "*", "decay_factor", "\n", "", "else", ":", "\n", "                ", "opt", ".", "current_lr", "=", "opt", ".", "learning_rate", "\n", "", "utils", ".", "set_lr", "(", "optimizer", ",", "opt", ".", "current_lr", ")", "\n", "# Assign the scheduled sampling prob", "\n", "if", "epoch", ">", "opt", ".", "scheduled_sampling_start", "and", "opt", ".", "scheduled_sampling_start", ">=", "0", ":", "\n", "                ", "frac", "=", "(", "epoch", "-", "opt", ".", "scheduled_sampling_start", ")", "//", "opt", ".", "scheduled_sampling_increase_every", "\n", "opt", ".", "ss_prob", "=", "min", "(", "opt", ".", "scheduled_sampling_increase_prob", "*", "frac", ",", "opt", ".", "scheduled_sampling_max_prob", ")", "\n", "decoder", ".", "ss_prob", "=", "opt", ".", "ss_prob", "\n", "\n", "# If start self critical training", "\n", "", "if", "opt", ".", "self_critical_after", "!=", "-", "1", "and", "epoch", ">=", "opt", ".", "self_critical_after", ":", "\n", "                ", "sc_flag", "=", "True", "\n", "init_scorer", "(", "opt", ".", "cached_tokens", ")", "\n", "", "else", ":", "\n", "                ", "sc_flag", "=", "False", "\n", "", "epoch_done", "=", "False", "\n", "\n", "# 1. fetch a batch of data from train split", "\n", "", "data", "=", "loader", ".", "get_batch", "(", "'train'", ")", "\n", "tmp", "=", "[", "data", "[", "'fc_feats'", "]", ",", "data", "[", "'att_feats'", "]", ",", "data", "[", "'labels'", "]", ",", "data", "[", "'masks'", "]", ",", "data", "[", "'att_masks'", "]", "]", "\n", "tmp", "=", "[", "_", "if", "_", "is", "None", "else", "torch", ".", "from_numpy", "(", "_", ")", ".", "cuda", "(", ")", "for", "_", "in", "tmp", "]", "\n", "fc_feats", ",", "att_feats", ",", "labels", ",", "masks", ",", "att_masks", "=", "tmp", "\n", "sg_data", "=", "{", "key", ":", "data", "[", "'sg_data'", "]", "[", "key", "]", "if", "data", "[", "'sg_data'", "]", "[", "key", "]", "is", "None", "else", "torch", ".", "from_numpy", "(", "data", "[", "'sg_data'", "]", "[", "key", "]", ")", ".", "cuda", "(", ")", "for", "key", "in", "data", "[", "'sg_data'", "]", "}", "\n", "\n", "# 2. Forward model and compute loss", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "if", "not", "sc_flag", ":", "\n", "            ", "out", "=", "decoder", "(", "sg_data", ",", "fc_feats", ",", "att_feats", ",", "labels", ",", "att_masks", ")", "\n", "loss", "=", "crit", "(", "out", ",", "labels", "[", ":", ",", "1", ":", "]", ",", "masks", "[", ":", ",", "1", ":", "]", ")", "\n", "", "else", ":", "\n", "            ", "gen_result", ",", "sample_logprobs", ",", "core_args", "=", "decoder", "(", "sg_data", ",", "fc_feats", ",", "att_feats", ",", "att_masks", ",", "opt", "=", "{", "'sample_max'", ":", "0", ",", "'return_core_args'", ":", "True", "}", ",", "mode", "=", "'sample'", ")", "\n", "reward", "=", "get_self_critical_reward", "(", "decoder", ",", "core_args", ",", "sg_data", ",", "fc_feats", ",", "att_feats", ",", "att_masks", ",", "data", ",", "gen_result", ",", "opt", ")", "\n", "loss", "=", "rl_crit", "(", "sample_logprobs", ",", "gen_result", ".", "data", ",", "torch", ".", "from_numpy", "(", "reward", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "# 3. Update model", "\n", "", "loss", ".", "backward", "(", ")", "\n", "utils", ".", "clip_gradient", "(", "optimizer", ",", "opt", ".", "grad_clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "train_loss", "=", "loss", ".", "item", "(", ")", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "\n", "# Update the iteration and epoch", "\n", "iteration", "+=", "1", "\n", "# Write the training loss summary", "\n", "if", "(", "iteration", "%", "opt", ".", "log_loss_every", "==", "0", ")", ":", "\n", "# logging log", "\n", "            ", "logger", ".", "info", "(", "\"{} ({}), loss: {:.3f}\"", ".", "format", "(", "iteration", ",", "epoch", ",", "train_loss", ")", ")", "\n", "tb", ".", "add_values", "(", "'loss'", ",", "{", "'train'", ":", "train_loss", "}", ",", "iteration", ")", "\n", "\n", "", "if", "data", "[", "'bounds'", "]", "[", "'wrapped'", "]", ":", "\n", "            ", "epoch", "+=", "1", "\n", "epoch_done", "=", "True", "\n", "\n", "# Make evaluation and save checkpoint", "\n", "", "if", "(", "opt", ".", "save_checkpoint_every", ">", "0", "and", "iteration", "%", "opt", ".", "save_checkpoint_every", "==", "0", ")", "or", "(", "opt", ".", "save_checkpoint_every", "==", "-", "1", "and", "epoch_done", ")", ":", "\n", "# eval model", "\n", "            ", "eval_kwargs", "=", "{", "'split'", ":", "'val'", ",", "\n", "'dataset'", ":", "opt", ".", "input_json", ",", "\n", "'expand_features'", ":", "False", "}", "\n", "eval_kwargs", ".", "update", "(", "vars", "(", "opt", ")", ")", "\n", "predictions", ",", "lang_stats", "=", "eval_utils", ".", "eval_split", "(", "decoder", ",", "loader", ",", "eval_kwargs", ")", "\n", "# log val results", "\n", "if", "not", "lang_stats", "is", "None", ":", "\n", "                ", "logger", ".", "info", "(", "\"Scores: {}\"", ".", "format", "(", "lang_stats", ")", ")", "\n", "tb", ".", "add_values", "(", "'scores'", ",", "lang_stats", ",", "epoch", ")", "\n", "", "val_result_history", "[", "epoch", "]", "=", "{", "'lang_stats'", ":", "lang_stats", ",", "'predictions'", ":", "predictions", "}", "\n", "\n", "# Save model if is improving on validation result", "\n", "current_score", "=", "0", "if", "lang_stats", "is", "None", "else", "lang_stats", "[", "'CIDEr'", "]", "\n", "best_flag", "=", "False", "\n", "if", "best_val_score", "is", "None", "or", "current_score", ">", "best_val_score", ":", "\n", "                ", "best_val_score", "=", "current_score", "\n", "best_flag", "=", "True", "\n", "\n", "# Dump miscalleous informations", "\n", "", "infos", "[", "'iter'", "]", "=", "iteration", "\n", "infos", "[", "'epoch'", "]", "=", "epoch", "\n", "infos", "[", "'iterators'", "]", "=", "loader", ".", "iterators", "\n", "infos", "[", "'split_ix'", "]", "=", "loader", ".", "split_ix", "\n", "infos", "[", "'best_val_score'", "]", "=", "best_val_score", "\n", "infos", "[", "'opt'", "]", "=", "opt", "\n", "infos", "[", "'vocab'", "]", "=", "loader", ".", "get_vocab", "(", ")", "\n", "infos", "[", "'val_result_history'", "]", "=", "val_result_history", "\n", "\n", "save_checkpoint", "(", "models", ",", "optimizers", ",", "\n", "infos", ",", "best_flag", ",", "opt", ")", "\n", "\n", "# Stop if reaching max epochs", "\n", "", "if", "epoch", ">", "opt", ".", "max_epochs", "and", "opt", ".", "max_epochs", "!=", "-", "1", ":", "\n", "            ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.eval_utils.language_eval": [[10, 46], ["sys.path.append", "os.path.join", "COCO", "COCO.getImgIds", "print", "json.dump", "COCO.loadRes", "COCOEvalCap", "coco.loadRes.getImgIds", "COCOEvalCap.evaluate", "COCOEvalCap.eval.items", "os.path.isdir", "os.mkdir", "open", "open", "json.dump", "len", "len"], "function", ["None"], ["def", "language_eval", "(", "preds", ",", "model_id", ",", "split", ")", ":", "\n", "    ", "import", "sys", "\n", "sys", ".", "path", ".", "append", "(", "\"coco-caption\"", ")", "\n", "annFile", "=", "'coco-caption/annotations/captions_val2014.json'", "\n", "from", "pycocotools", ".", "coco", "import", "COCO", "\n", "from", "pycocoevalcap", ".", "eval", "import", "COCOEvalCap", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "'eval_results'", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "'eval_results'", ")", "\n", "", "cache_path", "=", "os", ".", "path", ".", "join", "(", "'eval_results/'", ",", "model_id", "+", "'_'", "+", "split", "+", "'.json'", ")", "\n", "\n", "coco", "=", "COCO", "(", "annFile", ")", "\n", "valids", "=", "coco", ".", "getImgIds", "(", ")", "\n", "\n", "# filter results to only those in MSCOCO validation set (will be about a third)", "\n", "preds_filt", "=", "[", "p", "for", "p", "in", "preds", "if", "p", "[", "'image_id'", "]", "in", "valids", "]", "\n", "print", "(", "'using %d/%d predictions'", "%", "(", "len", "(", "preds_filt", ")", ",", "len", "(", "preds", ")", ")", ")", "\n", "json", ".", "dump", "(", "preds_filt", ",", "open", "(", "cache_path", ",", "'w'", ")", ")", "# serialize to temporary json file. Sigh, COCO API...", "\n", "\n", "cocoRes", "=", "coco", ".", "loadRes", "(", "cache_path", ")", "\n", "cocoEval", "=", "COCOEvalCap", "(", "coco", ",", "cocoRes", ")", "\n", "cocoEval", ".", "params", "[", "'image_id'", "]", "=", "cocoRes", ".", "getImgIds", "(", ")", "\n", "cocoEval", ".", "evaluate", "(", ")", "\n", "\n", "# create output dictionary", "\n", "out", "=", "{", "}", "\n", "for", "metric", ",", "score", "in", "cocoEval", ".", "eval", ".", "items", "(", ")", ":", "\n", "        ", "out", "[", "metric", "]", "=", "score", "\n", "\n", "", "imgToEval", "=", "cocoEval", ".", "imgToEval", "\n", "for", "p", "in", "preds_filt", ":", "\n", "        ", "image_id", ",", "caption", "=", "p", "[", "'image_id'", "]", ",", "p", "[", "'caption'", "]", "\n", "imgToEval", "[", "image_id", "]", "[", "'caption'", "]", "=", "caption", "\n", "", "with", "open", "(", "cache_path", ",", "'w'", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "'overall'", ":", "out", ",", "'imgToEval'", ":", "imgToEval", "}", ",", "outfile", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.eval_utils.eval_split": [[48, 118], ["eval_kwargs.get", "eval_kwargs.get", "eval_kwargs.get", "eval_kwargs.get", "eval_kwargs.get", "eval_kwargs.get", "model.eval", "loader.reset_iterator", "model.train", "eval_kwargs.get", "loader.get_batch", "misc.decode_sequence", "enumerate", "range", "eval_utils.language_eval", "torch.no_grad", "range", "loader.get_vocab", "predictions.append", "min", "predictions.pop", "print", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "print", "print", "eval_kwargs.get", "eval_kwargs.get", "print", "os.system", "print", "model", "torch.from_numpy", "torch.from_numpy", "str", "len", "len", "misc.decode_sequence", "os.path.join", "loader.get_vocab", "_[].unsqueeze"], "function", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.reset_iterator", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.train.train", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.get_batch", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.decode_sequence", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.eval_utils.language_eval", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.get_vocab", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.decode_sequence", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.get_vocab"], ["", "def", "eval_split", "(", "model", ",", "loader", ",", "eval_kwargs", "=", "{", "}", ")", ":", "\n", "    ", "verbose", "=", "eval_kwargs", ".", "get", "(", "'verbose'", ",", "True", ")", "\n", "verbose_beam", "=", "eval_kwargs", ".", "get", "(", "'verbose_beam'", ",", "1", ")", "\n", "num_images", "=", "eval_kwargs", ".", "get", "(", "'num_images'", ",", "eval_kwargs", ".", "get", "(", "'val_images_use'", ",", "-", "1", ")", ")", "\n", "split", "=", "eval_kwargs", ".", "get", "(", "'split'", ",", "'val'", ")", "\n", "lang_eval", "=", "eval_kwargs", ".", "get", "(", "'language_eval'", ",", "0", ")", "\n", "beam_size", "=", "eval_kwargs", ".", "get", "(", "'beam_size'", ",", "1", ")", "\n", "\n", "# Make sure in the evaluation mode", "\n", "model", ".", "eval", "(", ")", "\n", "loader", ".", "reset_iterator", "(", "split", ")", "\n", "\n", "n", "=", "0", "\n", "predictions", "=", "[", "]", "\n", "while", "True", ":", "\n", "        ", "data", "=", "loader", ".", "get_batch", "(", "split", ")", "\n", "n", "=", "n", "+", "loader", ".", "batch_size", "\n", "\n", "# forward the model to get generated samples for each image", "\n", "tmp", "=", "[", "data", "[", "'fc_feats'", "]", ",", "data", "[", "'att_feats'", "]", ",", "data", "[", "'att_masks'", "]", "]", "\n", "tmp", "=", "[", "_", "if", "_", "is", "None", "else", "torch", ".", "from_numpy", "(", "_", ")", ".", "cuda", "(", ")", "for", "_", "in", "tmp", "]", "\n", "fc_feats", ",", "att_feats", ",", "att_masks", "=", "tmp", "\n", "sg_data", "=", "{", "key", ":", "data", "[", "'sg_data'", "]", "[", "key", "]", "if", "data", "[", "'sg_data'", "]", "[", "key", "]", "is", "None", "else", "torch", ".", "from_numpy", "(", "data", "[", "'sg_data'", "]", "[", "key", "]", ")", ".", "cuda", "(", ")", "for", "key", "in", "data", "[", "'sg_data'", "]", "}", "\n", "\n", "# forward the model to also get generated samples for each image", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "seq", "=", "model", "(", "sg_data", ",", "fc_feats", ",", "att_feats", ",", "att_masks", ",", "opt", "=", "eval_kwargs", ",", "mode", "=", "'sample'", ")", "[", "0", "]", ".", "data", "\n", "# Print beam search", "\n", "", "if", "beam_size", ">", "1", "and", "verbose_beam", ":", "\n", "            ", "for", "i", "in", "range", "(", "loader", ".", "batch_size", ")", ":", "\n", "                ", "print", "(", "'\\n'", ".", "join", "(", "[", "utils", ".", "decode_sequence", "(", "loader", ".", "get_vocab", "(", ")", ",", "_", "[", "'seq'", "]", ".", "unsqueeze", "(", "0", ")", ")", "[", "0", "]", "for", "_", "in", "model", ".", "done_beams", "[", "i", "]", "]", ")", ")", "\n", "print", "(", "'--'", "*", "10", ")", "\n", "", "", "sents", "=", "utils", ".", "decode_sequence", "(", "loader", ".", "get_vocab", "(", ")", ",", "seq", ")", "\n", "\n", "for", "k", ",", "sent", "in", "enumerate", "(", "sents", ")", ":", "\n", "            ", "entry", "=", "{", "'image_id'", ":", "data", "[", "'infos'", "]", "[", "k", "]", "[", "'id'", "]", ",", "'caption'", ":", "sent", "}", "\n", "if", "eval_kwargs", ".", "get", "(", "'dump_path'", ",", "0", ")", "==", "1", ":", "\n", "                ", "entry", "[", "'file_name'", "]", "=", "data", "[", "'infos'", "]", "[", "k", "]", "[", "'file_path'", "]", "\n", "", "predictions", ".", "append", "(", "entry", ")", "\n", "if", "eval_kwargs", ".", "get", "(", "'dump_images'", ",", "0", ")", "==", "1", ":", "\n", "# dump the raw image to vis/ folder", "\n", "                ", "cmd", "=", "'cp \"'", "+", "os", ".", "path", ".", "join", "(", "eval_kwargs", "[", "'image_root'", "]", ",", "data", "[", "'infos'", "]", "[", "k", "]", "[", "'file_path'", "]", ")", "+", "'\" vis/imgs/img'", "+", "str", "(", "len", "(", "predictions", ")", ")", "+", "'.jpg'", "# bit gross", "\n", "print", "(", "cmd", ")", "\n", "os", ".", "system", "(", "cmd", ")", "\n", "", "if", "verbose", "and", "k", "%", "20", "==", "0", ":", "\n", "                ", "print", "(", "'image %s: %s'", "%", "(", "entry", "[", "'image_id'", "]", ",", "entry", "[", "'caption'", "]", ")", ")", "\n", "\n", "# if we wrapped around the split or used up val imgs budget then bail", "\n", "", "", "ix0", "=", "data", "[", "'bounds'", "]", "[", "'it_pos_now'", "]", "\n", "ix1", "=", "data", "[", "'bounds'", "]", "[", "'it_max'", "]", "\n", "if", "num_images", "!=", "-", "1", ":", "\n", "            ", "ix1", "=", "min", "(", "ix1", ",", "num_images", ")", "\n", "", "for", "i", "in", "range", "(", "n", "-", "ix1", ")", ":", "\n", "            ", "predictions", ".", "pop", "(", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", "'evaluating validation preformance... %d/%d'", "%", "(", "len", "(", "predictions", ")", ",", "ix1", ")", ")", "\n", "\n", "", "if", "data", "[", "'bounds'", "]", "[", "'wrapped'", "]", ":", "\n", "            ", "break", "\n", "", "if", "num_images", ">=", "0", "and", "n", ">=", "num_images", ":", "\n", "            ", "break", "\n", "\n", "", "", "lang_stats", "=", "None", "\n", "if", "lang_eval", "==", "1", ":", "\n", "        ", "lang_stats", "=", "language_eval", "(", "predictions", ",", "eval_kwargs", "[", "'id'", "]", ",", "split", ")", "\n", "\n", "# Switch back to training mode", "\n", "", "model", ".", "train", "(", ")", "\n", "return", "predictions", ",", "lang_stats", "\n", "", ""]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.reset_iterator": [[17, 21], ["dataloader.BlobFetcher"], "methods", ["None"], ["    ", "def", "reset_iterator", "(", "self", ",", "split", ")", ":", "\n", "        ", "del", "self", ".", "_prefetch_process", "[", "split", "]", "\n", "self", ".", "_prefetch_process", "[", "split", "]", "=", "BlobFetcher", "(", "split", ",", "self", ",", "split", "==", "'train'", ",", "self", ".", "opt", ".", "loader_num_workers", ",", "self", ".", "opt", ")", "\n", "self", ".", "iterators", "[", "split", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.get_vocab_size": [[22, 24], ["None"], "methods", ["None"], ["", "def", "get_vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "vocab_size", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.get_vocab": [[25, 27], ["None"], "methods", ["None"], ["", "def", "get_vocab", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "ix_to_word", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.get_seq_length": [[28, 30], ["None"], "methods", ["None"], ["", "def", "get_seq_length", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "seq_length", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.__init__": [[31, 108], ["logging.getLogger", "getattr", "getattr", "getattr", "getattr", "getattr", "dataloader.DataLoader.logger.info", "json.load", "len", "dataloader.DataLoader.logger.info", "print", "h5py.File", "dataloader.DataLoader.logger.info", "dataloader.DataLoader.logger.info", "range", "dataloader.DataLoader.split_ix.keys", "dataloader.DataLoader.iterators.keys", "atexit.register", "numpy.load", "open", "len", "dataloader.DataLoader.logger.info", "dataloader.DataLoader.logger.info", "pickle.load", "dataloader.BlobFetcher", "print", "dataloader.DataLoader.iterators.keys", "dataloader.DataLoader.split_ix[].append", "open", "dataloader.DataLoader.split_ix[].append", "dataloader.DataLoader.split_ix[].append", "len", "dataloader.DataLoader.split_ix[].append"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", "'__main__'", ")", "\n", "self", ".", "batch_size", "=", "self", ".", "opt", ".", "batch_size", "\n", "self", ".", "seq_per_img", "=", "opt", ".", "seq_per_img", "\n", "self", ".", "geometry_relation", "=", "opt", ".", "geometry_relation", "\n", "\n", "# feature related options", "\n", "self", ".", "use_att", "=", "getattr", "(", "opt", ",", "'use_att'", ",", "True", ")", "\n", "self", ".", "use_fc", "=", "getattr", "(", "opt", ",", "'use_fc'", ",", "True", ")", "\n", "self", ".", "use_box", "=", "getattr", "(", "opt", ",", "'use_box'", ",", "0", ")", "\n", "self", ".", "norm_att_feat", "=", "getattr", "(", "opt", ",", "'norm_att_feat'", ",", "0", ")", "\n", "self", ".", "norm_box_feat", "=", "getattr", "(", "opt", ",", "'norm_box_feat'", ",", "0", ")", "\n", "\n", "# data dir", "\n", "self", ".", "input_fc_dir", "=", "self", ".", "opt", ".", "input_fc_dir", "\n", "self", ".", "input_att_dir", "=", "self", ".", "opt", ".", "input_att_dir", "\n", "\n", "# scene graph data", "\n", "self", ".", "sg_data_dir", "=", "opt", ".", "sg_data_dir", "\n", "self", ".", "sg_geometry_dir", "=", "self", ".", "opt", ".", "sg_geometry_dir", "\n", "self", ".", "sg_vocab", "=", "np", ".", "load", "(", "opt", ".", "sg_vocab_path", ")", "[", "(", ")", "]", "\n", "\n", "# load the json file which contains additional information about the dataset", "\n", "self", ".", "logger", ".", "info", "(", "'DataLoader loading json file: %s'", "%", "opt", ".", "input_json", ")", "\n", "self", ".", "info", "=", "json", ".", "load", "(", "open", "(", "self", ".", "opt", ".", "input_json", ")", ")", "\n", "self", ".", "ix_to_word", "=", "self", ".", "info", "[", "'ix_to_word'", "]", "\n", "self", ".", "vocab_size", "=", "len", "(", "self", ".", "ix_to_word", ")", "\n", "self", ".", "logger", ".", "info", "(", "'vocab size is %d'", "%", "self", ".", "vocab_size", ")", "\n", "\n", "# open the hdf5 file", "\n", "print", "(", "'DataLoader loading h5 file: '", ",", "opt", ".", "input_label_h5", ")", "\n", "self", ".", "h5_label_file", "=", "h5py", ".", "File", "(", "self", ".", "opt", ".", "input_label_h5", ",", "'r'", ",", "driver", "=", "'core'", ")", "\n", "\n", "# load in the sequence data", "\n", "seq_size", "=", "self", ".", "h5_label_file", "[", "'labels'", "]", ".", "shape", "\n", "self", ".", "seq_length", "=", "seq_size", "[", "1", "]", "\n", "self", ".", "logger", ".", "info", "(", "'max sequence length in data is %d'", "%", "self", ".", "seq_length", ")", "\n", "# load the pointers in full to RAM (should be small enough)", "\n", "self", ".", "label_start_ix", "=", "self", ".", "h5_label_file", "[", "'label_start_ix'", "]", "[", ":", "]", "\n", "self", ".", "label_end_ix", "=", "self", ".", "h5_label_file", "[", "'label_end_ix'", "]", "[", ":", "]", "\n", "\n", "self", ".", "num_images", "=", "self", ".", "label_start_ix", ".", "shape", "[", "0", "]", "\n", "self", ".", "logger", ".", "info", "(", "'read %d image features'", "%", "(", "self", ".", "num_images", ")", ")", "\n", "\n", "# separate out indexes for each of the provided splits", "\n", "self", ".", "split_ix", "=", "{", "'train'", ":", "[", "]", ",", "'val'", ":", "[", "]", ",", "'test'", ":", "[", "]", "}", "\n", "for", "ix", "in", "range", "(", "len", "(", "self", ".", "info", "[", "'images'", "]", ")", ")", ":", "\n", "            ", "img", "=", "self", ".", "info", "[", "'images'", "]", "[", "ix", "]", "\n", "if", "img", "[", "'split'", "]", "==", "'train'", ":", "\n", "                ", "self", ".", "split_ix", "[", "'train'", "]", ".", "append", "(", "ix", ")", "\n", "", "elif", "img", "[", "'split'", "]", "==", "'val'", ":", "\n", "                ", "self", ".", "split_ix", "[", "'val'", "]", ".", "append", "(", "ix", ")", "\n", "", "elif", "img", "[", "'split'", "]", "==", "'test'", ":", "\n", "                ", "self", ".", "split_ix", "[", "'test'", "]", ".", "append", "(", "ix", ")", "\n", "", "elif", "opt", ".", "train_only", "==", "0", ":", "# restval", "\n", "                ", "self", ".", "split_ix", "[", "'train'", "]", ".", "append", "(", "ix", ")", "\n", "", "", "self", ".", "iterators", "=", "{", "'train'", ":", "0", ",", "'val'", ":", "0", ",", "'test'", ":", "0", "}", "\n", "\n", "for", "split", "in", "self", ".", "split_ix", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "'assigned %d images to split %s'", "%", "(", "len", "(", "self", ".", "split_ix", "[", "split", "]", ")", ",", "split", ")", ")", "\n", "\n", "# load the width and height of images", "\n", "", "if", "self", ".", "use_box", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "'Loading sg_box_info'", ")", "\n", "self", ".", "sg_box_info", "=", "pickle", ".", "load", "(", "open", "(", "opt", ".", "sg_box_info_path", ")", ")", "\n", "\n", "", "self", ".", "_prefetch_process", "=", "{", "}", "# The three prefetch process", "\n", "for", "split", "in", "self", ".", "iterators", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "_prefetch_process", "[", "split", "]", "=", "BlobFetcher", "(", "split", ",", "self", ",", "split", "==", "'train'", ",", "self", ".", "opt", ".", "loader_num_workers", ",", "self", ".", "opt", ")", "\n", "# Terminate the child process when the parent exists", "\n", "", "def", "cleanup", "(", ")", ":", "\n", "            ", "print", "(", "'Terminating BlobFetcher'", ")", "\n", "for", "split", "in", "self", ".", "iterators", ".", "keys", "(", ")", ":", "\n", "                ", "del", "self", ".", "_prefetch_process", "[", "split", "]", "\n", "", "", "import", "atexit", "\n", "atexit", ".", "register", "(", "cleanup", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.get_captions": [[109, 127], ["numpy.zeros", "range", "random.randint", "random.randint"], "methods", ["None"], ["", "def", "get_captions", "(", "self", ",", "ix", ",", "seq_per_img", ")", ":", "\n", "# fetch the sequence labels", "\n", "        ", "ix1", "=", "self", ".", "label_start_ix", "[", "ix", "]", "-", "1", "#label_start_ix starts from 1", "\n", "ix2", "=", "self", ".", "label_end_ix", "[", "ix", "]", "-", "1", "\n", "ncap", "=", "ix2", "-", "ix1", "+", "1", "# number of captions available for this image", "\n", "assert", "ncap", ">", "0", ",", "'an image does not have any label. this can be handled but right now isn\\'t'", "\n", "\n", "if", "ncap", "<", "seq_per_img", ":", "\n", "# we need to subsample (with replacement)", "\n", "            ", "seq", "=", "np", ".", "zeros", "(", "[", "seq_per_img", ",", "self", ".", "seq_length", "]", ",", "dtype", "=", "'int'", ")", "\n", "for", "q", "in", "range", "(", "seq_per_img", ")", ":", "\n", "                ", "ixl", "=", "random", ".", "randint", "(", "ix1", ",", "ix2", ")", "\n", "seq", "[", "q", ",", ":", "]", "=", "self", ".", "h5_label_file", "[", "'labels'", "]", "[", "ixl", ",", ":", "self", ".", "seq_length", "]", "\n", "", "", "else", ":", "\n", "            ", "ixl", "=", "random", ".", "randint", "(", "ix1", ",", "ix2", "-", "seq_per_img", "+", "1", ")", "\n", "seq", "=", "self", ".", "h5_label_file", "[", "'labels'", "]", "[", "ixl", ":", "ixl", "+", "seq_per_img", ",", ":", "self", ".", "seq_length", "]", "\n", "\n", "", "return", "seq", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.get_batch": [[128, 192], ["numpy.zeros", "numpy.zeros", "range", "numpy.stack", "max", "numpy.zeros", "range", "numpy.zeros", "range", "numpy.array", "enumerate", "dataloader.DataLoader.batch_sg", "dataloader.DataLoader._prefetch_process[].get", "fc_batch.append", "att_batch.append", "sg_batch.append", "dataloader.DataLoader.get_captions", "gts.append", "infos.append", "reduce", "len", "len", "list", "len", "len", "map"], "methods", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.batch_sg", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.get_captions"], ["", "def", "get_batch", "(", "self", ",", "split", ",", "batch_size", "=", "None", ",", "seq_per_img", "=", "None", ")", ":", "\n", "        ", "batch_size", "=", "batch_size", "or", "self", ".", "batch_size", "\n", "seq_per_img", "=", "seq_per_img", "or", "self", ".", "seq_per_img", "\n", "\n", "fc_batch", "=", "[", "]", "# np.ndarray((batch_size * seq_per_img, self.opt.fc_feat_size), dtype = 'float32')", "\n", "att_batch", "=", "[", "]", "# np.ndarray((batch_size * seq_per_img, 14, 14, self.opt.att_feat_size), dtype = 'float32')", "\n", "sg_batch", "=", "[", "]", "\n", "label_batch", "=", "np", ".", "zeros", "(", "[", "batch_size", "*", "seq_per_img", ",", "self", ".", "seq_length", "+", "2", "]", ",", "dtype", "=", "'int'", ")", "\n", "mask_batch", "=", "np", ".", "zeros", "(", "[", "batch_size", "*", "seq_per_img", ",", "self", ".", "seq_length", "+", "2", "]", ",", "dtype", "=", "'float32'", ")", "\n", "infos", "=", "[", "]", "\n", "gts", "=", "[", "]", "\n", "wrapped", "=", "False", "\n", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "# fetch image", "\n", "            ", "tmp_fc", ",", "tmp_att", ",", "tmp_sg", ",", "ix", ",", "tmp_wrapped", "=", "self", ".", "_prefetch_process", "[", "split", "]", ".", "get", "(", ")", "\n", "fc_batch", ".", "append", "(", "tmp_fc", ")", "\n", "att_batch", ".", "append", "(", "tmp_att", ")", "\n", "sg_batch", ".", "append", "(", "tmp_sg", ")", "\n", "\n", "label_batch", "[", "i", "*", "seq_per_img", ":", "(", "i", "+", "1", ")", "*", "seq_per_img", ",", "1", ":", "self", ".", "seq_length", "+", "1", "]", "=", "self", ".", "get_captions", "(", "ix", ",", "seq_per_img", ")", "\n", "\n", "if", "tmp_wrapped", ":", "\n", "                ", "wrapped", "=", "True", "\n", "\n", "# Used for reward evaluation", "\n", "", "gts", ".", "append", "(", "self", ".", "h5_label_file", "[", "'labels'", "]", "[", "self", ".", "label_start_ix", "[", "ix", "]", "-", "1", ":", "self", ".", "label_end_ix", "[", "ix", "]", "]", ")", "\n", "\n", "# record associated info as well", "\n", "info_dict", "=", "{", "}", "\n", "info_dict", "[", "'ix'", "]", "=", "ix", "\n", "info_dict", "[", "'id'", "]", "=", "self", ".", "info", "[", "'images'", "]", "[", "ix", "]", "[", "'id'", "]", "\n", "info_dict", "[", "'file_path'", "]", "=", "self", ".", "info", "[", "'images'", "]", "[", "ix", "]", "[", "'file_path'", "]", "\n", "infos", ".", "append", "(", "info_dict", ")", "\n", "\n", "", "data", "=", "{", "}", "\n", "data", "[", "'fc_feats'", "]", "=", "np", ".", "stack", "(", "reduce", "(", "lambda", "x", ",", "y", ":", "x", "+", "y", ",", "[", "[", "_", "]", "*", "1", "for", "_", "in", "fc_batch", "]", ")", ")", "\n", "# merge att_feats", "\n", "max_att_len", "=", "max", "(", "[", "_", ".", "shape", "[", "0", "]", "for", "_", "in", "att_batch", "]", ")", "\n", "data", "[", "'att_feats'", "]", "=", "np", ".", "zeros", "(", "[", "len", "(", "att_batch", ")", ",", "max_att_len", ",", "att_batch", "[", "0", "]", ".", "shape", "[", "1", "]", "]", ",", "dtype", "=", "'float32'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "att_batch", ")", ")", ":", "\n", "            ", "data", "[", "'att_feats'", "]", "[", "i", ",", ":", "att_batch", "[", "i", "]", ".", "shape", "[", "0", "]", "]", "=", "att_batch", "[", "i", "]", "\n", "", "data", "[", "'att_masks'", "]", "=", "np", ".", "zeros", "(", "data", "[", "'att_feats'", "]", ".", "shape", "[", ":", "2", "]", ",", "dtype", "=", "'float32'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "att_batch", ")", ")", ":", "\n", "            ", "data", "[", "'att_masks'", "]", "[", "i", ",", ":", "att_batch", "[", "i", "]", ".", "shape", "[", "0", "]", "]", "=", "1", "\n", "# set att_masks to None if attention features have same length", "\n", "# if data['att_masks'].sum() == data['att_masks'].size:", "\n", "#     data['att_masks'] = None", "\n", "\n", "", "data", "[", "'labels'", "]", "=", "label_batch", "# np.vstack(label_batch)", "\n", "# generate mask", "\n", "nonzeros", "=", "np", ".", "array", "(", "list", "(", "map", "(", "lambda", "x", ":", "(", "x", "!=", "0", ")", ".", "sum", "(", ")", "+", "2", ",", "data", "[", "'labels'", "]", ")", ")", ")", "\n", "for", "ix", ",", "row", "in", "enumerate", "(", "mask_batch", ")", ":", "\n", "            ", "row", "[", ":", "nonzeros", "[", "ix", "]", "]", "=", "1", "\n", "", "data", "[", "'masks'", "]", "=", "mask_batch", "\n", "\n", "data", "[", "'gts'", "]", "=", "gts", "# all ground truth captions of each images", "\n", "data", "[", "'bounds'", "]", "=", "{", "'it_pos_now'", ":", "self", ".", "iterators", "[", "split", "]", ",", "'it_max'", ":", "len", "(", "self", ".", "split_ix", "[", "split", "]", ")", ",", "'wrapped'", ":", "wrapped", "}", "\n", "data", "[", "'infos'", "]", "=", "infos", "\n", "\n", "data", "[", "'sg_data'", "]", "=", "self", ".", "batch_sg", "(", "sg_batch", ",", "max_att_len", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.batch_sg": [[194, 228], ["numpy.zeros", "range", "numpy.zeros", "range", "max", "numpy.zeros", "numpy.zeros", "range", "len", "len", "numpy.zeros", "numpy.zeros", "len", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "batch_sg", "(", "self", ",", "sg_batch", ",", "max_att_len", ")", ":", "\n", "        ", "\"batching object, attribute, and relationship data\"", "\n", "obj_batch", "=", "[", "_", "[", "'obj'", "]", "for", "_", "in", "sg_batch", "]", "\n", "attr_batch", "=", "[", "_", "[", "'attr'", "]", "for", "_", "in", "sg_batch", "]", "\n", "rela_batch", "=", "[", "_", "[", "'rela'", "]", "for", "_", "in", "sg_batch", "]", "\n", "sg_data", "=", "{", "}", "\n", "\n", "# obj labels, shape: (B, No, 1)", "\n", "sg_data", "[", "'obj_labels'", "]", "=", "np", ".", "zeros", "(", "[", "len", "(", "obj_batch", ")", ",", "max_att_len", ",", "self", ".", "opt", ".", "num_obj_label_use", "]", ",", "dtype", "=", "'int'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "obj_batch", ")", ")", ":", "\n", "            ", "sg_data", "[", "'obj_labels'", "]", "[", "i", ",", ":", "obj_batch", "[", "i", "]", ".", "shape", "[", "0", "]", "]", "=", "obj_batch", "[", "i", "]", "\n", "\n", "# attr labels, shape: (B, No, 3)", "\n", "", "sg_data", "[", "'attr_labels'", "]", "=", "np", ".", "zeros", "(", "[", "len", "(", "attr_batch", ")", ",", "max_att_len", ",", "self", ".", "opt", ".", "num_attr_label_use", "]", ",", "dtype", "=", "'int'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "attr_batch", ")", ")", ":", "\n", "            ", "sg_data", "[", "'attr_labels'", "]", "[", "i", ",", ":", "attr_batch", "[", "i", "]", ".", "shape", "[", "0", "]", "]", "=", "attr_batch", "[", "i", "]", "\n", "# obj and attr share the same mask as att_feats", "\n", "\n", "# rela", "\n", "", "max_rela_len", "=", "max", "(", "[", "_", "[", "'edges'", "]", ".", "shape", "[", "0", "]", "for", "_", "in", "rela_batch", "]", ")", "\n", "sg_data", "[", "'rela_edges'", "]", "=", "np", ".", "zeros", "(", "[", "len", "(", "rela_batch", ")", ",", "max_rela_len", ",", "2", "]", ",", "dtype", "=", "'int'", ")", "\n", "if", "self", ".", "geometry_relation", ":", "\n", "            ", "sg_data", "[", "'rela_feats'", "]", "=", "np", ".", "zeros", "(", "[", "len", "(", "rela_batch", ")", ",", "max_rela_len", ",", "self", ".", "opt", ".", "geometry_rela_feat_dim", "]", ",", "dtype", "=", "'float32'", ")", "\n", "", "else", ":", "\n", "            ", "sg_data", "[", "'rela_feats'", "]", "=", "np", ".", "zeros", "(", "[", "len", "(", "rela_batch", ")", ",", "max_rela_len", "]", ",", "dtype", "=", "'int'", ")", "\n", "# rela_masks, because no all items in rela_edges and rela_feats are meaningful", "\n", "", "sg_data", "[", "'rela_masks'", "]", "=", "np", ".", "zeros", "(", "sg_data", "[", "'rela_edges'", "]", ".", "shape", "[", ":", "2", "]", ",", "dtype", "=", "'float32'", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "rela_batch", ")", ")", ":", "\n", "            ", "sg_data", "[", "'rela_edges'", "]", "[", "i", ",", ":", "rela_batch", "[", "i", "]", "[", "'edges'", "]", ".", "shape", "[", "0", "]", "]", "=", "rela_batch", "[", "i", "]", "[", "'edges'", "]", "\n", "sg_data", "[", "'rela_feats'", "]", "[", "i", ",", ":", "rela_batch", "[", "i", "]", "[", "'edges'", "]", ".", "shape", "[", "0", "]", "]", "=", "rela_batch", "[", "i", "]", "[", "'feats'", "]", "\n", "sg_data", "[", "'rela_masks'", "]", "[", "i", ",", ":", "rela_batch", "[", "i", "]", "[", "'edges'", "]", ".", "shape", "[", "0", "]", "]", "=", "1", "\n", "\n", "", "return", "sg_data", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.__getitem__": [[233, 259], ["str", "numpy.load", "dataloader.DataLoader.get_graph_data", "numpy.hstack.reshape", "numpy.zeros", "os.path.join", "numpy.load", "dataloader.DataLoader.get_box_feat", "numpy.hstack", "os.path.join", "numpy.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.get_graph_data", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.get_box_feat"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"This function returns a tuple that is further passed to collate_fn\n        \"\"\"", "\n", "ix", "=", "index", "#self.split_ix[index]", "\n", "image_id", "=", "str", "(", "self", ".", "info", "[", "'images'", "]", "[", "ix", "]", "[", "'id'", "]", ")", "\n", "if", "self", ".", "use_att", ":", "\n", "            ", "att_feat", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "input_att_dir", ",", "image_id", "+", "'.npz'", ")", ")", "[", "'feat'", "]", "\n", "# Reshape to K x C", "\n", "att_feat", "=", "att_feat", ".", "reshape", "(", "-", "1", ",", "att_feat", ".", "shape", "[", "-", "1", "]", ")", "\n", "if", "self", ".", "norm_att_feat", ":", "\n", "                ", "att_feat", "=", "att_feat", "/", "np", ".", "linalg", ".", "norm", "(", "att_feat", ",", "2", ",", "1", ",", "keepdims", "=", "True", ")", "\n", "", "if", "self", ".", "use_box", ":", "\n", "                ", "box_feat", "=", "self", ".", "get_box_feat", "(", "image_id", ")", "\n", "att_feat", "=", "np", ".", "hstack", "(", "[", "att_feat", ",", "box_feat", "]", ")", "\n", "# sort the features by the size of boxes", "\n", "# att_feat = np.stack(sorted(att_feat, key=lambda x:x[-1], reverse=True))", "\n", "", "", "else", ":", "\n", "            ", "att_feat", "=", "np", ".", "zeros", "(", "(", "1", ",", "1", ",", "1", ")", ")", "\n", "", "fc_feat", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "input_fc_dir", ",", "image_id", "+", "'.npy'", ")", ")", "\n", "\n", "sg_data", "=", "self", ".", "get_graph_data", "(", "index", ")", "\n", "\n", "return", "(", "fc_feat", ",", "\n", "att_feat", ",", "\n", "sg_data", ",", "\n", "ix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.get_graph_data": [[261, 283], ["str", "numpy.load", "os.path.join", "numpy.load", "numpy.array"], "methods", ["None"], ["", "def", "get_graph_data", "(", "self", ",", "index", ")", ":", "\n", "        ", "image_id", "=", "str", "(", "self", ".", "info", "[", "'images'", "]", "[", "index", "]", "[", "'id'", "]", ")", "\n", "sg_use", "=", "np", ".", "load", "(", "self", ".", "sg_data_dir", "+", "image_id", "+", "'.npy'", ")", "[", "(", ")", "]", "\n", "if", "self", ".", "geometry_relation", ":", "\n", "            ", "geometry_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "sg_geometry_dir", ",", "image_id", "+", "'.npy'", ")", "\n", "rela", "=", "np", ".", "load", "(", "geometry_path", ")", "[", "(", ")", "]", "# dict contains keys of edges and feats", "\n", "", "else", ":", "\n", "# if the relation of an image is empty, then fill in it with <0, 0, 'near'> to avoid problems", "\n", "            ", "if", "sg_use", "[", "'rela_matrix'", "]", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "                ", "sg_use", "[", "'rela_matrix'", "]", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "self", ".", "sg_vocab", "[", "'w2i'", "]", "[", "'near'", "]", "]", ",", "dtype", "=", "sg_use", "[", "'rela_matrix'", "]", ".", "dtype", ")", "\n", "\n", "# shape (Nr, 3), column index 0,1 is edge, index 2 is relation label", "\n", "", "triplet", "=", "sg_use", "[", "'rela_matrix'", "]", "\n", "rela", "=", "{", "}", "\n", "rela", "[", "'edges'", "]", "=", "triplet", "[", ":", ",", "0", ":", "2", "]", "\n", "rela", "[", "'feats'", "]", "=", "triplet", "[", ":", ",", "2", "]", "\n", "\n", "", "obj", "=", "sg_use", "[", "'obj_attr'", "]", "[", ":", ",", "1", ":", "1", "+", "self", ".", "opt", ".", "num_obj_label_use", "]", "# shape (No, ?)", "\n", "attr", "=", "sg_use", "[", "'obj_attr'", "]", "[", ":", ",", "4", ":", "4", "+", "self", ".", "opt", ".", "num_attr_label_use", "]", "# shape (No, ?)", "\n", "\n", "sg_data", "=", "{", "'obj'", ":", "obj", ",", "'attr'", ":", "attr", ",", "'rela'", ":", "rela", "}", "\n", "return", "sg_data", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.get_box_feat": [[285, 294], ["numpy.hsplit", "numpy.hstack", "int", "numpy.linalg.norm", "int", "int"], "methods", ["None"], ["", "def", "get_box_feat", "(", "self", ",", "image_id", ")", ":", "\n", "        ", "image", "=", "self", ".", "sg_box_info", "[", "int", "(", "image_id", ")", "]", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "np", ".", "hsplit", "(", "image", "[", "'boxes'", "]", ",", "4", ")", "\n", "h", ",", "w", "=", "image", "[", "int", "(", "image_id", ")", "]", "[", "'image_h'", "]", ",", "image", "[", "int", "(", "image_id", ")", "]", "[", "'image_w'", "]", "\n", "iw", ",", "ih", "=", "x2", "-", "x1", "+", "1", ",", "y2", "-", "y1", "+", "1", "\n", "box_feat", "=", "np", ".", "hstack", "(", "(", "0.5", "*", "(", "x1", "+", "x2", ")", "/", "w", ",", "0.5", "*", "(", "y1", "+", "y2", ")", "/", "h", ",", "iw", "/", "w", ",", "ih", "/", "h", ",", "iw", "*", "ih", "/", "(", "w", "*", "h", ")", ")", ")", "\n", "if", "self", ".", "norm_box_feat", ":", "\n", "            ", "box_feat", "=", "box_feat", "/", "np", ".", "linalg", ".", "norm", "(", "box_feat", ",", "2", ",", "1", ",", "keepdims", "=", "True", ")", "\n", "", "return", "box_feat", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.DataLoader.__len__": [[296, 298], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "info", "[", "'images'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.SubsetSampler.__init__": [[306, 308], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "indices", ")", ":", "\n", "        ", "self", ".", "indices", "=", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.SubsetSampler.__iter__": [[309, 311], ["range", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "indices", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "self", ".", "indices", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.SubsetSampler.__len__": [[312, 314], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.__init__": [[317, 326], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "split", ",", "dataloader", ",", "if_shuffle", "=", "False", ",", "num_workers", "=", "4", ",", "opt", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        db is a list of tuples containing: imcrop_name, caption, bbox_feat of gt box, imname\n        \"\"\"", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "dataloader", "=", "dataloader", "\n", "self", ".", "if_shuffle", "=", "if_shuffle", "\n", "self", ".", "num_workers", "=", "num_workers", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.reset": [[328, 343], ["iter", "torch.DataLoader", "torch.DataLoader", "dataloader.SubsetSampler"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Two cases for this function to be triggered:\n        1. not hasattr(self, 'split_loader'): Resume from previous training. Create the dataset given the saved split_ix and iterator\n        2. wrapped: a new epoch, the split_ix and iterator have been updated in the get_minibatch_inds already.\n        \"\"\"", "\n", "# batch_size is 1, the merge is done in DataLoader class", "\n", "self", ".", "split_loader", "=", "iter", "(", "data", ".", "DataLoader", "(", "dataset", "=", "self", ".", "dataloader", ",", "\n", "batch_size", "=", "1", ",", "\n", "sampler", "=", "SubsetSampler", "(", "self", ".", "dataloader", ".", "split_ix", "[", "self", ".", "split", "]", "[", "self", ".", "dataloader", ".", "iterators", "[", "self", ".", "split", "]", ":", "]", ")", ",", "\n", "shuffle", "=", "False", ",", "\n", "pin_memory", "=", "True", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "# 4 is usually enough", "\n", "worker_init_fn", "=", "None", ",", "\n", "collate_fn", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher._get_next_minibatch_inds": [[344, 360], ["len", "random.shuffle"], "methods", ["None"], ["", "def", "_get_next_minibatch_inds", "(", "self", ")", ":", "\n", "        ", "max_index", "=", "len", "(", "self", ".", "dataloader", ".", "split_ix", "[", "self", ".", "split", "]", ")", "\n", "wrapped", "=", "False", "\n", "\n", "ri", "=", "self", ".", "dataloader", ".", "iterators", "[", "self", ".", "split", "]", "\n", "ix", "=", "self", ".", "dataloader", ".", "split_ix", "[", "self", ".", "split", "]", "[", "ri", "]", "\n", "\n", "ri_next", "=", "ri", "+", "1", "\n", "if", "ri_next", ">=", "max_index", ":", "\n", "            ", "ri_next", "=", "0", "\n", "if", "self", ".", "if_shuffle", ":", "\n", "                ", "random", ".", "shuffle", "(", "self", ".", "dataloader", ".", "split_ix", "[", "self", ".", "split", "]", ")", "\n", "", "wrapped", "=", "True", "\n", "", "self", ".", "dataloader", ".", "iterators", "[", "self", ".", "split", "]", "=", "ri_next", "\n", "\n", "return", "ix", ",", "wrapped", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get": [[361, 373], ["dataloader.BlobFetcher._get_next_minibatch_inds", "dataloader.BlobFetcher.split_loader.next", "hasattr", "dataloader.BlobFetcher.reset", "dataloader.BlobFetcher.reset"], "methods", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher._get_next_minibatch_inds", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.reset", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.reset"], ["", "def", "get", "(", "self", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'split_loader'", ")", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "\n", "", "ix", ",", "wrapped", "=", "self", ".", "_get_next_minibatch_inds", "(", ")", "\n", "tmp", "=", "self", ".", "split_loader", ".", "next", "(", ")", "\n", "if", "wrapped", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "\n", "", "assert", "tmp", "[", "-", "1", "]", "==", "ix", ",", "\"ix not equal\"", "\n", "\n", "return", "tmp", "+", "[", "wrapped", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.utils.logger.MyTensorboard.__init__": [[30, 32], ["tb.SummaryWriter"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "self", ".", "writer", "=", "tb", "and", "tb", ".", "SummaryWriter", "(", "opt", ".", "checkpoint_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.utils.logger.MyTensorboard.add_value": [[34, 37], ["logger.MyTensorboard.writer.add_scalar"], "methods", ["None"], ["", "def", "add_value", "(", "self", ",", "key", ",", "value", ",", "iteration", ")", ":", "\n", "        ", "if", "self", ".", "writer", ":", "\n", "            ", "self", ".", "writer", ".", "add_scalar", "(", "key", ",", "value", ",", "iteration", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.utils.logger.MyTensorboard.add_values": [[39, 44], ["tag_scalar_dict.items", "logger.MyTensorboard.writer.add_scalar"], "methods", ["None"], ["", "", "def", "add_values", "(", "self", ",", "main_tag", ",", "tag_scalar_dict", ",", "iteration", ")", ":", "\n", "        ", "if", "self", ".", "writer", ":", "\n", "            ", "for", "name", ",", "value", "in", "tag_scalar_dict", ".", "items", "(", ")", ":", "\n", "                ", "key", "=", "main_tag", "+", "'/'", "+", "name", "\n", "self", ".", "writer", ".", "add_scalar", "(", "key", ",", "value", ",", "iteration", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.utils.logger.define_logger": [[10, 27], ["logging.getLogger", "logging.getLogger.setLevel", "os.path.join", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.Formatter", "logging.FileHandler.setFormatter", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "logging.getLogger.addHandler"], "function", ["None"], ["", "def", "define_logger", "(", "opt", ",", "id", "=", "None", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "id", "=", "opt", ".", "id", "if", "id", "is", "None", "else", "id", "\n", "\n", "logfile", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_path", ",", "opt", ".", "id", "+", "'.log'", ")", "\n", "fh", "=", "logging", ".", "FileHandler", "(", "logfile", ",", "mode", "=", "'a'", ")", "\n", "fh", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "ch", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "ch", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "\"%(asctime)s [\"", "+", "id", "+", "\"] %(levelname)s %(message)s\"", ")", "\n", "fh", ".", "setFormatter", "(", "formatter", ")", "\n", "ch", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", ".", "addHandler", "(", "fh", ")", "\n", "logger", ".", "addHandler", "(", "ch", ")", "\n", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.utils.helper.str2bool": [[6, 13], ["v.lower", "v.lower", "Exception"], "function", ["None"], ["def", "str2bool", "(", "v", ")", ":", "\n", "    ", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"value not allowed\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.utils.helper.str2list": [[15, 17], ["v.split"], "function", ["None"], ["", "", "def", "str2list", "(", "v", ")", ":", "\n", "    ", "return", "v", ".", "split", "(", "\",\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.utils.load_save.save_nets_structure": [[6, 14], ["os.path.join", "type", "open", "nets.items", "str", "enumerate", "f.write"], "function", ["None"], ["def", "save_nets_structure", "(", "nets", ",", "opt", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_path", ",", "'models.txt'", ")", "\n", "if", "type", "(", "nets", ")", "is", "list", ":", "\n", "        ", "nets", "=", "{", "'Net_'", "+", "str", "(", "i", ")", ":", "net", "for", "i", ",", "net", "in", "enumerate", "(", "nets", ")", "}", "\n", "", "with", "open", "(", "path", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "name", ",", "net", "in", "nets", ".", "items", "(", ")", ":", "\n", "            ", "if", "net", "is", "not", "None", ":", "\n", "                ", "f", ".", "write", "(", "\"Name: {}\\n{}\\n\"", ".", "format", "(", "name", ",", "net", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.utils.load_save.save_checkpoint": [[17, 39], ["logging.getLogger", "os.path.join", "logging.getLogger.info", "load_save.save_checkpoint.save"], "function", ["None"], ["", "", "", "", "def", "save_checkpoint", "(", "models", ",", "optimizers", ",", "infos", ",", "is_best", ",", "opt", ")", ":", "\n", "    ", "\"save model, optimizer, and infos\"", "\n", "assert", "type", "(", "models", ")", "is", "dict", "and", "type", "(", "optimizers", ")", "is", "dict", ",", "\"models and optimizers should be dict\"", "\n", "def", "save", "(", "prefix", ")", ":", "\n", "        ", "model_params", "=", "{", "name", ":", "model", ".", "state_dict", "(", ")", "for", "name", ",", "model", "in", "models", ".", "items", "(", ")", "}", "\n", "torch", ".", "save", "(", "model_params", ",", "prefix", "+", "'model.pth'", ")", "\n", "optimizer_params", "=", "{", "name", ":", "optimizer", ".", "state_dict", "(", ")", "for", "name", ",", "optimizer", "in", "optimizers", ".", "items", "(", ")", "}", "\n", "torch", ".", "save", "(", "optimizer_params", ",", "prefix", "+", "'optimizer.pth'", ")", "\n", "with", "open", "(", "prefix", "+", "'infos.pkl'", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "cPickle", ".", "dump", "(", "infos", ",", "f", ")", "\n", "\n", "", "", "logger", "=", "logging", ".", "getLogger", "(", "'__main__'", ")", "\n", "# save current and override", "\n", "prefix", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_path", ",", "''", ")", "\n", "logger", ".", "info", "(", "\"Saving checkpoint to {}\"", ".", "format", "(", "prefix", "+", "'model.pth'", ")", ")", "\n", "save", "(", "prefix", ")", "\n", "# save best", "\n", "if", "is_best", ":", "\n", "        ", "prefix", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_path", ",", "'best_'", ")", "\n", "logger", ".", "info", "(", "\"Saving best checkpoint\"", ")", "\n", "save", "(", "prefix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.utils.load_save.load_checkpoint": [[41, 73], ["logging.getLogger", "os.path.join", "os.path.isfile", "os.path.join", "os.path.isfile", "os.path.isdir", "logging.getLogger.info", "logging.getLogger.info", "torch.load", "models.items", "logging.getLogger.warning", "logging.getLogger.info", "torch.load", "optimizers.items", "logging.getLogger.warning", "model.load_state_dict", "optim.load_state_dict"], "function", ["None"], ["", "", "def", "load_checkpoint", "(", "models", ",", "optimizers", ",", "opt", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "'__main__'", ")", "\n", "# check compatibility if training is continued from previously saved model", "\n", "if", "opt", ".", "resume_from", "is", "None", "or", "os", ".", "path", ".", "isdir", "(", "opt", ".", "resume_from", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"resume_from not set, training from scratch\"", ")", "\n", "return", "False", "\n", "", "prefix", "=", "'best_'", "if", "opt", ".", "resume_from_best", "else", "''", "\n", "flag", "=", "True", "\n", "\n", "# load model", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "resume_from", ",", "prefix", "+", "'model.pth'", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "path", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading models from %s\"", "%", "path", ")", "\n", "params", "=", "torch", ".", "load", "(", "path", ")", "\n", "for", "name", ",", "model", "in", "models", ".", "items", "(", ")", ":", "\n", "            ", "model", ".", "load_state_dict", "(", "params", "[", "name", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "logger", ".", "warning", "(", "\"Fail to load model\"", ")", "\n", "flag", "=", "False", "\n", "\n", "# load optimizer", "\n", "", "path", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "resume_from", ",", "prefix", "+", "'optimizer.pth'", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "path", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading optimizers from %s\"", "%", "path", ")", "\n", "params", "=", "torch", ".", "load", "(", "path", ")", "\n", "for", "name", ",", "optim", "in", "optimizers", ".", "items", "(", ")", ":", "\n", "            ", "optim", ".", "load_state_dict", "(", "params", "[", "name", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "logger", ".", "warning", "(", "\"Fail to load optimizer\"", ")", "\n", "flag", "=", "False", "\n", "\n", "", "return", "flag", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.utils.load_save.load_info": [[75, 97], ["logging.getLogger", "os.path.join", "os.path.isfile", "os.path.isdir", "logging.getLogger.info", "logging.getLogger.info", "logging.getLogger.warning", "open", "cPickle.load", "os.path.join", "vars", "vars"], "function", ["None"], ["", "def", "load_info", "(", "opt", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "'__main__'", ")", "\n", "# check compatibility if training is continued from previously saved model", "\n", "if", "opt", ".", "resume_from", "is", "None", "or", "os", ".", "path", ".", "isdir", "(", "opt", ".", "resume_from", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"resume_from not set, not loadding infos\"", ")", "\n", "return", "{", "}", "\n", "", "prefix", "=", "'best_'", "if", "opt", ".", "resume_from_best", "else", "''", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "resume_from", ",", "prefix", "+", "'infos.pkl'", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "path", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading infos from %s\"", "%", "path", ")", "\n", "# open old infos and check if models are compatible", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path", ")", ")", "as", "f", ":", "\n", "            ", "infos", "=", "cPickle", ".", "load", "(", "f", ")", "\n", "", "saved_model_opt", "=", "infos", "[", "'opt'", "]", "\n", "need_be_same", "=", "[", "\"caption_model\"", ",", "\"rnn_type\"", ",", "\"rnn_size\"", ",", "\"num_layers\"", "]", "\n", "for", "checkme", "in", "need_be_same", ":", "\n", "            ", "assert", "vars", "(", "saved_model_opt", ")", "[", "checkme", "]", "==", "vars", "(", "opt", ")", "[", "checkme", "]", ",", "\"Command line argument and saved model disagree on '%s' \"", "%", "checkme", "\n", "", "", "else", ":", "\n", "        ", "logger", ".", "warning", "(", "\"Fail to load infos\"", ")", "\n", "infos", "=", "{", "}", "\n", "\n", "", "return", "infos", "\n", "", ""]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.build_geometry_graph.Counter.__init__": [[16, 18], ["multiprocessing.Value"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "Value", "(", "'i'", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.build_geometry_graph.Counter.add": [[19, 22], ["build_geometry_graph.Counter.val.get_lock"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "n", "=", "1", ")", ":", "\n", "        ", "with", "self", ".", "val", ".", "get_lock", "(", ")", ":", "\n", "            ", "self", ".", "val", ".", "value", "+=", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.build_geometry_graph.Counter.value": [[23, 26], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "value", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "val", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.build_geometry_graph.build_geometry_graph": [[28, 61], ["range", "numpy.array", "numpy.array", "numpy.save", "range", "np.array.append", "np.array.append", "os.path.join", "print", "np.array.append", "np.array.append", "str"], "function", ["None"], ["", "", "def", "build_geometry_graph", "(", "id", ")", ":", "\n", "    ", "feats", "=", "all_feats", "[", "id", "]", "\n", "num_boxes", "=", "feats", ".", "shape", "[", "0", "]", "\n", "edges", "=", "[", "]", "\n", "relas", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_boxes", ")", ":", "\n", "        ", "if", "Directed", ":", "\n", "            ", "start", "=", "0", "\n", "", "else", ":", "\n", "            ", "start", "=", "i", "\n", "", "for", "j", "in", "range", "(", "start", ",", "num_boxes", ")", ":", "\n", "            ", "if", "i", "==", "j", ":", "\n", "                ", "continue", "\n", "# iou and dist thresholds", "\n", "", "if", "feats", "[", "i", "]", "[", "j", "]", "[", "3", "]", "<", "Iou", "or", "feats", "[", "i", "]", "[", "j", "]", "[", "6", "]", ">", "Dist", ":", "\n", "                ", "continue", "\n", "", "edges", ".", "append", "(", "[", "i", ",", "j", "]", ")", "\n", "relas", ".", "append", "(", "feats", "[", "i", "]", "[", "j", "]", ")", "\n", "\n", "# in case some trouble is met", "\n", "", "", "if", "edges", "==", "[", "]", ":", "\n", "        ", "edges", ".", "append", "(", "[", "0", ",", "1", "]", ")", "\n", "relas", ".", "append", "(", "feats", "[", "0", "]", "[", "1", "]", ")", "\n", "\n", "", "edges", "=", "np", ".", "array", "(", "edges", ")", "\n", "relas", "=", "np", ".", "array", "(", "relas", ")", "\n", "graph", "=", "{", "}", "\n", "graph", "[", "'edges'", "]", "=", "edges", "\n", "graph", "[", "'feats'", "]", "=", "relas", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "SaveDir", ",", "str", "(", "id", ")", ")", ",", "graph", ")", "\n", "\n", "if", "counter", ".", "value", "%", "100", "==", "0", "and", "counter", ".", "value", ">=", "100", ":", "\n", "        ", "print", "(", "'{} / {}'", ".", "format", "(", "counter", ".", "value", ",", "num_images", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.prepro_ngrams.precook": [[33, 49], ["s.split", "collections.defaultdict", "xrange", "xrange", "tuple", "len"], "function", ["None"], ["def", "precook", "(", "s", ",", "n", "=", "4", ",", "out", "=", "False", ")", ":", "\n", "  ", "\"\"\"\n  Takes a string as input and returns an object that can be given to\n  either cook_refs or cook_test. This is optional: cook_refs and cook_test\n  can take string arguments as well.\n  :param s: string : sentence to be converted into ngrams\n  :param n: int    : number of ngrams for which representation is calculated\n  :return: term frequency vector for occuring ngrams\n  \"\"\"", "\n", "words", "=", "s", ".", "split", "(", ")", "\n", "counts", "=", "defaultdict", "(", "int", ")", "\n", "for", "k", "in", "xrange", "(", "1", ",", "n", "+", "1", ")", ":", "\n", "    ", "for", "i", "in", "xrange", "(", "len", "(", "words", ")", "-", "k", "+", "1", ")", ":", "\n", "      ", "ngram", "=", "tuple", "(", "words", "[", "i", ":", "i", "+", "k", "]", ")", "\n", "counts", "[", "ngram", "]", "+=", "1", "\n", "", "", "return", "counts", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.prepro_ngrams.cook_refs": [[50, 59], ["prepro_ngrams.precook"], "function", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.prepro_ngrams.precook"], ["", "def", "cook_refs", "(", "refs", ",", "n", "=", "4", ")", ":", "## lhuang: oracle will call with \"average\"", "\n", "    ", "'''Takes a list of reference sentences for a single segment\n    and returns an object that encapsulates everything that BLEU\n    needs to know about them.\n    :param refs: list of string : reference sentences for some image\n    :param n: int : number of ngrams for which (ngram) representation is calculated\n    :return: result (list of dict)\n    '''", "\n", "return", "[", "precook", "(", "ref", ",", "n", ")", "for", "ref", "in", "refs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.prepro_ngrams.create_crefs": [[60, 66], ["crefs.append", "prepro_ngrams.cook_refs"], "function", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.prepro_ngrams.cook_refs"], ["", "def", "create_crefs", "(", "refs", ")", ":", "\n", "  ", "crefs", "=", "[", "]", "\n", "for", "ref", "in", "refs", ":", "\n", "# ref is a list of 5 captions", "\n", "    ", "crefs", ".", "append", "(", "cook_refs", "(", "ref", ")", ")", "\n", "", "return", "crefs", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.prepro_ngrams.compute_doc_freq": [[67, 81], ["collections.defaultdict", "set", "ref.iteritems"], "function", ["None"], ["", "def", "compute_doc_freq", "(", "crefs", ")", ":", "\n", "  ", "'''\n  Compute term frequency for reference data.\n  This will be used to compute idf (inverse document frequency later)\n  The term frequency is stored in the object\n  :return: None\n  '''", "\n", "document_frequency", "=", "defaultdict", "(", "float", ")", "\n", "for", "refs", "in", "crefs", ":", "\n", "# refs, k ref captions of one image", "\n", "    ", "for", "ngram", "in", "set", "(", "[", "ngram", "for", "ref", "in", "refs", "for", "(", "ngram", ",", "count", ")", "in", "ref", ".", "iteritems", "(", ")", "]", ")", ":", "\n", "      ", "document_frequency", "[", "ngram", "]", "+=", "1", "\n", "# maxcounts[ngram] = max(maxcounts.get(ngram,0), count)", "\n", "", "", "return", "document_frequency", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.prepro_ngrams.build_dict": [[82, 111], ["print", "prepro_ngrams.compute_doc_freq", "prepro_ngrams.compute_doc_freq", "prepro_ngrams.create_crefs", "prepro_ngrams.create_crefs", "refs_words.append", "refs_idxs.append", "hasattr", "ref_words.append", "ref_idxs.append", "params.bpe.segment().strip().split", "params.bpe.segment().strip", "str", "params.bpe.segment"], "function", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.prepro_ngrams.compute_doc_freq", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.prepro_ngrams.compute_doc_freq", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.prepro_ngrams.create_crefs", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.prepro_ngrams.create_crefs"], ["", "def", "build_dict", "(", "imgs", ",", "wtoi", ",", "params", ")", ":", "\n", "  ", "wtoi", "[", "'<eos>'", "]", "=", "0", "\n", "\n", "count_imgs", "=", "0", "\n", "\n", "refs_words", "=", "[", "]", "\n", "refs_idxs", "=", "[", "]", "\n", "for", "img", "in", "imgs", ":", "\n", "    ", "if", "(", "params", "[", "'split'", "]", "==", "img", "[", "'split'", "]", ")", "or", "(", "params", "[", "'split'", "]", "==", "'train'", "and", "img", "[", "'split'", "]", "==", "'restval'", ")", "or", "(", "params", "[", "'split'", "]", "==", "'all'", ")", ":", "\n", "#(params['split'] == 'val' and img['split'] == 'restval') or \\", "\n", "      ", "ref_words", "=", "[", "]", "\n", "ref_idxs", "=", "[", "]", "\n", "for", "sent", "in", "img", "[", "'sentences'", "]", ":", "\n", "        ", "if", "hasattr", "(", "params", ",", "'bpe'", ")", ":", "\n", "          ", "sent", "[", "'tokens'", "]", "=", "params", ".", "bpe", ".", "segment", "(", "' '", ".", "join", "(", "sent", "[", "'tokens'", "]", ")", ")", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "", "tmp_tokens", "=", "sent", "[", "'tokens'", "]", "+", "[", "'<eos>'", "]", "\n", "tmp_tokens", "=", "[", "_", "if", "_", "in", "wtoi", "else", "'UNK'", "for", "_", "in", "tmp_tokens", "]", "\n", "ref_words", ".", "append", "(", "' '", ".", "join", "(", "tmp_tokens", ")", ")", "\n", "ref_idxs", ".", "append", "(", "' '", ".", "join", "(", "[", "str", "(", "wtoi", "[", "_", "]", ")", "for", "_", "in", "tmp_tokens", "]", ")", ")", "\n", "", "refs_words", ".", "append", "(", "ref_words", ")", "\n", "refs_idxs", ".", "append", "(", "ref_idxs", ")", "\n", "count_imgs", "+=", "1", "\n", "", "", "print", "(", "'total imgs:'", ",", "count_imgs", ")", "\n", "\n", "ngram_words", "=", "compute_doc_freq", "(", "create_crefs", "(", "refs_words", ")", ")", "\n", "ngram_idxs", "=", "compute_doc_freq", "(", "create_crefs", "(", "refs_idxs", ")", ")", "\n", "return", "ngram_words", ",", "ngram_idxs", ",", "count_imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.prepro_ngrams.main": [[112, 137], ["json.load", "json.load", "prepro_ngrams.build_dict", "misc.pickle_dump", "misc.pickle_dump", "open", "open", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.close", "open", "open", "itow.items", "open", "f.write", "codecs.open", "apply_bpe.BPE"], "function", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.prepro_ngrams.build_dict"], ["", "def", "main", "(", "params", ")", ":", "\n", "\n", "  ", "imgs", "=", "json", ".", "load", "(", "open", "(", "params", "[", "'input_json'", "]", ",", "'r'", ")", ")", "\n", "dict_json", "=", "json", ".", "load", "(", "open", "(", "params", "[", "'dict_json'", "]", ",", "'r'", ")", ")", "\n", "itow", "=", "dict_json", "[", "'ix_to_word'", "]", "\n", "wtoi", "=", "{", "w", ":", "i", "for", "i", ",", "w", "in", "itow", ".", "items", "(", ")", "}", "\n", "\n", "# Load bpe", "\n", "if", "'bpe'", "in", "dict_json", ":", "\n", "    ", "import", "tempfile", "\n", "import", "codecs", "\n", "codes_f", "=", "tempfile", ".", "NamedTemporaryFile", "(", "delete", "=", "False", ")", "\n", "codes_f", ".", "close", "(", ")", "\n", "with", "open", "(", "codes_f", ".", "name", ",", "'w'", ")", "as", "f", ":", "\n", "      ", "f", ".", "write", "(", "dict_json", "[", "'bpe'", "]", ")", "\n", "", "with", "codecs", ".", "open", "(", "codes_f", ".", "name", ",", "encoding", "=", "'UTF-8'", ")", "as", "codes", ":", "\n", "      ", "bpe", "=", "apply_bpe", ".", "BPE", "(", "codes", ")", "\n", "", "params", ".", "bpe", "=", "bpe", "\n", "\n", "", "imgs", "=", "imgs", "[", "'images'", "]", "\n", "\n", "ngram_words", ",", "ngram_idxs", ",", "ref_len", "=", "build_dict", "(", "imgs", ",", "wtoi", ",", "params", ")", "\n", "\n", "utils", ".", "pickle_dump", "(", "{", "'document_frequency'", ":", "ngram_words", ",", "'ref_len'", ":", "ref_len", "}", ",", "open", "(", "params", "[", "'output_pkl'", "]", "+", "'-words.p'", ",", "'w'", ")", ")", "\n", "utils", ".", "pickle_dump", "(", "{", "'document_frequency'", ":", "ngram_idxs", ",", "'ref_len'", ":", "ref_len", "}", ",", "open", "(", "params", "[", "'output_pkl'", "]", "+", "'-idxs.p'", ",", "'w'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.prepro_labels.build_vocab": [[43, 94], ["sorted", "print", "print", "sum", "print", "sum", "print", "print", "print", "max", "print", "print", "sum", "range", "counts.values", "sent_lengths.keys", "sent_lengths.values", "print", "print", "vocab.append", "map", "counts.items", "counts.items", "len", "img[].append", "counts.items", "len", "len", "len", "sent_lengths.get", "counts.get", "len", "sent_lengths.get", "len", "counts.get", "sent_lengths.get"], "function", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get"], ["def", "build_vocab", "(", "imgs", ",", "params", ")", ":", "\n", "  ", "count_thr", "=", "params", "[", "'word_count_threshold'", "]", "\n", "\n", "# count up the number of words", "\n", "counts", "=", "{", "}", "\n", "for", "img", "in", "imgs", ":", "\n", "    ", "for", "sent", "in", "img", "[", "'sentences'", "]", ":", "\n", "      ", "for", "w", "in", "sent", "[", "'tokens'", "]", ":", "\n", "        ", "counts", "[", "w", "]", "=", "counts", ".", "get", "(", "w", ",", "0", ")", "+", "1", "\n", "", "", "", "cw", "=", "sorted", "(", "[", "(", "count", ",", "w", ")", "for", "w", ",", "count", "in", "counts", ".", "items", "(", ")", "]", ",", "reverse", "=", "True", ")", "\n", "print", "(", "'top words and their counts:'", ")", "\n", "print", "(", "'\\n'", ".", "join", "(", "map", "(", "str", ",", "cw", "[", ":", "20", "]", ")", ")", ")", "\n", "\n", "# print some stats", "\n", "total_words", "=", "sum", "(", "counts", ".", "values", "(", ")", ")", "\n", "print", "(", "'total words:'", ",", "total_words", ")", "\n", "bad_words", "=", "[", "w", "for", "w", ",", "n", "in", "counts", ".", "items", "(", ")", "if", "n", "<=", "count_thr", "]", "\n", "vocab", "=", "[", "w", "for", "w", ",", "n", "in", "counts", ".", "items", "(", ")", "if", "n", ">", "count_thr", "]", "\n", "bad_count", "=", "sum", "(", "counts", "[", "w", "]", "for", "w", "in", "bad_words", ")", "\n", "print", "(", "'number of bad words: %d/%d = %.2f%%'", "%", "(", "len", "(", "bad_words", ")", ",", "len", "(", "counts", ")", ",", "len", "(", "bad_words", ")", "*", "100.0", "/", "len", "(", "counts", ")", ")", ")", "\n", "print", "(", "'number of words in vocab would be %d'", "%", "(", "len", "(", "vocab", ")", ",", ")", ")", "\n", "print", "(", "'number of UNKs: %d/%d = %.2f%%'", "%", "(", "bad_count", ",", "total_words", ",", "bad_count", "*", "100.0", "/", "total_words", ")", ")", "\n", "\n", "# lets look at the distribution of lengths as well", "\n", "sent_lengths", "=", "{", "}", "\n", "for", "img", "in", "imgs", ":", "\n", "    ", "for", "sent", "in", "img", "[", "'sentences'", "]", ":", "\n", "      ", "txt", "=", "sent", "[", "'tokens'", "]", "\n", "nw", "=", "len", "(", "txt", ")", "\n", "sent_lengths", "[", "nw", "]", "=", "sent_lengths", ".", "get", "(", "nw", ",", "0", ")", "+", "1", "\n", "", "", "max_len", "=", "max", "(", "sent_lengths", ".", "keys", "(", ")", ")", "\n", "print", "(", "'max length sentence in raw data: '", ",", "max_len", ")", "\n", "print", "(", "'sentence length distribution (count, number of words):'", ")", "\n", "sum_len", "=", "sum", "(", "sent_lengths", ".", "values", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "max_len", "+", "1", ")", ":", "\n", "    ", "print", "(", "'%2d: %10d   %f%%'", "%", "(", "i", ",", "sent_lengths", ".", "get", "(", "i", ",", "0", ")", ",", "sent_lengths", ".", "get", "(", "i", ",", "0", ")", "*", "100.0", "/", "sum_len", ")", ")", "\n", "\n", "# lets now produce the final annotations", "\n", "", "if", "bad_count", ">", "0", ":", "\n", "# additional special UNK token we will use below to map infrequent words to", "\n", "    ", "print", "(", "'inserting the special UNK token'", ")", "\n", "vocab", ".", "append", "(", "'UNK'", ")", "\n", "\n", "", "for", "img", "in", "imgs", ":", "\n", "    ", "img", "[", "'final_captions'", "]", "=", "[", "]", "\n", "for", "sent", "in", "img", "[", "'sentences'", "]", ":", "\n", "      ", "txt", "=", "sent", "[", "'tokens'", "]", "\n", "caption", "=", "[", "w", "if", "counts", ".", "get", "(", "w", ",", "0", ")", ">", "count_thr", "else", "'UNK'", "for", "w", "in", "txt", "]", "\n", "img", "[", "'final_captions'", "]", ".", "append", "(", "caption", ")", "\n", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.prepro_labels.encode_captions": [[95, 138], ["len", "sum", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "numpy.concatenate", "numpy.all", "print", "len", "numpy.zeros", "enumerate", "label_arrays.append", "len", "min", "enumerate", "len"], "function", ["None"], ["", "def", "encode_captions", "(", "imgs", ",", "params", ",", "wtoi", ")", ":", "\n", "  ", "\"\"\" \n  encode all captions into one large array, which will be 1-indexed.\n  also produces label_start_ix and label_end_ix which store 1-indexed \n  and inclusive (Lua-style) pointers to the first and last caption for\n  each image in the dataset.\n  \"\"\"", "\n", "\n", "max_length", "=", "params", "[", "'max_length'", "]", "\n", "N", "=", "len", "(", "imgs", ")", "\n", "M", "=", "sum", "(", "len", "(", "img", "[", "'final_captions'", "]", ")", "for", "img", "in", "imgs", ")", "# total number of captions", "\n", "\n", "label_arrays", "=", "[", "]", "\n", "label_start_ix", "=", "np", ".", "zeros", "(", "N", ",", "dtype", "=", "'uint32'", ")", "# note: these will be one-indexed", "\n", "label_end_ix", "=", "np", ".", "zeros", "(", "N", ",", "dtype", "=", "'uint32'", ")", "\n", "label_length", "=", "np", ".", "zeros", "(", "M", ",", "dtype", "=", "'uint32'", ")", "\n", "caption_counter", "=", "0", "\n", "counter", "=", "1", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "imgs", ")", ":", "\n", "    ", "n", "=", "len", "(", "img", "[", "'final_captions'", "]", ")", "\n", "assert", "n", ">", "0", ",", "'error: some image has no captions'", "\n", "\n", "Li", "=", "np", ".", "zeros", "(", "(", "n", ",", "max_length", ")", ",", "dtype", "=", "'uint32'", ")", "\n", "for", "j", ",", "s", "in", "enumerate", "(", "img", "[", "'final_captions'", "]", ")", ":", "\n", "      ", "label_length", "[", "caption_counter", "]", "=", "min", "(", "max_length", ",", "len", "(", "s", ")", ")", "# record the length of this sequence", "\n", "caption_counter", "+=", "1", "\n", "for", "k", ",", "w", "in", "enumerate", "(", "s", ")", ":", "\n", "        ", "if", "k", "<", "max_length", ":", "\n", "          ", "Li", "[", "j", ",", "k", "]", "=", "wtoi", "[", "w", "]", "\n", "\n", "# note: word indices are 1-indexed, and captions are padded with zeros", "\n", "", "", "", "label_arrays", ".", "append", "(", "Li", ")", "\n", "label_start_ix", "[", "i", "]", "=", "counter", "\n", "label_end_ix", "[", "i", "]", "=", "counter", "+", "n", "-", "1", "\n", "\n", "counter", "+=", "n", "\n", "\n", "", "L", "=", "np", ".", "concatenate", "(", "label_arrays", ",", "axis", "=", "0", ")", "# put all the labels together", "\n", "assert", "L", ".", "shape", "[", "0", "]", "==", "M", ",", "'lengths don\\'t match? that\\'s weird'", "\n", "assert", "np", ".", "all", "(", "label_length", ">", "0", ")", ",", "'error: some caption had no words?'", "\n", "\n", "print", "(", "'encoded captions to array of size '", ",", "L", ".", "shape", ")", "\n", "return", "L", ",", "label_start_ix", ",", "label_end_ix", ",", "label_length", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.prepro_labels.main": [[139, 185], ["json.load", "random.seed", "prepro_labels.build_vocab", "prepro_labels.encode_captions", "len", "h5py.File", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.close", "enumerate", "json.dump", "print", "open", "out[].append", "open", "enumerate", "enumerate", "os.path.join", "img.get", "PIL.Image.open", "os.path.join"], "function", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.prepro_labels.build_vocab", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.prepro_labels.encode_captions", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get"], ["", "def", "main", "(", "params", ")", ":", "\n", "\n", "  ", "imgs", "=", "json", ".", "load", "(", "open", "(", "params", "[", "'input_json'", "]", ",", "'r'", ")", ")", "\n", "imgs", "=", "imgs", "[", "'images'", "]", "\n", "\n", "seed", "(", "123", ")", "# make reproducible", "\n", "\n", "# create the vocab", "\n", "vocab", "=", "build_vocab", "(", "imgs", ",", "params", ")", "\n", "itow", "=", "{", "i", "+", "1", ":", "w", "for", "i", ",", "w", "in", "enumerate", "(", "vocab", ")", "}", "# a 1-indexed vocab translation table", "\n", "wtoi", "=", "{", "w", ":", "i", "+", "1", "for", "i", ",", "w", "in", "enumerate", "(", "vocab", ")", "}", "# inverse table", "\n", "\n", "# encode captions in large arrays, ready to ship to hdf5 file", "\n", "L", ",", "label_start_ix", ",", "label_end_ix", ",", "label_length", "=", "encode_captions", "(", "imgs", ",", "params", ",", "wtoi", ")", "\n", "\n", "# create output h5 file", "\n", "N", "=", "len", "(", "imgs", ")", "\n", "f_lb", "=", "h5py", ".", "File", "(", "params", "[", "'output_h5'", "]", "+", "'_label.h5'", ",", "\"w\"", ")", "\n", "f_lb", ".", "create_dataset", "(", "\"labels\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "L", ")", "\n", "f_lb", ".", "create_dataset", "(", "\"label_start_ix\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "label_start_ix", ")", "\n", "f_lb", ".", "create_dataset", "(", "\"label_end_ix\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "label_end_ix", ")", "\n", "f_lb", ".", "create_dataset", "(", "\"label_length\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "label_length", ")", "\n", "f_lb", ".", "close", "(", ")", "\n", "\n", "# create output json file", "\n", "out", "=", "{", "}", "\n", "out", "[", "'ix_to_word'", "]", "=", "itow", "# encode the (1-indexed) vocab", "\n", "out", "[", "'images'", "]", "=", "[", "]", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "imgs", ")", ":", "\n", "\n", "    ", "jimg", "=", "{", "}", "\n", "jimg", "[", "'split'", "]", "=", "img", "[", "'split'", "]", "\n", "if", "'filename'", "in", "img", ":", "jimg", "[", "'file_path'", "]", "=", "os", ".", "path", ".", "join", "(", "img", ".", "get", "(", "'filepath'", ",", "''", ")", ",", "img", "[", "'filename'", "]", ")", "# copy it over, might need", "\n", "if", "'cocoid'", "in", "img", ":", "\n", "      ", "jimg", "[", "'id'", "]", "=", "img", "[", "'cocoid'", "]", "# copy over & mantain an id, if present (e.g. coco ids, useful)", "\n", "", "elif", "'imgid'", "in", "img", ":", "\n", "      ", "jimg", "[", "'id'", "]", "=", "img", "[", "'imgid'", "]", "\n", "\n", "", "if", "params", "[", "'images_root'", "]", "!=", "''", ":", "\n", "      ", "with", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "params", "[", "'images_root'", "]", ",", "img", "[", "'filepath'", "]", ",", "img", "[", "'filename'", "]", ")", ")", "as", "_img", ":", "\n", "        ", "jimg", "[", "'width'", "]", ",", "jimg", "[", "'height'", "]", "=", "_img", ".", "size", "\n", "\n", "", "", "out", "[", "'images'", "]", ".", "append", "(", "jimg", ")", "\n", "\n", "", "json", ".", "dump", "(", "out", ",", "open", "(", "params", "[", "'output_json'", "]", ",", "'w'", ")", ")", "\n", "print", "(", "'wrote '", ",", "params", "[", "'output_json'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.prepro_feats.main": [[52, 92], ["net.load_state_dict", "misc.resnet_utils.myResnet", "misc.resnet_utils.myResnet.cuda", "misc.resnet_utils.myResnet.eval", "json.load", "len", "random.seed", "enumerate", "print", "getattr", "torch.load", "open", "os.path.isdir", "os.mkdir", "os.path.isdir", "os.mkdir", "skimage.io.imread", "torch.from_numpy().cuda", "preprocess", "numpy.save", "numpy.savez_compressed", "os.path.join", "os.path.join", "len", "numpy.concatenate", "np.concatenate.astype", "torch.no_grad", "misc.resnet_utils.myResnet.", "os.path.join", "tmp_fc.data.cpu().float().numpy", "os.path.join", "print", "torch.from_numpy", "str", "str", "tmp_att.data.cpu().float().numpy", "np.concatenate.transpose", "tmp_fc.data.cpu().float", "tmp_att.data.cpu().float", "tmp_fc.data.cpu", "tmp_att.data.cpu"], "function", ["None"], ["def", "main", "(", "params", ")", ":", "\n", "  ", "net", "=", "getattr", "(", "resnet", ",", "params", "[", "'model'", "]", ")", "(", ")", "\n", "net", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "params", "[", "'model_root'", "]", ",", "params", "[", "'model'", "]", "+", "'.pth'", ")", ")", ")", "\n", "my_resnet", "=", "myResnet", "(", "net", ")", "\n", "my_resnet", ".", "cuda", "(", ")", "\n", "my_resnet", ".", "eval", "(", ")", "\n", "\n", "imgs", "=", "json", ".", "load", "(", "open", "(", "params", "[", "'input_json'", "]", ",", "'r'", ")", ")", "\n", "imgs", "=", "imgs", "[", "'images'", "]", "\n", "N", "=", "len", "(", "imgs", ")", "\n", "\n", "seed", "(", "123", ")", "# make reproducible", "\n", "\n", "dir_fc", "=", "params", "[", "'output_dir'", "]", "+", "'_fc'", "\n", "dir_att", "=", "params", "[", "'output_dir'", "]", "+", "'_att'", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "dir_fc", ")", ":", "\n", "    ", "os", ".", "mkdir", "(", "dir_fc", ")", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "dir_att", ")", ":", "\n", "    ", "os", ".", "mkdir", "(", "dir_att", ")", "\n", "\n", "", "for", "i", ",", "img", "in", "enumerate", "(", "imgs", ")", ":", "\n", "# load the image", "\n", "    ", "I", "=", "skimage", ".", "io", ".", "imread", "(", "os", ".", "path", ".", "join", "(", "params", "[", "'images_root'", "]", ",", "img", "[", "'filepath'", "]", ",", "img", "[", "'filename'", "]", ")", ")", "\n", "# handle grayscale input images", "\n", "if", "len", "(", "I", ".", "shape", ")", "==", "2", ":", "\n", "      ", "I", "=", "I", "[", ":", ",", ":", ",", "np", ".", "newaxis", "]", "\n", "I", "=", "np", ".", "concatenate", "(", "(", "I", ",", "I", ",", "I", ")", ",", "axis", "=", "2", ")", "\n", "\n", "", "I", "=", "I", ".", "astype", "(", "'float32'", ")", "/", "255.0", "\n", "I", "=", "torch", ".", "from_numpy", "(", "I", ".", "transpose", "(", "[", "2", ",", "0", ",", "1", "]", ")", ")", ".", "cuda", "(", ")", "\n", "I", "=", "preprocess", "(", "I", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "      ", "tmp_fc", ",", "tmp_att", "=", "my_resnet", "(", "I", ",", "params", "[", "'att_size'", "]", ")", "\n", "# write to pkl", "\n", "", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "dir_fc", ",", "str", "(", "img", "[", "'cocoid'", "]", ")", ")", ",", "tmp_fc", ".", "data", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", ")", "\n", "np", ".", "savez_compressed", "(", "os", ".", "path", ".", "join", "(", "dir_att", ",", "str", "(", "img", "[", "'cocoid'", "]", ")", ")", ",", "feat", "=", "tmp_att", ".", "data", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "if", "i", "%", "1000", "==", "0", ":", "\n", "      ", "print", "(", "'processing %d/%d (%.2f%% done)'", "%", "(", "i", ",", "N", ",", "i", "*", "100.0", "/", "N", ")", ")", "\n", "", "", "print", "(", "'wrote '", ",", "params", "[", "'output_dir'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.cal_geometry_feats.Counter.__init__": [[12, 14], ["multiprocessing.Value"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "Value", "(", "'i'", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.cal_geometry_feats.Counter.add": [[15, 18], ["cal_geometry_feats.Counter.val.get_lock"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "n", "=", "1", ")", ":", "\n", "        ", "with", "self", ".", "val", ".", "get_lock", "(", ")", ":", "\n", "            ", "self", ".", "val", ".", "value", "+=", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.cal_geometry_feats.Counter.value": [[19, 22], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "value", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "val", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.cal_geometry_feats.get_cwh": [[24, 31], ["None"], "function", ["None"], ["", "", "def", "get_cwh", "(", "box", ")", ":", "\n", "    ", "x_min", ",", "y_min", ",", "x_max", ",", "y_max", "=", "box", "\n", "cx", "=", "(", "x_min", "+", "x_max", ")", "*", "0.5", "\n", "cy", "=", "(", "y_min", "+", "y_max", ")", "*", "0.5", "\n", "w", "=", "(", "x_max", "-", "x_min", ")", "+", "1.", "\n", "h", "=", "(", "y_max", "-", "y_min", ")", "+", "1.", "\n", "return", "cx", ",", "cy", ",", "w", ",", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.cal_geometry_feats.cal_geometry_feats": [[34, 103], ["counter.add", "math.sqrt", "numpy.zeros", "range", "range", "print", "cal_geometry_feats.get_cwh", "cal_geometry_feats.get_cwh", "max", "max", "min", "min", "max", "max", "math.sqrt", "math.atan2", "math.sqrt", "numpy.array", "math.sqrt", "math.sqrt"], "function", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.cal_geometry_feats.Counter.add", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.cal_geometry_feats.get_cwh", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.scripts.cal_geometry_feats.get_cwh"], ["", "def", "cal_geometry_feats", "(", "id", ")", ":", "\n", "    ", "counter", ".", "add", "(", "1", ")", "\n", "info", "=", "BoxInfo", "[", "id", "]", "\n", "boxes", "=", "info", "[", "'boxes'", "]", "\n", "num_boxes", "=", "boxes", ".", "shape", "[", "0", "]", "\n", "w", ",", "h", "=", "info", "[", "'image_w'", "]", ",", "info", "[", "'image_h'", "]", "\n", "scale", "=", "w", "*", "h", "\n", "diag_len", "=", "math", ".", "sqrt", "(", "w", "**", "2", "+", "h", "**", "2", ")", "\n", "feats", "=", "np", ".", "zeros", "(", "[", "num_boxes", ",", "num_boxes", ",", "NumFeats", "]", ",", "dtype", "=", "'float'", ")", "\n", "for", "i", "in", "range", "(", "num_boxes", ")", ":", "\n", "        ", "if", "Directed", ":", "\n", "            ", "start", "=", "0", "\n", "", "else", ":", "\n", "            ", "start", "=", "i", "\n", "", "for", "j", "in", "range", "(", "start", ",", "num_boxes", ")", ":", "\n", "            ", "if", "Directed", ":", "\n", "                ", "_box1", ",", "_box2", "=", "boxes", "[", "i", "]", ",", "boxes", "[", "j", "]", "\n", "_w1", "=", "(", "_box1", "[", "2", "]", "-", "_box1", "[", "0", "]", ")", "+", "1.", "\n", "_h1", "=", "(", "_box1", "[", "3", "]", "-", "_box1", "[", "1", "]", ")", "+", "1.", "\n", "_w2", "=", "(", "_box2", "[", "2", "]", "-", "_box2", "[", "0", "]", ")", "+", "1.", "\n", "_h2", "=", "(", "_box2", "[", "3", "]", "-", "_box2", "[", "1", "]", ")", "+", "1.", "\n", "# the larger box as box1, the other one as box2", "\n", "if", "(", "_w1", "*", "_h1", ")", "/", "(", "_w2", "*", "_h2", ")", ">", "1", ":", "\n", "                    ", "box1", ",", "box2", "=", "_box1", ",", "_box2", "\n", "", "else", ":", "\n", "                    ", "box2", ",", "box1", "=", "_box1", ",", "_box2", "\n", "", "", "else", ":", "\n", "                ", "box1", ",", "box2", "=", "boxes", "[", "i", "]", ",", "boxes", "[", "j", "]", "\n", "\n", "", "cx1", ",", "cy1", ",", "w1", ",", "h1", "=", "get_cwh", "(", "box1", ")", "\n", "cx2", ",", "cy2", ",", "w2", ",", "h2", "=", "get_cwh", "(", "box2", ")", "\n", "x_min1", ",", "y_min1", ",", "x_max1", ",", "y_max1", "=", "box1", "\n", "x_min2", ",", "y_min2", ",", "x_max2", ",", "y_max2", "=", "box2", "\n", "# scale", "\n", "scale1", "=", "w1", "*", "h1", "\n", "scale2", "=", "w2", "*", "h2", "\n", "# Offset", "\n", "offsetx", "=", "cx2", "-", "cx1", "\n", "offsety", "=", "cy2", "-", "cy1", "\n", "# Aspect ratio", "\n", "aspect1", "=", "w1", "/", "h1", "\n", "aspect2", "=", "w2", "/", "h2", "\n", "# Overlap", "\n", "i_xmin", "=", "max", "(", "x_min1", ",", "x_min2", ")", "\n", "i_ymin", "=", "max", "(", "y_min1", ",", "y_min2", ")", "\n", "i_xmax", "=", "min", "(", "x_max1", ",", "x_max2", ")", "\n", "i_ymax", "=", "min", "(", "y_max1", ",", "y_max2", ")", "\n", "iw", "=", "max", "(", "i_xmax", "-", "i_xmin", "+", "1", ",", "0", ")", "\n", "ih", "=", "max", "(", "i_ymax", "-", "i_ymin", "+", "1", ",", "0", ")", "\n", "areaI", "=", "iw", "*", "ih", "\n", "areaU", "=", "scale1", "+", "scale2", "-", "areaI", "\n", "# dist", "\n", "dist", "=", "math", ".", "sqrt", "(", "(", "cx1", "-", "cx2", ")", "**", "2", "+", "(", "cy1", "-", "cy2", ")", "**", "2", ")", "\n", "# angle", "\n", "angle", "=", "math", ".", "atan2", "(", "cy2", "-", "cy1", ",", "cx2", "-", "cx1", ")", "\n", "\n", "f1", "=", "offsetx", "/", "math", ".", "sqrt", "(", "scale1", ")", "\n", "f2", "=", "offsety", "/", "math", ".", "sqrt", "(", "scale1", ")", "\n", "f3", "=", "math", ".", "sqrt", "(", "scale2", "/", "scale1", ")", "\n", "f4", "=", "areaI", "/", "areaU", "\n", "f5", "=", "aspect1", "\n", "f6", "=", "aspect2", "\n", "f7", "=", "dist", "/", "diag_len", "\n", "f8", "=", "angle", "\n", "feat", "=", "[", "f1", ",", "f2", ",", "f3", ",", "f4", ",", "f5", ",", "f6", ",", "f7", ",", "f8", "]", "\n", "feats", "[", "i", "]", "[", "j", "]", "=", "np", ".", "array", "(", "feat", ")", "\n", "", "", "if", "counter", ".", "value", "%", "100", "==", "0", "and", "counter", ".", "value", ">=", "100", ":", "\n", "        ", "print", "(", "'{} / {}'", ".", "format", "(", "counter", ".", "value", ",", "NumImages", ")", ")", "\n", "", "return", "id", ",", "feats", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.GNN.__init__": [[39, 60], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.LanguageModelCriterion.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "GNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "in_dim", "=", "opt", ".", "rnn_size", "\n", "out_dim", "=", "opt", ".", "rnn_size", "\n", "\n", "\n", "if", "self", ".", "opt", ".", "rela_gnn_type", "==", "0", ":", "\n", "            ", "in_rela_dim", "=", "in_dim", "*", "3", "\n", "", "elif", "self", ".", "opt", ".", "rela_gnn_type", "==", "1", ":", "\n", "            ", "in_rela_dim", "=", "in_dim", "*", "2", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "# gnn with simple MLP", "\n", "", "self", ".", "gnn_attr", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "in_dim", "*", "2", ",", "out_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", "opt", ".", "drop_prob_lm", ")", ")", "\n", "self", ".", "gnn_rela", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "in_rela_dim", ",", "out_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", "opt", ".", "drop_prob_lm", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.GNN.forward": [[62, 89], ["VSUAModel.GNN.feat_3d_to_2d", "edges[].contiguous", "edges[].contiguous", "VSUAModel.GNN.feat_2d_to_3d", "VSUAModel.GNN.gnn_attr", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "VSUAModel.GNN.gnn_rela", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.GNN.feat_3d_to_2d", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.GNN.feat_2d_to_3d"], ["", "def", "forward", "(", "self", ",", "obj_vecs", ",", "attr_vecs", ",", "rela_vecs", ",", "edges", ",", "rela_masks", "=", "None", ")", ":", "\n", "# for easily indexing the subject and object of each relation in the tensors", "\n", "        ", "obj_vecs", ",", "attr_vecs", ",", "rela_vecs", ",", "edges", ",", "ori_shape", "=", "self", ".", "feat_3d_to_2d", "(", "obj_vecs", ",", "attr_vecs", ",", "rela_vecs", ",", "edges", ")", "\n", "\n", "# obj", "\n", "new_obj_vecs", "=", "obj_vecs", "\n", "\n", "# attr", "\n", "new_attr_vecs", "=", "self", ".", "gnn_attr", "(", "torch", ".", "cat", "(", "[", "obj_vecs", ",", "attr_vecs", "]", ",", "dim", "=", "-", "1", ")", ")", "+", "attr_vecs", "\n", "\n", "# rela", "\n", "# get node features for each triplet <subject, relation, object>", "\n", "s_idx", "=", "edges", "[", ":", ",", "0", "]", ".", "contiguous", "(", ")", "# index of subject", "\n", "o_idx", "=", "edges", "[", ":", ",", "1", "]", ".", "contiguous", "(", ")", "# index of object", "\n", "s_vecs", "=", "obj_vecs", "[", "s_idx", "]", "\n", "o_vecs", "=", "obj_vecs", "[", "o_idx", "]", "\n", "if", "self", ".", "opt", ".", "rela_gnn_type", "==", "0", ":", "\n", "            ", "t_vecs", "=", "torch", ".", "cat", "(", "[", "s_vecs", ",", "rela_vecs", ",", "o_vecs", "]", ",", "dim", "=", "1", ")", "\n", "", "elif", "self", ".", "opt", ".", "rela_gnn_type", "==", "1", ":", "\n", "            ", "t_vecs", "=", "torch", ".", "cat", "(", "[", "s_vecs", "+", "o_vecs", ",", "rela_vecs", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "", "new_rela_vecs", "=", "self", ".", "gnn_rela", "(", "t_vecs", ")", "+", "rela_vecs", "\n", "\n", "new_obj_vecs", ",", "new_attr_vecs", ",", "new_rela_vecs", "=", "self", ".", "feat_2d_to_3d", "(", "new_obj_vecs", ",", "new_attr_vecs", ",", "new_rela_vecs", ",", "rela_masks", ",", "ori_shape", ")", "\n", "\n", "return", "new_obj_vecs", ",", "new_attr_vecs", ",", "new_rela_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.GNN.feat_3d_to_2d": [[91, 105], ["obj_vecs.view.view.view", "attr_vecs.view.view.view", "rela_vecs.view.view.view", "edges.view.view.new_tensor", "edges.view.view.view", "obj_vecs.view.view.size", "attr_vecs.view.view.size", "rela_vecs.view.view.size", "range", "edges.view.new_tensor.view", "edges.view.view.size"], "methods", ["None"], ["", "def", "feat_3d_to_2d", "(", "self", ",", "obj_vecs", ",", "attr_vecs", ",", "rela_vecs", ",", "edges", ")", ":", "\n", "        ", "\"\"\"\n        convert 3d features of shape (B, N, d) into 2d features of shape (B*N, d)\n        \"\"\"", "\n", "B", ",", "No", "=", "obj_vecs", ".", "shape", "[", ":", "2", "]", "\n", "obj_vecs", "=", "obj_vecs", ".", "view", "(", "-", "1", ",", "obj_vecs", ".", "size", "(", "-", "1", ")", ")", "\n", "attr_vecs", "=", "attr_vecs", ".", "view", "(", "-", "1", ",", "attr_vecs", ".", "size", "(", "-", "1", ")", ")", "\n", "rela_vecs", "=", "rela_vecs", ".", "view", "(", "-", "1", ",", "rela_vecs", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "# edge: (B, max_rela_num, 2) => (B*max_rela_num, 2)", "\n", "obj_offsets", "=", "edges", ".", "new_tensor", "(", "range", "(", "0", ",", "B", "*", "No", ",", "No", ")", ")", "\n", "edges", "=", "edges", "+", "obj_offsets", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", "\n", "edges", "=", "edges", ".", "view", "(", "-", "1", ",", "edges", ".", "size", "(", "-", "1", ")", ")", "\n", "return", "obj_vecs", ",", "attr_vecs", ",", "rela_vecs", ",", "edges", ",", "(", "B", ",", "No", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.GNN.feat_2d_to_3d": [[107, 116], ["obj_vecs.view.view.view", "attr_vecs.view.view.view", "rela_vecs.view", "rela_vecs.size"], "methods", ["None"], ["", "def", "feat_2d_to_3d", "(", "self", ",", "obj_vecs", ",", "attr_vecs", ",", "rela_vecs", ",", "rela_masks", ",", "ori_shape", ")", ":", "\n", "        ", "\"\"\"\n        convert 2d features of shape (B*N, d) back into 3d features of shape (B, N, d)\n        \"\"\"", "\n", "B", ",", "No", "=", "ori_shape", "\n", "obj_vecs", "=", "obj_vecs", ".", "view", "(", "B", ",", "No", ",", "-", "1", ")", "\n", "attr_vecs", "=", "attr_vecs", ".", "view", "(", "B", ",", "No", ",", "-", "1", ")", "\n", "rela_vecs", "=", "rela_vecs", ".", "view", "(", "B", ",", "-", "1", ",", "rela_vecs", ".", "size", "(", "-", "1", ")", ")", "*", "rela_masks", "\n", "return", "obj_vecs", ",", "attr_vecs", ",", "rela_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel.__init__": [[126, 178], ["CaptionModel.CaptionModel.__init__", "getattr", "VSUAModel.build_embeding_layer", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "VSUAModel.build_embeding_layer", "VSUAModel.build_embeding_layer", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "VSUAModel.GNN", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "VSUAModel.AttModel.init_weights", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "VSUAModel.build_embeding_layer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.LanguageModelCriterion.__init__", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.build_embeding_layer", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.build_embeding_layer", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.build_embeding_layer", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel.init_weights", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.build_embeding_layer"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "AttModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "geometry_relation", "=", "opt", ".", "geometry_relation", "\n", "self", ".", "vocab_size", "=", "opt", ".", "vocab_size", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "num_layers", "=", "opt", ".", "num_layers", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "seq_length", "=", "opt", ".", "seq_length", "\n", "self", ".", "fc_feat_size", "=", "opt", ".", "fc_feat_size", "\n", "self", ".", "att_hid_size", "=", "opt", ".", "att_hid_size", "\n", "self", ".", "seq_per_img", "=", "opt", ".", "seq_per_img", "\n", "self", ".", "use_bn", "=", "getattr", "(", "opt", ",", "'use_bn'", ",", "0", ")", "\n", "self", ".", "att_feat_size", "=", "opt", ".", "att_feat_size", "\n", "if", "opt", ".", "use_box", ":", "\n", "            ", "self", ".", "att_feat_size", "=", "self", ".", "att_feat_size", "+", "5", "# concat box position features", "\n", "", "self", ".", "sg_label_embed_size", "=", "opt", ".", "sg_label_embed_size", "\n", "self", ".", "ss_prob", "=", "0.0", "# Schedule sampling probability", "\n", "\n", "self", ".", "embed", "=", "build_embeding_layer", "(", "self", ".", "vocab_size", "+", "1", ",", "self", ".", "input_encoding_size", ",", "self", ".", "drop_prob_lm", ")", "\n", "self", ".", "fc_embed", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "fc_feat_size", ",", "self", ".", "rnn_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", ")", "\n", "self", ".", "att_embed", "=", "nn", ".", "Sequential", "(", "*", "(", "\n", "(", "(", "nn", ".", "BatchNorm1d", "(", "self", ".", "att_feat_size", ")", ",", ")", "if", "self", ".", "use_bn", "else", "(", ")", ")", "+", "\n", "(", "nn", ".", "Linear", "(", "self", ".", "att_feat_size", ",", "self", ".", "rnn_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", ")", "+", "\n", "(", "(", "nn", ".", "BatchNorm1d", "(", "self", ".", "rnn_size", ")", ",", ")", "if", "self", ".", "use_bn", "==", "2", "else", "(", ")", ")", ")", ")", "\n", "\n", "# lazily use the same vocabulary size for obj, attr and rela embeddings", "\n", "num_objs", "=", "num_attrs", "=", "num_relas", "=", "472", "\n", "self", ".", "obj_embed", "=", "build_embeding_layer", "(", "num_objs", ",", "self", ".", "sg_label_embed_size", ",", "self", ".", "drop_prob_lm", ")", "\n", "self", ".", "attr_embed", "=", "build_embeding_layer", "(", "num_attrs", ",", "self", ".", "sg_label_embed_size", ",", "self", ".", "drop_prob_lm", ")", "\n", "if", "not", "self", ".", "geometry_relation", ":", "\n", "            ", "self", ".", "rela_embed", "=", "build_embeding_layer", "(", "num_relas", ",", "self", ".", "sg_label_embed_size", ",", "self", ".", "drop_prob_lm", ")", "\n", "\n", "", "self", ".", "proj_obj", "=", "nn", ".", "Sequential", "(", "*", "[", "nn", ".", "Linear", "(", "self", ".", "rnn_size", "+", "self", ".", "sg_label_embed_size", "*", "self", ".", "opt", ".", "num_obj_label_use", ",", "\n", "self", ".", "rnn_size", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Dropout", "(", "0.5", ")", "]", ")", "\n", "self", ".", "proj_attr", "=", "nn", ".", "Sequential", "(", "*", "[", "nn", ".", "Linear", "(", "self", ".", "sg_label_embed_size", "*", "3", ",", "self", ".", "rnn_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Dropout", "(", "0.5", ")", "]", ")", "\n", "self", ".", "proj_rela", "=", "nn", ".", "Sequential", "(", "*", "[", "nn", ".", "Linear", "(", "self", ".", "opt", ".", "geometry_rela_feat_dim", "if", "self", ".", "geometry_relation", "else", "self", ".", "sg_label_embed_size", ",", "\n", "self", ".", "rnn_size", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Dropout", "(", "0.5", ")", "]", ")", "\n", "self", ".", "gnn", "=", "GNN", "(", "opt", ")", "\n", "\n", "self", ".", "ctx2att_obj", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "att_hid_size", ")", "\n", "self", ".", "ctx2att_attr", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "att_hid_size", ")", "\n", "self", ".", "ctx2att_rela", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "att_hid_size", ")", "\n", "\n", "self", ".", "logit", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "vocab_size", "+", "1", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel.init_weights": [[179, 186], ["VSUAModel.AttModel.embed[].weight.data.uniform_", "VSUAModel.AttModel.obj_embed[].weight.data.uniform_", "VSUAModel.AttModel.attr_embed[].weight.data.uniform_", "VSUAModel.AttModel.rela_embed[].weight.data.uniform_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "self", ".", "embed", "[", "0", "]", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "obj_embed", "[", "0", "]", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "attr_embed", "[", "0", "]", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "if", "not", "self", ".", "geometry_relation", ":", "\n", "            ", "self", ".", "rela_embed", "[", "0", "]", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel.init_hidden": [[188, 192], ["next", "VSUAModel.AttModel.parameters", "next.new_zeros", "next.new_zeros"], "methods", ["None"], ["", "", "def", "init_hidden", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "weight", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", "\n", "return", "(", "weight", ".", "new_zeros", "(", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "rnn_size", ")", ",", "\n", "weight", ".", "new_zeros", "(", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "rnn_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel._embed_vsu": [[194, 203], ["VSUAModel.AttModel.obj_embed", "VSUAModel.AttModel.attr_embed", "VSUAModel.AttModel.rela_embed"], "methods", ["None"], ["", "def", "_embed_vsu", "(", "self", ",", "obj_labels", ",", "attr_labels", ",", "rela_labels", ")", ":", "\n", "        ", "obj_embed", "=", "self", ".", "obj_embed", "(", "obj_labels", ")", "\n", "attr_embed", "=", "self", ".", "attr_embed", "(", "attr_labels", ")", "\n", "if", "self", ".", "geometry_relation", ":", "\n", "            ", "rela_embed", "=", "rela_labels", "\n", "", "else", ":", "\n", "            ", "rela_embed", "=", "self", ".", "rela_embed", "(", "rela_labels", ")", "\n", "\n", "", "return", "obj_embed", ",", "attr_embed", ",", "rela_embed", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel._proj_vsu": [[204, 217], ["obj_embed.view.view.view", "attr_embed.view", "VSUAModel.AttModel.proj_attr", "VSUAModel.AttModel.proj_rela", "obj_embed.view.view.size", "obj_embed.view.view.size", "VSUAModel.AttModel.proj_obj", "attr_embed.size", "attr_embed.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "_proj_vsu", "(", "self", ",", "obj_embed", ",", "attr_embed", ",", "rela_embed", ",", "att_feats", ")", ":", "\n", "        ", "\"project node features, equation 4-7 in paper\"", "\n", "\n", "# handle multiple object labels", "\n", "obj_embed", "=", "obj_embed", ".", "view", "(", "obj_embed", ".", "size", "(", "0", ")", ",", "obj_embed", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "obj_vecs", "=", "self", ".", "proj_obj", "(", "torch", ".", "cat", "(", "[", "att_feats", ",", "obj_embed", "]", ",", "dim", "=", "-", "1", ")", ")", "+", "att_feats", "\n", "\n", "# handle multiple attribute labels: (128, 3) -> (128*3)", "\n", "attr_vecs", "=", "attr_embed", ".", "view", "(", "attr_embed", ".", "size", "(", "0", ")", ",", "attr_embed", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "attr_vecs", "=", "self", ".", "proj_attr", "(", "attr_vecs", ")", "\n", "\n", "rela_vecs", "=", "self", ".", "proj_rela", "(", "rela_embed", ")", "\n", "return", "obj_vecs", ",", "attr_vecs", ",", "rela_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel._prepare_vsu_features": [[218, 245], ["VSUAModel.AttModel._embed_vsu", "VSUAModel.AttModel._proj_vsu", "VSUAModel.AttModel.gnn", "att_masks.unsqueeze", "rela_masks.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel._embed_vsu", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel._proj_vsu"], ["", "def", "_prepare_vsu_features", "(", "self", ",", "sg_data", ",", "att_feats", ",", "att_masks", ")", ":", "\n", "        ", "\"\"\"\n        prepare node features for each type of visual semantic units (vsus): obj, attr, and rela\n\n        the raw data the are needed:\n            - obj_labels: (B, No, ?)\n            - attr_labels: (B, No, ?)\n            - rela_labels: (B, Nr, ?)\n            - rela_triplets: (subj_index, obj_index, rela_label) of shape (B, Nr, 3)\n            - rela_edges: LongTensor of shape (B, Nr, 2), where rela_edges[b, k] = [i, j] indicates the\n                        presence of the relation triple: ( obj[b][i], rela[b][k], obj[b][j] ),\n                        i.e. the k-th relation of the b-th sample which is between the i-th and j-th objects\n        \"\"\"", "\n", "obj_labels", "=", "sg_data", "[", "'obj_labels'", "]", "\n", "attr_labels", "=", "sg_data", "[", "'attr_labels'", "]", "\n", "rela_masks", "=", "sg_data", "[", "'rela_masks'", "]", "\n", "rela_edges", ",", "rela_labels", "=", "sg_data", "[", "'rela_edges'", "]", ",", "sg_data", "[", "'rela_feats'", "]", "\n", "\n", "att_masks", ",", "rela_masks", "=", "att_masks", ".", "unsqueeze", "(", "-", "1", ")", ",", "rela_masks", ".", "unsqueeze", "(", "-", "1", ")", "\n", "# node features", "\n", "obj_embed", ",", "attr_embed", ",", "rela_embed", "=", "self", ".", "_embed_vsu", "(", "obj_labels", ",", "attr_labels", ",", "rela_labels", ")", "\n", "# project node features to the same size as att_feats", "\n", "obj_vecs", ",", "attr_vecs", ",", "rela_vecs", "=", "self", ".", "_proj_vsu", "(", "obj_embed", ",", "attr_embed", ",", "rela_embed", ",", "att_feats", ")", "\n", "# node embedding with simple gnns", "\n", "obj_vecs", ",", "attr_vecs", ",", "rela_vecs", "=", "self", ".", "gnn", "(", "obj_vecs", ",", "attr_vecs", ",", "rela_vecs", ",", "rela_edges", ",", "rela_masks", ")", "\n", "\n", "return", "obj_vecs", ",", "attr_vecs", ",", "rela_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel.prepare_core_args": [[247, 268], ["VSUAModel.AttModel.fc_embed", "VSUAModel.pack_wrapper", "VSUAModel.AttModel._prepare_vsu_features", "VSUAModel.AttModel.ctx2att_obj", "VSUAModel.AttModel.ctx2att_attr", "VSUAModel.AttModel.ctx2att_rela"], "methods", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.pack_wrapper", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel._prepare_vsu_features"], ["", "def", "prepare_core_args", "(", "self", ",", "sg_data", ",", "fc_feats", ",", "att_feats", ",", "att_masks", ")", ":", "\n", "        ", "rela_masks", "=", "sg_data", "[", "'rela_masks'", "]", "\n", "# embed fc and att features", "\n", "fc_feats", "=", "self", ".", "fc_embed", "(", "fc_feats", ")", "\n", "att_feats", "=", "pack_wrapper", "(", "self", ".", "att_embed", ",", "att_feats", ",", "att_masks", ")", "\n", "\n", "obj_feats", ",", "attr_feats", ",", "rela_feats", "=", "self", ".", "_prepare_vsu_features", "(", "sg_data", ",", "att_feats", ",", "att_masks", ")", "\n", "\n", "# Project the attention feats first to reduce memory and computation consumptions", "\n", "p_obj_feats", "=", "p_attr_feats", "=", "p_rela_feats", "=", "[", "]", "\n", "if", "'o'", "in", "self", ".", "opt", ".", "vsua_use", ":", "\n", "            ", "p_obj_feats", "=", "self", ".", "ctx2att_obj", "(", "obj_feats", ")", "\n", "", "if", "'a'", "in", "self", ".", "opt", ".", "vsua_use", ":", "\n", "            ", "p_attr_feats", "=", "self", ".", "ctx2att_attr", "(", "attr_feats", ")", "\n", "", "if", "'r'", "in", "self", ".", "opt", ".", "vsua_use", ":", "\n", "            ", "p_rela_feats", "=", "self", ".", "ctx2att_rela", "(", "rela_feats", ")", "\n", "\n", "", "core_args", "=", "[", "fc_feats", ",", "att_feats", ",", "obj_feats", ",", "attr_feats", ",", "rela_feats", ",", "p_obj_feats", ",", "p_attr_feats", ",", "p_rela_feats", ",", "att_masks", ",", "rela_masks", "]", "\n", "return", "core_args", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel._forward": [[270, 301], ["VSUAModel.AttModel.prepare_core_args", "misc.utils.expand_feats", "VSUAModel.AttModel.init_hidden", "fc_feats.new_zeros", "range", "fc_feats.size", "VSUAModel.AttModel.get_logprobs_state", "seq.size", "seq.size", "fc_feats.new().uniform_", "seq[].clone", "sample_mask.sum", "seq[].clone", "sample_mask.nonzero().view", "seq[].data.clone", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "seq[].data.clone.index_copy_", "seq[].sum", "fc_feats.new", "outputs[].detach", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "sample_mask.nonzero", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial"], "methods", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel.prepare_core_args", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.expand_feats", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel.init_hidden", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel.get_logprobs_state"], ["", "def", "_forward", "(", "self", ",", "sg_data", ",", "fc_feats", ",", "att_feats", ",", "seq", ",", "att_masks", "=", "None", ")", ":", "\n", "        ", "core_args", "=", "self", ".", "prepare_core_args", "(", "sg_data", ",", "fc_feats", ",", "att_feats", ",", "att_masks", ")", "\n", "# make seq_per_img copies of the encoded inputs:  shape: (B, ...) => (B*seq_per_image, ...)", "\n", "core_args", "=", "expand_feats", "(", "core_args", ",", "self", ".", "seq_per_img", ")", "\n", "\n", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "*", "self", ".", "seq_per_img", "\n", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "outputs", "=", "fc_feats", ".", "new_zeros", "(", "batch_size", ",", "seq", ".", "size", "(", "1", ")", "-", "1", ",", "self", ".", "vocab_size", "+", "1", ")", "\n", "# teacher forcing", "\n", "for", "i", "in", "range", "(", "seq", ".", "size", "(", "1", ")", "-", "1", ")", ":", "\n", "# scheduled sampling", "\n", "            ", "if", "self", ".", "training", "and", "i", ">=", "1", "and", "self", ".", "ss_prob", ">", "0.0", ":", "\n", "                ", "sample_prob", "=", "fc_feats", ".", "new", "(", "batch_size", ")", ".", "uniform_", "(", "0", ",", "1", ")", "\n", "sample_mask", "=", "sample_prob", "<", "self", ".", "ss_prob", "\n", "if", "sample_mask", ".", "sum", "(", ")", "==", "0", ":", "\n", "                    ", "it", "=", "seq", "[", ":", ",", "i", "]", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "                    ", "sample_ind", "=", "sample_mask", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "it", "=", "seq", "[", ":", ",", "i", "]", ".", "data", ".", "clone", "(", ")", "\n", "prob_prev", "=", "torch", ".", "exp", "(", "outputs", "[", ":", ",", "i", "-", "1", "]", ".", "detach", "(", ")", ")", "# fetch prev distribution: shape Nx(M+1)", "\n", "it", ".", "index_copy_", "(", "0", ",", "sample_ind", ",", "torch", ".", "multinomial", "(", "prob_prev", ",", "1", ")", ".", "view", "(", "-", "1", ")", ".", "index_select", "(", "0", ",", "sample_ind", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "it", "=", "seq", "[", ":", ",", "i", "]", ".", "clone", "(", ")", "\n", "# break if all the sequences end", "\n", "", "if", "i", ">=", "1", "and", "seq", "[", ":", ",", "i", "]", ".", "sum", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "output", ",", "state", "=", "self", ".", "get_logprobs_state", "(", "it", ",", "state", ",", "core_args", ")", "\n", "outputs", "[", ":", ",", "i", "]", "=", "output", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel.get_logprobs_state": [[302, 310], ["VSUAModel.AttModel.embed", "VSUAModel.AttModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "VSUAModel.AttModel.logit"], "methods", ["None"], ["", "def", "get_logprobs_state", "(", "self", ",", "it", ",", "state", ",", "core_args", ")", ":", "\n", "# 'it' contains a word index", "\n", "        ", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "state", ",", "core_args", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "output", ")", ",", "dim", "=", "1", ")", "\n", "\n", "return", "logprobs", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel._sample": [[312, 383], ["opt.get", "opt.get", "opt.get", "opt.get", "opt.get", "opt.get", "VSUAModel.AttModel.init_hidden", "fc_feats.new_zeros", "fc_feats.new_zeros", "range", "VSUAModel.AttModel._sample_beam", "VSUAModel.AttModel.prepare_core_args", "misc.utils.expand_feats", "fc_feats.size", "VSUAModel.AttModel.get_logprobs_state", "logprobs.gather.view", "returns.append", "fc_feats.size", "fc_feats.new_zeros", "logprobs.new_zeros", "logprobs.new_zeros.scatter_", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "it.view().long.view().long.view().long", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "logprobs.gather", "it.view().long.view().long.view().long", "unfinished.type_as", "unfinished.sum", "logprobs.size", "seq[].data.unsqueeze", "float", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "it.view().long.view().long.view", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "it.view().long.view().long.view"], "methods", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel.init_hidden", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel._sample_beam", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel.prepare_core_args", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.expand_feats", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel.get_logprobs_state"], ["", "def", "_sample", "(", "self", ",", "sg_data", ",", "fc_feats", ",", "att_feats", ",", "att_masks", "=", "None", ",", "opt", "=", "{", "}", ",", "_core_args", "=", "None", ")", ":", "\n", "        ", "sample_max", "=", "opt", ".", "get", "(", "'sample_max'", ",", "1", ")", "\n", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "1", ")", "\n", "temperature", "=", "opt", ".", "get", "(", "'temperature'", ",", "1.0", ")", "\n", "decoding_constraint", "=", "opt", ".", "get", "(", "'decoding_constraint'", ",", "0", ")", "\n", "return_core_args", "=", "opt", ".", "get", "(", "'return_core_args'", ",", "False", ")", "\n", "expand_features", "=", "opt", ".", "get", "(", "'expand_features'", ",", "True", ")", "\n", "\n", "if", "beam_size", ">", "1", ":", "\n", "            ", "return", "self", ".", "_sample_beam", "(", "sg_data", ",", "fc_feats", ",", "att_feats", ",", "att_masks", ",", "opt", ")", "\n", "", "if", "_core_args", "is", "not", "None", ":", "\n", "# reuse the core_args calculated during generating sampled captions", "\n", "# when generating greedy captions for SCST,", "\n", "            ", "core_args", "=", "_core_args", "\n", "", "else", ":", "\n", "            ", "core_args", "=", "self", ".", "prepare_core_args", "(", "sg_data", ",", "fc_feats", ",", "att_feats", ",", "att_masks", ")", "\n", "\n", "# make seq_per_img copies of the encoded inputs:  shape: (B, ...) => (B*seq_per_image, ...)", "\n", "# should be True when training (xe or scst), False when evaluation", "\n", "", "if", "expand_features", ":", "\n", "            ", "if", "return_core_args", ":", "\n", "                ", "_core_args", "=", "core_args", "\n", "", "core_args", "=", "expand_feats", "(", "core_args", ",", "self", ".", "seq_per_img", ")", "\n", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "*", "self", ".", "opt", ".", "seq_per_img", "\n", "", "else", ":", "\n", "            ", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "\n", "", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "seq", "=", "fc_feats", ".", "new_zeros", "(", "(", "batch_size", ",", "self", ".", "seq_length", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "seqLogprobs", "=", "fc_feats", ".", "new_zeros", "(", "batch_size", ",", "self", ".", "seq_length", ")", "\n", "for", "t", "in", "range", "(", "self", ".", "seq_length", "+", "1", ")", ":", "\n", "            ", "if", "t", "==", "0", ":", "# input <bos>", "\n", "                ", "it", "=", "fc_feats", ".", "new_zeros", "(", "batch_size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "", "logprobs", ",", "state", "=", "self", ".", "get_logprobs_state", "(", "it", ",", "state", ",", "core_args", ")", "\n", "if", "decoding_constraint", "and", "t", ">", "0", ":", "\n", "                ", "tmp", "=", "logprobs", ".", "new_zeros", "(", "logprobs", ".", "size", "(", ")", ")", "\n", "tmp", ".", "scatter_", "(", "1", ",", "seq", "[", ":", ",", "t", "-", "1", "]", ".", "data", ".", "unsqueeze", "(", "1", ")", ",", "float", "(", "'-inf'", ")", ")", "\n", "logprobs", "=", "logprobs", "+", "tmp", "\n", "# sample the next word", "\n", "", "if", "t", "==", "self", ".", "seq_length", ":", "# skip if we achieve maximum length", "\n", "                ", "break", "\n", "", "if", "sample_max", ":", "\n", "                ", "sampleLogprobs", ",", "it", "=", "torch", ".", "max", "(", "logprobs", ".", "data", ",", "1", ")", "\n", "it", "=", "it", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "                ", "if", "temperature", "==", "1.0", ":", "\n", "                    ", "prob_prev", "=", "torch", ".", "exp", "(", "logprobs", ".", "data", ")", "# fetch prev distribution: shape Nx(M+1)", "\n", "", "else", ":", "\n", "# scale logprobs by temperature", "\n", "                    ", "prob_prev", "=", "torch", ".", "exp", "(", "torch", ".", "div", "(", "logprobs", ".", "data", ",", "temperature", ")", ")", "\n", "", "it", "=", "torch", ".", "multinomial", "(", "prob_prev", ",", "1", ")", "\n", "sampleLogprobs", "=", "logprobs", ".", "gather", "(", "1", ",", "it", ")", "# gather the logprobs at sampled positions", "\n", "it", "=", "it", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "# and flatten indices for downstream processing", "\n", "\n", "# stop when all finished", "\n", "", "if", "t", "==", "0", ":", "\n", "                ", "unfinished", "=", "it", ">", "0", "\n", "", "else", ":", "\n", "                ", "unfinished", "=", "unfinished", "*", "(", "it", ">", "0", ")", "\n", "", "it", "=", "it", "*", "unfinished", ".", "type_as", "(", "it", ")", "\n", "seq", "[", ":", ",", "t", "]", "=", "it", "\n", "seqLogprobs", "[", ":", ",", "t", "]", "=", "sampleLogprobs", ".", "view", "(", "-", "1", ")", "\n", "# quit loop if all sequences have finished", "\n", "if", "unfinished", ".", "sum", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "", "returns", "=", "[", "seq", ",", "seqLogprobs", "]", "\n", "if", "return_core_args", ":", "\n", "            ", "returns", ".", "append", "(", "_core_args", ")", "\n", "", "return", "returns", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel._sample_beam": [[386, 420], ["opt.get", "fc_feats.size", "VSUAModel.AttModel.prepare_core_args", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "range", "VSUAModel.AttModel.init_hidden", "misc.utils.expand_feats", "range", "VSUAModel.AttModel.beam_search", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "VSUAModel.AttModel.get_logprobs_state", "misc.utils.expand_feats.append", "misc.utils.expand_feats.append", "fc_feats.new_zeros", "type"], "methods", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel.prepare_core_args", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel.init_hidden", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.expand_feats", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.CaptionModel.CaptionModel.beam_search", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.AttModel.get_logprobs_state"], ["", "def", "_sample_beam", "(", "self", ",", "sg_data", ",", "fc_feats", ",", "att_feats", ",", "att_masks", "=", "None", ",", "opt", "=", "{", "}", ")", ":", "\n", "        ", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "10", ")", "\n", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "\n", "core_args", "=", "self", ".", "prepare_core_args", "(", "sg_data", ",", "fc_feats", ",", "att_feats", ",", "att_masks", ")", "\n", "\n", "assert", "beam_size", "<=", "self", ".", "vocab_size", "+", "1", ",", "'lets assume this for now, otherwise this corner case causes a few headaches down the road. can be dealt with in future if needed'", "\n", "seq", "=", "torch", ".", "LongTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", ".", "zero_", "(", ")", "\n", "seqLogprobs", "=", "torch", ".", "FloatTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", "\n", "# lets process every image independently for now, for simplicity", "\n", "\n", "self", ".", "done_beams", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "for", "k", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "state", "=", "self", ".", "init_hidden", "(", "beam_size", ")", "\n", "sample_core_args", "=", "[", "]", "\n", "for", "item", "in", "core_args", ":", "\n", "                ", "if", "type", "(", "item", ")", "is", "list", "or", "item", "is", "None", ":", "\n", "                    ", "sample_core_args", ".", "append", "(", "item", ")", "\n", "continue", "\n", "", "else", ":", "\n", "                    ", "sample_core_args", ".", "append", "(", "item", "[", "k", ":", "k", "+", "1", "]", ")", "\n", "", "", "sample_core_args", "=", "expand_feats", "(", "sample_core_args", ",", "beam_size", ")", "\n", "\n", "for", "t", "in", "range", "(", "1", ")", ":", "\n", "                ", "if", "t", "==", "0", ":", "# input <bos>", "\n", "                    ", "it", "=", "fc_feats", ".", "new_zeros", "(", "[", "beam_size", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "", "logprobs", ",", "state", "=", "self", ".", "get_logprobs_state", "(", "it", ",", "state", ",", "sample_core_args", ")", "\n", "\n", "", "self", ".", "done_beams", "[", "k", "]", "=", "self", ".", "beam_search", "(", "state", ",", "logprobs", ",", "sample_core_args", ",", "opt", "=", "opt", ")", "\n", "seq", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'seq'", "]", "# the first beam has highest cumulative score", "\n", "seqLogprobs", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'logps'", "]", "\n", "# return the samples and their log likelihoods", "\n", "", "return", "seq", ".", "transpose", "(", "0", ",", "1", ")", ",", "seqLogprobs", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.VSUACore.__init__": [[423, 439], ["torch.Module.__init__", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "VSUAModel.Attention", "VSUAModel.Attention", "VSUAModel.Attention", "len"], "methods", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.LanguageModelCriterion.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "use_maxout", "=", "False", ")", ":", "\n", "        ", "super", "(", "VSUACore", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "\n", "self", ".", "att_lstm", "=", "nn", ".", "LSTMCell", "(", "opt", ".", "input_encoding_size", "+", "opt", ".", "rnn_size", "*", "2", ",", "opt", ".", "rnn_size", ")", "# we, fc, h^2_t-1", "\n", "\n", "lang_lstm_in_dim", "=", "opt", ".", "rnn_size", "*", "(", "1", "+", "len", "(", "self", ".", "opt", ".", "vsua_use", ")", ")", "\n", "self", ".", "lang_lstm", "=", "nn", ".", "LSTMCell", "(", "lang_lstm_in_dim", ",", "opt", ".", "rnn_size", ")", "# h^1_t, \\hat v", "\n", "\n", "if", "'o'", "in", "self", ".", "opt", ".", "vsua_use", ":", "\n", "            ", "self", ".", "attention_obj", "=", "Attention", "(", "opt", ")", "\n", "", "if", "'a'", "in", "self", ".", "opt", ".", "vsua_use", ":", "\n", "            ", "self", ".", "attention_attr", "=", "Attention", "(", "opt", ")", "\n", "", "if", "'r'", "in", "self", ".", "opt", ".", "vsua_use", ":", "\n", "            ", "self", ".", "attention_rela", "=", "Attention", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.VSUACore.forward": [[441, 467], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "VSUAModel.VSUACore.att_lstm", "VSUAModel.VSUACore.lang_lstm", "torch.dropout", "torch.dropout", "torch.dropout", "VSUAModel.VSUACore.attention_obj", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "VSUAModel.VSUACore.attention_attr", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "VSUAModel.VSUACore.attention_rela", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "xt", ",", "state", ",", "core_args", ")", ":", "\n", "        ", "fc_feats", ",", "att_feats", ",", "obj_feats", ",", "attr_feats", ",", "rela_feats", ",", "p_obj_feats", ",", "p_attr_feats", ",", "p_rela_feats", ",", "att_masks", ",", "rela_masks", "=", "core_args", "\n", "prev_h", "=", "state", "[", "0", "]", "[", "-", "1", "]", "\n", "att_lstm_input", "=", "torch", ".", "cat", "(", "[", "prev_h", ",", "fc_feats", ",", "xt", "]", ",", "1", ")", "\n", "h_att", ",", "c_att", "=", "self", ".", "att_lstm", "(", "att_lstm_input", ",", "(", "state", "[", "0", "]", "[", "0", "]", ",", "state", "[", "1", "]", "[", "0", "]", ")", ")", "\n", "\n", "lang_lstm_input", "=", "h_att", "\n", "if", "'o'", "in", "self", ".", "opt", ".", "vsua_use", ":", "\n", "            ", "att_obj", "=", "self", ".", "attention_obj", "(", "h_att", ",", "obj_feats", ",", "p_obj_feats", ",", "att_masks", ")", "\n", "lang_lstm_input", "=", "torch", ".", "cat", "(", "[", "lang_lstm_input", ",", "att_obj", "]", ",", "1", ")", "\n", "\n", "", "if", "'a'", "in", "self", ".", "opt", ".", "vsua_use", ":", "\n", "            ", "att_attr", "=", "self", ".", "attention_attr", "(", "h_att", ",", "attr_feats", ",", "p_attr_feats", ",", "att_masks", ")", "\n", "lang_lstm_input", "=", "torch", ".", "cat", "(", "[", "lang_lstm_input", ",", "att_attr", "]", ",", "1", ")", "\n", "\n", "", "if", "'r'", "in", "self", ".", "opt", ".", "vsua_use", ":", "\n", "            ", "att_rela", "=", "self", ".", "attention_rela", "(", "h_att", ",", "rela_feats", ",", "p_rela_feats", ",", "rela_masks", ")", "\n", "lang_lstm_input", "=", "torch", ".", "cat", "(", "[", "lang_lstm_input", ",", "att_rela", "]", ",", "1", ")", "\n", "\n", "", "h_lang", ",", "c_lang", "=", "self", ".", "lang_lstm", "(", "lang_lstm_input", ",", "(", "state", "[", "0", "]", "[", "1", "]", ",", "state", "[", "1", "]", "[", "1", "]", ")", ")", "\n", "\n", "output", "=", "F", ".", "dropout", "(", "h_lang", ",", "self", ".", "drop_prob_lm", ",", "self", ".", "training", ")", "\n", "state", "=", "(", "torch", ".", "stack", "(", "[", "h_att", ",", "h_lang", "]", ")", ",", "torch", ".", "stack", "(", "[", "c_att", ",", "c_lang", "]", ")", ")", "\n", "return", "output", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.Attention.__init__": [[471, 479], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.LanguageModelCriterion.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "att_hid_size", "=", "opt", ".", "att_hid_size", "\n", "self", ".", "query_dim", "=", "self", ".", "rnn_size", "\n", "self", ".", "h2att", "=", "nn", ".", "Linear", "(", "self", ".", "query_dim", ",", "self", ".", "att_hid_size", ")", "\n", "self", ".", "alpha_net", "=", "nn", ".", "Linear", "(", "self", ".", "att_hid_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.Attention.forward": [[481, 501], ["p_att_feats.view", "VSUAModel.Attention.h2att", "att_h.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "dot.view.view.view", "VSUAModel.Attention.alpha_net", "dot.view.view.view", "torch.softmax", "torch.softmax", "torch.softmax", "att_feats.view", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "att_feats.size", "att_feats.size", "att_feats.numel", "att_feats.size", "att_h.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze", "att_masks.view().float", "torch.softmax.sum", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax.unsqueeze", "att_masks.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h", ",", "att_feats", ",", "p_att_feats", ",", "att_masks", "=", "None", ")", ":", "\n", "# The p_att_feats here is already projected", "\n", "        ", "att_size", "=", "att_feats", ".", "numel", "(", ")", "//", "att_feats", ".", "size", "(", "0", ")", "//", "att_feats", ".", "size", "(", "-", "1", ")", "\n", "att", "=", "p_att_feats", ".", "view", "(", "-", "1", ",", "att_size", ",", "self", ".", "att_hid_size", ")", "\n", "\n", "att_h", "=", "self", ".", "h2att", "(", "h", ")", "# batch * att_hid_size", "\n", "att_h", "=", "att_h", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "att", ")", "# batch * att_size * att_hid_size", "\n", "dot", "=", "att", "+", "att_h", "# batch * att_size * att_hid_size", "\n", "dot", "=", "torch", ".", "tanh", "(", "dot", ")", "# batch * att_size * att_hid_size", "\n", "dot", "=", "dot", ".", "view", "(", "-", "1", ",", "self", ".", "att_hid_size", ")", "# (batch * att_size) * att_hid_size", "\n", "dot", "=", "self", ".", "alpha_net", "(", "dot", ")", "# (batch * att_size) * 1", "\n", "dot", "=", "dot", ".", "view", "(", "-", "1", ",", "att_size", ")", "# batch * att_size", "\n", "\n", "weight", "=", "F", ".", "softmax", "(", "dot", ",", "dim", "=", "1", ")", "# batch * att_size", "\n", "if", "att_masks", "is", "not", "None", ":", "\n", "            ", "weight", "=", "weight", "*", "att_masks", ".", "view", "(", "-", "1", ",", "att_size", ")", ".", "float", "(", ")", "\n", "weight", "=", "weight", "/", "weight", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "# normalize to 1", "\n", "", "att_feats_", "=", "att_feats", ".", "view", "(", "-", "1", ",", "att_size", ",", "att_feats", ".", "size", "(", "-", "1", ")", ")", "# batch * att_size * att_feat_size", "\n", "att_res", "=", "torch", ".", "bmm", "(", "weight", ".", "unsqueeze", "(", "1", ")", ",", "att_feats_", ")", ".", "squeeze", "(", "1", ")", "# batch * att_feat_size", "\n", "return", "att_res", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.VSUAModel.__init__": [[505, 509], ["VSUAModel.AttModel.__init__", "VSUAModel.VSUACore"], "methods", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.LanguageModelCriterion.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "VSUAModel", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "self", ".", "num_layers", "=", "2", "\n", "self", ".", "core", "=", "VSUACore", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.sort_pack_padded_sequence": [[18, 24], ["torch.sort", "torch.sort", "torch.sort", "torch.nn.utils.rnn.pack_padded_sequence", "indices.clone", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange", "torch.arange", "torch.arange", "len"], "function", ["None"], ["def", "sort_pack_padded_sequence", "(", "input", ",", "lengths", ")", ":", "\n", "    ", "sorted_lengths", ",", "indices", "=", "torch", ".", "sort", "(", "lengths", ",", "descending", "=", "True", ")", "\n", "tmp", "=", "pack_padded_sequence", "(", "input", "[", "indices", "]", ",", "sorted_lengths", ",", "batch_first", "=", "True", ")", "\n", "inv_ix", "=", "indices", ".", "clone", "(", ")", "\n", "inv_ix", "[", "indices", "]", "=", "torch", ".", "arange", "(", "0", ",", "len", "(", "indices", ")", ")", ".", "type_as", "(", "inv_ix", ")", "\n", "return", "tmp", ",", "inv_ix", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.pad_unsort_packed_sequence": [[25, 29], ["torch.nn.utils.rnn.pad_packed_sequence"], "function", ["None"], ["", "def", "pad_unsort_packed_sequence", "(", "input", ",", "inv_ix", ")", ":", "\n", "    ", "tmp", ",", "_", "=", "pad_packed_sequence", "(", "input", ",", "batch_first", "=", "True", ")", "\n", "tmp", "=", "tmp", "[", "inv_ix", "]", "\n", "return", "tmp", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.pack_wrapper": [[30, 36], ["VSUAModel.sort_pack_padded_sequence", "VSUAModel.pad_unsort_packed_sequence", "module", "att_masks.data.long().sum", "torch.nn.utils.rnn.PackedSequence", "module", "att_masks.data.long"], "function", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.sort_pack_padded_sequence", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.pad_unsort_packed_sequence"], ["", "def", "pack_wrapper", "(", "module", ",", "att_feats", ",", "att_masks", ")", ":", "\n", "    ", "if", "att_masks", "is", "not", "None", ":", "\n", "        ", "packed", ",", "inv_ix", "=", "sort_pack_padded_sequence", "(", "att_feats", ",", "att_masks", ".", "data", ".", "long", "(", ")", ".", "sum", "(", "1", ")", ")", "\n", "return", "pad_unsort_packed_sequence", "(", "PackedSequence", "(", "module", "(", "packed", "[", "0", "]", ")", ",", "packed", "[", "1", "]", ")", ",", "inv_ix", ")", "\n", "", "else", ":", "\n", "        ", "return", "module", "(", "att_feats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.VSUAModel.build_embeding_layer": [[118, 123], ["torch.Sequential", "torch.Embedding", "torch.ReLU", "torch.Dropout"], "function", ["None"], ["", "", "def", "build_embeding_layer", "(", "vocab_size", ",", "dim", ",", "drop_prob", ")", ":", "\n", "    ", "embed", "=", "nn", ".", "Sequential", "(", "nn", ".", "Embedding", "(", "vocab_size", ",", "dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "drop_prob", ")", ")", "\n", "return", "embed", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.CaptionModel.CaptionModel.__init__": [[14, 16], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.LanguageModelCriterion.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "CaptionModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.CaptionModel.CaptionModel.forward": [[21, 26], ["kwargs.get", "getattr"], "methods", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get"], ["", "def", "forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "mode", "=", "kwargs", ".", "get", "(", "'mode'", ",", "'forward'", ")", "\n", "if", "'mode'", "in", "kwargs", ":", "\n", "            ", "del", "kwargs", "[", "'mode'", "]", "\n", "", "return", "getattr", "(", "self", ",", "'_'", "+", "mode", ")", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.CaptionModel.CaptionModel.beam_search": [[27, 172], ["opt.get", "opt.get", "opt.get", "opt.get", "opt.get", "list", "list", "range", "reduce", "logprobs_table[].data.float.clone", "range", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "min", "range", "sorted", "range", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "list", "init_logprobs.chunk", "range", "range", "ys.size", "range", "_.clone", "beam_seq[].clone", "beam_seq_logprobs[].clone", "range", "range", "range", "range", "range", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.stack().chunk", "torch.stack().chunk", "torch.stack().chunk", "torch.stack().chunk", "_.chunk", "range", "sorted", "range", "range", "ys[].item", "sorted.append", "len", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "range", "logprobs_table[].data.float", "CaptionModel.CaptionModel.beam_search.add_diversity"], "methods", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.dataloader.BlobFetcher.get"], ["", "def", "beam_search", "(", "self", ",", "init_state", ",", "init_logprobs", ",", "core_args", ",", "**", "kwargs", ")", ":", "\n", "\n", "# function computes the similarity score to be augmented", "\n", "        ", "def", "add_diversity", "(", "beam_seq_table", ",", "logprobsf", ",", "t", ",", "divm", ",", "diversity_lambda", ",", "bdash", ")", ":", "\n", "            ", "local_time", "=", "t", "-", "divm", "\n", "unaug_logprobsf", "=", "logprobsf", ".", "clone", "(", ")", "\n", "for", "prev_choice", "in", "range", "(", "divm", ")", ":", "\n", "                ", "prev_decisions", "=", "beam_seq_table", "[", "prev_choice", "]", "[", "local_time", "]", "\n", "for", "sub_beam", "in", "range", "(", "bdash", ")", ":", "\n", "                    ", "for", "prev_labels", "in", "range", "(", "bdash", ")", ":", "\n", "                        ", "logprobsf", "[", "sub_beam", "]", "[", "prev_decisions", "[", "prev_labels", "]", "]", "=", "logprobsf", "[", "sub_beam", "]", "[", "prev_decisions", "[", "prev_labels", "]", "]", "-", "diversity_lambda", "\n", "", "", "", "return", "unaug_logprobsf", "\n", "\n", "# does one step of classical beam search", "\n", "\n", "", "def", "beam_step", "(", "logprobsf", ",", "unaug_logprobsf", ",", "beam_size", ",", "t", ",", "beam_seq", ",", "beam_seq_logprobs", ",", "beam_logprobs_sum", ",", "state", ")", ":", "\n", "#INPUTS:", "\n", "#logprobsf: probabilities augmented after diversity", "\n", "#beam_size: obvious", "\n", "#t        : time instant", "\n", "#beam_seq : tensor contanining the beams", "\n", "#beam_seq_logprobs: tensor contanining the beam logprobs", "\n", "#beam_logprobs_sum: tensor contanining joint logprobs", "\n", "#OUPUTS:", "\n", "#beam_seq : tensor containing the word indices of the decoded captions", "\n", "#beam_seq_logprobs : log-probability of each decision made, same size as beam_seq", "\n", "#beam_logprobs_sum : joint log-probability of each beam", "\n", "\n", "            ", "ys", ",", "ix", "=", "torch", ".", "sort", "(", "logprobsf", ",", "1", ",", "True", ")", "\n", "candidates", "=", "[", "]", "\n", "cols", "=", "min", "(", "beam_size", ",", "ys", ".", "size", "(", "1", ")", ")", "\n", "rows", "=", "beam_size", "\n", "if", "t", "==", "0", ":", "\n", "                ", "rows", "=", "1", "\n", "", "for", "c", "in", "range", "(", "cols", ")", ":", "# for each column (word, essentially)", "\n", "                ", "for", "q", "in", "range", "(", "rows", ")", ":", "# for each beam expansion", "\n", "#compute logprob of expanding beam q with word in (sorted) position c", "\n", "                    ", "local_logprob", "=", "ys", "[", "q", ",", "c", "]", ".", "item", "(", ")", "\n", "candidate_logprob", "=", "beam_logprobs_sum", "[", "q", "]", "+", "local_logprob", "\n", "local_unaug_logprob", "=", "unaug_logprobsf", "[", "q", ",", "ix", "[", "q", ",", "c", "]", "]", "\n", "candidates", ".", "append", "(", "{", "'c'", ":", "ix", "[", "q", ",", "c", "]", ",", "'q'", ":", "q", ",", "'p'", ":", "candidate_logprob", ",", "'r'", ":", "local_unaug_logprob", "}", ")", "\n", "", "", "candidates", "=", "sorted", "(", "candidates", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "'p'", "]", ")", "\n", "\n", "new_state", "=", "[", "_", ".", "clone", "(", ")", "for", "_", "in", "state", "]", "\n", "#beam_seq_prev, beam_seq_logprobs_prev", "\n", "if", "t", ">=", "1", ":", "\n", "#we''ll need these as reference when we fork beams around", "\n", "                ", "beam_seq_prev", "=", "beam_seq", "[", ":", "t", "]", ".", "clone", "(", ")", "\n", "beam_seq_logprobs_prev", "=", "beam_seq_logprobs", "[", ":", "t", "]", ".", "clone", "(", ")", "\n", "", "for", "vix", "in", "range", "(", "beam_size", ")", ":", "\n", "                ", "v", "=", "candidates", "[", "vix", "]", "\n", "#fork beam index q into index vix", "\n", "if", "t", ">=", "1", ":", "\n", "                    ", "beam_seq", "[", ":", "t", ",", "vix", "]", "=", "beam_seq_prev", "[", ":", ",", "v", "[", "'q'", "]", "]", "\n", "beam_seq_logprobs", "[", ":", "t", ",", "vix", "]", "=", "beam_seq_logprobs_prev", "[", ":", ",", "v", "[", "'q'", "]", "]", "\n", "#rearrange recurrent states", "\n", "", "for", "state_ix", "in", "range", "(", "len", "(", "new_state", ")", ")", ":", "\n", "#  copy over state in previous beam q to new beam at vix", "\n", "                    ", "new_state", "[", "state_ix", "]", "[", ":", ",", "vix", "]", "=", "state", "[", "state_ix", "]", "[", ":", ",", "v", "[", "'q'", "]", "]", "# dimension one is time step", "\n", "#append new end terminal at the end of this beam", "\n", "", "beam_seq", "[", "t", ",", "vix", "]", "=", "v", "[", "'c'", "]", "# c'th word is the continuation", "\n", "beam_seq_logprobs", "[", "t", ",", "vix", "]", "=", "v", "[", "'r'", "]", "# the raw logprob here", "\n", "beam_logprobs_sum", "[", "vix", "]", "=", "v", "[", "'p'", "]", "# the new (sum) logprob along this beam", "\n", "", "state", "=", "new_state", "\n", "return", "beam_seq", ",", "beam_seq_logprobs", ",", "beam_logprobs_sum", ",", "state", ",", "candidates", "\n", "\n", "# Start diverse_beam_search", "\n", "", "opt", "=", "kwargs", "[", "'opt'", "]", "\n", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "10", ")", "\n", "group_size", "=", "opt", ".", "get", "(", "'group_size'", ",", "1", ")", "\n", "diversity_lambda", "=", "opt", ".", "get", "(", "'diversity_lambda'", ",", "0.5", ")", "\n", "decoding_constraint", "=", "opt", ".", "get", "(", "'decoding_constraint'", ",", "0", ")", "\n", "max_ppl", "=", "opt", ".", "get", "(", "'max_ppl'", ",", "0", ")", "\n", "bdash", "=", "beam_size", "//", "group_size", "# beam per group", "\n", "\n", "# INITIALIZATIONS", "\n", "beam_seq_table", "=", "[", "torch", ".", "LongTensor", "(", "self", ".", "seq_length", ",", "bdash", ")", ".", "zero_", "(", ")", "for", "_", "in", "range", "(", "group_size", ")", "]", "\n", "beam_seq_logprobs_table", "=", "[", "torch", ".", "FloatTensor", "(", "self", ".", "seq_length", ",", "bdash", ")", ".", "zero_", "(", ")", "for", "_", "in", "range", "(", "group_size", ")", "]", "\n", "beam_logprobs_sum_table", "=", "[", "torch", ".", "zeros", "(", "bdash", ")", "for", "_", "in", "range", "(", "group_size", ")", "]", "\n", "\n", "# logprobs # logprobs predicted in last time step, shape (beam_size, vocab_size+1)", "\n", "done_beams_table", "=", "[", "[", "]", "for", "_", "in", "range", "(", "group_size", ")", "]", "\n", "state_table", "=", "[", "list", "(", "torch", ".", "unbind", "(", "_", ")", ")", "for", "_", "in", "torch", ".", "stack", "(", "init_state", ")", ".", "chunk", "(", "group_size", ",", "2", ")", "]", "\n", "logprobs_table", "=", "list", "(", "init_logprobs", ".", "chunk", "(", "group_size", ",", "0", ")", ")", "\n", "# END INIT", "\n", "\n", "# Chunk elements in the args", "\n", "core_args", "=", "list", "(", "core_args", ")", "\n", "core_args", "=", "[", "_", ".", "chunk", "(", "group_size", ")", "if", "(", "_", "is", "not", "None", "and", "type", "(", "_", ")", "is", "not", "list", ")", "else", "[", "_", "]", "*", "group_size", "for", "_", "in", "core_args", "]", "\n", "core_args", "=", "[", "[", "core_args", "[", "i", "]", "[", "j", "]", "for", "i", "in", "range", "(", "len", "(", "core_args", ")", ")", "]", "for", "j", "in", "range", "(", "group_size", ")", "]", "\n", "\n", "for", "t", "in", "range", "(", "self", ".", "seq_length", "+", "group_size", "-", "1", ")", ":", "\n", "            ", "for", "divm", "in", "range", "(", "group_size", ")", ":", "\n", "                ", "if", "t", ">=", "divm", "and", "t", "<=", "self", ".", "seq_length", "+", "divm", "-", "1", ":", "\n", "# add diversity", "\n", "                    ", "logprobsf", "=", "logprobs_table", "[", "divm", "]", ".", "data", ".", "float", "(", ")", "\n", "# suppress previous word", "\n", "if", "decoding_constraint", "and", "t", "-", "divm", ">", "0", ":", "\n", "                        ", "logprobsf", ".", "scatter_", "(", "1", ",", "beam_seq_table", "[", "divm", "]", "[", "t", "-", "divm", "-", "1", "]", ".", "unsqueeze", "(", "1", ")", ".", "cuda", "(", ")", ",", "float", "(", "'-inf'", ")", ")", "\n", "# suppress UNK tokens in the decoding", "\n", "", "logprobsf", "[", ":", ",", "logprobsf", ".", "size", "(", "1", ")", "-", "1", "]", "=", "logprobsf", "[", ":", ",", "logprobsf", ".", "size", "(", "1", ")", "-", "1", "]", "-", "1000", "\n", "# diversity is added here", "\n", "# the function directly modifies the logprobsf values and hence, we need to return", "\n", "# the unaugmented ones for sorting the candidates in the end. # for historical", "\n", "# reasons :-)", "\n", "unaug_logprobsf", "=", "add_diversity", "(", "beam_seq_table", ",", "logprobsf", ",", "t", ",", "divm", ",", "diversity_lambda", ",", "bdash", ")", "\n", "\n", "# infer new beams", "\n", "beam_seq_table", "[", "divm", "]", ",", "beam_seq_logprobs_table", "[", "divm", "]", ",", "beam_logprobs_sum_table", "[", "divm", "]", ",", "state_table", "[", "divm", "]", ",", "candidates_divm", "=", "beam_step", "(", "logprobsf", ",", "\n", "unaug_logprobsf", ",", "\n", "bdash", ",", "\n", "t", "-", "divm", ",", "\n", "beam_seq_table", "[", "divm", "]", ",", "\n", "beam_seq_logprobs_table", "[", "divm", "]", ",", "\n", "beam_logprobs_sum_table", "[", "divm", "]", ",", "\n", "state_table", "[", "divm", "]", ")", "\n", "\n", "# if time's up... or if end token is reached then copy beams", "\n", "for", "vix", "in", "range", "(", "bdash", ")", ":", "\n", "                        ", "if", "beam_seq_table", "[", "divm", "]", "[", "t", "-", "divm", ",", "vix", "]", "==", "0", "or", "t", "==", "self", ".", "seq_length", "+", "divm", "-", "1", ":", "\n", "                            ", "final_beam", "=", "{", "\n", "'seq'", ":", "beam_seq_table", "[", "divm", "]", "[", ":", ",", "vix", "]", ".", "clone", "(", ")", ",", "\n", "'logps'", ":", "beam_seq_logprobs_table", "[", "divm", "]", "[", ":", ",", "vix", "]", ".", "clone", "(", ")", ",", "\n", "'unaug_p'", ":", "beam_seq_logprobs_table", "[", "divm", "]", "[", ":", ",", "vix", "]", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "\n", "'p'", ":", "beam_logprobs_sum_table", "[", "divm", "]", "[", "vix", "]", ".", "item", "(", ")", "\n", "}", "\n", "if", "max_ppl", ":", "\n", "                                ", "final_beam", "[", "'p'", "]", "=", "final_beam", "[", "'p'", "]", "/", "(", "t", "-", "divm", "+", "1", ")", "\n", "", "done_beams_table", "[", "divm", "]", ".", "append", "(", "final_beam", ")", "\n", "# don't continue beams from finished sequences", "\n", "beam_logprobs_sum_table", "[", "divm", "]", "[", "vix", "]", "=", "-", "1000", "\n", "\n", "# move the current group one step forward in time", "\n", "\n", "", "", "it", "=", "beam_seq_table", "[", "divm", "]", "[", "t", "-", "divm", "]", "\n", "logprobs_table", "[", "divm", "]", ",", "state_table", "[", "divm", "]", "=", "self", ".", "get_logprobs_state", "(", "it", ".", "cuda", "(", ")", ",", "state_table", "[", "divm", "]", ",", "core_args", "[", "divm", "]", ")", "\n", "\n", "# all beams are sorted by their log-probabilities", "\n", "", "", "", "done_beams_table", "=", "[", "sorted", "(", "done_beams_table", "[", "i", "]", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "'p'", "]", ")", "[", ":", "bdash", "]", "for", "i", "in", "range", "(", "group_size", ")", "]", "\n", "done_beams", "=", "reduce", "(", "lambda", "a", ",", "b", ":", "a", "+", "b", ",", "done_beams_table", ")", "\n", "return", "done_beams", "", "", "", ""]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.models.__init__.setup": [[6, 14], ["VSUAModel", "Exception"], "function", ["None"], []], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.rewards_graph.init_scorer": [[19, 24], ["pyciderevalcap.ciderD.ciderD.CiderD", "pycocoevalcap.bleu.bleu.Bleu"], "function", ["None"], ["def", "init_scorer", "(", "cached_tokens", ")", ":", "\n", "    ", "global", "CiderD_scorer", "\n", "CiderD_scorer", "=", "CiderD_scorer", "or", "CiderD", "(", "df", "=", "cached_tokens", ")", "\n", "global", "Bleu_scorer", "\n", "Bleu_scorer", "=", "Bleu_scorer", "or", "Bleu", "(", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.rewards_graph.array_to_str": [[25, 32], ["range", "out.strip", "len", "str"], "function", ["None"], ["", "def", "array_to_str", "(", "arr", ")", ":", "\n", "    ", "out", "=", "''", "\n", "for", "i", "in", "range", "(", "len", "(", "arr", ")", ")", ":", "\n", "        ", "out", "+=", "str", "(", "arr", "[", "i", "]", ")", "+", "' '", "\n", "if", "arr", "[", "i", "]", "==", "0", ":", "\n", "            ", "break", "\n", "", "", "return", "out", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.rewards_graph.get_self_critical_reward": [[33, 76], ["gen_result.data.cpu().numpy.size", "model.eval", "model.train", "collections.OrderedDict", "gen_result.data.cpu().numpy.data.cpu().numpy", "greedy_res.data.cpu().numpy.data.cpu().numpy", "range", "range", "collections.OrderedDict", "range", "numpy.repeat", "len", "torch.no_grad", "model", "misc.utils.expand_feats", "len", "CiderD_scorer.compute_score", "print", "Bleu_scorer.compute_score", "numpy.array", "print", "gen_result.data.cpu().numpy.data.cpu", "greedy_res.data.cpu().numpy.data.cpu", "rewards_graph.array_to_str", "rewards_graph.array_to_str", "rewards_graph.array_to_str", "range", "range", "range", "range", "len"], "function", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.None.train.train", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.expand_feats", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.rewards_graph.array_to_str", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.rewards_graph.array_to_str", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.rewards_graph.array_to_str"], ["", "def", "get_self_critical_reward", "(", "model", ",", "core_args", ",", "sg_data", ",", "fc_feats", ",", "att_feats", ",", "att_masks", ",", "data", ",", "gen_result", ",", "opt", ")", ":", "\n", "    ", "batch_size", "=", "gen_result", ".", "size", "(", "0", ")", "\n", "seq_per_img", "=", "batch_size", "//", "len", "(", "data", "[", "'gts'", "]", ")", "\n", "\n", "# get greedy decoding baseline", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "greedy_res", ",", "_", "=", "model", "(", "sg_data", ",", "fc_feats", ",", "att_feats", ",", "att_masks", "=", "att_masks", ",", "_core_args", "=", "core_args", ",", "\n", "opt", "=", "{", "'expand_features'", ":", "False", "}", ",", "mode", "=", "'sample'", ")", "\n", "", "model", ".", "train", "(", ")", "\n", "greedy_res", "=", "expand_feats", "(", "[", "greedy_res", "]", ",", "seq_per_img", ")", "[", "0", "]", "\n", "res", "=", "OrderedDict", "(", ")", "\n", "\n", "gen_result", "=", "gen_result", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "greedy_res", "=", "greedy_res", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "res", "[", "i", "]", "=", "[", "array_to_str", "(", "gen_result", "[", "i", "]", ")", "]", "\n", "", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "res", "[", "batch_size", "+", "i", "]", "=", "[", "array_to_str", "(", "greedy_res", "[", "i", "]", ")", "]", "\n", "", "gts", "=", "OrderedDict", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "data", "[", "'gts'", "]", ")", ")", ":", "\n", "        ", "gts", "[", "i", "]", "=", "[", "array_to_str", "(", "data", "[", "'gts'", "]", "[", "i", "]", "[", "j", "]", ")", "for", "j", "in", "range", "(", "len", "(", "data", "[", "'gts'", "]", "[", "i", "]", ")", ")", "]", "\n", "\n", "", "res_", "=", "[", "{", "'image_id'", ":", "i", ",", "'caption'", ":", "res", "[", "i", "]", "}", "for", "i", "in", "range", "(", "2", "*", "batch_size", ")", "]", "\n", "res__", "=", "{", "i", ":", "res", "[", "i", "]", "for", "i", "in", "range", "(", "2", "*", "batch_size", ")", "}", "\n", "gts", "=", "{", "i", ":", "gts", "[", "i", "%", "batch_size", "//", "seq_per_img", "]", "for", "i", "in", "range", "(", "2", "*", "batch_size", ")", "}", "\n", "if", "opt", ".", "cider_reward_weight", ">", "0", ":", "\n", "        ", "_", ",", "cider_scores", "=", "CiderD_scorer", ".", "compute_score", "(", "gts", ",", "res_", ")", "\n", "print", "(", "'Cider scores:'", ",", "_", ")", "\n", "", "else", ":", "\n", "        ", "cider_scores", "=", "0", "\n", "", "if", "opt", ".", "bleu_reward_weight", ">", "0", ":", "\n", "        ", "_", ",", "bleu_scores", "=", "Bleu_scorer", ".", "compute_score", "(", "gts", ",", "res__", ")", "\n", "bleu_scores", "=", "np", ".", "array", "(", "bleu_scores", "[", "3", "]", ")", "\n", "print", "(", "'Bleu scores:'", ",", "_", "[", "3", "]", ")", "\n", "", "else", ":", "\n", "        ", "bleu_scores", "=", "0", "\n", "", "scores", "=", "opt", ".", "cider_reward_weight", "*", "cider_scores", "+", "opt", ".", "bleu_reward_weight", "*", "bleu_scores", "\n", "scores", "=", "scores", "[", ":", "batch_size", "]", "-", "scores", "[", "batch_size", ":", "]", "\n", "# batch_size * seq_length", "\n", "rewards", "=", "np", ".", "repeat", "(", "scores", "[", ":", ",", "np", ".", "newaxis", "]", ",", "gen_result", ".", "shape", "[", "1", "]", ",", "1", ")", "\n", "\n", "return", "rewards", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.RewardCriterion.__init__": [[43, 45], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.LanguageModelCriterion.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "RewardCriterion", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.RewardCriterion.forward": [[46, 55], ["to_contiguous().view", "to_contiguous().view", "to_contiguous().view", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "utils.to_contiguous", "utils.to_contiguous", "utils.to_contiguous", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "to_contiguous().view.new().fill_", "to_contiguous().view.new", "to_contiguous().view.size"], "methods", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.to_contiguous", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.to_contiguous", "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.to_contiguous"], ["", "def", "forward", "(", "self", ",", "input", ",", "seq", ",", "reward", ")", ":", "\n", "        ", "input", "=", "to_contiguous", "(", "input", ")", ".", "view", "(", "-", "1", ")", "\n", "reward", "=", "to_contiguous", "(", "reward", ")", ".", "view", "(", "-", "1", ")", "\n", "mask", "=", "(", "seq", ">", "0", ")", ".", "float", "(", ")", "\n", "mask", "=", "to_contiguous", "(", "torch", ".", "cat", "(", "[", "mask", ".", "new", "(", "mask", ".", "size", "(", "0", ")", ",", "1", ")", ".", "fill_", "(", "1", ")", ",", "mask", "[", ":", ",", ":", "-", "1", "]", "]", ",", "1", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "output", "=", "-", "input", "*", "reward", "*", "mask", "\n", "output", "=", "torch", ".", "sum", "(", "output", ")", "/", "torch", ".", "sum", "(", "mask", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.LanguageModelCriterion.__init__": [[57, 59], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.LanguageModelCriterion.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "LanguageModelCriterion", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.LanguageModelCriterion.forward": [[60, 69], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "input.gather().squeeze", "input.size", "input.size", "input.gather", "target.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ",", "mask", ")", ":", "\n", "# truncate to the same size", "\n", "        ", "target", "=", "target", "[", ":", ",", ":", "input", ".", "size", "(", "1", ")", "]", "\n", "mask", "=", "mask", "[", ":", ",", ":", "input", ".", "size", "(", "1", ")", "]", "\n", "\n", "output", "=", "-", "input", ".", "gather", "(", "2", ",", "target", ".", "unsqueeze", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "*", "mask", "\n", "output", "=", "torch", ".", "sum", "(", "output", ")", "/", "torch", ".", "sum", "(", "mask", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.if_use_att": [[9, 13], ["None"], "function", ["None"], ["def", "if_use_att", "(", "caption_model", ")", ":", "\n", "    ", "if", "caption_model", "in", "[", "''", "]", ":", "\n", "        ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.if_use_fc": [[14, 18], ["None"], "function", ["None"], ["", "def", "if_use_fc", "(", "caption_model", ")", ":", "\n", "    ", "if", "caption_model", "in", "[", "]", ":", "\n", "        ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.decode_sequence": [[19, 34], ["seq.size", "range", "range", "out.append", "str", "ix.item"], "function", ["None"], ["", "def", "decode_sequence", "(", "ix_to_word", ",", "seq", ")", ":", "\n", "    ", "N", ",", "D", "=", "seq", ".", "size", "(", ")", "\n", "out", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "        ", "txt", "=", "''", "\n", "for", "j", "in", "range", "(", "D", ")", ":", "\n", "            ", "ix", "=", "seq", "[", "i", ",", "j", "]", "\n", "if", "ix", ">", "0", ":", "\n", "                ", "if", "j", ">=", "1", ":", "\n", "                    ", "txt", "=", "txt", "+", "' '", "\n", "", "txt", "=", "txt", "+", "ix_to_word", "[", "str", "(", "ix", ".", "item", "(", ")", ")", "]", "\n", "", "else", ":", "\n", "                ", "break", "\n", "", "", "out", ".", "append", "(", "txt", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.to_contiguous": [[35, 40], ["tensor.is_contiguous", "tensor.contiguous"], "function", ["None"], ["", "def", "to_contiguous", "(", "tensor", ")", ":", "\n", "    ", "if", "tensor", ".", "is_contiguous", "(", ")", ":", "\n", "        ", "return", "tensor", "\n", "", "else", ":", "\n", "        ", "return", "tensor", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.set_lr": [[71, 74], ["None"], "function", ["None"], ["", "", "def", "set_lr", "(", "optimizer", ",", "lr", ")", ":", "\n", "    ", "for", "group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.get_lr": [[75, 78], ["None"], "function", ["None"], ["", "", "def", "get_lr", "(", "optimizer", ")", ":", "\n", "    ", "for", "group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "return", "group", "[", "'lr'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.clip_gradient": [[79, 84], ["param.grad.data.clamp_"], "function", ["None"], ["", "", "def", "clip_gradient", "(", "optimizer", ",", "grad_clip", ")", ":", "\n", "    ", "for", "group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "for", "param", "in", "group", "[", "'params'", "]", ":", "\n", "            ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                ", "param", ".", "grad", ".", "data", ".", "clamp_", "(", "-", "grad_clip", ",", "grad_clip", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.build_optimizer": [[85, 100], ["torch.RMSprop", "torch.Adagrad", "torch.SGD", "torch.SGD", "torch.SGD", "torch.Adam", "Exception"], "function", ["None"], ["", "", "", "", "def", "build_optimizer", "(", "params", ",", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "optim", "==", "'rmsprop'", ":", "\n", "        ", "return", "optim", ".", "RMSprop", "(", "params", ",", "opt", ".", "learning_rate", ",", "opt", ".", "optim_alpha", ",", "opt", ".", "optim_epsilon", ",", "weight_decay", "=", "opt", ".", "weight_decay", ")", "\n", "", "elif", "opt", ".", "optim", "==", "'adagrad'", ":", "\n", "        ", "return", "optim", ".", "Adagrad", "(", "params", ",", "opt", ".", "learning_rate", ",", "weight_decay", "=", "opt", ".", "weight_decay", ")", "\n", "", "elif", "opt", ".", "optim", "==", "'sgd'", ":", "\n", "        ", "return", "optim", ".", "SGD", "(", "params", ",", "opt", ".", "learning_rate", ",", "weight_decay", "=", "opt", ".", "weight_decay", ")", "\n", "", "elif", "opt", ".", "optim", "==", "'sgdm'", ":", "\n", "        ", "return", "optim", ".", "SGD", "(", "params", ",", "opt", ".", "learning_rate", ",", "opt", ".", "optim_alpha", ",", "weight_decay", "=", "opt", ".", "weight_decay", ")", "\n", "", "elif", "opt", ".", "optim", "==", "'sgdmom'", ":", "\n", "        ", "return", "optim", ".", "SGD", "(", "params", ",", "opt", ".", "learning_rate", ",", "opt", ".", "optim_alpha", ",", "weight_decay", "=", "opt", ".", "weight_decay", ",", "nesterov", "=", "True", ")", "\n", "", "elif", "opt", ".", "optim", "==", "'adam'", ":", "\n", "        ", "return", "optim", ".", "Adam", "(", "params", ",", "opt", ".", "learning_rate", ",", "(", "opt", ".", "optim_alpha", ",", "opt", ".", "optim_beta", ")", ",", "opt", ".", "optim_epsilon", ",", "weight_decay", "=", "opt", ".", "weight_decay", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"bad option opt.optim: {}\"", ".", "format", "(", "opt", ".", "optim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ltguo19_VSUA-Captioning.misc.utils.expand_feats": [[103, 113], ["input.unsqueeze().expand().contiguous().view", "temp.append", "temp.append", "type", "input.unsqueeze().expand().contiguous", "input.unsqueeze().expand", "input.size", "input.size", "input.unsqueeze", "input.size", "input.size"], "function", ["None"], ["", "", "def", "expand_feats", "(", "inputs", ",", "count", ")", ":", "\n", "    ", "temp", "=", "[", "]", "\n", "for", "input", "in", "inputs", ":", "\n", "        ", "if", "type", "(", "input", ")", "is", "list", "or", "input", "is", "None", ":", "\n", "            ", "temp", ".", "append", "(", "input", ")", "\n", "continue", "\n", "", "expanded", "=", "input", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "*", "(", "(", "input", ".", "size", "(", "0", ")", ",", "count", ",", ")", "+", "input", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", ".", "contiguous", "(", ")", ".", "view", "(", "*", "(", "(", "input", ".", "size", "(", "0", ")", "*", "count", ",", ")", "+", "input", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", "\n", "temp", ".", "append", "(", "expanded", ")", "\n", "", "return", "temp", "\n", "", ""]]}