{"home.repos.pwc.inspect_result.BruceWen120_medal.None.hubconf.__build_model": [[3, 26], ["model_class", "torch.hub.load_state_dict_from_url", "torch.hub.load_state_dict_from_url.items", "torch.device", "key.startswith", "model_class.state_dict", "print", "[].copy_", "print", "len", "model_class.state_dict"], "function", ["None"], ["def", "__build_model", "(", "model_class", ",", "ckpt", ",", "pretrained", "=", "True", ",", "device", "=", "'cpu'", ",", "progress", "=", "True", ",", "check_hash", "=", "True", ")", ":", "\n", "    ", "net", "=", "model_class", "(", "device", "=", "device", ")", "\n", "\n", "if", "pretrained", ":", "\n", "        ", "state_dict", "=", "torch", ".", "hub", ".", "load_state_dict_from_url", "(", "\n", "ckpt", ",", "\n", "map_location", "=", "torch", ".", "device", "(", "device", ")", ",", "\n", "progress", "=", "progress", ",", "\n", "check_hash", "=", "check_hash", "\n", ")", "\n", "\n", "for", "key", ",", "value", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "            ", "new_key", "=", "key", "[", "len", "(", "'module.'", ")", ":", "]", "if", "key", ".", "startswith", "(", "'module.'", ")", "else", "key", "\n", "if", "new_key", "not", "in", "net", ".", "state_dict", "(", ")", ":", "\n", "                ", "print", "(", "new_key", ",", "'not expected'", ")", "\n", "continue", "\n", "", "try", ":", "\n", "                ", "net", ".", "state_dict", "(", ")", "[", "new_key", "]", ".", "copy_", "(", "value", ")", "\n", "", "except", ":", "\n", "                ", "print", "(", "new_key", ",", "'not loaded'", ")", "\n", "continue", "\n", "\n", "", "", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.None.hubconf.electra": [[28, 34], ["hubconf.__build_model"], "function", ["home.repos.pwc.inspect_result.BruceWen120_medal.None.hubconf.__build_model"], ["", "def", "electra", "(", "pretrained", "=", "True", ",", "device", "=", "'cpu'", ",", "progress", "=", "True", ")", ":", "\n", "    ", "from", "models", ".", "electra", "import", "Electra", "\n", "return", "__build_model", "(", "\n", "Electra", ",", "\n", "ckpt", "=", "\"https://github.com/BruceWen120/medal/releases/download/data/electra.pt\"", ",", "\n", "pretrained", "=", "pretrained", ",", "device", "=", "device", ",", "progress", "=", "progress", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.None.hubconf.lstm": [[36, 42], ["hubconf.__build_model"], "function", ["home.repos.pwc.inspect_result.BruceWen120_medal.None.hubconf.__build_model"], ["", "def", "lstm", "(", "pretrained", "=", "True", ",", "device", "=", "'cpu'", ",", "progress", "=", "True", ",", "check_hash", "=", "True", ")", ":", "\n", "    ", "from", "models", ".", "rnn", "import", "RNN", "\n", "return", "__build_model", "(", "\n", "RNN", ",", "\n", "ckpt", "=", "\"https://github.com/BruceWen120/medal/releases/download/data/lstm.pt\"", ",", "\n", "pretrained", "=", "pretrained", ",", "device", "=", "device", ",", "progress", "=", "progress", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.None.hubconf.lstm_sa": [[45, 51], ["hubconf.__build_model"], "function", ["home.repos.pwc.inspect_result.BruceWen120_medal.None.hubconf.__build_model"], ["", "def", "lstm_sa", "(", "pretrained", "=", "True", ",", "device", "=", "'cpu'", ",", "progress", "=", "True", ",", "check_hash", "=", "True", ")", ":", "\n", "    ", "from", "models", ".", "lstm_sa", "import", "RNNAtt", "\n", "return", "__build_model", "(", "\n", "RNNAtt", ",", "\n", "ckpt", "=", "\"https://github.com/BruceWen120/medal/releases/download/data/lstm_sa.pt\"", ",", "\n", "pretrained", "=", "pretrained", ",", "device", "=", "device", ",", "progress", "=", "progress", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.None.run.parse_args": [[20, 49], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.BruceWen120_medal.preprocess.batch_abstract_clean.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--savedir\"", ",", "help", "=", "\"Directory for storing experiments\"", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--model\"", ",", "help", "=", "\"Type of model\"", ",", "choices", "=", "[", "'rnnsoft'", ",", "'electra'", ",", "'rnn'", "]", ",", "required", "=", "True", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "help", "=", "\"Root path for train/valid/test data files\"", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_filename\"", ",", "help", "=", "\"Data file name (train/valid/test should have same name, in different dirs)\"", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_path\"", ",", "help", "=", "\"Path to ADAM abbreviations mapping table\"", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--embs_path\"", ",", "help", "=", "\"Path to pretrained Fasttext embeddings\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--pretrained_model\"", ",", "help", "=", "\"Path to previously trained model\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--use_scheduler\"", ",", "help", "=", "\"Whether to use lr scheduler\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "help", "=", "\"Learning rate\"", ",", "default", "=", "0.001", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--clip\"", ",", "help", "=", "\"Gradient clipping\"", ",", "default", "=", "0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--dropout\"", ",", "help", "=", "\"Drop out rate\"", ",", "default", "=", "0.1", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "help", "=", "\"Number of epochs\"", ",", "default", "=", "5", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--accum_num\"", ",", "help", "=", "\"Number of batches for gradient accumulation\"", ",", "default", "=", "1", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_every\"", ",", "help", "=", "\"Frequency of checkpoint\"", ",", "default", "=", "40", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_every\"", ",", "help", "=", "\"Frequency of evaluation\"", ",", "default", "=", "10000", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"-bs\"", ",", "\"--batchsize\"", ",", "help", "=", "\"Batch Size\"", ",", "default", "=", "128", ",", "type", "=", "int", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--hidden_size\"", ",", "help", "=", "\"Hidden layer size\"", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--rnn_layers\"", ",", "help", "=", "\"Number of RNN layers\"", ",", "default", "=", "1", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--da_layers\"", ",", "help", "=", "\"Number of decision attention layers\"", ",", "default", "=", "1", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--ncpu\"", ",", "help", "=", "\"Number of CPU cores\"", ",", "default", "=", "4", ",", "type", "=", "int", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.None.utils.load_dataframes": [[15, 29], ["pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "pd.read_csv.EXPANSION.unique", "pd.read_csv.LABEL.apply", "pd.read_csv.LABEL.apply", "pd.read_csv.LABEL.apply", "os.path.join", "os.path.join", "os.path.join", "enumerate"], "function", ["None"], ["def", "load_dataframes", "(", "data_dir", ",", "data_filename", ",", "adam_path", ")", ":", "\n", "    ", "train", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'train'", ",", "data_filename", ")", ",", "engine", "=", "'c'", ")", "\n", "valid", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'valid'", ",", "data_filename", ")", ",", "engine", "=", "'c'", ")", "\n", "test", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'test'", ",", "data_filename", ")", ",", "engine", "=", "'c'", ")", "\n", "\n", "adam_df", "=", "pd", ".", "read_csv", "(", "adam_path", ",", "sep", "=", "'\\t'", ")", "\n", "unique_labels", "=", "adam_df", ".", "EXPANSION", ".", "unique", "(", ")", "\n", "label_to_ix", "=", "{", "label", ":", "ix", "for", "ix", ",", "label", "in", "enumerate", "(", "unique_labels", ")", "}", "\n", "\n", "train", "[", "'LABEL_NUM'", "]", "=", "train", ".", "LABEL", ".", "apply", "(", "lambda", "l", ":", "label_to_ix", "[", "l", "]", ")", "\n", "valid", "[", "'LABEL_NUM'", "]", "=", "valid", ".", "LABEL", ".", "apply", "(", "lambda", "l", ":", "label_to_ix", "[", "l", "]", ")", "\n", "test", "[", "'LABEL_NUM'", "]", "=", "test", ".", "LABEL", ".", "apply", "(", "lambda", "l", ":", "label_to_ix", "[", "l", "]", ")", "\n", "\n", "return", "train", ",", "valid", ",", "test", ",", "label_to_ix", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.None.utils.load_model": [[30, 49], ["print", "torch.load.items", "torch.load().state_dict", "torch.load", "os.path.splitext", "torch.load.keys", "key.startswith", "net.state_dict", "print", "[].copy_", "torch.load", "print", "len", "net.state_dict"], "function", ["None"], ["", "def", "load_model", "(", "net", ",", "load_path", ",", "device", "=", "'cpu'", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "pretrained", "=", "torch", ".", "load", "(", "load_path", ",", "map_location", "=", "device", ")", ".", "state_dict", "(", ")", "\n", "", "except", ":", "\n", "        ", "pretrained", "=", "torch", ".", "load", "(", "load_path", ",", "map_location", "=", "device", ")", "\n", "", "if", "os", ".", "path", ".", "splitext", "(", "load_path", ")", "[", "-", "1", "]", "==", "'.tar'", ":", "\n", "        ", "pretrained", "=", "pretrained", "[", "'model_state_dict'", "]", "\n", "", "print", "(", "'pretrained: {}'", ".", "format", "(", "pretrained", ".", "keys", "(", ")", ")", ")", "\n", "for", "key", ",", "value", "in", "pretrained", ".", "items", "(", ")", ":", "\n", "        ", "new_key", "=", "key", "[", "len", "(", "'module.'", ")", ":", "]", "if", "key", ".", "startswith", "(", "'module.'", ")", "else", "key", "\n", "if", "new_key", "not", "in", "net", ".", "state_dict", "(", ")", ":", "\n", "            ", "print", "(", "new_key", ",", "'not expected'", ")", "\n", "continue", "\n", "", "try", ":", "\n", "            ", "net", ".", "state_dict", "(", ")", "[", "new_key", "]", ".", "copy_", "(", "value", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "new_key", ",", "'not loaded'", ")", "\n", "continue", "\n", "", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.None.utils.evaluate": [[50, 88], ["model.eval", "torch.no_grad", "tqdm.tqdm", "enumerate", "criterion", "criterion.item", "torch.sum().item", "labels.size", "model.forward", "model", "torch.sum", "labels.numel", "model", "model", "model.argmax"], "function", ["home.repos.pwc.inspect_result.BruceWen120_medal.downstream.electra.Electra.forward"], ["", "def", "evaluate", "(", "model", ",", "model_type", ",", "loader", ",", "dataset", ",", "criterion", ",", "verbose", "=", "False", ",", "full", "=", "True", ")", ":", "\n", "    ", "running_loss", "=", "0.0", "\n", "count", "=", "0.", "\n", "correct", "=", "0.", "\n", "total", "=", "0.", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch_idx", ",", "idx", "in", "tqdm", "(", "enumerate", "(", "loader", ")", ",", "disable", "=", "not", "verbose", ")", ":", "\n", "            ", "if", "not", "full", "and", "batch_idx", ">=", "10000", ":", "\n", "                ", "break", "\n", "", "if", "model_type", "in", "[", "\"lr\"", "]", ":", "\n", "                ", "sents", ",", "labels", "=", "dataset", "[", "idx", "]", "\n", "\n", "outputs", "=", "model", ".", "forward", "(", "sents", ")", "\n", "", "elif", "model_type", "in", "[", "\"trm\"", ",", "\"rnnsoft\"", ",", "\"disbert\"", ",", "\"electra\"", ",", "\"rnn\"", ",", "\"clibert\"", ",", "\"biobert\"", "]", ":", "\n", "                ", "sents", ",", "locs", ",", "labels", "=", "dataset", "[", "idx", "]", "\n", "if", "labels", ".", "numel", "(", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "outputs", "=", "model", "(", "sents", ",", "locs", ")", "\n", "", "elif", "model_type", "in", "[", "\"atetm\"", "]", ":", "\n", "                ", "sents", ",", "bows", ",", "locs", ",", "labels", "=", "dataset", "[", "idx", "]", "\n", "outputs", ",", "etm_loss", "=", "model", "(", "sents", ",", "bows", ",", "locs", ")", "\n", "", "else", ":", "\n", "                ", "sents", ",", "mixtures", ",", "locs", ",", "labels", "=", "dataset", "[", "idx", "]", "\n", "outputs", "=", "model", "(", "sents", ",", "mixtures", ",", "locs", ")", "\n", "\n", "", "loss", "=", "criterion", "(", "outputs", ",", "labels", ")", "\n", "\n", "running_loss", "+=", "loss", ".", "item", "(", ")", "\n", "correct", "+=", "torch", ".", "sum", "(", "outputs", ".", "argmax", "(", "dim", "=", "-", "1", ")", "==", "labels", ")", ".", "item", "(", ")", "\n", "total", "+=", "labels", ".", "size", "(", "0", ")", "\n", "count", "+=", "1", "\n", "\n", "", "", "accuracy", "=", "correct", "/", "total", "\n", "loss", "=", "running_loss", "/", "count", "\n", "\n", "return", "loss", ",", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.None.utils.train_loop": [[89, 205], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "print", "print", "print", "print", "range", "range", "range", "len", "len", "net.train", "tqdm.tqdm", "utils.evaluate", "print", "print", "print", "print", "print", "logs[].append", "logs[].append", "logs[].append", "logs[].append", "len", "len", "net", "criterion", "criterion.backward", "criterion.item", "torch.sum().item", "labels.size", "scheduler.step", "logs.items", "torch.save", "pandas.DataFrame", "pd.DataFrame.to_csv", "optimizer.zero_grad", "labels.numel", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "net.eval", "utils.evaluate", "net.train", "print", "print", "print", "print", "print", "intermediate_logs[].append", "intermediate_logs[].append", "intermediate_logs[].append", "intermediate_logs[].append", "intermediate_logs[].append", "intermediate_logs[].append", "pandas.DataFrame", "pd.DataFrame.to_csv", "writer.add_scalar", "numpy.sum", "os.path.exists", "os.makedirs", "os.path.join", "os.path.join", "net.parameters", "torch.sum", "scheduler.step", "os.path.exists", "os.makedirs", "os.path.join", "os.path.join", "os.path.join", "net.state_dict", "optimizer.state_dict", "os.path.join", "os.path.join", "str", "str", "net.argmax"], "function", ["home.repos.pwc.inspect_result.BruceWen120_medal.downstream.utils.evaluate", "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.utils.evaluate"], ["", "def", "train_loop", "(", "net", ",", "model_type", ",", "optimizer", ",", "criterion", ",", "train_data", ",", "valid_data", ",", "n_epochs", ",", "batch_size", ",", "save_dir", "=", "None", ",", "\n", "verbose", "=", "False", ",", "scheduler", "=", "None", ",", "eval_every", "=", "10000", ",", "save_every", "=", "40", ",", "clip", "=", "0", ",", "writer", "=", "None", ",", "accum_num", "=", "1", ")", ":", "\n", "\n", "    ", "logs", "=", "{", "k", ":", "[", "]", "for", "k", "in", "[", "'train_loss'", ",", "'valid_loss'", ",", "'train_acc'", ",", "'valid_acc'", "]", "}", "\n", "intermediate_logs", "=", "{", "k", ":", "[", "]", "for", "k", "in", "[", "'epoch'", ",", "'iteration'", ",", "'train_loss'", ",", "'valid_loss'", ",", "'train_acc'", ",", "'valid_acc'", "]", "}", "\n", "\n", "break_cnt", "=", "0", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "range", "(", "len", "(", "train_data", ")", ")", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "batch_size", "\n", ")", "\n", "valid_loader", "=", "DataLoader", "(", "\n", "range", "(", "len", "(", "valid_data", ")", ")", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "batch_size", "\n", ")", "\n", "print", "(", "\"Datasets created:\\n\"", ")", "\n", "print", "(", "\"Training set:\"", ",", "len", "(", "train_data", ")", ",", "\"samples\\n\"", ")", "\n", "print", "(", "\"Validation set:\"", ",", "len", "(", "valid_data", ")", ",", "\"samples\\n\"", ")", "\n", "print", "(", "\"Start training\\n\"", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "n_epochs", ")", ":", "\n", "        ", "running_loss", "=", "0.0", "\n", "count", "=", "0.", "\n", "correct", "=", "0.", "\n", "total", "=", "0.", "\n", "\n", "\n", "net", ".", "train", "(", ")", "\n", "for", "idx", "in", "tqdm", "(", "train_loader", ")", ":", "\n", "            ", "sents", ",", "locs", ",", "labels", "=", "train_data", "[", "idx", "]", "\n", "# gradient accumulation", "\n", "if", "count", ">", "1", "and", "(", "count", "-", "1", ")", "%", "accum_num", "==", "0", ":", "\n", "                ", "optimizer", ".", "zero_grad", "(", ")", "\n", "", "if", "labels", ".", "numel", "(", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "outputs", "=", "net", "(", "sents", ",", "locs", ")", "\n", "loss", "=", "criterion", "(", "outputs", ",", "labels", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "clip", ">", "0", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "net", ".", "parameters", "(", ")", ",", "clip", ")", "\n", "# gradient accumulation", "\n", "", "if", "count", ">", "0", "and", "count", "%", "accum_num", "==", "0", ":", "\n", "                ", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "running_loss", "+=", "loss", ".", "item", "(", ")", "\n", "correct", "+=", "torch", ".", "sum", "(", "outputs", ".", "argmax", "(", "dim", "=", "-", "1", ")", "==", "labels", ")", ".", "item", "(", ")", "\n", "total", "+=", "labels", ".", "size", "(", "0", ")", "\n", "if", "count", "%", "eval_every", "==", "0", "and", "count", ">", "0", ":", "\n", "                ", "net", ".", "eval", "(", ")", "\n", "valid_loss", ",", "valid_acc", "=", "evaluate", "(", "net", ",", "model_type", ",", "valid_loader", ",", "valid_data", ",", "criterion", ",", "verbose", "=", "verbose", ",", "full", "=", "False", ")", "\n", "net", ".", "train", "(", ")", "\n", "if", "scheduler", ":", "\n", "                    ", "scheduler", ".", "step", "(", "valid_loss", ")", "\n", "\n", "", "print", "(", "f\"End of iteration {count}\"", ")", "\n", "print", "(", "f\"Train Loss: {running_loss/count:.4f} \\tTrain Accuracy:{correct/total:.4f}\"", ")", "\n", "print", "(", "f\"Valid Loss: {valid_loss:.4f} \\tValid Accuracy:{valid_acc:.4f}\"", ")", "\n", "print", "(", "\"=\"", "*", "50", ")", "\n", "print", "(", ")", "\n", "intermediate_logs", "[", "'epoch'", "]", ".", "append", "(", "epoch", ")", "\n", "intermediate_logs", "[", "'iteration'", "]", ".", "append", "(", "count", ")", "\n", "intermediate_logs", "[", "'train_loss'", "]", ".", "append", "(", "running_loss", "/", "count", ")", "\n", "intermediate_logs", "[", "'train_acc'", "]", ".", "append", "(", "correct", "/", "total", ")", "\n", "intermediate_logs", "[", "'valid_loss'", "]", ".", "append", "(", "valid_loss", ")", "\n", "intermediate_logs", "[", "'valid_acc'", "]", ".", "append", "(", "valid_acc", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "save_dir", ")", ")", ":", "\n", "                    ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "save_dir", ")", ")", "\n", "", "intermediate_log_df", "=", "pd", ".", "DataFrame", "(", "intermediate_logs", ")", "\n", "intermediate_log_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'intermediate_logs.csv'", ")", ")", "\n", "", "count", "+=", "1", "\n", "\n", "", "valid_loss", ",", "valid_acc", "=", "evaluate", "(", "net", ",", "model_type", ",", "valid_loader", ",", "valid_data", ",", "criterion", ",", "verbose", "=", "verbose", ")", "\n", "if", "scheduler", ":", "\n", "            ", "scheduler", ".", "step", "(", "valid_loss", ")", "\n", "\n", "", "print", "(", "f\"End of epoch {epoch}\"", ")", "\n", "print", "(", "f\"Train Loss: {running_loss/count:.4f} \\tTrain Accuracy:{correct/total:.4f}\"", ")", "\n", "print", "(", "f\"Valid Loss: {valid_loss:.4f} \\tValid Accuracy:{valid_acc:.4f}\"", ")", "\n", "print", "(", "\"=\"", "*", "50", ")", "\n", "print", "(", ")", "\n", "\n", "logs", "[", "'train_loss'", "]", ".", "append", "(", "running_loss", "/", "count", ")", "\n", "logs", "[", "'train_acc'", "]", ".", "append", "(", "correct", "/", "total", ")", "\n", "logs", "[", "'valid_loss'", "]", ".", "append", "(", "valid_loss", ")", "\n", "logs", "[", "'valid_acc'", "]", ".", "append", "(", "valid_acc", ")", "\n", "\n", "# Tensorboard", "\n", "if", "writer", ":", "\n", "            ", "for", "key", ",", "values", "in", "logs", ".", "items", "(", ")", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "key", ",", "values", "[", "-", "1", "]", ",", "epoch", ")", "\n", "\n", "", "", "if", "epoch", ">", "3", ":", "\n", "            ", "if", "logs", "[", "'valid_acc'", "]", "[", "-", "1", "]", "<", "np", ".", "sum", "(", "logs", "[", "'valid_acc'", "]", "[", "-", "2", "]", ")", ":", "\n", "                ", "break_cnt", "+=", "1", "\n", "if", "break_cnt", "==", "3", ":", "\n", "                    ", "break", "\n", "", "", "else", ":", "\n", "                ", "break_cnt", "=", "0", "\n", "\n", "", "", "if", "save_dir", "and", "epoch", ">", "0", "and", "(", "epoch", "%", "save_every", "==", "0", ")", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'checkpoints'", ")", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'checkpoints'", ")", ")", "\n", "", "torch", ".", "save", "(", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'model_state_dict'", ":", "net", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_state_dict'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "'loss'", ":", "loss", ",", "\n", "}", ",", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'checkpoints'", ",", "str", "(", "epoch", ")", "+", "'.tar'", ")", ")", "\n", "\n", "log_df", "=", "pd", ".", "DataFrame", "(", "logs", ")", "\n", "log_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'checkpoints'", ",", "str", "(", "epoch", ")", "+", "'_logs.csv'", ")", ")", "\n", "\n", "", "", "return", "net", ",", "logs", "\n", "", ""]], "home.repos.pwc.inspect_result.BruceWen120_medal.models.rnn.RNN.__init__": [[13, 22], ["torch.nn.Module.__init__", "torch.nn.LSTM().to", "torch.nn.Linear().to", "torch.nn.LSTM", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.BruceWen120_medal.downstream.electra.Electra.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embedding_dim", "=", "300", ",", "output_size", "=", "22555", ",", "rnn_params", "=", "default_rnn_params", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "\n", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "self", ".", "embedding_dim", ",", "**", "rnn_params", ")", ".", "to", "(", "device", ")", "\n", "rnn_out_size", "=", "self", ".", "rnn", ".", "hidden_size", "*", "2", "if", "self", ".", "rnn", ".", "bidirectional", "else", "rnn", ".", "hidden_size", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "rnn_out_size", ",", "output_size", ")", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.models.rnn.RNN.forward": [[23, 38], ["torch.tensor().to", "rnn.RNN.rnn.flatten_parameters", "rnn.RNN.rnn", "torch.stack", "rnn.RNN.linear", "torch.tensor", "enumerate"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sents", ",", "locs", ")", ":", "\n", "        ", "sents", "=", "torch", ".", "tensor", "(", "sents", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# Run LSTM", "\n", "self", ".", "rnn", ".", "flatten_parameters", "(", ")", "\n", "h_t", ",", "_", "=", "self", ".", "rnn", "(", "sents", ")", "\n", "\n", "# Locate the abbreviations, this is what we will be predicting", "\n", "abvs", "=", "torch", ".", "stack", "(", "[", "\n", "h_t", "[", "n", ",", "idx", ",", ":", "]", "\n", "for", "n", ",", "idx", "in", "enumerate", "(", "locs", ")", "\n", "]", ")", "\n", "out", "=", "self", ".", "linear", "(", "abvs", ")", "\n", "\n", "return", "out", "", "", "", ""]], "home.repos.pwc.inspect_result.BruceWen120_medal.models.tokenizer_and_dataset.FastTextTokenizer.__init__": [[14, 26], ["os.path.exists", "os.makedirs"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "verbose", "=", "False", ",", "use_cache", "=", "True", ",", "\n", "save_cache", "=", "True", ",", "cache_dir", "=", "'word_index_cache'", ")", ":", "\n", "        ", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "use_cache", "=", "use_cache", "\n", "self", ".", "save_cache", "=", "save_cache", "\n", "self", ".", "cache_dir", "=", "cache_dir", "\n", "\n", "self", ".", "word_index", "=", "{", "}", "\n", "\n", "if", "use_cache", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "cache_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.models.tokenizer_and_dataset.FastTextTokenizer.build_word_index": [[27, 57], ["print", "print", "os.path.join", "os.path.exists", "print", "tqdm.tqdm.tqdm", "os.path.join", "print", "pickle.dump", "print", "print", "pickle.load", "print", "sent.split", "open", "open", "len"], "methods", ["None"], ["", "", "", "def", "build_word_index", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "\"\"\"\n        args: pandas series that we will use to build word index\n        \"\"\"", "\n", "if", "self", ".", "use_cache", ":", "\n", "            ", "filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cache_dir", ",", "\"word_index.pickle\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "filename", ")", ":", "\n", "                ", "print", "(", "\"Loading word index from cache...\"", ",", "end", "=", "\" \"", ")", "\n", "self", ".", "word_index", "=", "pickle", ".", "load", "(", "open", "(", "filename", ",", "\"rb\"", ")", ")", "\n", "# if \"[MASK]\" not in self.word_index:", "\n", "#     self.word_index[\"[MASK]\"] = len(self.word_index)", "\n", "print", "(", "\"Done.\"", ")", "\n", "return", "\n", "\n", "", "print", "(", "\"Word Index not found!\"", ")", "\n", "\n", "", "print", "(", "\"Generating new word index...\"", ",", "end", "=", "\" \"", ")", "\n", "for", "df", "in", "args", ":", "\n", "            ", "for", "sent", "in", "tqdm", "(", "df", ",", "disable", "=", "not", "self", ".", "verbose", ")", ":", "\n", "                ", "for", "word", "in", "sent", ".", "split", "(", ")", ":", "\n", "                    ", "if", "word", "not", "in", "self", ".", "word_index", ":", "\n", "                        ", "self", ".", "word_index", "[", "word", "]", "=", "len", "(", "self", ".", "word_index", ")", "\n", "", "", "", "", "print", "(", "\"Done.\"", ")", "\n", "\n", "\n", "if", "self", ".", "save_cache", ":", "\n", "            ", "filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cache_dir", ",", "\"word_index.pickle\"", ")", "\n", "print", "(", "\"Saving word index...\"", ",", "end", "=", "\" \"", ")", "\n", "pickle", ".", "dump", "(", "self", ".", "word_index", ",", "open", "(", "filename", ",", "'wb'", ")", ")", "\n", "print", "(", "\"Done.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.models.tokenizer_and_dataset.FastTextTokenizer.prepare_words": [[58, 61], ["None"], "methods", ["None"], ["", "", "def", "prepare_words", "(", "self", ",", "words", ")", ":", "\n", "        ", "idxs", "=", "[", "self", ".", "word_index", "[", "w", "]", "for", "w", "in", "words", "]", "\n", "return", "self", ".", "embedding_matrix", "[", "idxs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.models.tokenizer_and_dataset.FastTextTokenizer.prepare_sequence": [[62, 65], ["torch.tensor", "seq.split"], "methods", ["None"], ["", "def", "prepare_sequence", "(", "self", ",", "seq", ")", ":", "\n", "        ", "idxs", "=", "[", "self", ".", "word_index", "[", "w", "]", "for", "w", "in", "seq", ".", "split", "(", ")", "]", "\n", "return", "torch", ".", "tensor", "(", "self", ".", "embedding_matrix", "[", "idxs", "]", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.models.tokenizer_and_dataset.FastTextTokenizer.build_embedding_matrix": [[66, 74], ["numpy.zeros", "fasttext.load_model", "tqdm.tqdm.tqdm", "tokenizer_and_dataset.FastTextTokenizer.word_index.items", "fasttext.load_model.get_word_vector", "len"], "methods", ["home.repos.pwc.inspect_result.BruceWen120_medal.downstream.utils.load_model"], ["", "def", "build_embedding_matrix", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "embedding_matrix", "=", "np", ".", "zeros", "(", "(", "len", "(", "self", ".", "word_index", ")", "+", "1", ",", "300", ")", ")", "\n", "ft_model", "=", "fasttext", ".", "load_model", "(", "path", ")", "\n", "\n", "for", "word", ",", "i", "in", "tqdm", "(", "self", ".", "word_index", ".", "items", "(", ")", ",", "disable", "=", "not", "self", ".", "verbose", ")", ":", "\n", "            ", "self", ".", "embedding_matrix", "[", "i", "]", "=", "ft_model", ".", "get_word_vector", "(", "word", ")", "\n", "\n", "", "return", "self", ".", "embedding_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.models.tokenizer_and_dataset.EmbeddingsDataset.__init__": [[77, 82], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "df", ",", "tokenizer", ",", "max_length", "=", "512", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "df", "=", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.models.tokenizer_and_dataset.EmbeddingsDataset.get_n_features": [[83, 85], ["None"], "methods", ["None"], ["", "def", "get_n_features", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "embedding_matrix", ".", "shape", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.models.tokenizer_and_dataset.EmbeddingsDataset.__len__": [[86, 88], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "df", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.models.tokenizer_and_dataset.EmbeddingsDataset.__getitem__": [[89, 100], ["list", "torch.nn.utils.rnn.pad_sequence", "torch.tensor", "labels.to.to.to", "itertools.compress", "batch_df[].apply", "torch.tensor", "batch_df[].apply().to_list", "batch_df[].apply", "len", "string.split"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idxs", ")", ":", "\n", "        ", "batch_df", "=", "self", ".", "df", ".", "iloc", "[", "idxs", "]", "\n", "idxs", "=", "list", "(", "compress", "(", "idxs", ",", "batch_df", "[", "'TEXT'", "]", ".", "apply", "(", "lambda", "string", ":", "len", "(", "string", ".", "split", "(", ")", ")", "<", "self", ".", "max_length", ")", ".", "to_list", "(", ")", ")", ")", "\n", "batch_df", "=", "self", ".", "df", ".", "iloc", "[", "idxs", "]", "\n", "locs", "=", "batch_df", "[", "'LOCATION'", "]", ".", "values", "\n", "tokenized", "=", "batch_df", "[", "'TEXT'", "]", ".", "apply", "(", "self", ".", "tokenizer", ".", "prepare_sequence", ")", ".", "values", "\n", "padded", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "tokenized", ",", "batch_first", "=", "True", ")", "\n", "\n", "labels", "=", "torch", ".", "tensor", "(", "batch_df", "[", "'LABEL_NUM'", "]", ".", "values", ")", "\n", "labels", "=", "labels", ".", "to", "(", "self", ".", "device", ")", "\n", "return", "padded", ",", "torch", ".", "tensor", "(", "locs", ")", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.models.tokenizer_and_dataset.HuggingfaceDataset.__init__": [[103, 108], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "df", ",", "tokenizer", ",", "max_length", "=", "512", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "df", "=", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.models.tokenizer_and_dataset.HuggingfaceDataset.__len__": [[109, 111], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "df", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.models.tokenizer_and_dataset.HuggingfaceDataset.__getitem__": [[112, 122], ["list", "torch.tensor", "labels.to.to.to", "itertools.compress", "tokenizer_and_dataset.HuggingfaceDataset.tokenizer.batch_encode_plus", "torch.tensor", "batch_df[].apply().to_list", "batch_df[].tolist", "batch_df[].apply", "len", "string.split"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idxs", ")", ":", "\n", "        ", "batch_df", "=", "self", ".", "df", ".", "iloc", "[", "idxs", "]", "\n", "idxs", "=", "list", "(", "compress", "(", "idxs", ",", "batch_df", "[", "'TEXT'", "]", ".", "apply", "(", "lambda", "string", ":", "len", "(", "string", ".", "split", "(", ")", ")", "<", "self", ".", "max_length", ")", ".", "to_list", "(", ")", ")", ")", "\n", "batch_df", "=", "self", ".", "df", ".", "iloc", "[", "idxs", "]", "\n", "locs", "=", "batch_df", "[", "'LOCATION'", "]", ".", "values", "\n", "labels", "=", "torch", ".", "tensor", "(", "batch_df", "[", "'LABEL_NUM'", "]", ".", "values", ")", "\n", "labels", "=", "labels", ".", "to", "(", "self", ".", "device", ")", "\n", "tokenized", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "batch_df", "[", "'TEXT'", "]", ".", "tolist", "(", ")", ",", "max_length", "=", "self", ".", "max_length", ",", "pad_to_max_length", "=", "True", ")", "[", "'input_ids'", "]", "\n", "return", "tokenized", ",", "torch", ".", "tensor", "(", "locs", ")", ",", "labels", "", "", "", ""]], "home.repos.pwc.inspect_result.BruceWen120_medal.models.lstm_sa.AttentionModule.__init__": [[7, 15], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.LayerNorm().to", "torch.nn.LayerNorm().to", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.nn.LayerNorm", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.BruceWen120_medal.downstream.electra.Electra.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "d_k", "=", "None", ",", "device", "=", "'cpu'", ",", "dropout", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "not", "d_k", ":", "\n", "            ", "d_k", "=", "d_model", "\n", "", "self", ".", "W", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "d_model", ",", "d_model", ",", "device", "=", "device", ")", ")", "# (M * M)", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "1", ",", "device", "=", "device", ")", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.models.lstm_sa.AttentionModule.forward": [[16, 28], ["lstm_sa.AttentionModule.norm", "lstm_sa.AttentionModule.norm", "lstm_sa.AttentionModule.norm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "lstm_sa.AttentionModule.transpose", "lstm_sa.AttentionModule.dropout", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "key", ",", "query", ",", "value", ")", ":", "\n", "        ", "key", "=", "self", ".", "norm", "(", "key", ")", "\n", "query", "=", "self", ".", "norm", "(", "query", ")", "\n", "value", "=", "self", ".", "norm", "(", "value", ")", "\n", "# key: (B * N * M) -> (B * N * d_k)", "\n", "# query: (B * N * M) -> (B * N * d_k)", "\n", "# value: (B * N * M) -> (B * N * d_k)", "\n", "query_W_key", "=", "torch", ".", "bmm", "(", "torch", ".", "matmul", "(", "query", ",", "self", ".", "W", ")", ",", "key", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "# (B * N * N)", "\n", "if", "self", ".", "dropout", ":", "\n", "            ", "query_W_key", "=", "self", ".", "dropout", "(", "query_W_key", ")", "\n", "", "weights", "=", "F", ".", "softmax", "(", "torch", ".", "tanh", "(", "query_W_key", "+", "self", ".", "bias", ")", ",", "dim", "=", "-", "1", ")", "# (B * N * N)", "\n", "return", "weights", ",", "torch", ".", "bmm", "(", "weights", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.models.lstm_sa.RNNAtt.__init__": [[30, 43], ["torch.nn.Module.__init__", "torch.nn.LSTM().to", "torch.nn.LSTM().to", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.LayerNorm().to", "torch.nn.LayerNorm().to", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Linear().to", "torch.nn.Linear().to", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "lstm_sa.AttentionModule", "torch.nn.Linear", "torch.nn.Linear", "range"], "methods", ["home.repos.pwc.inspect_result.BruceWen120_medal.downstream.electra.Electra.__init__"], ["    ", "def", "__init__", "(", "self", ",", "rnn_layers", "=", "3", ",", "da_layers", "=", "1", ",", "output_size", "=", "22555", ",", "embedding_dim", "=", "300", ",", "d_model", "=", "512", ",", "dropout_rate", "=", "0.1", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "embedding_dim", ",", "hidden_size", "=", "d_model", ",", "bidirectional", "=", "True", ",", "dropout", "=", "dropout_rate", ",", "num_layers", "=", "rnn_layers", ",", "batch_first", "=", "True", ")", ".", "to", "(", "device", ")", "\n", "rnn_out_size", "=", "d_model", "*", "2", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout_rate", ")", "\n", "self", ".", "norm", "=", "nn", ".", "LayerNorm", "(", "rnn_out_size", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "attentions", "=", "nn", ".", "ModuleList", "(", "[", "AttentionModule", "(", "d_model", "=", "rnn_out_size", ",", "d_k", "=", "rnn_out_size", ",", "device", "=", "device", ",", "dropout", "=", "self", ".", "dropout", ")", "for", "_", "in", "range", "(", "da_layers", ")", "]", ")", "\n", "\n", "self", ".", "output", "=", "nn", ".", "Linear", "(", "rnn_out_size", ",", "output_size", ")", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.models.lstm_sa.RNNAtt.forward": [[44, 53], ["torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "lstm_sa.RNNAtt.rnn.flatten_parameters", "lstm_sa.RNNAtt.rnn", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "lstm_sa.RNNAtt.output", "lstm_sa.RNNAtt.norm", "layer", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "enumerate"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sents", ",", "locs", ")", ":", "\n", "        ", "sents", "=", "torch", ".", "tensor", "(", "sents", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "rnn", ".", "flatten_parameters", "(", ")", "\n", "sents", ",", "_", "=", "self", ".", "rnn", "(", "sents", ")", "\n", "for", "layer", "in", "self", ".", "attentions", ":", "\n", "            ", "sents", "=", "self", ".", "norm", "(", "sents", ")", "\n", "_", ",", "sents", "=", "layer", "(", "sents", ",", "sents", ",", "sents", ")", "\n", "", "abbs", "=", "torch", ".", "stack", "(", "[", "sents", "[", "n", ",", "idx", ",", ":", "]", "for", "n", ",", "idx", "in", "enumerate", "(", "locs", ")", "]", ")", "# (B * M)", "\n", "return", "self", ".", "output", "(", "abbs", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.BruceWen120_medal.models.electra.Electra.__init__": [[7, 13], ["torch.nn.Module.__init__", "transformers.ElectraConfig.from_pretrained", "transformers.AutoModel.from_config().to", "torch.nn.Linear().to", "transformers.AutoModel.from_config", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.BruceWen120_medal.downstream.electra.Electra.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_size", "=", "24005", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "device", "=", "device", "\n", "config", "=", "ElectraConfig", ".", "from_pretrained", "(", "'google/electra-small-discriminator'", ")", "\n", "self", ".", "electra", "=", "AutoModel", ".", "from_config", "(", "config", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "output", "=", "nn", ".", "Linear", "(", "self", ".", "electra", ".", "config", ".", "hidden_size", ",", "output_size", ")", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.models.electra.Electra.forward": [[14, 19], ["torch.tensor().to", "torch.stack", "electra.Electra.output", "electra.Electra.electra", "torch.tensor", "enumerate"], "methods", ["home.repos.pwc.inspect_result.BruceWen120_medal.None.hubconf.electra"], ["", "def", "forward", "(", "self", ",", "sents", ",", "locs", ")", ":", "\n", "        ", "sents", "=", "torch", ".", "tensor", "(", "sents", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "sents", "=", "self", ".", "electra", "(", "sents", ")", "[", "0", "]", "\n", "abbs", "=", "torch", ".", "stack", "(", "[", "sents", "[", "n", ",", "idx", ",", ":", "]", "for", "n", ",", "idx", "in", "enumerate", "(", "locs", ")", "]", ")", "# (B * M)", "\n", "return", "self", ".", "output", "(", "abbs", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.run_downstream.parse_args": [[19, 49], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.BruceWen120_medal.preprocess.batch_abstract_clean.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--savedir\"", ",", "help", "=", "\"Directory for storing experiments\"", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--model\"", ",", "help", "=", "\"Type of model\"", ",", "choices", "=", "[", "'rnnsoft'", ",", "'electra'", ",", "'rnn'", "]", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--task\"", ",", "help", "=", "\"Downstream task\"", ",", "choices", "=", "[", "'mimic-mortality'", ",", "'mimic-diagnosis'", "]", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--test\"", ",", "help", "=", "\"Test model on test set\"", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "help", "=", "\"Root path for train/valid/test data files\"", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_filename\"", ",", "help", "=", "\"Data file name (train/valid/test should have same name, in different dirs)\"", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--diag_to_idx_path\"", ",", "required", "=", "False", ",", "help", "=", "\"Path to the diag_to_idx file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--embs_path\"", ",", "help", "=", "\"Path to pretrained Fasttext embeddings\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--pretrained_model\"", ",", "help", "=", "\"Path to previously trained model\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--use_scheduler\"", ",", "help", "=", "\"Whether to use lr scheduler\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "help", "=", "\"Learning rate\"", ",", "default", "=", "0.001", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--dropout\"", ",", "help", "=", "\"Drop out rate\"", ",", "default", "=", "0.1", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "help", "=", "\"Number of epochs\"", ",", "default", "=", "5", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_every\"", ",", "help", "=", "\"Frequency of checkpoint\"", ",", "default", "=", "40", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_every\"", ",", "help", "=", "\"Frequency of evaluation\"", ",", "default", "=", "10000", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"-bs\"", ",", "\"--batchsize\"", ",", "help", "=", "\"LSTM Batch Size\"", ",", "default", "=", "128", ",", "type", "=", "int", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--hidden_size\"", ",", "help", "=", "\"Hidden layer size\"", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--rnn_layers\"", ",", "help", "=", "\"Number of RNN layers\"", ",", "default", "=", "1", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--da_layers\"", ",", "help", "=", "\"Number of decision attention layers\"", ",", "default", "=", "1", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--ncpu\"", ",", "help", "=", "\"Number of CPU cores\"", ",", "default", "=", "4", ",", "type", "=", "int", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.tokenizer_and_dataset.FastTextTokenizer.__init__": [[15, 28], ["os.path.exists", "os.makedirs"], "methods", ["None"], ["save_cache", "=", "True", ",", "cache_dir", "=", "'word_index_cache'", ")", ":", "\n", "        ", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "use_cache", "=", "use_cache", "\n", "self", ".", "save_cache", "=", "save_cache", "\n", "self", ".", "cache_dir", "=", "cache_dir", "\n", "\n", "self", ".", "word_index", "=", "{", "}", "\n", "\n", "if", "use_cache", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "cache_dir", ")", "\n", "\n", "", "", "", "def", "build_word_index", "(", "self", ",", "*", "args", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.tokenizer_and_dataset.FastTextTokenizer.build_word_index": [[29, 59], ["print", "print", "os.path.join", "os.path.exists", "print", "tqdm.tqdm.tqdm", "os.path.join", "print", "pickle.dump", "print", "print", "pickle.load", "print", "sent.split", "open", "open", "len"], "methods", ["None"], ["\n", "if", "self", ".", "use_cache", ":", "\n", "            ", "filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cache_dir", ",", "\"word_index.pickle\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "filename", ")", ":", "\n", "                ", "print", "(", "\"Loading word index from cache...\"", ",", "end", "=", "\" \"", ")", "\n", "self", ".", "word_index", "=", "pickle", ".", "load", "(", "open", "(", "filename", ",", "\"rb\"", ")", ")", "\n", "# if \"[MASK]\" not in self.word_index:", "\n", "#     self.word_index[\"[MASK]\"] = len(self.word_index)", "\n", "print", "(", "\"Done.\"", ")", "\n", "return", "\n", "\n", "", "print", "(", "\"Word Index not found!\"", ")", "\n", "\n", "", "print", "(", "\"Generating new word index...\"", ",", "end", "=", "\" \"", ")", "\n", "for", "df", "in", "args", ":", "\n", "            ", "for", "sent", "in", "tqdm", "(", "df", ",", "disable", "=", "not", "self", ".", "verbose", ")", ":", "\n", "                ", "for", "word", "in", "sent", ".", "split", "(", ")", ":", "\n", "                    ", "if", "word", "not", "in", "self", ".", "word_index", ":", "\n", "                        ", "self", ".", "word_index", "[", "word", "]", "=", "len", "(", "self", ".", "word_index", ")", "\n", "", "", "", "", "print", "(", "\"Done.\"", ")", "\n", "\n", "\n", "if", "self", ".", "save_cache", ":", "\n", "            ", "filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cache_dir", ",", "\"word_index.pickle\"", ")", "\n", "print", "(", "\"Saving word index...\"", ",", "end", "=", "\" \"", ")", "\n", "pickle", ".", "dump", "(", "self", ".", "word_index", ",", "open", "(", "filename", ",", "'wb'", ")", ")", "\n", "print", "(", "\"Done.\"", ")", "\n", "\n", "", "", "def", "prepare_words", "(", "self", ",", "words", ")", ":", "\n", "        ", "idxs", "=", "[", "self", ".", "word_index", "[", "w", "]", "for", "w", "in", "words", "]", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.tokenizer_and_dataset.FastTextTokenizer.prepare_words": [[60, 63], ["None"], "methods", ["None"], ["return", "self", ".", "embedding_matrix", "[", "idxs", "]", "\n", "\n", "", "def", "prepare_sequence", "(", "self", ",", "seq", ")", ":", "\n", "        ", "idxs", "=", "[", "self", ".", "word_index", "[", "w", "]", "for", "w", "in", "seq", ".", "split", "(", ")", "]", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.tokenizer_and_dataset.FastTextTokenizer.prepare_sequence": [[64, 67], ["torch.tensor", "seq.split"], "methods", ["None"], ["return", "torch", ".", "tensor", "(", "self", ".", "embedding_matrix", "[", "idxs", "]", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "", "def", "build_embedding_matrix", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "embedding_matrix", "=", "np", ".", "zeros", "(", "(", "len", "(", "self", ".", "word_index", ")", "+", "1", ",", "300", ")", ")", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.tokenizer_and_dataset.FastTextTokenizer.build_embedding_matrix": [[69, 77], ["numpy.zeros", "fasttext.load_model", "tqdm.tqdm.tqdm", "tokenizer_and_dataset.FastTextTokenizer.word_index.items", "fasttext.load_model.get_word_vector", "len"], "methods", ["home.repos.pwc.inspect_result.BruceWen120_medal.downstream.utils.load_model"], ["\n", "for", "word", ",", "i", "in", "tqdm", "(", "self", ".", "word_index", ".", "items", "(", ")", ",", "disable", "=", "not", "self", ".", "verbose", ")", ":", "\n", "            ", "self", ".", "embedding_matrix", "[", "i", "]", "=", "ft_model", ".", "get_word_vector", "(", "word", ")", "\n", "\n", "", "return", "self", ".", "embedding_matrix", "\n", "\n", "# for LSTM and LSTM SA", "\n", "", "", "class", "EmbeddingsDataset", "(", "torch", ".", "utils", ".", "data", ".", "Dataset", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "df", ",", "tokenizer", ",", "max_length", "=", "512", ",", "device", "=", "'cpu'", ")", ":", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.tokenizer_and_dataset.MimicDataset.__init__": [[90, 100], ["None"], "methods", ["None"], ["        ", "batch_df", "=", "self", ".", "df", ".", "iloc", "[", "idxs", "]", "\n", "idxs", "=", "list", "(", "compress", "(", "idxs", ",", "batch_df", "[", "'TEXT'", "]", ".", "apply", "(", "lambda", "string", ":", "len", "(", "string", ".", "split", "(", ")", ")", "<", "self", ".", "max_length", ")", ".", "to_list", "(", ")", ")", ")", "\n", "batch_df", "=", "self", ".", "df", ".", "iloc", "[", "idxs", "]", "\n", "locs", "=", "batch_df", "[", "'LOCATION'", "]", ".", "values", "\n", "tokenized", "=", "batch_df", "[", "'TEXT'", "]", ".", "apply", "(", "self", ".", "tokenizer", ".", "prepare_sequence", ")", ".", "values", "\n", "padded", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "tokenized", ",", "batch_first", "=", "True", ")", "\n", "\n", "labels", "=", "torch", ".", "tensor", "(", "batch_df", "[", "'LABEL_NUM'", "]", ".", "values", ")", "\n", "labels", "=", "labels", ".", "to", "(", "self", ".", "device", ")", "\n", "return", "padded", ",", "torch", ".", "tensor", "(", "locs", ")", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.tokenizer_and_dataset.MimicDataset.__len__": [[101, 103], ["None"], "methods", ["None"], ["# for ELECTRA", "\n", "", "", "class", "HuggingfaceDataset", "(", "torch", ".", "utils", ".", "data", ".", "Dataset", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "df", ",", "tokenizer", ",", "max_length", "=", "512", ",", "device", "=", "'cpu'", ")", ":", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.tokenizer_and_dataset.MimicDataset.__getitem__": [[104, 120], ["tokenizer_and_dataset.prepare_label", "torch.nn.utils.rnn.pad_sequence", "labels.to.to.to", "batch_df[].apply"], "methods", ["home.repos.pwc.inspect_result.BruceWen120_medal.downstream.tokenizer_and_dataset.prepare_label"], ["        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "df", "=", "df", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "df", ".", "shape", "[", "0", "]", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "idxs", ")", ":", "\n", "        ", "batch_df", "=", "self", ".", "df", ".", "iloc", "[", "idxs", "]", "\n", "idxs", "=", "list", "(", "compress", "(", "idxs", ",", "batch_df", "[", "'TEXT'", "]", ".", "apply", "(", "lambda", "string", ":", "len", "(", "string", ".", "split", "(", ")", ")", "<", "self", ".", "max_length", ")", ".", "to_list", "(", ")", ")", ")", "\n", "batch_df", "=", "self", ".", "df", ".", "iloc", "[", "idxs", "]", "\n", "locs", "=", "batch_df", "[", "'LOCATION'", "]", ".", "values", "\n", "labels", "=", "torch", ".", "tensor", "(", "batch_df", "[", "'LABEL_NUM'", "]", ".", "values", ")", "\n", "labels", "=", "labels", ".", "to", "(", "self", ".", "device", ")", "\n", "tokenized", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "batch_df", "[", "'TEXT'", "]", ".", "tolist", "(", ")", ",", "max_length", "=", "self", ".", "max_length", ",", "pad_to_max_length", "=", "True", ")", "[", "'input_ids'", "]", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.tokenizer_and_dataset.HuggingfaceDataset.__init__": [[123, 133], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.tokenizer_and_dataset.HuggingfaceDataset.__len__": [[134, 136], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.tokenizer_and_dataset.HuggingfaceDataset.__getitem__": [[137, 144], ["tokenizer_and_dataset.prepare_label", "labels.to.to.to", "tokenizer_and_dataset.HuggingfaceDataset.tokenizer.batch_encode_plus", "batch_df[].tolist"], "methods", ["home.repos.pwc.inspect_result.BruceWen120_medal.downstream.tokenizer_and_dataset.prepare_label"], []], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.tokenizer_and_dataset.prepare_label": [[78, 87], ["torch.tensor", "torch.zeros", "enumerate", "label.split", "int"], "function", ["None"], ["        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "df", "=", "df", "\n", "\n", "", "def", "get_n_features", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "embedding_matrix", ".", "shape", "[", "1", "]", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "df", ".", "shape", "[", "0", "]", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.lstm.RNN.__init__": [[5, 15], ["torch.nn.Module.__init__", "torch.nn.LSTM().to", "torch.nn.Linear().to", "torch.nn.Dropout().to", "torch.nn.LSTM", "torch.nn.Linear", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.BruceWen120_medal.downstream.electra.Electra.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_size", ",", "rnn_params", ",", "embedding_dim", "=", "300", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "\n", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "self", ".", "embedding_dim", ",", "**", "rnn_params", ")", ".", "to", "(", "device", ")", "\n", "rnn_out_size", "=", "self", ".", "rnn", ".", "hidden_size", "*", "2", "if", "self", ".", "rnn", ".", "bidirectional", "else", "self", ".", "rnn", ".", "hidden_size", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "rnn_out_size", ",", "output_size", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.lstm.RNN.forward": [[16, 28], ["lstm.RNN.rnn.flatten_parameters", "torch.tensor().to", "lstm.RNN.rnn", "lstm.RNN.dropout", "lstm.RNN.linear", "torch.sigmoid().squeeze", "torch.max", "torch.tensor", "torch.sigmoid"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sents", ")", ":", "\n", "        ", "self", ".", "rnn", ".", "flatten_parameters", "(", ")", "\n", "sents", "=", "torch", ".", "tensor", "(", "sents", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "h_t", ",", "_", "=", "self", ".", "rnn", "(", "sents", ")", "\n", "\n", "# Pool and pass through a FF layer before outputting prediction", "\n", "out", "=", "torch", ".", "max", "(", "h_t", ",", "dim", "=", "1", ")", "[", "0", "]", "\n", "out", "=", "self", ".", "dropout", "(", "out", ")", "\n", "out", "=", "self", ".", "linear", "(", "out", ")", "\n", "out", "=", "torch", ".", "sigmoid", "(", "out", ")", ".", "squeeze", "(", ")", "\n", "\n", "return", "out", "", "", "", ""]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.lstm_sa.AttentionModule.__init__": [[6, 14], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.BruceWen120_medal.downstream.electra.Electra.__init__"], ["class", "AttentionModule", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "d_model", ",", "d_k", "=", "None", ",", "device", "=", "'cpu'", ",", "dropout", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "not", "d_k", ":", "\n", "            ", "d_k", "=", "d_model", "\n", "", "self", ".", "W", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "d_model", ",", "d_model", ",", "device", "=", "device", ")", ")", "# (M * M)", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "1", ",", "device", "=", "device", ")", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", ".", "to", "(", "device", ")", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.lstm_sa.AttentionModule.forward": [[15, 24], ["torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.matmul().transpose", "torch.matmul().transpose", "torch.matmul().transpose", "torch.matmul().transpose", "lstm_sa.AttentionModule.dropout", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "key.transpose", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul().transpose", "torch.matmul().transpose", "torch.matmul().transpose", "torch.matmul().transpose", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul"], "methods", ["None"], ["\n", "", "def", "forward", "(", "self", ",", "key", ",", "query", ",", "value", ")", ":", "\n", "        ", "key", "=", "self", ".", "norm", "(", "key", ")", "\n", "query", "=", "self", ".", "norm", "(", "query", ")", "\n", "value", "=", "self", ".", "norm", "(", "value", ")", "\n", "# key: (B * N * M) -> (B * N * d_k)", "\n", "# query: (B * N * M) -> (B * N * d_k)", "\n", "# value: (B * N * M) -> (B * N * d_k)", "\n", "query_W_key", "=", "torch", ".", "bmm", "(", "torch", ".", "matmul", "(", "query", ",", "self", ".", "W", ")", ",", "key", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "# (B * N * N)", "\n", "if", "self", ".", "dropout", ":", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.lstm_sa.RNNAtt.__init__": [[26, 38], ["torch.nn.Module.__init__", "torch.nn.LSTM().to", "torch.nn.LSTM().to", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Parameter", "torch.nn.Parameter", "lstm_sa.AttentionModule", "torch.nn.Linear().to", "torch.nn.Linear().to", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.nn.LSTM", "torch.nn.LSTM", "lstm_sa.AttentionModule", "torch.nn.Linear", "torch.nn.Linear", "range"], "methods", ["home.repos.pwc.inspect_result.BruceWen120_medal.downstream.electra.Electra.__init__"], ["", "weights", "=", "F", ".", "softmax", "(", "torch", ".", "tanh", "(", "query_W_key", "+", "self", ".", "bias", ")", ",", "dim", "=", "-", "1", ")", "# (B * N * N)", "\n", "return", "weights", ",", "torch", ".", "bmm", "(", "weights", ",", "value", ")", "\n", "\n", "", "", "class", "RNNAtt", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "rnn_layers", "=", "3", ",", "da_layers", "=", "1", ",", "output_size", "=", "22555", ",", "embedding_dim", "=", "300", ",", "d_model", "=", "512", ",", "dropout_rate", "=", "0.1", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "embedding_dim", ",", "hidden_size", "=", "d_model", ",", "bidirectional", "=", "True", ",", "dropout", "=", "dropout_rate", ",", "num_layers", "=", "rnn_layers", ",", "batch_first", "=", "True", ")", ".", "to", "(", "device", ")", "\n", "rnn_out_size", "=", "d_model", "*", "2", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout_rate", ")", "\n", "self", ".", "norm", "=", "nn", ".", "LayerNorm", "(", "rnn_out_size", ")", ".", "to", "(", "device", ")", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.lstm_sa.RNNAtt.forward": [[39, 48], ["torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "lstm_sa.RNNAtt.rnn.flatten_parameters", "lstm_sa.RNNAtt.rnn", "lstm_sa.RNNAtt.cls_att", "torch.sigmoid().squeeze", "torch.sigmoid().squeeze", "torch.sigmoid().squeeze", "torch.sigmoid().squeeze", "layer", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "lstm_sa.RNNAtt.output"], "methods", ["None"], ["self", ".", "attentions", "=", "nn", ".", "ModuleList", "(", "[", "AttentionModule", "(", "d_model", "=", "rnn_out_size", ",", "d_k", "=", "rnn_out_size", ",", "device", "=", "device", ",", "dropout", "=", "self", ".", "dropout", ")", "for", "_", "in", "range", "(", "da_layers", ")", "]", ")", "\n", "\n", "self", ".", "output", "=", "nn", ".", "Linear", "(", "rnn_out_size", ",", "output_size", ")", ".", "to", "(", "device", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "sents", ",", "locs", ")", ":", "\n", "        ", "sents", "=", "torch", ".", "tensor", "(", "sents", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "rnn", ".", "flatten_parameters", "(", ")", "\n", "sents", ",", "_", "=", "self", ".", "rnn", "(", "sents", ")", "\n", "for", "layer", "in", "self", ".", "attentions", ":", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.utils.load_mimic_mortality": [[22, 32], ["pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "pd.read_csv.HOSPITAL_EXPIRE_FLAG.astype", "pd.read_csv.HOSPITAL_EXPIRE_FLAG.astype", "pd.read_csv.HOSPITAL_EXPIRE_FLAG.astype", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["label_to_ix", "=", "{", "label", ":", "ix", "for", "ix", ",", "label", "in", "enumerate", "(", "unique_labels", ")", "}", "\n", "\n", "train", "[", "'LABEL_NUM'", "]", "=", "train", ".", "LABEL", ".", "apply", "(", "lambda", "l", ":", "label_to_ix", "[", "l", "]", ")", "\n", "valid", "[", "'LABEL_NUM'", "]", "=", "valid", ".", "LABEL", ".", "apply", "(", "lambda", "l", ":", "label_to_ix", "[", "l", "]", ")", "\n", "test", "[", "'LABEL_NUM'", "]", "=", "test", ".", "LABEL", ".", "apply", "(", "lambda", "l", ":", "label_to_ix", "[", "l", "]", ")", "\n", "\n", "return", "train", ",", "valid", ",", "test", ",", "label_to_ix", "\n", "\n", "", "def", "load_model", "(", "net", ",", "load_path", ",", "device", "=", "'cpu'", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "pretrained", "=", "torch", ".", "load", "(", "load_path", ",", "map_location", "=", "device", ")", ".", "state_dict", "(", ")", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.utils.load_mimic_diagnosis": [[33, 42], ["pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "os.path.join", "os.path.join", "os.path.join", "open", "pickle.load"], "function", ["None"], ["", "except", ":", "\n", "        ", "pretrained", "=", "torch", ".", "load", "(", "load_path", ",", "map_location", "=", "device", ")", "\n", "", "if", "os", ".", "path", ".", "splitext", "(", "load_path", ")", "[", "-", "1", "]", "==", "'.tar'", ":", "\n", "        ", "pretrained", "=", "pretrained", "[", "'model_state_dict'", "]", "\n", "", "print", "(", "'pretrained: {}'", ".", "format", "(", "pretrained", ".", "keys", "(", ")", ")", ")", "\n", "for", "key", ",", "value", "in", "pretrained", ".", "items", "(", ")", ":", "\n", "        ", "new_key", "=", "key", "[", "len", "(", "'module.'", ")", ":", "]", "if", "key", ".", "startswith", "(", "'module.'", ")", "else", "key", "\n", "if", "new_key", "not", "in", "net", ".", "state_dict", "(", ")", ":", "\n", "            ", "print", "(", "new_key", ",", "'not expected'", ")", "\n", "continue", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.utils.load_model": [[43, 62], ["print", "torch.load.items", "torch.load().state_dict", "torch.load", "os.path.splitext", "torch.load.keys", "key.startswith", "net.state_dict", "print", "[].copy_", "torch.load", "print", "len", "net.state_dict"], "function", ["None"], ["", "try", ":", "\n", "            ", "net", ".", "state_dict", "(", ")", "[", "new_key", "]", ".", "copy_", "(", "value", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "new_key", ",", "'not loaded'", ")", "\n", "continue", "\n", "", "", "return", "net", "\n", "\n", "", "def", "evaluate", "(", "model", ",", "model_type", ",", "loader", ",", "dataset", ",", "criterion", ",", "verbose", "=", "False", ",", "full", "=", "True", ")", ":", "\n", "    ", "running_loss", "=", "0.0", "\n", "count", "=", "0.", "\n", "correct", "=", "0.", "\n", "total", "=", "0.", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch_idx", ",", "idx", "in", "tqdm", "(", "enumerate", "(", "loader", ")", ",", "disable", "=", "not", "verbose", ")", ":", "\n", "            ", "if", "not", "full", "and", "batch_idx", ">=", "10000", ":", "\n", "                ", "break", "\n", "", "if", "model_type", "in", "[", "\"lr\"", "]", ":", "\n", "                ", "sents", ",", "labels", "=", "dataset", "[", "idx", "]", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.utils.compute_top_k_recall": [[63, 69], ["torch.argsort", "Exception", "torch.gather().sum", "labels.sum", "torch.gather"], "function", ["None"], ["\n", "outputs", "=", "model", ".", "forward", "(", "sents", ")", "\n", "", "elif", "model_type", "in", "[", "\"trm\"", ",", "\"rnnsoft\"", ",", "\"disbert\"", ",", "\"electra\"", ",", "\"rnn\"", ",", "\"clibert\"", ",", "\"biobert\"", "]", ":", "\n", "                ", "sents", ",", "locs", ",", "labels", "=", "dataset", "[", "idx", "]", "\n", "if", "labels", ".", "numel", "(", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "outputs", "=", "model", "(", "sents", ",", "locs", ")", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.utils.predict": [[70, 83], ["model.eval", "torch.cat", "torch.no_grad", "tqdm.tqdm", "model", "preds.append", "model.round"], "function", ["None"], ["", "elif", "model_type", "in", "[", "\"atetm\"", "]", ":", "\n", "                ", "sents", ",", "bows", ",", "locs", ",", "labels", "=", "dataset", "[", "idx", "]", "\n", "outputs", ",", "etm_loss", "=", "model", "(", "sents", ",", "bows", ",", "locs", ")", "\n", "", "else", ":", "\n", "                ", "sents", ",", "mixtures", ",", "locs", ",", "labels", "=", "dataset", "[", "idx", "]", "\n", "outputs", "=", "model", "(", "sents", ",", "mixtures", ",", "locs", ")", "\n", "\n", "", "loss", "=", "criterion", "(", "outputs", ",", "labels", ")", "\n", "\n", "running_loss", "+=", "loss", ".", "item", "(", ")", "\n", "correct", "+=", "torch", ".", "sum", "(", "outputs", ".", "argmax", "(", "dim", "=", "-", "1", ")", "==", "labels", ")", ".", "item", "(", ")", "\n", "total", "+=", "labels", ".", "size", "(", "0", ")", "\n", "count", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.utils.evaluate": [[84, 123], ["model.eval", "torch.no_grad", "tqdm.tqdm", "model", "criterion", "criterion.item", "len", "torch.sum().item", "labels.size", "utils.compute_top_k_recall", "utils.compute_top_k_recall", "utils.compute_top_k_recall", "torch.sum", "model.round"], "function", ["home.repos.pwc.inspect_result.BruceWen120_medal.downstream.utils.compute_top_k_recall", "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.utils.compute_top_k_recall", "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.utils.compute_top_k_recall"], ["", "", "accuracy", "=", "correct", "/", "total", "\n", "loss", "=", "running_loss", "/", "count", "\n", "\n", "return", "loss", ",", "accuracy", "\n", "\n", "", "def", "train_loop", "(", "net", ",", "model_type", ",", "optimizer", ",", "criterion", ",", "train_data", ",", "valid_data", ",", "n_epochs", ",", "batch_size", ",", "save_dir", "=", "None", ",", "\n", "verbose", "=", "False", ",", "scheduler", "=", "None", ",", "eval_every", "=", "10000", ",", "save_every", "=", "40", ",", "clip", "=", "0", ",", "writer", "=", "None", ",", "accum_num", "=", "1", ")", ":", "\n", "\n", "    ", "logs", "=", "{", "k", ":", "[", "]", "for", "k", "in", "[", "'train_loss'", ",", "'valid_loss'", ",", "'train_acc'", ",", "'valid_acc'", "]", "}", "\n", "intermediate_logs", "=", "{", "k", ":", "[", "]", "for", "k", "in", "[", "'epoch'", ",", "'iteration'", ",", "'train_loss'", ",", "'valid_loss'", ",", "'train_acc'", ",", "'valid_acc'", "]", "}", "\n", "\n", "break_cnt", "=", "0", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "range", "(", "len", "(", "train_data", ")", ")", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "batch_size", "\n", ")", "\n", "valid_loader", "=", "DataLoader", "(", "\n", "range", "(", "len", "(", "valid_data", ")", ")", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "batch_size", "\n", ")", "\n", "print", "(", "\"Datasets created:\\n\"", ")", "\n", "print", "(", "\"Training set:\"", ",", "len", "(", "train_data", ")", ",", "\"samples\\n\"", ")", "\n", "print", "(", "\"Validation set:\"", ",", "len", "(", "valid_data", ")", ",", "\"samples\\n\"", ")", "\n", "print", "(", "\"Start training\\n\"", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "n_epochs", ")", ":", "\n", "        ", "running_loss", "=", "0.0", "\n", "count", "=", "0.", "\n", "correct", "=", "0.", "\n", "total", "=", "0.", "\n", "\n", "\n", "net", ".", "train", "(", ")", "\n", "for", "idx", "in", "tqdm", "(", "train_loader", ")", ":", "\n", "            ", "sents", ",", "locs", ",", "labels", "=", "train_data", "[", "idx", "]", "\n", "# gradient accumulation", "\n", "if", "count", ">", "1", "and", "(", "count", "-", "1", ")", "%", "accum_num", "==", "0", ":", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.utils.train_loop": [[124, 290], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "print", "print", "print", "print", "range", "range", "range", "len", "len", "net.train", "tqdm.tqdm", "print", "print", "print", "print", "print", "logs[].append", "logs[].append", "logs[].append", "logs[].append", "len", "len", "optimizer.zero_grad", "net", "criterion", "criterion.backward", "optimizer.step", "criterion.item", "utils.evaluate", "scheduler.step", "print", "logs[].append", "logs[].append", "logs[].append", "logs[].append", "logs.items", "torch.save", "pandas.DataFrame", "pd.DataFrame.to_csv", "torch.sum().item", "labels.size", "net.eval", "net.train", "print", "print", "print", "print", "print", "intermediate_logs[].append", "intermediate_logs[].append", "intermediate_logs[].append", "intermediate_logs[].append", "intermediate_logs[].append", "intermediate_logs[].append", "pandas.DataFrame", "pd.DataFrame.to_csv", "utils.evaluate", "writer.add_scalar", "os.path.exists", "os.makedirs", "os.path.join", "os.path.join", "utils.compute_top_k_recall", "utils.compute_top_k_recall", "utils.compute_top_k_recall", "utils.evaluate", "scheduler.step", "print", "intermediate_logs[].append", "intermediate_logs[].append", "intermediate_logs[].append", "intermediate_logs[].append", "os.path.exists", "os.makedirs", "os.path.join", "os.path.join", "os.path.join", "net.state_dict", "optimizer.state_dict", "torch.sum", "utils.evaluate", "os.path.join", "os.path.join", "str", "str", "net.round"], "function", ["home.repos.pwc.inspect_result.BruceWen120_medal.downstream.utils.evaluate", "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.utils.evaluate", "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.utils.compute_top_k_recall", "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.utils.compute_top_k_recall", "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.utils.compute_top_k_recall", "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.utils.evaluate", "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.utils.evaluate"], ["                ", "optimizer", ".", "zero_grad", "(", ")", "\n", "", "if", "labels", ".", "numel", "(", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "outputs", "=", "net", "(", "sents", ",", "locs", ")", "\n", "loss", "=", "criterion", "(", "outputs", ",", "labels", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "clip", ">", "0", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "net", ".", "parameters", "(", ")", ",", "clip", ")", "\n", "# gradient accumulation", "\n", "", "if", "count", ">", "0", "and", "count", "%", "accum_num", "==", "0", ":", "\n", "                ", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "running_loss", "+=", "loss", ".", "item", "(", ")", "\n", "correct", "+=", "torch", ".", "sum", "(", "outputs", ".", "argmax", "(", "dim", "=", "-", "1", ")", "==", "labels", ")", ".", "item", "(", ")", "\n", "total", "+=", "labels", ".", "size", "(", "0", ")", "\n", "if", "count", "%", "eval_every", "==", "0", "and", "count", ">", "0", ":", "\n", "                ", "net", ".", "eval", "(", ")", "\n", "valid_loss", ",", "valid_acc", "=", "evaluate", "(", "net", ",", "model_type", ",", "valid_loader", ",", "valid_data", ",", "criterion", ",", "verbose", "=", "verbose", ",", "full", "=", "False", ")", "\n", "net", ".", "train", "(", ")", "\n", "if", "scheduler", ":", "\n", "                    ", "scheduler", ".", "step", "(", "valid_loss", ")", "\n", "\n", "", "print", "(", "f\"End of iteration {count}\"", ")", "\n", "print", "(", "f\"Train Loss: {running_loss/count:.4f} \\tTrain Accuracy:{correct/total:.4f}\"", ")", "\n", "print", "(", "f\"Valid Loss: {valid_loss:.4f} \\tValid Accuracy:{valid_acc:.4f}\"", ")", "\n", "print", "(", "\"=\"", "*", "50", ")", "\n", "print", "(", ")", "\n", "intermediate_logs", "[", "'epoch'", "]", ".", "append", "(", "epoch", ")", "\n", "intermediate_logs", "[", "'iteration'", "]", ".", "append", "(", "count", ")", "\n", "intermediate_logs", "[", "'train_loss'", "]", ".", "append", "(", "running_loss", "/", "count", ")", "\n", "intermediate_logs", "[", "'train_acc'", "]", ".", "append", "(", "correct", "/", "total", ")", "\n", "intermediate_logs", "[", "'valid_loss'", "]", ".", "append", "(", "valid_loss", ")", "\n", "intermediate_logs", "[", "'valid_acc'", "]", ".", "append", "(", "valid_acc", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "save_dir", ")", ")", ":", "\n", "                    ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "save_dir", ")", ")", "\n", "", "intermediate_log_df", "=", "pd", ".", "DataFrame", "(", "intermediate_logs", ")", "\n", "intermediate_log_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'intermediate_logs.csv'", ")", ")", "\n", "", "count", "+=", "1", "\n", "\n", "", "valid_loss", ",", "valid_acc", "=", "evaluate", "(", "net", ",", "model_type", ",", "valid_loader", ",", "valid_data", ",", "criterion", ",", "verbose", "=", "verbose", ")", "\n", "if", "scheduler", ":", "\n", "            ", "scheduler", ".", "step", "(", "valid_loss", ")", "\n", "\n", "", "print", "(", "f\"End of epoch {epoch}\"", ")", "\n", "print", "(", "f\"Train Loss: {running_loss/count:.4f} \\tTrain Accuracy:{correct/total:.4f}\"", ")", "\n", "print", "(", "f\"Valid Loss: {valid_loss:.4f} \\tValid Accuracy:{valid_acc:.4f}\"", ")", "\n", "print", "(", "\"=\"", "*", "50", ")", "\n", "print", "(", ")", "\n", "\n", "logs", "[", "'train_loss'", "]", ".", "append", "(", "running_loss", "/", "count", ")", "\n", "logs", "[", "'train_acc'", "]", ".", "append", "(", "correct", "/", "total", ")", "\n", "logs", "[", "'valid_loss'", "]", ".", "append", "(", "valid_loss", ")", "\n", "logs", "[", "'valid_acc'", "]", ".", "append", "(", "valid_acc", ")", "\n", "\n", "# Tensorboard", "\n", "if", "writer", ":", "\n", "            ", "for", "key", ",", "values", "in", "logs", ".", "items", "(", ")", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "key", ",", "values", "[", "-", "1", "]", ",", "epoch", ")", "\n", "\n", "", "", "if", "epoch", ">", "3", ":", "\n", "            ", "if", "logs", "[", "'valid_acc'", "]", "[", "-", "1", "]", "<", "np", ".", "sum", "(", "logs", "[", "'valid_acc'", "]", "[", "-", "2", "]", ")", ":", "\n", "                ", "break_cnt", "+=", "1", "\n", "if", "break_cnt", "==", "3", ":", "\n", "                    ", "break", "\n", "", "", "else", ":", "\n", "                ", "break_cnt", "=", "0", "\n", "\n", "", "", "if", "save_dir", "and", "epoch", ">", "0", "and", "(", "epoch", "%", "save_every", "==", "0", ")", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'checkpoints'", ")", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'checkpoints'", ")", ")", "\n", "", "torch", ".", "save", "(", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'model_state_dict'", ":", "net", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_state_dict'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "'loss'", ":", "loss", ",", "\n", "}", ",", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'checkpoints'", ",", "str", "(", "epoch", ")", "+", "'.tar'", ")", ")", "\n", "\n", "log_df", "=", "pd", ".", "DataFrame", "(", "logs", ")", "\n", "log_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'checkpoints'", ",", "str", "(", "epoch", ")", "+", "'_logs.csv'", ")", ")", "\n", "\n", "", "", "return", "net", ",", "logs", "\n", "", ""]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.electra.AttentionModule.__init__": [[8, 16], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.BruceWen120_medal.downstream.electra.Electra.__init__"], ["        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "device", "=", "device", "\n", "config", "=", "ElectraConfig", ".", "from_pretrained", "(", "'google/electra-small-discriminator'", ")", "\n", "self", ".", "electra", "=", "AutoModel", ".", "from_config", "(", "config", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "output", "=", "nn", ".", "Linear", "(", "self", ".", "electra", ".", "config", ".", "hidden_size", ",", "output_size", ")", ".", "to", "(", "device", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "sents", ",", "locs", ")", ":", "\n", "        ", "sents", "=", "torch", ".", "tensor", "(", "sents", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "sents", "=", "self", ".", "electra", "(", "sents", ")", "[", "0", "]", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.electra.AttentionModule.forward": [[17, 26], ["torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.matmul().transpose", "torch.matmul().transpose", "torch.matmul().transpose", "torch.matmul().transpose", "electra.AttentionModule.dropout", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "key.transpose", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul().transpose", "torch.matmul().transpose", "torch.matmul().transpose", "torch.matmul().transpose", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul"], "methods", ["None"], ["abbs", "=", "torch", ".", "stack", "(", "[", "sents", "[", "n", ",", "idx", ",", ":", "]", "for", "n", ",", "idx", "in", "enumerate", "(", "locs", ")", "]", ")", "# (B * M)", "\n", "return", "self", ".", "output", "(", "abbs", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.electra.Electra.__init__": [[28, 36], ["torch.nn.Module.__init__", "torch.nn.Dropout", "torch.nn.Dropout", "transformers.ElectraModel.from_pretrained().to", "torch.nn.Parameter", "torch.nn.Parameter", "electra.AttentionModule", "torch.nn.Linear().to", "torch.nn.Linear().to", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "transformers.ElectraModel.from_pretrained", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.BruceWen120_medal.downstream.electra.Electra.__init__"], []], "home.repos.pwc.inspect_result.BruceWen120_medal.downstream.electra.Electra.forward": [[37, 43], ["torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "electra.Electra.cls_att", "torch.sigmoid().squeeze", "torch.sigmoid().squeeze", "torch.sigmoid().squeeze", "torch.sigmoid().squeeze", "electra.Electra.electra", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "electra.Electra.output"], "methods", ["home.repos.pwc.inspect_result.BruceWen120_medal.None.hubconf.electra"], []], "home.repos.pwc.inspect_result.BruceWen120_medal.preprocess.mimic.isolate": [[77, 81], ["text.replace.replace"], "function", ["home.repos.pwc.inspect_result.BruceWen120_medal.preprocess.mimic.replace"], ["def", "isolate", "(", "text", ",", "chars", ")", ":", "\n", "    ", "for", "c", "in", "chars", ":", "\n", "        ", "text", "=", "text", ".", "replace", "(", "c", ",", "f\" {c} \"", ")", "\n", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.preprocess.mimic.replace": [[82, 86], ["text.replace.replace"], "function", ["home.repos.pwc.inspect_result.BruceWen120_medal.preprocess.mimic.replace"], ["", "def", "replace", "(", "text", ",", "chars", ",", "new", "=", "\"\"", ")", ":", "\n", "    ", "for", "c", "in", "chars", ":", "\n", "        ", "text", "=", "text", ".", "replace", "(", "c", ",", "new", ")", "\n", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.preprocess.mimic.clean_text": [[87, 94], ["mimic.replace", "mimic.replace", "mimic.isolate", "text.lower.lower"], "function", ["home.repos.pwc.inspect_result.BruceWen120_medal.preprocess.mimic.replace", "home.repos.pwc.inspect_result.BruceWen120_medal.preprocess.mimic.replace", "home.repos.pwc.inspect_result.BruceWen120_medal.preprocess.mimic.isolate"], ["", "def", "clean_text", "(", "text", ")", ":", "\n", "    ", "text", "=", "replace", "(", "text", ",", "\"[**\"", ")", "\n", "text", "=", "replace", "(", "text", ",", "\"**]\"", ")", "\n", "text", "=", "isolate", "(", "text", ",", "\"~!@#$%^&*()_+-={}:\\\";',./<>?\\\\|`'\"", ")", "\n", "text", "=", "text", ".", "lower", "(", ")", "\n", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.preprocess.batch_abstract_extract.parse_args": [[9, 15], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.BruceWen120_medal.preprocess.batch_abstract_clean.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Parse xml.gz files and extract abstracts'", ")", "\n", "parser", ".", "add_argument", "(", "'input_directory'", ",", "help", "=", "'directory containing xml.gz files'", ")", "\n", "parser", ".", "add_argument", "(", "'output_directory'", ",", "help", "=", "'output directory'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_cores'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "'max number of cpu cores'", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.preprocess.batch_abstract_extract.extract_abstract": [[16, 36], ["lxml.etree.parse", "etree.parse.getroot", "enumerate", "os.path.join", "open", "file.writelines", "text.split", "abstracts.items", "os.path.join", "str", "os.path.splitext", "os.path.splitext"], "function", ["None"], ["", "def", "extract_abstract", "(", "input_tuple", ")", ":", "\n", "    ", "input_directory", ",", "output_directory", ",", "filename", "=", "input_tuple", "\n", "tree", "=", "etree", ".", "parse", "(", "os", ".", "path", ".", "join", "(", "input_directory", ",", "filename", ")", ")", "\n", "root", "=", "tree", ".", "getroot", "(", ")", "\n", "abstracts", "=", "{", "}", "\n", "for", "idx", ",", "child", "in", "enumerate", "(", "root", ")", ":", "\n", "        ", "text", "=", "None", "\n", "for", "value", "in", "child", "[", "0", "]", "[", "3", "]", ":", "\n", "            ", "if", "value", ".", "tag", "==", "'Abstract'", ":", "\n", "                ", "text", "=", "value", "[", "0", "]", ".", "text", "\n", "break", "\n", "", "", "if", "not", "text", ":", "\n", "            ", "continue", "\n", "", "text", "=", "\" \"", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "if", "text", "!=", "\"\\n\"", "and", "text", ":", "\n", "            ", "abstracts", "[", "str", "(", "idx", ")", "]", "=", "text", "\n", "", "", "output_abstracts", "=", "[", "':'", ".", "join", "(", "[", "key", ",", "value", "]", ")", "for", "key", ",", "value", "in", "abstracts", ".", "items", "(", ")", "]", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_directory", ",", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "splitext", "(", "filename", ")", "[", "0", "]", ")", "[", "0", "]", "+", "'.txt'", ")", ",", "'w'", ")", "as", "file", ":", "\n", "        ", "file", ".", "writelines", "(", "'\\n'", ".", "join", "(", "output_abstracts", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.preprocess.batch_reverse_substitute.parse_args": [[15, 24], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.BruceWen120_medal.preprocess.batch_abstract_clean.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Reverse substitution'", ")", "\n", "parser", ".", "add_argument", "(", "'-i'", ",", "'--input_file'", ",", "required", "=", "True", ",", "help", "=", "'path to file containing text'", ")", "\n", "parser", ".", "add_argument", "(", "'-n'", ",", "'--num_of_rows'", ",", "type", "=", "int", ",", "help", "=", "'number of rows to be read from input text file'", ")", "\n", "parser", ".", "add_argument", "(", "'-a'", ",", "'--abbreviation_table'", ",", "required", "=", "True", ",", "help", "=", "'path to abbreviation table'", ")", "\n", "parser", ".", "add_argument", "(", "'-o'", ",", "'--output_file'", ",", "required", "=", "True", ",", "help", "=", "'path to output file'", ")", "\n", "parser", ".", "add_argument", "(", "'-p'", ",", "'--probability'", ",", "default", "=", "0.15", ",", "type", "=", "float", ",", "help", "=", "'probability of reverse substitution'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_cores'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "'max number of cpu cores'", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.preprocess.batch_reverse_substitute.clean_expansion": [[25, 31], ["text.lower", "text.lower.translate", "no_white.translate", "str.maketrans", "lower.translate.split", "str.maketrans"], "function", ["None"], ["", "def", "clean_expansion", "(", "text", ")", ":", "\n", "    ", "lower", "=", "text", ".", "lower", "(", ")", "\n", "no_punc", "=", "lower", ".", "translate", "(", "str", ".", "maketrans", "(", "\"\"", ",", "\"\"", ",", "string", ".", "punctuation", ")", ")", "\n", "no_white", "=", "\" \"", ".", "join", "(", "no_punc", ".", "split", "(", ")", ")", "\n", "no_num", "=", "no_white", ".", "translate", "(", "str", ".", "maketrans", "(", "\"\"", ",", "\"\"", ",", "string", ".", "digits", ")", ")", "\n", "return", "no_num", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.preprocess.batch_reverse_substitute.reverse_substitute": [[32, 60], ["numpy.max", "text.split", "enumerate", "len", "expansions_to_ab.keys", "expansion.split", "expansion.split", "numpy.sum", "scipy.stats.bernoulli.rvs", "range", "range", "len", "range"], "function", ["None"], ["", "def", "reverse_substitute", "(", "input_tuple", ")", ":", "\n", "    ", "text", ",", "expansions_to_ab", ",", "p", "=", "input_tuple", "\n", "expansions", "=", "[", "expans", "for", "expans", "in", "expansions_to_ab", ".", "keys", "(", ")", "if", "expans", "in", "text", "]", "\n", "if", "not", "expansions", ":", "# no expansion found", "\n", "        ", "return", "None", "\n", "", "wcs", "=", "[", "len", "(", "expansion", ".", "split", "(", ")", ")", "for", "expansion", "in", "expansions", "]", "\n", "first_words", "=", "[", "expansion", ".", "split", "(", ")", "[", "0", "]", "for", "expansion", "in", "expansions", "]", "\n", "max_wc", "=", "np", ".", "max", "(", "wcs", ")", "\n", "labels", "=", "{", "}", "\n", "current_text", "=", "text", ".", "split", "(", ")", "\n", "for", "idx", ",", "word", "in", "enumerate", "(", "current_text", ")", ":", "\n", "        ", "if", "word", "not", "in", "first_words", ":", "# the word can be the first word", "\n", "            ", "continue", "\n", "", "if", "np", ".", "sum", "(", "[", "' '", ".", "join", "(", "current_text", "[", "idx", ":", "idx", "+", "wc", "]", ")", "in", "expansions", "for", "wc", "in", "range", "(", "max_wc", ",", "0", ",", "-", "1", ")", "]", ")", "==", "0", ":", "# no expansion detected here", "\n", "            ", "continue", "\n", "", "current_wcs", "=", "[", "wc", "for", "wc", "in", "range", "(", "max_wc", ",", "0", ",", "-", "1", ")", "if", "' '", ".", "join", "(", "current_text", "[", "idx", ":", "idx", "+", "wc", "]", ")", "in", "expansions", "]", "# word counts for all possible expansions", "\n", "for", "wc", "in", "current_wcs", ":", "# starting with longest", "\n", "            ", "if", "wc", ">", "len", "(", "current_text", ")", "-", "idx", ":", "# if remaining text is not long enough", "\n", "                ", "continue", "\n", "", "if", "bernoulli", ".", "rvs", "(", "p", ",", "size", "=", "1", ")", ":", "\n", "                ", "labels", "[", "idx", "]", "=", "' '", ".", "join", "(", "current_text", "[", "idx", ":", "idx", "+", "wc", "]", ")", "# record location", "\n", "current_text", "[", "idx", "]", "=", "expansions_to_ab", "[", "' '", ".", "join", "(", "current_text", "[", "idx", ":", "idx", "+", "wc", "]", ")", "]", "# replace with abb", "\n", "for", "_", "in", "range", "(", "1", ",", "wc", ")", ":", "\n", "                    ", "del", "current_text", "[", "idx", "+", "1", "]", "# delete remaining expansion", "\n", "", "break", "# don't search for shorter expansions", "\n", "", "", "", "if", "not", "labels", ":", "\n", "        ", "return", "None", "\n", "", "return", "' '", ".", "join", "(", "current_text", ")", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.preprocess.batch_abstract_clean.parse_args": [[9, 16], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.BruceWen120_medal.preprocess.batch_abstract_clean.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Clean extracted abstracts in txt format'", ")", "\n", "parser", ".", "add_argument", "(", "'-i'", ",", "'--input_directory'", ",", "required", "=", "True", ",", "help", "=", "'directory containing extracted abstracts'", ")", "\n", "parser", ".", "add_argument", "(", "'-s'", ",", "'--stop_word_file'", ",", "required", "=", "False", ",", "help", "=", "'file containing stop words to ignore'", ")", "\n", "parser", ".", "add_argument", "(", "'-o'", ",", "'--output_directory'", ",", "required", "=", "True", ",", "help", "=", "'output directory'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_cores'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "'max number of cpu cores'", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BruceWen120_medal.preprocess.batch_abstract_clean.clean_abstract": [[17, 40], ["abstracts.items", "open", "file.readlines", "len", "int", "text.lower", "text.lower.translate", "no_white.translate", "cleaned_abstracts.append", "open", "file.writelines", "os.path.join", "str.maketrans", "lower.translate.split", "str.maketrans", "os.path.join", "raw_abstract.split", "str", "raw_abstract.split", "no_white.translate.split", "os.path.splitext", "len", "os.path.splitext"], "function", ["None"], ["", "def", "clean_abstract", "(", "input_tuple", ")", ":", "\n", "    ", "input_directory", ",", "file_name", ",", "output_directory", ",", "sws", "=", "input_tuple", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "input_directory", ",", "file_name", ")", ",", "'r'", ")", "as", "file", ":", "\n", "        ", "raw_abstracts", "=", "file", ".", "readlines", "(", ")", "\n", "", "if", "len", "(", "raw_abstracts", ")", "==", "1", ":", "\n", "        ", "return", "\n", "", "abstracts", "=", "{", "int", "(", "raw_abstract", ".", "split", "(", "':'", ")", "[", "0", "]", ")", ":", "':'", ".", "join", "(", "raw_abstract", ".", "split", "(", "':'", ")", "[", "1", ":", "]", ")", ".", "rstrip", "(", "'\\n'", ")", "for", "raw_abstract", "in", "raw_abstracts", "}", "\n", "cleaned_abstracts", "=", "[", "]", "\n", "\n", "for", "idx", ",", "text", "in", "abstracts", ".", "items", "(", ")", ":", "\n", "        ", "lower", "=", "text", ".", "lower", "(", ")", "\n", "no_punc", "=", "lower", ".", "translate", "(", "str", ".", "maketrans", "(", "\"\"", ",", "\"\"", ",", "string", ".", "punctuation", ")", ")", "\n", "no_white", "=", "\" \"", ".", "join", "(", "no_punc", ".", "split", "(", ")", ")", "\n", "no_num", "=", "no_white", ".", "translate", "(", "str", ".", "maketrans", "(", "\"\"", ",", "\"\"", ",", "string", ".", "digits", ")", ")", "\n", "if", "sws", ":", "\n", "            ", "no_sw", "=", "\" \"", ".", "join", "(", "[", "word", "for", "word", "in", "no_num", ".", "split", "(", ")", "if", "(", "word", "not", "in", "sws", ")", "and", "(", "len", "(", "word", ")", ">", "1", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "no_sw", "=", "no_num", "\n", "", "cleaned_abstracts", ".", "append", "(", "\":\"", ".", "join", "(", "[", "str", "(", "idx", ")", ",", "no_sw", "]", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_directory", ",", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "splitext", "(", "file_name", ")", "[", "0", "]", ")", "[", "0", "]", "+", "'_cleaned.txt'", ")", ",", "'w'", ")", "as", "file", ":", "\n", "        ", "file", ".", "writelines", "(", "'\\n'", ".", "join", "(", "cleaned_abstracts", ")", "+", "'\\n'", ")", "\n", "\n"]]}