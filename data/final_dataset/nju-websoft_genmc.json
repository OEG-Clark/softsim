{"home.repos.pwc.inspect_result.nju-websoft_genmc.None.run_genmc.get_input_feature": [[15, 77], ["run_genmc.get_input_feature.tokenizer_fun"], "function", ["None"], ["def", "get_input_feature", "(", "samples", ",", "max_source_length", ",", "max_len_gen", ",", "choice_num", ",", "external_sent_num", "=", "None", ")", ":", "\n", "    ", "sep", "=", "' \\\\n '", "\n", "output_clue", "=", "[", "]", "\n", "answers", "=", "[", "]", "\n", "input_ids_q", ",", "attention_mask_q", "=", "[", "]", ",", "[", "]", "\n", "input_ids_qo", ",", "attention_mask_qo", "=", "[", "]", ",", "[", "]", "\n", "for", "sample", "in", "samples", ":", "\n", "        ", "if", "'answerKey'", "in", "sample", ":", "\n", "            ", "answerKey", "=", "sample", "[", "'answerKey'", "]", "\n", "", "else", ":", "\n", "            ", "answerKey", "=", "\"A\"", "\n", "", "question", "=", "sample", "[", "'question'", "]", "[", "'stem'", "]", "\n", "while", "len", "(", "sample", "[", "'question'", "]", "[", "'choices'", "]", ")", "<", "choice_num", ":", "\n", "            ", "sample", "[", "'question'", "]", "[", "'choices'", "]", ".", "append", "(", "{", "\"text\"", ":", "\"error\"", ",", "\"para\"", ":", "\"\"", ",", "\"label\"", ":", "chr", "(", "ord", "(", "'A'", ")", "+", "len", "(", "sample", ")", "-", "1", ")", "}", ")", "\n", "", "for", "o_i", ",", "(", "opt", ",", "opt_name", ")", "in", "enumerate", "(", "zip", "(", "sample", "[", "'question'", "]", "[", "'choices'", "]", ",", "'ABCDEFGH'", "[", ":", "choice_num", "]", ")", ")", ":", "\n", "            ", "option", "=", "opt", "[", "'text'", "]", "\n", "content", "=", "\"\"", "\n", "if", "external_sent_num", "is", "not", "None", "and", "'para'", "in", "opt", ":", "\n", "                ", "para", "=", "opt", "[", "\"para\"", "]", "\n", "if", "isinstance", "(", "para", ",", "list", ")", ":", "\n", "                    ", "if", "len", "(", "para", ")", ">", "external_sent_num", ":", "\n", "                        ", "para", "=", "para", "[", ":", "external_sent_num", "]", "\n", "", "content", "=", "sep", "+", "\" \"", ".", "join", "(", "para", ")", "\n", "", "elif", "isinstance", "(", "para", ",", "str", ")", ":", "\n", "                    ", "para", "=", "para", ".", "split", "(", "\".\"", ")", "\n", "if", "len", "(", "para", ")", ">", "external_sent_num", ":", "\n", "                        ", "para", "=", "para", "[", ":", "external_sent_num", "]", "\n", "", "content", "=", "sep", "+", "\" \"", ".", "join", "(", "para", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "'lack retrieval'", ")", "\n", "# exit(0)", "\n", "", "", "input_ids_qo", ".", "append", "(", "question", "+", "sep", "+", "option", "+", "content", ")", "\n", "\n", "\n", "", "input_ids_q", ".", "append", "(", "question", "+", "sep", ")", "\n", "if", "answerKey", "in", "'123456'", ":", "\n", "            ", "answer", "=", "ord", "(", "answerKey", ")", "-", "ord", "(", "'1'", ")", "\n", "", "else", ":", "\n", "            ", "answer", "=", "ord", "(", "answerKey", ")", "-", "ord", "(", "'A'", ")", "\n", "", "answers", ".", "append", "(", "answer", ")", "\n", "output_clue", ".", "append", "(", "sample", "[", "'question'", "]", "[", "'choices'", "]", "[", "answer", "]", "[", "'text'", "]", ")", "\n", "\n", "", "def", "tokenizer_fun", "(", "input_ids", ",", "max_len", ")", ":", "\n", "        ", "encoding", "=", "tokenizer", "(", "input_ids", ",", "\n", "padding", "=", "'longest'", ",", "\n", "max_length", "=", "max_len", ",", "\n", "truncation", "=", "True", ",", "\n", "return_tensors", "=", "\"pt\"", ")", "\n", "ids", "=", "encoding", ".", "input_ids", ".", "to", "(", "device", ")", "\n", "mask", "=", "encoding", ".", "attention_mask", ".", "to", "(", "device", ")", "\n", "return", "ids", ",", "mask", "\n", "\n", "", "q_ids", ",", "q_mask", "=", "tokenizer_fun", "(", "input_ids_q", ",", "max_source_length", ")", "\n", "qo_ids", ",", "qo_mask", "=", "tokenizer_fun", "(", "input_ids_qo", ",", "max_source_length", ")", "\n", "clue_ids", ",", "_", "=", "tokenizer_fun", "(", "output_clue", ",", "max_len_gen", ")", "\n", "clue_ids", "=", "[", "\n", "[", "(", "label", "if", "label", "!=", "tokenizer", ".", "pad_token_id", "else", "-", "100", ")", "for", "label", "in", "labels_example", "]", "for", "labels_example", "in", "\n", "clue_ids", "\n", "]", "\n", "clue_ids", "=", "torch", ".", "tensor", "(", "clue_ids", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "\n", "answers", "=", "torch", ".", "tensor", "(", "answers", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "\n", "return", "q_ids", ",", "q_mask", ",", "qo_ids", ",", "qo_mask", ",", "clue_ids", ",", "answers", ",", "output_clue", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.None.run_genmc.eval": [[79, 118], ["torch.no_grad", "model.eval", "tqdm.trange", "len", "len", "min", "run_genmc.get_input_feature", "model", "scores.cpu().detach().tolist.cpu().detach().tolist", "answers.cpu().detach().tolist.cpu().detach().tolist", "zip", "zip", "tokenizer.batch_decode", "utils.compute_rouges", "len", "p.index", "p_anss.append", "results.append", "scores.cpu().detach().tolist.cpu().detach", "answers.cpu().detach().tolist.cpu().detach", "max", "scores.cpu().detach().tolist.cpu", "answers.cpu().detach().tolist.cpu"], "function", ["home.repos.pwc.inspect_result.nju-websoft_genmc.None.run_genmc.eval", "home.repos.pwc.inspect_result.nju-websoft_genmc.None.run_genmc.get_input_feature", "home.repos.pwc.inspect_result.nju-websoft_genmc.None.utils.compute_rouges"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "eval", "(", "model", ",", "test_examples", ",", "tokenizer", ",", "eval_batch_size", ",", "choice_num", ",", "max_len", ",", "max_len_gen", ",", "external_sent_num", ")", ":", "\n", "    ", "count", ",", "count_right", "=", "0", ",", "0", "\n", "results", "=", "[", "]", "\n", "model", ".", "eval", "(", ")", "\n", "step_count", "=", "len", "(", "test_examples", ")", "//", "eval_batch_size", "\n", "if", "step_count", "*", "eval_batch_size", "<", "len", "(", "test_examples", ")", ":", "\n", "        ", "step_count", "+=", "1", "\n", "", "step_trange", "=", "trange", "(", "step_count", ")", "\n", "sources", ",", "targets", "=", "[", "]", ",", "[", "]", "\n", "for", "step", "in", "step_trange", ":", "\n", "        ", "beg_index", "=", "step", "*", "eval_batch_size", "\n", "end_index", "=", "min", "(", "(", "step", "+", "1", ")", "*", "eval_batch_size", ",", "len", "(", "test_examples", ")", ")", "\n", "batch_example", "=", "[", "example", "for", "example", "in", "test_examples", "[", "beg_index", ":", "end_index", "]", "]", "\n", "q_ids", ",", "q_mask", ",", "qo_ids", ",", "qo_mask", ",", "clue_ids", ",", "answers", ",", "output_clue", "=", "get_input_feature", "(", "batch_example", ",", "\n", "max_len", ",", "max_len_gen", ",", "\n", "args", ".", "choice_num", ",", "\n", "external_sent_num", ")", "\n", "scores", ",", "output_sequences", "=", "model", "(", "q_ids", ",", "q_mask", ",", "qo_ids", ",", "qo_mask", ",", "choice_num", ")", "\n", "\n", "scores", "=", "scores", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "tolist", "(", ")", "\n", "answers", "=", "answers", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "tolist", "(", ")", "\n", "p_anss", "=", "[", "]", "\n", "for", "p", ",", "a", ",", "example", "in", "zip", "(", "scores", ",", "answers", ",", "batch_example", ")", ":", "\n", "            ", "p_ans", "=", "p", ".", "index", "(", "max", "(", "p", ")", ")", "\n", "p_anss", ".", "append", "(", "example", "[", "'question'", "]", "[", "'choices'", "]", "[", "p_ans", "]", "[", "'label'", "]", ")", "\n", "if", "p_ans", "==", "a", ":", "\n", "                ", "count_right", "+=", "1", "\n", "", "count", "+=", "1", "\n", "", "for", "sample", ",", "p_ans", "in", "zip", "(", "batch_example", ",", "p_anss", ")", ":", "\n", "            ", "qid", "=", "sample", "[", "'id'", "]", "\n", "results", ".", "append", "(", "qid", "+", "\",\"", "+", "p_ans", ")", "\n", "", "predicts", "=", "tokenizer", ".", "batch_decode", "(", "output_sequences", ",", "skip_special_tokens", "=", "True", ")", "\n", "sources", "+=", "predicts", "\n", "targets", "+=", "output_clue", "\n", "\n", "", "rouge_score", "=", "compute_rouges", "(", "sources", ",", "targets", ")", "[", "'rouge-l'", "]", "\n", "\n", "return", "count_right", "/", "count", ",", "rouge_score", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.None.utils.compute_rouge": [[10, 25], ["rouge.get_scores"], "function", ["None"], ["def", "compute_rouge", "(", "source", ",", "target", ")", ":", "\n", "\n", "    ", "source", ",", "target", "=", "' '", ".", "join", "(", "source", ")", ",", "' '", ".", "join", "(", "target", ")", "\n", "try", ":", "\n", "        ", "scores", "=", "rouge", ".", "get_scores", "(", "hyps", "=", "source", ",", "refs", "=", "target", ")", "\n", "return", "{", "\n", "'rouge-1'", ":", "scores", "[", "0", "]", "[", "'rouge-1'", "]", "[", "'f'", "]", ",", "\n", "'rouge-2'", ":", "scores", "[", "0", "]", "[", "'rouge-2'", "]", "[", "'f'", "]", ",", "\n", "'rouge-l'", ":", "scores", "[", "0", "]", "[", "'rouge-l'", "]", "[", "'f'", "]", ",", "\n", "}", "\n", "", "except", "ValueError", ":", "\n", "        ", "return", "{", "\n", "'rouge-1'", ":", "0.0", ",", "\n", "'rouge-2'", ":", "0.0", ",", "\n", "'rouge-l'", ":", "0.0", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.None.utils.compute_rouges": [[28, 39], ["zip", "utils.compute_rouge", "scores.items", "len", "scores.items"], "function", ["home.repos.pwc.inspect_result.nju-websoft_genmc.None.utils.compute_rouge"], ["", "", "def", "compute_rouges", "(", "sources", ",", "targets", ")", ":", "\n", "    ", "scores", "=", "{", "\n", "'rouge-1'", ":", "0.0", ",", "\n", "'rouge-2'", ":", "0.0", ",", "\n", "'rouge-l'", ":", "0.0", ",", "\n", "}", "\n", "for", "source", ",", "target", "in", "zip", "(", "sources", ",", "targets", ")", ":", "\n", "        ", "score", "=", "compute_rouge", "(", "source", ",", "target", ")", "\n", "for", "k", ",", "v", "in", "scores", ".", "items", "(", ")", ":", "\n", "            ", "scores", "[", "k", "]", "=", "v", "+", "score", "[", "k", "]", "\n", "", "", "return", "{", "k", ":", "v", "/", "len", "(", "targets", ")", "for", "k", ",", "v", "in", "scores", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.None.utils.save_dataset": [[41, 46], ["open", "f.write"], "function", ["None"], ["", "def", "save_dataset", "(", "path", ",", "dataset", ")", ":", "\n", "\n", "    ", "with", "open", "(", "path", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "for", "sample", "in", "dataset", ":", "\n", "            ", "f", ".", "write", "(", "sample", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.None.utils.read_dataset": [[48, 59], ["open", "f.readlines", "enumerate", "json.loads.strip", "json.loads", "dataset.append"], "function", ["None"], ["", "", "", "def", "read_dataset", "(", "path", ")", ":", "\n", "    ", "dataset", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "# if i > 10:", "\n", "#     break", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "line", "=", "json", ".", "loads", "(", "line", ")", "\n", "dataset", ".", "append", "(", "line", ")", "\n", "", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.None.utils.save_model": [[60, 67], ["os.makedirs", "torch.save", "model.state_dict", "optimizer.state_dict"], "function", ["None"], ["", "def", "save_model", "(", "output_model_file", ",", "model", ",", "optimizer", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "output_model_file", ",", "exist_ok", "=", "True", ")", "\n", "output_model_file", "+=", "'pytorch_model.bin'", "\n", "torch", ".", "save", "(", "{", "\n", "'model_state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_state_dict'", ":", "optimizer", ".", "state_dict", "(", ")", "\n", "}", ",", "output_model_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.None.utils.set_seed": [[69, 77], ["str", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all", "numpy.random.seed", "random.seed"], "function", ["None"], ["", "def", "set_seed", "(", "seed", ")", ":", "\n", "    ", "os", ".", "environ", "[", "'PYTHONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "# cpu", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "# gpu", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "# consistent results on the cpu and gpu", "\n", "", ""]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertConfig.__init__": [[68, 123], ["isinstance", "json.loads.items", "isinstance", "open", "json.loads", "ValueError", "reader.read"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "vocab_size_or_config_json_file", ",", "\n", "hidden_size", "=", "768", ",", "\n", "num_hidden_layers", "=", "12", ",", "\n", "num_attention_heads", "=", "12", ",", "\n", "intermediate_size", "=", "3072", ",", "\n", "hidden_act", "=", "\"gelu\"", ",", "\n", "hidden_dropout_prob", "=", "0.1", ",", "\n", "attention_probs_dropout_prob", "=", "0.1", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "type_vocab_size", "=", "2", ",", "\n", "initializer_range", "=", "0.02", ")", ":", "\n", "        ", "\"\"\"Constructs BertConfig.\n\n        Args:\n            vocab_size_or_config_json_file: Vocabulary size of `inputs_ids` in `BertModel`.\n            hidden_size: Size of the encoder layers and the pooler layer.\n            num_hidden_layers: Number of hidden layers in the Transformer encoder.\n            num_attention_heads: Number of attention heads for each attention layer in\n                the Transformer encoder.\n            intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n                layer in the Transformer encoder.\n            hidden_act: The non-linear activation function (function or string) in the\n                encoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported.\n            hidden_dropout_prob: The dropout probabilitiy for all fully connected\n                layers in the embeddings, encoder, and pooler.\n            attention_probs_dropout_prob: The dropout ratio for the attention\n                probabilities.\n            max_position_embeddings: The maximum sequence length that this model might\n                ever be used with. Typically set this to something large just in case\n                (e.g., 512 or 1024 or 2048).\n            type_vocab_size: The vocabulary size of the `token_type_ids` passed into\n                `BertModel`.\n            initializer_range: The sttdev of the truncated_normal_initializer for\n                initializing all weight matrices.\n        \"\"\"", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "vocab_size", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_hidden_layers", "=", "num_hidden_layers", "\n", "self", ".", "num_attention_heads", "=", "num_attention_heads", "\n", "self", ".", "hidden_act", "=", "hidden_act", "\n", "self", ".", "intermediate_size", "=", "intermediate_size", "\n", "self", ".", "hidden_dropout_prob", "=", "hidden_dropout_prob", "\n", "self", ".", "attention_probs_dropout_prob", "=", "attention_probs_dropout_prob", "\n", "self", ".", "max_position_embeddings", "=", "max_position_embeddings", "\n", "self", ".", "type_vocab_size", "=", "type_vocab_size", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"First argument must be either a vocabulary size (int)\"", "\n", "\"or the path to a pretrained model config file (str)\"", ")", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertConfig.from_dict": [[125, 132], ["modeling_transformer.BertConfig", "json_object.items"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "json_object", ")", ":", "\n", "        ", "\"\"\"Constructs a `BertConfig` from a Python dictionary of parameters.\"\"\"", "\n", "config", "=", "BertConfig", "(", "vocab_size_or_config_json_file", "=", "-", "1", ")", "\n", "for", "key", ",", "value", "in", "json_object", ".", "items", "(", ")", ":", "\n", "            ", "config", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertConfig.from_json_file": [[133, 139], ["cls.from_dict", "open", "reader.read", "json.loads"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertConfig.from_dict"], ["", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ")", ":", "\n", "        ", "\"\"\"Constructs a `BertConfig` from a json file of parameters.\"\"\"", "\n", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "return", "cls", ".", "from_dict", "(", "json", ".", "loads", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertConfig.__repr__": [[140, 142], ["str", "modeling_transformer.BertConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertConfig.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertConfig.to_dict": [[143, 147], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertConfig.to_json_string": [[148, 151], ["json.dumps", "modeling_transformer.BertConfig.to_dict"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertConfig.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertEmbeddings.__init__": [[179, 189], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEmbeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertEmbeddings.forward": [[190, 205], ["input_ids.size", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "modeling_transformer.BertEmbeddings.word_embeddings", "modeling_transformer.BertEmbeddings.position_embeddings", "modeling_transformer.BertEmbeddings.token_type_embeddings", "modeling_transformer.BertEmbeddings.LayerNorm", "modeling_transformer.BertEmbeddings.dropout", "torch.zeros_like", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ")", ":", "\n", "        ", "seq_length", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "position_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "\n", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "", "words_embeddings", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "words_embeddings", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertSelfAttention.__init__": [[208, 221], ["torch.nn.Module.__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "ValueError"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", ")", "\n", "", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertSelfAttention.transpose_for_scores": [[222, 226], ["x.view.view.view", "x.view.view.permute", "x.view.view.size"], "methods", ["None"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertSelfAttention.forward": [[227, 253], ["modeling_transformer.BertSelfAttention.query", "modeling_transformer.BertSelfAttention.key", "modeling_transformer.BertSelfAttention.value", "modeling_transformer.BertSelfAttention.transpose_for_scores", "modeling_transformer.BertSelfAttention.transpose_for_scores", "modeling_transformer.BertSelfAttention.transpose_for_scores", "torch.matmul", "modeling_transformer.BertSelfAttention.dropout", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "modeling_transformer.BertSelfAttention.transpose", "math.sqrt", "torch.nn.Softmax", "context_layer.view.view.permute", "context_layer.view.view.size"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertSelfAttention.transpose_for_scores"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ")", ":", "\n", "        ", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "# Apply the attention mask is (precomputed for all layers in BertModel forward() function)", "\n", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "# Normalize the attention scores to probabilities.", "\n", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "attention_softmax", "=", "attention_probs", "\n", "\n", "# This is actually dropping out entreader2 tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "return", "context_layer", ",", "attention_softmax", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertSelfOutput.__init__": [[256, 261], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertSelfOutput.forward": [[262, 267], ["modeling_transformer.BertSelfOutput.dense", "modeling_transformer.BertSelfOutput.dropout", "modeling_transformer.BertSelfOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertAttention.__init__": [[270, 274], ["torch.nn.Module.__init__", "modeling_transformer.BertSelfAttention", "modeling_transformer.BertSelfOutput"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self", "=", "BertSelfAttention", "(", "config", ")", "\n", "self", ".", "output", "=", "BertSelfOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertAttention.forward": [[275, 279], ["modeling_transformer.BertAttention.self", "modeling_transformer.BertAttention.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_tensor", ",", "attention_mask", ")", ":", "\n", "        ", "self_output", ",", "attention_probs", "=", "self", ".", "self", "(", "input_tensor", ",", "attention_mask", ")", "\n", "attention_output", "=", "self", ".", "output", "(", "self_output", ",", "input_tensor", ")", "\n", "return", "attention_output", ",", "attention_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertIntermediate.__init__": [[282, 287], ["torch.nn.Module.__init__", "torch.nn.Linear", "isinstance"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertIntermediate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "intermediate_size", ")", "\n", "self", ".", "intermediate_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", "else", "config", ".", "hidden_act", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertIntermediate.forward": [[288, 292], ["modeling_transformer.BertIntermediate.dense", "modeling_transformer.BertIntermediate.intermediate_act_fn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "intermediate_act_fn", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertOutput.__init__": [[295, 300], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertOutput.forward": [[301, 306], ["modeling_transformer.BertOutput.dense", "modeling_transformer.BertOutput.dropout", "modeling_transformer.BertOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertLayer.__init__": [[309, 314], ["torch.nn.Module.__init__", "modeling_transformer.BertAttention", "modeling_transformer.BertIntermediate", "modeling_transformer.BertOutput"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention", "=", "BertAttention", "(", "config", ")", "\n", "self", ".", "intermediate", "=", "BertIntermediate", "(", "config", ")", "\n", "self", ".", "output", "=", "BertOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertLayer.forward": [[315, 320], ["modeling_transformer.BertLayer.attention", "modeling_transformer.BertLayer.intermediate", "modeling_transformer.BertLayer.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ")", ":", "\n", "        ", "attention_output", ",", "attention_probs", "=", "self", ".", "attention", "(", "hidden_states", ",", "attention_mask", ")", "\n", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ")", "\n", "return", "layer_output", ",", "attention_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertEncoder.__init__": [[323, 327], ["torch.nn.Module.__init__", "modeling_transformer.BertLayer", "torch.nn.ModuleList", "copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "layer", "=", "BertLayer", "(", "config", ")", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "layer", ")", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertEncoder.forward": [[328, 338], ["layer_module", "all_encoder_layers.append", "all_encoder_layers.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "True", ")", ":", "\n", "        ", "all_encoder_layers", "=", "[", "]", "\n", "for", "layer_module", "in", "self", ".", "layer", ":", "\n", "            ", "hidden_states", ",", "attention_probs", "=", "layer_module", "(", "hidden_states", ",", "attention_mask", ")", "\n", "\n", "if", "output_all_encoded_layers", ":", "\n", "                ", "all_encoder_layers", ".", "append", "(", "hidden_states", ")", "\n", "", "", "if", "not", "output_all_encoded_layers", ":", "\n", "            ", "all_encoder_layers", ".", "append", "(", "hidden_states", ")", "\n", "", "return", "all_encoder_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertPooler.__init__": [[340, 344], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPooler", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertPooler.forward": [[345, 352], ["modeling_transformer.BertPooler.dense", "modeling_transformer.BertPooler.activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "# We \"pool\" the model by simply taking the hidden state corresponding", "\n", "# to the first token.", "\n", "        ", "first_token_tensor", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "pooled_output", "=", "self", ".", "dense", "(", "first_token_tensor", ")", "\n", "pooled_output", "=", "self", ".", "activation", "(", "pooled_output", ")", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertPredictionHeadTransform.__init__": [[355, 361], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "isinstance"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPredictionHeadTransform", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "transform_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", "else", "config", ".", "hidden_act", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertPredictionHeadTransform.forward": [[362, 367], ["modeling_transformer.BertPredictionHeadTransform.dense", "modeling_transformer.BertPredictionHeadTransform.transform_act_fn", "modeling_transformer.BertPredictionHeadTransform.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "transform_act_fn", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertLMPredictionHead.__init__": [[370, 381], ["torch.nn.Module.__init__", "modeling_transformer.BertPredictionHeadTransform", "torch.nn.Linear", "torch.nn.Parameter", "bert_model_embedding_weights.size", "bert_model_embedding_weights.size", "torch.zeros", "bert_model_embedding_weights.size"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert_model_embedding_weights", ")", ":", "\n", "        ", "super", "(", "BertLMPredictionHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "BertPredictionHeadTransform", "(", "config", ")", "\n", "\n", "# The output weights are the same as the input embeddings, but thretriever is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "bert_model_embedding_weights", ".", "size", "(", "1", ")", ",", "\n", "bert_model_embedding_weights", ".", "size", "(", "0", ")", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "decoder", ".", "weight", "=", "bert_model_embedding_weights", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "bert_model_embedding_weights", ".", "size", "(", "0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertLMPredictionHead.forward": [[382, 386], ["modeling_transformer.BertLMPredictionHead.transform", "modeling_transformer.BertLMPredictionHead.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "transform", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "decoder", "(", "hidden_states", ")", "+", "self", ".", "bias", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertOnlyMLMHead.__init__": [[389, 392], ["torch.nn.Module.__init__", "modeling_transformer.BertLMPredictionHead"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert_model_embedding_weights", ")", ":", "\n", "        ", "super", "(", "BertOnlyMLMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ",", "bert_model_embedding_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertOnlyMLMHead.forward": [[393, 396], ["modeling_transformer.BertOnlyMLMHead.predictions"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "return", "prediction_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertOnlyNSPHead.__init__": [[399, 402], ["torch.nn.Module.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOnlyNSPHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertOnlyNSPHead.forward": [[403, 406], ["modeling_transformer.BertOnlyNSPHead.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pooled_output", ")", ":", "\n", "        ", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertPreTrainingHeads.__init__": [[409, 413], ["torch.nn.Module.__init__", "modeling_transformer.BertLMPredictionHead", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert_model_embedding_weights", ")", ":", "\n", "        ", "super", "(", "BertPreTrainingHeads", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ",", "bert_model_embedding_weights", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.BertPreTrainingHeads.forward": [[414, 418], ["modeling_transformer.BertPreTrainingHeads.predictions", "modeling_transformer.BertPreTrainingHeads.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ",", "pooled_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "prediction_scores", ",", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.MyTransformer.__init__": [[420, 428], ["torch.nn.Module.__init__", "modeling_transformer.Config", "modeling_transformer.BertEncoder", "modeling_transformer.BertPooler"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "num_attention_heads", ",", "num_hidden_layers", ")", ":", "\n", "        ", "super", "(", "MyTransformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "config", "=", "Config", "(", ")", "\n", "config", ".", "num_hidden_layers", "=", "num_hidden_layers", "\n", "config", ".", "hidden_size", "=", "dim", "\n", "config", ".", "num_attention_heads", "=", "num_attention_heads", "\n", "self", ".", "encoder", "=", "BertEncoder", "(", "config", ")", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.MyTransformer.forward": [[429, 442], ["attention_mask.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "modeling_transformer.MyTransformer.encoder", "modeling_transformer.MyTransformer.pooler", "attention_mask.unsqueeze", "next", "modeling_transformer.MyTransformer.parameters"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "embedding_output", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", ":", "\n", "\n", "        ", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "encoded_layers", "=", "self", ".", "encoder", "(", "embedding_output", ",", "\n", "extended_attention_mask", ",", "\n", "output_all_encoded_layers", "=", "output_all_encoded_layers", ")", "\n", "sequence_output", "=", "encoded_layers", "[", "-", "1", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "if", "not", "output_all_encoded_layers", ":", "\n", "            ", "encoded_layers", "=", "encoded_layers", "[", "-", "1", "]", "\n", "", "return", "encoded_layers", ",", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.Config.__init__": [[444, 458], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "attention_probs_dropout_prob", "=", "0.1", "\n", "self", ".", "hidden_act", "=", "\"relu\"", "\n", "self", ".", "hidden_dropout_prob", "=", "0.1", "\n", "self", ".", "hidden_size", "=", "768", "\n", "self", ".", "initializer_range", "=", "0.02", "\n", "self", ".", "max_position_embeddings", "=", "513", "\n", "self", ".", "num_attention_heads", "=", "16", "\n", "# self.num_attention_heads = 12", "\n", "# self.num_attention_heads = 8", "\n", "self", ".", "num_hidden_layers", "=", "1", "\n", "self", ".", "type_vocab_size", "=", "2", "\n", "self", ".", "layer_norm_eps", "=", "1e-05", "\n", "self", ".", "intermediate_size", "=", "3072", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.MultiModalMapping.__init__": [[460, 467], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ")", ":", "\n", "        ", "super", "(", "MultiModalMapping", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", "*", "4", ")", "\n", "self", ".", "dense_output", "=", "nn", ".", "Linear", "(", "dim", "*", "4", ",", "dim", ")", "\n", "self", ".", "intermediate_act_fn", "=", "ACT2FN", "[", "'relu'", "]", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "dim", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.MultiModalMapping.forward": [[468, 476], ["modeling_transformer.MultiModalMapping.dense", "modeling_transformer.MultiModalMapping.intermediate_act_fn", "modeling_transformer.MultiModalMapping.dense_output", "modeling_transformer.MultiModalMapping.dropout", "modeling_transformer.MultiModalMapping.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states0", "=", "hidden_states", "\n", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "intermediate_act_fn", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dense_output", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "hidden_states0", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.SemanticMatch.__init__": [[508, 515], ["torch.nn.Module.__init__", "modeling_transformer.DPDALayear", "torch.nn.ModuleList", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Tanh", "copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "layer_num", ")", ":", "\n", "        ", "super", "(", "SemanticMatch", ",", "self", ")", ".", "__init__", "(", ")", "\n", "dpda_layer", "=", "DPDALayear", "(", "dim", ")", "\n", "self", ".", "q_o", "=", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "dpda_layer", ")", "for", "_", "in", "range", "(", "layer_num", ")", "]", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "2", "*", "dim", ",", "dim", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.SemanticMatch.forward": [[516, 523], ["torch.max", "torch.max", "modeling_transformer.SemanticMatch.get_vector", "layer_module"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.SemanticMatch.get_vector"], ["", "def", "forward", "(", "self", ",", "q", ",", "o", ",", "mask_q", ",", "mask_o", ")", ":", "\n", "        ", "for", "layer_module", "in", "self", ".", "q_o", ":", "\n", "            ", "q", ",", "o", ",", "q_weight", ",", "o_weight", "=", "layer_module", "(", "q", ",", "o", ",", "mask_q", ",", "mask_o", ")", "\n", "", "q", ",", "_", "=", "torch", ".", "max", "(", "q", ",", "dim", "=", "1", ")", "\n", "o", ",", "_", "=", "torch", ".", "max", "(", "o", ",", "dim", "=", "1", ")", "\n", "q_o", "=", "self", ".", "get_vector", "(", "q", ",", "o", ")", "\n", "return", "q_o", ",", "q_weight", ",", "o_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.SemanticMatch.get_vector": [[524, 529], ["torch.cat", "modeling_transformer.SemanticMatch.linear", "modeling_transformer.SemanticMatch.relu"], "methods", ["None"], ["", "def", "get_vector", "(", "self", ",", "v1", ",", "v2", ")", ":", "\n", "        ", "p_b", "=", "torch", ".", "cat", "(", "[", "v1", ",", "v2", "]", ",", "dim", "=", "1", ")", "# 2*dim", "\n", "p_b", "=", "self", ".", "linear", "(", "p_b", ")", "# dim", "\n", "p_b", "=", "self", ".", "relu", "(", "p_b", ")", "\n", "return", "p_b", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.DPDALayear.__init__": [[532, 537], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ")", ":", "\n", "        ", "super", "(", "DPDALayear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "W_p", "=", "nn", ".", "Linear", "(", "2", "*", "dim", ",", "dim", ")", "\n", "self", ".", "W_q", "=", "nn", ".", "Linear", "(", "2", "*", "dim", ",", "dim", ")", "\n", "self", ".", "W_map", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.DPDALayear.forward": [[539, 589], ["torch.matmul", "torch.max", "torch.max", "torch.softmax", "torch.softmax", "torch.matmul", "torch.matmul", "torch.cat", "torch.cat", "torch.matmul", "torch.matmul", "torch.nn.LayerNorm", "torch.nn.LayerNorm.", "torch.nn.LayerNorm", "torch.nn.LayerNorm.", "nn.LayerNorm.transpose", "p_mask.expand_as.expand_as.float", "p_mask.expand_as.expand_as.unsqueeze", "p_mask.expand_as.expand_as.expand_as", "A.to.to.to", "q_mask.expand_as.expand_as.float", "q_mask.expand_as.expand_as.unsqueeze", "q_mask.expand_as.expand_as.expand_as", "A.to.to.to", "A.to.to.transpose", "modeling_transformer.DPDALayear.W_p", "modeling_transformer.DPDALayear.W_q", "nn.LayerNorm.size", "nn.LayerNorm.size", "nn.LayerNorm.size", "nn.LayerNorm.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "P", ",", "Q", ",", "p_mask", "=", "None", ",", "q_mask", "=", "None", ")", ":", "\n", "# P = self.W_map(P)", "\n", "        ", "P_ori", "=", "P", "\n", "Q_ori", "=", "Q", "\n", "A", "=", "torch", ".", "matmul", "(", "P", ",", "Q", ".", "transpose", "(", "dim0", "=", "1", ",", "dim1", "=", "2", ")", ")", "# batch, l_p, l_q", "\n", "\n", "if", "p_mask", "is", "not", "None", ":", "\n", "            ", "p_mask", "=", "p_mask", ".", "float", "(", ")", "\n", "p_mask", "=", "1", "-", "p_mask", "\n", "p_mask", "=", "p_mask", "*", "-", "10000.0", "\n", "p_mask", "=", "p_mask", ".", "unsqueeze", "(", "dim", "=", "2", ")", "\n", "p_mask", "=", "p_mask", ".", "expand_as", "(", "A", ")", "\n", "A", "=", "A", "+", "p_mask", "\n", "A", "=", "A", ".", "to", "(", "P", ".", "dtype", ")", "\n", "\n", "", "if", "q_mask", "is", "not", "None", ":", "\n", "            ", "q_mask", "=", "q_mask", ".", "float", "(", ")", "\n", "q_mask", "=", "1", "-", "q_mask", "\n", "q_mask", "=", "q_mask", "*", "-", "10000.0", "\n", "q_mask", "=", "q_mask", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "q_mask", "=", "q_mask", ".", "expand_as", "(", "A", ")", "\n", "A", "=", "A", "+", "q_mask", "\n", "A", "=", "A", ".", "to", "(", "Q", ".", "dtype", ")", "\n", "\n", "", "p_weight", ",", "_", "=", "torch", ".", "max", "(", "A", ",", "dim", "=", "2", ")", "\n", "q_weight", ",", "_", "=", "torch", ".", "max", "(", "A", ",", "dim", "=", "1", ")", "\n", "# if p_mask is not None:", "\n", "#     p_weight *= p_mask", "\n", "# if q_mask is not None:", "\n", "#     q_weight *= q_mask", "\n", "\n", "\n", "A_q", "=", "torch", ".", "softmax", "(", "A", ",", "dim", "=", "2", ")", "# l_p, l_q", "\n", "A_p", "=", "torch", ".", "softmax", "(", "A", ".", "transpose", "(", "dim0", "=", "1", ",", "dim1", "=", "2", ")", ",", "dim", "=", "2", ")", "# l_q, l_p", "\n", "\n", "P_q", "=", "torch", ".", "matmul", "(", "A_q", ",", "Q", ")", "# l_p, dim", "\n", "Q_p", "=", "torch", ".", "matmul", "(", "A_p", ",", "P", ")", "# l_q, dim", "\n", "\n", "P_t", "=", "torch", ".", "cat", "(", "[", "P_q", ",", "P", "]", ",", "dim", "=", "2", ")", "# l_p, 2*dim", "\n", "Q_t", "=", "torch", ".", "cat", "(", "[", "Q_p", ",", "Q", "]", ",", "dim", "=", "2", ")", "# l_q, 2*dim", "\n", "\n", "Q", "=", "torch", ".", "matmul", "(", "A_p", ",", "P_t", ")", "# l_q, 2*dim", "\n", "P", "=", "torch", ".", "matmul", "(", "A_q", ",", "Q_t", ")", "# l_p, 2*dim", "\n", "P", "=", "P_ori", "+", "self", ".", "W_p", "(", "P", ")", "# l_p, dim", "\n", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "normalized_shape", "=", "[", "P", ".", "size", "(", "-", "2", ")", ",", "P", ".", "size", "(", "-", "1", ")", "]", ",", "elementwise_affine", "=", "False", ")", "\n", "P", "=", "layer_norm", "(", "P", ")", "\n", "Q", "=", "Q_ori", "+", "self", ".", "W_q", "(", "Q", ")", "# l_q, dim", "\n", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "normalized_shape", "=", "[", "Q", ".", "size", "(", "-", "2", ")", ",", "Q", ".", "size", "(", "-", "1", ")", "]", ",", "elementwise_affine", "=", "False", ")", "\n", "Q", "=", "layer_norm", "(", "Q", ")", "\n", "return", "P", ",", "Q", ",", "p_weight", ",", "q_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.gelu": [[49, 55], ["torch.erf", "math.sqrt"], "function", ["None"], ["def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\"Implementation of the gelu activation function.\n        For information: OpenAI GPT's gelu is slightly diffretrievernt (and gives slightly diffretrievernt results):\n        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n    \"\"\"", "\n", "return", "x", "*", "0.5", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_transformer.swish": [[57, 59], ["torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.__init__": [[10, 37], ["torch.nn.Module.__init__", "torch.device", "transformers.T5ForConditionalGeneration.from_pretrained", "torch.nn.Linear().to", "torch.nn.CrossEntropyLoss", "modeling_transformer.SemanticMatch().to", "modeling_transformer.MyTransformer().to", "torch.nn.ReLU", "torch.cuda.device_count", "range", "modeling_genmc.GenMC.t5_model.parallelize", "torch.nn.Linear", "modeling_transformer.SemanticMatch", "modeling_transformer.MyTransformer", "range", "range"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model_path", ",", "num_hidden_layers", ",", "alpha", ",", "beta", ")", ":", "\n", "        ", "super", "(", "GenMC", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "beta", "=", "beta", "\n", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", ")", "\n", "self", ".", "t5_model", "=", "T5ForConditionalGeneration", ".", "from_pretrained", "(", "model_path", ")", "\n", "dim", "=", "self", ".", "t5_model", ".", "config", ".", "d_model", "\n", "self", ".", "option_linear", "=", "nn", ".", "Linear", "(", "dim", ",", "1", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "option_linear", ".", "device", "=", "device", "\n", "self", ".", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "semantic_matching", "=", "SemanticMatch", "(", "dim", ",", "num_hidden_layers", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "semantic_matching", ".", "device", "=", "device", "\n", "num_attention_heads", "=", "dim", "//", "64", "\n", "self", ".", "transformer_laryer_de", "=", "MyTransformer", "(", "dim", ",", "num_attention_heads", ",", "num_hidden_layers", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "transformer_laryer_de", ".", "device", "=", "device", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "layer_num", "=", "self", ".", "t5_model", ".", "config", ".", "num_layers", "\n", "layer_per_gpu", "=", "layer_num", "//", "n_gpu", "\n", "device_map", "=", "{", "}", "\n", "for", "n", "in", "range", "(", "n_gpu", ")", ":", "\n", "            ", "device_map", "[", "n", "]", "=", "[", "i", "+", "n", "*", "layer_per_gpu", "for", "i", "in", "range", "(", "layer_per_gpu", ")", "]", "\n", "", "remain_layer", "=", "[", "i", "+", "n_gpu", "*", "layer_per_gpu", "for", "i", "in", "range", "(", "layer_num", "-", "layer_per_gpu", "*", "n_gpu", ")", "]", "\n", "device_map", "[", "n_gpu", "-", "1", "]", "+=", "remain_layer", "\n", "self", ".", "t5_model", ".", "parallelize", "(", "device_map", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.forward": [[39, 52], ["modeling_genmc.GenMC.get_option_score", "modeling_genmc.GenMC.t5_model", "modeling_genmc.GenMC.criterion", "modeling_genmc.GenMC.get_option_score", "q_ids.to", "q_mask.to", "clue_ids.to"], "methods", ["home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.get_option_score", "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.get_option_score"], ["", "def", "forward", "(", "self", ",", "q_ids", ",", "q_mask", ",", "qo_ids", ",", "qo_mask", ",", "choice_num", ",", "clue_ids", "=", "None", ",", "answers", "=", "None", ")", ":", "\n", "        ", "self", ".", "choice_num", "=", "choice_num", "\n", "if", "answers", "is", "not", "None", "and", "clue_ids", "is", "not", "None", ":", "\n", "            ", "opt_score", ",", "output_sequences", "=", "self", ".", "get_option_score", "(", "q_ids", ",", "q_mask", ",", "qo_ids", ",", "qo_mask", ")", "\n", "local_device", "=", "self", ".", "t5_model", ".", "device", "\n", "t5_output", "=", "self", ".", "t5_model", "(", "input_ids", "=", "q_ids", ".", "to", "(", "local_device", ")", ",", "attention_mask", "=", "q_mask", ".", "to", "(", "local_device", ")", ",", "\n", "labels", "=", "clue_ids", ".", "to", "(", "local_device", ")", ")", "\n", "loss_ans", "=", "t5_output", ".", "loss", "\n", "loss", "=", "self", ".", "criterion", "(", "opt_score", ",", "answers", ")", "\n", "return", "self", ".", "alpha", "*", "loss", "+", "self", ".", "beta", "*", "loss_ans", "\n", "", "else", ":", "\n", "            ", "opt_score", ",", "output_sequences", "=", "self", ".", "get_option_score", "(", "q_ids", ",", "q_mask", ",", "qo_ids", ",", "qo_mask", ")", "\n", "return", "opt_score", ",", "output_sequences", "\n", "\n"]], "home.repos.pwc.inspect_result.nju-websoft_genmc.model.modeling_genmc.GenMC.get_option_score": [[53, 97], ["modeling_genmc.GenMC.t5_model.encoder", "modeling_genmc.GenMC.t5_model.encoder", "modeling_genmc.GenMC.t5_model.generate", "output_sequences[].contiguous", "torch.cat", "torch.cat.long", "torch.cat", "torch.cat", "modeling_genmc.GenMC.transformer_laryer_de", "torch.cat.unsqueeze", "output_sequences_mask_ex.view.view.expand().contiguous", "output_sequences_mask_ex.view.view.view", "decoder_qo.view.view.unsqueeze", "decoder_qo.view.view.expand().contiguous", "decoder_qo.view.view.view", "modeling_genmc.GenMC.semantic_matching", "modeling_genmc.GenMC.option_linear().view", "decoder_qo.view.view.to", "torch.cat.to", "torch.cat.size", "decoder_qo.view.view.size", "decoder_qo.view.view.size", "encoder_qo.to", "decoder_qo.view.view.to", "qo_mask.to", "output_sequences_mask_ex.view.view.to", "qo_ids.to", "qo_mask.to", "q_ids.to", "q_mask.to", "transformers.file_utils.ModelOutput", "q_mask.to", "output_sequences_mask_ex.view.view.expand", "decoder_qo.view.view.expand", "modeling_genmc.GenMC.option_linear", "semantic_vec.to", "encoder_q.to", "output_sequences_mask_ex.view.view.size", "output_sequences_mask_ex.view.view.size", "decoder_qo.view.view.size", "decoder_qo.view.view.size", "decoder_qo.view.view.size"], "methods", ["None"], ["", "", "def", "get_option_score", "(", "self", ",", "q_ids", ",", "q_mask", ",", "qo_ids", ",", "qo_mask", ")", ":", "\n", "        ", "local_device", "=", "self", ".", "t5_model", ".", "encoder", ".", "device", "\n", "t5_output", "=", "self", ".", "t5_model", ".", "encoder", "(", "input_ids", "=", "qo_ids", ".", "to", "(", "local_device", ")", ",", "attention_mask", "=", "qo_mask", ".", "to", "(", "local_device", ")", ")", "\n", "encoder_qo", "=", "t5_output", "[", "0", "]", "\n", "\n", "t5_output", "=", "self", ".", "t5_model", ".", "encoder", "(", "input_ids", "=", "q_ids", ".", "to", "(", "local_device", ")", ",", "attention_mask", "=", "q_mask", ".", "to", "(", "local_device", ")", ")", "\n", "encoder_q", "=", "t5_output", "[", "0", "]", "\n", "local_device", "=", "self", ".", "t5_model", ".", "device", "\n", "t5_output", "=", "self", ".", "t5_model", ".", "generate", "(", "\n", "encoder_outputs", "=", "ModelOutput", "(", "last_hidden_state", "=", "encoder_q", ".", "to", "(", "local_device", ")", ")", ",", "\n", "attention_mask", "=", "q_mask", ".", "to", "(", "local_device", ")", ",", "\n", "do_sample", "=", "False", ",", "\n", "output_hidden_states", "=", "True", ",", "\n", "return_dict_in_generate", "=", "True", "\n", ")", "\n", "output_sequences", "=", "t5_output", ".", "sequences", "\n", "output_sequences", "=", "output_sequences", "[", ":", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "decoder_o", "=", "t5_output", ".", "decoder_hidden_states", "\n", "decoder_o", "=", "[", "item", "[", "-", "1", "]", "for", "item", "in", "decoder_o", "]", "\n", "decoder_o", "=", "torch", ".", "cat", "(", "decoder_o", ",", "dim", "=", "1", ")", "\n", "\n", "output_sequences_mask1", "=", "output_sequences", "!=", "0", "\n", "output_sequences_mask2", "=", "output_sequences", "!=", "1", "\n", "output_sequences_mask", "=", "output_sequences_mask1", "*", "output_sequences_mask2", "\n", "output_sequences_mask", "=", "output_sequences_mask", ".", "long", "(", ")", "\n", "decoder_qo", "=", "torch", ".", "cat", "(", "[", "encoder_q", ",", "decoder_o", "]", ",", "dim", "=", "1", ")", "\n", "output_sequences_mask", "=", "torch", ".", "cat", "(", "[", "q_mask", ",", "output_sequences_mask", "]", ",", "dim", "=", "1", ")", "\n", "local_device", "=", "self", ".", "transformer_laryer_de", ".", "device", "\n", "decoder_qo", ",", "_", "=", "self", ".", "transformer_laryer_de", "(", "decoder_qo", ".", "to", "(", "local_device", ")", ",", "output_sequences_mask", ".", "to", "(", "local_device", ")", ")", "\n", "output_sequences_mask_ex", "=", "output_sequences_mask", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "output_sequences_mask_ex", "=", "output_sequences_mask_ex", ".", "expand", "(", "\n", "[", "output_sequences_mask_ex", ".", "size", "(", "0", ")", ",", "self", ".", "choice_num", ",", "output_sequences_mask_ex", ".", "size", "(", "-", "1", ")", "]", ")", ".", "contiguous", "(", ")", "\n", "output_sequences_mask_ex", "=", "output_sequences_mask_ex", ".", "view", "(", "-", "1", ",", "output_sequences_mask", ".", "size", "(", "-", "1", ")", ")", "\n", "decoder_qo", "=", "decoder_qo", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "decoder_qo", "=", "decoder_qo", ".", "expand", "(", "\n", "[", "decoder_qo", ".", "size", "(", "0", ")", ",", "self", ".", "choice_num", ",", "decoder_qo", ".", "size", "(", "-", "2", ")", ",", "decoder_qo", ".", "size", "(", "-", "1", ")", "]", ")", ".", "contiguous", "(", ")", "\n", "decoder_qo", "=", "decoder_qo", ".", "view", "(", "-", "1", ",", "decoder_qo", ".", "size", "(", "-", "2", ")", ",", "decoder_qo", ".", "size", "(", "-", "1", ")", ")", "\n", "local_device", "=", "self", ".", "semantic_matching", ".", "device", "\n", "semantic_vec", ",", "_", ",", "_", "=", "self", ".", "semantic_matching", "(", "encoder_qo", ".", "to", "(", "local_device", ")", ",", "decoder_qo", ".", "to", "(", "local_device", ")", ",", "\n", "qo_mask", ".", "to", "(", "local_device", ")", ",", "output_sequences_mask_ex", ".", "to", "(", "local_device", ")", ")", "\n", "local_device", "=", "self", ".", "option_linear", ".", "device", "\n", "opt_score", "=", "self", ".", "option_linear", "(", "semantic_vec", ".", "to", "(", "local_device", ")", ")", ".", "view", "(", "-", "1", ",", "self", ".", "choice_num", ")", "\n", "\n", "return", "opt_score", ",", "output_sequences", "", "", "", ""]]}