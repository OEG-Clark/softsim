{"home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.multi_turn.get_nbest_file": [[18, 38], ["os.path.join", "logger.info", "os.path.isfile", "logger.info", "logger.info", "subprocess.Popen().wait", "os.path.isfile", "logger.error", "exit", "subprocess.Popen"], "function", ["None"], ["def", "get_nbest_file", "(", "model_dir", ",", "dev_file", ",", "params", ")", ":", "\n", "    ", "command", "=", "'python run_squad.py --model_type bert \\\n            --model_name_or_path bert-large-uncased-whole-word-masking \\\n            --do_eval --do_lower_case --train_file %s \\\n            --predict_file %s --max_seq_length 384  --doc_stride 128 --output_dir %s \\\n            --per_gpu_eval_batch_size=12 --eval_prefix dev'", "%", "(", "params", ".", "predict_file", ",", "dev_file", ",", "model_dir", ")", "\n", "if", "params", ".", "fp16", ":", "\n", "        ", "command", "+=", "' --fp16'", "\n", "", "nbest_file", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "'nbest_predictions_dev.json'", ")", "\n", "if", "params", ".", "debug", "and", "os", ".", "path", ".", "isfile", "(", "nbest_file", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'%s already existed and we use it.'", "%", "nbest_file", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "'Generating nbest file...'", ")", "\n", "subprocess", ".", "Popen", "(", "command", ",", "shell", "=", "True", ")", ".", "wait", "(", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "isfile", "(", "nbest_file", ")", ":", "\n", "        ", "logger", ".", "error", "(", "'Nbest file %s is not found.'", "%", "nbest_file", ")", "\n", "exit", "(", ")", "\n", "", "logger", ".", "info", "(", "'Got nbest file %s'", "%", "nbest_file", ")", "\n", "return", "nbest_file", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.multi_turn.get_new_train_file": [[39, 49], ["os.path.join", "subprocess.Popen().wait", "logger.info", "os.path.isfile", "logger.error", "exit", "subprocess.Popen"], "function", ["None"], ["", "def", "get_new_train_file", "(", "dev_file", ",", "nbest_file", ",", "model_dir", ",", "params", ")", ":", "\n", "    ", "new_train_file", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "'train_data_for_next_turn.json'", ")", "\n", "command", "=", "'python generate_new_qadata.py --input %s --nbest %s --output %s \\\n            --generate_method %d --score_threshold %.4f --seed %d'", "%", "(", "dev_file", ",", "nbest_file", ",", "new_train_file", ",", "params", ".", "generate_method", ",", "params", ".", "score_threshold", ",", "params", ".", "seed", ")", "\n", "subprocess", ".", "Popen", "(", "command", ",", "shell", "=", "True", ")", ".", "wait", "(", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "new_train_file", ")", ":", "\n", "        ", "logger", ".", "error", "(", "'New train file %s is not found.'", "%", "new_train_file", ")", "\n", "exit", "(", ")", "\n", "", "logger", ".", "info", "(", "'Got new train file %s'", "%", "new_train_file", ")", "\n", "return", "new_train_file", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.multi_turn.do_evaluate": [[51, 58], ["evaluate.evaluate", "open", "json.load", "open", "json.load"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.evaluate"], ["", "def", "do_evaluate", "(", "dataset_file", ",", "prediction_file", ")", ":", "\n", "    ", "with", "open", "(", "dataset_file", ")", "as", "df", ":", "\n", "        ", "dataset_json", "=", "json", ".", "load", "(", "df", ")", "\n", "dataset", "=", "dataset_json", "[", "'data'", "]", "\n", "", "with", "open", "(", "prediction_file", ")", "as", "pf", ":", "\n", "        ", "predictions", "=", "json", ".", "load", "(", "pf", ")", "\n", "", "return", "evaluate", "(", "dataset", ",", "predictions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.multi_turn.train_model": [[59, 90], ["subprocess.Popen().wait", "os.listdir", "multi_turn.do_evaluate", "subprocess.Popen", "os.path.join", "multi_turn.do_evaluate", "filename.replace().replace", "os.path.join", "subprocess.Popen().wait", "subprocess.Popen().wait", "subprocess.Popen().wait", "subprocess.Popen().wait", "filename.startswith", "os.path.join", "filename.replace", "subprocess.Popen", "subprocess.Popen", "subprocess.Popen", "subprocess.Popen"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.multi_turn.do_evaluate", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.multi_turn.do_evaluate"], ["", "def", "train_model", "(", "train_file", ",", "model_dir", ",", "output_dir", ",", "params", ")", ":", "\n", "    ", "command", "=", "'python -m torch.distributed.launch --nproc_per_node=4 run_squad.py \\\n        --model_type bert  --model_name_or_path %s --do_train  --do_eval  --do_lower_case \\\n        --train_file %s --predict_file %s \\\n        --learning_rate 3e-5  --num_train_epochs 1.0  --max_seq_length 384  --doc_stride 128 \\\n        --output_dir %s  --per_gpu_eval_batch_size=6  --per_gpu_train_batch_size=6 --seed %d \\\n        --logging_steps 1000  --save_steps 1000 --eval_all_checkpoints \\\n        --overwrite_output_dir --overwrite_cache'", "%", "(", "model_dir", ",", "train_file", ",", "params", ".", "predict_file", ",", "output_dir", ",", "params", ".", "seed", ")", "\n", "if", "params", ".", "fp16", ":", "\n", "        ", "command", "+=", "' --fp16'", "\n", "", "subprocess", ".", "Popen", "(", "command", ",", "shell", "=", "True", ")", ".", "wait", "(", ")", "\n", "\n", "# select best model for next turn", "\n", "new_model_dir", "=", "output_dir", "\n", "score", "=", "do_evaluate", "(", "params", ".", "predict_file", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'predictions_.json'", ")", ")", "[", "'f1'", "]", "\n", "\n", "for", "filename", "in", "os", ".", "listdir", "(", "output_dir", ")", ":", "\n", "        ", "if", "(", "not", "filename", ".", "startswith", "(", "'predictions_'", ")", ")", "or", "(", "filename", "==", "'predictions_.json'", ")", ":", "\n", "            ", "continue", "\n", "", "new_score", "=", "do_evaluate", "(", "params", ".", "predict_file", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "filename", ")", ")", "[", "'f1'", "]", "\n", "if", "new_score", ">", "score", ":", "\n", "            ", "score", "=", "new_score", "\n", "ckpt", "=", "filename", ".", "replace", "(", "'.json'", ",", "''", ")", ".", "replace", "(", "'predictions_'", ",", "'checkpoint-'", ")", "\n", "new_model_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "ckpt", ")", "\n", "subprocess", ".", "Popen", "(", "'cp %s/vocab.txt  %s'", "%", "(", "output_dir", ",", "new_model_dir", ")", ",", "shell", "=", "True", ")", ".", "wait", "(", ")", "\n", "subprocess", ".", "Popen", "(", "'cp %s/special_tokens_map.json  %s'", "%", "(", "output_dir", ",", "new_model_dir", ")", ",", "shell", "=", "True", ")", ".", "wait", "(", ")", "\n", "subprocess", ".", "Popen", "(", "'cp %s/added_tokens.json  %s'", "%", "(", "output_dir", ",", "new_model_dir", ")", ",", "shell", "=", "True", ")", ".", "wait", "(", ")", "\n", "subprocess", ".", "Popen", "(", "'cp %s/%s  %s/predictions_.json'", "%", "(", "output_dir", ",", "filename", ",", "new_model_dir", ")", ",", "shell", "=", "True", ")", ".", "wait", "(", ")", "\n", "\n", "\n", "", "", "return", "new_model_dir", ",", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.multi_turn.main": [[93, 139], ["os.path.join", "os.path.join", "logger.info", "subprocess.Popen().wait", "subprocess.Popen().wait", "subprocess.Popen().wait", "subprocess.Popen().wait", "subprocess.Popen().wait", "subprocess.Popen().wait", "subprocess.Popen().wait", "os.path.exists", "enumerate", "os.path.exists", "subprocess.Popen().wait", "subprocess.Popen().wait", "os.path.join", "logger.info", "logger.info", "os.path.join", "multi_turn.get_nbest_file", "multi_turn.get_new_train_file", "multi_turn.train_model", "subprocess.Popen", "subprocess.Popen", "subprocess.Popen", "subprocess.Popen", "subprocess.Popen", "subprocess.Popen", "subprocess.Popen", "multi_turn.do_evaluate", "os.path.exists", "subprocess.Popen().wait", "logger.info", "subprocess.Popen", "subprocess.Popen", "os.path.join", "subprocess.Popen"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.multi_turn.get_nbest_file", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.multi_turn.get_new_train_file", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.multi_turn.train_model", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.multi_turn.do_evaluate"], ["", "def", "main", "(", "params", ")", ":", "\n", "    ", "dev_data_name", "=", "os", ".", "path", ".", "join", "(", "args", ".", "refine_data_dir", ",", "'uqa_train_refine_%d.json'", ")", "\n", "\n", "model_dir", "=", "os", ".", "path", ".", "join", "(", "params", ".", "output_dir", ",", "'init'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "model_dir", ")", ":", "\n", "        ", "subprocess", ".", "Popen", "(", "'mkdir -p %s'", "%", "model_dir", ",", "shell", "=", "True", ")", ".", "wait", "(", ")", "\n", "", "logger", ".", "info", "(", "'Copy model from %s to %s.'", "%", "(", "params", ".", "model_dir", ",", "model_dir", ")", ")", "\n", "subprocess", ".", "Popen", "(", "'cp %s/vocab.txt %s'", "%", "(", "params", ".", "model_dir", ",", "model_dir", ")", ",", "shell", "=", "True", ")", ".", "wait", "(", ")", "\n", "subprocess", ".", "Popen", "(", "'cp %s/special_tokens_map.json %s'", "%", "(", "params", ".", "model_dir", ",", "model_dir", ")", ",", "shell", "=", "True", ")", ".", "wait", "(", ")", "\n", "subprocess", ".", "Popen", "(", "'cp %s/added_tokens.json %s'", "%", "(", "params", ".", "model_dir", ",", "model_dir", ")", ",", "shell", "=", "True", ")", ".", "wait", "(", ")", "\n", "subprocess", ".", "Popen", "(", "'cp %s/config.json %s'", "%", "(", "params", ".", "model_dir", ",", "model_dir", ")", ",", "shell", "=", "True", ")", ".", "wait", "(", ")", "\n", "subprocess", ".", "Popen", "(", "'cp %s/training_args.bin %s'", "%", "(", "params", ".", "model_dir", ",", "model_dir", ")", ",", "shell", "=", "True", ")", ".", "wait", "(", ")", "\n", "subprocess", ".", "Popen", "(", "'cp %s/predictions_.json %s'", "%", "(", "params", ".", "model_dir", ",", "model_dir", ")", ",", "shell", "=", "True", ")", ".", "wait", "(", ")", "\n", "subprocess", ".", "Popen", "(", "'cp %s/pytorch_model.bin %s'", "%", "(", "params", ".", "model_dir", ",", "model_dir", ")", ",", "shell", "=", "True", ")", ".", "wait", "(", ")", "\n", "\n", "if", "params", ".", "debug", ":", "\n", "        ", "subprocess", ".", "Popen", "(", "'cp %s/nbest_predictions_6_no_train_eval2.json %s/nbest_predictions_dev.json'", "%", "(", "params", ".", "model_dir", ",", "model_dir", ")", ",", "shell", "=", "True", ")", ".", "wait", "(", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "model_dir", ",", "'predictions_.json'", ")", ")", ":", "\n", "        ", "current_score", "=", "do_evaluate", "(", "params", ".", "predict_file", ",", "os", ".", "path", ".", "join", "(", "model_dir", ",", "'predictions_.json'", ")", ")", "[", "'f1'", "]", "\n", "", "else", ":", "\n", "        ", "current_score", "=", "0.0", "\n", "\n", "", "order", "=", "[", "1", ",", "3", ",", "2", ",", "4", ",", "5", ",", "0", "]", "\n", "if", "params", ".", "debug", ":", "\n", "        ", "order", "=", "[", "6", "]", "+", "order", "\n", "\n", "", "for", "step", ",", "idx", "in", "enumerate", "(", "order", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'-'", "*", "80", ")", "\n", "logger", ".", "info", "(", "'Prepare for turn_%d / Current f1 %.2f/ Current model %s'", "%", "(", "step", ",", "current_score", ",", "model_dir", ")", ")", "\n", "dev_file", "=", "dev_data_name", "%", "idx", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "params", ".", "output_dir", ",", "'turn_%d'", "%", "step", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "            ", "subprocess", ".", "Popen", "(", "'mkdir -p %s'", "%", "output_dir", ",", "shell", "=", "True", ")", ".", "wait", "(", ")", "\n", "\n", "", "nbest_file", "=", "get_nbest_file", "(", "model_dir", ",", "dev_file", ",", "params", ")", "\n", "new_train_file", "=", "get_new_train_file", "(", "dev_file", ",", "nbest_file", ",", "model_dir", ",", "params", ")", "\n", "\n", "new_model_dir", ",", "new_score", "=", "train_model", "(", "new_train_file", ",", "model_dir", ",", "output_dir", ",", "params", ")", "\n", "\n", "if", "new_score", ">", "current_score", ":", "\n", "            ", "model_dir", "=", "new_model_dir", "\n", "current_score", "=", "new_score", "\n", "logger", ".", "info", "(", "'Find better model %s and f1 is %.2f'", "%", "(", "model_dir", ",", "current_score", ")", ")", "\n", "\n", "", "params", ".", "score_threshold", "=", "params", ".", "score_threshold", "*", "params", ".", "threshold_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.generate_new_qadata.get_ref_data": [[32, 39], ["open", "json.load"], "function", ["None"], ["", "", "def", "get_ref_data", "(", "data_path", "=", "'./data/wikiref.json'", ")", ":", "\n", "    ", "with", "open", "(", "data_path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "reader", ")", "\n", "", "refdata", "=", "{", "}", "\n", "for", "item", "in", "data", ":", "\n", "        ", "refdata", "[", "item", "[", "'uid'", "]", "]", "=", "item", "[", "'summary'", "]", "\n", "", "return", "refdata", "\n", "", "refdata", "=", "get_ref_data", "(", "os", ".", "path", ".", "join", "(", "os", ".", "getenv", "(", "\"REFQA_DATA_DIR\"", ",", "\"./data\"", ")", ",", "'wikiref.json'", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.generate_new_qadata.get_new_question": [[46, 101], ["spacy_parser", "spacy_tagger", "sorted", "wikiref_process.get_clause_v2", "cloze2natural.identity_translate", "spacy_tagger", "sorted.append", "data_utils.reformulate_quesiton", "cloze2natural.identity_translate.startswith", "cloze2natural.identity_translate.startswith", "sentences.append", "len", "len", "c_tokens.append", "clause.replace", "len", "len"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.wikiref_process.get_clause_v2", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.cloze2natural.identity_translate", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.reformulate_quesiton"], ["def", "get_new_question", "(", "context", ",", "answer", ",", "answer_start", ",", "summary", ",", "qtype", ")", ":", "\n", "    ", "sentences", "=", "[", "]", "\n", "for", "sent", "in", "summary", ":", "\n", "        ", "if", "answer", "in", "sent", ":", "\n", "            ", "sentences", ".", "append", "(", "sent", ")", "\n", "", "", "if", "len", "(", "sentences", ")", "==", "0", "or", "answer_start", "==", "-", "1", ":", "\n", "        ", "return", "None", "\n", "\n", "", "doc", "=", "spacy_parser", "(", "context", ")", "\n", "context_sent", "=", "None", "\n", "char_cnt", "=", "0", "\n", "for", "sent_item", "in", "doc", ".", "sents", ":", "\n", "        ", "sent", "=", "sent_item", ".", "text", "\n", "if", "char_cnt", "<=", "answer_start", "<", "char_cnt", "+", "len", "(", "sent", ")", ":", "\n", "            ", "context_sent", "=", "sent", "\n", "break", "\n", "", "else", ":", "\n", "            ", "char_cnt", "+=", "len", "(", "sent", ")", "\n", "while", "char_cnt", "<", "len", "(", "context", ")", "and", "context", "[", "char_cnt", "]", "==", "' '", ":", "\n", "                ", "char_cnt", "+=", "1", "\n", "\n", "", "", "", "if", "context_sent", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "c_tokens", "=", "[", "]", "\n", "c_doc", "=", "spacy_tagger", "(", "context_sent", ")", "\n", "for", "token", "in", "c_doc", ":", "\n", "        ", "if", "not", "token", ".", "is_stop", ":", "\n", "            ", "c_tokens", ".", "append", "(", "token", ".", "lemma_", ")", "\n", "\n", "", "", "result", "=", "[", "]", "\n", "for", "sent", "in", "sentences", ":", "\n", "        ", "sent_doc", "=", "spacy_tagger", "(", "sent", ")", "\n", "score", "=", "0", "\n", "for", "token", "in", "sent_doc", ":", "\n", "            ", "if", "token", ".", "is_stop", ":", "\n", "                ", "continue", "\n", "", "if", "token", ".", "lemma_", "in", "c_tokens", ":", "\n", "                ", "score", "+=", "1", "\n", "", "", "result", ".", "append", "(", "[", "score", ",", "sent", "]", ")", "\n", "", "result", "=", "sorted", "(", "result", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "sentence", "=", "result", "[", "-", "1", "]", "[", "1", "]", "\n", "cloze_text", "=", "None", "\n", "for", "clause", "in", "get_clause_v2", "(", "sentence", ",", "bene_parser", ")", ":", "\n", "        ", "if", "answer", "in", "clause", ":", "\n", "            ", "cloze_text", "=", "clause", ".", "replace", "(", "answer", ",", "qtype", ",", "1", ")", "\n", "break", "\n", "", "", "if", "cloze_text", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "new_question", "=", "identity_translate", "(", "reformulate_quesiton", "(", "cloze_text", ",", "spacy_parser", ",", "reform_version", "=", "1", ")", ")", "\n", "if", "new_question", ".", "startswith", "(", "'Wh'", ")", "or", "new_question", ".", "startswith", "(", "'How'", ")", ":", "\n", "        ", "return", "new_question", "\n", "", "else", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.generate_new_qadata.get_answer_start": [[102, 106], ["len", "context.find", "context.split"], "function", ["None"], ["", "", "def", "get_answer_start", "(", "context", ",", "answer", ",", "orig_doc_start", ")", ":", "\n", "    ", "begin_index", "=", "len", "(", "' '", ".", "join", "(", "context", ".", "split", "(", "' '", ")", "[", ":", "orig_doc_start", "]", ")", ")", "\n", "answer_index", "=", "context", ".", "find", "(", "answer", ",", "begin_index", ")", "\n", "return", "answer_index", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.generate_new_qadata.generate": [[107, 167], ["print", "json.dump", "open", "open", "json.load", "tqdm.tqdm", "new_data.append", "open", "json.load", "len", "paras.append", "len", "len", "copy.deepcopy", "ans[].strip", "generate_new_qadata.get_answer_start", "generate_new_qadata.get_new_question", "qas.append", "qas.append", "qid.split", "qid.split"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.wikiref_process.get_answer_start", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.generate_new_qadata.get_new_question"], ["", "def", "generate", "(", "input_file", ",", "nbest_file", ",", "output_file", ",", "remove_em_answer", "=", "False", ",", "hard_em", "=", "False", ",", "score_lower_bound", "=", "0.5", ",", "debug", "=", "False", ")", ":", "\n", "    ", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "        ", "input_data", "=", "json", ".", "load", "(", "reader", ")", "[", "\"data\"", "]", "\n", "", "with", "open", "(", "nbest_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "        ", "nbest_data", "=", "json", ".", "load", "(", "reader", ")", "\n", "\n", "", "q_count", "=", "0", "\n", "\n", "new_data", "=", "[", "]", "\n", "for", "entry", "in", "(", "input_data", "if", "not", "debug", "else", "tqdm", "(", "input_data", ",", "desc", "=", "'generate'", ")", ")", ":", "\n", "        ", "paras", "=", "[", "]", "\n", "for", "paragraph", "in", "entry", "[", "'paragraphs'", "]", ":", "\n", "            ", "context", "=", "paragraph", "[", "'context'", "]", "\n", "qas", "=", "[", "]", "\n", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "                ", "answer_text", "=", "qa", "[", "'answers'", "]", "[", "0", "]", "[", "'text'", "]", "\n", "qid", "=", "qa", "[", "'id'", "]", "\n", "cnt", "=", "0", "\n", "for", "ans", "in", "(", "nbest_data", "[", "qid", "]", "[", ":", "1", "]", "if", "hard_em", "else", "nbest_data", "[", "qid", "]", ")", ":", "\n", "                    ", "if", "ans", "[", "'probability'", "]", "<", "score_lower_bound", ":", "\n", "                        ", "continue", "\n", "", "new_qa", "=", "copy", ".", "deepcopy", "(", "qa", ")", "\n", "new_qa", "[", "'id'", "]", "=", "qa", "[", "'id'", "]", "+", "'_%d'", "%", "cnt", "\n", "ans", "[", "'text'", "]", "=", "ans", "[", "'text'", "]", ".", "strip", "(", ")", "\n", "\n", "if", "debug", ":", "\n", "                        ", "new_qa", "[", "'orig_question'", "]", "=", "qa", "[", "'question'", "]", "\n", "new_qa", "[", "'orig_answer'", "]", "=", "answer_text", "\n", "new_qa", "[", "'predict_answer'", "]", "=", "ans", "[", "'text'", "]", "\n", "new_qa", "[", "'summary'", "]", "=", "refdata", "[", "qid", ".", "split", "(", "'_'", ")", "[", "0", "]", "]", "\n", "\n", "", "if", "(", "answer_text", "==", "ans", "[", "'text'", "]", ")", "or", "(", "ans", "[", "'text'", "]", "in", "answer_text", ")", ":", "\n", "                        ", "if", "remove_em_answer", "and", "answer_text", "==", "ans", "[", "'text'", "]", ":", "\n", "                            ", "continue", "\n", "", "else", ":", "\n", "                            ", "qas", ".", "append", "(", "new_qa", ")", "\n", "", "", "else", ":", "\n", "                        ", "new_qa", "[", "'answers'", "]", "[", "0", "]", "[", "'text'", "]", "=", "ans", "[", "'text'", "]", "\n", "new_qa", "[", "'answers'", "]", "[", "0", "]", "[", "'answer_start'", "]", "=", "get_answer_start", "(", "context", ",", "ans", "[", "'text'", "]", ",", "ans", "[", "'orig_doc_start'", "]", ")", "\n", "prev_qtype", "=", "qa", "[", "'answers'", "]", "[", "0", "]", "[", "'type'", "]", "\n", "new_qa", "[", "'question'", "]", "=", "get_new_question", "(", "context", ",", "ans", "[", "'text'", "]", ",", "new_qa", "[", "'answers'", "]", "[", "0", "]", "[", "'answer_start'", "]", ",", "refdata", "[", "qid", ".", "split", "(", "'_'", ")", "[", "0", "]", "]", ",", "entity_type_map", "[", "prev_qtype", "]", ")", "\n", "\n", "if", "(", "new_qa", "[", "'question'", "]", "is", "None", ")", "or", "(", "new_qa", "[", "'answers'", "]", "[", "0", "]", "[", "'answer_start'", "]", "==", "-", "1", ")", ":", "\n", "                            ", "continue", "\n", "", "qas", ".", "append", "(", "new_qa", ")", "\n", "", "cnt", "+=", "1", "\n", "\n", "", "", "if", "len", "(", "qas", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "q_count", "+=", "len", "(", "qas", ")", "\n", "paragraph", "[", "'qas'", "]", "=", "qas", "\n", "paras", ".", "append", "(", "paragraph", ")", "\n", "", "if", "len", "(", "paras", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "", "entry", "[", "'paragraphs'", "]", "=", "paras", "\n", "new_data", ".", "append", "(", "entry", ")", "\n", "\n", "", "print", "(", "'New Questions'", ",", "q_count", ")", "\n", "\n", "json", ".", "dump", "(", "{", "\"version\"", ":", "\"v2.0\"", ",", "'data'", ":", "new_data", "}", ",", "open", "(", "output_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.generate_new_qadata.generate2": [[168, 232], ["copy.deepcopy", "random.shuffle", "data_utils.filter_data_given_qids", "len", "print", "json.dump", "open", "open", "json.load", "new_data.append", "open", "json.load", "len", "paras.append", "len", "len", "copy.deepcopy", "ans[].strip", "generate_new_qadata.get_answer_start", "generate_new_qadata.get_new_question", "qas.append", "em_qids.append", "qas.append", "qid.split", "qid.split"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.cloze2natural.filter_data_given_qids", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.wikiref_process.get_answer_start", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.generate_new_qadata.get_new_question"], ["", "def", "generate2", "(", "input_file", ",", "nbest_file", ",", "output_file", ",", "hard_em", "=", "False", ",", "score_lower_bound", "=", "0.5", ",", "debug", "=", "False", ")", ":", "\n", "    ", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "        ", "input_data", "=", "json", ".", "load", "(", "reader", ")", "[", "\"data\"", "]", "\n", "", "with", "open", "(", "nbest_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "        ", "nbest_data", "=", "json", ".", "load", "(", "reader", ")", "\n", "\n", "", "q_count", "=", "0", "\n", "em_qids", "=", "[", "]", "\n", "\n", "new_data", "=", "[", "]", "\n", "for", "entry", "in", "copy", ".", "deepcopy", "(", "input_data", ")", ":", "\n", "        ", "paras", "=", "[", "]", "\n", "for", "paragraph", "in", "entry", "[", "'paragraphs'", "]", ":", "\n", "            ", "context", "=", "paragraph", "[", "'context'", "]", "\n", "qas", "=", "[", "]", "\n", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "                ", "answer_text", "=", "qa", "[", "'answers'", "]", "[", "0", "]", "[", "'text'", "]", "\n", "qid", "=", "qa", "[", "'id'", "]", "\n", "cnt", "=", "0", "\n", "for", "ans", "in", "(", "nbest_data", "[", "qid", "]", "[", ":", "1", "]", "if", "hard_em", "else", "nbest_data", "[", "qid", "]", ")", ":", "\n", "                    ", "if", "ans", "[", "'probability'", "]", "<", "score_lower_bound", ":", "\n", "                        ", "continue", "\n", "", "new_qa", "=", "copy", ".", "deepcopy", "(", "qa", ")", "\n", "new_qa", "[", "'id'", "]", "=", "qa", "[", "'id'", "]", "+", "'_%d'", "%", "cnt", "\n", "ans", "[", "'text'", "]", "=", "ans", "[", "'text'", "]", ".", "strip", "(", ")", "\n", "if", "debug", ":", "\n", "                        ", "new_qa", "[", "'orig_question'", "]", "=", "qa", "[", "'question'", "]", "\n", "new_qa", "[", "'orig_answer'", "]", "=", "answer_text", "\n", "new_qa", "[", "'predict_answer'", "]", "=", "ans", "[", "'text'", "]", "\n", "new_qa", "[", "'summary'", "]", "=", "refdata", "[", "qid", ".", "split", "(", "'_'", ")", "[", "0", "]", "]", "\n", "\n", "", "if", "(", "answer_text", "==", "ans", "[", "'text'", "]", ")", "or", "(", "ans", "[", "'text'", "]", "in", "answer_text", ")", ":", "\n", "                        ", "if", "answer_text", "==", "ans", "[", "'text'", "]", ":", "\n", "                            ", "em_qids", ".", "append", "(", "qid", ")", "\n", "", "else", ":", "\n", "                            ", "qas", ".", "append", "(", "new_qa", ")", "\n", "", "", "else", ":", "\n", "                        ", "new_qa", "[", "'answers'", "]", "[", "0", "]", "[", "'text'", "]", "=", "ans", "[", "'text'", "]", "\n", "new_qa", "[", "'answers'", "]", "[", "0", "]", "[", "'answer_start'", "]", "=", "get_answer_start", "(", "context", ",", "ans", "[", "'text'", "]", ",", "ans", "[", "'orig_doc_start'", "]", ")", "\n", "prev_qtype", "=", "qa", "[", "'answers'", "]", "[", "0", "]", "[", "'type'", "]", "\n", "new_qa", "[", "'question'", "]", "=", "get_new_question", "(", "context", ",", "ans", "[", "'text'", "]", ",", "new_qa", "[", "'answers'", "]", "[", "0", "]", "[", "'answer_start'", "]", ",", "refdata", "[", "qid", ".", "split", "(", "'_'", ")", "[", "0", "]", "]", ",", "entity_type_map", "[", "prev_qtype", "]", ")", "\n", "\n", "if", "(", "new_qa", "[", "'question'", "]", "is", "None", ")", "or", "(", "new_qa", "[", "'answers'", "]", "[", "0", "]", "[", "'answer_start'", "]", "==", "-", "1", ")", ":", "\n", "                            ", "continue", "\n", "", "qas", ".", "append", "(", "new_qa", ")", "\n", "", "cnt", "+=", "1", "\n", "\n", "", "", "if", "len", "(", "qas", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "q_count", "+=", "len", "(", "qas", ")", "\n", "paragraph", "[", "'qas'", "]", "=", "qas", "\n", "paras", ".", "append", "(", "paragraph", ")", "\n", "", "if", "len", "(", "paras", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "", "entry", "[", "'paragraphs'", "]", "=", "paras", "\n", "new_data", ".", "append", "(", "entry", ")", "\n", "\n", "", "random", ".", "shuffle", "(", "em_qids", ")", "\n", "em_qids", "=", "em_qids", "[", ":", "q_count", "]", "\n", "new_data", "+=", "filter_data_given_qids", "(", "input_data", ",", "em_qids", ")", "\n", "q_count", "+=", "len", "(", "em_qids", ")", "\n", "print", "(", "'New Questions'", ",", "q_count", ")", "\n", "\n", "json", ".", "dump", "(", "{", "\"version\"", ":", "\"v2.0\"", ",", "'data'", ":", "new_data", "}", ",", "open", "(", "output_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.evaluate.normalize_answer": [[11, 27], ["evaluate.normalize_answer.white_space_fix"], "function", ["None"], ["def", "normalize_answer", "(", "s", ")", ":", "\n", "    ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "return", "re", ".", "sub", "(", "r'\\b(a|an|the)\\b'", ",", "' '", ",", "text", ")", "\n", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.evaluate.f1_score": [[29, 40], ["normalize_answer().split", "normalize_answer().split", "sum", "collections.Counter", "collections.Counter", "common.values", "len", "len", "evaluate.normalize_answer", "evaluate.normalize_answer"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.normalize_answer", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.normalize_answer"], ["", "def", "f1_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "prediction_tokens", "=", "normalize_answer", "(", "prediction", ")", ".", "split", "(", ")", "\n", "ground_truth_tokens", "=", "normalize_answer", "(", "ground_truth", ")", ".", "split", "(", ")", "\n", "common", "=", "Counter", "(", "prediction_tokens", ")", "&", "Counter", "(", "ground_truth_tokens", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "num_same", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "prediction_tokens", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "ground_truth_tokens", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.evaluate.exact_match_score": [[42, 44], ["evaluate.normalize_answer", "evaluate.normalize_answer"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.normalize_answer", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.normalize_answer"], ["", "def", "exact_match_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "return", "(", "normalize_answer", "(", "prediction", ")", "==", "normalize_answer", "(", "ground_truth", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.evaluate.metric_max_over_ground_truths": [[46, 52], ["max", "scores_for_ground_truths.append", "evaluate.exact_match_score", "evaluate.f1_score", "evaluate.f1_score", "evaluate.f1_score"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.evaluate.exact_match_score", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.evaluate.f1_score", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.evaluate.f1_score", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.evaluate.f1_score"], ["", "def", "metric_max_over_ground_truths", "(", "metric_fn", ",", "prediction", ",", "ground_truths", ")", ":", "\n", "    ", "scores_for_ground_truths", "=", "[", "]", "\n", "for", "ground_truth", "in", "ground_truths", ":", "\n", "        ", "score", "=", "metric_fn", "(", "prediction", ",", "ground_truth", ")", "\n", "scores_for_ground_truths", ".", "append", "(", "score", ")", "\n", "", "return", "max", "(", "scores_for_ground_truths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.evaluate.evaluate": [[54, 76], ["list", "evaluate.metric_max_over_ground_truths", "evaluate.metric_max_over_ground_truths", "print", "map"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.evaluate.metric_max_over_ground_truths", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.evaluate.metric_max_over_ground_truths"], ["", "def", "evaluate", "(", "dataset", ",", "predictions", ")", ":", "\n", "    ", "f1", "=", "exact_match", "=", "total", "=", "0", "\n", "for", "article", "in", "dataset", ":", "\n", "        ", "for", "paragraph", "in", "article", "[", "'paragraphs'", "]", ":", "\n", "            ", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "                ", "total", "+=", "1", "\n", "if", "qa", "[", "'id'", "]", "not", "in", "predictions", ":", "\n", "                    ", "message", "=", "'Unanswered question '", "+", "qa", "[", "'id'", "]", "+", "' will receive score 0.'", "\n", "print", "(", "message", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "continue", "\n", "", "ground_truths", "=", "list", "(", "map", "(", "lambda", "x", ":", "x", "[", "'text'", "]", ",", "qa", "[", "'answers'", "]", ")", ")", "\n", "prediction", "=", "predictions", "[", "qa", "[", "'id'", "]", "]", "\n", "exact_match", "+=", "metric_max_over_ground_truths", "(", "\n", "exact_match_score", ",", "prediction", ",", "ground_truths", ")", "\n", "f1", "+=", "metric_max_over_ground_truths", "(", "\n", "f1_score", ",", "prediction", ",", "ground_truths", ")", "\n", "\n", "", "", "", "exact_match", "=", "100.0", "*", "exact_match", "/", "total", "\n", "f1", "=", "100.0", "*", "f1", "/", "total", "\n", "\n", "return", "{", "'exact_match'", ":", "exact_match", ",", "'f1'", ":", "f1", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.evaluate.evaluate_each_qtype": [[78, 110], ["print", "list", "evaluate.metric_max_over_ground_truths", "qa[].split", "other_wh.append", "print", "map"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.evaluate.metric_max_over_ground_truths"], ["", "def", "evaluate_each_qtype", "(", "dataset", ",", "predictions", ")", ":", "\n", "    ", "result", "=", "{", "}", "\n", "for", "wh", "in", "[", "'What'", ",", "'How'", ",", "'When'", ",", "'Where'", ",", "'Who'", ",", "'Other'", "]", ":", "\n", "        ", "result", "[", "wh", "]", "=", "{", "'f1'", ":", "0", ",", "'total'", ":", "0", "}", "\n", "\n", "", "other_wh", "=", "[", "]", "\n", "for", "article", "in", "dataset", ":", "\n", "        ", "for", "paragraph", "in", "article", "[", "'paragraphs'", "]", ":", "\n", "            ", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "                ", "wh", "=", "qa", "[", "'question'", "]", ".", "split", "(", "' '", ")", "[", "0", "]", "\n", "if", "wh", "not", "in", "result", ":", "\n", "                    ", "other_wh", ".", "append", "(", "wh", ")", "\n", "wh", "=", "'Other'", "\n", "", "result", "[", "wh", "]", "[", "'total'", "]", "+=", "1", "\n", "\n", "if", "qa", "[", "'id'", "]", "not", "in", "predictions", ":", "\n", "                    ", "message", "=", "'Unanswered question '", "+", "qa", "[", "'id'", "]", "+", "' will receive score 0.'", "\n", "print", "(", "message", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "continue", "\n", "", "ground_truths", "=", "list", "(", "map", "(", "lambda", "x", ":", "x", "[", "'text'", "]", ",", "qa", "[", "'answers'", "]", ")", ")", "\n", "prediction", "=", "predictions", "[", "qa", "[", "'id'", "]", "]", "\n", "result", "[", "wh", "]", "[", "'f1'", "]", "+=", "metric_max_over_ground_truths", "(", "\n", "f1_score", ",", "prediction", ",", "ground_truths", ")", "\n", "#print(Counter(other_wh))", "\n", "", "", "", "total", "=", "0", "\n", "for", "wh", "in", "result", ":", "\n", "        ", "total", "+=", "result", "[", "wh", "]", "[", "'total'", "]", "\n", "", "for", "wh", "in", "result", ":", "\n", "        ", "result", "[", "wh", "]", "[", "'f1'", "]", "/=", "result", "[", "wh", "]", "[", "'total'", "]", "\n", "print", "(", "wh", ",", "'F1'", ",", "result", "[", "wh", "]", "[", "'f1'", "]", ",", "'Rate'", ",", "result", "[", "wh", "]", "[", "'total'", "]", "/", "total", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.evaluate.evaluate_what": [[111, 138], ["sorted", "print", "list", "list", "evaluate.metric_max_over_ground_truths", "result.keys", "qa[].split", "wh.lower", "print", "map"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.evaluate.metric_max_over_ground_truths"], ["", "def", "evaluate_what", "(", "dataset", ",", "predictions", ")", ":", "\n", "    ", "result", "=", "{", "}", "\n", "for", "article", "in", "dataset", ":", "\n", "        ", "for", "paragraph", "in", "article", "[", "'paragraphs'", "]", ":", "\n", "            ", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "                ", "wh", ",", "token", "=", "qa", "[", "'question'", "]", ".", "split", "(", "' '", ")", "[", ":", "2", "]", "\n", "if", "wh", ".", "lower", "(", ")", "!=", "'what'", ":", "\n", "                    ", "continue", "\n", "", "if", "token", "not", "in", "result", ":", "\n", "                    ", "result", "[", "token", "]", "=", "{", "'f1'", ":", "0", ",", "'total'", ":", "0", "}", "\n", "", "result", "[", "token", "]", "[", "'total'", "]", "+=", "1", "\n", "if", "qa", "[", "'id'", "]", "not", "in", "predictions", ":", "\n", "                    ", "message", "=", "'Unanswered question '", "+", "qa", "[", "'id'", "]", "+", "' will receive score 0.'", "\n", "print", "(", "message", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "continue", "\n", "", "ground_truths", "=", "list", "(", "map", "(", "lambda", "x", ":", "x", "[", "'text'", "]", ",", "qa", "[", "'answers'", "]", ")", ")", "\n", "prediction", "=", "predictions", "[", "qa", "[", "'id'", "]", "]", "\n", "result", "[", "token", "]", "[", "'f1'", "]", "+=", "metric_max_over_ground_truths", "(", "\n", "f1_score", ",", "prediction", ",", "ground_truths", ")", "\n", "#print(Counter(other_wh))", "\n", "", "", "", "total", "=", "0", "\n", "for", "wh", "in", "result", ":", "\n", "        ", "total", "+=", "result", "[", "wh", "]", "[", "'total'", "]", "\n", "", "for", "wh", "in", "sorted", "(", "list", "(", "result", ".", "keys", "(", ")", ")", ",", "key", "=", "lambda", "x", ":", "result", "[", "x", "]", "[", "'total'", "]", ",", "reverse", "=", "True", ")", "[", ":", "20", "]", ":", "\n", "        ", "result", "[", "wh", "]", "[", "'f1'", "]", "/=", "result", "[", "wh", "]", "[", "'total'", "]", "\n", "print", "(", "wh", ",", "'F1'", ",", "'%.4f'", "%", "result", "[", "wh", "]", "[", "'f1'", "]", ",", "'Num'", ",", "result", "[", "wh", "]", "[", "'total'", "]", ",", "'Rate'", ",", "'%.4f'", "%", "(", "result", "[", "wh", "]", "[", "'total'", "]", "/", "total", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.tokenize": [[20, 39], ["data_utils.tokenize.is_whitespace"], "function", ["None"], ["def", "tokenize", "(", "text", ")", ":", "\n", "    ", "def", "is_whitespace", "(", "c", ")", ":", "\n", "        ", "if", "c", "==", "\" \"", "or", "c", "==", "\"\\t\"", "or", "c", "==", "\"\\r\"", "or", "c", "==", "\"\\n\"", "or", "ord", "(", "c", ")", "==", "0x202F", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n", "", "prev_is_whitespace", "=", "True", "\n", "doc_tokens", "=", "[", "]", "\n", "\n", "for", "c", "in", "text", ":", "\n", "        ", "if", "is_whitespace", "(", "c", ")", ":", "\n", "            ", "prev_is_whitespace", "=", "True", "\n", "", "else", ":", "\n", "            ", "if", "prev_is_whitespace", ":", "\n", "                ", "doc_tokens", ".", "append", "(", "c", ")", "\n", "", "else", ":", "\n", "                ", "doc_tokens", "[", "-", "1", "]", "+=", "c", "\n", "", "prev_is_whitespace", "=", "False", "\n", "", "", "return", "doc_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.parsing_tree_dfs": [[40, 52], ["len", "len", "data_utils.parsing_tree_dfs", "data_utils.parsing_tree_dfs"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.parsing_tree_dfs", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.parsing_tree_dfs"], ["", "def", "parsing_tree_dfs", "(", "node", ")", ":", "\n", "    ", "N", "=", "len", "(", "node", ".", "_", ".", "lefts", ")", "+", "len", "(", "node", ".", "_", ".", "rights", ")", "\n", "if", "N", "==", "0", ":", "\n", "        ", "return", "node", ".", "text", "\n", "\n", "", "text", "=", "''", "\n", "for", "child", "in", "node", ".", "_", ".", "lefts", ":", "\n", "        ", "text", "+=", "parsing_tree_dfs", "(", "child", ")", "+", "' '", "\n", "", "text", "+=", "node", ".", "text", "\n", "for", "child", "in", "node", ".", "_", ".", "rights", ":", "\n", "        ", "text", "+=", "' '", "+", "parsing_tree_dfs", "(", "child", ")", "\n", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.reform_tree": [[54, 75], ["data_utils.reform_tree", "node._.lefts.remove", "data_utils.reform_tree", "node._.rights.remove"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.reform_tree", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.reform_tree"], ["", "def", "reform_tree", "(", "node", ")", ":", "\n", "#print(node.text, node.head, node.text in ANSWER_TYPE)", "\n", "    ", "if", "node", ".", "text", "in", "ANSWER_TYPE", ":", "\n", "        ", "node", ".", "_", ".", "lefts", "=", "[", "]", "\n", "return", "True", "\n", "", "flag", "=", "False", "\n", "res", "=", "None", "\n", "for", "child", "in", "node", ".", "_", ".", "lefts", ":", "\n", "        ", "flag", "|=", "reform_tree", "(", "child", ")", "\n", "if", "flag", ":", "\n", "            ", "node", ".", "_", ".", "lefts", ".", "remove", "(", "child", ")", "\n", "node", ".", "_", ".", "lefts", "=", "[", "child", "]", "+", "node", ".", "_", ".", "lefts", "\n", "break", "\n", "", "", "if", "not", "flag", ":", "\n", "        ", "for", "child", "in", "node", ".", "_", ".", "rights", ":", "\n", "            ", "flag", "|=", "reform_tree", "(", "child", ")", "\n", "if", "flag", ":", "\n", "                ", "node", ".", "_", ".", "rights", ".", "remove", "(", "child", ")", "\n", "node", ".", "_", ".", "lefts", "=", "[", "child", "]", "+", "node", ".", "_", ".", "lefts", "\n", "break", "\n", "", "", "", "return", "flag", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.reformulate_quesiton": [[78, 102], ["parser", "new_question.strip", "roots.append", "data_utils.reform_tree", "roots.remove", "data_utils.parsing_tree_dfs"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.reform_tree", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.parsing_tree_dfs"], ["", "def", "reformulate_quesiton", "(", "question", ",", "parser", ",", "reform_version", "=", "1", ")", ":", "\n", "\n", "    ", "doc", "=", "parser", "(", "question", ")", "\n", "roots", "=", "[", "]", "\n", "for", "token", "in", "doc", ":", "\n", "        ", "token", ".", "_", ".", "lefts", "=", "[", "child", "for", "child", "in", "token", ".", "lefts", "]", "\n", "token", ".", "_", ".", "rights", "=", "[", "child", "for", "child", "in", "token", ".", "rights", "]", "\n", "if", "token", ".", "dep_", "==", "'ROOT'", ":", "\n", "            ", "roots", ".", "append", "(", "token", ")", "\n", "#print(token.text, token.head.text, [child for child in token.children])", "\n", "### reformulate ###", "\n", "", "", "for", "root", "in", "roots", ":", "\n", "        ", "if", "reform_version", "==", "1", ":", "\n", "            ", "result", "=", "reform_tree", "(", "root", ")", "\n", "", "else", ":", "\n", "            ", "result", "=", "False", "\n", "", "if", "result", ":", "\n", "            ", "roots", ".", "remove", "(", "root", ")", "\n", "roots", "=", "[", "root", "]", "+", "roots", "\n", "### tree to seqence ###", "\n", "", "", "new_question", "=", "''", "\n", "for", "root", "in", "roots", ":", "\n", "        ", "new_question", "+=", "' '", "+", "parsing_tree_dfs", "(", "root", ")", "\n", "", "return", "new_question", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.reformulate_demo": [[103, 120], ["spacy.load", "tqdm.tqdm", "qu.split", "print", "data_utils.reformulate_quesiton", "print", "print", "qs.append"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.reformulate_quesiton"], ["", "def", "reformulate_demo", "(", ")", ":", "\n", "    ", "parser", "=", "spacy", ".", "load", "(", "\"en\"", ",", "disable", "=", "[", "'ner'", ",", "'tagger'", "]", ")", "\n", "#with open('/home/zhongli/projects/XLMRAW/data/mono/cl2/news.cl2', 'r', encoding='utf-8') as f:", "\n", "#    questions = [ line.strip().replace('PERSON/NORP/ORG' ,'PERSONNORPORG') for line in f ]", "\n", "#f = open('/home/zhongli/projects/XLMRAW/data/mono/cl2r1/news.cl2r1', 'w', encoding='utf-8')", "\n", "questions", "=", "[", "'What Guillermo crashed a Matt Damon interview , about his upcoming movie THING'", "]", "\n", "qs", "=", "[", "]", "\n", "for", "qu", "in", "tqdm", "(", "questions", "[", ":", "10", "]", ",", "desc", "=", "'reform demo'", ")", ":", "\n", "        ", "tokens", "=", "qu", ".", "split", "(", "' '", ")", "\n", "wh", "=", "tokens", "[", "0", "]", "\n", "q_text", "=", "' '", ".", "join", "(", "tokens", "[", "1", ":", "]", ")", "\n", "print", "(", "q_text", ")", "\n", "q_text", "=", "reformulate_quesiton", "(", "q_text", ",", "parser", ",", "1", ")", "\n", "print", "(", "q_text", ")", "\n", "print", "(", "'----------------------'", ")", "\n", "qu_new", "=", "wh", "+", "' '", "+", "q_text", "\n", "qs", ".", "append", "(", "qu_new", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.data_check": [[121, 140], ["print", "open", "print", "print", "json.load", "context[].startswith"], "function", ["None"], ["", "", "def", "data_check", "(", "input_file", ")", ":", "\n", "    ", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "        ", "input_data", "=", "json", ".", "load", "(", "reader", ")", "[", "\"data\"", "]", "\n", "", "q_count", "=", "0", "\n", "err", "=", "0", "\n", "for", "entry", "in", "input_data", ":", "\n", "        ", "for", "paragraph", "in", "entry", "[", "'paragraphs'", "]", ":", "\n", "            ", "context", "=", "paragraph", "[", "'context'", "]", "\n", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "                ", "q_count", "+=", "1", "\n", "answer_text", "=", "qa", "[", "'answers'", "]", "[", "0", "]", "[", "'text'", "]", "\n", "answer_start", "=", "qa", "[", "'answers'", "]", "[", "0", "]", "[", "'answer_start'", "]", "\n", "if", "not", "context", "[", "answer_start", ":", "]", ".", "startswith", "(", "answer_text", ")", ":", "\n", "                    ", "err", "+=", "1", "\n", "", "", "", "", "if", "err", "==", "0", ":", "\n", "        ", "print", "(", "input_file", ",", "'is correct.'", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "input_file", ",", "'has %d problems.'", "%", "err", ")", "\n", "", "print", "(", "'Number of Question:'", ",", "q_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.data_sample_v2": [[141, 210], ["sorted", "sorted.append", "tqdm.tqdm", "print", "print", "json.dump", "open", "int", "random.shuffle", "int", "sample_data.append", "open", "json.load", "random.shuffle", "parags.append", "len", "len", "print", "int.split", "int", "len", "int", "input_file.split", "qa[].split", "sorted.append", "qa[].replace", "qas.append", "input_file.split", "wh_qids[].append", "qa[].split"], "function", ["None"], ["", "def", "data_sample_v2", "(", "input_file", ",", "sample_number", ",", "balance", "=", "False", ",", "output_file", "=", "None", ")", ":", "\n", "    ", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "        ", "input_data", "=", "json", ".", "load", "(", "reader", ")", "[", "\"data\"", "]", "\n", "", "sample_data", "=", "[", "]", "\n", "qids", "=", "[", "]", "\n", "q_count", "=", "0", "\n", "\n", "if", "balance", ":", "\n", "        ", "whs", "=", "[", "'How'", ",", "'Who'", ",", "'When'", ",", "'What'", ",", "'Where'", "]", "\n", "wh_qids", "=", "{", "}", "\n", "for", "wh", "in", "whs", ":", "\n", "            ", "wh_qids", "[", "wh", "]", "=", "[", "]", "\n", "", "for", "entry", "in", "input_data", ":", "\n", "            ", "for", "paragraph", "in", "entry", "[", "'paragraphs'", "]", ":", "\n", "                ", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "                    ", "q_tokens", "=", "qa", "[", "'question'", "]", ".", "split", "(", ")", "\n", "qid", "=", "qa", "[", "'id'", "]", "\n", "q_wh", "=", "None", "\n", "for", "wh", "in", "whs", ":", "\n", "                        ", "if", "wh", "in", "q_tokens", ":", "\n", "                            ", "q_wh", "=", "wh", "\n", "break", "\n", "", "", "if", "q_wh", "is", "not", "None", ":", "\n", "                        ", "wh_qids", "[", "q_wh", "]", ".", "append", "(", "qid", ")", "\n", "", "", "", "", "balance_number", "=", "int", "(", "sample_number", "/", "len", "(", "whs", ")", ")", "\n", "for", "wh", "in", "whs", ":", "\n", "            ", "if", "len", "(", "wh_qids", "[", "wh", "]", ")", "<", "balance_number", ":", "\n", "                ", "print", "(", "wh", ",", "'quesitons not enough.'", ")", "\n", "", "random", ".", "shuffle", "(", "wh_qids", "[", "wh", "]", ")", "\n", "#print(balance_number, len(balance_number))", "\n", "qids", "+=", "wh_qids", "[", "wh", "]", "[", ":", "balance_number", "]", "\n", "\n", "", "", "else", ":", "\n", "        ", "for", "entry", "in", "input_data", ":", "\n", "            ", "for", "paragraph", "in", "entry", "[", "'paragraphs'", "]", ":", "\n", "                ", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "                    ", "qids", ".", "append", "(", "qa", "[", "'id'", "]", ")", "\n", "", "", "", "random", ".", "shuffle", "(", "qids", ")", "\n", "qids", "=", "qids", "[", ":", "sample_number", "]", "\n", "\n", "", "qids", "=", "[", "int", "(", "qid", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ")", "for", "qid", "in", "qids", "]", "\n", "qids", "=", "sorted", "(", "qids", ")", "\n", "qids", ".", "append", "(", "-", "1", ")", "\n", "\n", "for", "entry", "in", "tqdm", "(", "input_data", ",", "desc", "=", "\"sample\"", ")", ":", "\n", "        ", "parags", "=", "[", "]", "\n", "for", "paragraph", "in", "entry", "[", "'paragraphs'", "]", ":", "\n", "            ", "qas", "=", "[", "]", "\n", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "                ", "qid", "=", "int", "(", "qa", "[", "'id'", "]", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ")", "\n", "if", "qid", "==", "qids", "[", "q_count", "]", ":", "\n", "                    ", "qa", "[", "'question'", "]", "=", "qa", "[", "'question'", "]", ".", "replace", "(", "'PERSON/NORP/ORG'", ",", "'PERSONNORPORG'", ")", "\n", "qas", ".", "append", "(", "qa", ")", "\n", "q_count", "+=", "1", "\n", "", "", "if", "len", "(", "qas", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "paragraph", "[", "\"qas\"", "]", "=", "qas", "\n", "parags", ".", "append", "(", "paragraph", ")", "\n", "", "entry", "[", "\"paragraphs\"", "]", "=", "parags", "\n", "sample_data", ".", "append", "(", "entry", ")", "\n", "\n", "", "print", "(", "'Questions Number'", ",", "q_count", ")", "\n", "if", "output_file", "is", "None", ":", "\n", "        ", "output_file", "=", "'/'", ".", "join", "(", "input_file", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "+", "'/'", "\n", "if", "balance", ":", "\n", "            ", "output_file", "+=", "'balanced_'", "\n", "", "output_file", "+=", "'sample_%dw-'", "%", "(", "int", "(", "sample_number", "/", "10000", ")", ")", "+", "input_file", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "", "print", "(", "'Saving to'", ",", "output_file", ")", "\n", "json", ".", "dump", "(", "{", "\"version\"", ":", "\"v2.0\"", ",", "'data'", ":", "sample_data", "}", ",", "open", "(", "output_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.filter_data_given_qids": [[211, 234], ["copy.deepcopy", "tqdm.tqdm", "sorted", "new_data.append", "paras.append", "len", "len", "int", "qas.append", "len", "x.strip().split", "x.strip"], "function", ["None"], ["", "def", "filter_data_given_qids", "(", "input_data_", ",", "qids", ",", "is_sorted", "=", "False", ")", ":", "\n", "    ", "input_data", "=", "copy", ".", "deepcopy", "(", "input_data_", ")", "\n", "if", "not", "is_sorted", ":", "\n", "        ", "qids", "=", "sorted", "(", "qids", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", ".", "strip", "(", ")", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ")", ")", "\n", "", "q_count", "=", "0", "\n", "new_data", "=", "[", "]", "\n", "for", "entry", "in", "tqdm", "(", "input_data", ",", "desc", "=", "'filter'", ")", ":", "\n", "        ", "paras", "=", "[", "]", "\n", "for", "paragraph", "in", "entry", "[", "'paragraphs'", "]", ":", "\n", "            ", "qas", "=", "[", "]", "\n", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "                ", "if", "q_count", "<", "len", "(", "qids", ")", "and", "qa", "[", "'id'", "]", "==", "qids", "[", "q_count", "]", ":", "\n", "                    ", "qas", ".", "append", "(", "qa", ")", "\n", "q_count", "+=", "1", "\n", "", "", "if", "len", "(", "qas", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "paragraph", "[", "'qas'", "]", "=", "qas", "\n", "paras", ".", "append", "(", "paragraph", ")", "\n", "", "if", "len", "(", "paras", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "", "entry", "[", "'paragraphs'", "]", "=", "paras", "\n", "new_data", ".", "append", "(", "entry", ")", "\n", "", "return", "new_data", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.data_split": [[235, 257], ["random.shuffle", "open", "len", "data_utils.filter_data_given_qids", "json.dump", "print", "data_utils.data_check", "json.load", "open", "len", "qids.append", "min", "input_file.split", "len", "input_file.split"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.cloze2natural.filter_data_given_qids", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.data_check"], ["", "def", "data_split", "(", "input_file", ",", "data_size", ")", ":", "\n", "    ", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "        ", "input_data", "=", "json", ".", "load", "(", "reader", ")", "[", "\"data\"", "]", "\n", "", "sample_data", "=", "[", "]", "\n", "qids", "=", "[", "]", "\n", "q_count", "=", "0", "\n", "for", "entry", "in", "input_data", ":", "\n", "        ", "for", "paragraph", "in", "entry", "[", "'paragraphs'", "]", ":", "\n", "            ", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "                ", "qids", ".", "append", "(", "qa", "[", "'id'", "]", ")", "\n", "", "", "", "random", ".", "shuffle", "(", "qids", ")", "\n", "\n", "num", "=", "0", "\n", "while", "num", "*", "data_size", "<", "len", "(", "qids", ")", ":", "\n", "        ", "nqids", "=", "qids", "[", "num", "*", "data_size", ":", "min", "(", "len", "(", "qids", ")", ",", "(", "num", "+", "1", ")", "*", "data_size", ")", "]", "\n", "new_data", "=", "filter_data_given_qids", "(", "input_data", ",", "nqids", ")", "\n", "output_file", "=", "'/'", ".", "join", "(", "input_file", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "+", "'/'", "\n", "output_file", "+=", "(", "'%d_'", "%", "num", ")", "+", "input_file", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "json", ".", "dump", "(", "{", "\"version\"", ":", "\"v2.0\"", ",", "'data'", ":", "new_data", "}", ",", "open", "(", "output_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "print", "(", "output_file", ",", "len", "(", "nqids", ")", ")", "\n", "data_check", "(", "output_file", ")", "\n", "num", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.data_concat": [[259, 266], ["json.dump", "open", "open", "json.load"], "function", ["None"], ["", "", "def", "data_concat", "(", "files", ",", "output_file", ")", ":", "\n", "    ", "all_data", "=", "[", "]", "\n", "for", "input_file", "in", "files", ":", "\n", "        ", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "            ", "input_data", "=", "json", ".", "load", "(", "reader", ")", "[", "\"data\"", "]", "\n", "all_data", "+=", "input_data", "\n", "", "", "json", ".", "dump", "(", "{", "\"version\"", ":", "\"v2.0\"", ",", "'data'", ":", "all_data", "}", ",", "open", "(", "output_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.split_all_data": [[267, 288], ["os.path.join", "zip", "open", "len", "len", "os.path.join", "data_utils.filter_data_given_qids", "json.dump", "data_utils.data_check", "json.load", "open", "qids.append"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.cloze2natural.filter_data_given_qids", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.data_check"], ["", "def", "split_all_data", "(", "data_dir", ",", "input_file", ",", "output_files", ",", "output_sizes", ")", ":", "\n", "    ", "input_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "input_file", ")", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "        ", "input_data", "=", "json", ".", "load", "(", "reader", ")", "[", "\"data\"", "]", "\n", "\n", "", "qids", "=", "[", "]", "\n", "for", "entry", "in", "input_data", ":", "\n", "        ", "for", "paragraph", "in", "entry", "[", "'paragraphs'", "]", ":", "\n", "            ", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "                ", "qids", ".", "append", "(", "qa", "[", "'id'", "]", ")", "\n", "\n", "", "", "", "q_pos", "=", "0", "\n", "assert", "len", "(", "output_files", ")", "==", "len", "(", "output_sizes", ")", "\n", "\n", "for", "output_file", ",", "data_size", "in", "zip", "(", "output_files", ",", "output_sizes", ")", ":", "\n", "        ", "output_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "output_file", ")", "\n", "nqids", "=", "qids", "[", "q_pos", ":", "q_pos", "+", "data_size", "]", "\n", "q_pos", "+=", "data_size", "\n", "new_data", "=", "filter_data_given_qids", "(", "input_data", ",", "nqids", ")", "\n", "json", ".", "dump", "(", "{", "\"version\"", ":", "\"v2.0\"", ",", "'data'", ":", "new_data", "}", ",", "open", "(", "output_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "data_check", "(", "output_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.recover_wikiref": [[289, 315], ["spacy.load", "tqdm.tqdm", "print", "json.dump", "open", "len", "open", "json.load", "spacy.load.", "context[].strip", "sent.text.strip", "qid.split", "len"], "function", ["None"], ["", "", "def", "recover_wikiref", "(", ")", ":", "\n", "    ", "input_file", "=", "\"../uqa_all_data.json\"", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "        ", "input_data", "=", "json", ".", "load", "(", "reader", ")", "[", "\"data\"", "]", "\n", "", "nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_sm\"", ",", "disable", "=", "[", "'ner'", ",", "'tagger'", "]", ")", "\n", "\n", "wikiref_data", "=", "{", "}", "\n", "\n", "for", "entry", "in", "tqdm", "(", "input_data", ",", "desc", "=", "\"Recover Wikiref\"", ")", ":", "\n", "        ", "title", "=", "entry", "[", "'title'", "]", "\n", "for", "paragraph", "in", "entry", "[", "'paragraphs'", "]", ":", "\n", "            ", "context", "=", "paragraph", "[", "'context'", "]", "\n", "doc", "=", "nlp", "(", "context", "[", "len", "(", "title", ")", ":", "]", ".", "strip", "(", ")", ")", "\n", "sents", "=", "[", "title", "]", "+", "[", "sent", ".", "text", ".", "strip", "(", ")", "for", "sent", "in", "doc", ".", "sents", "]", "\n", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "                ", "qid", "=", "qa", "[", "'id'", "]", "\n", "summary", "=", "qa", "[", "'summary'", "]", "\n", "uid", "=", "qid", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "wikiref_data", "[", "uid", "]", "=", "{", "\n", "\"uid\"", ":", "uid", ",", "\n", "\"document\"", ":", "sents", ",", "\n", "\"summary\"", ":", "summary", "\n", "}", "\n", "", "", "", "wikiref", "=", "[", "wikiref_data", "[", "key", "]", "for", "key", "in", "wikiref_data", "]", "\n", "print", "(", "len", "(", "wikiref", ")", ")", "\n", "json", ".", "dump", "(", "wikiref", ",", "open", "(", "\"../wikiref.json\"", ",", "\"w\"", ",", "encoding", "=", "'utf-8'", ")", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.EVAL_OPTS.__init__": [[19, 29], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "data_file", ",", "pred_file", ",", "out_file", "=", "\"\"", ",", "\n", "na_prob_file", "=", "\"na_prob.json\"", ",", "na_prob_thresh", "=", "1.0", ",", "\n", "out_image_dir", "=", "None", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "self", ".", "data_file", "=", "data_file", "\n", "self", ".", "pred_file", "=", "pred_file", "\n", "self", ".", "out_file", "=", "out_file", "\n", "self", ".", "na_prob_file", "=", "na_prob_file", "\n", "self", ".", "na_prob_thresh", "=", "na_prob_thresh", "\n", "self", ".", "out_image_dir", "=", "out_image_dir", "\n", "self", ".", "verbose", "=", "verbose", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.parse_args": [[32, 49], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "len", "argparse.ArgumentParser.print_help", "sys.exit"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "'Official evaluation script for SQuAD version 2.0.'", ")", "\n", "parser", ".", "add_argument", "(", "'data_file'", ",", "metavar", "=", "'data.json'", ",", "help", "=", "'Input data JSON file.'", ")", "\n", "parser", ".", "add_argument", "(", "'pred_file'", ",", "metavar", "=", "'pred.json'", ",", "help", "=", "'Model predictions.'", ")", "\n", "parser", ".", "add_argument", "(", "'--out-file'", ",", "'-o'", ",", "metavar", "=", "'eval.json'", ",", "\n", "help", "=", "'Write accuracy metrics to file (default is stdout).'", ")", "\n", "parser", ".", "add_argument", "(", "'--na-prob-file'", ",", "'-n'", ",", "metavar", "=", "'na_prob.json'", ",", "\n", "help", "=", "'Model estimates of probability of no answer.'", ")", "\n", "parser", ".", "add_argument", "(", "'--na-prob-thresh'", ",", "'-t'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "'Predict \"\" if no-answer probability exceeds this (default = 1.0).'", ")", "\n", "parser", ".", "add_argument", "(", "'--out-image-dir'", ",", "'-p'", ",", "metavar", "=", "'out_images'", ",", "default", "=", "None", ",", "\n", "help", "=", "'Save precision-recall curves to directory.'", ")", "\n", "parser", ".", "add_argument", "(", "'--verbose'", ",", "'-v'", ",", "action", "=", "'store_true'", ")", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "1", ":", "\n", "    ", "parser", ".", "print_help", "(", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.make_qid_to_has_ans": [[50, 57], ["bool"], "function", ["None"], ["", "def", "make_qid_to_has_ans", "(", "dataset", ")", ":", "\n", "  ", "qid_to_has_ans", "=", "{", "}", "\n", "for", "article", "in", "dataset", ":", "\n", "    ", "for", "p", "in", "article", "[", "'paragraphs'", "]", ":", "\n", "      ", "for", "qa", "in", "p", "[", "'qas'", "]", ":", "\n", "        ", "qid_to_has_ans", "[", "qa", "[", "'id'", "]", "]", "=", "bool", "(", "qa", "[", "'answers'", "]", ")", "\n", "", "", "", "return", "qid_to_has_ans", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.normalize_answer": [[58, 71], ["utils_squad_evaluate.normalize_answer.white_space_fix"], "function", ["None"], ["", "def", "normalize_answer", "(", "s", ")", ":", "\n", "  ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "    ", "regex", "=", "re", ".", "compile", "(", "r'\\b(a|an|the)\\b'", ",", "re", ".", "UNICODE", ")", "\n", "return", "re", ".", "sub", "(", "regex", ",", "' '", ",", "text", ")", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "    ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "    ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "    ", "return", "text", ".", "lower", "(", ")", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.get_tokens": [[72, 75], ["normalize_answer().split", "utils_squad_evaluate.normalize_answer"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.normalize_answer"], ["", "def", "get_tokens", "(", "s", ")", ":", "\n", "  ", "if", "not", "s", ":", "return", "[", "]", "\n", "return", "normalize_answer", "(", "s", ")", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.compute_exact": [[76, 78], ["int", "utils_squad_evaluate.normalize_answer", "utils_squad_evaluate.normalize_answer"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.normalize_answer", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.normalize_answer"], ["", "def", "compute_exact", "(", "a_gold", ",", "a_pred", ")", ":", "\n", "  ", "return", "int", "(", "normalize_answer", "(", "a_gold", ")", "==", "normalize_answer", "(", "a_pred", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.compute_f1": [[79, 93], ["utils_squad_evaluate.get_tokens", "utils_squad_evaluate.get_tokens", "sum", "collections.Counter", "collections.Counter", "common.values", "int", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.get_tokens", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.get_tokens"], ["", "def", "compute_f1", "(", "a_gold", ",", "a_pred", ")", ":", "\n", "  ", "gold_toks", "=", "get_tokens", "(", "a_gold", ")", "\n", "pred_toks", "=", "get_tokens", "(", "a_pred", ")", "\n", "common", "=", "collections", ".", "Counter", "(", "gold_toks", ")", "&", "collections", ".", "Counter", "(", "pred_toks", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "len", "(", "gold_toks", ")", "==", "0", "or", "len", "(", "pred_toks", ")", "==", "0", ":", "\n", "# If either is no-answer, then F1 is 1 if they agree, 0 otherwise", "\n", "    ", "return", "int", "(", "gold_toks", "==", "pred_toks", ")", "\n", "", "if", "num_same", "==", "0", ":", "\n", "    ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "pred_toks", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "gold_toks", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.get_raw_scores": [[94, 114], ["max", "max", "print", "utils_squad_evaluate.normalize_answer", "utils_squad_evaluate.compute_exact", "utils_squad_evaluate.compute_f1"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.normalize_answer", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.compute_exact", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.compute_f1"], ["", "def", "get_raw_scores", "(", "dataset", ",", "preds", ")", ":", "\n", "  ", "exact_scores", "=", "{", "}", "\n", "f1_scores", "=", "{", "}", "\n", "for", "article", "in", "dataset", ":", "\n", "    ", "for", "p", "in", "article", "[", "'paragraphs'", "]", ":", "\n", "      ", "for", "qa", "in", "p", "[", "'qas'", "]", ":", "\n", "        ", "qid", "=", "qa", "[", "'id'", "]", "\n", "gold_answers", "=", "[", "a", "[", "'text'", "]", "for", "a", "in", "qa", "[", "'answers'", "]", "\n", "if", "normalize_answer", "(", "a", "[", "'text'", "]", ")", "]", "\n", "if", "not", "gold_answers", ":", "\n", "# For unanswerable questions, only correct answer is empty string", "\n", "          ", "gold_answers", "=", "[", "''", "]", "\n", "", "if", "qid", "not", "in", "preds", ":", "\n", "          ", "print", "(", "'Missing prediction for %s'", "%", "qid", ")", "\n", "continue", "\n", "", "a_pred", "=", "preds", "[", "qid", "]", "\n", "# Take max over all gold answers", "\n", "exact_scores", "[", "qid", "]", "=", "max", "(", "compute_exact", "(", "a", ",", "a_pred", ")", "for", "a", "in", "gold_answers", ")", "\n", "f1_scores", "[", "qid", "]", "=", "max", "(", "compute_f1", "(", "a", ",", "a_pred", ")", "for", "a", "in", "gold_answers", ")", "\n", "", "", "", "return", "exact_scores", ",", "f1_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.apply_no_ans_threshold": [[115, 124], ["scores.items", "float"], "function", ["None"], ["", "def", "apply_no_ans_threshold", "(", "scores", ",", "na_probs", ",", "qid_to_has_ans", ",", "na_prob_thresh", ")", ":", "\n", "  ", "new_scores", "=", "{", "}", "\n", "for", "qid", ",", "s", "in", "scores", ".", "items", "(", ")", ":", "\n", "    ", "pred_na", "=", "na_probs", "[", "qid", "]", ">", "na_prob_thresh", "\n", "if", "pred_na", ":", "\n", "      ", "new_scores", "[", "qid", "]", "=", "float", "(", "not", "qid_to_has_ans", "[", "qid", "]", ")", "\n", "", "else", ":", "\n", "      ", "new_scores", "[", "qid", "]", "=", "s", "\n", "", "", "return", "new_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.make_eval_dict": [[125, 139], ["len", "collections.OrderedDict", "len", "collections.OrderedDict", "sum", "sum", "sum", "sum", "exact_scores.values", "f1_scores.values"], "function", ["None"], ["", "def", "make_eval_dict", "(", "exact_scores", ",", "f1_scores", ",", "qid_list", "=", "None", ")", ":", "\n", "  ", "if", "not", "qid_list", ":", "\n", "    ", "total", "=", "len", "(", "exact_scores", ")", "\n", "return", "collections", ".", "OrderedDict", "(", "[", "\n", "(", "'exact'", ",", "100.0", "*", "sum", "(", "exact_scores", ".", "values", "(", ")", ")", "/", "total", ")", ",", "\n", "(", "'f1'", ",", "100.0", "*", "sum", "(", "f1_scores", ".", "values", "(", ")", ")", "/", "total", ")", ",", "\n", "(", "'total'", ",", "total", ")", ",", "\n", "]", ")", "\n", "", "else", ":", "\n", "    ", "total", "=", "len", "(", "qid_list", ")", "\n", "return", "collections", ".", "OrderedDict", "(", "[", "\n", "(", "'exact'", ",", "100.0", "*", "sum", "(", "exact_scores", "[", "k", "]", "for", "k", "in", "qid_list", ")", "/", "total", ")", ",", "\n", "(", "'f1'", ",", "100.0", "*", "sum", "(", "f1_scores", "[", "k", "]", "for", "k", "in", "qid_list", ")", "/", "total", ")", ",", "\n", "(", "'total'", ",", "total", ")", ",", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.merge_eval": [[141, 144], ["None"], "function", ["None"], ["", "", "def", "merge_eval", "(", "main_eval", ",", "new_eval", ",", "prefix", ")", ":", "\n", "  ", "for", "k", "in", "new_eval", ":", "\n", "    ", "main_eval", "[", "'%s_%s'", "%", "(", "prefix", ",", "k", ")", "]", "=", "new_eval", "[", "k", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.plot_pr_curve": [[145, 155], ["plt.step", "plt.fill_between", "plt.xlabel", "plt.ylabel", "plt.xlim", "plt.ylim", "plt.title", "plt.savefig", "plt.clf"], "function", ["None"], ["", "", "def", "plot_pr_curve", "(", "precisions", ",", "recalls", ",", "out_image", ",", "title", ")", ":", "\n", "  ", "plt", ".", "step", "(", "recalls", ",", "precisions", ",", "color", "=", "'b'", ",", "alpha", "=", "0.2", ",", "where", "=", "'post'", ")", "\n", "plt", ".", "fill_between", "(", "recalls", ",", "precisions", ",", "step", "=", "'post'", ",", "alpha", "=", "0.2", ",", "color", "=", "'b'", ")", "\n", "plt", ".", "xlabel", "(", "'Recall'", ")", "\n", "plt", ".", "ylabel", "(", "'Precision'", ")", "\n", "plt", ".", "xlim", "(", "[", "0.0", ",", "1.05", "]", ")", "\n", "plt", ".", "ylim", "(", "[", "0.0", ",", "1.05", "]", ")", "\n", "plt", ".", "title", "(", "title", ")", "\n", "plt", ".", "savefig", "(", "out_image", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.make_precision_recall_eval": [[156, 178], ["sorted", "enumerate", "utils_squad_evaluate.plot_pr_curve", "float", "float", "precisions.append", "recalls.append", "len"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.plot_pr_curve"], ["", "def", "make_precision_recall_eval", "(", "scores", ",", "na_probs", ",", "num_true_pos", ",", "qid_to_has_ans", ",", "\n", "out_image", "=", "None", ",", "title", "=", "None", ")", ":", "\n", "  ", "qid_list", "=", "sorted", "(", "na_probs", ",", "key", "=", "lambda", "k", ":", "na_probs", "[", "k", "]", ")", "\n", "true_pos", "=", "0.0", "\n", "cur_p", "=", "1.0", "\n", "cur_r", "=", "0.0", "\n", "precisions", "=", "[", "1.0", "]", "\n", "recalls", "=", "[", "0.0", "]", "\n", "avg_prec", "=", "0.0", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n", "    ", "if", "qid_to_has_ans", "[", "qid", "]", ":", "\n", "      ", "true_pos", "+=", "scores", "[", "qid", "]", "\n", "", "cur_p", "=", "true_pos", "/", "float", "(", "i", "+", "1", ")", "\n", "cur_r", "=", "true_pos", "/", "float", "(", "num_true_pos", ")", "\n", "if", "i", "==", "len", "(", "qid_list", ")", "-", "1", "or", "na_probs", "[", "qid", "]", "!=", "na_probs", "[", "qid_list", "[", "i", "+", "1", "]", "]", ":", "\n", "# i.e., if we can put a threshold after this point", "\n", "      ", "avg_prec", "+=", "cur_p", "*", "(", "cur_r", "-", "recalls", "[", "-", "1", "]", ")", "\n", "precisions", ".", "append", "(", "cur_p", ")", "\n", "recalls", ".", "append", "(", "cur_r", ")", "\n", "", "", "if", "out_image", ":", "\n", "    ", "plot_pr_curve", "(", "precisions", ",", "recalls", ",", "out_image", ",", "title", ")", "\n", "", "return", "{", "'ap'", ":", "100.0", "*", "avg_prec", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.run_precision_recall_analysis": [[179, 202], ["sum", "utils_squad_evaluate.make_precision_recall_eval", "utils_squad_evaluate.make_precision_recall_eval", "utils_squad_evaluate.make_precision_recall_eval", "utils_squad_evaluate.merge_eval", "utils_squad_evaluate.merge_eval", "utils_squad_evaluate.merge_eval", "os.makedirs", "float", "os.path.exists", "os.path.join", "os.path.join", "qid_to_has_ans.items", "os.path.join", "qid_to_has_ans.values"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.make_precision_recall_eval", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.make_precision_recall_eval", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.make_precision_recall_eval", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.merge_eval", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.merge_eval", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.merge_eval"], ["", "def", "run_precision_recall_analysis", "(", "main_eval", ",", "exact_raw", ",", "f1_raw", ",", "na_probs", ",", "\n", "qid_to_has_ans", ",", "out_image_dir", ")", ":", "\n", "  ", "if", "out_image_dir", "and", "not", "os", ".", "path", ".", "exists", "(", "out_image_dir", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "out_image_dir", ")", "\n", "", "num_true_pos", "=", "sum", "(", "1", "for", "v", "in", "qid_to_has_ans", ".", "values", "(", ")", "if", "v", ")", "\n", "if", "num_true_pos", "==", "0", ":", "\n", "    ", "return", "\n", "", "pr_exact", "=", "make_precision_recall_eval", "(", "\n", "exact_raw", ",", "na_probs", ",", "num_true_pos", ",", "qid_to_has_ans", ",", "\n", "out_image", "=", "os", ".", "path", ".", "join", "(", "out_image_dir", ",", "'pr_exact.png'", ")", ",", "\n", "title", "=", "'Precision-Recall curve for Exact Match score'", ")", "\n", "pr_f1", "=", "make_precision_recall_eval", "(", "\n", "f1_raw", ",", "na_probs", ",", "num_true_pos", ",", "qid_to_has_ans", ",", "\n", "out_image", "=", "os", ".", "path", ".", "join", "(", "out_image_dir", ",", "'pr_f1.png'", ")", ",", "\n", "title", "=", "'Precision-Recall curve for F1 score'", ")", "\n", "oracle_scores", "=", "{", "k", ":", "float", "(", "v", ")", "for", "k", ",", "v", "in", "qid_to_has_ans", ".", "items", "(", ")", "}", "\n", "pr_oracle", "=", "make_precision_recall_eval", "(", "\n", "oracle_scores", ",", "na_probs", ",", "num_true_pos", ",", "qid_to_has_ans", ",", "\n", "out_image", "=", "os", ".", "path", ".", "join", "(", "out_image_dir", ",", "'pr_oracle.png'", ")", ",", "\n", "title", "=", "'Oracle Precision-Recall curve (binary task of HasAns vs. NoAns)'", ")", "\n", "merge_eval", "(", "main_eval", ",", "pr_exact", ",", "'pr_exact'", ")", "\n", "merge_eval", "(", "main_eval", ",", "pr_f1", ",", "'pr_f1'", ")", "\n", "merge_eval", "(", "main_eval", ",", "pr_oracle", ",", "'pr_oracle'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.histogram_na_prob": [[203, 214], ["plt.hist", "plt.xlabel", "plt.ylabel", "plt.title", "plt.savefig", "plt.clf", "numpy.ones_like", "float", "os.path.join", "len"], "function", ["None"], ["", "def", "histogram_na_prob", "(", "na_probs", ",", "qid_list", ",", "image_dir", ",", "name", ")", ":", "\n", "  ", "if", "not", "qid_list", ":", "\n", "    ", "return", "\n", "", "x", "=", "[", "na_probs", "[", "k", "]", "for", "k", "in", "qid_list", "]", "\n", "weights", "=", "np", ".", "ones_like", "(", "x", ")", "/", "float", "(", "len", "(", "x", ")", ")", "\n", "plt", ".", "hist", "(", "x", ",", "weights", "=", "weights", ",", "bins", "=", "20", ",", "range", "=", "(", "0.0", ",", "1.0", ")", ")", "\n", "plt", ".", "xlabel", "(", "'Model probability of no-answer'", ")", "\n", "plt", ".", "ylabel", "(", "'Proportion of dataset'", ")", "\n", "plt", ".", "title", "(", "'Histogram of no-answer probability: %s'", "%", "name", ")", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'na_prob_hist_%s.png'", "%", "name", ")", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.find_best_thresh": [[215, 235], ["sum", "sorted", "enumerate", "len"], "function", ["None"], ["", "def", "find_best_thresh", "(", "preds", ",", "scores", ",", "na_probs", ",", "qid_to_has_ans", ")", ":", "\n", "  ", "num_no_ans", "=", "sum", "(", "1", "for", "k", "in", "qid_to_has_ans", "if", "not", "qid_to_has_ans", "[", "k", "]", ")", "\n", "cur_score", "=", "num_no_ans", "\n", "best_score", "=", "cur_score", "\n", "best_thresh", "=", "0.0", "\n", "qid_list", "=", "sorted", "(", "na_probs", ",", "key", "=", "lambda", "k", ":", "na_probs", "[", "k", "]", ")", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n", "    ", "if", "qid", "not", "in", "scores", ":", "continue", "\n", "if", "qid_to_has_ans", "[", "qid", "]", ":", "\n", "      ", "diff", "=", "scores", "[", "qid", "]", "\n", "", "else", ":", "\n", "      ", "if", "preds", "[", "qid", "]", ":", "\n", "        ", "diff", "=", "-", "1", "\n", "", "else", ":", "\n", "        ", "diff", "=", "0", "\n", "", "", "cur_score", "+=", "diff", "\n", "if", "cur_score", ">", "best_score", ":", "\n", "      ", "best_score", "=", "cur_score", "\n", "best_thresh", "=", "na_probs", "[", "qid", "]", "\n", "", "", "return", "100.0", "*", "best_score", "/", "len", "(", "scores", ")", ",", "best_thresh", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.find_best_thresh_v2": [[236, 265], ["sum", "sorted", "enumerate", "len"], "function", ["None"], ["", "def", "find_best_thresh_v2", "(", "preds", ",", "scores", ",", "na_probs", ",", "qid_to_has_ans", ")", ":", "\n", "  ", "num_no_ans", "=", "sum", "(", "1", "for", "k", "in", "qid_to_has_ans", "if", "not", "qid_to_has_ans", "[", "k", "]", ")", "\n", "cur_score", "=", "num_no_ans", "\n", "best_score", "=", "cur_score", "\n", "best_thresh", "=", "0.0", "\n", "qid_list", "=", "sorted", "(", "na_probs", ",", "key", "=", "lambda", "k", ":", "na_probs", "[", "k", "]", ")", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n", "    ", "if", "qid", "not", "in", "scores", ":", "continue", "\n", "if", "qid_to_has_ans", "[", "qid", "]", ":", "\n", "      ", "diff", "=", "scores", "[", "qid", "]", "\n", "", "else", ":", "\n", "      ", "if", "preds", "[", "qid", "]", ":", "\n", "        ", "diff", "=", "-", "1", "\n", "", "else", ":", "\n", "        ", "diff", "=", "0", "\n", "", "", "cur_score", "+=", "diff", "\n", "if", "cur_score", ">", "best_score", ":", "\n", "      ", "best_score", "=", "cur_score", "\n", "best_thresh", "=", "na_probs", "[", "qid", "]", "\n", "\n", "", "", "has_ans_score", ",", "has_ans_cnt", "=", "0", ",", "0", "\n", "for", "qid", "in", "qid_list", ":", "\n", "    ", "if", "not", "qid_to_has_ans", "[", "qid", "]", ":", "continue", "\n", "has_ans_cnt", "+=", "1", "\n", "\n", "if", "qid", "not", "in", "scores", ":", "continue", "\n", "has_ans_score", "+=", "scores", "[", "qid", "]", "\n", "\n", "", "return", "100.0", "*", "best_score", "/", "len", "(", "scores", ")", ",", "best_thresh", ",", "1.0", "*", "has_ans_score", "/", "has_ans_cnt", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.find_all_best_thresh": [[266, 273], ["utils_squad_evaluate.find_best_thresh", "utils_squad_evaluate.find_best_thresh"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.find_best_thresh", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.find_best_thresh"], ["", "def", "find_all_best_thresh", "(", "main_eval", ",", "preds", ",", "exact_raw", ",", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", ":", "\n", "  ", "best_exact", ",", "exact_thresh", "=", "find_best_thresh", "(", "preds", ",", "exact_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", "\n", "best_f1", ",", "f1_thresh", "=", "find_best_thresh", "(", "preds", ",", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", "\n", "main_eval", "[", "'best_exact'", "]", "=", "best_exact", "\n", "main_eval", "[", "'best_exact_thresh'", "]", "=", "exact_thresh", "\n", "main_eval", "[", "'best_f1'", "]", "=", "best_f1", "\n", "main_eval", "[", "'best_f1_thresh'", "]", "=", "f1_thresh", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.find_all_best_thresh_v2": [[274, 283], ["utils_squad_evaluate.find_best_thresh_v2", "utils_squad_evaluate.find_best_thresh_v2"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.find_best_thresh_v2", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.find_best_thresh_v2"], ["", "def", "find_all_best_thresh_v2", "(", "main_eval", ",", "preds", ",", "exact_raw", ",", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", ":", "\n", "  ", "best_exact", ",", "exact_thresh", ",", "has_ans_exact", "=", "find_best_thresh_v2", "(", "preds", ",", "exact_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", "\n", "best_f1", ",", "f1_thresh", ",", "has_ans_f1", "=", "find_best_thresh_v2", "(", "preds", ",", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", "\n", "main_eval", "[", "'best_exact'", "]", "=", "best_exact", "\n", "main_eval", "[", "'best_exact_thresh'", "]", "=", "exact_thresh", "\n", "main_eval", "[", "'best_f1'", "]", "=", "best_f1", "\n", "main_eval", "[", "'best_f1_thresh'", "]", "=", "f1_thresh", "\n", "main_eval", "[", "'has_ans_exact'", "]", "=", "has_ans_exact", "\n", "main_eval", "[", "'has_ans_f1'", "]", "=", "has_ans_f1", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.main": [[284, 323], ["utils_squad_evaluate.make_qid_to_has_ans", "utils_squad_evaluate.get_raw_scores", "utils_squad_evaluate.apply_no_ans_threshold", "utils_squad_evaluate.apply_no_ans_threshold", "utils_squad_evaluate.make_eval_dict", "open", "json.load", "open", "json.load", "utils_squad_evaluate.make_eval_dict", "utils_squad_evaluate.merge_eval", "utils_squad_evaluate.make_eval_dict", "utils_squad_evaluate.merge_eval", "utils_squad_evaluate.find_all_best_thresh", "utils_squad_evaluate.run_precision_recall_analysis", "utils_squad_evaluate.histogram_na_prob", "utils_squad_evaluate.histogram_na_prob", "print", "open", "json.load", "make_qid_to_has_ans.items", "make_qid_to_has_ans.items", "open", "json.dump", "json.dumps"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.make_qid_to_has_ans", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.get_raw_scores", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.apply_no_ans_threshold", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.apply_no_ans_threshold", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.make_eval_dict", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.make_eval_dict", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.merge_eval", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.make_eval_dict", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.merge_eval", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.find_all_best_thresh", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.run_precision_recall_analysis", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.histogram_na_prob", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.histogram_na_prob"], ["", "def", "main", "(", "OPTS", ")", ":", "\n", "  ", "with", "open", "(", "OPTS", ".", "data_file", ")", "as", "f", ":", "\n", "    ", "dataset_json", "=", "json", ".", "load", "(", "f", ")", "\n", "dataset", "=", "dataset_json", "[", "'data'", "]", "\n", "", "with", "open", "(", "OPTS", ".", "pred_file", ")", "as", "f", ":", "\n", "    ", "preds", "=", "json", ".", "load", "(", "f", ")", "\n", "", "if", "OPTS", ".", "na_prob_file", ":", "\n", "    ", "with", "open", "(", "OPTS", ".", "na_prob_file", ")", "as", "f", ":", "\n", "      ", "na_probs", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "    ", "na_probs", "=", "{", "k", ":", "0.0", "for", "k", "in", "preds", "}", "\n", "", "qid_to_has_ans", "=", "make_qid_to_has_ans", "(", "dataset", ")", "# maps qid to True/False", "\n", "has_ans_qids", "=", "[", "k", "for", "k", ",", "v", "in", "qid_to_has_ans", ".", "items", "(", ")", "if", "v", "]", "\n", "no_ans_qids", "=", "[", "k", "for", "k", ",", "v", "in", "qid_to_has_ans", ".", "items", "(", ")", "if", "not", "v", "]", "\n", "exact_raw", ",", "f1_raw", "=", "get_raw_scores", "(", "dataset", ",", "preds", ")", "\n", "exact_thresh", "=", "apply_no_ans_threshold", "(", "exact_raw", ",", "na_probs", ",", "qid_to_has_ans", ",", "\n", "OPTS", ".", "na_prob_thresh", ")", "\n", "f1_thresh", "=", "apply_no_ans_threshold", "(", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ",", "\n", "OPTS", ".", "na_prob_thresh", ")", "\n", "out_eval", "=", "make_eval_dict", "(", "exact_thresh", ",", "f1_thresh", ")", "\n", "if", "has_ans_qids", ":", "\n", "    ", "has_ans_eval", "=", "make_eval_dict", "(", "exact_thresh", ",", "f1_thresh", ",", "qid_list", "=", "has_ans_qids", ")", "\n", "merge_eval", "(", "out_eval", ",", "has_ans_eval", ",", "'HasAns'", ")", "\n", "", "if", "no_ans_qids", ":", "\n", "    ", "no_ans_eval", "=", "make_eval_dict", "(", "exact_thresh", ",", "f1_thresh", ",", "qid_list", "=", "no_ans_qids", ")", "\n", "merge_eval", "(", "out_eval", ",", "no_ans_eval", ",", "'NoAns'", ")", "\n", "", "if", "OPTS", ".", "na_prob_file", ":", "\n", "    ", "find_all_best_thresh", "(", "out_eval", ",", "preds", ",", "exact_raw", ",", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", "\n", "", "if", "OPTS", ".", "na_prob_file", "and", "OPTS", ".", "out_image_dir", ":", "\n", "    ", "run_precision_recall_analysis", "(", "out_eval", ",", "exact_raw", ",", "f1_raw", ",", "na_probs", ",", "\n", "qid_to_has_ans", ",", "OPTS", ".", "out_image_dir", ")", "\n", "histogram_na_prob", "(", "na_probs", ",", "has_ans_qids", ",", "OPTS", ".", "out_image_dir", ",", "'hasAns'", ")", "\n", "histogram_na_prob", "(", "na_probs", ",", "no_ans_qids", ",", "OPTS", ".", "out_image_dir", ",", "'noAns'", ")", "\n", "", "if", "OPTS", ".", "out_file", ":", "\n", "    ", "with", "open", "(", "OPTS", ".", "out_file", ",", "'w'", ")", "as", "f", ":", "\n", "      ", "json", ".", "dump", "(", "out_eval", ",", "f", ")", "\n", "", "", "else", ":", "\n", "    ", "print", "(", "json", ".", "dumps", "(", "out_eval", ",", "indent", "=", "2", ")", ")", "\n", "", "return", "out_eval", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.cloze2natural.identity_translate": [[32, 40], ["cloze_question.replace", "Exception", "cloze_question.replace", "int", "random.random"], "function", ["None"], ["def", "identity_translate", "(", "cloze_question", ")", ":", "\n", "    ", "if", "'NUMERIC'", "in", "cloze_question", ":", "\n", "        ", "return", "cloze_question", ".", "replace", "(", "'NUMERIC'", ",", "mask2wh", "[", "'NUMERIC'", "]", "[", "int", "(", "2", "*", "random", ".", "random", "(", ")", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "for", "mask", "in", "mask2wh", ":", "\n", "            ", "if", "mask", "in", "cloze_question", ":", "\n", "                ", "return", "cloze_question", ".", "replace", "(", "mask", ",", "mask2wh", "[", "mask", "]", ")", "\n", "", "", "raise", "Exception", "(", "'\\'{}\\' should have one specific masked tag.'", ".", "format", "(", "cloze_question", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.cloze2natural.word_shuffle": [[41, 51], ["len", "numpy.random.uniform", "numpy.array", "scores.argsort", "numpy.arange", "range"], "function", ["None"], ["", "", "def", "word_shuffle", "(", "tokens", ",", "word_shuffle_param", ")", ":", "\n", "    ", "length", "=", "len", "(", "tokens", ")", "\n", "noise", "=", "np", ".", "random", ".", "uniform", "(", "0", ",", "word_shuffle_param", ",", "size", "=", "(", "length", ")", ")", "\n", "word_idx", "=", "np", ".", "array", "(", "[", "1.0", "*", "i", "for", "i", "in", "range", "(", "length", ")", "]", ")", "\n", "\n", "scores", "=", "word_idx", "+", "noise", "\n", "scores", "+=", "1e-6", "*", "np", ".", "arange", "(", "length", ")", "\n", "permutation", "=", "scores", ".", "argsort", "(", ")", "\n", "new_s", "=", "[", "tokens", "[", "idx", "]", "for", "idx", "in", "permutation", "]", "\n", "return", "new_s", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.cloze2natural.word_dropout": [[52, 63], ["len", "numpy.random.rand", "enumerate"], "function", ["None"], ["", "def", "word_dropout", "(", "tokens", ",", "word_dropout_param", ")", ":", "\n", "    ", "length", "=", "len", "(", "tokens", ")", "\n", "if", "word_dropout_param", "==", "0", ":", "\n", "        ", "return", "tokens", "\n", "", "assert", "0", "<", "word_dropout_param", "<", "1", "\n", "\n", "keep", "=", "np", ".", "random", ".", "rand", "(", "length", ")", ">=", "word_dropout_param", "\n", "#if length:", "\n", "#    keep[0] = 1", "\n", "new_s", "=", "[", "w", "for", "j", ",", "w", "in", "enumerate", "(", "tokens", ")", "if", "keep", "[", "j", "]", "]", "\n", "return", "new_s", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.cloze2natural.word_mask": [[64, 75], ["len", "numpy.random.rand", "enumerate"], "function", ["None"], ["", "def", "word_mask", "(", "tokens", ",", "word_mask_param", ",", "mask_str", "=", "'[MASK]'", ")", ":", "\n", "    ", "length", "=", "len", "(", "tokens", ")", "\n", "if", "word_mask_param", "==", "0", ":", "\n", "        ", "return", "tokens", "\n", "", "assert", "0", "<", "word_mask_param", "<", "1", "\n", "\n", "keep", "=", "np", ".", "random", ".", "rand", "(", "length", ")", ">=", "word_mask_param", "\n", "#if length:", "\n", "#    keep[0] = 1", "\n", "new_s", "=", "[", "w", "if", "keep", "[", "j", "]", "else", "mask_str", "for", "j", ",", "w", "in", "enumerate", "(", "tokens", ")", "]", "\n", "return", "new_s", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.cloze2natural.noisy_clozes_translate": [[76, 91], ["isinstance", "nltk.word_tokenize", "cloze2natural.word_shuffle", "cloze2natural.word_dropout", "cloze2natural.word_mask", "cloze_question.replace.replace", "int", "random.random"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.cloze2natural.word_shuffle", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.cloze2natural.word_dropout", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.cloze2natural.word_mask"], ["", "def", "noisy_clozes_translate", "(", "cloze_question", ",", "params", "=", "[", "2", ",", "0.2", ",", "0.1", "]", ")", ":", "\n", "    ", "wh", "=", "None", "\n", "for", "mask", "in", "mask2wh", ":", "\n", "        ", "if", "mask", "in", "cloze_question", ":", "\n", "            ", "cloze_question", "=", "cloze_question", ".", "replace", "(", "mask", ",", "''", ")", "\n", "wh", "=", "mask2wh", "[", "mask", "]", "\n", "break", "\n", "", "", "if", "isinstance", "(", "wh", ",", "list", ")", ":", "\n", "        ", "wh", "=", "wh", "[", "int", "(", "2", "*", "random", ".", "random", "(", ")", ")", "]", "\n", "\n", "", "tokens", "=", "word_tokenize", "(", "cloze_question", ")", "\n", "tokens", "=", "word_shuffle", "(", "tokens", ",", "params", "[", "0", "]", ")", "\n", "tokens", "=", "word_dropout", "(", "tokens", ",", "params", "[", "1", "]", ")", "\n", "tokens", "=", "word_mask", "(", "tokens", ",", "params", "[", "2", "]", ")", "\n", "return", "wh", "+", "' '", "+", "(", "' '", ".", "join", "(", "tokens", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.cloze2natural.cloze_to_natural_questions": [[92, 130], ["spacy.load", "tqdm.tqdm", "print", "natural_data.append", "parags.append", "len", "qa[].replace", "qas.append", "cloze2natural.identity_translate", "print", "print", "cloze2natural.noisy_clozes_translate", "repr", "cloze2natural.identity_translate", "NotImplementedError", "data_utils.reformulate_quesiton"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.cloze2natural.identity_translate", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.cloze2natural.noisy_clozes_translate", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.cloze2natural.identity_translate", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.reformulate_quesiton"], ["", "def", "cloze_to_natural_questions", "(", "input_data", ",", "method", ")", ":", "\n", "\n", "    ", "natural_data", "=", "[", "]", "\n", "q_count", "=", "0", "\n", "\n", "parser", "=", "spacy", ".", "load", "(", "\"en\"", ",", "disable", "=", "[", "'ner'", ",", "'tagger'", "]", ")", "\n", "\n", "for", "entry", "in", "tqdm", "(", "input_data", ",", "desc", "=", "\"cloze\"", ")", ":", "\n", "        ", "parags", "=", "[", "]", "\n", "for", "paragraph", "in", "entry", "[", "'paragraphs'", "]", ":", "\n", "            ", "qas", "=", "[", "]", "\n", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "                ", "qa", "[", "'question'", "]", "=", "qa", "[", "'question'", "]", ".", "replace", "(", "'PERSON/NORP/ORG'", ",", "'PERSONNORPORG'", ")", "\n", "try", ":", "\n", "                    ", "if", "method", "==", "0", ":", "\n", "                        ", "qa", "[", "'question'", "]", "=", "identity_translate", "(", "qa", "[", "'question'", "]", ")", "\n", "", "elif", "method", "==", "1", ":", "\n", "                        ", "qa", "[", "'question'", "]", "=", "noisy_clozes_translate", "(", "qa", "[", "'question'", "]", ")", "\n", "", "elif", "method", "==", "2", ":", "\n", "                        ", "qa", "[", "'question'", "]", "=", "identity_translate", "(", "reformulate_quesiton", "(", "qa", "[", "'question'", "]", ",", "parser", ",", "reform_version", "=", "1", ")", ")", "\n", "", "else", ":", "\n", "                        ", "raise", "NotImplementedError", "(", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "print", "(", "qa", "[", "'question'", "]", ")", "\n", "print", "(", "repr", "(", "e", ")", ")", "\n", "continue", "\n", "\n", "", "qas", ".", "append", "(", "qa", ")", "\n", "", "paragraph", "[", "\"qas\"", "]", "=", "qas", "\n", "parags", ".", "append", "(", "paragraph", ")", "\n", "q_count", "+=", "len", "(", "qas", ")", "\n", "", "entry", "[", "\"paragraphs\"", "]", "=", "parags", "\n", "natural_data", ".", "append", "(", "entry", ")", "\n", "#if q_count > 10:", "\n", "#    break", "\n", "\n", "", "print", "(", "'Questions Number'", ",", "q_count", ")", "\n", "return", "{", "\"version\"", ":", "\"v2.0\"", ",", "'data'", ":", "natural_data", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.cloze2natural.filter_data_given_qids": [[132, 154], ["copy.deepcopy", "sorted", "tqdm.tqdm", "new_data.append", "paras.append", "len", "int", "len", "qas.append", "x.strip().split", "len", "x.strip"], "function", ["None"], ["", "def", "filter_data_given_qids", "(", "input_data_", ",", "qids", ")", ":", "\n", "    ", "input_data", "=", "copy", ".", "deepcopy", "(", "input_data_", ")", "\n", "qids", "=", "sorted", "(", "qids", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", ".", "strip", "(", ")", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ")", ")", "\n", "q_count", "=", "0", "\n", "new_data", "=", "[", "]", "\n", "for", "entry", "in", "tqdm", "(", "input_data", ",", "desc", "=", "'filter'", ")", ":", "\n", "        ", "paras", "=", "[", "]", "\n", "for", "paragraph", "in", "entry", "[", "'paragraphs'", "]", ":", "\n", "            ", "qas", "=", "[", "]", "\n", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "                ", "if", "q_count", "<", "len", "(", "qids", ")", "and", "qa", "[", "'id'", "]", "==", "qids", "[", "q_count", "]", ":", "\n", "                    ", "qas", ".", "append", "(", "qa", ")", "\n", "q_count", "+=", "1", "\n", "", "", "if", "len", "(", "qas", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "paragraph", "[", "'qas'", "]", "=", "qas", "\n", "paras", ".", "append", "(", "paragraph", ")", "\n", "", "if", "len", "(", "paras", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "", "entry", "[", "'paragraphs'", "]", "=", "paras", "\n", "new_data", ".", "append", "(", "entry", ")", "\n", "", "return", "new_data", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.cloze2natural.main": [[155, 161], ["os.path.join", "cloze2natural.cloze_to_natural_questions", "json.dump", "open", "open", "json.load", "os.path.join"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.cloze2natural.cloze_to_natural_questions"], ["", "def", "main", "(", "input_file", ",", "output_file", ",", "method", ")", ":", "\n", "    ", "input_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "input_file", ")", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "        ", "input_data", "=", "json", ".", "load", "(", "reader", ")", "[", "\"data\"", "]", "\n", "", "natural_data", "=", "cloze_to_natural_questions", "(", "input_data", ",", "method", ")", "\n", "json", ".", "dump", "(", "natural_data", ",", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "output_file", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad.SquadExample.__init__": [[41, 56], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "qas_id", ",", "\n", "question_text", ",", "\n", "doc_tokens", ",", "\n", "orig_answer_text", "=", "None", ",", "\n", "start_position", "=", "None", ",", "\n", "end_position", "=", "None", ",", "\n", "is_impossible", "=", "None", ")", ":", "\n", "        ", "self", ".", "qas_id", "=", "qas_id", "\n", "self", ".", "question_text", "=", "question_text", "\n", "self", ".", "doc_tokens", "=", "doc_tokens", "\n", "self", ".", "orig_answer_text", "=", "orig_answer_text", "\n", "self", ".", "start_position", "=", "start_position", "\n", "self", ".", "end_position", "=", "end_position", "\n", "self", ".", "is_impossible", "=", "is_impossible", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad.SquadExample.__str__": [[57, 59], ["utils_squad.SquadExample.__repr__"], "methods", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad.SquadExample.__repr__"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__repr__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad.SquadExample.__repr__": [[60, 73], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "s", "=", "\"\"", "\n", "s", "+=", "\"qas_id: %s\"", "%", "(", "self", ".", "qas_id", ")", "\n", "s", "+=", "\", question_text: %s\"", "%", "(", "\n", "self", ".", "question_text", ")", "\n", "s", "+=", "\", doc_tokens: [%s]\"", "%", "(", "\" \"", ".", "join", "(", "self", ".", "doc_tokens", ")", ")", "\n", "if", "self", ".", "start_position", ":", "\n", "            ", "s", "+=", "\", start_position: %d\"", "%", "(", "self", ".", "start_position", ")", "\n", "", "if", "self", ".", "end_position", ":", "\n", "            ", "s", "+=", "\", end_position: %d\"", "%", "(", "self", ".", "end_position", ")", "\n", "", "if", "self", ".", "is_impossible", ":", "\n", "            ", "s", "+=", "\", is_impossible: %r\"", "%", "(", "self", ".", "is_impossible", ")", "\n", "", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad.InputFeatures.__init__": [[78, 109], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "unique_id", ",", "\n", "example_index", ",", "\n", "doc_span_index", ",", "\n", "tokens", ",", "\n", "token_to_orig_map", ",", "\n", "token_is_max_context", ",", "\n", "input_ids", ",", "\n", "input_mask", ",", "\n", "segment_ids", ",", "\n", "cls_index", ",", "\n", "p_mask", ",", "\n", "paragraph_len", ",", "\n", "start_position", "=", "None", ",", "\n", "end_position", "=", "None", ",", "\n", "is_impossible", "=", "None", ")", ":", "\n", "        ", "self", ".", "unique_id", "=", "unique_id", "\n", "self", ".", "example_index", "=", "example_index", "\n", "self", ".", "doc_span_index", "=", "doc_span_index", "\n", "self", ".", "tokens", "=", "tokens", "\n", "self", ".", "token_to_orig_map", "=", "token_to_orig_map", "\n", "self", ".", "token_is_max_context", "=", "token_is_max_context", "\n", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "cls_index", "=", "cls_index", "\n", "self", ".", "p_mask", "=", "p_mask", "\n", "self", ".", "paragraph_len", "=", "paragraph_len", "\n", "self", ".", "start_position", "=", "start_position", "\n", "self", ".", "end_position", "=", "end_position", "\n", "self", ".", "is_impossible", "=", "is_impossible", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad.read_squad_examples": [[111, 187], ["io.open", "json.load", "ord", "utils_squad.read_squad_examples.is_whitespace"], "function", ["None"], ["", "", "def", "read_squad_examples", "(", "input_file", ",", "is_training", ",", "version_2_with_negative", ")", ":", "\n", "    ", "\"\"\"Read a SQuAD json file into a list of SquadExample.\"\"\"", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "        ", "input_data", "=", "json", ".", "load", "(", "reader", ")", "[", "\"data\"", "]", "\n", "\n", "", "def", "is_whitespace", "(", "c", ")", ":", "\n", "        ", "if", "c", "==", "\" \"", "or", "c", "==", "\"\\t\"", "or", "c", "==", "\"\\r\"", "or", "c", "==", "\"\\n\"", "or", "ord", "(", "c", ")", "==", "0x202F", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n", "", "examples", "=", "[", "]", "\n", "for", "entry", "in", "input_data", ":", "\n", "        ", "for", "paragraph", "in", "entry", "[", "\"paragraphs\"", "]", ":", "\n", "            ", "paragraph_text", "=", "paragraph", "[", "\"context\"", "]", "\n", "doc_tokens", "=", "[", "]", "\n", "char_to_word_offset", "=", "[", "]", "\n", "prev_is_whitespace", "=", "True", "\n", "for", "c", "in", "paragraph_text", ":", "\n", "                ", "if", "is_whitespace", "(", "c", ")", ":", "\n", "                    ", "prev_is_whitespace", "=", "True", "\n", "", "else", ":", "\n", "                    ", "if", "prev_is_whitespace", ":", "\n", "                        ", "doc_tokens", ".", "append", "(", "c", ")", "\n", "", "else", ":", "\n", "                        ", "doc_tokens", "[", "-", "1", "]", "+=", "c", "\n", "", "prev_is_whitespace", "=", "False", "\n", "", "char_to_word_offset", ".", "append", "(", "len", "(", "doc_tokens", ")", "-", "1", ")", "\n", "\n", "", "for", "qa", "in", "paragraph", "[", "\"qas\"", "]", ":", "\n", "                ", "qas_id", "=", "qa", "[", "\"id\"", "]", "\n", "question_text", "=", "qa", "[", "\"question\"", "]", "\n", "start_position", "=", "None", "\n", "end_position", "=", "None", "\n", "orig_answer_text", "=", "None", "\n", "is_impossible", "=", "False", "\n", "if", "is_training", ":", "\n", "                    ", "if", "version_2_with_negative", ":", "\n", "                        ", "is_impossible", "=", "qa", "[", "\"is_impossible\"", "]", "\n", "", "if", "(", "len", "(", "qa", "[", "\"answers\"", "]", ")", "!=", "1", ")", "and", "(", "not", "is_impossible", ")", ":", "\n", "                        ", "raise", "ValueError", "(", "\n", "\"For training, each question should have exactly 1 answer.\"", ")", "\n", "", "if", "not", "is_impossible", ":", "\n", "                        ", "answer", "=", "qa", "[", "\"answers\"", "]", "[", "0", "]", "\n", "orig_answer_text", "=", "answer", "[", "\"text\"", "]", "\n", "answer_offset", "=", "answer", "[", "\"answer_start\"", "]", "\n", "answer_length", "=", "len", "(", "orig_answer_text", ")", "\n", "start_position", "=", "char_to_word_offset", "[", "answer_offset", "]", "\n", "end_position", "=", "char_to_word_offset", "[", "answer_offset", "+", "answer_length", "-", "1", "]", "\n", "# Only add answers where the text can be exactly recovered from the", "\n", "# document. If this CAN'T happen it's likely due to weird Unicode", "\n", "# stuff so we will just skip the example.", "\n", "#", "\n", "# Note that this means for training mode, every example is NOT", "\n", "# guaranteed to be preserved.", "\n", "actual_text", "=", "\" \"", ".", "join", "(", "doc_tokens", "[", "start_position", ":", "(", "end_position", "+", "1", ")", "]", ")", "\n", "cleaned_answer_text", "=", "\" \"", ".", "join", "(", "\n", "whitespace_tokenize", "(", "orig_answer_text", ")", ")", "\n", "if", "actual_text", ".", "find", "(", "cleaned_answer_text", ")", "==", "-", "1", ":", "\n", "                            ", "logger", ".", "warning", "(", "\"Could not find answer: '%s' vs. '%s'\"", ",", "\n", "actual_text", ",", "cleaned_answer_text", ")", "\n", "continue", "\n", "", "", "else", ":", "\n", "                        ", "start_position", "=", "-", "1", "\n", "end_position", "=", "-", "1", "\n", "orig_answer_text", "=", "\"\"", "\n", "\n", "", "", "example", "=", "SquadExample", "(", "\n", "qas_id", "=", "qas_id", ",", "\n", "question_text", "=", "question_text", ",", "\n", "doc_tokens", "=", "doc_tokens", ",", "\n", "orig_answer_text", "=", "orig_answer_text", ",", "\n", "start_position", "=", "start_position", ",", "\n", "end_position", "=", "end_position", ",", "\n", "is_impossible", "=", "is_impossible", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad.convert_examples_to_features": [[189, 400], ["enumerate", "tokenizer.tokenize", "enumerate", "collections.namedtuple", "enumerate", "len", "orig_to_tok_index.append", "tokenizer.tokenize", "utils_squad._improve_answer_span", "len", "doc_spans.append", "min", "tokens.append", "segment_ids.append", "p_mask.append", "range", "tokens.append", "segment_ids.append", "p_mask.append", "tokenizer.convert_tokens_to_ids", "features.append", "len", "tok_to_orig_index.append", "all_doc_tokens.append", "len", "len", "collections.namedtuple.", "len", "tokens.append", "segment_ids.append", "p_mask.append", "tokens.append", "segment_ids.append", "p_mask.append", "utils_squad._check_is_max_context", "tokens.append", "segment_ids.append", "p_mask.append", "tokens.append", "segment_ids.append", "p_mask.append", "len", "len", "tokenizer.convert_tokens_to_ids.append", "input_mask.append", "segment_ids.append", "p_mask.append", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "utils_squad.InputFeatures", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "len", "len", "len", "str", "str", "str", "token_to_orig_map.items", "token_is_max_context.items"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.tokenize", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.tokenize", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad._improve_answer_span", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad._check_is_max_context"], ["", "def", "convert_examples_to_features", "(", "examples", ",", "tokenizer", ",", "max_seq_length", ",", "\n", "doc_stride", ",", "max_query_length", ",", "is_training", ",", "\n", "cls_token_at_end", "=", "False", ",", "\n", "cls_token", "=", "'[CLS]'", ",", "sep_token", "=", "'[SEP]'", ",", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "0", ",", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "    ", "\"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"", "\n", "\n", "unique_id", "=", "1000000000", "\n", "# cnt_pos, cnt_neg = 0, 0", "\n", "# max_N, max_M = 1024, 1024", "\n", "# f = np.zeros((max_N, max_M), dtype=np.float32)", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "example_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "\n", "# if example_index % 100 == 0:", "\n", "#     logger.info('Converting %s/%s pos %s neg %s', example_index, len(examples), cnt_pos, cnt_neg)", "\n", "\n", "        ", "query_tokens", "=", "tokenizer", ".", "tokenize", "(", "example", ".", "question_text", ")", "\n", "\n", "if", "len", "(", "query_tokens", ")", ">", "max_query_length", ":", "\n", "            ", "query_tokens", "=", "query_tokens", "[", "0", ":", "max_query_length", "]", "\n", "\n", "", "tok_to_orig_index", "=", "[", "]", "\n", "orig_to_tok_index", "=", "[", "]", "\n", "all_doc_tokens", "=", "[", "]", "\n", "for", "(", "i", ",", "token", ")", "in", "enumerate", "(", "example", ".", "doc_tokens", ")", ":", "\n", "            ", "orig_to_tok_index", ".", "append", "(", "len", "(", "all_doc_tokens", ")", ")", "\n", "sub_tokens", "=", "tokenizer", ".", "tokenize", "(", "token", ")", "\n", "for", "sub_token", "in", "sub_tokens", ":", "\n", "                ", "tok_to_orig_index", ".", "append", "(", "i", ")", "\n", "all_doc_tokens", ".", "append", "(", "sub_token", ")", "\n", "\n", "", "", "tok_start_position", "=", "None", "\n", "tok_end_position", "=", "None", "\n", "if", "is_training", "and", "example", ".", "is_impossible", ":", "\n", "            ", "tok_start_position", "=", "-", "1", "\n", "tok_end_position", "=", "-", "1", "\n", "", "if", "is_training", "and", "not", "example", ".", "is_impossible", ":", "\n", "            ", "tok_start_position", "=", "orig_to_tok_index", "[", "example", ".", "start_position", "]", "\n", "if", "example", ".", "end_position", "<", "len", "(", "example", ".", "doc_tokens", ")", "-", "1", ":", "\n", "                ", "tok_end_position", "=", "orig_to_tok_index", "[", "example", ".", "end_position", "+", "1", "]", "-", "1", "\n", "", "else", ":", "\n", "                ", "tok_end_position", "=", "len", "(", "all_doc_tokens", ")", "-", "1", "\n", "", "(", "tok_start_position", ",", "tok_end_position", ")", "=", "_improve_answer_span", "(", "\n", "all_doc_tokens", ",", "tok_start_position", ",", "tok_end_position", ",", "tokenizer", ",", "\n", "example", ".", "orig_answer_text", ")", "\n", "\n", "# The -3 accounts for [CLS], [SEP] and [SEP]", "\n", "", "max_tokens_for_doc", "=", "max_seq_length", "-", "len", "(", "query_tokens", ")", "-", "3", "\n", "\n", "# We can have documents that are longer than the maximum sequence length.", "\n", "# To deal with this we do a sliding window approach, where we take chunks", "\n", "# of the up to our max length with a stride of `doc_stride`.", "\n", "_DocSpan", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"DocSpan\"", ",", "[", "\"start\"", ",", "\"length\"", "]", ")", "\n", "doc_spans", "=", "[", "]", "\n", "start_offset", "=", "0", "\n", "while", "start_offset", "<", "len", "(", "all_doc_tokens", ")", ":", "\n", "            ", "length", "=", "len", "(", "all_doc_tokens", ")", "-", "start_offset", "\n", "if", "length", ">", "max_tokens_for_doc", ":", "\n", "                ", "length", "=", "max_tokens_for_doc", "\n", "", "doc_spans", ".", "append", "(", "_DocSpan", "(", "start", "=", "start_offset", ",", "length", "=", "length", ")", ")", "\n", "if", "start_offset", "+", "length", "==", "len", "(", "all_doc_tokens", ")", ":", "\n", "                ", "break", "\n", "", "start_offset", "+=", "min", "(", "length", ",", "doc_stride", ")", "\n", "\n", "", "for", "(", "doc_span_index", ",", "doc_span", ")", "in", "enumerate", "(", "doc_spans", ")", ":", "\n", "            ", "tokens", "=", "[", "]", "\n", "token_to_orig_map", "=", "{", "}", "\n", "token_is_max_context", "=", "{", "}", "\n", "segment_ids", "=", "[", "]", "\n", "\n", "# p_mask: mask with 1 for token than cannot be in the answer (0 for token which can be in an answer)", "\n", "# Original TF implem also keep the classification token (set to 0) (not sure why...)", "\n", "p_mask", "=", "[", "]", "\n", "\n", "# CLS token at the beginning", "\n", "if", "not", "cls_token_at_end", ":", "\n", "                ", "tokens", ".", "append", "(", "cls_token", ")", "\n", "segment_ids", ".", "append", "(", "cls_token_segment_id", ")", "\n", "p_mask", ".", "append", "(", "0", ")", "\n", "cls_index", "=", "0", "\n", "\n", "# Query", "\n", "", "for", "token", "in", "query_tokens", ":", "\n", "                ", "tokens", ".", "append", "(", "token", ")", "\n", "segment_ids", ".", "append", "(", "sequence_a_segment_id", ")", "\n", "p_mask", ".", "append", "(", "1", ")", "\n", "\n", "# SEP token", "\n", "", "tokens", ".", "append", "(", "sep_token", ")", "\n", "segment_ids", ".", "append", "(", "sequence_a_segment_id", ")", "\n", "p_mask", ".", "append", "(", "1", ")", "\n", "\n", "# Paragraph", "\n", "for", "i", "in", "range", "(", "doc_span", ".", "length", ")", ":", "\n", "                ", "split_token_index", "=", "doc_span", ".", "start", "+", "i", "\n", "token_to_orig_map", "[", "len", "(", "tokens", ")", "]", "=", "tok_to_orig_index", "[", "split_token_index", "]", "\n", "\n", "is_max_context", "=", "_check_is_max_context", "(", "doc_spans", ",", "doc_span_index", ",", "\n", "split_token_index", ")", "\n", "token_is_max_context", "[", "len", "(", "tokens", ")", "]", "=", "is_max_context", "\n", "tokens", ".", "append", "(", "all_doc_tokens", "[", "split_token_index", "]", ")", "\n", "segment_ids", ".", "append", "(", "sequence_b_segment_id", ")", "\n", "p_mask", ".", "append", "(", "0", ")", "\n", "", "paragraph_len", "=", "doc_span", ".", "length", "\n", "\n", "# SEP token", "\n", "tokens", ".", "append", "(", "sep_token", ")", "\n", "segment_ids", ".", "append", "(", "sequence_b_segment_id", ")", "\n", "p_mask", ".", "append", "(", "1", ")", "\n", "\n", "# CLS token at the end", "\n", "if", "cls_token_at_end", ":", "\n", "                ", "tokens", ".", "append", "(", "cls_token", ")", "\n", "segment_ids", ".", "append", "(", "cls_token_segment_id", ")", "\n", "p_mask", ".", "append", "(", "0", ")", "\n", "cls_index", "=", "len", "(", "tokens", ")", "-", "1", "# Index of classification token", "\n", "\n", "", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "while", "len", "(", "input_ids", ")", "<", "max_seq_length", ":", "\n", "                ", "input_ids", ".", "append", "(", "pad_token", ")", "\n", "input_mask", ".", "append", "(", "0", "if", "mask_padding_with_zero", "else", "1", ")", "\n", "segment_ids", ".", "append", "(", "pad_token_segment_id", ")", "\n", "p_mask", ".", "append", "(", "1", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "\n", "span_is_impossible", "=", "example", ".", "is_impossible", "\n", "start_position", "=", "None", "\n", "end_position", "=", "None", "\n", "if", "is_training", "and", "not", "span_is_impossible", ":", "\n", "# For training, if our document chunk does not contain an annotation", "\n", "# we throw it out, since there is nothing to predict.", "\n", "                ", "doc_start", "=", "doc_span", ".", "start", "\n", "doc_end", "=", "doc_span", ".", "start", "+", "doc_span", ".", "length", "-", "1", "\n", "out_of_span", "=", "False", "\n", "if", "not", "(", "tok_start_position", ">=", "doc_start", "and", "\n", "tok_end_position", "<=", "doc_end", ")", ":", "\n", "                    ", "out_of_span", "=", "True", "\n", "", "if", "out_of_span", ":", "\n", "                    ", "start_position", "=", "0", "\n", "end_position", "=", "0", "\n", "span_is_impossible", "=", "True", "\n", "continue", "\n", "", "else", ":", "\n", "                    ", "doc_offset", "=", "len", "(", "query_tokens", ")", "+", "2", "\n", "start_position", "=", "tok_start_position", "-", "doc_start", "+", "doc_offset", "\n", "end_position", "=", "tok_end_position", "-", "doc_start", "+", "doc_offset", "\n", "\n", "", "", "if", "is_training", "and", "span_is_impossible", ":", "\n", "                ", "start_position", "=", "cls_index", "\n", "end_position", "=", "cls_index", "\n", "\n", "", "if", "example_index", "<", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"unique_id: %s\"", "%", "(", "unique_id", ")", ")", "\n", "logger", ".", "info", "(", "\"example_index: %s\"", "%", "(", "example_index", ")", ")", "\n", "logger", ".", "info", "(", "\"doc_span_index: %s\"", "%", "(", "doc_span_index", ")", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", "%", "\" \"", ".", "join", "(", "tokens", ")", ")", "\n", "logger", ".", "info", "(", "\"token_to_orig_map: %s\"", "%", "\" \"", ".", "join", "(", "[", "\n", "\"%d:%d\"", "%", "(", "x", ",", "y", ")", "for", "(", "x", ",", "y", ")", "in", "token_to_orig_map", ".", "items", "(", ")", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"token_is_max_context: %s\"", "%", "\" \"", ".", "join", "(", "[", "\n", "\"%d:%s\"", "%", "(", "x", ",", "y", ")", "for", "(", "x", ",", "y", ")", "in", "token_is_max_context", ".", "items", "(", ")", "\n", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"input_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"segment_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "if", "is_training", "and", "span_is_impossible", ":", "\n", "                    ", "logger", ".", "info", "(", "\"impossible example\"", ")", "\n", "", "if", "is_training", "and", "not", "span_is_impossible", ":", "\n", "                    ", "answer_text", "=", "\" \"", ".", "join", "(", "tokens", "[", "start_position", ":", "(", "end_position", "+", "1", ")", "]", ")", "\n", "logger", ".", "info", "(", "\"start_position: %d\"", "%", "(", "start_position", ")", ")", "\n", "logger", ".", "info", "(", "\"end_position: %d\"", "%", "(", "end_position", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"answer: %s\"", "%", "(", "answer_text", ")", ")", "\n", "", "", "if", "example_index", "and", "example_index", "%", "10000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"Converting to features: %d finished.\"", "%", "(", "example_index", ")", ")", "\n", "", "features", ".", "append", "(", "\n", "InputFeatures", "(", "\n", "unique_id", "=", "unique_id", ",", "\n", "example_index", "=", "example_index", ",", "\n", "doc_span_index", "=", "doc_span_index", ",", "\n", "tokens", "=", "tokens", ",", "\n", "token_to_orig_map", "=", "token_to_orig_map", ",", "\n", "token_is_max_context", "=", "token_is_max_context", ",", "\n", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "cls_index", "=", "cls_index", ",", "\n", "p_mask", "=", "p_mask", ",", "\n", "paragraph_len", "=", "paragraph_len", ",", "\n", "start_position", "=", "start_position", ",", "\n", "end_position", "=", "end_position", ",", "\n", "is_impossible", "=", "span_is_impossible", ")", ")", "\n", "unique_id", "+=", "1", "\n", "\n", "", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad._improve_answer_span": [[402, 437], ["range", "tokenizer.tokenize", "range"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.data_utils.tokenize"], ["", "def", "_improve_answer_span", "(", "doc_tokens", ",", "input_start", ",", "input_end", ",", "tokenizer", ",", "\n", "orig_answer_text", ")", ":", "\n", "    ", "\"\"\"Returns tokenized answer spans that better match the annotated answer.\"\"\"", "\n", "\n", "# The SQuAD annotations are character based. We first project them to", "\n", "# whitespace-tokenized words. But then after WordPiece tokenization, we can", "\n", "# often find a \"better match\". For example:", "\n", "#", "\n", "#   Question: What year was John Smith born?", "\n", "#   Context: The leader was John Smith (1895-1943).", "\n", "#   Answer: 1895", "\n", "#", "\n", "# The original whitespace-tokenized answer will be \"(1895-1943).\". However", "\n", "# after tokenization, our tokens will be \"( 1895 - 1943 ) .\". So we can match", "\n", "# the exact answer, 1895.", "\n", "#", "\n", "# However, this is not always possible. Consider the following:", "\n", "#", "\n", "#   Question: What country is the top exporter of electornics?", "\n", "#   Context: The Japanese electronics industry is the lagest in the world.", "\n", "#   Answer: Japan", "\n", "#", "\n", "# In this case, the annotator chose \"Japan\" as a character sub-span of", "\n", "# the word \"Japanese\". Since our WordPiece tokenizer does not split", "\n", "# \"Japanese\", we just use \"Japanese\" as the annotation. This is fairly rare", "\n", "# in SQuAD, but does happen.", "\n", "tok_answer_text", "=", "\" \"", ".", "join", "(", "tokenizer", ".", "tokenize", "(", "orig_answer_text", ")", ")", "\n", "\n", "for", "new_start", "in", "range", "(", "input_start", ",", "input_end", "+", "1", ")", ":", "\n", "        ", "for", "new_end", "in", "range", "(", "input_end", ",", "new_start", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "text_span", "=", "\" \"", ".", "join", "(", "doc_tokens", "[", "new_start", ":", "(", "new_end", "+", "1", ")", "]", ")", "\n", "if", "text_span", "==", "tok_answer_text", ":", "\n", "                ", "return", "(", "new_start", ",", "new_end", ")", "\n", "\n", "", "", "", "return", "(", "input_start", ",", "input_end", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad._check_is_max_context": [[439, 474], ["enumerate", "min"], "function", ["None"], ["", "def", "_check_is_max_context", "(", "doc_spans", ",", "cur_span_index", ",", "position", ")", ":", "\n", "    ", "\"\"\"Check if this is the 'max context' doc span for the token.\"\"\"", "\n", "\n", "# Because of the sliding window approach taken to scoring documents, a single", "\n", "# token can appear in multiple documents. E.g.", "\n", "#  Doc: the man went to the store and bought a gallon of milk", "\n", "#  Span A: the man went to the", "\n", "#  Span B: to the store and bought", "\n", "#  Span C: and bought a gallon of", "\n", "#  ...", "\n", "#", "\n", "# Now the word 'bought' will have two scores from spans B and C. We only", "\n", "# want to consider the score with \"maximum context\", which we define as", "\n", "# the *minimum* of its left and right context (the *sum* of left and", "\n", "# right context will always be the same, of course).", "\n", "#", "\n", "# In the example the maximum context for 'bought' would be span C since", "\n", "# it has 1 left context and 3 right context, while span B has 4 left context", "\n", "# and 0 right context.", "\n", "best_score", "=", "None", "\n", "best_span_index", "=", "None", "\n", "for", "(", "span_index", ",", "doc_span", ")", "in", "enumerate", "(", "doc_spans", ")", ":", "\n", "        ", "end", "=", "doc_span", ".", "start", "+", "doc_span", ".", "length", "-", "1", "\n", "if", "position", "<", "doc_span", ".", "start", ":", "\n", "            ", "continue", "\n", "", "if", "position", ">", "end", ":", "\n", "            ", "continue", "\n", "", "num_left_context", "=", "position", "-", "doc_span", ".", "start", "\n", "num_right_context", "=", "end", "-", "position", "\n", "score", "=", "min", "(", "num_left_context", ",", "num_right_context", ")", "+", "0.01", "*", "doc_span", ".", "length", "\n", "if", "best_score", "is", "None", "or", "score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "score", "\n", "best_span_index", "=", "span_index", "\n", "\n", "", "", "return", "cur_span_index", "==", "best_span_index", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad.write_predictions": [[479, 677], ["logger.info", "logger.info", "collections.defaultdict", "collections.namedtuple", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "enumerate", "example_index_to_features[].append", "enumerate", "sorted", "collections.namedtuple", "utils_squad._compute_softmax", "enumerate", "io.open", "writer.write", "io.open", "writer.write", "utils_squad._get_best_indexes", "utils_squad._get_best_indexes", "sorted.append", "nbest.append", "nbest.append", "len", "total_scores.append", "collections.OrderedDict", "nbest_json.append", "len", "io.open", "writer.write", "collections.namedtuple.", "len", "tok_text.strip.replace", "tok_text.strip.replace", "tok_text.strip.strip", "utils_squad.get_final_text", "collections.namedtuple.", "nbest.append", "len", "nbest.insert", "collections.namedtuple.", "json.dumps", "json.dumps", "sorted.append", "tok_text.strip.split", "collections.namedtuple.", "collections.namedtuple.", "json.dumps", "len", "len", "feature.token_is_max_context.get", "collections.namedtuple."], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad._compute_softmax", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad._get_best_indexes", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad._get_best_indexes", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad.get_final_text"], ["def", "write_predictions", "(", "all_examples", ",", "all_features", ",", "all_results", ",", "n_best_size", ",", "\n", "max_answer_length", ",", "do_lower_case", ",", "output_prediction_file", ",", "\n", "output_nbest_file", ",", "output_null_log_odds_file", ",", "verbose_logging", ",", "\n", "version_2_with_negative", ",", "null_score_diff_threshold", ")", ":", "\n", "    ", "\"\"\"Write final predictions to the json file and log-odds of null if needed.\"\"\"", "\n", "logger", ".", "info", "(", "\"Writing predictions to: %s\"", "%", "(", "output_prediction_file", ")", ")", "\n", "logger", ".", "info", "(", "\"Writing nbest to: %s\"", "%", "(", "output_nbest_file", ")", ")", "\n", "\n", "example_index_to_features", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "feature", "in", "all_features", ":", "\n", "        ", "example_index_to_features", "[", "feature", ".", "example_index", "]", ".", "append", "(", "feature", ")", "\n", "\n", "", "unique_id_to_result", "=", "{", "}", "\n", "for", "result", "in", "all_results", ":", "\n", "        ", "unique_id_to_result", "[", "result", ".", "unique_id", "]", "=", "result", "\n", "\n", "", "_PrelimPrediction", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"PrelimPrediction\"", ",", "\n", "[", "\"feature_index\"", ",", "\"start_index\"", ",", "\"end_index\"", ",", "\"start_logit\"", ",", "\"end_logit\"", "]", ")", "\n", "\n", "all_predictions", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "all_nbest_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "scores_diff_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "\n", "for", "(", "example_index", ",", "example", ")", "in", "enumerate", "(", "all_examples", ")", ":", "\n", "        ", "features", "=", "example_index_to_features", "[", "example_index", "]", "\n", "\n", "prelim_predictions", "=", "[", "]", "\n", "# keep track of the minimum score of null start+end of position 0", "\n", "score_null", "=", "1000000", "# large and positive", "\n", "min_null_feature_index", "=", "0", "# the paragraph slice with min null score", "\n", "null_start_logit", "=", "0", "# the start logit at the slice with min null score", "\n", "null_end_logit", "=", "0", "# the end logit at the slice with min null score", "\n", "for", "(", "feature_index", ",", "feature", ")", "in", "enumerate", "(", "features", ")", ":", "\n", "            ", "result", "=", "unique_id_to_result", "[", "feature", ".", "unique_id", "]", "\n", "start_indexes", "=", "_get_best_indexes", "(", "result", ".", "start_logits", ",", "n_best_size", ")", "\n", "end_indexes", "=", "_get_best_indexes", "(", "result", ".", "end_logits", ",", "n_best_size", ")", "\n", "# if we could have irrelevant answers, get the min score of irrelevant", "\n", "if", "version_2_with_negative", ":", "\n", "                ", "feature_null_score", "=", "result", ".", "start_logits", "[", "0", "]", "+", "result", ".", "end_logits", "[", "0", "]", "\n", "if", "feature_null_score", "<", "score_null", ":", "\n", "                    ", "score_null", "=", "feature_null_score", "\n", "min_null_feature_index", "=", "feature_index", "\n", "null_start_logit", "=", "result", ".", "start_logits", "[", "0", "]", "\n", "null_end_logit", "=", "result", ".", "end_logits", "[", "0", "]", "\n", "", "", "for", "start_index", "in", "start_indexes", ":", "\n", "                ", "for", "end_index", "in", "end_indexes", ":", "\n", "# We could hypothetically create invalid predictions, e.g., predict", "\n", "# that the start of the span is in the question. We throw out all", "\n", "# invalid predictions.", "\n", "                    ", "if", "start_index", ">=", "len", "(", "feature", ".", "tokens", ")", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", ">=", "len", "(", "feature", ".", "tokens", ")", ":", "\n", "                        ", "continue", "\n", "", "if", "start_index", "not", "in", "feature", ".", "token_to_orig_map", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", "not", "in", "feature", ".", "token_to_orig_map", ":", "\n", "                        ", "continue", "\n", "", "if", "not", "feature", ".", "token_is_max_context", ".", "get", "(", "start_index", ",", "False", ")", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", "<", "start_index", ":", "\n", "                        ", "continue", "\n", "", "length", "=", "end_index", "-", "start_index", "+", "1", "\n", "if", "length", ">", "max_answer_length", ":", "\n", "                        ", "continue", "\n", "", "prelim_predictions", ".", "append", "(", "\n", "_PrelimPrediction", "(", "\n", "feature_index", "=", "feature_index", ",", "\n", "start_index", "=", "start_index", ",", "\n", "end_index", "=", "end_index", ",", "\n", "start_logit", "=", "result", ".", "start_logits", "[", "start_index", "]", ",", "\n", "end_logit", "=", "result", ".", "end_logits", "[", "end_index", "]", ")", ")", "\n", "", "", "", "if", "version_2_with_negative", ":", "\n", "            ", "prelim_predictions", ".", "append", "(", "\n", "_PrelimPrediction", "(", "\n", "feature_index", "=", "min_null_feature_index", ",", "\n", "start_index", "=", "0", ",", "\n", "end_index", "=", "0", ",", "\n", "start_logit", "=", "null_start_logit", ",", "\n", "end_logit", "=", "null_end_logit", ")", ")", "\n", "", "prelim_predictions", "=", "sorted", "(", "\n", "prelim_predictions", ",", "\n", "key", "=", "lambda", "x", ":", "(", "x", ".", "start_logit", "+", "x", ".", "end_logit", ")", ",", "\n", "reverse", "=", "True", ")", "\n", "\n", "_NbestPrediction", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"NbestPrediction\"", ",", "[", "\"text\"", ",", "\"start_logit\"", ",", "\"end_logit\"", ",", "\"orig_doc_start\"", "]", ")", "\n", "\n", "seen_predictions", "=", "{", "}", "\n", "nbest", "=", "[", "]", "\n", "for", "pred", "in", "prelim_predictions", ":", "\n", "            ", "if", "len", "(", "nbest", ")", ">=", "n_best_size", ":", "\n", "                ", "break", "\n", "", "feature", "=", "features", "[", "pred", ".", "feature_index", "]", "\n", "if", "pred", ".", "start_index", ">", "0", ":", "# this is a non-null prediction", "\n", "                ", "tok_tokens", "=", "feature", ".", "tokens", "[", "pred", ".", "start_index", ":", "(", "pred", ".", "end_index", "+", "1", ")", "]", "\n", "orig_doc_start", "=", "feature", ".", "token_to_orig_map", "[", "pred", ".", "start_index", "]", "\n", "orig_doc_end", "=", "feature", ".", "token_to_orig_map", "[", "pred", ".", "end_index", "]", "\n", "orig_tokens", "=", "example", ".", "doc_tokens", "[", "orig_doc_start", ":", "(", "orig_doc_end", "+", "1", ")", "]", "\n", "tok_text", "=", "\" \"", ".", "join", "(", "tok_tokens", ")", "\n", "\n", "# De-tokenize WordPieces that have been split off.", "\n", "tok_text", "=", "tok_text", ".", "replace", "(", "\" ##\"", ",", "\"\"", ")", "\n", "tok_text", "=", "tok_text", ".", "replace", "(", "\"##\"", ",", "\"\"", ")", "\n", "\n", "# Clean whitespace", "\n", "tok_text", "=", "tok_text", ".", "strip", "(", ")", "\n", "tok_text", "=", "\" \"", ".", "join", "(", "tok_text", ".", "split", "(", ")", ")", "\n", "orig_text", "=", "\" \"", ".", "join", "(", "orig_tokens", ")", "\n", "\n", "final_text", "=", "get_final_text", "(", "tok_text", ",", "orig_text", ",", "do_lower_case", ",", "verbose_logging", ")", "\n", "#ans_pos_str = \"<ANSPOS>{}\".format(orig_doc_start)", "\n", "#final_text = final_text + ans_pos_str", "\n", "if", "final_text", "in", "seen_predictions", ":", "\n", "                    ", "continue", "\n", "\n", "", "seen_predictions", "[", "final_text", "]", "=", "True", "\n", "", "else", ":", "\n", "                ", "final_text", "=", "\"\"", "\n", "seen_predictions", "[", "final_text", "]", "=", "True", "\n", "\n", "", "nbest", ".", "append", "(", "\n", "_NbestPrediction", "(", "\n", "text", "=", "final_text", ",", "\n", "start_logit", "=", "pred", ".", "start_logit", ",", "\n", "end_logit", "=", "pred", ".", "end_logit", ",", "\n", "orig_doc_start", "=", "orig_doc_start", "\n", ")", ")", "\n", "# if we didn't include the empty option in the n-best, include it", "\n", "", "if", "version_2_with_negative", ":", "\n", "            ", "if", "\"\"", "not", "in", "seen_predictions", ":", "\n", "                ", "nbest", ".", "append", "(", "\n", "_NbestPrediction", "(", "\n", "text", "=", "\"\"", ",", "\n", "start_logit", "=", "null_start_logit", ",", "\n", "end_logit", "=", "null_end_logit", ",", "\n", "orig_doc_start", "=", "0", ")", ")", "\n", "\n", "# In very rare edge cases we could only have single null prediction.", "\n", "# So we just create a nonce prediction in this case to avoid failure.", "\n", "", "if", "len", "(", "nbest", ")", "==", "1", ":", "\n", "                ", "nbest", ".", "insert", "(", "0", ",", "\n", "_NbestPrediction", "(", "text", "=", "\"empty\"", ",", "start_logit", "=", "0.0", ",", "end_logit", "=", "0.0", ",", "orig_doc_start", "=", "0", ")", ")", "\n", "\n", "# In very rare edge cases we could have no valid predictions. So we", "\n", "# just create a nonce prediction in this case to avoid failure.", "\n", "", "", "if", "not", "nbest", ":", "\n", "            ", "nbest", ".", "append", "(", "\n", "_NbestPrediction", "(", "text", "=", "\"empty\"", ",", "start_logit", "=", "0.0", ",", "end_logit", "=", "0.0", ",", "orig_doc_start", "=", "0", ")", ")", "\n", "\n", "", "assert", "len", "(", "nbest", ")", ">=", "1", "\n", "\n", "total_scores", "=", "[", "]", "\n", "best_non_null_entry", "=", "None", "\n", "for", "entry", "in", "nbest", ":", "\n", "            ", "total_scores", ".", "append", "(", "entry", ".", "start_logit", "+", "entry", ".", "end_logit", ")", "\n", "if", "not", "best_non_null_entry", ":", "\n", "                ", "if", "entry", ".", "text", ":", "\n", "                    ", "best_non_null_entry", "=", "entry", "\n", "\n", "", "", "", "probs", "=", "_compute_softmax", "(", "total_scores", ")", "\n", "\n", "nbest_json", "=", "[", "]", "\n", "for", "(", "i", ",", "entry", ")", "in", "enumerate", "(", "nbest", ")", ":", "\n", "            ", "output", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "output", "[", "\"text\"", "]", "=", "entry", ".", "text", "\n", "output", "[", "\"probability\"", "]", "=", "probs", "[", "i", "]", "\n", "output", "[", "\"start_logit\"", "]", "=", "entry", ".", "start_logit", "\n", "output", "[", "\"end_logit\"", "]", "=", "entry", ".", "end_logit", "\n", "output", "[", "'orig_doc_start'", "]", "=", "entry", ".", "orig_doc_start", "\n", "nbest_json", ".", "append", "(", "output", ")", "\n", "\n", "", "assert", "len", "(", "nbest_json", ")", ">=", "1", "\n", "\n", "if", "not", "version_2_with_negative", ":", "\n", "            ", "all_predictions", "[", "example", ".", "qas_id", "]", "=", "nbest_json", "[", "0", "]", "[", "\"text\"", "]", "\n", "", "else", ":", "\n", "# predict \"\" iff the null score - the score of best non-null > threshold", "\n", "            ", "score_diff", "=", "score_null", "-", "best_non_null_entry", ".", "start_logit", "-", "(", "\n", "best_non_null_entry", ".", "end_logit", ")", "\n", "scores_diff_json", "[", "example", ".", "qas_id", "]", "=", "score_diff", "\n", "if", "score_diff", ">", "null_score_diff_threshold", ":", "\n", "                ", "all_predictions", "[", "example", ".", "qas_id", "]", "=", "\"\"", "\n", "", "else", ":", "\n", "                ", "all_predictions", "[", "example", ".", "qas_id", "]", "=", "best_non_null_entry", ".", "text", "\n", "", "", "all_nbest_json", "[", "example", ".", "qas_id", "]", "=", "nbest_json", "\n", "\n", "", "with", "open", "(", "output_prediction_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_predictions", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "with", "open", "(", "output_nbest_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_nbest_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "if", "version_2_with_negative", ":", "\n", "        ", "with", "open", "(", "output_null_log_odds_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "scores_diff_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "return", "all_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad.write_predictions_extended": [[685, 874], ["collections.namedtuple", "collections.namedtuple", "logger.info", "collections.defaultdict", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "enumerate", "utils_squad_evaluate.make_qid_to_has_ans", "utils_squad_evaluate.get_raw_scores", "utils_squad_evaluate.find_all_best_thresh_v2", "example_index_to_features[].append", "enumerate", "sorted", "utils_squad._compute_softmax", "enumerate", "io.open", "writer.write", "io.open", "writer.write", "io.open", "min", "range", "tokenizer.convert_tokens_to_string", "tok_text.strip.strip", "utils_squad.get_final_text", "nbest.append", "nbest.append", "total_scores.append", "collections.OrderedDict", "nbest_json.append", "len", "io.open", "writer.write", "json.load", "utils_squad_evaluate.make_qid_to_has_ans.items", "utils_squad_evaluate.make_qid_to_has_ans.items", "range", "len", "tok_text.strip.split", "collections.namedtuple.", "collections.namedtuple.", "json.dumps", "json.dumps", "sorted.append", "json.dumps", "feature.token_is_max_context.get", "collections.namedtuple."], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.make_qid_to_has_ans", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.get_raw_scores", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.find_all_best_thresh_v2", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad._compute_softmax", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad.get_final_text"], ["def", "write_predictions_extended", "(", "all_examples", ",", "all_features", ",", "all_results", ",", "n_best_size", ",", "\n", "max_answer_length", ",", "output_prediction_file", ",", "\n", "output_nbest_file", ",", "\n", "output_null_log_odds_file", ",", "orig_data_file", ",", "\n", "start_n_top", ",", "end_n_top", ",", "version_2_with_negative", ",", "\n", "tokenizer", ",", "verbose_logging", ")", ":", "\n", "    ", "\"\"\" XLNet write prediction logic (more complex than Bert's).\n        Write final predictions to the json file and log-odds of null if needed.\n\n        Requires utils_squad_evaluate.py\n    \"\"\"", "\n", "_PrelimPrediction", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"PrelimPrediction\"", ",", "\n", "[", "\"feature_index\"", ",", "\"start_index\"", ",", "\"end_index\"", ",", "\n", "\"start_log_prob\"", ",", "\"end_log_prob\"", "]", ")", "\n", "\n", "_NbestPrediction", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"NbestPrediction\"", ",", "[", "\"text\"", ",", "\"start_log_prob\"", ",", "\"end_log_prob\"", "]", ")", "\n", "\n", "logger", ".", "info", "(", "\"Writing predictions to: %s\"", ",", "output_prediction_file", ")", "\n", "# logger.info(\"Writing nbest to: %s\" % (output_nbest_file))", "\n", "\n", "example_index_to_features", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "feature", "in", "all_features", ":", "\n", "        ", "example_index_to_features", "[", "feature", ".", "example_index", "]", ".", "append", "(", "feature", ")", "\n", "\n", "", "unique_id_to_result", "=", "{", "}", "\n", "for", "result", "in", "all_results", ":", "\n", "        ", "unique_id_to_result", "[", "result", ".", "unique_id", "]", "=", "result", "\n", "\n", "", "all_predictions", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "all_nbest_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "scores_diff_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "\n", "for", "(", "example_index", ",", "example", ")", "in", "enumerate", "(", "all_examples", ")", ":", "\n", "        ", "features", "=", "example_index_to_features", "[", "example_index", "]", "\n", "\n", "prelim_predictions", "=", "[", "]", "\n", "# keep track of the minimum score of null start+end of position 0", "\n", "score_null", "=", "1000000", "# large and positive", "\n", "\n", "for", "(", "feature_index", ",", "feature", ")", "in", "enumerate", "(", "features", ")", ":", "\n", "            ", "result", "=", "unique_id_to_result", "[", "feature", ".", "unique_id", "]", "\n", "\n", "cur_null_score", "=", "result", ".", "cls_logits", "\n", "\n", "# if we could have irrelevant answers, get the min score of irrelevant", "\n", "score_null", "=", "min", "(", "score_null", ",", "cur_null_score", ")", "\n", "\n", "for", "i", "in", "range", "(", "start_n_top", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "end_n_top", ")", ":", "\n", "                    ", "start_log_prob", "=", "result", ".", "start_top_log_probs", "[", "i", "]", "\n", "start_index", "=", "result", ".", "start_top_index", "[", "i", "]", "\n", "\n", "j_index", "=", "i", "*", "end_n_top", "+", "j", "\n", "\n", "end_log_prob", "=", "result", ".", "end_top_log_probs", "[", "j_index", "]", "\n", "end_index", "=", "result", ".", "end_top_index", "[", "j_index", "]", "\n", "\n", "# We could hypothetically create invalid predictions, e.g., predict", "\n", "# that the start of the span is in the question. We throw out all", "\n", "# invalid predictions.", "\n", "if", "start_index", ">=", "feature", ".", "paragraph_len", "-", "1", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", ">=", "feature", ".", "paragraph_len", "-", "1", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "feature", ".", "token_is_max_context", ".", "get", "(", "start_index", ",", "False", ")", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", "<", "start_index", ":", "\n", "                        ", "continue", "\n", "", "length", "=", "end_index", "-", "start_index", "+", "1", "\n", "if", "length", ">", "max_answer_length", ":", "\n", "                        ", "continue", "\n", "\n", "", "prelim_predictions", ".", "append", "(", "\n", "_PrelimPrediction", "(", "\n", "feature_index", "=", "feature_index", ",", "\n", "start_index", "=", "start_index", ",", "\n", "end_index", "=", "end_index", ",", "\n", "start_log_prob", "=", "start_log_prob", ",", "\n", "end_log_prob", "=", "end_log_prob", ")", ")", "\n", "\n", "", "", "", "prelim_predictions", "=", "sorted", "(", "\n", "prelim_predictions", ",", "\n", "key", "=", "lambda", "x", ":", "(", "x", ".", "start_log_prob", "+", "x", ".", "end_log_prob", ")", ",", "\n", "reverse", "=", "True", ")", "\n", "\n", "seen_predictions", "=", "{", "}", "\n", "nbest", "=", "[", "]", "\n", "for", "pred", "in", "prelim_predictions", ":", "\n", "            ", "if", "len", "(", "nbest", ")", ">=", "n_best_size", ":", "\n", "                ", "break", "\n", "", "feature", "=", "features", "[", "pred", ".", "feature_index", "]", "\n", "\n", "# XLNet un-tokenizer", "\n", "# Let's keep it simple for now and see if we need all this later.", "\n", "# ", "\n", "# tok_start_to_orig_index = feature.tok_start_to_orig_index", "\n", "# tok_end_to_orig_index = feature.tok_end_to_orig_index", "\n", "# start_orig_pos = tok_start_to_orig_index[pred.start_index]", "\n", "# end_orig_pos = tok_end_to_orig_index[pred.end_index]", "\n", "# paragraph_text = example.paragraph_text", "\n", "# final_text = paragraph_text[start_orig_pos: end_orig_pos + 1].strip()", "\n", "\n", "# Previously used Bert untokenizer", "\n", "tok_tokens", "=", "feature", ".", "tokens", "[", "pred", ".", "start_index", ":", "(", "pred", ".", "end_index", "+", "1", ")", "]", "\n", "orig_doc_start", "=", "feature", ".", "token_to_orig_map", "[", "pred", ".", "start_index", "]", "\n", "orig_doc_end", "=", "feature", ".", "token_to_orig_map", "[", "pred", ".", "end_index", "]", "\n", "orig_tokens", "=", "example", ".", "doc_tokens", "[", "orig_doc_start", ":", "(", "orig_doc_end", "+", "1", ")", "]", "\n", "tok_text", "=", "tokenizer", ".", "convert_tokens_to_string", "(", "tok_tokens", ")", "\n", "\n", "# Clean whitespace", "\n", "tok_text", "=", "tok_text", ".", "strip", "(", ")", "\n", "tok_text", "=", "\" \"", ".", "join", "(", "tok_text", ".", "split", "(", ")", ")", "\n", "orig_text", "=", "\" \"", ".", "join", "(", "orig_tokens", ")", "\n", "\n", "final_text", "=", "get_final_text", "(", "tok_text", ",", "orig_text", ",", "tokenizer", ".", "do_lower_case", ",", "\n", "verbose_logging", ")", "\n", "\n", "if", "final_text", "in", "seen_predictions", ":", "\n", "                ", "continue", "\n", "\n", "", "seen_predictions", "[", "final_text", "]", "=", "True", "\n", "\n", "nbest", ".", "append", "(", "\n", "_NbestPrediction", "(", "\n", "text", "=", "final_text", ",", "\n", "start_log_prob", "=", "pred", ".", "start_log_prob", ",", "\n", "end_log_prob", "=", "pred", ".", "end_log_prob", ")", ")", "\n", "\n", "# In very rare edge cases we could have no valid predictions. So we", "\n", "# just create a nonce prediction in this case to avoid failure.", "\n", "", "if", "not", "nbest", ":", "\n", "            ", "nbest", ".", "append", "(", "\n", "_NbestPrediction", "(", "text", "=", "\"\"", ",", "start_log_prob", "=", "-", "1e6", ",", "\n", "end_log_prob", "=", "-", "1e6", ")", ")", "\n", "\n", "", "total_scores", "=", "[", "]", "\n", "best_non_null_entry", "=", "None", "\n", "for", "entry", "in", "nbest", ":", "\n", "            ", "total_scores", ".", "append", "(", "entry", ".", "start_log_prob", "+", "entry", ".", "end_log_prob", ")", "\n", "if", "not", "best_non_null_entry", ":", "\n", "                ", "best_non_null_entry", "=", "entry", "\n", "\n", "", "", "probs", "=", "_compute_softmax", "(", "total_scores", ")", "\n", "\n", "nbest_json", "=", "[", "]", "\n", "for", "(", "i", ",", "entry", ")", "in", "enumerate", "(", "nbest", ")", ":", "\n", "            ", "output", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "output", "[", "\"text\"", "]", "=", "entry", ".", "text", "\n", "output", "[", "\"probability\"", "]", "=", "probs", "[", "i", "]", "\n", "output", "[", "\"start_log_prob\"", "]", "=", "entry", ".", "start_log_prob", "\n", "output", "[", "\"end_log_prob\"", "]", "=", "entry", ".", "end_log_prob", "\n", "nbest_json", ".", "append", "(", "output", ")", "\n", "\n", "", "assert", "len", "(", "nbest_json", ")", ">=", "1", "\n", "assert", "best_non_null_entry", "is", "not", "None", "\n", "\n", "score_diff", "=", "score_null", "\n", "scores_diff_json", "[", "example", ".", "qas_id", "]", "=", "score_diff", "\n", "# note(zhiliny): always predict best_non_null_entry", "\n", "# and the evaluation script will search for the best threshold", "\n", "all_predictions", "[", "example", ".", "qas_id", "]", "=", "best_non_null_entry", ".", "text", "\n", "\n", "all_nbest_json", "[", "example", ".", "qas_id", "]", "=", "nbest_json", "\n", "\n", "", "with", "open", "(", "output_prediction_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_predictions", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "with", "open", "(", "output_nbest_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_nbest_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "if", "version_2_with_negative", ":", "\n", "        ", "with", "open", "(", "output_null_log_odds_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "scores_diff_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "with", "open", "(", "orig_data_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "        ", "orig_data", "=", "json", ".", "load", "(", "reader", ")", "[", "\"data\"", "]", "\n", "\n", "", "qid_to_has_ans", "=", "make_qid_to_has_ans", "(", "orig_data", ")", "\n", "has_ans_qids", "=", "[", "k", "for", "k", ",", "v", "in", "qid_to_has_ans", ".", "items", "(", ")", "if", "v", "]", "\n", "no_ans_qids", "=", "[", "k", "for", "k", ",", "v", "in", "qid_to_has_ans", ".", "items", "(", ")", "if", "not", "v", "]", "\n", "exact_raw", ",", "f1_raw", "=", "get_raw_scores", "(", "orig_data", ",", "all_predictions", ")", "\n", "out_eval", "=", "{", "}", "\n", "\n", "find_all_best_thresh_v2", "(", "out_eval", ",", "all_predictions", ",", "exact_raw", ",", "f1_raw", ",", "scores_diff_json", ",", "qid_to_has_ans", ")", "\n", "\n", "return", "out_eval", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad.get_final_text": [[876, 970], ["pytorch_transformers.tokenization_bert.BasicTokenizer", "tok_text.find", "utils_squad.get_final_text._strip_spaces"], "function", ["None"], ["", "def", "get_final_text", "(", "pred_text", ",", "orig_text", ",", "do_lower_case", ",", "verbose_logging", "=", "False", ")", ":", "\n", "    ", "\"\"\"Project the tokenized prediction back to the original text.\"\"\"", "\n", "\n", "# When we created the data, we kept track of the alignment between original", "\n", "# (whitespace tokenized) tokens and our WordPiece tokenized tokens. So", "\n", "# now `orig_text` contains the span of our original text corresponding to the", "\n", "# span that we predicted.", "\n", "#", "\n", "# However, `orig_text` may contain extra characters that we don't want in", "\n", "# our prediction.", "\n", "#", "\n", "# For example, let's say:", "\n", "#   pred_text = steve smith", "\n", "#   orig_text = Steve Smith's", "\n", "#", "\n", "# We don't want to return `orig_text` because it contains the extra \"'s\".", "\n", "#", "\n", "# We don't want to return `pred_text` because it's already been normalized", "\n", "# (the SQuAD eval script also does punctuation stripping/lower casing but", "\n", "# our tokenizer does additional normalization like stripping accent", "\n", "# characters).", "\n", "#", "\n", "# What we really want to return is \"Steve Smith\".", "\n", "#", "\n", "# Therefore, we have to apply a semi-complicated alignment heuristic between", "\n", "# `pred_text` and `orig_text` to get a character-to-character alignment. This", "\n", "# can fail in certain cases in which case we just return `orig_text`.", "\n", "\n", "def", "_strip_spaces", "(", "text", ")", ":", "\n", "        ", "ns_chars", "=", "[", "]", "\n", "ns_to_s_map", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "(", "i", ",", "c", ")", "in", "enumerate", "(", "text", ")", ":", "\n", "            ", "if", "c", "==", "\" \"", ":", "\n", "                ", "continue", "\n", "", "ns_to_s_map", "[", "len", "(", "ns_chars", ")", "]", "=", "i", "\n", "ns_chars", ".", "append", "(", "c", ")", "\n", "", "ns_text", "=", "\"\"", ".", "join", "(", "ns_chars", ")", "\n", "return", "(", "ns_text", ",", "ns_to_s_map", ")", "\n", "\n", "# We first tokenize `orig_text`, strip whitespace from the result", "\n", "# and `pred_text`, and check if they are the same length. If they are", "\n", "# NOT the same length, the heuristic has failed. If they are the same", "\n", "# length, we assume the characters are one-to-one aligned.", "\n", "", "tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "do_lower_case", ")", "\n", "\n", "tok_text", "=", "\" \"", ".", "join", "(", "tokenizer", ".", "tokenize", "(", "orig_text", ")", ")", "\n", "\n", "start_position", "=", "tok_text", ".", "find", "(", "pred_text", ")", "\n", "if", "start_position", "==", "-", "1", ":", "\n", "        ", "if", "verbose_logging", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Unable to find text: '%s' in '%s'\"", "%", "(", "pred_text", ",", "orig_text", ")", ")", "\n", "", "return", "orig_text", "\n", "", "end_position", "=", "start_position", "+", "len", "(", "pred_text", ")", "-", "1", "\n", "\n", "(", "orig_ns_text", ",", "orig_ns_to_s_map", ")", "=", "_strip_spaces", "(", "orig_text", ")", "\n", "(", "tok_ns_text", ",", "tok_ns_to_s_map", ")", "=", "_strip_spaces", "(", "tok_text", ")", "\n", "\n", "if", "len", "(", "orig_ns_text", ")", "!=", "len", "(", "tok_ns_text", ")", ":", "\n", "        ", "if", "verbose_logging", ":", "\n", "            ", "logger", ".", "info", "(", "\"Length not equal after stripping spaces: '%s' vs '%s'\"", ",", "\n", "orig_ns_text", ",", "tok_ns_text", ")", "\n", "", "return", "orig_text", "\n", "\n", "# We then project the characters in `pred_text` back to `orig_text` using", "\n", "# the character-to-character alignment.", "\n", "", "tok_s_to_ns_map", "=", "{", "}", "\n", "for", "(", "i", ",", "tok_index", ")", "in", "tok_ns_to_s_map", ".", "items", "(", ")", ":", "\n", "        ", "tok_s_to_ns_map", "[", "tok_index", "]", "=", "i", "\n", "\n", "", "orig_start_position", "=", "None", "\n", "if", "start_position", "in", "tok_s_to_ns_map", ":", "\n", "        ", "ns_start_position", "=", "tok_s_to_ns_map", "[", "start_position", "]", "\n", "if", "ns_start_position", "in", "orig_ns_to_s_map", ":", "\n", "            ", "orig_start_position", "=", "orig_ns_to_s_map", "[", "ns_start_position", "]", "\n", "\n", "", "", "if", "orig_start_position", "is", "None", ":", "\n", "        ", "if", "verbose_logging", ":", "\n", "            ", "logger", ".", "info", "(", "\"Couldn't map start position\"", ")", "\n", "", "return", "orig_text", "\n", "\n", "", "orig_end_position", "=", "None", "\n", "if", "end_position", "in", "tok_s_to_ns_map", ":", "\n", "        ", "ns_end_position", "=", "tok_s_to_ns_map", "[", "end_position", "]", "\n", "if", "ns_end_position", "in", "orig_ns_to_s_map", ":", "\n", "            ", "orig_end_position", "=", "orig_ns_to_s_map", "[", "ns_end_position", "]", "\n", "\n", "", "", "if", "orig_end_position", "is", "None", ":", "\n", "        ", "if", "verbose_logging", ":", "\n", "            ", "logger", ".", "info", "(", "\"Couldn't map end position\"", ")", "\n", "", "return", "orig_text", "\n", "\n", "", "output_text", "=", "orig_text", "[", "orig_start_position", ":", "(", "orig_end_position", "+", "1", ")", "]", "\n", "return", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad._get_best_indexes": [[972, 982], ["sorted", "range", "enumerate", "len", "best_indexes.append"], "function", ["None"], ["", "def", "_get_best_indexes", "(", "logits", ",", "n_best_size", ")", ":", "\n", "    ", "\"\"\"Get the n-best logits from a list.\"\"\"", "\n", "index_and_score", "=", "sorted", "(", "enumerate", "(", "logits", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "best_indexes", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "index_and_score", ")", ")", ":", "\n", "        ", "if", "i", ">=", "n_best_size", ":", "\n", "            ", "break", "\n", "", "best_indexes", ".", "append", "(", "index_and_score", "[", "i", "]", "[", "0", "]", ")", "\n", "", "return", "best_indexes", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad._compute_softmax": [[984, 1005], ["math.exp", "exp_scores.append", "probs.append"], "function", ["None"], ["", "def", "_compute_softmax", "(", "scores", ")", ":", "\n", "    ", "\"\"\"Compute softmax probability over raw logits.\"\"\"", "\n", "if", "not", "scores", ":", "\n", "        ", "return", "[", "]", "\n", "\n", "", "max_score", "=", "None", "\n", "for", "score", "in", "scores", ":", "\n", "        ", "if", "max_score", "is", "None", "or", "score", ">", "max_score", ":", "\n", "            ", "max_score", "=", "score", "\n", "\n", "", "", "exp_scores", "=", "[", "]", "\n", "total_sum", "=", "0.0", "\n", "for", "score", "in", "scores", ":", "\n", "        ", "x", "=", "math", ".", "exp", "(", "score", "-", "max_score", ")", "\n", "exp_scores", ".", "append", "(", "x", ")", "\n", "total_sum", "+=", "x", "\n", "\n", "", "probs", "=", "[", "]", "\n", "for", "score", "in", "exp_scores", ":", "\n", "        ", "probs", ".", "append", "(", "score", "/", "total_sum", ")", "\n", "", "return", "probs", "", "", ""]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.wikiref_process.search_sbar_from_tree": [[28, 38], ["range", "isinstance", "len", "wikiref_process.search_sbar_from_tree", "clause.append", "tree_node.label", "tree_node.label"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.wikiref_process.search_sbar_from_tree"], ["", "", "def", "search_sbar_from_tree", "(", "tree_node", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "tree_node", ",", "nltk", ".", "Tree", ")", ":", "\n", "        ", "return", "[", "]", "\n", "", "clause", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "tree_node", ")", ")", ":", "\n", "        ", "clause", "+=", "search_sbar_from_tree", "(", "tree_node", "[", "i", "]", ")", "\n", "#if tree_node.label() == 'SBAR':", "\n", "", "if", "tree_node", ".", "label", "(", ")", "==", "'S'", "or", "tree_node", ".", "label", "(", ")", "==", "'SBAR'", ":", "\n", "        ", "clause", ".", "append", "(", "tree_node", ")", "\n", "", "return", "clause", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.wikiref_process.get_clause_v2": [[39, 67], ["time.time", "predictor.parse", "sorted", "sentence.split", "range", "sorted", "wikiref_process.search_sbar_from_tree", "predictor.parse.leaves", "len", "sorted.append", "item.leaves", "node.label", "sorted.append", "item.strip", "node.leaves", "len", "len", "len", "len", "len", "item.split", "item.split"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.wikiref_process.search_sbar_from_tree"], ["", "def", "get_clause_v2", "(", "sentence", ",", "predictor", ")", ":", "\n", "    ", "start", "=", "time", ".", "time", "(", ")", "\n", "parsing_tree", "=", "predictor", ".", "parse", "(", "sentence", ")", "\n", "sbar", "=", "search_sbar_from_tree", "(", "parsing_tree", ")", "[", ":", "-", "1", "]", "\n", "sbar_text", "=", "[", "' '", ".", "join", "(", "item", ".", "leaves", "(", ")", ")", "for", "item", "in", "sbar", "]", "\n", "\n", "result", "=", "[", "]", "\n", "for", "node", "in", "sbar", ":", "\n", "        ", "if", "node", ".", "label", "(", ")", "==", "'S'", ":", "\n", "            ", "item", "=", "' '", ".", "join", "(", "node", ".", "leaves", "(", ")", ")", "\n", "if", "len", "(", "item", ".", "split", "(", ")", ")", "<=", "5", ":", "\n", "                ", "continue", "\n", "", "result", ".", "append", "(", "item", ")", "\n", "\n", "", "", "result", "=", "sorted", "(", "result", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", ")", ")", "\n", "\n", "result2", "=", "[", "]", "\n", "sentence", "=", "' '", ".", "join", "(", "parsing_tree", ".", "leaves", "(", ")", ")", "\n", "clauses", "=", "sentence", ".", "split", "(", "','", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "clauses", ")", ")", ":", "\n", "        ", "item", ",", "p", "=", "clauses", "[", "i", "]", ",", "i", "+", "1", "\n", "while", "len", "(", "item", ".", "split", "(", ")", ")", "<", "10", "and", "p", "<", "len", "(", "clauses", ")", ":", "\n", "            ", "item", "=", "','", ".", "join", "(", "[", "item", ",", "clauses", "[", "p", "]", "]", ")", "\n", "p", "+=", "1", "\n", "", "result2", ".", "append", "(", "item", ".", "strip", "(", ")", ")", "\n", "\n", "", "result2", "=", "sorted", "(", "result2", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", ")", ")", "\n", "return", "result", "+", "result2", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.wikiref_process.get_answer_start": [[68, 95], ["tagger", "tagger", "sorted.append", "len", "sorted", "q_tokens.append", "sent.find", "res_sent.find"], "function", ["None"], ["", "def", "get_answer_start", "(", "answer", ",", "question", ",", "sentences", ",", "tagger", ")", ":", "\n", "    ", "q_tokens", "=", "[", "]", "\n", "q_doc", "=", "tagger", "(", "question", ")", "\n", "for", "token", "in", "q_doc", ":", "\n", "        ", "if", "not", "token", ".", "is_stop", ":", "\n", "            ", "q_tokens", ".", "append", "(", "token", ".", "lemma_", ")", "\n", "\n", "", "", "result", "=", "[", "]", "\n", "for", "sent", "in", "sentences", ":", "\n", "        ", "if", "sent", ".", "find", "(", "answer", ")", "==", "-", "1", ":", "\n", "            ", "continue", "\n", "", "sent_doc", "=", "tagger", "(", "sent", ")", "\n", "score", "=", "0", "\n", "for", "token", "in", "sent_doc", ":", "\n", "            ", "if", "token", ".", "is_stop", ":", "\n", "                ", "continue", "\n", "", "if", "token", ".", "lemma_", "in", "q_tokens", ":", "\n", "                ", "score", "+=", "1", "\n", "", "", "result", ".", "append", "(", "[", "score", ",", "sent", "]", ")", "\n", "", "if", "len", "(", "result", ")", "==", "0", ":", "\n", "        ", "return", "-", "1", "\n", "", "else", ":", "\n", "        ", "result", "=", "sorted", "(", "result", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "res_sent", "=", "result", "[", "-", "1", "]", "[", "1", "]", "\n", "\n", "answer_start", "=", "' '", ".", "join", "(", "sentences", ")", ".", "find", "(", "res_sent", ")", "+", "res_sent", ".", "find", "(", "answer", ")", "\n", "return", "answer_start", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.wikiref_process.get_cloze_data": [[97, 177], ["spacy.load", "spacy.load", "tqdm.tqdm", "print", "benepar.Parser", "cloze_data.append", "json.dump", "spacy.load.", "print", "open", "wikiref_process.get_answer_start", "qas.append", "os.path.join", "wikiref_process.get_clause_v2", "sent[].replace", "len", "each.find", "each.replace"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.wikiref_process.get_answer_start", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.wikiref_process.get_clause_v2"], ["", "", "def", "get_cloze_data", "(", "input_data", ",", "clause_extract", "=", "False", ",", "proc", "=", "None", ")", ":", "\n", "    ", "if", "clause_extract", ":", "\n", "        ", "parser", "=", "benepar", ".", "Parser", "(", "\"benepar_en2\"", ")", "\n", "\n", "", "ner", "=", "spacy", ".", "load", "(", "\"en\"", ",", "disable", "=", "[", "'parser'", ",", "'tagger'", "]", ")", "\n", "tagger", "=", "spacy", ".", "load", "(", "\"en\"", ",", "disable", "=", "[", "'parser'", ",", "'ner'", "]", ")", "\n", "\n", "cloze_data", "=", "[", "]", "\n", "\n", "q_count", "=", "0", "\n", "c_count", "=", "0", "\n", "\n", "for", "item", "in", "tqdm", "(", "input_data", ",", "desc", "=", "\"cloze\"", ")", ":", "\n", "        ", "entry", "=", "{", "}", "\n", "entry", "[", "'title'", "]", "=", "item", "[", "\"document\"", "]", "[", "0", "]", "\n", "paragraph", "=", "{", "}", "\n", "paragraph", "[", "\"context\"", "]", "=", "' '", ".", "join", "(", "item", "[", "\"document\"", "]", ")", "\n", "\n", "qas", "=", "[", "]", "\n", "\n", "for", "sent", "in", "item", "[", "'summary'", "]", ":", "\n", "            ", "sent_doc", "=", "ner", "(", "sent", ")", "\n", "\n", "if", "clause_extract", ":", "\n", "                ", "try", ":", "\n", "                    ", "clause", "=", "get_clause_v2", "(", "sent", ",", "parser", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "continue", "\n", "\n", "", "", "for", "ent", "in", "sent_doc", ".", "ents", ":", "\n", "                ", "answer", "=", "ent", ".", "text", "\n", "\n", "question", "=", "None", "\n", "if", "clause_extract", ":", "\n", "                    ", "for", "each", "in", "clause", ":", "\n", "                        ", "if", "each", ".", "find", "(", "answer", ")", "!=", "-", "1", ":", "\n", "                            ", "question", "=", "each", ".", "replace", "(", "answer", ",", "entity_type_map", "[", "ent", ".", "label_", "]", ",", "1", ")", "\n", "break", "\n", "", "", "", "else", ":", "\n", "                    ", "question", "=", "sent", "[", ":", "ent", ".", "start_char", "]", "+", "sent", "[", "ent", ".", "start_char", ":", "]", ".", "replace", "(", "answer", ",", "entity_type_map", "[", "ent", ".", "label_", "]", ",", "1", ")", "\n", "", "if", "not", "question", ":", "\n", "                    ", "continue", "\n", "\n", "\n", "", "answer_start", "=", "get_answer_start", "(", "answer", ",", "question", ",", "item", "[", "'document'", "]", ",", "tagger", ")", "\n", "if", "answer_start", "==", "-", "1", ":", "\n", "                    ", "continue", "\n", "\n", "", "qas", ".", "append", "(", "{", "\n", "\"question\"", ":", "question", ",", "\n", "\"id\"", ":", "\"%s_%d\"", "%", "(", "item", "[", "'uid'", "]", ",", "q_count", ")", ",", "\n", "\"is_impossible\"", ":", "False", ",", "\n", "\"answers\"", ":", "[", "\n", "{", "\n", "\"answer_start\"", ":", "answer_start", ",", "\n", "\"text\"", ":", "answer", ",", "\n", "\"type\"", ":", "ent", ".", "label_", "\n", "}", "\n", "]", ",", "\n", "\"plausible_answers\"", ":", "[", "]", "\n", "}", ")", "\n", "q_count", "+=", "1", "\n", "\n", "", "", "paragraph", "[", "'qas'", "]", "=", "qas", "\n", "entry", "[", "'paragraphs'", "]", "=", "[", "paragraph", "]", "\n", "\n", "cloze_data", ".", "append", "(", "entry", ")", "\n", "#if q_count > 10:", "\n", "#    break", "\n", "c_count", "+=", "1", "\n", "if", "c_count", "%", "2000", "==", "0", ":", "\n", "            ", "print", "(", "proc", ",", "'processing %d/%d ...'", "%", "(", "c_count", ",", "len", "(", "input_data", ")", ")", ")", "\n", "\n", "\n", "", "", "if", "proc", "is", "not", "None", ":", "\n", "        ", "json", ".", "dump", "(", "cloze_data", ",", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'tmp_store_%d.json'", "%", "proc", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "\n", "", "print", "(", "'Questions Number'", ",", "q_count", ")", "\n", "return", "{", "\"version\"", ":", "\"v2.0\"", ",", "'data'", ":", "cloze_data", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.wikiref_process.main": [[179, 187], ["os.path.join", "wikiref_process.get_cloze_data", "json.dump", "open", "json.load", "open", "os.path.join"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.wikiref_process.get_cloze_data"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "input_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "args", ".", "input_file", ")", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "        ", "input_data", "=", "json", ".", "load", "(", "reader", ")", "\n", "\n", "", "cloze_clause_data", "=", "get_cloze_data", "(", "input_data", ",", "clause_extract", "=", "True", ")", "\n", "json", ".", "dump", "(", "cloze_clause_data", ",", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "args", ".", "output_file", ")", ",", "\n", "\"w\"", ",", "encoding", "=", "'utf-8'", ")", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.set_seed": [[64, 70], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.to_list": [[71, 73], ["tensor.detach().cpu().tolist", "tensor.detach().cpu", "tensor.detach"], "function", ["None"], ["", "", "def", "to_list", "(", "tensor", ")", ":", "\n", "    ", "return", "tensor", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.train": [[74, 206], ["torch.utils.data.DataLoader", "pytorch_transformers.AdamW", "pytorch_transformers.WarmupLinearSchedule", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_squad.set_seed", "tensorboardX.SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "int", "enumerate", "tensorboardX.SummaryWriter.close", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "tqdm.trange.close", "len", "ImportError", "torch.distributed.get_world_size", "inputs.update", "loss.mean.mean", "torch.nn.utils.clip_grad_norm_", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "pytorch_transformers.WarmupLinearSchedule.step", "pytorch_transformers.AdamW.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "epoch_iterator.close", "len", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "t.to", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "logger.info", "os.path.join", "model_to_save.save_pretrained", "torch.save", "logger.info", "any", "run_squad.evaluate", "evaluate.items", "logger.info", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "tensorboardX.SummaryWriter.add_scalar", "pytorch_transformers.WarmupLinearSchedule.get_lr", "pytorch_transformers.WarmupLinearSchedule.get_lr"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.set_seed", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.train", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "", "if", "t_total", "<", "args", ".", "min_steps", ":", "\n", "        ", "t_total", "=", "args", ".", "min_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "min_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "WarmupLinearSchedule", "(", "optimizer", ",", "warmup_steps", "=", "args", ".", "warmup_steps", ",", "t_total", "=", "t_total", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "\n", "output_device", "=", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility (even between python 2 and 3)", "\n", "for", "_", "in", "train_iterator", ":", "\n", "#epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])", "\n", "        ", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "None", "if", "args", ".", "model_type", "==", "'xlm'", "else", "batch", "[", "2", "]", ",", "\n", "'start_positions'", ":", "batch", "[", "3", "]", ",", "\n", "'end_positions'", ":", "batch", "[", "4", "]", "}", "\n", "if", "args", ".", "model_type", "in", "[", "'xlnet'", ",", "'xlm'", "]", ":", "\n", "                ", "inputs", ".", "update", "(", "{", "'cls_index'", ":", "batch", "[", "5", "]", ",", "\n", "'p_mask'", ":", "batch", "[", "6", "]", "}", ")", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in pytorch-transformers (see doc)", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel (not distributed) training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "optimizer", ".", "step", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Log metrics", "\n", "                    ", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "tb_writer", ".", "add_scalar", "(", "'eval_{}'", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "logger", ".", "info", "(", "'Eval F1 {}'", ".", "format", "(", "results", "[", "'f1'", "]", ")", ")", "\n", "", "tb_writer", ".", "add_scalar", "(", "'lr'", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "'loss'", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "'Step {}, LR {}, Loss {}'", ".", "format", "(", "global_step", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ")", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "# Save model checkpoint", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-{}'", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "if", "args", ".", "few_shot", ":", "\n", "                        ", "args", ".", "save_steps", "=", "args", ".", "save_steps", "*", "2", "\n", "if", "args", ".", "save_steps", ">", "args", ".", "logging_steps", ":", "\n", "                            ", "args", ".", "save_steps", "=", "args", ".", "logging_steps", "\n", "\n", "\n", "", "", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.evaluate": [[208, 282], ["run_squad.load_and_cache_examples", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "os.path.join", "os.path.join", "utils_squad_evaluate.EVAL_OPTS", "utils_squad_evaluate.main", "os.makedirs", "max", "len", "model.eval", "tuple", "enumerate", "os.path.join", "utils_squad.write_predictions_extended", "utils_squad.write_predictions", "os.path.exists", "torch.no_grad", "model", "int", "all_results.append", "t.to", "inputs.update", "utils_squad.RawResultExtended", "utils_squad.RawResult", "example_index.item", "run_squad.to_list", "run_squad.to_list", "run_squad.to_list", "run_squad.to_list", "run_squad.to_list", "run_squad.to_list", "run_squad.to_list"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.load_and_cache_examples", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.main", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad.write_predictions_extended", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad.write_predictions", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.to_list", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.to_list", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.to_list", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.to_list", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.to_list", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.to_list", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.to_list"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ")", ":", "\n", "    ", "dataset", ",", "examples", ",", "features", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "True", ",", "output_examples", "=", "True", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval!", "\n", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "all_results", "=", "[", "]", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'token_type_ids'", ":", "None", "if", "args", ".", "model_type", "==", "'xlm'", "else", "batch", "[", "2", "]", "# XLM don't use segment_ids", "\n", "}", "\n", "example_indices", "=", "batch", "[", "3", "]", "\n", "if", "args", ".", "model_type", "in", "[", "'xlnet'", ",", "'xlm'", "]", ":", "\n", "                ", "inputs", ".", "update", "(", "{", "'cls_index'", ":", "batch", "[", "4", "]", ",", "\n", "'p_mask'", ":", "batch", "[", "5", "]", "}", ")", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "", "for", "i", ",", "example_index", "in", "enumerate", "(", "example_indices", ")", ":", "\n", "            ", "eval_feature", "=", "features", "[", "example_index", ".", "item", "(", ")", "]", "\n", "unique_id", "=", "int", "(", "eval_feature", ".", "unique_id", ")", "\n", "if", "args", ".", "model_type", "in", "[", "'xlnet'", ",", "'xlm'", "]", ":", "\n", "# XLNet uses a more complex post-processing procedure", "\n", "                ", "result", "=", "RawResultExtended", "(", "unique_id", "=", "unique_id", ",", "\n", "start_top_log_probs", "=", "to_list", "(", "outputs", "[", "0", "]", "[", "i", "]", ")", ",", "\n", "start_top_index", "=", "to_list", "(", "outputs", "[", "1", "]", "[", "i", "]", ")", ",", "\n", "end_top_log_probs", "=", "to_list", "(", "outputs", "[", "2", "]", "[", "i", "]", ")", ",", "\n", "end_top_index", "=", "to_list", "(", "outputs", "[", "3", "]", "[", "i", "]", ")", ",", "\n", "cls_logits", "=", "to_list", "(", "outputs", "[", "4", "]", "[", "i", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "result", "=", "RawResult", "(", "unique_id", "=", "unique_id", ",", "\n", "start_logits", "=", "to_list", "(", "outputs", "[", "0", "]", "[", "i", "]", ")", ",", "\n", "end_logits", "=", "to_list", "(", "outputs", "[", "1", "]", "[", "i", "]", ")", ")", "\n", "", "all_results", ".", "append", "(", "result", ")", "\n", "\n", "# Compute predictions", "\n", "", "", "output_prediction_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"predictions_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "output_nbest_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"nbest_predictions_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "if", "args", ".", "version_2_with_negative", ":", "\n", "        ", "output_null_log_odds_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"null_odds_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "", "else", ":", "\n", "        ", "output_null_log_odds_file", "=", "None", "\n", "\n", "", "if", "args", ".", "model_type", "in", "[", "'xlnet'", ",", "'xlm'", "]", ":", "\n", "# XLNet uses a more complex post-processing procedure", "\n", "        ", "write_predictions_extended", "(", "examples", ",", "features", ",", "all_results", ",", "args", ".", "n_best_size", ",", "\n", "args", ".", "max_answer_length", ",", "output_prediction_file", ",", "\n", "output_nbest_file", ",", "output_null_log_odds_file", ",", "args", ".", "predict_file", ",", "\n", "model", ".", "config", ".", "start_n_top", ",", "model", ".", "config", ".", "end_n_top", ",", "\n", "args", ".", "version_2_with_negative", ",", "tokenizer", ",", "args", ".", "verbose_logging", ")", "\n", "", "else", ":", "\n", "        ", "write_predictions", "(", "examples", ",", "features", ",", "all_results", ",", "args", ".", "n_best_size", ",", "\n", "args", ".", "max_answer_length", ",", "args", ".", "do_lower_case", ",", "output_prediction_file", ",", "\n", "output_nbest_file", ",", "output_null_log_odds_file", ",", "args", ".", "verbose_logging", ",", "\n", "args", ".", "version_2_with_negative", ",", "args", ".", "null_score_diff_threshold", ")", "\n", "\n", "# Evaluate with the official SQuAD script", "\n", "", "evaluate_options", "=", "EVAL_OPTS", "(", "data_file", "=", "args", ".", "predict_file", ",", "\n", "pred_file", "=", "output_prediction_file", ",", "\n", "na_prob_file", "=", "output_null_log_odds_file", ")", "\n", "results", "=", "evaluate_on_squad", "(", "evaluate_options", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.load_and_cache_examples": [[284, 328], ["os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "os.path.dirname", "os.path.exists", "logger.info", "torch.load", "logger.info", "utils_squad.read_squad_examples", "utils_squad.convert_examples_to_features", "torch.arange", "torch.utils.data.TensorDataset", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "str", "list().pop", "list().pop", "logger.info", "torch.save", "torch.tensor.size", "list", "list", "filter", "filter", "args.model_name_or_path.split", "input_file.split"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad.read_squad_examples", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad.convert_examples_to_features"], ["", "def", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ",", "output_examples", "=", "False", ")", ":", "\n", "# Load data features from cache or dataset file", "\n", "    ", "input_file", "=", "args", ".", "predict_file", "if", "evaluate", "else", "args", ".", "train_file", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "input_file", ")", ",", "'cached_{}_{}_{}_{}'", ".", "format", "(", "\n", "'dev'", "if", "evaluate", "else", "'train'", ",", "str", "(", "args", ".", "max_seq_length", ")", ",", "list", "(", "filter", "(", "None", ",", "args", ".", "model_name_or_path", ".", "split", "(", "'/'", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "list", "(", "filter", "(", "None", ",", "input_file", ".", "split", "(", "'/'", ")", ")", ")", ".", "pop", "(", ")", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", "and", "not", "output_examples", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "input_file", ")", "\n", "examples", "=", "read_squad_examples", "(", "input_file", "=", "input_file", ",", "\n", "is_training", "=", "not", "evaluate", ",", "\n", "version_2_with_negative", "=", "args", ".", "version_2_with_negative", ")", "\n", "features", "=", "convert_examples_to_features", "(", "examples", "=", "examples", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "max_seq_length", "=", "args", ".", "max_seq_length", ",", "\n", "doc_stride", "=", "args", ".", "doc_stride", ",", "\n", "max_query_length", "=", "args", ".", "max_query_length", ",", "\n", "is_training", "=", "not", "evaluate", ")", "\n", "if", "(", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ")", "and", "(", "not", "evaluate", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "features", ",", "cached_features_file", ")", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_cls_index", "=", "torch", ".", "tensor", "(", "[", "f", ".", "cls_index", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_p_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "p_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "if", "evaluate", ":", "\n", "        ", "all_example_index", "=", "torch", ".", "arange", "(", "all_input_ids", ".", "size", "(", "0", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "\n", "all_example_index", ",", "all_cls_index", ",", "all_p_mask", ")", "\n", "", "else", ":", "\n", "        ", "all_start_positions", "=", "torch", ".", "tensor", "(", "[", "f", ".", "start_position", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_end_positions", "=", "torch", ".", "tensor", "(", "[", "f", ".", "end_position", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "\n", "all_start_positions", ",", "all_end_positions", ",", "\n", "all_cls_index", ",", "all_p_mask", ")", "\n", "\n", "", "if", "output_examples", ":", "\n", "        ", "return", "dataset", ",", "examples", ",", "features", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.main": [[330, 556], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "parser.parse_args.output_dir.replace", "logging.basicConfig", "logger.warning", "run_squad.set_seed", "parser.parse_args.model_type.lower", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "logger.info", "os.getenv", "os.path.exists", "os.listdir", "ValueError", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.device_count", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "torch.distributed.barrier", "torch.distributed.barrier", "run_squad.load_and_cache_examples", "run_squad.train", "logger.info", "logger.info", "bool", "logger.info", "model_to_save.save_pretrained", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "model_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained.to", "list", "logging.getLogger().setLevel", "len", "sorted", "sorted.append", "model_class.from_pretrained", "model_class.from_pretrained.to", "global_step.isdigit", "run_squad.evaluate", "logger.info", "dict", "results.update", "torch.distributed.get_rank", "os.makedirs", "hasattr", "os.path.join", "MODEL_CLASSES.keys", "torch.cuda.is_available", "os.path.exists", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "sorted", "int", "dict.items", "glob.glob", "x.split"], "function", ["home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.utils_squad_evaluate.parse_args", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.set_seed", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.load_and_cache_examples", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.train", "home.repos.pwc.inspect_result.Neutralzz_RefQA.uqa.run_squad.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--train_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"SQuAD json for training. E.g., train-v1.1.json\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--predict_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"SQuAD json for predictions. E.g., dev-v1.1.json or test-v1.1.json\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name selected in the list: \"", "+", "\", \"", ".", "join", "(", "ALL_MODELS", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model checkpoints and predictions will be written.\"", ")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--eval_prefix\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Evaluate prefix\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--version_2_with_negative'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'If true, the SQuAD examples contain some that do not have an answer.'", ")", "\n", "parser", ".", "add_argument", "(", "'--null_score_diff_threshold'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "\"If null_score - best_non_null is greater than the threshold predict null.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "default", "=", "384", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after WordPiece tokenization. Sequences \"", "\n", "\"longer than this will be truncated, and sequences shorter than this will be padded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--doc_stride\"", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "\"When splitting up a long document into chunks, how much stride to take between chunks.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_query_length\"", ",", "default", "=", "64", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum number of tokens for the question. Questions longer than this will \"", "\n", "\"be truncated to this length.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Rul evaluation during training at each logging step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--min_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: \"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_best_size\"", ",", "default", "=", "20", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The total number of n-best predictions to generate in the nbest_predictions.json output file.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_answer_length\"", ",", "default", "=", "30", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum length of an answer that can be generated. This is needed because the start \"", "\n", "\"and end predictions are not conditioned on one another.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--verbose_logging\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"If true, all of the warnings related to data processing will be printed. \"", "\n", "\"A number of warnings are expected for a normal SQuAD evaluation.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--few_shot'", ",", "action", "=", "'store_true'", ",", "help", "=", "'few-shot learning'", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_all_checkpoints\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether not to use CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_output_dir'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Overwrite the content of the output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_cache'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"local_rank for distributed training on gpus\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_ip'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"Can be used for distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_port'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"Can be used for distant debugging.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "args", ".", "output_dir", "=", "args", ".", "output_dir", ".", "replace", "(", "\n", "'[PT_OUTPUT_DIR]'", ",", "os", ".", "getenv", "(", "'PT_OUTPUT_DIR'", ",", "''", ")", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "and", "args", ".", "do_train", "and", "not", "args", ".", "overwrite_output_dir", ":", "\n", "        ", "raise", "ValueError", "(", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "args", ".", "output_dir", ")", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "", "if", "args", ".", "few_shot", ":", "\n", "        ", "args", ".", "save_steps", "=", "64", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s -   %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "warning", "(", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "args", ".", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "from_tf", "=", "bool", "(", "'.ckpt'", "in", "args", ".", "model_name_or_path", ")", ",", "config", "=", "config", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ",", "output_examples", "=", "False", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "\n", "# Save the trained model and the tokenizer", "\n", "if", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "# Create output directory if needed", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "                ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "\n", "# Evaluation - we can ask to evaluate all the checkpoints (sub-directories) in a directory", "\n", "", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce model loading logs", "\n", "\n", "", "if", "len", "(", "checkpoints", ")", ">", "1", ":", "\n", "            ", "final_model", "=", "checkpoints", "[", "-", "1", "]", "\n", "checkpoints", "=", "checkpoints", "[", ":", "-", "1", "]", "\n", "#print(checkpoints)", "\n", "checkpoints", "=", "sorted", "(", "checkpoints", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", ")", ")", "\n", "checkpoints", ".", "append", "(", "final_model", ")", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "# Reload the model", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# Evaluate", "\n", "if", "global_step", ".", "isdigit", "(", ")", ":", "\n", "                ", "global_step", "=", "args", ".", "eval_prefix", "+", "global_step", "\n", "", "else", ":", "\n", "                ", "global_step", "=", "args", ".", "eval_prefix", "\n", "", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "global_step", ")", "\n", "logger", ".", "info", "(", "\"Step {}, Result {}\"", ".", "format", "(", "global_step", ",", "result", ")", ")", "\n", "\n", "result", "=", "dict", "(", "(", "k", "+", "(", "'_{}'", ".", "format", "(", "global_step", ")", "if", "global_step", "else", "''", ")", ",", "v", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"Results: {}\"", ".", "format", "(", "results", ")", ")", "\n", "\n", "return", "results", "\n", "\n"]]}