{"home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper.__init__": [[53, 70], ["pytorch_lightning.LightningModule.__init__", "transformers.MT5Tokenizer.from_pretrained", "main.ModelWrapper.add_special_tokens", "sacrebleu.metrics.BLEU", "utils.get_language_normalizer", "main.ModelWrapper.model.resize_token_embeddings", "transformers.MT5ForConditionalGeneration.from_pretrained", "transformers.MT5ForConditionalGeneration.from_config", "len", "transformers.MT5ForConditionalGeneration.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf.__init__", "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper.add_special_tokens", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.get_language_normalizer"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "ModelWrapper", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "step_loss_labels", "=", "{", "'train'", ":", "'loss'", ",", "'val'", ":", "'val_loss'", ",", "'test'", ":", "'test_loss'", "}", "\n", "self", ".", "config_args", "=", "args", "\n", "self", ".", "tokenizer", "=", "MT5Tokenizer", ".", "from_pretrained", "(", "args", ".", "model_name", ",", "cache_dir", "=", "\"/tmp/hugginface\"", ")", "\n", "self", ".", "add_special_tokens", "(", ")", "\n", "self", ".", "cal_bleu", "=", "BLEU", "(", "tokenize", "=", "'none'", ")", "\n", "self", ".", "lang_normalizer", "=", "get_language_normalizer", "(", ")", "\n", "\n", "if", "args", ".", "use_pretrained", ":", "\n", "# using pretrained transformers", "\n", "            ", "self", ".", "model", "=", "MT5ForConditionalGeneration", ".", "from_pretrained", "(", "args", ".", "model_name", ",", "dropout_rate", "=", "args", ".", "dropout_rate", ",", "cache_dir", "=", "\"/tmp/hugginface\"", ")", "\n", "", "else", ":", "\n", "# training transformer from scratch", "\n", "            ", "self", ".", "model", "=", "MT5ForConditionalGeneration", ".", "from_config", "(", "MT5ForConditionalGeneration", ".", "from_pretrained", "(", "\n", "args", ".", "model_name", ",", "dropout_rate", "=", "args", ".", "dropout_rate", ",", "cache_dir", "=", "\"/tmp/hugginface\"", ")", ")", "\n", "", "self", ".", "model", ".", "resize_token_embeddings", "(", "len", "(", "self", ".", "tokenizer", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper.add_special_tokens": [[71, 79], ["enumerate", "main.ModelWrapper.tokenizer.add_special_tokens", "main.ModelWrapper.config_args.logger.critical", "new_tokens_vocab[].append"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper.add_special_tokens", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.critical"], ["", "def", "add_special_tokens", "(", "self", ")", ":", "\n", "        ", "new_tokens", "=", "[", "'<H>'", ",", "'<R>'", ",", "'<T>'", ",", "'<QR>'", ",", "'<QT>'", ",", "'<S>'", "]", "\n", "new_tokens_vocab", "=", "{", "}", "\n", "new_tokens_vocab", "[", "'additional_special_tokens'", "]", "=", "[", "]", "\n", "for", "idx", ",", "t", "in", "enumerate", "(", "new_tokens", ")", ":", "\n", "            ", "new_tokens_vocab", "[", "'additional_special_tokens'", "]", ".", "append", "(", "t", ")", "\n", "", "num_added_toks", "=", "self", ".", "tokenizer", ".", "add_special_tokens", "(", "new_tokens_vocab", ")", "\n", "self", ".", "config_args", ".", "logger", ".", "critical", "(", "'added %s tokens'", "%", "num_added_toks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper.forward": [[80, 88], ["main.ModelWrapper.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "decoder_input_ids", "=", "None", ",", "decoder_attention_mask", "=", "None", ",", "lm_labels", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "model", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "labels", "=", "lm_labels", ",", "\n", "decoder_attention_mask", "=", "decoder_attention_mask", "\n", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper.configure_optimizers": [[89, 115], ["transformers.Adafactor", "int", "numpy.ceil", "transformers.get_linear_schedule_with_warmup", "main.ModelWrapper.named_parameters", "main.ModelWrapper.named_parameters", "any", "any"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "        ", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "self", ".", "config_args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "\n", "optimizer", "=", "Adafactor", "(", "optimizer_grouped_parameters", ",", "lr", "=", "self", ".", "config_args", ".", "learning_rate", ",", "scale_parameter", "=", "False", ",", "relative_step", "=", "False", ",", "warmup_init", "=", "False", ")", "\n", "# optimizer = torch.optim.Adam(optimizer_grouped_parameters, lr=self.config_args.learning_rate, eps=1e-6)", "\n", "\n", "if", "self", ".", "config_args", ".", "enable_scheduler", ":", "\n", "            ", "total_dataset_count", "=", "self", ".", "config_args", ".", "train_dataset_count", "\n", "total_steps", "=", "int", "(", "np", ".", "ceil", "(", "(", "self", ".", "config_args", ".", "epochs", "*", "total_dataset_count", ")", "/", "\n", "(", "self", ".", "config_args", ".", "batch_size", "*", "self", ".", "config_args", ".", "gpus", ")", ")", ")", "\n", "\n", "scheduler", "=", "{", "\n", "# 'scheduler': get_constant_schedule_with_warmup(optimizer, self.config_args.warmup_steps*total_steps)", "\n", "'scheduler'", ":", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "self", ".", "config_args", ".", "warmup_steps", "*", "total_steps", ",", "total_steps", ")", ",", "\n", "'interval'", ":", "'step'", ",", "\n", "}", "\n", "return", "[", "optimizer", "]", ",", "[", "scheduler", "]", "\n", "\n", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper.ids_to_clean_text": [[116, 121], ["main.ModelWrapper.tokenizer.batch_decode", "list", "map"], "methods", ["None"], ["", "def", "ids_to_clean_text", "(", "self", ",", "generated_ids", ",", "remove_special_tokens", "=", "True", ",", "remove_tok_spaces", "=", "True", ")", ":", "\n", "        ", "gen_text", "=", "self", ".", "tokenizer", ".", "batch_decode", "(", "\n", "generated_ids", ",", "skip_special_tokens", "=", "remove_special_tokens", ",", "clean_up_tokenization_spaces", "=", "remove_tok_spaces", "\n", ")", "\n", "return", "list", "(", "map", "(", "str", ".", "strip", ",", "gen_text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper._generative_step": [[122, 135], ["main.ModelWrapper.model.generate", "main.ModelWrapper.ids_to_clean_text", "main.ModelWrapper.ids_to_clean_text"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper.ids_to_clean_text", "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper.ids_to_clean_text"], ["", "def", "_generative_step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "generated_ids", "=", "self", ".", "model", ".", "generate", "(", "\n", "batch", "[", "0", "]", ",", "\n", "attention_mask", "=", "batch", "[", "1", "]", ",", "\n", "use_cache", "=", "True", ",", "\n", "num_beams", "=", "self", ".", "config_args", ".", "eval_beams", ",", "\n", "max_length", "=", "self", ".", "config_args", ".", "tgt_max_seq_len", ",", "\n", "length_penalty", "=", "self", ".", "config_args", ".", "length_penalty", ",", "\n", ")", "\n", "\n", "preds", "=", "self", ".", "ids_to_clean_text", "(", "generated_ids", ")", "\n", "target", "=", "self", ".", "ids_to_clean_text", "(", "batch", "[", "2", "]", ")", "\n", "return", "{", "'predicted_txt'", ":", "preds", ",", "'target_txt'", ":", "target", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper._recover_input_text": [[136, 148], ["main.ModelWrapper.ids_to_clean_text", "range", "len", "re.sub.strip", "re.sub"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper.ids_to_clean_text"], ["", "def", "_recover_input_text", "(", "self", ",", "input_ids", ")", ":", "\n", "        ", "input_txt", "=", "self", ".", "ids_to_clean_text", "(", "input_ids", ",", "remove_special_tokens", "=", "False", ")", "\n", "processed_input_ids", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "input_txt", ")", ")", ":", "\n", "            ", "final_str", "=", "input_txt", "[", "i", "]", "\n", "# removing model's default special token", "\n", "for", "special_token", "in", "[", "self", ".", "tokenizer", ".", "eos_token", ",", "self", ".", "tokenizer", ".", "pad_token", "]", ":", "\n", "                ", "if", "not", "special_token", ":", "\n", "                    ", "continue", "\n", "", "final_str", "=", "re", ".", "sub", "(", "special_token", ",", "''", ",", "final_str", ")", "\n", "", "input_txt", "[", "i", "]", "=", "final_str", ".", "strip", "(", ")", "\n", "", "return", "input_txt", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper._step": [[149, 173], ["torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "main.ModelWrapper.", "return_map.update", "online_logger_data.update", "main.ModelWrapper.logger.log_metrics", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "return_map.update", "return_map.update", "return_map.update", "return_map.update", "main.ModelWrapper._generative_step", "len", "main.ModelWrapper._recover_input_text", "batch[].cpu().detach().tolist", "batch[].cpu().detach().tolist", "batch[].cpu().detach", "batch[].cpu().detach", "batch[].cpu", "batch[].cpu"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper._generative_step", "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper._recover_input_text"], ["", "def", "_step", "(", "self", ",", "batch", ",", "step_type", ")", ":", "\n", "        ", "lm_labels", "=", "torch", ".", "clone", "(", "batch", "[", "2", "]", ")", "\n", "lm_labels", "[", "lm_labels", "[", ":", ",", ":", "]", "==", "self", ".", "tokenizer", ".", "pad_token_id", "]", "=", "-", "100", "\n", "outputs", "=", "self", "(", "\n", "batch", "[", "0", "]", ",", "\n", "attention_mask", "=", "batch", "[", "1", "]", ",", "\n", "lm_labels", "=", "lm_labels", ",", "\n", "decoder_attention_mask", "=", "batch", "[", "3", "]", "\n", ")", "\n", "return_map", "=", "{", "}", "\n", "online_logger_data", "=", "{", "}", "\n", "return_map", ".", "update", "(", "{", "self", ".", "step_loss_labels", "[", "step_type", "]", ":", "outputs", "[", "0", "]", "}", ")", "\n", "# updating the online logger", "\n", "online_logger_data", ".", "update", "(", "return_map", ")", "\n", "# inserting the predictions and actual text for validation and testing dataset when executing bi-lingual training", "\n", "# inserting the predictions and actual text for test dataset only when executing multi-lingual training", "\n", "if", "step_type", "!=", "'train'", "and", "(", "(", "len", "(", "self", ".", "config_args", ".", "lang", ")", "==", "1", "and", "self", ".", "config_args", ".", "enable_bleu_cal_per_epoch", "==", "1", ")", "or", "step_type", "==", "'test'", ")", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "return_map", ".", "update", "(", "self", ".", "_generative_step", "(", "batch", ")", ")", "\n", "return_map", ".", "update", "(", "{", "'source_txt'", ":", "self", ".", "_recover_input_text", "(", "batch", "[", "0", "]", ")", "}", ")", "\n", "return_map", ".", "update", "(", "{", "'lang_id'", ":", "batch", "[", "4", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "tolist", "(", ")", "}", ")", "\n", "return_map", ".", "update", "(", "{", "'seq_id'", ":", "batch", "[", "5", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "tolist", "(", ")", "}", ")", "\n", "", "", "self", ".", "logger", ".", "log_metrics", "(", "online_logger_data", ")", "\n", "return", "return_map", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper._preprocess_text": [[174, 184], ["utils.get_native_text_from_unified_script.strip", "utils.get_native_text_from_unified_script", "utils.get_native_text_from_unified_script.split"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.utils.get_native_text_from_unified_script"], ["", "def", "_preprocess_text", "(", "self", ",", "text", ",", "lang", ")", ":", "\n", "        ", "native_text", "=", "text", "\n", "if", "self", ".", "config_args", ".", "enable_script_unification", ">", "0", "and", "lang", "!=", "'en'", ":", "\n", "# convert unified script to native langauge text", "\n", "            ", "native_text", "=", "get_native_text_from_unified_script", "(", "text", ",", "lang", ")", "\n", "\n", "", "native_text", "=", "native_text", ".", "strip", "(", ")", "\n", "# as input and predicted text are already space tokenized", "\n", "native_text", "=", "' '", ".", "join", "(", "[", "x", "for", "x", "in", "native_text", ".", "split", "(", ")", "]", ")", "\n", "return", "native_text", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper._epoch_end": [[185, 252], ["torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "main.ModelWrapper.config_args.logger.info", "main.ModelWrapper.logger.log_metrics", "main.ModelWrapper.log", "utils.get_id_to_lang", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "src_txt.extend", "pred_txt.extend", "ref_txt.extend", "lang_info.extend", "seq_id.extend", "main.ModelWrapper._preprocess_text", "main.ModelWrapper._preprocess_text", "utils.store_txt", "main.ModelWrapper.cal_bleu.corpus_score", "main.ModelWrapper.config_args.logger.info", "list", "main.ModelWrapper.logger.log_metrics", "main.ModelWrapper.log", "collections.defaultdict", "zip", "collections.defaultdict.items", "zip", "zip", "utils.store_txt", "utils.store_txt", "os.path.join", "len", "map", "[].append", "[].append", "main.ModelWrapper.cal_bleu.corpus_score", "main.ModelWrapper.config_args.logger.info", "list", "main.ModelWrapper.logger.log_metrics", "main.ModelWrapper.log", "torch.stack().mean.item", "torch.stack().mean.item", "torch.stack().mean.item", "len", "os.path.join", "os.path.join", "main.ModelWrapper.prec_str.split", "map", "len", "main.ModelWrapper.prec_str.split"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.utils.get_id_to_lang", "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper._preprocess_text", "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper._preprocess_text", "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.utils.store_txt", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.utils.store_txt", "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.utils.store_txt", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info"], ["", "def", "_epoch_end", "(", "self", ",", "step_outputs", ",", "end_type", ")", ":", "\n", "        ", "loss_label", "=", "self", ".", "step_loss_labels", "[", "end_type", "]", "\n", "avg_loss", "=", "torch", ".", "stack", "(", "[", "x", "[", "loss_label", "]", "for", "x", "in", "step_outputs", "]", ")", ".", "mean", "(", ")", "\n", "if", "end_type", "!=", "'train'", "and", "(", "(", "len", "(", "self", ".", "config_args", ".", "lang", ")", "==", "1", "and", "self", ".", "config_args", ".", "enable_bleu_cal_per_epoch", "==", "1", ")", "or", "end_type", "==", "'test'", ")", ":", "\n", "            ", "id_to_lang", "=", "get_id_to_lang", "(", ")", "\n", "src_txt", "=", "[", "]", "\n", "pred_txt", "=", "[", "]", "\n", "ref_txt", "=", "[", "]", "\n", "lang_info", "=", "[", "]", "\n", "seq_id", "=", "[", "]", "\n", "for", "z", "in", "step_outputs", ":", "\n", "                ", "src_txt", ".", "extend", "(", "z", "[", "'source_txt'", "]", ")", "\n", "pred_txt", ".", "extend", "(", "z", "[", "'predicted_txt'", "]", ")", "\n", "ref_txt", ".", "extend", "(", "z", "[", "'target_txt'", "]", ")", "\n", "lang_info", ".", "extend", "(", "[", "id_to_lang", "[", "u", "]", "for", "u", "in", "z", "[", "'lang_id'", "]", "]", ")", "\n", "seq_id", ".", "extend", "(", "z", "[", "'seq_id'", "]", ")", "\n", "# normalizing and tokenizing using indic_tokenize", "\n", "", "pred_txt", "=", "[", "self", ".", "_preprocess_text", "(", "x", ",", "l", ")", "for", "x", ",", "l", "in", "zip", "(", "pred_txt", ",", "lang_info", ")", "]", "\n", "ref_txt", "=", "[", "self", ".", "_preprocess_text", "(", "x", ",", "l", ")", "for", "x", ",", "l", "in", "zip", "(", "ref_txt", ",", "lang_info", ")", "]", "\n", "\n", "# visual model prediction on wandb", "\n", "if", "self", ".", "config_args", ".", "verbose", "and", "(", "(", "len", "(", "self", ".", "config_args", ".", "lang", ")", "==", "1", "and", "self", ".", "config_args", ".", "enable_bleu_cal_per_epoch", "==", "1", ")", "or", "end_type", "==", "'test'", ")", ":", "\n", "                ", "if", "self", ".", "current_epoch", "==", "0", "or", "end_type", "==", "'test'", ":", "\n", "# writing the model generated outputs", "\n", "                    ", "store_txt", "(", "src_txt", ",", "os", ".", "path", ".", "join", "(", "self", ".", "config_args", ".", "verbose_output_dir", ",", "'%s-src.txt'", "%", "end_type", ")", ")", "\n", "store_txt", "(", "ref_txt", ",", "os", ".", "path", ".", "join", "(", "self", ".", "config_args", ".", "verbose_output_dir", ",", "'%s-ref.txt'", "%", "end_type", ")", ")", "\n", "", "store_txt", "(", "pred_txt", ",", "os", ".", "path", ".", "join", "(", "self", ".", "config_args", ".", "verbose_output_dir", ",", "'%s-predicted-epoch-%d.txt'", "%", "(", "end_type", ",", "self", ".", "current_epoch", ")", ")", ")", "\n", "\n", "# calculating the bleu score", "\n", "", "if", "(", "len", "(", "self", ".", "config_args", ".", "lang", ")", "==", "1", "and", "self", ".", "config_args", ".", "enable_bleu_cal_per_epoch", "==", "1", ")", ":", "\n", "# handling bilingual setting", "\n", "                ", "bleu", "=", "self", ".", "cal_bleu", ".", "corpus_score", "(", "pred_txt", ",", "[", "ref_txt", "]", ")", "\n", "self", ".", "config_args", ".", "logger", ".", "info", "(", "\"epoch : %d | %s\"", "%", "(", "self", ".", "current_epoch", ",", "bleu", ")", ")", "\n", "bleu_list", "=", "list", "(", "map", "(", "float", ",", "bleu", ".", "prec_str", ".", "split", "(", "'/'", ")", ")", ")", "\n", "self", ".", "logger", ".", "log_metrics", "(", "{", "\n", "'overall_%s_bleu'", "%", "end_type", ":", "bleu", ".", "score", ",", "\n", "'%s_bleu_1'", "%", "end_type", ":", "bleu_list", "[", "0", "]", ",", "\n", "'%s_bleu_2'", "%", "end_type", ":", "bleu_list", "[", "1", "]", ",", "\n", "'%s_bleu_3'", "%", "end_type", ":", "bleu_list", "[", "2", "]", ",", "\n", "'%s_bleu_4'", "%", "end_type", ":", "bleu_list", "[", "3", "]", "\n", "}", ")", "\n", "self", ".", "log", "(", "'overall_%s_bleu'", "%", "end_type", ",", "bleu", ".", "score", ",", "prog_bar", "=", "True", ")", "\n", "", "else", ":", "\n", "# handling multilingual setting", "\n", "                ", "language_specific_inout", "=", "defaultdict", "(", "lambda", ":", "{", "'pred'", ":", "[", "]", ",", "'ref'", ":", "[", "]", "}", ")", "\n", "for", "lpred", ",", "lref", ",", "llang", "in", "zip", "(", "pred_txt", ",", "ref_txt", ",", "lang_info", ")", ":", "\n", "                    ", "language_specific_inout", "[", "llang", "]", "[", "'pred'", "]", ".", "append", "(", "lpred", ")", "\n", "language_specific_inout", "[", "llang", "]", "[", "'ref'", "]", ".", "append", "(", "lref", ")", "\n", "\n", "", "for", "klang", ",", "vdata", "in", "language_specific_inout", ".", "items", "(", ")", ":", "\n", "                    ", "bleu", "=", "self", ".", "cal_bleu", ".", "corpus_score", "(", "vdata", "[", "'pred'", "]", ",", "[", "vdata", "[", "'ref'", "]", "]", ")", "\n", "self", ".", "config_args", ".", "logger", ".", "info", "(", "\"%s : epoch : %d | %s\"", "%", "(", "klang", ",", "self", ".", "current_epoch", ",", "bleu", ")", ")", "\n", "bleu_list", "=", "list", "(", "map", "(", "float", ",", "bleu", ".", "prec_str", ".", "split", "(", "'/'", ")", ")", ")", "\n", "self", ".", "logger", ".", "log_metrics", "(", "{", "\n", "'%s_overall_%s_bleu'", "%", "(", "klang", ",", "end_type", ")", ":", "bleu", ".", "score", ",", "\n", "'%s_%s_bleu_1'", "%", "(", "klang", ",", "end_type", ")", ":", "bleu_list", "[", "0", "]", ",", "\n", "'%s_%s_bleu_2'", "%", "(", "klang", ",", "end_type", ")", ":", "bleu_list", "[", "1", "]", ",", "\n", "'%s_%s_bleu_3'", "%", "(", "klang", ",", "end_type", ")", ":", "bleu_list", "[", "2", "]", ",", "\n", "'%s_%s_bleu_4'", "%", "(", "klang", ",", "end_type", ")", ":", "bleu_list", "[", "3", "]", "\n", "}", ")", "\n", "self", ".", "log", "(", "'%s_overall_%s_bleu'", "%", "(", "klang", ",", "end_type", ")", ",", "bleu", ".", "score", ",", "prog_bar", "=", "False", ")", "\n", "\n", "", "", "", "self", ".", "config_args", ".", "logger", ".", "info", "(", "'epoch : %d - average_%s_loss : %f'", "%", "(", "self", ".", "current_epoch", ",", "end_type", ",", "avg_loss", ".", "item", "(", ")", ")", ")", "\n", "# logging to weight and bias if online mode is enabled", "\n", "self", ".", "logger", ".", "log_metrics", "(", "\n", "{", "'avg_%s_loss'", "%", "end_type", ":", "avg_loss", "}", ")", "\n", "self", ".", "log", "(", "'avg_%s_loss'", "%", "end_type", ",", "avg_loss", ",", "prog_bar", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper.training_step": [[253, 255], ["main.ModelWrapper._step"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper._step"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "return", "self", ".", "_step", "(", "batch", ",", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper.training_epoch_end": [[256, 258], ["main.ModelWrapper._epoch_end"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper._epoch_end"], ["", "def", "training_epoch_end", "(", "self", ",", "train_step_outputs", ")", ":", "\n", "        ", "self", ".", "_epoch_end", "(", "train_step_outputs", ",", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper.validation_step": [[259, 261], ["main.ModelWrapper._step"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper._step"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "return", "self", ".", "_step", "(", "batch", ",", "'val'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper.validation_epoch_end": [[262, 264], ["main.ModelWrapper._epoch_end"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper._epoch_end"], ["", "def", "validation_epoch_end", "(", "self", ",", "val_step_outputs", ")", ":", "\n", "        ", "self", ".", "_epoch_end", "(", "val_step_outputs", ",", "'val'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper.test_step": [[265, 267], ["main.ModelWrapper._step"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper._step"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "return", "self", ".", "_step", "(", "batch", ",", "'test'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper.test_epoch_end": [[268, 270], ["main.ModelWrapper._epoch_end"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper._epoch_end"], ["", "def", "test_epoch_end", "(", "self", ",", "test_step_outputs", ")", ":", "\n", "        ", "self", ".", "_epoch_end", "(", "test_step_outputs", ",", "'test'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper._intiate_dataset_merging": [[271, 281], ["logger.critical", "os.path.join", "os.makedirs", "utils.dataset_exists", "os.path.abspath", "logger.info", "utils.merge_dataset_across_languages", "os.path.join", "len"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.critical", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.dataset_exists", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.merge_dataset_across_languages"], ["", "def", "_intiate_dataset_merging", "(", "self", ",", "dataset_type", ",", "dataset_dir", ",", "languages", ",", "logger", ")", ":", "\n", "        ", "logger", ".", "critical", "(", "'%s: merging the %d %s different languages dataset'", "%", "(", "dataset_type", ",", "len", "(", "languages", ")", ",", "languages", ")", ")", "\n", "final_dir_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "dataset_dir", ")", ",", "'-'", ".", "join", "(", "languages", ")", ")", "\n", "os", ".", "makedirs", "(", "final_dir_path", ",", "exist_ok", "=", "True", ")", "\n", "# check if dataset already exists", "\n", "if", "dataset_exists", "(", "final_dir_path", ",", "required_files", "=", "[", "'%s.jsonl'", "%", "dataset_type", "]", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"%s dataset is already present.\"", "%", "dataset_type", ")", "\n", "", "else", ":", "\n", "            ", "merge_dataset_across_languages", "(", "dataset_dir", ",", "languages", ",", "dataset_type", ",", "os", ".", "path", ".", "join", "(", "final_dir_path", ",", "\"%s.jsonl\"", "%", "dataset_type", ")", ")", "\n", "", "return", "final_dir_path", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper.val_dataloader": [[282, 298], ["dataloader.get_dataset_loaders", "len", "os.path.join", "main.ModelWrapper._intiate_dataset_merging", "os.path.join", "os.path.abspath", "os.path.abspath"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.get_dataset_loaders", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.TextDataModule._intiate_dataset_merging"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "script_unification", "=", "self", ".", "config_args", ".", "enable_script_unification", ">", "0", "\n", "coverage_flag", "=", "self", ".", "config_args", ".", "complete_coverage", ">", "0", "\n", "if", "len", "(", "self", ".", "config_args", ".", "lang", ")", "==", "1", ":", "\n", "            ", "enable_prefix", "=", "False", "\n", "dev_file_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "self", ".", "config_args", ".", "dataset_path", ")", ",", "self", ".", "config_args", ".", "lang", "[", "0", "]", ",", "'val.jsonl'", ")", "\n", "", "else", ":", "\n", "            ", "enable_prefix", "=", "True", "\n", "merged_directory", "=", "self", ".", "_intiate_dataset_merging", "(", "'val'", ",", "self", ".", "config_args", ".", "dataset_path", ",", "self", ".", "config_args", ".", "lang", ",", "\n", "self", ".", "config_args", ".", "logger", ")", "\n", "dev_file_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "merged_directory", ")", ",", "'val.jsonl'", ")", "\n", "", "val_dataset", "=", "get_dataset_loaders", "(", "self", ".", "tokenizer", ",", "dev_file_path", ",", "self", ".", "config_args", ".", "logger", ",", "dataset_count", "=", "self", ".", "config_args", ".", "val_dataset_count", ",", "\n", "batch_size", "=", "self", ".", "config_args", ".", "eval_batch_size", ",", "src_max_seq_len", "=", "self", ".", "config_args", ".", "src_max_seq_len", ",", "\n", "tgt_max_seq_len", "=", "self", ".", "config_args", ".", "tgt_max_seq_len", ",", "script_unification", "=", "script_unification", ",", "prefix", "=", "enable_prefix", ",", "\n", "complete_coverage", "=", "coverage_flag", ")", "\n", "return", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper.train_dataloader": [[299, 315], ["dataloader.get_dataset_loaders", "len", "os.path.join", "main.ModelWrapper._intiate_dataset_merging", "os.path.join", "os.path.abspath", "os.path.abspath"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.get_dataset_loaders", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.TextDataModule._intiate_dataset_merging"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "script_unification", "=", "self", ".", "config_args", ".", "enable_script_unification", ">", "0", "\n", "coverage_flag", "=", "self", ".", "config_args", ".", "complete_coverage", ">", "0", "\n", "if", "len", "(", "self", ".", "config_args", ".", "lang", ")", "==", "1", ":", "\n", "            ", "enable_prefix", "=", "False", "\n", "train_file_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "self", ".", "config_args", ".", "dataset_path", ")", ",", "self", ".", "config_args", ".", "lang", "[", "0", "]", ",", "'train.jsonl'", ")", "\n", "", "else", ":", "\n", "            ", "enable_prefix", "=", "True", "\n", "merged_directory", "=", "self", ".", "_intiate_dataset_merging", "(", "'train'", ",", "self", ".", "config_args", ".", "dataset_path", ",", "self", ".", "config_args", ".", "lang", ",", "\n", "self", ".", "config_args", ".", "logger", ")", "\n", "train_file_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "merged_directory", ")", ",", "'train.jsonl'", ")", "\n", "", "train_dataset", "=", "get_dataset_loaders", "(", "self", ".", "tokenizer", ",", "train_file_path", ",", "self", ".", "config_args", ".", "logger", ",", "dataset_count", "=", "self", ".", "config_args", ".", "train_dataset_count", ",", "\n", "batch_size", "=", "self", ".", "config_args", ".", "batch_size", ",", "src_max_seq_len", "=", "self", ".", "config_args", ".", "src_max_seq_len", ",", "\n", "tgt_max_seq_len", "=", "self", ".", "config_args", ".", "tgt_max_seq_len", ",", "script_unification", "=", "script_unification", ",", "prefix", "=", "enable_prefix", ",", "\n", "complete_coverage", "=", "coverage_flag", ")", "\n", "return", "train_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.ModelWrapper.test_dataloader": [[316, 330], ["dataloader.get_dataset_loaders", "len", "os.path.join", "main.ModelWrapper._intiate_dataset_merging", "os.path.join", "os.path.abspath", "os.path.abspath"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.get_dataset_loaders", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.TextDataModule._intiate_dataset_merging"], ["", "def", "test_dataloader", "(", "self", ")", ":", "\n", "        ", "script_unification", "=", "self", ".", "config_args", ".", "enable_script_unification", ">", "0", "\n", "if", "len", "(", "self", ".", "config_args", ".", "lang", ")", "==", "1", ":", "\n", "            ", "enable_prefix", "=", "False", "\n", "test_file_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "self", ".", "config_args", ".", "dataset_path", ")", ",", "self", ".", "config_args", ".", "lang", "[", "0", "]", ",", "'test.jsonl'", ")", "\n", "", "else", ":", "\n", "            ", "enable_prefix", "=", "True", "\n", "merged_directory", "=", "self", ".", "_intiate_dataset_merging", "(", "'test'", ",", "self", ".", "config_args", ".", "dataset_path", ",", "self", ".", "config_args", ".", "lang", ",", "\n", "self", ".", "config_args", ".", "logger", ")", "\n", "test_file_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "merged_directory", ")", ",", "'test.jsonl'", ")", "\n", "", "test_dataset", "=", "get_dataset_loaders", "(", "self", ".", "tokenizer", ",", "test_file_path", ",", "self", ".", "config_args", ".", "logger", ",", "dataset_count", "=", "self", ".", "config_args", ".", "test_dataset_count", ",", "\n", "batch_size", "=", "self", ".", "config_args", ".", "eval_batch_size", ",", "src_max_seq_len", "=", "self", ".", "config_args", ".", "src_max_seq_len", ",", "\n", "tgt_max_seq_len", "=", "self", ".", "config_args", ".", "tgt_max_seq_len", ",", "script_unification", "=", "script_unification", ",", "prefix", "=", "enable_prefix", ")", "\n", "return", "test_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.random_seed": [[42, 48], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed"], "function", ["None"], ["def", "random_seed", "(", "seed", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.count_parameters": [[49, 51], ["sum", "p.numel", "model.parameters"], "function", ["None"], ["", "def", "count_parameters", "(", "model", ")", ":", "\n", "    ", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.get_checkpoint_file": [[331, 347], ["os.listdir", "logger.info", "sorted", "os.path.getmtime", "sorted.append", "len", "os.path.join", "file_name.endswith", "os.path.join", "len"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info"], ["", "", "def", "get_checkpoint_file", "(", "checkpoint_path", ",", "logger", ")", ":", "\n", "    ", "file_list", "=", "[", "]", "\n", "for", "file_name", "in", "os", ".", "listdir", "(", "checkpoint_path", ")", ":", "\n", "        ", "if", "not", "file_name", ".", "endswith", "(", "'ckpt'", ")", ":", "\n", "            ", "continue", "\n", "", "last_modified_time", "=", "os", ".", "path", ".", "getmtime", "(", "\n", "os", ".", "path", ".", "join", "(", "checkpoint_path", ",", "file_name", ")", ")", "\n", "file_list", ".", "append", "(", "[", "file_name", ",", "last_modified_time", "]", ")", "\n", "\n", "", "logger", ".", "info", "(", "\n", "'total number of files within checkpoint directory [%s]: %d'", "%", "(", "checkpoint_path", ",", "len", "(", "file_list", ")", ")", ")", "\n", "if", "len", "(", "file_list", ")", "==", "0", ":", "\n", "        ", "return", "False", ",", "\"\"", "\n", "# if multiple files exists then choose the last modified checkpoint path", "\n", "", "file_list", "=", "sorted", "(", "file_list", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "return", "True", ",", "os", ".", "path", ".", "join", "(", "checkpoint_path", ",", "file_list", "[", "0", "]", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.main.start_training": [[348, 428], ["args.logger.debug", "os.makedirs", "pytorch_lightning.callbacks.ModelCheckpoint", "pytorch_lightning.callbacks.early_stopping.EarlyStopping", "main.ModelWrapper", "args.logger.debug", "args.logger.info", "main.get_checkpoint_file", "pytorch_lightning.Trainer", "model_name.split", "os.path.join", "os.path.join", "global_callback_params.update", "args.logger.info", "args.logger.debug", "pl.Trainer.test", "args.logger.debug", "args.logger.debug", "pl.Trainer.fit", "args.logger.debug", "main.count_parameters", "args.logger.error", "sys.exit", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.debug", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.debug", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.get_checkpoint_file", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.debug", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.debug", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.debug", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.debug", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.count_parameters", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.error"], ["", "def", "start_training", "(", "args", ")", ":", "\n", "    ", "model_name", "=", "args", ".", "logger_exp_name", "\n", "\n", "args", ".", "logger", ".", "debug", "(", "'initiating training process...'", ")", "\n", "\n", "if", "args", ".", "inference", ":", "\n", "        ", "actual_model_name", "=", "model_name", ".", "split", "(", "'-'", ",", "1", ")", "\n", "final_checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint_path", ",", "actual_model_name", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "        ", "final_checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint_path", ",", "model_name", ")", "\n", "", "os", ".", "makedirs", "(", "final_checkpoint_path", ",", "exist_ok", "=", "True", ")", "\n", "\n", "call_back_parameters", "=", "{", "\n", "'filepath'", ":", "final_checkpoint_path", ",", "\n", "'save_top_k'", ":", "1", ",", "\n", "'verbose'", ":", "True", ",", "\n", "'monitor'", ":", "'overall_val_bleu'", "if", "(", "len", "(", "args", ".", "lang", ")", "==", "1", "and", "args", ".", "enable_bleu_cal_per_epoch", "==", "1", ")", "else", "'avg_val_loss'", ",", "\n", "'mode'", ":", "'max'", "if", "(", "len", "(", "args", ".", "lang", ")", "==", "1", "and", "args", ".", "enable_bleu_cal_per_epoch", "==", "1", ")", "else", "'min'", ",", "\n", "}", "\n", "\n", "# checkpoint callback to used by the Trainer", "\n", "checkpoint_callback", "=", "ModelCheckpoint", "(", "**", "call_back_parameters", ")", "\n", "\n", "# # checkpoint save function for newer version of pytorch lightning  ", "\n", "# # checkpoint callback to used by the Trainer that saves file like: my/path/epoch=02-val_loss=0.32.ckpt", "\n", "# checkpoint_callback = ModelCheckpoint(", "\n", "#     monitor=\"overall_val_bleu\",", "\n", "#     dirpath=final_checkpoint_path,", "\n", "#     filename=\"{epoch:02d}-{val_bleu:.2f}\",", "\n", "#     save_top_k=1,", "\n", "#     mode=\"max\",", "\n", "# )", "\n", "\n", "# early stop callback", "\n", "early_stop_callback", "=", "EarlyStopping", "(", "\n", "monitor", "=", "'overall_val_bleu'", "if", "(", "len", "(", "args", ".", "lang", ")", "==", "1", "and", "args", ".", "enable_bleu_cal_per_epoch", "==", "1", ")", "else", "'avg_val_loss'", ",", "\n", "patience", "=", "args", ".", "patience", ",", "\n", "verbose", "=", "True", ",", "\n", "mode", "=", "'max'", "if", "(", "len", "(", "args", ".", "lang", ")", "==", "1", "and", "args", ".", "enable_bleu_cal_per_epoch", "==", "1", ")", "else", "'min'", ",", "\n", ")", "\n", "\n", "model", "=", "ModelWrapper", "(", "args", ")", "\n", "\n", "args", ".", "logger", ".", "debug", "(", "model", ")", "\n", "args", ".", "logger", ".", "info", "(", "'Model has %d trainable parameters'", "%", "\n", "count_parameters", "(", "model", ")", ")", "\n", "\n", "callback_list", "=", "[", "checkpoint_callback", ",", "early_stop_callback", "]", "\n", "\n", "global_callback_params", "=", "{", "\n", "\"callbacks\"", ":", "callback_list", ",", "\n", "\"max_epochs\"", ":", "args", ".", "epochs", ",", "\n", "\"min_epochs\"", ":", "1", ",", "\n", "\"gradient_clip_val\"", ":", "args", ".", "clip_grad_norm", ",", "\n", "\"gpus\"", ":", "1", "if", "args", ".", "inference", "else", "args", ".", "gpus", ",", "\n", "\"distributed_backend\"", ":", "\"ddp\"", ",", "\n", "\"logger\"", ":", "args", ".", "online_logger", "\n", "}", "\n", "\n", "#checking whether checkpoint already exists or not", "\n", "checkpoint_exists", ",", "checkpoint_file", "=", "get_checkpoint_file", "(", "final_checkpoint_path", ",", "args", ".", "logger", ")", "\n", "if", "checkpoint_exists", ":", "\n", "        ", "global_callback_params", ".", "update", "(", "{", "'resume_from_checkpoint'", ":", "checkpoint_file", "}", ")", "\n", "args", ".", "logger", ".", "info", "(", "'resuming training from checkpoint : %s'", "%", "checkpoint_file", ")", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "**", "global_callback_params", ")", "\n", "if", "args", ".", "inference", ":", "\n", "        ", "if", "not", "checkpoint_exists", ":", "\n", "            ", "args", ".", "logger", ".", "error", "(", "'No checkpoint found in directory : %s'", "%", "final_checkpoint_path", ")", "\n", "sys", ".", "exit", "(", "0", ")", "\n", "", "args", ".", "logger", ".", "debug", "(", "'about to start testing loop...'", ")", "\n", "# change gpus to 1 while testing", "\n", "trainer", ".", "gpus", "=", "1", "\n", "trainer", ".", "test", "(", "model", "=", "model", ",", "ckpt_path", "=", "checkpoint_file", ")", "\n", "args", ".", "logger", ".", "debug", "(", "'testing done.'", ")", "\n", "", "else", ":", "\n", "# finally train the model", "\n", "        ", "args", ".", "logger", ".", "debug", "(", "'about to start training loop...'", ")", "\n", "trainer", ".", "fit", "(", "model", ")", "\n", "args", ".", "logger", ".", "debug", "(", "'training done.'", ")", "\n", "# args.logger.debug('about to start testing loop...')", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.logger.LOG_LEVELS.get_name": [[14, 28], ["None"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "get_name", "(", "level", ")", ":", "\n", "        ", "if", "level", "==", "1", ":", "\n", "            ", "return", "'DEBUG'", "\n", "", "elif", "level", "==", "2", ":", "\n", "            ", "return", "'INFO'", "\n", "", "elif", "level", "==", "3", ":", "\n", "            ", "return", "'WARN'", "\n", "", "elif", "level", "==", "4", ":", "\n", "            ", "return", "'CRITICAL'", "\n", "", "elif", "level", "==", "5", ":", "\n", "            ", "return", "'ERROR'", "\n", "", "else", ":", "\n", "            ", "return", "'UNKNOWN'", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.logger.MyLogger.__init__": [[30, 40], ["open"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "log_file_path", ",", "use_stdout", "=", "False", ",", "overwrite", "=", "True", ",", "log_level", "=", "LOG_LEVELS", ".", "DEBUG", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "log_file_path", "=", "log_file_path", "\n", "self", ".", "stdout", "=", "use_stdout", "\n", "self", ".", "level", "=", "log_level", "\n", "#only zero rank process can truncate the file", "\n", "if", "overwrite", "and", "rank_zero_only", ".", "rank", "==", "0", ":", "\n", "#truncate the file", "\n", "            ", "with", "open", "(", "self", ".", "log_file_path", ",", "'w'", ")", "as", "log_file", ":", "\n", "                ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.logger.MyLogger._log_msg": [[41, 50], ["datetime.datetime.datetime.now", "print", "open", "log_file.write", "datetime.datetime.now.strftime", "logger.LOG_LEVELS.get_name", "os.path.abspath"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.LOG_LEVELS.get_name"], ["", "", "", "@", "rank_zero_only", "\n", "def", "_log_msg", "(", "self", ",", "msg", ",", "level", ")", ":", "\n", "        ", "if", "level", ">=", "self", ".", "level", ":", "\n", "            ", "present_time", "=", "datetime", ".", "now", "(", ")", "\n", "msg_str", "=", "'%s [%s] %s'", "%", "(", "present_time", ".", "strftime", "(", "'%m/%d/%Y %I:%M:%S %p'", ")", ",", "LOG_LEVELS", ".", "get_name", "(", "level", ")", ",", "msg", ")", "\n", "if", "self", ".", "stdout", ":", "\n", "                ", "print", "(", "msg_str", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "abspath", "(", "self", ".", "log_file_path", ")", ",", "'a+'", ")", "as", "log_file", ":", "\n", "                ", "log_file", ".", "write", "(", "msg_str", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.logger.MyLogger.info": [[51, 54], ["logger.MyLogger._log_msg"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger._log_msg"], ["", "", "", "@", "rank_zero_only", "\n", "def", "info", "(", "self", ",", "msg", ")", ":", "\n", "        ", "self", ".", "_log_msg", "(", "msg", ",", "LOG_LEVELS", ".", "INFO", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.logger.MyLogger.critical": [[55, 58], ["logger.MyLogger._log_msg"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger._log_msg"], ["", "@", "rank_zero_only", "\n", "def", "critical", "(", "self", ",", "msg", ")", ":", "\n", "        ", "self", ".", "_log_msg", "(", "msg", ",", "LOG_LEVELS", ".", "CRITICAL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.logger.MyLogger.debug": [[59, 62], ["logger.MyLogger._log_msg"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger._log_msg"], ["", "@", "rank_zero_only", "\n", "def", "debug", "(", "self", ",", "msg", ")", ":", "\n", "        ", "self", ".", "_log_msg", "(", "msg", ",", "LOG_LEVELS", ".", "DEBUG", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.logger.MyLogger.warn": [[63, 66], ["logger.MyLogger._log_msg"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger._log_msg"], ["", "@", "rank_zero_only", "\n", "def", "warn", "(", "self", ",", "msg", ")", ":", "\n", "        ", "self", ".", "_log_msg", "(", "msg", ",", "LOG_LEVELS", ".", "WARN", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.logger.MyLogger.error": [[67, 70], ["logger.MyLogger._log_msg"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger._log_msg"], ["", "@", "rank_zero_only", "\n", "def", "error", "(", "self", ",", "msg", ")", ":", "\n", "        ", "self", ".", "_log_msg", "(", "msg", ",", "LOG_LEVELS", ".", "ERROR", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.logger.logger_wrapper": [[71, 78], ["isinstance", "os.path.dirname", "os.path.join", "os.makedirs", "logger.MyLogger", "os.path.realpath", "os.path.join"], "function", ["None"], ["", "", "def", "logger_wrapper", "(", "logger", ",", "logger_name", ")", ":", "\n", "    ", "if", "isinstance", "(", "logger", ",", "MyLogger", ")", ":", "\n", "        ", "return", "logger", "\n", "", "base_dir", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "'logs'", ")", "\n", "os", ".", "makedirs", "(", "log_dir", ",", "exist_ok", "=", "True", ")", "\n", "return", "MyLogger", "(", "logger_name", ",", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"%s.log\"", "%", "logger_name", ")", ",", "use_stdout", "=", "True", ",", "overwrite", "=", "True", ")", "", "", ""]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.dataloader.TextDataset.__init__": [[12, 31], ["utils.load_jsonl", "utils.get_language_normalizer", "logger.info", "os.path.basename().split", "logger.critical", "os.path.basename", "len"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.load_jsonl", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.get_language_normalizer", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.critical"], ["    ", "def", "__init__", "(", "self", ",", "prefix", ",", "tokenizer", ",", "filename", ",", "dataset_count", ",", "src_max_seq_len", ",", "tgt_max_seq_len", ",", "script_unification", ",", "logger", ",", "complete_coverage", ",", "sorted_order", "=", "True", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "src_max_seq_len", "=", "src_max_seq_len", "\n", "self", ".", "tgt_max_seq_len", "=", "tgt_max_seq_len", "\n", "self", ".", "dataset", "=", "load_jsonl", "(", "filename", ")", "\n", "if", "complete_coverage", ":", "\n", "            ", "self", ".", "dataset", "=", "[", "x", "for", "x", "in", "self", ".", "dataset", "if", "x", "[", "'complete_coverage'", "]", "==", "1", "]", "\n", "", "self", ".", "logger", "=", "logger", "\n", "self", ".", "prefix", "=", "prefix", "\n", "self", ".", "sorted_order", "=", "sorted_order", "\n", "self", ".", "script_unification", "=", "script_unification", "\n", "self", ".", "lang_normalizer", "=", "get_language_normalizer", "(", ")", "\n", "if", "dataset_count", ">", "0", ":", "\n", "# retain selected dataset count", "\n", "            ", "self", ".", "dataset", "=", "self", ".", "dataset", "[", ":", "dataset_count", "]", "\n", "", "data_type", "=", "os", ".", "path", ".", "basename", "(", "filename", ")", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "if", "self", ".", "script_unification", ":", "\n", "            ", "logger", ".", "critical", "(", "\"%s : script unification to Devanagari is enabled.\"", "%", "data_type", ")", "\n", "", "logger", ".", "info", "(", "\"%s dataset count : %d\"", "%", "(", "data_type", ",", "len", "(", "self", ".", "dataset", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.dataloader.TextDataset.process_facts": [[32, 41], ["range", "sorted", "len", "utils.linear_fact_str", "utils.get_relation().lower", "utils.get_relation"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.linear_fact_str", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.get_relation"], ["", "def", "process_facts", "(", "self", ",", "facts", ")", ":", "\n", "        ", "\"\"\" linearizes the facts on the encoder side \"\"\"", "\n", "if", "self", ".", "sorted_order", ":", "\n", "            ", "facts", "=", "sorted", "(", "facts", ",", "key", "=", "lambda", "x", ":", "get_relation", "(", "x", "[", "0", "]", ")", ".", "lower", "(", ")", ")", "\n", "", "linearized_facts", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "facts", ")", ")", ":", "\n", "            ", "linearized_facts", "+=", "linear_fact_str", "(", "facts", "[", "i", "]", ",", "enable_qualifiers", "=", "True", ")", "\n", "", "processed_facts_str", "=", "' '", ".", "join", "(", "linearized_facts", ")", "\n", "return", "processed_facts_str", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.dataloader.TextDataset.process_text": [[42, 54], ["utils.get_text_in_unified_script", "en_tok.tokenize", "indicnlp.tokenize.indic_tokenize.trivial_tokenize", "dataloader.TextDataset.lang_normalizer[].normalize", "dataloader.TextDataset.lang_normalizer[].normalize", "text.strip", "text.strip"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.utils.get_text_in_unified_script"], ["", "def", "process_text", "(", "self", ",", "text", ",", "lang", ")", ":", "\n", "        ", "\"\"\" normalize and tokenize and then space join the text \"\"\"", "\n", "if", "lang", "==", "'en'", ":", "\n", "            ", "return", "\" \"", ".", "join", "(", "en_tok", ".", "tokenize", "(", "self", ".", "lang_normalizer", "[", "lang", "]", ".", "normalize", "(", "text", ".", "strip", "(", ")", ")", ",", "escape", "=", "False", ")", ")", ".", "strip", "(", ")", "\n", "", "else", ":", "\n", "# return unified script text", "\n", "            ", "if", "self", ".", "script_unification", ":", "\n", "                ", "return", "get_text_in_unified_script", "(", "text", ",", "self", ".", "lang_normalizer", "[", "lang", "]", ",", "lang", ")", "\n", "\n", "# return original text", "\n", "", "return", "\" \"", ".", "join", "(", "\n", "indic_tokenize", ".", "trivial_tokenize", "(", "self", ".", "lang_normalizer", "[", "lang", "]", ".", "normalize", "(", "text", ".", "strip", "(", ")", ")", ",", "lang", ")", "\n", ")", ".", "strip", "(", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.dataloader.TextDataset.preprocess": [[56, 61], ["dataloader.TextDataset.tokenizer.encode_plus"], "methods", ["None"], ["", "", "def", "preprocess", "(", "self", ",", "text", ",", "max_seq_len", ")", ":", "\n", "        ", "tokenzier_args", "=", "{", "'text'", ":", "text", ",", "'truncation'", ":", "True", ",", "'pad_to_max_length'", ":", "False", ",", "\n", "'max_length'", ":", "max_seq_len", ",", "'return_attention_mask'", ":", "True", "}", "\n", "tokenized_data", "=", "self", ".", "tokenizer", ".", "encode_plus", "(", "**", "tokenzier_args", ")", "\n", "return", "tokenized_data", "[", "'input_ids'", "]", ",", "tokenized_data", "[", "'attention_mask'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.dataloader.TextDataset.__getitem__": [[62, 78], ["data_instance[].strip().lower", "dataloader.TextDataset.preprocess", "dataloader.TextDataset.preprocess", "dataloader.TextDataset.process_text", "data_instance[].strip", "[].lower", "data_instance[].lower().strip", "dataloader.TextDataset.process_facts", "section_info.lower().strip", "data_instance[].lower", "section_info.lower"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.TextDataset.preprocess", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.TextDataset.preprocess", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.TextDataset.process_text", "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.dataloader.TextDataset.process_facts"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "prefix_str", "=", "''", "\n", "data_instance", "=", "self", ".", "dataset", "[", "idx", "]", "\n", "lang_iso", "=", "data_instance", "[", "'lang'", "]", ".", "strip", "(", ")", ".", "lower", "(", ")", "\n", "lang_id", "=", "languages_map", "[", "lang_iso", "]", "[", "'id'", "]", "\n", "if", "self", ".", "prefix", ":", "\n", "            ", "prefix_str", "=", "\"generate  %s : \"", "%", "languages_map", "[", "lang_iso", "]", "[", "'label'", "]", ".", "lower", "(", ")", "\n", "# preparing the input", "\n", "", "section_info", "=", "data_instance", "[", "'native_sentence_section'", "]", "if", "lang_iso", "==", "'en'", "else", "data_instance", "[", "'translated_sentence_section'", "]", "\n", "input_str", "=", "\"{prefix}<H> {entity} {triples} <S> {section}\"", ".", "format", "(", "prefix", "=", "prefix_str", ",", "\n", "entity", "=", "data_instance", "[", "'entity_name'", "]", ".", "lower", "(", ")", ".", "strip", "(", ")", ",", "triples", "=", "self", ".", "process_facts", "(", "data_instance", "[", "'facts'", "]", ")", ",", "\n", "section", "=", "section_info", ".", "lower", "(", ")", ".", "strip", "(", ")", ")", "\n", "\n", "src_ids", ",", "src_mask", "=", "self", ".", "preprocess", "(", "input_str", ",", "self", ".", "src_max_seq_len", ")", "\n", "tgt_ids", ",", "tgt_mask", "=", "self", ".", "preprocess", "(", "self", ".", "process_text", "(", "data_instance", "[", "'sentence'", "]", ",", "lang_iso", ")", ",", "self", ".", "tgt_max_seq_len", ")", "\n", "return", "src_ids", ",", "src_mask", ",", "tgt_ids", ",", "tgt_mask", ",", "lang_id", ",", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.dataloader.TextDataset.__len__": [[79, 81], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.dataloader.pad_seq": [[82, 84], ["len"], "function", ["None"], ["", "", "def", "pad_seq", "(", "seq", ",", "max_batch_len", ",", "pad_value", ")", ":", "\n", "    ", "return", "seq", "+", "(", "max_batch_len", "-", "len", "(", "seq", ")", ")", "*", "[", "pad_value", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.dataloader.collate_batch": [[85, 105], ["max", "max", "lang_id.append", "idx.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len", "dataloader.pad_seq", "dataloader.pad_seq", "dataloader.pad_seq", "dataloader.pad_seq"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.pad_seq", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.pad_seq", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.pad_seq", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.pad_seq"], ["", "def", "collate_batch", "(", "batch", ",", "tokenizer", ")", ":", "\n", "    ", "batch_src_inputs", "=", "[", "]", "\n", "batch_src_masks", "=", "[", "]", "\n", "batch_tgt_inputs", "=", "[", "]", "\n", "batch_tgt_masks", "=", "[", "]", "\n", "lang_id", "=", "[", "]", "\n", "idx", "=", "[", "]", "\n", "\n", "max_src_len", "=", "max", "(", "[", "len", "(", "ex", "[", "0", "]", ")", "for", "ex", "in", "batch", "]", ")", "\n", "max_tgt_len", "=", "max", "(", "[", "len", "(", "ex", "[", "2", "]", ")", "for", "ex", "in", "batch", "]", ")", "\n", "\n", "for", "item", "in", "batch", ":", "\n", "        ", "batch_src_inputs", "+=", "[", "pad_seq", "(", "item", "[", "0", "]", ",", "max_src_len", ",", "tokenizer", ".", "pad_token_id", ")", "]", "\n", "batch_src_masks", "+=", "[", "pad_seq", "(", "item", "[", "1", "]", ",", "max_src_len", ",", "0", ")", "]", "\n", "batch_tgt_inputs", "+=", "[", "pad_seq", "(", "item", "[", "2", "]", ",", "max_tgt_len", ",", "tokenizer", ".", "pad_token_id", ")", "]", "\n", "batch_tgt_masks", "+=", "[", "pad_seq", "(", "item", "[", "3", "]", ",", "max_tgt_len", ",", "0", ")", "]", "\n", "lang_id", ".", "append", "(", "item", "[", "4", "]", ")", "\n", "idx", ".", "append", "(", "item", "[", "5", "]", ")", "\n", "\n", "", "return", "torch", ".", "tensor", "(", "batch_src_inputs", ",", "dtype", "=", "torch", ".", "long", ")", ",", "torch", ".", "tensor", "(", "batch_src_masks", ",", "dtype", "=", "torch", ".", "long", ")", ",", "torch", ".", "tensor", "(", "batch_tgt_inputs", ",", "dtype", "=", "torch", ".", "long", ")", ",", "torch", ".", "tensor", "(", "batch_tgt_masks", ",", "dtype", "=", "torch", ".", "long", ")", ",", "torch", ".", "tensor", "(", "lang_id", ",", "dtype", "=", "torch", ".", "long", ")", ",", "torch", ".", "tensor", "(", "idx", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.dataloader.get_dataset_loaders": [[106, 110], ["dataloader.TextDataset", "torch.utils.data.DataLoader", "dataloader.collate_batch"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.collate_batch"], ["", "def", "get_dataset_loaders", "(", "tokenizer", ",", "filename", ",", "logger", ",", "prefix", "=", "False", ",", "dataset_count", "=", "0", ",", "batch_size", "=", "8", ",", "num_threads", "=", "0", ",", "src_max_seq_len", "=", "200", ",", "tgt_max_seq_len", "=", "200", ",", "script_unification", "=", "False", ",", "complete_coverage", "=", "False", ")", ":", "\n", "    ", "dataset", "=", "TextDataset", "(", "prefix", ",", "tokenizer", ",", "filename", ",", "dataset_count", ",", "src_max_seq_len", ",", "tgt_max_seq_len", ",", "script_unification", ",", "logger", ",", "complete_coverage", ")", "\n", "input_dataloader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ",", "num_workers", "=", "num_threads", ",", "collate_fn", "=", "lambda", "x", ":", "collate_batch", "(", "x", ",", "tokenizer", ")", ")", "\n", "return", "input_dataloader", "\n", "", ""]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.utils.handle_multiple_languages": [[30, 43], ["print", "sorted", "x.strip().lower", "sorted.append", "len", "len", "print", "lang.split", "x.strip", "len", "len", "len"], "function", ["None"], ["def", "handle_multiple_languages", "(", "lang", ")", ":", "\n", "# check if multiple \",\" separated entries exists.", "\n", "    ", "lang_list", "=", "[", "x", ".", "strip", "(", ")", ".", "lower", "(", ")", "for", "x", "in", "lang", ".", "split", "(", "','", ")", "]", "\n", "valid_languages", "=", "[", "]", "\n", "for", "x", "in", "lang_list", ":", "\n", "        ", "if", "x", "not", "in", "languages_map", ":", "\n", "            ", "continue", "\n", "", "valid_languages", ".", "append", "(", "x", ")", "\n", "", "if", "len", "(", "valid_languages", ")", "!=", "len", "(", "lang_list", ")", ":", "\n", "        ", "print", "(", "\"%d invalid languages identified\"", "%", "(", "len", "(", "lang_list", ")", "-", "len", "(", "valid_languages", ")", ")", ")", "\n", "", "print", "(", "'successfully identified %d langauges: %s'", "%", "(", "len", "(", "valid_languages", ")", ",", "valid_languages", ")", ")", "\n", "valid_languages", "=", "sorted", "(", "valid_languages", ")", "\n", "return", "valid_languages", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.utils.get_language_normalizer": [[44, 55], ["sacremoses.MosesPunctNormalizer", "indicnlp.normalize.indic_normalize.IndicNormalizerFactory", "indic_normalize.IndicNormalizerFactory.get_normalizer"], "function", ["None"], ["", "def", "get_language_normalizer", "(", ")", ":", "\n", "    ", "lang_normalizer", "=", "{", "}", "\n", "for", "k", "in", "languages_map", ":", "\n", "        ", "if", "k", "==", "'ur'", ":", "\n", "            ", "lang_normalizer", "[", "k", "]", "=", "urduhack", ".", "normalization", "\n", "", "elif", "k", "==", "'en'", ":", "\n", "            ", "lang_normalizer", "[", "k", "]", "=", "MosesPunctNormalizer", "(", ")", "\n", "", "else", ":", "\n", "            ", "normfactory", "=", "indic_normalize", ".", "IndicNormalizerFactory", "(", ")", "\n", "lang_normalizer", "[", "k", "]", "=", "normfactory", ".", "get_normalizer", "(", "k", ")", "\n", "", "", "return", "lang_normalizer", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.utils.get_id_to_lang": [[56, 61], ["languages_map.items"], "function", ["None"], ["", "def", "get_id_to_lang", "(", ")", ":", "\n", "    ", "id_to_lang", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "languages_map", ".", "items", "(", ")", ":", "\n", "        ", "id_to_lang", "[", "v", "[", "'id'", "]", "]", "=", "k", "\n", "", "return", "id_to_lang", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.utils.load_jsonl": [[62, 68], ["open", "dfile.readlines", "res.append", "json.loads", "line.strip"], "function", ["None"], ["", "def", "load_jsonl", "(", "file_path", ")", ":", "\n", "    ", "res", "=", "[", "]", "\n", "with", "open", "(", "file_path", ",", "encoding", "=", "'utf-8'", ")", "as", "dfile", ":", "\n", "        ", "for", "line", "in", "dfile", ".", "readlines", "(", ")", ":", "\n", "            ", "res", ".", "append", "(", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", ")", "\n", "", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.utils.dataset_exists": [[69, 79], ["set", "set", "os.listdir", "set.difference", "len", "os.path.abspath", "print", "len", "set.add"], "function", ["None"], ["", "def", "dataset_exists", "(", "dir_path", ",", "required_files", "=", "[", "'train.jsonl'", ",", "'test.jsonl'", ",", "'val.jsonl'", "]", ")", ":", "\n", "    ", "required_files", "=", "set", "(", "required_files", ")", "\n", "existing_files", "=", "set", "(", ")", "\n", "for", "dfile", "in", "os", ".", "listdir", "(", "os", ".", "path", ".", "abspath", "(", "dir_path", ")", ")", ":", "\n", "        ", "if", "dfile", "in", "required_files", ":", "\n", "            ", "existing_files", ".", "add", "(", "dfile", ")", "\n", "", "", "missing_files", "=", "required_files", ".", "difference", "(", "existing_files", ")", "\n", "if", "len", "(", "missing_files", ")", ":", "\n", "        ", "print", "(", "\"%s files are missing, creating the files..\"", "%", "missing_files", ")", "\n", "", "return", "len", "(", "missing_files", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.utils.store_jsonl": [[80, 85], ["open", "json.dump", "dfile.write"], "function", ["None"], ["", "def", "store_jsonl", "(", "res", ",", "file_path", ")", ":", "\n", "    ", "with", "open", "(", "file_path", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "dfile", ":", "\n", "        ", "for", "item", "in", "res", ":", "\n", "            ", "json", ".", "dump", "(", "item", ",", "dfile", ",", "ensure_ascii", "=", "False", ")", "\n", "dfile", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.utils.merge_dataset_across_languages": [[86, 94], ["random.seed", "random.shuffle", "utils.store_jsonl", "os.path.join", "final_res.extend", "utils.load_jsonl"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.store_jsonl", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.load_jsonl"], ["", "", "", "def", "merge_dataset_across_languages", "(", "dataset_dir", ",", "languages", ",", "dataset_type", ",", "merged_file", ")", ":", "\n", "    ", "final_res", "=", "[", "]", "\n", "for", "lang", "in", "languages", ":", "\n", "        ", "file_path", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "lang", ",", "\"%s.jsonl\"", "%", "dataset_type", ")", "\n", "final_res", ".", "extend", "(", "load_jsonl", "(", "file_path", ")", ")", "\n", "", "random", ".", "seed", "(", "42", ")", "\n", "random", ".", "shuffle", "(", "final_res", ")", "\n", "store_jsonl", "(", "final_res", ",", "merged_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.utils.store_txt": [[95, 99], ["open", "dfile.write", "item.strip"], "function", ["None"], ["", "def", "store_txt", "(", "res", ",", "file_path", ")", ":", "\n", "    ", "with", "open", "(", "file_path", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "dfile", ":", "\n", "        ", "for", "item", "in", "res", ":", "\n", "            ", "dfile", ".", "write", "(", "\"%s\\n\"", "%", "item", ".", "strip", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.utils.get_nodes": [[100, 109], ["unidecode.unidecode.strip", "unidecode.unidecode.replace", "unidecode.unidecode.replace", "unidecode.unidecode.replace", "unidecode.unidecode.replace", "unidecode.unidecode.replace", "unidecode.unidecode"], "function", ["None"], ["", "", "", "def", "get_nodes", "(", "n", ")", ":", "\n", "    ", "n", "=", "n", ".", "strip", "(", ")", "\n", "n", "=", "n", ".", "replace", "(", "'('", ",", "''", ")", "\n", "n", "=", "n", ".", "replace", "(", "'\\\"'", ",", "''", ")", "\n", "n", "=", "n", ".", "replace", "(", "')'", ",", "''", ")", "\n", "n", "=", "n", ".", "replace", "(", "','", ",", "' '", ")", "\n", "n", "=", "n", ".", "replace", "(", "'_'", ",", "' '", ")", "\n", "n", "=", "unidecode", ".", "unidecode", "(", "n", ")", "\n", "return", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.utils.get_relation": [[111, 118], ["n.split.replace", "n.split.replace", "n.split.strip", "n.split.split"], "function", ["None"], ["", "def", "get_relation", "(", "n", ")", ":", "\n", "    ", "n", "=", "n", ".", "replace", "(", "'('", ",", "''", ")", "\n", "n", "=", "n", ".", "replace", "(", "')'", ",", "''", ")", "\n", "n", "=", "n", ".", "strip", "(", ")", "\n", "n", "=", "n", ".", "split", "(", ")", "\n", "n", "=", "\"_\"", ".", "join", "(", "n", ")", "\n", "return", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.utils.linear_fact_str": [[120, 126], ["get_relation().lower", "get_nodes().lower", "len", "utils.get_relation", "utils.get_nodes", "get_relation().lower", "get_nodes().lower", "utils.get_relation", "utils.get_nodes"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.get_relation", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.get_nodes", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.get_relation", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.get_nodes"], ["", "def", "linear_fact_str", "(", "fact", ",", "enable_qualifiers", "=", "False", ")", ":", "\n", "    ", "fact_str", "=", "[", "'<R>'", ",", "get_relation", "(", "fact", "[", "0", "]", ")", ".", "lower", "(", ")", ",", "'<T>'", ",", "get_nodes", "(", "fact", "[", "1", "]", ")", ".", "lower", "(", ")", "]", "\n", "qualifier_str", "=", "[", "' '", ".", "join", "(", "[", "'<QR>'", ",", "get_relation", "(", "x", "[", "0", "]", ")", ".", "lower", "(", ")", ",", "'<QT>'", ",", "get_nodes", "(", "x", "[", "1", "]", ")", ".", "lower", "(", ")", "]", ")", "for", "x", "in", "fact", "[", "2", "]", "]", "\n", "if", "enable_qualifiers", "and", "len", "(", "fact", "[", "2", "]", ")", ">", "0", ":", "\n", "        ", "fact_str", "+=", "[", "' '", ".", "join", "(", "qualifier_str", ")", "]", "\n", "", "return", "fact_str", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.utils.get_text_in_unified_script": [[127, 137], ["indicnlp.transliterate.unicode_transliterate.UnicodeIndicTransliterator.transliterate().replace", "indicnlp.transliterate.unicode_transliterate.UnicodeIndicTransliterator.transliterate", "indicnlp.tokenize.indic_tokenize.trivial_tokenize", "normalizer.normalize", "text.strip"], "function", ["None"], ["", "def", "get_text_in_unified_script", "(", "text", ",", "normalizer", ",", "lang", ")", ":", "\n", "    ", "return", "unicode_transliterate", ".", "UnicodeIndicTransliterator", ".", "transliterate", "(", "\n", "\" \"", ".", "join", "(", "\n", "indic_tokenize", ".", "trivial_tokenize", "(", "\n", "normalizer", ".", "normalize", "(", "text", ".", "strip", "(", ")", ")", ",", "lang", "\n", ")", "\n", ")", ",", "\n", "lang", ",", "\n", "\"hi\"", ",", "\n", ")", ".", "replace", "(", "\" \u094d \"", ",", "\"\u094d\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.mT5-baseline.utils.get_native_text_from_unified_script": [[138, 140], ["indicnlp.transliterate.unicode_transliterate.UnicodeIndicTransliterator.transliterate"], "function", ["None"], ["", "def", "get_native_text_from_unified_script", "(", "unified_text", ",", "lang", ")", ":", "\n", "    ", "return", "unicode_transliterate", ".", "UnicodeIndicTransliterator", ".", "transliterate", "(", "unified_text", ",", "\"hi\"", ",", "lang", ")", "", "", ""]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.main.TexClassificationHead.__init__": [[47, 52], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf.__init__"], ["torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n", "", "def", "count_parameters", "(", "model", ")", ":", "\n", "    ", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n", "", "class", "ModelWrapper", "(", "pl", ".", "LightningModule", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.main.TexClassificationHead.forward": [[53, 61], ["main.TexClassificationHead.dropout", "main.TexClassificationHead.dense", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "main.TexClassificationHead.dropout", "main.TexClassificationHead.out_proj"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "ModelWrapper", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "step_loss_labels", "=", "{", "'train'", ":", "'loss'", ",", "'val'", ":", "'val_loss'", ",", "'test'", ":", "'test_loss'", "}", "\n", "self", ".", "config_args", "=", "args", "\n", "self", ".", "tokenizer", "=", "MT5Tokenizer", ".", "from_pretrained", "(", "args", ".", "model_name", ",", "cache_dir", "=", "\"/tmp/hugginface\"", ")", "\n", "self", ".", "add_special_tokens", "(", ")", "\n", "self", ".", "cal_bleu", "=", "BLEU", "(", "tokenize", "=", "'none'", ")", "\n", "self", ".", "lang_normalizer", "=", "get_language_normalizer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.main.ModelWrapper.__init__": [[63, 78], ["pytorch_lightning.LightningModule.__init__", "transformers.AutoTokenizer.from_pretrained", "main.TexClassificationHead", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Accuracy", "transformers.AutoModel.from_pretrained", "transformers.AutoModel.from_config", "transformers.AutoModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf.__init__"], ["# using pretrained transformers", "\n", "            ", "self", ".", "model", "=", "MT5ForConditionalGeneration", ".", "from_pretrained", "(", "args", ".", "model_name", ",", "dropout_rate", "=", "args", ".", "dropout_rate", ",", "cache_dir", "=", "\"/tmp/hugginface\"", ")", "\n", "", "else", ":", "\n", "# training transformer from scratch", "\n", "            ", "self", ".", "model", "=", "MT5ForConditionalGeneration", ".", "from_config", "(", "MT5ForConditionalGeneration", ".", "from_pretrained", "(", "\n", "args", ".", "model_name", ",", "dropout_rate", "=", "args", ".", "dropout_rate", ",", "cache_dir", "=", "\"/tmp/hugginface\"", ")", ")", "\n", "", "self", ".", "model", ".", "resize_token_embeddings", "(", "len", "(", "self", ".", "tokenizer", ")", ")", "\n", "\n", "", "def", "add_special_tokens", "(", "self", ")", ":", "\n", "        ", "new_tokens", "=", "[", "'<H>'", ",", "'<R>'", ",", "'<T>'", ",", "'<QR>'", ",", "'<QT>'", ",", "'<S>'", "]", "\n", "new_tokens_vocab", "=", "{", "}", "\n", "new_tokens_vocab", "[", "'additional_special_tokens'", "]", "=", "[", "]", "\n", "for", "idx", ",", "t", "in", "enumerate", "(", "new_tokens", ")", ":", "\n", "            ", "new_tokens_vocab", "[", "'additional_special_tokens'", "]", ".", "append", "(", "t", ")", "\n", "", "num_added_toks", "=", "self", ".", "tokenizer", ".", "add_special_tokens", "(", "new_tokens_vocab", ")", "\n", "self", ".", "config_args", ".", "logger", ".", "critical", "(", "'added %s tokens'", "%", "num_added_toks", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.main.ModelWrapper.forward": [[79, 87], ["main.ModelWrapper.task_head", "main.ModelWrapper.model"], "methods", ["None"], ["\n", "", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "decoder_input_ids", "=", "None", ",", "decoder_attention_mask", "=", "None", ",", "lm_labels", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "model", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "labels", "=", "lm_labels", ",", "\n", "decoder_attention_mask", "=", "decoder_attention_mask", "\n", ")", "\n", "return", "outputs", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.main.ModelWrapper.configure_optimizers": [[88, 117], ["transformers.AdamW", "int", "numpy.ceil", "transformers.get_linear_schedule_with_warmup", "main.ModelWrapper.named_parameters", "main.ModelWrapper.named_parameters", "any", "any"], "methods", ["None"], ["\n", "", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "        ", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "self", ".", "config_args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "\n", "optimizer", "=", "Adafactor", "(", "optimizer_grouped_parameters", ",", "lr", "=", "self", ".", "config_args", ".", "learning_rate", ",", "scale_parameter", "=", "False", ",", "relative_step", "=", "False", ",", "warmup_init", "=", "False", ")", "\n", "# optimizer = torch.optim.Adam(optimizer_grouped_parameters, lr=self.config_args.learning_rate, eps=1e-6)", "\n", "\n", "if", "self", ".", "config_args", ".", "enable_scheduler", ":", "\n", "            ", "total_dataset_count", "=", "self", ".", "config_args", ".", "train_dataset_count", "\n", "total_steps", "=", "int", "(", "np", ".", "ceil", "(", "(", "self", ".", "config_args", ".", "epochs", "*", "total_dataset_count", ")", "/", "\n", "(", "self", ".", "config_args", ".", "batch_size", "*", "self", ".", "config_args", ".", "gpus", ")", ")", ")", "\n", "\n", "scheduler", "=", "{", "\n", "# 'scheduler': get_constant_schedule_with_warmup(optimizer, self.config_args.warmup_steps*total_steps)", "\n", "'scheduler'", ":", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "self", ".", "config_args", ".", "warmup_steps", "*", "total_steps", ",", "total_steps", ")", ",", "\n", "'interval'", ":", "'step'", ",", "\n", "}", "\n", "return", "[", "optimizer", "]", ",", "[", "scheduler", "]", "\n", "\n", "", "return", "optimizer", "\n", "\n", "", "def", "ids_to_clean_text", "(", "self", ",", "generated_ids", ",", "remove_special_tokens", "=", "True", ",", "remove_tok_spaces", "=", "True", ")", ":", "\n", "        ", "gen_text", "=", "self", ".", "tokenizer", ".", "batch_decode", "(", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.main.ModelWrapper._step": [[118, 151], ["main.ModelWrapper.", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "step_metric", "online_logger_data.update", "online_logger_data.update", "main.ModelWrapper.logger.log_metrics", "len", "label_ids.long", "main.ModelWrapper.softmax", "label_ids.long"], "methods", ["None"], ["generated_ids", ",", "skip_special_tokens", "=", "remove_special_tokens", ",", "clean_up_tokenization_spaces", "=", "remove_tok_spaces", "\n", ")", "\n", "return", "list", "(", "map", "(", "str", ".", "strip", ",", "gen_text", ")", ")", "\n", "\n", "", "def", "_generative_step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "generated_ids", "=", "self", ".", "model", ".", "generate", "(", "\n", "batch", "[", "0", "]", ",", "\n", "attention_mask", "=", "batch", "[", "1", "]", ",", "\n", "use_cache", "=", "True", ",", "\n", "num_beams", "=", "self", ".", "config_args", ".", "eval_beams", ",", "\n", "max_length", "=", "self", ".", "config_args", ".", "tgt_max_seq_len", ",", "\n", "length_penalty", "=", "self", ".", "config_args", ".", "length_penalty", ",", "\n", ")", "\n", "\n", "preds", "=", "self", ".", "ids_to_clean_text", "(", "generated_ids", ")", "\n", "target", "=", "self", ".", "ids_to_clean_text", "(", "batch", "[", "2", "]", ")", "\n", "return", "{", "'predicted_txt'", ":", "preds", ",", "'target_txt'", ":", "target", "}", "\n", "\n", "", "def", "_recover_input_text", "(", "self", ",", "input_ids", ")", ":", "\n", "        ", "input_txt", "=", "self", ".", "ids_to_clean_text", "(", "input_ids", ",", "remove_special_tokens", "=", "False", ")", "\n", "processed_input_ids", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "input_txt", ")", ")", ":", "\n", "            ", "final_str", "=", "input_txt", "[", "i", "]", "\n", "# removing model's default special token", "\n", "for", "special_token", "in", "[", "self", ".", "tokenizer", ".", "eos_token", ",", "self", ".", "tokenizer", ".", "pad_token", "]", ":", "\n", "                ", "if", "not", "special_token", ":", "\n", "                    ", "continue", "\n", "", "final_str", "=", "re", ".", "sub", "(", "special_token", ",", "''", ",", "final_str", ")", "\n", "", "input_txt", "[", "i", "]", "=", "final_str", ".", "strip", "(", ")", "\n", "", "return", "input_txt", "\n", "\n", "", "def", "_step", "(", "self", ",", "batch", ",", "step_type", ")", ":", "\n", "        ", "lm_labels", "=", "torch", ".", "clone", "(", "batch", "[", "2", "]", ")", "\n", "lm_labels", "[", "lm_labels", "[", ":", ",", ":", "]", "==", "self", ".", "tokenizer", ".", "pad_token_id", "]", "=", "-", "100", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.main.ModelWrapper._epoch_end": [[152, 172], ["torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "end_metric.compute", "main.ModelWrapper.config_args.logger.info", "main.ModelWrapper.logger.log_metrics", "main.ModelWrapper.log", "main.ModelWrapper.log", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack().mean.item", "torch.stack().mean.item", "torch.stack().mean.item", "end_metric.compute.item"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info"], ["outputs", "=", "self", "(", "\n", "batch", "[", "0", "]", ",", "\n", "attention_mask", "=", "batch", "[", "1", "]", ",", "\n", "lm_labels", "=", "lm_labels", ",", "\n", "decoder_attention_mask", "=", "batch", "[", "3", "]", "\n", ")", "\n", "return_map", "=", "{", "}", "\n", "online_logger_data", "=", "{", "}", "\n", "return_map", ".", "update", "(", "{", "self", ".", "step_loss_labels", "[", "step_type", "]", ":", "outputs", "[", "0", "]", "}", ")", "\n", "# updating the online logger", "\n", "online_logger_data", ".", "update", "(", "return_map", ")", "\n", "# inserting the predictions and actual text for validation and testing dataset when executing bi-lingual training", "\n", "# inserting the predictions and actual text for test dataset only when executing multi-lingual training", "\n", "if", "step_type", "!=", "'train'", "and", "(", "(", "len", "(", "self", ".", "config_args", ".", "lang", ")", "==", "1", "and", "self", ".", "config_args", ".", "enable_bleu_cal_per_epoch", "==", "1", ")", "or", "step_type", "==", "'test'", ")", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "return_map", ".", "update", "(", "self", ".", "_generative_step", "(", "batch", ")", ")", "\n", "return_map", ".", "update", "(", "{", "'source_txt'", ":", "self", ".", "_recover_input_text", "(", "batch", "[", "0", "]", ")", "}", ")", "\n", "return_map", ".", "update", "(", "{", "'lang_id'", ":", "batch", "[", "4", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "tolist", "(", ")", "}", ")", "\n", "return_map", ".", "update", "(", "{", "'seq_id'", ":", "batch", "[", "5", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "tolist", "(", ")", "}", ")", "\n", "", "", "self", ".", "logger", ".", "log_metrics", "(", "online_logger_data", ")", "\n", "return", "return_map", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.main.ModelWrapper.training_step": [[173, 175], ["main.ModelWrapper._step"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper._step"], ["\n", "", "def", "_preprocess_text", "(", "self", ",", "text", ",", "lang", ")", ":", "\n", "        ", "native_text", "=", "text", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.main.ModelWrapper.training_epoch_end": [[176, 178], ["main.ModelWrapper._epoch_end"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper._epoch_end"], ["if", "self", ".", "config_args", ".", "enable_script_unification", ">", "0", "and", "lang", "!=", "'en'", ":", "\n", "# convert unified script to native langauge text", "\n", "            ", "native_text", "=", "get_native_text_from_unified_script", "(", "text", ",", "lang", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.main.ModelWrapper.validation_step": [[179, 181], ["main.ModelWrapper._step"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper._step"], ["\n", "", "native_text", "=", "native_text", ".", "strip", "(", ")", "\n", "# as input and predicted text are already space tokenized", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.main.ModelWrapper.validation_epoch_end": [[182, 184], ["main.ModelWrapper._epoch_end"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper._epoch_end"], ["native_text", "=", "' '", ".", "join", "(", "[", "x", "for", "x", "in", "native_text", ".", "split", "(", ")", "]", ")", "\n", "return", "native_text", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.main.TextDataModule.__init__": [[187, 191], ["pytorch_lightning.LightningDataModule.__init__", "transformers.AutoTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf.__init__"], ["avg_loss", "=", "torch", ".", "stack", "(", "[", "x", "[", "loss_label", "]", "for", "x", "in", "step_outputs", "]", ")", ".", "mean", "(", ")", "\n", "if", "end_type", "!=", "'train'", "and", "(", "(", "len", "(", "self", ".", "config_args", ".", "lang", ")", "==", "1", "and", "self", ".", "config_args", ".", "enable_bleu_cal_per_epoch", "==", "1", ")", "or", "end_type", "==", "'test'", ")", ":", "\n", "            ", "id_to_lang", "=", "get_id_to_lang", "(", ")", "\n", "src_txt", "=", "[", "]", "\n", "pred_txt", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.main.TextDataModule._intiate_dataset_merging": [[190, 200], ["logger.critical", "os.path.join", "os.makedirs", "utils.dataset_exists", "os.path.abspath", "logger.info", "utils.merge_dataset_across_languages", "os.path.join", "len"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.critical", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.dataset_exists", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.merge_dataset_across_languages"], ["src_txt", "=", "[", "]", "\n", "pred_txt", "=", "[", "]", "\n", "ref_txt", "=", "[", "]", "\n", "lang_info", "=", "[", "]", "\n", "seq_id", "=", "[", "]", "\n", "for", "z", "in", "step_outputs", ":", "\n", "                ", "src_txt", ".", "extend", "(", "z", "[", "'source_txt'", "]", ")", "\n", "pred_txt", ".", "extend", "(", "z", "[", "'predicted_txt'", "]", ")", "\n", "ref_txt", ".", "extend", "(", "z", "[", "'target_txt'", "]", ")", "\n", "lang_info", ".", "extend", "(", "[", "id_to_lang", "[", "u", "]", "for", "u", "in", "z", "[", "'lang_id'", "]", "]", ")", "\n", "seq_id", ".", "extend", "(", "z", "[", "'seq_id'", "]", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.main.TextDataModule.val_dataloader": [[192, 197], ["os.path.join", "dataloader.get_dataset_loaders", "os.path.abspath"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.get_dataset_loaders"], ["ref_txt", "=", "[", "]", "\n", "lang_info", "=", "[", "]", "\n", "seq_id", "=", "[", "]", "\n", "for", "z", "in", "step_outputs", ":", "\n", "                ", "src_txt", ".", "extend", "(", "z", "[", "'source_txt'", "]", ")", "\n", "pred_txt", ".", "extend", "(", "z", "[", "'predicted_txt'", "]", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.main.TextDataModule.train_dataloader": [[198, 203], ["os.path.join", "dataloader.get_dataset_loaders", "os.path.abspath"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.get_dataset_loaders"], ["ref_txt", ".", "extend", "(", "z", "[", "'target_txt'", "]", ")", "\n", "lang_info", ".", "extend", "(", "[", "id_to_lang", "[", "u", "]", "for", "u", "in", "z", "[", "'lang_id'", "]", "]", ")", "\n", "seq_id", ".", "extend", "(", "z", "[", "'seq_id'", "]", ")", "\n", "# normalizing and tokenizing using indic_tokenize", "\n", "", "pred_txt", "=", "[", "self", ".", "_preprocess_text", "(", "x", ",", "l", ")", "for", "x", ",", "l", "in", "zip", "(", "pred_txt", ",", "lang_info", ")", "]", "\n", "ref_txt", "=", "[", "self", ".", "_preprocess_text", "(", "x", ",", "l", ")", "for", "x", ",", "l", "in", "zip", "(", "ref_txt", ",", "lang_info", ")", "]", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.main.random_seed": [[35, 41], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed"], "function", ["None"], ["\n", "\n", "base_dir", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", "\n", "from", "sacremoses", "import", "MosesTokenizer", "\n", "en_tok", "=", "MosesTokenizer", "(", "lang", "=", "\"en\"", ")", "\n", "\n", "# allow deterministic psuedo-random-initialization", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.main.count_parameters": [[42, 44], ["sum", "p.numel", "model.parameters"], "function", ["None"], ["def", "random_seed", "(", "seed", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.main.get_checkpoint_file": [[204, 220], ["os.listdir", "logger.info", "sorted", "os.path.getmtime", "sorted.append", "len", "os.path.join", "file_name.endswith", "os.path.join", "len"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info"], ["\n", "# visual model prediction on wandb", "\n", "if", "self", ".", "config_args", ".", "verbose", "and", "(", "(", "len", "(", "self", ".", "config_args", ".", "lang", ")", "==", "1", "and", "self", ".", "config_args", ".", "enable_bleu_cal_per_epoch", "==", "1", ")", "or", "end_type", "==", "'test'", ")", ":", "\n", "                ", "if", "self", ".", "current_epoch", "==", "0", "or", "end_type", "==", "'test'", ":", "\n", "# writing the model generated outputs", "\n", "                    ", "store_txt", "(", "src_txt", ",", "os", ".", "path", ".", "join", "(", "self", ".", "config_args", ".", "verbose_output_dir", ",", "'%s-src.txt'", "%", "end_type", ")", ")", "\n", "store_txt", "(", "ref_txt", ",", "os", ".", "path", ".", "join", "(", "self", ".", "config_args", ".", "verbose_output_dir", ",", "'%s-ref.txt'", "%", "end_type", ")", ")", "\n", "", "store_txt", "(", "pred_txt", ",", "os", ".", "path", ".", "join", "(", "self", ".", "config_args", ".", "verbose_output_dir", ",", "'%s-predicted-epoch-%d.txt'", "%", "(", "end_type", ",", "self", ".", "current_epoch", ")", ")", ")", "\n", "\n", "# calculating the bleu score", "\n", "", "if", "(", "len", "(", "self", ".", "config_args", ".", "lang", ")", "==", "1", "and", "self", ".", "config_args", ".", "enable_bleu_cal_per_epoch", "==", "1", ")", ":", "\n", "# handling bilingual setting", "\n", "                ", "bleu", "=", "self", ".", "cal_bleu", ".", "corpus_score", "(", "pred_txt", ",", "[", "ref_txt", "]", ")", "\n", "self", ".", "config_args", ".", "logger", ".", "info", "(", "\"epoch : %d | %s\"", "%", "(", "self", ".", "current_epoch", ",", "bleu", ")", ")", "\n", "bleu_list", "=", "list", "(", "map", "(", "float", ",", "bleu", ".", "prec_str", ".", "split", "(", "'/'", ")", ")", ")", "\n", "self", ".", "logger", ".", "log_metrics", "(", "{", "\n", "'overall_%s_bleu'", "%", "end_type", ":", "bleu", ".", "score", ",", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.main.start_training": [[221, 263], ["args.logger.debug", "os.path.join", "os.makedirs", "main.TextDataModule", "pytorch_lightning.callbacks.ModelCheckpoint", "main.ModelWrapper", "args.logger.debug", "args.logger.info", "pytorch_lightning.Trainer", "args.logger.debug", "pl.Trainer.fit", "args.logger.debug", "main.get_checkpoint_file", "args.online_logger.experiment.save", "main.count_parameters"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.debug", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.debug", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.debug", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.debug", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.get_checkpoint_file", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.count_parameters"], ["'%s_bleu_1'", "%", "end_type", ":", "bleu_list", "[", "0", "]", ",", "\n", "'%s_bleu_2'", "%", "end_type", ":", "bleu_list", "[", "1", "]", ",", "\n", "'%s_bleu_3'", "%", "end_type", ":", "bleu_list", "[", "2", "]", ",", "\n", "'%s_bleu_4'", "%", "end_type", ":", "bleu_list", "[", "3", "]", "\n", "}", ")", "\n", "self", ".", "log", "(", "'overall_%s_bleu'", "%", "end_type", ",", "bleu", ".", "score", ",", "prog_bar", "=", "True", ")", "\n", "", "else", ":", "\n", "# handling multilingual setting", "\n", "                ", "language_specific_inout", "=", "defaultdict", "(", "lambda", ":", "{", "'pred'", ":", "[", "]", ",", "'ref'", ":", "[", "]", "}", ")", "\n", "for", "lpred", ",", "lref", ",", "llang", "in", "zip", "(", "pred_txt", ",", "ref_txt", ",", "lang_info", ")", ":", "\n", "                    ", "language_specific_inout", "[", "llang", "]", "[", "'pred'", "]", ".", "append", "(", "lpred", ")", "\n", "language_specific_inout", "[", "llang", "]", "[", "'ref'", "]", ".", "append", "(", "lref", ")", "\n", "\n", "", "for", "klang", ",", "vdata", "in", "language_specific_inout", ".", "items", "(", ")", ":", "\n", "                    ", "bleu", "=", "self", ".", "cal_bleu", ".", "corpus_score", "(", "vdata", "[", "'pred'", "]", ",", "[", "vdata", "[", "'ref'", "]", "]", ")", "\n", "self", ".", "config_args", ".", "logger", ".", "info", "(", "\"%s : epoch : %d | %s\"", "%", "(", "klang", ",", "self", ".", "current_epoch", ",", "bleu", ")", ")", "\n", "bleu_list", "=", "list", "(", "map", "(", "float", ",", "bleu", ".", "prec_str", ".", "split", "(", "'/'", ")", ")", ")", "\n", "self", ".", "logger", ".", "log_metrics", "(", "{", "\n", "'%s_overall_%s_bleu'", "%", "(", "klang", ",", "end_type", ")", ":", "bleu", ".", "score", ",", "\n", "'%s_%s_bleu_1'", "%", "(", "klang", ",", "end_type", ")", ":", "bleu_list", "[", "0", "]", ",", "\n", "'%s_%s_bleu_2'", "%", "(", "klang", ",", "end_type", ")", ":", "bleu_list", "[", "1", "]", ",", "\n", "'%s_%s_bleu_3'", "%", "(", "klang", ",", "end_type", ")", ":", "bleu_list", "[", "2", "]", ",", "\n", "'%s_%s_bleu_4'", "%", "(", "klang", ",", "end_type", ")", ":", "bleu_list", "[", "3", "]", "\n", "}", ")", "\n", "self", ".", "log", "(", "'%s_overall_%s_bleu'", "%", "(", "klang", ",", "end_type", ")", ",", "bleu", ".", "score", ",", "prog_bar", "=", "False", ")", "\n", "\n", "", "", "", "self", ".", "config_args", ".", "logger", ".", "info", "(", "'epoch : %d - average_%s_loss : %f'", "%", "(", "self", ".", "current_epoch", ",", "end_type", ",", "avg_loss", ".", "item", "(", ")", ")", ")", "\n", "# logging to weight and bias if online mode is enabled", "\n", "self", ".", "logger", ".", "log_metrics", "(", "\n", "{", "'avg_%s_loss'", "%", "end_type", ":", "avg_loss", "}", ")", "\n", "self", ".", "log", "(", "'avg_%s_loss'", "%", "end_type", ",", "avg_loss", ",", "prog_bar", "=", "True", ")", "\n", "\n", "", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "return", "self", ".", "_step", "(", "batch", ",", "'train'", ")", "\n", "\n", "", "def", "training_epoch_end", "(", "self", ",", "train_step_outputs", ")", ":", "\n", "        ", "self", ".", "_epoch_end", "(", "train_step_outputs", ",", "'train'", ")", "\n", "\n", "", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "return", "self", ".", "_step", "(", "batch", ",", "'val'", ")", "\n", "\n", "", "def", "validation_epoch_end", "(", "self", ",", "val_step_outputs", ")", ":", "\n", "        ", "self", ".", "_epoch_end", "(", "val_step_outputs", ",", "'val'", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.logger.LOG_LEVELS.get_name": [[14, 28], ["None"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "get_name", "(", "level", ")", ":", "\n", "        ", "if", "level", "==", "1", ":", "\n", "            ", "return", "'DEBUG'", "\n", "", "elif", "level", "==", "2", ":", "\n", "            ", "return", "'INFO'", "\n", "", "elif", "level", "==", "3", ":", "\n", "            ", "return", "'WARN'", "\n", "", "elif", "level", "==", "4", ":", "\n", "            ", "return", "'CRITICAL'", "\n", "", "elif", "level", "==", "5", ":", "\n", "            ", "return", "'ERROR'", "\n", "", "else", ":", "\n", "            ", "return", "'UNKNOWN'", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.logger.MyLogger.__init__": [[30, 41], ["open"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "log_file_path", ",", "use_stdout", "=", "False", ",", "overwrite", "=", "True", ",", "log_level", "=", "LOG_LEVELS", ".", "DEBUG", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "log_file_path", "=", "log_file_path", "\n", "self", ".", "stdout", "=", "use_stdout", "\n", "self", ".", "level", "=", "log_level", "\n", "#only zero rank process can truncate the file", "\n", "if", "overwrite", "and", "rank_zero_only", ".", "rank", "==", "0", ":", "\n", "#truncate the file", "\n", "            ", "with", "open", "(", "self", ".", "log_file_path", ",", "'w'", ")", "as", "log_file", ":", "\n", "                ", "pass", "\n", "\n", "", "", "", "@", "rank_zero_only", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.logger.MyLogger._log_msg": [[42, 51], ["datetime.datetime.datetime.now", "print", "open", "log_file.write", "datetime.datetime.now.strftime", "logger.LOG_LEVELS.get_name", "os.path.abspath"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.LOG_LEVELS.get_name"], ["def", "_log_msg", "(", "self", ",", "msg", ",", "level", ")", ":", "\n", "        ", "if", "level", ">=", "self", ".", "level", ":", "\n", "            ", "present_time", "=", "datetime", ".", "now", "(", ")", "\n", "msg_str", "=", "'%s [%s] %s'", "%", "(", "present_time", ".", "strftime", "(", "'%m/%d/%Y %I:%M:%S %p'", ")", ",", "LOG_LEVELS", ".", "get_name", "(", "level", ")", ",", "msg", ")", "\n", "if", "self", ".", "stdout", ":", "\n", "                ", "print", "(", "msg_str", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "abspath", "(", "self", ".", "log_file_path", ")", ",", "'a+'", ")", "as", "log_file", ":", "\n", "                ", "log_file", ".", "write", "(", "msg_str", "+", "\"\\n\"", ")", "\n", "\n", "", "", "", "@", "rank_zero_only", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.logger.MyLogger.update_log_path": [[52, 58], ["open"], "methods", ["None"], ["def", "info", "(", "self", ",", "msg", ")", ":", "\n", "        ", "self", ".", "_log_msg", "(", "msg", ",", "LOG_LEVELS", ".", "INFO", ")", "\n", "\n", "", "@", "rank_zero_only", "\n", "def", "critical", "(", "self", ",", "msg", ")", ":", "\n", "        ", "self", ".", "_log_msg", "(", "msg", ",", "LOG_LEVELS", ".", "CRITICAL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.logger.MyLogger.info": [[59, 62], ["logger.MyLogger._log_msg"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger._log_msg"], ["", "@", "rank_zero_only", "\n", "def", "debug", "(", "self", ",", "msg", ")", ":", "\n", "        ", "self", ".", "_log_msg", "(", "msg", ",", "LOG_LEVELS", ".", "DEBUG", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.logger.MyLogger.critical": [[63, 66], ["logger.MyLogger._log_msg"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger._log_msg"], ["", "@", "rank_zero_only", "\n", "def", "warn", "(", "self", ",", "msg", ")", ":", "\n", "        ", "self", ".", "_log_msg", "(", "msg", ",", "LOG_LEVELS", ".", "WARN", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.logger.MyLogger.debug": [[67, 70], ["logger.MyLogger._log_msg"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger._log_msg"], ["", "@", "rank_zero_only", "\n", "def", "error", "(", "self", ",", "msg", ")", ":", "\n", "        ", "self", ".", "_log_msg", "(", "msg", ",", "LOG_LEVELS", ".", "ERROR", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.logger.MyLogger.warn": [[71, 74], ["logger.MyLogger._log_msg"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger._log_msg"], ["", "", "def", "logger_wrapper", "(", "logger", ",", "logger_name", ")", ":", "\n", "    ", "if", "isinstance", "(", "logger", ",", "MyLogger", ")", ":", "\n", "        ", "return", "logger", "\n", "", "base_dir", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.logger.MyLogger.error": [[75, 78], ["logger.MyLogger._log_msg"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger._log_msg"], ["log_dir", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "'logs'", ")", "\n", "os", ".", "makedirs", "(", "log_dir", ",", "exist_ok", "=", "True", ")", "\n", "return", "MyLogger", "(", "logger_name", ",", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"%s.log\"", "%", "logger_name", ")", ",", "use_stdout", "=", "True", ",", "overwrite", "=", "True", ")", "", "", ""]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.logger.logger_wrapper": [[79, 86], ["isinstance", "os.path.dirname", "os.path.join", "os.makedirs", "logger.MyLogger", "os.path.realpath", "os.path.join"], "function", ["None"], []], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.dataloader.TextDataset.__init__": [[7, 22], ["utils.load_jsonl", "logger.info", "utils.get_balanced_data", "os.path.basename().split", "os.path.basename", "len"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.load_jsonl", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.get_balanced_data"], ["import", "torch", "\n", "en_tok", "=", "MosesTokenizer", "(", "lang", "=", "\"en\"", ")", "\n", "\n", "\n", "class", "TextDataset", "(", "Dataset", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "prefix", ",", "tokenizer", ",", "filename", ",", "dataset_count", ",", "src_max_seq_len", ",", "tgt_max_seq_len", ",", "script_unification", ",", "logger", ",", "complete_coverage", ",", "sorted_order", "=", "True", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "src_max_seq_len", "=", "src_max_seq_len", "\n", "self", ".", "tgt_max_seq_len", "=", "tgt_max_seq_len", "\n", "self", ".", "dataset", "=", "load_jsonl", "(", "filename", ")", "\n", "if", "complete_coverage", ":", "\n", "            ", "self", ".", "dataset", "=", "[", "x", "for", "x", "in", "self", ".", "dataset", "if", "x", "[", "'complete_coverage'", "]", "==", "1", "]", "\n", "", "self", ".", "logger", "=", "logger", "\n", "self", ".", "prefix", "=", "prefix", "\n", "self", ".", "sorted_order", "=", "sorted_order", "\n", "self", ".", "script_unification", "=", "script_unification", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.dataloader.TextDataset.fact_str": [[19, 21], ["utils.linear_fact_str"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.linear_fact_str"], ["", "self", ".", "logger", "=", "logger", "\n", "self", ".", "prefix", "=", "prefix", "\n", "self", ".", "sorted_order", "=", "sorted_order", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.dataloader.TextDataset.process_text": [[22, 25], ["dataloader.TextDataset.fact_str().strip", "dataloader.TextDataset.fact_str"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.fact_str"], ["self", ".", "script_unification", "=", "script_unification", "\n", "self", ".", "lang_normalizer", "=", "get_language_normalizer", "(", ")", "\n", "if", "dataset_count", ">", "0", ":", "\n", "# retain selected dataset count", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.dataloader.TextDataset.preprocess": [[27, 32], ["dataloader.TextDataset.tokenizer.encode_plus"], "methods", ["None"], ["", "data_type", "=", "os", ".", "path", ".", "basename", "(", "filename", ")", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "if", "self", ".", "script_unification", ":", "\n", "            ", "logger", ".", "critical", "(", "\"%s : script unification to Devanagari is enabled.\"", "%", "data_type", ")", "\n", "", "logger", ".", "info", "(", "\"%s dataset count : %d\"", "%", "(", "data_type", ",", "len", "(", "self", ".", "dataset", ")", ")", ")", "\n", "\n", "", "def", "process_facts", "(", "self", ",", "facts", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.dataloader.TextDataset.__getitem__": [[33, 37], ["dataloader.TextDataset.preprocess", "dataloader.TextDataset.process_nli"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.TextDataset.preprocess", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.TextDataset.process_nli"], ["        ", "\"\"\" linearizes the facts on the encoder side \"\"\"", "\n", "if", "self", ".", "sorted_order", ":", "\n", "            ", "facts", "=", "sorted", "(", "facts", ",", "key", "=", "lambda", "x", ":", "get_relation", "(", "x", "[", "0", "]", ")", ".", "lower", "(", ")", ")", "\n", "", "linearized_facts", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "facts", ")", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.dataloader.TextDataset.__len__": [[38, 40], ["len"], "methods", ["None"], ["            ", "linearized_facts", "+=", "linear_fact_str", "(", "facts", "[", "i", "]", ",", "enable_qualifiers", "=", "True", ")", "\n", "", "processed_facts_str", "=", "' '", ".", "join", "(", "linearized_facts", ")", "\n", "return", "processed_facts_str", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.dataloader.pad_seq": [[41, 43], ["len"], "function", ["None"], ["\n", "", "def", "process_text", "(", "self", ",", "text", ",", "lang", ")", ":", "\n", "        ", "\"\"\" normalize and tokenize and then space join the text \"\"\"", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.dataloader.collate_batch": [[44, 57], ["max", "labels.append", "torch.tensor", "torch.tensor", "torch.tensor", "len", "dataloader.pad_seq", "dataloader.pad_seq"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.pad_seq", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.pad_seq"], ["if", "lang", "==", "'en'", ":", "\n", "            ", "return", "\" \"", ".", "join", "(", "en_tok", ".", "tokenize", "(", "self", ".", "lang_normalizer", "[", "lang", "]", ".", "normalize", "(", "text", ".", "strip", "(", ")", ")", ",", "escape", "=", "False", ")", ")", ".", "strip", "(", ")", "\n", "", "else", ":", "\n", "# return unified script text", "\n", "            ", "if", "self", ".", "script_unification", ":", "\n", "                ", "return", "get_text_in_unified_script", "(", "text", ",", "self", ".", "lang_normalizer", "[", "lang", "]", ",", "lang", ")", "\n", "\n", "# return original text", "\n", "", "return", "\" \"", ".", "join", "(", "\n", "indic_tokenize", ".", "trivial_tokenize", "(", "self", ".", "lang_normalizer", "[", "lang", "]", ".", "normalize", "(", "text", ".", "strip", "(", ")", ")", ",", "lang", ")", "\n", ")", ".", "strip", "(", ")", "\n", "\n", "", "", "def", "preprocess", "(", "self", ",", "text", ",", "max_seq_len", ")", ":", "\n", "        ", "tokenzier_args", "=", "{", "'text'", ":", "text", ",", "'truncation'", ":", "True", ",", "'pad_to_max_length'", ":", "False", ",", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.dataloader.get_dataset_loaders": [[58, 62], ["dataloader.TextDataset", "torch.utils.data.DataLoader", "dataloader.collate_batch"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.collate_batch"], ["'max_length'", ":", "max_seq_len", ",", "'return_attention_mask'", ":", "True", "}", "\n", "tokenized_data", "=", "self", ".", "tokenizer", ".", "encode_plus", "(", "**", "tokenzier_args", ")", "\n", "return", "tokenized_data", "[", "'input_ids'", "]", ",", "tokenized_data", "[", "'attention_mask'", "]", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.utils.store_jsonl": [[24, 29], ["open", "json.dump", "dfile.write"], "function", ["None"], ["'mr'", ":", "{", "\"label\"", ":", "\"Marathi\"", ",", "'id'", ":", "9", "}", ",", "\n", "'kn'", ":", "{", "\"label\"", ":", "\"Kannada\"", ",", "'id'", ":", "10", "}", ",", "\n", "'ta'", ":", "{", "\"label\"", ":", "\"Tamil\"", ",", "'id'", ":", "11", "}", ",", "\n", "'ml'", ":", "{", "\"label\"", ":", "\"Malayalam\"", ",", "'id'", ":", "12", "}", "\n", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.utils.load_jsonl": [[21, 27], ["open", "dfile.readlines", "res.append", "json.loads", "line.strip"], "function", ["None"], ["'or'", ":", "{", "\"label\"", ":", "\"Odia\"", ",", "'id'", ":", "6", "}", ",", "\n", "'as'", ":", "{", "\"label\"", ":", "\"Assamese\"", ",", "'id'", ":", "7", "}", ",", "\n", "'gu'", ":", "{", "\"label\"", ":", "\"Gujarati\"", ",", "'id'", ":", "8", "}", ",", "\n", "'mr'", ":", "{", "\"label\"", ":", "\"Marathi\"", ",", "'id'", ":", "9", "}", ",", "\n", "'kn'", ":", "{", "\"label\"", ":", "\"Kannada\"", ",", "'id'", ":", "10", "}", ",", "\n", "'ta'", ":", "{", "\"label\"", ":", "\"Tamil\"", ",", "'id'", ":", "11", "}", ",", "\n", "'ml'", ":", "{", "\"label\"", ":", "\"Malayalam\"", ",", "'id'", ":", "12", "}", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.utils.handle_multiple_languages": [[37, 50], ["print", "sorted", "x.strip().lower", "sorted.append", "len", "len", "print", "lang.split", "x.strip", "len", "len", "len"], "function", ["None"], ["", "valid_languages", ".", "append", "(", "x", ")", "\n", "", "if", "len", "(", "valid_languages", ")", "!=", "len", "(", "lang_list", ")", ":", "\n", "        ", "print", "(", "\"%d invalid languages identified\"", "%", "(", "len", "(", "lang_list", ")", "-", "len", "(", "valid_languages", ")", ")", ")", "\n", "", "print", "(", "'successfully identified %d langauges: %s'", "%", "(", "len", "(", "valid_languages", ")", ",", "valid_languages", ")", ")", "\n", "valid_languages", "=", "sorted", "(", "valid_languages", ")", "\n", "return", "valid_languages", "\n", "\n", "", "def", "get_language_normalizer", "(", ")", ":", "\n", "    ", "lang_normalizer", "=", "{", "}", "\n", "for", "k", "in", "languages_map", ":", "\n", "        ", "if", "k", "==", "'ur'", ":", "\n", "            ", "lang_normalizer", "[", "k", "]", "=", "urduhack", ".", "normalization", "\n", "", "elif", "k", "==", "'en'", ":", "\n", "            ", "lang_normalizer", "[", "k", "]", "=", "MosesPunctNormalizer", "(", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.utils.get_nodes": [[51, 60], ["unidecode.unidecode.strip", "unidecode.unidecode.replace", "unidecode.unidecode.replace", "unidecode.unidecode.replace", "unidecode.unidecode.replace", "unidecode.unidecode.replace", "unidecode.unidecode"], "function", ["None"], ["", "else", ":", "\n", "            ", "normfactory", "=", "indic_normalize", ".", "IndicNormalizerFactory", "(", ")", "\n", "lang_normalizer", "[", "k", "]", "=", "normfactory", ".", "get_normalizer", "(", "k", ")", "\n", "", "", "return", "lang_normalizer", "\n", "\n", "", "def", "get_id_to_lang", "(", ")", ":", "\n", "    ", "id_to_lang", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "languages_map", ".", "items", "(", ")", ":", "\n", "        ", "id_to_lang", "[", "v", "[", "'id'", "]", "]", "=", "k", "\n", "", "return", "id_to_lang", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.utils.get_relation": [[61, 68], ["n.split.replace", "n.split.replace", "n.split.strip", "n.split.split"], "function", ["None"], ["\n", "", "def", "load_jsonl", "(", "file_path", ")", ":", "\n", "    ", "res", "=", "[", "]", "\n", "with", "open", "(", "file_path", ",", "encoding", "=", "'utf-8'", ")", "as", "dfile", ":", "\n", "        ", "for", "line", "in", "dfile", ".", "readlines", "(", ")", ":", "\n", "            ", "res", ".", "append", "(", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", ")", "\n", "", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.utils.linear_fact_str": [[69, 75], ["get_relation().lower", "get_nodes().lower", "len", "utils.get_relation", "utils.get_nodes", "get_relation().lower", "get_nodes().lower", "utils.get_relation", "utils.get_nodes"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.get_relation", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.get_nodes", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.get_relation", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.get_nodes"], ["", "def", "dataset_exists", "(", "dir_path", ",", "required_files", "=", "[", "'train.jsonl'", ",", "'test.jsonl'", ",", "'val.jsonl'", "]", ")", ":", "\n", "    ", "required_files", "=", "set", "(", "required_files", ")", "\n", "existing_files", "=", "set", "(", ")", "\n", "for", "dfile", "in", "os", ".", "listdir", "(", "os", ".", "path", ".", "abspath", "(", "dir_path", ")", ")", ":", "\n", "        ", "if", "dfile", "in", "required_files", ":", "\n", "            ", "existing_files", ".", "add", "(", "dfile", ")", "\n", "", "", "missing_files", "=", "required_files", ".", "difference", "(", "existing_files", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.utils.merge_dataset_across_languages": [[76, 84], ["random.seed", "random.shuffle", "utils.store_jsonl", "os.path.join", "final_res.extend", "utils.load_jsonl"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.store_jsonl", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.load_jsonl"], ["if", "len", "(", "missing_files", ")", ":", "\n", "        ", "print", "(", "\"%s files are missing, creating the files..\"", "%", "missing_files", ")", "\n", "", "return", "len", "(", "missing_files", ")", "==", "0", "\n", "\n", "", "def", "store_jsonl", "(", "res", ",", "file_path", ")", ":", "\n", "    ", "with", "open", "(", "file_path", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "dfile", ":", "\n", "        ", "for", "item", "in", "res", ":", "\n", "            ", "json", ".", "dump", "(", "item", ",", "dfile", ",", "ensure_ascii", "=", "False", ")", "\n", "dfile", ".", "write", "(", "'\\n'", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.utils.get_balanced_data": [[6, 20], ["collections.defaultdict", "random.shuffle", "logger.debug", "collections.defaultdict.items", "random.shuffle", "logger.debug", "final_dataset.append"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.debug", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.debug"], ["from", "indicnlp", ".", "transliterate", "import", "unicode_transliterate", "\n", "from", "indicnlp", ".", "tokenize", "import", "indic_tokenize", "\n", "from", "sacremoses", "import", "MosesPunctNormalizer", "\n", "from", "sacremoses", "import", "MosesTokenizer", "\n", "import", "urduhack", "\n", "import", "os", "\n", "\n", "\n", "languages_map", "=", "{", "\n", "'en'", ":", "{", "\"label\"", ":", "\"English\"", ",", "'id'", ":", "0", "}", ",", "\n", "'hi'", ":", "{", "\"label\"", ":", "\"Hindi\"", ",", "'id'", ":", "1", "}", ",", "\n", "'te'", ":", "{", "\"label\"", ":", "\"Telugu\"", ",", "'id'", ":", "2", "}", ",", "\n", "'bn'", ":", "{", "\"label\"", ":", "\"Bengali\"", ",", "'id'", ":", "3", "}", ",", "\n", "'pa'", ":", "{", "\"label\"", ":", "\"Punjabi\"", ",", "'id'", ":", "4", "}", ",", "\n", "'ur'", ":", "{", "\"label\"", ":", "\"Urdu\"", ",", "'id'", ":", "5", "}", ",", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.utils.dataset_exists": [[100, 110], ["set", "set", "os.listdir", "set.difference", "len", "os.path.abspath", "print", "len", "set.add"], "function", ["None"], ["", "", "", "def", "get_nodes", "(", "n", ")", ":", "\n", "    ", "n", "=", "n", ".", "strip", "(", ")", "\n", "n", "=", "n", ".", "replace", "(", "'('", ",", "''", ")", "\n", "n", "=", "n", ".", "replace", "(", "'\\\"'", ",", "''", ")", "\n", "n", "=", "n", ".", "replace", "(", "')'", ",", "''", ")", "\n", "n", "=", "n", ".", "replace", "(", "','", ",", "' '", ")", "\n", "n", "=", "n", ".", "replace", "(", "'_'", ",", "' '", ")", "\n", "n", "=", "unidecode", ".", "unidecode", "(", "n", ")", "\n", "return", "n", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_multilingual_encoder_models.dataloader.TextDataset.process_nli": [[23, 26], ["None"], "methods", ["None"], ["self", ".", "lang_normalizer", "=", "get_language_normalizer", "(", ")", "\n", "if", "dataset_count", ">", "0", ":", "\n", "# retain selected dataset count", "\n", "            ", "self", ".", "dataset", "=", "self", ".", "dataset", "[", ":", "dataset_count", "]", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper.__init__": [[44, 57], ["pytorch_lightning.LightningModule.__init__", "transformers.MT5Tokenizer.from_pretrained", "pytorch_lightning.metrics.Accuracy", "transformers.MT5ForConditionalGeneration.from_pretrained", "transformers.MT5ForConditionalGeneration.from_config", "transformers.MT5ForConditionalGeneration.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf.__init__"], ["np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n", "", "def", "count_parameters", "(", "model", ")", ":", "\n", "    ", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n", "", "class", "ModelWrapper", "(", "pl", ".", "LightningModule", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "ModelWrapper", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "step_loss_labels", "=", "{", "'train'", ":", "'loss'", ",", "'val'", ":", "'val_loss'", ",", "'test'", ":", "'test_loss'", "}", "\n", "self", ".", "config_args", "=", "args", "\n", "self", ".", "tokenizer", "=", "MT5Tokenizer", ".", "from_pretrained", "(", "args", ".", "model_name", ",", "cache_dir", "=", "\"/tmp/hugginface\"", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper.forward": [[58, 67], ["main.ModelWrapper.model"], "methods", ["None"], ["self", ".", "add_special_tokens", "(", ")", "\n", "self", ".", "cal_bleu", "=", "BLEU", "(", "tokenize", "=", "'none'", ")", "\n", "self", ".", "lang_normalizer", "=", "get_language_normalizer", "(", ")", "\n", "\n", "if", "args", ".", "use_pretrained", ":", "\n", "# using pretrained transformers", "\n", "            ", "self", ".", "model", "=", "MT5ForConditionalGeneration", ".", "from_pretrained", "(", "args", ".", "model_name", ",", "dropout_rate", "=", "args", ".", "dropout_rate", ",", "cache_dir", "=", "\"/tmp/hugginface\"", ")", "\n", "", "else", ":", "\n", "# training transformer from scratch", "\n", "            ", "self", ".", "model", "=", "MT5ForConditionalGeneration", ".", "from_config", "(", "MT5ForConditionalGeneration", ".", "from_pretrained", "(", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper.configure_optimizers": [[68, 94], ["transformers.Adafactor", "int", "numpy.ceil", "transformers.get_linear_schedule_with_warmup", "main.ModelWrapper.named_parameters", "main.ModelWrapper.named_parameters", "any", "any"], "methods", ["None"], ["args", ".", "model_name", ",", "dropout_rate", "=", "args", ".", "dropout_rate", ",", "cache_dir", "=", "\"/tmp/hugginface\"", ")", ")", "\n", "", "self", ".", "model", ".", "resize_token_embeddings", "(", "len", "(", "self", ".", "tokenizer", ")", ")", "\n", "\n", "", "def", "add_special_tokens", "(", "self", ")", ":", "\n", "        ", "new_tokens", "=", "[", "'<H>'", ",", "'<R>'", ",", "'<T>'", ",", "'<QR>'", ",", "'<QT>'", ",", "'<S>'", "]", "\n", "new_tokens_vocab", "=", "{", "}", "\n", "new_tokens_vocab", "[", "'additional_special_tokens'", "]", "=", "[", "]", "\n", "for", "idx", ",", "t", "in", "enumerate", "(", "new_tokens", ")", ":", "\n", "            ", "new_tokens_vocab", "[", "'additional_special_tokens'", "]", ".", "append", "(", "t", ")", "\n", "", "num_added_toks", "=", "self", ".", "tokenizer", ".", "add_special_tokens", "(", "new_tokens_vocab", ")", "\n", "self", ".", "config_args", ".", "logger", ".", "critical", "(", "'added %s tokens'", "%", "num_added_toks", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "decoder_input_ids", "=", "None", ",", "decoder_attention_mask", "=", "None", ",", "lm_labels", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "model", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "labels", "=", "lm_labels", ",", "\n", "decoder_attention_mask", "=", "decoder_attention_mask", "\n", ")", "\n", "return", "outputs", "\n", "\n", "", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "        ", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "self", ".", "config_args", ".", "weight_decay", "}", ",", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper.get_entailment": [[95, 110], ["main.ModelWrapper.tokenizer.convert_tokens_to_ids", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "main.ModelWrapper.model.generate", "[].argmax().cpu().tolist", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "batch[].to", "batch[].to", "[].argmax().cpu", "[].argmax"], "methods", ["None"], ["{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "\n", "optimizer", "=", "Adafactor", "(", "optimizer_grouped_parameters", ",", "lr", "=", "self", ".", "config_args", ".", "learning_rate", ",", "scale_parameter", "=", "False", ",", "relative_step", "=", "False", ",", "warmup_init", "=", "False", ")", "\n", "# optimizer = torch.optim.Adam(optimizer_grouped_parameters, lr=self.config_args.learning_rate, eps=1e-6)", "\n", "\n", "if", "self", ".", "config_args", ".", "enable_scheduler", ":", "\n", "            ", "total_dataset_count", "=", "self", ".", "config_args", ".", "train_dataset_count", "\n", "total_steps", "=", "int", "(", "np", ".", "ceil", "(", "(", "self", ".", "config_args", ".", "epochs", "*", "total_dataset_count", ")", "/", "\n", "(", "self", ".", "config_args", ".", "batch_size", "*", "self", ".", "config_args", ".", "gpus", ")", ")", ")", "\n", "\n", "scheduler", "=", "{", "\n", "# 'scheduler': get_constant_schedule_with_warmup(optimizer, self.config_args.warmup_steps*total_steps)", "\n", "'scheduler'", ":", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "self", ".", "config_args", ".", "warmup_steps", "*", "total_steps", ",", "total_steps", ")", ",", "\n", "'interval'", ":", "'step'", ",", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper._step": [[111, 148], ["main.ModelWrapper.", "online_logger_data.update", "online_logger_data.update", "main.ModelWrapper.logger.log_metrics", "len", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "step_metric", "main.ModelWrapper.get_entailment", "label_ids.long"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper.get_entailment"], ["}", "\n", "return", "[", "optimizer", "]", ",", "[", "scheduler", "]", "\n", "\n", "", "return", "optimizer", "\n", "\n", "", "def", "ids_to_clean_text", "(", "self", ",", "generated_ids", ",", "remove_special_tokens", "=", "True", ",", "remove_tok_spaces", "=", "True", ")", ":", "\n", "        ", "gen_text", "=", "self", ".", "tokenizer", ".", "batch_decode", "(", "\n", "generated_ids", ",", "skip_special_tokens", "=", "remove_special_tokens", ",", "clean_up_tokenization_spaces", "=", "remove_tok_spaces", "\n", ")", "\n", "return", "list", "(", "map", "(", "str", ".", "strip", ",", "gen_text", ")", ")", "\n", "\n", "", "def", "_generative_step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "generated_ids", "=", "self", ".", "model", ".", "generate", "(", "\n", "batch", "[", "0", "]", ",", "\n", "attention_mask", "=", "batch", "[", "1", "]", ",", "\n", "use_cache", "=", "True", ",", "\n", "num_beams", "=", "self", ".", "config_args", ".", "eval_beams", ",", "\n", "max_length", "=", "self", ".", "config_args", ".", "tgt_max_seq_len", ",", "\n", "length_penalty", "=", "self", ".", "config_args", ".", "length_penalty", ",", "\n", ")", "\n", "\n", "preds", "=", "self", ".", "ids_to_clean_text", "(", "generated_ids", ")", "\n", "target", "=", "self", ".", "ids_to_clean_text", "(", "batch", "[", "2", "]", ")", "\n", "return", "{", "'predicted_txt'", ":", "preds", ",", "'target_txt'", ":", "target", "}", "\n", "\n", "", "def", "_recover_input_text", "(", "self", ",", "input_ids", ")", ":", "\n", "        ", "input_txt", "=", "self", ".", "ids_to_clean_text", "(", "input_ids", ",", "remove_special_tokens", "=", "False", ")", "\n", "processed_input_ids", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "input_txt", ")", ")", ":", "\n", "            ", "final_str", "=", "input_txt", "[", "i", "]", "\n", "# removing model's default special token", "\n", "for", "special_token", "in", "[", "self", ".", "tokenizer", ".", "eos_token", ",", "self", ".", "tokenizer", ".", "pad_token", "]", ":", "\n", "                ", "if", "not", "special_token", ":", "\n", "                    ", "continue", "\n", "", "final_str", "=", "re", ".", "sub", "(", "special_token", ",", "''", ",", "final_str", ")", "\n", "", "input_txt", "[", "i", "]", "=", "final_str", ".", "strip", "(", ")", "\n", "", "return", "input_txt", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper._epoch_end": [[149, 174], ["torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "end_metric.compute", "main.ModelWrapper.config_args.logger.info", "main.ModelWrapper.logger.log_metrics", "main.ModelWrapper.log", "main.ModelWrapper.log", "main.ModelWrapper.config_args.logger.info", "main.ModelWrapper.logger.log_metrics", "main.ModelWrapper.log", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack().mean.item", "torch.stack().mean.item", "torch.stack().mean.item", "end_metric.compute.item", "torch.stack().mean.item", "torch.stack().mean.item", "torch.stack().mean.item"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info"], ["", "def", "_step", "(", "self", ",", "batch", ",", "step_type", ")", ":", "\n", "        ", "lm_labels", "=", "torch", ".", "clone", "(", "batch", "[", "2", "]", ")", "\n", "lm_labels", "[", "lm_labels", "[", ":", ",", ":", "]", "==", "self", ".", "tokenizer", ".", "pad_token_id", "]", "=", "-", "100", "\n", "outputs", "=", "self", "(", "\n", "batch", "[", "0", "]", ",", "\n", "attention_mask", "=", "batch", "[", "1", "]", ",", "\n", "lm_labels", "=", "lm_labels", ",", "\n", "decoder_attention_mask", "=", "batch", "[", "3", "]", "\n", ")", "\n", "return_map", "=", "{", "}", "\n", "online_logger_data", "=", "{", "}", "\n", "return_map", ".", "update", "(", "{", "self", ".", "step_loss_labels", "[", "step_type", "]", ":", "outputs", "[", "0", "]", "}", ")", "\n", "# updating the online logger", "\n", "online_logger_data", ".", "update", "(", "return_map", ")", "\n", "# inserting the predictions and actual text for validation and testing dataset when executing bi-lingual training", "\n", "# inserting the predictions and actual text for test dataset only when executing multi-lingual training", "\n", "if", "step_type", "!=", "'train'", "and", "(", "(", "len", "(", "self", ".", "config_args", ".", "lang", ")", "==", "1", "and", "self", ".", "config_args", ".", "enable_bleu_cal_per_epoch", "==", "1", ")", "or", "step_type", "==", "'test'", ")", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "return_map", ".", "update", "(", "self", ".", "_generative_step", "(", "batch", ")", ")", "\n", "return_map", ".", "update", "(", "{", "'source_txt'", ":", "self", ".", "_recover_input_text", "(", "batch", "[", "0", "]", ")", "}", ")", "\n", "return_map", ".", "update", "(", "{", "'lang_id'", ":", "batch", "[", "4", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "tolist", "(", ")", "}", ")", "\n", "return_map", ".", "update", "(", "{", "'seq_id'", ":", "batch", "[", "5", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "tolist", "(", ")", "}", ")", "\n", "", "", "self", ".", "logger", ".", "log_metrics", "(", "online_logger_data", ")", "\n", "return", "return_map", "\n", "\n", "", "def", "_preprocess_text", "(", "self", ",", "text", ",", "lang", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper.training_step": [[175, 177], ["main.ModelWrapper._step"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper._step"], ["        ", "native_text", "=", "text", "\n", "if", "self", ".", "config_args", ".", "enable_script_unification", ">", "0", "and", "lang", "!=", "'en'", ":", "\n", "# convert unified script to native langauge text", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper.training_epoch_end": [[178, 180], ["main.ModelWrapper._epoch_end"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper._epoch_end"], ["            ", "native_text", "=", "get_native_text_from_unified_script", "(", "text", ",", "lang", ")", "\n", "\n", "", "native_text", "=", "native_text", ".", "strip", "(", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper.validation_step": [[181, 183], ["main.ModelWrapper._step"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper._step"], ["# as input and predicted text are already space tokenized", "\n", "native_text", "=", "' '", ".", "join", "(", "[", "x", "for", "x", "in", "native_text", ".", "split", "(", ")", "]", ")", "\n", "return", "native_text", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper.validation_epoch_end": [[184, 186], ["main.ModelWrapper._epoch_end"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.ModelWrapper._epoch_end"], ["\n", "", "def", "_epoch_end", "(", "self", ",", "step_outputs", ",", "end_type", ")", ":", "\n", "        ", "loss_label", "=", "self", ".", "step_loss_labels", "[", "end_type", "]", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.TextDataModule.__init__": [[189, 193], ["pytorch_lightning.LightningDataModule.__init__", "transformers.MT5Tokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf.__init__"], ["            ", "id_to_lang", "=", "get_id_to_lang", "(", ")", "\n", "src_txt", "=", "[", "]", "\n", "pred_txt", "=", "[", "]", "\n", "ref_txt", "=", "[", "]", "\n", "lang_info", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.TextDataModule._intiate_dataset_merging": [[194, 204], ["logger.critical", "os.path.join", "os.makedirs", "utils.dataset_exists", "os.path.abspath", "logger.info", "utils.merge_dataset_across_languages", "os.path.join", "len"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.critical", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.dataset_exists", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.merge_dataset_across_languages"], ["seq_id", "=", "[", "]", "\n", "for", "z", "in", "step_outputs", ":", "\n", "                ", "src_txt", ".", "extend", "(", "z", "[", "'source_txt'", "]", ")", "\n", "pred_txt", ".", "extend", "(", "z", "[", "'predicted_txt'", "]", ")", "\n", "ref_txt", ".", "extend", "(", "z", "[", "'target_txt'", "]", ")", "\n", "lang_info", ".", "extend", "(", "[", "id_to_lang", "[", "u", "]", "for", "u", "in", "z", "[", "'lang_id'", "]", "]", ")", "\n", "seq_id", ".", "extend", "(", "z", "[", "'seq_id'", "]", ")", "\n", "# normalizing and tokenizing using indic_tokenize", "\n", "", "pred_txt", "=", "[", "self", ".", "_preprocess_text", "(", "x", ",", "l", ")", "for", "x", ",", "l", "in", "zip", "(", "pred_txt", ",", "lang_info", ")", "]", "\n", "ref_txt", "=", "[", "self", ".", "_preprocess_text", "(", "x", ",", "l", ")", "for", "x", ",", "l", "in", "zip", "(", "ref_txt", ",", "lang_info", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.TextDataModule.val_dataloader": [[194, 199], ["os.path.join", "dataloader.get_dataset_loaders", "os.path.abspath"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.get_dataset_loaders"], ["seq_id", "=", "[", "]", "\n", "for", "z", "in", "step_outputs", ":", "\n", "                ", "src_txt", ".", "extend", "(", "z", "[", "'source_txt'", "]", ")", "\n", "pred_txt", ".", "extend", "(", "z", "[", "'predicted_txt'", "]", ")", "\n", "ref_txt", ".", "extend", "(", "z", "[", "'target_txt'", "]", ")", "\n", "lang_info", ".", "extend", "(", "[", "id_to_lang", "[", "u", "]", "for", "u", "in", "z", "[", "'lang_id'", "]", "]", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.TextDataModule.train_dataloader": [[200, 205], ["os.path.join", "dataloader.get_dataset_loaders", "os.path.abspath"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.get_dataset_loaders"], ["seq_id", ".", "extend", "(", "z", "[", "'seq_id'", "]", ")", "\n", "# normalizing and tokenizing using indic_tokenize", "\n", "", "pred_txt", "=", "[", "self", ".", "_preprocess_text", "(", "x", ",", "l", ")", "for", "x", ",", "l", "in", "zip", "(", "pred_txt", ",", "lang_info", ")", "]", "\n", "ref_txt", "=", "[", "self", ".", "_preprocess_text", "(", "x", ",", "l", ")", "for", "x", ",", "l", "in", "zip", "(", "ref_txt", ",", "lang_info", ")", "]", "\n", "\n", "# visual model prediction on wandb", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.random_seed": [[33, 39], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed"], "function", ["None"], ["from", "dataloader", "import", "get_dataset_loaders", "\n", "from", "sacrebleu", ".", "metrics", "import", "BLEU", "\n", "\n", "\n", "base_dir", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", "\n", "from", "sacremoses", "import", "MosesTokenizer", "\n", "en_tok", "=", "MosesTokenizer", "(", "lang", "=", "\"en\"", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.count_parameters": [[40, 42], ["sum", "p.numel", "model.parameters"], "function", ["None"], ["\n", "# allow deterministic psuedo-random-initialization", "\n", "def", "random_seed", "(", "seed", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.get_checkpoint_file": [[228, 244], ["os.listdir", "logger.info", "sorted", "os.path.getmtime", "sorted.append", "len", "os.path.join", "file_name.endswith", "os.path.join", "len"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info"], ["# handling multilingual setting", "\n", "                ", "language_specific_inout", "=", "defaultdict", "(", "lambda", ":", "{", "'pred'", ":", "[", "]", ",", "'ref'", ":", "[", "]", "}", ")", "\n", "for", "lpred", ",", "lref", ",", "llang", "in", "zip", "(", "pred_txt", ",", "ref_txt", ",", "lang_info", ")", ":", "\n", "                    ", "language_specific_inout", "[", "llang", "]", "[", "'pred'", "]", ".", "append", "(", "lpred", ")", "\n", "language_specific_inout", "[", "llang", "]", "[", "'ref'", "]", ".", "append", "(", "lref", ")", "\n", "\n", "", "for", "klang", ",", "vdata", "in", "language_specific_inout", ".", "items", "(", ")", ":", "\n", "                    ", "bleu", "=", "self", ".", "cal_bleu", ".", "corpus_score", "(", "vdata", "[", "'pred'", "]", ",", "[", "vdata", "[", "'ref'", "]", "]", ")", "\n", "self", ".", "config_args", ".", "logger", ".", "info", "(", "\"%s : epoch : %d | %s\"", "%", "(", "klang", ",", "self", ".", "current_epoch", ",", "bleu", ")", ")", "\n", "bleu_list", "=", "list", "(", "map", "(", "float", ",", "bleu", ".", "prec_str", ".", "split", "(", "'/'", ")", ")", ")", "\n", "self", ".", "logger", ".", "log_metrics", "(", "{", "\n", "'%s_overall_%s_bleu'", "%", "(", "klang", ",", "end_type", ")", ":", "bleu", ".", "score", ",", "\n", "'%s_%s_bleu_1'", "%", "(", "klang", ",", "end_type", ")", ":", "bleu_list", "[", "0", "]", ",", "\n", "'%s_%s_bleu_2'", "%", "(", "klang", ",", "end_type", ")", ":", "bleu_list", "[", "1", "]", ",", "\n", "'%s_%s_bleu_3'", "%", "(", "klang", ",", "end_type", ")", ":", "bleu_list", "[", "2", "]", ",", "\n", "'%s_%s_bleu_4'", "%", "(", "klang", ",", "end_type", ")", ":", "bleu_list", "[", "3", "]", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.start_training": [[206, 245], ["args.logger.debug", "os.path.join", "os.makedirs", "main.TextDataModule", "pytorch_lightning.callbacks.ModelCheckpoint", "main.ModelWrapper", "args.logger.debug", "args.logger.info", "pytorch_lightning.Trainer", "args.logger.debug", "pl.Trainer.fit", "args.logger.debug", "main.count_parameters"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.debug", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.debug", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.debug", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.debug", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.main.count_parameters"], ["if", "self", ".", "config_args", ".", "verbose", "and", "(", "(", "len", "(", "self", ".", "config_args", ".", "lang", ")", "==", "1", "and", "self", ".", "config_args", ".", "enable_bleu_cal_per_epoch", "==", "1", ")", "or", "end_type", "==", "'test'", ")", ":", "\n", "                ", "if", "self", ".", "current_epoch", "==", "0", "or", "end_type", "==", "'test'", ":", "\n", "# writing the model generated outputs", "\n", "                    ", "store_txt", "(", "src_txt", ",", "os", ".", "path", ".", "join", "(", "self", ".", "config_args", ".", "verbose_output_dir", ",", "'%s-src.txt'", "%", "end_type", ")", ")", "\n", "store_txt", "(", "ref_txt", ",", "os", ".", "path", ".", "join", "(", "self", ".", "config_args", ".", "verbose_output_dir", ",", "'%s-ref.txt'", "%", "end_type", ")", ")", "\n", "", "store_txt", "(", "pred_txt", ",", "os", ".", "path", ".", "join", "(", "self", ".", "config_args", ".", "verbose_output_dir", ",", "'%s-predicted-epoch-%d.txt'", "%", "(", "end_type", ",", "self", ".", "current_epoch", ")", ")", ")", "\n", "\n", "# calculating the bleu score", "\n", "", "if", "(", "len", "(", "self", ".", "config_args", ".", "lang", ")", "==", "1", "and", "self", ".", "config_args", ".", "enable_bleu_cal_per_epoch", "==", "1", ")", ":", "\n", "# handling bilingual setting", "\n", "                ", "bleu", "=", "self", ".", "cal_bleu", ".", "corpus_score", "(", "pred_txt", ",", "[", "ref_txt", "]", ")", "\n", "self", ".", "config_args", ".", "logger", ".", "info", "(", "\"epoch : %d | %s\"", "%", "(", "self", ".", "current_epoch", ",", "bleu", ")", ")", "\n", "bleu_list", "=", "list", "(", "map", "(", "float", ",", "bleu", ".", "prec_str", ".", "split", "(", "'/'", ")", ")", ")", "\n", "self", ".", "logger", ".", "log_metrics", "(", "{", "\n", "'overall_%s_bleu'", "%", "end_type", ":", "bleu", ".", "score", ",", "\n", "'%s_bleu_1'", "%", "end_type", ":", "bleu_list", "[", "0", "]", ",", "\n", "'%s_bleu_2'", "%", "end_type", ":", "bleu_list", "[", "1", "]", ",", "\n", "'%s_bleu_3'", "%", "end_type", ":", "bleu_list", "[", "2", "]", ",", "\n", "'%s_bleu_4'", "%", "end_type", ":", "bleu_list", "[", "3", "]", "\n", "}", ")", "\n", "self", ".", "log", "(", "'overall_%s_bleu'", "%", "end_type", ",", "bleu", ".", "score", ",", "prog_bar", "=", "True", ")", "\n", "", "else", ":", "\n", "# handling multilingual setting", "\n", "                ", "language_specific_inout", "=", "defaultdict", "(", "lambda", ":", "{", "'pred'", ":", "[", "]", ",", "'ref'", ":", "[", "]", "}", ")", "\n", "for", "lpred", ",", "lref", ",", "llang", "in", "zip", "(", "pred_txt", ",", "ref_txt", ",", "lang_info", ")", ":", "\n", "                    ", "language_specific_inout", "[", "llang", "]", "[", "'pred'", "]", ".", "append", "(", "lpred", ")", "\n", "language_specific_inout", "[", "llang", "]", "[", "'ref'", "]", ".", "append", "(", "lref", ")", "\n", "\n", "", "for", "klang", ",", "vdata", "in", "language_specific_inout", ".", "items", "(", ")", ":", "\n", "                    ", "bleu", "=", "self", ".", "cal_bleu", ".", "corpus_score", "(", "vdata", "[", "'pred'", "]", ",", "[", "vdata", "[", "'ref'", "]", "]", ")", "\n", "self", ".", "config_args", ".", "logger", ".", "info", "(", "\"%s : epoch : %d | %s\"", "%", "(", "klang", ",", "self", ".", "current_epoch", ",", "bleu", ")", ")", "\n", "bleu_list", "=", "list", "(", "map", "(", "float", ",", "bleu", ".", "prec_str", ".", "split", "(", "'/'", ")", ")", ")", "\n", "self", ".", "logger", ".", "log_metrics", "(", "{", "\n", "'%s_overall_%s_bleu'", "%", "(", "klang", ",", "end_type", ")", ":", "bleu", ".", "score", ",", "\n", "'%s_%s_bleu_1'", "%", "(", "klang", ",", "end_type", ")", ":", "bleu_list", "[", "0", "]", ",", "\n", "'%s_%s_bleu_2'", "%", "(", "klang", ",", "end_type", ")", ":", "bleu_list", "[", "1", "]", ",", "\n", "'%s_%s_bleu_3'", "%", "(", "klang", ",", "end_type", ")", ":", "bleu_list", "[", "2", "]", ",", "\n", "'%s_%s_bleu_4'", "%", "(", "klang", ",", "end_type", ")", ":", "bleu_list", "[", "3", "]", "\n", "}", ")", "\n", "self", ".", "log", "(", "'%s_overall_%s_bleu'", "%", "(", "klang", ",", "end_type", ")", ",", "bleu", ".", "score", ",", "prog_bar", "=", "False", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.TextDataset.__init__": [[7, 22], ["utils.load_jsonl", "logger.info", "utils.get_balanced_data", "os.path.basename().split", "os.path.basename", "len"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.load_jsonl", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.get_balanced_data"], ["import", "torch", "\n", "en_tok", "=", "MosesTokenizer", "(", "lang", "=", "\"en\"", ")", "\n", "\n", "\n", "class", "TextDataset", "(", "Dataset", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "prefix", ",", "tokenizer", ",", "filename", ",", "dataset_count", ",", "src_max_seq_len", ",", "tgt_max_seq_len", ",", "script_unification", ",", "logger", ",", "complete_coverage", ",", "sorted_order", "=", "True", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "src_max_seq_len", "=", "src_max_seq_len", "\n", "self", ".", "tgt_max_seq_len", "=", "tgt_max_seq_len", "\n", "self", ".", "dataset", "=", "load_jsonl", "(", "filename", ")", "\n", "if", "complete_coverage", ":", "\n", "            ", "self", ".", "dataset", "=", "[", "x", "for", "x", "in", "self", ".", "dataset", "if", "x", "[", "'complete_coverage'", "]", "==", "1", "]", "\n", "", "self", ".", "logger", "=", "logger", "\n", "self", ".", "prefix", "=", "prefix", "\n", "self", ".", "sorted_order", "=", "sorted_order", "\n", "self", ".", "script_unification", "=", "script_unification", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.TextDataset.process_text": [[28, 30], ["dataloader.TextDataset.fact_str().strip", "dataloader.TextDataset.fact_str"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.fact_str"], ["if", "self", ".", "script_unification", ":", "\n", "            ", "logger", ".", "critical", "(", "\"%s : script unification to Devanagari is enabled.\"", "%", "data_type", ")", "\n", "", "logger", ".", "info", "(", "\"%s dataset count : %d\"", "%", "(", "data_type", ",", "len", "(", "self", ".", "dataset", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.TextDataset.fact_str": [[31, 33], ["utils.linear_fact_str"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.linear_fact_str"], ["\n", "", "def", "process_facts", "(", "self", ",", "facts", ")", ":", "\n", "        ", "\"\"\" linearizes the facts on the encoder side \"\"\"", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.TextDataset.preprocess": [[27, 33], ["dataloader.TextDataset.tokenizer.encode_plus"], "methods", ["None"], ["", "data_type", "=", "os", ".", "path", ".", "basename", "(", "filename", ")", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "if", "self", ".", "script_unification", ":", "\n", "            ", "logger", ".", "critical", "(", "\"%s : script unification to Devanagari is enabled.\"", "%", "data_type", ")", "\n", "", "logger", ".", "info", "(", "\"%s dataset count : %d\"", "%", "(", "data_type", ",", "len", "(", "self", ".", "dataset", ")", ")", ")", "\n", "\n", "", "def", "process_facts", "(", "self", ",", "facts", ")", ":", "\n", "        ", "\"\"\" linearizes the facts on the encoder side \"\"\"", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.TextDataset.__getitem__": [[34, 39], ["dataloader.TextDataset.preprocess", "dataloader.TextDataset.preprocess", "dataloader.TextDataset.process_nli"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.TextDataset.preprocess", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.TextDataset.preprocess", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.TextDataset.process_nli"], ["if", "self", ".", "sorted_order", ":", "\n", "            ", "facts", "=", "sorted", "(", "facts", ",", "key", "=", "lambda", "x", ":", "get_relation", "(", "x", "[", "0", "]", ")", ".", "lower", "(", ")", ")", "\n", "", "linearized_facts", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "facts", ")", ")", ":", "\n", "            ", "linearized_facts", "+=", "linear_fact_str", "(", "facts", "[", "i", "]", ",", "enable_qualifiers", "=", "True", ")", "\n", "", "processed_facts_str", "=", "' '", ".", "join", "(", "linearized_facts", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.TextDataset.__len__": [[40, 42], ["len"], "methods", ["None"], ["return", "processed_facts_str", "\n", "\n", "", "def", "process_text", "(", "self", ",", "text", ",", "lang", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.pad_seq": [[49, 51], ["len"], "function", ["None"], ["                ", "return", "get_text_in_unified_script", "(", "text", ",", "self", ".", "lang_normalizer", "[", "lang", "]", ",", "lang", ")", "\n", "\n", "# return original text", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.collate_batch": [[52, 68], ["max", "max", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len", "dataloader.pad_seq", "dataloader.pad_seq", "dataloader.pad_seq", "dataloader.pad_seq"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.pad_seq", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.pad_seq", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.pad_seq", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.pad_seq"], ["", "return", "\" \"", ".", "join", "(", "\n", "indic_tokenize", ".", "trivial_tokenize", "(", "self", ".", "lang_normalizer", "[", "lang", "]", ".", "normalize", "(", "text", ".", "strip", "(", ")", ")", ",", "lang", ")", "\n", ")", ".", "strip", "(", ")", "\n", "\n", "", "", "def", "preprocess", "(", "self", ",", "text", ",", "max_seq_len", ")", ":", "\n", "        ", "tokenzier_args", "=", "{", "'text'", ":", "text", ",", "'truncation'", ":", "True", ",", "'pad_to_max_length'", ":", "False", ",", "\n", "'max_length'", ":", "max_seq_len", ",", "'return_attention_mask'", ":", "True", "}", "\n", "tokenized_data", "=", "self", ".", "tokenizer", ".", "encode_plus", "(", "**", "tokenzier_args", ")", "\n", "return", "tokenized_data", "[", "'input_ids'", "]", ",", "tokenized_data", "[", "'attention_mask'", "]", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "prefix_str", "=", "''", "\n", "data_instance", "=", "self", ".", "dataset", "[", "idx", "]", "\n", "lang_iso", "=", "data_instance", "[", "'lang'", "]", ".", "strip", "(", ")", ".", "lower", "(", ")", "\n", "lang_id", "=", "languages_map", "[", "lang_iso", "]", "[", "'id'", "]", "\n", "if", "self", ".", "prefix", ":", "\n", "            ", "prefix_str", "=", "\"generate  %s : \"", "%", "languages_map", "[", "lang_iso", "]", "[", "'label'", "]", ".", "lower", "(", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.get_dataset_loaders": [[43, 47], ["dataloader.TextDataset", "torch.utils.data.DataLoader"], "function", ["None"], ["        ", "\"\"\" normalize and tokenize and then space join the text \"\"\"", "\n", "if", "lang", "==", "'en'", ":", "\n", "            ", "return", "\" \"", ".", "join", "(", "en_tok", ".", "tokenize", "(", "self", ".", "lang_normalizer", "[", "lang", "]", ".", "normalize", "(", "text", ".", "strip", "(", ")", ")", ",", "escape", "=", "False", ")", ")", ".", "strip", "(", ")", "\n", "", "else", ":", "\n", "# return unified script text", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.store_jsonl": [[28, 33], ["open", "json.dump", "dfile.write"], "function", ["None"], ["}", "\n", "\n", "def", "handle_multiple_languages", "(", "lang", ")", ":", "\n", "# check if multiple \",\" separated entries exists.", "\n", "    ", "lang_list", "=", "[", "x", ".", "strip", "(", ")", ".", "lower", "(", ")", "for", "x", "in", "lang", ".", "split", "(", "','", ")", "]", "\n", "valid_languages", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.load_jsonl": [[21, 27], ["open", "dfile.readlines", "res.append", "json.loads", "line.strip"], "function", ["None"], ["'or'", ":", "{", "\"label\"", ":", "\"Odia\"", ",", "'id'", ":", "6", "}", ",", "\n", "'as'", ":", "{", "\"label\"", ":", "\"Assamese\"", ",", "'id'", ":", "7", "}", ",", "\n", "'gu'", ":", "{", "\"label\"", ":", "\"Gujarati\"", ",", "'id'", ":", "8", "}", ",", "\n", "'mr'", ":", "{", "\"label\"", ":", "\"Marathi\"", ",", "'id'", ":", "9", "}", ",", "\n", "'kn'", ":", "{", "\"label\"", ":", "\"Kannada\"", ",", "'id'", ":", "10", "}", ",", "\n", "'ta'", ":", "{", "\"label\"", ":", "\"Tamil\"", ",", "'id'", ":", "11", "}", ",", "\n", "'ml'", ":", "{", "\"label\"", ":", "\"Malayalam\"", ",", "'id'", ":", "12", "}", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.handle_multiple_languages": [[41, 54], ["print", "sorted", "x.strip().lower", "sorted.append", "len", "len", "print", "lang.split", "x.strip", "len", "len", "len"], "function", ["None"], ["valid_languages", "=", "sorted", "(", "valid_languages", ")", "\n", "return", "valid_languages", "\n", "\n", "", "def", "get_language_normalizer", "(", ")", ":", "\n", "    ", "lang_normalizer", "=", "{", "}", "\n", "for", "k", "in", "languages_map", ":", "\n", "        ", "if", "k", "==", "'ur'", ":", "\n", "            ", "lang_normalizer", "[", "k", "]", "=", "urduhack", ".", "normalization", "\n", "", "elif", "k", "==", "'en'", ":", "\n", "            ", "lang_normalizer", "[", "k", "]", "=", "MosesPunctNormalizer", "(", ")", "\n", "", "else", ":", "\n", "            ", "normfactory", "=", "indic_normalize", ".", "IndicNormalizerFactory", "(", ")", "\n", "lang_normalizer", "[", "k", "]", "=", "normfactory", ".", "get_normalizer", "(", "k", ")", "\n", "", "", "return", "lang_normalizer", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.get_language_normalizer": [[55, 64], ["sacremoses.MosesPunctNormalizer", "indicnlp.normalize.indic_normalize.IndicNormalizerFactory", "indic_normalize.IndicNormalizerFactory.get_normalizer"], "function", ["None"], ["\n", "", "def", "get_id_to_lang", "(", ")", ":", "\n", "    ", "id_to_lang", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "languages_map", ".", "items", "(", ")", ":", "\n", "        ", "id_to_lang", "[", "v", "[", "'id'", "]", "]", "=", "k", "\n", "", "return", "id_to_lang", "\n", "\n", "", "def", "load_jsonl", "(", "file_path", ")", ":", "\n", "    ", "res", "=", "[", "]", "\n", "with", "open", "(", "file_path", ",", "encoding", "=", "'utf-8'", ")", "as", "dfile", ":", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.get_nodes": [[65, 74], ["unidecode.unidecode.strip", "unidecode.unidecode.replace", "unidecode.unidecode.replace", "unidecode.unidecode.replace", "unidecode.unidecode.replace", "unidecode.unidecode.replace", "unidecode.unidecode"], "function", ["None"], ["        ", "for", "line", "in", "dfile", ".", "readlines", "(", ")", ":", "\n", "            ", "res", ".", "append", "(", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", ")", "\n", "", "", "return", "res", "\n", "\n", "", "def", "dataset_exists", "(", "dir_path", ",", "required_files", "=", "[", "'train.jsonl'", ",", "'test.jsonl'", ",", "'val.jsonl'", "]", ")", ":", "\n", "    ", "required_files", "=", "set", "(", "required_files", ")", "\n", "existing_files", "=", "set", "(", ")", "\n", "for", "dfile", "in", "os", ".", "listdir", "(", "os", ".", "path", ".", "abspath", "(", "dir_path", ")", ")", ":", "\n", "        ", "if", "dfile", "in", "required_files", ":", "\n", "            ", "existing_files", ".", "add", "(", "dfile", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.get_relation": [[75, 82], ["n.split.replace", "n.split.replace", "n.split.strip", "n.split.split"], "function", ["None"], ["", "", "missing_files", "=", "required_files", ".", "difference", "(", "existing_files", ")", "\n", "if", "len", "(", "missing_files", ")", ":", "\n", "        ", "print", "(", "\"%s files are missing, creating the files..\"", "%", "missing_files", ")", "\n", "", "return", "len", "(", "missing_files", ")", "==", "0", "\n", "\n", "", "def", "store_jsonl", "(", "res", ",", "file_path", ")", ":", "\n", "    ", "with", "open", "(", "file_path", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "dfile", ":", "\n", "        ", "for", "item", "in", "res", ":", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.linear_fact_str": [[83, 89], ["get_relation().lower", "get_nodes().lower", "len", "utils.get_relation", "utils.get_nodes", "get_relation().lower", "get_nodes().lower", "utils.get_relation", "utils.get_nodes"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.get_relation", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.get_nodes", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.get_relation", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.get_nodes"], ["            ", "json", ".", "dump", "(", "item", ",", "dfile", ",", "ensure_ascii", "=", "False", ")", "\n", "dfile", ".", "write", "(", "'\\n'", ")", "\n", "\n", "", "", "", "def", "merge_dataset_across_languages", "(", "dataset_dir", ",", "languages", ",", "dataset_type", ",", "merged_file", ")", ":", "\n", "    ", "final_res", "=", "[", "]", "\n", "for", "lang", "in", "languages", ":", "\n", "        ", "file_path", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "lang", ",", "\"%s.jsonl\"", "%", "dataset_type", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.merge_dataset_across_languages": [[90, 98], ["random.seed", "random.shuffle", "utils.store_jsonl", "os.path.join", "final_res.extend", "utils.load_jsonl"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.store_jsonl", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.load_jsonl"], ["final_res", ".", "extend", "(", "load_jsonl", "(", "file_path", ")", ")", "\n", "", "random", ".", "seed", "(", "42", ")", "\n", "random", ".", "shuffle", "(", "final_res", ")", "\n", "store_jsonl", "(", "final_res", ",", "merged_file", ")", "\n", "\n", "", "def", "store_txt", "(", "res", ",", "file_path", ")", ":", "\n", "    ", "with", "open", "(", "file_path", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "dfile", ":", "\n", "        ", "for", "item", "in", "res", ":", "\n", "            ", "dfile", ".", "write", "(", "\"%s\\n\"", "%", "item", ".", "strip", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.get_balanced_data": [[6, 20], ["collections.defaultdict", "random.shuffle", "logger.debug", "collections.defaultdict.items", "random.shuffle", "logger.debug", "final_dataset.append"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.debug", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.debug"], ["from", "indicnlp", ".", "transliterate", "import", "unicode_transliterate", "\n", "from", "indicnlp", ".", "tokenize", "import", "indic_tokenize", "\n", "from", "sacremoses", "import", "MosesPunctNormalizer", "\n", "from", "sacremoses", "import", "MosesTokenizer", "\n", "import", "urduhack", "\n", "import", "os", "\n", "\n", "\n", "languages_map", "=", "{", "\n", "'en'", ":", "{", "\"label\"", ":", "\"English\"", ",", "'id'", ":", "0", "}", ",", "\n", "'hi'", ":", "{", "\"label\"", ":", "\"Hindi\"", ",", "'id'", ":", "1", "}", ",", "\n", "'te'", ":", "{", "\"label\"", ":", "\"Telugu\"", ",", "'id'", ":", "2", "}", ",", "\n", "'bn'", ":", "{", "\"label\"", ":", "\"Bengali\"", ",", "'id'", ":", "3", "}", ",", "\n", "'pa'", ":", "{", "\"label\"", ":", "\"Punjabi\"", ",", "'id'", ":", "4", "}", ",", "\n", "'ur'", ":", "{", "\"label\"", ":", "\"Urdu\"", ",", "'id'", ":", "5", "}", ",", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.utils.dataset_exists": [[114, 124], ["set", "set", "os.listdir", "set.difference", "len", "os.path.abspath", "print", "len", "set.add"], "function", ["None"], ["n", "=", "n", ".", "strip", "(", ")", "\n", "n", "=", "n", ".", "split", "(", ")", "\n", "n", "=", "\"_\"", ".", "join", "(", "n", ")", "\n", "return", "n", "\n", "\n", "\n", "", "def", "linear_fact_str", "(", "fact", ",", "enable_qualifiers", "=", "False", ")", ":", "\n", "    ", "fact_str", "=", "[", "'<R>'", ",", "get_relation", "(", "fact", "[", "0", "]", ")", ".", "lower", "(", ")", ",", "'<T>'", ",", "get_nodes", "(", "fact", "[", "1", "]", ")", ".", "lower", "(", ")", "]", "\n", "qualifier_str", "=", "[", "' '", ".", "join", "(", "[", "'<QR>'", ",", "get_relation", "(", "x", "[", "0", "]", ")", ".", "lower", "(", ")", ",", "'<QT>'", ",", "get_nodes", "(", "x", "[", "1", "]", ")", ".", "lower", "(", ")", "]", ")", "for", "x", "in", "fact", "[", "2", "]", "]", "\n", "if", "enable_qualifiers", "and", "len", "(", "fact", "[", "2", "]", ")", ">", "0", ":", "\n", "        ", "fact_str", "+=", "[", "' '", ".", "join", "(", "qualifier_str", ")", "]", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.LOG_LEVELS.get_name": [[14, 28], ["None"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "get_name", "(", "level", ")", ":", "\n", "        ", "if", "level", "==", "1", ":", "\n", "            ", "return", "'DEBUG'", "\n", "", "elif", "level", "==", "2", ":", "\n", "            ", "return", "'INFO'", "\n", "", "elif", "level", "==", "3", ":", "\n", "            ", "return", "'WARN'", "\n", "", "elif", "level", "==", "4", ":", "\n", "            ", "return", "'CRITICAL'", "\n", "", "elif", "level", "==", "5", ":", "\n", "            ", "return", "'ERROR'", "\n", "", "else", ":", "\n", "            ", "return", "'UNKNOWN'", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.__init__": [[30, 40], ["open"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "log_file_path", ",", "use_stdout", "=", "False", ",", "overwrite", "=", "True", ",", "log_level", "=", "LOG_LEVELS", ".", "DEBUG", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "log_file_path", "=", "log_file_path", "\n", "self", ".", "stdout", "=", "use_stdout", "\n", "self", ".", "level", "=", "log_level", "\n", "#only zero rank process can truncate the file", "\n", "if", "overwrite", "and", "rank_zero_only", ".", "rank", "==", "0", ":", "\n", "#truncate the file", "\n", "            ", "with", "open", "(", "self", ".", "log_file_path", ",", "'w'", ")", "as", "log_file", ":", "\n", "                ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger._log_msg": [[41, 50], ["datetime.datetime.datetime.now", "print", "open", "log_file.write", "datetime.datetime.now.strftime", "logger.LOG_LEVELS.get_name", "os.path.abspath"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.LOG_LEVELS.get_name"], ["", "", "", "@", "rank_zero_only", "\n", "def", "_log_msg", "(", "self", ",", "msg", ",", "level", ")", ":", "\n", "        ", "if", "level", ">=", "self", ".", "level", ":", "\n", "            ", "present_time", "=", "datetime", ".", "now", "(", ")", "\n", "msg_str", "=", "'%s [%s] %s'", "%", "(", "present_time", ".", "strftime", "(", "'%m/%d/%Y %I:%M:%S %p'", ")", ",", "LOG_LEVELS", ".", "get_name", "(", "level", ")", ",", "msg", ")", "\n", "if", "self", ".", "stdout", ":", "\n", "                ", "print", "(", "msg_str", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "abspath", "(", "self", ".", "log_file_path", ")", ",", "'a+'", ")", "as", "log_file", ":", "\n", "                ", "log_file", ".", "write", "(", "msg_str", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info": [[51, 54], ["logger.MyLogger._log_msg"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger._log_msg"], ["", "", "", "@", "rank_zero_only", "\n", "def", "info", "(", "self", ",", "msg", ")", ":", "\n", "        ", "self", ".", "_log_msg", "(", "msg", ",", "LOG_LEVELS", ".", "INFO", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.critical": [[55, 58], ["logger.MyLogger._log_msg"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger._log_msg"], ["", "@", "rank_zero_only", "\n", "def", "critical", "(", "self", ",", "msg", ")", ":", "\n", "        ", "self", ".", "_log_msg", "(", "msg", ",", "LOG_LEVELS", ".", "CRITICAL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.debug": [[59, 62], ["logger.MyLogger._log_msg"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger._log_msg"], ["", "@", "rank_zero_only", "\n", "def", "debug", "(", "self", ",", "msg", ")", ":", "\n", "        ", "self", ".", "_log_msg", "(", "msg", ",", "LOG_LEVELS", ".", "DEBUG", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.warn": [[63, 66], ["logger.MyLogger._log_msg"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger._log_msg"], ["", "@", "rank_zero_only", "\n", "def", "warn", "(", "self", ",", "msg", ")", ":", "\n", "        ", "self", ".", "_log_msg", "(", "msg", ",", "LOG_LEVELS", ".", "WARN", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.error": [[67, 70], ["logger.MyLogger._log_msg"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger._log_msg"], ["", "@", "rank_zero_only", "\n", "def", "error", "(", "self", ",", "msg", ")", ":", "\n", "        ", "self", ".", "_log_msg", "(", "msg", ",", "LOG_LEVELS", ".", "ERROR", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.logger_wrapper": [[71, 78], ["isinstance", "os.path.dirname", "os.path.join", "os.makedirs", "logger.MyLogger", "os.path.realpath", "os.path.join"], "function", ["None"], ["", "", "def", "logger_wrapper", "(", "logger", ",", "logger_name", ")", ":", "\n", "    ", "if", "isinstance", "(", "logger", ",", "MyLogger", ")", ":", "\n", "        ", "return", "logger", "\n", "", "base_dir", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "'logs'", ")", "\n", "os", ".", "makedirs", "(", "log_dir", ",", "exist_ok", "=", "True", ")", "\n", "return", "MyLogger", "(", "logger_name", ",", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"%s.log\"", "%", "logger_name", ")", ",", "use_stdout", "=", "True", ",", "overwrite", "=", "True", ")", "", "", ""]], "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.dataloader.TextDataset.process_nli": [[23, 26], ["None"], "methods", ["None"], ["self", ".", "lang_normalizer", "=", "get_language_normalizer", "(", ")", "\n", "if", "dataset_count", ">", "0", ":", "\n", "# retain selected dataset count", "\n", "            ", "self", ".", "dataset", "=", "self", ".", "dataset", "[", ":", "dataset_count", "]", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.fact_str": [[24, 30], ["fact_str.extend"], "function", ["None"], ["def", "fact_str", "(", "fact", ",", "enable_qualifiers", "=", "False", ")", ":", "\n", "    ", "fact_str", "=", "fact", "[", "0", ":", "2", "]", "\n", "qualifier_str", "=", "[", "' | '", ".", "join", "(", "x", ")", "for", "x", "in", "fact", "[", "2", "]", "]", "\n", "if", "enable_qualifiers", ":", "\n", "        ", "fact_str", ".", "extend", "(", "qualifier_str", ")", "\n", "", "return", "fact_str", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.get_tfidf_edge_score": [[31, 39], ["range", "len", "tfidf_scorer.get_scores", "enumerate", "stage-I-aligner.fact_str", "edge_scores.append"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf.get_scores", "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.fact_str"], ["", "def", "get_tfidf_edge_score", "(", "tfidf_scorer", ",", "tsentences", ",", "tfacts", ",", "enable_qualifers", "=", "False", ")", ":", "\n", "    ", "edge_scores", "=", "[", "]", "\n", "processed_facts", "=", "[", "' '", ".", "join", "(", "fact_str", "(", "x", ",", "enable_qualifiers", "=", "enable_qualifers", ")", ")", "for", "x", "in", "tfacts", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "tsentences", ")", ")", ":", "\n", "        ", "scores", "=", "tfidf_scorer", ".", "get_scores", "(", "tsentences", "[", "i", "]", ",", "processed_facts", ")", "\n", "for", "j", ",", "k", "in", "enumerate", "(", "scores", ")", ":", "\n", "            ", "edge_scores", ".", "append", "(", "[", "i", ",", "j", ",", "k", "]", ")", "\n", "", "", "return", "edge_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.pooled_rep": [[40, 56], ["attention_mask.unsqueeze().expand().float", "torch.sum", "torch.sum", "torch.clamp", "torch.clamp", "attention_mask.unsqueeze().expand().float.sum", "attention_mask.unsqueeze().expand().float", "torch.sum", "torch.sum", "Exception", "attention_mask.unsqueeze().expand", "token_embeddings.size", "attention_mask.unsqueeze().expand", "attention_mask.unsqueeze", "token_embeddings.size", "attention_mask.unsqueeze"], "function", ["None"], ["", "def", "pooled_rep", "(", "model_output", ",", "attention_mask", ",", "reduce", "=", "'cls'", ")", ":", "\n", "    ", "if", "reduce", "==", "'cls'", ":", "\n", "        ", "return", "model_output", "[", ":", ",", "0", ",", ":", "]", "\n", "", "elif", "reduce", "==", "\"mean\"", ":", "\n", "        ", "token_embeddings", "=", "model_output", "#First element of model_output contains all token embeddings", "\n", "input_mask_expanded", "=", "attention_mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "token_embeddings", ".", "size", "(", ")", ")", ".", "float", "(", ")", "\n", "sum_embeddings", "=", "torch", ".", "sum", "(", "token_embeddings", "*", "input_mask_expanded", ",", "1", ")", "\n", "sum_mask", "=", "torch", ".", "clamp", "(", "input_mask_expanded", ".", "sum", "(", "1", ")", ",", "min", "=", "1e-9", ")", "\n", "return", "sum_embeddings", "/", "sum_mask", "\n", "", "elif", "reduce", "==", "'sum'", ":", "\n", "        ", "token_embeddings", "=", "model_output", "#First element of model_output contains all token embeddings", "\n", "input_mask_expanded", "=", "attention_mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "token_embeddings", ".", "size", "(", ")", ")", ".", "float", "(", ")", "\n", "sum_embeddings", "=", "torch", ".", "sum", "(", "token_embeddings", "*", "input_mask_expanded", ",", "1", ")", "\n", "return", "sum_embeddings", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "'reduce function not present !!!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.encode_in_batches": [[57, 68], ["torch.cat", "torch.cat", "torch.no_grad", "torch.no_grad", "torch.utils.data.TensorDataset", "torch.utils.data.DataLoader", "temp.append", "torch.utils.data.SequentialSampler", "model", "batch[].to", "batch[].to"], "function", ["None"], ["", "", "def", "encode_in_batches", "(", "model", ",", "input_ids", ",", "attention_mask", ",", "batch_size", "=", "32", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "dataset", "=", "TensorDataset", "(", "input_ids", ",", "attention_mask", ")", "\n", "dataloader", "=", "DataLoader", "(", "\n", "dataset", ",", "sampler", "=", "SequentialSampler", "(", "dataset", ")", ",", "batch_size", "=", "batch_size", ")", "\n", "temp", "=", "[", "]", "\n", "for", "batch", "in", "dataloader", ":", "\n", "            ", "temp_out", "=", "model", "(", "batch", "[", "0", "]", ".", "to", "(", "\n", "device", ")", ",", "batch", "[", "1", "]", ".", "to", "(", "device", ")", ")", "[", "0", "]", "\n", "temp", ".", "append", "(", "temp_out", ")", "\n", "", "", "return", "torch", ".", "cat", "(", "temp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.get_edge_scores": [[69, 91], ["torch.no_grad", "torch.no_grad", "tokenizer.batch_encode_plus", "stage-I-aligner.encode_in_batches", "stage-I-aligner.pooled_rep", "tokenizer.batch_encode_plus", "stage-I-aligner.encode_in_batches", "stage-I-aligner.pooled_rep", "range", "enc[].to", "fenc[].to", "len", "torch.cosine_similarity().cpu().tolist", "enumerate", "stage-I-aligner.fact_str", "edge_scores.append", "torch.cosine_similarity().cpu", "torch.cosine_similarity", "sentence_encoding[].unsqueeze"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.encode_in_batches", "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.pooled_rep", "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.encode_in_batches", "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.pooled_rep", "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.fact_str"], ["", "def", "get_edge_scores", "(", "model", ",", "tokenizer", ",", "tsentences", ",", "tfacts", ",", "reduce", "=", "'cls'", ")", ":", "\n", "    ", "res", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "enc", "=", "tokenizer", ".", "batch_encode_plus", "(", "tsentences", ",", "truncation", "=", "True", ",", "padding", "=", "'max_length'", ",", "max_length", "=", "512", ",", "return_attention_mask", "=", "True", ",", "return_tensors", "=", "'pt'", ")", "\n", "#taking the [CLS] token", "\n", "# s_out = model(input_ids=enc[\"input_ids\"].to(device), attention_mask=enc[\"attention_mask\"].to(device))[0]", "\n", "s_out", "=", "encode_in_batches", "(", "model", ",", "enc", "[", "\"input_ids\"", "]", ",", "attention_mask", "=", "enc", "[", "\"attention_mask\"", "]", ")", "\n", "sentence_encoding", "=", "pooled_rep", "(", "s_out", ",", "enc", "[", "\"attention_mask\"", "]", ".", "to", "(", "device", ")", ",", "reduce", "=", "reduce", ")", "\n", "\n", "processed_facts", "=", "[", "' | '", ".", "join", "(", "fact_str", "(", "x", ",", "enable_qualifiers", "=", "True", ")", ")", "for", "x", "in", "tfacts", "]", "\n", "fenc", "=", "tokenizer", ".", "batch_encode_plus", "(", "processed_facts", ",", "truncation", "=", "True", ",", "padding", "=", "'max_length'", ",", "max_length", "=", "512", ",", "return_attention_mask", "=", "True", ",", "return_tensors", "=", "'pt'", ")", "\n", "# f_out = model(input_ids=fenc[\"input_ids\"].to(device), attention_mask=fenc[\"attention_mask\"].to(device))[0]", "\n", "f_out", "=", "encode_in_batches", "(", "model", ",", "fenc", "[", "\"input_ids\"", "]", ",", "attention_mask", "=", "fenc", "[", "\"attention_mask\"", "]", ")", "\n", "facts_encoding", "=", "pooled_rep", "(", "f_out", ",", "fenc", "[", "\"attention_mask\"", "]", ".", "to", "(", "device", ")", ",", "reduce", "=", "reduce", ")", "\n", "\n", "edge_scores", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "tsentences", ")", ")", ":", "\n", "            ", "scores", "=", "F", ".", "cosine_similarity", "(", "facts_encoding", ",", "sentence_encoding", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "1", ",", "1e-6", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "for", "j", ",", "k", "in", "enumerate", "(", "scores", ")", ":", "\n", "                ", "edge_scores", ".", "append", "(", "[", "i", ",", "j", ",", "k", "]", ")", "\n", "\n", "", "", "return", "edge_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.predict_edges": [[92, 117], ["stage-I-aligner.get_tfidf_edge_score", "stage-I-aligner.get_tfidf_edge_score", "stage-I-aligner.get_edge_scores", "stage-I-aligner.get_edge_scores", "collections.defaultdict", "range", "min", "sorted", "hybrid_scores.append", "numpy.mean", "int", "res.append", "collections.defaultdict", "len", "len", "len", "len", "numpy.mean", "len"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.get_tfidf_edge_score", "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.get_tfidf_edge_score", "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.get_edge_scores", "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.get_edge_scores"], ["", "", "def", "predict_edges", "(", "model", ",", "tokenizer", ",", "tf_en_scorer", ",", "tf_native_scorer", ",", "tsentences", ",", "translated_sents", ",", "tfacts", ",", "translated_facts", ",", "reduce", "=", "'cls'", ",", "threshold", "=", "1.0", ",", "max_edge_count", "=", "None", ")", ":", "\n", "\n", "    ", "src_syntactic_scores", "=", "get_tfidf_edge_score", "(", "tf_native_scorer", ",", "tsentences", ",", "translated_facts", ")", "\n", "tgt_syntactic_scores", "=", "get_tfidf_edge_score", "(", "tf_en_scorer", ",", "translated_sents", ",", "tfacts", ",", "enable_qualifers", "=", "True", ")", "\n", "\n", "fwd_semantic_scores", "=", "get_edge_scores", "(", "model", ",", "tokenizer", ",", "tsentences", ",", "tfacts", ",", "reduce", "=", "reduce", ")", "\n", "bwd_semantic_scores", "=", "get_edge_scores", "(", "model", ",", "tokenizer", ",", "translated_sents", ",", "translated_facts", ",", "reduce", "=", "reduce", ")", "\n", "\n", "hybrid_scores", "=", "[", "]", "\n", "hybrid_scores_map", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "lambda", ":", "0", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "tsentences", ")", "*", "len", "(", "tfacts", ")", ")", ":", "\n", "# tgt_syntactic_scores[i] + src_syntactic_scores[i] + ", "\n", "        ", "final_score", "=", "[", "src_syntactic_scores", "[", "i", "]", "[", "2", "]", ",", "tgt_syntactic_scores", "[", "i", "]", "[", "2", "]", ",", "fwd_semantic_scores", "[", "i", "]", "[", "2", "]", ",", "bwd_semantic_scores", "[", "i", "]", "[", "2", "]", "]", "\n", "hybrid_scores", ".", "append", "(", "[", "tgt_syntactic_scores", "[", "i", "]", "[", "0", "]", ",", "tgt_syntactic_scores", "[", "i", "]", "[", "1", "]", ",", "np", ".", "mean", "(", "final_score", ")", "]", ")", "\n", "hybrid_scores_map", "[", "tgt_syntactic_scores", "[", "i", "]", "[", "0", "]", "]", "[", "tgt_syntactic_scores", "[", "i", "]", "[", "1", "]", "]", "=", "np", ".", "mean", "(", "final_score", ")", "\n", "\n", "", "res", "=", "[", "]", "\n", "max_edge_count", "=", "max_edge_count", "if", "max_edge_count", "else", "len", "(", "tsentences", ")", "*", "len", "(", "tfacts", ")", "\n", "max_edges", "=", "min", "(", "int", "(", "threshold", "*", "len", "(", "hybrid_scores", ")", ")", ",", "max_edge_count", ")", "\n", "for", "u", "in", "sorted", "(", "hybrid_scores", ",", "key", "=", "lambda", "x", ":", "x", "[", "2", "]", ",", "reverse", "=", "True", ")", ":", "\n", "        ", "if", "max_edges", "<", "1", ":", "\n", "            ", "break", "\n", "", "res", ".", "append", "(", "u", ")", "\n", "max_edges", "-=", "1", "\n", "", "return", "res", ",", "hybrid_scores_map", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.word_stemmer": [[121, 127], ["set", "set.add", "stemmer.stem", "z.strip", "x.split"], "function", ["None"], ["def", "word_stemmer", "(", "list_str", ")", ":", "\n", "    ", "res", "=", "set", "(", ")", "\n", "for", "x", "in", "list_str", ":", "\n", "        ", "temp", "=", "' '", ".", "join", "(", "[", "stemmer", ".", "stem", "(", "z", ".", "strip", "(", ")", ")", "for", "z", "in", "x", ".", "split", "(", ")", "]", ")", "\n", "res", ".", "add", "(", "temp", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.custom_fact_filter": [[128, 153], ["set", "set", "stage-I-aligner.word_stemmer", "set", "x[].strip", "x[].strip", "x[].strip", "x[].strip", "x[].strip", "x[].strip", "x[].strip", "stemmer.stem", "z.strip", "x[].split"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.word_stemmer"], ["", "def", "custom_fact_filter", "(", "x", ",", "fact_list", ")", ":", "\n", "    ", "useless_predicates", "=", "[", "'entity_name'", ",", "'instance of'", ",", "'sex or gender'", ",", "'given name'", ",", "'family name'", ",", "\"described by source\"", ",", "\"on focus list of Wikimedia project\"", ",", "\"different from\"", ",", "\"topic's main category\"", "]", "\n", "# fetch country of citizenship first", "\n", "nationality", "=", "set", "(", "[", "x", "[", "1", "]", ".", "strip", "(", ")", "for", "x", "in", "fact_list", "if", "x", "[", "0", "]", ".", "strip", "(", ")", "==", "\"country of citizenship\"", "]", ")", "\n", "# get all occupation for  ", "\n", "occupation", "=", "set", "(", "[", "x", "[", "1", "]", ".", "strip", "(", ")", "for", "x", "in", "fact_list", "if", "x", "[", "0", "]", ".", "strip", "(", ")", "==", "\"occupation\"", "]", ")", "\n", "occupation", "=", "word_stemmer", "(", "occupation", ")", "\n", "\n", "languages_spoken_written_signed", "=", "set", "(", "[", "x", "[", "1", "]", ".", "strip", "(", ")", "for", "x", "in", "fact_list", "if", "x", "[", "0", "]", ".", "strip", "(", ")", "==", "\"languages spoken, written or signed\"", "]", ")", "\n", "\n", "# remove useless predicates", "\n", "if", "x", "[", "0", "]", "in", "useless_predicates", ":", "\n", "        ", "return", "False", ",", "x", "\n", "# remove country for sport if it is same country of citizenship", "\n", "", "if", "x", "[", "0", "]", "==", "\"country for sport\"", "and", "x", "[", "1", "]", ".", "strip", "(", ")", "in", "nationality", ":", "\n", "        ", "return", "False", ",", "x", "\n", "", "if", "x", "[", "0", "]", "==", "\"sport\"", "and", "' '", ".", "join", "(", "[", "stemmer", ".", "stem", "(", "z", ".", "strip", "(", ")", ")", "for", "z", "in", "x", "[", "1", "]", ".", "split", "(", ")", "]", ")", "in", "occupation", ":", "\n", "        ", "return", "False", ",", "x", "\n", "# replace \"writing language\" with \"languages spoken, written or signed\"", "\n", "", "if", "x", "[", "0", "]", "==", "\"writing language\"", ":", "\n", "        ", "if", "x", "[", "1", "]", "in", "languages_spoken_written_signed", ":", "\n", "            ", "return", "False", ",", "x", "\n", "", "x", "[", "0", "]", "==", "\"languages spoken, written or signed\"", "\n", "return", "True", ",", "x", "\n", "", "return", "True", ",", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.execute": [[154, 258], ["config.logger.info", "config.logger.info", "config.logger.info", "article_map.items", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModel.from_pretrained().to", "config.logger.info", "AutoModel.from_pretrained().to.eval", "config.logger.info", "tfidf.TfIdf", "config.logger.info", "tfidf.TfIdf", "datetime.datetime.utcnow", "config.logger.info", "open", "dfile.readlines", "zip", "open", "enumerate", "config.logger.info", "config.logger.info", "config.logger.info", "json.loads", "len", "len", "stage-I-aligner.custom_fact_filter", "processed_en_facts.append", "processed_native_facts.append", "transformers.AutoModel.from_pretrained", "len", "collections.defaultdict", "enumerate", "len", "collections.defaultdict.items", "line.strip", "len", "torch.no_grad", "torch.no_grad", "stage-I-aligner.predict_edges", "config.logger.info", "config.logger.info", "config.logger.info", "datetime.datetime.utcnow", "sorted", "json.dump", "dfile.write", "len", "len", "pred_edge_map[].items", "res[].append", "res[].append", "datetime.datetime.utcnow", "len"], "function", ["home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.custom_fact_filter", "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.stage-I-aligner.predict_edges", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info", "home.repos.pwc.inspect_result.tushar117_xalign.finetune_mt5.logger.MyLogger.info"], ["", "def", "execute", "(", "config", ")", ":", "\n", "    ", "article_map", "=", "{", "}", "\n", "config", ".", "logger", ".", "info", "(", "'loading the articles...'", ")", "\n", "with", "open", "(", "config", ".", "input_file", ",", "encoding", "=", "'utf-8'", ")", "as", "dfile", ":", "\n", "        ", "for", "line", "in", "dfile", ".", "readlines", "(", ")", ":", "\n", "            ", "temp_json", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "qid", "=", "temp_json", "[", "'qid'", "]", "\n", "del", "temp_json", "[", "'qid'", "]", "\n", "article_map", "[", "qid", "]", "=", "temp_json", "\n", "\n", "", "", "config", ".", "logger", ".", "info", "(", "'loaded %d articles from file : %s'", "%", "(", "len", "(", "article_map", ")", ",", "config", ".", "input_file", ")", ")", "\n", "config", ".", "logger", ".", "info", "(", "'removing non-essential facts'", ")", "\n", "\n", "# preprocess the facts for removal of the non-essential facts", "\n", "for", "key", ",", "value", "in", "article_map", ".", "items", "(", ")", ":", "\n", "        ", "processed_en_facts", "=", "[", "]", "\n", "processed_native_facts", "=", "[", "]", "\n", "assert", "len", "(", "value", "[", "'facts'", "]", ")", "==", "len", "(", "value", "[", "'translated_facts'", "]", ")", "\n", "for", "fact_tuple", ",", "native_fact_tuple", "in", "zip", "(", "value", "[", "'facts'", "]", ",", "value", "[", "'translated_facts'", "]", ")", ":", "\n", "            ", "flag", ",", "modified_fact_tuple", "=", "custom_fact_filter", "(", "fact_tuple", ",", "value", "[", "'facts'", "]", ")", "\n", "if", "not", "flag", ":", "\n", "                ", "continue", "\n", "", "processed_en_facts", ".", "append", "(", "modified_fact_tuple", ")", "\n", "processed_native_facts", ".", "append", "(", "native_fact_tuple", ")", "\n", "", "article_map", "[", "key", "]", "[", "'facts'", "]", "=", "processed_en_facts", "\n", "article_map", "[", "key", "]", "[", "'translated_facts'", "]", "=", "processed_native_facts", "\n", "\n", "# loading the module", "\n", "", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "config", ".", "plm_module", ")", "\n", "model", "=", "AutoModel", ".", "from_pretrained", "(", "config", ".", "plm_module", ")", ".", "to", "(", "device", ")", "\n", "\n", "edge_threshold", "=", "config", ".", "edge_threshold", "\n", "top_k_facts", "=", "config", ".", "fact_threshold", "\n", "config", ".", "logger", ".", "info", "(", "'initiating the stage-I aligner with edge threshold : %0.2f and fact threshold : %d'", "%", "(", "edge_threshold", ",", "top_k_facts", ")", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "config", ".", "logger", ".", "info", "(", "'loading the Term Frequency (TF) module for \"en\" language'", ")", "\n", "tf_en_scorer", "=", "TfIdf", "(", "'en'", ",", "ngram", "=", "2", ",", "ngram_weights", "=", "[", "0.8", ",", "0.2", "]", ",", "use_idf", "=", "False", ")", "\n", "config", ".", "logger", ".", "info", "(", "'loading the Term Frequency (TF) module for \"%s\" language'", "%", "config", ".", "lang", ")", "\n", "tf_native_scorer", "=", "TfIdf", "(", "config", ".", "lang", ",", "ngram", "=", "2", ",", "ngram_weights", "=", "[", "0.8", ",", "0.2", "]", ",", "use_idf", "=", "False", ",", "transformer", "=", "True", ")", "\n", "\n", "#writing output to file", "\n", "total_sentences", "=", "0", "\n", "retained_sentences", "=", "0", "\n", "invalid_articles", "=", "0", "\n", "start_time", "=", "datetime", ".", "utcnow", "(", ")", "\n", "config", ".", "logger", ".", "info", "(", "'initaiting the sentence and fact filter...'", ")", "\n", "with", "open", "(", "config", ".", "output_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "dfile", ":", "\n", "        ", "for", "i", ",", "qid", "in", "enumerate", "(", "article_map", ")", ":", "\n", "# print(\"[ %s ] %d - %d - %d\" % (qid, i, len(article_map[qid]['sentences']), len(article_map[qid]['facts'])))", "\n", "# if facts or sentences is empty then skip", "\n", "            ", "if", "len", "(", "article_map", "[", "qid", "]", "[", "'facts'", "]", ")", "==", "0", "or", "len", "(", "article_map", "[", "qid", "]", "[", "'sentences'", "]", ")", "==", "0", ":", "\n", "                ", "invalid_articles", "+=", "1", "\n", "continue", "\n", "", "total_sentences", "+=", "len", "(", "article_map", "[", "qid", "]", "[", "'sentences'", "]", ")", "\n", "t_qid_data", "=", "article_map", "[", "qid", "]", "\n", "\n", "\n", "# hybrid alignment", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "pred_edges", ",", "pred_edge_map", "=", "predict_edges", "(", "model", ",", "tokenizer", ",", "tf_en_scorer", ",", "tf_native_scorer", ",", "t_qid_data", "[", "'sentences'", "]", ",", "t_qid_data", "[", "'translated_sentences'", "]", ",", "\n", "t_qid_data", "[", "'facts'", "]", ",", "t_qid_data", "[", "'translated_facts'", "]", ",", "\n", "threshold", "=", "1.00", ",", "reduce", "=", "'mean'", ")", "\n", "\n", "", "sent_index", "=", "defaultdict", "(", "lambda", ":", "0.0", ")", "\n", "for", "rank", ",", "edge", "in", "enumerate", "(", "pred_edges", ")", ":", "\n", "                ", "if", "edge", "[", "2", "]", "<", "edge_threshold", ":", "\n", "                    ", "break", "\n", "", "sent_index", "[", "edge", "[", "0", "]", "]", "=", "edge", "[", "2", "]", "if", "sent_index", "[", "edge", "[", "0", "]", "]", "<", "edge", "[", "2", "]", "else", "sent_index", "[", "edge", "[", "0", "]", "]", "\n", "\n", "", "if", "(", "i", "+", "1", ")", "%", "config", ".", "log_interval", "==", "0", ":", "\n", "                ", "delta", "=", "(", "datetime", ".", "utcnow", "(", ")", "-", "start_time", ")", ".", "total_seconds", "(", ")", "\n", "config", ".", "logger", ".", "info", "(", "'processsd %d / %d articles in %.2f secs'", "%", "(", "i", "+", "1", ",", "len", "(", "article_map", ")", ",", "delta", ")", ")", "\n", "config", ".", "logger", ".", "info", "(", "'number of empty articles: %d'", "%", "invalid_articles", ")", "\n", "config", ".", "logger", ".", "info", "(", "'%d [ %0.2f ] sentences retained out of %d total sentences'", "%", "(", "retained_sentences", ",", "retained_sentences", "/", "total_sentences", ",", "total_sentences", ")", ")", "\n", "start_time", "=", "datetime", ".", "utcnow", "(", ")", "\n", "\n", "", "retained_sentences", "+=", "len", "(", "sent_index", ")", "\n", "for", "sindx", ",", "sent_score", "in", "sent_index", ".", "items", "(", ")", ":", "\n", "                ", "res", "=", "{", "\n", "'qid'", ":", "qid", ",", "\n", "'entity_name'", ":", "t_qid_data", "[", "'entity_name'", "]", ",", "\n", "'sentence'", ":", "t_qid_data", "[", "'sentences'", "]", "[", "sindx", "]", ",", "\n", "'native_sentence_section'", ":", "t_qid_data", "[", "'native_sentence_sections'", "]", "[", "sindx", "]", ",", "\n", "'translated_sentence'", ":", "t_qid_data", "[", "'translated_sentences'", "]", "[", "sindx", "]", ",", "\n", "'sent_index'", ":", "sindx", ",", "\n", "'facts'", ":", "[", "]", ",", "\n", "'sent_score'", ":", "\"%0.2f\"", "%", "sent_score", ",", "\n", "'translated_facts'", ":", "[", "]", ",", "\n", "}", "\n", "count", "=", "1", "\n", "for", "k", ",", "v", "in", "sorted", "(", "pred_edge_map", "[", "sindx", "]", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", ":", "\n", "                    ", "if", "count", ">", "top_k_facts", ":", "\n", "                        ", "break", "\n", "", "res", "[", "'facts'", "]", ".", "append", "(", "t_qid_data", "[", "'facts'", "]", "[", "k", "]", ")", "\n", "res", "[", "'translated_facts'", "]", ".", "append", "(", "t_qid_data", "[", "'translated_facts'", "]", "[", "k", "]", ")", "\n", "count", "+=", "1", "\n", "", "json", ".", "dump", "(", "res", ",", "dfile", ",", "ensure_ascii", "=", "False", ")", "\n", "dfile", ".", "write", "(", "'\\n'", ")", "\n", "\n", "", "", "config", ".", "logger", ".", "info", "(", "'=='", "*", "30", ")", "\n", "config", ".", "logger", ".", "info", "(", "'%d [ %0.2f ] sentences retained out of %d total sentences'", "%", "(", "retained_sentences", ",", "retained_sentences", "/", "total_sentences", ",", "total_sentences", ")", ")", "\n", "config", ".", "logger", ".", "info", "(", "'number of empty articles: %d'", "%", "invalid_articles", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf._load_stop_words": [[11, 21], ["tfidf.TfIdf.stop_words.update", "tfidf.TfIdf.stop_words.update", "stopwords.words"], "methods", ["None"], ["    ", "def", "_load_stop_words", "(", "self", ")", ":", "\n", "# using dictionary implementation for faster execution", "\n", "        ", "punct", "=", "{", "x", ":", "''", "for", "x", "in", "string", ".", "punctuation", "}", "\n", "self", ".", "stop_words", "=", "punct", "\n", "if", "self", ".", "lang", "==", "'en'", ":", "\n", "            ", "from", "nltk", ".", "corpus", "import", "stopwords", "\n", "self", ".", "stop_words", ".", "update", "(", "{", "x", ":", "''", "for", "x", "in", "stopwords", ".", "words", "(", "'english'", ")", "}", ")", "\n", "", "if", "self", ".", "lang", "==", "'hi'", ":", "\n", "            ", "from", "spacy", ".", "lang", ".", "hi", "import", "STOP_WORDS", "as", "hi_stop_words", "\n", "self", ".", "stop_words", ".", "update", "(", "{", "x", ":", "''", "for", "x", "in", "hi_stop_words", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf._feature_vectorizer": [[22, 31], ["sklearn.feature_extraction.text.CountVectorizer.fit", "sklearn.feature_extraction.text.CountVectorizer.get_feature_names", "sklearn.feature_extraction.text.TfidfVectorizer", "sklearn.feature_extraction.text.CountVectorizer", "tfidf.TfIdf._tokenizer", "tfidf.TfIdf._tokenizer"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf._tokenizer", "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf._tokenizer"], ["", "", "def", "_feature_vectorizer", "(", "self", ",", "doc_corpus", ",", "n_gram", "=", "1", ",", "enable_idf", "=", "False", ")", ":", "\n", "# obtain n-grams", "\n", "        ", "if", "enable_idf", ":", "\n", "            ", "vectorizer", "=", "TfidfVectorizer", "(", "ngram_range", "=", "(", "n_gram", ",", "n_gram", ")", ",", "tokenizer", "=", "lambda", "text", ":", "self", ".", "_tokenizer", "(", "text", ")", ")", "\n", "", "else", ":", "\n", "            ", "vectorizer", "=", "CountVectorizer", "(", "ngram_range", "=", "(", "n_gram", ",", "n_gram", ")", ",", "tokenizer", "=", "lambda", "text", ":", "self", ".", "_tokenizer", "(", "text", ")", ")", "\n", "", "doc_vectorizer", "=", "vectorizer", ".", "fit", "(", "doc_corpus", ")", "\n", "doc_features", "=", "(", "vectorizer", ".", "get_feature_names", "(", ")", ")", "\n", "return", "doc_vectorizer", ",", "doc_features", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf._calculate_score": [[32, 36], ["numpy.dot", "numpy.dot", "numpy.linalg.norm", "numpy.linalg.norm", "numpy.linalg.norm", "numpy.linalg.norm"], "methods", ["None"], ["", "def", "_calculate_score", "(", "self", ",", "a", ",", "b", ")", ":", "\n", "        ", "if", "dot", "(", "a", ",", "b", ")", "==", "0", "or", "norm", "(", "a", ")", "==", "0", "or", "norm", "(", "b", ")", "==", "0", ":", "\n", "            ", "return", "0", "\n", "", "return", "dot", "(", "a", ",", "b", ")", "/", "(", "norm", "(", "a", ")", "*", "norm", "(", "b", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf._load_lemmatizer": [[37, 46], ["stanza.Pipeline", "stanza.Pipeline", "stanza.Pipeline", "Exception"], "methods", ["None"], ["", "def", "_load_lemmatizer", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "lang", "==", "'en'", ":", "\n", "            ", "self", ".", "nlp", "=", "stanza", ".", "Pipeline", "(", "lang", "=", "self", ".", "lang", ",", "processors", "=", "'tokenize'", ",", "tokenize_no_ssplit", "=", "True", ")", "\n", "", "elif", "self", ".", "lang", "==", "'hi'", ":", "\n", "            ", "self", ".", "nlp", "=", "stanza", ".", "Pipeline", "(", "lang", "=", "self", ".", "lang", ",", "processors", "=", "'tokenize'", ",", "tokenize_no_ssplit", "=", "True", ")", "\n", "", "elif", "self", ".", "lang", "==", "'mr'", ":", "\n", "            ", "self", ".", "nlp", "=", "stanza", ".", "Pipeline", "(", "lang", "=", "self", ".", "lang", ",", "processors", "=", "'tokenize'", ",", "tokenize_no_ssplit", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'%s language support is not available yet !!!'", "%", "self", ".", "lang", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf._handle_ngram_args": [[47, 56], ["isinstance", "len", "numpy.sum", "numpy.ones"], "methods", ["None"], ["", "", "def", "_handle_ngram_args", "(", "self", ")", ":", "\n", "        ", "assert", "self", ".", "ngram", ">", "0", ",", "\"invalid ngrams specified, it must be greater than zero ( >0 )\"", "\n", "if", "self", ".", "ngram_weights", "is", "None", ":", "\n", "            ", "self", ".", "ngram_weights", "=", "(", "(", "1.0", "/", "self", ".", "ngram", ")", "*", "np", ".", "ones", "(", "self", ".", "ngram", ")", ")", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "            ", "assert", "isinstance", "(", "self", ".", "ngram_weights", ",", "list", ")", ",", "\"invalid input for ngram_weights, expected list\"", "\n", "assert", "len", "(", "self", ".", "ngram_weights", ")", "==", "self", ".", "ngram", ",", "\"ngram_weights distribution : %s \\\n                                    doesn't match with ngram specified : %s\"", "%", "(", "self", ".", "ngram_weights", ",", "self", ".", "ngram", ")", "\n", "assert", "np", ".", "sum", "(", "self", ".", "ngram_weights", ")", "==", "1", ",", "\"sum of entries of ngram_weight should be one.\"", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf._tokenizer": [[57, 60], ["text.split"], "methods", ["None"], ["", "", "def", "_tokenizer", "(", "self", ",", "text", ")", ":", "\n", "# as self._process_text has already lemmatized it, we just need to return space separated tokens", "\n", "        ", "return", "text", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf._process_text": [[61, 69], ["tfidf.TfIdf._normalize_input", "tfidf.TfIdf.tokenizer.tokenize", "tfidf.TfIdf.nlp"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf._normalize_input"], ["", "def", "_process_text", "(", "self", ",", "text", ")", ":", "\n", "        ", "text", "=", "self", ".", "_normalize_input", "(", "text", ")", "\n", "if", "self", ".", "use_transformer", ":", "\n", "            ", "t_doc", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "return", "' '", ".", "join", "(", "t_doc", ")", "\n", "", "else", ":", "\n", "            ", "t_doc", "=", "self", ".", "nlp", "(", "text", ")", "\n", "return", "' '", ".", "join", "(", "[", "word", ".", "text", "for", "sent", "in", "t_doc", ".", "sentences", "for", "word", "in", "sent", ".", "words", "if", "word", ".", "text", "not", "in", "self", ".", "stop_words", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf.__init__": [[71, 84], ["tfidf.TfIdf._handle_ngram_args", "transformers.AutoTokenizer.from_pretrained", "tfidf.TfIdf._load_lemmatizer", "tfidf.TfIdf._load_stop_words"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf._handle_ngram_args", "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf._load_lemmatizer", "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf._load_stop_words"], ["", "", "def", "__init__", "(", "self", ",", "lang", ",", "ngram", "=", "1", ",", "ngram_weights", "=", "None", ",", "use_idf", "=", "True", ",", "transformer", "=", "False", ")", ":", "\n", "        ", "self", ".", "lang", "=", "lang", "\n", "self", ".", "ngram", "=", "ngram", "\n", "self", ".", "ngram_weights", "=", "ngram_weights", "\n", "self", ".", "use_idf", "=", "use_idf", "\n", "self", ".", "use_transformer", "=", "transformer", "\n", "\n", "self", ".", "_handle_ngram_args", "(", ")", "\n", "if", "self", ".", "use_transformer", ":", "\n", "            ", "self", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "'google/muril-base-cased'", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_load_lemmatizer", "(", ")", "\n", "self", ".", "_load_stop_words", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf._normalize_input": [[85, 91], ["text.lower.lower.strip", "re.sub", "re.compile", "text.lower.lower.lower"], "methods", ["None"], ["", "", "def", "_normalize_input", "(", "self", ",", "text", ")", ":", "\n", "        ", "text", "=", "text", ".", "strip", "(", ")", "\n", "text", "=", "re", ".", "sub", "(", "re", ".", "compile", "(", "\"\\s{2,}\"", ")", ",", "' '", ",", "text", ")", "\n", "if", "self", ".", "lang", "==", "'en'", ":", "\n", "            ", "text", "=", "text", ".", "lower", "(", ")", "\n", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf.get_scores": [[92, 117], ["list", "tfidf.TfIdf._process_text", "numpy.zeros().tolist", "range", "map", "tfidf.TfIdf._feature_vectorizer", "vectorizer.transform().toarray", "range", "numpy.zeros", "vectorizer.transform().toarray", "len", "len", "len", "len", "vectorizer.transform", "tfidf.TfIdf._calculate_score", "vectorizer.transform"], "methods", ["home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf._process_text", "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf._feature_vectorizer", "home.repos.pwc.inspect_result.tushar117_xalign.stage-I-aligner.tfidf.TfIdf._calculate_score"], ["", "def", "get_scores", "(", "self", ",", "query", ",", "docs", ")", ":", "\n", "        ", "\"\"\"\n        returns tf-idf score for list of documents against the single query string\n        \n        Args:\n            query: a single query instance \n            docs: list of documents on which tf-idf score are calculated\n        \n        Returns:\n            scores: list of tf-idf scores in the same order as of the docs.\n        \"\"\"", "\n", "processed_docs", "=", "list", "(", "map", "(", "self", ".", "_process_text", ",", "docs", ")", ")", "\n", "query", "=", "self", ".", "_process_text", "(", "query", ")", "\n", "\n", "final_scores", "=", "np", ".", "zeros", "(", "len", "(", "docs", ")", ")", ".", "tolist", "(", ")", "\n", "for", "ngram", "in", "range", "(", "1", ",", "self", ".", "ngram", "+", "1", ")", ":", "\n", "            ", "vectorizer", ",", "_", "=", "self", ".", "_feature_vectorizer", "(", "processed_docs", ",", "n_gram", "=", "ngram", ",", "enable_idf", "=", "self", ".", "use_idf", ")", "\n", "doc_vector", "=", "vectorizer", ".", "transform", "(", "processed_docs", ")", ".", "toarray", "(", ")", "\n", "query_vector", "=", "vectorizer", ".", "transform", "(", "[", "query", "]", ")", ".", "toarray", "(", ")", "[", "0", "]", "\n", "\n", "assert", "len", "(", "doc_vector", ")", "==", "len", "(", "docs", ")", ",", "\"doc vector and actual doc are of different size.\"", "\n", "#calculating score", "\n", "for", "idx", "in", "range", "(", "len", "(", "doc_vector", ")", ")", ":", "\n", "                ", "final_scores", "[", "idx", "]", "+=", "self", ".", "ngram_weights", "[", "ngram", "-", "1", "]", "*", "self", ".", "_calculate_score", "(", "query_vector", ",", "doc_vector", "[", "idx", "]", ")", "\n", "", "", "return", "final_scores", "", "", "", ""]]}