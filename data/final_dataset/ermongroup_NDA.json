{"home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns.dummy_training_function": [[16, 20], ["None"], "function", ["None"], ["def", "dummy_training_function", "(", ")", ":", "\n", "    ", "def", "train", "(", "x", ",", "y", ")", ":", "\n", "        ", "return", "{", "}", "\n", "", "return", "train", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns.select_loss": [[22, 43], ["ValueError"], "function", ["None"], ["", "def", "select_loss", "(", "config", ")", ":", "\n", "    ", "if", "config", "[", "'loss_type'", "]", "==", "'hinge'", ":", "\n", "        ", "return", "losses", ".", "loss_hinge_dis", ",", "losses", ".", "loss_hinge_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'dcgan'", ":", "\n", "         ", "return", "losses", ".", "loss_dcgan_dis", ",", "losses", ".", "loss_dcgan_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'kl'", ":", "\n", "        ", "return", "losses", ".", "loss_kl_dis", ",", "losses", ".", "loss_kl_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'kl_gen'", ":", "\n", "        ", "return", "losses", ".", "loss_hinge_dis", ",", "losses", ".", "loss_kl_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'kl_dis'", ":", "\n", "        ", "return", "losses", ".", "loss_kl_dis", ",", "losses", ".", "loss_hinge_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'kl_grad'", ":", "\n", "        ", "return", "losses", ".", "loss_kl_grad_dis", ",", "losses", ".", "loss_kl_grad_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'f_kl'", ":", "\n", "        ", "return", "losses", ".", "loss_f_kl_dis", ",", "losses", ".", "loss_f_kl_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'chi2'", ":", "\n", "        ", "return", "losses", ".", "loss_chi_dis", ",", "losses", ".", "loss_chi_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'dv'", ":", "\n", "        ", "return", "losses", ".", "loss_dv_dis", ",", "losses", ".", "loss_dv_gen", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'loss not defined'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns.GAN_training_function": [[45, 139], ["train_fns.select_loss", "G.optim.zero_grad", "D.optim.zero_grad", "torch.split", "torch.split", "torch.split", "torch.split", "range", "G.optim.zero_grad", "range", "G.optim.step", "utils.toggle_grad", "utils.toggle_grad", "D.optim.zero_grad", "range", "D.optim.step", "utils.toggle_grad", "utils.toggle_grad", "z_.sample_", "y_.sample_", "GD", "G_loss.backward", "print", "utils.ortho", "ema.update", "float", "float", "float", "z_.sample_", "GD", "discriminator_loss", "D_loss.backward", "print", "utils.ortho", "y_.zero_", "generator_loss", "float", "G_loss.item", "D_loss_real.item", "D_loss_fake.item", "y_.zero_", "torch.zeros_like().to().long", "torch.zeros_like().to().long", "y_.sample_", "float", "torch.zeros_like().to", "torch.zeros_like().to", "G.shared.parameters", "torch.zeros_like", "torch.zeros_like"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.select_loss", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Adam16.step", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.toggle_grad", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.toggle_grad", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Adam16.step", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.toggle_grad", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.toggle_grad", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.ortho", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.ema.update", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.ortho", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to"], ["", "", "def", "GAN_training_function", "(", "G", ",", "D", ",", "GD", ",", "z_", ",", "y_", ",", "ema", ",", "state_dict", ",", "config", ")", ":", "\n", "    ", "discriminator_loss", ",", "generator_loss", "=", "select_loss", "(", "config", ")", "\n", "\n", "def", "train", "(", "x", ",", "y", ")", ":", "\n", "        ", "G", ".", "optim", ".", "zero_grad", "(", ")", "\n", "D", ".", "optim", ".", "zero_grad", "(", ")", "\n", "# How many chunks to split x and y into?", "\n", "x", "=", "torch", ".", "split", "(", "x", ",", "config", "[", "'batch_size'", "]", ")", "\n", "y", "=", "torch", ".", "split", "(", "y", ",", "config", "[", "'batch_size'", "]", ")", "\n", "counter", "=", "0", "\n", "\n", "# Optionally toggle D and G's \"require_grad\"", "\n", "if", "config", "[", "'toggle_grads'", "]", ":", "\n", "            ", "utils", ".", "toggle_grad", "(", "D", ",", "True", ")", "\n", "utils", ".", "toggle_grad", "(", "G", ",", "False", ")", "\n", "\n", "", "for", "step_index", "in", "range", "(", "config", "[", "'num_D_steps'", "]", ")", ":", "\n", "# If accumulating gradients, loop multiple times before an optimizer step", "\n", "            ", "D", ".", "optim", ".", "zero_grad", "(", ")", "\n", "for", "accumulation_index", "in", "range", "(", "config", "[", "'num_D_accumulations'", "]", ")", ":", "\n", "                ", "z_", ".", "sample_", "(", ")", "\n", "if", "not", "config", "[", "'conditional'", "]", ":", "\n", "# only feed in 0's for y if \"unconditional\"", "\n", "                    ", "y_", ".", "zero_", "(", ")", "\n", "y_counter", "=", "torch", ".", "zeros_like", "(", "y", "[", "counter", "]", ")", ".", "to", "(", "y_", ".", "device", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "                    ", "y_", ".", "sample_", "(", ")", "\n", "y_counter", "=", "y", "[", "counter", "]", "\n", "", "D_fake", ",", "D_real", "=", "GD", "(", "z_", "[", ":", "config", "[", "'batch_size'", "]", "]", ",", "y_", "[", ":", "config", "[", "'batch_size'", "]", "]", ",", "x", "[", "counter", "]", ",", "\n", "y_counter", ",", "train_G", "=", "False", ",", "split_D", "=", "config", "[", "'split_D'", "]", ")", "\n", "# y_.sample_()", "\n", "# D_fake, D_real = GD(z_[:config['batch_size']], y_[:config['batch_size']],", "\n", "#                     x[counter], y[counter], train_G=False,", "\n", "#                     split_D=config['split_D'])", "\n", "# Compute components of D's loss, average them, and divide by", "\n", "# the number of gradient accumulations", "\n", "# if D_fake.max().item() - D_fake.min().item() > 30:", "\n", "# import ipdb", "\n", "# ipdb.set_trace()", "\n", "\n", "D_loss_real", ",", "D_loss_fake", "=", "discriminator_loss", "(", "\n", "D_fake", ",", "D_real", ")", "\n", "D_loss", "=", "(", "D_loss_real", "+", "2", "*", "D_loss_fake", ")", "/", "float", "(", "config", "[", "'num_D_accumulations'", "]", ")", "\n", "\n", "D_loss", ".", "backward", "(", ")", "\n", "counter", "+=", "1", "\n", "\n", "# Optionally apply ortho reg in D", "\n", "", "if", "config", "[", "'D_ortho'", "]", ">", "0.0", ":", "\n", "# Debug print to indicate we're using ortho reg in D.", "\n", "                ", "print", "(", "'using modified ortho reg in D'", ")", "\n", "utils", ".", "ortho", "(", "D", ",", "config", "[", "'D_ortho'", "]", ")", "\n", "\n", "", "D", ".", "optim", ".", "step", "(", ")", "\n", "\n", "# Optionally toggle \"requires_grad\"", "\n", "", "if", "config", "[", "'toggle_grads'", "]", ":", "\n", "            ", "utils", ".", "toggle_grad", "(", "D", ",", "False", ")", "\n", "utils", ".", "toggle_grad", "(", "G", ",", "True", ")", "\n", "\n", "# Zero G's gradients by default before training G, for safety", "\n", "", "G", ".", "optim", ".", "zero_grad", "(", ")", "\n", "\n", "# If accumulating gradients, loop multiple times", "\n", "for", "accumulation_index", "in", "range", "(", "config", "[", "'num_G_accumulations'", "]", ")", ":", "\n", "            ", "z_", ".", "sample_", "(", ")", "\n", "y_", ".", "sample_", "(", ")", "\n", "if", "not", "config", "[", "'conditional'", "]", ":", "\n", "                ", "y_", ".", "zero_", "(", ")", "\n", "", "D_fake", "=", "GD", "(", "z_", ",", "y_", ",", "train_G", "=", "True", ",", "split_D", "=", "config", "[", "'split_D'", "]", ")", "\n", "G_loss", "=", "generator_loss", "(", "\n", "D_fake", ")", "/", "float", "(", "config", "[", "'num_G_accumulations'", "]", ")", "\n", "G_loss", ".", "backward", "(", ")", "\n", "\n", "# Optionally apply modified ortho reg in G", "\n", "", "if", "config", "[", "'G_ortho'", "]", ">", "0.0", ":", "\n", "# Debug print to indicate we're using ortho reg in G", "\n", "            ", "print", "(", "'using modified ortho reg in G'", ")", "\n", "# Don't ortho reg shared, it makes no sense. Really we should blacklist any embeddings for this", "\n", "utils", ".", "ortho", "(", "G", ",", "config", "[", "'G_ortho'", "]", ",", "\n", "blacklist", "=", "[", "param", "for", "param", "in", "G", ".", "shared", ".", "parameters", "(", ")", "]", ")", "\n", "", "G", ".", "optim", ".", "step", "(", ")", "\n", "\n", "# If we have an ema, update it, regardless of if we test with it or not", "\n", "if", "config", "[", "'ema'", "]", ":", "\n", "            ", "ema", ".", "update", "(", "state_dict", "[", "'itr'", "]", ")", "\n", "\n", "", "out", "=", "{", "'G_loss'", ":", "float", "(", "G_loss", ".", "item", "(", ")", ")", ",", "\n", "'D_loss_real'", ":", "float", "(", "D_loss_real", ".", "item", "(", ")", ")", ",", "\n", "'D_loss_fake'", ":", "float", "(", "D_loss_fake", ".", "item", "(", ")", ")", "}", "\n", "# Return G's loss and the components of D's loss.", "\n", "return", "out", "\n", "", "return", "train", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns.GAN_cleaning_function": [[140, 229], ["train_fns.select_loss", "print", "print", "print", "numpy.transpose", "int", "torch.zeros().to().long", "torch.zeros().to().long", "range", "numpy.array", "print", "numpy.load", "torch.from_numpy().float", "torch.from_numpy().float", "test_data.to.to", "test_data.to.clone", "int", "range", "print", "torch.max.data.cpu().numpy", "np.array.extend", "numpy.min", "numpy.max", "numpy.save", "numpy.save", "len", "torch.zeros().to", "torch.zeros().to", "float", "GD", "discriminator_loss", "D_loss.backward", "torch.from_numpy", "torch.from_numpy", "torch.max.grad.data._zero", "torch.no_grad", "torch.no_grad", "torch.clamp", "torch.clamp", "torch.max.data.cpu", "torch.zeros", "torch.zeros", "torch.min", "torch.min", "torch.max", "torch.max", "str", "str", "torch.sign", "torch.sign"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.select_loss", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to"], ["", "def", "GAN_cleaning_function", "(", "G", ",", "D", ",", "GD", ",", "z_", ",", "y_", ",", "ema", ",", "state_dict", ",", "config", ",", "sgd", "=", "False", ")", ":", "\n", "    ", "import", "numpy", "as", "np", "\n", "discriminator_loss", ",", "generator_loss", "=", "select_loss", "(", "config", ")", "\n", "\n", "def", "train", "(", ")", ":", "\n", "\n", "        ", "corrupt_dict", "=", "{", "'elastic'", ":", "'elastic_transform'", ",", "'jpeg'", ":", "'jpeg_compression'", ",", "'speckle'", ":", "'speckle_noise'", ",", "'gaussian'", ":", "'gaussian_noise'", ",", "\n", "'blur'", ":", "'gaussian_blur'", ",", "\n", "'zoom'", ":", "'zoom_blur'", ",", "'brightness'", ":", "'brightness'", ",", "'contrast'", ":", "'contrast'", ",", "'defocus'", ":", "'defocus_blur'", ",", "\n", "'fog'", ":", "'fog'", ",", "'frost'", ":", "'frost'", ",", "'glass'", ":", "'glass_blur'", ",", "'impulse'", ":", "'impulse_noise'", ",", "'motion'", ":", "'motion_blur'", ",", "\n", "'pixelate'", ":", "'pixelate'", ",", "'saturate'", ":", "'saturate'", ",", "'shot'", ":", "'shot_noise'", ",", "'snow'", ":", "'snow'", ",", "'spatter'", ":", "'spatter'", ",", "\n", "#'clean':'test_samples'", "\n", "}", "\n", "if", "not", "config", "[", "'data_type'", "]", "==", "'all'", ":", "\n", "            ", "corrupt_dict", "=", "{", "config", "[", "'data_type'", "]", ":", "corrupt_dict", "[", "config", "[", "'data_type'", "]", "]", "}", "\n", "", "print", "(", "\"sgd is \"", ",", "sgd", ")", "\n", "print", "(", "\"the value of eps is \"", ",", "config", "[", "'eps'", "]", ")", "\n", "#if sgd :", "\n", "#    corrupt_dict = {'elastic':'elastic_transform','jpeg':'jpeg_compression','speckle':'speckle_noise','gaussian':'gaussian_noise'}", "\n", "base_dir", "=", "\"../mintnet/CIFAR-10-C/\"", "\n", "if", "config", "[", "'experiment_name'", "]", ":", "\n", "            ", "corruption_dir", "=", "\"corruption_new/\"", "\n", "", "else", ":", "\n", "            ", "corruption_dir", "=", "\"corruption/\"", "\n", "", "print", "(", "\"corruption dir is \"", ",", "corruption_dir", ")", "\n", "\n", "for", "mode", "in", "corrupt_dict", ":", "\n", "\n", "# test_batch = np.transpose(np.load(\"../mintnet/CIFAR-10-C/elastic_transform.npy\"), (0, 3, 1, 2))[-10000:]", "\n", "            ", "test_batch", "=", "np", ".", "transpose", "(", "np", ".", "load", "(", "base_dir", "+", "corrupt_dict", "[", "mode", "]", "+", "\".npy\"", ")", ",", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "\n", "batch_size", "=", "50", "\n", "test_iters", "=", "int", "(", "len", "(", "test_batch", ")", "/", "batch_size", ")", "\n", "cleaned_data", "=", "[", "]", "\n", "y_counter", "=", "torch", ".", "zeros", "(", "batch_size", ")", ".", "to", "(", "\"cuda\"", ")", ".", "long", "(", ")", "\n", "for", "idx", "in", "range", "(", "test_iters", ")", ":", "\n", "                ", "data_batch", "=", "test_batch", "[", "idx", "*", "batch_size", ":", "(", "idx", "+", "1", ")", "*", "batch_size", "]", "\n", "test_data", "=", "torch", ".", "from_numpy", "(", "data_batch", ")", ".", "float", "(", ")", "\n", "test_data", "=", "test_data", ".", "to", "(", "\"cuda\"", ")", "\n", "adv", "=", "test_data", ".", "clone", "(", ")", "\n", "\n", "eps", "=", "int", "(", "config", "[", "'eps'", "]", ")", "\n", "iters", "=", "40", "\n", "alpha", "=", "2.5", "*", "eps", "/", "float", "(", "iters", ")", "\n", "if", "sgd", ":", "\n", "                    ", "alpha", "*=", "6000.0", "\n", "#adv = adv + eps * (torch.rand_like(adv)-0.5)*2.0", "\n", "", "for", "i", "in", "range", "(", "iters", ")", ":", "\n", "                    ", "adv", ".", "requires_grad", "=", "True", "\n", "if", "adv", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "adv", ".", "grad", ".", "data", ".", "_zero", "(", ")", "\n", "", "data", "=", "adv", "/", "255.0", "\n", "\n", "D_fake", ",", "D_real", "=", "GD", "(", "z_", "[", ":", "config", "[", "'batch_size'", "]", "]", ",", "y_", "[", ":", "config", "[", "'batch_size'", "]", "]", ",", "data", ",", "\n", "y_counter", ",", "train_G", "=", "False", ",", "split_D", "=", "config", "[", "'split_D'", "]", ")", "\n", "\n", "D_loss_real", ",", "D_loss_fake", "=", "discriminator_loss", "(", "\n", "D_fake", ",", "D_real", ")", "\n", "D_loss", "=", "D_loss_real", "\n", "D_loss", ".", "backward", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                        ", "if", "sgd", ":", "\n", "                            ", "adv", "=", "adv", "-", "alpha", "*", "adv", ".", "grad", "\n", "", "else", ":", "\n", "                            ", "adv", "=", "adv", "-", "alpha", "*", "torch", ".", "sign", "(", "adv", ".", "grad", ")", "\n", "adv", "=", "torch", ".", "min", "(", "adv", ",", "test_data", "+", "eps", ")", "\n", "adv", "=", "torch", ".", "max", "(", "adv", ",", "test_data", "-", "eps", ")", "\n", "", "adv", "=", "torch", ".", "clamp", "(", "adv", ",", "0.0", ",", "255.0", ")", "\n", "", "", "print", "(", "\"%d iters reached\"", "%", "idx", ")", "\n", "adv_numpy", "=", "adv", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "cleaned_data", ".", "extend", "(", "adv_numpy", ")", "\n", "", "cleaned_data", "=", "np", ".", "array", "(", "cleaned_data", ")", "\n", "# print(np.min(cleaned_data), np.max(cleaned_data), cleaned_data.shape)", "\n", "# np.save(\"corruption/elastic_pgd.npy\", cleaned_data)", "\n", "print", "(", "\"cleaning done for the corruption \"", ",", "mode", ",", "\" and the shape of data is \"", ",", "cleaned_data", ".", "shape", ",", "\" min is \"", ",", "np", ".", "min", "(", "cleaned_data", ")", ",", "\n", "\" max is \"", ",", "np", ".", "max", "(", "cleaned_data", ")", ")", "\n", "#if config['experiment_name'] :", "\n", "#    corruption_dir = \"corruption_new/\"", "\n", "#else :", "\n", "#    corruption_dir = \"corruption/\"", "\n", "#print(\"corruption dir is \", corruption_dir)", "\n", "if", "sgd", ":", "\n", "                ", "np", ".", "save", "(", "corruption_dir", "+", "mode", "+", "\"_sgd_\"", "+", "str", "(", "eps", ")", "+", "\".npy\"", ",", "cleaned_data", ")", "\n", "", "else", ":", "\n", "                ", "np", ".", "save", "(", "corruption_dir", "+", "mode", "+", "\"_pgd_\"", "+", "str", "(", "eps", ")", "+", "\".npy\"", ",", "cleaned_data", ")", "\n", "\n", "\n", "\n", "", "", "", "return", "train", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns.GAN_inpainting_function": [[231, 320], ["train_fns.select_loss", "int", "torch.from_numpy().to().long", "torch.from_numpy().to().long", "numpy.zeros", "torch.from_numpy().float", "torch.from_numpy().float", "mask.to.to", "torch.from_numpy().float", "torch.from_numpy().float", "noise.to.to", "range", "numpy.transpose", "numpy.transpose", "numpy.save", "numpy.save", "numpy.transpose", "numpy.transpose", "numpy.load", "torch.from_numpy().float", "torch.from_numpy().float", "test_data.to.to", "test_data.to.clone", "print", "print", "range", "test_data.to.data.cpu().numpy", "torch.clamp.data.cpu().numpy", "numpy.load", "numpy.load", "len", "len", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "GD", "discriminator_loss", "D_loss.sum.sum", "D_loss.sum.backward", "print", "print", "torch.from_numpy", "torch.from_numpy", "torch.clamp.grad.data._zero", "torch.no_grad", "torch.no_grad", "torch.clamp", "torch.clamp", "test_data.to.data.cpu", "torch.clamp.data.cpu", "torch.from_numpy", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.select_loss", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to"], ["", "def", "GAN_inpainting_function", "(", "G", ",", "D", ",", "GD", ",", "z_", ",", "y_", ",", "ema", ",", "state_dict", ",", "config", ")", ":", "\n", "    ", "import", "numpy", "as", "np", "\n", "discriminator_loss", ",", "generator_loss", "=", "select_loss", "(", "config", ")", "\n", "\n", "def", "train", "(", ")", ":", "\n", "\n", "\n", "\n", "#if sgd :", "\n", "#    corrupt_dict = {'elastic':'elastic_transform','jpeg':'jpeg_compression','speckle':'speckle_noise','gaussian':'gaussian_noise'}", "\n", "        ", "base_dir", "=", "\"../mintnet/CIFAR-10-C/\"", "\n", "\n", "\n", "cleaned_dir", "=", "\"inpainting/\"", "\n", "\n", "\n", "batch_size", "=", "50", "\n", "# test_batch = np.transpose(np.load(\"../mintnet/CIFAR-10-C/elastic_transform.npy\"), (0, 3, 1, 2))[-10000:]", "\n", "test_batch", "=", "np", ".", "transpose", "(", "np", ".", "load", "(", "base_dir", "+", "\"test_samples.npy\"", ")", ",", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "[", ":", "batch_size", "]", "\n", "noise", "=", "np", ".", "transpose", "(", "np", ".", "load", "(", "base_dir", "+", "\"noise.npy\"", ")", ",", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "[", ":", "batch_size", "]", "\n", "# noise = np.zeros(test_batch.shape)", "\n", "test_labels", "=", "np", ".", "load", "(", "base_dir", "+", "\"test_labels.npy\"", ")", "[", ":", "len", "(", "test_batch", ")", "]", "\n", "\n", "test_iters", "=", "int", "(", "len", "(", "test_batch", ")", "/", "batch_size", ")", "\n", "cleaned_data", "=", "[", "]", "\n", "# y_counter = torch.zeros(batch_size).to(\"cuda\").long()", "\n", "y_counter", "=", "torch", ".", "from_numpy", "(", "test_labels", ")", ".", "to", "(", "\"cuda\"", ")", ".", "long", "(", ")", "\n", "mask", "=", "np", ".", "zeros", "(", "[", "batch_size", ",", "3", ",", "32", ",", "32", "]", ")", "\n", "mask", "[", ":", ",", ":", ",", "16", ":", ",", ":", "]", "=", "1.0", "\n", "\n", "mask", "=", "torch", ".", "from_numpy", "(", "mask", ")", ".", "float", "(", ")", "\n", "mask", "=", "mask", ".", "to", "(", "\"cuda\"", ")", "\n", "noise", "=", "torch", ".", "from_numpy", "(", "noise", ")", ".", "float", "(", ")", "\n", "noise", "=", "noise", ".", "to", "(", "\"cuda\"", ")", "\n", "\n", "for", "idx", "in", "range", "(", "test_iters", ")", ":", "\n", "            ", "data_batch", "=", "test_batch", "[", "idx", "*", "batch_size", ":", "(", "idx", "+", "1", ")", "*", "batch_size", "]", "\n", "test_data", "=", "torch", ".", "from_numpy", "(", "data_batch", ")", ".", "float", "(", ")", "\n", "test_data", "=", "test_data", ".", "to", "(", "\"cuda\"", ")", "\n", "test_data", "=", "test_data", "*", "(", "1.0", "-", "mask", ")", "+", "noise", "*", "mask", "\n", "adv", "=", "test_data", ".", "clone", "(", ")", "\n", "\n", "# eps = 8.0", "\n", "# iters = 100", "\n", "# alpha = 2.5*eps/float(iters)", "\n", "# # if sgd :", "\n", "# alpha*= 6000.0", "\n", "iters", "=", "1000", "\n", "alpha", "=", "1000.0", "\n", "print", "(", "\"the value of alpha is \"", ",", "alpha", ")", "\n", "#adv = adv + eps * (torch.rand_like(adv)-0.5)*2.0", "\n", "print", "(", "adv", "[", "0", ",", ":", ",", "-", "1", ",", "0", "]", ")", "\n", "for", "i", "in", "range", "(", "iters", ")", ":", "\n", "                ", "adv", ".", "requires_grad", "=", "True", "\n", "if", "adv", ".", "grad", "is", "not", "None", ":", "\n", "                    ", "adv", ".", "grad", ".", "data", ".", "_zero", "(", ")", "\n", "", "data", "=", "adv", "/", "255.0", "\n", "\n", "D_fake", ",", "D_real", "=", "GD", "(", "z_", "[", ":", "config", "[", "'batch_size'", "]", "]", ",", "y_", "[", ":", "config", "[", "'batch_size'", "]", "]", ",", "data", ",", "\n", "y_counter", ",", "train_G", "=", "False", ",", "split_D", "=", "config", "[", "'split_D'", "]", ")", "\n", "\n", "D_loss_real", ",", "D_loss_fake", "=", "discriminator_loss", "(", "\n", "D_fake", ",", "D_real", ")", "\n", "D_loss", "=", "-", "D_real", "\n", "D_loss", "=", "D_loss", ".", "sum", "(", ")", "\n", "D_loss", ".", "backward", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# if sgd :", "\n", "                    ", "adv", "=", "adv", "-", "alpha", "*", "adv", ".", "grad", "*", "mask", "\n", "# else :", "\n", "#     adv = adv - alpha * torch.sign(adv.grad) * mask", "\n", "#     adv = torch.min(adv, test_data+eps)", "\n", "#     adv = torch.max(adv, test_data-eps)", "\n", "adv", "=", "torch", ".", "clamp", "(", "adv", ",", "0.0", ",", "255.0", ")", "\n", "", "print", "(", "\"%d iters reached\"", "%", "i", ")", "\n", "print", "(", "adv", "[", "0", ",", ":", ",", "-", "1", ",", "0", "]", ")", "\n", "\n", "", "break", "\n", "\n", "\n", "", "corrupted_data", "=", "np", ".", "transpose", "(", "test_data", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n", "cleaned_data", "=", "np", ".", "transpose", "(", "adv", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n", "np", ".", "save", "(", "cleaned_dir", "+", "\"corruption.npy\"", ",", "corrupted_data", ")", "\n", "np", ".", "save", "(", "cleaned_dir", "+", "\"cleaned.npy\"", ",", "cleaned_data", ")", "\n", "\n", "\n", "\n", "", "return", "train", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns.GAN_MH": [[322, 404], ["train_fns.select_loss", "torch.distributions.Normal().log_prob().view().sum", "torch.distributions.Normal().log_prob().view().sum", "torch.distributions.Normal().log_prob().view().sum", "torch.distributions.Normal().log_prob().view().sum", "torch.distributions.Normal().log_prob().view().sum", "torch.distributions.Normal().log_prob().view().sum", "torch.distributions.Normal().log_prob().view().sum", "torch.distributions.Normal().log_prob().view().sum", "torch.exp", "torch.exp", "torch.zeros().to().long", "torch.zeros().to().long", "D", "torch.squeeze", "torch.squeeze", "numpy.transpose", "int", "float", "int", "print", "range", "numpy.concatenate", "print", "print", "numpy.save", "numpy.save", "numpy.load", "math.ceil", "torch.from_numpy().float", "torch.from_numpy().float", "test_data.to.to", "test_data.to.clone", "test_data.to.clone", "len", "numpy.min", "numpy.max", "torch.distributions.Normal().log_prob().view", "torch.distributions.Normal().log_prob().view", "torch.distributions.Normal().log_prob().view", "torch.distributions.Normal().log_prob().view", "torch.distributions.Normal().log_prob().view", "torch.distributions.Normal().log_prob().view", "torch.distributions.Normal().log_prob().view", "torch.distributions.Normal().log_prob().view", "torch.zeros().to", "torch.zeros().to", "[].split", "range", "torch.no_grad", "torch.no_grad", "range", "str", "str", "len", "len", "torch.from_numpy", "torch.from_numpy", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal.sample", "torch.clamp", "torch.clamp", "train_fns.GAN_MH.get_logp"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.select_loss", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.sample"], ["", "def", "GAN_MH", "(", "G", ",", "D", ",", "GD", ",", "z_", ",", "y_", ",", "ema", ",", "state_dict", ",", "config", ")", ":", "\n", "    ", "import", "numpy", "as", "np", "\n", "discriminator_loss", ",", "generator_loss", "=", "select_loss", "(", "config", ")", "\n", "\n", "def", "acceptance_rejection", "(", "x", ",", "x_new", ",", "x_logp", ",", "x_new_logp", ",", "x_corrupt", ",", "eps", "=", "2.0", ",", "eps_actual", "=", "4.0", ")", ":", "\n", "\n", "        ", "x_log_likelihood", "=", "torch", ".", "distributions", ".", "Normal", "(", "x", ",", "torch", ".", "ones", "(", "x", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", "*", "eps_actual", ")", ".", "log_prob", "(", "x_corrupt", ")", ".", "view", "(", "-", "1", ",", "3", "*", "32", "*", "32", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "x_new_log_likelihood", "=", "torch", ".", "distributions", ".", "Normal", "(", "x_new", ",", "torch", ".", "ones", "(", "x_new", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", "*", "eps_actual", ")", ".", "log_prob", "(", "x_corrupt", ")", ".", "view", "(", "-", "1", ",", "3", "*", "32", "*", "32", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n", "q_x_x_new", "=", "torch", ".", "distributions", ".", "Normal", "(", "x_new", ",", "torch", ".", "ones", "(", "x_new", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", "*", "eps", ")", ".", "log_prob", "(", "x", ")", ".", "view", "(", "-", "1", ",", "3", "*", "32", "*", "32", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "q_x_new_x", "=", "torch", ".", "distributions", ".", "Normal", "(", "x", ",", "torch", ".", "ones", "(", "x", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", "*", "eps", ")", ".", "log_prob", "(", "x_new", ")", ".", "view", "(", "-", "1", ",", "3", "*", "32", "*", "32", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n", "#numerator = x_new_logp + x_new_log_likelihood + q_x_x_new", "\n", "#denominator = x_logp + x_log_likelihood + q_x_new_x", "\n", "\n", "numerator", "=", "x_new_logp", "+", "q_x_x_new", "\n", "denominator", "=", "x_logp", "+", "q_x_new_x", "\n", "\n", "ratio", "=", "torch", ".", "exp", "(", "numerator", "-", "denominator", ")", "\n", "return", "ratio", "\n", "\n", "", "def", "get_logp", "(", "data", ",", "D", ")", ":", "\n", "# data = data/255.0", "\n", "        ", "y_counter", "=", "torch", ".", "zeros", "(", "data", ".", "size", "(", ")", "[", "0", "]", ")", ".", "to", "(", "\"cuda\"", ")", ".", "long", "(", ")", "\n", "D_real", "=", "D", "(", "data", "/", "255.0", ",", "y_counter", ")", "\n", "D_real", "=", "torch", ".", "squeeze", "(", "D_real", ",", "-", "1", ")", "\n", "return", "D_real", "\n", "\n", "", "def", "train", "(", ")", ":", "\n", "\n", "        ", "fname", "=", "\"../corrupt_robustness/robustness/ImageNet-C/create_c/synthetic_corruption/cifar_custom_noise_64.npy\"", "\n", "test_batch", "=", "np", ".", "transpose", "(", "np", ".", "load", "(", "fname", ")", ",", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "\n", "batch_size", "=", "50", "\n", "test_iters", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "test_batch", ")", "/", "batch_size", ")", ")", "\n", "eps_actual", "=", "float", "(", "fname", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", ")", "\n", "iters", "=", "int", "(", "config", "[", "'iters'", "]", ")", "\n", "eps", "=", "0.1", "\n", "cleaned_data", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "test_batch", ")", ")", "]", "\n", "\n", "print", "(", "\"total iterations are \"", ",", "test_iters", ")", "\n", "for", "idx", "in", "range", "(", "test_iters", ")", ":", "\n", "            ", "data_batch", "=", "test_batch", "[", "idx", "*", "batch_size", ":", "(", "idx", "+", "1", ")", "*", "batch_size", "]", "\n", "test_data", "=", "torch", ".", "from_numpy", "(", "data_batch", ")", ".", "float", "(", ")", "\n", "test_data", "=", "test_data", "=", "test_data", ".", "to", "(", "\"cuda\"", ")", "\n", "\n", "x_corrupt", "=", "test_data", ".", "clone", "(", ")", "\n", "x", "=", "test_data", ".", "clone", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "iters", ")", ":", "\n", "                    ", "q_dist", "=", "torch", ".", "distributions", ".", "Normal", "(", "x", ",", "torch", ".", "ones", "(", "x", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", "*", "eps", ")", "\n", "x_new", "=", "q_dist", ".", "sample", "(", ")", "\n", "x_new", "=", "torch", ".", "clamp", "(", "x_new", ",", "0.0", ",", "255.0", ")", "\n", "\n", "x_logp", "=", "get_logp", "(", "x", ",", "D", ")", "\n", "x_new_logp", "=", "get_logp", "(", "x_new", ",", "D", ")", "\n", "acceptance", "=", "acceptance_rejection", "(", "x", ",", "x_new", ",", "x_logp", ",", "x_new_logp", ",", "x_corrupt", ",", "eps", "=", "eps", ",", "eps_actual", "=", "eps_actual", ")", "\n", "x", "=", "x", ".", "clone", "(", ")", "\n", "for", "j", "in", "range", "(", "x", ".", "size", "(", ")", "[", "0", "]", ")", ":", "\n", "                        ", "ratio", "=", "acceptance", "[", "j", "]", ".", "item", "(", ")", "\n", "acceptance_prob", "=", "min", "(", "1", ",", "max", "(", "ratio", ",", "0", ")", ")", "\n", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "acceptance_prob", ":", "\n", "                            ", "x", "[", "j", "]", "=", "x_new", "[", "j", "]", "\n", "cleaned_data", "[", "idx", "*", "batch_size", "+", "j", "]", ".", "extend", "(", "np", ".", "expand_dims", "(", "x_new", "[", "j", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "0", ")", ")", "\n", "", "", "print", "(", "\"%d steps reached for idx %d\"", "%", "(", "i", ",", "idx", ")", ")", "\n", "\n", "\n", "", "", "", "cleaned_data_lengths", "=", "[", "len", "(", "val", ")", "for", "val", "in", "cleaned_data", "]", "\n", "cleaned_data", "=", "[", "val", "for", "val", "in", "cleaned_data", "if", "len", "(", "val", ")", ">", "0", "]", "\n", "cleaned_data", "=", "np", ".", "concatenate", "(", "cleaned_data", ")", "\n", "\n", "print", "(", "np", ".", "min", "(", "cleaned_data", ")", ",", "np", ".", "max", "(", "cleaned_data", ")", ",", "cleaned_data", ".", "shape", ")", "\n", "fname", "=", "\"synthetic/cifar_custom_noise_mh_\"", "+", "str", "(", "eps_actual", ")", "+", "\".npy\"", "\n", "print", "(", "\"the fname is \"", ",", "fname", ")", "\n", "np", ".", "save", "(", "fname", ",", "cleaned_data", ")", "\n", "len_fname", "=", "\"synthetic/cifar_custom_noise_length_mh_\"", "+", "str", "(", "eps_actual", ")", "+", "\".npy\"", "\n", "np", ".", "save", "(", "len_fname", ",", "cleaned_data_lengths", ")", "\n", "\n", "\n", "\n", "", "return", "train", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns.GAN_log_function": [[405, 549], ["torch.split", "torch.split", "range", "torch.stack", "torch.stack", "range", "torch.split", "torch.split", "range", "torch.squeeze", "torch.squeeze", "torch.randperm", "torch.randperm", "torch.split", "torch.split", "torch.split", "torch.split", "range", "range", "torch.cat", "torch.cat", "torch.randperm", "torch.randperm", "print", "int", "print", "mixup.size", "mixup.size", "int", "torch.split", "torch.split", "torch.cat", "torch.cat", "mixup.size", "mixup.size", "mixup.size", "[].item", "int", "int", "mixup.size", "config[].split", "print", "numpy.load", "int", "torch.zeros().to().long", "torch.zeros().to().long", "range", "numpy.array", "print", "print", "numpy.save", "int", "torch.cat.size", "torch.cat", "torch.cat", "int", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat", "torch.cat", "numpy.transpose", "torch.from_numpy().float", "torch.from_numpy().float", "test_data.to.to", "GD", "numpy.squeeze", "np.array.extend", "print", "numpy.min", "numpy.max", "int", "int", "numpy.reshape", "numpy.ones", "len", "torch.zeros().to", "torch.zeros().to", "int", "train_fns.GAN_log_function.jigsaw_k"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.jigsaw_k"], ["", "def", "GAN_log_function", "(", "G", ",", "D", ",", "GD", ",", "z_", ",", "y_", ",", "ema", ",", "state_dict", ",", "config", ")", ":", "\n", "    ", "import", "numpy", "as", "np", "\n", "discriminator_loss", "=", "losses", ".", "loss_hinge_analysis", "\n", "\n", "def", "jigsaw_k", "(", "data", ",", "k", "=", "2", ")", ":", "\n", "        ", "actual_h", "=", "data", ".", "size", "(", ")", "[", "2", "]", "\n", "actual_w", "=", "data", ".", "size", "(", ")", "[", "3", "]", "\n", "h", "=", "torch", ".", "split", "(", "data", ",", "int", "(", "actual_h", "/", "k", ")", ",", "dim", "=", "2", ")", "\n", "splits", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k", ")", ":", "\n", "            ", "splits", "+=", "torch", ".", "split", "(", "h", "[", "i", "]", ",", "int", "(", "actual_w", "/", "k", ")", ",", "dim", "=", "3", ")", "\n", "", "fake_samples", "=", "torch", ".", "stack", "(", "splits", ",", "-", "1", ")", "\n", "for", "idx", "in", "range", "(", "fake_samples", ".", "size", "(", ")", "[", "0", "]", ")", ":", "\n", "            ", "fake_samples", "[", "idx", "]", "=", "fake_samples", "[", "idx", ",", ":", ",", ":", ",", ":", ",", "torch", ".", "randperm", "(", "k", "*", "k", ")", "]", "\n", "", "fake_samples", "=", "torch", ".", "split", "(", "fake_samples", ",", "1", ",", "dim", "=", "4", ")", "\n", "merged", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k", ")", ":", "\n", "            ", "merged", "+=", "[", "torch", ".", "cat", "(", "fake_samples", "[", "i", "*", "k", ":", "(", "i", "+", "1", ")", "*", "k", "]", ",", "2", ")", "]", "\n", "", "fake_samples", "=", "torch", ".", "squeeze", "(", "torch", ".", "cat", "(", "merged", ",", "3", ")", ",", "-", "1", ")", "\n", "return", "fake_samples", "\n", "\n", "", "def", "stitch", "(", "data", ",", "k", "=", "2", ")", ":", "\n", "        ", "indices", "=", "torch", ".", "randperm", "(", "data", ".", "size", "(", "0", ")", ")", "\n", "data_perm", "=", "data", "[", "indices", "]", "\n", "actual_h", "=", "data", ".", "size", "(", ")", "[", "2", "]", "\n", "actual_w", "=", "data", ".", "size", "(", ")", "[", "3", "]", "\n", "if", "torch", ".", "randint", "(", "0", ",", "2", ",", "(", "1", ",", ")", ")", "[", "0", "]", ".", "item", "(", ")", "==", "0", ":", "\n", "            ", "dim0", ",", "dim1", "=", "2", ",", "3", "\n", "", "else", ":", "\n", "            ", "dim0", ",", "dim1", "=", "3", ",", "2", "\n", "\n", "", "h", "=", "torch", ".", "split", "(", "data", ",", "int", "(", "actual_h", "/", "k", ")", ",", "dim", "=", "dim0", ")", "\n", "h_1", "=", "torch", ".", "split", "(", "data_perm", ",", "int", "(", "actual_h", "/", "k", ")", ",", "dim", "=", "dim0", ")", "\n", "splits", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k", ")", ":", "\n", "            ", "if", "i", "<", "int", "(", "k", "/", "2", ")", ":", "\n", "                ", "splits", "+=", "torch", ".", "split", "(", "h", "[", "i", "]", ",", "int", "(", "actual_w", "/", "k", ")", ",", "dim", "=", "dim1", ")", "\n", "", "else", ":", "\n", "                ", "splits", "+=", "torch", ".", "split", "(", "h_1", "[", "i", "]", ",", "int", "(", "actual_w", "/", "k", ")", ",", "dim", "=", "dim1", ")", "\n", "", "", "merged", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k", ")", ":", "\n", "            ", "merged", "+=", "[", "torch", ".", "cat", "(", "splits", "[", "i", "*", "k", ":", "(", "i", "+", "1", ")", "*", "k", "]", ",", "dim1", ")", "]", "\n", "", "fake_samples", "=", "torch", ".", "cat", "(", "merged", ",", "dim0", ")", "\n", "\n", "return", "fake_samples", "\n", "\n", "", "def", "mixup", "(", "data", ",", "alpha", "=", "1.0", ")", ":", "\n", "#lamb = np.random.beta(alpha, alpha)", "\n", "        ", "lamb", "=", "0.5", "\n", "indices", "=", "torch", ".", "randperm", "(", "data", ".", "size", "(", "0", ")", ")", "\n", "data_perm", "=", "data", "[", "indices", "]", "\n", "return", "data", "*", "lamb", "+", "(", "1", "-", "lamb", ")", "*", "data_perm", "\n", "\n", "", "def", "train", "(", ")", ":", "\n", "\n", "        ", "corrupt_dict", "=", "{", "'elastic'", ":", "'elastic_transform'", ",", "'jpeg'", ":", "'jpeg_compression'", ",", "'speckle'", ":", "'speckle_noise'", ",", "'gaussian'", ":", "'gaussian_noise'", ",", "\n", "'blur'", ":", "'gaussian_blur'", ",", "\n", "'zoom'", ":", "'zoom_blur'", ",", "'brightness'", ":", "'brightness'", ",", "'contrast'", ":", "'contrast'", ",", "'defocus'", ":", "'defocus_blur'", ",", "\n", "'fog'", ":", "'fog'", ",", "'frost'", ":", "'frost'", ",", "'glass'", ":", "'glass_blur'", ",", "'impulse'", ":", "'impulse_noise'", ",", "'motion'", ":", "'motion_blur'", ",", "\n", "'pixelate'", ":", "'pixelate'", ",", "'saturate'", ":", "'saturate'", ",", "'shot'", ":", "'shot_noise'", ",", "'snow'", ":", "'snow'", ",", "'spatter'", ":", "'spatter'", ",", "\n", "'train'", ":", "'train_samples'", ",", "'test'", ":", "'test_samples'", ",", "'svhn'", ":", "'svhn_test_data'", ",", "'jigsaw_2'", ":", "'test_samples'", ",", "\n", "'jigsaw_4'", ":", "'test_samples'", ",", "'jigsaw_8'", ":", "'test_samples'", ",", "'jigsaw_16'", ":", "'test_samples'", ",", "'noise'", ":", "'noise'", ",", "\n", "'stitch'", ":", "'test_samples'", ",", "'mixup'", ":", "'test_samples'", ",", "'dtd'", ":", "'dtd_images'", ",", "'uniform'", ":", "'test_samples'", "\n", "}", "\n", "\n", "#if not config['data_type'] == 'all' :", "\n", "#    corrupt_dict = {config['data_type'] : corrupt_dict[config['data_type']]} ", "\n", "if", "not", "config", "[", "'data_type'", "]", "==", "'all'", ":", "\n", "            ", "corruptions", "=", "config", "[", "'data_type'", "]", ".", "split", "(", "\",\"", ")", "\n", "corrupt_dict_new", "=", "{", "}", "\n", "print", "(", "\"the corruptions are \"", ",", "corruptions", ")", "\n", "for", "corruption", "in", "corruptions", ":", "\n", "                ", "corrupt_dict_new", "[", "corruption", "]", "=", "corrupt_dict", "[", "corruption", "]", "\n", "", "corrupt_dict", "=", "corrupt_dict_new", "\n", "\n", "", "base_dir", "=", "\"../mintnet/CIFAR-10-C/\"", "\n", "#base_dir = \"corruption_new/\"", "\n", "print", "(", "\"the value of eps is \"", ",", "config", "[", "'eps'", "]", ")", "\n", "eps", "=", "int", "(", "config", "[", "'eps'", "]", ")", "\n", "out_dir", "=", "\"corruption1/\"", "\n", "if", "\"jigsaw\"", "in", "config", "[", "'experiment_name'", "]", ":", "\n", "            ", "out_dir", "=", "\"corruption_new1/\"", "\n", "", "if", "'stitch'", "in", "config", "[", "'experiment_name'", "]", ":", "\n", "            ", "out_dir", "=", "\"stitch/\"", "\n", "", "print", "(", "\"the out dir is \"", ",", "out_dir", ")", "\n", "for", "mode", "in", "corrupt_dict", ":", "\n", "\n", "# test_batch = np.transpose(np.load(\"../mintnet/CIFAR-10-C/elastic_transform.npy\"), (0, 3, 1, 2))[-10000:]", "\n", "\n", "            ", "test_batch", "=", "np", ".", "load", "(", "base_dir", "+", "corrupt_dict", "[", "mode", "]", "+", "\".npy\"", ")", "\n", "\n", "#test_batch = np.load(base_dir + mode+\"_sgd_\" + str(eps) + \".npy\")", "\n", "if", "test_batch", ".", "shape", "[", "-", "1", "]", "==", "3", ":", "\n", "                ", "test_batch", "=", "np", ".", "transpose", "(", "test_batch", ",", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "\n", "", "if", "mode", "==", "\"uniform\"", ":", "\n", "                ", "test_batch", "=", "np", ".", "reshape", "(", "np", ".", "arange", "(", "250", ")", ",", "[", "-", "1", ",", "1", ",", "1", ",", "1", "]", ")", "*", "np", ".", "ones", "(", "[", "250", ",", "3", ",", "32", ",", "32", "]", ")", "\n", "", "batch_size", "=", "50", "\n", "test_iters", "=", "int", "(", "len", "(", "test_batch", ")", "/", "batch_size", ")", "\n", "logp", "=", "[", "]", "\n", "y_counter", "=", "torch", ".", "zeros", "(", "batch_size", ")", ".", "to", "(", "\"cuda\"", ")", ".", "long", "(", ")", "\n", "losses", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "test_iters", ")", ":", "\n", "                ", "data_batch", "=", "test_batch", "[", "idx", "*", "batch_size", ":", "(", "idx", "+", "1", ")", "*", "batch_size", "]", "\n", "test_data", "=", "torch", ".", "from_numpy", "(", "data_batch", ")", ".", "float", "(", ")", "\n", "test_data", "=", "test_data", ".", "to", "(", "\"cuda\"", ")", "\n", "\n", "data", "=", "test_data", "/", "255.0", "\n", "data", "=", "(", "data", "-", "0.5", ")", "/", "0.5", "\n", "if", "'jigsaw'", "in", "mode", ":", "\n", "                    ", "k", "=", "int", "(", "mode", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ")", "\n", "data", "=", "jigsaw_k", "(", "data", ",", "k", "=", "k", ")", "\n", "", "elif", "'stitch'", "in", "mode", ":", "\n", "                    ", "data", "=", "stitch", "(", "data", ")", "\n", "", "elif", "'mixup'", "in", "mode", ":", "\n", "                    ", "data", "=", "mixup", "(", "data", ")", "\n", "\n", "", "D_fake", ",", "D_real", "=", "GD", "(", "z_", "[", ":", "config", "[", "'batch_size'", "]", "]", ",", "y_", "[", ":", "config", "[", "'batch_size'", "]", "]", ",", "data", ",", "\n", "y_counter", ",", "train_G", "=", "False", ",", "split_D", "=", "config", "[", "'split_D'", "]", ")", "\n", "\n", "#D_loss_real = discriminator_loss(", "\n", "#        D_real)", "\n", "\n", "#D_loss_real_np = np.squeeze(D_loss_real.cpu().data.numpy(), -1) ", "\n", "D_real_np", "=", "np", ".", "squeeze", "(", "D_real", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "-", "1", ")", "\n", "\n", "logp", ".", "extend", "(", "D_real_np", ")", "\n", "#losses.extend(D_loss_real_np)", "\n", "print", "(", "\"%d iters reached\"", "%", "idx", ")", "\n", "\n", "\n", "", "logp", "=", "np", ".", "array", "(", "logp", ")", "\n", "#losses = np.array(losses)", "\n", "# print(np.min(cleaned_data), np.max(cleaned_data), cleaned_data.shape)", "\n", "# np.save(\"corruption/elastic_pgd.npy\", cleaned_data)", "\n", "print", "(", "\"logp calculation done for the corruption \"", ",", "mode", ",", "\" and the shape of data is \"", ",", "logp", ".", "shape", ",", "\" min is \"", ",", "np", ".", "min", "(", "logp", ")", ",", "\n", "\" max is \"", ",", "np", ".", "max", "(", "logp", ")", ")", "\n", "#np.save(\"corruption_new/\"+mode+\"_sgd_\" + str(eps) + \"_logp.npy\", logp)", "\n", "print", "(", "\"the fname is \"", ",", "out_dir", "+", "mode", "+", "\"_logp.npy\"", ")", "\n", "np", ".", "save", "(", "out_dir", "+", "mode", "+", "\"_logp.npy\"", ",", "logp", ")", "\n", "#np.save(\"corruption/temp.npy\", losses)", "\n", "#break", "\n", "\n", "\n", "", "", "return", "train", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns.GAN_auroc_function": [[550, 634], ["print", "open.write", "open.close", "config[].split", "print", "numpy.load", "open", "int", "torch.zeros().to().long", "torch.zeros().to().long", "range", "numpy.array", "numpy.array", "numpy.array", "sklearn.metrics.roc_auc_score", "auroc_scores.append", "print", "open.write", "numpy.mean", "numpy.load", "open", "numpy.load", "open", "numpy.load", "numpy.transpose", "torch.from_numpy().float", "torch.from_numpy().float", "test_data.to.to", "GD", "numpy.squeeze", "np.array.extend", "print", "len", "torch.zeros().to", "torch.zeros().to", "D_real.cpu().data.numpy", "list", "list", "list", "list", "str", "torch.from_numpy", "torch.from_numpy", "numpy.zeros", "numpy.ones", "str", "numpy.mean", "torch.zeros", "torch.zeros", "str", "D_real.cpu", "len", "len"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to"], ["", "def", "GAN_auroc_function", "(", "G", ",", "D", ",", "GD", ",", "z_", ",", "y_", ",", "ema", ",", "state_dict", ",", "config", ")", ":", "\n", "    ", "import", "numpy", "as", "np", "\n", "discriminator_loss", "=", "losses", ".", "loss_hinge_analysis", "\n", "\n", "def", "train", "(", ")", ":", "\n", "\n", "        ", "corrupt_dict", "=", "{", "'svhn'", ":", "'svhn_test_data'", ",", "'C100'", ":", "'cifar100_normal_10k'", ",", "'places'", ":", "'places'", ",", "'dtd'", ":", "'textures_new'", ",", "'timagenet'", ":", "'timagenet'", ",", "\n", "'elastic'", ":", "'elastic_transform'", ",", "'jpeg'", ":", "'jpeg_compression'", ",", "'speckle'", ":", "'speckle_noise'", ",", "'gaussian'", ":", "'gaussian_noise'", ",", "\n", "'blur'", ":", "'gaussian_blur'", ",", "\n", "'zoom'", ":", "'zoom_blur'", ",", "'brightness'", ":", "'brightness'", ",", "'contrast'", ":", "'contrast'", ",", "'defocus'", ":", "'defocus_blur'", ",", "\n", "'fog'", ":", "'fog'", ",", "'frost'", ":", "'frost'", ",", "'glass'", ":", "'glass_blur'", ",", "'impulse'", ":", "'impulse_noise'", ",", "'motion'", ":", "'motion_blur'", ",", "\n", "'pixelate'", ":", "'pixelate'", ",", "'saturate'", ":", "'saturate'", ",", "'shot'", ":", "'shot_noise'", ",", "'snow'", ":", "'snow'", ",", "'spatter'", ":", "'spatter'", "\n", "}", "\n", "\n", "#if not config['data_type'] == 'all' :", "\n", "#    corrupt_dict = {config['data_type'] : corrupt_dict[config['data_type']]} ", "\n", "if", "not", "config", "[", "'data_type'", "]", "==", "'all'", ":", "\n", "            ", "corruptions", "=", "config", "[", "'data_type'", "]", ".", "split", "(", "\",\"", ")", "\n", "corrupt_dict_new", "=", "{", "}", "\n", "print", "(", "\"the corruptions are \"", ",", "corruptions", ")", "\n", "for", "corruption", "in", "corruptions", ":", "\n", "                ", "corrupt_dict_new", "[", "corruption", "]", "=", "corrupt_dict", "[", "corruption", "]", "\n", "", "corrupt_dict", "=", "corrupt_dict_new", "\n", "\n", "", "base_dir", "=", "\"../mintnet/CIFAR-10-C/\"", "\n", "#base_dir = \"corruption_new/\"", "\n", "if", "\"jigsaw\"", "in", "config", "[", "'experiment_name'", "]", ":", "\n", "            ", "pos_logp", "=", "np", ".", "load", "(", "\"corruption_new1/test_logp.npy\"", ")", "\n", "f", "=", "open", "(", "\"auroc_jigsaw.txt\"", ",", "\"w\"", ")", "\n", "", "elif", "\"stitch\"", "in", "config", "[", "'experiment_name'", "]", ":", "\n", "            ", "pos_logp", "=", "np", ".", "load", "(", "\"stitch/test_logp.npy\"", ")", "\n", "f", "=", "open", "(", "\"auroc_stitch.txt\"", ",", "\"w\"", ")", "\n", "", "else", ":", "\n", "            ", "pos_logp", "=", "np", ".", "load", "(", "\"corruption1/test_logp.npy\"", ")", "\n", "f", "=", "open", "(", "\"auroc.txt\"", ",", "\"w\"", ")", "\n", "\n", "", "auroc_scores", "=", "[", "]", "\n", "\n", "\n", "for", "mode", "in", "corrupt_dict", ":", "\n", "\n", "            ", "test_batch", "=", "np", ".", "load", "(", "base_dir", "+", "corrupt_dict", "[", "mode", "]", "+", "\".npy\"", ")", "[", "-", "10000", ":", "]", "\n", "\n", "if", "test_batch", ".", "shape", "[", "-", "1", "]", "==", "3", ":", "\n", "                ", "test_batch", "=", "np", ".", "transpose", "(", "test_batch", ",", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "\n", "\n", "", "batch_size", "=", "50", "\n", "test_iters", "=", "int", "(", "len", "(", "test_batch", ")", "/", "batch_size", ")", "\n", "logp", "=", "[", "]", "\n", "y_counter", "=", "torch", ".", "zeros", "(", "batch_size", ")", ".", "to", "(", "\"cuda\"", ")", ".", "long", "(", ")", "\n", "losses", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "test_iters", ")", ":", "\n", "                ", "data_batch", "=", "test_batch", "[", "idx", "*", "batch_size", ":", "(", "idx", "+", "1", ")", "*", "batch_size", "]", "\n", "test_data", "=", "torch", ".", "from_numpy", "(", "data_batch", ")", ".", "float", "(", ")", "\n", "test_data", "=", "test_data", ".", "to", "(", "\"cuda\"", ")", "\n", "\n", "data", "=", "test_data", "/", "255.0", "\n", "data", "=", "(", "data", "-", "0.5", ")", "/", "0.5", "\n", "\n", "D_fake", ",", "D_real", "=", "GD", "(", "z_", "[", ":", "config", "[", "'batch_size'", "]", "]", ",", "y_", "[", ":", "config", "[", "'batch_size'", "]", "]", ",", "data", ",", "\n", "y_counter", ",", "train_G", "=", "False", ",", "split_D", "=", "config", "[", "'split_D'", "]", ")", "\n", "\n", "D_real_np", "=", "np", ".", "squeeze", "(", "D_real", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "-", "1", ")", "\n", "\n", "logp", ".", "extend", "(", "D_real_np", ")", "\n", "print", "(", "\"%d iters reached\"", "%", "idx", ")", "\n", "\n", "\n", "", "logp", "=", "np", ".", "array", "(", "logp", ")", "\n", "\n", "y_true", "=", "np", ".", "array", "(", "list", "(", "np", ".", "zeros", "(", "[", "len", "(", "logp", ")", "]", ")", ")", "+", "list", "(", "np", ".", "ones", "(", "[", "len", "(", "pos_logp", ")", "]", ")", ")", ")", "\n", "y_scores", "=", "np", ".", "array", "(", "list", "(", "logp", ")", "+", "list", "(", "pos_logp", ")", ")", "\n", "auroc", "=", "roc_auc_score", "(", "y_true", ",", "y_scores", ")", "\n", "auroc_scores", ".", "append", "(", "auroc", ")", "\n", "print", "(", "\"for the mode \"", ",", "mode", ",", "\" the ROC score is \"", ",", "auroc", ")", "\n", "f", ".", "write", "(", "str", "(", "mode", ")", "+", "\" \"", "+", "str", "(", "auroc", ")", "+", "\"\\n\"", ")", "\n", "\n", "\n", "\n", "", "print", "(", "\"the mean score is \"", ",", "np", ".", "mean", "(", "auroc_scores", ")", ")", "\n", "f", ".", "write", "(", "\"mean \"", "+", "str", "(", "np", ".", "mean", "(", "auroc_scores", ")", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n", "", "return", "train", "\n", ""]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns.save_and_sample": [[640, 700], ["utils.save_weights", "torchvision.utils.save_image", "utils.sample_sheet", "zip", "utils.save_weights", "utils.accumulate_standing_stats", "torch.no_grad", "torch.no_grad", "os.path.isdir", "os.mkdir", "which_G.float().cpu", "utils.interp_sheet", "y_.zero_", "torch.parallel.data_parallel", "which_G", "int", "which_G.shared", "which_G.float", "which_G.shared"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.save_weights", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.sample_sheet", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.save_weights", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.accumulate_standing_stats", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.interp_sheet"], ["def", "save_and_sample", "(", "G", ",", "D", ",", "G_ema", ",", "z_", ",", "y_", ",", "fixed_z", ",", "fixed_y", ",", "\n", "state_dict", ",", "config", ",", "experiment_name", ")", ":", "\n", "    ", "utils", ".", "save_weights", "(", "G", ",", "D", ",", "state_dict", ",", "config", "[", "'weights_root'", "]", ",", "\n", "experiment_name", ",", "None", ",", "G_ema", "if", "config", "[", "'ema'", "]", "else", "None", ")", "\n", "# Save an additional copy to mitigate accidental corruption if process", "\n", "# is killed during a save (it's happened to me before -.-)", "\n", "if", "config", "[", "'num_save_copies'", "]", ">", "0", ":", "\n", "        ", "utils", ".", "save_weights", "(", "G", ",", "D", ",", "state_dict", ",", "config", "[", "'weights_root'", "]", ",", "\n", "experiment_name", ",", "\n", "'copy%d'", "%", "state_dict", "[", "'save_num'", "]", ",", "\n", "G_ema", "if", "config", "[", "'ema'", "]", "else", "None", ")", "\n", "state_dict", "[", "'save_num'", "]", "=", "(", "\n", "state_dict", "[", "'save_num'", "]", "+", "1", ")", "%", "config", "[", "'num_save_copies'", "]", "\n", "\n", "# Use EMA G for samples or non-EMA?", "\n", "", "which_G", "=", "G_ema", "if", "config", "[", "'ema'", "]", "and", "config", "[", "'use_ema'", "]", "else", "G", "\n", "\n", "# Accumulate standing statistics?", "\n", "if", "config", "[", "'accumulate_stats'", "]", ":", "\n", "        ", "if", "not", "config", "[", "'conditional'", "]", ":", "\n", "            ", "y_", ".", "zero_", "(", ")", "\n", "", "utils", ".", "accumulate_standing_stats", "(", "G_ema", "if", "config", "[", "'ema'", "]", "and", "config", "[", "'use_ema'", "]", "else", "G", ",", "\n", "z_", ",", "y_", ",", "config", "[", "'n_classes'", "]", ",", "\n", "config", "[", "'num_standing_accumulations'", "]", ")", "\n", "\n", "# Save a random sample sheet with fixed z and y", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "if", "config", "[", "'parallel'", "]", ":", "\n", "            ", "fixed_Gz", "=", "nn", ".", "parallel", ".", "data_parallel", "(", "\n", "which_G", ",", "(", "fixed_z", ",", "which_G", ".", "shared", "(", "fixed_y", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "fixed_Gz", "=", "which_G", "(", "fixed_z", ",", "which_G", ".", "shared", "(", "fixed_y", ")", ")", "\n", "", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "'%s/%s'", "%", "(", "config", "[", "'samples_root'", "]", ",", "experiment_name", ")", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "'%s/%s'", "%", "(", "config", "[", "'samples_root'", "]", ",", "experiment_name", ")", ")", "\n", "", "image_filename", "=", "'%s/%s/fixed_samples%d.jpg'", "%", "(", "config", "[", "'samples_root'", "]", ",", "\n", "experiment_name", ",", "\n", "state_dict", "[", "'itr'", "]", ")", "\n", "torchvision", ".", "utils", ".", "save_image", "(", "fixed_Gz", ".", "float", "(", ")", ".", "cpu", "(", ")", ",", "image_filename", ",", "\n", "nrow", "=", "int", "(", "fixed_Gz", ".", "shape", "[", "0", "]", "**", "0.5", ")", ",", "normalize", "=", "True", ")", "\n", "# For now, every time we save, also save sample sheets", "\n", "utils", ".", "sample_sheet", "(", "which_G", ",", "\n", "classes_per_sheet", "=", "utils", ".", "classes_per_sheet_dict", "[", "config", "[", "'dataset'", "]", "]", ",", "\n", "num_classes", "=", "config", "[", "'n_classes'", "]", ",", "\n", "samples_per_class", "=", "10", ",", "parallel", "=", "config", "[", "'parallel'", "]", ",", "\n", "samples_root", "=", "config", "[", "'samples_root'", "]", ",", "\n", "experiment_name", "=", "experiment_name", ",", "\n", "folder_number", "=", "state_dict", "[", "'itr'", "]", ",", "\n", "z_", "=", "z_", ")", "\n", "# Also save interp sheets", "\n", "for", "fix_z", ",", "fix_y", "in", "zip", "(", "[", "False", ",", "False", ",", "True", "]", ",", "[", "False", ",", "True", ",", "False", "]", ")", ":", "\n", "        ", "utils", ".", "interp_sheet", "(", "which_G", ",", "\n", "num_per_sheet", "=", "16", ",", "\n", "num_midpoints", "=", "8", ",", "\n", "num_classes", "=", "config", "[", "'n_classes'", "]", ",", "\n", "parallel", "=", "config", "[", "'parallel'", "]", ",", "\n", "samples_root", "=", "config", "[", "'samples_root'", "]", ",", "\n", "experiment_name", "=", "experiment_name", ",", "\n", "folder_number", "=", "state_dict", "[", "'itr'", "]", ",", "\n", "sheet_number", "=", "0", ",", "\n", "fix_z", "=", "fix_z", ",", "fix_y", "=", "fix_y", ",", "device", "=", "'cuda'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns.test": [[707, 759], ["print", "ResNet18", "clf.to.load_state_dict", "clf.to.to", "clf.to.eval", "train_fns.classify_examples", "utils.fairness_discrepancy", "print", "print", "get_inception_metrics", "print", "max", "min", "min", "test_log.log", "torch.cuda.is_available", "torch.cuda.is_available", "utils.accumulate_standing_stats", "print", "utils.save_weights", "torch.load", "torch.load", "int", "float", "float", "float"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Adam16.load_state_dict", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.classify_examples", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.fairness_discrepancy", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MyLogger.log", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.accumulate_standing_stats", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.save_weights"], ["def", "test", "(", "G", ",", "D", ",", "G_ema", ",", "z_", ",", "y_", ",", "state_dict", ",", "config", ",", "sample", ",", "get_inception_metrics", ",", "\n", "experiment_name", ",", "test_log", ")", ":", "\n", "    ", "\"\"\"\n    Saving the appropriate metrics for sample quality (FID) and level of bias\n    \"\"\"", "\n", "print", "(", "'Pre-loading pre-trained attribute classifier...'", ")", "\n", "if", "config", "[", "'n_classes'", "]", "==", "2", ":", "\n", "        ", "clf_state_dict", "=", "torch", ".", "load", "(", "CLF_PATH", ")", "[", "'state_dict'", "]", "\n", "", "else", ":", "\n", "# multi-attribute", "\n", "        ", "raise", "NotImplementedError", "\n", "# load attribute classifier here", "\n", "", "clf", "=", "ResNet18", "(", "block", "=", "BasicBlock", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "num_classes", "=", "config", "[", "'n_classes'", "]", ",", "grayscale", "=", "False", ")", "\n", "clf", ".", "load_state_dict", "(", "clf_state_dict", ")", "\n", "device", "=", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", "\n", "clf", "=", "clf", ".", "to", "(", "device", ")", "\n", "clf", ".", "eval", "(", ")", "# turn off batch norm", "\n", "\n", "# obtain classifier predictions for samples", "\n", "preds", "=", "classify_examples", "(", "clf", ",", "config", ")", "# (10K,)", "\n", "fair_d", "=", "utils", ".", "fairness_discrepancy", "(", "preds", ",", "config", "[", "'n_classes'", "]", ")", "\n", "print", "(", "'Fairness discrepancy metric is: {}'", ".", "format", "(", "fair_d", ")", ")", "\n", "\n", "print", "(", "'Gathering inception metrics...'", ")", "\n", "if", "config", "[", "'accumulate_stats'", "]", ":", "\n", "        ", "utils", ".", "accumulate_standing_stats", "(", "G_ema", "if", "config", "[", "'ema'", "]", "and", "config", "[", "'use_ema'", "]", "else", "G", ",", "\n", "z_", ",", "y_", ",", "config", "[", "'n_classes'", "]", ",", "\n", "config", "[", "'num_standing_accumulations'", "]", ")", "\n", "", "IS_mean", ",", "IS_std", ",", "FID", "=", "get_inception_metrics", "(", "sample", ",", "\n", "config", "[", "'num_inception_images'", "]", ",", "\n", "num_splits", "=", "10", ")", "\n", "print", "(", "'Itr %d: PYTORCH UNOFFICIAL Inception Score is %3.3f +/- %3.3f, PYTORCH UNOFFICIAL FID is %5.4f'", "%", "\n", "(", "state_dict", "[", "'itr'", "]", ",", "IS_mean", ",", "IS_std", ",", "FID", ")", ")", "\n", "# If improved over previous best metric, save approrpiate copy", "\n", "if", "(", "(", "config", "[", "'which_best'", "]", "==", "'IS'", "and", "IS_mean", ">", "state_dict", "[", "'best_IS'", "]", ")", "\n", "or", "(", "config", "[", "'which_best'", "]", "==", "'FID'", "and", "FID", "<", "state_dict", "[", "'best_FID'", "]", ")", "\n", "or", "(", "config", "[", "'which_best'", "]", "==", "'fair'", "and", "fair_d", "<", "state_dict", "[", "'best_fair_d'", "]", ")", "\n", ")", ":", "\n", "        ", "print", "(", "'%s improved over previous best, saving checkpoint...'", "%", "\n", "config", "[", "'which_best'", "]", ")", "\n", "utils", ".", "save_weights", "(", "G", ",", "D", ",", "state_dict", ",", "config", "[", "'weights_root'", "]", ",", "\n", "experiment_name", ",", "'best%d'", "%", "state_dict", "[", "'save_best_num'", "]", ",", "\n", "G_ema", "if", "config", "[", "'ema'", "]", "else", "None", ")", "\n", "state_dict", "[", "'save_best_num'", "]", "=", "(", "\n", "state_dict", "[", "'save_best_num'", "]", "+", "1", ")", "%", "config", "[", "'num_best_copies'", "]", "\n", "", "state_dict", "[", "'best_IS'", "]", "=", "max", "(", "state_dict", "[", "'best_IS'", "]", ",", "IS_mean", ")", "\n", "state_dict", "[", "'best_FID'", "]", "=", "min", "(", "state_dict", "[", "'best_FID'", "]", ",", "FID", ")", "\n", "state_dict", "[", "'best_fair_d'", "]", "=", "min", "(", "state_dict", "[", "'best_fair_d'", "]", ",", "fair_d", ")", "\n", "# Log results to file", "\n", "test_log", ".", "log", "(", "itr", "=", "int", "(", "state_dict", "[", "'itr'", "]", ")", ",", "IS_mean", "=", "float", "(", "IS_mean", ")", ",", "\n", "IS_std", "=", "float", "(", "IS_std", ")", ",", "FID", "=", "float", "(", "FID", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns.update_FID": [[760, 777], ["print", "min", "test_log.log", "print", "utils.save_weights", "int", "float", "float", "float"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MyLogger.log", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.save_weights"], ["", "def", "update_FID", "(", "G", ",", "D", ",", "G_ema", ",", "state_dict", ",", "config", ",", "FID", ",", "experiment_name", ",", "test_log", ")", ":", "\n", "    ", "print", "(", "'Itr %d: PYTORCH UNOFFICIAL FID is %5.4f'", "%", "\n", "(", "state_dict", "[", "'itr'", "]", ",", "FID", ")", ")", "\n", "# If improved over previous best metric, save approrpiate copy", "\n", "if", "(", "(", "config", "[", "'which_best'", "]", "==", "'IS'", "and", "IS_mean", ">", "state_dict", "[", "'best_IS'", "]", ")", "\n", "or", "(", "config", "[", "'which_best'", "]", "==", "'FID'", "and", "FID", "<", "state_dict", "[", "'best_FID'", "]", ")", ")", ":", "\n", "        ", "print", "(", "'%s improved over previous best, saving checkpoint...'", "%", "\n", "config", "[", "'which_best'", "]", ")", "\n", "utils", ".", "save_weights", "(", "G", ",", "D", ",", "state_dict", ",", "config", "[", "'weights_root'", "]", ",", "\n", "experiment_name", ",", "'best%d'", "%", "state_dict", "[", "'save_best_num'", "]", ",", "\n", "G_ema", "if", "config", "[", "'ema'", "]", "else", "None", ")", "\n", "state_dict", "[", "'save_best_num'", "]", "=", "(", "\n", "state_dict", "[", "'save_best_num'", "]", "+", "1", ")", "%", "config", "[", "'num_best_copies'", "]", "\n", "", "state_dict", "[", "'best_FID'", "]", "=", "min", "(", "state_dict", "[", "'best_FID'", "]", ",", "FID", ")", "\n", "# Log results to file", "\n", "test_log", ".", "log", "(", "itr", "=", "int", "(", "state_dict", "[", "'itr'", "]", ")", ",", "IS_mean", "=", "float", "(", "0", ")", ",", "\n", "IS_std", "=", "float", "(", "0", ")", ",", "FID", "=", "float", "(", "FID", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns.classify_examples": [[778, 802], ["model.eval", "numpy.load", "torch.no_grad", "torch.no_grad", "range", "torch.cat().data.cpu().numpy", "torch.cat().data.cpu().numpy", "torch.from_numpy().to().float", "torch.from_numpy().to().float", "model", "torch.max", "torch.max", "torch.cat().data.cpu().numpy.append", "torch.cat().data.cpu", "torch.cat().data.cpu", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy", "torch.from_numpy", "torch.cat", "torch.cat"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to"], ["", "def", "classify_examples", "(", "model", ",", "config", ")", ":", "\n", "    ", "\"\"\"\n    classifies generated samples into appropriate classes \n    \"\"\"", "\n", "import", "numpy", "as", "np", "\n", "model", ".", "eval", "(", ")", "\n", "preds", "=", "[", "]", "\n", "samples", "=", "np", ".", "load", "(", "config", "[", "'sample_path'", "]", ")", "[", "'x'", "]", "\n", "n_batches", "=", "samples", ".", "shape", "[", "0", "]", "//", "1000", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# generate 10K samples", "\n", "        ", "for", "i", "in", "range", "(", "n_batches", ")", ":", "\n", "            ", "x", "=", "samples", "[", "i", "*", "1000", ":", "(", "i", "+", "1", ")", "*", "1000", "]", "\n", "samp", "=", "x", "/", "255.", "# renormalize to feed into classifier", "\n", "samp", "=", "torch", ".", "from_numpy", "(", "samp", ")", ".", "to", "(", "'cuda'", ")", ".", "float", "(", ")", "\n", "\n", "# get classifier predictions", "\n", "logits", ",", "probas", "=", "model", "(", "samp", ")", "\n", "_", ",", "pred", "=", "torch", ".", "max", "(", "probas", ",", "1", ")", "\n", "preds", ".", "append", "(", "pred", ")", "\n", "", "preds", "=", "torch", ".", "cat", "(", "preds", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "return", "preds", "\n", "", ""]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN_new.Generator.__init__": [[56, 207], ["torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Module.__init__", "functools.partial", "BigGAN_new.Generator.which_linear", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "BigGAN_new.G_arch", "functools.partial", "functools.partial", "functools.partial", "functools.partial", "BigGAN_new.Generator.which_embedding", "layers.identity", "len", "layers.bn", "BigGAN_new.Generator.which_conv", "BigGAN_new.Generator.init_weights", "print", "utils.Adam16", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "len", "print", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "layers.GBlock", "layers.Attention", "BigGAN_new.Generator.parameters", "BigGAN_new.Generator.parameters", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__", "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN.G_arch", "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN.Discriminator.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "G_ch", "=", "64", ",", "dim_z", "=", "128", ",", "bottom_width", "=", "4", ",", "resolution", "=", "128", ",", "\n", "G_kernel_size", "=", "3", ",", "G_attn", "=", "'64'", ",", "n_classes", "=", "1000", ",", "\n", "num_G_SVs", "=", "1", ",", "num_G_SV_itrs", "=", "1", ",", "\n", "G_shared", "=", "True", ",", "shared_dim", "=", "0", ",", "hier", "=", "False", ",", "\n", "cross_replica", "=", "False", ",", "mybn", "=", "False", ",", "\n", "G_activation", "=", "nn", ".", "ReLU", "(", "inplace", "=", "False", ")", ",", "\n", "G_lr", "=", "5e-5", ",", "G_B1", "=", "0.0", ",", "G_B2", "=", "0.999", ",", "adam_eps", "=", "1e-8", ",", "\n", "BN_eps", "=", "1e-5", ",", "SN_eps", "=", "1e-12", ",", "G_mixed_precision", "=", "False", ",", "G_fp16", "=", "False", ",", "\n", "G_init", "=", "'ortho'", ",", "skip_init", "=", "False", ",", "no_optim", "=", "False", ",", "\n", "G_param", "=", "'SN'", ",", "norm_style", "=", "'bn'", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Generator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Channel width mulitplier", "\n", "self", ".", "ch", "=", "G_ch", "\n", "# Dimensionality of the latent space", "\n", "self", ".", "dim_z", "=", "dim_z", "\n", "# The initial spatial dimensions", "\n", "self", ".", "bottom_width", "=", "bottom_width", "\n", "# Resolution of the output", "\n", "self", ".", "resolution", "=", "resolution", "\n", "# Kernel size?", "\n", "self", ".", "kernel_size", "=", "G_kernel_size", "\n", "# Attention?", "\n", "self", ".", "attention", "=", "G_attn", "\n", "# number of classes, for use in categorical conditional generation", "\n", "self", ".", "n_classes", "=", "n_classes", "\n", "# Use shared embeddings?", "\n", "self", ".", "G_shared", "=", "G_shared", "\n", "# Dimensionality of the shared embedding? Unused if not using G_shared", "\n", "self", ".", "shared_dim", "=", "shared_dim", "if", "shared_dim", ">", "0", "else", "dim_z", "\n", "# Hierarchical latent space?", "\n", "self", ".", "hier", "=", "hier", "\n", "# Cross replica batchnorm?", "\n", "self", ".", "cross_replica", "=", "cross_replica", "\n", "# Use my batchnorm?", "\n", "self", ".", "mybn", "=", "mybn", "\n", "# nonlinearity for residual blocks", "\n", "self", ".", "activation", "=", "G_activation", "\n", "# Initialization style", "\n", "self", ".", "init", "=", "G_init", "\n", "# Parameterization style", "\n", "self", ".", "G_param", "=", "G_param", "\n", "# Normalization style", "\n", "self", ".", "norm_style", "=", "norm_style", "\n", "# Epsilon for BatchNorm?", "\n", "self", ".", "BN_eps", "=", "BN_eps", "\n", "# Epsilon for Spectral Norm?", "\n", "self", ".", "SN_eps", "=", "SN_eps", "\n", "# fp16?", "\n", "self", ".", "fp16", "=", "G_fp16", "\n", "# Architecture dict", "\n", "self", ".", "arch", "=", "G_arch", "(", "self", ".", "ch", ",", "self", ".", "attention", ")", "[", "resolution", "]", "\n", "\n", "# If using hierarchical latents, adjust z", "\n", "if", "self", ".", "hier", ":", "\n", "# Number of places z slots into", "\n", "            ", "self", ".", "num_slots", "=", "len", "(", "self", ".", "arch", "[", "'in_channels'", "]", ")", "+", "1", "\n", "self", ".", "z_chunk_size", "=", "(", "self", ".", "dim_z", "//", "self", ".", "num_slots", ")", "\n", "# Recalculate latent dimensionality for even splitting into chunks", "\n", "self", ".", "dim_z", "=", "self", ".", "z_chunk_size", "*", "self", ".", "num_slots", "\n", "", "else", ":", "\n", "            ", "self", ".", "num_slots", "=", "1", "\n", "self", ".", "z_chunk_size", "=", "0", "\n", "\n", "# Which convs, batchnorms, and linear layers to use", "\n", "", "if", "self", ".", "G_param", "==", "'SN'", ":", "\n", "            ", "self", ".", "which_conv", "=", "functools", ".", "partial", "(", "layers", ".", "SNConv2d", ",", "\n", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "\n", "num_svs", "=", "num_G_SVs", ",", "num_itrs", "=", "num_G_SV_itrs", ",", "\n", "eps", "=", "self", ".", "SN_eps", ")", "\n", "self", ".", "which_linear", "=", "functools", ".", "partial", "(", "layers", ".", "SNLinear", ",", "\n", "num_svs", "=", "num_G_SVs", ",", "num_itrs", "=", "num_G_SV_itrs", ",", "\n", "eps", "=", "self", ".", "SN_eps", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "which_conv", "=", "functools", ".", "partial", "(", "\n", "nn", ".", "Conv2d", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "which_linear", "=", "nn", ".", "Linear", "\n", "\n", "# We use a non-spectral-normed embedding here regardless;", "\n", "# For some reason applying SN to G's embedding seems to randomly cripple G", "\n", "", "self", ".", "which_embedding", "=", "nn", ".", "Embedding", "\n", "bn_linear", "=", "(", "functools", ".", "partial", "(", "self", ".", "which_linear", ",", "bias", "=", "False", ")", "if", "self", ".", "G_shared", "\n", "else", "self", ".", "which_embedding", ")", "\n", "self", ".", "which_bn", "=", "functools", ".", "partial", "(", "layers", ".", "ccbn", ",", "\n", "which_linear", "=", "bn_linear", ",", "\n", "cross_replica", "=", "self", ".", "cross_replica", ",", "\n", "mybn", "=", "self", ".", "mybn", ",", "\n", "input_size", "=", "(", "self", ".", "shared_dim", "+", "self", ".", "z_chunk_size", "if", "self", ".", "G_shared", "\n", "else", "self", ".", "n_classes", ")", ",", "\n", "norm_style", "=", "self", ".", "norm_style", ",", "\n", "eps", "=", "self", ".", "BN_eps", ")", "\n", "\n", "# Prepare model", "\n", "# If not using shared embeddings, self.shared is just a passthrough", "\n", "self", ".", "shared", "=", "(", "self", ".", "which_embedding", "(", "n_classes", ",", "self", ".", "shared_dim", ")", "if", "G_shared", "\n", "else", "layers", ".", "identity", "(", ")", ")", "\n", "# First linear layer", "\n", "self", ".", "linear", "=", "self", ".", "which_linear", "(", "self", ".", "dim_z", "//", "self", ".", "num_slots", ",", "\n", "self", ".", "arch", "[", "'in_channels'", "]", "[", "0", "]", "*", "(", "self", ".", "bottom_width", "**", "2", ")", ")", "\n", "\n", "# self.blocks is a doubly-nested list of modules, the outer loop intended", "\n", "# to be over blocks at a given resolution (resblocks and/or self-attention)", "\n", "# while the inner loop is over a given block", "\n", "self", ".", "blocks", "=", "[", "]", "\n", "for", "index", "in", "range", "(", "len", "(", "self", ".", "arch", "[", "'out_channels'", "]", ")", ")", ":", "\n", "            ", "self", ".", "blocks", "+=", "[", "[", "layers", ".", "GBlock", "(", "in_channels", "=", "self", ".", "arch", "[", "'in_channels'", "]", "[", "index", "]", ",", "\n", "out_channels", "=", "self", ".", "arch", "[", "'out_channels'", "]", "[", "index", "]", ",", "\n", "which_conv", "=", "self", ".", "which_conv", ",", "\n", "which_bn", "=", "self", ".", "which_bn", ",", "\n", "activation", "=", "self", ".", "activation", ",", "\n", "upsample", "=", "(", "functools", ".", "partial", "(", "F", ".", "interpolate", ",", "scale_factor", "=", "2", ")", "\n", "if", "self", ".", "arch", "[", "'upsample'", "]", "[", "index", "]", "else", "None", ")", ")", "]", "]", "\n", "\n", "# If attention on this block, attach it to the end", "\n", "if", "self", ".", "arch", "[", "'attention'", "]", "[", "self", ".", "arch", "[", "'resolution'", "]", "[", "index", "]", "]", ":", "\n", "                ", "print", "(", "'Adding attention layer in G at resolution %d'", "%", "\n", "self", ".", "arch", "[", "'resolution'", "]", "[", "index", "]", ")", "\n", "self", ".", "blocks", "[", "-", "1", "]", "+=", "[", "layers", ".", "Attention", "(", "\n", "self", ".", "arch", "[", "'out_channels'", "]", "[", "index", "]", ",", "self", ".", "which_conv", ")", "]", "\n", "\n", "# Turn self.blocks into a ModuleList so that it's all properly registered.", "\n", "", "", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "ModuleList", "(", "block", ")", "\n", "for", "block", "in", "self", ".", "blocks", "]", ")", "\n", "\n", "# output layer: batchnorm-relu-conv.", "\n", "# Consider using a non-spectral conv here", "\n", "self", ".", "output_layer", "=", "nn", ".", "Sequential", "(", "layers", ".", "bn", "(", "self", ".", "arch", "[", "'out_channels'", "]", "[", "-", "1", "]", ",", "\n", "cross_replica", "=", "self", ".", "cross_replica", ",", "\n", "mybn", "=", "self", ".", "mybn", ")", ",", "\n", "self", ".", "activation", ",", "\n", "self", ".", "which_conv", "(", "self", ".", "arch", "[", "'out_channels'", "]", "[", "-", "1", "]", ",", "3", ")", ")", "\n", "\n", "# Initialize weights. Optionally skip init for testing.", "\n", "if", "not", "skip_init", ":", "\n", "            ", "self", ".", "init_weights", "(", ")", "\n", "\n", "# Set up optimizer", "\n", "# If this is an EMA copy, no need for an optim, so just return now", "\n", "", "if", "no_optim", ":", "\n", "            ", "return", "\n", "", "self", ".", "lr", ",", "self", ".", "B1", ",", "self", ".", "B2", ",", "self", ".", "adam_eps", "=", "G_lr", ",", "G_B1", ",", "G_B2", ",", "adam_eps", "\n", "if", "G_mixed_precision", ":", "\n", "            ", "print", "(", "'Using fp16 adam in G...'", ")", "\n", "import", "utils", "\n", "self", ".", "optim", "=", "utils", ".", "Adam16", "(", "params", "=", "self", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ",", "\n", "betas", "=", "(", "self", ".", "B1", ",", "self", ".", "B2", ")", ",", "weight_decay", "=", "0", ",", "\n", "eps", "=", "self", ".", "adam_eps", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "optim", "=", "optim", ".", "Adam", "(", "params", "=", "self", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ",", "\n", "betas", "=", "(", "self", ".", "B1", ",", "self", ".", "B2", ")", ",", "weight_decay", "=", "0", ",", "\n", "eps", "=", "self", ".", "adam_eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN_new.Generator.init_weights": [[213, 231], ["BigGAN_new.Generator.modules", "print", "isinstance", "isinstance", "isinstance", "sum", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "p.data.nelement", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "print", "module.parameters"], "methods", ["None"], ["", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "self", ".", "param_count", "=", "0", "\n", "for", "module", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "(", "isinstance", "(", "module", ",", "nn", ".", "Conv2d", ")", "\n", "or", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "\n", "or", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "                ", "if", "self", ".", "init", "==", "'ortho'", ":", "\n", "                    ", "init", ".", "orthogonal_", "(", "module", ".", "weight", ")", "\n", "", "elif", "self", ".", "init", "==", "'N02'", ":", "\n", "                    ", "init", ".", "normal_", "(", "module", ".", "weight", ",", "0", ",", "0.02", ")", "\n", "", "elif", "self", ".", "init", "in", "[", "'glorot'", ",", "'xavier'", "]", ":", "\n", "                    ", "init", ".", "xavier_uniform_", "(", "module", ".", "weight", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "'Init style not recognized...'", ")", "\n", "", "self", ".", "param_count", "+=", "sum", "(", "[", "p", ".", "data", ".", "nelement", "(", ")", "\n", "for", "p", "in", "module", ".", "parameters", "(", ")", "]", ")", "\n", "", "", "print", "(", "'Param count for G'", "'s initialized parameters: %d'", "%", "\n", "self", ".", "param_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN_new.Generator.forward": [[236, 258], ["BigGAN_new.Generator.linear", "block.view", "enumerate", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "block.size", "BigGAN_new.Generator.output_layer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "block"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "z", ",", "y", ")", ":", "\n", "# If hierarchical, concatenate zs and ys", "\n", "        ", "if", "self", ".", "hier", ":", "\n", "            ", "zs", "=", "torch", ".", "split", "(", "z", ",", "self", ".", "z_chunk_size", ",", "1", ")", "\n", "z", "=", "zs", "[", "0", "]", "\n", "ys", "=", "[", "torch", ".", "cat", "(", "[", "y", ",", "item", "]", ",", "1", ")", "for", "item", "in", "zs", "[", "1", ":", "]", "]", "\n", "", "else", ":", "\n", "            ", "ys", "=", "[", "y", "]", "*", "len", "(", "self", ".", "blocks", ")", "\n", "\n", "# First linear layer", "\n", "", "h", "=", "self", ".", "linear", "(", "z", ")", "\n", "# Reshape", "\n", "h", "=", "h", ".", "view", "(", "h", ".", "size", "(", "0", ")", ",", "-", "1", ",", "self", ".", "bottom_width", ",", "self", ".", "bottom_width", ")", "\n", "\n", "# Loop over blocks", "\n", "for", "index", ",", "blocklist", "in", "enumerate", "(", "self", ".", "blocks", ")", ":", "\n", "# Second inner loop in case block has multiple layers", "\n", "            ", "for", "block", "in", "blocklist", ":", "\n", "                ", "h", "=", "block", "(", "h", ",", "ys", "[", "index", "]", ")", "\n", "\n", "# Apply batchnorm-relu-conv-tanh at output", "\n", "", "", "return", "torch", ".", "tanh", "(", "self", ".", "output_layer", "(", "h", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN_new.Discriminator.__init__": [[292, 380], ["torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Module.__init__", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "BigGAN_new.Discriminator.which_linear", "BigGAN_new.Discriminator.which_embedding", "BigGAN_new.D_arch", "functools.partial", "functools.partial", "functools.partial", "len", "BigGAN_new.Discriminator.init_weights", "print", "utils.Adam16", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "print", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "layers.DBlock", "layers.Attention", "BigGAN_new.Discriminator.parameters", "BigGAN_new.Discriminator.parameters", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__", "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN.D_arch", "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN.Discriminator.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "D_ch", "=", "64", ",", "D_wide", "=", "True", ",", "resolution", "=", "128", ",", "\n", "D_kernel_size", "=", "3", ",", "D_attn", "=", "'64'", ",", "n_classes", "=", "1000", ",", "\n", "num_D_SVs", "=", "1", ",", "num_D_SV_itrs", "=", "1", ",", "D_activation", "=", "nn", ".", "ReLU", "(", "inplace", "=", "False", ")", ",", "\n", "D_lr", "=", "2e-4", ",", "D_B1", "=", "0.0", ",", "D_B2", "=", "0.999", ",", "adam_eps", "=", "1e-8", ",", "\n", "SN_eps", "=", "1e-12", ",", "output_dim", "=", "1", ",", "D_mixed_precision", "=", "False", ",", "D_fp16", "=", "False", ",", "\n", "D_init", "=", "'ortho'", ",", "skip_init", "=", "False", ",", "D_param", "=", "'SN'", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Width multiplier", "\n", "self", ".", "ch", "=", "D_ch", "\n", "# Use Wide D as in BigGAN and SA-GAN or skinny D as in SN-GAN?", "\n", "self", ".", "D_wide", "=", "D_wide", "\n", "# Resolution", "\n", "self", ".", "resolution", "=", "resolution", "\n", "# Kernel size", "\n", "self", ".", "kernel_size", "=", "D_kernel_size", "\n", "# Attention?", "\n", "self", ".", "attention", "=", "D_attn", "\n", "# Number of classes", "\n", "self", ".", "n_classes", "=", "n_classes", "\n", "# Activation", "\n", "self", ".", "activation", "=", "D_activation", "\n", "# Initialization style", "\n", "self", ".", "init", "=", "D_init", "\n", "# Parameterization style", "\n", "self", ".", "D_param", "=", "D_param", "\n", "# Epsilon for Spectral Norm?", "\n", "self", ".", "SN_eps", "=", "SN_eps", "\n", "# Fp16?", "\n", "self", ".", "fp16", "=", "D_fp16", "\n", "# Architecture", "\n", "self", ".", "arch", "=", "D_arch", "(", "self", ".", "ch", ",", "self", ".", "attention", ")", "[", "resolution", "]", "\n", "\n", "# Which convs, batchnorms, and linear layers to use", "\n", "# No option to turn off SN in D right now", "\n", "if", "self", ".", "D_param", "==", "'SN'", ":", "\n", "            ", "self", ".", "which_conv", "=", "functools", ".", "partial", "(", "layers", ".", "SNConv2d", ",", "\n", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "\n", "num_svs", "=", "num_D_SVs", ",", "num_itrs", "=", "num_D_SV_itrs", ",", "\n", "eps", "=", "self", ".", "SN_eps", ")", "\n", "self", ".", "which_linear", "=", "functools", ".", "partial", "(", "layers", ".", "SNLinear", ",", "\n", "num_svs", "=", "num_D_SVs", ",", "num_itrs", "=", "num_D_SV_itrs", ",", "\n", "eps", "=", "self", ".", "SN_eps", ")", "\n", "self", ".", "which_embedding", "=", "functools", ".", "partial", "(", "layers", ".", "SNEmbedding", ",", "\n", "num_svs", "=", "num_D_SVs", ",", "num_itrs", "=", "num_D_SV_itrs", ",", "\n", "eps", "=", "self", ".", "SN_eps", ")", "\n", "# Prepare model", "\n", "# self.blocks is a doubly-nested list of modules, the outer loop intended", "\n", "# to be over blocks at a given resolution (resblocks and/or self-attention)", "\n", "", "self", ".", "blocks", "=", "[", "]", "\n", "for", "index", "in", "range", "(", "len", "(", "self", ".", "arch", "[", "'out_channels'", "]", ")", ")", ":", "\n", "            ", "self", ".", "blocks", "+=", "[", "[", "layers", ".", "DBlock", "(", "in_channels", "=", "self", ".", "arch", "[", "'in_channels'", "]", "[", "index", "]", ",", "\n", "out_channels", "=", "self", ".", "arch", "[", "'out_channels'", "]", "[", "index", "]", ",", "\n", "which_conv", "=", "self", ".", "which_conv", ",", "\n", "wide", "=", "self", ".", "D_wide", ",", "\n", "activation", "=", "self", ".", "activation", ",", "\n", "preactivation", "=", "(", "index", ">", "0", ")", ",", "\n", "downsample", "=", "(", "nn", ".", "AvgPool2d", "(", "2", ")", "if", "self", ".", "arch", "[", "'downsample'", "]", "[", "index", "]", "else", "None", ")", ")", "]", "]", "\n", "# If attention on this block, attach it to the end", "\n", "if", "self", ".", "arch", "[", "'attention'", "]", "[", "self", ".", "arch", "[", "'resolution'", "]", "[", "index", "]", "]", ":", "\n", "                ", "print", "(", "'Adding attention layer in D at resolution %d'", "%", "\n", "self", ".", "arch", "[", "'resolution'", "]", "[", "index", "]", ")", "\n", "self", ".", "blocks", "[", "-", "1", "]", "+=", "[", "layers", ".", "Attention", "(", "self", ".", "arch", "[", "'out_channels'", "]", "[", "index", "]", ",", "\n", "self", ".", "which_conv", ")", "]", "\n", "# Turn self.blocks into a ModuleList so that it's all properly registered.", "\n", "", "", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "ModuleList", "(", "block", ")", "\n", "for", "block", "in", "self", ".", "blocks", "]", ")", "\n", "# Linear output layer. The output dimension is typically 1, but may be", "\n", "# larger if we're e.g. turning this into a VAE with an inference output", "\n", "self", ".", "linear", "=", "self", ".", "which_linear", "(", "\n", "self", ".", "arch", "[", "'out_channels'", "]", "[", "-", "1", "]", ",", "output_dim", ")", "\n", "# Embedding for projection discrimination", "\n", "self", ".", "embed", "=", "self", ".", "which_embedding", "(", "\n", "self", ".", "n_classes", ",", "self", ".", "arch", "[", "'out_channels'", "]", "[", "-", "1", "]", ")", "\n", "\n", "# Initialize weights", "\n", "if", "not", "skip_init", ":", "\n", "            ", "self", ".", "init_weights", "(", ")", "\n", "\n", "# Set up optimizer", "\n", "", "self", ".", "lr", ",", "self", ".", "B1", ",", "self", ".", "B2", ",", "self", ".", "adam_eps", "=", "D_lr", ",", "D_B1", ",", "D_B2", ",", "adam_eps", "\n", "if", "D_mixed_precision", ":", "\n", "            ", "print", "(", "'Using fp16 adam in D...'", ")", "\n", "import", "utils", "\n", "self", ".", "optim", "=", "utils", ".", "Adam16", "(", "params", "=", "self", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ",", "\n", "betas", "=", "(", "self", ".", "B1", ",", "self", ".", "B2", ")", ",", "weight_decay", "=", "0", ",", "eps", "=", "self", ".", "adam_eps", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "optim", "=", "optim", ".", "Adam", "(", "params", "=", "self", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ",", "\n", "betas", "=", "(", "self", ".", "B1", ",", "self", ".", "B2", ")", ",", "weight_decay", "=", "0", ",", "eps", "=", "self", ".", "adam_eps", ")", "\n", "# LR scheduling, left here for forward compatibility", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN_new.Discriminator.init_weights": [[385, 403], ["BigGAN_new.Discriminator.modules", "print", "isinstance", "isinstance", "isinstance", "sum", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "p.data.nelement", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "print", "module.parameters"], "methods", ["None"], ["", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "self", ".", "param_count", "=", "0", "\n", "for", "module", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "(", "isinstance", "(", "module", ",", "nn", ".", "Conv2d", ")", "\n", "or", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "\n", "or", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "                ", "if", "self", ".", "init", "==", "'ortho'", ":", "\n", "                    ", "init", ".", "orthogonal_", "(", "module", ".", "weight", ")", "\n", "", "elif", "self", ".", "init", "==", "'N02'", ":", "\n", "                    ", "init", ".", "normal_", "(", "module", ".", "weight", ",", "0", ",", "0.02", ")", "\n", "", "elif", "self", ".", "init", "in", "[", "'glorot'", ",", "'xavier'", "]", ":", "\n", "                    ", "init", ".", "xavier_uniform_", "(", "module", ".", "weight", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "'Init style not recognized...'", ")", "\n", "", "self", ".", "param_count", "+=", "sum", "(", "[", "p", ".", "data", ".", "nelement", "(", ")", "\n", "for", "p", "in", "module", ".", "parameters", "(", ")", "]", ")", "\n", "", "", "print", "(", "'Param count for D'", "'s initialized parameters: %d'", "%", "\n", "self", ".", "param_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN_new.Discriminator.forward": [[404, 418], ["enumerate", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "BigGAN_new.Discriminator.linear", "BigGAN_new.Discriminator.activation", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "block", "BigGAN_new.Discriminator.embed"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", "=", "None", ")", ":", "\n", "# Stick x into h for cleaner for loops without flow control", "\n", "        ", "h", "=", "x", "\n", "# Loop over blocks", "\n", "for", "index", ",", "blocklist", "in", "enumerate", "(", "self", ".", "blocks", ")", ":", "\n", "            ", "for", "block", "in", "blocklist", ":", "\n", "                ", "h", "=", "block", "(", "h", ")", "\n", "# Apply global sum pooling as in SN-GAN", "\n", "", "", "h", "=", "torch", ".", "sum", "(", "self", ".", "activation", "(", "h", ")", ",", "[", "2", ",", "3", "]", ")", "\n", "# Get initial class-unconditional output", "\n", "out", "=", "self", ".", "linear", "(", "h", ")", "\n", "# Get projection of final featureset onto class vectors and add to evidence", "\n", "out", "=", "out", "+", "torch", ".", "sum", "(", "self", ".", "embed", "(", "y", ")", "*", "h", ",", "1", ",", "keepdim", "=", "True", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN_new.G_D.__init__": [[424, 429], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__"], ["    ", "def", "__init__", "(", "self", ",", "G", ",", "D", ",", "conditional", ")", ":", "\n", "        ", "super", "(", "G_D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "G", "=", "G", "\n", "self", ".", "D", "=", "D", "\n", "self", ".", "conditional", "=", "conditional", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN_new.G_D.forward": [[430, 476], ["torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "BigGAN_new.G_D.G", "BigGAN_new.G_D.D", "BigGAN_new.G_D.D", "gy.sum", "BigGAN_new.G_D.G.shared", "G_z.half.half.float", "G_z.half.half.half", "BigGAN_new.G_D.D", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "BigGAN_new.G_D.D", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "dy.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "z", ",", "gy", ",", "x", "=", "None", ",", "real_fake_x", "=", "None", ",", "dy", "=", "None", ",", "train_G", "=", "False", ",", "return_G_z", "=", "False", ",", "\n", "split_D", "=", "False", ")", ":", "\n", "# if not using label information, make sure all y's are zero'ed out", "\n", "        ", "if", "not", "self", ".", "conditional", ":", "\n", "          ", "assert", "gy", ".", "sum", "(", ")", "==", "0", "\n", "if", "dy", "is", "not", "None", ":", "\n", "            ", "assert", "dy", ".", "sum", "(", ")", "==", "0", "\n", "# If training G, enable grad tape", "\n", "", "", "with", "torch", ".", "set_grad_enabled", "(", "train_G", ")", ":", "\n", "# Get Generator output given noise", "\n", "            ", "G_z", "=", "self", ".", "G", "(", "z", ",", "self", ".", "G", ".", "shared", "(", "gy", ")", ")", "\n", "# Cast as necessary", "\n", "if", "self", ".", "G", ".", "fp16", "and", "not", "self", ".", "D", ".", "fp16", ":", "\n", "                ", "G_z", "=", "G_z", ".", "float", "(", ")", "\n", "", "if", "self", ".", "D", ".", "fp16", "and", "not", "self", ".", "G", ".", "fp16", ":", "\n", "                ", "G_z", "=", "G_z", ".", "half", "(", ")", "\n", "# Split_D means to run D once with real data and once with fake,", "\n", "# rather than concatenating along the batch dimension.", "\n", "\n", "", "", "if", "split_D", ":", "\n", "            ", "D_fake", "=", "self", ".", "D", "(", "G_z", ",", "gy", ")", "\n", "if", "x", "is", "not", "None", ":", "\n", "                ", "D_real", "=", "self", ".", "D", "(", "x", ",", "dy", ")", "\n", "return", "D_fake", ",", "D_real", "\n", "", "else", ":", "\n", "                ", "if", "return_G_z", ":", "\n", "                    ", "return", "D_fake", ",", "G_z", "\n", "", "else", ":", "\n", "                    ", "return", "D_fake", "\n", "# If real data is provided, concatenate it with the Generator's output", "\n", "# along the batch dimension for improved efficiency.", "\n", "", "", "", "else", ":", "\n", "            ", "D_input", "=", "torch", ".", "cat", "(", "[", "G_z", ",", "x", "]", ",", "0", ")", "if", "x", "is", "not", "None", "else", "G_z", "\n", "D_class", "=", "torch", ".", "cat", "(", "[", "gy", ",", "dy", "]", ",", "0", ")", "if", "dy", "is", "not", "None", "else", "gy", "\n", "# Get Discriminator output", "\n", "D_out", "=", "self", ".", "D", "(", "D_input", ",", "D_class", ")", "\n", "if", "x", "is", "not", "None", ":", "\n", "# D_fake, D_real", "\n", "                ", "D_real_fake", "=", "self", ".", "D", "(", "real_fake_x", ",", "dy", ")", "\n", "D_fake", ",", "D_real", "=", "torch", ".", "split", "(", "D_out", ",", "[", "G_z", ".", "shape", "[", "0", "]", ",", "x", ".", "shape", "[", "0", "]", "]", ")", "\n", "return", "D_fake", ",", "D_real", ",", "D_real_fake", "\n", "", "else", ":", "\n", "                ", "if", "return_G_z", ":", "\n", "                    ", "return", "D_out", ",", "G_z", "\n", "", "else", ":", "\n", "                    ", "return", "D_out", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN_new.G_arch": [[19, 53], ["range", "range", "range", "range", "range", "int", "int", "int", "int", "int", "attention.split", "attention.split", "attention.split", "attention.split", "attention.split"], "function", ["None"], ["def", "G_arch", "(", "ch", "=", "64", ",", "attention", "=", "'64'", ",", "ksize", "=", "'333333'", ",", "dilation", "=", "'111111'", ")", ":", "\n", "    ", "arch", "=", "{", "}", "\n", "arch", "[", "512", "]", "=", "{", "'in_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "16", ",", "16", ",", "8", ",", "8", ",", "4", ",", "2", ",", "1", "]", "]", ",", "\n", "'out_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "16", ",", "8", ",", "8", ",", "4", ",", "2", ",", "1", ",", "1", "]", "]", ",", "\n", "'upsample'", ":", "[", "True", "]", "*", "7", ",", "\n", "'resolution'", ":", "[", "8", ",", "16", ",", "32", ",", "64", ",", "128", ",", "256", ",", "512", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "(", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "3", ",", "10", ")", "}", "}", "\n", "arch", "[", "256", "]", "=", "{", "'in_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "16", ",", "16", ",", "8", ",", "8", ",", "4", ",", "2", "]", "]", ",", "\n", "'out_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "16", ",", "8", ",", "8", ",", "4", ",", "2", ",", "1", "]", "]", ",", "\n", "'upsample'", ":", "[", "True", "]", "*", "6", ",", "\n", "'resolution'", ":", "[", "8", ",", "16", ",", "32", ",", "64", ",", "128", ",", "256", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "(", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "3", ",", "9", ")", "}", "}", "\n", "arch", "[", "128", "]", "=", "{", "'in_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "16", ",", "16", ",", "8", ",", "4", ",", "2", "]", "]", ",", "\n", "'out_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "16", ",", "8", ",", "4", ",", "2", ",", "1", "]", "]", ",", "\n", "'upsample'", ":", "[", "True", "]", "*", "5", ",", "\n", "'resolution'", ":", "[", "8", ",", "16", ",", "32", ",", "64", ",", "128", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "(", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "3", ",", "8", ")", "}", "}", "\n", "arch", "[", "64", "]", "=", "{", "'in_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "16", ",", "16", ",", "8", ",", "4", "]", "]", ",", "\n", "'out_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "16", ",", "8", ",", "4", ",", "2", "]", "]", ",", "\n", "'upsample'", ":", "[", "True", "]", "*", "4", ",", "\n", "'resolution'", ":", "[", "8", ",", "16", ",", "32", ",", "64", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "(", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "3", ",", "7", ")", "}", "}", "\n", "arch", "[", "32", "]", "=", "{", "'in_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "4", ",", "4", ",", "4", "]", "]", ",", "\n", "'out_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "4", ",", "4", ",", "4", "]", "]", ",", "\n", "'upsample'", ":", "[", "True", "]", "*", "3", ",", "\n", "'resolution'", ":", "[", "8", ",", "16", ",", "32", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "(", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "3", ",", "6", ")", "}", "}", "\n", "\n", "return", "arch", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN_new.D_arch": [[261, 288], ["range", "range", "range", "range", "int", "int", "int", "int", "attention.split", "attention.split", "attention.split", "attention.split"], "function", ["None"], ["", "", "def", "D_arch", "(", "ch", "=", "64", ",", "attention", "=", "'64'", ",", "ksize", "=", "'333333'", ",", "dilation", "=", "'111111'", ")", ":", "\n", "    ", "arch", "=", "{", "}", "\n", "arch", "[", "256", "]", "=", "{", "'in_channels'", ":", "[", "3", "]", "+", "[", "ch", "*", "item", "for", "item", "in", "[", "1", ",", "2", ",", "4", ",", "8", ",", "8", ",", "16", "]", "]", ",", "\n", "'out_channels'", ":", "[", "item", "*", "ch", "for", "item", "in", "[", "1", ",", "2", ",", "4", ",", "8", ",", "8", ",", "16", ",", "16", "]", "]", ",", "\n", "'downsample'", ":", "[", "True", "]", "*", "6", "+", "[", "False", "]", ",", "\n", "'resolution'", ":", "[", "128", ",", "64", ",", "32", ",", "16", ",", "8", ",", "4", ",", "4", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", "\n", "for", "i", "in", "range", "(", "2", ",", "8", ")", "}", "}", "\n", "arch", "[", "128", "]", "=", "{", "'in_channels'", ":", "[", "3", "]", "+", "[", "ch", "*", "item", "for", "item", "in", "[", "1", ",", "2", ",", "4", ",", "8", ",", "16", "]", "]", ",", "\n", "'out_channels'", ":", "[", "item", "*", "ch", "for", "item", "in", "[", "1", ",", "2", ",", "4", ",", "8", ",", "16", ",", "16", "]", "]", ",", "\n", "'downsample'", ":", "[", "True", "]", "*", "5", "+", "[", "False", "]", ",", "\n", "'resolution'", ":", "[", "64", ",", "32", ",", "16", ",", "8", ",", "4", ",", "4", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", "\n", "for", "i", "in", "range", "(", "2", ",", "8", ")", "}", "}", "\n", "arch", "[", "64", "]", "=", "{", "'in_channels'", ":", "[", "3", "]", "+", "[", "ch", "*", "item", "for", "item", "in", "[", "1", ",", "2", ",", "4", ",", "8", "]", "]", ",", "\n", "'out_channels'", ":", "[", "item", "*", "ch", "for", "item", "in", "[", "1", ",", "2", ",", "4", ",", "8", ",", "16", "]", "]", ",", "\n", "'downsample'", ":", "[", "True", "]", "*", "4", "+", "[", "False", "]", ",", "\n", "'resolution'", ":", "[", "32", ",", "16", ",", "8", ",", "4", ",", "4", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", "\n", "for", "i", "in", "range", "(", "2", ",", "7", ")", "}", "}", "\n", "arch", "[", "32", "]", "=", "{", "'in_channels'", ":", "[", "3", "]", "+", "[", "item", "*", "ch", "for", "item", "in", "[", "4", ",", "4", ",", "4", "]", "]", ",", "\n", "'out_channels'", ":", "[", "item", "*", "ch", "for", "item", "in", "[", "4", ",", "4", ",", "4", ",", "4", "]", "]", ",", "\n", "'downsample'", ":", "[", "True", ",", "True", ",", "False", ",", "False", "]", ",", "\n", "'resolution'", ":", "[", "16", ",", "16", ",", "16", ",", "16", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", "\n", "for", "i", "in", "range", "(", "2", ",", "6", ")", "}", "}", "\n", "return", "arch", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.dataset_utils.gen_bar_updater": [[8, 18], ["torch.utils.model_zoo.tqdm", "torch.utils.model_zoo.tqdm.update"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.ema.update"], ["def", "gen_bar_updater", "(", ")", ":", "\n", "    ", "pbar", "=", "tqdm", "(", "total", "=", "None", ")", "\n", "\n", "def", "bar_update", "(", "count", ",", "block_size", ",", "total_size", ")", ":", "\n", "        ", "if", "pbar", ".", "total", "is", "None", "and", "total_size", ":", "\n", "            ", "pbar", ".", "total", "=", "total_size", "\n", "", "progress_bytes", "=", "count", "*", "block_size", "\n", "pbar", ".", "update", "(", "progress_bytes", "-", "pbar", ".", "n", ")", "\n", "\n", "", "return", "bar_update", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.dataset_utils.check_integrity": [[20, 34], ["hashlib.md5", "hashlib.md5.hexdigest", "os.path.isfile", "os.path.isfile", "open", "iter", "hashlib.md5.update", "f.read"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.ema.update"], ["", "def", "check_integrity", "(", "fpath", ",", "md5", "=", "None", ")", ":", "\n", "    ", "if", "md5", "is", "None", ":", "\n", "        ", "return", "True", "\n", "", "if", "not", "os", ".", "path", ".", "isfile", "(", "fpath", ")", ":", "\n", "        ", "return", "False", "\n", "", "md5o", "=", "hashlib", ".", "md5", "(", ")", "\n", "with", "open", "(", "fpath", ",", "'rb'", ")", "as", "f", ":", "\n", "# read in 1MB chunks", "\n", "        ", "for", "chunk", "in", "iter", "(", "lambda", ":", "f", ".", "read", "(", "1024", "*", "1024", ")", ",", "b''", ")", ":", "\n", "            ", "md5o", ".", "update", "(", "chunk", ")", "\n", "", "", "md5c", "=", "md5o", ".", "hexdigest", "(", ")", "\n", "if", "md5c", "!=", "md5", ":", "\n", "        ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.dataset_utils.makedir_exist_ok": [[36, 47], ["os.makedirs", "os.makedirs"], "function", ["None"], ["", "def", "makedir_exist_ok", "(", "dirpath", ")", ":", "\n", "    ", "\"\"\"\n    Python2 support for os.makedirs(.., exist_ok=True)\n    \"\"\"", "\n", "try", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirpath", ")", "\n", "", "except", "OSError", "as", "e", ":", "\n", "        ", "if", "e", ".", "errno", "==", "errno", ".", "EEXIST", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.dataset_utils.download_url": [[49, 84], ["os.path.expanduser", "os.path.expanduser", "os.path.join", "os.path.join", "dataset_utils.makedir_exist_ok", "os.path.basename", "os.path.basename", "os.path.isfile", "os.path.isfile", "dataset_utils.check_integrity", "print", "print", "urllib.request.urlretrieve", "dataset_utils.gen_bar_updater", "url.replace.replace", "print", "urllib.request.urlretrieve", "dataset_utils.gen_bar_updater"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.dataset_utils.makedir_exist_ok", "home.repos.pwc.inspect_result.ermongroup_NDA.None.dataset_utils.check_integrity", "home.repos.pwc.inspect_result.ermongroup_NDA.None.dataset_utils.gen_bar_updater", "home.repos.pwc.inspect_result.ermongroup_NDA.None.dataset_utils.gen_bar_updater"], ["", "", "", "def", "download_url", "(", "url", ",", "root", ",", "filename", "=", "None", ",", "md5", "=", "None", ")", ":", "\n", "    ", "\"\"\"Download a file from a url and place it in root.\n    Args:\n        url (str): URL to download file from\n        root (str): Directory to place downloaded file in\n        filename (str, optional): Name to save the file under. If None, use the basename of the URL\n        md5 (str, optional): MD5 checksum of the download. If None, do not check\n    \"\"\"", "\n", "from", "six", ".", "moves", "import", "urllib", "\n", "\n", "root", "=", "os", ".", "path", ".", "expanduser", "(", "root", ")", "\n", "if", "not", "filename", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "basename", "(", "url", ")", "\n", "", "fpath", "=", "os", ".", "path", ".", "join", "(", "root", ",", "filename", ")", "\n", "\n", "makedir_exist_ok", "(", "root", ")", "\n", "\n", "# downloads file", "\n", "if", "os", ".", "path", ".", "isfile", "(", "fpath", ")", "and", "check_integrity", "(", "fpath", ",", "md5", ")", ":", "\n", "        ", "print", "(", "'Using downloaded and verified file: '", "+", "fpath", ")", "\n", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "print", "(", "'Downloading '", "+", "url", "+", "' to '", "+", "fpath", ")", "\n", "urllib", ".", "request", ".", "urlretrieve", "(", "\n", "url", ",", "fpath", ",", "\n", "reporthook", "=", "gen_bar_updater", "(", ")", "\n", ")", "\n", "", "except", "OSError", ":", "\n", "            ", "if", "url", "[", ":", "5", "]", "==", "'https'", ":", "\n", "                ", "url", "=", "url", ".", "replace", "(", "'https:'", ",", "'http:'", ")", "\n", "print", "(", "'Failed download. Trying https -> http instead.'", "\n", "' Downloading '", "+", "url", "+", "' to '", "+", "fpath", ")", "\n", "urllib", ".", "request", ".", "urlretrieve", "(", "\n", "url", ",", "fpath", ",", "\n", "reporthook", "=", "gen_bar_updater", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.dataset_utils.list_dir": [[87, 106], ["os.path.expanduser", "os.path.expanduser", "list", "filter", "os.listdir", "os.listdir", "os.path.join", "os.path.join", "os.path.isdir", "os.path.isdir", "os.path.join", "os.path.join"], "function", ["None"], ["", "", "", "", "def", "list_dir", "(", "root", ",", "prefix", "=", "False", ")", ":", "\n", "    ", "\"\"\"List all directories at a given root\n    Args:\n        root (str): Path to directory whose folders need to be listed\n        prefix (bool, optional): If true, prepends the path to each result, otherwise\n            only returns the name of the directories found\n    \"\"\"", "\n", "root", "=", "os", ".", "path", ".", "expanduser", "(", "root", ")", "\n", "directories", "=", "list", "(", "\n", "filter", "(", "\n", "lambda", "p", ":", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "root", ",", "p", ")", ")", ",", "\n", "os", ".", "listdir", "(", "root", ")", "\n", ")", "\n", ")", "\n", "\n", "if", "prefix", "is", "True", ":", "\n", "        ", "directories", "=", "[", "os", ".", "path", ".", "join", "(", "root", ",", "d", ")", "for", "d", "in", "directories", "]", "\n", "\n", "", "return", "directories", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.dataset_utils.list_files": [[108, 129], ["os.path.expanduser", "os.path.expanduser", "list", "filter", "os.listdir", "os.listdir", "os.path.join", "os.path.join", "os.path.isfile", "os.path.isfile", "p.endswith", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "list_files", "(", "root", ",", "suffix", ",", "prefix", "=", "False", ")", ":", "\n", "    ", "\"\"\"List all files ending with a suffix at a given root\n    Args:\n        root (str): Path to directory whose folders need to be listed\n        suffix (str or tuple): Suffix of the files to match, e.g. '.png' or ('.jpg', '.png').\n            It uses the Python \"str.endswith\" method and is passed directly\n        prefix (bool, optional): If true, prepends the path to each result, otherwise\n            only returns the name of the files found\n    \"\"\"", "\n", "root", "=", "os", ".", "path", ".", "expanduser", "(", "root", ")", "\n", "files", "=", "list", "(", "\n", "filter", "(", "\n", "lambda", "p", ":", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "root", ",", "p", ")", ")", "and", "p", ".", "endswith", "(", "suffix", ")", ",", "\n", "os", ".", "listdir", "(", "root", ")", "\n", ")", "\n", ")", "\n", "\n", "if", "prefix", "is", "True", ":", "\n", "        ", "files", "=", "[", "os", ".", "path", ".", "join", "(", "root", ",", "d", ")", "for", "d", "in", "files", "]", "\n", "\n", "", "return", "files", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.dataset_utils.download_file_from_google_drive": [[131, 163], ["os.path.expanduser", "os.path.expanduser", "os.path.join", "os.path.join", "dataset_utils.makedir_exist_ok", "os.path.isfile", "os.path.isfile", "dataset_utils.check_integrity", "print", "requests.Session", "requests.Session.get", "dataset_utils._get_confirm_token", "dataset_utils._save_response_content", "requests.Session.get"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.dataset_utils.makedir_exist_ok", "home.repos.pwc.inspect_result.ermongroup_NDA.None.dataset_utils.check_integrity", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.comm.FutureResult.get", "home.repos.pwc.inspect_result.ermongroup_NDA.None.dataset_utils._get_confirm_token", "home.repos.pwc.inspect_result.ermongroup_NDA.None.dataset_utils._save_response_content", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.comm.FutureResult.get"], ["", "def", "download_file_from_google_drive", "(", "file_id", ",", "root", ",", "filename", "=", "None", ",", "md5", "=", "None", ")", ":", "\n", "    ", "\"\"\"Download a Google Drive file from  and place it in root.\n    Args:\n        file_id (str): id of file to be downloaded\n        root (str): Directory to place downloaded file in\n        filename (str, optional): Name to save the file under. If None, use the id of the file.\n        md5 (str, optional): MD5 checksum of the download. If None, do not check\n    \"\"\"", "\n", "# Based on https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url", "\n", "import", "requests", "\n", "url", "=", "\"https://docs.google.com/uc?export=download\"", "\n", "\n", "root", "=", "os", ".", "path", ".", "expanduser", "(", "root", ")", "\n", "if", "not", "filename", ":", "\n", "        ", "filename", "=", "file_id", "\n", "", "fpath", "=", "os", ".", "path", ".", "join", "(", "root", ",", "filename", ")", "\n", "\n", "makedir_exist_ok", "(", "root", ")", "\n", "\n", "if", "os", ".", "path", ".", "isfile", "(", "fpath", ")", "and", "check_integrity", "(", "fpath", ",", "md5", ")", ":", "\n", "        ", "print", "(", "'Using downloaded and verified file: '", "+", "fpath", ")", "\n", "", "else", ":", "\n", "        ", "session", "=", "requests", ".", "Session", "(", ")", "\n", "\n", "response", "=", "session", ".", "get", "(", "url", ",", "params", "=", "{", "'id'", ":", "file_id", "}", ",", "stream", "=", "True", ")", "\n", "token", "=", "_get_confirm_token", "(", "response", ")", "\n", "\n", "if", "token", ":", "\n", "            ", "params", "=", "{", "'id'", ":", "file_id", ",", "'confirm'", ":", "token", "}", "\n", "response", "=", "session", ".", "get", "(", "url", ",", "params", "=", "params", ",", "stream", "=", "True", ")", "\n", "\n", "", "_save_response_content", "(", "response", ",", "fpath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.dataset_utils._get_confirm_token": [[165, 171], ["response.cookies.items", "key.startswith"], "function", ["None"], ["", "", "def", "_get_confirm_token", "(", "response", ")", ":", "\n", "    ", "for", "key", ",", "value", "in", "response", ".", "cookies", ".", "items", "(", ")", ":", "\n", "        ", "if", "key", ".", "startswith", "(", "'download_warning'", ")", ":", "\n", "            ", "return", "value", "\n", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.dataset_utils._save_response_content": [[173, 183], ["open", "torch.utils.model_zoo.tqdm", "response.iter_content", "torch.utils.model_zoo.tqdm.close", "f.write", "len", "torch.utils.model_zoo.tqdm.update"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.ema.update"], ["", "def", "_save_response_content", "(", "response", ",", "destination", ",", "chunk_size", "=", "32768", ")", ":", "\n", "    ", "with", "open", "(", "destination", ",", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "pbar", "=", "tqdm", "(", "total", "=", "None", ")", "\n", "progress", "=", "0", "\n", "for", "chunk", "in", "response", ".", "iter_content", "(", "chunk_size", ")", ":", "\n", "            ", "if", "chunk", ":", "# filter out keep-alive new chunks", "\n", "                ", "f", ".", "write", "(", "chunk", ")", "\n", "progress", "+=", "len", "(", "chunk", ")", "\n", "pbar", ".", "update", "(", "progress", "-", "pbar", ".", "n", ")", "\n", "", "", "pbar", ".", "close", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN.Generator.__init__": [[56, 207], ["torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Module.__init__", "functools.partial", "BigGAN.Generator.which_linear", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "BigGAN.G_arch", "functools.partial", "functools.partial", "functools.partial", "functools.partial", "BigGAN.Generator.which_embedding", "layers.identity", "len", "layers.bn", "BigGAN.Generator.which_conv", "BigGAN.Generator.init_weights", "print", "utils.Adam16", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "len", "print", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "layers.GBlock", "layers.Attention", "BigGAN.Generator.parameters", "BigGAN.Generator.parameters", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__", "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN.G_arch", "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN.Discriminator.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "G_ch", "=", "64", ",", "dim_z", "=", "128", ",", "bottom_width", "=", "4", ",", "resolution", "=", "128", ",", "\n", "G_kernel_size", "=", "3", ",", "G_attn", "=", "'64'", ",", "n_classes", "=", "1000", ",", "\n", "num_G_SVs", "=", "1", ",", "num_G_SV_itrs", "=", "1", ",", "\n", "G_shared", "=", "True", ",", "shared_dim", "=", "0", ",", "hier", "=", "False", ",", "\n", "cross_replica", "=", "False", ",", "mybn", "=", "False", ",", "\n", "G_activation", "=", "nn", ".", "ReLU", "(", "inplace", "=", "False", ")", ",", "\n", "G_lr", "=", "5e-5", ",", "G_B1", "=", "0.0", ",", "G_B2", "=", "0.999", ",", "adam_eps", "=", "1e-8", ",", "\n", "BN_eps", "=", "1e-5", ",", "SN_eps", "=", "1e-12", ",", "G_mixed_precision", "=", "False", ",", "G_fp16", "=", "False", ",", "\n", "G_init", "=", "'ortho'", ",", "skip_init", "=", "False", ",", "no_optim", "=", "False", ",", "\n", "G_param", "=", "'SN'", ",", "norm_style", "=", "'bn'", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Generator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Channel width mulitplier", "\n", "self", ".", "ch", "=", "G_ch", "\n", "# Dimensionality of the latent space", "\n", "self", ".", "dim_z", "=", "dim_z", "\n", "# The initial spatial dimensions", "\n", "self", ".", "bottom_width", "=", "bottom_width", "\n", "# Resolution of the output", "\n", "self", ".", "resolution", "=", "resolution", "\n", "# Kernel size?", "\n", "self", ".", "kernel_size", "=", "G_kernel_size", "\n", "# Attention?", "\n", "self", ".", "attention", "=", "G_attn", "\n", "# number of classes, for use in categorical conditional generation", "\n", "self", ".", "n_classes", "=", "n_classes", "\n", "# Use shared embeddings?", "\n", "self", ".", "G_shared", "=", "G_shared", "\n", "# Dimensionality of the shared embedding? Unused if not using G_shared", "\n", "self", ".", "shared_dim", "=", "shared_dim", "if", "shared_dim", ">", "0", "else", "dim_z", "\n", "# Hierarchical latent space?", "\n", "self", ".", "hier", "=", "hier", "\n", "# Cross replica batchnorm?", "\n", "self", ".", "cross_replica", "=", "cross_replica", "\n", "# Use my batchnorm?", "\n", "self", ".", "mybn", "=", "mybn", "\n", "# nonlinearity for residual blocks", "\n", "self", ".", "activation", "=", "G_activation", "\n", "# Initialization style", "\n", "self", ".", "init", "=", "G_init", "\n", "# Parameterization style", "\n", "self", ".", "G_param", "=", "G_param", "\n", "# Normalization style", "\n", "self", ".", "norm_style", "=", "norm_style", "\n", "# Epsilon for BatchNorm?", "\n", "self", ".", "BN_eps", "=", "BN_eps", "\n", "# Epsilon for Spectral Norm?", "\n", "self", ".", "SN_eps", "=", "SN_eps", "\n", "# fp16?", "\n", "self", ".", "fp16", "=", "G_fp16", "\n", "# Architecture dict", "\n", "self", ".", "arch", "=", "G_arch", "(", "self", ".", "ch", ",", "self", ".", "attention", ")", "[", "resolution", "]", "\n", "\n", "# If using hierarchical latents, adjust z", "\n", "if", "self", ".", "hier", ":", "\n", "# Number of places z slots into", "\n", "            ", "self", ".", "num_slots", "=", "len", "(", "self", ".", "arch", "[", "'in_channels'", "]", ")", "+", "1", "\n", "self", ".", "z_chunk_size", "=", "(", "self", ".", "dim_z", "//", "self", ".", "num_slots", ")", "\n", "# Recalculate latent dimensionality for even splitting into chunks", "\n", "self", ".", "dim_z", "=", "self", ".", "z_chunk_size", "*", "self", ".", "num_slots", "\n", "", "else", ":", "\n", "            ", "self", ".", "num_slots", "=", "1", "\n", "self", ".", "z_chunk_size", "=", "0", "\n", "\n", "# Which convs, batchnorms, and linear layers to use", "\n", "", "if", "self", ".", "G_param", "==", "'SN'", ":", "\n", "            ", "self", ".", "which_conv", "=", "functools", ".", "partial", "(", "layers", ".", "SNConv2d", ",", "\n", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "\n", "num_svs", "=", "num_G_SVs", ",", "num_itrs", "=", "num_G_SV_itrs", ",", "\n", "eps", "=", "self", ".", "SN_eps", ")", "\n", "self", ".", "which_linear", "=", "functools", ".", "partial", "(", "layers", ".", "SNLinear", ",", "\n", "num_svs", "=", "num_G_SVs", ",", "num_itrs", "=", "num_G_SV_itrs", ",", "\n", "eps", "=", "self", ".", "SN_eps", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "which_conv", "=", "functools", ".", "partial", "(", "\n", "nn", ".", "Conv2d", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "which_linear", "=", "nn", ".", "Linear", "\n", "\n", "# We use a non-spectral-normed embedding here regardless;", "\n", "# For some reason applying SN to G's embedding seems to randomly cripple G", "\n", "", "self", ".", "which_embedding", "=", "nn", ".", "Embedding", "\n", "bn_linear", "=", "(", "functools", ".", "partial", "(", "self", ".", "which_linear", ",", "bias", "=", "False", ")", "if", "self", ".", "G_shared", "\n", "else", "self", ".", "which_embedding", ")", "\n", "self", ".", "which_bn", "=", "functools", ".", "partial", "(", "layers", ".", "ccbn", ",", "\n", "which_linear", "=", "bn_linear", ",", "\n", "cross_replica", "=", "self", ".", "cross_replica", ",", "\n", "mybn", "=", "self", ".", "mybn", ",", "\n", "input_size", "=", "(", "self", ".", "shared_dim", "+", "self", ".", "z_chunk_size", "if", "self", ".", "G_shared", "\n", "else", "self", ".", "n_classes", ")", ",", "\n", "norm_style", "=", "self", ".", "norm_style", ",", "\n", "eps", "=", "self", ".", "BN_eps", ")", "\n", "\n", "# Prepare model", "\n", "# If not using shared embeddings, self.shared is just a passthrough", "\n", "self", ".", "shared", "=", "(", "self", ".", "which_embedding", "(", "n_classes", ",", "self", ".", "shared_dim", ")", "if", "G_shared", "\n", "else", "layers", ".", "identity", "(", ")", ")", "\n", "# First linear layer", "\n", "self", ".", "linear", "=", "self", ".", "which_linear", "(", "self", ".", "dim_z", "//", "self", ".", "num_slots", ",", "\n", "self", ".", "arch", "[", "'in_channels'", "]", "[", "0", "]", "*", "(", "self", ".", "bottom_width", "**", "2", ")", ")", "\n", "\n", "# self.blocks is a doubly-nested list of modules, the outer loop intended", "\n", "# to be over blocks at a given resolution (resblocks and/or self-attention)", "\n", "# while the inner loop is over a given block", "\n", "self", ".", "blocks", "=", "[", "]", "\n", "for", "index", "in", "range", "(", "len", "(", "self", ".", "arch", "[", "'out_channels'", "]", ")", ")", ":", "\n", "            ", "self", ".", "blocks", "+=", "[", "[", "layers", ".", "GBlock", "(", "in_channels", "=", "self", ".", "arch", "[", "'in_channels'", "]", "[", "index", "]", ",", "\n", "out_channels", "=", "self", ".", "arch", "[", "'out_channels'", "]", "[", "index", "]", ",", "\n", "which_conv", "=", "self", ".", "which_conv", ",", "\n", "which_bn", "=", "self", ".", "which_bn", ",", "\n", "activation", "=", "self", ".", "activation", ",", "\n", "upsample", "=", "(", "functools", ".", "partial", "(", "F", ".", "interpolate", ",", "scale_factor", "=", "2", ")", "\n", "if", "self", ".", "arch", "[", "'upsample'", "]", "[", "index", "]", "else", "None", ")", ")", "]", "]", "\n", "\n", "# If attention on this block, attach it to the end", "\n", "if", "self", ".", "arch", "[", "'attention'", "]", "[", "self", ".", "arch", "[", "'resolution'", "]", "[", "index", "]", "]", ":", "\n", "                ", "print", "(", "'Adding attention layer in G at resolution %d'", "%", "\n", "self", ".", "arch", "[", "'resolution'", "]", "[", "index", "]", ")", "\n", "self", ".", "blocks", "[", "-", "1", "]", "+=", "[", "layers", ".", "Attention", "(", "\n", "self", ".", "arch", "[", "'out_channels'", "]", "[", "index", "]", ",", "self", ".", "which_conv", ")", "]", "\n", "\n", "# Turn self.blocks into a ModuleList so that it's all properly registered.", "\n", "", "", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "ModuleList", "(", "block", ")", "\n", "for", "block", "in", "self", ".", "blocks", "]", ")", "\n", "\n", "# output layer: batchnorm-relu-conv.", "\n", "# Consider using a non-spectral conv here", "\n", "self", ".", "output_layer", "=", "nn", ".", "Sequential", "(", "layers", ".", "bn", "(", "self", ".", "arch", "[", "'out_channels'", "]", "[", "-", "1", "]", ",", "\n", "cross_replica", "=", "self", ".", "cross_replica", ",", "\n", "mybn", "=", "self", ".", "mybn", ")", ",", "\n", "self", ".", "activation", ",", "\n", "self", ".", "which_conv", "(", "self", ".", "arch", "[", "'out_channels'", "]", "[", "-", "1", "]", ",", "3", ")", ")", "\n", "\n", "# Initialize weights. Optionally skip init for testing.", "\n", "if", "not", "skip_init", ":", "\n", "            ", "self", ".", "init_weights", "(", ")", "\n", "\n", "# Set up optimizer", "\n", "# If this is an EMA copy, no need for an optim, so just return now", "\n", "", "if", "no_optim", ":", "\n", "            ", "return", "\n", "", "self", ".", "lr", ",", "self", ".", "B1", ",", "self", ".", "B2", ",", "self", ".", "adam_eps", "=", "G_lr", ",", "G_B1", ",", "G_B2", ",", "adam_eps", "\n", "if", "G_mixed_precision", ":", "\n", "            ", "print", "(", "'Using fp16 adam in G...'", ")", "\n", "import", "utils", "\n", "self", ".", "optim", "=", "utils", ".", "Adam16", "(", "params", "=", "self", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ",", "\n", "betas", "=", "(", "self", ".", "B1", ",", "self", ".", "B2", ")", ",", "weight_decay", "=", "0", ",", "\n", "eps", "=", "self", ".", "adam_eps", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "optim", "=", "optim", ".", "Adam", "(", "params", "=", "self", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ",", "\n", "betas", "=", "(", "self", ".", "B1", ",", "self", ".", "B2", ")", ",", "weight_decay", "=", "0", ",", "\n", "eps", "=", "self", ".", "adam_eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN.Generator.init_weights": [[213, 231], ["BigGAN.Generator.modules", "print", "isinstance", "isinstance", "isinstance", "sum", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "p.data.nelement", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "print", "module.parameters"], "methods", ["None"], ["", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "self", ".", "param_count", "=", "0", "\n", "for", "module", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "(", "isinstance", "(", "module", ",", "nn", ".", "Conv2d", ")", "\n", "or", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "\n", "or", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "                ", "if", "self", ".", "init", "==", "'ortho'", ":", "\n", "                    ", "init", ".", "orthogonal_", "(", "module", ".", "weight", ")", "\n", "", "elif", "self", ".", "init", "==", "'N02'", ":", "\n", "                    ", "init", ".", "normal_", "(", "module", ".", "weight", ",", "0", ",", "0.02", ")", "\n", "", "elif", "self", ".", "init", "in", "[", "'glorot'", ",", "'xavier'", "]", ":", "\n", "                    ", "init", ".", "xavier_uniform_", "(", "module", ".", "weight", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "'Init style not recognized...'", ")", "\n", "", "self", ".", "param_count", "+=", "sum", "(", "[", "p", ".", "data", ".", "nelement", "(", ")", "\n", "for", "p", "in", "module", ".", "parameters", "(", ")", "]", ")", "\n", "", "", "print", "(", "'Param count for G'", "'s initialized parameters: %d'", "%", "\n", "self", ".", "param_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN.Generator.forward": [[236, 258], ["BigGAN.Generator.linear", "block.view", "enumerate", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "block.size", "BigGAN.Generator.output_layer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "block"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "z", ",", "y", ")", ":", "\n", "# If hierarchical, concatenate zs and ys", "\n", "        ", "if", "self", ".", "hier", ":", "\n", "            ", "zs", "=", "torch", ".", "split", "(", "z", ",", "self", ".", "z_chunk_size", ",", "1", ")", "\n", "z", "=", "zs", "[", "0", "]", "\n", "ys", "=", "[", "torch", ".", "cat", "(", "[", "y", ",", "item", "]", ",", "1", ")", "for", "item", "in", "zs", "[", "1", ":", "]", "]", "\n", "", "else", ":", "\n", "            ", "ys", "=", "[", "y", "]", "*", "len", "(", "self", ".", "blocks", ")", "\n", "\n", "# First linear layer", "\n", "", "h", "=", "self", ".", "linear", "(", "z", ")", "\n", "# Reshape", "\n", "h", "=", "h", ".", "view", "(", "h", ".", "size", "(", "0", ")", ",", "-", "1", ",", "self", ".", "bottom_width", ",", "self", ".", "bottom_width", ")", "\n", "\n", "# Loop over blocks", "\n", "for", "index", ",", "blocklist", "in", "enumerate", "(", "self", ".", "blocks", ")", ":", "\n", "# Second inner loop in case block has multiple layers", "\n", "            ", "for", "block", "in", "blocklist", ":", "\n", "                ", "h", "=", "block", "(", "h", ",", "ys", "[", "index", "]", ")", "\n", "\n", "# Apply batchnorm-relu-conv-tanh at output", "\n", "", "", "return", "torch", ".", "tanh", "(", "self", ".", "output_layer", "(", "h", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN.Discriminator.__init__": [[292, 380], ["torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Module.__init__", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "BigGAN.Discriminator.which_linear", "BigGAN.Discriminator.which_embedding", "BigGAN.D_arch", "functools.partial", "functools.partial", "functools.partial", "len", "BigGAN.Discriminator.init_weights", "print", "utils.Adam16", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "print", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "layers.DBlock", "layers.Attention", "BigGAN.Discriminator.parameters", "BigGAN.Discriminator.parameters", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__", "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN.D_arch", "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN.Discriminator.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "D_ch", "=", "64", ",", "D_wide", "=", "True", ",", "resolution", "=", "128", ",", "\n", "D_kernel_size", "=", "3", ",", "D_attn", "=", "'64'", ",", "n_classes", "=", "1000", ",", "\n", "num_D_SVs", "=", "1", ",", "num_D_SV_itrs", "=", "1", ",", "D_activation", "=", "nn", ".", "ReLU", "(", "inplace", "=", "False", ")", ",", "\n", "D_lr", "=", "2e-4", ",", "D_B1", "=", "0.0", ",", "D_B2", "=", "0.999", ",", "adam_eps", "=", "1e-8", ",", "\n", "SN_eps", "=", "1e-12", ",", "output_dim", "=", "1", ",", "D_mixed_precision", "=", "False", ",", "D_fp16", "=", "False", ",", "\n", "D_init", "=", "'ortho'", ",", "skip_init", "=", "False", ",", "D_param", "=", "'SN'", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Width multiplier", "\n", "self", ".", "ch", "=", "D_ch", "\n", "# Use Wide D as in BigGAN and SA-GAN or skinny D as in SN-GAN?", "\n", "self", ".", "D_wide", "=", "D_wide", "\n", "# Resolution", "\n", "self", ".", "resolution", "=", "resolution", "\n", "# Kernel size", "\n", "self", ".", "kernel_size", "=", "D_kernel_size", "\n", "# Attention?", "\n", "self", ".", "attention", "=", "D_attn", "\n", "# Number of classes", "\n", "self", ".", "n_classes", "=", "n_classes", "\n", "# Activation", "\n", "self", ".", "activation", "=", "D_activation", "\n", "# Initialization style", "\n", "self", ".", "init", "=", "D_init", "\n", "# Parameterization style", "\n", "self", ".", "D_param", "=", "D_param", "\n", "# Epsilon for Spectral Norm?", "\n", "self", ".", "SN_eps", "=", "SN_eps", "\n", "# Fp16?", "\n", "self", ".", "fp16", "=", "D_fp16", "\n", "# Architecture", "\n", "self", ".", "arch", "=", "D_arch", "(", "self", ".", "ch", ",", "self", ".", "attention", ")", "[", "resolution", "]", "\n", "\n", "# Which convs, batchnorms, and linear layers to use", "\n", "# No option to turn off SN in D right now", "\n", "if", "self", ".", "D_param", "==", "'SN'", ":", "\n", "            ", "self", ".", "which_conv", "=", "functools", ".", "partial", "(", "layers", ".", "SNConv2d", ",", "\n", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "\n", "num_svs", "=", "num_D_SVs", ",", "num_itrs", "=", "num_D_SV_itrs", ",", "\n", "eps", "=", "self", ".", "SN_eps", ")", "\n", "self", ".", "which_linear", "=", "functools", ".", "partial", "(", "layers", ".", "SNLinear", ",", "\n", "num_svs", "=", "num_D_SVs", ",", "num_itrs", "=", "num_D_SV_itrs", ",", "\n", "eps", "=", "self", ".", "SN_eps", ")", "\n", "self", ".", "which_embedding", "=", "functools", ".", "partial", "(", "layers", ".", "SNEmbedding", ",", "\n", "num_svs", "=", "num_D_SVs", ",", "num_itrs", "=", "num_D_SV_itrs", ",", "\n", "eps", "=", "self", ".", "SN_eps", ")", "\n", "# Prepare model", "\n", "# self.blocks is a doubly-nested list of modules, the outer loop intended", "\n", "# to be over blocks at a given resolution (resblocks and/or self-attention)", "\n", "", "self", ".", "blocks", "=", "[", "]", "\n", "for", "index", "in", "range", "(", "len", "(", "self", ".", "arch", "[", "'out_channels'", "]", ")", ")", ":", "\n", "            ", "self", ".", "blocks", "+=", "[", "[", "layers", ".", "DBlock", "(", "in_channels", "=", "self", ".", "arch", "[", "'in_channels'", "]", "[", "index", "]", ",", "\n", "out_channels", "=", "self", ".", "arch", "[", "'out_channels'", "]", "[", "index", "]", ",", "\n", "which_conv", "=", "self", ".", "which_conv", ",", "\n", "wide", "=", "self", ".", "D_wide", ",", "\n", "activation", "=", "self", ".", "activation", ",", "\n", "preactivation", "=", "(", "index", ">", "0", ")", ",", "\n", "downsample", "=", "(", "nn", ".", "AvgPool2d", "(", "2", ")", "if", "self", ".", "arch", "[", "'downsample'", "]", "[", "index", "]", "else", "None", ")", ")", "]", "]", "\n", "# If attention on this block, attach it to the end", "\n", "if", "self", ".", "arch", "[", "'attention'", "]", "[", "self", ".", "arch", "[", "'resolution'", "]", "[", "index", "]", "]", ":", "\n", "                ", "print", "(", "'Adding attention layer in D at resolution %d'", "%", "\n", "self", ".", "arch", "[", "'resolution'", "]", "[", "index", "]", ")", "\n", "self", ".", "blocks", "[", "-", "1", "]", "+=", "[", "layers", ".", "Attention", "(", "self", ".", "arch", "[", "'out_channels'", "]", "[", "index", "]", ",", "\n", "self", ".", "which_conv", ")", "]", "\n", "# Turn self.blocks into a ModuleList so that it's all properly registered.", "\n", "", "", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "ModuleList", "(", "block", ")", "\n", "for", "block", "in", "self", ".", "blocks", "]", ")", "\n", "# Linear output layer. The output dimension is typically 1, but may be", "\n", "# larger if we're e.g. turning this into a VAE with an inference output", "\n", "self", ".", "linear", "=", "self", ".", "which_linear", "(", "\n", "self", ".", "arch", "[", "'out_channels'", "]", "[", "-", "1", "]", ",", "output_dim", ")", "\n", "# Embedding for projection discrimination", "\n", "self", ".", "embed", "=", "self", ".", "which_embedding", "(", "\n", "self", ".", "n_classes", ",", "self", ".", "arch", "[", "'out_channels'", "]", "[", "-", "1", "]", ")", "\n", "\n", "# Initialize weights", "\n", "if", "not", "skip_init", ":", "\n", "            ", "self", ".", "init_weights", "(", ")", "\n", "\n", "# Set up optimizer", "\n", "", "self", ".", "lr", ",", "self", ".", "B1", ",", "self", ".", "B2", ",", "self", ".", "adam_eps", "=", "D_lr", ",", "D_B1", ",", "D_B2", ",", "adam_eps", "\n", "if", "D_mixed_precision", ":", "\n", "            ", "print", "(", "'Using fp16 adam in D...'", ")", "\n", "import", "utils", "\n", "self", ".", "optim", "=", "utils", ".", "Adam16", "(", "params", "=", "self", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ",", "\n", "betas", "=", "(", "self", ".", "B1", ",", "self", ".", "B2", ")", ",", "weight_decay", "=", "0", ",", "eps", "=", "self", ".", "adam_eps", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "optim", "=", "optim", ".", "Adam", "(", "params", "=", "self", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ",", "\n", "betas", "=", "(", "self", ".", "B1", ",", "self", ".", "B2", ")", ",", "weight_decay", "=", "0", ",", "eps", "=", "self", ".", "adam_eps", ")", "\n", "# LR scheduling, left here for forward compatibility", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN.Discriminator.init_weights": [[385, 403], ["BigGAN.Discriminator.modules", "print", "isinstance", "isinstance", "isinstance", "sum", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "p.data.nelement", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "print", "module.parameters"], "methods", ["None"], ["", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "self", ".", "param_count", "=", "0", "\n", "for", "module", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "(", "isinstance", "(", "module", ",", "nn", ".", "Conv2d", ")", "\n", "or", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "\n", "or", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "                ", "if", "self", ".", "init", "==", "'ortho'", ":", "\n", "                    ", "init", ".", "orthogonal_", "(", "module", ".", "weight", ")", "\n", "", "elif", "self", ".", "init", "==", "'N02'", ":", "\n", "                    ", "init", ".", "normal_", "(", "module", ".", "weight", ",", "0", ",", "0.02", ")", "\n", "", "elif", "self", ".", "init", "in", "[", "'glorot'", ",", "'xavier'", "]", ":", "\n", "                    ", "init", ".", "xavier_uniform_", "(", "module", ".", "weight", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "'Init style not recognized...'", ")", "\n", "", "self", ".", "param_count", "+=", "sum", "(", "[", "p", ".", "data", ".", "nelement", "(", ")", "\n", "for", "p", "in", "module", ".", "parameters", "(", ")", "]", ")", "\n", "", "", "print", "(", "'Param count for D'", "'s initialized parameters: %d'", "%", "\n", "self", ".", "param_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN.Discriminator.forward": [[404, 418], ["enumerate", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "BigGAN.Discriminator.linear", "BigGAN.Discriminator.activation", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "block", "BigGAN.Discriminator.embed"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", "=", "None", ")", ":", "\n", "# Stick x into h for cleaner for loops without flow control", "\n", "        ", "h", "=", "x", "\n", "# Loop over blocks", "\n", "for", "index", ",", "blocklist", "in", "enumerate", "(", "self", ".", "blocks", ")", ":", "\n", "            ", "for", "block", "in", "blocklist", ":", "\n", "                ", "h", "=", "block", "(", "h", ")", "\n", "# Apply global sum pooling as in SN-GAN", "\n", "", "", "h", "=", "torch", ".", "sum", "(", "self", ".", "activation", "(", "h", ")", ",", "[", "2", ",", "3", "]", ")", "\n", "# Get initial class-unconditional output", "\n", "out", "=", "self", ".", "linear", "(", "h", ")", "\n", "# Get projection of final featureset onto class vectors and add to evidence", "\n", "out", "=", "out", "+", "torch", ".", "sum", "(", "self", ".", "embed", "(", "y", ")", "*", "h", ",", "1", ",", "keepdim", "=", "True", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN.G_D.__init__": [[424, 429], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__"], ["    ", "def", "__init__", "(", "self", ",", "G", ",", "D", ",", "conditional", ")", ":", "\n", "        ", "super", "(", "G_D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "G", "=", "G", "\n", "self", ".", "D", "=", "D", "\n", "self", ".", "conditional", "=", "conditional", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN.G_D.forward": [[430, 474], ["torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "BigGAN.G_D.G", "BigGAN.G_D.D", "BigGAN.G_D.D", "gy.sum", "BigGAN.G_D.G.shared", "G_z.half.half.float", "G_z.half.half.half", "BigGAN.G_D.D", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "dy.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "z", ",", "gy", ",", "x", "=", "None", ",", "dy", "=", "None", ",", "train_G", "=", "False", ",", "return_G_z", "=", "False", ",", "\n", "split_D", "=", "False", ")", ":", "\n", "# if not using label information, make sure all y's are zero'ed out", "\n", "        ", "if", "not", "self", ".", "conditional", ":", "\n", "          ", "assert", "gy", ".", "sum", "(", ")", "==", "0", "\n", "if", "dy", "is", "not", "None", ":", "\n", "            ", "assert", "dy", ".", "sum", "(", ")", "==", "0", "\n", "# If training G, enable grad tape", "\n", "", "", "with", "torch", ".", "set_grad_enabled", "(", "train_G", ")", ":", "\n", "# Get Generator output given noise", "\n", "            ", "G_z", "=", "self", ".", "G", "(", "z", ",", "self", ".", "G", ".", "shared", "(", "gy", ")", ")", "\n", "# Cast as necessary", "\n", "if", "self", ".", "G", ".", "fp16", "and", "not", "self", ".", "D", ".", "fp16", ":", "\n", "                ", "G_z", "=", "G_z", ".", "float", "(", ")", "\n", "", "if", "self", ".", "D", ".", "fp16", "and", "not", "self", ".", "G", ".", "fp16", ":", "\n", "                ", "G_z", "=", "G_z", ".", "half", "(", ")", "\n", "# Split_D means to run D once with real data and once with fake,", "\n", "# rather than concatenating along the batch dimension.", "\n", "\n", "", "", "if", "split_D", ":", "\n", "            ", "D_fake", "=", "self", ".", "D", "(", "G_z", ",", "gy", ")", "\n", "if", "x", "is", "not", "None", ":", "\n", "                ", "D_real", "=", "self", ".", "D", "(", "x", ",", "dy", ")", "\n", "return", "D_fake", ",", "D_real", "\n", "", "else", ":", "\n", "                ", "if", "return_G_z", ":", "\n", "                    ", "return", "D_fake", ",", "G_z", "\n", "", "else", ":", "\n", "                    ", "return", "D_fake", "\n", "# If real data is provided, concatenate it with the Generator's output", "\n", "# along the batch dimension for improved efficiency.", "\n", "", "", "", "else", ":", "\n", "            ", "D_input", "=", "torch", ".", "cat", "(", "[", "G_z", ",", "x", "]", ",", "0", ")", "if", "x", "is", "not", "None", "else", "G_z", "\n", "D_class", "=", "torch", ".", "cat", "(", "[", "gy", ",", "dy", "]", ",", "0", ")", "if", "dy", "is", "not", "None", "else", "gy", "\n", "# Get Discriminator output", "\n", "D_out", "=", "self", ".", "D", "(", "D_input", ",", "D_class", ")", "\n", "if", "x", "is", "not", "None", ":", "\n", "# D_fake, D_real", "\n", "                ", "return", "torch", ".", "split", "(", "D_out", ",", "[", "G_z", ".", "shape", "[", "0", "]", ",", "x", ".", "shape", "[", "0", "]", "]", ")", "\n", "", "else", ":", "\n", "                ", "if", "return_G_z", ":", "\n", "                    ", "return", "D_out", ",", "G_z", "\n", "", "else", ":", "\n", "                    ", "return", "D_out", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN.G_arch": [[19, 53], ["range", "range", "range", "range", "range", "int", "int", "int", "int", "int", "attention.split", "attention.split", "attention.split", "attention.split", "attention.split"], "function", ["None"], ["def", "G_arch", "(", "ch", "=", "64", ",", "attention", "=", "'64'", ",", "ksize", "=", "'333333'", ",", "dilation", "=", "'111111'", ")", ":", "\n", "    ", "arch", "=", "{", "}", "\n", "arch", "[", "512", "]", "=", "{", "'in_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "16", ",", "16", ",", "8", ",", "8", ",", "4", ",", "2", ",", "1", "]", "]", ",", "\n", "'out_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "16", ",", "8", ",", "8", ",", "4", ",", "2", ",", "1", ",", "1", "]", "]", ",", "\n", "'upsample'", ":", "[", "True", "]", "*", "7", ",", "\n", "'resolution'", ":", "[", "8", ",", "16", ",", "32", ",", "64", ",", "128", ",", "256", ",", "512", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "(", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "3", ",", "10", ")", "}", "}", "\n", "arch", "[", "256", "]", "=", "{", "'in_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "16", ",", "16", ",", "8", ",", "8", ",", "4", ",", "2", "]", "]", ",", "\n", "'out_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "16", ",", "8", ",", "8", ",", "4", ",", "2", ",", "1", "]", "]", ",", "\n", "'upsample'", ":", "[", "True", "]", "*", "6", ",", "\n", "'resolution'", ":", "[", "8", ",", "16", ",", "32", ",", "64", ",", "128", ",", "256", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "(", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "3", ",", "9", ")", "}", "}", "\n", "arch", "[", "128", "]", "=", "{", "'in_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "16", ",", "16", ",", "8", ",", "4", ",", "2", "]", "]", ",", "\n", "'out_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "16", ",", "8", ",", "4", ",", "2", ",", "1", "]", "]", ",", "\n", "'upsample'", ":", "[", "True", "]", "*", "5", ",", "\n", "'resolution'", ":", "[", "8", ",", "16", ",", "32", ",", "64", ",", "128", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "(", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "3", ",", "8", ")", "}", "}", "\n", "arch", "[", "64", "]", "=", "{", "'in_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "16", ",", "16", ",", "8", ",", "4", "]", "]", ",", "\n", "'out_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "16", ",", "8", ",", "4", ",", "2", "]", "]", ",", "\n", "'upsample'", ":", "[", "True", "]", "*", "4", ",", "\n", "'resolution'", ":", "[", "8", ",", "16", ",", "32", ",", "64", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "(", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "3", ",", "7", ")", "}", "}", "\n", "arch", "[", "32", "]", "=", "{", "'in_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "4", ",", "4", ",", "4", "]", "]", ",", "\n", "'out_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "4", ",", "4", ",", "4", "]", "]", ",", "\n", "'upsample'", ":", "[", "True", "]", "*", "3", ",", "\n", "'resolution'", ":", "[", "8", ",", "16", ",", "32", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "(", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "3", ",", "6", ")", "}", "}", "\n", "\n", "return", "arch", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.BigGAN.D_arch": [[261, 288], ["range", "range", "range", "range", "int", "int", "int", "int", "attention.split", "attention.split", "attention.split", "attention.split"], "function", ["None"], ["", "", "def", "D_arch", "(", "ch", "=", "64", ",", "attention", "=", "'64'", ",", "ksize", "=", "'333333'", ",", "dilation", "=", "'111111'", ")", ":", "\n", "    ", "arch", "=", "{", "}", "\n", "arch", "[", "256", "]", "=", "{", "'in_channels'", ":", "[", "3", "]", "+", "[", "ch", "*", "item", "for", "item", "in", "[", "1", ",", "2", ",", "4", ",", "8", ",", "8", ",", "16", "]", "]", ",", "\n", "'out_channels'", ":", "[", "item", "*", "ch", "for", "item", "in", "[", "1", ",", "2", ",", "4", ",", "8", ",", "8", ",", "16", ",", "16", "]", "]", ",", "\n", "'downsample'", ":", "[", "True", "]", "*", "6", "+", "[", "False", "]", ",", "\n", "'resolution'", ":", "[", "128", ",", "64", ",", "32", ",", "16", ",", "8", ",", "4", ",", "4", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", "\n", "for", "i", "in", "range", "(", "2", ",", "8", ")", "}", "}", "\n", "arch", "[", "128", "]", "=", "{", "'in_channels'", ":", "[", "3", "]", "+", "[", "ch", "*", "item", "for", "item", "in", "[", "1", ",", "2", ",", "4", ",", "8", ",", "16", "]", "]", ",", "\n", "'out_channels'", ":", "[", "item", "*", "ch", "for", "item", "in", "[", "1", ",", "2", ",", "4", ",", "8", ",", "16", ",", "16", "]", "]", ",", "\n", "'downsample'", ":", "[", "True", "]", "*", "5", "+", "[", "False", "]", ",", "\n", "'resolution'", ":", "[", "64", ",", "32", ",", "16", ",", "8", ",", "4", ",", "4", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", "\n", "for", "i", "in", "range", "(", "2", ",", "8", ")", "}", "}", "\n", "arch", "[", "64", "]", "=", "{", "'in_channels'", ":", "[", "3", "]", "+", "[", "ch", "*", "item", "for", "item", "in", "[", "1", ",", "2", ",", "4", ",", "8", "]", "]", ",", "\n", "'out_channels'", ":", "[", "item", "*", "ch", "for", "item", "in", "[", "1", ",", "2", ",", "4", ",", "8", ",", "16", "]", "]", ",", "\n", "'downsample'", ":", "[", "True", "]", "*", "4", "+", "[", "False", "]", ",", "\n", "'resolution'", ":", "[", "32", ",", "16", ",", "8", ",", "4", ",", "4", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", "\n", "for", "i", "in", "range", "(", "2", ",", "7", ")", "}", "}", "\n", "arch", "[", "32", "]", "=", "{", "'in_channels'", ":", "[", "3", "]", "+", "[", "item", "*", "ch", "for", "item", "in", "[", "4", ",", "4", ",", "4", "]", "]", ",", "\n", "'out_channels'", ":", "[", "item", "*", "ch", "for", "item", "in", "[", "4", ",", "4", ",", "4", ",", "4", "]", "]", ",", "\n", "'downsample'", ":", "[", "True", ",", "True", ",", "False", ",", "False", "]", ",", "\n", "'resolution'", ":", "[", "16", ",", "16", ",", "16", ",", "16", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", "\n", "for", "i", "in", "range", "(", "2", ",", "6", ")", "}", "}", "\n", "return", "arch", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.dummy_training_function": [[17, 21], ["None"], "function", ["None"], ["def", "dummy_training_function", "(", ")", ":", "\n", "    ", "def", "train", "(", "x", ",", "y", ")", ":", "\n", "        ", "return", "{", "}", "\n", "", "return", "train", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.select_loss": [[23, 44], ["ValueError"], "function", ["None"], ["", "def", "select_loss", "(", "config", ")", ":", "\n", "    ", "if", "config", "[", "'loss_type'", "]", "==", "'hinge'", ":", "\n", "        ", "return", "losses", ".", "loss_hinge_dis_new", ",", "losses", ".", "loss_hinge_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'dcgan'", ":", "\n", "        ", "return", "losses", ".", "loss_dcgan_dis_new", ",", "losses", ".", "loss_dcgan_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'kl'", ":", "\n", "        ", "return", "losses", ".", "loss_kl_dis_new", ",", "losses", ".", "loss_kl_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'kl_gen'", ":", "\n", "        ", "return", "losses", ".", "loss_hinge_dis", ",", "losses", ".", "loss_kl_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'kl_dis'", ":", "\n", "        ", "return", "losses", ".", "loss_kl_dis", ",", "losses", ".", "loss_hinge_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'kl_grad'", ":", "\n", "        ", "return", "losses", ".", "loss_kl_grad_dis", ",", "losses", ".", "loss_kl_grad_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'f_kl'", ":", "\n", "        ", "return", "losses", ".", "loss_f_kl_dis", ",", "losses", ".", "loss_f_kl_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'chi2'", ":", "\n", "        ", "return", "losses", ".", "loss_chi_dis", ",", "losses", ".", "loss_chi_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'dv'", ":", "\n", "        ", "return", "losses", ".", "loss_dv_dis", ",", "losses", ".", "loss_dv_gen", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'loss not defined'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.shifted": [[45, 55], ["shift.long().item", "img.clone", "torch.rand", "torch.rand", "shift.long"], "function", ["None"], ["", "", "def", "shifted", "(", "img", ")", ":", "\n", "    ", "min_shift", "=", "10", "\n", "max_shift", "=", "25", "\n", "shift", "=", "min_shift", "+", "(", "max_shift", "-", "min_shift", ")", "*", "torch", ".", "rand", "(", "1", ")", "\n", "k", "=", "shift", ".", "long", "(", ")", ".", "item", "(", ")", "\n", "new_data", "=", "img", ".", "clone", "(", ")", "\n", "new_data", "[", ":", ",", ":", ",", ":", "k", ",", ":", "k", "]", "=", "img", "[", ":", ",", ":", ",", "-", "k", ":", ",", "-", "k", ":", "]", "\n", "new_data", "[", ":", ",", ":", ",", ":", "k", ",", "k", ":", "]", "=", "img", "[", ":", ",", ":", ",", "-", "k", ":", ",", ":", "-", "k", "]", "\n", "new_data", "[", ":", ",", ":", ",", "k", ":", ",", ":", "k", "]", "=", "img", "[", ":", ",", ":", ",", ":", "-", "k", ",", "-", "k", ":", "]", "\n", "return", "new_data", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.get_perm": [[56, 61], ["torch.randperm", "torch.randperm", "torch.all", "torch.all", "torch.eq", "torch.eq", "torch.randperm", "torch.randperm", "torch.arange", "torch.arange"], "function", ["None"], ["", "def", "get_perm", "(", "l", ")", ":", "\n", "    ", "perm", "=", "torch", ".", "randperm", "(", "l", ")", "\n", "while", "torch", ".", "all", "(", "torch", ".", "eq", "(", "perm", ",", "torch", ".", "arange", "(", "l", ")", ")", ")", ":", "\n", "        ", "perm", "=", "torch", ".", "randperm", "(", "l", ")", "\n", "", "return", "perm", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.jigsaw_k": [[62, 81], ["torch.no_grad", "torch.no_grad", "torch.split", "torch.split", "range", "torch.stack", "torch.stack", "range", "torch.split", "torch.split", "range", "torch.squeeze", "torch.squeeze", "data.size", "data.size", "int", "torch.split", "torch.split", "train_fns_aug.get_perm", "torch.cat", "torch.cat", "int", "torch.squeeze.size", "torch.cat", "torch.cat"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.get_perm"], ["", "def", "jigsaw_k", "(", "data", ",", "k", "=", "2", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "actual_h", "=", "data", ".", "size", "(", ")", "[", "2", "]", "\n", "actual_w", "=", "data", ".", "size", "(", ")", "[", "3", "]", "\n", "h", "=", "torch", ".", "split", "(", "data", ",", "int", "(", "actual_h", "/", "k", ")", ",", "dim", "=", "2", ")", "\n", "splits", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k", ")", ":", "\n", "            ", "splits", "+=", "torch", ".", "split", "(", "h", "[", "i", "]", ",", "int", "(", "actual_w", "/", "k", ")", ",", "dim", "=", "3", ")", "\n", "", "fake_samples", "=", "torch", ".", "stack", "(", "splits", ",", "-", "1", ")", "\n", "for", "idx", "in", "range", "(", "fake_samples", ".", "size", "(", ")", "[", "0", "]", ")", ":", "\n", "            ", "perm", "=", "get_perm", "(", "k", "*", "k", ")", "\n", "# fake_samples[idx] = fake_samples[idx,:,:,:,torch.randperm(k*k)]", "\n", "fake_samples", "[", "idx", "]", "=", "fake_samples", "[", "idx", ",", ":", ",", ":", ",", ":", ",", "perm", "]", "\n", "", "fake_samples", "=", "torch", ".", "split", "(", "fake_samples", ",", "1", ",", "dim", "=", "4", ")", "\n", "merged", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k", ")", ":", "\n", "            ", "merged", "+=", "[", "torch", ".", "cat", "(", "fake_samples", "[", "i", "*", "k", ":", "(", "i", "+", "1", ")", "*", "k", "]", ",", "2", ")", "]", "\n", "", "fake_samples", "=", "torch", ".", "squeeze", "(", "torch", ".", "cat", "(", "merged", ",", "3", ")", ",", "-", "1", ")", "\n", "return", "fake_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.stitch": [[82, 107], ["train_fns_aug.get_perm", "torch.split", "torch.split", "torch.split", "torch.split", "range", "range", "torch.cat", "torch.cat", "data.size", "data.size", "data.size", "[].item", "int", "int", "int", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat", "torch.cat", "int", "int", "torch.randint", "torch.randint"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.get_perm"], ["", "", "def", "stitch", "(", "data", ",", "k", "=", "2", ")", ":", "\n", "#  = torch.randperm()", "\n", "    ", "indices", "=", "get_perm", "(", "data", ".", "size", "(", "0", ")", ")", "\n", "data_perm", "=", "data", "[", "indices", "]", "\n", "actual_h", "=", "data", ".", "size", "(", ")", "[", "2", "]", "\n", "actual_w", "=", "data", ".", "size", "(", ")", "[", "3", "]", "\n", "if", "torch", ".", "randint", "(", "0", ",", "2", ",", "(", "1", ",", ")", ")", "[", "0", "]", ".", "item", "(", ")", "==", "0", ":", "\n", "        ", "dim0", ",", "dim1", "=", "2", ",", "3", "\n", "", "else", ":", "\n", "        ", "dim0", ",", "dim1", "=", "3", ",", "2", "\n", "\n", "", "h", "=", "torch", ".", "split", "(", "data", ",", "int", "(", "actual_h", "/", "k", ")", ",", "dim", "=", "dim0", ")", "\n", "h_1", "=", "torch", ".", "split", "(", "data_perm", ",", "int", "(", "actual_h", "/", "k", ")", ",", "dim", "=", "dim0", ")", "\n", "splits", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k", ")", ":", "\n", "        ", "if", "i", "<", "int", "(", "k", "/", "2", ")", ":", "\n", "            ", "splits", "+=", "torch", ".", "split", "(", "h", "[", "i", "]", ",", "int", "(", "actual_w", "/", "k", ")", ",", "dim", "=", "dim1", ")", "\n", "", "else", ":", "\n", "            ", "splits", "+=", "torch", ".", "split", "(", "h_1", "[", "i", "]", ",", "int", "(", "actual_w", "/", "k", ")", ",", "dim", "=", "dim1", ")", "\n", "", "", "merged", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k", ")", ":", "\n", "        ", "merged", "+=", "[", "torch", ".", "cat", "(", "splits", "[", "i", "*", "k", ":", "(", "i", "+", "1", ")", "*", "k", "]", ",", "dim1", ")", "]", "\n", "", "fake_samples", "=", "torch", ".", "cat", "(", "merged", ",", "dim0", ")", "\n", "\n", "return", "fake_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.mixup": [[108, 114], ["numpy.random.beta", "train_fns_aug.get_perm", "data.size"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.get_perm"], ["", "def", "mixup", "(", "data", ",", "alpha", "=", "25.0", ")", ":", "\n", "    ", "lamb", "=", "np", ".", "random", ".", "beta", "(", "alpha", ",", "alpha", ")", "\n", "# indices = torch.randperm(data.size(0))", "\n", "indices", "=", "get_perm", "(", "data", ".", "size", "(", "0", ")", ")", "\n", "data_perm", "=", "data", "[", "indices", "]", "\n", "return", "data", "*", "lamb", "+", "(", "1", "-", "lamb", ")", "*", "data_perm", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.rand_bbox": [[115, 132], ["numpy.sqrt", "numpy.int", "numpy.int", "numpy.random.randint", "numpy.random.randint", "numpy.clip", "numpy.clip", "numpy.clip", "numpy.clip"], "function", ["None"], ["", "def", "rand_bbox", "(", "size", ",", "lam", ")", ":", "\n", "    ", "W", "=", "size", "[", "2", "]", "\n", "H", "=", "size", "[", "3", "]", "\n", "cut_rat", "=", "np", ".", "sqrt", "(", "1.", "-", "lam", ")", "\n", "cut_w", "=", "np", ".", "int", "(", "W", "*", "cut_rat", ")", "\n", "cut_h", "=", "np", ".", "int", "(", "H", "*", "cut_rat", ")", "\n", "\n", "# uniform", "\n", "cx", "=", "np", ".", "random", ".", "randint", "(", "W", ")", "\n", "cy", "=", "np", ".", "random", ".", "randint", "(", "H", ")", "\n", "\n", "bbx1", "=", "np", ".", "clip", "(", "cx", "-", "cut_w", "//", "2", ",", "0", ",", "W", ")", "\n", "bby1", "=", "np", ".", "clip", "(", "cy", "-", "cut_h", "//", "2", ",", "0", ",", "H", ")", "\n", "bbx2", "=", "np", ".", "clip", "(", "cx", "+", "cut_w", "//", "2", ",", "0", ",", "W", ")", "\n", "bby2", "=", "np", ".", "clip", "(", "cy", "+", "cut_h", "//", "2", ",", "0", ",", "H", ")", "\n", "\n", "return", "bbx1", ",", "bby1", ",", "bbx2", ",", "bby2", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.cutout": [[133, 147], ["data.clone.clone", "data.clone.size", "range", "data.clone.size", "data.clone.size", "torch.mean", "torch.mean", "torch.ones_like", "torch.ones_like", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "function", ["None"], ["", "def", "cutout", "(", "data", ")", ":", "\n", "    ", "min_k", ",", "max_k", "=", "10", ",", "20", "\n", "data", "=", "data", ".", "clone", "(", ")", "\n", "h", ",", "w", "=", "data", ".", "size", "(", "2", ")", ",", "data", ".", "size", "(", "3", ")", "\n", "b_size", "=", "data", ".", "size", "(", "0", ")", "\n", "for", "i", "in", "range", "(", "b_size", ")", ":", "\n", "        ", "k", "=", "(", "min_k", "+", "(", "max_k", "-", "min_k", ")", "*", "torch", ".", "rand", "(", "1", ")", ")", ".", "long", "(", ")", ".", "item", "(", ")", "\n", "h_pos", "=", "(", "(", "h", "-", "k", ")", "*", "torch", ".", "rand", "(", "1", ")", ")", ".", "long", "(", ")", ".", "item", "(", ")", "\n", "w_pos", "=", "(", "(", "w", "-", "k", ")", "*", "torch", ".", "rand", "(", "1", ")", ")", ".", "long", "(", ")", ".", "item", "(", ")", "\n", "patch", "=", "data", "[", "i", ",", ":", ",", "h_pos", ":", "h_pos", "+", "k", ",", "w_pos", ":", "w_pos", "+", "k", "]", "\n", "patch_mean", "=", "torch", ".", "mean", "(", "patch", ",", "axis", "=", "(", "1", ",", "2", ")", ",", "keepdim", "=", "True", ")", "\n", "data", "[", "i", ",", ":", ",", "h_pos", ":", "h_pos", "+", "k", ",", "w_pos", ":", "w_pos", "+", "k", "]", "=", "torch", ".", "ones_like", "(", "patch", ")", "*", "patch_mean", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.cut_mix": [[148, 156], ["data.clone.clone", "numpy.random.beta", "train_fns_aug.get_perm", "train_fns_aug.rand_bbox", "data.clone.size", "data.clone.size"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.get_perm", "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.rand_bbox"], ["", "def", "cut_mix", "(", "data", ",", "beta", "=", "1.0", ")", ":", "\n", "    ", "data", "=", "data", ".", "clone", "(", ")", "\n", "lam", "=", "np", ".", "random", ".", "beta", "(", "beta", ",", "beta", ")", "\n", "indices", "=", "get_perm", "(", "data", ".", "size", "(", "0", ")", ")", "\n", "data_perm", "=", "data", "[", "indices", "]", "\n", "bbx1", ",", "bby1", ",", "bbx2", ",", "bby2", "=", "rand_bbox", "(", "data", ".", "size", "(", ")", ",", "lam", ")", "\n", "data", "[", ":", ",", ":", ",", "bbx1", ":", "bbx2", ",", "bby1", ":", "bby2", "]", "=", "data_perm", "[", ":", ",", ":", ",", "bbx1", ":", "bbx2", ",", "bby1", ":", "bby2", "]", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.rotate": [[157, 166], ["data.size", "range", "torch.stack", "torch.stack", "torch.stack.cuda", "torchvision.functional.rotate", "torch.stack.append", "torchvision.ToPILImage", "data[].cpu", "torchvision.ToTensor"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.rotate"], ["", "def", "rotate", "(", "data", ",", "angle", "=", "60", ")", ":", "\n", "    ", "batch_size", "=", "data", ".", "size", "(", "0", ")", "\n", "new_data", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "pil_img", "=", "transforms", ".", "ToPILImage", "(", ")", "(", "data", "[", "i", "]", ".", "cpu", "(", ")", ")", "\n", "img_rotated", "=", "transforms", ".", "functional", ".", "rotate", "(", "pil_img", ",", "angle", ")", "\n", "new_data", ".", "append", "(", "transforms", ".", "ToTensor", "(", ")", "(", "img_rotated", ")", ")", "\n", "", "new_data", "=", "torch", ".", "stack", "(", "new_data", ",", "0", ")", "\n", "return", "new_data", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.GAN_training_function": [[167, 273], ["train_fns_aug.select_loss", "G.optim.zero_grad", "D.optim.zero_grad", "torch.split", "torch.split", "torch.split", "torch.split", "range", "G.optim.zero_grad", "range", "G.optim.step", "utils.toggle_grad", "utils.toggle_grad", "D.optim.zero_grad", "range", "D.optim.step", "utils.toggle_grad", "utils.toggle_grad", "z_.sample_", "y_.sample_", "GD", "G_loss.backward", "print", "utils.ortho", "ema.update", "float", "float", "float", "z_.sample_", "train_fns_aug.jigsaw_k", "GD", "discriminator_loss", "D_loss.backward", "print", "utils.ortho", "y_.zero_", "generator_loss", "float", "G_loss.item", "D_loss_real.item", "D_loss_fake.item", "y_.zero_", "torch.zeros_like().to().long", "torch.zeros_like().to().long", "y_.sample_", "float", "float", "torch.zeros_like().to", "torch.zeros_like().to", "G.shared.parameters", "torch.zeros_like", "torch.zeros_like"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.select_loss", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Adam16.step", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.toggle_grad", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.toggle_grad", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Adam16.step", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.toggle_grad", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.toggle_grad", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.ortho", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.ema.update", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.jigsaw_k", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.ortho", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to"], ["", "def", "GAN_training_function", "(", "G", ",", "D", ",", "GD", ",", "z_", ",", "y_", ",", "ema", ",", "state_dict", ",", "config", ")", ":", "\n", "    ", "discriminator_loss", ",", "generator_loss", "=", "select_loss", "(", "config", ")", "\n", "\n", "\n", "def", "train", "(", "x", ",", "y", ")", ":", "\n", "        ", "G", ".", "optim", ".", "zero_grad", "(", ")", "\n", "D", ".", "optim", ".", "zero_grad", "(", ")", "\n", "# How many chunks to split x and y into?", "\n", "x", "=", "torch", ".", "split", "(", "x", ",", "config", "[", "'batch_size'", "]", ")", "\n", "y", "=", "torch", ".", "split", "(", "y", ",", "config", "[", "'batch_size'", "]", ")", "\n", "counter", "=", "0", "\n", "\n", "# Optionally toggle D and G's \"require_grad\"", "\n", "if", "config", "[", "'toggle_grads'", "]", ":", "\n", "            ", "utils", ".", "toggle_grad", "(", "D", ",", "True", ")", "\n", "utils", ".", "toggle_grad", "(", "G", ",", "False", ")", "\n", "\n", "", "for", "step_index", "in", "range", "(", "config", "[", "'num_D_steps'", "]", ")", ":", "\n", "# If accumulating gradients, loop multiple times before an optimizer step", "\n", "            ", "D", ".", "optim", ".", "zero_grad", "(", ")", "\n", "for", "accumulation_index", "in", "range", "(", "config", "[", "'num_D_accumulations'", "]", ")", ":", "\n", "                ", "z_", ".", "sample_", "(", ")", "\n", "if", "not", "config", "[", "'conditional'", "]", ":", "\n", "# only feed in 0's for y if \"unconditional\"", "\n", "                    ", "y_", ".", "zero_", "(", ")", "\n", "y_counter", "=", "torch", ".", "zeros_like", "(", "y", "[", "counter", "]", ")", ".", "to", "(", "y_", ".", "device", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "                    ", "y_", ".", "sample_", "(", ")", "\n", "y_counter", "=", "y", "[", "counter", "]", "\n", "\n", "", "real_samples", "=", "x", "[", "counter", "]", "\n", "real_fake_samples", "=", "jigsaw_k", "(", "real_samples", ",", "k", "=", "2", ")", "\n", "# real_fake_samples = stitch(real_samples, k = 2)", "\n", "# real_fake_samples = mixup(real_samples, alpha = 25.0)", "\n", "#real_fake_samples = cutout(real_samples)", "\n", "#real_fake_samples = cut_mix(real_samples)", "\n", "\n", "D_fake", ",", "D_real", ",", "D_real_fake", "=", "GD", "(", "z_", "[", ":", "config", "[", "'batch_size'", "]", "]", ",", "y_", "[", ":", "config", "[", "'batch_size'", "]", "]", ",", "real_samples", ",", "real_fake_samples", ",", "\n", "y_counter", ",", "train_G", "=", "False", ",", "split_D", "=", "config", "[", "'split_D'", "]", ")", "\n", "# y_.sample_()", "\n", "# D_fake, D_real = GD(z_[:config['batch_size']], y_[:config['batch_size']],", "\n", "#                     x[counter], y[counter], train_G=False,", "\n", "#                     split_D=config['split_D'])", "\n", "# Compute components of D's loss, average them, and divide by", "\n", "# the number of gradient accumulations", "\n", "# if D_fake.max().item() - D_fake.min().item() > 30:", "\n", "# import ipdb", "\n", "# ipdb.set_trace()", "\n", "\n", "D_loss_real", ",", "D_loss_fake", ",", "D_loss_real_fake", "=", "discriminator_loss", "(", "\n", "D_fake", ",", "D_real", ",", "D_real_fake", ")", "\n", "if", "config", "[", "'curriculum_baseline'", "]", "and", "state_dict", "[", "'epoch'", "]", "<=", "config", "[", "'curriculum_epochs'", "]", ":", "\n", "                    ", "D_loss", "=", "(", "D_loss_real", "+", "D_loss_fake", ")", "/", "float", "(", "config", "[", "'num_D_accumulations'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "D_loss", "=", "(", "D_loss_real", "+", "config", "[", "'alpha'", "]", "*", "D_loss_fake", "+", "config", "[", "'beta'", "]", "*", "D_loss_real_fake", ")", "/", "float", "(", "config", "[", "'num_D_accumulations'", "]", ")", "\n", "\n", "", "D_loss", ".", "backward", "(", ")", "\n", "counter", "+=", "1", "\n", "\n", "# Optionally apply ortho reg in D", "\n", "", "if", "config", "[", "'D_ortho'", "]", ">", "0.0", ":", "\n", "# Debug print to indicate we're using ortho reg in D.", "\n", "                ", "print", "(", "'using modified ortho reg in D'", ")", "\n", "utils", ".", "ortho", "(", "D", ",", "config", "[", "'D_ortho'", "]", ")", "\n", "\n", "", "D", ".", "optim", ".", "step", "(", ")", "\n", "\n", "# Optionally toggle \"requires_grad\"", "\n", "", "if", "config", "[", "'toggle_grads'", "]", ":", "\n", "            ", "utils", ".", "toggle_grad", "(", "D", ",", "False", ")", "\n", "utils", ".", "toggle_grad", "(", "G", ",", "True", ")", "\n", "\n", "# Zero G's gradients by default before training G, for safety", "\n", "", "G", ".", "optim", ".", "zero_grad", "(", ")", "\n", "\n", "# If accumulating gradients, loop multiple times", "\n", "for", "accumulation_index", "in", "range", "(", "config", "[", "'num_G_accumulations'", "]", ")", ":", "\n", "            ", "z_", ".", "sample_", "(", ")", "\n", "y_", ".", "sample_", "(", ")", "\n", "if", "not", "config", "[", "'conditional'", "]", ":", "\n", "                ", "y_", ".", "zero_", "(", ")", "\n", "", "D_fake", "=", "GD", "(", "z_", ",", "y_", ",", "train_G", "=", "True", ",", "split_D", "=", "config", "[", "'split_D'", "]", ")", "\n", "G_loss", "=", "generator_loss", "(", "\n", "D_fake", ")", "/", "float", "(", "config", "[", "'num_G_accumulations'", "]", ")", "\n", "G_loss", ".", "backward", "(", ")", "\n", "\n", "# Optionally apply modified ortho reg in G", "\n", "", "if", "config", "[", "'G_ortho'", "]", ">", "0.0", ":", "\n", "# Debug print to indicate we're using ortho reg in G", "\n", "            ", "print", "(", "'using modified ortho reg in G'", ")", "\n", "# Don't ortho reg shared, it makes no sense. Really we should blacklist any embeddings for this", "\n", "utils", ".", "ortho", "(", "G", ",", "config", "[", "'G_ortho'", "]", ",", "\n", "blacklist", "=", "[", "param", "for", "param", "in", "G", ".", "shared", ".", "parameters", "(", ")", "]", ")", "\n", "", "G", ".", "optim", ".", "step", "(", ")", "\n", "\n", "# If we have an ema, update it, regardless of if we test with it or not", "\n", "if", "config", "[", "'ema'", "]", ":", "\n", "            ", "ema", ".", "update", "(", "state_dict", "[", "'itr'", "]", ")", "\n", "\n", "", "out", "=", "{", "'G_loss'", ":", "float", "(", "G_loss", ".", "item", "(", ")", ")", ",", "\n", "'D_loss_real'", ":", "float", "(", "D_loss_real", ".", "item", "(", ")", ")", ",", "\n", "'D_loss_fake'", ":", "float", "(", "D_loss_fake", ".", "item", "(", ")", ")", "}", "\n", "# Return G's loss and the components of D's loss.", "\n", "return", "out", "\n", "", "return", "train", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.GAN_log_function": [[280, 337], ["numpy.transpose", "int", "torch.zeros().to().long", "torch.zeros().to().long", "range", "numpy.array", "print", "numpy.save", "numpy.load", "math.ceil", "torch.from_numpy().float", "torch.from_numpy().float", "test_data.to.to", "GD", "numpy.squeeze", "np.array.extend", "print", "numpy.min", "numpy.max", "torch.zeros().to", "torch.zeros().to", "D_real.cpu().data.numpy", "len", "torch.from_numpy", "torch.from_numpy", "torch.zeros", "torch.zeros", "D_real.cpu"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to"], ["def", "GAN_log_function", "(", "G", ",", "D", ",", "GD", ",", "z_", ",", "y_", ",", "ema", ",", "state_dict", ",", "config", ")", ":", "\n", "    ", "import", "numpy", "as", "np", "\n", "import", "math", "\n", "discriminator_loss", "=", "losses", ".", "loss_hinge_analysis", "\n", "\n", "def", "train", "(", ")", ":", "\n", "\n", "        ", "corrupt_dict", "=", "{", "'elastic'", ":", "'elastic_transform'", ",", "'jpeg'", ":", "'jpeg_compression'", ",", "'speckle'", ":", "'speckle_noise'", ",", "'gaussian'", ":", "'gaussian_noise'", ",", "\n", "'blur'", ":", "'gaussian_blur'", ",", "\n", "'zoom'", ":", "'zoom_blur'", ",", "'brightness'", ":", "'brightness'", ",", "'contrast'", ":", "'contrast'", ",", "'defocus'", ":", "'defocus_blur'", ",", "\n", "'fog'", ":", "'fog'", ",", "'frost'", ":", "'frost'", ",", "'glass'", ":", "'glass_blur'", ",", "'impulse'", ":", "'impulse_noise'", ",", "'motion'", ":", "'motion_blur'", ",", "\n", "'pixelate'", ":", "'pixelate'", ",", "'saturate'", ":", "'saturate'", ",", "'shot'", ":", "'shot_noise'", ",", "'snow'", ":", "'snow'", ",", "'spatter'", ":", "'spatter'", ",", "\n", "'train'", ":", "'train_samples'", ",", "'test'", ":", "'test_samples'", "\n", "}", "\n", "base_dir", "=", "\"../mintnet/CIFAR-10-C/\"", "\n", "for", "mode", "in", "corrupt_dict", ":", "\n", "\n", "# test_batch = np.transpose(np.load(\"../mintnet/CIFAR-10-C/elastic_transform.npy\"), (0, 3, 1, 2))[-10000:]", "\n", "            ", "test_batch", "=", "np", ".", "transpose", "(", "np", ".", "load", "(", "base_dir", "+", "corrupt_dict", "[", "mode", "]", "+", "\".npy\"", ")", ",", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "\n", "batch_size", "=", "50", "\n", "test_iters", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "test_batch", ")", "/", "batch_size", ")", ")", "\n", "logp", "=", "[", "]", "\n", "y_counter", "=", "torch", ".", "zeros", "(", "batch_size", ")", ".", "to", "(", "\"cuda\"", ")", ".", "long", "(", ")", "\n", "losses", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "test_iters", ")", ":", "\n", "                ", "data_batch", "=", "test_batch", "[", "idx", "*", "batch_size", ":", "(", "idx", "+", "1", ")", "*", "batch_size", "]", "\n", "test_data", "=", "torch", ".", "from_numpy", "(", "data_batch", ")", ".", "float", "(", ")", "\n", "test_data", "=", "test_data", ".", "to", "(", "\"cuda\"", ")", "\n", "\n", "data", "=", "test_data", "/", "255.0", "\n", "\n", "D_fake", ",", "D_real", "=", "GD", "(", "z_", "[", ":", "config", "[", "'batch_size'", "]", "]", ",", "y_", "[", ":", "config", "[", "'batch_size'", "]", "]", ",", "data", ",", "\n", "y_counter", ",", "train_G", "=", "False", ",", "split_D", "=", "config", "[", "'split_D'", "]", ")", "\n", "\n", "#D_loss_real = discriminator_loss(", "\n", "#        D_real)", "\n", "\n", "#D_loss_real_np = np.squeeze(D_loss_real.cpu().data.numpy(), -1) ", "\n", "D_real_np", "=", "np", ".", "squeeze", "(", "D_real", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "-", "1", ")", "\n", "\n", "logp", ".", "extend", "(", "D_real_np", ")", "\n", "#losses.extend(D_loss_real_np)", "\n", "print", "(", "\"%d iters reached\"", "%", "idx", ")", "\n", "\n", "\n", "", "logp", "=", "np", ".", "array", "(", "logp", ")", "\n", "#losses = np.array(losses)", "\n", "# print(np.min(cleaned_data), np.max(cleaned_data), cleaned_data.shape)", "\n", "# np.save(\"corruption/elastic_pgd.npy\", cleaned_data)", "\n", "print", "(", "\"logp calculation done for the corruption \"", ",", "mode", ",", "\" and the shape of data is \"", ",", "logp", ".", "shape", ",", "\" min is \"", ",", "np", ".", "min", "(", "logp", ")", ",", "\n", "\" max is \"", ",", "np", ".", "max", "(", "logp", ")", ")", "\n", "np", ".", "save", "(", "\"corruption_new/\"", "+", "mode", "+", "\"_logp.npy\"", ",", "logp", ")", "\n", "#np.save(\"corruption/temp.npy\", losses)", "\n", "#break", "\n", "\n", "\n", "", "", "return", "train", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.save_and_sample": [[338, 398], ["utils.save_weights", "torchvision.utils.save_image", "torchvision.utils.save_image", "utils.sample_sheet", "zip", "utils.save_weights", "utils.accumulate_standing_stats", "torch.no_grad", "torch.no_grad", "os.path.isdir", "os.mkdir", "which_G.float().cpu", "utils.interp_sheet", "y_.zero_", "torch.parallel.data_parallel", "which_G", "int", "which_G.shared", "which_G.float", "which_G.shared"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.save_weights", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.sample_sheet", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.save_weights", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.accumulate_standing_stats", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.interp_sheet"], ["", "def", "save_and_sample", "(", "G", ",", "D", ",", "G_ema", ",", "z_", ",", "y_", ",", "fixed_z", ",", "fixed_y", ",", "\n", "state_dict", ",", "config", ",", "experiment_name", ")", ":", "\n", "    ", "utils", ".", "save_weights", "(", "G", ",", "D", ",", "state_dict", ",", "config", "[", "'weights_root'", "]", ",", "\n", "experiment_name", ",", "None", ",", "G_ema", "if", "config", "[", "'ema'", "]", "else", "None", ")", "\n", "# Save an additional copy to mitigate accidental corruption if process", "\n", "# is killed during a save (it's happened to me before -.-)", "\n", "if", "config", "[", "'num_save_copies'", "]", ">", "0", ":", "\n", "        ", "utils", ".", "save_weights", "(", "G", ",", "D", ",", "state_dict", ",", "config", "[", "'weights_root'", "]", ",", "\n", "experiment_name", ",", "\n", "'copy%d'", "%", "state_dict", "[", "'save_num'", "]", ",", "\n", "G_ema", "if", "config", "[", "'ema'", "]", "else", "None", ")", "\n", "state_dict", "[", "'save_num'", "]", "=", "(", "\n", "state_dict", "[", "'save_num'", "]", "+", "1", ")", "%", "config", "[", "'num_save_copies'", "]", "\n", "\n", "# Use EMA G for samples or non-EMA?", "\n", "", "which_G", "=", "G_ema", "if", "config", "[", "'ema'", "]", "and", "config", "[", "'use_ema'", "]", "else", "G", "\n", "\n", "# Accumulate standing statistics?", "\n", "if", "config", "[", "'accumulate_stats'", "]", ":", "\n", "        ", "if", "not", "config", "[", "'conditional'", "]", ":", "\n", "            ", "y_", ".", "zero_", "(", ")", "\n", "", "utils", ".", "accumulate_standing_stats", "(", "G_ema", "if", "config", "[", "'ema'", "]", "and", "config", "[", "'use_ema'", "]", "else", "G", ",", "\n", "z_", ",", "y_", ",", "config", "[", "'n_classes'", "]", ",", "\n", "config", "[", "'num_standing_accumulations'", "]", ")", "\n", "\n", "# Save a random sample sheet with fixed z and y", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "if", "config", "[", "'parallel'", "]", ":", "\n", "            ", "fixed_Gz", "=", "nn", ".", "parallel", ".", "data_parallel", "(", "\n", "which_G", ",", "(", "fixed_z", ",", "which_G", ".", "shared", "(", "fixed_y", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "fixed_Gz", "=", "which_G", "(", "fixed_z", ",", "which_G", ".", "shared", "(", "fixed_y", ")", ")", "\n", "", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "'%s/%s'", "%", "(", "config", "[", "'samples_root'", "]", ",", "experiment_name", ")", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "'%s/%s'", "%", "(", "config", "[", "'samples_root'", "]", ",", "experiment_name", ")", ")", "\n", "", "image_filename", "=", "'%s/%s/fixed_samples%d.jpg'", "%", "(", "config", "[", "'samples_root'", "]", ",", "\n", "experiment_name", ",", "\n", "state_dict", "[", "'itr'", "]", ")", "\n", "torchvision", ".", "utils", ".", "save_image", "(", "fixed_Gz", ".", "float", "(", ")", ".", "cpu", "(", ")", ",", "image_filename", ",", "\n", "nrow", "=", "int", "(", "fixed_Gz", ".", "shape", "[", "0", "]", "**", "0.5", ")", ",", "normalize", "=", "True", ")", "\n", "# For now, every time we save, also save sample sheets", "\n", "utils", ".", "sample_sheet", "(", "which_G", ",", "\n", "classes_per_sheet", "=", "utils", ".", "classes_per_sheet_dict", "[", "config", "[", "'dataset'", "]", "]", ",", "\n", "num_classes", "=", "config", "[", "'n_classes'", "]", ",", "\n", "samples_per_class", "=", "10", ",", "parallel", "=", "config", "[", "'parallel'", "]", ",", "\n", "samples_root", "=", "config", "[", "'samples_root'", "]", ",", "\n", "experiment_name", "=", "experiment_name", ",", "\n", "folder_number", "=", "state_dict", "[", "'itr'", "]", ",", "\n", "z_", "=", "z_", ")", "\n", "# Also save interp sheets", "\n", "for", "fix_z", ",", "fix_y", "in", "zip", "(", "[", "False", ",", "False", ",", "True", "]", ",", "[", "False", ",", "True", ",", "False", "]", ")", ":", "\n", "        ", "utils", ".", "interp_sheet", "(", "which_G", ",", "\n", "num_per_sheet", "=", "16", ",", "\n", "num_midpoints", "=", "8", ",", "\n", "num_classes", "=", "config", "[", "'n_classes'", "]", ",", "\n", "parallel", "=", "config", "[", "'parallel'", "]", ",", "\n", "samples_root", "=", "config", "[", "'samples_root'", "]", ",", "\n", "experiment_name", "=", "experiment_name", ",", "\n", "folder_number", "=", "state_dict", "[", "'itr'", "]", ",", "\n", "sheet_number", "=", "0", ",", "\n", "fix_z", "=", "fix_z", ",", "fix_y", "=", "fix_y", ",", "device", "=", "'cuda'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.test": [[405, 457], ["print", "ResNet18", "clf.to.load_state_dict", "clf.to.to", "clf.to.eval", "train_fns_aug.classify_examples", "utils.fairness_discrepancy", "print", "print", "get_inception_metrics", "print", "max", "min", "min", "test_log.log", "torch.cuda.is_available", "torch.cuda.is_available", "utils.accumulate_standing_stats", "print", "utils.save_weights", "torch.load", "torch.load", "int", "float", "float", "float"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Adam16.load_state_dict", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.classify_examples", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.fairness_discrepancy", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MyLogger.log", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.accumulate_standing_stats", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.save_weights"], ["def", "test", "(", "G", ",", "D", ",", "G_ema", ",", "z_", ",", "y_", ",", "state_dict", ",", "config", ",", "sample", ",", "get_inception_metrics", ",", "\n", "experiment_name", ",", "test_log", ")", ":", "\n", "    ", "\"\"\"\n    Saving the appropriate metrics for sample quality (FID) and level of bias\n    \"\"\"", "\n", "print", "(", "'Pre-loading pre-trained attribute classifier...'", ")", "\n", "if", "config", "[", "'n_classes'", "]", "==", "2", ":", "\n", "        ", "clf_state_dict", "=", "torch", ".", "load", "(", "CLF_PATH", ")", "[", "'state_dict'", "]", "\n", "", "else", ":", "\n", "# multi-attribute", "\n", "        ", "raise", "NotImplementedError", "\n", "# load attribute classifier here", "\n", "", "clf", "=", "ResNet18", "(", "block", "=", "BasicBlock", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "num_classes", "=", "config", "[", "'n_classes'", "]", ",", "grayscale", "=", "False", ")", "\n", "clf", ".", "load_state_dict", "(", "clf_state_dict", ")", "\n", "device", "=", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", "\n", "clf", "=", "clf", ".", "to", "(", "device", ")", "\n", "clf", ".", "eval", "(", ")", "# turn off batch norm", "\n", "\n", "# obtain classifier predictions for samples", "\n", "preds", "=", "classify_examples", "(", "clf", ",", "config", ")", "# (10K,)", "\n", "fair_d", "=", "utils", ".", "fairness_discrepancy", "(", "preds", ",", "config", "[", "'n_classes'", "]", ")", "\n", "print", "(", "'Fairness discrepancy metric is: {}'", ".", "format", "(", "fair_d", ")", ")", "\n", "\n", "print", "(", "'Gathering inception metrics...'", ")", "\n", "if", "config", "[", "'accumulate_stats'", "]", ":", "\n", "        ", "utils", ".", "accumulate_standing_stats", "(", "G_ema", "if", "config", "[", "'ema'", "]", "and", "config", "[", "'use_ema'", "]", "else", "G", ",", "\n", "z_", ",", "y_", ",", "config", "[", "'n_classes'", "]", ",", "\n", "config", "[", "'num_standing_accumulations'", "]", ")", "\n", "", "IS_mean", ",", "IS_std", ",", "FID", "=", "get_inception_metrics", "(", "sample", ",", "\n", "config", "[", "'num_inception_images'", "]", ",", "\n", "num_splits", "=", "10", ")", "\n", "print", "(", "'Itr %d: PYTORCH UNOFFICIAL Inception Score is %3.3f +/- %3.3f, PYTORCH UNOFFICIAL FID is %5.4f'", "%", "\n", "(", "state_dict", "[", "'itr'", "]", ",", "IS_mean", ",", "IS_std", ",", "FID", ")", ")", "\n", "# If improved over previous best metric, save approrpiate copy", "\n", "if", "(", "(", "config", "[", "'which_best'", "]", "==", "'IS'", "and", "IS_mean", ">", "state_dict", "[", "'best_IS'", "]", ")", "\n", "or", "(", "config", "[", "'which_best'", "]", "==", "'FID'", "and", "FID", "<", "state_dict", "[", "'best_FID'", "]", ")", "\n", "or", "(", "config", "[", "'which_best'", "]", "==", "'fair'", "and", "fair_d", "<", "state_dict", "[", "'best_fair_d'", "]", ")", "\n", ")", ":", "\n", "        ", "print", "(", "'%s improved over previous best, saving checkpoint...'", "%", "\n", "config", "[", "'which_best'", "]", ")", "\n", "utils", ".", "save_weights", "(", "G", ",", "D", ",", "state_dict", ",", "config", "[", "'weights_root'", "]", ",", "\n", "experiment_name", ",", "'best%d'", "%", "state_dict", "[", "'save_best_num'", "]", ",", "\n", "G_ema", "if", "config", "[", "'ema'", "]", "else", "None", ")", "\n", "state_dict", "[", "'save_best_num'", "]", "=", "(", "\n", "state_dict", "[", "'save_best_num'", "]", "+", "1", ")", "%", "config", "[", "'num_best_copies'", "]", "\n", "", "state_dict", "[", "'best_IS'", "]", "=", "max", "(", "state_dict", "[", "'best_IS'", "]", ",", "IS_mean", ")", "\n", "state_dict", "[", "'best_FID'", "]", "=", "min", "(", "state_dict", "[", "'best_FID'", "]", ",", "FID", ")", "\n", "state_dict", "[", "'best_fair_d'", "]", "=", "min", "(", "state_dict", "[", "'best_fair_d'", "]", ",", "fair_d", ")", "\n", "# Log results to file", "\n", "test_log", ".", "log", "(", "itr", "=", "int", "(", "state_dict", "[", "'itr'", "]", ")", ",", "IS_mean", "=", "float", "(", "IS_mean", ")", ",", "\n", "IS_std", "=", "float", "(", "IS_std", ")", ",", "FID", "=", "float", "(", "FID", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.update_FID": [[458, 475], ["print", "min", "test_log.log", "print", "utils.save_weights", "int", "float", "float", "float"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MyLogger.log", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.save_weights"], ["", "def", "update_FID", "(", "G", ",", "D", ",", "G_ema", ",", "state_dict", ",", "config", ",", "FID", ",", "experiment_name", ",", "test_log", ")", ":", "\n", "    ", "print", "(", "'Itr %d: PYTORCH UNOFFICIAL FID is %5.4f'", "%", "\n", "(", "state_dict", "[", "'itr'", "]", ",", "FID", ")", ")", "\n", "# If improved over previous best metric, save approrpiate copy", "\n", "if", "(", "(", "config", "[", "'which_best'", "]", "==", "'IS'", "and", "IS_mean", ">", "state_dict", "[", "'best_IS'", "]", ")", "\n", "or", "(", "config", "[", "'which_best'", "]", "==", "'FID'", "and", "FID", "<", "state_dict", "[", "'best_FID'", "]", ")", ")", ":", "\n", "        ", "print", "(", "'%s improved over previous best, saving checkpoint...'", "%", "\n", "config", "[", "'which_best'", "]", ")", "\n", "utils", ".", "save_weights", "(", "G", ",", "D", ",", "state_dict", ",", "config", "[", "'weights_root'", "]", ",", "\n", "experiment_name", ",", "'best%d'", "%", "state_dict", "[", "'save_best_num'", "]", ",", "\n", "G_ema", "if", "config", "[", "'ema'", "]", "else", "None", ")", "\n", "state_dict", "[", "'save_best_num'", "]", "=", "(", "\n", "state_dict", "[", "'save_best_num'", "]", "+", "1", ")", "%", "config", "[", "'num_best_copies'", "]", "\n", "", "state_dict", "[", "'best_FID'", "]", "=", "min", "(", "state_dict", "[", "'best_FID'", "]", ",", "FID", ")", "\n", "# Log results to file", "\n", "test_log", ".", "log", "(", "itr", "=", "int", "(", "state_dict", "[", "'itr'", "]", ")", ",", "IS_mean", "=", "float", "(", "0", ")", ",", "\n", "IS_std", "=", "float", "(", "0", ")", ",", "FID", "=", "float", "(", "FID", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_aug.classify_examples": [[476, 500], ["model.eval", "numpy.load", "torch.no_grad", "torch.no_grad", "range", "torch.cat().data.cpu().numpy", "torch.cat().data.cpu().numpy", "torch.from_numpy().to().float", "torch.from_numpy().to().float", "model", "torch.max", "torch.max", "torch.cat().data.cpu().numpy.append", "torch.cat().data.cpu", "torch.cat().data.cpu", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy", "torch.from_numpy", "torch.cat", "torch.cat"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to"], ["", "def", "classify_examples", "(", "model", ",", "config", ")", ":", "\n", "    ", "\"\"\"\n    classifies generated samples into appropriate classes \n    \"\"\"", "\n", "import", "numpy", "as", "np", "\n", "model", ".", "eval", "(", ")", "\n", "preds", "=", "[", "]", "\n", "samples", "=", "np", ".", "load", "(", "config", "[", "'sample_path'", "]", ")", "[", "'x'", "]", "\n", "n_batches", "=", "samples", ".", "shape", "[", "0", "]", "//", "1000", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# generate 10K samples", "\n", "        ", "for", "i", "in", "range", "(", "n_batches", ")", ":", "\n", "            ", "x", "=", "samples", "[", "i", "*", "1000", ":", "(", "i", "+", "1", ")", "*", "1000", "]", "\n", "samp", "=", "x", "/", "255.", "# renormalize to feed into classifier", "\n", "samp", "=", "torch", ".", "from_numpy", "(", "samp", ")", ".", "to", "(", "'cuda'", ")", ".", "float", "(", ")", "\n", "\n", "# get classifier predictions", "\n", "logits", ",", "probas", "=", "model", "(", "samp", ")", "\n", "_", ",", "pred", "=", "torch", ".", "max", "(", "probas", ",", "1", ")", "\n", "preds", ".", "append", "(", "pred", ")", "\n", "", "preds", "=", "torch", ".", "cat", "(", "preds", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "return", "preds", "\n", "", ""]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception.InceptionV3.__init__": [[31, 128], ["torch.Module.__init__", "sorted", "max", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "models.inception_v3.InceptionV3.blocks.append", "models.inception_v3.InceptionV3.parameters", "inception.fid_inception_v3", "torchvision.models.inception_v3", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "models.inception_v3.InceptionV3.blocks.append", "models.inception_v3.InceptionV3.blocks.append", "models.inception_v3.InceptionV3.blocks.append", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Sequential", "torch.Sequential", "torch.Sequential"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__", "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception.fid_inception_v3"], ["def", "__init__", "(", "self", ",", "\n", "output_blocks", "=", "[", "DEFAULT_BLOCK_INDEX", "]", ",", "\n", "resize_input", "=", "True", ",", "\n", "normalize_input", "=", "True", ",", "\n", "requires_grad", "=", "False", ",", "\n", "use_fid_inception", "=", "True", ")", ":", "\n", "        ", "\"\"\"Build pretrained InceptionV3\n\n        Parameters\n        ----------\n        output_blocks : list of int\n            Indices of blocks to return features of. Possible values are:\n                - 0: corresponds to output of first max pooling\n                - 1: corresponds to output of second max pooling\n                - 2: corresponds to output which is fed to aux classifier\n                - 3: corresponds to output of final average pooling\n        resize_input : bool\n            If true, bilinearly resizes input to width and height 299 before\n            feeding input to model. As the network without fully connected\n            layers is fully convolutional, it should be able to handle inputs\n            of arbitrary size, so resizing might not be strictly needed\n        normalize_input : bool\n            If true, scales the input from range (0, 1) to the range the\n            pretrained Inception network expects, namely (-1, 1)\n        requires_grad : bool\n            If true, parameters of the model require gradients. Possibly useful\n            for finetuning the network\n        use_fid_inception : bool\n            If true, uses the pretrained Inception model used in Tensorflow's\n            FID implementation. If false, uses the pretrained Inception model\n            available in torchvision. The FID Inception model has different\n            weights and a slightly different structure from torchvision's\n            Inception model. If you want to compute FID scores, you are\n            strongly advised to set this parameter to true to get comparable\n            results.\n        \"\"\"", "\n", "super", "(", "InceptionV3", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "resize_input", "=", "resize_input", "\n", "self", ".", "normalize_input", "=", "normalize_input", "\n", "self", ".", "output_blocks", "=", "sorted", "(", "output_blocks", ")", "\n", "self", ".", "last_needed_block", "=", "max", "(", "output_blocks", ")", "\n", "\n", "assert", "self", ".", "last_needed_block", "<=", "3", ",", "'Last possible output block index is 3'", "\n", "\n", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "if", "use_fid_inception", ":", "\n", "            ", "inception", "=", "fid_inception_v3", "(", ")", "\n", "", "else", ":", "\n", "            ", "inception", "=", "models", ".", "inception_v3", "(", "pretrained", "=", "True", ")", "\n", "\n", "# Block 0: input to maxpool1", "\n", "", "block0", "=", "[", "\n", "inception", ".", "Conv2d_1a_3x3", ",", "\n", "inception", ".", "Conv2d_2a_3x3", ",", "\n", "inception", ".", "Conv2d_2b_3x3", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "]", "\n", "self", ".", "blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block0", ")", ")", "\n", "\n", "# Block 1: maxpool1 to maxpool2", "\n", "if", "self", ".", "last_needed_block", ">=", "1", ":", "\n", "            ", "block1", "=", "[", "\n", "inception", ".", "Conv2d_3b_1x1", ",", "\n", "inception", ".", "Conv2d_4a_3x3", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "]", "\n", "self", ".", "blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block1", ")", ")", "\n", "\n", "# Block 2: maxpool2 to aux classifier", "\n", "", "if", "self", ".", "last_needed_block", ">=", "2", ":", "\n", "            ", "block2", "=", "[", "\n", "inception", ".", "Mixed_5b", ",", "\n", "inception", ".", "Mixed_5c", ",", "\n", "inception", ".", "Mixed_5d", ",", "\n", "inception", ".", "Mixed_6a", ",", "\n", "inception", ".", "Mixed_6b", ",", "\n", "inception", ".", "Mixed_6c", ",", "\n", "inception", ".", "Mixed_6d", ",", "\n", "inception", ".", "Mixed_6e", ",", "\n", "]", "\n", "self", ".", "blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block2", ")", ")", "\n", "\n", "# Block 3: aux classifier to final avgpool", "\n", "", "if", "self", ".", "last_needed_block", ">=", "3", ":", "\n", "            ", "block3", "=", "[", "\n", "inception", ".", "Mixed_7a", ",", "\n", "inception", ".", "Mixed_7b", ",", "\n", "inception", ".", "Mixed_7c", ",", "\n", "nn", ".", "AdaptiveAvgPool2d", "(", "output_size", "=", "(", "1", ",", "1", ")", ")", "\n", "]", "\n", "self", ".", "blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block3", ")", ")", "\n", "\n", "", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "requires_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception.InceptionV3.forward": [[129, 164], ["enumerate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "block", "outp.append"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "\"\"\"Get Inception feature maps\n\n        Parameters\n        ----------\n        inp : torch.autograd.Variable\n            Input tensor of shape Bx3xHxW. Values are expected to be in\n            range (0, 1)\n\n        Returns\n        -------\n        List of torch.autograd.Variable, corresponding to the selected output\n        block, sorted ascending by index\n        \"\"\"", "\n", "outp", "=", "[", "]", "\n", "x", "=", "inp", "\n", "\n", "if", "self", ".", "resize_input", ":", "\n", "            ", "x", "=", "F", ".", "interpolate", "(", "x", ",", "\n", "size", "=", "(", "299", ",", "299", ")", ",", "\n", "mode", "=", "'bilinear'", ",", "\n", "align_corners", "=", "False", ")", "\n", "\n", "", "if", "self", ".", "normalize_input", ":", "\n", "            ", "x", "=", "2", "*", "x", "-", "1", "# Scale from range (0, 1) to range (-1, 1)", "\n", "\n", "", "for", "idx", ",", "block", "in", "enumerate", "(", "self", ".", "blocks", ")", ":", "\n", "            ", "x", "=", "block", "(", "x", ")", "\n", "if", "idx", "in", "self", ".", "output_blocks", ":", "\n", "                ", "outp", ".", "append", "(", "x", ")", "\n", "\n", "", "if", "idx", "==", "self", ".", "last_needed_block", ":", "\n", "                ", "break", "\n", "\n", "", "", "return", "outp", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception.FIDInceptionA.__init__": [[195, 197], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "pool_features", ")", ":", "\n", "        ", "super", "(", "FIDInceptionA", ",", "self", ")", ".", "__init__", "(", "in_channels", ",", "pool_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception.FIDInceptionA.forward": [[198, 216], ["inception.FIDInceptionA.branch1x1", "inception.FIDInceptionA.branch5x5_1", "inception.FIDInceptionA.branch5x5_2", "inception.FIDInceptionA.branch3x3dbl_1", "inception.FIDInceptionA.branch3x3dbl_2", "inception.FIDInceptionA.branch3x3dbl_3", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "inception.FIDInceptionA.branch_pool", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "branch1x1", "=", "self", ".", "branch1x1", "(", "x", ")", "\n", "\n", "branch5x5", "=", "self", ".", "branch5x5_1", "(", "x", ")", "\n", "branch5x5", "=", "self", ".", "branch5x5_2", "(", "branch5x5", ")", "\n", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_1", "(", "x", ")", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_2", "(", "branch3x3dbl", ")", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_3", "(", "branch3x3dbl", ")", "\n", "\n", "# Patch: Tensorflow's average pool does not use the padded zero's in", "\n", "# its average calculation", "\n", "branch_pool", "=", "F", ".", "avg_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "\n", "count_include_pad", "=", "False", ")", "\n", "branch_pool", "=", "self", ".", "branch_pool", "(", "branch_pool", ")", "\n", "\n", "outputs", "=", "[", "branch1x1", ",", "branch5x5", ",", "branch3x3dbl", ",", "branch_pool", "]", "\n", "return", "torch", ".", "cat", "(", "outputs", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception.FIDInceptionC.__init__": [[220, 222], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "channels_7x7", ")", ":", "\n", "        ", "super", "(", "FIDInceptionC", ",", "self", ")", ".", "__init__", "(", "in_channels", ",", "channels_7x7", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception.FIDInceptionC.forward": [[223, 244], ["inception.FIDInceptionC.branch1x1", "inception.FIDInceptionC.branch7x7_1", "inception.FIDInceptionC.branch7x7_2", "inception.FIDInceptionC.branch7x7_3", "inception.FIDInceptionC.branch7x7dbl_1", "inception.FIDInceptionC.branch7x7dbl_2", "inception.FIDInceptionC.branch7x7dbl_3", "inception.FIDInceptionC.branch7x7dbl_4", "inception.FIDInceptionC.branch7x7dbl_5", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "inception.FIDInceptionC.branch_pool", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "branch1x1", "=", "self", ".", "branch1x1", "(", "x", ")", "\n", "\n", "branch7x7", "=", "self", ".", "branch7x7_1", "(", "x", ")", "\n", "branch7x7", "=", "self", ".", "branch7x7_2", "(", "branch7x7", ")", "\n", "branch7x7", "=", "self", ".", "branch7x7_3", "(", "branch7x7", ")", "\n", "\n", "branch7x7dbl", "=", "self", ".", "branch7x7dbl_1", "(", "x", ")", "\n", "branch7x7dbl", "=", "self", ".", "branch7x7dbl_2", "(", "branch7x7dbl", ")", "\n", "branch7x7dbl", "=", "self", ".", "branch7x7dbl_3", "(", "branch7x7dbl", ")", "\n", "branch7x7dbl", "=", "self", ".", "branch7x7dbl_4", "(", "branch7x7dbl", ")", "\n", "branch7x7dbl", "=", "self", ".", "branch7x7dbl_5", "(", "branch7x7dbl", ")", "\n", "\n", "# Patch: Tensorflow's average pool does not use the padded zero's in", "\n", "# its average calculation", "\n", "branch_pool", "=", "F", ".", "avg_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "\n", "count_include_pad", "=", "False", ")", "\n", "branch_pool", "=", "self", ".", "branch_pool", "(", "branch_pool", ")", "\n", "\n", "outputs", "=", "[", "branch1x1", ",", "branch7x7", ",", "branch7x7dbl", ",", "branch_pool", "]", "\n", "return", "torch", ".", "cat", "(", "outputs", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception.FIDInceptionE_1.__init__": [[248, 250], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "FIDInceptionE_1", ",", "self", ")", ".", "__init__", "(", "in_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception.FIDInceptionE_1.forward": [[251, 277], ["inception.FIDInceptionE_1.branch1x1", "inception.FIDInceptionE_1.branch3x3_1", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inception.FIDInceptionE_1.branch3x3dbl_1", "inception.FIDInceptionE_1.branch3x3dbl_2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "inception.FIDInceptionE_1.branch_pool", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inception.FIDInceptionE_1.branch3x3_2a", "inception.FIDInceptionE_1.branch3x3_2b", "inception.FIDInceptionE_1.branch3x3dbl_3a", "inception.FIDInceptionE_1.branch3x3dbl_3b"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "branch1x1", "=", "self", ".", "branch1x1", "(", "x", ")", "\n", "\n", "branch3x3", "=", "self", ".", "branch3x3_1", "(", "x", ")", "\n", "branch3x3", "=", "[", "\n", "self", ".", "branch3x3_2a", "(", "branch3x3", ")", ",", "\n", "self", ".", "branch3x3_2b", "(", "branch3x3", ")", ",", "\n", "]", "\n", "branch3x3", "=", "torch", ".", "cat", "(", "branch3x3", ",", "1", ")", "\n", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_1", "(", "x", ")", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_2", "(", "branch3x3dbl", ")", "\n", "branch3x3dbl", "=", "[", "\n", "self", ".", "branch3x3dbl_3a", "(", "branch3x3dbl", ")", ",", "\n", "self", ".", "branch3x3dbl_3b", "(", "branch3x3dbl", ")", ",", "\n", "]", "\n", "branch3x3dbl", "=", "torch", ".", "cat", "(", "branch3x3dbl", ",", "1", ")", "\n", "\n", "# Patch: Tensorflow's average pool does not use the padded zero's in", "\n", "# its average calculation", "\n", "branch_pool", "=", "F", ".", "avg_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "\n", "count_include_pad", "=", "False", ")", "\n", "branch_pool", "=", "self", ".", "branch_pool", "(", "branch_pool", ")", "\n", "\n", "outputs", "=", "[", "branch1x1", ",", "branch3x3", ",", "branch3x3dbl", ",", "branch_pool", "]", "\n", "return", "torch", ".", "cat", "(", "outputs", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception.FIDInceptionE_2.__init__": [[281, 283], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "FIDInceptionE_2", ",", "self", ")", ".", "__init__", "(", "in_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception.FIDInceptionE_2.forward": [[284, 311], ["inception.FIDInceptionE_2.branch1x1", "inception.FIDInceptionE_2.branch3x3_1", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inception.FIDInceptionE_2.branch3x3dbl_1", "inception.FIDInceptionE_2.branch3x3dbl_2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "inception.FIDInceptionE_2.branch_pool", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inception.FIDInceptionE_2.branch3x3_2a", "inception.FIDInceptionE_2.branch3x3_2b", "inception.FIDInceptionE_2.branch3x3dbl_3a", "inception.FIDInceptionE_2.branch3x3dbl_3b"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "branch1x1", "=", "self", ".", "branch1x1", "(", "x", ")", "\n", "\n", "branch3x3", "=", "self", ".", "branch3x3_1", "(", "x", ")", "\n", "branch3x3", "=", "[", "\n", "self", ".", "branch3x3_2a", "(", "branch3x3", ")", ",", "\n", "self", ".", "branch3x3_2b", "(", "branch3x3", ")", ",", "\n", "]", "\n", "branch3x3", "=", "torch", ".", "cat", "(", "branch3x3", ",", "1", ")", "\n", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_1", "(", "x", ")", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_2", "(", "branch3x3dbl", ")", "\n", "branch3x3dbl", "=", "[", "\n", "self", ".", "branch3x3dbl_3a", "(", "branch3x3dbl", ")", ",", "\n", "self", ".", "branch3x3dbl_3b", "(", "branch3x3dbl", ")", ",", "\n", "]", "\n", "branch3x3dbl", "=", "torch", ".", "cat", "(", "branch3x3dbl", ",", "1", ")", "\n", "\n", "# Patch: The FID Inception model uses max pooling instead of average", "\n", "# pooling. This is likely an error in this specific Inception", "\n", "# implementation, as other Inception models use average pooling here", "\n", "# (which matches the description in the paper).", "\n", "branch_pool", "=", "F", ".", "max_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "branch_pool", "=", "self", ".", "branch_pool", "(", "branch_pool", ")", "\n", "\n", "outputs", "=", "[", "branch1x1", ",", "branch3x3", ",", "branch3x3dbl", ",", "branch_pool", "]", "\n", "return", "torch", ".", "cat", "(", "outputs", ",", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception.fid_inception_v3": [[166, 191], ["torchvision.models.inception_v3", "inception.FIDInceptionA", "inception.FIDInceptionA", "inception.FIDInceptionA", "inception.FIDInceptionC", "inception.FIDInceptionC", "inception.FIDInceptionC", "inception.FIDInceptionC", "inception.FIDInceptionE_1", "inception.FIDInceptionE_2", "load_state_dict_from_url", "models.inception_v3.load_state_dict"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Adam16.load_state_dict"], ["", "", "def", "fid_inception_v3", "(", ")", ":", "\n", "    ", "\"\"\"Build pretrained Inception model for FID computation\n\n    The Inception model for FID computation uses a different set of weights\n    and has a slightly different structure than torchvision's Inception.\n\n    This method first constructs torchvision's Inception and then patches the\n    necessary parts that are different in the FID Inception model.\n    \"\"\"", "\n", "inception", "=", "models", ".", "inception_v3", "(", "num_classes", "=", "1008", ",", "\n", "aux_logits", "=", "False", ",", "\n", "pretrained", "=", "False", ")", "\n", "inception", ".", "Mixed_5b", "=", "FIDInceptionA", "(", "192", ",", "pool_features", "=", "32", ")", "\n", "inception", ".", "Mixed_5c", "=", "FIDInceptionA", "(", "256", ",", "pool_features", "=", "64", ")", "\n", "inception", ".", "Mixed_5d", "=", "FIDInceptionA", "(", "288", ",", "pool_features", "=", "64", ")", "\n", "inception", ".", "Mixed_6b", "=", "FIDInceptionC", "(", "768", ",", "channels_7x7", "=", "128", ")", "\n", "inception", ".", "Mixed_6c", "=", "FIDInceptionC", "(", "768", ",", "channels_7x7", "=", "160", ")", "\n", "inception", ".", "Mixed_6d", "=", "FIDInceptionC", "(", "768", ",", "channels_7x7", "=", "160", ")", "\n", "inception", ".", "Mixed_6e", "=", "FIDInceptionC", "(", "768", ",", "channels_7x7", "=", "192", ")", "\n", "inception", ".", "Mixed_7b", "=", "FIDInceptionE_1", "(", "1280", ")", "\n", "inception", ".", "Mixed_7c", "=", "FIDInceptionE_2", "(", "2048", ")", "\n", "\n", "state_dict", "=", "load_state_dict_from_url", "(", "FID_WEIGHTS_URL", ",", "progress", "=", "True", ")", "\n", "inception", ".", "load_state_dict", "(", "state_dict", ")", "\n", "return", "inception", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.sample.run": [[23, 186], ["utils.update_config_roots", "__import__", "print", "__import__.Generator().cuda", "utils.count_parameters", "print", "utils.load_weights", "max", "utils.prepare_z_y", "functools.partial", "inception_utils.prepare_inception_metrics", "utils.load_weights", "utils.name_from_config", "print", "model.Generator().cuda.eval", "print", "print", "utils.accumulate_standing_stats", "print", "tqdm.trange", "print", "print", "numpy.savez", "print", "print", "utils.sample_sheet", "print", "zip", "print", "functools.partial.", "torchvision.utils.save_image", "functools.partial", "inception_utils.prepare_inception_metrics.", "print", "print", "sample.run.get_metrics"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.update_config_roots", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.count_parameters", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.load_weights", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.prepare_z_y", "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_utils.prepare_inception_metrics", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.load_weights", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.name_from_config", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.accumulate_standing_stats", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.sample_sheet"], ["def", "run", "(", "config", ")", ":", "\n", "# Prepare state dict, which holds things like epoch # and itr #", "\n", "    ", "state_dict", "=", "{", "'itr'", ":", "0", ",", "'epoch'", ":", "0", ",", "'save_num'", ":", "0", ",", "'save_best_num'", ":", "0", ",", "\n", "'best_IS'", ":", "0", ",", "'best_FID'", ":", "999999", ",", "'config'", ":", "config", "}", "\n", "\n", "# Optionally, get the configuration from the state dict. This allows for", "\n", "# recovery of the config provided only a state dict and experiment name,", "\n", "# and can be convenient for writing less verbose sample shell scripts.", "\n", "if", "config", "[", "'config_from_name'", "]", ":", "\n", "        ", "utils", ".", "load_weights", "(", "None", ",", "None", ",", "state_dict", ",", "config", "[", "'weights_root'", "]", ",", "\n", "config", "[", "'experiment_name'", "]", ",", "config", "[", "'load_weights'", "]", ",", "None", ",", "\n", "strict", "=", "False", ",", "load_optim", "=", "False", ")", "\n", "# Ignore items which we might want to overwrite from the command line", "\n", "for", "item", "in", "state_dict", "[", "'config'", "]", ":", "\n", "            ", "if", "item", "not", "in", "[", "'z_var'", ",", "'base_root'", ",", "'batch_size'", ",", "'G_batch_size'", ",", "'use_ema'", ",", "'G_eval_mode'", "]", ":", "\n", "                ", "config", "[", "item", "]", "=", "state_dict", "[", "'config'", "]", "[", "item", "]", "\n", "\n", "# update config (see train.py for explanation)", "\n", "", "", "", "config", "[", "'resolution'", "]", "=", "utils", ".", "imsize_dict", "[", "config", "[", "'dataset'", "]", "]", "\n", "config", "[", "'n_classes'", "]", "=", "utils", ".", "nclass_dict", "[", "config", "[", "'dataset'", "]", "]", "\n", "config", "[", "'G_activation'", "]", "=", "utils", ".", "activation_dict", "[", "config", "[", "'G_nl'", "]", "]", "\n", "config", "[", "'D_activation'", "]", "=", "utils", ".", "activation_dict", "[", "config", "[", "'D_nl'", "]", "]", "\n", "config", "=", "utils", ".", "update_config_roots", "(", "config", ")", "\n", "config", "[", "'skip_init'", "]", "=", "True", "\n", "config", "[", "'no_optim'", "]", "=", "True", "\n", "device", "=", "'cuda'", "\n", "\n", "# Seed RNG", "\n", "# utils.seed_rng(config['seed'])  # config['seed'])", "\n", "\n", "# Setup cudnn.benchmark for free speed", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "# Import the model--this line allows us to dynamically select different files.", "\n", "model", "=", "__import__", "(", "config", "[", "'model'", "]", ")", "\n", "experiment_name", "=", "(", "config", "[", "'experiment_name'", "]", "if", "config", "[", "'experiment_name'", "]", "\n", "else", "utils", ".", "name_from_config", "(", "config", ")", ")", "\n", "print", "(", "'Experiment name is %s'", "%", "experiment_name", ")", "\n", "\n", "G", "=", "model", ".", "Generator", "(", "**", "config", ")", ".", "cuda", "(", ")", "\n", "utils", ".", "count_parameters", "(", "G", ")", "\n", "\n", "# Load weights", "\n", "print", "(", "'Loading weights...'", ")", "\n", "# Here is where we deal with the ema--load ema weights or load normal weights", "\n", "utils", ".", "load_weights", "(", "G", "if", "not", "(", "config", "[", "'use_ema'", "]", ")", "else", "None", ",", "None", ",", "state_dict", ",", "\n", "config", "[", "'weights_root'", "]", ",", "experiment_name", ",", "config", "[", "'load_weights'", "]", ",", "\n", "G", "if", "config", "[", "'ema'", "]", "and", "config", "[", "'use_ema'", "]", "else", "None", ",", "\n", "strict", "=", "False", ",", "load_optim", "=", "False", ")", "\n", "# Update batch size setting used for G", "\n", "G_batch_size", "=", "max", "(", "config", "[", "'G_batch_size'", "]", ",", "config", "[", "'batch_size'", "]", ")", "\n", "z_", ",", "y_", "=", "utils", ".", "prepare_z_y", "(", "G_batch_size", ",", "G", ".", "dim_z", ",", "config", "[", "'n_classes'", "]", ",", "\n", "device", "=", "device", ",", "fp16", "=", "config", "[", "'G_fp16'", "]", ",", "\n", "z_var", "=", "config", "[", "'z_var'", "]", ")", "\n", "\n", "if", "config", "[", "'G_eval_mode'", "]", ":", "\n", "        ", "print", "(", "'Putting G in eval mode..'", ")", "\n", "G", ".", "eval", "(", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'G is in %s mode...'", "%", "(", "'training'", "if", "G", ".", "training", "else", "'eval'", ")", ")", "\n", "\n", "# Sample function", "\n", "", "sample", "=", "functools", ".", "partial", "(", "utils", ".", "sample", ",", "G", "=", "G", ",", "z_", "=", "z_", ",", "y_", "=", "y_", ",", "config", "=", "config", ")", "\n", "if", "config", "[", "'accumulate_stats'", "]", ":", "\n", "        ", "print", "(", "'Accumulating standing stats across %d accumulations...'", "%", "\n", "config", "[", "'num_standing_accumulations'", "]", ")", "\n", "utils", ".", "accumulate_standing_stats", "(", "G", ",", "z_", ",", "y_", ",", "config", "[", "'n_classes'", "]", ",", "\n", "config", "[", "'num_standing_accumulations'", "]", ")", "\n", "\n", "# Sample a number of images and save them to an NPZ, for use with TF-Inception", "\n", "", "if", "config", "[", "'sample_npz'", "]", ":", "\n", "# Lists to hold images and labels for images", "\n", "        ", "x", ",", "y", "=", "[", "]", ",", "[", "]", "\n", "print", "(", "'Sampling %d images and saving them to npz...'", "%", "\n", "config", "[", "'sample_num_npz'", "]", ")", "\n", "for", "i", "in", "trange", "(", "int", "(", "np", ".", "ceil", "(", "config", "[", "'sample_num_npz'", "]", "/", "float", "(", "G_batch_size", ")", ")", ")", ")", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "images", ",", "labels", "=", "sample", "(", ")", "\n", "", "x", "+=", "[", "np", ".", "uint8", "(", "255", "*", "(", "images", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "+", "1", ")", "/", "2.", ")", "]", "\n", "y", "+=", "[", "labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "]", "\n", "", "x", "=", "np", ".", "concatenate", "(", "x", ",", "0", ")", "[", ":", "config", "[", "'sample_num_npz'", "]", "]", "\n", "y", "=", "np", ".", "concatenate", "(", "y", ",", "0", ")", "[", ":", "config", "[", "'sample_num_npz'", "]", "]", "\n", "print", "(", "'Images shape: %s, Labels shape: %s'", "%", "(", "x", ".", "shape", ",", "y", ".", "shape", ")", ")", "\n", "npz_filename", "=", "'%s/%s/samples.npz'", "%", "(", "\n", "config", "[", "'samples_root'", "]", ",", "experiment_name", ")", "\n", "print", "(", "'Saving npz to %s...'", "%", "npz_filename", ")", "\n", "np", ".", "savez", "(", "npz_filename", ",", "**", "{", "'x'", ":", "x", ",", "'y'", ":", "y", "}", ")", "\n", "print", "(", "\"images have been sampled\"", ")", "\n", "return", "\n", "# Prepare sample sheets", "\n", "", "if", "config", "[", "'sample_sheets'", "]", ":", "\n", "        ", "print", "(", "'Preparing conditional sample sheets...'", ")", "\n", "utils", ".", "sample_sheet", "(", "G", ",", "classes_per_sheet", "=", "utils", ".", "classes_per_sheet_dict", "[", "config", "[", "'dataset'", "]", "]", ",", "\n", "num_classes", "=", "config", "[", "'n_classes'", "]", ",", "\n", "samples_per_class", "=", "10", ",", "parallel", "=", "config", "[", "'parallel'", "]", ",", "\n", "samples_root", "=", "config", "[", "'samples_root'", "]", ",", "\n", "experiment_name", "=", "experiment_name", ",", "\n", "folder_number", "=", "config", "[", "'sample_sheet_folder_num'", "]", ",", "\n", "z_", "=", "z_", ",", ")", "\n", "# Sample interp sheets", "\n", "", "if", "config", "[", "'sample_interps'", "]", ":", "\n", "        ", "print", "(", "'Preparing interp sheets...'", ")", "\n", "for", "fix_z", ",", "fix_y", "in", "zip", "(", "[", "False", ",", "False", ",", "True", "]", ",", "[", "False", ",", "True", ",", "False", "]", ")", ":", "\n", "            ", "utils", ".", "interp_sheet", "(", "G", ",", "num_per_sheet", "=", "16", ",", "num_midpoints", "=", "8", ",", "\n", "num_classes", "=", "config", "[", "'n_classes'", "]", ",", "\n", "parallel", "=", "config", "[", "'parallel'", "]", ",", "\n", "samples_root", "=", "config", "[", "'samples_root'", "]", ",", "\n", "experiment_name", "=", "experiment_name", ",", "\n", "folder_number", "=", "config", "[", "'sample_sheet_folder_num'", "]", ",", "\n", "sheet_number", "=", "0", ",", "\n", "fix_z", "=", "fix_z", ",", "fix_y", "=", "fix_y", ",", "device", "=", "'cuda'", ")", "\n", "# Sample random sheet", "\n", "", "", "if", "config", "[", "'sample_random'", "]", ":", "\n", "        ", "print", "(", "'Preparing random sample sheet...'", ")", "\n", "images", ",", "labels", "=", "sample", "(", ")", "\n", "torchvision", ".", "utils", ".", "save_image", "(", "images", ".", "float", "(", ")", ",", "\n", "'%s/%s/random_samples.jpg'", "%", "(", "\n", "config", "[", "'samples_root'", "]", ",", "experiment_name", ")", ",", "\n", "nrow", "=", "int", "(", "G_batch_size", "**", "0.5", ")", ",", "\n", "normalize", "=", "True", ")", "\n", "\n", "# Get Inception Score and FID", "\n", "", "get_inception_metrics", "=", "inception_utils", ".", "prepare_inception_metrics", "(", "\n", "config", "[", "'dataset'", "]", ",", "config", "[", "'parallel'", "]", ",", "config", "[", "'no_fid'", "]", ")", "\n", "# Prepare a simple function get metrics that we use for trunc curves", "\n", "\n", "def", "get_metrics", "(", ")", ":", "\n", "        ", "sample", "=", "functools", ".", "partial", "(", "\n", "utils", ".", "sample", ",", "G", "=", "G", ",", "z_", "=", "z_", ",", "y_", "=", "y_", ",", "config", "=", "config", ")", "\n", "IS_mean", ",", "IS_std", ",", "FID", "=", "get_inception_metrics", "(", "\n", "sample", ",", "config", "[", "'num_inception_images'", "]", ",", "num_splits", "=", "10", ",", "prints", "=", "False", ")", "\n", "# Prepare output string", "\n", "outstring", "=", "'Using %s weights '", "%", "(", "\n", "'ema'", "if", "config", "[", "'use_ema'", "]", "else", "'non-ema'", ")", "\n", "outstring", "+=", "'in %s mode, '", "%", "(", "\n", "'eval'", "if", "config", "[", "'G_eval_mode'", "]", "else", "'training'", ")", "\n", "outstring", "+=", "'with noise variance %3.3f, '", "%", "z_", ".", "var", "\n", "outstring", "+=", "'over %d images, '", "%", "config", "[", "'num_inception_images'", "]", "\n", "if", "config", "[", "'accumulate_stats'", "]", "or", "not", "config", "[", "'G_eval_mode'", "]", ":", "\n", "            ", "outstring", "+=", "'with batch size %d, '", "%", "G_batch_size", "\n", "", "if", "config", "[", "'accumulate_stats'", "]", ":", "\n", "            ", "outstring", "+=", "'using %d standing stat accumulations, '", "%", "config", "[", "'num_standing_accumulations'", "]", "\n", "", "outstring", "+=", "'Itr %d: PYTORCH UNOFFICIAL Inception Score is %3.3f +/- %3.3f, PYTORCH UNOFFICIAL FID is %5.4f'", "%", "(", "\n", "state_dict", "[", "'itr'", "]", ",", "IS_mean", ",", "IS_std", ",", "FID", ")", "\n", "print", "(", "outstring", ")", "\n", "", "if", "config", "[", "'sample_inception_metrics'", "]", ":", "\n", "        ", "print", "(", "'Calculating Inception metrics...'", ")", "\n", "get_metrics", "(", ")", "\n", "\n", "# Sample truncation curve stuff. This is basically the same as the inception metrics code", "\n", "", "if", "config", "[", "'sample_trunc_curves'", "]", ":", "\n", "        ", "start", ",", "step", ",", "end", "=", "[", "\n", "float", "(", "item", ")", "for", "item", "in", "config", "[", "'sample_trunc_curves'", "]", ".", "split", "(", "'_'", ")", "]", "\n", "print", "(", "'Getting truncation values for variance in range (%3.3f:%3.3f:%3.3f)...'", "%", "(", "\n", "start", ",", "step", ",", "end", ")", ")", "\n", "for", "var", "in", "np", ".", "arange", "(", "start", ",", "end", "+", "step", ",", "step", ")", ":", "\n", "            ", "z_", ".", "var", "=", "var", "\n", "# Optionally comment this out if you want to run with standing stats", "\n", "# accumulated at one z variance setting", "\n", "if", "config", "[", "'accumulate_stats'", "]", ":", "\n", "                ", "utils", ".", "accumulate_standing_stats", "(", "G", ",", "z_", ",", "y_", ",", "config", "[", "'n_classes'", "]", ",", "\n", "config", "[", "'num_standing_accumulations'", "]", ")", "\n", "", "get_metrics", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.sample.main": [[188, 195], ["utils.prepare_parser", "utils.add_sample_parser", "vars", "print", "sample.run", "utils.add_sample_parser.parse_args"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.prepare_parser", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.add_sample_parser", "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_aug.run"], ["", "", "", "def", "main", "(", ")", ":", "\n", "# parse command line and run", "\n", "    ", "parser", "=", "utils", ".", "prepare_parser", "(", ")", "\n", "parser", "=", "utils", ".", "add_sample_parser", "(", "parser", ")", "\n", "config", "=", "vars", "(", "parser", ".", "parse_args", "(", ")", ")", "\n", "print", "(", "config", ")", "\n", "run", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_score.get_activations": [[67, 141], ["model.eval", "path.endswith", "numpy.empty", "tqdm", "numpy.load", "files.swapaxes().swapaxes.swapaxes().swapaxes", "len", "range", "print", "print", "images.transpose.transpose", "torch.from_numpy().type", "torch.nn.functional.adaptive_avg_pool2d.cpu().data.numpy().reshape", "print", "numpy.load", "batch.cuda.cuda", "model", "torch.nn.functional.adaptive_avg_pool2d", "files.swapaxes().swapaxes.swapaxes", "torch.from_numpy", "torch.nn.functional.adaptive_avg_pool2d.cpu().data.numpy", "torch.nn.functional.adaptive_avg_pool2d.cpu"], "function", ["None"], ["def", "get_activations", "(", "path", ",", "model", ",", "batch_size", "=", "50", ",", "dims", "=", "2048", ",", "\n", "cuda", "=", "False", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculates the activations of the pool_3 layer for all images.\n\n    Params:\n    -- files       : List of image files paths\n    -- model       : Instance of inception model\n    -- batch_size  : Batch size of images for the model to process at once.\n                     Make sure that the number of samples is a multiple of\n                     the batch size, otherwise some samples are ignored. This\n                     behavior is retained to match the original FID score\n                     implementation.\n    -- dims        : Dimensionality of features returned by Inception\n    -- cuda        : If set to True, use GPU\n    -- verbose     : If set to True and parameter out_step is given, the number\n                     of calculated batches is reported.\n    Returns:\n    -- A numpy array of dimension (num images, dims) that contains the\n       activations of the given tensor when feeding inception with the\n       query tensor.\n    \"\"\"", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "##if len(files) % batch_size != 0:", "\n", "##    print(('Warning: number of images is not a multiple of the '", "\n", "#'batch size. Some samples are going to be ignored.'))", "\n", "##if batch_size > len(files):", "\n", "##    print(('Warning: batch size is bigger than the data size. '", "\n", "#'Setting batch size to data size'))", "\n", "##    batch_size = len(files)", "\n", "if", "path", ".", "endswith", "(", "\"npy\"", ")", ":", "\n", "        ", "files", "=", "np", ".", "load", "(", "path", ")", "\n", "", "else", ":", "\n", "        ", "files", "=", "np", ".", "load", "(", "path", ")", "[", "'x'", "]", "\n", "files", "=", "files", ".", "swapaxes", "(", "1", ",", "2", ")", ".", "swapaxes", "(", "2", ",", "3", ")", "\n", "\n", "", "n_batches", "=", "len", "(", "files", ")", "//", "batch_size", "\n", "n_used_imgs", "=", "n_batches", "*", "batch_size", "\n", "\n", "pred_arr", "=", "np", ".", "empty", "(", "(", "n_used_imgs", ",", "dims", ")", ")", "\n", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "n_batches", ")", ")", ":", "\n", "#if verbose:", "\n", "        ", "print", "(", "'\\rPropagating batch %d/%d'", "%", "(", "i", "+", "1", ",", "n_batches", ")", ",", "\n", "end", "=", "''", ",", "flush", "=", "True", ")", "\n", "start", "=", "i", "*", "batch_size", "\n", "end", "=", "start", "+", "batch_size", "\n", "images", "=", "files", "[", "start", ":", "end", "]", "\n", "print", "(", "images", ".", "shape", ")", "\n", "#images = np.array([imread(str(f)).astype(np.float32)", "\n", "#                   for f in files[start:end]])", "\n", "\n", "# Reshape to (n_images, 3, height, width)", "\n", "images", "=", "images", ".", "transpose", "(", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "\n", "images", "=", "images", "/", "255.0", "\n", "\n", "batch", "=", "torch", ".", "from_numpy", "(", "images", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "if", "cuda", ":", "\n", "            ", "batch", "=", "batch", ".", "cuda", "(", ")", "\n", "\n", "", "pred", "=", "model", "(", "batch", ")", "[", "0", "]", "\n", "\n", "# If model output is not scalar, apply global spatial average pooling.", "\n", "# This happens if you choose a dimensionality not equal 2048.", "\n", "if", "pred", ".", "shape", "[", "2", "]", "!=", "1", "or", "pred", ".", "shape", "[", "3", "]", "!=", "1", ":", "\n", "            ", "pred", "=", "adaptive_avg_pool2d", "(", "pred", ",", "output_size", "=", "(", "1", ",", "1", ")", ")", "\n", "\n", "", "pred_arr", "[", "start", ":", "end", "]", "=", "pred", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "reshape", "(", "batch_size", ",", "-", "1", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "        ", "print", "(", "' done'", ")", "\n", "\n", "", "return", "pred_arr", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_score.calculate_frechet_distance": [[143, 198], ["numpy.atleast_1d", "numpy.atleast_1d", "numpy.atleast_2d", "numpy.atleast_2d", "scipy.linalg.sqrtm", "numpy.iscomplexobj", "numpy.trace", "np.atleast_2d.dot", "numpy.isfinite().all", "print", "scipy.linalg.sqrtm", "numpy.eye", "numpy.allclose", "numpy.max", "ValueError", "numpy.trace", "numpy.isfinite", "numpy.abs", "diff.dot", "numpy.trace", "numpy.diagonal"], "function", ["None"], ["", "def", "calculate_frechet_distance", "(", "mu1", ",", "sigma1", ",", "mu2", ",", "sigma2", ",", "eps", "=", "1e-6", ")", ":", "\n", "    ", "\"\"\"Numpy implementation of the Frechet Distance.\n    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n    and X_2 ~ N(mu_2, C_2) is\n            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n\n    Stable version by Dougal J. Sutherland.\n\n    Params:\n    -- mu1   : Numpy array containing the activations of a layer of the\n               inception net (like returned by the function 'get_predictions')\n               for generated samples.\n    -- mu2   : The sample mean over activations, precalculated on an\n               representative data set.\n    -- sigma1: The covariance matrix over activations for generated samples.\n    -- sigma2: The covariance matrix over activations, precalculated on an\n               representative data set.\n\n    Returns:\n    --   : The Frechet Distance.\n    \"\"\"", "\n", "\n", "mu1", "=", "np", ".", "atleast_1d", "(", "mu1", ")", "\n", "mu2", "=", "np", ".", "atleast_1d", "(", "mu2", ")", "\n", "\n", "sigma1", "=", "np", ".", "atleast_2d", "(", "sigma1", ")", "\n", "sigma2", "=", "np", ".", "atleast_2d", "(", "sigma2", ")", "\n", "\n", "assert", "mu1", ".", "shape", "==", "mu2", ".", "shape", ",", "'Training and test mean vectors have different lengths'", "\n", "assert", "sigma1", ".", "shape", "==", "sigma2", ".", "shape", ",", "'Training and test covariances have different dimensions'", "\n", "\n", "diff", "=", "mu1", "-", "mu2", "\n", "\n", "# Product might be almost singular", "\n", "covmean", ",", "_", "=", "linalg", ".", "sqrtm", "(", "sigma1", ".", "dot", "(", "sigma2", ")", ",", "disp", "=", "False", ")", "\n", "if", "not", "np", ".", "isfinite", "(", "covmean", ")", ".", "all", "(", ")", ":", "\n", "        ", "msg", "=", "(", "'fid calculation produces singular product; '", "\n", "'adding %s to diagonal of cov estimates'", ")", "%", "eps", "\n", "print", "(", "msg", ")", "\n", "offset", "=", "np", ".", "eye", "(", "sigma1", ".", "shape", "[", "0", "]", ")", "*", "eps", "\n", "covmean", "=", "linalg", ".", "sqrtm", "(", "(", "sigma1", "+", "offset", ")", ".", "dot", "(", "sigma2", "+", "offset", ")", ")", "\n", "\n", "# Numerical error might give slight imaginary component", "\n", "", "if", "np", ".", "iscomplexobj", "(", "covmean", ")", ":", "\n", "        ", "if", "not", "np", ".", "allclose", "(", "np", ".", "diagonal", "(", "covmean", ")", ".", "imag", ",", "0", ",", "atol", "=", "1e-3", ")", ":", "\n", "            ", "m", "=", "np", ".", "max", "(", "np", ".", "abs", "(", "covmean", ".", "imag", ")", ")", "\n", "raise", "ValueError", "(", "'Imaginary component {}'", ".", "format", "(", "m", ")", ")", "\n", "", "covmean", "=", "covmean", ".", "real", "\n", "\n", "", "tr_covmean", "=", "np", ".", "trace", "(", "covmean", ")", "\n", "\n", "return", "(", "diff", ".", "dot", "(", "diff", ")", "+", "np", ".", "trace", "(", "sigma1", ")", "+", "\n", "np", ".", "trace", "(", "sigma2", ")", "-", "2", "*", "tr_covmean", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_score.calculate_activation_statistics": [[200, 223], ["fid_score.get_activations", "numpy.mean", "numpy.cov"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf.get_activations"], ["", "def", "calculate_activation_statistics", "(", "files", ",", "model", ",", "batch_size", "=", "50", ",", "\n", "dims", "=", "2048", ",", "cuda", "=", "False", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculation of the statistics used by the FID.\n    Params:\n    -- files       : List of image files paths\n    -- model       : Instance of inception model\n    -- batch_size  : The images numpy array is split into batches with\n                     batch size batch_size. A reasonable batch size\n                     depends on the hardware.\n    -- dims        : Dimensionality of features returned by Inception\n    -- cuda        : If set to True, use GPU\n    -- verbose     : If set to True and parameter out_step is given, the\n                     number of calculated batches is reported.\n    Returns:\n    -- mu    : The mean over samples of the activations of the pool_3 layer of\n               the inception model.\n    -- sigma : The covariance matrix of the activations of the pool_3 layer of\n               the inception model.\n    \"\"\"", "\n", "act", "=", "get_activations", "(", "files", ",", "model", ",", "batch_size", ",", "dims", ",", "cuda", ",", "verbose", ")", "\n", "mu", "=", "np", ".", "mean", "(", "act", ",", "axis", "=", "0", ")", "\n", "sigma", "=", "np", ".", "cov", "(", "act", ",", "rowvar", "=", "False", ")", "\n", "return", "mu", ",", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_score._compute_statistics_of_path": [[225, 237], ["path.endswith", "numpy.load", "np.load.close", "fid_score.calculate_activation_statistics"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf.calculate_activation_statistics"], ["", "def", "_compute_statistics_of_path", "(", "path", ",", "model", ",", "batch_size", ",", "dims", ",", "cuda", ")", ":", "\n", "    ", "if", "path", ".", "endswith", "(", "'.npz'", ")", "and", "not", "\"sample\"", "in", "path", ":", "\n", "        ", "f", "=", "np", ".", "load", "(", "path", ")", "\n", "m", ",", "s", "=", "f", "[", "'mu'", "]", "[", ":", "]", ",", "f", "[", "'sigma'", "]", "[", ":", "]", "\n", "f", ".", "close", "(", ")", "\n", "", "else", ":", "\n", "#path = pathlib.Path(path)", "\n", "#files = list(path.glob('*.jpg')) + list(path.glob('*.png'))", "\n", "        ", "m", ",", "s", "=", "calculate_activation_statistics", "(", "path", ",", "model", ",", "batch_size", ",", "\n", "dims", ",", "cuda", ")", "\n", "\n", "", "return", "m", ",", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_score.calculate_fid_given_paths": [[239, 259], ["inception.InceptionV3", "fid_score._compute_statistics_of_path", "fid_score._compute_statistics_of_path", "fid_score.calculate_frechet_distance", "inception.InceptionV3.cuda", "os.path.exists", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_score._compute_statistics_of_path", "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_score._compute_statistics_of_path", "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf.calculate_frechet_distance"], ["", "def", "calculate_fid_given_paths", "(", "paths", ",", "batch_size", ",", "cuda", ",", "dims", ")", ":", "\n", "    ", "\"\"\"Calculates the FID of two paths\"\"\"", "\n", "cuda", "=", "True", "\n", "for", "p", "in", "paths", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "p", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Invalid path: %s'", "%", "p", ")", "\n", "\n", "", "", "block_idx", "=", "InceptionV3", ".", "BLOCK_INDEX_BY_DIM", "[", "dims", "]", "\n", "\n", "model", "=", "InceptionV3", "(", "[", "block_idx", "]", ")", "\n", "if", "cuda", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "\n", "", "m1", ",", "s1", "=", "_compute_statistics_of_path", "(", "paths", "[", "0", "]", ",", "model", ",", "batch_size", ",", "\n", "dims", ",", "cuda", ")", "\n", "m2", ",", "s2", "=", "_compute_statistics_of_path", "(", "paths", "[", "1", "]", ",", "model", ",", "batch_size", ",", "\n", "dims", ",", "cuda", ")", "\n", "fid_value", "=", "calculate_frechet_distance", "(", "m1", ",", "s1", ",", "m2", ",", "s2", ")", "\n", "\n", "return", "fid_value", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_tf13.prepare_parser": [[30, 43], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "prepare_parser", "(", ")", ":", "\n", "    ", "usage", "=", "'Parser for TF1.3- Inception Score scripts.'", "\n", "parser", "=", "ArgumentParser", "(", "description", "=", "usage", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--experiment_name'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'Which experiment'", "'s samples.npz file to pull and evaluate'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--experiment_root'", ",", "type", "=", "str", ",", "default", "=", "'samples'", ",", "\n", "help", "=", "'Default location where samples are stored (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Default overall batchsize (default: %(default)s)'", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_tf13.run": [[45, 141], ["inception_tf13.run._init_inception"], "function", ["None"], ["", "def", "run", "(", "config", ")", ":", "\n", "# Inception with TF1.3 or earlier.", "\n", "# Call this function with list of images. Each of elements should be a", "\n", "# numpy array with values ranging from 0 to 255.", "\n", "    ", "def", "get_inception_score", "(", "images", ",", "splits", "=", "10", ")", ":", "\n", "        ", "assert", "(", "type", "(", "images", ")", "==", "list", ")", "\n", "assert", "(", "type", "(", "images", "[", "0", "]", ")", "==", "np", ".", "ndarray", ")", "\n", "assert", "(", "len", "(", "images", "[", "0", "]", ".", "shape", ")", "==", "3", ")", "\n", "assert", "(", "np", ".", "max", "(", "images", "[", "0", "]", ")", ">", "10", ")", "\n", "assert", "(", "np", ".", "min", "(", "images", "[", "0", "]", ")", ">=", "0.0", ")", "\n", "inps", "=", "[", "]", "\n", "for", "img", "in", "images", ":", "\n", "            ", "img", "=", "img", ".", "astype", "(", "np", ".", "float32", ")", "\n", "inps", ".", "append", "(", "np", ".", "expand_dims", "(", "img", ",", "0", ")", ")", "\n", "", "bs", "=", "config", "[", "'batch_size'", "]", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "preds", ",", "pools", "=", "[", "]", ",", "[", "]", "\n", "n_batches", "=", "int", "(", "math", ".", "ceil", "(", "float", "(", "len", "(", "inps", ")", ")", "/", "float", "(", "bs", ")", ")", ")", "\n", "for", "i", "in", "trange", "(", "n_batches", ")", ":", "\n", "                ", "inp", "=", "inps", "[", "(", "i", "*", "bs", ")", ":", "min", "(", "(", "i", "+", "1", ")", "*", "bs", ",", "len", "(", "inps", ")", ")", "]", "\n", "inp", "=", "np", ".", "concatenate", "(", "inp", ",", "0", ")", "\n", "pred", ",", "pool", "=", "sess", ".", "run", "(", "[", "softmax", ",", "pool3", "]", ",", "{", "'ExpandDims:0'", ":", "inp", "}", ")", "\n", "preds", ".", "append", "(", "pred", ")", "\n", "pools", ".", "append", "(", "pool", ")", "\n", "", "preds", "=", "np", ".", "concatenate", "(", "preds", ",", "0", ")", "\n", "scores", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "splits", ")", ":", "\n", "                ", "part", "=", "preds", "[", "(", "i", "*", "preds", ".", "shape", "[", "0", "]", "//", "splits", ")", ":", "(", "(", "i", "+", "1", ")", "*", "preds", ".", "shape", "[", "0", "]", "//", "splits", ")", ",", ":", "]", "\n", "kl", "=", "part", "*", "(", "np", ".", "log", "(", "part", ")", "-", "\n", "np", ".", "log", "(", "np", ".", "expand_dims", "(", "np", ".", "mean", "(", "part", ",", "0", ")", ",", "0", ")", ")", ")", "\n", "kl", "=", "np", ".", "mean", "(", "np", ".", "sum", "(", "kl", ",", "1", ")", ")", "\n", "scores", ".", "append", "(", "np", ".", "exp", "(", "kl", ")", ")", "\n", "", "return", "np", ".", "mean", "(", "scores", ")", ",", "np", ".", "std", "(", "scores", ")", ",", "np", ".", "squeeze", "(", "np", ".", "concatenate", "(", "pools", ",", "0", ")", ")", "\n", "# Init inception", "\n", "\n", "", "", "def", "_init_inception", "(", ")", ":", "\n", "        ", "global", "softmax", ",", "pool3", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "MODEL_DIR", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "MODEL_DIR", ")", "\n", "", "filename", "=", "DATA_URL", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "MODEL_DIR", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "filepath", ")", ":", "\n", "            ", "def", "_progress", "(", "count", ",", "block_size", ",", "total_size", ")", ":", "\n", "                ", "sys", ".", "stdout", ".", "write", "(", "'\\r>> Downloading %s %.1f%%'", "%", "(", "\n", "filename", ",", "float", "(", "count", "*", "block_size", ")", "/", "float", "(", "total_size", ")", "*", "100.0", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "filepath", ",", "_", "=", "urllib", ".", "request", ".", "urlretrieve", "(", "\n", "DATA_URL", ",", "filepath", ",", "_progress", ")", "\n", "print", "(", ")", "\n", "statinfo", "=", "os", ".", "stat", "(", "filepath", ")", "\n", "print", "(", "'Succesfully downloaded'", ",", "filename", ",", "\n", "statinfo", ".", "st_size", ",", "'bytes.'", ")", "\n", "", "tarfile", ".", "open", "(", "filepath", ",", "'r:gz'", ")", ".", "extractall", "(", "MODEL_DIR", ")", "\n", "with", "tf", ".", "gfile", ".", "FastGFile", "(", "os", ".", "path", ".", "join", "(", "\n", "MODEL_DIR", ",", "'classify_image_graph_def.pb'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "graph_def", "=", "tf", ".", "GraphDef", "(", ")", "\n", "graph_def", ".", "ParseFromString", "(", "f", ".", "read", "(", ")", ")", "\n", "_", "=", "tf", ".", "import_graph_def", "(", "graph_def", ",", "name", "=", "''", ")", "\n", "# Works with an arbitrary minibatch size.", "\n", "", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "pool3", "=", "sess", ".", "graph", ".", "get_tensor_by_name", "(", "'pool_3:0'", ")", "\n", "ops", "=", "pool3", ".", "graph", ".", "get_operations", "(", ")", "\n", "for", "op_idx", ",", "op", "in", "enumerate", "(", "ops", ")", ":", "\n", "                ", "for", "o", "in", "op", ".", "outputs", ":", "\n", "                    ", "shape", "=", "o", ".", "get_shape", "(", ")", "\n", "shape", "=", "[", "s", ".", "value", "for", "s", "in", "shape", "]", "\n", "new_shape", "=", "[", "]", "\n", "for", "j", ",", "s", "in", "enumerate", "(", "shape", ")", ":", "\n", "                        ", "if", "s", "==", "1", "and", "j", "==", "0", ":", "\n", "                            ", "new_shape", ".", "append", "(", "None", ")", "\n", "", "else", ":", "\n", "                            ", "new_shape", ".", "append", "(", "s", ")", "\n", "", "", "o", ".", "__dict__", "[", "'_shape_val'", "]", "=", "tf", ".", "TensorShape", "(", "new_shape", ")", "\n", "# o._shape = tf.TensorShape(new_shape)", "\n", "", "", "w", "=", "sess", ".", "graph", ".", "get_operation_by_name", "(", "\n", "\"softmax/logits/MatMul\"", ")", ".", "inputs", "[", "1", "]", "\n", "logits", "=", "tf", ".", "matmul", "(", "tf", ".", "squeeze", "(", "pool3", ",", "[", "1", ",", "2", "]", ")", ",", "w", ")", "\n", "softmax", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", "\n", "\n", "# if softmax is None: # No need to functionalize like this.", "\n", "", "", "_init_inception", "(", ")", "\n", "\n", "fname", "=", "'%s/%s/samples.npz'", "%", "(", "config", "[", "'experiment_root'", "]", ",", "\n", "config", "[", "'experiment_name'", "]", ")", "\n", "print", "(", "'loading %s ...'", "%", "fname", ")", "\n", "ims", "=", "np", ".", "load", "(", "fname", ")", "[", "'x'", "]", "\n", "import", "time", "\n", "t0", "=", "time", ".", "time", "(", ")", "\n", "inc_mean", ",", "inc_std", ",", "pool_activations", "=", "get_inception_score", "(", "\n", "list", "(", "ims", ".", "swapaxes", "(", "1", ",", "2", ")", ".", "swapaxes", "(", "2", ",", "3", ")", ")", ",", "splits", "=", "10", ")", "\n", "t1", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'Saving pool to numpy file for FID calculations...'", ")", "\n", "np", ".", "savez", "(", "'%s/%s/TF_pool.npz'", "%", "(", "config", "[", "'experiment_root'", "]", ",", "config", "[", "'experiment_name'", "]", ")", ",", "**", "{", "\n", "'pool_mean'", ":", "np", ".", "mean", "(", "pool_activations", ",", "axis", "=", "0", ")", ",", "'pool_var'", ":", "np", ".", "cov", "(", "pool_activations", ",", "rowvar", "=", "False", ")", "}", ")", "\n", "print", "(", "'Inception took %3f seconds, score of %3f +/- %3f.'", "%", "\n", "(", "t1", "-", "t0", ",", "inc_mean", ",", "inc_std", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_tf13.main": [[143, 149], ["inception_tf13.prepare_parser", "vars", "print", "inception_tf13.run", "prepare_parser.parse_args"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.prepare_parser", "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_aug.run"], ["", "def", "main", "(", ")", ":", "\n", "# parse command line and run", "\n", "    ", "parser", "=", "prepare_parser", "(", ")", "\n", "config", "=", "vars", "(", "parser", ".", "parse_args", "(", ")", ")", "\n", "print", "(", "config", ")", "\n", "run", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train.run": [[37, 245], ["utils.update_config_roots", "utils.seed_rng", "utils.prepare_root", "__import__", "print", "__import__.Generator().to", "__import__.Discriminator().to", "__import__.G_D", "print", "print", "print", "print", "utils.MetricsLogger", "print", "utils.MyLogger", "utils.write_metadata", "utils.get_data_loaders", "inception_utils.prepare_inception_metrics", "max", "utils.prepare_z_y", "utils.prepare_z_y", "fixed_z.sample_", "fixed_y.sample_", "functools.partial", "print", "range", "print", "utils.name_from_config", "print", "__import__.Generator().to", "utils.ema", "print", "G.half.half", "print", "D.half.half", "print", "utils.load_weights", "torch.DataParallel", "fixed_y.zero_", "y_.zero_", "train_fns.GAN_training_function", "train_fns.dummy_training_function", "enumerate", "__import__.Generator", "__import__.Discriminator", "G_ema.half.half", "sync_batchnorm.patch_replication_callback", "utils.progress", "tqdm.tqdm", "G.half.train", "D.half.train", "train_fns.dummy_training_function.", "utils.MyLogger.log", "__import__.Generator", "G_ema.half.train", "utils.MyLogger.log", "print", "train_fns.save_and_sample", "utils.name_from_config", "utils.sample_inception", "str", "fid_score.calculate_fid_given_paths", "print", "train_fns.update_FID", "sum", "x.to().half", "y.to", "x.to", "y.to", "int", "print", "G.half.eval", "print", "G.half.eval", "str", "int", "G_ema.half.eval", "G_ema.half.eval", "p.data.nelement", "x.to", "utils.get_SVs", "utils.get_SVs", "net.parameters"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.update_config_roots", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.seed_rng", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.prepare_root", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.write_metadata", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.get_data_loaders", "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_utils.prepare_inception_metrics", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.prepare_z_y", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.prepare_z_y", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.name_from_config", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.load_weights", "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.GAN_training_function", "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.dummy_training_function", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.replicate.patch_replication_callback", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.progress", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MyLogger.log", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MyLogger.log", "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.save_and_sample", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.name_from_config", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.sample_inception", "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf.calculate_fid_given_paths", "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.update_FID", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.get_SVs", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.get_SVs"], ["def", "run", "(", "config", ")", ":", "\n", "\n", "# Update the config dict as necessary", "\n", "# This is for convenience, to add settings derived from the user-specified", "\n", "# configuration into the config-dict (e.g. inferring the number of classes", "\n", "# and size of the images from the dataset, passing in a pytorch object", "\n", "# for the activation specified as a string)", "\n", "    ", "config", "[", "'resolution'", "]", "=", "utils", ".", "imsize_dict", "[", "config", "[", "'dataset'", "]", "]", "\n", "config", "[", "'n_classes'", "]", "=", "utils", ".", "nclass_dict", "[", "config", "[", "'dataset'", "]", "]", "\n", "config", "[", "'G_activation'", "]", "=", "utils", ".", "activation_dict", "[", "config", "[", "'G_nl'", "]", "]", "\n", "config", "[", "'D_activation'", "]", "=", "utils", ".", "activation_dict", "[", "config", "[", "'D_nl'", "]", "]", "\n", "# By default, skip init if resuming training.", "\n", "if", "config", "[", "'resume'", "]", ":", "\n", "        ", "print", "(", "'Skipping initialization for training resumption...'", ")", "\n", "config", "[", "'skip_init'", "]", "=", "True", "\n", "", "config", "=", "utils", ".", "update_config_roots", "(", "config", ")", "\n", "device", "=", "'cuda'", "\n", "\n", "# Seed RNG", "\n", "utils", ".", "seed_rng", "(", "config", "[", "'seed'", "]", ")", "\n", "\n", "# Prepare root folders if necessary", "\n", "utils", ".", "prepare_root", "(", "config", ")", "\n", "\n", "# Setup cudnn.benchmark for free speed", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "# Import the model--this line allows us to dynamically select different files.", "\n", "model", "=", "__import__", "(", "config", "[", "'model'", "]", ")", "\n", "experiment_name", "=", "(", "config", "[", "'experiment_name'", "]", "if", "config", "[", "'experiment_name'", "]", "\n", "else", "utils", ".", "name_from_config", "(", "config", ")", ")", "\n", "print", "(", "'Experiment name is %s'", "%", "experiment_name", ")", "\n", "\n", "# Next, build the model", "\n", "G", "=", "model", ".", "Generator", "(", "**", "config", ")", ".", "to", "(", "device", ")", "\n", "D", "=", "model", ".", "Discriminator", "(", "**", "config", ")", ".", "to", "(", "device", ")", "\n", "\n", "# If using EMA, prepare it", "\n", "if", "config", "[", "'ema'", "]", ":", "\n", "        ", "print", "(", "'Preparing EMA for G with decay of {}'", ".", "format", "(", "\n", "config", "[", "'ema_decay'", "]", ")", ")", "\n", "G_ema", "=", "model", ".", "Generator", "(", "**", "{", "**", "config", ",", "'skip_init'", ":", "True", ",", "\n", "'no_optim'", ":", "True", "}", ")", ".", "to", "(", "device", ")", "\n", "ema", "=", "utils", ".", "ema", "(", "G", ",", "G_ema", ",", "config", "[", "'ema_decay'", "]", ",", "config", "[", "'ema_start'", "]", ")", "\n", "", "else", ":", "\n", "        ", "G_ema", ",", "ema", "=", "None", ",", "None", "\n", "\n", "# FP16?", "\n", "", "if", "config", "[", "'G_fp16'", "]", ":", "\n", "        ", "print", "(", "'Casting G to float16...'", ")", "\n", "G", "=", "G", ".", "half", "(", ")", "\n", "if", "config", "[", "'ema'", "]", ":", "\n", "            ", "G_ema", "=", "G_ema", ".", "half", "(", ")", "\n", "", "", "if", "config", "[", "'D_fp16'", "]", ":", "\n", "        ", "print", "(", "'Casting D to fp16...'", ")", "\n", "D", "=", "D", ".", "half", "(", ")", "\n", "# Consider automatically reducing SN_eps?", "\n", "", "GD", "=", "model", ".", "G_D", "(", "G", ",", "D", ",", "config", "[", "'conditional'", "]", ")", "# setting conditional to false", "\n", "print", "(", "G", ")", "\n", "print", "(", "D", ")", "\n", "print", "(", "'Number of params in G: {} D: {}'", ".", "format", "(", "\n", "*", "[", "sum", "(", "[", "p", ".", "data", ".", "nelement", "(", ")", "for", "p", "in", "net", ".", "parameters", "(", ")", "]", ")", "for", "net", "in", "[", "G", ",", "D", "]", "]", ")", ")", "\n", "# Prepare state dict, which holds things like epoch # and itr #", "\n", "state_dict", "=", "{", "'itr'", ":", "0", ",", "'epoch'", ":", "0", ",", "'save_num'", ":", "0", ",", "'save_best_num'", ":", "0", ",", "\n", "'best_IS'", ":", "0", ",", "'best_FID'", ":", "999999", ",", "'config'", ":", "config", "}", "\n", "\n", "# If loading from a pre-trained model, load weights", "\n", "if", "config", "[", "'resume'", "]", ":", "\n", "        ", "print", "(", "'Loading weights...'", ")", "\n", "utils", ".", "load_weights", "(", "G", ",", "D", ",", "state_dict", ",", "\n", "config", "[", "'weights_root'", "]", ",", "experiment_name", ",", "\n", "config", "[", "'load_weights'", "]", "if", "config", "[", "'load_weights'", "]", "else", "None", ",", "\n", "G_ema", "if", "config", "[", "'ema'", "]", "else", "None", ")", "\n", "\n", "# If parallel, parallelize the GD module", "\n", "", "if", "config", "[", "'parallel'", "]", ":", "\n", "        ", "GD", "=", "nn", ".", "DataParallel", "(", "GD", ")", "\n", "if", "config", "[", "'cross_replica'", "]", ":", "\n", "            ", "patch_replication_callback", "(", "GD", ")", "\n", "\n", "# Prepare loggers for stats; metrics holds test metrics,", "\n", "# lmetrics holds any desired training metrics.", "\n", "", "", "test_metrics_fname", "=", "'%s/%s_log.jsonl'", "%", "(", "config", "[", "'logs_root'", "]", ",", "\n", "experiment_name", ")", "\n", "train_metrics_fname", "=", "'%s/%s'", "%", "(", "config", "[", "'logs_root'", "]", ",", "experiment_name", ")", "\n", "print", "(", "'Inception Metrics will be saved to {}'", ".", "format", "(", "test_metrics_fname", ")", ")", "\n", "test_log", "=", "utils", ".", "MetricsLogger", "(", "test_metrics_fname", ",", "\n", "reinitialize", "=", "(", "not", "config", "[", "'resume'", "]", ")", ")", "\n", "print", "(", "'Training Metrics will be saved to {}'", ".", "format", "(", "train_metrics_fname", ")", ")", "\n", "train_log", "=", "utils", ".", "MyLogger", "(", "train_metrics_fname", ",", "\n", "reinitialize", "=", "(", "not", "config", "[", "'resume'", "]", ")", ",", "\n", "logstyle", "=", "config", "[", "'logstyle'", "]", ")", "\n", "# Write metadata", "\n", "utils", ".", "write_metadata", "(", "config", "[", "'logs_root'", "]", ",", "\n", "experiment_name", ",", "config", ",", "state_dict", ")", "\n", "# Prepare data; the Discriminator's batch size is all that needs to be passed", "\n", "# to the dataloader, as G doesn't require dataloading.", "\n", "# Note that at every loader iteration we pass in enough data to complete", "\n", "# a full D iteration (regardless of number of D steps and accumulations)", "\n", "D_batch_size", "=", "(", "config", "[", "'batch_size'", "]", "*", "config", "[", "'num_D_steps'", "]", "\n", "*", "config", "[", "'num_D_accumulations'", "]", ")", "\n", "loaders", "=", "utils", ".", "get_data_loaders", "(", "**", "{", "**", "config", ",", "'batch_size'", ":", "D_batch_size", ",", "\n", "'start_itr'", ":", "state_dict", "[", "'itr'", "]", "}", ")", "\n", "\n", "# Prepare inception metrics: FID and IS", "\n", "get_inception_metrics", "=", "inception_utils", ".", "prepare_inception_metrics", "(", "\n", "config", "[", "'dataset'", "]", ",", "config", "[", "'parallel'", "]", ",", "config", "[", "'no_fid'", "]", ")", "\n", "\n", "# Prepare noise and randomly sampled label arrays", "\n", "# Allow for different batch sizes in G", "\n", "G_batch_size", "=", "max", "(", "config", "[", "'G_batch_size'", "]", ",", "config", "[", "'batch_size'", "]", ")", "\n", "z_", ",", "y_", "=", "utils", ".", "prepare_z_y", "(", "G_batch_size", ",", "G", ".", "dim_z", ",", "config", "[", "'n_classes'", "]", ",", "\n", "device", "=", "device", ",", "fp16", "=", "config", "[", "'G_fp16'", "]", ")", "\n", "# Prepare a fixed z & y to see individual sample evolution throghout training", "\n", "fixed_z", ",", "fixed_y", "=", "utils", ".", "prepare_z_y", "(", "G_batch_size", ",", "G", ".", "dim_z", ",", "\n", "config", "[", "'n_classes'", "]", ",", "device", "=", "device", ",", "\n", "fp16", "=", "config", "[", "'G_fp16'", "]", ")", "\n", "fixed_z", ".", "sample_", "(", ")", "\n", "fixed_y", ".", "sample_", "(", ")", "\n", "\n", "if", "not", "config", "[", "'conditional'", "]", ":", "\n", "        ", "fixed_y", ".", "zero_", "(", ")", "\n", "y_", ".", "zero_", "(", ")", "\n", "# Loaders are loaded, prepare the training function", "\n", "", "if", "config", "[", "'which_train_fn'", "]", "==", "'GAN'", ":", "\n", "        ", "train", "=", "train_fns", ".", "GAN_training_function", "(", "G", ",", "D", ",", "GD", ",", "z_", ",", "y_", ",", "\n", "ema", ",", "state_dict", ",", "config", ")", "\n", "# Else, assume debugging and use the dummy train fn", "\n", "", "else", ":", "\n", "        ", "train", "=", "train_fns", ".", "dummy_training_function", "(", ")", "\n", "# Prepare Sample function for use with inception metrics", "\n", "", "sample", "=", "functools", ".", "partial", "(", "utils", ".", "sample", ",", "\n", "G", "=", "(", "G_ema", "if", "config", "[", "'ema'", "]", "and", "config", "[", "'use_ema'", "]", "\n", "else", "G", ")", ",", "\n", "z_", "=", "z_", ",", "y_", "=", "y_", ",", "config", "=", "config", ")", "\n", "\n", "print", "(", "'Beginning training at epoch %d...'", "%", "state_dict", "[", "'epoch'", "]", ")", "\n", "# Train for specified number of epochs, although we mostly track G iterations.", "\n", "for", "epoch", "in", "range", "(", "state_dict", "[", "'epoch'", "]", ",", "config", "[", "'num_epochs'", "]", ")", ":", "\n", "# Which progressbar to use? TQDM or my own?", "\n", "        ", "if", "config", "[", "'pbar'", "]", "==", "'mine'", ":", "\n", "            ", "pbar", "=", "utils", ".", "progress", "(", "\n", "loaders", "[", "0", "]", ",", "displaytype", "=", "'s1k'", "if", "config", "[", "'use_multiepoch_sampler'", "]", "else", "'eta'", ")", "\n", "", "else", ":", "\n", "            ", "pbar", "=", "tqdm", "(", "loaders", "[", "0", "]", ")", "\n", "", "for", "i", ",", "(", "x", ",", "y", ")", "in", "enumerate", "(", "pbar", ")", ":", "\n", "# Increment the iteration counter", "\n", "            ", "state_dict", "[", "'itr'", "]", "+=", "1", "\n", "# Make sure G and D are in training mode, just in case they got set to eval", "\n", "# For D, which typically doesn't have BN, this shouldn't matter much.", "\n", "G", ".", "train", "(", ")", "\n", "D", ".", "train", "(", ")", "\n", "if", "config", "[", "'ema'", "]", ":", "\n", "                ", "G_ema", ".", "train", "(", ")", "\n", "", "if", "config", "[", "'D_fp16'", "]", ":", "\n", "                ", "x", ",", "y", "=", "x", ".", "to", "(", "device", ")", ".", "half", "(", ")", ",", "y", ".", "to", "(", "device", ")", "\n", "", "else", ":", "\n", "                ", "x", ",", "y", "=", "x", ".", "to", "(", "device", ")", ",", "y", ".", "to", "(", "device", ")", "\n", "", "metrics", "=", "train", "(", "x", ",", "y", ")", "\n", "train_log", ".", "log", "(", "itr", "=", "int", "(", "state_dict", "[", "'itr'", "]", ")", ",", "**", "metrics", ")", "\n", "\n", "# Every sv_log_interval, log singular values", "\n", "if", "(", "config", "[", "'sv_log_interval'", "]", ">", "0", ")", "and", "(", "not", "(", "state_dict", "[", "'itr'", "]", "%", "config", "[", "'sv_log_interval'", "]", ")", ")", ":", "\n", "                ", "train_log", ".", "log", "(", "itr", "=", "int", "(", "state_dict", "[", "'itr'", "]", ")", ",", "\n", "**", "{", "**", "utils", ".", "get_SVs", "(", "G", ",", "'G'", ")", ",", "**", "utils", ".", "get_SVs", "(", "D", ",", "'D'", ")", "}", ")", "\n", "\n", "# If using my progbar, print metrics.", "\n", "", "if", "config", "[", "'pbar'", "]", "==", "'mine'", ":", "\n", "                ", "print", "(", "', '", ".", "join", "(", "[", "'itr: %d'", "%", "state_dict", "[", "'itr'", "]", "]", "\n", "+", "[", "'%s : %+4.3f'", "%", "(", "key", ",", "metrics", "[", "key", "]", ")", "\n", "for", "key", "in", "metrics", "]", ")", ",", "end", "=", "' '", ")", "\n", "\n", "# Save weights and copies as configured at specified interval", "\n", "", "if", "not", "(", "state_dict", "[", "'itr'", "]", "%", "config", "[", "'save_every'", "]", ")", ":", "\n", "                ", "if", "config", "[", "'G_eval_mode'", "]", ":", "\n", "                    ", "print", "(", "'Switchin G to eval mode...'", ")", "\n", "G", ".", "eval", "(", ")", "\n", "if", "config", "[", "'ema'", "]", ":", "\n", "                        ", "G_ema", ".", "eval", "(", ")", "\n", "", "", "train_fns", ".", "save_and_sample", "(", "G", ",", "D", ",", "G_ema", ",", "z_", ",", "y_", ",", "fixed_z", ",", "fixed_y", ",", "\n", "state_dict", ",", "config", ",", "experiment_name", ")", "\n", "\n", "# Test every specified interval", "\n", "# First load celeba moments", "\n", "", "data_moments", "=", "'fid_stats_cifar10_train.npz'", "\n", "experiment_name", "=", "(", "config", "[", "'experiment_name'", "]", "if", "config", "[", "'experiment_name'", "]", "\n", "else", "utils", ".", "name_from_config", "(", "config", ")", ")", "\n", "if", "(", "not", "(", "state_dict", "[", "'itr'", "]", "%", "config", "[", "'test_every'", "]", ")", ")", "and", "(", "epoch", ">=", "config", "[", "'start_eval'", "]", ")", ":", "\n", "                ", "if", "config", "[", "'G_eval_mode'", "]", ":", "\n", "                    ", "print", "(", "'Switchin G to eval mode...'", ")", "\n", "G", ".", "eval", "(", ")", "\n", "if", "config", "[", "'ema'", "]", ":", "\n", "                        ", "G_ema", ".", "eval", "(", ")", "\n", "# sampling images and saving to samples/experiments/epoch", "\n", "", "", "utils", ".", "sample_inception", "(", "\n", "G_ema", "if", "config", "[", "'ema'", "]", "and", "config", "[", "'use_ema'", "]", "else", "G", ",", "config", ",", "str", "(", "epoch", ")", ")", "\n", "# Get saved sample path", "\n", "folder_number", "=", "str", "(", "epoch", ")", "\n", "sample_moments", "=", "'%s/%s/%s/samples.npz'", "%", "(", "config", "[", "'samples_root'", "]", ",", "experiment_name", ",", "folder_number", ")", "\n", "# Calculate FID", "\n", "FID", "=", "fid_score", ".", "calculate_fid_given_paths", "(", "[", "data_moments", ",", "sample_moments", "]", ",", "\n", "batch_size", "=", "50", ",", "cuda", "=", "True", ",", "dims", "=", "2048", ")", "\n", "print", "(", "\"FID calculated\"", ")", "\n", "train_fns", ".", "update_FID", "(", "G", ",", "D", ",", "G_ema", ",", "state_dict", ",", "config", ",", "FID", ",", "experiment_name", ",", "test_log", ")", "\n", "# train_fns.test(G, D, G_ema, z_, y_, state_dict, config, sample,", "\n", "#                get_inception_metrics, experiment_name, test_log)", "\n", "# Increment epoch counter at end of epoch", "\n", "", "", "state_dict", "[", "'epoch'", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train.main": [[247, 253], ["utils.prepare_parser", "vars", "print", "train.run", "utils.prepare_parser.parse_args"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.prepare_parser", "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_aug.run"], ["", "", "def", "main", "(", ")", ":", "\n", "# parse command line and run", "\n", "    ", "parser", "=", "utils", ".", "prepare_parser", "(", ")", "\n", "config", "=", "vars", "(", "parser", ".", "parse_args", "(", ")", ")", "\n", "print", "(", "config", ")", "\n", "run", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.dummy_training_function": [[14, 18], ["None"], "function", ["None"], ["def", "dummy_training_function", "(", ")", ":", "\n", "    ", "def", "train", "(", "x", ",", "y", ")", ":", "\n", "        ", "return", "{", "}", "\n", "", "return", "train", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.select_loss": [[20, 39], ["ValueError"], "function", ["None"], ["", "def", "select_loss", "(", "config", ")", ":", "\n", "    ", "if", "config", "[", "'loss_type'", "]", "==", "'hinge'", ":", "\n", "        ", "return", "losses", ".", "loss_hinge_dis_new", ",", "losses", ".", "loss_hinge_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'kl'", ":", "\n", "        ", "return", "losses", ".", "loss_kl_dis", ",", "losses", ".", "loss_kl_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'kl_gen'", ":", "\n", "        ", "return", "losses", ".", "loss_hinge_dis", ",", "losses", ".", "loss_kl_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'kl_dis'", ":", "\n", "        ", "return", "losses", ".", "loss_kl_dis", ",", "losses", ".", "loss_hinge_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'kl_grad'", ":", "\n", "        ", "return", "losses", ".", "loss_kl_grad_dis", ",", "losses", ".", "loss_kl_grad_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'f_kl'", ":", "\n", "        ", "return", "losses", ".", "loss_f_kl_dis", ",", "losses", ".", "loss_f_kl_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'chi2'", ":", "\n", "        ", "return", "losses", ".", "loss_chi_dis", ",", "losses", ".", "loss_chi_gen", "\n", "", "elif", "config", "[", "'loss_type'", "]", "==", "'dv'", ":", "\n", "        ", "return", "losses", ".", "loss_dv_dis", ",", "losses", ".", "loss_dv_gen", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'loss not defined'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.GAN_training_function": [[41, 150], ["train_fns_new.select_loss", "G.optim.zero_grad", "D.optim.zero_grad", "torch.split", "torch.split", "torch.split", "torch.split", "range", "G.optim.zero_grad", "range", "G.optim.step", "utils.toggle_grad", "utils.toggle_grad", "D.optim.zero_grad", "range", "D.optim.step", "utils.toggle_grad", "utils.toggle_grad", "z_.sample_", "y_.sample_", "GD", "G_loss.backward", "print", "utils.ortho", "ema.update", "float", "float", "float", "z_.sample_", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.stack", "torch.stack", "range", "torch.split", "torch.split", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "GD", "discriminator_loss", "D_loss.backward", "print", "utils.ortho", "y_.zero_", "generator_loss", "float", "G_loss.item", "D_loss_real.item", "D_loss_fake.item", "y_.zero_", "torch.zeros_like().to().long", "torch.zeros_like().to().long", "y_.sample_", "real_samples.size", "real_samples.size", "int", "int", "int", "float", "torch.split.size", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.zeros_like().to", "torch.zeros_like().to", "G.shared.parameters", "torch.randperm", "torch.randperm", "torch.zeros_like", "torch.zeros_like"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.select_loss", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Adam16.step", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.toggle_grad", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.toggle_grad", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Adam16.step", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.toggle_grad", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.toggle_grad", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.ortho", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.ema.update", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.ortho", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to"], ["", "", "def", "GAN_training_function", "(", "G", ",", "D", ",", "GD", ",", "z_", ",", "y_", ",", "ema", ",", "state_dict", ",", "config", ")", ":", "\n", "    ", "discriminator_loss", ",", "generator_loss", "=", "select_loss", "(", "config", ")", "\n", "\n", "def", "train", "(", "x", ",", "y", ")", ":", "\n", "        ", "G", ".", "optim", ".", "zero_grad", "(", ")", "\n", "D", ".", "optim", ".", "zero_grad", "(", ")", "\n", "# How many chunks to split x and y into?", "\n", "x", "=", "torch", ".", "split", "(", "x", ",", "config", "[", "'batch_size'", "]", ")", "\n", "y", "=", "torch", ".", "split", "(", "y", ",", "config", "[", "'batch_size'", "]", ")", "\n", "counter", "=", "0", "\n", "\n", "# Optionally toggle D and G's \"require_grad\"", "\n", "if", "config", "[", "'toggle_grads'", "]", ":", "\n", "            ", "utils", ".", "toggle_grad", "(", "D", ",", "True", ")", "\n", "utils", ".", "toggle_grad", "(", "G", ",", "False", ")", "\n", "\n", "", "for", "step_index", "in", "range", "(", "config", "[", "'num_D_steps'", "]", ")", ":", "\n", "# If accumulating gradients, loop multiple times before an optimizer step", "\n", "            ", "D", ".", "optim", ".", "zero_grad", "(", ")", "\n", "for", "accumulation_index", "in", "range", "(", "config", "[", "'num_D_accumulations'", "]", ")", ":", "\n", "                ", "z_", ".", "sample_", "(", ")", "\n", "if", "not", "config", "[", "'conditional'", "]", ":", "\n", "# only feed in 0's for y if \"unconditional\"", "\n", "                    ", "y_", ".", "zero_", "(", ")", "\n", "y_counter", "=", "torch", ".", "zeros_like", "(", "y", "[", "counter", "]", ")", ".", "to", "(", "y_", ".", "device", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "                    ", "y_", ".", "sample_", "(", ")", "\n", "y_counter", "=", "y", "[", "counter", "]", "\n", "", "real_samples", "=", "x", "[", "counter", "]", "\n", "actual_h", "=", "real_samples", ".", "size", "(", ")", "[", "2", "]", "\n", "actual_w", "=", "real_samples", ".", "size", "(", ")", "[", "3", "]", "\n", "h1", ",", "h2", "=", "torch", ".", "split", "(", "real_samples", ",", "int", "(", "actual_h", "/", "2", ")", ",", "dim", "=", "2", ")", "\n", "split1", ",", "split2", "=", "torch", ".", "split", "(", "h1", ",", "int", "(", "actual_w", "/", "2", ")", ",", "dim", "=", "3", ")", "\n", "split3", ",", "split4", "=", "torch", ".", "split", "(", "h2", ",", "int", "(", "actual_w", "/", "2", ")", ",", "dim", "=", "3", ")", "\n", "splits", "=", "[", "split1", ",", "split2", ",", "split3", ",", "split4", "]", "\n", "fake_samples", "=", "torch", ".", "stack", "(", "splits", ",", "-", "1", ")", "\n", "for", "idx", "in", "range", "(", "fake_samples", ".", "size", "(", ")", "[", "0", "]", ")", ":", "\n", "                    ", "fake_samples", "[", "idx", "]", "=", "fake_samples", "[", "idx", ",", ":", ",", ":", ",", ":", ",", "torch", ".", "randperm", "(", "4", ")", "]", "\n", "", "fake_samples", "=", "torch", ".", "split", "(", "fake_samples", ",", "1", ",", "dim", "=", "4", ")", "\n", "new_split1", "=", "torch", ".", "cat", "(", "(", "torch", ".", "squeeze", "(", "fake_samples", "[", "0", "]", ",", "-", "1", ")", ",", "torch", ".", "squeeze", "(", "fake_samples", "[", "1", "]", ",", "-", "1", ")", ")", ",", "2", ")", "\n", "new_split2", "=", "torch", ".", "cat", "(", "(", "torch", ".", "squeeze", "(", "fake_samples", "[", "2", "]", ",", "-", "1", ")", ",", "torch", ".", "squeeze", "(", "fake_samples", "[", "3", "]", ",", "-", "1", ")", ")", ",", "2", ")", "\n", "real_fake_samples", "=", "torch", ".", "cat", "(", "(", "new_split1", ",", "new_split2", ")", ",", "3", ")", "\n", "\n", "D_fake", ",", "D_real", ",", "D_real_fake", "=", "GD", "(", "z_", "[", ":", "config", "[", "'batch_size'", "]", "]", ",", "y_", "[", ":", "config", "[", "'batch_size'", "]", "]", ",", "real_samples", ",", "real_fake_samples", ",", "\n", "y_counter", ",", "train_G", "=", "False", ",", "split_D", "=", "config", "[", "'split_D'", "]", ")", "\n", "# y_.sample_()", "\n", "# D_fake, D_real = GD(z_[:config['batch_size']], y_[:config['batch_size']],", "\n", "#                     x[counter], y[counter], train_G=False,", "\n", "#                     split_D=config['split_D'])", "\n", "# Compute components of D's loss, average them, and divide by", "\n", "# the number of gradient accumulations", "\n", "# if D_fake.max().item() - D_fake.min().item() > 30:", "\n", "# import ipdb", "\n", "# ipdb.set_trace()", "\n", "\n", "D_loss_real", ",", "D_loss_fake", ",", "D_loss_real_fake", "=", "discriminator_loss", "(", "\n", "D_fake", ",", "D_real", ",", "D_real_fake", ")", "\n", "D_loss", "=", "(", "D_loss_real", "+", "D_loss_fake", "+", "D_loss_real_fake", ")", "/", "float", "(", "config", "[", "'num_D_accumulations'", "]", ")", "\n", "\n", "D_loss", ".", "backward", "(", ")", "\n", "counter", "+=", "1", "\n", "\n", "# Optionally apply ortho reg in D", "\n", "", "if", "config", "[", "'D_ortho'", "]", ">", "0.0", ":", "\n", "# Debug print to indicate we're using ortho reg in D.", "\n", "                ", "print", "(", "'using modified ortho reg in D'", ")", "\n", "utils", ".", "ortho", "(", "D", ",", "config", "[", "'D_ortho'", "]", ")", "\n", "\n", "", "D", ".", "optim", ".", "step", "(", ")", "\n", "\n", "# Optionally toggle \"requires_grad\"", "\n", "", "if", "config", "[", "'toggle_grads'", "]", ":", "\n", "            ", "utils", ".", "toggle_grad", "(", "D", ",", "False", ")", "\n", "utils", ".", "toggle_grad", "(", "G", ",", "True", ")", "\n", "\n", "# Zero G's gradients by default before training G, for safety", "\n", "", "G", ".", "optim", ".", "zero_grad", "(", ")", "\n", "\n", "# If accumulating gradients, loop multiple times", "\n", "for", "accumulation_index", "in", "range", "(", "config", "[", "'num_G_accumulations'", "]", ")", ":", "\n", "            ", "z_", ".", "sample_", "(", ")", "\n", "y_", ".", "sample_", "(", ")", "\n", "if", "not", "config", "[", "'conditional'", "]", ":", "\n", "                ", "y_", ".", "zero_", "(", ")", "\n", "", "D_fake", "=", "GD", "(", "z_", ",", "y_", ",", "train_G", "=", "True", ",", "split_D", "=", "config", "[", "'split_D'", "]", ")", "\n", "G_loss", "=", "generator_loss", "(", "\n", "D_fake", ")", "/", "float", "(", "config", "[", "'num_G_accumulations'", "]", ")", "\n", "G_loss", ".", "backward", "(", ")", "\n", "\n", "# Optionally apply modified ortho reg in G", "\n", "", "if", "config", "[", "'G_ortho'", "]", ">", "0.0", ":", "\n", "# Debug print to indicate we're using ortho reg in G", "\n", "            ", "print", "(", "'using modified ortho reg in G'", ")", "\n", "# Don't ortho reg shared, it makes no sense. Really we should blacklist any embeddings for this", "\n", "utils", ".", "ortho", "(", "G", ",", "config", "[", "'G_ortho'", "]", ",", "\n", "blacklist", "=", "[", "param", "for", "param", "in", "G", ".", "shared", ".", "parameters", "(", ")", "]", ")", "\n", "", "G", ".", "optim", ".", "step", "(", ")", "\n", "\n", "# If we have an ema, update it, regardless of if we test with it or not", "\n", "if", "config", "[", "'ema'", "]", ":", "\n", "            ", "ema", ".", "update", "(", "state_dict", "[", "'itr'", "]", ")", "\n", "\n", "", "out", "=", "{", "'G_loss'", ":", "float", "(", "G_loss", ".", "item", "(", ")", ")", ",", "\n", "'D_loss_real'", ":", "float", "(", "D_loss_real", ".", "item", "(", ")", ")", ",", "\n", "'D_loss_fake'", ":", "float", "(", "D_loss_fake", ".", "item", "(", ")", ")", "}", "\n", "# Return G's loss and the components of D's loss.", "\n", "return", "out", "\n", "", "return", "train", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.GAN_log_function": [[157, 214], ["np.transpose", "int", "torch.zeros().to().long", "torch.zeros().to().long", "range", "np.array", "print", "np.save", "np.load", "math.ceil", "torch.from_numpy().float", "torch.from_numpy().float", "test_data.to.to", "GD", "np.squeeze", "np.array.extend", "print", "np.min", "np.max", "torch.zeros().to", "torch.zeros().to", "D_real.cpu().data.numpy", "len", "torch.from_numpy", "torch.from_numpy", "torch.zeros", "torch.zeros", "D_real.cpu"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to"], ["def", "GAN_log_function", "(", "G", ",", "D", ",", "GD", ",", "z_", ",", "y_", ",", "ema", ",", "state_dict", ",", "config", ")", ":", "\n", "    ", "import", "numpy", "as", "np", "\n", "import", "math", "\n", "discriminator_loss", "=", "losses", ".", "loss_hinge_analysis", "\n", "\n", "def", "train", "(", ")", ":", "\n", "\n", "        ", "corrupt_dict", "=", "{", "'elastic'", ":", "'elastic_transform'", ",", "'jpeg'", ":", "'jpeg_compression'", ",", "'speckle'", ":", "'speckle_noise'", ",", "'gaussian'", ":", "'gaussian_noise'", ",", "\n", "'blur'", ":", "'gaussian_blur'", ",", "\n", "'zoom'", ":", "'zoom_blur'", ",", "'brightness'", ":", "'brightness'", ",", "'contrast'", ":", "'contrast'", ",", "'defocus'", ":", "'defocus_blur'", ",", "\n", "'fog'", ":", "'fog'", ",", "'frost'", ":", "'frost'", ",", "'glass'", ":", "'glass_blur'", ",", "'impulse'", ":", "'impulse_noise'", ",", "'motion'", ":", "'motion_blur'", ",", "\n", "'pixelate'", ":", "'pixelate'", ",", "'saturate'", ":", "'saturate'", ",", "'shot'", ":", "'shot_noise'", ",", "'snow'", ":", "'snow'", ",", "'spatter'", ":", "'spatter'", ",", "\n", "'train'", ":", "'train_samples'", ",", "'test'", ":", "'test_samples'", "\n", "}", "\n", "base_dir", "=", "\"../mintnet/CIFAR-10-C/\"", "\n", "for", "mode", "in", "corrupt_dict", ":", "\n", "\n", "# test_batch = np.transpose(np.load(\"../mintnet/CIFAR-10-C/elastic_transform.npy\"), (0, 3, 1, 2))[-10000:]", "\n", "            ", "test_batch", "=", "np", ".", "transpose", "(", "np", ".", "load", "(", "base_dir", "+", "corrupt_dict", "[", "mode", "]", "+", "\".npy\"", ")", ",", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "\n", "batch_size", "=", "50", "\n", "test_iters", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "test_batch", ")", "/", "batch_size", ")", ")", "\n", "logp", "=", "[", "]", "\n", "y_counter", "=", "torch", ".", "zeros", "(", "batch_size", ")", ".", "to", "(", "\"cuda\"", ")", ".", "long", "(", ")", "\n", "losses", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "test_iters", ")", ":", "\n", "                ", "data_batch", "=", "test_batch", "[", "idx", "*", "batch_size", ":", "(", "idx", "+", "1", ")", "*", "batch_size", "]", "\n", "test_data", "=", "torch", ".", "from_numpy", "(", "data_batch", ")", ".", "float", "(", ")", "\n", "test_data", "=", "test_data", ".", "to", "(", "\"cuda\"", ")", "\n", "\n", "data", "=", "test_data", "/", "255.0", "\n", "\n", "D_fake", ",", "D_real", "=", "GD", "(", "z_", "[", ":", "config", "[", "'batch_size'", "]", "]", ",", "y_", "[", ":", "config", "[", "'batch_size'", "]", "]", ",", "data", ",", "\n", "y_counter", ",", "train_G", "=", "False", ",", "split_D", "=", "config", "[", "'split_D'", "]", ")", "\n", "\n", "#D_loss_real = discriminator_loss(", "\n", "#        D_real)", "\n", "\n", "#D_loss_real_np = np.squeeze(D_loss_real.cpu().data.numpy(), -1) ", "\n", "D_real_np", "=", "np", ".", "squeeze", "(", "D_real", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "-", "1", ")", "\n", "\n", "logp", ".", "extend", "(", "D_real_np", ")", "\n", "#losses.extend(D_loss_real_np)", "\n", "print", "(", "\"%d iters reached\"", "%", "idx", ")", "\n", "\n", "\n", "", "logp", "=", "np", ".", "array", "(", "logp", ")", "\n", "#losses = np.array(losses)", "\n", "# print(np.min(cleaned_data), np.max(cleaned_data), cleaned_data.shape)", "\n", "# np.save(\"corruption/elastic_pgd.npy\", cleaned_data)", "\n", "print", "(", "\"logp calculation done for the corruption \"", ",", "mode", ",", "\" and the shape of data is \"", ",", "logp", ".", "shape", ",", "\" min is \"", ",", "np", ".", "min", "(", "logp", ")", ",", "\n", "\" max is \"", ",", "np", ".", "max", "(", "logp", ")", ")", "\n", "np", ".", "save", "(", "\"corruption_new/\"", "+", "mode", "+", "\"_logp.npy\"", ",", "logp", ")", "\n", "#np.save(\"corruption/temp.npy\", losses)", "\n", "#break", "\n", "\n", "\n", "", "", "return", "train", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.save_and_sample": [[215, 275], ["utils.save_weights", "torchvision.utils.save_image", "utils.sample_sheet", "zip", "utils.save_weights", "utils.accumulate_standing_stats", "torch.no_grad", "torch.no_grad", "os.path.isdir", "os.mkdir", "which_G.float().cpu", "utils.interp_sheet", "y_.zero_", "torch.parallel.data_parallel", "which_G", "int", "which_G.shared", "which_G.float", "which_G.shared"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.save_weights", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.sample_sheet", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.save_weights", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.accumulate_standing_stats", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.interp_sheet"], ["", "def", "save_and_sample", "(", "G", ",", "D", ",", "G_ema", ",", "z_", ",", "y_", ",", "fixed_z", ",", "fixed_y", ",", "\n", "state_dict", ",", "config", ",", "experiment_name", ")", ":", "\n", "    ", "utils", ".", "save_weights", "(", "G", ",", "D", ",", "state_dict", ",", "config", "[", "'weights_root'", "]", ",", "\n", "experiment_name", ",", "None", ",", "G_ema", "if", "config", "[", "'ema'", "]", "else", "None", ")", "\n", "# Save an additional copy to mitigate accidental corruption if process", "\n", "# is killed during a save (it's happened to me before -.-)", "\n", "if", "config", "[", "'num_save_copies'", "]", ">", "0", ":", "\n", "        ", "utils", ".", "save_weights", "(", "G", ",", "D", ",", "state_dict", ",", "config", "[", "'weights_root'", "]", ",", "\n", "experiment_name", ",", "\n", "'copy%d'", "%", "state_dict", "[", "'save_num'", "]", ",", "\n", "G_ema", "if", "config", "[", "'ema'", "]", "else", "None", ")", "\n", "state_dict", "[", "'save_num'", "]", "=", "(", "\n", "state_dict", "[", "'save_num'", "]", "+", "1", ")", "%", "config", "[", "'num_save_copies'", "]", "\n", "\n", "# Use EMA G for samples or non-EMA?", "\n", "", "which_G", "=", "G_ema", "if", "config", "[", "'ema'", "]", "and", "config", "[", "'use_ema'", "]", "else", "G", "\n", "\n", "# Accumulate standing statistics?", "\n", "if", "config", "[", "'accumulate_stats'", "]", ":", "\n", "        ", "if", "not", "config", "[", "'conditional'", "]", ":", "\n", "            ", "y_", ".", "zero_", "(", ")", "\n", "", "utils", ".", "accumulate_standing_stats", "(", "G_ema", "if", "config", "[", "'ema'", "]", "and", "config", "[", "'use_ema'", "]", "else", "G", ",", "\n", "z_", ",", "y_", ",", "config", "[", "'n_classes'", "]", ",", "\n", "config", "[", "'num_standing_accumulations'", "]", ")", "\n", "\n", "# Save a random sample sheet with fixed z and y", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "if", "config", "[", "'parallel'", "]", ":", "\n", "            ", "fixed_Gz", "=", "nn", ".", "parallel", ".", "data_parallel", "(", "\n", "which_G", ",", "(", "fixed_z", ",", "which_G", ".", "shared", "(", "fixed_y", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "fixed_Gz", "=", "which_G", "(", "fixed_z", ",", "which_G", ".", "shared", "(", "fixed_y", ")", ")", "\n", "", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "'%s/%s'", "%", "(", "config", "[", "'samples_root'", "]", ",", "experiment_name", ")", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "'%s/%s'", "%", "(", "config", "[", "'samples_root'", "]", ",", "experiment_name", ")", ")", "\n", "", "image_filename", "=", "'%s/%s/fixed_samples%d.jpg'", "%", "(", "config", "[", "'samples_root'", "]", ",", "\n", "experiment_name", ",", "\n", "state_dict", "[", "'itr'", "]", ")", "\n", "torchvision", ".", "utils", ".", "save_image", "(", "fixed_Gz", ".", "float", "(", ")", ".", "cpu", "(", ")", ",", "image_filename", ",", "\n", "nrow", "=", "int", "(", "fixed_Gz", ".", "shape", "[", "0", "]", "**", "0.5", ")", ",", "normalize", "=", "True", ")", "\n", "# For now, every time we save, also save sample sheets", "\n", "utils", ".", "sample_sheet", "(", "which_G", ",", "\n", "classes_per_sheet", "=", "utils", ".", "classes_per_sheet_dict", "[", "config", "[", "'dataset'", "]", "]", ",", "\n", "num_classes", "=", "config", "[", "'n_classes'", "]", ",", "\n", "samples_per_class", "=", "10", ",", "parallel", "=", "config", "[", "'parallel'", "]", ",", "\n", "samples_root", "=", "config", "[", "'samples_root'", "]", ",", "\n", "experiment_name", "=", "experiment_name", ",", "\n", "folder_number", "=", "state_dict", "[", "'itr'", "]", ",", "\n", "z_", "=", "z_", ")", "\n", "# Also save interp sheets", "\n", "for", "fix_z", ",", "fix_y", "in", "zip", "(", "[", "False", ",", "False", ",", "True", "]", ",", "[", "False", ",", "True", ",", "False", "]", ")", ":", "\n", "        ", "utils", ".", "interp_sheet", "(", "which_G", ",", "\n", "num_per_sheet", "=", "16", ",", "\n", "num_midpoints", "=", "8", ",", "\n", "num_classes", "=", "config", "[", "'n_classes'", "]", ",", "\n", "parallel", "=", "config", "[", "'parallel'", "]", ",", "\n", "samples_root", "=", "config", "[", "'samples_root'", "]", ",", "\n", "experiment_name", "=", "experiment_name", ",", "\n", "folder_number", "=", "state_dict", "[", "'itr'", "]", ",", "\n", "sheet_number", "=", "0", ",", "\n", "fix_z", "=", "fix_z", ",", "fix_y", "=", "fix_y", ",", "device", "=", "'cuda'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.test": [[282, 334], ["print", "ResNet18", "clf.to.load_state_dict", "clf.to.to", "clf.to.eval", "train_fns_new.classify_examples", "utils.fairness_discrepancy", "print", "print", "get_inception_metrics", "print", "max", "min", "min", "test_log.log", "torch.cuda.is_available", "torch.cuda.is_available", "utils.accumulate_standing_stats", "print", "utils.save_weights", "torch.load", "torch.load", "int", "float", "float", "float"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Adam16.load_state_dict", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.classify_examples", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.fairness_discrepancy", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MyLogger.log", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.accumulate_standing_stats", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.save_weights"], ["def", "test", "(", "G", ",", "D", ",", "G_ema", ",", "z_", ",", "y_", ",", "state_dict", ",", "config", ",", "sample", ",", "get_inception_metrics", ",", "\n", "experiment_name", ",", "test_log", ")", ":", "\n", "    ", "\"\"\"\n    Saving the appropriate metrics for sample quality (FID) and level of bias\n    \"\"\"", "\n", "print", "(", "'Pre-loading pre-trained attribute classifier...'", ")", "\n", "if", "config", "[", "'n_classes'", "]", "==", "2", ":", "\n", "        ", "clf_state_dict", "=", "torch", ".", "load", "(", "CLF_PATH", ")", "[", "'state_dict'", "]", "\n", "", "else", ":", "\n", "# multi-attribute", "\n", "        ", "raise", "NotImplementedError", "\n", "# load attribute classifier here", "\n", "", "clf", "=", "ResNet18", "(", "block", "=", "BasicBlock", ",", "layers", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "num_classes", "=", "config", "[", "'n_classes'", "]", ",", "grayscale", "=", "False", ")", "\n", "clf", ".", "load_state_dict", "(", "clf_state_dict", ")", "\n", "device", "=", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", "\n", "clf", "=", "clf", ".", "to", "(", "device", ")", "\n", "clf", ".", "eval", "(", ")", "# turn off batch norm", "\n", "\n", "# obtain classifier predictions for samples", "\n", "preds", "=", "classify_examples", "(", "clf", ",", "config", ")", "# (10K,)", "\n", "fair_d", "=", "utils", ".", "fairness_discrepancy", "(", "preds", ",", "config", "[", "'n_classes'", "]", ")", "\n", "print", "(", "'Fairness discrepancy metric is: {}'", ".", "format", "(", "fair_d", ")", ")", "\n", "\n", "print", "(", "'Gathering inception metrics...'", ")", "\n", "if", "config", "[", "'accumulate_stats'", "]", ":", "\n", "        ", "utils", ".", "accumulate_standing_stats", "(", "G_ema", "if", "config", "[", "'ema'", "]", "and", "config", "[", "'use_ema'", "]", "else", "G", ",", "\n", "z_", ",", "y_", ",", "config", "[", "'n_classes'", "]", ",", "\n", "config", "[", "'num_standing_accumulations'", "]", ")", "\n", "", "IS_mean", ",", "IS_std", ",", "FID", "=", "get_inception_metrics", "(", "sample", ",", "\n", "config", "[", "'num_inception_images'", "]", ",", "\n", "num_splits", "=", "10", ")", "\n", "print", "(", "'Itr %d: PYTORCH UNOFFICIAL Inception Score is %3.3f +/- %3.3f, PYTORCH UNOFFICIAL FID is %5.4f'", "%", "\n", "(", "state_dict", "[", "'itr'", "]", ",", "IS_mean", ",", "IS_std", ",", "FID", ")", ")", "\n", "# If improved over previous best metric, save approrpiate copy", "\n", "if", "(", "(", "config", "[", "'which_best'", "]", "==", "'IS'", "and", "IS_mean", ">", "state_dict", "[", "'best_IS'", "]", ")", "\n", "or", "(", "config", "[", "'which_best'", "]", "==", "'FID'", "and", "FID", "<", "state_dict", "[", "'best_FID'", "]", ")", "\n", "or", "(", "config", "[", "'which_best'", "]", "==", "'fair'", "and", "fair_d", "<", "state_dict", "[", "'best_fair_d'", "]", ")", "\n", ")", ":", "\n", "        ", "print", "(", "'%s improved over previous best, saving checkpoint...'", "%", "\n", "config", "[", "'which_best'", "]", ")", "\n", "utils", ".", "save_weights", "(", "G", ",", "D", ",", "state_dict", ",", "config", "[", "'weights_root'", "]", ",", "\n", "experiment_name", ",", "'best%d'", "%", "state_dict", "[", "'save_best_num'", "]", ",", "\n", "G_ema", "if", "config", "[", "'ema'", "]", "else", "None", ")", "\n", "state_dict", "[", "'save_best_num'", "]", "=", "(", "\n", "state_dict", "[", "'save_best_num'", "]", "+", "1", ")", "%", "config", "[", "'num_best_copies'", "]", "\n", "", "state_dict", "[", "'best_IS'", "]", "=", "max", "(", "state_dict", "[", "'best_IS'", "]", ",", "IS_mean", ")", "\n", "state_dict", "[", "'best_FID'", "]", "=", "min", "(", "state_dict", "[", "'best_FID'", "]", ",", "FID", ")", "\n", "state_dict", "[", "'best_fair_d'", "]", "=", "min", "(", "state_dict", "[", "'best_fair_d'", "]", ",", "fair_d", ")", "\n", "# Log results to file", "\n", "test_log", ".", "log", "(", "itr", "=", "int", "(", "state_dict", "[", "'itr'", "]", ")", ",", "IS_mean", "=", "float", "(", "IS_mean", ")", ",", "\n", "IS_std", "=", "float", "(", "IS_std", ")", ",", "FID", "=", "float", "(", "FID", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.update_FID": [[335, 352], ["print", "min", "test_log.log", "print", "utils.save_weights", "int", "float", "float", "float"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MyLogger.log", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.save_weights"], ["", "def", "update_FID", "(", "G", ",", "D", ",", "G_ema", ",", "state_dict", ",", "config", ",", "FID", ",", "experiment_name", ",", "test_log", ")", ":", "\n", "    ", "print", "(", "'Itr %d: PYTORCH UNOFFICIAL FID is %5.4f'", "%", "\n", "(", "state_dict", "[", "'itr'", "]", ",", "FID", ")", ")", "\n", "# If improved over previous best metric, save approrpiate copy", "\n", "if", "(", "(", "config", "[", "'which_best'", "]", "==", "'IS'", "and", "IS_mean", ">", "state_dict", "[", "'best_IS'", "]", ")", "\n", "or", "(", "config", "[", "'which_best'", "]", "==", "'FID'", "and", "FID", "<", "state_dict", "[", "'best_FID'", "]", ")", ")", ":", "\n", "        ", "print", "(", "'%s improved over previous best, saving checkpoint...'", "%", "\n", "config", "[", "'which_best'", "]", ")", "\n", "utils", ".", "save_weights", "(", "G", ",", "D", ",", "state_dict", ",", "config", "[", "'weights_root'", "]", ",", "\n", "experiment_name", ",", "'best%d'", "%", "state_dict", "[", "'save_best_num'", "]", ",", "\n", "G_ema", "if", "config", "[", "'ema'", "]", "else", "None", ")", "\n", "state_dict", "[", "'save_best_num'", "]", "=", "(", "\n", "state_dict", "[", "'save_best_num'", "]", "+", "1", ")", "%", "config", "[", "'num_best_copies'", "]", "\n", "", "state_dict", "[", "'best_FID'", "]", "=", "min", "(", "state_dict", "[", "'best_FID'", "]", ",", "FID", ")", "\n", "# Log results to file", "\n", "test_log", ".", "log", "(", "itr", "=", "int", "(", "state_dict", "[", "'itr'", "]", ")", ",", "IS_mean", "=", "float", "(", "0", ")", ",", "\n", "IS_std", "=", "float", "(", "0", ")", ",", "FID", "=", "float", "(", "FID", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.classify_examples": [[353, 377], ["model.eval", "np.load", "torch.no_grad", "torch.no_grad", "range", "torch.cat().data.cpu().numpy", "torch.cat().data.cpu().numpy", "torch.from_numpy().to().float", "torch.from_numpy().to().float", "model", "torch.max", "torch.max", "torch.cat().data.cpu().numpy.append", "torch.cat().data.cpu", "torch.cat().data.cpu", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy", "torch.from_numpy", "torch.cat", "torch.cat"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to"], ["", "def", "classify_examples", "(", "model", ",", "config", ")", ":", "\n", "    ", "\"\"\"\n    classifies generated samples into appropriate classes \n    \"\"\"", "\n", "import", "numpy", "as", "np", "\n", "model", ".", "eval", "(", ")", "\n", "preds", "=", "[", "]", "\n", "samples", "=", "np", ".", "load", "(", "config", "[", "'sample_path'", "]", ")", "[", "'x'", "]", "\n", "n_batches", "=", "samples", ".", "shape", "[", "0", "]", "//", "1000", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# generate 10K samples", "\n", "        ", "for", "i", "in", "range", "(", "n_batches", ")", ":", "\n", "            ", "x", "=", "samples", "[", "i", "*", "1000", ":", "(", "i", "+", "1", ")", "*", "1000", "]", "\n", "samp", "=", "x", "/", "255.", "# renormalize to feed into classifier", "\n", "samp", "=", "torch", ".", "from_numpy", "(", "samp", ")", ".", "to", "(", "'cuda'", ")", ".", "float", "(", ")", "\n", "\n", "# get classifier predictions", "\n", "logits", ",", "probas", "=", "model", "(", "samp", ")", "\n", "_", ",", "pred", "=", "torch", ".", "max", "(", "probas", ",", "1", ")", "\n", "preds", ".", "append", "(", "pred", ")", "\n", "", "preds", "=", "torch", ".", "cat", "(", "preds", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "return", "preds", "\n", "", ""]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.identity.forward": [[55, 57], ["None"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "input", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.SN.__init__": [[61, 74], ["range", "layers.SN.register_buffer", "layers.SN.register_buffer", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "num_svs", ",", "num_itrs", ",", "num_outputs", ",", "transpose", "=", "False", ",", "eps", "=", "1e-12", ")", ":", "\n", "# Number of power iterations per step", "\n", "        ", "self", ".", "num_itrs", "=", "num_itrs", "\n", "# Number of singular values", "\n", "self", ".", "num_svs", "=", "num_svs", "\n", "# Transposed?", "\n", "self", ".", "transpose", "=", "transpose", "\n", "# Epsilon value for avoiding divide-by-0", "\n", "self", ".", "eps", "=", "eps", "\n", "# Register a singular vector for each sv", "\n", "for", "i", "in", "range", "(", "self", ".", "num_svs", ")", ":", "\n", "            ", "self", ".", "register_buffer", "(", "'u%d'", "%", "i", ",", "torch", ".", "randn", "(", "1", ",", "num_outputs", ")", ")", "\n", "self", ".", "register_buffer", "(", "'sv%d'", "%", "i", ",", "torch", ".", "ones", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.SN.u": [[76, 79], ["getattr", "range"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "u", "(", "self", ")", ":", "\n", "        ", "return", "[", "getattr", "(", "self", ",", "'u%d'", "%", "i", ")", "for", "i", "in", "range", "(", "self", ".", "num_svs", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.SN.sv": [[82, 85], ["getattr", "range"], "methods", ["None"], ["", "@", "property", "\n", "def", "sv", "(", "self", ")", ":", "\n", "        ", "return", "[", "getattr", "(", "self", ",", "'sv%d'", "%", "i", ")", "for", "i", "in", "range", "(", "self", ".", "num_svs", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.SN.W_": [[87, 101], ["layers.SN.weight.view", "range", "layers.SN.weight.size", "W_mat.t.t.t", "layers.power_iteration", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.power_iteration"], ["", "def", "W_", "(", "self", ")", ":", "\n", "        ", "W_mat", "=", "self", ".", "weight", ".", "view", "(", "self", ".", "weight", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "if", "self", ".", "transpose", ":", "\n", "            ", "W_mat", "=", "W_mat", ".", "t", "(", ")", "\n", "# Apply num_itrs power iterations", "\n", "", "for", "_", "in", "range", "(", "self", ".", "num_itrs", ")", ":", "\n", "            ", "svs", ",", "us", ",", "vs", "=", "power_iteration", "(", "\n", "W_mat", ",", "self", ".", "u", ",", "update", "=", "self", ".", "training", ",", "eps", "=", "self", ".", "eps", ")", "\n", "# Update the svs", "\n", "", "if", "self", ".", "training", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "# Make sure to do this in a no_grad() context or you'll get memory leaks!", "\n", "                ", "for", "i", ",", "sv", "in", "enumerate", "(", "svs", ")", ":", "\n", "                    ", "self", ".", "sv", "[", "i", "]", "[", ":", "]", "=", "sv", "\n", "", "", "", "return", "self", ".", "weight", "/", "svs", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.SNConv2d.__init__": [[105, 111], ["torch.Conv2d.__init__", "torch.Conv2d.__init__", "torch.Conv2d.__init__", "torch.Conv2d.__init__", "layers.SN.__init__"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "bias", "=", "True", ",", "\n", "num_svs", "=", "1", ",", "num_itrs", "=", "1", ",", "eps", "=", "1e-12", ")", ":", "\n", "        ", "nn", ".", "Conv2d", ".", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ",", "\n", "padding", ",", "dilation", ",", "groups", ",", "bias", ")", "\n", "SN", ".", "__init__", "(", "self", ",", "num_svs", ",", "num_itrs", ",", "out_channels", ",", "eps", "=", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.SNConv2d.forward": [[112, 115], ["torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "layers.SNConv2d.W_"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.SN.W_"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "F", ".", "conv2d", "(", "x", ",", "self", ".", "W_", "(", ")", ",", "self", ".", "bias", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.SNLinear.__init__": [[119, 123], ["torch.Linear.__init__", "torch.Linear.__init__", "torch.Linear.__init__", "torch.Linear.__init__", "layers.SN.__init__"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "bias", "=", "True", ",", "\n", "num_svs", "=", "1", ",", "num_itrs", "=", "1", ",", "eps", "=", "1e-12", ")", ":", "\n", "        ", "nn", ".", "Linear", ".", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "bias", ")", "\n", "SN", ".", "__init__", "(", "self", ",", "num_svs", ",", "num_itrs", ",", "out_features", ",", "eps", "=", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.SNLinear.forward": [[124, 126], ["torch.linear", "torch.linear", "torch.linear", "torch.linear", "layers.SNLinear.W_"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.SN.W_"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "F", ".", "linear", "(", "x", ",", "self", ".", "W_", "(", ")", ",", "self", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.SNEmbedding.__init__": [[132, 140], ["torch.Embedding.__init__", "torch.Embedding.__init__", "torch.Embedding.__init__", "torch.Embedding.__init__", "layers.SN.__init__"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "None", ",", "\n", "max_norm", "=", "None", ",", "norm_type", "=", "2", ",", "scale_grad_by_freq", "=", "False", ",", "\n", "sparse", "=", "False", ",", "_weight", "=", "None", ",", "\n", "num_svs", "=", "1", ",", "num_itrs", "=", "1", ",", "eps", "=", "1e-12", ")", ":", "\n", "        ", "nn", ".", "Embedding", ".", "__init__", "(", "self", ",", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ",", "\n", "max_norm", ",", "norm_type", ",", "scale_grad_by_freq", ",", "\n", "sparse", ",", "_weight", ")", "\n", "SN", ".", "__init__", "(", "self", ",", "num_svs", ",", "num_itrs", ",", "num_embeddings", ",", "eps", "=", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.SNEmbedding.forward": [[141, 143], ["torch.embedding", "torch.embedding", "torch.embedding", "torch.embedding", "layers.SNEmbedding.W_"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.SN.W_"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "F", ".", "embedding", "(", "x", ",", "self", ".", "W_", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.Attention.__init__": [[149, 164], ["torch.Module.__init__", "layers.Attention.which_conv", "layers.Attention.which_conv", "layers.Attention.which_conv", "layers.Attention.which_conv", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ch", ",", "which_conv", "=", "SNConv2d", ",", "name", "=", "'attention'", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Channel multiplier", "\n", "self", ".", "ch", "=", "ch", "\n", "self", ".", "which_conv", "=", "which_conv", "\n", "self", ".", "theta", "=", "self", ".", "which_conv", "(", "\n", "self", ".", "ch", ",", "self", ".", "ch", "//", "8", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "self", ".", "phi", "=", "self", ".", "which_conv", "(", "\n", "self", ".", "ch", ",", "self", ".", "ch", "//", "8", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "self", ".", "g", "=", "self", ".", "which_conv", "(", "\n", "self", ".", "ch", ",", "self", ".", "ch", "//", "2", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "self", ".", "o", "=", "self", ".", "which_conv", "(", "\n", "self", ".", "ch", "//", "2", ",", "self", ".", "ch", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "# Learnable gain parameter", "\n", "self", ".", "gamma", "=", "P", "(", "torch", ".", "tensor", "(", "0.", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.Attention.forward": [[165, 180], ["layers.Attention.theta", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "theta.view.view.view", "phi.view.view.view", "g.view.view.view", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "layers.Attention.o", "layers.Attention.phi", "layers.Attention.g", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "theta.view.view.transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", "=", "None", ")", ":", "\n", "# Apply convs", "\n", "        ", "theta", "=", "self", ".", "theta", "(", "x", ")", "\n", "phi", "=", "F", ".", "max_pool2d", "(", "self", ".", "phi", "(", "x", ")", ",", "[", "2", ",", "2", "]", ")", "\n", "g", "=", "F", ".", "max_pool2d", "(", "self", ".", "g", "(", "x", ")", ",", "[", "2", ",", "2", "]", ")", "\n", "# Perform reshapes", "\n", "theta", "=", "theta", ".", "view", "(", "-", "1", ",", "self", ".", "ch", "//", "8", ",", "x", ".", "shape", "[", "2", "]", "*", "x", ".", "shape", "[", "3", "]", ")", "\n", "phi", "=", "phi", ".", "view", "(", "-", "1", ",", "self", ".", "ch", "//", "8", ",", "x", ".", "shape", "[", "2", "]", "*", "x", ".", "shape", "[", "3", "]", "//", "4", ")", "\n", "g", "=", "g", ".", "view", "(", "-", "1", ",", "self", ".", "ch", "//", "2", ",", "x", ".", "shape", "[", "2", "]", "*", "x", ".", "shape", "[", "3", "]", "//", "4", ")", "\n", "# Matmul and softmax to get attention maps", "\n", "beta", "=", "F", ".", "softmax", "(", "torch", ".", "bmm", "(", "theta", ".", "transpose", "(", "1", ",", "2", ")", ",", "phi", ")", ",", "-", "1", ")", "\n", "# Attention map times g path", "\n", "o", "=", "self", ".", "o", "(", "torch", ".", "bmm", "(", "g", ",", "beta", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "view", "(", "-", "1", ",", "\n", "self", ".", "ch", "//", "2", ",", "x", ".", "shape", "[", "2", "]", ",", "x", ".", "shape", "[", "3", "]", ")", ")", "\n", "return", "self", ".", "gamma", "*", "o", "+", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.myBN.__init__": [[223, 237], ["torch.Module.__init__", "layers.myBN.register_buffer", "layers.myBN.register_buffer", "layers.myBN.register_buffer", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_channels", ",", "eps", "=", "1e-5", ",", "momentum", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "myBN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# momentum for updating running stats", "\n", "self", ".", "momentum", "=", "momentum", "\n", "# epsilon to avoid dividing by 0", "\n", "self", ".", "eps", "=", "eps", "\n", "# Momentum", "\n", "self", ".", "momentum", "=", "momentum", "\n", "# Register buffers", "\n", "self", ".", "register_buffer", "(", "'stored_mean'", ",", "torch", ".", "zeros", "(", "num_channels", ")", ")", "\n", "self", ".", "register_buffer", "(", "'stored_var'", ",", "torch", ".", "ones", "(", "num_channels", ")", ")", "\n", "self", ".", "register_buffer", "(", "'accumulation_counter'", ",", "torch", ".", "zeros", "(", "1", ")", ")", "\n", "# Accumulate running means and vars", "\n", "self", ".", "accumulate_standing", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.myBN.reset_stats": [[239, 243], ["None"], "methods", ["None"], ["", "def", "reset_stats", "(", "self", ")", ":", "\n", "        ", "self", ".", "stored_mean", "[", ":", "]", "=", "0", "\n", "self", ".", "stored_var", "[", ":", "]", "=", "0", "\n", "self", ".", "accumulation_counter", "[", ":", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.myBN.forward": [[244, 269], ["layers.manual_bn", "layers.myBN.stored_mean.view", "layers.myBN.stored_var.view", "layers.fused_bn"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.manual_bn", "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.fused_bn"], ["", "def", "forward", "(", "self", ",", "x", ",", "gain", ",", "bias", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "out", ",", "mean", ",", "var", "=", "manual_bn", "(", "\n", "x", ",", "gain", ",", "bias", ",", "return_mean_var", "=", "True", ",", "eps", "=", "self", ".", "eps", ")", "\n", "# If accumulating standing stats, increment them", "\n", "if", "self", ".", "accumulate_standing", ":", "\n", "                ", "self", ".", "stored_mean", "[", ":", "]", "=", "self", ".", "stored_mean", "+", "mean", ".", "data", "\n", "self", ".", "stored_var", "[", ":", "]", "=", "self", ".", "stored_var", "+", "var", ".", "data", "\n", "self", ".", "accumulation_counter", "+=", "1.0", "\n", "# If not accumulating standing stats, take running averages", "\n", "", "else", ":", "\n", "                ", "self", ".", "stored_mean", "[", ":", "]", "=", "self", ".", "stored_mean", "*", "(", "1", "-", "self", ".", "momentum", ")", "+", "mean", "*", "self", ".", "momentum", "\n", "self", ".", "stored_var", "[", ":", "]", "=", "self", ".", "stored_var", "*", "(", "1", "-", "self", ".", "momentum", ")", "+", "var", "*", "self", ".", "momentum", "\n", "", "return", "out", "\n", "# If not in training mode, use the stored statistics", "\n", "", "else", ":", "\n", "            ", "mean", "=", "self", ".", "stored_mean", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "var", "=", "self", ".", "stored_var", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "# If using standing stats, divide them by the accumulation counter", "\n", "if", "self", ".", "accumulate_standing", ":", "\n", "                ", "mean", "=", "mean", "/", "self", ".", "accumulation_counter", "\n", "var", "=", "var", "/", "self", ".", "accumulation_counter", "\n", "", "return", "fused_bn", "(", "x", ",", "mean", ",", "var", ",", "gain", ",", "bias", ",", "self", ".", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.ccbn.__init__": [[292, 318], ["torch.Module.__init__", "which_linear", "which_linear", "sync_batchnorm.SynchronizedBatchNorm2d", "layers.myBN", "layers.ccbn.register_buffer", "layers.ccbn.register_buffer", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_size", ",", "input_size", ",", "which_linear", ",", "eps", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "\n", "cross_replica", "=", "False", ",", "mybn", "=", "False", ",", "norm_style", "=", "'bn'", ",", ")", ":", "\n", "        ", "super", "(", "ccbn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_size", ",", "self", ".", "input_size", "=", "output_size", ",", "input_size", "\n", "# Prepare gain and bias layers", "\n", "self", ".", "gain", "=", "which_linear", "(", "input_size", ",", "output_size", ")", "\n", "self", ".", "bias", "=", "which_linear", "(", "input_size", ",", "output_size", ")", "\n", "# epsilon to avoid dividing by 0", "\n", "self", ".", "eps", "=", "eps", "\n", "# Momentum", "\n", "self", ".", "momentum", "=", "momentum", "\n", "# Use cross-replica batchnorm?", "\n", "self", ".", "cross_replica", "=", "cross_replica", "\n", "# Use my batchnorm?", "\n", "self", ".", "mybn", "=", "mybn", "\n", "# Norm style?", "\n", "self", ".", "norm_style", "=", "norm_style", "\n", "\n", "if", "self", ".", "cross_replica", ":", "\n", "            ", "self", ".", "bn", "=", "SyncBN2d", "(", "output_size", ",", "eps", "=", "self", ".", "eps", ",", "\n", "momentum", "=", "self", ".", "momentum", ",", "affine", "=", "False", ")", "\n", "", "elif", "self", ".", "mybn", ":", "\n", "            ", "self", ".", "bn", "=", "myBN", "(", "output_size", ",", "self", ".", "eps", ",", "self", ".", "momentum", ")", "\n", "", "elif", "self", ".", "norm_style", "in", "[", "'bn'", ",", "'in'", "]", ":", "\n", "            ", "self", ".", "register_buffer", "(", "'stored_mean'", ",", "torch", ".", "zeros", "(", "output_size", ")", ")", "\n", "self", ".", "register_buffer", "(", "'stored_var'", ",", "torch", ".", "ones", "(", "output_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.ccbn.forward": [[319, 339], ["layers.ccbn.bias().view", "y.size", "y.size", "layers.ccbn.bn", "layers.ccbn.bias", "torch.batch_norm", "torch.batch_norm", "torch.batch_norm", "torch.batch_norm", "layers.ccbn.gain", "torch.instance_norm", "torch.instance_norm", "torch.instance_norm", "torch.instance_norm", "layers.groupnorm"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.groupnorm"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "# Calculate class-conditional gains and biases", "\n", "        ", "gain", "=", "(", "1", "+", "self", ".", "gain", "(", "y", ")", ")", ".", "view", "(", "y", ".", "size", "(", "0", ")", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "bias", "=", "self", ".", "bias", "(", "y", ")", ".", "view", "(", "y", ".", "size", "(", "0", ")", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "# If using my batchnorm", "\n", "if", "self", ".", "mybn", "or", "self", ".", "cross_replica", ":", "\n", "            ", "return", "self", ".", "bn", "(", "x", ",", "gain", "=", "gain", ",", "bias", "=", "bias", ")", "\n", "# else:", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "norm_style", "==", "'bn'", ":", "\n", "                ", "out", "=", "F", ".", "batch_norm", "(", "x", ",", "self", ".", "stored_mean", ",", "self", ".", "stored_var", ",", "None", ",", "None", ",", "\n", "self", ".", "training", ",", "0.1", ",", "self", ".", "eps", ")", "\n", "", "elif", "self", ".", "norm_style", "==", "'in'", ":", "\n", "                ", "out", "=", "F", ".", "instance_norm", "(", "x", ",", "self", ".", "stored_mean", ",", "self", ".", "stored_var", ",", "None", ",", "None", ",", "\n", "self", ".", "training", ",", "0.1", ",", "self", ".", "eps", ")", "\n", "", "elif", "self", ".", "norm_style", "==", "'gn'", ":", "\n", "                ", "out", "=", "groupnorm", "(", "x", ",", "self", ".", "normstyle", ")", "\n", "", "elif", "self", ".", "norm_style", "==", "'nonorm'", ":", "\n", "                ", "out", "=", "x", "\n", "", "return", "out", "*", "gain", "+", "bias", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.ccbn.extra_repr": [[340, 344], ["s.format"], "methods", ["None"], ["", "", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "s", "=", "'out: {output_size}, in: {input_size},'", "\n", "s", "+=", "' cross_replica={cross_replica}'", "\n", "return", "s", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.bn.__init__": [[348, 373], ["torch.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "sync_batchnorm.SynchronizedBatchNorm2d", "layers.myBN", "layers.bn.register_buffer", "layers.bn.register_buffer", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_size", ",", "eps", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "\n", "cross_replica", "=", "False", ",", "mybn", "=", "False", ")", ":", "\n", "        ", "super", "(", "bn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_size", "=", "output_size", "\n", "# Prepare gain and bias layers", "\n", "self", ".", "gain", "=", "P", "(", "torch", ".", "ones", "(", "output_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "bias", "=", "P", "(", "torch", ".", "zeros", "(", "output_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "# epsilon to avoid dividing by 0", "\n", "self", ".", "eps", "=", "eps", "\n", "# Momentum", "\n", "self", ".", "momentum", "=", "momentum", "\n", "# Use cross-replica batchnorm?", "\n", "self", ".", "cross_replica", "=", "cross_replica", "\n", "# Use my batchnorm?", "\n", "self", ".", "mybn", "=", "mybn", "\n", "\n", "if", "self", ".", "cross_replica", ":", "\n", "            ", "self", ".", "bn", "=", "SyncBN2d", "(", "output_size", ",", "eps", "=", "self", ".", "eps", ",", "\n", "momentum", "=", "self", ".", "momentum", ",", "affine", "=", "False", ")", "\n", "", "elif", "mybn", ":", "\n", "            ", "self", ".", "bn", "=", "myBN", "(", "output_size", ",", "self", ".", "eps", ",", "self", ".", "momentum", ")", "\n", "# Register buffers if neither of the above", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_buffer", "(", "'stored_mean'", ",", "torch", ".", "zeros", "(", "output_size", ")", ")", "\n", "self", ".", "register_buffer", "(", "'stored_var'", ",", "torch", ".", "ones", "(", "output_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.bn.forward": [[374, 382], ["layers.bn.gain.view", "layers.bn.bias.view", "layers.bn.bn", "torch.batch_norm", "torch.batch_norm", "torch.batch_norm", "torch.batch_norm"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "y", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "cross_replica", "or", "self", ".", "mybn", ":", "\n", "            ", "gain", "=", "self", ".", "gain", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "bias", "=", "self", ".", "bias", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "return", "self", ".", "bn", "(", "x", ",", "gain", "=", "gain", ",", "bias", "=", "bias", ")", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "batch_norm", "(", "x", ",", "self", ".", "stored_mean", ",", "self", ".", "stored_var", ",", "self", ".", "gain", ",", "\n", "self", ".", "bias", ",", "self", ".", "training", ",", "self", ".", "momentum", ",", "self", ".", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.GBlock.__init__": [[391, 412], ["torch.Module.__init__", "layers.GBlock.which_conv", "layers.GBlock.which_conv", "layers.GBlock.which_bn", "layers.GBlock.which_bn", "layers.GBlock.which_conv"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "\n", "which_conv", "=", "nn", ".", "Conv2d", ",", "which_bn", "=", "bn", ",", "activation", "=", "None", ",", "\n", "upsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "GBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "in_channels", ",", "self", ".", "out_channels", "=", "in_channels", ",", "out_channels", "\n", "self", ".", "which_conv", ",", "self", ".", "which_bn", "=", "which_conv", ",", "which_bn", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "upsample", "=", "upsample", "\n", "# Conv layers", "\n", "self", ".", "conv1", "=", "self", ".", "which_conv", "(", "self", ".", "in_channels", ",", "self", ".", "out_channels", ")", "\n", "self", ".", "conv2", "=", "self", ".", "which_conv", "(", "self", ".", "out_channels", ",", "self", ".", "out_channels", ")", "\n", "self", ".", "learnable_sc", "=", "in_channels", "!=", "out_channels", "or", "upsample", "\n", "if", "self", ".", "learnable_sc", ":", "\n", "            ", "self", ".", "conv_sc", "=", "self", ".", "which_conv", "(", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "padding", "=", "0", ")", "\n", "# Batchnorm layers", "\n", "", "self", ".", "bn1", "=", "self", ".", "which_bn", "(", "in_channels", ")", "\n", "self", ".", "bn2", "=", "self", ".", "which_bn", "(", "out_channels", ")", "\n", "# upsample layers", "\n", "self", ".", "upsample", "=", "upsample", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.GBlock.forward": [[413, 424], ["layers.GBlock.activation", "layers.GBlock.conv1", "layers.GBlock.activation", "layers.GBlock.conv2", "layers.GBlock.bn1", "layers.GBlock.upsample", "layers.GBlock.upsample", "layers.GBlock.bn2", "layers.GBlock.conv_sc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "h", "=", "self", ".", "activation", "(", "self", ".", "bn1", "(", "x", ",", "y", ")", ")", "\n", "if", "self", ".", "upsample", ":", "\n", "            ", "h", "=", "self", ".", "upsample", "(", "h", ")", "\n", "x", "=", "self", ".", "upsample", "(", "x", ")", "\n", "", "h", "=", "self", ".", "conv1", "(", "h", ")", "\n", "h", "=", "self", ".", "activation", "(", "self", ".", "bn2", "(", "h", ",", "y", ")", ")", "\n", "h", "=", "self", ".", "conv2", "(", "h", ")", "\n", "if", "self", ".", "learnable_sc", ":", "\n", "            ", "x", "=", "self", ".", "conv_sc", "(", "x", ")", "\n", "", "return", "h", "+", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.DBlock.__init__": [[428, 447], ["torch.Module.__init__", "layers.DBlock.which_conv", "layers.DBlock.which_conv", "layers.DBlock.which_conv"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "which_conv", "=", "SNConv2d", ",", "wide", "=", "True", ",", "\n", "preactivation", "=", "False", ",", "activation", "=", "None", ",", "downsample", "=", "None", ",", ")", ":", "\n", "        ", "super", "(", "DBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_channels", ",", "self", ".", "out_channels", "=", "in_channels", ",", "out_channels", "\n", "# If using wide D (as in SA-GAN and BigGAN), change the channel pattern", "\n", "self", ".", "hidden_channels", "=", "self", ".", "out_channels", "if", "wide", "else", "self", ".", "in_channels", "\n", "self", ".", "which_conv", "=", "which_conv", "\n", "self", ".", "preactivation", "=", "preactivation", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "downsample", "=", "downsample", "\n", "\n", "# Conv layers", "\n", "self", ".", "conv1", "=", "self", ".", "which_conv", "(", "self", ".", "in_channels", ",", "self", ".", "hidden_channels", ")", "\n", "self", ".", "conv2", "=", "self", ".", "which_conv", "(", "self", ".", "hidden_channels", ",", "self", ".", "out_channels", ")", "\n", "self", ".", "learnable_sc", "=", "True", "if", "(", "\n", "in_channels", "!=", "out_channels", ")", "or", "downsample", "else", "False", "\n", "if", "self", ".", "learnable_sc", ":", "\n", "            ", "self", ".", "conv_sc", "=", "self", ".", "which_conv", "(", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "padding", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.DBlock.shortcut": [[448, 460], ["layers.DBlock.conv_sc", "layers.DBlock.downsample", "layers.DBlock.downsample", "layers.DBlock.conv_sc"], "methods", ["None"], ["", "", "def", "shortcut", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "preactivation", ":", "\n", "            ", "if", "self", ".", "learnable_sc", ":", "\n", "                ", "x", "=", "self", ".", "conv_sc", "(", "x", ")", "\n", "", "if", "self", ".", "downsample", ":", "\n", "                ", "x", "=", "self", ".", "downsample", "(", "x", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "downsample", ":", "\n", "                ", "x", "=", "self", ".", "downsample", "(", "x", ")", "\n", "", "if", "self", ".", "learnable_sc", ":", "\n", "                ", "x", "=", "self", ".", "conv_sc", "(", "x", ")", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.DBlock.forward": [[461, 475], ["layers.DBlock.conv1", "layers.DBlock.conv2", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "layers.DBlock.activation", "layers.DBlock.downsample", "layers.DBlock.shortcut"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.DBlock.shortcut"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "preactivation", ":", "\n", "# h = self.activation(x) # NOT TODAY SATAN", "\n", "# Andy's note: This line *must* be an out-of-place ReLU or it", "\n", "#              will negatively affect the shortcut connection.", "\n", "            ", "h", "=", "F", ".", "relu", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "h", "=", "x", "\n", "", "h", "=", "self", ".", "conv1", "(", "h", ")", "\n", "h", "=", "self", ".", "conv2", "(", "self", ".", "activation", "(", "h", ")", ")", "\n", "if", "self", ".", "downsample", ":", "\n", "            ", "h", "=", "self", ".", "downsample", "(", "h", ")", "\n", "\n", "", "return", "h", "+", "self", ".", "shortcut", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.proj": [[16, 18], ["torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "y.t", "x.t"], "function", ["None"], ["def", "proj", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "torch", ".", "mm", "(", "y", ",", "x", ".", "t", "(", ")", ")", "*", "y", "/", "torch", ".", "mm", "(", "y", ",", "y", ".", "t", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.gram_schmidt": [[21, 25], ["layers.proj"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.proj"], ["", "def", "gram_schmidt", "(", "x", ",", "ys", ")", ":", "\n", "    ", "for", "y", "in", "ys", ":", "\n", "        ", "x", "=", "x", "-", "proj", "(", "x", ",", "y", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.power_iteration": [[28, 51], ["enumerate", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.normalize", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.normalize", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "layers.gram_schmidt", "W.t", "layers.gram_schmidt", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "F.normalize.t", "W.t"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.gram_schmidt", "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.gram_schmidt"], ["", "def", "power_iteration", "(", "W", ",", "u_", ",", "update", "=", "True", ",", "eps", "=", "1e-12", ")", ":", "\n", "# Lists holding singular vectors and values", "\n", "    ", "us", ",", "vs", ",", "svs", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "u", "in", "enumerate", "(", "u_", ")", ":", "\n", "# Run one step of the power iteration", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "v", "=", "torch", ".", "matmul", "(", "u", ",", "W", ")", "\n", "# Run Gram-Schmidt to subtract components of all other singular vectors", "\n", "v", "=", "F", ".", "normalize", "(", "gram_schmidt", "(", "v", ",", "vs", ")", ",", "eps", "=", "eps", ")", "\n", "# Add to the list", "\n", "vs", "+=", "[", "v", "]", "\n", "# Update the other singular vector", "\n", "u", "=", "torch", ".", "matmul", "(", "v", ",", "W", ".", "t", "(", ")", ")", "\n", "# Run Gram-Schmidt to subtract components of all other singular vectors", "\n", "u", "=", "F", ".", "normalize", "(", "gram_schmidt", "(", "u", ",", "us", ")", ",", "eps", "=", "eps", ")", "\n", "# Add to the list", "\n", "us", "+=", "[", "u", "]", "\n", "if", "update", ":", "\n", "                ", "u_", "[", "i", "]", "[", ":", "]", "=", "u", "\n", "# Compute this singular value and add it to the list", "\n", "", "", "svs", "+=", "[", "torch", ".", "squeeze", "(", "torch", ".", "matmul", "(", "torch", ".", "matmul", "(", "v", ",", "W", ".", "t", "(", ")", ")", ",", "u", ".", "t", "(", ")", ")", ")", "]", "\n", "#svs += [torch.sum(F.linear(u, W.transpose(0, 1)) * v)]", "\n", "", "return", "svs", ",", "us", ",", "vs", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.fused_bn": [[183, 196], ["torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt"], "function", ["None"], ["", "", "def", "fused_bn", "(", "x", ",", "mean", ",", "var", ",", "gain", "=", "None", ",", "bias", "=", "None", ",", "eps", "=", "1e-5", ")", ":", "\n", "# Apply scale and shift--if gain and bias are provided, fuse them here", "\n", "# Prepare scale", "\n", "    ", "scale", "=", "torch", ".", "rsqrt", "(", "var", "+", "eps", ")", "\n", "# If a gain is provided, use it", "\n", "if", "gain", "is", "not", "None", ":", "\n", "        ", "scale", "=", "scale", "*", "gain", "\n", "# Prepare shift", "\n", "", "shift", "=", "mean", "*", "scale", "\n", "# If bias is provided, use it", "\n", "if", "bias", "is", "not", "None", ":", "\n", "        ", "shift", "=", "shift", "-", "bias", "\n", "", "return", "x", "*", "scale", "-", "shift", "\n", "# return ((x - mean) / ((var + eps) ** 0.5)) * gain + bias # The unfused way.", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.manual_bn": [[201, 219], ["x.float", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "var.type.type", "m.type.type", "x.type", "x.type", "layers.fused_bn", "layers.fused_bn", "m.type.squeeze", "var.type.squeeze"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.fused_bn", "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.fused_bn"], ["", "def", "manual_bn", "(", "x", ",", "gain", "=", "None", ",", "bias", "=", "None", ",", "return_mean_var", "=", "False", ",", "eps", "=", "1e-5", ")", ":", "\n", "# Cast x to float32 if necessary", "\n", "    ", "float_x", "=", "x", ".", "float", "(", ")", "\n", "# Calculate expected value of x (m) and expected value of x**2 (m2)", "\n", "# Mean of x", "\n", "m", "=", "torch", ".", "mean", "(", "float_x", ",", "[", "0", ",", "2", ",", "3", "]", ",", "keepdim", "=", "True", ")", "\n", "# Mean of x squared", "\n", "m2", "=", "torch", ".", "mean", "(", "float_x", "**", "2", ",", "[", "0", ",", "2", ",", "3", "]", ",", "keepdim", "=", "True", ")", "\n", "# Calculate variance as mean of squared minus mean squared.", "\n", "var", "=", "(", "m2", "-", "m", "**", "2", ")", "\n", "# Cast back to float 16 if necessary", "\n", "var", "=", "var", ".", "type", "(", "x", ".", "type", "(", ")", ")", "\n", "m", "=", "m", ".", "type", "(", "x", ".", "type", "(", ")", ")", "\n", "# Return mean and variance for updating stored mean/var if requested", "\n", "if", "return_mean_var", ":", "\n", "        ", "return", "fused_bn", "(", "x", ",", "m", ",", "var", ",", "gain", ",", "bias", ",", "eps", ")", ",", "m", ".", "squeeze", "(", ")", ",", "var", ".", "squeeze", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "fused_bn", "(", "x", ",", "m", ",", "var", ",", "gain", ",", "bias", ",", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.groupnorm": [[272, 284], ["torch.group_norm", "int", "max", "int", "norm_style.split", "int", "norm_style.split"], "function", ["None"], ["", "", "", "def", "groupnorm", "(", "x", ",", "norm_style", ")", ":", "\n", "# If number of channels specified in norm_style:", "\n", "    ", "if", "'ch'", "in", "norm_style", ":", "\n", "        ", "ch", "=", "int", "(", "norm_style", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ")", "\n", "groups", "=", "max", "(", "int", "(", "x", ".", "shape", "[", "1", "]", ")", "//", "ch", ",", "1", ")", "\n", "# If number of groups specified in norm style", "\n", "", "elif", "'grp'", "in", "norm_style", ":", "\n", "        ", "groups", "=", "int", "(", "norm_style", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ")", "\n", "# If neither, default to groups = 16", "\n", "", "else", ":", "\n", "        ", "groups", "=", "16", "\n", "", "return", "F", ".", "group_norm", "(", "x", ",", "groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_utils.WrapInception.__init__": [[28, 35], ["torch.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__"], ["    ", "def", "__init__", "(", "self", ",", "net", ")", ":", "\n", "        ", "super", "(", "WrapInception", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "net", "=", "net", "\n", "self", ".", "mean", "=", "P", "(", "torch", ".", "tensor", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ",", "\n", "requires_grad", "=", "False", ")", "\n", "self", ".", "std", "=", "P", "(", "torch", ".", "tensor", "(", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ",", "\n", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_utils.WrapInception.forward": [[36, 87], ["inception_utils.WrapInception.net.Conv2d_1a_3x3", "inception_utils.WrapInception.net.Conv2d_2a_3x3", "inception_utils.WrapInception.net.Conv2d_2b_3x3", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "inception_utils.WrapInception.net.Conv2d_3b_1x1", "inception_utils.WrapInception.net.Conv2d_4a_3x3", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "inception_utils.WrapInception.net.Mixed_5b", "inception_utils.WrapInception.net.Mixed_5c", "inception_utils.WrapInception.net.Mixed_5d", "inception_utils.WrapInception.net.Mixed_6a", "inception_utils.WrapInception.net.Mixed_6b", "inception_utils.WrapInception.net.Mixed_6c", "inception_utils.WrapInception.net.Mixed_6d", "inception_utils.WrapInception.net.Mixed_6e", "inception_utils.WrapInception.net.Mixed_7a", "inception_utils.WrapInception.net.Mixed_7b", "inception_utils.WrapInception.net.Mixed_7c", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "inception_utils.WrapInception.net.fc", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate.view", "torch.dropout().view", "torch.dropout().view", "torch.dropout().view", "torch.interpolate.size", "torch.interpolate.size", "torch.mean.size", "torch.mean.size", "torch.mean.size", "torch.dropout", "torch.dropout", "torch.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# Normalize x", "\n", "        ", "x", "=", "(", "x", "-", "self", ".", "mean", ")", "/", "self", ".", "std", "\n", "# Upsample if necessary", "\n", "if", "x", ".", "shape", "[", "2", "]", "!=", "299", "or", "x", ".", "shape", "[", "3", "]", "!=", "299", ":", "\n", "            ", "x", "=", "F", ".", "interpolate", "(", "x", ",", "size", "=", "(", "299", ",", "299", ")", ",", "\n", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "# 299 x 299 x 3", "\n", "", "x", "=", "self", ".", "net", ".", "Conv2d_1a_3x3", "(", "x", ")", "\n", "# 149 x 149 x 32", "\n", "x", "=", "self", ".", "net", ".", "Conv2d_2a_3x3", "(", "x", ")", "\n", "# 147 x 147 x 32", "\n", "x", "=", "self", ".", "net", ".", "Conv2d_2b_3x3", "(", "x", ")", "\n", "# 147 x 147 x 64", "\n", "x", "=", "F", ".", "max_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "# 73 x 73 x 64", "\n", "x", "=", "self", ".", "net", ".", "Conv2d_3b_1x1", "(", "x", ")", "\n", "# 73 x 73 x 80", "\n", "x", "=", "self", ".", "net", ".", "Conv2d_4a_3x3", "(", "x", ")", "\n", "# 71 x 71 x 192", "\n", "x", "=", "F", ".", "max_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "# 35 x 35 x 192", "\n", "x", "=", "self", ".", "net", ".", "Mixed_5b", "(", "x", ")", "\n", "# 35 x 35 x 256", "\n", "x", "=", "self", ".", "net", ".", "Mixed_5c", "(", "x", ")", "\n", "# 35 x 35 x 288", "\n", "x", "=", "self", ".", "net", ".", "Mixed_5d", "(", "x", ")", "\n", "# 35 x 35 x 288", "\n", "x", "=", "self", ".", "net", ".", "Mixed_6a", "(", "x", ")", "\n", "# 17 x 17 x 768", "\n", "x", "=", "self", ".", "net", ".", "Mixed_6b", "(", "x", ")", "\n", "# 17 x 17 x 768", "\n", "x", "=", "self", ".", "net", ".", "Mixed_6c", "(", "x", ")", "\n", "# 17 x 17 x 768", "\n", "x", "=", "self", ".", "net", ".", "Mixed_6d", "(", "x", ")", "\n", "# 17 x 17 x 768", "\n", "x", "=", "self", ".", "net", ".", "Mixed_6e", "(", "x", ")", "\n", "# 17 x 17 x 768", "\n", "# 17 x 17 x 768", "\n", "x", "=", "self", ".", "net", ".", "Mixed_7a", "(", "x", ")", "\n", "# 8 x 8 x 1280", "\n", "x", "=", "self", ".", "net", ".", "Mixed_7b", "(", "x", ")", "\n", "# 8 x 8 x 2048", "\n", "x", "=", "self", ".", "net", ".", "Mixed_7c", "(", "x", ")", "\n", "# 8 x 8 x 2048", "\n", "pool", "=", "torch", ".", "mean", "(", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ",", "-", "1", ")", ",", "2", ")", "\n", "# 1 x 1 x 2048", "\n", "logits", "=", "self", ".", "net", ".", "fc", "(", "\n", "F", ".", "dropout", "(", "pool", ",", "training", "=", "False", ")", ".", "view", "(", "pool", ".", "size", "(", "0", ")", ",", "-", "1", ")", ")", "\n", "# 1000 (num_classes)", "\n", "return", "pool", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_utils.torch_cov": [[91, 122], ["torch.mean", "torch.mean", "torch.mean", "m.t.t", "m.t.dim", "ValueError", "m.t.dim", "m.t.view", "m.t.t", "m.t.matmul().squeeze", "m.t.size", "m.t.size", "m.t.matmul"], "function", ["None"], ["", "", "def", "torch_cov", "(", "m", ",", "rowvar", "=", "False", ")", ":", "\n", "    ", "'''Estimate a covariance matrix given data.\n\n    Covariance indicates the level to which two variables vary together.\n    If we examine N-dimensional samples, `X = [x_1, x_2, ... x_N]^T`,\n    then the covariance matrix element `C_{ij}` is the covariance of\n    `x_i` and `x_j`. The element `C_{ii}` is the variance of `x_i`.\n\n    Args:\n        m: A 1-D or 2-D array containing multiple variables and observations.\n            Each row of `m` represents a variable, and each column a single\n            observation of all those variables.\n        rowvar: If `rowvar` is True, then each row represents a\n            variable, with observations in the columns. Otherwise, the\n            relationship is transposed: each column represents a variable,\n            while the rows contain observations.\n\n    Returns:\n        The covariance matrix of the variables.\n    '''", "\n", "if", "m", ".", "dim", "(", ")", ">", "2", ":", "\n", "        ", "raise", "ValueError", "(", "'m has more than 2 dimensions'", ")", "\n", "", "if", "m", ".", "dim", "(", ")", "<", "2", ":", "\n", "        ", "m", "=", "m", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "", "if", "not", "rowvar", "and", "m", ".", "size", "(", "0", ")", "!=", "1", ":", "\n", "        ", "m", "=", "m", ".", "t", "(", ")", "\n", "# m = m.type(torch.double)  # uncomment this line if desired", "\n", "", "fact", "=", "1.0", "/", "(", "m", ".", "size", "(", "1", ")", "-", "1", ")", "\n", "m", "-=", "torch", ".", "mean", "(", "m", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "mt", "=", "m", ".", "t", "(", ")", "# if complex: mt = m.t().conj()", "\n", "return", "fact", "*", "m", ".", "matmul", "(", "mt", ")", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_utils.sqrt_newton_schulz": [[126, 144], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "A.mul().sum().sum().sqrt", "A.div", "torch.eye().view().repeat().type", "torch.eye().view().repeat().type", "torch.eye().view().repeat().type", "torch.eye().view().repeat().type", "torch.eye().view().repeat().type", "torch.eye().view().repeat().type", "range", "A.type", "A.mul().sum().sum().sqrt.view().expand_as", "Y.bmm.bmm", "T.bmm", "torch.sqrt().view().expand_as", "torch.sqrt().view().expand_as", "torch.sqrt().view().expand_as", "A.mul().sum().sum", "torch.eye().view().repeat", "torch.eye().view().repeat", "torch.eye().view().repeat", "torch.eye().view().repeat", "torch.eye().view().repeat", "torch.eye().view().repeat", "A.mul().sum().sum().sqrt.view", "T.bmm.bmm", "torch.sqrt().view", "torch.sqrt().view", "torch.sqrt().view", "A.mul().sum", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.sqrt", "torch.sqrt", "torch.sqrt", "A.mul", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye"], "function", ["None"], ["", "def", "sqrt_newton_schulz", "(", "A", ",", "numIters", ",", "dtype", "=", "None", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "if", "dtype", "is", "None", ":", "\n", "            ", "dtype", "=", "A", ".", "type", "(", ")", "\n", "", "batchSize", "=", "A", ".", "shape", "[", "0", "]", "\n", "dim", "=", "A", ".", "shape", "[", "1", "]", "\n", "normA", "=", "A", ".", "mul", "(", "A", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "sqrt", "(", ")", "\n", "Y", "=", "A", ".", "div", "(", "normA", ".", "view", "(", "batchSize", ",", "1", ",", "1", ")", ".", "expand_as", "(", "A", ")", ")", "\n", "I", "=", "torch", ".", "eye", "(", "dim", ",", "dim", ")", ".", "view", "(", "1", ",", "dim", ",", "dim", ")", ".", "repeat", "(", "\n", "batchSize", ",", "1", ",", "1", ")", ".", "type", "(", "dtype", ")", "\n", "Z", "=", "torch", ".", "eye", "(", "dim", ",", "dim", ")", ".", "view", "(", "1", ",", "dim", ",", "dim", ")", ".", "repeat", "(", "\n", "batchSize", ",", "1", ",", "1", ")", ".", "type", "(", "dtype", ")", "\n", "for", "i", "in", "range", "(", "numIters", ")", ":", "\n", "            ", "T", "=", "0.5", "*", "(", "3.0", "*", "I", "-", "Z", ".", "bmm", "(", "Y", ")", ")", "\n", "Y", "=", "Y", ".", "bmm", "(", "T", ")", "\n", "Z", "=", "T", ".", "bmm", "(", "Z", ")", "\n", "", "sA", "=", "Y", "*", "torch", ".", "sqrt", "(", "normA", ")", ".", "view", "(", "batchSize", ",", "1", ",", "1", ")", ".", "expand_as", "(", "A", ")", "\n", "", "return", "sA", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_utils.numpy_calculate_frechet_distance": [[148, 202], ["numpy.atleast_1d", "numpy.atleast_1d", "numpy.atleast_2d", "numpy.atleast_2d", "scipy.linalg.sqrtm", "numpy.iscomplexobj", "numpy.trace", "np.atleast_2d.dot", "numpy.isfinite().all", "print", "scipy.linalg.sqrtm", "print", "numpy.eye", "numpy.allclose", "numpy.max", "ValueError", "numpy.trace", "numpy.isfinite", "numpy.abs", "diff.dot", "numpy.trace", "numpy.diagonal"], "function", ["None"], ["", "def", "numpy_calculate_frechet_distance", "(", "mu1", ",", "sigma1", ",", "mu2", ",", "sigma2", ",", "eps", "=", "1e-6", ")", ":", "\n", "    ", "\"\"\"Numpy implementation of the Frechet Distance.\n    Taken from https://github.com/bioinf-jku/TTUR\n    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n    and X_2 ~ N(mu_2, C_2) is\n            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n    Stable version by Dougal J. Sutherland.\n    Params:\n    -- mu1   : Numpy array containing the activations of a layer of the\n               inception net (like returned by the function 'get_predictions')\n               for generated samples.\n    -- mu2   : The sample mean over activations, precalculated on an \n               representive data set.\n    -- sigma1: The covariance matrix over activations for generated samples.\n    -- sigma2: The covariance matrix over activations, precalculated on an \n               representive data set.\n    Returns:\n    --   : The Frechet Distance.\n    \"\"\"", "\n", "\n", "mu1", "=", "np", ".", "atleast_1d", "(", "mu1", ")", "\n", "mu2", "=", "np", ".", "atleast_1d", "(", "mu2", ")", "\n", "\n", "sigma1", "=", "np", ".", "atleast_2d", "(", "sigma1", ")", "\n", "sigma2", "=", "np", ".", "atleast_2d", "(", "sigma2", ")", "\n", "\n", "assert", "mu1", ".", "shape", "==", "mu2", ".", "shape", ",", "'Training and test mean vectors have different lengths'", "\n", "assert", "sigma1", ".", "shape", "==", "sigma2", ".", "shape", ",", "'Training and test covariances have different dimensions'", "\n", "\n", "diff", "=", "mu1", "-", "mu2", "\n", "\n", "# Product might be almost singular", "\n", "covmean", ",", "_", "=", "linalg", ".", "sqrtm", "(", "sigma1", ".", "dot", "(", "sigma2", ")", ",", "disp", "=", "False", ")", "\n", "if", "not", "np", ".", "isfinite", "(", "covmean", ")", ".", "all", "(", ")", ":", "\n", "        ", "msg", "=", "(", "'fid calculation produces singular product; '", "\n", "'adding %s to diagonal of cov estimates'", ")", "%", "eps", "\n", "print", "(", "msg", ")", "\n", "offset", "=", "np", ".", "eye", "(", "sigma1", ".", "shape", "[", "0", "]", ")", "*", "eps", "\n", "covmean", "=", "linalg", ".", "sqrtm", "(", "(", "sigma1", "+", "offset", ")", ".", "dot", "(", "sigma2", "+", "offset", ")", ")", "\n", "\n", "# Numerical error might give slight imaginary component", "\n", "", "if", "np", ".", "iscomplexobj", "(", "covmean", ")", ":", "\n", "        ", "print", "(", "'wat'", ")", "\n", "if", "not", "np", ".", "allclose", "(", "np", ".", "diagonal", "(", "covmean", ")", ".", "imag", ",", "0", ",", "atol", "=", "1e-3", ")", ":", "\n", "            ", "m", "=", "np", ".", "max", "(", "np", ".", "abs", "(", "covmean", ".", "imag", ")", ")", "\n", "raise", "ValueError", "(", "'Imaginary component {}'", ".", "format", "(", "m", ")", ")", "\n", "", "covmean", "=", "covmean", ".", "real", "\n", "\n", "", "tr_covmean", "=", "np", ".", "trace", "(", "covmean", ")", "\n", "\n", "out", "=", "diff", ".", "dot", "(", "diff", ")", "+", "np", ".", "trace", "(", "sigma1", ")", "+", "np", ".", "trace", "(", "sigma2", ")", "-", "2", "*", "tr_covmean", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_utils.torch_calculate_frechet_distance": [[204, 235], ["sqrt_newton_schulz().squeeze", "inception_utils.sqrt_newton_schulz", "torch.trace", "torch.trace", "torch.trace", "torch.trace", "torch.trace", "torch.trace", "sigma1.mm().unsqueeze", "diff.dot", "torch.trace", "torch.trace", "torch.trace", "sigma1.mm"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_utils.sqrt_newton_schulz"], ["", "def", "torch_calculate_frechet_distance", "(", "mu1", ",", "sigma1", ",", "mu2", ",", "sigma2", ",", "eps", "=", "1e-6", ")", ":", "\n", "    ", "\"\"\"Pytorch implementation of the Frechet Distance.\n    Taken from https://github.com/bioinf-jku/TTUR\n    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n    and X_2 ~ N(mu_2, C_2) is\n            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n    Stable version by Dougal J. Sutherland.\n    Params:\n    -- mu1   : Numpy array containing the activations of a layer of the\n               inception net (like returned by the function 'get_predictions')\n               for generated samples.\n    -- mu2   : The sample mean over activations, precalculated on an \n               representive data set.\n    -- sigma1: The covariance matrix over activations for generated samples.\n    -- sigma2: The covariance matrix over activations, precalculated on an \n               representive data set.\n    Returns:\n    --   : The Frechet Distance.\n    \"\"\"", "\n", "\n", "assert", "mu1", ".", "shape", "==", "mu2", ".", "shape", ",", "'Training and test mean vectors have different lengths'", "\n", "assert", "sigma1", ".", "shape", "==", "sigma2", ".", "shape", ",", "'Training and test covariances have different dimensions'", "\n", "\n", "diff", "=", "mu1", "-", "mu2", "\n", "# Run 50 itrs of newton-schulz to get the matrix sqrt of sigma1 dot sigma2", "\n", "covmean", "=", "sqrt_newton_schulz", "(", "sigma1", ".", "mm", "(", "sigma2", ")", ".", "unsqueeze", "(", "0", ")", ",", "50", ")", ".", "squeeze", "(", ")", "\n", "out", "=", "(", "diff", ".", "dot", "(", "diff", ")", "+", "torch", ".", "trace", "(", "sigma1", ")", "+", "torch", ".", "trace", "(", "sigma2", ")", "\n", "-", "2", "*", "torch", ".", "trace", "(", "covmean", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_utils.calculate_inception_score": [[238, 248], ["range", "numpy.mean", "scores.append", "numpy.mean", "numpy.std", "numpy.sum", "numpy.exp", "numpy.log", "numpy.log", "numpy.expand_dims", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MyLogger.log", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MyLogger.log"], ["", "def", "calculate_inception_score", "(", "pred", ",", "num_splits", "=", "10", ")", ":", "\n", "    ", "scores", "=", "[", "]", "\n", "for", "index", "in", "range", "(", "num_splits", ")", ":", "\n", "        ", "pred_chunk", "=", "pred", "[", "index", "*", "(", "pred", ".", "shape", "[", "0", "]", "//", "num_splits", ")", "\n", ":", "(", "index", "+", "1", ")", "*", "(", "pred", ".", "shape", "[", "0", "]", "//", "num_splits", ")", ",", ":", "]", "\n", "kl_inception", "=", "pred_chunk", "*", "(", "np", ".", "log", "(", "pred_chunk", ")", "-", "np", ".", "log", "(", "np", ".", "expand_dims", "(", "np", ".", "mean", "(", "pred_chunk", ",", "0", ")", ",", "0", ")", ")", ")", "\n", "kl_inception", "=", "np", ".", "mean", "(", "np", ".", "sum", "(", "kl_inception", ",", "1", ")", ")", "\n", "scores", ".", "append", "(", "np", ".", "exp", "(", "kl_inception", ")", ")", "\n", "", "return", "np", ".", "mean", "(", "scores", ")", ",", "np", ".", "std", "(", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_utils.accumulate_inception_activations": [[254, 264], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sample", "net", "images.float", "torch.softmax", "torch.cat", "torch.cat", "torch.cat"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.sample"], ["", "def", "accumulate_inception_activations", "(", "sample", ",", "net", ",", "num_inception_images", "=", "50000", ")", ":", "\n", "    ", "pool", ",", "logits", ",", "labels", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "while", "(", "torch", ".", "cat", "(", "logits", ",", "0", ")", ".", "shape", "[", "0", "]", "if", "len", "(", "logits", ")", "else", "0", ")", "<", "num_inception_images", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "images", ",", "labels_val", "=", "sample", "(", ")", "\n", "pool_val", ",", "logits_val", "=", "net", "(", "images", ".", "float", "(", ")", ")", "\n", "pool", "+=", "[", "pool_val", "]", "\n", "logits", "+=", "[", "F", ".", "softmax", "(", "logits_val", ",", "1", ")", "]", "\n", "labels", "+=", "[", "labels_val", "]", "\n", "", "", "return", "torch", ".", "cat", "(", "pool", ",", "0", ")", ",", "torch", ".", "cat", "(", "logits", ",", "0", ")", ",", "torch", ".", "cat", "(", "labels", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_utils.load_inception_net": [[267, 274], ["torchvision.models.inception.inception_v3", "WrapInception().cuda", "print", "torch.DataParallel", "inception_utils.WrapInception", "nn.DataParallel.eval"], "function", ["None"], ["", "def", "load_inception_net", "(", "parallel", "=", "False", ")", ":", "\n", "    ", "inception_model", "=", "inception_v3", "(", "pretrained", "=", "True", ",", "transform_input", "=", "False", ")", "\n", "inception_model", "=", "WrapInception", "(", "inception_model", ".", "eval", "(", ")", ")", ".", "cuda", "(", ")", "\n", "if", "parallel", ":", "\n", "        ", "print", "(", "'Parallelizing Inception module...'", ")", "\n", "inception_model", "=", "nn", ".", "DataParallel", "(", "inception_model", ")", "\n", "", "return", "inception_model", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_utils.prepare_inception_metrics": [[280, 332], ["dataset.strip.strip", "numpy.load", "inception_utils.load_inception_net", "inception_utils.accumulate_inception_activations", "inception_utils.calculate_inception_score", "print", "print", "logits.cpu().numpy", "print", "print", "inception_utils.torch_calculate_frechet_distance", "float", "inception_utils.numpy_calculate_frechet_distance", "logits.cpu", "torch.mean", "torch.mean", "torch.mean", "inception_utils.torch_cov", "numpy.mean", "numpy.cov", "torch.tensor().float().cuda", "torch.tensor().float().cuda", "torch.tensor().float().cuda", "torch.tensor().float().cuda", "torch.tensor().float().cuda", "torch.tensor().float().cuda", "numpy_calculate_frechet_distance.cpu().numpy", "pool.cpu().numpy", "pool.cpu().numpy", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "numpy_calculate_frechet_distance.cpu", "pool.cpu", "pool.cpu", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_utils.load_inception_net", "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_utils.accumulate_inception_activations", "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_utils.calculate_inception_score", "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_utils.torch_calculate_frechet_distance", "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_utils.numpy_calculate_frechet_distance", "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_utils.torch_cov"], ["", "def", "prepare_inception_metrics", "(", "dataset", ",", "parallel", ",", "no_fid", "=", "False", ")", ":", "\n", "# Load metrics; this is intentionally not in a try-except loop so that", "\n", "# the script will crash here if it cannot find the Inception moments.", "\n", "# By default, remove the \"hdf5\" from dataset", "\n", "    ", "dataset", "=", "dataset", ".", "strip", "(", "'_hdf5'", ")", "\n", "moments", "=", "np", ".", "load", "(", "'./cifar10_10k_stats.npz'", ")", "\n", "data_mu", "=", "moments", "[", "'mu'", "]", "\n", "data_sigma", "=", "moments", "[", "'sigma'", "]", "\n", "# data_mu = np.load(dataset+'_inception_moments.npz')['mu']", "\n", "# data_sigma = np.load(dataset+'_inception_moments.npz')['sigma']", "\n", "# Load network", "\n", "net", "=", "load_inception_net", "(", "parallel", ")", "\n", "\n", "def", "get_inception_metrics", "(", "sample", ",", "num_inception_images", ",", "num_splits", "=", "10", ",", "\n", "prints", "=", "True", ",", "use_torch", "=", "False", ")", ":", "\n", "# TS: use_torch set to True", "\n", "        ", "if", "prints", ":", "\n", "            ", "print", "(", "'Gathering activations...'", ")", "\n", "", "pool", ",", "logits", ",", "labels", "=", "accumulate_inception_activations", "(", "\n", "sample", ",", "net", ",", "num_inception_images", ")", "\n", "if", "prints", ":", "\n", "            ", "print", "(", "'Calculating Inception Score...'", ")", "\n", "", "IS_mean", ",", "IS_std", "=", "calculate_inception_score", "(", "\n", "logits", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "num_splits", ")", "\n", "if", "no_fid", ":", "\n", "            ", "FID", "=", "9999.0", "\n", "", "else", ":", "\n", "            ", "if", "prints", ":", "\n", "                ", "print", "(", "'Calculating means and covariances...'", ")", "\n", "", "if", "use_torch", ":", "\n", "                ", "mu", ",", "sigma", "=", "torch", ".", "mean", "(", "pool", ",", "0", ")", ",", "torch_cov", "(", "pool", ",", "rowvar", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "mu", ",", "sigma", "=", "np", ".", "mean", "(", "pool", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", ",", "np", ".", "cov", "(", "\n", "pool", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "rowvar", "=", "False", ")", "\n", "", "if", "prints", ":", "\n", "                ", "print", "(", "'Covariances calculated, getting FID...'", ")", "\n", "# DEBUGGING", "\n", "# print(sigma)", "\n", "# np.savez('fid_debugging/sample_inception_moments.npz', {'mu': mu, 'sigma': sigma})", "\n", "# np.savez('fid_debugging/data_inception_moments.npz', {'mu': data_mu, 'sigma': data_sigma})", "\n", "#", "\n", "", "if", "use_torch", ":", "\n", "                ", "FID", "=", "torch_calculate_frechet_distance", "(", "mu", ",", "sigma", ",", "torch", ".", "tensor", "(", "\n", "data_mu", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", ",", "torch", ".", "tensor", "(", "data_sigma", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", ")", "\n", "FID", "=", "float", "(", "FID", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "FID", "=", "numpy_calculate_frechet_distance", "(", "\n", "mu", ",", "sigma", ",", "data_mu", ",", "data_sigma", ")", "\n", "# Delete mu, sigma, pool, logits, and labels, just in case", "\n", "", "", "del", "mu", ",", "sigma", ",", "pool", ",", "logits", ",", "labels", "\n", "return", "IS_mean", ",", "IS_std", ",", "FID", "\n", "", "return", "get_inception_metrics", "\n", "", ""]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.CenterCropLongEdge.__call__": [[502, 510], ["torchvision.functional.center_crop", "torchvision.functional.center_crop", "min"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Image to be cropped.\n        Returns:\n            PIL Image: Cropped image.\n        \"\"\"", "\n", "return", "transforms", ".", "functional", ".", "center_crop", "(", "img", ",", "min", "(", "img", ".", "size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.CenterCropLongEdge.__repr__": [[511, 513], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.RandomCropLongEdge.__call__": [[523, 537], ["torchvision.functional.crop", "torchvision.functional.crop", "min", "min", "numpy.random.randint", "numpy.random.randint"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Image to be cropped.\n        Returns:\n            PIL Image: Cropped image.\n        \"\"\"", "\n", "size", "=", "(", "min", "(", "img", ".", "size", ")", ",", "min", "(", "img", ".", "size", ")", ")", "\n", "# Only step forward along this edge if it's the long edge", "\n", "i", "=", "(", "0", "if", "size", "[", "0", "]", "==", "img", ".", "size", "[", "0", "]", "\n", "else", "np", ".", "random", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "img", ".", "size", "[", "0", "]", "-", "size", "[", "0", "]", ")", ")", "\n", "j", "=", "(", "0", "if", "size", "[", "1", "]", "==", "img", ".", "size", "[", "1", "]", "\n", "else", "np", ".", "random", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "img", ".", "size", "[", "1", "]", "-", "size", "[", "1", "]", ")", ")", "\n", "return", "transforms", ".", "functional", ".", "crop", "(", "img", ",", "i", ",", "j", ",", "size", "[", "0", "]", ",", "size", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.RandomCropLongEdge.__repr__": [[538, 540], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MultiEpochSampler.__init__": [[553, 563], ["len", "ValueError", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_source", ",", "num_epochs", ",", "start_itr", "=", "0", ",", "batch_size", "=", "128", ")", ":", "\n", "        ", "self", ".", "data_source", "=", "data_source", "\n", "self", ".", "num_samples", "=", "len", "(", "self", ".", "data_source", ")", "\n", "self", ".", "num_epochs", "=", "num_epochs", "\n", "self", ".", "start_itr", "=", "start_itr", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n", "if", "not", "isinstance", "(", "self", ".", "num_samples", ",", "int", ")", "or", "self", ".", "num_samples", "<=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"num_samples should be a positive integeral \"", "\n", "\"value, but got num_samples={}\"", ".", "format", "(", "self", ".", "num_samples", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MultiEpochSampler.__iter__": [[564, 582], ["len", "int", "torch.cat().tolist", "torch.cat().tolist", "torch.cat().tolist", "torch.cat().tolist", "torch.cat().tolist", "torch.cat().tolist", "torch.cat().tolist", "torch.cat().tolist", "torch.cat().tolist", "print", "iter", "numpy.ceil", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "float", "range"], "methods", ["None"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "n", "=", "len", "(", "self", ".", "data_source", ")", "\n", "# Determine number of epochs", "\n", "num_epochs", "=", "int", "(", "np", ".", "ceil", "(", "(", "n", "*", "self", ".", "num_epochs", "\n", "-", "(", "self", ".", "start_itr", "*", "self", ".", "batch_size", ")", ")", "/", "float", "(", "n", ")", ")", ")", "\n", "# Sample all the indices, and then grab the last num_epochs index sets;", "\n", "# This ensures if we're starting at epoch 4, we're still grabbing epoch 4's", "\n", "# indices", "\n", "out", "=", "[", "torch", ".", "randperm", "(", "n", ")", "\n", "for", "epoch", "in", "range", "(", "self", ".", "num_epochs", ")", "]", "[", "-", "num_epochs", ":", "]", "\n", "# Ignore the first start_itr % n indices of the first epoch", "\n", "out", "[", "0", "]", "=", "out", "[", "0", "]", "[", "(", "self", ".", "start_itr", "*", "self", ".", "batch_size", "%", "n", ")", ":", "]", "\n", "# if self.replacement:", "\n", "# return iter(torch.randint(high=n, size=(self.num_samples,), dtype=torch.int64).tolist())", "\n", "# return iter(.tolist())", "\n", "output", "=", "torch", ".", "cat", "(", "out", ")", ".", "tolist", "(", ")", "\n", "print", "(", "'Length dataset output is %d'", "%", "len", "(", "output", ")", ")", "\n", "return", "iter", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MultiEpochSampler.__len__": [[583, 585], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data_source", ")", "*", "self", ".", "num_epochs", "-", "self", ".", "start_itr", "*", "self", ".", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.ema.__init__": [[695, 708], ["utils.ema.source.state_dict", "utils.ema.target.state_dict", "print", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "utils.ema.target_dict[].data.copy_"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "source", ",", "target", ",", "decay", "=", "0.9999", ",", "start_itr", "=", "0", ")", ":", "\n", "        ", "self", ".", "source", "=", "source", "\n", "self", ".", "target", "=", "target", "\n", "self", ".", "decay", "=", "decay", "\n", "# Optional parameter indicating what iteration to start the decay at", "\n", "self", ".", "start_itr", "=", "start_itr", "\n", "# Initialize target's params to be source's", "\n", "self", ".", "source_dict", "=", "self", ".", "source", ".", "state_dict", "(", ")", "\n", "self", ".", "target_dict", "=", "self", ".", "target", ".", "state_dict", "(", ")", "\n", "print", "(", "'Initializing EMA parameters to be source parameters...'", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "key", "in", "self", ".", "source_dict", ":", "\n", "                ", "self", ".", "target_dict", "[", "key", "]", ".", "data", ".", "copy_", "(", "self", ".", "source_dict", "[", "key", "]", ".", "data", ")", "\n", "# target_dict[key].data = source_dict[key].data # Doesn't work!", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.ema.update": [[710, 721], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "utils.ema.target_dict[].data.copy_"], "methods", ["None"], ["", "", "", "def", "update", "(", "self", ",", "itr", "=", "None", ")", ":", "\n", "# If an iteration counter is provided and itr is less than the start itr,", "\n", "# peg the ema weights to the underlying weights.", "\n", "        ", "if", "itr", "and", "itr", "<", "self", ".", "start_itr", ":", "\n", "            ", "decay", "=", "0.0", "\n", "", "else", ":", "\n", "            ", "decay", "=", "self", ".", "decay", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "key", "in", "self", ".", "source_dict", ":", "\n", "                ", "self", ".", "target_dict", "[", "key", "]", ".", "data", ".", "copy_", "(", "self", ".", "target_dict", "[", "key", "]", ".", "data", "*", "decay", "\n", "+", "self", ".", "source_dict", "[", "key", "]", ".", "data", "*", "(", "1", "-", "decay", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MetricsLogger.__init__": [[831, 838], ["os.path.exists", "print", "os.remove"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "fname", ",", "reinitialize", "=", "False", ")", ":", "\n", "        ", "self", ".", "fname", "=", "fname", "\n", "self", ".", "reinitialize", "=", "reinitialize", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "fname", ")", ":", "\n", "            ", "if", "self", ".", "reinitialize", ":", "\n", "                ", "print", "(", "'{} exists, deleting...'", ".", "format", "(", "self", ".", "fname", ")", ")", "\n", "os", ".", "remove", "(", "self", ".", "fname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MetricsLogger.log": [[839, 849], ["record.update", "time.time", "open", "f.write", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.ema.update"], ["", "", "", "def", "log", "(", "self", ",", "record", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Assumption: no newlines in the input.\n        \"\"\"", "\n", "if", "record", "is", "None", ":", "\n", "            ", "record", "=", "{", "}", "\n", "", "record", ".", "update", "(", "kwargs", ")", "\n", "record", "[", "'_stamp'", "]", "=", "time", ".", "time", "(", ")", "\n", "with", "open", "(", "self", ".", "fname", ",", "'a'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "record", ",", "ensure_ascii", "=", "True", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MyLogger.__init__": [[858, 865], ["os.path.exists", "os.mkdir"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "fname", ",", "reinitialize", "=", "False", ",", "logstyle", "=", "'%3.3f'", ")", ":", "\n", "        ", "self", ".", "root", "=", "fname", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "root", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "self", ".", "root", ")", "\n", "", "self", ".", "reinitialize", "=", "reinitialize", "\n", "self", ".", "metrics", "=", "[", "]", "\n", "self", ".", "logstyle", "=", "logstyle", "# One of '%3.3f' or like '%3.3e'", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MyLogger.reinit": [[867, 878], ["os.path.exists", "os.remove", "print", "any", "print"], "methods", ["None"], ["", "def", "reinit", "(", "self", ",", "item", ")", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "'%s/%s.log'", "%", "(", "self", ".", "root", ",", "item", ")", ")", ":", "\n", "            ", "if", "self", ".", "reinitialize", ":", "\n", "# Only print the removal mess", "\n", "                ", "if", "'sv'", "in", "item", ":", "\n", "                    ", "if", "not", "any", "(", "'sv'", "in", "item", "for", "item", "in", "self", ".", "metrics", ")", ":", "\n", "                        ", "print", "(", "'Deleting singular value logs...'", ")", "\n", "", "", "else", ":", "\n", "                    ", "print", "(", "'{} exists, deleting...'", ".", "format", "(", "\n", "'%s_%s.log'", "%", "(", "self", ".", "root", ",", "item", ")", ")", ")", "\n", "", "os", ".", "remove", "(", "'%s/%s.log'", "%", "(", "self", ".", "root", ",", "item", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MyLogger.log": [[880, 895], ["print", "utils.MyLogger.reinit", "print", "open", "f.write"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MyLogger.reinit"], ["", "", "", "def", "log", "(", "self", ",", "itr", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "arg", "in", "kwargs", ":", "\n", "            ", "if", "arg", "not", "in", "self", ".", "metrics", ":", "\n", "                ", "if", "self", ".", "reinitialize", ":", "\n", "                    ", "self", ".", "reinit", "(", "arg", ")", "\n", "", "self", ".", "metrics", "+=", "[", "arg", "]", "\n", "", "if", "self", ".", "logstyle", "==", "'pickle'", ":", "\n", "                ", "print", "(", "'Pickle not currently supported...'", ")", "\n", "# with open('%s/%s.log' % (self.root, arg), 'a') as f:", "\n", "# pickle.dump(kwargs[arg], f)", "\n", "", "elif", "self", ".", "logstyle", "==", "'mat'", ":", "\n", "                ", "print", "(", "'.mat logstyle not currently supported...'", ")", "\n", "", "else", ":", "\n", "                ", "with", "open", "(", "'%s/%s.log'", "%", "(", "self", ".", "root", ",", "arg", ")", ",", "'a'", ")", "as", "f", ":", "\n", "                    ", "f", ".", "write", "(", "'%d: %s\\n'", "%", "(", "itr", ",", "self", ".", "logstyle", "%", "kwargs", "[", "arg", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.init_distribution": [[1198, 1205], ["None"], "methods", ["None"], ["    ", "def", "init_distribution", "(", "self", ",", "dist_type", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "dist_type", "=", "dist_type", "\n", "self", ".", "dist_kwargs", "=", "kwargs", "\n", "if", "self", ".", "dist_type", "==", "'normal'", ":", "\n", "            ", "self", ".", "mean", ",", "self", ".", "var", "=", "kwargs", "[", "'mean'", "]", ",", "kwargs", "[", "'var'", "]", "\n", "", "elif", "self", ".", "dist_type", "==", "'categorical'", ":", "\n", "            ", "self", ".", "num_categories", "=", "kwargs", "[", "'num_categories'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.sample_": [[1206, 1211], ["utils.Distribution.normal_", "utils.Distribution.random_"], "methods", ["None"], ["", "", "def", "sample_", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "dist_type", "==", "'normal'", ":", "\n", "            ", "self", ".", "normal_", "(", "self", ".", "mean", ",", "self", ".", "var", ")", "\n", "", "elif", "self", ".", "dist_type", "==", "'categorical'", ":", "\n", "            ", "self", ".", "random_", "(", "0", ",", "self", ".", "num_categories", ")", "\n", "# return self.variable", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to": [[1215, 1220], ["utils.Distribution", "utils.Distribution.init_distribution", "super().to"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.init_distribution", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to"], ["", "", "def", "to", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "new_obj", "=", "Distribution", "(", "self", ")", "\n", "new_obj", ".", "init_distribution", "(", "self", ".", "dist_type", ",", "**", "self", ".", "dist_kwargs", ")", "\n", "new_obj", ".", "data", "=", "super", "(", ")", ".", "to", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "new_obj", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Adam16.__init__": [[1282, 1287], ["dict", "list", "torch.optim.optimizer.Optimizer.__init__"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-8", ",", "weight_decay", "=", "0", ")", ":", "\n", "        ", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "\n", "weight_decay", "=", "weight_decay", ")", "\n", "params", "=", "list", "(", "params", ")", "\n", "super", "(", "Adam16", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Adam16.load_state_dict": [[1289, 1296], ["super().load_state_dict", "[].float", "[].float", "[].float"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Adam16.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "super", "(", "Adam16", ",", "self", ")", ".", "load_state_dict", "(", "state_dict", ")", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "self", ".", "state", "[", "p", "]", "[", "'exp_avg'", "]", "=", "self", ".", "state", "[", "p", "]", "[", "'exp_avg'", "]", ".", "float", "(", ")", "\n", "self", ".", "state", "[", "p", "]", "[", "'exp_avg_sq'", "]", "=", "self", ".", "state", "[", "p", "]", "[", "'exp_avg_sq'", "]", ".", "float", "(", ")", "\n", "self", ".", "state", "[", "p", "]", "[", "'fp32_p'", "]", "=", "self", ".", "state", "[", "p", "]", "[", "'fp32_p'", "]", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Adam16.step": [[1297, 1348], ["closure", "p.grad.data.float", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "exp_avg_sq.sqrt().add_", "state[].addcdiv_", "state[].half", "len", "grad.add.add.new().resize_as_().zero_", "grad.add.add.new().resize_as_().zero_", "p.data.float", "grad.add.add.add", "exp_avg.mul_", "exp_avg_sq.mul_", "exp_avg_sq.sqrt", "math.sqrt", "grad.add.add.new().resize_as_", "grad.add.add.new().resize_as_", "grad.add.add.new", "grad.add.add.new"], "methods", ["None"], ["", "", "", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n        Arguments:\n          closure (callable, optional): A closure that reevaluates the model\n            and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", ".", "float", "(", ")", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'exp_avg'", "]", "=", "grad", ".", "new", "(", ")", ".", "resize_as_", "(", "grad", ")", ".", "zero_", "(", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "grad", ".", "new", "(", ")", ".", "resize_as_", "(", "grad", ")", ".", "zero_", "(", ")", "\n", "# Fp32 copy of the weights", "\n", "state", "[", "'fp32_p'", "]", "=", "p", ".", "data", ".", "float", "(", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "                    ", "grad", "=", "grad", ".", "add", "(", "group", "[", "'weight_decay'", "]", ",", "state", "[", "'fp32_p'", "]", ")", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "\n", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "\n", "bias_correction1", "=", "1", "-", "beta1", "**", "state", "[", "'step'", "]", "\n", "bias_correction2", "=", "1", "-", "beta2", "**", "state", "[", "'step'", "]", "\n", "step_size", "=", "group", "[", "'lr'", "]", "*", "math", ".", "sqrt", "(", "bias_correction2", ")", "/", "bias_correction1", "\n", "\n", "state", "[", "'fp32_p'", "]", ".", "addcdiv_", "(", "-", "step_size", ",", "exp_avg", ",", "denom", ")", "\n", "p", ".", "data", "=", "state", "[", "'fp32_p'", "]", ".", "half", "(", ")", "\n", "\n", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.prepare_parser": [[34, 418], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "prepare_parser", "(", ")", ":", "\n", "    ", "usage", "=", "'Parser for all scripts.'", "\n", "parser", "=", "ArgumentParser", "(", "description", "=", "usage", ")", "\n", "\n", "### Dataset/Dataloader stuff ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--dataset'", ",", "type", "=", "str", ",", "default", "=", "'I128_hdf5'", ",", "\n", "help", "=", "'Which Dataset to train on, out of I128, I256, C10, C100;'", "\n", "'Append \"_hdf5\" to use the hdf5 version for ISLVRC '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--augment'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Augment with random crops and flips (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_workers'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "'Number of dataloader workers; consider using less for HDF5 '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--no_pin_memory'", ",", "action", "=", "'store_false'", ",", "dest", "=", "'pin_memory'", ",", "default", "=", "True", ",", "\n", "help", "=", "'Pin data into memory through dataloader? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--shuffle'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Shuffle the data (strongly recommended)? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--load_in_mem'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Load all data into memory? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--use_multiepoch_sampler'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Use the multi-epoch sampler for dataloader? (default: %(default)s)'", ")", "\n", "\n", "# loss selection argument", "\n", "parser", ".", "add_argument", "(", "\n", "'--loss_type'", ",", "type", "=", "str", ",", "default", "=", "'hinge'", ",", "\n", "help", "=", "'use what type of loss'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--alpha'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "'alpha'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--rot_angle'", ",", "type", "=", "int", ",", "default", "=", "60", ",", "\n", "help", "=", "'Rotation angle'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--curriculum_epochs'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "'epochs after which to switch'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--beta'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "'iterations of bayesian'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--curriculum_baseline'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'whether to use baseline for the curriculum learning'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--other_dataset'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'whether to use other dataset'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--logp'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'whether to compute logp'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--eps'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "'iterations of bayesian'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--iters'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "'iterations of bayesian'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--data_type'", ",", "type", "=", "str", ",", "default", "=", "'all'", ",", "\n", "help", "=", "'data for which to calculate logp'", ")", "\n", "\n", "### Model stuff ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--model'", ",", "type", "=", "str", ",", "default", "=", "'BigGAN'", ",", "\n", "help", "=", "'Name of the model module (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_param'", ",", "type", "=", "str", ",", "default", "=", "'SN'", ",", "\n", "help", "=", "'Parameterization style to use for G, spectral norm (SN) or SVD (SVD)'", "\n", "' or None (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_param'", ",", "type", "=", "str", ",", "default", "=", "'SN'", ",", "\n", "help", "=", "'Parameterization style to use for D, spectral norm (SN) or SVD (SVD)'", "\n", "' or None (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_ch'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'Channel multiplier for G (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_ch'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'Channel multiplier for D (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_depth'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of resblocks per stage in G? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_depth'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of resblocks per stage in D? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_thin'", ",", "action", "=", "'store_false'", ",", "dest", "=", "'D_wide'", ",", "default", "=", "True", ",", "\n", "help", "=", "'Use the SN-GAN channel pattern for D? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_shared'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Use shared embeddings in G? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--shared_dim'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'G'", "'s shared embedding dimensionality; if 0, will be equal to dim_z. '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--dim_z'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "\n", "help", "=", "'Noise dimensionality: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--z_var'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "'Noise variance: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--hier'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Use hierarchical z in G? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cross_replica'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Cross_replica batchnorm in G?(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--mybn'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Use my batchnorm (which supports standing stats?) %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_nl'", ",", "type", "=", "str", ",", "default", "=", "'relu'", ",", "\n", "help", "=", "'Activation function for G (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_nl'", ",", "type", "=", "str", ",", "default", "=", "'relu'", ",", "\n", "help", "=", "'Activation function for D (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_attn'", ",", "type", "=", "str", ",", "default", "=", "'64'", ",", "\n", "help", "=", "'What resolutions to use attention on for G (underscore separated) '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_attn'", ",", "type", "=", "str", ",", "default", "=", "'64'", ",", "\n", "help", "=", "'What resolutions to use attention on for D (underscore separated) '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--norm_style'", ",", "type", "=", "str", ",", "default", "=", "'bn'", ",", "\n", "help", "=", "'Normalizer style for G, one of bn [batchnorm], in [instancenorm], '", "\n", "'ln [layernorm], gn [groupnorm] (default: %(default)s)'", ")", "\n", "\n", "### Model init stuff ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Random seed to use; affects both initialization and '", "\n", "' dataloading. (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_init'", ",", "type", "=", "str", ",", "default", "=", "'ortho'", ",", "\n", "help", "=", "'Init style to use for G (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_init'", ",", "type", "=", "str", ",", "default", "=", "'ortho'", ",", "\n", "help", "=", "'Init style to use for D(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--skip_init'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Skip initialization, ideal for testing when ortho init was used '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--conditional'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'run unconditional BigGAN'", ")", "\n", "\n", "### Optimizer stuff ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_lr'", ",", "type", "=", "float", ",", "default", "=", "5e-5", ",", "\n", "help", "=", "'Learning rate to use for Generator (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_lr'", ",", "type", "=", "float", ",", "default", "=", "2e-4", ",", "\n", "help", "=", "'Learning rate to use for Discriminator (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_B1'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "'Beta1 to use for Generator (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_B1'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "'Beta1 to use for Discriminator (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_B2'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "\n", "help", "=", "'Beta2 to use for Generator (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_B2'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "\n", "help", "=", "'Beta2 to use for Discriminator (default: %(default)s)'", ")", "\n", "\n", "### Batch size, parallel, and precision stuff ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'Default overall batchsize (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_batch_size'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Batch size to use for G; if 0, same as D (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_G_accumulations'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of passes to accumulate G'", "'s gradients over '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_D_steps'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'Number of D steps per G step (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_D_accumulations'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of passes to accumulate D'", "'s gradients over '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--split_D'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Run D twice rather than concatenating inputs? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_epochs'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "'Number of epochs to train for (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--parallel'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Train with multiple GPUs (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_fp16'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Train with half-precision in G? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_fp16'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Train with half-precision in D? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_mixed_precision'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Train with half-precision activations but fp32 params in D? '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_mixed_precision'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Train with half-precision activations but fp32 params in G? '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--accumulate_stats'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Accumulate \"standing\" batchnorm stats? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_standing_accumulations'", ",", "type", "=", "int", ",", "default", "=", "16", ",", "\n", "help", "=", "'Number of forward passes to use in accumulating standing stats? '", "\n", "'(default: %(default)s)'", ")", "\n", "\n", "### Bookkeping stuff ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_eval_mode'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Run G in eval mode (running/standing stats?) at sample/test time? '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--save_every'", ",", "type", "=", "int", ",", "default", "=", "2000", ",", "\n", "help", "=", "'Save every X iterations (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_save_copies'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'How many copies to save (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_best_copies'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'How many previous best checkpoints to save (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--which_best'", ",", "type", "=", "str", ",", "default", "=", "'FID'", ",", "\n", "help", "=", "'Which metric to use to determine when to save new \"best\"'", "\n", "'checkpoints, one of IS or FID (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--no_fid'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Calculate IS only, not FID? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "'--start_eval'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "'number of epochs after the model begins evaluation.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--test_every'", ",", "type", "=", "int", ",", "default", "=", "5000", ",", "\n", "help", "=", "'Test every X iterations (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "# CHANGED FROM 50000 to 10000", "\n", "'--num_inception_images'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "'Number of samples to compute inception metrics with '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--hashname'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Use a hash of the experiment name instead of the full config '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--base_root'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'Default location to store all weights, samples, data, and logs '", "\n", "' (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--data_root'", ",", "type", "=", "str", ",", "default", "=", "'data'", ",", "\n", "help", "=", "'Default location where data is stored (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--weights_root'", ",", "type", "=", "str", ",", "default", "=", "'weights'", ",", "\n", "help", "=", "'Default location to store weights (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--logs_root'", ",", "type", "=", "str", ",", "default", "=", "'logs'", ",", "\n", "help", "=", "'Default location to store logs (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--samples_root'", ",", "type", "=", "str", ",", "default", "=", "'samples'", ",", "\n", "help", "=", "'Default location to store samples (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--pbar'", ",", "type", "=", "str", ",", "default", "=", "'mine'", ",", "\n", "help", "=", "'Type of progressbar to use; one of \"mine\" or \"tqdm\" '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--name_suffix'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'Suffix for experiment name for loading weights for sampling '", "\n", "'(consider \"best0\") (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--experiment_name'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'Optionally override the automatic experiment naming with this arg. '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--config_from_name'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Use a hash of the experiment name instead of the full config '", "\n", "'(default: %(default)s)'", ")", "\n", "\n", "### EMA Stuff ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--ema'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Keep an ema of G'", "'s weights? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--ema_decay'", ",", "type", "=", "float", ",", "default", "=", "0.9999", ",", "\n", "help", "=", "'EMA decay rate (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--use_ema'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Use the EMA parameters of G for evaluation? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--ema_start'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'When to start updating the EMA weights (default: %(default)s)'", ")", "\n", "\n", "### Numerical precision and SV stuff ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--adam_eps'", ",", "type", "=", "float", ",", "default", "=", "1e-8", ",", "\n", "help", "=", "'epsilon value to use for Adam (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--BN_eps'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ",", "\n", "help", "=", "'epsilon value to use for BatchNorm (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--SN_eps'", ",", "type", "=", "float", ",", "default", "=", "1e-8", ",", "\n", "help", "=", "'epsilon value to use for Spectral Norm(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_G_SVs'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of SVs to track in G (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_D_SVs'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of SVs to track in D (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_G_SV_itrs'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of SV itrs in G (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_D_SV_itrs'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of SV itrs in D (default: %(default)s)'", ")", "\n", "\n", "### Ortho reg stuff ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_ortho'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "# 1e-4 is default for BigGAN", "\n", "help", "=", "'Modified ortho reg coefficient in G(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_ortho'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "'Modified ortho reg coefficient in D (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--toggle_grads'", ",", "action", "=", "'store_true'", ",", "default", "=", "True", ",", "\n", "help", "=", "'Toggle D and G'", "'s \"requires_grad\" settings when not training them? '", "\n", "' (default: %(default)s)'", ")", "\n", "\n", "### Which train function ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--which_train_fn'", ",", "type", "=", "str", ",", "default", "=", "'GAN'", ",", "\n", "help", "=", "'How2trainyourbois (default: %(default)s)'", ")", "\n", "\n", "# Resume training stuff", "\n", "parser", ".", "add_argument", "(", "\n", "'--load_weights'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'Suffix for which weights to load (e.g. best0, copy0) '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--resume'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Resume training? (default: %(default)s)'", ")", "\n", "\n", "### Log stuff ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--logstyle'", ",", "type", "=", "str", ",", "default", "=", "'%3.3e'", ",", "\n", "help", "=", "'What style to use when logging training metrics?'", "\n", "'One of: %#.#f/ %#.#e (float/exp, text),'", "\n", "'pickle (python pickle),'", "\n", "'npz (numpy zip),'", "\n", "'mat (MATLAB .mat file) (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--log_G_spectra'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Log the top 3 singular values in each SN layer in G? '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--log_D_spectra'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Log the top 3 singular values in each SN layer in D? '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--sv_log_interval'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "'Iteration interval for logging singular values '", "\n", "' (default: %(default)s)'", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.add_sample_parser": [[422, 459], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "def", "add_sample_parser", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "\n", "'--sample_npz'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Sample \"sample_num_npz\" images and save to npz? '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "# CHANGED FROM 50000 to 10000", "\n", "'--sample_num_npz'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "'Number of images to sample when sampling NPZs '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--sample_sheets'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Produce class-conditional sample sheets and stick them in '", "\n", "'the samples root? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--sample_interps'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Produce interpolation sheets and stick them in '", "\n", "'the samples root? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--sample_sheet_folder_num'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Number to use for the folder for these sample sheets '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--sample_random'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Produce a single random sheet? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--sample_trunc_curves'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'Get inception metrics with a range of variances?'", "\n", "'To use this, specify a startpoint, step, and endpoint, e.g. '", "\n", "'--sample_trunc_curves 0.2_0.1_1.0 for a startpoint of 0.2, '", "\n", "'endpoint of 1.0, and stepsize of 1.0.  Note that this is '", "\n", "'not exactly identical to using tf.truncated_normal, but should '", "\n", "'have approximately the same effect. (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--sample_inception_metrics'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Calculate Inception metrics with sample.py? (default: %(default)s)'", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.get_data_loaders": [[588, 664], ["print", "which_dataset", "loaders.append", "torchvision.Compose", "print", "utils.MultiEpochSampler", "torch.utils.data.DataLoader", "print", "torch.utils.data.DataLoader", "print", "print", "torchvision.RandomHorizontalFlip", "torchvision.Resize", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.CenterCrop", "torchvision.Resize", "torchvision.RandomHorizontalFlip", "utils.RandomCropLongEdge", "torchvision.Resize", "torchvision.RandomHorizontalFlip", "torchvision.CenterCrop", "torchvision.Resize", "torchvision.CenterCrop", "torchvision.Resize", "torchvision.Resize", "utils.CenterCropLongEdge", "torchvision.Resize"], "function", ["None"], ["", "", "def", "get_data_loaders", "(", "dataset", ",", "data_root", "=", "None", ",", "augment", "=", "False", ",", "batch_size", "=", "64", ",", "\n", "num_workers", "=", "8", ",", "shuffle", "=", "True", ",", "load_in_mem", "=", "False", ",", "hdf5", "=", "False", ",", "\n", "pin_memory", "=", "True", ",", "drop_last", "=", "True", ",", "start_itr", "=", "0", ",", "\n", "num_epochs", "=", "500", ",", "use_multiepoch_sampler", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "# Append /FILENAME.hdf5 to root if using hdf5", "\n", "    ", "data_root", "+=", "'/%s'", "%", "root_dict", "[", "dataset", "]", "\n", "print", "(", "'Using dataset root location %s'", "%", "data_root", ")", "\n", "\n", "which_dataset", "=", "dset_dict", "[", "dataset", "]", "\n", "norm_mean", "=", "[", "0.5", ",", "0.5", ",", "0.5", "]", "\n", "norm_std", "=", "[", "0.5", ",", "0.5", ",", "0.5", "]", "\n", "image_size", "=", "imsize_dict", "[", "dataset", "]", "\n", "# For image folder datasets, name of the file where we store the precomputed", "\n", "# image locations to avoid having to walk the dirs every time we load.", "\n", "dataset_kwargs", "=", "{", "'index_filename'", ":", "'%s_imgs.npz'", "%", "dataset", "}", "\n", "\n", "# HDF5 datasets have their own inbuilt transform, no need to train_transform", "\n", "if", "'hdf5'", "in", "dataset", ":", "\n", "        ", "train_transform", "=", "None", "\n", "", "else", ":", "\n", "        ", "if", "augment", ":", "\n", "            ", "print", "(", "'Data will be augmented...'", ")", "\n", "if", "dataset", "in", "[", "'C10'", ",", "'C100'", ",", "'CINIC10'", ",", "'STL10'", ",", "'C10U'", "]", ":", "\n", "#train_transform = [transforms.RandomCrop(32, padding=4),", "\n", "#                   transforms.RandomHorizontalFlip()]", "\n", "                ", "train_transform", "=", "[", "transforms", ".", "RandomHorizontalFlip", "(", ")", "]", "\n", "", "elif", "dataset", "in", "[", "'CelebA'", "]", ":", "\n", "                ", "train_transform", "=", "[", "transforms", ".", "CenterCrop", "(", "140", ")", ",", "\n", "transforms", ".", "Resize", "(", "image_size", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "train_transform", "=", "[", "RandomCropLongEdge", "(", ")", ",", "\n", "transforms", ".", "Resize", "(", "image_size", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", "]", "\n", "", "", "else", ":", "\n", "            ", "print", "(", "'Data will not be augmented...'", ")", "\n", "if", "dataset", "in", "[", "'C10'", ",", "'C100'", ",", "'CINIC10'", ",", "'STL10'", ",", "'C10U'", "]", ":", "\n", "                ", "train_transform", "=", "[", "transforms", ".", "Resize", "(", "image_size", ")", "]", "\n", "", "elif", "dataset", "in", "[", "'CelebA'", "]", ":", "\n", "                ", "train_transform", "=", "[", "transforms", ".", "CenterCrop", "(", "140", ")", ",", "\n", "transforms", ".", "Resize", "(", "image_size", ")", "]", "\n", "", "elif", "dataset", "in", "[", "'CA64'", "]", ":", "\n", "                ", "train_transform", "=", "[", "transforms", ".", "CenterCrop", "(", "140", ")", ",", "\n", "transforms", ".", "Resize", "(", "image_size", ")", "]", "\n", "", "elif", "dataset", "in", "[", "'CAHQ_64'", ",", "'CAHQ_128'", "]", ":", "\n", "                ", "train_transform", "=", "[", "transforms", ".", "Resize", "(", "image_size", ")", "]", "\n", "", "else", ":", "\n", "                ", "train_transform", "=", "[", "\n", "CenterCropLongEdge", "(", ")", ",", "transforms", ".", "Resize", "(", "image_size", ")", "]", "\n", "# train_transform = [transforms.Resize(image_size), transforms.CenterCrop]", "\n", "", "", "train_transform", "=", "transforms", ".", "Compose", "(", "train_transform", "+", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "norm_mean", ",", "norm_std", ")", "]", ")", "\n", "", "train_set", "=", "which_dataset", "(", "root", "=", "data_root", ",", "transform", "=", "train_transform", ",", "\n", "load_in_mem", "=", "load_in_mem", ",", "**", "dataset_kwargs", ")", "\n", "\n", "# Prepare loader; the loaders list is for forward compatibility with", "\n", "# using validation / test splits.", "\n", "loaders", "=", "[", "]", "\n", "if", "use_multiepoch_sampler", ":", "\n", "        ", "print", "(", "'Using multiepoch sampler from start_itr %d...'", "%", "start_itr", ")", "\n", "loader_kwargs", "=", "{", "'num_workers'", ":", "num_workers", ",", "'pin_memory'", ":", "pin_memory", "}", "\n", "sampler", "=", "MultiEpochSampler", "(", "\n", "train_set", ",", "num_epochs", ",", "start_itr", ",", "batch_size", ")", "\n", "train_loader", "=", "DataLoader", "(", "train_set", ",", "batch_size", "=", "batch_size", ",", "\n", "sampler", "=", "sampler", ",", "**", "loader_kwargs", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'shuffle '", ",", "shuffle", ",", "' batch_size '", ",", "batch_size", ",", "' num_workers '", ",", "num_workers", ",", "' pin_memory '", ",", "pin_memory", ")", "\n", "loader_kwargs", "=", "{", "'num_workers'", ":", "num_workers", ",", "'pin_memory'", ":", "pin_memory", ",", "\n", "'drop_last'", ":", "drop_last", "}", "# Default, drop last incomplete batch", "\n", "train_loader", "=", "DataLoader", "(", "train_set", ",", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "shuffle", ",", "**", "loader_kwargs", ")", "\n", "", "loaders", ".", "append", "(", "train_loader", ")", "\n", "return", "loaders", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.seed_rng": [[667, 671], ["torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "numpy.random.seed"], "function", ["None"], ["", "def", "seed_rng", "(", "seed", ")", ":", "\n", "    ", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.update_config_roots": [[675, 681], ["print"], "function", ["None"], ["", "def", "update_config_roots", "(", "config", ")", ":", "\n", "    ", "if", "config", "[", "'base_root'", "]", ":", "\n", "        ", "print", "(", "'Pegging all root folders to base root %s'", "%", "config", "[", "'base_root'", "]", ")", "\n", "for", "key", "in", "[", "'data'", ",", "'weights'", ",", "'logs'", ",", "'samples'", "]", ":", "\n", "            ", "config", "[", "'%s_root'", "%", "key", "]", "=", "'%s/%s'", "%", "(", "config", "[", "'base_root'", "]", ",", "key", ")", "\n", "", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.prepare_root": [[684, 689], ["os.path.exists", "print", "os.mkdir"], "function", ["None"], ["", "def", "prepare_root", "(", "config", ")", ":", "\n", "    ", "for", "key", "in", "[", "'weights_root'", ",", "'logs_root'", ",", "'samples_root'", "]", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "config", "[", "key", "]", ")", ":", "\n", "            ", "print", "(", "'Making directory %s for %s...'", "%", "(", "config", "[", "key", "]", ",", "key", ")", ")", "\n", "os", ".", "mkdir", "(", "config", "[", "key", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.ortho": [[726, 736], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "model.parameters", "param.view", "any", "torch.mm", "torch.mm", "torch.mm", "grad.view", "len", "torch.mm", "torch.mm", "torch.mm", "param.view.t", "torch.eye", "torch.eye", "torch.eye"], "function", ["None"], ["", "", "", "", "def", "ortho", "(", "model", ",", "strength", "=", "1e-4", ",", "blacklist", "=", "[", "]", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "# Only apply this to parameters with at least 2 axes, and not in the blacklist", "\n", "            ", "if", "len", "(", "param", ".", "shape", ")", "<", "2", "or", "any", "(", "[", "param", "is", "item", "for", "item", "in", "blacklist", "]", ")", ":", "\n", "                ", "continue", "\n", "", "w", "=", "param", ".", "view", "(", "param", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "grad", "=", "(", "2", "*", "torch", ".", "mm", "(", "torch", ".", "mm", "(", "w", ",", "w", ".", "t", "(", ")", ")", "\n", "*", "(", "1.", "-", "torch", ".", "eye", "(", "w", ".", "shape", "[", "0", "]", ",", "device", "=", "w", ".", "device", ")", ")", ",", "w", ")", ")", "\n", "param", ".", "grad", ".", "data", "+=", "strength", "*", "grad", ".", "view", "(", "param", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.default_ortho": [[741, 751], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "model.parameters", "param.view", "torch.mm", "torch.mm", "torch.mm", "grad.view", "len", "torch.mm", "torch.mm", "torch.mm", "torch.eye", "torch.eye", "torch.eye", "param.view.t"], "function", ["None"], ["", "", "", "def", "default_ortho", "(", "model", ",", "strength", "=", "1e-4", ",", "blacklist", "=", "[", "]", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "# Only apply this to parameters with at least 2 axes & not in blacklist", "\n", "            ", "if", "len", "(", "param", ".", "shape", ")", "<", "2", "or", "param", "in", "blacklist", ":", "\n", "                ", "continue", "\n", "", "w", "=", "param", ".", "view", "(", "param", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "grad", "=", "(", "2", "*", "torch", ".", "mm", "(", "torch", ".", "mm", "(", "w", ",", "w", ".", "t", "(", ")", ")", "\n", "-", "torch", ".", "eye", "(", "w", ".", "shape", "[", "0", "]", ",", "device", "=", "w", ".", "device", ")", ",", "w", ")", ")", "\n", "param", ".", "grad", ".", "data", "+=", "strength", "*", "grad", ".", "view", "(", "param", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.toggle_grad": [[754, 757], ["model.parameters"], "function", ["None"], ["", "", "", "def", "toggle_grad", "(", "model", ",", "on_or_off", ")", ":", "\n", "    ", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "param", ".", "requires_grad", "=", "on_or_off", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.join_strings": [[762, 764], ["base_string.join"], "function", ["None"], ["", "", "def", "join_strings", "(", "base_string", ",", "strings", ")", ":", "\n", "    ", "return", "base_string", ".", "join", "(", "[", "item", "for", "item", "in", "strings", "if", "item", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.save_weights": [[767, 789], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "os.path.exists", "os.mkdir", "print", "print", "G.state_dict", "G.optim.state_dict", "D.state_dict", "D.optim.state_dict", "torch.save", "torch.save", "torch.save", "G_ema.state_dict", "utils.join_strings", "utils.join_strings", "utils.join_strings", "utils.join_strings", "utils.join_strings", "utils.join_strings"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.join_strings", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.join_strings", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.join_strings", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.join_strings", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.join_strings", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.join_strings"], ["", "def", "save_weights", "(", "G", ",", "D", ",", "state_dict", ",", "weights_root", ",", "experiment_name", ",", "\n", "name_suffix", "=", "None", ",", "G_ema", "=", "None", ")", ":", "\n", "    ", "root", "=", "'/'", ".", "join", "(", "[", "weights_root", ",", "experiment_name", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "root", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "root", ")", "\n", "", "if", "name_suffix", ":", "\n", "        ", "print", "(", "'Saving weights to %s/%s...'", "%", "(", "root", ",", "name_suffix", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Saving weights to %s...'", "%", "root", ")", "\n", "", "torch", ".", "save", "(", "G", ".", "state_dict", "(", ")", ",", "\n", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'G'", ",", "name_suffix", "]", ")", ")", ")", "\n", "torch", ".", "save", "(", "G", ".", "optim", ".", "state_dict", "(", ")", ",", "\n", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'G_optim'", ",", "name_suffix", "]", ")", ")", ")", "\n", "torch", ".", "save", "(", "D", ".", "state_dict", "(", ")", ",", "\n", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'D'", ",", "name_suffix", "]", ")", ")", ")", "\n", "torch", ".", "save", "(", "D", ".", "optim", ".", "state_dict", "(", ")", ",", "\n", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'D_optim'", ",", "name_suffix", "]", ")", ")", ")", "\n", "torch", ".", "save", "(", "state_dict", ",", "\n", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'state_dict'", ",", "name_suffix", "]", ")", ")", ")", "\n", "if", "G_ema", "is", "not", "None", ":", "\n", "        ", "torch", ".", "save", "(", "G_ema", ".", "state_dict", "(", ")", ",", "\n", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'G_ema'", ",", "name_suffix", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.load_weights": [[792, 824], ["print", "print", "G.load_state_dict", "D.load_state_dict", "G_ema.load_state_dict", "torch.load", "torch.load", "torch.load", "G.optim.load_state_dict", "torch.load", "torch.load", "torch.load", "D.optim.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "utils.join_strings", "utils.join_strings", "utils.join_strings", "utils.join_strings", "utils.join_strings", "utils.join_strings"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Adam16.load_state_dict", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Adam16.load_state_dict", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Adam16.load_state_dict", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Adam16.load_state_dict", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Adam16.load_state_dict", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.join_strings", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.join_strings", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.join_strings", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.join_strings", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.join_strings", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.join_strings"], ["", "", "def", "load_weights", "(", "G", ",", "D", ",", "state_dict", ",", "weights_root", ",", "experiment_name", ",", "\n", "name_suffix", "=", "None", ",", "G_ema", "=", "None", ",", "strict", "=", "True", ",", "load_optim", "=", "True", ")", ":", "\n", "    ", "root", "=", "'/'", ".", "join", "(", "[", "weights_root", ",", "experiment_name", "]", ")", "\n", "if", "name_suffix", ":", "\n", "        ", "print", "(", "'Loading %s weights from %s...'", "%", "(", "name_suffix", ",", "root", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Loading weights from %s...'", "%", "root", ")", "\n", "", "if", "G", "is", "not", "None", ":", "\n", "        ", "G", ".", "load_state_dict", "(", "\n", "torch", ".", "load", "(", "'%s/%s.pth'", "%", "\n", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'G'", ",", "name_suffix", "]", ")", ")", ")", ",", "\n", "strict", "=", "strict", ")", "\n", "if", "load_optim", ":", "\n", "            ", "G", ".", "optim", ".", "load_state_dict", "(", "\n", "torch", ".", "load", "(", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'G_optim'", ",", "name_suffix", "]", ")", ")", ")", ")", "\n", "", "", "if", "D", "is", "not", "None", ":", "\n", "        ", "D", ".", "load_state_dict", "(", "\n", "torch", ".", "load", "(", "'%s/%s.pth'", "%", "\n", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'D'", ",", "name_suffix", "]", ")", ")", ")", ",", "\n", "strict", "=", "strict", ")", "\n", "if", "load_optim", ":", "\n", "            ", "D", ".", "optim", ".", "load_state_dict", "(", "\n", "torch", ".", "load", "(", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'D_optim'", ",", "name_suffix", "]", ")", ")", ")", ")", "\n", "# Load state dict", "\n", "", "", "for", "item", "in", "state_dict", ":", "\n", "        ", "state_dict", "[", "item", "]", "=", "torch", ".", "load", "(", "\n", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'state_dict'", ",", "name_suffix", "]", ")", ")", ")", "[", "item", "]", "\n", "", "if", "G_ema", "is", "not", "None", ":", "\n", "        ", "G_ema", ".", "load_state_dict", "(", "\n", "torch", ".", "load", "(", "'%s/%s.pth'", "%", "\n", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'G_ema'", ",", "name_suffix", "]", ")", ")", ")", ",", "\n", "strict", "=", "strict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.write_metadata": [[898, 904], ["open", "writefile.write", "writefile.write", "writefile.write", "str", "str", "str", "datetime.datetime.now"], "function", ["None"], ["", "", "", "", "", "def", "write_metadata", "(", "logs_root", ",", "experiment_name", ",", "config", ",", "state_dict", ")", ":", "\n", "    ", "with", "open", "(", "(", "'%s/%s/metalog.txt'", "%", "\n", "(", "logs_root", ",", "experiment_name", ")", ")", ",", "'w'", ")", "as", "writefile", ":", "\n", "        ", "writefile", ".", "write", "(", "'datetime: %s\\n'", "%", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "writefile", ".", "write", "(", "'config: %s\\n'", "%", "str", "(", "config", ")", ")", "\n", "writefile", ".", "write", "(", "'state: %s\\n'", "%", "str", "(", "state_dict", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.progress": [[915, 955], ["time.time", "enumerate", "print", "len", "time.time", "time.time", "print", "sys.stdout.flush", "divmod", "print", "print", "list", "list", "list", "list", "divmod", "divmod", "tuple", "divmod", "divmod", "tuple", "float"], "function", ["None"], ["def", "progress", "(", "items", ",", "desc", "=", "''", ",", "total", "=", "None", ",", "min_delay", "=", "0.1", ",", "displaytype", "=", "'s1k'", ")", ":", "\n", "    ", "\"\"\"\n    Returns a generator over `items`, printing the number and percentage of\n    items processed and the estimated remaining processing time before yielding\n    the next item. `total` gives the total number of items (required if `items`\n    has no length), and `min_delay` gives the minimum time in seconds between\n    subsequent prints. `desc` gives an optional prefix text (end with a space).\n    \"\"\"", "\n", "total", "=", "total", "or", "len", "(", "items", ")", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "t_last", "=", "0", "\n", "for", "n", ",", "item", "in", "enumerate", "(", "items", ")", ":", "\n", "        ", "t_now", "=", "time", ".", "time", "(", ")", "\n", "if", "t_now", "-", "t_last", ">", "min_delay", ":", "\n", "            ", "print", "(", "\"\\r%s%d/%d (%6.2f%%)\"", "%", "(", "\n", "desc", ",", "n", "+", "1", ",", "total", ",", "n", "/", "float", "(", "total", ")", "*", "100", ")", ",", "end", "=", "\" \"", ")", "\n", "if", "n", ">", "0", ":", "\n", "\n", "                ", "if", "displaytype", "==", "'s1k'", ":", "# minutes/seconds for 1000 iters", "\n", "                    ", "next_1000", "=", "n", "+", "(", "1000", "-", "n", "%", "1000", ")", "\n", "t_done", "=", "t_now", "-", "t_start", "\n", "t_1k", "=", "t_done", "/", "n", "*", "next_1000", "\n", "outlist", "=", "list", "(", "divmod", "(", "t_done", ",", "60", ")", ")", "+", "list", "(", "divmod", "(", "t_1k", "-", "t_done", ",", "60", ")", ")", "\n", "print", "(", "\"(TE/ET1k: %d:%02d / %d:%02d)\"", "%", "\n", "tuple", "(", "outlist", ")", ",", "end", "=", "\" \"", ")", "\n", "", "else", ":", "# displaytype == 'eta':", "\n", "                    ", "t_done", "=", "t_now", "-", "t_start", "\n", "t_total", "=", "t_done", "/", "n", "*", "total", "\n", "outlist", "=", "list", "(", "divmod", "(", "t_done", ",", "60", ")", ")", "+", "list", "(", "divmod", "(", "t_total", "-", "t_done", ",", "60", ")", ")", "\n", "print", "(", "\"(TE/ETA: %d:%02d / %d:%02d)\"", "%", "\n", "tuple", "(", "outlist", ")", ",", "end", "=", "\" \"", ")", "\n", "\n", "", "", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "t_last", "=", "t_now", "\n", "", "yield", "item", "\n", "", "t_total", "=", "time", ".", "time", "(", ")", "-", "t_start", "\n", "print", "(", "\"\\r%s%d/%d (100.00%%) (took %d:%02d)\"", "%", "(", "(", "desc", ",", "total", ",", "total", ")", "+", "\n", "divmod", "(", "t_total", ",", "60", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.sample": [[958, 967], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "z_.sample_", "y_.sample_", "torch.parallel.data_parallel", "G", "G.shared", "G.shared"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.sample_"], ["", "def", "sample", "(", "G", ",", "z_", ",", "y_", ",", "config", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "z_", ".", "sample_", "(", ")", "\n", "y_", ".", "sample_", "(", ")", "\n", "if", "config", "[", "'parallel'", "]", ":", "\n", "            ", "G_z", "=", "nn", ".", "parallel", ".", "data_parallel", "(", "G", ",", "(", "z_", ",", "G", ".", "shared", "(", "y_", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "G_z", "=", "G", "(", "z_", ",", "G", ".", "shared", "(", "y_", ")", ")", "\n", "", "return", "G_z", ",", "y_", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.sample_inception": [[969, 1003], ["max", "utils.prepare_z_y", "functools.partial", "print", "tqdm.trange", "print", "print", "numpy.savez", "utils.name_from_config", "os.path.isdir", "os.mkdir", "int", "numpy.concatenate", "numpy.concatenate", "numpy.ceil", "torch.no_grad", "torch.no_grad", "torch.no_grad", "functools.partial.", "numpy.uint8", "labels.cpu().numpy", "float", "labels.cpu", "images.cpu().numpy", "images.cpu"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.prepare_z_y", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.name_from_config"], ["", "", "def", "sample_inception", "(", "G_ema", ",", "config", ",", "folder_number", ")", ":", "\n", "# CHANGED FROM 50000 to 10000", "\n", "    ", "if", "config", "[", "'dataset'", "]", "in", "[", "'CAHQ_64'", ",", "'CAHQ_128'", "]", ":", "\n", "        ", "config", "[", "'sample_num_npz'", "]", "=", "3000", "\n", "", "else", ":", "\n", "        ", "config", "[", "'sample_num_npz'", "]", "=", "10000", "\n", "", "experiment_name", "=", "(", "config", "[", "'experiment_name'", "]", "if", "config", "[", "'experiment_name'", "]", "\n", "else", "name_from_config", "(", "config", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "'%s/%s/%s'", "%", "(", "config", "[", "'samples_root'", "]", ",", "experiment_name", ",", "folder_number", ")", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "'%s/%s/%s'", "%", "\n", "(", "config", "[", "'samples_root'", "]", ",", "experiment_name", ",", "folder_number", ")", ")", "\n", "", "import", "functools", "\n", "device", "=", "'cuda'", "\n", "G_batch_size", "=", "max", "(", "config", "[", "'G_batch_size'", "]", ",", "config", "[", "'batch_size'", "]", ")", "\n", "z_", ",", "y_", "=", "prepare_z_y", "(", "G_batch_size", ",", "G_ema", ".", "dim_z", ",", "config", "[", "'n_classes'", "]", ",", "\n", "device", "=", "device", ",", "fp16", "=", "config", "[", "'G_fp16'", "]", ",", "\n", "z_var", "=", "config", "[", "'z_var'", "]", ")", "\n", "sample_", "=", "functools", ".", "partial", "(", "sample", ",", "G", "=", "G_ema", ",", "z_", "=", "z_", ",", "y_", "=", "y_", ",", "config", "=", "config", ")", "\n", "\n", "x", ",", "y", "=", "[", "]", ",", "[", "]", "\n", "print", "(", "'Sampling %d images and saving them to npz...'", "%", "\n", "config", "[", "'sample_num_npz'", "]", ")", "\n", "for", "i", "in", "trange", "(", "int", "(", "np", ".", "ceil", "(", "config", "[", "'sample_num_npz'", "]", "/", "float", "(", "G_batch_size", ")", ")", ")", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "images", ",", "labels", "=", "sample_", "(", ")", "\n", "", "x", "+=", "[", "np", ".", "uint8", "(", "255", "*", "(", "images", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "+", "1", ")", "/", "2.", ")", "]", "\n", "y", "+=", "[", "labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "]", "\n", "", "x", "=", "np", ".", "concatenate", "(", "x", ",", "0", ")", "[", ":", "config", "[", "'sample_num_npz'", "]", "]", "\n", "y", "=", "np", ".", "concatenate", "(", "y", ",", "0", ")", "[", ":", "config", "[", "'sample_num_npz'", "]", "]", "\n", "print", "(", "'Images shape: %s, Labels shape: %s'", "%", "(", "x", ".", "shape", ",", "y", ".", "shape", ")", ")", "\n", "npz_filename", "=", "'%s/%s/%s/samples.npz'", "%", "(", "\n", "config", "[", "'samples_root'", "]", ",", "experiment_name", ",", "folder_number", ")", "\n", "print", "(", "'Saving npz to %s...'", "%", "npz_filename", ")", "\n", "np", ".", "savez", "(", "npz_filename", ",", "**", "{", "'x'", ":", "x", ",", "'y'", ":", "y", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.sample_sheet": [[1006, 1039], ["range", "os.path.isdir", "os.mkdir", "os.path.isdir", "os.mkdir", "torch.arange", "torch.arange", "torch.arange", "range", "torch.stack().view().data.float().cpu", "torch.stack().view().data.float().cpu", "torch.stack().view().data.float().cpu", "torchvision.utils.save_image", "torchvision.utils.save_image", "hasattr", "torch.randn.sample_", "torch.randn", "torch.randn", "torch.randn", "torch.no_grad", "torch.no_grad", "torch.no_grad", "G.data.cpu", "torch.stack().view().data.float", "torch.stack().view().data.float", "torch.stack().view().data.float", "torch.randn.size", "torch.parallel.data_parallel", "G", "G.shared", "G.shared", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack", "torch.stack", "torch.stack"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.sample_"], ["", "def", "sample_sheet", "(", "G", ",", "classes_per_sheet", ",", "num_classes", ",", "samples_per_class", ",", "parallel", ",", "\n", "samples_root", ",", "experiment_name", ",", "folder_number", ",", "z_", "=", "None", ")", ":", "\n", "# Prepare sample directory", "\n", "    ", "if", "not", "os", ".", "path", ".", "isdir", "(", "'%s/%s'", "%", "(", "samples_root", ",", "experiment_name", ")", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "'%s/%s'", "%", "(", "samples_root", ",", "experiment_name", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "'%s/%s/%d'", "%", "(", "samples_root", ",", "experiment_name", ",", "folder_number", ")", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "'%s/%s/%d'", "%", "(", "samples_root", ",", "experiment_name", ",", "folder_number", ")", ")", "\n", "# loop over total number of sheets", "\n", "", "for", "i", "in", "range", "(", "num_classes", "//", "classes_per_sheet", ")", ":", "\n", "        ", "ims", "=", "[", "]", "\n", "y", "=", "torch", ".", "arange", "(", "i", "*", "classes_per_sheet", ",", "(", "i", "+", "1", ")", "*", "\n", "classes_per_sheet", ",", "device", "=", "'cuda'", ")", "\n", "for", "j", "in", "range", "(", "samples_per_class", ")", ":", "\n", "            ", "if", "(", "z_", "is", "not", "None", ")", "and", "hasattr", "(", "z_", ",", "'sample_'", ")", "and", "classes_per_sheet", "<=", "z_", ".", "size", "(", "0", ")", ":", "\n", "                ", "z_", ".", "sample_", "(", ")", "\n", "", "else", ":", "\n", "                ", "z_", "=", "torch", ".", "randn", "(", "classes_per_sheet", ",", "G", ".", "dim_z", ",", "device", "=", "'cuda'", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "if", "parallel", ":", "\n", "                    ", "o", "=", "nn", ".", "parallel", ".", "data_parallel", "(", "\n", "G", ",", "(", "z_", "[", ":", "classes_per_sheet", "]", ",", "G", ".", "shared", "(", "y", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "o", "=", "G", "(", "z_", "[", ":", "classes_per_sheet", "]", ",", "G", ".", "shared", "(", "y", ")", ")", "\n", "\n", "", "", "ims", "+=", "[", "o", ".", "data", ".", "cpu", "(", ")", "]", "\n", "# This line should properly unroll the images", "\n", "", "out_ims", "=", "torch", ".", "stack", "(", "ims", ",", "1", ")", ".", "view", "(", "-", "1", ",", "ims", "[", "0", "]", ".", "shape", "[", "1", "]", ",", "ims", "[", "0", "]", ".", "shape", "[", "2", "]", ",", "\n", "ims", "[", "0", "]", ".", "shape", "[", "3", "]", ")", ".", "data", ".", "float", "(", ")", ".", "cpu", "(", ")", "\n", "# The path for the samples", "\n", "image_filename", "=", "'%s/%s/%d/samples%d.jpg'", "%", "(", "samples_root", ",", "experiment_name", ",", "\n", "folder_number", ",", "i", ")", "\n", "torchvision", ".", "utils", ".", "save_image", "(", "out_ims", ",", "image_filename", ",", "\n", "nrow", "=", "samples_per_class", ",", "normalize", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.interp": [[1042, 1046], ["torch.linspace().to", "torch.linspace().to", "torch.linspace().to", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace().to.view", "torch.linspace().to.view"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to"], ["", "", "def", "interp", "(", "x0", ",", "x1", ",", "num_midpoints", ")", ":", "\n", "    ", "lerp", "=", "torch", ".", "linspace", "(", "0", ",", "1.0", ",", "num_midpoints", "+", "2", ",", "\n", "device", "=", "'cuda'", ")", ".", "to", "(", "x0", ".", "dtype", ")", "\n", "return", "(", "(", "x0", "*", "(", "1", "-", "lerp", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", ")", ")", "+", "(", "x1", "*", "lerp", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.interp_sheet": [[1050, 1085], ["torchvision.utils.save_image", "torchvision.utils.save_image", "torch.randn", "torch.randn", "torch.randn", "zs.half.repeat().view", "interp().view", "utils.sample_1hot", "G.shared().view", "interp().view.repeat().view", "interp().view", "zs.half.half", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.parallel.data_parallel().data.cpu", "G().data.cpu", "zs.half.repeat", "utils.interp", "G.shared", "interp().view.repeat", "utils.interp", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "G.shared().view", "G.shared().view", "torch.parallel.data_parallel", "G", "G.shared", "G.shared", "utils.sample_1hot", "utils.sample_1hot"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.sample_1hot", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.interp", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.interp", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.sample_1hot", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.sample_1hot"], ["", "def", "interp_sheet", "(", "G", ",", "num_per_sheet", ",", "num_midpoints", ",", "num_classes", ",", "parallel", ",", "\n", "samples_root", ",", "experiment_name", ",", "folder_number", ",", "sheet_number", "=", "0", ",", "\n", "fix_z", "=", "False", ",", "fix_y", "=", "False", ",", "device", "=", "'cuda'", ")", ":", "\n", "# Prepare zs and ys", "\n", "    ", "if", "fix_z", ":", "# If fix Z, only sample 1 z per row", "\n", "        ", "zs", "=", "torch", ".", "randn", "(", "num_per_sheet", ",", "1", ",", "G", ".", "dim_z", ",", "device", "=", "device", ")", "\n", "zs", "=", "zs", ".", "repeat", "(", "1", ",", "num_midpoints", "+", "2", ",", "1", ")", ".", "view", "(", "-", "1", ",", "G", ".", "dim_z", ")", "\n", "", "else", ":", "\n", "        ", "zs", "=", "interp", "(", "torch", ".", "randn", "(", "num_per_sheet", ",", "1", ",", "G", ".", "dim_z", ",", "device", "=", "device", ")", ",", "\n", "torch", ".", "randn", "(", "num_per_sheet", ",", "1", ",", "G", ".", "dim_z", ",", "device", "=", "device", ")", ",", "\n", "num_midpoints", ")", ".", "view", "(", "-", "1", ",", "G", ".", "dim_z", ")", "\n", "", "if", "fix_y", ":", "# If fix y, only sample 1 z per row", "\n", "        ", "ys", "=", "sample_1hot", "(", "num_per_sheet", ",", "num_classes", ")", "\n", "ys", "=", "G", ".", "shared", "(", "ys", ")", ".", "view", "(", "num_per_sheet", ",", "1", ",", "-", "1", ")", "\n", "ys", "=", "ys", ".", "repeat", "(", "1", ",", "num_midpoints", "+", "2", ",", "\n", "1", ")", ".", "view", "(", "num_per_sheet", "*", "(", "num_midpoints", "+", "2", ")", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "ys", "=", "interp", "(", "G", ".", "shared", "(", "sample_1hot", "(", "num_per_sheet", ",", "num_classes", ")", ")", ".", "view", "(", "num_per_sheet", ",", "1", ",", "-", "1", ")", ",", "\n", "G", ".", "shared", "(", "sample_1hot", "(", "num_per_sheet", ",", "num_classes", ")", ")", ".", "view", "(", "\n", "num_per_sheet", ",", "1", ",", "-", "1", ")", ",", "\n", "num_midpoints", ")", ".", "view", "(", "num_per_sheet", "*", "(", "num_midpoints", "+", "2", ")", ",", "-", "1", ")", "\n", "# Run the net--note that we've already passed y through G.shared.", "\n", "", "if", "G", ".", "fp16", ":", "\n", "        ", "zs", "=", "zs", ".", "half", "(", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "if", "parallel", ":", "\n", "            ", "out_ims", "=", "nn", ".", "parallel", ".", "data_parallel", "(", "G", ",", "(", "zs", ",", "ys", ")", ")", ".", "data", ".", "cpu", "(", ")", "\n", "", "else", ":", "\n", "            ", "out_ims", "=", "G", "(", "zs", ",", "ys", ")", ".", "data", ".", "cpu", "(", ")", "\n", "", "", "interp_style", "=", "''", "+", "(", "'Z'", "if", "not", "fix_z", "else", "''", ")", "+", "(", "'Y'", "if", "not", "fix_y", "else", "''", ")", "\n", "image_filename", "=", "'%s/%s/%d/interp%s%d.jpg'", "%", "(", "samples_root", ",", "experiment_name", ",", "\n", "folder_number", ",", "interp_style", ",", "\n", "sheet_number", ")", "\n", "torchvision", ".", "utils", ".", "save_image", "(", "out_ims", ",", "image_filename", ",", "\n", "nrow", "=", "num_midpoints", "+", "2", ",", "normalize", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.print_grad_norms": [[1089, 1098], ["numpy.argsort", "print", "float", "float", "net.parameters", "torch.norm().item", "torch.norm().item", "torch.norm().item", "torch.norm().item", "torch.norm().item", "torch.norm().item", "str", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm"], "function", ["None"], ["", "def", "print_grad_norms", "(", "net", ")", ":", "\n", "    ", "gradsums", "=", "[", "[", "float", "(", "torch", ".", "norm", "(", "param", ".", "grad", ")", ".", "item", "(", ")", ")", ",", "\n", "float", "(", "torch", ".", "norm", "(", "param", ")", ".", "item", "(", ")", ")", ",", "param", ".", "shape", "]", "\n", "for", "param", "in", "net", ".", "parameters", "(", ")", "]", "\n", "order", "=", "np", ".", "argsort", "(", "[", "item", "[", "0", "]", "for", "item", "in", "gradsums", "]", ")", "\n", "print", "(", "[", "'%3.3e,%3.3e, %s'", "%", "(", "gradsums", "[", "item_index", "]", "[", "0", "]", ",", "\n", "gradsums", "[", "item_index", "]", "[", "1", "]", ",", "\n", "str", "(", "gradsums", "[", "item_index", "]", "[", "2", "]", ")", ")", "\n", "for", "item_index", "in", "order", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.get_SVs": [[1102, 1107], ["net.state_dict", "float", "d[].item"], "function", ["None"], ["", "def", "get_SVs", "(", "net", ",", "prefix", ")", ":", "\n", "    ", "d", "=", "net", ".", "state_dict", "(", ")", "\n", "return", "{", "(", "'%s_%s'", "%", "(", "prefix", ",", "key", ")", ")", ".", "replace", "(", "'.'", ",", "'_'", ")", ":", "\n", "float", "(", "d", "[", "key", "]", ".", "item", "(", ")", ")", "\n", "for", "key", "in", "d", "if", "'sv'", "in", "key", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.name_from_config": [[1110, 1159], ["utils.hashname"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.hashname"], ["", "def", "name_from_config", "(", "config", ")", ":", "\n", "    ", "name", "=", "'_'", ".", "join", "(", "[", "\n", "item", "for", "item", "in", "[", "\n", "'Big%s'", "%", "config", "[", "'which_train_fn'", "]", ",", "\n", "config", "[", "'dataset'", "]", ",", "\n", "config", "[", "'loss_type'", "]", ",", "\n", "config", "[", "'model'", "]", "if", "config", "[", "'model'", "]", "!=", "'BigGAN'", "else", "None", ",", "\n", "'seed%d'", "%", "config", "[", "'seed'", "]", ",", "\n", "'Gch%d'", "%", "config", "[", "'G_ch'", "]", ",", "\n", "'Dch%d'", "%", "config", "[", "'D_ch'", "]", ",", "\n", "'Gd%d'", "%", "config", "[", "'G_depth'", "]", "if", "config", "[", "'G_depth'", "]", ">", "1", "else", "None", ",", "\n", "'Dd%d'", "%", "config", "[", "'D_depth'", "]", "if", "config", "[", "'D_depth'", "]", ">", "1", "else", "None", ",", "\n", "'bs%d'", "%", "config", "[", "'batch_size'", "]", ",", "\n", "'Gfp16'", "if", "config", "[", "'G_fp16'", "]", "else", "None", ",", "\n", "'Dfp16'", "if", "config", "[", "'D_fp16'", "]", "else", "None", ",", "\n", "'nDs%d'", "%", "config", "[", "'num_D_steps'", "]", "if", "config", "[", "'num_D_steps'", "]", ">", "1", "else", "None", ",", "\n", "'nDa%d'", "%", "config", "[", "'num_D_accumulations'", "]", "if", "config", "[", "'num_D_accumulations'", "]", ">", "1", "else", "None", ",", "\n", "'nGa%d'", "%", "config", "[", "'num_G_accumulations'", "]", "if", "config", "[", "'num_G_accumulations'", "]", ">", "1", "else", "None", ",", "\n", "'Glr%2.1e'", "%", "config", "[", "'G_lr'", "]", ",", "\n", "'Dlr%2.1e'", "%", "config", "[", "'D_lr'", "]", ",", "\n", "'GB%3.3f'", "%", "config", "[", "'G_B1'", "]", "if", "config", "[", "'G_B1'", "]", "!=", "0.0", "else", "None", ",", "\n", "'GBB%3.3f'", "%", "config", "[", "'G_B2'", "]", "if", "config", "[", "\n", "\n", "'G_B2'", "]", "!=", "0.999", "else", "None", ",", "\n", "'DB%3.3f'", "%", "config", "[", "'D_B1'", "]", "if", "config", "[", "'D_B1'", "]", "!=", "0.0", "else", "None", ",", "\n", "'DBB%3.3f'", "%", "config", "[", "'D_B2'", "]", "if", "config", "[", "'D_B2'", "]", "!=", "0.999", "else", "None", ",", "\n", "'Gnl%s'", "%", "config", "[", "'G_nl'", "]", ",", "\n", "'Dnl%s'", "%", "config", "[", "'D_nl'", "]", ",", "\n", "'Ginit%s'", "%", "config", "[", "'G_init'", "]", ",", "\n", "'Dinit%s'", "%", "config", "[", "'D_init'", "]", ",", "\n", "'G%s'", "%", "config", "[", "'G_param'", "]", "if", "config", "[", "'G_param'", "]", "!=", "'SN'", "else", "None", ",", "\n", "'D%s'", "%", "config", "[", "'D_param'", "]", "if", "config", "[", "'D_param'", "]", "!=", "'SN'", "else", "None", ",", "\n", "'Gattn%s'", "%", "config", "[", "'G_attn'", "]", "if", "config", "[", "'G_attn'", "]", "!=", "'0'", "else", "None", ",", "\n", "'Dattn%s'", "%", "config", "[", "'D_attn'", "]", "if", "config", "[", "'D_attn'", "]", "!=", "'0'", "else", "None", ",", "\n", "'Gortho%2.1e'", "%", "config", "[", "'G_ortho'", "]", "if", "config", "[", "'G_ortho'", "]", ">", "0.0", "else", "None", ",", "\n", "'Dortho%2.1e'", "%", "config", "[", "'D_ortho'", "]", "if", "config", "[", "'D_ortho'", "]", ">", "0.0", "else", "None", ",", "\n", "config", "[", "'norm_style'", "]", "if", "config", "[", "'norm_style'", "]", "!=", "'bn'", "else", "None", ",", "\n", "'cr'", "if", "config", "[", "'cross_replica'", "]", "else", "None", ",", "\n", "'Gshared'", "if", "config", "[", "'G_shared'", "]", "else", "None", ",", "\n", "'hier'", "if", "config", "[", "'hier'", "]", "else", "None", ",", "\n", "'ema'", "if", "config", "[", "'ema'", "]", "else", "None", ",", "\n", "config", "[", "'name_suffix'", "]", "if", "config", "[", "'name_suffix'", "]", "else", "None", ",", "\n", "]", "\n", "if", "item", "is", "not", "None", "]", ")", "\n", "# dogball", "\n", "if", "config", "[", "'hashname'", "]", ":", "\n", "        ", "return", "hashname", "(", "name", ")", "\n", "", "else", ":", "\n", "        ", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.hashname": [[1162, 1170], ["hash", "len", "len", "len", "len", "len"], "function", ["None"], ["", "", "def", "hashname", "(", "name", ")", ":", "\n", "    ", "h", "=", "hash", "(", "name", ")", "\n", "a", "=", "h", "%", "len", "(", "animal_hash", ".", "a", ")", "\n", "h", "=", "h", "//", "len", "(", "animal_hash", ".", "a", ")", "\n", "b", "=", "h", "%", "len", "(", "animal_hash", ".", "b", ")", "\n", "h", "=", "h", "//", "len", "(", "animal_hash", ".", "c", ")", "\n", "c", "=", "h", "%", "len", "(", "animal_hash", ".", "c", ")", "\n", "return", "animal_hash", ".", "a", "[", "a", "]", "+", "animal_hash", ".", "b", "[", "b", "]", "+", "animal_hash", ".", "c", "[", "c", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.query_gpu": [[1173, 1175], ["os.system"], "function", ["None"], ["", "def", "query_gpu", "(", "indices", ")", ":", "\n", "    ", "os", ".", "system", "(", "'nvidia-smi -i 0 --query-gpu=memory.free --format=csv'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.count_parameters": [[1178, 1181], ["print", "sum", "p.data.nelement", "module.parameters"], "function", ["None"], ["", "def", "count_parameters", "(", "module", ")", ":", "\n", "    ", "print", "(", "'Number of parameters: {}'", ".", "format", "(", "\n", "sum", "(", "[", "p", ".", "data", ".", "nelement", "(", ")", "for", "p", "in", "module", ".", "parameters", "(", ")", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.sample_1hot": [[1184, 1187], ["torch.randint", "torch.randint", "torch.randint"], "function", ["None"], ["", "def", "sample_1hot", "(", "batch_size", ",", "num_classes", ",", "device", "=", "'cuda'", ")", ":", "\n", "    ", "return", "torch", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "num_classes", ",", "size", "=", "(", "batch_size", ",", ")", ",", "\n", "device", "=", "device", ",", "dtype", "=", "torch", ".", "int64", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.prepare_z_y": [[1223, 1236], ["utils.Distribution", "z_.half.init_distribution", "z_.half.to", "utils.Distribution", "y_.to.init_distribution", "y_.to.to", "torch.randn", "torch.randn", "torch.randn", "z_.half.half", "torch.zeros", "torch.zeros", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.init_distribution", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.init_distribution", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to"], ["", "", "def", "prepare_z_y", "(", "G_batch_size", ",", "dim_z", ",", "nclasses", ",", "device", "=", "'cuda'", ",", "\n", "fp16", "=", "False", ",", "z_var", "=", "1.0", ")", ":", "\n", "    ", "z_", "=", "Distribution", "(", "torch", ".", "randn", "(", "G_batch_size", ",", "dim_z", ",", "requires_grad", "=", "False", ")", ")", "\n", "z_", ".", "init_distribution", "(", "'normal'", ",", "mean", "=", "0", ",", "var", "=", "z_var", ")", "\n", "z_", "=", "z_", ".", "to", "(", "device", ",", "torch", ".", "float16", "if", "fp16", "else", "torch", ".", "float32", ")", "\n", "\n", "if", "fp16", ":", "\n", "        ", "z_", "=", "z_", ".", "half", "(", ")", "\n", "\n", "", "y_", "=", "Distribution", "(", "torch", ".", "zeros", "(", "G_batch_size", ",", "requires_grad", "=", "False", ")", ")", "\n", "y_", ".", "init_distribution", "(", "'categorical'", ",", "num_categories", "=", "nclasses", ")", "\n", "y_", "=", "y_", ".", "to", "(", "device", ",", "torch", ".", "int64", ")", "\n", "return", "z_", ",", "y_", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.initiate_standing_stats": [[1238, 1243], ["net.modules", "hasattr", "module.reset_stats"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.layers.myBN.reset_stats"], ["", "def", "initiate_standing_stats", "(", "net", ")", ":", "\n", "    ", "for", "module", "in", "net", ".", "modules", "(", ")", ":", "\n", "        ", "if", "hasattr", "(", "module", ",", "'accumulate_standing'", ")", ":", "\n", "            ", "module", ".", "reset_stats", "(", ")", "\n", "module", ".", "accumulate_standing", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.accumulate_standing_stats": [[1245, 1256], ["utils.initiate_standing_stats", "net.train", "range", "net.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "z.normal_", "y.random_", "net", "net.shared"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.initiate_standing_stats"], ["", "", "", "def", "accumulate_standing_stats", "(", "net", ",", "z", ",", "y", ",", "nclasses", ",", "num_accumulations", "=", "16", ")", ":", "\n", "    ", "initiate_standing_stats", "(", "net", ")", "\n", "net", ".", "train", "(", ")", "\n", "for", "i", "in", "range", "(", "num_accumulations", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "z", ".", "normal_", "(", ")", "\n", "y", ".", "random_", "(", "0", ",", "nclasses", ")", "\n", "# No need to parallelize here unless using syncbn", "\n", "x", "=", "net", "(", "z", ",", "net", ".", "shared", "(", "y", ")", ")", "\n", "# Set to eval mode", "\n", "", "", "net", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.fairness_discrepancy": [[1259, 1272], ["abs", "numpy.unique", "numpy.sqrt", "data.sum", "abs"], "function", ["None"], ["", "def", "fairness_discrepancy", "(", "data", ",", "n_classes", ")", ":", "\n", "    ", "\"\"\"\n    computes fairness discrepancy metric for single or multi-attribute\n    \"\"\"", "\n", "if", "n_classes", "==", "2", ":", "\n", "        ", "props", "=", "data", ".", "sum", "(", ")", "/", "10000", "# assume 10K samples", "\n", "fair_d", "=", "abs", "(", ".5", "-", "props", ")", "\n", "", "else", ":", "\n", "# multi-attribute", "\n", "        ", "unique", ",", "freq", "=", "np", ".", "unique", "(", "data", ",", "return_counts", "=", "True", ")", "\n", "props", "=", "freq", "/", "10000", "# assumes 10K samples", "\n", "fair_d", "=", "np", ".", "sqrt", "(", "(", "abs", "(", "props", "-", "0.25", ")", "**", "2", ")", ".", "sum", "(", ")", ")", "\n", "", "return", "fair_d", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_aug.run": [[37, 255], ["utils.update_config_roots", "utils.seed_rng", "utils.prepare_root", "__import__", "print", "__import__.Generator().to", "__import__.Discriminator().to", "__import__.G_D", "print", "print", "print", "print", "utils.MetricsLogger", "print", "utils.MyLogger", "utils.write_metadata", "utils.get_data_loaders", "inception_utils.prepare_inception_metrics", "max", "utils.prepare_z_y", "utils.prepare_z_y", "fixed_z.sample_", "fixed_y.sample_", "functools.partial", "print", "print", "print", "print", "range", "print", "utils.name_from_config", "print", "__import__.Generator().to", "utils.ema", "print", "G.half.half", "print", "D.half.half", "print", "utils.load_weights", "torch.DataParallel", "fixed_y.zero_", "y_.zero_", "train_fns_aug.GAN_training_function", "train_fns_aug.dummy_training_function", "print", "sys.exit", "enumerate", "__import__.Generator", "__import__.Discriminator", "G_ema.half.half", "sync_batchnorm.patch_replication_callback", "utils.progress", "tqdm.tqdm", "G.half.train", "D.half.train", "train_fns.dummy_training_function.", "utils.MyLogger.log", "__import__.Generator", "G_ema.half.train", "utils.MyLogger.log", "print", "train_fns_aug.save_and_sample", "utils.name_from_config", "utils.sample_inception", "str", "fid_score.calculate_fid_given_paths", "print", "train_fns_aug.update_FID", "sum", "x.to().half", "y.to", "x.to", "y.to", "int", "print", "G.half.eval", "print", "G.half.eval", "str", "int", "G_ema.half.eval", "G_ema.half.eval", "p.data.nelement", "x.to", "utils.get_SVs", "utils.get_SVs", "net.parameters"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.update_config_roots", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.seed_rng", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.prepare_root", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.write_metadata", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.get_data_loaders", "home.repos.pwc.inspect_result.ermongroup_NDA.None.inception_utils.prepare_inception_metrics", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.prepare_z_y", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.prepare_z_y", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.name_from_config", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.load_weights", "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.GAN_training_function", "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.dummy_training_function", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.replicate.patch_replication_callback", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.progress", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MyLogger.log", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MyLogger.log", "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.save_and_sample", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.name_from_config", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.sample_inception", "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf.calculate_fid_given_paths", "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_fns_new.update_FID", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.Distribution.to", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.get_SVs", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.get_SVs"], ["def", "run", "(", "config", ")", ":", "\n", "\n", "# Update the config dict as necessary", "\n", "# This is for convenience, to add settings derived from the user-specified", "\n", "# configuration into the config-dict (e.g. inferring the number of classes", "\n", "# and size of the images from the dataset, passing in a pytorch object", "\n", "# for the activation specified as a string)", "\n", "    ", "config", "[", "'resolution'", "]", "=", "utils", ".", "imsize_dict", "[", "config", "[", "'dataset'", "]", "]", "\n", "config", "[", "'n_classes'", "]", "=", "utils", ".", "nclass_dict", "[", "config", "[", "'dataset'", "]", "]", "\n", "config", "[", "'G_activation'", "]", "=", "utils", ".", "activation_dict", "[", "config", "[", "'G_nl'", "]", "]", "\n", "config", "[", "'D_activation'", "]", "=", "utils", ".", "activation_dict", "[", "config", "[", "'D_nl'", "]", "]", "\n", "# By default, skip init if resuming training.", "\n", "if", "config", "[", "'resume'", "]", ":", "\n", "        ", "print", "(", "'Skipping initialization for training resumption...'", ")", "\n", "config", "[", "'skip_init'", "]", "=", "True", "\n", "", "config", "=", "utils", ".", "update_config_roots", "(", "config", ")", "\n", "device", "=", "'cuda'", "\n", "\n", "# Seed RNG", "\n", "utils", ".", "seed_rng", "(", "config", "[", "'seed'", "]", ")", "\n", "\n", "# Prepare root folders if necessary", "\n", "utils", ".", "prepare_root", "(", "config", ")", "\n", "\n", "# Setup cudnn.benchmark for free speed", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "# Import the model--this line allows us to dynamically select different files.", "\n", "model", "=", "__import__", "(", "config", "[", "'model'", "]", ")", "\n", "experiment_name", "=", "(", "config", "[", "'experiment_name'", "]", "if", "config", "[", "'experiment_name'", "]", "\n", "else", "utils", ".", "name_from_config", "(", "config", ")", ")", "\n", "print", "(", "'Experiment name is %s'", "%", "experiment_name", ")", "\n", "\n", "# Next, build the model", "\n", "G", "=", "model", ".", "Generator", "(", "**", "config", ")", ".", "to", "(", "device", ")", "\n", "D", "=", "model", ".", "Discriminator", "(", "**", "config", ")", ".", "to", "(", "device", ")", "\n", "\n", "# If using EMA, prepare it", "\n", "if", "config", "[", "'ema'", "]", ":", "\n", "        ", "print", "(", "'Preparing EMA for G with decay of {}'", ".", "format", "(", "\n", "config", "[", "'ema_decay'", "]", ")", ")", "\n", "G_ema", "=", "model", ".", "Generator", "(", "**", "{", "**", "config", ",", "'skip_init'", ":", "True", ",", "\n", "'no_optim'", ":", "True", "}", ")", ".", "to", "(", "device", ")", "\n", "ema", "=", "utils", ".", "ema", "(", "G", ",", "G_ema", ",", "config", "[", "'ema_decay'", "]", ",", "config", "[", "'ema_start'", "]", ")", "\n", "", "else", ":", "\n", "        ", "G_ema", ",", "ema", "=", "None", ",", "None", "\n", "\n", "# FP16?", "\n", "", "if", "config", "[", "'G_fp16'", "]", ":", "\n", "        ", "print", "(", "'Casting G to float16...'", ")", "\n", "G", "=", "G", ".", "half", "(", ")", "\n", "if", "config", "[", "'ema'", "]", ":", "\n", "            ", "G_ema", "=", "G_ema", ".", "half", "(", ")", "\n", "", "", "if", "config", "[", "'D_fp16'", "]", ":", "\n", "        ", "print", "(", "'Casting D to fp16...'", ")", "\n", "D", "=", "D", ".", "half", "(", ")", "\n", "# Consider automatically reducing SN_eps?", "\n", "", "GD", "=", "model", ".", "G_D", "(", "G", ",", "D", ",", "config", "[", "'conditional'", "]", ")", "# setting conditional to false", "\n", "print", "(", "G", ")", "\n", "print", "(", "D", ")", "\n", "print", "(", "'Number of params in G: {} D: {}'", ".", "format", "(", "\n", "*", "[", "sum", "(", "[", "p", ".", "data", ".", "nelement", "(", ")", "for", "p", "in", "net", ".", "parameters", "(", ")", "]", ")", "for", "net", "in", "[", "G", ",", "D", "]", "]", ")", ")", "\n", "# Prepare state dict, which holds things like epoch # and itr #", "\n", "state_dict", "=", "{", "'itr'", ":", "0", ",", "'epoch'", ":", "0", ",", "'save_num'", ":", "0", ",", "'save_best_num'", ":", "0", ",", "\n", "'best_IS'", ":", "0", ",", "'best_FID'", ":", "999999", ",", "'config'", ":", "config", "}", "\n", "\n", "# If loading from a pre-trained model, load weights", "\n", "if", "config", "[", "'resume'", "]", ":", "\n", "        ", "print", "(", "'Loading weights...'", ")", "\n", "utils", ".", "load_weights", "(", "G", ",", "D", ",", "state_dict", ",", "\n", "config", "[", "'weights_root'", "]", ",", "experiment_name", ",", "\n", "config", "[", "'load_weights'", "]", "if", "config", "[", "'load_weights'", "]", "else", "None", ",", "\n", "G_ema", "if", "config", "[", "'ema'", "]", "else", "None", ")", "\n", "\n", "# If parallel, parallelize the GD module", "\n", "", "if", "config", "[", "'parallel'", "]", ":", "\n", "        ", "GD", "=", "nn", ".", "DataParallel", "(", "GD", ")", "\n", "if", "config", "[", "'cross_replica'", "]", ":", "\n", "            ", "patch_replication_callback", "(", "GD", ")", "\n", "\n", "# Prepare loggers for stats; metrics holds test metrics,", "\n", "# lmetrics holds any desired training metrics.", "\n", "", "", "test_metrics_fname", "=", "'%s/%s_log.jsonl'", "%", "(", "config", "[", "'logs_root'", "]", ",", "\n", "experiment_name", ")", "\n", "train_metrics_fname", "=", "'%s/%s'", "%", "(", "config", "[", "'logs_root'", "]", ",", "experiment_name", ")", "\n", "print", "(", "'Inception Metrics will be saved to {}'", ".", "format", "(", "test_metrics_fname", ")", ")", "\n", "test_log", "=", "utils", ".", "MetricsLogger", "(", "test_metrics_fname", ",", "\n", "reinitialize", "=", "(", "not", "config", "[", "'resume'", "]", ")", ")", "\n", "print", "(", "'Training Metrics will be saved to {}'", ".", "format", "(", "train_metrics_fname", ")", ")", "\n", "train_log", "=", "utils", ".", "MyLogger", "(", "train_metrics_fname", ",", "\n", "reinitialize", "=", "(", "not", "config", "[", "'resume'", "]", ")", ",", "\n", "logstyle", "=", "config", "[", "'logstyle'", "]", ")", "\n", "# Write metadata", "\n", "utils", ".", "write_metadata", "(", "config", "[", "'logs_root'", "]", ",", "\n", "experiment_name", ",", "config", ",", "state_dict", ")", "\n", "# Prepare data; the Discriminator's batch size is all that needs to be passed", "\n", "# to the dataloader, as G doesn't require dataloading.", "\n", "# Note that at every loader iteration we pass in enough data to complete", "\n", "# a full D iteration (regardless of number of D steps and accumulations)", "\n", "D_batch_size", "=", "(", "config", "[", "'batch_size'", "]", "*", "config", "[", "'num_D_steps'", "]", "\n", "*", "config", "[", "'num_D_accumulations'", "]", ")", "\n", "loaders", "=", "utils", ".", "get_data_loaders", "(", "**", "{", "**", "config", ",", "'batch_size'", ":", "D_batch_size", ",", "\n", "'start_itr'", ":", "state_dict", "[", "'itr'", "]", "}", ")", "\n", "\n", "# Prepare inception metrics: FID and IS", "\n", "get_inception_metrics", "=", "inception_utils", ".", "prepare_inception_metrics", "(", "\n", "config", "[", "'dataset'", "]", ",", "config", "[", "'parallel'", "]", ",", "config", "[", "'no_fid'", "]", ")", "\n", "\n", "# Prepare noise and randomly sampled label arrays", "\n", "# Allow for different batch sizes in G", "\n", "G_batch_size", "=", "max", "(", "config", "[", "'G_batch_size'", "]", ",", "config", "[", "'batch_size'", "]", ")", "\n", "z_", ",", "y_", "=", "utils", ".", "prepare_z_y", "(", "G_batch_size", ",", "G", ".", "dim_z", ",", "config", "[", "'n_classes'", "]", ",", "\n", "device", "=", "device", ",", "fp16", "=", "config", "[", "'G_fp16'", "]", ")", "\n", "# Prepare a fixed z & y to see individual sample evolution throghout training", "\n", "fixed_z", ",", "fixed_y", "=", "utils", ".", "prepare_z_y", "(", "G_batch_size", ",", "G", ".", "dim_z", ",", "\n", "config", "[", "'n_classes'", "]", ",", "device", "=", "device", ",", "\n", "fp16", "=", "config", "[", "'G_fp16'", "]", ")", "\n", "fixed_z", ".", "sample_", "(", ")", "\n", "fixed_y", ".", "sample_", "(", ")", "\n", "\n", "if", "not", "config", "[", "'conditional'", "]", ":", "\n", "        ", "fixed_y", ".", "zero_", "(", ")", "\n", "y_", ".", "zero_", "(", ")", "\n", "# Loaders are loaded, prepare the training function", "\n", "", "if", "config", "[", "'which_train_fn'", "]", "==", "'GAN'", ":", "\n", "        ", "train", "=", "train_fns", ".", "GAN_training_function", "(", "G", ",", "D", ",", "GD", ",", "z_", ",", "y_", ",", "\n", "ema", ",", "state_dict", ",", "config", ")", "\n", "# Else, assume debugging and use the dummy train fn", "\n", "", "else", ":", "\n", "        ", "train", "=", "train_fns", ".", "dummy_training_function", "(", ")", "\n", "# Prepare Sample function for use with inception metrics", "\n", "", "sample", "=", "functools", ".", "partial", "(", "utils", ".", "sample", ",", "\n", "G", "=", "(", "G_ema", "if", "config", "[", "'ema'", "]", "and", "config", "[", "'use_ema'", "]", "\n", "else", "G", ")", ",", "\n", "z_", "=", "z_", ",", "y_", "=", "y_", ",", "config", "=", "config", ")", "\n", "\n", "print", "(", "'Beginning training at epoch %d...'", "%", "state_dict", "[", "'epoch'", "]", ")", "\n", "print", "(", "'Total training epochs '", ",", "config", "[", "'num_epochs'", "]", ")", "\n", "print", "(", "\"the dataset is \"", ",", "config", "[", "'dataset'", "]", ",", ")", "\n", "if", "config", "[", "'dataset'", "]", "==", "'C10U'", "or", "config", "[", "'dataset'", "]", "==", "'C10'", ":", "\n", "        ", "data_moments", "=", "'cifar10_10k_stats.npz'", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"cannot find the dataset\"", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n", "", "print", "(", "\"the data moments is \"", ",", "data_moments", ")", "\n", "# Train for specified number of epochs, although we mostly track G iterations.", "\n", "for", "epoch", "in", "range", "(", "state_dict", "[", "'epoch'", "]", ",", "config", "[", "'num_epochs'", "]", ")", ":", "\n", "# Which progressbar to use? TQDM or my own?", "\n", "        ", "if", "config", "[", "'pbar'", "]", "==", "'mine'", ":", "\n", "            ", "pbar", "=", "utils", ".", "progress", "(", "\n", "loaders", "[", "0", "]", ",", "displaytype", "=", "'s1k'", "if", "config", "[", "'use_multiepoch_sampler'", "]", "else", "'eta'", ")", "\n", "", "else", ":", "\n", "            ", "pbar", "=", "tqdm", "(", "loaders", "[", "0", "]", ")", "\n", "", "for", "i", ",", "(", "x", ",", "y", ")", "in", "enumerate", "(", "pbar", ")", ":", "\n", "# Increment the iteration counter", "\n", "            ", "state_dict", "[", "'itr'", "]", "+=", "1", "\n", "# Make sure G and D are in training mode, just in case they got set to eval", "\n", "# For D, which typically doesn't have BN, this shouldn't matter much.", "\n", "G", ".", "train", "(", ")", "\n", "D", ".", "train", "(", ")", "\n", "if", "config", "[", "'ema'", "]", ":", "\n", "                ", "G_ema", ".", "train", "(", ")", "\n", "", "if", "config", "[", "'D_fp16'", "]", ":", "\n", "                ", "x", ",", "y", "=", "x", ".", "to", "(", "device", ")", ".", "half", "(", ")", ",", "y", ".", "to", "(", "device", ")", "\n", "", "else", ":", "\n", "                ", "x", ",", "y", "=", "x", ".", "to", "(", "device", ")", ",", "y", ".", "to", "(", "device", ")", "\n", "", "metrics", "=", "train", "(", "x", ",", "y", ")", "\n", "train_log", ".", "log", "(", "itr", "=", "int", "(", "state_dict", "[", "'itr'", "]", ")", ",", "**", "metrics", ")", "\n", "\n", "# Every sv_log_interval, log singular values", "\n", "if", "(", "config", "[", "'sv_log_interval'", "]", ">", "0", ")", "and", "(", "not", "(", "state_dict", "[", "'itr'", "]", "%", "config", "[", "'sv_log_interval'", "]", ")", ")", ":", "\n", "                ", "train_log", ".", "log", "(", "itr", "=", "int", "(", "state_dict", "[", "'itr'", "]", ")", ",", "\n", "**", "{", "**", "utils", ".", "get_SVs", "(", "G", ",", "'G'", ")", ",", "**", "utils", ".", "get_SVs", "(", "D", ",", "'D'", ")", "}", ")", "\n", "\n", "# If using my progbar, print metrics.", "\n", "", "if", "config", "[", "'pbar'", "]", "==", "'mine'", ":", "\n", "                ", "print", "(", "', '", ".", "join", "(", "[", "'itr: %d'", "%", "state_dict", "[", "'itr'", "]", "]", "\n", "+", "[", "'%s : %+4.3f'", "%", "(", "key", ",", "metrics", "[", "key", "]", ")", "\n", "for", "key", "in", "metrics", "]", ")", ",", "end", "=", "' '", ")", "\n", "\n", "# Save weights and copies as configured at specified interval", "\n", "", "if", "not", "(", "state_dict", "[", "'itr'", "]", "%", "config", "[", "'save_every'", "]", ")", ":", "\n", "                ", "if", "config", "[", "'G_eval_mode'", "]", ":", "\n", "                    ", "print", "(", "'Switchin G to eval mode...'", ")", "\n", "G", ".", "eval", "(", ")", "\n", "if", "config", "[", "'ema'", "]", ":", "\n", "                        ", "G_ema", ".", "eval", "(", ")", "\n", "", "", "train_fns", ".", "save_and_sample", "(", "G", ",", "D", ",", "G_ema", ",", "z_", ",", "y_", ",", "fixed_z", ",", "fixed_y", ",", "\n", "state_dict", ",", "config", ",", "experiment_name", ")", "\n", "\n", "# Test every specified interval", "\n", "# First load celeba moments", "\n", "\n", "", "experiment_name", "=", "(", "config", "[", "'experiment_name'", "]", "if", "config", "[", "'experiment_name'", "]", "\n", "else", "utils", ".", "name_from_config", "(", "config", ")", ")", "\n", "if", "(", "not", "(", "state_dict", "[", "'itr'", "]", "%", "config", "[", "'test_every'", "]", ")", ")", "and", "(", "epoch", ">=", "config", "[", "'start_eval'", "]", ")", ":", "\n", "                ", "if", "config", "[", "'G_eval_mode'", "]", ":", "\n", "                    ", "print", "(", "'Switchin G to eval mode...'", ")", "\n", "G", ".", "eval", "(", ")", "\n", "if", "config", "[", "'ema'", "]", ":", "\n", "                        ", "G_ema", ".", "eval", "(", ")", "\n", "# sampling images and saving to samples/experiments/epoch", "\n", "", "", "utils", ".", "sample_inception", "(", "\n", "G_ema", "if", "config", "[", "'ema'", "]", "and", "config", "[", "'use_ema'", "]", "else", "G", ",", "config", ",", "str", "(", "epoch", ")", ")", "\n", "# Get saved sample path", "\n", "folder_number", "=", "str", "(", "epoch", ")", "\n", "sample_moments", "=", "'%s/%s/%s/samples.npz'", "%", "(", "config", "[", "'samples_root'", "]", ",", "experiment_name", ",", "folder_number", ")", "\n", "# Calculate FID", "\n", "FID", "=", "fid_score", ".", "calculate_fid_given_paths", "(", "[", "data_moments", ",", "sample_moments", "]", ",", "\n", "batch_size", "=", "50", ",", "cuda", "=", "True", ",", "dims", "=", "2048", ")", "\n", "print", "(", "\"FID calculated\"", ")", "\n", "train_fns", ".", "update_FID", "(", "G", ",", "D", ",", "G_ema", ",", "state_dict", ",", "config", ",", "FID", ",", "experiment_name", ",", "test_log", ")", "\n", "# train_fns.test(G, D, G_ema, z_, y_, state_dict, config, sample,", "\n", "#                get_inception_metrics, experiment_name, test_log)", "\n", "# Increment epoch counter at end of epoch", "\n", "", "", "state_dict", "[", "'epoch'", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_aug.main": [[257, 263], ["utils.prepare_parser", "vars", "print", "train_aug.run", "utils.prepare_parser.parse_args"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.prepare_parser", "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_aug.run"], ["", "", "def", "main", "(", ")", ":", "\n", "# parse command line and run", "\n", "    ", "parser", "=", "utils", ".", "prepare_parser", "(", ")", "\n", "config", "=", "vars", "(", "parser", ".", "parse_args", "(", ")", ")", "\n", "print", "(", "config", ")", "\n", "run", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.losses.loss_dcgan_dis": [[7, 11], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.softplus", "torch.softplus"], "function", ["None"], ["def", "loss_dcgan_dis", "(", "dis_fake", ",", "dis_real", ")", ":", "\n", "    ", "L1", "=", "torch", ".", "mean", "(", "F", ".", "softplus", "(", "-", "dis_real", ")", ")", "\n", "L2", "=", "torch", ".", "mean", "(", "F", ".", "softplus", "(", "dis_fake", ")", ")", "\n", "return", "L1", ",", "L2", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.losses.loss_dcgan_gen": [[13, 16], ["torch.mean", "torch.mean", "torch.softplus"], "function", ["None"], ["", "def", "loss_dcgan_gen", "(", "dis_fake", ")", ":", "\n", "    ", "loss", "=", "torch", ".", "mean", "(", "F", ".", "softplus", "(", "-", "dis_fake", ")", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.losses.loss_dcgan_dis_new": [[17, 22], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.softplus", "torch.softplus", "torch.softplus"], "function", ["None"], ["", "def", "loss_dcgan_dis_new", "(", "dis_fake", ",", "dis_real", ",", "dis_real_fake", ")", ":", "\n", "    ", "L1", "=", "torch", ".", "mean", "(", "F", ".", "softplus", "(", "-", "dis_real", ")", ")", "\n", "L2", "=", "torch", ".", "mean", "(", "F", ".", "softplus", "(", "dis_fake", ")", ")", "\n", "L_real_fake", "=", "torch", ".", "mean", "(", "F", ".", "softplus", "(", "dis_real_fake", ")", ")", "\n", "return", "L1", ",", "L2", ",", "L_real_fake", "\n", "# Hinge Loss", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.losses.loss_hinge_dis": [[24, 36], ["torch.relu", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.relu"], "function", ["None"], ["", "def", "loss_hinge_dis", "(", "dis_fake", ",", "dis_real", ")", ":", "\n", "\n", "    ", "\"\"\"\n    fixed to take in density ratio estimates\n    \"\"\"", "\n", "# properly match up dimensions, and only reweight real examples", "\n", "# weighted = F.relu(1. - dis_real) * ratio.unsqueeze(1)", "\n", "weighted", "=", "F", ".", "relu", "(", "1.", "-", "dis_real", ")", "\n", "loss_real", "=", "torch", ".", "mean", "(", "weighted", ")", "\n", "# loss_real = torch.mean(F.relu(1. - dis_real))", "\n", "loss_fake", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.", "+", "dis_fake", ")", ")", "\n", "return", "loss_real", ",", "loss_fake", "\n", "# def loss_hinge_dis(dis_fake, dis_real): # This version returns a single loss", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.losses.loss_hinge_analysis": [[41, 51], ["torch.relu"], "function", ["None"], ["", "def", "loss_hinge_analysis", "(", "dis_real", ")", ":", "\n", "\n", "    ", "\"\"\"\n    fixed to take in density ratio estimates\n    \"\"\"", "\n", "# properly match up dimensions, and only reweight real examples", "\n", "# weighted = F.relu(1. - dis_real) * ratio.unsqueeze(1)", "\n", "weighted", "=", "F", ".", "relu", "(", "1.", "-", "dis_real", ")", "\n", "loss_real", "=", "weighted", "\n", "return", "loss_real", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.losses.loss_hinge_dis_new": [[52, 57], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.relu", "torch.relu", "torch.relu"], "function", ["None"], ["", "def", "loss_hinge_dis_new", "(", "dis_fake", ",", "dis_real", ",", "dis_real_fake", ")", ":", "\n", "    ", "loss_real", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.", "-", "dis_real", ")", ")", "\n", "loss_fake", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.", "+", "dis_fake", ")", ")", "\n", "loss_real_fake", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.", "+", "dis_real_fake", ")", ")", "\n", "return", "loss_real", ",", "loss_fake", ",", "loss_real_fake", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.losses.loss_hinge_dis_new_fake": [[58, 64], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.relu", "torch.relu", "torch.relu", "torch.relu"], "function", ["None"], ["", "def", "loss_hinge_dis_new_fake", "(", "dis_fake", ",", "dis_real", ",", "dis_real_fake", ",", "dis_fake_fake", ")", ":", "\n", "    ", "loss_real", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.", "-", "dis_real", ")", ")", "\n", "loss_fake", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.", "+", "dis_fake", ")", ")", "\n", "loss_real_fake", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.", "+", "dis_real_fake", ")", ")", "\n", "loss_fake_fake", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.", "+", "dis_fake_fake", ")", ")", "\n", "return", "loss_real", ",", "loss_fake", ",", "loss_real_fake", ",", "loss_fake_fake", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.losses.loss_hinge_gen": [[65, 72], ["torch.mean", "torch.mean"], "function", ["None"], ["", "def", "loss_hinge_gen", "(", "dis_fake", ")", ":", "\n", "# with torch.no_grad():", "\n", "#   dis_fake_norm = torch.exp(dis_fake).mean()", "\n", "#   dis_fake_ratio = torch.exp(dis_fake) / dis_fake_norm", "\n", "# dis_fake = dis_fake * dis_fake_ratio", "\n", "    ", "loss", "=", "-", "torch", ".", "mean", "(", "dis_fake", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.losses.loss_kl_dis": [[74, 84], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.relu", "torch.no_grad", "torch.no_grad", "torch.clamp", "torch.clamp", "torch.relu", "dis_fake.mean", "torch.exp().mean", "torch.exp().mean", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "function", ["None"], ["", "def", "loss_kl_dis", "(", "dis_fake", ",", "dis_real", ")", ":", "\n", "    ", "loss_real", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.", "-", "dis_real", ")", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "dis_fake_m", "=", "dis_fake", "-", "dis_fake", ".", "mean", "(", ")", "\n", "dis_fake_m", "=", "torch", ".", "clamp", "(", "dis_fake_m", ",", "min", "=", "-", "10.0", ",", "max", "=", "10.0", ")", "\n", "dis_fake_norm", "=", "torch", ".", "exp", "(", "dis_fake_m", ")", ".", "mean", "(", ")", "+", "1e-8", "\n", "dis_fake_ratio", "=", "(", "torch", ".", "exp", "(", "dis_fake_m", ")", "+", "1e-8", ")", "/", "dis_fake_norm", "\n", "", "dis_fake", "=", "dis_fake", "*", "dis_fake_ratio", "\n", "loss_fake", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.", "+", "dis_fake", ")", ")", "\n", "return", "loss_real", ",", "loss_fake", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.losses.loss_kl_dis_new": [[85, 104], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.relu", "torch.no_grad", "torch.no_grad", "torch.clamp", "torch.clamp", "torch.relu", "torch.no_grad", "torch.no_grad", "torch.clamp", "torch.clamp", "torch.relu", "dis_fake.mean", "torch.exp().mean", "torch.exp().mean", "dis_real_fake.mean", "torch.exp().mean", "torch.exp().mean", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "function", ["None"], ["", "def", "loss_kl_dis_new", "(", "dis_fake", ",", "dis_real", ",", "dis_real_fake", ")", ":", "\n", "    ", "loss_real", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.", "-", "dis_real", ")", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "dis_fake_m", "=", "dis_fake", "-", "dis_fake", ".", "mean", "(", ")", "\n", "dis_fake_m", "=", "torch", ".", "clamp", "(", "dis_fake_m", ",", "min", "=", "-", "10.0", ",", "max", "=", "10.0", ")", "\n", "dis_fake_norm", "=", "torch", ".", "exp", "(", "dis_fake_m", ")", ".", "mean", "(", ")", "+", "1e-8", "\n", "dis_fake_ratio", "=", "(", "torch", ".", "exp", "(", "dis_fake_m", ")", "+", "1e-8", ")", "/", "dis_fake_norm", "\n", "", "dis_fake", "=", "dis_fake", "*", "dis_fake_ratio", "\n", "loss_fake", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.", "+", "dis_fake", ")", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "dis_fake_m", "=", "dis_real_fake", "-", "dis_real_fake", ".", "mean", "(", ")", "\n", "dis_fake_m", "=", "torch", ".", "clamp", "(", "dis_fake_m", ",", "min", "=", "-", "10.0", ",", "max", "=", "10.0", ")", "\n", "dis_fake_norm", "=", "torch", ".", "exp", "(", "dis_fake_m", ")", ".", "mean", "(", ")", "+", "1e-8", "\n", "dis_fake_ratio", "=", "(", "torch", ".", "exp", "(", "dis_fake_m", ")", "+", "1e-8", ")", "/", "dis_fake_norm", "\n", "", "dis_real_fake", "=", "dis_real_fake", "*", "dis_fake_ratio", "\n", "loss_real_fake", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.", "+", "dis_real_fake", ")", ")", "\n", "\n", "return", "loss_real", ",", "loss_fake", ",", "loss_real_fake", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.losses.loss_kl_gen": [[106, 115], ["torch.no_grad", "torch.no_grad", "torch.clamp", "torch.clamp", "torch.mean", "torch.mean", "dis_fake.mean", "torch.exp().mean", "torch.exp().mean", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "function", ["None"], ["", "def", "loss_kl_gen", "(", "dis_fake", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "dis_fake_m", "=", "dis_fake", "-", "dis_fake", ".", "mean", "(", ")", "\n", "dis_fake_m", "=", "torch", ".", "clamp", "(", "dis_fake_m", ",", "min", "=", "-", "10.0", ",", "max", "=", "10.0", ")", "\n", "dis_fake_norm", "=", "torch", ".", "exp", "(", "dis_fake_m", ")", ".", "mean", "(", ")", "+", "1e-8", "\n", "dis_fake_ratio", "=", "(", "torch", ".", "exp", "(", "dis_fake_m", ")", "+", "1e-8", ")", "/", "dis_fake_norm", "\n", "", "dis_fake", "=", "dis_fake", "*", "dis_fake_ratio", "\n", "loss", "=", "-", "torch", ".", "mean", "(", "dis_fake", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.losses.loss_kl_grad_dis": [[117, 127], ["torch.clamp", "torch.clamp", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "dis_fake.mean", "torch.exp().mean", "torch.exp().mean", "torch.relu", "torch.relu", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "function", ["None"], ["", "def", "loss_kl_grad_dis", "(", "dis_fake", ",", "dis_real", ")", ":", "\n", "    ", "dis_fake_m", "=", "dis_fake", "-", "dis_fake", ".", "mean", "(", ")", "\n", "dis_fake_m", "=", "torch", ".", "clamp", "(", "dis_fake_m", ",", "min", "=", "-", "10.0", ",", "max", "=", "10.0", ")", "\n", "dis_fake_norm", "=", "torch", ".", "exp", "(", "dis_fake_m", ")", ".", "mean", "(", ")", "+", "1e-8", "\n", "dis_fake_ratio", "=", "(", "torch", ".", "exp", "(", "dis_fake_m", ")", "+", "1e-8", ")", "/", "dis_fake_norm", "\n", "dis_fake", "=", "dis_fake", "*", "dis_fake_ratio", "\n", "\n", "loss_real", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.", "-", "dis_real", ")", ")", "\n", "loss_fake", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.", "+", "dis_fake", ")", ")", "\n", "return", "loss_real", ",", "loss_fake", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.losses.loss_kl_grad_gen": [[129, 138], ["torch.clamp", "torch.clamp", "dis_fake.mean", "torch.exp().mean", "torch.exp().mean", "torch.mean", "torch.mean", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "function", ["None"], ["", "def", "loss_kl_grad_gen", "(", "dis_fake", ")", ":", "\n", "    ", "dis_fake_m", "=", "dis_fake", "-", "dis_fake", ".", "mean", "(", ")", "\n", "dis_fake_m", "=", "torch", ".", "clamp", "(", "dis_fake_m", ",", "min", "=", "-", "10.0", ",", "max", "=", "10.0", ")", "\n", "dis_fake_norm", "=", "torch", ".", "exp", "(", "dis_fake_m", ")", ".", "mean", "(", ")", "+", "1e-8", "\n", "dis_fake_ratio", "=", "(", "torch", ".", "exp", "(", "dis_fake_m", ")", "+", "1e-8", ")", "/", "dis_fake_norm", "\n", "dis_fake", "=", "dis_fake", "*", "dis_fake_ratio", "\n", "\n", "loss", "=", "-", "torch", ".", "mean", "(", "dis_fake", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.losses.loss_f_kl_dis": [[144, 150], ["ipdb.set_trace", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.relu", "torch.exp", "torch.exp"], "function", ["None"], ["", "def", "loss_f_kl_dis", "(", "dis_fake", ",", "dis_real", ")", ":", "\n", "    ", "import", "ipdb", "\n", "ipdb", ".", "set_trace", "(", ")", "\n", "loss_real", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.0", "-", "dis_real", ")", ")", "\n", "loss_fake", "=", "torch", ".", "mean", "(", "torch", ".", "exp", "(", "dis_fake", "-", "1.0", ")", ")", "\n", "return", "loss_real", ",", "loss_fake", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.losses.loss_f_kl_gen": [[152, 157], ["ipdb.set_trace", "torch.mean", "torch.mean", "torch.exp", "torch.exp"], "function", ["None"], ["", "def", "loss_f_kl_gen", "(", "dis_fake", ")", ":", "\n", "    ", "import", "ipdb", "\n", "ipdb", ".", "set_trace", "(", ")", "\n", "loss", "=", "-", "torch", ".", "mean", "(", "torch", ".", "exp", "(", "dis_fake", "-", "1.0", ")", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.losses.loss_dv_dis": [[188, 196], ["torch.mean", "torch.mean", "torch.relu", "torch.exp().mean", "torch.exp().mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.exp", "torch.exp", "torch.relu", "torch.exp", "torch.exp", "torch.log", "torch.log"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MyLogger.log", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MyLogger.log"], ["", "def", "loss_dv_dis", "(", "dis_fake", ",", "dis_real", ")", ":", "\n", "    ", "loss_real", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.", "-", "dis_real", ")", ")", "\n", "dis_fake_norm", "=", "torch", ".", "exp", "(", "dis_fake", ")", ".", "mean", "(", ")", "+", "1e-8", "\n", "dis_fake_ratio", "=", "(", "torch", ".", "exp", "(", "dis_fake", ")", "+", "1e-8", ")", "/", "dis_fake_norm", "\n", "dis_fake", "=", "dis_fake", "*", "dis_fake_ratio", "\n", "loss_fake", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.", "+", "dis_fake", ")", ")", "+", "torch", ".", "mean", "(", "dis_fake_ratio", "*", "torch", ".", "log", "(", "dis_fake_ratio", ")", ")", "\n", "return", "loss_real", ",", "loss_fake", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.losses.loss_dv_gen": [[198, 205], ["torch.exp().mean", "torch.exp().mean", "torch.mean", "torch.mean", "torch.exp", "torch.exp", "torch.mean", "torch.mean", "torch.exp", "torch.exp", "torch.log", "torch.log"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MyLogger.log", "home.repos.pwc.inspect_result.ermongroup_NDA.None.utils.MyLogger.log"], ["", "def", "loss_dv_gen", "(", "dis_fake", ")", ":", "\n", "    ", "dis_fake_norm", "=", "torch", ".", "exp", "(", "dis_fake", ")", ".", "mean", "(", ")", "+", "1e-8", "\n", "dis_fake_ratio", "=", "(", "torch", ".", "exp", "(", "dis_fake", ")", "+", "1e-8", ")", "/", "dis_fake_norm", "\n", "dis_fake", "=", "dis_fake", "*", "dis_fake_ratio", "\n", "loss", "=", "-", "torch", ".", "mean", "(", "dis_fake", ")", "-", "torch", ".", "mean", "(", "dis_fake_ratio", "*", "torch", ".", "log", "(", "dis_fake_ratio", ")", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.losses.loss_chi_dis": [[172, 179], ["torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "function", ["None"], ["", "def", "loss_chi_dis", "(", "dis_fake", ",", "dis_real", ")", ":", "\n", "    ", "dis_fake", "=", "torch", ".", "clamp", "(", "dis_fake", ",", "-", "1.0", ",", "1.0", ")", "\n", "dis_real", "=", "torch", ".", "clamp", "(", "dis_real", ",", "-", "1.0", ",", "1.0", ")", "\n", "loss_real", "=", "torch", ".", "mean", "(", "-", "dis_real", ")", "\n", "dis_fake_mean", "=", "torch", ".", "mean", "(", "dis_fake", ")", "\n", "loss_fake", "=", "torch", ".", "mean", "(", "dis_fake", "*", "(", "dis_fake", "-", "dis_fake_mean", "+", "2", ")", ")", "/", "2.0", "\n", "return", "loss_real", ",", "loss_fake", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.losses.loss_chi_gen": [[181, 186], ["torch.clamp", "torch.clamp", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "function", ["None"], ["", "def", "loss_chi_gen", "(", "dis_fake", ")", ":", "\n", "    ", "dis_fake", "=", "torch", ".", "clamp", "(", "dis_fake", ",", "-", "1.0", ",", "1.0", ")", "\n", "dis_fake_mean", "=", "torch", ".", "mean", "(", "dis_fake", ")", "\n", "loss_fake", "=", "-", "torch", ".", "mean", "(", "dis_fake", "*", "(", "dis_fake", "-", "dis_fake_mean", "+", "2", ")", ")", "/", "2.0", "\n", "return", "loss_fake", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.ImageFolder.__init__": [[113, 148], ["datasets.find_classes", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "print", "print", "datasets.make_dataset", "numpy.savez_compressed", "len", "RuntimeError", "print", "tqdm.tqdm.tqdm", "numpy.load", "range", "datasets.ImageFolder.data.append", "datasets.ImageFolder.labels.append", "len", "datasets.ImageFolder.transform", "datasets.ImageFolder.loader"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.find_classes", "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.make_dataset"], ["def", "__init__", "(", "self", ",", "root", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "\n", "loader", "=", "default_loader", ",", "load_in_mem", "=", "False", ",", "\n", "index_filename", "=", "'imagenet_imgs.npz'", ",", "**", "kwargs", ")", ":", "\n", "        ", "classes", ",", "class_to_idx", "=", "find_classes", "(", "root", ")", "\n", "# Load pre-computed image directory walk", "\n", "if", "os", ".", "path", ".", "exists", "(", "index_filename", ")", ":", "\n", "            ", "print", "(", "'Loading pre-saved Index file %s...'", "%", "index_filename", ")", "\n", "imgs", "=", "np", ".", "load", "(", "index_filename", ")", "[", "'imgs'", "]", "\n", "# If first time, walk the folder directory and save the", "\n", "# results to a pre-computed file.", "\n", "", "else", ":", "\n", "            ", "print", "(", "'Generating  Index file %s...'", "%", "index_filename", ")", "\n", "imgs", "=", "make_dataset", "(", "root", ",", "class_to_idx", ")", "\n", "np", ".", "savez_compressed", "(", "index_filename", ",", "**", "{", "'imgs'", ":", "imgs", "}", ")", "\n", "", "if", "len", "(", "imgs", ")", "==", "0", ":", "\n", "            ", "raise", "(", "RuntimeError", "(", "\"Found 0 images in subfolders of: \"", "+", "root", "+", "\"\\n\"", "\n", "\"Supported image extensions are: \"", "+", "\",\"", ".", "join", "(", "IMG_EXTENSIONS", ")", ")", ")", "\n", "\n", "", "self", ".", "root", "=", "root", "\n", "self", ".", "imgs", "=", "imgs", "\n", "self", ".", "classes", "=", "classes", "\n", "self", ".", "class_to_idx", "=", "class_to_idx", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "loader", "=", "loader", "\n", "self", ".", "load_in_mem", "=", "load_in_mem", "\n", "\n", "if", "self", ".", "load_in_mem", ":", "\n", "            ", "print", "(", "'Loading all images into memory...'", ")", "\n", "self", ".", "data", ",", "self", ".", "labels", "=", "[", "]", ",", "[", "]", "\n", "for", "index", "in", "tqdm", "(", "range", "(", "len", "(", "self", ".", "imgs", ")", ")", ")", ":", "\n", "\n", "                ", "path", ",", "target", "=", "imgs", "[", "index", "]", "[", "0", "]", ",", "imgs", "[", "index", "]", "[", "1", "]", "\n", "self", ".", "data", ".", "append", "(", "self", ".", "transform", "(", "self", ".", "loader", "(", "path", ")", ")", ")", "\n", "self", ".", "labels", ".", "append", "(", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.ImageFolder.__getitem__": [[149, 171], ["datasets.ImageFolder.loader", "datasets.ImageFolder.target_transform", "int", "str", "datasets.ImageFolder.transform"], "methods", ["None"], ["", "", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (image, target) where target is class_index of the target class.\n        \"\"\"", "\n", "if", "self", ".", "load_in_mem", ":", "\n", "            ", "img", "=", "self", ".", "data", "[", "index", "]", "\n", "target", "=", "self", ".", "labels", "[", "index", "]", "\n", "", "else", ":", "\n", "            ", "path", ",", "target", "=", "self", ".", "imgs", "[", "index", "]", "\n", "img", "=", "self", ".", "loader", "(", "str", "(", "path", ")", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "                ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "#print(img.size(), target)", "\n", "", "return", "img", ",", "int", "(", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.ImageFolder.__len__": [[172, 174], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "imgs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.ImageFolder.__repr__": [[175, 186], ["datasets.ImageFolder.__len__", "datasets.ImageFolder.transform.__repr__().replace", "datasets.ImageFolder.target_transform.__repr__().replace", "datasets.ImageFolder.transform.__repr__", "datasets.ImageFolder.target_transform.__repr__", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CelebA.__len__", "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.ImageFolder.__repr__", "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.ImageFolder.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "fmt_str", "=", "'Dataset '", "+", "self", ".", "__class__", ".", "__name__", "+", "'\\n'", "\n", "fmt_str", "+=", "'    Number of datapoints: {}\\n'", ".", "format", "(", "self", ".", "__len__", "(", ")", ")", "\n", "fmt_str", "+=", "'    Root Location: {}\\n'", ".", "format", "(", "self", ".", "root", ")", "\n", "tmp", "=", "'    Transforms (if any): '", "\n", "fmt_str", "+=", "'{0}{1}\\n'", ".", "format", "(", "\n", "tmp", ",", "self", ".", "transform", ".", "__repr__", "(", ")", ".", "replace", "(", "'\\n'", ",", "'\\n'", "+", "' '", "*", "len", "(", "tmp", ")", ")", ")", "\n", "tmp", "=", "'    Target Transforms (if any): '", "\n", "fmt_str", "+=", "'{0}{1}'", ".", "format", "(", "\n", "tmp", ",", "self", ".", "target_transform", ".", "__repr__", "(", ")", ".", "replace", "(", "'\\n'", ",", "'\\n'", "+", "' '", "*", "len", "(", "tmp", ")", ")", ")", "\n", "return", "fmt_str", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.ILSVRC_HDF5.__init__": [[193, 215], ["len", "print", "h5py.File", "h5py.File"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "\n", "load_in_mem", "=", "False", ",", "train", "=", "True", ",", "download", "=", "False", ",", "validate_seed", "=", "0", ",", "\n", "val_split", "=", "0", ",", "**", "kwargs", ")", ":", "# last four are dummies", "\n", "\n", "        ", "self", ".", "root", "=", "root", "\n", "self", ".", "num_imgs", "=", "len", "(", "h5", ".", "File", "(", "root", ",", "'r'", ")", "[", "'labels'", "]", ")", "\n", "\n", "# self.transform = transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "\n", "# Set the transform here", "\n", "self", ".", "transform", "=", "transform", "\n", "\n", "# load the entire dataset into memory?", "\n", "self", ".", "load_in_mem", "=", "load_in_mem", "\n", "\n", "# If loading into memory, do so now", "\n", "if", "self", ".", "load_in_mem", ":", "\n", "            ", "print", "(", "'Loading %s into memory...'", "%", "root", ")", "\n", "with", "h5", ".", "File", "(", "root", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "self", ".", "data", "=", "f", "[", "'imgs'", "]", "[", ":", "]", "\n", "self", ".", "labels", "=", "f", "[", "'labels'", "]", "[", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.ILSVRC_HDF5.__getitem__": [[216, 244], ["datasets.ILSVRC_HDF5.target_transform", "int", "h5py.File", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (image, target) where target is class_index of the target class.\n        \"\"\"", "\n", "# If loaded the entire dataset in RAM, get image from memory", "\n", "if", "self", ".", "load_in_mem", ":", "\n", "            ", "img", "=", "self", ".", "data", "[", "index", "]", "\n", "target", "=", "self", ".", "labels", "[", "index", "]", "\n", "\n", "# Else load it from disk", "\n", "", "else", ":", "\n", "            ", "with", "h5", ".", "File", "(", "self", ".", "root", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "img", "=", "f", "[", "'imgs'", "]", "[", "index", "]", "\n", "target", "=", "f", "[", "'labels'", "]", "[", "index", "]", "\n", "\n", "# if self.transform is not None:", "\n", "# img = self.transform(img)", "\n", "# Apply my own transform", "\n", "", "", "img", "=", "(", "(", "torch", ".", "from_numpy", "(", "img", ")", ".", "float", "(", ")", "/", "255", ")", "-", "0.5", ")", "*", "2", "\n", "\n", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "int", "(", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.ILSVRC_HDF5.__len__": [[245, 247], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_imgs", "\n", "# return len(self.f['imgs'])", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CIFAR10.__init__": [[252, 336], ["os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "numpy.concatenate", "datasets.CIFAR10.download", "datasets.CIFAR10._check_integrity", "RuntimeError", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open", "datasets.CIFAR10.data.append", "open.close", "enumerate", "numpy.asarray", "numpy.random.seed", "list", "datasets.CIFAR10.data.reshape", "datasets.CIFAR10.data.transpose", "pickle.load", "pickle.load", "list", "print", "datasets.CIFAR10.data.reshape", "datasets.CIFAR10.data.transpose", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open", "open.close", "datasets.CIFAR10.data.reshape", "datasets.CIFAR10.data.transpose", "range", "numpy.asarray", "int", "numpy.shape", "numpy.delete", "list", "pickle.load", "pickle.load", "numpy.delete", "int", "max", "numpy.random.choice", "numpy.asarray", "len", "int", "max", "len"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CelebA.download", "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CelebA._check_integrity"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "train", "=", "True", ",", "\n", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "\n", "download", "=", "True", ",", "validate_seed", "=", "0", ",", "\n", "val_split", "=", "0", ",", "load_in_mem", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "root", "=", "os", ".", "path", ".", "expanduser", "(", "root", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "train", "=", "train", "# training set or test set", "\n", "self", ".", "val_split", "=", "val_split", "\n", "\n", "if", "download", ":", "\n", "            ", "self", ".", "download", "(", ")", "\n", "\n", "", "if", "not", "self", ".", "_check_integrity", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Dataset not found or corrupted.'", "+", "\n", "' You can use download=True to download it'", ")", "\n", "\n", "# now load the picked numpy arrays", "\n", "", "self", ".", "data", "=", "[", "]", "\n", "self", ".", "labels", "=", "[", "]", "\n", "for", "fentry", "in", "self", ".", "train_list", ":", "\n", "            ", "f", "=", "fentry", "[", "0", "]", "\n", "file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "base_folder", ",", "f", ")", "\n", "fo", "=", "open", "(", "file", ",", "'rb'", ")", "\n", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "                ", "entry", "=", "pickle", ".", "load", "(", "fo", ")", "\n", "", "else", ":", "\n", "                ", "entry", "=", "pickle", ".", "load", "(", "fo", ",", "encoding", "=", "'latin1'", ")", "\n", "", "self", ".", "data", ".", "append", "(", "entry", "[", "'data'", "]", ")", "\n", "if", "'labels'", "in", "entry", ":", "\n", "                ", "self", ".", "labels", "+=", "entry", "[", "'labels'", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "labels", "+=", "entry", "[", "'fine_labels'", "]", "\n", "", "fo", ".", "close", "(", ")", "\n", "\n", "", "self", ".", "data", "=", "np", ".", "concatenate", "(", "self", ".", "data", ")", "\n", "# Randomly select indices for validation", "\n", "if", "self", ".", "val_split", ">", "0", ":", "\n", "            ", "label_indices", "=", "[", "[", "]", "for", "_", "in", "range", "(", "max", "(", "self", ".", "labels", ")", "+", "1", ")", "]", "\n", "for", "i", ",", "l", "in", "enumerate", "(", "self", ".", "labels", ")", ":", "\n", "                ", "label_indices", "[", "l", "]", "+=", "[", "i", "]", "\n", "", "label_indices", "=", "np", ".", "asarray", "(", "label_indices", ")", "\n", "\n", "# randomly grab 500 elements of each class", "\n", "np", ".", "random", ".", "seed", "(", "validate_seed", ")", "\n", "self", ".", "val_indices", "=", "[", "]", "\n", "for", "l_i", "in", "label_indices", ":", "\n", "                ", "self", ".", "val_indices", "+=", "list", "(", "l_i", "[", "np", ".", "random", ".", "choice", "(", "len", "(", "l_i", ")", ",", "int", "(", "\n", "len", "(", "self", ".", "data", ")", "*", "val_split", ")", "//", "(", "max", "(", "self", ".", "labels", ")", "+", "1", ")", ",", "replace", "=", "False", ")", "]", ")", "\n", "\n", "", "", "if", "self", ".", "train", "==", "'validate'", ":", "\n", "            ", "self", ".", "data", "=", "self", ".", "data", "[", "self", ".", "val_indices", "]", "\n", "self", ".", "labels", "=", "list", "(", "np", ".", "asarray", "(", "self", ".", "labels", ")", "[", "self", ".", "val_indices", "]", ")", "\n", "\n", "self", ".", "data", "=", "self", ".", "data", ".", "reshape", "(", "\n", "(", "int", "(", "50e3", "*", "self", ".", "val_split", ")", ",", "3", ",", "32", ",", "32", ")", ")", "\n", "self", ".", "data", "=", "self", ".", "data", ".", "transpose", "(", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "# convert to HWC", "\n", "\n", "", "elif", "self", ".", "train", ":", "\n", "            ", "print", "(", "np", ".", "shape", "(", "self", ".", "data", ")", ")", "\n", "if", "self", ".", "val_split", ">", "0", ":", "\n", "                ", "self", ".", "data", "=", "np", ".", "delete", "(", "self", ".", "data", ",", "self", ".", "val_indices", ",", "axis", "=", "0", ")", "\n", "self", ".", "labels", "=", "list", "(", "np", ".", "delete", "(", "np", ".", "asarray", "(", "\n", "self", ".", "labels", ")", ",", "self", ".", "val_indices", ",", "axis", "=", "0", ")", ")", "\n", "\n", "", "self", ".", "data", "=", "self", ".", "data", ".", "reshape", "(", "\n", "(", "int", "(", "50e3", "*", "(", "1.", "-", "self", ".", "val_split", ")", ")", ",", "3", ",", "32", ",", "32", ")", ")", "\n", "self", ".", "data", "=", "self", ".", "data", ".", "transpose", "(", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "# convert to HWC", "\n", "", "else", ":", "\n", "            ", "f", "=", "self", ".", "test_list", "[", "0", "]", "[", "0", "]", "\n", "file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "base_folder", ",", "f", ")", "\n", "fo", "=", "open", "(", "file", ",", "'rb'", ")", "\n", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "                ", "entry", "=", "pickle", ".", "load", "(", "fo", ")", "\n", "", "else", ":", "\n", "                ", "entry", "=", "pickle", ".", "load", "(", "fo", ",", "encoding", "=", "'latin1'", ")", "\n", "", "self", ".", "data", "=", "entry", "[", "'data'", "]", "\n", "if", "'labels'", "in", "entry", ":", "\n", "                ", "self", ".", "labels", "=", "entry", "[", "'labels'", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "labels", "=", "entry", "[", "'fine_labels'", "]", "\n", "", "fo", ".", "close", "(", ")", "\n", "self", ".", "data", "=", "self", ".", "data", ".", "reshape", "(", "(", "10000", ",", "3", ",", "32", ",", "32", ")", ")", "\n", "self", ".", "data", "=", "self", ".", "data", ".", "transpose", "(", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "# convert to HWC", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CIFAR10.__getitem__": [[337, 357], ["PIL.Image.fromarray", "datasets.CIFAR10.transform", "datasets.CIFAR10.target_transform"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is index of the target class.\n        \"\"\"", "\n", "img", ",", "target", "=", "self", ".", "data", "[", "index", "]", ",", "self", ".", "labels", "[", "index", "]", "\n", "\n", "# doing this so that it is consistent with all other datasets", "\n", "# to return a PIL Image", "\n", "img", "=", "Image", ".", "fromarray", "(", "img", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CIFAR10.__len__": [[358, 360], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CIFAR10Unsupervised.__getitem__": [[363, 367], ["datasets.CIFAR10.__getitem__"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CelebA.__getitem__"], ["    ", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "img", ",", "target", "=", "super", "(", ")", ".", "__getitem__", "(", "index", ")", "\n", "target", "=", "0", "\n", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CINIC10Unsupervised.__getitem__": [[369, 373], ["datasets.ImageFolder.__getitem__"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CelebA.__getitem__"], ["    ", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "img", ",", "target", "=", "super", "(", ")", ".", "__getitem__", "(", "index", ")", "\n", "target", "=", "0", "\n", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.Art.__getitem__": [[375, 378], ["datasets.ImageFolder.__getitem__"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CelebA.__getitem__"], ["    ", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "img", ",", "target", "=", "super", "(", ")", ".", "__getitem__", "(", "index", ")", "\n", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CIFAR100Unsupervised.__getitem__": [[394, 398], ["datasets.CIFAR10.__getitem__"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CelebA.__getitem__"], ["    ", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "img", ",", "target", "=", "super", "(", ")", ".", "__getitem__", "(", "index", ")", "\n", "target", "=", "0", "\n", "return", "img", ",", "target", "\n", "", "", "class", "STL10", "(", "dset", ".", "STL10", ")", ":", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.STL10.__init__": [[399, 405], ["torchvision.STL10.__init__"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "train", "=", "True", ",", "\n", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "\n", "download", "=", "True", ",", "validate_seed", "=", "0", ",", "\n", "val_split", "=", "0", ",", "load_in_mem", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "STL10", ",", "self", ")", ".", "__init__", "(", "root", ",", "split", "=", "'unlabeled'", ",", "download", "=", "download", ",", "\n", "transform", "=", "transform", ",", "target_transform", "=", "target_transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.STL10.__getitem__": [[406, 423], ["PIL.Image.fromarray", "numpy.transpose", "datasets.STL10.transform", "datasets.STL10.target_transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "# if self.labels is not None:", "\n", "#     img, target = self.data[index], int(self.labels[index])", "\n", "# else:", "\n", "        ", "img", ",", "target", "=", "self", ".", "data", "[", "index", "]", ",", "0", "\n", "\n", "# doing this so that it is consistent with all other datasets", "\n", "# to return a PIL Image", "\n", "img", "=", "Image", ".", "fromarray", "(", "np", ".", "transpose", "(", "img", ",", "(", "1", ",", "2", ",", "0", ")", ")", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CelebA.__init__": [[472, 538], ["torch.Dataset.__init__", "isinstance", "isinstance", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "datasets.CelebA.download", "datasets.CelebA._check_integrity", "RuntimeError", "split.lower", "open", "pandas.read_csv", "open", "pandas.read_csv", "open", "pandas.read_csv", "open", "pandas.read_csv", "open", "pandas.read_csv", "split.lower", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "split.lower", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__", "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CelebA.download", "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CelebA._check_integrity"], ["def", "__init__", "(", "self", ",", "root", ",", "\n", "split", "=", "\"train\"", ",", "\n", "target_type", "=", "\"attr\"", ",", "\n", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "load_in_mem", "=", "False", ",", "\n", "download", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "import", "pandas", "\n", "super", "(", "CelebA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "root", ",", "torch", ".", "_six", ".", "string_classes", ")", ":", "\n", "            ", "root", "=", "os", ".", "path", ".", "expanduser", "(", "root", ")", "\n", "", "self", ".", "root", "=", "root", "\n", "\n", "self", ".", "split", "=", "split", "\n", "if", "isinstance", "(", "target_type", ",", "list", ")", ":", "\n", "            ", "self", ".", "target_type", "=", "target_type", "\n", "", "else", ":", "\n", "            ", "self", ".", "target_type", "=", "[", "target_type", "]", "\n", "", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "\n", "if", "download", ":", "\n", "            ", "self", ".", "download", "(", ")", "\n", "\n", "", "if", "not", "self", ".", "_check_integrity", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Dataset not found or corrupted.'", "+", "\n", "' You can use download=True to download it'", ")", "\n", "\n", "", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "\n", "if", "split", ".", "lower", "(", ")", "==", "\"train\"", ":", "\n", "            ", "split", "=", "0", "\n", "", "elif", "split", ".", "lower", "(", ")", "==", "\"valid\"", ":", "\n", "            ", "split", "=", "1", "\n", "", "elif", "split", ".", "lower", "(", ")", "==", "\"test\"", ":", "\n", "            ", "split", "=", "2", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Wrong split entered! Please use split=\"train\" '", "\n", "'or split=\"valid\" or split=\"test\"'", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "base_folder", ",", "\"list_eval_partition.txt\"", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "splits", "=", "pandas", ".", "read_csv", "(", "\n", "f", ",", "delim_whitespace", "=", "True", ",", "header", "=", "None", ",", "index_col", "=", "0", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "base_folder", ",", "\"identity_CelebA.txt\"", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "self", ".", "identity", "=", "pandas", ".", "read_csv", "(", "\n", "f", ",", "delim_whitespace", "=", "True", ",", "header", "=", "None", ",", "index_col", "=", "0", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "base_folder", ",", "\"list_bbox_celeba.txt\"", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "self", ".", "bbox", "=", "pandas", ".", "read_csv", "(", "\n", "f", ",", "delim_whitespace", "=", "True", ",", "header", "=", "1", ",", "index_col", "=", "0", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "base_folder", ",", "\"list_landmarks_align_celeba.txt\"", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "self", ".", "landmarks_align", "=", "pandas", ".", "read_csv", "(", "\n", "f", ",", "delim_whitespace", "=", "True", ",", "header", "=", "1", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "base_folder", ",", "\"list_attr_celeba.txt\"", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "self", ".", "attr", "=", "pandas", ".", "read_csv", "(", "f", ",", "delim_whitespace", "=", "True", ",", "header", "=", "1", ")", "\n", "\n", "", "mask", "=", "(", "splits", "[", "1", "]", "==", "split", ")", "\n", "self", ".", "filename", "=", "splits", "[", "mask", "]", ".", "index", ".", "values", "\n", "self", ".", "identity", "=", "torch", ".", "as_tensor", "(", "self", ".", "identity", "[", "mask", "]", ".", "values", ")", "\n", "self", ".", "bbox", "=", "torch", ".", "as_tensor", "(", "self", ".", "bbox", "[", "mask", "]", ".", "values", ")", "\n", "self", ".", "landmarks_align", "=", "torch", ".", "as_tensor", "(", "\n", "self", ".", "landmarks_align", "[", "mask", "]", ".", "values", ")", "\n", "self", ".", "attr", "=", "torch", ".", "as_tensor", "(", "self", ".", "attr", "[", "mask", "]", ".", "values", ")", "\n", "self", ".", "attr", "=", "(", "self", ".", "attr", "+", "1", ")", "//", "2", "# map from {-1, 1} to {0, 1}", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CelebA._check_integrity": [[539, 550], ["os.path.isdir", "os.path.isdir", "os.path.isdir", "os.path.isdir", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.splitext", "os.path.splitext", "os.path.splitext", "os.path.splitext", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "dataset_utils.check_integrity"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.dataset_utils.check_integrity"], ["", "def", "_check_integrity", "(", "self", ")", ":", "\n", "        ", "for", "(", "_", ",", "md5", ",", "filename", ")", "in", "self", ".", "file_list", ":", "\n", "            ", "fpath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "base_folder", ",", "filename", ")", "\n", "_", ",", "ext", "=", "os", ".", "path", ".", "splitext", "(", "filename", ")", "\n", "# Allow original archive to be deleted (zip and 7z)", "\n", "# Only need the extracted images", "\n", "if", "ext", "not", "in", "[", "\".zip\"", ",", "\".7z\"", "]", "and", "not", "check_integrity", "(", "fpath", ",", "md5", ")", ":", "\n", "                ", "return", "False", "\n", "\n", "# Should check a hash of the images", "\n", "", "", "return", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "base_folder", ",", "\"img_align_celeba\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CelebA.download": [[551, 564], ["datasets.CelebA._check_integrity", "print", "dataset_utils.download_file_from_google_drive", "zipfile.ZipFile", "f.extractall", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CelebA._check_integrity", "home.repos.pwc.inspect_result.ermongroup_NDA.None.dataset_utils.download_file_from_google_drive"], ["", "def", "download", "(", "self", ")", ":", "\n", "        ", "import", "zipfile", "\n", "\n", "if", "self", ".", "_check_integrity", "(", ")", ":", "\n", "            ", "print", "(", "'Files already downloaded and verified'", ")", "\n", "return", "\n", "\n", "", "for", "(", "file_id", ",", "md5", ",", "filename", ")", "in", "self", ".", "file_list", ":", "\n", "            ", "download_file_from_google_drive", "(", "file_id", ",", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "root", ",", "self", ".", "base_folder", ")", ",", "filename", ",", "md5", ")", "\n", "\n", "", "with", "zipfile", ".", "ZipFile", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "base_folder", ",", "\"img_align_celeba.zip\"", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "extractall", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "base_folder", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CelebA.__getitem__": [[565, 591], ["PIL.Image.open", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "tuple", "datasets.CelebA.transform", "datasets.CelebA.target_transform", "datasets.CelebA.append", "len", "datasets.CelebA.append", "datasets.CelebA.append", "datasets.CelebA.append", "ValueError"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "X", "=", "PIL", ".", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "root", ",", "self", ".", "base_folder", ",", "\"img_align_celeba\"", ",", "self", ".", "filename", "[", "index", "]", ")", ")", "\n", "\n", "target", "=", "[", "]", "\n", "for", "t", "in", "self", ".", "target_type", ":", "\n", "            ", "if", "t", "==", "\"attr\"", ":", "\n", "                ", "target", ".", "append", "(", "self", ".", "attr", "[", "index", ",", ":", "]", ")", "\n", "", "elif", "t", "==", "\"identity\"", ":", "\n", "                ", "target", ".", "append", "(", "self", ".", "identity", "[", "index", ",", "0", "]", ")", "\n", "", "elif", "t", "==", "\"bbox\"", ":", "\n", "                ", "target", ".", "append", "(", "self", ".", "bbox", "[", "index", ",", ":", "]", ")", "\n", "", "elif", "t", "==", "\"landmarks\"", ":", "\n", "                ", "target", ".", "append", "(", "self", ".", "landmarks_align", "[", "index", ",", ":", "]", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Target type \\\"{}\\\" is not recognized.\"", ".", "format", "(", "t", ")", ")", "\n", "", "", "target", "=", "tuple", "(", "target", ")", "if", "len", "(", "target", ")", ">", "1", "else", "target", "[", "0", "]", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "X", "=", "self", ".", "transform", "(", "X", ")", "\n", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "X", ",", "0", "# target", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CelebA.__len__": [[592, 594], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "attr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.CelebA.extra_repr": [[595, 598], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "lines", "=", "[", "\"Target type: {target_type}\"", ",", "\"Split: {split}\"", "]", "\n", "return", "'\\n'", ".", "join", "(", "lines", ")", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.is_image_file": [[25, 36], ["filename.lower", "any", "filename.lower.endswith"], "function", ["None"], ["def", "is_image_file", "(", "filename", ")", ":", "\n", "    ", "\"\"\"Checks if a file is an image.\n\n    Args:\n        filename (string): path to a file\n\n    Returns:\n        bool: True if the filename ends with a known image extension\n    \"\"\"", "\n", "filename_lower", "=", "filename", ".", "lower", "(", ")", "\n", "return", "any", "(", "filename_lower", ".", "endswith", "(", "ext", ")", "for", "ext", "in", "IMG_EXTENSIONS", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.find_classes": [[38, 44], ["classes.sort", "os.listdir", "os.listdir", "os.path.isdir", "os.path.isdir", "range", "os.path.join", "os.path.join", "len"], "function", ["None"], ["", "def", "find_classes", "(", "dir", ")", ":", "\n", "    ", "classes", "=", "[", "d", "for", "d", "in", "os", ".", "listdir", "(", "\n", "dir", ")", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "d", ")", ")", "]", "\n", "classes", ".", "sort", "(", ")", "\n", "class_to_idx", "=", "{", "classes", "[", "i", "]", ":", "i", "for", "i", "in", "range", "(", "len", "(", "classes", ")", ")", "}", "\n", "return", "classes", ",", "class_to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.make_dataset": [[46, 62], ["os.path.expanduser", "os.path.expanduser", "tqdm.tqdm", "sorted", "os.path.join", "os.path.join", "sorted", "os.listdir", "os.listdir", "os.path.isdir", "os.path.isdir", "os.walk", "os.walk", "sorted", "datasets.is_image_file", "os.path.join", "os.path.join", "images.append"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.is_image_file"], ["", "def", "make_dataset", "(", "dir", ",", "class_to_idx", ")", ":", "\n", "    ", "images", "=", "[", "]", "\n", "dir", "=", "os", ".", "path", ".", "expanduser", "(", "dir", ")", "\n", "for", "target", "in", "tqdm", "(", "sorted", "(", "os", ".", "listdir", "(", "dir", ")", ")", ")", ":", "\n", "        ", "d", "=", "os", ".", "path", ".", "join", "(", "dir", ",", "target", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "d", ")", ":", "\n", "            ", "continue", "\n", "\n", "", "for", "root", ",", "_", ",", "fnames", "in", "sorted", "(", "os", ".", "walk", "(", "d", ")", ")", ":", "\n", "            ", "for", "fname", "in", "sorted", "(", "fnames", ")", ":", "\n", "                ", "if", "is_image_file", "(", "fname", ")", ":", "\n", "                    ", "path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "fname", ")", "\n", "item", "=", "(", "path", ",", "class_to_idx", "[", "target", "]", ")", "\n", "images", ".", "append", "(", "item", ")", "\n", "\n", "", "", "", "", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.pil_loader": [[64, 69], ["open", "PIL.Image.open", "Image.open.convert"], "function", ["None"], ["", "def", "pil_loader", "(", "path", ")", ":", "\n", "# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)", "\n", "    ", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "img", "=", "Image", ".", "open", "(", "f", ")", "\n", "return", "img", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.accimage_loader": [[71, 78], ["accimage.Image", "datasets.pil_loader"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.pil_loader"], ["", "", "def", "accimage_loader", "(", "path", ")", ":", "\n", "    ", "import", "accimage", "\n", "try", ":", "\n", "        ", "return", "accimage", ".", "Image", "(", "path", ")", "\n", "", "except", "IOError", ":", "\n", "# Potentially a decoding problem, fall back to PIL.Image", "\n", "        ", "return", "pil_loader", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.default_loader": [[80, 86], ["get_image_backend", "datasets.accimage_loader", "datasets.pil_loader"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.accimage_loader", "home.repos.pwc.inspect_result.ermongroup_NDA.None.datasets.pil_loader"], ["", "", "def", "default_loader", "(", "path", ")", ":", "\n", "    ", "from", "torchvision", "import", "get_image_backend", "\n", "if", "get_image_backend", "(", ")", "==", "'accimage'", ":", "\n", "        ", "return", "accimage_loader", "(", "path", ")", "\n", "", "else", ":", "\n", "        ", "return", "pil_loader", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf.create_inception_graph": [[34, 41], ["tensorflow.gfile.FastGFile", "tensorflow.GraphDef", "tf.GraphDef.ParseFromString", "tensorflow.import_graph_def", "f.read"], "function", ["None"], ["", "def", "create_inception_graph", "(", "pth", ")", ":", "\n", "    ", "\"\"\"Creates a graph from saved GraphDef file.\"\"\"", "\n", "# Creates graph from saved graph_def.pb.", "\n", "with", "tf", ".", "gfile", ".", "FastGFile", "(", "pth", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "graph_def", "=", "tf", ".", "GraphDef", "(", ")", "\n", "graph_def", ".", "ParseFromString", "(", "f", ".", "read", "(", ")", ")", "\n", "_", "=", "tf", ".", "import_graph_def", "(", "graph_def", ",", "name", "=", "'FID_Inception_Net'", ")", "\n", "#-------------------------------------------------------------------------------", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf._get_inception_layer": [[46, 64], ["sess.graph.get_tensor_by_name", "sess.graph.get_tensor_by_name.graph.get_operations", "enumerate", "o.get_shape", "enumerate", "tensorflow.TensorShape", "new_shape.append", "new_shape.append"], "function", ["None"], ["", "", "def", "_get_inception_layer", "(", "sess", ")", ":", "\n", "    ", "\"\"\"Prepares inception net for batched usage and returns pool_3 layer. \"\"\"", "\n", "layername", "=", "'FID_Inception_Net/pool_3:0'", "\n", "pool3", "=", "sess", ".", "graph", ".", "get_tensor_by_name", "(", "layername", ")", "\n", "ops", "=", "pool3", ".", "graph", ".", "get_operations", "(", ")", "\n", "for", "op_idx", ",", "op", "in", "enumerate", "(", "ops", ")", ":", "\n", "        ", "for", "o", "in", "op", ".", "outputs", ":", "\n", "            ", "shape", "=", "o", ".", "get_shape", "(", ")", "\n", "if", "shape", ".", "_dims", "!=", "[", "]", ":", "\n", "              ", "shape", "=", "[", "s", ".", "value", "for", "s", "in", "shape", "]", "\n", "new_shape", "=", "[", "]", "\n", "for", "j", ",", "s", "in", "enumerate", "(", "shape", ")", ":", "\n", "                ", "if", "s", "==", "1", "and", "j", "==", "0", ":", "\n", "                  ", "new_shape", ".", "append", "(", "None", ")", "\n", "", "else", ":", "\n", "                  ", "new_shape", ".", "append", "(", "s", ")", "\n", "", "", "o", ".", "__dict__", "[", "'_shape_val'", "]", "=", "tf", ".", "TensorShape", "(", "new_shape", ")", "\n", "", "", "", "return", "pool3", "\n", "#-------------------------------------------------------------------------------", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf.get_activations": [[67, 101], ["fid_tf._get_inception_layer", "numpy.empty", "range", "print", "sess.run", "sess.run.reshape", "print", "print"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf._get_inception_layer", "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_aug.run"], ["", "def", "get_activations", "(", "images", ",", "sess", ",", "batch_size", "=", "50", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculates the activations of the pool_3 layer for all images.\n\n    Params:\n    -- images      : Numpy array of dimension (n_images, hi, wi, 3). The values\n                     must lie between 0 and 256.\n    -- sess        : current session\n    -- batch_size  : the images numpy array is split into batches with batch size\n                     batch_size. A reasonable batch size depends on the disposable hardware.\n    -- verbose    : If set to True and parameter out_step is given, the number of calculated\n                     batches is reported.\n    Returns:\n    -- A numpy array of dimension (num images, 2048) that contains the\n       activations of the given tensor when feeding inception with the query tensor.\n    \"\"\"", "\n", "inception_layer", "=", "_get_inception_layer", "(", "sess", ")", "\n", "d0", "=", "images", ".", "shape", "[", "0", "]", "\n", "if", "batch_size", ">", "d0", ":", "\n", "        ", "print", "(", "\"warning: batch size is bigger than the data size. setting batch size to data size\"", ")", "\n", "batch_size", "=", "d0", "\n", "", "n_batches", "=", "d0", "//", "batch_size", "\n", "n_used_imgs", "=", "n_batches", "*", "batch_size", "\n", "pred_arr", "=", "np", ".", "empty", "(", "(", "n_used_imgs", ",", "2048", ")", ")", "\n", "for", "i", "in", "range", "(", "n_batches", ")", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "\"\\rPropagating batch %d/%d\"", "%", "(", "i", "+", "1", ",", "n_batches", ")", ",", "end", "=", "\"\"", ",", "flush", "=", "True", ")", "\n", "", "start", "=", "i", "*", "batch_size", "\n", "end", "=", "start", "+", "batch_size", "\n", "batch", "=", "images", "[", "start", ":", "end", "]", "\n", "pred", "=", "sess", ".", "run", "(", "inception_layer", ",", "{", "'FID_Inception_Net/ExpandDims:0'", ":", "batch", "}", ")", "\n", "pred_arr", "[", "start", ":", "end", "]", "=", "pred", ".", "reshape", "(", "batch_size", ",", "-", "1", ")", "\n", "", "if", "verbose", ":", "\n", "        ", "print", "(", "\" done\"", ")", "\n", "", "return", "pred_arr", "\n", "#-------------------------------------------------------------------------------", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf.calculate_frechet_distance": [[104, 156], ["numpy.atleast_1d", "numpy.atleast_1d", "numpy.atleast_2d", "numpy.atleast_2d", "scipy.linalg.sqrtm", "numpy.iscomplexobj", "numpy.trace", "np.atleast_2d.dot", "numpy.isfinite().all", "warnings.warn", "scipy.linalg.sqrtm", "numpy.eye", "numpy.allclose", "numpy.max", "ValueError", "numpy.trace", "numpy.isfinite", "numpy.abs", "diff.dot", "numpy.trace", "numpy.diagonal"], "function", ["None"], ["", "def", "calculate_frechet_distance", "(", "mu1", ",", "sigma1", ",", "mu2", ",", "sigma2", ",", "eps", "=", "1e-6", ")", ":", "\n", "    ", "\"\"\"Numpy implementation of the Frechet Distance.\n    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n    and X_2 ~ N(mu_2, C_2) is\n            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n            \n    Stable version by Dougal J. Sutherland.\n\n    Params:\n    -- mu1 : Numpy array containing the activations of the pool_3 layer of the\n             inception net ( like returned by the function 'get_predictions')\n             for generated samples.\n    -- mu2   : The sample mean over activations of the pool_3 layer, precalcualted\n               on an representive data set.\n    -- sigma1: The covariance matrix over activations of the pool_3 layer for\n               generated samples.\n    -- sigma2: The covariance matrix over activations of the pool_3 layer,\n               precalcualted on an representive data set.\n\n    Returns:\n    --   : The Frechet Distance.\n    \"\"\"", "\n", "\n", "mu1", "=", "np", ".", "atleast_1d", "(", "mu1", ")", "\n", "mu2", "=", "np", ".", "atleast_1d", "(", "mu2", ")", "\n", "\n", "sigma1", "=", "np", ".", "atleast_2d", "(", "sigma1", ")", "\n", "sigma2", "=", "np", ".", "atleast_2d", "(", "sigma2", ")", "\n", "\n", "assert", "mu1", ".", "shape", "==", "mu2", ".", "shape", ",", "\"Training and test mean vectors have different lengths\"", "\n", "assert", "sigma1", ".", "shape", "==", "sigma2", ".", "shape", ",", "\"Training and test covariances have different dimensions\"", "\n", "\n", "diff", "=", "mu1", "-", "mu2", "\n", "\n", "# product might be almost singular", "\n", "covmean", ",", "_", "=", "linalg", ".", "sqrtm", "(", "sigma1", ".", "dot", "(", "sigma2", ")", ",", "disp", "=", "False", ")", "\n", "if", "not", "np", ".", "isfinite", "(", "covmean", ")", ".", "all", "(", ")", ":", "\n", "        ", "msg", "=", "\"fid calculation produces singular product; adding %s to diagonal of cov estimates\"", "%", "eps", "\n", "warnings", ".", "warn", "(", "msg", ")", "\n", "offset", "=", "np", ".", "eye", "(", "sigma1", ".", "shape", "[", "0", "]", ")", "*", "eps", "\n", "covmean", "=", "linalg", ".", "sqrtm", "(", "(", "sigma1", "+", "offset", ")", ".", "dot", "(", "sigma2", "+", "offset", ")", ")", "\n", "\n", "# numerical error might give slight imaginary component", "\n", "", "if", "np", ".", "iscomplexobj", "(", "covmean", ")", ":", "\n", "        ", "if", "not", "np", ".", "allclose", "(", "np", ".", "diagonal", "(", "covmean", ")", ".", "imag", ",", "0", ",", "atol", "=", "1e-3", ")", ":", "\n", "            ", "m", "=", "np", ".", "max", "(", "np", ".", "abs", "(", "covmean", ".", "imag", ")", ")", "\n", "raise", "ValueError", "(", "\"Imaginary component {}\"", ".", "format", "(", "m", ")", ")", "\n", "", "covmean", "=", "covmean", ".", "real", "\n", "\n", "", "tr_covmean", "=", "np", ".", "trace", "(", "covmean", ")", "\n", "\n", "return", "diff", ".", "dot", "(", "diff", ")", "+", "np", ".", "trace", "(", "sigma1", ")", "+", "np", ".", "trace", "(", "sigma2", ")", "-", "2", "*", "tr_covmean", "\n", "#-------------------------------------------------------------------------------", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf.calculate_activation_statistics": [[159, 179], ["fid_tf.get_activations", "numpy.mean", "numpy.cov"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf.get_activations"], ["", "def", "calculate_activation_statistics", "(", "images", ",", "sess", ",", "batch_size", "=", "50", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculation of the statistics used by the FID.\n    Params:\n    -- images      : Numpy array of dimension (n_images, hi, wi, 3). The values\n                     must lie between 0 and 255.\n    -- sess        : current session\n    -- batch_size  : the images numpy array is split into batches with batch size\n                     batch_size. A reasonable batch size depends on the available hardware.\n    -- verbose     : If set to True and parameter out_step is given, the number of calculated\n                     batches is reported.\n    Returns:\n    -- mu    : The mean over samples of the activations of the pool_3 layer of\n               the incption model.\n    -- sigma : The covariance matrix of the activations of the pool_3 layer of\n               the incption model.\n    \"\"\"", "\n", "act", "=", "get_activations", "(", "images", ",", "sess", ",", "batch_size", ",", "verbose", ")", "\n", "mu", "=", "np", ".", "mean", "(", "act", ",", "axis", "=", "0", ")", "\n", "sigma", "=", "np", ".", "cov", "(", "act", ",", "rowvar", "=", "False", ")", "\n", "return", "mu", ",", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf.load_image_batch": [[188, 196], ["numpy.array", "imageio.imread().astype", "imageio.imread", "str"], "function", ["None"], ["", "def", "load_image_batch", "(", "files", ")", ":", "\n", "    ", "\"\"\"Convenience method for batch-loading images\n    Params:\n    -- files    : list of paths to image files. Images need to have same dimensions for all files.\n    Returns:\n    -- A numpy array of dimensions (num_images,hi, wi, 3) representing the image pixel values.\n    \"\"\"", "\n", "return", "np", ".", "array", "(", "[", "imread", "(", "str", "(", "fn", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "for", "fn", "in", "files", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf.get_activations_from_files": [[197, 231], ["fid_tf._get_inception_layer", "len", "numpy.empty", "range", "print", "fid_tf.load_image_batch", "sess.run", "sess.run.reshape", "print", "print"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf._get_inception_layer", "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf.load_image_batch", "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_aug.run"], ["", "def", "get_activations_from_files", "(", "files", ",", "sess", ",", "batch_size", "=", "50", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculates the activations of the pool_3 layer for all images.\n\n    Params:\n    -- files      : list of paths to image files. Images need to have same dimensions for all files.\n    -- sess        : current session\n    -- batch_size  : the images numpy array is split into batches with batch size\n                     batch_size. A reasonable batch size depends on the disposable hardware.\n    -- verbose    : If set to True and parameter out_step is given, the number of calculated\n                     batches is reported.\n    Returns:\n    -- A numpy array of dimension (num images, 2048) that contains the\n       activations of the given tensor when feeding inception with the query tensor.\n    \"\"\"", "\n", "inception_layer", "=", "_get_inception_layer", "(", "sess", ")", "\n", "d0", "=", "len", "(", "files", ")", "\n", "if", "batch_size", ">", "d0", ":", "\n", "        ", "print", "(", "\"warning: batch size is bigger than the data size. setting batch size to data size\"", ")", "\n", "batch_size", "=", "d0", "\n", "", "n_batches", "=", "d0", "//", "batch_size", "\n", "n_used_imgs", "=", "n_batches", "*", "batch_size", "\n", "pred_arr", "=", "np", ".", "empty", "(", "(", "n_used_imgs", ",", "2048", ")", ")", "\n", "for", "i", "in", "range", "(", "n_batches", ")", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "\"\\rPropagating batch %d/%d\"", "%", "(", "i", "+", "1", ",", "n_batches", ")", ",", "end", "=", "\"\"", ",", "flush", "=", "True", ")", "\n", "", "start", "=", "i", "*", "batch_size", "\n", "end", "=", "start", "+", "batch_size", "\n", "batch", "=", "load_image_batch", "(", "files", "[", "start", ":", "end", "]", ")", "\n", "pred", "=", "sess", ".", "run", "(", "inception_layer", ",", "{", "'FID_Inception_Net/ExpandDims:0'", ":", "batch", "}", ")", "\n", "pred_arr", "[", "start", ":", "end", "]", "=", "pred", ".", "reshape", "(", "batch_size", ",", "-", "1", ")", "\n", "del", "batch", "#clean up memory", "\n", "", "if", "verbose", ":", "\n", "        ", "print", "(", "\" done\"", ")", "\n", "", "return", "pred_arr", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf.calculate_activation_statistics_from_files": [[232, 251], ["fid_tf.get_activations_from_files", "numpy.mean", "numpy.cov"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf.get_activations_from_files"], ["", "def", "calculate_activation_statistics_from_files", "(", "files", ",", "sess", ",", "batch_size", "=", "50", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculation of the statistics used by the FID.\n    Params:\n    -- files      : list of paths to image files. Images need to have same dimensions for all files.\n    -- sess        : current session\n    -- batch_size  : the images numpy array is split into batches with batch size\n                     batch_size. A reasonable batch size depends on the available hardware.\n    -- verbose     : If set to True and parameter out_step is given, the number of calculated\n                     batches is reported.\n    Returns:\n    -- mu    : The mean over samples of the activations of the pool_3 layer of\n               the incption model.\n    -- sigma : The covariance matrix of the activations of the pool_3 layer of\n               the incption model.\n    \"\"\"", "\n", "act", "=", "get_activations_from_files", "(", "files", ",", "sess", ",", "batch_size", ",", "verbose", ")", "\n", "mu", "=", "np", ".", "mean", "(", "act", ",", "axis", "=", "0", ")", "\n", "sigma", "=", "np", ".", "cov", "(", "act", ",", "rowvar", "=", "False", ")", "\n", "return", "mu", ",", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf.check_or_download_inception": [[260, 276], ["pathlib.Path", "str", "model_file.exists", "print", "request.urlretrieve", "tarfile.open", "f.extract", "str"], "function", ["None"], ["", "def", "check_or_download_inception", "(", "inception_path", ")", ":", "\n", "    ", "''' Checks if the path to the inception file is valid, or downloads\n        the file if it is not present. '''", "\n", "INCEPTION_URL", "=", "'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'", "\n", "if", "inception_path", "is", "None", ":", "\n", "        ", "inception_path", "=", "'/tmp'", "\n", "", "inception_path", "=", "pathlib", ".", "Path", "(", "inception_path", ")", "\n", "model_file", "=", "inception_path", "/", "'classify_image_graph_def.pb'", "\n", "if", "not", "model_file", ".", "exists", "(", ")", ":", "\n", "        ", "print", "(", "\"Downloading Inception model\"", ")", "\n", "from", "urllib", "import", "request", "\n", "import", "tarfile", "\n", "fn", ",", "_", "=", "request", ".", "urlretrieve", "(", "INCEPTION_URL", ")", "\n", "with", "tarfile", ".", "open", "(", "fn", ",", "mode", "=", "'r'", ")", "as", "f", ":", "\n", "            ", "f", ".", "extract", "(", "'classify_image_graph_def.pb'", ",", "str", "(", "model_file", ".", "parent", ")", ")", "\n", "", "", "return", "str", "(", "model_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf._handle_path": [[278, 299], ["path.endswith", "numpy.load", "np.load.close", "path.endswith", "fid_tf.calculate_activation_statistics", "numpy.load", "x.swapaxes().swapaxes.swapaxes().swapaxes", "numpy.load", "x.swapaxes().swapaxes.swapaxes"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf.calculate_activation_statistics"], ["", "def", "_handle_path", "(", "path", ",", "sess", ",", "low_profile", "=", "False", ")", ":", "\n", "#if path.endswith('.npz'):", "\n", "    ", "if", "path", ".", "endswith", "(", "'.npz'", ")", "and", "not", "\"sample\"", "in", "path", ":", "\n", "        ", "f", "=", "np", ".", "load", "(", "path", ")", "\n", "try", ":", "\n", "            ", "m", ",", "s", "=", "f", "[", "'mu'", "]", "[", ":", "]", ",", "f", "[", "'sigma'", "]", "[", ":", "]", "\n", "", "except", ":", "\n", "            ", "m", ",", "s", "=", "f", "[", "'pool_mean'", "]", "[", ":", "]", ",", "f", "[", "'pool_var'", "]", "[", ":", "]", "\n", "", "f", ".", "close", "(", ")", "\n", "", "else", ":", "\n", "\n", "#     m, s = calculate_activation_statistics_from_files(files, sess)", "\n", "# else:", "\n", "        ", "if", "path", ".", "endswith", "(", "\"npy\"", ")", ":", "\n", "            ", "x", "=", "np", ".", "load", "(", "path", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "np", ".", "load", "(", "path", ")", "[", "'x'", "]", "\n", "x", "=", "x", ".", "swapaxes", "(", "1", ",", "2", ")", ".", "swapaxes", "(", "2", ",", "3", ")", "\n", "", "m", ",", "s", "=", "calculate_activation_statistics", "(", "x", ",", "sess", ")", "\n", "# del x #clean up memory", "\n", "", "return", "m", ",", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf.calculate_fid_given_paths": [[301, 316], ["fid_tf.check_or_download_inception", "fid_tf.create_inception_graph", "str", "tensorflow.Session", "sess.run", "fid_tf._handle_path", "fid_tf._handle_path", "fid_tf.calculate_frechet_distance", "os.path.exists", "RuntimeError", "tensorflow.global_variables_initializer"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf.check_or_download_inception", "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf.create_inception_graph", "home.repos.pwc.inspect_result.ermongroup_NDA.None.train_aug.run", "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf._handle_path", "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf._handle_path", "home.repos.pwc.inspect_result.ermongroup_NDA.None.fid_tf.calculate_frechet_distance"], ["", "def", "calculate_fid_given_paths", "(", "paths", ",", "inception_path", ",", "low_profile", "=", "False", ")", ":", "\n", "    ", "''' Calculates the FID of two paths. '''", "\n", "inception_path", "=", "check_or_download_inception", "(", "inception_path", ")", "\n", "\n", "for", "p", "in", "paths", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "p", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Invalid path: %s\"", "%", "p", ")", "\n", "\n", "", "", "create_inception_graph", "(", "str", "(", "inception_path", ")", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "m1", ",", "s1", "=", "_handle_path", "(", "paths", "[", "0", "]", ",", "sess", ",", "low_profile", "=", "low_profile", ")", "\n", "m2", ",", "s2", "=", "_handle_path", "(", "paths", "[", "1", "]", ",", "sess", ",", "low_profile", "=", "low_profile", ")", "\n", "fid_value", "=", "calculate_frechet_distance", "(", "m1", ",", "s1", ",", "m2", ",", "s2", ")", "\n", "return", "fid_value", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.replicate.DataParallelWithCallback.replicate": [[64, 68], ["super().replicate", "replicate.execute_replication_callbacks"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.replicate.DataParallelWithCallback.replicate", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.replicate.execute_replication_callbacks"], ["def", "replicate", "(", "self", ",", "module", ",", "device_ids", ")", ":", "\n", "        ", "modules", "=", "super", "(", "DataParallelWithCallback", ",", "self", ")", ".", "replicate", "(", "module", ",", "device_ids", ")", "\n", "execute_replication_callbacks", "(", "modules", ")", "\n", "return", "modules", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.replicate.execute_replication_callbacks": [[27, 48], ["len", "enumerate", "list", "replicate.CallbackContext", "enumerate", "master_copy.modules", "range", "module.modules", "hasattr", "m.__data_parallel_replicate__"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm._SynchronizedBatchNorm.__data_parallel_replicate__"], ["", "def", "execute_replication_callbacks", "(", "modules", ")", ":", "\n", "    ", "\"\"\"\n    Execute an replication callback `__data_parallel_replicate__` on each module created by original replication.\n\n    The callback will be invoked with arguments `__data_parallel_replicate__(ctx, copy_id)`\n\n    Note that, as all modules are isomorphism, we assign each sub-module with a context\n    (shared among multiple copies of this module on different devices).\n    Through this context, different copies can share some information.\n\n    We guarantee that the callback on the master copy (the first copy) will be called ahead of calling the callback\n    of any slave copies.\n    \"\"\"", "\n", "master_copy", "=", "modules", "[", "0", "]", "\n", "nr_modules", "=", "len", "(", "list", "(", "master_copy", ".", "modules", "(", ")", ")", ")", "\n", "ctxs", "=", "[", "CallbackContext", "(", ")", "for", "_", "in", "range", "(", "nr_modules", ")", "]", "\n", "\n", "for", "i", ",", "module", "in", "enumerate", "(", "modules", ")", ":", "\n", "        ", "for", "j", ",", "m", "in", "enumerate", "(", "module", ".", "modules", "(", ")", ")", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'__data_parallel_replicate__'", ")", ":", "\n", "                ", "m", ".", "__data_parallel_replicate__", "(", "ctxs", "[", "j", "]", ",", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.replicate.patch_replication_callback": [[70, 95], ["isinstance", "functools.wraps", "old_replicate", "replicate.execute_replication_callbacks"], "function", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.replicate.execute_replication_callbacks"], ["", "", "def", "patch_replication_callback", "(", "data_parallel", ")", ":", "\n", "    ", "\"\"\"\n    Monkey-patch an existing `DataParallel` object. Add the replication callback.\n    Useful when you have customized `DataParallel` implementation.\n\n    Examples:\n        > sync_bn = SynchronizedBatchNorm1d(10, eps=1e-5, affine=False)\n        > sync_bn = DataParallel(sync_bn, device_ids=[0, 1])\n        > patch_replication_callback(sync_bn)\n        # this is equivalent to\n        > sync_bn = SynchronizedBatchNorm1d(10, eps=1e-5, affine=False)\n        > sync_bn = DataParallelWithCallback(sync_bn, device_ids=[0, 1])\n    \"\"\"", "\n", "\n", "assert", "isinstance", "(", "data_parallel", ",", "DataParallel", ")", "\n", "\n", "old_replicate", "=", "data_parallel", ".", "replicate", "\n", "\n", "@", "functools", ".", "wraps", "(", "old_replicate", ")", "\n", "def", "new_replicate", "(", "module", ",", "device_ids", ")", ":", "\n", "        ", "modules", "=", "old_replicate", "(", "module", ",", "device_ids", ")", "\n", "execute_replication_callbacks", "(", "modules", ")", "\n", "return", "modules", "\n", "\n", "", "data_parallel", ".", "replicate", "=", "new_replicate", "\n", "", ""]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.comm.FutureResult.__init__": [[21, 25], ["threading.Lock", "threading.Condition"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_result", "=", "None", "\n", "self", ".", "_lock", "=", "threading", ".", "Lock", "(", ")", "\n", "self", ".", "_cond", "=", "threading", ".", "Condition", "(", "self", ".", "_lock", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.comm.FutureResult.put": [[26, 31], ["comm.FutureResult._cond.notify"], "methods", ["None"], ["", "def", "put", "(", "self", ",", "result", ")", ":", "\n", "        ", "with", "self", ".", "_lock", ":", "\n", "            ", "assert", "self", ".", "_result", "is", "None", ",", "'Previous result has\\'t been fetched.'", "\n", "self", ".", "_result", "=", "result", "\n", "self", ".", "_cond", ".", "notify", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.comm.FutureResult.get": [[32, 40], ["comm.FutureResult._cond.wait"], "methods", ["None"], ["", "", "def", "get", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "_lock", ":", "\n", "            ", "if", "self", ".", "_result", "is", "None", ":", "\n", "                ", "self", ".", "_cond", ".", "wait", "(", ")", "\n", "\n", "", "res", "=", "self", ".", "_result", "\n", "self", ".", "_result", "=", "None", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.comm.SlavePipe.run_slave": [[49, 54], ["comm.SlavePipe.queue.put", "comm.SlavePipe.result.get", "comm.SlavePipe.queue.put"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.comm.FutureResult.put", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.comm.FutureResult.get", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.comm.FutureResult.put"], ["def", "run_slave", "(", "self", ",", "msg", ")", ":", "\n", "        ", "self", ".", "queue", ".", "put", "(", "(", "self", ".", "identifier", ",", "msg", ")", ")", "\n", "ret", "=", "self", ".", "result", ".", "get", "(", ")", "\n", "self", ".", "queue", ".", "put", "(", "True", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.comm.SyncMaster.__init__": [[67, 77], ["queue.Queue", "collections.OrderedDict"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "master_callback", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            master_callback: a callback to be invoked after having collected messages from slave devices.\n        \"\"\"", "\n", "self", ".", "_master_callback", "=", "master_callback", "\n", "self", ".", "_queue", "=", "queue", ".", "Queue", "(", ")", "\n", "self", ".", "_registry", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "self", ".", "_activated", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.comm.SyncMaster.__getstate__": [[78, 80], ["None"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "return", "{", "'master_callback'", ":", "self", ".", "_master_callback", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.comm.SyncMaster.__setstate__": [[81, 83], ["comm.SyncMaster.__init__"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "self", ".", "__init__", "(", "state", "[", "'master_callback'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.comm.SyncMaster.register_slave": [[84, 101], ["comm.FutureResult", "_MasterRegistry", "comm.SlavePipe", "comm.SyncMaster._queue.empty", "comm.SyncMaster._registry.clear"], "methods", ["None"], ["", "def", "register_slave", "(", "self", ",", "identifier", ")", ":", "\n", "        ", "\"\"\"\n        Register an slave device.\n\n        Args:\n            identifier: an identifier, usually is the device id.\n\n        Returns: a `SlavePipe` object which can be used to communicate with the master device.\n\n        \"\"\"", "\n", "if", "self", ".", "_activated", ":", "\n", "            ", "assert", "self", ".", "_queue", ".", "empty", "(", ")", ",", "'Queue is not clean before next initialization.'", "\n", "self", ".", "_activated", "=", "False", "\n", "self", ".", "_registry", ".", "clear", "(", ")", "\n", "", "future", "=", "FutureResult", "(", ")", "\n", "self", ".", "_registry", "[", "identifier", "]", "=", "_MasterRegistry", "(", "future", ")", "\n", "return", "SlavePipe", "(", "identifier", ",", "self", ".", "_queue", ",", "future", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.comm.SyncMaster.run_master": [[102, 134], ["range", "comm.SyncMaster._master_callback", "range", "intermediates.append", "comm.SyncMaster._registry[].result.put", "comm.SyncMaster._queue.get", "comm.SyncMaster._queue.get"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.comm.FutureResult.put", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.comm.FutureResult.get", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.comm.FutureResult.get"], ["", "def", "run_master", "(", "self", ",", "master_msg", ")", ":", "\n", "        ", "\"\"\"\n        Main entry for the master device in each forward pass.\n        The messages were first collected from each devices (including the master device), and then\n        an callback will be invoked to compute the message to be sent back to each devices\n        (including the master device).\n\n        Args:\n            master_msg: the message that the master want to send to itself. This will be placed as the first\n            message when calling `master_callback`. For detailed usage, see `_SynchronizedBatchNorm` for an example.\n\n        Returns: the message to be sent back to the master device.\n\n        \"\"\"", "\n", "self", ".", "_activated", "=", "True", "\n", "\n", "intermediates", "=", "[", "(", "0", ",", "master_msg", ")", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "nr_slaves", ")", ":", "\n", "            ", "intermediates", ".", "append", "(", "self", ".", "_queue", ".", "get", "(", ")", ")", "\n", "\n", "", "results", "=", "self", ".", "_master_callback", "(", "intermediates", ")", "\n", "assert", "results", "[", "0", "]", "[", "0", "]", "==", "0", ",", "'The first result should belongs to the master.'", "\n", "\n", "for", "i", ",", "res", "in", "results", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "self", ".", "_registry", "[", "i", "]", ".", "result", ".", "put", "(", "res", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "nr_slaves", ")", ":", "\n", "            ", "assert", "self", ".", "_queue", ".", "get", "(", ")", "is", "True", "\n", "\n", "", "return", "results", "[", "0", "]", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.comm.SyncMaster.nr_slaves": [[135, 138], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "nr_slaves", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_registry", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.unittest.TorchTestCase.assertTensorClose": [[16, 29], ["float", "unittest.TorchTestCase.assertTrue", "float", "torch.allclose"], "methods", ["None"], ["    ", "def", "assertTensorClose", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "adiff", "=", "float", "(", "(", "x", "-", "y", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ")", "\n", "if", "(", "y", "==", "0", ")", ".", "all", "(", ")", ":", "\n", "            ", "rdiff", "=", "'NaN'", "\n", "", "else", ":", "\n", "            ", "rdiff", "=", "float", "(", "(", "adiff", "/", "y", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ")", "\n", "\n", "", "message", "=", "(", "\n", "'Tensor close check failed\\n'", "\n", "'adiff={}\\n'", "\n", "'rdiff={}\\n'", "\n", ")", ".", "format", "(", "adiff", ",", "rdiff", ")", "\n", "self", ".", "assertTrue", "(", "torch", ".", "allclose", "(", "x", ",", "y", ")", ",", "message", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm._SynchronizedBatchNorm.__init__": [[39, 47], ["torch.nn.modules.batchnorm._BatchNorm.__init__", "comm.SyncMaster"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ",", "eps", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "affine", "=", "True", ")", ":", "\n", "        ", "super", "(", "_SynchronizedBatchNorm", ",", "self", ")", ".", "__init__", "(", "num_features", ",", "eps", "=", "eps", ",", "momentum", "=", "momentum", ",", "affine", "=", "affine", ")", "\n", "\n", "self", ".", "_sync_master", "=", "SyncMaster", "(", "self", ".", "_data_parallel_master", ")", "\n", "\n", "self", ".", "_is_parallel", "=", "False", "\n", "self", ".", "_parallel_id", "=", "None", "\n", "self", ".", "_slave_pipe", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm._SynchronizedBatchNorm.forward": [[48, 109], ["input.view.view.size", "input.view.view.view", "batchnorm._sum_ft", "batchnorm._sum_ft", "output.view", "torch.batch_norm", "torch.batch_norm", "input.view.view.size", "input.view.view.size", "input.view.view.size", "input.view.view.size", "batchnorm._SynchronizedBatchNorm._sync_master.run_master", "batchnorm._SynchronizedBatchNorm._slave_pipe.run_slave", "_ChildMessage", "_ChildMessage", "bias.squeeze", "batchnorm._unsqueeze_ft", "batchnorm._unsqueeze_ft", "batchnorm._unsqueeze_ft", "batchnorm._unsqueeze_ft", "gain.squeeze", "batchnorm._unsqueeze_ft", "batchnorm._unsqueeze_ft", "batchnorm._unsqueeze_ft"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm._sum_ft", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm._sum_ft", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.comm.SyncMaster.run_master", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.comm.SlavePipe.run_slave", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm._unsqueeze_ft", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm._unsqueeze_ft", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm._unsqueeze_ft", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm._unsqueeze_ft", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm._unsqueeze_ft", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm._unsqueeze_ft", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm._unsqueeze_ft"], ["", "def", "forward", "(", "self", ",", "input", ",", "gain", "=", "None", ",", "bias", "=", "None", ")", ":", "\n", "# If it is not parallel computation or is in evaluation mode, use PyTorch's implementation.", "\n", "        ", "if", "not", "(", "self", ".", "_is_parallel", "and", "self", ".", "training", ")", ":", "\n", "            ", "out", "=", "F", ".", "batch_norm", "(", "\n", "input", ",", "self", ".", "running_mean", ",", "self", ".", "running_var", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "\n", "self", ".", "training", ",", "self", ".", "momentum", ",", "self", ".", "eps", ")", "\n", "if", "gain", "is", "not", "None", ":", "\n", "              ", "out", "=", "out", "+", "gain", "\n", "", "if", "bias", "is", "not", "None", ":", "\n", "              ", "out", "=", "out", "+", "bias", "\n", "", "return", "out", "\n", "\n", "# Resize the input to (B, C, -1).", "\n", "", "input_shape", "=", "input", ".", "size", "(", ")", "\n", "# print(input_shape)", "\n", "input", "=", "input", ".", "view", "(", "input", ".", "size", "(", "0", ")", ",", "input", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "\n", "# Compute the sum and square-sum.", "\n", "sum_size", "=", "input", ".", "size", "(", "0", ")", "*", "input", ".", "size", "(", "2", ")", "\n", "input_sum", "=", "_sum_ft", "(", "input", ")", "\n", "input_ssum", "=", "_sum_ft", "(", "input", "**", "2", ")", "\n", "# Reduce-and-broadcast the statistics.", "\n", "# print('it begins')", "\n", "if", "self", ".", "_parallel_id", "==", "0", ":", "\n", "            ", "mean", ",", "inv_std", "=", "self", ".", "_sync_master", ".", "run_master", "(", "_ChildMessage", "(", "input_sum", ",", "input_ssum", ",", "sum_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "mean", ",", "inv_std", "=", "self", ".", "_slave_pipe", ".", "run_slave", "(", "_ChildMessage", "(", "input_sum", ",", "input_ssum", ",", "sum_size", ")", ")", "\n", "# if self._parallel_id == 0:", "\n", "# # print('here')", "\n", "# sum, ssum, num = self._sync_master.run_master(_ChildMessage(input_sum, input_ssum, sum_size))", "\n", "# else:", "\n", "# # print('there')", "\n", "# sum, ssum, num = self._slave_pipe.run_slave(_ChildMessage(input_sum, input_ssum, sum_size))", "\n", "\n", "# print('how2')", "\n", "# num = sum_size", "\n", "# print('Sum: %f, ssum: %f, sumsize: %f, insum: %f' %(float(sum.sum().cpu()), float(ssum.sum().cpu()), float(sum_size), float(input_sum.sum().cpu()))) ", "\n", "# Fix the graph", "\n", "# sum = (sum.detach() - input_sum.detach()) + input_sum", "\n", "# ssum = (ssum.detach() - input_ssum.detach()) + input_ssum", "\n", "\n", "# mean = sum / num", "\n", "# var = ssum / num - mean ** 2", "\n", "# # var = (ssum - mean * sum) / num", "\n", "# inv_std = torch.rsqrt(var + self.eps)", "\n", "\n", "# Compute the output.", "\n", "", "if", "gain", "is", "not", "None", ":", "\n", "# print('gaining')", "\n", "# scale = _unsqueeze_ft(inv_std) * gain.squeeze(-1)", "\n", "# shift = _unsqueeze_ft(mean) * scale - bias.squeeze(-1)", "\n", "# output = input * scale - shift", "\n", "          ", "output", "=", "(", "input", "-", "_unsqueeze_ft", "(", "mean", ")", ")", "*", "(", "_unsqueeze_ft", "(", "inv_std", ")", "*", "gain", ".", "squeeze", "(", "-", "1", ")", ")", "+", "bias", ".", "squeeze", "(", "-", "1", ")", "\n", "", "elif", "self", ".", "affine", ":", "\n", "# MJY:: Fuse the multiplication for speed.", "\n", "            ", "output", "=", "(", "input", "-", "_unsqueeze_ft", "(", "mean", ")", ")", "*", "_unsqueeze_ft", "(", "inv_std", "*", "self", ".", "weight", ")", "+", "_unsqueeze_ft", "(", "self", ".", "bias", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "(", "input", "-", "_unsqueeze_ft", "(", "mean", ")", ")", "*", "_unsqueeze_ft", "(", "inv_std", ")", "\n", "\n", "# Reshape it.", "\n", "", "return", "output", ".", "view", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm._SynchronizedBatchNorm.__data_parallel_replicate__": [[110, 119], ["ctx.sync_master.register_slave"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.comm.SyncMaster.register_slave"], ["", "def", "__data_parallel_replicate__", "(", "self", ",", "ctx", ",", "copy_id", ")", ":", "\n", "        ", "self", ".", "_is_parallel", "=", "True", "\n", "self", ".", "_parallel_id", "=", "copy_id", "\n", "\n", "# parallel_id == 0 means master device.", "\n", "if", "self", ".", "_parallel_id", "==", "0", ":", "\n", "            ", "ctx", ".", "sync_master", "=", "self", ".", "_sync_master", "\n", "", "else", ":", "\n", "            ", "self", ".", "_slave_pipe", "=", "ctx", ".", "sync_master", ".", "register_slave", "(", "copy_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm._SynchronizedBatchNorm._data_parallel_master": [[120, 146], ["sorted", "sum", "torch.nn.parallel._functions.ReduceAddCoalesced.apply", "torch.nn.parallel._functions.ReduceAddCoalesced.apply", "batchnorm._SynchronizedBatchNorm._compute_mean_std", "torch.nn.parallel._functions.Broadcast.apply", "torch.nn.parallel._functions.Broadcast.apply", "enumerate", "i[].sum.get_device", "outputs.append", "i[].sum.get_device", "_MasterMessage"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm._SynchronizedBatchNorm._compute_mean_std"], ["", "", "def", "_data_parallel_master", "(", "self", ",", "intermediates", ")", ":", "\n", "        ", "\"\"\"Reduce the sum and square-sum, compute the statistics, and broadcast it.\"\"\"", "\n", "\n", "# Always using same \"device order\" makes the ReduceAdd operation faster.", "\n", "# Thanks to:: Tete Xiao (http://tetexiao.com/)", "\n", "intermediates", "=", "sorted", "(", "intermediates", ",", "key", "=", "lambda", "i", ":", "i", "[", "1", "]", ".", "sum", ".", "get_device", "(", ")", ")", "\n", "\n", "to_reduce", "=", "[", "i", "[", "1", "]", "[", ":", "2", "]", "for", "i", "in", "intermediates", "]", "\n", "to_reduce", "=", "[", "j", "for", "i", "in", "to_reduce", "for", "j", "in", "i", "]", "# flatten", "\n", "target_gpus", "=", "[", "i", "[", "1", "]", ".", "sum", ".", "get_device", "(", ")", "for", "i", "in", "intermediates", "]", "\n", "\n", "sum_size", "=", "sum", "(", "[", "i", "[", "1", "]", ".", "sum_size", "for", "i", "in", "intermediates", "]", ")", "\n", "sum_", ",", "ssum", "=", "ReduceAddCoalesced", ".", "apply", "(", "target_gpus", "[", "0", "]", ",", "2", ",", "*", "to_reduce", ")", "\n", "mean", ",", "inv_std", "=", "self", ".", "_compute_mean_std", "(", "sum_", ",", "ssum", ",", "sum_size", ")", "\n", "\n", "broadcasted", "=", "Broadcast", ".", "apply", "(", "target_gpus", ",", "mean", ",", "inv_std", ")", "\n", "# print('a')", "\n", "# print(type(sum_), type(ssum), type(sum_size), sum_.shape, ssum.shape, sum_size)", "\n", "# broadcasted = Broadcast.apply(target_gpus, sum_, ssum, torch.tensor(sum_size).float().to(sum_.device))", "\n", "# print('b')", "\n", "outputs", "=", "[", "]", "\n", "for", "i", ",", "rec", "in", "enumerate", "(", "intermediates", ")", ":", "\n", "            ", "outputs", ".", "append", "(", "(", "rec", "[", "0", "]", ",", "_MasterMessage", "(", "*", "broadcasted", "[", "i", "*", "2", ":", "i", "*", "2", "+", "2", "]", ")", ")", ")", "\n", "# outputs.append((rec[0], _MasterMessage(*broadcasted[i*3:i*3+3])))", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm._SynchronizedBatchNorm._compute_mean_std": [[147, 159], ["torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt"], "methods", ["None"], ["", "def", "_compute_mean_std", "(", "self", ",", "sum_", ",", "ssum", ",", "size", ")", ":", "\n", "        ", "\"\"\"Compute the mean and standard-deviation with sum and square-sum. This method\n        also maintains the moving average on the master device.\"\"\"", "\n", "assert", "size", ">", "1", ",", "'BatchNorm computes unbiased standard-deviation, which requires size > 1.'", "\n", "mean", "=", "sum_", "/", "size", "\n", "sumvar", "=", "ssum", "-", "sum_", "*", "mean", "\n", "unbias_var", "=", "sumvar", "/", "(", "size", "-", "1", ")", "\n", "bias_var", "=", "sumvar", "/", "size", "\n", "\n", "self", ".", "running_mean", "=", "(", "1", "-", "self", ".", "momentum", ")", "*", "self", ".", "running_mean", "+", "self", ".", "momentum", "*", "mean", ".", "data", "\n", "self", ".", "running_var", "=", "(", "1", "-", "self", ".", "momentum", ")", "*", "self", ".", "running_var", "+", "self", ".", "momentum", "*", "unbias_var", ".", "data", "\n", "return", "mean", ",", "torch", ".", "rsqrt", "(", "bias_var", "+", "self", ".", "eps", ")", "\n", "# return mean, bias_var.clamp(self.eps) ** -0.5", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm.SynchronizedBatchNorm1d._check_input_dim": [[218, 223], ["super()._check_input_dim", "ValueError", "input.dim", "input.dim", "input.dim"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm.SynchronizedBatchNorm3d._check_input_dim"], ["def", "_check_input_dim", "(", "self", ",", "input", ")", ":", "\n", "        ", "if", "input", ".", "dim", "(", ")", "!=", "2", "and", "input", ".", "dim", "(", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "'expected 2D or 3D input (got {}D input)'", "\n", ".", "format", "(", "input", ".", "dim", "(", ")", ")", ")", "\n", "", "super", "(", "SynchronizedBatchNorm1d", ",", "self", ")", ".", "_check_input_dim", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm.SynchronizedBatchNorm2d._check_input_dim": [[281, 286], ["super()._check_input_dim", "input.dim", "ValueError", "input.dim"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm.SynchronizedBatchNorm3d._check_input_dim"], ["def", "_check_input_dim", "(", "self", ",", "input", ")", ":", "\n", "        ", "if", "input", ".", "dim", "(", ")", "!=", "4", ":", "\n", "            ", "raise", "ValueError", "(", "'expected 4D input (got {}D input)'", "\n", ".", "format", "(", "input", ".", "dim", "(", ")", ")", ")", "\n", "", "super", "(", "SynchronizedBatchNorm2d", ",", "self", ")", ".", "_check_input_dim", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm.SynchronizedBatchNorm3d._check_input_dim": [[345, 350], ["super()._check_input_dim", "input.dim", "ValueError", "input.dim"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm.SynchronizedBatchNorm3d._check_input_dim"], ["def", "_check_input_dim", "(", "self", ",", "input", ")", ":", "\n", "        ", "if", "input", ".", "dim", "(", ")", "!=", "5", ":", "\n", "            ", "raise", "ValueError", "(", "'expected 5D input (got {}D input)'", "\n", ".", "format", "(", "input", ".", "dim", "(", ")", ")", ")", "\n", "", "super", "(", "SynchronizedBatchNorm3d", ",", "self", ")", ".", "_check_input_dim", "(", "input", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm._sum_ft": [[24, 27], ["tensor.sum().sum", "tensor.sum"], "function", ["None"], ["def", "_sum_ft", "(", "tensor", ")", ":", "\n", "    ", "\"\"\"sum over the first and last dimention\"\"\"", "\n", "return", "tensor", ".", "sum", "(", "dim", "=", "0", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm._unsqueeze_ft": [[29, 32], ["tensor.unsqueeze().unsqueeze", "tensor.unsqueeze"], "function", ["None"], ["", "def", "_unsqueeze_ft", "(", "tensor", ")", ":", "\n", "    ", "\"\"\"add new dementions at the front and the tail\"\"\"", "\n", "return", "tensor", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__": [[27, 38], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "batchnorm_reimpl.BatchNorm2dReimpl.register_buffer", "batchnorm_reimpl.BatchNorm2dReimpl.register_buffer", "batchnorm_reimpl.BatchNorm2dReimpl.reset_parameters", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__", "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.reset_parameters"], ["def", "__init__", "(", "self", ",", "num_features", ",", "eps", "=", "1e-5", ",", "momentum", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "momentum", "=", "momentum", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "num_features", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "num_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'running_mean'", ",", "torch", ".", "zeros", "(", "num_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'running_var'", ",", "torch", ".", "ones", "(", "num_features", ")", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.reset_running_stats": [[39, 42], ["batchnorm_reimpl.BatchNorm2dReimpl.running_mean.zero_", "batchnorm_reimpl.BatchNorm2dReimpl.running_var.fill_"], "methods", ["None"], ["", "def", "reset_running_stats", "(", "self", ")", ":", "\n", "        ", "self", ".", "running_mean", ".", "zero_", "(", ")", "\n", "self", ".", "running_var", ".", "fill_", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.reset_parameters": [[43, 47], ["batchnorm_reimpl.BatchNorm2dReimpl.reset_running_stats", "torch.uniform_", "torch.uniform_", "torch.uniform_", "torch.zeros_", "torch.zeros_", "torch.zeros_"], "methods", ["home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.reset_running_stats"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset_running_stats", "(", ")", "\n", "init", ".", "uniform_", "(", "self", ".", "weight", ")", "\n", "init", ".", "zeros_", "(", "self", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ermongroup_NDA.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.forward": [[48, 74], ["input_.permute().contiguous().view.permute().contiguous().view.size", "input_.permute().contiguous().view.permute().contiguous().view.permute().contiguous().view", "input_.permute().contiguous().view.permute().contiguous().view.sum", "input_.permute().contiguous().view.permute().contiguous().view.pow().sum", "output.view().permute().contiguous", "batchnorm_reimpl.BatchNorm2dReimpl.bias.unsqueeze", "input_.permute().contiguous().view.permute().contiguous().view.permute().contiguous", "input_.permute().contiguous().view.permute().contiguous().view.pow", "mean.detach", "unbias_var.detach", "batchnorm_reimpl.BatchNorm2dReimpl.weight.unsqueeze", "output.view().permute", "inv_std.unsqueeze", "input_.permute().contiguous().view.permute().contiguous().view.permute", "mean.unsqueeze", "output.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_", ")", ":", "\n", "        ", "batchsize", ",", "channels", ",", "height", ",", "width", "=", "input_", ".", "size", "(", ")", "\n", "numel", "=", "batchsize", "*", "height", "*", "width", "\n", "input_", "=", "input_", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", ".", "contiguous", "(", ")", ".", "view", "(", "channels", ",", "numel", ")", "\n", "sum_", "=", "input_", ".", "sum", "(", "1", ")", "\n", "sum_of_square", "=", "input_", ".", "pow", "(", "2", ")", ".", "sum", "(", "1", ")", "\n", "mean", "=", "sum_", "/", "numel", "\n", "sumvar", "=", "sum_of_square", "-", "sum_", "*", "mean", "\n", "\n", "self", ".", "running_mean", "=", "(", "\n", "(", "1", "-", "self", ".", "momentum", ")", "*", "self", ".", "running_mean", "\n", "+", "self", ".", "momentum", "*", "mean", ".", "detach", "(", ")", "\n", ")", "\n", "unbias_var", "=", "sumvar", "/", "(", "numel", "-", "1", ")", "\n", "self", ".", "running_var", "=", "(", "\n", "(", "1", "-", "self", ".", "momentum", ")", "*", "self", ".", "running_var", "\n", "+", "self", ".", "momentum", "*", "unbias_var", ".", "detach", "(", ")", "\n", ")", "\n", "\n", "bias_var", "=", "sumvar", "/", "numel", "\n", "inv_std", "=", "1", "/", "(", "bias_var", "+", "self", ".", "eps", ")", ".", "pow", "(", "0.5", ")", "\n", "output", "=", "(", "\n", "(", "input_", "-", "mean", ".", "unsqueeze", "(", "1", ")", ")", "*", "inv_std", ".", "unsqueeze", "(", "1", ")", "*", "\n", "self", ".", "weight", ".", "unsqueeze", "(", "1", ")", "+", "self", ".", "bias", ".", "unsqueeze", "(", "1", ")", ")", "\n", "\n", "return", "output", ".", "view", "(", "channels", ",", "batchsize", ",", "height", ",", "width", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "\n"]]}