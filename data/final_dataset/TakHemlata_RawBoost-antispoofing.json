{"home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.data_utils_rawboost.Dataset_ASVspoof2019_train.__init__": [[122, 132], ["None"], "methods", ["None"], ["\t", "def", "__init__", "(", "self", ",", "args", ",", "list_IDs", ",", "labels", ",", "base_dir", ",", "algo", ")", ":", "\n", "            ", "'''self.list_IDs\t: list of strings (each string: utt key),\n               self.labels      : dictionary (key: utt key, value: label integer)'''", "\n", "\n", "self", ".", "list_IDs", "=", "list_IDs", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "base_dir", "=", "base_dir", "\n", "self", ".", "algo", "=", "algo", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "cut", "=", "64600", "# take ~4 sec audio (64600 samples)", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.data_utils_rawboost.Dataset_ASVspoof2019_train.__len__": [[133, 135], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "           ", "return", "len", "(", "self", ".", "list_IDs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.data_utils_rawboost.Dataset_ASVspoof2019_train.__getitem__": [[137, 147], ["librosa.load", "data_utils_rawboost.process_Rawboost_feature", "data_utils_rawboost.pad", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.data_utils_rawboost.process_Rawboost_feature", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.data_utils_rawboost.pad"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "            ", "key", "=", "self", ".", "list_IDs", "[", "index", "]", "\n", "X", ",", "fs", "=", "librosa", ".", "load", "(", "self", ".", "base_dir", "+", "'flac/'", "+", "key", "+", "'.flac'", ",", "sr", "=", "16000", ")", "\n", "Y", "=", "process_Rawboost_feature", "(", "X", ",", "fs", ",", "self", ".", "args", ",", "self", ".", "algo", ")", "\n", "X_pad", "=", "pad", "(", "Y", ",", "self", ".", "cut", ")", "\n", "x_inp", "=", "Tensor", "(", "X_pad", ")", "\n", "y", "=", "self", ".", "labels", "[", "key", "]", "\n", "\n", "return", "x_inp", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.data_utils_rawboost.Dataset_ASVspoof2021_eval.__init__": [[151, 158], ["None"], "methods", ["None"], ["\t", "def", "__init__", "(", "self", ",", "list_IDs", ",", "base_dir", ")", ":", "\n", "            ", "'''self.list_IDs\t: list of strings (each string: utt key),\n               '''", "\n", "\n", "self", ".", "list_IDs", "=", "list_IDs", "\n", "self", ".", "base_dir", "=", "base_dir", "\n", "self", ".", "cut", "=", "64600", "# take ~4 sec audio (64600 samples)", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.data_utils_rawboost.Dataset_ASVspoof2021_eval.__len__": [[159, 161], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "            ", "return", "len", "(", "self", ".", "list_IDs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.data_utils_rawboost.Dataset_ASVspoof2021_eval.__getitem__": [[163, 170], ["librosa.load", "data_utils_rawboost.pad", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.data_utils_rawboost.pad"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "            ", "key", "=", "self", ".", "list_IDs", "[", "index", "]", "\n", "X", ",", "fs", "=", "librosa", ".", "load", "(", "self", ".", "base_dir", "+", "'flac/'", "+", "key", "+", "'.flac'", ",", "sr", "=", "16000", ")", "\n", "X_pad", "=", "pad", "(", "X", ",", "self", ".", "cut", ")", "\n", "x_inp", "=", "Tensor", "(", "X_pad", ")", "\n", "return", "x_inp", ",", "key", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.data_utils_rawboost.process_Rawboost_feature": [[18, 81], ["RawBoost.LnL_convolutive_noise", "RawBoost.ISD_additive_noise", "RawBoost.SSI_additive_noise", "RawBoost.LnL_convolutive_noise", "RawBoost.ISD_additive_noise", "RawBoost.SSI_additive_noise", "RawBoost.LnL_convolutive_noise", "RawBoost.ISD_additive_noise", "RawBoost.LnL_convolutive_noise", "RawBoost.SSI_additive_noise", "RawBoost.ISD_additive_noise", "RawBoost.SSI_additive_noise", "RawBoost.LnL_convolutive_noise", "RawBoost.ISD_additive_noise", "RawBoost.normWav"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.LnL_convolutive_noise", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.ISD_additive_noise", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.SSI_additive_noise", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.LnL_convolutive_noise", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.ISD_additive_noise", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.SSI_additive_noise", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.LnL_convolutive_noise", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.ISD_additive_noise", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.LnL_convolutive_noise", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.SSI_additive_noise", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.ISD_additive_noise", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.SSI_additive_noise", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.LnL_convolutive_noise", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.ISD_additive_noise", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.normWav"], ["def", "process_Rawboost_feature", "(", "feature", ",", "sr", ",", "args", ",", "algo", ")", ":", "\n", "\n", "# Data process by Convolutive noise (1st algo)", "\n", "    ", "if", "algo", "==", "1", ":", "\n", "\n", "        ", "feature", "=", "LnL_convolutive_noise", "(", "feature", ",", "args", ".", "N_f", ",", "args", ".", "nBands", ",", "args", ".", "minF", ",", "args", ".", "maxF", ",", "args", ".", "minBW", ",", "args", ".", "maxBW", ",", "args", ".", "minCoeff", ",", "args", ".", "maxCoeff", ",", "args", ".", "minG", ",", "args", ".", "maxG", ",", "args", ".", "minBiasLinNonLin", ",", "args", ".", "maxBiasLinNonLin", ",", "sr", ")", "\n", "\n", "# Data process by Impulsive noise (2nd algo)", "\n", "", "elif", "algo", "==", "2", ":", "\n", "\n", "        ", "feature", "=", "ISD_additive_noise", "(", "feature", ",", "args", ".", "P", ",", "args", ".", "g_sd", ")", "\n", "\n", "# Data process by coloured additive noise (3rd algo)", "\n", "", "elif", "algo", "==", "3", ":", "\n", "\n", "        ", "feature", "=", "SSI_additive_noise", "(", "feature", ",", "args", ".", "SNRmin", ",", "args", ".", "SNRmax", ",", "args", ".", "nBands", ",", "args", ".", "minF", ",", "args", ".", "maxF", ",", "args", ".", "minBW", ",", "args", ".", "maxBW", ",", "args", ".", "minCoeff", ",", "args", ".", "maxCoeff", ",", "args", ".", "minG", ",", "args", ".", "maxG", ",", "sr", ")", "\n", "\n", "# Data process by all 3 algo. together in series (1+2+3)", "\n", "", "elif", "algo", "==", "4", ":", "\n", "\n", "        ", "feature", "=", "LnL_convolutive_noise", "(", "feature", ",", "args", ".", "N_f", ",", "args", ".", "nBands", ",", "args", ".", "minF", ",", "args", ".", "maxF", ",", "args", ".", "minBW", ",", "args", ".", "maxBW", ",", "\n", "args", ".", "minCoeff", ",", "args", ".", "maxCoeff", ",", "args", ".", "minG", ",", "args", ".", "maxG", ",", "args", ".", "minBiasLinNonLin", ",", "args", ".", "maxBiasLinNonLin", ",", "sr", ")", "\n", "feature", "=", "ISD_additive_noise", "(", "feature", ",", "args", ".", "P", ",", "args", ".", "g_sd", ")", "\n", "feature", "=", "SSI_additive_noise", "(", "feature", ",", "args", ".", "SNRmin", ",", "args", ".", "SNRmax", ",", "args", ".", "nBands", ",", "args", ".", "minF", ",", "\n", "args", ".", "maxF", ",", "args", ".", "minBW", ",", "args", ".", "maxBW", ",", "args", ".", "minCoeff", ",", "args", ".", "maxCoeff", ",", "args", ".", "minG", ",", "args", ".", "maxG", ",", "sr", ")", "\n", "\n", "# Data process by 1st two algo. together in series (1+2)", "\n", "", "elif", "algo", "==", "5", ":", "\n", "\n", "        ", "feature", "=", "LnL_convolutive_noise", "(", "feature", ",", "args", ".", "N_f", ",", "args", ".", "nBands", ",", "args", ".", "minF", ",", "args", ".", "maxF", ",", "args", ".", "minBW", ",", "args", ".", "maxBW", ",", "\n", "args", ".", "minCoeff", ",", "args", ".", "maxCoeff", ",", "args", ".", "minG", ",", "args", ".", "maxG", ",", "args", ".", "minBiasLinNonLin", ",", "args", ".", "maxBiasLinNonLin", ",", "sr", ")", "\n", "feature", "=", "ISD_additive_noise", "(", "feature", ",", "args", ".", "P", ",", "args", ".", "g_sd", ")", "\n", "\n", "\n", "# Data process by 1st and 3rd algo. together in series (1+3)", "\n", "", "elif", "algo", "==", "6", ":", "\n", "\n", "        ", "feature", "=", "LnL_convolutive_noise", "(", "feature", ",", "args", ".", "N_f", ",", "args", ".", "nBands", ",", "args", ".", "minF", ",", "args", ".", "maxF", ",", "args", ".", "minBW", ",", "args", ".", "maxBW", ",", "\n", "args", ".", "minCoeff", ",", "args", ".", "maxCoeff", ",", "args", ".", "minG", ",", "args", ".", "maxG", ",", "args", ".", "minBiasLinNonLin", ",", "args", ".", "maxBiasLinNonLin", ",", "sr", ")", "\n", "feature", "=", "SSI_additive_noise", "(", "feature", ",", "args", ".", "SNRmin", ",", "args", ".", "SNRmax", ",", "args", ".", "nBands", ",", "args", ".", "minF", ",", "args", ".", "maxF", ",", "args", ".", "minBW", ",", "args", ".", "maxBW", ",", "args", ".", "minCoeff", ",", "args", ".", "maxCoeff", ",", "args", ".", "minG", ",", "args", ".", "maxG", ",", "sr", ")", "\n", "\n", "# Data process by 2nd and 3rd algo. together in series (2+3)", "\n", "", "elif", "algo", "==", "7", ":", "\n", "\n", "        ", "feature", "=", "ISD_additive_noise", "(", "feature", ",", "args", ".", "P", ",", "args", ".", "g_sd", ")", "\n", "feature", "=", "SSI_additive_noise", "(", "feature", ",", "args", ".", "SNRmin", ",", "args", ".", "SNRmax", ",", "args", ".", "nBands", ",", "args", ".", "minF", ",", "args", ".", "maxF", ",", "args", ".", "minBW", ",", "args", ".", "maxBW", ",", "args", ".", "minCoeff", ",", "args", ".", "maxCoeff", ",", "args", ".", "minG", ",", "args", ".", "maxG", ",", "sr", ")", "\n", "\n", "# Data process by 1st two algo. together in Parallel (1||2)", "\n", "", "elif", "algo", "==", "8", ":", "\n", "\n", "        ", "feature1", "=", "LnL_convolutive_noise", "(", "feature", ",", "args", ".", "N_f", ",", "args", ".", "nBands", ",", "args", ".", "minF", ",", "args", ".", "maxF", ",", "args", ".", "minBW", ",", "args", ".", "maxBW", ",", "\n", "args", ".", "minCoeff", ",", "args", ".", "maxCoeff", ",", "args", ".", "minG", ",", "args", ".", "maxG", ",", "args", ".", "minBiasLinNonLin", ",", "args", ".", "maxBiasLinNonLin", ",", "sr", ")", "\n", "feature2", "=", "ISD_additive_noise", "(", "feature", ",", "args", ".", "P", ",", "args", ".", "g_sd", ")", "\n", "\n", "feature_para", "=", "feature1", "+", "feature2", "\n", "feature", "=", "normWav", "(", "feature_para", ",", "0", ")", "#normalized resultant waveform", "\n", "\n", "# original data without Rawboost processing           ", "\n", "", "else", ":", "\n", "\n", "        ", "feature", "=", "feature", "\n", "\n", "", "return", "feature", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.data_utils_rawboost.genSpoof_list": [[83, 108], ["open", "f.readlines", "line.strip().split", "file_list.append", "line.strip", "file_list.append", "line.strip().split", "file_list.append", "line.strip", "line.strip"], "function", ["None"], ["", "def", "genSpoof_list", "(", "dir_meta", ",", "is_train", "=", "False", ",", "is_eval", "=", "False", ")", ":", "\n", "\n", "    ", "d_meta", "=", "{", "}", "\n", "file_list", "=", "[", "]", "\n", "with", "open", "(", "dir_meta", ",", "'r'", ")", "as", "f", ":", "\n", "         ", "l_meta", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "if", "(", "is_train", ")", ":", "\n", "        ", "for", "line", "in", "l_meta", ":", "\n", "             ", "_", ",", "key", ",", "_", ",", "_", ",", "label", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "file_list", ".", "append", "(", "key", ")", "\n", "d_meta", "[", "key", "]", "=", "1", "if", "label", "==", "'bonafide'", "else", "0", "\n", "", "return", "d_meta", ",", "file_list", "\n", "\n", "", "elif", "(", "is_eval", ")", ":", "\n", "        ", "for", "line", "in", "l_meta", ":", "\n", "            ", "key", "=", "line", ".", "strip", "(", ")", "\n", "file_list", ".", "append", "(", "key", ")", "\n", "", "return", "file_list", "\n", "", "else", ":", "\n", "        ", "for", "line", "in", "l_meta", ":", "\n", "             ", "_", ",", "key", ",", "_", ",", "_", ",", "label", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "file_list", ".", "append", "(", "key", ")", "\n", "d_meta", "[", "key", "]", "=", "1", "if", "label", "==", "'bonafide'", "else", "0", "\n", "", "return", "d_meta", ",", "file_list", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.data_utils_rawboost.pad": [[111, 119], ["int", "numpy.tile"], "function", ["None"], ["", "", "def", "pad", "(", "x", ",", "max_len", "=", "64600", ")", ":", "\n", "    ", "x_len", "=", "x", ".", "shape", "[", "0", "]", "\n", "if", "x_len", ">=", "max_len", ":", "\n", "        ", "return", "x", "[", ":", "max_len", "]", "\n", "# need to pad", "\n", "", "num_repeats", "=", "int", "(", "max_len", "/", "x_len", ")", "+", "1", "\n", "padded_x", "=", "np", ".", "tile", "(", "x", ",", "(", "1", ",", "num_repeats", ")", ")", "[", ":", ",", ":", "max_len", "]", "[", "0", "]", "\n", "return", "padded_x", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.main.evaluate_accuracy": [[20, 34], ["model.eval", "batch_x.to.size", "batch_x.to.to", "batch_y.view().type().to.view().type().to", "model", "model.max", "batch_y.view().type().to.view().type", "batch_y.view().type().to.view"], "function", ["None"], ["def", "evaluate_accuracy", "(", "dev_loader", ",", "model", ",", "device", ")", ":", "\n", "    ", "num_correct", "=", "0.0", "\n", "num_total", "=", "0.0", "\n", "model", ".", "eval", "(", ")", "\n", "for", "batch_x", ",", "batch_y", "in", "dev_loader", ":", "\n", "\n", "        ", "batch_size", "=", "batch_x", ".", "size", "(", "0", ")", "\n", "num_total", "+=", "batch_size", "\n", "batch_x", "=", "batch_x", ".", "to", "(", "device", ")", "\n", "batch_y", "=", "batch_y", ".", "view", "(", "-", "1", ")", ".", "type", "(", "torch", ".", "int64", ")", ".", "to", "(", "device", ")", "\n", "batch_out", "=", "model", "(", "batch_x", ")", "\n", "_", ",", "batch_pred", "=", "batch_out", ".", "max", "(", "dim", "=", "1", ")", "\n", "num_correct", "+=", "(", "batch_pred", "==", "batch_y", ")", ".", "sum", "(", "dim", "=", "0", ")", ".", "item", "(", ")", "\n", "", "return", "100", "*", "(", "num_correct", "/", "num_total", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.main.produce_evaluation_file": [[36, 57], ["torch.utils.data.DataLoader", "model.eval", "print", "batch_x.to.size", "batch_x.to.to", "model", "batch_out[].data.cpu().numpy().ravel", "fname_list.extend", "score_list.extend", "fh.close", "batch_out[].data.cpu().numpy().ravel.tolist", "open", "zip", "batch_out[].data.cpu().numpy", "fh.write", "batch_out[].data.cpu"], "function", ["None"], ["", "def", "produce_evaluation_file", "(", "dataset", ",", "model", ",", "device", ",", "save_path", ")", ":", "\n", "    ", "data_loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "128", ",", "shuffle", "=", "False", ",", "drop_last", "=", "False", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "for", "batch_x", ",", "utt_id", "in", "data_loader", ":", "\n", "        ", "fname_list", "=", "[", "]", "\n", "score_list", "=", "[", "]", "\n", "batch_size", "=", "batch_x", ".", "size", "(", "0", ")", "\n", "batch_x", "=", "batch_x", ".", "to", "(", "device", ")", "\n", "batch_out", "=", "model", "(", "batch_x", ",", "is_test", "=", "True", ")", "\n", "batch_score", "=", "(", "batch_out", "[", ":", ",", "1", "]", "\n", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "ravel", "(", ")", "\n", "# add outputs", "\n", "fname_list", ".", "extend", "(", "utt_id", ")", "\n", "score_list", ".", "extend", "(", "batch_score", ".", "tolist", "(", ")", ")", "\n", "\n", "with", "open", "(", "save_path", ",", "'a+'", ")", "as", "fh", ":", "\n", "            ", "for", "f", ",", "cm", "in", "zip", "(", "fname_list", ",", "score_list", ")", ":", "\n", "                ", "fh", ".", "write", "(", "'{} {}\\n'", ".", "format", "(", "f", ",", "cm", ")", ")", "\n", "", "", "fh", ".", "close", "(", ")", "\n", "", "print", "(", "'Scores saved to {}'", ".", "format", "(", "save_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.main.train_epoch": [[58, 91], ["model.train", "torch.FloatTensor().to", "torch.nn.CrossEntropyLoss", "batch_x.to.size", "batch_x.to.to", "batch_y.view().type().to.view().type().to", "model", "nn.CrossEntropyLoss.", "model.max", "optim.zero_grad", "criterion.backward", "optim.step", "torch.FloatTensor", "criterion.item", "sys.stdout.write", "batch_y.view().type().to.view().type", "batch_y.view().type().to.view"], "function", ["None"], ["", "def", "train_epoch", "(", "train_loader", ",", "model", ",", "lr", ",", "optim", ",", "device", ")", ":", "\n", "    ", "running_loss", "=", "0", "\n", "num_correct", "=", "0.0", "\n", "num_total", "=", "0.0", "\n", "ii", "=", "0", "\n", "model", ".", "train", "(", ")", "\n", "\n", "#set objective (Loss) functions", "\n", "weight", "=", "torch", ".", "FloatTensor", "(", "[", "0.1", ",", "0.9", "]", ")", ".", "to", "(", "device", ")", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "weight", "=", "weight", ")", "\n", "\n", "for", "batch_x", ",", "batch_y", "in", "train_loader", ":", "\n", "\n", "        ", "batch_size", "=", "batch_x", ".", "size", "(", "0", ")", "\n", "num_total", "+=", "batch_size", "\n", "ii", "+=", "1", "\n", "batch_x", "=", "batch_x", ".", "to", "(", "device", ")", "\n", "batch_y", "=", "batch_y", ".", "view", "(", "-", "1", ")", ".", "type", "(", "torch", ".", "int64", ")", ".", "to", "(", "device", ")", "\n", "batch_out", "=", "model", "(", "batch_x", ")", "\n", "batch_loss", "=", "criterion", "(", "batch_out", ",", "batch_y", ")", "\n", "_", ",", "batch_pred", "=", "batch_out", ".", "max", "(", "dim", "=", "1", ")", "\n", "num_correct", "+=", "(", "batch_pred", "==", "batch_y", ")", ".", "sum", "(", "dim", "=", "0", ")", ".", "item", "(", ")", "\n", "running_loss", "+=", "(", "batch_loss", ".", "item", "(", ")", "*", "batch_size", ")", "\n", "if", "ii", "%", "10", "==", "0", ":", "\n", "            ", "sys", ".", "stdout", ".", "write", "(", "'\\r \\t {:.2f}'", ".", "format", "(", "\n", "(", "num_correct", "/", "num_total", ")", "*", "100", ")", ")", "\n", "", "optim", ".", "zero_grad", "(", ")", "\n", "batch_loss", ".", "backward", "(", ")", "\n", "optim", ".", "step", "(", ")", "\n", "\n", "", "running_loss", "/=", "num_total", "\n", "train_accuracy", "=", "(", "num_correct", "/", "num_total", ")", "*", "100", "\n", "return", "running_loss", ",", "train_accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.randRange": [[14, 19], ["numpy.random.uniform", "int"], "function", ["None"], ["def", "randRange", "(", "x1", ",", "x2", ",", "integer", ")", ":", "\n", "    ", "y", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "x1", ",", "high", "=", "x2", ",", "size", "=", "(", "1", ",", ")", ")", "\n", "if", "integer", ":", "\n", "        ", "y", "=", "int", "(", "y", ")", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.normWav": [[20, 26], ["numpy.amax", "numpy.amax", "abs", "abs", "numpy.amax", "abs"], "function", ["None"], ["", "def", "normWav", "(", "x", ",", "always", ")", ":", "\n", "    ", "if", "always", ":", "\n", "        ", "x", "=", "x", "/", "np", ".", "amax", "(", "abs", "(", "x", ")", ")", "\n", "", "elif", "np", ".", "amax", "(", "abs", "(", "x", ")", ")", ">", "1", ":", "\n", "            ", "x", "=", "x", "/", "np", ".", "amax", "(", "abs", "(", "x", ")", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.genNotchCoeffs": [[29, 50], ["range", "RawBoost.randRange", "scipy.signal.freqz", "RawBoost.randRange", "RawBoost.randRange", "RawBoost.randRange", "numpy.convolve", "numpy.amax", "int", "scipy.signal.firwin", "pow", "abs", "float", "float"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.randRange", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.randRange", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.randRange", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.randRange"], ["", "def", "genNotchCoeffs", "(", "nBands", ",", "minF", ",", "maxF", ",", "minBW", ",", "maxBW", ",", "minCoeff", ",", "maxCoeff", ",", "minG", ",", "maxG", ",", "fs", ")", ":", "\n", "    ", "b", "=", "1", "\n", "for", "i", "in", "range", "(", "0", ",", "nBands", ")", ":", "\n", "        ", "fc", "=", "randRange", "(", "minF", ",", "maxF", ",", "0", ")", ";", "\n", "bw", "=", "randRange", "(", "minBW", ",", "maxBW", ",", "0", ")", ";", "\n", "c", "=", "randRange", "(", "minCoeff", ",", "maxCoeff", ",", "1", ")", ";", "\n", "\n", "if", "c", "/", "2", "==", "int", "(", "c", "/", "2", ")", ":", "\n", "            ", "c", "=", "c", "+", "1", "\n", "", "f1", "=", "fc", "-", "bw", "/", "2", "\n", "f2", "=", "fc", "+", "bw", "/", "2", "\n", "if", "f1", "<=", "0", ":", "\n", "            ", "f1", "=", "1", "/", "1000", "\n", "", "if", "f2", ">=", "fs", "/", "2", ":", "\n", "            ", "f2", "=", "fs", "/", "2", "-", "1", "/", "1000", "\n", "", "b", "=", "np", ".", "convolve", "(", "signal", ".", "firwin", "(", "c", ",", "[", "float", "(", "f1", ")", ",", "float", "(", "f2", ")", "]", ",", "window", "=", "'hamming'", ",", "fs", "=", "fs", ")", ",", "b", ")", "\n", "\n", "", "G", "=", "randRange", "(", "minG", ",", "maxG", ",", "0", ")", ";", "\n", "_", ",", "h", "=", "signal", ".", "freqz", "(", "b", ",", "1", ",", "fs", "=", "fs", ")", "\n", "b", "=", "pow", "(", "10", ",", "G", "/", "20", ")", "*", "b", "/", "np", ".", "amax", "(", "abs", "(", "h", ")", ")", "\n", "return", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.filterFIR": [[52, 58], ["numpy.pad", "scipy.signal.lfilter", "int", "int"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.data_utils_rawboost.pad"], ["", "def", "filterFIR", "(", "x", ",", "b", ")", ":", "\n", "    ", "N", "=", "b", ".", "shape", "[", "0", "]", "+", "1", "\n", "xpad", "=", "np", ".", "pad", "(", "x", ",", "(", "0", ",", "N", ")", ",", "'constant'", ")", "\n", "y", "=", "signal", ".", "lfilter", "(", "b", ",", "1", ",", "xpad", ")", "\n", "y", "=", "y", "[", "int", "(", "N", "/", "2", ")", ":", "int", "(", "y", ".", "shape", "[", "0", "]", "-", "N", "/", "2", ")", "]", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.LnL_convolutive_noise": [[60, 71], ["range", "RawBoost.normWav", "RawBoost.genNotchCoeffs", "numpy.mean", "RawBoost.filterFIR", "numpy.power"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.normWav", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.genNotchCoeffs", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.filterFIR"], ["", "def", "LnL_convolutive_noise", "(", "x", ",", "N_f", ",", "nBands", ",", "minF", ",", "maxF", ",", "minBW", ",", "maxBW", ",", "minCoeff", ",", "maxCoeff", ",", "minG", ",", "maxG", ",", "minBiasLinNonLin", ",", "maxBiasLinNonLin", ",", "fs", ")", ":", "\n", "    ", "y", "=", "[", "0", "]", "*", "x", ".", "shape", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "N_f", ")", ":", "\n", "        ", "if", "i", "==", "1", ":", "\n", "            ", "minG", "=", "minG", "-", "minBiasLinNonLin", ";", "\n", "maxG", "=", "maxG", "-", "maxBiasLinNonLin", ";", "\n", "", "b", "=", "genNotchCoeffs", "(", "nBands", ",", "minF", ",", "maxF", ",", "minBW", ",", "maxBW", ",", "minCoeff", ",", "maxCoeff", ",", "minG", ",", "maxG", ",", "fs", ")", "\n", "y", "=", "y", "+", "filterFIR", "(", "np", ".", "power", "(", "x", ",", "(", "i", "+", "1", ")", ")", ",", "b", ")", "\n", "", "y", "=", "y", "-", "np", ".", "mean", "(", "y", ")", "\n", "y", "=", "normWav", "(", "y", ",", "0", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.ISD_additive_noise": [[74, 86], ["RawBoost.randRange", "copy.deepcopy", "int", "numpy.multiply", "RawBoost.normWav", "numpy.random.permutation", "numpy.random.rand", "numpy.random.rand"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.randRange", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.normWav"], ["", "def", "ISD_additive_noise", "(", "x", ",", "P", ",", "g_sd", ")", ":", "\n", "    ", "beta", "=", "randRange", "(", "0", ",", "P", ",", "0", ")", "\n", "\n", "y", "=", "copy", ".", "deepcopy", "(", "x", ")", "\n", "x_len", "=", "x", ".", "shape", "[", "0", "]", "\n", "n", "=", "int", "(", "x_len", "*", "(", "beta", "/", "100", ")", ")", "\n", "p", "=", "np", ".", "random", ".", "permutation", "(", "x_len", ")", "[", ":", "n", "]", "\n", "f_r", "=", "np", ".", "multiply", "(", "(", "(", "2", "*", "np", ".", "random", ".", "rand", "(", "p", ".", "shape", "[", "0", "]", ")", ")", "-", "1", ")", ",", "(", "(", "2", "*", "np", ".", "random", ".", "rand", "(", "p", ".", "shape", "[", "0", "]", ")", ")", "-", "1", ")", ")", "\n", "r", "=", "g_sd", "*", "x", "[", "p", "]", "*", "f_r", "\n", "y", "[", "p", "]", "=", "x", "[", "p", "]", "+", "r", "\n", "y", "=", "normWav", "(", "y", ",", "0", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.SSI_additive_noise": [[90, 99], ["numpy.random.normal", "RawBoost.genNotchCoeffs", "RawBoost.filterFIR", "RawBoost.normWav", "RawBoost.randRange", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.genNotchCoeffs", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.filterFIR", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.normWav", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.RawBoost.randRange"], ["", "def", "SSI_additive_noise", "(", "x", ",", "SNRmin", ",", "SNRmax", ",", "nBands", ",", "minF", ",", "maxF", ",", "minBW", ",", "maxBW", ",", "minCoeff", ",", "maxCoeff", ",", "minG", ",", "maxG", ",", "fs", ")", ":", "\n", "    ", "noise", "=", "np", ".", "random", ".", "normal", "(", "0", ",", "1", ",", "x", ".", "shape", "[", "0", "]", ")", "\n", "b", "=", "genNotchCoeffs", "(", "nBands", ",", "minF", ",", "maxF", ",", "minBW", ",", "maxBW", ",", "minCoeff", ",", "maxCoeff", ",", "minG", ",", "maxG", ",", "fs", ")", "\n", "noise", "=", "filterFIR", "(", "noise", ",", "b", ")", "\n", "noise", "=", "normWav", "(", "noise", ",", "1", ")", "\n", "SNR", "=", "randRange", "(", "SNRmin", ",", "SNRmax", ",", "0", ")", "\n", "noise", "=", "noise", "/", "np", ".", "linalg", ".", "norm", "(", "noise", ",", "2", ")", "*", "np", ".", "linalg", ".", "norm", "(", "x", ",", "2", ")", "/", "10.0", "**", "(", "0.05", "*", "SNR", ")", "\n", "x", "=", "x", "+", "noise", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.model.SincConv.to_mel": [[16, 19], ["numpy.log10"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "to_mel", "(", "hz", ")", ":", "\n", "        ", "return", "2595", "*", "np", ".", "log10", "(", "1", "+", "hz", "/", "700", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.model.SincConv.to_hz": [[20, 23], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "to_hz", "(", "mel", ")", ":", "\n", "        ", "return", "700", "*", "(", "10", "**", "(", "mel", "/", "2595", ")", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.model.SincConv.__init__": [[25, 65], ["torch.Module.__init__", "model.SincConv.to_mel", "numpy.max", "numpy.min", "numpy.linspace", "model.SincConv.to_hz", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "ValueError", "ValueError", "ValueError", "int", "numpy.linspace", "int"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.__init__", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.model.SincConv.to_mel", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.model.SincConv.to_hz"], ["", "def", "__init__", "(", "self", ",", "device", ",", "out_channels", ",", "kernel_size", ",", "in_channels", "=", "1", ",", "sample_rate", "=", "16000", ",", "\n", "stride", "=", "1", ",", "padding", "=", "0", ",", "dilation", "=", "1", ",", "bias", "=", "False", ",", "groups", "=", "1", ")", ":", "\n", "\n", "        ", "super", "(", "SincConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "in_channels", "!=", "1", ":", "\n", "\n", "            ", "msg", "=", "\"SincConv only support one input channel (here, in_channels = {%i})\"", "%", "(", "in_channels", ")", "\n", "raise", "ValueError", "(", "msg", ")", "\n", "\n", "", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "\n", "# Forcing the filters to be odd (i.e, perfectly symmetrics)", "\n", "if", "kernel_size", "%", "2", "==", "0", ":", "\n", "            ", "self", ".", "kernel_size", "=", "self", ".", "kernel_size", "+", "1", "\n", "\n", "", "self", ".", "device", "=", "device", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "dilation", "=", "dilation", "\n", "\n", "if", "bias", ":", "\n", "            ", "raise", "ValueError", "(", "'SincConv does not support bias.'", ")", "\n", "", "if", "groups", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "'SincConv does not support groups.'", ")", "\n", "\n", "\n", "# initialize filterbanks using Mel scale", "\n", "", "NFFT", "=", "512", "\n", "f", "=", "int", "(", "self", ".", "sample_rate", "/", "2", ")", "*", "np", ".", "linspace", "(", "0", ",", "1", ",", "int", "(", "NFFT", "/", "2", ")", "+", "1", ")", "\n", "fmel", "=", "self", ".", "to_mel", "(", "f", ")", "# Hz to mel conversion", "\n", "fmelmax", "=", "np", ".", "max", "(", "fmel", ")", "\n", "fmelmin", "=", "np", ".", "min", "(", "fmel", ")", "\n", "filbandwidthsmel", "=", "np", ".", "linspace", "(", "fmelmin", ",", "fmelmax", ",", "self", ".", "out_channels", "+", "1", ")", "\n", "filbandwidthsf", "=", "self", ".", "to_hz", "(", "filbandwidthsmel", ")", "# Mel to Hz conversion", "\n", "self", ".", "mel", "=", "filbandwidthsf", "\n", "self", ".", "hsupp", "=", "torch", ".", "arange", "(", "-", "(", "self", ".", "kernel_size", "-", "1", ")", "/", "2", ",", "(", "self", ".", "kernel_size", "-", "1", ")", "/", "2", "+", "1", ")", "\n", "self", ".", "band_pass", "=", "torch", ".", "zeros", "(", "self", ".", "out_channels", ",", "self", ".", "kernel_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.model.SincConv.forward": [[68, 85], ["range", "model.SincConv.band_pass.to", "model.SincConv.view", "torch.conv1d", "torch.conv1d", "torch.conv1d", "len", "numpy.sinc", "numpy.sinc", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.hamming"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "mel", ")", "-", "1", ")", ":", "\n", "            ", "fmin", "=", "self", ".", "mel", "[", "i", "]", "\n", "fmax", "=", "self", ".", "mel", "[", "i", "+", "1", "]", "\n", "hHigh", "=", "(", "2", "*", "fmax", "/", "self", ".", "sample_rate", ")", "*", "np", ".", "sinc", "(", "2", "*", "fmax", "*", "self", ".", "hsupp", "/", "self", ".", "sample_rate", ")", "\n", "hLow", "=", "(", "2", "*", "fmin", "/", "self", ".", "sample_rate", ")", "*", "np", ".", "sinc", "(", "2", "*", "fmin", "*", "self", ".", "hsupp", "/", "self", ".", "sample_rate", ")", "\n", "hideal", "=", "hHigh", "-", "hLow", "\n", "\n", "self", ".", "band_pass", "[", "i", ",", ":", "]", "=", "Tensor", "(", "np", ".", "hamming", "(", "self", ".", "kernel_size", ")", ")", "*", "Tensor", "(", "hideal", ")", "\n", "\n", "", "band_pass_filter", "=", "self", ".", "band_pass", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "filters", "=", "(", "band_pass_filter", ")", ".", "view", "(", "self", ".", "out_channels", ",", "1", ",", "self", ".", "kernel_size", ")", "\n", "\n", "return", "F", ".", "conv1d", "(", "x", ",", "self", ".", "filters", ",", "stride", "=", "self", ".", "stride", ",", "\n", "padding", "=", "self", ".", "padding", ",", "dilation", "=", "self", ".", "dilation", ",", "\n", "bias", "=", "None", ",", "groups", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.model.Residual_block.__init__": [[89, 122], ["torch.Module.__init__", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.MaxPool1d", "torch.MaxPool1d", "torch.MaxPool1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nb_filts", ",", "first", "=", "False", ")", ":", "\n", "        ", "super", "(", "Residual_block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "first", "=", "first", "\n", "\n", "if", "not", "self", ".", "first", ":", "\n", "            ", "self", ".", "bn1", "=", "nn", ".", "BatchNorm1d", "(", "num_features", "=", "nb_filts", "[", "0", "]", ")", "\n", "\n", "", "self", ".", "lrelu", "=", "nn", ".", "LeakyReLU", "(", "negative_slope", "=", "0.3", ")", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "nb_filts", "[", "0", "]", ",", "\n", "out_channels", "=", "nb_filts", "[", "1", "]", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", "stride", "=", "1", ")", "\n", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm1d", "(", "num_features", "=", "nb_filts", "[", "1", "]", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "nb_filts", "[", "1", "]", ",", "\n", "out_channels", "=", "nb_filts", "[", "1", "]", ",", "\n", "padding", "=", "1", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ")", "\n", "\n", "if", "nb_filts", "[", "0", "]", "!=", "nb_filts", "[", "1", "]", ":", "\n", "            ", "self", ".", "downsample", "=", "True", "\n", "self", ".", "conv_downsample", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "nb_filts", "[", "0", "]", ",", "\n", "out_channels", "=", "nb_filts", "[", "1", "]", ",", "\n", "padding", "=", "0", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "downsample", "=", "False", "\n", "", "self", ".", "mp", "=", "nn", ".", "MaxPool1d", "(", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.model.Residual_block.forward": [[123, 142], ["model.Residual_block.conv1", "model.Residual_block.bn2", "model.Residual_block.lrelu", "model.Residual_block.conv2", "model.Residual_block.mp", "model.Residual_block.bn1", "model.Residual_block.lrelu", "model.Residual_block.conv_downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "if", "not", "self", ".", "first", ":", "\n", "            ", "out", "=", "self", ".", "bn1", "(", "x", ")", "\n", "out", "=", "self", ".", "lrelu", "(", "out", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "x", "\n", "\n", "", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "lrelu", "(", "out", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", ":", "\n", "            ", "identity", "=", "self", ".", "conv_downsample", "(", "identity", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "self", ".", "mp", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.model.RawNet.__init__": [[148, 199], ["torch.Module.__init__", "model.SincConv", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.SELU", "torch.SELU", "torch.SELU", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.AdaptiveAvgPool1d", "torch.AdaptiveAvgPool1d", "torch.AdaptiveAvgPool1d", "model.RawNet._make_attention_fc", "model.RawNet._make_attention_fc", "model.RawNet._make_attention_fc", "model.RawNet._make_attention_fc", "model.RawNet._make_attention_fc", "model.RawNet._make_attention_fc", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.GRU", "torch.GRU", "torch.GRU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "model.Residual_block", "model.Residual_block", "model.Residual_block", "model.Residual_block", "model.Residual_block", "model.Residual_block"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.__init__", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.model.RawNet._make_attention_fc", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.model.RawNet._make_attention_fc", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.model.RawNet._make_attention_fc", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.model.RawNet._make_attention_fc", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.model.RawNet._make_attention_fc", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.model.RawNet._make_attention_fc"], ["    ", "def", "__init__", "(", "self", ",", "d_args", ",", "device", ")", ":", "\n", "        ", "super", "(", "RawNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "\n", "self", ".", "device", "=", "device", "\n", "\n", "self", ".", "Sinc_conv", "=", "SincConv", "(", "device", "=", "self", ".", "device", ",", "\n", "out_channels", "=", "d_args", "[", "'filts'", "]", "[", "0", "]", ",", "\n", "kernel_size", "=", "d_args", "[", "'first_conv'", "]", ",", "\n", "in_channels", "=", "d_args", "[", "'in_channels'", "]", "\n", ")", "\n", "\n", "self", ".", "first_bn", "=", "nn", ".", "BatchNorm1d", "(", "num_features", "=", "d_args", "[", "'filts'", "]", "[", "0", "]", ")", "\n", "self", ".", "selu", "=", "nn", ".", "SELU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "block0", "=", "nn", ".", "Sequential", "(", "Residual_block", "(", "nb_filts", "=", "d_args", "[", "'filts'", "]", "[", "1", "]", ",", "first", "=", "True", ")", ")", "\n", "self", ".", "block1", "=", "nn", ".", "Sequential", "(", "Residual_block", "(", "nb_filts", "=", "d_args", "[", "'filts'", "]", "[", "1", "]", ")", ")", "\n", "self", ".", "block2", "=", "nn", ".", "Sequential", "(", "Residual_block", "(", "nb_filts", "=", "d_args", "[", "'filts'", "]", "[", "2", "]", ")", ")", "\n", "d_args", "[", "'filts'", "]", "[", "2", "]", "[", "0", "]", "=", "d_args", "[", "'filts'", "]", "[", "2", "]", "[", "1", "]", "\n", "self", ".", "block3", "=", "nn", ".", "Sequential", "(", "Residual_block", "(", "nb_filts", "=", "d_args", "[", "'filts'", "]", "[", "2", "]", ")", ")", "\n", "self", ".", "block4", "=", "nn", ".", "Sequential", "(", "Residual_block", "(", "nb_filts", "=", "d_args", "[", "'filts'", "]", "[", "2", "]", ")", ")", "\n", "self", ".", "block5", "=", "nn", ".", "Sequential", "(", "Residual_block", "(", "nb_filts", "=", "d_args", "[", "'filts'", "]", "[", "2", "]", ")", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool1d", "(", "1", ")", "\n", "\n", "self", ".", "fc_attention0", "=", "self", ".", "_make_attention_fc", "(", "in_features", "=", "d_args", "[", "'filts'", "]", "[", "1", "]", "[", "-", "1", "]", ",", "\n", "l_out_features", "=", "d_args", "[", "'filts'", "]", "[", "1", "]", "[", "-", "1", "]", ")", "\n", "self", ".", "fc_attention1", "=", "self", ".", "_make_attention_fc", "(", "in_features", "=", "d_args", "[", "'filts'", "]", "[", "1", "]", "[", "-", "1", "]", ",", "\n", "l_out_features", "=", "d_args", "[", "'filts'", "]", "[", "1", "]", "[", "-", "1", "]", ")", "\n", "self", ".", "fc_attention2", "=", "self", ".", "_make_attention_fc", "(", "in_features", "=", "d_args", "[", "'filts'", "]", "[", "2", "]", "[", "-", "1", "]", ",", "\n", "l_out_features", "=", "d_args", "[", "'filts'", "]", "[", "2", "]", "[", "-", "1", "]", ")", "\n", "self", ".", "fc_attention3", "=", "self", ".", "_make_attention_fc", "(", "in_features", "=", "d_args", "[", "'filts'", "]", "[", "2", "]", "[", "-", "1", "]", ",", "\n", "l_out_features", "=", "d_args", "[", "'filts'", "]", "[", "2", "]", "[", "-", "1", "]", ")", "\n", "self", ".", "fc_attention4", "=", "self", ".", "_make_attention_fc", "(", "in_features", "=", "d_args", "[", "'filts'", "]", "[", "2", "]", "[", "-", "1", "]", ",", "\n", "l_out_features", "=", "d_args", "[", "'filts'", "]", "[", "2", "]", "[", "-", "1", "]", ")", "\n", "self", ".", "fc_attention5", "=", "self", ".", "_make_attention_fc", "(", "in_features", "=", "d_args", "[", "'filts'", "]", "[", "2", "]", "[", "-", "1", "]", ",", "\n", "l_out_features", "=", "d_args", "[", "'filts'", "]", "[", "2", "]", "[", "-", "1", "]", ")", "\n", "\n", "self", ".", "bn_before_gru", "=", "nn", ".", "BatchNorm1d", "(", "num_features", "=", "d_args", "[", "'filts'", "]", "[", "2", "]", "[", "-", "1", "]", ")", "\n", "self", ".", "gru", "=", "nn", ".", "GRU", "(", "input_size", "=", "d_args", "[", "'filts'", "]", "[", "2", "]", "[", "-", "1", "]", ",", "\n", "hidden_size", "=", "d_args", "[", "'gru_node'", "]", ",", "\n", "num_layers", "=", "d_args", "[", "'nb_gru_layer'", "]", ",", "\n", "batch_first", "=", "True", ")", "\n", "\n", "\n", "self", ".", "fc1_gru", "=", "nn", ".", "Linear", "(", "in_features", "=", "d_args", "[", "'gru_node'", "]", ",", "\n", "out_features", "=", "d_args", "[", "'nb_fc_node'", "]", ")", "\n", "\n", "self", ".", "fc2_gru", "=", "nn", ".", "Linear", "(", "in_features", "=", "d_args", "[", "'nb_fc_node'", "]", ",", "\n", "out_features", "=", "d_args", "[", "'nb_classes'", "]", ",", "bias", "=", "True", ")", "\n", "\n", "\n", "self", ".", "sig", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.model.RawNet.forward": [[201, 267], ["model.RawNet.view", "model.RawNet.Sinc_conv", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "model.RawNet.first_bn", "model.RawNet.selu", "model.RawNet.block0", "model.RawNet.avgpool().view", "model.RawNet.fc_attention0", "model.RawNet.sig().view", "model.RawNet.block1", "model.RawNet.avgpool().view", "model.RawNet.fc_attention1", "model.RawNet.sig().view", "model.RawNet.block2", "model.RawNet.avgpool().view", "model.RawNet.fc_attention2", "model.RawNet.sig().view", "model.RawNet.block3", "model.RawNet.avgpool().view", "model.RawNet.fc_attention3", "model.RawNet.sig().view", "model.RawNet.block4", "model.RawNet.avgpool().view", "model.RawNet.fc_attention4", "model.RawNet.sig().view", "model.RawNet.block5", "model.RawNet.avgpool().view", "model.RawNet.fc_attention5", "model.RawNet.sig().view", "model.RawNet.bn_before_gru", "model.RawNet.selu", "model.RawNet.permute", "model.RawNet.gru.flatten_parameters", "model.RawNet.gru", "model.RawNet.fc1_gru", "model.RawNet.fc2_gru", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "model.RawNet.size", "model.RawNet.size", "model.RawNet.size", "model.RawNet.size", "model.RawNet.size", "model.RawNet.size", "model.RawNet.size", "model.RawNet.size", "model.RawNet.size", "model.RawNet.size", "model.RawNet.size", "model.RawNet.size", "model.RawNet.size", "model.RawNet.size", "model.RawNet.size", "model.RawNet.size", "model.RawNet.size", "model.RawNet.size", "torch.softmax", "torch.softmax", "torch.softmax", "model.RawNet.avgpool", "model.RawNet.sig", "model.RawNet.avgpool", "model.RawNet.sig", "model.RawNet.avgpool", "model.RawNet.sig", "model.RawNet.avgpool", "model.RawNet.sig", "model.RawNet.avgpool", "model.RawNet.sig", "model.RawNet.avgpool", "model.RawNet.sig"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", "=", "None", ",", "is_test", "=", "False", ")", ":", "\n", "\n", "\n", "        ", "nb_samp", "=", "x", ".", "shape", "[", "0", "]", "\n", "len_seq", "=", "x", ".", "shape", "[", "1", "]", "\n", "x", "=", "x", ".", "view", "(", "nb_samp", ",", "1", ",", "len_seq", ")", "\n", "\n", "x", "=", "self", ".", "Sinc_conv", "(", "x", ")", "\n", "x", "=", "F", ".", "max_pool1d", "(", "torch", ".", "abs", "(", "x", ")", ",", "3", ")", "\n", "x", "=", "self", ".", "first_bn", "(", "x", ")", "\n", "x", "=", "self", ".", "selu", "(", "x", ")", "\n", "\n", "x0", "=", "self", ".", "block0", "(", "x", ")", "\n", "y0", "=", "self", ".", "avgpool", "(", "x0", ")", ".", "view", "(", "x0", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# torch.Size([batch, filter])", "\n", "y0", "=", "self", ".", "fc_attention0", "(", "y0", ")", "\n", "y0", "=", "self", ".", "sig", "(", "y0", ")", ".", "view", "(", "y0", ".", "size", "(", "0", ")", ",", "y0", ".", "size", "(", "1", ")", ",", "-", "1", ")", "# torch.Size([batch, filter, 1])", "\n", "x", "=", "x0", "*", "y0", "+", "y0", "# (batch, filter, time) x (batch, filter, 1)", "\n", "\n", "\n", "x1", "=", "self", ".", "block1", "(", "x", ")", "\n", "y1", "=", "self", ".", "avgpool", "(", "x1", ")", ".", "view", "(", "x1", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# torch.Size([batch, filter])", "\n", "y1", "=", "self", ".", "fc_attention1", "(", "y1", ")", "\n", "y1", "=", "self", ".", "sig", "(", "y1", ")", ".", "view", "(", "y1", ".", "size", "(", "0", ")", ",", "y1", ".", "size", "(", "1", ")", ",", "-", "1", ")", "# torch.Size([batch, filter, 1])", "\n", "x", "=", "x1", "*", "y1", "+", "y1", "# (batch, filter, time) x (batch, filter, 1)", "\n", "\n", "x2", "=", "self", ".", "block2", "(", "x", ")", "\n", "y2", "=", "self", ".", "avgpool", "(", "x2", ")", ".", "view", "(", "x2", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# torch.Size([batch, filter])", "\n", "y2", "=", "self", ".", "fc_attention2", "(", "y2", ")", "\n", "y2", "=", "self", ".", "sig", "(", "y2", ")", ".", "view", "(", "y2", ".", "size", "(", "0", ")", ",", "y2", ".", "size", "(", "1", ")", ",", "-", "1", ")", "# torch.Size([batch, filter, 1])", "\n", "x", "=", "x2", "*", "y2", "+", "y2", "# (batch, filter, time) x (batch, filter, 1)", "\n", "\n", "x3", "=", "self", ".", "block3", "(", "x", ")", "\n", "y3", "=", "self", ".", "avgpool", "(", "x3", ")", ".", "view", "(", "x3", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# torch.Size([batch, filter])", "\n", "y3", "=", "self", ".", "fc_attention3", "(", "y3", ")", "\n", "y3", "=", "self", ".", "sig", "(", "y3", ")", ".", "view", "(", "y3", ".", "size", "(", "0", ")", ",", "y3", ".", "size", "(", "1", ")", ",", "-", "1", ")", "# torch.Size([batch, filter, 1])", "\n", "x", "=", "x3", "*", "y3", "+", "y3", "# (batch, filter, time) x (batch, filter, 1)", "\n", "\n", "x4", "=", "self", ".", "block4", "(", "x", ")", "\n", "y4", "=", "self", ".", "avgpool", "(", "x4", ")", ".", "view", "(", "x4", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# torch.Size([batch, filter])", "\n", "y4", "=", "self", ".", "fc_attention4", "(", "y4", ")", "\n", "y4", "=", "self", ".", "sig", "(", "y4", ")", ".", "view", "(", "y4", ".", "size", "(", "0", ")", ",", "y4", ".", "size", "(", "1", ")", ",", "-", "1", ")", "# torch.Size([batch, filter, 1])", "\n", "x", "=", "x4", "*", "y4", "+", "y4", "# (batch, filter, time) x (batch, filter, 1)", "\n", "\n", "x5", "=", "self", ".", "block5", "(", "x", ")", "\n", "y5", "=", "self", ".", "avgpool", "(", "x5", ")", ".", "view", "(", "x5", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# torch.Size([batch, filter])", "\n", "y5", "=", "self", ".", "fc_attention5", "(", "y5", ")", "\n", "y5", "=", "self", ".", "sig", "(", "y5", ")", ".", "view", "(", "y5", ".", "size", "(", "0", ")", ",", "y5", ".", "size", "(", "1", ")", ",", "-", "1", ")", "# torch.Size([batch, filter, 1])", "\n", "x", "=", "x5", "*", "y5", "+", "y5", "# (batch, filter, time) x (batch, filter, 1)", "\n", "\n", "x", "=", "self", ".", "bn_before_gru", "(", "x", ")", "\n", "x", "=", "self", ".", "selu", "(", "x", ")", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "#(batch, filt, time) >> (batch, time, filt)", "\n", "self", ".", "gru", ".", "flatten_parameters", "(", ")", "\n", "x", ",", "_", "=", "self", ".", "gru", "(", "x", ")", "\n", "x", "=", "x", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "x", "=", "self", ".", "fc1_gru", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2_gru", "(", "x", ")", "\n", "\n", "\n", "if", "not", "is_test", ":", "\n", "            ", "output", "=", "x", "\n", "return", "output", "\n", "\n", "", "else", ":", "\n", "            ", "output", "=", "F", ".", "softmax", "(", "x", ",", "dim", "=", "1", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.model.RawNet._make_attention_fc": [[270, 280], ["l_fc.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["None"], ["", "", "def", "_make_attention_fc", "(", "self", ",", "in_features", ",", "l_out_features", ")", ":", "\n", "\n", "        ", "l_fc", "=", "[", "]", "\n", "\n", "l_fc", ".", "append", "(", "nn", ".", "Linear", "(", "in_features", "=", "in_features", ",", "\n", "out_features", "=", "l_out_features", ")", ")", "\n", "\n", "\n", "\n", "return", "nn", ".", "Sequential", "(", "*", "l_fc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.model.RawNet._make_layer": [[282, 292], ["range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.append", "model.Residual_block"], "methods", ["None"], ["", "def", "_make_layer", "(", "self", ",", "nb_blocks", ",", "nb_filts", ",", "first", "=", "False", ")", ":", "\n", "        ", "layers", "=", "[", "]", "\n", "#def __init__(self, nb_filts, first = False):", "\n", "for", "i", "in", "range", "(", "nb_blocks", ")", ":", "\n", "            ", "first", "=", "first", "if", "i", "==", "0", "else", "False", "\n", "layers", ".", "append", "(", "Residual_block", "(", "nb_filts", "=", "nb_filts", ",", "\n", "first", "=", "first", ")", ")", "\n", "if", "i", "==", "0", ":", "nb_filts", "[", "0", "]", "=", "nb_filts", "[", "1", "]", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.None.model.RawNet.summary": [[293, 370], ["device.lower.lower.lower", "isinstance", "collections.OrderedDict", "model.RawNet.RawNet.apply", "model.RawNet.RawNet.", "print_fn", "print_fn", "print_fn", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.rand().type", "torch.rand().type", "torch.rand().type", "torch.rand().type", "torch.rand().type", "torch.rand().type", "torch.rand().type", "torch.rand().type", "torch.rand().type", "h.remove", "numpy.prod", "print_fn", "len", "collections.OrderedDict", "list", "isinstance", "hooks.append", "str", "[].split", "input[].size", "list", "hasattr", "hasattr", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "hasattr", "hasattr", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "isinstance", "isinstance", "module.register_forward_hook", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "output.size", "len", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "list", "list", "str().split", "list", "module.weight.size", "module.bias.size", "o.size", "str"], "methods", ["None"], ["", "def", "summary", "(", "self", ",", "input_size", ",", "batch_size", "=", "-", "1", ",", "device", "=", "\"cuda\"", ",", "print_fn", "=", "None", ")", ":", "\n", "        ", "if", "print_fn", "==", "None", ":", "printfn", "=", "print", "\n", "model", "=", "self", "\n", "\n", "def", "register_hook", "(", "module", ")", ":", "\n", "            ", "def", "hook", "(", "module", ",", "input", ",", "output", ")", ":", "\n", "                ", "class_name", "=", "str", "(", "module", ".", "__class__", ")", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"'\"", ")", "[", "0", "]", "\n", "module_idx", "=", "len", "(", "summary", ")", "\n", "\n", "m_key", "=", "\"%s-%i\"", "%", "(", "class_name", ",", "module_idx", "+", "1", ")", "\n", "summary", "[", "m_key", "]", "=", "OrderedDict", "(", ")", "\n", "summary", "[", "m_key", "]", "[", "\"input_shape\"", "]", "=", "list", "(", "input", "[", "0", "]", ".", "size", "(", ")", ")", "\n", "summary", "[", "m_key", "]", "[", "\"input_shape\"", "]", "[", "0", "]", "=", "batch_size", "\n", "if", "isinstance", "(", "output", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                    ", "summary", "[", "m_key", "]", "[", "\"output_shape\"", "]", "=", "[", "\n", "[", "-", "1", "]", "+", "list", "(", "o", ".", "size", "(", ")", ")", "[", "1", ":", "]", "for", "o", "in", "output", "\n", "]", "\n", "", "else", ":", "\n", "                    ", "summary", "[", "m_key", "]", "[", "\"output_shape\"", "]", "=", "list", "(", "output", ".", "size", "(", ")", ")", "\n", "if", "len", "(", "summary", "[", "m_key", "]", "[", "\"output_shape\"", "]", ")", "!=", "0", ":", "\n", "                        ", "summary", "[", "m_key", "]", "[", "\"output_shape\"", "]", "[", "0", "]", "=", "batch_size", "\n", "\n", "", "", "params", "=", "0", "\n", "if", "hasattr", "(", "module", ",", "\"weight\"", ")", "and", "hasattr", "(", "module", ".", "weight", ",", "\"size\"", ")", ":", "\n", "                    ", "params", "+=", "torch", ".", "prod", "(", "torch", ".", "LongTensor", "(", "list", "(", "module", ".", "weight", ".", "size", "(", ")", ")", ")", ")", "\n", "summary", "[", "m_key", "]", "[", "\"trainable\"", "]", "=", "module", ".", "weight", ".", "requires_grad", "\n", "", "if", "hasattr", "(", "module", ",", "\"bias\"", ")", "and", "hasattr", "(", "module", ".", "bias", ",", "\"size\"", ")", ":", "\n", "                    ", "params", "+=", "torch", ".", "prod", "(", "torch", ".", "LongTensor", "(", "list", "(", "module", ".", "bias", ".", "size", "(", ")", ")", ")", ")", "\n", "", "summary", "[", "m_key", "]", "[", "\"nb_params\"", "]", "=", "params", "\n", "\n", "", "if", "(", "\n", "not", "isinstance", "(", "module", ",", "nn", ".", "Sequential", ")", "\n", "and", "not", "isinstance", "(", "module", ",", "nn", ".", "ModuleList", ")", "\n", "and", "not", "(", "module", "==", "model", ")", "\n", ")", ":", "\n", "                ", "hooks", ".", "append", "(", "module", ".", "register_forward_hook", "(", "hook", ")", ")", "\n", "\n", "", "", "device", "=", "device", ".", "lower", "(", ")", "\n", "assert", "device", "in", "[", "\n", "\"cuda\"", ",", "\n", "\"cpu\"", ",", "\n", "]", ",", "\"Input device is not valid, please specify 'cuda' or 'cpu'\"", "\n", "\n", "if", "device", "==", "\"cuda\"", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "dtype", "=", "torch", ".", "cuda", ".", "FloatTensor", "\n", "", "else", ":", "\n", "            ", "dtype", "=", "torch", ".", "FloatTensor", "\n", "", "if", "isinstance", "(", "input_size", ",", "tuple", ")", ":", "\n", "            ", "input_size", "=", "[", "input_size", "]", "\n", "", "x", "=", "[", "torch", ".", "rand", "(", "2", ",", "*", "in_size", ")", ".", "type", "(", "dtype", ")", "for", "in_size", "in", "input_size", "]", "\n", "summary", "=", "OrderedDict", "(", ")", "\n", "hooks", "=", "[", "]", "\n", "model", ".", "apply", "(", "register_hook", ")", "\n", "model", "(", "*", "x", ")", "\n", "for", "h", "in", "hooks", ":", "\n", "            ", "h", ".", "remove", "(", ")", "\n", "\n", "", "print_fn", "(", "\"----------------------------------------------------------------\"", ")", "\n", "line_new", "=", "\"{:>20}  {:>25} {:>15}\"", ".", "format", "(", "\"Layer (type)\"", ",", "\"Output Shape\"", ",", "\"Param #\"", ")", "\n", "print_fn", "(", "line_new", ")", "\n", "print_fn", "(", "\"================================================================\"", ")", "\n", "total_params", "=", "0", "\n", "total_output", "=", "0", "\n", "trainable_params", "=", "0", "\n", "for", "layer", "in", "summary", ":", "\n", "# input_shape, output_shape, trainable, nb_params", "\n", "            ", "line_new", "=", "\"{:>20}  {:>25} {:>15}\"", ".", "format", "(", "\n", "layer", ",", "\n", "str", "(", "summary", "[", "layer", "]", "[", "\"output_shape\"", "]", ")", ",", "\n", "\"{0:,}\"", ".", "format", "(", "summary", "[", "layer", "]", "[", "\"nb_params\"", "]", ")", ",", "\n", ")", "\n", "total_params", "+=", "summary", "[", "layer", "]", "[", "\"nb_params\"", "]", "\n", "total_output", "+=", "np", ".", "prod", "(", "summary", "[", "layer", "]", "[", "\"output_shape\"", "]", ")", "\n", "if", "\"trainable\"", "in", "summary", "[", "layer", "]", ":", "\n", "                ", "if", "summary", "[", "layer", "]", "[", "\"trainable\"", "]", "==", "True", ":", "\n", "                    ", "trainable_params", "+=", "summary", "[", "layer", "]", "[", "\"nb_params\"", "]", "\n", "", "", "print_fn", "(", "line_new", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.core_scripts.startup_config.set_random_seed": [[22, 59], ["torch.manual_seed", "random.seed", "numpy.random.seed", "str", "torch.cuda.is_available", "torch.cuda.manual_seed_all", "print", "print"], "function", ["None"], ["def", "set_random_seed", "(", "random_seed", ",", "args", "=", "None", ")", ":", "\n", "    ", "\"\"\" set_random_seed(random_seed, args=None)\n    \n    Set the random_seed for numpy, python, and cudnn\n    \n    input\n    -----\n      random_seed: integer random seed\n      args: argue parser\n    \"\"\"", "\n", "\n", "# initialization                                       ", "\n", "torch", ".", "manual_seed", "(", "random_seed", ")", "\n", "random", ".", "seed", "(", "random_seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "random_seed", ")", "\n", "os", ".", "environ", "[", "'PYTHONHASHSEED'", "]", "=", "str", "(", "random_seed", ")", "\n", "\n", "#For torch.backends.cudnn.deterministic", "\n", "#Note: this default configuration may result in RuntimeError", "\n", "#see https://pytorch.org/docs/stable/notes/randomness.html    ", "\n", "if", "args", "is", "None", ":", "\n", "        ", "cudnn_deterministic", "=", "True", "\n", "cudnn_benchmark", "=", "False", "\n", "", "else", ":", "\n", "        ", "cudnn_deterministic", "=", "args", ".", "cudnn_deterministic_toggle", "\n", "cudnn_benchmark", "=", "args", ".", "cudnn_benchmark_toggle", "\n", "\n", "if", "not", "cudnn_deterministic", ":", "\n", "            ", "print", "(", "\"cudnn_deterministic set to False\"", ")", "\n", "", "if", "cudnn_benchmark", ":", "\n", "            ", "print", "(", "\"cudnn_benchmark set to True\"", ")", "\n", "\n", "", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "random_seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "cudnn_deterministic", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "cudnn_benchmark", "\n", "", "return", "\n", "", ""]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.__init__": [[24, 44], ["int", "int"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "length", "=", "0", ",", "\n", "seq_name", "=", "''", ",", "\n", "seg_idx", "=", "0", ",", "\n", "start_pos", "=", "0", ",", "\n", "info_id", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            length: length this utterance segment\n            seq_name: name of the utterance\n            seg_idx: idx of this segment in the original utterance\n            start_pos: from which step does this segment start in the\n                       original utterance\n            info_id: idx of this seq segment in training set\n        \"\"\"", "\n", "self", ".", "length", "=", "int", "(", "length", ")", "\n", "self", ".", "seq_name", "=", "seq_name", "\n", "self", ".", "seg_idx", "=", "seg_idx", "\n", "self", ".", "start_pos", "=", "int", "(", "start_pos", ")", "\n", "self", ".", "info_id", "=", "info_id", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.print_to_dic": [[46, 55], ["None"], "methods", ["None"], ["", "def", "print_to_dic", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Print to dictionary format in order to dump\n        \"\"\"", "\n", "return", "{", "\"length\"", ":", "self", ".", "length", ",", "\n", "\"seq_name\"", ":", "self", ".", "seq_name", ",", "\n", "\"seg_idx\"", ":", "self", ".", "seg_idx", ",", "\n", "\"start_pos\"", ":", "self", ".", "start_pos", ",", "\n", "\"info_id\"", ":", "self", ".", "info_id", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.load_from_dic": [[56, 68], ["nii_warn.f_die", "str"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die"], ["", "def", "load_from_dic", "(", "self", ",", "dic", ")", ":", "\n", "        ", "\"\"\"\n        Load seq informaiton from dictionary\n        \"\"\"", "\n", "try", ":", "\n", "            ", "self", ".", "length", "=", "dic", "[", "\"length\"", "]", "\n", "self", ".", "seq_name", "=", "dic", "[", "\"seq_name\"", "]", "\n", "self", ".", "seg_idx", "=", "dic", "[", "\"seg_idx\"", "]", "\n", "self", ".", "start_pos", "=", "dic", "[", "\"start_pos\"", "]", "\n", "self", ".", "info_id", "=", "dic", "[", "\"info_id\"", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "nii_warn", ".", "f_die", "(", "\"Seq infor %s invalid\"", "%", "str", "(", "dic", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.print_to_str": [[69, 79], ["None"], "methods", ["None"], ["", "", "def", "print_to_str", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Print infor to str\n        \"\"\"", "\n", "temp", "=", "\"{:d},{},{:d},{:d},{:d}\"", ".", "format", "(", "self", ".", "info_id", ",", "self", ".", "seq_name", ",", "self", ".", "seg_idx", ",", "self", ".", "length", ",", "self", ".", "start_pos", ")", "\n", "return", "temp", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.parse_from_str": [[80, 94], ["input_str.split", "int", "int", "int", "int", "nii_warn.f_die"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die"], ["", "def", "parse_from_str", "(", "self", ",", "input_str", ")", ":", "\n", "        ", "\"\"\"\n        Parse a input string (which should be generated from print_to_str)\n        \"\"\"", "\n", "temp", "=", "input_str", ".", "split", "(", "','", ")", "\n", "self", ".", "seq_name", "=", "temp", "[", "1", "]", "\n", "try", ":", "\n", "            ", "self", ".", "info_id", "=", "int", "(", "temp", "[", "0", "]", ")", "\n", "self", ".", "seg_idx", "=", "int", "(", "temp", "[", "2", "]", ")", "\n", "self", ".", "length", "=", "int", "(", "temp", "[", "3", "]", ")", "\n", "self", ".", "start_pos", "=", "int", "(", "temp", "[", "4", "]", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "nii_warn", ".", "f_die", "(", "\"Seq infor cannot parse {}\"", ".", "format", "(", "input_str", ")", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.seq_length": [[95, 97], ["None"], "methods", ["None"], ["", "def", "seq_length", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.seq_tag": [[98, 100], ["None"], "methods", ["None"], ["", "def", "seq_tag", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "seq_name", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.seq_start_pos": [[101, 103], ["None"], "methods", ["None"], ["", "def", "seq_start_pos", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "start_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.parse_length": [[108, 110], ["int", "input_str.split"], "function", ["None"], ["", "", "def", "parse_length", "(", "input_str", ")", ":", "\n", "    ", "return", "int", "(", "input_str", ".", "split", "(", "','", ")", "[", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.parse_filename": [[111, 113], ["input_str.split"], "function", ["None"], ["", "def", "parse_filename", "(", "input_str", ")", ":", "\n", "    ", "return", "input_str", ".", "split", "(", "','", ")", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_dataset.merge_loader.__init__": [[38, 47], ["numpy.cumsum", "x.get_loader", "x.get_seq_num"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_loader", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_seq_num"], ["def", "__init__", "(", "self", ",", "datasets", ")", ":", "\n", "# list of datasets", "\n", "        ", "self", ".", "m_datasets", "=", "datasets", "\n", "# initialized iterators ", "\n", "self", ".", "m_loaders", "=", "[", "x", ".", "get_loader", "(", ")", "for", "x", "in", "self", ".", "m_datasets", "]", "\n", "# utterance index shift", "\n", "self", ".", "m_idx_shift", "=", "np", ".", "cumsum", "(", "[", "0", "]", "+", "\n", "[", "x", ".", "get_seq_num", "(", ")", "for", "x", "in", "self", ".", "m_datasets", "]", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_dataset.merge_loader.adjust_utt_idx": [[48, 58], ["customize_dataset.merge_loader.m_datasets[].get_dataset().f_adjust_idx", "customize_dataset.merge_loader.m_datasets[].get_dataset"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_adjust_idx", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_dataset"], ["", "def", "adjust_utt_idx", "(", "self", ",", "data_tuple", ",", "dataset_idx", ")", ":", "\n", "        ", "\"\"\" when merging dataset 1, 2, 3 ...\n        index for dataset 2: index += dataset_1.get_seq_num()\n        index for dataset 3: index += dataset_1 + dataset_2.get_seq_num()\n        \n        We have to call dataset.f_adjust_idx because it is the dataset itself\n        that knows how to parse the data_tuple\n        \"\"\"", "\n", "return", "self", ".", "m_datasets", "[", "dataset_idx", "]", ".", "get_dataset", "(", ")", ".", "f_adjust_idx", "(", "\n", "data_tuple", ",", "self", ".", "m_idx_shift", "[", "dataset_idx", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_dataset.merge_loader.__iter__": [[59, 65], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        create the list of iterators\n        \"\"\"", "\n", "self", ".", "m_loader_iter", "=", "[", "iter", "(", "x", ")", "for", "x", "in", "self", ".", "m_loaders", "]", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_dataset.merge_loader.__next__": [[66, 79], ["enumerate", "core_scripts.customize_collate_from_batch", "core_scripts.customize_collate_from_batch", "core_scripts.customize_collate_from_batch", "core_scripts.customize_collate_from_batch", "core_scripts.customize_collate_from_batch", "data_list.append", "customize_dataset.merge_loader.adjust_utt_idx", "next"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_collate_fn.customize_collate_from_batch", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_collate_fn.customize_collate_from_batch", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_collate_fn.customize_collate_from_batch", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_collate_fn.customize_collate_from_batch", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_collate_fn.customize_collate_from_batch", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.adjust_utt_idx"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "\"\"\" try to load data from m_datasets, and merge them into a \n        single minibatch\n        \"\"\"", "\n", "try", ":", "\n", "            ", "data_list", "=", "[", "]", "\n", "for", "dataset_idx", ",", "dataloader", "in", "enumerate", "(", "self", ".", "m_loader_iter", ")", ":", "\n", "                ", "data_list", ".", "append", "(", "\n", "self", ".", "adjust_utt_idx", "(", "next", "(", "dataloader", ")", ",", "dataset_idx", ")", ")", "\n", "# data shape should be the same", "\n", "", "return", "nii_collate_fn", ".", "customize_collate_from_batch", "(", "data_list", ")", "\n", "", "except", "StopIteration", ":", "\n", "            ", "raise", "StopIteration", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_dataset.ConcatDataset.__init__": [[87, 100], ["len", "numpy.cumsum", "numpy.cumsum", "x.__len__"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.__len__"], ["def", "__init__", "(", "self", ",", "datasets", ")", ":", "\n", "        ", "\"\"\" datasets must be torch.utils.data.Dataset\n        \"\"\"", "\n", "# all the sub sets", "\n", "self", ".", "datasets", "=", "datasets", "\n", "self", ".", "num_subset", "=", "len", "(", "datasets", ")", "\n", "# len of each sub set", "\n", "self", ".", "len_buffer", "=", "[", "x", ".", "__len__", "(", ")", "for", "x", "in", "self", ".", "datasets", "]", "\n", "# for later use, to decide from which subset we draw the sample", "\n", "self", ".", "len_top", "=", "np", ".", "cumsum", "(", "self", ".", "len_buffer", ")", "\n", "self", ".", "len_bot", "=", "np", ".", "cumsum", "(", "[", "0", "]", "+", "self", ".", "len_buffer", "[", ":", "-", "1", "]", ")", "\n", "# done", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_dataset.ConcatDataset.__getitem__": [[101, 120], ["zip", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "subset.__getitem__"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.__getitem__"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "\"\"\" getitem from the corresponding subcorpus\n        \"\"\"", "\n", "# for example, data1 = [a], data2 = [b, c]", "\n", "# self.len_buffer = [1, 2]", "\n", "# self.len_top = [1, 3] ", "\n", "# self.len_bot = [0, 1]", "\n", "#  __getitem__(0) -> data1[0-0] = a", "\n", "#  __getitem__(1) -> data2[1-1] = b", "\n", "#  __getitem__(2) -> data2[2-1] = c", "\n", "for", "idx_u", ",", "idx_d", ",", "subset", "in", "zip", "(", "self", ".", "len_top", ",", "self", ".", "len_bot", ",", "self", ".", "datasets", ")", ":", "\n", "            ", "if", "i", "<", "idx_u", ":", "\n", "                ", "return", "subset", ".", "__getitem__", "(", "i", "-", "idx_d", ")", "\n", "", "else", ":", "\n", "# keep going to the next subset", "\n", "                ", "pass", "\n", "", "", "nii_warn", ".", "f_die", "(", "\"Merge dataset: fatal error in __getitem__\"", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_dataset.ConcatDataset.__len__": [[121, 123], ["sum"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "sum", "(", "self", ".", "len_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_dataset.ConcatDataset.f_get_seq_len_list": [[124, 129], ["sub_dataset.f_get_seq_len_list"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_get_seq_len_list"], ["", "def", "f_get_seq_len_list", "(", "self", ")", ":", "\n", "        ", "tmp", "=", "[", "]", "\n", "for", "sub_dataset", "in", "self", ".", "datasets", ":", "\n", "            ", "tmp", "+=", "sub_dataset", ".", "f_get_seq_len_list", "(", ")", "\n", "", "return", "tmp", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_dataset.NII_MergeDataSetLoader.__init__": [[136, 307], ["zip", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "type", "lst_dset.append", "customize_dataset.ConcatDataset", "params.copy.copy", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "customize_dataset.merge_loader", "lst_dset[].get_loader_params", "type", "type", "type", "len", "len", "len", "len", "str", "str", "str", "len", "len", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.NIIDataSetLoader", "core_scripts.NIIDataSetLoader", "core_scripts.NIIDataSetLoader", "core_scripts.NIIDataSetLoader", "core_scripts.NIIDataSetLoader", "params.copy", "len", "str", "len", "len", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "numpy.arange", "x.get_dataset", "list", "str", "len", "core_scripts.SamplerBlockShuffleByLen", "core_scripts.SamplerBlockShuffleByLen", "core_scripts.SamplerBlockShuffleByLen", "core_scripts.SamplerBlockShuffleByLen", "core_scripts.SamplerBlockShuffleByLen", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "set", "customize_dataset.ConcatDataset.f_get_seq_len_list"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_loader_params", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_dataset", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_get_seq_len_list"], ["def", "__init__", "(", "self", ",", "\n", "dataset_name", ",", "list_file_list", ",", "list_input_dirs", ",", "input_exts", ",", "input_dims", ",", "input_reso", ",", "input_norm", ",", "list_output_dirs", ",", "output_exts", ",", "output_dims", ",", "output_reso", ",", "output_norm", ",", "stats_path", ",", "data_format", "=", "nii_dconf", ".", "h_dtype_str", ",", "params", "=", "None", ",", "truncate_seq", "=", "None", ",", "min_seq_len", "=", "None", ",", "\n", "save_mean_std", "=", "True", ",", "wav_samp_rate", "=", "None", ",", "flag_lang", "=", "'EN'", ",", "way_to_merge", "=", "'concatenate'", ",", "\n", "global_arg", "=", "None", ")", ":", "\n", "        ", "\"\"\" Signature is similar to default_io.NIIDataSetLoader.\n        file_list, input_dirs, and output_dirs are different.\n        One additional optional argument is way_to_merge.\n\n        Args\n        ----\n            data_set_name: a string to name this dataset\n                           this will be used to name the statistics files\n                           such as the mean/std for this dataset\n            list_file_list: a list of file_name path\n            list_input_dirs: a list of lists of dirs for input features\n            input_exts: a list of input feature name extentions\n            input_dims: a list of input feature dimensions\n            input_reso: a list of input feature temporal resolution,\n                        or None\n            input_norm: a list of bool, whether normalize input feature or not\n\n            list_output_dirs: a list of lists of dirs for output features\n            output_exts: a list of output feature name extentions\n            output_dims: a list of output feature dimensions\n            output_reso: a list of output feature temporal resolution, \n                         or None\n            output_norm: a list of bool, whether normalize target feature or not\n\n            stats_path: path to the directory of statistics(mean/std)\n            data_format: method to load the data\n                    '<f4' (default): load data as float32m little-endian\n                    'htk': load data as htk format\n            params: parameter for torch.utils.data.DataLoader\n\n            truncate_seq: None or int, \n                          truncate data sequence into smaller truncks\n                          truncate_seq > 0 specifies the trunck length\n            min_seq_len: None (default) or int, minimum length of an utterance\n                         utterance shorter than min_seq_len will be ignored\n            save_mean_std: bool, True (default): save mean and std \n            wav_samp_rate: None (default) or int, if input data has  waveform, \n                         please set sampling rate. It is used by _data_writer\n            flag_lang: str, 'EN' (default), if input data has text, text will\n                       be converted into code indices. flag_lang indicates the \n                     language for the text processer. It is used by _data_reader\n            wav_to_merge: string, 'concatenate' (default) or 'merge'\n                     'concatenate': simply concatenate multiple corpora\n                     'merge': create minibatch by merging data from each copora\n            global_arg: argument parser returned by arg_parse.f_args_parsed()\n                      default None\n\n        Methods\n        -------\n            get_loader(): return a torch.util.data.DataLoader\n            get_dataset(): return a torch.util.data.DataSet\n        \"\"\"", "\n", "# check whether input_dirs and output_dirs are lists", "\n", "if", "type", "(", "list_input_dirs", "[", "0", "]", ")", "is", "list", "and", "type", "(", "list_output_dirs", "[", "0", "]", ")", "is", "list", "and", "type", "(", "list_file_list", ")", "is", "list", "and", "len", "(", "list_input_dirs", ")", "==", "len", "(", "list_output_dirs", ")", "and", "len", "(", "list_input_dirs", ")", "==", "len", "(", "list_file_list", ")", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "mes", "=", "\"NII_MergeDataSetLoader: input_dirs, output_dirs, \"", "\n", "mes", "+=", "\"and file_list should be list of lists. \"", "\n", "mes", "+=", "\"They should have equal length. But we have:\"", "\n", "mes", "+=", "\"{:s}\\n{:s}\\n{:s}\"", ".", "format", "(", "\n", "str", "(", "list_input_dirs", ")", ",", "str", "(", "list_output_dirs", ")", ",", "\n", "str", "(", "list_file_list", ")", ")", "\n", "nii_warn", ".", "f_die", "(", "mes", ")", "\n", "\n", "", "if", "type", "(", "dataset_name", ")", "is", "list", ":", "\n", "            ", "if", "len", "(", "dataset_name", ")", "!=", "len", "(", "list_input_dirs", ")", ":", "\n", "                ", "mes", "=", "\"dataset_name should have {:d} elements. \"", ".", "format", "(", "\n", "len", "(", "list_file_list", ")", ")", "\n", "mes", "+=", "\"But we have: {:s}\"", ".", "format", "(", "str", "(", "dataset_name", ")", ")", "\n", "nii_warn", ".", "f_die", "(", "mes", ")", "\n", "", "elif", "len", "(", "list", "(", "set", "(", "dataset_name", ")", ")", ")", "!=", "len", "(", "list_input_dirs", ")", ":", "\n", "                ", "mes", "=", "\"dataset_name has duplicated elements: {:s}\"", ".", "format", "(", "\n", "str", "(", "dataset_name", ")", ")", "\n", "nii_warn", ".", "f_die", "(", "mes", ")", "\n", "", "else", ":", "\n", "                ", "tmp_dnames", "=", "dataset_name", "\n", "", "", "else", ":", "\n", "            ", "tmp_dnames", "=", "[", "dataset_name", "+", "'_sub_{:d}'", ".", "format", "(", "idx", ")", "for", "idx", "in", "np", ".", "arange", "(", "len", "(", "list_input_dirs", ")", ")", "]", "\n", "\n", "\n", "\n", "# create individual datasets", "\n", "", "lst_dset", "=", "[", "]", "\n", "for", "sub_input_dirs", ",", "sub_output_dirs", ",", "sub_file_list", ",", "tmp_name", "in", "zip", "(", "list_input_dirs", ",", "list_output_dirs", ",", "list_file_list", ",", "tmp_dnames", ")", ":", "\n", "\n", "            ", "lst_dset", ".", "append", "(", "\n", "nii_default_dset", ".", "NIIDataSetLoader", "(", "\n", "tmp_name", ",", "\n", "sub_file_list", ",", "\n", "sub_input_dirs", ",", "input_exts", ",", "input_dims", ",", "input_reso", ",", "input_norm", ",", "sub_output_dirs", ",", "output_exts", ",", "output_dims", ",", "output_reso", ",", "output_norm", ",", "stats_path", ",", "data_format", ",", "params", ",", "truncate_seq", ",", "min_seq_len", ",", "\n", "save_mean_std", ",", "wav_samp_rate", ",", "flag_lang", ",", "global_arg", ")", ")", "\n", "\n", "# list of the datasets", "\n", "", "self", ".", "m_datasets", "=", "lst_dset", "\n", "\n", "self", ".", "way_to_merge", "=", "way_to_merge", "\n", "# create data loader", "\n", "if", "way_to_merge", "==", "'concatenate'", ":", "\n", "\n", "# to create DataLoader, we need the pytorch.dataset", "\n", "            ", "py_datasets", "=", "ConcatDataset", "(", "[", "x", ".", "get_dataset", "(", ")", "for", "x", "in", "lst_dset", "]", ")", "\n", "\n", "####", "\n", "# Although members in l_dset have Dataloader, we need to ", "\n", "# create a dataloder for the concatenate dataset", "\n", "###", "\n", "if", "params", "is", "None", ":", "\n", "                ", "tmp_params", "=", "nii_dconf", ".", "default_loader_conf", "\n", "", "else", ":", "\n", "                ", "tmp_params", "=", "params", ".", "copy", "(", ")", "\n", "\n", "# save parameters", "\n", "", "self", ".", "m_params", "=", "tmp_params", ".", "copy", "(", ")", "\n", "\n", "# ", "\n", "if", "'sampler'", "in", "tmp_params", ":", "\n", "                ", "tmp_sampler", "=", "None", "\n", "if", "tmp_params", "[", "'sampler'", "]", "==", "nii_sampler_fn", ".", "g_str_sampler_bsbl", ":", "\n", "                    ", "if", "'batch_size'", "in", "tmp_params", ":", "\n", "# initialize the sampler", "\n", "                        ", "tmp_sampler", "=", "nii_sampler_fn", ".", "SamplerBlockShuffleByLen", "(", "\n", "py_datasets", ".", "f_get_seq_len_list", "(", ")", ",", "\n", "tmp_params", "[", "'batch_size'", "]", ")", "\n", "# turn off automatic shuffle", "\n", "tmp_params", "[", "'shuffle'", "]", "=", "False", "\n", "", "else", ":", "\n", "                        ", "nii_warn", ".", "f_die", "(", "\"Sampler requires batch size > 1\"", ")", "\n", "", "", "tmp_params", "[", "'sampler'", "]", "=", "tmp_sampler", "\n", "\n", "# collate function", "\n", "", "if", "'batch_size'", "in", "tmp_params", "and", "tmp_params", "[", "'batch_size'", "]", ">", "1", ":", "\n", "# use customize_collate to handle data with unequal length", "\n", "                ", "collate_fn", "=", "nii_collate_fn", ".", "customize_collate", "\n", "", "else", ":", "\n", "                ", "collate_fn", "=", "None", "\n", "\n", "", "self", ".", "m_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "py_datasets", ",", "collate_fn", "=", "collate_fn", ",", "**", "tmp_params", ")", "\n", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "m_loader", "=", "merge_loader", "(", "lst_dset", ")", "\n", "self", ".", "m_params", "=", "lst_dset", "[", "0", "]", ".", "get_loader_params", "(", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_dataset.NII_MergeDataSetLoader.get_loader_params": [[308, 310], ["None"], "methods", ["None"], ["", "def", "get_loader_params", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "m_params", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_dataset.NII_MergeDataSetLoader.get_loader": [[311, 316], ["None"], "methods", ["None"], ["", "def", "get_loader", "(", "self", ")", ":", "\n", "        ", "\"\"\" get_loader():\n        Return the dataLoader (torch.util.data.DataLoader)\n        \"\"\"", "\n", "return", "self", ".", "m_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_dataset.NII_MergeDataSetLoader.get_dataset": [[317, 322], ["None"], "methods", ["None"], ["", "def", "get_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\" get_dataset():\n        Return the dataset (torch.util.data.Dataset)\n        \"\"\"", "\n", "return", "self", ".", "m_datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_dataset.NII_MergeDataSetLoader.get_data_mean_std": [[323, 328], ["customize_dataset.NII_MergeDataSetLoader.m_datasets[].get_data_mean_std"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_data_mean_std"], ["", "def", "get_data_mean_std", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "# temporary solution: just use the first one", "\n", "return", "self", ".", "m_datasets", "[", "0", "]", ".", "get_data_mean_std", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_dataset.NII_MergeDataSetLoader.print_info": [[329, 336], ["core_scripts.f_print_message", "core_scripts.f_print_message", "core_scripts.f_print_message", "core_scripts.f_print_message", "core_scripts.f_print_message", "dset.print_info"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.print_info"], ["", "def", "print_info", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "nii_warn", ".", "f_print_message", "(", "\"Merge datasets by: \"", "+", "self", ".", "way_to_merge", ")", "\n", "for", "dset", "in", "self", ".", "m_datasets", ":", "\n", "            ", "dset", ".", "print_info", "(", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_dataset.NII_MergeDataSetLoader.putitem": [[337, 344], ["customize_dataset.NII_MergeDataSetLoader.m_datasets[].putitem"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.putitem"], ["", "def", "putitem", "(", "self", ",", "output_data", ",", "save_dir", ",", "data_infor_str", ")", ":", "\n", "        ", "\"\"\" Decompose the output_data from network into\n        separate files\n        \"\"\"", "\n", "# Since all datasets have similar configuration on feat dim,", "\n", "# use anyone is OK", "\n", "self", ".", "m_datasets", "[", "0", "]", ".", "putitem", "(", "output_data", ",", "save_dir", ",", "data_infor_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_dataset.NII_MergeDataSetLoader.get_in_dim": [[345, 351], ["customize_dataset.NII_MergeDataSetLoader.m_datasets[].get_in_dim"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_in_dim"], ["", "def", "get_in_dim", "(", "self", ")", ":", "\n", "        ", "\"\"\" Return the dimension of input features\n        \"\"\"", "\n", "# Since all datasets have similar configuration on feat dim,", "\n", "# use anyone is OK", "\n", "return", "self", ".", "m_datasets", "[", "0", "]", ".", "get_in_dim", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_dataset.NII_MergeDataSetLoader.get_out_dim": [[352, 358], ["customize_dataset.NII_MergeDataSetLoader.m_datasets[].get_out_dim"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_out_dim"], ["", "def", "get_out_dim", "(", "self", ")", ":", "\n", "        ", "\"\"\" Return the dimension of output features\n        \"\"\"", "\n", "# Since all datasets have similar configuration on feat dim,", "\n", "# use anyone is OK", "\n", "return", "self", ".", "m_datasets", "[", "0", "]", ".", "get_out_dim", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_dataset.NII_MergeDataSetLoader.get_seq_num": [[359, 363], ["sum", "x.get_seq_num"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_seq_num"], ["", "def", "get_seq_num", "(", "self", ")", ":", "\n", "        ", "\"\"\" Return the number of sequences (after truncation)\n        \"\"\"", "\n", "return", "sum", "(", "[", "x", ".", "get_seq_num", "(", ")", "for", "x", "in", "self", ".", "m_datasets", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.wavformRaw2MuLaw": [[28, 63], ["numpy.round", "print", "sys.exit", "numpy.log", "numpy.array", "numpy.power", "numpy.array", "numpy.power", "numpy.sign", "numpy.log", "numpy.abs"], "function", ["None"], ["def", "wavformRaw2MuLaw", "(", "wavdata", ",", "bit", "=", "16", ",", "signed", "=", "True", ",", "quanLevel", "=", "256.0", ")", ":", "\n", "    ", "\"\"\" \n    wavConverted = wavformRaw2MuLaw(wavdata, bit=16, signed=True, \\\n                                    quanLevel = 256.0)\n    Assume wavData is int type:\n        step1. convert int wav -> float wav\n        step2. convert linear scale wav -> mu-law wav\n\n    Args: \n      wavdata: np array of int-16 or int-32 waveform \n      bit: number of bits to encode waveform\n      signed: input is signed or not\n      quanLevel: level of quantization (default 2 ^ 8)\n    Returned:\n      wav: integer stored as float numbers\n    \"\"\"", "\n", "if", "wavdata", ".", "dtype", "!=", "np", ".", "int16", "and", "wavdata", ".", "dtype", "!=", "np", ".", "int32", ":", "\n", "        ", "print", "(", "\"Input waveform data in not int16 or int32\"", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "# convert to float numbers", "\n", "", "if", "signed", "==", "True", ":", "\n", "        ", "wavdata", "=", "np", ".", "array", "(", "wavdata", ",", "dtype", "=", "np", ".", "float32", ")", "/", "np", ".", "power", "(", "2.0", ",", "bit", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "wavdata", "=", "np", ".", "array", "(", "wavdata", ",", "dtype", "=", "np", ".", "float32", ")", "/", "np", ".", "power", "(", "2.0", ",", "bit", ")", "\n", "\n", "", "tmp_quan_level", "=", "quanLevel", "-", "1", "\n", "# mu-law compansion", "\n", "wavtrans", "=", "np", ".", "sign", "(", "wavdata", ")", "*", "np", ".", "log", "(", "1.0", "+", "tmp_quan_level", "*", "np", ".", "abs", "(", "wavdata", ")", ")", "/", "np", ".", "log", "(", "1.0", "+", "tmp_quan_level", ")", "\n", "wavtrans", "=", "np", ".", "round", "(", "(", "wavtrans", "+", "1.0", ")", "*", "tmp_quan_level", "/", "2.0", ")", "\n", "return", "wavtrans", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.wavformMuLaw2Raw": [[65, 83], ["numpy.sign", "numpy.power", "numpy.abs"], "function", ["None"], ["", "def", "wavformMuLaw2Raw", "(", "wavdata", ",", "quanLevel", "=", "256.0", ")", ":", "\n", "    ", "\"\"\" \n    waveformMuLaw2Raw(wavdata, quanLevel = 256.0)\n    \n    Convert Mu-law waveform  back to raw waveform\n    \n    Args:\n      wavdata: np array\n      quanLevel: level of quantization (default: 2 ^ 8)\n    \n    Return:\n      raw waveform: np array, float\n    \"\"\"", "\n", "tmp_quan_level", "=", "quanLevel", "-", "1", "\n", "wavdata", "=", "wavdata", "*", "2.0", "/", "tmp_quan_level", "-", "1.0", "\n", "wavdata", "=", "np", ".", "sign", "(", "wavdata", ")", "*", "(", "1.0", "/", "tmp_quan_level", ")", "*", "(", "np", ".", "power", "(", "quanLevel", ",", "np", ".", "abs", "(", "wavdata", ")", ")", "-", "1.0", ")", "\n", "return", "wavdata", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.float2wav": [[85, 114], ["scipy.io.wavfile.write", "numpy.power", "numpy.power", "numpy.power", "numpy.asarray", "numpy.asarray", "print", "print", "numpy.asarray", "numpy.power", "numpy.power"], "function", ["None"], ["", "def", "float2wav", "(", "rawData", ",", "wavFile", ",", "bit", "=", "16", ",", "samplingRate", "=", "16000", ")", ":", "\n", "    ", "\"\"\" \n    float2wav(rawFile, wavFile, bit=16, samplingRate = 16000)\n    Convert float waveform into waveform in int\n\n    This is identitcal to waveFloatToPCMFile\n    To be removed\n\n    Args: \n         rawdata: float waveform data in np-arrary\n         wavFile: output file path\n         bit: number of bits to encode waveform in output *.wav\n         samplingrate: \n    \"\"\"", "\n", "rawData", "=", "rawData", "*", "np", ".", "power", "(", "2.0", ",", "bit", "-", "1", ")", "\n", "rawData", "[", "rawData", ">=", "np", ".", "power", "(", "2.0", ",", "bit", "-", "1", ")", "]", "=", "np", ".", "power", "(", "2.0", ",", "bit", "-", "1", ")", "-", "1", "\n", "rawData", "[", "rawData", "<", "-", "1", "*", "np", ".", "power", "(", "2.0", ",", "bit", "-", "1", ")", "]", "=", "-", "1", "*", "np", ".", "power", "(", "2.0", ",", "bit", "-", "1", ")", "\n", "\n", "# write as signed 16bit PCM", "\n", "if", "bit", "==", "16", ":", "\n", "        ", "rawData", "=", "np", ".", "asarray", "(", "rawData", ",", "dtype", "=", "np", ".", "int16", ")", "\n", "", "elif", "bit", "==", "32", ":", "\n", "        ", "rawData", "=", "np", ".", "asarray", "(", "rawData", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Only be able to save wav in int16 and int32 type\"", ")", "\n", "print", "(", "\"Save to int16\"", ")", "\n", "rawData", "=", "np", ".", "asarray", "(", "rawData", ",", "dtype", "=", "np", ".", "int16", ")", "\n", "", "scipy", ".", "io", ".", "wavfile", ".", "write", "(", "wavFile", ",", "samplingRate", ",", "rawData", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.waveReadAsFloat": [[115, 137], ["scipy.io.wavfile.read", "numpy.dtype", "numpy.array", "numpy.power", "numpy.dtype", "numpy.array", "numpy.power", "numpy.dtype", "print", "sys.exit"], "function", ["None"], ["", "def", "waveReadAsFloat", "(", "wavFileIn", ")", ":", "\n", "    ", "\"\"\" sr, wavData = wavReadToFloat(wavFileIn)\n    Wrapper over scipy.io.wavfile\n    Return: \n        sr: sampling_rate\n        wavData: waveform in np.float32 (-1, 1)\n    \"\"\"", "\n", "\n", "sr", ",", "wavdata", "=", "scipy", ".", "io", ".", "wavfile", ".", "read", "(", "wavFileIn", ")", "\n", "\n", "if", "wavdata", ".", "dtype", "is", "np", ".", "dtype", "(", "np", ".", "int16", ")", ":", "\n", "        ", "wavdata", "=", "np", ".", "array", "(", "wavdata", ",", "dtype", "=", "np", ".", "float32", ")", "/", "np", ".", "power", "(", "2.0", ",", "16", "-", "1", ")", "\n", "", "elif", "wavdata", ".", "dtype", "is", "np", ".", "dtype", "(", "np", ".", "int32", ")", ":", "\n", "        ", "wavdata", "=", "np", ".", "array", "(", "wavdata", ",", "dtype", "=", "np", ".", "float32", ")", "/", "np", ".", "power", "(", "2.0", ",", "32", "-", "1", ")", "\n", "", "elif", "wavdata", ".", "dtype", "is", "np", ".", "dtype", "(", "np", ".", "float32", ")", ":", "\n", "        ", "pass", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Unknown waveform format %s\"", "%", "(", "wavFileIn", ")", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "return", "sr", ",", "wavdata", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.waveFloatToPCMFile": [[138, 165], ["scipy.io.wavfile.write", "numpy.power", "numpy.power", "numpy.power", "numpy.asarray", "numpy.asarray", "print", "print", "numpy.asarray", "numpy.power", "numpy.power"], "function", ["None"], ["", "def", "waveFloatToPCMFile", "(", "waveData", ",", "wavFile", ",", "bit", "=", "16", ",", "sr", "=", "16000", ")", ":", "\n", "    ", "\"\"\"waveSaveFromFloat(waveData, wavFile, bit=16, sr=16000)\n    Save waveData (np.float32) as PCM *.wav\n    \n    Args:\n       waveData: waveform data as np.float32\n       wavFile: output PCM waveform file\n       bit: PCM bits\n       sr: sampling rate\n    \"\"\"", "\n", "\n", "# recover to 16bit range [-32768, +32767]", "\n", "rawData", "=", "waveData", "*", "np", ".", "power", "(", "2.0", ",", "bit", "-", "1", ")", "\n", "rawData", "[", "rawData", ">=", "np", ".", "power", "(", "2.0", ",", "bit", "-", "1", ")", "]", "=", "np", ".", "power", "(", "2.0", ",", "bit", "-", "1", ")", "-", "1", "\n", "rawData", "[", "rawData", "<", "-", "1", "*", "np", ".", "power", "(", "2.0", ",", "bit", "-", "1", ")", "]", "=", "-", "1", "*", "np", ".", "power", "(", "2.0", ",", "bit", "-", "1", ")", "\n", "\n", "# write as signed 16bit PCM", "\n", "if", "bit", "==", "16", ":", "\n", "        ", "rawData", "=", "np", ".", "asarray", "(", "rawData", ",", "dtype", "=", "np", ".", "int16", ")", "\n", "", "elif", "bit", "==", "32", ":", "\n", "        ", "rawData", "=", "np", ".", "asarray", "(", "rawData", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Only be able to save wav in int16 and int32 type\"", ")", "\n", "print", "(", "\"Save to int16\"", ")", "\n", "rawData", "=", "np", ".", "asarray", "(", "rawData", ",", "dtype", "=", "np", ".", "int16", ")", "\n", "", "scipy", ".", "io", ".", "wavfile", ".", "write", "(", "wavFile", ",", "sr", ",", "rawData", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.buffering": [[167, 215], ["list", "numpy.vstack().astype", "ValueError", "numpy.hstack", "numpy.expand_dims", "len", "len", "np.hstack.append", "numpy.hstack", "numpy.hstack", "numpy.array", "numpy.vstack", "numpy.zeros", "numpy.zeros", "len"], "function", ["None"], ["", "def", "buffering", "(", "x", ",", "n", ",", "p", "=", "0", ",", "opt", "=", "None", ")", ":", "\n", "    ", "\"\"\"buffering(x, n, p=0, opt=None)\n    input\n    -----\n      x: np.array, input signal, (length, )\n      n: int, window length\n      p: int, overlap, not frame shift\n    \n    outpupt\n    -------\n      output: np.array, framed buffer, (frame_num, frame_length)\n      \n    Example\n    -------\n       framed = buffer(wav, 320, 80, 'nodelay')\n       \n    Code from https://stackoverflow.com/questions/38453249/\n    \"\"\"", "\n", "if", "opt", "not", "in", "(", "'nodelay'", ",", "None", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'{} not implemented'", ".", "format", "(", "opt", ")", ")", "\n", "", "i", "=", "0", "\n", "if", "opt", "==", "'nodelay'", ":", "\n", "# No zeros at array start", "\n", "        ", "result", "=", "x", "[", ":", "n", "]", "\n", "i", "=", "n", "\n", "", "else", ":", "\n", "# Start with `p` zeros", "\n", "        ", "result", "=", "np", ".", "hstack", "(", "[", "np", ".", "zeros", "(", "p", ")", ",", "x", "[", ":", "n", "-", "p", "]", "]", ")", "\n", "i", "=", "n", "-", "p", "\n", "\n", "# Make 2D array, cast to list for .append()", "\n", "", "result", "=", "list", "(", "np", ".", "expand_dims", "(", "result", ",", "axis", "=", "0", ")", ")", "\n", "\n", "while", "i", "<", "len", "(", "x", ")", ":", "\n", "# Create next column, add `p` results from last col if given", "\n", "        ", "col", "=", "x", "[", "i", ":", "i", "+", "(", "n", "-", "p", ")", "]", "\n", "if", "p", "!=", "0", ":", "\n", "            ", "col", "=", "np", ".", "hstack", "(", "[", "result", "[", "-", "1", "]", "[", "-", "p", ":", "]", ",", "col", "]", ")", "\n", "\n", "# Append zeros if last row and not length `n`", "\n", "", "if", "len", "(", "col", ")", ":", "\n", "            ", "col", "=", "np", ".", "hstack", "(", "[", "col", ",", "np", ".", "zeros", "(", "n", "-", "len", "(", "col", ")", ")", "]", ")", "\n", "\n", "# Combine result with next row", "\n", "", "result", ".", "append", "(", "np", ".", "array", "(", "col", ")", ")", "\n", "i", "+=", "(", "n", "-", "p", ")", "\n", "\n", "", "return", "np", ".", "vstack", "(", "result", ")", ".", "astype", "(", "x", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.windowing": [[216, 230], ["numpy.hanning", "np.hanning.astype"], "function", ["None"], ["", "def", "windowing", "(", "framed_buffer", ",", "window_type", "=", "'hanning'", ")", ":", "\n", "    ", "\"\"\"windowing(framed_buffer, window_type='hanning')\n    \n    input\n    -----\n      framed_buffer: np.array, (frame_num, frame_length), output of buffering\n      window_type: str, default 'hanning'\n      \n    \"\"\"", "\n", "if", "window_type", "==", "'hanning'", ":", "\n", "        ", "window", "=", "np", ".", "hanning", "(", "framed_buffer", ".", "shape", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "        ", "assert", "False", ",", "\"Unknown window type in windowing\"", "\n", "", "return", "framed_buffer", "*", "window", ".", "astype", "(", "framed_buffer", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler": [[233, 333], ["wav_tools.buffering", "wav_tools.windowing", "numpy.max", "numpy.bitwise_and", "numpy.asarray", "wav_tools.silence_handler.ignore_short_seg"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.buffering", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.windowing"], ["", "def", "silence_handler", "(", "wav", ",", "sr", ",", "fl", "=", "320", ",", "fs", "=", "80", ",", "\n", "max_thres_below", "=", "30", ",", "\n", "min_thres", "=", "-", "55", ",", "\n", "shortest_len_in_ms", "=", "50", ",", "\n", "flag_output", "=", "0", ")", ":", "\n", "    ", "\"\"\"silence_handler(wav, sr, fs, fl)\n    \n    input\n    -----\n      wav: np.array, (wav_length, ), wavform data\n      sr: int, sampling rate\n      fl: int, frame length, default 320\n      fs: int, frame shift, in number of waveform poings, default 80\n      \n      flag_output: int, flag to select output\n          0: return wav_no_sil, sil_wav, time_tag\n          1: return wav_no_sil\n          2: return sil_wav\n      \n      max_thres_below: int, default 30, max_enenergy - max_thres_below \n          is the lower threshold for speech frame\n      min_thres: int, default -55, the lower threshold for speech frame\n      shortest_len_in_ms: int, ms, default 50 ms, \n          segment less than this length is treated as speech\n      \n    output\n    ------\n      wav_no_sil: np.array, (length_1, ), waveform after removing silence\n      sil_wav: np.array, (length_2, ), waveform in silence regions\n      time_tag: [[start, end], []], where \n      \n      Note: output depends on flag_output\n    \"\"\"", "\n", "assert", "fs", "<", "fl", ",", "\"Frame shift should be smaller than frame length\"", "\n", "\n", "frames", "=", "buffering", "(", "wav", ",", "fl", ",", "fl", "-", "fs", ",", "'nodelay'", ")", "\n", "windowed_frames", "=", "windowing", "(", "frames", ")", "\n", "\n", "frame_energy", "=", "20", "*", "np", ".", "log10", "(", "np", ".", "std", "(", "frames", ",", "axis", "=", "1", ")", "+", "np", ".", "finfo", "(", "np", ".", "float32", ")", ".", "eps", ")", "\n", "frame_energy_max", "=", "np", ".", "max", "(", "frame_energy", ")", "\n", "\n", "frame_tag", "=", "np", ".", "bitwise_and", "(", "\n", "(", "frame_energy", ">", "(", "frame_energy_max", "-", "max_thres_below", ")", ")", ",", "\n", "frame_energy", ">", "min_thres", ")", "\n", "frame_tag", "=", "np", ".", "asarray", "(", "frame_tag", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "seg_len_thres", "=", "shortest_len_in_ms", "*", "sr", "/", "1000", "/", "fs", "\n", "\n", "\n", "def", "ignore_short_seg", "(", "frame_tag", ",", "seg_len_thres", ")", ":", "\n", "        ", "frame_tag_new", "=", "np", ".", "zeros_like", "(", "frame_tag", ")", "+", "frame_tag", "\n", "# boundary of each segment", "\n", "seg_bound", "=", "np", ".", "diff", "(", "np", ".", "concatenate", "(", "(", "[", "0", "]", ",", "frame_tag", ",", "[", "0", "]", ")", ")", ")", "\n", "# start of each segment", "\n", "seg_start", "=", "np", ".", "argwhere", "(", "seg_bound", "==", "1", ")", "[", ":", ",", "0", "]", "\n", "# end of each segment", "\n", "seg_end", "=", "np", ".", "argwhere", "(", "seg_bound", "==", "-", "1", ")", "[", ":", ",", "0", "]", "\n", "assert", "seg_start", ".", "shape", "[", "0", "]", "==", "seg_end", ".", "shape", "[", "0", "]", ",", "\"Fail to extract segment boundaries\"", "\n", "\n", "# length of segment", "\n", "seg_len", "=", "seg_end", "-", "seg_start", "\n", "seg_short_ids", "=", "np", ".", "argwhere", "(", "seg_len", "<", "seg_len_thres", ")", "[", ":", ",", "0", "]", "\n", "for", "idx", "in", "seg_short_ids", ":", "\n", "            ", "start_frame_idx", "=", "seg_start", "[", "idx", "]", "\n", "end_frame_idx", "=", "seg_end", "[", "idx", "]", "\n", "frame_tag_new", "[", "start_frame_idx", ":", "end_frame_idx", "]", "=", "0", "\n", "", "return", "frame_tag_new", "\n", "\n", "# work on non-speech, 1-frame_tag indicates non-speech frames", "\n", "", "frame_process_sil", "=", "ignore_short_seg", "(", "1", "-", "frame_tag", ",", "seg_len_thres", ")", "\n", "# reverse the sign", "\n", "frame_process_sil", "=", "1", "-", "frame_process_sil", "\n", "\n", "# work on speech", "\n", "frame_process_all", "=", "ignore_short_seg", "(", "frame_process_sil", ",", "seg_len_thres", ")", "\n", "\n", "# separate non-speech and speech segments", "\n", "#  do overlap and add", "\n", "frame_tag", "=", "frame_process_all", "\n", "# buffer for speech segments", "\n", "spe_buf", "=", "np", ".", "zeros", "(", "[", "np", ".", "sum", "(", "frame_tag", ")", "*", "fs", "+", "fl", "]", ",", "dtype", "=", "wav", ".", "dtype", ")", "\n", "# buffer for non-speech segments", "\n", "sil_buf", "=", "np", ".", "zeros", "(", "[", "np", ".", "sum", "(", "1", "-", "frame_tag", ")", "*", "fs", "+", "fl", "]", ",", "dtype", "=", "wav", ".", "dtype", ")", "\n", "spe_fr_pt", "=", "0", "\n", "non_fr_pt", "=", "0", "\n", "for", "frame_idx", ",", "flag_speech", "in", "enumerate", "(", "frame_tag", ")", ":", "\n", "        ", "if", "flag_speech", ":", "\n", "            ", "spe_buf", "[", "spe_fr_pt", "*", "fs", ":", "spe_fr_pt", "*", "fs", "+", "fl", "]", "+=", "windowed_frames", "[", "frame_idx", "]", "\n", "spe_fr_pt", "+=", "1", "\n", "", "else", ":", "\n", "            ", "sil_buf", "[", "non_fr_pt", "*", "fs", ":", "non_fr_pt", "*", "fs", "+", "fl", "]", "+=", "windowed_frames", "[", "frame_idx", "]", "\n", "non_fr_pt", "+=", "1", "\n", "\n", "", "", "if", "flag_output", "==", "1", ":", "\n", "        ", "return", "spe_buf", "\n", "", "elif", "flag_output", "==", "2", ":", "\n", "        ", "return", "sil_buf", "\n", "", "else", ":", "\n", "        ", "return", "spe_buf", ",", "sil_buf", ",", "frame_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.f_read_raw_mat": [[20, 52], ["open", "numpy.dtype", "numpy.fromfile", "open.close"], "function", ["None"], ["def", "f_read_raw_mat", "(", "filename", ",", "col", ",", "data_format", "=", "'f4'", ",", "end", "=", "'l'", ")", ":", "\n", "    ", "\"\"\"data = f_read_raw_mat(filename, col, data_format='float', end='l')\n    Read the binary data from filename\n    Return data, which is a (N, col) array\n\n    input\n    -----    \n       filename: str, path to the binary data on the file system\n       col:      int, number of column assumed by the data matrix\n       format:   str, please use the Python protocal to write format\n                 default: 'f4', float32\n       end:      str, little endian 'l' or big endian 'b'?\n                 default: 'l'\n    output\n    ------\n       data: np.array, shape (N, col), where N is the number of rows\n           decided by total_number_elements // col\n    \"\"\"", "\n", "f", "=", "open", "(", "filename", ",", "'rb'", ")", "\n", "if", "end", "==", "'l'", ":", "\n", "        ", "data_format", "=", "'<'", "+", "data_format", "\n", "", "elif", "end", "==", "'b'", ":", "\n", "        ", "data_format", "=", "'>'", "+", "data_format", "\n", "", "else", ":", "\n", "        ", "data_format", "=", "'='", "+", "data_format", "\n", "", "datatype", "=", "np", ".", "dtype", "(", "(", "data_format", ",", "(", "col", ",", ")", ")", ")", "\n", "data", "=", "np", ".", "fromfile", "(", "f", ",", "dtype", "=", "datatype", ")", "\n", "f", ".", "close", "(", ")", "\n", "if", "data", ".", "ndim", "==", "2", "and", "data", ".", "shape", "[", "1", "]", "==", "1", ":", "\n", "        ", "return", "data", "[", ":", ",", "0", "]", "\n", "", "else", ":", "\n", "        ", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.f_read_raw_mat_length": [[53, 75], ["open", "open.seek", "open.tell", "open.close", "int"], "function", ["None"], ["", "", "def", "f_read_raw_mat_length", "(", "filename", ",", "data_format", "=", "'f4'", ")", ":", "\n", "    ", "\"\"\"len = f_read_raw_mat_length(filename, data_format='f4')\n    Read length of data, i.e., number of elements in the data file.\n    If data is in shape (N, M), then len = N * M\n    \n    input\n    -----\n      filename: str, path to the binary data on the file system\n      format:   str, please use the Python protocal to write format\n                 default: 'f4', float32\n    output\n    ------\n      len: int, number of data elements in the data file\n    \"\"\"", "\n", "f", "=", "open", "(", "filename", ",", "'rb'", ")", "\n", "tmp", "=", "f", ".", "seek", "(", "0", ",", "2", ")", "\n", "bytes_num", "=", "f", ".", "tell", "(", ")", "\n", "f", ".", "close", "(", ")", "\n", "if", "data_format", "==", "'f4'", ":", "\n", "        ", "return", "int", "(", "bytes_num", "/", "4", ")", "\n", "", "else", ":", "\n", "        ", "return", "bytes_num", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.f_read_htk": [[76, 128], ["numpy.dtype", "open", "numpy.fromfile", "numpy.dtype", "numpy.fromfile", "open.close", "int", "print"], "function", ["None"], ["", "", "def", "f_read_htk", "(", "filename", ",", "data_format", "=", "'f4'", ",", "end", "=", "'l'", ")", ":", "\n", "    ", "\"\"\"data = read_htk(filename, data_format='f4', end='l')\n    Read HTK File and return the data as numpy.array\n    \n    input\n    -----\n       filename: str, path to the binary HTK data on file system\n       data_format: str, format of the returned data\n                    default: 'f4' float32\n       end:        little endian 'l' or big endian 'b'?\n                   default: 'l'\n    output\n    ------\n       data: numpy.array\n    \"\"\"", "\n", "if", "end", "==", "'l'", ":", "\n", "        ", "data_format", "=", "'<'", "+", "data_format", "\n", "data_formatInt4", "=", "'<i4'", "\n", "data_formatInt2", "=", "'<i2'", "\n", "", "elif", "end", "==", "'b'", ":", "\n", "        ", "data_format", "=", "'>'", "+", "data_format", "\n", "data_formatInt4", "=", "'>i4'", "\n", "data_formatInt2", "=", "'>i2'", "\n", "", "else", ":", "\n", "        ", "data_format", "=", "'='", "+", "data_format", "\n", "data_formatInt4", "=", "'=i4'", "\n", "data_formatInt2", "=", "'=i2'", "\n", "\n", "", "head_type", "=", "np", ".", "dtype", "(", "[", "(", "'nSample'", ",", "data_formatInt4", ")", ",", "\n", "(", "'Period'", ",", "data_formatInt4", ")", ",", "\n", "(", "'SampleSize'", ",", "data_formatInt2", ")", ",", "\n", "(", "'kind'", ",", "data_formatInt2", ")", "]", ")", "\n", "f", "=", "open", "(", "filename", ",", "'rb'", ")", "\n", "head_info", "=", "np", ".", "fromfile", "(", "f", ",", "dtype", "=", "head_type", ",", "count", "=", "1", ")", "\n", "\n", "\"\"\"if end=='l':\n        data_format = '<'+data_format\n    elif end=='b':\n        data_format = '>'+data_format\n    else:\n        data_format = '='+data_format\n    \"\"\"", "\n", "if", "'f'", "in", "data_format", ":", "\n", "        ", "sample_size", "=", "int", "(", "head_info", "[", "'SampleSize'", "]", "[", "0", "]", "/", "4", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Error in read_htk: input should be float32\"", ")", "\n", "return", "False", "\n", "\n", "", "datatype", "=", "np", ".", "dtype", "(", "(", "data_format", ",", "(", "sample_size", ",", ")", ")", ")", "\n", "data", "=", "np", ".", "fromfile", "(", "f", ",", "dtype", "=", "datatype", ")", "\n", "f", ".", "close", "(", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.f_read_htk_length": [[130, 170], ["numpy.dtype", "open", "numpy.fromfile", "open.close", "int"], "function", ["None"], ["", "def", "f_read_htk_length", "(", "filename", ",", "data_format", "=", "'f4'", ",", "end", "=", "'l'", ")", ":", "\n", "    ", "\"\"\"length = read_htk(filename, data_format='f4', end='l')\n    Read HTK File and return the number of data elements in the file\n\n    Read HTK File and return the data as numpy.array\n    \n    input\n    -----\n       filename: str, path to the binary HTK data on file system\n       data_format: str, format of the returned data\n                    default: 'f4' float32\n       end:        little endian 'l' or big endian 'b'?\n                   default: 'l'\n    output\n    ------\n       length: int, number of data elements in the file\n    \"\"\"", "\n", "if", "end", "==", "'l'", ":", "\n", "        ", "data_format", "=", "'<'", "+", "data_format", "\n", "data_formatInt4", "=", "'<i4'", "\n", "data_formatInt2", "=", "'<i2'", "\n", "", "elif", "end", "==", "'b'", ":", "\n", "        ", "data_format", "=", "'>'", "+", "data_format", "\n", "data_formatInt4", "=", "'>i4'", "\n", "data_formatInt2", "=", "'>i2'", "\n", "", "else", ":", "\n", "        ", "data_format", "=", "'='", "+", "data_format", "\n", "data_formatInt4", "=", "'=i4'", "\n", "data_formatInt2", "=", "'=i2'", "\n", "\n", "", "head_type", "=", "np", ".", "dtype", "(", "[", "(", "'nSample'", ",", "data_formatInt4", ")", ",", "\n", "(", "'Period'", ",", "data_formatInt4", ")", ",", "\n", "(", "'SampleSize'", ",", "data_formatInt2", ")", ",", "\n", "(", "'kind'", ",", "data_formatInt2", ")", "]", ")", "\n", "f", "=", "open", "(", "filename", ",", "'rb'", ")", "\n", "head_info", "=", "np", ".", "fromfile", "(", "f", ",", "dtype", "=", "head_type", ",", "count", "=", "1", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n", "sample_size", "=", "int", "(", "head_info", "[", "'SampleSize'", "]", "[", "0", "]", "/", "4", ")", "\n", "return", "sample_size", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.f_write_raw_mat": [[171, 206], ["open", "data.astype.tofile", "open.close", "isinstance", "print", "len", "numpy.dtype", "data.astype"], "function", ["None"], ["", "def", "f_write_raw_mat", "(", "data", ",", "filename", ",", "data_format", "=", "'f4'", ",", "end", "=", "'l'", ")", ":", "\n", "    ", "\"\"\"flag = write_raw_mat(data, filename, data_format='f4', end='l')\n    Write data to file on the file system as binary data\n\n    input\n    -----\n      data:     np.array, data to be saved\n      filename: str, path of the file to save the data\n      data_format:   str, data_format for numpy\n                 default: 'f4', float32\n      end: str   little endian 'l' or big endian 'b'?\n                 default: 'l'\n\n    output   \n    ------\n      flag: bool, whether the writing is done or not\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "data", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "print", "(", "\"Error write_raw_mat: input should be np.array\"", ")", "\n", "return", "False", "\n", "", "f", "=", "open", "(", "filename", ",", "'wb'", ")", "\n", "if", "len", "(", "data_format", ")", ">", "0", ":", "\n", "        ", "if", "end", "==", "'l'", ":", "\n", "            ", "data_format", "=", "'<'", "+", "data_format", "\n", "", "elif", "end", "==", "'b'", ":", "\n", "            ", "data_format", "=", "'>'", "+", "data_format", "\n", "", "else", ":", "\n", "            ", "data_format", "=", "'='", "+", "data_format", "\n", "", "datatype", "=", "np", ".", "dtype", "(", "data_format", ")", "\n", "temp_data", "=", "data", ".", "astype", "(", "datatype", ")", "\n", "", "else", ":", "\n", "        ", "temp_data", "=", "data", "\n", "", "temp_data", ".", "tofile", "(", "f", ",", "''", ")", "\n", "f", ".", "close", "(", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.f_append_raw_mat": [[207, 242], ["open", "data.astype.tofile", "open.close", "isinstance", "print", "len", "numpy.dtype", "data.astype"], "function", ["None"], ["", "def", "f_append_raw_mat", "(", "data", ",", "filename", ",", "data_format", "=", "'f4'", ",", "end", "=", "'l'", ")", ":", "\n", "    ", "\"\"\"flag = write_raw_mat(data, filename, data_format='f4', end='l')\n    Append data to an existing file on the file system as binary data\n\n    input\n    -----\n      data:     np.array, data to be saved\n      filename: str, path of the file to save the data\n      data_format:   str, data_format for numpy\n                 default: 'f4', float32\n      end: str   little endian 'l' or big endian 'b'?\n                 default: 'l'\n\n    output   \n    ------\n      flag: bool, whether the writing is done or not\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "data", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "print", "(", "\"Error write_raw_mat: input shoul be np.array\"", ")", "\n", "return", "False", "\n", "", "f", "=", "open", "(", "filename", ",", "'ab'", ")", "\n", "if", "len", "(", "data_format", ")", ">", "0", ":", "\n", "        ", "if", "end", "==", "'l'", ":", "\n", "            ", "data_format", "=", "'<'", "+", "data_format", "\n", "", "elif", "end", "==", "'b'", ":", "\n", "            ", "data_format", "=", "'>'", "+", "data_format", "\n", "", "else", ":", "\n", "            ", "data_format", "=", "'='", "+", "data_format", "\n", "", "datatype", "=", "np", ".", "dtype", "(", "data_format", ")", "\n", "temp_data", "=", "data", ".", "astype", "(", "datatype", ")", "\n", "", "else", ":", "\n", "        ", "temp_data", "=", "data", "\n", "", "temp_data", ".", "tofile", "(", "f", ",", "''", ")", "\n", "f", ".", "close", "(", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.f_write_htk": [[243, 304], ["open", "numpy.array", "data.astype.tofile", "numpy.array", "data.astype.tofile", "data.astype.tofile", "open.close", "len", "len", "numpy.dtype", "data.astype", "numpy.dtype", "numpy.dtype"], "function", ["None"], ["", "def", "f_write_htk", "(", "data", ",", "targetfile", ",", "\n", "sampPeriod", "=", "50000", ",", "sampKind", "=", "9", ",", "data_format", "=", "'f4'", ",", "end", "=", "'l'", ")", ":", "\n", "    ", "\"\"\"\n    write_htk(data,targetfile,\n      sampPeriod=50000,sampKind=9,data_format='f4',end='l')\n    \n    Write data as HTK-compatible format\n    \n    input\n    -----\n      data: np.array, data to be saved\n      targetfile: str, path of the file to save the data\n      ...\n    \n    output\n    ------\n    \"\"\"", "\n", "if", "data", ".", "ndim", "==", "1", ":", "\n", "        ", "nSamples", ",", "vDim", "=", "data", ".", "shape", "[", "0", "]", ",", "1", "\n", "", "else", ":", "\n", "        ", "nSamples", ",", "vDim", "=", "data", ".", "shape", "\n", "", "if", "data_format", "==", "'f4'", ":", "\n", "        ", "sampSize", "=", "vDim", "*", "4", ";", "\n", "", "else", ":", "\n", "        ", "sampSize", "=", "vDim", "*", "8", ";", "\n", "\n", "", "f", "=", "open", "(", "targetfile", ",", "'wb'", ")", "\n", "\n", "if", "len", "(", "data_format", ")", ">", "0", ":", "\n", "        ", "if", "end", "==", "'l'", ":", "\n", "            ", "data_format1", "=", "'<i4'", "\n", "data_format2", "=", "'<i2'", "\n", "", "elif", "end", "==", "'b'", ":", "\n", "            ", "data_format1", "=", "'>i4'", "\n", "data_format2", "=", "'>i2'", "\n", "", "else", ":", "\n", "            ", "data_format1", "=", "'=i4'", "\n", "data_format2", "=", "'=i2'", "\n", "\n", "", "", "temp_data", "=", "np", ".", "array", "(", "[", "nSamples", ",", "sampPeriod", "]", ",", "\n", "dtype", "=", "np", ".", "dtype", "(", "data_format", ")", ")", "\n", "temp_data", ".", "tofile", "(", "f", ",", "''", ")", "\n", "\n", "temp_data", "=", "np", ".", "array", "(", "[", "sampSize", ",", "sampKind", "]", ",", "dtype", "=", "np", ".", "dtype", "(", "data_format2", ")", ")", "\n", "temp_data", ".", "tofile", "(", "f", ",", "''", ")", "\n", "\n", "\n", "if", "len", "(", "data_format", ")", ">", "0", ":", "\n", "        ", "if", "end", "==", "'l'", ":", "\n", "            ", "data_format", "=", "'<'", "+", "data_format", "\n", "", "elif", "end", "==", "'b'", ":", "\n", "            ", "data_format", "=", "'>'", "+", "data_format", "\n", "", "else", ":", "\n", "            ", "data_format", "=", "'='", "+", "data_format", "\n", "", "datatype", "=", "np", ".", "dtype", "(", "data_format", ")", "\n", "temp_data", "=", "data", ".", "astype", "(", "datatype", ")", "\n", "", "else", ":", "\n", "        ", "temp_data", "=", "data", "\n", "", "temp_data", ".", "tofile", "(", "f", ",", "''", ")", "\n", "f", ".", "close", "(", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.read_dic": [[305, 326], ["json.load", "open", "print", "sys.exit", "print", "sys.exit"], "function", ["None"], ["", "def", "read_dic", "(", "file_path", ")", ":", "\n", "    ", "\"\"\" dic = read_dic(file_path)\n    Read a json file from file_path and return a dictionary\n    \n    input\n    -----\n      file_path: string, path to the file\n\n    output\n    ------\n      dic: a dictionary\n    \"\"\"", "\n", "try", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "open", "(", "file_path", ")", ")", "\n", "", "except", "IOError", ":", "\n", "        ", "print", "(", "\"Cannot find %s\"", "%", "(", "file_path", ")", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "except", "json", ".", "decoder", ".", "JSONDecodeError", ":", "\n", "        ", "print", "(", "\"Cannot parse %s\"", "%", "(", "file_path", ")", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.write_dic": [[329, 344], ["json.dump", "open", "print", "sys.exit"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.debug.data_probe.dump"], ["", "def", "write_dic", "(", "dic", ",", "file_path", ")", ":", "\n", "    ", "\"\"\" write_dic(dic, file_path)\n    Write a dictionary to file\n    \n    input\n    -----\n      dic: dictionary to be dumped\n      file_path: file to store the dictionary\n    \"\"\"", "\n", "\n", "try", ":", "\n", "        ", "json", ".", "dump", "(", "dic", ",", "open", "(", "file_path", ",", "'w'", ")", ")", "\n", "", "except", "IOError", ":", "\n", "        ", "print", "(", "\"Cannot write to %s \"", "%", "(", "file_path", ")", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist": [[345, 350], ["os.path.isfile", "os.path.islink"], "function", ["None"], ["", "", "def", "file_exist", "(", "file_path", ")", ":", "\n", "    ", "\"\"\" file_exit(file_path)\n    Whether file exists\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "isfile", "(", "file_path", ")", "or", "os", ".", "path", ".", "islink", "(", "file_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.pickle_dump": [[352, 368], ["os.mkdir", "open", "pickle.dump", "os.path.dirname"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.debug.data_probe.dump"], ["", "def", "pickle_dump", "(", "data", ",", "file_path", ")", ":", "\n", "    ", "\"\"\" pickle_dump(data, file_path)\n    Dump data into a pickle file\n\n    inputs:\n      data: python object, data to be dumped\n      file_path: str, path to save the pickle file\n    \"\"\"", "\n", "try", ":", "\n", "        ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "dirname", "(", "file_path", ")", ")", "\n", "", "except", "OSError", ":", "\n", "        ", "pass", "\n", "\n", "", "with", "open", "(", "file_path", ",", "'wb'", ")", "as", "file_ptr", ":", "\n", "        ", "pickle", ".", "dump", "(", "data", ",", "file_ptr", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.pickle_load": [[369, 382], ["open", "pickle.load"], "function", ["None"], ["", "def", "pickle_load", "(", "file_path", ")", ":", "\n", "    ", "\"\"\" data = pickle_load(file_path)\n    Load data from a pickle dump file\n    \n    inputs:\n      file_path: str, path of the pickle file\n    \n    output:\n      data: python object\n    \"\"\"", "\n", "with", "open", "(", "file_path", ",", "'rb'", ")", "as", "file_ptr", ":", "\n", "        ", "data", "=", "pickle", ".", "load", "(", "file_ptr", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.wrapper_data_load_with_cache": [[384, 435], ["os.path.join", "os.mkdir", "file_path.split", "os.path.isfile", "io_tools.pickle_load", "method_data_load", "io_tools.pickle_dump", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.pickle_load", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.pickle_dump"], ["", "def", "wrapper_data_load_with_cache", "(", "file_path", ",", "method_data_load", ",", "\n", "cache_dir", "=", "'__cache'", ",", "\n", "use_cached_data", "=", "True", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "\"\"\"wrapper_data_load_with_cache(file_path, method_data_load,\n         cache_dir='__cache', \n         use_cached_data=True, verbose=False):\n\n    Load data from file and save data as pickle file in cache.\n    \n    input\n    -----\n      file_path: str, path of input file\n      method_data_load: python function, funtion to load the data\n      cache_dir: str, default __cache, the directory to save cached pickle file\n      use_cached_data: bool, default True, use cached data when available\n      verbose: bool, default False, print information on reading/writing\n    \n    output\n    ------\n      data: python object decided by method_data_load\n    \n    This method is useful to load large text file. No need to parse text \n    everytime because the data will be saved as pickle file in cache after\n    the first time of execution\n\n    Example:\n    from core_scripts.data_io import io_tools\n    from core_scripts.other_tools import list_tools\n    data = io_tools.wrapper_data_load_with_cache('test_file', \n              list_tools.read_list_from_text)\n    \"\"\"", "\n", "try", ":", "\n", "        ", "os", ".", "mkdir", "(", "cache_dir", ")", "\n", "", "except", "OSError", ":", "\n", "        ", "pass", "\n", "\n", "", "cache_file_path", "=", "'_'", ".", "join", "(", "file_path", ".", "split", "(", "os", ".", "path", ".", "sep", ")", ")", "\n", "cache_file_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "cache_file_path", ")", "\n", "cache_file_path", "+=", "'.pkl'", "\n", "\n", "if", "use_cached_data", "and", "os", ".", "path", ".", "isfile", "(", "cache_file_path", ")", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "\"Load cached data {:s}\"", ".", "format", "(", "cache_file_path", ")", ")", "\n", "", "return", "pickle_load", "(", "cache_file_path", ")", "\n", "", "else", ":", "\n", "        ", "data", "=", "method_data_load", "(", "file_path", ")", "\n", "pickle_dump", "(", "data", ",", "cache_file_path", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "\"Load data {:s}\"", ".", "format", "(", "file_path", ")", ")", "\n", "print", "(", "\"Save cahced data {:s}\"", ".", "format", "(", "cache_file_path", ")", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_sampler.SamplerBlockShuffleByLen.__init__": [[38, 55], ["numpy.argsort", "core_scripts.f_die", "core_scripts.f_die"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die"], ["def", "__init__", "(", "self", ",", "buf_dataseq_length", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\" SamplerBlockShuffleByLength(buf_dataseq_length, batch_size)\n        args\n        ----\n          buf_dataseq_length: list or np.array of int, \n                              length of each data in a dataset\n          batch_size: int, batch_size\n        \"\"\"", "\n", "if", "batch_size", "==", "1", ":", "\n", "            ", "mes", "=", "\"Sampler block shuffle by length requires batch-size>1\"", "\n", "nii_warn", ".", "f_die", "(", "mes", ")", "\n", "\n", "# hyper-parameter, just let block_size = batch_size * 3", "\n", "", "self", ".", "m_block_size", "=", "batch_size", "*", "4", "\n", "# idx sorted based on sequence length", "\n", "self", ".", "m_idx", "=", "np", ".", "argsort", "(", "buf_dataseq_length", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_sampler.SamplerBlockShuffleByLen.__iter__": [[56, 72], ["list", "core_scripts.f_shuffle_in_block_inplace", "core_scripts.f_shuffle_in_block_inplace", "core_scripts.f_shuffle_blocks_inplace", "core_scripts.f_shuffle_blocks_inplace", "iter", "customize_sampler.SamplerBlockShuffleByLen.m_idx.copy"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.random_tools.f_shuffle_in_block_inplace", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.random_tools.f_shuffle_in_block_inplace", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.random_tools.f_shuffle_blocks_inplace", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.random_tools.f_shuffle_blocks_inplace"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Return a iterator to be iterated. \n        \"\"\"", "\n", "tmp_list", "=", "list", "(", "self", ".", "m_idx", ".", "copy", "(", ")", ")", "\n", "\n", "# shuffle within each block", "\n", "# e.g., [1,2,3,4,5,6], block_size=3 -> [3,1,2,5,4,6]", "\n", "nii_rand_tk", ".", "f_shuffle_in_block_inplace", "(", "tmp_list", ",", "self", ".", "m_block_size", ")", "\n", "\n", "# shuffle blocks", "\n", "# e.g., [3,1,2,5,4,6], block_size=3 -> [5,4,6,3,1,2]", "\n", "nii_rand_tk", ".", "f_shuffle_blocks_inplace", "(", "tmp_list", ",", "self", ".", "m_block_size", ")", "\n", "\n", "# return a iterator, list is iterable but not a iterator", "\n", "# https://www.programiz.com/python-programming/iterator", "\n", "return", "iter", "(", "tmp_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_sampler.SamplerBlockShuffleByLen.__len__": [[74, 79], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Sampler requires __len__\n        https://pytorch.org/docs/stable/data.html#torch.utils.data.Sampler\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "m_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_collate_fn.pad_sequence": [[45, 78], ["batch[].size", "max", "all", "enumerate", "s.size", "tensor.new_full", "output_batch.append", "print", "RuntimeError", "tensor.size", "print", "str", "tensor.size", "data.size"], "function", ["None"], ["def", "pad_sequence", "(", "batch", ",", "padding_value", "=", "0.0", ")", ":", "\n", "    ", "\"\"\" pad_sequence(batch)\n    \n    Pad a sequence of data sequences to be same length.\n    Assume batch = [data_1, data2, ...], where data_1 has shape (len, dim, ...)\n    \n    This function is based on \n    pytorch.org/docs/stable/_modules/torch/nn/utils/rnn.html#pad_sequence\n    \"\"\"", "\n", "max_size", "=", "batch", "[", "0", "]", ".", "size", "(", ")", "\n", "trailing_dims", "=", "max_size", "[", "1", ":", "]", "\n", "max_len", "=", "max", "(", "[", "s", ".", "size", "(", "0", ")", "for", "s", "in", "batch", "]", ")", "\n", "\n", "if", "all", "(", "x", ".", "shape", "[", "0", "]", "==", "max_len", "for", "x", "in", "batch", ")", ":", "\n", "# if all data sequences in batch have the same length, no need to pad", "\n", "        ", "return", "batch", "\n", "", "else", ":", "\n", "# we need to pad", "\n", "        ", "out_dims", "=", "(", "max_len", ",", ")", "+", "trailing_dims", "\n", "\n", "output_batch", "=", "[", "]", "\n", "for", "i", ",", "tensor", "in", "enumerate", "(", "batch", ")", ":", "\n", "# check the rest of dimensions", "\n", "            ", "if", "tensor", ".", "size", "(", ")", "[", "1", ":", "]", "!=", "trailing_dims", ":", "\n", "                ", "print", "(", "\"Data in batch has different dimensions:\"", ")", "\n", "for", "data", "in", "batch", ":", "\n", "                    ", "print", "(", "str", "(", "data", ".", "size", "(", ")", ")", ")", "\n", "", "raise", "RuntimeError", "(", "'Fail to create batch data'", ")", "\n", "# save padded results", "\n", "", "out_tensor", "=", "tensor", ".", "new_full", "(", "out_dims", ",", "padding_value", ")", "\n", "out_tensor", "[", ":", "tensor", ".", "size", "(", "0", ")", ",", "...", "]", "=", "tensor", "\n", "output_batch", ".", "append", "(", "out_tensor", ")", "\n", "", "return", "output_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_collate_fn.customize_collate": [[80, 140], ["type", "isinstance", "TypeError", "customize_collate_fn.pad_sequence", "torch.stack", "customize_collate_err_msg.format", "torch.utils.data.get_worker_info", "elem.storage()._new_shared", "elem.new", "isinstance", "max", "len", "customize_collate_fn.customize_collate", "torch.tensor", "isinstance", "elem.storage", "np_str_obj_array_pattern.search", "TypeError", "torch.as_tensor", "torch.tensor", "isinstance", "x.numel", "customize_collate_err_msg.format", "torch.as_tensor", "isinstance", "customize_collate_fn.customize_collate", "isinstance", "hasattr", "type.", "isinstance", "iter", "len", "zip", "next", "all", "RuntimeError", "customize_collate_fn.customize_collate", "customize_collate_fn.customize_collate", "zip", "len"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_collate_fn.pad_sequence", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_collate_fn.customize_collate", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_collate_fn.customize_collate", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_collate_fn.customize_collate", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_collate_fn.customize_collate"], ["", "", "def", "customize_collate", "(", "batch", ")", ":", "\n", "    ", "\"\"\" customize_collate(batch)\n    \n    Collate a list of data into batch. Modified from default_collate.\n    \n    \"\"\"", "\n", "\n", "elem", "=", "batch", "[", "0", "]", "\n", "elem_type", "=", "type", "(", "elem", ")", "\n", "if", "isinstance", "(", "elem", ",", "torch", ".", "Tensor", ")", ":", "\n", "# this is the main part to handle varied length data in a batch", "\n", "# batch = [data_tensor_1, data_tensor_2, data_tensor_3 ... ]", "\n", "# ", "\n", "        ", "batch_new", "=", "pad_sequence", "(", "batch", ")", "\n", "\n", "out", "=", "None", "\n", "if", "torch", ".", "utils", ".", "data", ".", "get_worker_info", "(", ")", "is", "not", "None", ":", "\n", "# If we're in a background process, concatenate directly into a", "\n", "# shared memory tensor to avoid an extra copy", "\n", "\n", "# allocate the memory based on maximum numel", "\n", "            ", "numel", "=", "max", "(", "[", "x", ".", "numel", "(", ")", "for", "x", "in", "batch_new", "]", ")", "*", "len", "(", "batch_new", ")", "\n", "storage", "=", "elem", ".", "storage", "(", ")", ".", "_new_shared", "(", "numel", ")", "\n", "out", "=", "elem", ".", "new", "(", "storage", ")", "\n", "", "return", "torch", ".", "stack", "(", "batch_new", ",", "0", ",", "out", "=", "out", ")", "\n", "\n", "", "elif", "elem_type", ".", "__module__", "==", "'numpy'", "and", "elem_type", ".", "__name__", "!=", "'str_'", "and", "elem_type", ".", "__name__", "!=", "'string_'", ":", "\n", "        ", "if", "elem_type", ".", "__name__", "==", "'ndarray'", "or", "elem_type", ".", "__name__", "==", "'memmap'", ":", "\n", "# array of string classes and object", "\n", "            ", "if", "np_str_obj_array_pattern", ".", "search", "(", "elem", ".", "dtype", ".", "str", ")", "is", "not", "None", ":", "\n", "                ", "raise", "TypeError", "(", "customize_collate_err_msg", ".", "format", "(", "elem", ".", "dtype", ")", ")", "\n", "# this will go to loop in the last case", "\n", "", "return", "customize_collate", "(", "[", "torch", ".", "as_tensor", "(", "b", ")", "for", "b", "in", "batch", "]", ")", "\n", "", "elif", "elem", ".", "shape", "==", "(", ")", ":", "# scalars", "\n", "            ", "return", "torch", ".", "as_tensor", "(", "batch", ")", "\n", "\n", "", "", "elif", "isinstance", "(", "elem", ",", "float", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "batch", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "", "elif", "isinstance", "(", "elem", ",", "int_classes", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "batch", ")", "\n", "", "elif", "isinstance", "(", "elem", ",", "string_classes", ")", ":", "\n", "        ", "return", "batch", "\n", "", "elif", "isinstance", "(", "elem", ",", "container_abcs", ".", "Mapping", ")", ":", "\n", "        ", "return", "{", "key", ":", "customize_collate", "(", "[", "d", "[", "key", "]", "for", "d", "in", "batch", "]", ")", "for", "key", "in", "elem", "}", "\n", "", "elif", "isinstance", "(", "elem", ",", "tuple", ")", "and", "hasattr", "(", "elem", ",", "'_fields'", ")", ":", "# namedtuple", "\n", "        ", "return", "elem_type", "(", "*", "(", "customize_collate", "(", "samples", ")", "for", "samples", "in", "zip", "(", "*", "batch", ")", ")", ")", "\n", "", "elif", "isinstance", "(", "elem", ",", "container_abcs", ".", "Sequence", ")", ":", "\n", "# check to make sure that the elements in batch have consistent size", "\n", "        ", "it", "=", "iter", "(", "batch", ")", "\n", "elem_size", "=", "len", "(", "next", "(", "it", ")", ")", "\n", "if", "not", "all", "(", "len", "(", "elem", ")", "==", "elem_size", "for", "elem", "in", "it", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'each element in batch should be of equal size'", ")", "\n", "\n", "# zip([[A, B, C], [a, b, c]])  -> [[A, a], [B, b], [C, c]]", "\n", "", "transposed", "=", "zip", "(", "*", "batch", ")", "\n", "return", "[", "customize_collate", "(", "samples", ")", "for", "samples", "in", "transposed", "]", "\n", "\n", "", "raise", "TypeError", "(", "customize_collate_err_msg", ".", "format", "(", "elem_type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_collate_fn.customize_collate_from_batch": [[143, 196], ["type", "isinstance", "TypeError", "customize_collate_fn.pad_sequence", "torch.cat", "customize_collate_err_msg.format", "torch.utils.data.get_worker_info", "elem.storage()._new_shared", "elem.new", "isinstance", "max", "len", "customize_collate_fn.customize_collate_from_batch", "torch.tensor", "isinstance", "elem.storage", "np_str_obj_array_pattern.search", "TypeError", "torch.as_tensor", "torch.tensor", "isinstance", "x.numel", "customize_collate_err_msg.format", "torch.as_tensor", "isinstance", "isinstance", "iter", "len", "zip", "next", "all", "RuntimeError", "customize_collate_fn.customize_collate_from_batch", "len"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_collate_fn.pad_sequence", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_collate_fn.customize_collate_from_batch", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.customize_collate_fn.customize_collate_from_batch"], ["", "def", "customize_collate_from_batch", "(", "batch", ")", ":", "\n", "    ", "\"\"\" customize_collate_existing_batch\n    Similar to customize_collate, but input is a list of batch data that have\n    been collated through customize_collate.\n    The difference is use torch.cat rather than torch.stack to merge tensors.\n    Also, list of data is directly concatenated\n\n    This is used in customize_dataset when merging data from multiple datasets.\n    It is better to separate this function from customize_collate\n    \"\"\"", "\n", "\n", "elem", "=", "batch", "[", "0", "]", "\n", "elem_type", "=", "type", "(", "elem", ")", "\n", "if", "isinstance", "(", "elem", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "batch_new", "=", "pad_sequence", "(", "batch", ")", "\n", "out", "=", "None", "\n", "if", "torch", ".", "utils", ".", "data", ".", "get_worker_info", "(", ")", "is", "not", "None", ":", "\n", "            ", "numel", "=", "max", "(", "[", "x", ".", "numel", "(", ")", "for", "x", "in", "batch_new", "]", ")", "*", "len", "(", "batch_new", ")", "\n", "storage", "=", "elem", ".", "storage", "(", ")", ".", "_new_shared", "(", "numel", ")", "\n", "out", "=", "elem", ".", "new", "(", "storage", ")", "\n", "# here is the difference", "\n", "", "return", "torch", ".", "cat", "(", "batch_new", ",", "0", ",", "out", "=", "out", ")", "\n", "\n", "", "elif", "elem_type", ".", "__module__", "==", "'numpy'", "and", "elem_type", ".", "__name__", "!=", "'str_'", "and", "elem_type", ".", "__name__", "!=", "'string_'", ":", "\n", "        ", "if", "elem_type", ".", "__name__", "==", "'ndarray'", "or", "elem_type", ".", "__name__", "==", "'memmap'", ":", "\n", "            ", "if", "np_str_obj_array_pattern", ".", "search", "(", "elem", ".", "dtype", ".", "str", ")", "is", "not", "None", ":", "\n", "                ", "raise", "TypeError", "(", "customize_collate_err_msg", ".", "format", "(", "elem", ".", "dtype", ")", ")", "\n", "", "return", "customize_collate_from_batch", "(", "\n", "[", "torch", ".", "as_tensor", "(", "b", ")", "for", "b", "in", "batch", "]", ")", "\n", "", "elif", "elem", ".", "shape", "==", "(", ")", ":", "# scalars", "\n", "            ", "return", "torch", ".", "as_tensor", "(", "batch", ")", "\n", "", "", "elif", "isinstance", "(", "elem", ",", "float", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "batch", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "", "elif", "isinstance", "(", "elem", ",", "int_classes", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "batch", ")", "\n", "", "elif", "isinstance", "(", "elem", ",", "string_classes", ")", ":", "\n", "        ", "return", "batch", "\n", "", "elif", "isinstance", "(", "elem", ",", "tuple", ")", ":", "\n", "# concatenate two tuples", "\n", "        ", "tmp", "=", "elem", "\n", "for", "tmp_elem", "in", "batch", "[", "1", ":", "]", ":", "\n", "            ", "tmp", "+=", "tmp_elem", "\n", "", "return", "tmp", "\n", "", "elif", "isinstance", "(", "elem", ",", "container_abcs", ".", "Sequence", ")", ":", "\n", "        ", "it", "=", "iter", "(", "batch", ")", "\n", "elem_size", "=", "len", "(", "next", "(", "it", ")", ")", "\n", "if", "not", "all", "(", "len", "(", "elem", ")", "==", "elem_size", "for", "elem", "in", "it", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'each element in batch should be of equal size'", ")", "\n", "", "transposed", "=", "zip", "(", "*", "batch", ")", "\n", "return", "[", "customize_collate_from_batch", "(", "samples", ")", "for", "samples", "in", "transposed", "]", "\n", "\n", "", "raise", "TypeError", "(", "customize_collate_err_msg", ".", "format", "(", "elem_type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.__init__": [[83, 298], ["default_data_io.NIIDataSet.__init__._tmp_f"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "dataset_name", ",", "file_list", ",", "input_dirs", ",", "input_exts", ",", "input_dims", ",", "input_reso", ",", "input_norm", ",", "output_dirs", ",", "output_exts", ",", "output_dims", ",", "output_reso", ",", "output_norm", ",", "stats_path", ",", "data_format", "=", "nii_dconf", ".", "h_dtype_str", ",", "truncate_seq", "=", "None", ",", "min_seq_len", "=", "None", ",", "save_mean_std", "=", "True", ",", "wav_samp_rate", "=", "None", ",", "flag_lang", "=", "'EN'", ",", "global_arg", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        args\n        ----\n          dataset_name: name of this data set\n          file_list: a list of file name strings (without extension)\n                     or, path to the file that contains the file names\n          input_dirs: a list of dirs from which input feature is loaded\n          input_exts: a list of input feature name extentions\n          input_dims: a list of input feature dimensions\n          input_reso: a list of input feature temporal resolutions\n          input_norm: a list of bool, whether normalize input feature or not\n          output_dirs: a list of dirs from which output feature is loaded\n          output_exts: a list of output feature name extentions\n          output_dims: a list of output feature dimensions\n          output_reso: a list of output feature temporal resolutions\n          output_norm: a list of bool, whether normalize target feature or not\n          stat_path: path to the directory that saves mean/std, \n                     utterance length\n          data_format: method to load the data\n                    '<f4' (default): load data as float32m little-endian\n                    'htk': load data as htk format\n          truncate_seq: None (default) or int, truncate sequence into truncks.\n                        truncate_seq > 0 specifies the trunck length \n          min_seq_len: None (default) or int, minimum length of an utterance\n                        utterance shorter than min_seq_len will be ignored\n          save_mean_std: bool, True (default): save mean and std \n          wav_samp_rate: None (default) or int, if input data has  waveform, \n                         please set sampling rate. It is used by _data_writer\n          flag_lang: str, 'EN' (default), if input data has text, the text will\n                     be converted into code indices. flag_lang indicates the \n                     language for the text processer. It is used by _data_reader\n          global_arg: argument parser returned by arg_parse.f_args_parsed()\n                      default None\n        \"\"\"", "\n", "# initialization", "\n", "self", ".", "m_set_name", "=", "dataset_name", "\n", "self", ".", "m_file_list", "=", "file_list", "\n", "self", ".", "m_input_dirs", "=", "input_dirs", "\n", "self", ".", "m_input_exts", "=", "input_exts", "\n", "self", ".", "m_input_dims", "=", "input_dims", "\n", "\n", "self", ".", "m_output_dirs", "=", "output_dirs", "\n", "self", ".", "m_output_exts", "=", "output_exts", "\n", "self", ".", "m_output_dims", "=", "output_dims", "\n", "\n", "if", "len", "(", "self", ".", "m_input_dirs", ")", "!=", "len", "(", "self", ".", "m_input_exts", ")", "or", "len", "(", "self", ".", "m_input_dirs", ")", "!=", "len", "(", "self", ".", "m_input_dims", ")", ":", "\n", "            ", "nii_warn", ".", "f_print", "(", "\"Input dirs, exts, dims, unequal length\"", ",", "\n", "'error'", ")", "\n", "nii_warn", ".", "f_print", "(", "str", "(", "self", ".", "m_input_dirs", ")", ",", "'error'", ")", "\n", "nii_warn", ".", "f_print", "(", "str", "(", "self", ".", "m_input_exts", ")", ",", "'error'", ")", "\n", "nii_warn", ".", "f_print", "(", "str", "(", "self", ".", "m_input_dims", ")", ",", "'error'", ")", "\n", "nii_warn", ".", "f_die", "(", "\"Please check input dirs, exts, dims\"", ")", "\n", "\n", "", "if", "len", "(", "self", ".", "m_output_dims", ")", "!=", "len", "(", "self", ".", "m_output_exts", ")", "or", "(", "self", ".", "m_output_dirs", "and", "len", "(", "self", ".", "m_output_dirs", ")", "!=", "len", "(", "self", ".", "m_output_exts", ")", ")", ":", "\n", "            ", "nii_warn", ".", "f_print", "(", "\"Output dirs, exts, dims, unequal length\"", ",", "'error'", ")", "\n", "nii_warn", ".", "f_die", "(", "\"Please check output dirs, exts, dims\"", ")", "\n", "\n", "# fill in m_*_reso and m_*_norm", "\n", "", "def", "_tmp_f", "(", "list2", ",", "default_value", ",", "length", ")", ":", "\n", "            ", "if", "list2", "is", "None", ":", "\n", "                ", "return", "[", "default_value", "for", "x", "in", "range", "(", "length", ")", "]", "\n", "", "else", ":", "\n", "                ", "return", "list2", "\n", "\n", "", "", "self", ".", "m_input_reso", "=", "_tmp_f", "(", "input_reso", ",", "1", ",", "len", "(", "input_dims", ")", ")", "\n", "self", ".", "m_input_norm", "=", "_tmp_f", "(", "input_norm", ",", "True", ",", "len", "(", "input_dims", ")", ")", "\n", "self", ".", "m_output_reso", "=", "_tmp_f", "(", "output_reso", ",", "1", ",", "len", "(", "output_dims", ")", ")", "\n", "self", ".", "m_output_norm", "=", "_tmp_f", "(", "output_norm", ",", "True", ",", "len", "(", "output_dims", ")", ")", "\n", "if", "len", "(", "self", ".", "m_input_reso", ")", "!=", "len", "(", "self", ".", "m_input_dims", ")", ":", "\n", "            ", "nii_warn", ".", "f_die", "(", "\"len(input_reso) != len(input_dims) in config\"", ")", "\n", "", "if", "len", "(", "self", ".", "m_output_reso", ")", "!=", "len", "(", "self", ".", "m_output_dims", ")", ":", "\n", "            ", "nii_warn", ".", "f_die", "(", "\"len(output_reso) != len(input_dims) in config\"", ")", "\n", "", "if", "len", "(", "self", ".", "m_input_norm", ")", "!=", "len", "(", "self", ".", "m_input_dims", ")", ":", "\n", "            ", "nii_warn", ".", "f_die", "(", "\"len(input_norm) != len(input_dims) in config\"", ")", "\n", "", "if", "len", "(", "self", ".", "m_output_norm", ")", "!=", "len", "(", "self", ".", "m_output_dims", ")", ":", "\n", "            ", "nii_warn", ".", "f_die", "(", "\"len(output_norm) != len(output_dims) in config\"", ")", "\n", "\n", "# dimensions", "\n", "", "self", ".", "m_input_all_dim", "=", "sum", "(", "self", ".", "m_input_dims", ")", "\n", "self", ".", "m_output_all_dim", "=", "sum", "(", "self", ".", "m_output_dims", ")", "\n", "self", ".", "m_io_dim", "=", "self", ".", "m_input_all_dim", "+", "self", ".", "m_output_all_dim", "\n", "\n", "self", ".", "m_truncate_seq", "=", "truncate_seq", "\n", "self", ".", "m_min_seq_len", "=", "min_seq_len", "\n", "self", ".", "m_save_ms", "=", "save_mean_std", "\n", "\n", "# in case there is waveform data in input or output features ", "\n", "self", ".", "m_wav_sr", "=", "wav_samp_rate", "\n", "# option to process waveform with simple VAD", "\n", "if", "global_arg", "is", "not", "None", ":", "\n", "            ", "self", ".", "m_opt_wav_handler", "=", "global_arg", ".", "opt_wav_silence_handler", "\n", "", "else", ":", "\n", "            ", "self", ".", "m_opt_wav_handler", "=", "0", "\n", "\n", "# in case there is text data in input or output features", "\n", "", "self", ".", "m_flag_lang", "=", "flag_lang", "\n", "\n", "# sanity check on resolution configuration", "\n", "# currently, only input features can have different reso,", "\n", "# and the m_input_reso must be the same for all input features", "\n", "if", "any", "(", "[", "x", "!=", "self", ".", "m_input_reso", "[", "0", "]", "for", "x", "in", "self", ".", "m_input_reso", "]", ")", ":", "\n", "            ", "nii_warn", ".", "f_print", "(", "\"input_reso: %s\"", "%", "(", "str", "(", "self", ".", "m_input_reso", ")", ")", ",", "'error'", ")", "\n", "nii_warn", ".", "f_print", "(", "\"NIIDataSet not support\"", ",", "'error'", ",", "end", "=", "''", ")", "\n", "nii_warn", ".", "f_die", "(", "\" different input_reso\"", ")", "\n", "\n", "", "if", "any", "(", "[", "x", "!=", "self", ".", "m_output_reso", "[", "0", "]", "for", "x", "in", "self", ".", "m_output_reso", "]", ")", ":", "\n", "            ", "nii_warn", ".", "f_print", "(", "\"output_reso: %s\"", "%", "(", "str", "(", "self", ".", "m_output_reso", ")", ")", ",", "'error'", ")", "\n", "nii_warn", ".", "f_print", "(", "\"NIIDataSet not support\"", ",", "'error'", ",", "end", "=", "''", ")", "\n", "nii_warn", ".", "f_die", "(", "\" different output_reso\"", ")", "\n", "", "if", "np", ".", "any", "(", "np", ".", "array", "(", "self", ".", "m_output_reso", ")", "<", "0", ")", ":", "\n", "            ", "nii_warn", ".", "f_print", "(", "\"NIIDataSet not support negative reso\"", ",", "\n", "'error'", ",", "end", "=", "''", ")", "\n", "nii_warn", ".", "f_die", "(", "\" Output reso: %s\"", "%", "(", "str", "(", "self", ".", "m_output_reso", ")", ")", ")", "\n", "", "if", "np", ".", "any", "(", "np", ".", "array", "(", "self", ".", "m_input_reso", ")", "<", "0", ")", ":", "\n", "            ", "nii_warn", ".", "f_print", "(", "\"Input resolution: %s\"", "%", "(", "str", "(", "self", ".", "m_input_reso", ")", ")", ")", "\n", "nii_warn", ".", "f_print", "(", "\"Data IO for unaligned input and output pairs\"", ")", "\n", "if", "truncate_seq", "is", "not", "None", ":", "\n", "                ", "nii_warn", ".", "f_print", "(", "\"truncate is set to None\"", ",", "'warning'", ")", "\n", "self", ".", "m_truncate_seq", "=", "None", "\n", "self", ".", "m_min_seq_len", "=", "None", "\n", "\n", "\n", "# no need to contrain output_reso = 1", "\n", "#if any([x != 1 for x in self.m_output_reso]):", "\n", "#    nii_warn.f_print(\"NIIDataSet only supports\", 'error', end='')", "\n", "#    nii_warn.f_die(\" output_reso = [1, 1, ... 1]\")", "\n", "#self.m_single_reso = self.m_input_reso[0]", "\n", "", "", "self", ".", "m_single_reso", "=", "np", ".", "max", "(", "self", ".", "m_input_reso", "+", "self", ".", "m_output_reso", ")", "\n", "\n", "# To make sure that target waveform length is exactly equal", "\n", "#  to the up-sampled sequence length", "\n", "# self.m_truncate_seq must be changed to be N * up_sample", "\n", "if", "self", ".", "m_truncate_seq", "is", "not", "None", ":", "\n", "# assume input resolution is the same", "\n", "            ", "self", ".", "m_truncate_seq", "=", "self", ".", "f_adjust_len", "(", "self", ".", "m_truncate_seq", ")", "\n", "\n", "# similarly on self.m_min_seq_len", "\n", "", "if", "self", ".", "m_min_seq_len", "is", "not", "None", ":", "\n", "# assume input resolution is the same", "\n", "            ", "self", ".", "m_min_seq_len", "=", "self", ".", "f_adjust_len", "(", "self", ".", "m_min_seq_len", ")", "\n", "\n", "# method to load/write raw data", "\n", "", "if", "data_format", "==", "nii_dconf", ".", "h_dtype_str", ":", "\n", "            ", "self", ".", "f_load_data", "=", "lambda", "x", ",", "y", ":", "_data_reader", "(", "x", ",", "y", ",", "self", ".", "m_flag_lang", ")", "\n", "self", ".", "f_length_data", "=", "_data_len_reader", "\n", "self", ".", "f_write_data", "=", "lambda", "x", ",", "y", ":", "_data_writer", "(", "x", ",", "y", ",", "self", ".", "m_wav_sr", ")", "\n", "", "else", ":", "\n", "            ", "nii_warn", ".", "f_print", "(", "\"Unsupported dtype %s\"", "%", "(", "data_format", ")", ")", "\n", "nii_warn", ".", "f_die", "(", "\"Only supports %s \"", "%", "(", "nii_dconf", ".", "h_dtype_str", ")", ")", "\n", "\n", "# check the validity of data", "\n", "", "self", ".", "f_check_file_list", "(", ")", "\n", "\n", "# log down statiscs ", "\n", "#  1. length of each data utterance", "\n", "#  2. mean / std of feature feature file", "\n", "def", "get_name", "(", "stats_path", ",", "set_name", ",", "file_name", ")", ":", "\n", "            ", "tmp", "=", "set_name", "+", "'_'", "+", "file_name", "\n", "return", "os", ".", "path", ".", "join", "(", "stats_path", ",", "tmp", ")", "\n", "\n", "", "self", ".", "m_ms_input_path", "=", "get_name", "(", "stats_path", ",", "self", ".", "m_set_name", ",", "nii_dconf", ".", "mean_std_i_file", ")", "\n", "self", ".", "m_ms_output_path", "=", "get_name", "(", "stats_path", ",", "self", ".", "m_set_name", ",", "nii_dconf", ".", "mean_std_o_file", ")", "\n", "self", ".", "m_data_len_path", "=", "get_name", "(", "stats_path", ",", "self", ".", "m_set_name", ",", "nii_dconf", ".", "data_len_file", ")", "\n", "\n", "# initialize data length and mean /std, read prepared data stats", "\n", "flag_cal_len", "=", "self", ".", "f_init_data_len_stats", "(", "self", ".", "m_data_len_path", ")", "\n", "flag_cal_mean_std", "=", "self", ".", "f_init_mean_std", "(", "self", ".", "m_ms_input_path", ",", "\n", "self", ".", "m_ms_output_path", ")", "\n", "\n", "# if data information is not available, read it again from data", "\n", "if", "flag_cal_len", "or", "flag_cal_mean_std", ":", "\n", "            ", "self", ".", "f_calculate_stats", "(", "flag_cal_len", ",", "flag_cal_mean_std", ")", "\n", "\n", "# check", "\n", "", "if", "self", ".", "__len__", "(", ")", "<", "1", ":", "\n", "            ", "nii_warn", ".", "f_print", "(", "\"Fail to load any data\"", ",", "\"error\"", ")", "\n", "nii_warn", ".", "f_print", "(", "\"Possible reasons: \"", ",", "\"error\"", ")", "\n", "mes", "=", "\"1. Old cache %s. Please delete it.\"", "%", "(", "self", ".", "m_data_len_path", ")", "\n", "mes", "+=", "\"\\n2. input_dirs, input_exts, \"", "\n", "mes", "+=", "\"output_dirs, or output_exts incorrect.\"", "\n", "mes", "+=", "\"\\n3. all data are less than minimum_len in length. \"", "\n", "mes", "+=", "\"\\nThe last case may happen if truncate_seq == mininum_len \"", "\n", "mes", "+=", "\"and truncate_seq % input_reso != 0. Then, the actual \"", "\n", "mes", "+=", "\"truncate_seq becomes truncate_seq//input_reso*input_reso \"", "\n", "mes", "+=", "\"and it will be shorter than minimum_len. Please change \"", "\n", "mes", "+=", "\"truncate_seq and minimum_len so that \"", "\n", "mes", "+=", "\"truncate_seq % input_reso == 0.\"", "\n", "nii_warn", ".", "f_print", "(", "mes", ",", "\"error\"", ")", "\n", "nii_warn", ".", "f_die", "(", "\"Please check configuration file\"", ")", "\n", "# done", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.__len__": [[299, 304], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\" __len__():\n        Return the number of samples in the list\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "m_seq_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.__getitem__": [[305, 427], ["tmp_seq_info.seq_tag", "int", "int", "numpy.zeros", "zip", "default_data_io.NIIDataSet.f_post_data_process", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "int", "int", "numpy.zeros", "zip", "tmp_seq_info.print_to_str", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "tmp_seq_info.seq_length", "tmp_seq_info.seq_start_pos", "default_data_io.NIIDataSet.f_load_data", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "numpy.expand_dims", "tmp_seq_info.seq_length", "tmp_seq_info.seq_start_pos", "default_data_io.NIIDataSet.f_load_data", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.seq_tag", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_post_data_process", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.print_to_str", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.seq_length", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.seq_start_pos", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.seq_length", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.seq_start_pos", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\" __getitem__(self, idx):\n        Return input, output\n        \n        For test set data, output can be None\n        \"\"\"", "\n", "try", ":", "\n", "            ", "tmp_seq_info", "=", "self", ".", "m_seq_info", "[", "idx", "]", "\n", "", "except", "IndexError", ":", "\n", "            ", "nii_warn", ".", "f_die", "(", "\"Sample %d is not in seq_info\"", "%", "(", "idx", ")", ")", "\n", "\n", "# file_name", "\n", "", "file_name", "=", "tmp_seq_info", ".", "seq_tag", "(", ")", "\n", "\n", "# For input data", "\n", "input_reso", "=", "self", ".", "m_input_reso", "[", "0", "]", "\n", "seq_len", "=", "int", "(", "tmp_seq_info", ".", "seq_length", "(", ")", "//", "input_reso", ")", "\n", "s_idx", "=", "int", "(", "tmp_seq_info", ".", "seq_start_pos", "(", ")", "//", "input_reso", ")", "\n", "e_idx", "=", "s_idx", "+", "seq_len", "\n", "\n", "# in case the input length not account using tmp_seq_info.seq_length", "\n", "if", "seq_len", "<", "0", ":", "\n", "            ", "seq_len", "=", "0", "\n", "s_idx", "=", "0", "\n", "e_idx", "=", "0", "\n", "\n", "", "input_dim", "=", "self", ".", "m_input_all_dim", "\n", "in_data", "=", "np", ".", "zeros", "(", "[", "seq_len", ",", "input_dim", "]", ",", "dtype", "=", "nii_dconf", ".", "h_dtype", ")", "\n", "s_dim", "=", "0", "\n", "e_dim", "=", "0", "\n", "\n", "# loop over each feature type", "\n", "for", "t_dir", ",", "t_ext", ",", "t_dim", ",", "t_res", "in", "zip", "(", "self", ".", "m_input_dirs", ",", "self", ".", "m_input_exts", ",", "self", ".", "m_input_dims", ",", "self", ".", "m_input_reso", ")", ":", "\n", "            ", "e_dim", "=", "s_dim", "+", "t_dim", "\n", "\n", "# get file path and load data", "\n", "file_path", "=", "nii_str_tk", ".", "f_realpath", "(", "t_dir", ",", "file_name", ",", "t_ext", ")", "\n", "try", ":", "\n", "                ", "tmp_d", "=", "self", ".", "f_load_data", "(", "file_path", ",", "t_dim", ")", "\n", "", "except", "IOError", ":", "\n", "                ", "nii_warn", ".", "f_die", "(", "\"Cannot find %s\"", "%", "(", "file_path", ")", ")", "\n", "\n", "# write data", "\n", "", "if", "t_res", "<", "0", ":", "\n", "# if this is for input data not aligned with output", "\n", "# make sure that the input is in shape (seq_len, dim)", "\n", "#  f_load_data should return data in shape (seq_len, dim)", "\n", "                ", "if", "tmp_d", ".", "ndim", "==", "1", ":", "\n", "                    ", "in_data", "=", "np", ".", "expand_dims", "(", "tmp_d", ",", "axis", "=", "1", ")", "\n", "", "elif", "tmp_d", ".", "ndim", "==", "2", ":", "\n", "                    ", "in_data", "=", "tmp_d", "\n", "", "else", ":", "\n", "                    ", "nii_warn", ".", "f_die", "(", "\"Default IO cannot handle %s\"", "%", "(", "file_path", ")", ")", "\n", "", "", "elif", "tmp_d", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "# input data has only one frame, duplicate", "\n", "                ", "if", "tmp_d", ".", "ndim", ">", "1", ":", "\n", "                    ", "in_data", "[", ":", ",", "s_dim", ":", "e_dim", "]", "=", "tmp_d", "[", "0", ",", ":", "]", "\n", "", "elif", "t_dim", "==", "1", ":", "\n", "                    ", "in_data", "[", ":", ",", "s_dim", "]", "=", "tmp_d", "\n", "", "else", ":", "\n", "                    ", "nii_warn", ".", "f_die", "(", "\"Dimension wrong %s\"", "%", "(", "file_path", ")", ")", "\n", "", "", "else", ":", "\n", "# normal case", "\n", "                ", "if", "tmp_d", ".", "ndim", ">", "1", ":", "\n", "# write multi-dimension data", "\n", "                    ", "in_data", "[", ":", ",", "s_dim", ":", "e_dim", "]", "=", "tmp_d", "[", "s_idx", ":", "e_idx", ",", ":", "]", "\n", "", "elif", "t_dim", "==", "1", ":", "\n", "# write one-dimension data", "\n", "                    ", "in_data", "[", ":", ",", "s_dim", "]", "=", "tmp_d", "[", "s_idx", ":", "e_idx", "]", "\n", "", "else", ":", "\n", "                    ", "nii_warn", ".", "f_die", "(", "\"Dimension wrong %s\"", "%", "(", "file_path", ")", ")", "\n", "", "", "s_dim", "=", "e_dim", "\n", "\n", "# load output data", "\n", "", "if", "self", ".", "m_output_dirs", ":", "\n", "            ", "output_reso", "=", "self", ".", "m_output_reso", "[", "0", "]", "\n", "seq_len", "=", "int", "(", "tmp_seq_info", ".", "seq_length", "(", ")", "//", "output_reso", ")", "\n", "s_idx", "=", "int", "(", "tmp_seq_info", ".", "seq_start_pos", "(", ")", "//", "output_reso", ")", "\n", "e_idx", "=", "s_idx", "+", "seq_len", "\n", "\n", "out_dim", "=", "self", ".", "m_output_all_dim", "\n", "out_data", "=", "np", ".", "zeros", "(", "[", "seq_len", ",", "out_dim", "]", ",", "dtype", "=", "nii_dconf", ".", "h_dtype", ")", "\n", "s_dim", "=", "0", "\n", "e_dim", "=", "0", "\n", "for", "t_dir", ",", "t_ext", ",", "t_dim", "in", "zip", "(", "self", ".", "m_output_dirs", ",", "self", ".", "m_output_exts", ",", "self", ".", "m_output_dims", ")", ":", "\n", "                ", "e_dim", "=", "s_dim", "+", "t_dim", "\n", "# get file path and load data", "\n", "file_path", "=", "nii_str_tk", ".", "f_realpath", "(", "t_dir", ",", "file_name", ",", "t_ext", ")", "\n", "try", ":", "\n", "                    ", "tmp_d", "=", "self", ".", "f_load_data", "(", "file_path", ",", "t_dim", ")", "\n", "", "except", "IOError", ":", "\n", "                    ", "nii_warn", ".", "f_die", "(", "\"Cannot find %s\"", "%", "(", "file_path", ")", ")", "\n", "\n", "", "if", "tmp_d", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "                    ", "if", "tmp_d", ".", "ndim", ">", "1", ":", "\n", "                        ", "out_data", "[", ":", ",", "s_dim", ":", "e_dim", "]", "=", "tmp_d", "[", "0", ",", ":", "]", "\n", "", "elif", "t_dim", "==", "1", ":", "\n", "                        ", "out_data", "[", ":", ",", "s_dim", "]", "=", "tmp_d", "\n", "", "else", ":", "\n", "                        ", "nii_warn", ".", "f_die", "(", "\"Dimension wrong %s\"", "%", "(", "file_path", ")", ")", "\n", "", "", "else", ":", "\n", "                    ", "if", "tmp_d", ".", "ndim", ">", "1", ":", "\n", "                        ", "out_data", "[", ":", ",", "s_dim", ":", "e_dim", "]", "=", "tmp_d", "[", "s_idx", ":", "e_idx", ",", ":", "]", "\n", "", "elif", "t_dim", "==", "1", ":", "\n", "                        ", "out_data", "[", ":", ",", "s_dim", "]", "=", "tmp_d", "[", "s_idx", ":", "e_idx", "]", "\n", "", "else", ":", "\n", "                        ", "nii_warn", ".", "f_die", "(", "\"Dimension wrong %s\"", "%", "(", "file_path", ")", ")", "\n", "", "", "s_dim", "=", "s_dim", "+", "t_dim", "\n", "", "", "else", ":", "\n", "            ", "out_data", "=", "[", "]", "\n", "\n", "# post processing if necessary", "\n", "", "in_data", ",", "out_data", ",", "tmp_seq_info", ",", "idx", "=", "self", ".", "f_post_data_process", "(", "\n", "in_data", ",", "out_data", ",", "tmp_seq_info", ",", "idx", ")", "\n", "\n", "# return data", "\n", "return", "in_data", ",", "out_data", ",", "tmp_seq_info", ".", "print_to_str", "(", ")", ",", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_post_data_process": [[429, 471], ["core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.silence_handler", "core_scripts.silence_handler", "core_scripts.silence_handler", "core_scripts.silence_handler", "core_scripts.silence_handler", "core_scripts.silence_handler", "core_scripts.silence_handler", "core_scripts.silence_handler", "core_scripts.silence_handler", "core_scripts.silence_handler", "core_scripts.silence_handler", "numpy.expand_dims", "core_scripts.silence_handler", "core_scripts.silence_handler", "core_scripts.silence_handler", "core_scripts.silence_handler", "core_scripts.silence_handler", "core_scripts.silence_handler", "core_scripts.silence_handler", "core_scripts.silence_handler", "core_scripts.silence_handler", "core_scripts.silence_handler", "core_scripts.silence_handler", "numpy.expand_dims", "len", "len"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.silence_handler"], ["", "def", "f_post_data_process", "(", "self", ",", "in_data", ",", "out_data", ",", "seq_info", ",", "idx", ")", ":", "\n", "        ", "\"\"\"A wrapper to process the data after loading from files\n        \"\"\"", "\n", "\n", "if", "self", ".", "m_opt_wav_handler", ">", "0", ":", "\n", "\n", "# Do post processing one by one", "\n", "            ", "tmp_seq_info", "=", "nii_seqinfo", ".", "SeqInfo", "(", "\n", "seq_info", ".", "length", ",", "seq_info", ".", "seq_name", ",", "seq_info", ".", "seg_idx", ",", "\n", "seq_info", ".", "start_pos", ",", "seq_info", ".", "info_id", ")", "\n", "\n", "# waveform silence handler", "\n", "if", "len", "(", "self", ".", "m_input_exts", ")", "==", "1", "and", "self", ".", "m_input_exts", "[", "0", "]", "[", "-", "3", ":", "]", "==", "'wav'", ":", "\n", "                ", "in_data_n", "=", "nii_wav_tk", ".", "silence_handler", "(", "\n", "in_data", "[", ":", ",", "0", "]", ",", "self", ".", "m_wav_sr", ",", "\n", "flag_output", "=", "self", ".", "m_opt_wav_handler", ")", "\n", "in_data_n", "=", "np", ".", "expand_dims", "(", "in_data_n", ",", "axis", "=", "1", ")", "\n", "\n", "# this is temporary setting, use length if it is compatible", "\n", "if", "tmp_seq_info", ".", "length", "==", "in_data", ".", "shape", "[", "0", "]", ":", "\n", "                    ", "tmp_seq_info", ".", "length", "=", "in_data_n", ".", "shape", "[", "0", "]", "\n", "", "", "else", ":", "\n", "                ", "in_data_n", "=", "in_data", "\n", "\n", "", "if", "len", "(", "self", ".", "m_output_exts", ")", "==", "1", "and", "self", ".", "m_output_exts", "[", "0", "]", "[", "-", "3", ":", "]", "==", "'wav'", ":", "\n", "                ", "out_data_n", "=", "nii_wav_tk", ".", "silence_handler", "(", "\n", "out_data", "[", ":", ",", "0", "]", ",", "self", ".", "m_wav_sr", ",", "\n", "flag_output", "=", "self", ".", "m_opt_wav_handler", ")", "\n", "out_data_n", "=", "np", ".", "expand_dims", "(", "out_data_n", ",", "axis", "=", "1", ")", "\n", "\n", "# this is temporary setting, use length if it is compatible", "\n", "if", "tmp_seq_info", ".", "length", "==", "out_data", ".", "shape", "[", "0", "]", ":", "\n", "                    ", "tmp_seq_info", ".", "length", "=", "out_data_n", ".", "shape", "[", "0", "]", "\n", "", "", "else", ":", "\n", "                ", "out_data_n", "=", "out_data", "\n", "\n", "", "return", "in_data_n", ",", "out_data_n", ",", "tmp_seq_info", ",", "idx", "\n", "\n", "", "else", ":", "\n", "            ", "return", "in_data", ",", "out_data", ",", "seq_info", ",", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_get_num_seq": [[473, 478], ["len"], "methods", ["None"], ["", "", "def", "f_get_num_seq", "(", "self", ")", ":", "\n", "        ", "\"\"\" __len__():\n        Return the number of samples in the list\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "m_seq_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_get_seq_len_list": [[479, 483], ["x.seq_length"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.seq_length"], ["", "def", "f_get_seq_len_list", "(", "self", ")", ":", "\n", "        ", "\"\"\" Return length of each sequence as list\n        \"\"\"", "\n", "return", "[", "x", ".", "seq_length", "(", ")", "for", "x", "in", "self", ".", "m_seq_info", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_get_mean_std_tuple": [[484, 487], ["None"], "methods", ["None"], ["", "def", "f_get_mean_std_tuple", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "m_input_mean", ",", "self", ".", "m_input_std", ",", "\n", "self", ".", "m_output_mean", ",", "self", ".", "m_output_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_check_file_list": [[489, 555], ["zip", "isinstance", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.common_members", "core_scripts.common_members", "core_scripts.common_members", "core_scripts.common_members", "core_scripts.common_members", "core_scripts.common_members", "core_scripts.common_members", "core_scripts.common_members", "core_scripts.common_members", "core_scripts.common_members", "core_scripts.common_members", "len", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "zip", "isinstance", "os.path.isfile", "core_scripts.read_list_from_text", "core_scripts.read_list_from_text", "core_scripts.read_list_from_text", "core_scripts.read_list_from_text", "core_scripts.read_list_from_text", "core_scripts.read_list_from_text", "core_scripts.read_list_from_text", "core_scripts.read_list_from_text", "core_scripts.read_list_from_text", "core_scripts.read_list_from_text", "core_scripts.read_list_from_text", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.listdir_with_ext", "core_scripts.common_members", "core_scripts.common_members", "core_scripts.common_members", "core_scripts.common_members", "core_scripts.common_members", "core_scripts.common_members", "core_scripts.common_members", "core_scripts.common_members", "core_scripts.common_members", "core_scripts.common_members", "core_scripts.common_members", "len", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.read_list_from_text", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.read_list_from_text", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.read_list_from_text", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.read_list_from_text", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.read_list_from_text", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.read_list_from_text", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.read_list_from_text", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.read_list_from_text", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.read_list_from_text", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.read_list_from_text", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.read_list_from_text", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die"], ["", "def", "f_check_file_list", "(", "self", ")", ":", "\n", "        ", "\"\"\" f_check_file_list():\n            Check the file list after initialization\n            Make sure that the file in file_list appears in every \n            input/output feature directory. \n            If not, get a file_list in which every file is avaiable\n            in every input/output directory\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "self", ".", "m_file_list", ",", "list", ")", ":", "\n", "            ", "if", "isinstance", "(", "self", ".", "m_file_list", ",", "str", ")", "and", "os", ".", "path", ".", "isfile", "(", "self", ".", "m_file_list", ")", ":", "\n", "# read the list if m_file_list is a str", "\n", "                ", "self", ".", "m_file_list", "=", "nii_list_tools", ".", "read_list_from_text", "(", "\n", "self", ".", "m_file_list", ")", "\n", "", "else", ":", "\n", "                ", "nii_warn", ".", "f_print", "(", "\"Cannot read {:s}\"", ".", "format", "(", "self", ".", "m_file_list", ")", ")", "\n", "nii_warn", ".", "f_print", "(", "\"Read file list from directories\"", ")", "\n", "self", ".", "m_file_list", "=", "None", "\n", "\n", "#  get a initial file list", "\n", "", "", "if", "self", ".", "m_file_list", "is", "None", ":", "\n", "            ", "self", ".", "m_file_list", "=", "nii_list_tools", ".", "listdir_with_ext", "(", "\n", "self", ".", "m_input_dirs", "[", "0", "]", ",", "self", ".", "m_input_exts", "[", "0", "]", ")", "\n", "\n", "# check the list of files exist in all input/output directories", "\n", "", "for", "tmp_d", ",", "tmp_e", "in", "zip", "(", "self", ".", "m_input_dirs", ",", "self", ".", "m_input_exts", ")", ":", "\n", "            ", "tmp_list", "=", "nii_list_tools", ".", "listdir_with_ext", "(", "tmp_d", ",", "tmp_e", ")", "\n", "self", ".", "m_file_list", "=", "nii_list_tools", ".", "common_members", "(", "\n", "tmp_list", ",", "self", ".", "m_file_list", ")", "\n", "\n", "", "if", "len", "(", "self", ".", "m_file_list", ")", "<", "1", ":", "\n", "            ", "nii_warn", ".", "f_print", "(", "\"No input features found after scannning\"", ",", "'error'", ")", "\n", "nii_warn", ".", "f_print", "(", "\"Please check %s\"", "%", "(", "str", "(", "self", ".", "m_input_dirs", ")", ")", ",", "'error'", ")", "\n", "nii_warn", ".", "f_print", "(", "\"They should contain all files in file list\"", ",", "\n", "'error'", ")", "\n", "nii_warn", ".", "f_print", "(", "\"Please also check filename extentions %s\"", "%", "(", "str", "(", "self", ".", "m_input_exts", ")", ")", ",", "'error'", ")", "\n", "nii_warn", ".", "f_print", "(", "\"They should be correctly specified\"", ",", "'error'", ")", "\n", "nii_warn", ".", "f_die", "(", "\"Failed to read input features\"", ")", "\n", "\n", "# check output files if necessary", "\n", "", "if", "self", ".", "m_output_dirs", ":", "\n", "            ", "for", "tmp_d", ",", "tmp_e", "in", "zip", "(", "self", ".", "m_output_dirs", ",", "self", ".", "m_output_exts", ")", ":", "\n", "                ", "tmp_list", "=", "nii_list_tools", ".", "listdir_with_ext", "(", "tmp_d", ",", "tmp_e", ")", "\n", "self", ".", "m_file_list", "=", "nii_list_tools", ".", "common_members", "(", "\n", "tmp_list", ",", "self", ".", "m_file_list", ")", "\n", "\n", "", "if", "len", "(", "self", ".", "m_file_list", ")", "<", "1", ":", "\n", "                ", "nii_warn", ".", "f_print", "(", "\"No output data found\"", ",", "'error'", ")", "\n", "nii_warn", ".", "f_print", "(", "\"Please check %s\"", "%", "(", "str", "(", "self", ".", "m_output_dirs", ")", ")", ",", "'error'", ")", "\n", "nii_warn", ".", "f_print", "(", "\"They should contain all files in file list\"", ",", "\n", "'error'", ")", "\n", "nii_warn", ".", "f_print", "(", "\"Please also check filename extentions %s\"", "%", "(", "str", "(", "self", ".", "m_output_exts", ")", ")", ",", "'error'", ")", "\n", "nii_warn", ".", "f_print", "(", "\"They should be correctly specified\"", ",", "'error'", ")", "\n", "nii_warn", ".", "f_die", "(", "\"Failed to read output features\"", ")", "\n", "", "", "else", ":", "\n", "#nii_warn.f_print(\"Not loading output features\")", "\n", "            ", "pass", "\n", "\n", "# done", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_valid_len": [[557, 566], ["max", "numpy.abs"], "methods", ["None"], ["", "def", "f_valid_len", "(", "self", ",", "t_1", ",", "t_2", ",", "min_length", ")", ":", "\n", "        ", "\"\"\" f_valid_time_steps(time_step1, time_step2, min_length)\n        When either t_1 > min_length or t_2 > min_length, check whether \n        time_step1 and time_step2 are too different       \n        \"\"\"", "\n", "if", "max", "(", "t_1", ",", "t_2", ")", ">", "min_length", ":", "\n", "            ", "if", "(", "np", ".", "abs", "(", "t_1", "-", "t_2", ")", "*", "1.0", "/", "t_1", ")", ">", "0.1", ":", "\n", "                ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_check_specific_data": [[567, 591], ["default_data_io.NIIDataSet.m_input_dirs.copy", "default_data_io.NIIDataSet.m_input_exts.copy", "default_data_io.NIIDataSet.m_input_dims.copy", "default_data_io.NIIDataSet.m_input_reso.copy", "default_data_io.NIIDataSet.extend", "default_data_io.NIIDataSet.extend", "default_data_io.NIIDataSet.extend", "default_data_io.NIIDataSet.extend", "zip", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.file_exist", "core_scripts.file_exist", "core_scripts.file_exist", "core_scripts.file_exist", "core_scripts.file_exist", "core_scripts.file_exist", "core_scripts.file_exist", "core_scripts.file_exist", "core_scripts.file_exist", "core_scripts.file_exist", "core_scripts.file_exist", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "print", "default_data_io.NIIDataSet.f_length_data"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die"], ["", "def", "f_check_specific_data", "(", "self", ",", "file_name", ")", ":", "\n", "        ", "\"\"\" check the data length of a specific file\n        \"\"\"", "\n", "tmp_dirs", "=", "self", ".", "m_input_dirs", ".", "copy", "(", ")", "\n", "tmp_exts", "=", "self", ".", "m_input_exts", ".", "copy", "(", ")", "\n", "tmp_dims", "=", "self", ".", "m_input_dims", ".", "copy", "(", ")", "\n", "tmp_reso", "=", "self", ".", "m_input_reso", ".", "copy", "(", ")", "\n", "tmp_dirs", ".", "extend", "(", "self", ".", "m_output_dirs", ")", "\n", "tmp_exts", ".", "extend", "(", "self", ".", "m_output_exts", ")", "\n", "tmp_dims", ".", "extend", "(", "self", ".", "m_output_dims", ")", "\n", "tmp_reso", ".", "extend", "(", "self", ".", "m_output_reso", ")", "\n", "\n", "# loop over each input/output feature type", "\n", "for", "t_dir", ",", "t_ext", ",", "t_dim", ",", "t_res", "in", "zip", "(", "tmp_dirs", ",", "tmp_exts", ",", "tmp_dims", ",", "tmp_reso", ")", ":", "\n", "\n", "            ", "file_path", "=", "nii_str_tk", ".", "f_realpath", "(", "t_dir", ",", "file_name", ",", "t_ext", ")", "\n", "if", "not", "nii_io_tk", ".", "file_exist", "(", "file_path", ")", ":", "\n", "                ", "nii_warn", ".", "f_die", "(", "\"%s not found\"", "%", "(", "file_path", ")", ")", "\n", "", "else", ":", "\n", "                ", "t_len", "=", "self", ".", "f_length_data", "(", "file_path", ")", "//", "t_dim", "\n", "print", "(", "\"%s, length %d, dim %d, reso: %d\"", "%", "(", "file_path", ",", "t_len", ",", "t_dim", ",", "t_res", ")", ")", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_log_data_len": [[593, 644], ["default_data_io.NIIDataSet.f_adjust_len", "default_data_io.NIIDataSet.f_valid_len", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "default_data_io.NIIDataSet.f_check_specific_data", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_adjust_len", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_valid_len", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_check_specific_data", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die"], ["", "def", "f_log_data_len", "(", "self", ",", "file_name", ",", "t_len", ",", "t_reso", ")", ":", "\n", "        ", "\"\"\" f_log_data_len(file_name, t_len, t_reso):\n        Log down the length of the data file.\n\n        When comparing the different input/output features for the same\n        file_name, only keep the shortest length\n        \"\"\"", "\n", "\n", "# We need to exclude features that should not be considered when", "\n", "#  calculating the sequence length", "\n", "#  1. sentence-level vector (t_len = 1)", "\n", "#  2. unaligned feature (text in text-to-speech) (t_reso < 0)", "\n", "valid_flag", "=", "t_len", ">", "1", "and", "t_reso", ">", "0", "\n", "\n", "if", "valid_flag", ":", "\n", "# the length for the sequence with the fast tempoeral rate", "\n", "# For example, acoustic-feature -> waveform 16kHz,", "\n", "# if acoustic-feature is one frame per 5ms,", "\n", "#  tmp_len = acoustic feature frame length * (5 * 16)", "\n", "# where t_reso = 5*16 is the up-sampling rate of acoustic feature", "\n", "            ", "tmp_len", "=", "t_len", "*", "t_reso", "\n", "\n", "# save length when have not read the file", "\n", "if", "file_name", "not", "in", "self", ".", "m_data_length", ":", "\n", "                ", "self", ".", "m_data_length", "[", "file_name", "]", "=", "tmp_len", "\n", "\n", "# check length", "\n", "", "if", "t_len", "==", "1", ":", "\n", "# cannot come here, keep this line as history", "\n", "# if this is an utterance-level feature, it has only 1 frame", "\n", "                ", "pass", "\n", "", "elif", "self", ".", "f_valid_len", "(", "self", ".", "m_data_length", "[", "file_name", "]", ",", "tmp_len", ",", "nii_dconf", ".", "data_seq_min_length", ")", ":", "\n", "# if the difference in length is small", "\n", "                ", "if", "self", ".", "m_data_length", "[", "file_name", "]", ">", "tmp_len", ":", "\n", "                    ", "self", ".", "m_data_length", "[", "file_name", "]", "=", "tmp_len", "\n", "", "", "else", ":", "\n", "                ", "nii_warn", ".", "f_print", "(", "\"Sequence length mismatch:\"", ",", "'error'", ")", "\n", "self", ".", "f_check_specific_data", "(", "file_name", ")", "\n", "nii_warn", ".", "f_print", "(", "\"Please the above features\"", ",", "'error'", ")", "\n", "nii_warn", ".", "f_die", "(", "\"Possible invalid data %s\"", "%", "(", "file_name", ")", ")", "\n", "\n", "# adjust the length so that, when reso is used,", "\n", "# the sequence length will be N * reso", "\n", "", "tmp", "=", "self", ".", "m_data_length", "[", "file_name", "]", "\n", "self", ".", "m_data_length", "[", "file_name", "]", "=", "self", ".", "f_adjust_len", "(", "tmp", ")", "\n", "", "else", ":", "\n", "# do nothing for unaligned input or sentence-level input", "\n", "            ", "pass", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_adjust_len": [[645, 652], ["None"], "methods", ["None"], ["", "def", "f_adjust_len", "(", "self", ",", "length", ")", ":", "\n", "        ", "\"\"\" When input data will be up-sampled by self.m_single_reso,\n        Make sure that the sequence length at the up-sampled level is\n         = N * self.m_single_reso\n        For data without up-sampling m_single_reso = 1\n        \"\"\"", "\n", "return", "length", "//", "self", ".", "m_single_reso", "*", "self", ".", "m_single_reso", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_precheck_data_length": [[653, 667], ["all"], "methods", ["None"], ["", "def", "f_precheck_data_length", "(", "self", ")", ":", "\n", "        ", "\"\"\" For unaligned input and output, there is no way to know the \n        target sequence length before hand during inference stage\n        \n        self.m_data_length will be empty\n        \"\"\"", "\n", "\n", "if", "not", "self", ".", "m_data_length", "and", "not", "self", ".", "m_output_dirs", "and", "all", "(", "[", "x", "<", "0", "for", "x", "in", "self", ".", "m_input_reso", "]", ")", ":", "\n", "# inference stage, when only input is given", "\n", "# manually create a fake data length for each utterance", "\n", "            ", "for", "file_name", "in", "self", ".", "m_file_list", ":", "\n", "                ", "self", ".", "m_data_length", "[", "file_name", "]", "=", "0", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_log_seq_info": [[670, 711], ["default_data_io.NIIDataSet.f_sum_data_length", "core_scripts.f_eprint", "core_scripts.f_eprint", "core_scripts.f_eprint", "core_scripts.f_eprint", "core_scripts.f_eprint", "core_scripts.f_eprint", "core_scripts.f_eprint", "core_scripts.f_eprint", "core_scripts.f_eprint", "core_scripts.f_eprint", "core_scripts.f_eprint", "len", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "len", "min", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "default_data_io.NIIDataSet.m_seq_info.append", "default_data_io.NIIDataSet.m_seq_info.append"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_sum_data_length", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint"], ["", "def", "f_log_seq_info", "(", "self", ")", ":", "\n", "        ", "\"\"\" After m_data_length has been created, create seq_info\n        \n        \"\"\"", "\n", "for", "file_name", "in", "self", ".", "m_file_list", ":", "\n", "\n", "# if file_name is not logged, ignore this file", "\n", "            ", "if", "file_name", "not", "in", "self", ".", "m_data_length", ":", "\n", "                ", "nii_warn", ".", "f_eprint", "(", "\"Exclude %s from dataset\"", "%", "(", "file_name", ")", ")", "\n", "continue", "\n", "\n", "# if not truncate, save the seq_info directly", "\n", "# otherwise, save truncate_seq info", "\n", "", "length_remain", "=", "self", ".", "m_data_length", "[", "file_name", "]", "\n", "start_pos", "=", "0", "\n", "seg_idx", "=", "0", "\n", "if", "self", ".", "m_truncate_seq", "is", "not", "None", ":", "\n", "                ", "while", "(", "length_remain", ">", "0", ")", ":", "\n", "                    ", "info_idx", "=", "len", "(", "self", ".", "m_seq_info", ")", "\n", "seg_length", "=", "min", "(", "self", ".", "m_truncate_seq", ",", "length_remain", ")", "\n", "seq_info", "=", "nii_seqinfo", ".", "SeqInfo", "(", "seg_length", ",", "\n", "file_name", ",", "seg_idx", ",", "\n", "start_pos", ",", "info_idx", ")", "\n", "if", "self", ".", "m_min_seq_len", "is", "None", "or", "seg_length", ">=", "self", ".", "m_min_seq_len", ":", "\n", "                        ", "self", ".", "m_seq_info", ".", "append", "(", "seq_info", ")", "\n", "seg_idx", "+=", "1", "\n", "", "start_pos", "+=", "seg_length", "\n", "length_remain", "-=", "seg_length", "\n", "", "", "else", ":", "\n", "                ", "info_idx", "=", "len", "(", "self", ".", "m_seq_info", ")", "\n", "seq_info", "=", "nii_seqinfo", ".", "SeqInfo", "(", "length_remain", ",", "\n", "file_name", ",", "seg_idx", ",", "\n", "start_pos", ",", "info_idx", ")", "\n", "if", "self", ".", "m_min_seq_len", "is", "None", "or", "length_remain", ">=", "self", ".", "m_min_seq_len", ":", "\n", "                    ", "self", ".", "m_seq_info", ".", "append", "(", "seq_info", ")", "\n", "\n", "# get the total length", "\n", "", "", "", "self", ".", "m_data_total_length", "=", "self", ".", "f_sum_data_length", "(", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_init_mean_std": [[712, 756], ["numpy.zeros", "numpy.ones", "numpy.zeros", "numpy.ones", "any", "os.path.isfile", "os.path.isfile", "default_data_io.NIIDataSet.f_load_data", "default_data_io.NIIDataSet.f_load_data", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print"], ["", "def", "f_init_mean_std", "(", "self", ",", "ms_input_path", ",", "ms_output_path", ")", ":", "\n", "        ", "\"\"\" f_init_mean_std\n        Initialzie mean and std vectors for input and output\n        \"\"\"", "\n", "self", ".", "m_input_mean", "=", "np", ".", "zeros", "(", "[", "self", ".", "m_input_all_dim", "]", ")", "\n", "self", ".", "m_input_std", "=", "np", ".", "ones", "(", "[", "self", ".", "m_input_all_dim", "]", ")", "\n", "self", ".", "m_output_mean", "=", "np", ".", "zeros", "(", "[", "self", ".", "m_output_all_dim", "]", ")", "\n", "self", ".", "m_output_std", "=", "np", ".", "ones", "(", "[", "self", ".", "m_output_all_dim", "]", ")", "\n", "\n", "flag", "=", "True", "\n", "if", "not", "self", ".", "m_save_ms", ":", "\n", "# assume mean/std will be loaded from the network", "\n", "# for example, for validation and test sets", "\n", "            ", "flag", "=", "False", "\n", "\n", "", "if", "not", "any", "(", "self", ".", "m_input_norm", "+", "self", ".", "m_output_norm", ")", ":", "\n", "# none of the input / output features needs norm", "\n", "            ", "flag", "=", "False", "\n", "\n", "", "if", "os", ".", "path", ".", "isfile", "(", "ms_input_path", ")", "and", "os", ".", "path", ".", "isfile", "(", "ms_output_path", ")", ":", "\n", "# load mean and std if exists", "\n", "            ", "ms_input", "=", "self", ".", "f_load_data", "(", "ms_input_path", ",", "1", ")", "\n", "ms_output", "=", "self", ".", "f_load_data", "(", "ms_output_path", ",", "1", ")", "\n", "\n", "if", "ms_input", ".", "shape", "[", "0", "]", "!=", "(", "self", ".", "m_input_all_dim", "*", "2", ")", "or", "ms_output", ".", "shape", "[", "0", "]", "!=", "(", "self", ".", "m_output_all_dim", "*", "2", ")", ":", "\n", "                ", "if", "ms_input", ".", "shape", "[", "0", "]", "!=", "(", "self", ".", "m_input_all_dim", "*", "2", ")", ":", "\n", "                    ", "nii_warn", ".", "f_print", "(", "\"%s incompatible\"", "%", "(", "ms_input_path", ")", ",", "\n", "'warning'", ")", "\n", "", "if", "ms_output", ".", "shape", "[", "0", "]", "!=", "(", "self", ".", "m_output_all_dim", "*", "2", ")", ":", "\n", "                    ", "nii_warn", ".", "f_print", "(", "\"%s incompatible\"", "%", "(", "ms_output_path", ")", ",", "\n", "'warning'", ")", "\n", "", "nii_warn", ".", "f_print", "(", "\"mean/std will be recomputed\"", ",", "'warning'", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "m_input_mean", "=", "ms_input", "[", "0", ":", "self", ".", "m_input_all_dim", "]", "\n", "self", ".", "m_input_std", "=", "ms_input", "[", "self", ".", "m_input_all_dim", ":", "]", "\n", "\n", "self", ".", "m_output_mean", "=", "ms_output", "[", "0", ":", "self", ".", "m_output_all_dim", "]", "\n", "self", ".", "m_output_std", "=", "ms_output", "[", "self", ".", "m_output_all_dim", ":", "]", "\n", "nii_warn", ".", "f_print", "(", "\"Load mean/std from %s and %s\"", "%", "(", "ms_input_path", ",", "ms_output_path", ")", ")", "\n", "flag", "=", "False", "\n", "", "", "return", "flag", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_sum_data_length": [[758, 763], ["sum", "x.seq_length"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.seq_length"], ["", "def", "f_sum_data_length", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "\n", "return", "sum", "(", "[", "x", ".", "seq_length", "(", ")", "for", "x", "in", "self", ".", "m_seq_info", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_init_data_len_stats": [[764, 815], ["os.path.isfile", "core_scripts.read_dic", "core_scripts.read_dic", "core_scripts.read_dic", "core_scripts.read_dic", "core_scripts.read_dic", "core_scripts.read_dic", "core_scripts.read_dic", "core_scripts.read_dic", "core_scripts.read_dic", "core_scripts.read_dic", "core_scripts.read_dic", "default_data_io.NIIDataSet.f_sum_data_length", "core_scripts.list_identical", "core_scripts.list_identical", "core_scripts.list_identical", "core_scripts.list_identical", "core_scripts.list_identical", "core_scripts.list_identical", "core_scripts.list_identical", "core_scripts.list_identical", "core_scripts.list_identical", "core_scripts.list_identical", "core_scripts.list_identical", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo.load_from_dic", "default_data_io.NIIDataSet.m_seq_info.append", "core_scripts.SeqInfo.seq_tag", "default_data_io.NIIDataSet.m_data_length.keys", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.list_b_in_list_a", "core_scripts.list_b_in_list_a", "core_scripts.list_b_in_list_a", "core_scripts.list_b_in_list_a", "core_scripts.list_b_in_list_a", "core_scripts.list_b_in_list_a", "core_scripts.list_b_in_list_a", "core_scripts.list_b_in_list_a", "core_scripts.list_b_in_list_a", "core_scripts.list_b_in_list_a", "core_scripts.list_b_in_list_a", "core_scripts.SeqInfo.seq_length", "core_scripts.SeqInfo.seq_length", "default_data_io.NIIDataSet.m_data_length.keys", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.members_in_a_not_in_b", "core_scripts.members_in_a_not_in_b", "core_scripts.members_in_a_not_in_b", "core_scripts.members_in_a_not_in_b", "core_scripts.members_in_a_not_in_b", "core_scripts.members_in_a_not_in_b", "core_scripts.members_in_a_not_in_b", "core_scripts.members_in_a_not_in_b", "core_scripts.members_in_a_not_in_b", "core_scripts.members_in_a_not_in_b", "core_scripts.members_in_a_not_in_b", "default_data_io.NIIDataSet.m_data_length.keys", "core_scripts.f_eprint", "core_scripts.f_eprint", "core_scripts.f_eprint", "core_scripts.f_eprint", "core_scripts.f_eprint", "core_scripts.f_eprint", "core_scripts.f_eprint", "core_scripts.f_eprint", "core_scripts.f_eprint", "core_scripts.f_eprint", "core_scripts.f_eprint", "len", "len"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.read_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.read_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.read_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.read_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.read_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.read_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.read_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.read_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.read_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.read_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.read_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_sum_data_length", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_identical", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_identical", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_identical", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_identical", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_identical", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_identical", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_identical", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_identical", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_identical", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_identical", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_identical", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.load_from_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.seq_tag", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_b_in_list_a", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_b_in_list_a", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_b_in_list_a", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_b_in_list_a", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_b_in_list_a", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_b_in_list_a", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_b_in_list_a", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_b_in_list_a", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_b_in_list_a", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_b_in_list_a", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_b_in_list_a", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.seq_length", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.seq_length", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.members_in_a_not_in_b", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.members_in_a_not_in_b", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.members_in_a_not_in_b", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.members_in_a_not_in_b", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.members_in_a_not_in_b", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.members_in_a_not_in_b", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.members_in_a_not_in_b", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.members_in_a_not_in_b", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.members_in_a_not_in_b", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.members_in_a_not_in_b", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.members_in_a_not_in_b", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint"], ["", "def", "f_init_data_len_stats", "(", "self", ",", "data_path", ")", ":", "\n", "        ", "\"\"\"\n        flag = f_init_data_len_stats(self, data_path)\n        Check whether data length has been stored in data_pat.\n        If yes, load data_path and return False\n        Else, return True\n        \"\"\"", "\n", "self", ".", "m_seq_info", "=", "[", "]", "\n", "self", ".", "m_data_length", "=", "{", "}", "\n", "self", ".", "m_data_total_length", "=", "0", "\n", "\n", "flag", "=", "True", "\n", "if", "os", ".", "path", ".", "isfile", "(", "data_path", ")", ":", "\n", "# load data length from pre-stored *.dic", "\n", "            ", "dic_seq_infos", "=", "nii_io_tk", ".", "read_dic", "(", "self", ".", "m_data_len_path", ")", "\n", "for", "dic_seq_info", "in", "dic_seq_infos", ":", "\n", "                ", "seq_info", "=", "nii_seqinfo", ".", "SeqInfo", "(", ")", "\n", "seq_info", ".", "load_from_dic", "(", "dic_seq_info", ")", "\n", "self", ".", "m_seq_info", ".", "append", "(", "seq_info", ")", "\n", "seq_tag", "=", "seq_info", ".", "seq_tag", "(", ")", "\n", "if", "seq_tag", "not", "in", "self", ".", "m_data_length", ":", "\n", "                    ", "self", ".", "m_data_length", "[", "seq_tag", "]", "=", "seq_info", ".", "seq_length", "(", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "m_data_length", "[", "seq_tag", "]", "+=", "seq_info", ".", "seq_length", "(", ")", "\n", "", "", "self", ".", "m_data_total_length", "=", "self", ".", "f_sum_data_length", "(", ")", "\n", "\n", "# check whether *.dic contains files in filelist", "\n", "# note: one file is not found in self.m_data_length if it", "\n", "#  is shorter than the truncate_seq", "\n", "if", "nii_list_tools", ".", "list_identical", "(", "self", ".", "m_file_list", ",", "self", ".", "m_data_length", ".", "keys", "(", ")", ")", ":", "\n", "                ", "nii_warn", ".", "f_print", "(", "\"Read sequence info: %s\"", "%", "(", "data_path", ")", ")", "\n", "flag", "=", "False", "\n", "", "elif", "nii_list_tools", ".", "list_b_in_list_a", "(", "self", ".", "m_file_list", ",", "\n", "self", ".", "m_data_length", ".", "keys", "(", ")", ")", ":", "\n", "                ", "nii_warn", ".", "f_print", "(", "\"Read sequence info: %s\"", "%", "(", "data_path", ")", ")", "\n", "nii_warn", ".", "f_print", "(", "\n", "\"However %d samples are ignoed\"", "%", "(", "len", "(", "self", ".", "m_file_list", ")", "-", "len", "(", "self", ".", "m_data_length", ")", ")", ")", "\n", "tmp", "=", "nii_list_tools", ".", "members_in_a_not_in_b", "(", "\n", "self", ".", "m_file_list", ",", "self", ".", "m_data_length", ".", "keys", "(", ")", ")", "\n", "for", "tmp_name", "in", "tmp", ":", "\n", "                    ", "nii_warn", ".", "f_eprint", "(", "\"Exclude %s from dataset\"", "%", "(", "tmp_name", ")", ")", "\n", "\n", "", "flag", "=", "False", "\n", "", "else", ":", "\n", "                ", "self", ".", "m_seq_info", "=", "[", "]", "\n", "self", ".", "m_data_length", "=", "{", "}", "\n", "self", ".", "m_data_total_length", "=", "0", "\n", "\n", "", "", "return", "flag", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_save_data_len": [[816, 821], ["core_scripts.write_dic", "core_scripts.write_dic", "core_scripts.write_dic", "core_scripts.write_dic", "core_scripts.write_dic", "core_scripts.write_dic", "core_scripts.write_dic", "core_scripts.write_dic", "core_scripts.write_dic", "core_scripts.write_dic", "core_scripts.write_dic", "x.print_to_dic"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.write_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.write_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.write_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.write_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.write_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.write_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.write_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.write_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.write_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.write_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.write_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.print_to_dic"], ["", "def", "f_save_data_len", "(", "self", ",", "data_len_path", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "nii_io_tk", ".", "write_dic", "(", "[", "x", ".", "print_to_dic", "(", ")", "for", "x", "in", "self", ".", "m_seq_info", "]", ",", "data_len_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_save_mean_std": [[822, 837], ["numpy.zeros", "default_data_io.NIIDataSet.f_write_data", "numpy.zeros", "default_data_io.NIIDataSet.f_write_data"], "methods", ["None"], ["", "def", "f_save_mean_std", "(", "self", ",", "ms_input_path", ",", "ms_output_path", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "# save mean and std", "\n", "ms_input", "=", "np", ".", "zeros", "(", "[", "self", ".", "m_input_all_dim", "*", "2", "]", ")", "\n", "ms_input", "[", "0", ":", "self", ".", "m_input_all_dim", "]", "=", "self", ".", "m_input_mean", "\n", "ms_input", "[", "self", ".", "m_input_all_dim", ":", "]", "=", "self", ".", "m_input_std", "\n", "self", ".", "f_write_data", "(", "ms_input", ",", "ms_input_path", ")", "\n", "\n", "ms_output", "=", "np", ".", "zeros", "(", "[", "self", ".", "m_output_all_dim", "*", "2", "]", ")", "\n", "ms_output", "[", "0", ":", "self", ".", "m_output_all_dim", "]", "=", "self", ".", "m_output_mean", "\n", "ms_output", "[", "self", ".", "m_output_all_dim", ":", "]", "=", "self", ".", "m_output_std", "\n", "self", ".", "f_write_data", "(", "ms_output", ",", "ms_output_path", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_print_info": [[838, 870], ["min", "max", "core_scripts.f_print_message", "core_scripts.f_print_message", "core_scripts.f_print_message", "core_scripts.f_print_message", "core_scripts.f_print_message", "core_scripts.f_print_message", "core_scripts.f_print_message", "core_scripts.f_print_message", "core_scripts.f_print_message", "core_scripts.f_print_message", "core_scripts.f_print_message", "len", "str", "str", "str", "str", "str", "str", "str", "str", "x.seq_length", "x.seq_length"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.seq_length", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.seq_length"], ["", "def", "f_print_info", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "mes", "=", "\"Dataset {}:\"", ".", "format", "(", "self", ".", "m_set_name", ")", "\n", "mes", "+=", "\"\\n  Time steps: {:d} \"", ".", "format", "(", "self", ".", "m_data_total_length", ")", "\n", "if", "self", ".", "m_truncate_seq", "is", "not", "None", ":", "\n", "            ", "mes", "+=", "\"\\n  Truncate length: {:d}\"", ".", "format", "(", "self", ".", "m_truncate_seq", ")", "\n", "", "mes", "+=", "\"\\n  Data sequence num: {:d}\"", ".", "format", "(", "len", "(", "self", ".", "m_seq_info", ")", ")", "\n", "tmp_min_len", "=", "min", "(", "[", "x", ".", "seq_length", "(", ")", "for", "x", "in", "self", ".", "m_seq_info", "]", ")", "\n", "tmp_max_len", "=", "max", "(", "[", "x", ".", "seq_length", "(", ")", "for", "x", "in", "self", ".", "m_seq_info", "]", ")", "\n", "mes", "+=", "\"\\n  Maximum sequence length: {:d}\"", ".", "format", "(", "tmp_max_len", ")", "\n", "mes", "+=", "\"\\n  Minimum sequence length: {:d}\"", ".", "format", "(", "tmp_min_len", ")", "\n", "if", "self", ".", "m_min_seq_len", "is", "not", "None", ":", "\n", "            ", "mes", "+=", "\"\\n  Shorter sequences are ignored\"", "\n", "", "mes", "+=", "\"\\n  Inputs\\n    Dirs:\"", "\n", "for", "subdir", "in", "self", ".", "m_input_dirs", ":", "\n", "            ", "mes", "+=", "\"\\n        {:s}\"", ".", "format", "(", "subdir", ")", "\n", "", "mes", "+=", "\"\\n    Exts:{:s}\"", ".", "format", "(", "str", "(", "self", ".", "m_input_exts", ")", ")", "\n", "mes", "+=", "\"\\n    Dims:{:s}\"", ".", "format", "(", "str", "(", "self", ".", "m_input_dims", ")", ")", "\n", "mes", "+=", "\"\\n    Reso:{:s}\"", ".", "format", "(", "str", "(", "self", ".", "m_input_reso", ")", ")", "\n", "mes", "+=", "\"\\n    Norm:{:s}\"", ".", "format", "(", "str", "(", "self", ".", "m_input_norm", ")", ")", "\n", "mes", "+=", "\"\\n  Outputs\\n    Dirs:\"", "\n", "for", "subdir", "in", "self", ".", "m_output_dirs", ":", "\n", "            ", "mes", "+=", "\"\\n        {:s}\"", ".", "format", "(", "subdir", ")", "\n", "", "mes", "+=", "\"\\n    Exts:{:s}\"", ".", "format", "(", "str", "(", "self", ".", "m_output_exts", ")", ")", "\n", "mes", "+=", "\"\\n    Dims:{:s}\"", ".", "format", "(", "str", "(", "self", ".", "m_output_dims", ")", ")", "\n", "mes", "+=", "\"\\n    Reso:{:s}\"", ".", "format", "(", "str", "(", "self", ".", "m_output_reso", ")", ")", "\n", "mes", "+=", "\"\\n    Norm:{:s}\"", ".", "format", "(", "str", "(", "self", ".", "m_output_norm", ")", ")", "\n", "if", "self", ".", "m_opt_wav_handler", ">", "0", ":", "\n", "            ", "mes", "+=", "\"\\n  Waveform silence handler will be used\"", "\n", "", "nii_warn", ".", "f_print_message", "(", "mes", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_calculate_stats": [[871, 965], ["default_data_io.NIIDataSet.m_input_dirs.copy", "default_data_io.NIIDataSet.m_input_exts.copy", "default_data_io.NIIDataSet.m_input_dims.copy", "default_data_io.NIIDataSet.m_input_reso.copy", "default_data_io.NIIDataSet.m_input_norm.copy", "default_data_io.NIIDataSet.extend", "default_data_io.NIIDataSet.extend", "default_data_io.NIIDataSet.extend", "default_data_io.NIIDataSet.extend", "default_data_io.NIIDataSet.extend", "zip", "default_data_io.NIIDataSet.f_precheck_data_length", "default_data_io.NIIDataSet.f_log_seq_info", "default_data_io.NIIDataSet.f_save_data_len", "default_data_io.NIIDataSet.f_save_mean_std", "numpy.zeros", "numpy.zeros", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.file_exist", "core_scripts.file_exist", "core_scripts.file_exist", "core_scripts.file_exist", "core_scripts.file_exist", "core_scripts.file_exist", "core_scripts.file_exist", "core_scripts.file_exist", "core_scripts.file_exist", "core_scripts.file_exist", "core_scripts.file_exist", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "default_data_io.NIIDataSet.f_log_data_len", "default_data_io.NIIDataSet.f_load_data", "core_scripts.f_online_mean_std", "core_scripts.f_online_mean_std", "core_scripts.f_online_mean_std", "core_scripts.f_online_mean_std", "core_scripts.f_online_mean_std", "core_scripts.f_online_mean_std", "core_scripts.f_online_mean_std", "core_scripts.f_online_mean_std", "core_scripts.f_online_mean_std", "core_scripts.f_online_mean_std", "core_scripts.f_online_mean_std", "core_scripts.f_var2std", "core_scripts.f_var2std", "core_scripts.f_var2std", "core_scripts.f_var2std", "core_scripts.f_var2std", "core_scripts.f_var2std", "core_scripts.f_var2std", "core_scripts.f_var2std", "core_scripts.f_var2std", "core_scripts.f_var2std", "core_scripts.f_var2std", "core_scripts.f_var2std", "core_scripts.f_var2std", "core_scripts.f_var2std", "core_scripts.f_var2std", "core_scripts.f_var2std", "core_scripts.f_var2std", "core_scripts.f_var2std", "core_scripts.f_var2std", "core_scripts.f_var2std", "core_scripts.f_var2std", "core_scripts.f_var2std", "default_data_io.NIIDataSet.f_length_data"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_precheck_data_length", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_log_seq_info", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_save_data_len", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_save_mean_std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.file_exist", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_log_data_len", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_online_mean_std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_online_mean_std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_online_mean_std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_online_mean_std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_online_mean_std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_online_mean_std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_online_mean_std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_online_mean_std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_online_mean_std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_online_mean_std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_online_mean_std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std"], ["", "def", "f_calculate_stats", "(", "self", ",", "flag_cal_data_len", ",", "flag_cal_mean_std", ")", ":", "\n", "        ", "\"\"\" f_calculate_stats\n        Log down the number of time steps for each file\n        Calculate the mean/std\n        \"\"\"", "\n", "# check", "\n", "#if not self.m_output_dirs:", "\n", "#    nii_warn.f_print(\"Calculating mean/std\", 'error')", "\n", "#    nii_warn.f_die(\"But output_dirs is not provided\")", "\n", "\n", "# prepare the directory, extension, and dimensions", "\n", "tmp_dirs", "=", "self", ".", "m_input_dirs", ".", "copy", "(", ")", "\n", "tmp_exts", "=", "self", ".", "m_input_exts", ".", "copy", "(", ")", "\n", "tmp_dims", "=", "self", ".", "m_input_dims", ".", "copy", "(", ")", "\n", "tmp_reso", "=", "self", ".", "m_input_reso", ".", "copy", "(", ")", "\n", "tmp_norm", "=", "self", ".", "m_input_norm", ".", "copy", "(", ")", "\n", "tmp_dirs", ".", "extend", "(", "self", ".", "m_output_dirs", ")", "\n", "tmp_exts", ".", "extend", "(", "self", ".", "m_output_exts", ")", "\n", "tmp_dims", ".", "extend", "(", "self", ".", "m_output_dims", ")", "\n", "tmp_reso", ".", "extend", "(", "self", ".", "m_output_reso", ")", "\n", "tmp_norm", ".", "extend", "(", "self", ".", "m_output_norm", ")", "\n", "\n", "# starting dimension of one type of feature", "\n", "s_dim", "=", "0", "\n", "# ending dimension of one type of feature        ", "\n", "e_dim", "=", "0", "\n", "\n", "# loop over each input/output feature type", "\n", "for", "t_dir", ",", "t_ext", ",", "t_dim", ",", "t_reso", ",", "t_norm", "in", "zip", "(", "tmp_dirs", ",", "tmp_exts", ",", "tmp_dims", ",", "tmp_reso", ",", "tmp_norm", ")", ":", "\n", "\n", "            ", "s_dim", "=", "e_dim", "\n", "e_dim", "=", "s_dim", "+", "t_dim", "\n", "t_cnt", "=", "0", "\n", "mean_i", ",", "var_i", "=", "np", ".", "zeros", "(", "[", "t_dim", "]", ")", ",", "np", ".", "zeros", "(", "[", "t_dim", "]", ")", "\n", "\n", "# loop over all the data", "\n", "for", "file_name", "in", "self", ".", "m_file_list", ":", "\n", "# get file path", "\n", "                ", "file_path", "=", "nii_str_tk", ".", "f_realpath", "(", "t_dir", ",", "file_name", ",", "t_ext", ")", "\n", "if", "not", "nii_io_tk", ".", "file_exist", "(", "file_path", ")", ":", "\n", "                    ", "nii_warn", ".", "f_die", "(", "\"%s not found\"", "%", "(", "file_path", ")", ")", "\n", "\n", "# read the length of the data", "\n", "", "if", "flag_cal_data_len", ":", "\n", "                    ", "t_len", "=", "self", ".", "f_length_data", "(", "file_path", ")", "//", "t_dim", "\n", "self", ".", "f_log_data_len", "(", "file_name", ",", "t_len", ",", "t_reso", ")", "\n", "\n", "\n", "# accumulate the mean/std recursively", "\n", "", "if", "flag_cal_mean_std", ":", "\n", "                    ", "t_data", "=", "self", ".", "f_load_data", "(", "file_path", ",", "t_dim", ")", "\n", "\n", "# if the is F0 data, only consider voiced data", "\n", "if", "t_ext", "in", "nii_dconf", ".", "f0_unvoiced_dic", ":", "\n", "                        ", "unvoiced_value", "=", "nii_dconf", ".", "f0_unvoiced_dic", "[", "t_ext", "]", "\n", "t_data", "=", "t_data", "[", "t_data", ">", "unvoiced_value", "]", "\n", "# mean_i, var_i, t_cnt will be updated using online", "\n", "# accumulation method", "\n", "", "mean_i", ",", "var_i", ",", "t_cnt", "=", "nii_stats", ".", "f_online_mean_std", "(", "\n", "t_data", ",", "mean_i", ",", "var_i", ",", "t_cnt", ")", "\n", "\n", "# save mean and std for one feature type", "\n", "", "", "if", "flag_cal_mean_std", ":", "\n", "# if not normalize this dimension, set mean=0, std=1", "\n", "                ", "if", "not", "t_norm", ":", "\n", "                    ", "mean_i", "[", ":", "]", "=", "0", "\n", "var_i", "[", ":", "]", "=", "1", "\n", "\n", "", "if", "s_dim", "<", "self", ".", "m_input_all_dim", ":", "\n", "                    ", "self", ".", "m_input_mean", "[", "s_dim", ":", "e_dim", "]", "=", "mean_i", "\n", "\n", "std_i", "=", "nii_stats", ".", "f_var2std", "(", "var_i", ")", "\n", "self", ".", "m_input_std", "[", "s_dim", ":", "e_dim", "]", "=", "std_i", "\n", "", "else", ":", "\n", "                    ", "tmp_s", "=", "s_dim", "-", "self", ".", "m_input_all_dim", "\n", "tmp_e", "=", "e_dim", "-", "self", ".", "m_input_all_dim", "\n", "self", ".", "m_output_mean", "[", "tmp_s", ":", "tmp_e", "]", "=", "mean_i", "\n", "std_i", "=", "nii_stats", ".", "f_var2std", "(", "var_i", ")", "\n", "self", ".", "m_output_std", "[", "tmp_s", ":", "tmp_e", "]", "=", "std_i", "\n", "\n", "", "", "", "if", "flag_cal_data_len", ":", "\n", "# ", "\n", "            ", "self", ".", "f_precheck_data_length", "(", ")", "\n", "# create seq_info", "\n", "self", ".", "f_log_seq_info", "(", ")", "\n", "# save len information", "\n", "self", ".", "f_save_data_len", "(", "self", ".", "m_data_len_path", ")", "\n", "\n", "", "if", "flag_cal_mean_std", ":", "\n", "            ", "self", ".", "f_save_mean_std", "(", "self", ".", "m_ms_input_path", ",", "\n", "self", ".", "m_ms_output_path", ")", "\n", "# done", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_putitem": [[966, 1010], ["core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo", "core_scripts.SeqInfo.parse_from_str", "core_scripts.SeqInfo.seq_tag", "zip", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "os.path.isdir", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "core_scripts.f_realpath", "default_data_io.NIIDataSet.f_write_data", "numpy.expand_dims", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "os.mkdir", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.parse_from_str", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.seq_info.SeqInfo.seq_tag", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die"], ["", "def", "f_putitem", "(", "self", ",", "output_data", ",", "save_dir", ",", "data_infor_str", ")", ":", "\n", "        ", "\"\"\" \n        \"\"\"", "\n", "# Change the dimension to (length, dim)", "\n", "if", "output_data", ".", "ndim", "==", "3", "and", "output_data", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "# When input data is (batchsize=1, length, dim)", "\n", "            ", "output_data", "=", "output_data", "[", "0", "]", "\n", "", "elif", "output_data", ".", "ndim", "==", "2", "and", "output_data", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "# When input data is (batchsize=1, length)", "\n", "            ", "output_data", "=", "np", ".", "expand_dims", "(", "output_data", "[", "0", "]", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "nii_warn", ".", "f_print", "(", "\"Output data format not supported.\"", ",", "\"error\"", ")", "\n", "nii_warn", ".", "f_print", "(", "\"Format is not (batch, len, dim)\"", ",", "\"error\"", ")", "\n", "nii_warn", ".", "f_die", "(", "\"Please use batch_size = 1 in generation\"", ")", "\n", "\n", "# Save output", "\n", "", "if", "output_data", ".", "shape", "[", "1", "]", "!=", "self", ".", "m_output_all_dim", ":", "\n", "            ", "nii_warn", ".", "f_print", "(", "\"Output data dim != expected dim\"", ",", "\"error\"", ")", "\n", "nii_warn", ".", "f_print", "(", "\"Output:%d\"", "%", "(", "output_data", ".", "shape", "[", "1", "]", ")", ",", "\"error\"", ")", "\n", "nii_warn", ".", "f_print", "(", "\"Expected:%d\"", "%", "(", "self", ".", "m_output_all_dim", ")", ",", "\"error\"", ")", "\n", "nii_warn", ".", "f_die", "(", "\"Please check configuration\"", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_dir", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "os", ".", "mkdir", "(", "save_dir", ")", "\n", "", "except", "OSError", ":", "\n", "                ", "nii_warn", ".", "f_die", "(", "\"Cannot carete {}\"", ".", "format", "(", "save_dir", ")", ")", "\n", "\n", "# read the sentence information", "\n", "", "", "tmp_seq_info", "=", "nii_seqinfo", ".", "SeqInfo", "(", ")", "\n", "tmp_seq_info", ".", "parse_from_str", "(", "data_infor_str", ")", "\n", "\n", "# write the data", "\n", "file_name", "=", "tmp_seq_info", ".", "seq_tag", "(", ")", "\n", "s_dim", "=", "0", "\n", "e_dim", "=", "0", "\n", "for", "t_ext", ",", "t_dim", "in", "zip", "(", "self", ".", "m_output_exts", ",", "self", ".", "m_output_dims", ")", ":", "\n", "            ", "e_dim", "=", "s_dim", "+", "t_dim", "\n", "file_path", "=", "nii_str_tk", ".", "f_realpath", "(", "save_dir", ",", "file_name", ",", "t_ext", ")", "\n", "self", ".", "f_write_data", "(", "output_data", "[", ":", ",", "s_dim", ":", "e_dim", "]", ",", "file_path", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_input_dim": [[1011, 1017], ["None"], "methods", ["None"], ["", "def", "f_input_dim", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        f_input_dim()\n        return the total dimension of input features\n        \"\"\"", "\n", "return", "self", ".", "m_input_all_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_output_dim": [[1018, 1024], ["None"], "methods", ["None"], ["", "def", "f_output_dim", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        f_output_dim\n        return the total dimension of output features\n        \"\"\"", "\n", "return", "self", ".", "m_output_all_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_adjust_idx": [[1025, 1039], ["numpy.arange", "len"], "methods", ["None"], ["", "def", "f_adjust_idx", "(", "self", ",", "data_tuple", ",", "idx_shift", ")", ":", "\n", "        ", "\"\"\"\n        f_adjust_idx\n\n        This is to be used by customize_dataset for idx adjustment.\n        When multiple data sets are merged, the idx from __getitem__\n        should be adjusted.\n\n        Only data_io itselts knows how to identify idx from the output of\n        __getitem__, we need to define the function here\n        \"\"\"", "\n", "for", "idx", "in", "np", ".", "arange", "(", "len", "(", "data_tuple", "[", "-", "1", "]", ")", ")", ":", "\n", "            ", "data_tuple", "[", "-", "1", "]", "[", "idx", "]", "+=", "idx_shift", "\n", "", "return", "data_tuple", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.__init__": [[1047, 1180], ["core_scripts.f_print_w_date", "core_scripts.f_print_w_date", "core_scripts.f_print_w_date", "core_scripts.f_print_w_date", "core_scripts.f_print_w_date", "core_scripts.f_print_w_date", "core_scripts.f_print_w_date", "core_scripts.f_print_w_date", "core_scripts.f_print_w_date", "core_scripts.f_print_w_date", "core_scripts.f_print_w_date", "default_data_io.NIIDataSet", "params.copy.copy", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "params.copy", "core_scripts.SamplerBlockShuffleByLen", "core_scripts.SamplerBlockShuffleByLen", "core_scripts.SamplerBlockShuffleByLen", "core_scripts.SamplerBlockShuffleByLen", "core_scripts.SamplerBlockShuffleByLen", "core_scripts.SamplerBlockShuffleByLen", "core_scripts.SamplerBlockShuffleByLen", "core_scripts.SamplerBlockShuffleByLen", "core_scripts.SamplerBlockShuffleByLen", "core_scripts.SamplerBlockShuffleByLen", "core_scripts.SamplerBlockShuffleByLen", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "default_data_io.NIIDataSetLoader.m_dataset.f_get_seq_len_list"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_w_date", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_w_date", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_w_date", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_w_date", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_w_date", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_w_date", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_w_date", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_w_date", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_w_date", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_w_date", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_w_date", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_get_seq_len_list"], ["def", "__init__", "(", "self", ",", "\n", "dataset_name", ",", "file_list", ",", "input_dirs", ",", "input_exts", ",", "input_dims", ",", "input_reso", ",", "input_norm", ",", "output_dirs", ",", "output_exts", ",", "output_dims", ",", "output_reso", ",", "output_norm", ",", "stats_path", ",", "data_format", "=", "nii_dconf", ".", "h_dtype_str", ",", "params", "=", "None", ",", "truncate_seq", "=", "None", ",", "min_seq_len", "=", "None", ",", "\n", "save_mean_std", "=", "True", ",", "wav_samp_rate", "=", "None", ",", "flag_lang", "=", "'EN'", ",", "\n", "global_arg", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        NIIDataSetLoader(\n               data_set_name,\n               file_list,\n               input_dirs, input_exts, input_dims, input_reso, input_norm,\n               output_dirs, output_exts, output_dims, output_reso, output_norm,\n               stats_path,\n               data_format = '<f4',\n               params = None,\n               truncate_seq = None,\n               min_seq_len = None,\n               save_mean_std = True, \\\n               wav_samp_rate = None, \\\n               flag_lang = 'EN',\n               global_arg = None):\n        Args\n        ----\n            data_set_name: a string to name this dataset\n                           this will be used to name the statistics files\n                           such as the mean/std for this dataset\n            file_list: a list of file name strings (without extension)\n                     or, path to the file that contains the file names\n            input_dirs: a list of dirs from which input feature is loaded\n            input_exts: a list of input feature name extentions\n            input_dims: a list of input feature dimensions\n            input_reso: a list of input feature temporal resolution,\n                        or None\n            input_norm: a list of bool, whether normalize input feature or not\n\n            output_dirs: a list of dirs from which output feature is loaded\n            output_exts: a list of output feature name extentions\n            output_dims: a list of output feature dimensions\n            output_reso: a list of output feature temporal resolution, \n                         or None\n            output_norm: a list of bool, whether normalize target feature or not\n\n            stats_path: path to the directory of statistics(mean/std)\n            data_format: method to load the data\n                    '<f4' (default): load data as float32m little-endian\n                    'htk': load data as htk format\n            params: parameter for torch.utils.data.DataLoader\n\n            truncate_seq: None or int, \n                          truncate data sequence into smaller truncks\n                          truncate_seq > 0 specifies the trunck length\n            min_seq_len: None (default) or int, minimum length of an utterance\n                         utterance shorter than min_seq_len will be ignored\n            save_mean_std: bool, True (default): save mean and std \n            wav_samp_rate: None (default) or int, if input data has  waveform, \n                         please set sampling rate. It is used by _data_writer\n            flag_lang: str, 'EN' (default), if input data has text, text will\n                       be converted into code indices. flag_lang indicates the \n                       language for the text processer, used by _data_reader\n            global_arg: argument parser returned by arg_parse.f_args_parsed()\n                      default None\n        Methods\n        -------\n            get_loader(): return a torch.util.data.DataLoader\n            get_dataset(): return a torch.util.data.DataSet\n        \"\"\"", "\n", "nii_warn", ".", "f_print_w_date", "(", "\"Loading dataset %s\"", "%", "(", "dataset_name", ")", ",", "\n", "level", "=", "\"h\"", ")", "\n", "\n", "# create torch.util.data.DataSet", "\n", "self", ".", "m_dataset", "=", "NIIDataSet", "(", "dataset_name", ",", "file_list", ",", "input_dirs", ",", "input_exts", ",", "input_dims", ",", "input_reso", ",", "input_norm", ",", "output_dirs", ",", "output_exts", ",", "output_dims", ",", "output_reso", ",", "output_norm", ",", "stats_path", ",", "data_format", ",", "truncate_seq", ",", "min_seq_len", ",", "save_mean_std", ",", "wav_samp_rate", ",", "flag_lang", ",", "global_arg", ")", "\n", "\n", "# create torch.util.data.DataLoader", "\n", "if", "params", "is", "None", ":", "\n", "            ", "tmp_params", "=", "nii_dconf", ".", "default_loader_conf", "\n", "", "else", ":", "\n", "            ", "tmp_params", "=", "params", ".", "copy", "(", ")", "\n", "\n", "# save parameters", "\n", "", "self", ".", "m_params", "=", "tmp_params", ".", "copy", "(", ")", "\n", "\n", "# initialize sampler if necessary", "\n", "if", "'sampler'", "in", "tmp_params", ":", "\n", "            ", "tmp_sampler", "=", "None", "\n", "if", "tmp_params", "[", "'sampler'", "]", "==", "nii_sampler_fn", ".", "g_str_sampler_bsbl", ":", "\n", "                ", "if", "'batch_size'", "in", "tmp_params", ":", "\n", "# initialize the sampler", "\n", "                    ", "tmp_sampler", "=", "nii_sampler_fn", ".", "SamplerBlockShuffleByLen", "(", "\n", "self", ".", "m_dataset", ".", "f_get_seq_len_list", "(", ")", ",", "\n", "tmp_params", "[", "'batch_size'", "]", ")", "\n", "# turn off automatic shuffle", "\n", "tmp_params", "[", "'shuffle'", "]", "=", "False", "\n", "", "else", ":", "\n", "                    ", "nii_warn", ".", "f_die", "(", "\"Sampler requires batch size > 1\"", ")", "\n", "", "", "tmp_params", "[", "'sampler'", "]", "=", "tmp_sampler", "\n", "\n", "\n", "# collate function", "\n", "", "if", "'batch_size'", "in", "tmp_params", "and", "tmp_params", "[", "'batch_size'", "]", ">", "1", ":", "\n", "# for batch-size > 1, use customize_collate to handle", "\n", "# data with different length", "\n", "            ", "collate_fn", "=", "nii_collate_fn", ".", "customize_collate", "\n", "", "else", ":", "\n", "            ", "collate_fn", "=", "None", "\n", "\n", "", "self", ".", "m_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "self", ".", "m_dataset", ",", "collate_fn", "=", "collate_fn", ",", "**", "tmp_params", ")", "\n", "\n", "# done", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_loader_params": [[1181, 1183], ["None"], "methods", ["None"], ["", "def", "get_loader_params", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "m_params", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_loader": [[1184, 1189], ["None"], "methods", ["None"], ["", "def", "get_loader", "(", "self", ")", ":", "\n", "        ", "\"\"\" get_loader():\n        Return the dataLoader (torch.util.data.DataLoader)\n        \"\"\"", "\n", "return", "self", ".", "m_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_dataset": [[1190, 1195], ["None"], "methods", ["None"], ["", "def", "get_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\" get_dataset():\n        Return the dataset (torch.util.data.Dataset)\n        \"\"\"", "\n", "return", "self", ".", "m_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_data_mean_std": [[1196, 1200], ["default_data_io.NIIDataSetLoader.m_dataset.f_get_mean_std_tuple"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_get_mean_std_tuple"], ["", "def", "get_data_mean_std", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "return", "self", ".", "m_dataset", ".", "f_get_mean_std_tuple", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.print_info": [[1201, 1207], ["default_data_io.NIIDataSetLoader.m_dataset.f_print_info", "print", "str"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_print_info"], ["", "def", "print_info", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "self", ".", "m_dataset", ".", "f_print_info", "(", ")", "\n", "print", "(", "str", "(", "self", ".", "m_params", ")", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.putitem": [[1208, 1213], ["default_data_io.NIIDataSetLoader.m_dataset.f_putitem"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_putitem"], ["", "def", "putitem", "(", "self", ",", "output_data", ",", "save_dir", ",", "data_infor_str", ")", ":", "\n", "        ", "\"\"\" Decompose the output_data from network into\n        separate files\n        \"\"\"", "\n", "self", ".", "m_dataset", ".", "f_putitem", "(", "output_data", ",", "save_dir", ",", "data_infor_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_in_dim": [[1214, 1218], ["default_data_io.NIIDataSetLoader.m_dataset.f_input_dim"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_input_dim"], ["", "def", "get_in_dim", "(", "self", ")", ":", "\n", "        ", "\"\"\" Return the dimension of input features\n        \"\"\"", "\n", "return", "self", ".", "m_dataset", ".", "f_input_dim", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_out_dim": [[1219, 1223], ["default_data_io.NIIDataSetLoader.m_dataset.f_output_dim"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_output_dim"], ["", "def", "get_out_dim", "(", "self", ")", ":", "\n", "        ", "\"\"\" Return the dimension of output features\n        \"\"\"", "\n", "return", "self", ".", "m_dataset", ".", "f_output_dim", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_seq_num": [[1224, 1228], ["default_data_io.NIIDataSetLoader.m_dataset.f_get_num_seq"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_get_num_seq"], ["", "def", "get_seq_num", "(", "self", ")", ":", "\n", "        ", "\"\"\" Return the number of sequences (after truncation)\n        \"\"\"", "\n", "return", "self", ".", "m_dataset", ".", "f_get_num_seq", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.adjust_utt_idx": [[1229, 1235], ["default_data_io.NIIDataSetLoader.m_dataset.f_adjust_idx"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSet.f_adjust_idx"], ["", "def", "adjust_utt_idx", "(", "self", ",", "data_tuple", ",", "utt_idx_shift", ")", ":", "\n", "        ", "\"\"\" Return data tuple with adjusted utterance index in merged dataset\n        \n        This is used by customize_dataset.\n        \"\"\"", "\n", "return", "self", ".", "m_dataset", ".", "f_adjust_idx", "(", "data_tuple", ",", "utt_idx_shift", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io._data_reader": [[36, 47], ["os.path.splitext", "core_scripts.waveReadAsFloat", "core_scripts.textloader", "core_scripts.f_read_raw_mat"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.waveReadAsFloat", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.text_io.textloader", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.f_read_raw_mat"], ["def", "_data_reader", "(", "file_path", ",", "dim", ",", "flag_lang", ")", ":", "\n", "    ", "\"\"\" A wrapper to read raw binary data, waveform, or text\n    \"\"\"", "\n", "file_name", ",", "file_ext", "=", "os", ".", "path", ".", "splitext", "(", "file_path", ")", "\n", "if", "file_ext", "==", "'.wav'", ":", "\n", "        ", "sr", ",", "data", "=", "nii_wav_tk", ".", "waveReadAsFloat", "(", "file_path", ")", "\n", "", "elif", "file_ext", "==", "'.txt'", ":", "\n", "        ", "data", "=", "nii_text_tk", ".", "textloader", "(", "file_path", ",", "flag_lang", ")", "\n", "", "else", ":", "\n", "        ", "data", "=", "nii_io_tk", ".", "f_read_raw_mat", "(", "file_path", ",", "dim", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io._data_writer": [[48, 59], ["os.path.splitext", "core_scripts.waveFloatToPCMFile", "core_scripts.f_die", "core_scripts.f_write_raw_mat"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.waveFloatToPCMFile", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.f_write_raw_mat"], ["", "def", "_data_writer", "(", "data", ",", "file_path", ",", "sr", "=", "16000", ")", ":", "\n", "    ", "\"\"\" A wrapper to write raw binary data or waveform\n    \"\"\"", "\n", "file_name", ",", "file_ext", "=", "os", ".", "path", ".", "splitext", "(", "file_path", ")", "\n", "if", "file_ext", "==", "'.wav'", ":", "\n", "        ", "nii_wav_tk", ".", "waveFloatToPCMFile", "(", "data", ",", "file_path", ",", "sr", "=", "sr", ")", "\n", "", "elif", "file_ext", "==", "'.txt'", ":", "\n", "        ", "nii_warn", ".", "f_die", "(", "\"Cannot write to %s\"", "%", "(", "file_path", ")", ")", "\n", "", "else", ":", "\n", "        ", "nii_io_tk", ".", "f_write_raw_mat", "(", "data", ",", "file_path", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io._data_len_reader": [[60, 74], ["os.path.splitext", "core_scripts.waveReadAsFloat", "core_scripts.f_read_raw_mat_length"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.wav_tools.waveReadAsFloat", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.f_read_raw_mat_length"], ["", "def", "_data_len_reader", "(", "file_path", ")", ":", "\n", "    ", "\"\"\" A wrapper to read length of data\n    \"\"\"", "\n", "file_name", ",", "file_ext", "=", "os", ".", "path", ".", "splitext", "(", "file_path", ")", "\n", "if", "file_ext", "==", "'.wav'", ":", "\n", "        ", "sr", ",", "data", "=", "nii_wav_tk", ".", "waveReadAsFloat", "(", "file_path", ")", "\n", "length", "=", "data", ".", "shape", "[", "0", "]", "\n", "", "elif", "file_ext", "==", "'.txt'", ":", "\n", "# txt, no need to account length", "\n", "# note that this is for tts task", "\n", "        ", "length", "=", "0", "\n", "", "else", ":", "\n", "        ", "length", "=", "nii_io_tk", ".", "f_read_raw_mat_length", "(", "file_path", ")", "\n", "", "return", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.text_io.text2code": [[24, 54], ["core_scripts.data_io.text_process.toolkit_all.parse_curly_bracket", "numpy.array", "core_scripts.other_tools.display.f_die", "core_scripts.data_io.text_process.toolkit_en.text2code"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_all.parse_curly_bracket", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.text2code"], ["def", "text2code", "(", "text", ",", "flag_lang", "=", "'EN'", ")", ":", "\n", "    ", "\"\"\" Convert text string into code indices\n    \n    input\n    -----\n      text: string\n      flag_lang: string, 'EN': English\n\n    output\n    ------\n      code_seq: list of integers\n    \"\"\"", "\n", "code_seq", "=", "[", "]", "\n", "\n", "# parse the curly bracket", "\n", "text_trunks", "=", "toolkit_all", ".", "parse_curly_bracket", "(", "text", ")", "\n", "\n", "# parse", "\n", "if", "flag_lang", "==", "'EN'", ":", "\n", "# English text", "\n", "        ", "for", "text_trunk", "in", "text_trunks", ":", "\n", "            ", "code_seq", "+=", "toolkit_en", ".", "text2code", "(", "text_trunk", ")", "\n", "", "", "else", ":", "\n", "# unsupporte languages", "\n", "        ", "nii_warn", ".", "f_die", "(", "\"Error: text2code cannot handle {:s}\"", ".", "format", "(", "flag_lang", ")", ")", "\n", "\n", "# convert to numpy format", "\n", "", "code_seq", "=", "np", ".", "array", "(", "code_seq", ",", "dtype", "=", "nii_dconf", ".", "h_dtype", ")", "\n", "\n", "return", "code_seq", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.text_io.code2text": [[55, 76], ["int", "core_scripts.data_io.text_process.toolkit_en.code2text", "core_scripts.other_tools.display.f_die"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.code2text", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die"], ["", "def", "code2text", "(", "codes", ",", "flag_lang", "=", "'EN'", ")", ":", "\n", "    ", "\"\"\" Convert text string into code indices\n    \n    input\n    -----\n      code_seq: numpy arrays of integers\n      flag_lang: string, 'EN': English\n\n    output\n    ------\n      text: string\n    \"\"\"", "\n", "# convert numpy array backto indices", "\n", "codes_tmp", "=", "[", "int", "(", "x", ")", "for", "x", "in", "codes", "]", "\n", "\n", "output_text", "=", "''", "\n", "if", "flag_lang", "==", "'EN'", ":", "\n", "        ", "output_text", "=", "toolkit_en", ".", "code2text", "(", "codes_tmp", ")", "\n", "", "else", ":", "\n", "        ", "nii_warn", ".", "f_die", "(", "\"Error: code2text cannot handle {:s}\"", ".", "format", "(", "flag_lang", ")", ")", "\n", "", "return", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.text_io.symbol_num": [[77, 93], ["core_scripts.data_io.text_process.toolkit_en.symbol_num", "core_scripts.other_tools.display.f_die"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.symbol_num", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die"], ["", "def", "symbol_num", "(", "flag_lang", "=", "'EN'", ")", ":", "\n", "    ", "\"\"\" Return the number of symbols defined for one language\n    \n    input\n    -----\n      flag_lange: string, 'EN': English\n\n    output\n    ------\n      integer\n    \"\"\"", "\n", "if", "flag_lang", "==", "'EN'", ":", "\n", "        ", "return", "toolkit_en", ".", "symbol_num", "(", ")", "\n", "", "else", ":", "\n", "        ", "nii_warn", ".", "f_die", "(", "\"Error: symbol_num cannot handle {:s}\"", ".", "format", "(", "flag_lang", ")", ")", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.text_io.textloader": [[94, 111], ["text_io.text2code", "core_scripts.other_tools.str_tools.string_chop", "open"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.text2code", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.string_chop"], ["", "def", "textloader", "(", "file_path", ",", "flag_lang", "=", "'EN'", ")", ":", "\n", "    ", "\"\"\" Load text and return the sybmol sequences\n    input\n    -----\n      file_path: string, absolute path to the text file\n      flag_lang: string, 'EN' by default, the language option to process text\n    \n    output\n    ------\n      output: np.array of shape (L), where L is the number of chars \n    \"\"\"", "\n", "# load lines and chop '\\n', join into one line", "\n", "text_buffer", "=", "[", "nii_str_tk", ".", "string_chop", "(", "x", ")", "for", "x", "in", "open", "(", "file_path", ",", "'r'", ")", "]", "\n", "text_buffer", "=", "' '", ".", "join", "(", "text_buffer", ")", "\n", "\n", "# convert to indices", "\n", "return", "text2code", "(", "text_buffer", ",", "flag_lang", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.symbol_num": [[55, 57], ["len"], "function", ["None"], ["def", "symbol_num", "(", ")", ":", "\n", "    ", "return", "len", "(", "_symbols", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.symbol2index": [[58, 60], ["None"], "function", ["None"], ["", "def", "symbol2index", "(", "x", ")", ":", "\n", "    ", "return", "_symbol_to_index", "[", "x", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.index2symbol": [[61, 63], ["None"], "function", ["None"], ["", "def", "index2symbol", "(", "x", ")", ":", "\n", "    ", "return", "_symbols", "[", "x", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.text_numbers": [[75, 87], ["text.startswith", "all", "toolkit_en.text_numbers._tmp"], "function", ["None"], ["def", "text_numbers", "(", "text", ")", ":", "\n", "    ", "\"\"\" Place holder, just convert individual number to alphabet\n    \"\"\"", "\n", "def", "_tmp", "(", "tmp_text", ")", ":", "\n", "        ", "if", "all", "(", "[", "x", "in", "_number_map", "for", "x", "in", "tmp_text", "]", ")", ":", "\n", "            ", "return", "' '", ".", "join", "(", "[", "_number_map", "[", "x", "]", "for", "x", "in", "tmp_text", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "tmp_text", "\n", "", "", "tmp", "=", "' '", ".", "join", "(", "[", "_tmp", "(", "x", ")", "for", "x", "in", "text", ".", "split", "(", ")", "]", ")", "\n", "if", "text", ".", "startswith", "(", "' '", ")", ":", "\n", "        ", "tmp", "=", "' '", "+", "tmp", "\n", "", "return", "tmp", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.text_case_convert": [[88, 92], ["text.lower"], "function", ["None"], ["", "def", "text_case_convert", "(", "text", ")", ":", "\n", "    ", "\"\"\" By default, use lower case\n    \"\"\"", "\n", "return", "text", ".", "lower", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.text_whitespace_convert": [[93, 98], ["re.sub"], "function", ["None"], ["", "def", "text_whitespace_convert", "(", "text", ")", ":", "\n", "    ", "\"\"\" Collapse all redundant white spaces\n    e.g., 'qweq 1231   123151' -> 'qweq 1231 123151'\n    \"\"\"", "\n", "return", "re", ".", "sub", "(", "_whitespace_re", ",", "' '", ",", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.text_normalizer": [[99, 105], ["toolkit_en.text_whitespace_convert", "toolkit_en.text_numbers", "toolkit_en.text_case_convert"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.text_whitespace_convert", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.text_numbers", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.text_case_convert"], ["", "def", "text_normalizer", "(", "text", ")", ":", "\n", "    ", "\"\"\" Text normalizer\n\n    In this code, only lower case conversion and white space is handled\n    \"\"\"", "\n", "return", "text_whitespace_convert", "(", "text_numbers", "(", "text_case_convert", "(", "text", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.flag_convert_symbol": [[111, 123], ["None"], "function", ["None"], ["", "def", "flag_convert_symbol", "(", "symbol", ")", ":", "\n", "    ", "\"\"\" check whether input symbol should be converted or not\n\n    input\n    -----\n      symbol: str\n    \n    output\n    ------\n      bool\n    \"\"\"", "\n", "return", "symbol", "in", "_symbol_to_index", "and", "symbol", "not", "in", "_skip_symbols", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.rawtext2indices": [[124, 138], ["toolkit_en.symbol2index", "toolkit_en.flag_convert_symbol"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.symbol2index", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.flag_convert_symbol"], ["", "def", "rawtext2indices", "(", "text", ")", ":", "\n", "    ", "\"\"\" Look up the table and return the index for input symbol in input text\n    \n    input\n    -----\n      text: str\n    \n    output\n    ------\n      list of indices\n\n    for example, 'text' -> [23, 16, 28, 23]\n    \"\"\"", "\n", "return", "[", "symbol2index", "(", "x", ")", "for", "x", "in", "text", "if", "flag_convert_symbol", "(", "x", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.arpabet2indices": [[139, 154], ["toolkit_en.symbol2index", "arpa_text.split", "toolkit_en.flag_convert_symbol"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.symbol2index", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.flag_convert_symbol"], ["", "def", "arpabet2indices", "(", "arpa_text", ")", ":", "\n", "    ", "\"\"\" Look up the table and return the index for input symbol in input text\n\n    input\n    -----\n      arpa_text: str\n    \n    output\n    ------\n      list of indices\n\n    for example, 'AH HH' -> [12 19]\n    \"\"\"", "\n", "tmp", "=", "[", "_arpabet_symbol_marker", "+", "x", "for", "x", "in", "arpa_text", ".", "split", "(", ")", "]", "\n", "return", "[", "symbol2index", "(", "x", ")", "for", "x", "in", "tmp", "if", "flag_convert_symbol", "(", "x", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.text2code": [[160, 171], ["text.startswith", "toolkit_en.arpabet2indices", "toolkit_en.text_normalizer", "toolkit_en.rawtext2indices", "text.lstrip"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.arpabet2indices", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.text_normalizer", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.rawtext2indices"], ["", "def", "text2code", "(", "text", ")", ":", "\n", "    ", "\"\"\" Convert English text and ARPAbet into code symbols (int)\n    \"\"\"", "\n", "if", "text", ".", "startswith", "(", "toolkit_all", ".", "_curly_symbol", ")", ":", "\n", "# phonemic annotation, no normalization", "\n", "        ", "return", "arpabet2indices", "(", "text", ".", "lstrip", "(", "toolkit_all", ".", "_curly_symbol", ")", ")", "\n", "", "else", ":", "\n", "# normal text, do normalization before conversion", "\n", "# text normalization", "\n", "        ", "text_normalized", "=", "text_normalizer", "(", "text", ")", "\n", "return", "rawtext2indices", "(", "text_normalized", ")", "\n", "# done", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.code2text": [[173, 178], ["toolkit_en.text_whitespace_convert", "toolkit_en.index2symbol", "txt_tmp.replace"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.text_whitespace_convert", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_en.index2symbol"], ["", "", "def", "code2text", "(", "codes", ")", ":", "\n", "# x-1 because  _symbol_to_index", "\n", "    ", "txt_tmp", "=", "[", "index2symbol", "(", "x", ")", "for", "x", "in", "codes", "]", "\n", "txt_tmp", "=", "''", ".", "join", "(", "txt_tmp", ")", "\n", "return", "text_whitespace_convert", "(", "txt_tmp", ".", "replace", "(", "_arpabet_symbol_marker", ",", "' '", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.text_process.toolkit_all.parse_curly_bracket": [[26, 59], ["len", "_curly_re.match", "text_list.append", "text_list.append", "_curly_re.match.group", "text_list.append", "_curly_re.match.group", "_curly_re.match.group"], "function", ["None"], ["def", "parse_curly_bracket", "(", "text", ")", ":", "\n", "    ", "\"\"\" Prase the text based on curly brackets\n    Inspired by https://github.com/fatchord/WaveRNN: when input text\n    is mixed with raw text and phonemic annotation, the {} pair indicates\n    the phonemic part\n    \n    input\n    -----\n      text: str\n    \n    output\n    ------\n      text_list: list of str\n\n    For example, 'text {AH II} test' -> ['text ', 'AH II', ' test']\n    \"\"\"", "\n", "text_list", "=", "[", "]", "\n", "text_tmp", "=", "text", "\n", "\n", "while", "len", "(", "text_tmp", ")", ":", "\n", "        ", "re_matched", "=", "_curly_re", ".", "match", "(", "text_tmp", ")", "\n", "\n", "if", "re_matched", ":", "\n", "# e.g., 'text {AH II} test'", "\n", "# group(1), group(2) -> ['text ', 'AH II']", "\n", "            ", "text_list", ".", "append", "(", "re_matched", ".", "group", "(", "1", ")", ")", "\n", "text_list", ".", "append", "(", "_curly_symbol", "+", "re_matched", ".", "group", "(", "2", ")", ")", "\n", "# group(3) -> ' test'", "\n", "text_tmp", "=", "re_matched", ".", "group", "(", "3", ")", "\n", "", "else", ":", "\n", "            ", "text_list", ".", "append", "(", "text_tmp", ")", "\n", "break", "\n", "", "", "return", "text_list", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_GAN.f_run_one_epoch_GAN": [[33, 205], ["time.time", "enumerate", "isinstance", "data_in.to.to", "pt_model_D.zero_grad", "pt_model_D", "loss_wrapper.compute_gan_D_real", "pt_model_D", "loss_wrapper.compute_gan_D_fake", "pt_model_G.zero_grad", "pt_model_D", "loss_wrapper.compute_gan_G", "hasattr", "hasattr", "core_scripts.f_process_loss", "time.time", "len", "enumerate", "time.time", "optimizer_G.zero_grad", "optimizer_D.zero_grad", "data_tar.to.to", "core_scripts.f_die", "loss_wrapper.compute_gan_D_real.backward", "isinstance", "pt_model_G.detach", "loss_wrapper.compute_gan_D_fake.backward", "optimizer_D.step", "loss_wrapper.compute_aux", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "loss_wrapper.compute_feat_match", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "errG.backward", "optimizer_G.step", "monitor.log_loss", "pt_model_G.normalize_target", "target_norm_method", "data_tar.to.to", "core_scripts.f_print", "core_scripts.f_die", "pt_model_G", "pt_model_G", "monitor.print_error_for_batch", "pt_model_G", "pt_model_G", "idx_orig.numpy", "idx_orig.numpy"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_process_loss", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.log_loss", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.print_error_for_batch"], ["def", "f_run_one_epoch_GAN", "(", "\n", "args", ",", "pt_model_G", ",", "pt_model_D", ",", "\n", "loss_wrapper", ",", "device", ",", "monitor", ",", "data_loader", ",", "epoch_idx", ",", "\n", "optimizer_G", "=", "None", ",", "optimizer_D", "=", "None", ",", "target_norm_method", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    f_run_one_epoch_GAN: \n       run one poech over the dataset (for training or validation sets)\n\n    Args:\n       args:         from argpase\n       pt_model_G:   pytorch model (torch.nn.Module) generator\n       pt_model_D:   pytorch model (torch.nn.Module) discriminator\n       loss_wrapper: a wrapper over loss function\n                     loss_wrapper.compute(generated, target) \n       device:       torch.device(\"cuda\") or torch.device(\"cpu\")\n       monitor:      defined in op_procfess_monitor.py\n       data_loader:  pytorch DataLoader. \n       epoch_idx:    int, index of the current epoch\n       optimizer_G:  torch optimizer or None, for generator\n       optimizer_D:  torch optimizer or None, for discriminator\n                     if None, the back propgation will be skipped\n                     (for developlement set)\n       target_norm_method: method to normalize target data\n                           (by default, use pt_model.normalize_target)\n    \"\"\"", "\n", "# timer", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# loop over samples", "\n", "for", "data_idx", ",", "(", "data_in", ",", "data_tar", ",", "data_info", ",", "idx_orig", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "\n", "#############", "\n", "# prepare", "\n", "#############        ", "\n", "# send data to device", "\n", "        ", "if", "optimizer_G", "is", "not", "None", ":", "\n", "            ", "optimizer_G", ".", "zero_grad", "(", ")", "\n", "", "if", "optimizer_D", "is", "not", "None", ":", "\n", "            ", "optimizer_D", ".", "zero_grad", "(", ")", "\n", "\n", "# normalize the target data (for input for discriminator)", "\n", "", "if", "isinstance", "(", "data_tar", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "data_tar", "=", "data_tar", ".", "to", "(", "device", ",", "dtype", "=", "nii_dconf", ".", "d_dtype", ")", "\n", "# there is no way to normalize the data inside loss", "\n", "# thus, do normalization here", "\n", "if", "target_norm_method", "is", "None", ":", "\n", "                ", "normed_target", "=", "pt_model_G", ".", "normalize_target", "(", "data_tar", ")", "\n", "", "else", ":", "\n", "                ", "normed_target", "=", "target_norm_method", "(", "data_tar", ")", "\n", "", "", "else", ":", "\n", "            ", "nii_display", ".", "f_die", "(", "\"target data is required\"", ")", "\n", "\n", "# to device (we assume noise will be generated by the model itself)", "\n", "# here we only provide external condition", "\n", "", "data_in", "=", "data_in", ".", "to", "(", "device", ",", "dtype", "=", "nii_dconf", ".", "d_dtype", ")", "\n", "\n", "############################", "\n", "# Update Discriminator", "\n", "############################        ", "\n", "####", "\n", "# train with real", "\n", "####", "\n", "pt_model_D", ".", "zero_grad", "(", ")", "\n", "d_out_real", "=", "pt_model_D", "(", "data_tar", ",", "data_in", ")", "\n", "errD_real", "=", "loss_wrapper", ".", "compute_gan_D_real", "(", "d_out_real", ")", "\n", "if", "optimizer_D", "is", "not", "None", ":", "\n", "            ", "errD_real", ".", "backward", "(", ")", "\n", "\n", "# this should be given by pt_model_D or loss wrapper", "\n", "#d_out_real_mean = d_out_real.mean()", "\n", "\n", "###", "\n", "# train with fake", "\n", "###", "\n", "#  generate sample", "\n", "", "if", "args", ".", "model_forward_with_target", ":", "\n", "# if model.forward requires (input, target) as arguments", "\n", "# for example, for auto-encoder & autoregressive model", "\n", "            ", "if", "isinstance", "(", "data_tar", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "data_tar_tm", "=", "data_tar", ".", "to", "(", "device", ",", "dtype", "=", "nii_dconf", ".", "d_dtype", ")", "\n", "if", "args", ".", "model_forward_with_file_name", ":", "\n", "                    ", "data_gen", "=", "pt_model_G", "(", "data_in", ",", "data_tar_tm", ",", "data_info", ")", "\n", "", "else", ":", "\n", "                    ", "data_gen", "=", "pt_model_G", "(", "data_in", ",", "data_tar_tm", ")", "\n", "", "", "else", ":", "\n", "                ", "nii_display", ".", "f_print", "(", "\"--model-forward-with-target is set\"", ")", "\n", "nii_display", ".", "f_die", "(", "\"but data_tar is not loaded\"", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "args", ".", "model_forward_with_file_name", ":", "\n", "# specifcal case when model.forward requires data_info", "\n", "                ", "data_gen", "=", "pt_model_G", "(", "data_in", ",", "data_info", ")", "\n", "", "else", ":", "\n", "# normal case for model.forward(input)", "\n", "                ", "data_gen", "=", "pt_model_G", "(", "data_in", ")", "\n", "\n", "# data_gen.detach() is required", "\n", "#  https://github.com/pytorch/examples/issues/116", "\n", "#  https://stackoverflow.com/questions/46774641/", "\n", "", "", "d_out_fake", "=", "pt_model_D", "(", "data_gen", ".", "detach", "(", ")", ",", "data_in", ")", "\n", "errD_fake", "=", "loss_wrapper", ".", "compute_gan_D_fake", "(", "d_out_fake", ")", "\n", "if", "optimizer_D", "is", "not", "None", ":", "\n", "            ", "errD_fake", ".", "backward", "(", ")", "\n", "\n", "# get the summed error for discrminator (only for displaying)", "\n", "", "errD", "=", "errD_real", "+", "errD_fake", "\n", "\n", "# update discriminator weight", "\n", "if", "optimizer_D", "is", "not", "None", ":", "\n", "            ", "optimizer_D", ".", "step", "(", ")", "\n", "\n", "############################", "\n", "# Update Generator ", "\n", "############################", "\n", "", "pt_model_G", ".", "zero_grad", "(", ")", "\n", "d_out_fake_for_G", "=", "pt_model_D", "(", "data_gen", ",", "data_in", ")", "\n", "errG_gan", "=", "loss_wrapper", ".", "compute_gan_G", "(", "d_out_fake_for_G", ")", "\n", "\n", "# if defined, calculate auxilliart loss", "\n", "if", "hasattr", "(", "loss_wrapper", ",", "\"compute_aux\"", ")", ":", "\n", "            ", "errG_aux", "=", "loss_wrapper", ".", "compute_aux", "(", "data_gen", ",", "data_tar", ")", "\n", "", "else", ":", "\n", "            ", "errG_aux", "=", "torch", ".", "zeros_like", "(", "errG_gan", ")", "\n", "\n", "# if defined, calculate feat-matching loss", "\n", "", "if", "hasattr", "(", "loss_wrapper", ",", "\"compute_feat_match\"", ")", ":", "\n", "            ", "errG_feat", "=", "loss_wrapper", ".", "compute_feat_match", "(", "\n", "d_out_real", ",", "d_out_fake_for_G", ")", "\n", "", "else", ":", "\n", "            ", "errG_feat", "=", "torch", ".", "zeros_like", "(", "errG_gan", ")", "\n", "\n", "# sum loss for generator", "\n", "", "errG", "=", "errG_gan", "+", "errG_aux", "+", "errG_feat", "\n", "\n", "if", "optimizer_G", "is", "not", "None", ":", "\n", "            ", "errG", ".", "backward", "(", ")", "\n", "optimizer_G", ".", "step", "(", ")", "\n", "\n", "# construct the loss for logging and early stopping ", "\n", "# only use errG_aux for early-stopping", "\n", "", "loss_computed", "=", "[", "\n", "[", "errG_aux", ",", "errD_real", ",", "errD_fake", ",", "errG_gan", ",", "errG_feat", "]", ",", "\n", "[", "True", ",", "False", ",", "False", ",", "False", ",", "False", "]", "]", "\n", "\n", "# to handle cases where there are multiple loss functions", "\n", "_", ",", "loss_vals", ",", "loss_flags", "=", "nii_nn_tools", ".", "f_process_loss", "(", "loss_computed", ")", "\n", "\n", "# save the training process information to the monitor", "\n", "end_time", "=", "time", ".", "time", "(", ")", "\n", "batchsize", "=", "len", "(", "data_info", ")", "\n", "for", "idx", ",", "data_seq_info", "in", "enumerate", "(", "data_info", ")", ":", "\n", "# loss_value is supposed to be the average loss value", "\n", "# over samples in the the batch, thus, just loss_value", "\n", "# rather loss_value / batchsize", "\n", "            ", "monitor", ".", "log_loss", "(", "loss_vals", ",", "loss_flags", ",", "(", "end_time", "-", "start_time", ")", "/", "batchsize", ",", "data_seq_info", ",", "idx_orig", ".", "numpy", "(", ")", "[", "idx", "]", ",", "epoch_idx", ")", "\n", "# print infor for one sentence", "\n", "if", "args", ".", "verbose", "==", "1", ":", "\n", "                ", "monitor", ".", "print_error_for_batch", "(", "data_idx", "*", "batchsize", "+", "idx", ",", "idx_orig", ".", "numpy", "(", ")", "[", "idx", "]", ",", "epoch_idx", ")", "\n", "# ", "\n", "# start the timer for a new batch", "\n", "", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# lopp done", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_GAN.f_run_one_epoch_WGAN": [[206, 350], ["time.time", "enumerate", "isinstance", "data_in.to.to", "pt_model_D.zero_grad", "pt_model_D", "loss_wrapper.compute_gan_D_real", "pt_model_D.mean", "pt_model_D", "loss_wrapper.compute_gan_D_fake", "pt_model_D.mean", "pt_model_D.parameters", "pt_model_G.zero_grad", "pt_model_D", "loss_wrapper.compute_gan_G", "loss_wrapper.compute_aux", "pt_model_D.mean", "core_scripts.f_process_loss", "time.time", "len", "enumerate", "time.time", "optimizer_G.zero_grad", "optimizer_D.zero_grad", "data_tar.to.to", "core_scripts.f_die", "loss_wrapper.compute_gan_D_real.backward", "isinstance", "pt_model_G.detach", "loss_wrapper.compute_gan_D_fake.backward", "optimizer_D.step", "p.data.clamp_", "errG.backward", "optimizer_G.step", "monitor.log_loss", "pt_model_G.normalize_target", "target_norm_method", "data_tar.to.to", "core_scripts.f_print", "core_scripts.f_die", "pt_model_G", "pt_model_G", "monitor.print_error_for_batch", "pt_model_G", "pt_model_G", "idx_orig.numpy", "idx_orig.numpy"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_process_loss", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.log_loss", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.print_error_for_batch"], ["", "def", "f_run_one_epoch_WGAN", "(", "\n", "args", ",", "pt_model_G", ",", "pt_model_D", ",", "\n", "loss_wrapper", ",", "device", ",", "monitor", ",", "data_loader", ",", "epoch_idx", ",", "\n", "optimizer_G", "=", "None", ",", "optimizer_D", "=", "None", ",", "target_norm_method", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    f_run_one_epoch_WGAN: \n       similar to f_run_one_epoch_GAN, but for WGAN\n    \"\"\"", "\n", "# timer", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# This should be moved to model definition", "\n", "# number of critic (default 5)", "\n", "num_critic", "=", "5", "\n", "# clip value", "\n", "wgan_clamp", "=", "0.01", "\n", "\n", "# loop over samples", "\n", "for", "data_idx", ",", "(", "data_in", ",", "data_tar", ",", "data_info", ",", "idx_orig", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "\n", "# send data to device", "\n", "        ", "if", "optimizer_G", "is", "not", "None", ":", "\n", "            ", "optimizer_G", ".", "zero_grad", "(", ")", "\n", "", "if", "optimizer_D", "is", "not", "None", ":", "\n", "            ", "optimizer_D", ".", "zero_grad", "(", ")", "\n", "\n", "# prepare data", "\n", "", "if", "isinstance", "(", "data_tar", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "data_tar", "=", "data_tar", ".", "to", "(", "device", ",", "dtype", "=", "nii_dconf", ".", "d_dtype", ")", "\n", "# there is no way to normalize the data inside loss", "\n", "# thus, do normalization here", "\n", "if", "target_norm_method", "is", "None", ":", "\n", "                ", "normed_target", "=", "pt_model_G", ".", "normalize_target", "(", "data_tar", ")", "\n", "", "else", ":", "\n", "                ", "normed_target", "=", "target_norm_method", "(", "data_tar", ")", "\n", "", "", "else", ":", "\n", "            ", "nii_display", ".", "f_die", "(", "\"target data is required\"", ")", "\n", "\n", "# to device (we assume noise will be generated by the model itself)", "\n", "# here we only provide external condition", "\n", "", "data_in", "=", "data_in", ".", "to", "(", "device", ",", "dtype", "=", "nii_dconf", ".", "d_dtype", ")", "\n", "\n", "############################", "\n", "# Update Discriminator", "\n", "############################", "\n", "# train with real", "\n", "pt_model_D", ".", "zero_grad", "(", ")", "\n", "d_out_real", "=", "pt_model_D", "(", "data_tar", ")", "\n", "errD_real", "=", "loss_wrapper", ".", "compute_gan_D_real", "(", "d_out_real", ")", "\n", "if", "optimizer_D", "is", "not", "None", ":", "\n", "            ", "errD_real", ".", "backward", "(", ")", "\n", "", "d_out_real_mean", "=", "d_out_real", ".", "mean", "(", ")", "\n", "\n", "# train with fake", "\n", "#  generate sample", "\n", "if", "args", ".", "model_forward_with_target", ":", "\n", "# if model.forward requires (input, target) as arguments", "\n", "# for example, for auto-encoder & autoregressive model", "\n", "            ", "if", "isinstance", "(", "data_tar", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "data_tar_tm", "=", "data_tar", ".", "to", "(", "device", ",", "dtype", "=", "nii_dconf", ".", "d_dtype", ")", "\n", "if", "args", ".", "model_forward_with_file_name", ":", "\n", "                    ", "data_gen", "=", "pt_model_G", "(", "data_in", ",", "data_tar_tm", ",", "data_info", ")", "\n", "", "else", ":", "\n", "                    ", "data_gen", "=", "pt_model_G", "(", "data_in", ",", "data_tar_tm", ")", "\n", "", "", "else", ":", "\n", "                ", "nii_display", ".", "f_print", "(", "\"--model-forward-with-target is set\"", ")", "\n", "nii_display", ".", "f_die", "(", "\"but data_tar is not loaded\"", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "args", ".", "model_forward_with_file_name", ":", "\n", "# specifcal case when model.forward requires data_info", "\n", "                ", "data_gen", "=", "pt_model_G", "(", "data_in", ",", "data_info", ")", "\n", "", "else", ":", "\n", "# normal case for model.forward(input)", "\n", "                ", "data_gen", "=", "pt_model_G", "(", "data_in", ")", "\n", "\n", "# data_gen.detach() is required", "\n", "# https://github.com/pytorch/examples/issues/116", "\n", "", "", "d_out_fake", "=", "pt_model_D", "(", "data_gen", ".", "detach", "(", ")", ")", "\n", "errD_fake", "=", "loss_wrapper", ".", "compute_gan_D_fake", "(", "d_out_fake", ")", "\n", "if", "optimizer_D", "is", "not", "None", ":", "\n", "            ", "errD_fake", ".", "backward", "(", ")", "\n", "", "d_out_fake_mean", "=", "d_out_fake", ".", "mean", "(", ")", "\n", "\n", "errD", "=", "errD_real", "+", "errD_fake", "\n", "if", "optimizer_D", "is", "not", "None", ":", "\n", "            ", "optimizer_D", ".", "step", "(", ")", "\n", "\n", "# clip weights of discriminator", "\n", "", "for", "p", "in", "pt_model_D", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "data", ".", "clamp_", "(", "-", "wgan_clamp", ",", "wgan_clamp", ")", "\n", "\n", "############################", "\n", "# Update Generator ", "\n", "############################", "\n", "", "pt_model_G", ".", "zero_grad", "(", ")", "\n", "d_out_fake_for_G", "=", "pt_model_D", "(", "data_gen", ")", "\n", "errG_gan", "=", "loss_wrapper", ".", "compute_gan_G", "(", "d_out_fake_for_G", ")", "\n", "errG_aux", "=", "loss_wrapper", ".", "compute_aux", "(", "data_gen", ",", "data_tar", ")", "\n", "errG", "=", "errG_gan", "+", "errG_aux", "\n", "\n", "# only update after num_crictic iterations on discriminator", "\n", "if", "data_idx", "%", "num_critic", "==", "0", "and", "optimizer_G", "is", "not", "None", ":", "\n", "            ", "errG", ".", "backward", "(", ")", "\n", "optimizer_G", ".", "step", "(", ")", "\n", "\n", "", "d_out_fake_for_G_mean", "=", "d_out_fake_for_G", ".", "mean", "(", ")", "\n", "\n", "# construct the loss for logging and early stopping ", "\n", "# only use errG_aux for early-stopping", "\n", "loss_computed", "=", "[", "[", "errG_aux", ",", "errG_gan", ",", "errD_real", ",", "errD_fake", ",", "\n", "d_out_real_mean", ",", "d_out_fake_mean", ",", "\n", "d_out_fake_for_G_mean", "]", ",", "\n", "[", "True", ",", "False", ",", "False", ",", "False", ",", "False", ",", "False", ",", "False", "]", "]", "\n", "\n", "# to handle cases where there are multiple loss functions", "\n", "loss", ",", "loss_vals", ",", "loss_flags", "=", "nii_nn_tools", ".", "f_process_loss", "(", "loss_computed", ")", "\n", "\n", "\n", "# save the training process information to the monitor", "\n", "end_time", "=", "time", ".", "time", "(", ")", "\n", "batchsize", "=", "len", "(", "data_info", ")", "\n", "for", "idx", ",", "data_seq_info", "in", "enumerate", "(", "data_info", ")", ":", "\n", "# loss_value is supposed to be the average loss value", "\n", "# over samples in the the batch, thus, just loss_value", "\n", "# rather loss_value / batchsize", "\n", "            ", "monitor", ".", "log_loss", "(", "loss_vals", ",", "loss_flags", ",", "(", "end_time", "-", "start_time", ")", "/", "batchsize", ",", "data_seq_info", ",", "idx_orig", ".", "numpy", "(", ")", "[", "idx", "]", ",", "epoch_idx", ")", "\n", "# print infor for one sentence", "\n", "if", "args", ".", "verbose", "==", "1", ":", "\n", "                ", "monitor", ".", "print_error_for_batch", "(", "data_idx", "*", "batchsize", "+", "idx", ",", "idx_orig", ".", "numpy", "(", ")", "[", "idx", "]", ",", "epoch_idx", ")", "\n", "# ", "\n", "# start the timer for a new batch", "\n", "", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# lopp done", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_GAN.f_train_wrapper_GAN": [[352, 626], ["core_scripts.f_print_w_date", "optimizer_G_wrapper.print_info", "optimizer_D_wrapper.print_info", "optimizer_G_wrapper.get_epoch_num", "optimizer_G_wrapper.get_no_best_epoch_num", "train_dataset_wrapper.print_info", "train_dataset_wrapper.get_loader", "train_dataset_wrapper.get_seq_num", "core_scripts.Monitor", "pt_model_G.to", "pt_model_D.to", "core_scripts.f_print", "core_scripts.f_model_show", "core_scripts.f_print", "core_scripts.f_model_show", "core_scripts.f_loss_show", "core_scripts.CheckPointKey", "nii_monitor.Monitor.get_epoch", "nii_monitor.Monitor.get_max_epoch", "core_scripts.print_log_head", "core_scripts.f_print_message", "range", "core_scripts.print_log_tail", "core_scripts.f_print", "val_dataset_wrapper.print_info", "val_dataset_wrapper.get_loader", "val_dataset_wrapper.get_seq_num", "core_scripts.Monitor", "core_scripts.f_die", "core_scripts.f_print", "zip", "hasattr", "pt_model_D.train", "pt_model_G.train", "f_wrapper_gan_one_epoch", "nii_monitor.Monitor.get_time", "nii_monitor.Monitor.get_loss", "core_scripts.print_train_info", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "core_scripts.f_print", "nii_monitor.Monitor.get_time", "nii_monitor.Monitor.get_loss", "nii_monitor.Monitor.is_new_best", "optimizer_G_wrapper.get_lr_info", "zip", "zip", "nii_monitor.Monitor.should_early_stop", "torch.cuda.get_device_name", "torch.cuda.get_device_name", "torch.cuda.get_device_name", "type", "pt_model_G.eval", "pt_model_D.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "f_wrapper_gan_one_epoch", "core_scripts.f_save_trained_name", "torch.save", "torch.save", "torch.save", "core_scripts.f_save_epoch_name", "torch.save", "torch.save", "torch.save", "core_scripts.f_save_trained_name", "pt_model.load_state_dict", "optimizer.load_state_dict", "core_scripts.f_print", "core_scripts.f_print", "pt_model.load_state_dict", "core_scripts.f_print", "core_scripts.f_print", "pt_model.state_dict", "nii_monitor.Monitor.get_state_dic", "pt_model.state_dict", "optimizer.state_dict", "nii_monitor.Monitor.get_state_dic", "core_scripts.f_eprint", "core_scripts.f_eprint", "core_scripts.f_state_dict_wrapper", "nii_monitor.Monitor.load_state_dic", "nii_monitor.Monitor.load_state_dic", "core_scripts.f_state_dict_wrapper", "str", "datetime.datetime.now"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_w_date", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.print_info", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.print_info", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.get_epoch_num", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.get_no_best_epoch_num", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.print_info", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_loader", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_seq_num", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.script_model_para.f_model_show", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.script_model_para.f_model_show", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_loss_show", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.get_epoch", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.get_max_epoch", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_display_tools.print_log_head", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_display_tools.print_log_tail", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.print_info", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_loader", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_seq_num", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.get_time", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.get_loss", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_display_tools.print_train_info", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.get_time", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.get_loss", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.is_new_best", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.get_lr_info", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.should_early_stop", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_save_trained_name", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_save_epoch_name", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_save_trained_name", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.get_state_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.get_state_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_state_dict_wrapper", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.load_state_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.load_state_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_state_dict_wrapper"], ["", "def", "f_train_wrapper_GAN", "(", "\n", "args", ",", "pt_model_G", ",", "pt_model_D", ",", "loss_wrapper", ",", "device", ",", "optimizer_G_wrapper", ",", "optimizer_D_wrapper", ",", "train_dataset_wrapper", ",", "val_dataset_wrapper", "=", "None", ",", "checkpoint_G", "=", "None", ",", "checkpoint_D", "=", "None", ")", ":", "\n", "    ", "\"\"\" \n    f_train_wrapper_GAN(\n       args, pt_model_G, pt_model_D, loss_wrapper, device, \n       optimizer_G_wrapper, optimizer_D_wrapper, \n       train_dataset_wrapper, val_dataset_wrapper = None,\n       check_point = None):\n\n      A wrapper to run the training process\n\n    Args:\n       args:         argument information given by argpase\n       pt_model_G:   generator, pytorch model (torch.nn.Module)\n       pt_model_D:   discriminator, pytorch model (torch.nn.Module)\n       loss_wrapper: a wrapper over loss functions\n                     loss_wrapper.compute_D_real(discriminator_output) \n                     loss_wrapper.compute_D_fake(discriminator_output) \n                     loss_wrapper.compute_G(discriminator_output)\n                     loss_wrapper.compute_G(fake, real)\n\n       device:       torch.device(\"cuda\") or torch.device(\"cpu\")\n\n       optimizer_G_wrapper: \n           a optimizer wrapper for generator (defined in op_manager.py)\n       optimizer_D_wrapper: \n           a optimizer wrapper for discriminator (defined in op_manager.py)\n       \n       train_dataset_wrapper: \n           a wrapper over training data set (data_io/default_data_io.py)\n           train_dataset_wrapper.get_loader() returns torch.DataSetLoader\n       \n       val_dataset_wrapper: \n           a wrapper over validation data set (data_io/default_data_io.py)\n           it can None.\n       \n       checkpoint_G:\n           a check_point that stores every thing to resume training\n\n       checkpoint_D:\n           a check_point that stores every thing to resume training\n    \"\"\"", "\n", "\n", "nii_display", ".", "f_print_w_date", "(", "\"Start model training\"", ")", "\n", "\n", "##############", "\n", "## Preparation", "\n", "##############", "\n", "\n", "# get the optimizer", "\n", "optimizer_G_wrapper", ".", "print_info", "(", ")", "\n", "optimizer_D_wrapper", ".", "print_info", "(", ")", "\n", "optimizer_G", "=", "optimizer_G_wrapper", ".", "optimizer", "\n", "optimizer_D", "=", "optimizer_D_wrapper", ".", "optimizer", "\n", "epoch_num", "=", "optimizer_G_wrapper", ".", "get_epoch_num", "(", ")", "\n", "no_best_epoch_num", "=", "optimizer_G_wrapper", ".", "get_no_best_epoch_num", "(", ")", "\n", "\n", "# get data loader for training set", "\n", "train_dataset_wrapper", ".", "print_info", "(", ")", "\n", "train_data_loader", "=", "train_dataset_wrapper", ".", "get_loader", "(", ")", "\n", "train_seq_num", "=", "train_dataset_wrapper", ".", "get_seq_num", "(", ")", "\n", "\n", "# get the training process monitor", "\n", "monitor_trn", "=", "nii_monitor", ".", "Monitor", "(", "epoch_num", ",", "train_seq_num", ")", "\n", "\n", "# if validation data is provided, get data loader for val set", "\n", "if", "val_dataset_wrapper", "is", "not", "None", ":", "\n", "        ", "val_dataset_wrapper", ".", "print_info", "(", ")", "\n", "val_data_loader", "=", "val_dataset_wrapper", ".", "get_loader", "(", ")", "\n", "val_seq_num", "=", "val_dataset_wrapper", ".", "get_seq_num", "(", ")", "\n", "monitor_val", "=", "nii_monitor", ".", "Monitor", "(", "epoch_num", ",", "val_seq_num", ")", "\n", "", "else", ":", "\n", "        ", "monitor_val", "=", "None", "\n", "\n", "# training log information", "\n", "", "train_log", "=", "''", "\n", "model_tags", "=", "[", "\"_G\"", ",", "\"_D\"", "]", "\n", "\n", "# prepare for DataParallism if available", "\n", "# pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html", "\n", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", "and", "args", ".", "multi_gpu_data_parallel", ":", "\n", "        ", "nii_display", ".", "f_die", "(", "\"data_parallel not implemented for GAN\"", ")", "\n", "", "else", ":", "\n", "        ", "nii_display", ".", "f_print", "(", "\"\\nUse single GPU: %s\\n\"", "%", "(", "torch", ".", "cuda", ".", "get_device_name", "(", "device", ")", ")", ")", "\n", "flag_multi_device", "=", "False", "\n", "normtarget_f", "=", "None", "\n", "\n", "", "pt_model_G", ".", "to", "(", "device", ",", "dtype", "=", "nii_dconf", ".", "d_dtype", ")", "\n", "pt_model_D", ".", "to", "(", "device", ",", "dtype", "=", "nii_dconf", ".", "d_dtype", ")", "\n", "\n", "# print the network    ", "\n", "nii_display", ".", "f_print", "(", "\"Setup generator\"", ")", "\n", "nii_nn_tools", ".", "f_model_show", "(", "pt_model_G", ",", "model_type", "=", "'GAN'", ")", "\n", "nii_display", ".", "f_print", "(", "\"Setup discriminator\"", ")", "\n", "nii_nn_tools", ".", "f_model_show", "(", "pt_model_D", ",", "do_model_def_check", "=", "False", ",", "\n", "model_type", "=", "'GAN'", ")", "\n", "nii_nn_tools", ".", "f_loss_show", "(", "loss_wrapper", ",", "model_type", "=", "'GAN'", ")", "\n", "\n", "###############################", "\n", "## Resume training if necessary", "\n", "###############################", "\n", "\n", "# resume training or initialize the model if necessary", "\n", "cp_names", "=", "nii_nn_manage_conf", ".", "CheckPointKey", "(", ")", "\n", "if", "checkpoint_G", "is", "not", "None", "or", "checkpoint_D", "is", "not", "None", ":", "\n", "        ", "for", "checkpoint", ",", "optimizer", ",", "pt_model", ",", "model_name", "in", "zip", "(", "[", "checkpoint_G", ",", "checkpoint_D", "]", ",", "[", "optimizer_G", ",", "optimizer_D", "]", ",", "\n", "[", "pt_model_G", ",", "pt_model_D", "]", ",", "[", "\"Generator\"", ",", "\"Discriminator\"", "]", ")", ":", "\n", "            ", "nii_display", ".", "f_print", "(", "\"For %s\"", "%", "(", "model_name", ")", ")", "\n", "if", "type", "(", "checkpoint", ")", "is", "dict", ":", "\n", "# checkpoint", "\n", "# load model parameter and optimizer state", "\n", "                ", "if", "cp_names", ".", "state_dict", "in", "checkpoint", ":", "\n", "# wrap the state_dic in f_state_dict_wrapper ", "\n", "# in case the model is saved when DataParallel is on", "\n", "                    ", "pt_model", ".", "load_state_dict", "(", "\n", "nii_nn_tools", ".", "f_state_dict_wrapper", "(", "\n", "checkpoint", "[", "cp_names", ".", "state_dict", "]", ",", "\n", "flag_multi_device", ")", ")", "\n", "# load optimizer state", "\n", "", "if", "cp_names", ".", "optimizer", "in", "checkpoint", ":", "\n", "                    ", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "cp_names", ".", "optimizer", "]", ")", "\n", "# optionally, load training history", "\n", "", "if", "not", "args", ".", "ignore_training_history_in_trained_model", ":", "\n", "#nii_display.f_print(\"Load \")", "\n", "                    ", "if", "cp_names", ".", "trnlog", "in", "checkpoint", ":", "\n", "                        ", "monitor_trn", ".", "load_state_dic", "(", "\n", "checkpoint", "[", "cp_names", ".", "trnlog", "]", ")", "\n", "", "if", "cp_names", ".", "vallog", "in", "checkpoint", "and", "monitor_val", ":", "\n", "                        ", "monitor_val", ".", "load_state_dic", "(", "\n", "checkpoint", "[", "cp_names", ".", "vallog", "]", ")", "\n", "", "if", "cp_names", ".", "info", "in", "checkpoint", ":", "\n", "                        ", "train_log", "=", "checkpoint", "[", "cp_names", ".", "info", "]", "\n", "", "nii_display", ".", "f_print", "(", "\"Load check point, resume training\"", ")", "\n", "", "else", ":", "\n", "                    ", "nii_display", ".", "f_print", "(", "\"Load pretrained model and optimizer\"", ")", "\n", "", "", "elif", "checkpoint", "is", "not", "None", ":", "\n", "# only model status", "\n", "#pt_model.load_state_dict(checkpoint)", "\n", "                ", "pt_model", ".", "load_state_dict", "(", "\n", "nii_nn_tools", ".", "f_state_dict_wrapper", "(", "\n", "checkpoint", ",", "flag_multi_device", ")", ")", "\n", "nii_display", ".", "f_print", "(", "\"Load pretrained model\"", ")", "\n", "", "else", ":", "\n", "                ", "nii_display", ".", "f_print", "(", "\"No pretrained model\"", ")", "\n", "# done for resume training", "\n", "\n", "######################", "\n", "### User defined setup ", "\n", "######################", "\n", "# Not implemented yet", "\n", "\n", "######################", "\n", "### Start training", "\n", "######################", "\n", "\n", "# other variables", "\n", "", "", "", "flag_early_stopped", "=", "False", "\n", "start_epoch", "=", "monitor_trn", ".", "get_epoch", "(", ")", "\n", "epoch_num", "=", "monitor_trn", ".", "get_max_epoch", "(", ")", "\n", "\n", "# select one wrapper, based on the flag in loss definition", "\n", "if", "hasattr", "(", "loss_wrapper", ",", "\"flag_wgan\"", ")", "and", "loss_wrapper", ".", "flag_wgan", ":", "\n", "        ", "f_wrapper_gan_one_epoch", "=", "f_run_one_epoch_WGAN", "\n", "", "else", ":", "\n", "        ", "f_wrapper_gan_one_epoch", "=", "f_run_one_epoch_GAN", "\n", "\n", "# print", "\n", "", "_", "=", "nii_op_display_tk", ".", "print_log_head", "(", ")", "\n", "nii_display", ".", "f_print_message", "(", "train_log", ",", "flush", "=", "True", ",", "end", "=", "''", ")", "\n", "\n", "\n", "# loop over multiple epochs", "\n", "for", "epoch_idx", "in", "range", "(", "start_epoch", ",", "epoch_num", ")", ":", "\n", "\n", "# training one epoch", "\n", "        ", "pt_model_D", ".", "train", "(", ")", "\n", "pt_model_G", ".", "train", "(", ")", "\n", "\n", "f_wrapper_gan_one_epoch", "(", "\n", "args", ",", "pt_model_G", ",", "pt_model_D", ",", "\n", "loss_wrapper", ",", "device", ",", "monitor_trn", ",", "train_data_loader", ",", "epoch_idx", ",", "optimizer_G", ",", "optimizer_D", ",", "\n", "normtarget_f", ")", "\n", "\n", "time_trn", "=", "monitor_trn", ".", "get_time", "(", "epoch_idx", ")", "\n", "loss_trn", "=", "monitor_trn", ".", "get_loss", "(", "epoch_idx", ")", "\n", "\n", "# if necessary, do validataion ", "\n", "if", "val_dataset_wrapper", "is", "not", "None", ":", "\n", "# set eval() if necessary ", "\n", "            ", "if", "args", ".", "eval_mode_for_validation", ":", "\n", "                ", "pt_model_G", ".", "eval", "(", ")", "\n", "pt_model_D", ".", "eval", "(", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "f_wrapper_gan_one_epoch", "(", "\n", "args", ",", "pt_model_G", ",", "pt_model_D", ",", "\n", "loss_wrapper", ",", "device", ",", "monitor_val", ",", "val_data_loader", ",", "epoch_idx", ",", "None", ",", "None", ",", "normtarget_f", ")", "\n", "", "time_val", "=", "monitor_val", ".", "get_time", "(", "epoch_idx", ")", "\n", "loss_val", "=", "monitor_val", ".", "get_loss", "(", "epoch_idx", ")", "\n", "", "else", ":", "\n", "            ", "time_val", ",", "loss_val", "=", "0", ",", "0", "\n", "\n", "\n", "", "if", "val_dataset_wrapper", "is", "not", "None", ":", "\n", "            ", "flag_new_best", "=", "monitor_val", ".", "is_new_best", "(", ")", "\n", "", "else", ":", "\n", "            ", "flag_new_best", "=", "True", "\n", "\n", "# print information", "\n", "", "train_log", "+=", "nii_op_display_tk", ".", "print_train_info", "(", "\n", "epoch_idx", ",", "time_trn", ",", "loss_trn", ",", "time_val", ",", "loss_val", ",", "\n", "flag_new_best", ",", "optimizer_G_wrapper", ".", "get_lr_info", "(", ")", ")", "\n", "\n", "# save the best model", "\n", "if", "flag_new_best", ":", "\n", "            ", "for", "pt_model", ",", "tmp_tag", "in", "zip", "(", "[", "pt_model_G", ",", "pt_model_D", "]", ",", "model_tags", ")", ":", "\n", "                ", "tmp_best_name", "=", "nii_nn_tools", ".", "f_save_trained_name", "(", "args", ",", "tmp_tag", ")", "\n", "torch", ".", "save", "(", "pt_model", ".", "state_dict", "(", ")", ",", "tmp_best_name", ")", "\n", "\n", "# save intermediate model if necessary", "\n", "", "", "if", "not", "args", ".", "not_save_each_epoch", ":", "\n", "# save model discrminator and generator", "\n", "            ", "for", "pt_model", ",", "optimizer", ",", "model_tag", "in", "zip", "(", "[", "pt_model_G", ",", "pt_model_D", "]", ",", "[", "optimizer_G", ",", "optimizer_D", "]", ",", "\n", "model_tags", ")", ":", "\n", "\n", "                ", "tmp_model_name", "=", "nii_nn_tools", ".", "f_save_epoch_name", "(", "\n", "args", ",", "epoch_idx", ",", "model_tag", ")", "\n", "if", "monitor_val", "is", "not", "None", ":", "\n", "                    ", "tmp_val_log", "=", "monitor_val", ".", "get_state_dic", "(", ")", "\n", "", "else", ":", "\n", "                    ", "tmp_val_log", "=", "None", "\n", "# save", "\n", "", "tmp_dic", "=", "{", "\n", "cp_names", ".", "state_dict", ":", "pt_model", ".", "state_dict", "(", ")", ",", "\n", "cp_names", ".", "info", ":", "train_log", ",", "\n", "cp_names", ".", "optimizer", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "cp_names", ".", "trnlog", ":", "monitor_trn", ".", "get_state_dic", "(", ")", ",", "\n", "cp_names", ".", "vallog", ":", "tmp_val_log", "\n", "}", "\n", "torch", ".", "save", "(", "tmp_dic", ",", "tmp_model_name", ")", "\n", "if", "args", ".", "verbose", "==", "1", ":", "\n", "                    ", "nii_display", ".", "f_eprint", "(", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "nii_display", ".", "f_eprint", "(", "\"Save {:s}\"", ".", "format", "(", "tmp_model_name", ")", ",", "\n", "flush", "=", "True", ")", "\n", "\n", "# early stopping", "\n", "", "", "", "if", "monitor_val", "is", "not", "None", "and", "monitor_val", ".", "should_early_stop", "(", "no_best_epoch_num", ")", ":", "\n", "            ", "flag_early_stopped", "=", "True", "\n", "break", "\n", "\n", "# loop done        ", "\n", "\n", "", "", "nii_op_display_tk", ".", "print_log_tail", "(", ")", "\n", "if", "flag_early_stopped", ":", "\n", "        ", "nii_display", ".", "f_print", "(", "\"Training finished by early stopping\"", ")", "\n", "", "else", ":", "\n", "        ", "nii_display", ".", "f_print", "(", "\"Training finished\"", ")", "\n", "", "nii_display", ".", "f_print", "(", "\"Model is saved to\"", ",", "end", "=", "''", ")", "\n", "for", "model_tag", "in", "model_tags", ":", "\n", "        ", "nii_display", ".", "f_print", "(", "\"{}\"", ".", "format", "(", "\n", "nii_nn_tools", ".", "f_save_trained_name", "(", "args", ",", "model_tag", ")", ")", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_state_dict_wrapper": [[24, 55], ["collections.OrderedDict", "state_dict.items", "collections.OrderedDict", "state_dict.items", "k.startswith", "k.startswith"], "function", ["None"], ["def", "f_state_dict_wrapper", "(", "state_dict", ",", "data_parallel", "=", "False", ")", ":", "\n", "    ", "\"\"\" a wrapper to take care of state_dict when using DataParallism\n\n    f_model_load_wrapper(state_dict, data_parallel):\n    state_dict: pytorch state_dict\n    data_parallel: whether DataParallel is used\n    \n    https://discuss.pytorch.org/t/solved-keyerror-unexpected-\n    key-module-encoder-embedding-weight-in-state-dict/1686/3\n    \"\"\"", "\n", "if", "data_parallel", "is", "True", ":", "\n", "# if data_parallel is used", "\n", "        ", "new_state_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "not", "k", ".", "startswith", "(", "'module'", ")", ":", "\n", "# if key is not starting with module, add it", "\n", "                ", "name", "=", "'module.'", "+", "k", "\n", "", "else", ":", "\n", "                ", "name", "=", "k", "\n", "", "new_state_dict", "[", "name", "]", "=", "v", "\n", "", "return", "new_state_dict", "\n", "", "else", ":", "\n", "        ", "new_state_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "not", "k", ".", "startswith", "(", "'module'", ")", ":", "\n", "                ", "name", "=", "k", "\n", "", "else", ":", "\n", "# remove module.", "\n", "                ", "name", "=", "k", "[", "7", ":", "]", "\n", "", "new_state_dict", "[", "name", "]", "=", "v", "\n", "", "return", "new_state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_process_loss": [[56, 81], ["type", "[].item", "len", "loss_list.append", "loss.item", "loss_tmp.item"], "function", ["None"], ["", "", "def", "f_process_loss", "(", "loss", ")", ":", "\n", "    ", "\"\"\" loss, loss_value = f_process_loss(loss):\n    Input:\n      loss: returned by loss_wrapper.compute\n      It can be a torch.tensor or a list of torch.tensor\n      When it is a list, it should look like:\n       [[loss_1, loss_2, loss_3],\n        [true/false,   true/false,  true.false]]\n      where true / false tells whether the loss should be taken into \n      consideration for early-stopping\n\n    Output:\n      loss: a torch.tensor\n      loss_value: a torch number of a list of torch number\n    \"\"\"", "\n", "if", "type", "(", "loss", ")", "is", "list", ":", "\n", "        ", "loss_sum", "=", "loss", "[", "0", "]", "[", "0", "]", "\n", "loss_list", "=", "[", "loss", "[", "0", "]", "[", "0", "]", ".", "item", "(", ")", "]", "\n", "if", "len", "(", "loss", "[", "0", "]", ")", ">", "1", ":", "\n", "            ", "for", "loss_tmp", "in", "loss", "[", "0", "]", "[", "1", ":", "]", ":", "\n", "                ", "loss_sum", "+=", "loss_tmp", "\n", "loss_list", ".", "append", "(", "loss_tmp", ".", "item", "(", ")", ")", "\n", "", "", "return", "loss_sum", ",", "loss_list", ",", "loss", "[", "1", "]", "\n", "", "else", ":", "\n", "        ", "return", "loss", ",", "[", "loss", ".", "item", "(", ")", "]", ",", "[", "True", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_load_pretrained_model_partially": [[83, 131], ["model.state_dict", "zip", "type", "type", "torch.load", "print", "model.state_dict.update", "model.load_state_dict", "torch.load.items", "len", "torch.load.keys"], "function", ["None"], ["", "", "def", "f_load_pretrained_model_partially", "(", "model", ",", "model_paths", ",", "model_name_prefix", ")", ":", "\n", "    ", "\"\"\" f_load_pretrained_model_partially(model, model_paths, model_name_prefix)\n    \n    Initialize part of the model with pre-trained models\n    \n    Input:\n    -----\n       model: torch model\n       model_paths: list of path to pre-trained models\n       model_prefix: list of model name prefix used by model\n            for example, pre_trained_model.*** may be referred to as \n            model.m_part1.*** in the new model. The prefix is \"m_part1.\"\n    \n    Output:\n    ------\n       None\n    \"\"\"", "\n", "if", "type", "(", "model_paths", ")", "is", "str", ":", "\n", "        ", "model_path_tmp", "=", "[", "model_paths", "]", "\n", "", "else", ":", "\n", "        ", "model_path_tmp", "=", "model_paths", "\n", "", "if", "type", "(", "model_name_prefix", ")", "is", "str", ":", "\n", "        ", "model_prefix_tmp", "=", "[", "model_name_prefix", "]", "\n", "", "else", ":", "\n", "        ", "model_prefix_tmp", "=", "model_name_prefix", "\n", "\n", "", "model_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "\n", "for", "model_path", ",", "prefix", "in", "zip", "(", "model_path_tmp", ",", "model_prefix_tmp", ")", ":", "\n", "        ", "if", "prefix", "[", "-", "1", "]", "!=", "'.'", ":", "\n", "# m_part1. not m_part", "\n", "            ", "prefix", "+=", "'.'", "\n", "\n", "", "pretrained_dict", "=", "torch", ".", "load", "(", "model_path", ")", "\n", "\n", "# 1. filter out unnecessary keys", "\n", "pretrained_dict", "=", "{", "prefix", "+", "k", ":", "v", "for", "k", ",", "v", "in", "pretrained_dict", ".", "items", "(", ")", "if", "prefix", "+", "k", "in", "model_dict", "}", "\n", "print", "(", "\"Load model {:s} as {:s} ({:d} parameter buffers)\"", ".", "format", "(", "\n", "model_path", ",", "prefix", ",", "len", "(", "pretrained_dict", ".", "keys", "(", ")", ")", ")", ")", "\n", "\n", "# 2. overwrite entries in the existing state dict", "\n", "model_dict", ".", "update", "(", "pretrained_dict", ")", "\n", "\n", "# 3. load the new state dict", "\n", "model", ".", "load_state_dict", "(", "model_dict", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_save_epoch_name": [[132, 148], ["core_scripts.f_realpath"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath"], ["", "def", "f_save_epoch_name", "(", "args", ",", "epoch_idx", ",", "suffix", "=", "''", ")", ":", "\n", "    ", "\"\"\" str = f_save_epoch_name(args, epoch_idx)\n    Return the name of the model file saved during training\n\n    Args: \n      args: argument object by arg_parse, we will use\n            args.save_epoch_name, args.save_model_dir, args.save_model_ext\n      epoch_idx:, int, epoch index\n      suffix: a suffix to the name (default '')\n\n    Return: \n      str: name of epoch state file, str, e.g. epoch_001.pt\n    \"\"\"", "\n", "tmp_name", "=", "\"{}_{:03d}\"", ".", "format", "(", "args", ".", "save_epoch_name", ",", "epoch_idx", ")", "+", "suffix", "\n", "return", "nii_str_tk", ".", "f_realpath", "(", "args", ".", "save_model_dir", ",", "tmp_name", ",", "args", ".", "save_model_ext", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_save_trained_name": [[149, 164], ["core_scripts.f_realpath"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath"], ["", "def", "f_save_trained_name", "(", "args", ",", "suffix", "=", "''", ")", ":", "\n", "    ", "\"\"\" str = f_save_trained_name(args)\n    Return the name of the best trained model file\n\n    Args: \n      args: argument object by arg_parse\n            args.save_trained_name, args.save_model_dir, args.save_model_ext\n      suffix: a suffix added to the name (default '')\n\n    Return: \n      str: name of trained network file, e.g., trained_network.pt\n    \"\"\"", "\n", "return", "nii_str_tk", ".", "f_realpath", "(", "\n", "args", ".", "save_model_dir", ",", "args", ".", "save_trained_name", "+", "suffix", ",", "\n", "args", ".", "save_model_ext", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_model_check": [[166, 202], ["core_scripts.f_print", "keywords_bag.keys", "core_scripts.f_print", "hasattr", "core_scripts.f_print", "core_scripts.f_die", "print", "hasattr", "print", "print"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die"], ["", "def", "f_model_check", "(", "pt_model", ",", "model_type", "=", "None", ")", ":", "\n", "    ", "\"\"\" f_model_check(pt_model)\n    Check whether the model contains all the necessary keywords \n    \n    Args: \n    ----\n      pt_model: a Pytorch model\n      model_type_flag: str or None, a flag indicating the type of network\n\n    Return:\n    -------\n    \"\"\"", "\n", "nii_display", ".", "f_print", "(", "\"Model check:\"", ")", "\n", "if", "model_type", "in", "nii_nn_manage_conf", ".", "nn_model_keywords_bags", ":", "\n", "        ", "keywords_bag", "=", "nii_nn_manage_conf", ".", "nn_model_keywords_bags", "[", "model_type", "]", "\n", "", "else", ":", "\n", "        ", "keywords_bag", "=", "nii_nn_manage_conf", ".", "nn_model_keywords_default", "\n", "\n", "", "for", "tmpkey", "in", "keywords_bag", ".", "keys", "(", ")", ":", "\n", "        ", "flag_mandatory", ",", "mes", "=", "keywords_bag", "[", "tmpkey", "]", "\n", "\n", "# mandatory keywords", "\n", "if", "flag_mandatory", ":", "\n", "            ", "if", "not", "hasattr", "(", "pt_model", ",", "tmpkey", ")", ":", "\n", "                ", "nii_display", ".", "f_print", "(", "\"Please implement %s (%s)\"", "%", "(", "tmpkey", ",", "mes", ")", ")", "\n", "nii_display", ".", "f_die", "(", "\"[Error]: found no %s in Model\"", "%", "(", "tmpkey", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"[OK]: %s found\"", "%", "(", "tmpkey", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "not", "hasattr", "(", "pt_model", ",", "tmpkey", ")", ":", "\n", "                ", "print", "(", "\"[OK]: %s is ignored, %s\"", "%", "(", "tmpkey", ",", "mes", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"[OK]: use %s, %s\"", "%", "(", "tmpkey", ",", "mes", ")", ")", "\n", "# done", "\n", "", "", "", "nii_display", ".", "f_print", "(", "\"Model check done\\n\"", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_model_show": [[203, 223], ["core_scripts.f_print", "print", "sum", "core_scripts.f_print", "nn_manager_tools.f_model_check", "p.numel", "pt_model.parameters"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_model_check"], ["", "def", "f_model_show", "(", "pt_model", ",", "do_model_def_check", "=", "True", ",", "model_type", "=", "None", ")", ":", "\n", "    ", "\"\"\" f_model_show(pt_model, do_model_check=True)\n    Print the informaiton of the model\n\n    Args: \n      pt_model, a Pytorch model\n      do_model_def_check, bool, whether check model definition (default True)\n      model_type: str or None (default None), what type of network\n\n    Return:\n      None\n    \"\"\"", "\n", "if", "do_model_def_check", ":", "\n", "        ", "f_model_check", "(", "pt_model", ",", "model_type", ")", "\n", "\n", "", "nii_display", ".", "f_print", "(", "\"Model infor:\"", ")", "\n", "print", "(", "pt_model", ")", "\n", "num", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "pt_model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "nii_display", ".", "f_print", "(", "\"Parameter number: {:d}\\n\"", ".", "format", "(", "num", ")", ",", "\"normal\"", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_loss_check": [[225, 263], ["core_scripts.f_print", "keywords_bag.keys", "core_scripts.f_print", "hasattr", "core_scripts.f_print", "core_scripts.f_die", "hasattr", "print"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die"], ["", "def", "f_loss_check", "(", "loss_module", ",", "model_type", "=", "None", ")", ":", "\n", "    ", "\"\"\" f_loss_check(pt_model)\n    Check whether the loss module contains all the necessary keywords \n    \n    Args: \n    ----\n      loss_module, a class\n      model_type, a str or None\n    Return:\n    -------\n    \"\"\"", "\n", "nii_display", ".", "f_print", "(", "\"Loss check\"", ")", "\n", "\n", "if", "model_type", "in", "nii_nn_manage_conf", ".", "loss_method_keywords_bags", ":", "\n", "        ", "keywords_bag", "=", "nii_nn_manage_conf", ".", "loss_method_keywords_bags", "[", "model_type", "]", "\n", "", "else", ":", "\n", "        ", "keywords_bag", "=", "nii_nn_manage_conf", ".", "loss_method_keywords_default", "\n", "\n", "", "for", "tmpkey", "in", "keywords_bag", ".", "keys", "(", ")", ":", "\n", "        ", "flag_mandatory", ",", "mes", "=", "keywords_bag", "[", "tmpkey", "]", "\n", "\n", "# mandatory keywords", "\n", "if", "flag_mandatory", ":", "\n", "            ", "if", "not", "hasattr", "(", "loss_module", ",", "tmpkey", ")", ":", "\n", "                ", "nii_display", ".", "f_print", "(", "\"Please implement %s (%s)\"", "%", "(", "tmpkey", ",", "mes", ")", ")", "\n", "nii_display", ".", "f_die", "(", "\"[Error]: found no %s in Loss\"", "%", "(", "tmpkey", ")", ")", "\n", "", "else", ":", "\n", "# no need to print other information here", "\n", "                ", "pass", "#print(\"[OK]: %s found\" % (tmpkey))", "\n", "", "", "else", ":", "\n", "            ", "if", "not", "hasattr", "(", "loss_module", ",", "tmpkey", ")", ":", "\n", "# no need to print other information here", "\n", "                ", "pass", "#print(\"[OK]: %s is ignored, %s\" % (tmpkey, mes))", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"[OK]: use %s, %s\"", "%", "(", "tmpkey", ",", "mes", ")", ")", "\n", "# done", "\n", "", "", "", "nii_display", ".", "f_print", "(", "\"Loss check done\\n\"", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_loss_show": [[264, 284], ["nn_manager_tools.f_loss_check"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_loss_check"], ["", "def", "f_loss_show", "(", "loss_module", ",", "do_loss_def_check", "=", "True", ",", "model_type", "=", "None", ")", ":", "\n", "    ", "\"\"\" f_model_show(pt_model, do_model_check=True)\n    Print the informaiton of the model\n\n    Args: \n      pt_model, a Pytorch model\n      do_model_def_check, bool, whether check model definition (default True)\n      model_type: str or None (default None), what type of network\n\n    Return:\n      None\n    \"\"\"", "\n", "# no need to print other information here", "\n", "# because loss is usually not a torch.Module", "\n", "\n", "#nii_display.f_print(\"Loss infor:\")", "\n", "if", "do_loss_def_check", ":", "\n", "        ", "f_loss_check", "(", "loss_module", ",", "model_type", ")", "\n", "#print(loss_module)", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager.f_run_one_epoch": [[32, 190], ["time.time", "enumerate", "data_in.to.to", "hasattr", "core_scripts.f_process_loss", "time.time", "len", "enumerate", "time.time", "optimizer.zero_grad", "isinstance", "isinstance", "pt_model.loss", "isinstance", "loss_wrapper.compute", "loss.backward", "optimizer.step", "monitor.log_loss", "data_tar.to.to", "core_scripts.f_print", "core_scripts.f_die", "pt_model", "pt_model", "data_tar.to.to", "data_tar.to.to", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "monitor.print_error_for_batch", "pt_model", "pt_model", "pt_model.normalize_target", "target_norm_method", "pt_model.parameters", "idx_orig.numpy", "idx_orig.numpy"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_process_loss", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.log_loss", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.print_error_for_batch"], ["def", "f_run_one_epoch", "(", "args", ",", "\n", "pt_model", ",", "loss_wrapper", ",", "device", ",", "monitor", ",", "data_loader", ",", "epoch_idx", ",", "optimizer", "=", "None", ",", "target_norm_method", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    f_run_one_epoch: \n       run one poech over the dataset (for training or validation sets)\n\n    Args:\n       args:         from argpase\n       pt_model:     pytorch model (torch.nn.Module)\n       loss_wrapper: a wrapper over loss function\n                     loss_wrapper.compute(generated, target) \n       device:       torch.device(\"cuda\") or torch.device(\"cpu\")\n       monitor:      defined in op_procfess_monitor.py\n       data_loader:  pytorch DataLoader. \n       epoch_idx:    int, index of the current epoch\n       optimizer:    torch optimizer or None\n                     if None, the back propgation will be skipped\n                     (for developlement set)\n       target_norm_method: method to normalize target data\n                           (by default, use pt_model.normalize_target)\n    \"\"\"", "\n", "# timer", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# loop over samples", "\n", "for", "data_idx", ",", "(", "data_in", ",", "data_tar", ",", "data_info", ",", "idx_orig", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "\n", "#############", "\n", "# prepare", "\n", "#############", "\n", "# idx_orig is the original idx in the dataset", "\n", "# which can be different from data_idx when shuffle = True", "\n", "#idx_orig = idx_orig.numpy()[0]", "\n", "#data_seq_info = data_info[0]    ", "\n", "\n", "# send data to device", "\n", "        ", "if", "optimizer", "is", "not", "None", ":", "\n", "            ", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "############", "\n", "# compute output", "\n", "############", "\n", "", "data_in", "=", "data_in", ".", "to", "(", "device", ",", "dtype", "=", "nii_dconf", ".", "d_dtype", ")", "\n", "if", "args", ".", "model_forward_with_target", ":", "\n", "# if model.forward requires (input, target) as arguments", "\n", "# for example, for auto-encoder & autoregressive model", "\n", "            ", "if", "isinstance", "(", "data_tar", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "data_tar_tm", "=", "data_tar", ".", "to", "(", "device", ",", "dtype", "=", "nii_dconf", ".", "d_dtype", ")", "\n", "if", "args", ".", "model_forward_with_file_name", ":", "\n", "                    ", "data_gen", "=", "pt_model", "(", "data_in", ",", "data_tar_tm", ",", "data_info", ")", "\n", "", "else", ":", "\n", "                    ", "data_gen", "=", "pt_model", "(", "data_in", ",", "data_tar_tm", ")", "\n", "", "", "else", ":", "\n", "                ", "nii_display", ".", "f_print", "(", "\"--model-forward-with-target is set\"", ")", "\n", "nii_display", ".", "f_die", "(", "\"but data_tar is not loaded\"", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "args", ".", "model_forward_with_file_name", ":", "\n", "# specifcal case when model.forward requires data_info", "\n", "                ", "data_gen", "=", "pt_model", "(", "data_in", ",", "data_info", ")", "\n", "", "else", ":", "\n", "# normal case for model.forward(input)", "\n", "                ", "data_gen", "=", "pt_model", "(", "data_in", ")", "\n", "\n", "\n", "#####################", "\n", "# compute loss and do back propagate", "\n", "#####################", "\n", "\n", "# Two cases", "\n", "# 1. if loss is defined as pt_model.loss, then let the users do", "\n", "#    normalization inside the pt_mode.loss", "\n", "# 2. if loss_wrapper is defined as a class independent from model", "\n", "#    there is no way to normalize the data inside the loss_wrapper", "\n", "#    because the normalization weight is saved in pt_model", "\n", "\n", "", "", "if", "hasattr", "(", "pt_model", ",", "'loss'", ")", ":", "\n", "# case 1, pt_model.loss is available", "\n", "            ", "if", "isinstance", "(", "data_tar", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "data_tar", "=", "data_tar", ".", "to", "(", "device", ",", "dtype", "=", "nii_dconf", ".", "d_dtype", ")", "\n", "", "else", ":", "\n", "                ", "data_tar", "=", "[", "]", "\n", "\n", "", "loss_computed", "=", "pt_model", ".", "loss", "(", "data_gen", ",", "data_tar", ")", "\n", "", "else", ":", "\n", "# case 2, loss is defined independent of pt_model", "\n", "            ", "if", "isinstance", "(", "data_tar", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "data_tar", "=", "data_tar", ".", "to", "(", "device", ",", "dtype", "=", "nii_dconf", ".", "d_dtype", ")", "\n", "# there is no way to normalize the data inside loss", "\n", "# thus, do normalization here", "\n", "if", "target_norm_method", "is", "None", ":", "\n", "                    ", "normed_target", "=", "pt_model", ".", "normalize_target", "(", "data_tar", ")", "\n", "", "else", ":", "\n", "                    ", "normed_target", "=", "target_norm_method", "(", "data_tar", ")", "\n", "", "", "else", ":", "\n", "                ", "normed_target", "=", "[", "]", "\n", "\n", "# return the loss from loss_wrapper", "\n", "# loss_computed may be [[loss_1, loss_2, ...],[flag_1, flag_2,.]]", "\n", "#   which contain multiple loss and flags indicating whether", "\n", "#   the corresponding loss should be taken into consideration", "\n", "#   for early stopping", "\n", "# or ", "\n", "# loss_computed may be simply a tensor loss ", "\n", "", "loss_computed", "=", "loss_wrapper", ".", "compute", "(", "data_gen", ",", "normed_target", ")", "\n", "\n", "", "loss_values", "=", "[", "0", "]", "\n", "# To handle cases where there are multiple loss functions", "\n", "# when loss_comptued is [[loss_1, loss_2, ...],[flag_1, flag_2,.]]", "\n", "#   loss: sum of [loss_1, loss_2, ...], for backward()", "\n", "#   loss_values: [loss_1.item(), loss_2.item() ..], for logging", "\n", "#   loss_flags: [True/False, ...], for logging, ", "\n", "#               whether loss_n is used for early stopping", "\n", "# when loss_computed is loss", "\n", "#   loss: loss", "\n", "#   los_vals: [loss.item()]", "\n", "#   loss_flags: [True]", "\n", "loss", ",", "loss_values", ",", "loss_flags", "=", "nii_nn_tools", ".", "f_process_loss", "(", "\n", "loss_computed", ")", "\n", "\n", "# Back-propgation using the summed loss", "\n", "if", "optimizer", "is", "not", "None", ":", "\n", "# backward propagation", "\n", "            ", "loss", ".", "backward", "(", ")", "\n", "\n", "# apply gradient clip ", "\n", "if", "args", ".", "grad_clip_norm", ">", "0", ":", "\n", "                ", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "pt_model", ".", "parameters", "(", ")", ",", "args", ".", "grad_clip_norm", ")", "\n", "\n", "# update parameters", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "\n", "# save the training process information to the monitor", "\n", "", "end_time", "=", "time", ".", "time", "(", ")", "\n", "batchsize", "=", "len", "(", "data_info", ")", "\n", "for", "idx", ",", "data_seq_info", "in", "enumerate", "(", "data_info", ")", ":", "\n", "# loss_value is supposed to be the average loss value", "\n", "# over samples in the the batch, thus, just loss_value", "\n", "# rather loss_value / batchsize", "\n", "            ", "monitor", ".", "log_loss", "(", "loss_values", ",", "loss_flags", ",", "(", "end_time", "-", "start_time", ")", "/", "batchsize", ",", "data_seq_info", ",", "idx_orig", ".", "numpy", "(", ")", "[", "idx", "]", ",", "epoch_idx", ")", "\n", "# print infor for one sentence", "\n", "if", "args", ".", "verbose", "==", "1", ":", "\n", "                ", "monitor", ".", "print_error_for_batch", "(", "data_idx", "*", "batchsize", "+", "idx", ",", "idx_orig", ".", "numpy", "(", ")", "[", "idx", "]", ",", "epoch_idx", ")", "\n", "# ", "\n", "# start the timer for a new batch", "\n", "", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# lopp done", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager.f_train_wrapper": [[192, 471], ["core_scripts.f_print_w_date", "optimizer_wrapper.print_info", "optimizer_wrapper.get_epoch_num", "optimizer_wrapper.get_no_best_epoch_num", "train_dataset_wrapper.print_info", "train_dataset_wrapper.get_loader", "train_dataset_wrapper.get_seq_num", "core_scripts.Monitor", "nn.DataParallel.to", "core_scripts.f_model_show", "core_scripts.f_loss_show", "core_scripts.CheckPointKey", "hasattr", "nii_monitor.Monitor.get_epoch", "nii_monitor.Monitor.get_max_epoch", "core_scripts.print_log_head", "core_scripts.f_print_message", "range", "core_scripts.print_log_tail", "core_scripts.f_print", "core_scripts.f_print", "val_dataset_wrapper.print_info", "val_dataset_wrapper.get_loader", "val_dataset_wrapper.get_seq_num", "core_scripts.Monitor", "core_scripts.f_print", "torch.DataParallel", "core_scripts.f_print", "core_scripts.f_print", "nn.DataParallel.other_setups", "hasattr", "hasattr", "core_scripts.f_print", "core_scripts.f_load_pretrained_model_partially", "nn.DataParallel.train", "hasattr", "hasattr", "nn_manager.f_run_one_epoch", "nii_monitor.Monitor.get_time", "nii_monitor.Monitor.get_loss", "core_scripts.print_train_info", "core_scripts.f_print", "core_scripts.f_print", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "type", "nn.DataParallel.load_state_dict", "core_scripts.f_print", "core_scripts.f_print", "hasattr", "hasattr", "nii_monitor.Monitor.get_time", "nii_monitor.Monitor.get_loss", "lr_scheduler.f_valid", "nii_monitor.Monitor.is_new_best", "optimizer_wrapper.get_lr_info", "core_scripts.f_save_trained_name", "torch.save", "torch.save", "torch.save", "core_scripts.f_save_epoch_name", "lr_scheduler.f_valid", "torch.save", "torch.save", "torch.save", "lr_scheduler.f_allow_early_stopping", "nii_monitor.Monitor.should_early_stop", "core_scripts.f_save_trained_name", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.get_device_name", "torch.cuda.get_device_name", "torch.cuda.get_device_name", "nn.DataParallel.load_state_dict", "optimizer.load_state_dict", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_state_dict_wrapper", "nn.DataParallel.eval", "core_scripts.f_print", "torch.no_grad", "torch.no_grad", "torch.no_grad", "nn_manager.f_run_one_epoch", "lr_scheduler.f_step", "nn.DataParallel.state_dict", "nii_monitor.Monitor.get_state_dic", "lr_scheduler.f_state_dict", "nn.DataParallel.state_dict", "optimizer.state_dict", "nii_monitor.Monitor.get_state_dic", "core_scripts.f_eprint", "core_scripts.f_eprint", "core_scripts.f_state_dict_wrapper", "nii_monitor.Monitor.load_state_dic", "nii_monitor.Monitor.load_state_dic", "lr_scheduler.f_valid", "lr_scheduler.f_load_state_dict", "str", "datetime.datetime.now"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_w_date", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.print_info", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.get_epoch_num", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.get_no_best_epoch_num", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.print_info", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_loader", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_seq_num", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.script_model_para.f_model_show", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_loss_show", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.get_epoch", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.get_max_epoch", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_display_tools.print_log_head", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_display_tools.print_log_tail", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.print_info", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_loader", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_seq_num", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_load_pretrained_model_partially", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager.f_run_one_epoch", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.get_time", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.get_loss", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_display_tools.print_train_info", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.get_time", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.get_loss", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_valid", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.is_new_best", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.get_lr_info", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_save_trained_name", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_save_epoch_name", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_valid", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_allow_early_stopping", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.should_early_stop", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_save_trained_name", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_state_dict_wrapper", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager.f_run_one_epoch", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_step", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.get_state_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_state_dict", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.get_state_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager_tools.f_state_dict_wrapper", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.load_state_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.load_state_dic", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_valid", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_load_state_dict"], ["", "def", "f_train_wrapper", "(", "args", ",", "pt_model", ",", "loss_wrapper", ",", "device", ",", "optimizer_wrapper", ",", "train_dataset_wrapper", ",", "val_dataset_wrapper", "=", "None", ",", "checkpoint", "=", "None", ")", ":", "\n", "    ", "\"\"\" \n    f_train_wrapper(args, pt_model, loss_wrapper, device, \n                    optimizer_wrapper\n                    train_dataset_wrapper, val_dataset_wrapper = None,\n                    check_point = None):\n      A wrapper to run the training process\n\n    Args:\n       args:         argument information given by argpase\n       pt_model:     pytorch model (torch.nn.Module)\n       loss_wrapper: a wrapper over loss function\n                     loss_wrapper.compute(generated, target) \n       device:       torch.device(\"cuda\") or torch.device(\"cpu\")\n\n       optimizer_wrapper: \n           a wrapper over optimizer (defined in op_manager.py)\n           optimizer_wrapper.optimizer is torch.optimizer\n    \n       train_dataset_wrapper: \n           a wrapper over training data set (data_io/default_data_io.py)\n           train_dataset_wrapper.get_loader() returns torch.DataSetLoader\n       \n       val_dataset_wrapper: \n           a wrapper over validation data set (data_io/default_data_io.py)\n           it can None.\n       \n       check_point:\n           a check_point that stores every thing to resume training\n    \"\"\"", "\n", "\n", "nii_display", ".", "f_print_w_date", "(", "\"Start model training\"", ")", "\n", "\n", "##############", "\n", "## Preparation", "\n", "##############", "\n", "\n", "# get the optimizer", "\n", "optimizer_wrapper", ".", "print_info", "(", ")", "\n", "optimizer", "=", "optimizer_wrapper", ".", "optimizer", "\n", "lr_scheduler", "=", "optimizer_wrapper", ".", "lr_scheduler", "\n", "epoch_num", "=", "optimizer_wrapper", ".", "get_epoch_num", "(", ")", "\n", "no_best_epoch_num", "=", "optimizer_wrapper", ".", "get_no_best_epoch_num", "(", ")", "\n", "\n", "# get data loader for training set", "\n", "train_dataset_wrapper", ".", "print_info", "(", ")", "\n", "train_data_loader", "=", "train_dataset_wrapper", ".", "get_loader", "(", ")", "\n", "train_seq_num", "=", "train_dataset_wrapper", ".", "get_seq_num", "(", ")", "\n", "\n", "# get the training process monitor", "\n", "monitor_trn", "=", "nii_monitor", ".", "Monitor", "(", "epoch_num", ",", "train_seq_num", ")", "\n", "\n", "# if validation data is provided, get data loader for val set", "\n", "if", "val_dataset_wrapper", "is", "not", "None", ":", "\n", "        ", "val_dataset_wrapper", ".", "print_info", "(", ")", "\n", "val_data_loader", "=", "val_dataset_wrapper", ".", "get_loader", "(", ")", "\n", "val_seq_num", "=", "val_dataset_wrapper", ".", "get_seq_num", "(", ")", "\n", "monitor_val", "=", "nii_monitor", ".", "Monitor", "(", "epoch_num", ",", "val_seq_num", ")", "\n", "", "else", ":", "\n", "        ", "monitor_val", "=", "None", "\n", "\n", "# training log information", "\n", "", "train_log", "=", "''", "\n", "\n", "# prepare for DataParallism if available", "\n", "# pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html", "\n", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", "and", "args", ".", "multi_gpu_data_parallel", ":", "\n", "        ", "flag_multi_device", "=", "True", "\n", "nii_display", ".", "f_print", "(", "\"\\nUse %d GPUs\\n\"", "%", "(", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", ")", "\n", "# no way to call normtarget_f after pt_model is in DataParallel", "\n", "normtarget_f", "=", "pt_model", ".", "normalize_target", "\n", "pt_model", "=", "nn", ".", "DataParallel", "(", "pt_model", ")", "\n", "", "else", ":", "\n", "        ", "nii_display", ".", "f_print", "(", "\"\\nUse single GPU: %s\\n\"", "%", "(", "torch", ".", "cuda", ".", "get_device_name", "(", "device", ")", ")", ")", "\n", "flag_multi_device", "=", "False", "\n", "normtarget_f", "=", "None", "\n", "", "pt_model", ".", "to", "(", "device", ",", "dtype", "=", "nii_dconf", ".", "d_dtype", ")", "\n", "\n", "# print the network", "\n", "nii_nn_tools", ".", "f_model_show", "(", "pt_model", ")", "\n", "nii_nn_tools", ".", "f_loss_show", "(", "loss_wrapper", ")", "\n", "\n", "###############################", "\n", "## Resume training if necessary", "\n", "###############################", "\n", "# resume training or initialize the model if necessary", "\n", "cp_names", "=", "nii_nn_manage_conf", ".", "CheckPointKey", "(", ")", "\n", "if", "checkpoint", "is", "not", "None", ":", "\n", "        ", "if", "type", "(", "checkpoint", ")", "is", "dict", ":", "\n", "# checkpoint", "\n", "\n", "# load model parameter and optimizer state", "\n", "            ", "if", "cp_names", ".", "state_dict", "in", "checkpoint", ":", "\n", "# wrap the state_dic in f_state_dict_wrapper ", "\n", "# in case the model is saved when DataParallel is on", "\n", "                ", "pt_model", ".", "load_state_dict", "(", "\n", "nii_nn_tools", ".", "f_state_dict_wrapper", "(", "\n", "checkpoint", "[", "cp_names", ".", "state_dict", "]", ",", "\n", "flag_multi_device", ")", ")", "\n", "\n", "# load optimizer state", "\n", "", "if", "cp_names", ".", "optimizer", "in", "checkpoint", "and", "not", "args", ".", "ignore_optimizer_statistics_in_trained_model", ":", "\n", "                ", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "cp_names", ".", "optimizer", "]", ")", "\n", "\n", "# optionally, load training history", "\n", "", "if", "not", "args", ".", "ignore_training_history_in_trained_model", ":", "\n", "#nii_display.f_print(\"Load \")", "\n", "                ", "if", "cp_names", ".", "trnlog", "in", "checkpoint", ":", "\n", "                    ", "monitor_trn", ".", "load_state_dic", "(", "\n", "checkpoint", "[", "cp_names", ".", "trnlog", "]", ")", "\n", "", "if", "cp_names", ".", "vallog", "in", "checkpoint", "and", "monitor_val", ":", "\n", "                    ", "monitor_val", ".", "load_state_dic", "(", "\n", "checkpoint", "[", "cp_names", ".", "vallog", "]", ")", "\n", "", "if", "cp_names", ".", "info", "in", "checkpoint", ":", "\n", "                    ", "train_log", "=", "checkpoint", "[", "cp_names", ".", "info", "]", "\n", "", "if", "cp_names", ".", "lr_scheduler", "in", "checkpoint", "and", "checkpoint", "[", "cp_names", ".", "lr_scheduler", "]", "and", "lr_scheduler", ".", "f_valid", "(", ")", ":", "\n", "                    ", "lr_scheduler", ".", "f_load_state_dict", "(", "\n", "checkpoint", "[", "cp_names", ".", "lr_scheduler", "]", ")", "\n", "\n", "", "nii_display", ".", "f_print", "(", "\"Load check point, resume training\"", ")", "\n", "", "else", ":", "\n", "                ", "nii_display", ".", "f_print", "(", "\"Load pretrained model and optimizer\"", ")", "\n", "", "", "else", ":", "\n", "# only model status", "\n", "            ", "pt_model", ".", "load_state_dict", "(", "\n", "nii_nn_tools", ".", "f_state_dict_wrapper", "(", "\n", "checkpoint", ",", "flag_multi_device", ")", ")", "\n", "nii_display", ".", "f_print", "(", "\"Load pretrained model\"", ")", "\n", "\n", "\n", "######################", "\n", "### User defined setup ", "\n", "######################", "\n", "", "", "if", "hasattr", "(", "pt_model", ",", "\"other_setups\"", ")", ":", "\n", "        ", "nii_display", ".", "f_print", "(", "\"Conduct User-defined setup\"", ")", "\n", "pt_model", ".", "other_setups", "(", ")", "\n", "\n", "# This should be merged with other_setups", "\n", "", "if", "hasattr", "(", "pt_model", ",", "\"g_pretrained_model_path\"", ")", "and", "hasattr", "(", "pt_model", ",", "\"g_pretrained_model_prefix\"", ")", ":", "\n", "        ", "nii_display", ".", "f_print", "(", "\"Load pret-rained models as part of this mode\"", ")", "\n", "nii_nn_tools", ".", "f_load_pretrained_model_partially", "(", "\n", "pt_model", ",", "pt_model", ".", "g_pretrained_model_path", ",", "\n", "pt_model", ".", "g_pretrained_model_prefix", ")", "\n", "\n", "######################", "\n", "### Start training", "\n", "######################", "\n", "# other variables", "\n", "", "flag_early_stopped", "=", "False", "\n", "start_epoch", "=", "monitor_trn", ".", "get_epoch", "(", ")", "\n", "epoch_num", "=", "monitor_trn", ".", "get_max_epoch", "(", ")", "\n", "\n", "# print", "\n", "_", "=", "nii_op_display_tk", ".", "print_log_head", "(", ")", "\n", "nii_display", ".", "f_print_message", "(", "train_log", ",", "flush", "=", "True", ",", "end", "=", "''", ")", "\n", "\n", "\n", "# loop over multiple epochs", "\n", "for", "epoch_idx", "in", "range", "(", "start_epoch", ",", "epoch_num", ")", ":", "\n", "\n", "# training one epoch", "\n", "        ", "pt_model", ".", "train", "(", ")", "\n", "# set validation flag if necessary", "\n", "if", "hasattr", "(", "pt_model", ",", "'validation'", ")", ":", "\n", "            ", "pt_model", ".", "validation", "=", "False", "\n", "mes", "=", "\"Warning: model.validation is deprecated, \"", "\n", "mes", "+=", "\"please use model.flag_validation\"", "\n", "nii_display", ".", "f_print", "(", "mes", ",", "'warning'", ")", "\n", "", "if", "hasattr", "(", "pt_model", ",", "'flag_validation'", ")", ":", "\n", "            ", "pt_model", ".", "flag_validation", "=", "False", "\n", "\n", "", "f_run_one_epoch", "(", "args", ",", "pt_model", ",", "loss_wrapper", ",", "device", ",", "monitor_trn", ",", "train_data_loader", ",", "epoch_idx", ",", "optimizer", ",", "normtarget_f", ")", "\n", "time_trn", "=", "monitor_trn", ".", "get_time", "(", "epoch_idx", ")", "\n", "loss_trn", "=", "monitor_trn", ".", "get_loss", "(", "epoch_idx", ")", "\n", "\n", "# if necessary, do validataion ", "\n", "if", "val_dataset_wrapper", "is", "not", "None", ":", "\n", "# set eval() if necessary ", "\n", "            ", "if", "args", ".", "eval_mode_for_validation", ":", "\n", "                ", "pt_model", ".", "eval", "(", ")", "\n", "\n", "# set validation flag if necessary", "\n", "", "if", "hasattr", "(", "pt_model", ",", "'validation'", ")", ":", "\n", "                ", "pt_model", ".", "validation", "=", "True", "\n", "mes", "=", "\"Warning: model.validation is deprecated, \"", "\n", "mes", "+=", "\"please use model.flag_validation\"", "\n", "nii_display", ".", "f_print", "(", "mes", ",", "'warning'", ")", "\n", "", "if", "hasattr", "(", "pt_model", ",", "'flag_validation'", ")", ":", "\n", "                ", "pt_model", ".", "flag_validation", "=", "True", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "f_run_one_epoch", "(", "args", ",", "pt_model", ",", "loss_wrapper", ",", "device", ",", "monitor_val", ",", "val_data_loader", ",", "epoch_idx", ",", "None", ",", "normtarget_f", ")", "\n", "", "time_val", "=", "monitor_val", ".", "get_time", "(", "epoch_idx", ")", "\n", "loss_val", "=", "monitor_val", ".", "get_loss", "(", "epoch_idx", ")", "\n", "\n", "# update lr rate scheduler if necessary", "\n", "if", "lr_scheduler", ".", "f_valid", "(", ")", ":", "\n", "                ", "lr_scheduler", ".", "f_step", "(", "loss_val", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "time_val", ",", "loss_val", "=", "0", ",", "0", "\n", "\n", "\n", "", "if", "val_dataset_wrapper", "is", "not", "None", ":", "\n", "            ", "flag_new_best", "=", "monitor_val", ".", "is_new_best", "(", ")", "\n", "", "else", ":", "\n", "            ", "flag_new_best", "=", "True", "\n", "\n", "# print information", "\n", "", "train_log", "+=", "nii_op_display_tk", ".", "print_train_info", "(", "\n", "epoch_idx", ",", "time_trn", ",", "loss_trn", ",", "time_val", ",", "loss_val", ",", "\n", "flag_new_best", ",", "optimizer_wrapper", ".", "get_lr_info", "(", ")", ")", "\n", "\n", "# save the best model", "\n", "if", "flag_new_best", ":", "\n", "            ", "tmp_best_name", "=", "nii_nn_tools", ".", "f_save_trained_name", "(", "args", ")", "\n", "torch", ".", "save", "(", "pt_model", ".", "state_dict", "(", ")", ",", "tmp_best_name", ")", "\n", "\n", "# save intermediate model if necessary", "\n", "", "if", "not", "args", ".", "not_save_each_epoch", ":", "\n", "            ", "tmp_model_name", "=", "nii_nn_tools", ".", "f_save_epoch_name", "(", "args", ",", "epoch_idx", ")", "\n", "\n", "if", "monitor_val", "is", "not", "None", ":", "\n", "                ", "tmp_val_log", "=", "monitor_val", ".", "get_state_dic", "(", ")", "\n", "", "else", ":", "\n", "                ", "tmp_val_log", "=", "None", "\n", "\n", "", "if", "lr_scheduler", ".", "f_valid", "(", ")", ":", "\n", "                ", "lr_scheduler_state", "=", "lr_scheduler", ".", "f_state_dict", "(", ")", "\n", "", "else", ":", "\n", "                ", "lr_scheduler_state", "=", "None", "\n", "\n", "# save", "\n", "", "tmp_dic", "=", "{", "\n", "cp_names", ".", "state_dict", ":", "pt_model", ".", "state_dict", "(", ")", ",", "\n", "cp_names", ".", "info", ":", "train_log", ",", "\n", "cp_names", ".", "optimizer", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "cp_names", ".", "trnlog", ":", "monitor_trn", ".", "get_state_dic", "(", ")", ",", "\n", "cp_names", ".", "vallog", ":", "tmp_val_log", ",", "\n", "cp_names", ".", "lr_scheduler", ":", "lr_scheduler_state", "\n", "}", "\n", "torch", ".", "save", "(", "tmp_dic", ",", "tmp_model_name", ")", "\n", "if", "args", ".", "verbose", "==", "1", ":", "\n", "                ", "nii_display", ".", "f_eprint", "(", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "nii_display", ".", "f_eprint", "(", "\"Save {:s}\"", ".", "format", "(", "tmp_model_name", ")", ",", "\n", "flush", "=", "True", ")", "\n", "\n", "\n", "# Early stopping", "\n", "#  note: if LR scheduler is used, early stopping will be", "\n", "#  disabled", "\n", "", "", "if", "lr_scheduler", ".", "f_allow_early_stopping", "(", ")", "and", "monitor_val", "is", "not", "None", "and", "monitor_val", ".", "should_early_stop", "(", "no_best_epoch_num", ")", ":", "\n", "            ", "flag_early_stopped", "=", "True", "\n", "break", "\n", "\n", "# loop done        ", "\n", "", "", "nii_op_display_tk", ".", "print_log_tail", "(", ")", "\n", "if", "flag_early_stopped", ":", "\n", "        ", "nii_display", ".", "f_print", "(", "\"Training finished by early stopping\"", ")", "\n", "", "else", ":", "\n", "        ", "nii_display", ".", "f_print", "(", "\"Training finished\"", ")", "\n", "", "nii_display", ".", "f_print", "(", "\"Model is saved to\"", ",", "end", "=", "''", ")", "\n", "nii_display", ".", "f_print", "(", "\"{}\"", ".", "format", "(", "nii_nn_tools", ".", "f_save_trained_name", "(", "args", ")", ")", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.nn_manager.nn_manager.f_inference_wrapper": [[473, 574], ["test_dataset_wrapper.get_loader", "test_dataset_wrapper.get_seq_num", "test_dataset_wrapper.print_info", "core_scripts.f_print", "pt_model.to", "core_scripts.f_model_show", "core_scripts.CheckPointKey", "core_scripts.f_print", "pt_model.eval", "core_scripts.f_print", "hasattr", "core_scripts.f_print", "pt_model.load_state_dict", "pt_model.load_state_dict", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "pt_model.finish_up_inference", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.get_device_name", "torch.cuda.get_device_name", "torch.cuda.get_device_name", "type", "data_in.to.to", "isinstance", "time.time", "hasattr", "data_tar.to.to", "time.time", "len", "core_scripts.f_print", "enumerate", "enumerate", "infer_func", "infer_func", "infer_func", "infer_func", "core_scripts.print_gen_info", "pt_model.denormalize_output", "pt_model.denormalize_output.to().numpy", "core_scripts.print_gen_info", "test_dataset_wrapper.putitem", "str", "core_scripts.f_die", "pt_model.denormalize_output.to"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_loader", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.get_seq_num", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.print_info", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.script_model_para.f_model_show", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_display_tools.print_gen_info", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_display_tools.print_gen_info", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.default_data_io.NIIDataSetLoader.putitem", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die"], ["", "def", "f_inference_wrapper", "(", "args", ",", "pt_model", ",", "device", ",", "test_dataset_wrapper", ",", "checkpoint", ")", ":", "\n", "    ", "\"\"\" Wrapper for inference\n    \"\"\"", "\n", "\n", "# prepare dataloader", "\n", "test_data_loader", "=", "test_dataset_wrapper", ".", "get_loader", "(", ")", "\n", "test_seq_num", "=", "test_dataset_wrapper", ".", "get_seq_num", "(", ")", "\n", "test_dataset_wrapper", ".", "print_info", "(", ")", "\n", "\n", "# cuda device", "\n", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", "and", "args", ".", "multi_gpu_data_parallel", ":", "\n", "        ", "nii_display", ".", "f_print", "(", "\n", "\"DataParallel for inference is not implemented\"", ",", "'warning'", ")", "\n", "", "nii_display", ".", "f_print", "(", "\"\\nUse single GPU: %s\\n\"", "%", "(", "torch", ".", "cuda", ".", "get_device_name", "(", "device", ")", ")", ")", "\n", "\n", "# print the network", "\n", "pt_model", ".", "to", "(", "device", ",", "dtype", "=", "nii_dconf", ".", "d_dtype", ")", "\n", "nii_nn_tools", ".", "f_model_show", "(", "pt_model", ")", "\n", "\n", "# load trained model parameters from checkpoint", "\n", "cp_names", "=", "nii_nn_manage_conf", ".", "CheckPointKey", "(", ")", "\n", "if", "type", "(", "checkpoint", ")", "is", "dict", "and", "cp_names", ".", "state_dict", "in", "checkpoint", ":", "\n", "        ", "pt_model", ".", "load_state_dict", "(", "checkpoint", "[", "cp_names", ".", "state_dict", "]", ")", "\n", "", "else", ":", "\n", "        ", "pt_model", ".", "load_state_dict", "(", "checkpoint", ")", "\n", "\n", "# start generation", "\n", "", "nii_display", ".", "f_print", "(", "\"Start inference (generation):\"", ",", "'highlight'", ")", "\n", "\n", "pt_model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "_", ",", "(", "data_in", ",", "data_tar", ",", "data_info", ",", "idx_orig", ")", "in", "enumerate", "(", "test_data_loader", ")", ":", "\n", "\n", "# send data to device and convert data type", "\n", "            ", "data_in", "=", "data_in", ".", "to", "(", "device", ",", "dtype", "=", "nii_dconf", ".", "d_dtype", ")", "\n", "if", "isinstance", "(", "data_tar", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "data_tar", "=", "data_tar", ".", "to", "(", "device", ",", "dtype", "=", "nii_dconf", ".", "d_dtype", ")", "\n", "\n", "# compute output", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# in case the model defines inference function explicitly", "\n", "if", "hasattr", "(", "pt_model", ",", "\"inference\"", ")", ":", "\n", "                ", "infer_func", "=", "pt_model", ".", "inference", "\n", "", "else", ":", "\n", "                ", "infer_func", "=", "pt_model", ".", "forward", "\n", "\n", "", "if", "args", ".", "model_forward_with_target", ":", "\n", "# if model.forward requires (input, target) as arguments", "\n", "# for example, for auto-encoder", "\n", "                ", "if", "args", ".", "model_forward_with_file_name", ":", "\n", "                    ", "data_gen", "=", "infer_func", "(", "data_in", ",", "data_tar", ",", "data_info", ")", "\n", "", "else", ":", "\n", "                    ", "data_gen", "=", "infer_func", "(", "data_in", ",", "data_tar", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "args", ".", "model_forward_with_file_name", ":", "\n", "                    ", "data_gen", "=", "infer_func", "(", "data_in", ",", "data_info", ")", "\n", "", "else", ":", "\n", "                    ", "data_gen", "=", "infer_func", "(", "data_in", ")", "\n", "\n", "", "", "time_cost", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "# average time for each sequence when batchsize > 1", "\n", "time_cost", "=", "time_cost", "/", "len", "(", "data_info", ")", "\n", "\n", "if", "data_gen", "is", "None", ":", "\n", "                ", "nii_display", ".", "f_print", "(", "\"No output saved: %s\"", "%", "(", "str", "(", "data_info", ")", ")", ",", "'warning'", ")", "\n", "for", "idx", ",", "seq_info", "in", "enumerate", "(", "data_info", ")", ":", "\n", "                    ", "_", "=", "nii_op_display_tk", ".", "print_gen_info", "(", "seq_info", ",", "time_cost", ")", "\n", "", "continue", "\n", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "data_gen", "=", "pt_model", ".", "denormalize_output", "(", "data_gen", ")", "\n", "data_gen_np", "=", "data_gen", ".", "to", "(", "\"cpu\"", ")", ".", "numpy", "(", ")", "\n", "", "except", "AttributeError", ":", "\n", "                    ", "mes", "=", "\"Output data is not torch.tensor. Please check \"", "\n", "mes", "+=", "\"model.forward or model.inference\"", "\n", "nii_display", ".", "f_die", "(", "mes", ")", "\n", "\n", "# save output (in case batchsize > 1, )", "\n", "", "for", "idx", ",", "seq_info", "in", "enumerate", "(", "data_info", ")", ":", "\n", "                    ", "_", "=", "nii_op_display_tk", ".", "print_gen_info", "(", "seq_info", ",", "time_cost", ")", "\n", "test_dataset_wrapper", ".", "putitem", "(", "data_gen_np", "[", "idx", ":", "idx", "+", "1", "]", ",", "args", ".", "output_dir", ",", "seq_info", ")", "\n", "\n", "# done for", "\n", "# done with", "\n", "\n", "# ", "\n", "", "", "", "", "nii_display", ".", "f_print", "(", "\"Generated data to %s\"", "%", "(", "args", ".", "output_dir", ")", ")", "\n", "\n", "# finish up if necessary", "\n", "if", "hasattr", "(", "pt_model", ",", "\"finish_up_inference\"", ")", ":", "\n", "        ", "pt_model", ".", "finish_up_inference", "(", ")", "\n", "\n", "# done", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.config_parse.config_parse.ConfigParse.__init__": [[28, 45], ["os.path.isfile", "config_parse.ConfigParse.f_parse", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.config_parse.config_parse.ConfigParse.f_parse", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die"], ["def", "__init__", "(", "self", ",", "config_path", ")", ":", "\n", "        ", "\"\"\" initialization\n        \"\"\"", "\n", "# get configuration path", "\n", "self", ".", "m_config_path", "=", "None", "\n", "if", "os", ".", "path", ".", "isfile", "(", "config_path", ")", ":", "\n", "            ", "self", ".", "m_config_path", "=", "config_path", "\n", "", "else", ":", "\n", "            ", "nii_display", ".", "f_die", "(", "\"Cannot find %s\"", "%", "(", "config_path", ")", ",", "'error'", ")", "\n", "\n", "# path configuration file", "\n", "", "self", ".", "m_config", "=", "self", ".", "f_parse", "(", ")", "\n", "if", "self", ".", "m_config", "is", "None", ":", "\n", "            ", "nii_display", ".", "f_die", "(", "\"Fail to parse %s\"", "%", "(", "config_path", ")", ",", "'error'", ")", "\n", "\n", "# done", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.config_parse.config_parse.ConfigParse.f_parse": [[46, 57], ["configparser.ConfigParser", "configparser.ConfigParser.read", "core_scripts.f_print", "core_scripts.f_print"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print"], ["", "def", "f_parse", "(", "self", ")", ":", "\n", "        ", "\"\"\" f_parse\n        parse the configuration file\n        \"\"\"", "\n", "if", "self", ".", "m_config_path", "is", "not", "None", ":", "\n", "            ", "tmp_config", "=", "configparser", ".", "ConfigParser", "(", ")", "\n", "tmp_config", ".", "read", "(", "self", ".", "m_config_path", ")", "\n", "return", "tmp_config", "\n", "", "else", ":", "\n", "            ", "nii_display", ".", "f_print", "(", "\"No config file provided\"", ",", "'error'", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.config_parse.config_parse.ConfigParse.f_retrieve": [[58, 96], ["config_parse.ConfigParse.m_config.sections", "config_parse.ConfigParse.f_retrieve", "core_scripts.f_die", "core_scripts.f_die", "config_parse.ConfigParse.m_config.sections", "tmp_sec.getint", "tmp_sec.getfloat", "tmp_sec.getboolean", "tmp_sec.get"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.config_parse.config_parse.ConfigParse.f_retrieve", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die"], ["", "", "def", "f_retrieve", "(", "self", ",", "keyword", ",", "section_name", "=", "None", ",", "config_type", "=", "None", ")", ":", "\n", "        ", "\"\"\" f_retrieve(self, keyword, section_name=None, config_type=None)\n        retrieve the keyword from config file\n        \n        Return:\n           value: string, int, float\n        \n        Parameters:\n           keyword: 'keyword' to be retrieved\n           section: which section is this keyword in the config. \n                    None will search all the config sections and \n                    return the first\n           config_type: which can be 'int', 'float', or None.\n                    None will return the value as a string\n        \"\"\"", "\n", "tmp_value", "=", "None", "\n", "if", "section_name", "is", "None", ":", "\n", "# if section is not given, search all the sections", "\n", "            ", "for", "section_name", "in", "self", ".", "m_config", ".", "sections", "(", ")", ":", "\n", "                ", "tmp_value", "=", "self", ".", "f_retrieve", "(", "keyword", ",", "section_name", ",", "config_type", ")", "\n", "if", "tmp_value", "is", "not", "None", ":", "\n", "                    ", "break", "\n", "", "", "", "elif", "section_name", "in", "self", ".", "m_config", ".", "sections", "(", ")", "or", "section_name", "==", "'DEFAULT'", ":", "\n", "            ", "tmp_sec", "=", "self", ".", "m_config", "[", "section_name", "]", "\n", "# search a specific section", "\n", "if", "config_type", "==", "'int'", ":", "\n", "                ", "tmp_value", "=", "tmp_sec", ".", "getint", "(", "keyword", ",", "fallback", "=", "None", ")", "\n", "", "elif", "config_type", "==", "'float'", ":", "\n", "                ", "tmp_value", "=", "tmp_sec", ".", "getfloat", "(", "keyword", ",", "fallback", "=", "None", ")", "\n", "", "elif", "config_type", "==", "'bool'", ":", "\n", "                ", "tmp_value", "=", "tmp_sec", ".", "getboolean", "(", "keyword", ",", "fallback", "=", "None", ")", "\n", "", "else", ":", "\n", "                ", "tmp_value", "=", "tmp_sec", ".", "get", "(", "keyword", ",", "fallback", "=", "None", ")", "\n", "", "", "else", ":", "\n", "            ", "nii_display", ".", "f_die", "(", "\"Unknown section %s\"", "%", "(", "section_name", ")", ")", "\n", "", "return", "tmp_value", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.config_parse.arg_parse.f_args_parsed": [[26, 214], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "f_args_parsed", "(", "argument_input", "=", "None", ")", ":", "\n", "    ", "\"\"\" Arg_parse\n    \"\"\"", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'General argument parse'", ")", "\n", "\n", "######", "\n", "# lib", "\n", "mes", "=", "'module of model definition (default model, model.py will be loaded)'", "\n", "parser", ".", "add_argument", "(", "'--module-model'", ",", "type", "=", "str", ",", "default", "=", "\"model\"", ",", "help", "=", "mes", ")", "\n", "\n", "mes", "=", "'module of configuration (default config, config.py will be loaded)'", "\n", "parser", ".", "add_argument", "(", "'--module-config'", ",", "type", "=", "str", ",", "default", "=", "\"config\"", ",", "\n", "help", "=", "mes", ")", "\n", "\n", "######", "\n", "# Training settings    ", "\n", "mes", "=", "'batch size for training/inference (default: 1)'", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "mes", ")", "\n", "\n", "mes", "=", "'number of epochs to train (default: 50)'", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "mes", ")", "\n", "\n", "mes", "=", "'number of no-best epochs for early stopping (default: 5)'", "\n", "parser", ".", "add_argument", "(", "'--no-best-epochs'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "mes", ")", "\n", "\n", "mes", "=", "'sampler (default: None). Default sampler is random shuffler'", "\n", "mes", "+=", "'default'", "\n", "parser", ".", "add_argument", "(", "'--sampler'", ",", "type", "=", "str", ",", "default", "=", "'None'", ",", "help", "=", "mes", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.0001", ",", "\n", "help", "=", "'learning rate (default: 0.0001)'", ")", "\n", "\n", "mes", "=", "'learning rate decaying factor, using '", "\n", "mes", "+=", "'torch.optim.lr_scheduler.ReduceLROnPlateau(patience=no-best-epochs,'", "\n", "mes", "+=", "' factor=lr-decay-factor). By default, no decaying is used.'", "\n", "mes", "+=", "' Training stopped after --no-best-epochs.'", "\n", "parser", ".", "add_argument", "(", "'--lr-decay-factor'", ",", "type", "=", "float", ",", "default", "=", "-", "1.0", ",", "help", "=", "mes", ")", "\n", "\n", "\n", "mes", "=", "'L2 penalty on weight (default: not use). '", "\n", "mes", "+=", "'It corresponds to the weight_decay option in Adam'", "\n", "parser", ".", "add_argument", "(", "'--l2-penalty'", ",", "type", "=", "float", ",", "default", "=", "-", "1.0", ",", "help", "=", "mes", ")", "\n", "\n", "mes", "=", "'gradient norm (torch.nn.utils.clip_grad_norm_ of Pytorch)'", "\n", "mes", "+=", "'default (-1, not use)'", "\n", "parser", ".", "add_argument", "(", "'--grad-clip-norm'", ",", "type", "=", "float", ",", "default", "=", "-", "1.0", ",", "\n", "help", "=", "mes", ")", "\n", "\n", "mes", "=", "'lr scheduler: 0: ReduceLROnPlateau (default); 1: StepLR; '", "\n", "mes", "+=", "'this option is set on only when --lr-decay-factor > 0. '", "\n", "mes", "+=", "'Please check core_scripts/op_manager/lr_scheduler.py '", "\n", "mes", "+=", "'for detailed hyper config for each type of lr scheduler'", "\n", "parser", ".", "add_argument", "(", "'--lr-scheduler-type'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "mes", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--no-cuda'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'disables CUDA training'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'random seed (default: 1)'", ")", "\n", "\n", "mes", "=", "'turn model.eval() on validation set (default: false)'", "\n", "parser", ".", "add_argument", "(", "'--eval-mode-for-validation'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "mes", ")", "\n", "\n", "mes", "=", "'if model.forward(input, target), please set this option on. '", "\n", "mes", "+=", "'This is used for autoregressive model, auto-encoder, and so on. '", "\n", "mes", "+=", "'When --model-forward-with-file-name is also on, '", "\n", "mes", "+=", "'model.forward(input, target, file_name) should be defined'", "\n", "parser", ".", "add_argument", "(", "'--model-forward-with-target'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "mes", ")", "\n", "\n", "mes", "=", "'if model.forward(input, file_name), please set option on. '", "\n", "mes", "+=", "'This is used with forward requires file name of the data. '", "\n", "mes", "+=", "'When --model-forward-with-target is also on, '", "\n", "mes", "+=", "'model.forward(input, target, file_name) should be defined'", "\n", "parser", ".", "add_argument", "(", "'--model-forward-with-file-name'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "mes", ")", "\n", "\n", "mes", "=", "'shuffle data? (default true). Set --shuffle will turn off shuffling'", "\n", "parser", ".", "add_argument", "(", "'--shuffle'", ",", "action", "=", "'store_false'", ",", "default", "=", "True", ",", "help", "=", "mes", ")", "\n", "\n", "mes", "=", "'number of parallel workers to load data (default: 0)'", "\n", "parser", ".", "add_argument", "(", "'--num-workers'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "mes", ")", "\n", "\n", "mes", "=", "'use DataParallel to levarage multiple GPU (default: False)'", "\n", "parser", ".", "add_argument", "(", "'--multi-gpu-data-parallel'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "mes", ")", "\n", "\n", "mes", "=", "'way to concatenate multiple datasets: '", "\n", "mes", "+=", "'concatenate: simply merge two datasets as one large dataset. '", "\n", "mes", "+=", "'batch_merge: make a minibatch by drawing one sample from each set. '", "\n", "mes", "+=", "'(default: concatenate)'", "\n", "parser", ".", "add_argument", "(", "'--way-to-merge-datasets'", ",", "type", "=", "str", ",", "default", "=", "'concatenate'", ",", "help", "=", "mes", ")", "\n", "######", "\n", "# options to save model / checkpoint", "\n", "parser", ".", "add_argument", "(", "'--save-model-dir'", ",", "type", "=", "str", ",", "default", "=", "\"./\"", ",", "help", "=", "'save model to this direcotry (default ./)'", ")", "\n", "\n", "mes", "=", "'do not save model after every epoch (default: False)'", "\n", "parser", ".", "add_argument", "(", "'--not-save-each-epoch'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "mes", ")", "\n", "\n", "mes", "=", "'name prefix of saved model (default: epoch)'", "\n", "parser", ".", "add_argument", "(", "'--save-epoch-name'", ",", "type", "=", "str", ",", "default", "=", "\"epoch\"", ",", "help", "=", "mes", ")", "\n", "\n", "mes", "=", "'name of trained model (default: trained_network)'", "\n", "parser", ".", "add_argument", "(", "'--save-trained-name'", ",", "type", "=", "str", ",", "default", "=", "\"trained_network\"", ",", "help", "=", "mes", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--save-model-ext'", ",", "type", "=", "str", ",", "default", "=", "\".pt\"", ",", "\n", "help", "=", "'extension name of model (default: .pt)'", ")", "\n", "\n", "#######", "\n", "# options to load model", "\n", "mes", "=", "'a trained model for inference or resume training '", "\n", "parser", ".", "add_argument", "(", "'--trained-model'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "mes", "+", "\"(default: '')\"", ")", "\n", "\n", "mes", "=", "'do not load previous training error information.'", "\n", "mes", "+=", "\" Load only model para. and optimizer state  (default: false)\"", "\n", "parser", ".", "add_argument", "(", "'--ignore-training-history-in-trained-model'", ",", "\n", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "mes", ")", "\n", "\n", "mes", "=", "'do not load previous training statistics in optimizer.'", "\n", "mes", "+=", "\" (default: false)\"", "\n", "parser", ".", "add_argument", "(", "'--ignore-optimizer-statistics-in-trained-model'", ",", "\n", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "mes", ")", "\n", "\n", "mes", "=", "'run inference mode (default: False, run training script)'", "\n", "parser", ".", "add_argument", "(", "'--inference'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "mes", ")", "\n", "#######", "\n", "# options to output", "\n", "mes", "=", "'path to save generated data (default: ./output)'", "\n", "parser", ".", "add_argument", "(", "'--output-dir'", ",", "type", "=", "str", ",", "default", "=", "\"./output\"", ",", "help", "=", "mes", ")", "\n", "mes", "=", "'which optimizer to use (Adam | SGD, default: Adam)'", "\n", "parser", ".", "add_argument", "(", "'--optimizer'", ",", "type", "=", "str", ",", "default", "=", "'Adam'", ",", "help", "=", "mes", ")", "\n", "\n", "mes", "=", "'verbose level 0: nothing; 1: print error per utterance'", "\n", "mes", "=", "mes", "+", "' (default: 1)'", "\n", "parser", ".", "add_argument", "(", "'--verbose'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "mes", ")", "\n", "\n", "#######", "\n", "# options for user defined ", "\n", "mes", "=", "'a temporary flag without specific purpose.'", "\n", "mes", "+=", "'User should define args.temp_flag only for temporary usage.'", "\n", "parser", ".", "add_argument", "(", "'--temp-flag'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "mes", ")", "\n", "\n", "#######", "\n", "# backend options", "\n", "parser", ".", "add_argument", "(", "'--cudnn-deterministic-toggle'", ",", "action", "=", "'store_false'", ",", "default", "=", "True", ",", "\n", "help", "=", "'use cudnn-deterministic? (default true)'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--cudnn-benchmark-toggle'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'use cudnn-benchmark? (default false)'", ")", "\n", "\n", "\n", "#######", "\n", "# data options", "\n", "mes", "=", "'option to set silence_handler on waveform data.\\n'", "\n", "mes", "+=", "' 0: do nothing, use the data as it is (default) \\n'", "\n", "mes", "+=", "' 1: remove segments with small energy, use other segments\\n'", "\n", "mes", "+=", "' 2: keep only segments with small energy, remove other segments\\n'", "\n", "mes", "+=", "'Code in core_scripts.data_io.wav_tools.silence_handler. '", "\n", "mes", "+=", "'This option is used when input or output contains only waveform. '", "\n", "mes", "+=", "'It only process waveform. Other features will not be trimmed.'", "\n", "parser", ".", "add_argument", "(", "'--opt-wav-silence-handler'", ",", "type", "=", "int", ",", "\n", "default", "=", "0", ",", "help", "=", "mes", ")", "\n", "\n", "\n", "#", "\n", "# done", "\n", "if", "argument_input", "is", "not", "None", ":", "\n", "        ", "return", "parser", ".", "parse_args", "(", "argument_input", ")", "\n", "", "else", ":", "\n", "        ", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.data_warehouse.DataEntry.__init__": [[23, 34], ["data_warehouse.DataEntry._parse_tag"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.data_warehouse.DataEntry._parse_tag"], ["def", "__init__", "(", "self", ",", "data", ",", "tags", ",", "comment", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"DataEntry(data, tags, comment)\n        \n        args: \n          data: any kind of python object\n          tags: list of str, tags of the data entry\n          comment: coment\n        \"\"\"", "\n", "self", ".", "data_value", "=", "data", "\n", "self", ".", "tags", "=", "self", ".", "_parse_tag", "(", "tags", ")", "\n", "self", ".", "comment", "=", "comment", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.data_warehouse.DataEntry._parse_tag": [[35, 40], ["enumerate"], "methods", ["None"], ["", "def", "_parse_tag", "(", "self", ",", "tags", ")", ":", "\n", "        ", "\"\"\"[tag_1, tag_2, tag_3] -> {1: tag1, 2: tag2, 3: tag3}\n        \"\"\"", "\n", "temp", "=", "{", "x", ":", "y", "for", "x", ",", "y", "in", "enumerate", "(", "tags", ")", "}", "\n", "return", "temp", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.data_warehouse.DataEntry.get_value": [[41, 43], ["None"], "methods", ["None"], ["", "def", "get_value", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "data_value", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.data_warehouse.DataEntry.get_tag": [[44, 46], ["None"], "methods", ["None"], ["", "def", "get_tag", "(", "self", ",", "tag_idx", ")", ":", "\n", "        ", "return", "self", ".", "tags", "[", "tag_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.data_warehouse.DataEntry.check_tags": [[47, 62], ["zip"], "methods", ["None"], ["", "def", "check_tags", "(", "self", ",", "tag_indices", ",", "tag_values", ")", ":", "\n", "        ", "\"\"\"check_tags(tag_indices, tag_values)\n        check whether the specified tag is equal to the tag value\n        \n        input:\n          tag_indices: list, self.tags[tag_index] should be accessible\n          tag_values: list, self.tags[tag_index] == tag_value?\n        \n        output:\n          True: if tag_values are matched with tags if this data\n        \"\"\"", "\n", "for", "tag_idx", ",", "tag_value", "in", "zip", "(", "tag_indices", ",", "tag_values", ")", ":", "\n", "            ", "if", "self", ".", "tags", "[", "tag_idx", "]", "!=", "tag_value", ":", "\n", "                ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.data_warehouse.DataWarehouse.__init__": [[66, 78], ["data_warehouse.DataWarehouse._parse_file"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.data_warehouse.DataWarehouse._parse_file"], ["def", "__init__", "(", "self", ",", "orig_file_path", ",", "parse_value_methods", ",", "parse_tag_methods", ")", ":", "\n", "        ", "\"\"\"DataWarehouse(orig_file_path, parse_methods)\n        input:\n          orig_file_path: str, path to the original file\n          parse_methods: list of functions, to parse the data entry\n        \"\"\"", "\n", "self", ".", "file_path", "=", "orig_file_path", "\n", "self", ".", "parse_v_methods", "=", "parse_value_methods", "\n", "self", ".", "parse_t_methods", "=", "parse_tag_methods", "\n", "self", ".", "data_list", "=", "[", "]", "\n", "self", ".", "tag_list", "=", "{", "}", "\n", "self", ".", "data_entries", "=", "self", ".", "_parse_file", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.data_warehouse.DataWarehouse._parse_file": [[79, 105], ["core_scripts.other_tools.list_tools.read_list_from_text", "zip", "parse_v_method", "data_warehouse.DataEntry", "data_warehouse.DataWarehouse.data_list.append", "enumerate", "x", "data_warehouse.DataWarehouse._add_tag"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.read_list_from_text", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.data_warehouse.DataWarehouse._add_tag"], ["", "def", "_parse_file", "(", "self", ")", ":", "\n", "# load list", "\n", "        ", "data_content", "=", "list_tools", ".", "read_list_from_text", "(", "self", ".", "file_path", ")", "\n", "\n", "for", "data_entry", "in", "data_content", ":", "\n", "# iterate over parse methods", "\n", "            ", "for", "parse_v_method", ",", "parse_t_method", "in", "zip", "(", "self", ".", "parse_v_methods", ",", "self", ".", "parse_t_methods", ")", ":", "\n", "\n", "# get value", "\n", "                ", "data_value", "=", "parse_v_method", "(", "data_entry", ")", "\n", "# get tag", "\n", "tags", "=", "[", "x", "(", "data_entry", ")", "for", "x", "in", "parse_t_method", "]", "\n", "\n", "# skip invalid line", "\n", "if", "data_value", "is", "None", "or", "None", "in", "tags", ":", "\n", "                    ", "continue", "\n", "\n", "# create data entry", "\n", "", "tmp_data_entry", "=", "DataEntry", "(", "data_value", ",", "tags", ")", "\n", "self", ".", "data_list", ".", "append", "(", "tmp_data_entry", ")", "\n", "\n", "# add tag to the self.tag_list", "\n", "for", "tag_id", ",", "tag_val", "in", "enumerate", "(", "tags", ")", ":", "\n", "                    ", "self", ".", "_add_tag", "(", "tag_id", ",", "tag_val", ")", "\n", "", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.data_warehouse.DataWarehouse._add_tag": [[106, 114], ["data_warehouse.DataWarehouse.tag_list[].append"], "methods", ["None"], ["", "def", "_add_tag", "(", "self", ",", "tag_id", ",", "tag_val", ")", ":", "\n", "# collect all possible tags for the tag_id-th tag", "\n", "        ", "if", "tag_id", "in", "self", ".", "tag_list", ":", "\n", "            ", "if", "not", "tag_val", "in", "self", ".", "tag_list", "[", "tag_id", "]", ":", "\n", "                ", "self", ".", "tag_list", "[", "tag_id", "]", ".", "append", "(", "tag_val", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "tag_list", "[", "tag_id", "]", "=", "[", "tag_val", "]", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.data_warehouse.DataWarehouse.get_view": [[116, 134], ["x.get_value", "x.check_tags", "score_parse"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.data_warehouse.DataEntry.get_value", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.data_warehouse.DataEntry.check_tags"], ["", "def", "get_view", "(", "self", ",", "tag_idxs", ",", "tag_values", ",", "score_parse", "=", "None", ")", ":", "\n", "        ", "\"\"\" get_view(tag_idxs, tag_values, score_parse = None)\n        \n        input:\n          tag_idxs: list, the index of the tag slot to check\n          tag_values: list, the value of the tag slot to compare\n          score_parse: function, a function to extract score from entry\n        \n        output:\n          data_view: list of data\n        \"\"\"", "\n", "\n", "data_view", "=", "[", "x", ".", "get_value", "(", ")", "for", "x", "in", "self", ".", "data_list", "if", "x", ".", "check_tags", "(", "tag_idxs", ",", "tag_values", ")", "]", "\n", "if", "score_parse", "is", "not", "None", ":", "\n", "            ", "return", "[", "score_parse", "(", "x", ")", "for", "x", "in", "data_view", "]", "\n", "", "else", ":", "\n", "            ", "return", "data_view", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.data_warehouse.DataWarehouse._to_numpy": [[135, 154], ["max", "enumerate", "numpy.reshape", "numpy.ones", "enumerate", "numpy.reshape", "len", "numpy.ones", "numpy.array", "numpy.prod", "statistics", "numpy.prod", "len"], "methods", ["None"], ["", "", "def", "_to_numpy", "(", "self", ",", "data_list", ",", "dims", ",", "statistics", ")", ":", "\n", "        ", "\"\"\" convert data_list to numpy\n        \"\"\"", "\n", "# maximum length of one data entry", "\n", "max_length", "=", "max", "(", "[", "len", "(", "x", ")", "for", "x", "in", "data_list", "]", ")", "\n", "# create data array", "\n", "if", "statistics", "is", "None", ":", "\n", "            ", "data_array", "=", "np", ".", "ones", "(", "[", "np", ".", "prod", "(", "dims", ")", ",", "max_length", "]", ")", "*", "np", ".", "inf", "\n", "\n", "for", "idx", ",", "data_entry", "in", "enumerate", "(", "data_list", ")", ":", "\n", "                ", "data_array", "[", "idx", ",", "0", ":", "len", "(", "data_entry", ")", "]", "=", "np", ".", "array", "(", "data_entry", ")", "\n", "", "return", "np", ".", "reshape", "(", "data_array", ",", "dims", "+", "[", "max_length", "]", ")", "\n", "", "else", ":", "\n", "            ", "data_array", "=", "np", ".", "ones", "(", "[", "np", ".", "prod", "(", "dims", ")", "]", ")", "\n", "\n", "for", "idx", ",", "data_entry", "in", "enumerate", "(", "data_list", ")", ":", "\n", "                ", "if", "data_entry", ":", "\n", "                    ", "data_array", "[", "idx", "]", "=", "statistics", "(", "data_entry", ")", "\n", "", "", "return", "np", ".", "reshape", "(", "data_array", ",", "dims", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.data_warehouse.DataWarehouse.get_views_cross": [[156, 184], ["itertools.product", "len", "data_list.append", "data_warehouse.DataWarehouse._to_numpy", "data_warehouse.DataWarehouse.get_view"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.data_warehouse.DataWarehouse._to_numpy", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.data_warehouse.DataWarehouse.get_view"], ["", "", "def", "get_views_cross", "(", "self", ",", "tag_idxs", ",", "tag_values", ",", "\n", "score_parse", "=", "None", ",", "to_numpy", "=", "False", ",", "statistics", "=", "None", ")", ":", "\n", "        ", "\"\"\"get_views_cross(self, tag_idxs, tag_values, \n                           score_parse=None, to_numpy=False, statistics=None)\n        input:\n          tag_idxs: list, list of tag indices to check\n          tag_values: list of list, for each tag_index, \n              A list of tags will be created through this cross:\n              tag_values[0] x tag_values[1] x ... \n              \n              Then, each combination is used to retrieve the data\n              output data will be a tensor of \n                 [len(tag_values[0]), len(tag_values[1]), ...]\n          \n        output:\n           data_list:\n        \"\"\"", "\n", "data_list", "=", "[", "]", "\n", "data_mat_size", "=", "[", "len", "(", "x", ")", "for", "x", "in", "tag_values", "]", "\n", "\n", "tag_iter", "=", "itertools", ".", "product", "(", "*", "tag_values", ")", "\n", "for", "tag_ent", "in", "tag_iter", ":", "\n", "            ", "data_list", ".", "append", "(", "self", ".", "get_view", "(", "tag_idxs", ",", "tag_ent", ",", "score_parse", ")", ")", "\n", "\n", "", "if", "to_numpy", ":", "\n", "            ", "return", "self", ".", "_to_numpy", "(", "data_list", ",", "data_mat_size", ",", "statistics", ")", "\n", "", "else", ":", "\n", "            ", "return", "data_list", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.data_warehouse.DataWarehouse.get_tags": [[185, 190], ["None"], "methods", ["None"], ["", "", "def", "get_tags", "(", "self", ",", "tag_idx", ")", ":", "\n", "        ", "if", "tag_idx", "in", "self", ".", "tag_list", ":", "\n", "            ", "return", "self", ".", "tag_list", "[", "tag_idx", "]", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print": [[30, 53], ["print", "print", "print", "str", "print", "print", "str", "str", "str"], "function", ["None"], ["", "def", "f_print", "(", "message", ",", "opt", "=", "'ok'", ",", "end", "=", "'\\n'", ",", "flush", "=", "False", ")", ":", "\n", "    ", "\"\"\" f_print(message, opt)\n    Print message with specific style\n    \n    Args:\n      message: str\n      opt: str, \"warning\", \"highlight\", \"ok\", \"error\"\n    \"\"\"", "\n", "if", "opt", "==", "'warning'", ":", "\n", "        ", "print", "(", "DisplayColors", ".", "WARNING", "+", "str", "(", "message", ")", "+", "DisplayColors", ".", "ENDC", ",", "\n", "flush", "=", "flush", ",", "end", "=", "end", ")", "\n", "", "elif", "opt", "==", "'highlight'", ":", "\n", "        ", "print", "(", "DisplayColors", ".", "OKGREEN", "+", "str", "(", "message", ")", "+", "DisplayColors", ".", "ENDC", ",", "\n", "flush", "=", "flush", ",", "end", "=", "end", ")", "\n", "", "elif", "opt", "==", "'ok'", ":", "\n", "        ", "print", "(", "DisplayColors", ".", "OKBLUE", "+", "str", "(", "message", ")", "+", "DisplayColors", ".", "ENDC", ",", "\n", "flush", "=", "flush", ",", "end", "=", "end", ")", "\n", "", "elif", "opt", "==", "'error'", ":", "\n", "        ", "print", "(", "DisplayColors", ".", "FAIL", "+", "str", "(", "message", ")", "+", "DisplayColors", ".", "ENDC", ",", "\n", "flush", "=", "flush", ",", "end", "=", "end", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "message", ",", "flush", "=", "flush", ",", "end", "=", "end", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_w_date": [[54, 77], ["sys.stdout.flush", "display.f_print", "display.f_print", "display.f_print", "display.f_print", "display.f_print", "str", "datetime.datetime.now", "range", "str", "str", "len", "str", "str", "datetime.datetime.now().time", "datetime.datetime.now().time", "str", "datetime.datetime.now", "datetime.datetime.now"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print"], ["", "def", "f_print_w_date", "(", "message", ",", "level", "=", "'h'", ")", ":", "\n", "    ", "\"\"\" f_print_w_date(message, level)\n    \n    Print message with date shown\n    \n    Args: \n      message: a string\n      level: which can be 'h' (high-level), 'm' (middle-level), 'l' (low-level)\n    \"\"\"", "\n", "if", "level", "==", "'h'", ":", "\n", "        ", "message", "=", "'---  '", "+", "str", "(", "message", ")", "+", "' '", "+", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", "+", "' ---'", "\n", "tmp", "=", "''", ".", "join", "(", "[", "'-'", "for", "x", "in", "range", "(", "len", "(", "message", ")", ")", "]", ")", "\n", "f_print", "(", "tmp", ")", "\n", "f_print", "(", "message", ")", "\n", "f_print", "(", "tmp", ")", "\n", "", "elif", "level", "==", "'m'", ":", "\n", "        ", "f_print", "(", "'---'", "+", "str", "(", "message", ")", "+", "' '", "+", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "time", "(", ")", ")", "+", "'---'", ")", "\n", "", "else", ":", "\n", "        ", "f_print", "(", "str", "(", "message", ")", "+", "' '", "+", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "time", "(", ")", ")", ")", "\n", "", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die": [[78, 84], ["display.f_print", "sys.exit"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print"], ["", "def", "f_die", "(", "message", ")", ":", "\n", "    ", "\"\"\" f_die(message)\n    Print message in \"error\" mode and exit program with sys.exit(1)\n    \"\"\"", "\n", "f_print", "(", "\"Error: \"", "+", "message", ",", "'error'", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint": [[86, 91], ["print"], "function", ["None"], ["", "def", "f_eprint", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" f_eprint(*args, **kwargs)\n    Print\n    \"\"\"", "\n", "print", "(", "*", "args", ",", "file", "=", "sys", ".", "stderr", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message": [[92, 94], ["display.f_print"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print"], ["", "def", "f_print_message", "(", "message", ",", "flush", "=", "False", ",", "end", "=", "'\\n'", ")", ":", "\n", "    ", "f_print", "(", "message", ",", "'normal'", ",", "flush", "=", "flush", ",", "end", "=", "end", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.log_parser.f_read_log_err": [[21, 68], ["len", "len", "numpy.zeros", "enumerate", "print", "int", "numpy.zeros", "numpy.zeros", "range", "open", "numpy.fromstring", "numpy.fromstring", "numpy.mean", "numpy.mean", "line.count", "int", "data_str.append"], "function", ["None"], ["def", "f_read_log_err", "(", "file_path", ",", "train_num", ",", "val_num", ")", ":", "\n", "    ", "\"\"\" \n    log_train, log_val = f_read_log_err(log_err, num_train_utt, num_val_utt)\n\n    input:\n    -----\n     log_err: path to the log_err file\n     num_train_utt: how many training utterances\n     num_val_utt: how many validation utterances\n    \n    output:\n    ------\n     log_train: np.array, average error values per epoch on training set\n     log_val: np.array, average error values per epoch on valiation set\n    \"\"\"", "\n", "\n", "data_str", "=", "[", "]", "\n", "with", "open", "(", "file_path", ",", "'r'", ")", "as", "file_ptr", ":", "\n", "        ", "for", "line", "in", "file_ptr", ":", "\n", "            ", "if", "not", "line", ".", "count", "(", "'skip'", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "tmp", "=", "int", "(", "line", "[", "0", "]", ")", "\n", "data_str", ".", "append", "(", "line", ")", "\n", "", "except", "ValueError", ":", "\n", "                    ", "pass", "\n", "\n", "", "", "", "", "row", "=", "len", "(", "data_str", ")", "\n", "col", "=", "len", "(", "np", ".", "fromstring", "(", "data_str", "[", "0", "]", ",", "dtype", "=", "np", ".", "float32", ",", "sep", "=", "','", ")", ")", "\n", "\n", "data", "=", "np", ".", "zeros", "(", "[", "row", ",", "col", "]", ")", "\n", "for", "idx", ",", "line", "in", "enumerate", "(", "data_str", ")", ":", "\n", "        ", "data", "[", "idx", ",", ":", "]", "=", "np", ".", "fromstring", "(", "line", ",", "dtype", "=", "np", ".", "float32", ",", "sep", "=", "','", ")", "\n", "\n", "", "print", "(", "data", ".", "shape", "[", "0", "]", ")", "\n", "total_num", "=", "train_num", "+", "val_num", "\n", "epoch_num", "=", "int", "(", "data", ".", "shape", "[", "0", "]", "/", "total_num", ")", "\n", "data_train", "=", "np", ".", "zeros", "(", "[", "epoch_num", ",", "data", ".", "shape", "[", "1", "]", "]", ")", "\n", "data_val", "=", "np", ".", "zeros", "(", "[", "epoch_num", ",", "data", ".", "shape", "[", "1", "]", "]", ")", "\n", "\n", "for", "x", "in", "range", "(", "epoch_num", ")", ":", "\n", "        ", "temp_data", "=", "data", "[", "x", "*", "total_num", ":", "(", "x", "+", "1", ")", "*", "total_num", ",", ":", "]", "\n", "train_part", "=", "temp_data", "[", "0", ":", "train_num", ",", ":", "]", "\n", "val_part", "=", "temp_data", "[", "train_num", ":", "(", "train_num", "+", "val_num", ")", ",", ":", "]", "\n", "data_train", "[", "x", ",", ":", "]", "=", "np", ".", "mean", "(", "train_part", ",", "axis", "=", "0", ")", "\n", "data_val", "[", "x", ",", ":", "]", "=", "np", ".", "mean", "(", "val_part", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "data_train", ",", "data_val", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.log_parser.f_read_log_train": [[70, 111], ["len", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "open", "[].split", "[].split", "numpy.arange", "line.count", "float", "len", "float", "float", "data_str.append", "line.count", "line.split", "line.split", "line.split"], "function", ["None"], ["", "def", "f_read_log_train", "(", "file_path", ")", ":", "\n", "    ", "\"\"\" \n    data_train, data_val, time_per_epoch = read_log_train(path_to_log_train)\n    \n    input:\n    -----\n     path_to_log_train: path to the log_train file\n    \n    output:\n    ------\n     data_train: error values per epoch on training set\n     data_val: error values per epoch on valiation set\n     time_per_epoch: training time per epoch\n    \"\"\"", "\n", "read_flag", "=", "False", "\n", "\n", "data_str", "=", "[", "]", "\n", "with", "open", "(", "file_path", ",", "'r'", ")", "as", "file_ptr", ":", "\n", "        ", "for", "line", "in", "file_ptr", ":", "\n", "            ", "if", "read_flag", "and", "line", ".", "count", "(", "'|'", ")", ">", "2", ":", "\n", "                ", "data_str", ".", "append", "(", "line", ")", "\n", "", "if", "line", ".", "count", "(", "'Duration'", ")", ":", "\n", "                ", "read_flag", "=", "True", "\n", "\n", "", "", "", "row", "=", "len", "(", "data_str", ")", "\n", "\n", "data_train", "=", "np", ".", "zeros", "(", "[", "row", ",", "3", "]", ")", "\n", "data_val", "=", "np", ".", "zeros", "(", "[", "row", ",", "3", "]", ")", "\n", "time_per_epoch", "=", "np", ".", "zeros", "(", "row", ")", "\n", "for", "idx", ",", "line", "in", "enumerate", "(", "data_str", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "time_per_epoch", "[", "idx", "]", "=", "float", "(", "line", ".", "split", "(", "'|'", ")", "[", "1", "]", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "continue", "\n", "", "trn_data", "=", "line", ".", "split", "(", "'|'", ")", "[", "2", "]", ".", "split", "(", "'/'", ")", "\n", "val_data", "=", "line", ".", "split", "(", "'|'", ")", "[", "3", "]", ".", "split", "(", "'/'", ")", "\n", "for", "idx2", "in", "np", ".", "arange", "(", "len", "(", "trn_data", ")", ")", ":", "\n", "            ", "data_train", "[", "idx", ",", "idx2", "]", "=", "float", "(", "trn_data", "[", "idx2", "]", ")", "\n", "data_val", "[", "idx", ",", "idx2", "]", "=", "float", "(", "val_data", "[", "idx2", "]", ")", "\n", "\n", "", "", "return", "data_train", ",", "data_val", ",", "time_per_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.log_parser.read_log_err_pytorch": [[113, 176], ["print", "numpy.zeros", "numpy.zeros", "int", "line.count", "open", "print", "print", "print", "open", "numpy.zeros", "numpy.zeros", "range", "float", "log_parser.read_log_err_pytorch.set_size"], "function", ["None"], ["", "def", "read_log_err_pytorch", "(", "file_path", ",", "merge_epoch", "=", "False", ")", ":", "\n", "    ", "def", "set_size", "(", "line", ")", ":", "\n", "        ", "return", "int", "(", "line", ".", "split", "(", "'/'", ")", "[", "1", "]", ".", "split", "(", "','", ")", "[", "0", "]", ")", "\n", "", "def", "data_line", "(", "line", ")", ":", "\n", "        ", "if", "line", ".", "count", "(", "\"Time:\"", ")", ":", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "return", "False", "\n", "", "", "def", "get_data", "(", "line", ")", ":", "\n", "        ", "return", "[", "float", "(", "x", ".", "split", "(", "\":\"", ")", "[", "1", "]", ")", "for", "x", "in", "line", ".", "split", "(", "','", ")", "if", "x", ".", "count", "(", "\"Loss:\"", ")", "]", "\n", "\n", "", "trn_utt_num", "=", "None", "\n", "val_utt_num", "=", "None", "\n", "trn_total_num", "=", "0", "\n", "val_total_num", "=", "0", "\n", "with", "open", "(", "file_path", ",", "'r'", ")", "as", "file_ptr", ":", "\n", "        ", "for", "line", "in", "file_ptr", ":", "\n", "            ", "if", "not", "data_line", "(", "line", ")", ":", "\n", "                ", "continue", "\n", "", "temp_num", "=", "set_size", "(", "line", ")", "\n", "col_num", "=", "len", "(", "get_data", "(", "line", ")", ")", "\n", "if", "trn_utt_num", "is", "None", ":", "\n", "                ", "trn_utt_num", "=", "temp_num", "\n", "", "if", "temp_num", "!=", "val_utt_num", "and", "temp_num", "!=", "trn_utt_num", ":", "\n", "                ", "val_utt_num", "=", "temp_num", "\n", "", "if", "trn_utt_num", "==", "temp_num", ":", "\n", "                ", "trn_total_num", "+=", "1", "\n", "", "if", "val_utt_num", "==", "temp_num", ":", "\n", "                ", "val_total_num", "+=", "1", "\n", "\n", "", "", "", "if", "trn_utt_num", "is", "None", ":", "\n", "        ", "print", "(", "\"Cannot parse file\"", ")", "\n", "return", "\n", "", "if", "val_utt_num", "is", "None", ":", "\n", "        ", "print", "(", "\"Trn %d, no val\"", "%", "(", "trn_utt_num", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Trn %d, val %d\"", "%", "(", "trn_utt_num", ",", "val_utt_num", ")", ")", "\n", "", "print", "(", "\"Trn data %d, val data %d\"", "%", "(", "trn_total_num", ",", "val_total_num", ")", ")", "\n", "trn_data", "=", "np", ".", "zeros", "(", "[", "trn_total_num", ",", "col_num", "]", ")", "\n", "val_data", "=", "np", ".", "zeros", "(", "[", "val_total_num", ",", "col_num", "]", ")", "\n", "trn_utt_cnt", "=", "0", "\n", "val_utt_cnt", "=", "0", "\n", "with", "open", "(", "file_path", ",", "'r'", ")", "as", "file_ptr", ":", "\n", "        ", "for", "line", "in", "file_ptr", ":", "\n", "            ", "if", "not", "data_line", "(", "line", ")", ":", "\n", "                ", "continue", "\n", "", "data", "=", "get_data", "(", "line", ")", "\n", "temp_num", "=", "set_size", "(", "line", ")", "\n", "if", "trn_utt_num", "==", "temp_num", ":", "\n", "                ", "trn_data", "[", "trn_utt_cnt", ",", ":", "]", "=", "np", ".", "array", "(", "data", ")", "\n", "trn_utt_cnt", "+=", "1", "\n", "", "if", "val_utt_num", "==", "temp_num", ":", "\n", "                ", "val_data", "[", "val_utt_cnt", ",", ":", "]", "=", "np", ".", "array", "(", "data", ")", "\n", "val_utt_cnt", "+=", "1", "\n", "", "", "", "if", "merge_epoch", ":", "\n", "        ", "trn_data_new", "=", "np", ".", "zeros", "(", "[", "trn_total_num", "//", "trn_utt_num", ",", "col_num", "]", ")", "\n", "val_data_new", "=", "np", ".", "zeros", "(", "[", "val_total_num", "//", "val_utt_num", ",", "col_num", "]", ")", "\n", "for", "idx", "in", "range", "(", "min", "(", "[", "trn_total_num", "//", "trn_utt_num", ",", "val_total_num", "//", "val_utt_num", "]", ")", ")", ":", "\n", "            ", "trn_data_new", "[", "idx", ",", ":", "]", "=", "trn_data", "[", "idx", "*", "trn_utt_num", ":", "(", "idx", "+", "1", ")", "*", "trn_utt_num", ",", ":", "]", ".", "mean", "(", "axis", "=", "0", ")", "\n", "val_data_new", "[", "idx", ",", ":", "]", "=", "val_data", "[", "idx", "*", "val_utt_num", ":", "(", "idx", "+", "1", ")", "*", "val_utt_num", ",", ":", "]", ".", "mean", "(", "axis", "=", "0", ")", "\n", "", "return", "trn_data_new", ",", "val_data_new", "\n", "", "else", ":", "\n", "        ", "return", "trn_data", ",", "val_data", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.listdir_with_ext": [[20, 43], ["core_scripts.f_print", "os.path.splitext", "os.listdir", "os.path.splitext", "os.listdir", "x.startswith", "x.endswith", "x.startswith"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print"], ["def", "listdir_with_ext", "(", "file_dir", ",", "file_ext", "=", "None", ")", ":", "\n", "    ", "\"\"\" \n    file_list = lstdir_with_ext(file_dir, file_ext=None)\n    Return a list of file names with specified extention\n\n    Args:\n        file_dir: a file directory\n        file_ext: string, specify the extention, e.g., txt, bin\n    Return:\n        file_list: a list of file_names\n    \"\"\"", "\n", "try", ":", "\n", "\n", "        ", "if", "file_ext", "is", "None", ":", "\n", "            ", "file_list", "=", "[", "os", ".", "path", ".", "splitext", "(", "x", ")", "[", "0", "]", "for", "x", "in", "os", ".", "listdir", "(", "file_dir", ")", "if", "not", "x", ".", "startswith", "(", "'.'", ")", "]", "\n", "", "else", ":", "\n", "            ", "file_list", "=", "[", "os", ".", "path", ".", "splitext", "(", "x", ")", "[", "0", "]", "for", "x", "in", "os", ".", "listdir", "(", "file_dir", ")", "if", "not", "x", ".", "startswith", "(", "'.'", ")", "and", "x", ".", "endswith", "(", "file_ext", ")", "]", "\n", "", "return", "file_list", "\n", "", "except", "OSError", ":", "\n", "        ", "nii_warn", ".", "f_print", "(", "\"Cannot access %s\"", "%", "(", "file_dir", ")", ",", "\"error\"", ")", "\n", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.common_members": [[44, 58], ["list", "list.sort", "set().intersection", "set"], "function", ["None"], ["", "", "def", "common_members", "(", "list_a", ",", "list_b", ")", ":", "\n", "    ", "\"\"\" list_c = common_members(list_a, list_b)\n    Return a list (sorted) of common members in list_a, list_b\n    \n    Parameters:\n        list_a: list\n        list_b: list\n    Returns:\n        list_c: a list of common members in list_a and list_b\n    \n    \"\"\"", "\n", "list_c", "=", "list", "(", "set", "(", "list_a", ")", ".", "intersection", "(", "list_b", ")", ")", "\n", "list_c", ".", "sort", "(", ")", "\n", "return", "list_c", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_identical": [[60, 66], ["collections.Counter", "collections.Counter"], "function", ["None"], ["", "def", "list_identical", "(", "list_a", ",", "list_b", ")", ":", "\n", "    ", "\"\"\" flag = list_identical(list_a, list_b)\n    Return true/false, check whether list_a is identical to list_b\n    stackoverflow.com/a/19244156/403423\n    \"\"\"", "\n", "return", "collections", ".", "Counter", "(", "list_a", ")", "==", "collections", ".", "Counter", "(", "list_b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.list_b_in_list_a": [[67, 78], ["set", "set"], "function", ["None"], ["", "def", "list_b_in_list_a", "(", "list_a", ",", "list_b", ")", ":", "\n", "    ", "\"\"\" list_b_in_list_a(list_a, list_b)\n    Whether list_b is subset of list_a\n\n    Parameters:\n        list_a: list\n        list_b: list\n    Return: \n        flag: bool\n    \"\"\"", "\n", "return", "set", "(", "list_b", ")", "<=", "set", "(", "list_a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.members_in_a_not_in_b": [[79, 90], ["list", "set", "set"], "function", ["None"], ["", "def", "members_in_a_not_in_b", "(", "list_a", ",", "list_b", ")", ":", "\n", "    ", "\"\"\" members_in_a_not_b(list_a, list_b):\n    Return a list of members that are in list_a but not in list_b\n    \n    Args:\n        list_a: list\n        list_b: list\n    Return: \n        list\n    \"\"\"", "\n", "return", "list", "(", "set", "(", "list_a", ")", "-", "set", "(", "list_b", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.read_list_from_text": [[91, 108], ["open", "data.append", "core_scripts.string_chop"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.string_chop"], ["", "def", "read_list_from_text", "(", "filename", ",", "f_chop", "=", "True", ")", ":", "\n", "    ", "\"\"\"out_list = read_list_from_text(filename, f_chop=True)\n    Read a text file and return a list, where each text line is one element\n    \n    Args:\n      filename: str, path to the file\n      f_chop: bool, whether trim the newline symbol at the end of each line\n              (default True)\n    Return:\n      output_list: list, each element is one line in the input text file\n    \"\"\"", "\n", "data", "=", "[", "]", "\n", "with", "open", "(", "filename", ",", "'r'", ")", "as", "file_ptr", ":", "\n", "        ", "for", "line", "in", "file_ptr", ":", "\n", "            ", "line", "=", "nii_str_tool", ".", "string_chop", "(", "line", ")", "if", "f_chop", "else", "line", "\n", "data", ".", "append", "(", "line", ")", "\n", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.list_tools.write_list_to_text_file": [[109, 128], ["open", "type", "file_ptr.write", "file_ptr.write", "str"], "function", ["None"], ["", "def", "write_list_to_text_file", "(", "data_list", ",", "filepath", ",", "endl", "=", "'\\n'", ")", ":", "\n", "    ", "\"\"\"write_list_to_text(data_list, filepath, endl='\\n')              \n    Save a list of data to a text file                                 \n                                                                       \n    Args:                                                              \n      data_list: list, data list to be saved                           \n      filepath: str, path to the output text file                      \n      endl: str, ending of each new line, default \\n                   \n                                                                       \n    If each element in data_list is not str, it will be converted to   \n    str by str().                                                      \n    \"\"\"", "\n", "with", "open", "(", "filepath", ",", "'w'", ")", "as", "file_ptr", ":", "\n", "        ", "for", "data_entry", "in", "data_list", ":", "\n", "            ", "if", "type", "(", "data_entry", ")", "is", "str", ":", "\n", "                ", "file_ptr", ".", "write", "(", "data_entry", "+", "endl", ")", "\n", "", "else", ":", "\n", "                ", "file_ptr", ".", "write", "(", "str", "(", "data_entry", ")", "+", "endl", ")", "\n", "", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.debug.data_probe.__init__": [[91, 103], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "# a list to store all intermediate data", "\n", "        ", "self", ".", "data_buf", "=", "[", "]", "\n", "# a single array to store the data", "\n", "self", ".", "data_concated", "=", "None", "\n", "# default data convert method", "\n", "self", ".", "data_convert_method", "=", "convert_data_for_debug", "\n", "# default method to dump method", "\n", "self", ".", "data_dump_method", "=", "nii_io", ".", "pickle_dump", "\n", "# dump file name extension", "\n", "self", ".", "dump_file_ext", "=", "'.pkl'", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.debug.data_probe.add_data": [[104, 115], ["debug.data_probe.data_buf.append", "debug.data_probe.data_convert_method"], "methods", ["None"], ["", "def", "add_data", "(", "self", ",", "input_data", ")", ":", "\n", "        ", "\"\"\" add_data(input_data)\n        Add the input data to a data list. Data will be automatically\n        converted by self.data_convert_method\n\n        input\n        -----\n          input_data: tensor, or numpy.array        \n        \"\"\"", "\n", "self", ".", "data_buf", ".", "append", "(", "self", ".", "data_convert_method", "(", "input_data", ")", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.debug.data_probe._merge_data": [[116, 124], ["numpy.concatenate"], "methods", ["None"], ["", "def", "_merge_data", "(", "self", ")", ":", "\n", "        ", "\"\"\" merge_data()\n        Merge the data in the list to a big numpy array table.\n        Follow the convention of this project, we assume data has shape\n        (batchsize, length, feat_dim)\n        \"\"\"", "\n", "self", ".", "data_concated", "=", "np", ".", "concatenate", "(", "self", ".", "data_buf", ",", "axis", "=", "1", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.debug.data_probe._dump_file_path": [[125, 130], ["datetime.datetime.now().strftime", "datetime.datetime.now"], "methods", ["None"], ["", "def", "_dump_file_path", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "\"\"\" add additional infor to the ump file path\n        \"\"\"", "\n", "time_tag", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%Y%m%d%H%M%S\"", ")", "\n", "return", "file_path", "+", "'_'", "+", "time_tag", "+", "self", ".", "dump_file_ext", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.debug.data_probe.dump": [[131, 154], ["debug.data_probe._dump_file_path", "debug.data_probe.data_dump_method", "print", "os.mkdir", "os.path.dirname"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.debug.data_probe._dump_file_path"], ["", "def", "dump", "(", "self", ",", "output_path", "=", "'./debug/data_dump'", ")", ":", "\n", "        ", "\"\"\" dump(output_path='./debug/data_dump')\n        input\n        -----\n          output_path: str, path to store the dumped data\n        \"\"\"", "\n", "# add additional infor to output_path name", "\n", "output_path_new", "=", "self", ".", "_dump_file_path", "(", "output_path", ")", "\n", "try", ":", "\n", "            ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "dirname", "(", "output_path_new", ")", ")", "\n", "", "except", "OSError", ":", "\n", "            ", "pass", "\n", "\n", "## merge data if it has not been done", "\n", "#if self.data_concated is None:", "\n", "#    self.merge_data()", "\n", "#nii_io.f_write_raw_mat(self.data_concated, output_path_new)", "\n", "\n", "", "self", ".", "data_dump_method", "(", "self", ".", "data_buf", ",", "output_path_new", ")", "\n", "print", "(", "\"Data dumped to {:s}\"", ".", "format", "(", "output_path_new", ")", ")", "\n", "\n", "self", ".", "data_concated", "=", "None", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.debug.convert_data_for_debug": [[23, 43], ["hasattr", "data.detach().to().numpy", "hasattr", "data.to().numpy", "hasattr", "data.detach().to", "data.numpy", "data.to", "data.detach"], "function", ["None"], ["def", "convert_data_for_debug", "(", "data", ")", ":", "\n", "    ", "\"\"\" data_new = convert_data_for_debug(data)\n    For debugging, it is convenient to has a data in numpy format\n\n    Args\n    ----\n      data: tensor\n\n    Return\n    ------\n      data_new: numpy array\n    \"\"\"", "\n", "if", "hasattr", "(", "data", ",", "'detach'", ")", ":", "\n", "        ", "return", "data", ".", "detach", "(", ")", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "", "elif", "hasattr", "(", "data", ",", "'cpu'", ")", ":", "\n", "        ", "return", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "", "elif", "hasattr", "(", "data", ",", "'numpy'", ")", ":", "\n", "        ", "return", "data", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.debug.qw": [[44, 67], ["core_scripts.data_io.io_tools.f_write_raw_mat", "os.mkdir", "debug.convert_data_for_debug", "os.path.dirname"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.f_write_raw_mat", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.debug.convert_data_for_debug"], ["", "", "def", "qw", "(", "data", ",", "path", "=", "None", ")", ":", "\n", "    ", "\"\"\" write data tensor into a temporary buffer\n    \n    Args\n    ----\n      data: a pytorch tensor or numpy tensor\n      path: str, path to be write the data\n            if None, it will be \"./debug/temp.bin\"\n    Return\n    ------\n      None\n    \"\"\"", "\n", "if", "path", "is", "None", ":", "\n", "        ", "path", "=", "'debug/temp.bin'", "\n", "\n", "", "try", ":", "\n", "        ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "dirname", "(", "path", ")", ")", "\n", "", "except", "OSError", ":", "\n", "        ", "pass", "\n", "\n", "# write to IO", "\n", "", "nii_io", ".", "f_write_raw_mat", "(", "convert_data_for_debug", "(", "data", ")", ",", "path", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.debug.check_para": [[68, 85], ["print", "print", "p.mean", "p.std", "numpy.array", "numpy.array", "pt_model.parameters", "pt_model.parameters", "debug.convert_data_for_debug", "debug.convert_data_for_debug"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.debug.convert_data_for_debug", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.debug.convert_data_for_debug"], ["", "def", "check_para", "(", "pt_model", ")", ":", "\n", "    ", "\"\"\" check_para(pt_model)\n    Quickly check the statistics on the parameters of the model\n    \n    Args\n    ----\n      pt_model: a Pytorch model defined based on torch.nn.Module\n    \n    Return\n    ------\n      None\n    \"\"\"", "\n", "mean_buf", "=", "[", "p", ".", "mean", "(", ")", "for", "p", "in", "pt_model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "std_buf", "=", "[", "p", ".", "std", "(", ")", "for", "p", "in", "pt_model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "print", "(", "np", ".", "array", "(", "[", "convert_data_for_debug", "(", "x", ")", "for", "x", "in", "mean_buf", "]", ")", ")", "\n", "print", "(", "np", ".", "array", "(", "[", "convert_data_for_debug", "(", "x", ")", "for", "x", "in", "std_buf", "]", ")", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.f_realpath": [[17, 33], ["os.path.join", "f_ext.startswith"], "function", ["None"], ["def", "f_realpath", "(", "f_dir", ",", "f_name", ",", "f_ext", ")", ":", "\n", "    ", "\"\"\" file_path = f_realpath(f_dir, f_name, f_ext)\n    Args:\n      f_dir: string, directory\n      f_name: string, file name\n      f_ext: string, file name extension\n\n    Return:\n      file_path: realpath     \n    \"\"\"", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "f_dir", ",", "f_name", ")", "\n", "if", "f_ext", ".", "startswith", "(", "os", ".", "extsep", ")", ":", "\n", "        ", "file_path", "=", "file_path", "+", "f_ext", "\n", "", "else", ":", "\n", "        ", "file_path", "=", "file_path", "+", "os", ".", "extsep", "+", "f_ext", "\n", "", "return", "file_path", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.str_tools.string_chop": [[34, 53], ["len", "ord", "ord", "len", "ord"], "function", ["None"], ["", "def", "string_chop", "(", "InStr", ")", ":", "\n", "    ", "\"\"\" output = string_chop(InStr)\n    Chop the ending '\\r' and '\\n' from input string\n    \n    Args:\n        InStr: str, the input string\n\n    Return:\n        output: str\n    \n    '\\r' corresponds to '0x0d' or 13,\n    '\\n' corresponds to '0x0a' or 10                               \n    \"\"\"", "\n", "if", "len", "(", "InStr", ")", ">=", "2", "and", "ord", "(", "InStr", "[", "-", "1", "]", ")", "==", "10", "and", "ord", "(", "InStr", "[", "-", "2", "]", ")", "==", "13", ":", "\n", "        ", "return", "InStr", "[", ":", "-", "2", "]", "\n", "", "elif", "len", "(", "InStr", ")", ">=", "1", "and", "ord", "(", "InStr", "[", "-", "1", "]", ")", "==", "10", ":", "\n", "        ", "return", "InStr", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "        ", "return", "InStr", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.random_name_mgn.RandomNameMgn.__init__": [[37, 63], ["random_name_mgn.list_loader", "print", "random_name_mgn.RandomNameMgn.print_info"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.random_name_mgn.list_loader", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.print_info"], ["def", "__init__", "(", "self", ",", "file_random_name_list", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "\"\"\" RandomNameMgn(file_random_name_list, verbose=False)\n        Create a random name manager\n        \n        Args:\n          file_random_name_list: str, path to the text file of random names.\n          verbose: bool, default False, print information during initialziation\n        \"\"\"", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "\"Loading random name tables\"", ")", "\n", "\n", "## For unused random name list", "\n", "# load entries in the list", "\n", "", "self", ".", "unused_entries", "=", "list_loader", "(", "file_random_name_list", ")", "\n", "# prepare dictionary", "\n", "self", ".", "mapper", "=", "{", "x", ":", "None", "for", "x", "in", "self", ".", "unused_entries", "}", "\n", "# reverse dictionary", "\n", "self", ".", "mapper_rev", "=", "{", "}", "\n", "\n", "# print some informaiton", "\n", "if", "verbose", ":", "\n", "            ", "self", ".", "print_info", "(", ")", "\n", "\n", "", "self", ".", "verbose", "=", "verbose", "\n", "# done", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.random_name_mgn.RandomNameMgn.print_info": [[64, 69], ["print", "len"], "methods", ["None"], ["", "def", "print_info", "(", "self", ")", ":", "\n", "        ", "mes", "=", "\"Number of unused random file names: {:d}\"", ".", "format", "(", "\n", "len", "(", "self", ".", "unused_entries", ")", ")", "\n", "print", "(", "mes", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.random_name_mgn.RandomNameMgn.retrieve_rand_name": [[70, 83], ["random_name_mgn.RandomNameMgn.unused_entries.pop"], "methods", ["None"], ["", "def", "retrieve_rand_name", "(", "self", ",", "filename", ")", ":", "\n", "        ", "\"\"\" rand_name = retrieve_rand_name(filename)\n        \n        filename: str, input, input file name\n        rand_name: str, output, the random file name\n        \"\"\"", "\n", "if", "filename", "in", "self", ".", "mapper_rev", ":", "\n", "            ", "return", "self", ".", "mapper_rev", "[", "filename", "]", "\n", "", "else", ":", "\n", "            ", "rand_name", "=", "self", ".", "unused_entries", ".", "pop", "(", ")", "\n", "self", ".", "mapper", "[", "rand_name", "]", "=", "filename", "\n", "self", ".", "mapper_rev", "[", "filename", "]", "=", "rand_name", "\n", "return", "rand_name", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.random_name_mgn.RandomNameMgn.save_unused_name": [[84, 98], ["open", "random_name_mgn.RandomNameMgn.print_info", "print", "file_ptr.write"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.print_info"], ["", "", "def", "save_unused_name", "(", "self", ",", "save_file", ")", ":", "\n", "        ", "\"\"\" save_unused_name(save_file)\n        \n        save_file: str, input, the path to save random names that\n            have NOT been used\n        \"\"\"", "\n", "with", "open", "(", "save_file", ",", "'w'", ")", "as", "file_ptr", ":", "\n", "            ", "for", "entry", "in", "self", ".", "unused_entries", ":", "\n", "                ", "file_ptr", ".", "write", "(", "entry", "+", "'\\n'", ")", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "            ", "self", ".", "print_info", "(", ")", "\n", "print", "(", "\"Save unused random names to {:s}\"", ".", "format", "(", "save_file", ")", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.random_name_mgn.RandomNameMgn.retrieve_filename": [[99, 105], ["print", "sys.exit"], "methods", ["None"], ["", "def", "retrieve_filename", "(", "self", ",", "random_name", ")", ":", "\n", "        ", "if", "random_name", "in", "self", ".", "mapper", ":", "\n", "            ", "return", "self", ".", "mapper", "[", "random_name", "]", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Random name {:s} has not been logged\"", ".", "format", "(", "random_name", ")", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.random_name_mgn.list_loader": [[18, 33], ["os.path.join", "core_scripts.data_io.io_tools.wrapper_data_load_with_cache", "os.path.dirname"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.data_io.io_tools.wrapper_data_load_with_cache"], ["def", "list_loader", "(", "list_file", ")", ":", "\n", "    ", "\"\"\" output_list = list_loader(list_file)\n    Load a text file as a list of string. This function will use __cache to save\n    the loaded list\n\n    Args:\n      list_file: str, path to the input text file\n    Return:\n      output_list: list,\n    \n    Note, a __cache will be created along list_file\n    \"\"\"", "\n", "cache_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "list_file", ")", ",", "'__cache'", ")", "\n", "return", "io_tools", ".", "wrapper_data_load_with_cache", "(", "\n", "list_file", ",", "list_tools", ".", "read_list_from_text", ",", "cache_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.script_model_para.f_model_show": [[27, 44], ["print", "sum", "print", "pt_model.named_parameters", "p.numel", "print", "pt_model.parameters", "p.numel", "str", "p.numel"], "function", ["None"], ["def", "f_model_show", "(", "pt_model", ")", ":", "\n", "    ", "\"\"\"                                                                      \n    f_model_show(pt_model)                                                   \n    Args: pt_model, a Pytorch model                                          \n                                                                             \n    Print the informaiton of the model                                       \n    \"\"\"", "\n", "#f_model_check(pt_model)", "\n", "\n", "print", "(", "pt_model", ")", "\n", "num", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "pt_model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "print", "(", "\"Parameter number: {:d}\"", ".", "format", "(", "num", ")", ")", "\n", "for", "name", ",", "p", "in", "pt_model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "p", ".", "requires_grad", ":", "\n", "            ", "print", "(", "\"Layer: {:s}\\tPara. num: {:<10d} ({:02.1f}%)\\tShape: {:s}\"", ".", "format", "(", "name", ",", "p", ".", "numel", "(", ")", ",", "p", ".", "numel", "(", ")", "*", "100.0", "/", "num", ",", "str", "(", "p", ".", "shape", ")", ")", ")", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.random_tools.f_shuffle_slice_inplace": [[25, 64], ["len", "random.randrange", "len"], "function", ["None"], ["def", "f_shuffle_slice_inplace", "(", "input_list", ",", "slice_start", "=", "None", ",", "slice_stop", "=", "None", ")", ":", "\n", "    ", "\"\"\" shuffle_slice(input_list, slice_start, slice_stop)\n    \n    Shuffling input list (in place) in the range specified by slice_start\n    and slice_stop.\n\n    Based on Knuth shuffling \n    https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle\n\n    input\n    -----\n      input_list: list\n      slice_start: int, start idx of the range to be shuffled\n      slice_end: int, end idx of the range to be shuffled\n      \n      Both slice_start and slice_end should be in the style of python index\n      e.g., shuffle_slice(input_list, 0, N) will shuffle the slice input[0:N]\n    \n      When slice_start / slice_stop is None,\n      slice_start = 0 / slice_stop = len(input_list)\n\n    output\n    ------\n      none: shuffling is done in place\n    \"\"\"", "\n", "if", "slice_start", "is", "None", "or", "slice_start", "<", "0", ":", "\n", "        ", "slice_start", "=", "0", "\n", "", "if", "slice_stop", "is", "None", "or", "slice_stop", ">", "len", "(", "input_list", ")", ":", "\n", "        ", "slice_stop", "=", "len", "(", "input_list", ")", "\n", "\n", "", "idx", "=", "slice_start", "\n", "while", "(", "idx", "<", "slice_stop", "-", "1", ")", ":", "\n", "        ", "idx_swap", "=", "random", ".", "randrange", "(", "idx", ",", "slice_stop", ")", "\n", "# naive swap", "\n", "tmp", "=", "input_list", "[", "idx_swap", "]", "\n", "input_list", "[", "idx_swap", "]", "=", "input_list", "[", "idx", "]", "\n", "input_list", "[", "idx", "]", "=", "tmp", "\n", "idx", "+=", "1", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.random_tools.f_shuffle_in_block_inplace": [[65, 98], ["len", "range", "random_tools.f_shuffle_slice_inplace"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.random_tools.f_shuffle_slice_inplace"], ["", "def", "f_shuffle_in_block_inplace", "(", "input_list", ",", "block_size", ")", ":", "\n", "    ", "\"\"\"\n    f_shuffle_in_block_inplace(input_list, block_size)\n    \n    Shuffle the input list (in place) by dividing the list input blocks and \n    shuffling within each block\n    \n    Example:\n    >>> data = [1,2,3,4,5,6]\n    >>> random_tools.f_shuffle_in_block_inplace(data, 3)\n    >>> data\n    [3, 1, 2, 5, 4, 6]\n\n    input\n    -----\n      input_list: input list\n      block_size: int\n    \n    output\n    ------\n      None: shuffling is done in place\n    \"\"\"", "\n", "if", "block_size", "<=", "1", ":", "\n", "# no need to shuffle if block size if 1", "\n", "        ", "return", "\n", "", "else", ":", "\n", "        ", "list_length", "=", "len", "(", "input_list", ")", "\n", "# range( -(- x // y) ) -> int(ceil(x / y))", "\n", "for", "iter_idx", "in", "range", "(", "-", "(", "-", "list_length", "//", "block_size", ")", ")", ":", "\n", "# shuffle within each block", "\n", "            ", "f_shuffle_slice_inplace", "(", "\n", "input_list", ",", "iter_idx", "*", "block_size", ",", "(", "iter_idx", "+", "1", ")", "*", "block_size", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.random_tools.f_shuffle_blocks_inplace": [[99, 136], ["input_list.copy", "random.shuffle", "range", "len", "range"], "function", ["None"], ["", "", "def", "f_shuffle_blocks_inplace", "(", "input_list", ",", "block_size", ")", ":", "\n", "    ", "\"\"\" \n    f_shuffle_blocks_inplace(input_list, block_size)\n    \n    Shuffle the input list (in place) by dividing the list input blocks and \n    shuffling blocks\n    \n    Example:\n     >> data = np.arange(1, 7)\n     >> f_shuffle_blocks_inplace(data, 3)\n     >> print(data)\n     [4 5 6 1 2 3]\n\n    input\n    -----\n      input_list: input list\n      block_size: int\n    \n    output\n    ------\n      None: shuffling is done in place\n    \"\"\"", "\n", "# new list", "\n", "tmp_list", "=", "input_list", ".", "copy", "(", ")", "\n", "\n", "block_number", "=", "len", "(", "input_list", ")", "//", "block_size", "\n", "\n", "shuffle_block_idx", "=", "[", "x", "for", "x", "in", "range", "(", "block_number", ")", "]", "\n", "random", ".", "shuffle", "(", "shuffle_block_idx", ")", "\n", "\n", "new_idx", "=", "None", "\n", "for", "iter_idx", "in", "range", "(", "block_size", "*", "block_number", ")", ":", "\n", "        ", "block_idx", "=", "iter_idx", "//", "block_size", "\n", "in_block_idx", "=", "iter_idx", "%", "block_size", "\n", "new_idx", "=", "shuffle_block_idx", "[", "block_idx", "]", "*", "block_size", "+", "in_block_idx", "\n", "input_list", "[", "iter_idx", "]", "=", "tmp_list", "[", "new_idx", "]", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_var2std": [[21, 38], ["numpy.sqrt"], "function", ["None"], ["def", "f_var2std", "(", "var", ")", ":", "\n", "    ", "\"\"\"\n    std = f_var2std(var)\n    Args:\n     var: np.arrary, variance\n    \n    Return:\n     std: np.array, standard-devitation\n\n    std = sqrt(variance), std[std<floor] = 1.0\n    \"\"\"", "\n", "negative_idx", "=", "var", "<", "0", "\n", "std", "=", "np", ".", "sqrt", "(", "var", ")", "\n", "std", "[", "negative_idx", "]", "=", "1.0", "\n", "floored_idx", "=", "std", "<", "nii_dconf", ".", "std_floor", "\n", "std", "[", "floored_idx", "]", "=", "1.0", "\n", "return", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.math_tools.stats.f_online_mean_std": [[40, 127], ["numpy.zeros", "numpy.zeros", "data.mean", "data.var", "data.mean", "data.var", "float", "core_scripts.f_print", "core_scripts.f_die", "core_scripts.f_print", "core_scripts.f_die", "float", "float", "float", "float"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die"], ["", "def", "f_online_mean_std", "(", "data", ",", "mean_old", ",", "var_old", ",", "cnt_old", ")", ":", "\n", "    ", "\"\"\" \n    mean, var, count=f_online_mean_var(data, mean, var, num_count):\n    \n    online algorithm to accumulate mean and var\n    \n    Args:\n      data: input data as numpy.array, in shape [length, dimension]\n    \n      mean: mean to be updated, np.array [dimension]\n\n      var: var to be updated, np.array [dimension]\n\n      num_count: how many data rows have been calculated before \n        this calling.\n\n    Return:\n      mean: mean, np.array [dimension]\n      var: var, np.array [dimension]\n      count: accumulated data number, = num_count + data.shape[0]\n\n    Ref. parallel algorithm                                                 \n    https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance  \n    \"\"\"", "\n", "\n", "try", ":", "\n", "# how many time steps (number of rows) in this data", "\n", "        ", "cnt_this", "=", "data", ".", "shape", "[", "0", "]", "\n", "\n", "# if input data is empty, don't update", "\n", "if", "cnt_this", "==", "0", ":", "\n", "            ", "return", "mean_old", ",", "var_old", ",", "cnt_old", "\n", "\n", "", "if", "data", ".", "ndim", "==", "1", ":", "\n", "# single dimension data, 1d array", "\n", "            ", "mean_this", "=", "data", ".", "mean", "(", ")", "\n", "var_this", "=", "data", ".", "var", "(", ")", "\n", "dim", "=", "1", "\n", "", "else", ":", "\n", "# multiple dimension data, 2d array", "\n", "            ", "mean_this", "=", "data", ".", "mean", "(", "axis", "=", "0", ")", "\n", "var_this", "=", "data", ".", "var", "(", "axis", "=", "0", ")", "\n", "dim", "=", "data", ".", "shape", "[", "1", "]", "\n", "\n", "# difference of accumulated mean and data mean", "\n", "", "diff_mean", "=", "mean_this", "-", "mean_old", "\n", "\n", "# new mean and var", "\n", "new_mean", "=", "np", ".", "zeros", "(", "[", "dim", "]", ",", "dtype", "=", "nii_dconf", ".", "h_dtype", ")", "\n", "new_var", "=", "np", ".", "zeros", "(", "[", "dim", "]", ",", "dtype", "=", "nii_dconf", ".", "h_dtype", ")", "\n", "\n", "# update count", "\n", "updated_count", "=", "cnt_old", "+", "cnt_this", "\n", "\n", "# update mean", "\n", "new_mean", "=", "mean_old", "+", "diff_mean", "*", "(", "float", "(", "cnt_this", ")", "/", "\n", "(", "cnt_old", "+", "cnt_this", ")", ")", "\n", "# update var", "\n", "if", "cnt_old", "==", "0", ":", "\n", "# if this is the first data", "\n", "            ", "if", "data", ".", "ndim", "==", "1", ":", "\n", "# remember that var is array, not scalar", "\n", "                ", "new_var", "[", "0", "]", "=", "var_this", "\n", "", "else", ":", "\n", "                ", "new_var", "=", "var_this", "\n", "", "", "else", ":", "\n", "# not first data", "\n", "            ", "new_var", "=", "(", "var_old", "*", "(", "float", "(", "cnt_old", ")", "/", "updated_count", ")", "\n", "+", "var_this", "*", "(", "float", "(", "cnt_this", ")", "/", "updated_count", ")", "\n", "+", "(", "diff_mean", "*", "diff_mean", "\n", "/", "(", "float", "(", "cnt_this", ")", "/", "cnt_old", "\n", "+", "float", "(", "cnt_old", ")", "/", "cnt_this", "\n", "+", "2.0", ")", ")", ")", "\n", "# done", "\n", "", "return", "new_mean", ",", "new_var", ",", "updated_count", "\n", "\n", "", "except", "ValueError", ":", "\n", "        ", "if", "data", ".", "ndim", ">", "1", ":", "\n", "            ", "if", "data", ".", "shape", "[", "1", "]", "!=", "mean_old", ".", "shape", "[", "0", "]", "or", "data", ".", "shape", "[", "1", "]", "!=", "var_old", ".", "shape", "[", "0", "]", ":", "\n", "                ", "nii_display", ".", "f_print", "(", "\"Dimension incompatible\"", ",", "\"error\"", ")", "\n", "nii_display", ".", "f_die", "(", "\"Error in online mean var calculation\"", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "mean_old", ".", "shape", "[", "0", "]", "!=", "1", "or", "var_old", ".", "shape", "[", "0", "]", "!=", "1", ":", "\n", "                ", "nii_display", ".", "f_print", "(", "\"Dimension incompatible\"", ",", "\"error\"", ")", "\n", "nii_display", ".", "f_die", "(", "\"Error in online mean var calculation\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.__init__": [[25, 35], ["numpy.zeros", "numpy.zeros"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "epoch_num", ",", "seq_num", ")", ":", "\n", "        ", "self", ".", "loss_mat", "=", "np", ".", "zeros", "(", "[", "epoch_num", ",", "seq_num", ",", "1", "]", ")", "\n", "self", ".", "time_mat", "=", "np", ".", "zeros", "(", "[", "epoch_num", ",", "seq_num", "]", ")", "\n", "self", ".", "seq_names", "=", "{", "}", "\n", "self", ".", "epoch_num", "=", "epoch_num", "\n", "self", ".", "seq_num", "=", "seq_num", "\n", "self", ".", "cur_epoch", "=", "0", "\n", "self", ".", "best_error", "=", "None", "\n", "self", ".", "best_epoch", "=", "None", "\n", "self", ".", "loss_flag", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.clear": [[36, 44], ["op_process_monitor.Monitor.loss_mat.fill", "op_process_monitor.Monitor.time_mat.fill"], "methods", ["None"], ["", "def", "clear", "(", "self", ")", ":", "\n", "        ", "self", ".", "loss_mat", ".", "fill", "(", "0", ")", "\n", "self", ".", "time_mat", ".", "fill", "(", "0", ")", "\n", "self", ".", "cur_epoch", "=", "0", "\n", "self", ".", "seq_names", "=", "{", "}", "\n", "self", ".", "best_error", "=", "None", "\n", "self", ".", "best_epoch", "=", "None", "\n", "self", ".", "loss_flag", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.get_state_dic": [[45, 59], ["None"], "methods", ["None"], ["", "def", "get_state_dic", "(", "self", ")", ":", "\n", "        ", "\"\"\" create a dictionary to save process\n        \"\"\"", "\n", "state_dic", "=", "{", "}", "\n", "state_dic", "[", "'loss_mat'", "]", "=", "self", ".", "loss_mat", "\n", "state_dic", "[", "'time_mat'", "]", "=", "self", ".", "time_mat", "\n", "state_dic", "[", "'epoch_num'", "]", "=", "self", ".", "epoch_num", "\n", "state_dic", "[", "'seq_num'", "]", "=", "self", ".", "seq_num", "\n", "state_dic", "[", "'cur_epoch'", "]", "=", "self", ".", "cur_epoch", "\n", "state_dic", "[", "'best_error'", "]", "=", "self", ".", "best_error", "\n", "state_dic", "[", "'best_epoch'", "]", "=", "self", ".", "best_epoch", "\n", "state_dic", "[", "'loss_flag'", "]", "=", "self", ".", "loss_flag", "\n", "# no need to save self.seq_names", "\n", "return", "state_dic", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.load_state_dic": [[60, 94], ["core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_die", "numpy.resize", "core_scripts.f_die"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die"], ["", "def", "load_state_dic", "(", "self", ",", "state_dic", ")", ":", "\n", "        ", "\"\"\" resume training, load the information\n        \"\"\"", "\n", "try", ":", "\n", "            ", "if", "self", ".", "seq_num", "!=", "state_dic", "[", "'seq_num'", "]", ":", "\n", "                ", "nii_display", ".", "f_print", "(", "\"Number of samples are different \\\n                from previous training\"", ",", "'error'", ")", "\n", "nii_display", ".", "f_print", "(", "\"Please make sure that you are \\\n                using the same training/development sets as before.\"", ",", "\"error\"", ")", "\n", "nii_display", ".", "f_print", "(", "\"Or\\nPlease add --\"", ")", "\n", "nii_display", ".", "f_print", "(", "\"ignore_training_history_in_trained_model\"", ")", "\n", "nii_display", ".", "f_die", "(", "\" to avoid loading training history\"", ")", "\n", "\n", "", "if", "self", ".", "epoch_num", "==", "state_dic", "[", "'epoch_num'", "]", ":", "\n", "                ", "self", ".", "loss_mat", "=", "state_dic", "[", "'loss_mat'", "]", "\n", "self", ".", "time_mat", "=", "state_dic", "[", "'time_mat'", "]", "\n", "", "else", ":", "\n", "# if training epoch is increased, resize the shape", "\n", "                ", "tmp_loss_mat", "=", "state_dic", "[", "'loss_mat'", "]", "\n", "self", ".", "loss_mat", "=", "np", ".", "resize", "(", "\n", "self", ".", "loss_mat", ",", "\n", "[", "self", ".", "epoch_num", ",", "self", ".", "seq_num", ",", "tmp_loss_mat", ".", "shape", "[", "2", "]", "]", ")", "\n", "self", ".", "loss_mat", "[", "0", ":", "tmp_loss_mat", ".", "shape", "[", "0", "]", "]", "=", "tmp_loss_mat", "\n", "self", ".", "time_mat", "[", "0", ":", "tmp_loss_mat", ".", "shape", "[", "0", "]", "]", "=", "state_dic", "[", "'time_mat'", "]", "\n", "\n", "", "self", ".", "seq_num", "=", "state_dic", "[", "'seq_num'", "]", "\n", "# since the saved cur_epoch has been finished", "\n", "self", ".", "cur_epoch", "=", "state_dic", "[", "'cur_epoch'", "]", "+", "1", "\n", "self", ".", "best_error", "=", "state_dic", "[", "'best_error'", "]", "\n", "self", ".", "best_epoch", "=", "state_dic", "[", "'best_epoch'", "]", "\n", "self", ".", "loss_flag", "=", "state_dic", "[", "'loss_flag'", "]", "\n", "self", ".", "seq_names", "=", "{", "}", "\n", "", "except", "KeyError", ":", "\n", "            ", "nii_display", ".", "f_die", "(", "\"Invalid op_process_monitor state_dic\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.print_error_for_batch": [[95, 112], ["core_scripts.f_eprint", "core_scripts.f_die", "core_scripts.f_die"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_eprint", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die"], ["", "", "def", "print_error_for_batch", "(", "self", ",", "cnt_idx", ",", "seq_idx", ",", "epoch_idx", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "t_1", "=", "self", ".", "loss_mat", "[", "epoch_idx", ",", "seq_idx", "]", "\n", "t_2", "=", "self", ".", "time_mat", "[", "epoch_idx", ",", "seq_idx", "]", "\n", "\n", "mes", "=", "\"{}, \"", ".", "format", "(", "self", ".", "seq_names", "[", "seq_idx", "]", ")", "\n", "mes", "+=", "\"{:d}/{:d}, \"", ".", "format", "(", "cnt_idx", "+", "1", ",", "self", ".", "seq_num", ")", "\n", "mes", "+=", "\"Time: {:.6f}s\"", ".", "format", "(", "t_2", ")", "\n", "for", "loss_indi", "in", "t_1", ":", "\n", "                ", "mes", "+=", "\", Loss: {:.6f}\"", ".", "format", "(", "loss_indi", ")", "\n", "", "nii_display", ".", "f_eprint", "(", "mes", ",", "flush", "=", "True", ")", "\n", "", "except", "IndexError", ":", "\n", "            ", "nii_display", ".", "f_die", "(", "\"Unknown sample index in Monitor\"", ")", "\n", "", "except", "KeyError", ":", "\n", "            ", "nii_display", ".", "f_die", "(", "\"Unknown sample index in Monitor\"", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.get_time": [[113, 115], ["numpy.sum"], "methods", ["None"], ["", "def", "get_time", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "return", "np", ".", "sum", "(", "self", ".", "time_mat", "[", "epoch", ",", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.get_loss": [[116, 119], ["numpy.mean"], "methods", ["None"], ["", "def", "get_loss", "(", "self", ",", "epoch", ")", ":", "\n", "# return a array", "\n", "        ", "return", "np", ".", "mean", "(", "self", ".", "loss_mat", "[", "epoch", ",", ":", "]", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.get_epoch": [[120, 122], ["None"], "methods", ["None"], ["", "def", "get_epoch", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cur_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.get_max_epoch": [[123, 125], ["None"], "methods", ["None"], ["", "def", "get_max_epoch", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "epoch_num", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor._get_loss_for_learning_stopping": [[126, 138], ["numpy.sum", "numpy.sum", "core_scripts.f_print", "core_scripts.f_die", "core_scripts.f_print", "core_scripts.f_die"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die"], ["", "def", "_get_loss_for_learning_stopping", "(", "self", ",", "epoch_idx", ")", ":", "\n", "# compute the average loss values", "\n", "        ", "if", "epoch_idx", ">", "self", ".", "cur_epoch", ":", "\n", "            ", "nii_display", ".", "f_print", "(", "\"To find loss for future epochs\"", ",", "'error'", ")", "\n", "nii_display", ".", "f_die", "(", "\"Op_process_monitor: error\"", ")", "\n", "", "if", "epoch_idx", "<", "0", ":", "\n", "            ", "nii_display", ".", "f_print", "(", "\"To find loss for NULL epoch\"", ",", "'error'", ")", "\n", "nii_display", ".", "f_die", "(", "\"Op_process_monitor: error\"", ")", "\n", "", "loss_this", "=", "np", ".", "sum", "(", "self", ".", "loss_mat", "[", "epoch_idx", ",", ":", ",", ":", "]", ",", "axis", "=", "0", ")", "\n", "# compute only part of the loss for early stopping when necessary", "\n", "loss_this", "=", "np", ".", "sum", "(", "loss_this", "*", "self", ".", "loss_flag", ")", "\n", "return", "loss_this", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.print_error_for_epoch": [[139, 146], ["numpy.mean", "numpy.sum", "core_scripts.f_print_message"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message"], ["", "def", "print_error_for_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "loss", "=", "np", ".", "mean", "(", "self", ".", "loss_mat", "[", "epoch", ",", ":", "]", ")", "\n", "time_sum", "=", "np", ".", "sum", "(", "self", ".", "time_mat", "[", "epoch", ",", ":", "]", ")", "\n", "mes", "=", "\"Epoch {:d}: \"", ".", "format", "(", "epoch", ")", "\n", "mes", "+=", "'Time: {:.6f}, Loss: {:.6f}'", ".", "format", "(", "time_sum", ",", "loss", ")", "\n", "nii_display", ".", "f_print_message", "(", "mes", ")", "\n", "return", "\"{}\\n\"", ".", "format", "(", "mes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.log_loss": [[147, 162], ["len", "numpy.resize", "len"], "methods", ["None"], ["", "def", "log_loss", "(", "self", ",", "loss", ",", "loss_flag", ",", "time_cost", ",", "seq_info", ",", "seq_idx", ",", "epoch_idx", ")", ":", "\n", "        ", "\"\"\" Log down the loss\n        \"\"\"", "\n", "self", ".", "seq_names", "[", "seq_idx", "]", "=", "seq_info", "\n", "if", "self", ".", "loss_mat", ".", "shape", "[", "-", "1", "]", "!=", "len", "(", "loss", ")", ":", "\n", "            ", "self", ".", "loss_mat", "=", "np", ".", "resize", "(", "self", ".", "loss_mat", ",", "\n", "[", "self", ".", "loss_mat", ".", "shape", "[", "0", "]", ",", "\n", "self", ".", "loss_mat", ".", "shape", "[", "1", "]", ",", "\n", "len", "(", "loss", ")", "]", ")", "\n", "", "self", ".", "loss_flag", "=", "loss_flag", "\n", "self", ".", "loss_mat", "[", "epoch_idx", ",", "seq_idx", ",", ":", "]", "=", "loss", "\n", "self", ".", "time_mat", "[", "epoch_idx", ",", "seq_idx", "]", "=", "time_cost", "\n", "self", ".", "cur_epoch", "=", "epoch_idx", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.is_new_best": [[163, 174], ["op_process_monitor.Monitor._get_loss_for_learning_stopping"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor._get_loss_for_learning_stopping"], ["", "def", "is_new_best", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        check whether epoch is the new_best\n        \"\"\"", "\n", "loss_this", "=", "self", ".", "_get_loss_for_learning_stopping", "(", "self", ".", "cur_epoch", ")", "\n", "if", "self", ".", "best_error", "is", "None", "or", "loss_this", "<", "self", ".", "best_error", ":", "\n", "            ", "self", ".", "best_error", "=", "loss_this", "\n", "self", ".", "best_epoch", "=", "self", ".", "cur_epoch", "\n", "return", "True", "\n", "", "else", ":", "\n", "            ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_process_monitor.Monitor.should_early_stop": [[175, 192], ["None"], "methods", ["None"], ["", "", "def", "should_early_stop", "(", "self", ",", "no_best_epoch_num", ")", ":", "\n", "        ", "\"\"\" \n        check whether to stop training early\n        \"\"\"", "\n", "if", "(", "self", ".", "cur_epoch", "-", "self", ".", "best_epoch", ")", ">=", "no_best_epoch_num", ":", "\n", "#", "\n", "#tmp = []", "\n", "#for idx in np.arange(no_best_epoch_num+1):", "\n", "#    tmp.append(self._get_loss_for_learning_stopping(", "\n", "#        self.cur_epoch - idx))", "\n", "#if np.sum(np.diff(tmp) < 0) >= no_best_epoch_num:", "\n", "#    return True", "\n", "#else:", "\n", "#    return False", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.__init__": [[33, 71], ["core_scripts.LRScheduler", "core_scripts.LRScheduler", "core_scripts.LRScheduler", "core_scripts.LRScheduler", "core_scripts.LRScheduler", "core_scripts.LRScheduler", "hasattr", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_print", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "core_scripts.f_die", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "model.parameters", "model.parameters"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_die"], ["def", "__init__", "(", "self", ",", "model", ",", "args", ")", ":", "\n", "        ", "\"\"\" Initialize an optimizer over model.parameters()\n        \"\"\"", "\n", "# check valildity of model", "\n", "if", "not", "hasattr", "(", "model", ",", "\"parameters\"", ")", ":", "\n", "            ", "nii_warn", ".", "f_print", "(", "\"model is not torch.nn\"", ",", "\"error\"", ")", "\n", "nii_warn", ".", "f_die", "(", "\"Error in creating OptimizerWrapper\"", ")", "\n", "\n", "# set optimizer type", "\n", "", "self", ".", "op_flag", "=", "args", ".", "optimizer", "\n", "self", ".", "lr", "=", "args", ".", "lr", "\n", "self", ".", "l2_penalty", "=", "args", ".", "l2_penalty", "\n", "\n", "# grad clip norm is directly added in nn_manager", "\n", "self", ".", "grad_clip_norm", "=", "args", ".", "grad_clip_norm", "\n", "\n", "# create optimizer", "\n", "if", "self", ".", "op_flag", "==", "\"Adam\"", ":", "\n", "            ", "if", "self", ".", "l2_penalty", ">", "0", ":", "\n", "                ", "self", ".", "optimizer", "=", "torch_optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "lr", ",", "\n", "weight_decay", "=", "self", ".", "l2_penalty", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "optimizer", "=", "torch_optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "lr", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "nii_warn", ".", "f_print", "(", "\"%s not availabel\"", "%", "(", "self", ".", "op_flag", ")", ",", "\n", "\"error\"", ")", "\n", "nii_warn", ".", "f_die", "(", "\"Please change optimizer\"", ")", "\n", "\n", "# number of epochs", "\n", "", "self", ".", "epochs", "=", "args", ".", "epochs", "\n", "self", ".", "no_best_epochs", "=", "args", ".", "no_best_epochs", "\n", "\n", "# lr scheduler", "\n", "self", ".", "lr_scheduler", "=", "nii_lr_scheduler", ".", "LRScheduler", "(", "self", ".", "optimizer", ",", "args", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.print_info": [[72, 86], ["op_manager.OptimizerWrapper.lr_scheduler.f_valid", "core_scripts.f_print_message", "core_scripts.f_print_message", "core_scripts.f_print_message", "core_scripts.f_print_message", "core_scripts.f_print_message", "core_scripts.f_print_message", "op_manager.OptimizerWrapper.lr_scheduler.f_print_info"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_valid", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_print_info"], ["", "def", "print_info", "(", "self", ")", ":", "\n", "        ", "\"\"\" print message of optimizer\n        \"\"\"", "\n", "mes", "=", "\"Optimizer:\\n  Type: {} \"", ".", "format", "(", "self", ".", "op_flag", ")", "\n", "mes", "+=", "\"\\n  Learing rate: {:2.6f}\"", ".", "format", "(", "self", ".", "lr", ")", "\n", "mes", "+=", "\"\\n  Epochs: {:d}\"", ".", "format", "(", "self", ".", "epochs", ")", "\n", "mes", "+=", "\"\\n  No-best-epochs: {:d}\"", ".", "format", "(", "self", ".", "no_best_epochs", ")", "\n", "if", "self", ".", "lr_scheduler", ".", "f_valid", "(", ")", ":", "\n", "            ", "mes", "+=", "self", ".", "lr_scheduler", ".", "f_print_info", "(", ")", "\n", "", "if", "self", ".", "l2_penalty", ">", "0", ":", "\n", "            ", "mes", "+=", "\"\\n  With weight penalty {:f}\"", ".", "format", "(", "self", ".", "l2_penalty", ")", "\n", "", "if", "self", ".", "grad_clip_norm", ">", "0", ":", "\n", "            ", "mes", "+=", "\"\\n  With grad clip norm {:f}\"", ".", "format", "(", "self", ".", "grad_clip_norm", ")", "\n", "", "nii_warn", ".", "f_print_message", "(", "mes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.get_epoch_num": [[87, 89], ["None"], "methods", ["None"], ["", "def", "get_epoch_num", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "epochs", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.get_no_best_epoch_num": [[90, 92], ["None"], "methods", ["None"], ["", "def", "get_no_best_epoch_num", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "no_best_epochs", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_manager.OptimizerWrapper.get_lr_info": [[93, 106], ["op_manager.OptimizerWrapper.lr_scheduler.f_valid", "op_manager.OptimizerWrapper.lr_scheduler.f_last_lr", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_valid", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_last_lr"], ["", "def", "get_lr_info", "(", "self", ")", ":", "\n", "\n", "        ", "if", "self", ".", "lr_scheduler", ".", "f_valid", "(", ")", ":", "\n", "# no way to look into the updated lr rather than using _last_lr", "\n", "            ", "tmp", "=", "''", "\n", "for", "updated_lr", "in", "self", ".", "lr_scheduler", ".", "f_last_lr", "(", ")", ":", "\n", "                ", "if", "np", ".", "abs", "(", "self", ".", "lr", "-", "updated_lr", ")", ">", "0.0000001", ":", "\n", "                    ", "tmp", "+=", "\"{:.2e} \"", ".", "format", "(", "updated_lr", ")", "\n", "", "", "if", "tmp", ":", "\n", "                ", "tmp", "=", "\" LR -> \"", "+", "tmp", "\n", "", "return", "tmp", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_display_tools.print_gen_info": [[20, 26], ["core_scripts.f_print_message"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message"], ["def", "print_gen_info", "(", "seq_name", ",", "time", ")", ":", "\n", "    ", "\"\"\" Print the information during inference\n    \"\"\"", "\n", "mes", "=", "\"Generating {}, time: {:.3f}s\"", ".", "format", "(", "seq_name", ",", "time", ")", "\n", "nii_display", ".", "f_print_message", "(", "mes", ")", "\n", "return", "mes", "+", "'\\n'", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_display_tools._print_loss": [[27, 38], ["mes.append"], "function", ["None"], ["", "def", "_print_loss", "(", "loss_array", ")", ":", "\n", "    ", "mes", "=", "\"\"", "\n", "if", "loss_array", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "        ", "mes", "+=", "\"%12.4f \"", "%", "(", "loss_array", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "        ", "mes", "=", "[", "]", "\n", "for", "data", "in", "loss_array", ":", "\n", "            ", "mes", ".", "append", "(", "'%6.2f'", "%", "(", "data", ")", ")", "\n", "", "mes", "=", "' '", ".", "join", "(", "mes", ")", "\n", "", "mes", "+=", "\"| \"", "\n", "return", "mes", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_display_tools.print_train_info": [[39, 57], ["op_display_tools._print_loss", "op_display_tools._print_loss", "core_scripts.f_print_message"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_display_tools._print_loss", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_display_tools._print_loss", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message"], ["", "def", "print_train_info", "(", "epoch", ",", "time_tr", ",", "loss_tr", ",", "time_val", ",", "\n", "loss_val", ",", "isbest", ",", "lr_info", ")", ":", "\n", "    ", "\"\"\" Print the information during training\n    \"\"\"", "\n", "mes", "=", "\"{:>7d} | \"", ".", "format", "(", "epoch", ")", "\n", "mes", "=", "mes", "+", "\"{:>12.1f} | \"", ".", "format", "(", "time_tr", "+", "time_val", ")", "\n", "mes", "+=", "_print_loss", "(", "loss_tr", ")", "\n", "mes", "+=", "_print_loss", "(", "loss_val", ")", "\n", "#mes = mes + \"{:>12.4f} | \".format(loss_tr)", "\n", "#mes = mes + \"{:>12.4f} | \".format(loss_val)    ", "\n", "if", "isbest", ":", "\n", "        ", "mes", "=", "mes", "+", "\"{:>5s}\"", ".", "format", "(", "\"yes\"", ")", "\n", "", "else", ":", "\n", "        ", "mes", "=", "mes", "+", "\"{:>5s}\"", ".", "format", "(", "\"no\"", ")", "\n", "", "if", "lr_info", ":", "\n", "        ", "mes", "=", "mes", "+", "lr_info", "\n", "", "nii_display", ".", "f_print_message", "(", "mes", ",", "flush", "=", "True", ")", "\n", "return", "mes", "+", "'\\n'", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_display_tools.print_log_head": [[58, 70], ["core_scripts.f_print_message", "core_scripts.f_print_message", "core_scripts.f_print_message"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message"], ["", "def", "print_log_head", "(", ")", ":", "\n", "    ", "\"\"\" Print the head information\n    \"\"\"", "\n", "nii_display", ".", "f_print_message", "(", "\"{:->62s}\"", ".", "format", "(", "\"\"", ")", ")", "\n", "mes", "=", "\"{:>7s} | \"", ".", "format", "(", "\"Epoch\"", ")", "\n", "mes", "=", "mes", "+", "\"{:>12s} | \"", ".", "format", "(", "\"Duration(s)\"", ")", "\n", "mes", "=", "mes", "+", "\"{:>12s} | \"", ".", "format", "(", "\"Train loss\"", ")", "\n", "mes", "=", "mes", "+", "\"{:>12s} | \"", ".", "format", "(", "\"Dev loss\"", ")", "\n", "mes", "=", "mes", "+", "\"{:>5s}\"", ".", "format", "(", "\"Best\"", ")", "\n", "nii_display", ".", "f_print_message", "(", "mes", ")", "\n", "nii_display", ".", "f_print_message", "(", "\"{:->62s}\"", ".", "format", "(", "\"\"", ")", ",", "flush", "=", "True", ")", "\n", "return", "mes", "+", "'\\n'", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.op_display_tools.print_log_tail": [[71, 76], ["core_scripts.f_print_message"], "function", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print_message"], ["", "def", "print_log_tail", "(", ")", ":", "\n", "    ", "\"\"\" Print the tail line\n    \"\"\"", "\n", "nii_display", ".", "f_print_message", "(", "\"{:->62s}\"", ".", "format", "(", "\"\"", ")", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.__init__": [[29, 66], ["torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.ReduceLROnPlateau", "torch.ReduceLROnPlateau", "torch.ReduceLROnPlateau", "core_scripts.f_print", "core_scripts.f_print"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print", "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.other_tools.display.f_print"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "args", ")", ":", "\n", "\n", "# learning rate decay", "\n", "        ", "self", ".", "lr_decay", "=", "args", ".", "lr_decay_factor", "\n", "\n", "# lr scheduler type ", "\n", "# please check arg_parse.py for the number ID", "\n", "self", ".", "lr_scheduler_type", "=", "args", ".", "lr_scheduler_type", "\n", "\n", "# patentience for ReduceLROnPlateau", "\n", "self", ".", "lr_patience", "=", "5", "\n", "\n", "# step size for stepLR", "\n", "self", ".", "lr_stepLR_size", "=", "10", "\n", "\n", "if", "self", ".", "lr_decay", ">", "0", ":", "\n", "            ", "if", "self", ".", "lr_scheduler_type", "==", "1", ":", "\n", "# StepLR", "\n", "                ", "self", ".", "lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "\n", "optimizer", "=", "optimizer", ",", "step_size", "=", "self", ".", "lr_stepLR_size", ",", "\n", "gamma", "=", "self", ".", "lr_decay", ")", "\n", "", "else", ":", "\n", "# by default, ReduceLROnPlateau", "\n", "                ", "if", "args", ".", "no_best_epochs", "<", "0", ":", "\n", "                    ", "self", ".", "lr_patience", "=", "5", "\n", "nii_warn", ".", "f_print", "(", "\"--no-best-epochs is set to 5 \"", ")", "\n", "nii_warn", ".", "f_print", "(", "\"for learning rate decaying\"", ")", "\n", "\n", "", "self", ".", "lr_scheduler", "=", "torch_optim_steplr", ".", "ReduceLROnPlateau", "(", "\n", "optimizer", "=", "optimizer", ",", "factor", "=", "self", ".", "lr_decay", ",", "\n", "patience", "=", "self", ".", "lr_patience", ")", "\n", "\n", "", "self", ".", "flag", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "lr_scheduler", "=", "None", "\n", "self", ".", "flag", "=", "False", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_valid": [[67, 71], ["None"], "methods", ["None"], ["", "def", "f_valid", "(", "self", ")", ":", "\n", "        ", "\"\"\" Whether this LR scheduler is valid\n        \"\"\"", "\n", "return", "self", ".", "flag", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_print_info": [[72, 86], ["None"], "methods", ["None"], ["", "def", "f_print_info", "(", "self", ")", ":", "\n", "        ", "\"\"\" Print information about the LR scheduler\n        \"\"\"", "\n", "if", "not", "self", ".", "flag", ":", "\n", "            ", "mes", "=", "\"\"", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "lr_scheduler_type", "==", "1", ":", "\n", "                ", "mes", "=", "\"\\n  LR scheduler, StepLR [gamma %f, step %d]\"", "%", "(", "\n", "self", ".", "lr_decay", ",", "self", ".", "lr_stepLR_size", ")", "\n", "", "else", ":", "\n", "                ", "mes", "=", "\"\\n  LR scheduler, ReduceLROnPlateau \"", "\n", "mes", "+=", "\"[decay %f, patience %d]\"", "%", "(", "\n", "self", ".", "lr_decay", ",", "self", ".", "lr_patience", ")", "\n", "", "", "return", "mes", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_last_lr": [[87, 97], ["lr_scheduler.LRScheduler.f_valid", "hasattr", "lr_scheduler.LRScheduler.lr_scheduler.get_last_lr"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_valid"], ["", "def", "f_last_lr", "(", "self", ")", ":", "\n", "        ", "\"\"\" Return the last lr\n        \"\"\"", "\n", "if", "self", ".", "f_valid", "(", ")", ":", "\n", "            ", "if", "hasattr", "(", "self", ".", "lr_scheduler", ",", "\"get_last_lr\"", ")", ":", "\n", "                ", "return", "self", ".", "lr_scheduler", ".", "get_last_lr", "(", ")", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "lr_scheduler", ".", "_last_lr", "\n", "", "", "else", ":", "\n", "            ", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_load_state_dict": [[98, 102], ["lr_scheduler.LRScheduler.f_valid", "lr_scheduler.LRScheduler.lr_scheduler.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_valid"], ["", "", "def", "f_load_state_dict", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "self", ".", "f_valid", "(", ")", ":", "\n", "            ", "self", ".", "lr_scheduler", ".", "load_state_dict", "(", "state", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_state_dict": [[103, 108], ["lr_scheduler.LRScheduler.f_valid", "lr_scheduler.LRScheduler.lr_scheduler.state_dict"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_valid"], ["", "def", "f_state_dict", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "f_valid", "(", ")", ":", "\n", "            ", "return", "self", ".", "lr_scheduler", ".", "state_dict", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_step": [[109, 116], ["lr_scheduler.LRScheduler.f_valid", "lr_scheduler.LRScheduler.lr_scheduler.step", "lr_scheduler.LRScheduler.lr_scheduler.step"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_valid"], ["", "", "def", "f_step", "(", "self", ",", "loss_val", ")", ":", "\n", "        ", "if", "self", ".", "f_valid", "(", ")", ":", "\n", "            ", "if", "self", ".", "lr_scheduler_type", "==", "1", ":", "\n", "                ", "self", ".", "lr_scheduler", ".", "step", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "lr_scheduler", ".", "step", "(", "loss_val", ")", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_allow_early_stopping": [[117, 126], ["lr_scheduler.LRScheduler.f_valid"], "methods", ["home.repos.pwc.inspect_result.TakHemlata_RawBoost-antispoofing.op_manager.lr_scheduler.LRScheduler.f_valid"], ["", "def", "f_allow_early_stopping", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "f_valid", "(", ")", ":", "\n", "            ", "if", "self", ".", "lr_scheduler_type", "==", "1", ":", "\n", "                ", "return", "True", "\n", "", "else", ":", "\n", "# ReduceLROnPlateau no need to use early stopping", "\n", "                ", "return", "False", "\n", "", "", "else", ":", "\n", "            ", "return", "True", "\n", "\n"]]}