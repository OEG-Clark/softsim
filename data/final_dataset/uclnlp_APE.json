{"home.repos.pwc.inspect_result.uclnlp_APE.FiD.options.Options.__init__": [[6, 9], ["argparse.ArgumentParser", "options.Options.initialize"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.options.Options.initialize"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "self", ".", "parser", "=", "self", ".", "initialize", "(", "parser", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.options.Options.initialize": [[10, 93], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "# basic parameters", "\n", "        ", "parser", ".", "add_argument", "(", "'--name'", ",", "type", "=", "str", ",", "default", "=", "'experiment_name'", ",", "help", "=", "'name of the experiment'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint_dir'", ",", "type", "=", "str", ",", "default", "=", "'./checkpoint/'", ",", "help", "=", "'models are saved here'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_path'", ",", "type", "=", "str", ",", "default", "=", "'none'", ",", "help", "=", "'path for retraining'", ")", "\n", "parser", ".", "add_argument", "(", "'--train_data_path'", ",", "type", "=", "str", ",", "default", "=", "'none'", ",", "help", "=", "'path of train data'", ")", "\n", "parser", ".", "add_argument", "(", "'--dev_data_path'", ",", "type", "=", "str", ",", "default", "=", "'none'", ",", "help", "=", "'path of dev data'", ")", "\n", "parser", ".", "add_argument", "(", "'--dev_data_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "'subsample dev data to speedup evaluation'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_data_path'", ",", "type", "=", "str", ",", "default", "=", "'none'", ",", "help", "=", "'path of test data'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_type'", ",", "type", "=", "str", ",", "default", "=", "'t5'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_size'", ",", "type", "=", "str", ",", "default", "=", "'base'", ")", "\n", "parser", ".", "add_argument", "(", "'--write_results'", ",", "action", "=", "'store_true'", ",", "help", "=", "'save test results'", ")", "\n", "\n", "# dataset parameters", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gradient_accumulation_steps\"", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "\"Accumulation step.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--no_title'", ",", "action", "=", "'store_true'", ",", "help", "=", "'article titles not included in passages'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_context'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--total_step'", ",", "type", "=", "int", ",", "default", "=", "10000", ")", "\n", "parser", ".", "add_argument", "(", "'--reload_step'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "'reload model at step <reload_step>'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_passage_length'", ",", "type", "=", "int", ",", "default", "=", "250", ",", "\n", "help", "=", "'maximum number of tokens in the passages (question included)'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpointing_encoder'", ",", "action", "=", "'store_true'", ",", "help", "=", "'trades memory for compute'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpointing_decoder'", ",", "action", "=", "'store_true'", ",", "help", "=", "'trades memory for compute'", ")", "\n", "\n", "# training parameters", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "1e-4", ",", "help", "=", "'learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--adam_epsilon'", ",", "type", "=", "float", ",", "default", "=", "1e-8", ",", "help", "=", "'epsilon for Adam optimizer'", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup_step'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'number of warmup steps'", ")", "\n", "parser", ".", "add_argument", "(", "'--clip'", ",", "type", "=", "float", ",", "default", "=", "1.", ",", "help", "=", "'gradient clipping'", ")", "\n", "parser", ".", "add_argument", "(", "'--log_freq'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "'log model loss every <log_freq> steps during training'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_freq'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'evaluate model every <eval_freq> steps during training'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_print_freq'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "\n", "help", "=", "'print intermediate results of evaluation every <eval_print_freq> steps'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_freq'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "\n", "help", "=", "'save model every <save_freq> steps during training'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--master_port\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Master port (for multi-node SLURM jobs)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "'--global_rank'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--world_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--is_master'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "\n", "# AC (Adaptive Computation) has_answer_heads parameters", "\n", "parser", ".", "add_argument", "(", "'--has_answer_pool_type'", ",", "type", "=", "str", ",", "default", "=", "\"none\"", ",", "\n", "help", "=", "'pooling type of has_answer_heads'", ")", "\n", "\n", "# AC (Adaptive Computation) Scheduler model parameters", "\n", "parser", ".", "add_argument", "(", "'--scheduler_type'", ",", "type", "=", "str", ",", "default", "=", "\"none\"", ",", "\n", "help", "=", "'type of the AC scheduler (default: none)'", ")", "\n", "parser", ".", "add_argument", "(", "'--scheduler_n_context'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'maximum number of context for the AC scheduler'", ")", "\n", "parser", ".", "add_argument", "(", "'--scheduler_embed_size'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "'embedding size of the AC MLPScheduler'", ")", "\n", "parser", ".", "add_argument", "(", "'--scheduler_hidden_size'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "'hidden size of the AC MLPScheduler'", ")", "\n", "\n", "# AC (Adaptive Computation) train/inference parameters", "\n", "parser", ".", "add_argument", "(", "'--freeze_fid_params'", ",", "action", "=", "'store_true'", ",", "help", "=", "'freeze the FiD parameters'", ")", "\n", "parser", ".", "add_argument", "(", "'--freeze_has_answer_heads'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'freeze the has_answer_heads parameters (used when training the AC scheduler)'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_bce_loss'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'train the has_answer_heads with Binary Cross-entropy loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_rl_loss'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'train the scheduler with REINFORCE loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--budget'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "help", "=", "'budget number of passage layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_passages_retained'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "'number of passages retained after AC'", ")", "\n", "parser", ".", "add_argument", "(", "'--step_cost'", ",", "type", "=", "float", ",", "default", "=", "0.", ",", "\n", "help", "=", "'cost per step when training the scheduler with REINFORCE'", ")", "\n", "parser", ".", "add_argument", "(", "'--discount'", ",", "type", "=", "float", ",", "default", "=", "1.", ",", "\n", "help", "=", "'discount factor when training the scheduler with REINFORCE'", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.options.Options.print_options": [[94, 111], ["sorted", "os.path.join", "os.path.join", "os.path.join", "vars().items", "options.Options.parser.get_default", "os.path.exists", "os.makedirs", "open", "opt_file.write", "opt_file.write", "str", "str", "os.path.join", "vars", "str"], "methods", ["None"], ["", "def", "print_options", "(", "self", ",", "opt", ")", ":", "\n", "        ", "message", "=", "''", "\n", "for", "k", ",", "v", "in", "sorted", "(", "vars", "(", "opt", ")", ".", "items", "(", ")", ")", ":", "\n", "            ", "comment", "=", "''", "\n", "default", "=", "self", ".", "parser", ".", "get_default", "(", "k", ")", "\n", "if", "v", "!=", "default", ":", "\n", "                ", "comment", "=", "'\\t[default: %s]'", "%", "str", "(", "default", ")", "\n", "", "message", "+=", "'{:>40}: {:<40}{}\\n'", ".", "format", "(", "str", "(", "k", ")", ",", "str", "(", "v", ")", ",", "comment", ")", "\n", "\n", "", "expr_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_dir", ",", "opt", ".", "name", ")", "\n", "model_dir", "=", "os", ".", "path", ".", "join", "(", "expr_dir", ",", "'models'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "model_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "expr_dir", ",", "'models'", ")", ")", "\n", "", "file_name", "=", "os", ".", "path", ".", "join", "(", "expr_dir", ",", "'opt.txt'", ")", "\n", "with", "open", "(", "file_name", ",", "'wt'", ")", "as", "opt_file", ":", "\n", "            ", "opt_file", ".", "write", "(", "message", ")", "\n", "opt_file", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.options.Options.parse": [[112, 116], ["options.Options.parser.parse_known_args", "options.Options.parser.parse_args"], "methods", ["None"], ["", "", "def", "parse", "(", "self", ")", ":", "\n", "        ", "opt", ",", "_", "=", "self", ".", "parser", ".", "parse_known_args", "(", ")", "\n", "opt", "=", "self", ".", "parser", ".", "parse_args", "(", ")", "\n", "return", "opt", "\n", "", "", ""]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.test_ac.evaluate": [[19, 74], ["model.eval", "hasattr", "logger.warning", "logger.warning", "util.weighted_average", "logger.info", "os.path.join", "open", "torch.no_grad", "torch.no_grad", "enumerate", "torch.distributed.barrier", "torch.distributed.barrier", "numpy.mean", "os.path.join", "context_ids.cuda().view.size", "context_ids.cuda().view.cuda().view", "context_mask.cuda().view.cuda().view", "model.generate", "enumerate", "context_ids.cuda().view.size", "context_ids.cuda().view.size", "tokenizer.decode", "dataset.get_example", "evaluation.ems", "ems.append", "logger.warning", "numpy.mean", "context_ids.cuda().view.cuda", "context_mask.cuda().view.cuda", "open.write", "len", "numpy.mean", "str"], "function", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.weighted_average", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.ACFiDT5.generate", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.data.Dataset.get_example", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.ems"], ["def", "evaluate", "(", "model", ",", "dataset", ",", "dataloader", ",", "tokenizer", ",", "opt", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "if", "hasattr", "(", "model", ",", "\"module\"", ")", ":", "\n", "        ", "model", "=", "model", ".", "module", "\n", "\n", "# Set AC parameters", "\n", "", "model", ".", "encoder", ".", "budget", "=", "opt", ".", "budget", "\n", "model", ".", "encoder", ".", "num_passages_retained", "=", "opt", ".", "num_passages_retained", "\n", "logger", ".", "warning", "(", "f\"budget = {opt.budget}, num_passages_retained = {opt.num_passages_retained}\"", ")", "\n", "\n", "total", "=", "0", "\n", "ems", "=", "[", "]", "\n", "\n", "fw", "=", "None", "\n", "if", "opt", ".", "write_results", ":", "\n", "        ", "write_path", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_dir", ",", "opt", ".", "name", ",", "'test_results'", ")", "\n", "fw", "=", "open", "(", "os", ".", "path", ".", "join", "(", "write_path", ",", "'%d.txt'", "%", "opt", ".", "global_rank", ")", ",", "'w'", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "            ", "idx", ",", "answer_ids", ",", "answer_mask", ",", "context_ids", ",", "context_mask", "=", "batch", "\n", "# answer_ids, answer_mask = answer_ids.cuda(), answer_mask.bool().cuda()", "\n", "model", ".", "encoder", ".", "n_passages", "=", "context_ids", ".", "size", "(", "1", ")", "\n", "context_ids", "=", "context_ids", ".", "cuda", "(", ")", ".", "view", "(", "context_ids", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "context_mask", "=", "context_mask", ".", "cuda", "(", ")", ".", "view", "(", "context_ids", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "outputs", "=", "model", ".", "generate", "(", "\n", "input_ids", "=", "context_ids", ",", "\n", "attention_mask", "=", "context_mask", ",", "\n", "max_length", "=", "50", ",", "\n", ")", "\n", "\n", "for", "k", ",", "o", "in", "enumerate", "(", "outputs", ")", ":", "\n", "                ", "ans", "=", "tokenizer", ".", "decode", "(", "o", ",", "skip_special_tokens", "=", "True", ")", "\n", "example", "=", "dataset", ".", "get_example", "(", "idx", "[", "k", "]", ")", "\n", "question", "=", "example", ".", "question", "\n", "gold", "=", "example", ".", "answers", "\n", "id", "=", "example", ".", "id", "\n", "ems_score", "=", "evaluation", ".", "ems", "(", "ans", ",", "gold", ")", "\n", "ems", ".", "append", "(", "ems_score", ")", "\n", "\n", "if", "fw", "is", "not", "None", ":", "\n", "                    ", "fw", ".", "write", "(", "str", "(", "id", ")", "+", "\"\\t\"", "+", "ans", "+", "'\\n'", ")", "\n", "\n", "", "total", "+=", "1", "\n", "\n", "", "if", "(", "i", "+", "1", ")", "%", "opt", ".", "eval_print_freq", "==", "0", ":", "\n", "                ", "logger", ".", "warning", "(", "f\"{opt.global_rank}, {i + 1} / {len(dataloader)} -- average = {np.mean(ems):.3f}\"", ")", "\n", "\n", "", "", "", "logger", ".", "warning", "(", "f\"{opt.global_rank}, total {total} -- average = {np.mean(ems):.3f}\"", ")", "\n", "if", "opt", ".", "world_size", ">", "1", "and", "not", "opt", ".", "local_rank", "==", "-", "1", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "", "score", ",", "total", "=", "util", ".", "weighted_average", "(", "np", ".", "mean", "(", "ems", ")", ",", "total", ",", "opt", ")", "\n", "logger", ".", "info", "(", "'total number of example %d'", "%", "total", ")", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.slurm.sig_handler": [[12, 22], ["logger.warning", "int", "logger.warning", "sys.exit", "logger.warning", "os.system", "logger.warning", "str", "socket.gethostname"], "function", ["None"], ["def", "sig_handler", "(", "signum", ",", "frame", ")", ":", "\n", "    ", "logger", ".", "warning", "(", "\"Signal handler called with signal \"", "+", "str", "(", "signum", ")", ")", "\n", "prod_id", "=", "int", "(", "os", ".", "environ", "[", "'SLURM_PROCID'", "]", ")", "\n", "logger", ".", "warning", "(", "\"Host: %s - Global rank: %i\"", "%", "(", "socket", ".", "gethostname", "(", ")", ",", "prod_id", ")", ")", "\n", "if", "prod_id", "==", "0", ":", "\n", "        ", "logger", ".", "warning", "(", "\"Requeuing job \"", "+", "os", ".", "environ", "[", "'SLURM_JOB_ID'", "]", ")", "\n", "os", ".", "system", "(", "'scontrol requeue '", "+", "os", ".", "environ", "[", "'SLURM_JOB_ID'", "]", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "warning", "(", "\"Not the master process, no need to requeue.\"", ")", "\n", "", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.slurm.term_handler": [[24, 27], ["logger.warning", "logger.warning", "str"], "function", ["None"], ["", "def", "term_handler", "(", "signum", ",", "frame", ")", ":", "\n", "    ", "logger", ".", "warning", "(", "\"Signal handler called with signal \"", "+", "str", "(", "signum", ")", ")", "\n", "logger", ".", "warning", "(", "\"Bypassing SIGTERM.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.slurm.init_signal_handler": [[29, 35], ["signal.signal", "signal.signal"], "function", ["None"], ["", "def", "init_signal_handler", "(", ")", ":", "\n", "    ", "\"\"\"\n    Handle signals sent by SLURM for time limit / pre-emption.\n    \"\"\"", "\n", "signal", ".", "signal", "(", "signal", ".", "SIGUSR1", ",", "sig_handler", ")", "\n", "signal", ".", "signal", "(", "signal", ".", "SIGTERM", ",", "term_handler", ")", "\n", "#logger.warning(\"Signal handler installed.\")", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.slurm.init_distributed_mode": [[38, 162], ["torch.cuda.set_device", "int", "int", "int", "int", "int", "subprocess.check_output", "[].decode", "str", "str", "str", "torch.distributed.init_process_group", "int", "os.environ.get", "int", "int", "int", "subprocess.check_output.split"], "function", ["None"], ["", "def", "init_distributed_mode", "(", "params", ")", ":", "\n", "    ", "\"\"\"\n    Handle single and multi-GPU / multi-node / SLURM jobs.\n    Initialize the following variables:\n        - n_nodes\n        - node_id\n        - local_rank\n        - global_rank\n        - world_size\n    \"\"\"", "\n", "params", ".", "is_slurm_job", "=", "'SLURM_JOB_ID'", "in", "os", ".", "environ", "\n", "#print(\"SLURM job: %s\" % str(params.is_slurm_job))", "\n", "\n", "# SLURM job", "\n", "if", "params", ".", "is_slurm_job", ":", "\n", "\n", "        ", "assert", "params", ".", "local_rank", "==", "-", "1", "# on the cluster, this is handled by SLURM", "\n", "\n", "SLURM_VARIABLES", "=", "[", "\n", "'SLURM_JOB_ID'", ",", "\n", "'SLURM_JOB_NODELIST'", ",", "'SLURM_JOB_NUM_NODES'", ",", "'SLURM_NTASKS'", ",", "'SLURM_TASKS_PER_NODE'", ",", "\n", "'SLURM_MEM_PER_NODE'", ",", "'SLURM_MEM_PER_CPU'", ",", "\n", "'SLURM_NODEID'", ",", "'SLURM_PROCID'", ",", "'SLURM_LOCALID'", ",", "'SLURM_TASK_PID'", "\n", "]", "\n", "\n", "PREFIX", "=", "\"%i - \"", "%", "int", "(", "os", ".", "environ", "[", "'SLURM_PROCID'", "]", ")", "\n", "for", "name", "in", "SLURM_VARIABLES", ":", "\n", "            ", "value", "=", "os", ".", "environ", ".", "get", "(", "name", ",", "None", ")", "\n", "#print(PREFIX + \"%s: %s\" % (name, str(value)))", "\n", "\n", "# # job ID", "\n", "# params.job_id = os.environ['SLURM_JOB_ID']", "\n", "\n", "# number of nodes / node ID", "\n", "", "params", ".", "n_nodes", "=", "int", "(", "os", ".", "environ", "[", "'SLURM_JOB_NUM_NODES'", "]", ")", "\n", "params", ".", "node_id", "=", "int", "(", "os", ".", "environ", "[", "'SLURM_NODEID'", "]", ")", "\n", "\n", "# local rank on the current node / global rank", "\n", "params", ".", "local_rank", "=", "int", "(", "os", ".", "environ", "[", "'SLURM_LOCALID'", "]", ")", "\n", "params", ".", "global_rank", "=", "int", "(", "os", ".", "environ", "[", "'SLURM_PROCID'", "]", ")", "\n", "\n", "# number of processes / GPUs per node", "\n", "params", ".", "world_size", "=", "int", "(", "os", ".", "environ", "[", "'SLURM_NTASKS'", "]", ")", "\n", "params", ".", "n_gpu_per_node", "=", "params", ".", "world_size", "//", "params", ".", "n_nodes", "\n", "\n", "# define master address and master port", "\n", "hostnames", "=", "subprocess", ".", "check_output", "(", "[", "'scontrol'", ",", "'show'", ",", "'hostnames'", ",", "os", ".", "environ", "[", "'SLURM_JOB_NODELIST'", "]", "]", ")", "\n", "params", ".", "master_addr", "=", "hostnames", ".", "split", "(", ")", "[", "0", "]", ".", "decode", "(", "'utf-8'", ")", "\n", "assert", "10001", "<=", "params", ".", "master_port", "<=", "20000", "or", "params", ".", "world_size", "==", "1", "\n", "#print(PREFIX + \"Master address: %s\" % params.master_addr)", "\n", "#print(PREFIX + \"Master port   : %i\" % params.master_port)", "\n", "\n", "# set environment variables for 'env://'", "\n", "os", ".", "environ", "[", "'MASTER_ADDR'", "]", "=", "params", ".", "master_addr", "\n", "os", ".", "environ", "[", "'MASTER_PORT'", "]", "=", "str", "(", "params", ".", "master_port", ")", "\n", "os", ".", "environ", "[", "'WORLD_SIZE'", "]", "=", "str", "(", "params", ".", "world_size", ")", "\n", "os", ".", "environ", "[", "'RANK'", "]", "=", "str", "(", "params", ".", "global_rank", ")", "\n", "\n", "# multi-GPU job (local or multi-node) - jobs started with torch.distributed.launch", "\n", "", "elif", "params", ".", "local_rank", "!=", "-", "1", ":", "\n", "\n", "        ", "assert", "params", ".", "master_port", "==", "-", "1", "\n", "\n", "# read environment variables", "\n", "params", ".", "global_rank", "=", "int", "(", "os", ".", "environ", "[", "'RANK'", "]", ")", "\n", "params", ".", "world_size", "=", "int", "(", "os", ".", "environ", "[", "'WORLD_SIZE'", "]", ")", "\n", "params", ".", "n_gpu_per_node", "=", "int", "(", "os", ".", "environ", "[", "'NGPU'", "]", ")", "\n", "\n", "# number of nodes / node ID", "\n", "params", ".", "n_nodes", "=", "params", ".", "world_size", "//", "params", ".", "n_gpu_per_node", "\n", "params", ".", "node_id", "=", "params", ".", "global_rank", "//", "params", ".", "n_gpu_per_node", "\n", "\n", "# local job (single GPU)", "\n", "", "else", ":", "\n", "        ", "assert", "params", ".", "local_rank", "==", "-", "1", "\n", "assert", "params", ".", "master_port", "==", "-", "1", "\n", "params", ".", "n_nodes", "=", "1", "\n", "params", ".", "node_id", "=", "0", "\n", "params", ".", "local_rank", "=", "0", "\n", "params", ".", "global_rank", "=", "0", "\n", "params", ".", "world_size", "=", "1", "\n", "params", ".", "n_gpu_per_node", "=", "1", "\n", "\n", "# sanity checks", "\n", "", "assert", "params", ".", "n_nodes", ">=", "1", "\n", "assert", "0", "<=", "params", ".", "node_id", "<", "params", ".", "n_nodes", "\n", "assert", "0", "<=", "params", ".", "local_rank", "<=", "params", ".", "global_rank", "<", "params", ".", "world_size", "\n", "assert", "params", ".", "world_size", "==", "params", ".", "n_nodes", "*", "params", ".", "n_gpu_per_node", "\n", "\n", "# define whether this is the master process / if we are in distributed mode", "\n", "params", ".", "is_master", "=", "params", ".", "node_id", "==", "0", "and", "params", ".", "local_rank", "==", "0", "\n", "params", ".", "multi_node", "=", "params", ".", "n_nodes", ">", "1", "\n", "params", ".", "multi_gpu", "=", "params", ".", "world_size", ">", "1", "\n", "\n", "# summary", "\n", "PREFIX", "=", "\"%i - \"", "%", "params", ".", "global_rank", "\n", "#print(PREFIX + \"Number of nodes: %i\" % params.n_nodes)", "\n", "#print(PREFIX + \"Node ID        : %i\" % params.node_id)", "\n", "#print(PREFIX + \"Local rank     : %i\" % params.local_rank)", "\n", "#print(PREFIX + \"Global rank    : %i\" % params.global_rank)", "\n", "#print(PREFIX + \"World size     : %i\" % params.world_size)", "\n", "#print(PREFIX + \"GPUs per node  : %i\" % params.n_gpu_per_node)", "\n", "#print(PREFIX + \"Master         : %s\" % str(params.is_master))", "\n", "#print(PREFIX + \"Multi-node     : %s\" % str(params.multi_node))", "\n", "#print(PREFIX + \"Multi-GPU      : %s\" % str(params.multi_gpu))", "\n", "#print(PREFIX + \"Hostname       : %s\" % socket.gethostname())", "\n", "\n", "# set GPU device", "\n", "torch", ".", "cuda", ".", "set_device", "(", "params", ".", "local_rank", ")", "\n", "\n", "# initialize multi-GPU", "\n", "if", "params", ".", "multi_gpu", ":", "\n", "\n", "# http://pytorch.apachecn.org/en/0.3.0/distributed.html#environment-variable-initialization", "\n", "# 'env://' will read these environment variables:", "\n", "# MASTER_PORT - required; has to be a free port on machine with rank 0", "\n", "# MASTER_ADDR - required (except for rank 0); address of rank 0 node", "\n", "# WORLD_SIZE - required; can be set either here, or in a call to init function", "\n", "# RANK - required; can be set either here, or in a call to init function", "\n", "\n", "#print(\"Initializing PyTorch distributed ...\")", "\n", "        ", "torch", ".", "distributed", ".", "init_process_group", "(", "\n", "init_method", "=", "'env://'", ",", "\n", "backend", "=", "'nccl'", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.train_ac.log_scalar": [[42, 46], ["tb_logger.add_scalar", "wandb.log"], "function", ["None"], ["", "def", "log_scalar", "(", "name", ",", "value", ",", "step", ")", ":", "\n", "    ", "tb_logger", ".", "add_scalar", "(", "name", ",", "value", ",", "step", ")", "\n", "if", "_has_wandb", ":", "\n", "        ", "wandb", ".", "log", "(", "{", "name", ":", "value", ",", "\"step\"", ":", "step", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.train_ac.train_evaluate": [[48, 211], ["torch.utils.data.DataLoader", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "list", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.train", "torch.nn.parallel.DistributedDataParallel.zero_grad", "torch.utils.data.RandomSampler", "torch.utils.data.DistributedSampler", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.optim.Adam", "torch.optim.Adam", "util.FixedScheduler", "amp.initialize", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "tqdm.auto.tqdm", "n.startswith", "len", "train_sampler.set_epoch", "enumerate", "has_answer_labels.cuda.cuda", "answer_ids.masked_fill", "hasattr", "context_ids.cuda().view.cuda().view", "context_mask.cuda().view.cuda().view", "torch.nn.parallel.DistributedDataParallel.", "util.average_master", "util.average_master.item", "n.startswith", "n.startswith", "new_np.append", "new_np.append", "ImportError", "answer_ids.cuda", "answer_mask.bool().cuda", "context_ids.cuda().view.size", "context_ids.cuda().view.size", "context_ids.cuda().view.size", "context_ids.cuda().view.size", "util.average_master.backward", "torch.optim.Adam.step", "util.FixedScheduler.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "context_ids.cuda().view.cuda", "context_mask.cuda().view.cuda", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "logger.info", "train_ac.log_scalar", "train_ac.evaluate", "torch.nn.parallel.DistributedDataParallel.train", "util.save", "answer_mask.bool", "amp.master_params", "logger.info", "evaluate.items", "hasattr", "train_ac.log_scalar", "util.save", "hasattr", "util.FixedScheduler.get_last_lr"], "function", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.options.Options.initialize", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.average_master", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.train_ac_scheduler.log_scalar", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.test_retrieval_acc.evaluate", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.save", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.train_ac_scheduler.log_scalar", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.save"], ["", "", "def", "train_evaluate", "(", "model", ",", "optimizer", ",", "scheduler", ",", "global_step", ",", "\n", "train_dataset", ",", "dev_dataset", ",", "opt", ",", "collator_function", ",", "best_metric", ")", ":", "\n", "    ", "train_sampler", "=", "(", "RandomSampler", "(", "train_dataset", ")", "if", "opt", ".", "local_rank", "==", "-", "1", "or", "opt", ".", "world_size", "==", "1", "\n", "else", "DistributedSampler", "(", "train_dataset", ")", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "opt", ".", "per_gpu_batch_size", ",", "drop_last", "=", "True", ",", "num_workers", "=", "3", ",", "\n", "collate_fn", "=", "collator_function", ")", "\n", "\n", "dev_sampler", "=", "SequentialSampler", "(", "dev_dataset", ")", "\n", "dev_dataloader", "=", "DataLoader", "(", "dev_dataset", ",", "sampler", "=", "dev_sampler", ",", "batch_size", "=", "opt", ".", "per_gpu_batch_size", ",", "\n", "drop_last", "=", "True", ",", "num_workers", "=", "3", ",", "collate_fn", "=", "collator_function", ")", "\n", "\n", "# Freeze the FiD parameters and only train AC part.", "\n", "trainable_np", "=", "list", "(", "model", ".", "named_parameters", "(", ")", ")", "\n", "if", "opt", ".", "freeze_fid_params", ":", "\n", "        ", "new_np", "=", "[", "]", "\n", "for", "n", ",", "p", "in", "trainable_np", ":", "\n", "            ", "if", "n", ".", "startswith", "(", "\"encoder.has_answer_heads\"", ")", "or", "n", ".", "startswith", "(", "\"ac_scheduler\"", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "True", "\n", "new_np", ".", "append", "(", "(", "n", ",", "p", ")", ")", "\n", "", "else", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "", "", "trainable_np", "=", "new_np", "\n", "\n", "", "if", "opt", ".", "freeze_has_answer_heads", ":", "\n", "        ", "new_np", "=", "[", "]", "\n", "for", "n", ",", "p", "in", "trainable_np", ":", "\n", "            ", "if", "n", ".", "startswith", "(", "\"encoder.has_answer_heads\"", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "", "else", ":", "\n", "                ", "p", ".", "requires_grad", "=", "True", "\n", "new_np", ".", "append", "(", "(", "n", ",", "p", ")", ")", "\n", "", "", "trainable_np", "=", "new_np", "\n", "\n", "", "trainable_parameters", "=", "[", "p", "for", "n", ",", "p", "in", "trainable_np", "]", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "if", "optimizer", "is", "None", "or", "scheduler", "is", "None", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "trainable_parameters", ",", "lr", "=", "opt", ".", "lr", ")", "\n", "scheduler", "=", "util", ".", "FixedScheduler", "(", "optimizer", ")", "\n", "\n", "# fp16", "\n", "", "if", "opt", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "opt", ".", "fp16_opt_level", ")", "\n", "\n", "# Distributed training", "\n", "", "if", "opt", ".", "world_size", ">", "1", "and", "opt", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "\n", "device_ids", "=", "[", "opt", ".", "local_rank", "]", ",", "\n", "output_device", "=", "opt", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "False", ",", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "# logger.info(\"  Num Epochs = %d\", args.num_train_epochs)", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "opt", ".", "per_gpu_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "opt", ".", "train_batch_size", "*", "opt", ".", "gradient_accumulation_steps", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "opt", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "opt", ".", "total_step", ")", "\n", "logger", ".", "info", "(", "\"  Total number of training epochs = %f\"", ",", "\n", "opt", ".", "total_step", "*", "opt", ".", "train_batch_size", "*", "opt", ".", "gradient_accumulation_steps", "/", "len", "(", "train_dataset", ")", ")", "\n", "\n", "loss", ",", "curr_loss", "=", "0.0", ",", "0.0", "\n", "epoch", "=", "0", "\n", "step", "=", "0", "\n", "model", ".", "train", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "while", "global_step", "<", "opt", ".", "total_step", ":", "\n", "        ", "epoch", "+=", "1", "\n", "if", "opt", ".", "world_size", ">", "1", ":", "\n", "            ", "train_sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "", "for", "i", ",", "batch", "in", "tqdm", "(", "enumerate", "(", "train_dataloader", ")", ")", ":", "\n", "            ", "step", "+=", "1", "\n", "\n", "# Process the inputs", "\n", "idx", ",", "answer_ids", ",", "answer_mask", ",", "context_ids", ",", "context_mask", ",", "has_answer_labels", "=", "batch", "\n", "answer_ids", ",", "answer_mask", "=", "answer_ids", ".", "cuda", "(", ")", ",", "answer_mask", ".", "bool", "(", ")", ".", "cuda", "(", ")", "\n", "has_answer_labels", "=", "has_answer_labels", ".", "cuda", "(", ")", "\n", "labels", "=", "answer_ids", ".", "masked_fill", "(", "~", "answer_mask", ",", "-", "100", ")", "\n", "if", "hasattr", "(", "model", ",", "\"module\"", ")", ":", "\n", "                ", "model", ".", "module", ".", "encoder", ".", "n_passages", "=", "context_ids", ".", "size", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "model", ".", "encoder", ".", "n_passages", "=", "context_ids", ".", "size", "(", "1", ")", "\n", "", "context_ids", "=", "context_ids", ".", "cuda", "(", ")", ".", "view", "(", "context_ids", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "context_mask", "=", "context_mask", ".", "cuda", "(", ")", ".", "view", "(", "context_ids", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "decoder_input_ids", "=", "None", "\n", "\n", "inputs", "=", "{", "\n", "'input_ids'", ":", "context_ids", ",", "\n", "'attention_mask'", ":", "context_mask", ",", "\n", "'decoder_attention_mask'", ":", "answer_mask", ",", "\n", "'decoder_input_ids'", ":", "decoder_input_ids", ",", "\n", "'labels'", ":", "labels", ",", "\n", "'has_answer_labels'", ":", "has_answer_labels", ",", "\n", "}", "\n", "\n", "# Run the model", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "train_loss", "=", "outputs", "[", "0", "]", "\n", "train_loss", "=", "util", ".", "average_master", "(", "train_loss", ",", "opt", ")", "\n", "\n", "if", "opt", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "train_loss", "=", "train_loss", "/", "opt", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "opt", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "train_loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "train_loss", ".", "backward", "(", ")", "\n", "\n", "", "curr_loss", "+=", "train_loss", ".", "item", "(", ")", "\n", "if", "step", "%", "opt", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "# util.clip_gradients(model, opt.clip)", "\n", "                ", "if", "opt", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "opt", ".", "clip", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "trainable_parameters", ",", "opt", ".", "clip", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "opt", ".", "is_master", "and", "global_step", "%", "opt", ".", "log_freq", "==", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "\n", "f\"{global_step} / {opt.total_step} -- train loss = {curr_loss / opt.log_freq:.3f}\"", "\n", "f\" | lr = {scheduler.get_last_lr()[0]:.5f}\"", "\n", ")", "\n", "log_scalar", "(", "\"Train/Loss\"", ",", "curr_loss", "/", "opt", ".", "log_freq", ",", "global_step", ")", "\n", "curr_loss", "=", "0.", "\n", "\n", "", "if", "global_step", "%", "opt", ".", "eval_freq", "==", "0", ":", "\n", "                    ", "results", "=", "evaluate", "(", "model", ",", "dev_dataset", ",", "dev_dataloader", ",", "tokenizer", ",", "opt", ")", "\n", "dev_f1", "=", "results", "[", "\"avg_f1\"", "]", "# use average F1 (across all layers) as evaluation metric", "\n", "if", "opt", ".", "is_master", ":", "\n", "                        ", "logger", ".", "info", "(", "f\"{global_step} / {opt.total_step} -- dev evaluation = {100 * dev_f1:.2f} F1\"", ")", "\n", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "log_scalar", "(", "f\"Dev/{k}\"", ",", "v", ",", "global_step", ")", "\n", "\n", "", "", "if", "dev_f1", ">", "best_metric", ":", "\n", "                        ", "best_metric", "=", "dev_f1", "\n", "if", "opt", ".", "is_master", ":", "\n", "                            ", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", "util", ".", "save", "(", "model_to_save", ",", "optimizer", ",", "scheduler", ",", "global_step", ",", "best_metric", ",", "opt", ",", "dir_path", ",", "\n", "'best_dev'", ")", "\n", "", "", "model", ".", "train", "(", ")", "\n", "\n", "", "if", "opt", ".", "is_master", "and", "global_step", "%", "opt", ".", "save_freq", "==", "0", ":", "\n", "                    ", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", "util", ".", "save", "(", "model_to_save", ",", "optimizer", ",", "scheduler", ",", "global_step", ",", "best_metric", ",", "opt", ",", "dir_path", ",", "\n", "f\"step-{global_step}\"", ")", "\n", "", "if", "global_step", ">", "opt", ".", "total_step", ":", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.train_ac.evaluate": [[213, 276], ["model.eval", "hasattr", "enumerate", "range", "numpy.mean", "collections.defaultdict", "torch.no_grad", "torch.no_grad", "enumerate", "results.items", "all_f1.append", "range", "has_answer_labels.cuda.cuda", "answer_ids.masked_fill", "hasattr", "context_ids.cuda().view.cuda().view", "context_mask.cuda().view.cuda().view", "model", "torch.numel", "torch.numel", "enumerate", "zip", "max", "answer_ids.cuda", "answer_mask.bool().cuda", "context_ids.cuda().view.size", "context_ids.cuda().view.size", "context_ids.cuda().view.size", "context_ids.cuda().view.size", "torch.sum().item", "torch.sum().item", "[].append", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "[].append", "[].append", "sum", "max", "context_ids.cuda().view.cuda", "context_mask.cuda().view.cuda", "sum", "answer_mask.bool", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.eq", "torch.eq", "logits.sigmoid", "logits.sigmoid"], "function", ["None"], ["", "", "", "", "", "def", "evaluate", "(", "model", ",", "dataset", ",", "dataloader", ",", "tokenizer", ",", "opt", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "if", "hasattr", "(", "model", ",", "\"module\"", ")", ":", "\n", "        ", "model", "=", "model", ".", "module", "\n", "\n", "", "num_layers", "=", "model", ".", "encoder", ".", "config", ".", "num_layers", "\n", "all_results", "=", "[", "defaultdict", "(", "list", ")", "for", "_", "in", "range", "(", "num_layers", ")", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "            ", "idx", ",", "answer_ids", ",", "answer_mask", ",", "context_ids", ",", "context_mask", ",", "has_answer_labels", "=", "batch", "\n", "answer_ids", ",", "answer_mask", "=", "answer_ids", ".", "cuda", "(", ")", ",", "answer_mask", ".", "bool", "(", ")", ".", "cuda", "(", ")", "\n", "has_answer_labels", "=", "has_answer_labels", ".", "cuda", "(", ")", "\n", "labels", "=", "answer_ids", ".", "masked_fill", "(", "~", "answer_mask", ",", "-", "100", ")", "\n", "if", "hasattr", "(", "model", ",", "\"module\"", ")", ":", "\n", "                ", "model", ".", "module", ".", "encoder", ".", "n_passages", "=", "context_ids", ".", "size", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "model", ".", "encoder", ".", "n_passages", "=", "context_ids", ".", "size", "(", "1", ")", "\n", "", "context_ids", "=", "context_ids", ".", "cuda", "(", ")", ".", "view", "(", "context_ids", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "context_mask", "=", "context_mask", ".", "cuda", "(", ")", ".", "view", "(", "context_ids", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "decoder_input_ids", "=", "None", "\n", "\n", "inputs", "=", "{", "\n", "'input_ids'", ":", "context_ids", ",", "\n", "'attention_mask'", ":", "context_mask", ",", "\n", "'decoder_attention_mask'", ":", "answer_mask", ",", "\n", "'decoder_input_ids'", ":", "decoder_input_ids", ",", "\n", "'labels'", ":", "labels", ",", "\n", "'has_answer_labels'", ":", "has_answer_labels", ",", "\n", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "all_has_answer_outputs", "=", "outputs", "[", "-", "1", "]", "# Tuple[Tensor], shape: [bsz, n_passages]", "\n", "\n", "count", "=", "torch", ".", "numel", "(", "has_answer_labels", ")", "\n", "for", "layer_idx", ",", "logits", "in", "enumerate", "(", "all_has_answer_outputs", ")", ":", "\n", "                ", "correct", "=", "torch", ".", "sum", "(", "torch", ".", "eq", "(", "(", "logits", ".", "sigmoid", "(", ")", ">", "0.5", ")", ".", "float", "(", ")", ",", "has_answer_labels", ")", ")", ".", "item", "(", ")", "\n", "all_results", "[", "layer_idx", "]", "[", "\"acc\"", "]", ".", "append", "(", "(", "correct", ",", "count", ")", ")", "\n", "\n", "predictions", "=", "(", "logits", ".", "sigmoid", "(", ")", ">", "0.5", ")", ".", "float", "(", ")", "\n", "true_positive", "=", "torch", ".", "sum", "(", "predictions", "*", "has_answer_labels", ")", ".", "item", "(", ")", "\n", "pred_positive", "=", "torch", ".", "sum", "(", "predictions", ")", ".", "item", "(", ")", "\n", "gt_positive", "=", "torch", ".", "sum", "(", "has_answer_labels", ")", ".", "item", "(", ")", "\n", "\n", "all_results", "[", "layer_idx", "]", "[", "\"prec\"", "]", ".", "append", "(", "(", "true_positive", ",", "pred_positive", ")", ")", "\n", "all_results", "[", "layer_idx", "]", "[", "\"recall\"", "]", ".", "append", "(", "(", "true_positive", ",", "gt_positive", ")", ")", "\n", "\n", "", "", "", "final_results", "=", "{", "}", "\n", "for", "idx", ",", "results", "in", "enumerate", "(", "all_results", ")", ":", "\n", "        ", "for", "metric", ",", "values", "in", "results", ".", "items", "(", ")", ":", "\n", "            ", "value_list", ",", "count_list", "=", "zip", "(", "*", "values", ")", "\n", "final_results", "[", "f\"layer{idx}/{metric}\"", "]", "=", "sum", "(", "value_list", ")", "/", "max", "(", "sum", "(", "count_list", ")", ",", "1", ")", "\n", "\n", "", "", "all_f1", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "num_layers", ")", ":", "\n", "        ", "prec", "=", "final_results", "[", "f\"layer{idx}/prec\"", "]", "\n", "recall", "=", "final_results", "[", "f\"layer{idx}/recall\"", "]", "\n", "f1", "=", "2", "*", "prec", "*", "recall", "/", "max", "(", "prec", "+", "recall", ",", "1e-5", ")", "\n", "final_results", "[", "f\"layer{idx}/f1\"", "]", "=", "f1", "\n", "all_f1", ".", "append", "(", "f1", ")", "\n", "\n", "", "average_f1", "=", "np", ".", "mean", "(", "all_f1", ")", "\n", "final_results", "[", "\"avg_f1\"", "]", "=", "average_f1", "\n", "return", "final_results", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.train_ac_scheduler.log_scalar": [[42, 46], ["tb_logger.add_scalar", "wandb.log"], "function", ["None"], ["", "def", "log_scalar", "(", "name", ",", "value", ",", "step", ")", ":", "\n", "    ", "tb_logger", ".", "add_scalar", "(", "name", ",", "value", ",", "step", ")", "\n", "if", "_has_wandb", ":", "\n", "        ", "wandb", ".", "log", "(", "{", "name", ":", "value", ",", "\"step\"", ":", "step", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.train_ac_scheduler.train_evaluate": [[48, 219], ["torch.utils.data.DataLoader", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "list", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.train", "torch.nn.parallel.DistributedDataParallel.zero_grad", "torch.utils.data.RandomSampler", "torch.utils.data.DistributedSampler", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.optim.Adam", "torch.optim.Adam", "util.FixedScheduler", "amp.initialize", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "tqdm.auto.tqdm", "n.startswith", "len", "train_sampler.set_epoch", "enumerate", "has_answer_labels.cuda.cuda", "answer_ids.masked_fill", "hasattr", "context_ids.cuda().view.cuda().view", "context_mask.cuda().view.cuda().view", "torch.nn.parallel.DistributedDataParallel.", "util.average_master", "util.average_master", "util.average_master.item", "util.average_master.item", "n.startswith", "n.startswith", "new_np.append", "new_np.append", "ImportError", "answer_ids.cuda", "answer_mask.bool().cuda", "context_ids.cuda().view.size", "context_ids.cuda().view.size", "context_ids.cuda().view.size", "context_ids.cuda().view.size", "util.average_master.backward", "torch.optim.Adam.step", "util.FixedScheduler.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "context_ids.cuda().view.cuda", "context_mask.cuda().view.cuda", "float", "float", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "logger.info", "train_ac_scheduler.log_scalar", "train_ac_scheduler.log_scalar", "train_ac_scheduler.evaluate", "torch.nn.parallel.DistributedDataParallel.train", "util.save", "answer_mask.bool", "amp.master_params", "logger.info", "evaluate.items", "hasattr", "train_ac_scheduler.log_scalar", "util.save", "hasattr", "util.FixedScheduler.get_last_lr"], "function", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.options.Options.initialize", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.average_master", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.average_master", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.train_ac_scheduler.log_scalar", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.train_ac_scheduler.log_scalar", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.test_retrieval_acc.evaluate", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.save", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.train_ac_scheduler.log_scalar", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.save"], ["", "", "def", "train_evaluate", "(", "model", ",", "optimizer", ",", "scheduler", ",", "global_step", ",", "\n", "train_dataset", ",", "dev_dataset", ",", "opt", ",", "collator_function", ",", "best_metric", ")", ":", "\n", "    ", "train_sampler", "=", "(", "RandomSampler", "(", "train_dataset", ")", "if", "opt", ".", "local_rank", "==", "-", "1", "or", "opt", ".", "world_size", "==", "1", "\n", "else", "DistributedSampler", "(", "train_dataset", ")", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "opt", ".", "per_gpu_batch_size", ",", "drop_last", "=", "True", ",", "num_workers", "=", "3", ",", "\n", "collate_fn", "=", "collator_function", ")", "\n", "\n", "dev_sampler", "=", "SequentialSampler", "(", "dev_dataset", ")", "\n", "dev_dataloader", "=", "DataLoader", "(", "dev_dataset", ",", "sampler", "=", "dev_sampler", ",", "batch_size", "=", "opt", ".", "per_gpu_batch_size", ",", "\n", "shuffle", "=", "False", ",", "num_workers", "=", "3", ",", "collate_fn", "=", "collator_function", ")", "\n", "\n", "# Freeze the FiD parameters and only train AC part.", "\n", "trainable_np", "=", "list", "(", "model", ".", "named_parameters", "(", ")", ")", "\n", "if", "opt", ".", "freeze_fid_params", ":", "\n", "        ", "new_np", "=", "[", "]", "\n", "for", "n", ",", "p", "in", "trainable_np", ":", "\n", "            ", "if", "n", ".", "startswith", "(", "\"encoder.has_answer_heads\"", ")", "or", "n", ".", "startswith", "(", "\"ac_scheduler\"", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "True", "\n", "new_np", ".", "append", "(", "(", "n", ",", "p", ")", ")", "\n", "", "else", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "", "", "trainable_np", "=", "new_np", "\n", "\n", "", "if", "opt", ".", "freeze_has_answer_heads", ":", "\n", "        ", "new_np", "=", "[", "]", "\n", "for", "n", ",", "p", "in", "trainable_np", ":", "\n", "            ", "if", "n", ".", "startswith", "(", "\"encoder.has_answer_heads\"", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "", "else", ":", "\n", "                ", "p", ".", "requires_grad", "=", "True", "\n", "new_np", ".", "append", "(", "(", "n", ",", "p", ")", ")", "\n", "", "", "trainable_np", "=", "new_np", "\n", "\n", "", "trainable_parameters", "=", "[", "p", "for", "n", ",", "p", "in", "trainable_np", "]", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "if", "optimizer", "is", "None", "or", "scheduler", "is", "None", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "trainable_parameters", ",", "lr", "=", "opt", ".", "lr", ")", "\n", "# optimizer = torch.optim.SGD(trainable_parameters, lr=opt.lr)", "\n", "scheduler", "=", "util", ".", "FixedScheduler", "(", "optimizer", ")", "\n", "\n", "# fp16", "\n", "", "if", "opt", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "opt", ".", "fp16_opt_level", ")", "\n", "\n", "# Distributed training", "\n", "", "if", "opt", ".", "world_size", ">", "1", "and", "opt", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "\n", "device_ids", "=", "[", "opt", ".", "local_rank", "]", ",", "\n", "output_device", "=", "opt", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "False", ",", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "# logger.info(\"  Num Epochs = %d\", args.num_train_epochs)", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "opt", ".", "per_gpu_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "opt", ".", "train_batch_size", "*", "opt", ".", "gradient_accumulation_steps", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "opt", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "opt", ".", "total_step", ")", "\n", "logger", ".", "info", "(", "\"  Total number of training epochs = %f\"", ",", "\n", "opt", ".", "total_step", "*", "opt", ".", "train_batch_size", "*", "opt", ".", "gradient_accumulation_steps", "/", "len", "(", "train_dataset", ")", ")", "\n", "\n", "loss", ",", "curr_loss", ",", "curr_reward", "=", "0.0", ",", "0.0", ",", "0.0", "\n", "epoch", "=", "0", "\n", "step", "=", "0", "\n", "model", ".", "train", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "while", "global_step", "<", "opt", ".", "total_step", ":", "\n", "        ", "epoch", "+=", "1", "\n", "if", "opt", ".", "world_size", ">", "1", ":", "\n", "            ", "train_sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "", "for", "i", ",", "batch", "in", "tqdm", "(", "enumerate", "(", "train_dataloader", ")", ")", ":", "\n", "            ", "step", "+=", "1", "\n", "\n", "# Process the inputs", "\n", "idx", ",", "answer_ids", ",", "answer_mask", ",", "context_ids", ",", "context_mask", ",", "has_answer_labels", "=", "batch", "\n", "answer_ids", ",", "answer_mask", "=", "answer_ids", ".", "cuda", "(", ")", ",", "answer_mask", ".", "bool", "(", ")", ".", "cuda", "(", ")", "\n", "has_answer_labels", "=", "has_answer_labels", ".", "cuda", "(", ")", "\n", "labels", "=", "answer_ids", ".", "masked_fill", "(", "~", "answer_mask", ",", "-", "100", ")", "\n", "if", "hasattr", "(", "model", ",", "\"module\"", ")", ":", "\n", "                ", "model", ".", "module", ".", "encoder", ".", "n_passages", "=", "context_ids", ".", "size", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "model", ".", "encoder", ".", "n_passages", "=", "context_ids", ".", "size", "(", "1", ")", "\n", "", "context_ids", "=", "context_ids", ".", "cuda", "(", ")", ".", "view", "(", "context_ids", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "context_mask", "=", "context_mask", ".", "cuda", "(", ")", ".", "view", "(", "context_ids", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "decoder_input_ids", "=", "None", "\n", "\n", "inputs", "=", "{", "\n", "'input_ids'", ":", "context_ids", ",", "\n", "'attention_mask'", ":", "context_mask", ",", "\n", "'decoder_attention_mask'", ":", "answer_mask", ",", "\n", "'decoder_input_ids'", ":", "decoder_input_ids", ",", "\n", "'labels'", ":", "labels", ",", "\n", "'has_answer_labels'", ":", "has_answer_labels", ",", "\n", "}", "\n", "\n", "# Run the model", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "train_loss", "=", "outputs", "[", "0", "]", "\n", "train_loss", "=", "util", ".", "average_master", "(", "train_loss", ",", "opt", ")", "\n", "train_reward", "=", "outputs", "[", "1", "]", "\n", "train_reward", "=", "util", ".", "average_master", "(", "train_reward", ",", "opt", ")", "\n", "\n", "if", "opt", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "train_loss", "=", "train_loss", "/", "float", "(", "opt", ".", "gradient_accumulation_steps", ")", "\n", "train_reward", "=", "train_reward", "/", "float", "(", "opt", ".", "gradient_accumulation_steps", ")", "\n", "\n", "", "if", "opt", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "train_loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "train_loss", ".", "backward", "(", ")", "\n", "\n", "", "curr_loss", "+=", "train_loss", ".", "item", "(", ")", "\n", "curr_reward", "+=", "train_reward", ".", "item", "(", ")", "\n", "if", "step", "%", "opt", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "# util.clip_gradients(model, opt.clip)", "\n", "                ", "if", "opt", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "opt", ".", "clip", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "trainable_parameters", ",", "opt", ".", "clip", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "opt", ".", "is_master", "and", "global_step", "%", "opt", ".", "log_freq", "==", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "\n", "f\"{global_step} / {opt.total_step} -- train loss = {curr_loss / opt.log_freq}\"", "\n", "f\" | train reward = {curr_reward / opt.log_freq:.3f}\"", "\n", "f\" | lr = {scheduler.get_last_lr()[0]}\"", "\n", ")", "\n", "log_scalar", "(", "\"Train/Loss\"", ",", "curr_loss", "/", "opt", ".", "log_freq", ",", "global_step", ")", "\n", "log_scalar", "(", "\"Train/Reward\"", ",", "curr_reward", "/", "opt", ".", "log_freq", ",", "global_step", ")", "\n", "curr_loss", "=", "0.", "\n", "curr_reward", "=", "0.", "\n", "\n", "", "if", "global_step", "%", "opt", ".", "eval_freq", "==", "0", ":", "\n", "                    ", "results", "=", "evaluate", "(", "model", ",", "dev_dataset", ",", "dev_dataloader", ",", "tokenizer", ",", "opt", ")", "\n", "dev_reward", "=", "results", "[", "\"reward\"", "]", "# use reward as evaluation metric", "\n", "if", "opt", ".", "is_master", ":", "\n", "                        ", "logger", ".", "info", "(", "f\"{global_step} / {opt.total_step} -- dev reward = {dev_reward:.2f}\"", ")", "\n", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "log_scalar", "(", "f\"Dev/{k}\"", ",", "v", ",", "global_step", ")", "\n", "\n", "", "", "if", "dev_reward", ">", "best_metric", ":", "\n", "                        ", "best_metric", "=", "dev_reward", "\n", "if", "opt", ".", "is_master", ":", "\n", "                            ", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", "util", ".", "save", "(", "model_to_save", ",", "optimizer", ",", "scheduler", ",", "global_step", ",", "best_metric", ",", "opt", ",", "dir_path", ",", "\n", "'best_dev'", ")", "\n", "", "", "model", ".", "train", "(", ")", "\n", "\n", "", "if", "opt", ".", "is_master", "and", "global_step", "%", "opt", ".", "save_freq", "==", "0", ":", "\n", "                    ", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", "util", ".", "save", "(", "model_to_save", ",", "optimizer", ",", "scheduler", ",", "global_step", ",", "best_metric", ",", "opt", ",", "dir_path", ",", "\n", "f\"step-{global_step}\"", ")", "\n", "", "if", "global_step", ">", "opt", ".", "total_step", ":", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.train_ac_scheduler.evaluate": [[221, 256], ["model.eval", "hasattr", "torch.no_grad", "torch.no_grad", "enumerate", "numpy.mean", "has_answer_labels.cuda.cuda", "answer_ids.masked_fill", "hasattr", "context_ids.cuda().view.cuda().view", "context_mask.cuda().view.cuda().view", "model", "outputs[].item", "all_rewards.append", "answer_ids.cuda", "answer_mask.bool().cuda", "context_ids.cuda().view.size", "context_ids.cuda().view.size", "context_ids.cuda().view.size", "context_ids.cuda().view.size", "context_ids.cuda().view.cuda", "context_mask.cuda().view.cuda", "answer_mask.bool"], "function", ["None"], ["", "", "", "", "", "def", "evaluate", "(", "model", ",", "dataset", ",", "dataloader", ",", "tokenizer", ",", "opt", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "if", "hasattr", "(", "model", ",", "\"module\"", ")", ":", "\n", "        ", "model", "=", "model", ".", "module", "\n", "\n", "", "all_rewards", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "            ", "idx", ",", "answer_ids", ",", "answer_mask", ",", "context_ids", ",", "context_mask", ",", "has_answer_labels", "=", "batch", "\n", "answer_ids", ",", "answer_mask", "=", "answer_ids", ".", "cuda", "(", ")", ",", "answer_mask", ".", "bool", "(", ")", ".", "cuda", "(", ")", "\n", "has_answer_labels", "=", "has_answer_labels", ".", "cuda", "(", ")", "\n", "labels", "=", "answer_ids", ".", "masked_fill", "(", "~", "answer_mask", ",", "-", "100", ")", "\n", "if", "hasattr", "(", "model", ",", "\"module\"", ")", ":", "\n", "                ", "model", ".", "module", ".", "encoder", ".", "n_passages", "=", "context_ids", ".", "size", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "model", ".", "encoder", ".", "n_passages", "=", "context_ids", ".", "size", "(", "1", ")", "\n", "", "context_ids", "=", "context_ids", ".", "cuda", "(", ")", ".", "view", "(", "context_ids", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "context_mask", "=", "context_mask", ".", "cuda", "(", ")", ".", "view", "(", "context_ids", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "decoder_input_ids", "=", "None", "\n", "\n", "inputs", "=", "{", "\n", "'input_ids'", ":", "context_ids", ",", "\n", "'attention_mask'", ":", "context_mask", ",", "\n", "'decoder_attention_mask'", ":", "answer_mask", ",", "\n", "'decoder_input_ids'", ":", "decoder_input_ids", ",", "\n", "'labels'", ":", "labels", ",", "\n", "'has_answer_labels'", ":", "has_answer_labels", ",", "\n", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "mean_rewards", "=", "outputs", "[", "1", "]", ".", "item", "(", ")", "\n", "all_rewards", ".", "append", "(", "mean_rewards", ")", "\n", "\n", "", "", "final_results", "=", "{", "\"reward\"", ":", "np", ".", "mean", "(", "all_rewards", ")", "}", "\n", "return", "final_results", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.data_ac.QAExample.__init__": [[7, 14], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "id", ",", "question", ",", "answers", ",", "target", "=", "None", ",", "titles", "=", "None", ",", "contexts", "=", "None", ")", ":", "\n", "        ", "self", ".", "id", "=", "id", "\n", "self", ".", "question", "=", "question", "\n", "self", ".", "answers", "=", "answers", "\n", "self", ".", "target", "=", "target", "\n", "self", ".", "titles", "=", "titles", "\n", "self", ".", "contexts", "=", "contexts", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.data_ac.Dataset.__init__": [[17, 26], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "n_context", ",", "tokenizer", ",", "max_passage_length", "=", "250", ",", "no_title", "=", "False", ")", ":", "\n", "        ", "self", ".", "data", "=", "data", "\n", "self", ".", "n_context", "=", "n_context", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "max_passage_length", "=", "max_passage_length", "\n", "self", ".", "no_title", "=", "no_title", "\n", "self", ".", "question_prefix", "=", "'question:'", "\n", "self", ".", "title_prefix", "=", "'title:'", "\n", "self", ".", "context_prefix", "=", "'context:'", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.data_ac.Dataset.__len__": [[27, 29], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.data_ac.Dataset.__getitem__": [[30, 58], ["range", "random.choice", "len", "passages.append", "min", "passages.append", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "example", "=", "self", ".", "data", "[", "index", "]", "\n", "question", "=", "example", ".", "question", "\n", "if", "example", ".", "target", "is", "None", ":", "\n", "            ", "target", "=", "random", ".", "choice", "(", "example", ".", "answers", ")", "\n", "", "else", ":", "\n", "            ", "target", "=", "example", ".", "target", "\n", "\n", "", "titles", "=", "example", ".", "titles", "[", ":", "self", ".", "n_context", "]", "\n", "contexts", "=", "example", ".", "contexts", "[", ":", "self", ".", "n_context", "]", "\n", "\n", "passages", "=", "[", "]", "\n", "if", "len", "(", "contexts", ")", "==", "0", ":", "\n", "            ", "to_concatenate", "=", "[", "self", ".", "question_prefix", ",", "question", "]", "\n", "text", "=", "' '", ".", "join", "(", "to_concatenate", ")", "\n", "passages", ".", "append", "(", "text", ")", "\n", "", "for", "i", "in", "range", "(", "min", "(", "self", ".", "n_context", ",", "len", "(", "contexts", ")", ")", ")", ":", "\n", "            ", "c", "=", "contexts", "[", "i", "]", "\n", "t", "=", "titles", "[", "i", "]", "\n", "to_concatenate", "=", "[", "self", ".", "question_prefix", ",", "question", "]", "\n", "if", "c", "is", "not", "None", ":", "\n", "                ", "if", "not", "self", ".", "no_title", ":", "\n", "                    ", "to_concatenate", "+=", "[", "self", ".", "title_prefix", ",", "t", "]", "\n", "", "to_concatenate", "+=", "[", "self", ".", "context_prefix", ",", "c", "]", "\n", "", "text", "=", "' '", ".", "join", "(", "to_concatenate", ")", "\n", "passages", ".", "append", "(", "text", ")", "\n", "\n", "", "return", "{", "'index'", ":", "index", ",", "'question'", ":", "question", ",", "'target'", ":", "target", ",", "'passages'", ":", "passages", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.data_ac.Dataset.get_example": [[59, 61], ["None"], "methods", ["None"], ["", "def", "get_example", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "data", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.data_ac.Collator.__init__": [[64, 68], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "tokenizer", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "max_passage_length", "=", "opt", ".", "max_passage_length", "\n", "self", ".", "model_type", "=", "opt", ".", "model_type", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.data_ac.Collator.__call__": [[69, 125], ["torch.tensor", "data_ac.Collator.tokenizer.batch_encode_plus", "enumerate", "min", "enumerate", "torch.stack", "torch.stack", "zip", "torch.tensor", "batch_encoded_passages.append", "torch.stack", "torch.stack", "torch.stack.append", "torch.stack.append", "torch.tensor.append", "data_ac.Collator.tokenizer.encode", "max", "encoded_passages.append", "len", "torch.cat", "torch.stack.append", "torch.cat", "torch.stack.append", "has_answer_labels.append", "len", "len", "torch.tensor", "torch.zeros().long", "torch.ones().bool", "torch.zeros().bool", "torch.zeros", "torch.ones", "torch.zeros"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "batch", ")", ":", "\n", "        ", "index", "=", "torch", ".", "tensor", "(", "[", "ex", "[", "'index'", "]", "for", "ex", "in", "batch", "]", ")", "\n", "question", "=", "[", "ex", "[", "'question'", "]", "for", "ex", "in", "batch", "]", "\n", "if", "self", ".", "model_type", "==", "'bart'", ":", "\n", "            ", "target", "=", "[", "ex", "[", "'target'", "]", "for", "ex", "in", "batch", "]", "\n", "", "else", ":", "\n", "            ", "target", "=", "[", "ex", "[", "'target'", "]", "+", "' </s>'", "for", "ex", "in", "batch", "]", "\n", "", "target", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "target", ",", "pad_to_max_length", "=", "True", ",", "return_tensors", "=", "\"pt\"", ")", "\n", "target_ids", ",", "target_mask", "=", "target", "[", "\"input_ids\"", "]", ",", "target", "[", "\"attention_mask\"", "]", "\n", "\n", "batch_text_passages", "=", "[", "ex", "[", "'passages'", "]", "for", "ex", "in", "batch", "]", "\n", "batch_encoded_passages", "=", "[", "]", "\n", "\n", "# Encode the passages", "\n", "max_context_length", "=", "0", "\n", "for", "k", ",", "text_passages", "in", "enumerate", "(", "batch_text_passages", ")", ":", "\n", "            ", "encoded_passages", "=", "[", "]", "\n", "for", "text_p", "in", "text_passages", ":", "\n", "                ", "encoded_p", "=", "self", ".", "tokenizer", ".", "encode", "(", "text_p", ")", "\n", "if", "len", "(", "encoded_p", ")", ">", "self", ".", "max_passage_length", ":", "\n", "                    ", "encoded_p", "=", "encoded_p", "[", ":", "self", ".", "max_passage_length", "]", "\n", "", "max_context_length", "=", "max", "(", "max_context_length", ",", "len", "(", "encoded_p", ")", ")", "\n", "encoded_passages", ".", "append", "(", "encoded_p", ")", "\n", "", "batch_encoded_passages", ".", "append", "(", "encoded_passages", ")", "\n", "", "max_context_length", "=", "min", "(", "max_context_length", ",", "self", ".", "max_passage_length", ")", "\n", "\n", "# Pad the passages to maximum length", "\n", "batch_passage_ids", ",", "batch_passage_masks", "=", "[", "]", ",", "[", "]", "\n", "for", "k", ",", "encoded_passages", "in", "enumerate", "(", "batch_encoded_passages", ")", ":", "\n", "            ", "p_ids", ",", "p_masks", "=", "[", "]", ",", "[", "]", "\n", "for", "p", "in", "encoded_passages", ":", "\n", "                ", "plen", "=", "len", "(", "p", ")", "\n", "c", "=", "torch", ".", "cat", "(", "(", "torch", ".", "tensor", "(", "p", ")", ",", "torch", ".", "zeros", "(", "max_context_length", "-", "plen", ")", ".", "long", "(", ")", ")", ",", "dim", "=", "0", ")", "# shape: [L]", "\n", "p_ids", ".", "append", "(", "c", ")", "\n", "m", "=", "torch", ".", "cat", "(", "(", "torch", ".", "ones", "(", "plen", ")", ".", "bool", "(", ")", ",", "torch", ".", "zeros", "(", "max_context_length", "-", "plen", ")", ".", "bool", "(", ")", ")", ",", "\n", "dim", "=", "0", ")", "# shape: [L]", "\n", "p_masks", ".", "append", "(", "m", ")", "\n", "", "p_ids", "=", "torch", ".", "stack", "(", "p_ids", ",", "dim", "=", "0", ")", "# shape: [N, L], N is the number of passages", "\n", "p_masks", "=", "torch", ".", "stack", "(", "p_masks", ",", "dim", "=", "0", ")", "# shape: [N, L]", "\n", "batch_passage_ids", ".", "append", "(", "p_ids", ")", "\n", "batch_passage_masks", ".", "append", "(", "p_masks", ")", "\n", "\n", "", "batch_passage_ids", "=", "torch", ".", "stack", "(", "batch_passage_ids", ",", "dim", "=", "0", ")", "# shape: [B, N, L], B is the batch size", "\n", "batch_passage_masks", "=", "torch", ".", "stack", "(", "batch_passage_masks", ",", "dim", "=", "0", ")", "# shape: [B, N, L]", "\n", "\n", "# Get the has_answer labels for training the adaptive computation mechanisms", "\n", "batch_answers", "=", "[", "ex", "[", "'target'", "]", "for", "ex", "in", "batch", "]", "\n", "batch_has_answer_labels", "=", "[", "]", "\n", "for", "text_passages", ",", "answer", "in", "zip", "(", "batch_text_passages", ",", "batch_answers", ")", ":", "\n", "            ", "has_answer_labels", "=", "[", "]", "\n", "for", "text_p", "in", "text_passages", ":", "\n", "                ", "has_answer_labels", ".", "append", "(", "1.", "if", "answer", "in", "text_p", "else", "0.", ")", "\n", "", "batch_has_answer_labels", ".", "append", "(", "has_answer_labels", ")", "\n", "", "batch_has_answer_labels", "=", "torch", ".", "tensor", "(", "batch_has_answer_labels", ")", "# shape: [B, N]", "\n", "\n", "return", "index", ",", "target_ids", ",", "target_mask", ",", "batch_passage_ids", ",", "batch_passage_masks", ",", "batch_has_answer_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.data_ac.load_data": [[127, 158], ["enumerate", "open", "json.load", "data_ac.QAExample", "examples.append", "enumerate", "titles.append", "contexts.append"], "function", ["None"], ["", "", "def", "load_data", "(", "data_path", ",", "global_rank", "=", "-", "1", ",", "world_size", "=", "-", "1", ",", "n_context", "=", "None", ")", ":", "\n", "    ", "with", "open", "(", "data_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "examples", "=", "[", "]", "\n", "for", "k", ",", "example", "in", "enumerate", "(", "data", ")", ":", "\n", "        ", "if", "global_rank", ">", "-", "1", "and", "not", "k", "%", "world_size", "==", "global_rank", ":", "\n", "            ", "continue", "\n", "", "if", "'id'", "in", "example", ":", "\n", "            ", "id", "=", "example", "[", "'id'", "]", "\n", "", "else", ":", "\n", "            ", "id", "=", "k", "\n", "", "if", "'target'", "in", "example", ":", "\n", "            ", "target", "=", "example", "[", "'target'", "]", "\n", "", "else", ":", "\n", "            ", "target", "=", "None", "\n", "", "answers", "=", "example", "[", "'answers'", "]", "\n", "question", "=", "example", "[", "'question'", "]", "\n", "titles", ",", "contexts", "=", "[", "]", ",", "[", "]", "\n", "if", "'ctxs'", "in", "example", ":", "\n", "            ", "ctxs", "=", "example", "[", "'ctxs'", "]", "\n", "if", "n_context", "is", "not", "None", ":", "\n", "                ", "ctxs", "=", "ctxs", "[", ":", "n_context", "]", "\n", "", "for", "i", ",", "c", "in", "enumerate", "(", "ctxs", ")", ":", "\n", "                ", "titles", ".", "append", "(", "c", "[", "'title'", "]", ")", "\n", "contexts", ".", "append", "(", "c", "[", "'text'", "]", ")", "\n", "", "", "ex", "=", "QAExample", "(", "id", "=", "id", ",", "question", "=", "question", ",", "answers", "=", "answers", ",", "target", "=", "target", ",", "titles", "=", "titles", ",", "contexts", "=", "contexts", ")", "\n", "examples", ".", "append", "(", "ex", ")", "\n", "\n", "", "del", "data", "\n", "return", "examples", "\n", "", ""]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.train.train_evaluate": [[24, 100], ["torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "model.train", "torch.utils.tensorboard.SummaryWriter", "torch.utils.data.RandomSampler", "torch.utils.data.DistributedSampler", "tqdm.auto.tqdm", "os.path.join", "train_sampler.set_epoch", "enumerate", "answer_ids.masked_fill", "hasattr", "context_ids.cuda().view.cuda().view", "context_mask.cuda().view.cuda().view", "model.zero_grad", "util.average_master.backward", "util.clip_gradients", "optimizer.step", "scheduler.step", "util.average_master", "util.average_master.item", "answer_ids.cuda", "answer_mask.bool().cuda", "context_ids.cuda().view.size", "context_ids.cuda().view.size", "context_ids.cuda().view.size", "context_ids.cuda().view.size", "model", "train.evaluate", "model.train", "logger.info", "torch.utils.tensorboard.SummaryWriter.add_scalar", "util.save", "context_ids.cuda().view.cuda", "context_mask.cuda().view.cuda", "torch.utils.tensorboard.SummaryWriter.add_scalar", "hasattr", "answer_mask.bool", "util.save", "hasattr", "scheduler.get_last_lr"], "function", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.clip_gradients", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.average_master", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.test_retrieval_acc.evaluate", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.save", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.save"], ["def", "train_evaluate", "(", "model", ",", "optimizer", ",", "scheduler", ",", "global_step", ",", "\n", "train_dataset", ",", "dev_dataset", ",", "opt", ",", "collator_function", ",", "best_dev_em", ")", ":", "\n", "    ", "if", "opt", ".", "is_master", ":", "\n", "        ", "tb_logger", "=", "SummaryWriter", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_dir", ",", "opt", ".", "name", ")", ")", "\n", "\n", "", "train_sampler", "=", "(", "RandomSampler", "(", "train_dataset", ")", "if", "opt", ".", "local_rank", "==", "-", "1", "or", "opt", ".", "world_size", "==", "1", "\n", "else", "DistributedSampler", "(", "train_dataset", ")", ")", "\n", "dev_sampler", "=", "SequentialSampler", "(", "dev_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "opt", ".", "per_gpu_batch_size", ",", "drop_last", "=", "True", ",", "num_workers", "=", "20", ",", "\n", "collate_fn", "=", "collator_function", ")", "\n", "dev_dataloader", "=", "DataLoader", "(", "dev_dataset", ",", "sampler", "=", "dev_sampler", ",", "batch_size", "=", "opt", ".", "per_gpu_batch_size", ",", "\n", "drop_last", "=", "True", ",", "num_workers", "=", "20", ",", "collate_fn", "=", "collator_function", ")", "\n", "\n", "loss", ",", "curr_loss", "=", "0.0", ",", "0.0", "\n", "epoch", "=", "1", "\n", "model", ".", "train", "(", ")", "\n", "while", "global_step", "<", "opt", ".", "total_step", ":", "\n", "        ", "if", "opt", ".", "world_size", ">", "1", ":", "\n", "            ", "train_sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "", "epoch", "+=", "1", "\n", "for", "i", ",", "batch", "in", "tqdm", "(", "enumerate", "(", "train_dataloader", ")", ")", ":", "\n", "            ", "global_step", "+=", "1", "\n", "idx", ",", "answer_ids", ",", "answer_mask", ",", "context_ids", ",", "context_mask", "=", "batch", "\n", "answer_ids", ",", "answer_mask", "=", "answer_ids", ".", "cuda", "(", ")", ",", "answer_mask", ".", "bool", "(", ")", ".", "cuda", "(", ")", "\n", "labels", "=", "answer_ids", ".", "masked_fill", "(", "~", "answer_mask", ",", "-", "100", ")", "\n", "if", "hasattr", "(", "model", ",", "\"module\"", ")", ":", "\n", "                ", "model", ".", "module", ".", "encoder", ".", "n_passages", "=", "context_ids", ".", "size", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "model", ".", "encoder", ".", "n_passages", "=", "context_ids", ".", "size", "(", "1", ")", "\n", "", "context_ids", "=", "context_ids", ".", "cuda", "(", ")", ".", "view", "(", "context_ids", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "context_mask", "=", "context_mask", ".", "cuda", "(", ")", ".", "view", "(", "context_ids", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "decoder_input_ids", "=", "None", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "inputs", "=", "{", "\n", "'input_ids'", ":", "context_ids", ",", "\n", "'attention_mask'", ":", "context_mask", ",", "\n", "'decoder_attention_mask'", ":", "answer_mask", ",", "\n", "'decoder_input_ids'", ":", "decoder_input_ids", ",", "\n", "'labels'", ":", "labels", ",", "\n", "}", "\n", "train_loss", "=", "model", "(", "**", "inputs", ")", "[", "0", "]", "\n", "train_loss", ".", "backward", "(", ")", "\n", "util", ".", "clip_gradients", "(", "model", ",", "opt", ".", "clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "train_loss", "=", "util", ".", "average_master", "(", "train_loss", ",", "opt", ")", "\n", "curr_loss", "+=", "train_loss", ".", "item", "(", ")", "\n", "\n", "if", "global_step", "%", "opt", ".", "eval_freq", "==", "0", ":", "\n", "                ", "dev_em", "=", "evaluate", "(", "model", ",", "dev_dataset", ",", "dev_dataloader", ",", "tokenizer", ",", "opt", ")", "\n", "if", "opt", ".", "is_master", ":", "\n", "                    ", "tb_logger", ".", "add_scalar", "(", "\"Evaluation\"", ",", "dev_em", ",", "global_step", ")", "\n", "", "if", "dev_em", ">", "best_dev_em", ":", "\n", "                    ", "best_dev_em", "=", "dev_em", "\n", "if", "opt", ".", "is_master", ":", "\n", "                        ", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", "util", ".", "save", "(", "model_to_save", ",", "optimizer", ",", "scheduler", ",", "global_step", ",", "best_dev_em", ",", "opt", ",", "dir_path", ",", "\n", "'best_dev'", ")", "\n", "", "", "model", ".", "train", "(", ")", "\n", "", "if", "opt", ".", "is_master", "and", "global_step", "%", "opt", ".", "eval_freq", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "f\"{global_step} / {opt.total_step} -- train = {curr_loss / opt.eval_freq:.3f} | evaluation = {100 * dev_em:.2f}EM | lr = {scheduler.get_last_lr()[0]:.5f}\"", "\n", ")", "\n", "tb_logger", ".", "add_scalar", "(", "\"Training\"", ",", "curr_loss", "/", "(", "opt", ".", "eval_freq", ")", ",", "global_step", ")", "\n", "curr_loss", "=", "0", "\n", "\n", "", "if", "opt", ".", "is_master", "and", "global_step", "%", "(", "50", "*", "opt", ".", "eval_freq", ")", "==", "0", ":", "\n", "                ", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", "util", ".", "save", "(", "model_to_save", ",", "optimizer", ",", "scheduler", ",", "global_step", ",", "best_dev_em", ",", "opt", ",", "dir_path", ",", "\n", "f\"step-{global_step}\"", ")", "\n", "", "if", "global_step", ">", "opt", ".", "total_step", ":", "\n", "                ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.train.evaluate": [[102, 135], ["model.eval", "hasattr", "util.weighted_average", "torch.no_grad", "torch.no_grad", "enumerate", "numpy.mean", "hasattr", "context_ids.cuda().view.cuda().view", "context_mask.cuda().view.cuda().view", "model.generate", "enumerate", "context_ids.cuda().view.size", "context_ids.cuda().view.size", "context_ids.cuda().view.size", "context_mask.cuda().view.size", "tokenizer.decode", "evaluation.ems", "ems.append", "logger.info", "context_ids.cuda().view.cuda", "context_mask.cuda().view.cuda", "dataset.get_example", "len", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.weighted_average", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.ACFiDT5.generate", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.ems", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.data.Dataset.get_example"], ["", "", "", "", "def", "evaluate", "(", "model", ",", "dataset", ",", "dataloader", ",", "tokenizer", ",", "opt", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "if", "hasattr", "(", "model", ",", "\"module\"", ")", ":", "\n", "        ", "model", "=", "model", ".", "module", "\n", "", "total", "=", "0", "\n", "ems", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "            ", "idx", ",", "answer_ids", ",", "answer_mask", ",", "context_ids", ",", "context_mask", "=", "batch", "\n", "if", "hasattr", "(", "model", ",", "\"module\"", ")", ":", "\n", "                ", "model", ".", "module", ".", "encoder", ".", "n_passages", "=", "context_ids", ".", "size", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "model", ".", "encoder", ".", "n_passages", "=", "context_ids", ".", "size", "(", "1", ")", "\n", "", "context_ids", "=", "context_ids", ".", "cuda", "(", ")", ".", "view", "(", "context_ids", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "context_mask", "=", "context_mask", ".", "cuda", "(", ")", ".", "view", "(", "context_mask", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "outputs", "=", "model", ".", "generate", "(", "\n", "input_ids", "=", "context_ids", ",", "\n", "attention_mask", "=", "context_mask", ",", "\n", "max_length", "=", "50", ",", "\n", ")", "\n", "\n", "for", "k", ",", "o", "in", "enumerate", "(", "outputs", ")", ":", "\n", "                ", "ans", "=", "tokenizer", ".", "decode", "(", "o", ",", "skip_special_tokens", "=", "True", ")", "\n", "gold", "=", "dataset", ".", "get_example", "(", "idx", "[", "k", "]", ")", ".", "answers", "\n", "ems_score", "=", "evaluation", ".", "ems", "(", "ans", ",", "gold", ")", "\n", "total", "+=", "1", "\n", "ems", ".", "append", "(", "ems_score", ")", "\n", "", "if", "opt", ".", "is_master", "and", "(", "i", "+", "1", ")", "%", "opt", ".", "eval_print_freq", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "f\"{i + 1} / {len(dataloader)} -- average = {100 * np.mean(ems):.2f}EM\"", ")", "\n", "\n", "", "", "", "score", ",", "total", "=", "util", ".", "weighted_average", "(", "np", ".", "mean", "(", "ems", ")", ",", "total", ",", "opt", ")", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.data.QAExample.__init__": [[7, 14], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "id", ",", "question", ",", "answers", ",", "target", "=", "None", ",", "titles", "=", "None", ",", "contexts", "=", "None", ")", ":", "\n", "        ", "self", ".", "id", "=", "id", "\n", "self", ".", "question", "=", "question", "\n", "self", ".", "answers", "=", "answers", "\n", "self", ".", "target", "=", "target", "\n", "self", ".", "titles", "=", "titles", "\n", "self", ".", "contexts", "=", "contexts", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.data.Dataset.__init__": [[17, 26], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "n_context", ",", "tokenizer", ",", "max_passage_length", "=", "250", ",", "no_title", "=", "False", ")", ":", "\n", "        ", "self", ".", "data", "=", "data", "\n", "self", ".", "n_context", "=", "n_context", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "max_passage_length", "=", "max_passage_length", "\n", "self", ".", "no_title", "=", "no_title", "\n", "self", ".", "question_prefix", "=", "'question:'", "\n", "self", ".", "title_prefix", "=", "'title:'", "\n", "self", ".", "context_prefix", "=", "'context:'", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.data.Dataset.__len__": [[27, 29], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.data.Dataset.__getitem__": [[30, 58], ["range", "random.choice", "len", "passages.append", "min", "passages.append", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "example", "=", "self", ".", "data", "[", "index", "]", "\n", "question", "=", "example", ".", "question", "\n", "if", "example", ".", "target", "is", "None", ":", "\n", "            ", "target", "=", "random", ".", "choice", "(", "example", ".", "answers", ")", "\n", "", "else", ":", "\n", "            ", "target", "=", "example", ".", "target", "\n", "\n", "", "titles", "=", "example", ".", "titles", "[", ":", "self", ".", "n_context", "]", "\n", "contexts", "=", "example", ".", "contexts", "[", ":", "self", ".", "n_context", "]", "\n", "\n", "passages", "=", "[", "]", "\n", "if", "len", "(", "contexts", ")", "==", "0", ":", "\n", "            ", "to_concatenate", "=", "[", "self", ".", "question_prefix", ",", "question", "]", "\n", "text", "=", "' '", ".", "join", "(", "to_concatenate", ")", "\n", "passages", ".", "append", "(", "text", ")", "\n", "", "for", "i", "in", "range", "(", "min", "(", "self", ".", "n_context", ",", "len", "(", "contexts", ")", ")", ")", ":", "\n", "            ", "c", "=", "contexts", "[", "i", "]", "\n", "t", "=", "titles", "[", "i", "]", "\n", "to_concatenate", "=", "[", "self", ".", "question_prefix", ",", "question", "]", "\n", "if", "c", "is", "not", "None", ":", "\n", "                ", "if", "not", "self", ".", "no_title", ":", "\n", "                    ", "to_concatenate", "+=", "[", "self", ".", "title_prefix", ",", "t", "]", "\n", "", "to_concatenate", "+=", "[", "self", ".", "context_prefix", ",", "c", "]", "\n", "", "text", "=", "' '", ".", "join", "(", "to_concatenate", ")", "\n", "passages", ".", "append", "(", "text", ")", "\n", "\n", "", "return", "{", "'index'", ":", "index", ",", "'question'", ":", "question", ",", "'target'", ":", "target", ",", "'passages'", ":", "passages", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.data.Dataset.get_example": [[59, 61], ["None"], "methods", ["None"], ["", "def", "get_example", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "data", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.data.Collator.__init__": [[64, 68], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "tokenizer", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "max_passage_length", "=", "opt", ".", "max_passage_length", "\n", "self", ".", "model_type", "=", "opt", ".", "model_type", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.data.Collator.__call__": [[69, 113], ["torch.tensor", "data.Collator.tokenizer.batch_encode_plus", "enumerate", "min", "enumerate", "torch.stack", "torch.stack", "batch_encoded_passages.append", "torch.stack", "torch.stack", "torch.stack.append", "torch.stack.append", "data.Collator.tokenizer.encode", "max", "encoded_passages.append", "len", "torch.cat", "torch.stack.append", "torch.cat", "torch.stack.append", "len", "len", "torch.tensor", "torch.zeros().long", "torch.ones().bool", "torch.zeros().bool", "torch.zeros", "torch.ones", "torch.zeros"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "batch", ")", ":", "\n", "        ", "index", "=", "torch", ".", "tensor", "(", "[", "ex", "[", "'index'", "]", "for", "ex", "in", "batch", "]", ")", "\n", "question", "=", "[", "ex", "[", "'question'", "]", "for", "ex", "in", "batch", "]", "\n", "if", "self", ".", "model_type", "==", "'bart'", ":", "\n", "            ", "target", "=", "[", "ex", "[", "'target'", "]", "for", "ex", "in", "batch", "]", "\n", "", "else", ":", "\n", "            ", "target", "=", "[", "ex", "[", "'target'", "]", "+", "' </s>'", "for", "ex", "in", "batch", "]", "\n", "", "target", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "target", ",", "pad_to_max_length", "=", "True", ",", "return_tensors", "=", "\"pt\"", ")", "\n", "target_ids", ",", "target_mask", "=", "target", "[", "\"input_ids\"", "]", ",", "target", "[", "\"attention_mask\"", "]", "\n", "\n", "batch_text_passages", "=", "[", "ex", "[", "'passages'", "]", "for", "ex", "in", "batch", "]", "\n", "batch_encoded_passages", "=", "[", "]", "\n", "\n", "max_context_length", "=", "0", "\n", "for", "k", ",", "text_passages", "in", "enumerate", "(", "batch_text_passages", ")", ":", "\n", "            ", "encoded_passages", "=", "[", "]", "\n", "for", "text_p", "in", "text_passages", ":", "\n", "                ", "encoded_p", "=", "self", ".", "tokenizer", ".", "encode", "(", "text_p", ")", "\n", "if", "len", "(", "encoded_p", ")", ">", "self", ".", "max_passage_length", ":", "\n", "                    ", "encoded_p", "=", "encoded_p", "[", ":", "self", ".", "max_passage_length", "]", "\n", "", "max_context_length", "=", "max", "(", "max_context_length", ",", "len", "(", "encoded_p", ")", ")", "\n", "encoded_passages", ".", "append", "(", "encoded_p", ")", "\n", "", "batch_encoded_passages", ".", "append", "(", "encoded_passages", ")", "\n", "", "max_context_length", "=", "min", "(", "max_context_length", ",", "self", ".", "max_passage_length", ")", "\n", "\n", "batch_passage_ids", ",", "batch_passage_masks", "=", "[", "]", ",", "[", "]", "\n", "for", "k", ",", "encoded_passages", "in", "enumerate", "(", "batch_encoded_passages", ")", ":", "\n", "            ", "p_ids", ",", "p_masks", "=", "[", "]", ",", "[", "]", "\n", "for", "p", "in", "encoded_passages", ":", "\n", "                ", "plen", "=", "len", "(", "p", ")", "\n", "c", "=", "torch", ".", "cat", "(", "(", "torch", ".", "tensor", "(", "p", ")", ",", "torch", ".", "zeros", "(", "max_context_length", "-", "plen", ")", ".", "long", "(", ")", ")", ",", "dim", "=", "0", ")", "# shape: [L]", "\n", "p_ids", ".", "append", "(", "c", ")", "\n", "m", "=", "torch", ".", "cat", "(", "(", "torch", ".", "ones", "(", "plen", ")", ".", "bool", "(", ")", ",", "torch", ".", "zeros", "(", "max_context_length", "-", "plen", ")", ".", "bool", "(", ")", ")", ",", "\n", "dim", "=", "0", ")", "# shape: [L]", "\n", "p_masks", ".", "append", "(", "m", ")", "\n", "", "p_ids", "=", "torch", ".", "stack", "(", "p_ids", ",", "dim", "=", "0", ")", "# shape: [N, L], N is the number of passages", "\n", "p_masks", "=", "torch", ".", "stack", "(", "p_masks", ",", "dim", "=", "0", ")", "# shape: [N, L]", "\n", "batch_passage_ids", ".", "append", "(", "p_ids", ")", "\n", "batch_passage_masks", ".", "append", "(", "p_masks", ")", "\n", "\n", "", "batch_passage_ids", "=", "torch", ".", "stack", "(", "batch_passage_ids", ",", "dim", "=", "0", ")", "# shape: [B, N, L], B is the batch size", "\n", "batch_passage_masks", "=", "torch", ".", "stack", "(", "batch_passage_masks", ",", "dim", "=", "0", ")", "# shape: [B, N, L]", "\n", "\n", "return", "index", ",", "target_ids", ",", "target_mask", ",", "batch_passage_ids", ",", "batch_passage_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.data.load_data": [[115, 146], ["enumerate", "open", "json.load", "data.QAExample", "examples.append", "enumerate", "titles.append", "contexts.append"], "function", ["None"], ["", "", "def", "load_data", "(", "data_path", ",", "global_rank", "=", "-", "1", ",", "world_size", "=", "-", "1", ",", "n_context", "=", "None", ")", ":", "\n", "    ", "with", "open", "(", "data_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "examples", "=", "[", "]", "\n", "for", "k", ",", "example", "in", "enumerate", "(", "data", ")", ":", "\n", "        ", "if", "global_rank", ">", "-", "1", "and", "not", "k", "%", "world_size", "==", "global_rank", ":", "\n", "            ", "continue", "\n", "", "if", "'id'", "in", "example", ":", "\n", "            ", "id", "=", "example", "[", "'id'", "]", "\n", "", "else", ":", "\n", "            ", "id", "=", "k", "\n", "", "if", "'target'", "in", "example", ":", "\n", "            ", "target", "=", "example", "[", "'target'", "]", "\n", "", "else", ":", "\n", "            ", "target", "=", "None", "\n", "", "answers", "=", "example", "[", "'answers'", "]", "\n", "question", "=", "example", "[", "'question'", "]", "\n", "titles", ",", "contexts", "=", "[", "]", ",", "[", "]", "\n", "if", "'ctxs'", "in", "example", ":", "\n", "            ", "ctxs", "=", "example", "[", "'ctxs'", "]", "\n", "if", "n_context", "is", "not", "None", ":", "\n", "                ", "ctxs", "=", "ctxs", "[", ":", "n_context", "]", "\n", "", "for", "i", ",", "c", "in", "enumerate", "(", "ctxs", ")", ":", "\n", "                ", "titles", ".", "append", "(", "c", "[", "'title'", "]", ")", "\n", "contexts", ".", "append", "(", "c", "[", "'text'", "]", ")", "\n", "", "", "ex", "=", "QAExample", "(", "id", "=", "id", ",", "question", "=", "question", ",", "answers", "=", "answers", ",", "target", "=", "target", ",", "titles", "=", "titles", ",", "contexts", "=", "contexts", ")", "\n", "examples", ".", "append", "(", "ex", ")", "\n", "\n", "", "del", "data", "\n", "return", "examples", "\n", "", ""]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.test.evaluate": [[19, 68], ["model.eval", "hasattr", "logger.warning", "util.weighted_average", "logger.info", "os.path.join", "open", "torch.no_grad", "torch.no_grad", "enumerate", "torch.distributed.barrier", "torch.distributed.barrier", "numpy.mean", "os.path.join", "context_ids.cuda().view.size", "context_ids.cuda().view.cuda().view", "context_mask.cuda().view.cuda().view", "model.generate", "enumerate", "context_ids.cuda().view.size", "context_ids.cuda().view.size", "tokenizer.decode", "dataset.get_example", "evaluation.ems", "ems.append", "logger.warning", "numpy.mean", "context_ids.cuda().view.cuda", "context_mask.cuda().view.cuda", "open.write", "len", "numpy.mean", "str"], "function", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.weighted_average", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.ACFiDT5.generate", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.data.Dataset.get_example", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.ems"], ["def", "evaluate", "(", "model", ",", "dataset", ",", "dataloader", ",", "tokenizer", ",", "opt", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "if", "hasattr", "(", "model", ",", "\"module\"", ")", ":", "\n", "        ", "model", "=", "model", ".", "module", "\n", "", "total", "=", "0", "\n", "ems", "=", "[", "]", "\n", "\n", "fw", "=", "None", "\n", "if", "opt", ".", "write_results", ":", "\n", "        ", "write_path", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_dir", ",", "opt", ".", "name", ",", "'test_results'", ")", "\n", "fw", "=", "open", "(", "os", ".", "path", ".", "join", "(", "write_path", ",", "'%d.txt'", "%", "opt", ".", "global_rank", ")", ",", "'w'", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "            ", "idx", ",", "answer_ids", ",", "answer_mask", ",", "context_ids", ",", "context_mask", "=", "batch", "\n", "# answer_ids, answer_mask = answer_ids.cuda(), answer_mask.bool().cuda()", "\n", "model", ".", "encoder", ".", "n_passages", "=", "context_ids", ".", "size", "(", "1", ")", "\n", "context_ids", "=", "context_ids", ".", "cuda", "(", ")", ".", "view", "(", "context_ids", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "context_mask", "=", "context_mask", ".", "cuda", "(", ")", ".", "view", "(", "context_ids", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "outputs", "=", "model", ".", "generate", "(", "\n", "input_ids", "=", "context_ids", ",", "\n", "attention_mask", "=", "context_mask", ",", "\n", "max_length", "=", "50", ",", "\n", ")", "\n", "\n", "for", "k", ",", "o", "in", "enumerate", "(", "outputs", ")", ":", "\n", "                ", "ans", "=", "tokenizer", ".", "decode", "(", "o", ",", "skip_special_tokens", "=", "True", ")", "\n", "example", "=", "dataset", ".", "get_example", "(", "idx", "[", "k", "]", ")", "\n", "question", "=", "example", ".", "question", "\n", "gold", "=", "example", ".", "answers", "\n", "id", "=", "example", ".", "id", "\n", "ems_score", "=", "evaluation", ".", "ems", "(", "ans", ",", "gold", ")", "\n", "ems", ".", "append", "(", "ems_score", ")", "\n", "\n", "if", "fw", "is", "not", "None", ":", "\n", "                    ", "fw", ".", "write", "(", "str", "(", "id", ")", "+", "\"\\t\"", "+", "ans", "+", "'\\n'", ")", "\n", "\n", "", "total", "+=", "1", "\n", "\n", "", "if", "(", "i", "+", "1", ")", "%", "opt", ".", "eval_print_freq", "==", "0", ":", "\n", "                ", "logger", ".", "warning", "(", "f\"{opt.global_rank}, {i + 1} / {len(dataloader)} -- average = {np.mean(ems):.3f}\"", ")", "\n", "\n", "", "", "", "logger", ".", "warning", "(", "f\"{opt.global_rank}, total {total} -- average = {np.mean(ems):.3f}\"", ")", "\n", "if", "opt", ".", "world_size", ">", "1", "and", "not", "opt", ".", "local_rank", "==", "-", "1", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "", "score", ",", "total", "=", "util", ".", "weighted_average", "(", "np", ".", "mean", "(", "ems", ")", ",", "total", ",", "opt", ")", "\n", "logger", ".", "info", "(", "'total number of example %d'", "%", "total", ")", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.T5Block.__init__": [[40, 49], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "fidt5_ac.T5Block.layer.append", "fidt5_ac.T5Block.layer.append", "transformers.modeling_t5.T5LayerSelfAttention", "fidt5_ac.T5Block.layer.append", "transformers.modeling_t5.T5LayerFF", "transformers.modeling_t5.T5LayerCrossAttention"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "has_relative_attention_bias", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "layer", ".", "append", "(", "T5LayerSelfAttention", "(", "config", ",", "has_relative_attention_bias", "=", "has_relative_attention_bias", ")", ")", "\n", "if", "self", ".", "is_decoder", ":", "\n", "            ", "self", ".", "layer", ".", "append", "(", "T5LayerCrossAttention", "(", "config", ",", "has_relative_attention_bias", "=", "has_relative_attention_bias", ")", ")", "\n", "\n", "", "self", ".", "layer", ".", "append", "(", "T5LayerFF", "(", "config", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.T5Block.forward": [[50, 126], ["len", "len"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "position_bias", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "encoder_decoder_position_bias", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "past_key_value_state", "=", "None", ",", "\n", "use_cache", "=", "False", ",", "\n", "output_attentions", "=", "False", ",", "\n", ")", ":", "\n", "\n", "        ", "if", "past_key_value_state", "is", "not", "None", ":", "\n", "            ", "assert", "self", ".", "is_decoder", ",", "\"Only decoder can use `past_key_value_states`\"", "\n", "expected_num_past_key_value_states", "=", "2", "if", "encoder_hidden_states", "is", "None", "else", "4", "\n", "\n", "error_message", "=", "\"There should be {} past states. 2 (past / key) for self attention.{} Got {} past key / value states\"", ".", "format", "(", "\n", "expected_num_past_key_value_states", ",", "\n", "\"2 (past / key) for cross attention\"", "if", "expected_num_past_key_value_states", "==", "4", "else", "\"\"", ",", "\n", "len", "(", "past_key_value_state", ")", ",", "\n", ")", "\n", "assert", "len", "(", "past_key_value_state", ")", "==", "expected_num_past_key_value_states", ",", "error_message", "\n", "\n", "self_attn_past_key_value_state", "=", "past_key_value_state", "[", ":", "2", "]", "\n", "cross_attn_past_key_value_state", "=", "past_key_value_state", "[", "2", ":", "]", "\n", "", "else", ":", "\n", "            ", "self_attn_past_key_value_state", ",", "cross_attn_past_key_value_state", "=", "None", ",", "None", "\n", "\n", "", "self_attention_outputs", "=", "self", ".", "layer", "[", "0", "]", "(", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "position_bias", "=", "position_bias", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "past_key_value_state", "=", "self_attn_past_key_value_state", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "hidden_states", ",", "present_key_value_state", "=", "self_attention_outputs", "[", ":", "2", "]", "\n", "attention_outputs", "=", "self_attention_outputs", "[", "2", ":", "]", "# Keep self-attention outputs and relative position weights", "\n", "\n", "if", "self", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "# the actual query length is unknown for cross attention", "\n", "# if using past key value states. Need to inject it here", "\n", "            ", "if", "present_key_value_state", "is", "not", "None", ":", "\n", "                ", "query_length", "=", "present_key_value_state", "[", "0", "]", ".", "shape", "[", "2", "]", "\n", "", "else", ":", "\n", "                ", "query_length", "=", "None", "\n", "\n", "", "cross_attention_outputs", "=", "self", ".", "layer", "[", "1", "]", "(", "\n", "hidden_states", ",", "\n", "kv", "=", "encoder_hidden_states", ",", "\n", "attention_mask", "=", "encoder_attention_mask", ",", "\n", "position_bias", "=", "encoder_decoder_position_bias", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "past_key_value_state", "=", "cross_attn_past_key_value_state", ",", "\n", "query_length", "=", "query_length", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "hidden_states", "=", "cross_attention_outputs", "[", "0", "]", "\n", "# Combine self attn and cross attn key value states", "\n", "if", "present_key_value_state", "is", "not", "None", ":", "\n", "                ", "present_key_value_state", "=", "present_key_value_state", "+", "cross_attention_outputs", "[", "1", "]", "\n", "\n", "# Keep cross-attention outputs and relative position weights", "\n", "", "attention_outputs", "=", "attention_outputs", "+", "cross_attention_outputs", "[", "2", ":", "]", "\n", "\n", "# Apply Feed Forward layer", "\n", "", "hidden_states", "=", "self", ".", "layer", "[", "-", "1", "]", "(", "hidden_states", ")", "\n", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "\n", "# Add attentions if we output them", "\n", "outputs", "=", "outputs", "+", "(", "present_key_value_state", ",", ")", "+", "attention_outputs", "\n", "return", "outputs", "# hidden-states, present_key_value_states, (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.T5PreTrainedModel.dummy_inputs": [[137, 147], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["@", "property", "\n", "def", "dummy_inputs", "(", "self", ")", ":", "\n", "        ", "input_ids", "=", "torch", ".", "tensor", "(", "DUMMY_INPUTS", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "DUMMY_MASK", ")", "\n", "dummy_inputs", "=", "{", "\n", "\"decoder_input_ids\"", ":", "input_ids", ",", "\n", "\"input_ids\"", ":", "input_ids", ",", "\n", "\"decoder_attention_mask\"", ":", "input_mask", ",", "\n", "}", "\n", "return", "dummy_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.T5PreTrainedModel._init_weights": [[148, 179], ["isinstance", "module.weight.data.fill_", "isinstance", "module.shared.weight.data.normal_", "isinstance", "module.wi.weight.data.normal_", "module.wo.weight.data.normal_", "isinstance", "hasattr", "module.wi.bias.data.zero_", "hasattr", "module.wo.bias.data.zero_", "module.q.weight.data.normal_", "module.k.weight.data.normal_", "module.v.weight.data.normal_", "module.o.weight.data.normal_", "module.relative_attention_bias.weight.data.normal_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights \"\"\"", "\n", "factor", "=", "self", ".", "config", ".", "initializer_factor", "# Used for testing weights initialization", "\n", "if", "isinstance", "(", "module", ",", "T5LayerNorm", ")", ":", "\n", "            ", "module", ".", "weight", ".", "data", ".", "fill_", "(", "factor", "*", "1.0", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "(", "T5Model", ",", "T5ForConditionalGeneration", ",", "ACFiDT5", ")", ")", ":", "# Change (ACFiD): added ACFiDT5", "\n", "# Mesh TensorFlow embeddings initialization", "\n", "# See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L1624", "\n", "            ", "module", ".", "shared", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "1.0", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "T5DenseReluDense", ")", ":", "\n", "# Mesh TensorFlow FF initialization", "\n", "# See https://github.com/tensorflow/mesh/blob/master/mesh_tensorflow/transformer/transformer_layers.py#L56", "\n", "# and https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L89", "\n", "            ", "module", ".", "wi", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "self", ".", "config", ".", "d_model", ")", "**", "-", "0.5", ")", ")", "\n", "if", "hasattr", "(", "module", ".", "wi", ",", "\"bias\"", ")", "and", "module", ".", "wi", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "wi", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "module", ".", "wo", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "self", ".", "config", ".", "d_ff", ")", "**", "-", "0.5", ")", ")", "\n", "if", "hasattr", "(", "module", ".", "wo", ",", "\"bias\"", ")", "and", "module", ".", "wo", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "wo", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "T5Attention", ")", ":", "\n", "# Mesh TensorFlow attention initialization to avoid scaling before softmax", "\n", "# See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/attention.py#L136", "\n", "            ", "d_model", "=", "self", ".", "config", ".", "d_model", "\n", "d_kv", "=", "self", ".", "config", ".", "d_kv", "\n", "n_heads", "=", "self", ".", "config", ".", "num_heads", "\n", "module", ".", "q", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "d_model", "*", "d_kv", ")", "**", "-", "0.5", ")", ")", "\n", "module", ".", "k", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "d_model", "**", "-", "0.5", ")", ")", "\n", "module", ".", "v", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "d_model", "**", "-", "0.5", ")", ")", "\n", "module", ".", "o", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "n_heads", "*", "d_kv", ")", "**", "-", "0.5", ")", ")", "\n", "if", "module", ".", "has_relative_attention_bias", ":", "\n", "                ", "module", ".", "relative_attention_bias", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "d_model", ")", "**", "-", "0.5", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.T5PreTrainedModel._shift_right": [[180, 200], ["input_ids.new_zeros", "input_ids[].clone", "input_ids.new_zeros.masked_fill_", "torch.all().item", "torch.all().item", "torch.all().item", "torch.all().item", "torch.all().item", "torch.all().item", "torch.all().item", "torch.all().item", "torch.all().item", "torch.all", "torch.all", "torch.all", "torch.all", "torch.all", "torch.all", "torch.all", "torch.all", "torch.all"], "methods", ["None"], ["", "", "", "def", "_shift_right", "(", "self", ",", "input_ids", ")", ":", "\n", "        ", "decoder_start_token_id", "=", "self", ".", "config", ".", "decoder_start_token_id", "\n", "pad_token_id", "=", "self", ".", "config", ".", "pad_token_id", "\n", "\n", "assert", "(", "\n", "decoder_start_token_id", "is", "not", "None", "\n", ")", ",", "\"self.model.config.decoder_start_token_id has to be defined. In T5 it is usually set to the pad_token_id. See T5 docs for more information\"", "\n", "\n", "# shift inputs to the right", "\n", "shifted_input_ids", "=", "input_ids", ".", "new_zeros", "(", "input_ids", ".", "shape", ")", "\n", "shifted_input_ids", "[", "...", ",", "1", ":", "]", "=", "input_ids", "[", "...", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "shifted_input_ids", "[", "...", ",", "0", "]", "=", "decoder_start_token_id", "\n", "\n", "assert", "pad_token_id", "is", "not", "None", ",", "\"self.model.config.pad_token_id has to be defined.\"", "\n", "# replace possible -100 values in labels by `pad_token_id`", "\n", "shifted_input_ids", ".", "masked_fill_", "(", "shifted_input_ids", "==", "-", "100", ",", "pad_token_id", ")", "\n", "\n", "assert", "torch", ".", "all", "(", "shifted_input_ids", ">=", "0", ")", ".", "item", "(", ")", ",", "\"Verify that `labels` has only positive values and -100\"", "\n", "\n", "return", "shifted_input_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.HasAnswerHead.__init__": [[204, 210], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "getattr"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dense1", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "d_model", ",", "bias", "=", "False", ")", "\n", "self", ".", "dense2", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "type", "=", "getattr", "(", "config", ",", "\"has_answer_pool_type\"", ",", "\"first\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.HasAnswerHead.forward": [[211, 233], ["hidden_states.detach.detach.detach", "fidt5_ac.HasAnswerHead.dense1", "torch.relu", "torch.relu", "torch.relu", "fidt5_ac.HasAnswerHead.dense2", "fidt5_ac.HasAnswerHead.dense1", "torch.relu", "torch.relu", "torch.relu", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "fidt5_ac.HasAnswerHead.dense2", "fidt5_ac.HasAnswerHead.dense1", "torch.relu", "torch.relu", "torch.relu", "fidt5_ac.HasAnswerHead.dense2", "ValueError", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "hidden_states", ".", "detach", "(", ")", "# stop gradient BP to the hidden states", "\n", "\n", "if", "self", ".", "type", "==", "\"first\"", ":", "\n", "            ", "h", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "h", "=", "self", ".", "dense1", "(", "h", ")", "\n", "h", "=", "F", ".", "relu", "(", "h", ")", "\n", "h", "=", "self", ".", "dense2", "(", "h", ")", "\n", "", "elif", "self", ".", "type", "==", "\"mean\"", ":", "\n", "            ", "k", "=", "self", ".", "dense1", "(", "hidden_states", ")", "# shape: [batch_size, seq_len, d_model]", "\n", "k", "=", "F", ".", "relu", "(", "k", ")", "\n", "h", "=", "torch", ".", "mean", "(", "k", ",", "dim", "=", "1", ")", "# max-pooling over seq_len dimension", "\n", "h", "=", "self", ".", "dense2", "(", "h", ")", "\n", "", "elif", "self", ".", "type", "==", "\"max\"", ":", "\n", "            ", "k", "=", "self", ".", "dense1", "(", "hidden_states", ")", "# shape: [batch_size, seq_len, d_model]", "\n", "k", "=", "F", ".", "relu", "(", "k", ")", "\n", "h", "=", "torch", ".", "max", "(", "k", ",", "dim", "=", "1", ")", "[", "0", "]", "# max-pooling over seq_len dimension", "\n", "h", "=", "self", ".", "dense2", "(", "h", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Invalid has_answer_pool_type: {self.type}\"", ")", "\n", "\n", "", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.T5Stack.__init__": [[236, 256], ["transformers.modeling_utils.PreTrainedModel.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "transformers.modeling_t5.T5LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "fidt5_ac.T5Stack.init_weights", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "fidt5_ac.T5Block", "range", "fidt5_ac.HasAnswerHead", "bool", "range"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "embed_tokens", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "\n", "self", ".", "block", "=", "nn", ".", "ModuleList", "(", "\n", "[", "T5Block", "(", "config", ",", "has_relative_attention_bias", "=", "bool", "(", "i", "==", "0", ")", ")", "for", "i", "in", "range", "(", "config", ".", "num_layers", ")", "]", "\n", ")", "\n", "self", ".", "final_layer_norm", "=", "T5LayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "self", ".", "checkpoint", "=", "False", "# Change (FiD): flag for gradient checkpointing (during training)", "\n", "\n", "self", ".", "has_answer_heads", "=", "None", "if", "self", ".", "is_decoder", "else", "nn", ".", "ModuleList", "(", "\n", "[", "HasAnswerHead", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "num_layers", ")", "]", ")", "# Change (ACFiD): encoder only", "\n", "\n", "self", ".", "budget", "=", "None", "# Change (ACFiD): budget number of passage layer", "\n", "self", ".", "num_passages_retained", "=", "None", "# Change (ACFiD): number of passages retained after AC", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.T5Stack.get_input_embeddings": [[257, 259], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embed_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.T5Stack.get_output_embeddings": [[260, 262], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embed_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.T5Stack.set_input_embeddings": [[263, 265], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "embed_tokens", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.T5Stack.forward": [[266, 450], ["fidt5_ac.T5Stack.get_extended_attention_mask", "fidt5_ac.T5Stack.get_head_mask", "fidt5_ac.T5Stack.dropout", "enumerate", "fidt5_ac.T5Stack.final_layer_norm", "fidt5_ac.T5Stack.dropout", "input_ids.view.view.view", "attention_mask.view.view.view", "ValueError", "fidt5_ac.T5Stack.embed_tokens", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "fidt5_ac.T5Stack.invert_attention_mask", "zip", "hasattr", "input_ids.view.view.size", "input_ids.view.view.view", "len", "hidden_states.view.view.contiguous", "extended_attention_mask.contiguous.contiguous.contiguous", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "layer_module", "has_answer_head().view", "hidden_states.view.view.view", "attention_mask.view.view.view", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "ac_scheduler.run_ac_scheduler", "hidden_states.view.view.view", "attention_mask.view.view.view", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "has_answer_outputs.detach.detach.detach", "fidt5_ac.T5Stack.size", "ValueError", "ValueError", "has_answer_head"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.run_ac_scheduler"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "past_key_value_states", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "ac_scheduler", "=", "None", ",", "\n", "freeze_has_answer_heads", "=", "False", ",", "\n", ")", ":", "\n", "        ", "if", "not", "self", ".", "is_decoder", ":", "# Change (FiD): encoder needs to reshape the inputs", "\n", "            ", "assert", "hasattr", "(", "self", ",", "\"n_passages\"", ")", "and", "self", ".", "n_passages", "is", "not", "None", ",", "\"n_passages is not set\"", "\n", "bsz", ",", "tc", "=", "input_ids", ".", "shape", "\n", "plen", "=", "tc", "//", "self", ".", "n_passages", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "bsz", "*", "self", ".", "n_passages", ",", "plen", ")", "\n", "attention_mask", "=", "attention_mask", ".", "view", "(", "bsz", "*", "self", ".", "n_passages", ",", "plen", ")", "\n", "\n", "", "use_cache", "=", "use_cache", "if", "use_cache", "is", "not", "None", "else", "self", ".", "config", ".", "use_cache", "\n", "output_attentions", "=", "output_attentions", "if", "output_attentions", "is", "not", "None", "else", "self", ".", "config", ".", "output_attentions", "\n", "output_hidden_states", "=", "(", "\n", "output_hidden_states", "if", "output_hidden_states", "is", "not", "None", "else", "self", ".", "config", ".", "output_hidden_states", "\n", ")", "\n", "\n", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "is_decoder", ":", "\n", "                ", "raise", "ValueError", "(", "\"You have to specify either decoder_input_ids or decoder_inputs_embeds\"", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "assert", "self", ".", "embed_tokens", "is", "not", "None", ",", "\"You have to initialize the model with valid token embeddings\"", "\n", "inputs_embeds", "=", "self", ".", "embed_tokens", "(", "input_ids", ")", "\n", "\n", "", "batch_size", ",", "seq_length", "=", "input_shape", "\n", "\n", "if", "past_key_value_states", "is", "not", "None", ":", "\n", "            ", "assert", "seq_length", "==", "1", ",", "\"Input shape is {}, but should be {} when using past_key_value_sates\"", ".", "format", "(", "\n", "input_shape", ",", "(", "batch_size", ",", "1", ")", "\n", ")", "\n", "# required mask seq length can be calculated via length of past", "\n", "# key value states and seq_length = 1 for the last token", "\n", "mask_seq_length", "=", "past_key_value_states", "[", "0", "]", "[", "0", "]", ".", "shape", "[", "2", "]", "+", "seq_length", "\n", "", "else", ":", "\n", "            ", "mask_seq_length", "=", "seq_length", "\n", "\n", "", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones", "(", "batch_size", ",", "mask_seq_length", ")", ".", "to", "(", "inputs_embeds", ".", "device", ")", "\n", "", "if", "self", ".", "is_decoder", "and", "encoder_attention_mask", "is", "None", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "encoder_seq_length", "=", "encoder_hidden_states", ".", "shape", "[", "1", "]", "\n", "encoder_attention_mask", "=", "torch", ".", "ones", "(", "\n", "batch_size", ",", "encoder_seq_length", ",", "device", "=", "inputs_embeds", ".", "device", ",", "dtype", "=", "torch", ".", "long", "\n", ")", "\n", "\n", "# initialize past_key_value_states with `None` if past does not exist", "\n", "", "if", "past_key_value_states", "is", "None", ":", "\n", "            ", "past_key_value_states", "=", "[", "None", "]", "*", "len", "(", "self", ".", "block", ")", "\n", "\n", "# ourselves in which case we just need to make it broadcastable to all heads.", "\n", "", "extended_attention_mask", "=", "self", ".", "get_extended_attention_mask", "(", "attention_mask", ",", "input_shape", ",", "inputs_embeds", ".", "device", ")", "\n", "\n", "if", "self", ".", "is_decoder", "and", "encoder_attention_mask", "is", "not", "None", ":", "\n", "            ", "encoder_extended_attention_mask", "=", "self", ".", "invert_attention_mask", "(", "encoder_attention_mask", ")", "\n", "", "else", ":", "\n", "            ", "encoder_extended_attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "", "head_mask", "=", "self", ".", "get_head_mask", "(", "head_mask", ",", "self", ".", "config", ".", "num_layers", ")", "\n", "present_key_value_states", "=", "(", ")", "\n", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "(", ")", "\n", "all_has_answer_outputs", "=", "(", ")", "\n", "position_bias", "=", "None", "\n", "encoder_decoder_position_bias", "=", "None", "\n", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "inputs_embeds", ")", "\n", "\n", "for", "i", ",", "(", "layer_module", ",", "past_key_value_state", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "block", ",", "past_key_value_states", ")", ")", ":", "\n", "            ", "if", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "if", "not", "self", ".", "is_decoder", "and", "self", ".", "checkpoint", ":", "# Change (FiD): encoder with gradient checkpointing", "\n", "                ", "hidden_states", "=", "hidden_states", ".", "contiguous", "(", ")", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "contiguous", "(", ")", "\n", "layer_outputs", "=", "torch", ".", "utils", ".", "checkpoint", ".", "checkpoint", "(", "\n", "layer_module", ",", "\n", "hidden_states", ",", "\n", "extended_attention_mask", ",", "\n", "position_bias", ",", "\n", "# encoder_hidden_states, encoder_extended_attention_mask, encoder_decoder_position_bias, head_mask[i], past_key_value_state,", "\n", ")", "\n", "", "else", ":", "\n", "                ", "layer_outputs", "=", "layer_module", "(", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "position_bias", "=", "position_bias", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_extended_attention_mask", ",", "\n", "encoder_decoder_position_bias", "=", "encoder_decoder_position_bias", ",", "\n", "head_mask", "=", "head_mask", "[", "i", "]", ",", "\n", "past_key_value_state", "=", "past_key_value_state", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "# layer_outputs is a tuple with:", "\n", "# hidden-states, key-value-states, (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)", "\n", "", "hidden_states", ",", "present_key_value_state", "=", "layer_outputs", "[", ":", "2", "]", "\n", "\n", "if", "i", "==", "0", ":", "\n", "# We share the position biases between the layers - the first layer store them", "\n", "# layer_outputs = hidden-states, key-value-states (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)", "\n", "                ", "position_bias", "=", "layer_outputs", "[", "3", "if", "output_attentions", "else", "2", "]", "\n", "if", "self", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "                    ", "encoder_decoder_position_bias", "=", "layer_outputs", "[", "5", "if", "output_attentions", "else", "3", "]", "\n", "# append next layer key value states", "\n", "", "", "present_key_value_states", "=", "present_key_value_states", "+", "(", "present_key_value_state", ",", ")", "\n", "\n", "if", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "2", "]", ",", ")", "# We keep only self-attention weights for now", "\n", "\n", "", "if", "not", "self", ".", "is_decoder", "and", "self", ".", "has_answer_heads", "is", "not", "None", ":", "# Change (ACFiD): output all_has_answer_outputs", "\n", "                ", "has_answer_head", "=", "self", ".", "has_answer_heads", "[", "i", "]", "\n", "has_answer_output", "=", "has_answer_head", "(", "hidden_states", ")", ".", "view", "(", "bsz", ",", "self", ".", "n_passages", ")", "\n", "all_has_answer_outputs", "=", "all_has_answer_outputs", "+", "(", "has_answer_output", ",", ")", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "final_layer_norm", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "\n", "# Add last layer", "\n", "if", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "# Change (FiD & ACFiD): change the output of encoder", "\n", "", "if", "not", "self", ".", "is_decoder", ":", "\n", "            ", "if", "self", ".", "budget", "is", "not", "None", "and", "self", ".", "num_passages_retained", "is", "not", "None", ":", "\n", "# Change (ACFiD): run the AC priorization algorithm to choose passages", "\n", "                ", "batch_hidden_states", "=", "hidden_states", ".", "view", "(", "bsz", ",", "self", ".", "n_passages", ",", "plen", ",", "-", "1", ")", "\n", "batch_attention_masks", "=", "attention_mask", ".", "view", "(", "bsz", ",", "self", ".", "n_passages", ",", "plen", ")", "\n", "\n", "has_answer_outputs", "=", "torch", ".", "stack", "(", "all_has_answer_outputs", ",", "2", ")", "# shape: [B, N, num_layers]", "\n", "if", "freeze_has_answer_heads", ":", "\n", "                    ", "has_answer_outputs", "=", "has_answer_outputs", ".", "detach", "(", ")", "\n", "\n", "", "hidden_states", ",", "attention_mask", ",", "scheduler_outputs", "=", "run_ac_scheduler", "(", "\n", "batch_hidden_states", ",", "# [bsz (B), n_passages (N), plen (L), d_model (D)]", "\n", "batch_attention_masks", ",", "# [B, N, L]", "\n", "has_answer_outputs", ",", "\n", "ac_scheduler", "=", "ac_scheduler", ",", "\n", "budget", "=", "self", ".", "budget", ",", "\n", "num_passages_retained", "=", "self", ".", "num_passages_retained", ",", "\n", "is_training", "=", "self", ".", "training", ",", "\n", ")", "\n", "", "else", ":", "# Change (FiD): reshape output", "\n", "                ", "hidden_states", "=", "hidden_states", ".", "view", "(", "bsz", ",", "self", ".", "n_passages", "*", "plen", ",", "-", "1", ")", "\n", "attention_mask", "=", "attention_mask", ".", "view", "(", "bsz", ",", "self", ".", "n_passages", "*", "plen", ")", "\n", "scheduler_outputs", "=", "None", "\n", "\n", "", "", "if", "not", "self", ".", "is_decoder", ":", "# Change (ACFiD): output attention_mask because they are updated by AC", "\n", "            ", "outputs", "=", "(", "hidden_states", ",", "attention_mask", ",", "scheduler_outputs", ")", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "\n", "", "if", "use_cache", "is", "True", ":", "\n", "            ", "assert", "self", ".", "is_decoder", ",", "\"`use_cache` can only be set to `True` if {} is used as a decoder\"", ".", "format", "(", "self", ")", "\n", "outputs", "=", "outputs", "+", "(", "present_key_value_states", ",", ")", "\n", "", "if", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "if", "not", "self", ".", "is_decoder", "and", "self", ".", "has_answer_heads", "is", "not", "None", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_has_answer_outputs", ",", ")", "\n", "\n", "", "return", "outputs", "# last-layer hidden state, (presents,) (all hidden states), (all attentions), (all_has_answer_outputs)", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.ACFiDT5.__init__": [[455, 482], ["transformers.modeling_utils.PreTrainedModel.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "copy.deepcopy", "fidt5_ac.T5Stack", "copy.deepcopy", "fidt5_ac.T5Stack", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "ac_scheduler.get_scheduler", "fidt5_ac.ACFiDT5.init_weights"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.get_scheduler"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "model_dim", "=", "config", ".", "d_model", "\n", "\n", "self", ".", "shared", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "d_model", ")", "\n", "\n", "encoder_config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "encoder_config", ".", "use_cache", "=", "False", "\n", "self", ".", "encoder", "=", "T5Stack", "(", "encoder_config", ",", "self", ".", "shared", ")", "\n", "\n", "decoder_config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "decoder_config", ".", "is_decoder", "=", "True", "\n", "self", ".", "decoder", "=", "T5Stack", "(", "decoder_config", ",", "self", ".", "shared", ")", "\n", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "freeze_fid_params", "=", "False", "# Change (ACFiD): freeze FiD parameters when training AC has_answer_heads", "\n", "# Change (ACFiD): added AC scheduler", "\n", "self", ".", "ac_scheduler", "=", "get_scheduler", "(", "config", ")", "\n", "self", ".", "freeze_has_answer_heads", "=", "False", "# freeze the has_answer_heads parameters when training the AC scheduler", "\n", "self", ".", "use_bce_loss", "=", "False", "# train the has_answer_heads with Binary Cross-entropy loss", "\n", "self", ".", "use_rl_loss", "=", "False", "# train the scheduler with REINFORCE loss", "\n", "\n", "self", ".", "step_cost", "=", "0.", "# cost per step when training the scheduler with REINFORCE", "\n", "self", ".", "discount", "=", "1.", "# discount factor when training the scheduler with REINFORCE", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.ACFiDT5.get_input_embeddings": [[483, 485], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "shared", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.ACFiDT5.set_input_embeddings": [[486, 490], ["fidt5_ac.ACFiDT5.encoder.set_input_embeddings", "fidt5_ac.ACFiDT5.decoder.set_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.FiDT5.set_input_embeddings", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.FiDT5.set_input_embeddings"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "shared", "=", "new_embeddings", "\n", "self", ".", "encoder", ".", "set_input_embeddings", "(", "new_embeddings", ")", "\n", "self", ".", "decoder", ".", "set_input_embeddings", "(", "new_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.ACFiDT5.get_output_embeddings": [[491, 493], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.ACFiDT5.get_encoder": [[494, 496], ["None"], "methods", ["None"], ["", "def", "get_encoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.ACFiDT5.get_decoder": [[497, 499], ["None"], "methods", ["None"], ["", "def", "get_decoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.ACFiDT5.forward": [[500, 624], ["warnings.warn", "kwargs.pop", "fidt5_ac.ACFiDT5.encoder", "fidt5_ac.ACFiDT5.decoder", "fidt5_ac.ACFiDT5.lm_head", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss", "ac_scheduler.compute_REINFORCE_loss", "list", "fidt5_ac.ACFiDT5._shift_right", "fidt5_ac.ACFiDT5.view", "kwargs.pop.view", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss.", "has_answer_losses.append", "sum", "len", "kwargs.keys", "fidt5_ac.ACFiDT5.size"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.compute_REINFORCE_loss", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.T5PreTrainedModel._shift_right"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "\n", "decoder_input_ids", "=", "None", ",", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "decoder_past_key_value_states", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "has_answer_labels", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "decoder_inputs_embeds", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "\n", "        ", "if", "\"lm_labels\"", "in", "kwargs", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"The `lm_labels` argument is deprecated and will be removed in a future version, use `labels` instead.\"", ",", "\n", "DeprecationWarning", ",", "\n", ")", "\n", "labels", "=", "kwargs", ".", "pop", "(", "\"lm_labels\"", ")", "\n", "", "assert", "kwargs", "==", "{", "}", ",", "f\"Unexpected keyword arguments: {list(kwargs.keys())}.\"", "\n", "\n", "use_cache", "=", "use_cache", "if", "use_cache", "is", "not", "None", "else", "self", ".", "config", ".", "use_cache", "\n", "\n", "# Encode if needed (training, first prediction pass)", "\n", "if", "encoder_outputs", "is", "None", ":", "\n", "# Convert encoder inputs in embeddings if needed", "\n", "            ", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "ac_scheduler", "=", "self", ".", "ac_scheduler", ",", "\n", "freeze_has_answer_heads", "=", "self", ".", "freeze_has_answer_heads", ",", "\n", ")", "\n", "\n", "", "hidden_states", "=", "encoder_outputs", "[", "0", "]", "# shape: [bsz, n_passages * plen, d_model]", "\n", "attention_mask", "=", "encoder_outputs", "[", "1", "]", "# Change (ACFiD): updated for the chosen passages", "\n", "scheduler_outputs", "=", "encoder_outputs", "[", "2", "]", "# Change (ACFiD): outputs from the scheduler", "\n", "all_has_answer_outputs", "=", "encoder_outputs", "[", "3", "]", "# Tuple[Tensor], shape: [bsz, n_passages]", "\n", "\n", "if", "self", ".", "freeze_fid_params", "or", "self", ".", "freeze_has_answer_heads", ":", "\n", "# Skip the decoder when training/evaluating AC mechanism (has_answer_heads and scheduler)", "\n", "            ", "decoder_outputs", "=", "(", ")", "\n", "", "else", ":", "\n", "            ", "if", "labels", "is", "not", "None", "and", "decoder_input_ids", "is", "None", "and", "decoder_inputs_embeds", "is", "None", ":", "\n", "# get decoder inputs from shifting lm labels to the right", "\n", "                ", "decoder_input_ids", "=", "self", ".", "_shift_right", "(", "labels", ")", "\n", "\n", "# If decoding with past key value states, only the last tokens", "\n", "# should be given as an input", "\n", "", "if", "decoder_past_key_value_states", "is", "not", "None", ":", "\n", "                ", "assert", "labels", "is", "None", ",", "\"Decoder should not use cached key value states when training.\"", "\n", "if", "decoder_input_ids", "is", "not", "None", ":", "\n", "                    ", "decoder_input_ids", "=", "decoder_input_ids", "[", ":", ",", "-", "1", ":", "]", "\n", "", "if", "decoder_inputs_embeds", "is", "not", "None", ":", "\n", "                    ", "decoder_inputs_embeds", "=", "decoder_inputs_embeds", "[", ":", ",", "-", "1", ":", "]", "\n", "\n", "# Decode", "\n", "", "", "decoder_outputs", "=", "self", ".", "decoder", "(", "\n", "input_ids", "=", "decoder_input_ids", ",", "\n", "attention_mask", "=", "decoder_attention_mask", ",", "\n", "inputs_embeds", "=", "decoder_inputs_embeds", ",", "\n", "past_key_value_states", "=", "decoder_past_key_value_states", ",", "\n", "encoder_hidden_states", "=", "hidden_states", ",", "\n", "encoder_attention_mask", "=", "attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", ")", "\n", "\n", "# insert decoder past at right place", "\n", "# to speed up decoding", "\n", "if", "use_cache", "is", "True", ":", "\n", "                ", "past", "=", "(", "(", "encoder_outputs", ",", "decoder_outputs", "[", "1", "]", ")", ",", ")", "\n", "decoder_outputs", "=", "decoder_outputs", "[", ":", "1", "]", "+", "past", "+", "decoder_outputs", "[", "2", ":", "]", "\n", "\n", "", "sequence_output", "=", "decoder_outputs", "[", "0", "]", "\n", "# Rescale output before projecting on vocab", "\n", "# See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/transformer.py#L586", "\n", "sequence_output", "=", "sequence_output", "*", "(", "self", ".", "model_dim", "**", "-", "0.5", ")", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "sequence_output", ")", "\n", "\n", "decoder_outputs", "=", "(", "lm_logits", ",", ")", "+", "decoder_outputs", "[", "1", ":", "]", "# Add hidden states and attention if they are here", "\n", "\n", "# Compute losses", "\n", "", "loss", "=", "None", "\n", "if", "labels", "is", "not", "None", "and", "not", "self", ".", "freeze_fid_params", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "100", ")", "\n", "loss", "=", "loss_fct", "(", "lm_logits", ".", "view", "(", "-", "1", ",", "lm_logits", ".", "size", "(", "-", "1", ")", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "# TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666", "\n", "\n", "", "if", "has_answer_labels", "is", "not", "None", "and", "not", "self", ".", "freeze_has_answer_heads", "and", "self", ".", "use_bce_loss", ":", "\n", "            ", "has_answer_loss_fct", "=", "BCEWithLogitsLoss", "(", "reduction", "=", "\"mean\"", ")", "\n", "has_answer_losses", "=", "[", "]", "\n", "for", "has_answer_logits", "in", "all_has_answer_outputs", ":", "\n", "                ", "layer_ha_loss", "=", "has_answer_loss_fct", "(", "has_answer_logits", ",", "has_answer_labels", ")", "\n", "has_answer_losses", ".", "append", "(", "layer_ha_loss", ")", "\n", "", "avg_has_answer_loss", "=", "sum", "(", "has_answer_losses", ")", "/", "len", "(", "has_answer_losses", ")", "\n", "loss", "=", "avg_has_answer_loss", "if", "loss", "is", "None", "else", "loss", "+", "avg_has_answer_loss", "\n", "\n", "# REINFORCE loss for training the scheduler", "\n", "", "reward", "=", "None", "\n", "if", "scheduler_outputs", "is", "not", "None", "and", "has_answer_labels", "is", "not", "None", "and", "self", ".", "use_rl_loss", ":", "\n", "            ", "actions", ",", "log_probs", ",", "all_skylines", ",", "retained_passages", "=", "scheduler_outputs", "\n", "rl_loss", ",", "reward", "=", "compute_REINFORCE_loss", "(", "has_answer_labels", ",", "actions", ",", "log_probs", ",", "\n", "self", ".", "step_cost", ",", "discount", "=", "self", ".", "discount", ")", "\n", "loss", "=", "rl_loss", "if", "loss", "is", "None", "else", "loss", "+", "rl_loss", "\n", "\n", "", "if", "loss", "is", "not", "None", ":", "\n", "            ", "if", "reward", "is", "not", "None", ":", "\n", "                ", "decoder_outputs", "=", "(", "loss", ",", "reward", ")", "+", "decoder_outputs", "\n", "", "else", ":", "\n", "                ", "decoder_outputs", "=", "(", "loss", ",", ")", "+", "decoder_outputs", "\n", "\n", "", "", "return", "decoder_outputs", "+", "encoder_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.ACFiDT5.prepare_inputs_for_generation": [[625, 636], ["None"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "self", ",", "input_ids", ",", "past", ",", "attention_mask", ",", "use_cache", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "past", "is", "not", "None", ",", "\"past has to be defined for encoder_outputs\"", "\n", "\n", "encoder_outputs", ",", "decoder_past_key_value_states", "=", "past", "\n", "\n", "return", "{", "\n", "\"decoder_input_ids\"", ":", "input_ids", ",", "\n", "\"decoder_past_key_value_states\"", ":", "decoder_past_key_value_states", ",", "\n", "\"encoder_outputs\"", ":", "encoder_outputs", ",", "\n", "\"attention_mask\"", ":", "attention_mask", ",", "\n", "\"use_cache\"", ":", "use_cache", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.ACFiDT5._reorder_cache": [[638, 663], ["logger.warning", "len", "len", "layer_past_state.index_select"], "methods", ["None"], ["", "def", "_reorder_cache", "(", "self", ",", "past", ",", "beam_idx", ")", ":", "\n", "# if decoder past is not included in output", "\n", "# speedy decoding is disabled and no need to reorder", "\n", "        ", "if", "past", "[", "1", "]", "is", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\"You might want to consider setting `use_cache=True` to speed up decoding\"", ")", "\n", "return", "past", "\n", "\n", "", "decoder_past", "=", "past", "[", "1", "]", "\n", "past", "=", "(", "past", "[", "0", "]", ",", ")", "\n", "reordered_decoder_past", "=", "(", ")", "\n", "for", "layer_past_states", "in", "decoder_past", ":", "\n", "# get the correct batch idx from layer past batch dim", "\n", "# batch dim of `past` is at 2nd position", "\n", "            ", "reordered_layer_past_states", "=", "(", ")", "\n", "for", "layer_past_state", "in", "layer_past_states", ":", "\n", "# need to set correct `past` for each of the four key / value states", "\n", "                ", "reordered_layer_past_states", "=", "reordered_layer_past_states", "+", "(", "\n", "layer_past_state", ".", "index_select", "(", "0", ",", "beam_idx", ")", ",", "\n", ")", "\n", "\n", "", "assert", "reordered_layer_past_states", "[", "0", "]", ".", "shape", "==", "layer_past_states", "[", "0", "]", ".", "shape", "\n", "assert", "len", "(", "reordered_layer_past_states", ")", "==", "len", "(", "layer_past_states", ")", "\n", "\n", "reordered_decoder_past", "=", "reordered_decoder_past", "+", "(", "reordered_layer_past_states", ",", ")", "\n", "", "return", "past", "+", "(", "reordered_decoder_past", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.ACFiDT5.generate": [[664, 1062], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "isinstance", "isinstance", "isinstance", "hasattr", "fidt5_ac.ACFiDT5.get_output_embeddings", "AttributeError", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full.ne().long", "torch.full.ne().long", "torch.full.ne().long", "logger.warning", "hasattr", "callable", "fidt5_ac.ACFiDT5.get_encoder", "fidt5_ac.ACFiDT5.", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.full.unsqueeze().expand", "torch.full.unsqueeze().expand", "torch.full.unsqueeze().expand", "torch.full.new_ones.unsqueeze().expand", "torch.full.contiguous().view", "torch.full.contiguous().view", "torch.full.contiguous().view", "torch.full.new_ones.contiguous().view", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.arange().view().repeat().view().to", "torch.arange().view().repeat().view().to", "torch.arange().view().repeat().view().to", "torch.arange().view().repeat().view().to", "torch.arange().view().repeat().view().to", "torch.arange().view().repeat().view().to", "torch.arange().view().repeat().view().to", "torch.arange().view().repeat().view().to", "torch.arange().view().repeat().view().to", "fidt5_ac.ACFiDT5._generate_beam_search", "fidt5_ac.ACFiDT5._generate_no_beam_search", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "torch.full.dim", "torch.full.dim", "torch.full.dim", "torch.full.new_ones", "torch.full.new_ones", "torch.full.new_ones", "hasattr", "hasattr", "encoder_outputs[].index_select", "encoder_outputs[].index_select", "torch.full.ne", "torch.full.ne", "torch.full.ne", "torch.full.unsqueeze", "torch.full.unsqueeze", "torch.full.unsqueeze", "torch.full.new_ones.unsqueeze", "torch.full.contiguous", "torch.full.contiguous", "torch.full.contiguous", "torch.full.new_ones.contiguous", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "next", "next", "fidt5_ac.ACFiDT5.parameters", "fidt5_ac.ACFiDT5.parameters", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.FiDT5.get_output_embeddings", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.FiDT5.get_encoder"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate", "(", "\n", "self", ",", "\n", "input_ids", ":", "Optional", "[", "torch", ".", "LongTensor", "]", "=", "None", ",", "\n", "max_length", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "min_length", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "do_sample", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "early_stopping", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "num_beams", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "temperature", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "top_k", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "top_p", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "repetition_penalty", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "bad_words_ids", ":", "Optional", "[", "Iterable", "[", "int", "]", "]", "=", "None", ",", "\n", "bos_token_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "pad_token_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "eos_token_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "length_penalty", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "no_repeat_ngram_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "num_return_sequences", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "attention_mask", ":", "Optional", "[", "torch", ".", "LongTensor", "]", "=", "None", ",", "\n", "decoder_start_token_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "use_cache", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "**", "model_specific_kwargs", "\n", ")", "->", "torch", ".", "LongTensor", ":", "\n", "        ", "r\"\"\" Generates sequences for models with a LM head. The method currently supports greedy decoding, beam-search decoding, sampling with temperature, sampling with top-k or nucleus sampling.\n\n        Adapted in part from `Facebook's XLM beam search code`_.\n\n        .. _`Facebook's XLM beam search code`:\n           https://github.com/facebookresearch/XLM/blob/9e6f6814d17be4fe5b15f2e6c43eb2b2d76daeb4/src/model/transformer.py#L529\n\n\n        Parameters:\n\n            input_ids: (`optional`) `torch.LongTensor` of shape `(batch_size, sequence_length)`\n                The sequence used as a prompt for the generation. If `None` the method initializes\n                it as an empty `torch.LongTensor` of shape `(1,)`.\n\n            max_length: (`optional`) int\n                The max length of the sequence to be generated.  Between `min_length` and infinity. Default to 20.\n\n            min_length: (`optional`) int\n                The min length of the sequence to be generated.  Between 0 and infinity. Default to 0.\n\n            do_sample: (`optional`) bool\n                If set to `False` greedy decoding is used. Otherwise sampling is used. Defaults to `False` as defined in `configuration_utils.PretrainedConfig`.\n\n            early_stopping: (`optional`) bool\n                if set to `True` beam search is stopped when at least `num_beams` sentences finished per batch. Defaults to `False` as defined in `configuration_utils.PretrainedConfig`.\n\n            num_beams: (`optional`) int\n                Number of beams for beam search. Must be between 1 and infinity. 1 means no beam search. Default to 1.\n\n            temperature: (`optional`) float\n                The value used to module the next token probabilities. Must be strictly positive. Default to 1.0.\n\n            top_k: (`optional`) int\n                The number of highest probability vocabulary tokens to keep for top-k-filtering. Between 1 and infinity. Default to 50.\n\n            top_p: (`optional`) float\n                The cumulative probability of parameter highest probability vocabulary tokens to keep for nucleus sampling. Must be between 0 and 1. Default to 1.\n\n            repetition_penalty: (`optional`) float\n                The parameter for repetition penalty. Between 1.0 and infinity. 1.0 means no penalty. Default to 1.0.\n\n            pad_token_id: (`optional`) int\n                Padding token. Default to specicic model pad_token_id or None if it does not exist.\n\n            bos_token_id: (`optional`) int\n                BOS token. Defaults to `bos_token_id` as defined in the models config.\n\n            eos_token_id: (`optional`) int\n                EOS token. Defaults to `eos_token_id` as defined in the models config.\n\n            length_penalty: (`optional`) float\n                Exponential penalty to the length. Default to 1.\n\n            no_repeat_ngram_size: (`optional`) int\n                If set to int > 0, all ngrams of size `no_repeat_ngram_size` can only occur once.\n            bad_words_ids: (`optional`) list of lists of int\n                `bad_words_ids` contains tokens that are not allowed to be generated. In order to get the tokens of the words that should not appear in the generated text, use `tokenizer.encode(bad_word, add_prefix_space=True)`.\n\n            num_return_sequences: (`optional`) int\n                The number of independently computed returned sequences for each element in the batch. Default to 1.\n\n            attention_mask (`optional`) obj: `torch.LongTensor` of same shape as `input_ids`\n                Mask to avoid performing attention on padding token indices.\n                Mask values selected in ``[0, 1]``:\n                ``1`` for tokens that are NOT MASKED, ``0`` for MASKED tokens.\n                Defaults to `None`.\n\n                `What are attention masks? <../glossary.html#attention-mask>`__\n\n            decoder_start_token_id=None: (`optional`) int\n                If an encoder-decoder model starts decoding with a different token than BOS.\n                Defaults to `None` and is changed to `BOS` later.\n\n            use_cache: (`optional`) bool\n                If `use_cache` is True, past key values are used to speed up decoding if applicable to model. Defaults to `True`.\n\n            model_specific_kwargs: (`optional`) dict\n                Additional model specific kwargs will be forwarded to the `forward` function of the model.\n\n        Return:\n\n            output: `torch.LongTensor` of shape `(batch_size * num_return_sequences, sequence_length)`\n                sequence_length is either equal to max_length or shorter if all batches finished early due to the `eos_token_id`\n\n        Examples::\n\n            tokenizer = AutoTokenizer.from_pretrained('distilgpt2')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('distilgpt2')    # Download model and configuration from S3 and cache.\n            outputs = model.generate(max_length=40)  # do greedy decoding\n            print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('openai-gpt')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('openai-gpt')    # Download model and configuration from S3 and cache.\n            input_context = 'The dog'\n            input_ids = tokenizer.encode(input_context, return_tensors='pt')  # encode input context\n            outputs = model.generate(input_ids=input_ids, num_beams=5, num_return_sequences=3, temperature=1.5)  # generate 3 independent sequences using beam search decoding (5 beams) with sampling from initial context 'The dog'\n            for i in range(3): #  3 output sequences were generated\n                print('Generated {}: {}'.format(i, tokenizer.decode(outputs[i], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('distilgpt2')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('distilgpt2')    # Download model and configuration from S3 and cache.\n            input_context = 'The dog'\n            input_ids = tokenizer.encode(input_context, return_tensors='pt')  # encode input context\n            outputs = model.generate(input_ids=input_ids, max_length=40, temperature=0.7, num_return_sequences=3)  # 3 generate sequences using by sampling\n            for i in range(3): #  3 output sequences were generated\n                print('Generated {}: {}'.format(i, tokenizer.decode(outputs[i], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('ctrl')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('ctrl')    # Download model and configuration from S3 and cache.\n            input_context = 'Legal My neighbor is'  # \"Legal\" is one of the control codes for ctrl\n            input_ids = tokenizer.encode(input_context, return_tensors='pt')  # encode input context\n            outputs = model.generate(input_ids=input_ids, max_length=50, temperature=0.7, repetition_penalty=1.2)  # generate sequences\n            print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('gpt2')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('gpt2')    # Download model and configuration from S3 and cache.\n            input_context = 'My cute dog'  # \"Legal\" is one of the control codes for ctrl\n            bad_words_ids = [tokenizer.encode(bad_word, add_prefix_space=True) for bad_word in ['idiot', 'stupid', 'shut up']]\n            input_ids = tokenizer.encode(input_context, return_tensors='pt')  # encode input context\n            outputs = model.generate(input_ids=input_ids, max_length=100, do_sample=True, bad_words_ids=bad_words_ids)  # generate sequences without allowing bad_words to be generated\n        \"\"\"", "\n", "\n", "# We cannot generate if the model does not have a LM head", "\n", "if", "self", ".", "get_output_embeddings", "(", ")", "is", "None", ":", "\n", "            ", "raise", "AttributeError", "(", "\n", "\"You tried to generate sequences with a model that does not have a LM Head.\"", "\n", "\"Please use another model class (e.g. `OpenAIGPTLMHeadModel`, `XLNetLMHeadModel`, `GPT2LMHeadModel`, `CTRLLMHeadModel`, `T5WithLMHeadModel`, `TransfoXLLMHeadModel`, `XLMWithLMHeadModel`, `BartForConditionalGeneration` )\"", "\n", ")", "\n", "\n", "", "max_length", "=", "max_length", "if", "max_length", "is", "not", "None", "else", "self", ".", "config", ".", "max_length", "\n", "min_length", "=", "min_length", "if", "min_length", "is", "not", "None", "else", "self", ".", "config", ".", "min_length", "\n", "do_sample", "=", "do_sample", "if", "do_sample", "is", "not", "None", "else", "self", ".", "config", ".", "do_sample", "\n", "early_stopping", "=", "early_stopping", "if", "early_stopping", "is", "not", "None", "else", "self", ".", "config", ".", "early_stopping", "\n", "use_cache", "=", "use_cache", "if", "use_cache", "is", "not", "None", "else", "self", ".", "config", ".", "use_cache", "\n", "num_beams", "=", "num_beams", "if", "num_beams", "is", "not", "None", "else", "self", ".", "config", ".", "num_beams", "\n", "temperature", "=", "temperature", "if", "temperature", "is", "not", "None", "else", "self", ".", "config", ".", "temperature", "\n", "top_k", "=", "top_k", "if", "top_k", "is", "not", "None", "else", "self", ".", "config", ".", "top_k", "\n", "top_p", "=", "top_p", "if", "top_p", "is", "not", "None", "else", "self", ".", "config", ".", "top_p", "\n", "repetition_penalty", "=", "repetition_penalty", "if", "repetition_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "repetition_penalty", "\n", "bos_token_id", "=", "bos_token_id", "if", "bos_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "bos_token_id", "\n", "pad_token_id", "=", "pad_token_id", "if", "pad_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "pad_token_id", "\n", "eos_token_id", "=", "eos_token_id", "if", "eos_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "eos_token_id", "\n", "length_penalty", "=", "length_penalty", "if", "length_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "length_penalty", "\n", "no_repeat_ngram_size", "=", "(", "\n", "no_repeat_ngram_size", "if", "no_repeat_ngram_size", "is", "not", "None", "else", "self", ".", "config", ".", "no_repeat_ngram_size", "\n", ")", "\n", "bad_words_ids", "=", "bad_words_ids", "if", "bad_words_ids", "is", "not", "None", "else", "self", ".", "config", ".", "bad_words_ids", "\n", "num_return_sequences", "=", "(", "\n", "num_return_sequences", "if", "num_return_sequences", "is", "not", "None", "else", "self", ".", "config", ".", "num_return_sequences", "\n", ")", "\n", "decoder_start_token_id", "=", "(", "\n", "decoder_start_token_id", "if", "decoder_start_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "decoder_start_token_id", "\n", ")", "\n", "\n", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "batch_size", "=", "input_ids", ".", "shape", "[", "0", "]", "# overriden by the input batch_size", "\n", "", "else", ":", "\n", "            ", "batch_size", "=", "1", "\n", "\n", "", "assert", "isinstance", "(", "max_length", ",", "int", ")", "and", "max_length", ">", "0", ",", "\"`max_length` should be a strictly positive integer.\"", "\n", "assert", "isinstance", "(", "min_length", ",", "int", ")", "and", "min_length", ">=", "0", ",", "\"`min_length` should be a positive integer.\"", "\n", "assert", "isinstance", "(", "do_sample", ",", "bool", ")", ",", "\"`do_sample` should be a boolean.\"", "\n", "assert", "isinstance", "(", "early_stopping", ",", "bool", ")", ",", "\"`early_stopping` should be a boolean.\"", "\n", "assert", "isinstance", "(", "use_cache", ",", "bool", ")", ",", "\"`use_cache` should be a boolean.\"", "\n", "assert", "isinstance", "(", "num_beams", ",", "int", ")", "and", "num_beams", ">", "0", ",", "\"`num_beams` should be a strictly positive integer.\"", "\n", "assert", "temperature", ">", "0", ",", "\"`temperature` should be strictly positive.\"", "\n", "assert", "isinstance", "(", "top_k", ",", "int", ")", "and", "top_k", ">=", "0", ",", "\"`top_k` should be a positive integer.\"", "\n", "assert", "0", "<=", "top_p", "<=", "1", ",", "\"`top_p` should be between 0 and 1.\"", "\n", "assert", "repetition_penalty", ">=", "1.0", ",", "\"`repetition_penalty` should be >= 1.\"", "\n", "assert", "input_ids", "is", "not", "None", "or", "(", "\n", "isinstance", "(", "bos_token_id", ",", "int", ")", "and", "bos_token_id", ">=", "0", "\n", ")", ",", "\"If input_ids is not defined, `bos_token_id` should be a positive integer.\"", "\n", "assert", "pad_token_id", "is", "None", "or", "(", "\n", "isinstance", "(", "pad_token_id", ",", "int", ")", "and", "(", "pad_token_id", ">=", "0", ")", "\n", ")", ",", "\"`pad_token_id` should be a positive integer.\"", "\n", "assert", "(", "eos_token_id", "is", "None", ")", "or", "(", "\n", "isinstance", "(", "eos_token_id", ",", "int", ")", "and", "(", "eos_token_id", ">=", "0", ")", "\n", ")", ",", "\"`eos_token_id` should be a positive integer.\"", "\n", "assert", "length_penalty", ">", "0", ",", "\"`length_penalty` should be strictly positive.\"", "\n", "assert", "(", "\n", "isinstance", "(", "no_repeat_ngram_size", ",", "int", ")", "and", "no_repeat_ngram_size", ">=", "0", "\n", ")", ",", "\"`no_repeat_ngram_size` should be a positive integer.\"", "\n", "assert", "(", "\n", "isinstance", "(", "num_return_sequences", ",", "int", ")", "and", "num_return_sequences", ">", "0", "\n", ")", ",", "\"`num_return_sequences` should be a strictly positive integer.\"", "\n", "assert", "(", "\n", "bad_words_ids", "is", "None", "or", "isinstance", "(", "bad_words_ids", ",", "list", ")", "and", "isinstance", "(", "bad_words_ids", "[", "0", "]", ",", "list", ")", "\n", ")", ",", "\"`bad_words_ids` is either `None` or a list of lists of tokens that should not be generated\"", "\n", "\n", "if", "input_ids", "is", "None", ":", "\n", "            ", "assert", "isinstance", "(", "bos_token_id", ",", "int", ")", "and", "bos_token_id", ">=", "0", ",", "(", "\n", "\"you should either supply a context to complete as `input_ids` input \"", "\n", "\"or a `bos_token_id` (integer >= 0) as a first token to start the generation.\"", "\n", ")", "\n", "input_ids", "=", "torch", ".", "full", "(", "\n", "(", "batch_size", ",", "1", ")", ",", "bos_token_id", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "assert", "input_ids", ".", "dim", "(", ")", "==", "2", ",", "\"Input prompt should be of shape (batch_size, sequence length).\"", "\n", "\n", "# not allow to duplicate outputs when greedy decoding", "\n", "", "if", "do_sample", "is", "False", ":", "\n", "            ", "if", "num_beams", "==", "1", ":", "\n", "# no_beam_search greedy generation conditions", "\n", "                ", "assert", "(", "\n", "num_return_sequences", "==", "1", "\n", ")", ",", "\"Greedy decoding will always produce the same output for num_beams == 1 and num_return_sequences > 1. Please set num_return_sequences = 1\"", "\n", "\n", "", "else", ":", "\n", "# beam_search greedy generation conditions", "\n", "                ", "assert", "(", "\n", "num_beams", ">=", "num_return_sequences", "\n", ")", ",", "\"Greedy beam search decoding cannot return more sequences than it has beams. Please set num_beams >= num_return_sequences\"", "\n", "\n", "# create attention mask if necessary", "\n", "# TODO (PVP): this should later be handled by the forward fn() in each model in the future see PR 3140", "\n", "", "", "if", "(", "attention_mask", "is", "None", ")", "and", "(", "pad_token_id", "is", "not", "None", ")", "and", "(", "pad_token_id", "in", "input_ids", ")", ":", "\n", "            ", "attention_mask", "=", "input_ids", ".", "ne", "(", "pad_token_id", ")", ".", "long", "(", ")", "\n", "", "elif", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "input_ids", ".", "new_ones", "(", "input_ids", ".", "shape", ")", "\n", "\n", "# set pad_token_id to eos_token_id if not set. Important that this is done after", "\n", "# attention_mask is created", "\n", "", "if", "pad_token_id", "is", "None", "and", "eos_token_id", "is", "not", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Setting `pad_token_id` to {} (first `eos_token_id`) to generate sequence\"", ".", "format", "(", "eos_token_id", ")", "\n", ")", "\n", "pad_token_id", "=", "eos_token_id", "\n", "\n", "# current position and vocab size", "\n", "", "if", "hasattr", "(", "self", ".", "config", ",", "\"vocab_size\"", ")", ":", "\n", "            ", "vocab_size", "=", "self", ".", "config", ".", "vocab_size", "\n", "", "elif", "(", "\n", "self", ".", "config", ".", "is_encoder_decoder", "\n", "and", "hasattr", "(", "self", ".", "config", ",", "\"decoder\"", ")", "\n", "and", "hasattr", "(", "self", ".", "config", ".", "decoder", ",", "\"vocab_size\"", ")", "\n", ")", ":", "\n", "            ", "vocab_size", "=", "self", ".", "config", ".", "decoder", ".", "vocab_size", "\n", "\n", "# set effective batch size and effective batch multiplier according to do_sample", "\n", "", "if", "do_sample", ":", "\n", "            ", "effective_batch_size", "=", "batch_size", "*", "num_return_sequences", "\n", "effective_batch_mult", "=", "num_return_sequences", "\n", "", "else", ":", "\n", "            ", "effective_batch_size", "=", "batch_size", "\n", "effective_batch_mult", "=", "1", "\n", "\n", "", "if", "self", ".", "config", ".", "is_encoder_decoder", ":", "\n", "            ", "if", "decoder_start_token_id", "is", "None", ":", "\n", "                ", "decoder_start_token_id", "=", "bos_token_id", "\n", "\n", "", "assert", "(", "\n", "decoder_start_token_id", "is", "not", "None", "\n", ")", ",", "\"decoder_start_token_id or bos_token_id has to be defined for encoder-decoder generation\"", "\n", "assert", "hasattr", "(", "self", ",", "\"get_encoder\"", ")", ",", "\"{} should have a 'get_encoder' function defined\"", ".", "format", "(", "self", ")", "\n", "assert", "callable", "(", "self", ".", "get_encoder", ")", ",", "\"{} should be a method\"", ".", "format", "(", "self", ".", "get_encoder", ")", "\n", "\n", "# get encoder and store encoder outputs", "\n", "encoder", "=", "self", ".", "get_encoder", "(", ")", "\n", "\n", "encoder_outputs", ":", "tuple", "=", "encoder", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "ac_scheduler", "=", "self", ".", "ac_scheduler", ",", "\n", ")", "\n", "# Change (ACFiD): return the actual number of layers computed by AC scheduler", "\n", "skyline", "=", "encoder_outputs", "[", "2", "]", "[", "2", "]", "\n", "layer_cost", "=", "torch", ".", "sum", "(", "skyline", "+", "1", ",", "1", ")", "# shape: [bsz]", "\n", "", "else", ":", "\n", "            ", "layer_cost", "=", "None", "\n", "\n", "# Expand input ids if num_beams > 1 or num_return_sequences > 1", "\n", "", "if", "num_return_sequences", ">", "1", "or", "num_beams", ">", "1", ":", "\n", "# input_ids_len = input_ids.shape[-1]", "\n", "            ", "input_ids", "=", "input_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "effective_batch_mult", "*", "num_beams", ",", "-", "1", ")", "\n", "attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "\n", "batch_size", ",", "effective_batch_mult", "*", "num_beams", ",", "-", "1", "\n", ")", "\n", "\n", "input_ids", "=", "input_ids", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "effective_batch_size", "*", "num_beams", ",", "-", "1", "\n", ")", "# shape: (batch_size * num_return_sequences * num_beams, cur_len)", "\n", "attention_mask", "=", "attention_mask", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "effective_batch_size", "*", "num_beams", ",", "-", "1", "\n", ")", "# shape: (batch_size * num_return_sequences * num_beams, cur_len)", "\n", "\n", "", "if", "self", ".", "config", ".", "is_encoder_decoder", ":", "\n", "# create empty decoder_input_ids", "\n", "            ", "input_ids", "=", "torch", ".", "full", "(", "\n", "(", "effective_batch_size", "*", "num_beams", ",", "1", ")", ",", "\n", "decoder_start_token_id", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", ",", "\n", ")", "\n", "cur_len", "=", "1", "\n", "\n", "assert", "(", "\n", "batch_size", "==", "encoder_outputs", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", ")", ",", "f\"expected encoder_outputs[0] to have 1st dimension bs={batch_size}, got {encoder_outputs[0].shape[0]} \"", "\n", "\n", "# expand batch_idx to assign correct encoder output for expanded input_ids (due to num_beams > 1 and num_return_sequences > 1)", "\n", "expanded_batch_idxs", "=", "(", "\n", "torch", ".", "arange", "(", "batch_size", ")", "\n", ".", "view", "(", "-", "1", ",", "1", ")", "\n", ".", "repeat", "(", "1", ",", "num_beams", "*", "effective_batch_mult", ")", "\n", ".", "view", "(", "-", "1", ")", "\n", ".", "to", "(", "input_ids", ".", "device", ")", "\n", ")", "\n", "# expand encoder_outputs", "\n", "encoder_outputs", "=", "(", "\n", "encoder_outputs", "[", "0", "]", ".", "index_select", "(", "0", ",", "expanded_batch_idxs", ")", ",", "# hidden_states", "\n", "encoder_outputs", "[", "1", "]", ".", "index_select", "(", "0", ",", "expanded_batch_idxs", ")", ",", "# attention_mask", "\n", "*", "encoder_outputs", "[", "2", ":", "]", "\n", ")", "\n", "# ^Change (ACFiD): update the attention_mask by the one returned by encoder", "\n", "\n", "", "else", ":", "\n", "            ", "encoder_outputs", "=", "None", "\n", "cur_len", "=", "input_ids", ".", "shape", "[", "-", "1", "]", "\n", "\n", "", "assert", "(", "\n", "cur_len", "<", "max_length", "\n", ")", ",", "f\"The context has {cur_len} number of tokens, but `max_length` is only {max_length}. Please make sure that `max_length` is bigger than the number of tokens, by setting either `generate(max_length=...,...)` or `config.max_length = ...`\"", "\n", "\n", "if", "num_beams", ">", "1", ":", "\n", "            ", "output", "=", "self", ".", "_generate_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", "=", "cur_len", ",", "\n", "max_length", "=", "max_length", ",", "\n", "min_length", "=", "min_length", ",", "\n", "do_sample", "=", "do_sample", ",", "\n", "early_stopping", "=", "early_stopping", ",", "\n", "temperature", "=", "temperature", ",", "\n", "top_k", "=", "top_k", ",", "\n", "top_p", "=", "top_p", ",", "\n", "repetition_penalty", "=", "repetition_penalty", ",", "\n", "no_repeat_ngram_size", "=", "no_repeat_ngram_size", ",", "\n", "bad_words_ids", "=", "bad_words_ids", ",", "\n", "pad_token_id", "=", "pad_token_id", ",", "\n", "eos_token_id", "=", "eos_token_id", ",", "\n", "batch_size", "=", "effective_batch_size", ",", "\n", "num_return_sequences", "=", "num_return_sequences", ",", "\n", "length_penalty", "=", "length_penalty", ",", "\n", "num_beams", "=", "num_beams", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "encoder_outputs", "=", "encoder_outputs", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "model_specific_kwargs", "=", "model_specific_kwargs", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "_generate_no_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", "=", "cur_len", ",", "\n", "max_length", "=", "max_length", ",", "\n", "min_length", "=", "min_length", ",", "\n", "do_sample", "=", "do_sample", ",", "\n", "temperature", "=", "temperature", ",", "\n", "top_k", "=", "top_k", ",", "\n", "top_p", "=", "top_p", ",", "\n", "repetition_penalty", "=", "repetition_penalty", ",", "\n", "no_repeat_ngram_size", "=", "no_repeat_ngram_size", ",", "\n", "bad_words_ids", "=", "bad_words_ids", ",", "\n", "pad_token_id", "=", "pad_token_id", ",", "\n", "eos_token_id", "=", "eos_token_id", ",", "\n", "batch_size", "=", "effective_batch_size", ",", "\n", "encoder_outputs", "=", "encoder_outputs", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "model_specific_kwargs", "=", "model_specific_kwargs", ",", "\n", ")", "\n", "\n", "", "return", "output", ",", "layer_cost", "\n", "", "", ""]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.test_retriever_baseline.evaluate": [[24, 73], ["enumerate", "numpy.mean", "logger.info", "logger.info", "enumerate", "dataset.get_example", "range", "all_accuracies.append", "len", "evaluation.has_answer"], "function", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.data.Dataset.get_example", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.has_answer"], ["def", "evaluate", "(", "dataset", ",", "dataloader", ",", "opt", ")", ":", "\n", "    ", "all_accuracies", "=", "[", "]", "\n", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "        ", "idx", ",", "answer_ids", ",", "answer_mask", ",", "context_ids", ",", "context_mask", ",", "has_answer_labels", "=", "batch", "\n", "# model.encoder.n_passages = context_ids.size(1)", "\n", "# answer_ids, answer_mask = answer_ids.cuda(), answer_mask.bool().cuda()", "\n", "# context_ids = context_ids.cuda().view(context_ids.size(0), -1)", "\n", "# context_mask = context_mask.cuda().view(context_ids.size(0), -1)", "\n", "# decoder_input_ids = None", "\n", "# has_answer_labels = None", "\n", "# # labels = answer_ids.masked_fill(~answer_mask, -100)", "\n", "# labels = None", "\n", "#", "\n", "# inputs = {", "\n", "#     'input_ids': context_ids,", "\n", "#     'attention_mask': context_mask,", "\n", "#     'decoder_attention_mask': answer_mask,", "\n", "#     'decoder_input_ids': decoder_input_ids,", "\n", "#     'labels': labels,", "\n", "#     'has_answer_labels': has_answer_labels,", "\n", "# }", "\n", "# outputs = model(**inputs)", "\n", "# scheduler_outputs = outputs[-2]", "\n", "# actions, log_probs, all_skylines, retained_passages = scheduler_outputs", "\n", "\n", "# retained_passages: [bsz, num_passages_retained]", "\n", "for", "j", ",", "index", "in", "enumerate", "(", "idx", ")", ":", "\n", "            ", "answer_acc", "=", "0", "# 1 if the selected top-k passages contain the answer, 0 otherwise", "\n", "example", "=", "dataset", ".", "get_example", "(", "index", ")", "\n", "answers", "=", "example", ".", "answers", "\n", "for", "k", "in", "range", "(", "opt", ".", "num_passages_retained", ")", ":", "\n", "                ", "context", "=", "example", ".", "contexts", "[", "k", "]", "\n", "if", "has_answer", "(", "answers", ",", "context", ",", "simple_tokenizer", ")", ":", "\n", "                    ", "answer_acc", "=", "1", "\n", "break", "\n", "", "", "all_accuracies", ".", "append", "(", "answer_acc", ")", "\n", "\n", "", "", "accuracy", "=", "np", ".", "mean", "(", "all_accuracies", ")", "\n", "\n", "logger", ".", "info", "(", "'total number of example %d'", "%", "len", "(", "all_accuracies", ")", ")", "\n", "logger", ".", "info", "(", "f\"top-k retrieval accuracy = {accuracy:.5f}\"", ")", "\n", "\n", "# # write result", "\n", "# with open(os.path.join(opt.checkpoint_dir, \"retrieval_acc\"), \"a\") as f:", "\n", "#     f.write(f\"budget = {opt.budget}, num_passages_retained = {opt.num_passages_retained}, \"", "\n", "#             f\"accuracy = {accuracy}\\n\")", "\n", "\n", "return", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.BaseScheduler.__init__": [[17, 21], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "ac_scheduler.BaseScheduler._get_init_priorities"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.BaseScheduler._get_init_priorities"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "init_priorities", "=", "nn", ".", "Parameter", "(", "self", ".", "_get_init_priorities", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.BaseScheduler._get_init_priorities": [[22, 36], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.distributions.utils.probs_to_logits", "torch.distributions.utils.probs_to_logits", "range"], "methods", ["None"], ["", "def", "_get_init_priorities", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Initialize the initial priorities for all passages.\"\"\"", "\n", "# # Uniform", "\n", "# self.init_priorities = nn.Parameter(torch.Tensor(self.config.scheduler_n_context))", "\n", "# bound = 1 / math.sqrt(self.config.scheduler_n_context)", "\n", "# self.init_priorities.data.uniform_(-bound, bound)", "\n", "#", "\n", "# # Zeros", "\n", "# self.init_priorities = nn.Parameter(torch.Tensor(self.config.scheduler_n_context))", "\n", "# self.init_priorities.data.fill_(0.)", "\n", "\n", "# Heuristic", "\n", "init_probs", "=", "torch", ".", "tensor", "(", "[", "0.5", "/", "(", "i", "+", "1", ")", "for", "i", "in", "range", "(", "self", ".", "config", ".", "scheduler_n_context", ")", "]", ")", "\n", "return", "probs_to_logits", "(", "init_probs", ",", "is_binary", "=", "True", ")", "# shape: [n_passages]", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.BaseScheduler.forward": [[37, 48], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "has_answer_logits", ",", "layers", ",", "ranks", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            has_answer_logits (Tensor): float Tensor with shape [bsz, n_passages]\n            layers (Tensor): int Tensor with shape [bsz, n_passages]\n            ranks (Tensor): int Tensor with shape [bsz, n_passages]\n\n        Returns:\n            priorities (Tensor): float Tensor with shape [bsz, n_passages]\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.BaseScheduler.act": [[49, 91], ["ac_scheduler.BaseScheduler.init_priorities[].unsqueeze().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.cat.gather().squeeze", "torch.cat.gather().squeeze", "ac_scheduler.BaseScheduler.forward", "ac_scheduler.BaseScheduler.argmax", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.log_prob", "torch.distributions.Categorical.log_prob", "ac_scheduler.BaseScheduler.init_priorities[].unsqueeze", "ac_scheduler.BaseScheduler.unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.cat.gather", "torch.cat.gather", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "layer_tensor.unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.FiDT5.forward"], ["", "def", "act", "(", "self", ",", "all_has_answer_logits", ",", "layer_indices", ",", "masks", ",", "greedy", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Take an action given the current status of the skyline.\n\n        Args:\n            all_has_answer_logits (torch.Tensor): float Tensor with shape [bsz, n_passages, num_layers]\n            layer_indices (torch.Tensor): int Tensor with shape [bsz, n_passages]\n            masks (torch.Tensor): float Tensor with shape [bsz, n_passages]\n            greedy (bool): True if act greedily\n            **kwargs:\n\n        Returns:\n            action (torch.Tensor): int Tensor with shape [bsz] that indicates the actions chosen\n            log_probs (torch.Tensor): float Tensor with shape [bsz] that indicates the log-prob of the actions\n        \"\"\"", "\n", "bsz", ",", "n_passages", ",", "num_layers", "=", "all_has_answer_logits", ".", "shape", "\n", "device", "=", "all_has_answer_logits", ".", "device", "\n", "\n", "init_priors", "=", "self", ".", "init_priorities", "[", ":", "n_passages", "]", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "bsz", ",", "-", "1", ")", "# [bsz, n_passages]", "\n", "all_has_answer_logits_with_init", "=", "torch", ".", "cat", "(", "(", "init_priors", ".", "unsqueeze", "(", "-", "1", ")", ",", "all_has_answer_logits", ")", ",", "-", "1", ")", "\n", "# shape: [bsz, n_passages, num_layers + 1]", "\n", "\n", "layer_tensor", "=", "layer_indices", "+", "1", "# shape: [bsz, n_passages], range=[0, num_layers]", "\n", "rank_tensor", "=", "torch", ".", "arange", "(", "n_passages", ",", "device", "=", "device", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "bsz", ",", "-", "1", ")", "# shape: [bsz, n_passages]", "\n", "\n", "# Collect the has_answer logits for each tower (including the initial layers), shape: [bsz, n_passages]", "\n", "has_answer_logits", "=", "all_has_answer_logits_with_init", ".", "gather", "(", "2", ",", "layer_tensor", ".", "unsqueeze", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "\n", "# has_answer_logits = torch.where(layer_indices < 0, init_priors, has_answer_logits)", "\n", "\n", "priorities", "=", "self", ".", "forward", "(", "has_answer_logits", ",", "layer_tensor", ",", "rank_tensor", ")", "# shape: [bsz, n_passages]", "\n", "\n", "# Apply the mask to avoid choosing the maximum towers again", "\n", "priorities", "=", "priorities", "+", "(", "1.", "-", "masks", ")", "*", "LARGE_NEG", "\n", "\n", "if", "greedy", ":", "# select the max priority during evaluation", "\n", "            ", "action", "=", "priorities", ".", "argmax", "(", "-", "1", ")", "# shape: [bsz]", "\n", "log_prob", "=", "-", "torch", ".", "ones", "(", "bsz", ",", "device", "=", "device", ",", "requires_grad", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "m", "=", "Categorical", "(", "logits", "=", "priorities", ")", "\n", "action", "=", "m", ".", "sample", "(", ")", "# shape: [bsz]", "\n", "log_prob", "=", "m", ".", "log_prob", "(", "action", ")", "# shape: [bsz]", "\n", "\n", "", "return", "action", ",", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.TopScheduler.forward": [[94, 97], ["ranks.float"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "has_answer_logits", ",", "layers", ",", "ranks", ")", ":", "\n", "        ", "priorities", "=", "has_answer_logits", "*", "0.", "-", "ranks", ".", "float", "(", ")", "# shape: [bsz, n_passages]", "\n", "return", "priorities", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.DummyScheduler.__init__": [[102, 105], ["ac_scheduler.BaseScheduler.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "1.0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.DummyScheduler.forward": [[106, 109], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "has_answer_logits", ",", "layers", ",", "ranks", ")", ":", "\n", "        ", "priorities", "=", "self", ".", "weight", "*", "has_answer_logits", "# shape: [bsz, n_passages]", "\n", "return", "priorities", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.SimpleScheduler.__init__": [[114, 120], ["ac_scheduler.BaseScheduler.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "1.0", ")", ")", "\n", "\n", "self", ".", "layer_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "num_layers", "+", "1", ",", "1", ")", "\n", "self", ".", "rank_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "scheduler_n_context", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.SimpleScheduler.forward": [[121, 129], ["ac_scheduler.SimpleScheduler.layer_embeddings", "ac_scheduler.SimpleScheduler.rank_embeddings", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "has_answer_logits", ",", "layers", ",", "ranks", ")", ":", "\n", "# Compute the offsets", "\n", "        ", "layer_emb", "=", "self", ".", "layer_embeddings", "(", "layers", ")", "# shape: [bsz, n_passages, 1]", "\n", "rank_emb", "=", "self", ".", "rank_embeddings", "(", "ranks", ")", "# shape: [bsz, n_passages, 1]", "\n", "offsets", "=", "torch", ".", "squeeze", "(", "layer_emb", "+", "rank_emb", ",", "-", "1", ")", "# shape: [bsz, n_passages]", "\n", "\n", "priorities", "=", "self", ".", "weight", "*", "has_answer_logits", "+", "offsets", "# shape: [bsz, n_passages]", "\n", "return", "priorities", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.MLPScheduler.__init__": [[134, 147], ["ac_scheduler.BaseScheduler.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "1.0", ")", ")", "\n", "\n", "embed_size", "=", "config", ".", "scheduler_embed_size", "\n", "self", ".", "layer_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "num_layers", "+", "1", ",", "embed_size", ")", "\n", "self", ".", "rank_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "scheduler_n_context", ",", "embed_size", ")", "\n", "\n", "# MLP", "\n", "hidden_size", "=", "config", ".", "scheduler_hidden_size", "\n", "self", ".", "dense0", "=", "nn", ".", "Linear", "(", "embed_size", "*", "2", "+", "1", ",", "hidden_size", ")", "\n", "self", ".", "act_fn", "=", "F", ".", "relu", "\n", "self", ".", "dense1", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "2", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.MLPScheduler.forward": [[148, 171], ["ac_scheduler.MLPScheduler.layer_embeddings", "ac_scheduler.MLPScheduler.rank_embeddings", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ac_scheduler.MLPScheduler.dense1", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "ac_scheduler.MLPScheduler.act_fn", "has_answer_logits.unsqueeze", "ac_scheduler.MLPScheduler.dense0"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "has_answer_logits", ",", "layers", ",", "ranks", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            has_answer_logits (Tensor): float Tensor with shape [bsz, n_passages]\n            layers (Tensor): int Tensor with shape [bsz, n_passages]\n            ranks (Tensor): int Tensor with shape [bsz, n_passages]\n\n        Returns:\n            priorities (Tensor): float Tensor with shape [bsz, n_passages]\n        \"\"\"", "\n", "\n", "layer_emb", "=", "self", ".", "layer_embeddings", "(", "layers", ")", "# shape: [bsz, n_passages, embed_size]", "\n", "rank_emb", "=", "self", ".", "rank_embeddings", "(", "ranks", ")", "# shape: [bsz, n_passages, embed_size]", "\n", "\n", "mlp_input", "=", "torch", ".", "cat", "(", "\n", "(", "has_answer_logits", ".", "unsqueeze", "(", "-", "1", ")", ",", "layer_emb", ",", "rank_emb", ")", ",", "-", "1", "\n", ")", "# shape: [bsz, n_passages, embed_size * 2 + 1]", "\n", "mlp_output", "=", "self", ".", "dense1", "(", "self", ".", "act_fn", "(", "self", ".", "dense0", "(", "mlp_input", ")", ")", ")", "# shape: [bsz, n_passages, 1]", "\n", "\n", "offset_logit", "=", "torch", ".", "squeeze", "(", "mlp_output", ",", "-", "1", ")", "# shape: [bsz, n_passages]", "\n", "priorities", "=", "self", ".", "weight", "*", "has_answer_logits", "+", "offset_logit", "# shape: [bsz, n_passages]", "\n", "\n", "return", "priorities", "# shape: [bsz, n_passages]", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.GatedMLPScheduler.__init__": [[176, 189], ["ac_scheduler.BaseScheduler.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "1.0", ")", ")", "\n", "\n", "embed_size", "=", "config", ".", "scheduler_embed_size", "\n", "self", ".", "layer_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "num_layers", "+", "1", ",", "embed_size", ")", "\n", "self", ".", "rank_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "scheduler_n_context", ",", "embed_size", ")", "\n", "\n", "# MLP", "\n", "hidden_size", "=", "config", ".", "scheduler_hidden_size", "\n", "self", ".", "dense0", "=", "nn", ".", "Linear", "(", "embed_size", "*", "2", "+", "1", ",", "hidden_size", ")", "\n", "self", ".", "act_fn", "=", "F", ".", "relu", "\n", "self", ".", "dense1", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "2", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.GatedMLPScheduler.forward": [[190, 214], ["ac_scheduler.GatedMLPScheduler.layer_embeddings", "ac_scheduler.GatedMLPScheduler.rank_embeddings", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ac_scheduler.GatedMLPScheduler.dense1", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "ac_scheduler.GatedMLPScheduler.act_fn", "has_answer_logits.unsqueeze", "ac_scheduler.GatedMLPScheduler.dense0"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "has_answer_logits", ",", "layers", ",", "ranks", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            has_answer_logits (Tensor): float Tensor with shape [bsz, n_passages]\n            layers (Tensor): int Tensor with shape [bsz, n_passages]\n            ranks (Tensor): int Tensor with shape [bsz, n_passages]\n\n        Returns:\n            priorities (Tensor): float Tensor with shape [bsz, n_passages]\n        \"\"\"", "\n", "\n", "layer_emb", "=", "self", ".", "layer_embeddings", "(", "layers", ")", "# shape: [bsz, n_passages, embed_size]", "\n", "rank_emb", "=", "self", ".", "rank_embeddings", "(", "ranks", ")", "# shape: [bsz, n_passages, embed_size]", "\n", "\n", "mlp_input", "=", "torch", ".", "cat", "(", "\n", "(", "has_answer_logits", ".", "unsqueeze", "(", "-", "1", ")", ",", "layer_emb", ",", "rank_emb", ")", ",", "-", "1", "\n", ")", "# shape: [bsz, n_passages, embed_size * 2 + 1]", "\n", "mlp_output", "=", "self", ".", "dense1", "(", "self", ".", "act_fn", "(", "self", ".", "dense0", "(", "mlp_input", ")", ")", ")", "# shape: [bsz, n_passages, 2]", "\n", "\n", "offset_logit", ",", "gate_logit", "=", "torch", ".", "unbind", "(", "mlp_output", ",", "dim", "=", "-", "1", ")", "\n", "gate", "=", "torch", ".", "sigmoid", "(", "gate_logit", ")", "# shape: [bsz, n_passages]", "\n", "priorities", "=", "self", ".", "weight", "*", "gate", "*", "has_answer_logits", "+", "offset_logit", "# shape: [bsz, n_passages]", "\n", "\n", "return", "priorities", "# shape: [bsz, n_passages]", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.GatedMLPSchedulerWithPosition.__init__": [[219, 232], ["ac_scheduler.GatedMLPScheduler.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "1.0", ")", ")", "\n", "\n", "embed_size", "=", "config", ".", "scheduler_embed_size", "\n", "self", ".", "layer_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "num_layers", "+", "1", ",", "embed_size", ")", "\n", "self", ".", "rank_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "scheduler_n_context", ",", "embed_size", ")", "\n", "\n", "# MLP", "\n", "hidden_size", "=", "config", ".", "scheduler_hidden_size", "\n", "self", ".", "dense0", "=", "nn", ".", "Linear", "(", "embed_size", "*", "2", "+", "4", ",", "hidden_size", ")", "\n", "self", ".", "act_fn", "=", "F", ".", "relu", "\n", "self", ".", "dense1", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "2", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.GatedMLPSchedulerWithPosition.forward": [[233, 262], ["ac_scheduler.GatedMLPSchedulerWithPosition.layer_embeddings", "ac_scheduler.GatedMLPSchedulerWithPosition.rank_embeddings", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ac_scheduler.GatedMLPSchedulerWithPosition.dense1", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "ac_scheduler.GatedMLPSchedulerWithPosition.act_fn", "has_answer_logits.unsqueeze", "ac_scheduler.GatedMLPSchedulerWithPosition.dense0", "layers.float", "ranks.float"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "has_answer_logits", ",", "layers", ",", "ranks", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            has_answer_logits (Tensor): float Tensor with shape [bsz, n_passages]\n            layers (Tensor): int Tensor with shape [bsz, n_passages]\n            ranks (Tensor): int Tensor with shape [bsz, n_passages]\n\n        Returns:\n            priorities (Tensor): float Tensor with shape [bsz, n_passages]\n        \"\"\"", "\n", "\n", "layer_emb", "=", "self", ".", "layer_embeddings", "(", "layers", ")", "# shape: [bsz, n_passages, embed_size]", "\n", "rank_emb", "=", "self", ".", "rank_embeddings", "(", "ranks", ")", "# shape: [bsz, n_passages, embed_size]", "\n", "\n", "# Additional features", "\n", "layers_feat", "=", "(", "layers", ".", "float", "(", ")", "/", "self", ".", "config", ".", "num_layers", ")", ".", "unsqueeze", "(", "-", "1", ")", "# shape: [bsz, n_passages, 1]", "\n", "ranks_feat", "=", "(", "ranks", ".", "float", "(", ")", "/", "self", ".", "config", ".", "scheduler_n_context", ")", ".", "unsqueeze", "(", "-", "1", ")", "# shape: [bsz, n_passages, 1]", "\n", "\n", "mlp_input", "=", "torch", ".", "cat", "(", "\n", "(", "has_answer_logits", ".", "unsqueeze", "(", "-", "1", ")", ",", "layers_feat", ",", "ranks_feat", ",", "layers_feat", "+", "ranks_feat", ",", "\n", "layer_emb", ",", "rank_emb", ")", ",", "-", "1", "\n", ")", "# shape: [bsz, n_passages, embed_size * 2 + 1]", "\n", "mlp_output", "=", "self", ".", "dense1", "(", "self", ".", "act_fn", "(", "self", ".", "dense0", "(", "mlp_input", ")", ")", ")", "# shape: [bsz, n_passages, 2]", "\n", "\n", "offset_logit", ",", "gate_logit", "=", "torch", ".", "unbind", "(", "mlp_output", ",", "dim", "=", "-", "1", ")", "\n", "gate", "=", "torch", ".", "sigmoid", "(", "gate_logit", ")", "# shape: [bsz, n_passages]", "\n", "priorities", "=", "self", ".", "weight", "*", "gate", "*", "has_answer_logits", "+", "offset_logit", "# shape: [bsz, n_passages]", "\n", "\n", "return", "priorities", "# shape: [bsz, n_passages]", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.get_scheduler": [[274, 284], ["hasattr", "KeyError"], "function", ["None"], ["def", "get_scheduler", "(", "config", ")", ":", "\n", "    ", "\"\"\"Construct a scheduler from the config (default: None)\"\"\"", "\n", "if", "hasattr", "(", "config", ",", "\"scheduler_type\"", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "scheduler", "=", "SchedulerMapping", "[", "config", ".", "scheduler_type", "]", "(", "config", ")", "\n", "", "except", "KeyError", ":", "\n", "            ", "raise", "KeyError", "(", "f\"Invalid scheduler_type: {config.scheduler_type}\"", ")", "\n", "", "", "else", ":", "\n", "        ", "scheduler", "=", "None", "\n", "", "return", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.run_ac_scheduler": [[286, 366], ["torch.ones", "torch.ones", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "skyline.scatter_", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "ValueError", "torch.ones", "torch.ones", "ac_scheduler.act", "all_actions.append", "all_log_probs.append", "enumerate", "skyline.argsort", "torch.cat", "torch.cat", "retained_hidden_states.append", "torch.cat", "torch.cat", "retained_attention_masks.append", "skyline[].item", "ValueError", "range", "range"], "function", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.BaseScheduler.act"], ["", "def", "run_ac_scheduler", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "has_answer_outputs", ",", "\n", "ac_scheduler", ":", "BaseScheduler", ",", "\n", "budget", ":", "int", ",", "\n", "num_passages_retained", ":", "int", ",", "\n", "is_training", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n\n    Args:\n        hidden_states (torch.Tensor): float Tensor with shape [bsz (B), n_passages (N), plen (L), d_model (D)]\n        attention_mask (torch.Tensor): float Tensor with shape [B, N, L]\n        has_answer_outputs (torch.Tensor): float Tensor with shape [B, N, num_layers]\n        ac_scheduler (BaseScheduler):\n        budget (int):\n        num_passages_retained (int):\n        is_training (bool):\n\n    Returns:\n\n    \"\"\"", "\n", "bsz", ",", "n_passages", ",", "plen", ",", "_", "=", "hidden_states", ".", "shape", "\n", "num_layers", "=", "has_answer_outputs", ".", "shape", "[", "2", "]", "\n", "if", "budget", ">", "num_layers", "*", "n_passages", ":", "\n", "        ", "raise", "ValueError", "(", "f\"budget={budget} should be small than num_layers * n_passages={num_layers * n_passages}\"", ")", "\n", "", "device", "=", "hidden_states", ".", "device", "\n", "\n", "# Run the AC prioritization algorithm", "\n", "all_actions", ",", "all_log_probs", "=", "[", "]", ",", "[", "]", "\n", "skyline", "=", "-", "torch", ".", "ones", "(", "(", "bsz", ",", "n_passages", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "# -1 indicates the initial state", "\n", "tower_masks", "=", "torch", ".", "ones", "(", "(", "bsz", ",", "n_passages", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "# 1.->active, 0.->inactive", "\n", "for", "step", "in", "range", "(", "budget", ")", ":", "\n", "        ", "actions", ",", "action_log_probs", "=", "ac_scheduler", ".", "act", "(", "\n", "has_answer_outputs", ",", "\n", "skyline", ",", "\n", "masks", "=", "tower_masks", ",", "\n", "greedy", "=", "not", "is_training", "\n", ")", "# shape: [bsz], [bsz]", "\n", "all_actions", ".", "append", "(", "actions", ")", "\n", "all_log_probs", ".", "append", "(", "action_log_probs", ")", "\n", "\n", "# Update the selected towers in the skyline", "\n", "for", "i", ",", "action", "in", "enumerate", "(", "actions", ")", ":", "\n", "            ", "new_layer", "=", "skyline", "[", "i", ",", "action", "]", ".", "item", "(", ")", "+", "1", "# increment the layer", "\n", "if", "new_layer", "<", "num_layers", "-", "1", ":", "\n", "                ", "skyline", "[", "i", ",", "action", "]", "=", "new_layer", "\n", "", "elif", "new_layer", "==", "num_layers", "-", "1", ":", "# reaches the last layer", "\n", "                ", "skyline", "[", "i", ",", "action", "]", "=", "new_layer", "\n", "tower_masks", "[", "i", ",", "action", "]", "=", "0.", "# mask the tower to avoid choosing it again.", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Selected the tower that is at maximum height.\"", ")", "\n", "\n", "", "", "", "actions", "=", "torch", ".", "stack", "(", "all_actions", ",", "1", ")", "# shape: [bsz, budget]", "\n", "log_probs", "=", "torch", ".", "stack", "(", "all_log_probs", ",", "1", ")", "# shape: [bsz, budget]", "\n", "\n", "# Find the highest <num_passages_retained> towers (passages), shape: [bsz, num_passages_retained]", "\n", "retained_passages", "=", "skyline", ".", "argsort", "(", "dim", "=", "1", ",", "descending", "=", "True", ")", "[", ":", ",", ":", "num_passages_retained", "]", "\n", "\n", "# Update the skyline: forward the highest towers to their last layer", "\n", "skyline", ".", "scatter_", "(", "1", ",", "retained_passages", ",", "num_layers", "-", "1", ")", "# shape: [bsz, n_passages]", "\n", "\n", "# Acquire the hidden_states and attention_masks for the retained passages", "\n", "retained_hidden_states", ",", "retained_attention_masks", "=", "[", "]", ",", "[", "]", "\n", "for", "bi", "in", "range", "(", "bsz", ")", ":", "\n", "# TODO (jimmycode): find a more efficient implementation for this indexing operation", "\n", "        ", "cur_retained_hidden_states", "=", "torch", ".", "cat", "(", "\n", "[", "hidden_states", "[", "bi", ",", "retained_passages", "[", "bi", ",", "pj", "]", "]", "for", "pj", "in", "range", "(", "num_passages_retained", ")", "]", ",", "0", "\n", ")", "# shape: [num_passages_retained * p_len, d_model]", "\n", "retained_hidden_states", ".", "append", "(", "cur_retained_hidden_states", ")", "\n", "\n", "cur_retained_attention_masks", "=", "torch", ".", "cat", "(", "\n", "[", "attention_mask", "[", "bi", ",", "retained_passages", "[", "bi", ",", "pj", "]", "]", "for", "pj", "in", "range", "(", "num_passages_retained", ")", "]", ",", "0", "\n", ")", "# shape: [num_passages_retained * p_len]", "\n", "retained_attention_masks", ".", "append", "(", "cur_retained_attention_masks", ")", "\n", "", "hidden_states", "=", "torch", ".", "stack", "(", "retained_hidden_states", ",", "0", ")", "# shape: [bsz, num_passages_retained * p_len, d_model]", "\n", "attention_mask", "=", "torch", ".", "stack", "(", "retained_attention_masks", ",", "0", ")", "# shape: [bsz, num_passages_retained * p_len]", "\n", "\n", "return", "hidden_states", ",", "attention_mask", ",", "(", "actions", ",", "log_probs", ",", "skyline", ",", "retained_passages", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.ac_scheduler.compute_REINFORCE_loss": [[368, 387], ["torch.gather", "torch.gather", "immediate_rewards.flip().unbind", "torch.stack().flip", "torch.stack().flip", "torch.mean", "torch.mean", "all_returns.append", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "immediate_rewards.flip", "torch.stack", "torch.stack"], "function", ["None"], ["", "def", "compute_REINFORCE_loss", "(", "has_answer_labels", ",", "actions", ",", "log_probs", ",", "step_cost", ",", "discount", "=", "1.0", ")", ":", "\n", "    ", "\"\"\" Compute the REINFORCE loss: 1) evaluate rewards and returns 2) compute the loss \"\"\"", "\n", "action_labels", "=", "torch", ".", "gather", "(", "has_answer_labels", ",", "1", ",", "actions", ")", "# shape: [bsz, budget]", "\n", "immediate_rewards", "=", "action_labels", "-", "step_cost", "# shape: [bsz, budget]", "\n", "\n", "# Calculate return values", "\n", "# return_values = immediate_rewards.flip(1).cumsum(1).flip(1)  # shape: [bsz, budget]", "\n", "all_imd_rewards", "=", "immediate_rewards", ".", "flip", "(", "1", ")", ".", "unbind", "(", "1", ")", "\n", "all_returns", ",", "acc", "=", "[", "]", ",", "None", "\n", "for", "ir", "in", "all_imd_rewards", ":", "\n", "        ", "cur_return", "=", "ir", "if", "acc", "is", "None", "else", "ir", "+", "acc", "*", "discount", "# shape: [bsz]", "\n", "all_returns", ".", "append", "(", "cur_return", ")", "\n", "acc", "=", "cur_return", "\n", "", "return_values", "=", "torch", ".", "stack", "(", "all_returns", ",", "1", ")", ".", "flip", "(", "1", ")", "# shape: [bsz, budget]", "\n", "\n", "loss", "=", "-", "torch", ".", "sum", "(", "log_probs", "*", "return_values", ")", "# add negative to maximize", "\n", "sum_reward", "=", "torch", ".", "mean", "(", "torch", ".", "sum", "(", "immediate_rewards", ",", "1", ")", ")", "# the sum of all immediate rewards (for logging)", "\n", "\n", "return", "loss", ",", "sum_reward", "\n", "", ""]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.WarmupLinearScheduler.__init__": [[79, 88], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "optimizer", ",", "warmup_steps", ",", "t_total", ",", "min_ratio", ",", "fixed_lr", ",", "last_epoch", "=", "-", "1", "\n", ")", ":", "\n", "        ", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "self", ".", "t_total", "=", "t_total", "\n", "self", ".", "min_ratio", "=", "min_ratio", "\n", "self", ".", "fixed_lr", "=", "fixed_lr", "\n", "super", "(", "WarmupLinearScheduler", ",", "self", ")", ".", "__init__", "(", "\n", "optimizer", ",", "self", ".", "lr_lambda", ",", "last_epoch", "=", "last_epoch", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.WarmupLinearScheduler.lr_lambda": [[90, 105], ["max", "float", "float", "float", "float", "max", "max"], "methods", ["None"], ["", "def", "lr_lambda", "(", "self", ",", "step", ")", ":", "\n", "        ", "if", "step", "<", "self", ".", "warmup_steps", ":", "\n", "            ", "return", "(", "1", "-", "self", ".", "min_ratio", ")", "*", "float", "(", "step", ")", "/", "float", "(", "\n", "max", "(", "1", ",", "self", ".", "warmup_steps", ")", "\n", ")", "+", "self", ".", "min_ratio", "\n", "", "return", "1.0", "\n", "\n", "if", "self", ".", "fixed_lr", ":", "\n", "            ", "return", "1.0", "\n", "\n", "", "return", "max", "(", "\n", "0.0", ",", "\n", "1.0", "\n", "+", "float", "(", "(", "self", ".", "min_ratio", "-", "1", ")", "*", "(", "step", "-", "self", ".", "warmup_steps", ")", ")", "\n", "/", "float", "(", "max", "(", "1.0", ",", "self", ".", "t_total", "-", "self", ".", "warmup_steps", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.FixedScheduler.__init__": [[109, 111], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "optimizer", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "        ", "super", "(", "FixedScheduler", ",", "self", ")", ".", "__init__", "(", "optimizer", ",", "self", ".", "lr_lambda", ",", "last_epoch", "=", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.FixedScheduler.lr_lambda": [[112, 114], ["None"], "methods", ["None"], ["", "def", "lr_lambda", "(", "self", ",", "step", ")", ":", "\n", "        ", "return", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.copy_dir": [[11, 17], ["os.path.exists", "shutil.copytree", "os.path.isdir", "shutil.rmtree"], "function", ["None"], ["def", "copy_dir", "(", "source", ",", "target", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "target", ")", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isdir", "(", "target", ")", "\n", "shutil", ".", "rmtree", "(", "target", ")", "\n", "\n", "", "shutil", ".", "copytree", "(", "source", ",", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.save": [[19, 38], ["os.path.join", "os.path.join", "os.makedirs", "model.save_pretrained", "os.path.join", "torch.save", "torch.save", "os.path.join", "util.copy_dir", "optimizer.state_dict", "scheduler.state_dict"], "function", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.save", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.save", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.copy_dir"], ["", "def", "save", "(", "model", ",", "optimizer", ",", "scheduler", ",", "step", ",", "best_dev_em", ",", "opt", ",", "dir_path", ",", "name", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "\"checkpoint\"", ")", "\n", "epoch_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", "# \"step-%s\" % step)", "\n", "os", ".", "makedirs", "(", "epoch_path", ",", "exist_ok", "=", "True", ")", "\n", "model", ".", "save_pretrained", "(", "epoch_path", ")", "\n", "\n", "# Save optimizer states", "\n", "fp", "=", "os", ".", "path", ".", "join", "(", "epoch_path", ",", "\"optimizer.pth.tar\"", ")", "\n", "checkpoint", "=", "{", "\n", "\"step\"", ":", "step", ",", "\n", "\"optimizer\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "\"scheduler\"", ":", "scheduler", ".", "state_dict", "(", ")", ",", "\n", "\"opt\"", ":", "opt", ",", "\n", "\"best_dev_em\"", ":", "best_dev_em", ",", "\n", "}", "\n", "torch", ".", "save", "(", "checkpoint", ",", "fp", ")", "\n", "\n", "latest_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"latest\"", ")", "\n", "copy_dir", "(", "epoch_path", ",", "latest_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.restore_epoch": [[40, 62], ["os.path.join", "os.path.realpath", "os.path.join", "logger.info", "model_class.from_pretrained", "logger.info", "torch.load", "torch.load", "model.to.to", "util.set_optim", "scheduler.load_state_dict", "optimizer.load_state_dict", "util.set_optim", "str"], "function", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.set_optim", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.set_optim"], ["", "def", "restore_epoch", "(", "model_class", ",", "dir_path", ",", "opt", ",", "name", ",", "reset_params", "=", "False", ")", ":", "\n", "    ", "epoch_path", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "\"checkpoint\"", ",", "name", ")", "# str(epoch))", "\n", "epoch_path", "=", "os", ".", "path", ".", "realpath", "(", "epoch_path", ")", "\n", "optimizer_path", "=", "os", ".", "path", ".", "join", "(", "epoch_path", ",", "\"optimizer.pth.tar\"", ")", "\n", "logger", ".", "info", "(", "\"Loading %s\"", "%", "epoch_path", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "epoch_path", ")", "# , map_location=\"cuda:\"+str(opt.local_rank))", "\n", "logger", ".", "info", "(", "\"loading checkpoint %s\"", "%", "optimizer_path", ")", "\n", "\n", "local_rank", "=", "0", "if", "opt", ".", "local_rank", "==", "-", "1", "else", "opt", ".", "local_rank", "\n", "checkpoint", "=", "torch", ".", "load", "(", "optimizer_path", ",", "map_location", "=", "\"cuda:\"", "+", "str", "(", "local_rank", ")", ")", "\n", "opt_checkpoint", "=", "checkpoint", "[", "\"opt\"", "]", "\n", "step", "=", "checkpoint", "[", "\"step\"", "]", "\n", "best_dev_em", "=", "checkpoint", "[", "\"best_dev_em\"", "]", "\n", "if", "not", "reset_params", ":", "\n", "        ", "optimizer", ",", "scheduler", "=", "set_optim", "(", "opt_checkpoint", ",", "model", ")", "\n", "scheduler", ".", "load_state_dict", "(", "checkpoint", "[", "\"scheduler\"", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "\"optimizer\"", "]", ")", "\n", "", "else", ":", "\n", "        ", "optimizer", ",", "scheduler", "=", "set_optim", "(", "opt", ",", "model", ")", "\n", "\n", "", "model", "=", "model", ".", "to", "(", "local_rank", ")", "\n", "return", "model", ",", "optimizer", ",", "scheduler", ",", "opt_checkpoint", ",", "step", ",", "best_dev_em", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.load_model": [[64, 73], ["logger.info", "model_class.from_pretrained", "model.to.to", "util.set_optim"], "function", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.set_optim"], ["", "def", "load_model", "(", "model_class", ",", "model_path", ",", "opt", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"Loading %s\"", "%", "model_path", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "model_path", ")", "# , map_location=\"cuda:\"+str(opt.local_rank))", "\n", "\n", "local_rank", "=", "0", "if", "opt", ".", "local_rank", "==", "-", "1", "else", "opt", ".", "local_rank", "\n", "model", "=", "model", ".", "to", "(", "local_rank", ")", "\n", "optimizer", ",", "scheduler", "=", "set_optim", "(", "opt", ",", "model", ")", "\n", "\n", "return", "model", ",", "optimizer", ",", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.clip_gradients": [[116, 121], ["list", "filter", "model.parameters", "p.grad.data.mul_", "p.grad.data.norm"], "function", ["None"], ["", "", "def", "clip_gradients", "(", "model", ",", "clip", ")", ":", "\n", "    ", "for", "p", "in", "list", "(", "filter", "(", "lambda", "p", ":", "p", ".", "grad", "is", "not", "None", ",", "model", ".", "parameters", "(", ")", ")", ")", ":", "\n", "        ", "clip_coef", "=", "clip", "/", "(", "p", ".", "grad", ".", "data", ".", "norm", "(", "2", ")", "+", "1e-6", ")", "\n", "if", "clip_coef", "<", "1", ":", "\n", "            ", "p", ".", "grad", ".", "data", ".", "mul_", "(", "clip_coef", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.set_optim": [[147, 151], ["torch.optim.Adam", "torch.optim.Adam", "util.FixedScheduler", "model.parameters"], "function", ["None"], ["", "", "", "def", "set_optim", "(", "opt", ",", "model", ")", ":", "\n", "    ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "opt", ".", "lr", ")", "\n", "scheduler", "=", "FixedScheduler", "(", "optimizer", ")", "\n", "return", "optimizer", ",", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util._get_grad_requiring_params": [[153, 161], ["model.parameters", "param.numel", "grad_requiring_params.append"], "function", ["None"], ["", "def", "_get_grad_requiring_params", "(", "model", ")", ":", "\n", "    ", "nb_parameters", "=", "0", "\n", "grad_requiring_params", "=", "[", "]", "\n", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "if", "param", ".", "requires_grad", ":", "\n", "            ", "nb_parameters", "+=", "param", ".", "numel", "(", ")", "\n", "grad_requiring_params", ".", "append", "(", "param", ")", "\n", "", "", "return", "grad_requiring_params", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.print_parameters": [[163, 177], ["os.path.join", "net.parameters", "print", "sys.stdout.flush", "param.numel", "print", "open", "log_file.write", "open", "log_file.write", "str"], "function", ["None"], ["", "def", "print_parameters", "(", "net", ",", "log_dir", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "file_name", "=", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"opt.txt\"", ")", "\n", "num_params", "=", "0", "\n", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "        ", "num_params", "+=", "param", ".", "numel", "(", ")", "\n", "", "message", "=", "\"[Network] Total number of parameters : %.6f M\"", "%", "(", "num_params", "/", "1e6", ")", "\n", "print", "(", "message", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "net", ")", "\n", "", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "with", "open", "(", "file_name", ",", "\"a\"", ")", "as", "log_file", ":", "\n", "        ", "log_file", ".", "write", "(", "message", "+", "\"\\n\"", ")", "\n", "with", "open", "(", "file_name", ",", "\"a\"", ")", "as", "log_file", ":", "\n", "            ", "log_file", ".", "write", "(", "str", "(", "net", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.average_master": [[179, 185], ["torch.reduce"], "function", ["None"], ["", "", "", "def", "average_master", "(", "x", ",", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "world_size", ">", "1", ":", "\n", "        ", "dist", ".", "reduce", "(", "x", ",", "0", ",", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", ")", "\n", "if", "opt", ".", "is_master", ":", "\n", "            ", "x", "=", "x", "/", "opt", ".", "world_size", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.sum_master": [[187, 191], ["torch.reduce"], "function", ["None"], ["", "def", "sum_master", "(", "x", ",", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "world_size", ">", "1", ":", "\n", "        ", "dist", ".", "reduce", "(", "x", ",", "0", ",", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.weighted_average": [[193, 200], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "util.sum_master", "util.sum_master", "sum_master.item", "str", "str"], "function", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.sum_master", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.sum_master"], ["", "def", "weighted_average", "(", "x", ",", "count", ",", "opt", ")", ":", "\n", "    ", "local_rank", "=", "0", "if", "opt", ".", "local_rank", "==", "-", "1", "else", "opt", ".", "local_rank", "\n", "t_loss", "=", "torch", ".", "tensor", "(", "[", "x", "*", "count", "]", ",", "device", "=", "\"cuda:\"", "+", "str", "(", "local_rank", ")", ")", "\n", "t_total", "=", "torch", ".", "tensor", "(", "[", "count", "]", ",", "device", "=", "\"cuda:\"", "+", "str", "(", "local_rank", ")", ")", "\n", "t_loss", "=", "sum_master", "(", "t_loss", ",", "opt", ")", "\n", "t_total", "=", "sum_master", "(", "t_total", ",", "opt", ")", "\n", "return", "(", "t_loss", "/", "t_total", ")", ".", "item", "(", ")", ",", "t_total", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.write_output": [[202, 213], ["list", "list.sort", "glob_path.rmdir", "glob_path.glob", "open", "path.unlink", "open", "f.readlines", "outfile.write"], "function", ["None"], ["", "def", "write_output", "(", "glob_path", ",", "output_path", ")", ":", "\n", "    ", "files", "=", "list", "(", "glob_path", ".", "glob", "(", "'*.txt'", ")", ")", "\n", "files", ".", "sort", "(", ")", "\n", "with", "open", "(", "output_path", ",", "'w'", ")", "as", "outfile", ":", "\n", "        ", "for", "path", "in", "files", ":", "\n", "            ", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "                    ", "outfile", ".", "write", "(", "line", ")", "\n", "", "", "path", ".", "unlink", "(", ")", "\n", "", "", "glob_path", ".", "rmdir", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.test_ac_scheduler.evaluate": [[20, 82], ["model.eval", "hasattr", "logger.warning", "util.weighted_average", "logger.info", "logger.info", "numpy.mean", "logger.info", "os.path.join", "open", "torch.no_grad", "torch.no_grad", "enumerate", "torch.distributed.barrier", "torch.distributed.barrier", "numpy.mean", "open", "f.write", "os.path.join", "context_ids.cuda().view.size", "context_ids.cuda().view.cuda().view", "context_mask.cuda().view.cuda().view", "model.generate", "enumerate", "os.path.join", "context_ids.cuda().view.size", "context_ids.cuda().view.size", "tokenizer.decode", "dataset.get_example", "evaluation.ems", "ems.append", "all_layer_cost.append", "logger.warning", "numpy.mean", "context_ids.cuda().view.cuda", "context_mask.cuda().view.cuda", "open.write", "c.item", "len", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.util.weighted_average", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5_ac.ACFiDT5.generate", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.data.Dataset.get_example", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.ems"], ["def", "evaluate", "(", "model", ",", "dataset", ",", "dataloader", ",", "tokenizer", ",", "opt", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "if", "hasattr", "(", "model", ",", "\"module\"", ")", ":", "\n", "        ", "model", "=", "model", ".", "module", "\n", "\n", "", "total", "=", "0", "\n", "ems", "=", "[", "]", "\n", "all_layer_cost", "=", "[", "]", "\n", "\n", "fw", "=", "None", "\n", "if", "opt", ".", "write_results", ":", "\n", "        ", "write_path", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_dir", ",", "opt", ".", "name", ",", "'test_results'", ")", "\n", "fw", "=", "open", "(", "os", ".", "path", ".", "join", "(", "write_path", ",", "'%d.txt'", "%", "opt", ".", "global_rank", ")", ",", "'w'", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "            ", "idx", ",", "answer_ids", ",", "answer_mask", ",", "context_ids", ",", "context_mask", ",", "has_answer_labels", "=", "batch", "\n", "model", ".", "encoder", ".", "n_passages", "=", "context_ids", ".", "size", "(", "1", ")", "\n", "context_ids", "=", "context_ids", ".", "cuda", "(", ")", ".", "view", "(", "context_ids", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "context_mask", "=", "context_mask", ".", "cuda", "(", ")", ".", "view", "(", "context_ids", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "outputs", ",", "layer_cost", "=", "model", ".", "generate", "(", "\n", "input_ids", "=", "context_ids", ",", "\n", "attention_mask", "=", "context_mask", ",", "\n", "max_length", "=", "50", ",", "\n", ")", "\n", "\n", "for", "k", ",", "o", "in", "enumerate", "(", "outputs", ")", ":", "\n", "                ", "ans", "=", "tokenizer", ".", "decode", "(", "o", ",", "skip_special_tokens", "=", "True", ")", "\n", "example", "=", "dataset", ".", "get_example", "(", "idx", "[", "k", "]", ")", "\n", "question", "=", "example", ".", "question", "\n", "gold", "=", "example", ".", "answers", "\n", "id", "=", "example", ".", "id", "\n", "ems_score", "=", "evaluation", ".", "ems", "(", "ans", ",", "gold", ")", "\n", "ems", ".", "append", "(", "ems_score", ")", "\n", "\n", "if", "fw", "is", "not", "None", ":", "\n", "                    ", "fw", ".", "write", "(", "f\"{id}\\t{question}\\t{ans}\\n\"", ")", "\n", "\n", "", "total", "+=", "1", "\n", "\n", "", "for", "c", "in", "layer_cost", ":", "\n", "                ", "all_layer_cost", ".", "append", "(", "c", ".", "item", "(", ")", ")", "\n", "\n", "", "if", "(", "i", "+", "1", ")", "%", "opt", ".", "eval_print_freq", "==", "0", ":", "\n", "                ", "logger", ".", "warning", "(", "f\"{opt.global_rank}, {i + 1} / {len(dataloader)} -- average = {np.mean(ems):.3f}\"", ")", "\n", "\n", "", "", "", "logger", ".", "warning", "(", "f\"{opt.global_rank}, total {total} -- average = {np.mean(ems):.3f}\"", ")", "\n", "if", "opt", ".", "world_size", ">", "1", "and", "not", "opt", ".", "local_rank", "==", "-", "1", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "", "score", ",", "total", "=", "util", ".", "weighted_average", "(", "np", ".", "mean", "(", "ems", ")", ",", "total", ",", "opt", ")", "\n", "logger", ".", "info", "(", "'total number of example %d'", "%", "total", ")", "\n", "logger", ".", "info", "(", "f\"average EM = {score:.5f}\"", ")", "\n", "avg_layer_cost", "=", "np", ".", "mean", "(", "all_layer_cost", ")", "\n", "logger", ".", "info", "(", "f\"average layer cost = {avg_layer_cost:.3f}\"", ")", "\n", "\n", "# write result", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_dir", ",", "\"all_results\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "f\"budget = {opt.budget}, num_passages_retained = {opt.num_passages_retained}, \"", "\n", "f\"layer cost = {avg_layer_cost}, EM = {score}\\n\"", ")", "\n", "\n", "", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.test_retrieval_acc.evaluate": [[24, 79], ["model.eval", "hasattr", "numpy.mean", "logger.info", "logger.info", "torch.no_grad", "torch.no_grad", "enumerate", "open", "f.write", "context_ids.cuda().view.size", "context_ids.cuda().view.cuda().view", "context_mask.cuda().view.cuda().view", "model", "enumerate", "len", "os.path.join", "answer_ids.cuda", "answer_mask.bool().cuda", "context_ids.cuda().view.size", "context_ids.cuda().view.size", "dataset.get_example", "enumerate", "all_accuracies.append", "context_ids.cuda().view.cuda", "context_mask.cuda().view.cuda", "rank.item.item", "evaluation.has_answer", "answer_mask.bool"], "function", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.data.Dataset.get_example", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.has_answer"], ["def", "evaluate", "(", "model", ",", "dataset", ",", "dataloader", ",", "tokenizer", ",", "opt", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "if", "hasattr", "(", "model", ",", "\"module\"", ")", ":", "\n", "        ", "model", "=", "model", ".", "module", "\n", "\n", "", "all_accuracies", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "            ", "idx", ",", "answer_ids", ",", "answer_mask", ",", "context_ids", ",", "context_mask", ",", "has_answer_labels", "=", "batch", "\n", "model", ".", "encoder", ".", "n_passages", "=", "context_ids", ".", "size", "(", "1", ")", "\n", "answer_ids", ",", "answer_mask", "=", "answer_ids", ".", "cuda", "(", ")", ",", "answer_mask", ".", "bool", "(", ")", ".", "cuda", "(", ")", "\n", "context_ids", "=", "context_ids", ".", "cuda", "(", ")", ".", "view", "(", "context_ids", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "context_mask", "=", "context_mask", ".", "cuda", "(", ")", ".", "view", "(", "context_ids", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "decoder_input_ids", "=", "None", "\n", "has_answer_labels", "=", "None", "\n", "# labels = answer_ids.masked_fill(~answer_mask, -100)", "\n", "labels", "=", "None", "\n", "\n", "inputs", "=", "{", "\n", "'input_ids'", ":", "context_ids", ",", "\n", "'attention_mask'", ":", "context_mask", ",", "\n", "'decoder_attention_mask'", ":", "answer_mask", ",", "\n", "'decoder_input_ids'", ":", "decoder_input_ids", ",", "\n", "'labels'", ":", "labels", ",", "\n", "'has_answer_labels'", ":", "has_answer_labels", ",", "\n", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "scheduler_outputs", "=", "outputs", "[", "-", "2", "]", "\n", "actions", ",", "log_probs", ",", "all_skylines", ",", "retained_passages", "=", "scheduler_outputs", "\n", "\n", "# retained_passages: [bsz, num_passages_retained]", "\n", "for", "j", ",", "psg_ranks", "in", "enumerate", "(", "retained_passages", ")", ":", "\n", "                ", "answer_acc", "=", "0", "# 1 if the selected top-k passages contain the answer, 0 otherwise", "\n", "example", "=", "dataset", ".", "get_example", "(", "idx", "[", "j", "]", ")", "\n", "answers", "=", "example", ".", "answers", "\n", "for", "k", ",", "rank", "in", "enumerate", "(", "psg_ranks", ")", ":", "\n", "                    ", "rank", "=", "rank", ".", "item", "(", ")", "\n", "context", "=", "example", ".", "contexts", "[", "rank", "]", "\n", "if", "has_answer", "(", "answers", ",", "context", ",", "simple_tokenizer", ")", ":", "\n", "                        ", "answer_acc", "=", "1", "\n", "break", "\n", "", "", "all_accuracies", ".", "append", "(", "answer_acc", ")", "\n", "\n", "", "", "", "accuracy", "=", "np", ".", "mean", "(", "all_accuracies", ")", "\n", "\n", "logger", ".", "info", "(", "'total number of example %d'", "%", "len", "(", "all_accuracies", ")", ")", "\n", "logger", ".", "info", "(", "f\"top-k retrieval accuracy = {accuracy:.5f}\"", ")", "\n", "\n", "# write result", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_dir", ",", "\"retrieval_acc\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "f\"budget = {opt.budget}, num_passages_retained = {opt.num_passages_retained}, \"", "\n", "f\"accuracy = {accuracy}\\n\"", ")", "\n", "\n", "", "return", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.t5blocks.T5LayerNorm.__init__": [[30, 37], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "eps", "=", "1e-6", ")", ":", "\n", "        ", "\"\"\" Construct a layernorm module in the T5 style\n            No bias and no substraction of mean.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "hidden_size", ")", ")", "\n", "self", ".", "variance_epsilon", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.t5blocks.T5LayerNorm.forward": [[38, 46], ["x.to.to.to().pow().mean", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "x.to.to.to", "x.to.to.to().pow", "x.to.to.to"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# layer norm should always be calculated in float32", "\n", "        ", "variance", "=", "x", ".", "to", "(", "torch", ".", "float32", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "x", "=", "x", "/", "torch", ".", "sqrt", "(", "variance", "+", "self", ".", "variance_epsilon", ")", "\n", "\n", "if", "self", ".", "weight", ".", "dtype", "==", "torch", ".", "float16", ":", "\n", "            ", "x", "=", "x", ".", "to", "(", "torch", ".", "float16", ")", "\n", "", "return", "self", ".", "weight", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.t5blocks.T5DenseReluDense.__init__": [[49, 54], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "wi", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "d_ff", ",", "bias", "=", "False", ")", "\n", "self", ".", "wo", "=", "nn", ".", "Linear", "(", "config", ".", "d_ff", ",", "config", ".", "d_model", ",", "bias", "=", "False", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.t5blocks.T5DenseReluDense.forward": [[55, 61], ["t5blocks.T5DenseReluDense.wi", "torch.relu", "torch.relu", "torch.relu", "t5blocks.T5DenseReluDense.dropout", "t5blocks.T5DenseReluDense.wo"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "h", "=", "self", ".", "wi", "(", "hidden_states", ")", "\n", "h", "=", "F", ".", "relu", "(", "h", ")", "\n", "h", "=", "self", ".", "dropout", "(", "h", ")", "\n", "h", "=", "self", ".", "wo", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.t5blocks.T5LayerFF.__init__": [[64, 69], ["torch.nn.Module.__init__", "t5blocks.T5DenseReluDense", "t5blocks.T5LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "DenseReluDense", "=", "T5DenseReluDense", "(", "config", ")", "\n", "self", ".", "layer_norm", "=", "T5LayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.t5blocks.T5LayerFF.forward": [[70, 75], ["t5blocks.T5LayerFF.layer_norm", "t5blocks.T5LayerFF.DenseReluDense", "t5blocks.T5LayerFF.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "norm_x", "=", "self", ".", "layer_norm", "(", "hidden_states", ")", "\n", "y", "=", "self", ".", "DenseReluDense", "(", "norm_x", ")", "\n", "layer_output", "=", "hidden_states", "+", "self", ".", "dropout", "(", "y", ")", "\n", "return", "layer_output", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.t5blocks.T5Attention.__init__": [[78, 99], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "set", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "has_relative_attention_bias", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "self", ".", "has_relative_attention_bias", "=", "has_relative_attention_bias", "\n", "\n", "self", ".", "relative_attention_num_buckets", "=", "config", ".", "relative_attention_num_buckets", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "d_kv", "=", "config", ".", "d_kv", "\n", "self", ".", "n_heads", "=", "config", ".", "num_heads", "\n", "self", ".", "dropout", "=", "config", ".", "dropout_rate", "\n", "self", ".", "inner_dim", "=", "self", ".", "n_heads", "*", "self", ".", "d_kv", "\n", "\n", "# Mesh TensorFlow initialization to avoid scaling before softmax", "\n", "self", ".", "q", "=", "nn", ".", "Linear", "(", "self", ".", "d_model", ",", "self", ".", "inner_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "k", "=", "nn", ".", "Linear", "(", "self", ".", "d_model", ",", "self", ".", "inner_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "v", "=", "nn", ".", "Linear", "(", "self", ".", "d_model", ",", "self", ".", "inner_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "o", "=", "nn", ".", "Linear", "(", "self", ".", "inner_dim", ",", "self", ".", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "if", "self", ".", "has_relative_attention_bias", ":", "\n", "            ", "self", ".", "relative_attention_bias", "=", "nn", ".", "Embedding", "(", "self", ".", "relative_attention_num_buckets", ",", "self", ".", "n_heads", ")", "\n", "", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.t5blocks.T5Attention.prune_heads": [[100, 113], ["find_pruneable_heads_and_indices", "prune_linear_layer", "prune_linear_layer", "prune_linear_layer", "prune_linear_layer", "t5blocks.T5Attention.pruned_heads.union", "len", "len"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "heads", ",", "index", "=", "find_pruneable_heads_and_indices", "(", "heads", ",", "self", ".", "n_heads", ",", "self", ".", "d_kv", ",", "self", ".", "pruned_heads", ")", "\n", "# Prune linear layers", "\n", "self", ".", "q", "=", "prune_linear_layer", "(", "self", ".", "q", ",", "index", ")", "\n", "self", ".", "k", "=", "prune_linear_layer", "(", "self", ".", "k", ",", "index", ")", "\n", "self", ".", "v", "=", "prune_linear_layer", "(", "self", ".", "v", ",", "index", ")", "\n", "self", ".", "o", "=", "prune_linear_layer", "(", "self", ".", "o", ",", "index", ",", "dim", "=", "1", ")", "\n", "# Update hyper params", "\n", "self", ".", "n_heads", "=", "self", ".", "n_heads", "-", "len", "(", "heads", ")", "\n", "self", ".", "inner_dim", "=", "self", ".", "d_kv", "*", "self", ".", "n_heads", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.t5blocks.T5Attention._relative_position_bucket": [[114, 160], ["torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "math.log", "torch.max.float", "torch.max.float", "torch.max.float"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_relative_position_bucket", "(", "relative_position", ",", "bidirectional", "=", "True", ",", "num_buckets", "=", "32", ",", "max_distance", "=", "128", ")", ":", "\n", "        ", "\"\"\"\n        Adapted from Mesh Tensorflow:\n        https://github.com/tensorflow/mesh/blob/0cb87fe07da627bf0b7e60475d59f95ed6b5be3d/mesh_tensorflow/transformer/transformer_layers.py#L593\n        Translate relative position to a bucket number for relative attention.\n        The relative position is defined as memory_position - query_position, i.e.\n        the distance in tokens from the attending position to the attended-to\n        position.  If bidirectional=False, then positive relative positions are\n        invalid.\n        We use smaller buckets for small absolute relative_position and larger buckets\n        for larger absolute relative_positions.  All relative positions >=max_distance\n        map to the same bucket.  All relative positions <=-max_distance map to the\n        same bucket.  This should allow for more graceful generalization to longer\n        sequences than the model has been trained on.\n        Args:\n            relative_position: an int32 Tensor\n            bidirectional: a boolean - whether the attention is bidirectional\n            num_buckets: an integer\n            max_distance: an integer\n        Returns:\n            a Tensor with the same shape as relative_position, containing int32\n            values in the range [0, num_buckets)\n        \"\"\"", "\n", "ret", "=", "0", "\n", "n", "=", "-", "relative_position", "\n", "if", "bidirectional", ":", "\n", "            ", "num_buckets", "//=", "2", "\n", "ret", "+=", "(", "n", "<", "0", ")", ".", "to", "(", "torch", ".", "long", ")", "*", "num_buckets", "# mtf.to_int32(mtf.less(n, 0)) * num_buckets", "\n", "n", "=", "torch", ".", "abs", "(", "n", ")", "\n", "", "else", ":", "\n", "            ", "n", "=", "torch", ".", "max", "(", "n", ",", "torch", ".", "zeros_like", "(", "n", ")", ")", "\n", "# now n is in the range [0, inf)", "\n", "\n", "# half of the buckets are for exact increments in positions", "\n", "", "max_exact", "=", "num_buckets", "//", "2", "\n", "is_small", "=", "n", "<", "max_exact", "\n", "\n", "# The other half of the buckets are for logarithmically bigger bins in positions up to max_distance", "\n", "val_if_large", "=", "max_exact", "+", "(", "\n", "torch", ".", "log", "(", "n", ".", "float", "(", ")", "/", "max_exact", ")", "/", "math", ".", "log", "(", "max_distance", "/", "max_exact", ")", "*", "(", "num_buckets", "-", "max_exact", ")", "\n", ")", ".", "to", "(", "torch", ".", "long", ")", "\n", "val_if_large", "=", "torch", ".", "min", "(", "val_if_large", ",", "torch", ".", "full_like", "(", "val_if_large", ",", "num_buckets", "-", "1", ")", ")", "\n", "\n", "ret", "+=", "torch", ".", "where", "(", "is_small", ",", "n", ",", "val_if_large", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.t5blocks.T5Attention.compute_bias": [[161, 175], ["t5blocks.T5Attention._relative_position_bucket", "rp_bucket.to.to.to", "t5blocks.T5Attention.relative_attention_bias", "values.permute().unsqueeze.permute().unsqueeze.permute().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "values.permute().unsqueeze.permute().unsqueeze.permute"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.t5blocks.T5Attention._relative_position_bucket"], ["", "def", "compute_bias", "(", "self", ",", "qlen", ",", "klen", ")", ":", "\n", "        ", "\"\"\" Compute binned relative position bias \"\"\"", "\n", "context_position", "=", "torch", ".", "arange", "(", "qlen", ",", "dtype", "=", "torch", ".", "long", ")", "[", ":", ",", "None", "]", "\n", "memory_position", "=", "torch", ".", "arange", "(", "klen", ",", "dtype", "=", "torch", ".", "long", ")", "[", "None", ",", ":", "]", "\n", "relative_position", "=", "memory_position", "-", "context_position", "# shape (qlen, klen)", "\n", "rp_bucket", "=", "self", ".", "_relative_position_bucket", "(", "\n", "relative_position", ",", "# shape (qlen, klen)", "\n", "bidirectional", "=", "not", "self", ".", "is_decoder", ",", "\n", "num_buckets", "=", "self", ".", "relative_attention_num_buckets", ",", "\n", ")", "\n", "rp_bucket", "=", "rp_bucket", ".", "to", "(", "self", ".", "relative_attention_bias", ".", "weight", ".", "device", ")", "\n", "values", "=", "self", ".", "relative_attention_bias", "(", "rp_bucket", ")", "# shape (qlen, klen, num_heads)", "\n", "values", "=", "values", ".", "permute", "(", "[", "2", ",", "0", ",", "1", "]", ")", ".", "unsqueeze", "(", "0", ")", "# shape (1, num_heads, qlen, klen)", "\n", "return", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.t5blocks.T5Attention.forward": [[176, 278], ["input.size", "t5blocks.T5Attention.forward.shape"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input", ",", "\n", "mask", "=", "None", ",", "\n", "kv", "=", "None", ",", "\n", "position_bias", "=", "None", ",", "\n", "past_key_value_state", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "query_length", "=", "None", ",", "\n", "use_cache", "=", "False", ",", "\n", "output_attentions", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Self-attention (if kv is None) or attention over source sentence (provided by kv).\n        \"\"\"", "\n", "# Input is (bs, qlen, dim)", "\n", "# Mask is (bs, klen) (non-causal) or (bs, klen, klen)", "\n", "# past_key_value_state[0] is (bs, n_heads, q_len - 1, dim_per_head)", "\n", "bs", ",", "qlen", ",", "dim", "=", "input", ".", "size", "(", ")", "\n", "\n", "if", "past_key_value_state", "is", "not", "None", ":", "\n", "            ", "assert", "self", ".", "is_decoder", "is", "True", ",", "\"Encoder cannot cache past key value states\"", "\n", "assert", "(", "\n", "len", "(", "past_key_value_state", ")", "==", "2", "\n", ")", ",", "\"past_key_value_state should have 2 past states: keys and values. Got {} past states\"", ".", "format", "(", "\n", "len", "(", "past_key_value_state", ")", "\n", ")", "\n", "real_qlen", "=", "qlen", "+", "past_key_value_state", "[", "0", "]", ".", "shape", "[", "2", "]", "if", "query_length", "is", "None", "else", "query_length", "\n", "", "else", ":", "\n", "            ", "real_qlen", "=", "qlen", "\n", "\n", "", "if", "kv", "is", "None", ":", "\n", "            ", "klen", "=", "real_qlen", "\n", "", "else", ":", "\n", "            ", "klen", "=", "kv", ".", "size", "(", "1", ")", "\n", "\n", "", "def", "shape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  projection \"\"\"", "\n", "return", "x", ".", "view", "(", "bs", ",", "-", "1", ",", "self", ".", "n_heads", ",", "self", ".", "d_kv", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "", "def", "unshape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  compute context \"\"\"", "\n", "return", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "bs", ",", "-", "1", ",", "self", ".", "inner_dim", ")", "\n", "\n", "", "q", "=", "shape", "(", "self", ".", "q", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "k", "=", "shape", "(", "self", ".", "k", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "v", "=", "shape", "(", "self", ".", "v", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "", "elif", "past_key_value_state", "is", "None", ":", "\n", "            ", "k", "=", "v", "=", "kv", "\n", "k", "=", "shape", "(", "self", ".", "k", "(", "k", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "v", "=", "shape", "(", "self", ".", "v", "(", "v", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "\n", "", "if", "past_key_value_state", "is", "not", "None", ":", "\n", "            ", "if", "kv", "is", "None", ":", "\n", "                ", "k_", ",", "v_", "=", "past_key_value_state", "\n", "k", "=", "torch", ".", "cat", "(", "[", "k_", ",", "k", "]", ",", "dim", "=", "2", ")", "# (bs, n_heads, klen, dim_per_head)", "\n", "v", "=", "torch", ".", "cat", "(", "[", "v_", ",", "v", "]", ",", "dim", "=", "2", ")", "# (bs, n_heads, klen, dim_per_head)", "\n", "", "else", ":", "\n", "                ", "k", ",", "v", "=", "past_key_value_state", "\n", "\n", "", "", "if", "self", ".", "is_decoder", "and", "use_cache", "is", "True", ":", "\n", "            ", "present_key_value_state", "=", "(", "(", "k", ",", "v", ")", ",", ")", "\n", "", "else", ":", "\n", "            ", "present_key_value_state", "=", "(", "None", ",", ")", "\n", "\n", "", "scores", "=", "torch", ".", "einsum", "(", "\"bnqd,bnkd->bnqk\"", ",", "q", ",", "k", ")", "# (bs, n_heads, qlen, klen)", "\n", "\n", "if", "position_bias", "is", "None", ":", "\n", "            ", "if", "not", "self", ".", "has_relative_attention_bias", ":", "\n", "                ", "raise", "ValueError", "(", "\"No position_bias provided and no weights to compute position_bias\"", ")", "\n", "", "position_bias", "=", "self", ".", "compute_bias", "(", "real_qlen", ",", "klen", ")", "\n", "\n", "# if key and values are already calculated", "\n", "# we want only the last query position bias", "\n", "if", "past_key_value_state", "is", "not", "None", ":", "\n", "                ", "position_bias", "=", "position_bias", "[", ":", ",", ":", ",", "-", "1", ":", ",", ":", "]", "\n", "\n", "", "if", "mask", "is", "not", "None", ":", "\n", "                ", "position_bias", "=", "position_bias", "+", "mask", "# (bs, n_heads, qlen, klen)", "\n", "\n", "", "", "scores", "+=", "position_bias", "\n", "weights", "=", "F", ".", "softmax", "(", "scores", ".", "float", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "type_as", "(", "scores", ")", "# (bs, n_heads, qlen, klen)", "\n", "weights", "=", "F", ".", "dropout", "(", "weights", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "# (bs, n_heads, qlen, klen)", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "weights", "=", "weights", "*", "head_mask", "\n", "\n", "", "context", "=", "torch", ".", "matmul", "(", "weights", ",", "v", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "context", "=", "unshape", "(", "context", ")", "# (bs, qlen, dim)", "\n", "\n", "context", "=", "self", ".", "o", "(", "context", ")", "\n", "\n", "outputs", "=", "(", "context", ",", ")", "+", "present_key_value_state", "\n", "\n", "if", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "weights", ",", ")", "\n", "", "if", "self", ".", "has_relative_attention_bias", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "position_bias", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.t5blocks.T5LayerSelfAttention.__init__": [[281, 286], ["torch.nn.Module.__init__", "t5blocks.T5Attention", "t5blocks.T5LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "has_relative_attention_bias", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "SelfAttention", "=", "T5Attention", "(", "config", ",", "has_relative_attention_bias", "=", "has_relative_attention_bias", ")", "\n", "self", ".", "layer_norm", "=", "T5LayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.t5blocks.T5LayerSelfAttention.forward": [[287, 311], ["t5blocks.T5LayerSelfAttention.layer_norm", "t5blocks.T5LayerSelfAttention.SelfAttention", "t5blocks.T5LayerSelfAttention.dropout"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "position_bias", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "past_key_value_state", "=", "None", ",", "\n", "use_cache", "=", "False", ",", "\n", "output_attentions", "=", "False", ",", "\n", ")", ":", "\n", "        ", "norm_x", "=", "self", ".", "layer_norm", "(", "hidden_states", ")", "\n", "attention_output", "=", "self", ".", "SelfAttention", "(", "\n", "norm_x", ",", "\n", "mask", "=", "attention_mask", ",", "\n", "position_bias", "=", "position_bias", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "past_key_value_state", "=", "past_key_value_state", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "y", "=", "attention_output", "[", "0", "]", "\n", "layer_output", "=", "hidden_states", "+", "self", ".", "dropout", "(", "y", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "attention_output", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.t5blocks.T5LayerCrossAttention.__init__": [[314, 319], ["torch.nn.Module.__init__", "t5blocks.T5Attention", "t5blocks.T5LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "has_relative_attention_bias", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "EncDecAttention", "=", "T5Attention", "(", "config", ",", "has_relative_attention_bias", "=", "has_relative_attention_bias", ")", "\n", "self", ".", "layer_norm", "=", "T5LayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.t5blocks.T5LayerCrossAttention.forward": [[320, 348], ["t5blocks.T5LayerCrossAttention.layer_norm", "t5blocks.T5LayerCrossAttention.EncDecAttention", "t5blocks.T5LayerCrossAttention.dropout"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "kv", ",", "\n", "attention_mask", "=", "None", ",", "\n", "position_bias", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "past_key_value_state", "=", "None", ",", "\n", "use_cache", "=", "False", ",", "\n", "query_length", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", ")", ":", "\n", "        ", "norm_x", "=", "self", ".", "layer_norm", "(", "hidden_states", ")", "\n", "attention_output", "=", "self", ".", "EncDecAttention", "(", "\n", "norm_x", ",", "\n", "mask", "=", "attention_mask", ",", "\n", "kv", "=", "kv", ",", "\n", "position_bias", "=", "position_bias", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "past_key_value_state", "=", "past_key_value_state", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "query_length", "=", "query_length", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "y", "=", "attention_output", "[", "0", "]", "\n", "layer_output", "=", "hidden_states", "+", "self", ".", "dropout", "(", "y", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "attention_output", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.T5Block.__init__": [[36, 45], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "fidt5.T5Block.layer.append", "fidt5.T5Block.layer.append", "transformers.modeling_t5.T5LayerSelfAttention", "fidt5.T5Block.layer.append", "transformers.modeling_t5.T5LayerFF", "transformers.modeling_t5.T5LayerCrossAttention"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "has_relative_attention_bias", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "layer", ".", "append", "(", "T5LayerSelfAttention", "(", "config", ",", "has_relative_attention_bias", "=", "has_relative_attention_bias", ")", ")", "\n", "if", "self", ".", "is_decoder", ":", "\n", "            ", "self", ".", "layer", ".", "append", "(", "T5LayerCrossAttention", "(", "config", ",", "has_relative_attention_bias", "=", "has_relative_attention_bias", ")", ")", "\n", "\n", "", "self", ".", "layer", ".", "append", "(", "T5LayerFF", "(", "config", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.T5Block.forward": [[46, 122], ["len", "len"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "position_bias", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "encoder_decoder_position_bias", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "past_key_value_state", "=", "None", ",", "\n", "use_cache", "=", "False", ",", "\n", "output_attentions", "=", "False", ",", "\n", ")", ":", "\n", "\n", "        ", "if", "past_key_value_state", "is", "not", "None", ":", "\n", "            ", "assert", "self", ".", "is_decoder", ",", "\"Only decoder can use `past_key_value_states`\"", "\n", "expected_num_past_key_value_states", "=", "2", "if", "encoder_hidden_states", "is", "None", "else", "4", "\n", "\n", "error_message", "=", "\"There should be {} past states. 2 (past / key) for self attention.{} Got {} past key / value states\"", ".", "format", "(", "\n", "expected_num_past_key_value_states", ",", "\n", "\"2 (past / key) for cross attention\"", "if", "expected_num_past_key_value_states", "==", "4", "else", "\"\"", ",", "\n", "len", "(", "past_key_value_state", ")", ",", "\n", ")", "\n", "assert", "len", "(", "past_key_value_state", ")", "==", "expected_num_past_key_value_states", ",", "error_message", "\n", "\n", "self_attn_past_key_value_state", "=", "past_key_value_state", "[", ":", "2", "]", "\n", "cross_attn_past_key_value_state", "=", "past_key_value_state", "[", "2", ":", "]", "\n", "", "else", ":", "\n", "            ", "self_attn_past_key_value_state", ",", "cross_attn_past_key_value_state", "=", "None", ",", "None", "\n", "\n", "", "self_attention_outputs", "=", "self", ".", "layer", "[", "0", "]", "(", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "position_bias", "=", "position_bias", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "past_key_value_state", "=", "self_attn_past_key_value_state", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "hidden_states", ",", "present_key_value_state", "=", "self_attention_outputs", "[", ":", "2", "]", "\n", "attention_outputs", "=", "self_attention_outputs", "[", "2", ":", "]", "# Keep self-attention outputs and relative position weights", "\n", "\n", "if", "self", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "# the actual query length is unknown for cross attention", "\n", "# if using past key value states. Need to inject it here", "\n", "            ", "if", "present_key_value_state", "is", "not", "None", ":", "\n", "                ", "query_length", "=", "present_key_value_state", "[", "0", "]", ".", "shape", "[", "2", "]", "\n", "", "else", ":", "\n", "                ", "query_length", "=", "None", "\n", "\n", "", "cross_attention_outputs", "=", "self", ".", "layer", "[", "1", "]", "(", "\n", "hidden_states", ",", "\n", "kv", "=", "encoder_hidden_states", ",", "\n", "attention_mask", "=", "encoder_attention_mask", ",", "\n", "position_bias", "=", "encoder_decoder_position_bias", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "past_key_value_state", "=", "cross_attn_past_key_value_state", ",", "\n", "query_length", "=", "query_length", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "hidden_states", "=", "cross_attention_outputs", "[", "0", "]", "\n", "# Combine self attn and cross attn key value states", "\n", "if", "present_key_value_state", "is", "not", "None", ":", "\n", "                ", "present_key_value_state", "=", "present_key_value_state", "+", "cross_attention_outputs", "[", "1", "]", "\n", "\n", "# Keep cross-attention outputs and relative position weights", "\n", "", "attention_outputs", "=", "attention_outputs", "+", "cross_attention_outputs", "[", "2", ":", "]", "\n", "\n", "# Apply Feed Forward layer", "\n", "", "hidden_states", "=", "self", ".", "layer", "[", "-", "1", "]", "(", "hidden_states", ")", "\n", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "\n", "# Add attentions if we output them", "\n", "outputs", "=", "outputs", "+", "(", "present_key_value_state", ",", ")", "+", "attention_outputs", "\n", "return", "outputs", "# hidden-states, present_key_value_states, (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.T5PreTrainedModel.dummy_inputs": [[133, 143], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["@", "property", "\n", "def", "dummy_inputs", "(", "self", ")", ":", "\n", "        ", "input_ids", "=", "torch", ".", "tensor", "(", "DUMMY_INPUTS", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "DUMMY_MASK", ")", "\n", "dummy_inputs", "=", "{", "\n", "\"decoder_input_ids\"", ":", "input_ids", ",", "\n", "\"input_ids\"", ":", "input_ids", ",", "\n", "\"decoder_attention_mask\"", ":", "input_mask", ",", "\n", "}", "\n", "return", "dummy_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.T5PreTrainedModel._init_weights": [[144, 175], ["isinstance", "module.weight.data.fill_", "isinstance", "module.shared.weight.data.normal_", "isinstance", "module.wi.weight.data.normal_", "module.wo.weight.data.normal_", "isinstance", "hasattr", "module.wi.bias.data.zero_", "hasattr", "module.wo.bias.data.zero_", "module.q.weight.data.normal_", "module.k.weight.data.normal_", "module.v.weight.data.normal_", "module.o.weight.data.normal_", "module.relative_attention_bias.weight.data.normal_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights \"\"\"", "\n", "factor", "=", "self", ".", "config", ".", "initializer_factor", "# Used for testing weights initialization", "\n", "if", "isinstance", "(", "module", ",", "T5LayerNorm", ")", ":", "\n", "            ", "module", ".", "weight", ".", "data", ".", "fill_", "(", "factor", "*", "1.0", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "(", "T5Model", ",", "T5ForConditionalGeneration", ",", "FiDT5", ")", ")", ":", "# Change (FiD): added FiDT5", "\n", "# Mesh TensorFlow embeddings initialization", "\n", "# See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L1624", "\n", "            ", "module", ".", "shared", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "1.0", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "T5DenseReluDense", ")", ":", "\n", "# Mesh TensorFlow FF initialization", "\n", "# See https://github.com/tensorflow/mesh/blob/master/mesh_tensorflow/transformer/transformer_layers.py#L56", "\n", "# and https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L89", "\n", "            ", "module", ".", "wi", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "self", ".", "config", ".", "d_model", ")", "**", "-", "0.5", ")", ")", "\n", "if", "hasattr", "(", "module", ".", "wi", ",", "\"bias\"", ")", "and", "module", ".", "wi", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "wi", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "module", ".", "wo", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "self", ".", "config", ".", "d_ff", ")", "**", "-", "0.5", ")", ")", "\n", "if", "hasattr", "(", "module", ".", "wo", ",", "\"bias\"", ")", "and", "module", ".", "wo", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "wo", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "T5Attention", ")", ":", "\n", "# Mesh TensorFlow attention initialization to avoid scaling before softmax", "\n", "# See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/attention.py#L136", "\n", "            ", "d_model", "=", "self", ".", "config", ".", "d_model", "\n", "d_kv", "=", "self", ".", "config", ".", "d_kv", "\n", "n_heads", "=", "self", ".", "config", ".", "num_heads", "\n", "module", ".", "q", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "d_model", "*", "d_kv", ")", "**", "-", "0.5", ")", ")", "\n", "module", ".", "k", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "d_model", "**", "-", "0.5", ")", ")", "\n", "module", ".", "v", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "d_model", "**", "-", "0.5", ")", ")", "\n", "module", ".", "o", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "n_heads", "*", "d_kv", ")", "**", "-", "0.5", ")", ")", "\n", "if", "module", ".", "has_relative_attention_bias", ":", "\n", "                ", "module", ".", "relative_attention_bias", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "d_model", ")", "**", "-", "0.5", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.T5PreTrainedModel._shift_right": [[176, 196], ["input_ids.new_zeros", "input_ids[].clone", "input_ids.new_zeros.masked_fill_", "torch.all().item", "torch.all().item", "torch.all().item", "torch.all().item", "torch.all", "torch.all", "torch.all", "torch.all"], "methods", ["None"], ["", "", "", "def", "_shift_right", "(", "self", ",", "input_ids", ")", ":", "\n", "        ", "decoder_start_token_id", "=", "self", ".", "config", ".", "decoder_start_token_id", "\n", "pad_token_id", "=", "self", ".", "config", ".", "pad_token_id", "\n", "\n", "assert", "(", "\n", "decoder_start_token_id", "is", "not", "None", "\n", ")", ",", "\"self.model.config.decoder_start_token_id has to be defined. In T5 it is usually set to the pad_token_id. See T5 docs for more information\"", "\n", "\n", "# shift inputs to the right", "\n", "shifted_input_ids", "=", "input_ids", ".", "new_zeros", "(", "input_ids", ".", "shape", ")", "\n", "shifted_input_ids", "[", "...", ",", "1", ":", "]", "=", "input_ids", "[", "...", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "shifted_input_ids", "[", "...", ",", "0", "]", "=", "decoder_start_token_id", "\n", "\n", "assert", "pad_token_id", "is", "not", "None", ",", "\"self.model.config.pad_token_id has to be defined.\"", "\n", "# replace possible -100 values in labels by `pad_token_id`", "\n", "shifted_input_ids", ".", "masked_fill_", "(", "shifted_input_ids", "==", "-", "100", ",", "pad_token_id", ")", "\n", "\n", "assert", "torch", ".", "all", "(", "shifted_input_ids", ">=", "0", ")", ".", "item", "(", ")", ",", "\"Verify that `labels` has only positive values and -100\"", "\n", "\n", "return", "shifted_input_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.T5Stack.__init__": [[199, 213], ["transformers.modeling_utils.PreTrainedModel.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "transformers.modeling_t5.T5LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "fidt5.T5Stack.init_weights", "fidt5.T5Block", "range", "bool"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "embed_tokens", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "\n", "self", ".", "block", "=", "nn", ".", "ModuleList", "(", "\n", "[", "T5Block", "(", "config", ",", "has_relative_attention_bias", "=", "bool", "(", "i", "==", "0", ")", ")", "for", "i", "in", "range", "(", "config", ".", "num_layers", ")", "]", "\n", ")", "\n", "self", ".", "final_layer_norm", "=", "T5LayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "self", ".", "checkpoint", "=", "False", "# Change (FiD): flag for gradient checkpointing (during training)", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.T5Stack.get_input_embeddings": [[214, 216], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embed_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.T5Stack.get_output_embeddings": [[217, 219], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embed_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.T5Stack.set_input_embeddings": [[220, 222], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "embed_tokens", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.T5Stack.forward": [[223, 373], ["fidt5.T5Stack.get_extended_attention_mask", "fidt5.T5Stack.get_head_mask", "fidt5.T5Stack.dropout", "enumerate", "fidt5.T5Stack.final_layer_norm", "fidt5.T5Stack.dropout", "input_ids.view.view.view", "torch.ones().to.view", "torch.ones().to.view", "ValueError", "fidt5.T5Stack.embed_tokens", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "fidt5.T5Stack.invert_attention_mask", "zip", "hidden_states.contiguous.contiguous.view", "input_ids.view.view.size", "input_ids.view.view.view", "len", "hidden_states.contiguous.contiguous.contiguous", "extended_attention_mask.contiguous.contiguous.contiguous", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "layer_module", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "fidt5.T5Stack.size", "ValueError", "ValueError"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "past_key_value_states", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "not", "self", ".", "is_decoder", ":", "# Change (FiD): encoder needs to reshape the inputs", "\n", "            ", "bsz", ",", "tc", "=", "input_ids", ".", "shape", "\n", "plen", "=", "tc", "//", "self", ".", "n_passages", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "bsz", "*", "self", ".", "n_passages", ",", "plen", ")", "\n", "attention_mask", "=", "attention_mask", ".", "view", "(", "bsz", "*", "self", ".", "n_passages", ",", "plen", ")", "\n", "\n", "", "use_cache", "=", "use_cache", "if", "use_cache", "is", "not", "None", "else", "self", ".", "config", ".", "use_cache", "\n", "output_attentions", "=", "output_attentions", "if", "output_attentions", "is", "not", "None", "else", "self", ".", "config", ".", "output_attentions", "\n", "output_hidden_states", "=", "(", "\n", "output_hidden_states", "if", "output_hidden_states", "is", "not", "None", "else", "self", ".", "config", ".", "output_hidden_states", "\n", ")", "\n", "\n", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "is_decoder", ":", "\n", "                ", "raise", "ValueError", "(", "\"You have to specify either decoder_input_ids or decoder_inputs_embeds\"", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "assert", "self", ".", "embed_tokens", "is", "not", "None", ",", "\"You have to initialize the model with valid token embeddings\"", "\n", "inputs_embeds", "=", "self", ".", "embed_tokens", "(", "input_ids", ")", "\n", "\n", "", "batch_size", ",", "seq_length", "=", "input_shape", "\n", "\n", "if", "past_key_value_states", "is", "not", "None", ":", "\n", "            ", "assert", "seq_length", "==", "1", ",", "\"Input shape is {}, but should be {} when using past_key_value_sates\"", ".", "format", "(", "\n", "input_shape", ",", "(", "batch_size", ",", "1", ")", "\n", ")", "\n", "# required mask seq length can be calculated via length of past", "\n", "# key value states and seq_length = 1 for the last token", "\n", "mask_seq_length", "=", "past_key_value_states", "[", "0", "]", "[", "0", "]", ".", "shape", "[", "2", "]", "+", "seq_length", "\n", "", "else", ":", "\n", "            ", "mask_seq_length", "=", "seq_length", "\n", "\n", "", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones", "(", "batch_size", ",", "mask_seq_length", ")", ".", "to", "(", "inputs_embeds", ".", "device", ")", "\n", "", "if", "self", ".", "is_decoder", "and", "encoder_attention_mask", "is", "None", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "encoder_seq_length", "=", "encoder_hidden_states", ".", "shape", "[", "1", "]", "\n", "encoder_attention_mask", "=", "torch", ".", "ones", "(", "\n", "batch_size", ",", "encoder_seq_length", ",", "device", "=", "inputs_embeds", ".", "device", ",", "dtype", "=", "torch", ".", "long", "\n", ")", "\n", "\n", "# initialize past_key_value_states with `None` if past does not exist", "\n", "", "if", "past_key_value_states", "is", "None", ":", "\n", "            ", "past_key_value_states", "=", "[", "None", "]", "*", "len", "(", "self", ".", "block", ")", "\n", "\n", "# ourselves in which case we just need to make it broadcastable to all heads.", "\n", "", "extended_attention_mask", "=", "self", ".", "get_extended_attention_mask", "(", "attention_mask", ",", "input_shape", ",", "inputs_embeds", ".", "device", ")", "\n", "\n", "if", "self", ".", "is_decoder", "and", "encoder_attention_mask", "is", "not", "None", ":", "\n", "            ", "encoder_extended_attention_mask", "=", "self", ".", "invert_attention_mask", "(", "encoder_attention_mask", ")", "\n", "", "else", ":", "\n", "            ", "encoder_extended_attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "", "head_mask", "=", "self", ".", "get_head_mask", "(", "head_mask", ",", "self", ".", "config", ".", "num_layers", ")", "\n", "present_key_value_states", "=", "(", ")", "\n", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "(", ")", "\n", "position_bias", "=", "None", "\n", "encoder_decoder_position_bias", "=", "None", "\n", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "inputs_embeds", ")", "\n", "\n", "for", "i", ",", "(", "layer_module", ",", "past_key_value_state", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "block", ",", "past_key_value_states", ")", ")", ":", "\n", "            ", "if", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "if", "not", "self", ".", "is_decoder", "and", "self", ".", "checkpoint", ":", "# Change (FiD): encoder with gradient checkpointing", "\n", "                ", "hidden_states", "=", "hidden_states", ".", "contiguous", "(", ")", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "contiguous", "(", ")", "\n", "layer_outputs", "=", "torch", ".", "utils", ".", "checkpoint", ".", "checkpoint", "(", "\n", "layer_module", ",", "\n", "hidden_states", ",", "\n", "extended_attention_mask", ",", "\n", "position_bias", ",", "\n", "# encoder_hidden_states,", "\n", "# encoder_extended_attention_mask,", "\n", "# encoder_decoder_position_bias,", "\n", "# head_mask[i],", "\n", "# past_key_value_state,", "\n", ")", "\n", "", "else", ":", "\n", "                ", "layer_outputs", "=", "layer_module", "(", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "position_bias", "=", "position_bias", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_extended_attention_mask", ",", "\n", "encoder_decoder_position_bias", "=", "encoder_decoder_position_bias", ",", "\n", "head_mask", "=", "head_mask", "[", "i", "]", ",", "\n", "past_key_value_state", "=", "past_key_value_state", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "# layer_outputs is a tuple with:", "\n", "# hidden-states, key-value-states, (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)", "\n", "", "hidden_states", ",", "present_key_value_state", "=", "layer_outputs", "[", ":", "2", "]", "\n", "\n", "if", "i", "==", "0", ":", "\n", "# We share the position biases between the layers - the first layer store them", "\n", "# layer_outputs = hidden-states, key-value-states (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)", "\n", "                ", "position_bias", "=", "layer_outputs", "[", "3", "if", "output_attentions", "else", "2", "]", "\n", "if", "self", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "                    ", "encoder_decoder_position_bias", "=", "layer_outputs", "[", "5", "if", "output_attentions", "else", "3", "]", "\n", "# append next layer key value states", "\n", "", "", "present_key_value_states", "=", "present_key_value_states", "+", "(", "present_key_value_state", ",", ")", "\n", "\n", "if", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "2", "]", ",", ")", "# We keep only self-attention weights for now", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "final_layer_norm", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "\n", "if", "not", "self", ".", "is_decoder", ":", "# Change (FiD): reshape output", "\n", "            ", "hidden_states", "=", "hidden_states", ".", "view", "(", "bsz", ",", "self", ".", "n_passages", "*", "plen", ",", "-", "1", ")", "\n", "\n", "# Add last layer", "\n", "", "if", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "use_cache", "is", "True", ":", "\n", "            ", "assert", "self", ".", "is_decoder", ",", "\"`use_cache` can only be set to `True` if {} is used as a decoder\"", ".", "format", "(", "self", ")", "\n", "outputs", "=", "outputs", "+", "(", "present_key_value_states", ",", ")", "\n", "", "if", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last-layer hidden state, (presents,) (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.FiDT5.__init__": [[376, 393], ["transformers.modeling_utils.PreTrainedModel.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "copy.deepcopy", "fidt5.T5Stack", "copy.deepcopy", "fidt5.T5Stack", "torch.nn.Linear", "torch.nn.Linear", "fidt5.FiDT5.init_weights"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "model_dim", "=", "config", ".", "d_model", "\n", "\n", "self", ".", "shared", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "d_model", ")", "\n", "\n", "encoder_config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "encoder_config", ".", "use_cache", "=", "False", "\n", "self", ".", "encoder", "=", "T5Stack", "(", "encoder_config", ",", "self", ".", "shared", ")", "\n", "\n", "decoder_config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "decoder_config", ".", "is_decoder", "=", "True", "\n", "self", ".", "decoder", "=", "T5Stack", "(", "decoder_config", ",", "self", ".", "shared", ")", "\n", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.FiDT5.get_input_embeddings": [[394, 396], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "shared", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.FiDT5.set_input_embeddings": [[397, 401], ["fidt5.FiDT5.encoder.set_input_embeddings", "fidt5.FiDT5.decoder.set_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.FiDT5.set_input_embeddings", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.FiDT5.set_input_embeddings"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "shared", "=", "new_embeddings", "\n", "self", ".", "encoder", ".", "set_input_embeddings", "(", "new_embeddings", ")", "\n", "self", ".", "decoder", ".", "set_input_embeddings", "(", "new_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.FiDT5.get_output_embeddings": [[402, 404], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.FiDT5.get_encoder": [[405, 407], ["None"], "methods", ["None"], ["", "def", "get_encoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.FiDT5.get_decoder": [[408, 410], ["None"], "methods", ["None"], ["", "def", "get_decoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.FiDT5.forward": [[411, 500], ["fidt5.FiDT5.decoder", "fidt5.FiDT5.lm_head", "warnings.warn", "kwargs.pop", "fidt5.FiDT5.encoder", "fidt5.FiDT5._shift_right", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "list", "fidt5.FiDT5.view", "kwargs.pop.view", "kwargs.keys", "fidt5.FiDT5.size"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.T5PreTrainedModel._shift_right"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "\n", "decoder_input_ids", "=", "None", ",", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "decoder_past_key_value_states", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "decoder_inputs_embeds", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "\n", "        ", "if", "\"lm_labels\"", "in", "kwargs", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"The `lm_labels` argument is deprecated and will be removed in a future version, use `labels` instead.\"", ",", "\n", "DeprecationWarning", ",", "\n", ")", "\n", "labels", "=", "kwargs", ".", "pop", "(", "\"lm_labels\"", ")", "\n", "", "assert", "kwargs", "==", "{", "}", ",", "f\"Unexpected keyword arguments: {list(kwargs.keys())}.\"", "\n", "\n", "use_cache", "=", "use_cache", "if", "use_cache", "is", "not", "None", "else", "self", ".", "config", ".", "use_cache", "\n", "\n", "# Encode if needed (training, first prediction pass)", "\n", "if", "encoder_outputs", "is", "None", ":", "\n", "# Convert encoder inputs in embeddings if needed", "\n", "            ", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", ")", "\n", "\n", "", "hidden_states", "=", "encoder_outputs", "[", "0", "]", "\n", "\n", "if", "labels", "is", "not", "None", "and", "decoder_input_ids", "is", "None", "and", "decoder_inputs_embeds", "is", "None", ":", "\n", "# get decoder inputs from shifting lm labels to the right", "\n", "            ", "decoder_input_ids", "=", "self", ".", "_shift_right", "(", "labels", ")", "\n", "\n", "# If decoding with past key value states, only the last tokens", "\n", "# should be given as an input", "\n", "", "if", "decoder_past_key_value_states", "is", "not", "None", ":", "\n", "            ", "assert", "labels", "is", "None", ",", "\"Decoder should not use cached key value states when training.\"", "\n", "if", "decoder_input_ids", "is", "not", "None", ":", "\n", "                ", "decoder_input_ids", "=", "decoder_input_ids", "[", ":", ",", "-", "1", ":", "]", "\n", "", "if", "decoder_inputs_embeds", "is", "not", "None", ":", "\n", "                ", "decoder_inputs_embeds", "=", "decoder_inputs_embeds", "[", ":", ",", "-", "1", ":", "]", "\n", "\n", "# Decode", "\n", "", "", "decoder_outputs", "=", "self", ".", "decoder", "(", "\n", "input_ids", "=", "decoder_input_ids", ",", "\n", "attention_mask", "=", "decoder_attention_mask", ",", "\n", "inputs_embeds", "=", "decoder_inputs_embeds", ",", "\n", "past_key_value_states", "=", "decoder_past_key_value_states", ",", "\n", "encoder_hidden_states", "=", "hidden_states", ",", "\n", "encoder_attention_mask", "=", "attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", ")", "\n", "\n", "# insert decoder past at right place", "\n", "# to speed up decoding", "\n", "if", "use_cache", "is", "True", ":", "\n", "            ", "past", "=", "(", "(", "encoder_outputs", ",", "decoder_outputs", "[", "1", "]", ")", ",", ")", "\n", "decoder_outputs", "=", "decoder_outputs", "[", ":", "1", "]", "+", "past", "+", "decoder_outputs", "[", "2", ":", "]", "\n", "\n", "", "sequence_output", "=", "decoder_outputs", "[", "0", "]", "\n", "# Rescale output before projecting on vocab", "\n", "# See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/transformer.py#L586", "\n", "sequence_output", "=", "sequence_output", "*", "(", "self", ".", "model_dim", "**", "-", "0.5", ")", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "sequence_output", ")", "\n", "\n", "decoder_outputs", "=", "(", "lm_logits", ",", ")", "+", "decoder_outputs", "[", "1", ":", "]", "# Add hidden states and attention if they are here", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "100", ")", "\n", "loss", "=", "loss_fct", "(", "lm_logits", ".", "view", "(", "-", "1", ",", "lm_logits", ".", "size", "(", "-", "1", ")", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "# TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666", "\n", "decoder_outputs", "=", "(", "loss", ",", ")", "+", "decoder_outputs", "\n", "\n", "", "return", "decoder_outputs", "+", "encoder_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.FiDT5.prepare_inputs_for_generation": [[501, 512], ["None"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "self", ",", "input_ids", ",", "past", ",", "attention_mask", ",", "use_cache", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "past", "is", "not", "None", ",", "\"past has to be defined for encoder_outputs\"", "\n", "\n", "encoder_outputs", ",", "decoder_past_key_value_states", "=", "past", "\n", "\n", "return", "{", "\n", "\"decoder_input_ids\"", ":", "input_ids", ",", "\n", "\"decoder_past_key_value_states\"", ":", "decoder_past_key_value_states", ",", "\n", "\"encoder_outputs\"", ":", "encoder_outputs", ",", "\n", "\"attention_mask\"", ":", "attention_mask", ",", "\n", "\"use_cache\"", ":", "use_cache", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.fidt5.FiDT5._reorder_cache": [[514, 539], ["logger.warning", "len", "len", "layer_past_state.index_select"], "methods", ["None"], ["", "def", "_reorder_cache", "(", "self", ",", "past", ",", "beam_idx", ")", ":", "\n", "# if decoder past is not included in output", "\n", "# speedy decoding is disabled and no need to reorder", "\n", "        ", "if", "past", "[", "1", "]", "is", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\"You might want to consider setting `use_cache=True` to speed up decoding\"", ")", "\n", "return", "past", "\n", "\n", "", "decoder_past", "=", "past", "[", "1", "]", "\n", "past", "=", "(", "past", "[", "0", "]", ",", ")", "\n", "reordered_decoder_past", "=", "(", ")", "\n", "for", "layer_past_states", "in", "decoder_past", ":", "\n", "# get the correct batch idx from layer past batch dim", "\n", "# batch dim of `past` is at 2nd position", "\n", "            ", "reordered_layer_past_states", "=", "(", ")", "\n", "for", "layer_past_state", "in", "layer_past_states", ":", "\n", "# need to set correct `past` for each of the four key / value states", "\n", "                ", "reordered_layer_past_states", "=", "reordered_layer_past_states", "+", "(", "\n", "layer_past_state", ".", "index_select", "(", "0", ",", "beam_idx", ")", ",", "\n", ")", "\n", "\n", "", "assert", "reordered_layer_past_states", "[", "0", "]", ".", "shape", "==", "layer_past_states", "[", "0", "]", ".", "shape", "\n", "assert", "len", "(", "reordered_layer_past_states", ")", "==", "len", "(", "layer_past_states", ")", "\n", "\n", "reordered_decoder_past", "=", "reordered_decoder_past", "+", "(", "reordered_layer_past_states", ",", ")", "\n", "", "return", "past", "+", "(", "reordered_decoder_past", ",", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.Tokens.__init__": [[45, 49], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ",", "annotators", ",", "opts", "=", "None", ")", ":", "\n", "        ", "self", ".", "data", "=", "data", "\n", "self", ".", "annotators", "=", "annotators", "\n", "self", ".", "opts", "=", "opts", "or", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.Tokens.__len__": [[50, 53], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"The number of tokens.\"\"\"", "\n", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.Tokens.slice": [[54, 59], ["copy.copy"], "methods", ["None"], ["", "def", "slice", "(", "self", ",", "i", "=", "None", ",", "j", "=", "None", ")", ":", "\n", "        ", "\"\"\"Return a view of the list of tokens from [i, j).\"\"\"", "\n", "new_tokens", "=", "copy", ".", "copy", "(", "self", ")", "\n", "new_tokens", ".", "data", "=", "self", ".", "data", "[", "i", ":", "j", "]", "\n", "return", "new_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.Tokens.untokenize": [[60, 63], ["None"], "methods", ["None"], ["", "def", "untokenize", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the original text (with whitespace reinserted).\"\"\"", "\n", "return", "''", ".", "join", "(", "[", "t", "[", "self", ".", "TEXT_WS", "]", "for", "t", "in", "self", ".", "data", "]", ")", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.Tokens.words": [[64, 73], ["t[].lower"], "methods", ["None"], ["", "def", "words", "(", "self", ",", "uncased", "=", "False", ")", ":", "\n", "        ", "\"\"\"Returns a list of the text of each token\n        Args:\n            uncased: lower cases text\n        \"\"\"", "\n", "if", "uncased", ":", "\n", "            ", "return", "[", "t", "[", "self", ".", "TEXT", "]", ".", "lower", "(", ")", "for", "t", "in", "self", ".", "data", "]", "\n", "", "else", ":", "\n", "            ", "return", "[", "t", "[", "self", ".", "TEXT", "]", "for", "t", "in", "self", ".", "data", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.Tokens.offsets": [[74, 77], ["None"], "methods", ["None"], ["", "", "def", "offsets", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns a list of [start, end) character offsets of each token.\"\"\"", "\n", "return", "[", "t", "[", "self", ".", "SPAN", "]", "for", "t", "in", "self", ".", "data", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.Tokens.pos": [[78, 85], ["None"], "methods", ["None"], ["", "def", "pos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns a list of part-of-speech tags of each token.\n        Returns None if this annotation was not included.\n        \"\"\"", "\n", "if", "'pos'", "not", "in", "self", ".", "annotators", ":", "\n", "            ", "return", "None", "\n", "", "return", "[", "t", "[", "self", ".", "POS", "]", "for", "t", "in", "self", ".", "data", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.Tokens.lemmas": [[86, 93], ["None"], "methods", ["None"], ["", "def", "lemmas", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns a list of the lemmatized text of each token.\n        Returns None if this annotation was not included.\n        \"\"\"", "\n", "if", "'lemma'", "not", "in", "self", ".", "annotators", ":", "\n", "            ", "return", "None", "\n", "", "return", "[", "t", "[", "self", ".", "LEMMA", "]", "for", "t", "in", "self", ".", "data", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.Tokens.entities": [[94, 101], ["None"], "methods", ["None"], ["", "def", "entities", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns a list of named-entity-recognition tags of each token.\n        Returns None if this annotation was not included.\n        \"\"\"", "\n", "if", "'ner'", "not", "in", "self", ".", "annotators", ":", "\n", "            ", "return", "None", "\n", "", "return", "[", "t", "[", "self", ".", "NER", "]", "for", "t", "in", "self", ".", "data", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.Tokens.ngrams": [[102, 128], ["evaluation.Tokens.words", "filter_fn", "range", "range", "len", "min", "evaluation.Tokens.ngrams._skip"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.Tokens.words"], ["", "def", "ngrams", "(", "self", ",", "n", "=", "1", ",", "uncased", "=", "False", ",", "filter_fn", "=", "None", ",", "as_strings", "=", "True", ")", ":", "\n", "        ", "\"\"\"Returns a list of all ngrams from length 1 to n.\n        Args:\n            n: upper limit of ngram length\n            uncased: lower cases text\n            filter_fn: user function that takes in an ngram list and returns\n              True or False to keep or not keep the ngram\n            as_string: return the ngram as a string vs list\n        \"\"\"", "\n", "\n", "def", "_skip", "(", "gram", ")", ":", "\n", "            ", "if", "not", "filter_fn", ":", "\n", "                ", "return", "False", "\n", "", "return", "filter_fn", "(", "gram", ")", "\n", "\n", "", "words", "=", "self", ".", "words", "(", "uncased", ")", "\n", "ngrams", "=", "[", "(", "s", ",", "e", "+", "1", ")", "\n", "for", "s", "in", "range", "(", "len", "(", "words", ")", ")", "\n", "for", "e", "in", "range", "(", "s", ",", "min", "(", "s", "+", "n", ",", "len", "(", "words", ")", ")", ")", "\n", "if", "not", "_skip", "(", "words", "[", "s", ":", "e", "+", "1", "]", ")", "]", "\n", "\n", "# Concatenate into strings", "\n", "if", "as_strings", ":", "\n", "            ", "ngrams", "=", "[", "'{}'", ".", "format", "(", "' '", ".", "join", "(", "words", "[", "s", ":", "e", "]", ")", ")", "for", "(", "s", ",", "e", ")", "in", "ngrams", "]", "\n", "\n", "", "return", "ngrams", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.Tokens.entity_groups": [[129, 149], ["evaluation.Tokens.entities", "evaluation.Tokens.opts.get", "len", "groups.append", "len", "evaluation.Tokens.slice().untokenize", "evaluation.Tokens.slice"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.Tokens.entities", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.Tokens.untokenize", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.Tokens.slice"], ["", "def", "entity_groups", "(", "self", ")", ":", "\n", "        ", "\"\"\"Group consecutive entity tokens with the same NER tag.\"\"\"", "\n", "entities", "=", "self", ".", "entities", "(", ")", "\n", "if", "not", "entities", ":", "\n", "            ", "return", "None", "\n", "", "non_ent", "=", "self", ".", "opts", ".", "get", "(", "'non_ent'", ",", "'O'", ")", "\n", "groups", "=", "[", "]", "\n", "idx", "=", "0", "\n", "while", "idx", "<", "len", "(", "entities", ")", ":", "\n", "            ", "ner_tag", "=", "entities", "[", "idx", "]", "\n", "# Check for entity tag", "\n", "if", "ner_tag", "!=", "non_ent", ":", "\n", "# Chomp the sequence", "\n", "                ", "start", "=", "idx", "\n", "while", "(", "idx", "<", "len", "(", "entities", ")", "and", "entities", "[", "idx", "]", "==", "ner_tag", ")", ":", "\n", "                    ", "idx", "+=", "1", "\n", "", "groups", ".", "append", "(", "(", "self", ".", "slice", "(", "start", ",", "idx", ")", ".", "untokenize", "(", ")", ",", "ner_tag", ")", ")", "\n", "", "else", ":", "\n", "                ", "idx", "+=", "1", "\n", "", "", "return", "groups", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.Tokenizer.tokenize": [[156, 158], ["None"], "methods", ["None"], ["def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.Tokenizer.shutdown": [[159, 161], ["None"], "methods", ["None"], ["", "def", "shutdown", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.Tokenizer.__del__": [[162, 164], ["evaluation.Tokenizer.shutdown"], "methods", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.Tokenizer.shutdown"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.__init__": [[170, 183], ["regex.compile", "set", "len", "logger.warning", "kwargs.get", "kwargs.get", "type"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            annotators: None or empty set (only tokenizes).\n        \"\"\"", "\n", "self", ".", "_regexp", "=", "regex", ".", "compile", "(", "\n", "'(%s)|(%s)'", "%", "(", "self", ".", "ALPHA_NUM", ",", "self", ".", "NON_WS", ")", ",", "\n", "flags", "=", "regex", ".", "IGNORECASE", "+", "regex", ".", "UNICODE", "+", "regex", ".", "MULTILINE", "\n", ")", "\n", "if", "len", "(", "kwargs", ".", "get", "(", "'annotators'", ",", "{", "}", ")", ")", ">", "0", ":", "\n", "            ", "logger", ".", "warning", "(", "'%s only tokenizes! Skipping annotators: %s'", "%", "\n", "(", "type", "(", "self", ")", ".", "__name__", ",", "kwargs", ".", "get", "(", "'annotators'", ")", ")", ")", "\n", "", "self", ".", "annotators", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.tokenize": [[184, 206], ["range", "evaluation.Tokens", "len", "matches[].group", "matches[].span", "data.append", "evaluation.SimpleTokenizer._regexp.finditer", "len", "matches[].span"], "methods", ["None"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "data", "=", "[", "]", "\n", "matches", "=", "[", "m", "for", "m", "in", "self", ".", "_regexp", ".", "finditer", "(", "text", ")", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "matches", ")", ")", ":", "\n", "# Get text", "\n", "            ", "token", "=", "matches", "[", "i", "]", ".", "group", "(", ")", "\n", "\n", "# Get whitespace", "\n", "span", "=", "matches", "[", "i", "]", ".", "span", "(", ")", "\n", "start_ws", "=", "span", "[", "0", "]", "\n", "if", "i", "+", "1", "<", "len", "(", "matches", ")", ":", "\n", "                ", "end_ws", "=", "matches", "[", "i", "+", "1", "]", ".", "span", "(", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "end_ws", "=", "span", "[", "1", "]", "\n", "\n", "# Format data", "\n", "", "data", ".", "append", "(", "(", "\n", "token", ",", "\n", "text", "[", "start_ws", ":", "end_ws", "]", ",", "\n", "span", ",", "\n", ")", ")", "\n", "", "return", "Tokens", "(", "data", ",", "self", ".", "annotators", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.normalize_answer": [[11, 26], ["evaluation.normalize_answer.white_space_fix"], "function", ["None"], ["def", "normalize_answer", "(", "s", ")", ":", "\n", "    ", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "return", "re", ".", "sub", "(", "r'\\b(a|an|the)\\b'", ",", "' '", ",", "text", ")", "\n", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.exact_match_score": [[28, 30], ["evaluation.normalize_answer", "evaluation.normalize_answer"], "function", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.normalize_answer", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.normalize_answer"], ["", "def", "exact_match_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "return", "normalize_answer", "(", "prediction", ")", "==", "normalize_answer", "(", "ground_truth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.ems": [[32, 34], ["max", "evaluation.exact_match_score"], "function", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.exact_match_score"], ["", "def", "ems", "(", "prediction", ",", "ground_truths", ")", ":", "\n", "    ", "return", "max", "(", "[", "exact_match_score", "(", "prediction", ",", "gt", ")", "for", "gt", "in", "ground_truths", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation._normalize": [[208, 210], ["unicodedata.normalize"], "function", ["None"], ["", "", "def", "_normalize", "(", "text", ")", ":", "\n", "    ", "return", "unicodedata", ".", "normalize", "(", "\"NFD\"", ",", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.has_answer": [[212, 232], ["evaluation._normalize", "tokenizer.tokenize().words", "evaluation._normalize", "tokenizer.tokenize", "single_answer.words.words", "range", "tokenizer.tokenize", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation._normalize", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.Tokens.words", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation._normalize", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.tokenize", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.Tokens.words", "home.repos.pwc.inspect_result.uclnlp_APE.FiD.evaluation.SimpleTokenizer.tokenize"], ["", "def", "has_answer", "(", "answers", ",", "text", ",", "tokenizer", ")", "->", "bool", ":", "\n", "    ", "\"\"\"Check if a document contains an answer string.\n    If `match_type` is string, token matching is done between the text and answer.\n    If `match_type` is regex, we search the whole text with the regex.\n    \"\"\"", "\n", "text", "=", "_normalize", "(", "text", ")", "\n", "\n", "# Answer is a list of possible strings", "\n", "text", "=", "tokenizer", ".", "tokenize", "(", "text", ")", ".", "words", "(", "uncased", "=", "True", ")", "\n", "\n", "for", "single_answer", "in", "answers", ":", "\n", "        ", "single_answer", "=", "_normalize", "(", "single_answer", ")", "\n", "single_answer", "=", "tokenizer", ".", "tokenize", "(", "single_answer", ")", "\n", "single_answer", "=", "single_answer", ".", "words", "(", "uncased", "=", "True", ")", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "text", ")", "-", "len", "(", "single_answer", ")", "+", "1", ")", ":", "\n", "            ", "if", "single_answer", "==", "text", "[", "i", ":", "i", "+", "len", "(", "single_answer", ")", "]", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "", "return", "False", "\n", "", ""]]}