{"home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.setUp": [[172, 179], ["super().setUp", "json.loads", "json.loads", "qed_eval.load_single_line"], "methods", ["home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.setUp", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.load_single_line"], ["  ", "def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "QedEvalTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "self", ".", "_annotation_jsonlines", "=", "[", "json", ".", "loads", "(", "example_1", ")", ",", "json", ".", "loads", "(", "example_2", ")", "]", "\n", "annot_elems", "=", "[", "\n", "qed_eval", ".", "load_single_line", "(", "l", ")", "for", "l", "in", "self", ".", "_annotation_jsonlines", "\n", "]", "\n", "self", ".", "annotation_dict", "=", "{", "elem", ".", "example_id", ":", "elem", "for", "elem", "in", "annot_elems", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.get_span": [[180, 182], ["None"], "methods", ["None"], ["", "def", "get_span", "(", "self", ",", "text", ",", "span", ")", ":", "\n", "    ", "return", "{", "\"start\"", ":", "span", "[", "0", "]", ",", "\"end\"", ":", "span", "[", "1", "]", ",", "\"string\"", ":", "text", "[", "span", "[", "0", "]", ":", "span", "[", "1", "]", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_answer": [[183, 190], ["output_answers.clear", "output_answers.append", "qed_eval_test.QedEvalTest.get_span"], "methods", ["home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.get_span"], ["", "def", "set_answer", "(", "self", ",", "example", ",", "answers", ")", ":", "\n", "    ", "output_answers", "=", "example", "[", "\"annotation\"", "]", "[", "\"answer\"", "]", "\n", "output_answers", ".", "clear", "(", ")", "\n", "for", "answer", "in", "answers", ":", "\n", "      ", "output_answers", ".", "append", "(", "{", "\n", "\"paragraph_reference\"", ":", "\n", "self", ".", "get_span", "(", "example", "[", "\"paragraph_text\"", "]", ",", "answer", ")", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_refs": [[192, 202], ["refs_output.clear", "refs_output.append", "qed_eval_test.QedEvalTest.get_span", "qed_eval_test.QedEvalTest.get_span"], "methods", ["home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.get_span", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.get_span"], ["", "", "def", "set_refs", "(", "self", ",", "example", ",", "refs", ")", ":", "\n", "    ", "refs_output", "=", "example", "[", "\"annotation\"", "]", "[", "\"referential_equalities\"", "]", "\n", "refs_output", ".", "clear", "(", ")", "\n", "for", "ref", "in", "refs", ":", "\n", "      ", "question_span", ",", "sentence_span", "=", "ref", "\n", "refs_output", ".", "append", "(", "{", "\n", "\"question_reference\"", ":", "\n", "self", ".", "get_span", "(", "example", "[", "\"question_text\"", "]", ",", "question_span", ")", ",", "\n", "\"sentence_reference\"", ":", "\n", "self", ".", "get_span", "(", "example", "[", "\"paragraph_text\"", "]", ",", "sentence_span", ")", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.test_strict_accuracy_on_correct": [[204, 232], ["qed_eval_test.QedEvalTest.set_answer", "qed_eval_test.QedEvalTest.set_refs", "qed_eval_test.QedEvalTest.set_answer", "qed_eval_test.QedEvalTest.set_refs", "qed_eval.compute_scores", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "json.loads", "json.loads", "qed_eval.load_single_line"], "methods", ["home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_answer", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_refs", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_answer", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_refs", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_scores", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.load_single_line"], ["", "", "def", "test_strict_accuracy_on_correct", "(", "self", ")", ":", "\n", "    ", "prediction_jsonlines", "=", "[", "json", ".", "loads", "(", "example_1", ")", ",", "json", ".", "loads", "(", "example_2", ")", "]", "\n", "self", ".", "set_answer", "(", "prediction_jsonlines", "[", "0", "]", ",", "[", "(", "506", ",", "520", ")", "]", ")", "# correct answer", "\n", "self", ".", "set_refs", "(", "\n", "prediction_jsonlines", "[", "0", "]", ",", "\n", "[", "\n", "(", "(", "12", ",", "27", ")", ",", "(", "459", ",", "479", ")", ")", ",", "# two correct refs", "\n", "(", "(", "28", ",", "41", ")", ",", "(", "-", "1", ",", "-", "1", ")", ")", "\n", "]", ")", "\n", "self", ".", "set_answer", "(", "prediction_jsonlines", "[", "1", "]", ",", "[", "(", "216", ",", "243", ")", "]", ")", "# correct answer", "\n", "self", ".", "set_refs", "(", "prediction_jsonlines", "[", "1", "]", ",", "\n", "[", "(", "(", "10", ",", "12", ")", ",", "(", "259", ",", "261", ")", ")", "]", ")", "# one correct ref", "\n", "\n", "pred_elems", "=", "[", "qed_eval", ".", "load_single_line", "(", "l", ")", "for", "l", "in", "prediction_jsonlines", "]", "\n", "prediction_dict", "=", "{", "elem", ".", "example_id", ":", "elem", "for", "elem", "in", "pred_elems", "}", "\n", "score_dict", "=", "qed_eval", ".", "compute_scores", "(", "\n", "self", ".", "annotation_dict", ",", "prediction_dict", ",", "strict", "=", "True", ")", "\n", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"exact_match_accuracy\"", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"pair\"", "]", "[", "0", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"pair\"", "]", "[", "1", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"question_mention\"", "]", "[", "0", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"question_mention\"", "]", "[", "1", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"context_mention\"", "]", "[", "0", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"context_mention\"", "]", "[", "1", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"all_mention\"", "]", "[", "0", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"all_mention\"", "]", "[", "1", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"answer_accuracy\"", "]", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.test_strict_accuracy": [[233, 257], ["qed_eval_test.QedEvalTest.set_answer", "qed_eval_test.QedEvalTest.set_refs", "qed_eval_test.QedEvalTest.set_answer", "qed_eval_test.QedEvalTest.set_refs", "qed_eval.compute_scores", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "json.loads", "json.loads", "qed_eval.load_single_line"], "methods", ["home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_answer", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_refs", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_answer", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_refs", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_scores", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.load_single_line"], ["", "def", "test_strict_accuracy", "(", "self", ")", ":", "\n", "    ", "prediction_jsonlines", "=", "[", "json", ".", "loads", "(", "example_1", ")", ",", "json", ".", "loads", "(", "example_2", ")", "]", "\n", "self", ".", "set_answer", "(", "prediction_jsonlines", "[", "0", "]", ",", "[", "(", "506", ",", "520", ")", "]", ")", "# correct answer", "\n", "self", ".", "set_refs", "(", "prediction_jsonlines", "[", "0", "]", ",", "\n", "[", "(", "(", "28", ",", "41", ")", ",", "(", "-", "1", ",", "-", "1", ")", ")", "]", ")", "# one correct ref, one missing", "\n", "self", ".", "set_answer", "(", "prediction_jsonlines", "[", "1", "]", ",", "[", "(", "217", ",", "243", ")", "]", ")", "# wrong answer", "\n", "self", ".", "set_refs", "(", "prediction_jsonlines", "[", "1", "]", ",", "\n", "[", "(", "(", "10", ",", "12", ")", ",", "(", "259", ",", "261", ")", ")", "]", ")", "# one correct ref", "\n", "\n", "pred_elems", "=", "[", "qed_eval", ".", "load_single_line", "(", "l", ")", "for", "l", "in", "prediction_jsonlines", "]", "\n", "prediction_dict", "=", "{", "elem", ".", "example_id", ":", "elem", "for", "elem", "in", "pred_elems", "}", "\n", "score_dict", "=", "qed_eval", ".", "compute_scores", "(", "\n", "self", ".", "annotation_dict", ",", "prediction_dict", ",", "strict", "=", "True", ")", "\n", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"exact_match_accuracy\"", "]", ",", "0.5", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"pair\"", "]", "[", "0", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"pair\"", "]", "[", "1", "]", ",", "2.0", "/", "3.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"question_mention\"", "]", "[", "0", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"question_mention\"", "]", "[", "1", "]", ",", "2.0", "/", "3.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"context_mention\"", "]", "[", "0", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"context_mention\"", "]", "[", "1", "]", ",", "1.0", "/", "2.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"all_mention\"", "]", "[", "0", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"all_mention\"", "]", "[", "1", "]", ",", "3.0", "/", "5.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"answer_accuracy\"", "]", ",", "1.0", "/", "2.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.test_non_strict_accuracy": [[258, 302], ["qed_eval_test.QedEvalTest.set_answer", "qed_eval_test.QedEvalTest.set_refs", "qed_eval_test.QedEvalTest.set_answer", "qed_eval_test.QedEvalTest.set_refs", "qed_eval.compute_scores", "print", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval.compute_scores", "print", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "json.loads", "json.loads", "qed_eval.load_single_line"], "methods", ["home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_answer", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_refs", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_answer", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_refs", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_scores", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_scores", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.load_single_line"], ["", "def", "test_non_strict_accuracy", "(", "self", ")", ":", "\n", "    ", "prediction_jsonlines", "=", "[", "json", ".", "loads", "(", "example_1", ")", ",", "json", ".", "loads", "(", "example_2", ")", "]", "\n", "self", ".", "set_answer", "(", "prediction_jsonlines", "[", "0", "]", ",", "[", "(", "506", ",", "520", ")", "]", ")", "# correct answer", "\n", "self", ".", "set_refs", "(", "\n", "prediction_jsonlines", "[", "0", "]", ",", "\n", "[", "\n", "(", "(", "15", ",", "27", ")", ",", "(", "462", ",", "479", ")", ")", ",", "# one correct ref (non strict)", "\n", "(", "(", "28", ",", "41", ")", ",", "(", "-", "1", ",", "-", "1", ")", ")", "\n", "]", ")", "# one correct ref", "\n", "self", ".", "set_answer", "(", "prediction_jsonlines", "[", "1", "]", ",", "\n", "[", "(", "217", ",", "243", ")", "]", ")", "# correct answer (non strict)", "\n", "self", ".", "set_refs", "(", "prediction_jsonlines", "[", "1", "]", ",", "\n", "[", "(", "(", "10", ",", "12", ")", ",", "(", "259", ",", "261", ")", ")", "]", ")", "# one correct ref", "\n", "\n", "pred_elems", "=", "[", "qed_eval", ".", "load_single_line", "(", "l", ")", "for", "l", "in", "prediction_jsonlines", "]", "\n", "prediction_dict", "=", "{", "elem", ".", "example_id", ":", "elem", "for", "elem", "in", "pred_elems", "}", "\n", "\n", "score_dict", "=", "qed_eval", ".", "compute_scores", "(", "\n", "self", ".", "annotation_dict", ",", "prediction_dict", ",", "strict", "=", "False", ")", "\n", "print", "(", "score_dict", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"exact_match_accuracy\"", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"pair\"", "]", "[", "0", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"pair\"", "]", "[", "1", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"question_mention\"", "]", "[", "0", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"question_mention\"", "]", "[", "1", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"context_mention\"", "]", "[", "0", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"context_mention\"", "]", "[", "1", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"all_mention\"", "]", "[", "0", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"all_mention\"", "]", "[", "1", "]", ",", "1.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"answer_accuracy\"", "]", ",", "1.0", ")", "\n", "\n", "score_dict", "=", "qed_eval", ".", "compute_scores", "(", "\n", "self", ".", "annotation_dict", ",", "prediction_dict", ",", "strict", "=", "True", ")", "\n", "print", "(", "score_dict", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"exact_match_accuracy\"", "]", ",", "0.5", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"pair\"", "]", "[", "0", "]", ",", "2.0", "/", "3.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"pair\"", "]", "[", "1", "]", ",", "2.0", "/", "3.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"question_mention\"", "]", "[", "0", "]", ",", "2.0", "/", "3.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"question_mention\"", "]", "[", "1", "]", ",", "2.0", "/", "3.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"context_mention\"", "]", "[", "0", "]", ",", "0.5", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"context_mention\"", "]", "[", "1", "]", ",", "0.5", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"all_mention\"", "]", "[", "0", "]", ",", "3.0", "/", "5.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"all_mention\"", "]", "[", "1", "]", ",", "3.0", "/", "5.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"answer_accuracy\"", "]", ",", "1.0", "/", "2.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.test_non_strict_accuracy_not_enough_overlap": [[303, 346], ["qed_eval_test.QedEvalTest.set_answer", "qed_eval_test.QedEvalTest.set_refs", "qed_eval_test.QedEvalTest.set_answer", "qed_eval_test.QedEvalTest.set_refs", "qed_eval.compute_scores", "print", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval.compute_scores", "print", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval_test.QedEvalTest.assertEqual", "json.loads", "json.loads", "qed_eval.load_single_line"], "methods", ["home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_answer", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_refs", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_answer", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_refs", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_scores", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_scores", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.load_single_line"], ["", "def", "test_non_strict_accuracy_not_enough_overlap", "(", "self", ")", ":", "\n", "    ", "prediction_jsonlines", "=", "[", "json", ".", "loads", "(", "example_1", ")", ",", "json", ".", "loads", "(", "example_2", ")", "]", "\n", "self", ".", "set_answer", "(", "prediction_jsonlines", "[", "0", "]", ",", "[", "(", "500", ",", "510", ")", "]", ")", "# correct answer", "\n", "self", ".", "set_refs", "(", "\n", "prediction_jsonlines", "[", "0", "]", ",", "\n", "[", "\n", "(", "(", "16", ",", "27", ")", ",", "(", "462", ",", "481", ")", ")", ",", "# one wrong ref (overlap 0.88)", "\n", "(", "(", "30", ",", "45", ")", ",", "(", "0", ",", "0", ")", ")", "\n", "]", ")", "# one wrong ref", "\n", "self", ".", "set_answer", "(", "prediction_jsonlines", "[", "1", "]", ",", "[", "(", "230", ",", "250", ")", "]", ")", "# correct answer", "\n", "self", ".", "set_refs", "(", "prediction_jsonlines", "[", "1", "]", ",", "\n", "[", "(", "(", "9", ",", "12", ")", ",", "(", "259", ",", "262", ")", ")", "]", ")", "# one wrong ref", "\n", "\n", "pred_elems", "=", "[", "qed_eval", ".", "load_single_line", "(", "l", ")", "for", "l", "in", "prediction_jsonlines", "]", "\n", "prediction_dict", "=", "{", "elem", ".", "example_id", ":", "elem", "for", "elem", "in", "pred_elems", "}", "\n", "\n", "score_dict", "=", "qed_eval", ".", "compute_scores", "(", "\n", "self", ".", "annotation_dict", ",", "prediction_dict", ",", "strict", "=", "False", ")", "\n", "print", "(", "score_dict", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"exact_match_accuracy\"", "]", ",", "0.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"pair\"", "]", "[", "0", "]", ",", "0.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"pair\"", "]", "[", "1", "]", ",", "0.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"question_mention\"", "]", "[", "0", "]", ",", "0.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"question_mention\"", "]", "[", "1", "]", ",", "0.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"context_mention\"", "]", "[", "0", "]", ",", "0.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"context_mention\"", "]", "[", "1", "]", ",", "0.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"all_mention\"", "]", "[", "0", "]", ",", "0.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"all_mention\"", "]", "[", "1", "]", ",", "0.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"answer_accuracy\"", "]", ",", "0.0", ")", "\n", "\n", "score_dict", "=", "qed_eval", ".", "compute_scores", "(", "\n", "self", ".", "annotation_dict", ",", "prediction_dict", ",", "strict", "=", "True", ")", "\n", "print", "(", "score_dict", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"exact_match_accuracy\"", "]", ",", "0.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"pair\"", "]", "[", "0", "]", ",", "0.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"pair\"", "]", "[", "1", "]", ",", "0.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"question_mention\"", "]", "[", "0", "]", ",", "0.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"question_mention\"", "]", "[", "1", "]", ",", "0.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"context_mention\"", "]", "[", "0", "]", ",", "0.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"context_mention\"", "]", "[", "1", "]", ",", "0.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"all_mention\"", "]", "[", "0", "]", ",", "0.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"all_mention\"", "]", "[", "1", "]", ",", "0.0", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"answer_accuracy\"", "]", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.test_accuracy_for_alternative_answers": [[347, 359], ["qed_eval_test.QedEvalTest.set_answer", "qed_eval_test.QedEvalTest.set_answer", "qed_eval.compute_scores", "qed_eval_test.QedEvalTest.assertEqual", "json.loads", "json.loads", "qed_eval.load_single_line"], "methods", ["home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_answer", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_answer", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_scores", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.load_single_line"], ["", "def", "test_accuracy_for_alternative_answers", "(", "self", ")", ":", "\n", "    ", "prediction_jsonlines", "=", "[", "json", ".", "loads", "(", "example_1", ")", ",", "json", ".", "loads", "(", "example_2", ")", "]", "\n", "self", ".", "set_answer", "(", "prediction_jsonlines", "[", "0", "]", ",", "\n", "[", "(", "506", ",", "537", ")", "]", ")", "# correct answer (alternative answer)", "\n", "self", ".", "set_answer", "(", "prediction_jsonlines", "[", "1", "]", ",", "[", "(", "216", ",", "243", ")", "]", ")", "# correct answer", "\n", "\n", "pred_elems", "=", "[", "qed_eval", ".", "load_single_line", "(", "l", ")", "for", "l", "in", "prediction_jsonlines", "]", "\n", "prediction_dict", "=", "{", "elem", ".", "example_id", ":", "elem", "for", "elem", "in", "pred_elems", "}", "\n", "score_dict", "=", "qed_eval", ".", "compute_scores", "(", "\n", "self", ".", "annotation_dict", ",", "prediction_dict", ",", "strict", "=", "True", ")", "\n", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"answer_accuracy\"", "]", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.test_accuracy_for_alternative_answers_with_multiple_spans": [[360, 375], ["qed_eval_test.QedEvalTest.set_answer", "qed_eval_test.QedEvalTest.set_answer", "qed_eval.compute_scores", "qed_eval_test.QedEvalTest.assertEqual", "qed_eval.compute_scores", "qed_eval_test.QedEvalTest.assertEqual", "json.loads", "json.loads", "qed_eval.load_single_line"], "methods", ["home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_answer", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval_test.QedEvalTest.set_answer", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_scores", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_scores", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.load_single_line"], ["", "def", "test_accuracy_for_alternative_answers_with_multiple_spans", "(", "self", ")", ":", "\n", "    ", "prediction_jsonlines", "=", "[", "json", ".", "loads", "(", "example_1", ")", ",", "json", ".", "loads", "(", "example_2", ")", "]", "\n", "self", ".", "set_answer", "(", "prediction_jsonlines", "[", "0", "]", ",", "\n", "[", "(", "524", ",", "536", ")", ",", "(", "505", ",", "519", ")", "]", ")", "# correct alternative, non strict", "\n", "self", ".", "set_answer", "(", "prediction_jsonlines", "[", "1", "]", ",", "[", "(", "216", ",", "243", ")", "]", ")", "# correct answer", "\n", "\n", "pred_elems", "=", "[", "qed_eval", ".", "load_single_line", "(", "l", ")", "for", "l", "in", "prediction_jsonlines", "]", "\n", "prediction_dict", "=", "{", "elem", ".", "example_id", ":", "elem", "for", "elem", "in", "pred_elems", "}", "\n", "score_dict", "=", "qed_eval", ".", "compute_scores", "(", "\n", "self", ".", "annotation_dict", ",", "prediction_dict", ",", "strict", "=", "True", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"answer_accuracy\"", "]", ",", "0.5", ")", "\n", "\n", "score_dict", "=", "qed_eval", ".", "compute_scores", "(", "\n", "self", ".", "annotation_dict", ",", "prediction_dict", ",", "strict", "=", "False", ")", "\n", "self", ".", "assertEqual", "(", "score_dict", "[", "\"answer_accuracy\"", "]", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.Entity.__hash__": [[134, 136], ["hash"], "methods", ["None"], ["def", "__hash__", "(", "self", ")", ":", "\n", "    ", "return", "hash", "(", "(", "self", ".", "start_offset", ",", "self", ".", "end_offset", ",", "self", ".", "type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.Entity.__eq__": [[137, 140], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "    ", "return", "(", "self", ".", "start_offset", "==", "other", ".", "start_offset", "and", "\n", "self", ".", "end_offset", "==", "other", ".", "end_offset", "and", "self", ".", "type", "==", "other", ".", "type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.normalize_text": [[96, 114], ["white_space_fix.lower", "qed_eval.normalize_text.replace_punctuation"], "function", ["None"], ["def", "normalize_text", "(", "text", ":", "Text", ")", "->", "Text", ":", "\n", "  ", "\"\"\"Lowercases text and removes punctuation, articles and extra whitespace.\"\"\"", "\n", "\n", "def", "remove_articles", "(", "s", ")", ":", "\n", "    ", "return", "re", ".", "sub", "(", "r'\\b(a|an|the)\\b'", ",", "' '", ",", "s", ")", "\n", "\n", "", "def", "replace_punctuation", "(", "s", ")", ":", "\n", "    ", "to_replace", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "''", "if", "ch", "in", "to_replace", "else", "ch", "for", "ch", "in", "s", ")", "\n", "\n", "", "def", "white_space_fix", "(", "s", ")", ":", "\n", "    ", "return", "' '", ".", "join", "(", "s", ".", "split", "(", ")", ")", "\n", "\n", "", "text", "=", "text", ".", "lower", "(", ")", "\n", "text", "=", "replace_punctuation", "(", "text", ")", "\n", "text", "=", "remove_articles", "(", "text", ")", "\n", "text", "=", "white_space_fix", "(", "text", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.load_answer": [[156, 168], ["output_answer.append", "qed_eval.Entity", "qed_eval.normalize_text"], "function", ["home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.normalize_text"], ["", "def", "load_answer", "(", "answer", ":", "List", "[", "Mapping", "[", "Text", ",", "Any", "]", "]", ")", "->", "List", "[", "Entity", "]", ":", "\n", "  ", "\"\"\"Loads annotated QED answer, potentially composed of multiple spans.\"\"\"", "\n", "output_answer", "=", "[", "]", "\n", "for", "a", "in", "answer", ":", "\n", "    ", "output_answer", ".", "append", "(", "\n", "Entity", "(", "\n", "text", "=", "a", "[", "'paragraph_reference'", "]", "[", "'string'", "]", ",", "\n", "normalized_text", "=", "normalize_text", "(", "a", "[", "'paragraph_reference'", "]", "[", "'string'", "]", ")", ",", "\n", "start_offset", "=", "a", "[", "'paragraph_reference'", "]", "[", "'start'", "]", ",", "\n", "end_offset", "=", "a", "[", "'paragraph_reference'", "]", "[", "'end'", "]", ",", "\n", "type", "=", "'context'", ")", ")", "\n", "", "return", "output_answer", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.load_nq_answers": [[170, 186], ["output_answer_list.append", "output_answer.append", "qed_eval.Entity", "qed_eval.normalize_text"], "function", ["home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.normalize_text"], ["", "def", "load_nq_answers", "(", "\n", "answer_list", ":", "List", "[", "List", "[", "Mapping", "[", "Text", ",", "Any", "]", "]", "]", ")", "->", "List", "[", "List", "[", "Entity", "]", "]", ":", "\n", "  ", "\"\"\"Loads annotated NQ answers, each potentially composed of multiple spans.\"\"\"", "\n", "output_answer_list", "=", "[", "]", "\n", "for", "answer", "in", "answer_list", ":", "\n", "    ", "output_answer", "=", "[", "]", "\n", "for", "a", "in", "answer", ":", "\n", "      ", "output_answer", ".", "append", "(", "\n", "Entity", "(", "\n", "text", "=", "a", "[", "'string'", "]", ",", "\n", "normalized_text", "=", "normalize_text", "(", "a", "[", "'string'", "]", ")", ",", "\n", "start_offset", "=", "a", "[", "'start'", "]", ",", "\n", "end_offset", "=", "a", "[", "'end'", "]", ",", "\n", "type", "=", "'context'", ")", ")", "\n", "", "output_answer_list", ".", "append", "(", "output_answer", ")", "\n", "", "return", "output_answer_list", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.load_aligned_entities": [[188, 233], ["qed_eval.Entity", "aligned_nps.append", "absl.logging.error", "ValueError", "qed_eval.Entity", "qed_eval.Entity", "qed_eval.normalize_text", "absl.logging.error", "ValueError", "qed_eval.normalize_text"], "function", ["home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.normalize_text", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.normalize_text"], ["", "def", "load_aligned_entities", "(", "alignment_dict", ":", "List", "[", "Mapping", "[", "Text", ",", "Any", "]", "]", ",", "\n", "question_text", ":", "Text", ",", "\n", "context_text", ":", "Text", ")", "->", "List", "[", "Tuple", "[", "Entity", ",", "Entity", "]", "]", ":", "\n", "  ", "\"\"\"Loads aligned entities from json.\"\"\"", "\n", "aligned_nps", "=", "[", "]", "\n", "for", "single_np_alignment", "in", "alignment_dict", ":", "\n", "    ", "q_entity_text", "=", "single_np_alignment", "[", "'question_reference'", "]", "[", "'string'", "]", "\n", "q_entity_offset", "=", "(", "single_np_alignment", "[", "'question_reference'", "]", "[", "'start'", "]", ",", "\n", "single_np_alignment", "[", "'question_reference'", "]", "[", "'end'", "]", ")", "\n", "c_entity_text", "=", "single_np_alignment", "[", "'sentence_reference'", "]", "[", "'string'", "]", "\n", "c_entity_offset", "=", "(", "single_np_alignment", "[", "'sentence_reference'", "]", "[", "'start'", "]", ",", "\n", "single_np_alignment", "[", "'sentence_reference'", "]", "[", "'end'", "]", ")", "\n", "if", "q_entity_text", "!=", "question_text", "[", "q_entity_offset", "[", "0", "]", ":", "q_entity_offset", "[", "1", "]", "]", ":", "\n", "      ", "logging", ".", "error", "(", "\n", "'Question entity offset not proper. from text: %s, from byte offset %s'", ",", "\n", "q_entity_text", ",", "question_text", "[", "q_entity_offset", "[", "0", "]", ":", "q_entity_offset", "[", "1", "]", "]", ")", "\n", "raise", "ValueError", "(", ")", "\n", "\n", "", "question_entity", "=", "Entity", "(", "\n", "text", "=", "question_text", "[", "q_entity_offset", "[", "0", "]", ":", "q_entity_offset", "[", "1", "]", "]", ",", "\n", "normalized_text", "=", "normalize_text", "(", "q_entity_text", ")", ",", "\n", "start_offset", "=", "q_entity_offset", "[", "0", "]", ",", "\n", "end_offset", "=", "q_entity_offset", "[", "1", "]", ",", "\n", "type", "=", "'question'", ")", "\n", "if", "c_entity_offset", "[", "0", "]", "!=", "-", "1", ":", "\n", "      ", "if", "c_entity_text", "!=", "context_text", "[", "c_entity_offset", "[", "0", "]", ":", "c_entity_offset", "[", "1", "]", "]", ":", "\n", "        ", "logging", ".", "error", "(", "\n", "'Context entity offset not proper. from text: %s, from byte offset %s'", ",", "\n", "c_entity_text", ",", "context_text", "[", "c_entity_offset", "[", "0", "]", ":", "c_entity_offset", "[", "1", "]", "]", ")", "\n", "raise", "ValueError", "(", ")", "\n", "", "doc_entity", "=", "Entity", "(", "\n", "text", "=", "context_text", "[", "c_entity_offset", "[", "0", "]", ":", "c_entity_offset", "[", "1", "]", "]", ",", "\n", "normalized_text", "=", "normalize_text", "(", "c_entity_text", ")", ",", "\n", "start_offset", "=", "c_entity_offset", "[", "0", "]", ",", "\n", "end_offset", "=", "c_entity_offset", "[", "1", "]", ",", "\n", "type", "=", "'context'", ")", "\n", "", "else", ":", "# this is a bridging linguistic context instance.", "\n", "      ", "doc_entity", "=", "Entity", "(", "\n", "text", "=", "''", ",", "\n", "start_offset", "=", "-", "1", ",", "\n", "end_offset", "=", "-", "1", ",", "\n", "type", "=", "'context'", ",", "\n", "normalized_text", "=", "''", ")", "\n", "", "aligned_nps", ".", "append", "(", "(", "question_entity", ",", "doc_entity", ")", ")", "\n", "", "return", "aligned_nps", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.load_single_line": [[235, 248], ["qed_eval.QEDExample", "qed_eval.load_answer", "qed_eval.load_nq_answers", "qed_eval.load_aligned_entities", "elem[].get", "elem[].get"], "function", ["home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.load_answer", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.load_nq_answers", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.load_aligned_entities"], ["", "def", "load_single_line", "(", "elem", ":", "Mapping", "[", "Text", ",", "Any", "]", ")", "->", "QEDExample", ":", "\n", "  ", "\"\"\"Loads a QEDExample from json.\"\"\"", "\n", "return", "QEDExample", "(", "\n", "example_id", "=", "elem", "[", "'example_id'", "]", ",", "\n", "title", "=", "elem", "[", "'title_text'", "]", ",", "\n", "question", "=", "elem", "[", "'question_text'", "]", ",", "\n", "answer", "=", "load_answer", "(", "elem", "[", "'annotation'", "]", ".", "get", "(", "'answer'", ",", "[", "]", ")", ")", ",", "\n", "nq_answers", "=", "load_nq_answers", "(", "elem", "[", "'original_nq_answers'", "]", ")", ",", "\n", "aligned_nps", "=", "load_aligned_entities", "(", "\n", "elem", "[", "'annotation'", "]", ".", "get", "(", "'referential_equalities'", ",", "[", "]", ")", ",", "\n", "elem", "[", "'question_text'", "]", ",", "\n", "elem", "[", "'paragraph_text'", "]", ")", ",", "\n", "explanation_type", "=", "elem", "[", "'annotation'", "]", "[", "'explanation_type'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.load_data": [[250, 266], ["absl.logging.info", "open", "json.loads", "qed_eval.load_single_line"], "function", ["home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.load_single_line"], ["", "def", "load_data", "(", "fname", ":", "Text", ")", "->", "Mapping", "[", "int", ",", "QEDExample", "]", ":", "\n", "  ", "\"\"\"Loads jsonl data and outputs a dict mapping example_id to QEDExample.\"\"\"", "\n", "output_dict", "=", "{", "}", "\n", "incorrectly_formatted", "=", "0", "\n", "with", "open", "(", "fname", ")", "as", "f", ":", "\n", "    ", "for", "line", "in", "f", ":", "\n", "      ", "try", ":", "\n", "        ", "elem", "=", "json", ".", "loads", "(", "line", ")", "\n", "example", "=", "load_single_line", "(", "elem", ")", "\n", "if", "example", ".", "explanation_type", "==", "'single_sentence'", ":", "\n", "          ", "output_dict", "[", "example", ".", "example_id", "]", "=", "example", "\n", "", "", "except", "ValueError", ":", "\n", "        ", "incorrectly_formatted", "+=", "1", "\n", "", "", "", "logging", ".", "info", "(", "'%d examples not correctly formatted and skipped.'", ",", "\n", "incorrectly_formatted", ")", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.overlap": [[268, 285], ["abs", "abs", "abs"], "function", ["None"], ["", "def", "overlap", "(", "ent1", ":", "Entity", ",", "ent2", ":", "Entity", ")", "->", "bool", ":", "\n", "  ", "\"\"\"Returns whether two entities overlap at least with 90% F1.\"\"\"", "\n", "if", "(", "ent1", ".", "start_offset", "==", "-", "1", "or", "ent1", ".", "end_offset", "==", "-", "1", "or", "\n", "ent2", ".", "start_offset", "==", "-", "1", "or", "ent2", ".", "end_offset", "==", "-", "1", ")", ":", "\n", "    ", "return", "(", "ent1", ".", "start_offset", ",", "ent1", ".", "end_offset", ",", "ent2", ".", "start_offset", ",", "\n", "ent2", ".", "end_offset", ")", "==", "(", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "\n", "# Compute F1 as follows:", "\n", "#   F1 = tp / (tp + (fp + fn) / 2)", "\n", "#   [------ ent1 --------]", "\n", "#             [------- ent2 -----]", "\n", "#   [-- fn --][--- tp ---][- fp -]", "\n", "", "tp", "=", "abs", "(", "ent1", ".", "end_offset", "-", "ent2", ".", "start_offset", ")", "\n", "fn", "=", "abs", "(", "ent2", ".", "start_offset", "-", "ent1", ".", "start_offset", ")", "\n", "fp", "=", "abs", "(", "ent2", ".", "end_offset", "-", "ent1", ".", "end_offset", ")", "\n", "f1", "=", "tp", "/", "(", "tp", "+", "(", "fp", "+", "fn", ")", "/", "2", ")", "if", "tp", "else", "0.0", "\n", "return", "f1", ">=", "MIN_F1_FOR_NON_STRICT_OVERLAP", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_mention_score": [[287, 312], ["set", "set", "len", "len", "len", "len", "qed_eval.overlap"], "function", ["home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.overlap"], ["", "def", "compute_mention_score", "(", "annotation", ":", "Collection", "[", "Entity", "]", ",", "\n", "prediction", ":", "Collection", "[", "Entity", "]", ",", "\n", "strict", ":", "bool", ")", "->", "Tuple", "[", "float", ",", "float", ",", "float", "]", ":", "\n", "  ", "\"\"\"Computes mention identification performance.\"\"\"", "\n", "if", "strict", ":", "\n", "    ", "annot_entities", "=", "set", "(", "[", "ent", "for", "ent", "in", "annotation", "if", "ent", ".", "start_offset", "!=", "-", "1", "]", ")", "\n", "pred_entities", "=", "set", "(", "[", "ent", "for", "ent", "in", "prediction", "if", "ent", ".", "start_offset", "!=", "-", "1", "]", ")", "\n", "tp", "=", "len", "(", "annot_entities", "&", "pred_entities", ")", "\n", "tn", "=", "len", "(", "annot_entities", "-", "pred_entities", ")", "\n", "fn", "=", "len", "(", "pred_entities", "-", "annot_entities", ")", "\n", "", "else", ":", "\n", "    ", "tp", ",", "tn", ",", "fn", "=", "0", ",", "0", ",", "0", "\n", "for", "annot_entity", "in", "annotation", ":", "\n", "      ", "found", "=", "False", "\n", "for", "pred_entity", "in", "prediction", ":", "\n", "        ", "if", "pred_entity", ".", "normalized_text", "==", "annot_entity", ".", "normalized_text", ":", "\n", "          ", "if", "overlap", "(", "pred_entity", ",", "annot_entity", ")", ":", "\n", "            ", "found", "=", "True", "\n", "break", "\n", "", "", "", "if", "found", ":", "\n", "        ", "tp", "+=", "1", "\n", "", "else", ":", "\n", "        ", "tn", "+=", "1", "\n", "", "", "fn", "=", "len", "(", "prediction", ")", "-", "tp", "\n", "", "return", "tp", ",", "tn", ",", "fn", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_alignment_score": [[314, 340], ["set", "set", "len", "len", "len", "len", "qed_eval.overlap", "qed_eval.overlap"], "function", ["home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.overlap", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.overlap"], ["", "def", "compute_alignment_score", "(", "annotation", ":", "QEDExample", ",", "prediction", ":", "QEDExample", ",", "\n", "strict", ":", "bool", ")", "->", "Tuple", "[", "float", ",", "float", ",", "float", "]", ":", "\n", "  ", "\"\"\"Computes the alignment match score.\"\"\"", "\n", "if", "strict", ":", "\n", "    ", "annot_pairs", "=", "set", "(", "annotation", ".", "aligned_nps", ")", "\n", "pred_pairs", "=", "set", "(", "prediction", ".", "aligned_nps", ")", "\n", "tp", "=", "len", "(", "annot_pairs", "&", "pred_pairs", ")", "\n", "tn", "=", "len", "(", "annot_pairs", "-", "pred_pairs", ")", "\n", "fn", "=", "len", "(", "pred_pairs", "-", "annot_pairs", ")", "\n", "", "else", ":", "\n", "    ", "tp", ",", "tn", ",", "fn", "=", "0", ",", "0", ",", "0", "\n", "for", "annot_q_ent", ",", "annot_doc_ent", "in", "annotation", ".", "aligned_nps", ":", "\n", "      ", "found", "=", "False", "\n", "for", "pred_q_ent", ",", "pred_doc_ent", "in", "prediction", ".", "aligned_nps", ":", "\n", "        ", "if", "pred_q_ent", ".", "normalized_text", "==", "annot_q_ent", ".", "normalized_text", ":", "\n", "          ", "if", "annot_doc_ent", ".", "normalized_text", "==", "pred_doc_ent", ".", "normalized_text", ":", "\n", "            ", "if", "overlap", "(", "pred_q_ent", ",", "annot_q_ent", ")", ":", "\n", "              ", "if", "overlap", "(", "pred_doc_ent", ",", "annot_doc_ent", ")", ":", "\n", "                ", "found", "=", "True", "\n", "break", "\n", "", "", "", "", "", "if", "found", ":", "\n", "        ", "tp", "+=", "1", "\n", "", "else", ":", "\n", "        ", "tn", "+=", "1", "\n", "", "", "fn", "=", "len", "(", "prediction", ".", "aligned_nps", ")", "-", "tp", "\n", "", "return", "tp", ",", "tn", ",", "fn", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_prf1": [[342, 350], ["None"], "function", ["None"], ["", "def", "compute_prf1", "(", "tp", ",", "tn", ",", "fn", ")", "->", "Tuple", "[", "float", ",", "float", ",", "float", "]", ":", "\n", "  ", "\"\"\"Computes precistion, recall and f1 from true/false positives/negatives.\"\"\"", "\n", "if", "tp", ">", "0", ":", "\n", "    ", "p", ",", "r", "=", "tp", "/", "(", "tp", "+", "fn", ")", ",", "tp", "/", "(", "tp", "+", "tn", ")", "\n", "f1", "=", "2", "*", "p", "*", "r", "/", "(", "p", "+", "r", ")", "\n", "", "else", ":", "\n", "    ", "p", ",", "r", ",", "f1", "=", "0.0", ",", "0.0", ",", "0.0", "\n", "", "return", "p", ",", "r", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.is_permutation_matrix": [[352, 356], ["all", "sum", "len", "sum", "any"], "function", ["None"], ["", "def", "is_permutation_matrix", "(", "matrix", ":", "List", "[", "List", "[", "bool", "]", "]", ")", "->", "bool", ":", "\n", "  ", "\"\"\"Returns whether the given boolean matrix is a permutation matrix.\"\"\"", "\n", "return", "(", "all", "(", "sum", "(", "v", ")", "==", "1", "for", "v", "in", "matrix", ")", "and", "\n", "sum", "(", "any", "(", "v", ")", "for", "v", "in", "matrix", ")", "==", "len", "(", "matrix", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_answer_accuracy": [[358, 376], ["qed_eval.is_permutation_matrix", "all_matches.append", "all_matches[].append", "all_matches[].append", "qed_eval.overlap"], "function", ["home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.is_permutation_matrix", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.overlap"], ["", "def", "compute_answer_accuracy", "(", "annotation", ":", "QEDExample", ",", "prediction", ":", "QEDExample", ",", "\n", "strict", ":", "bool", ")", "->", "float", ":", "\n", "  ", "\"\"\"Checks whether the predicted answer matches any of the annotated ones.\"\"\"", "\n", "for", "annot_answer", "in", "[", "annotation", ".", "answer", "]", "+", "annotation", ".", "nq_answers", ":", "\n", "    ", "all_matches", "=", "[", "]", "\n", "for", "a", "in", "annot_answer", ":", "\n", "      ", "all_matches", ".", "append", "(", "[", "]", ")", "\n", "for", "p", "in", "prediction", ".", "answer", ":", "\n", "        ", "if", "strict", ":", "\n", "          ", "all_matches", "[", "-", "1", "]", ".", "append", "(", "a", "==", "p", ")", "\n", "", "else", ":", "\n", "          ", "all_matches", "[", "-", "1", "]", ".", "append", "(", "overlap", "(", "a", ",", "p", ")", ")", "\n", "\n", "# The all_matches matrix should basically a permutation matrix.", "\n", "", "", "", "if", "is_permutation_matrix", "(", "all_matches", ")", ":", "\n", "      ", "return", "1.0", "\n", "\n", "", "", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_scores": [[378, 449], ["qed_eval.compute_prf1", "qed_eval.compute_prf1", "qed_eval.compute_prf1", "qed_eval.compute_prf1", "absl.logging.info", "absl.logging.info", "absl.logging.info", "absl.logging.info", "absl.logging.info", "absl.logging.info", "qed_eval.compute_mention_score", "qed_eval.compute_mention_score", "qed_eval.compute_alignment_score", "qed_eval.compute_answer_accuracy", "len"], "function", ["home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_prf1", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_prf1", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_prf1", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_prf1", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_mention_score", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_mention_score", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_alignment_score", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_answer_accuracy"], ["", "def", "compute_scores", "(", "\n", "annotation_dict", ":", "Mapping", "[", "int", ",", "\n", "QEDExample", "]", ",", "prediction_dict", ":", "Mapping", "[", "int", ",", "\n", "QEDExample", "]", ",", "\n", "strict", ":", "bool", ")", "->", "Mapping", "[", "Text", ",", "Union", "[", "float", ",", "Tuple", "[", "float", ",", "float", ",", "float", "]", "]", "]", ":", "\n", "  ", "\"\"\"Compute scores.\"\"\"", "\n", "score_dict", "=", "{", "}", "\n", "total_q_tp", ",", "total_q_tn", ",", "total_q_fn", "=", "0", ",", "0", ",", "0", "\n", "total_c_tp", ",", "total_c_tn", ",", "total_c_fn", "=", "0", ",", "0", ",", "0", "\n", "total_pair_tp", ",", "total_pair_tn", ",", "total_pair_fn", "=", "0", ",", "0", ",", "0", "\n", "completely_correct_example_count", "=", "0.0", "\n", "total_correct_answers", "=", "0", "\n", "total_answers", "=", "0", "\n", "for", "example_id", "in", "annotation_dict", ":", "\n", "    ", "if", "example_id", "not", "in", "prediction_dict", ":", "\n", "      ", "logging", ".", "info", "(", "'Missing prediction for id %d'", ",", "example_id", ")", "\n", "", "else", ":", "\n", "      ", "prediction", "=", "prediction_dict", "[", "example_id", "]", "\n", "annotation", "=", "annotation_dict", "[", "example_id", "]", "\n", "q_tp", ",", "q_tn", ",", "q_fn", "=", "compute_mention_score", "(", "\n", "[", "nps", "[", "0", "]", "for", "nps", "in", "annotation", ".", "aligned_nps", "]", ",", "\n", "[", "nps", "[", "0", "]", "for", "nps", "in", "prediction", ".", "aligned_nps", "]", ",", "strict", ")", "\n", "c_tp", ",", "c_tn", ",", "c_fn", "=", "compute_mention_score", "(", "\n", "[", "nps", "[", "1", "]", "for", "nps", "in", "annotation", ".", "aligned_nps", "]", ",", "\n", "[", "nps", "[", "1", "]", "for", "nps", "in", "prediction", ".", "aligned_nps", "]", ",", "strict", ")", "\n", "pair_tp", ",", "pair_tn", ",", "pair_fn", "=", "compute_alignment_score", "(", "\n", "annotation", ",", "prediction", ",", "strict", ")", "\n", "total_correct_answers", "+=", "compute_answer_accuracy", "(", "annotation", ",", "prediction", ",", "\n", "strict", ")", "\n", "total_answers", "+=", "1", "\n", "if", "pair_tn", "+", "pair_fn", "==", "0", ":", "\n", "        ", "completely_correct_example_count", "+=", "1", "\n", "", "total_q_tp", "+=", "q_tp", "\n", "total_q_tn", "+=", "q_tn", "\n", "total_q_fn", "+=", "q_fn", "\n", "total_c_tp", "+=", "c_tp", "\n", "total_c_tn", "+=", "c_tn", "\n", "total_c_fn", "+=", "c_fn", "\n", "total_pair_tp", "+=", "pair_tp", "\n", "total_pair_tn", "+=", "pair_tn", "\n", "total_pair_fn", "+=", "pair_fn", "\n", "", "", "question_mention_p", ",", "question_mention_r", ",", "question_mention_f1", "=", "compute_prf1", "(", "\n", "total_q_tp", ",", "total_q_tn", ",", "total_q_fn", ")", "\n", "context_mention_p", ",", "context_mention_r", ",", "context_mention_f1", "=", "compute_prf1", "(", "\n", "total_c_tp", ",", "total_c_tn", ",", "total_c_fn", ")", "\n", "mention_p", ",", "mention_r", ",", "mention_f1", "=", "compute_prf1", "(", "total_q_tp", "+", "total_c_tp", ",", "\n", "total_q_tn", "+", "total_c_tn", ",", "\n", "total_q_fn", "+", "total_c_fn", ")", "\n", "pair_p", ",", "pair_r", ",", "pair_f1", "=", "compute_prf1", "(", "total_pair_tp", ",", "total_pair_tn", ",", "\n", "total_pair_fn", ")", "\n", "logging", ".", "info", "(", "'# of examples completely correct: %d'", ",", "\n", "completely_correct_example_count", ")", "\n", "score_dict", "=", "{", "\n", "'exact_match_accuracy'", ":", "\n", "completely_correct_example_count", "/", "len", "(", "annotation_dict", ")", ",", "\n", "'question_mention'", ":", "\n", "(", "question_mention_p", ",", "question_mention_r", ",", "question_mention_f1", ")", ",", "\n", "'context_mention'", ":", "\n", "(", "context_mention_p", ",", "context_mention_r", ",", "context_mention_f1", ")", ",", "\n", "'all_mention'", ":", "(", "mention_p", ",", "mention_r", ",", "mention_f1", ")", ",", "\n", "'pair'", ":", "(", "pair_p", ",", "pair_r", ",", "pair_f1", ")", ",", "\n", "'answer_accuracy'", ":", "(", "total_correct_answers", "/", "total_answers", ")", "\n", "}", "\n", "logging", ".", "info", "(", "'Question mention P/R/F1 %.4f %.4f %.4f'", ",", "question_mention_p", ",", "\n", "question_mention_r", ",", "question_mention_f1", ")", "\n", "logging", ".", "info", "(", "'Context mention P/R/F1 %.4f %.4f %.4f'", ",", "context_mention_p", ",", "\n", "context_mention_r", ",", "context_mention_f1", ")", "\n", "logging", ".", "info", "(", "'Both Mention P/R/F1 %.4f %.4f %.4f'", ",", "mention_p", ",", "mention_r", ",", "\n", "mention_f1", ")", "\n", "logging", ".", "info", "(", "'Pair P/R/F1 %.4f %.4f %.4f'", ",", "pair_p", ",", "pair_r", ",", "pair_f1", ")", "\n", "return", "score_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.main": [[451, 460], ["qed_eval.load_data", "absl.logging.info", "qed_eval.load_data", "absl.logging.info", "qed_eval.compute_scores", "absl.logging.info", "len", "absl.app.UsageError", "len", "len"], "function", ["home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.load_data", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.load_data", "home.repos.pwc.inspect_result.google-research-datasets_QED.None.qed_eval.compute_scores"], ["", "def", "main", "(", "argv", ")", ":", "\n", "  ", "if", "len", "(", "argv", ")", ">", "1", ":", "\n", "    ", "raise", "app", ".", "UsageError", "(", "'Too many command-line arguments.'", ")", "\n", "", "annotation_dict", "=", "load_data", "(", "FLAGS", ".", "annotation", ")", "\n", "logging", ".", "info", "(", "'%d examples in annotation.'", ",", "len", "(", "annotation_dict", ")", ")", "\n", "prediction_dict", "=", "load_data", "(", "FLAGS", ".", "prediction", ")", "\n", "logging", ".", "info", "(", "'%d examples in predicton.'", ",", "len", "(", "prediction_dict", ")", ")", "\n", "score_dict", "=", "compute_scores", "(", "annotation_dict", ",", "prediction_dict", ",", "FLAGS", ".", "strict", ")", "\n", "logging", ".", "info", "(", "score_dict", ")", "\n", "\n"]]}