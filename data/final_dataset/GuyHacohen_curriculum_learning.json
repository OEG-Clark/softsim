{"home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_reproduce_paper.curriculum_small_mammals": [[13, 36], ["argparse.Namespace", "main_train_networks.run_expriment"], "function", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.run_expriment"], ["def", "curriculum_small_mammals", "(", "repeats", ",", "output_path", "=", "\"\"", ")", ":", "\n", "\n", "    ", "args", "=", "Namespace", "(", "dataset", "=", "\"cifar100_subset_16\"", ",", "\n", "model", "=", "'stVGG'", ",", "\n", "output_path", "=", "output_path", ",", "\n", "verbose", "=", "False", ",", "\n", "optimizer", "=", "\"sgd\"", ",", "\n", "curriculum", "=", "\"curriculum\"", ",", "\n", "batch_size", "=", "100", ",", "\n", "num_epochs", "=", "140", ",", "\n", "learning_rate", "=", "0.03", ",", "\n", "lr_decay_rate", "=", "1.1", ",", "\n", "minimal_lr", "=", "1e-4", ",", "\n", "lr_batch_size", "=", "100", ",", "\n", "batch_increase", "=", "100", ",", "\n", "increase_amount", "=", "1.9", ",", "\n", "starting_percent", "=", "0.04", ",", "\n", "order", "=", "\"inception\"", ",", "\n", "test_each", "=", "50", ",", "\n", "repeats", "=", "repeats", ",", "\n", "balance", "=", "True", ")", "\n", "\n", "run_expriment", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_reproduce_paper.vanilla_small_mammals": [[38, 61], ["argparse.Namespace", "main_train_networks.run_expriment"], "function", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.run_expriment"], ["", "def", "vanilla_small_mammals", "(", "repeats", ",", "output_path", "=", "\"\"", ")", ":", "\n", "\n", "    ", "args", "=", "Namespace", "(", "dataset", "=", "\"cifar100_subset_16\"", ",", "\n", "model", "=", "'stVGG'", ",", "\n", "output_path", "=", "output_path", ",", "\n", "verbose", "=", "False", ",", "\n", "optimizer", "=", "\"sgd\"", ",", "\n", "curriculum", "=", "\"vanilla\"", ",", "\n", "batch_size", "=", "100", ",", "\n", "num_epochs", "=", "140", ",", "\n", "learning_rate", "=", "0.035", ",", "\n", "lr_decay_rate", "=", "1.8", ",", "\n", "minimal_lr", "=", "1e-4", ",", "\n", "lr_batch_size", "=", "600", ",", "\n", "batch_increase", "=", "100", ",", "\n", "increase_amount", "=", "1.9", ",", "\n", "starting_percent", "=", "0.04", ",", "\n", "order", "=", "\"inception\"", ",", "\n", "test_each", "=", "50", ",", "\n", "repeats", "=", "repeats", ",", "\n", "balance", "=", "True", ")", "\n", "\n", "run_expriment", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_reproduce_paper.anti_curriculum_small_mammals": [[63, 86], ["argparse.Namespace", "main_train_networks.run_expriment"], "function", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.run_expriment"], ["", "def", "anti_curriculum_small_mammals", "(", "repeats", ",", "output_path", "=", "\"\"", ")", ":", "\n", "\n", "    ", "args", "=", "Namespace", "(", "dataset", "=", "\"cifar100_subset_16\"", ",", "\n", "model", "=", "'stVGG'", ",", "\n", "output_path", "=", "output_path", ",", "\n", "verbose", "=", "False", ",", "\n", "optimizer", "=", "\"sgd\"", ",", "\n", "curriculum", "=", "\"anti\"", ",", "\n", "batch_size", "=", "100", ",", "\n", "num_epochs", "=", "140", ",", "\n", "learning_rate", "=", "0.025", ",", "\n", "lr_decay_rate", "=", "1.1", ",", "\n", "minimal_lr", "=", "1e-4", ",", "\n", "lr_batch_size", "=", "200", ",", "\n", "batch_increase", "=", "100", ",", "\n", "increase_amount", "=", "1.9", ",", "\n", "starting_percent", "=", "0.04", ",", "\n", "order", "=", "\"inception\"", ",", "\n", "test_each", "=", "50", ",", "\n", "repeats", "=", "repeats", ",", "\n", "balance", "=", "True", ")", "\n", "\n", "run_expriment", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_reproduce_paper.random_small_mammals": [[88, 111], ["argparse.Namespace", "main_train_networks.run_expriment"], "function", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.run_expriment"], ["", "def", "random_small_mammals", "(", "repeats", ",", "output_path", "=", "\"\"", ")", ":", "\n", "\n", "    ", "args", "=", "Namespace", "(", "dataset", "=", "\"cifar100_subset_16\"", ",", "\n", "model", "=", "'stVGG'", ",", "\n", "output_path", "=", "output_path", ",", "\n", "verbose", "=", "False", ",", "\n", "optimizer", "=", "\"sgd\"", ",", "\n", "curriculum", "=", "\"random\"", ",", "\n", "batch_size", "=", "100", ",", "\n", "num_epochs", "=", "140", ",", "\n", "learning_rate", "=", "0.025", ",", "\n", "lr_decay_rate", "=", "1.3", ",", "\n", "minimal_lr", "=", "1e-4", ",", "\n", "lr_batch_size", "=", "400", ",", "\n", "batch_increase", "=", "100", ",", "\n", "increase_amount", "=", "1.9", ",", "\n", "starting_percent", "=", "0.04", ",", "\n", "order", "=", "\"inception\"", ",", "\n", "test_each", "=", "50", ",", "\n", "repeats", "=", "repeats", ",", "\n", "balance", "=", "True", ")", "\n", "\n", "run_expriment", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_reproduce_paper.vanilla_cifar10_st_vgg": [[113, 134], ["argparse.Namespace", "main_train_networks.run_expriment"], "function", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.run_expriment"], ["", "def", "vanilla_cifar10_st_vgg", "(", "repeats", ",", "output_path", "=", "\"\"", ")", ":", "\n", "    ", "args", "=", "Namespace", "(", "dataset", "=", "\"cifar10\"", ",", "\n", "model", "=", "'stVGG'", ",", "\n", "output_path", "=", "output_path", ",", "\n", "verbose", "=", "True", ",", "\n", "optimizer", "=", "\"sgd\"", ",", "\n", "curriculum", "=", "\"vanilla\"", ",", "\n", "batch_size", "=", "100", ",", "\n", "num_epochs", "=", "140", ",", "\n", "learning_rate", "=", "0.12", ",", "\n", "lr_decay_rate", "=", "1.1", ",", "\n", "minimal_lr", "=", "1e-3", ",", "\n", "lr_batch_size", "=", "700", ",", "\n", "batch_increase", "=", "100", ",", "\n", "increase_amount", "=", "1.9", ",", "\n", "starting_percent", "=", "0.04", ",", "\n", "order", "=", "\"inception\"", ",", "\n", "test_each", "=", "50", ",", "\n", "repeats", "=", "repeats", ",", "\n", "balance", "=", "True", ")", "\n", "run_expriment", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_reproduce_paper.curriculum_cifar10_st_vgg": [[135, 157], ["argparse.Namespace", "main_train_networks.run_expriment"], "function", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.run_expriment"], ["", "def", "curriculum_cifar10_st_vgg", "(", "repeats", ",", "output_path", "=", "\"\"", ")", ":", "\n", "    ", "args", "=", "Namespace", "(", "dataset", "=", "\"cifar10\"", ",", "\n", "model", "=", "'stVGG'", ",", "\n", "output_path", "=", "output_path", ",", "\n", "verbose", "=", "True", ",", "\n", "optimizer", "=", "\"sgd\"", ",", "\n", "curriculum", "=", "\"curriculum\"", ",", "\n", "batch_size", "=", "100", ",", "\n", "num_epochs", "=", "140", ",", "\n", "learning_rate", "=", "0.12", ",", "\n", "lr_decay_rate", "=", "1.1", ",", "\n", "minimal_lr", "=", "1e-3", ",", "\n", "lr_batch_size", "=", "700", ",", "\n", "batch_increase", "=", "100", ",", "\n", "increase_amount", "=", "1.9", ",", "\n", "starting_percent", "=", "0.04", ",", "\n", "order", "=", "\"inception\"", ",", "\n", "test_each", "=", "50", ",", "\n", "repeats", "=", "repeats", ",", "\n", "balance", "=", "True", ")", "\n", "\n", "run_expriment", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_reproduce_paper.vanilla_cifar100_st_vgg": [[158, 181], ["argparse.Namespace", "main_train_networks.run_expriment"], "function", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.run_expriment"], ["", "def", "vanilla_cifar100_st_vgg", "(", "repeats", ",", "output_path", "=", "\"\"", ")", ":", "\n", "\n", "    ", "args", "=", "Namespace", "(", "dataset", "=", "\"cifar100\"", ",", "\n", "model", "=", "'stVGG'", ",", "\n", "output_path", "=", "output_path", ",", "\n", "verbose", "=", "True", ",", "\n", "optimizer", "=", "\"sgd\"", ",", "\n", "curriculum", "=", "\"vanilla\"", ",", "\n", "batch_size", "=", "100", ",", "\n", "num_epochs", "=", "140", ",", "\n", "learning_rate", "=", "0.12", ",", "\n", "lr_decay_rate", "=", "1.1", ",", "\n", "minimal_lr", "=", "1e-3", ",", "\n", "lr_batch_size", "=", "400", ",", "\n", "batch_increase", "=", "100", ",", "\n", "increase_amount", "=", "1.9", ",", "\n", "starting_percent", "=", "0.04", ",", "\n", "order", "=", "\"inception\"", ",", "\n", "test_each", "=", "50", ",", "\n", "repeats", "=", "repeats", ",", "\n", "balance", "=", "True", ")", "\n", "\n", "run_expriment", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_reproduce_paper.curriculum_cifar100_st_vgg": [[182, 204], ["argparse.Namespace", "main_train_networks.run_expriment"], "function", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.run_expriment"], ["", "def", "curriculum_cifar100_st_vgg", "(", "repeats", ",", "output_path", "=", "\"\"", ")", ":", "\n", "    ", "args", "=", "Namespace", "(", "dataset", "=", "\"cifar100\"", ",", "\n", "model", "=", "'stVGG'", ",", "\n", "output_path", "=", "output_path", ",", "\n", "verbose", "=", "True", ",", "\n", "optimizer", "=", "\"sgd\"", ",", "\n", "curriculum", "=", "\"curriculum\"", ",", "\n", "batch_size", "=", "100", ",", "\n", "num_epochs", "=", "140", ",", "\n", "learning_rate", "=", "0.12", ",", "\n", "lr_decay_rate", "=", "1.1", ",", "\n", "minimal_lr", "=", "1e-3", ",", "\n", "lr_batch_size", "=", "400", ",", "\n", "batch_increase", "=", "100", ",", "\n", "increase_amount", "=", "1.9", ",", "\n", "starting_percent", "=", "0.04", ",", "\n", "order", "=", "\"inception\"", ",", "\n", "test_each", "=", "50", ",", "\n", "repeats", "=", "repeats", ",", "\n", "balance", "=", "True", ")", "\n", "\n", "run_expriment", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.ModelLib.ModelLib.build_classifier_model": [[8, 10], ["None"], "methods", ["None"], ["    ", "def", "build_classifier_model", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.ModelLib.ModelLib.corriculum_svm_based_training_data": [[12, 33], ["transfer_learning.get_transfer_values_inception", "transfer_learning.get_svm_scores", "transfer_learning.rank_data_according_to_score", "list", "sum", "len", "int", "zip", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.transfer_learning.get_transfer_values_inception", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.transfer_learning.get_svm_scores", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.transfer_learning.rank_data_according_to_score"], ["", "def", "corriculum_svm_based_training_data", "(", "self", ",", "dataset", ",", "anti_corriculum", "=", "False", ",", "random", "=", "False", ")", ":", "\n", "        ", "(", "transfer_values_train", ",", "transfer_values_test", ")", "=", "transfer_learning", ".", "get_transfer_values_inception", "(", "dataset", ")", "\n", "train_scores", ",", "test_scores", "=", "transfer_learning", ".", "get_svm_scores", "(", "transfer_values_train", ",", "dataset", ".", "y_train", ",", "\n", "transfer_values_test", ",", "dataset", ".", "y_test", ",", "dataset", ")", "\n", "order", "=", "transfer_learning", ".", "rank_data_according_to_score", "(", "train_scores", ",", "dataset", ".", "y_train", ",", "reverse", "=", "anti_corriculum", ",", "\n", "random", "=", "random", ")", "\n", "size_data", "=", "dataset", ".", "x_train", ".", "shape", "[", "0", "]", "\n", "epochs_each_data", "=", "10", "\n", "jumps", "=", "0.1", "\n", "data_sizes", "=", "list", "(", "int", "(", "size_data", "*", "frac", ")", "for", "frac", "in", "(", "np", ".", "arange", "(", "0", ",", "1", ",", "jumps", ")", "+", "jumps", ")", ")", "\n", "epochs", "=", "[", "epochs_each_data", "]", "*", "len", "(", "data_sizes", ")", "\n", "total_batchs", "=", "sum", "(", "epoch", "*", "data_size", "for", "epoch", ",", "data_size", "in", "zip", "(", "epochs", ",", "data_sizes", ")", ")", "\n", "total_batchs_original", "=", "100", "*", "size_data", "\n", "epochs", "[", "-", "1", "]", "+=", "(", "total_batchs_original", "-", "total_batchs", ")", "//", "size_data", "\n", "\n", "def", "data_function", "(", "x", ",", "y", ",", "cur_phase", ",", "num_phases", ")", ":", "\n", "            ", "data_limit", "=", "data_sizes", "[", "cur_phase", "]", "\n", "new_data", "=", "order", "[", ":", "data_limit", "]", "\n", "return", "x", "[", "new_data", ",", ":", ",", ":", ",", ":", "]", ",", "y", "[", "new_data", ",", ":", "]", "\n", "\n", "", "return", "epochs", ",", "data_function", "\n", "", "", ""]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.cache.cache": [[30, 74], ["os.path.exists", "print", "fn", "print", "open", "pickle.load", "open", "pickle.dump"], "function", ["None"], ["def", "cache", "(", "cache_path", ",", "fn", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Cache-wrapper for a function or class. If the cache-file exists\n    then the data is reloaded and returned, otherwise the function\n    is called and the result is saved to cache. The fn-argument can\n    also be a class instead, in which case an object-instance is\n    created and saved to the cache-file.\n\n    :param cache_path:\n        File-path for the cache-file.\n\n    :param fn:\n        Function or class to be called.\n\n    :param args:\n        Arguments to the function or class-init.\n\n    :param kwargs:\n        Keyword arguments to the function or class-init.\n\n    :return:\n        The result of calling the function or creating the object-instance.\n    \"\"\"", "\n", "\n", "# If the cache-file exists.", "\n", "if", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "# Load the cached data from the file.", "\n", "        ", "with", "open", "(", "cache_path", ",", "mode", "=", "'rb'", ")", "as", "file", ":", "\n", "            ", "obj", "=", "pickle", ".", "load", "(", "file", ")", "\n", "\n", "", "print", "(", "\"- Data loaded from cache-file: \"", "+", "cache_path", ")", "\n", "", "else", ":", "\n", "# The cache-file does not exist.", "\n", "\n", "# Call the function / class-init with the supplied arguments.", "\n", "        ", "obj", "=", "fn", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "# Save the data to a cache-file.", "\n", "with", "open", "(", "cache_path", ",", "mode", "=", "'wb'", ")", "as", "file", ":", "\n", "            ", "pickle", ".", "dump", "(", "obj", ",", "file", ")", "\n", "\n", "", "print", "(", "\"- Data saved to cache-file: \"", "+", "cache_path", ")", "\n", "\n", "", "return", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.cache.convert_numpy2pickle": [[79, 103], ["numpy.load", "open", "pickle.dump"], "function", ["None"], ["", "def", "convert_numpy2pickle", "(", "in_path", ",", "out_path", ")", ":", "\n", "    ", "\"\"\"\n    Convert a numpy-file to pickle-file.\n\n    The first version of the cache-function used numpy for saving the data.\n    Instead of re-calculating all the data, you can just convert the\n    cache-file using this function.\n\n    :param in_path:\n        Input file in numpy-format written using numpy.save().\n\n    :param out_path:\n        Output file written as a pickle-file.\n\n    :return:\n        Nothing.\n    \"\"\"", "\n", "\n", "# Load the data using numpy.", "\n", "data", "=", "np", ".", "load", "(", "in_path", ")", "\n", "\n", "# Save the data using pickle.", "\n", "with", "open", "(", "out_path", ",", "mode", "=", "'wb'", ")", "as", "file", ":", "\n", "        ", "pickle", ".", "dump", "(", "data", ",", "file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.exponent_decay_lr_generator": [[26, 37], ["max"], "function", ["None"], ["def", "exponent_decay_lr_generator", "(", "decay_rate", ",", "minimum_lr", ",", "batch_to_decay", ")", ":", "\n", "    ", "cur_lr", "=", "None", "\n", "def", "exponent_decay_lr", "(", "initial_lr", ",", "batch", ",", "history", ")", ":", "\n", "        ", "nonlocal", "cur_lr", "\n", "if", "batch", "==", "0", ":", "\n", "            ", "cur_lr", "=", "initial_lr", "\n", "", "if", "(", "batch", "%", "batch_to_decay", ")", "==", "0", "and", "batch", "!=", "0", ":", "\n", "            ", "new_lr", "=", "cur_lr", "/", "decay_rate", "\n", "cur_lr", "=", "max", "(", "new_lr", ",", "minimum_lr", ")", "\n", "", "return", "cur_lr", "\n", "", "return", "exponent_decay_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.exponent_data_function_generator": [[38, 66], ["min", "numpy.int", "numpy.ceil"], "function", ["None"], ["", "def", "exponent_data_function_generator", "(", "dataset", ",", "order", ",", "batches_to_increase", ",", "\n", "increase_amount", ",", "starting_percent", ",", "\n", "batch_size", "=", "100", ")", ":", "\n", "\n", "    ", "size_data", "=", "dataset", ".", "x_train", ".", "shape", "[", "0", "]", "\n", "\n", "cur_percent", "=", "1", "\n", "cur_data_x", "=", "dataset", ".", "x_train", "\n", "cur_data_y", "=", "dataset", ".", "y_test_labels", "\n", "\n", "\n", "def", "data_function", "(", "x", ",", "y", ",", "batch", ",", "history", ",", "model", ")", ":", "\n", "        ", "nonlocal", "cur_percent", ",", "cur_data_x", ",", "cur_data_y", "\n", "\n", "if", "batch", "%", "batches_to_increase", "==", "0", ":", "\n", "            ", "if", "batch", "==", "0", ":", "\n", "                ", "percent", "=", "starting_percent", "\n", "", "else", ":", "\n", "                ", "percent", "=", "min", "(", "cur_percent", "*", "increase_amount", ",", "1", ")", "\n", "", "if", "percent", "!=", "cur_percent", ":", "\n", "                ", "cur_percent", "=", "percent", "\n", "data_limit", "=", "np", ".", "int", "(", "np", ".", "ceil", "(", "size_data", "*", "percent", ")", ")", "\n", "new_data", "=", "order", "[", ":", "data_limit", "]", "\n", "cur_data_x", "=", "dataset", ".", "x_train", "[", "new_data", ",", ":", ",", ":", ",", ":", "]", "\n", "cur_data_y", "=", "dataset", ".", "y_train_labels", "[", "new_data", ",", ":", "]", "\n", "", "", "return", "cur_data_x", ",", "cur_data_y", "\n", "\n", "", "return", "data_function", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.order_by_loss": [[67, 73], ["len", "model.predict", "numpy.asarray", "sorted", "range", "list", "len", "range"], "function", ["None"], ["", "def", "order_by_loss", "(", "dataset", ",", "model", ")", ":", "\n", "    ", "size_train", "=", "len", "(", "dataset", ".", "y_train", ")", "\n", "scores", "=", "model", ".", "predict", "(", "dataset", ".", "x_train", ")", "\n", "hardness_score", "=", "scores", "[", "list", "(", "range", "(", "size_train", ")", ")", ",", "dataset", ".", "y_train", "]", "\n", "res", "=", "np", ".", "asarray", "(", "sorted", "(", "range", "(", "len", "(", "hardness_score", ")", ")", ",", "key", "=", "lambda", "k", ":", "hardness_score", "[", "k", "]", ",", "reverse", "=", "True", ")", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.balance_order": [[74, 88], ["range", "range", "class_orders.append", "sorted", "new_order.append", "range", "range", "len"], "function", ["None"], ["", "def", "balance_order", "(", "order", ",", "dataset", ")", ":", "\n", "    ", "num_classes", "=", "dataset", ".", "n_classes", "\n", "size_each_class", "=", "dataset", ".", "x_train", ".", "shape", "[", "0", "]", "//", "num_classes", "\n", "class_orders", "=", "[", "]", "\n", "for", "cls", "in", "range", "(", "num_classes", ")", ":", "\n", "        ", "class_orders", ".", "append", "(", "[", "i", "for", "i", "in", "range", "(", "len", "(", "order", ")", ")", "if", "dataset", ".", "y_train", "[", "order", "[", "i", "]", "]", "==", "cls", "]", ")", "\n", "", "new_order", "=", "[", "]", "\n", "## take each group containing the next easiest image for each class,", "\n", "## and putting them according to diffuclt-level in the new order", "\n", "for", "group_idx", "in", "range", "(", "size_each_class", ")", ":", "\n", "        ", "group", "=", "sorted", "(", "[", "class_orders", "[", "cls", "]", "[", "group_idx", "]", "for", "cls", "in", "range", "(", "num_classes", ")", "]", ")", "\n", "for", "idx", "in", "group", ":", "\n", "            ", "new_order", ".", "append", "(", "order", "[", "idx", "]", ")", "\n", "", "", "return", "new_order", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.data_function_from_input": [[90, 107], ["numpy.random.shuffle", "main_train_networks.exponent_data_function_generator", "print", "print"], "function", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.exponent_data_function_generator"], ["", "def", "data_function_from_input", "(", "curriculum", ",", "batch_size", ",", "\n", "dataset", ",", "order", ",", "batch_increase", ",", "\n", "increase_amount", ",", "starting_percent", ")", ":", "\n", "    ", "if", "curriculum", "==", "\"random\"", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "order", ")", "\n", "\n", "", "if", "curriculum", "==", "\"None\"", "or", "curriculum", "==", "\"vanilla\"", ":", "\n", "        ", "data_function", "=", "train_keras_model", ".", "basic_data_function", "\n", "", "elif", "curriculum", "in", "[", "\"curriculum\"", ",", "\"vanilla\"", ",", "\"anti\"", ",", "\"random\"", "]", ":", "\n", "        ", "data_function", "=", "exponent_data_function_generator", "(", "dataset", ",", "order", ",", "batch_increase", ",", "increase_amount", ",", "\n", "starting_percent", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"unsupprted condition (not vanilla/curriculum/random/anti)\"", ")", "\n", "print", "(", "\"got the value:\"", ",", "curriculum", ")", "\n", "raise", "ValueError", "\n", "", "return", "data_function", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.load_dataset": [[109, 127], ["dataset_name.startswith", "int", "datasets.cifar100_subset.Cifar100_Subset", "datasets.cifar100_subset.Cifar100_Subset", "datasets.cifar100_subset.Cifar100_Subset", "datasets.cifar10.Cifar10", "datasets.cifar10.Cifar10", "datasets.cifar10.Cifar10", "datasets.cifar100.Cifar100", "datasets.cifar100.Cifar100", "datasets.cifar100.Cifar100", "print", "len"], "function", ["None"], ["", "def", "load_dataset", "(", "dataset_name", ")", ":", "\n", "\n", "    ", "if", "dataset_name", ".", "startswith", "(", "'cifar100_subset'", ")", ":", "\n", "        ", "superclass_idx", "=", "int", "(", "dataset_name", "[", "len", "(", "\"cifar100_subset_\"", ")", ":", "]", ")", "\n", "dataset", "=", "datasets", ".", "cifar100_subset", ".", "Cifar100_Subset", "(", "supeclass_idx", "=", "superclass_idx", ",", "\n", "normalize", "=", "False", ")", "\n", "\n", "", "elif", "dataset_name", "==", "\"cifar10\"", ":", "\n", "        ", "dataset", "=", "datasets", ".", "cifar10", ".", "Cifar10", "(", "normalize", "=", "False", ")", "\n", "\n", "", "elif", "dataset_name", "==", "\"cifar100\"", ":", "\n", "        ", "dataset", "=", "datasets", ".", "cifar100", ".", "Cifar100", "(", "normalize", "=", "False", ")", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"do not support datset: %s\"", "%", "dataset_name", ")", "\n", "raise", "ValueError", "\n", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.load_model": [[129, 131], ["models.cifar100_model.Cifar100_Model"], "function", ["None"], ["", "def", "load_model", "(", ")", ":", "\n", "    ", "return", "models", ".", "cifar100_model", ".", "Cifar100_Model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.load_order": [[133, 158], ["transfer_learning.get_svm_scores", "transfer_learning.rank_data_according_to_score", "print", "transfer_learning.svm_scores_exists", "transfer_learning.get_transfer_values_inception", "transfer_learning.get_transfer_values_classic_networks"], "function", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.transfer_learning.get_svm_scores", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.transfer_learning.rank_data_according_to_score", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.transfer_learning.svm_scores_exists", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.transfer_learning.get_transfer_values_inception", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.transfer_learning.get_transfer_values_classic_networks"], ["", "def", "load_order", "(", "order_name", ",", "dataset", ")", ":", "\n", "    ", "classic_networks", "=", "[", "\"vgg16\"", ",", "\"vgg19\"", ",", "\"inception\"", ",", "\"xception\"", ",", "\"resnet\"", "]", "\n", "if", "order_name", "in", "classic_networks", ":", "\n", "        ", "network_name", "=", "order_name", "\n", "if", "not", "transfer_learning", ".", "svm_scores_exists", "(", "dataset", ",", "\n", "network_name", "=", "network_name", ")", ":", "\n", "            ", "if", "order_name", "==", "\"inception\"", ":", "\n", "                ", "(", "transfer_values_train", ",", "transfer_values_test", ")", "=", "transfer_learning", ".", "get_transfer_values_inception", "(", "dataset", ")", "\n", "\n", "", "else", ":", "\n", "                ", "(", "transfer_values_train", ",", "transfer_values_test", ")", "=", "transfer_learning", ".", "get_transfer_values_classic_networks", "(", "dataset", ",", "\n", "network_name", ")", "\n", "", "", "else", ":", "\n", "            ", "(", "transfer_values_train", ",", "transfer_values_test", ")", "=", "(", "None", ",", "None", ")", "\n", "\n", "", "train_scores", ",", "test_scores", "=", "transfer_learning", ".", "get_svm_scores", "(", "transfer_values_train", ",", "dataset", ".", "y_train", ",", "\n", "transfer_values_test", ",", "dataset", ".", "y_test", ",", "dataset", ",", "\n", "network_name", "=", "network_name", ")", "\n", "order", "=", "transfer_learning", ".", "rank_data_according_to_score", "(", "train_scores", ",", "dataset", ".", "y_train", ")", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"do not support order: %s\"", "%", "args", ".", "order", ")", "\n", "raise", "ValueError", "\n", "\n", "", "return", "order", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.combine_histories": [[160, 183], ["len", "history_list[].copy", "len", "numpy.zeros", "range", "numpy.mean", "scipy.stats.sem", "scipy.stats.sem"], "function", ["None"], ["", "def", "combine_histories", "(", "history_list", ")", ":", "\n", "\n", "    ", "num_repeats", "=", "len", "(", "history_list", ")", "\n", "\n", "combined_history", "=", "history_list", "[", "0", "]", ".", "copy", "(", ")", "\n", "for", "key", "in", "[", "\"loss\"", ",", "\"acc\"", ",", "\"val_loss\"", ",", "\"val_acc\"", "]", ":", "\n", "        ", "size_key", "=", "len", "(", "history_list", "[", "0", "]", "[", "key", "]", ")", "\n", "results", "=", "np", ".", "zeros", "(", "(", "num_repeats", ",", "size_key", ")", ")", "\n", "for", "i", "in", "range", "(", "num_repeats", ")", ":", "\n", "            ", "results", "[", "i", ",", ":", "]", "=", "history_list", "[", "i", "]", "[", "key", "]", "\n", "", "combined_history", "[", "key", "]", "=", "np", ".", "mean", "(", "results", ",", "axis", "=", "0", ")", "\n", "if", "key", "==", "\"acc\"", ":", "\n", "            ", "if", "num_repeats", ">", "1", ":", "\n", "                ", "combined_history", "[", "\"std_acc\"", "]", "=", "scipy", ".", "stats", ".", "sem", "(", "results", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "combined_history", "[", "\"std_acc\"", "]", "=", "None", "\n", "", "", "if", "key", "==", "\"val_acc\"", ":", "\n", "            ", "if", "num_repeats", ">", "1", ":", "\n", "                ", "combined_history", "[", "\"std_val_acc\"", "]", "=", "scipy", ".", "stats", ".", "sem", "(", "results", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "combined_history", "[", "\"std_val_acc\"", "]", "=", "None", "\n", "\n", "", "", "", "return", "combined_history", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.graph_from_history": [[186, 215], ["matplotlib.subplots", "axs.set_xlabel", "axs.set_ylabel", "matplotlib.legend", "numpy.array", "numpy.array", "axs.errorbar", "matplotlib.plot", "axs.errorbar", "matplotlib.plot"], "function", ["None"], ["", "def", "graph_from_history", "(", "history", ",", "plot_train", "=", "False", ",", "plot_test", "=", "True", ")", ":", "\n", "\n", "    ", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "figsize", "=", "(", "10", ",", "5", ")", ")", "\n", "\n", "if", "plot_train", ":", "\n", "        ", "x", "=", "np", ".", "array", "(", "history", "[", "'batch_num'", "]", ")", "\n", "y", "=", "history", "[", "'acc'", "]", "[", "x", "]", "\n", "error", "=", "history", "[", "'std_acc'", "]", "[", "x", "]", "\n", "\n", "if", "error", "is", "not", "None", ":", "\n", "            ", "axs", ".", "errorbar", "(", "x", ",", "y", ",", "error", ",", "marker", "=", "'^'", ",", "label", "=", "\"train\"", ")", "\n", "", "else", ":", "\n", "            ", "plt", ".", "plot", "(", "x", ",", "y", ",", "label", "=", "\"train\"", ")", "\n", "\n", "", "", "if", "plot_test", ":", "\n", "        ", "x", "=", "np", ".", "array", "(", "history", "[", "'batch_num'", "]", ")", "\n", "y", "=", "history", "[", "'val_acc'", "]", "\n", "error", "=", "history", "[", "'std_val_acc'", "]", "\n", "\n", "if", "error", "is", "not", "None", ":", "\n", "            ", "axs", ".", "errorbar", "(", "x", ",", "y", ",", "error", ",", "marker", "=", "'^'", ",", "label", "=", "\"test\"", ")", "\n", "", "else", ":", "\n", "            ", "plt", ".", "plot", "(", "x", ",", "y", ",", "label", "=", "\"test\"", ")", "\n", "\n", "\n", "\n", "", "", "axs", ".", "set_xlabel", "(", "\"batch number\"", ")", "\n", "axs", ".", "set_ylabel", "(", "\"accuracy\"", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "#    axs.legend(loc=\"best\")", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.run_expriment": [[217, 294], ["main_train_networks.load_dataset", "main_train_networks.load_model", "main_train_networks.exponent_decay_lr_generator", "main_train_networks.load_order", "main_train_networks.balance_order", "load_dataset.normalize_dataset", "time.time", "range", "print", "main_train_networks.combine_histories", "print", "print", "main_train_networks.graph_from_history", "numpy.flip", "main_train_networks.data_function_from_input", "print", "load_model.build_classifier_model", "train_keras_model.compile_model", "train_keras_model.train_model_batches", "histories.append", "numpy.random.shuffle", "open", "pickle.dump", "print", "str", "time.time"], "function", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.load_dataset", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.load_model", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.exponent_decay_lr_generator", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.load_order", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.balance_order", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.Dataset.Dataset.normalize_dataset", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.combine_histories", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.graph_from_history", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.main_train_networks.data_function_from_input", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.cifar100_model.Cifar100_Model.build_classifier_model", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.train_keras_model.compile_model", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.train_keras_model.train_model_batches"], ["", "def", "run_expriment", "(", "args", ")", ":", "\n", "    ", "dataset", "=", "load_dataset", "(", "args", ".", "dataset", ")", "\n", "model_lib", "=", "load_model", "(", ")", "\n", "\n", "size_train", "=", "dataset", ".", "x_train", ".", "shape", "[", "0", "]", "\n", "num_batches", "=", "(", "args", ".", "num_epochs", "*", "size_train", ")", "//", "args", ".", "batch_size", "\n", "\n", "lr_scheduler", "=", "exponent_decay_lr_generator", "(", "args", ".", "lr_decay_rate", ",", "\n", "args", ".", "minimal_lr", ",", "\n", "args", ".", "lr_batch_size", ")", "\n", "order", "=", "load_order", "(", "args", ".", "order", ",", "dataset", ")", "\n", "\n", "order", "=", "balance_order", "(", "order", ",", "dataset", ")", "\n", "\n", "if", "args", ".", "curriculum", "==", "\"anti\"", ":", "\n", "        ", "order", "=", "np", ".", "flip", "(", "order", ",", "0", ")", "\n", "", "elif", "args", ".", "curriculum", "==", "\"random\"", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "order", ")", "\n", "\n", "", "elif", "(", "args", ".", "curriculum", "not", "in", "[", "\"None\"", ",", "\"curriculum\"", ",", "\"vanilla\"", "]", ")", ":", "\n", "        ", "print", "(", "\"--curriculum value of %s is not supported!\"", "%", "args", ".", "curriculum", ")", "\n", "raise", "ValueError", "\n", "\n", "", "dataset", ".", "normalize_dataset", "(", ")", "\n", "if", "args", ".", "output_path", ":", "\n", "        ", "output_path", "=", "args", ".", "output_path", "\n", "", "else", ":", "\n", "        ", "output_path", "=", "None", "\n", "\n", "## start expriment", "\n", "", "start_time_all", "=", "time", ".", "time", "(", ")", "\n", "histories", "=", "[", "]", "\n", "for", "repeat", "in", "range", "(", "args", ".", "repeats", ")", ":", "\n", "\n", "        ", "data_function", "=", "data_function_from_input", "(", "args", ".", "curriculum", ",", "\n", "args", ".", "batch_size", ",", "\n", "dataset", ",", "\n", "order", ",", "\n", "args", ".", "batch_increase", ",", "\n", "args", ".", "increase_amount", ",", "\n", "args", ".", "starting_percent", ")", "\n", "\n", "print", "(", "\"starting repeat number: \"", "+", "str", "(", "repeat", "+", "1", ")", ")", "\n", "model", "=", "model_lib", ".", "build_classifier_model", "(", "dataset", ")", "\n", "\n", "train_keras_model", ".", "compile_model", "(", "model", ",", "\n", "initial_lr", "=", "args", ".", "learning_rate", ",", "\n", "loss", "=", "'categorical_crossentropy'", ",", "\n", "optimizer", "=", "\"sgd\"", ")", "\n", "\n", "\n", "\n", "history", "=", "train_keras_model", ".", "train_model_batches", "(", "model", ",", "\n", "dataset", ",", "\n", "num_batches", ",", "\n", "verbose", "=", "args", ".", "verbose", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "initial_lr", "=", "args", ".", "learning_rate", ",", "\n", "lr_scheduler", "=", "lr_scheduler", ",", "\n", "data_function", "=", "data_function", ")", "\n", "\n", "histories", ".", "append", "(", "history", ")", "\n", "\n", "\n", "", "print", "(", "\"time all: --- %s seconds ---\"", "%", "(", "time", ".", "time", "(", ")", "-", "start_time_all", ")", ")", "\n", "\n", "\n", "combined_history", "=", "combine_histories", "(", "histories", ")", "\n", "\n", "if", "output_path", ":", "\n", "        ", "with", "open", "(", "output_path", "+", "\"_history\"", ",", "'wb'", ")", "as", "file_pi", ":", "\n", "            ", "pickle", ".", "dump", "(", "combined_history", ",", "file_pi", ")", "\n", "\n", "", "", "print", "(", "\"training acc:\"", ",", "combined_history", "[", "'acc'", "]", "[", "-", "1", "]", ")", "\n", "print", "(", "\"test acc:\"", ",", "combined_history", "[", "'val_acc'", "]", "[", "-", "1", "]", ")", "\n", "\n", "graph_from_history", "(", "combined_history", ",", "plot_train", "=", "False", ",", "plot_test", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.transfer_learning.get_transfer_values_inception": [[21, 71], ["os.path.join", "os.path.join", "models.inception.maybe_download", "models.inception.Inception", "os.path.join", "os.path.join", "print", "models.inception.transfer_values_cache", "print", "models.inception.transfer_values_cache", "os.path.exists", "os.mkdir"], "function", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.maybe_download", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.transfer_values_cache", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.transfer_values_cache"], ["def", "get_transfer_values_inception", "(", "dataset", ")", ":", "\n", "    ", "data_dir", "=", "r'./data/'", "\n", "models", ".", "inception", ".", "data_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'inception/'", ")", "\n", "dataset", ".", "data_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "dataset", ".", "name", "+", "r'/'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dataset", ".", "data_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "dataset", ".", "data_dir", ")", "\n", "", "models", ".", "inception", ".", "maybe_download", "(", ")", "\n", "#    dataset.maybe_download()", "\n", "\n", "#load the inception model", "\n", "model", "=", "models", ".", "inception", ".", "Inception", "(", ")", "\n", "\n", "#load the dataset data", "\n", "#    images_train, cls_train, labels_train = dataset.load_training_data()", "\n", "#    images_test, cls_test, labels_test = dataset.load_test_data()", "\n", "\n", "images_train", "=", "dataset", ".", "x_train", "\n", "#    cls_train = dataset.y_train", "\n", "#    labels_train = dataset.y_train_labels", "\n", "\n", "images_test", "=", "dataset", ".", "x_test", "\n", "#    cls_test = dataset.y_test", "\n", "#    labels_test = dataset.y_test_labels", "\n", "\n", "# path to save the cache values", "\n", "file_path_cache_train", "=", "os", ".", "path", ".", "join", "(", "dataset", ".", "data_dir", ",", "'inception_'", "+", "dataset", ".", "name", "+", "'_train.pkl'", ")", "\n", "file_path_cache_test", "=", "os", ".", "path", ".", "join", "(", "dataset", ".", "data_dir", ",", "'inception_'", "+", "dataset", ".", "name", "+", "'_test.pkl'", ")", "\n", "\n", "# stl10 and inception both need pixels between 0 to 255.", "\n", "# however, when using other datasets, preprocessing might ", "\n", "# be required.", "\n", "\n", "# images_scaled = images_train * 255.0", "\n", "\n", "print", "(", "\"Transfering training set\"", ")", "\n", "\n", "# If transfer-values have already been calculated then reload them,", "\n", "# otherwise calculate them and save them to a cache-file.", "\n", "transfer_values_train", "=", "transfer_values_cache", "(", "cache_path", "=", "file_path_cache_train", ",", "\n", "images", "=", "images_train", ",", "\n", "model", "=", "model", ")", "\n", "\n", "print", "(", "\"Transfering test set\"", ")", "\n", "\n", "# If transfer-values have already been calculated then reload them,", "\n", "# otherwise calculate them and save them to a cache-file.", "\n", "transfer_values_test", "=", "transfer_values_cache", "(", "cache_path", "=", "file_path_cache_test", ",", "\n", "images", "=", "images_test", ",", "\n", "model", "=", "model", ")", "\n", "return", "transfer_values_train", ",", "transfer_values_test", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.transfer_learning.get_transfer_values_classic_networks": [[73, 110], ["os.path.join", "os.path.join", "print", "os.path.exists", "print", "os.path.exists", "print", "classic_nets_imagenet.classify_img", "print", "classic_nets_imagenet.classify_img", "open", "pickle.load", "open", "pickle.dump", "open", "pickle.load", "open", "pickle.dump"], "function", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.classic_nets_imagenet.classify_img", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.classic_nets_imagenet.classify_img"], ["", "def", "get_transfer_values_classic_networks", "(", "dataset", ",", "network_name", ")", ":", "\n", "\n", "# path to save the cache values", "\n", "    ", "file_path_cache_train", "=", "os", ".", "path", ".", "join", "(", "dataset", ".", "data_dir", ",", "network_name", "+", "'_'", "+", "dataset", ".", "name", "+", "'_train.pkl'", ")", "\n", "file_path_cache_test", "=", "os", ".", "path", ".", "join", "(", "dataset", ".", "data_dir", ",", "network_name", "+", "'_'", "+", "dataset", ".", "name", "+", "'_test.pkl'", ")", "\n", "\n", "\n", "#", "\n", "# if output_path is not None:", "\n", "#     history_output = output_path + \"_nets\" + str(args.num_models) + \"_history\"", "\n", "#     print('saving trained model to:', history_output)", "\n", "#     with open(history_output, 'wb') as file_pi:", "\n", "#         pickle.dump(history, file_pi)", "\n", "\n", "print", "(", "\"Transfering training set\"", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "file_path_cache_train", ")", ":", "\n", "        ", "print", "(", "\"training set already exist on disk\"", ")", "\n", "with", "open", "(", "file_path_cache_train", ",", "\"rb\"", ")", "as", "pick_file", ":", "\n", "            ", "transfer_values_train", "=", "pickle", ".", "load", "(", "pick_file", ")", "\n", "", "", "else", ":", "\n", "        ", "transfer_values_train", "=", "classic_nets_imagenet", ".", "classify_img", "(", "dataset", ".", "x_train", ",", "network_name", ")", "\n", "with", "open", "(", "file_path_cache_train", ",", "\"wb\"", ")", "as", "pick_file", ":", "\n", "            ", "pickle", ".", "dump", "(", "transfer_values_train", ",", "pick_file", ")", "\n", "\n", "", "", "print", "(", "\"Transfering test set\"", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "file_path_cache_test", ")", ":", "\n", "        ", "print", "(", "\"test set already exist on disk\"", ")", "\n", "with", "open", "(", "file_path_cache_test", ",", "\"rb\"", ")", "as", "pick_file", ":", "\n", "            ", "transfer_values_test", "=", "pickle", ".", "load", "(", "pick_file", ")", "\n", "", "", "else", ":", "\n", "        ", "transfer_values_test", "=", "classic_nets_imagenet", ".", "classify_img", "(", "dataset", ".", "x_test", ",", "network_name", ")", "\n", "with", "open", "(", "file_path_cache_test", ",", "\"wb\"", ")", "as", "pick_file", ":", "\n", "            ", "pickle", ".", "dump", "(", "transfer_values_test", ",", "pick_file", ")", "\n", "\n", "", "", "return", "transfer_values_train", ",", "transfer_values_test", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.transfer_learning.transfer_values_svm_scores": [[112, 124], ["sklearn.svm.SVC", "print", "svm.SVC.fit", "svm.SVC.predict_proba", "len", "print", "svm.SVC.predict_proba", "print", "str", "numpy.mean", "numpy.argmax"], "function", ["None"], ["", "def", "transfer_values_svm_scores", "(", "train_x", ",", "train_y", ",", "test_x", ",", "test_y", ")", ":", "\n", "    ", "clf", "=", "svm", ".", "SVC", "(", "probability", "=", "True", ")", "\n", "print", "(", "\"fitting svm\"", ")", "\n", "clf", ".", "fit", "(", "train_x", ",", "train_y", ")", "\n", "if", "len", "(", "test_x", ")", "!=", "0", ":", "\n", "        ", "print", "(", "\"evaluating svm\"", ")", "\n", "test_scores", "=", "clf", ".", "predict_proba", "(", "test_x", ")", "\n", "print", "(", "'accuracy for svm = '", ",", "str", "(", "np", ".", "mean", "(", "np", ".", "argmax", "(", "test_scores", ",", "axis", "=", "1", ")", "==", "test_y", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "test_scores", "=", "[", "]", "\n", "", "train_scores", "=", "clf", ".", "predict_proba", "(", "train_x", ")", "\n", "return", "train_scores", ",", "test_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.transfer_learning.svm_scores_exists": [[125, 135], ["os.path.join", "os.path.join", "os.path.exists", "os.path.exists"], "function", ["None"], ["", "def", "svm_scores_exists", "(", "dataset", ",", "network_name", "=", "\"inception\"", ",", "\n", "alternative_data_dir", "=", "\".\"", ")", ":", "\n", "    ", "if", "dataset", "is", "None", ":", "\n", "        ", "data_dir", "=", "alternative_data_dir", "\n", "", "else", ":", "\n", "        ", "data_dir", "=", "dataset", ".", "data_dir", "\n", "\n", "", "svm_train_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "network_name", "+", "'svm_train_values.pkl'", ")", "\n", "svm_test_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "network_name", "+", "'svm_test_values.pkl'", ")", "\n", "return", "os", ".", "path", ".", "exists", "(", "svm_train_path", ")", "and", "os", ".", "path", ".", "exists", "(", "svm_test_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.transfer_learning.get_svm_scores": [[136, 161], ["os.path.join", "os.path.join", "transfer_learning.transfer_values_svm_scores", "os.path.exists", "os.path.exists", "open", "pickle.dump", "open", "pickle.dump", "open", "pickle.load", "open", "pickle.load"], "function", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.transfer_learning.transfer_values_svm_scores"], ["", "def", "get_svm_scores", "(", "transfer_values_train", ",", "y_train", ",", "transfer_values_test", ",", "\n", "y_test", ",", "dataset", ",", "network_name", "=", "\"inception\"", ",", "\n", "alternative_data_dir", "=", "\".\"", ")", ":", "\n", "\n", "    ", "if", "dataset", "is", "None", ":", "\n", "        ", "data_dir", "=", "alternative_data_dir", "\n", "", "else", ":", "\n", "        ", "data_dir", "=", "dataset", ".", "data_dir", "\n", "\n", "", "svm_train_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "network_name", "+", "'svm_train_values.pkl'", ")", "\n", "svm_test_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "network_name", "+", "'svm_test_values.pkl'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "svm_train_path", ")", "or", "not", "os", ".", "path", ".", "exists", "(", "svm_test_path", ")", ":", "\n", "        ", "train_scores", ",", "test_scores", "=", "transfer_values_svm_scores", "(", "transfer_values_train", ",", "y_train", ",", "transfer_values_test", ",", "y_test", ")", "\n", "with", "open", "(", "svm_train_path", ",", "'wb'", ")", "as", "file_pi", ":", "\n", "            ", "pickle", ".", "dump", "(", "train_scores", ",", "file_pi", ")", "\n", "\n", "", "with", "open", "(", "svm_test_path", ",", "'wb'", ")", "as", "file_pi", ":", "\n", "            ", "pickle", ".", "dump", "(", "test_scores", ",", "file_pi", ")", "\n", "", "", "else", ":", "\n", "        ", "with", "open", "(", "svm_train_path", ",", "'rb'", ")", "as", "file_pi", ":", "\n", "            ", "train_scores", "=", "pickle", ".", "load", "(", "file_pi", ")", "\n", "\n", "", "with", "open", "(", "svm_test_path", ",", "'rb'", ")", "as", "file_pi", ":", "\n", "            ", "test_scores", "=", "pickle", ".", "load", "(", "file_pi", ")", "\n", "", "", "return", "train_scores", ",", "test_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.transfer_learning.rank_data_according_to_score": [[163, 172], ["numpy.asarray", "sorted", "numpy.flip", "numpy.random.shuffle", "range", "list", "len", "range"], "function", ["None"], ["", "def", "rank_data_according_to_score", "(", "train_scores", ",", "y_train", ",", "reverse", "=", "False", ",", "random", "=", "False", ")", ":", "\n", "    ", "train_size", ",", "_", "=", "train_scores", ".", "shape", "\n", "hardness_score", "=", "train_scores", "[", "list", "(", "range", "(", "train_size", ")", ")", ",", "y_train", "]", "\n", "res", "=", "np", ".", "asarray", "(", "sorted", "(", "range", "(", "len", "(", "hardness_score", ")", ")", ",", "key", "=", "lambda", "k", ":", "hardness_score", "[", "k", "]", ",", "reverse", "=", "True", ")", ")", "\n", "if", "reverse", ":", "\n", "        ", "res", "=", "np", ".", "flip", "(", "res", ",", "0", ")", "\n", "", "if", "random", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "res", ")", "\n", "", "return", "res", "\n", "", ""]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.train_keras_model.compile_model": [[13, 29], ["model.compile", "keras.optimizers.Adam", "keras.optimizers.Adam", "keras.optimizers.SGD", "keras.optimizers.SGD", "print"], "function", ["None"], ["def", "compile_model", "(", "model", ",", "initial_lr", "=", "1e-3", ",", "loss", "=", "'categorical_crossentropy'", ",", "\n", "optimizer", "=", "'adam'", ",", "metrics", "=", "[", "'accuracy'", "]", ",", "momentum", "=", "0.0", ")", ":", "\n", "    ", "if", "optimizer", "==", "'adam'", ":", "\n", "        ", "optimizer", "=", "keras", ".", "optimizers", ".", "Adam", "(", "initial_lr", ",", "beta_1", "=", "0.9", ",", "beta_2", "=", "0.999", ",", "\n", "epsilon", "=", "None", ",", "decay", "=", "0.0", ",", "\n", "amsgrad", "=", "False", ")", "\n", "", "elif", "optimizer", "==", "'sgd'", ":", "\n", "        ", "optimizer", "=", "keras", ".", "optimizers", ".", "SGD", "(", "initial_lr", ",", "momentum", "=", "momentum", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"optimizer not supported\"", ")", "\n", "raise", "ValueError", "\n", "\n", "", "model", ".", "compile", "(", "\n", "loss", "=", "loss", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "metrics", "=", "metrics", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.train_keras_model.basic_data_function": [[31, 33], ["None"], "function", ["None"], ["", "def", "basic_data_function", "(", "x_train", ",", "y_train", ",", "batch", ",", "history", ",", "model", ")", ":", "\n", "    ", "return", "x_train", ",", "y_train", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.train_keras_model.basic_lr_scheduler": [[34, 36], ["None"], "function", ["None"], ["", "def", "basic_lr_scheduler", "(", "initial_lr", ",", "batch", ",", "history", ")", ":", "\n", "    ", "return", "initial_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.train_keras_model.generate_random_batch": [[38, 42], ["numpy.random.choice"], "function", ["None"], ["", "def", "generate_random_batch", "(", "x", ",", "y", ",", "batch_size", ")", ":", "\n", "    ", "size_data", "=", "x", ".", "shape", "[", "0", "]", "\n", "cur_batch_idxs", "=", "np", ".", "random", ".", "choice", "(", "size_data", ",", "batch_size", ",", "replace", "=", "False", ")", "\n", "return", "x", "[", "cur_batch_idxs", ",", ":", ",", ":", ",", ":", "]", ",", "y", "[", "cur_batch_idxs", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.train_keras_model.train_model_batches": [[44, 82], ["time.time", "range", "data_function", "lr_scheduler", "keras.set_value", "batch_generator", "model.train_on_batch", "history[].append", "history[].append", "history[].append", "model.evaluate", "history[].append", "history[].append", "history[].append", "print", "print", "print", "print", "print", "time.time", "print", "str", "str", "str", "str", "time.time", "str"], "function", ["None"], ["", "def", "train_model_batches", "(", "model", ",", "dataset", ",", "num_batches", ",", "batch_size", "=", "100", ",", "\n", "test_each", "=", "50", ",", "batch_generator", "=", "generate_random_batch", ",", "initial_lr", "=", "1e-3", ",", "\n", "lr_scheduler", "=", "basic_lr_scheduler", ",", "loss", "=", "'categorical_crossentropy'", ",", "\n", "data_function", "=", "basic_data_function", ",", "\n", "verbose", "=", "False", ")", ":", "\n", "\n", "    ", "x_train", "=", "dataset", ".", "x_train", "\n", "y_train", "=", "dataset", ".", "y_train_labels", "\n", "x_test", "=", "dataset", ".", "x_test", "\n", "y_test", "=", "dataset", ".", "y_test_labels", "\n", "\n", "history", "=", "{", "\"loss\"", ":", "[", "]", ",", "\"acc\"", ":", "[", "]", ",", "\"val_loss\"", ":", "[", "]", ",", "\"val_acc\"", ":", "[", "]", ",", "\"batch_num\"", ":", "[", "]", ",", "\"data_size\"", ":", "[", "]", "}", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "for", "batch", "in", "range", "(", "num_batches", ")", ":", "\n", "        ", "cur_x", ",", "cur_y", "=", "data_function", "(", "x_train", ",", "y_train", ",", "batch", ",", "history", ",", "model", ")", "\n", "cur_lr", "=", "lr_scheduler", "(", "initial_lr", ",", "batch", ",", "history", ")", "\n", "K", ".", "set_value", "(", "model", ".", "optimizer", ".", "lr", ",", "cur_lr", ")", "\n", "batch_x", ",", "batch_y", "=", "batch_generator", "(", "cur_x", ",", "cur_y", ",", "batch_size", ")", "\n", "cur_loss", ",", "cur_accuracy", "=", "model", ".", "train_on_batch", "(", "batch_x", ",", "batch_y", ")", "\n", "history", "[", "\"loss\"", "]", ".", "append", "(", "cur_loss", ")", "\n", "history", "[", "\"acc\"", "]", ".", "append", "(", "cur_accuracy", ")", "\n", "history", "[", "\"data_size\"", "]", ".", "append", "(", "cur_x", ".", "shape", "[", "0", "]", ")", "\n", "if", "test_each", "is", "not", "None", "and", "(", "batch", "+", "1", ")", "%", "test_each", "==", "0", ":", "\n", "            ", "cur_val_loss", ",", "cur_val_acc", "=", "model", ".", "evaluate", "(", "x_test", ",", "y_test", ",", "verbose", "=", "0", ")", "\n", "history", "[", "\"val_loss\"", "]", ".", "append", "(", "cur_val_loss", ")", "\n", "history", "[", "\"val_acc\"", "]", ".", "append", "(", "cur_val_acc", ")", "\n", "history", "[", "\"batch_num\"", "]", ".", "append", "(", "batch", ")", "\n", "if", "verbose", ":", "\n", "                ", "print", "(", "\"val accuracy:\"", ",", "cur_val_acc", ")", "\n", "", "", "if", "verbose", "and", "(", "batch", "+", "1", ")", "%", "5", "==", "0", ":", "\n", "            ", "print", "(", "\"batch: \"", "+", "str", "(", "batch", "+", "1", ")", "+", "r\"/\"", "+", "str", "(", "num_batches", ")", ")", "\n", "print", "(", "\"last lr used: \"", "+", "str", "(", "cur_lr", ")", ")", "\n", "print", "(", "\"data_size: \"", "+", "str", "(", "cur_x", ".", "shape", "[", "0", "]", ")", ")", "\n", "print", "(", "\"loss: \"", "+", "str", "(", "cur_loss", ")", ")", "\n", "print", "(", "\"--- %s seconds ---\"", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "", "return", "history", "", "", ""]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.download._print_download_progress": [[28, 43], ["sys.stdout.write", "sys.stdout.flush", "float"], "function", ["None"], ["def", "_print_download_progress", "(", "count", ",", "block_size", ",", "total_size", ")", ":", "\n", "    ", "\"\"\"\n    Function used for printing the download progress.\n    Used as a call-back function in maybe_download_and_extract().\n    \"\"\"", "\n", "\n", "# Percentage completion.", "\n", "pct_complete", "=", "float", "(", "count", "*", "block_size", ")", "/", "total_size", "\n", "\n", "# Status-message. Note the \\r which means the line should overwrite itself.", "\n", "msg", "=", "\"\\r- Download progress: {0:.1%}\"", ".", "format", "(", "pct_complete", ")", "\n", "\n", "# Print it.", "\n", "sys", ".", "stdout", ".", "write", "(", "msg", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.download.maybe_download_and_extract": [[48, 96], ["os.path.join", "url.split", "os.path.exists", "urllib.request.urlretrieve", "print", "print", "os.path.join.endswith", "print", "print", "os.path.exists", "os.makedirs", "zipfile.ZipFile().extractall", "os.path.join.endswith", "tarfile.open().extractall", "zipfile.ZipFile", "tarfile.open"], "function", ["None"], ["", "def", "maybe_download_and_extract", "(", "url", ",", "download_dir", ")", ":", "\n", "    ", "\"\"\"\n    Download and extract the data if it doesn't already exist.\n    Assumes the url is a tar-ball file.\n\n    :param url:\n        Internet URL for the tar-file to download.\n        Example: \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n\n    :param download_dir:\n        Directory where the downloaded file is saved.\n        Example: \"data/CIFAR-10/\"\n\n    :return:\n        Nothing.\n    \"\"\"", "\n", "\n", "# Filename for saving the file downloaded from the internet.", "\n", "# Use the filename from the URL and add it to the download_dir.", "\n", "filename", "=", "url", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "download_dir", ",", "filename", ")", "\n", "\n", "# Check if the file already exists.", "\n", "# If it exists then we assume it has also been extracted,", "\n", "# otherwise we need to download and extract it now.", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "file_path", ")", ":", "\n", "# Check if the download directory exists, otherwise create it.", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "download_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "download_dir", ")", "\n", "\n", "# Download the file from the internet.", "\n", "", "file_path", ",", "_", "=", "urllib", ".", "request", ".", "urlretrieve", "(", "url", "=", "url", ",", "\n", "filename", "=", "file_path", ",", "\n", "reporthook", "=", "_print_download_progress", ")", "\n", "\n", "print", "(", ")", "\n", "print", "(", "\"Download finished. Extracting files.\"", ")", "\n", "\n", "if", "file_path", ".", "endswith", "(", "\".zip\"", ")", ":", "\n", "# Unpack the zip-file.", "\n", "            ", "zipfile", ".", "ZipFile", "(", "file", "=", "file_path", ",", "mode", "=", "\"r\"", ")", ".", "extractall", "(", "download_dir", ")", "\n", "", "elif", "file_path", ".", "endswith", "(", "(", "\".tar.gz\"", ",", "\".tgz\"", ")", ")", ":", "\n", "# Unpack the tar-ball.", "\n", "            ", "tarfile", ".", "open", "(", "name", "=", "file_path", ",", "mode", "=", "\"r:gz\"", ")", ".", "extractall", "(", "download_dir", ")", "\n", "\n", "", "print", "(", "\"Done.\"", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Data has apparently already been downloaded and unpacked.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.classic_nets_imagenet.classify_img": [[16, 82], ["print", "Network", "keras.backend.function", "numpy.zeros", "range", "print", "MODELS.keys", "print", "print", "PIL.Image.fromarray().resize", "keras.preprocessing.image.img_to_array", "numpy.expand_dims", "preprocess", "K.function.", "str", "str", "PIL.Image.fromarray", "str", "str"], "function", ["None"], ["def", "classify_img", "(", "input_images", ",", "input_model", ")", ":", "\n", "    ", "num_images", ",", "rows", ",", "cols", ",", "channels", "=", "input_images", ".", "shape", "\n", "# define a dictionary that maps model names to their classes", "\n", "# inside Keras", "\n", "MODELS", "=", "{", "\n", "\"vgg16\"", ":", "VGG16", ",", "\n", "\"vgg19\"", ":", "VGG19", ",", "\n", "\"inception\"", ":", "InceptionV3", ",", "\n", "\"xception\"", ":", "Xception", ",", "# TensorFlow ONLY", "\n", "\"resnet\"", ":", "ResNet50", "\n", "}", "\n", "\n", "if", "input_model", "not", "in", "MODELS", ".", "keys", "(", ")", ":", "\n", "        ", "print", "(", "\"unsupported imagenet network\"", ")", "\n", "raise", "ValueError", "\n", "# initialize the input image shape (224x224 pixels) along with", "\n", "# the pre-processing function (this might need to be changed", "\n", "# based on which model we use to classify our image)", "\n", "", "inputShape", "=", "(", "224", ",", "224", ")", "\n", "preprocess", "=", "imagenet_utils", ".", "preprocess_input", "\n", "\n", "# if we are using the InceptionV3 or Xception networks, then we", "\n", "# need to set the input shape to (299x299) [rather than (224x224)]", "\n", "# and use a different image processing function", "\n", "if", "input_model", "in", "(", "\"inception\"", ",", "\"xception\"", ")", ":", "\n", "        ", "inputShape", "=", "(", "299", ",", "299", ")", "\n", "preprocess", "=", "preprocess_input", "\n", "\n", "", "print", "(", "\"[INFO] loading {}...\"", ".", "format", "(", "input_model", ")", ")", "\n", "Network", "=", "MODELS", "[", "input_model", "]", "\n", "model", "=", "Network", "(", "weights", "=", "\"imagenet\"", ")", "\n", "\n", "# with a Sequential model", "\n", "get_last_layer_output", "=", "K", ".", "function", "(", "[", "model", ".", "layers", "[", "0", "]", ".", "input", "]", ",", "\n", "[", "model", ".", "layers", "[", "-", "2", "]", ".", "output", "]", ")", "\n", "\n", "# load the input image using the Keras helper utility while ensuring", "\n", "# the image is resized to `inputShape`, the required input dimensions", "\n", "# for the ImageNet pre-trained network", "\n", "# print(\"[INFO] loading and pre-processing image...\")", "\n", "# image = load_img(input_image, target_size=inputShape)", "\n", "# image = img_to_array(image)", "\n", "\n", "# our input image is now represented as a NumPy array of shape", "\n", "# (inputShape[0], inputShape[1], 3) however we need to expand the", "\n", "# dimension by making the shape (1, inputShape[0], inputShape[1], 3)", "\n", "# so we can pass it through the network", "\n", "# image = np.expand_dims(image, axis=0)", "\n", "\n", "# pre-process the image using the appropriate function based on the", "\n", "# model that has been loaded (i.e., mean subtraction, scaling, etc.)", "\n", "\n", "transfer_values", "=", "np", ".", "zeros", "(", "(", "num_images", ",", "model", ".", "layers", "[", "-", "2", "]", ".", "output_shape", "[", "1", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "num_images", ")", ":", "\n", "        ", "print", "(", "\"transferring image: \"", "+", "str", "(", "i", ")", "+", "r\"/\"", "+", "str", "(", "num_images", ")", ",", "end", "=", "'\\r'", ")", "\n", "image", "=", "PIL", ".", "Image", ".", "fromarray", "(", "input_images", "[", "i", ",", ":", ",", ":", ",", ":", "]", ")", ".", "resize", "(", "inputShape", ")", "\n", "image", "=", "img_to_array", "(", "image", ")", "\n", "image", "=", "np", ".", "expand_dims", "(", "image", ",", "axis", "=", "0", ")", "\n", "image", "=", "preprocess", "(", "image", ")", "\n", "# model.predict(images)", "\n", "# classify the image", "\n", "# print(\"[INFO] classifying images with '{}'...\".format(input_model))", "\n", "transfer_value", "=", "get_last_layer_output", "(", "[", "image", "]", ")", "[", "0", "]", "\n", "transfer_values", "[", "i", ",", ":", "]", "=", "transfer_value", "\n", "", "print", "(", "\"transferring image: \"", "+", "str", "(", "num_images", ")", "+", "r\"/\"", "+", "str", "(", "num_images", ")", ")", "\n", "return", "transfer_values", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar100.Cifar100.__init__": [[17, 34], ["list", "len", "super().__init__", "range"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.Inception.__init__"], ["    ", "def", "__init__", "(", "self", ",", "normalize", "=", "True", ")", ":", "\n", "        ", "self", ".", "name", "=", "'cifar100'", "\n", "\n", "self", ".", "subsets_idxes", "=", "list", "(", "range", "(", "100", ")", ")", "\n", "\n", "# Internet URL for the tar-file with the Inception model.", "\n", "# Note that this might change in the future and will need to be updated.", "\n", "self", ".", "data_url", "=", "r\"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"", "\n", "\n", "# Directory to store the downloaded data.", "\n", "self", ".", "data_dir", "=", "\"./data/cifar100/\"", "\n", "\n", "self", ".", "height", ",", "self", ".", "width", ",", "self", ".", "depth", "=", "32", ",", "32", ",", "3", "\n", "self", ".", "n_classes", "=", "len", "(", "self", ".", "subsets_idxes", ")", "\n", "self", ".", "img_size_flat", "=", "self", ".", "height", "*", "self", ".", "width", "*", "self", ".", "depth", "\n", "\n", "super", "(", "Cifar100", ",", "self", ")", ".", "__init__", "(", "normalize", "=", "normalize", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar100.Cifar100._load_batch": [[35, 62], ["open", "open.close", "data.reshape.reshape.reshape", "six.moves.cPickle.load", "six.moves.cPickle.load", "six.moves.cPickle.load.items", "k.decode"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.Inception.close"], ["", "def", "_load_batch", "(", "self", ",", "fpath", ",", "label_key", "=", "'labels'", ")", ":", "\n", "        ", "\"\"\"Internal utility for parsing CIFAR data.\n\n        # Arguments\n            fpath: path the file to parse.\n            label_key: key for label data in the retrieve\n                dictionary.\n\n        # Returns\n            A tuple `(data, labels)`.\n        \"\"\"", "\n", "f", "=", "open", "(", "fpath", ",", "'rb'", ")", "\n", "if", "sys", ".", "version_info", "<", "(", "3", ",", ")", ":", "\n", "            ", "d", "=", "cPickle", ".", "load", "(", "f", ")", "\n", "", "else", ":", "\n", "            ", "d", "=", "cPickle", ".", "load", "(", "f", ",", "encoding", "=", "'bytes'", ")", "\n", "# decode utf8", "\n", "d_decoded", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "d", ".", "items", "(", ")", ":", "\n", "                ", "d_decoded", "[", "k", ".", "decode", "(", "'utf8'", ")", "]", "=", "v", "\n", "", "d", "=", "d_decoded", "\n", "", "f", ".", "close", "(", ")", "\n", "data", "=", "d", "[", "'data'", "]", "\n", "labels", "=", "d", "[", "label_key", "]", "\n", "\n", "data", "=", "data", ".", "reshape", "(", "data", ".", "shape", "[", "0", "]", ",", "3", ",", "32", ",", "32", ")", "\n", "return", "data", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar100.Cifar100.maybe_download": [[63, 70], ["download.maybe_download_and_extract"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.download.maybe_download_and_extract"], ["", "def", "maybe_download", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Download and extract the CIFAR-100 data-set if it doesn't already exist\n        in data_path (set this variable first to the desired path).\n        \"\"\"", "\n", "\n", "download", ".", "maybe_download_and_extract", "(", "url", "=", "self", ".", "data_url", ",", "download_dir", "=", "self", ".", "data_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar100.Cifar100.load_training_data": [[71, 92], ["os.path.join", "os.path.join", "cifar100.Cifar100._load_batch", "len", "sorted", "enumerate", "datasets.Dataset.one_hot_encoded", "keras.backend.image_data_format", "x_train.transpose.transpose.transpose", "numpy.asarray", "list", "len", "range", "set", "enumerate"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar10.Cifar10._load_batch", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.Dataset.one_hot_encoded"], ["", "def", "load_training_data", "(", "self", ")", ":", "\n", "        ", "dirname", "=", "'cifar-100-python'", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "dirname", ")", "\n", "fpath", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'train'", ")", "\n", "x_train", ",", "y_train_fine", "=", "self", ".", "_load_batch", "(", "fpath", ",", "'fine_labels'", ")", "\n", "data_size", "=", "len", "(", "y_train_fine", ")", "\n", "\n", "if", "K", ".", "image_data_format", "(", ")", "==", "'channels_last'", ":", "\n", "            ", "x_train", "=", "x_train", ".", "transpose", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "\n", "", "relevant_idxes", "=", "[", "i", "for", "i", "in", "range", "(", "data_size", ")", "if", "y_train_fine", "[", "i", "]", "in", "self", ".", "subsets_idxes", "]", "\n", "x_train", "=", "x_train", "[", "relevant_idxes", ",", ":", ",", ":", ",", ":", "]", "\n", "y_train", "=", "np", ".", "asarray", "(", "y_train_fine", ")", "[", "relevant_idxes", "]", "\n", "y_train_values", "=", "sorted", "(", "list", "(", "set", "(", "y_train", ")", ")", ")", "\n", "assert", "(", "len", "(", "y_train_values", ")", "==", "self", ".", "n_classes", ")", "\n", "map_dict", "=", "{", "val", ":", "i", "for", "i", ",", "val", "in", "enumerate", "(", "y_train_values", ")", "}", "\n", "for", "i", ",", "y", "in", "enumerate", "(", "y_train", ")", ":", "\n", "            ", "y_train", "[", "i", "]", "=", "map_dict", "[", "y", "]", "\n", "\n", "", "y_train_labels", "=", "one_hot_encoded", "(", "y_train", ",", "num_classes", "=", "self", ".", "n_classes", ")", "\n", "return", "x_train", ",", "y_train", ",", "y_train_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar100.Cifar100.load_test_data": [[93, 114], ["os.path.join", "os.path.join", "cifar100.Cifar100._load_batch", "len", "sorted", "enumerate", "datasets.Dataset.one_hot_encoded", "keras.backend.image_data_format", "x_test.transpose.transpose.transpose", "numpy.asarray", "list", "len", "range", "set", "enumerate"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar10.Cifar10._load_batch", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.Dataset.one_hot_encoded"], ["", "def", "load_test_data", "(", "self", ")", ":", "\n", "        ", "dirname", "=", "'cifar-100-python'", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "dirname", ")", "\n", "fpath", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'test'", ")", "\n", "x_test", ",", "y_test_fine", "=", "self", ".", "_load_batch", "(", "fpath", ",", "'fine_labels'", ")", "\n", "data_size", "=", "len", "(", "y_test_fine", ")", "\n", "\n", "if", "K", ".", "image_data_format", "(", ")", "==", "'channels_last'", ":", "\n", "            ", "x_test", "=", "x_test", ".", "transpose", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "\n", "", "relevant_idxes", "=", "[", "i", "for", "i", "in", "range", "(", "data_size", ")", "if", "y_test_fine", "[", "i", "]", "in", "self", ".", "subsets_idxes", "]", "\n", "x_test", "=", "x_test", "[", "relevant_idxes", ",", ":", ",", ":", ",", ":", "]", "\n", "y_test", "=", "np", ".", "asarray", "(", "y_test_fine", ")", "[", "relevant_idxes", "]", "\n", "y_test_values", "=", "sorted", "(", "list", "(", "set", "(", "y_test", ")", ")", ")", "\n", "assert", "(", "len", "(", "y_test_values", ")", "==", "self", ".", "n_classes", ")", "\n", "map_dict", "=", "{", "val", ":", "i", "for", "i", ",", "val", "in", "enumerate", "(", "y_test_values", ")", "}", "\n", "for", "i", ",", "y", "in", "enumerate", "(", "y_test", ")", ":", "\n", "            ", "y_test", "[", "i", "]", "=", "map_dict", "[", "y", "]", "\n", "\n", "", "y_test_labels", "=", "one_hot_encoded", "(", "y_test", ",", "num_classes", "=", "self", ".", "n_classes", ")", "\n", "return", "x_test", ",", "y_test", ",", "y_test_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar100.Cifar100.normalize_dataset": [[115, 136], ["cifar100.Cifar100.x_train.astype", "cifar100.Cifar100.x_test.astype", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.std", "numpy.std", "numpy.std"], "methods", ["None"], ["", "def", "normalize_dataset", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "normalized", ":", "\n", "            ", "self", ".", "x_train", "=", "self", ".", "x_train", ".", "astype", "(", "'float32'", ")", "\n", "self", ".", "x_test", "=", "self", ".", "x_test", ".", "astype", "(", "'float32'", ")", "\n", "mean_r", "=", "np", ".", "mean", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "0", "]", ")", "\n", "mean_g", "=", "np", ".", "mean", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "1", "]", ")", "\n", "mean_b", "=", "np", ".", "mean", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "2", "]", ")", "\n", "\n", "std_r", "=", "np", ".", "std", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "0", "]", ")", "\n", "std_g", "=", "np", ".", "std", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "1", "]", ")", "\n", "std_b", "=", "np", ".", "std", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "2", "]", ")", "\n", "\n", "\n", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "0", "]", "=", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "0", "]", "-", "mean_r", ")", "/", "std_r", "\n", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "1", "]", "=", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "1", "]", "-", "mean_g", ")", "/", "std_g", "\n", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "2", "]", "=", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "2", "]", "-", "mean_b", ")", "/", "std_b", "\n", "\n", "self", ".", "x_test", "[", ":", ",", ":", ",", ":", ",", "0", "]", "=", "(", "self", ".", "x_test", "[", ":", ",", ":", ",", ":", ",", "0", "]", "-", "mean_r", ")", "/", "std_r", "\n", "self", ".", "x_test", "[", ":", ",", ":", ",", ":", ",", "1", "]", "=", "(", "self", ".", "x_test", "[", ":", ",", ":", ",", ":", ",", "1", "]", "-", "mean_g", ")", "/", "std_g", "\n", "self", ".", "x_test", "[", ":", ",", ":", ",", ":", ",", "2", "]", "=", "(", "self", ".", "x_test", "[", ":", ",", ":", ",", ":", ",", "2", "]", "-", "mean_b", ")", "/", "std_b", "\n", "", "self", ".", "normalized", "=", "True", "", "", "", ""]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar100_subset.Cifar100_Subset.__init__": [[17, 49], ["super().__init__", "str"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.Inception.__init__"], ["    ", "def", "__init__", "(", "self", ",", "supeclass_idx", "=", "16", ",", "normalize", "=", "True", ",", "order_name", "=", "\"\"", ")", ":", "\n", "\n", "        ", "self", ".", "superclass_idx", "=", "supeclass_idx", "\n", "self", ".", "name", "=", "'cifar_100_superclass_'", "+", "str", "(", "self", ".", "superclass_idx", ")", "\n", "\n", "# Internet URL for the tar-file with the Inception model.", "\n", "# Note that this might change in the future and will need to be updated.", "\n", "self", ".", "data_url", "=", "r\"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"", "\n", "\n", "# Directory to store the downloaded data.", "\n", "self", ".", "data_dir", "=", "\"./data/cifar100/\"", "\n", "\n", "self", ".", "height", ",", "self", ".", "width", ",", "self", ".", "depth", "=", "32", ",", "32", ",", "3", "\n", "self", ".", "n_classes", "=", "5", "\n", "self", ".", "n_super_classes", "=", "1", "\n", "self", ".", "img_size_flat", "=", "self", ".", "height", "*", "self", ".", "width", "*", "self", ".", "depth", "\n", "\n", "\n", "########################################################################", "\n", "# Various constants used to allocate arrays of the correct size.", "\n", "\n", "# Number of files for the training-set.", "\n", "self", ".", "_num_files_train", "=", "1", "\n", "\n", "# Number of images for each batch-file in the training-set.", "\n", "self", ".", "_images_per_file", "=", "2500", "\n", "\n", "# Total number of images in the training-set.", "\n", "# This is used to pre-allocate arrays for efficiency.", "\n", "self", ".", "_num_images_train", "=", "self", ".", "_num_files_train", "*", "self", ".", "_images_per_file", "\n", "\n", "super", "(", "Cifar100_Subset", ",", "self", ")", ".", "__init__", "(", "normalize", "=", "normalize", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar100_subset.Cifar100_Subset._load_batch": [[50, 77], ["open", "open.close", "data.reshape.reshape.reshape", "six.moves.cPickle.load", "six.moves.cPickle.load", "six.moves.cPickle.load.items", "k.decode"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.Inception.close"], ["", "def", "_load_batch", "(", "self", ",", "fpath", ",", "label_key", "=", "'labels'", ")", ":", "\n", "        ", "\"\"\"Internal utility for parsing CIFAR data.\n\n        # Arguments\n            fpath: path the file to parse.\n            label_key: key for label data in the retrieve\n                dictionary.\n\n        # Returns\n            A tuple `(data, labels)`.\n        \"\"\"", "\n", "f", "=", "open", "(", "fpath", ",", "'rb'", ")", "\n", "if", "sys", ".", "version_info", "<", "(", "3", ",", ")", ":", "\n", "            ", "d", "=", "cPickle", ".", "load", "(", "f", ")", "\n", "", "else", ":", "\n", "            ", "d", "=", "cPickle", ".", "load", "(", "f", ",", "encoding", "=", "'bytes'", ")", "\n", "# decode utf8", "\n", "d_decoded", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "d", ".", "items", "(", ")", ":", "\n", "                ", "d_decoded", "[", "k", ".", "decode", "(", "'utf8'", ")", "]", "=", "v", "\n", "", "d", "=", "d_decoded", "\n", "", "f", ".", "close", "(", ")", "\n", "data", "=", "d", "[", "'data'", "]", "\n", "labels", "=", "d", "[", "label_key", "]", "\n", "\n", "data", "=", "data", ".", "reshape", "(", "data", ".", "shape", "[", "0", "]", ",", "3", ",", "32", ",", "32", ")", "\n", "return", "data", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar100_subset.Cifar100_Subset.maybe_download": [[78, 85], ["download.maybe_download_and_extract"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.download.maybe_download_and_extract"], ["", "def", "maybe_download", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Download and extract the CIFAR-100 data-set if it doesn't already exist\n        in data_path (set this variable first to the desired path).\n        \"\"\"", "\n", "\n", "download", ".", "maybe_download_and_extract", "(", "url", "=", "self", ".", "data_url", ",", "download_dir", "=", "self", ".", "data_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar100_subset.Cifar100_Subset.load_training_data": [[86, 107], ["os.path.join", "os.path.join", "cifar100_subset.Cifar100_Subset._load_batch", "cifar100_subset.Cifar100_Subset._load_batch", "sorted", "enumerate", "datasets.Dataset.one_hot_encoded", "keras.backend.image_data_format", "x_train.transpose.transpose.transpose", "numpy.asarray", "list", "len", "range", "set", "enumerate", "len"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar10.Cifar10._load_batch", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar10.Cifar10._load_batch", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.Dataset.one_hot_encoded"], ["", "def", "load_training_data", "(", "self", ")", ":", "\n", "        ", "dirname", "=", "'cifar-100-python'", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "dirname", ")", "\n", "fpath", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'train'", ")", "\n", "x_train", ",", "y_train_fine", "=", "self", ".", "_load_batch", "(", "fpath", ",", "'fine_labels'", ")", "\n", "_", ",", "y_train_coarse", "=", "self", ".", "_load_batch", "(", "fpath", ",", "'coarse_labels'", ")", "\n", "\n", "if", "K", ".", "image_data_format", "(", ")", "==", "'channels_last'", ":", "\n", "            ", "x_train", "=", "x_train", ".", "transpose", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "\n", "", "curr_superclass_idxes", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "y_train_fine", ")", ")", "if", "y_train_coarse", "[", "i", "]", "==", "self", ".", "superclass_idx", "]", "\n", "x_train", "=", "x_train", "[", "curr_superclass_idxes", "]", "\n", "y_train", "=", "np", ".", "asarray", "(", "y_train_fine", ")", "[", "curr_superclass_idxes", "]", "\n", "y_train_values", "=", "sorted", "(", "list", "(", "set", "(", "y_train", ")", ")", ")", "\n", "assert", "(", "len", "(", "y_train_values", ")", "==", "self", ".", "n_classes", ")", "\n", "map_dict", "=", "{", "val", ":", "i", "for", "i", ",", "val", "in", "enumerate", "(", "y_train_values", ")", "}", "\n", "for", "i", ",", "y", "in", "enumerate", "(", "y_train", ")", ":", "\n", "            ", "y_train", "[", "i", "]", "=", "map_dict", "[", "y", "]", "\n", "\n", "", "y_train_labels", "=", "one_hot_encoded", "(", "y_train", ",", "num_classes", "=", "self", ".", "n_classes", ")", "\n", "return", "x_train", ",", "y_train", ",", "y_train_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar100_subset.Cifar100_Subset.load_test_data": [[108, 129], ["os.path.join", "os.path.join", "cifar100_subset.Cifar100_Subset._load_batch", "cifar100_subset.Cifar100_Subset._load_batch", "sorted", "enumerate", "datasets.Dataset.one_hot_encoded", "keras.backend.image_data_format", "x_test.transpose.transpose.transpose", "numpy.asarray", "list", "len", "range", "set", "enumerate", "len"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar10.Cifar10._load_batch", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar10.Cifar10._load_batch", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.Dataset.one_hot_encoded"], ["", "def", "load_test_data", "(", "self", ")", ":", "\n", "        ", "dirname", "=", "'cifar-100-python'", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "dirname", ")", "\n", "fpath", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'test'", ")", "\n", "x_test", ",", "y_test_fine", "=", "self", ".", "_load_batch", "(", "fpath", ",", "'fine_labels'", ")", "\n", "_", ",", "y_test_coarse", "=", "self", ".", "_load_batch", "(", "fpath", ",", "'coarse_labels'", ")", "\n", "\n", "if", "K", ".", "image_data_format", "(", ")", "==", "'channels_last'", ":", "\n", "            ", "x_test", "=", "x_test", ".", "transpose", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "\n", "", "curr_superclass_idxes", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "y_test_fine", ")", ")", "if", "y_test_coarse", "[", "i", "]", "==", "self", ".", "superclass_idx", "]", "\n", "x_test", "=", "x_test", "[", "curr_superclass_idxes", "]", "\n", "y_test", "=", "np", ".", "asarray", "(", "y_test_fine", ")", "[", "curr_superclass_idxes", "]", "\n", "y_test_values", "=", "sorted", "(", "list", "(", "set", "(", "y_test", ")", ")", ")", "\n", "assert", "(", "len", "(", "y_test_values", ")", "==", "self", ".", "n_classes", ")", "\n", "map_dict", "=", "{", "val", ":", "i", "for", "i", ",", "val", "in", "enumerate", "(", "y_test_values", ")", "}", "\n", "for", "i", ",", "y", "in", "enumerate", "(", "y_test", ")", ":", "\n", "            ", "y_test", "[", "i", "]", "=", "map_dict", "[", "y", "]", "\n", "\n", "", "y_test_labels", "=", "one_hot_encoded", "(", "y_test", ",", "num_classes", "=", "self", ".", "n_classes", ")", "\n", "return", "x_test", ",", "y_test", ",", "y_test_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar100_subset.Cifar100_Subset.set_superclass_idx": [[130, 137], ["super().update_data_set", "str"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.Dataset.Dataset.update_data_set"], ["", "def", "set_superclass_idx", "(", "self", ",", "new_idx", ")", ":", "\n", "        ", "self", ".", "superclass_idx", "=", "new_idx", "\n", "self", ".", "name", "=", "'cifar_100_superclass_'", "+", "str", "(", "new_idx", ")", "\n", "smaller_data_set", "=", "None", "\n", "if", "self", ".", "smaller_data_set", ":", "\n", "            ", "smaller_data_set", "=", "self", ".", "data_size", "\n", "", "super", "(", "Cifar100_Subset", ",", "self", ")", ".", "update_data_set", "(", "smaller_data_set", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar100_subset.Cifar100_Subset.normalize_dataset": [[138, 159], ["cifar100_subset.Cifar100_Subset.x_train.astype", "cifar100_subset.Cifar100_Subset.x_test.astype", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.std", "numpy.std", "numpy.std"], "methods", ["None"], ["", "def", "normalize_dataset", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "normalized", ":", "\n", "            ", "self", ".", "x_train", "=", "self", ".", "x_train", ".", "astype", "(", "'float32'", ")", "\n", "self", ".", "x_test", "=", "self", ".", "x_test", ".", "astype", "(", "'float32'", ")", "\n", "mean_r", "=", "np", ".", "mean", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "0", "]", ")", "\n", "mean_g", "=", "np", ".", "mean", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "1", "]", ")", "\n", "mean_b", "=", "np", ".", "mean", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "2", "]", ")", "\n", "\n", "std_r", "=", "np", ".", "std", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "0", "]", ")", "\n", "std_g", "=", "np", ".", "std", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "1", "]", ")", "\n", "std_b", "=", "np", ".", "std", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "2", "]", ")", "\n", "\n", "\n", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "0", "]", "=", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "0", "]", "-", "mean_r", ")", "/", "std_r", "\n", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "1", "]", "=", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "1", "]", "-", "mean_g", ")", "/", "std_g", "\n", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "2", "]", "=", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "2", "]", "-", "mean_b", ")", "/", "std_b", "\n", "\n", "self", ".", "x_test", "[", ":", ",", ":", ",", ":", ",", "0", "]", "=", "(", "self", ".", "x_test", "[", ":", ",", ":", ",", ":", ",", "0", "]", "-", "mean_r", ")", "/", "std_r", "\n", "self", ".", "x_test", "[", ":", ",", ":", ",", ":", ",", "1", "]", "=", "(", "self", ".", "x_test", "[", ":", ",", ":", ",", ":", ",", "1", "]", "-", "mean_g", ")", "/", "std_g", "\n", "self", ".", "x_test", "[", ":", ",", ":", ",", ":", ",", "2", "]", "=", "(", "self", ".", "x_test", "[", ":", ",", ":", ",", ":", ",", "2", "]", "-", "mean_b", ")", "/", "std_b", "\n", "", "self", ".", "normalized", "=", "True", "", "", "", ""]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar10.Cifar10.__init__": [[17, 37], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.Inception.__init__"], ["    ", "def", "__init__", "(", "self", ",", "smaller_data_size", "=", "None", ",", "normalize", "=", "True", ")", ":", "\n", "        ", "self", ".", "name", "=", "'cifar10'", "\n", "\n", "# Internet URL for the tar-file with the Inception model.", "\n", "# Note that this might change in the future and will need to be updated.", "\n", "self", ".", "data_url", "=", "r\"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"", "\n", "\n", "# Directory to store the downloaded data.", "\n", "self", ".", "data_dir", "=", "\"./data/cifar10/\"", "\n", "\n", "self", ".", "height", ",", "self", ".", "width", ",", "self", ".", "depth", "=", "32", ",", "32", ",", "3", "\n", "self", ".", "n_classes", "=", "10", "\n", "self", ".", "img_size_flat", "=", "self", ".", "height", "*", "self", ".", "width", "*", "self", ".", "depth", "\n", "\n", "\n", "self", ".", "smaller_data_set", "=", "False", "\n", "if", "smaller_data_size", "is", "not", "None", ":", "\n", "            ", "self", ".", "smaller_data_set", "=", "True", "\n", "self", ".", "data_size", "=", "smaller_data_size", "\n", "", "super", "(", "Cifar10", ",", "self", ")", ".", "__init__", "(", "normalize", "=", "normalize", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar10.Cifar10._load_batch": [[38, 65], ["open", "open.close", "data.reshape.reshape.reshape", "six.moves.cPickle.load", "six.moves.cPickle.load", "six.moves.cPickle.load.items", "k.decode"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.Inception.close"], ["", "def", "_load_batch", "(", "self", ",", "fpath", ",", "label_key", "=", "'labels'", ")", ":", "\n", "        ", "\"\"\"Internal utility for parsing CIFAR data.\n\n        # Arguments\n            fpath: path the file to parse.\n            label_key: key for label data in the retrieve\n                dictionary.\n\n        # Returns\n            A tuple `(data, labels)`.\n        \"\"\"", "\n", "f", "=", "open", "(", "fpath", ",", "'rb'", ")", "\n", "if", "sys", ".", "version_info", "<", "(", "3", ",", ")", ":", "\n", "            ", "d", "=", "cPickle", ".", "load", "(", "f", ")", "\n", "", "else", ":", "\n", "            ", "d", "=", "cPickle", ".", "load", "(", "f", ",", "encoding", "=", "'bytes'", ")", "\n", "# decode utf8", "\n", "d_decoded", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "d", ".", "items", "(", ")", ":", "\n", "                ", "d_decoded", "[", "k", ".", "decode", "(", "'utf8'", ")", "]", "=", "v", "\n", "", "d", "=", "d_decoded", "\n", "", "f", ".", "close", "(", ")", "\n", "data", "=", "d", "[", "'data'", "]", "\n", "labels", "=", "d", "[", "label_key", "]", "\n", "\n", "data", "=", "data", ".", "reshape", "(", "data", ".", "shape", "[", "0", "]", ",", "self", ".", "depth", ",", "self", ".", "width", ",", "self", ".", "height", ")", "\n", "return", "data", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar10.Cifar10.maybe_download": [[66, 73], ["download.maybe_download_and_extract"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.download.maybe_download_and_extract"], ["", "def", "maybe_download", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Download and extract the CIFAR-100 data-set if it doesn't already exist\n        in data_path (set this variable first to the desired path).\n        \"\"\"", "\n", "\n", "download", ".", "maybe_download_and_extract", "(", "url", "=", "self", ".", "data_url", ",", "download_dir", "=", "self", ".", "data_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar10.Cifar10.load_training_data": [[74, 90], ["os.path.join", "numpy.zeros", "range", "x_train.transpose.transpose.astype", "datasets.Dataset.one_hot_encoded", "os.path.join", "cifar10.Cifar10._load_batch", "numpy.concatenate", "keras.backend.image_data_format", "x_train.transpose.transpose.transpose", "numpy.array", "str"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.Dataset.one_hot_encoded", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar10.Cifar10._load_batch"], ["", "def", "load_training_data", "(", "self", ")", ":", "\n", "        ", "dirname", "=", "'cifar-10-batches-py'", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "dirname", ")", "\n", "n_train_batchs", "=", "5", "\n", "x_train", "=", "np", ".", "zeros", "(", "(", "0", ",", "self", ".", "depth", ",", "self", ".", "width", ",", "self", ".", "height", ")", ")", "\n", "y_train", "=", "[", "]", "\n", "for", "batch", "in", "range", "(", "n_train_batchs", ")", ":", "\n", "            ", "fpath", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'data_batch_'", "+", "str", "(", "batch", "+", "1", ")", ")", "\n", "cur_data", ",", "cur_labels", "=", "self", ".", "_load_batch", "(", "fpath", ")", "\n", "x_train", "=", "np", ".", "concatenate", "(", "(", "cur_data", ",", "x_train", ")", ",", "axis", "=", "0", ")", "\n", "y_train", "=", "cur_labels", "+", "y_train", "\n", "", "x_train", "=", "x_train", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "if", "K", ".", "image_data_format", "(", ")", "==", "'channels_last'", ":", "\n", "            ", "x_train", "=", "x_train", ".", "transpose", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "", "y_train_labels", "=", "one_hot_encoded", "(", "y_train", ",", "num_classes", "=", "self", ".", "n_classes", ")", "\n", "return", "x_train", ",", "np", ".", "array", "(", "y_train", ")", ",", "y_train_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar10.Cifar10.load_test_data": [[92, 103], ["os.path.join", "os.path.join", "cifar10.Cifar10._load_batch", "datasets.Dataset.one_hot_encoded", "keras.backend.image_data_format", "x_test.transpose.transpose.transpose", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar10.Cifar10._load_batch", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.Dataset.one_hot_encoded"], ["", "def", "load_test_data", "(", "self", ")", ":", "\n", "        ", "dirname", "=", "'cifar-10-batches-py'", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "dirname", ")", "\n", "fpath", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'test_batch'", ")", "\n", "x_test", ",", "y_test", "=", "self", ".", "_load_batch", "(", "fpath", ")", "\n", "\n", "if", "K", ".", "image_data_format", "(", ")", "==", "'channels_last'", ":", "\n", "            ", "x_test", "=", "x_test", ".", "transpose", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "\n", "", "y_test_labels", "=", "one_hot_encoded", "(", "y_test", ",", "num_classes", "=", "self", ".", "n_classes", ")", "\n", "return", "x_test", ",", "np", ".", "array", "(", "y_test", ")", ",", "y_test_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.cifar10.Cifar10.normalize_dataset": [[104, 125], ["cifar10.Cifar10.x_train.astype", "cifar10.Cifar10.x_test.astype", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.std", "numpy.std", "numpy.std"], "methods", ["None"], ["", "def", "normalize_dataset", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "normalized", ":", "\n", "            ", "self", ".", "x_train", "=", "self", ".", "x_train", ".", "astype", "(", "'float32'", ")", "\n", "self", ".", "x_test", "=", "self", ".", "x_test", ".", "astype", "(", "'float32'", ")", "\n", "mean_r", "=", "np", ".", "mean", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "0", "]", ")", "\n", "mean_g", "=", "np", ".", "mean", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "1", "]", ")", "\n", "mean_b", "=", "np", ".", "mean", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "2", "]", ")", "\n", "\n", "std_r", "=", "np", ".", "std", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "0", "]", ")", "\n", "std_g", "=", "np", ".", "std", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "1", "]", ")", "\n", "std_b", "=", "np", ".", "std", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "2", "]", ")", "\n", "\n", "\n", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "0", "]", "=", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "0", "]", "-", "mean_r", ")", "/", "std_r", "\n", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "1", "]", "=", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "1", "]", "-", "mean_g", ")", "/", "std_g", "\n", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "2", "]", "=", "(", "self", ".", "x_train", "[", ":", ",", ":", ",", ":", ",", "2", "]", "-", "mean_b", ")", "/", "std_b", "\n", "\n", "self", ".", "x_test", "[", ":", ",", ":", ",", ":", ",", "0", "]", "=", "(", "self", ".", "x_test", "[", ":", ",", ":", ",", ":", ",", "0", "]", "-", "mean_r", ")", "/", "std_r", "\n", "self", ".", "x_test", "[", ":", ",", ":", ",", ":", ",", "1", "]", "=", "(", "self", ".", "x_test", "[", ":", ",", ":", ",", ":", ",", "1", "]", "-", "mean_g", ")", "/", "std_g", "\n", "self", ".", "x_test", "[", ":", ",", ":", ",", ":", ",", "2", "]", "=", "(", "self", ".", "x_test", "[", ":", ",", ":", ",", ":", ",", "2", "]", "-", "mean_b", ")", "/", "std_b", "\n", "", "self", ".", "normalized", "=", "True", "", "", "", ""]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.Dataset.Dataset.__init__": [[38, 45], ["Dataset.Dataset.maybe_download", "Dataset.Dataset.update_data_set", "Dataset.Dataset.normalize_dataset"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.maybe_download", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.Dataset.Dataset.update_data_set", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.Dataset.Dataset.normalize_dataset"], ["    ", "def", "__init__", "(", "self", ",", "normalize", "=", "True", ")", ":", "\n", "        ", "self", ".", "maybe_download", "(", ")", "\n", "self", ".", "update_data_set", "(", ")", "\n", "self", ".", "normalized", "=", "False", "\n", "if", "normalize", ":", "\n", "            ", "self", ".", "normalize_dataset", "(", ")", "\n", "self", ".", "normalized", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.Dataset.Dataset.update_train_test_cross_validate": [[46, 57], ["None"], "methods", ["None"], ["", "", "def", "update_train_test_cross_validate", "(", "self", ",", "train_idx", ",", "val_idx", ")", ":", "\n", "\n", "        ", "self", ".", "x_test", "=", "self", ".", "x_train", "[", "val_idx", ",", ":", ",", ":", ",", ":", "]", "\n", "self", ".", "x_train", "=", "self", ".", "x_train", "[", "train_idx", ",", ":", ",", ":", ",", ":", "]", "\n", "self", ".", "y_test_labels", "=", "self", ".", "y_train_labels", "[", "val_idx", ",", ":", "]", "\n", "self", ".", "y_train_labels", "=", "self", ".", "y_train_labels", "[", "train_idx", ",", ":", "]", "\n", "self", ".", "y_test", "=", "self", ".", "y_train", "[", "val_idx", "]", "\n", "self", ".", "y_train", "=", "self", ".", "y_train", "[", "train_idx", "]", "\n", "\n", "self", ".", "test_size", "=", "self", ".", "y_test", ".", "size", "\n", "self", ".", "train_size", "=", "self", ".", "y_train", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.Dataset.Dataset.update_data_set": [[58, 65], ["Dataset.Dataset.load_training_data", "Dataset.Dataset.load_test_data"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.Dataset.Dataset.load_training_data", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.Dataset.Dataset.load_test_data"], ["", "def", "update_data_set", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "x_train", ",", "self", ".", "y_train", ",", "self", ".", "y_train_labels", "=", "self", ".", "load_training_data", "(", ")", "\n", "self", ".", "x_test", ",", "self", ".", "y_test", ",", "self", ".", "y_test_labels", "=", "self", ".", "load_test_data", "(", ")", "\n", "\n", "self", ".", "test_size", "=", "self", ".", "y_test", ".", "size", "\n", "self", ".", "train_size", "=", "self", ".", "y_train", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.Dataset.Dataset.normalize_dataset": [[67, 69], ["None"], "methods", ["None"], ["", "def", "normalize_dataset", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.Dataset.Dataset.maybe_download": [[70, 72], ["None"], "methods", ["None"], ["", "def", "maybe_download", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.Dataset.Dataset.load_training_data": [[73, 75], ["None"], "methods", ["None"], ["", "def", "load_training_data", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.Dataset.Dataset.load_test_data": [[76, 78], ["None"], "methods", ["None"], ["", "def", "load_test_data", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.datasets.Dataset.one_hot_encoded": [[11, 35], ["numpy.eye", "numpy.max"], "function", ["None"], ["def", "one_hot_encoded", "(", "class_numbers", ",", "num_classes", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Generate the One-Hot encoded class-labels from an array of integers.\n\n    For example, if class_number=2 and num_classes=4 then\n    the one-hot encoded label is the float array: [0. 0. 1. 0.]\n\n    :param class_numbers:\n        Array of integers with class-numbers.\n        Assume the integers are from zero to num_classes-1 inclusive.\n\n    :param num_classes:\n        Number of classes. If None then use max(class_numbers)+1.\n\n    :return:\n        2-dim array of shape: [len(class_numbers), num_classes]\n    \"\"\"", "\n", "\n", "# Find the number of classes if None is provided.", "\n", "# Assumes the lowest class-number is zero.", "\n", "if", "num_classes", "is", "None", ":", "\n", "        ", "num_classes", "=", "np", ".", "max", "(", "class_numbers", ")", "+", "1", "\n", "\n", "", "return", "np", ".", "eye", "(", "num_classes", ",", "dtype", "=", "float", ")", "[", "class_numbers", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.NameLookup.__init__": [[115, 178], ["os.path.join", "os.path.join", "open", "file.readlines", "open", "file.readlines", "line.replace.replace.replace", "line.replace.replace.split", "line.replace.replace.startswith", "line.replace.replace.split", "int", "line.replace.replace.startswith", "line.replace.replace.split"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "# Mappings between uid, cls and name are dicts, where insertions and", "\n", "# lookup have O(1) time-usage on average, but may be O(n) in worst case.", "\n", "        ", "self", ".", "_uid_to_cls", "=", "{", "}", "# Map from uid to cls.", "\n", "self", ".", "_uid_to_name", "=", "{", "}", "# Map from uid to name.", "\n", "self", ".", "_cls_to_uid", "=", "{", "}", "# Map from cls to uid.", "\n", "\n", "# Read the uid-to-name mappings from file.", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "path_uid_to_name", ")", "\n", "with", "open", "(", "file", "=", "path", ",", "mode", "=", "'r'", ")", "as", "file", ":", "\n", "# Read all lines from the file.", "\n", "            ", "lines", "=", "file", ".", "readlines", "(", ")", "\n", "\n", "for", "line", "in", "lines", ":", "\n", "# Remove newlines.", "\n", "                ", "line", "=", "line", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "\n", "# Split the line on tabs.", "\n", "elements", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "\n", "# Get the uid.", "\n", "uid", "=", "elements", "[", "0", "]", "\n", "\n", "# Get the class-name.", "\n", "name", "=", "elements", "[", "1", "]", "\n", "\n", "# Insert into the lookup-dict.", "\n", "self", ".", "_uid_to_name", "[", "uid", "]", "=", "name", "\n", "\n", "# Read the uid-to-cls mappings from file.", "\n", "", "", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "path_uid_to_cls", ")", "\n", "with", "open", "(", "file", "=", "path", ",", "mode", "=", "'r'", ")", "as", "file", ":", "\n", "# Read all lines from the file.", "\n", "            ", "lines", "=", "file", ".", "readlines", "(", ")", "\n", "\n", "for", "line", "in", "lines", ":", "\n", "# We assume the file is in the proper format,", "\n", "# so the following lines come in pairs. Other lines are ignored.", "\n", "\n", "                ", "if", "line", ".", "startswith", "(", "\"  target_class: \"", ")", ":", "\n", "# This line must be the class-number as an integer.", "\n", "\n", "# Split the line.", "\n", "                    ", "elements", "=", "line", ".", "split", "(", "\": \"", ")", "\n", "\n", "# Get the class-number as an integer.", "\n", "cls", "=", "int", "(", "elements", "[", "1", "]", ")", "\n", "\n", "", "elif", "line", ".", "startswith", "(", "\"  target_class_string: \"", ")", ":", "\n", "# This line must be the uid as a string.", "\n", "\n", "# Split the line.", "\n", "                    ", "elements", "=", "line", ".", "split", "(", "\": \"", ")", "\n", "\n", "# Get the uid as a string e.g. \"n01494475\"", "\n", "uid", "=", "elements", "[", "1", "]", "\n", "\n", "# Remove the enclosing \"\" from the string.", "\n", "uid", "=", "uid", "[", "1", ":", "-", "2", "]", "\n", "\n", "# Insert into the lookup-dicts for both ways between uid and cls.", "\n", "self", ".", "_uid_to_cls", "[", "uid", "]", "=", "cls", "\n", "self", ".", "_cls_to_uid", "[", "cls", "]", "=", "uid", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.NameLookup.uid_to_cls": [[179, 185], ["None"], "methods", ["None"], ["", "", "", "", "def", "uid_to_cls", "(", "self", ",", "uid", ")", ":", "\n", "        ", "\"\"\"\n        Return the class-number as an integer for the given uid-string.\n        \"\"\"", "\n", "\n", "return", "self", ".", "_uid_to_cls", "[", "uid", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.NameLookup.uid_to_name": [[186, 202], ["name.split"], "methods", ["None"], ["", "def", "uid_to_name", "(", "self", ",", "uid", ",", "only_first_name", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Return the class-name for the given uid string.\n\n        Some class-names are lists of names, if you only want the first name,\n        then set only_first_name=True.\n        \"\"\"", "\n", "\n", "# Lookup the name from the uid.", "\n", "name", "=", "self", ".", "_uid_to_name", "[", "uid", "]", "\n", "\n", "# Only use the first name in the list?", "\n", "if", "only_first_name", ":", "\n", "            ", "name", "=", "name", ".", "split", "(", "\",\"", ")", "[", "0", "]", "\n", "\n", "", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.NameLookup.cls_to_name": [[203, 218], ["inception.NameLookup.uid_to_name"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.NameLookup.uid_to_name"], ["", "def", "cls_to_name", "(", "self", ",", "cls", ",", "only_first_name", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Return the class-name from the integer class-number.\n\n        Some class-names are lists of names, if you only want the first name,\n        then set only_first_name=True.\n        \"\"\"", "\n", "\n", "# Lookup the uid from the cls.", "\n", "uid", "=", "self", ".", "_cls_to_uid", "[", "cls", "]", "\n", "\n", "# Lookup the name from the uid.", "\n", "name", "=", "self", ".", "uid_to_name", "(", "uid", "=", "uid", ",", "only_first_name", "=", "only_first_name", ")", "\n", "\n", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.Inception.__init__": [[256, 307], ["inception.NameLookup", "tensorflow.Graph", "inception.Inception.graph.get_tensor_by_name", "inception.Inception.graph.get_tensor_by_name", "inception.Inception.graph.get_tensor_by_name", "inception.Inception.graph.get_tensor_by_name", "tensorflow.Session", "inception.Inception.graph.as_default", "os.path.join", "inception.Inception.transfer_layer.get_shape", "tensorflow.gfile.FastGFile", "tensorflow.GraphDef", "tensorflow.GraphDef.ParseFromString", "tensorflow.import_graph_def", "file.read"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "# Mappings between class-numbers and class-names.", "\n", "# Used to print the class-name as a string e.g. \"horse\" or \"plant\".", "\n", "        ", "self", ".", "name_lookup", "=", "NameLookup", "(", ")", "\n", "\n", "# Now load the Inception model from file. The way TensorFlow", "\n", "# does this is confusing and requires several steps.", "\n", "\n", "# Create a new TensorFlow computational graph.", "\n", "self", ".", "graph", "=", "tf", ".", "Graph", "(", ")", "\n", "\n", "# Set the new graph as the default.", "\n", "with", "self", ".", "graph", ".", "as_default", "(", ")", ":", "\n", "\n", "# TensorFlow graphs are saved to disk as so-called Protocol Buffers", "\n", "# aka. proto-bufs which is a file-format that works on multiple", "\n", "# platforms. In this case it is saved as a binary file.", "\n", "\n", "# Open the graph-def file for binary reading.", "\n", "            ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "path_graph_def", ")", "\n", "with", "tf", ".", "gfile", ".", "FastGFile", "(", "path", ",", "'rb'", ")", "as", "file", ":", "\n", "# The graph-def is a saved copy of a TensorFlow graph.", "\n", "# First we need to create an empty graph-def.", "\n", "                ", "graph_def", "=", "tf", ".", "GraphDef", "(", ")", "\n", "\n", "# Then we load the proto-buf file into the graph-def.", "\n", "graph_def", ".", "ParseFromString", "(", "file", ".", "read", "(", ")", ")", "\n", "\n", "# Finally we import the graph-def to the default TensorFlow graph.", "\n", "tf", ".", "import_graph_def", "(", "graph_def", ",", "name", "=", "''", ")", "\n", "\n", "# Now self.graph holds the Inception model from the proto-buf file.", "\n", "\n", "# Get the output of the Inception model by looking up the tensor", "\n", "# with the appropriate name for the output of the softmax-classifier.", "\n", "", "", "self", ".", "y_pred", "=", "self", ".", "graph", ".", "get_tensor_by_name", "(", "self", ".", "tensor_name_softmax", ")", "\n", "\n", "# Get the unscaled outputs for the Inception model (aka. softmax-logits).", "\n", "self", ".", "y_logits", "=", "self", ".", "graph", ".", "get_tensor_by_name", "(", "self", ".", "tensor_name_softmax_logits", ")", "\n", "\n", "# Get the tensor for the resized image that is input to the neural network.", "\n", "self", ".", "resized_image", "=", "self", ".", "graph", ".", "get_tensor_by_name", "(", "self", ".", "tensor_name_resized_image", ")", "\n", "\n", "# Get the tensor for the last layer of the graph, aka. the transfer-layer.", "\n", "self", ".", "transfer_layer", "=", "self", ".", "graph", ".", "get_tensor_by_name", "(", "self", ".", "tensor_name_transfer_layer", ")", "\n", "\n", "# Get the number of elements in the transfer-layer.", "\n", "self", ".", "transfer_len", "=", "self", ".", "transfer_layer", ".", "get_shape", "(", ")", "[", "3", "]", "\n", "\n", "# Create a TensorFlow session for executing the graph.", "\n", "self", ".", "session", "=", "tf", ".", "Session", "(", "graph", "=", "self", ".", "graph", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.Inception.close": [[308, 315], ["inception.Inception.session.close"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.Inception.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Call this function when you are done using the Inception model.\n        It closes the TensorFlow session to release its resources.\n        \"\"\"", "\n", "\n", "self", ".", "session", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.Inception._write_summary": [[316, 331], ["tensorflow.train.SummaryWriter", "tensorflow.train.SummaryWriter.close"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.Inception.close"], ["", "def", "_write_summary", "(", "self", ",", "logdir", "=", "'summary/'", ")", ":", "\n", "        ", "\"\"\"\n        Write graph to summary-file so it can be shown in TensorBoard.\n\n        This function is used for debugging and may be changed or removed in the future.\n\n        :param logdir:\n            Directory for writing the summary-files.\n\n        :return:\n            Nothing.\n        \"\"\"", "\n", "\n", "writer", "=", "tf", ".", "train", ".", "SummaryWriter", "(", "logdir", "=", "logdir", ",", "graph", "=", "self", ".", "graph", ")", "\n", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.Inception._create_feed_dict": [[332, 362], ["tensorflow.gfile.FastGFile().read", "ValueError", "tensorflow.gfile.FastGFile"], "methods", ["None"], ["", "def", "_create_feed_dict", "(", "self", ",", "image_path", "=", "None", ",", "image", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Create and return a feed-dict with an image.\n\n        :param image_path:\n            The input image is a jpeg-file with this file-path.\n\n        :param image:\n            The input image is a 3-dim array which is already decoded.\n            The pixels MUST be values between 0 and 255 (float or int).\n\n        :return:\n            Dict for feeding to the Inception graph in TensorFlow.\n        \"\"\"", "\n", "\n", "if", "image", "is", "not", "None", ":", "\n", "# Image is passed in as a 3-dim array that is already decoded.", "\n", "            ", "feed_dict", "=", "{", "self", ".", "tensor_name_input_image", ":", "image", "}", "\n", "\n", "", "elif", "image_path", "is", "not", "None", ":", "\n", "# Read the jpeg-image as an array of bytes.", "\n", "            ", "image_data", "=", "tf", ".", "gfile", ".", "FastGFile", "(", "image_path", ",", "'rb'", ")", ".", "read", "(", ")", "\n", "\n", "# Image is passed in as a jpeg-encoded image.", "\n", "feed_dict", "=", "{", "self", ".", "tensor_name_input_jpeg", ":", "image_data", "}", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Either image or image_path must be set.\"", ")", "\n", "\n", "", "return", "feed_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.Inception.classify": [[363, 392], ["inception.Inception._create_feed_dict", "inception.Inception.session.run", "numpy.squeeze"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.Inception._create_feed_dict"], ["", "def", "classify", "(", "self", ",", "image_path", "=", "None", ",", "image", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Use the Inception model to classify a single image.\n\n        The image will be resized automatically to 299 x 299 pixels,\n        see the discussion in the Python Notebook for Tutorial #07.\n\n        :param image_path:\n            The input image is a jpeg-file with this file-path.\n\n        :param image:\n            The input image is a 3-dim array which is already decoded.\n            The pixels MUST be values between 0 and 255 (float or int).\n\n        :return:\n            Array of floats (aka. softmax-array) indicating how likely\n            the Inception model thinks the image is of each given class.\n        \"\"\"", "\n", "\n", "# Create a feed-dict for the TensorFlow graph with the input image.", "\n", "feed_dict", "=", "self", ".", "_create_feed_dict", "(", "image_path", "=", "image_path", ",", "image", "=", "image", ")", "\n", "\n", "# Execute the TensorFlow session to get the predicted labels.", "\n", "pred", "=", "self", ".", "session", ".", "run", "(", "self", ".", "y_pred", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "# Reduce the array to a single dimension.", "\n", "pred", "=", "np", ".", "squeeze", "(", "pred", ")", "\n", "\n", "return", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.Inception.get_resized_image": [[393, 423], ["inception.Inception._create_feed_dict", "inception.Inception.session.run", "resized_image.squeeze.squeeze.squeeze", "resized_image.squeeze.squeeze.astype"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.Inception._create_feed_dict"], ["", "def", "get_resized_image", "(", "self", ",", "image_path", "=", "None", ",", "image", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Input an image to the Inception model and return\n        the resized image. The resized image can be plotted so\n        we can see what the neural network sees as its input.\n\n        :param image_path:\n            The input image is a jpeg-file with this file-path.\n\n        :param image:\n            The input image is a 3-dim array which is already decoded.\n            The pixels MUST be values between 0 and 255 (float or int).\n\n        :return:\n            A 3-dim array holding the image.\n        \"\"\"", "\n", "\n", "# Create a feed-dict for the TensorFlow graph with the input image.", "\n", "feed_dict", "=", "self", ".", "_create_feed_dict", "(", "image_path", "=", "image_path", ",", "image", "=", "image", ")", "\n", "\n", "# Execute the TensorFlow session to get the predicted labels.", "\n", "resized_image", "=", "self", ".", "session", ".", "run", "(", "self", ".", "resized_image", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "# Remove the 1st dimension of the 4-dim tensor.", "\n", "resized_image", "=", "resized_image", ".", "squeeze", "(", "axis", "=", "0", ")", "\n", "\n", "# Scale pixels to be between 0.0 and 1.0", "\n", "resized_image", "=", "resized_image", ".", "astype", "(", "float", ")", "/", "255.0", "\n", "\n", "return", "resized_image", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.Inception.print_scores": [[424, 458], ["pred.argsort", "reversed", "inception.Inception.name_lookup.cls_to_name", "print"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.NameLookup.cls_to_name"], ["", "def", "print_scores", "(", "self", ",", "pred", ",", "k", "=", "10", ",", "only_first_name", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Print the scores (or probabilities) for the top-k predicted classes.\n\n        :param pred:\n            Predicted class-labels returned from the predict() function.\n\n        :param k:\n            How many classes to print.\n\n        :param only_first_name:\n            Some class-names are lists of names, if you only want the first name,\n            then set only_first_name=True.\n\n        :return:\n            Nothing.\n        \"\"\"", "\n", "\n", "# Get a sorted index for the pred-array.", "\n", "idx", "=", "pred", ".", "argsort", "(", ")", "\n", "\n", "# The index is sorted lowest-to-highest values. Take the last k.", "\n", "top_k", "=", "idx", "[", "-", "k", ":", "]", "\n", "\n", "# Iterate the top-k classes in reversed order (i.e. highest first).", "\n", "for", "cls", "in", "reversed", "(", "top_k", ")", ":", "\n", "# Lookup the class-name.", "\n", "            ", "name", "=", "self", ".", "name_lookup", ".", "cls_to_name", "(", "cls", "=", "cls", ",", "only_first_name", "=", "only_first_name", ")", "\n", "\n", "# Predicted score (or probability) for this class.", "\n", "score", "=", "pred", "[", "cls", "]", "\n", "\n", "# Print the score and class-name.", "\n", "print", "(", "\"{0:>6.2%} : {1}\"", ".", "format", "(", "score", ",", "name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.Inception.transfer_values": [[459, 495], ["inception.Inception._create_feed_dict", "inception.Inception.session.run", "numpy.squeeze"], "methods", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.Inception._create_feed_dict"], ["", "", "def", "transfer_values", "(", "self", ",", "image_path", "=", "None", ",", "image", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Calculate the transfer-values for the given image.\n        These are the values of the last layer of the Inception model before\n        the softmax-layer, when inputting the image to the Inception model.\n\n        The transfer-values allow us to use the Inception model in so-called\n        Transfer Learning for other data-sets and different classifications.\n\n        It may take several hours or more to calculate the transfer-values\n        for all images in a data-set. It is therefore useful to cache the\n        results using the function transfer_values_cache() below.\n\n        :param image_path:\n            The input image is a jpeg-file with this file-path.\n\n        :param image:\n            The input image is a 3-dim array which is already decoded.\n            The pixels MUST be values between 0 and 255 (float or int).\n\n        :return:\n            The transfer-values for those images.\n        \"\"\"", "\n", "\n", "# Create a feed-dict for the TensorFlow graph with the input image.", "\n", "feed_dict", "=", "self", ".", "_create_feed_dict", "(", "image_path", "=", "image_path", ",", "image", "=", "image", ")", "\n", "\n", "# Use TensorFlow to run the graph for the Inception model.", "\n", "# This calculates the values for the last layer of the Inception model", "\n", "# prior to the softmax-classification, which we call transfer-values.", "\n", "transfer_values", "=", "self", ".", "session", ".", "run", "(", "self", ".", "transfer_layer", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "# Reduce to a 1-dim array.", "\n", "transfer_values", "=", "np", ".", "squeeze", "(", "transfer_values", ")", "\n", "\n", "return", "transfer_values", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.maybe_download": [[86, 94], ["print", "download.maybe_download_and_extract"], "function", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.download.maybe_download_and_extract"], ["def", "maybe_download", "(", ")", ":", "\n", "    ", "\"\"\"\n    Download the Inception model from the internet if it does not already\n    exist in the data_dir. The file is about 85 MB.\n    \"\"\"", "\n", "\n", "print", "(", "\"Downloading Inception v3 Model ...\"", ")", "\n", "download", ".", "maybe_download_and_extract", "(", "url", "=", "data_url", ",", "download_dir", "=", "data_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.process_images": [[501, 554], ["range", "print", "numpy.array", "len", "len", "sys.stdout.write", "sys.stdout.flush", "inception.transfer_values_cache.fn", "inception.transfer_values_cache.fn"], "function", ["None"], ["", "", "def", "process_images", "(", "fn", ",", "images", "=", "None", ",", "image_paths", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Call the function fn() for each image, e.g. transfer_values() from\n    the Inception model above. All the results are concatenated and returned.\n\n    :param fn:\n        Function to be called for each image.\n\n    :param images:\n        List of images to process.\n\n    :param image_paths:\n        List of file-paths for the images to process.\n\n    :return:\n        Numpy array with the results.\n    \"\"\"", "\n", "\n", "# Are we using images or image_paths?", "\n", "using_images", "=", "images", "is", "not", "None", "\n", "\n", "# Number of images.", "\n", "if", "using_images", ":", "\n", "        ", "num_images", "=", "len", "(", "images", ")", "\n", "", "else", ":", "\n", "        ", "num_images", "=", "len", "(", "image_paths", ")", "\n", "\n", "# Pre-allocate list for the results.", "\n", "# This holds references to other arrays. Initially the references are None.", "\n", "", "result", "=", "[", "None", "]", "*", "num_images", "\n", "\n", "# For each input image.", "\n", "for", "i", "in", "range", "(", "num_images", ")", ":", "\n", "# Status-message. Note the \\r which means the line should overwrite itself.", "\n", "        ", "msg", "=", "\"\\r- Processing image: {0:>6} / {1}\"", ".", "format", "(", "i", "+", "1", ",", "num_images", ")", "\n", "\n", "# Print the status message.", "\n", "sys", ".", "stdout", ".", "write", "(", "msg", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "# Process the image and store the result for later use.", "\n", "if", "using_images", ":", "\n", "            ", "result", "[", "i", "]", "=", "fn", "(", "image", "=", "images", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "            ", "result", "[", "i", "]", "=", "fn", "(", "image_path", "=", "image_paths", "[", "i", "]", ")", "\n", "\n", "# Print newline.", "\n", "", "", "print", "(", ")", "\n", "\n", "# Convert the result to a numpy array.", "\n", "result", "=", "np", ".", "array", "(", "result", ")", "\n", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.transfer_values_cache": [[559, 597], ["cache.cache", "inception.process_images"], "function", ["home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.None.cache.cache", "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.inception.process_images"], ["", "def", "transfer_values_cache", "(", "cache_path", ",", "model", ",", "images", "=", "None", ",", "image_paths", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    This function either loads the transfer-values if they have\n    already been calculated, otherwise it calculates the values\n    and saves them to a file that can be re-loaded again later.\n\n    Because the transfer-values can be expensive to compute, it can\n    be useful to cache the values through this function instead\n    of calling transfer_values() directly on the Inception model.\n\n    See Tutorial #08 for an example on how to use this function.\n\n    :param cache_path:\n        File containing the cached transfer-values for the images.\n\n    :param model:\n        Instance of the Inception model.\n\n    :param images:\n        4-dim array with images. [image_number, height, width, colour_channel]\n\n    :param image_paths:\n        Array of file-paths for images (must be jpeg-format).\n\n    :return:\n        The transfer-values from the Inception model for those images.\n    \"\"\"", "\n", "\n", "# Helper-function for processing the images if the cache-file does not exist.", "\n", "# This is needed because we cannot supply both fn=process_images", "\n", "# and fn=model.transfer_values to the cache()-function.", "\n", "def", "fn", "(", ")", ":", "\n", "        ", "return", "process_images", "(", "fn", "=", "model", ".", "transfer_values", ",", "images", "=", "images", ",", "image_paths", "=", "image_paths", ")", "\n", "\n", "# Read the transfer-values from a cache-file, or calculate them if the file does not exist.", "\n", "", "transfer_values", "=", "cache", "(", "cache_path", "=", "cache_path", ",", "fn", "=", "fn", ")", "\n", "\n", "return", "transfer_values", "\n", "\n"]], "home.repos.pwc.inspect_result.GuyHacohen_curriculum_learning.models.cifar100_model.Cifar100_Model.build_classifier_model": [[17, 99], ["keras.regularizers.l2", "keras.layers.Input", "keras.engine.training.Model", "keras.regularizers.l2", "keras.backend.image_data_format", "keras.layers.Conv2D", "keras.layers.Activation", "keras.layers.Conv2D", "keras.layers.Activation", "keras.layers.MaxPooling2D", "keras.layers.Dropout", "keras.layers.Conv2D", "keras.layers.Activation", "keras.layers.Conv2D", "keras.layers.Activation", "keras.layers.MaxPooling2D", "keras.layers.Dropout", "keras.layers.Conv2D", "keras.layers.Activation", "keras.layers.Conv2D", "keras.layers.Activation", "keras.layers.MaxPooling2D", "keras.layers.Dropout", "keras.layers.Conv2D", "keras.layers.Activation", "keras.layers.Conv2D", "keras.layers.Activation", "keras.layers.MaxPooling2D", "keras.layers.Dropout", "keras.layers.Flatten", "keras.layers.Dense", "keras.layers.Activation", "keras.layers.Dropout", "keras.layers.Dense", "keras.layers.Activation", "keras.layers.BatchNormalization", "keras.layers.BatchNormalization", "keras.layers.BatchNormalization", "keras.layers.BatchNormalization", "keras.layers.BatchNormalization", "keras.layers.BatchNormalization", "keras.layers.BatchNormalization", "keras.layers.BatchNormalization", "keras.layers.BatchNormalization", "keras.layers.BatchNormalization"], "methods", ["None"], ["    ", "def", "build_classifier_model", "(", "self", ",", "dataset", ",", "n_classes", "=", "5", ",", "\n", "activation", "=", "'elu'", ",", "dropout_1_rate", "=", "0.25", ",", "\n", "dropout_2_rate", "=", "0.5", ",", "\n", "reg_factor", "=", "50e-4", ",", "bias_reg_factor", "=", "None", ",", "batch_norm", "=", "False", ")", ":", "\n", "\n", "        ", "n_classes", "=", "dataset", ".", "n_classes", "\n", "\n", "l2_reg", "=", "regularizers", ".", "l2", "(", "reg_factor", ")", "#K.variable(K.cast_to_floatx(reg_factor))", "\n", "l2_bias_reg", "=", "None", "\n", "if", "bias_reg_factor", ":", "\n", "            ", "l2_bias_reg", "=", "regularizers", ".", "l2", "(", "bias_reg_factor", ")", "#K.variable(K.cast_to_floatx(bias_reg_factor))", "\n", "\n", "# input image dimensions", "\n", "", "h", ",", "w", ",", "d", "=", "32", ",", "32", ",", "3", "\n", "\n", "if", "K", ".", "image_data_format", "(", ")", "==", "'channels_first'", ":", "\n", "            ", "input_shape", "=", "(", "d", ",", "h", ",", "w", ")", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "(", "h", ",", "w", ",", "d", ")", "\n", "\n", "# input image dimensions", "\n", "", "x", "=", "input_1", "=", "Input", "(", "shape", "=", "input_shape", ")", "\n", "\n", "x", "=", "Conv2D", "(", "filters", "=", "32", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "padding", "=", "'same'", ",", "kernel_regularizer", "=", "l2_reg", ",", "bias_regularizer", "=", "l2_bias_reg", ")", "(", "x", ")", "\n", "if", "batch_norm", ":", "\n", "            ", "x", "=", "BatchNormalization", "(", ")", "(", "x", ")", "\n", "", "x", "=", "Activation", "(", "activation", "=", "activation", ")", "(", "x", ")", "\n", "x", "=", "Conv2D", "(", "filters", "=", "32", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "padding", "=", "'same'", ",", "kernel_regularizer", "=", "l2_reg", ",", "bias_regularizer", "=", "l2_bias_reg", ")", "(", "x", ")", "\n", "if", "batch_norm", ":", "\n", "            ", "x", "=", "BatchNormalization", "(", ")", "(", "x", ")", "\n", "", "x", "=", "Activation", "(", "activation", "=", "activation", ")", "(", "x", ")", "\n", "x", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ")", "(", "x", ")", "\n", "x", "=", "Dropout", "(", "rate", "=", "dropout_1_rate", ")", "(", "x", ")", "\n", "\n", "x", "=", "Conv2D", "(", "filters", "=", "64", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "padding", "=", "'same'", ",", "kernel_regularizer", "=", "l2_reg", ",", "bias_regularizer", "=", "l2_bias_reg", ")", "(", "x", ")", "\n", "if", "batch_norm", ":", "\n", "            ", "x", "=", "BatchNormalization", "(", ")", "(", "x", ")", "\n", "", "x", "=", "Activation", "(", "activation", "=", "activation", ")", "(", "x", ")", "\n", "x", "=", "Conv2D", "(", "filters", "=", "64", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "padding", "=", "'same'", ",", "kernel_regularizer", "=", "l2_reg", ",", "bias_regularizer", "=", "l2_bias_reg", ")", "(", "x", ")", "\n", "if", "batch_norm", ":", "\n", "            ", "x", "=", "BatchNormalization", "(", ")", "(", "x", ")", "\n", "", "x", "=", "Activation", "(", "activation", "=", "activation", ")", "(", "x", ")", "\n", "x", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ")", "(", "x", ")", "\n", "x", "=", "Dropout", "(", "rate", "=", "dropout_1_rate", ")", "(", "x", ")", "\n", "\n", "x", "=", "Conv2D", "(", "filters", "=", "128", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "padding", "=", "'same'", ",", "kernel_regularizer", "=", "l2_reg", ",", "bias_regularizer", "=", "l2_bias_reg", ")", "(", "x", ")", "\n", "if", "batch_norm", ":", "\n", "            ", "x", "=", "BatchNormalization", "(", ")", "(", "x", ")", "\n", "", "x", "=", "Activation", "(", "activation", "=", "activation", ")", "(", "x", ")", "\n", "x", "=", "Conv2D", "(", "filters", "=", "128", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "padding", "=", "'same'", ",", "kernel_regularizer", "=", "l2_reg", ",", "bias_regularizer", "=", "l2_bias_reg", ")", "(", "x", ")", "\n", "if", "batch_norm", ":", "\n", "            ", "x", "=", "BatchNormalization", "(", ")", "(", "x", ")", "\n", "", "x", "=", "Activation", "(", "activation", "=", "activation", ")", "(", "x", ")", "\n", "x", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ")", "(", "x", ")", "\n", "x", "=", "Dropout", "(", "rate", "=", "dropout_1_rate", ")", "(", "x", ")", "\n", "\n", "x", "=", "Conv2D", "(", "filters", "=", "256", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "'same'", ",", "kernel_regularizer", "=", "l2_reg", ",", "bias_regularizer", "=", "l2_bias_reg", ")", "(", "x", ")", "\n", "if", "batch_norm", ":", "\n", "            ", "x", "=", "BatchNormalization", "(", ")", "(", "x", ")", "\n", "", "x", "=", "Activation", "(", "activation", "=", "activation", ")", "(", "x", ")", "\n", "x", "=", "Conv2D", "(", "filters", "=", "256", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "'same'", ",", "kernel_regularizer", "=", "l2_reg", ",", "bias_regularizer", "=", "l2_bias_reg", ")", "(", "x", ")", "\n", "if", "batch_norm", ":", "\n", "            ", "x", "=", "BatchNormalization", "(", ")", "(", "x", ")", "\n", "", "x", "=", "Activation", "(", "activation", "=", "activation", ")", "(", "x", ")", "\n", "x", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ")", "(", "x", ")", "\n", "x", "=", "Dropout", "(", "rate", "=", "dropout_1_rate", ")", "(", "x", ")", "\n", "\n", "x", "=", "Flatten", "(", ")", "(", "x", ")", "\n", "x", "=", "Dense", "(", "units", "=", "512", ",", "kernel_regularizer", "=", "l2_reg", ",", "bias_regularizer", "=", "l2_bias_reg", ")", "(", "x", ")", "\n", "if", "batch_norm", ":", "\n", "            ", "x", "=", "BatchNormalization", "(", ")", "(", "x", ")", "\n", "", "x", "=", "Activation", "(", "activation", "=", "activation", ")", "(", "x", ")", "\n", "\n", "\n", "x", "=", "Dropout", "(", "rate", "=", "dropout_2_rate", ")", "(", "x", ")", "\n", "x", "=", "Dense", "(", "units", "=", "n_classes", ",", "kernel_regularizer", "=", "l2_reg", ",", "bias_regularizer", "=", "l2_bias_reg", ")", "(", "x", ")", "\n", "if", "batch_norm", ":", "\n", "            ", "x", "=", "BatchNormalization", "(", ")", "(", "x", ")", "\n", "", "x", "=", "Activation", "(", "activation", "=", "'softmax'", ")", "(", "x", ")", "\n", "\n", "model", "=", "Model", "(", "inputs", "=", "[", "input_1", "]", ",", "outputs", "=", "[", "x", "]", ")", "\n", "return", "model", "\n", "", "", ""]]}