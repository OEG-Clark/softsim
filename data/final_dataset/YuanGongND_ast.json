{"home.repos.pwc.inspect_result.YuanGongND_ast.src.traintest.train": [[20, 260], ["torch.device", "print", "torch.set_grad_enabled", "AverageMeter", "AverageMeter", "AverageMeter", "AverageMeter", "AverageMeter", "AverageMeter", "time.time", "nn.DataParallel.to", "print", "print", "torch.optim.Adam", "print", "torch.cuda.amp.GradScaler", "print", "print", "numpy.zeros", "nn.DataParallel.train", "progress.append", "isinstance", "torch.nn.DataParallel", "torch.nn.BCEWithLogitsLoss", "time.time", "time.time", "nn.DataParallel.train", "print", "print", "print", "enumerate", "print", "traintest.validate", "traintest.validate_ensemble", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "print", "print", "print", "print", "print", "print", "numpy.savetxt", "print", "torch.save", "torch.optim.lr_scheduler.MultiStepLR.step", "print", "traintest.train._save_progress"], "function", ["home.repos.pwc.inspect_result.YuanGongND_ast.src.traintest.train", "home.repos.pwc.inspect_result.YuanGongND_ast.src.traintest.train", "home.repos.pwc.inspect_result.YuanGongND_ast.src.traintest.validate", "home.repos.pwc.inspect_result.YuanGongND_ast.src.traintest.validate_ensemble"], ["def", "train", "(", "audio_model", ",", "train_loader", ",", "test_loader", ",", "args", ")", ":", "\n", "    ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "print", "(", "'running on '", "+", "str", "(", "device", ")", ")", "\n", "torch", ".", "set_grad_enabled", "(", "True", ")", "\n", "\n", "# Initialize all of the statistics we want to keep track of", "\n", "batch_time", "=", "AverageMeter", "(", ")", "\n", "per_sample_time", "=", "AverageMeter", "(", ")", "\n", "data_time", "=", "AverageMeter", "(", ")", "\n", "per_sample_data_time", "=", "AverageMeter", "(", ")", "\n", "loss_meter", "=", "AverageMeter", "(", ")", "\n", "per_sample_dnn_time", "=", "AverageMeter", "(", ")", "\n", "progress", "=", "[", "]", "\n", "# best_cum_mAP is checkpoint ensemble from the first epoch to the best epoch", "\n", "best_epoch", ",", "best_cum_epoch", ",", "best_mAP", ",", "best_acc", ",", "best_cum_mAP", "=", "0", ",", "0", ",", "-", "np", ".", "inf", ",", "-", "np", ".", "inf", ",", "-", "np", ".", "inf", "\n", "global_step", ",", "epoch", "=", "0", ",", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "exp_dir", "=", "args", ".", "exp_dir", "\n", "\n", "def", "_save_progress", "(", ")", ":", "\n", "        ", "progress", ".", "append", "(", "[", "epoch", ",", "global_step", ",", "best_epoch", ",", "best_mAP", ",", "\n", "time", ".", "time", "(", ")", "-", "start_time", "]", ")", "\n", "with", "open", "(", "\"%s/progress.pkl\"", "%", "exp_dir", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "pickle", ".", "dump", "(", "progress", ",", "f", ")", "\n", "\n", "", "", "if", "not", "isinstance", "(", "audio_model", ",", "nn", ".", "DataParallel", ")", ":", "\n", "        ", "audio_model", "=", "nn", ".", "DataParallel", "(", "audio_model", ")", "\n", "\n", "", "audio_model", "=", "audio_model", ".", "to", "(", "device", ")", "\n", "# Set up the optimizer", "\n", "trainables", "=", "[", "p", "for", "p", "in", "audio_model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "print", "(", "'Total parameter number is : {:.3f} million'", ".", "format", "(", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "audio_model", ".", "parameters", "(", ")", ")", "/", "1e6", ")", ")", "\n", "print", "(", "'Total trainable parameter number is : {:.3f} million'", ".", "format", "(", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "trainables", ")", "/", "1e6", ")", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "trainables", ",", "args", ".", "lr", ",", "weight_decay", "=", "5e-7", ",", "betas", "=", "(", "0.95", ",", "0.999", ")", ")", "\n", "\n", "# dataset specific settings", "\n", "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=args.lr_patience, verbose=True)", "\n", "if", "args", ".", "dataset", "==", "'audioset'", ":", "\n", "        ", "if", "len", "(", "train_loader", ".", "dataset", ")", ">", "2e5", ":", "\n", "            ", "print", "(", "'scheduler for full audioset is used'", ")", "\n", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "MultiStepLR", "(", "optimizer", ",", "[", "2", ",", "3", ",", "4", ",", "5", "]", ",", "gamma", "=", "0.5", ",", "last_epoch", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'scheduler for balanced audioset is used'", ")", "\n", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "MultiStepLR", "(", "optimizer", ",", "[", "10", ",", "15", ",", "20", ",", "25", "]", ",", "gamma", "=", "0.5", ",", "last_epoch", "=", "-", "1", ")", "\n", "", "main_metrics", "=", "'mAP'", "\n", "loss_fn", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "warmup", "=", "True", "\n", "", "elif", "args", ".", "dataset", "==", "'esc50'", ":", "\n", "        ", "print", "(", "'scheduler for esc-50 is used'", ")", "\n", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "MultiStepLR", "(", "optimizer", ",", "list", "(", "range", "(", "5", ",", "26", ")", ")", ",", "gamma", "=", "0.85", ")", "\n", "main_metrics", "=", "'acc'", "\n", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "warmup", "=", "False", "\n", "", "elif", "args", ".", "dataset", "==", "'speechcommands'", ":", "\n", "        ", "print", "(", "'scheduler for speech commands is used'", ")", "\n", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "MultiStepLR", "(", "optimizer", ",", "list", "(", "range", "(", "5", ",", "26", ")", ")", ",", "gamma", "=", "0.85", ")", "\n", "main_metrics", "=", "'acc'", "\n", "loss_fn", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "warmup", "=", "False", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'unknown dataset, dataset should be in [audioset, speechcommands, esc50]'", ")", "\n", "", "print", "(", "'now training with {:s}, main metrics: {:s}, loss function: {:s}, learning rate scheduler: {:s}'", ".", "format", "(", "str", "(", "args", ".", "dataset", ")", ",", "str", "(", "main_metrics", ")", ",", "str", "(", "loss_fn", ")", ",", "str", "(", "scheduler", ")", ")", ")", "\n", "args", ".", "loss_fn", "=", "loss_fn", "\n", "\n", "epoch", "+=", "1", "\n", "# for amp", "\n", "scaler", "=", "GradScaler", "(", ")", "\n", "\n", "print", "(", "\"current #steps=%s, #epochs=%s\"", "%", "(", "global_step", ",", "epoch", ")", ")", "\n", "print", "(", "\"start training...\"", ")", "\n", "result", "=", "np", ".", "zeros", "(", "[", "args", ".", "n_epochs", ",", "10", "]", ")", "\n", "audio_model", ".", "train", "(", ")", "\n", "while", "epoch", "<", "args", ".", "n_epochs", "+", "1", ":", "\n", "        ", "begin_time", "=", "time", ".", "time", "(", ")", "\n", "end_time", "=", "time", ".", "time", "(", ")", "\n", "audio_model", ".", "train", "(", ")", "\n", "print", "(", "'---------------'", ")", "\n", "print", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", "\n", "print", "(", "\"current #epochs=%s, #steps=%s\"", "%", "(", "epoch", ",", "global_step", ")", ")", "\n", "\n", "for", "i", ",", "(", "audio_input", ",", "labels", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "\n", "            ", "B", "=", "audio_input", ".", "size", "(", "0", ")", "\n", "audio_input", "=", "audio_input", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "labels", "=", "labels", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "\n", "data_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end_time", ")", "\n", "per_sample_data_time", ".", "update", "(", "(", "time", ".", "time", "(", ")", "-", "end_time", ")", "/", "audio_input", ".", "shape", "[", "0", "]", ")", "\n", "dnn_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# first several steps for warm-up", "\n", "if", "global_step", "<=", "1000", "and", "global_step", "%", "50", "==", "0", "and", "warmup", "==", "True", ":", "\n", "                ", "warm_lr", "=", "(", "global_step", "/", "1000", ")", "*", "args", ".", "lr", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "'lr'", "]", "=", "warm_lr", "\n", "", "print", "(", "'warm-up learning rate is {:f}'", ".", "format", "(", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ")", ")", "\n", "\n", "", "with", "autocast", "(", ")", ":", "\n", "                ", "audio_output", "=", "audio_model", "(", "audio_input", ")", "\n", "if", "isinstance", "(", "loss_fn", ",", "torch", ".", "nn", ".", "CrossEntropyLoss", ")", ":", "\n", "                    ", "loss", "=", "loss_fn", "(", "audio_output", ",", "torch", ".", "argmax", "(", "labels", ".", "long", "(", ")", ",", "axis", "=", "1", ")", ")", "\n", "", "else", ":", "\n", "                    ", "loss", "=", "loss_fn", "(", "audio_output", ",", "labels", ")", "\n", "\n", "# optimization if amp is not used", "\n", "# optimizer.zero_grad()", "\n", "# loss.backward()", "\n", "# optimizer.step()", "\n", "\n", "# optimiztion if amp is used", "\n", "", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "scaler", ".", "step", "(", "optimizer", ")", "\n", "scaler", ".", "update", "(", ")", "\n", "\n", "# record loss", "\n", "loss_meter", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "B", ")", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end_time", ")", "\n", "per_sample_time", ".", "update", "(", "(", "time", ".", "time", "(", ")", "-", "end_time", ")", "/", "audio_input", ".", "shape", "[", "0", "]", ")", "\n", "per_sample_dnn_time", ".", "update", "(", "(", "time", ".", "time", "(", ")", "-", "dnn_start_time", ")", "/", "audio_input", ".", "shape", "[", "0", "]", ")", "\n", "\n", "print_step", "=", "global_step", "%", "args", ".", "n_print_steps", "==", "0", "\n", "early_print_step", "=", "epoch", "==", "0", "and", "global_step", "%", "(", "args", ".", "n_print_steps", "/", "10", ")", "==", "0", "\n", "print_step", "=", "print_step", "or", "early_print_step", "\n", "\n", "if", "print_step", "and", "global_step", "!=", "0", ":", "\n", "                ", "print", "(", "'Epoch: [{0}][{1}/{2}]\\t'", "\n", "'Per Sample Total Time {per_sample_time.avg:.5f}\\t'", "\n", "'Per Sample Data Time {per_sample_data_time.avg:.5f}\\t'", "\n", "'Per Sample DNN Time {per_sample_dnn_time.avg:.5f}\\t'", "\n", "'Train Loss {loss_meter.avg:.4f}\\t'", ".", "format", "(", "\n", "epoch", ",", "i", ",", "len", "(", "train_loader", ")", ",", "per_sample_time", "=", "per_sample_time", ",", "per_sample_data_time", "=", "per_sample_data_time", ",", "\n", "per_sample_dnn_time", "=", "per_sample_dnn_time", ",", "loss_meter", "=", "loss_meter", ")", ",", "flush", "=", "True", ")", "\n", "if", "np", ".", "isnan", "(", "loss_meter", ".", "avg", ")", ":", "\n", "                    ", "print", "(", "\"training diverged...\"", ")", "\n", "return", "\n", "\n", "", "", "end_time", "=", "time", ".", "time", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "", "print", "(", "'start validation'", ")", "\n", "stats", ",", "valid_loss", "=", "validate", "(", "audio_model", ",", "test_loader", ",", "args", ",", "epoch", ")", "\n", "\n", "# ensemble results", "\n", "cum_stats", "=", "validate_ensemble", "(", "args", ",", "epoch", ")", "\n", "cum_mAP", "=", "np", ".", "mean", "(", "[", "stat", "[", "'AP'", "]", "for", "stat", "in", "cum_stats", "]", ")", "\n", "cum_mAUC", "=", "np", ".", "mean", "(", "[", "stat", "[", "'auc'", "]", "for", "stat", "in", "cum_stats", "]", ")", "\n", "cum_acc", "=", "cum_stats", "[", "0", "]", "[", "'acc'", "]", "\n", "\n", "mAP", "=", "np", ".", "mean", "(", "[", "stat", "[", "'AP'", "]", "for", "stat", "in", "stats", "]", ")", "\n", "mAUC", "=", "np", ".", "mean", "(", "[", "stat", "[", "'auc'", "]", "for", "stat", "in", "stats", "]", ")", "\n", "acc", "=", "stats", "[", "0", "]", "[", "'acc'", "]", "\n", "\n", "middle_ps", "=", "[", "stat", "[", "'precisions'", "]", "[", "int", "(", "len", "(", "stat", "[", "'precisions'", "]", ")", "/", "2", ")", "]", "for", "stat", "in", "stats", "]", "\n", "middle_rs", "=", "[", "stat", "[", "'recalls'", "]", "[", "int", "(", "len", "(", "stat", "[", "'recalls'", "]", ")", "/", "2", ")", "]", "for", "stat", "in", "stats", "]", "\n", "average_precision", "=", "np", ".", "mean", "(", "middle_ps", ")", "\n", "average_recall", "=", "np", ".", "mean", "(", "middle_rs", ")", "\n", "\n", "if", "main_metrics", "==", "'mAP'", ":", "\n", "            ", "print", "(", "\"mAP: {:.6f}\"", ".", "format", "(", "mAP", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"acc: {:.6f}\"", ".", "format", "(", "acc", ")", ")", "\n", "", "print", "(", "\"AUC: {:.6f}\"", ".", "format", "(", "mAUC", ")", ")", "\n", "print", "(", "\"Avg Precision: {:.6f}\"", ".", "format", "(", "average_precision", ")", ")", "\n", "print", "(", "\"Avg Recall: {:.6f}\"", ".", "format", "(", "average_recall", ")", ")", "\n", "print", "(", "\"d_prime: {:.6f}\"", ".", "format", "(", "d_prime", "(", "mAUC", ")", ")", ")", "\n", "print", "(", "\"train_loss: {:.6f}\"", ".", "format", "(", "loss_meter", ".", "avg", ")", ")", "\n", "print", "(", "\"valid_loss: {:.6f}\"", ".", "format", "(", "valid_loss", ")", ")", "\n", "\n", "if", "main_metrics", "==", "'mAP'", ":", "\n", "            ", "result", "[", "epoch", "-", "1", ",", ":", "]", "=", "[", "mAP", ",", "mAUC", ",", "average_precision", ",", "average_recall", ",", "d_prime", "(", "mAUC", ")", ",", "loss_meter", ".", "avg", ",", "valid_loss", ",", "cum_mAP", ",", "cum_mAUC", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "]", "\n", "", "else", ":", "\n", "            ", "result", "[", "epoch", "-", "1", ",", ":", "]", "=", "[", "acc", ",", "mAUC", ",", "average_precision", ",", "average_recall", ",", "d_prime", "(", "mAUC", ")", ",", "loss_meter", ".", "avg", ",", "valid_loss", ",", "cum_acc", ",", "cum_mAUC", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "]", "\n", "", "np", ".", "savetxt", "(", "exp_dir", "+", "'/result.csv'", ",", "result", ",", "delimiter", "=", "','", ")", "\n", "print", "(", "'validation finished'", ")", "\n", "\n", "if", "mAP", ">", "best_mAP", ":", "\n", "            ", "best_mAP", "=", "mAP", "\n", "if", "main_metrics", "==", "'mAP'", ":", "\n", "                ", "best_epoch", "=", "epoch", "\n", "\n", "", "", "if", "acc", ">", "best_acc", ":", "\n", "            ", "best_acc", "=", "acc", "\n", "if", "main_metrics", "==", "'acc'", ":", "\n", "                ", "best_epoch", "=", "epoch", "\n", "\n", "", "", "if", "cum_mAP", ">", "best_cum_mAP", ":", "\n", "            ", "best_cum_epoch", "=", "epoch", "\n", "best_cum_mAP", "=", "cum_mAP", "\n", "\n", "", "if", "best_epoch", "==", "epoch", ":", "\n", "            ", "torch", ".", "save", "(", "audio_model", ".", "state_dict", "(", ")", ",", "\"%s/models/best_audio_model.pth\"", "%", "(", "exp_dir", ")", ")", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "\"%s/models/best_optim_state.pth\"", "%", "(", "exp_dir", ")", ")", "\n", "\n", "", "torch", ".", "save", "(", "audio_model", ".", "state_dict", "(", ")", ",", "\"%s/models/audio_model.%d.pth\"", "%", "(", "exp_dir", ",", "epoch", ")", ")", "\n", "if", "len", "(", "train_loader", ".", "dataset", ")", ">", "2e5", ":", "\n", "            ", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "\"%s/models/optim_state.%d.pth\"", "%", "(", "exp_dir", ",", "epoch", ")", ")", "\n", "\n", "", "scheduler", ".", "step", "(", ")", "\n", "\n", "print", "(", "'Epoch-{0} lr: {1}'", ".", "format", "(", "epoch", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ")", ")", "\n", "\n", "with", "open", "(", "exp_dir", "+", "'/stats_'", "+", "str", "(", "epoch", ")", "+", "'.pickle'", ",", "'wb'", ")", "as", "handle", ":", "\n", "            ", "pickle", ".", "dump", "(", "stats", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "_save_progress", "(", ")", "\n", "\n", "finish_time", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'epoch {:d} training time: {:.3f}'", ".", "format", "(", "epoch", ",", "finish_time", "-", "begin_time", ")", ")", "\n", "\n", "epoch", "+=", "1", "\n", "\n", "batch_time", ".", "reset", "(", ")", "\n", "per_sample_time", ".", "reset", "(", ")", "\n", "data_time", ".", "reset", "(", ")", "\n", "per_sample_data_time", ".", "reset", "(", ")", "\n", "loss_meter", ".", "reset", "(", ")", "\n", "per_sample_dnn_time", ".", "reset", "(", ")", "\n", "\n", "", "if", "args", ".", "dataset", "==", "'audioset'", ":", "\n", "        ", "if", "len", "(", "train_loader", ".", "dataset", ")", ">", "2e5", ":", "\n", "            ", "stats", "=", "validate_wa", "(", "audio_model", ",", "test_loader", ",", "args", ",", "1", ",", "5", ")", "\n", "", "else", ":", "\n", "            ", "stats", "=", "validate_wa", "(", "audio_model", ",", "test_loader", ",", "args", ",", "6", ",", "25", ")", "\n", "", "mAP", "=", "np", ".", "mean", "(", "[", "stat", "[", "'AP'", "]", "for", "stat", "in", "stats", "]", ")", "\n", "mAUC", "=", "np", ".", "mean", "(", "[", "stat", "[", "'auc'", "]", "for", "stat", "in", "stats", "]", ")", "\n", "middle_ps", "=", "[", "stat", "[", "'precisions'", "]", "[", "int", "(", "len", "(", "stat", "[", "'precisions'", "]", ")", "/", "2", ")", "]", "for", "stat", "in", "stats", "]", "\n", "middle_rs", "=", "[", "stat", "[", "'recalls'", "]", "[", "int", "(", "len", "(", "stat", "[", "'recalls'", "]", ")", "/", "2", ")", "]", "for", "stat", "in", "stats", "]", "\n", "average_precision", "=", "np", ".", "mean", "(", "middle_ps", ")", "\n", "average_recall", "=", "np", ".", "mean", "(", "middle_rs", ")", "\n", "wa_result", "=", "[", "mAP", ",", "mAUC", ",", "average_precision", ",", "average_recall", ",", "d_prime", "(", "mAUC", ")", "]", "\n", "print", "(", "'---------------Training Finished---------------'", ")", "\n", "print", "(", "'weighted averaged model results'", ")", "\n", "print", "(", "\"mAP: {:.6f}\"", ".", "format", "(", "mAP", ")", ")", "\n", "print", "(", "\"AUC: {:.6f}\"", ".", "format", "(", "mAUC", ")", ")", "\n", "print", "(", "\"Avg Precision: {:.6f}\"", ".", "format", "(", "average_precision", ")", ")", "\n", "print", "(", "\"Avg Recall: {:.6f}\"", ".", "format", "(", "average_recall", ")", ")", "\n", "print", "(", "\"d_prime: {:.6f}\"", ".", "format", "(", "d_prime", "(", "mAUC", ")", ")", ")", "\n", "print", "(", "\"train_loss: {:.6f}\"", ".", "format", "(", "loss_meter", ".", "avg", ")", ")", "\n", "print", "(", "\"valid_loss: {:.6f}\"", ".", "format", "(", "valid_loss", ")", ")", "\n", "np", ".", "savetxt", "(", "exp_dir", "+", "'/wa_result.csv'", ",", "wa_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.src.traintest.validate": [[261, 310], ["torch.device", "AverageMeter", "nn.DataParallel.to", "nn.DataParallel.eval", "time.time", "isinstance", "torch.nn.DataParallel", "torch.no_grad", "enumerate", "torch.cat", "torch.cat", "numpy.mean", "calculate_stats", "numpy.savetxt", "torch.cuda.is_available", "audio_input.to.to", "nn.DataParallel.", "torch.sigmoid", "torch.sigmoid.to().detach", "A_predictions.append", "A_targets.append", "labels.to.to", "isinstance", "A_loss.append", "AverageMeter.update", "time.time", "os.path.exists", "os.mkdir", "numpy.savetxt", "args.loss_fn", "args.loss_fn", "args.loss_fn.to().detach", "torch.sigmoid.to", "torch.argmax", "time.time", "str", "labels.to.long", "args.loss_fn.to"], "function", ["home.repos.pwc.inspect_result.YuanGongND_ast.utilities.stats.calculate_stats", "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.AverageMeter.update"], ["", "", "def", "validate", "(", "audio_model", ",", "val_loader", ",", "args", ",", "epoch", ")", ":", "\n", "    ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "batch_time", "=", "AverageMeter", "(", ")", "\n", "if", "not", "isinstance", "(", "audio_model", ",", "nn", ".", "DataParallel", ")", ":", "\n", "        ", "audio_model", "=", "nn", ".", "DataParallel", "(", "audio_model", ")", "\n", "", "audio_model", "=", "audio_model", ".", "to", "(", "device", ")", "\n", "# switch to evaluate mode", "\n", "audio_model", ".", "eval", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "A_predictions", "=", "[", "]", "\n", "A_targets", "=", "[", "]", "\n", "A_loss", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "(", "audio_input", ",", "labels", ")", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "            ", "audio_input", "=", "audio_input", ".", "to", "(", "device", ")", "\n", "\n", "# compute output", "\n", "audio_output", "=", "audio_model", "(", "audio_input", ")", "\n", "audio_output", "=", "torch", ".", "sigmoid", "(", "audio_output", ")", "\n", "predictions", "=", "audio_output", ".", "to", "(", "'cpu'", ")", ".", "detach", "(", ")", "\n", "\n", "A_predictions", ".", "append", "(", "predictions", ")", "\n", "A_targets", ".", "append", "(", "labels", ")", "\n", "\n", "# compute the loss", "\n", "labels", "=", "labels", ".", "to", "(", "device", ")", "\n", "if", "isinstance", "(", "args", ".", "loss_fn", ",", "torch", ".", "nn", ".", "CrossEntropyLoss", ")", ":", "\n", "                ", "loss", "=", "args", ".", "loss_fn", "(", "audio_output", ",", "torch", ".", "argmax", "(", "labels", ".", "long", "(", ")", ",", "axis", "=", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "args", ".", "loss_fn", "(", "audio_output", ",", "labels", ")", "\n", "", "A_loss", ".", "append", "(", "loss", ".", "to", "(", "'cpu'", ")", ".", "detach", "(", ")", ")", "\n", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "audio_output", "=", "torch", ".", "cat", "(", "A_predictions", ")", "\n", "target", "=", "torch", ".", "cat", "(", "A_targets", ")", "\n", "loss", "=", "np", ".", "mean", "(", "A_loss", ")", "\n", "stats", "=", "calculate_stats", "(", "audio_output", ",", "target", ")", "\n", "\n", "# save the prediction here", "\n", "exp_dir", "=", "args", ".", "exp_dir", "\n", "if", "os", ".", "path", ".", "exists", "(", "exp_dir", "+", "'/predictions'", ")", "==", "False", ":", "\n", "            ", "os", ".", "mkdir", "(", "exp_dir", "+", "'/predictions'", ")", "\n", "np", ".", "savetxt", "(", "exp_dir", "+", "'/predictions/target.csv'", ",", "target", ",", "delimiter", "=", "','", ")", "\n", "", "np", ".", "savetxt", "(", "exp_dir", "+", "'/predictions/predictions_'", "+", "str", "(", "epoch", ")", "+", "'.csv'", ",", "audio_output", ",", "delimiter", "=", "','", ")", "\n", "\n", "", "return", "stats", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.src.traintest.validate_ensemble": [[311, 328], ["numpy.loadtxt", "numpy.savetxt", "calculate_stats", "numpy.loadtxt", "numpy.loadtxt", "os.remove", "numpy.loadtxt", "str", "str"], "function", ["home.repos.pwc.inspect_result.YuanGongND_ast.utilities.stats.calculate_stats"], ["", "def", "validate_ensemble", "(", "args", ",", "epoch", ")", ":", "\n", "    ", "exp_dir", "=", "args", ".", "exp_dir", "\n", "target", "=", "np", ".", "loadtxt", "(", "exp_dir", "+", "'/predictions/target.csv'", ",", "delimiter", "=", "','", ")", "\n", "if", "epoch", "==", "1", ":", "\n", "        ", "cum_predictions", "=", "np", ".", "loadtxt", "(", "exp_dir", "+", "'/predictions/predictions_1.csv'", ",", "delimiter", "=", "','", ")", "\n", "", "else", ":", "\n", "        ", "cum_predictions", "=", "np", ".", "loadtxt", "(", "exp_dir", "+", "'/predictions/cum_predictions.csv'", ",", "delimiter", "=", "','", ")", "*", "(", "epoch", "-", "1", ")", "\n", "predictions", "=", "np", ".", "loadtxt", "(", "exp_dir", "+", "'/predictions/predictions_'", "+", "str", "(", "epoch", ")", "+", "'.csv'", ",", "delimiter", "=", "','", ")", "\n", "cum_predictions", "=", "cum_predictions", "+", "predictions", "\n", "# remove the prediction file to save storage space", "\n", "os", ".", "remove", "(", "exp_dir", "+", "'/predictions/predictions_'", "+", "str", "(", "epoch", "-", "1", ")", "+", "'.csv'", ")", "\n", "\n", "", "cum_predictions", "=", "cum_predictions", "/", "epoch", "\n", "np", ".", "savetxt", "(", "exp_dir", "+", "'/predictions/cum_predictions.csv'", ",", "cum_predictions", ",", "delimiter", "=", "','", ")", "\n", "\n", "stats", "=", "calculate_stats", "(", "cum_predictions", ",", "target", ")", "\n", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.src.traintest.validate_wa": [[329, 356], ["torch.device", "torch.load", "range", "audio_model.load_state_dict", "torch.save", "traintest.validate", "torch.load", "audio_model.state_dict", "torch.cuda.is_available", "os.remove", "float", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.YuanGongND_ast.src.traintest.validate"], ["", "def", "validate_wa", "(", "audio_model", ",", "val_loader", ",", "args", ",", "start_epoch", ",", "end_epoch", ")", ":", "\n", "    ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "exp_dir", "=", "args", ".", "exp_dir", "\n", "\n", "sdA", "=", "torch", ".", "load", "(", "exp_dir", "+", "'/models/audio_model.'", "+", "str", "(", "start_epoch", ")", "+", "'.pth'", ",", "map_location", "=", "device", ")", "\n", "\n", "model_cnt", "=", "1", "\n", "for", "epoch", "in", "range", "(", "start_epoch", "+", "1", ",", "end_epoch", "+", "1", ")", ":", "\n", "        ", "sdB", "=", "torch", ".", "load", "(", "exp_dir", "+", "'/models/audio_model.'", "+", "str", "(", "epoch", ")", "+", "'.pth'", ",", "map_location", "=", "device", ")", "\n", "for", "key", "in", "sdA", ":", "\n", "            ", "sdA", "[", "key", "]", "=", "sdA", "[", "key", "]", "+", "sdB", "[", "key", "]", "\n", "", "model_cnt", "+=", "1", "\n", "\n", "# if choose not to save models of epoch, remove to save space", "\n", "if", "args", ".", "save_model", "==", "False", ":", "\n", "            ", "os", ".", "remove", "(", "exp_dir", "+", "'/models/audio_model.'", "+", "str", "(", "epoch", ")", "+", "'.pth'", ")", "\n", "\n", "# averaging", "\n", "", "", "for", "key", "in", "sdA", ":", "\n", "        ", "sdA", "[", "key", "]", "=", "sdA", "[", "key", "]", "/", "float", "(", "model_cnt", ")", "\n", "\n", "", "audio_model", ".", "load_state_dict", "(", "sdA", ")", "\n", "\n", "torch", ".", "save", "(", "audio_model", ".", "state_dict", "(", ")", ",", "exp_dir", "+", "'/models/audio_model_wa.pth'", ")", "\n", "\n", "stats", ",", "loss", "=", "validate", "(", "audio_model", ",", "val_loader", ",", "args", ",", "'wa'", ")", "\n", "return", "stats", "", "", ""]], "home.repos.pwc.inspect_result.YuanGongND_ast.src.dataloader.AudiosetDataset.__init__": [[58, 97], ["print", "dataloader.AudiosetDataset.audio_conf.get", "dataloader.AudiosetDataset.audio_conf.get", "dataloader.AudiosetDataset.audio_conf.get", "print", "dataloader.AudiosetDataset.audio_conf.get", "print", "dataloader.AudiosetDataset.audio_conf.get", "print", "dataloader.AudiosetDataset.audio_conf.get", "dataloader.AudiosetDataset.audio_conf.get", "dataloader.AudiosetDataset.audio_conf.get", "dataloader.make_index_dict", "len", "print", "open", "json.load", "dataloader.AudiosetDataset.audio_conf.get", "dataloader.AudiosetDataset.audio_conf.get", "print", "print", "print", "dataloader.AudiosetDataset.audio_conf.get", "dataloader.AudiosetDataset.audio_conf.get", "dataloader.AudiosetDataset.audio_conf.get"], "methods", ["home.repos.pwc.inspect_result.YuanGongND_ast.audioset.gen_weight_file.make_index_dict"], ["    ", "def", "__init__", "(", "self", ",", "dataset_json_file", ",", "audio_conf", ",", "label_csv", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Dataset that manages audio recordings\n        :param audio_conf: Dictionary containing the audio loading and preprocessing settings\n        :param dataset_json_file\n        \"\"\"", "\n", "self", ".", "datapath", "=", "dataset_json_file", "\n", "with", "open", "(", "dataset_json_file", ",", "'r'", ")", "as", "fp", ":", "\n", "            ", "data_json", "=", "json", ".", "load", "(", "fp", ")", "\n", "\n", "", "self", ".", "data", "=", "data_json", "[", "'data'", "]", "\n", "self", ".", "audio_conf", "=", "audio_conf", "\n", "print", "(", "'---------------the {:s} dataloader---------------'", ".", "format", "(", "self", ".", "audio_conf", ".", "get", "(", "'mode'", ")", ")", ")", "\n", "self", ".", "melbins", "=", "self", ".", "audio_conf", ".", "get", "(", "'num_mel_bins'", ")", "\n", "self", ".", "freqm", "=", "self", ".", "audio_conf", ".", "get", "(", "'freqm'", ")", "\n", "self", ".", "timem", "=", "self", ".", "audio_conf", ".", "get", "(", "'timem'", ")", "\n", "print", "(", "'now using following mask: {:d} freq, {:d} time'", ".", "format", "(", "self", ".", "audio_conf", ".", "get", "(", "'freqm'", ")", ",", "self", ".", "audio_conf", ".", "get", "(", "'timem'", ")", ")", ")", "\n", "self", ".", "mixup", "=", "self", ".", "audio_conf", ".", "get", "(", "'mixup'", ")", "\n", "print", "(", "'now using mix-up with rate {:f}'", ".", "format", "(", "self", ".", "mixup", ")", ")", "\n", "self", ".", "dataset", "=", "self", ".", "audio_conf", ".", "get", "(", "'dataset'", ")", "\n", "print", "(", "'now process '", "+", "self", ".", "dataset", ")", "\n", "# dataset spectrogram mean and std, used to normalize the input", "\n", "self", ".", "norm_mean", "=", "self", ".", "audio_conf", ".", "get", "(", "'mean'", ")", "\n", "self", ".", "norm_std", "=", "self", ".", "audio_conf", ".", "get", "(", "'std'", ")", "\n", "# skip_norm is a flag that if you want to skip normalization to compute the normalization stats using src/get_norm_stats.py, if Ture, input normalization will be skipped for correctly calculating the stats.", "\n", "# set it as True ONLY when you are getting the normalization stats.", "\n", "self", ".", "skip_norm", "=", "self", ".", "audio_conf", ".", "get", "(", "'skip_norm'", ")", "if", "self", ".", "audio_conf", ".", "get", "(", "'skip_norm'", ")", "else", "False", "\n", "if", "self", ".", "skip_norm", ":", "\n", "            ", "print", "(", "'now skip normalization (use it ONLY when you are computing the normalization stats).'", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'use dataset mean {:.3f} and std {:.3f} to normalize the input.'", ".", "format", "(", "self", ".", "norm_mean", ",", "self", ".", "norm_std", ")", ")", "\n", "# if add noise for data augmentation", "\n", "", "self", ".", "noise", "=", "self", ".", "audio_conf", ".", "get", "(", "'noise'", ")", "\n", "if", "self", ".", "noise", "==", "True", ":", "\n", "            ", "print", "(", "'now use noise augmentation'", ")", "\n", "\n", "", "self", ".", "index_dict", "=", "make_index_dict", "(", "label_csv", ")", "\n", "self", ".", "label_num", "=", "len", "(", "self", ".", "index_dict", ")", "\n", "print", "(", "'number of classes is {:d}'", ".", "format", "(", "self", ".", "label_num", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.src.dataloader.AudiosetDataset._wav2fbank": [[98, 148], ["torchaudio.compliance.kaldi.fbank", "dataloader.AudiosetDataset.audio_conf.get", "torchaudio.load", "torchaudio.load", "torchaudio.load", "numpy.random.beta", "torch.nn.ZeroPad2d", "torch.nn.ZeroPad2d", "torch.nn.ZeroPad2d", "torch.nn.ZeroPad2d", "torch.nn.ZeroPad2d.", "torch.nn.ZeroPad2d.", "waveform.mean", "waveform1.mean", "waveform2.mean", "mix_waveform.mean", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "_wav2fbank", "(", "self", ",", "filename", ",", "filename2", "=", "None", ")", ":", "\n", "# mixup", "\n", "        ", "if", "filename2", "==", "None", ":", "\n", "            ", "waveform", ",", "sr", "=", "torchaudio", ".", "load", "(", "filename", ")", "\n", "waveform", "=", "waveform", "-", "waveform", ".", "mean", "(", ")", "\n", "# mixup", "\n", "", "else", ":", "\n", "            ", "waveform1", ",", "sr", "=", "torchaudio", ".", "load", "(", "filename", ")", "\n", "waveform2", ",", "_", "=", "torchaudio", ".", "load", "(", "filename2", ")", "\n", "\n", "waveform1", "=", "waveform1", "-", "waveform1", ".", "mean", "(", ")", "\n", "waveform2", "=", "waveform2", "-", "waveform2", ".", "mean", "(", ")", "\n", "\n", "if", "waveform1", ".", "shape", "[", "1", "]", "!=", "waveform2", ".", "shape", "[", "1", "]", ":", "\n", "                ", "if", "waveform1", ".", "shape", "[", "1", "]", ">", "waveform2", ".", "shape", "[", "1", "]", ":", "\n", "# padding", "\n", "                    ", "temp_wav", "=", "torch", ".", "zeros", "(", "1", ",", "waveform1", ".", "shape", "[", "1", "]", ")", "\n", "temp_wav", "[", "0", ",", "0", ":", "waveform2", ".", "shape", "[", "1", "]", "]", "=", "waveform2", "\n", "waveform2", "=", "temp_wav", "\n", "", "else", ":", "\n", "# cutting", "\n", "                    ", "waveform2", "=", "waveform2", "[", "0", ",", "0", ":", "waveform1", ".", "shape", "[", "1", "]", "]", "\n", "\n", "# sample lambda from uniform distribution", "\n", "#mix_lambda = random.random()", "\n", "# sample lambda from beta distribtion", "\n", "", "", "mix_lambda", "=", "np", ".", "random", ".", "beta", "(", "10", ",", "10", ")", "\n", "\n", "mix_waveform", "=", "mix_lambda", "*", "waveform1", "+", "(", "1", "-", "mix_lambda", ")", "*", "waveform2", "\n", "waveform", "=", "mix_waveform", "-", "mix_waveform", ".", "mean", "(", ")", "\n", "\n", "", "fbank", "=", "torchaudio", ".", "compliance", ".", "kaldi", ".", "fbank", "(", "waveform", ",", "htk_compat", "=", "True", ",", "sample_frequency", "=", "sr", ",", "use_energy", "=", "False", ",", "\n", "window_type", "=", "'hanning'", ",", "num_mel_bins", "=", "self", ".", "melbins", ",", "dither", "=", "0.0", ",", "frame_shift", "=", "10", ")", "\n", "\n", "target_length", "=", "self", ".", "audio_conf", ".", "get", "(", "'target_length'", ")", "\n", "n_frames", "=", "fbank", ".", "shape", "[", "0", "]", "\n", "\n", "p", "=", "target_length", "-", "n_frames", "\n", "\n", "# cut and pad", "\n", "if", "p", ">", "0", ":", "\n", "            ", "m", "=", "torch", ".", "nn", ".", "ZeroPad2d", "(", "(", "0", ",", "0", ",", "0", ",", "p", ")", ")", "\n", "fbank", "=", "m", "(", "fbank", ")", "\n", "", "elif", "p", "<", "0", ":", "\n", "            ", "fbank", "=", "fbank", "[", "0", ":", "target_length", ",", ":", "]", "\n", "\n", "", "if", "filename2", "==", "None", ":", "\n", "            ", "return", "fbank", ",", "0", "\n", "", "else", ":", "\n", "            ", "return", "fbank", ",", "mix_lambda", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.src.dataloader.AudiosetDataset.__getitem__": [[149, 215], ["torchaudio.transforms.FrequencyMasking", "torchaudio.transforms.TimeMasking", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.roll.unsqueeze", "torch.roll.unsqueeze", "torch.roll.squeeze", "torch.roll.squeeze", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "random.random", "random.randint", "dataloader.AudiosetDataset._wav2fbank", "numpy.zeros", "datum[].split", "mix_datum[].split", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "numpy.zeros", "dataloader.AudiosetDataset._wav2fbank", "datum[].split", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torchaudio.transforms.FrequencyMasking.", "torchaudio.transforms.TimeMasking.", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "min", "max", "numpy.random.randint", "len", "int", "int", "int", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "numpy.random.rand"], "methods", ["home.repos.pwc.inspect_result.YuanGongND_ast.src.dataloader.AudiosetDataset._wav2fbank", "home.repos.pwc.inspect_result.YuanGongND_ast.src.dataloader.AudiosetDataset._wav2fbank"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        returns: image, audio, nframes\n        where image is a FloatTensor of size (3, H, W)\n        audio is a FloatTensor of size (N_freq, N_frames) for spectrogram, or (N_frames) for waveform\n        nframes is an integer\n        \"\"\"", "\n", "# do mix-up for this sample (controlled by the given mixup rate)", "\n", "if", "random", ".", "random", "(", ")", "<", "self", ".", "mixup", ":", "\n", "            ", "datum", "=", "self", ".", "data", "[", "index", "]", "\n", "# find another sample to mix, also do balance sampling", "\n", "# sample the other sample from the multinomial distribution, will make the performance worse", "\n", "# mix_sample_idx = np.random.choice(len(self.data), p=self.sample_weight_file)", "\n", "# sample the other sample from the uniform distribution", "\n", "mix_sample_idx", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "data", ")", "-", "1", ")", "\n", "mix_datum", "=", "self", ".", "data", "[", "mix_sample_idx", "]", "\n", "# get the mixed fbank", "\n", "fbank", ",", "mix_lambda", "=", "self", ".", "_wav2fbank", "(", "datum", "[", "'wav'", "]", ",", "mix_datum", "[", "'wav'", "]", ")", "\n", "# initialize the label", "\n", "label_indices", "=", "np", ".", "zeros", "(", "self", ".", "label_num", ")", "\n", "# add sample 1 labels", "\n", "for", "label_str", "in", "datum", "[", "'labels'", "]", ".", "split", "(", "','", ")", ":", "\n", "                ", "label_indices", "[", "int", "(", "self", ".", "index_dict", "[", "label_str", "]", ")", "]", "+=", "mix_lambda", "\n", "# add sample 2 labels", "\n", "", "for", "label_str", "in", "mix_datum", "[", "'labels'", "]", ".", "split", "(", "','", ")", ":", "\n", "                ", "label_indices", "[", "int", "(", "self", ".", "index_dict", "[", "label_str", "]", ")", "]", "+=", "1.0", "-", "mix_lambda", "\n", "", "label_indices", "=", "torch", ".", "FloatTensor", "(", "label_indices", ")", "\n", "# if not do mixup", "\n", "", "else", ":", "\n", "            ", "datum", "=", "self", ".", "data", "[", "index", "]", "\n", "label_indices", "=", "np", ".", "zeros", "(", "self", ".", "label_num", ")", "\n", "fbank", ",", "mix_lambda", "=", "self", ".", "_wav2fbank", "(", "datum", "[", "'wav'", "]", ")", "\n", "for", "label_str", "in", "datum", "[", "'labels'", "]", ".", "split", "(", "','", ")", ":", "\n", "                ", "label_indices", "[", "int", "(", "self", ".", "index_dict", "[", "label_str", "]", ")", "]", "=", "1.0", "\n", "\n", "", "label_indices", "=", "torch", ".", "FloatTensor", "(", "label_indices", ")", "\n", "\n", "# SpecAug, not do for eval set", "\n", "", "freqm", "=", "torchaudio", ".", "transforms", ".", "FrequencyMasking", "(", "self", ".", "freqm", ")", "\n", "timem", "=", "torchaudio", ".", "transforms", ".", "TimeMasking", "(", "self", ".", "timem", ")", "\n", "fbank", "=", "torch", ".", "transpose", "(", "fbank", ",", "0", ",", "1", ")", "\n", "# this is just to satisfy new torchaudio version, which only accept [1, freq, time]", "\n", "fbank", "=", "fbank", ".", "unsqueeze", "(", "0", ")", "\n", "if", "self", ".", "freqm", "!=", "0", ":", "\n", "            ", "fbank", "=", "freqm", "(", "fbank", ")", "\n", "", "if", "self", ".", "timem", "!=", "0", ":", "\n", "            ", "fbank", "=", "timem", "(", "fbank", ")", "\n", "# squeeze it back, it is just a trick to satisfy new torchaudio version", "\n", "", "fbank", "=", "fbank", ".", "squeeze", "(", "0", ")", "\n", "fbank", "=", "torch", ".", "transpose", "(", "fbank", ",", "0", ",", "1", ")", "\n", "\n", "# normalize the input for both training and test", "\n", "if", "not", "self", ".", "skip_norm", ":", "\n", "            ", "fbank", "=", "(", "fbank", "-", "self", ".", "norm_mean", ")", "/", "(", "self", ".", "norm_std", "*", "2", ")", "\n", "# skip normalization the input if you are trying to get the normalization stats.", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "\n", "", "if", "self", ".", "noise", "==", "True", ":", "\n", "            ", "fbank", "=", "fbank", "+", "torch", ".", "rand", "(", "fbank", ".", "shape", "[", "0", "]", ",", "fbank", ".", "shape", "[", "1", "]", ")", "*", "np", ".", "random", ".", "rand", "(", ")", "/", "10", "\n", "fbank", "=", "torch", ".", "roll", "(", "fbank", ",", "np", ".", "random", ".", "randint", "(", "-", "10", ",", "10", ")", ",", "0", ")", "\n", "\n", "", "mix_ratio", "=", "min", "(", "mix_lambda", ",", "1", "-", "mix_lambda", ")", "/", "max", "(", "mix_lambda", ",", "1", "-", "mix_lambda", ")", "\n", "\n", "# the output fbank shape is [time_frame_num, frequency_bins], e.g., [1024, 128]", "\n", "return", "fbank", ",", "label_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.src.dataloader.AudiosetDataset.__len__": [[216, 218], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.YuanGongND_ast.src.dataloader.make_index_dict": [[21, 30], ["open", "csv.DictReader"], "function", ["None"], ["def", "make_index_dict", "(", "label_csv", ")", ":", "\n", "    ", "index_lookup", "=", "{", "}", "\n", "with", "open", "(", "label_csv", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "csv_reader", "=", "csv", ".", "DictReader", "(", "f", ")", "\n", "line_count", "=", "0", "\n", "for", "row", "in", "csv_reader", ":", "\n", "            ", "index_lookup", "[", "row", "[", "'mid'", "]", "]", "=", "row", "[", "'index'", "]", "\n", "line_count", "+=", "1", "\n", "", "", "return", "index_lookup", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.src.dataloader.make_name_dict": [[31, 40], ["open", "csv.DictReader"], "function", ["None"], ["", "def", "make_name_dict", "(", "label_csv", ")", ":", "\n", "    ", "name_lookup", "=", "{", "}", "\n", "with", "open", "(", "label_csv", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "csv_reader", "=", "csv", ".", "DictReader", "(", "f", ")", "\n", "line_count", "=", "0", "\n", "for", "row", "in", "csv_reader", ":", "\n", "            ", "name_lookup", "[", "row", "[", "'index'", "]", "]", "=", "row", "[", "'display_name'", "]", "\n", "line_count", "+=", "1", "\n", "", "", "return", "name_lookup", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.src.dataloader.lookup_list": [[41, 47], ["dataloader.make_name_dict", "label_list.append"], "function", ["home.repos.pwc.inspect_result.YuanGongND_ast.src.dataloader.make_name_dict"], ["", "def", "lookup_list", "(", "index_list", ",", "label_csv", ")", ":", "\n", "    ", "label_list", "=", "[", "]", "\n", "table", "=", "make_name_dict", "(", "label_csv", ")", "\n", "for", "item", "in", "index_list", ":", "\n", "        ", "label_list", ".", "append", "(", "table", "[", "item", "]", ")", "\n", "", "return", "label_list", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.src.dataloader.preemphasis": [[48, 56], ["numpy.append"], "function", ["None"], ["", "def", "preemphasis", "(", "signal", ",", "coeff", "=", "0.97", ")", ":", "\n", "    ", "\"\"\"perform preemphasis on the input signal.\n\n    :param signal: The signal to filter.\n    :param coeff: The preemphasis coefficient. 0 is none, default 0.97.\n    :returns: the filtered signal.\n    \"\"\"", "\n", "return", "np", ".", "append", "(", "signal", "[", "0", "]", ",", "signal", "[", "1", ":", "]", "-", "coeff", "*", "signal", "[", ":", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.models.ast_models.PatchEmbed.__init__": [[19, 30], ["torch.Module.__init__", "timm.models.layers.to_2tuple", "timm.models.layers.to_2tuple", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "embed_dim", "=", "768", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "img_size", "=", "to_2tuple", "(", "img_size", ")", "\n", "patch_size", "=", "to_2tuple", "(", "patch_size", ")", "\n", "num_patches", "=", "(", "img_size", "[", "1", "]", "//", "patch_size", "[", "1", "]", ")", "*", "(", "img_size", "[", "0", "]", "//", "patch_size", "[", "0", "]", ")", "\n", "self", ".", "img_size", "=", "img_size", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "self", ".", "num_patches", "=", "num_patches", "\n", "\n", "self", ".", "proj", "=", "nn", ".", "Conv2d", "(", "in_chans", ",", "embed_dim", ",", "kernel_size", "=", "patch_size", ",", "stride", "=", "patch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.models.ast_models.PatchEmbed.forward": [[31, 34], ["ast_models.PatchEmbed.proj().flatten().transpose", "ast_models.PatchEmbed.proj().flatten", "ast_models.PatchEmbed.proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "proj", "(", "x", ")", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.models.ast_models.ASTModel.__init__": [[47, 150], ["torch.Module.__init__", "print", "print", "int", "torch.Sequential", "torch.Sequential", "ast_models.ASTModel.get_shape", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "timm.create_model", "torch.LayerNorm", "torch.LayerNorm", "torch.Linear", "torch.Linear", "print", "print", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "ast_models.ASTModel.v.pos_embed[].detach().reshape().transpose().reshape", "torch.nn.functional.interpolate.reshape().transpose", "torch.nn.functional.interpolate.reshape().transpose", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "timm.models.layers.trunc_normal_", "torch.device", "torch.device", "torch.device", "torch.device", "torch.load", "torch.load", "torch.load", "torch.load", "ast_models.ASTModel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel.load_state_dict", "torch.nn.DataParallel.load_state_dict", "torch.Sequential", "torch.Sequential", "ast_models.ASTModel.get_shape", "ast_models.ASTModel.v.pos_embed[].detach().reshape().transpose().reshape", "torch.nn.functional.interpolate.reshape().transpose", "torch.nn.functional.interpolate.reshape().transpose", "torch.Parameter", "torch.Parameter", "str", "str", "timm.create_model", "torch.sum().unsqueeze", "torch.sum().unsqueeze", "torch.sum().unsqueeze", "torch.sum().unsqueeze", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "ValueError", "ValueError", "os.path.exists", "wget.download", "torch.LayerNorm", "torch.LayerNorm", "torch.Linear", "torch.Linear", "print", "print", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "timm.create_model", "ast_models.ASTModel.v.pos_embed[].detach().reshape().transpose", "torch.nn.functional.interpolate.reshape", "torch.nn.functional.interpolate.reshape", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "ast_models.ASTModel.v.pos_embed[].detach().reshape().transpose", "torch.nn.functional.interpolate.reshape", "torch.nn.functional.interpolate.reshape", "timm.create_model", "Exception", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "ast_models.ASTModel.v.pos_embed[].detach", "ast_models.ASTModel.v.pos_embed[].detach", "ast_models.ASTModel.v.pos_embed[].detach().reshape", "ast_models.ASTModel.v.pos_embed[].detach().reshape", "int", "int", "int", "int", "int", "ast_models.ASTModel.v.pos_embed[].detach", "int", "int", "int", "int", "ast_models.ASTModel.v.pos_embed[].detach", "int"], "methods", ["home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.AverageMeter.__init__", "home.repos.pwc.inspect_result.YuanGongND_ast.models.ast_models.ASTModel.get_shape", "home.repos.pwc.inspect_result.YuanGongND_ast.models.ast_models.ASTModel.get_shape"], ["def", "__init__", "(", "self", ",", "label_dim", "=", "527", ",", "fstride", "=", "10", ",", "tstride", "=", "10", ",", "input_fdim", "=", "128", ",", "input_tdim", "=", "1024", ",", "imagenet_pretrain", "=", "True", ",", "audioset_pretrain", "=", "False", ",", "model_size", "=", "'base384'", ",", "verbose", "=", "True", ")", ":", "\n", "\n", "        ", "super", "(", "ASTModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "timm", ".", "__version__", "==", "'0.4.5'", ",", "'Please use timm == 0.4.5, the code might not be compatible with newer versions.'", "\n", "\n", "if", "verbose", "==", "True", ":", "\n", "            ", "print", "(", "'---------------AST Model Summary---------------'", ")", "\n", "print", "(", "'ImageNet pretraining: {:s}, AudioSet pretraining: {:s}'", ".", "format", "(", "str", "(", "imagenet_pretrain", ")", ",", "str", "(", "audioset_pretrain", ")", ")", ")", "\n", "# override timm input shape restriction", "\n", "", "timm", ".", "models", ".", "vision_transformer", ".", "PatchEmbed", "=", "PatchEmbed", "\n", "\n", "# if AudioSet pretraining is not used (but ImageNet pretraining may still apply)", "\n", "if", "audioset_pretrain", "==", "False", ":", "\n", "            ", "if", "model_size", "==", "'tiny224'", ":", "\n", "                ", "self", ".", "v", "=", "timm", ".", "create_model", "(", "'vit_deit_tiny_distilled_patch16_224'", ",", "pretrained", "=", "imagenet_pretrain", ")", "\n", "", "elif", "model_size", "==", "'small224'", ":", "\n", "                ", "self", ".", "v", "=", "timm", ".", "create_model", "(", "'vit_deit_small_distilled_patch16_224'", ",", "pretrained", "=", "imagenet_pretrain", ")", "\n", "", "elif", "model_size", "==", "'base224'", ":", "\n", "                ", "self", ".", "v", "=", "timm", ".", "create_model", "(", "'vit_deit_base_distilled_patch16_224'", ",", "pretrained", "=", "imagenet_pretrain", ")", "\n", "", "elif", "model_size", "==", "'base384'", ":", "\n", "                ", "self", ".", "v", "=", "timm", ".", "create_model", "(", "'vit_deit_base_distilled_patch16_384'", ",", "pretrained", "=", "imagenet_pretrain", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "'Model size must be one of tiny224, small224, base224, base384.'", ")", "\n", "", "self", ".", "original_num_patches", "=", "self", ".", "v", ".", "patch_embed", ".", "num_patches", "\n", "self", ".", "oringal_hw", "=", "int", "(", "self", ".", "original_num_patches", "**", "0.5", ")", "\n", "self", ".", "original_embedding_dim", "=", "self", ".", "v", ".", "pos_embed", ".", "shape", "[", "2", "]", "\n", "self", ".", "mlp_head", "=", "nn", ".", "Sequential", "(", "nn", ".", "LayerNorm", "(", "self", ".", "original_embedding_dim", ")", ",", "nn", ".", "Linear", "(", "self", ".", "original_embedding_dim", ",", "label_dim", ")", ")", "\n", "\n", "# automatcially get the intermediate shape", "\n", "f_dim", ",", "t_dim", "=", "self", ".", "get_shape", "(", "fstride", ",", "tstride", ",", "input_fdim", ",", "input_tdim", ")", "\n", "num_patches", "=", "f_dim", "*", "t_dim", "\n", "self", ".", "v", ".", "patch_embed", ".", "num_patches", "=", "num_patches", "\n", "if", "verbose", "==", "True", ":", "\n", "                ", "print", "(", "'frequncey stride={:d}, time stride={:d}'", ".", "format", "(", "fstride", ",", "tstride", ")", ")", "\n", "print", "(", "'number of patches={:d}'", ".", "format", "(", "num_patches", ")", ")", "\n", "\n", "# the linear projection layer", "\n", "", "new_proj", "=", "torch", ".", "nn", ".", "Conv2d", "(", "1", ",", "self", ".", "original_embedding_dim", ",", "kernel_size", "=", "(", "16", ",", "16", ")", ",", "stride", "=", "(", "fstride", ",", "tstride", ")", ")", "\n", "if", "imagenet_pretrain", "==", "True", ":", "\n", "                ", "new_proj", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "sum", "(", "self", ".", "v", ".", "patch_embed", ".", "proj", ".", "weight", ",", "dim", "=", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "new_proj", ".", "bias", "=", "self", ".", "v", ".", "patch_embed", ".", "proj", ".", "bias", "\n", "", "self", ".", "v", ".", "patch_embed", ".", "proj", "=", "new_proj", "\n", "\n", "# the positional embedding", "\n", "if", "imagenet_pretrain", "==", "True", ":", "\n", "# get the positional embedding from deit model, skip the first two tokens (cls token and distillation token), reshape it to original 2D shape (24*24).", "\n", "                ", "new_pos_embed", "=", "self", ".", "v", ".", "pos_embed", "[", ":", ",", "2", ":", ",", ":", "]", ".", "detach", "(", ")", ".", "reshape", "(", "1", ",", "self", ".", "original_num_patches", ",", "self", ".", "original_embedding_dim", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "1", ",", "self", ".", "original_embedding_dim", ",", "self", ".", "oringal_hw", ",", "self", ".", "oringal_hw", ")", "\n", "# cut (from middle) or interpolate the second dimension of the positional embedding", "\n", "if", "t_dim", "<=", "self", ".", "oringal_hw", ":", "\n", "                    ", "new_pos_embed", "=", "new_pos_embed", "[", ":", ",", ":", ",", ":", ",", "int", "(", "self", ".", "oringal_hw", "/", "2", ")", "-", "int", "(", "t_dim", "/", "2", ")", ":", "int", "(", "self", ".", "oringal_hw", "/", "2", ")", "-", "int", "(", "t_dim", "/", "2", ")", "+", "t_dim", "]", "\n", "", "else", ":", "\n", "                    ", "new_pos_embed", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "new_pos_embed", ",", "size", "=", "(", "self", ".", "oringal_hw", ",", "t_dim", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "# cut (from middle) or interpolate the first dimension of the positional embedding", "\n", "", "if", "f_dim", "<=", "self", ".", "oringal_hw", ":", "\n", "                    ", "new_pos_embed", "=", "new_pos_embed", "[", ":", ",", ":", ",", "int", "(", "self", ".", "oringal_hw", "/", "2", ")", "-", "int", "(", "f_dim", "/", "2", ")", ":", "int", "(", "self", ".", "oringal_hw", "/", "2", ")", "-", "int", "(", "f_dim", "/", "2", ")", "+", "f_dim", ",", ":", "]", "\n", "", "else", ":", "\n", "                    ", "new_pos_embed", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "new_pos_embed", ",", "size", "=", "(", "f_dim", ",", "t_dim", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "# flatten the positional embedding", "\n", "", "new_pos_embed", "=", "new_pos_embed", ".", "reshape", "(", "1", ",", "self", ".", "original_embedding_dim", ",", "num_patches", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# concatenate the above positional embedding with the cls token and distillation token of the deit model.", "\n", "self", ".", "v", ".", "pos_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "cat", "(", "[", "self", ".", "v", ".", "pos_embed", "[", ":", ",", ":", "2", ",", ":", "]", ".", "detach", "(", ")", ",", "new_pos_embed", "]", ",", "dim", "=", "1", ")", ")", "\n", "", "else", ":", "\n", "# if not use imagenet pretrained model, just randomly initialize a learnable positional embedding", "\n", "# TODO can use sinusoidal positional embedding instead", "\n", "                ", "new_pos_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "self", ".", "v", ".", "patch_embed", ".", "num_patches", "+", "2", ",", "self", ".", "original_embedding_dim", ")", ")", "\n", "self", ".", "v", ".", "pos_embed", "=", "new_pos_embed", "\n", "trunc_normal_", "(", "self", ".", "v", ".", "pos_embed", ",", "std", "=", ".02", ")", "\n", "\n", "# now load a model that is pretrained on both ImageNet and AudioSet", "\n", "", "", "elif", "audioset_pretrain", "==", "True", ":", "\n", "            ", "if", "audioset_pretrain", "==", "True", "and", "imagenet_pretrain", "==", "False", ":", "\n", "                ", "raise", "ValueError", "(", "'currently model pretrained on only audioset is not supported, please set imagenet_pretrain = True to use audioset pretrained model.'", ")", "\n", "", "if", "model_size", "!=", "'base384'", ":", "\n", "                ", "raise", "ValueError", "(", "'currently only has base384 AudioSet pretrained model.'", ")", "\n", "", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "'../../pretrained_models/audioset_10_10_0.4593.pth'", ")", "==", "False", ":", "\n", "# this model performs 0.4593 mAP on the audioset eval set", "\n", "                ", "audioset_mdl_url", "=", "'https://www.dropbox.com/s/cv4knew8mvbrnvq/audioset_0.4593.pth?dl=1'", "\n", "wget", ".", "download", "(", "audioset_mdl_url", ",", "out", "=", "'../../pretrained_models/audioset_10_10_0.4593.pth'", ")", "\n", "", "sd", "=", "torch", ".", "load", "(", "'../../pretrained_models/audioset_10_10_0.4593.pth'", ",", "map_location", "=", "device", ")", "\n", "audio_model", "=", "ASTModel", "(", "label_dim", "=", "527", ",", "fstride", "=", "10", ",", "tstride", "=", "10", ",", "input_fdim", "=", "128", ",", "input_tdim", "=", "1024", ",", "imagenet_pretrain", "=", "False", ",", "audioset_pretrain", "=", "False", ",", "model_size", "=", "'base384'", ",", "verbose", "=", "False", ")", "\n", "audio_model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "audio_model", ")", "\n", "audio_model", ".", "load_state_dict", "(", "sd", ",", "strict", "=", "False", ")", "\n", "self", ".", "v", "=", "audio_model", ".", "module", ".", "v", "\n", "self", ".", "original_embedding_dim", "=", "self", ".", "v", ".", "pos_embed", ".", "shape", "[", "2", "]", "\n", "self", ".", "mlp_head", "=", "nn", ".", "Sequential", "(", "nn", ".", "LayerNorm", "(", "self", ".", "original_embedding_dim", ")", ",", "nn", ".", "Linear", "(", "self", ".", "original_embedding_dim", ",", "label_dim", ")", ")", "\n", "\n", "f_dim", ",", "t_dim", "=", "self", ".", "get_shape", "(", "fstride", ",", "tstride", ",", "input_fdim", ",", "input_tdim", ")", "\n", "num_patches", "=", "f_dim", "*", "t_dim", "\n", "self", ".", "v", ".", "patch_embed", ".", "num_patches", "=", "num_patches", "\n", "if", "verbose", "==", "True", ":", "\n", "                ", "print", "(", "'frequncey stride={:d}, time stride={:d}'", ".", "format", "(", "fstride", ",", "tstride", ")", ")", "\n", "print", "(", "'number of patches={:d}'", ".", "format", "(", "num_patches", ")", ")", "\n", "\n", "", "new_pos_embed", "=", "self", ".", "v", ".", "pos_embed", "[", ":", ",", "2", ":", ",", ":", "]", ".", "detach", "(", ")", ".", "reshape", "(", "1", ",", "1212", ",", "768", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "1", ",", "768", ",", "12", ",", "101", ")", "\n", "# if the input sequence length is larger than the original audioset (10s), then cut the positional embedding", "\n", "if", "t_dim", "<", "101", ":", "\n", "                ", "new_pos_embed", "=", "new_pos_embed", "[", ":", ",", ":", ",", ":", ",", "50", "-", "int", "(", "t_dim", "/", "2", ")", ":", "50", "-", "int", "(", "t_dim", "/", "2", ")", "+", "t_dim", "]", "\n", "# otherwise interpolate", "\n", "", "else", ":", "\n", "                ", "new_pos_embed", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "new_pos_embed", ",", "size", "=", "(", "12", ",", "t_dim", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "", "new_pos_embed", "=", "new_pos_embed", ".", "reshape", "(", "1", ",", "768", ",", "num_patches", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "self", ".", "v", ".", "pos_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "cat", "(", "[", "self", ".", "v", ".", "pos_embed", "[", ":", ",", ":", "2", ",", ":", "]", ".", "detach", "(", ")", ",", "new_pos_embed", "]", ",", "dim", "=", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.models.ast_models.ASTModel.get_shape": [[151, 158], ["torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d."], "methods", ["None"], ["", "", "def", "get_shape", "(", "self", ",", "fstride", ",", "tstride", ",", "input_fdim", "=", "128", ",", "input_tdim", "=", "1024", ")", ":", "\n", "        ", "test_input", "=", "torch", ".", "randn", "(", "1", ",", "1", ",", "input_fdim", ",", "input_tdim", ")", "\n", "test_proj", "=", "nn", ".", "Conv2d", "(", "1", ",", "self", ".", "original_embedding_dim", ",", "kernel_size", "=", "(", "16", ",", "16", ")", ",", "stride", "=", "(", "fstride", ",", "tstride", ")", ")", "\n", "test_out", "=", "test_proj", "(", "test_input", ")", "\n", "f_dim", "=", "test_out", ".", "shape", "[", "2", "]", "\n", "t_dim", "=", "test_out", ".", "shape", "[", "3", "]", "\n", "return", "f_dim", ",", "t_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.models.ast_models.ASTModel.forward": [[159, 183], ["torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "blk.unsqueeze", "blk.transpose", "ast_models.ASTModel.v.patch_embed", "ast_models.ASTModel.v.cls_token.expand", "ast_models.ASTModel.v.dist_token.expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ast_models.ASTModel.v.pos_drop", "ast_models.ASTModel.v.norm", "ast_models.ASTModel.mlp_head", "blk"], "methods", ["None"], ["", "@", "autocast", "(", ")", "\n", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        :param x: the input spectrogram, expected shape: (batch_size, time_frame_num, frequency_bins), e.g., (12, 1024, 128)\n        :return: prediction\n        \"\"\"", "\n", "# expect input x = (batch_size, time_frame_num, frequency_bins), e.g., (12, 1024, 128)", "\n", "x", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "x", "=", "x", ".", "transpose", "(", "2", ",", "3", ")", "\n", "\n", "B", "=", "x", ".", "shape", "[", "0", "]", "\n", "x", "=", "self", ".", "v", ".", "patch_embed", "(", "x", ")", "\n", "cls_tokens", "=", "self", ".", "v", ".", "cls_token", ".", "expand", "(", "B", ",", "-", "1", ",", "-", "1", ")", "\n", "dist_token", "=", "self", ".", "v", ".", "dist_token", ".", "expand", "(", "B", ",", "-", "1", ",", "-", "1", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "cls_tokens", ",", "dist_token", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "x", "=", "x", "+", "self", ".", "v", ".", "pos_embed", "\n", "x", "=", "self", ".", "v", ".", "pos_drop", "(", "x", ")", "\n", "for", "blk", "in", "self", ".", "v", ".", "blocks", ":", "\n", "            ", "x", "=", "blk", "(", "x", ")", "\n", "", "x", "=", "self", ".", "v", ".", "norm", "(", "x", ")", "\n", "x", "=", "(", "x", "[", ":", ",", "0", "]", "+", "x", "[", ":", ",", "1", "]", ")", "/", "2", "\n", "\n", "x", "=", "self", ".", "mlp_head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.stats.d_prime": [[6, 10], ["scipy.stats.norm", "stats.norm.ppf", "numpy.sqrt"], "function", ["None"], ["def", "d_prime", "(", "auc", ")", ":", "\n", "    ", "standard_normal", "=", "stats", ".", "norm", "(", ")", "\n", "d_prime", "=", "standard_normal", ".", "ppf", "(", "auc", ")", "*", "np", ".", "sqrt", "(", "2.0", ")", "\n", "return", "d_prime", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.stats.calculate_stats": [[11, 58], ["sklearn.metrics.accuracy_score", "range", "numpy.argmax", "numpy.argmax", "sklearn.metrics.average_precision_score", "sklearn.metrics.roc_auc_score", "sklearn.metrics.precision_recall_curve", "sklearn.metrics.roc_curve", "scipy.stats.append"], "function", ["None"], ["", "def", "calculate_stats", "(", "output", ",", "target", ")", ":", "\n", "    ", "\"\"\"Calculate statistics including mAP, AUC, etc.\n\n    Args:\n      output: 2d array, (samples_num, classes_num)\n      target: 2d array, (samples_num, classes_num)\n\n    Returns:\n      stats: list of statistic of each class.\n    \"\"\"", "\n", "\n", "classes_num", "=", "target", ".", "shape", "[", "-", "1", "]", "\n", "stats", "=", "[", "]", "\n", "\n", "# Accuracy, only used for single-label classification such as esc-50, not for multiple label one such as AudioSet", "\n", "acc", "=", "metrics", ".", "accuracy_score", "(", "np", ".", "argmax", "(", "target", ",", "1", ")", ",", "np", ".", "argmax", "(", "output", ",", "1", ")", ")", "\n", "\n", "# Class-wise statistics", "\n", "for", "k", "in", "range", "(", "classes_num", ")", ":", "\n", "\n", "# Average precision", "\n", "        ", "avg_precision", "=", "metrics", ".", "average_precision_score", "(", "\n", "target", "[", ":", ",", "k", "]", ",", "output", "[", ":", ",", "k", "]", ",", "average", "=", "None", ")", "\n", "\n", "# AUC", "\n", "auc", "=", "metrics", ".", "roc_auc_score", "(", "target", "[", ":", ",", "k", "]", ",", "output", "[", ":", ",", "k", "]", ",", "average", "=", "None", ")", "\n", "\n", "# Precisions, recalls", "\n", "(", "precisions", ",", "recalls", ",", "thresholds", ")", "=", "metrics", ".", "precision_recall_curve", "(", "\n", "target", "[", ":", ",", "k", "]", ",", "output", "[", ":", ",", "k", "]", ")", "\n", "\n", "# FPR, TPR", "\n", "(", "fpr", ",", "tpr", ",", "thresholds", ")", "=", "metrics", ".", "roc_curve", "(", "target", "[", ":", ",", "k", "]", ",", "output", "[", ":", ",", "k", "]", ")", "\n", "\n", "save_every_steps", "=", "1000", "# Sample statistics to reduce size", "\n", "dict", "=", "{", "'precisions'", ":", "precisions", "[", "0", ":", ":", "save_every_steps", "]", ",", "\n", "'recalls'", ":", "recalls", "[", "0", ":", ":", "save_every_steps", "]", ",", "\n", "'AP'", ":", "avg_precision", ",", "\n", "'fpr'", ":", "fpr", "[", "0", ":", ":", "save_every_steps", "]", ",", "\n", "'fnr'", ":", "1.", "-", "tpr", "[", "0", ":", ":", "save_every_steps", "]", ",", "\n", "'auc'", ":", "auc", ",", "\n", "# note acc is not class-wise, this is just to keep consistent with other metrics", "\n", "'acc'", ":", "acc", "\n", "}", "\n", "stats", ".", "append", "(", "dict", ")", "\n", "\n", "", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.AverageMeter.__init__": [[240, 242], ["util.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.AverageMeter.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.AverageMeter.reset": [[243, 248], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.AverageMeter.update": [[249, 254], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.calc_recalls": [[9, 68], ["isinstance", "S.size", "S.topk", "S.topk", "util.AverageMeter", "util.AverageMeter", "util.AverageMeter", "util.AverageMeter", "util.AverageMeter", "util.AverageMeter", "range", "S.dim", "S.size", "S.size", "range", "util.AverageMeter.update", "util.AverageMeter.update", "util.AverageMeter.update", "util.AverageMeter.update", "util.AverageMeter.update", "util.AverageMeter.update", "util.AverageMeter.update", "util.AverageMeter.update", "util.AverageMeter.update", "util.AverageMeter.update", "util.AverageMeter.update", "util.AverageMeter.update"], "function", ["home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.AverageMeter.update"], ["def", "calc_recalls", "(", "S", ")", ":", "\n", "    ", "\"\"\"\n    Computes recall at 1, 5, and 10 given a similarity matrix S.\n    By convention, rows of S are assumed to correspond to images and columns are captions.\n    \"\"\"", "\n", "assert", "(", "S", ".", "dim", "(", ")", "==", "2", ")", "\n", "assert", "(", "S", ".", "size", "(", "0", ")", "==", "S", ".", "size", "(", "1", ")", ")", "\n", "if", "isinstance", "(", "S", ",", "torch", ".", "autograd", ".", "Variable", ")", ":", "\n", "        ", "S", "=", "S", ".", "data", "\n", "", "n", "=", "S", ".", "size", "(", "0", ")", "\n", "A2I_scores", ",", "A2I_ind", "=", "S", ".", "topk", "(", "10", ",", "0", ")", "\n", "I2A_scores", ",", "I2A_ind", "=", "S", ".", "topk", "(", "10", ",", "1", ")", "\n", "A_r1", "=", "AverageMeter", "(", ")", "\n", "A_r5", "=", "AverageMeter", "(", ")", "\n", "A_r10", "=", "AverageMeter", "(", ")", "\n", "I_r1", "=", "AverageMeter", "(", ")", "\n", "I_r5", "=", "AverageMeter", "(", ")", "\n", "I_r10", "=", "AverageMeter", "(", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "        ", "A_foundind", "=", "-", "1", "\n", "I_foundind", "=", "-", "1", "\n", "for", "ind", "in", "range", "(", "10", ")", ":", "\n", "            ", "if", "A2I_ind", "[", "ind", ",", "i", "]", "==", "i", ":", "\n", "                ", "I_foundind", "=", "ind", "\n", "", "if", "I2A_ind", "[", "i", ",", "ind", "]", "==", "i", ":", "\n", "                ", "A_foundind", "=", "ind", "\n", "# do r1s", "\n", "", "", "if", "A_foundind", "==", "0", ":", "\n", "            ", "A_r1", ".", "update", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "A_r1", ".", "update", "(", "0", ")", "\n", "", "if", "I_foundind", "==", "0", ":", "\n", "            ", "I_r1", ".", "update", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "I_r1", ".", "update", "(", "0", ")", "\n", "# do r5s", "\n", "", "if", "A_foundind", ">=", "0", "and", "A_foundind", "<", "5", ":", "\n", "            ", "A_r5", ".", "update", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "A_r5", ".", "update", "(", "0", ")", "\n", "", "if", "I_foundind", ">=", "0", "and", "I_foundind", "<", "5", ":", "\n", "            ", "I_r5", ".", "update", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "I_r5", ".", "update", "(", "0", ")", "\n", "# do r10s", "\n", "", "if", "A_foundind", ">=", "0", "and", "A_foundind", "<", "10", ":", "\n", "            ", "A_r10", ".", "update", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "A_r10", ".", "update", "(", "0", ")", "\n", "", "if", "I_foundind", ">=", "0", "and", "I_foundind", "<", "10", ":", "\n", "            ", "I_r10", ".", "update", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "I_r10", ".", "update", "(", "0", ")", "\n", "\n", "", "", "recalls", "=", "{", "'A_r1'", ":", "A_r1", ".", "avg", ",", "'A_r5'", ":", "A_r5", ".", "avg", ",", "'A_r10'", ":", "A_r10", ".", "avg", ",", "\n", "'I_r1'", ":", "I_r1", ".", "avg", ",", "'I_r5'", ":", "I_r5", ".", "avg", ",", "'I_r10'", ":", "I_r10", ".", "avg", "}", "\n", "#'A_meanR':A_meanR.avg, 'I_meanR':I_meanR.avg}", "\n", "\n", "return", "recalls", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.computeMatchmap": [[69, 80], ["I.size", "I.size", "I.size", "A.size", "I.view().t", "torch.mm", "torch.mm", "matchmap.view.view", "I.dim", "A.dim", "I.view"], "function", ["None"], ["", "def", "computeMatchmap", "(", "I", ",", "A", ")", ":", "\n", "    ", "assert", "(", "I", ".", "dim", "(", ")", "==", "3", ")", "\n", "assert", "(", "A", ".", "dim", "(", ")", "==", "2", ")", "\n", "D", "=", "I", ".", "size", "(", "0", ")", "\n", "H", "=", "I", ".", "size", "(", "1", ")", "\n", "W", "=", "I", ".", "size", "(", "2", ")", "\n", "T", "=", "A", ".", "size", "(", "1", ")", "\n", "Ir", "=", "I", ".", "view", "(", "D", ",", "-", "1", ")", ".", "t", "(", ")", "\n", "matchmap", "=", "torch", ".", "mm", "(", "Ir", ",", "A", ")", "\n", "matchmap", "=", "matchmap", ".", "view", "(", "H", ",", "W", ",", "T", ")", "\n", "return", "matchmap", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.matchmapSim": [[81, 94], ["M.dim", "M.mean", "M.max", "M_maxH.max", "M_maxHW.mean", "M.max", "M_maxT.mean"], "function", ["None"], ["", "def", "matchmapSim", "(", "M", ",", "simtype", ")", ":", "\n", "    ", "assert", "(", "M", ".", "dim", "(", ")", "==", "3", ")", "\n", "if", "simtype", "==", "'SISA'", ":", "\n", "        ", "return", "M", ".", "mean", "(", ")", "\n", "", "elif", "simtype", "==", "'MISA'", ":", "\n", "        ", "M_maxH", ",", "_", "=", "M", ".", "max", "(", "0", ")", "\n", "M_maxHW", ",", "_", "=", "M_maxH", ".", "max", "(", "0", ")", "\n", "return", "M_maxHW", ".", "mean", "(", ")", "\n", "", "elif", "simtype", "==", "'SIMA'", ":", "\n", "        ", "M_maxT", ",", "_", "=", "M", ".", "max", "(", "2", ")", "\n", "return", "M_maxT", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.sampled_margin_rank_loss": [[95, 124], ["image_outputs.size", "torch.zeros", "torch.zeros", "range", "image_outputs.dim", "audio_outputs.dim", "util.matchmapSim", "util.matchmapSim", "util.matchmapSim", "numpy.random.randint", "numpy.random.randint", "util.computeMatchmap", "util.computeMatchmap", "util.computeMatchmap"], "function", ["home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.matchmapSim", "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.matchmapSim", "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.matchmapSim", "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.computeMatchmap", "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.computeMatchmap", "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.computeMatchmap"], ["", "", "def", "sampled_margin_rank_loss", "(", "image_outputs", ",", "audio_outputs", ",", "nframes", ",", "margin", "=", "1.", ",", "simtype", "=", "'MISA'", ")", ":", "\n", "    ", "\"\"\"\n    Computes the triplet margin ranking loss for each anchor image/caption pair\n    The impostor image/caption is randomly sampled from the minibatch\n    \"\"\"", "\n", "assert", "(", "image_outputs", ".", "dim", "(", ")", "==", "4", ")", "\n", "assert", "(", "audio_outputs", ".", "dim", "(", ")", "==", "3", ")", "\n", "n", "=", "image_outputs", ".", "size", "(", "0", ")", "\n", "loss", "=", "torch", ".", "zeros", "(", "1", ",", "device", "=", "image_outputs", ".", "device", ",", "requires_grad", "=", "True", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "        ", "I_imp_ind", "=", "i", "\n", "A_imp_ind", "=", "i", "\n", "while", "I_imp_ind", "==", "i", ":", "\n", "            ", "I_imp_ind", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "n", ")", "\n", "", "while", "A_imp_ind", "==", "i", ":", "\n", "            ", "A_imp_ind", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "n", ")", "\n", "", "nF", "=", "nframes", "[", "i", "]", "\n", "nFimp", "=", "nframes", "[", "A_imp_ind", "]", "\n", "anchorsim", "=", "matchmapSim", "(", "computeMatchmap", "(", "image_outputs", "[", "i", "]", ",", "audio_outputs", "[", "i", "]", "[", ":", ",", "0", ":", "nF", "]", ")", ",", "simtype", ")", "\n", "Iimpsim", "=", "matchmapSim", "(", "computeMatchmap", "(", "image_outputs", "[", "I_imp_ind", "]", ",", "audio_outputs", "[", "i", "]", "[", ":", ",", "0", ":", "nF", "]", ")", ",", "simtype", ")", "\n", "Aimpsim", "=", "matchmapSim", "(", "computeMatchmap", "(", "image_outputs", "[", "i", "]", ",", "audio_outputs", "[", "A_imp_ind", "]", "[", ":", ",", "0", ":", "nFimp", "]", ")", ",", "simtype", ")", "\n", "A2I_simdif", "=", "margin", "+", "Iimpsim", "-", "anchorsim", "\n", "if", "(", "A2I_simdif", ".", "data", ">", "0", ")", ".", "all", "(", ")", ":", "\n", "            ", "loss", "=", "loss", "+", "A2I_simdif", "\n", "", "I2A_simdif", "=", "margin", "+", "Aimpsim", "-", "anchorsim", "\n", "if", "(", "I2A_simdif", ".", "data", ">", "0", ")", ".", "all", "(", ")", ":", "\n", "            ", "loss", "=", "loss", "+", "I2A_simdif", "\n", "", "", "loss", "=", "loss", "/", "n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.compute_matchmap_similarity_matrix": [[125, 140], ["image_outputs.size", "torch.zeros", "torch.zeros", "range", "image_outputs.dim", "audio_outputs.dim", "range", "max", "util.matchmapSim", "util.computeMatchmap"], "function", ["home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.matchmapSim", "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.computeMatchmap"], ["", "def", "compute_matchmap_similarity_matrix", "(", "image_outputs", ",", "audio_outputs", ",", "nframes", ",", "simtype", "=", "'MISA'", ")", ":", "\n", "    ", "\"\"\"\n    Assumes image_outputs is a (batchsize, embedding_dim, rows, height) tensor\n    Assumes audio_outputs is a (batchsize, embedding_dim, 1, time) tensor\n    Returns similarity matrix S where images are rows and audios are along the columns\n    \"\"\"", "\n", "assert", "(", "image_outputs", ".", "dim", "(", ")", "==", "4", ")", "\n", "assert", "(", "audio_outputs", ".", "dim", "(", ")", "==", "3", ")", "\n", "n", "=", "image_outputs", ".", "size", "(", "0", ")", "\n", "S", "=", "torch", ".", "zeros", "(", "n", ",", "n", ",", "device", "=", "image_outputs", ".", "device", ")", "\n", "for", "image_idx", "in", "range", "(", "n", ")", ":", "\n", "            ", "for", "audio_idx", "in", "range", "(", "n", ")", ":", "\n", "                ", "nF", "=", "max", "(", "1", ",", "nframes", "[", "audio_idx", "]", ")", "\n", "S", "[", "image_idx", ",", "audio_idx", "]", "=", "matchmapSim", "(", "computeMatchmap", "(", "image_outputs", "[", "image_idx", "]", ",", "audio_outputs", "[", "audio_idx", "]", "[", ":", ",", "0", ":", "nF", "]", ")", ",", "simtype", ")", "\n", "", "", "return", "S", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.compute_pooldot_similarity_matrix": [[141, 162], ["image_outputs.size", "torch.AdaptiveAvgPool2d", "nn.AdaptiveAvgPool2d.squeeze().squeeze", "torch.AdaptiveAvgPool2d", "range", "torch.cat().squeeze().squeeze", "torch.cat().squeeze().squeeze", "torch.mm", "torch.mm", "image_outputs.dim", "audio_outputs.dim", "max", "pooled_audio_outputs_list.append", "torch.cat().squeeze().squeeze.t", "nn.AdaptiveAvgPool2d.squeeze", "nn.AdaptiveAvgPool2d.unsqueeze", "torch.cat().squeeze", "torch.cat().squeeze", "nn.AdaptiveAvgPool2d.", "nn.AdaptiveAvgPool2d.", "torch.cat", "torch.cat"], "function", ["None"], ["", "def", "compute_pooldot_similarity_matrix", "(", "image_outputs", ",", "audio_outputs", ",", "nframes", ")", ":", "\n", "    ", "\"\"\"\n    Assumes image_outputs is a (batchsize, embedding_dim, rows, height) tensor\n    Assumes audio_outputs is a (batchsize, embedding_dim, 1, time) tensor\n    Returns similarity matrix S where images are rows and audios are along the columns\n    S[i][j] is computed as the dot product between the meanpooled embeddings of\n    the ith image output and jth audio output\n    \"\"\"", "\n", "assert", "(", "image_outputs", ".", "dim", "(", ")", "==", "4", ")", "\n", "assert", "(", "audio_outputs", ".", "dim", "(", ")", "==", "4", ")", "\n", "n", "=", "image_outputs", ".", "size", "(", "0", ")", "\n", "imagePoolfunc", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "pooled_image_outputs", "=", "imagePoolfunc", "(", "image_outputs", ")", ".", "squeeze", "(", "3", ")", ".", "squeeze", "(", "2", ")", "\n", "audioPoolfunc", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "pooled_audio_outputs_list", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "n", ")", ":", "\n", "        ", "nF", "=", "max", "(", "1", ",", "nframes", "[", "idx", "]", ")", "\n", "pooled_audio_outputs_list", ".", "append", "(", "audioPoolfunc", "(", "audio_outputs", "[", "idx", "]", "[", ":", ",", ":", ",", "0", ":", "nF", "]", ")", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "pooled_audio_outputs", "=", "torch", ".", "cat", "(", "pooled_audio_outputs_list", ")", ".", "squeeze", "(", "3", ")", ".", "squeeze", "(", "2", ")", "\n", "S", "=", "torch", ".", "mm", "(", "pooled_image_outputs", ",", "pooled_audio_outputs", ".", "t", "(", ")", ")", "\n", "return", "S", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.one_imposter_index": [[163, 168], ["random.randint"], "function", ["None"], ["", "def", "one_imposter_index", "(", "i", ",", "N", ")", ":", "\n", "    ", "imp_ind", "=", "random", ".", "randint", "(", "0", ",", "N", "-", "2", ")", "\n", "if", "imp_ind", "==", "i", ":", "\n", "        ", "imp_ind", "=", "N", "-", "1", "\n", "", "return", "imp_ind", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.basic_get_imposter_indices": [[169, 176], ["range", "util.one_imposter_index", "imposter_idc.append"], "function", ["home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.one_imposter_index"], ["", "def", "basic_get_imposter_indices", "(", "N", ")", ":", "\n", "    ", "imposter_idc", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "# Select an imposter index for example i:", "\n", "        ", "imp_ind", "=", "one_imposter_index", "(", "i", ",", "N", ")", "\n", "imposter_idc", ".", "append", "(", "imp_ind", ")", "\n", "", "return", "imposter_idc", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.semihardneg_triplet_loss_from_S": [[177, 214], ["S.size", "torch.autograd.Variable", "torch.autograd.Variable", "mask.type_as", "Sp.max", "idc.data.cpu.data.cpu", "torch.LongTensor", "torch.LongTensor", "enumerate", "S.dim", "S.size", "S.size", "torch.zeros().type", "torch.zeros().type", "torch.diag().view", "torch.diag().view", "util.basic_get_imposter_indices", "S.data.type", "torch.min().detach", "torch.min().detach", "torch.zeros", "torch.zeros", "torch.diag", "torch.diag", "torch.min", "torch.min", "mask.sum"], "function", ["home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.basic_get_imposter_indices"], ["", "def", "semihardneg_triplet_loss_from_S", "(", "S", ",", "margin", ")", ":", "\n", "    ", "\"\"\"\n    Input: Similarity matrix S as an autograd.Variable\n    Output: The one-way triplet loss from rows of S to columns of S. Impostors are taken\n    to be the most similar point to the anchor that is still less similar to the anchor\n    than the positive example.\n    You would need to run this function twice, once with S and once with S.t(),\n    in order to compute the triplet loss in both directions.\n    \"\"\"", "\n", "assert", "(", "S", ".", "dim", "(", ")", "==", "2", ")", "\n", "assert", "(", "S", ".", "size", "(", "0", ")", "==", "S", ".", "size", "(", "1", ")", ")", "\n", "N", "=", "S", ".", "size", "(", "0", ")", "\n", "loss", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "zeros", "(", "1", ")", ".", "type", "(", "S", ".", "data", ".", "type", "(", ")", ")", ",", "requires_grad", "=", "True", ")", "\n", "# Imposter - ground truth", "\n", "Sdiff", "=", "S", "-", "torch", ".", "diag", "(", "S", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "eps", "=", "1e-12", "\n", "# All examples less similar than ground truth", "\n", "mask", "=", "(", "Sdiff", "<", "-", "eps", ")", ".", "type", "(", "torch", ".", "LongTensor", ")", "\n", "maskf", "=", "mask", ".", "type_as", "(", "S", ")", "\n", "# Mask out all examples >= gt with minimum similarity", "\n", "Sp", "=", "maskf", "*", "Sdiff", "+", "(", "1", "-", "maskf", ")", "*", "torch", ".", "min", "(", "Sdiff", ")", ".", "detach", "(", ")", "\n", "# Find the index maximum similar of the remaining", "\n", "_", ",", "idc", "=", "Sp", ".", "max", "(", "dim", "=", "1", ")", "\n", "idc", "=", "idc", ".", "data", ".", "cpu", "(", ")", "\n", "# Vector mask: 1 iff there exists an example < gt", "\n", "has_neg", "=", "(", "mask", ".", "sum", "(", "dim", "=", "1", ")", ">", "0", ")", ".", "data", ".", "type", "(", "torch", ".", "LongTensor", ")", "\n", "# Random imposter indices", "\n", "random_imp_ind", "=", "torch", ".", "LongTensor", "(", "basic_get_imposter_indices", "(", "N", ")", ")", "\n", "# Use hardneg if there exists an example < gt, otherwise use random imposter", "\n", "imp_idc", "=", "has_neg", "*", "idc", "+", "(", "1", "-", "has_neg", ")", "*", "random_imp_ind", "\n", "# This could probably be vectorized too, but I haven't.", "\n", "for", "i", ",", "imp", "in", "enumerate", "(", "imp_idc", ")", ":", "\n", "        ", "local_loss", "=", "Sdiff", "[", "i", ",", "imp", "]", "+", "margin", "\n", "if", "(", "local_loss", ".", "data", ">", "0", ")", ".", "all", "(", ")", ":", "\n", "            ", "loss", "=", "loss", "+", "local_loss", "\n", "", "", "loss", "=", "loss", "/", "N", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.sampled_triplet_loss_from_S": [[215, 237], ["S.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.LongTensor", "torch.LongTensor", "enumerate", "S.dim", "S.size", "S.size", "torch.zeros().type", "torch.zeros().type", "torch.diag().view", "torch.diag().view", "util.basic_get_imposter_indices", "S.data.type", "torch.zeros", "torch.zeros", "torch.diag", "torch.diag"], "function", ["home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.basic_get_imposter_indices"], ["", "def", "sampled_triplet_loss_from_S", "(", "S", ",", "margin", ")", ":", "\n", "    ", "\"\"\"\n    Input: Similarity matrix S as an autograd.Variable\n    Output: The one-way triplet loss from rows of S to columns of S. Imposters are\n    randomly sampled from the columns of S.\n    You would need to run this function twice, once with S and once with S.t(),\n    in order to compute the triplet loss in both directions.\n    \"\"\"", "\n", "assert", "(", "S", ".", "dim", "(", ")", "==", "2", ")", "\n", "assert", "(", "S", ".", "size", "(", "0", ")", "==", "S", ".", "size", "(", "1", ")", ")", "\n", "N", "=", "S", ".", "size", "(", "0", ")", "\n", "loss", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "zeros", "(", "1", ")", ".", "type", "(", "S", ".", "data", ".", "type", "(", ")", ")", ",", "requires_grad", "=", "True", ")", "\n", "# Imposter - ground truth", "\n", "Sdiff", "=", "S", "-", "torch", ".", "diag", "(", "S", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "imp_ind", "=", "torch", ".", "LongTensor", "(", "basic_get_imposter_indices", "(", "N", ")", ")", "\n", "# This could probably be vectorized too, but I haven't.", "\n", "for", "i", ",", "imp", "in", "enumerate", "(", "imp_ind", ")", ":", "\n", "        ", "local_loss", "=", "Sdiff", "[", "i", ",", "imp", "]", "+", "margin", "\n", "if", "(", "local_loss", ".", "data", ">", "0", ")", ".", "all", "(", ")", ":", "\n", "            ", "loss", "=", "loss", "+", "local_loss", "\n", "", "", "loss", "=", "loss", "/", "N", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.adjust_learning_rate": [[255, 261], ["print"], "function", ["None"], ["", "", "def", "adjust_learning_rate", "(", "base_lr", ",", "lr_decay", ",", "optimizer", ",", "epoch", ")", ":", "\n", "    ", "\"\"\"Sets the learning rate to the initial LR decayed by 10 every lr_decay epochs\"\"\"", "\n", "lr", "=", "base_lr", "*", "(", "0.1", "**", "(", "epoch", "//", "lr_decay", ")", ")", "\n", "print", "(", "'now learning rate changed to {:f}'", ".", "format", "(", "lr", ")", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.adjust_learning_rate2": [[262, 271], ["print", "print"], "function", ["None"], ["", "", "def", "adjust_learning_rate2", "(", "base_lr", ",", "lr_decay", ",", "optimizer", ",", "epoch", ")", ":", "\n", "    ", "\"\"\"Sets the learning rate to the initial LR decayed by 10 every lr_decay epochs\"\"\"", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "cur_lr", "=", "param_group", "[", "'lr'", "]", "\n", "print", "(", "'current learing rate is {:f}'", ".", "format", "(", "lr", ")", ")", "\n", "", "lr", "=", "cur_lr", "*", "0.1", "\n", "print", "(", "'now learning rate changed to {:f}'", ".", "format", "(", "lr", ")", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.load_progress": [[273, 297], ["util.load_progress._print"], "function", ["None"], ["", "", "def", "load_progress", "(", "prog_pkl", ",", "quiet", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    load progress pkl file\n    Args:\n        prog_pkl(str): path to progress pkl file\n    Return:\n        progress(list):\n        epoch(int):\n        global_step(int):\n        best_epoch(int):\n        best_avg_r10(float):\n    \"\"\"", "\n", "def", "_print", "(", "msg", ")", ":", "\n", "        ", "if", "not", "quiet", ":", "\n", "            ", "print", "(", "msg", ")", "\n", "\n", "", "", "with", "open", "(", "prog_pkl", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "prog", "=", "pickle", ".", "load", "(", "f", ")", "\n", "epoch", ",", "global_step", ",", "best_epoch", ",", "best_avg_r10", ",", "_", "=", "prog", "[", "-", "1", "]", "\n", "\n", "", "_print", "(", "\"\\nPrevious Progress:\"", ")", "\n", "msg", "=", "\"[%5s %7s %5s %7s %6s]\"", "%", "(", "\"epoch\"", ",", "\"step\"", ",", "\"best_epoch\"", ",", "\"best_avg_r10\"", ",", "\"time\"", ")", "\n", "_print", "(", "msg", ")", "\n", "return", "prog", ",", "epoch", ",", "global_step", ",", "best_epoch", ",", "best_avg_r10", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.utilities.util.count_parameters": [[298, 300], ["sum", "p.numel", "model.parameters"], "function", ["None"], ["", "def", "count_parameters", "(", "model", ")", ":", "\n", "    ", "return", "sum", "(", "[", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.esc50.prep_esc50.get_immediate_subdirectories": [[32, 34], ["os.listdir", "os.path.isdir", "os.path.join"], "function", ["None"], ["def", "get_immediate_subdirectories", "(", "a_dir", ")", ":", "\n", "    ", "return", "[", "name", "for", "name", "in", "os", ".", "listdir", "(", "a_dir", ")", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "a_dir", ",", "name", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.esc50.prep_esc50.get_immediate_files": [[35, 37], ["os.listdir", "os.path.isfile", "os.path.join"], "function", ["None"], ["", "def", "get_immediate_files", "(", "a_dir", ")", ":", "\n", "    ", "return", "[", "name", "for", "name", "in", "os", ".", "listdir", "(", "a_dir", ")", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "a_dir", ",", "name", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.audioset.inference.make_features": [[23, 42], ["torchaudio.load", "torchaudio.compliance.kaldi.fbank", "torch.nn.ZeroPad2d", "torch.nn.ZeroPad2d."], "function", ["None"], ["def", "make_features", "(", "wav_name", ",", "mel_bins", ",", "target_length", "=", "1024", ")", ":", "\n", "    ", "waveform", ",", "sr", "=", "torchaudio", ".", "load", "(", "wav_name", ")", "\n", "\n", "fbank", "=", "torchaudio", ".", "compliance", ".", "kaldi", ".", "fbank", "(", "\n", "waveform", ",", "htk_compat", "=", "True", ",", "sample_frequency", "=", "sr", ",", "use_energy", "=", "False", ",", "\n", "window_type", "=", "'hanning'", ",", "num_mel_bins", "=", "mel_bins", ",", "dither", "=", "0.0", ",", "\n", "frame_shift", "=", "10", ")", "\n", "\n", "n_frames", "=", "fbank", ".", "shape", "[", "0", "]", "\n", "\n", "p", "=", "target_length", "-", "n_frames", "\n", "if", "p", ">", "0", ":", "\n", "        ", "m", "=", "torch", ".", "nn", ".", "ZeroPad2d", "(", "(", "0", ",", "0", ",", "0", ",", "p", ")", ")", "\n", "fbank", "=", "m", "(", "fbank", ")", "\n", "", "elif", "p", "<", "0", ":", "\n", "        ", "fbank", "=", "fbank", "[", "0", ":", "target_length", ",", ":", "]", "\n", "\n", "", "fbank", "=", "(", "fbank", "-", "(", "-", "4.2677393", ")", ")", "/", "(", "4.5689974", "*", "2", ")", "\n", "return", "fbank", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.audioset.inference.load_label": [[44, 56], ["range", "open", "csv.reader", "list", "len", "ids.append", "labels.append"], "function", ["None"], ["", "def", "load_label", "(", "label_csv", ")", ":", "\n", "    ", "with", "open", "(", "label_csv", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "','", ")", "\n", "lines", "=", "list", "(", "reader", ")", "\n", "", "labels", "=", "[", "]", "\n", "ids", "=", "[", "]", "# Each label has a unique id such as \"/m/068hy\"", "\n", "for", "i1", "in", "range", "(", "1", ",", "len", "(", "lines", ")", ")", ":", "\n", "        ", "id", "=", "lines", "[", "i1", "]", "[", "1", "]", "\n", "label", "=", "lines", "[", "i1", "]", "[", "2", "]", "\n", "ids", ".", "append", "(", "id", ")", "\n", "labels", ".", "append", "(", "label", ")", "\n", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.audioset.gen_weight_file.make_index_dict": [[16, 25], ["open", "csv.DictReader"], "function", ["None"], ["def", "make_index_dict", "(", "label_csv", ")", ":", "\n", "    ", "index_lookup", "=", "{", "}", "\n", "with", "open", "(", "label_csv", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "csv_reader", "=", "csv", ".", "DictReader", "(", "f", ")", "\n", "line_count", "=", "0", "\n", "for", "row", "in", "csv_reader", ":", "\n", "            ", "index_lookup", "[", "row", "[", "'mid'", "]", "]", "=", "row", "[", "'index'", "]", "\n", "line_count", "+=", "1", "\n", "", "", "return", "index_lookup", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.audioset.ensemble.get_ensemble_res": [[24, 74], ["numpy.zeros", "torch.device", "enumerate", "numpy.loadtxt", "numpy.loadtxt", "numpy.zeros", "range", "numpy.mean", "calculate_stats", "numpy.mean", "numpy.mean", "ensemble.d_prime", "print", "range", "print", "numpy.savetxt", "os.path.exists", "os.mkdir", "print", "print", "torch.load", "models.ASTModel", "torch.nn.DataParallel", "torch.nn.DataParallel.load_state_dict", "traintest.validate", "numpy.mean", "numpy.mean", "ensemble.d_prime", "print", "len", "numpy.loadtxt", "len", "print", "torch.cuda.is_available", "int", "int", "len", "len", "len", "[].split", "[].split", "str", "mdl.split", "[].split", "mdl.split"], "function", ["home.repos.pwc.inspect_result.YuanGongND_ast.utilities.stats.calculate_stats", "home.repos.pwc.inspect_result.YuanGongND_ast.audioset.ensemble.d_prime", "home.repos.pwc.inspect_result.YuanGongND_ast.src.traintest.validate", "home.repos.pwc.inspect_result.YuanGongND_ast.audioset.ensemble.d_prime"], ["def", "get_ensemble_res", "(", "mdl_list", ",", "base_path", ")", ":", "\n", "# the 0-len(mdl_list) rows record the results of single models, the last row record the result of the ensemble model.", "\n", "    ", "ensemble_res", "=", "np", ".", "zeros", "(", "[", "len", "(", "mdl_list", ")", "+", "1", ",", "3", "]", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "base_path", ")", "==", "False", ":", "\n", "        ", "os", ".", "mkdir", "(", "base_path", ")", "\n", "", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "for", "model_idx", ",", "mdl", "in", "enumerate", "(", "mdl_list", ")", ":", "\n", "        ", "print", "(", "'-----------------------'", ")", "\n", "print", "(", "'now loading model {:d}: {:s}'", ".", "format", "(", "model_idx", ",", "mdl", ")", ")", "\n", "\n", "# sd = torch.load('/Users/yuan/Documents/ast/pretrained_models/audio_model_wa.pth', map_location=device)", "\n", "sd", "=", "torch", ".", "load", "(", "mdl", ",", "map_location", "=", "device", ")", "\n", "# get the time and freq stride of the pretrained model", "\n", "fstride", ",", "tstride", "=", "int", "(", "mdl", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'_'", ")", "[", "1", "]", ")", ",", "int", "(", "mdl", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'_'", ")", "[", "2", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", "\n", "audio_model", "=", "models", ".", "ASTModel", "(", "fstride", "=", "fstride", ",", "tstride", "=", "tstride", ")", "\n", "audio_model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "audio_model", ")", "\n", "audio_model", ".", "load_state_dict", "(", "sd", ",", "strict", "=", "False", ")", "\n", "\n", "args", ".", "exp_dir", "=", "base_path", "\n", "\n", "stats", ",", "_", "=", "validate", "(", "audio_model", ",", "eval_loader", ",", "args", ",", "model_idx", ")", "\n", "mAP", "=", "np", ".", "mean", "(", "[", "stat", "[", "'AP'", "]", "for", "stat", "in", "stats", "]", ")", "\n", "mAUC", "=", "np", ".", "mean", "(", "[", "stat", "[", "'auc'", "]", "for", "stat", "in", "stats", "]", ")", "\n", "dprime", "=", "d_prime", "(", "mAUC", ")", "\n", "ensemble_res", "[", "model_idx", ",", ":", "]", "=", "[", "mAP", ",", "mAUC", ",", "dprime", "]", "\n", "print", "(", "\"Model {:d} {:s} mAP: {:.6f}, AUC: {:.6f}, d-prime: {:.6f}\"", ".", "format", "(", "model_idx", ",", "mdl", ",", "mAP", ",", "mAUC", ",", "dprime", ")", ")", "\n", "\n", "# calculate the ensemble result", "\n", "# get the ground truth label", "\n", "", "target", "=", "np", ".", "loadtxt", "(", "base_path", "+", "'/predictions/target.csv'", ",", "delimiter", "=", "','", ")", "\n", "# get the ground truth label", "\n", "prediction_sample", "=", "np", ".", "loadtxt", "(", "base_path", "+", "'/predictions/predictions_0.csv'", ",", "delimiter", "=", "','", ")", "\n", "# allocate memory space for the ensemble prediction", "\n", "predictions_table", "=", "np", ".", "zeros", "(", "[", "len", "(", "mdl_list", ")", ",", "prediction_sample", ".", "shape", "[", "0", "]", ",", "prediction_sample", ".", "shape", "[", "1", "]", "]", ")", "\n", "for", "model_idx", "in", "range", "(", "0", ",", "len", "(", "mdl_list", ")", ")", ":", "\n", "        ", "predictions_table", "[", "model_idx", ",", ":", ",", ":", "]", "=", "np", ".", "loadtxt", "(", "base_path", "+", "'/predictions/predictions_'", "+", "str", "(", "model_idx", ")", "+", "'.csv'", ",", "delimiter", "=", "','", ")", "\n", "model_idx", "+=", "1", "\n", "\n", "", "ensemble_predictions", "=", "np", ".", "mean", "(", "predictions_table", ",", "axis", "=", "0", ")", "\n", "stats", "=", "calculate_stats", "(", "ensemble_predictions", ",", "target", ")", "\n", "ensemble_mAP", "=", "np", ".", "mean", "(", "[", "stat", "[", "'AP'", "]", "for", "stat", "in", "stats", "]", ")", "\n", "ensemble_mAUC", "=", "np", ".", "mean", "(", "[", "stat", "[", "'auc'", "]", "for", "stat", "in", "stats", "]", ")", "\n", "ensemble_dprime", "=", "d_prime", "(", "ensemble_mAUC", ")", "\n", "ensemble_res", "[", "-", "1", ",", ":", "]", "=", "[", "ensemble_mAP", ",", "ensemble_mAUC", ",", "ensemble_dprime", "]", "\n", "print", "(", "'---------------Ensemble Result Summary---------------'", ")", "\n", "for", "model_idx", "in", "range", "(", "len", "(", "mdl_list", ")", ")", ":", "\n", "        ", "print", "(", "\"Model {:d} {:s} mAP: {:.6f}, AUC: {:.6f}, d-prime: {:.6f}\"", ".", "format", "(", "model_idx", ",", "mdl_list", "[", "model_idx", "]", ",", "ensemble_res", "[", "model_idx", ",", "0", "]", ",", "ensemble_res", "[", "model_idx", ",", "1", "]", ",", "ensemble_res", "[", "model_idx", ",", "2", "]", ")", ")", "\n", "", "print", "(", "\"Ensemble {:d} Models mAP: {:.6f}, AUC: {:.6f}, d-prime: {:.6f}\"", ".", "format", "(", "len", "(", "mdl_list", ")", ",", "ensemble_mAP", ",", "ensemble_mAUC", ",", "ensemble_dprime", ")", ")", "\n", "np", ".", "savetxt", "(", "base_path", "+", "'/ensemble_result.csv'", ",", "ensemble_res", ",", "delimiter", "=", "','", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_ast.audioset.ensemble.d_prime": [[75, 79], ["scipy.stats.norm", "stats.norm.ppf", "numpy.sqrt"], "function", ["None"], ["", "def", "d_prime", "(", "auc", ")", ":", "\n", "    ", "standard_normal", "=", "stats", ".", "norm", "(", ")", "\n", "d_prime", "=", "standard_normal", ".", "ppf", "(", "auc", ")", "*", "np", ".", "sqrt", "(", "2.0", ")", "\n", "return", "d_prime", "\n", "\n"]]}