{"home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.vectorspace.VSM.__init__": [[6, 16], ["numpy.array", "vectorspace.VSM.load_txt", "vectorspace.VSM.normalize"], "methods", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.vectorspace.VSM.load_txt", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.vectorspace.VSM.normalize"], ["    ", "def", "__init__", "(", "self", ",", "vecs_path", ",", "normalize", "=", "True", ")", ":", "\n", "        ", "self", ".", "labels", "=", "[", "]", "\n", "self", ".", "vectors", "=", "np", ".", "array", "(", "[", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "indices", "=", "{", "}", "\n", "self", ".", "ndims", "=", "0", "\n", "\n", "self", ".", "load_txt", "(", "vecs_path", ")", "\n", "\n", "if", "normalize", ":", "\n", "            ", "self", ".", "normalize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.vectorspace.VSM.load_txt": [[17, 28], ["numpy.vstack", "open", "line.split", "vectorspace.VSM.labels.append", "vectorspace.VSM.vectors.append", "enumerate", "numpy.array", "list", "map"], "methods", ["None"], ["", "", "def", "load_txt", "(", "self", ",", "vecs_path", ")", ":", "\n", "        ", "self", ".", "vectors", "=", "[", "]", "\n", "with", "open", "(", "vecs_path", ",", "encoding", "=", "'utf-8'", ")", "as", "vecs_f", ":", "\n", "            ", "for", "line", "in", "vecs_f", ":", "\n", "                ", "elems", "=", "line", ".", "split", "(", ")", "\n", "self", ".", "labels", ".", "append", "(", "elems", "[", "0", "]", ")", "\n", "self", ".", "vectors", ".", "append", "(", "np", ".", "array", "(", "list", "(", "map", "(", "float", ",", "elems", "[", "1", ":", "]", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "\n", "", "", "self", ".", "vectors", "=", "np", ".", "vstack", "(", "self", ".", "vectors", ")", "\n", "self", ".", "indices", "=", "{", "l", ":", "i", "for", "i", ",", "l", "in", "enumerate", "(", "self", ".", "labels", ")", "}", "\n", "self", ".", "ndims", "=", "self", ".", "vectors", ".", "shape", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.vectorspace.VSM.normalize": [[29, 31], ["numpy.linalg.norm"], "methods", ["None"], ["", "def", "normalize", "(", "self", ")", ":", "\n", "        ", "self", ".", "vectors", "=", "(", "self", ".", "vectors", ".", "T", "/", "np", ".", "linalg", ".", "norm", "(", "self", ".", "vectors", ",", "axis", "=", "1", ")", ")", ".", "T", "# L2", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.vectorspace.VSM.get_vec": [[32, 34], ["None"], "methods", ["None"], ["", "def", "get_vec", "(", "self", ",", "label", ")", ":", "\n", "        ", "return", "self", ".", "vectors", "[", "self", ".", "indices", "[", "label", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.vectorspace.VSM.similarity": [[35, 39], ["vectorspace.VSM.get_vec", "vectorspace.VSM.get_vec", "numpy.dot().tolist", "numpy.dot"], "methods", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.vectorspace.VSM.get_vec", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.vectorspace.VSM.get_vec"], ["", "def", "similarity", "(", "self", ",", "label1", ",", "label2", ")", ":", "\n", "        ", "v1", "=", "self", ".", "get_vec", "(", "label1", ")", "\n", "v2", "=", "self", ".", "get_vec", "(", "label2", ")", "\n", "return", "np", ".", "dot", "(", "v1", ",", "v2", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.vectorspace.VSM.most_similar_vec": [[40, 48], ["numpy.dot", "numpy.dot.tolist", "r.append", "numpy.dot.argsort().tolist", "numpy.dot.argsort"], "methods", ["None"], ["", "def", "most_similar_vec", "(", "self", ",", "vec", ",", "topn", "=", "10", ")", ":", "\n", "# TO-DO: tidy up...", "\n", "        ", "sims", "=", "np", ".", "dot", "(", "self", ".", "vectors", ",", "vec", ")", "\n", "sims_", "=", "sims", ".", "tolist", "(", ")", "\n", "r", "=", "[", "]", "\n", "for", "top_i", "in", "sims", ".", "argsort", "(", ")", ".", "tolist", "(", ")", "[", ":", ":", "-", "1", "]", "[", ":", "topn", "]", ":", "\n", "            ", "r", ".", "append", "(", "(", "self", ".", "labels", "[", "top_i", "]", ",", "sims_", "[", "top_i", "]", ")", ")", "\n", "", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.vectorspace.VSM.sims": [[49, 51], ["numpy.dot().tolist", "numpy.dot", "numpy.array"], "methods", ["None"], ["", "def", "sims", "(", "self", ",", "vec", ")", ":", "\n", "        ", "return", "np", ".", "dot", "(", "self", ".", "vectors", ",", "np", ".", "array", "(", "vec", ")", ")", ".", "tolist", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.eval_1nn.eval_nn": [[26, 130], ["collections.defaultdict", "collections.defaultdict", "logging.info", "enumerate", "sklearn.metrics.recall_score", "sklearn.metrics.precision_score", "print", "print", "open", "summary_f.write", "coarsewsd20_reader.load_instances", "senses_vsm.most_similar_vec", "all_sense_preds[].append", "all_results[].append", "sum", "len", "summary_f.write", "open", "enumerate", "encoder.get_num_subtokens", "logging.error", "all_sense_preds[].append", "all_results[].append", "numpy.linalg.norm", "len", "len", "len", "len", "summary_f.write", "word_results_f.write", "encoder.token_embeddings", "json.dumps", "sense.split"], "function", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.coarsewsd20_reader.load_instances", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.vectorspace.VSM.most_similar_vec", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.get_num_subtokens", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.token_embeddings"], ["def", "eval_nn", "(", "args", ")", ":", "\n", "\n", "    ", "all_sense_preds", "=", "defaultdict", "(", "list", ")", "\n", "all_results", "=", "defaultdict", "(", "list", ")", "\n", "\n", "# matching test instances", "\n", "for", "amb_word", "in", "ambiguous_words", ":", "\n", "        ", "logging", ".", "info", "(", "'Evaluating %s ...'", "%", "amb_word", ")", "\n", "\n", "for", "inst_idx", ",", "test_inst", "in", "enumerate", "(", "load_instances", "(", "amb_word", ",", "split", "=", "'test'", ",", "setname", "=", "args", ".", "dataset_id", ",", "mode", "=", "args", ".", "mode", ")", ")", ":", "\n", "            ", "gold_sense", "=", "test_inst", "[", "'class'", "]", "\n", "\n", "if", "encoder", ".", "get_num_subtokens", "(", "test_inst", "[", "'tokens'", "]", ")", ">=", "args", ".", "max_seq_len", ":", "\n", "                ", "logging", ".", "error", "(", "'%s:%d exceeds max_seq_len (%d).'", "%", "(", "amb_word", ",", "inst_idx", ",", "args", ".", "max_seq_len", ")", ")", "\n", "\n", "preds", "=", "[", "(", "'NULL'", ",", "-", "1", ")", "]", "\n", "all_sense_preds", "[", "gold_sense", "]", ".", "append", "(", "preds", ")", "\n", "all_results", "[", "amb_word", "]", ".", "append", "(", "(", "test_inst", ",", "preds", ")", ")", "\n", "continue", "\n", "\n", "", "inst_vecs", "=", "encoder", ".", "token_embeddings", "(", "[", "test_inst", "[", "'tokens'", "]", "]", ")", "[", "0", "]", "[", "0", "]", "\n", "\n", "assert", "inst_vecs", "[", "test_inst", "[", "'idx'", "]", "]", "[", "0", "]", "==", "amb_word", "# sanity check", "\n", "\n", "amb_word_vec", "=", "inst_vecs", "[", "test_inst", "[", "'idx'", "]", "]", "[", "1", "]", "\n", "amb_word_vec", "=", "amb_word_vec", "/", "np", ".", "linalg", ".", "norm", "(", "amb_word_vec", ")", "\n", "\n", "preds", "=", "senses_vsm", ".", "most_similar_vec", "(", "amb_word_vec", ",", "topn", "=", "None", ")", "\n", "\n", "# filter preds for target word", "\n", "preds", "=", "[", "(", "sense", ",", "score", ")", "for", "sense", ",", "score", "in", "preds", "if", "sense", ".", "split", "(", "'_'", ")", "[", "0", "]", "==", "amb_word", "]", "\n", "\n", "all_sense_preds", "[", "gold_sense", "]", ".", "append", "(", "preds", ")", "\n", "all_results", "[", "amb_word", "]", ".", "append", "(", "(", "test_inst", ",", "preds", ")", ")", "\n", "\n", "# computing accuracies", "\n", "", "", "all_senses_accs", "=", "{", "}", "\n", "all_words_accs", "=", "{", "}", "\n", "for", "amb_word", "in", "coarse_senses", ":", "\n", "        ", "n_word_correct", ",", "n_word_insts", "=", "0", ",", "0", "\n", "\n", "all_gold", ",", "all_pred", "=", "[", "]", ",", "[", "]", "\n", "for", "sense", "in", "coarse_senses", "[", "amb_word", "]", ":", "\n", "            ", "sense_preds", "=", "all_sense_preds", "[", "sense", "]", "\n", "if", "len", "(", "sense_preds", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "", "n_sense_correct", "=", "sum", "(", "[", "1", "for", "preds", "in", "sense_preds", "if", "preds", "[", "0", "]", "[", "0", "]", "==", "sense", "]", ")", "\n", "sense_acc", "=", "n_sense_correct", "/", "len", "(", "sense_preds", ")", "\n", "all_senses_accs", "[", "sense", "]", "=", "sense_acc", "\n", "\n", "n_word_correct", "+=", "n_sense_correct", "\n", "n_word_insts", "+=", "len", "(", "sense_preds", ")", "\n", "\n", "all_pred", "+=", "[", "preds", "[", "0", "]", "[", "0", "]", "for", "preds", "in", "sense_preds", "]", "\n", "all_gold", "+=", "[", "sense", "]", "*", "len", "(", "sense_preds", ")", "\n", "\n", "", "word_recall_scores", "=", "recall_score", "(", "all_gold", ",", "all_pred", ",", "average", "=", "None", ")", "\n", "word_recall_MFS", "=", "word_recall_scores", "[", "0", "]", "\n", "word_recall_LFS", "=", "word_recall_scores", "[", "-", "1", "]", "\n", "\n", "word_precision_scores", "=", "precision_score", "(", "all_gold", ",", "all_pred", ",", "average", "=", "None", ")", "\n", "word_precision_MFS", "=", "word_precision_scores", "[", "0", "]", "\n", "word_precision_LFS", "=", "word_precision_scores", "[", "-", "1", "]", "\n", "\n", "print", "(", "amb_word", ",", "'PRECISION'", ",", "word_precision_MFS", ",", "word_precision_LFS", ")", "\n", "print", "(", "amb_word", ",", "'RECALL'", ",", "word_recall_MFS", ",", "word_recall_LFS", ")", "\n", "\n", "all_words_accs", "[", "amb_word", "]", "=", "n_word_correct", "/", "n_word_insts", "\n", "\n", "# writing perf summary and logging to stdout", "\n", "", "if", "args", ".", "mode", "!=", "'regular'", ":", "\n", "        ", "summary_path", "=", "'results/%s/1nn/%s/summary.%s.csv'", "%", "(", "args", ".", "dataset_id", ",", "args", ".", "nlm_id", ",", "args", ".", "mode", ")", "\n", "", "else", ":", "\n", "        ", "summary_path", "=", "'results/%s/1nn/%s/summary.csv'", "%", "(", "args", ".", "dataset_id", ",", "args", ".", "nlm_id", ")", "\n", "\n", "", "with", "open", "(", "summary_path", ",", "'w'", ")", "as", "summary_f", ":", "\n", "        ", "summary_f", ".", "write", "(", "'word,sense,n_insts,acc\\n'", ")", "\n", "for", "amb_word", "in", "coarse_senses", ":", "\n", "            ", "n_word_insts", "=", "0", "\n", "for", "sense", "in", "coarse_senses", "[", "amb_word", "]", ":", "\n", "                ", "if", "sense", "not", "in", "all_senses_accs", ":", "\n", "                    ", "continue", "\n", "\n", "", "sense_acc", "=", "all_senses_accs", "[", "sense", "]", "\n", "n_sense_insts", "=", "len", "(", "all_sense_preds", "[", "sense", "]", ")", "\n", "n_word_insts", "+=", "n_sense_insts", "\n", "summary_f", ".", "write", "(", "'%s,%s,%d,%f\\n'", "%", "(", "amb_word", ",", "sense", ",", "n_sense_insts", ",", "sense_acc", ")", ")", "\n", "\n", "", "word_acc", "=", "all_words_accs", "[", "amb_word", "]", "\n", "summary_f", ".", "write", "(", "'%s,%s,%d,%f\\n'", "%", "(", "amb_word", ",", "'ALL'", ",", "n_word_insts", ",", "word_acc", ")", ")", "\n", "\n", "# store full results for further analysis", "\n", "", "", "for", "amb_word", "in", "all_results", ":", "\n", "\n", "        ", "if", "args", ".", "mode", "!=", "'regular'", ":", "\n", "            ", "word_results_path", "=", "'results/%s/1nn/%s/%s.%s.jsonl'", "%", "(", "args", ".", "dataset_id", ",", "args", ".", "nlm_id", ",", "amb_word", ",", "args", ".", "mode", ")", "\n", "", "else", ":", "\n", "            ", "word_results_path", "=", "'results/%s/1nn/%s/%s.jsonl'", "%", "(", "args", ".", "dataset_id", ",", "args", ".", "nlm_id", ",", "amb_word", ")", "\n", "\n", "", "with", "open", "(", "word_results_path", ",", "'w'", ")", "as", "word_results_f", ":", "\n", "            ", "for", "inst_idx", ",", "(", "test_inst", ",", "inst_matches", ")", "in", "enumerate", "(", "all_results", "[", "amb_word", "]", ")", ":", "\n", "                ", "jsonl_results", "=", "{", "'idx'", ":", "inst_idx", ",", "'matches'", ":", "inst_matches", ",", "'gold'", ":", "test_inst", "[", "'class'", "]", ",", "'tokens'", ":", "test_inst", "[", "'tokens'", "]", "}", "\n", "word_results_f", ".", "write", "(", "'%s\\n'", "%", "json", ".", "dumps", "(", "jsonl_results", ",", "sort_keys", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.create_1nn_vecs.create_vecs": [[19, 57], ["logging.info", "logging.info", "enumerate", "open", "sense_vecs.items", "coarsewsd20_reader.load_instances", "vecs_f.write", "encoder.get_num_subtokens", "logging.error", "logging.info", "str", "encoder.token_embeddings", "round", "vec.tolist"], "function", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.coarsewsd20_reader.load_instances", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.get_num_subtokens", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.token_embeddings"], ["def", "create_vecs", "(", "args", ")", ":", "\n", "    ", "sense_vecs", "=", "{", "}", "\n", "n_sents", "=", "0", "\n", "\n", "for", "word", "in", "ambiguous_words", ":", "\n", "        ", "logging", ".", "info", "(", "'Processing \\'%s\\' ...'", "%", "word", ")", "\n", "\n", "for", "inst_idx", ",", "inst", "in", "enumerate", "(", "load_instances", "(", "word", ",", "split", "=", "'train'", ",", "setname", "=", "args", ".", "dataset_id", ")", ")", ":", "\n", "            ", "n_sents", "+=", "1", "\n", "\n", "if", "encoder", ".", "get_num_subtokens", "(", "inst", "[", "'tokens'", "]", ")", ">=", "args", ".", "max_seq_len", ":", "\n", "                ", "logging", ".", "error", "(", "'%s:%d exceeds max_seq_len (%d).'", "%", "(", "word", ",", "inst_idx", ",", "args", ".", "max_seq_len", ")", ")", "\n", "continue", "\n", "\n", "", "try", ":", "\n", "                ", "inst_vecs", "=", "encoder", ".", "token_embeddings", "(", "[", "inst", "[", "'tokens'", "]", "]", ")", "[", "0", "]", "[", "0", "]", "\n", "", "except", ":", "\n", "                ", "logging", ".", "info", "(", "'ERROR: %s:%d'", "%", "(", "word", ",", "inst_idx", "+", "1", ")", ")", "\n", "continue", "\n", "\n", "", "assert", "inst_vecs", "[", "inst", "[", "'idx'", "]", "]", "[", "0", "]", "==", "word", "# sanity check", "\n", "\n", "word_vec", "=", "inst_vecs", "[", "inst", "[", "'idx'", "]", "]", "[", "1", "]", "\n", "word_cls", "=", "inst", "[", "'class'", "]", "\n", "\n", "try", ":", "\n", "                ", "sense_vecs", "[", "word_cls", "]", "[", "'vecs_sum'", "]", "+=", "word_vec", "\n", "sense_vecs", "[", "word_cls", "]", "[", "'vecs_num'", "]", "+=", "1", "\n", "", "except", "KeyError", ":", "\n", "                ", "sense_vecs", "[", "word_cls", "]", "=", "{", "'vecs_sum'", ":", "word_vec", ",", "'vecs_num'", ":", "1", "}", "\n", "\n", "\n", "", "", "", "logging", ".", "info", "(", "'Writing Sense Vectors to %s ...'", "%", "args", ".", "out_path", ")", "\n", "with", "open", "(", "args", ".", "out_path", ",", "'w'", ")", "as", "vecs_f", ":", "\n", "        ", "for", "sense", ",", "vecs_info", "in", "sense_vecs", ".", "items", "(", ")", ":", "\n", "            ", "vec", "=", "vecs_info", "[", "'vecs_sum'", "]", "/", "vecs_info", "[", "'vecs_num'", "]", "\n", "vec_str", "=", "' '", ".", "join", "(", "[", "str", "(", "round", "(", "v", ",", "6", ")", ")", "for", "v", "in", "vec", ".", "tolist", "(", ")", "]", ")", "\n", "vecs_f", ".", "write", "(", "'%s %s\\n'", "%", "(", "sense", ",", "vec_str", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.create_ftx_models.rem_prefix": [[19, 21], ["label.replace"], "function", ["None"], ["def", "rem_prefix", "(", "label", ")", ":", "\n", "    ", "return", "label", ".", "replace", "(", "'__label__'", ",", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.create_ftx_models.convert_dataset": [[23, 30], ["open", "coarsewsd20_reader.load_instances", "word_split_f.write"], "function", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.coarsewsd20_reader.load_instances"], ["", "def", "convert_dataset", "(", "dataset_id", ")", ":", "\n", "    ", "for", "split", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "        ", "for", "amb_word", "in", "ambiguous_words", ":", "\n", "            ", "with", "open", "(", "'data/fasttext_data/%s.fasttext.%s.%s'", "%", "(", "dataset_id", ",", "amb_word", ",", "split", ")", ",", "'w'", ")", "as", "word_split_f", ":", "\n", "                ", "for", "inst", "in", "load_instances", "(", "amb_word", ",", "split", "=", "split", ",", "setname", "=", "dataset_id", ")", ":", "\n", "                    ", "inst_str", "=", "'__label__%s %s'", "%", "(", "inst", "[", "'class'", "]", ",", "' '", ".", "join", "(", "inst", "[", "'tokens'", "]", ")", ")", "\n", "word_split_f", ".", "write", "(", "'%s\\n'", "%", "inst_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.create_ftx_models.create_models": [[32, 49], ["logging.info", "fasttext.train_supervised.save_model", "fasttext.train_supervised", "fasttext.train_supervised"], "function", ["None"], ["", "", "", "", "", "def", "create_models", "(", "use_pretrained", "=", "False", ")", ":", "\n", "\n", "    ", "for", "amb_word", "in", "ambiguous_words", ":", "\n", "        ", "logging", ".", "info", "(", "'Generating model for \\'%s\\' ...'", "%", "amb_word", ")", "\n", "train_path", "=", "'data/fasttext_data/%s.fasttext.%s.train'", "%", "(", "dataset_id", ",", "amb_word", ")", "\n", "if", "use_pretrained", ":", "\n", "            ", "model", "=", "fasttext", ".", "train_supervised", "(", "input", "=", "train_path", ",", "\n", "pretrainedVectors", "=", "'external/fastText-0.9.1/crawl-300d-2M.vec'", ",", "\n", "epoch", "=", "25", ",", "lr", "=", "0.5", ",", "dim", "=", "300", ",", "loss", "=", "'ova'", ")", "\n", "model_fn", "=", "'%s.fasttext.%s.crawl-300d-2M.model.bin'", "%", "(", "dataset_id", ",", "amb_word", ")", "\n", "\n", "", "else", ":", "\n", "            ", "model", "=", "fasttext", ".", "train_supervised", "(", "input", "=", "train_path", ",", "\n", "epoch", "=", "25", ",", "lr", "=", "0.5", ",", "dim", "=", "100", ",", "loss", "=", "'ova'", ")", "\n", "model_fn", "=", "'%s.fasttext.%s.base-100d.model.bin'", "%", "(", "dataset_id", ",", "amb_word", ")", "\n", "\n", "", "model", ".", "save_model", "(", "'data/fasttext_models/'", "+", "model_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.create_ftx_models.test_model": [[51, 81], ["logging.info", "fasttext.load_model", "open", "enumerate", "open", "instance_str.strip().split", "create_ftx_models.rem_prefix", "fasttext.load_model.predict", "results.append", "word_results_f.write", "instance_str.strip", "create_ftx_models.rem_prefix", "zip", "json.dumps", "sense.split"], "function", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.ftx_baseline.rem_prefix", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.ftx_baseline.rem_prefix"], ["", "", "def", "test_model", "(", "amb_word", ",", "model_id", ",", "dataset_id", ")", ":", "\n", "\n", "    ", "model_path", "=", "'data/fasttext_models/%s.fasttext.%s.%s.model.bin'", "%", "(", "dataset_id", ",", "amb_word", ",", "model_id", ")", "\n", "test_path", "=", "'data/fasttext_data/%s.fasttext.%s.test'", "%", "(", "dataset_id", ",", "amb_word", ")", "\n", "logging", ".", "info", "(", "'Processing %s with %s ...'", "%", "(", "amb_word", ",", "model_path", ")", ")", "\n", "\n", "model", "=", "fasttext", ".", "load_model", "(", "model_path", ")", "\n", "\n", "results", "=", "[", "]", "\n", "with", "open", "(", "test_path", ")", "as", "test_f", ":", "\n", "        ", "for", "inst_idx", ",", "instance_str", "in", "enumerate", "(", "test_f", ")", ":", "\n", "\n", "            ", "elems", "=", "instance_str", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "gold_label", ",", "inst_tokens", "=", "elems", "[", "0", "]", ",", "elems", "[", "1", ":", "]", "\n", "gold_sense", "=", "rem_prefix", "(", "gold_label", ")", "\n", "\n", "matches", "=", "model", ".", "predict", "(", "' '", ".", "join", "(", "inst_tokens", ")", ",", "k", "=", "-", "1", ")", "\n", "matches", "=", "[", "(", "rem_prefix", "(", "label", ")", ",", "score", ")", "for", "label", ",", "score", "in", "zip", "(", "matches", "[", "0", "]", ",", "matches", "[", "1", "]", ")", "]", "\n", "\n", "# filter matches for word", "\n", "matches", "=", "[", "(", "sense", ",", "score", ")", "for", "sense", ",", "score", "in", "matches", "if", "sense", ".", "split", "(", "'_'", ")", "[", "0", "]", "==", "amb_word", "]", "\n", "results", ".", "append", "(", "(", "inst_idx", ",", "inst_tokens", ",", "gold_sense", ",", "matches", ")", ")", "\n", "\n", "# store full results for further analysis", "\n", "", "", "with", "open", "(", "'results/%s/fasttext/%s/%s.jsonl'", "%", "(", "dataset_id", ",", "model_id", ",", "amb_word", ")", ",", "'w'", ")", "as", "word_results_f", ":", "\n", "        ", "for", "inst_idx", ",", "inst_tokens", ",", "gold_sense", ",", "matches", "in", "results", ":", "\n", "            ", "jsonl_results", "=", "{", "'idx'", ":", "inst_idx", ",", "'matches'", ":", "matches", ",", "'gold'", ":", "gold_sense", ",", "'tokens'", ":", "inst_tokens", "}", "\n", "word_results_f", ".", "write", "(", "'%s\\n'", "%", "json", ".", "dumps", "(", "jsonl_results", ",", "sort_keys", "=", "True", ")", ")", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.__init__": [[12, 19], ["wn_utils.WN_Utils.load_sk2syn", "wn_utils.WN_Utils.load_csi"], "methods", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.load_sk2syn", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.load_csi"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "map_sk2syn", "=", "{", "}", "\n", "self", ".", "map_syn2csi", "=", "{", "}", "\n", "\n", "self", ".", "load_sk2syn", "(", ")", "\n", "self", ".", "load_csi", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.load_sk2syn": [[20, 24], ["nltk.corpus.wordnet.all_synsets", "synset.lemmas", "lemma.key"], "methods", ["None"], ["", "def", "load_sk2syn", "(", "self", ")", ":", "\n", "        ", "for", "synset", "in", "wn", ".", "all_synsets", "(", ")", ":", "\n", "            ", "for", "lemma", "in", "synset", ".", "lemmas", "(", ")", ":", "\n", "                ", "self", ".", "map_sk2syn", "[", "lemma", ".", "key", "(", ")", "]", "=", "synset", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.load_csi": [[25, 33], ["open", "line.strip().split", "wn_offset.lstrip.lstrip.lstrip", "nltk.corpus.wordnet.of2ss", "line.strip", "nltk.corpus.wordnet.of2ss.name"], "methods", ["None"], ["", "", "", "def", "load_csi", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "'data/csi_data/wn_synset2csi.txt'", ")", "as", "csi_map_f", ":", "\n", "            ", "for", "line", "in", "csi_map_f", ":", "\n", "                ", "elems", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "wn_offset", ",", "csi_labels", "=", "elems", "[", "0", "]", ",", "elems", "[", "1", ":", "]", "\n", "wn_offset", "=", "wn_offset", ".", "lstrip", "(", "'wn:'", ")", "\n", "syn", "=", "wn", ".", "of2ss", "(", "wn_offset", ")", "\n", "self", ".", "map_syn2csi", "[", "syn", ".", "name", "(", ")", "]", "=", "csi_labels", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.syn2sks": [[34, 39], ["functools.lru_cache", "isinstance", "list", "nltk.corpus.wordnet.synset", "set", "lemma.key", "nltk.corpus.wordnet.synset.lemmas"], "methods", ["None"], ["", "", "", "@", "lru_cache", "(", ")", "\n", "def", "syn2sks", "(", "self", ",", "synset", ")", ":", "\n", "        ", "if", "isinstance", "(", "synset", ",", "str", ")", ":", "\n", "            ", "synset", "=", "wn", ".", "synset", "(", "synset", ")", "\n", "", "return", "list", "(", "set", "(", "[", "lemma", ".", "key", "(", ")", "for", "lemma", "in", "synset", ".", "lemmas", "(", ")", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.syn2pos": [[40, 45], ["functools.lru_cache", "isinstance", "nltk.corpus.wordnet.synset.pos", "nltk.corpus.wordnet.synset"], "methods", ["None"], ["", "@", "lru_cache", "(", ")", "\n", "def", "syn2pos", "(", "self", ",", "synset", ")", ":", "\n", "        ", "if", "isinstance", "(", "synset", ",", "str", ")", ":", "\n", "            ", "synset", "=", "wn", ".", "synset", "(", "synset", ")", "\n", "", "return", "synset", ".", "pos", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.syn2lemmas": [[46, 55], ["functools.lru_cache", "isinstance", "nltk.corpus.wordnet.synset.lemma_names", "nltk.corpus.wordnet.synset", "nltk.corpus.wordnet.synset.pos"], "methods", ["None"], ["", "@", "lru_cache", "(", ")", "\n", "def", "syn2lemmas", "(", "self", ",", "synset", ",", "include_pos", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "synset", ",", "str", ")", ":", "\n", "            ", "synset", "=", "wn", ".", "synset", "(", "synset", ")", "\n", "\n", "", "lemmas", "=", "synset", ".", "lemma_names", "(", ")", "\n", "if", "include_pos", ":", "\n", "            ", "lemmas", "=", "[", "'%s|%s'", "%", "(", "lem", ",", "synset", ".", "pos", "(", ")", ")", "for", "lem", "in", "lemmas", "]", "\n", "", "return", "lemmas", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.syn2lexname": [[56, 62], ["functools.lru_cache", "isinstance", "nltk.corpus.wordnet.synset.lexname", "nltk.corpus.wordnet.synset"], "methods", ["None"], ["", "@", "lru_cache", "(", ")", "\n", "def", "syn2lexname", "(", "self", ",", "synset", ")", ":", "\n", "        ", "if", "isinstance", "(", "synset", ",", "str", ")", ":", "\n", "            ", "synset", "=", "wn", ".", "synset", "(", "synset", ")", "\n", "\n", "", "return", "synset", ".", "lexname", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.syn2offset": [[63, 66], ["functools.lru_cache", "synset.offset"], "methods", ["None"], ["", "@", "lru_cache", "(", ")", "\n", "def", "syn2offset", "(", "self", ",", "synset", ")", ":", "\n", "        ", "return", "synset", ".", "offset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.syn2csi": [[67, 73], ["functools.lru_cache", "synset.name"], "methods", ["None"], ["", "@", "lru_cache", "(", ")", "\n", "def", "syn2csi", "(", "self", ",", "synset", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "self", ".", "map_syn2csi", "[", "synset", ".", "name", "(", ")", "]", "\n", "", "except", "KeyError", ":", "# synset not covered", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.sk2syn": [[74, 77], ["functools.lru_cache"], "methods", ["None"], ["", "", "@", "lru_cache", "(", ")", "\n", "def", "sk2syn", "(", "self", ",", "sk", ")", ":", "\n", "        ", "return", "self", ".", "map_sk2syn", "[", "sk", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.sk2lemma": [[78, 85], ["functools.lru_cache", "sk.split", "lemma_name.replace.replace.replace"], "methods", ["None"], ["", "@", "lru_cache", "(", ")", "\n", "def", "sk2lemma", "(", "self", ",", "sk", ",", "use_ws", "=", "False", ")", ":", "\n", "# lemma_name = wn.lemma_from_key(sk).name()  # alt?s", "\n", "        ", "lemma_name", "=", "sk", ".", "split", "(", "'%'", ")", "[", "0", "]", "\n", "if", "use_ws", ":", "\n", "            ", "lemma_name", "=", "lemma_name", ".", "replace", "(", "'_'", ",", "' '", ")", "\n", "", "return", "lemma_name", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.sk2pos": [[86, 92], ["functools.lru_cache", "int", "[].split", "sk.split"], "methods", ["None"], ["", "@", "lru_cache", "(", ")", "\n", "def", "sk2pos", "(", "self", ",", "sk", ")", ":", "\n", "# merging ADJ with ADJ_SAT", "\n", "        ", "sk_types_map", "=", "{", "1", ":", "'n'", ",", "2", ":", "'v'", ",", "3", ":", "'a'", ",", "4", ":", "'r'", ",", "5", ":", "'a'", "}", "\n", "sk_type", "=", "int", "(", "sk", ".", "split", "(", "'%'", ")", "[", "1", "]", ".", "split", "(", "':'", ")", "[", "0", "]", ")", "\n", "return", "sk_types_map", "[", "sk_type", "]", "\n", "# syn = self.sk2syn(sk)", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.sk2lexname": [[95, 99], ["functools.lru_cache", "wn_utils.WN_Utils.sk2syn", "wn_utils.WN_Utils.syn2lexname"], "methods", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.sk2syn", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.syn2lexname"], ["", "@", "lru_cache", "(", ")", "\n", "def", "sk2lexname", "(", "self", ",", "sk", ")", ":", "\n", "        ", "syn", "=", "self", ".", "sk2syn", "(", "sk", ")", "\n", "return", "self", ".", "syn2lexname", "(", "syn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.sk2csi": [[100, 104], ["functools.lru_cache", "wn_utils.WN_Utils.sk2syn", "wn_utils.WN_Utils.syn2csi"], "methods", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.sk2syn", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.syn2csi"], ["", "@", "lru_cache", "(", ")", "\n", "def", "sk2csi", "(", "self", ",", "sk", ")", ":", "\n", "        ", "syn", "=", "self", ".", "sk2syn", "(", "sk", ")", "\n", "return", "self", ".", "syn2csi", "(", "syn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.lemma2syns": [[105, 123], ["functools.lru_cache", "lemma.replace.replace.replace", "lemma.replace.replace.split", "nltk.corpus.wordnet.synsets", "len", "wn_utils.NoSynset", "nltk.corpus.wordnet.synsets", "nltk.corpus.wordnet.synsets"], "methods", ["None"], ["", "@", "lru_cache", "(", ")", "\n", "def", "lemma2syns", "(", "self", ",", "lemma", ",", "pos", "=", "None", ")", ":", "\n", "\n", "        ", "if", "'|'", "in", "lemma", ":", "# custom format, overrides arg", "\n", "            ", "lemma", ",", "pos", "=", "lemma", ".", "split", "(", "'|'", ")", "\n", "\n", "", "lemma", "=", "lemma", ".", "replace", "(", "' '", ",", "'_'", ")", "\n", "\n", "# merging ADJ with ADJ_SAT", "\n", "if", "pos", "in", "[", "'a'", ",", "'s'", "]", ":", "\n", "            ", "syns", "=", "wn", ".", "synsets", "(", "lemma", ",", "pos", "=", "'a'", ")", "+", "wn", ".", "synsets", "(", "lemma", ",", "pos", "=", "'s'", ")", "\n", "", "else", ":", "\n", "            ", "syns", "=", "wn", ".", "synsets", "(", "lemma", ",", "pos", "=", "pos", ")", "\n", "\n", "", "if", "len", "(", "syns", ")", ">", "0", ":", "\n", "            ", "return", "syns", "\n", "", "else", ":", "\n", "            ", "raise", "NoSynset", "(", "'No synset for lemma=\\'%s\\', pos=\\'%s\\'.'", "%", "(", "lemma", ",", "pos", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.lemma2sks": [[124, 138], ["functools.lru_cache", "set", "lemma.replace.replace.replace", "wn_utils.WN_Utils.lemma2syns", "list", "lemma.replace.replace.split", "wn_utils.WN_Utils.syn2sks", "wn_utils.WN_Utils.sk2lemma", "set.add"], "methods", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.lemma2syns", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.syn2sks", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.sk2lemma"], ["", "", "@", "lru_cache", "(", ")", "\n", "def", "lemma2sks", "(", "self", ",", "lemma", ",", "pos", "=", "None", ")", ":", "\n", "        ", "sks", "=", "set", "(", ")", "\n", "\n", "if", "'|'", "in", "lemma", ":", "# custom format, overrides arg", "\n", "            ", "lemma", ",", "pos", "=", "lemma", ".", "split", "(", "'|'", ")", "\n", "", "lemma", "=", "lemma", ".", "replace", "(", "' '", ",", "'_'", ")", "\n", "\n", "for", "syn", "in", "self", ".", "lemma2syns", "(", "lemma", ",", "pos", "=", "pos", ")", ":", "\n", "            ", "for", "sk", "in", "self", ".", "syn2sks", "(", "syn", ")", ":", "\n", "                ", "if", "self", ".", "sk2lemma", "(", "sk", ",", "use_ws", "=", "False", ")", "==", "lemma", ":", "\n", "                    ", "sks", ".", "add", "(", "sk", ")", "\n", "\n", "", "", "", "return", "list", "(", "sks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.lemma2lexnames": [[139, 145], ["functools.lru_cache", "set", "wn_utils.WN_Utils.lemma2syns", "list", "set.add", "wn_utils.WN_Utils.syn2lexname"], "methods", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.lemma2syns", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.syn2lexname"], ["", "@", "lru_cache", "(", ")", "\n", "def", "lemma2lexnames", "(", "self", ",", "lemma", ",", "pos", "=", "None", ")", ":", "\n", "        ", "lexnames", "=", "set", "(", ")", "\n", "for", "syn", "in", "self", ".", "lemma2syns", "(", "lemma", ",", "pos", "=", "pos", ")", ":", "\n", "            ", "lexnames", ".", "add", "(", "self", ".", "syn2lexname", "(", "syn", ")", ")", "\n", "", "return", "list", "(", "lexnames", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.lemma2csis": [[146, 152], ["functools.lru_cache", "set", "wn_utils.WN_Utils.lemma2syns", "list", "set.add", "wn_utils.WN_Utils.syn2csi"], "methods", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.lemma2syns", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.syn2csi"], ["", "@", "lru_cache", "(", ")", "\n", "def", "lemma2csis", "(", "self", ",", "lemma", ",", "pos", "=", "None", ")", ":", "\n", "        ", "csis", "=", "set", "(", ")", "\n", "for", "syn", "in", "self", ".", "lemma2syns", "(", "lemma", ",", "pos", "=", "pos", ")", ":", "\n", "            ", "csis", ".", "add", "(", "self", ".", "syn2csi", "(", "syn", ")", ")", "\n", "", "return", "list", "(", "csis", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.synid2syn": [[153, 156], ["functools.lru_cache", "nltk.corpus.wordnet.of2ss"], "methods", ["None"], ["", "@", "lru_cache", "(", ")", "\n", "def", "synid2syn", "(", "self", ",", "synid", ")", ":", "\n", "        ", "return", "wn", ".", "of2ss", "(", "synid", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.synname2syn": [[157, 160], ["functools.lru_cache", "nltk.corpus.wordnet.synset"], "methods", ["None"], ["", "@", "lru_cache", "(", ")", "\n", "def", "synname2syn", "(", "self", ",", "synname", ")", ":", "\n", "        ", "return", "wn", ".", "synset", "(", "synname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.get_all_syns": [[161, 163], ["list", "nltk.corpus.wordnet.all_synsets"], "methods", ["None"], ["", "def", "get_all_syns", "(", "self", ")", ":", "\n", "        ", "return", "list", "(", "wn", ".", "all_synsets", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.get_all_lemmas": [[164, 169], ["list", "nltk.corpus.wordnet.all_lemma_names", "lemma.replace"], "methods", ["None"], ["", "def", "get_all_lemmas", "(", "self", ",", "replace_ws", "=", "True", ")", ":", "\n", "        ", "all_wn_lemmas", "=", "list", "(", "wn", ".", "all_lemma_names", "(", ")", ")", "\n", "if", "replace_ws", ":", "\n", "            ", "all_wn_lemmas", "=", "[", "lemma", ".", "replace", "(", "'_'", ",", "' '", ")", "for", "lemma", "in", "all_wn_lemmas", "]", "\n", "", "return", "all_wn_lemmas", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.get_all_sks": [[170, 173], ["wn_utils.WN_Utils.map_sk2syn.keys"], "methods", ["None"], ["", "def", "get_all_sks", "(", "self", ")", ":", "\n", "# return list(self.map_sk2syn.keys())", "\n", "        ", "return", "self", ".", "map_sk2syn", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.get_all_lexnames": [[174, 179], ["set", "wn_utils.WN_Utils.get_all_syns", "list", "set.add", "wn_utils.WN_Utils.syn2lexname"], "methods", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.get_all_syns", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.syn2lexname"], ["", "def", "get_all_lexnames", "(", "self", ")", ":", "\n", "        ", "lexnames", "=", "set", "(", ")", "\n", "for", "syn", "in", "self", ".", "get_all_syns", "(", ")", ":", "\n", "            ", "lexnames", ".", "add", "(", "self", ".", "syn2lexname", "(", "syn", ")", ")", "\n", "", "return", "list", "(", "lexnames", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.get_all_csis": [[180, 183], ["None"], "methods", ["None"], ["", "def", "get_all_csis", "(", "self", ")", ":", "\n", "# TO-DO", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.wn_utils.WN_Utils.convert_postag": [[184, 194], ["postags_map.values"], "methods", ["None"], ["", "def", "convert_postag", "(", "self", ",", "postag", ")", ":", "\n", "# merges ADJ with ADJ_SAT", "\n", "        ", "postags_map", "=", "{", "'NOUN'", ":", "'n'", ",", "'VERB'", ":", "'v'", ",", "'ADJ'", ":", "'a'", ",", "'ADV'", ":", "'r'", ",", "'ADJ_SAT'", ":", "'a'", "}", "\n", "if", "postag", "in", "postags_map", ".", "values", "(", ")", ":", "\n", "            ", "return", "postag", "\n", "", "elif", "postag", "in", "postags_map", ":", "\n", "            ", "return", "postags_map", "[", "postag", "]", "\n", "", "else", ":", "\n", "# raise exception", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.ftx_baseline.rem_prefix": [[19, 21], ["label.replace"], "function", ["None"], ["def", "rem_prefix", "(", "label", ")", ":", "\n", "    ", "return", "label", ".", "replace", "(", "'__label__'", ",", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.ftx_baseline.convert_dataset": [[23, 30], ["open", "coarsewsd20_reader.load_instances", "word_split_f.write"], "function", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.coarsewsd20_reader.load_instances"], ["", "def", "convert_dataset", "(", "dataset_id", ")", ":", "\n", "    ", "for", "split", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "        ", "for", "amb_word", "in", "ambiguous_words", ":", "\n", "            ", "with", "open", "(", "'data/fasttext_data/%s.fasttext.%s.%s'", "%", "(", "dataset_id", ",", "amb_word", ",", "split", ")", ",", "'w'", ")", "as", "word_split_f", ":", "\n", "                ", "for", "inst", "in", "load_instances", "(", "amb_word", ",", "split", "=", "split", ",", "setname", "=", "dataset_id", ")", ":", "\n", "                    ", "inst_str", "=", "'__label__%s %s'", "%", "(", "inst", "[", "'class'", "]", ",", "' '", ".", "join", "(", "inst", "[", "'tokens'", "]", ")", ")", "\n", "word_split_f", ".", "write", "(", "'%s\\n'", "%", "inst_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.ftx_baseline.create_models": [[32, 49], ["logging.info", "fasttext.train_supervised.save_model", "fasttext.train_supervised", "fasttext.train_supervised"], "function", ["None"], ["", "", "", "", "", "def", "create_models", "(", "use_pretrained", "=", "False", ")", ":", "\n", "\n", "    ", "for", "amb_word", "in", "ambiguous_words", ":", "\n", "        ", "logging", ".", "info", "(", "'Generating model for \\'%s\\' ...'", "%", "amb_word", ")", "\n", "train_path", "=", "'data/fasttext_data/%s.fasttext.%s.train'", "%", "(", "dataset_id", ",", "amb_word", ")", "\n", "if", "use_pretrained", ":", "\n", "            ", "model", "=", "fasttext", ".", "train_supervised", "(", "input", "=", "train_path", ",", "\n", "pretrainedVectors", "=", "'external/fastText-0.9.1/crawl-300d-2M.vec'", ",", "\n", "epoch", "=", "25", ",", "lr", "=", "0.5", ",", "dim", "=", "300", ",", "loss", "=", "'ova'", ")", "\n", "model_fn", "=", "'%s.fasttext.%s.crawl-300d-2M.model.bin'", "%", "(", "dataset_id", ",", "amb_word", ")", "\n", "\n", "", "else", ":", "\n", "            ", "model", "=", "fasttext", ".", "train_supervised", "(", "input", "=", "train_path", ",", "\n", "epoch", "=", "25", ",", "lr", "=", "0.5", ",", "dim", "=", "100", ",", "loss", "=", "'ova'", ")", "\n", "model_fn", "=", "'%s.fasttext.%s.base-100d.model.bin'", "%", "(", "dataset_id", ",", "amb_word", ")", "\n", "\n", "", "model", ".", "save_model", "(", "'data/fasttext_models/'", "+", "model_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.ftx_baseline.test_model": [[51, 81], ["logging.info", "fasttext.load_model", "open", "enumerate", "open", "instance_str.strip().split", "ftx_baseline.rem_prefix", "fasttext.load_model.predict", "results.append", "word_results_f.write", "instance_str.strip", "ftx_baseline.rem_prefix", "zip", "json.dumps", "sense.split"], "function", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.ftx_baseline.rem_prefix", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.ftx_baseline.rem_prefix"], ["", "", "def", "test_model", "(", "amb_word", ",", "model_id", ",", "dataset_id", ")", ":", "\n", "\n", "    ", "model_path", "=", "'data/fasttext_models/%s.fasttext.%s.%s.model.bin'", "%", "(", "dataset_id", ",", "amb_word", ",", "model_id", ")", "\n", "test_path", "=", "'data/fasttext_data/%s.fasttext.%s.test'", "%", "(", "dataset_id", ",", "amb_word", ")", "\n", "logging", ".", "info", "(", "'Processing %s with %s ...'", "%", "(", "amb_word", ",", "model_path", ")", ")", "\n", "\n", "model", "=", "fasttext", ".", "load_model", "(", "model_path", ")", "\n", "\n", "results", "=", "[", "]", "\n", "with", "open", "(", "test_path", ")", "as", "test_f", ":", "\n", "        ", "for", "inst_idx", ",", "instance_str", "in", "enumerate", "(", "test_f", ")", ":", "\n", "\n", "            ", "elems", "=", "instance_str", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "gold_label", ",", "inst_tokens", "=", "elems", "[", "0", "]", ",", "elems", "[", "1", ":", "]", "\n", "gold_sense", "=", "rem_prefix", "(", "gold_label", ")", "\n", "\n", "matches", "=", "model", ".", "predict", "(", "' '", ".", "join", "(", "inst_tokens", ")", ",", "k", "=", "-", "1", ")", "\n", "matches", "=", "[", "(", "rem_prefix", "(", "label", ")", ",", "score", ")", "for", "label", ",", "score", "in", "zip", "(", "matches", "[", "0", "]", ",", "matches", "[", "1", "]", ")", "]", "\n", "\n", "# filter matches for word", "\n", "matches", "=", "[", "(", "sense", ",", "score", ")", "for", "sense", ",", "score", "in", "matches", "if", "sense", ".", "split", "(", "'_'", ")", "[", "0", "]", "==", "amb_word", "]", "\n", "results", ".", "append", "(", "(", "inst_idx", ",", "inst_tokens", ",", "gold_sense", ",", "matches", ")", ")", "\n", "\n", "# store full results for further analysis", "\n", "", "", "with", "open", "(", "'results/%s/fasttext/%s/%s.jsonl'", "%", "(", "dataset_id", ",", "model_id", ",", "amb_word", ")", ",", "'w'", ")", "as", "word_results_f", ":", "\n", "        ", "for", "inst_idx", ",", "inst_tokens", ",", "gold_sense", ",", "matches", "in", "results", ":", "\n", "            ", "jsonl_results", "=", "{", "'idx'", ":", "inst_idx", ",", "'matches'", ":", "matches", ",", "'gold'", ":", "gold_sense", ",", "'tokens'", ":", "inst_tokens", "}", "\n", "word_results_f", ".", "write", "(", "'%s\\n'", "%", "json", ".", "dumps", "(", "jsonl_results", ",", "sort_keys", "=", "True", ")", ")", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.coarsewsd20_reader.load_coarse_senses": [[5, 12], ["collections.defaultdict", "dict", "open", "line.strip().split", "senses[].append", "line.strip"], "function", ["None"], ["def", "load_coarse_senses", "(", ")", ":", "\n", "    ", "senses", "=", "defaultdict", "(", "list", ")", "\n", "with", "open", "(", "'data/senses.tsv'", ")", "as", "senses_f", ":", "\n", "        ", "for", "line", "in", "senses_f", ":", "\n", "            ", "amb_word", ",", "sense", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "senses", "[", "amb_word", "]", ".", "append", "(", "sense", ")", "\n", "", "", "return", "dict", "(", "senses", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.coarsewsd20_reader.get_word_classes": [[18, 24], ["open", "json.load"], "function", ["None"], ["def", "get_word_classes", "(", "word", ",", "setname", ")", ":", "\n", "\n", "    ", "with", "open", "(", "'data/%s/%s/classes_map.txt'", "%", "(", "setname", ",", "word", ")", ")", "as", "classes_json_f", ":", "\n", "        ", "word_classes", "=", "json", ".", "load", "(", "classes_json_f", ")", "\n", "\n", "", "return", "word_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.coarsewsd20_reader.sense2word": [[26, 28], ["sense.split"], "function", ["None"], ["", "def", "sense2word", "(", "sense", ")", ":", "\n", "    ", "return", "sense", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.coarsewsd20_reader.get_sk_mappings": [[30, 41], ["open", "enumerate", "line.strip().split", "line.strip"], "function", ["None"], ["", "def", "get_sk_mappings", "(", ")", ":", "\n", "    ", "sk_mappings", "=", "{", "}", "\n", "\n", "with", "open", "(", "'data/wn_mappings.tsv'", ")", "as", "f", ":", "\n", "        ", "for", "line_idx", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "            ", "if", "line_idx", "==", "0", ":", "\n", "                ", "continue", "\n", "", "word", ",", "coarse_sense", ",", "syn_offset", ",", "syn_name", ",", "sk", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "sk_mappings", "[", "sk", "]", "=", "coarse_sense", "\n", "\n", "", "", "return", "sk_mappings", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.coarsewsd20_reader.load_instances": [[43, 71], ["coarsewsd20_reader.get_word_classes", "open", "open", "enumerate", "line.split", "int", "tokens.split.split", "instances.append", "line.strip", "sorted", "list", "get_word_classes.keys"], "function", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.coarsewsd20_reader.get_word_classes"], ["", "def", "load_instances", "(", "word", ",", "split", ",", "setname", "=", "'CoarseWSD-20'", ",", "mode", "=", "'regular'", ")", ":", "\n", "    ", "instances", "=", "[", "]", "\n", "\n", "with", "open", "(", "'data/%s/%s/%s.data.txt'", "%", "(", "setname", ",", "word", ",", "split", ")", ")", "as", "split_data_f", ":", "\n", "        ", "for", "line", "in", "split_data_f", ":", "\n", "            ", "word_idx", ",", "tokens", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "word_idx", "=", "int", "(", "word_idx", ")", "\n", "tokens", "=", "tokens", ".", "split", "(", ")", "\n", "\n", "instances", ".", "append", "(", "{", "'tokens'", ":", "tokens", ",", "'idx'", ":", "word_idx", ",", "'class'", ":", "None", "}", ")", "\n", "\n", "", "", "word_classes", "=", "get_word_classes", "(", "word", ",", "setname", ")", "\n", "\n", "mfs_class", "=", "word_classes", "[", "'0'", "]", "\n", "lfs_class", "=", "word_classes", "[", "sorted", "(", "list", "(", "word_classes", ".", "keys", "(", ")", ")", ")", "[", "-", "1", "]", "]", "\n", "\n", "with", "open", "(", "'data/%s/%s/%s.gold.txt'", "%", "(", "setname", ",", "word", ",", "split", ")", ")", "as", "split_gold_f", ":", "\n", "        ", "for", "line_idx", ",", "line", "in", "enumerate", "(", "split_gold_f", ")", ":", "\n", "            ", "line_class", "=", "line", ".", "strip", "(", ")", "\n", "\n", "instances", "[", "line_idx", "]", "[", "'class'", "]", "=", "word_classes", "[", "line_class", "]", "\n", "\n", "", "", "if", "mode", "==", "'mfs'", ":", "\n", "        ", "instances", "=", "[", "inst", "for", "inst", "in", "instances", "if", "inst", "[", "'class'", "]", "==", "mfs_class", "]", "\n", "", "elif", "mode", "==", "'lfs'", ":", "\n", "        ", "instances", "=", "[", "inst", "for", "inst", "in", "instances", "if", "inst", "[", "'class'", "]", "==", "lfs_class", "]", "\n", "\n", "", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.coarsewsd20_reader.load_instances_ood": [[73, 82], ["collections.defaultdict", "open", "line.strip().split", "instances[].append", "line.strip", "tokens_str.split", "int"], "function", ["None"], ["", "def", "load_instances_ood", "(", ")", ":", "\n", "    ", "instances", "=", "defaultdict", "(", "list", ")", "\n", "\n", "with", "open", "(", "'data/CoarseWSD-20.outofdomain.tsv'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "word", ",", "sense", ",", "idx", ",", "tokens_str", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "instances", "[", "word", "]", ".", "append", "(", "{", "'tokens'", ":", "tokens_str", ".", "split", "(", "' '", ")", ",", "'idx'", ":", "int", "(", "idx", ")", ",", "'class'", ":", "sense", "}", ")", "\n", "\n", "", "", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.__init__": [[13, 19], ["nlm_encoder.TransformerEncoder.load_nlm"], "methods", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.load_nlm"], ["    ", "def", "__init__", "(", "self", ",", "nlm_config", ")", ":", "\n", "        ", "self", ".", "nlm_config", "=", "nlm_config", "\n", "self", ".", "nlm_model", "=", "None", "\n", "self", ".", "nlm_tokenizer", "=", "None", "\n", "\n", "self", ".", "load_nlm", "(", "nlm_config", "[", "'model_name_or_path'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.load_nlm": [[21, 37], ["model_name_or_path.startswith", "nlm_encoder.TransformerEncoder.nlm_model.eval", "nlm_encoder.TransformerEncoder.nlm_model.to", "transformers.BertModel.from_pretrained", "transformers.BertTokenizer.from_pretrained", "BaseException", "nlm_encoder.TransformerEncoder.nlm_tokenizer.encode", "nlm_encoder.TransformerEncoder.nlm_tokenizer.encode", "nlm_encoder.TransformerEncoder.nlm_tokenizer.encode"], "methods", ["None"], ["", "def", "load_nlm", "(", "self", ",", "model_name_or_path", ")", ":", "\n", "\n", "        ", "if", "model_name_or_path", ".", "startswith", "(", "'bert-'", ")", ":", "\n", "            ", "self", ".", "nlm_model", "=", "BertModel", ".", "from_pretrained", "(", "model_name_or_path", ",", "output_hidden_states", "=", "True", ")", "\n", "self", ".", "nlm_tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "model_name_or_path", ")", "\n", "\n", "self", ".", "cls_encoding", "=", "self", ".", "nlm_tokenizer", ".", "encode", "(", "self", ".", "nlm_tokenizer", ".", "cls_token", ",", "add_special_tokens", "=", "False", ")", "[", "0", "]", "\n", "self", ".", "sep_encoding", "=", "self", ".", "nlm_tokenizer", ".", "encode", "(", "self", ".", "nlm_tokenizer", ".", "sep_token", ",", "add_special_tokens", "=", "False", ")", "[", "0", "]", "\n", "self", ".", "pad_encoding", "=", "self", ".", "nlm_tokenizer", ".", "encode", "(", "self", ".", "nlm_tokenizer", ".", "pad_token", ",", "add_special_tokens", "=", "False", ")", "[", "0", "]", "\n", "\n", "", "else", ":", "\n", "# TO-DO: this module only supports BERT", "\n", "            ", "raise", "(", "BaseException", "(", "'Invalid model_name - %s'", "%", "model_name_or_path", ")", ")", "\n", "\n", "", "self", ".", "nlm_model", ".", "eval", "(", ")", "\n", "self", ".", "nlm_model", ".", "to", "(", "'cuda'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.encode_token": [[39, 42], ["nlm_encoder.TransformerEncoder.nlm_tokenizer.encode"], "methods", ["None"], ["", "def", "encode_token", "(", "self", ",", "token", ")", ":", "\n", "# returns list of subtokens", "\n", "        ", "return", "self", ".", "nlm_tokenizer", ".", "encode", "(", "token", ",", "add_special_tokens", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.get_encodings": [[44, 46], ["nlm_encoder.TransformerEncoder.encode_token"], "methods", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.encode_token"], ["", "def", "get_encodings", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "return", "[", "self", ".", "encode_token", "(", "t", ")", "for", "t", "in", "tokens", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.flatten_encodings": [[48, 50], ["sum"], "methods", ["None"], ["", "def", "flatten_encodings", "(", "self", ",", "encodings", ")", ":", "\n", "        ", "return", "sum", "(", "encodings", ",", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.add_special_encodings": [[52, 62], ["model_name_or_path.startswith", "BaseException"], "methods", ["None"], ["", "def", "add_special_encodings", "(", "self", ",", "encodings", ")", ":", "\n", "\n", "        ", "model_name_or_path", "=", "self", ".", "nlm_config", "[", "'model_name_or_path'", "]", "\n", "\n", "if", "model_name_or_path", ".", "startswith", "(", "'bert-'", ")", ":", "\n", "            ", "return", "[", "self", ".", "cls_encoding", "]", "+", "encodings", "+", "[", "self", ".", "sep_encoding", "]", "\n", "\n", "", "else", ":", "\n", "# TO-DO: this module only supports BERT", "\n", "            ", "raise", "(", "BaseException", "(", "'Invalid model_name - %s'", "%", "model_name_or_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.add_padding_encodings": [[64, 67], ["len"], "methods", ["None"], ["", "", "def", "add_padding_encodings", "(", "self", ",", "encodings", ",", "max_len", ")", ":", "\n", "        ", "encodings", "+=", "[", "self", ".", "pad_encoding", "]", "*", "(", "max_len", "-", "len", "(", "encodings", ")", ")", "\n", "return", "encodings", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.get_attention_mask": [[69, 77], ["att_mask.append", "att_mask.append"], "methods", ["None"], ["", "def", "get_attention_mask", "(", "self", ",", "encodings", ")", ":", "\n", "        ", "att_mask", "=", "[", "]", "\n", "for", "enc", "in", "encodings", ":", "\n", "            ", "if", "enc", "==", "self", ".", "pad_encoding", ":", "\n", "                ", "att_mask", ".", "append", "(", "0", ")", "\n", "", "else", ":", "\n", "                ", "att_mask", ".", "append", "(", "1", ")", "\n", "", "", "return", "att_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.merge_subword_embeddings": [[79, 108], ["zip", "torch.zeros().to.detach().cpu().numpy", "torch.zeros().to", "tok_embeddings.append", "tok_embeddings.append", "len", "BaseException", "torch.zeros().to.detach().cpu", "torch.zeros", "torch.zeros().to.detach"], "methods", ["None"], ["", "def", "merge_subword_embeddings", "(", "self", ",", "tokens", ",", "encodings", ",", "embeddings", ",", "return_tokens", "=", "True", ")", ":", "\n", "# align and merge subword embeddings", "\n", "        ", "tok_embeddings", "=", "[", "]", "\n", "encoding_idx", "=", "0", "\n", "for", "tok", ",", "tok_encodings", "in", "zip", "(", "tokens", ",", "encodings", ")", ":", "\n", "\n", "            ", "if", "self", ".", "nlm_config", "[", "'subword_op'", "]", "==", "'mean'", ":", "\n", "                ", "tok_embedding", "=", "th", ".", "zeros", "(", "embeddings", ".", "shape", "[", "-", "1", "]", ")", ".", "to", "(", "'cuda'", ")", "\n", "for", "_", "in", "tok_encodings", ":", "\n", "                    ", "tok_embedding", "+=", "embeddings", "[", "encoding_idx", "]", "\n", "encoding_idx", "+=", "1", "\n", "", "tok_embedding", "=", "tok_embedding", "/", "len", "(", "tok_encodings", ")", "# avg of subword embs", "\n", "\n", "", "elif", "self", ".", "nlm_config", "[", "'subword_op'", "]", "==", "'first'", ":", "\n", "                ", "tok_embedding", "=", "embeddings", "[", "encoding_idx", "]", "\n", "for", "_", "in", "tok_encodings", ":", "\n", "                    ", "encoding_idx", "+=", "1", "# just move idx", "\n", "\n", "", "", "else", ":", "\n", "                ", "raise", "(", "BaseException", "(", "'Invalid subword_op - %s'", "%", "self", ".", "nlm_config", "[", "'subword_op'", "]", ")", ")", "\n", "\n", "", "tok_embedding", "=", "tok_embedding", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "if", "return_tokens", ":", "\n", "                ", "tok_embeddings", ".", "append", "(", "(", "tok", ",", "tok_embedding", ")", ")", "\n", "", "else", ":", "\n", "                ", "tok_embeddings", ".", "append", "(", "tok_embedding", ")", "\n", "\n", "", "", "return", "tok_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.get_num_features": [[110, 112], ["len", "nlm_encoder.TransformerEncoder.get_encodings"], "methods", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.get_encodings"], ["", "def", "get_num_features", "(", "self", ",", "tokens", ",", "n_special_toks", "=", "2", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "get_encodings", "(", "tokens", ")", ")", "+", "n_special_toks", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.get_num_subtokens": [[114, 116], ["len", "nlm_encoder.TransformerEncoder.get_encodings"], "methods", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.get_encodings"], ["", "def", "get_num_subtokens", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "get_encodings", "(", "tokens", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.get_token_embeddings_batch": [[118, 191], ["zip", "torch.tensor().to", "torch.tensor().to", "enumerate", "nlm_encoder.TransformerEncoder.get_encodings", "max", "nlm_encoder.TransformerEncoder.flatten_encodings", "nlm_encoder.TransformerEncoder.add_special_encodings", "nlm_encoder.TransformerEncoder.add_padding_encodings", "torch.tensor().to.append", "nlm_encoder.TransformerEncoder.get_attention_mask", "torch.tensor().to.append", "torch.no_grad", "nlm_encoder.TransformerEncoder.nlm_config[].startswith", "enumerate", "merged_batch_hidden_states.append", "range", "combined_batch_embeddings.append", "len", "len", "torch.tensor", "torch.tensor", "nlm_encoder.TransformerEncoder.nlm_model", "nlm_encoder.TransformerEncoder.nlm_model", "nlm_encoder.TransformerEncoder.merge_subword_embeddings", "merged_layer_hidden_states.append", "len", "range", "combined_sent_embeddings.append", "len", "len", "numpy.array.append", "len", "numpy.array", "nlm_encoder.TransformerEncoder.flatten_encodings", "numpy.array.sum"], "methods", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.get_encodings", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.flatten_encodings", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.add_special_encodings", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.add_padding_encodings", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.get_attention_mask", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.merge_subword_embeddings", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.flatten_encodings"], ["", "def", "get_token_embeddings_batch", "(", "self", ",", "batch_sent_tokens", ",", "return_tokens", "=", "True", ")", ":", "\n", "\n", "        ", "batch_sent_encodings", "=", "[", "self", ".", "get_encodings", "(", "sent_tokens", ")", "for", "sent_tokens", "in", "batch_sent_tokens", "]", "\n", "batch_max_len", "=", "max", "(", "[", "len", "(", "self", ".", "flatten_encodings", "(", "e", ")", ")", "for", "e", "in", "batch_sent_encodings", "]", ")", "+", "2", "\n", "\n", "# prepare nlm input", "\n", "input_ids", ",", "input_mask", "=", "[", "]", ",", "[", "]", "\n", "for", "sent_tokens", ",", "sent_encodings", "in", "zip", "(", "batch_sent_tokens", ",", "batch_sent_encodings", ")", ":", "\n", "\n", "            ", "sent_encodings", "=", "self", ".", "flatten_encodings", "(", "sent_encodings", ")", "\n", "sent_encodings", "=", "self", ".", "add_special_encodings", "(", "sent_encodings", ")", "\n", "sent_encodings", "=", "self", ".", "add_padding_encodings", "(", "sent_encodings", ",", "batch_max_len", ")", "\n", "input_ids", ".", "append", "(", "sent_encodings", ")", "\n", "\n", "sent_attention", "=", "self", ".", "get_attention_mask", "(", "sent_encodings", ")", "\n", "input_mask", ".", "append", "(", "sent_attention", ")", "\n", "\n", "assert", "len", "(", "sent_encodings", ")", "==", "len", "(", "sent_attention", ")", "\n", "\n", "\n", "", "input_ids", "=", "th", ".", "tensor", "(", "input_ids", ")", ".", "to", "(", "'cuda'", ")", "\n", "input_mask", "=", "th", ".", "tensor", "(", "input_mask", ")", ".", "to", "(", "'cuda'", ")", "\n", "with", "th", ".", "no_grad", "(", ")", ":", "\n", "\n", "            ", "if", "self", ".", "nlm_config", "[", "'model_name_or_path'", "]", ".", "startswith", "(", "'xlnet-'", ")", ":", "\n", "                ", "pooled", ",", "batch_hidden_states", "=", "self", ".", "nlm_model", "(", "input_ids", ",", "attention_mask", "=", "input_mask", ")", "\n", "last_layer", "=", "batch_hidden_states", "[", "-", "1", "]", "\n", "\n", "", "else", ":", "\n", "                ", "last_layer", ",", "pooled", ",", "batch_hidden_states", "=", "self", ".", "nlm_model", "(", "input_ids", ",", "attention_mask", "=", "input_mask", ")", "\n", "\n", "# select layers of interest", "\n", "", "", "sel_hidden_states", "=", "[", "batch_hidden_states", "[", "i", "]", "for", "i", "in", "self", ".", "nlm_config", "[", "'layers'", "]", "]", "\n", "\n", "# merge subword embeddings", "\n", "merged_batch_hidden_states", "=", "[", "]", "\n", "for", "layer_hidden_states", "in", "sel_hidden_states", ":", "\n", "            ", "merged_layer_hidden_states", "=", "[", "]", "\n", "for", "sent_idx", ",", "sent_embeddings", "in", "enumerate", "(", "layer_hidden_states", ")", ":", "\n", "                ", "sent_embeddings", "=", "sent_embeddings", "[", "1", ":", "-", "1", "]", "# ignoring special tokens", "\n", "\n", "sent_tokens", "=", "batch_sent_tokens", "[", "sent_idx", "]", "\n", "sent_encodings", "=", "batch_sent_encodings", "[", "sent_idx", "]", "\n", "\n", "sent_embeddings", "=", "self", ".", "merge_subword_embeddings", "(", "sent_tokens", ",", "sent_encodings", ",", "sent_embeddings", ",", "return_tokens", "=", "return_tokens", ")", "\n", "merged_layer_hidden_states", ".", "append", "(", "sent_embeddings", ")", "\n", "", "merged_batch_hidden_states", ".", "append", "(", "merged_layer_hidden_states", ")", "\n", "\n", "# combine layers", "\n", "", "combined_batch_embeddings", "=", "[", "]", "\n", "for", "sent_idx", ",", "sent_tokens", "in", "enumerate", "(", "batch_sent_tokens", ")", ":", "\n", "\n", "            ", "combined_sent_embeddings", "=", "[", "]", "\n", "for", "tok_idx", "in", "range", "(", "len", "(", "sent_tokens", ")", ")", ":", "\n", "                ", "tok_layer_vecs", "=", "[", "]", "\n", "for", "layer_idx", "in", "range", "(", "len", "(", "merged_batch_hidden_states", ")", ")", ":", "\n", "                    ", "tok_layer_vecs", ".", "append", "(", "merged_batch_hidden_states", "[", "layer_idx", "]", "[", "sent_idx", "]", "[", "tok_idx", "]", "[", "1", "]", ")", "\n", "\n", "", "if", "len", "(", "tok_layer_vecs", ")", "==", "1", ":", "\n", "                    ", "tok_combined_vec", "=", "tok_layer_vecs", "[", "0", "]", "\n", "\n", "", "else", ":", "\n", "                    ", "tok_layer_vecs", "=", "np", ".", "array", "(", "tok_layer_vecs", ")", "\n", "\n", "if", "self", ".", "nlm_config", "[", "'layer_op'", "]", "==", "'sum'", ":", "\n", "                        ", "tok_combined_vec", "=", "tok_layer_vecs", ".", "sum", "(", "axis", "=", "0", ")", "\n", "\n", "", "", "tok", "=", "merged_batch_hidden_states", "[", "layer_idx", "]", "[", "sent_idx", "]", "[", "tok_idx", "]", "[", "0", "]", "\n", "combined_sent_embeddings", ".", "append", "(", "(", "tok", ",", "tok_combined_vec", ")", ")", "\n", "\n", "", "combined_batch_embeddings", ".", "append", "(", "combined_sent_embeddings", ")", "\n", "\n", "", "return", "[", "combined_batch_embeddings", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.token_embeddings": [[193, 195], ["nlm_encoder.TransformerEncoder.get_token_embeddings_batch"], "methods", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.get_token_embeddings_batch"], ["", "def", "token_embeddings", "(", "self", ",", "batch_sent_tokens", ",", "return_tokens", "=", "True", ")", ":", "\n", "        ", "return", "self", ".", "get_token_embeddings_batch", "(", "batch_sent_tokens", ",", "return_tokens", "=", "return_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.is_valid": [[197, 203], ["nlm_encoder.TransformerEncoder.flatten_encodings", "nlm_encoder.TransformerEncoder.get_encodings", "len"], "methods", ["home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.flatten_encodings", "home.repos.pwc.inspect_result.danlou_bert-disambiguation.None.nlm_encoder.TransformerEncoder.get_encodings"], ["", "def", "is_valid", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "encodings", "=", "self", ".", "flatten_encodings", "(", "self", ".", "get_encodings", "(", "tokens", ")", ")", "\n", "if", "(", "len", "(", "encodings", ")", "+", "2", ")", ">", "self", ".", "nlm_config", "[", "'max_seq_len'", "]", ":", "\n", "            ", "return", "False", "\n", "", "else", ":", "\n", "            ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.scripts.create_outofdomain.read_xml_sents": [[9, 20], ["open", "line.strip.strip", "line.strip.startswith", "line.strip.startswith", "line.strip.startswith", "sent_elems.append", "line.strip.startswith", "sent_elems.append", "lxml.etree.fromstring"], "function", ["None"], ["def", "read_xml_sents", "(", "xml_path", ")", ":", "\n", "    ", "with", "open", "(", "xml_path", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", ".", "startswith", "(", "'<sentence '", ")", ":", "\n", "                ", "sent_elems", "=", "[", "line", "]", "\n", "", "elif", "line", ".", "startswith", "(", "'<wf '", ")", "or", "line", ".", "startswith", "(", "'<instance '", ")", ":", "\n", "                ", "sent_elems", ".", "append", "(", "line", ")", "\n", "", "elif", "line", ".", "startswith", "(", "'</sentence>'", ")", ":", "\n", "                ", "sent_elems", ".", "append", "(", "line", ")", "\n", "yield", "lxml", ".", "etree", ".", "fromstring", "(", "''", ".", "join", "(", "sent_elems", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.danlou_bert-disambiguation.scripts.create_outofdomain.get_id_mappings": [[22, 30], ["open", "line.split", "line.split"], "function", ["None"], ["", "", "", "", "def", "get_id_mappings", "(", "keys_path", ")", ":", "\n", "    ", "id2sks", "=", "{", "}", "\n", "with", "open", "(", "keys_path", ")", "as", "keys_f", ":", "\n", "        ", "for", "line", "in", "keys_f", ":", "\n", "            ", "id_", "=", "line", ".", "split", "(", ")", "[", "0", "]", "\n", "keys", "=", "line", ".", "split", "(", ")", "[", "1", ":", "]", "\n", "id2sks", "[", "id_", "]", "=", "keys", "\n", "", "", "return", "id2sks", "\n", "\n"]]}