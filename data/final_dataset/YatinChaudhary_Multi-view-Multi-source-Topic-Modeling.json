{"home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.loadGloveModel": [[50, 74], ["print", "open", "print", "line.split", "numpy.array", "len", "os.path.join", "os.path.join", "float", "os.path.join", "os.path.join", "print", "exit"], "function", ["None"], ["def", "loadGloveModel", "(", "gloveFile", "=", "None", ",", "hidden_size", "=", "None", ")", ":", "\n", "    ", "if", "gloveFile", "is", "None", ":", "\n", "        ", "if", "hidden_size", "==", "50", ":", "\n", "            ", "gloveFile", "=", "os", ".", "path", ".", "join", "(", "home_dir", ",", "\"resources/pretrained_embeddings/glove.6B.50d.txt\"", ")", "\n", "", "elif", "hidden_size", "==", "100", ":", "\n", "            ", "gloveFile", "=", "os", ".", "path", ".", "join", "(", "home_dir", ",", "\"resources/pretrained_embeddings/glove.6B.100d.txt\"", ")", "\n", "", "elif", "hidden_size", "==", "200", ":", "\n", "            ", "gloveFile", "=", "os", ".", "path", ".", "join", "(", "home_dir", ",", "\"resources/pretrained_embeddings/glove.6B.200d.txt\"", ")", "\n", "", "elif", "hidden_size", "==", "300", ":", "\n", "            ", "gloveFile", "=", "os", ".", "path", ".", "join", "(", "home_dir", ",", "\"resources/pretrained_embeddings/glove.6B.300d.txt\"", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'Invalid dimension [%d] for Glove pretrained embedding matrix!!'", "%", "hidden_size", ")", "\n", "exit", "(", ")", "\n", "\n", "", "", "print", "(", "\"Loading Glove Model\"", ")", "\n", "f", "=", "open", "(", "gloveFile", ",", "'r'", ")", "\n", "model", "=", "{", "}", "\n", "for", "line", "in", "f", ":", "\n", "        ", "splitLine", "=", "line", ".", "split", "(", ")", "\n", "word", "=", "splitLine", "[", "0", "]", "\n", "embedding", "=", "np", ".", "array", "(", "[", "float", "(", "val", ")", "for", "val", "in", "splitLine", "[", "1", ":", "]", "]", ")", "\n", "model", "[", "word", "]", "=", "embedding", "\n", "", "print", "(", "\"Done.\"", ",", "len", "(", "model", ")", ",", "\" words loaded!\"", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.tokens": [[76, 79], ["w.lower", "tokenizer.tokenize"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.tokenize"], ["", "def", "tokens", "(", "text", ")", ":", "\n", "#return [w.lower() for w in nltk.word_tokenize(text)]", "\n", "    ", "return", "[", "w", ".", "lower", "(", ")", "for", "w", "in", "tokenizer", ".", "tokenize", "(", "text", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.counts_to_sequence": [[81, 86], ["range", "len", "seq.extend", "int"], "function", ["None"], ["", "def", "counts_to_sequence", "(", "counts", ")", ":", "\n", "\t", "seq", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "counts", ")", ")", ":", "\n", "\t\t", "seq", ".", "extend", "(", "[", "i", "]", "*", "int", "(", "counts", "[", "i", "]", ")", ")", "\n", "", "return", "seq", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.log_counts": [[88, 91], ["numpy.bincount", "numpy.floor", "numpy.log"], "function", ["None"], ["", "def", "log_counts", "(", "ids", ",", "vocab_size", ")", ":", "\n", "    ", "counts", "=", "np", ".", "bincount", "(", "ids", ",", "minlength", "=", "vocab_size", ")", "\n", "return", "np", ".", "floor", "(", "0.5", "+", "np", ".", "log", "(", "counts", "+", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.preprocess": [[93, 105], ["vocab_to_id.get", "preprocess_data.log_counts", "preprocess_data.counts_to_sequence", "len", "preprocess_data.tokens", "vocab_to_id.get", "len", "str"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.log_counts", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.counts_to_sequence", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.tokens"], ["", "def", "preprocess", "(", "text", ",", "vocab_to_id", ",", "dataset_type", ")", ":", "\n", "    ", "ids", "=", "[", "vocab_to_id", ".", "get", "(", "x", ")", "for", "x", "in", "tokens", "(", "text", ")", "if", "vocab_to_id", ".", "get", "(", "x", ")", "]", "\n", "if", "dataset_type", "==", "\"docnade\"", ":", "\n", "        ", "counts", "=", "log_counts", "(", "ids", ",", "len", "(", "vocab_to_id", ")", ")", "\n", "sequence", "=", "counts_to_sequence", "(", "counts", ")", "\n", "", "else", ":", "\n", "        ", "sequence", "=", "ids", "\n", "\n", "", "if", "len", "(", "sequence", ")", "==", "0", ":", "\n", "        ", "return", "None", "\n", "", "else", ":", "\n", "        ", "return", "' '", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "sequence", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.clean_str": [[107, 126], ["re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub.strip().split", "re.sub.strip"], "function", ["None"], ["", "", "def", "clean_str", "(", "string", ")", ":", "\n", "    ", "\"\"\"\n    Tokenization/string cleaning for all datasets.\n    \"\"\"", "\n", "string", "=", "re", ".", "sub", "(", "r\"[^A-Za-z0-9(),!?\\'\\`]\"", ",", "\" \"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "r\"\\'s\"", ",", "\" \\'s\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "r\"\\'ve\"", ",", "\" \\'ve\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "r\"n\\'t\"", ",", "\" n\\'t\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "r\"\\'re\"", ",", "\" \\'re\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "r\"\\'d\"", ",", "\" \\'d\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "r\"\\'ll\"", ",", "\" \\'ll\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "r\",\"", ",", "\" , \"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "r\"!\"", ",", "\" ! \"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "r\"\\(\"", ",", "\" \\( \"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "r\"\\)\"", ",", "\" \\) \"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "r\"\\?\"", ",", "\" \\? \"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "r\"\\s{2,}\"", ",", "\" \"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "r\"\\s+\"", ",", "\" \"", ",", "string", ")", "\n", "return", "string", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.tokenize": [[128, 130], ["preprocess_data.clean_str", "str().lower", "str"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.clean_str"], ["", "def", "tokenize", "(", "text", ")", ":", "\n", "\t", "return", "clean_str", "(", "str", "(", "text", ")", ".", "lower", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.TF": [[132, 136], ["sklearn.feature_extraction.text.CountVectorizer", "sklearn.feature_extraction.text.CountVectorizer.fit"], "function", ["None"], ["", "def", "TF", "(", "docs", ",", "max_features", "=", "2000", ")", ":", "\n", "\t", "cv", "=", "CountVectorizer", "(", "tokenizer", "=", "tokenize", ",", "min_df", "=", "3", ",", "max_df", "=", "1.0", ",", "max_features", "=", "max_features", ",", "encoding", "=", "'utf-8'", ",", "decode_error", "=", "'ignore'", ")", "\n", "cv", ".", "fit", "(", "docs", ")", "\n", "return", "cv", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.load_file": [[138, 160], ["open", "line.split", "docs.append", "labels.append", "len", "print", "exit", "len", "str().strip().strip().strip", "str().strip().strip", "str().strip", "str"], "function", ["None"], ["", "def", "load_file", "(", "filename", ")", ":", "\n", "\t", "\"\"\"\n\tRead the tab delimited file containing the labels and the docs.\n\n\t\"\"\"", "\n", "labels", "=", "[", "]", "\n", "docs", "=", "[", "]", "\n", "\n", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "\t\t", "for", "line", "in", "f", ":", "\n", "\t\t\t", "content", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "\n", "if", "len", "(", "content", ")", ">", "2", ":", "\n", "\t\t\t\t", "print", "(", "'incorrect read'", ")", "\n", "exit", "(", ")", "\n", "\n", "", "if", "len", "(", "content", "[", "1", "]", ")", "==", "0", ":", "continue", "\n", "\n", "docs", ".", "append", "(", "str", "(", "content", "[", "1", "]", ")", ".", "strip", "(", "'\\r'", ")", ".", "strip", "(", "'\\n'", ")", ".", "strip", "(", "'\\r\\n'", ")", ")", "\n", "labels", ".", "append", "(", "content", "[", "0", "]", ")", "\n", "\n", "", "", "return", "docs", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.str2bool": [[162, 169], ["v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["", "def", "str2bool", "(", "v", ")", ":", "\n", "    ", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.main": [[171, 392], ["preprocess_data.str2bool", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "preprocess_data.load_file", "preprocess_data.load_file", "print", "str", "total_docs.extend", "total_docs.extend", "total_docs.extend", "numpy.mean", "print", "total_docs.extend", "total_docs.extend", "preprocess_data.TF", "TF.get_feature_names", "model.data.Dataset", "dict", "print", "preprocess_data.load_file", "numpy.unique", "str().lower().strip().split", "len", "doc_lengths.append", "numpy.arange", "train_test_split", "open", "csv.writer", "zip", "open", "csv.writer", "zip", "open", "csv.writer", "zip", "open", "f.write", "open", "zip", "os.path.isdir", "os.mkdir", "os.path.join", "open", "f.write", "open", "pickle.dump", "args.data_output.split", "len", "tokenizer.tokenize", "csv.writer.writerow", "new_train_docs.append", "tokenizer.tokenize", "csv.writer.writerow", "new_val_docs.append", "tokenizer.tokenize", "csv.writer.writerow", "new_test_docs.append", "csv.writer.strip", "range", "open", "csv.writer", "model.data.Dataset.rows", "os.path.join", "os.path.join", "str().lower().strip", "str().lower().strip", "str().lower().strip", "str().lower().strip", "str().lower().strip", "str().lower().strip", "str().lower().strip", "str().lower().strip", "str().lower().strip", "str().lower().strip", "str().lower().strip", "str().lower().strip", "str().lower().strip", "f.readlines", "len", "preprocess_data.preprocess", "str().lower", "str().lower", "str().lower", "str().lower", "str().lower", "str().lower", "str().lower", "str().lower", "str().lower", "str().lower", "str().lower", "str().lower", "str().lower", "removed_indices[].append", "y.split", "csv.writer.writerow", "csv.writer.writerow", "pdb.set_trace", "sorted", "new_label.append", "len", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "len", "str", "str().lower", "str"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.load_file", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.load_file", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.TF", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.load_file", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.tokenize", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.tokenize", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.tokenize", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.rows", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.preprocess"], ["", "", "def", "main", "(", "args", ")", ":", "\n", "\t", "args", ".", "split_train_val", "=", "str2bool", "(", "args", ".", "split_train_val", ")", "\n", "\n", "doc_train_filename", "=", "args", ".", "training_file", "\n", "doc_val_filename", "=", "args", ".", "validation_file", "\n", "doc_test_filename", "=", "args", ".", "test_file", "\n", "\n", "train_csv_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_output", ",", "\"training.csv\"", ")", "\n", "val_csv_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_output", ",", "\"validation.csv\"", ")", "\n", "test_csv_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_output", ",", "\"test.csv\"", ")", "\n", "\n", "docnade_vocabulary", "=", "args", ".", "vocab_size", "\n", "docnade_vocab_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_output", ",", "\"vocab_docnade.vocab\"", ")", "\n", "lstm_vocab_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_output", ",", "\"vocab_lstm.vocab\"", ")", "\n", "\n", "mapping_dict_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_output", ",", "\"mapping_dict.pkl\"", ")", "\n", "\n", "\n", "train_docs", ",", "train_docs_labels", "=", "load_file", "(", "doc_train_filename", ")", "\n", "test_docs", ",", "test_docs_labels", "=", "load_file", "(", "doc_test_filename", ")", "\n", "if", "not", "args", ".", "split_train_val", ":", "\n", "\t\t", "val_docs", ",", "val_docs_labels", "=", "load_file", "(", "doc_val_filename", ")", "\n", "\n", "", "print", "(", "np", ".", "unique", "(", "train_docs_labels", ")", ")", "\n", "\n", "################### Calculate average document length #####################", "\n", "dataset_name", "=", "str", "(", "args", ".", "data_output", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", "\n", "\n", "total_docs", "=", "[", "]", "\n", "total_docs", ".", "extend", "(", "train_docs", ")", "\n", "total_docs", ".", "extend", "(", "val_docs", ")", "\n", "total_docs", ".", "extend", "(", "test_docs", ")", "\n", "\n", "doc_lengths", "=", "[", "]", "\n", "for", "doc", "in", "total_docs", ":", "\n", "\t\t", "doc_tokens", "=", "str", "(", "doc", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "doc_length", "=", "len", "(", "doc_tokens", ")", "\n", "doc_lengths", ".", "append", "(", "doc_length", ")", "\n", "\n", "", "average_doc_length", "=", "np", ".", "mean", "(", "doc_lengths", ")", "\n", "print", "(", "\"Average doc length for dataset [ %s ] is = %f\"", "%", "(", "dataset_name", ",", "average_doc_length", ")", ")", "\n", "\n", "#exit()", "\n", "###########################################################################", "\n", "# Prepare CSV file", "\n", "\n", "if", "args", ".", "split_train_val", ":", "\n", "\t\t", "from", "sklearn", ".", "model_selection", "import", "train_test_split", "\n", "indices", "=", "np", ".", "arange", "(", "len", "(", "train_docs", ")", ")", "\n", "#val_size = len(train_docs) * args.split_ratio", "\n", "val_size", "=", "args", ".", "split_num", "\n", "train_docs", ",", "val_docs", ",", "train_docs_labels", ",", "val_docs_labels", ",", "split_index_train", ",", "split_index_dev", "=", "train_test_split", "(", "train_docs", ",", "train_docs_labels", ",", "indices", ",", "test_size", "=", "50", ",", "random_state", "=", "1234", ")", "\n", "\n", "", "new_train_docs", "=", "[", "]", "\n", "with", "open", "(", "train_csv_filename", ",", "'w'", ")", "as", "csvfile", ":", "\n", "\t\t", "filewriter", "=", "csv", ".", "writer", "(", "csvfile", ",", "delimiter", "=", "','", ")", "\n", "for", "doc", ",", "label", "in", "zip", "(", "train_docs", ",", "train_docs_labels", ")", ":", "\n", "\t\t\t", "new_doc_tokens", "=", "tokenizer", ".", "tokenize", "(", "str", "(", "doc", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", ")", "\n", "new_doc", "=", "' '", ".", "join", "(", "new_doc_tokens", ")", "\n", "#doc_tokens = tokenize(str(doc).lower().strip())", "\n", "li", "=", "[", "str", "(", "label", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", ",", "str", "(", "new_doc", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", "]", "\n", "filewriter", ".", "writerow", "(", "li", ")", "\n", "new_train_docs", ".", "append", "(", "str", "(", "new_doc", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "new_val_docs", "=", "[", "]", "\n", "with", "open", "(", "val_csv_filename", ",", "'w'", ")", "as", "csvfile", ":", "\n", "\t\t", "filewriter", "=", "csv", ".", "writer", "(", "csvfile", ",", "delimiter", "=", "','", ")", "\n", "for", "doc", ",", "label", "in", "zip", "(", "val_docs", ",", "val_docs_labels", ")", ":", "\n", "\t\t\t", "new_doc_tokens", "=", "tokenizer", ".", "tokenize", "(", "str", "(", "doc", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", ")", "\n", "new_doc", "=", "' '", ".", "join", "(", "new_doc_tokens", ")", "\n", "li", "=", "[", "str", "(", "label", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", ",", "str", "(", "doc", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", "]", "\n", "filewriter", ".", "writerow", "(", "li", ")", "\n", "new_val_docs", ".", "append", "(", "str", "(", "new_doc", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "new_test_docs", "=", "[", "]", "\n", "with", "open", "(", "test_csv_filename", ",", "'w'", ")", "as", "csvfile", ":", "\n", "\t\t", "filewriter", "=", "csv", ".", "writer", "(", "csvfile", ",", "delimiter", "=", "','", ")", "\n", "for", "doc", ",", "label", "in", "zip", "(", "test_docs", ",", "test_docs_labels", ")", ":", "\n", "\t\t\t", "new_doc_tokens", "=", "tokenizer", ".", "tokenize", "(", "str", "(", "doc", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", ")", "\n", "new_doc", "=", "' '", ".", "join", "(", "new_doc_tokens", ")", "\n", "li", "=", "[", "str", "(", "label", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", ",", "str", "(", "doc", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", "]", "\n", "filewriter", ".", "writerow", "(", "li", ")", "\n", "new_test_docs", ".", "append", "(", "str", "(", "new_doc", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "total_docs", "=", "[", "]", "\n", "total_docs", ".", "extend", "(", "new_train_docs", ")", "\n", "total_docs", ".", "extend", "(", "new_val_docs", ")", "\n", "\n", "\"\"\"\n\t########################################################\n\ttotal_tokens = []\n\tfor doc in total_docs:\n\t\ttotal_tokens.extend(doc.split(' '))\n\n\tglove_embeddings = loadGloveModel(hidden_size=200)\n\tglove_keys = glove_embeddings.keys()\n\n\ttotal_missing = 0\n\tfor token in total_tokens:\n\t\tif str(token).lower().strip() in glove_keys:\n\t\t\tcontinue\n\t\telse:\n\t\t\ttotal_missing += 1\n\n\tprint(\"Total tokens missing %s / %s\" % (total_missing, len(total_tokens)))\n\n\texit()\n\t########################################################\n\t\"\"\"", "\n", "\n", "# Saving docnade vocabulary", "\n", "representer", "=", "TF", "(", "total_docs", ",", "max_features", "=", "docnade_vocabulary", ")", "\n", "vocab_dict_docnade", "=", "representer", ".", "get_feature_names", "(", ")", "\n", "\n", "with", "open", "(", "docnade_vocab_filename", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t", "f", ".", "write", "(", "'\\n'", ".", "join", "(", "vocab_dict_docnade", ")", ")", "\n", "", "\"\"\"\n\t# Saving lstm vocabulary\n\trepresenter = TF(total_docs, max_features=None)\n\tvocab_dict_lstm = representer.get_feature_names()\n\n\twith open(lstm_vocab_filename, \"w\") as f:\n\t\tf.write('\\n'.join(vocab_dict_lstm))\n\n\t# Creating mapping dictionary\n\tmapping_dict = {}\n\n\tfor i, word in enumerate(vocab_dict_docnade):\n\t\tmapping_dict[int(i)] = int(vocab_dict_lstm.index(str(word)))\n\n\twith open(mapping_dict_filename, \"wb\") as f:\n\t\tpickle.dump(mapping_dict, f)\n\n\tprint(\"Mapping dictionary created.\")\n\t\"\"\"", "\n", "# Preparing CSV files for DocNADE Tensorflow", "\n", "data", "=", "model", ".", "data", ".", "Dataset", "(", "args", ".", "data_output", ")", "\n", "\n", "with", "open", "(", "docnade_vocab_filename", ",", "'r'", ")", "as", "f", ":", "\n", "\t\t", "vocab", "=", "[", "w", ".", "strip", "(", ")", "for", "w", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "vocab_to_id", "=", "dict", "(", "zip", "(", "vocab", ",", "range", "(", "len", "(", "vocab", ")", ")", ")", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "data_output", ")", ":", "\n", "\t\t", "os", ".", "mkdir", "(", "args", ".", "data_output", ")", "\n", "\n", "", "labels", "=", "{", "}", "\n", "removed_indices", "=", "{", "\"training\"", ":", "[", "]", ",", "\"test\"", ":", "[", "]", ",", "\"validation\"", ":", "[", "]", "}", "\n", "for", "collection", "in", "data", ".", "collections", ":", "\n", "\t\t", "output_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_output", ",", "'{}_docnade.csv'", ".", "format", "(", "collection", ")", ")", "\n", "#with open(output_path, 'w', newline='') as f:", "\n", "with", "open", "(", "output_path", ",", "'w'", ")", "as", "f", ":", "\n", "\t\t\t", "w", "=", "csv", ".", "writer", "(", "f", ",", "delimiter", "=", "','", ")", "\n", "count", "=", "-", "1", "\n", "#for y, x in data.rows(collection, num_epochs=1):", "\n", "for", "index", ",", "(", "y", ",", "x", ")", "in", "data", ".", "rows", "(", "collection", ",", "num_epochs", "=", "1", ")", ":", "\n", "\t\t\t\t", "count", "+=", "1", "\n", "try", ":", "\n", "\t\t\t\t\t", "pre", "=", "preprocess", "(", "x", ",", "vocab_to_id", ",", "\"docnade\"", ")", "\n", "if", "pre", "is", "None", ":", "\n", "\t\t\t\t\t\t", "removed_indices", "[", "str", "(", "collection", ")", ".", "lower", "(", ")", "]", ".", "append", "(", "count", ")", "\n", "continue", "\n", "", "if", "':'", "in", "y", ":", "\n", "\t\t\t\t\t\t", "temp_labels", "=", "y", ".", "split", "(", "':'", ")", "\n", "new_label", "=", "[", "]", "\n", "for", "label", "in", "temp_labels", ":", "\n", "\t\t\t\t\t\t\t", "if", "label", "not", "in", "labels", ":", "\n", "\t\t\t\t\t\t\t\t", "labels", "[", "label", "]", "=", "len", "(", "labels", ")", "\n", "", "new_label", ".", "append", "(", "str", "(", "labels", "[", "label", "]", ")", ")", "\n", "", "temp_label", "=", "':'", ".", "join", "(", "new_label", ")", "\n", "w", ".", "writerow", "(", "(", "temp_label", ",", "pre", ")", ")", "\n", "", "else", ":", "\n", "\t\t\t\t\t\t", "if", "y", "not", "in", "labels", ":", "\n", "\t\t\t\t\t\t\t", "labels", "[", "y", "]", "=", "len", "(", "labels", ")", "\n", "", "w", ".", "writerow", "(", "(", "labels", "[", "y", "]", ",", "pre", ")", ")", "\n", "", "", "except", ":", "\n", "\t\t\t\t\t", "import", "pdb", ";", "pdb", ".", "set_trace", "(", ")", "\n", "\n", "", "", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_output", ",", "'labels.txt'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "\t\t", "f", ".", "write", "(", "'\\n'", ".", "join", "(", "[", "k", "for", "k", "in", "sorted", "(", "labels", ",", "key", "=", "labels", ".", "get", ")", "]", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_output", ",", "'removed_indices.pkl'", ")", ",", "\"wb\"", ")", "as", "f", ":", "\n", "\t\t", "pickle", ".", "dump", "(", "removed_indices", ",", "f", ")", "\n", "\n", "", "print", "(", "removed_indices", ")", "\n", "\"\"\"\n\t# Preparing CSV files for LSTM Tensorflow\n\twith open(lstm_vocab_filename, 'r') as f:\n\t\tvocab = [w.strip() for w in f.readlines()]\n\tvocab_to_id = dict(zip(vocab, range(len(vocab))))\n\n\tlabels = {}\n\tfor collection in data.collections:\n\t\tremoved_indices_collection = removed_indices[str(collection).lower()]\n\t\toutput_path = os.path.join(args.data_output, '{}_lstm.csv'.format(collection))\n\t\t#with open(output_path, 'w', newline='') as f:\n\t\twith open(output_path, 'w') as f:\n\t\t\tw = csv.writer(f, delimiter=',')\n\t\t\tcount = -1\n\t\t\t#for y, x in data.rows(collection, num_epochs=1):\n\t\t\tfor index, (y, x) in data.rows(collection, num_epochs=1):\n\t\t\t\tcount += 1\n\t\t\t\ttry:\n\t\t\t\t\tpre = preprocess(x, vocab_to_id, \"lstm\")\n\t\t\t\t\tif count in removed_indices_collection:\n\t\t\t\t\t\tcontinue\n\t\t\t\t\tif ':' in y:\n\t\t\t\t\t\ttemp_labels = y.split(':')\n\t\t\t\t\t\tnew_label = []\n\t\t\t\t\t\tfor label in temp_labels:\n\t\t\t\t\t\t\tif label not in labels:\n\t\t\t\t\t\t\t\tlabels[label] = len(labels)\n\t\t\t\t\t\t\tnew_label.append(str(labels[label]))\n\t\t\t\t\t\ttemp_label = ':'.join(new_label)\n\t\t\t\t\t\tw.writerow((temp_label, pre))\n\t\t\t\t\telse:\n\t\t\t\t\t\tif y not in labels:\n\t\t\t\t\t\t\tlabels[y] = len(labels)\n\t\t\t\t\t\tw.writerow((labels[y], pre))\n\t\t\t\texcept:\n\t\t\t\t\timport pdb; pdb.set_trace()\n\t\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.preprocess_data.parse_args": [[393, 411], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--training-file'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'path to validation text file'", ")", "\n", "parser", ".", "add_argument", "(", "'--validation-file'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'path to validation text file'", ")", "\n", "parser", ".", "add_argument", "(", "'--test-file'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'path to validation text file'", ")", "\n", "parser", ".", "add_argument", "(", "'--data-output'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'path to data output directory'", ")", "\n", "parser", ".", "add_argument", "(", "'--vocab-size'", ",", "type", "=", "int", ",", "default", "=", "2000", ",", "\n", "help", "=", "'the vocab size'", ")", "\n", "parser", ".", "add_argument", "(", "'--split-train-val'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether to do train-val split'", ")", "\n", "parser", ".", "add_argument", "(", "'--split-num'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "'number of documents in validation set'", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.loadGloveModel": [[33, 73], ["print", "open", "print", "numpy.zeros", "enumerate", "print", "line.split", "numpy.array", "len", "os.path.join", "len", "str().lower", "model.keys", "model.keys", "model.keys", "numpy.zeros", "os.path.join", "float", "len", "numpy.zeros", "numpy.array", "len", "os.path.join", "str", "os.path.join", "print", "exit", "str().lower", "str().lower", "str", "str"], "function", ["None"], ["def", "loadGloveModel", "(", "vocab_docnade", ",", "gloveFile", "=", "None", ",", "params", "=", "None", ")", ":", "\n", "\t", "if", "gloveFile", "is", "None", ":", "\n", "\t\t", "if", "params", ".", "hidden_size", "==", "50", ":", "\n", "\t\t\t", "gloveFile", "=", "os", ".", "path", ".", "join", "(", "home_dir", ",", "\"resources/pretrained_embeddings/glove.6B.50d.txt\"", ")", "\n", "", "elif", "params", ".", "hidden_size", "==", "100", ":", "\n", "\t\t\t", "gloveFile", "=", "os", ".", "path", ".", "join", "(", "home_dir", ",", "\"resources/pretrained_embeddings/glove.6B.100d.txt\"", ")", "\n", "", "elif", "params", ".", "hidden_size", "==", "200", ":", "\n", "\t\t\t", "gloveFile", "=", "os", ".", "path", ".", "join", "(", "home_dir", ",", "\"resources/pretrained_embeddings/glove.6B.200d.txt\"", ")", "\n", "", "elif", "params", ".", "hidden_size", "==", "300", ":", "\n", "\t\t\t", "gloveFile", "=", "os", ".", "path", ".", "join", "(", "home_dir", ",", "\"resources/pretrained_embeddings/glove.6B.300d.txt\"", ")", "\n", "", "else", ":", "\n", "\t\t\t", "print", "(", "'Invalid dimension [%d] for Glove pretrained embedding matrix!!'", "%", "params", ".", "hidden_size", ")", "\n", "exit", "(", ")", "\n", "\n", "", "", "print", "(", "\"Loading Glove Model\"", ")", "\n", "f", "=", "open", "(", "gloveFile", ",", "'r'", ")", "\n", "model", "=", "{", "}", "\n", "for", "line", "in", "f", ":", "\n", "\t\t", "splitLine", "=", "line", ".", "split", "(", ")", "\n", "word", "=", "splitLine", "[", "0", "]", "\n", "embedding", "=", "np", ".", "array", "(", "[", "float", "(", "val", ")", "for", "val", "in", "splitLine", "[", "1", ":", "]", "]", ")", "\n", "model", "[", "word", "]", "=", "embedding", "\n", "", "print", "(", "\"Done.\"", ",", "len", "(", "model", ")", ",", "\" words loaded!\"", ")", "\n", "\n", "missing_words", "=", "0", "\n", "docnade_glove_matrix", "=", "np", ".", "zeros", "(", "(", "len", "(", "vocab_docnade", ")", ",", "params", ".", "hidden_size", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "vocab_docnade", ")", ":", "\n", "\t\t", "if", "str", "(", "word", ")", ".", "lower", "(", ")", "in", "model", ".", "keys", "(", ")", ":", "\n", "\t\t\t", "if", "len", "(", "model", "[", "str", "(", "word", ")", ".", "lower", "(", ")", "]", ")", "==", "0", ":", "\n", "\t\t\t\t", "docnade_glove_matrix", "[", "i", ",", ":", "]", "=", "np", ".", "zeros", "(", "(", "params", ".", "hidden_size", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "missing_words", "+=", "1", "\n", "", "else", ":", "\n", "\t\t\t\t", "docnade_glove_matrix", "[", "i", ",", ":", "]", "=", "np", ".", "array", "(", "model", "[", "str", "(", "word", ")", ".", "lower", "(", ")", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "", "else", ":", "\n", "\t\t\t", "docnade_glove_matrix", "[", "i", ",", ":", "]", "=", "np", ".", "zeros", "(", "(", "params", ".", "hidden_size", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "missing_words", "+=", "1", "\n", "\n", "", "", "print", "(", "\"Total missing words:%d out of %d\"", "%", "(", "missing_words", ",", "len", "(", "vocab_docnade", ")", ")", ")", "\n", "#return model", "\n", "return", "docnade_glove_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.loadBioModel": [[74, 90], ["print", "gensim.models.keyedvectors.KeyedVectors.load_word2vec_format", "numpy.zeros", "enumerate", "print", "len", "len", "str().lower", "str"], "function", ["None"], ["", "def", "loadBioModel", "(", "vocab_docnade", ",", "BioFile", "=", "None", ",", "params", "=", "None", ")", ":", "\n", "\t", "print", "(", "\"Loading BioNLP Model\"", ")", "\n", "model", "=", "KeyedVectors", ".", "load_word2vec_format", "(", "'/home/ubuntu/resources/pretrained_embeddings/PubMed-and-PMC-w2v.bin'", ",", "binary", "=", "True", ")", "\n", "\n", "missing_words", "=", "0", "\n", "docnade_glove_matrix", "=", "np", ".", "zeros", "(", "(", "len", "(", "vocab_docnade", ")", ",", "params", ".", "hidden_size", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "vocab_docnade", ")", ":", "\n", "\t\t", "try", ":", "\n", "\t\t\t", "docnade_glove_matrix", "[", "i", ",", ":", "]", "=", "model", "[", "str", "(", "word", ")", ".", "lower", "(", ")", "]", "\n", "", "except", "KeyError", ":", "\n", "\t\t\t", "missing_words", "+=", "1", "\n", "pass", "\n", "", "", "print", "(", "\"Total missing words:%d out of %d\"", "%", "(", "missing_words", ",", "len", "(", "vocab_docnade", ")", ")", ")", "\n", "\n", "#return model", "\n", "return", "docnade_glove_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.loadFastTextModel": [[91, 103], ["print", "load_model", "numpy.array", "prior_vecs.append", "load_model.get_word_vector", "word.strip"], "function", ["None"], ["", "def", "loadFastTextModel", "(", "vocab_docnade", ",", "fasttext_file", "=", "None", ",", "params", "=", "None", ")", ":", "\n", "\t", "print", "(", "\"Loading FastText Model\"", ")", "\n", "if", "fasttext_file", "is", "None", ":", "\n", "\t\t", "fasttext_file", "=", "'/home/ubuntu/resources/pretrained_embeddings/wiki.en.bin'", "\n", "", "model", "=", "load_model", "(", "fasttext_file", ")", "\n", "\n", "prior_vecs", "=", "[", "]", "\n", "for", "word", "in", "vocab_docnade", ":", "\n", "\t\t", "prior_vecs", ".", "append", "(", "model", ".", "get_word_vector", "(", "word", ".", "strip", "(", ")", ")", ")", "\n", "", "docnade_fasttext_matrix", "=", "np", ".", "array", "(", "prior_vecs", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "return", "docnade_fasttext_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.get_bert_input": [[104, 117], ["numpy.stack", "np.stack.append", "len", "numpy.concatenate", "ValueError", "numpy.zeros"], "function", ["None"], ["", "def", "get_bert_input", "(", "reps", ",", "indices", ",", "max_length", ")", ":", "\n", "\t", "bert_inputs", "=", "[", "]", "\n", "for", "index", "in", "indices", ":", "\n", "\t\t", "inputs", "=", "reps", "[", "index", "]", "\n", "if", "inputs", ".", "shape", "[", "0", "]", "<", "max_length", ":", "\n", "\t\t\t", "inputs", "=", "np", ".", "concatenate", "(", "[", "inputs", ",", "np", ".", "zeros", "(", "(", "max_length", "-", "inputs", ".", "shape", "[", "0", "]", ",", "inputs", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "np", ".", "float32", ")", "]", ",", "axis", "=", "0", ")", "\n", "assert", "(", "inputs", ".", "shape", "[", "0", "]", "==", "max_length", ")", "\n", "", "if", "inputs", ".", "shape", "[", "0", "]", ">", "max_length", ":", "\n", "\t\t\t", "raise", "ValueError", "(", "\"Dimension mismatch.\"", ")", "\n", "", "bert_inputs", ".", "append", "(", "inputs", ")", "\n", "", "bert_inputs", "=", "np", ".", "stack", "(", "bert_inputs", ",", "axis", "=", "0", ")", "\n", "assert", "(", "bert_inputs", ".", "shape", "[", "0", "]", "==", "len", "(", "indices", ")", ")", "\n", "return", "bert_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.train": [[118, 515], ["os.path.join", "os.path.join", "os.path.join", "tensorflow.Session", "tensorflow.placeholder", "tensorflow.summary.scalar", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.FileWriter", "tensorflow.summary.merge_all", "tensorflow.train.Saver", "tensorflow.local_variables_initializer().run", "tensorflow.global_variables_initializer().run", "dataset.batches", "numpy.array", "numpy.array", "numpy.array", "range", "tensorflow.global_variables", "next", "session.run", "losses.append", "tf.train.Saver.restore", "dataset.batches", "numpy.mean", "numpy.exp", "dataset.batches", "numpy.mean", "numpy.exp", "print", "session.run", "range", "train_DocNADE_MVT_MST.compute_coherence", "tf.train.Saver.restore", "model.vectors", "model.vectors", "model.vectors", "model.evaluate", "model.evaluate", "print", "tensorflow.ConfigProto", "tensorflow.local_variables_initializer", "tensorflow.global_variables_initializer", "train_DocNADE_MVT_MST.get_bert_input", "print", "dataset.batches", "numpy.mean", "numpy.exp", "print", "model.vectors", "model.vectors", "print", "tensorflow.train.latest_checkpoint", "session.run", "this_val_nll.append", "this_val_loss_normed.append", "numpy.mean", "session.run", "this_test_nll.append", "this_test_loss_normed.append", "numpy.mean", "open", "f.write", "w_h_top_words_indices.append", "open", "open", "zip", "print", "open().readlines", "os.path.join", "tensorflow.train.latest_checkpoint", "dataset.batches", "dataset.batches", "dataset.batches", "open", "f.write", "f.write", "dataset.rows", "dataset.rows", "dataset.rows", "session.run", "this_val_nll.append", "this_val_loss_normed.append", "numpy.mean", "print", "tf.train.Saver.save", "open", "f.write", "print", "dataset.batches", "dataset.batches", "model.evaluate", "print", "tf.train.Saver.save", "open", "f.write", "print", "train_DocNADE_MVT_MST.get_bert_input", "train_DocNADE_MVT_MST.get_bert_input", "os.path.join", "w.strip", "os.path.join", "range", "topics_list_W.append", "print", "print", "print", "print", "f.write", "f.write", "f.write", "f.write", "str().strip", "texts.append", "os.path.join", "tensorflow.GPUOptions", "train_DocNADE_MVT_MST.get_bert_input", "os.path.join", "os.path.join", "numpy.array", "f.readlines", "len", "open", "str().strip.split", "numpy.argsort", "str"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.compute_coherence", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.vectors", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.vectors", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.vectors", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.evaluate.evaluate", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.evaluate.evaluate", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.get_bert_input", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.vectors", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.vectors", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.rows", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.rows", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.rows", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.evaluate.evaluate", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.get_bert_input", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.get_bert_input", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.get_bert_input"], ["", "def", "train", "(", "model", ",", "dataset", ",", "params", ",", "vocab", ",", "docnade_bert_reps", "=", "None", ")", ":", "\n", "\t", "log_dir", "=", "os", ".", "path", ".", "join", "(", "params", ".", "model", ",", "'logs'", ")", "\n", "model_dir_ir", "=", "os", ".", "path", ".", "join", "(", "params", ".", "model", ",", "'model_ir'", ")", "\n", "model_dir_ppl", "=", "os", ".", "path", ".", "join", "(", "params", ".", "model", ",", "'model_ppl'", ")", "\n", "\n", "with", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "inter_op_parallelism_threads", "=", "params", ".", "num_cores", ",", "\n", "intra_op_parallelism_threads", "=", "params", ".", "num_cores", ",", "\n", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "allow_growth", "=", "True", ")", "\n", ")", ")", "as", "session", ":", "\n", "\t\t", "avg_loss", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "]", ",", "'loss_ph'", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'loss'", ",", "avg_loss", ")", "\n", "\n", "validation", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "]", ",", "'validation_ph'", ")", "\n", "validation_accuracy", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "]", ",", "'validation_acc'", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'validation'", ",", "validation", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'validation_accuracy'", ",", "validation_accuracy", ")", "\n", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "log_dir", ",", "session", ".", "graph", ")", "\n", "summaries", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "global_variables", "(", ")", ")", "\n", "\n", "tf", ".", "local_variables_initializer", "(", ")", ".", "run", "(", ")", "\n", "tf", ".", "global_variables_initializer", "(", ")", ".", "run", "(", ")", "\n", "\n", "losses", "=", "[", "]", "\n", "\n", "# This currently streams from disk. You set num_epochs=1 and", "\n", "# wrap this call with something like itertools.cycle to keep", "\n", "# this data in memory.", "\n", "# shuffle: the order of words in the sentence for DocNADE", "\n", "\n", "training_data", "=", "dataset", ".", "batches", "(", "'training_docnade'", ",", "params", ".", "batch_size", ",", "shuffle", "=", "True", ",", "multilabel", "=", "params", ".", "multi_label", ")", "\n", "\n", "best_val_IR", "=", "0.0", "\n", "best_val_nll", "=", "np", ".", "inf", "\n", "best_val_ppl", "=", "np", ".", "inf", "\n", "best_val_disc_accuracy", "=", "0.0", "\n", "\n", "best_test_IR", "=", "0.0", "\n", "best_test_nll", "=", "np", ".", "inf", "\n", "best_test_ppl", "=", "np", ".", "inf", "\n", "best_test_disc_accuracy", "=", "0.0", "\n", "\n", "patience", "=", "params", ".", "patience", "\n", "\n", "patience_count", "=", "0", "\n", "patience_count_ir", "=", "0", "\n", "best_train_nll", "=", "np", ".", "inf", "\n", "\n", "training_labels", "=", "np", ".", "array", "(", "\n", "[", "[", "row", "[", "0", "]", "]", "for", "index", ",", "row", "in", "dataset", ".", "rows", "(", "'training_docnade'", ",", "num_epochs", "=", "1", ")", "]", "\n", ")", "\n", "validation_labels", "=", "np", ".", "array", "(", "\n", "[", "[", "row", "[", "0", "]", "]", "for", "index", ",", "row", "in", "dataset", ".", "rows", "(", "'validation_docnade'", ",", "num_epochs", "=", "1", ")", "]", "\n", ")", "\n", "test_labels", "=", "np", ".", "array", "(", "\n", "[", "[", "row", "[", "0", "]", "]", "for", "index", ",", "row", "in", "dataset", ".", "rows", "(", "'test_docnade'", ",", "num_epochs", "=", "1", ")", "]", "\n", ")", "\n", "\n", "ppl_model", "=", "False", "\n", "ir_model", "=", "False", "\n", "\n", "for", "step", "in", "range", "(", "params", ".", "num_steps", "+", "1", ")", ":", "\n", "\t\t\t", "this_loss", "=", "-", "1.", "\n", "\n", "indices", ",", "y", ",", "x", ",", "seq_lengths", "=", "next", "(", "training_data", ")", "\n", "train_feed_dict", "=", "{", "\n", "model", ".", "x", ":", "x", ",", "\n", "model", ".", "y", ":", "y", ",", "\n", "model", ".", "seq_lengths", ":", "seq_lengths", "\n", "}", "\n", "\n", "if", "params", ".", "use_bert_prior", ":", "\n", "\t\t\t\t", "x_bert", "=", "get_bert_input", "(", "docnade_bert_reps", "[", "\"training_docnade\"", "]", ",", "indices", ",", "x", ".", "shape", "[", "1", "]", ")", "\n", "train_feed_dict", "[", "model", ".", "x_bert", "]", "=", "x_bert", "\n", "\n", "", "_", ",", "loss", ",", "loss_unnormed", "=", "session", ".", "run", "(", "[", "model", ".", "opt", ",", "model", ".", "loss_normed", ",", "model", ".", "loss_unnormed", "]", ",", "feed_dict", "=", "train_feed_dict", ")", "\n", "this_loss", "=", "loss", "\n", "losses", ".", "append", "(", "this_loss", ")", "\n", "\n", "if", "(", "step", "%", "params", ".", "log_every", "==", "0", ")", ":", "\n", "\t\t\t\t", "print", "(", "'{}: {:.6f}'", ".", "format", "(", "step", ",", "this_loss", ")", ")", "\n", "\n", "", "if", "step", "and", "(", "step", "%", "params", ".", "validation_ppl_freq", ")", "==", "0", ":", "\n", "\t\t\t\t", "ppl_model", "=", "True", "\n", "\n", "this_val_nll", "=", "[", "]", "\n", "this_val_loss_normed", "=", "[", "]", "\n", "# val_loss_unnormed is NLL", "\n", "this_val_nll_bw", "=", "[", "]", "\n", "this_val_loss_normed_bw", "=", "[", "]", "\n", "\n", "this_val_disc_accuracy", "=", "[", "]", "\n", "\n", "for", "val_indices", ",", "val_y", ",", "val_x", ",", "val_seq_lengths", "in", "dataset", ".", "batches", "(", "'validation_docnade'", ",", "params", ".", "validation_bs", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "True", ",", "multilabel", "=", "params", ".", "multi_label", ")", ":", "\n", "\t\t\t\t\t", "val_feed_dict", "=", "{", "\n", "model", ".", "x", ":", "val_x", ",", "\n", "model", ".", "y", ":", "val_y", ",", "\n", "model", ".", "seq_lengths", ":", "val_seq_lengths", "\n", "}", "\n", "\n", "if", "params", ".", "use_bert_prior", ":", "\n", "\t\t\t\t\t\t", "val_x_bert", "=", "get_bert_input", "(", "docnade_bert_reps", "[", "\"validation_docnade\"", "]", ",", "val_indices", ",", "val_x", ".", "shape", "[", "1", "]", ")", "\n", "val_feed_dict", "[", "model", ".", "x_bert", "]", "=", "val_x_bert", "\n", "\n", "", "val_loss_normed", ",", "val_loss_unnormed", "=", "session", ".", "run", "(", "[", "model", ".", "loss_normed", ",", "model", ".", "loss_unnormed", "]", ",", "feed_dict", "=", "val_feed_dict", ")", "\n", "\n", "this_val_nll", ".", "append", "(", "val_loss_unnormed", ")", "\n", "this_val_loss_normed", ".", "append", "(", "val_loss_normed", ")", "\n", "\n", "", "total_val_nll", "=", "np", ".", "mean", "(", "this_val_nll", ")", "\n", "total_val_ppl", "=", "np", ".", "exp", "(", "np", ".", "mean", "(", "this_val_loss_normed", ")", ")", "\n", "\n", "if", "total_val_ppl", "<", "best_val_ppl", ":", "\n", "\t\t\t\t\t", "best_val_ppl", "=", "total_val_ppl", "\n", "print", "(", "'saving: {}'", ".", "format", "(", "model_dir_ppl", ")", ")", "\n", "saver", ".", "save", "(", "session", ",", "model_dir_ppl", "+", "'/model_ppl'", ",", "global_step", "=", "1", ")", "\n", "\n", "# Early stopping", "\n", "", "if", "total_val_nll", "<", "best_val_nll", ":", "\n", "\t\t\t\t\t", "best_val_nll", "=", "total_val_nll", "\n", "patience_count", "=", "0", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "patience_count", "+=", "1", "\n", "\n", "", "print", "(", "'This val PPL: {:.3f} (best val PPL: {:.3f},  best val loss: {:.3f}'", ".", "format", "(", "\n", "total_val_ppl", ",", "\n", "best_val_ppl", "or", "0.0", ",", "\n", "best_val_nll", "\n", ")", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"training_info.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t", "f", ".", "write", "(", "\"Step: %i,\tval PPL: %s,\t best val PPL: %s,\tbest val loss: %s\\n\"", "%", "\n", "(", "step", ",", "total_val_ppl", ",", "best_val_ppl", ",", "best_val_nll", ")", ")", "\n", "\n", "", "if", "patience_count", ">", "patience", ":", "\n", "\t\t\t\t\t", "print", "(", "\"Early stopping criterion satisfied.\"", ")", "\n", "break", "\n", "\n", "", "", "if", "step", "and", "(", "step", "%", "params", ".", "validation_ir_freq", ")", "==", "0", ":", "\n", "\t\t\t\t", "ir_model", "=", "True", "\n", "\n", "validation_vectors", "=", "m", ".", "vectors", "(", "\n", "model", ",", "\n", "dataset", ".", "batches", "(", "\n", "'validation_docnade'", ",", "\n", "params", ".", "batch_size", ",", "\n", "num_epochs", "=", "1", ",", "\n", "shuffle", "=", "True", ",", "\n", "multilabel", "=", "params", ".", "multi_label", "\n", ")", ",", "\n", "session", ",", "\n", "params", ",", "\n", "vocab", "=", "vocab", ",", "\n", "bert_reps", "=", "docnade_bert_reps", "[", "\"validation_docnade\"", "]", "\n", ")", "\n", "\n", "training_vectors", "=", "m", ".", "vectors", "(", "\n", "model", ",", "\n", "dataset", ".", "batches", "(", "\n", "'training_docnade'", ",", "\n", "params", ".", "batch_size", ",", "\n", "num_epochs", "=", "1", ",", "\n", "shuffle", "=", "True", ",", "\n", "multilabel", "=", "params", ".", "multi_label", "\n", ")", ",", "\n", "session", ",", "\n", "params", ",", "\n", "vocab", "=", "vocab", ",", "\n", "bert_reps", "=", "docnade_bert_reps", "[", "\"training_docnade\"", "]", "\n", ")", "\n", "\n", "val", "=", "eval", ".", "evaluate", "(", "\n", "training_vectors", ",", "\n", "validation_vectors", ",", "\n", "training_labels", ",", "\n", "validation_labels", ",", "\n", "recall", "=", "[", "0.02", "]", ",", "\n", "num_classes", "=", "params", ".", "num_classes", ",", "\n", "multi_label", "=", "params", ".", "multi_label", "\n", ")", "[", "0", "]", "\n", "\n", "if", "val", ">", "best_val_IR", ":", "\n", "\t\t\t\t\t", "best_val_IR", "=", "val", "\n", "print", "(", "'saving: {}'", ".", "format", "(", "model_dir_ir", ")", ")", "\n", "saver", ".", "save", "(", "session", ",", "model_dir_ir", "+", "'/model_ir'", ",", "global_step", "=", "1", ")", "\n", "patience_count_ir", "=", "0", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "patience_count_ir", "+=", "1", "\n", "\n", "", "print", "(", "'This val IR: {:.3f} (best val IR: {:.3f})'", ".", "format", "(", "\n", "val", ",", "\n", "best_val_IR", "or", "0.0", "\n", ")", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"training_info.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t", "f", ".", "write", "(", "\"Step: %i,\tval IR: %s,\tbest val IR: %s\\n\"", "%", "\n", "(", "step", ",", "val", ",", "best_val_IR", ")", ")", "\n", "\n", "", "if", "patience_count_ir", ">", "patience", ":", "\n", "\t\t\t\t\t", "print", "(", "\"Early stopping criterion satisfied.\"", ")", "\n", "break", "\n", "\n", "", "", "", "if", "ppl_model", ":", "\n", "\t\t\t", "saver", ".", "restore", "(", "session", ",", "tf", ".", "train", ".", "latest_checkpoint", "(", "model_dir_ppl", ")", ")", "\n", "\n", "## validation set ppl", "\n", "\n", "this_val_nll", "=", "[", "]", "\n", "this_val_loss_normed", "=", "[", "]", "\n", "# val_loss_unnormed is NLL", "\n", "\n", "for", "val_indices", ",", "val_y", ",", "val_x", ",", "val_seq_lengths", "in", "dataset", ".", "batches", "(", "'validation_docnade'", ",", "params", ".", "validation_bs", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ",", "multilabel", "=", "params", ".", "multi_label", ")", ":", "\n", "\t\t\t\t", "val_feed_dict", "=", "{", "\n", "model", ".", "x", ":", "val_x", ",", "\n", "model", ".", "y", ":", "val_y", ",", "\n", "model", ".", "seq_lengths", ":", "val_seq_lengths", "\n", "}", "\n", "\n", "if", "params", ".", "use_bert_prior", ":", "\n", "\t\t\t\t\t", "val_x_bert", "=", "get_bert_input", "(", "docnade_bert_reps", "[", "\"validation_docnade\"", "]", ",", "val_indices", ",", "val_x", ".", "shape", "[", "1", "]", ")", "\n", "val_feed_dict", "[", "model", ".", "x_bert", "]", "=", "val_x_bert", "\n", "\n", "", "val_loss_normed", ",", "val_loss_unnormed", "=", "session", ".", "run", "(", "[", "model", ".", "loss_normed", ",", "model", ".", "loss_unnormed", "]", ",", "feed_dict", "=", "val_feed_dict", ")", "\n", "\n", "this_val_nll", ".", "append", "(", "val_loss_unnormed", ")", "\n", "this_val_loss_normed", ".", "append", "(", "val_loss_normed", ")", "\n", "\n", "", "total_val_nll", "=", "np", ".", "mean", "(", "this_val_nll", ")", "\n", "total_val_ppl", "=", "np", ".", "exp", "(", "np", ".", "mean", "(", "this_val_loss_normed", ")", ")", "\n", "\n", "## test set ppl", "\n", "\n", "this_test_nll", "=", "[", "]", "\n", "this_test_loss_normed", "=", "[", "]", "\n", "# test_loss_unnormed is NLL", "\n", "\n", "for", "test_indices", ",", "test_y", ",", "test_x", ",", "test_seq_lengths", "in", "dataset", ".", "batches", "(", "'test_docnade'", ",", "params", ".", "validation_bs", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ",", "multilabel", "=", "params", ".", "multi_label", ")", ":", "\n", "\t\t\t\t", "test_feed_dict", "=", "{", "\n", "model", ".", "x", ":", "test_x", ",", "\n", "model", ".", "y", ":", "test_y", ",", "\n", "model", ".", "seq_lengths", ":", "test_seq_lengths", "\n", "}", "\n", "\n", "if", "params", ".", "use_bert_prior", ":", "\n", "\t\t\t\t\t", "test_x_bert", "=", "get_bert_input", "(", "docnade_bert_reps", "[", "\"test_docnade\"", "]", ",", "test_indices", ",", "test_x", ".", "shape", "[", "1", "]", ")", "\n", "test_feed_dict", "[", "model", ".", "x_bert", "]", "=", "test_x_bert", "\n", "\n", "", "test_loss_normed", ",", "test_loss_unnormed", "=", "session", ".", "run", "(", "[", "model", ".", "loss_normed", ",", "model", ".", "loss_unnormed", "]", ",", "feed_dict", "=", "test_feed_dict", ")", "\n", "\n", "this_test_nll", ".", "append", "(", "test_loss_unnormed", ")", "\n", "this_test_loss_normed", ".", "append", "(", "test_loss_normed", ")", "\n", "\n", "", "total_test_nll", "=", "np", ".", "mean", "(", "this_test_nll", ")", "\n", "total_test_ppl", "=", "np", ".", "exp", "(", "np", ".", "mean", "(", "this_test_loss_normed", ")", ")", "\n", "\n", "print", "(", "'Val PPL: {:.3f},    Test PPL: {:.3f}'", ".", "format", "(", "\n", "total_val_ppl", ",", "\n", "total_test_ppl", "\n", ")", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t\t", "f", ".", "write", "(", "\"\\nVal PPL: %s,\t Test PPL: %s\\n\"", "%", "\n", "(", "total_val_ppl", ",", "total_test_ppl", ")", ")", "\n", "\n", "# Topics with W matrix", "\n", "", "W_target", "=", "session", ".", "run", "(", "\"embedding:0\"", ")", "\n", "\n", "top_n_topic_words", "=", "20", "\n", "w_h_top_words_indices", "=", "[", "]", "\n", "W_topics", "=", "W_target", "\n", "topics_list_W", "=", "[", "]", "\n", "\n", "for", "h_num", "in", "range", "(", "np", ".", "array", "(", "W_topics", ")", ".", "shape", "[", "1", "]", ")", ":", "\n", "\t\t\t\t", "w_h_top_words_indices", ".", "append", "(", "np", ".", "argsort", "(", "W_topics", "[", ":", ",", "h_num", "]", ")", "[", ":", ":", "-", "1", "]", "[", ":", "top_n_topic_words", "]", ")", "\n", "\n", "", "with", "open", "(", "params", ".", "docnadeVocab", ",", "'r'", ")", "as", "f", ":", "\n", "\t\t\t\t", "vocab_docnade", "=", "[", "w", ".", "strip", "(", ")", "for", "w", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"topics_ppl_W.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t\t", "for", "w_h_top_words_indx", ",", "h_num", "in", "zip", "(", "w_h_top_words_indices", ",", "range", "(", "len", "(", "w_h_top_words_indices", ")", ")", ")", ":", "\n", "\t\t\t\t\t", "w_h_top_words", "=", "[", "vocab_docnade", "[", "w_indx", "]", "for", "w_indx", "in", "w_h_top_words_indx", "]", "\n", "\n", "topics_list_W", ".", "append", "(", "w_h_top_words", ")", "\n", "\n", "print", "(", "'h_num: %s'", "%", "h_num", ")", "\n", "print", "(", "'w_h_top_words_indx: %s'", "%", "w_h_top_words_indx", ")", "\n", "print", "(", "'w_h_top_words:%s'", "%", "w_h_top_words", ")", "\n", "print", "(", "'----------------------------------------------------------------------'", ")", "\n", "\n", "f", ".", "write", "(", "'h_num: %s\\n'", "%", "h_num", ")", "\n", "f", ".", "write", "(", "'w_h_top_words_indx: %s\\n'", "%", "w_h_top_words_indx", ")", "\n", "f", ".", "write", "(", "'w_h_top_words:%s\\n'", "%", "w_h_top_words", ")", "\n", "f", ".", "write", "(", "'----------------------------------------------------------------------\\n'", ")", "\n", "\n", "# TOPIC COHERENCE", "\n", "\n", "", "", "top_n_word_in_each_topic_list", "=", "[", "5", ",", "10", ",", "15", ",", "20", "]", "\n", "\n", "text_filenames", "=", "[", "\n", "params", ".", "trainfile", ",", "\n", "params", ".", "valfile", ",", "\n", "params", ".", "testfile", "\n", "]", "\n", "\n", "# read original text documents as list of words", "\n", "texts", "=", "[", "]", "\n", "\n", "for", "file", "in", "text_filenames", ":", "\n", "\t\t\t\t", "print", "(", "'filename:%s'", ",", "file", ")", "\n", "for", "line", "in", "open", "(", "file", ",", "'r'", ")", ".", "readlines", "(", ")", ":", "\n", "\t\t\t\t\t", "document", "=", "str", "(", "line", ")", ".", "strip", "(", ")", "\n", "texts", ".", "append", "(", "document", ".", "split", "(", ")", ")", "\n", "\n", "", "", "compute_coherence", "(", "texts", ",", "topics_list_W", ",", "top_n_word_in_each_topic_list", ",", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"topics_coherence_W.txt\"", ")", ")", "\n", "\n", "", "if", "ir_model", ":", "\n", "\t\t\t", "saver", ".", "restore", "(", "session", ",", "tf", ".", "train", ".", "latest_checkpoint", "(", "model_dir_ir", ")", ")", "\n", "\n", "ir_ratio_list", "=", "[", "0.0001", ",", "0.0005", ",", "0.001", ",", "0.002", ",", "0.005", ",", "0.01", ",", "0.02", ",", "0.05", ",", "0.1", ",", "0.2", ",", "0.3", ",", "0.5", ",", "0.8", ",", "1.0", "]", "\n", "#ir_ratio_list = [0.02]", "\n", "\n", "validation_vectors", "=", "m", ".", "vectors", "(", "\n", "model", ",", "\n", "dataset", ".", "batches", "(", "\n", "'validation_docnade'", ",", "\n", "params", ".", "batch_size", ",", "\n", "num_epochs", "=", "1", ",", "\n", "shuffle", "=", "True", ",", "\n", "multilabel", "=", "params", ".", "multi_label", "\n", ")", ",", "\n", "session", ",", "\n", "params", ",", "\n", "vocab", "=", "vocab", ",", "\n", "bert_reps", "=", "docnade_bert_reps", "[", "\"validation_docnade\"", "]", "\n", ")", "\n", "\n", "test_vectors", "=", "m", ".", "vectors", "(", "\n", "model", ",", "\n", "dataset", ".", "batches", "(", "\n", "'test_docnade'", ",", "\n", "params", ".", "batch_size", ",", "\n", "num_epochs", "=", "1", ",", "\n", "shuffle", "=", "True", ",", "\n", "multilabel", "=", "params", ".", "multi_label", "\n", ")", ",", "\n", "session", ",", "\n", "params", ",", "\n", "vocab", "=", "vocab", ",", "\n", "bert_reps", "=", "docnade_bert_reps", "[", "\"test_docnade\"", "]", "\n", ")", "\n", "\n", "training_vectors", "=", "m", ".", "vectors", "(", "\n", "model", ",", "\n", "dataset", ".", "batches", "(", "\n", "'training_docnade'", ",", "\n", "params", ".", "batch_size", ",", "\n", "num_epochs", "=", "1", ",", "\n", "shuffle", "=", "True", ",", "\n", "multilabel", "=", "params", ".", "multi_label", "\n", ")", ",", "\n", "session", ",", "\n", "params", ",", "\n", "vocab", "=", "vocab", ",", "\n", "bert_reps", "=", "docnade_bert_reps", "[", "\"training_docnade\"", "]", "\n", ")", "\n", "\n", "val", "=", "eval", ".", "evaluate", "(", "\n", "training_vectors", ",", "\n", "validation_vectors", ",", "\n", "training_labels", ",", "\n", "validation_labels", ",", "\n", "recall", "=", "ir_ratio_list", ",", "\n", "num_classes", "=", "params", ".", "num_classes", ",", "\n", "multi_label", "=", "params", ".", "multi_label", "\n", ")", "\n", "\n", "test", "=", "eval", ".", "evaluate", "(", "\n", "training_vectors", ",", "\n", "test_vectors", ",", "\n", "training_labels", ",", "\n", "test_labels", ",", "\n", "recall", "=", "ir_ratio_list", ",", "\n", "num_classes", "=", "params", ".", "num_classes", ",", "\n", "multi_label", "=", "params", ".", "multi_label", "\n", ")", "\n", "\n", "print", "(", "'This val IR: %s,    \\nbest test IR: %s'", "%", "(", "val", ",", "test", ")", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"training_info.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t\t", "f", ".", "write", "(", "\"IR Ratio: %s\"", "%", "ir_ratio_list", ")", "\n", "f", ".", "write", "(", "\"\\nval IR: %s,\t\\ntest IR: %s\"", "%", "(", "val", ",", "test", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.compute_coherence": [[519, 579], ["gensim.corpora.dictionary.Dictionary", "print", "print", "gensim.corpora.dictionary.Dictionary.doc2bow", "open", "len", "print", "print", "f.write", "f.write", "print", "print", "f.write", "f.write", "print", "print", "f.write", "gensim.models.CoherenceModel().get_coherence", "avg_coh_scores_dict[].append", "print", "f.write", "print", "numpy.mean", "numpy.mean", "gensim.models.CoherenceModel"], "function", ["None"], ["def", "compute_coherence", "(", "texts", ",", "list_of_topics", ",", "top_n_word_in_each_topic_list", ",", "reload_model_dir", ")", ":", "\n", "\n", "\t", "dictionary", "=", "Dictionary", "(", "texts", ")", "\n", "corpus", "=", "[", "dictionary", ".", "doc2bow", "(", "text", ")", "for", "text", "in", "texts", "]", "\n", "\n", "print", "(", "'corpus len:%s'", "%", "len", "(", "corpus", ")", ")", "\n", "print", "(", "'dictionary:%s'", "%", "dictionary", ")", "\n", "# https://github.com/earthquakesan/palmetto-py", "\n", "# compute_topic_coherence: PMI and other coherence types", "\n", "# from palmettopy.palmetto import Palmetto", "\n", "# palmetto = Palmetto()", "\n", "\n", "# coherence_types = [\"ca\", \"cp\", \"cv\", \"npmi\", \"uci\", \"umass\"] # for palmetto library", "\n", "coherence_types", "=", "[", "\"c_v\"", "]", "#, 'u_mass', 'c_v', 'c_uci', 'c_npmi'] # [\"c_v\"] # 'u_mass', 'c_v', 'c_uci', 'c_npmi',", "\n", "avg_coh_scores_dict", "=", "{", "}", "\n", "\n", "best_coh_type_value_topci_indx", "=", "{", "}", "\n", "for", "top_n", "in", "top_n_word_in_each_topic_list", ":", "\n", "\t\t", "avg_coh_scores_dict", "[", "top_n", "]", "=", "[", "]", "\n", "best_coh_type_value_topci_indx", "[", "top_n", "]", "=", "[", "0", ",", "0", ",", "[", "]", "]", "# score, topic_indx, topics words", "\n", "\n", "\n", "", "h_num", "=", "0", "\n", "with", "open", "(", "reload_model_dir", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t", "for", "topic_words_all", "in", "list_of_topics", ":", "\n", "\t\t\t", "h_num", "+=", "1", "\n", "for", "top_n", "in", "top_n_word_in_each_topic_list", ":", "\n", "\t\t\t\t", "topic_words", "=", "[", "topic_words_all", "[", ":", "top_n", "]", "]", "\n", "for", "coh_type", "in", "coherence_types", ":", "\n", "\t\t\t\t\t", "try", ":", "\n", "\t\t\t\t\t\t", "print", "(", "'top_n: %s Topic Num: %s \\nTopic Words: %s'", "%", "(", "top_n", ",", "h_num", ",", "topic_words", ")", ")", "\n", "f", ".", "write", "(", "'top_n: %s Topic Num: %s \\nTopic Words: %s\\n'", "%", "(", "top_n", ",", "h_num", ",", "topic_words", ")", ")", "\n", "# print('topic_words_top_10_abs[%s]:%s' % (h_num, topic_words_top_10_abs[h_num]))", "\n", "# PMI = palmetto.get_coherence(topic_words_top_10[h_num], coherence_type=coh_type)", "\n", "PMI", "=", "CoherenceModel", "(", "topics", "=", "topic_words", ",", "texts", "=", "texts", ",", "dictionary", "=", "dictionary", ",", "coherence", "=", "coh_type", ",", "processes", "=", "2", ")", ".", "get_coherence", "(", ")", "\n", "\n", "avg_coh_scores_dict", "[", "top_n", "]", ".", "append", "(", "PMI", ")", "\n", "\n", "if", "PMI", ">", "best_coh_type_value_topci_indx", "[", "top_n", "]", "[", "0", "]", ":", "\n", "\t\t\t\t\t\t\t", "best_coh_type_value_topci_indx", "[", "top_n", "]", "=", "[", "PMI", ",", "top_n", ",", "topic_words", "]", "\n", "\n", "", "print", "(", "'Coh_type:%s  Topic Num:%s COH score:%s'", "%", "(", "coh_type", ",", "h_num", ",", "PMI", ")", ")", "\n", "f", ".", "write", "(", "'Coh_type:%s  Topic Num:%s COH score:%s\\n'", "%", "(", "coh_type", ",", "h_num", ",", "PMI", ")", ")", "\n", "\n", "print", "(", "'--------------------------------------------------------------'", ")", "\n", "", "except", ":", "\n", "\t\t\t\t\t\t", "continue", "\n", "", "", "print", "(", "'========================================================================================================'", ")", "\n", "\n", "", "", "for", "top_n", "in", "top_n_word_in_each_topic_list", ":", "\n", "\t\t\t", "print", "(", "'top scores for top_%s:%s'", "%", "(", "top_n", ",", "best_coh_type_value_topci_indx", "[", "top_n", "]", ")", ")", "\n", "print", "(", "'-------------------------------------------------------------------'", ")", "\n", "f", ".", "write", "(", "'top scores for top_%s:%s\\n'", "%", "(", "top_n", ",", "best_coh_type_value_topci_indx", "[", "top_n", "]", ")", ")", "\n", "f", ".", "write", "(", "'-------------------------------------------------------------------\\n'", ")", "\n", "\n", "", "for", "top_n", "in", "top_n_word_in_each_topic_list", ":", "\n", "\t\t\t", "print", "(", "'Avg COH for top_%s topic words: %s'", "%", "(", "top_n", ",", "np", ".", "mean", "(", "avg_coh_scores_dict", "[", "top_n", "]", ")", ")", ")", "\n", "print", "(", "'-------------------------------------------------------------------'", ")", "\n", "f", ".", "write", "(", "'Avg COH for top_%s topic words: %s\\n'", "%", "(", "top_n", ",", "np", ".", "mean", "(", "avg_coh_scores_dict", "[", "top_n", "]", ")", ")", ")", "\n", "f", ".", "write", "(", "'-------------------------------------------------------------------\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.get_vectors_from_matrix": [[580, 590], ["numpy.array", "numpy.zeros", "vecs.append"], "function", ["None"], ["", "", "", "def", "get_vectors_from_matrix", "(", "matrix", ",", "batches", ")", ":", "\n", "# matrix: embedding matrix of shape = [vocab_size X embedding_size]", "\n", "\t", "vecs", "=", "[", "]", "\n", "for", "_", ",", "x", ",", "seq_length", "in", "batches", ":", "\n", "\t\t", "temp_vec", "=", "np", ".", "zeros", "(", "(", "matrix", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "indices", "=", "x", "[", "0", ",", ":", "seq_length", "[", "0", "]", "]", "\n", "for", "index", "in", "indices", ":", "\n", "\t\t\t", "temp_vec", "+=", "matrix", "[", "index", ",", ":", "]", "\n", "", "vecs", ".", "append", "(", "temp_vec", ")", "\n", "", "return", "np", ".", "array", "(", "vecs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.softmax": [[591, 633], ["numpy.atleast_2d", "numpy.exp", "numpy.expand_dims", "next", "float", "numpy.expand_dims", "numpy.sum", "len", "p.flatten.flatten", "numpy.max", "enumerate"], "function", ["None"], ["", "def", "softmax", "(", "X", ",", "theta", "=", "1.0", ",", "axis", "=", "None", ")", ":", "\n", "\t", "\"\"\"\n\tCompute the softmax of each element along an axis of X.\n\n\tParameters\n\t----------\n\tX: ND-Array. Probably should be floats. \n\ttheta (optional): float parameter, used as a multiplier\n\t\tprior to exponentiation. Default = 1.0\n\taxis (optional): axis to compute values along. Default is the \n\t\tfirst non-singleton axis.\n\n\tReturns an array the same size as X. The result will sum to 1\n\talong the specified axis.\n\t\"\"\"", "\n", "\n", "# make X at least 2d", "\n", "y", "=", "np", ".", "atleast_2d", "(", "X", ")", "\n", "\n", "# find axis", "\n", "if", "axis", "is", "None", ":", "\n", "\t\t", "axis", "=", "next", "(", "j", "[", "0", "]", "for", "j", "in", "enumerate", "(", "y", ".", "shape", ")", "if", "j", "[", "1", "]", ">", "1", ")", "\n", "\n", "# multiply y against the theta parameter, ", "\n", "", "y", "=", "y", "*", "float", "(", "theta", ")", "\n", "\n", "# subtract the max for numerical stability", "\n", "y", "=", "y", "-", "np", ".", "expand_dims", "(", "np", ".", "max", "(", "y", ",", "axis", "=", "axis", ")", ",", "axis", ")", "\n", "\n", "# exponentiate y", "\n", "y", "=", "np", ".", "exp", "(", "y", ")", "\n", "\n", "# take the sum along the specified axis", "\n", "ax_sum", "=", "np", ".", "expand_dims", "(", "np", ".", "sum", "(", "y", ",", "axis", "=", "axis", ")", ",", "axis", ")", "\n", "\n", "# finally: divide elementwise", "\n", "p", "=", "y", "/", "ax_sum", "\n", "\n", "# flatten if X was 1D", "\n", "if", "len", "(", "X", ".", "shape", ")", "==", "1", ":", "p", "=", "p", ".", "flatten", "(", ")", "\n", "\n", "return", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.square_rooted": [[637, 639], ["round", "sqrt", "sum"], "function", ["None"], ["def", "square_rooted", "(", "x", ")", ":", "\n", "\t", "return", "round", "(", "sqrt", "(", "sum", "(", "[", "a", "*", "a", "for", "a", "in", "x", "]", ")", ")", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.cosine_similarity": [[640, 644], ["sum", "round", "train_DocNADE_MVT_MST.square_rooted", "train_DocNADE_MVT_MST.square_rooted", "float", "zip"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.square_rooted", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.square_rooted"], ["", "def", "cosine_similarity", "(", "x", ",", "y", ")", ":", "\n", "\t", "numerator", "=", "sum", "(", "a", "*", "b", "for", "a", ",", "b", "in", "zip", "(", "x", ",", "y", ")", ")", "\n", "denominator", "=", "square_rooted", "(", "x", ")", "*", "square_rooted", "(", "y", ")", "\n", "return", "round", "(", "numerator", "/", "float", "(", "denominator", ")", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.reload_evaluation_ir": [[646, 680], ["model.Dataset", "os.path.join", "numpy.array", "numpy.array", "pdb.set_trace", "model.evaluate", "open", "f.write", "f.write", "os.path.join", "data.Dataset.rows", "data.Dataset.rows"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.evaluate.evaluate", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.rows", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.rows"], ["", "def", "reload_evaluation_ir", "(", "params", ",", "training_vectors", ",", "test_vectors", ",", "W_matrix", ",", "suffix", "=", "\"\"", ")", ":", "\n", "\n", "### Information Retrieval", "\n", "\n", "\t\t", "dataset", "=", "data", ".", "Dataset", "(", "params", "[", "'dataset'", "]", ")", "\n", "#log_dir = os.path.join(params['model'], 'logs')", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "\"model\"", ",", "params", "[", "'reload_model_dir'", "]", ",", "'logs'", ")", "\n", "\n", "ir_ratio_list", "=", "[", "0.0001", ",", "0.0005", ",", "0.001", ",", "0.002", ",", "0.005", ",", "0.01", ",", "0.02", ",", "0.05", ",", "0.1", ",", "0.2", ",", "0.3", ",", "0.5", ",", "0.8", ",", "1.0", "]", "\n", "#ir_ratio_list = [0.02]", "\n", "\n", "training_labels", "=", "np", ".", "array", "(", "\n", "[", "[", "row", "[", "0", "]", "]", "for", "index", ",", "row", "in", "dataset", ".", "rows", "(", "'training_docnade'", ",", "num_epochs", "=", "1", ")", "]", "\n", ")", "\n", "\n", "test_labels", "=", "np", ".", "array", "(", "\n", "[", "[", "row", "[", "0", "]", "]", "for", "index", ",", "row", "in", "dataset", ".", "rows", "(", "'test_docnade'", ",", "num_epochs", "=", "1", ")", "]", "\n", ")", "\n", "\n", "import", "pdb", ";", "pdb", ".", "set_trace", "(", ")", "\n", "test_ir_list", "=", "eval", ".", "evaluate", "(", "\n", "training_vectors", ",", "\n", "test_vectors", ",", "\n", "training_labels", ",", "\n", "test_labels", ",", "\n", "recall", "=", "ir_ratio_list", ",", "\n", "num_classes", "=", "params", "[", "'num_classes'", "]", ",", "\n", "multi_label", "=", "params", "[", "'multi_label'", "]", "\n", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_ir.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"\\n\\nFractions list: %s\"", "%", "(", "ir_ratio_list", ")", ")", "\n", "f", ".", "write", "(", "\"\\nTest IR: %s\"", "%", "(", "test_ir_list", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.reload_evaluation_ppl": [[682, 803], ["tensorflow.Session", "model.Dataset", "os.path.join", "tensorflow.train.import_meta_graph", "tf.train.import_meta_graph.restore", "tensorflow.get_default_graph", "tf.get_default_graph.get_tensor_by_name", "tf.get_default_graph.get_tensor_by_name", "tf.get_default_graph.get_tensor_by_name", "tf.get_default_graph.get_tensor_by_name", "tf.get_default_graph.get_tensor_by_name", "data.Dataset.batches", "numpy.mean", "numpy.exp", "print", "data.Dataset.batches", "numpy.mean", "numpy.exp", "print", "session_ppl.run", "sklearn.cosine_similarity", "session_ppl.run", "session_ppl.run", "session_ppl.run", "tensorflow.train.latest_checkpoint", "open", "session_ppl.run", "this_val_nll.append", "this_val_loss_normed.append", "numpy.mean", "open", "f.write", "session_ppl.run", "this_test_nll.append", "this_test_loss_normed.append", "numpy.mean", "open", "f.write", "open", "numpy.argsort", "open", "enumerate", "tensorflow.ConfigProto", "line.strip", "os.path.join", "os.path.join", "w.strip", "f.write", "f.readlines", "f.readlines", "numpy.arange", "numpy.arange", "tensorflow.GPUOptions", "len", "len", "str"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.cosine_similarity"], ["", "", "def", "reload_evaluation_ppl", "(", "params", ",", "suffix", "=", "\"\"", ")", ":", "\n", "\t", "with", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "inter_op_parallelism_threads", "=", "params", "[", "'num_cores'", "]", ",", "\n", "intra_op_parallelism_threads", "=", "params", "[", "'num_cores'", "]", ",", "\n", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "allow_growth", "=", "True", ")", "\n", ")", ")", "as", "session_ppl", ":", "\n", "\n", "\t\t", "dataset", "=", "data", ".", "Dataset", "(", "params", "[", "'dataset'", "]", ")", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "params", "[", "'model'", "]", ",", "'logs'", ")", "\n", "\n", "saver_ppl", "=", "tf", ".", "train", ".", "import_meta_graph", "(", "\"./model/\"", "+", "params", "[", "'reload_model_dir'", "]", "+", "\"/model_ppl/model_ppl-1.meta\"", ")", "\n", "saver_ppl", ".", "restore", "(", "session_ppl", ",", "tf", ".", "train", ".", "latest_checkpoint", "(", "\"./model/\"", "+", "params", "[", "'reload_model_dir'", "]", "+", "\"/model_ppl/\"", ")", ")", "\n", "\n", "graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", "\n", "x", "=", "graph", ".", "get_tensor_by_name", "(", "\"x:0\"", ")", "\n", "y", "=", "graph", ".", "get_tensor_by_name", "(", "\"y:0\"", ")", "\n", "seq_lengths", "=", "graph", ".", "get_tensor_by_name", "(", "\"seq_lengths:0\"", ")", "\n", "loss_normed", "=", "graph", ".", "get_tensor_by_name", "(", "\"loss_normed_x:0\"", ")", "\n", "loss_unnormed", "=", "graph", ".", "get_tensor_by_name", "(", "\"loss_unnormed_x:0\"", ")", "\n", "\n", "with", "open", "(", "params", "[", "'dataset'", "]", "+", "\"/vocab_docnade.vocab\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t", "vocab", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "# TODO: Validation PPL", "\n", "\n", "", "this_val_nll", "=", "[", "]", "\n", "this_val_loss_normed", "=", "[", "]", "\n", "# val_loss_unnormed is NLL", "\n", "this_val_nll_bw", "=", "[", "]", "\n", "this_val_loss_normed_bw", "=", "[", "]", "\n", "\n", "this_val_disc_accuracy", "=", "[", "]", "\n", "\n", "for", "val_indices", ",", "val_y", ",", "val_x", ",", "val_seq_lengths", "in", "dataset", ".", "batches", "(", "'validation_docnade'", ",", "params", "[", "'validation_bs'", "]", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ",", "multilabel", "=", "params", "[", "'multi_label'", "]", ")", ":", "\n", "\t\t\t", "val_feed_dict", "=", "{", "\n", "x", ":", "val_x", ",", "\n", "y", ":", "val_y", ",", "\n", "seq_lengths", ":", "val_seq_lengths", "\n", "}", "\n", "\n", "val_loss_normed", ",", "val_loss_unnormed", "=", "session_ppl", ".", "run", "(", "[", "loss_normed", ",", "loss_unnormed", "]", ",", "feed_dict", "=", "val_feed_dict", ")", "\n", "\n", "this_val_nll", ".", "append", "(", "val_loss_unnormed", ")", "\n", "this_val_loss_normed", ".", "append", "(", "val_loss_normed", ")", "\n", "\n", "\n", "", "total_val_nll", "=", "np", ".", "mean", "(", "this_val_nll", ")", "\n", "total_val_ppl", "=", "np", ".", "exp", "(", "np", ".", "mean", "(", "this_val_loss_normed", ")", ")", "\n", "\n", "print", "(", "'Val PPL: {:.3f},\tVal loss: {:.3f}\\n'", ".", "format", "(", "\n", "total_val_ppl", ",", "\n", "total_val_nll", "\n", ")", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_ppl_\"", "+", "suffix", "+", "\".txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"Val PPL: %s,\tVal loss: %s\"", "%", "\n", "(", "total_val_ppl", ",", "total_val_nll", ")", ")", "\n", "\n", "# TODO: Test PPL", "\n", "\n", "", "this_test_nll", "=", "[", "]", "\n", "this_test_loss_normed", "=", "[", "]", "\n", "this_test_nll_bw", "=", "[", "]", "\n", "this_test_loss_normed_bw", "=", "[", "]", "\n", "this_test_disc_accuracy", "=", "[", "]", "\n", "\n", "for", "test_indices", ",", "test_y", ",", "test_x", ",", "test_seq_lengths", "in", "dataset", ".", "batches", "(", "'test_docnade'", ",", "params", "[", "'test_bs'", "]", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ",", "multilabel", "=", "params", "[", "'multi_label'", "]", ")", ":", "\n", "\t\t\t", "test_feed_dict", "=", "{", "\n", "x", ":", "test_x", ",", "\n", "y", ":", "test_y", ",", "\n", "seq_lengths", ":", "test_seq_lengths", "\n", "}", "\n", "\n", "test_loss_normed", ",", "test_loss_unnormed", "=", "session_ppl", ".", "run", "(", "[", "loss_normed", ",", "loss_unnormed", "]", ",", "feed_dict", "=", "test_feed_dict", ")", "\n", "\n", "this_test_nll", ".", "append", "(", "test_loss_unnormed", ")", "\n", "this_test_loss_normed", ".", "append", "(", "test_loss_normed", ")", "\n", "\n", "", "total_test_nll", "=", "np", ".", "mean", "(", "this_test_nll", ")", "\n", "total_test_ppl", "=", "np", ".", "exp", "(", "np", ".", "mean", "(", "this_test_loss_normed", ")", ")", "\n", "\n", "print", "(", "'Test PPL: {:.3f},\tTest loss: {:.3f}\\n'", ".", "format", "(", "\n", "total_test_ppl", ",", "\n", "total_test_nll", "\n", ")", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_ppl_\"", "+", "suffix", "+", "\".txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"\\n\\nTest PPL: %s,\tTest loss: %s\"", "%", "\n", "(", "total_test_ppl", ",", "total_test_nll", ")", ")", "\n", "\n", "", "W_target", "=", "session_ppl", ".", "run", "(", "\"embedding:0\"", ")", "\n", "\n", "top_n_words", "=", "20", "\n", "\n", "# Nearest Neighbors", "\n", "with", "open", "(", "params", "[", "'docnadeVocab'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "\t\t\t", "vocab_docnade", "=", "[", "w", ".", "strip", "(", ")", "for", "w", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "W", "=", "W_target", "\n", "\n", "sim_mat", "=", "pw", ".", "cosine_similarity", "(", "W", ",", "W", ")", "\n", "sim_mat", "[", "np", ".", "arange", "(", "len", "(", "vocab_docnade", ")", ")", ",", "np", ".", "arange", "(", "len", "(", "vocab_docnade", ")", ")", "]", "=", "-", "1.0", "\n", "\n", "sorted_indices", "=", "np", ".", "argsort", "(", "sim_mat", ",", "axis", "=", "1", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "\n", "with", "open", "(", "log_dir", "+", "\"/nearest_neighbours.txt\"", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t", "for", "counter", ",", "indices", "in", "enumerate", "(", "sorted_indices", "[", ":", ",", ":", "top_n_words", "]", ")", ":", "\n", "\t\t\t\t", "query_word", "=", "vocab_docnade", "[", "counter", "]", "\n", "nn_words", "=", "\" | \"", ".", "join", "(", "[", "vocab_docnade", "[", "index", "]", "+", "\" ( \"", "+", "str", "(", "sim_mat", "[", "counter", ",", "index", "]", ")", "+", "\" ) \"", "for", "index", "in", "indices", "]", ")", "\n", "line", "=", "query_word", "+", "\" :: \"", "+", "nn_words", "+", "\"\\n\"", "\n", "f", ".", "write", "(", "line", ")", "\n", "\n", "\n", "", "", "bias_W_target", "=", "session_ppl", ".", "run", "(", "\"bias:0\"", ")", "\n", "U_target", "=", "session_ppl", ".", "run", "(", "\"U:0\"", ")", "\n", "bias_U_target", "=", "session_ppl", ".", "run", "(", "\"b:0\"", ")", "\n", "\n", "return", "W_target", ",", "bias_W_target", ",", "U_target", ",", "bias_U_target", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.reload_evaluation_topics": [[805, 858], ["os.path.join", "range", "train_DocNADE_MVT_MST.compute_coherence", "w_h_top_words_indices.append", "open", "open", "zip", "print", "open().readlines", "os.path.join", "w.strip", "os.path.join", "range", "topics_list_W.append", "print", "print", "print", "print", "f.write", "f.write", "f.write", "f.write", "str().strip", "texts.append", "numpy.array", "f.readlines", "len", "open", "str().strip.split", "numpy.argsort", "str"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.compute_coherence"], ["", "", "def", "reload_evaluation_topics", "(", "W_target", ",", "U_target", ",", "params", ")", ":", "\n", "\n", "\t", "log_dir", "=", "os", ".", "path", ".", "join", "(", "params", "[", "'model'", "]", ",", "'logs'", ")", "\n", "\n", "# Topics with W matrix", "\n", "\n", "top_n_topic_words", "=", "20", "\n", "w_h_top_words_indices", "=", "[", "]", "\n", "W_topics", "=", "W_target", "\n", "topics_list_W", "=", "[", "]", "\n", "\n", "for", "h_num", "in", "range", "(", "np", ".", "array", "(", "W_topics", ")", ".", "shape", "[", "1", "]", ")", ":", "\n", "\t\t", "w_h_top_words_indices", ".", "append", "(", "np", ".", "argsort", "(", "W_topics", "[", ":", ",", "h_num", "]", ")", "[", ":", ":", "-", "1", "]", "[", ":", "top_n_topic_words", "]", ")", "\n", "\n", "", "with", "open", "(", "params", "[", "'docnadeVocab'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "\t\t", "vocab_docnade", "=", "[", "w", ".", "strip", "(", ")", "for", "w", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"topics_ppl_W.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t", "for", "w_h_top_words_indx", ",", "h_num", "in", "zip", "(", "w_h_top_words_indices", ",", "range", "(", "len", "(", "w_h_top_words_indices", ")", ")", ")", ":", "\n", "\t\t\t", "w_h_top_words", "=", "[", "vocab_docnade", "[", "w_indx", "]", "for", "w_indx", "in", "w_h_top_words_indx", "]", "\n", "\n", "topics_list_W", ".", "append", "(", "w_h_top_words", ")", "\n", "\n", "print", "(", "'h_num: %s'", "%", "h_num", ")", "\n", "print", "(", "'w_h_top_words_indx: %s'", "%", "w_h_top_words_indx", ")", "\n", "print", "(", "'w_h_top_words:%s'", "%", "w_h_top_words", ")", "\n", "print", "(", "'----------------------------------------------------------------------'", ")", "\n", "\n", "f", ".", "write", "(", "'h_num: %s\\n'", "%", "h_num", ")", "\n", "f", ".", "write", "(", "'w_h_top_words_indx: %s\\n'", "%", "w_h_top_words_indx", ")", "\n", "f", ".", "write", "(", "'w_h_top_words:%s\\n'", "%", "w_h_top_words", ")", "\n", "f", ".", "write", "(", "'----------------------------------------------------------------------\\n'", ")", "\n", "\n", "# TOPIC COHERENCE", "\n", "\n", "", "", "top_n_word_in_each_topic_list", "=", "[", "5", ",", "10", ",", "15", ",", "20", "]", "\n", "\n", "text_filenames", "=", "[", "\n", "params", "[", "'trainfile'", "]", ",", "\n", "params", "[", "'valfile'", "]", ",", "\n", "params", "[", "'testfile'", "]", "\n", "]", "\n", "\n", "# read original text documents as list of words", "\n", "texts", "=", "[", "]", "\n", "\n", "for", "file", "in", "text_filenames", ":", "\n", "\t\t", "print", "(", "'filename:%s'", ",", "file", ")", "\n", "for", "line", "in", "open", "(", "file", ",", "'r'", ")", ".", "readlines", "(", ")", ":", "\n", "\t\t\t", "document", "=", "str", "(", "line", ")", ".", "strip", "(", ")", "\n", "texts", ".", "append", "(", "document", ".", "split", "(", ")", ")", "\n", "\n", "", "", "compute_coherence", "(", "texts", ",", "topics_list_W", ",", "top_n_word_in_each_topic_list", ",", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"topics_coherence_W.txt\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.str2bool": [[860, 867], ["v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["", "def", "str2bool", "(", "v", ")", ":", "\n", "\t", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "\t\t", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "\t\t", "return", "False", "\n", "", "else", ":", "\n", "\t\t", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.get_prior_matrix": [[869, 887], ["numpy.load", "numpy.zeros", "enumerate", "W_old_matrix.append", "W_old_indices.append", "W_new_indices.append", "numpy.array", "len", "prior_vocab.index"], "function", ["None"], ["", "", "def", "get_prior_matrix", "(", "prior_embedding_path", ",", "prior_vocab", ",", "docnade_vocab", ",", "hidden_size", ")", ":", "\n", "\t", "prior_embedding_matrix", "=", "np", ".", "load", "(", "prior_embedding_path", ")", "\n", "\n", "W_old_indices", "=", "[", "]", "\n", "W_new_indices", "=", "[", "]", "\n", "W_old_matrix", "=", "[", "]", "\n", "prior_matrix", "=", "np", ".", "zeros", "(", "(", "len", "(", "docnade_vocab", ")", ",", "hidden_size", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "docnade_vocab", ")", ":", "\n", "\t\t", "try", ":", "\n", "\t\t\t", "index", "=", "prior_vocab", ".", "index", "(", "word", ")", "\n", "", "except", "ValueError", ":", "\n", "\t\t\t", "continue", "\n", "", "prior_matrix", "[", "i", ",", ":", "]", "=", "prior_embedding_matrix", "[", "index", ",", ":", "]", "\n", "W_old_matrix", ".", "append", "(", "prior_embedding_matrix", "[", "index", ",", ":", "]", ")", "\n", "W_old_indices", ".", "append", "(", "index", ")", "\n", "W_new_indices", ".", "append", "(", "i", ")", "\n", "\n", "", "return", "prior_matrix", ",", "np", ".", "array", "(", "W_old_matrix", ",", "dtype", "=", "np", ".", "float32", ")", ",", "W_old_indices", ",", "W_new_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.main": [[888, 1168], ["train_DocNADE_MVT_MST.str2bool", "train_DocNADE_MVT_MST.str2bool", "train_DocNADE_MVT_MST.str2bool", "train_DocNADE_MVT_MST.str2bool", "train_DocNADE_MVT_MST.str2bool", "train_DocNADE_MVT_MST.str2bool", "train_DocNADE_MVT_MST.str2bool", "train_DocNADE_MVT_MST.str2bool", "train_DocNADE_MVT_MST.str2bool", "train_DocNADE_MVT_MST.str2bool", "os.path.isdir", "os.path.isdir", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "datetime.datetime.now", "model.Dataset", "model.DocNADE_MVT_MST", "print", "train_DocNADE_MVT_MST.train", "open", "json.load", "json.load", "train_DocNADE_MVT_MST.reload_evaluation_ppl", "train_DocNADE_MVT_MST.reload_evaluation_ir", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "str", "str", "os.path.isdir", "os.mkdir", "open", "open", "f.write", "numpy.load", "print", "numpy.load", "print", "enumerate", "print", "numpy.array", "numpy.array", "tensorflow.Session", "tensorflow.train.import_meta_graph", "tf.train.import_meta_graph.restore", "tensorflow.get_default_graph", "tf.get_default_graph.get_tensor_by_name", "tf.get_default_graph.get_tensor_by_name", "tf.get_default_graph.get_tensor_by_name", "tf.get_default_graph.get_tensor_by_name", "model.Dataset", "data.Dataset.batches", "numpy.squeeze", "data.Dataset.batches", "numpy.squeeze", "sess_ir.run", "str", "str", "w.strip", "os.path.join", "json.dumps", "json.dumps", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "open", "pickle.load", "open", "pickle.load", "open", "pickle.load", "pickle.load.items", "pickle.load.items", "pickle.load.items", "train_DocNADE_MVT_MST.get_prior_matrix", "W_embeddings_matrices_list.append", "W_old_matrices_list.append", "W_old_indices_list.append", "W_new_indices_list.append", "tensorflow.train.latest_checkpoint", "sess_ir.run", "np.squeeze.append", "numpy.array", "sess_ir.run", "np.squeeze.append", "numpy.array", "str", "str", "str", "str", "f.readlines", "vars", "os.path.join", "os.path.join", "os.path.join", "open", "pickle.load", "open", "pickle.load", "open", "pickle.load", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "open", "tensorflow.ConfigProto", "open", "pickle.load", "open", "pickle.load", "open", "pickle.load", "train_DocNADE_MVT_MST.get_bert_input", "train_DocNADE_MVT_MST.get_bert_input", "str", "str", "str", "os.path.join", "os.path.join", "os.path.join", "str().lower().strip", "os.path.join", "os.path.join", "os.path.join", "str", "str", "str", "f.readlines", "tensorflow.GPUOptions", "str().lower", "str", "str"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.train", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.reload_evaluation_ppl", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.reload_evaluation_ir", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.get_prior_matrix", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.get_bert_input", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.get_bert_input"], ["", "def", "main", "(", "args", ")", ":", "\n", "\t", "args", ".", "reload", "=", "str2bool", "(", "args", ".", "reload", ")", "\n", "args", ".", "use_glove_prior", "=", "str2bool", "(", "args", ".", "use_glove_prior", ")", "\n", "args", ".", "use_bio_prior", "=", "str2bool", "(", "args", ".", "use_bio_prior", ")", "\n", "args", ".", "projection", "=", "str2bool", "(", "args", ".", "projection", ")", "\n", "args", ".", "concat_projection", "=", "str2bool", "(", "args", ".", "concat_projection", ")", "\n", "args", ".", "multi_label", "=", "str2bool", "(", "args", ".", "multi_label", ")", "\n", "args", ".", "gvt_loss", "=", "str2bool", "(", "args", ".", "gvt_loss", ")", "\n", "args", ".", "use_embeddings_prior", "=", "str2bool", "(", "args", ".", "use_embeddings_prior", ")", "\n", "args", ".", "use_fasttext_prior", "=", "str2bool", "(", "args", ".", "use_fasttext_prior", ")", "\n", "args", ".", "use_bert_prior", "=", "str2bool", "(", "args", ".", "use_bert_prior", ")", "\n", "\n", "if", "args", ".", "reload", ":", "\n", "\t\t", "with", "open", "(", "\"./model/\"", "+", "args", ".", "reload_model_dir", "+", "\"/params.json\"", ")", "as", "f", ":", "\n", "\t\t\t", "params", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "params", "[", "'trainfile'", "]", "=", "args", ".", "trainfile", "\n", "params", "[", "'valfile'", "]", "=", "args", ".", "valfile", "\n", "params", "[", "'testfile'", "]", "=", "args", ".", "testfile", "\n", "\n", "params", "[", "'reload_model_dir'", "]", "=", "args", ".", "reload_model_dir", "\n", "\n", "reload_ir", "=", "False", "\n", "if", "os", ".", "path", ".", "isdir", "(", "\"./model/\"", "+", "args", ".", "reload_model_dir", "+", "\"/model_ir\"", ")", ":", "\n", "\t\t\t", "reload_ir", "=", "True", "\n", "\n", "", "reload_ppl", "=", "False", "\n", "if", "os", ".", "path", ".", "isdir", "(", "\"./model/\"", "+", "args", ".", "reload_model_dir", "+", "\"/model_ppl\"", ")", ":", "\n", "\t\t\t", "reload_ppl", "=", "True", "\n", "\n", "# Reloading and evaluating on Perplexity, Topic Coherence and calculating Nearest Neighbors", "\n", "", "if", "reload_ppl", ":", "\n", "\t\t\t", "W_target", ",", "bias_W_target", ",", "U_target", ",", "bias_U_target", "=", "reload_evaluation_ppl", "(", "params", ",", "suffix", "=", "\"target\"", ")", "\n", "#reload_evaluation_topics(W_target, U_target, params)", "\n", "\n", "# Reloading and evaluating on Information Retrieval and Classification - F1", "\n", "", "if", "reload_ir", ":", "\n", "\t\t\t", "with", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "inter_op_parallelism_threads", "=", "params", "[", "'num_cores'", "]", ",", "\n", "intra_op_parallelism_threads", "=", "params", "[", "'num_cores'", "]", ",", "\n", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "allow_growth", "=", "True", ")", "\n", ")", ")", "as", "sess_ir", ":", "\n", "\n", "\t\t\t\t", "saver_ir", "=", "tf", ".", "train", ".", "import_meta_graph", "(", "\"./model/\"", "+", "args", ".", "reload_model_dir", "+", "\"/model_ir/model_ir-1.meta\"", ")", "\n", "saver_ir", ".", "restore", "(", "sess_ir", ",", "tf", ".", "train", ".", "latest_checkpoint", "(", "\"./model/\"", "+", "args", ".", "reload_model_dir", "+", "\"/model_ir/\"", ")", ")", "\n", "\n", "graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", "\n", "x", "=", "graph", ".", "get_tensor_by_name", "(", "\"x:0\"", ")", "\n", "seq_lengths", "=", "graph", ".", "get_tensor_by_name", "(", "\"seq_lengths:0\"", ")", "\n", "last_hidden", "=", "graph", ".", "get_tensor_by_name", "(", "\"last_hidden:0\"", ")", "\n", "x_bert", "=", "graph", ".", "get_tensor_by_name", "(", "\"x_bert:0\"", ")", "\n", "\n", "dataset", "=", "data", ".", "Dataset", "(", "params", "[", "'dataset'", "]", ")", "\n", "#import pdb; pdb.set_trace()", "\n", "docnade_bert_reps", "=", "{", "\n", "\"training_docnade\"", ":", "None", ",", "\n", "\"validation_docnade\"", ":", "None", ",", "\n", "\"test_docnade\"", ":", "None", "\n", "}", "\n", "if", "params", "[", "\"use_bert_prior\"", "]", ":", "\n", "\t\t\t\t\t", "with", "open", "(", "os", ".", "path", ".", "join", "(", "params", "[", "\"bert_reps_path\"", "]", ",", "\"training.pkl\"", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "docnade_bert_reps", "[", "\"training_docnade\"", "]", "=", "pickle", ".", "load", "(", "f", ")", "\n", "bert_emb_shape", "=", "docnade_bert_reps", "[", "\"training_docnade\"", "]", "[", "0", "]", ".", "shape", "[", "1", "]", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "params", "[", "\"bert_reps_path\"", "]", ",", "\"validation.pkl\"", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "docnade_bert_reps", "[", "\"validation_docnade\"", "]", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "params", "[", "\"bert_reps_path\"", "]", ",", "\"test.pkl\"", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "docnade_bert_reps", "[", "\"test_docnade\"", "]", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "\"\"\"\n\t\t\t\t\twith open(os.path.join(params[\"bert_reps_path\"][0], \"training.pkl\"), \"rb\") as f:\n\t\t\t\t\t\tdocnade_bert_reps[\"training_docnade\"] = pickle.load(f)\n\t\t\t\t\t\tbert_emb_shape = docnade_bert_reps[\"training_docnade\"][0].shape[1]\n\t\t\t\t\twith open(os.path.join(params[\"bert_reps_path\"][0], \"validation.pkl\"), \"rb\") as f:\n\t\t\t\t\t\tdocnade_bert_reps[\"validation_docnade\"] = pickle.load(f)\n\t\t\t\t\twith open(os.path.join(params[\"bert_reps_path\"][0], \"test.pkl\"), \"rb\") as f:\n\t\t\t\t\t\tdocnade_bert_reps[\"test_docnade\"] = pickle.load(f)\n\t\t\t\t\t\n\t\t\t\t\tfor reps_path in params[\"bert_reps_path\"][1:]:\n\t\t\t\t\t\twith open(os.path.join(reps_path, \"training.pkl\"), \"rb\") as f:\n\t\t\t\t\t\t\tnew_train_reps = pickle.load(f)\n\t\t\t\t\t\t\tbert_emb_shape += new_train_reps[0].shape[1]\n\t\t\t\t\t\twith open(os.path.join(reps_path, \"validation.pkl\"), \"rb\") as f:\n\t\t\t\t\t\t\tnew_val_reps = pickle.load(f)\n\t\t\t\t\t\twith open(os.path.join(reps_path, \"test.pkl\"), \"rb\") as f:\n\t\t\t\t\t\t\tnew_test_reps = pickle.load(f)\n\t\t\t\t\t\t\n\t\t\t\t\t\tfor doc_num, doc_reps in new_train_reps.items():\n\t\t\t\t\t\t\tdocnade_bert_reps[\"training_docnade\"][doc_num] \\\n\t\t\t\t\t\t\t\t= np.concatenate([docnade_bert_reps[\"training_docnade\"][doc_num], doc_reps], axis=-1)\n\t\t\t\t\t\tfor doc_num, doc_reps in new_val_reps.items():\n\t\t\t\t\t\t\tdocnade_bert_reps[\"validation_docnade\"][doc_num] \\\n\t\t\t\t\t\t\t\t= np.concatenate([docnade_bert_reps[\"validation_docnade\"][doc_num], doc_reps], axis=-1)\n\t\t\t\t\t\tfor doc_num, doc_reps in new_test_reps.items():\n\t\t\t\t\t\t\tdocnade_bert_reps[\"test_docnade\"][doc_num] \\\n\t\t\t\t\t\t\t\t= np.concatenate([docnade_bert_reps[\"test_docnade\"][doc_num], doc_reps], axis=-1)\n\t\t\t\t\t\"\"\"", "\n", "", "hidden_vectors_tr", "=", "[", "]", "\n", "for", "tr_indices", ",", "tr_y", ",", "tr_x", ",", "tr_seq_lengths", "in", "dataset", ".", "batches", "(", "'training_docnade'", ",", "batch_size", "=", "1", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "True", ",", "multilabel", "=", "params", "[", "'multi_label'", "]", ")", ":", "\n", "\t\t\t\t\t", "tr_feed_dict", "=", "{", "\n", "x", ":", "tr_x", ",", "\n", "seq_lengths", ":", "tr_seq_lengths", "\n", "}", "\n", "if", "params", "[", "\"use_bert_prior\"", "]", ":", "\n", "\t\t\t\t\t\t", "tr_x_bert", "=", "get_bert_input", "(", "docnade_bert_reps", "[", "\"training_docnade\"", "]", ",", "tr_indices", ",", "tr_x", ".", "shape", "[", "1", "]", ")", "\n", "tr_feed_dict", "[", "x_bert", "]", "=", "tr_x_bert", "\n", "\n", "", "hidden_vec", "=", "sess_ir", ".", "run", "(", "[", "last_hidden", "]", ",", "feed_dict", "=", "tr_feed_dict", ")", "\n", "hidden_vectors_tr", ".", "append", "(", "hidden_vec", "[", "0", "]", ")", "\n", "", "hidden_vectors_tr", "=", "np", ".", "squeeze", "(", "np", ".", "array", "(", "hidden_vectors_tr", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "\n", "hidden_vectors_test", "=", "[", "]", "\n", "for", "te_indices", ",", "te_y", ",", "te_x", ",", "te_seq_lengths", "in", "dataset", ".", "batches", "(", "'test_docnade'", ",", "batch_size", "=", "1", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "True", ",", "multilabel", "=", "params", "[", "'multi_label'", "]", ")", ":", "\n", "\t\t\t\t\t", "te_feed_dict", "=", "{", "\n", "x", ":", "te_x", ",", "\n", "seq_lengths", ":", "te_seq_lengths", "\n", "}", "\n", "if", "params", "[", "\"use_bert_prior\"", "]", ":", "\n", "\t\t\t\t\t\t", "tr_x_bert", "=", "get_bert_input", "(", "docnade_bert_reps", "[", "\"test_docnade\"", "]", ",", "te_indices", ",", "te_x", ".", "shape", "[", "1", "]", ")", "\n", "te_feed_dict", "[", "x_bert", "]", "=", "tr_x_bert", "\n", "\n", "", "hidden_vec", "=", "sess_ir", ".", "run", "(", "[", "last_hidden", "]", ",", "feed_dict", "=", "te_feed_dict", ")", "\n", "hidden_vectors_test", ".", "append", "(", "hidden_vec", "[", "0", "]", ")", "\n", "", "hidden_vectors_test", "=", "np", ".", "squeeze", "(", "np", ".", "array", "(", "hidden_vectors_test", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "\n", "W_target", "=", "sess_ir", ".", "run", "(", "\"embedding:0\"", ")", "\n", "\n", "", "reload_evaluation_ir", "(", "params", ",", "hidden_vectors_tr", ",", "hidden_vectors_test", ",", "\n", "W_target", ",", "suffix", "=", "\"target\"", ")", "\n", "", "", "else", ":", "\n", "\n", "\t\t", "x", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ",", "None", ")", ",", "name", "=", "'x'", ")", "\n", "x_bw", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ",", "None", ")", ",", "name", "=", "'x_bw'", ")", "\n", "if", "args", ".", "multi_label", ":", "\n", "\t\t\t", "y", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "(", "None", ")", ",", "name", "=", "'y'", ")", "\n", "", "else", ":", "\n", "\t\t\t", "y", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ")", ",", "name", "=", "'y'", ")", "\n", "", "seq_lengths", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ")", ",", "name", "=", "'seq_lengths'", ")", "\n", "\n", "if", "args", ".", "use_bert_prior", ":", "\n", "\t\t\t", "x_bert", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "None", ",", "None", ")", ",", "name", "=", "'x_bert'", ")", "\n", "", "else", ":", "\n", "\t\t\t", "x_bert", "=", "None", "\n", "\n", "", "now", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "\n", "if", "args", ".", "use_glove_prior", ":", "\n", "\t\t\t", "args", ".", "model", "+=", "\"_emb_glove_\"", "+", "str", "(", "args", ".", "lambda_glove", ")", "\n", "\n", "", "if", "args", ".", "use_bio_prior", ":", "\n", "\t\t\t", "args", ".", "model", "+=", "\"_emb_bio_\"", "+", "str", "(", "args", ".", "lambda_glove", ")", "\n", "\n", "", "if", "args", ".", "use_embeddings_prior", ":", "\n", "\t\t\t", "args", ".", "model", "+=", "\"_emb_lambda_\"", "+", "str", "(", "args", ".", "lambda_embeddings", ")", "+", "\"_\"", "+", "\"_\"", ".", "join", "(", "[", "str", "(", "lamb", ")", "for", "lamb", "in", "args", ".", "lambda_embeddings_list", "]", ")", "\n", "\n", "", "if", "args", ".", "use_fasttext_prior", ":", "\n", "\t\t\t", "args", ".", "model", "+=", "\"_ftt_\"", "\n", "\n", "", "if", "args", ".", "use_bert_prior", ":", "\n", "\t\t\t", "args", ".", "model", "+=", "\"_bert_\"", "\n", "\n", "", "if", "args", ".", "W_pretrained_path", "or", "args", ".", "U_pretrained_path", ":", "\n", "\t\t\t", "args", ".", "model", "+=", "\"_pretr_reload_\"", "\n", "\n", "", "args", ".", "model", "+=", "\"_act_\"", "+", "str", "(", "args", ".", "activation", ")", "+", "\"_hid_\"", "+", "str", "(", "args", ".", "hidden_size", ")", "+", "\"_vocab_\"", "+", "str", "(", "args", ".", "vocab_size", ")", "+", "\"_lr_\"", "+", "str", "(", "args", ".", "learning_rate", ")", "\n", "if", "args", ".", "gvt_loss", ":", "\n", "\t\t\t", "args", ".", "model", "+=", "\"_gvt_loss_\"", "+", "str", "(", "args", ".", "gvt_loss", ")", "+", "\"_\"", "+", "str", "(", "args", ".", "gvt_lambda", ")", "+", "\"_\"", ".", "join", "(", "[", "str", "(", "lamb", ")", "for", "lamb", "in", "args", ".", "gvt_lambda_init", "]", ")", "\n", "\n", "", "if", "args", ".", "projection", ":", "\n", "\t\t\t", "args", ".", "model", "+=", "\"_projection\"", "\n", "\n", "", "if", "args", ".", "concat_projection", ":", "\n", "\t\t\t", "args", ".", "model", "+=", "\"_cp_\"", "+", "str", "(", "args", ".", "concat_projection_lambda", ")", "+", "\"_\"", "\n", "\n", "", "args", ".", "model", "+=", "\"_\"", "+", "str", "(", "now", ".", "day", ")", "+", "\"_\"", "+", "str", "(", "now", ".", "month", ")", "+", "\"_\"", "+", "str", "(", "now", ".", "year", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "model", ")", ":", "\n", "\t\t\t", "os", ".", "mkdir", "(", "args", ".", "model", ")", "\n", "\n", "", "docnade_vocab", "=", "args", ".", "docnadeVocab", "\n", "with", "open", "(", "docnade_vocab", ",", "'r'", ")", "as", "f", ":", "\n", "\t\t\t", "vocab_docnade", "=", "[", "w", ".", "strip", "(", ")", "for", "w", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model", ",", "'params.json'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "json", ".", "dumps", "(", "vars", "(", "args", ")", ")", ")", "\n", "\n", "", "dataset", "=", "data", ".", "Dataset", "(", "args", ".", "dataset", ")", "\n", "\n", "docnade_glove_matrix", "=", "None", "\n", "if", "args", ".", "use_glove_prior", ":", "\n", "\t\t\t", "if", "args", ".", "use_bio_prior", ":", "\n", "#docnade_glove_matrix = np.load(args.dataset + \"/glove_vectors_bio.npy\")", "\n", "\t\t\t\t", "docnade_glove_matrix", "=", "np", ".", "load", "(", "args", ".", "dataset", "+", "\"/word2vec_vectors_bio.npy\"", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "docnade_glove_matrix", "=", "np", ".", "load", "(", "args", ".", "dataset", "+", "\"/glove_vectors.npy\"", ")", "\n", "\n", "", "", "docnade_fasttext_matrix", "=", "None", "\n", "if", "args", ".", "use_fasttext_prior", ":", "\n", "\t\t\t", "if", "args", ".", "use_bio_prior", ":", "\n", "\t\t\t\t", "docnade_fasttext_matrix", "=", "np", ".", "load", "(", "args", ".", "dataset", "+", "\"/fasttext_vectors_bio.npy\"", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "docnade_fasttext_matrix", "=", "np", ".", "load", "(", "args", ".", "dataset", "+", "\"/fasttext_vectors.npy\"", ")", "\n", "\n", "", "", "docnade_bert_reps", "=", "{", "\n", "\"training_docnade\"", ":", "None", ",", "\n", "\"validation_docnade\"", ":", "None", ",", "\n", "\"test_docnade\"", ":", "None", "\n", "}", "\n", "bert_emb_shape", "=", "0", "\n", "if", "args", ".", "use_bert_prior", ":", "\n", "\t\t\t", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "bert_reps_path", "[", "0", "]", ",", "\"training.pkl\"", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "\t\t\t\t", "docnade_bert_reps", "[", "\"training_docnade\"", "]", "=", "pickle", ".", "load", "(", "f", ")", "\n", "bert_emb_shape", "=", "docnade_bert_reps", "[", "\"training_docnade\"", "]", "[", "0", "]", ".", "shape", "[", "1", "]", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "bert_reps_path", "[", "0", "]", ",", "\"validation.pkl\"", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "\t\t\t\t", "docnade_bert_reps", "[", "\"validation_docnade\"", "]", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "bert_reps_path", "[", "0", "]", ",", "\"test.pkl\"", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "\t\t\t\t", "docnade_bert_reps", "[", "\"test_docnade\"", "]", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "for", "reps_path", "in", "args", ".", "bert_reps_path", "[", "1", ":", "]", ":", "\n", "\t\t\t\t", "with", "open", "(", "os", ".", "path", ".", "join", "(", "reps_path", ",", "\"training.pkl\"", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t", "new_train_reps", "=", "pickle", ".", "load", "(", "f", ")", "\n", "bert_emb_shape", "+=", "new_train_reps", "[", "0", "]", ".", "shape", "[", "1", "]", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "reps_path", ",", "\"validation.pkl\"", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t", "new_val_reps", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "reps_path", ",", "\"test.pkl\"", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t", "new_test_reps", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "for", "doc_num", ",", "doc_reps", "in", "new_train_reps", ".", "items", "(", ")", ":", "\n", "\t\t\t\t\t", "docnade_bert_reps", "[", "\"training_docnade\"", "]", "[", "doc_num", "]", "=", "np", ".", "concatenate", "(", "[", "docnade_bert_reps", "[", "\"training_docnade\"", "]", "[", "doc_num", "]", ",", "doc_reps", "]", ",", "axis", "=", "-", "1", ")", "\n", "", "for", "doc_num", ",", "doc_reps", "in", "new_val_reps", ".", "items", "(", ")", ":", "\n", "\t\t\t\t\t", "docnade_bert_reps", "[", "\"validation_docnade\"", "]", "[", "doc_num", "]", "=", "np", ".", "concatenate", "(", "[", "docnade_bert_reps", "[", "\"validation_docnade\"", "]", "[", "doc_num", "]", ",", "doc_reps", "]", ",", "axis", "=", "-", "1", ")", "\n", "", "for", "doc_num", ",", "doc_reps", "in", "new_test_reps", ".", "items", "(", ")", ":", "\n", "\t\t\t\t\t", "docnade_bert_reps", "[", "\"test_docnade\"", "]", "[", "doc_num", "]", "=", "np", ".", "concatenate", "(", "[", "docnade_bert_reps", "[", "\"test_docnade\"", "]", "[", "doc_num", "]", ",", "doc_reps", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "", "", "W_pretrained_matrix", "=", "None", "\n", "if", "args", ".", "W_pretrained_path", ":", "\n", "\t\t\t", "W_pretrained_matrix", "=", "np", ".", "load", "(", "args", ".", "W_pretrained_path", ")", "\n", "print", "(", "\"pretrained W loaded.\"", ")", "\n", "\n", "", "U_pretrained_matrix", "=", "None", "\n", "if", "args", ".", "U_pretrained_path", ":", "\n", "\t\t\t", "U_pretrained_matrix", "=", "np", ".", "load", "(", "args", ".", "U_pretrained_path", ")", "\n", "print", "(", "\"pretrained U loaded.\"", ")", "\n", "\n", "", "W_old_indices_list", "=", "[", "]", "\n", "W_new_indices_list", "=", "[", "]", "\n", "W_old_matrices_list", "=", "[", "]", "\n", "W_embeddings_matrices_list", "=", "[", "]", "\n", "if", "args", ".", "use_embeddings_prior", "or", "args", ".", "gvt_loss", ":", "\n", "\t\t\t", "for", "i", ",", "W_old_path", "in", "enumerate", "(", "args", ".", "W_old_path_list", ")", ":", "\n", "\t\t\t\t", "with", "open", "(", "args", ".", "W_old_vocab_path_list", "[", "i", "]", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t", "temp_vocab", "=", "[", "str", "(", "word", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", "for", "word", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "prior_matrix", ",", "W_old_matrix", ",", "W_old_indices", ",", "W_new_indices", "=", "get_prior_matrix", "(", "W_old_path", ",", "temp_vocab", ",", "vocab_docnade", ",", "args", ".", "hidden_size", ")", "\n", "W_embeddings_matrices_list", ".", "append", "(", "prior_matrix", ")", "\n", "W_old_matrices_list", ".", "append", "(", "W_old_matrix", ")", "\n", "W_old_indices_list", ".", "append", "(", "W_old_indices", ")", "\n", "W_new_indices_list", ".", "append", "(", "W_new_indices", ")", "\n", "", "print", "(", "\"Loaded W_embeddings_matrices_list and W_embeddings_indices_list.\"", ")", "\n", "\n", "args", ".", "lambda_embeddings_list", "=", "np", ".", "array", "(", "args", ".", "lambda_embeddings_list", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "if", "args", ".", "gvt_loss", ":", "\n", "\t\t\t", "args", ".", "gvt_lambda_init", "=", "np", ".", "array", "(", "args", ".", "gvt_lambda_init", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "model", "=", "m", ".", "DocNADE_MVT_MST", "(", "x", ",", "y", ",", "seq_lengths", ",", "args", ",", "W_old_list", "=", "W_old_matrices_list", ",", "W_embeddings_matrices_list", "=", "W_embeddings_matrices_list", ",", "W_old_indices_list", "=", "W_old_indices_list", ",", "lambda_embeddings_list", "=", "args", ".", "lambda_embeddings_list", ",", "W_new_indices_list", "=", "W_new_indices_list", ",", "W_pretrained", "=", "W_pretrained_matrix", ",", "U_pretrained", "=", "U_pretrained_matrix", ",", "glove_embeddings", "=", "docnade_glove_matrix", ",", "lambda_glove", "=", "args", ".", "lambda_glove", ",", "fasttext_embeddings", "=", "docnade_fasttext_matrix", ",", "\n", "x_bert", "=", "x_bert", ",", "bert_emb_shape", "=", "bert_emb_shape", ")", "\n", "print", "(", "\"DocNADE created\"", ")", "\n", "\n", "train", "(", "model", ",", "dataset", ",", "args", ",", "vocab_docnade", ",", "docnade_bert_reps", "=", "docnade_bert_reps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.parse_args": [[1170, 1265], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.parse_args"], ["", "", "def", "parse_args", "(", ")", ":", "\n", "\t", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'path to model output directory'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'path to the input dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--vocab-size'", ",", "type", "=", "int", ",", "default", "=", "2000", ",", "\n", "help", "=", "'the vocab size'", ")", "\n", "parser", ".", "add_argument", "(", "'--hidden-size'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "'size of the hidden layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--activation'", ",", "type", "=", "str", ",", "default", "=", "'tanh'", ",", "\n", "help", "=", "'which activation to use: sigmoid|tanh'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning-rate'", ",", "type", "=", "float", ",", "default", "=", "0.0004", ",", "\n", "help", "=", "'initial learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-steps'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "'the number of steps to train for'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'the batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-cores'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'the number of CPU cores to use'", ")", "\n", "parser", ".", "add_argument", "(", "'--log-every'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "'print loss after this many steps'", ")", "\n", "parser", ".", "add_argument", "(", "'--validation-ppl-freq'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'print loss after this many steps'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-classes'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'number of classes'", ")", "\n", "parser", ".", "add_argument", "(", "'--use-glove-prior'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether to use GloVe embeddings as prior information'", ")", "\n", "parser", ".", "add_argument", "(", "'--use-bio-prior'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether to use BioNLP embeddings as prior information'", ")", "\n", "parser", ".", "add_argument", "(", "'--docnadeVocab'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'path to vocabulary file used by DocNADE'", ")", "\n", "parser", ".", "add_argument", "(", "'--test-ppl-freq'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "'print and log test PPL after this many steps'", ")", "\n", "parser", ".", "add_argument", "(", "'--test-ir-freq'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "'print and log test IR after this many steps'", ")", "\n", "parser", ".", "add_argument", "(", "'--patience'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "'print and log test IR after this many steps'", ")", "\n", "parser", ".", "add_argument", "(", "'--validation-bs'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'the batch size for validation evaluation'", ")", "\n", "parser", ".", "add_argument", "(", "'--test-bs'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'the batch size for test evaluation'", ")", "\n", "parser", ".", "add_argument", "(", "'--validation-ir-freq'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'print loss after this many steps'", ")", "\n", "parser", ".", "add_argument", "(", "'--projection'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether to project prior embeddings or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--reload'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether to reload model or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--reload-model-dir'", ",", "type", "=", "str", ",", "\n", "help", "=", "'path for model to be reloaded'", ")", "\n", "parser", ".", "add_argument", "(", "'--multi-label'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether dataset is multi-label or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--trainfile'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'path to train text file'", ")", "\n", "parser", ".", "add_argument", "(", "'--valfile'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'path to validation text file'", ")", "\n", "parser", ".", "add_argument", "(", "'--testfile'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'path to test text file'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda-glove'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "'combination weight for prior GloVe embeddings into docnade'", ")", "\n", "parser", ".", "add_argument", "(", "'--W-pretrained-path'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'path for pretrained W matrix'", ")", "\n", "parser", ".", "add_argument", "(", "'--U-pretrained-path'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'path for pretrained U matrix'", ")", "\n", "parser", ".", "add_argument", "(", "'--gvt-loss'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether to include LL loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--gvt-lambda'", ",", "type", "=", "str", ",", "default", "=", "\"automatic\"", ",", "\n", "help", "=", "'\"automatic\" or \"manual\"'", ")", "\n", "parser", ".", "add_argument", "(", "'--gvt-lambda-init'", ",", "type", "=", "float", ",", "nargs", "=", "'+'", ",", "default", "=", "[", "]", ",", "\n", "help", "=", "'\"automatic\" or \"manual\"'", ")", "\n", "parser", ".", "add_argument", "(", "'--W-old-path-list'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "default", "=", "[", "]", ",", "\n", "help", "=", "'path to the W matrices of source datasets'", ")", "\n", "parser", ".", "add_argument", "(", "'--U-old-path-list'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "default", "=", "[", "]", ",", "\n", "help", "=", "'path to the U matrices of source datasets'", ")", "\n", "parser", ".", "add_argument", "(", "'--W-old-vocab-path-list'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "default", "=", "[", "]", ",", "\n", "help", "=", "'path to the vocab of source datasets'", ")", "\n", "parser", ".", "add_argument", "(", "'--use-embeddings-prior'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether to embedings as prior or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda-embeddings'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'make embeddings lambda trainable or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda-embeddings-list'", ",", "type", "=", "float", ",", "nargs", "=", "'+'", ",", "default", "=", "[", "]", ",", "\n", "help", "=", "'list of lambda for every embedding prior'", ")", "\n", "parser", ".", "add_argument", "(", "'--use-fasttext-prior'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether to use fasttext embedings as prior or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--concat-projection'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether to use projection with concatenation of prior embeddings'", ")", "\n", "parser", ".", "add_argument", "(", "'--concat-projection-lambda'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "'value of lambda for concat projection'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--use-bert-prior'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether to bert contextualized embedings as prior or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--bert-reps-path'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "default", "=", "[", "]", ",", "\n", "help", "=", "'path to bert contextualized embedings as prior or not'", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.DocNADE_MVT_MST.__init__": [[162, 427], ["tensorflow.shape", "tensorflow.scan", "tensorflow.transpose", "tensorflow.concat", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.reshape", "model_MVT_MST.linear_TL", "model_MVT_MST.masked_sequence_cross_entropy_loss", "tensorflow.identity", "tensorflow.Variable", "model_MVT_MST.gradients", "tensorflow.shape", "tensorflow.shape", "tensorflow.device", "tensorflow.nn.embedding_lookup", "tensorflow.get_variable", "tensorflow.transpose", "tensorflow.sigmoid", "enumerate", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.embedding_lookup", "tensorflow.get_variable", "tensorflow.nn.embedding_lookup", "enumerate", "print", "tensorflow.get_variable", "tensorflow.concat", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.scalar_mul", "tensorflow.add", "tensorflow.zeros", "tensorflow.tanh", "tensorflow.range", "tensorflow.to_int32", "zip", "tensorflow.gather", "tensorflow.nn.l2_loss", "tensorflow.train.AdamOptimizer", "tensorflow.trainable_variables", "model_MVT_MST.DocNADE_MVT_MST.prior_embeddings.append", "tensorflow.add", "model_MVT_MST.DocNADE_MVT_MST.prior_embeddings.append", "model_MVT_MST.DocNADE_MVT_MST.prior_embeddings.append", "tensorflow.constant_initializer", "tensorflow.get_variable", "tensorflow.nn.embedding_lookup", "model_MVT_MST.DocNADE_MVT_MST.W_prior_list.append", "model_MVT_MST.DocNADE_MVT_MST.embeddings_prior_list.append", "tensorflow.get_variable", "enumerate", "tensorflow.nn.relu", "print", "exit", "tensorflow.matmul", "tensorflow.random_uniform_initializer", "tensorflow.scalar_mul", "tensorflow.add", "tensorflow.get_variable", "model_MVT_MST.DocNADE_MVT_MST.prior_embeddings.append", "tensorflow.scalar_mul", "tensorflow.add", "tensorflow.random_uniform_initializer", "tensorflow.get_variable", "tensorflow.clip_by_value", "print", "sys.exit", "tensorflow.get_variable", "model_MVT_MST.DocNADE_MVT_MST.gvt_proj_matrices_W.append", "tensorflow.get_variable", "tensorflow.clip_by_value", "print", "sys.exit", "str", "str", "str", "tensorflow.random_uniform_initializer"], "methods", ["home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.linear_TL", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.masked_sequence_cross_entropy_loss", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.gradients"], ["\t", "def", "__init__", "(", "self", ",", "x", ",", "y", ",", "seq_lengths", ",", "params", ",", "W_old_list", "=", "None", ",", "\n", "W_embeddings_matrices_list", "=", "None", ",", "W_old_indices_list", "=", "None", ",", "\n", "lambda_embeddings_list", "=", "None", ",", "W_new_indices_list", "=", "None", ",", "\n", "W_pretrained", "=", "None", ",", "U_pretrained", "=", "None", ",", "\n", "glove_embeddings", "=", "None", ",", "lambda_glove", "=", "0.0", ",", "\n", "fasttext_embeddings", "=", "None", ",", "x_bert", "=", "None", ",", "bert_emb_shape", "=", "0", ")", ":", "\n", "\t\t", "self", ".", "x", "=", "x", "\n", "self", ".", "y", "=", "y", "\n", "self", ".", "seq_lengths", "=", "seq_lengths", "\n", "if", "params", ".", "use_bert_prior", ":", "\n", "\t\t\t", "self", ".", "x_bert", "=", "x_bert", "\n", "\n", "", "batch_size", "=", "tf", ".", "shape", "(", "x", ")", "[", "0", "]", "\n", "batch_length", "=", "tf", ".", "shape", "(", "x", ")", "[", "1", "]", "\n", "self", ".", "b_s", "=", "tf", ".", "shape", "(", "x", ")", "\n", "self", ".", "W_old_list", "=", "W_old_list", "\n", "self", ".", "lambda_embeddings_list", "=", "lambda_embeddings_list", "\n", "self", ".", "lambda_glove", "=", "lambda_glove", "\n", "\n", "# Do an embedding lookup for each word in each sequence", "\n", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "\t\t\t", "if", "W_pretrained", "is", "None", ":", "\n", "\t\t\t\t", "max_embed_init", "=", "1.0", "/", "(", "params", ".", "vocab_size", "*", "params", ".", "hidden_size", ")", "\n", "W", "=", "tf", ".", "get_variable", "(", "\n", "'embedding'", ",", "\n", "[", "params", ".", "vocab_size", ",", "params", ".", "hidden_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", "\n", "maxval", "=", "max_embed_init", ",", "\n", "seed", "=", "tf_op_seed", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "W", "=", "tf", ".", "get_variable", "(", "\n", "'embedding'", ",", "\n", "initializer", "=", "W_pretrained", "\n", ")", "\n", "", "self", ".", "embeddings", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "W", ",", "x", ",", "name", "=", "'embeddings'", ")", "\n", "\n", "projection_input_dim", "=", "0", "\n", "self", ".", "prior_embeddings", "=", "[", "]", "\n", "if", "not", "glove_embeddings", "is", "None", ":", "\n", "\t\t\t\t", "glove_prior", "=", "tf", ".", "get_variable", "(", "\n", "'glove_prior'", ",", "\n", "initializer", "=", "glove_embeddings", ",", "\n", "trainable", "=", "False", "\n", ")", "\n", "self", ".", "embeddings_prior_glove", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "glove_prior", ",", "x", ",", "name", "=", "'glove_embeddings'", ")", "\n", "\n", "if", "params", ".", "concat_projection", ":", "\n", "\t\t\t\t\t", "self", ".", "prior_embeddings", ".", "append", "(", "self", ".", "embeddings_prior_glove", ")", "\n", "projection_input_dim", "+=", "glove_embeddings", ".", "shape", "[", "1", "]", "\n", "", "else", ":", "\n", "# Lambda multiplication", "\n", "\t\t\t\t\t", "if", "not", "self", ".", "lambda_glove", "<", "0.0", ":", "\n", "\t\t\t\t\t\t", "self", ".", "embeddings_prior_glove", "=", "tf", ".", "scalar_mul", "(", "self", ".", "lambda_glove", ",", "self", ".", "embeddings_prior_glove", ")", "\n", "", "self", ".", "embeddings", "=", "tf", ".", "add", "(", "self", ".", "embeddings", ",", "self", ".", "embeddings_prior_glove", ")", "\n", "\n", "", "", "if", "not", "fasttext_embeddings", "is", "None", ":", "\n", "\t\t\t\t", "fasttext_prior", "=", "tf", ".", "get_variable", "(", "\n", "'fasttext_prior'", ",", "\n", "initializer", "=", "fasttext_embeddings", ",", "\n", "trainable", "=", "False", "\n", ")", "\n", "self", ".", "embeddings_prior_fasttext", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "fasttext_prior", ",", "x", ",", "name", "=", "'fasttext_embeddings'", ")", "\n", "\n", "if", "params", ".", "concat_projection", ":", "\n", "\t\t\t\t\t", "self", ".", "prior_embeddings", ".", "append", "(", "self", ".", "embeddings_prior_fasttext", ")", "\n", "projection_input_dim", "+=", "fasttext_embeddings", ".", "shape", "[", "1", "]", "\n", "", "elif", "fasttext_embeddings", ".", "shape", "[", "1", "]", "!=", "params", ".", "hidden_size", ":", "\n", "\t\t\t\t\t", "pass", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "self", ".", "embeddings", "=", "tf", ".", "add", "(", "self", ".", "embeddings", ",", "self", ".", "embeddings_prior_fasttext", ")", "\n", "\n", "", "", "if", "params", ".", "use_bert_prior", ":", "\n", "\t\t\t\t", "if", "params", ".", "concat_projection", ":", "\n", "\t\t\t\t\t", "self", ".", "prior_embeddings", ".", "append", "(", "self", ".", "x_bert", ")", "\n", "projection_input_dim", "+=", "bert_emb_shape", "\n", "\n", "", "", "bias", "=", "tf", ".", "get_variable", "(", "\n", "'bias'", ",", "\n", "[", "params", ".", "hidden_size", "]", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0", ")", "\n", ")", "\n", "\n", "if", "params", ".", "use_embeddings_prior", ":", "\n", "\t\t\t\t", "if", "not", "params", ".", "concat_projection", ":", "\n", "\t\t\t\t\t", "if", "params", ".", "lambda_embeddings", "==", "\"manual\"", ":", "\n", "\t\t\t\t\t\t", "self", ".", "embeddings_lambda_list", "=", "tf", ".", "get_variable", "(", "\n", "'embeddings_lambda_list'", ",", "\n", "initializer", "=", "lambda_embeddings_list", ",", "\n", "trainable", "=", "False", "\n", ")", "\n", "", "elif", "params", ".", "lambda_embeddings", "==", "\"automatic\"", ":", "\n", "\t\t\t\t\t\t", "embeddings_lambda_list", "=", "tf", ".", "get_variable", "(", "\n", "'embeddings_lambda_list_unclipped'", ",", "\n", "initializer", "=", "lambda_embeddings_list", ",", "\n", "trainable", "=", "True", "\n", ")", "\n", "self", ".", "embeddings_lambda_list", "=", "tf", ".", "clip_by_value", "(", "embeddings_lambda_list", ",", "0.0", ",", "1.0", ",", "name", "=", "'embeddings_lambda_list'", ")", "\n", "", "else", ":", "\n", "\t\t\t\t\t\t", "print", "(", "\"Invalid parameter value for lambda_embeddings: \"", ",", "params", ".", "lambda_embeddings", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n", "", "", "self", ".", "W_prior_list", "=", "[", "]", "\n", "self", ".", "embeddings_prior_list", "=", "[", "]", "\n", "for", "i", ",", "W_embeddings", "in", "enumerate", "(", "W_embeddings_matrices_list", ")", ":", "\n", "\t\t\t\t\t", "W_prior", "=", "tf", ".", "get_variable", "(", "\n", "'embedding_prior_'", "+", "str", "(", "i", ")", ",", "\n", "initializer", "=", "W_embeddings", ",", "\n", "trainable", "=", "False", "\n", ")", "\n", "embedding_prior", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "W_prior", ",", "x", ")", "\n", "\n", "if", "params", ".", "concat_projection", ":", "\n", "\t\t\t\t\t\t", "self", ".", "prior_embeddings", ".", "append", "(", "embedding_prior", ")", "\n", "projection_input_dim", "+=", "W_embeddings", ".", "shape", "[", "1", "]", "\n", "", "else", ":", "\n", "\t\t\t\t\t\t", "embedding_prior_with_lambda", "=", "tf", ".", "scalar_mul", "(", "self", ".", "embeddings_lambda_list", "[", "i", "]", ",", "embedding_prior", ")", "\n", "self", ".", "embeddings", "=", "tf", ".", "add", "(", "self", ".", "embeddings", ",", "embedding_prior_with_lambda", ")", "\n", "\n", "", "self", ".", "W_prior_list", ".", "append", "(", "W_prior", ")", "\n", "self", ".", "embeddings_prior_list", ".", "append", "(", "embedding_prior", ")", "\n", "\n", "", "", "if", "params", ".", "concat_projection", "and", "(", "projection_input_dim", "!=", "0", ")", ":", "\n", "\t\t\t\t", "print", "(", "\"Projection.\"", ")", "\n", "max_embed_init_projection", "=", "1.0", "/", "(", "projection_input_dim", "*", "params", ".", "hidden_size", ")", "\n", "prior_emb_projection", "=", "tf", ".", "get_variable", "(", "\n", "'prior_emb_projection'", ",", "\n", "[", "projection_input_dim", ",", "params", ".", "hidden_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", "\n", "maxval", "=", "max_embed_init_projection", ",", "\n", "seed", "=", "tf_op_seed", "\n", ")", "\n", ")", "\n", "combined_embedding_prior", "=", "tf", ".", "concat", "(", "self", ".", "prior_embeddings", ",", "axis", "=", "2", ",", "name", "=", "'prior_embeddings_concat'", ")", "\n", "combined_embedding_prior", "=", "tf", ".", "reshape", "(", "\n", "combined_embedding_prior", ",", "\n", "[", "-", "1", ",", "projection_input_dim", "]", ",", "\n", "name", "=", "'embeddings_prior_fasttext_bert_reshape_before_proj'", "\n", ")", "\n", "\n", "combined_embedding_prior", "=", "tf", ".", "matmul", "(", "\n", "combined_embedding_prior", ",", "\n", "prior_emb_projection", ",", "\n", "name", "=", "'embeddings_prior_fasttext_bert_projected'", "\n", ")", "\n", "\n", "combined_embedding_prior", "=", "tf", ".", "reshape", "(", "\n", "combined_embedding_prior", ",", "\n", "[", "batch_size", ",", "batch_length", ",", "params", ".", "hidden_size", "]", ",", "\n", "name", "=", "'embeddings_prior_fasttext_bert_reshape_after_proj'", "\n", ")", "\n", "\n", "combined_embedding_prior", "=", "tf", ".", "scalar_mul", "(", "params", ".", "concat_projection_lambda", ",", "combined_embedding_prior", ")", "\n", "self", ".", "embeddings", "=", "tf", ".", "add", "(", "self", ".", "embeddings", ",", "combined_embedding_prior", ",", "name", "=", "'embeddings_combined'", ")", "\n", "\n", "", "if", "params", ".", "gvt_loss", ":", "\n", "\t\t\t\t", "if", "params", ".", "gvt_lambda", "==", "\"manual\"", ":", "\n", "\t\t\t\t\t", "self", ".", "gvt_lambda_list", "=", "tf", ".", "get_variable", "(", "\n", "'gvt_lambda_list'", ",", "\n", "initializer", "=", "params", ".", "gvt_lambda_init", ",", "\n", "trainable", "=", "False", "\n", ")", "\n", "", "elif", "params", ".", "gvt_lambda", "==", "\"automatic\"", ":", "\n", "\t\t\t\t\t", "gvt_lambda_list", "=", "tf", ".", "get_variable", "(", "\n", "'gvt_lambda_list_unclipped'", ",", "\n", "initializer", "=", "params", ".", "gvt_lambda_init", ",", "\n", "trainable", "=", "True", "\n", ")", "\n", "self", ".", "gvt_lambda_list", "=", "tf", ".", "clip_by_value", "(", "gvt_lambda_list", ",", "0.0", ",", "1.0", ",", "name", "=", "'gvt_lambda_list'", ")", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "print", "(", "\"Invalid parameter value for sal_gamma: \"", ",", "params", ".", "sal_gamma", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n", "", "if", "params", ".", "projection", ":", "\n", "\t\t\t\t\t", "self", ".", "gvt_proj_matrices_W", "=", "[", "]", "\n", "self", ".", "gvt_proj_matrices_U", "=", "[", "]", "\n", "\n", "max_embed_init", "=", "1.0", "/", "(", "params", ".", "hidden_size", "*", "params", ".", "hidden_size", ")", "\n", "\n", "for", "i", ",", "gvt_temp_init", "in", "enumerate", "(", "params", ".", "gvt_lambda_init", ")", ":", "\n", "\t\t\t\t\t\t", "gvt_proj_temp_W", "=", "tf", ".", "get_variable", "(", "\n", "'gvt_projection_W_'", "+", "str", "(", "i", ")", ",", "\n", "[", "params", ".", "hidden_size", ",", "params", ".", "hidden_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", "\n", "maxval", "=", "max_embed_init", ",", "\n", "seed", "=", "tf_op_seed", "\n", ")", "\n", ")", "\n", "self", ".", "gvt_proj_matrices_W", ".", "append", "(", "gvt_proj_temp_W", ")", "\n", "\n", "# Compute the hidden layer inputs: each gets summed embeddings of", "\n", "# previous words", "\n", "", "", "", "", "def", "sum_embeddings", "(", "previous", ",", "current", ")", ":", "\n", "\t\t\t", "return", "previous", "+", "current", "\n", "\n", "", "h", "=", "tf", ".", "scan", "(", "sum_embeddings", ",", "tf", ".", "transpose", "(", "self", ".", "embeddings", ",", "[", "1", ",", "2", ",", "0", "]", ")", ")", "\n", "h", "=", "tf", ".", "transpose", "(", "h", ",", "[", "2", ",", "0", ",", "1", "]", ")", "\n", "\n", "h", "=", "tf", ".", "concat", "(", "[", "\n", "tf", ".", "zeros", "(", "[", "batch_size", ",", "1", ",", "params", ".", "hidden_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "h", "\n", "]", ",", "axis", "=", "1", ")", "\n", "\n", "self", ".", "pre_act", "=", "h", "\n", "\n", "# Apply activation", "\n", "if", "params", ".", "activation", "==", "'sigmoid'", ":", "\n", "\t\t\t", "h", "=", "tf", ".", "sigmoid", "(", "h", "+", "bias", ")", "\n", "", "elif", "params", ".", "activation", "==", "'tanh'", ":", "\n", "\t\t\t", "h", "=", "tf", ".", "tanh", "(", "h", "+", "bias", ")", "\n", "", "elif", "params", ".", "activation", "==", "'relu'", ":", "\n", "\t\t\t", "h", "=", "tf", ".", "nn", ".", "relu", "(", "h", "+", "bias", ")", "\n", "", "else", ":", "\n", "\t\t\t", "print", "(", "'Invalid value for activation: %s'", "%", "(", "params", ".", "activation", ")", ")", "\n", "exit", "(", ")", "\n", "\n", "", "self", ".", "aft_act", "=", "h", "\n", "\n", "# Extract final state for each sequence in the batch", "\n", "indices", "=", "tf", ".", "stack", "(", "[", "\n", "tf", ".", "range", "(", "batch_size", ")", ",", "\n", "tf", ".", "to_int32", "(", "seq_lengths", ")", "\n", "]", ",", "axis", "=", "1", ")", "\n", "self", ".", "indices", "=", "indices", "\n", "self", ".", "h", "=", "tf", ".", "gather_nd", "(", "h", ",", "indices", ",", "name", "=", "'last_hidden'", ")", "\n", "\n", "h", "=", "h", "[", ":", ",", ":", "-", "1", ",", ":", "]", "\n", "h", "=", "tf", ".", "reshape", "(", "h", ",", "[", "-", "1", ",", "params", ".", "hidden_size", "]", ")", "\n", "\n", "self", ".", "logits", ",", "U_new", "=", "linear_TL", "(", "h", ",", "params", ".", "vocab_size", ",", "scope", "=", "'softmax'", ",", "U_pretrained", "=", "U_pretrained", ")", "\n", "loss_function", "=", "None", "\n", "\n", "self", ".", "loss_normed", ",", "self", ".", "labels", ",", "self", ".", "mask", ",", "self", ".", "loss_unnormed", "=", "masked_sequence_cross_entropy_loss", "(", "\n", "x", ",", "\n", "seq_lengths", ",", "\n", "self", ".", "logits", ",", "\n", "loss_function", "=", "loss_function", ",", "\n", "norm_by_seq_lengths", "=", "True", ",", "\n", "name", "=", "\"x\"", "\n", ")", "\n", "\n", "self", ".", "total_loss", "=", "tf", ".", "identity", "(", "self", ".", "loss_unnormed", ",", "name", "=", "\"total_loss\"", ")", "\n", "\n", "if", "params", ".", "gvt_loss", ":", "\n", "\t\t\t", "W_reg_loss", "=", "0.0", "\n", "for", "i", ",", "(", "W_old", ",", "W_new_indices", ")", "in", "enumerate", "(", "zip", "(", "W_old_list", ",", "W_new_indices_list", ")", ")", ":", "\n", "\t\t\t\t", "W_new_temp", "=", "tf", ".", "gather", "(", "W", ",", "W_new_indices", ",", "axis", "=", "0", ")", "\n", "if", "params", ".", "projection", ":", "\n", "\t\t\t\t\t", "W_new_temp_proj", "=", "tf", ".", "matmul", "(", "W_new_temp", ",", "self", ".", "gvt_proj_matrices_W", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "W_new_temp_proj", "=", "W_new_temp", "\n", "", "W_l2_loss", "=", "tf", ".", "nn", ".", "l2_loss", "(", "(", "W_new_temp_proj", "-", "W_old", ")", ",", "name", "=", "'l2_loss_W_old_'", "+", "str", "(", "i", ")", ")", "\n", "W_reg_loss", "+=", "self", ".", "gvt_lambda_list", "[", "i", "]", "*", "W_l2_loss", "\n", "\n", "", "self", ".", "total_reg_loss", "=", "W_reg_loss", "\n", "self", ".", "total_loss", "+=", "self", ".", "total_reg_loss", "\n", "self", ".", "W_new_temp", "=", "W_new_temp", "\n", "\n", "# Optimiser", "\n", "", "step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ")", "\n", "self", ".", "opt", "=", "gradients", "(", "\n", "opt", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "params", ".", "learning_rate", ")", ",", "\n", "loss", "=", "self", ".", "total_loss", ",", "\n", "vars", "=", "tf", ".", "trainable_variables", "(", ")", ",", "\n", "step", "=", "step", "\n", ")", ""]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.get_bert_input": [[13, 26], ["numpy.stack", "np.stack.append", "len", "numpy.concatenate", "ValueError", "numpy.zeros"], "function", ["None"], ["def", "get_bert_input", "(", "reps", ",", "indices", ",", "max_length", ")", ":", "\n", "\t", "bert_inputs", "=", "[", "]", "\n", "for", "index", "in", "indices", ":", "\n", "\t\t", "inputs", "=", "reps", "[", "index", "]", "\n", "if", "inputs", ".", "shape", "[", "0", "]", "<", "max_length", ":", "\n", "\t\t\t", "inputs", "=", "np", ".", "concatenate", "(", "[", "inputs", ",", "np", ".", "zeros", "(", "(", "max_length", "-", "inputs", ".", "shape", "[", "0", "]", ",", "inputs", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "np", ".", "float32", ")", "]", ",", "axis", "=", "0", ")", "\n", "assert", "(", "inputs", ".", "shape", "[", "0", "]", "==", "max_length", ")", "\n", "", "if", "inputs", ".", "shape", "[", "0", "]", ">", "max_length", ":", "\n", "\t\t\t", "raise", "ValueError", "(", "\"Dimension mismatch.\"", ")", "\n", "", "bert_inputs", ".", "append", "(", "inputs", ")", "\n", "", "bert_inputs", "=", "np", ".", "stack", "(", "bert_inputs", ",", "axis", "=", "0", ")", "\n", "assert", "(", "bert_inputs", ".", "shape", "[", "0", "]", "==", "len", "(", "indices", ")", ")", "\n", "return", "bert_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.vectors": [[27, 42], ["numpy.array", "vecs.extend", "model_MVT_MST.get_bert_input", "session.run"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.get_bert_input"], ["", "def", "vectors", "(", "model", ",", "data", ",", "session", ",", "params", ",", "vocab", "=", "None", ",", "bert_reps", "=", "None", ")", ":", "\n", "\t", "vecs", "=", "[", "]", "\n", "for", "indices", ",", "_", ",", "x", ",", "seq_lengths", "in", "data", ":", "\n", "\t\t", "feed_dict", "=", "{", "\n", "model", ".", "x", ":", "x", ",", "\n", "model", ".", "seq_lengths", ":", "seq_lengths", "\n", "}", "\n", "\n", "if", "params", ".", "use_bert_prior", ":", "\n", "\t\t\t", "x_bert", "=", "get_bert_input", "(", "bert_reps", ",", "indices", ",", "x", ".", "shape", "[", "1", "]", ")", "\n", "feed_dict", "[", "model", ".", "x_bert", "]", "=", "x_bert", "\n", "", "vecs", ".", "extend", "(", "\n", "session", ".", "run", "(", "[", "model", ".", "h", "]", ",", "feed_dict", "=", "feed_dict", ")", "[", "0", "]", "\n", ")", "\n", "", "return", "np", ".", "array", "(", "vecs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.loss": [[43, 53], ["loss.append", "sum", "len", "session.run"], "function", ["None"], ["", "def", "loss", "(", "model", ",", "data", ",", "session", ")", ":", "\n", "\t", "loss", "=", "[", "]", "\n", "for", "_", ",", "x", ",", "seq_lengths", "in", "data", ":", "\n", "\t\t", "loss", ".", "append", "(", "\n", "session", ".", "run", "(", "[", "model", ".", "loss", "]", ",", "feed_dict", "=", "{", "\n", "model", ".", "x", ":", "x", ",", "\n", "model", ".", "seq_lengths", ":", "seq_lengths", "\n", "}", ")", "[", "0", "]", "\n", ")", "\n", "", "return", "sum", "(", "loss", ")", "/", "len", "(", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.gradients": [[54, 83], ["opt.compute_gradients", "opt.apply_gradients", "zip", "tensorflow.python.ops.clip_ops.clip_by_global_norm", "isinstance", "list", "print", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "zip", "tensorflow.python.ops.clip_ops.global_norm"], "function", ["None"], ["", "def", "gradients", "(", "opt", ",", "loss", ",", "vars", ",", "step", ",", "max_gradient_norm", "=", "None", ",", "dont_clip", "=", "[", "]", ")", ":", "\n", "\t", "gradients", "=", "opt", ".", "compute_gradients", "(", "loss", ",", "vars", ")", "\n", "if", "max_gradient_norm", "is", "not", "None", ":", "\n", "\t\t", "to_clip", "=", "[", "(", "g", ",", "v", ")", "for", "g", ",", "v", "in", "gradients", "if", "v", ".", "name", "not", "in", "dont_clip", "]", "\n", "not_clipped", "=", "[", "(", "g", ",", "v", ")", "for", "g", ",", "v", "in", "gradients", "if", "v", ".", "name", "in", "dont_clip", "]", "\n", "gradients", ",", "variables", "=", "zip", "(", "*", "to_clip", ")", "\n", "clipped_gradients", ",", "_", "=", "clip_ops", ".", "clip_by_global_norm", "(", "\n", "gradients", ",", "\n", "max_gradient_norm", "\n", ")", "\n", "gradients", "=", "list", "(", "zip", "(", "clipped_gradients", ",", "variables", ")", ")", "+", "not_clipped", "\n", "\n", "# Add histograms for variables, gradients and gradient norms", "\n", "", "for", "gradient", ",", "variable", "in", "gradients", ":", "\n", "\t\t", "if", "isinstance", "(", "gradient", ",", "ops", ".", "IndexedSlices", ")", ":", "\n", "\t\t\t", "grad_values", "=", "gradient", ".", "values", "\n", "", "else", ":", "\n", "\t\t\t", "grad_values", "=", "gradient", "\n", "", "if", "grad_values", "is", "None", ":", "\n", "\t\t\t", "print", "(", "'warning: missing gradient: {}'", ".", "format", "(", "variable", ".", "name", ")", ")", "\n", "", "if", "grad_values", "is", "not", "None", ":", "\n", "\t\t\t", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "name", ",", "variable", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "name", "+", "'/gradients'", ",", "grad_values", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\n", "variable", ".", "name", "+", "'/gradient_norm'", ",", "\n", "clip_ops", ".", "global_norm", "(", "[", "grad_values", "]", ")", "\n", ")", "\n", "\n", "", "", "return", "opt", ".", "apply_gradients", "(", "gradients", ",", "global_step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.linear_TL": [[84, 112], ["tensorflow.constant_initializer", "tensorflow.get_variable", "tensorflow.nn.xw_plus_b", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "numpy.sqrt", "input.get_shape", "input.get_shape"], "function", ["None"], ["", "def", "linear_TL", "(", "input", ",", "output_dim", ",", "scope", "=", "None", ",", "stddev", "=", "None", ",", "U_pretrained", "=", "None", ")", ":", "\n", "\t", "const", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", "\n", "\n", "if", "U_pretrained", "is", "None", ":", "\n", "\t\t", "if", "stddev", ":", "\n", "\t\t\t", "norm", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "stddev", ",", "seed", "=", "tf_op_seed", ")", "\n", "", "else", ":", "\n", "\t\t\t", "norm", "=", "tf", ".", "random_normal_initializer", "(", "\n", "stddev", "=", "np", ".", "sqrt", "(", "2.0", "/", "input", ".", "get_shape", "(", ")", "[", "1", "]", ".", "value", ")", ",", "\n", "seed", "=", "tf_op_seed", "\n", ")", "\n", "\n", "", "U", "=", "tf", ".", "get_variable", "(", "\n", "'U'", ",", "\n", "[", "input", ".", "get_shape", "(", ")", "[", "1", "]", ",", "output_dim", "]", ",", "\n", "initializer", "=", "norm", "\n", ")", "\n", "", "else", ":", "\n", "\t\t", "U", "=", "tf", ".", "get_variable", "(", "\n", "'U'", ",", "\n", "initializer", "=", "U_pretrained", "\n", ")", "\n", "\n", "", "b", "=", "tf", ".", "get_variable", "(", "'b'", ",", "[", "output_dim", "]", ",", "initializer", "=", "const", ")", "\n", "\n", "input_logits", "=", "tf", ".", "nn", ".", "xw_plus_b", "(", "input", ",", "U", ",", "b", ")", "\n", "\n", "return", "input_logits", ",", "U", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.model_MVT_MST.masked_sequence_cross_entropy_loss": [[113, 160], ["tensorflow.reshape", "tensorflow.less", "tensorflow.reshape", "tensorflow.to_float", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.shape", "tensorflow.shape", "tensorflow.range", "tensorflow.reshape", "tensorflow.where", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "loss_function", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.ones_like", "tensorflow.zeros_like", "tensorflow.to_float"], "function", ["None"], ["", "def", "masked_sequence_cross_entropy_loss", "(", "\n", "x", ",", "\n", "seq_lengths", ",", "\n", "logits", ",", "\n", "loss_function", "=", "None", ",", "\n", "norm_by_seq_lengths", "=", "True", ",", "\n", "name", "=", "\"\"", "\n", ")", ":", "\n", "\t", "'''\n\tCompute the cross-entropy loss between all elements in x and logits.\n\tMasks out the loss for all positions greater than the sequence\n\tlength (as we expect that sequences may be padded).\n\n\tOptionally, also either use a different loss function (eg: sampled\n\tsoftmax), and/or normalise the loss for each sequence by the\n\tsequence length.\n\t'''", "\n", "batch_size", "=", "tf", ".", "shape", "(", "x", ")", "[", "0", "]", "\n", "labels", "=", "tf", ".", "reshape", "(", "x", ",", "[", "-", "1", "]", ")", "\n", "\n", "\n", "max_doc_length", "=", "tf", ".", "shape", "(", "x", ")", "[", "1", "]", "\n", "mask", "=", "tf", ".", "less", "(", "\n", "tf", ".", "range", "(", "0", ",", "max_doc_length", ",", "1", ")", ",", "\n", "tf", ".", "reshape", "(", "seq_lengths", ",", "[", "batch_size", ",", "1", "]", ")", "\n", ")", "\n", "mask", "=", "tf", ".", "reshape", "(", "mask", ",", "[", "-", "1", "]", ")", "\n", "mask", "=", "tf", ".", "to_float", "(", "tf", ".", "where", "(", "\n", "mask", ",", "\n", "tf", ".", "ones_like", "(", "labels", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "tf", ".", "zeros_like", "(", "labels", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", ")", ")", "\n", "\n", "if", "loss_function", "is", "None", ":", "\n", "\t\t", "loss", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "logits", ",", "\n", "labels", "=", "labels", "\n", ")", "\n", "", "else", ":", "\n", "\t\t", "loss", "=", "loss_function", "(", "logits", ",", "labels", ")", "\n", "", "loss", "*=", "mask", "\n", "loss", "=", "tf", ".", "reshape", "(", "loss", ",", "[", "batch_size", ",", "-", "1", "]", ")", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "loss", ",", "axis", "=", "1", ")", "\n", "loss_unnormed", "=", "loss", "\n", "if", "norm_by_seq_lengths", ":", "\n", "\t\t", "loss", "=", "loss", "/", "tf", ".", "to_float", "(", "seq_lengths", ")", "\n", "", "return", "tf", ".", "reduce_mean", "(", "loss", ",", "name", "=", "\"loss_normed_\"", "+", "name", ")", ",", "labels", ",", "mask", ",", "tf", ".", "reduce_mean", "(", "loss_unnormed", ",", "name", "=", "\"loss_unnormed_\"", "+", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.evaluate.compare_labels": [[11, 47], ["numpy.asarray", "numpy.array", "print", "exit", "numpy.ones", "numpy.asarray", "numpy.dot", "print", "isinstance", "isinstance", "print", "exit", "numpy.array", "len", "len", "numpy.array", "print", "numpy.ones", "numpy.sum"], "function", ["None"], ["def", "compare_labels", "(", "train_labels", ",", "test_label", ",", "label_type", "=", "\"\"", ",", "evaluation_type", "=", "\"\"", ",", "labels_to_count", "=", "[", "]", ")", ":", "\n", "\n", "\t", "vec_goodLabel", "=", "[", "]", "\n", "\n", "train_labels", "=", "np", ".", "asarray", "(", "train_labels", ")", "\n", "\n", "if", "label_type", "==", "\"single\"", ":", "\n", "\t\t", "if", "not", "(", "isinstance", "(", "test_label", ",", "int", ")", "or", "isinstance", "(", "train_labels", "[", "0", "]", ",", "int", ")", ")", ":", "\n", "\t\t\t", "print", "(", "\"Labels are not instances of int\"", ")", "\n", "exit", "(", ")", "\n", "\n", "", "test_labels", "=", "np", ".", "ones", "(", "train_labels", ".", "shape", "[", "0", "]", ",", "dtype", "=", "np", ".", "float32", ")", "*", "test_label", "\n", "\n", "vec_goodLabel", "=", "np", ".", "array", "(", "(", "train_labels", "==", "test_labels", ")", ",", "dtype", "=", "np", ".", "int8", ")", "\n", "", "elif", "label_type", "==", "\"multi\"", ":", "\n", "\t\t", "if", "not", "len", "(", "train_labels", "[", "0", "]", ")", "==", "len", "(", "test_label", ")", ":", "\n", "\t\t\t", "print", "(", "\"Mismatched label vector length\"", ")", "\n", "exit", "(", ")", "\n", "\n", "", "test_labels", "=", "np", ".", "asarray", "(", "test_label", ")", "\n", "labels_comparison_vec", "=", "np", ".", "dot", "(", "train_labels", ",", "test_labels", ")", "\n", "\n", "if", "evaluation_type", "==", "\"relaxed\"", ":", "\n", "\t\t\t", "vec_goodLabel", "=", "np", ".", "array", "(", "(", "labels_comparison_vec", "!=", "0", ")", ",", "dtype", "=", "np", ".", "int8", ")", "\n", "\n", "", "elif", "evaluation_type", "==", "\"strict\"", ":", "\n", "\t\t\t", "test_label_vec", "=", "np", ".", "ones", "(", "train_labels", ".", "shape", "[", "0", "]", ")", "*", "np", ".", "sum", "(", "test_label", ")", "\n", "vec_goodLabel", "=", "np", ".", "array", "(", "(", "labels_comparison_vec", "==", "test_label_vec", ")", ",", "dtype", "=", "np", ".", "int8", ")", "\n", "\n", "", "else", ":", "\n", "\t\t\t", "print", "(", "\"Invalid evaluation_type value.\"", ")", "\n", "\n", "", "", "else", ":", "\n", "\t\t", "print", "(", "\"Invalid label_type value.\"", ")", "\n", "\n", "", "return", "vec_goodLabel", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.evaluate.perform_IR_prec": [[48, 151], ["numpy.mean", "print", "exit", "numpy.floor", "enumerate", "enumerate", "len", "len", "range", "numpy.argsort", "numpy.zeros", "evaluate.compare_labels", "enumerate", "numpy.argsort", "numpy.zeros", "evaluate.compare_labels", "enumerate", "len", "numpy.sum", "float", "open", "enumerate", "len", "list_totalRetrievalCount.append", "open", "enumerate", "int", "len", "prec_label_wise[].append", "f.write", "f.write", "numpy.floor", "numpy.sum", "numpy.sum", "float", "f.write", "f.write", "f.write", "f.write", "int", "int", "int", "str", "str"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.evaluate.compare_labels", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.evaluate.compare_labels"], ["", "def", "perform_IR_prec", "(", "kernel_matrix_test", ",", "train_labels", ",", "test_labels", ",", "list_percRetrieval", "=", "None", ",", "single_precision", "=", "False", ",", "label_type", "=", "\"\"", ",", "evaluation", "=", "\"\"", ",", "index2label_dict", "=", "None", ",", "labels_to_not_count", "=", "[", "]", ",", "corpus_docs", "=", "None", ",", "query_docs", "=", "None", ",", "IR_filename", "=", "\"\"", ",", "top_n_retrieval", "=", "20", ")", ":", "\n", "\t", "'''\n\t:param kernel_matrix_test: shape: size = |test_samples| x |train_samples|\n\t:param train_labels:\t\t\t  size = |train_samples| or |train_samples| x num_labels\n\t:param test_labels:\t\t\t   size = |test_samples| or |test_samples| x num_labels\n\t:param list_percRetrieval:\t\tlist of fractions at which IR has to be calculated\n\t:param single_precision:\t\t  True, if only one fraction is used\n\t:param label_type:\t\t\t\t\"single\" or \"multi\"\n\t:param evaluation:\t\t\t\t\"strict\" or \"relaxed\", only for \n\t:return:\n\t'''", "\n", "#print('Computing IR prec......')", "\n", "\n", "if", "not", "len", "(", "test_labels", ")", "==", "len", "(", "kernel_matrix_test", ")", ":", "\n", "\t\t", "print", "(", "'mismatched samples in test_labels and kernel_matrix_test'", ")", "\n", "exit", "(", ")", "\n", "\n", "", "labels_to_count", "=", "[", "]", "\n", "\n", "prec", "=", "[", "]", "\n", "prec_label_wise", "=", "{", "label", ":", "[", "]", "for", "label", "in", "range", "(", "test_labels", ".", "shape", "[", "1", "]", ")", "}", "\n", "\n", "if", "single_precision", ":", "\n", "\t\t", "vec_simIndexSorted", "=", "np", ".", "argsort", "(", "kernel_matrix_test", ",", "axis", "=", "1", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "prec_num_docs", "=", "np", ".", "floor", "(", "list_percRetrieval", "[", "0", "]", "*", "kernel_matrix_test", ".", "shape", "[", "1", "]", ")", "\n", "#prec_num_docs = list_percRetrieval[0]", "\n", "vec_simIndexSorted_prec", "=", "vec_simIndexSorted", "[", ":", ",", ":", "int", "(", "prec_num_docs", ")", "]", "\n", "\n", "for", "counter", ",", "indices", "in", "enumerate", "(", "vec_simIndexSorted_prec", ")", ":", "\n", "\t\t\t", "if", "label_type", "==", "\"multi\"", ":", "\n", "\t\t\t\t", "classQuery", "=", "test_labels", "[", "counter", ",", ":", "]", "\n", "tr_labels", "=", "train_labels", "[", "indices", ",", ":", "]", "\n", "", "else", ":", "\n", "\t\t\t\t", "classQuery", "=", "test_labels", "[", "counter", "]", "\n", "tr_labels", "=", "train_labels", "[", "indices", "]", "\n", "", "list_percPrecision", "=", "np", ".", "zeros", "(", "len", "(", "list_percRetrieval", ")", ")", "\n", "\n", "vec_goodLabel", "=", "compare_labels", "(", "tr_labels", ",", "classQuery", ",", "label_type", "=", "label_type", ",", "evaluation_type", "=", "evaluation", ",", "labels_to_count", "=", "labels_to_count", ")", "\n", "\n", "list_percPrecision", "[", "0", "]", "=", "np", ".", "sum", "(", "vec_goodLabel", ")", "/", "float", "(", "len", "(", "vec_goodLabel", ")", ")", "\n", "\n", "prec", "+=", "[", "list_percPrecision", "]", "\n", "\n", "#import pdb; pdb.set_trace()", "\n", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "classQuery", ")", ":", "\n", "\t\t\t\t", "if", "label", "==", "1", ":", "\n", "\t\t\t\t\t", "prec_label_wise", "[", "i", "]", ".", "append", "(", "list_percPrecision", "[", "0", "]", ")", "\n", "\n", "", "", "", "if", "(", "corpus_docs", "is", "not", "None", ")", "and", "(", "query_docs", "is", "not", "None", ")", "and", "(", "IR_filename", "!=", "\"\"", ")", ":", "\n", "\t\t\t", "with", "open", "(", "IR_filename", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t\t", "for", "counter", ",", "indices", "in", "enumerate", "(", "vec_simIndexSorted", "[", ":", ",", ":", "top_n_retrieval", "]", ")", ":", "\n", "\t\t\t\t\t", "f", ".", "write", "(", "\"Query\\t::\\t\"", "+", "query_docs", "[", "counter", "]", "+", "\"\\n\\n\"", ")", "\n", "#for index in indices[:int(kernel_matrix_test.shape[1] * 0.02)]:", "\n", "for", "index", "in", "indices", "[", ":", "top_n_retrieval", "]", ":", "\n", "\t\t\t\t\t\t", "f", ".", "write", "(", "str", "(", "kernel_matrix_test", "[", "counter", ",", "index", "]", ")", "+", "\"\\t::\\t\"", "+", "corpus_docs", "[", "index", "]", "+", "\"\\n\"", ")", "\n", "", "f", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "", "", "", "", "else", ":", "\n", "\t\t", "vec_simIndexSorted", "=", "np", ".", "argsort", "(", "kernel_matrix_test", ",", "axis", "=", "1", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "for", "counter", ",", "indices", "in", "enumerate", "(", "vec_simIndexSorted", ")", ":", "\n", "\n", "#indices = np.delete(indices, 0)", "\n", "\n", "\t\t\t", "if", "label_type", "==", "\"multi\"", ":", "\n", "\t\t\t\t", "classQuery", "=", "test_labels", "[", "counter", ",", ":", "]", "\n", "tr_labels", "=", "train_labels", "[", "indices", ",", ":", "]", "\n", "", "else", ":", "\n", "\t\t\t\t", "classQuery", "=", "test_labels", "[", "counter", "]", "\n", "tr_labels", "=", "train_labels", "[", "indices", "]", "\n", "", "list_percPrecision", "=", "np", ".", "zeros", "(", "len", "(", "list_percRetrieval", ")", ")", "\n", "\n", "vec_goodLabel", "=", "compare_labels", "(", "tr_labels", ",", "classQuery", ",", "label_type", "=", "label_type", ",", "evaluation_type", "=", "evaluation", ",", "labels_to_count", "=", "labels_to_count", ")", "\n", "\n", "list_totalRetrievalCount", "=", "[", "]", "\n", "for", "frac", "in", "list_percRetrieval", ":", "\n", "\t\t\t\t", "list_totalRetrievalCount", ".", "append", "(", "np", ".", "floor", "(", "frac", "*", "kernel_matrix_test", ".", "shape", "[", "1", "]", ")", ")", "\n", "#list_totalRetrievalCount.append(frac)", "\n", "\n", "", "countGoodLabel", "=", "0", "\n", "for", "indexRetrieval", ",", "totalRetrievalCount", "in", "enumerate", "(", "list_totalRetrievalCount", ")", ":", "\n", "\t\t\t\t", "if", "indexRetrieval", "==", "0", ":", "\n", "\t\t\t\t\t", "countGoodLabel", "+=", "np", ".", "sum", "(", "vec_goodLabel", "[", ":", "int", "(", "totalRetrievalCount", ")", "]", ")", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "countGoodLabel", "+=", "np", ".", "sum", "(", "vec_goodLabel", "[", "int", "(", "lastTotalRetrievalCount", ")", ":", "int", "(", "totalRetrievalCount", ")", "]", ")", "\n", "\n", "", "list_percPrecision", "[", "indexRetrieval", "]", "=", "countGoodLabel", "/", "float", "(", "totalRetrievalCount", ")", "\n", "lastTotalRetrievalCount", "=", "totalRetrievalCount", "\n", "\n", "", "prec", "+=", "[", "list_percPrecision", "]", "# vec_simIndexSorted[:int(list_totalRetrievalCount[0])]", "\n", "\n", "", "if", "(", "corpus_docs", "is", "not", "None", ")", "and", "(", "query_docs", "is", "not", "None", ")", "and", "(", "IR_filename", "!=", "\"\"", ")", ":", "\n", "\t\t\t", "with", "open", "(", "IR_filename", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t\t", "for", "counter", ",", "indices", "in", "enumerate", "(", "vec_simIndexSorted", "[", ":", ",", ":", "top_n_retrieval", "]", ")", ":", "\n", "\t\t\t\t\t", "f", ".", "write", "(", "\"Query\\t::\\t\"", "+", "query_docs", "[", "counter", "]", "+", "\"\\n\\n\"", ")", "\n", "#for index in indices[:int(kernel_matrix_test.shape[1] * 0.02)]:", "\n", "for", "index", "in", "indices", "[", ":", "top_n_retrieval", "]", ":", "\n", "\t\t\t\t\t\t", "f", ".", "write", "(", "str", "(", "kernel_matrix_test", "[", "counter", ",", "index", "]", ")", "+", "\"\\t::\\t\"", "+", "corpus_docs", "[", "index", "]", "+", "\"\\n\"", ")", "\n", "", "f", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "\n", "\n", "", "", "", "", "prec", "=", "np", ".", "mean", "(", "prec", ",", "axis", "=", "0", ")", "\n", "\n", "return", "prec", ",", "prec_label_wise", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.evaluate.perform_classification_test_multi": [[153, 184], ["numpy.mean", "numpy.std", "sklearn.multiclass.OneVsRestClassifier.fit", "sklearn.multiclass.OneVsRestClassifier.predict", "sklearn.metrics.accuracy_score", "test_acc.append", "test_f1.append", "numpy.vstack", "numpy.vstack", "sklearn.multiclass.OneVsRestClassifier", "sklearn.metrics.precision_recall_fscore_support", "sklearn.linear_model.LogisticRegression", "sklearn.multiclass.OneVsRestClassifier", "sklearn.svm.SVC"], "function", ["None"], ["", "def", "perform_classification_test_multi", "(", "train_data", ",", "test_data", ",", "c_list", ",", "classification_model", "=", "\"logistic\"", ",", "norm_before_classification", "=", "False", ")", ":", "\n", "\t", "docVectors_train", ",", "train_labels", "=", "train_data", "\n", "docVectors_test", ",", "test_labels", "=", "test_data", "\n", "\n", "if", "norm_before_classification", ":", "\n", "\t\t", "mean", "=", "np", ".", "mean", "(", "np", ".", "vstack", "(", "(", "docVectors_train", ",", "docVectors_test", ")", ")", ",", "axis", "=", "0", ")", "\n", "std", "=", "np", ".", "std", "(", "np", ".", "vstack", "(", "(", "docVectors_train", ",", "docVectors_test", ")", ")", ",", "axis", "=", "0", ")", "\n", "\n", "docVectors_train", "=", "(", "docVectors_train", "-", "mean", ")", "/", "std", "\n", "docVectors_test", "=", "(", "docVectors_test", "-", "mean", ")", "/", "std", "\n", "\n", "## Classification Accuracy", "\n", "", "test_acc", "=", "[", "]", "\n", "test_f1", "=", "[", "]", "\n", "\n", "for", "c", "in", "c_list", ":", "\n", "\t\t", "if", "classification_model", "==", "\"logistic\"", ":", "\n", "\t\t\t", "clf", "=", "OneVsRestClassifier", "(", "LogisticRegression", "(", "C", "=", "c", ")", ",", "n_jobs", "=", "5", ")", "\n", "", "elif", "classification_model", "==", "\"svm\"", ":", "\n", "\t\t\t", "clf", "=", "OneVsRestClassifier", "(", "SVC", "(", "C", "=", "c", ",", "kernel", "=", "'precomputed'", ")", ")", "\n", "\n", "", "clf", ".", "fit", "(", "docVectors_train", ",", "train_labels", ")", "\n", "pred_test_labels", "=", "clf", ".", "predict", "(", "docVectors_test", ")", "\n", "\n", "acc_test", "=", "accuracy_score", "(", "test_labels", ",", "pred_test_labels", ")", "\n", "f1_test", "=", "precision_recall_fscore_support", "(", "test_labels", ",", "pred_test_labels", ",", "pos_label", "=", "None", ",", "average", "=", "'macro'", ")", "[", "2", "]", "\n", "\n", "test_acc", ".", "append", "(", "acc_test", ")", "\n", "test_f1", ".", "append", "(", "f1_test", ")", "\n", "\n", "", "return", "test_acc", ",", "test_f1", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.evaluate.perform_classification_test": [[186, 217], ["numpy.mean", "numpy.std", "sklearn.svm.SVC.fit", "sklearn.svm.SVC.predict", "sklearn.metrics.accuracy_score", "test_acc.append", "test_f1.append", "numpy.vstack", "numpy.vstack", "sklearn.linear_model.LogisticRegression", "sklearn.metrics.precision_recall_fscore_support", "sklearn.svm.SVC"], "function", ["None"], ["", "def", "perform_classification_test", "(", "train_data", ",", "test_data", ",", "c_list", ",", "classification_model", "=", "\"logistic\"", ",", "norm_before_classification", "=", "False", ")", ":", "\n", "\t", "docVectors_train", ",", "train_labels", "=", "train_data", "\n", "docVectors_test", ",", "test_labels", "=", "test_data", "\n", "\n", "if", "norm_before_classification", ":", "\n", "\t\t", "mean", "=", "np", ".", "mean", "(", "np", ".", "vstack", "(", "(", "docVectors_train", ",", "docVectors_test", ")", ")", ",", "axis", "=", "0", ")", "\n", "std", "=", "np", ".", "std", "(", "np", ".", "vstack", "(", "(", "docVectors_train", ",", "docVectors_test", ")", ")", ",", "axis", "=", "0", ")", "\n", "\n", "docVectors_train", "=", "(", "docVectors_train", "-", "mean", ")", "/", "std", "\n", "docVectors_test", "=", "(", "docVectors_test", "-", "mean", ")", "/", "std", "\n", "\n", "## Classification Accuracy", "\n", "", "test_acc", "=", "[", "]", "\n", "test_f1", "=", "[", "]", "\n", "\n", "for", "c", "in", "c_list", ":", "\n", "\t\t", "if", "classification_model", "==", "\"logistic\"", ":", "\n", "\t\t\t", "clf", "=", "LogisticRegression", "(", "C", "=", "c", ")", "\n", "", "elif", "classification_model", "==", "\"svm\"", ":", "\n", "\t\t\t", "clf", "=", "SVC", "(", "C", "=", "c", ",", "kernel", "=", "'precomputed'", ")", "\n", "\n", "", "clf", ".", "fit", "(", "docVectors_train", ",", "train_labels", ")", "\n", "pred_test_labels", "=", "clf", ".", "predict", "(", "docVectors_test", ")", "\n", "\n", "acc_test", "=", "accuracy_score", "(", "test_labels", ",", "pred_test_labels", ")", "\n", "f1_test", "=", "precision_recall_fscore_support", "(", "test_labels", ",", "pred_test_labels", ",", "pos_label", "=", "None", ",", "average", "=", "'macro'", ")", "[", "2", "]", "\n", "\n", "test_acc", ".", "append", "(", "acc_test", ")", "\n", "test_f1", ".", "append", "(", "f1_test", ")", "\n", "\n", "", "return", "test_acc", ",", "test_f1", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.evaluate.closest_docs_by_index": [[219, 224], ["range", "numpy.array", "len", "docs.append"], "function", ["None"], ["", "def", "closest_docs_by_index", "(", "sim", ",", "order", ",", "query_vectors", ",", "n_docs", ")", ":", "\n", "\t", "docs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "query_vectors", ")", ")", ":", "\n", "\t\t", "docs", ".", "append", "(", "order", "[", ":", ",", "i", "]", "[", "0", ":", "n_docs", "]", ")", "\n", "", "return", "np", ".", "array", "(", "docs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.evaluate.precision": [[226, 233], ["len", "float", "len", "len"], "function", ["None"], ["", "def", "precision", "(", "label", ",", "predictions", ")", ":", "\n", "\t", "if", "len", "(", "predictions", ")", ":", "\n", "\t\t", "return", "float", "(", "\n", "len", "(", "[", "x", "for", "x", "in", "predictions", "if", "label", "in", "x", "]", ")", "\n", ")", "/", "len", "(", "predictions", ")", "\n", "", "else", ":", "\n", "\t\t", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.evaluate.evaluate": [[235, 303], ["total_labels.extend", "total_labels.extend", "sklearn.preprocessing.MultiLabelBinarizer", "sklearn.preprocessing.MultiLabelBinarizer.fit", "sklearn.preprocessing.MultiLabelBinarizer.transform", "sklearn.preprocessing.MultiLabelBinarizer.transform", "evaluate.perform_IR_prec", "len", "len", "sklearn.cosine_similarity", "label[].split", "label[].split", "sklearn.cosine_similarity", "len", "numpy.argsort", "int", "evaluate.closest_docs_by_index", "range", "results.append", "str", "results.append", "len", "str", "range", "range", "evaluate.precision", "pdb.set_trace"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.evaluate.perform_IR_prec", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.cosine_similarity", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.None.train_DocNADE_MVT_MST.cosine_similarity", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.evaluate.closest_docs_by_index", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.evaluate.precision"], ["", "", "def", "evaluate", "(", "\n", "corpus_vectors", ",", "\n", "query_vectors", ",", "\n", "corpus_labels", ",", "\n", "query_labels", ",", "\n", "recall", "=", "[", "0.02", "]", ",", "\n", "num_classes", "=", "None", ",", "\n", "multi_label", "=", "False", ",", "\n", "query_docs", "=", "None", ",", "\n", "corpus_docs", "=", "None", ",", "\n", "IR_filename", "=", "\"\"", ",", "\n", "top_n_retrieval", "=", "20", "\n", ")", ":", "\n", "\t", "if", "multi_label", ":", "\n", "\n", "\t\t", "splitted_query_labels", "=", "[", "label", "[", "0", "]", ".", "split", "(", "':'", ")", "for", "label", "in", "query_labels", "]", "\n", "splitted_corpus_labels", "=", "[", "label", "[", "0", "]", ".", "split", "(", "':'", ")", "for", "label", "in", "corpus_labels", "]", "\n", "\n", "total_labels", "=", "[", "]", "\n", "total_labels", ".", "extend", "(", "splitted_query_labels", ")", "\n", "total_labels", ".", "extend", "(", "splitted_corpus_labels", ")", "\n", "\n", "mlb", "=", "MultiLabelBinarizer", "(", "classes", "=", "[", "str", "(", "i", ")", "for", "i", "in", "range", "(", "num_classes", ")", "]", ")", "\n", "mlb", ".", "fit", "(", "[", "str", "(", "i", ")", "for", "i", "in", "range", "(", "num_classes", ")", "]", ")", "\n", "\n", "query_one_hot_labels", "=", "mlb", ".", "transform", "(", "splitted_query_labels", ")", "\n", "corpus_one_hot_labels", "=", "mlb", ".", "transform", "(", "splitted_corpus_labels", ")", "\n", "\n", "similarity_matrix", "=", "pw", ".", "cosine_similarity", "(", "corpus_vectors", ",", "query_vectors", ")", ".", "T", "\n", "if", "len", "(", "recall", ")", "==", "1", ":", "\n", "\t\t\t", "single_precision", "=", "True", "\n", "", "else", ":", "\n", "\t\t\t", "single_precision", "=", "False", "\n", "\n", "", "results", ",", "results_label_wise", "=", "perform_IR_prec", "(", "similarity_matrix", ",", "corpus_one_hot_labels", ",", "query_one_hot_labels", ",", "list_percRetrieval", "=", "recall", ",", "single_precision", "=", "single_precision", ",", "label_type", "=", "\"multi\"", ",", "evaluation", "=", "\"relaxed\"", ",", "corpus_docs", "=", "corpus_docs", ",", "query_docs", "=", "query_docs", ",", "IR_filename", "=", "IR_filename", ",", "top_n_retrieval", "=", "top_n_retrieval", ")", "\n", "", "else", ":", "\n", "\t\t", "corpus_size", "=", "len", "(", "corpus_labels", ")", "\n", "query_size", "=", "len", "(", "query_labels", ")", "\n", "\n", "results", "=", "[", "]", "\n", "results_label_wise", "=", "{", "}", "\n", "\n", "sim", "=", "pw", ".", "cosine_similarity", "(", "corpus_vectors", ",", "query_vectors", ")", "\n", "order", "=", "np", ".", "argsort", "(", "sim", ",", "axis", "=", "0", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "for", "r", "in", "recall", ":", "\n", "\t\t\t", "n_docs", "=", "int", "(", "(", "corpus_size", "*", "r", ")", "+", "0.5", ")", "\n", "if", "not", "n_docs", ":", "\n", "\t\t\t\t", "results", ".", "append", "(", "0.0", ")", "\n", "continue", "\n", "\n", "", "closest", "=", "closest_docs_by_index", "(", "sim", ",", "order", ",", "query_vectors", ",", "n_docs", ")", "\n", "\n", "avg", "=", "0.0", "\n", "for", "i", "in", "range", "(", "query_size", ")", ":", "\n", "\t\t\t\t", "doc_labels", "=", "query_labels", "[", "i", "]", "\n", "doc_avg", "=", "0.0", "\n", "for", "label", "in", "doc_labels", ":", "\n", "\t\t\t\t\t", "try", ":", "\n", "\t\t\t\t\t\t", "doc_avg", "+=", "precision", "(", "label", ",", "corpus_labels", "[", "closest", "[", "i", "]", "]", ")", "\n", "", "except", ":", "\n", "\t\t\t\t\t\t", "import", "pdb", ";", "pdb", ".", "set_trace", "(", ")", "\n", "", "", "doc_avg", "/=", "len", "(", "doc_labels", ")", "\n", "avg", "+=", "doc_avg", "\n", "", "avg", "/=", "query_size", "\n", "results", ".", "append", "(", "avg", ")", "\n", "\n", "", "", "return", "results", "\n", "", ""]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.__init__": [[40, 44], ["glob.glob", "data.file_name"], "methods", ["home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.file_name"], ["\t", "def", "__init__", "(", "self", ",", "path", ")", ":", "\n", "\t\t", "self", ".", "path", "=", "path", "\n", "files", "=", "glob", ".", "glob", "(", "path", "+", "'/*.csv'", ")", "\n", "self", ".", "collections", "=", "{", "file_name", "(", "file", ")", ":", "file", "for", "file", "in", "files", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.rows": [[45, 62], ["ValueError", "open", "csv.reader", "enumerate"], "methods", ["None"], ["", "def", "rows", "(", "self", ",", "collection_name", ",", "num_epochs", "=", "None", ")", ":", "\n", "\t\t", "if", "collection_name", "not", "in", "self", ".", "collections", ":", "\n", "\t\t\t", "raise", "ValueError", "(", "\n", "'Collection not found: {}'", ".", "format", "(", "collection_name", ")", "\n", ")", "\n", "", "epoch", "=", "0", "\n", "while", "True", ":", "\n", "#with open(self.collections[collection_name], 'rb', newline='') as f:", "\n", "\t\t\t", "with", "open", "(", "self", ".", "collections", "[", "collection_name", "]", ",", "'r'", ")", "as", "f", ":", "\n", "\t\t\t\t", "r", "=", "csv", ".", "reader", "(", "f", ")", "\n", "#for row in r:", "\n", "for", "index", ",", "row", "in", "enumerate", "(", "r", ")", ":", "\n", "#yield row", "\n", "\t\t\t\t\t", "yield", "index", ",", "row", "\n", "", "", "epoch", "+=", "1", "\n", "if", "num_epochs", "and", "(", "epoch", ">=", "num_epochs", ")", ":", "\n", "\t\t\t\t", "raise", "StopIteration", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset._batch_iter": [[63, 66], ["itertools.zip_longest", "data.Dataset.rows"], "methods", ["home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.rows"], ["", "", "", "def", "_batch_iter", "(", "self", ",", "collection_name", ",", "batch_size", ",", "num_epochs", ")", ":", "\n", "\t\t", "gen", "=", "[", "self", ".", "rows", "(", "collection_name", ",", "num_epochs", ")", "]", "*", "batch_size", "\n", "return", "itertools", ".", "zip_longest", "(", "fillvalue", "=", "None", ",", "*", "gen", ")", "\n", "#return izip_longest(fillvalue=None, *gen)", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset.batches": [[68, 79], ["data.Dataset._batch_iter", "zip", "data.format_row", "keras.pad_sequences", "keras.pad_sequences", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.Dataset._batch_iter", "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.format_row"], ["", "def", "batches", "(", "self", ",", "collection_name", ",", "batch_size", ",", "num_epochs", "=", "None", ",", "shuffle", "=", "True", ",", "max_len", "=", "None", ",", "multilabel", "=", "False", ")", ":", "\n", "\t\t", "for", "batch", "in", "self", ".", "_batch_iter", "(", "collection_name", ",", "batch_size", ",", "num_epochs", ")", ":", "\n", "\t\t\t", "data", "=", "[", "format_row", "(", "row", ",", "shuffle", "=", "shuffle", ",", "multilabel", "=", "multilabel", ")", "for", "row", "in", "batch", "if", "row", "]", "\n", "#y, x, seq_lengths = zip(*data)", "\n", "indices", ",", "y", ",", "x", ",", "seq_lengths", "=", "zip", "(", "*", "data", ")", "\n", "if", "not", "max_len", "is", "None", ":", "\n", "\t\t\t\t", "x", "=", "pp", ".", "pad_sequences", "(", "x", ",", "maxlen", "=", "max_len", ",", "padding", "=", "'post'", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "x", "=", "pp", ".", "pad_sequences", "(", "x", ",", "padding", "=", "'post'", ")", "\n", "#yield np.array(y), x, np.array(seq_lengths)", "\n", "", "yield", "np", ".", "array", "(", "indices", ")", ",", "np", ".", "array", "(", "y", ")", ",", "x", ",", "np", ".", "array", "(", "seq_lengths", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.file_name": [[20, 22], ["os.path.basename().replace", "os.path.basename"], "function", ["None"], ["def", "file_name", "(", "abs_path", ")", ":", "\n", "\t", "return", "os", ".", "path", ".", "basename", "(", "abs_path", ")", ".", "replace", "(", "'.csv'", ",", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_Multi-view-Multi-source-Topic-Modeling.model.data.format_row": [[23, 38], ["numpy.array", "numpy.random.shuffle", "int", "len", "int", "len", "raw_x.split"], "function", ["None"], ["", "def", "format_row", "(", "row", ",", "shuffle", "=", "True", ",", "multilabel", "=", "False", ")", ":", "\n", "#y, raw_x = row", "\n", "\t", "index", ",", "data", "=", "row", "\n", "y", ",", "raw_x", "=", "data", "\n", "\n", "x", "=", "np", ".", "array", "(", "[", "int", "(", "v", ")", "for", "v", "in", "raw_x", ".", "split", "(", ")", "]", ")", "\n", "if", "shuffle", ":", "\n", "\t\t", "np", ".", "random", ".", "shuffle", "(", "x", ")", "\n", "\n", "", "if", "multilabel", ":", "\n", "#return [y, x, len(x)]", "\n", "\t\t", "return", "[", "index", ",", "y", ",", "x", ",", "len", "(", "x", ")", "]", "\n", "", "else", ":", "\n", "#return [int(y), x, len(x)]", "\n", "\t\t", "return", "[", "index", ",", "int", "(", "y", ")", ",", "x", ",", "len", "(", "x", ")", "]", "\n", "\n"]]}