{"home.repos.pwc.inspect_result.wgcban_HyperTransformer.None.train.ensure_dir": [[28, 33], ["os.path.dirname", "os.path.exists", "os.makedirs"], "function", ["None"], ["def", "ensure_dir", "(", "file_path", ")", ":", "\n", "    ", "directory", "=", "os", ".", "path", ".", "dirname", "(", "file_path", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "directory", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "directory", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.None.train.train": [[148, 207], ["model.train", "optimizer.zero_grad", "enumerate", "writer.add_scalar", "torch.autograd.Variable", "torch.autograd.Variable", "model", "torch.autograd.backward", "torch.autograd.backward", "torch.autograd.backward", "torch.autograd.backward", "torch.autograd.backward", "utils.helpers.make_patches", "utils.helpers.make_patches", "utils.helpers.make_patches", "torch.autograd.Variable.float().cuda", "torch.autograd.Variable.float().cuda", "torch.amax().unsqueeze().unsqueeze().expand_as().cuda", "torch.amax().unsqueeze().unsqueeze().expand_as().cuda", "torch.amax().unsqueeze().unsqueeze().expand_as().cuda", "torch.amax().unsqueeze().unsqueeze().expand_as().cuda", "torch.amax().unsqueeze().unsqueeze().expand_as().cuda", "criterion", "criterion", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "utils.vgg_perceptual_loss.VGGPerceptualLoss", "optimizer.step", "optimizer.zero_grad", "utils.helpers.to_variable", "Spatial_loss", "torch.autograd.Variable.float", "torch.autograd.Variable.float", "torch.amax().unsqueeze().unsqueeze().expand_as", "torch.amax().unsqueeze().unsqueeze().expand_as", "torch.amax().unsqueeze().unsqueeze().expand_as", "torch.amax().unsqueeze().unsqueeze().expand_as", "torch.amax().unsqueeze().unsqueeze().expand_as", "utils.helpers.to_variable", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "utils.helpers.to_variable", "criterion", "criterion", "len", "utils.helpers.to_variable", "utils.helpers.to_variable", "torch.amax().unsqueeze().unsqueeze", "torch.amax().unsqueeze().unsqueeze", "torch.amax().unsqueeze().unsqueeze", "torch.amax().unsqueeze().unsqueeze", "torch.amax().unsqueeze().unsqueeze", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.amax().unsqueeze", "torch.amax().unsqueeze", "torch.amax().unsqueeze", "torch.amax().unsqueeze", "torch.amax().unsqueeze", "utils.helpers.to_variable", "utils.helpers.to_variable", "utils.helpers.to_variable", "torch.amax", "torch.amax", "torch.amax", "torch.amax", "torch.amax"], "function", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.None.train.train", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.helpers.make_patches", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.helpers.make_patches", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.helpers.make_patches", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.vgg_perceptual_loss.VGGPerceptualLoss", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.helpers.to_variable", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.helpers.to_variable", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.helpers.to_variable", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.helpers.to_variable", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.helpers.to_variable", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.helpers.to_variable", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.helpers.to_variable", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.helpers.to_variable"], ["", "def", "train", "(", "epoch", ")", ":", "\n", "    ", "train_loss", "=", "0.0", "\n", "model", ".", "train", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "train_loader", ",", "0", ")", ":", "\n", "# Reading data.", "\n", "        ", "_", ",", "MS_image", ",", "PAN_image", ",", "reference", "=", "data", "\n", "\n", "# Making Smaller Patches for the training", "\n", "if", "config", "[", "\"trainer\"", "]", "[", "\"is_small_patch_train\"", "]", ":", "\n", "            ", "MS_image", ",", "_", "=", "make_patches", "(", "MS_image", ",", "patch_size", "=", "config", "[", "\"trainer\"", "]", "[", "\"patch_size\"", "]", ")", "\n", "PAN_image", ",", "_", "=", "make_patches", "(", "PAN_image", ",", "patch_size", "=", "config", "[", "\"trainer\"", "]", "[", "\"patch_size\"", "]", ")", "\n", "reference", ",", "_", "=", "make_patches", "(", "reference", ",", "patch_size", "=", "config", "[", "\"trainer\"", "]", "[", "\"patch_size\"", "]", ")", "\n", "\n", "# Taking model outputs ...", "\n", "", "MS_image", "=", "Variable", "(", "MS_image", ".", "float", "(", ")", ".", "cuda", "(", ")", ")", "\n", "PAN_image", "=", "Variable", "(", "PAN_image", ".", "float", "(", ")", ".", "cuda", "(", ")", ")", "\n", "out", "=", "model", "(", "MS_image", ",", "PAN_image", ")", "\n", "\n", "outputs", "=", "out", "[", "\"pred\"", "]", "\n", "\n", "######### Computing loss #########", "\n", "# Normal L1 loss", "\n", "if", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"Normalized_L1\"", "]", ":", "\n", "            ", "max_ref", "=", "torch", ".", "amax", "(", "reference", ",", "dim", "=", "(", "2", ",", "3", ")", ")", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "3", ")", ".", "expand_as", "(", "reference", ")", ".", "cuda", "(", ")", "\n", "loss", "=", "criterion", "(", "outputs", "/", "max_ref", ",", "to_variable", "(", "reference", ")", "/", "max_ref", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "criterion", "(", "outputs", ",", "to_variable", "(", "reference", ")", ")", "\n", "\n", "# VGG Perceptual Loss", "\n", "", "if", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"VGG_Loss\"", "]", ":", "\n", "            ", "predicted_RGB", "=", "torch", ".", "cat", "(", "(", "torch", ".", "mean", "(", "outputs", "[", ":", ",", "0", ":", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"G\"", "]", ",", ":", ",", ":", "]", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", ",", "\n", "torch", ".", "mean", "(", "outputs", "[", ":", ",", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"B\"", "]", ":", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"R\"", "]", ",", ":", ",", ":", "]", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", ",", "\n", "torch", ".", "mean", "(", "outputs", "[", ":", ",", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"G\"", "]", ":", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"spectral_bands\"", "]", ",", ":", ",", ":", "]", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", ",", "1", ")", "\n", "target_RGB", "=", "torch", ".", "cat", "(", "(", "torch", ".", "mean", "(", "to_variable", "(", "reference", ")", "[", ":", ",", "0", ":", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"G\"", "]", ",", ":", ",", ":", "]", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", ",", "\n", "torch", ".", "mean", "(", "to_variable", "(", "reference", ")", "[", ":", ",", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"B\"", "]", ":", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"R\"", "]", ",", ":", ",", ":", "]", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", ",", "\n", "torch", ".", "mean", "(", "to_variable", "(", "reference", ")", "[", ":", ",", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"G\"", "]", ":", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"spectral_bands\"", "]", ",", ":", ",", ":", "]", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", ",", "1", ")", "\n", "VGG_loss", "=", "VGGPerceptualLoss", "(", "predicted_RGB", ",", "target_RGB", ",", "vggnet", ")", "\n", "loss", "+=", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"VGG_Loss_F\"", "]", "*", "VGG_loss", "\n", "\n", "# Transfer Perceptual Loss", "\n", "", "if", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"Transfer_Periferal_Loss\"", "]", ":", "\n", "            ", "loss", "+=", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"Transfer_Periferal_Loss_F\"", "]", "*", "out", "[", "\"tp_loss\"", "]", "\n", "\n", "# Spatial loss", "\n", "", "if", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"Spatial_Loss\"", "]", ":", "\n", "            ", "loss", "+=", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"Spatial_Loss_F\"", "]", "*", "Spatial_loss", "(", "to_variable", "(", "reference", ")", ",", "outputs", ")", "\n", "\n", "# Spatial loss", "\n", "", "if", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"multi_scale_loss\"", "]", ":", "\n", "            ", "loss", "+=", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"multi_scale_loss_F\"", "]", "*", "criterion", "(", "to_variable", "(", "reference", ")", ",", "out", "[", "\"x13\"", "]", ")", "+", "2", "*", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"multi_scale_loss_F\"", "]", "*", "criterion", "(", "to_variable", "(", "reference", ")", ",", "out", "[", "\"x23\"", "]", ")", "\n", "\n", "", "torch", ".", "autograd", ".", "backward", "(", "loss", ")", "\n", "\n", "if", "i", "%", "config", "[", "\"trainer\"", "]", "[", "\"iter_size\"", "]", "==", "0", "or", "i", "==", "len", "(", "train_loader", ")", "-", "1", ":", "\n", "            ", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "", "writer", ".", "add_scalar", "(", "'Loss/train'", ",", "loss", ",", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.None.train.test": [[209, 326], ["model.eval", "len", "len", "len", "len", "len", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torchvision.utils.make_grid", "writer.add_image", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "torch.round.view().permute().contiguous", "torch.round.contiguous().view", "torch.round.view().permute().contiguous", "torch.round.contiguous().view", "MS_image.float().cuda.view().permute().contiguous", "MS_image.float().cuda.contiguous().view", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.interpolate", "MS_image.float().cuda.view", "torch.round.view", "torch.round.view", "float", "float", "float", "float", "float", "float", "MS_image.float().cuda.float().cuda", "PAN_image.float().cuda.float().cuda", "torch.round.float().cuda", "model", "criterion", "criterion.item", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "pred_dic.update", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "utils.metrics.cross_correlation", "utils.metrics.SAM", "utils.metrics.RMSE", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "utils.metrics.ERGAS", "utils.metrics.PSNR", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "utils.helpers.make_patches", "utils.helpers.make_patches", "utils.helpers.make_patches", "torch.round.view().permute", "torch.round.contiguous", "torch.round.view().permute", "torch.round.contiguous", "MS_image.float().cuda.view().permute", "MS_image.float().cuda.contiguous", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "MS_image.float().cuda.float", "PAN_image.float().cuda.float", "torch.round.float", "torch.squeeze().permute().cpu().numpy", "torch.squeeze().permute().cpu().numpy", "torch.squeeze().permute().cpu().numpy", "torch.squeeze().permute().cpu().numpy", "torch.squeeze().permute().cpu().numpy", "torch.round.detach", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.round.view", "torch.round.view", "MS_image.float().cuda.view", "torch.squeeze().permute().cpu", "torch.squeeze().permute().cpu", "torch.squeeze().permute().cpu", "torch.squeeze().permute().cpu", "torch.squeeze().permute().cpu", "[].split", "torch.squeeze().permute", "torch.squeeze().permute", "torch.squeeze().permute", "torch.squeeze().permute", "torch.squeeze().permute", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze"], "function", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.metrics.cross_correlation", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.metrics.SAM", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.metrics.RMSE", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.metrics.ERGAS", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.metrics.PSNR", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.helpers.make_patches", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.helpers.make_patches", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.helpers.make_patches"], ["", "def", "test", "(", "epoch", ")", ":", "\n", "    ", "test_loss", "=", "0.0", "\n", "cc", "=", "0.0", "\n", "sam", "=", "0.0", "\n", "rmse", "=", "0.0", "\n", "ergas", "=", "0.0", "\n", "psnr", "=", "0.0", "\n", "val_outputs", "=", "{", "}", "\n", "model", ".", "eval", "(", ")", "\n", "pred_dic", "=", "{", "}", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "data", "in", "enumerate", "(", "test_loader", ",", "0", ")", ":", "\n", "            ", "image_dict", ",", "MS_image", ",", "PAN_image", ",", "reference", "=", "data", "\n", "\n", "# Generating small patches", "\n", "if", "config", "[", "\"trainer\"", "]", "[", "\"is_small_patch_train\"", "]", ":", "\n", "                ", "MS_image", ",", "unfold_shape", "=", "make_patches", "(", "MS_image", ",", "patch_size", "=", "config", "[", "\"trainer\"", "]", "[", "\"patch_size\"", "]", ")", "\n", "PAN_image", ",", "_", "=", "make_patches", "(", "PAN_image", ",", "patch_size", "=", "config", "[", "\"trainer\"", "]", "[", "\"patch_size\"", "]", ")", "\n", "reference", ",", "_", "=", "make_patches", "(", "reference", ",", "patch_size", "=", "config", "[", "\"trainer\"", "]", "[", "\"patch_size\"", "]", ")", "\n", "\n", "# Inputs and references...", "\n", "", "MS_image", "=", "MS_image", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "PAN_image", "=", "PAN_image", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "reference", "=", "reference", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "# Taking model output", "\n", "out", "=", "model", "(", "MS_image", ",", "PAN_image", ")", "\n", "\n", "outputs", "=", "out", "[", "\"pred\"", "]", "\n", "\n", "# Computing validation loss", "\n", "loss", "=", "criterion", "(", "outputs", ",", "reference", ")", "\n", "test_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "# Scalling", "\n", "outputs", "[", "outputs", "<", "0", "]", "=", "0.0", "\n", "outputs", "[", "outputs", ">", "1.0", "]", "=", "1.0", "\n", "outputs", "=", "torch", ".", "round", "(", "outputs", "*", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"max_value\"", "]", ")", "\n", "pred_dic", ".", "update", "(", "{", "image_dict", "[", "\"imgs\"", "]", "[", "0", "]", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", "+", "\"_pred\"", ":", "torch", ".", "squeeze", "(", "outputs", ")", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "}", ")", "\n", "reference", "=", "torch", ".", "round", "(", "reference", ".", "detach", "(", ")", "*", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"max_value\"", "]", ")", "\n", "\n", "\n", "### Computing performance metrics ###", "\n", "# Cross-correlation", "\n", "cc", "+=", "cross_correlation", "(", "outputs", ",", "reference", ")", "\n", "# SAM", "\n", "sam", "+=", "SAM", "(", "outputs", ",", "reference", ")", "\n", "# RMSE", "\n", "rmse", "+=", "RMSE", "(", "outputs", "/", "torch", ".", "max", "(", "reference", ")", ",", "reference", "/", "torch", ".", "max", "(", "reference", ")", ")", "\n", "# ERGAS", "\n", "beta", "=", "torch", ".", "tensor", "(", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"HR_size\"", "]", "/", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"LR_size\"", "]", ")", ".", "cuda", "(", ")", "\n", "ergas", "+=", "ERGAS", "(", "outputs", ",", "reference", ",", "beta", ")", "\n", "# PSNR", "\n", "psnr", "+=", "PSNR", "(", "outputs", ",", "reference", ")", "\n", "\n", "# Taking average of performance metrics over test set", "\n", "", "", "cc", "/=", "len", "(", "test_loader", ")", "\n", "sam", "/=", "len", "(", "test_loader", ")", "\n", "rmse", "/=", "len", "(", "test_loader", ")", "\n", "ergas", "/=", "len", "(", "test_loader", ")", "\n", "psnr", "/=", "len", "(", "test_loader", ")", "\n", "\n", "# Writing test results to tensorboard", "\n", "writer", ".", "add_scalar", "(", "'Loss/test'", ",", "test_loss", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'Test_Metrics/CC'", ",", "cc", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'Test_Metrics/SAM'", ",", "sam", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'Test_Metrics/RMSE'", ",", "rmse", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'Test_Metrics/ERGAS'", ",", "ergas", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'Test_Metrics/PSNR'", ",", "psnr", ",", "epoch", ")", "\n", "\n", "# Images to tensorboard", "\n", "# Regenerating the final image", "\n", "if", "config", "[", "\"trainer\"", "]", "[", "\"is_small_patch_train\"", "]", ":", "\n", "        ", "outputs", "=", "outputs", ".", "view", "(", "unfold_shape", ")", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "2", ",", "5", ",", "3", ",", "6", ")", ".", "contiguous", "(", ")", "\n", "outputs", "=", "outputs", ".", "contiguous", "(", ")", ".", "view", "(", "config", "[", "\"val_batch_size\"", "]", ",", "\n", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"spectral_bands\"", "]", ",", "\n", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"HR_size\"", "]", ",", "\n", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"HR_size\"", "]", ")", "\n", "reference", "=", "reference", ".", "view", "(", "unfold_shape", ")", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "2", ",", "5", ",", "3", ",", "6", ")", ".", "contiguous", "(", ")", "\n", "reference", "=", "reference", ".", "contiguous", "(", ")", ".", "view", "(", "config", "[", "\"val_batch_size\"", "]", ",", "\n", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"spectral_bands\"", "]", ",", "\n", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"HR_size\"", "]", ",", "\n", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"HR_size\"", "]", ")", "\n", "MS_image", "=", "MS_image", ".", "view", "(", "unfold_shape", ")", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "2", ",", "5", ",", "3", ",", "6", ")", ".", "contiguous", "(", ")", "\n", "MS_image", "=", "MS_image", ".", "contiguous", "(", ")", ".", "view", "(", "config", "[", "\"val_batch_size\"", "]", ",", "\n", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"spectral_bands\"", "]", ",", "\n", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"HR_size\"", "]", ",", "\n", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"HR_size\"", "]", ")", "\n", "\n", "#Normalizing the images", "\n", "", "outputs", "=", "outputs", "/", "torch", ".", "max", "(", "reference", ")", "\n", "reference", "=", "reference", "/", "torch", ".", "max", "(", "reference", ")", "\n", "MS_image", "=", "MS_image", "/", "torch", ".", "max", "(", "reference", ")", "\n", "if", "config", "[", "\"model\"", "]", "==", "\"HyperPNN\"", "or", "config", "[", "\"is_DHP_MS\"", "]", "==", "False", ":", "\n", "        ", "MS_image", "=", "F", ".", "interpolate", "(", "MS_image", ",", "scale_factor", "=", "(", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"factor\"", "]", ",", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"factor\"", "]", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "\n", "", "ms", "=", "torch", ".", "unsqueeze", "(", "MS_image", ".", "view", "(", "-", "1", ",", "MS_image", ".", "shape", "[", "-", "2", "]", ",", "MS_image", ".", "shape", "[", "-", "1", "]", ")", ",", "1", ")", "\n", "pred", "=", "torch", ".", "unsqueeze", "(", "outputs", ".", "view", "(", "-", "1", ",", "outputs", ".", "shape", "[", "-", "2", "]", ",", "outputs", ".", "shape", "[", "-", "1", "]", ")", ",", "1", ")", "\n", "ref", "=", "torch", ".", "unsqueeze", "(", "reference", ".", "view", "(", "-", "1", ",", "reference", ".", "shape", "[", "-", "2", "]", ",", "reference", ".", "shape", "[", "-", "1", "]", ")", ",", "1", ")", "\n", "imgs", "=", "torch", ".", "zeros", "(", "5", "*", "pred", ".", "shape", "[", "0", "]", ",", "pred", ".", "shape", "[", "1", "]", ",", "pred", ".", "shape", "[", "2", "]", ",", "pred", ".", "shape", "[", "3", "]", ")", "\n", "for", "i", "in", "range", "(", "pred", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "imgs", "[", "5", "*", "i", "]", "=", "ms", "[", "i", "]", "\n", "imgs", "[", "5", "*", "i", "+", "1", "]", "=", "torch", ".", "abs", "(", "ms", "[", "i", "]", "-", "pred", "[", "i", "]", ")", "/", "torch", ".", "max", "(", "torch", ".", "abs", "(", "ms", "[", "i", "]", "-", "pred", "[", "i", "]", ")", ")", "\n", "imgs", "[", "5", "*", "i", "+", "2", "]", "=", "pred", "[", "i", "]", "\n", "imgs", "[", "5", "*", "i", "+", "3", "]", "=", "ref", "[", "i", "]", "\n", "imgs", "[", "5", "*", "i", "+", "4", "]", "=", "torch", ".", "abs", "(", "ref", "[", "i", "]", "-", "ms", "[", "i", "]", ")", "/", "torch", ".", "max", "(", "torch", ".", "abs", "(", "ref", "[", "i", "]", "-", "ms", "[", "i", "]", ")", ")", "\n", "", "imgs", "=", "torchvision", ".", "utils", ".", "make_grid", "(", "imgs", ",", "nrow", "=", "5", ")", "\n", "writer", ".", "add_image", "(", "'Images'", ",", "imgs", ",", "epoch", ")", "\n", "\n", "#Return Outputs", "\n", "metrics", "=", "{", "\"loss\"", ":", "float", "(", "test_loss", ")", ",", "\n", "\"cc\"", ":", "float", "(", "cc", ")", ",", "\n", "\"sam\"", ":", "float", "(", "sam", ")", ",", "\n", "\"rmse\"", ":", "float", "(", "rmse", ")", ",", "\n", "\"ergas\"", ":", "float", "(", "ergas", ")", ",", "\n", "\"psnr\"", ":", "float", "(", "psnr", ")", "}", "\n", "return", "image_dict", ",", "pred_dic", ",", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.vgg_perceptual_loss.VGG19.__init__": [[7, 16], ["torch.Module.__init__", "torchvision.models.vgg19", "torchvision.models.vgg19", "torchvision.models.vgg19", "torchvision.models.vgg19", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "list", "torchvision.models.vgg19.features.children", "torchvision.models.vgg19.features.children"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "VGG19", ",", "self", ")", ".", "__init__", "(", ")", "\n", "'''\n         use vgg19 conv1_2, conv2_2, conv3_3 feature, before relu layer\n        '''", "\n", "self", ".", "feature_list", "=", "[", "2", ",", "7", ",", "14", "]", "\n", "vgg19", "=", "torchvision", ".", "models", ".", "vgg19", "(", "pretrained", "=", "True", ")", "\n", "\n", "self", ".", "model", "=", "torch", ".", "nn", ".", "Sequential", "(", "*", "list", "(", "vgg19", ".", "features", ".", "children", "(", ")", ")", "[", ":", "self", ".", "feature_list", "[", "-", "1", "]", "+", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.vgg_perceptual_loss.VGG19.forward": [[18, 26], ["enumerate", "list", "layer", "features.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "(", "x", "-", "0.5", ")", "/", "0.5", "\n", "features", "=", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "list", "(", "self", ".", "model", ")", ")", ":", "\n", "            ", "x", "=", "layer", "(", "x", ")", "\n", "if", "i", "in", "self", ".", "feature_list", ":", "\n", "                ", "features", ".", "append", "(", "x", ")", "\n", "", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.vgg_perceptual_loss.VGGPerceptualLoss": [[27, 44], ["vggnet", "vggnet", "torch.MSELoss", "range", "f_real.detach", "len", "nn.MSELoss."], "function", ["None"], ["", "", "def", "VGGPerceptualLoss", "(", "fakeIm", ",", "realIm", ",", "vggnet", ")", ":", "\n", "    ", "'''\n    use vgg19 conv1_2, conv2_2, conv3_3 feature, before relu layer\n    '''", "\n", "\n", "weights", "=", "[", "1", ",", "0.2", ",", "0.04", "]", "\n", "features_fake", "=", "vggnet", "(", "fakeIm", ")", "\n", "features_real", "=", "vggnet", "(", "realIm", ")", "\n", "features_real_no_grad", "=", "[", "f_real", ".", "detach", "(", ")", "for", "f_real", "in", "features_real", "]", "\n", "mse_loss", "=", "nn", ".", "MSELoss", "(", "reduction", "=", "'elementwise_mean'", ")", "\n", "\n", "loss", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "features_real", ")", ")", ":", "\n", "        ", "loss_i", "=", "mse_loss", "(", "features_fake", "[", "i", "]", ",", "features_real_no_grad", "[", "i", "]", ")", "\n", "loss", "=", "loss", "+", "loss_i", "*", "weights", "[", "i", "]", "\n", "\n", "", "return", "loss", "", "", ""]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.crop_image": [[13, 28], ["img.crop", "int", "int", "int", "int"], "function", ["None"], ["def", "crop_image", "(", "img", ",", "d", "=", "32", ")", ":", "\n", "    ", "'''Make dimensions divisible by `d`'''", "\n", "\n", "new_size", "=", "(", "img", ".", "size", "[", "0", "]", "-", "img", ".", "size", "[", "0", "]", "%", "d", ",", "\n", "img", ".", "size", "[", "1", "]", "-", "img", ".", "size", "[", "1", "]", "%", "d", ")", "\n", "\n", "bbox", "=", "[", "\n", "int", "(", "(", "img", ".", "size", "[", "0", "]", "-", "new_size", "[", "0", "]", ")", "/", "2", ")", ",", "\n", "int", "(", "(", "img", ".", "size", "[", "1", "]", "-", "new_size", "[", "1", "]", ")", "/", "2", ")", ",", "\n", "int", "(", "(", "img", ".", "size", "[", "0", "]", "+", "new_size", "[", "0", "]", ")", "/", "2", ")", ",", "\n", "int", "(", "(", "img", ".", "size", "[", "1", "]", "+", "new_size", "[", "1", "]", ")", "/", "2", ")", ",", "\n", "]", "\n", "\n", "img_cropped", "=", "img", ".", "crop", "(", "bbox", ")", "\n", "return", "img_cropped", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.get_params": [[29, 54], ["opt_over.split", "net.parameters", "downsampler.parameters"], "function", ["None"], ["", "def", "get_params", "(", "opt_over", ",", "net", ",", "net_input", ",", "downsampler", "=", "None", ")", ":", "\n", "    ", "'''Returns parameters that we want to optimize over.\n\n    Args:\n        opt_over: comma separated list, e.g. \"net,input\" or \"net\"\n        net: network\n        net_input: torch.Tensor that stores input `z`\n    '''", "\n", "opt_over_list", "=", "opt_over", ".", "split", "(", "','", ")", "\n", "params", "=", "[", "]", "\n", "\n", "for", "opt", "in", "opt_over_list", ":", "\n", "\n", "        ", "if", "opt", "==", "'net'", ":", "\n", "            ", "params", "+=", "[", "x", "for", "x", "in", "net", ".", "parameters", "(", ")", "]", "\n", "", "elif", "opt", "==", "'down'", ":", "\n", "            ", "assert", "downsampler", "is", "not", "None", "\n", "params", "=", "[", "x", "for", "x", "in", "downsampler", ".", "parameters", "(", ")", "]", "\n", "", "elif", "opt", "==", "'input'", ":", "\n", "            ", "net_input", ".", "requires_grad", "=", "True", "\n", "params", "+=", "[", "net_input", "]", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "'what is it?'", "\n", "\n", "", "", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.get_image_grid": [[55, 61], ["torchvision.utils.make_grid", "torchvision.utils.make_grid.numpy", "torch.from_numpy", "torch.from_numpy"], "function", ["None"], ["", "def", "get_image_grid", "(", "images_np", ",", "nrow", "=", "8", ")", ":", "\n", "    ", "'''Creates a grid from a list of images by concatenating them.'''", "\n", "images_torch", "=", "[", "torch", ".", "from_numpy", "(", "x", ")", "for", "x", "in", "images_np", "]", "\n", "torch_grid", "=", "torchvision", ".", "utils", ".", "make_grid", "(", "images_torch", ",", "nrow", ")", "\n", "\n", "return", "torch_grid", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.plot_image_grid": [[62, 88], ["max", "common_utils.get_image_grid", "matplotlib.figure", "matplotlib.show", "matplotlib.imshow", "matplotlib.imshow", "numpy.concatenate", "get_image_grid.transpose", "len"], "function", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.get_image_grid"], ["", "def", "plot_image_grid", "(", "images_np", ",", "nrow", "=", "8", ",", "factor", "=", "1", ",", "interpolation", "=", "'lanczos'", ")", ":", "\n", "    ", "\"\"\"Draws images in a grid\n    \n    Args:\n        images_np: list of images, each image is np.array of size 3xHxW of 1xHxW\n        nrow: how many images will be in one row\n        factor: size if the plt.figure \n        interpolation: interpolation used in plt.imshow\n    \"\"\"", "\n", "n_channels", "=", "max", "(", "x", ".", "shape", "[", "0", "]", "for", "x", "in", "images_np", ")", "\n", "assert", "(", "n_channels", "==", "3", ")", "or", "(", "n_channels", "==", "1", ")", ",", "\"images should have 1 or 3 channels\"", "\n", "\n", "images_np", "=", "[", "x", "if", "(", "x", ".", "shape", "[", "0", "]", "==", "n_channels", ")", "else", "np", ".", "concatenate", "(", "[", "x", ",", "x", ",", "x", "]", ",", "axis", "=", "0", ")", "for", "x", "in", "images_np", "]", "\n", "\n", "grid", "=", "get_image_grid", "(", "images_np", ",", "nrow", ")", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "len", "(", "images_np", ")", "+", "factor", ",", "12", "+", "factor", ")", ")", "\n", "\n", "if", "images_np", "[", "0", "]", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "        ", "plt", ".", "imshow", "(", "grid", "[", "0", "]", ",", "cmap", "=", "'gray'", ",", "interpolation", "=", "interpolation", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "imshow", "(", "grid", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", ",", "interpolation", "=", "interpolation", ")", "\n", "\n", "", "plt", ".", "show", "(", ")", "\n", "\n", "return", "grid", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.load": [[89, 93], ["PIL.Image.open"], "function", ["None"], ["", "def", "load", "(", "path", ")", ":", "\n", "    ", "\"\"\"Load PIL image.\"\"\"", "\n", "img", "=", "Image", ".", "open", "(", "path", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.get_image": [[94, 115], ["common_utils.load", "isinstance", "common_utils.pil_to_np", "img.resize.resize", "img.resize.resize"], "function", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.load", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.pil_to_np"], ["", "def", "get_image", "(", "path", ",", "imsize", "=", "-", "1", ")", ":", "\n", "    ", "\"\"\"Load an image and resize to a cpecific size. \n\n    Args: \n        path: path to image\n        imsize: tuple or scalar with dimensions; -1 for `no resize`\n    \"\"\"", "\n", "img", "=", "load", "(", "path", ")", "\n", "\n", "if", "isinstance", "(", "imsize", ",", "int", ")", ":", "\n", "        ", "imsize", "=", "(", "imsize", ",", "imsize", ")", "\n", "\n", "", "if", "imsize", "[", "0", "]", "!=", "-", "1", "and", "img", ".", "size", "!=", "imsize", ":", "\n", "        ", "if", "imsize", "[", "0", "]", ">", "img", ".", "size", "[", "0", "]", ":", "\n", "            ", "img", "=", "img", ".", "resize", "(", "imsize", ",", "Image", ".", "BICUBIC", ")", "\n", "", "else", ":", "\n", "            ", "img", "=", "img", ".", "resize", "(", "imsize", ",", "Image", ".", "ANTIALIAS", ")", "\n", "\n", "", "", "img_np", "=", "pil_to_np", "(", "img", ")", "\n", "\n", "return", "img", ",", "img_np", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.fill_noise": [[118, 126], ["x.uniform_", "x.normal_"], "function", ["None"], ["", "def", "fill_noise", "(", "x", ",", "noise_type", ")", ":", "\n", "    ", "\"\"\"Fills tensor `x` with noise of type `noise_type`.\"\"\"", "\n", "if", "noise_type", "==", "'u'", ":", "\n", "        ", "x", ".", "uniform_", "(", ")", "\n", "", "elif", "noise_type", "==", "'n'", ":", "\n", "        ", "x", ".", "normal_", "(", ")", "\n", "", "else", ":", "\n", "        ", "assert", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.get_noise": [[127, 154], ["isinstance", "torch.zeros", "torch.zeros", "common_utils.fill_noise", "numpy.meshgrid", "numpy.concatenate", "common_utils.np_to_torch", "numpy.arange", "float", "numpy.arange", "float"], "function", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.fill_noise", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.np_to_torch"], ["", "", "def", "get_noise", "(", "input_depth", ",", "method", ",", "spatial_size", ",", "noise_type", "=", "'u'", ",", "var", "=", "1.", "/", "10", ")", ":", "\n", "    ", "\"\"\"Returns a pytorch.Tensor of size (1 x `input_depth` x `spatial_size[0]` x `spatial_size[1]`) \n    initialized in a specific way.\n    Args:\n        input_depth: number of channels in the tensor\n        method: `noise` for fillting tensor with noise; `meshgrid` for np.meshgrid\n        spatial_size: spatial size of the tensor to initialize\n        noise_type: 'u' for uniform; 'n' for normal\n        var: a factor, a noise will be multiplicated by. Basically it is standard deviation scaler. \n    \"\"\"", "\n", "if", "isinstance", "(", "spatial_size", ",", "int", ")", ":", "\n", "        ", "spatial_size", "=", "(", "spatial_size", ",", "spatial_size", ")", "\n", "", "if", "method", "==", "'noise'", ":", "\n", "        ", "shape", "=", "[", "1", ",", "input_depth", ",", "spatial_size", "[", "0", "]", ",", "spatial_size", "[", "1", "]", "]", "\n", "net_input", "=", "torch", ".", "zeros", "(", "shape", ")", "\n", "\n", "fill_noise", "(", "net_input", ",", "noise_type", ")", "\n", "net_input", "*=", "var", "\n", "", "elif", "method", "==", "'meshgrid'", ":", "\n", "        ", "assert", "input_depth", "==", "2", "\n", "X", ",", "Y", "=", "np", ".", "meshgrid", "(", "np", ".", "arange", "(", "0", ",", "spatial_size", "[", "1", "]", ")", "/", "float", "(", "spatial_size", "[", "1", "]", "-", "1", ")", ",", "np", ".", "arange", "(", "0", ",", "spatial_size", "[", "0", "]", ")", "/", "float", "(", "spatial_size", "[", "0", "]", "-", "1", ")", ")", "\n", "meshgrid", "=", "np", ".", "concatenate", "(", "[", "X", "[", "None", ",", ":", "]", ",", "Y", "[", "None", ",", ":", "]", "]", ")", "\n", "net_input", "=", "np_to_torch", "(", "meshgrid", ")", "\n", "", "else", ":", "\n", "        ", "assert", "False", "\n", "\n", "", "return", "net_input", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.pil_to_np": [[155, 168], ["numpy.array", "len", "ar.transpose.transpose", "ar.transpose.astype"], "function", ["None"], ["", "def", "pil_to_np", "(", "img_PIL", ")", ":", "\n", "    ", "'''Converts image in PIL format to np.array.\n    \n    From W x H x C [0...255] to C x W x H [0..1]\n    '''", "\n", "ar", "=", "np", ".", "array", "(", "img_PIL", ")", "\n", "\n", "if", "len", "(", "ar", ".", "shape", ")", "==", "3", ":", "\n", "        ", "ar", "=", "ar", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "", "else", ":", "\n", "        ", "ar", "=", "ar", "[", "None", ",", "...", "]", "\n", "\n", "", "return", "ar", ".", "astype", "(", "np", ".", "float32", ")", "/", "255.", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.np_to_pil": [[169, 182], ["numpy.clip().astype", "PIL.Image.fromarray", "ar.transpose.transpose", "numpy.clip"], "function", ["None"], ["", "def", "np_to_pil", "(", "img_np", ")", ":", "\n", "    ", "'''Converts image in np.array format to PIL image.\n    \n    From C x W x H [0..1] to  W x H x C [0...255]\n    '''", "\n", "ar", "=", "np", ".", "clip", "(", "img_np", "*", "255", ",", "0", ",", "255", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n", "if", "img_np", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "        ", "ar", "=", "ar", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "ar", "=", "ar", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "\n", "", "return", "Image", ".", "fromarray", "(", "ar", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.np_to_torch": [[183, 189], ["torch.from_numpy", "torch.from_numpy"], "function", ["None"], ["", "def", "np_to_torch", "(", "img_np", ")", ":", "\n", "    ", "'''Converts image in numpy.array to torch.Tensor.\n\n    From C x W x H [0..1] to  C x W x H [0..1]\n    '''", "\n", "return", "torch", ".", "from_numpy", "(", "img_np", ")", "[", "None", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.torch_to_np": [[190, 196], ["img_var.detach().cpu().numpy", "img_var.detach().cpu", "img_var.detach"], "function", ["None"], ["", "def", "torch_to_np", "(", "img_var", ")", ":", "\n", "    ", "'''Converts an image in torch.Tensor format to np.array.\n\n    From 1 x C x W x H [0..1] to  C x W x H [0..1]\n    '''", "\n", "return", "img_var", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.optimize": [[198, 238], ["torch.optim.Adam", "torch.optim.Adam", "range", "print", "torch.optim.LBFGS", "torch.optim.LBFGS", "torch.optim.Adam.step", "torch.optim.Adam.zero_grad", "closure", "torch.optim.Adam.step", "torch.optim.Adam.zero_grad", "closure", "print", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "range", "torch.optim.lr_scheduler.StepLR.step", "torch.optim.Adam.zero_grad", "closure", "torch.optim.Adam.step"], "function", ["None"], ["", "def", "optimize", "(", "optimizer_type", ",", "parameters", ",", "closure", ",", "LR", ",", "num_iter", ",", "step_size", ",", "gamma", ")", ":", "\n", "    ", "\"\"\"Runs optimization loop.\n\n    Args:\n        optimizer_type: 'LBFGS' of 'adam'\n        parameters: list of Tensors to optimize over\n        closure: function, that returns loss variable\n        LR: learning rate\n        num_iter: number of iterations \n    \"\"\"", "\n", "if", "optimizer_type", "==", "'LBFGS'", ":", "\n", "# Do several steps with adam first", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "parameters", ",", "lr", "=", "0.001", ")", "\n", "for", "j", "in", "range", "(", "100", ")", ":", "\n", "            ", "optimizer", ".", "zero_grad", "(", ")", "\n", "closure", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "print", "(", "'Starting optimization with LBFGS'", ")", "\n", "def", "closure2", "(", ")", ":", "\n", "            ", "optimizer", ".", "zero_grad", "(", ")", "\n", "return", "closure", "(", ")", "\n", "", "optimizer", "=", "torch", ".", "optim", ".", "LBFGS", "(", "parameters", ",", "max_iter", "=", "num_iter", ",", "lr", "=", "LR", ",", "tolerance_grad", "=", "-", "1", ",", "tolerance_change", "=", "-", "1", ")", "\n", "optimizer", ".", "step", "(", "closure2", ")", "\n", "\n", "", "elif", "optimizer_type", "==", "'adam'", ":", "\n", "        ", "print", "(", "'Starting optimization with ADAM'", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "parameters", ",", "lr", "=", "LR", ")", "\n", "# LEARNING RATE SHEDULER", "\n", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "optimizer", ",", "\n", "step_size", ",", "\n", "gamma", ")", "\n", "\n", "for", "j", "in", "range", "(", "num_iter", ")", ":", "\n", "            ", "scheduler", ".", "step", "(", "j", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "closure", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "", "", "else", ":", "\n", "        ", "assert", "False", "", "", "", ""]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.metrics.cross_correlation": [[6, 21], ["H_fuse.view", "H_ref.view", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean", "torch.sum", "torch.sqrt", "torch.mean", "torch.mean", "torch.sum", "torch.sum"], "function", ["None"], ["def", "cross_correlation", "(", "H_fuse", ",", "H_ref", ")", ":", "\n", "    ", "N_spectral", "=", "H_fuse", ".", "shape", "[", "1", "]", "\n", "\n", "# Rehsaping fused and reference data", "\n", "H_fuse_reshaped", "=", "H_fuse", ".", "view", "(", "N_spectral", ",", "-", "1", ")", "\n", "H_ref_reshaped", "=", "H_ref", ".", "view", "(", "N_spectral", ",", "-", "1", ")", "\n", "\n", "# Calculating mean value", "\n", "mean_fuse", "=", "torch", ".", "mean", "(", "H_fuse_reshaped", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "mean_ref", "=", "torch", ".", "mean", "(", "H_ref_reshaped", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "CC", "=", "torch", ".", "sum", "(", "(", "H_fuse_reshaped", "-", "mean_fuse", ")", "*", "(", "H_ref_reshaped", "-", "mean_ref", ")", ",", "1", ")", "/", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "(", "H_fuse_reshaped", "-", "mean_fuse", ")", "**", "2", ",", "1", ")", "*", "torch", ".", "sum", "(", "(", "H_ref_reshaped", "-", "mean_ref", ")", "**", "2", ",", "1", ")", ")", "\n", "\n", "CC", "=", "torch", ".", "mean", "(", "CC", ")", "\n", "return", "CC", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.metrics.SAM": [[23, 40], ["H_fuse.view", "H_ref.view", "torch.nansum", "torch.nansum().sqrt", "torch.nansum().sqrt", "torch.rad2deg", "torch.nansum", "torch.nansum", "torch.nansum", "torch.acos"], "function", ["None"], ["", "def", "SAM", "(", "H_fuse", ",", "H_ref", ")", ":", "\n", "#Compute number of spectral bands", "\n", "    ", "N_spectral", "=", "H_fuse", ".", "shape", "[", "1", "]", "\n", "\n", "# Rehsaping fused and reference data", "\n", "H_fuse_reshaped", "=", "H_fuse", ".", "view", "(", "N_spectral", ",", "-", "1", ")", "\n", "H_ref_reshaped", "=", "H_ref", ".", "view", "(", "N_spectral", ",", "-", "1", ")", "\n", "N_pixels", "=", "H_fuse_reshaped", ".", "shape", "[", "1", "]", "\n", "\n", "# Calculating inner product", "\n", "inner_prod", "=", "torch", ".", "nansum", "(", "H_fuse_reshaped", "*", "H_ref_reshaped", ",", "0", ")", "\n", "fuse_norm", "=", "torch", ".", "nansum", "(", "H_fuse_reshaped", "**", "2", ",", "dim", "=", "0", ")", ".", "sqrt", "(", ")", "\n", "ref_norm", "=", "torch", ".", "nansum", "(", "H_ref_reshaped", "**", "2", ",", "dim", "=", "0", ")", ".", "sqrt", "(", ")", "\n", "\n", "# Calculating SAM", "\n", "SAM", "=", "torch", ".", "rad2deg", "(", "torch", ".", "nansum", "(", "torch", ".", "acos", "(", "inner_prod", "/", "(", "fuse_norm", "*", "ref_norm", ")", ")", ")", "/", "N_pixels", ")", "\n", "return", "SAM", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.metrics.RMSE": [[42, 50], ["H_fuse.view", "H_ref.view", "torch.sqrt", "torch.nansum"], "function", ["None"], ["", "def", "RMSE", "(", "H_fuse", ",", "H_ref", ")", ":", "\n", "# Rehsaping fused and reference data", "\n", "    ", "H_fuse_reshaped", "=", "H_fuse", ".", "view", "(", "-", "1", ")", "\n", "H_ref_reshaped", "=", "H_ref", ".", "view", "(", "-", "1", ")", "\n", "\n", "# Calculating RMSE", "\n", "RMSE", "=", "torch", ".", "sqrt", "(", "torch", ".", "nansum", "(", "(", "H_ref_reshaped", "-", "H_fuse_reshaped", ")", "**", "2", ")", "/", "H_fuse_reshaped", ".", "shape", "[", "0", "]", ")", "\n", "return", "RMSE", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.metrics.ERGAS": [[52, 69], ["H_fuse.view", "H_ref.view", "torch.sqrt", "torch.mean", "torch.sqrt", "torch.nansum", "torch.nansum", "torch.div"], "function", ["None"], ["", "def", "ERGAS", "(", "H_fuse", ",", "H_ref", ",", "beta", ")", ":", "\n", "\n", "#Compute number of spectral bands", "\n", "    ", "N_spectral", "=", "H_fuse", ".", "shape", "[", "1", "]", "\n", "\n", "# Reshaping images", "\n", "H_fuse_reshaped", "=", "H_fuse", ".", "view", "(", "N_spectral", ",", "-", "1", ")", "\n", "H_ref_reshaped", "=", "H_ref", ".", "view", "(", "N_spectral", ",", "-", "1", ")", "\n", "N_pixels", "=", "H_fuse_reshaped", ".", "shape", "[", "1", "]", "\n", "\n", "# Calculating RMSE of each band", "\n", "rmse", "=", "torch", ".", "sqrt", "(", "torch", ".", "nansum", "(", "(", "H_ref_reshaped", "-", "H_fuse_reshaped", ")", "**", "2", ",", "dim", "=", "1", ")", "/", "N_pixels", ")", "\n", "mu_ref", "=", "torch", ".", "mean", "(", "H_ref_reshaped", ",", "dim", "=", "1", ")", "\n", "\n", "# Calculating Erreur Relative Globale Adimensionnelle De Synth\u00e8se (ERGAS)", "\n", "ERGAS", "=", "100", "*", "(", "1", "/", "beta", "**", "2", ")", "*", "torch", ".", "sqrt", "(", "torch", ".", "nansum", "(", "torch", ".", "div", "(", "rmse", ",", "mu_ref", ")", "**", "2", ")", "/", "N_spectral", ")", "\n", "return", "ERGAS", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.metrics.PSNR": [[72, 90], ["H_fuse.view", "H_ref.view", "torch.sqrt", "torch.max", "torch.nansum", "torch.sum", "torch.log10", "torch.div"], "function", ["None"], ["", "def", "PSNR", "(", "H_fuse", ",", "H_ref", ")", ":", "\n", "#Compute number of spectral bands", "\n", "    ", "N_spectral", "=", "H_fuse", ".", "shape", "[", "1", "]", "\n", "\n", "# Reshaping images", "\n", "H_fuse_reshaped", "=", "H_fuse", ".", "view", "(", "N_spectral", ",", "-", "1", ")", "\n", "H_ref_reshaped", "=", "H_ref", ".", "view", "(", "N_spectral", ",", "-", "1", ")", "\n", "\n", "# Calculating RMSE of each band", "\n", "rmse", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "(", "H_ref_reshaped", "-", "H_fuse_reshaped", ")", "**", "2", ",", "dim", "=", "1", ")", "/", "H_fuse_reshaped", ".", "shape", "[", "1", "]", ")", "\n", "\n", "# Calculating max of H_ref for each band", "\n", "max_H_ref", ",", "_", "=", "torch", ".", "max", "(", "H_ref_reshaped", ",", "dim", "=", "1", ")", "\n", "\n", "# Calculating PSNR", "\n", "PSNR", "=", "torch", ".", "nansum", "(", "10", "*", "torch", ".", "log10", "(", "torch", ".", "div", "(", "max_H_ref", ",", "rmse", ")", "**", "2", ")", ")", "/", "N_spectral", "\n", "\n", "return", "PSNR", "", "", ""]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.logger.Logger.__init__": [[13, 15], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "entries", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.logger.Logger.add_entry": [[16, 18], ["len"], "methods", ["None"], ["", "def", "add_entry", "(", "self", ",", "entry", ")", ":", "\n", "        ", "self", ".", "entries", "[", "len", "(", "self", ".", "entries", ")", "+", "1", "]", "=", "entry", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.logger.Logger.__str__": [[19, 21], ["json.dumps"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "json", ".", "dumps", "(", "self", ".", "entries", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.helpers.to_variable": [[9, 11], ["torch.autograd.Variable", "tensor.float().cuda", "tensor.float"], "function", ["None"], ["def", "to_variable", "(", "tensor", ",", "volatile", "=", "False", ",", "requires_grad", "=", "True", ")", ":", "\n", "    ", "return", "Variable", "(", "tensor", ".", "float", "(", ")", ".", "cuda", "(", ")", ",", "requires_grad", "=", "requires_grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.helpers.initialize_weights": [[13, 26], ["model.modules", "isinstance", "torch.init.kaiming_normal_", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "isinstance", "torch.init.normal_", "torch.init.constant_"], "function", ["None"], ["", "def", "initialize_weights", "(", "*", "models", ")", ":", "\n", "    ", "for", "model", "in", "models", ":", "\n", "        ", "for", "m", "in", "model", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "0", ",", "0.01", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.helpers.initialize_weights_new": [[28, 40], ["numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "numpy.random.seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "model.modules", "isinstance", "isinstance", "m.weight.data.normal_", "isinstance", "math.sqrt", "m.weight.data.fill_", "m.bias.data.zero_"], "function", ["None"], ["", "", "", "", "def", "initialize_weights_new", "(", "model", ",", "manual_seed", "=", "7", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "manual_seed", ")", "\n", "torch", ".", "manual_seed", "(", "manual_seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "manual_seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "manual_seed", ")", "\n", "for", "m", "in", "model", ".", "modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "m", ",", "nn", ".", "ConvTranspose2d", ")", ":", "\n", "            ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.0", "/", "n", ")", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "            ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.helpers.make_patches": [[41, 52], ["x.dim", "x.unfold().unfold().unfold", "patches.contiguous().view.size", "patches.contiguous().view.contiguous().view", "x.unfold().unfold", "patches.contiguous().view.size", "patches.contiguous().view.contiguous().view", "x.unfold().unfold", "patches.contiguous().view.contiguous", "x.unfold", "patches.contiguous().view.contiguous", "x.unfold"], "function", ["None"], ["", "", "", "def", "make_patches", "(", "x", ",", "patch_size", ")", ":", "\n", "    ", "if", "x", ".", "dim", "(", ")", ">", "3", ":", "\n", "        ", "channel_dim", "=", "x", ".", "shape", "[", "1", "]", "\n", "patches", "=", "x", ".", "unfold", "(", "1", ",", "channel_dim", ",", "channel_dim", ")", ".", "unfold", "(", "2", ",", "patch_size", ",", "patch_size", ")", ".", "unfold", "(", "3", ",", "patch_size", ",", "patch_size", ")", "\n", "unfold_shape", "=", "patches", ".", "size", "(", ")", "\n", "patches", "=", "patches", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "channel_dim", ",", "patch_size", ",", "patch_size", ")", "\n", "", "else", ":", "\n", "        ", "patches", "=", "x", ".", "unfold", "(", "2", ",", "patch_size", ",", "patch_size", ")", ".", "unfold", "(", "3", ",", "patch_size", ",", "patch_size", ")", "\n", "unfold_shape", "=", "patches", ".", "size", "(", ")", "\n", "patches", "=", "patches", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "patch_size", ",", "patch_size", ")", "\n", "", "return", "patches", ",", "unfold_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.augmentations.feature_dropout": [[4, 11], ["torch.mean", "torch.max", "threshold.view().expand_as.view().expand_as", "x.mul", "torch.mean.view", "numpy.random.uniform", "x.size", "threshold.view().expand_as.view", "x.size"], "function", ["None"], ["def", "feature_dropout", "(", "self", ",", "x", ")", ":", "\n", "        ", "attention", "=", "torch", ".", "mean", "(", "x", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "max_val", ",", "_", "=", "torch", ".", "max", "(", "attention", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "threshold", "=", "max_val", "*", "np", ".", "random", ".", "uniform", "(", "0.7", ",", "0.9", ")", "\n", "threshold", "=", "threshold", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "attention", ")", "\n", "drop_mask", "=", "(", "attention", "<", "threshold", ")", ".", "float", "(", ")", "\n", "return", "x", ".", "mul", "(", "drop_mask", ")", "", "", ""]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.spatial_loss.Spatial_Loss.__init__": [[6, 13], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.L1Loss", "torch.L1Loss"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "Spatial_Loss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "res_scale", "=", "in_channels", "\n", "\n", "self", ".", "make_PAN", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "1", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ")", "\n", "\n", "self", ".", "L1_loss", "=", "nn", ".", "L1Loss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.spatial_loss.Spatial_Loss.forward": [[14, 20], ["spatial_loss.Spatial_Loss.Spatial_Loss.make_PAN", "spatial_loss.Spatial_Loss.Spatial_Loss.L1_loss", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "spatial_loss.Spatial_Loss.Spatial_Loss.make_PAN", "spatial_loss.Spatial_Loss.Spatial_Loss.detach"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "ref_HS", ",", "pred_HS", ")", ":", "\n", "        ", "pan_pred", "=", "self", ".", "make_PAN", "(", "pred_HS", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "pan_ref", "=", "self", ".", "make_PAN", "(", "ref_HS", ")", "\n", "", "spatial_loss", "=", "self", ".", "L1_loss", "(", "pan_pred", ",", "pan_ref", ".", "detach", "(", ")", ")", "\n", "return", "spatial_loss", "", "", "", ""]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.sr_utils.put_in_center": [[3, 16], ["np.zeros", "int", "int", "int", "int"], "function", ["None"], ["def", "put_in_center", "(", "img_np", ",", "target_size", ")", ":", "\n", "    ", "img_out", "=", "np", ".", "zeros", "(", "[", "3", ",", "target_size", "[", "0", "]", ",", "target_size", "[", "1", "]", "]", ")", "\n", "\n", "bbox", "=", "[", "\n", "int", "(", "(", "target_size", "[", "0", "]", "-", "img_np", ".", "shape", "[", "1", "]", ")", "/", "2", ")", ",", "\n", "int", "(", "(", "target_size", "[", "1", "]", "-", "img_np", ".", "shape", "[", "2", "]", ")", "/", "2", ")", ",", "\n", "int", "(", "(", "target_size", "[", "0", "]", "+", "img_np", ".", "shape", "[", "1", "]", ")", "/", "2", ")", ",", "\n", "int", "(", "(", "target_size", "[", "1", "]", "+", "img_np", ".", "shape", "[", "2", "]", ")", "/", "2", ")", ",", "\n", "]", "\n", "\n", "img_out", "[", ":", ",", "bbox", "[", "0", "]", ":", "bbox", "[", "2", "]", ",", "bbox", "[", "1", "]", ":", "bbox", "[", "3", "]", "]", "=", "img_np", "\n", "\n", "return", "img_out", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.sr_utils.load_LR_HR_imgs_sr": [[18, 66], ["common_utils.get_image", "img_orig_pil.crop.resize", "common_utils.pil_to_np", "print", "common_utils.get_image", "img_orig_pil.crop", "common_utils.pil_to_np", "str", "str"], "function", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.get_image", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.pil_to_np", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.get_image", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.pil_to_np"], ["", "def", "load_LR_HR_imgs_sr", "(", "fname", ",", "imsize", ",", "factor", ",", "enforse_div32", "=", "None", ")", ":", "\n", "    ", "'''Loads an image, resizes it, center crops and downscales.\n\n    Args: \n        fname: path to the image\n        imsize: new size for the image, -1 for no resizing\n        factor: downscaling factor\n        enforse_div32: if 'CROP' center crops an image, so that its dimensions are divisible by 32.\n    '''", "\n", "img_orig_pil", ",", "img_orig_np", "=", "get_image", "(", "fname", ",", "-", "1", ")", "\n", "\n", "if", "imsize", "!=", "-", "1", ":", "\n", "        ", "img_orig_pil", ",", "img_orig_np", "=", "get_image", "(", "fname", ",", "imsize", ")", "\n", "\n", "# For comparison with GT", "\n", "", "if", "enforse_div32", "==", "'CROP'", ":", "\n", "        ", "new_size", "=", "(", "img_orig_pil", ".", "size", "[", "0", "]", "-", "img_orig_pil", ".", "size", "[", "0", "]", "%", "32", ",", "\n", "img_orig_pil", ".", "size", "[", "1", "]", "-", "img_orig_pil", ".", "size", "[", "1", "]", "%", "32", ")", "\n", "\n", "bbox", "=", "[", "\n", "(", "img_orig_pil", ".", "size", "[", "0", "]", "-", "new_size", "[", "0", "]", ")", "/", "2", ",", "\n", "(", "img_orig_pil", ".", "size", "[", "1", "]", "-", "new_size", "[", "1", "]", ")", "/", "2", ",", "\n", "(", "img_orig_pil", ".", "size", "[", "0", "]", "+", "new_size", "[", "0", "]", ")", "/", "2", ",", "\n", "(", "img_orig_pil", ".", "size", "[", "1", "]", "+", "new_size", "[", "1", "]", ")", "/", "2", ",", "\n", "]", "\n", "\n", "img_HR_pil", "=", "img_orig_pil", ".", "crop", "(", "bbox", ")", "\n", "img_HR_np", "=", "pil_to_np", "(", "img_HR_pil", ")", "\n", "", "else", ":", "\n", "        ", "img_HR_pil", ",", "img_HR_np", "=", "img_orig_pil", ",", "img_orig_np", "\n", "\n", "", "LR_size", "=", "[", "\n", "img_HR_pil", ".", "size", "[", "0", "]", "//", "factor", ",", "\n", "img_HR_pil", ".", "size", "[", "1", "]", "//", "factor", "\n", "]", "\n", "\n", "img_LR_pil", "=", "img_HR_pil", ".", "resize", "(", "LR_size", ",", "Image", ".", "ANTIALIAS", ")", "\n", "img_LR_np", "=", "pil_to_np", "(", "img_LR_pil", ")", "\n", "\n", "print", "(", "'HR and LR resolutions: %s, %s'", "%", "(", "str", "(", "img_HR_pil", ".", "size", ")", ",", "str", "(", "img_LR_pil", ".", "size", ")", ")", ")", "\n", "\n", "return", "{", "\n", "'orig_pil'", ":", "img_orig_pil", ",", "\n", "'orig_np'", ":", "img_orig_np", ",", "\n", "'LR_pil'", ":", "img_LR_pil", ",", "\n", "'LR_np'", ":", "img_LR_np", ",", "\n", "'HR_pil'", ":", "img_HR_pil", ",", "\n", "'HR_np'", ":", "img_HR_np", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.sr_utils.get_baselines": [[69, 81], ["img_LR_pil.resize", "common_utils.pil_to_np", "img_LR_pil.resize", "common_utils.pil_to_np", "img_LR_pil.resize.filter", "common_utils.pil_to_np", "PIL.ImageFilter.UnsharpMask"], "function", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.pil_to_np", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.pil_to_np", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.common_utils.pil_to_np"], ["", "def", "get_baselines", "(", "img_LR_pil", ",", "img_HR_pil", ")", ":", "\n", "    ", "'''Gets `bicubic`, sharpened bicubic and `nearest` baselines.'''", "\n", "img_bicubic_pil", "=", "img_LR_pil", ".", "resize", "(", "img_HR_pil", ".", "size", ",", "Image", ".", "BICUBIC", ")", "\n", "img_bicubic_np", "=", "pil_to_np", "(", "img_bicubic_pil", ")", "\n", "\n", "img_nearest_pil", "=", "img_LR_pil", ".", "resize", "(", "img_HR_pil", ".", "size", ",", "Image", ".", "NEAREST", ")", "\n", "img_nearest_np", "=", "pil_to_np", "(", "img_nearest_pil", ")", "\n", "\n", "img_bic_sharp_pil", "=", "img_bicubic_pil", ".", "filter", "(", "PIL", ".", "ImageFilter", ".", "UnsharpMask", "(", ")", ")", "\n", "img_bic_sharp_np", "=", "pil_to_np", "(", "img_bic_sharp_pil", ")", "\n", "\n", "return", "img_bicubic_np", ",", "img_bic_sharp_np", ",", "img_nearest_np", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.utils.sr_utils.tv_loss": [[84, 95], ["torch.pow", "torch.pow", "torch.sum", "torch.pow"], "function", ["None"], ["", "def", "tv_loss", "(", "x", ",", "beta", "=", "0.5", ")", ":", "\n", "    ", "'''Calculates TV loss for an image `x`.\n        \n    Args:\n        x: image, torch.Variable of torch.Tensor\n        beta: See https://arxiv.org/abs/1412.0035 (fig. 2) to see effect of `beta` \n    '''", "\n", "dh", "=", "torch", ".", "pow", "(", "x", "[", ":", ",", ":", ",", ":", ",", "1", ":", "]", "-", "x", "[", ":", ",", ":", ",", ":", ",", ":", "-", "1", "]", ",", "2", ")", "\n", "dw", "=", "torch", ".", "pow", "(", "x", "[", ":", ",", ":", ",", "1", ":", ",", ":", "]", "-", "x", "[", ":", ",", ":", ",", ":", "-", "1", ",", ":", "]", ",", "2", ")", "\n", "\n", "return", "torch", ".", "sum", "(", "torch", ".", "pow", "(", "dh", "[", ":", ",", ":", ",", ":", "-", "1", "]", "+", "dw", "[", ":", ",", ":", ",", ":", ",", ":", "-", "1", "]", ",", "beta", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.ResBlock.__init__": [[20, 26], ["torch.nn.Module.__init__", "HyperTransformer.conv3x3", "torch.nn.ReLU", "torch.nn.ReLU", "HyperTransformer.conv3x3"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__init__", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "res_scale", "=", "1", ")", ":", "\n", "        ", "super", "(", "ResBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "res_scale", "=", "res_scale", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "in_channels", ",", "out_channels", ",", "stride", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "out_channels", ",", "out_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.ResBlock.forward": [[27, 34], ["HyperTransformer.ResBlock.conv1", "HyperTransformer.ResBlock.relu", "HyperTransformer.ResBlock.conv2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x1", "=", "x", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "out", "*", "self", ".", "res_scale", "+", "x1", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.SFE.__init__": [[36, 47], ["torch.nn.Module.__init__", "HyperTransformer.conv3x3", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "HyperTransformer.conv3x3", "HyperTransformer.SFE.RBs.append", "HyperTransformer.ResBlock"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__init__", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3"], ["    ", "def", "__init__", "(", "self", ",", "in_feats", ",", "num_res_blocks", ",", "n_feats", ",", "res_scale", ")", ":", "\n", "        ", "super", "(", "SFE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_res_blocks", "=", "num_res_blocks", "\n", "self", ".", "conv_head", "=", "conv3x3", "(", "in_feats", ",", "n_feats", ")", "\n", "\n", "self", ".", "RBs", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_res_blocks", ")", ":", "\n", "            ", "self", ".", "RBs", ".", "append", "(", "ResBlock", "(", "in_channels", "=", "n_feats", ",", "out_channels", "=", "n_feats", ",", "\n", "res_scale", "=", "res_scale", ")", ")", "\n", "\n", "", "self", ".", "conv_tail", "=", "conv3x3", "(", "n_feats", ",", "n_feats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.SFE.forward": [[48, 56], ["torch.relu", "torch.relu", "range", "HyperTransformer.SFE.conv_tail", "HyperTransformer.SFE.conv_head"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "conv_head", "(", "x", ")", ")", "\n", "x1", "=", "x", "\n", "for", "i", "in", "range", "(", "self", ".", "num_res_blocks", ")", ":", "\n", "            ", "x", "=", "self", ".", "RBs", "[", "i", "]", "(", "x", ")", "\n", "", "x", "=", "self", ".", "conv_tail", "(", "x", ")", "\n", "x", "=", "x", "+", "x1", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.CSFI2.__init__": [[59, 66], ["torch.nn.Module.__init__", "HyperTransformer.conv1x1", "HyperTransformer.conv3x3", "HyperTransformer.conv3x3", "HyperTransformer.conv3x3", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__init__", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv1x1", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3"], ["    ", "def", "__init__", "(", "self", ",", "n_feats", ")", ":", "\n", "        ", "super", "(", "CSFI2", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv12", "=", "conv1x1", "(", "n_feats", ",", "int", "(", "n_feats", "/", "2", ")", ")", "\n", "self", ".", "conv21", "=", "conv3x3", "(", "int", "(", "n_feats", "/", "2", ")", ",", "n_feats", ",", "2", ")", "\n", "\n", "self", ".", "conv_merge1", "=", "conv3x3", "(", "n_feats", "*", "2", ",", "n_feats", ")", "\n", "self", ".", "conv_merge2", "=", "conv3x3", "(", "n_feats", ",", "int", "(", "n_feats", "/", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.CSFI2.forward": [[67, 76], ["torch.interpolate", "torch.interpolate", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "HyperTransformer.CSFI2.conv12", "HyperTransformer.CSFI2.conv21", "HyperTransformer.CSFI2.conv_merge1", "HyperTransformer.CSFI2.conv_merge2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x1", ",", "x2", ")", ":", "\n", "        ", "x12", "=", "F", ".", "interpolate", "(", "x1", ",", "scale_factor", "=", "2", ",", "mode", "=", "'bicubic'", ")", "\n", "x12", "=", "F", ".", "relu", "(", "self", ".", "conv12", "(", "x12", ")", ")", "\n", "x21", "=", "F", ".", "relu", "(", "self", ".", "conv21", "(", "x2", ")", ")", "\n", "\n", "x1", "=", "F", ".", "relu", "(", "self", ".", "conv_merge1", "(", "torch", ".", "cat", "(", "(", "x1", ",", "x21", ")", ",", "dim", "=", "1", ")", ")", ")", "\n", "x2", "=", "F", ".", "relu", "(", "self", ".", "conv_merge2", "(", "torch", ".", "cat", "(", "(", "x2", ",", "x12", ")", ",", "dim", "=", "1", ")", ")", ")", "\n", "\n", "return", "x1", ",", "x2", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.CSFI3.__init__": [[79, 97], ["torch.nn.Module.__init__", "HyperTransformer.conv1x1", "HyperTransformer.conv1x1", "int", "HyperTransformer.conv3x3", "HyperTransformer.conv1x1", "int", "HyperTransformer.conv3x3", "HyperTransformer.conv3x3", "HyperTransformer.conv3x3", "HyperTransformer.conv3x3", "HyperTransformer.conv3x3", "HyperTransformer.conv3x3"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__init__", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv1x1", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv1x1", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv1x1", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3"], ["    ", "def", "__init__", "(", "self", ",", "n_feats", ")", ":", "\n", "        ", "super", "(", "CSFI3", ",", "self", ")", ".", "__init__", "(", ")", "\n", "n_feats1", "=", "n_feats", "\n", "self", ".", "conv12", "=", "conv1x1", "(", "n_feats1", ",", "n_feats1", ")", "\n", "self", ".", "conv13", "=", "conv1x1", "(", "n_feats1", ",", "n_feats1", ")", "\n", "\n", "n_feats2", "=", "int", "(", "n_feats", "/", "2", ")", "\n", "self", ".", "conv21", "=", "conv3x3", "(", "n_feats2", ",", "n_feats2", ",", "2", ")", "\n", "self", ".", "conv23", "=", "conv1x1", "(", "n_feats2", ",", "n_feats2", ")", "\n", "\n", "n_feats3", "=", "int", "(", "n_feats", "/", "4", ")", "\n", "self", ".", "conv31_1", "=", "conv3x3", "(", "n_feats3", ",", "n_feats3", ",", "2", ")", "\n", "self", ".", "conv31_2", "=", "conv3x3", "(", "n_feats3", ",", "n_feats3", ",", "2", ")", "\n", "self", ".", "conv32", "=", "conv3x3", "(", "n_feats3", ",", "n_feats3", ",", "2", ")", "\n", "\n", "self", ".", "conv_merge1", "=", "conv3x3", "(", "n_feats1", "*", "3", ",", "n_feats1", ")", "\n", "self", ".", "conv_merge2", "=", "conv3x3", "(", "n_feats2", "*", "3", ",", "n_feats2", ")", "\n", "self", ".", "conv_merge3", "=", "conv3x3", "(", "n_feats3", "*", "3", ",", "n_feats3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.CSFI3.forward": [[98, 117], ["torch.interpolate", "torch.interpolate", "torch.relu", "torch.relu", "torch.interpolate", "torch.interpolate", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.interpolate", "torch.interpolate", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "HyperTransformer.CSFI3.conv12", "HyperTransformer.CSFI3.conv13", "HyperTransformer.CSFI3.conv21", "HyperTransformer.CSFI3.conv23", "HyperTransformer.CSFI3.conv31_1", "HyperTransformer.CSFI3.conv31_2", "HyperTransformer.CSFI3.conv32", "HyperTransformer.CSFI3.conv_merge1", "HyperTransformer.CSFI3.conv_merge2", "HyperTransformer.CSFI3.conv_merge3", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x1", ",", "x2", ",", "x3", ")", ":", "\n", "        ", "x12", "=", "F", ".", "interpolate", "(", "x1", ",", "scale_factor", "=", "2", ",", "mode", "=", "'bicubic'", ")", "\n", "x12", "=", "F", ".", "relu", "(", "self", ".", "conv12", "(", "x12", ")", ")", "\n", "x13", "=", "F", ".", "interpolate", "(", "x1", ",", "scale_factor", "=", "4", ",", "mode", "=", "'bicubic'", ")", "\n", "x13", "=", "F", ".", "relu", "(", "self", ".", "conv13", "(", "x13", ")", ")", "\n", "\n", "x21", "=", "F", ".", "relu", "(", "self", ".", "conv21", "(", "x2", ")", ")", "\n", "x23", "=", "F", ".", "interpolate", "(", "x2", ",", "scale_factor", "=", "2", ",", "mode", "=", "'bicubic'", ")", "\n", "x23", "=", "F", ".", "relu", "(", "self", ".", "conv23", "(", "x23", ")", ")", "\n", "\n", "x31", "=", "F", ".", "relu", "(", "self", ".", "conv31_1", "(", "x3", ")", ")", "\n", "x31", "=", "F", ".", "relu", "(", "self", ".", "conv31_2", "(", "x31", ")", ")", "\n", "x32", "=", "F", ".", "relu", "(", "self", ".", "conv32", "(", "x3", ")", ")", "\n", "\n", "x1", "=", "F", ".", "relu", "(", "self", ".", "conv_merge1", "(", "torch", ".", "cat", "(", "(", "x1", ",", "x21", ",", "x31", ")", ",", "dim", "=", "1", ")", ")", ")", "\n", "x2", "=", "F", ".", "relu", "(", "self", ".", "conv_merge2", "(", "torch", ".", "cat", "(", "(", "x2", ",", "x12", ",", "x32", ")", ",", "dim", "=", "1", ")", ")", ")", "\n", "x3", "=", "F", ".", "relu", "(", "self", ".", "conv_merge3", "(", "torch", ".", "cat", "(", "(", "x3", ",", "x13", ",", "x23", ")", ",", "dim", "=", "1", ")", ")", ")", "\n", "\n", "return", "x1", ",", "x2", ",", "x3", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.MergeTail.__init__": [[120, 127], ["torch.nn.Module.__init__", "HyperTransformer.conv1x1", "HyperTransformer.conv1x1", "HyperTransformer.conv3x3", "HyperTransformer.conv3x3", "HyperTransformer.conv1x1", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__init__", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv1x1", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv1x1", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv1x1"], ["    ", "def", "__init__", "(", "self", ",", "n_feats", ",", "out_channels", ")", ":", "\n", "        ", "super", "(", "MergeTail", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv13", "=", "conv1x1", "(", "n_feats", ",", "int", "(", "n_feats", "/", "4", ")", ")", "\n", "self", ".", "conv23", "=", "conv1x1", "(", "int", "(", "n_feats", "/", "2", ")", ",", "int", "(", "n_feats", "/", "4", ")", ")", "\n", "self", ".", "conv_merge", "=", "conv3x3", "(", "3", "*", "int", "(", "n_feats", "/", "4", ")", ",", "out_channels", ")", "\n", "self", ".", "conv_tail1", "=", "conv3x3", "(", "out_channels", ",", "out_channels", ")", "\n", "self", ".", "conv_tail2", "=", "conv1x1", "(", "n_feats", "//", "2", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.MergeTail.forward": [[128, 138], ["torch.interpolate", "torch.interpolate", "torch.relu", "torch.relu", "torch.interpolate", "torch.interpolate", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "HyperTransformer.MergeTail.conv_tail1", "HyperTransformer.MergeTail.conv13", "HyperTransformer.MergeTail.conv23", "HyperTransformer.MergeTail.conv_merge", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x1", ",", "x2", ",", "x3", ")", ":", "\n", "        ", "x13", "=", "F", ".", "interpolate", "(", "x1", ",", "scale_factor", "=", "4", ",", "mode", "=", "'bicubic'", ")", "\n", "x13", "=", "F", ".", "relu", "(", "self", ".", "conv13", "(", "x13", ")", ")", "\n", "x23", "=", "F", ".", "interpolate", "(", "x2", ",", "scale_factor", "=", "2", ",", "mode", "=", "'bicubic'", ")", "\n", "x23", "=", "F", ".", "relu", "(", "self", ".", "conv23", "(", "x23", ")", ")", "\n", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv_merge", "(", "torch", ".", "cat", "(", "(", "x3", ",", "x13", ",", "x23", ")", ",", "dim", "=", "1", ")", ")", ")", "\n", "x", "=", "self", ".", "conv_tail1", "(", "x", ")", "\n", "#x = self.conv_tail2(x)", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.MeanShift.__init__": [[141, 151], ["torch.nn.Conv2d.__init__", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.eye().view", "HyperTransformer.MeanShift.weight.data.div_", "HyperTransformer.MeanShift.bias.data.div_", "torch.Tensor.view", "torch.Tensor.view", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.eye", "torch.eye", "torch.eye", "torch.eye"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "rgb_range", ",", "rgb_mean", ",", "rgb_std", ",", "sign", "=", "-", "1", ")", ":", "\n", "        ", "super", "(", "MeanShift", ",", "self", ")", ".", "__init__", "(", "3", ",", "3", ",", "kernel_size", "=", "1", ")", "\n", "std", "=", "torch", ".", "Tensor", "(", "rgb_std", ")", "\n", "self", ".", "weight", ".", "data", "=", "torch", ".", "eye", "(", "3", ")", ".", "view", "(", "3", ",", "3", ",", "1", ",", "1", ")", "\n", "self", ".", "weight", ".", "data", ".", "div_", "(", "std", ".", "view", "(", "3", ",", "1", ",", "1", ",", "1", ")", ")", "\n", "self", ".", "bias", ".", "data", "=", "sign", "*", "rgb_range", "*", "torch", ".", "Tensor", "(", "rgb_mean", ")", "\n", "self", ".", "bias", ".", "data", ".", "div_", "(", "std", ")", "\n", "# self.requires_grad = False", "\n", "self", ".", "weight", ".", "requires_grad", "=", "False", "\n", "self", ".", "bias", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.Vgg19.__init__": [[153, 169], ["super().__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "range", "HyperTransformer.MeanShift", "torchvision.models.vgg19", "HyperTransformer.Vgg19.slice1.add_module", "HyperTransformer.Vgg19.slice1.parameters", "str"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "requires_grad", "=", "False", ",", "rgb_range", "=", "1", ")", ":", "\n", "        ", "super", "(", "Vgg19", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "vgg_pretrained_features", "=", "models", ".", "vgg19", "(", "pretrained", "=", "True", ")", ".", "features", "\n", "\n", "self", ".", "slice1", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "for", "x", "in", "range", "(", "30", ")", ":", "\n", "            ", "self", ".", "slice1", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "\n", "", "if", "not", "requires_grad", ":", "\n", "            ", "for", "param", "in", "self", ".", "slice1", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "vgg_mean", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", "\n", "vgg_std", "=", "(", "0.229", "*", "rgb_range", ",", "0.224", "*", "rgb_range", ",", "0.225", "*", "rgb_range", ")", "\n", "self", ".", "sub_mean", "=", "MeanShift", "(", "rgb_range", ",", "vgg_mean", ",", "vgg_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.Vgg19.forward": [[170, 174], ["HyperTransformer.Vgg19.sub_mean", "HyperTransformer.Vgg19.slice1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "X", ")", ":", "\n", "        ", "h", "=", "self", ".", "sub_mean", "(", "X", ")", "\n", "h_relu5_1", "=", "self", ".", "slice1", "(", "h", ")", "\n", "return", "h_relu5_1", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.VGG_LFE.__init__": [[176, 206], ["super().__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "range", "range", "range", "HyperTransformer.MeanShift", "torchvision.models.vgg19", "HyperTransformer.VGG_LFE.slice1.add_module", "HyperTransformer.VGG_LFE.slice2.add_module", "HyperTransformer.VGG_LFE.slice3.add_module", "HyperTransformer.VGG_LFE.slice1.parameters", "HyperTransformer.VGG_LFE.slice2.parameters", "HyperTransformer.VGG_LFE.slice3.parameters", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "requires_grad", "=", "True", ",", "rgb_range", "=", "1", ")", ":", "\n", "        ", "super", "(", "VGG_LFE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "### use vgg19 weights to initialize", "\n", "vgg_pretrained_features", "=", "models", ".", "vgg19", "(", "pretrained", "=", "True", ")", ".", "features", "\n", "\n", "#Initial convolutional layer to form RGB image", "\n", "self", ".", "conv_RGB", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "3", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "\n", "self", ".", "slice1", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice2", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice3", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "\n", "for", "x", "in", "range", "(", "2", ")", ":", "\n", "            ", "self", ".", "slice1", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "2", ",", "7", ")", ":", "\n", "            ", "self", ".", "slice2", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "7", ",", "12", ")", ":", "\n", "            ", "self", ".", "slice3", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "if", "not", "requires_grad", ":", "\n", "            ", "for", "param", "in", "self", ".", "slice1", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "requires_grad", "\n", "", "for", "param", "in", "self", ".", "slice2", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "requires_grad", "\n", "", "for", "param", "in", "self", ".", "slice3", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "requires_grad", "\n", "\n", "", "", "vgg_mean", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", "\n", "vgg_std", "=", "(", "0.229", "*", "rgb_range", ",", "0.224", "*", "rgb_range", ",", "0.225", "*", "rgb_range", ")", "\n", "self", ".", "sub_mean", "=", "MeanShift", "(", "rgb_range", ",", "vgg_mean", ",", "vgg_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.VGG_LFE.forward": [[207, 220], ["HyperTransformer.VGG_LFE.conv_RGB", "HyperTransformer.VGG_LFE.sub_mean", "HyperTransformer.VGG_LFE.slice1", "HyperTransformer.VGG_LFE.slice2", "HyperTransformer.VGG_LFE.slice3"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# Initial convolutional layer to make the RGB image...", "\n", "        ", "x", "=", "self", ".", "conv_RGB", "(", "x", ")", "\n", "\n", "# Extracting VGG Features...", "\n", "x", "=", "self", ".", "sub_mean", "(", "x", ")", "\n", "x", "=", "self", ".", "slice1", "(", "x", ")", "\n", "x_lv1", "=", "x", "\n", "x", "=", "self", ".", "slice2", "(", "x", ")", "\n", "x_lv2", "=", "x", "\n", "x", "=", "self", ".", "slice3", "(", "x", ")", "\n", "x_lv3", "=", "x", "\n", "return", "x_lv1", ",", "x_lv2", ",", "x_lv3", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.LFE.__init__": [[226, 254], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "LFE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "#Define number of input channels", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "\n", "#First level convolutions", "\n", "self", ".", "conv_64_1", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "self", ".", "in_channels", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "7", ",", "padding", "=", "3", ")", "\n", "self", ".", "bn_64_1", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "conv_64_2", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn_64_2", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "\n", "#Second level convolutions", "\n", "self", ".", "conv_128_1", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "128", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn_128_1", "=", "nn", ".", "BatchNorm2d", "(", "128", ")", "\n", "self", ".", "conv_128_2", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "128", ",", "out_channels", "=", "128", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn_128_2", "=", "nn", ".", "BatchNorm2d", "(", "128", ")", "\n", "\n", "#Third level convolutions", "\n", "self", ".", "conv_256_1", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "128", ",", "out_channels", "=", "256", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn_256_1", "=", "nn", ".", "BatchNorm2d", "(", "256", ")", "\n", "self", ".", "conv_256_2", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "256", ",", "out_channels", "=", "256", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn_256_2", "=", "nn", ".", "BatchNorm2d", "(", "256", ")", "\n", "\n", "#Max pooling", "\n", "self", ".", "MaxPool2x2", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", "\n", "\n", "#LeakyReLU ", "\n", "self", ".", "LeakyReLU", "=", "nn", ".", "LeakyReLU", "(", "negative_slope", "=", "0.0", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.LFE.forward": [[254, 270], ["HyperTransformer.LFE.LeakyReLU", "HyperTransformer.LFE.bn_64_2", "HyperTransformer.LFE.MaxPool2x2", "HyperTransformer.LFE.LeakyReLU", "HyperTransformer.LFE.bn_128_2", "HyperTransformer.LFE.MaxPool2x2", "HyperTransformer.LFE.LeakyReLU", "HyperTransformer.LFE.bn_256_2", "HyperTransformer.LFE.bn_64_1", "HyperTransformer.LFE.conv_64_2", "HyperTransformer.LFE.LeakyReLU", "HyperTransformer.LFE.bn_128_1", "HyperTransformer.LFE.conv_128_2", "HyperTransformer.LFE.LeakyReLU", "HyperTransformer.LFE.bn_256_1", "HyperTransformer.LFE.conv_256_2", "HyperTransformer.LFE.conv_64_1", "HyperTransformer.LFE.conv_128_1", "HyperTransformer.LFE.conv_256_1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "#First level outputs", "\n", "        ", "out1", "=", "self", ".", "LeakyReLU", "(", "self", ".", "bn_64_1", "(", "self", ".", "conv_64_1", "(", "x", ")", ")", ")", "\n", "out1", "=", "self", ".", "bn_64_2", "(", "self", ".", "conv_64_2", "(", "out1", ")", ")", "\n", "\n", "#Second level outputs", "\n", "out1_mp", "=", "self", ".", "MaxPool2x2", "(", "self", ".", "LeakyReLU", "(", "out1", ")", ")", "\n", "out2", "=", "self", ".", "LeakyReLU", "(", "self", ".", "bn_128_1", "(", "self", ".", "conv_128_1", "(", "out1_mp", ")", ")", ")", "\n", "out2", "=", "self", ".", "bn_128_2", "(", "self", ".", "conv_128_2", "(", "out2", ")", ")", "\n", "\n", "#Third level outputs", "\n", "out2_mp", "=", "self", ".", "MaxPool2x2", "(", "self", ".", "LeakyReLU", "(", "out2", ")", ")", "\n", "out3", "=", "self", ".", "LeakyReLU", "(", "self", ".", "bn_256_1", "(", "self", ".", "conv_256_1", "(", "out2_mp", ")", ")", ")", "\n", "out3", "=", "self", ".", "bn_256_2", "(", "self", ".", "conv_256_2", "(", "out3", ")", ")", "\n", "\n", "return", "out1", ",", "out2", ",", "out3", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.LFE_lvx.__init__": [[273, 307], ["torch.nn.Module.__init__", "int", "int", "int", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "n_feates", ",", "level", ")", ":", "\n", "        ", "super", "(", "LFE_lvx", ",", "self", ")", ".", "__init__", "(", ")", "\n", "#Define number of input channels", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "level", "=", "level", "\n", "lv1_c", "=", "int", "(", "n_feates", ")", "\n", "lv2_c", "=", "int", "(", "n_feates", "/", "2", ")", "\n", "lv3_c", "=", "int", "(", "n_feates", "/", "4", ")", "\n", "\n", "#First level convolutions", "\n", "self", ".", "conv_64_1", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "self", ".", "in_channels", ",", "out_channels", "=", "lv3_c", ",", "kernel_size", "=", "7", ",", "padding", "=", "3", ")", "\n", "self", ".", "bn_64_1", "=", "nn", ".", "BatchNorm2d", "(", "lv3_c", ")", "\n", "self", ".", "conv_64_2", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "lv3_c", ",", "out_channels", "=", "lv3_c", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn_64_2", "=", "nn", ".", "BatchNorm2d", "(", "lv3_c", ")", "\n", "\n", "#Second level convolutions", "\n", "if", "self", ".", "level", "==", "1", "or", "self", ".", "level", "==", "2", ":", "\n", "            ", "self", ".", "conv_128_1", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "lv3_c", ",", "out_channels", "=", "lv2_c", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn_128_1", "=", "nn", ".", "BatchNorm2d", "(", "lv2_c", ")", "\n", "self", ".", "conv_128_2", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "lv2_c", ",", "out_channels", "=", "lv2_c", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn_128_2", "=", "nn", ".", "BatchNorm2d", "(", "lv2_c", ")", "\n", "\n", "#Third level convolutions", "\n", "", "if", "self", ".", "level", "==", "1", ":", "\n", "            ", "self", ".", "conv_256_1", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "lv2_c", ",", "out_channels", "=", "lv1_c", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn_256_1", "=", "nn", ".", "BatchNorm2d", "(", "lv1_c", ")", "\n", "self", ".", "conv_256_2", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "lv1_c", ",", "out_channels", "=", "lv1_c", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn_256_2", "=", "nn", ".", "BatchNorm2d", "(", "lv1_c", ")", "\n", "\n", "#Max pooling", "\n", "", "self", ".", "MaxPool2x2", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", "\n", "\n", "#LeakyReLU ", "\n", "self", ".", "LeakyReLU", "=", "nn", ".", "LeakyReLU", "(", "negative_slope", "=", "0.0", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.LFE_lvx.forward": [[307, 325], ["HyperTransformer.LFE_lvx.LeakyReLU", "HyperTransformer.LFE_lvx.bn_64_2", "HyperTransformer.LFE_lvx.bn_64_1", "HyperTransformer.LFE_lvx.conv_64_2", "HyperTransformer.LFE_lvx.MaxPool2x2", "HyperTransformer.LFE_lvx.LeakyReLU", "HyperTransformer.LFE_lvx.bn_128_2", "HyperTransformer.LFE_lvx.MaxPool2x2", "HyperTransformer.LFE_lvx.LeakyReLU", "HyperTransformer.LFE_lvx.bn_256_2", "HyperTransformer.LFE_lvx.conv_64_1", "HyperTransformer.LFE_lvx.LeakyReLU", "HyperTransformer.LFE_lvx.bn_128_1", "HyperTransformer.LFE_lvx.conv_128_2", "HyperTransformer.LFE_lvx.LeakyReLU", "HyperTransformer.LFE_lvx.bn_256_1", "HyperTransformer.LFE_lvx.conv_256_2", "HyperTransformer.LFE_lvx.conv_128_1", "HyperTransformer.LFE_lvx.conv_256_1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "#First level outputs", "\n", "        ", "out", "=", "self", ".", "LeakyReLU", "(", "self", ".", "bn_64_1", "(", "self", ".", "conv_64_1", "(", "x", ")", ")", ")", "\n", "out", "=", "self", ".", "bn_64_2", "(", "self", ".", "conv_64_2", "(", "out", ")", ")", "\n", "\n", "#Second level outputs", "\n", "if", "self", ".", "level", "==", "1", "or", "self", ".", "level", "==", "2", ":", "\n", "            ", "out", "=", "self", ".", "MaxPool2x2", "(", "self", ".", "LeakyReLU", "(", "out", ")", ")", "\n", "out", "=", "self", ".", "LeakyReLU", "(", "self", ".", "bn_128_1", "(", "self", ".", "conv_128_1", "(", "out", ")", ")", ")", "\n", "out", "=", "self", ".", "bn_128_2", "(", "self", ".", "conv_128_2", "(", "out", ")", ")", "\n", "\n", "#Third level outputs", "\n", "", "if", "self", ".", "level", "==", "1", ":", "\n", "            ", "out", "=", "self", ".", "MaxPool2x2", "(", "self", ".", "LeakyReLU", "(", "out", ")", ")", "\n", "out", "=", "self", ".", "LeakyReLU", "(", "self", ".", "bn_256_1", "(", "self", ".", "conv_256_1", "(", "out", ")", ")", ")", "\n", "out", "=", "self", ".", "bn_256_2", "(", "self", ".", "conv_256_2", "(", "out", ")", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.NoAttention.__init__": [[330, 332], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.NoAttention.forward": [[333, 336], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "v", ",", "k", ",", "q", ",", "mask", "=", "None", ")", ":", "\n", "        ", "output", "=", "v", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.ScaledDotProductAttentionOnly.__init__": [[340, 343], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__init__"], ["def", "__init__", "(", "self", ",", "temperature", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "temperature", "=", "temperature", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.ScaledDotProductAttentionOnly.forward": [[344, 368], ["q.view.view.view", "k.view.view.view", "v.view.view.view", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.softmax", "torch.softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "output.view.view.view", "q.view.view.size", "q.view.view.size", "q.view.view.size", "q.view.view.size", "k.view.view.transpose", "attn.masked_fill.masked_fill.masked_fill"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "v", ",", "k", ",", "q", ",", "mask", "=", "None", ")", ":", "\n", "        ", "b", ",", "c", ",", "h", ",", "w", "=", "q", ".", "size", "(", "0", ")", ",", "q", ".", "size", "(", "1", ")", ",", "q", ".", "size", "(", "2", ")", ",", "q", ".", "size", "(", "3", ")", "\n", "\n", "# Reshaping K,Q, and Vs...", "\n", "q", "=", "q", ".", "view", "(", "b", ",", "c", ",", "h", "*", "w", ")", "\n", "k", "=", "k", ".", "view", "(", "b", ",", "c", ",", "h", "*", "w", ")", "\n", "v", "=", "v", ".", "view", "(", "b", ",", "c", ",", "h", "*", "w", ")", "\n", "\n", "\n", "# Compute attention", "\n", "attn", "=", "torch", ".", "matmul", "(", "q", "/", "self", ".", "temperature", ",", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "attn", "=", "attn", ".", "masked_fill", "(", "mask", "==", "0", ",", "-", "1e9", ")", "\n", "\n", "# Normalization (SoftMax)", "\n", "", "attn", "=", "F", ".", "softmax", "(", "attn", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Attention output", "\n", "output", "=", "torch", ".", "matmul", "(", "attn", ",", "v", ")", "\n", "\n", "#Reshape output to original format", "\n", "output", "=", "output", ".", "view", "(", "b", ",", "c", ",", "h", ",", "w", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.HyperTransformerResBlock.__init__": [[373, 393], ["torch.nn.Module.__init__", "HyperTransformer.LFE_lvx", "HyperTransformer.LFE_lvx", "HyperTransformer.ScaledDotProductAttentionOnly", "torch.nn.Conv2d", "torch.nn.Conv2d", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__init__"], ["def", "__init__", "(", "self", ",", "HSI_in_c", ",", "n_feates", ",", "lv", ",", "temperature", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "HSI_in_c", "=", "HSI_in_c", "#Number of input channels = Number of output channels", "\n", "self", ".", "lv", "=", "lv", "#Spatial level 1-> hxw, 2-> 2hx2w, 3-> 3hx3w", "\n", "if", "lv", "==", "1", ":", "\n", "            ", "out_channels", "=", "int", "(", "n_feates", ")", "\n", "", "elif", "lv", "==", "2", ":", "\n", "            ", "out_channels", "=", "int", "(", "n_feates", "/", "2", ")", "\n", "", "elif", "lv", "==", "3", ":", "\n", "            ", "out_channels", "=", "int", "(", "n_feates", "/", "4", ")", "\n", "\n", "#Learnable feature extractors (FE-PAN & FE-HSI)", "\n", "", "self", ".", "LFE_HSI", "=", "LFE_lvx", "(", "in_channels", "=", "self", ".", "HSI_in_c", ",", "n_feates", "=", "n_feates", ",", "level", "=", "lv", ")", "\n", "self", ".", "LFE_PAN", "=", "LFE_lvx", "(", "in_channels", "=", "1", ",", "n_feates", "=", "n_feates", ",", "level", "=", "lv", ")", "\n", "\n", "#Attention", "\n", "self", ".", "DotProductAttention", "=", "ScaledDotProductAttentionOnly", "(", "temperature", "=", "temperature", ")", "\n", "\n", "#Texture & Spectral Mixing", "\n", "self", ".", "TSmix", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "int", "(", "2", "*", "out_channels", ")", ",", "out_channels", "=", "out_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.HyperTransformerResBlock.forward": [[394, 412], ["HyperTransformer.HyperTransformerResBlock.LFE_PAN", "HyperTransformer.HyperTransformerResBlock.LFE_PAN", "HyperTransformer.HyperTransformerResBlock.LFE_HSI", "HyperTransformer.HyperTransformerResBlock.DotProductAttention", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "HyperTransformer.HyperTransformerResBlock.TSmix"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "F", ",", "X_PAN", ",", "PAN_UD", ",", "X_MS_UP", ")", ":", "\n", "# Obtaining Values, Keys, and Queries", "\n", "        ", "V", "=", "self", ".", "LFE_PAN", "(", "X_PAN", ")", "\n", "K", "=", "self", ".", "LFE_PAN", "(", "PAN_UD", ")", "\n", "Q", "=", "self", ".", "LFE_HSI", "(", "X_MS_UP", ")", "\n", "\n", "# Obtaining T (Transfered HR Features)", "\n", "T", "=", "self", ".", "DotProductAttention", "(", "V", ",", "K", ",", "Q", ")", "\n", "\n", "#Concatenating F and T", "\n", "FT", "=", "torch", ".", "cat", "(", "(", "F", ",", "T", ")", ",", "dim", "=", "1", ")", "\n", "\n", "#Texture spectral mixing", "\n", "res", "=", "self", ".", "TSmix", "(", "FT", ")", "\n", "\n", "#Output", "\n", "output", "=", "F", "+", "res", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.ScaledDotProductAttention.__init__": [[417, 420], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__init__"], ["def", "__init__", "(", "self", ",", "temperature", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "temperature", "=", "temperature", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.ScaledDotProductAttention.forward": [[421, 434], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.softmax", "torch.softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "k.transpose", "attn.masked_fill.masked_fill.masked_fill"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "v", ",", "k", ",", "q", ",", "mask", "=", "None", ")", ":", "\n", "# Compute attention", "\n", "        ", "attn", "=", "torch", ".", "matmul", "(", "q", "/", "self", ".", "temperature", ",", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "attn", "=", "attn", ".", "masked_fill", "(", "mask", "==", "0", ",", "-", "1e9", ")", "\n", "\n", "# Normalization (SoftMax)", "\n", "", "attn", "=", "F", ".", "softmax", "(", "attn", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Attention output", "\n", "output", "=", "torch", ".", "matmul", "(", "attn", ",", "v", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.MultiHeadAttention.__init__": [[439, 458], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "HyperTransformer.ScaledDotProductAttention", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__init__"], ["def", "__init__", "(", "self", ",", "n_head", ",", "in_pixels", ",", "linear_dim", ",", "num_features", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "#Parameters", "\n", "self", ".", "n_head", "=", "n_head", "#No of heads", "\n", "self", ".", "in_pixels", "=", "in_pixels", "#No of pixels in the input image", "\n", "self", ".", "linear_dim", "=", "linear_dim", "#Dim of linear-layer (outputs)", "\n", "\n", "#Linear layers", "\n", "\n", "self", ".", "w_qs", "=", "nn", ".", "Linear", "(", "in_pixels", ",", "n_head", "*", "linear_dim", ",", "bias", "=", "False", ")", "#Linear layer for queries", "\n", "self", ".", "w_ks", "=", "nn", ".", "Linear", "(", "in_pixels", ",", "n_head", "*", "linear_dim", ",", "bias", "=", "False", ")", "#Linear layer for keys", "\n", "self", ".", "w_vs", "=", "nn", ".", "Linear", "(", "in_pixels", ",", "n_head", "*", "linear_dim", ",", "bias", "=", "False", ")", "#Linear layer for values", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "n_head", "*", "linear_dim", ",", "in_pixels", ",", "bias", "=", "False", ")", "#Final fully connected layer", "\n", "\n", "#Scaled dot product attention", "\n", "self", ".", "attention", "=", "ScaledDotProductAttention", "(", "temperature", "=", "in_pixels", "**", "0.5", ")", "\n", "\n", "#Batch normalization layer", "\n", "self", ".", "OutBN", "=", "nn", ".", "BatchNorm2d", "(", "num_features", "=", "num_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.MultiHeadAttention.forward": [[459, 507], ["HyperTransformer.MultiHeadAttention.view", "HyperTransformer.MultiHeadAttention.view", "HyperTransformer.MultiHeadAttention.view", "HyperTransformer.MultiHeadAttention.w_qs().view", "HyperTransformer.MultiHeadAttention.w_ks().view", "HyperTransformer.MultiHeadAttention.w_vs().view", "HyperTransformer.MultiHeadAttention.attention", "HyperTransformer.MultiHeadAttention.transpose().contiguous().view", "HyperTransformer.MultiHeadAttention.fc", "HyperTransformer.MultiHeadAttention.view", "HyperTransformer.MultiHeadAttention.OutBN", "HyperTransformer.MultiHeadAttention.size", "HyperTransformer.MultiHeadAttention.size", "HyperTransformer.MultiHeadAttention.size", "HyperTransformer.MultiHeadAttention.size", "HyperTransformer.MultiHeadAttention.transpose", "HyperTransformer.MultiHeadAttention.transpose", "HyperTransformer.MultiHeadAttention.transpose", "mask.unsqueeze.unsqueeze.unsqueeze", "HyperTransformer.MultiHeadAttention.w_qs", "HyperTransformer.MultiHeadAttention.w_ks", "HyperTransformer.MultiHeadAttention.w_vs", "HyperTransformer.MultiHeadAttention.transpose().contiguous", "HyperTransformer.MultiHeadAttention.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "v", ",", "k", ",", "q", ",", "mask", "=", "None", ")", ":", "\n", "# Reshaping matrixes to 2D", "\n", "# q = b, c_q, h*w", "\n", "# k = b, c_k, h*w", "\n", "# v = b, c_v, h*w", "\n", "        ", "b", ",", "c", ",", "h", ",", "w", "=", "q", ".", "size", "(", "0", ")", ",", "q", ".", "size", "(", "1", ")", ",", "q", ".", "size", "(", "2", ")", ",", "q", ".", "size", "(", "3", ")", "\n", "n_head", "=", "self", ".", "n_head", "\n", "linear_dim", "=", "self", ".", "linear_dim", "\n", "\n", "# Reshaping K, Q, and Vs...", "\n", "q", "=", "q", ".", "view", "(", "b", ",", "c", ",", "h", "*", "w", ")", "\n", "k", "=", "k", ".", "view", "(", "b", ",", "c", ",", "h", "*", "w", ")", "\n", "v", "=", "v", ".", "view", "(", "b", ",", "c", ",", "h", "*", "w", ")", "\n", "\n", "#Save V", "\n", "output", "=", "v", "\n", "\n", "# Pass through the pre-attention projection: b x lq x (n*dv)", "\n", "# Separate different heads: b x lq x n x dv", "\n", "q", "=", "self", ".", "w_qs", "(", "q", ")", ".", "view", "(", "b", ",", "c", ",", "n_head", ",", "linear_dim", ")", "\n", "k", "=", "self", ".", "w_ks", "(", "k", ")", ".", "view", "(", "b", ",", "c", ",", "n_head", ",", "linear_dim", ")", "\n", "v", "=", "self", ".", "w_vs", "(", "v", ")", ".", "view", "(", "b", ",", "c", ",", "n_head", ",", "linear_dim", ")", "\n", "\n", "# Transpose for attention dot product: b x n x lq x dv", "\n", "q", ",", "k", ",", "v", "=", "q", ".", "transpose", "(", "1", ",", "2", ")", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ",", "v", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "# For head axis broadcasting.", "\n", "\n", "# Computing ScaledDotProduct attention for each head", "\n", "", "v_attn", "=", "self", ".", "attention", "(", "v", ",", "k", ",", "q", ",", "mask", "=", "mask", ")", "\n", "\n", "# Transpose to move the head dimension back: b x lq x n x dv", "\n", "# Combine the last two dimensions to concatenate all the heads together: b x lq x (n*dv)", "\n", "v_attn", "=", "v_attn", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "b", ",", "c", ",", "n_head", "*", "linear_dim", ")", "\n", "v_attn", "=", "self", ".", "fc", "(", "v_attn", ")", "\n", "\n", "\n", "output", "=", "output", "+", "v_attn", "\n", "#output  = v_attn", "\n", "\n", "#Reshape output to original image format", "\n", "output", "=", "output", ".", "view", "(", "b", ",", "c", ",", "h", ",", "w", ")", "\n", "\n", "#We can consider batch-normalization here,,,", "\n", "#Will complete it later", "\n", "output", "=", "self", ".", "OutBN", "(", "output", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.HyperTransformer.__init__": [[513, 642], ["torch.nn.Module.__init__", "HyperTransformer.LFE", "HyperTransformer.LFE", "HyperTransformer.SFE", "HyperTransformer.conv3x3", "torch.nn.PixelShuffle", "torch.nn.PixelShuffle", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "HyperTransformer.conv3x3", "HyperTransformer.conv3x3", "torch.nn.PixelShuffle", "torch.nn.PixelShuffle", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "HyperTransformer.conv3x3", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "HyperTransformer.conv3x3", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "HyperTransformer.conv3x3", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "HyperTransformer.VGG_LFE", "HyperTransformer.VGG_LFE", "HyperTransformer.NoAttention", "HyperTransformer.NoAttention", "HyperTransformer.NoAttention", "HyperTransformer.conv3x3", "HyperTransformer.conv3x3", "HyperTransformer.HyperTransformer.RB11.append", "HyperTransformer.conv3x3", "HyperTransformer.conv3x3", "int", "HyperTransformer.HyperTransformer.RB22.append", "int", "int", "HyperTransformer.conv3x3", "HyperTransformer.conv3x3", "HyperTransformer.HyperTransformer.RB33.append", "int", "int", "HyperTransformer.HyperTransformer.RBF.append", "int", "int", "HyperTransformer.ScaledDotProductAttentionOnly", "HyperTransformer.ScaledDotProductAttentionOnly", "HyperTransformer.ScaledDotProductAttentionOnly", "HyperTransformer.MultiHeadAttention", "HyperTransformer.MultiHeadAttention", "HyperTransformer.MultiHeadAttention", "HyperTransformer.ResBlock", "int", "int", "int", "HyperTransformer.ResBlock", "int", "int", "int", "HyperTransformer.ResBlock", "HyperTransformer.ResBlock", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__init__", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "HyperTransformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Settings", "\n", "self", ".", "is_DHP_MS", "=", "config", "[", "\"is_DHP_MS\"", "]", "\n", "self", ".", "in_channels", "=", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"spectral_bands\"", "]", "\n", "self", ".", "out_channels", "=", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"spectral_bands\"", "]", "\n", "self", ".", "factor", "=", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"factor\"", "]", "\n", "self", ".", "config", "=", "config", "\n", "\n", "# Parameter setup", "\n", "self", ".", "num_res_blocks", "=", "[", "16", ",", "4", ",", "4", ",", "4", ",", "4", "]", "\n", "self", ".", "n_feats", "=", "256", "\n", "self", ".", "res_scale", "=", "1", "\n", "\n", "# FE-PAN & FE-HSI", "\n", "self", ".", "LFE_HSI", "=", "LFE", "(", "in_channels", "=", "self", ".", "in_channels", ")", "\n", "self", ".", "LFE_PAN", "=", "LFE", "(", "in_channels", "=", "1", ")", "\n", "\n", "# Dimention of each Scaled-Dot-Product-Attention module", "\n", "lv1_dim", "=", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"LR_size\"", "]", "**", "2", "\n", "lv2_dim", "=", "(", "2", "*", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"LR_size\"", "]", ")", "**", "2", "\n", "lv3_dim", "=", "(", "4", "*", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"LR_size\"", "]", ")", "**", "2", "\n", "\n", "# Number of Heads in Multi-Head Attention Module", "\n", "n_head", "=", "config", "[", "\"N_modules\"", "]", "\n", "\n", "# Setting up Multi-Head Attention or Single-Head Attention", "\n", "if", "n_head", "==", "0", ":", "\n", "# No Attention #", "\n", "# JUst passing the HR features from PAN image (Values) #", "\n", "            ", "self", ".", "TS_lv3", "=", "NoAttention", "(", ")", "\n", "self", ".", "TS_lv2", "=", "NoAttention", "(", ")", "\n", "self", ".", "TS_lv1", "=", "NoAttention", "(", ")", "\n", "", "elif", "n_head", "==", "1", ":", "\n", "### Scaled Dot Product Attention ###", "\n", "            ", "self", ".", "TS_lv3", "=", "ScaledDotProductAttentionOnly", "(", "temperature", "=", "lv1_dim", ")", "\n", "self", ".", "TS_lv2", "=", "ScaledDotProductAttentionOnly", "(", "temperature", "=", "lv2_dim", ")", "\n", "self", ".", "TS_lv1", "=", "ScaledDotProductAttentionOnly", "(", "temperature", "=", "lv3_dim", ")", "\n", "", "else", ":", "\n", "### Multi-Head Attention ###", "\n", "            ", "lv1_pixels", "=", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"LR_size\"", "]", "**", "2", "\n", "lv2_pixels", "=", "(", "2", "*", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"LR_size\"", "]", ")", "**", "2", "\n", "lv3_pixels", "=", "(", "4", "*", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"LR_size\"", "]", ")", "**", "2", "\n", "self", ".", "TS_lv3", "=", "MultiHeadAttention", "(", "n_head", "=", "int", "(", "n_head", ")", ",", "\n", "in_pixels", "=", "int", "(", "lv1_pixels", ")", ",", "\n", "linear_dim", "=", "int", "(", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"LR_size\"", "]", ")", ",", "\n", "num_features", "=", "self", ".", "n_feats", ")", "\n", "self", ".", "TS_lv2", "=", "MultiHeadAttention", "(", "n_head", "=", "int", "(", "n_head", ")", ",", "\n", "in_pixels", "=", "int", "(", "lv2_pixels", ")", ",", "\n", "linear_dim", "=", "int", "(", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"LR_size\"", "]", ")", ",", "\n", "num_features", "=", "int", "(", "self", ".", "n_feats", "/", "2", ")", ")", "\n", "self", ".", "TS_lv1", "=", "MultiHeadAttention", "(", "n_head", "=", "int", "(", "n_head", ")", ",", "\n", "in_pixels", "=", "int", "(", "lv3_pixels", ")", ",", "\n", "linear_dim", "=", "int", "(", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"LR_size\"", "]", ")", ",", "\n", "num_features", "=", "int", "(", "self", ".", "n_feats", "/", "4", ")", ")", "\n", "\n", "", "self", ".", "SFE", "=", "SFE", "(", "self", ".", "in_channels", ",", "self", ".", "num_res_blocks", "[", "0", "]", ",", "self", ".", "n_feats", ",", "self", ".", "res_scale", ")", "\n", "\n", "###############", "\n", "### stage11 ###", "\n", "###############", "\n", "if", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"feature_sum\"", "]", ":", "\n", "            ", "self", ".", "conv11_headSUM", "=", "conv3x3", "(", "self", ".", "n_feats", ",", "self", ".", "n_feats", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv11_head", "=", "conv3x3", "(", "2", "*", "self", ".", "n_feats", ",", "self", ".", "n_feats", ")", "\n", "\n", "", "self", ".", "conv12", "=", "conv3x3", "(", "self", ".", "n_feats", ",", "self", ".", "n_feats", "*", "2", ")", "\n", "self", ".", "ps12", "=", "nn", ".", "PixelShuffle", "(", "2", ")", "\n", "#Residial blocks", "\n", "self", ".", "RB11", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_res_blocks", "[", "1", "]", ")", ":", "\n", "            ", "self", ".", "RB11", ".", "append", "(", "ResBlock", "(", "in_channels", "=", "self", ".", "n_feats", ",", "out_channels", "=", "self", ".", "n_feats", ",", "\n", "res_scale", "=", "self", ".", "res_scale", ")", ")", "\n", "", "self", ".", "conv11_tail", "=", "conv3x3", "(", "self", ".", "n_feats", ",", "self", ".", "n_feats", ")", "\n", "\n", "###############", "\n", "### stage22 ###", "\n", "###############", "\n", "if", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"feature_sum\"", "]", ":", "\n", "            ", "self", ".", "conv22_headSUM", "=", "conv3x3", "(", "int", "(", "self", ".", "n_feats", "/", "2", ")", ",", "int", "(", "self", ".", "n_feats", "/", "2", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv22_head", "=", "conv3x3", "(", "2", "*", "int", "(", "self", ".", "n_feats", "/", "2", ")", ",", "int", "(", "self", ".", "n_feats", "/", "2", ")", ")", "\n", "", "self", ".", "conv23", "=", "conv3x3", "(", "int", "(", "self", ".", "n_feats", "/", "2", ")", ",", "self", ".", "n_feats", ")", "\n", "self", ".", "ps23", "=", "nn", ".", "PixelShuffle", "(", "2", ")", "\n", "#Residual blocks", "\n", "self", ".", "RB22", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_res_blocks", "[", "2", "]", ")", ":", "\n", "            ", "self", ".", "RB22", ".", "append", "(", "ResBlock", "(", "in_channels", "=", "int", "(", "self", ".", "n_feats", "/", "2", ")", ",", "out_channels", "=", "int", "(", "self", ".", "n_feats", "/", "2", ")", ",", "res_scale", "=", "self", ".", "res_scale", ")", ")", "\n", "", "self", ".", "conv22_tail", "=", "conv3x3", "(", "int", "(", "self", ".", "n_feats", "/", "2", ")", ",", "int", "(", "self", ".", "n_feats", "/", "2", ")", ")", "\n", "\n", "###############", "\n", "### stage33 ###", "\n", "###############", "\n", "if", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"feature_sum\"", "]", ":", "\n", "             ", "self", ".", "conv33_headSUM", "=", "conv3x3", "(", "int", "(", "self", ".", "n_feats", "/", "4", ")", ",", "int", "(", "self", ".", "n_feats", "/", "4", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv33_head", "=", "conv3x3", "(", "2", "*", "int", "(", "self", ".", "n_feats", "/", "4", ")", ",", "int", "(", "self", ".", "n_feats", "/", "4", ")", ")", "\n", "", "self", ".", "RB33", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_res_blocks", "[", "3", "]", ")", ":", "\n", "            ", "self", ".", "RB33", ".", "append", "(", "ResBlock", "(", "in_channels", "=", "int", "(", "self", ".", "n_feats", "/", "4", ")", ",", "out_channels", "=", "int", "(", "self", ".", "n_feats", "/", "4", ")", ",", "res_scale", "=", "self", ".", "res_scale", ")", ")", "\n", "", "self", ".", "conv33_tail", "=", "conv3x3", "(", "int", "(", "self", ".", "n_feats", "/", "4", ")", ",", "int", "(", "self", ".", "n_feats", "/", "4", ")", ")", "\n", "\n", "##############", "\n", "### FINAL ####", "\n", "##############", "\n", "self", ".", "final_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "self", ".", "n_feats", "+", "int", "(", "self", ".", "n_feats", "/", "2", ")", "+", "int", "(", "self", ".", "n_feats", "/", "4", ")", ",", "out_channels", "=", "self", ".", "out_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "RBF", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_res_blocks", "[", "4", "]", ")", ":", "\n", "            ", "self", ".", "RBF", ".", "append", "(", "ResBlock", "(", "in_channels", "=", "self", ".", "out_channels", ",", "out_channels", "=", "self", ".", "out_channels", ",", "res_scale", "=", "self", ".", "res_scale", ")", ")", "\n", "", "self", ".", "convF_tail", "=", "conv3x3", "(", "self", ".", "out_channels", ",", "self", ".", "out_channels", ")", "\n", "\n", "###############", "\n", "# Batch Norm ##", "\n", "###############", "\n", "self", ".", "BN_x11", "=", "nn", ".", "BatchNorm2d", "(", "self", ".", "n_feats", ")", "\n", "self", ".", "BN_x22", "=", "nn", ".", "BatchNorm2d", "(", "int", "(", "self", ".", "n_feats", "/", "2", ")", ")", "\n", "self", ".", "BN_x33", "=", "nn", ".", "BatchNorm2d", "(", "int", "(", "self", ".", "n_feats", "/", "4", ")", ")", "\n", "\n", "######################", "\n", "# MUlti-Scale-Output #", "\n", "######################", "\n", "self", ".", "up_conv13", "=", "nn", ".", "ConvTranspose2d", "(", "in_channels", "=", "self", ".", "n_feats", ",", "out_channels", "=", "self", ".", "in_channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "4", ",", "output_padding", "=", "1", ")", "\n", "self", ".", "up_conv23", "=", "nn", ".", "ConvTranspose2d", "(", "in_channels", "=", "int", "(", "self", ".", "n_feats", "/", "2", ")", ",", "out_channels", "=", "self", ".", "in_channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "output_padding", "=", "1", ")", "\n", "\n", "###########################", "\n", "# Transfer Periferal Loss #", "\n", "###########################", "\n", "self", ".", "VGG_LFE_HSI", "=", "VGG_LFE", "(", "in_channels", "=", "self", ".", "in_channels", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "VGG_LFE_PAN", "=", "VGG_LFE", "(", "in_channels", "=", "1", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.HyperTransformer.forward": [[643, 783], ["HyperTransformer.HyperTransformer.LFE_PAN", "HyperTransformer.HyperTransformer.LFE_PAN", "HyperTransformer.HyperTransformer.LFE_HSI", "HyperTransformer.HyperTransformer.TS_lv3", "HyperTransformer.HyperTransformer.TS_lv2", "HyperTransformer.HyperTransformer.TS_lv1", "HyperTransformer.HyperTransformer.SFE", "range", "HyperTransformer.HyperTransformer.conv11_tail", "HyperTransformer.HyperTransformer.conv12", "torch.relu", "torch.relu", "range", "HyperTransformer.HyperTransformer.conv22_tail", "HyperTransformer.HyperTransformer.conv23", "torch.relu", "torch.relu", "range", "HyperTransformer.HyperTransformer.conv33_tail", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "HyperTransformer.HyperTransformer.final_conv", "range", "HyperTransformer.HyperTransformer.convF_tail", "HyperTransformer.HyperTransformer.LFE_HSI", "HyperTransformer.HyperTransformer.TS_lv3", "HyperTransformer.HyperTransformer.TS_lv2", "HyperTransformer.HyperTransformer.TS_lv1", "HyperTransformer.HyperTransformer.up_conv13", "HyperTransformer.HyperTransformer.up_conv23", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "X_PAN.unsqueeze.unsqueeze.unsqueeze", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "HyperTransformer.HyperTransformer.conv11_headSUM", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "HyperTransformer.HyperTransformer.conv11_head", "HyperTransformer.HyperTransformer.ps12", "HyperTransformer.HyperTransformer.conv22_headSUM", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "HyperTransformer.HyperTransformer.conv22_head", "HyperTransformer.HyperTransformer.ps23", "HyperTransformer.HyperTransformer.conv33_headSUM", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "HyperTransformer.HyperTransformer.conv33_head", "HyperTransformer.HyperTransformer.detach", "LOSS_TP", "torch.interpolate", "torch.interpolate", "LOSS_TP", "LOSS_TP", "HyperTransformer.HyperTransformer.BN_x11", "HyperTransformer.HyperTransformer.BN_x22", "HyperTransformer.HyperTransformer.BN_x33"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "X_MS", ",", "X_PAN", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "not", "self", ".", "is_DHP_MS", ":", "\n", "                ", "X_MS_UP", "=", "F", ".", "interpolate", "(", "X_MS", ",", "scale_factor", "=", "(", "self", ".", "factor", ",", "self", ".", "factor", ")", ",", "mode", "=", "'bicubic'", ")", "\n", "\n", "", "else", ":", "\n", "                ", "X_MS_UP", "=", "X_MS", "\n", "\n", "# Generating PAN, and PAN (UD) images", "\n", "", "X_PAN", "=", "X_PAN", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "PAN_D", "=", "F", ".", "interpolate", "(", "X_PAN", ",", "scale_factor", "=", "(", "1", "/", "self", ".", "factor", ",", "1", "/", "self", ".", "factor", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "PAN_UD", "=", "F", ".", "interpolate", "(", "PAN_D", ",", "scale_factor", "=", "(", "self", ".", "factor", ",", "self", ".", "factor", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "\n", "#Extracting T and S at multiple-scales", "\n", "#lv1 = LxW, lv2 = (L/2)x(w/2), lv3=(L/4, W/4)", "\n", "", "V_lv1", ",", "V_lv2", ",", "V_lv3", "=", "self", ".", "LFE_PAN", "(", "X_PAN", ")", "\n", "K_lv1", ",", "K_lv2", ",", "K_lv3", "=", "self", ".", "LFE_PAN", "(", "PAN_UD", ")", "\n", "Q_lv1", ",", "Q_lv2", ",", "Q_lv3", "=", "self", ".", "LFE_HSI", "(", "X_MS_UP", ")", "\n", "\n", "T_lv3", "=", "self", ".", "TS_lv3", "(", "V_lv3", ",", "K_lv3", ",", "Q_lv3", ")", "\n", "T_lv2", "=", "self", ".", "TS_lv2", "(", "V_lv2", ",", "K_lv2", ",", "Q_lv2", ")", "\n", "T_lv1", "=", "self", ".", "TS_lv1", "(", "V_lv1", ",", "K_lv1", ",", "Q_lv1", ")", "\n", "\n", "#Save feature maps for illustration purpose", "\n", "# feature_dic={}", "\n", "# feature_dic.update({\"V\": V_lv3.detach().cpu().numpy()})", "\n", "# feature_dic.update({\"K\": K_lv3.detach().cpu().numpy()})", "\n", "# feature_dic.update({\"Q\": Q_lv3.detach().cpu().numpy()})", "\n", "# feature_dic.update({\"T\": T_lv3.detach().cpu().numpy()})", "\n", "# savemat(\"/home/lidan/Dropbox/Hyperspectral/HyperTransformer/feature_visualization_pavia/soft_attention/multi_head_no_skip_lv3.mat\", feature_dic)", "\n", "# exit()", "\n", "\n", "#Shallow Feature Extraction (SFE)", "\n", "x", "=", "self", ".", "SFE", "(", "X_MS", ")", "\n", "\n", "#####################################", "\n", "#### stage1: (L/4, W/4) scale ######", "\n", "#####################################", "\n", "x11", "=", "x", "\n", "#HyperTransformer at (L/4, W/4) scale", "\n", "x11_res", "=", "x11", "\n", "if", "self", ".", "config", "[", "self", ".", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"feature_sum\"", "]", ":", "\n", "            ", "x11_res", "=", "x11_res", "+", "T_lv3", "\n", "x11_res", "=", "self", ".", "conv11_headSUM", "(", "x11_res", ")", "#F.relu(self.conv11_head(x11_res))", "\n", "", "else", ":", "\n", "            ", "x11_res", "=", "torch", ".", "cat", "(", "(", "self", ".", "BN_x11", "(", "x11_res", ")", ",", "T_lv3", ")", ",", "dim", "=", "1", ")", "\n", "x11_res", "=", "self", ".", "conv11_head", "(", "x11_res", ")", "#F.relu(self.conv11_head(x11_res))", "\n", "", "x11", "=", "x11", "+", "x11_res", "\n", "#Residial learning", "\n", "x11_res", "=", "x11", "\n", "for", "i", "in", "range", "(", "self", ".", "num_res_blocks", "[", "1", "]", ")", ":", "\n", "            ", "x11_res", "=", "self", ".", "RB11", "[", "i", "]", "(", "x11_res", ")", "\n", "", "x11_res", "=", "self", ".", "conv11_tail", "(", "x11_res", ")", "\n", "x11", "=", "x11", "+", "x11_res", "\n", "\n", "#####################################", "\n", "#### stage2: (L/2, W/2) scale ######", "\n", "#####################################", "\n", "x22", "=", "self", ".", "conv12", "(", "x11", ")", "\n", "x22", "=", "F", ".", "relu", "(", "self", ".", "ps12", "(", "x22", ")", ")", "\n", "#HyperTransformer at (L/2, W/2) scale", "\n", "x22_res", "=", "x22", "\n", "if", "self", ".", "config", "[", "self", ".", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"feature_sum\"", "]", ":", "\n", "            ", "x22_res", "=", "x22_res", "+", "T_lv2", "\n", "x22_res", "=", "self", ".", "conv22_headSUM", "(", "x22_res", ")", "#F.relu(self.conv22_head(x22_res))", "\n", "", "else", ":", "\n", "            ", "x22_res", "=", "torch", ".", "cat", "(", "(", "self", ".", "BN_x22", "(", "x22_res", ")", ",", "T_lv2", ")", ",", "dim", "=", "1", ")", "\n", "x22_res", "=", "self", ".", "conv22_head", "(", "x22_res", ")", "#F.relu(self.conv22_head(x22_res))", "\n", "", "x22", "=", "x22", "+", "x22_res", "\n", "#Residial learning", "\n", "x22_res", "=", "x22", "\n", "for", "i", "in", "range", "(", "self", ".", "num_res_blocks", "[", "2", "]", ")", ":", "\n", "            ", "x22_res", "=", "self", ".", "RB22", "[", "i", "]", "(", "x22_res", ")", "\n", "", "x22_res", "=", "self", ".", "conv22_tail", "(", "x22_res", ")", "\n", "x22", "=", "x22", "+", "x22_res", "\n", "\n", "#####################################", "\n", "###### stage3: (L, W) scale ########", "\n", "#####################################", "\n", "x33", "=", "self", ".", "conv23", "(", "x22", ")", "\n", "x33", "=", "F", ".", "relu", "(", "self", ".", "ps23", "(", "x33", ")", ")", "\n", "#HyperTransformer at (L, W) scale", "\n", "x33_res", "=", "x33", "\n", "if", "self", ".", "config", "[", "self", ".", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"feature_sum\"", "]", ":", "\n", "            ", "x33_res", "=", "x33_res", "+", "T_lv1", "\n", "x33_res", "=", "self", ".", "conv33_headSUM", "(", "x33_res", ")", "#F.relu(self.conv33_head(x33_res))", "\n", "", "else", ":", "\n", "            ", "x33_res", "=", "torch", ".", "cat", "(", "(", "self", ".", "BN_x33", "(", "x33_res", ")", ",", "T_lv1", ")", ",", "dim", "=", "1", ")", "\n", "x33_res", "=", "self", ".", "conv33_head", "(", "x33_res", ")", "#F.relu(self.conv33_head(x33_res))", "\n", "", "x33", "=", "x33", "+", "x33_res", "\n", "#Residual learning", "\n", "x33_res", "=", "x33", "\n", "for", "i", "in", "range", "(", "self", ".", "num_res_blocks", "[", "3", "]", ")", ":", "\n", "            ", "x33_res", "=", "self", ".", "RB33", "[", "i", "]", "(", "x33_res", ")", "\n", "", "x33_res", "=", "self", ".", "conv33_tail", "(", "x33_res", ")", "\n", "x33", "=", "x33", "+", "x33_res", "\n", "\n", "#####################################", "\n", "############ Feature Pyramid ########", "\n", "#####################################", "\n", "x11_up", "=", "F", ".", "interpolate", "(", "x11", ",", "scale_factor", "=", "4", ",", "mode", "=", "'bicubic'", ")", "\n", "x22_up", "=", "F", ".", "interpolate", "(", "x22", ",", "scale_factor", "=", "2", ",", "mode", "=", "'bicubic'", ")", "\n", "xF", "=", "torch", ".", "cat", "(", "(", "x11_up", ",", "x22_up", ",", "x33", ")", ",", "dim", "=", "1", ")", "\n", "\n", "#####################################", "\n", "####  Final convolution   ###########", "\n", "#####################################", "\n", "xF", "=", "self", ".", "final_conv", "(", "xF", ")", "\n", "xF_res", "=", "xF", "\n", "\n", "#Final resblocks", "\n", "for", "i", "in", "range", "(", "self", ".", "num_res_blocks", "[", "4", "]", ")", ":", "\n", "            ", "xF_res", "=", "self", ".", "RBF", "[", "i", "]", "(", "xF_res", ")", "\n", "", "xF_res", "=", "self", ".", "convF_tail", "(", "xF_res", ")", "\n", "x", "=", "xF", "+", "xF_res", "\n", "\n", "#####################################", "\n", "#      Transfer Periferal Loss      #", "\n", "#####################################", "\n", "#v_vgg_lv1, v_vgg_lv2, v_vgg_lv3 = self.VGG_LFE_HSI(X_MS_UP)", "\n", "#q_vgg_lv1, q_vgg_lv2, q_vgg_lv3 = self.VGG_LFE_PAN(X_PAN)", "\n", "#loss_tp = LOSS_TP(V_lv1, v_vgg_lv1) + LOSS_TP(V_lv2, v_vgg_lv2) + LOSS_TP(V_lv3, v_vgg_lv3)", "\n", "#loss_tp = loss_tp + LOSS_TP(Q_lv1, q_vgg_lv1) + LOSS_TP(Q_lv2, q_vgg_lv2) + LOSS_TP(Q_lv3, q_vgg_lv3)", "\n", "\n", "Phi_lv1", ",", "Phi_lv2", ",", "Phi_lv3", "=", "self", ".", "LFE_HSI", "(", "x", ".", "detach", "(", ")", ")", "\n", "Phi_T_lv3", "=", "self", ".", "TS_lv3", "(", "V_lv3", ",", "K_lv3", ",", "Phi_lv3", ")", "\n", "Phi_T_lv2", "=", "self", ".", "TS_lv2", "(", "V_lv2", ",", "K_lv2", ",", "Phi_lv2", ")", "\n", "Phi_T_lv1", "=", "self", ".", "TS_lv1", "(", "V_lv1", ",", "K_lv1", ",", "Phi_lv1", ")", "\n", "loss_tp", "=", "LOSS_TP", "(", "Phi_T_lv1", ",", "T_lv1", ")", "+", "LOSS_TP", "(", "Phi_T_lv2", ",", "T_lv2", ")", "+", "LOSS_TP", "(", "Phi_T_lv3", ",", "T_lv3", ")", "\n", "\n", "#####################################", "\n", "#       Output                      #", "\n", "#####################################", "\n", "x13", "=", "self", ".", "up_conv13", "(", "x11", ")", "\n", "x23", "=", "self", ".", "up_conv23", "(", "x22", ")", "\n", "output", "=", "{", "\"pred\"", ":", "x", ",", "\n", "\"x13\"", ":", "x13", ",", "\n", "\"x23\"", ":", "x23", ",", "\n", "\"tp_loss\"", ":", "loss_tp", "}", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.HyperTransformerPre.__init__": [[791, 838], ["torch.nn.Module.__init__", "HyperTransformer.LFE", "HyperTransformer.LFE", "HyperTransformer.ScaledDotProductAttentionOnly", "HyperTransformer.ScaledDotProductAttentionOnly", "HyperTransformer.ScaledDotProductAttentionOnly", "HyperTransformer.SFE", "HyperTransformer.conv3x3", "HyperTransformer.conv3x3", "torch.nn.PixelShuffle", "torch.nn.PixelShuffle", "HyperTransformer.conv3x3", "HyperTransformer.conv3x3", "torch.nn.PixelShuffle", "torch.nn.PixelShuffle", "HyperTransformer.conv3x3", "torch.nn.Conv2d", "torch.nn.Conv2d", "int", "int", "int", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__init__", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3", "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "HyperTransformerPre", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_DHP_MS", "=", "config", "[", "\"is_DHP_MS\"", "]", "\n", "self", ".", "in_channels", "=", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"spectral_bands\"", "]", "\n", "self", ".", "out_channels", "=", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"spectral_bands\"", "]", "\n", "self", ".", "factor", "=", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"factor\"", "]", "\n", "\n", "self", ".", "num_res_blocks", "=", "[", "16", ",", "1", ",", "1", ",", "1", ",", "4", "]", "\n", "self", ".", "n_feats", "=", "256", "\n", "self", ".", "res_scale", "=", "1", "\n", "\n", "self", ".", "LFE_HSI", "=", "LFE", "(", "in_channels", "=", "self", ".", "in_channels", ")", "\n", "self", ".", "LFE_PAN", "=", "LFE", "(", "in_channels", "=", "1", ")", "\n", "# Scaled dot product attention", "\n", "lv1_dim", "=", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"LR_size\"", "]", "**", "2", "\n", "lv2_dim", "=", "(", "2", "*", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"LR_size\"", "]", ")", "**", "2", "\n", "lv3_dim", "=", "(", "4", "*", "config", "[", "config", "[", "\"train_dataset\"", "]", "]", "[", "\"LR_size\"", "]", ")", "**", "2", "\n", "### Scaled Dot Product Attention ###", "\n", "self", ".", "TS_lv3", "=", "ScaledDotProductAttentionOnly", "(", "temperature", "=", "lv1_dim", ")", "\n", "self", ".", "TS_lv2", "=", "ScaledDotProductAttentionOnly", "(", "temperature", "=", "lv2_dim", ")", "\n", "self", ".", "TS_lv1", "=", "ScaledDotProductAttentionOnly", "(", "temperature", "=", "lv3_dim", ")", "\n", "self", ".", "SFE", "=", "SFE", "(", "self", ".", "in_channels", ",", "self", ".", "num_res_blocks", "[", "0", "]", ",", "self", ".", "n_feats", ",", "self", ".", "res_scale", ")", "\n", "\n", "###############", "\n", "### stage11 ###", "\n", "###############", "\n", "self", ".", "conv11_head", "=", "conv3x3", "(", "2", "*", "self", ".", "n_feats", ",", "self", ".", "n_feats", ")", "\n", "self", ".", "conv12", "=", "conv3x3", "(", "self", ".", "n_feats", ",", "self", ".", "n_feats", "*", "2", ")", "\n", "self", ".", "ps12", "=", "nn", ".", "PixelShuffle", "(", "2", ")", "\n", "\n", "###############", "\n", "### stage22 ###", "\n", "###############", "\n", "self", ".", "conv22_head", "=", "conv3x3", "(", "2", "*", "int", "(", "self", ".", "n_feats", "/", "2", ")", ",", "int", "(", "self", ".", "n_feats", "/", "2", ")", ")", "\n", "self", ".", "conv23", "=", "conv3x3", "(", "int", "(", "self", ".", "n_feats", "/", "2", ")", ",", "self", ".", "n_feats", ")", "\n", "self", ".", "ps23", "=", "nn", ".", "PixelShuffle", "(", "2", ")", "\n", "\n", "###############", "\n", "### stage33 ###", "\n", "###############", "\n", "self", ".", "conv33_head", "=", "conv3x3", "(", "2", "*", "int", "(", "self", ".", "n_feats", "/", "4", ")", ",", "int", "(", "self", ".", "n_feats", "/", "4", ")", ")", "\n", "\n", "\n", "##############", "\n", "### FINAL ####", "\n", "##############", "\n", "self", ".", "final_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "self", ".", "n_feats", "+", "int", "(", "self", ".", "n_feats", "/", "2", ")", "+", "int", "(", "self", ".", "n_feats", "/", "4", ")", ",", "out_channels", "=", "self", ".", "out_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.HyperTransformerPre.forward": [[839, 914], ["HyperTransformer.HyperTransformerPre.LFE_PAN", "HyperTransformer.HyperTransformerPre.LFE_PAN", "HyperTransformer.HyperTransformerPre.LFE_HSI", "HyperTransformer.HyperTransformerPre.TS_lv3", "HyperTransformer.HyperTransformerPre.TS_lv2", "HyperTransformer.HyperTransformerPre.TS_lv1", "HyperTransformer.HyperTransformerPre.SFE", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "HyperTransformer.HyperTransformerPre.conv11_head", "HyperTransformer.HyperTransformerPre.conv12", "torch.relu", "torch.relu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "HyperTransformer.HyperTransformerPre.conv22_head", "HyperTransformer.HyperTransformerPre.conv23", "torch.relu", "torch.relu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "HyperTransformer.HyperTransformerPre.conv33_head", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "HyperTransformer.HyperTransformerPre.final_conv", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "X_PAN.unsqueeze.unsqueeze.unsqueeze", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "HyperTransformer.HyperTransformerPre.ps12", "HyperTransformer.HyperTransformerPre.ps23", "torch.interpolate", "torch.interpolate"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "X_MS", ",", "X_PAN", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "not", "self", ".", "is_DHP_MS", ":", "\n", "                ", "X_MS_UP", "=", "F", ".", "interpolate", "(", "X_MS", ",", "scale_factor", "=", "(", "self", ".", "factor", ",", "self", ".", "factor", ")", ",", "mode", "=", "'bicubic'", ")", "\n", "\n", "", "else", ":", "\n", "                ", "X_MS_UP", "=", "X_MS", "\n", "\n", "# Generating PAN, and PAN (UD) images", "\n", "", "X_PAN", "=", "X_PAN", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "PAN_D", "=", "F", ".", "interpolate", "(", "X_PAN", ",", "scale_factor", "=", "(", "1", "/", "self", ".", "factor", ",", "1", "/", "self", ".", "factor", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "PAN_UD", "=", "F", ".", "interpolate", "(", "PAN_D", ",", "scale_factor", "=", "(", "self", ".", "factor", ",", "self", ".", "factor", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "\n", "#Extracting T and S at multiple-scales", "\n", "#lv1 = LxW, lv2 = (L/2)x(w/2), lv3=(L/4, W/4)", "\n", "", "V_lv1", ",", "V_lv2", ",", "V_lv3", "=", "self", ".", "LFE_PAN", "(", "X_PAN", ")", "\n", "K_lv1", ",", "K_lv2", ",", "K_lv3", "=", "self", ".", "LFE_PAN", "(", "PAN_UD", ")", "\n", "Q_lv1", ",", "Q_lv2", ",", "Q_lv3", "=", "self", ".", "LFE_HSI", "(", "X_MS_UP", ")", "\n", "\n", "T_lv3", "=", "self", ".", "TS_lv3", "(", "V_lv3", ",", "K_lv3", ",", "Q_lv3", ")", "\n", "T_lv2", "=", "self", ".", "TS_lv2", "(", "V_lv2", ",", "K_lv2", ",", "Q_lv2", ")", "\n", "T_lv1", "=", "self", ".", "TS_lv1", "(", "V_lv1", ",", "K_lv1", ",", "Q_lv1", ")", "\n", "\n", "#Shallow Feature Extraction (SFE)", "\n", "x", "=", "self", ".", "SFE", "(", "X_MS", ")", "\n", "\n", "#####################################", "\n", "#### stage11: (L/4, W/4) scale ######", "\n", "#####################################", "\n", "x11", "=", "x", "\n", "#HyperTransformer at (L/4, W/4) scale", "\n", "x11_res", "=", "x11", "\n", "x11_res", "=", "torch", ".", "cat", "(", "(", "x11_res", ",", "T_lv3", ")", ",", "dim", "=", "1", ")", "\n", "x11_res", "=", "self", ".", "conv11_head", "(", "x11_res", ")", "#F.relu(self.conv11_head(x11_res))", "\n", "x11", "=", "x11", "+", "x11_res", "\n", "\n", "#####################################", "\n", "#### stage22: (L/2, W/2) scale ######", "\n", "#####################################", "\n", "x22", "=", "self", ".", "conv12", "(", "x11", ")", "\n", "x22", "=", "F", ".", "relu", "(", "self", ".", "ps12", "(", "x22", ")", ")", "\n", "#HyperTransformer at (L/2, W/2) scale", "\n", "x22_res", "=", "x22", "\n", "x22_res", "=", "torch", ".", "cat", "(", "(", "x22_res", ",", "T_lv2", ")", ",", "dim", "=", "1", ")", "\n", "x22_res", "=", "self", ".", "conv22_head", "(", "x22_res", ")", "#F.relu(self.conv22_head(x22_res))", "\n", "x22", "=", "x22", "+", "x22_res", "\n", "\n", "#####################################", "\n", "###### stage22: (L, W) scale ########", "\n", "#####################################", "\n", "x33", "=", "self", ".", "conv23", "(", "x22", ")", "\n", "x33", "=", "F", ".", "relu", "(", "self", ".", "ps23", "(", "x33", ")", ")", "\n", "#HyperTransformer at (L, W) scale", "\n", "x33_res", "=", "x33", "\n", "x33_res", "=", "torch", ".", "cat", "(", "(", "x33_res", ",", "T_lv1", ")", ",", "dim", "=", "1", ")", "\n", "x33_res", "=", "self", ".", "conv33_head", "(", "x33_res", ")", "#F.relu(self.conv33_head(x33_res))", "\n", "x33", "=", "x33", "+", "x33_res", "\n", "\n", "#####################################", "\n", "############ Feature Pyramid ########", "\n", "#####################################", "\n", "x11_up", "=", "F", ".", "interpolate", "(", "x11", ",", "scale_factor", "=", "4", ",", "mode", "=", "'bicubic'", ")", "\n", "x22_up", "=", "F", ".", "interpolate", "(", "x22", ",", "scale_factor", "=", "2", ",", "mode", "=", "'bicubic'", ")", "\n", "xF", "=", "torch", ".", "cat", "(", "(", "x11_up", ",", "x22_up", ",", "x33", ")", ",", "dim", "=", "1", ")", "\n", "\n", "#####################################", "\n", "####  Final convolution   ###########", "\n", "#####################################", "\n", "x", "=", "self", ".", "final_conv", "(", "xF", ")", "\n", "\n", "#####################################", "\n", "#      Output                       #", "\n", "#####################################", "\n", "output", "=", "{", "\"pred\"", ":", "x", "}", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv1x1": [[11, 14], ["torch.nn.Conv2d"], "function", ["None"], ["def", "conv1x1", "(", "in_channels", ",", "out_channels", ",", "stride", "=", "1", ")", ":", "\n", "    ", "return", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride", ",", "padding", "=", "0", ",", "bias", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.models.HyperTransformer.conv3x3": [[15, 18], ["torch.nn.Conv2d"], "function", ["None"], ["", "def", "conv3x3", "(", "in_channels", ",", "out_channels", ",", "stride", "=", "1", ")", ":", "\n", "    ", "return", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.pavia_dataset.__init__": [[20, 52], ["cv2.setNumThreads", "collections.defaultdict", "os.path.join", "line.rstrip", "HSI_datasets.pavia_dataset.files[].append", "os.path.join", "open", "os.path.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "config", ",", "is_train", "=", "True", ",", "is_dhp", "=", "False", ",", "want_DHP_MS_HR", "=", "False", "\n", ")", ":", "\n", "        ", "self", ".", "split", "=", "\"train\"", "if", "is_train", "else", "\"val\"", "#Define train and validation splits", "\n", "self", ".", "config", "=", "config", "#Configuration file", "\n", "self", ".", "want_DHP_MS_HR", "=", "want_DHP_MS_HR", "#This ask: DO we need DIP up-sampled output as dataloader output?", "\n", "self", ".", "is_dhp", "=", "is_dhp", "#This checks: \"Is this DIP training?\"", "\n", "self", ".", "dir", "=", "self", ".", "config", "[", "\"pavia_dataset\"", "]", "[", "\"data_dir\"", "]", "#Path to Pavia Center dataset ", "\n", "\n", "if", "self", ".", "split", "==", "\"val\"", ":", "\n", "            ", "self", ".", "file_list", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dir", ",", "f\"{self.split}\"", "+", "\".txt\"", ")", "\n", "", "elif", "self", ".", "split", "==", "\"train\"", ":", "\n", "            ", "self", ".", "file_list", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dir", ",", "f\"{self.split}\"", "+", "\".txt\"", ")", "\n", "if", "is_dhp", ":", "\n", "                ", "self", ".", "file_list", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dir", ",", "f\"{self.split}_dhp\"", "+", "\".txt\"", ")", "\n", "\n", "", "", "self", ".", "images", "=", "[", "line", ".", "rstrip", "(", "\"\\n\"", ")", "for", "line", "in", "open", "(", "self", ".", "file_list", ")", "]", "#Read image name corresponds to train/val/test set", "\n", "\n", "self", ".", "augmentation", "=", "self", ".", "config", "[", "\"pavia_dataset\"", "]", "[", "\"augmentation\"", "]", "#Augmentation needed or not? ", "\n", "\n", "self", ".", "LR_crop_size", "=", "(", "self", ".", "config", "[", "\"pavia_dataset\"", "]", "[", "\"LR_size\"", "]", ",", "self", ".", "config", "[", "\"pavia_dataset\"", "]", "[", "\"LR_size\"", "]", ")", "#Size of the the LR-HSI", "\n", "\n", "self", ".", "HR_crop_size", "=", "[", "self", ".", "config", "[", "\"pavia_dataset\"", "]", "[", "\"HR_size\"", "]", ",", "self", ".", "config", "[", "\"pavia_dataset\"", "]", "[", "\"HR_size\"", "]", "]", "#Size of the HR-HSI", "\n", "\n", "cv2", ".", "setNumThreads", "(", "0", ")", "# to avoid Deadloack  between CV Threads and Pytorch Threads caused in resizing", "\n", "\n", "self", ".", "files", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "f", "in", "self", ".", "images", ":", "\n", "            ", "self", ".", "img_root", "=", "self", ".", "dir", "+", "f", "+", "\"/\"", "\n", "self", ".", "files", "[", "self", ".", "split", "]", ".", "append", "(", "\n", "{", "\n", "\"imgs\"", ":", "self", ".", "img_root", "+", "f", "+", "\".mat\"", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.pavia_dataset.__len__": [[55, 57], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "files", "[", "self", ".", "split", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.pavia_dataset._augmentaion": [[58, 82], ["torch.randint", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip"], "methods", ["None"], ["", "def", "_augmentaion", "(", "self", ",", "MS_image", ",", "PAN_image", ",", "reference", ")", ":", "\n", "        ", "N_augs", "=", "4", "\n", "aug_idx", "=", "torch", ".", "randint", "(", "0", ",", "N_augs", ",", "(", "1", ",", ")", ")", "\n", "if", "aug_idx", "==", "0", ":", "\n", "#Horizontal Flip", "\n", "            ", "MS_image", "=", "torch", ".", "flip", "(", "MS_image", ",", "[", "1", "]", ")", "\n", "PAN_image", "=", "torch", ".", "flip", "(", "PAN_image", ",", "[", "0", "]", ")", "\n", "reference", "=", "torch", ".", "flip", "(", "reference", ",", "[", "1", "]", ")", "\n", "", "elif", "aug_idx", "==", "1", ":", "\n", "#Vertical Flip", "\n", "            ", "MS_image", "=", "torch", ".", "flip", "(", "MS_image", ",", "[", "2", "]", ")", "\n", "PAN_image", "=", "torch", ".", "flip", "(", "PAN_image", ",", "[", "1", "]", ")", "\n", "reference", "=", "torch", ".", "flip", "(", "reference", ",", "[", "2", "]", ")", "\n", "", "elif", "aug_idx", "==", "2", ":", "\n", "#Horizontal flip", "\n", "            ", "MS_image", "=", "torch", ".", "flip", "(", "MS_image", ",", "[", "1", "]", ")", "\n", "PAN_image", "=", "torch", ".", "flip", "(", "PAN_image", ",", "[", "0", "]", ")", "\n", "reference", "=", "torch", ".", "flip", "(", "reference", ",", "[", "1", "]", ")", "\n", "#Vertical Flip", "\n", "MS_image", "=", "torch", ".", "flip", "(", "MS_image", ",", "[", "2", "]", ")", "\n", "PAN_image", "=", "torch", ".", "flip", "(", "PAN_image", ",", "[", "1", "]", ")", "\n", "reference", "=", "torch", ".", "flip", "(", "reference", ",", "[", "2", "]", ")", "\n", "\n", "", "return", "MS_image", ",", "PAN_image", ",", "reference", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.pavia_dataset.getHSIdata": [[83, 123], ["scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "HSI_datasets.pavia_dataset._augmentaion", "numpy.random.shuffle", "numpy.array", "len", "numpy.array", "numpy.array", "int"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset._augmentaion"], ["", "def", "getHSIdata", "(", "self", ",", "index", ")", ":", "\n", "        ", "image_dict", "=", "self", ".", "files", "[", "self", ".", "split", "]", "[", "index", "]", "\n", "\n", "# read each image in list", "\n", "mat", "=", "scipy", ".", "io", ".", "loadmat", "(", "image_dict", "[", "\"imgs\"", "]", ")", "\n", "reference", "=", "mat", "[", "\"ref\"", "]", "\n", "PAN_image", "=", "mat", "[", "\"pan\"", "]", "\n", "\n", "if", "self", ".", "want_DHP_MS_HR", ":", "\n", "            ", "opt_lambda", "=", "self", ".", "config", "[", "\"pavia_dataset\"", "]", "[", "\"optimal_lambda\"", "]", "\n", "mat_dhp", "=", "scipy", ".", "io", ".", "loadmat", "(", "image_dict", "[", "\"imgs\"", "]", "[", ":", "-", "4", "]", "+", "\"_dhp_\"", "+", "\"{0:0=1d}\"", ".", "format", "(", "int", "(", "10", "*", "opt_lambda", ")", ")", "+", "\".mat\"", ")", "\n", "\n", "# Taking DIP up-sampled image as inputs", "\n", "MS_image", "=", "mat_dhp", "[", "\"dhp\"", "]", "\n", "\n", "# Normalization", "\n", "#   MS_image    = torch.from_numpy(((np.array(MS_image) - self.dhp_mean)/self.dhp_std).transpose(2, 0, 1))", "\n", "#   PAN_image   = torch.from_numpy((np.array(PAN_image) - self.pan_mean)/self.pan_std)", "\n", "#   reference   = torch.from_numpy(((np.array(reference) - self.ref_mean)/self.ref_std).transpose(2, 0, 1))", "\n", "", "else", ":", "\n", "            ", "MS_image", "=", "mat", "[", "\"y\"", "]", "\n", "\n", "# COnvert inputs into torch tensors", "\n", "", "MS_image", "=", "torch", ".", "from_numpy", "(", "(", "np", ".", "array", "(", "MS_image", ")", "/", "1.0", ")", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "PAN_image", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "PAN_image", ")", "/", "1.0", ")", "\n", "reference", "=", "torch", ".", "from_numpy", "(", "(", "np", ".", "array", "(", "reference", ")", "/", "1.0", ")", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "\n", "# Max Normalization", "\n", "MS_image", "=", "MS_image", "/", "self", ".", "config", "[", "\"pavia_dataset\"", "]", "[", "\"max_value\"", "]", "\n", "PAN_image", "=", "PAN_image", "/", "self", ".", "config", "[", "\"pavia_dataset\"", "]", "[", "\"max_value\"", "]", "\n", "reference", "=", "reference", "/", "self", ".", "config", "[", "\"pavia_dataset\"", "]", "[", "\"max_value\"", "]", "\n", "\n", "#If split = \"train\" and augment = \"true\" do augmentation", "\n", "if", "self", ".", "split", "==", "\"train\"", "and", "self", ".", "augmentation", ":", "\n", "            ", "MS_image", ",", "PAN_image", ",", "reference", "=", "self", ".", "_augmentaion", "(", "MS_image", ",", "PAN_image", ",", "reference", ")", "\n", "\n", "", "if", "self", ".", "split", "==", "\"train\"", "and", "index", "==", "len", "(", "self", ".", "files", "[", "self", ".", "split", "]", ")", "-", "1", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "self", ".", "files", "[", "self", ".", "split", "]", ")", "\n", "\n", "", "return", "image_dict", ",", "MS_image", ",", "PAN_image", ",", "reference", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.pavia_dataset.__getitem__": [[125, 130], ["HSI_datasets.pavia_dataset.getHSIdata"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.getHSIdata"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "image_dict", ",", "MS_image", ",", "PAN_image", ",", "reference", "=", "self", ".", "getHSIdata", "(", "index", ")", "\n", "\n", "return", "image_dict", ",", "MS_image", ",", "PAN_image", ",", "reference", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana_dataset.__init__": [[134, 182], ["cv2.setNumThreads", "collections.defaultdict", "os.path.join", "line.rstrip", "HSI_datasets.botswana_dataset.files[].append", "os.path.join", "open", "os.path.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "config", ",", "is_train", "=", "True", ",", "is_dhp", "=", "False", ",", "want_DHP_MS_HR", "=", "False", "\n", ")", ":", "\n", "# Determine between train and val splits", "\n", "        ", "self", ".", "split", "=", "\"train\"", "if", "is_train", "else", "\"val\"", "\n", "\n", "#COnfig file", "\n", "self", ".", "config", "=", "config", "\n", "\n", "#Settings (DIP or no-DIP)", "\n", "self", ".", "want_DHP_MS_HR", "=", "want_DHP_MS_HR", "\n", "self", ".", "is_dhp", "=", "is_dhp", "\n", "\n", "# Path to botswana dataset", "\n", "self", ".", "dir", "=", "self", ".", "config", "[", "\"botswana_dataset\"", "]", "[", "\"data_dir\"", "]", "\n", "\n", "if", "self", ".", "split", "==", "\"val\"", ":", "\n", "            ", "self", ".", "file_list", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dir", ",", "f\"{self.split}\"", "+", "\".txt\"", ")", "\n", "", "elif", "self", ".", "split", "==", "\"train\"", ":", "\n", "            ", "self", ".", "file_list", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dir", ",", "f\"{self.split}\"", "+", "\".txt\"", ")", "\n", "if", "is_dhp", ":", "\n", "                ", "self", ".", "file_list", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dir", ",", "f\"{self.split}_dhp\"", "+", "\".txt\"", ")", "\n", "\n", "# List of all images", "\n", "", "", "self", ".", "images", "=", "[", "line", ".", "rstrip", "(", "\"\\n\"", ")", "for", "line", "in", "open", "(", "self", ".", "file_list", ")", "]", "\n", "\n", "# augmentations (Not applicable in this experiment actually)", "\n", "self", ".", "augmentation", "=", "self", ".", "config", "[", "\"botswana_dataset\"", "]", "[", "\"augmentation\"", "]", "\n", "\n", "# Reading the LR crop size", "\n", "self", ".", "LR_crop_size", "=", "(", "self", ".", "config", "[", "\"botswana_dataset\"", "]", "[", "\"LR_size\"", "]", ",", "self", ".", "config", "[", "\"botswana_dataset\"", "]", "[", "\"LR_size\"", "]", ")", "\n", "\n", "# High resolution crop size", "\n", "self", ".", "HR_crop_size", "=", "[", "\n", "self", ".", "config", "[", "\"botswana_dataset\"", "]", "[", "\"HR_size\"", "]", ",", "\n", "self", ".", "config", "[", "\"botswana_dataset\"", "]", "[", "\"HR_size\"", "]", ",", "\n", "]", "\n", "\n", "# To avoid Deadloack  between CV Threads and Pytorch Threads caused in resizing", "\n", "cv2", ".", "setNumThreads", "(", "0", ")", "\n", "\n", "# Set of all image names", "\n", "self", ".", "files", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "f", "in", "self", ".", "images", ":", "\n", "            ", "self", ".", "img_root", "=", "self", ".", "dir", "+", "f", "+", "\"/\"", "\n", "self", ".", "files", "[", "self", ".", "split", "]", ".", "append", "(", "\n", "{", "\n", "\"imgs\"", ":", "self", ".", "img_root", "+", "f", "+", "\".mat\"", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana_dataset.__len__": [[185, 187], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "files", "[", "self", ".", "split", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana_dataset._augmentaion": [[188, 212], ["torch.randint", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip"], "methods", ["None"], ["", "def", "_augmentaion", "(", "self", ",", "MS_image", ",", "PAN_image", ",", "reference", ")", ":", "\n", "        ", "N_augs", "=", "4", "\n", "aug_idx", "=", "torch", ".", "randint", "(", "0", ",", "N_augs", ",", "(", "1", ",", ")", ")", "\n", "if", "aug_idx", "==", "0", ":", "\n", "#Horizontal Flip", "\n", "            ", "MS_image", "=", "torch", ".", "flip", "(", "MS_image", ",", "[", "1", "]", ")", "\n", "PAN_image", "=", "torch", ".", "flip", "(", "PAN_image", ",", "[", "0", "]", ")", "\n", "reference", "=", "torch", ".", "flip", "(", "reference", ",", "[", "1", "]", ")", "\n", "", "elif", "aug_idx", "==", "1", ":", "\n", "#Vertical Flip", "\n", "            ", "MS_image", "=", "torch", ".", "flip", "(", "MS_image", ",", "[", "2", "]", ")", "\n", "PAN_image", "=", "torch", ".", "flip", "(", "PAN_image", ",", "[", "1", "]", ")", "\n", "reference", "=", "torch", ".", "flip", "(", "reference", ",", "[", "2", "]", ")", "\n", "", "elif", "aug_idx", "==", "2", ":", "\n", "#Horizontal flip", "\n", "            ", "MS_image", "=", "torch", ".", "flip", "(", "MS_image", ",", "[", "1", "]", ")", "\n", "PAN_image", "=", "torch", ".", "flip", "(", "PAN_image", ",", "[", "0", "]", ")", "\n", "reference", "=", "torch", ".", "flip", "(", "reference", ",", "[", "1", "]", ")", "\n", "#Vertical Flip", "\n", "MS_image", "=", "torch", ".", "flip", "(", "MS_image", ",", "[", "2", "]", ")", "\n", "PAN_image", "=", "torch", ".", "flip", "(", "PAN_image", ",", "[", "1", "]", ")", "\n", "reference", "=", "torch", ".", "flip", "(", "reference", ",", "[", "2", "]", ")", "\n", "\n", "", "return", "MS_image", ",", "PAN_image", ",", "reference", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana_dataset.getHSIdata": [[213, 253], ["scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "HSI_datasets.botswana_dataset._augmentaion", "numpy.random.shuffle", "numpy.array", "len", "numpy.array", "numpy.array", "int"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset._augmentaion"], ["", "def", "getHSIdata", "(", "self", ",", "index", ")", ":", "\n", "        ", "image_dict", "=", "self", ".", "files", "[", "self", ".", "split", "]", "[", "index", "]", "\n", "\n", "# Reading the mat file", "\n", "mat", "=", "scipy", ".", "io", ".", "loadmat", "(", "image_dict", "[", "\"imgs\"", "]", ")", "\n", "reference", "=", "mat", "[", "\"ref\"", "]", "\n", "PAN_image", "=", "mat", "[", "\"pan\"", "]", "\n", "\n", "if", "self", ".", "want_DHP_MS_HR", ":", "\n", "            ", "opt_lambda", "=", "self", ".", "config", "[", "\"pavia_dataset\"", "]", "[", "\"optimal_lambda\"", "]", "\n", "mat_dhp", "=", "scipy", ".", "io", ".", "loadmat", "(", "image_dict", "[", "\"imgs\"", "]", "[", ":", "-", "4", "]", "+", "\"_dhp_\"", "+", "\"{0:0=1d}\"", ".", "format", "(", "int", "(", "10", "*", "opt_lambda", ")", ")", "+", "\".mat\"", ")", "\n", "\n", "# Taking DIP up-sampled image as inputs", "\n", "MS_image", "=", "mat_dhp", "[", "\"dhp\"", "]", "\n", "\n", "# Normalization", "\n", "#   MS_image    = torch.from_numpy(((np.array(MS_image) - self.dhp_mean)/self.dhp_std).transpose(2, 0, 1))", "\n", "#   PAN_image   = torch.from_numpy((np.array(PAN_image) - self.pan_mean)/self.pan_std)", "\n", "#   reference   = torch.from_numpy(((np.array(reference) - self.ref_mean)/self.ref_std).transpose(2, 0, 1))", "\n", "", "else", ":", "\n", "            ", "MS_image", "=", "mat", "[", "\"y\"", "]", "\n", "\n", "# Convert inputs into torch tensors", "\n", "", "MS_image", "=", "torch", ".", "from_numpy", "(", "(", "np", ".", "array", "(", "MS_image", ")", "/", "1.0", ")", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "PAN_image", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "PAN_image", ")", "/", "1.0", ")", "\n", "reference", "=", "torch", ".", "from_numpy", "(", "(", "np", ".", "array", "(", "reference", ")", "/", "1.0", ")", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "\n", "# Max Normalization", "\n", "MS_image", "=", "MS_image", "/", "self", ".", "config", "[", "\"botswana_dataset\"", "]", "[", "\"max_value\"", "]", "\n", "PAN_image", "=", "PAN_image", "/", "self", ".", "config", "[", "\"botswana_dataset\"", "]", "[", "\"max_value\"", "]", "\n", "reference", "=", "reference", "/", "self", ".", "config", "[", "\"botswana_dataset\"", "]", "[", "\"max_value\"", "]", "\n", "\n", "#If split = \"train\" and augment = \"true\" do augmentation", "\n", "if", "self", ".", "split", "==", "\"train\"", "and", "self", ".", "augmentation", ":", "\n", "            ", "MS_image", ",", "PAN_image", ",", "reference", "=", "self", ".", "_augmentaion", "(", "MS_image", ",", "PAN_image", ",", "reference", ")", "\n", "\n", "", "if", "self", ".", "split", "==", "\"train\"", "and", "index", "==", "len", "(", "self", ".", "files", "[", "self", ".", "split", "]", ")", "-", "1", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "self", ".", "files", "[", "self", ".", "split", "]", ")", "\n", "\n", "", "return", "image_dict", ",", "MS_image", ",", "PAN_image", ",", "reference", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana_dataset.__getitem__": [[255, 260], ["HSI_datasets.botswana_dataset.getHSIdata"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.getHSIdata"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "image_dict", ",", "MS_image", ",", "PAN_image", ",", "reference", "=", "self", ".", "getHSIdata", "(", "index", ")", "\n", "\n", "return", "image_dict", ",", "MS_image", ",", "PAN_image", ",", "reference", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.chikusei_dataset.__init__": [[262, 304], ["cv2.setNumThreads", "collections.defaultdict", "os.path.join", "line.rstrip", "HSI_datasets.chikusei_dataset.files[].append", "os.path.join", "open", "os.path.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "config", ",", "is_train", "=", "True", ",", "is_dhp", "=", "False", ",", "want_DHP_MS_HR", "=", "False", "\n", ")", ":", "\n", "# Settings", "\n", "        ", "self", ".", "split", "=", "\"train\"", "if", "is_train", "else", "\"val\"", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "want_DHP_MS_HR", "=", "want_DHP_MS_HR", "\n", "self", ".", "is_dhp", "=", "is_dhp", "\n", "\n", "# Paths", "\n", "self", ".", "dir", "=", "self", ".", "config", "[", "\"chikusei_dataset\"", "]", "[", "\"data_dir\"", "]", "\n", "\n", "# Read train/val image indexes from the text file (train.txt, val.txt, train_dhp.txt)", "\n", "if", "self", ".", "split", "==", "\"val\"", ":", "\n", "            ", "self", ".", "file_list", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dir", ",", "f\"{self.split}\"", "+", "\".txt\"", ")", "\n", "", "elif", "self", ".", "split", "==", "\"train\"", ":", "\n", "            ", "self", ".", "file_list", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dir", ",", "f\"{self.split}\"", "+", "\".txt\"", ")", "\n", "if", "is_dhp", ":", "\n", "                ", "self", ".", "file_list", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dir", ",", "f\"{self.split}_dhp\"", "+", "\".txt\"", ")", "\n", "\n", "# list of all images", "\n", "", "", "self", ".", "images", "=", "[", "line", ".", "rstrip", "(", "\"\\n\"", ")", "for", "line", "in", "open", "(", "self", ".", "file_list", ")", "]", "\n", "\n", "# augmentations", "\n", "self", ".", "augmentation", "=", "self", ".", "config", "[", "\"chikusei_dataset\"", "]", "[", "\"augmentation\"", "]", "\n", "\n", "self", ".", "LR_crop_size", "=", "(", "self", ".", "config", "[", "\"chikusei_dataset\"", "]", "[", "\"LR_size\"", "]", ",", "self", ".", "config", "[", "\"chikusei_dataset\"", "]", "[", "\"LR_size\"", "]", ")", "\n", "\n", "self", ".", "HR_crop_size", "=", "[", "\n", "self", ".", "config", "[", "\"chikusei_dataset\"", "]", "[", "\"HR_size\"", "]", ",", "\n", "self", ".", "config", "[", "\"chikusei_dataset\"", "]", "[", "\"HR_size\"", "]", ",", "\n", "]", "\n", "\n", "# to avoid Deadloack  between CV Threads and Pytorch Threads caused in resizing", "\n", "cv2", ".", "setNumThreads", "(", "0", ")", "\n", "\n", "self", ".", "files", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "f", "in", "self", ".", "images", ":", "\n", "            ", "self", ".", "img_root", "=", "self", ".", "dir", "+", "f", "+", "\"/\"", "\n", "self", ".", "files", "[", "self", ".", "split", "]", ".", "append", "(", "\n", "{", "\n", "\"imgs\"", ":", "self", ".", "img_root", "+", "f", "+", "\".mat\"", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.chikusei_dataset.__len__": [[307, 309], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "files", "[", "self", ".", "split", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.chikusei_dataset.getHSIdata": [[310, 341], ["scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "numpy.random.shuffle", "numpy.array", "len", "numpy.array", "numpy.array", "int"], "methods", ["None"], ["", "def", "getHSIdata", "(", "self", ",", "index", ")", ":", "\n", "        ", "image_dict", "=", "self", ".", "files", "[", "self", ".", "split", "]", "[", "index", "]", "\n", "\n", "# read each image in list", "\n", "mat", "=", "scipy", ".", "io", ".", "loadmat", "(", "image_dict", "[", "\"imgs\"", "]", ")", "\n", "reference", "=", "mat", "[", "\"ref\"", "]", "\n", "PAN_image", "=", "mat", "[", "\"pan\"", "]", "\n", "\n", "if", "self", ".", "want_DHP_MS_HR", ":", "\n", "            ", "opt_lambda", "=", "self", ".", "config", "[", "\"chikusei_dataset\"", "]", "[", "\"optimal_lambda\"", "]", "\n", "mat_dhp", "=", "scipy", ".", "io", ".", "loadmat", "(", "image_dict", "[", "\"imgs\"", "]", "[", ":", "-", "4", "]", "+", "\"_dhp_\"", "+", "\"{0:0=1d}\"", ".", "format", "(", "int", "(", "10", "*", "opt_lambda", ")", ")", "+", "\".mat\"", ")", "\n", "\n", "# Taking DIP up-sampled image as inputs", "\n", "MS_image", "=", "mat_dhp", "[", "\"dhp\"", "]", "\n", "", "else", ":", "\n", "            ", "MS_image", "=", "mat", "[", "\"y\"", "]", "\n", "\n", "# COnvert inputs into torch tensors", "\n", "", "MS_image", "=", "torch", ".", "from_numpy", "(", "(", "np", ".", "array", "(", "MS_image", ")", "/", "1.0", ")", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "PAN_image", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "PAN_image", ")", "/", "1.0", ")", "\n", "reference", "=", "torch", ".", "from_numpy", "(", "(", "np", ".", "array", "(", "reference", ")", "/", "1.0", ")", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "\n", "# Max Normalization", "\n", "MS_image", "=", "MS_image", "/", "self", ".", "config", "[", "\"chikusei_dataset\"", "]", "[", "\"max_value\"", "]", "\n", "PAN_image", "=", "PAN_image", "/", "self", ".", "config", "[", "\"chikusei_dataset\"", "]", "[", "\"max_value\"", "]", "\n", "reference", "=", "reference", "/", "self", ".", "config", "[", "\"chikusei_dataset\"", "]", "[", "\"max_value\"", "]", "\n", "\n", "if", "self", ".", "split", "==", "\"train\"", "and", "index", "==", "len", "(", "self", ".", "files", "[", "self", ".", "split", "]", ")", "-", "1", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "self", ".", "files", "[", "self", ".", "split", "]", ")", "\n", "\n", "", "return", "image_dict", ",", "MS_image", ",", "PAN_image", ",", "reference", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.chikusei_dataset.__getitem__": [[343, 348], ["HSI_datasets.chikusei_dataset.getHSIdata"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.getHSIdata"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "image_dict", ",", "MS_image", ",", "PAN_image", ",", "reference", "=", "self", ".", "getHSIdata", "(", "index", ")", "\n", "\n", "return", "image_dict", ",", "MS_image", ",", "PAN_image", ",", "reference", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.la_dataset.__init__": [[352, 394], ["cv2.setNumThreads", "collections.defaultdict", "os.path.join", "line.rstrip", "HSI_datasets.la_dataset.files[].append", "os.path.join", "open", "os.path.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "config", ",", "is_train", "=", "True", ",", "is_dhp", "=", "False", ",", "want_DHP_MS_HR", "=", "False", "\n", ")", ":", "\n", "# Settings", "\n", "        ", "self", ".", "split", "=", "\"train\"", "if", "is_train", "else", "\"val\"", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "want_DHP_MS_HR", "=", "want_DHP_MS_HR", "\n", "self", ".", "is_dhp", "=", "is_dhp", "\n", "\n", "# Paths", "\n", "self", ".", "dir", "=", "self", ".", "config", "[", "\"la_dataset\"", "]", "[", "\"data_dir\"", "]", "\n", "\n", "# Read train/val image indexes from the text file (train.txt, val.txt, train_dhp.txt)", "\n", "if", "self", ".", "split", "==", "\"val\"", ":", "\n", "            ", "self", ".", "file_list", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dir", ",", "f\"{self.split}\"", "+", "\".txt\"", ")", "\n", "", "elif", "self", ".", "split", "==", "\"train\"", ":", "\n", "            ", "self", ".", "file_list", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dir", ",", "f\"{self.split}\"", "+", "\".txt\"", ")", "\n", "if", "is_dhp", ":", "\n", "                ", "self", ".", "file_list", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dir", ",", "f\"{self.split}_dhp\"", "+", "\".txt\"", ")", "\n", "\n", "# list of all images", "\n", "", "", "self", ".", "images", "=", "[", "line", ".", "rstrip", "(", "\"\\n\"", ")", "for", "line", "in", "open", "(", "self", ".", "file_list", ")", "]", "\n", "\n", "# augmentations", "\n", "self", ".", "augmentation", "=", "self", ".", "config", "[", "\"la_dataset\"", "]", "[", "\"augmentation\"", "]", "\n", "\n", "self", ".", "LR_crop_size", "=", "(", "self", ".", "config", "[", "\"la_dataset\"", "]", "[", "\"LR_size\"", "]", ",", "self", ".", "config", "[", "\"la_dataset\"", "]", "[", "\"LR_size\"", "]", ")", "\n", "\n", "self", ".", "HR_crop_size", "=", "[", "\n", "self", ".", "config", "[", "\"la_dataset\"", "]", "[", "\"HR_size\"", "]", ",", "\n", "self", ".", "config", "[", "\"la_dataset\"", "]", "[", "\"HR_size\"", "]", ",", "\n", "]", "\n", "\n", "# to avoid Deadloack  between CV Threads and Pytorch Threads caused in resizing", "\n", "cv2", ".", "setNumThreads", "(", "0", ")", "\n", "\n", "self", ".", "files", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "f", "in", "self", ".", "images", ":", "\n", "            ", "self", ".", "img_root", "=", "self", ".", "dir", "+", "f", "+", "\"/\"", "\n", "self", ".", "files", "[", "self", ".", "split", "]", ".", "append", "(", "\n", "{", "\n", "\"imgs\"", ":", "self", ".", "img_root", "+", "f", "+", "\".mat\"", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.la_dataset.__len__": [[397, 399], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "files", "[", "self", ".", "split", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.la_dataset.getHSIdata": [[400, 431], ["scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "numpy.random.shuffle", "numpy.array", "len", "numpy.array", "numpy.array", "int"], "methods", ["None"], ["", "def", "getHSIdata", "(", "self", ",", "index", ")", ":", "\n", "        ", "image_dict", "=", "self", ".", "files", "[", "self", ".", "split", "]", "[", "index", "]", "\n", "\n", "# read each image in list", "\n", "mat", "=", "scipy", ".", "io", ".", "loadmat", "(", "image_dict", "[", "\"imgs\"", "]", ")", "\n", "reference", "=", "mat", "[", "\"ref\"", "]", "\n", "PAN_image", "=", "mat", "[", "\"pan\"", "]", "\n", "\n", "if", "self", ".", "want_DHP_MS_HR", ":", "\n", "            ", "opt_lambda", "=", "self", ".", "config", "[", "\"la_dataset\"", "]", "[", "\"optimal_lambda\"", "]", "\n", "mat_dhp", "=", "scipy", ".", "io", ".", "loadmat", "(", "image_dict", "[", "\"imgs\"", "]", "[", ":", "-", "4", "]", "+", "\"_dhp_\"", "+", "\"{0:0=1d}\"", ".", "format", "(", "int", "(", "10", "*", "opt_lambda", ")", ")", "+", "\".mat\"", ")", "\n", "\n", "# Taking DIP up-sampled image as inputs", "\n", "MS_image", "=", "mat_dhp", "[", "\"dhp\"", "]", "\n", "", "else", ":", "\n", "            ", "MS_image", "=", "mat", "[", "\"y\"", "]", "\n", "\n", "# COnvert inputs into torch tensors", "\n", "", "MS_image", "=", "torch", ".", "from_numpy", "(", "(", "np", ".", "array", "(", "MS_image", ")", "/", "1.0", ")", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "PAN_image", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "PAN_image", ")", "/", "1.0", ")", "\n", "reference", "=", "torch", ".", "from_numpy", "(", "(", "np", ".", "array", "(", "reference", ")", "/", "1.0", ")", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "\n", "# Max Normalization", "\n", "MS_image", "=", "MS_image", "/", "self", ".", "config", "[", "\"la_dataset\"", "]", "[", "\"max_value\"", "]", "\n", "PAN_image", "=", "PAN_image", "/", "self", ".", "config", "[", "\"la_dataset\"", "]", "[", "\"max_value\"", "]", "\n", "reference", "=", "reference", "/", "self", ".", "config", "[", "\"la_dataset\"", "]", "[", "\"max_value\"", "]", "\n", "\n", "if", "self", ".", "split", "==", "\"train\"", "and", "index", "==", "len", "(", "self", ".", "files", "[", "self", ".", "split", "]", ")", "-", "1", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "self", ".", "files", "[", "self", ".", "split", "]", ")", "\n", "\n", "", "return", "image_dict", ",", "MS_image", ",", "PAN_image", ",", "reference", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.la_dataset.__getitem__": [[433, 438], ["HSI_datasets.la_dataset.getHSIdata"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.getHSIdata"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "image_dict", ",", "MS_image", ",", "PAN_image", ",", "reference", "=", "self", ".", "getHSIdata", "(", "index", ")", "\n", "\n", "return", "image_dict", ",", "MS_image", ",", "PAN_image", ",", "reference", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__init__": [[441, 473], ["cv2.setNumThreads", "collections.defaultdict", "os.path.join", "line.rstrip", "HSI_datasets.botswana4_dataset.files[].append", "os.path.join", "open", "os.path.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "config", ",", "is_train", "=", "True", ",", "is_dhp", "=", "False", ",", "want_DHP_MS_HR", "=", "False", "\n", ")", ":", "\n", "        ", "self", ".", "split", "=", "\"train\"", "if", "is_train", "else", "\"val\"", "#Define train and validation splits", "\n", "self", ".", "config", "=", "config", "#Configuration file", "\n", "self", ".", "want_DHP_MS_HR", "=", "want_DHP_MS_HR", "#This ask: DO we need DIP up-sampled output as dataloader output?", "\n", "self", ".", "is_dhp", "=", "is_dhp", "#This checks: \"Is this DIP training?\"", "\n", "self", ".", "dir", "=", "self", ".", "config", "[", "\"botswana4_dataset\"", "]", "[", "\"data_dir\"", "]", "#Path to Pavia Center dataset ", "\n", "\n", "if", "self", ".", "split", "==", "\"val\"", ":", "\n", "            ", "self", ".", "file_list", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dir", ",", "f\"{self.split}\"", "+", "\".txt\"", ")", "\n", "", "elif", "self", ".", "split", "==", "\"train\"", ":", "\n", "            ", "self", ".", "file_list", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dir", ",", "f\"{self.split}\"", "+", "\".txt\"", ")", "\n", "if", "is_dhp", ":", "\n", "                ", "self", ".", "file_list", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dir", ",", "f\"{self.split}_dhp\"", "+", "\".txt\"", ")", "\n", "\n", "", "", "self", ".", "images", "=", "[", "line", ".", "rstrip", "(", "\"\\n\"", ")", "for", "line", "in", "open", "(", "self", ".", "file_list", ")", "]", "#Read image name corresponds to train/val/test set", "\n", "\n", "self", ".", "augmentation", "=", "self", ".", "config", "[", "\"botswana4_dataset\"", "]", "[", "\"augmentation\"", "]", "#Augmentation needed or not? ", "\n", "\n", "self", ".", "LR_crop_size", "=", "(", "self", ".", "config", "[", "\"botswana4_dataset\"", "]", "[", "\"LR_size\"", "]", ",", "self", ".", "config", "[", "\"botswana4_dataset\"", "]", "[", "\"LR_size\"", "]", ")", "#Size of the the LR-HSI", "\n", "\n", "self", ".", "HR_crop_size", "=", "[", "self", ".", "config", "[", "\"botswana4_dataset\"", "]", "[", "\"HR_size\"", "]", ",", "self", ".", "config", "[", "\"botswana4_dataset\"", "]", "[", "\"HR_size\"", "]", "]", "#Size of the HR-HSI", "\n", "\n", "cv2", ".", "setNumThreads", "(", "0", ")", "# to avoid Deadloack  between CV Threads and Pytorch Threads caused in resizing", "\n", "\n", "self", ".", "files", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "f", "in", "self", ".", "images", ":", "\n", "            ", "self", ".", "img_root", "=", "self", ".", "dir", "+", "f", "+", "\"/\"", "\n", "self", ".", "files", "[", "self", ".", "split", "]", ".", "append", "(", "\n", "{", "\n", "\"imgs\"", ":", "self", ".", "img_root", "+", "f", "+", "\".mat\"", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__len__": [[476, 478], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "files", "[", "self", ".", "split", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset._augmentaion": [[479, 503], ["torch.randint", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip"], "methods", ["None"], ["", "def", "_augmentaion", "(", "self", ",", "MS_image", ",", "PAN_image", ",", "reference", ")", ":", "\n", "        ", "N_augs", "=", "4", "\n", "aug_idx", "=", "torch", ".", "randint", "(", "0", ",", "N_augs", ",", "(", "1", ",", ")", ")", "\n", "if", "aug_idx", "==", "0", ":", "\n", "#Horizontal Flip", "\n", "            ", "MS_image", "=", "torch", ".", "flip", "(", "MS_image", ",", "[", "1", "]", ")", "\n", "PAN_image", "=", "torch", ".", "flip", "(", "PAN_image", ",", "[", "0", "]", ")", "\n", "reference", "=", "torch", ".", "flip", "(", "reference", ",", "[", "1", "]", ")", "\n", "", "elif", "aug_idx", "==", "1", ":", "\n", "#Vertical Flip", "\n", "            ", "MS_image", "=", "torch", ".", "flip", "(", "MS_image", ",", "[", "2", "]", ")", "\n", "PAN_image", "=", "torch", ".", "flip", "(", "PAN_image", ",", "[", "1", "]", ")", "\n", "reference", "=", "torch", ".", "flip", "(", "reference", ",", "[", "2", "]", ")", "\n", "", "elif", "aug_idx", "==", "2", ":", "\n", "#Horizontal flip", "\n", "            ", "MS_image", "=", "torch", ".", "flip", "(", "MS_image", ",", "[", "1", "]", ")", "\n", "PAN_image", "=", "torch", ".", "flip", "(", "PAN_image", ",", "[", "0", "]", ")", "\n", "reference", "=", "torch", ".", "flip", "(", "reference", ",", "[", "1", "]", ")", "\n", "#Vertical Flip", "\n", "MS_image", "=", "torch", ".", "flip", "(", "MS_image", ",", "[", "2", "]", ")", "\n", "PAN_image", "=", "torch", ".", "flip", "(", "PAN_image", ",", "[", "1", "]", ")", "\n", "reference", "=", "torch", ".", "flip", "(", "reference", ",", "[", "2", "]", ")", "\n", "\n", "", "return", "MS_image", ",", "PAN_image", ",", "reference", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.getHSIdata": [[504, 544], ["scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "HSI_datasets.botswana4_dataset._augmentaion", "numpy.random.shuffle", "numpy.array", "len", "numpy.array", "numpy.array", "int"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset._augmentaion"], ["", "def", "getHSIdata", "(", "self", ",", "index", ")", ":", "\n", "        ", "image_dict", "=", "self", ".", "files", "[", "self", ".", "split", "]", "[", "index", "]", "\n", "\n", "# read each image in list", "\n", "mat", "=", "scipy", ".", "io", ".", "loadmat", "(", "image_dict", "[", "\"imgs\"", "]", ")", "\n", "reference", "=", "mat", "[", "\"ref\"", "]", "\n", "PAN_image", "=", "mat", "[", "\"pan\"", "]", "\n", "\n", "if", "self", ".", "want_DHP_MS_HR", ":", "\n", "            ", "opt_lambda", "=", "self", ".", "config", "[", "\"botswana4_dataset\"", "]", "[", "\"optimal_lambda\"", "]", "\n", "mat_dhp", "=", "scipy", ".", "io", ".", "loadmat", "(", "image_dict", "[", "\"imgs\"", "]", "[", ":", "-", "4", "]", "+", "\"_dhp_\"", "+", "\"{0:0=1d}\"", ".", "format", "(", "int", "(", "10", "*", "opt_lambda", ")", ")", "+", "\".mat\"", ")", "\n", "\n", "# Taking DIP up-sampled image as inputs", "\n", "MS_image", "=", "mat_dhp", "[", "\"dhp\"", "]", "\n", "\n", "# Normalization", "\n", "#   MS_image    = torch.from_numpy(((np.array(MS_image) - self.dhp_mean)/self.dhp_std).transpose(2, 0, 1))", "\n", "#   PAN_image   = torch.from_numpy((np.array(PAN_image) - self.pan_mean)/self.pan_std)", "\n", "#   reference   = torch.from_numpy(((np.array(reference) - self.ref_mean)/self.ref_std).transpose(2, 0, 1))", "\n", "", "else", ":", "\n", "            ", "MS_image", "=", "mat", "[", "\"y\"", "]", "\n", "\n", "# COnvert inputs into torch tensors", "\n", "", "MS_image", "=", "torch", ".", "from_numpy", "(", "(", "np", ".", "array", "(", "MS_image", ")", "/", "1.0", ")", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "PAN_image", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "PAN_image", ")", "/", "1.0", ")", "\n", "reference", "=", "torch", ".", "from_numpy", "(", "(", "np", ".", "array", "(", "reference", ")", "/", "1.0", ")", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "\n", "# Max Normalization", "\n", "MS_image", "=", "MS_image", "/", "self", ".", "config", "[", "\"botswana4_dataset\"", "]", "[", "\"max_value\"", "]", "\n", "PAN_image", "=", "PAN_image", "/", "self", ".", "config", "[", "\"botswana4_dataset\"", "]", "[", "\"max_value\"", "]", "\n", "reference", "=", "reference", "/", "self", ".", "config", "[", "\"botswana4_dataset\"", "]", "[", "\"max_value\"", "]", "\n", "\n", "#If split = \"train\" and augment = \"true\" do augmentation", "\n", "if", "self", ".", "split", "==", "\"train\"", "and", "self", ".", "augmentation", ":", "\n", "            ", "MS_image", ",", "PAN_image", ",", "reference", "=", "self", ".", "_augmentaion", "(", "MS_image", ",", "PAN_image", ",", "reference", ")", "\n", "\n", "", "if", "self", ".", "split", "==", "\"train\"", "and", "index", "==", "len", "(", "self", ".", "files", "[", "self", ".", "split", "]", ")", "-", "1", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "self", ".", "files", "[", "self", ".", "split", "]", ")", "\n", "\n", "", "return", "image_dict", ",", "MS_image", ",", "PAN_image", ",", "reference", "\n", "\n"]], "home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.__getitem__": [[546, 551], ["HSI_datasets.botswana4_dataset.getHSIdata"], "methods", ["home.repos.pwc.inspect_result.wgcban_HyperTransformer.dataloaders.HSI_datasets.botswana4_dataset.getHSIdata"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "image_dict", ",", "MS_image", ",", "PAN_image", ",", "reference", "=", "self", ".", "getHSIdata", "(", "index", ")", "\n", "\n", "return", "image_dict", ",", "MS_image", ",", "PAN_image", ",", "reference", "", "", "", ""]]}