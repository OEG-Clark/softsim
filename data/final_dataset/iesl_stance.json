{"home.repos.pwc.inspect_result.iesl_stance.utils.model_helper.get_tokenizer": [[33, 49], ["main.objects.Tokenizer.Char"], "function", ["None"], ["def", "get_tokenizer", "(", "config", ")", ":", "\n", "    ", "'''\n    Returns the tokenizer specified in config \n\n    param config: configuration for training \n    return: tokenizer object \n    return: maximum number of tokens \n    '''", "\n", "tokenizer", "=", "\"\"", "\n", "max_len_token", "=", "0", "\n", "\n", "if", "(", "config", ".", "tokenizer_name", "==", "\"Char\"", ")", ":", "\n", "        ", "tokenizer", "=", "Char", "(", ")", "\n", "max_len_token", "=", "config", ".", "max_num_char", "\n", "\n", "", "return", "tokenizer", ",", "max_len_token", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.utils.model_helper.get_vocab": [[50, 65], ["main.objects.Vocab.Vocab", "config.tokenizer_name.lower", "os.path.exists", "print"], "function", ["None"], ["", "def", "get_vocab", "(", "config", ",", "tokenizer", ",", "max_len_token", ")", ":", "\n", "    ", "'''\n    Returns the vocabulary object \n\n    param config: configuratin for training \n    param tokenizer: tokenizer for training \n    param max_len_token: maximumum number of tokens \n    return: vocab object \n    '''", "\n", "vocab_file", "=", "config", ".", "vocab_file", "+", "\"_\"", "+", "config", ".", "tokenizer_name", ".", "lower", "(", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "exists", "(", "vocab_file", ")", ")", ":", "\n", "        ", "print", "(", "\"Make Vocab for \"", "+", "config", ".", "tokenizer_name", ")", "\n", "\n", "", "vocab", "=", "Vocab", "(", "vocab_file", ",", "tokenizer", ",", "max_len_token", ")", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.utils.model_helper.get_model": [[66, 94], ["main.models.AlignBinary.AlignBinary", "main.models.AlignDot.AlignDot", "main.models.AlignLinear.AlignLinear", "main.models.AlignCNN.AlignCNN", "main.models.Stance.Stance", "main.models.LDTW.LDTW", "ValueError"], "function", ["None"], ["", "def", "get_model", "(", "config", ",", "vocab", ",", "max_len_token", ")", ":", "\n", "    ", "'''\n    Returns an object of the model \n\n    param config: configuration of the model \n    param vocab: vocab for model \n    param max_len_token: maximum number of tokens \n    return: model \n    '''", "\n", "model", "=", "None", "\n", "\n", "# Set up Model", "\n", "if", "config", ".", "model_name", "==", "\"AlignBinary\"", ":", "\n", "        ", "model", "=", "AlignBinary", "(", "config", ",", "vocab", ",", "max_len_token", ")", "\n", "", "elif", "config", ".", "model_name", "==", "\"AlignDot\"", ":", "\n", "        ", "model", "=", "AlignDot", "(", "config", ",", "vocab", ",", "max_len_token", ")", "\n", "", "elif", "config", ".", "model_name", "==", "\"AlignLinear\"", ":", "\n", "        ", "model", "=", "AlignLinear", "(", "config", ",", "vocab", ",", "max_len_token", ")", "\n", "", "elif", "config", ".", "model_name", "==", "\"AlignCNN\"", ":", "\n", "        ", "model", "=", "AlignCNN", "(", "config", ",", "vocab", ",", "max_len_token", ")", "\n", "", "elif", "config", ".", "model_name", "==", "\"Stance\"", ":", "\n", "        ", "model", "=", "Stance", "(", "config", ",", "vocab", ",", "max_len_token", ")", "\n", "", "elif", "config", ".", "model_name", "==", "\"LDTW\"", ":", "\n", "        ", "model", "=", "LDTW", "(", "config", ",", "vocab", ",", "max_len_token", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Model Unknown: \"", ",", "config", ".", "model_name", ")", "\n", "\n", "", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.iesl_stance.utils.token_lookup.lookup_qry_cnd": [[18, 36], ["zip", "btc_qry_lkup.append", "btc_cnd_lkup.append", "numpy.asarray", "numpy.asarray", "vocab.to_ints", "vocab.to_ints"], "function", ["home.repos.pwc.inspect_result.iesl_stance.objects.Vocab.Vocab.to_ints", "home.repos.pwc.inspect_result.iesl_stance.objects.Vocab.Vocab.to_ints"], ["def", "lookup_qry_cnd", "(", "vocab", ",", "btc_qry_tk", ",", "btc_cnd_tk", ")", ":", "\n", "    ", "'''\n    Returns the list of token indices given list of tokens passed in \n\n    param vocab: vocab object\n    param btc_qry_tk: batch of query tokens \n    param btc_cnd_tk: batch of candidate tokens \n    return: batch of query token indices \n    return: batch of candidate token indices \n    '''", "\n", "btc_qry_lkup", "=", "[", "]", "\n", "btc_cnd_lkup", "=", "[", "]", "\n", "\n", "for", "qry_tk", ",", "cnd_tk", "in", "zip", "(", "btc_qry_tk", ",", "btc_cnd_tk", ")", ":", "\n", "        ", "btc_qry_lkup", ".", "append", "(", "vocab", ".", "to_ints", "(", "qry_tk", ")", ")", "\n", "btc_cnd_lkup", ".", "append", "(", "vocab", ".", "to_ints", "(", "cnd_tk", ")", ")", "\n", "\n", "", "return", "np", ".", "asarray", "(", "btc_qry_lkup", ")", ",", "np", ".", "asarray", "(", "btc_cnd_lkup", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.utils.token_lookup.lookup_qry_pos_neg": [[37, 59], ["zip", "btc_qry_lkup.append", "btc_pos_lkup.append", "btc_neg_lkup.append", "numpy.asarray", "numpy.asarray", "numpy.asarray", "vocab.to_ints", "vocab.to_ints", "vocab.to_ints"], "function", ["home.repos.pwc.inspect_result.iesl_stance.objects.Vocab.Vocab.to_ints", "home.repos.pwc.inspect_result.iesl_stance.objects.Vocab.Vocab.to_ints", "home.repos.pwc.inspect_result.iesl_stance.objects.Vocab.Vocab.to_ints"], ["", "def", "lookup_qry_pos_neg", "(", "vocab", ",", "btc_qry_tk", ",", "btc_pos_tk", ",", "btc_neg_tk", ")", ":", "\n", "    ", "'''\n    Returns the list of token indices given list of tokens passed in \n\n    param vocab: vocab object\n    param btc_qry_tk: batch of query tokens \n    param btc_pos_tk: batch of positive tokens \n    param btc_neg_tk: batch of negative tokens \n    return: batch of query token indices \n    return: batch of positive token indices\n    return: batch of negative token indices  \n    '''", "\n", "btc_qry_lkup", "=", "[", "]", "\n", "btc_pos_lkup", "=", "[", "]", "\n", "btc_neg_lkup", "=", "[", "]", "\n", "\n", "for", "qry_tk", ",", "pos_tk", ",", "neg_tk", "in", "zip", "(", "btc_qry_tk", ",", "btc_pos_tk", ",", "btc_neg_tk", ")", ":", "\n", "        ", "btc_qry_lkup", ".", "append", "(", "vocab", ".", "to_ints", "(", "qry_tk", ")", ")", "\n", "btc_pos_lkup", ".", "append", "(", "vocab", ".", "to_ints", "(", "pos_tk", ")", ")", "\n", "btc_neg_lkup", ".", "append", "(", "vocab", ".", "to_ints", "(", "neg_tk", ")", ")", "\n", "\n", "", "return", "np", ".", "asarray", "(", "btc_qry_lkup", ")", ",", "np", ".", "asarray", "(", "btc_pos_lkup", ")", ",", "np", ".", "asarray", "(", "btc_neg_lkup", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.utils.token_lookup.get_qry_pos_neg_tok_lookup": [[60, 71], ["token_lookup.lookup_qry_pos_neg"], "function", ["home.repos.pwc.inspect_result.iesl_stance.utils.token_lookup.lookup_qry_pos_neg"], ["", "def", "get_qry_pos_neg_tok_lookup", "(", "vocab", ",", "qry_tk", ",", "pos_tk", ",", "neg_tk", ")", ":", "\n", "    ", "'''\n    Returns the list of token indices given list of tokens passed in \n\n    param vocab: vocab object\n    param btc_qry_tk: batch of query tokens \n    param btc_cnd_tk: batch of candidate tokens \n    return: batch of query token indices \n    return: batch of candidate token indices \n    '''", "\n", "return", "lookup_qry_pos_neg", "(", "vocab", ",", "qry_tk", ",", "pos_tk", ",", "neg_tk", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.utils.token_lookup.get_qry_cnd_tok_lookup": [[72, 85], ["token_lookup.lookup_qry_cnd"], "function", ["home.repos.pwc.inspect_result.iesl_stance.utils.token_lookup.lookup_qry_cnd"], ["", "def", "get_qry_cnd_tok_lookup", "(", "vocab", ",", "qry_tk", ",", "cnd_tk", ")", ":", "\n", "    ", "'''\n    Returns the list of token indices given list of tokens passed in \n\n    param vocab: vocab object\n    param btc_qry_tk: batch of query tokens \n    param btc_pos_tk: batch of positive tokens \n    param btc_neg_tk: batch of negative tokens \n    return: batch of query token indices \n    return: batch of positive token indices\n    return: batch of negative token indices  \n    '''", "\n", "return", "lookup_qry_cnd", "(", "vocab", ",", "qry_tk", ",", "cnd_tk", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.iesl_stance.utils.util.__filter_json": [[24, 38], ["the_dict.keys", "type", "type", "type", "type", "type", "util.__filter_json"], "function", ["home.repos.pwc.inspect_result.iesl_stance.utils.util.__filter_json"], ["def", "__filter_json", "(", "the_dict", ")", ":", "\n", "    ", "'''\n    Filters the dictionary so that only the string, floats, ints, and lists are stored \n\n    param the_dict: dictionary to filter \n    return: filtered dictionary \n    '''", "\n", "res", "=", "{", "}", "\n", "for", "k", "in", "the_dict", ".", "keys", "(", ")", ":", "\n", "        ", "if", "type", "(", "the_dict", "[", "k", "]", ")", "is", "str", "or", "type", "(", "the_dict", "[", "k", "]", ")", "is", "float", "or", "type", "(", "the_dict", "[", "k", "]", ")", "is", "int", "or", "type", "(", "the_dict", "[", "k", "]", ")", "is", "list", ":", "\n", "            ", "res", "[", "k", "]", "=", "the_dict", "[", "k", "]", "\n", "", "elif", "type", "(", "the_dict", "[", "k", "]", ")", "is", "dict", ":", "\n", "            ", "res", "[", "k", "]", "=", "__filter_json", "(", "the_dict", "[", "k", "]", ")", "\n", "", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.utils.util.save_dict_to_json": [[39, 49], ["open", "fout.write", "fout.write", "json.dumps", "util.__filter_json"], "function", ["home.repos.pwc.inspect_result.iesl_stance.utils.util.__filter_json"], ["", "def", "save_dict_to_json", "(", "the_dict", ",", "the_file", ")", ":", "\n", "    ", "'''\n    Saves the dictionary to file \n\n    param the_dict: dictionary to save \n    param the_file: file to save dictionary \n    '''", "\n", "with", "open", "(", "the_file", ",", "'a+'", ")", "as", "fout", ":", "\n", "        ", "fout", ".", "write", "(", "json", ".", "dumps", "(", "__filter_json", "(", "the_dict", ")", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.utils.util.make_directory": [[50, 58], ["os.path.exists", "os.makedirs"], "function", ["None"], ["", "", "def", "make_directory", "(", "dir_name", ")", ":", "\n", "    ", "'''\n    Makes directory if it doesn't exist \n\n    param dir_name: directory name \n    '''", "\n", "if", "(", "not", "os", ".", "path", ".", "exists", "(", "dir_name", ")", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dir_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.utils.util.make_exp_dir": [[60, 77], ["datetime.datetime.now", "os.path.join", "util.make_directory"], "function", ["home.repos.pwc.inspect_result.iesl_stance.utils.util.make_directory"], ["", "", "def", "make_exp_dir", "(", "dataset_name", ",", "model_name", ",", "tokenizer_name", ")", ":", "\n", "    ", "'''\n    Makes experiment directory which includes timestamp to ensure distinct \n\n    param dataset_name: name of dataset \n    param model_name: name of model \n    param tokenizer_name: name of tokenizer\n    return: experiment directory name \n    '''", "\n", "now", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "ts", "=", "\"{:04d}-{:02d}-{:02d}-{:02d}-{:02d}-{:02d}\"", ".", "format", "(", "now", ".", "year", ",", "now", ".", "month", ",", "now", ".", "day", ",", "now", ".", "hour", ",", "now", ".", "minute", ",", "\n", "now", ".", "second", ")", "\n", "\n", "exp_dir", "=", "os", ".", "path", ".", "join", "(", "\"exp_out\"", ",", "dataset_name", ",", "model_name", ",", "tokenizer_name", ",", "ts", ")", "\n", "make_directory", "(", "exp_dir", ")", "\n", "\n", "return", "exp_dir", "", "", ""]], "home.repos.pwc.inspect_result.iesl_stance.base_models.EMB.EMB.__init__": [[25, 32], ["super().__init__", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vocab_size", ",", "embedding_dim", ")", ":", "\n", "        ", "'''\n        param  vocab_size: size of vocabulary\n        param embedding_dim: embedding dimension \n        '''", "\n", "super", "(", "EMB", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "num_embeddings", "=", "vocab_size", ",", "embedding_dim", "=", "embedding_dim", ",", "padding_idx", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.base_models.EMB.EMB.forward": [[33, 44], ["torch.autograd.Variable", "torch.autograd.Variable", "EMB.EMB.embedding", "torch.cuda.ByteTensor().float", "torch.cuda.ByteTensor().float", "torch.cuda.ByteTensor().float", "torch.cuda.ByteTensor().float", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cuda.ByteTensor", "torch.cuda.ByteTensor", "torch.cuda.ByteTensor", "torch.cuda.ByteTensor"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "string_lkup", ")", ":", "\n", "        ", "\"\"\"\n        Looks up the embedding for the string lookup integers \n\n        param string_lkup: string lookup integers \n        return:  embeddings for string lookup integers \n        return: mask for embeddings \n        \"\"\"", "\n", "mask", "=", "Variable", "(", "torch", ".", "cuda", ".", "ByteTensor", "(", "(", "string_lkup", ">", "0", ")", ")", ".", "float", "(", ")", ")", "\n", "emb", "=", "self", ".", "embedding", "(", "Variable", "(", "string_lkup", ")", ")", "\n", "return", "emb", ",", "mask", "\n", "", "", ""]], "home.repos.pwc.inspect_result.iesl_stance.base_models.CNN.CNN.__init__": [[27, 63], ["super().__init__", "int", "range", "torch.Parameter", "torch.Parameter", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "numpy.floor", "math.floor", "torch.Conv2d", "torch.Conv2d", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "CNN.CNN.add_module", "CNN.CNN.add_module", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "CNN.CNN.add_module", "CNN.CNN.add_module"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.__init__"], ["    ", "def", "__init__", "(", "self", ",", "is_increasing", ",", "num_layers", ",", "filter_counts", ",", "max_len_token", ")", ":", "\n", "        ", "\"\"\"\n        params is_increasing: whether the filter size is increasing or decreasing \n        params num_layers: number of layers in the CNN\n        params filter_counts: dictionary of filter index to filter size \n        params max_len_token: maximum number of tokens in sentence \n        \"\"\"", "\n", "super", "(", "CNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "decreasing", "=", "0", "\n", "if", "(", "is_increasing", "!=", "True", ")", ":", "\n", "            ", "decreasing", "=", "1", "\n", "", "self", ".", "num_layers", "=", "num_layers", "\n", "\n", "map_conv_layer_to_filter_size", "=", "{", "4", ":", "[", "[", "3", ",", "5", ",", "5", ",", "7", "]", ",", "[", "7", ",", "5", ",", "5", ",", "3", "]", "]", ",", "3", ":", "[", "[", "5", ",", "5", ",", "7", "]", ",", "[", "7", ",", "5", ",", "5", "]", "]", ",", "2", ":", "[", "[", "5", ",", "3", "]", ",", "[", "5", ",", "3", "]", "]", ",", "1", ":", "[", "[", "7", "]", ",", "[", "7", "]", "]", "}", "\n", "pool_output_height", "=", "int", "(", "np", ".", "floor", "(", "max_len_token", "/", "2.0", ")", ")", "\n", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "self", ".", "num_layers", "+", "1", ")", ":", "\n", "            ", "filter_size", "=", "map_conv_layer_to_filter_size", "[", "self", ".", "num_layers", "]", "[", "decreasing", "]", "[", "i", "-", "1", "]", "\n", "padding_size", "=", "math", ".", "floor", "(", "filter_size", "/", "2", ")", "\n", "prev_filter_count", "=", "1", "\n", "if", "(", "i", ">", "1", ")", ":", "\n", "                ", "prev_filter_count", "=", "filter_counts", "[", "i", "-", "2", "]", "\n", "", "convlyr", "=", "nn", ".", "Conv2d", "(", "prev_filter_count", ",", "filter_counts", "[", "i", "-", "1", "]", ",", "filter_size", ",", "padding", "=", "padding_size", ",", "stride", "=", "1", ")", "\n", "if", "(", "i", "==", "1", ")", ":", "\n", "                ", "self", ".", "add_module", "(", "\"cnn_1\"", ",", "convlyr", ")", "\n", "", "elif", "(", "i", "==", "2", ")", ":", "\n", "                ", "self", ".", "add_module", "(", "\"cnn_2\"", ",", "convlyr", ")", "\n", "", "elif", "(", "i", "==", "3", ")", ":", "\n", "                ", "self", ".", "add_module", "(", "\"cnn_3\"", ",", "convlyr", ")", "\n", "", "elif", "(", "i", "==", "4", ")", ":", "\n", "                ", "self", ".", "add_module", "(", "\"cnn_4\"", ",", "convlyr", ")", "\n", "\n", "", "", "self", ".", "align_weights", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "filter_counts", "[", "num_layers", "-", "1", "]", ",", "pool_output_height", ",", "pool_output_height", ")", ".", "cuda", "(", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "pool", "=", "nn", ".", "MaxPool2d", "(", "(", "2", ",", "2", ")", ",", "stride", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.base_models.CNN.CNN.forward": [[64, 93], ["CNN.CNN.cnn_1", "CNN.CNN.pool", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "src_tgt_sim.unsqueeze", "CNN.CNN.relu", "CNN.CNN.cnn_2", "CNN.CNN.relu", "CNN.CNN.cnn_3", "CNN.CNN.relu", "CNN.CNN.cnn_4", "CNN.CNN.align_weights.expand_as"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src_tgt_sim", ")", ":", "\n", "        ", "\"\"\"\n        Runns CNN over input \n\n        :params src_tgt_sim: tensor representing similarity between source and target \n        :return: scores for similarity\n        \"\"\"", "\n", "\n", "# Needs num channels", "\n", "convd", "=", "self", ".", "cnn_1", "(", "src_tgt_sim", ".", "unsqueeze", "(", "1", ")", ")", "\n", "if", "self", ".", "num_layers", ">", "1", ":", "\n", "            ", "convd", "=", "self", ".", "relu", "(", "convd", ")", "\n", "convd", "=", "self", ".", "cnn_2", "(", "convd", ")", "\n", "", "if", "self", ".", "num_layers", ">", "2", ":", "\n", "            ", "convd", "=", "self", ".", "relu", "(", "convd", ")", "\n", "convd", "=", "self", ".", "cnn_3", "(", "convd", ")", "\n", "", "if", "self", ".", "num_layers", ">", "3", ":", "\n", "            ", "convd", "=", "self", ".", "relu", "(", "convd", ")", "\n", "convd", "=", "self", ".", "cnn_4", "(", "convd", ")", "\n", "\n", "", "convd_after_pooling", "=", "self", ".", "pool", "(", "convd", ")", "\n", "\n", "output", "=", "torch", ".", "sum", "(", "self", ".", "align_weights", ".", "expand_as", "(", "convd_after_pooling", ")", "*", "convd_after_pooling", ",", "dim", "=", "3", ",", "keepdim", "=", "True", ")", "\n", "output", "=", "torch", ".", "sum", "(", "output", ",", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "output", "=", "torch", ".", "squeeze", "(", "output", ",", "dim", "=", "3", ")", "\n", "output", "=", "torch", ".", "squeeze", "(", "output", ",", "dim", "=", "2", ")", "\n", "output", "=", "torch", ".", "sum", "(", "output", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.iesl_stance.base_models.LSTM.LSTM.__init__": [[25, 40], ["super().__init__", "torch.LSTM", "torch.LSTM"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.__init__"], ["    ", "def", "__init__", "(", "self", ",", "emb", ",", "embedding_dim", ",", "rnn_hidden_size", ",", "is_bidirectional", ")", ":", "\n", "        ", "'''\n        param emb: embedding layer to use \n        param embedding_dim: embedding dimension \n        param rnn_hidden_size: dimension of rnn hidden unit \n        param is_bidirectional: whether the LSTM is bidirectional or not \n        '''", "\n", "super", "(", "LSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_directions", "=", "1", "\n", "if", "is_bidirectional", ":", "\n", "            ", "self", ".", "num_directions", "=", "2", "\n", "", "self", ".", "rnn_hidden_size", "=", "rnn_hidden_size", "\n", "\n", "self", ".", "EMB", "=", "emb", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "input_size", "=", "embedding_dim", ",", "hidden_size", "=", "rnn_hidden_size", ",", "num_layers", "=", "1", ",", "bidirectional", "=", "is_bidirectional", ",", "batch_first", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.base_models.LSTM.LSTM.forward": [[42, 53], ["LSTM.LSTM.EMB", "LSTM.LSTM.lstm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "str_lkp", ")", ":", "\n", "        ", "\"\"\"\n        Returns the hidden units after running LSTM and EMB over string lookup \n\n        :param str_lkp: batch_size * max_len_token\n        :return emb: batch_size * max_len_token * embedding dim\n        :return mask: batch_size * max_len_token * embedding dim\n        \"\"\"", "\n", "emb", ",", "mask", "=", "self", ".", "EMB", "(", "str_lkp", ")", "\n", "emb", ",", "final_hn_cn", "=", "self", ".", "lstm", "(", "emb", ")", "\n", "return", "emb", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.base_models.LSTM.LSTM.flatten_parameters": [[54, 56], ["LSTM.LSTM.lstm.flatten_parameters"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.flatten_parameters"], ["", "def", "flatten_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "lstm", ".", "flatten_parameters", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.iesl_stance.eval.score_shards.eval_map": [[25, 51], ["numpy.random.seed", "range", "len", "len", "len", "isnan", "sum", "len", "numpy.random.permutation", "sum", "aps.append", "len", "numpy.asarray", "numpy.asarray", "sklearn.metrics.average_precision_score"], "function", ["None"], ["def", "eval_map", "(", "list_of_list_of_labels", ",", "list_of_list_of_scores", ",", "randomize", "=", "True", ")", ":", "\n", "    ", "\"\"\"Compute Mean Average Precision\n    Given a two lists with one element per test example compute the\n    mean average precision score.\n    The i^th element of each list is an array of scores or labels corresponding\n    to the i^th training example.\n    :param list_of_list_of_labels: Binary relevance labels. One list per example.\n    :param list_of_list_of_scores: Predicted relevance scores. One list per example.\n    :return: the mean average precision\n    \"\"\"", "\n", "np", ".", "random", ".", "seed", "(", "19", ")", "\n", "assert", "len", "(", "list_of_list_of_labels", ")", "==", "len", "(", "list_of_list_of_scores", ")", "\n", "aps", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "list_of_list_of_labels", ")", ")", ":", "\n", "        ", "if", "randomize", "==", "True", ":", "\n", "            ", "perm", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "list_of_list_of_labels", "[", "i", "]", ")", ")", "\n", "list_of_list_of_labels", "[", "i", "]", "=", "np", ".", "asarray", "(", "list_of_list_of_labels", "[", "i", "]", ")", "[", "perm", "]", "\n", "list_of_list_of_scores", "[", "i", "]", "=", "np", ".", "asarray", "(", "list_of_list_of_scores", "[", "i", "]", ")", "[", "perm", "]", "\n", "\n", "", "where_are_NaNs", "=", "isnan", "(", "list_of_list_of_scores", "[", "i", "]", ")", "\n", "list_of_list_of_scores", "[", "i", "]", "[", "where_are_NaNs", "]", "=", "-", "999999999999999", "\n", "if", "sum", "(", "list_of_list_of_labels", "[", "i", "]", ")", ">", "0", ":", "\n", "            ", "aps", ".", "append", "(", "average_precision_score", "(", "list_of_list_of_labels", "[", "i", "]", ",", "\n", "list_of_list_of_scores", "[", "i", "]", ")", ")", "\n", "\n", "", "", "return", "sum", "(", "aps", ")", "/", "len", "(", "aps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.score_shards.eval_hits_at_k": [[53, 86], ["numpy.random.seed", "range", "len", "len", "len", "zip", "sorted", "sum", "len", "sum", "aps.append", "min", "sum", "sum"], "function", ["None"], ["", "def", "eval_hits_at_k", "(", "list_of_list_of_labels", ",", "\n", "list_of_list_of_scores", ",", "\n", "k", "=", "10", ",", "\n", "randomize", "=", "True", ",", "\n", "oracle", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Compute Hits at K\n    Given a two lists with one element per test example compute the\n    mean average precision score.\n    The i^th element of each list is an array of scores or labels corresponding\n    to the i^th training example.\n    All scores are SIMILARITIES.\n    :param list_of_list_of_labels: Binary relevance labels. One list per example.\n    :param list_of_list_of_scores: Predicted relevance scores. One list per example.\n    :param k: the number of elements to consider\n    :param randomize: whether to randomize the ordering\n    :param oracle: break ties using the labels\n    :return: the mean average precision\n    \"\"\"", "\n", "np", ".", "random", ".", "seed", "(", "19", ")", "\n", "assert", "len", "(", "list_of_list_of_labels", ")", "==", "len", "(", "list_of_list_of_scores", ")", "\n", "aps", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "list_of_list_of_labels", ")", ")", ":", "\n", "        ", "zpd", "=", "zip", "(", "list_of_list_of_scores", "[", "i", "]", ",", "list_of_list_of_labels", "[", "i", "]", ")", "\n", "sorted_zpd", "=", "sorted", "(", "zpd", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "list_of_list_of_labels", "[", "i", "]", "=", "[", "x", "[", "1", "]", "for", "x", "in", "sorted_zpd", "]", "\n", "list_of_list_of_scores", "[", "i", "]", "=", "[", "x", "[", "0", "]", "for", "x", "in", "sorted_zpd", "]", "\n", "labels_topk", "=", "list_of_list_of_labels", "[", "i", "]", "[", "0", ":", "k", "]", "\n", "if", "sum", "(", "list_of_list_of_labels", "[", "i", "]", ")", ">", "0", ":", "\n", "            ", "hits_at_k", "=", "sum", "(", "labels_topk", ")", "*", "1.0", "/", "min", "(", "k", ",", "sum", "(", "list_of_list_of_labels", "[", "i", "]", ")", ")", "\n", "aps", ".", "append", "(", "hits_at_k", ")", "\n", "\n", "", "", "return", "sum", "(", "aps", ")", "/", "len", "(", "aps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.score_shards.load": [[87, 117], ["result_labels.append", "result_scores.append", "open", "line.strip().split", "int", "float", "current_block_labels.append", "current_block_scores.append", "result_labels.append", "result_scores.append", "line.strip"], "function", ["None"], ["", "def", "load", "(", "filename", ")", ":", "\n", "    ", "\"\"\"Load the labels and scores for Hits at K evaluation.\n    Loads labels and model predictions from files of the format:\n    Query \\t Example \\t Label \\t Score\n    :param filename: Filename to load.\n    :return: list_of_list_of_labels, list_of_list_of_scores\n    \"\"\"", "\n", "result_labels", "=", "[", "]", "\n", "result_scores", "=", "[", "]", "\n", "current_block_name", "=", "\"\"", "\n", "current_block_scores", "=", "[", "]", "\n", "current_block_labels", "=", "[", "]", "\n", "with", "open", "(", "filename", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "for", "line", "in", "fin", ":", "\n", "            ", "splt", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "block_name", "=", "splt", "[", "0", "]", "\n", "block_example", "=", "splt", "[", "1", "]", "\n", "example_label", "=", "int", "(", "splt", "[", "2", "]", ")", "\n", "example_score", "=", "float", "(", "splt", "[", "3", "]", ")", "\n", "if", "block_name", "!=", "current_block_name", "and", "current_block_name", "!=", "\"\"", ":", "\n", "                ", "result_labels", ".", "append", "(", "current_block_labels", ")", "\n", "result_scores", ".", "append", "(", "current_block_scores", ")", "\n", "current_block_labels", "=", "[", "]", "\n", "current_block_scores", "=", "[", "]", "\n", "", "current_block_labels", ".", "append", "(", "example_label", ")", "\n", "current_block_scores", ".", "append", "(", "example_score", ")", "\n", "current_block_name", "=", "block_name", "\n", "", "", "result_labels", ".", "append", "(", "current_block_labels", ")", "\n", "result_scores", ".", "append", "(", "current_block_scores", ")", "\n", "return", "result_labels", ",", "result_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.score_shards.add_shard_file": [[121, 125], ["score_shards.load", "all_list_of_list_of_labels.extend", "all_list_of_list_of_scores.extend"], "function", ["home.repos.pwc.inspect_result.iesl_stance.objects.Vocab.Vocab.load"], ["def", "add_shard_file", "(", "filename", ")", ":", "\n", "    ", "list_of_list_of_labels", ",", "list_of_list_of_scores", "=", "load", "(", "filename", ")", "\n", "all_list_of_list_of_labels", ".", "extend", "(", "list_of_list_of_labels", ")", "\n", "all_list_of_list_of_scores", ".", "extend", "(", "list_of_list_of_scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.score_shards.score": [[126, 142], ["score_shards.eval_map", "score_shards.eval_hits_at_k", "score_shards.eval_hits_at_k", "score_shards.eval_hits_at_k"], "function", ["home.repos.pwc.inspect_result.iesl_stance.eval.EvalMap.eval_map", "home.repos.pwc.inspect_result.iesl_stance.eval.score_shards.eval_hits_at_k", "home.repos.pwc.inspect_result.iesl_stance.eval.score_shards.eval_hits_at_k", "home.repos.pwc.inspect_result.iesl_stance.eval.score_shards.eval_hits_at_k"], ["", "def", "score", "(", ")", ":", "\n", "    ", "\"\"\" Given a file of predictions, compute all metrics\n    \n    :param prediction_filename: TSV file of predictions\n    :param model_name: Name of the model\n    :param dataset_name: Name of the dataset\n    :return: \n    \"\"\"", "\n", "counter", "=", "0", "\n", "scores", "=", "\"\"", "\n", "map_score", "=", "eval_map", "(", "all_list_of_list_of_labels", ",", "all_list_of_list_of_scores", ")", "\n", "scores", "+=", "\"MAP\\t{}\\n\"", ".", "format", "(", "map_score", ")", "\n", "scores", "+=", "\"Hits@1\\t{}\\n\"", ".", "format", "(", "eval_hits_at_k", "(", "all_list_of_list_of_labels", ",", "all_list_of_list_of_scores", ",", "k", "=", "1", ",", "oracle", "=", "False", ")", ")", "\n", "scores", "+=", "\"Hits@10\\t{}\\n\"", ".", "format", "(", "eval_hits_at_k", "(", "all_list_of_list_of_labels", ",", "all_list_of_list_of_scores", ",", "k", "=", "10", ",", "oracle", "=", "False", ")", ")", "\n", "scores", "+=", "\"Hits@50\\t{}\\n\"", ".", "format", "(", "eval_hits_at_k", "(", "all_list_of_list_of_labels", ",", "all_list_of_list_of_scores", ",", "k", "=", "50", ",", "oracle", "=", "False", ")", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.EvalMap.eval_map": [[5, 31], ["numpy.random.seed", "range", "len", "len", "len", "sum", "len", "numpy.random.permutation", "sum", "aps.append", "len", "numpy.asarray", "numpy.asarray", "sklearn.metrics.average_precision_score"], "function", ["None"], ["def", "eval_map", "(", "list_of_list_of_labels", ",", "list_of_list_of_scores", ",", "randomize", "=", "True", ")", ":", "\n", "    ", "\"\"\"Compute Mean Average Precision\n    Given a two lists with one element per test example compute the\n    mean average precision score.\n    The i^th element of each list is an array of scores or labels corresponding\n    to the i^th training example.\n    :param list_of_list_of_labels: Binary relevance labels. One list per example.\n    :param list_of_list_of_scores: Predicted relevance scores. One list per example.\n    :return: the mean average precision\n    \"\"\"", "\n", "np", ".", "random", ".", "seed", "(", "19", ")", "\n", "assert", "len", "(", "list_of_list_of_labels", ")", "==", "len", "(", "list_of_list_of_scores", ")", "\n", "aps", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "list_of_list_of_labels", ")", ")", ":", "\n", "        ", "if", "randomize", "==", "True", ":", "\n", "            ", "perm", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "list_of_list_of_labels", "[", "i", "]", ")", ")", "\n", "list_of_list_of_labels", "[", "i", "]", "=", "np", ".", "asarray", "(", "list_of_list_of_labels", "[", "i", "]", ")", "[", "perm", "]", "\n", "list_of_list_of_scores", "[", "i", "]", "=", "np", ".", "asarray", "(", "list_of_list_of_scores", "[", "i", "]", ")", "[", "perm", "]", "\n", "# print(\"Labels: {}\".format(list_of_list_of_labels[i]))", "\n", "# print(\"Scores: {}\".format(list_of_list_of_scores[i]))", "\n", "# print(\"MAP: {}\".format(average_precision_score(list_of_list_of_labels[i],", "\n", "#                                                list_of_list_of_scores[i])))", "\n", "", "if", "sum", "(", "list_of_list_of_labels", "[", "i", "]", ")", ">", "0", ":", "\n", "            ", "aps", ".", "append", "(", "average_precision_score", "(", "list_of_list_of_labels", "[", "i", "]", ",", "\n", "list_of_list_of_scores", "[", "i", "]", ")", ")", "\n", "", "", "return", "sum", "(", "aps", ")", "/", "len", "(", "aps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.EvalMap.load": [[32, 64], ["result_labels.append", "result_scores.append", "open", "line.strip().split", "int", "float", "current_block_labels.append", "current_block_scores.append", "len", "print", "result_labels.append", "result_scores.append", "line.strip"], "function", ["None"], ["", "def", "load", "(", "filename", ")", ":", "\n", "    ", "\"\"\"Load the labels and scores for MAP evaluation.\n    Loads labels and model predictions from files of the format:\n    Query \\t Example \\t Label \\t Score\n    :param filename: Filename to load.\n    :return: list_of_list_of_labels, list_of_list_of_scores\n    \"\"\"", "\n", "result_labels", "=", "[", "]", "\n", "result_scores", "=", "[", "]", "\n", "current_block_name", "=", "\"\"", "\n", "current_block_scores", "=", "[", "]", "\n", "current_block_labels", "=", "[", "]", "\n", "with", "open", "(", "filename", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "for", "line", "in", "fin", ":", "\n", "            ", "splt", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "if", "len", "(", "splt", ")", "!=", "4", ":", "\n", "                ", "print", "(", "splt", ")", "\n", "", "block_name", "=", "splt", "[", "0", "]", "\n", "block_example", "=", "splt", "[", "1", "]", "\n", "example_label", "=", "int", "(", "splt", "[", "2", "]", ")", "\n", "example_score", "=", "float", "(", "splt", "[", "3", "]", ")", "\n", "if", "block_name", "!=", "current_block_name", "and", "current_block_name", "!=", "\"\"", ":", "\n", "                 ", "result_labels", ".", "append", "(", "current_block_labels", ")", "\n", "result_scores", ".", "append", "(", "current_block_scores", ")", "\n", "current_block_labels", "=", "[", "]", "\n", "current_block_scores", "=", "[", "]", "\n", "", "current_block_labels", ".", "append", "(", "example_label", ")", "\n", "current_block_scores", ".", "append", "(", "example_score", ")", "\n", "current_block_name", "=", "block_name", "\n", "", "", "result_labels", ".", "append", "(", "current_block_labels", ")", "\n", "result_scores", ".", "append", "(", "current_block_scores", ")", "\n", "return", "result_labels", ",", "result_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.EvalMap.eval_map_file": [[65, 68], ["EvalMap.load", "EvalMap.eval_map"], "function", ["home.repos.pwc.inspect_result.iesl_stance.objects.Vocab.Vocab.load", "home.repos.pwc.inspect_result.iesl_stance.eval.EvalMap.eval_map"], ["", "def", "eval_map_file", "(", "filename", ")", ":", "\n", "    ", "list_of_list_of_labels", ",", "list_of_list_of_scores", "=", "load", "(", "filename", ")", "\n", "return", "eval_map", "(", "list_of_list_of_labels", ",", "list_of_list_of_scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.test_model.test_model": [[29, 46], ["main.objects.Evaluator.Evaluator", "torch.load", "torch.load.eval", "main.objects.Evaluator.Evaluator.evaluate", "os.path.join"], "function", ["home.repos.pwc.inspect_result.iesl_stance.objects.Vocab.Vocab.load", "home.repos.pwc.inspect_result.iesl_stance.objects.Evaluator.Evaluator.evaluate"], ["def", "test_model", "(", "config", ",", "vocab", ",", "tokenizer", ",", "exp_dir", ",", "test_label_file", "=", "None", ",", "test_output_file", "=", "None", ")", ":", "\n", "    ", "'''\n    Test the model on test set \n\n    param config: configuration for training \n    param vocab: vocabulary for training\n    param tokenizer: tokenizer to training\n    param exp_dir: experiment directory that contains trained model to evaluate \n    param test_label_file: file with test data (default used will be the one specified in config)\n    param test_output_file: file to write test predictions (default will be the one specified in config )  \n    '''", "\n", "test_evaluator", "=", "Evaluator", "(", "config", ",", "vocab", ",", "tokenizer", ",", "'test'", ",", "exp_dir", ",", "list_k", "=", "[", "1", ",", "10", ",", "50", "]", ",", "labeled_file", "=", "test_label_file", ",", "output_file", "=", "test_output_file", ")", "\n", "model", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_model\"", ")", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "test_evaluator", ".", "evaluate", "(", "model", ",", "train_num_batches", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.shard_test_file.split_test_set": [[23, 44], ["shard_test_file.get_map_query_2_lines", "os.path.join", "os.path.exists", "os.makedirs", "enumerate", "shutil.rmtree", "get_map_query_2_lines.items", "os.path.join", "os.path.split", "int", "open", "str", "f.write"], "function", ["home.repos.pwc.inspect_result.iesl_stance.eval.shard_test_file.get_map_query_2_lines"], ["def", "split_test_set", "(", "filepath", ",", "num_shards", ")", ":", "\n", "    ", "'''\n    Shards the data in file to multiple files, ensuring that all the lines with the same query are grouped together\n\n    param num_shards: number of shards\n    '''", "\n", "map_query_2_lines", "=", "get_map_query_2_lines", "(", "filepath", ")", "\n", "\n", "data_shard_folder", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "split", "(", "filepath", ")", "[", "0", "]", ",", "\"test_shards\"", ")", "\n", "if", "(", "os", ".", "path", ".", "exists", "(", "data_shard_folder", ")", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "data_shard_folder", ")", "\n", "", "os", ".", "makedirs", "(", "data_shard_folder", ")", "\n", "\n", "for", "counter", ",", "(", "query", ",", "list_of_entities", ")", "in", "enumerate", "(", "map_query_2_lines", ".", "items", "(", ")", ")", ":", "\n", "        ", "shard", "=", "counter", "%", "int", "(", "num_shards", ")", "\n", "\n", "shard_filename", "=", "os", ".", "path", ".", "join", "(", "data_shard_folder", ",", "\"shard\"", "+", "\"_\"", "+", "str", "(", "shard", ")", ")", "\n", "\n", "with", "open", "(", "shard_filename", ",", "'a+'", ")", "as", "f", ":", "\n", "            ", "for", "entities", "in", "list_of_entities", ":", "\n", "                ", "f", ".", "write", "(", "'\\t'", ".", "join", "(", "entities", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.shard_test_file.get_map_query_2_lines": [[46, 65], ["open", "file.readlines", "line.strip().split", "map_query_2_lines.keys", "map_query_2_lines[].append", "line.strip"], "function", ["None"], ["", "", "", "", "def", "get_map_query_2_lines", "(", "filepath", ")", ":", "\n", "    ", "'''\n    Gets a dictionary of query to all the lines that include the query\n\n    param filepath: filepath to data file \n    return: dictionary of query to lines \n    '''", "\n", "map_query_2_lines", "=", "{", "}", "\n", "\n", "with", "open", "(", "filepath", ",", "'r'", ")", "as", "file", ":", "\n", "        ", "for", "line", "in", "file", ".", "readlines", "(", ")", ":", "\n", "            ", "entities", "=", "line", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "'\\t'", ")", "\n", "query", "=", "entities", "[", "0", "]", "\n", "if", "query", "in", "map_query_2_lines", ".", "keys", "(", ")", ":", "\n", "                ", "map_query_2_lines", "[", "query", "]", ".", "append", "(", "entities", ")", "\n", "", "else", ":", "\n", "                ", "map_query_2_lines", "[", "query", "]", "=", "[", "entities", "]", "\n", "\n", "", "", "", "return", "map_query_2_lines", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.find_best_grid_search_config.find_best_config": [[22, 54], ["os.getcwd", "print", "print", "os.path.join", "os.path.exists", "os.path.join", "os.path.exists", "str", "open", "f.readlines", "json.loads", "float", "float", "float"], "function", ["None"], ["def", "find_best_config", "(", "experiment_dir", ")", ":", "\n", "    ", "'''\n    Loops through configuration in experiment directory and finds the configuration with the highest dev score \n    '''", "\n", "best_config", "=", "0", "\n", "best_score", "=", "0", "\n", "config_counter", "=", "0", "\n", "cwd", "=", "os", ".", "getcwd", "(", ")", "\n", "\n", "while", "True", ":", "\n", "        ", "config_dir", "=", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"config_\"", "+", "str", "(", "config_counter", ")", ")", "\n", "if", "(", "os", ".", "path", ".", "exists", "(", "config_dir", ")", ")", ":", "\n", "\n", "            ", "dev_scores_json", "=", "os", ".", "path", ".", "join", "(", "config_dir", ",", "\"dev_scores.json\"", ")", "\n", "if", "(", "os", ".", "path", ".", "exists", "(", "dev_scores_json", ")", ")", ":", "\n", "                ", "with", "open", "(", "dev_scores_json", ")", "as", "f", ":", "\n", "\n", "                    ", "all_lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "all_lines", ":", "\n", "                        ", "score_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "score", "=", "score_json", "[", "\"map\"", "]", "\n", "\n", "if", "(", "float", "(", "score", ")", ">", "best_score", ")", ":", "\n", "                            ", "best_score", "=", "float", "(", "score", ")", "\n", "best_config", "=", "float", "(", "config_counter", ")", "\n", "", "", "", "", "", "else", ":", "\n", "            ", "break", "\n", "\n", "", "config_counter", "+=", "1", "\n", "\n", "", "print", "(", "\"Best Config: \"", ",", "best_config", ")", "\n", "print", "(", "\"Best Score: \"", ",", "best_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.heatmap.load_data": [[25, 46], ["numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "open", "f.readlines", "line.strip().split", "np.asarray.append", "np.asarray.append", "np.asarray.append", "np.asarray.append", "tokenizer.tokenize", "len", "tokenizer.tokenize", "len", "line.strip", "tokenizer.tokenize", "tokenizer.tokenize"], "function", ["home.repos.pwc.inspect_result.iesl_stance.objects.Tokenizer.Char.tokenize", "home.repos.pwc.inspect_result.iesl_stance.objects.Tokenizer.Char.tokenize", "home.repos.pwc.inspect_result.iesl_stance.objects.Tokenizer.Char.tokenize", "home.repos.pwc.inspect_result.iesl_stance.objects.Tokenizer.Char.tokenize"], ["def", "load_data", "(", "input_file", ",", "vocab", ",", "config", ",", "tokenizer", ",", "max_len_token", ")", ":", "\n", "    ", "with", "open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "qry_tk", "=", "[", "]", "\n", "qry_len", "=", "[", "]", "\n", "cnd_tk", "=", "[", "]", "\n", "cnd_len", "=", "[", "]", "\n", "\n", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "split", "=", "line", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "\n", "qry_tk", ".", "append", "(", "tokenizer", ".", "tokenize", "(", "split", "[", "0", "]", ")", ")", "\n", "qry_len", ".", "append", "(", "len", "(", "tokenizer", ".", "tokenize", "(", "split", "[", "0", "]", ")", ")", ")", "\n", "cnd_tk", ".", "append", "(", "tokenizer", ".", "tokenize", "(", "split", "[", "1", "]", ")", ")", "\n", "cnd_len", ".", "append", "(", "len", "(", "(", "tokenizer", ".", "tokenize", "(", "split", "[", "1", "]", ")", ")", ")", ")", "\n", "\n", "", "", "qry_tk", "=", "np", ".", "asarray", "(", "qry_tk", ")", "\n", "qry_len", "=", "np", ".", "asarray", "(", "qry_len", ")", "\n", "cnd_tk", "=", "np", ".", "asarray", "(", "cnd_tk", ")", "\n", "cnd_len", "=", "np", ".", "asarray", "(", "cnd_len", ")", "\n", "\n", "return", "qry_tk", ",", "cnd_tk", ",", "qry_len", ",", "cnd_len", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.heatmap.print_stance_mm": [[47, 73], ["torch.load", "main.utils.token_lookup.get_qry_cnd_tok_lookup", "torch.load.LSTM", "torch.load.LSTM", "torch.bmm", "torch.bmm", "main.objects.Sinkhorn.batch_sinkhorn_loss", "torch.mul", "torch.mul", "os.path.join", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.transpose", "qry_mask.unsqueeze", "cnd_mask.unsqueeze", "torch.cuda.FloatTensor().fill_", "torch.from_numpy", "torch.from_numpy", "torch.max", "torch.cuda.FloatTensor", "torch.bmm.size"], "function", ["home.repos.pwc.inspect_result.iesl_stance.objects.Vocab.Vocab.load", "home.repos.pwc.inspect_result.iesl_stance.utils.token_lookup.get_qry_cnd_tok_lookup", "home.repos.pwc.inspect_result.iesl_stance.objects.Sinkhorn.batch_sinkhorn_loss"], ["", "def", "print_stance_mm", "(", "exp_dir", ",", "qry_tk", ",", "cnd_tk", ")", ":", "\n", "    ", "\"\"\" Prints the matrix multiplication of the two embeddings.\n    This function is useful for creating a heatmap for figures.\n    :param src: Entity mentions\n    :param tgt: Entity mentions\n    :param src_len: lengths of src mentions\n    :param neg_len: lengths of tgt mentions\n    :return:\n    \"\"\"", "\n", "model", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_model\"", ")", ")", "\n", "\n", "qry_lkup", ",", "cnd_lkup", "=", "get_qry_cnd_tok_lookup", "(", "vocab", ",", "qry_tk", ",", "cnd_tk", ")", "\n", "\n", "qry_emb", ",", "qry_mask", "=", "model", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "qry_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "cnd_emb", ",", "cnd_mask", "=", "model", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "cnd_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "sim", "=", "torch", ".", "bmm", "(", "qry_emb", ",", "torch", ".", "transpose", "(", "cnd_emb", ",", "2", ",", "1", ")", ")", "\n", "dist", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "sim", ".", "size", "(", ")", ")", ".", "fill_", "(", "torch", ".", "max", "(", "sim", ")", ")", "-", "sim", "+", "1e-6", "\n", "\n", "mat_mask", "=", "torch", ".", "bmm", "(", "qry_mask", ".", "unsqueeze", "(", "2", ")", ",", "cnd_mask", ".", "unsqueeze", "(", "1", ")", ")", "\n", "pi", "=", "batch_sinkhorn_loss", "(", "dist", ",", "mat_mask", ")", "\n", "\n", "stance_multpld", "=", "torch", ".", "mul", "(", "sim", ",", "pi", ")", "\n", "stance_multpld", "=", "torch", ".", "mul", "(", "stance_multpld", ",", "mat_mask", ")", "\n", "\n", "return", "sim", ",", "dist", ",", "pi", ",", "stance_multpld", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.heatmap.print_dtw_mm": [[74, 102], ["torch.load", "main.utils.token_lookup.get_qry_cnd_tok_lookup", "torch.load.LSTM", "torch.load.LSTM", "torch.bmm", "torch.ones", "range", "os.path.join", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.transpose", "dist.size", "sdtw.SoftDTW", "sdtw.SoftDTW.compute", "torch.from_numpy", "torch.cuda.FloatTensor().fill_", "dist[].cpu().detach().numpy", "sdtw.SoftDTW.grad", "torch.from_numpy", "torch.from_numpy", "torch.max", "torch.cuda.FloatTensor", "dist[].cpu().detach", "torch.bmm.size", "dist[].cpu"], "function", ["home.repos.pwc.inspect_result.iesl_stance.objects.Vocab.Vocab.load", "home.repos.pwc.inspect_result.iesl_stance.utils.token_lookup.get_qry_cnd_tok_lookup"], ["", "def", "print_dtw_mm", "(", "exp_dir", ",", "qry_tk", ",", "cnd_tk", ")", ":", "\n", "    ", "\"\"\" Prints the matrix multiplication of the two embeddings.\n    This function is useful for creating a heatmap for figures.\n    :param src: Entity mentions\n    :param tgt: Entity mentions\n    :param src_len: lengths of src mentions\n    :param neg_len: lengths of tgt mentions\n    :return:\n    \"\"\"", "\n", "model", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_model\"", ")", ")", "\n", "\n", "qry_lkup", ",", "cnd_lkup", "=", "get_qry_cnd_tok_lookup", "(", "vocab", ",", "qry_tk", ",", "cnd_tk", ")", "\n", "\n", "qry_emb", ",", "qry_mask", "=", "model", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "qry_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "cnd_emb", ",", "cnd_mask", "=", "model", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "cnd_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "sim", "=", "torch", ".", "bmm", "(", "qry_emb", ",", "torch", ".", "transpose", "(", "cnd_emb", ",", "2", ",", "1", ")", ")", "\n", "dist", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "sim", ".", "size", "(", ")", ")", ".", "fill_", "(", "torch", ".", "max", "(", "sim", ")", ")", "-", "sim", "+", "1e-6", "\n", "\n", "dtw_mat", "=", "torch", ".", "ones", "(", "dist", ".", "size", "(", ")", ")", "\n", "batch_size", "=", "dist", ".", "shape", "[", "0", "]", "\n", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "sdtw", "=", "SoftDTW", "(", "dist", "[", "i", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", ".5", ")", "\n", "value", "=", "sdtw", ".", "compute", "(", ")", "\n", "dtw_mat", "[", "i", "]", "=", "torch", ".", "from_numpy", "(", "sdtw", ".", "grad", "(", ")", ")", "\n", "\n", "", "return", "dtw_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.read_test_file": [[7, 39], ["collections.defaultdict", "open", "line.strip().split", "int", "float", "float", "int", "line.strip"], "function", ["None"], ["def", "read_test_file", "(", "test_file", ",", "is_dcm", "=", "False", ")", ":", "\n", "    ", "'''\n    Reads the test file shard and returns dictionary mapping query to list of [candiate, label, prediction]\n\n    Args:\n        test_file: test_file containing predictions\n\n    Returns:\n        dictionary mapping to query to list of [candiate, label, prediction]\n    '''", "\n", "\n", "# Different paths for Deep Conflation Models and everything else ", "\n", "\n", "dict_qry_2_cnd", "=", "defaultdict", "(", "dict", ")", "\n", "\n", "with", "open", "(", "test_file", ")", "as", "f_in", ":", "\n", "        ", "for", "line", "in", "f_in", ":", "\n", "            ", "tab_split_line", "=", "line", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "'\\t'", ")", "\n", "qry", "=", "tab_split_line", "[", "0", "]", "\n", "cnd", "=", "tab_split_line", "[", "1", "]", "\n", "if", "is_dcm", "==", "False", ":", "\n", "                ", "lbl", "=", "int", "(", "tab_split_line", "[", "2", "]", ")", "\n", "pred", "=", "float", "(", "tab_split_line", "[", "3", "]", ")", "\n", "", "else", ":", "\n", "                ", "pred", "=", "float", "(", "tab_split_line", "[", "2", "]", ")", "\n", "lbl", "=", "int", "(", "2", ")", "\n", "", "lbl_pred", "=", "[", "lbl", ",", "pred", "]", "\n", "\n", "dict_qry_2_cnd", "[", "qry", "]", "[", "cnd", "]", "=", "lbl_pred", "\n", "\n", "\n", "", "", "return", "dict_qry_2_cnd", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.form_line": [[40, 52], ["map", "str"], "function", ["None"], ["", "def", "form_line", "(", "tab_split_list", ")", ":", "\n", "    ", "'''\n    Forms line from tab split list \n\n    Args:\n        tab_split_list: tab split list of strings \n\n    Returns:\n        string of tab split list joined by tab \n    '''", "\n", "str_tab_split_list", "=", "map", "(", "lambda", "x", ":", "str", "(", "x", ")", ",", "tab_split_list", ")", "\n", "return", "'\\t'", ".", "join", "(", "str_tab_split_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.compare_two_dictionary_queries": [[53, 102], ["dict_one_qry_2_cnd.keys", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "zip", "len", "len", "len", "len", "sorted", "sorted", "sorted", "collections.OrderedDict.items", "collections.OrderedDict.items", "collections.OrderedDict.items", "collections.OrderedDict.items", "collections.OrderedDict.items", "collections.OrderedDict.items", "int", "print", "print", "print", "print", "int", "int", "get_examples.form_line", "get_examples.form_line", "get_examples.form_line", "get_examples.form_line"], "function", ["home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.form_line", "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.form_line", "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.form_line", "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.form_line"], ["", "def", "compare_two_dictionary_queries", "(", "dict_one_qry_2_cnd", ",", "dict_two_qry_2_cnd", ",", "dict_three_qry_2_cnd", ")", ":", "\n", "    ", "'''\n    Finds candidates which model one performs better than model 2\n\n    Args:\n        dict_one_qry_2_cnd: dictionary of query to list of dictionaries of candidates to [label, pred]\n        dict_two_qry_2_cnd: dictionary of query to list of dictionaries of candidates to [label, pred]\n    '''", "\n", "\n", "for", "qry", "in", "dict_one_qry_2_cnd", ".", "keys", "(", ")", ":", "\n", "        ", "cnd_lbl_pred_one", "=", "dict_one_qry_2_cnd", "[", "qry", "]", "\n", "cnd_lbl_pred_two", "=", "dict_two_qry_2_cnd", "[", "qry", "]", "\n", "\n", "cnd_lbl_pred_three", "=", "dict_three_qry_2_cnd", "[", "qry", "]", "\n", "\n", "assert", "(", "len", "(", "cnd_lbl_pred_one", ")", "==", "len", "(", "cnd_lbl_pred_two", ")", ")", "\n", "assert", "(", "len", "(", "cnd_lbl_pred_one", ")", "==", "len", "(", "cnd_lbl_pred_three", ")", ")", "\n", "\n", "\n", "# Sort according to prediction score which is in index 0 of value ", "\n", "cnd_lbl_pred_one", "=", "collections", ".", "OrderedDict", "(", "sorted", "(", "cnd_lbl_pred_one", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", "[", "1", "]", ",", "reverse", "=", "True", ")", ")", "\n", "cnd_lbl_pred_two", "=", "collections", ".", "OrderedDict", "(", "sorted", "(", "cnd_lbl_pred_two", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", "[", "1", "]", ",", "reverse", "=", "True", ")", ")", "\n", "cnd_lbl_pred_three", "=", "collections", ".", "OrderedDict", "(", "sorted", "(", "cnd_lbl_pred_three", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", "[", "1", "]", ",", "reverse", "=", "True", ")", ")", "\n", "\n", "counter", "=", "0", "\n", "print_qry", "=", "False", "\n", "\n", "for", "(", "[", "cnd_one", ",", "[", "lbl_one", ",", "pred_one", "]", "]", ",", "[", "cnd_two", ",", "[", "lbl_two", ",", "pred_two", "]", "]", ",", "[", "cnd_three", ",", "[", "lbl_three", ",", "pred_three", "]", "]", ")", "in", "zip", "(", "cnd_lbl_pred_one", ".", "items", "(", ")", ",", "cnd_lbl_pred_two", ".", "items", "(", ")", ",", "cnd_lbl_pred_three", ".", "items", "(", ")", ")", ":", "\n", "\n", "            ", "lbl_two", "=", "cnd_lbl_pred_one", "[", "cnd_two", "]", "[", "0", "]", "\n", "lbl_three", "=", "cnd_lbl_pred_three", "[", "cnd_two", "]", "[", "0", "]", "\n", "\n", "# Consider only candidates which model 1 got correct (and candidates ranked higher must also be correct)", "\n", "if", "int", "(", "lbl_one", ")", "==", "1", ":", "\n", "# Try to find candidates which model 2 got wrong ", "\n", "                ", "if", "int", "(", "lbl_two", ")", "==", "0", "or", "int", "(", "lbl_three", ")", "==", "0", ":", "\n", "                    ", "print_qry", "=", "True", "\n", "\n", "print", "(", "form_line", "(", "[", "qry", ",", "cnd_one", ",", "lbl_one", ",", "pred_one", "]", ")", ")", "\n", "[", "model_one_cnd_two_lbl", ",", "model_one_cnd_two_pred", "]", "=", "cnd_lbl_pred_one", "[", "cnd_two", "]", "\n", "print", "(", "form_line", "(", "[", "qry", ",", "cnd_two", ",", "lbl_two", ",", "model_one_cnd_two_pred", "]", ")", ")", "\n", "\n", "print", "(", "form_line", "(", "[", "qry", ",", "cnd_two", ",", "lbl_two", ",", "pred_two", "]", ")", ")", "\n", "[", "model_two_cnd_one_lbl", ",", "model_two_cnd_one_pred", "]", "=", "cnd_lbl_pred_two", "[", "cnd_one", "]", "\n", "print", "(", "form_line", "(", "[", "qry", ",", "cnd_one", ",", "model_two_cnd_one_lbl", ",", "model_two_cnd_one_pred", "]", ")", ")", "\n", "\n", "", "", "else", ":", "\n", "                ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.compare_three_dictionary_queries": [[103, 162], ["dict_one_qry_2_cnd.keys", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "zip", "len", "len", "len", "len", "sorted", "sorted", "sorted", "collections.OrderedDict.items", "collections.OrderedDict.items", "collections.OrderedDict.items", "collections.OrderedDict.items", "collections.OrderedDict.items", "collections.OrderedDict.items", "int", "int", "print", "print", "print", "print", "print", "print", "print", "print", "get_examples.form_line", "get_examples.form_line", "get_examples.form_line", "print", "print", "print", "print", "get_examples.form_line", "get_examples.form_line", "get_examples.form_line", "get_examples.form_line", "get_examples.form_line", "get_examples.form_line"], "function", ["home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.form_line", "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.form_line", "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.form_line", "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.form_line", "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.form_line", "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.form_line", "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.form_line", "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.form_line", "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.form_line"], ["", "", "", "", "def", "compare_three_dictionary_queries", "(", "dict_one_qry_2_cnd", ",", "dict_two_qry_2_cnd", ",", "dict_three_qry_2_cnd", ")", ":", "\n", "    ", "'''\n    Finds candidates which model one performs better than model 2\n\n    Args:\n        dict_one_qry_2_cnd: dictionary of query to list of dictionaries of candidates to [label, pred]\n        dict_two_qry_2_cnd: dictionary of query to list of dictionaries of candidates to [label, pred]\n    '''", "\n", "\n", "for", "qry", "in", "dict_one_qry_2_cnd", ".", "keys", "(", ")", ":", "\n", "        ", "cnd_lbl_pred_one", "=", "dict_one_qry_2_cnd", "[", "qry", "]", "\n", "cnd_lbl_pred_two", "=", "dict_two_qry_2_cnd", "[", "qry", "]", "\n", "cnd_lbl_pred_three", "=", "dict_three_qry_2_cnd", "[", "qry", "]", "\n", "\n", "assert", "(", "len", "(", "cnd_lbl_pred_one", ")", "==", "len", "(", "cnd_lbl_pred_two", ")", ")", "\n", "assert", "(", "len", "(", "cnd_lbl_pred_one", ")", "==", "len", "(", "cnd_lbl_pred_three", ")", ")", "\n", "\n", "\n", "# Sort according to prediction score which is in index 0 of value ", "\n", "cnd_lbl_pred_one", "=", "collections", ".", "OrderedDict", "(", "sorted", "(", "cnd_lbl_pred_one", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", "[", "1", "]", ",", "reverse", "=", "True", ")", ")", "\n", "cnd_lbl_pred_two", "=", "collections", ".", "OrderedDict", "(", "sorted", "(", "cnd_lbl_pred_two", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", "[", "1", "]", ",", "reverse", "=", "True", ")", ")", "\n", "cnd_lbl_pred_three", "=", "collections", ".", "OrderedDict", "(", "sorted", "(", "cnd_lbl_pred_three", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", "[", "1", "]", ",", "reverse", "=", "True", ")", ")", "\n", "\n", "counter", "=", "0", "\n", "print_qry", "=", "False", "\n", "\n", "for", "(", "[", "cnd_one", ",", "[", "lbl_one", ",", "pred_one", "]", "]", ",", "[", "cnd_two", ",", "[", "lbl_two", ",", "pred_two", "]", "]", ",", "[", "cnd_three", ",", "[", "lbl_three", ",", "pred_three", "]", "]", ")", "in", "zip", "(", "cnd_lbl_pred_one", ".", "items", "(", ")", ",", "cnd_lbl_pred_two", ".", "items", "(", ")", ",", "cnd_lbl_pred_three", ".", "items", "(", ")", ")", ":", "\n", "\n", "            ", "lbl_two", "=", "cnd_lbl_pred_one", "[", "cnd_two", "]", "[", "0", "]", "\n", "lbl_three", "=", "cnd_lbl_pred_three", "[", "cnd_two", "]", "[", "0", "]", "\n", "\n", "# Consider only candidates which model 1 got correct (and candidates ranked higher must also be correct)", "\n", "if", "int", "(", "lbl_one", ")", "==", "1", ":", "\n", "# Try to find candidates which model 2 got wrong ", "\n", "                ", "if", "int", "(", "lbl_two", ")", "==", "0", ":", "\n", "                    ", "print_qry", "=", "True", "\n", "print", "(", "\"Rank: \"", ",", "counter", ")", "\n", "print", "(", "\"STANCE: \"", ",", "form_line", "(", "[", "qry", ",", "cnd_one", ",", "lbl_one", ",", "pred_one", "]", ")", ")", "\n", "print", "(", "\"LDTW: \"", ",", "form_line", "(", "[", "qry", ",", "cnd_two", ",", "lbl_two", ",", "pred_two", "]", ")", ")", "\n", "print", "(", "\"DCM: \"", ",", "form_line", "(", "[", "qry", ",", "cnd_three", ",", "lbl_three", ",", "pred_three", "]", ")", ")", "\n", "counter", "+=", "1", "\n", "\n", "", "elif", "print_qry", "==", "True", "and", "counter", "<", "5", ":", "\n", "                    ", "print", "(", "\"Rank: \"", ",", "counter", ")", "\n", "print", "(", "\"STANCE: \"", ",", "form_line", "(", "[", "qry", ",", "cnd_one", ",", "lbl_one", ",", "pred_one", "]", ")", ")", "\n", "print", "(", "\"LDTW: \"", ",", "form_line", "(", "[", "qry", ",", "cnd_two", ",", "lbl_two", ",", "pred_two", "]", ")", ")", "\n", "print", "(", "\"DCM: \"", ",", "form_line", "(", "[", "qry", ",", "cnd_three", ",", "lbl_three", ",", "pred_three", "]", ")", ")", "\n", "counter", "+=", "1", "\n", "\n", "", "", "elif", "print_qry", "==", "True", "and", "counter", "<", "5", ":", "\n", "                ", "print", "(", "\"Rank: \"", ",", "counter", ")", "\n", "print", "(", "\"STANCE: \"", ",", "form_line", "(", "[", "qry", ",", "cnd_one", ",", "lbl_one", ",", "pred_one", "]", ")", ")", "\n", "print", "(", "\"LDTW: \"", ",", "form_line", "(", "[", "qry", ",", "cnd_two", ",", "lbl_two", ",", "pred_two", "]", ")", ")", "\n", "print", "(", "\"DCM: \"", ",", "form_line", "(", "[", "qry", ",", "cnd_three", ",", "lbl_three", ",", "pred_three", "]", ")", ")", "\n", "counter", "+=", "1", "\n", "\n", "", "else", ":", "\n", "                ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.get_correct_queries": [[163, 184], ["dict_one_qry_2_cnd.keys", "collections.OrderedDict", "collections.OrderedDict.items", "sorted", "collections.OrderedDict.items", "int", "print", "get_examples.form_line"], "function", ["home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.form_line"], ["", "", "", "", "def", "get_correct_queries", "(", "dict_one_qry_2_cnd", ")", ":", "\n", "    ", "'''\n    Finds candidates which model one performs better than model 2\n\n    Args:\n        dict_one_qry_2_cnd: dictionary of query to list of dictionaries of candidates to [label, pred]\n    '''", "\n", "for", "qry", "in", "dict_one_qry_2_cnd", ".", "keys", "(", ")", ":", "\n", "        ", "cnd_lbl_pred_one", "=", "dict_one_qry_2_cnd", "[", "qry", "]", "\n", "\n", "# Sort according to prediction score which is in index 0 of value ", "\n", "cnd_lbl_pred_one", "=", "collections", ".", "OrderedDict", "(", "sorted", "(", "cnd_lbl_pred_one", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", "[", "1", "]", ",", "reverse", "=", "True", ")", ")", "\n", "\n", "for", "[", "cnd_one", ",", "[", "lbl_one", ",", "pred_one", "]", "]", "in", "cnd_lbl_pred_one", ".", "items", "(", ")", ":", "\n", "# Consider only candidates which model 1 got correct (and candidates ranked higher must also be correct)", "\n", "            ", "if", "int", "(", "lbl_one", ")", "==", "1", ":", "\n", "# Try to find candidates which model 2 got wrong ", "\n", "                ", "print", "(", "form_line", "(", "[", "qry", ",", "cnd_one", ",", "lbl_one", ",", "pred_one", "]", ")", ")", "\n", "break", "\n", "", "else", ":", "\n", "                ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.model_get_correct": [[185, 199], ["range", "get_examples.get_correct_queries", "os.path.join", "get_examples.read_test_file"], "function", ["home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.get_correct_queries", "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.read_test_file"], ["", "", "", "", "def", "model_get_correct", "(", "exp_dir_one", ")", ":", "\n", "    ", "'''\n    Gets the queries which the model gets correct (i.e. the highest ranked candidate is a true positive)\n\n    Args:\n        exp_dir_one: directory of model (assumes that test predictions are already scored)\n    '''", "\n", "dict_one_qry_2_cnd", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "        ", "test_shard_pred_file", "=", "os", ".", "path", ".", "join", "(", "exp_dir_one", ",", "'test_shards_pred'", ",", "'shard_%d.pred'", "%", "i", ")", "\n", "shard_dict_one_qry_2_cnd", "=", "read_test_file", "(", "test_shard_pred_file", ")", "\n", "dict_one_qry_2_cnd", "=", "{", "**", "dict_one_qry_2_cnd", ",", "**", "shard_dict_one_qry_2_cnd", "}", "\n", "\n", "", "get_correct_queries", "(", "dict_one_qry_2_cnd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.compare_models": [[200, 231], ["range", "range", "compare_dictionary_queries", "os.path.join", "get_examples.read_test_file", "get_examples.read_test_file", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.read_test_file", "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.read_test_file"], ["", "def", "compare_models", "(", "exp_dir_one", ",", "exp_dir_two", ")", ":", "\n", "    ", "'''\n    Compares two models and determines which model_one got correct that model_two got wrong \n    where correct is defined as highest ranked canddiate is a true positive \n\n    Args:\n        exp_dir_one: directory of model (assumes that test predictions are already scored)\n        exp_dir_two: directory of model (assumes that test predictions are already scored)\n    '''", "\n", "dict_one_qry_2_cnd", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "        ", "test_shard_pred_file", "=", "os", ".", "path", ".", "join", "(", "exp_dir_one", ",", "'test_shards_pred'", ",", "'shard_%d.pred'", "%", "i", ")", "\n", "\n", "shard_dict_one_qry_2_cnd", "=", "read_test_file", "(", "test_shard_pred_file", ")", "\n", "dict_one_qry_2_cnd", "=", "{", "**", "dict_one_qry_2_cnd", ",", "**", "shard_dict_one_qry_2_cnd", "}", "\n", "\n", "", "exp_dir_two_num_shards", "=", "10", "\n", "if", "\"Deep_Conflation_Model\"", "in", "exp_dir_two", ":", "\n", "        ", "exp_dir_two_num_shards", "=", "5", "\n", "\n", "", "dict_two_qry_2_cnd", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "exp_dir_two_num_shards", ")", ":", "\n", "        ", "if", "'Deep_Conflation_Model'", "in", "exp_dir", ":", "\n", "            ", "test_shard_pred_file", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "'test_predictions'", ",", "'prediction_%d'", "%", "i", ")", "\n", "", "else", ":", "\n", "            ", "test_shard_pred_file", "=", "os", ".", "path", ".", "join", "(", "exp_dir_one", ",", "'test_shards_pred'", ",", "'shard_%d.pred'", "%", "i", ")", "\n", "\n", "", "shard_dict_two_qry_2_cnd", "=", "read_test_file", "(", "test_shard_pred_file", ")", "\n", "dict_two_qry_2_cnd", "=", "{", "**", "dict_two_qry_2_cnd", ",", "**", "shard_dict_two_qry_2_cnd", "}", "\n", "\n", "", "compare_dictionary_queries", "(", "dict_one_qry_2_cnd", ",", "dict_two_qry_2_cnd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.compare_three_models": [[232, 263], ["range", "range", "range", "get_examples.compare_three_dictionary_queries", "os.path.join", "get_examples.read_test_file", "os.path.join", "get_examples.read_test_file", "os.path.join", "get_examples.read_test_file"], "function", ["home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.compare_three_dictionary_queries", "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.read_test_file", "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.read_test_file", "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.read_test_file"], ["", "def", "compare_three_models", "(", "exp_dir_one", ",", "exp_dir_two", ",", "exp_dir_three", ")", ":", "\n", "    ", "'''\n    Compares two models and determines which model_one got correct that model_two got wrong \n    where correct is defined as highest ranked canddiate is a true positive \n\n    Args:\n        exp_dir_one: directory of model (assumes that test predictions are already scored)\n        exp_dir_two: directory of model (assumes that test predictions are already scored)\n    '''", "\n", "dict_one_qry_2_cnd", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "        ", "test_shard_pred_file", "=", "os", ".", "path", ".", "join", "(", "exp_dir_one", ",", "'test_shards_pred'", ",", "'shard_%d.pred'", "%", "i", ")", "\n", "\n", "shard_dict_one_qry_2_cnd", "=", "read_test_file", "(", "test_shard_pred_file", ")", "\n", "dict_one_qry_2_cnd", "=", "{", "**", "dict_one_qry_2_cnd", ",", "**", "shard_dict_one_qry_2_cnd", "}", "\n", "\n", "", "dict_two_qry_2_cnd", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "        ", "test_shard_pred_file", "=", "os", ".", "path", ".", "join", "(", "exp_dir_two", ",", "'test_shards_pred'", ",", "'shard_%d.pred'", "%", "i", ")", "\n", "\n", "shard_dict_two_qry_2_cnd", "=", "read_test_file", "(", "test_shard_pred_file", ")", "\n", "dict_two_qry_2_cnd", "=", "{", "**", "dict_two_qry_2_cnd", ",", "**", "shard_dict_two_qry_2_cnd", "}", "\n", "\n", "", "dict_three_qry_2_cnd", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "7", ")", ":", "\n", "        ", "test_shard_pred_file", "=", "os", ".", "path", ".", "join", "(", "exp_dir_three", ",", "'test_predictions'", ",", "'prediction_%d'", "%", "i", ")", "\n", "\n", "shard_dict_three_qry_2_cnd", "=", "read_test_file", "(", "test_shard_pred_file", ",", "is_dcm", "=", "True", ")", "\n", "dict_three_qry_2_cnd", "=", "{", "**", "dict_three_qry_2_cnd", ",", "**", "shard_dict_three_qry_2_cnd", "}", "\n", "\n", "", "compare_three_dictionary_queries", "(", "dict_one_qry_2_cnd", ",", "dict_two_qry_2_cnd", ",", "dict_three_qry_2_cnd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.sort_queries": [[264, 279], ["get_examples.read_test_file", "read_test_file.keys", "collections.OrderedDict", "collections.OrderedDict.items", "sorted", "print", "collections.OrderedDict.items", "get_examples.form_line"], "function", ["home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.read_test_file", "home.repos.pwc.inspect_result.iesl_stance.eval.get_examples.form_line"], ["", "def", "sort_queries", "(", "output_file", ")", ":", "\n", "    ", "'''\n    Sorts the lines according to predicted score per query in output_file\n\n    '''", "\n", "dict_qry_2_cnd", "=", "read_test_file", "(", "output_file", ")", "\n", "\n", "for", "qry", "in", "dict_qry_2_cnd", ".", "keys", "(", ")", ":", "\n", "        ", "cnd_lbl_pred", "=", "dict_qry_2_cnd", "[", "qry", "]", "\n", "\n", "# Sort according to prediction score which is in index 0 of value ", "\n", "cnd_lbl_pred", "=", "collections", ".", "OrderedDict", "(", "sorted", "(", "cnd_lbl_pred", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", "[", "1", "]", ",", "reverse", "=", "True", ")", ")", "\n", "\n", "for", "(", "candidate", ",", "[", "label", ",", "pred", "]", ")", "in", "cnd_lbl_pred", ".", "items", "(", ")", ":", "\n", "            ", "print", "(", "form_line", "(", "[", "qry", ",", "candidate", ",", "label", ",", "pred", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.AlignDot.AlignDot.__init__": [[32, 51], ["super().__init__", "main.base_models.EMB.EMB", "main.base_models.LSTM.LSTM", "torch.autograd.Variable", "torch.autograd.Variable", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "vocab", ",", "max_len_token", ")", ":", "\n", "        ", "\"\"\"\n        param config: config object\n        param vocab: vocab object\n        param max_len_token: max number of tokens \n        \"\"\"", "\n", "super", "(", "AlignDot", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "max_len_token", "=", "max_len_token", "\n", "\n", "self", ".", "need_flatten", "=", "True", "\n", "\n", "self", ".", "EMB", "=", "EMB", "(", "vocab", ".", "size", "+", "1", ",", "config", ".", "embedding_dim", ")", "\n", "self", ".", "LSTM", "=", "LSTM", "(", "self", ".", "EMB", ",", "config", ".", "embedding_dim", ",", "config", ".", "rnn_hidden_dim", ",", "config", ".", "bidirectional", ")", "\n", "\n", "# Vector of ones (used for loss)", "\n", "self", ".", "ones", "=", "Variable", "(", "torch", ".", "ones", "(", "config", ".", "train_batch_size", ",", "1", ")", ")", "\n", "self", ".", "loss", "=", "BCEWithLogitsLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.AlignDot.AlignDot.compute_loss": [[52, 83], ["main.utils.token_lookup.get_qry_pos_neg_tok_lookup", "AlignDot.AlignDot.LSTM", "AlignDot.AlignDot.LSTM", "AlignDot.AlignDot.LSTM", "torch.sum().view().unsqueeze().repeat().long", "torch.sum().view().unsqueeze().repeat().long", "torch.sum().view().unsqueeze().repeat().long", "torch.sum().view().unsqueeze().repeat().long", "torch.sum().view().unsqueeze().repeat().long", "torch.sum().view().unsqueeze().repeat().long", "torch.sum().view().unsqueeze().repeat().long", "torch.sum().view().unsqueeze().repeat().long", "torch.sum().view().unsqueeze().repeat().long", "torch.sum().view().unsqueeze().repeat().long", "torch.sum().view().unsqueeze().repeat().long", "torch.sum().view().unsqueeze().repeat().long", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "AlignDot.AlignDot.loss", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.sum().view().unsqueeze().repeat", "torch.sum().view().unsqueeze().repeat", "torch.sum().view().unsqueeze().repeat", "torch.sum().view().unsqueeze().repeat", "torch.sum().view().unsqueeze().repeat", "torch.sum().view().unsqueeze().repeat", "torch.sum().view().unsqueeze().repeat", "torch.sum().view().unsqueeze().repeat", "torch.sum().view().unsqueeze().repeat", "torch.sum().view().unsqueeze().repeat", "torch.sum().view().unsqueeze().repeat", "torch.sum().view().unsqueeze().repeat", "AlignDot.AlignDot.score_pair_train", "AlignDot.AlignDot.score_pair_train", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.sum().view().unsqueeze", "torch.sum().view().unsqueeze", "torch.sum().view().unsqueeze", "torch.sum().view().unsqueeze", "torch.sum().view().unsqueeze", "torch.sum().view().unsqueeze", "torch.sum().view().unsqueeze", "torch.sum().view().unsqueeze", "torch.sum().view().unsqueeze", "torch.sum().view().unsqueeze", "torch.sum().view().unsqueeze", "torch.sum().view().unsqueeze", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.utils.token_lookup.get_qry_pos_neg_tok_lookup", "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.score_pair_train", "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.score_pair_train"], ["", "def", "compute_loss", "(", "self", ",", "qry_tk", ",", "pos_tk", ",", "neg_tk", ")", ":", "\n", "        ", "\"\"\"\n        Computes loss for batch of query positive negative triplets\n\n        param qry: query mention lookup (batch_size of list of token)\n        param pos: positive mention lookup (batch_size of list of token)\n        param neg: negative mention lookup (batch_size of list of token)\n        return: loss (batch_size)\n        \"\"\"", "\n", "qry_lkup", ",", "pos_lkup", ",", "neg_lkup", "=", "get_qry_pos_neg_tok_lookup", "(", "self", ".", "vocab", ",", "qry_tk", ",", "pos_tk", ",", "neg_tk", ")", "\n", "\n", "qry_emb", ",", "qry_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "qry_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "pos_emb", ",", "pos_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "pos_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "neg_emb", ",", "neg_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "neg_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "output_dim", "=", "qry_emb", ".", "shape", "[", "2", "]", "\n", "\n", "qry_len", "=", "torch", ".", "sum", "(", "qry_mask", ",", "dim", "=", "1", ")", ".", "view", "(", "-", "1", ",", "1", ")", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "output_dim", ")", ".", "long", "(", ")", "\n", "pos_len", "=", "torch", ".", "sum", "(", "pos_mask", ",", "dim", "=", "1", ")", ".", "view", "(", "-", "1", ",", "1", ")", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "output_dim", ")", ".", "long", "(", ")", "\n", "neg_len", "=", "torch", ".", "sum", "(", "neg_mask", ",", "dim", "=", "1", ")", ".", "view", "(", "-", "1", ",", "1", ")", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "output_dim", ")", ".", "long", "(", ")", "\n", "\n", "qry_emb", "=", "torch", ".", "gather", "(", "input", "=", "qry_emb", ",", "dim", "=", "1", ",", "index", "=", "qry_len", ")", "\n", "pos_emb", "=", "torch", ".", "gather", "(", "input", "=", "pos_emb", ",", "dim", "=", "1", ",", "index", "=", "pos_len", ")", "\n", "neg_emb", "=", "torch", ".", "gather", "(", "input", "=", "neg_emb", ",", "dim", "=", "1", ",", "index", "=", "neg_len", ")", "\n", "\n", "loss", "=", "self", ".", "loss", "(", "\n", "self", ".", "score_pair_train", "(", "qry_emb", ",", "pos_emb", ",", "qry_mask", ",", "pos_mask", ")", "\n", "-", "self", ".", "score_pair_train", "(", "qry_emb", ",", "neg_emb", ",", "qry_mask", ",", "neg_mask", ")", ",", "\n", "self", ".", "ones", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.AlignDot.AlignDot.score_pair_train": [[84, 98], ["torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "score_pair_train", "(", "self", ",", "qry_emb", ",", "cnd_emb", ",", "qry_mask", ",", "cnd_mask", ")", ":", "\n", "        ", "\"\"\" \n        Scores the batch of query candidate pair\n        Take the dot product of all pairs of embeddings (with bmm) to get similarity matrix\n        Then multiply by weight matrix and sum across row and column of \n\n        param qry: query mention embedding (batch_size * max_len_token * hidden_state_output_size)\n        param cnd: candidate mention embedding (batch_size * max_len_token * hidden_state_output_size)\n        param qry_msk: query mention mask (batch_size * max_len_token)\n        param cnd_mask: candidate mention mask (batch_size * max_len_token)\n        return: score for query candidate pairs (batch_size)\n        \"\"\"", "\n", "\n", "return", "torch", ".", "sum", "(", "qry_emb", "*", "cnd_emb", ",", "dim", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.AlignDot.AlignDot.score_dev_test_batch": [[99, 123], ["main.utils.token_lookup.get_qry_cnd_tok_lookup", "AlignDot.AlignDot.LSTM", "AlignDot.AlignDot.LSTM", "torch.sum().view().unsqueeze().repeat().long", "torch.sum().view().unsqueeze().repeat().long", "torch.sum().view().unsqueeze().repeat().long", "torch.sum().view().unsqueeze().repeat().long", "torch.sum().view().unsqueeze().repeat().long", "torch.sum().view().unsqueeze().repeat().long", "torch.sum().view().unsqueeze().repeat().long", "torch.sum().view().unsqueeze().repeat().long", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "AlignDot.AlignDot.score_pair_train", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.sum().view().unsqueeze().repeat", "torch.sum().view().unsqueeze().repeat", "torch.sum().view().unsqueeze().repeat", "torch.sum().view().unsqueeze().repeat", "torch.sum().view().unsqueeze().repeat", "torch.sum().view().unsqueeze().repeat", "torch.sum().view().unsqueeze().repeat", "torch.sum().view().unsqueeze().repeat", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.sum().view().unsqueeze", "torch.sum().view().unsqueeze", "torch.sum().view().unsqueeze", "torch.sum().view().unsqueeze", "torch.sum().view().unsqueeze", "torch.sum().view().unsqueeze", "torch.sum().view().unsqueeze", "torch.sum().view().unsqueeze", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.utils.token_lookup.get_qry_cnd_tok_lookup", "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.score_pair_train"], ["", "def", "score_dev_test_batch", "(", "self", ",", "qry_tk", ",", "cnd_tk", ")", ":", "\n", "        ", "\"\"\" \n        Returns the score for query candidate pair \n\n        param qry: query mention lookup (batch_size of list of tokens)\n        param cnd: candidate mention lookup (batch_size of list of tokens)\n        return: scores (batch_size)\n        \"\"\"", "\n", "qry_lkup", ",", "cnd_lkup", "=", "get_qry_cnd_tok_lookup", "(", "self", ".", "vocab", ",", "qry_tk", ",", "cnd_tk", ")", "\n", "\n", "qry_emb", ",", "qry_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "qry_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "cnd_emb", ",", "cnd_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "cnd_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "output_dim", "=", "qry_emb", ".", "shape", "[", "2", "]", "\n", "\n", "qry_len", "=", "torch", ".", "sum", "(", "qry_mask", ",", "dim", "=", "1", ")", ".", "view", "(", "-", "1", ",", "1", ")", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "output_dim", ")", ".", "long", "(", ")", "\n", "cnd_len", "=", "torch", ".", "sum", "(", "cnd_mask", ",", "dim", "=", "1", ")", ".", "view", "(", "-", "1", ",", "1", ")", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "output_dim", ")", ".", "long", "(", ")", "\n", "\n", "qry_emb", "=", "torch", ".", "gather", "(", "input", "=", "qry_emb", ",", "dim", "=", "1", ",", "index", "=", "qry_len", ")", "\n", "cnd_emb", "=", "torch", ".", "gather", "(", "input", "=", "cnd_emb", ",", "dim", "=", "1", ",", "index", "=", "cnd_len", ")", "\n", "\n", "scores", "=", "self", ".", "score_pair_train", "(", "qry_emb", ",", "cnd_emb", ",", "qry_mask", ",", "cnd_mask", ")", "\n", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.AlignDot.AlignDot.flatten_parameters": [[124, 126], ["AlignDot.AlignDot.LSTM.flatten_parameters"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.flatten_parameters"], ["", "def", "flatten_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "LSTM", ".", "flatten_parameters", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.iesl_stance.models.AlignBinary.AlignBinary.__init__": [[34, 58], ["super().__init__", "torch.Embedding", "torch.Embedding", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "main.base_models.CNN.CNN", "torch.autograd.Variable", "torch.autograd.Variable", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "vocab", ",", "max_len_token", ")", ":", "\n", "        ", "\"\"\"\n        param config: config object\n        param vocab: vocab object\n        param max_len_token: max number of tokens \n        \"\"\"", "\n", "super", "(", "AlignBinary", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "vocab", "=", "vocab", "\n", "\n", "self", ".", "need_flatten", "=", "True", "\n", "\n", "# Embeddings hack to create one-hot vectors for everything in our vocab", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "vocab", ".", "size", "+", "1", ",", "vocab", ".", "size", "+", "1", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "embedding", ".", "weight", ".", "data", "=", "torch", ".", "eye", "(", "vocab", ".", "size", "+", "1", ")", "\n", "self", ".", "embedding", ".", "weight", ".", "requires_grad", "=", "False", "\n", "self", ".", "max_len_token", "=", "max_len_token", "\n", "self", ".", "CNN", "=", "CNN", "(", "config", ".", "increasing", ",", "config", ".", "num_layers", ",", "config", ".", "filter_counts", ",", "max_len_token", ")", "\n", "\n", "# Vector of ones (used for loss)", "\n", "self", ".", "ones", "=", "Variable", "(", "torch", ".", "ones", "(", "config", ".", "train_batch_size", ",", "1", ")", ")", "\n", "self", ".", "loss", "=", "BCEWithLogitsLoss", "(", ")", "\n", "\n", "self", ".", "has_hidden", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.AlignBinary.AlignBinary.compute_loss": [[59, 78], ["main.utils.token_lookup.get_qry_pos_neg_tok_lookup", "AlignBinary.AlignBinary.embed", "AlignBinary.AlignBinary.embed", "AlignBinary.AlignBinary.embed", "AlignBinary.AlignBinary.loss", "AlignBinary.AlignBinary.score_pair", "AlignBinary.AlignBinary.score_pair"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.utils.token_lookup.get_qry_pos_neg_tok_lookup", "home.repos.pwc.inspect_result.iesl_stance.models.AlignBinary.AlignBinary.embed", "home.repos.pwc.inspect_result.iesl_stance.models.AlignBinary.AlignBinary.embed", "home.repos.pwc.inspect_result.iesl_stance.models.AlignBinary.AlignBinary.embed", "home.repos.pwc.inspect_result.iesl_stance.models.AlignBinary.AlignBinary.score_pair", "home.repos.pwc.inspect_result.iesl_stance.models.AlignBinary.AlignBinary.score_pair"], ["", "def", "compute_loss", "(", "self", ",", "qry_tk", ",", "pos_tk", ",", "neg_tk", ")", ":", "\n", "        ", "\"\"\" \n        Computes loss for batch of query positive negative triplets\n\n        param qry: query mention tokens (batch_size of list of token)\n        param pos: positive mention tokens (batch_size of list of token)\n        param neg: negative mention tokens (batch_size of list of token)\n        return: loss (batch_size)\n        \"\"\"", "\n", "qry_lkup", ",", "pos_lkup", ",", "neg_lkup", "=", "get_qry_pos_neg_tok_lookup", "(", "self", ".", "vocab", ",", "qry_tk", ",", "pos_tk", ",", "neg_tk", ")", "\n", "\n", "qry_emb", ",", "qry_mask", "=", "self", ".", "embed", "(", "qry_lkup", ")", "\n", "pos_emb", ",", "pos_mask", "=", "self", ".", "embed", "(", "pos_lkup", ")", "\n", "neg_emb", ",", "neg_mask", "=", "self", ".", "embed", "(", "neg_lkup", ")", "\n", "\n", "scores", "=", "self", ".", "score_pair", "(", "qry_emb", ",", "pos_emb", ",", "qry_mask", ",", "pos_mask", ")", "-", "self", ".", "score_pair", "(", "qry_emb", ",", "neg_emb", ",", "qry_mask", ",", "neg_mask", ")", "\n", "loss", "=", "self", ".", "loss", "(", "scores", ",", "self", ".", "ones", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.AlignBinary.AlignBinary.score_pair": [[79, 96], ["torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "qry_msk.unsqueeze", "cnd_msk.unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "AlignBinary.AlignBinary.CNN", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose"], "methods", ["None"], ["", "def", "score_pair", "(", "self", ",", "qry_emb", ",", "cnd_emb", ",", "qry_msk", ",", "cnd_msk", ")", ":", "\n", "        ", "\"\"\" \n        Scores the batch of query candidate pair by taking the dot produc tof all pairs of embeddings \n        which are 1 hot vectors \n\n        param qry_emb: query mention embedding (batch_size * max_len_token * hidden_state_output_size)\n        param cnd_emb: candidate mention embedding (batch_size * max_len_token * hidden_state_output_size)\n        param qry_msk: query mention mask (batch_size * max_len_token)\n        param cnd_mask: candidate mention mask (batch_size * max_len_token)\n        return: score for query candidate pairs (batch_size * 1)\n        \"\"\"", "\n", "qry_cnd_sim", "=", "torch", ".", "bmm", "(", "qry_emb", ",", "torch", ".", "transpose", "(", "cnd_emb", ",", "2", ",", "1", ")", ")", "\n", "qry_mask", "=", "qry_msk", ".", "unsqueeze", "(", "dim", "=", "2", ")", "\n", "cnd_mask", "=", "cnd_msk", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "qry_cnd_mask", "=", "torch", ".", "bmm", "(", "qry_mask", ",", "cnd_mask", ")", "\n", "qry_cnd_sim", "=", "torch", ".", "mul", "(", "qry_cnd_sim", ",", "qry_cnd_mask", ")", "\n", "return", "self", ".", "CNN", "(", "qry_cnd_sim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.AlignBinary.AlignBinary.embed": [[97, 108], ["torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "AlignBinary.AlignBinary.embedding", "torch.cuda.ByteTensor().float", "torch.cuda.ByteTensor().float", "torch.cuda.ByteTensor().float", "torch.cuda.ByteTensor().float", "torch.autograd.Variable", "torch.autograd.Variable", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.cuda.ByteTensor", "torch.cuda.ByteTensor", "torch.cuda.ByteTensor", "torch.cuda.ByteTensor"], "methods", ["None"], ["", "def", "embed", "(", "self", ",", "mnt_lkp", ")", ":", "\n", "        ", "\"\"\"\n        Look up embeddings for tokens - which are actually 1 hot vectors\n\n        param mnt_lkp: batch mention lookup (batch_size * max_len_token)\n        return: batch mention embedding (batch_size * max_len_token embedding dim\n        \"\"\"", "\n", "mnt_lkp", "=", "torch", ".", "from_numpy", "(", "mnt_lkp", ")", ".", "cuda", "(", ")", "\n", "mnt_mask", "=", "Variable", "(", "torch", ".", "cuda", ".", "ByteTensor", "(", "(", "mnt_lkp", ">", "0", ")", ")", ".", "float", "(", ")", ")", "\n", "mnt_emb", "=", "self", ".", "embedding", "(", "Variable", "(", "mnt_lkp", ")", ")", "\n", "return", "mnt_emb", ",", "mnt_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.AlignBinary.AlignBinary.score_dev_test_batch": [[109, 123], ["main.utils.token_lookup.get_qry_cnd_tok_lookup", "AlignBinary.AlignBinary.embed", "AlignBinary.AlignBinary.embed", "AlignBinary.AlignBinary.score_pair"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.utils.token_lookup.get_qry_cnd_tok_lookup", "home.repos.pwc.inspect_result.iesl_stance.models.AlignBinary.AlignBinary.embed", "home.repos.pwc.inspect_result.iesl_stance.models.AlignBinary.AlignBinary.embed", "home.repos.pwc.inspect_result.iesl_stance.models.AlignBinary.AlignBinary.score_pair"], ["", "def", "score_dev_test_batch", "(", "self", ",", "qry_tk", ",", "cnd_tk", ")", ":", "\n", "        ", "\"\"\" \n        Returns the score for query candidate pair \n\n        param qry: query mention tokens (batch_size of list of token)\n        param cnd: candidate mention tokens (batch_size of list of token)\n        return: score (batch_size)\n        \"\"\"", "\n", "qry_lkup", ",", "cnd_lkup", "=", "get_qry_cnd_tok_lookup", "(", "self", ".", "vocab", ",", "qry_tk", ",", "cnd_tk", ")", "\n", "\n", "qry_emb", ",", "qry_mask", "=", "self", ".", "embed", "(", "qry_lkup", ")", "\n", "cnd_emb", ",", "cnd_mask", "=", "self", ".", "embed", "(", "cnd_lkup", ")", "\n", "\n", "return", "self", ".", "score_pair", "(", "qry_emb", ",", "cnd_emb", ",", "qry_mask", ",", "cnd_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.LDTW.MySoftDTW.forward": [[35, 48], ["torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "range", "dist_matrix.size", "sdtw.SoftDTW.SoftDTW", "sdtw.SoftDTW.SoftDTW.compute", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "dist_matrix[].cpu().detach().numpy", "sdtw.SoftDTW.SoftDTW.grad", "dist_matrix[].cpu().detach", "dist_matrix[].cpu"], "methods", ["None"], ["def", "forward", "(", "self", ",", "dist_matrix", ")", ":", "\n", "        ", "batch_size", "=", "dist_matrix", ".", "shape", "[", "0", "]", "\n", "output", "=", "torch", ".", "ones", "(", "[", "batch_size", ",", "1", "]", ")", ".", "cuda", "(", ")", "\n", "\n", "self", ".", "calc_grad", "=", "torch", ".", "ones", "(", "dist_matrix", ".", "size", "(", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "sdtw", "=", "SoftDTW", "(", "dist_matrix", "[", "i", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", ".5", ")", "\n", "value", "=", "sdtw", ".", "compute", "(", ")", "\n", "output", "[", "i", "]", "=", "-", "value", "\n", "self", ".", "calc_grad", "[", "i", "]", "=", "torch", ".", "from_numpy", "(", "sdtw", ".", "grad", "(", ")", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.LDTW.MySoftDTW.backward": [[49, 56], ["torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "range", "torch.ones().float.cuda", "torch.ones().float.cuda", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "[].item", "LDTW.MySoftDTW.calc_grad.size"], "methods", ["None"], ["", "def", "backward", "(", "self", ",", "grad_out", ")", ":", "\n", "        ", "grad_input", "=", "torch", ".", "ones", "(", "self", ".", "calc_grad", ".", "size", "(", ")", ")", ".", "float", "(", ")", "\n", "batch_size", "=", "grad_input", ".", "shape", "[", "0", "]", "\n", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "grad_input", "[", "i", "]", "=", "-", "self", ".", "calc_grad", "[", "i", "]", "*", "grad_out", "[", "i", "]", "[", "0", "]", ".", "item", "(", ")", "\n", "", "return", "grad_input", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.LDTW.LDTW.__init__": [[60, 74], ["super().__init__", "main.base_models.EMB.EMB", "main.base_models.LSTM.LSTM", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss", "torch.autograd.Variable", "torch.autograd.Variable", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "vocab", ",", "max_len_token", ")", ":", "\n", "        ", "super", "(", "LDTW", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "max_len_token", "=", "max_len_token", "\n", "\n", "self", ".", "need_flatten", "=", "True", "\n", "\n", "self", ".", "EMB", "=", "EMB", "(", "vocab", ".", "size", "+", "1", ",", "config", ".", "embedding_dim", ")", "\n", "self", ".", "LSTM", "=", "LSTM", "(", "self", ".", "EMB", ",", "config", ".", "embedding_dim", ",", "config", ".", "rnn_hidden_dim", ",", "config", ".", "bidirectional", ")", "\n", "\n", "# Vector of ones (used for loss)", "\n", "self", ".", "ones", "=", "Variable", "(", "torch", ".", "ones", "(", "config", ".", "train_batch_size", ",", "1", ")", ")", ".", "cuda", "(", ")", "\n", "self", ".", "loss", "=", "BCEWithLogitsLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.LDTW.LDTW.compute_loss": [[76, 95], ["main.utils.token_lookup.get_qry_pos_neg_tok_lookup", "LDTW.LDTW.LSTM", "LDTW.LDTW.LSTM", "LDTW.LDTW.LSTM", "LDTW.LDTW.loss", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "LDTW.LDTW.score_pair_train", "LDTW.LDTW.score_pair_train", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.utils.token_lookup.get_qry_pos_neg_tok_lookup", "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.score_pair_train", "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.score_pair_train"], ["", "def", "compute_loss", "(", "self", ",", "qry_tok", ",", "pos_tok", ",", "neg_tok", ")", ":", "\n", "        ", "\"\"\" \n        Computes loss for batch of query positive negative triplets\n\n        param qry: query tokens (batch size of list of tokens)\n        param pos: positive mention lookup (batch size of list of tokens)\n        param neg: negative mention lookup (batch size of list of tokens)\n        return: loss (batch_size)\n        \"\"\"", "\n", "qry_lkup", ",", "pos_lkup", ",", "neg_lkup", "=", "get_qry_pos_neg_tok_lookup", "(", "self", ".", "vocab", ",", "qry_tok", ",", "pos_tok", ",", "neg_tok", ")", "\n", "\n", "qry_emb", ",", "qry_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "qry_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "pos_emb", ",", "pos_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "pos_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "neg_emb", ",", "neg_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "neg_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "loss", "=", "self", ".", "loss", "(", "self", ".", "score_pair_train", "(", "qry_emb", ",", "pos_emb", ",", "qry_mask", ",", "pos_mask", ")", "-", "self", ".", "score_pair_train", "(", "qry_emb", ",", "neg_emb", ",", "qry_mask", ",", "neg_mask", ")", ",", "self", ".", "ones", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.LDTW.LDTW.score_pair_train": [[97, 115], ["torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "qry_msk.unsqueeze", "cnd_msk.unsqueeze.unsqueeze.unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "LDTW.MySoftDTW"], "methods", ["None"], ["", "def", "score_pair_train", "(", "self", ",", "qry_emb", ",", "cnd_emb", ",", "qry_msk", ",", "cnd_msk", ")", ":", "\n", "        ", "\"\"\" \n        param qry: query mention embedding (batch_size * max_len_token * hidden_state_output_size)\n        param cnd: candidate mention embedding (batch_size * max_len_token * hidden_state_output_size)\n        param qry_msk: query mention mask (batch_size * max_len_token)\n        param cnd_mask: candidate mention mask (batch_size * max_len_token)\n        return: score for query candidate pairs (batch_size * 1)\n        \"\"\"", "\n", "qry_cnd_sim", "=", "torch", ".", "bmm", "(", "qry_emb", ",", "torch", ".", "transpose", "(", "cnd_emb", ",", "2", ",", "1", ")", ")", "\n", "\n", "qry_mask", "=", "qry_msk", ".", "unsqueeze", "(", "dim", "=", "2", ")", "\n", "cnd_msk", "=", "cnd_msk", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "qry_cnd_mask", "=", "torch", ".", "bmm", "(", "qry_mask", ",", "cnd_msk", ")", "\n", "\n", "qry_cnd_sim", "=", "torch", ".", "mul", "(", "qry_cnd_sim", ",", "qry_cnd_mask", ")", "\n", "qry_cnd_dist", "=", "-", "qry_cnd_sim", "\n", "\n", "return", "MySoftDTW", "(", ")", "(", "qry_cnd_dist", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.LDTW.LDTW.score_dev_test_batch": [[116, 131], ["main.utils.token_lookup.get_qry_cnd_tok_lookup", "LDTW.LDTW.LSTM", "LDTW.LDTW.LSTM", "LDTW.LDTW.score_pair_train", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.utils.token_lookup.get_qry_cnd_tok_lookup", "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.score_pair_train"], ["", "def", "score_dev_test_batch", "(", "self", ",", "qry_tk", ",", "cnd_tk", ")", ":", "\n", "        ", "\"\"\" \n        Returns the score for query candidate pair \n\n        param qry: query mention lookup (batch size of list of tokens)\n        param cnd: candidate mention lookup (batch size of list of tokens)\n        return: score (batch_size)\n        \"\"\"", "\n", "qry_lkup", ",", "cnd_lkup", "=", "get_qry_cnd_tok_lookup", "(", "self", ".", "vocab", ",", "qry_tk", ",", "cnd_tk", ")", "\n", "\n", "qry_emb", ",", "qry_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "qry_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "cnd_embed", ",", "cnd_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "cnd_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "scores", "=", "self", ".", "score_pair_train", "(", "qry_emb", ",", "cnd_embed", ",", "qry_mask", ",", "cnd_mask", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.LDTW.LDTW.flatten_parameters": [[133, 135], ["LDTW.LDTW.LSTM.flatten_parameters"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.flatten_parameters"], ["", "def", "flatten_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "LSTM", ".", "flatten_parameters", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.iesl_stance.models.AlignCNN.AlignCNN.__init__": [[37, 57], ["super().__init__", "main.base_models.EMB.EMB", "main.base_models.LSTM.LSTM", "main.base_models.CNN.CNN", "torch.autograd.Variable().cuda().float", "torch.autograd.Variable().cuda().float", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "vocab", ",", "max_len_token", ")", ":", "\n", "        ", "\"\"\"\n        param config: config object\n        param vocab: vocab object\n        param max_len_token: max number of tokens \n        \"\"\"", "\n", "super", "(", "AlignCNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "max_len_token", "=", "max_len_token", "\n", "\n", "self", ".", "need_flatten", "=", "True", "\n", "\n", "self", ".", "EMB", "=", "EMB", "(", "vocab", ".", "size", "+", "1", ",", "config", ".", "embedding_dim", ")", "\n", "self", ".", "LSTM", "=", "LSTM", "(", "self", ".", "EMB", ",", "config", ".", "embedding_dim", ",", "config", ".", "rnn_hidden_dim", ",", "config", ".", "bidirectional", ")", "\n", "self", ".", "CNN", "=", "CNN", "(", "config", ".", "increasing", ",", "config", ".", "cnn_num_layers", ",", "config", ".", "filter_counts", ",", "max_len_token", ")", "\n", "\n", "# Vector of ones (used for loss)", "\n", "self", ".", "ones", "=", "Variable", "(", "torch", ".", "ones", "(", "config", ".", "train_batch_size", ",", "1", ")", ")", ".", "cuda", "(", ")", ".", "float", "(", ")", "\n", "self", ".", "loss", "=", "BCEWithLogitsLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.AlignCNN.AlignCNN.compute_loss": [[58, 77], ["main.utils.token_lookup.get_qry_pos_neg_tok_lookup", "AlignCNN.AlignCNN.LSTM", "AlignCNN.AlignCNN.LSTM", "AlignCNN.AlignCNN.LSTM", "AlignCNN.AlignCNN.loss", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "AlignCNN.AlignCNN.score_pair_train", "AlignCNN.AlignCNN.score_pair_train", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.utils.token_lookup.get_qry_pos_neg_tok_lookup", "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.score_pair_train", "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.score_pair_train"], ["", "def", "compute_loss", "(", "self", ",", "qry_tok", ",", "pos_tok", ",", "neg_tok", ")", ":", "\n", "        ", "\"\"\" \n        Computes loss for batch of query positive negative triplets\n\n        param qry: query tokens (batch size of list of tokens)\n        param pos: positive mention lookup (batch size of list of tokens)\n        param neg: negative mention lookup (batch size of list of tokens)\n        return: loss (batch_size)\n        \"\"\"", "\n", "qry_lkup", ",", "pos_lkup", ",", "neg_lkup", "=", "get_qry_pos_neg_tok_lookup", "(", "self", ".", "vocab", ",", "qry_tok", ",", "pos_tok", ",", "neg_tok", ")", "\n", "\n", "qry_emb", ",", "qry_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "qry_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "pos_emb", ",", "pos_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "pos_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "neg_emb", ",", "neg_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "neg_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "loss", "=", "self", ".", "loss", "(", "self", ".", "score_pair_train", "(", "qry_emb", ",", "pos_emb", ",", "qry_mask", ",", "pos_mask", ")", "\n", "-", "self", ".", "score_pair_train", "(", "qry_emb", ",", "neg_emb", ",", "qry_mask", ",", "neg_mask", ")", ",", "self", ".", "ones", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.AlignCNN.AlignCNN.score_pair_train": [[78, 97], ["torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "qry_msk.unsqueeze", "cnd_msk.unsqueeze.unsqueeze.unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "AlignCNN.AlignCNN.CNN", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose"], "methods", ["None"], ["", "def", "score_pair_train", "(", "self", ",", "qry_emb", ",", "cnd_emb", ",", "qry_msk", ",", "cnd_msk", ")", ":", "\n", "        ", "\"\"\" \n        Scores the batch of query candidate pair by taking the dot product of all pairs of embeddings (with bmm) to get similarity matrix\n        Then runs CNN over the similarity matrix\n\n        param qry: query mention embedding (batch_size * max_len_token * hidden_state_output_size)\n        param cnd: candidate mention embedding (batch_size * max_len_token * hidden_state_output_size)\n        param qry_msk: query mention mask (batch_size * max_len_token)\n        param cnd_mask: candidate mention mask (batch_size * max_len_token)\n        return: score for query candidate pairs (batch_size * 1)\n        \"\"\"", "\n", "qry_cnd_sim", "=", "torch", ".", "bmm", "(", "qry_emb", ",", "torch", ".", "transpose", "(", "cnd_emb", ",", "2", ",", "1", ")", ")", "\n", "\n", "qry_mask", "=", "qry_msk", ".", "unsqueeze", "(", "dim", "=", "2", ")", "\n", "cnd_msk", "=", "cnd_msk", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "qry_cnd_mask", "=", "torch", ".", "bmm", "(", "qry_mask", ",", "cnd_msk", ")", "\n", "qry_cnd_sim", "=", "torch", ".", "mul", "(", "qry_cnd_sim", ",", "qry_cnd_mask", ")", "\n", "\n", "return", "self", ".", "CNN", "(", "qry_cnd_sim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.AlignCNN.AlignCNN.score_dev_test_batch": [[98, 112], ["main.utils.token_lookup.get_qry_cnd_tok_lookup", "AlignCNN.AlignCNN.LSTM", "AlignCNN.AlignCNN.LSTM", "AlignCNN.AlignCNN.score_pair_train", "torch.from_numpy().cuda().long", "torch.from_numpy().cuda().long", "torch.from_numpy().cuda().long", "torch.from_numpy().cuda().long", "torch.from_numpy().cuda().long", "torch.from_numpy().cuda().long", "torch.from_numpy().cuda().long", "torch.from_numpy().cuda().long", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.utils.token_lookup.get_qry_cnd_tok_lookup", "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.score_pair_train"], ["", "def", "score_dev_test_batch", "(", "self", ",", "qry_tk", ",", "cnd_tk", ")", ":", "\n", "        ", "\"\"\"\n        Returns the score for query candidate pair \n\n        param qry: query mention lookup (batch size of list of tokens)\n        param cnd: candidate mention lookup (batch size of list of tokens)\n        return: score (batch_size)\n        \"\"\"", "\n", "qry_lkup", ",", "cnd_lkup", "=", "get_qry_cnd_tok_lookup", "(", "self", ".", "vocab", ",", "qry_tk", ",", "cnd_tk", ")", "\n", "qry_emb", ",", "qry_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "qry_lkup", ")", ".", "cuda", "(", ")", ".", "long", "(", ")", ")", "\n", "cnd_embed", ",", "cnd_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "cnd_lkup", ")", ".", "cuda", "(", ")", ".", "long", "(", ")", ")", "\n", "\n", "scores", "=", "self", ".", "score_pair_train", "(", "qry_emb", ",", "cnd_embed", ",", "qry_mask", ",", "cnd_mask", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.AlignCNN.AlignCNN.flatten_parameters": [[113, 115], ["AlignCNN.AlignCNN.LSTM.flatten_parameters"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.flatten_parameters"], ["", "def", "flatten_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "LSTM", ".", "flatten_parameters", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.iesl_stance.models.AlignLinear.AlignLinear.__init__": [[33, 53], ["super().__init__", "main.base_models.EMB.EMB", "main.base_models.LSTM.LSTM", "torch.Parameter", "torch.Parameter", "torch.autograd.Variable", "torch.autograd.Variable", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "vocab", ",", "max_len_token", ")", ":", "\n", "        ", "\"\"\"\n        param config: config object\n        param vocab: vocab object\n        param max_len_token: max number of tokens \n        \"\"\"", "\n", "super", "(", "AlignLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "max_len_token", "=", "max_len_token", "\n", "\n", "self", ".", "need_flatten", "=", "True", "\n", "\n", "self", ".", "EMB", "=", "EMB", "(", "vocab", ".", "size", "+", "1", ",", "config", ".", "embedding_dim", ")", "\n", "self", ".", "LSTM", "=", "LSTM", "(", "self", ".", "EMB", ",", "config", ".", "embedding_dim", ",", "config", ".", "rnn_hidden_dim", ",", "config", ".", "bidirectional", ")", "\n", "self", ".", "align_weights", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "max_len_token", ",", "max_len_token", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n", "# Vector of ones (used for loss)", "\n", "self", ".", "ones", "=", "Variable", "(", "torch", ".", "ones", "(", "config", ".", "train_batch_size", ",", "1", ")", ")", "\n", "self", ".", "loss", "=", "BCEWithLogitsLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.AlignLinear.AlignLinear.compute_loss": [[54, 75], ["main.utils.token_lookup.get_qry_pos_neg_tok_lookup", "AlignLinear.AlignLinear.LSTM", "AlignLinear.AlignLinear.LSTM", "AlignLinear.AlignLinear.LSTM", "AlignLinear.AlignLinear.loss", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "AlignLinear.AlignLinear.score_pair_train", "AlignLinear.AlignLinear.score_pair_train", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.utils.token_lookup.get_qry_pos_neg_tok_lookup", "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.score_pair_train", "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.score_pair_train"], ["", "def", "compute_loss", "(", "self", ",", "qry_tk", ",", "pos_tk", ",", "neg_tk", ")", ":", "\n", "        ", "\"\"\"\n        Computes loss for batch of query positive negative triplets\n\n        param qry: query mention lookup (batch_size of list of token)\n        param pos: positive mention lookup (batch_size of list of token)\n        param neg: negative mention lookup (batch_size of list of token)\n        return: loss (batch_size)\n        \"\"\"", "\n", "qry_lkup", ",", "pos_lkup", ",", "neg_lkup", "=", "get_qry_pos_neg_tok_lookup", "(", "self", ".", "vocab", ",", "qry_tk", ",", "pos_tk", ",", "neg_tk", ")", "\n", "\n", "qry_emb", ",", "qry_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "qry_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "pos_emb", ",", "pos_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "pos_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "neg_emb", ",", "neg_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "neg_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "loss", "=", "self", ".", "loss", "(", "\n", "self", ".", "score_pair_train", "(", "qry_emb", ",", "pos_emb", ",", "qry_mask", ",", "pos_mask", ")", "\n", "-", "self", ".", "score_pair_train", "(", "qry_emb", ",", "neg_emb", ",", "qry_mask", ",", "neg_mask", ")", ",", "\n", "self", ".", "ones", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.AlignLinear.AlignLinear.score_pair_train": [[76, 99], ["torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "qry_mask.unsqueeze.unsqueeze.unsqueeze", "cnd_mask.unsqueeze.unsqueeze.unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "AlignLinear.AlignLinear.align_weights.expand_as"], "methods", ["None"], ["", "def", "score_pair_train", "(", "self", ",", "qry_emb", ",", "cnd_emb", ",", "qry_mask", ",", "cnd_mask", ")", ":", "\n", "        ", "\"\"\" \n        Scores the batch of query candidate pair\n        Take the dot product of all pairs of embeddings (with bmm) to get similarity matrix\n        Then multiply by weight matrix and sum across row and column of \n\n        param qry: query mention embedding (batch_size * max_len_token * hidden_state_output_size)\n        param cnd: candidate mention embedding (batch_size * max_len_token * hidden_state_output_size)\n        param qry_msk: query mention mask (batch_size * max_len_token)\n        param cnd_mask: candidate mention mask (batch_size * max_len_token)\n        return: score for query candidate pairs (batch_size)\n        \"\"\"", "\n", "qry_cnd_sim", "=", "torch", ".", "bmm", "(", "qry_emb", ",", "torch", ".", "transpose", "(", "cnd_emb", ",", "2", ",", "1", ")", ")", "\n", "\n", "qry_mask", "=", "qry_mask", ".", "unsqueeze", "(", "dim", "=", "2", ")", "\n", "cnd_mask", "=", "cnd_mask", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "qry_cnd_mask", "=", "torch", ".", "bmm", "(", "qry_mask", ",", "cnd_mask", ")", "\n", "qry_cnd_sim", "=", "torch", ".", "mul", "(", "qry_cnd_sim", ",", "qry_cnd_mask", ")", "\n", "\n", "output", "=", "torch", ".", "sum", "(", "self", ".", "align_weights", ".", "expand_as", "(", "qry_cnd_sim", ")", "*", "qry_cnd_sim", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "output", "=", "torch", ".", "sum", "(", "output", ",", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "output", "=", "torch", ".", "squeeze", "(", "output", ",", "dim", "=", "2", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.AlignLinear.AlignLinear.score_dev_test_batch": [[100, 115], ["main.utils.token_lookup.get_qry_cnd_tok_lookup", "AlignLinear.AlignLinear.LSTM", "AlignLinear.AlignLinear.LSTM", "AlignLinear.AlignLinear.score_pair_train", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.utils.token_lookup.get_qry_cnd_tok_lookup", "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.score_pair_train"], ["", "def", "score_dev_test_batch", "(", "self", ",", "qry_tk", ",", "cnd_tk", ")", ":", "\n", "        ", "\"\"\" \n        Returns the score for query candidate pair \n\n        param qry: query mention lookup (batch_size of list of tokens)\n        param cnd: candidate mention lookup (batch_size of list of tokens)\n        return: scores (batch_size)\n        \"\"\"", "\n", "qry_lkup", ",", "cnd_lkup", "=", "get_qry_cnd_tok_lookup", "(", "self", ".", "vocab", ",", "qry_tk", ",", "cnd_tk", ")", "\n", "\n", "qry_emb", ",", "qry_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "qry_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "cnd_embed", ",", "cnd_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "cnd_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "scores", "=", "self", ".", "score_pair_train", "(", "qry_emb", ",", "cnd_embed", ",", "qry_mask", ",", "cnd_mask", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.AlignLinear.AlignLinear.flatten_parameters": [[116, 118], ["AlignLinear.AlignLinear.LSTM.flatten_parameters"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.flatten_parameters"], ["", "def", "flatten_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "LSTM", ".", "flatten_parameters", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.__init__": [[38, 58], ["super().__init__", "main.base_models.EMB.EMB", "main.base_models.LSTM.LSTM", "main.base_models.CNN.CNN", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss", "torch.autograd.Variable", "torch.autograd.Variable", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "vocab", ",", "max_len_token", ")", ":", "\n", "        ", "\"\"\"\n        param config: config object\n        param vocab: vocab object\n        param max_len_token: max number of tokens \n        \"\"\"", "\n", "super", "(", "Stance", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "max_len_token", "=", "max_len_token", "\n", "\n", "self", ".", "need_flatten", "=", "True", "\n", "\n", "self", ".", "EMB", "=", "EMB", "(", "vocab", ".", "size", "+", "1", ",", "config", ".", "embedding_dim", ")", "\n", "self", ".", "LSTM", "=", "LSTM", "(", "self", ".", "EMB", ",", "config", ".", "embedding_dim", ",", "config", ".", "rnn_hidden_dim", ",", "config", ".", "bidirectional", ")", "\n", "self", ".", "CNN", "=", "CNN", "(", "config", ".", "increasing", ",", "config", ".", "cnn_num_layers", ",", "config", ".", "filter_counts", ",", "max_len_token", ")", "\n", "\n", "# Vector of ones (used for loss)", "\n", "self", ".", "ones", "=", "Variable", "(", "torch", ".", "ones", "(", "config", ".", "train_batch_size", ",", "1", ")", ")", ".", "cuda", "(", ")", "\n", "self", ".", "loss", "=", "BCEWithLogitsLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.compute_loss": [[59, 78], ["main.utils.token_lookup.get_qry_pos_neg_tok_lookup", "Stance.Stance.LSTM", "Stance.Stance.LSTM", "Stance.Stance.LSTM", "Stance.Stance.loss", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "Stance.Stance.score_pair_train", "Stance.Stance.score_pair_train", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.utils.token_lookup.get_qry_pos_neg_tok_lookup", "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.score_pair_train", "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.score_pair_train"], ["", "def", "compute_loss", "(", "self", ",", "qry_tok", ",", "pos_tok", ",", "neg_tok", ")", ":", "\n", "        ", "\"\"\"\n        Computes loss for batch of query positive negative triplets\n\n        param qry: query tokens (batch size of list of tokens)\n        param pos: positive mention lookup (batch size of list of tokens)\n        param neg: negative mention lookup (batch size of list of tokens)\n        return: loss (batch_size)\n        \"\"\"", "\n", "qry_lkup", ",", "pos_lkup", ",", "neg_lkup", "=", "get_qry_pos_neg_tok_lookup", "(", "self", ".", "vocab", ",", "qry_tok", ",", "pos_tok", ",", "neg_tok", ")", "\n", "\n", "qry_emb", ",", "qry_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "qry_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "pos_emb", ",", "pos_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "pos_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "neg_emb", ",", "neg_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "neg_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "loss", "=", "self", ".", "loss", "(", "self", ".", "score_pair_train", "(", "qry_emb", ",", "pos_emb", ",", "qry_mask", ",", "pos_mask", ")", "\n", "-", "self", ".", "score_pair_train", "(", "qry_emb", ",", "neg_emb", ",", "qry_mask", ",", "neg_mask", ")", ",", "self", ".", "ones", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.score_pair_train": [[80, 105], ["torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "qry_msk.unsqueeze", "cnd_msk.unsqueeze.unsqueeze.unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "main.objects.Sinkhorn.batch_sinkhorn_loss", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "Stance.Stance.CNN", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.max", "torch.max", "torch.max", "torch.max", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.bmm.size", "torch.bmm.size"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.Sinkhorn.batch_sinkhorn_loss"], ["", "def", "score_pair_train", "(", "self", ",", "qry_emb", ",", "cnd_emb", ",", "qry_msk", ",", "cnd_msk", ")", ":", "\n", "        ", "\"\"\" \n        Scores the batch of query candidate pair\n        Take the dot product of all pairs of embeddings (with bmm) to get similarity matrix\n        Uses optimal transport to align the weights\n        Then runs CNN over the similarity matrix\n\n        param qry: query mention embedding (batch_size * max_len_token * hidden_state_output_size)\n        param cnd: candidate mention embedding (batch_size * max_len_token * hidden_state_output_size)\n        param qry_msk: query mention mask (batch_size * max_len_token)\n        param cnd_mask: candidate mention mask (batch_size * max_len_token)\n        return: score for query candidate pairs (batch_size * 1)\n        \"\"\"", "\n", "qry_cnd_sim", "=", "torch", ".", "bmm", "(", "qry_emb", ",", "torch", ".", "transpose", "(", "cnd_emb", ",", "2", ",", "1", ")", ")", "\n", "\n", "qry_mask", "=", "qry_msk", ".", "unsqueeze", "(", "dim", "=", "2", ")", "\n", "cnd_msk", "=", "cnd_msk", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "qry_cnd_mask", "=", "torch", ".", "bmm", "(", "qry_mask", ",", "cnd_msk", ")", "\n", "\n", "qry_cnd_dist", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "qry_cnd_sim", ".", "size", "(", ")", ")", ".", "fill_", "(", "torch", ".", "max", "(", "qry_cnd_sim", ")", ")", "-", "qry_cnd_sim", "+", "1e-6", "\n", "qry_cnd_pi", "=", "batch_sinkhorn_loss", "(", "qry_cnd_dist", ",", "qry_cnd_mask", ")", "\n", "qry_cnd_sim_aligned", "=", "torch", ".", "mul", "(", "qry_cnd_sim", ",", "qry_cnd_pi", ")", "\n", "qry_cnd_sim_aligned", "=", "torch", ".", "mul", "(", "qry_cnd_sim_aligned", ",", "qry_cnd_mask", ")", "\n", "\n", "return", "self", ".", "CNN", "(", "qry_cnd_sim_aligned", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.score_dev_test_batch": [[106, 121], ["main.utils.token_lookup.get_qry_cnd_tok_lookup", "Stance.Stance.LSTM", "Stance.Stance.LSTM", "Stance.Stance.score_pair_train", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.utils.token_lookup.get_qry_cnd_tok_lookup", "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.score_pair_train"], ["", "def", "score_dev_test_batch", "(", "self", ",", "qry_tk", ",", "cnd_tk", ")", ":", "\n", "        ", "\"\"\" \n        Returns the score for query candidate pair \n\n        param qry: query mention lookup (batch size of list of tokens)\n        param cnd: candidate mention lookup (batch size of list of tokens)\n        return: score (batch_size)\n        \"\"\"", "\n", "qry_lkup", ",", "cnd_lkup", "=", "get_qry_cnd_tok_lookup", "(", "self", ".", "vocab", ",", "qry_tk", ",", "cnd_tk", ")", "\n", "\n", "qry_emb", ",", "qry_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "qry_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "cnd_embed", ",", "cnd_mask", "=", "self", ".", "LSTM", "(", "torch", ".", "from_numpy", "(", "cnd_lkup", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "scores", "=", "self", ".", "score_pair_train", "(", "qry_emb", ",", "cnd_embed", ",", "qry_mask", ",", "cnd_mask", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.flatten_parameters": [[122, 124], ["Stance.Stance.LSTM.flatten_parameters"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.flatten_parameters"], ["", "def", "flatten_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "LSTM", ".", "flatten_parameters", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.iesl_stance.train.train_model.train_model": [[40, 73], ["torch.manual_seed", "torch.manual_seed", "main.utils.model_helper.get_tokenizer", "main.utils.model_helper.get_vocab", "main.utils.model_helper.get_model", "model.cuda.cuda", "torch.Adam", "main.objects.Batcher.Batcher", "main.objects.Evaluator.Evaluator", "enumerate", "filter", "main.objects.Batcher.Batcher.get_train_batches", "optim.Adam.zero_grad", "model.cuda.train", "model.cuda.compute_loss", "model.compute_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "optim.Adam.step", "model.cuda.parameters", "model.cuda.parameters", "model.cuda.eval", "main.objects.Evaluator.Evaluator.evaluate"], "function", ["home.repos.pwc.inspect_result.iesl_stance.utils.model_helper.get_tokenizer", "home.repos.pwc.inspect_result.iesl_stance.utils.model_helper.get_vocab", "home.repos.pwc.inspect_result.iesl_stance.utils.model_helper.get_model", "home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.get_train_batches", "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.compute_loss", "home.repos.pwc.inspect_result.iesl_stance.models.LDTW.MySoftDTW.backward", "home.repos.pwc.inspect_result.iesl_stance.objects.Evaluator.Evaluator.evaluate"], ["def", "train_model", "(", "config", ",", "exp_dir", ")", ":", "\n", "    ", "\"\"\" Train based on the given config, model / dataset\n    \n    :param config: config object\n    :param dataset_name: name of dataset\n    :param model_name: name of model\n    :return: \n    \"\"\"", "\n", "torch", ".", "manual_seed", "(", "config", ".", "random_seed", ")", "\n", "\n", "tokenizer", ",", "max_len_token", "=", "get_tokenizer", "(", "config", ")", "\n", "vocab", "=", "get_vocab", "(", "config", ",", "tokenizer", ",", "max_len_token", ")", "\n", "model", "=", "get_model", "(", "config", ",", "vocab", ",", "max_len_token", ")", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", ",", "lr", "=", "config", ".", "learning_rate", ",", "\n", "weight_decay", "=", "config", ".", "l2penalty", ")", "\n", "\n", "train_batcher", "=", "Batcher", "(", "config", ",", "'train'", ",", "tokenizer", ")", "\n", "dev_evaluator", "=", "Evaluator", "(", "config", ",", "vocab", ",", "tokenizer", ",", "'dev'", ",", "exp_dir", ",", "list_k", "=", "[", "5", "]", ")", "\n", "\n", "for", "train_num_batches", ",", "(", "qry_tk", ",", "pos_tk", ",", "neg_tk", ")", "in", "enumerate", "(", "train_batcher", ".", "get_train_batches", "(", ")", ")", ":", "\n", "        ", "optimizer", ".", "zero_grad", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "loss", "=", "model", ".", "compute_loss", "(", "qry_tk", ",", "pos_tk", ",", "neg_tk", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "config", ".", "clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "if", "train_num_batches", "==", "config", ".", "num_minibatches", ":", "\n", "            ", "break", "\n", "", "if", "train_num_batches", ">", "0", "and", "train_num_batches", "%", "config", ".", "eval_every_minibatch", "==", "0", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "dev_evaluator", ".", "evaluate", "(", "model", ",", "train_num_batches", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.setup.make_vocab.count_tokens": [[23, 73], ["sys.stdout.write", "print", "main.objects.Tokenizer.Char", "open", "codecs.open", "token_dict.keys", "wf.flush", "wf.close", "main.objects.Tokenizer.Unigram", "line.strip().split", "main.objects.Tokenizer.UnigramUC", "sys.stdout.write", "main.objects.Tokenizer.UnigramUC.tokenize", "wf.write", "line.strip"], "function", ["home.repos.pwc.inspect_result.iesl_stance.objects.Tokenizer.Char.tokenize"], ["def", "count_tokens", "(", "read_file", ",", "write_file", ",", "tokenizer_name", ",", "min_count", ")", ":", "\n", "    ", "'''\n    Counts the number of each token in the file and then writes the tokens that occur more than a threshold to form the vocab\n\n    param read_file: file to read tokens \n    param write_file: file to write vocab\n    param tokenizer_name: tokenizer to use \n    param min_count: threshold of minimum number of occurences of tokens for vocab\n    '''", "\n", "tokenizer", "=", "None", "\n", "if", "(", "tokenizer_name", "==", "\"Char\"", ")", ":", "\n", "        ", "print", "(", "\"Made Char\"", ")", "\n", "tokenizer", "=", "Char", "(", ")", "\n", "", "elif", "(", "tokenizer_name", "==", "\"Unigram\"", ")", ":", "\n", "        ", "tokenizer", "=", "Unigram", "(", ")", "\n", "", "elif", "(", "tokenizer_name", "==", "\"UnigramUC\"", ")", ":", "\n", "        ", "tokenizer", "=", "UnigramUC", "(", ")", "\n", "\n", "\n", "", "token_dict", "=", "{", "}", "\n", "\n", "counter", "=", "0", "\n", "\n", "with", "open", "(", "read_file", ",", "'r+'", ")", "as", "rf", ":", "\n", "        ", "for", "line", "in", "rf", ":", "\n", "            ", "splt", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "if", "counter", "%", "1000", "==", "0", ":", "\n", "                ", "sys", ".", "stdout", ".", "write", "(", "\"\\rProcessed {} lines\"", ".", "format", "(", "counter", ")", ")", "\n", "", "for", "s", "in", "splt", ":", "\n", "                ", "s_tokens", "=", "tokenizer", ".", "tokenize", "(", "s", ")", "\n", "for", "token", "in", "s_tokens", ":", "\n", "                    ", "if", "token", "not", "in", "token_dict", ":", "\n", "                        ", "token_dict", "[", "token", "]", "=", "1", "\n", "", "else", ":", "\n", "                        ", "token_dict", "[", "token", "]", "+=", "1", "\n", "\n", "", "", "counter", "+=", "1", "\n", "\n", "", "", "", "sys", ".", "stdout", ".", "write", "(", "\"\\nDone....Now Writing Vocab.\"", ")", "\n", "\n", "with", "codecs", ".", "open", "(", "outputfile", ",", "\"w+\"", ",", "\"UTF-8\"", ")", "as", "wf", ":", "\n", "\n", "        ", "token_id", "=", "2", "\n", "for", "token", "in", "token_dict", ".", "keys", "(", ")", ":", "\n", "            ", "if", "token_dict", "[", "token", "]", ">=", "min_count", ":", "\n", "                ", "wf", ".", "write", "(", "\"{}\\t{}\\n\"", ".", "format", "(", "token", ",", "token_id", ")", ")", "\n", "token_id", "+=", "1", "\n", "\n", "", "", "wf", ".", "flush", "(", ")", "\n", "wf", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.setup.setup_grid_search_train.setup_grid_search": [[10, 38], ["os.path.join", "open", "f.write", "enumerate", "grid_search_config.configs_iter", "os.path.join", "os.makedirs", "os.path.join", "config.save_config", "os.path.join", "os.path.join", "f.write", "str"], "function", ["home.repos.pwc.inspect_result.iesl_stance.objects.GridSearchConfig.GridSearchConfig.configs_iter", "home.repos.pwc.inspect_result.iesl_stance.objects.Config.Config.save_config"], ["def", "setup_grid_search", "(", "exp_dir", ",", "grid_search_config", ",", "gpu_type", ",", "mem", ")", ":", "\n", "    ", "'''\n    Sets up grid search to train different configurations of the model in parallel \n\n    param exp_dir: experiment directory for all the configurations \n    param grid_search_config: grid search configuration with all the parameters used in grid search \n    param gpu_type: gpu to train on \n    param mem: amount of mem to train with \n    '''", "\n", "bash_script", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"grid_search_config.sh\"", ")", "\n", "\n", "with", "open", "(", "bash_script", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "\"#!/usr/bin/env bash \\n\"", ")", "\n", "\n", "for", "config_counter", ",", "config", "in", "enumerate", "(", "grid_search_config", ".", "configs_iter", "(", ")", ")", ":", "\n", "            ", "config_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"config_\"", "+", "str", "(", "config_counter", ")", ")", "\n", "os", ".", "makedirs", "(", "config_dir", ")", "\n", "\n", "config_param", "=", "os", ".", "path", ".", "join", "(", "config_dir", ",", "\"config.json\"", ")", "\n", "config", ".", "save_config", "(", "config_dir", ")", "\n", "\n", "error_file", "=", "os", ".", "path", ".", "join", "(", "config_dir", ",", "\"error\"", ")", "\n", "output_file", "=", "os", ".", "path", ".", "join", "(", "config_dir", ",", "\"output\"", ")", "\n", "\n", "command", "=", "\"sbatch --partition={} --gres=gpu:1 --mem=30G --error {} --output {} bin/run/train_model.sh {} {} \\n\"", ".", "format", "(", "gpu_type", ",", "error_file", ",", "output_file", ",", "config_param", ",", "True", ")", "\n", "\n", "f", ".", "write", "(", "command", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Writer.Writer.__init__": [[20, 25], ["open"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "test_file", ")", ":", "\n", "        ", "'''\n        param test_file: test file to write the scores to \n        '''", "\n", "self", ".", "test_file", "=", "open", "(", "test_file", ",", "'w+'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Writer.Writer.add_batch_pred_lab": [[26, 39], ["range", "len", "Writer.Writer.test_file.write", "str"], "methods", ["None"], ["", "def", "add_batch_pred_lab", "(", "self", ",", "qry", ",", "cnd", ",", "lbl", ",", "score", ")", ":", "\n", "        ", "'''\n        Writes batch of prediction \n\n        param qry: batch of query tokens \n        param cnd: batch of candidate tokens \n        param lbl: batch of labels \n        param score: batch of scores \n        '''", "\n", "for", "i", "in", "range", "(", "len", "(", "qry", ")", ")", ":", "\n", "            ", "tab_splits", "=", "[", "qry", "[", "i", "]", ",", "cnd", "[", "i", "]", ",", "str", "(", "lbl", "[", "i", "]", ")", ",", "(", "\"{:.3f}\"", ".", "format", "(", "score", "[", "i", "]", ")", ")", "]", "\n", "line", "=", "'\\t'", ".", "join", "(", "tab_splits", ")", "+", "'\\n'", "\n", "self", ".", "test_file", ".", "write", "(", "line", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.iesl_stance.objects.Scorer.Scorer.__init__": [[23, 39], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "list_k", ",", "score_filename", ",", "train_num_batches", ")", ":", "\n", "        ", "'''\n        param list_k: list of k to evaluate hits@k\n        param score_filename: filename to write scores \n        param train_num_batches: number of batches model has been trained on \n        '''", "\n", "self", ".", "avg_precs", "=", "[", "]", "\n", "self", ".", "list_k", "=", "list_k", "\n", "self", ".", "dict_avg_hits_at_k", "=", "{", "}", "\n", "self", ".", "score_filename", "=", "score_filename", "\n", "self", ".", "train_num_batches", "=", "train_num_batches", "\n", "self", ".", "queries", "=", "[", "]", "\n", "self", ".", "scores", "=", "[", "]", "\n", "self", ".", "labels", "=", "[", "]", "\n", "for", "k", "in", "list_k", ":", "\n", "            ", "self", ".", "dict_avg_hits_at_k", "[", "k", "]", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Scorer.Scorer.add_batch_pred_scores": [[41, 74], ["Scorer.Scorer.scores.extend", "Scorer.Scorer.labels.extend", "sum", "Scorer.Scorer.avg_precs.append", "zip", "sorted", "print", "sklearn.metrics.average_precision_score", "list", "Scorer.Scorer.dict_avg_hits_at_k[].append", "zip", "sum", "min", "sum"], "methods", ["None"], ["", "", "def", "add_batch_pred_scores", "(", "self", ",", "qry_tk", ",", "scores", ",", "labels", ",", "end_block", ")", ":", "\n", "        ", "'''\n        Adds batch of predicted scores and calculates scores if end of current block of query \n\n        param qry_tk: query_tokens for current batch \n        param scores: scores predicted for current batch \n        param labels: labels for current batch \n        param end_block: whether the current batch is the end of a current block fo query or not \n        '''", "\n", "\n", "self", ".", "scores", ".", "extend", "(", "scores", ")", "\n", "self", ".", "labels", ".", "extend", "(", "labels", ")", "\n", "\n", "if", "end_block", ":", "\n", "# Ensures there is at least 1 true positive", "\n", "            ", "if", "sum", "(", "self", ".", "labels", ")", ">", "0", ":", "\n", "                ", "self", ".", "avg_precs", ".", "append", "(", "average_precision_score", "(", "self", ".", "labels", ",", "self", ".", "scores", ")", ")", "\n", "\n", "zipped", "=", "zip", "(", "self", ".", "scores", ",", "self", ".", "labels", ")", "\n", "sort_zipped", "=", "sorted", "(", "zipped", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "sorted_labels", "=", "list", "(", "zip", "(", "*", "sort_zipped", ")", ")", "[", "1", "]", "\n", "\n", "for", "k", "in", "self", ".", "list_k", ":", "\n", "                    ", "top_k_labels", "=", "sorted_labels", "[", ":", "k", "]", "\n", "hits_at_k", "=", "sum", "(", "top_k_labels", ")", "/", "min", "(", "k", ",", "sum", "(", "self", ".", "labels", ")", ")", "\n", "self", ".", "dict_avg_hits_at_k", "[", "k", "]", ".", "append", "(", "hits_at_k", ")", "\n", "\n", "\n", "", "", "else", ":", "\n", "                ", "print", "(", "\"No Positive Label\"", ")", "\n", "\n", "", "self", ".", "scores", "=", "[", "]", "\n", "self", ".", "labels", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Scorer.Scorer.load_blocks": [[75, 100], ["zip", "result_labels.append", "result_scores.append", "current_block_labels.append", "current_block_scores.append", "result_labels.append", "result_scores.append", "int", "float"], "methods", ["None"], ["", "", "def", "load_blocks", "(", "self", ")", ":", "\n", "        ", "'''\n        Loads and stores all the blocks \n\n        return: result_labels\n        return: result_scores\n        '''", "\n", "result_labels", "=", "[", "]", "\n", "result_scores", "=", "[", "]", "\n", "current_qry", "=", "\"\"", "\n", "current_block_scores", "=", "[", "]", "\n", "current_block_labels", "=", "[", "]", "\n", "\n", "for", "(", "qry", ",", "score", ",", "label", ")", "in", "zip", "(", "self", ".", "queries", ",", "self", ".", "labels", ",", "self", ".", "scores", ")", ":", "\n", "            ", "if", "qry", "!=", "current_qry", "and", "current_qry", "!=", "\"\"", ":", "\n", "                ", "result_labels", ".", "append", "(", "current_block_labels", ")", "\n", "result_scores", ".", "append", "(", "current_block_scores", ")", "\n", "current_block_labels", "=", "[", "]", "\n", "current_block_scores", "=", "[", "]", "\n", "", "current_block_labels", ".", "append", "(", "int", "(", "label", ")", ")", "\n", "current_block_scores", ".", "append", "(", "float", "(", "score", ")", ")", "\n", "current_qry", "=", "qry", "\n", "", "result_labels", ".", "append", "(", "current_block_labels", ")", "\n", "result_scores", ".", "append", "(", "current_block_scores", ")", "\n", "return", "result_labels", ",", "result_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Scorer.Scorer.calc_scores": [[102, 124], ["float", "Scorer.Scorer.dict_avg_hits_at_k.items", "main.utils.util.save_dict_to_json", "float", "sum", "len", "str", "sum", "len"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.utils.util.save_dict_to_json"], ["", "def", "calc_scores", "(", "self", ")", ":", "\n", "        ", "'''\n        Calculates all the scores that haven been added by the batch \n\n        return: map score for calculating dev score \n        '''", "\n", "\n", "# result_labels, result_scores = self.load_blocks()", "\n", "# map_score = eval_map(result_labels,result_scores)", "\n", "map_score", "=", "float", "(", "sum", "(", "self", ".", "avg_precs", ")", "/", "len", "(", "self", ".", "avg_precs", ")", ")", "\n", "scores_obj", "=", "{", "\"map\"", ":", "map_score", "}", "\n", "\n", "if", "self", ".", "train_num_batches", "!=", "-", "1", ":", "\n", "            ", "scores_obj", "[", "\"train_num_batches\"", "]", "=", "self", ".", "train_num_batches", "\n", "\n", "", "for", "(", "k", ",", "avg_hits_at_k", ")", "in", "self", ".", "dict_avg_hits_at_k", ".", "items", "(", ")", ":", "\n", "            ", "hits_at_k_label", "=", "\"hits_at_\"", "+", "str", "(", "k", ")", "\n", "hits_at_k_score", "=", "float", "(", "sum", "(", "avg_hits_at_k", ")", "/", "len", "(", "avg_hits_at_k", ")", ")", "\n", "scores_obj", "[", "hits_at_k_label", "]", "=", "hits_at_k_score", "\n", "", "save_dict_to_json", "(", "scores_obj", ",", "self", ".", "score_filename", ")", "\n", "\n", "return", "map_score", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.GridSearchConfig.GridSearchConfig.__init__": [[28, 70], ["main.objects.Config.Config.__init__", "random.Random", "GridSearchConfig.GridSearchConfig.__dict__.update", "json.load", "open"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.__init__", "home.repos.pwc.inspect_result.iesl_stance.objects.Vocab.Vocab.load"], ["    ", "def", "__init__", "(", "self", ",", "filename", "=", "None", ")", ":", "\n", "        ", "'''\n        Initializes the hyperparameters to default values \n\n        param filename: filename containing the hyperparameters to use for training \n        '''", "\n", "super", "(", "Config", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "grid_search_fields", "=", "[", "]", "\n", "self", ".", "learning_rate", "=", "0.0001", "\n", "self", ".", "l2penalty", "=", "10.0", "\n", "self", ".", "vocab_file", "=", "None", "\n", "self", ".", "train_file", "=", "None", "\n", "self", ".", "dev_file", "=", "None", "\n", "self", ".", "test_file", "=", "None", "\n", "\n", "self", ".", "num_minibatches", "=", "40000", "\n", "self", ".", "eval_every_minibatch", "=", "100", "\n", "self", ".", "train_batch_size", "=", "32", "\n", "self", ".", "dev_test_batch_size", "=", "16", "\n", "\n", "self", ".", "max_num_unigram", "=", "40", "\n", "self", ".", "max_num_char", "=", "200", "\n", "self", ".", "max_num_unigramuc", "=", "40", "\n", "\n", "self", ".", "embedding_dim", "=", "100", "\n", "self", ".", "rnn_hidden_dim", "=", "100", "\n", "self", ".", "random_seed", "=", "2524", "\n", "self", ".", "bidirectional", "=", "True", "\n", "self", ".", "cnn_num_layers", "=", "3", "\n", "self", ".", "filter_counts", "=", "[", "25", ",", "25", ",", "25", ",", "25", "]", "\n", "self", ".", "increasing", "=", "False", "\n", "\n", "self", ".", "dropout_rate", "=", "0.2", "\n", "self", ".", "clip", "=", "0.25", "\n", "\n", "self", ".", "dataset_name", "=", "\"dataset\"", "\n", "self", ".", "model_name", "=", "\"model\"", "\n", "self", ".", "tokenizer_name", "=", "\"tokenizer\"", "\n", "self", ".", "random", "=", "random", ".", "Random", "(", "self", ".", "random_seed", ")", "\n", "\n", "if", "filename", ":", "\n", "            ", "self", ".", "__dict__", ".", "update", "(", "json", ".", "load", "(", "open", "(", "filename", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.GridSearchConfig.GridSearchConfig.to_json": [[72, 81], ["GridSearchConfig.GridSearchConfig.__dict__.keys", "json.dumps", "type", "type", "type"], "methods", ["None"], ["", "", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "'''\n        Stores all the parameters into a json \n        '''", "\n", "res", "=", "{", "}", "\n", "for", "k", "in", "self", ".", "__dict__", ".", "keys", "(", ")", ":", "\n", "            ", "if", "type", "(", "self", ".", "__dict__", "[", "k", "]", ")", "is", "str", "or", "type", "(", "self", ".", "__dict__", "[", "k", "]", ")", "is", "float", "or", "type", "(", "self", ".", "__dict__", "[", "k", "]", ")", "is", "int", ":", "\n", "                ", "res", "[", "k", "]", "=", "self", ".", "__dict__", "[", "k", "]", "\n", "", "", "return", "json", ".", "dumps", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.GridSearchConfig.GridSearchConfig.save_config": [[82, 91], ["open", "fout.write", "fout.write", "os.path.join", "GridSearchConfig.GridSearchConfig.to_json"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.Config.Config.to_json"], ["", "def", "save_config", "(", "self", ",", "exp_dir", ")", ":", "\n", "        ", "'''\n        Saves the parameters used for training in experiment directory \n\n        param exp_dir: experiment directory to save configuration \n        '''", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"config.json\"", ")", ",", "'w'", ")", "as", "fout", ":", "\n", "            ", "fout", ".", "write", "(", "self", ".", "to_json", "(", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.GridSearchConfig.GridSearchConfig.copy_config": [[92, 99], ["main.objects.Config.Config", "GridSearchConfig.GridSearchConfig.__dict__.copy"], "methods", ["None"], ["", "", "def", "copy_config", "(", "self", ")", ":", "\n", "        ", "'''\n        Copies the config to use for different grid search configurations\n        '''", "\n", "c", "=", "Config", "(", ")", "\n", "c", ".", "__dict__", "=", "self", ".", "__dict__", ".", "copy", "(", ")", "\n", "return", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.GridSearchConfig.GridSearchConfig.configs_iter": [[100, 113], ["itertools.product", "GridSearchConfig.GridSearchConfig.copy_config", "zip"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.GridSearchConfig.GridSearchConfig.copy_config"], ["", "def", "configs_iter", "(", "self", ")", ":", "\n", "        ", "'''\n        Iterates through the grid search fields and creates a configuration for each possible configuration of grid search paramter values \n\n        return: grid search configuration \n        '''", "\n", "gs_vals", "=", "[", "self", ".", "__dict__", "[", "k", "]", "for", "k", "in", "self", ".", "grid_search_fields", "]", "\n", "gs_params", "=", "itertools", ".", "product", "(", "*", "gs_vals", ")", "\n", "for", "param_setting", "in", "gs_params", ":", "\n", "            ", "new_config", "=", "self", ".", "copy_config", "(", ")", "\n", "for", "param", ",", "setting", "in", "zip", "(", "self", ".", "grid_search_fields", ",", "param_setting", ")", ":", "\n", "                ", "new_config", ".", "__dict__", "[", "param", "]", "=", "setting", "\n", "", "yield", "new_config", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.GridSearchConfig.GridSearchConfig.update_dataset": [[114, 119], ["str.split"], "methods", ["None"], ["", "", "def", "update_dataset", "(", "self", ")", ":", "\n", "        ", "'''\n        Updates the dataset appropriately by looking at the training filename \n        '''", "\n", "self", ".", "dataset_name", "=", "'/'", ".", "join", "(", "str", ".", "split", "(", "self", ".", "train_file", ",", "'/'", ")", "[", "1", ":", "2", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.iesl_stance.objects.Evaluator.Evaluator.__init__": [[33, 68], ["main.objects.Batcher.Batcher", "os.path.join", "os.path.join", "os.path.join", "main.objects.Writer.Writer", "os.path.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "vocab", ",", "tokenizer", ",", "input_type", ",", "exp_dir", ",", "list_k", ",", "labeled_file", "=", "None", ",", "output_file", "=", "None", ")", ":", "\n", "        ", "'''\n        param config: configuration to use for evaluation \n        param vocab: vocabulary to use \n        param tokenizer: tokenizer to use \n        param input_type: input type of either dev/test\n        param exp_dir: experiment directory to save output\n        param list_k: list of k to evaluate hits@k\n        param labeled_file: labeled file to use for labels (default is specified in config )\n        param output_file: output file to use for writing prediction \n        '''", "\n", "self", ".", "batcher", "=", "Batcher", "(", "config", ",", "input_type", ",", "tokenizer", ",", "labeled_file", ")", "\n", "self", ".", "input_type", "=", "input_type", "\n", "self", ".", "list_k", "=", "list_k", "\n", "\n", "if", "self", ".", "input_type", "==", "\"dev\"", ":", "\n", "            ", "self", ".", "best_dev_score", "=", "0", "\n", "self", ".", "score_filename", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"dev_scores.json\"", ")", "\n", "self", ".", "best_model_filename", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_model\"", ")", "\n", "\n", "", "elif", "self", ".", "input_type", "==", "\"test\"", ":", "\n", "            ", "if", "output_file", "is", "not", "None", ":", "\n", "                ", "self", ".", "test_file", "=", "output_file", "\n", "", "else", ":", "\n", "                ", "self", ".", "test_file", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"test.predictions\"", ")", "\n", "", "self", ".", "score_filename", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"test_scores.json\"", ")", "\n", "self", ".", "writer", "=", "Writer", "(", "self", ".", "test_file", ")", "\n", "\n", "", "self", ".", "output_file", "=", "None", "\n", "if", "output_file", ":", "\n", "            ", "self", ".", "output_file", "=", "output_file", "\n", "\n", "", "self", ".", "score", "=", "True", "\n", "if", "self", ".", "output_file", "is", "not", "None", "and", "\"shard\"", "in", "self", ".", "output_file", ":", "\n", "            ", "self", ".", "score", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Evaluator.Evaluator.evaluate": [[70, 99], ["Evaluator.Evaluator.batcher.get_dev_test_batches", "main.objects.Scorer.Scorer", "model.score_dev_test_batch", "list", "main.objects.Scorer.Scorer.calc_scores", "list.cpu().data.numpy().squeeze", "main.objects.Scorer.Scorer.add_batch_pred_scores", "Evaluator.Evaluator.writer.add_batch_pred_lab", "torch.save", "list.cpu().data.numpy", "list.cpu"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.get_dev_test_batches", "home.repos.pwc.inspect_result.iesl_stance.models.Stance.Stance.score_dev_test_batch", "home.repos.pwc.inspect_result.iesl_stance.objects.Scorer.Scorer.calc_scores", "home.repos.pwc.inspect_result.iesl_stance.objects.Scorer.Scorer.add_batch_pred_scores", "home.repos.pwc.inspect_result.iesl_stance.objects.Writer.Writer.add_batch_pred_lab"], ["", "", "def", "evaluate", "(", "self", ",", "model", ",", "train_num_batches", ")", ":", "\n", "        ", "'''\n        Evaluates the model by scoring it and writing its predictions \n\n        param train_num_batches: number of batches the model has trained on \n        '''", "\n", "if", "self", ".", "score", "==", "True", ":", "\n", "            ", "scorer", "=", "Scorer", "(", "self", ".", "list_k", ",", "self", ".", "score_filename", ",", "train_num_batches", ")", "\n", "\n", "# Score the model batch by batch ", "\n", "", "for", "qry_tk", ",", "qry", ",", "cnd_tk", ",", "cnd", ",", "labels", ",", "end_block", "in", "self", ".", "batcher", ".", "get_dev_test_batches", "(", ")", ":", "\n", "            ", "scores", "=", "model", ".", "score_dev_test_batch", "(", "qry_tk", ",", "cnd_tk", ")", "\n", "scores", "=", "list", "(", "scores", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "squeeze", "(", "1", ")", ")", "\n", "\n", "# Adds the batch of scores to Scorer", "\n", "if", "self", ".", "score", "==", "True", ":", "\n", "                ", "scorer", ".", "add_batch_pred_scores", "(", "qry_tk", ",", "scores", ",", "labels", ",", "end_block", ")", "\n", "\n", "# Adds the batch of predictions to Writer", "\n", "", "if", "self", ".", "input_type", "==", "\"test\"", ":", "\n", "                ", "self", ".", "writer", ".", "add_batch_pred_lab", "(", "qry", ",", "cnd", ",", "labels", ",", "scores", ")", "\n", "\n", "# Calculate the scores and save if best so far", "\n", "", "", "if", "self", ".", "score", "==", "True", ":", "\n", "            ", "map_score", "=", "scorer", ".", "calc_scores", "(", ")", "\n", "if", "self", ".", "input_type", "==", "\"dev\"", ":", "\n", "                ", "if", "map_score", ">", "self", ".", "best_dev_score", ":", "\n", "                    ", "torch", ".", "save", "(", "model", ",", "self", ".", "best_model_filename", ")", "\n", "", "self", ".", "best_dev_score", "=", "map_score", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Config.Config.__init__": [[25, 65], ["random.Random", "Config.Config.__dict__.update", "json.load", "open"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.Vocab.Vocab.load"], ["    ", "def", "__init__", "(", "self", ",", "filename", "=", "None", ")", ":", "\n", "        ", "'''\n        Initializes the hyperparameters to default values \n\n        param filename: filename containing the hyperparameters to use for training \n        '''", "\n", "self", ".", "learning_rate", "=", "0.0001", "\n", "self", ".", "l2penalty", "=", "10.0", "\n", "self", ".", "vocab_file", "=", "None", "\n", "self", ".", "train_file", "=", "None", "\n", "self", ".", "dev_file", "=", "None", "\n", "self", ".", "test_file", "=", "None", "\n", "\n", "self", ".", "num_minibatches", "=", "40000", "\n", "self", ".", "eval_every_minibatch", "=", "100", "\n", "self", ".", "train_batch_size", "=", "32", "\n", "self", ".", "dev_test_batch_size", "=", "16", "\n", "\n", "self", ".", "max_num_unigram", "=", "40", "\n", "self", ".", "max_num_char", "=", "200", "\n", "self", ".", "max_num_unigramuc", "=", "40", "\n", "\n", "self", ".", "embedding_dim", "=", "100", "\n", "self", ".", "rnn_hidden_dim", "=", "100", "\n", "self", ".", "random_seed", "=", "2524", "\n", "self", ".", "bidirectional", "=", "True", "\n", "self", ".", "cnn_num_layers", "=", "3", "\n", "self", ".", "filter_counts", "=", "[", "25", ",", "25", ",", "25", ",", "25", "]", "\n", "self", ".", "increasing", "=", "False", "\n", "\n", "self", ".", "dropout_rate", "=", "0.2", "\n", "self", ".", "clip", "=", "0.25", "\n", "\n", "self", ".", "dataset_name", "=", "\"dataset\"", "\n", "self", ".", "model_name", "=", "\"model\"", "\n", "self", ".", "tokenizer_name", "=", "\"tokenizer\"", "\n", "self", ".", "random", "=", "random", ".", "Random", "(", "self", ".", "random_seed", ")", "\n", "\n", "if", "filename", ":", "\n", "            ", "self", ".", "__dict__", ".", "update", "(", "json", ".", "load", "(", "open", "(", "filename", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Config.Config.to_json": [[66, 75], ["Config.Config.__dict__.keys", "json.dumps", "type", "type", "type"], "methods", ["None"], ["", "", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "'''\n        Stores all the parameters into a json \n        '''", "\n", "res", "=", "{", "}", "\n", "for", "k", "in", "self", ".", "__dict__", ".", "keys", "(", ")", ":", "\n", "            ", "if", "type", "(", "self", ".", "__dict__", "[", "k", "]", ")", "is", "str", "or", "type", "(", "self", ".", "__dict__", "[", "k", "]", ")", "is", "float", "or", "type", "(", "self", ".", "__dict__", "[", "k", "]", ")", "is", "int", ":", "\n", "                ", "res", "[", "k", "]", "=", "self", ".", "__dict__", "[", "k", "]", "\n", "", "", "return", "json", ".", "dumps", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Config.Config.save_config": [[76, 85], ["open", "fout.write", "fout.write", "os.path.join", "Config.Config.to_json"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.Config.Config.to_json"], ["", "def", "save_config", "(", "self", ",", "exp_dir", ")", ":", "\n", "        ", "'''\n        Saves the parameters used for training in experiment directory \n\n        param exp_dir: experiment directory to save configuration \n        '''", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"config.json\"", ")", ",", "'w'", ")", "as", "fout", ":", "\n", "            ", "fout", ".", "write", "(", "self", ".", "to_json", "(", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Config.Config.update_dataset": [[86, 91], ["str.split"], "methods", ["None"], ["", "", "def", "update_dataset", "(", "self", ")", ":", "\n", "        ", "'''\n        Updates the dataset appropriately by looking at the training filename \n        '''", "\n", "self", ".", "dataset_name", "=", "'/'", ".", "join", "(", "str", ".", "split", "(", "self", ".", "train_file", ",", "'/'", ")", "[", "1", ":", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Tokenizer.Char.tokenize": [[23, 31], ["list"], "methods", ["None"], ["    ", "def", "tokenize", "(", "self", ",", "string", ")", ":", "\n", "        ", "'''\n        Converts string to list of characters \n\n        param string: string to tokenize\n        return: list of characters in string \n        '''", "\n", "return", "list", "(", "string", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.iesl_stance.objects.Vocab.Vocab.__init__": [[23, 37], ["Vocab.Vocab.load", "int", "len"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.Vocab.Vocab.load"], ["    ", "def", "__init__", "(", "self", ",", "filename", ",", "tokenizer", ",", "max_len_token", ")", ":", "\n", "        ", "'''\n        param filename: filename of vocab \n        param tokenizer: tokenizer used to generate vocab \n        param max_len_token: maximum number of tokens \n        '''", "\n", "self", ".", "filename", "=", "filename", "\n", "self", ".", "OOV", "=", "\"<OOV>\"", "\n", "self", ".", "OOV_INDEX", "=", "1", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "(", "self", ".", "token2id", ",", "self", ".", "id2token", ")", "=", "self", ".", "load", "(", "self", ".", "filename", ")", "\n", "self", ".", "PADDING_INDEX", "=", "0", "\n", "self", ".", "max_len_token", "=", "int", "(", "max_len_token", ")", "\n", "self", ".", "size", "=", "len", "(", "self", ".", "token2id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Vocab.Vocab.__len__": [[38, 44], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "'''\n\n        return: vocab size\n        '''", "\n", "return", "self", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Vocab.Vocab.load": [[45, 68], ["dict", "dict", "codecs.open", "line.split", "int", "splt[].strip"], "methods", ["None"], ["", "def", "load", "(", "self", ",", "filename", ")", ":", "\n", "        ", "'''\n        Loads the vocab from file \n\n        param filename: file name of vocab \n        return: dictionary of token to id of token \n        return: dictionary of id to token \n        '''", "\n", "token2id", "=", "dict", "(", ")", "\n", "id2token", "=", "dict", "(", ")", "\n", "\n", "token2id", "[", "self", ".", "OOV", "]", "=", "self", ".", "OOV_INDEX", "\n", "id2token", "[", "self", ".", "OOV_INDEX", "]", "=", "self", ".", "OOV", "\n", "\n", "with", "codecs", ".", "open", "(", "filename", ",", "'r'", ",", "'UTF-8'", ")", "as", "fin", ":", "\n", "            ", "for", "line", "in", "fin", ":", "\n", "                ", "splt", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "item", "=", "splt", "[", "0", "]", "\n", "id", "=", "int", "(", "splt", "[", "1", "]", ".", "strip", "(", ")", ")", "\n", "token2id", "[", "item", "]", "=", "id", "\n", "id2token", "[", "id", "]", "=", "item", "\n", "\n", "", "", "return", "token2id", ",", "id2token", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Vocab.Vocab.to_ints": [[69, 89], ["numpy.asarray", "list_ints.append", "len", "numpy.asarray", "len", "Vocab.Vocab.token2id.get"], "methods", ["None"], ["", "def", "to_ints", "(", "self", ",", "list_tokens", ")", ":", "\n", "        ", "'''\n        Converts a list of tokens to list of token indices\n\n        param list_tokens: list of tokens in string \n        return: list of token indices \n        '''", "\n", "list_ints", "=", "[", "]", "\n", "\n", "for", "token", "in", "list_tokens", ":", "\n", "            ", "list_ints", ".", "append", "(", "self", ".", "token2id", ".", "get", "(", "token", ",", "self", ".", "OOV_INDEX", ")", ")", "\n", "\n", "", "if", "len", "(", "list_ints", ")", ">", "self", ".", "max_len_token", ":", "\n", "            ", "return", "np", ".", "asarray", "(", "list_ints", "[", "0", ":", "self", ".", "max_len_token", "]", ")", "\n", "\n", "# Pad the list of ints if less than max_len", "\n", "", "while", "len", "(", "list_ints", ")", "<", "self", ".", "max_len_token", ":", "\n", "            ", "list_ints", "+=", "[", "self", ".", "PADDING_INDEX", "]", "\n", "\n", "", "return", "np", ".", "asarray", "(", "list_ints", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Vocab.Vocab.to_string": [[90, 104], ["numpy.asarray", "print", "list_tokens.append", "Vocab.Vocab.id2token.get", "int"], "methods", ["None"], ["", "def", "to_string", "(", "self", ",", "list_idx", ")", ":", "\n", "        ", "'''\n        Converts a list of indices to a list of tokens \n\n        param list_idx: list of indices of tokens in string \n        return: list of tokens \n        '''", "\n", "list_tokens", "=", "[", "]", "\n", "\n", "for", "idx", "in", "list_idx", ":", "\n", "            ", "print", "(", "idx", ")", "\n", "list_tokens", ".", "append", "(", "self", ".", "id2token", ".", "get", "(", "int", "(", "idx", ")", ",", "self", ".", "OOV", ")", ")", "\n", "\n", "", "return", "np", ".", "asarray", "(", "list_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Sinkhorn.sinkhorn_normalized": [[9, 15], ["Sinkhorn.sinkhorn_loss", "Sinkhorn.sinkhorn_loss", "Sinkhorn.sinkhorn_loss"], "function", ["home.repos.pwc.inspect_result.iesl_stance.objects.Sinkhorn.sinkhorn_loss", "home.repos.pwc.inspect_result.iesl_stance.objects.Sinkhorn.sinkhorn_loss", "home.repos.pwc.inspect_result.iesl_stance.objects.Sinkhorn.sinkhorn_loss"], ["def", "sinkhorn_normalized", "(", "x", ",", "y", ",", "epsilon", ",", "n", ",", "niter", ")", ":", "\n", "\n", "    ", "Wxy", "=", "sinkhorn_loss", "(", "x", ",", "y", ",", "epsilon", ",", "n", ",", "niter", ")", "\n", "Wxx", "=", "sinkhorn_loss", "(", "x", ",", "x", ",", "epsilon", ",", "n", ",", "niter", ")", "\n", "Wyy", "=", "sinkhorn_loss", "(", "y", ",", "y", ",", "epsilon", ",", "n", ",", "niter", ")", "\n", "return", "2", "*", "Wxy", "-", "Wxx", "-", "Wyy", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Sinkhorn.batch_sinkhorn_loss": [[17, 74], ["C_mask.size", "range", "torch.exp", "mu.sum", "nu.sum", "torch.log", "Sinkhorn.batch_sinkhorn_loss.M"], "function", ["None"], ["", "def", "batch_sinkhorn_loss", "(", "C", ",", "C_mask", ",", "epsilon", "=", "1", ",", "niter", "=", "100", ")", ":", "\n", "    ", "\"\"\"\n    \n    :param C: Batch size by MSL by MSL\n    :param C_mask: Batch size by MSL by MSL \n    :param epsilon: \n    :param n: \n    :param niter: \n    :return: \n    \"\"\"", "\n", "# B by MSL", "\n", "mu", "=", "C_mask", "[", ":", ",", ":", ",", "0", "]", "\n", "mu", "=", "mu", "/", "mu", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "nu", "=", "C_mask", "[", ":", ",", "0", ",", ":", "]", "\n", "nu", "=", "nu", "/", "nu", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "# Parameters of the Sinkhorn algorithm.", "\n", "rho", "=", "1", "# (.5) **2          # unbalanced transport", "\n", "tau", "=", "-", ".8", "# nesterov-like acceleration", "\n", "lam", "=", "rho", "/", "(", "rho", "+", "epsilon", ")", "# Update exponent", "\n", "thresh", "=", "10", "**", "(", "-", "1", ")", "# stopping criterion", "\n", "\n", "def", "ave", "(", "u", ",", "u1", ")", ":", "\n", "        ", "\"Barycenter subroutine, used by kinetic acceleration through extrapolation.\"", "\n", "return", "tau", "*", "u", "+", "(", "1", "-", "tau", ")", "*", "u1", "\n", "\n", "", "def", "M", "(", "u", ",", "v", ")", ":", "\n", "        ", "\"Modified cost for logarithmic updates\"", "\n", "\"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"", "\n", "return", "(", "-", "C", "+", "u", ".", "unsqueeze", "(", "2", ")", "+", "v", ".", "unsqueeze", "(", "1", ")", ")", "/", "epsilon", "\n", "\n", "", "def", "lse", "(", "A", ",", "dim", ")", ":", "\n", "        ", "\"log-sum-exp\"", "\n", "return", "torch", ".", "log", "(", "torch", ".", "exp", "(", "A", ")", ".", "sum", "(", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "+", "1e-6", ")", "# add 10^-6 to prevent NaN", "\n", "", "batch_size", "=", "C_mask", ".", "size", "(", "0", ")", "\n", "u", ",", "v", ",", "err", "=", "0.", "*", "mu", ",", "0.", "*", "nu", ",", "0.", "\n", "actual_nits", "=", "0", "# to check if algorithm terminates because of threshold or max iterations reached", "\n", "for", "i", "in", "range", "(", "niter", ")", ":", "\n", "        ", "u1", "=", "u", "# useful to check the update", "\n", "u", "=", "epsilon", "*", "(", "\n", "torch", ".", "log", "(", "mu", ")", "# B by MSL", "\n", "-", "lse", "(", "M", "(", "u", ",", "v", ")", ",", "# M = B by MSL by MSL, lse should sum along the columns", "\n", "dim", "=", "2", ")", ".", "squeeze", "(", ")", ")", "+", "u", "\n", "v", "=", "epsilon", "*", "(", "torch", ".", "log", "(", "nu", ")", "-", "lse", "(", "M", "(", "u", ",", "v", ")", ",", "dim", "=", "1", ")", ".", "squeeze", "(", ")", ")", "+", "v", "\n", "# accelerated unbalanced iterations", "\n", "# u = ave( u, lam * ( epsilon * ( torch.log(mu) - lse(M(u,v)).squeeze()   ) + u ) )", "\n", "# v = ave( v, lam * ( epsilon * ( torch.log(nu) - lse(M(u,v).t()).squeeze() ) + v ) )", "\n", "err", "=", "(", "u", "-", "u1", ")", ".", "abs", "(", ")", ".", "sum", "(", ")", "/", "batch_size", "\n", "\n", "actual_nits", "+=", "1", "\n", "if", "(", "err", "<", "thresh", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ":", "\n", "            ", "break", "\n", "", "", "U", ",", "V", "=", "u", ",", "v", "\n", "pi", "=", "torch", ".", "exp", "(", "M", "(", "U", ",", "V", ")", ")", "# Transport plan pi = diag(a)*K*diag(b)", "\n", "return", "pi", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Sinkhorn.sinkhorn_loss": [[75, 129], ["torch.autograd.Variable", "torch.autograd.Variable", "range", "torch.exp", "torch.log", "Sinkhorn.batch_sinkhorn_loss.M"], "function", ["None"], ["", "def", "sinkhorn_loss", "(", "C", ",", "epsilon", ",", "n", ",", "niter", ")", ":", "\n", "    ", "\"\"\"\n    Given two emprical measures with n points each with locations x and y\n    outputs an approximation of the OT cost with regularization parameter epsilon\n    niter is the max. number of steps in sinkhorn loop\n    \"\"\"", "\n", "\n", "# The Sinkhorn algorithm takes as input three variables :", "\n", "\n", "# both marginals are fixed with equal weights", "\n", "mu", "=", "Variable", "(", "1.", "/", "n", "*", "torch", ".", "cuda", ".", "FloatTensor", "(", "n", ")", ".", "fill_", "(", "1", ")", ",", "requires_grad", "=", "False", ")", "\n", "nu", "=", "Variable", "(", "1.", "/", "n", "*", "torch", ".", "cuda", ".", "FloatTensor", "(", "n", ")", ".", "fill_", "(", "1", ")", ",", "requires_grad", "=", "False", ")", "\n", "# mu = Variable(1. / n * torch.FloatTensor(n).fill_(1), requires_grad=False)", "\n", "# nu = Variable(1. / n * torch.FloatTensor(n).fill_(1), requires_grad=False)", "\n", "\n", "# Parameters of the Sinkhorn algorithm.", "\n", "rho", "=", "1", "# (.5) **2          # unbalanced transport", "\n", "tau", "=", "-", ".8", "# nesterov-like acceleration", "\n", "lam", "=", "rho", "/", "(", "rho", "+", "epsilon", ")", "# Update exponent", "\n", "thresh", "=", "10", "**", "(", "-", "1", ")", "# stopping criterion", "\n", "\n", "\n", "# Elementary operations .....................................................................", "\n", "def", "ave", "(", "u", ",", "u1", ")", ":", "\n", "        ", "\"Barycenter subroutine, used by kinetic acceleration through extrapolation.\"", "\n", "return", "tau", "*", "u", "+", "(", "1", "-", "tau", ")", "*", "u1", "\n", "\n", "", "def", "M", "(", "u", ",", "v", ")", ":", "\n", "        ", "\"Modified cost for logarithmic updates\"", "\n", "\"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"", "\n", "return", "(", "-", "C", "+", "u", ".", "unsqueeze", "(", "1", ")", "+", "v", ".", "unsqueeze", "(", "0", ")", ")", "/", "epsilon", "\n", "\n", "", "def", "lse", "(", "A", ")", ":", "\n", "        ", "\"log-sum-exp\"", "\n", "return", "torch", ".", "log", "(", "torch", ".", "exp", "(", "A", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "+", "1e-6", ")", "# add 10^-6 to prevent NaN", "\n", "\n", "# Actual Sinkhorn loop ......................................................................", "\n", "", "u", ",", "v", ",", "err", "=", "0.", "*", "mu", ",", "0.", "*", "nu", ",", "0.", "\n", "actual_nits", "=", "0", "# to check if algorithm terminates because of threshold or max iterations reached", "\n", "for", "i", "in", "range", "(", "niter", ")", ":", "\n", "        ", "u1", "=", "u", "# useful to check the update", "\n", "u", "=", "epsilon", "*", "(", "torch", ".", "log", "(", "mu", ")", "-", "lse", "(", "M", "(", "u", ",", "v", ")", ")", ".", "squeeze", "(", ")", ")", "+", "u", "\n", "v", "=", "epsilon", "*", "(", "torch", ".", "log", "(", "nu", ")", "-", "lse", "(", "M", "(", "u", ",", "v", ")", ".", "t", "(", ")", ")", ".", "squeeze", "(", ")", ")", "+", "v", "\n", "# accelerated unbalanced iterations", "\n", "# u = ave( u, lam * ( epsilon * ( torch.log(mu) - lse(M(u,v)).squeeze()   ) + u ) )", "\n", "# v = ave( v, lam * ( epsilon * ( torch.log(nu) - lse(M(u,v).t()).squeeze() ) + v ) )", "\n", "err", "=", "(", "u", "-", "u1", ")", ".", "abs", "(", ")", ".", "sum", "(", ")", "\n", "\n", "actual_nits", "+=", "1", "\n", "if", "(", "err", "<", "thresh", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ":", "\n", "            ", "break", "\n", "", "", "U", ",", "V", "=", "u", ",", "v", "\n", "pi", "=", "torch", ".", "exp", "(", "M", "(", "U", ",", "V", ")", ")", "# Transport plan pi = diag(a)*K*diag(b)", "\n", "return", "pi", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.__init__": [[26, 67], ["Batcher.Batcher.train_load_data", "Batcher.Batcher.train_shuffle_data", "Batcher.Batcher.dev_test_load_data"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.train_load_data", "home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.train_shuffle_data", "home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.dev_test_load_data"], ["\t", "def", "__init__", "(", "self", ",", "config", ",", "input_type", ",", "tokenizer", ",", "labeled_file", "=", "None", ")", ":", "\n", "\t\t", "'''\n\t\tparam config: configuration object \n\t\tparam input_type: whether the batcher is for train/dev/test\n\t\tparam tokenizer: tokenizer object \n\t\tparam labeled_file: labeled file to use for labels (default is specified in config )\n\t\t'''", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "\n", "if", "input_type", "==", "'train'", ":", "\n", "\t\t\t", "self", ".", "train_batch_size", "=", "config", ".", "train_batch_size", "\n", "", "else", ":", "\n", "\t\t\t", "self", ".", "dev_test_batch_size", "=", "config", ".", "dev_test_batch_size", "\n", "\n", "", "self", ".", "all_qry_tk", "=", "[", "]", "\n", "self", ".", "all_pos_tk", "=", "[", "]", "\n", "self", ".", "all_neg_tk", "=", "[", "]", "\n", "self", ".", "all_cnd_tk", "=", "[", "]", "\n", "\n", "self", ".", "all_qry", "=", "[", "]", "\n", "self", ".", "all_cnd", "=", "[", "]", "\n", "self", ".", "all_lbl", "=", "[", "]", "\n", "\n", "if", "input_type", "==", "'train'", ":", "\n", "\t\t\t", "self", ".", "input_file", "=", "config", ".", "train_file", "\n", "self", ".", "train_load_data", "(", ")", "\n", "self", ".", "train_shuffle_data", "(", ")", "\n", "", "else", ":", "\n", "\t\t\t", "if", "input_type", "==", "'dev'", ":", "\n", "\t\t\t\t", "self", ".", "input_file", "=", "config", ".", "dev_file", "\n", "", "else", ":", "\n", "# For partitioning test file to parallelize, so test_file won't be config but will be passed in", "\n", "\t\t\t\t", "if", "labeled_file", "is", "not", "None", ":", "\n", "\t\t\t\t\t", "self", ".", "input_file", "=", "labeled_file", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "self", ".", "input_file", "=", "config", ".", "test_file", "\n", "", "", "self", ".", "dev_test_load_data", "(", ")", "\n", "\n", "", "self", ".", "input_type", "=", "input_type", "\n", "self", ".", "start_idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.get_next_dev_test_end_idx": [[69, 82], ["None"], "methods", ["None"], ["", "def", "get_next_dev_test_end_idx", "(", "self", ",", "cur_qry", ")", ":", "\n", "\t\t", "'''\n\t\tGet the next batch end index such that every batch has the same query to calculate MAP without writing predictions\n\n\t\tparam cur_qry: current query of the current batch \n\t\t'''", "\n", "end_idx", "=", "self", ".", "start_idx", "\n", "\n", "# After breaking out of for loop, end_idx will point to first qry_tk that doesn't match cur_qry_tk", "\n", "while", "(", "end_idx", "<", "self", ".", "num_examples", "and", "self", ".", "all_qry", "[", "end_idx", "]", "==", "cur_qry", ")", ":", "\n", "\t\t\t", "end_idx", "+=", "1", "\n", "\n", "", "return", "end_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.get_dev_test_batches": [[83, 110], ["Batcher.Batcher.get_next_dev_test_end_idx"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.get_next_dev_test_end_idx"], ["", "def", "get_dev_test_batches", "(", "self", ")", ":", "\n", "\t\t", "'''\n\t\tReturns all the dev or test batches\n\t\t'''", "\n", "self", ".", "start_idx", "=", "0", "\n", "cur_qry", "=", "self", ".", "all_qry", "[", "self", ".", "start_idx", "]", "\n", "\n", "while", "True", ":", "\n", "\t\t\t", "if", "self", ".", "start_idx", ">=", "self", ".", "num_examples", ":", "\n", "\t\t\t\t", "return", "\n", "", "else", ":", "\n", "\t\t\t\t", "end_idx", "=", "self", ".", "get_next_dev_test_end_idx", "(", "cur_qry", ")", "\n", "\n", "if", "end_idx", ">", "self", ".", "start_idx", "+", "self", ".", "dev_test_batch_size", ":", "\n", "\t\t\t\t\t", "end_idx", "=", "self", ".", "start_idx", "+", "self", ".", "dev_test_batch_size", "\n", "\n", "", "if", "end_idx", "<", "self", ".", "num_examples", ":", "\n", "\t\t\t\t\t", "cur_qry", "=", "self", ".", "all_qry", "[", "end_idx", "]", "\n", "", "end_block", "=", "(", "end_idx", ">=", "self", ".", "num_examples", "or", "self", ".", "all_qry", "[", "end_idx", "-", "1", "]", "!=", "self", ".", "all_qry", "[", "end_idx", "]", ")", "\n", "\n", "yield", "self", ".", "all_qry_tk", "[", "self", ".", "start_idx", ":", "end_idx", "]", ",", "self", ".", "all_qry", "[", "self", ".", "start_idx", ":", "end_idx", "]", ",", "self", ".", "all_cnd_tk", "[", "self", ".", "start_idx", ":", "end_idx", "]", ",", "self", ".", "all_cnd", "[", "self", ".", "start_idx", ":", "end_idx", "]", ",", "self", ".", "all_lbl", "[", "self", ".", "start_idx", ":", "end_idx", "]", ",", "end_block", "\n", "self", ".", "start_idx", "=", "end_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.get_train_batches": [[111, 125], ["Batcher.Batcher.train_shuffle_data"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.train_shuffle_data"], ["", "", "", "def", "get_train_batches", "(", "self", ")", ":", "\n", "\t\t", "'''\n\t\tReturns all the train batches, where each batch includes examples with the same query \n\t\t'''", "\n", "while", "True", ":", "\n", "\t\t\t", "if", "self", ".", "start_idx", ">", "self", ".", "num_examples", "-", "self", ".", "train_batch_size", ":", "\n", "\t\t\t\t", "self", ".", "start_idx", "=", "0", "\n", "self", ".", "train_shuffle_data", "(", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "end_idx", "=", "self", ".", "start_idx", "+", "self", ".", "train_batch_size", "\n", "yield", "self", ".", "all_qry_tk", "[", "self", ".", "start_idx", ":", "end_idx", "]", ",", "self", ".", "all_pos_tk", "[", "self", ".", "start_idx", ":", "end_idx", "]", ",", "self", ".", "all_neg_tk", "[", "self", ".", "start_idx", ":", "end_idx", "]", "\n", "self", ".", "start_idx", "=", "end_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.train_shuffle_data": [[126, 133], ["numpy.random.permutation", "len"], "methods", ["None"], ["", "", "", "def", "train_shuffle_data", "(", "self", ")", ":", "\n", "\t\t", "'''\n\t\tShuffles the training data, maintining the permutation across query, positive, and negative tokens \n\t\t'''", "\n", "perm", "=", "np", ".", "random", ".", "permutation", "(", "self", ".", "num_examples", ")", "# perm of index in range(0, num_questions)", "\n", "assert", "len", "(", "perm", ")", "==", "self", ".", "num_examples", "\n", "self", ".", "all_qry_tk", ",", "self", ".", "all_pos_tk", ",", "self", ".", "all_neg_tk", "=", "self", ".", "all_qry_tk", "[", "perm", "]", ",", "self", ".", "all_pos_tk", "[", "perm", "]", ",", "self", ".", "all_neg_tk", "[", "perm", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.dev_test_load_data": [[134, 152], ["numpy.asarray", "numpy.asarray", "numpy.asarray", "len", "open", "f.readlines", "line.strip().split", "Batcher.Batcher.all_qry_tk.append", "Batcher.Batcher.all_qry.append", "Batcher.Batcher.all_cnd_tk.append", "Batcher.Batcher.all_cnd.append", "Batcher.Batcher.all_lbl.append", "Batcher.Batcher.tokenizer.tokenize", "Batcher.Batcher.tokenizer.tokenize", "int", "line.strip"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.Tokenizer.Char.tokenize", "home.repos.pwc.inspect_result.iesl_stance.objects.Tokenizer.Char.tokenize"], ["", "def", "dev_test_load_data", "(", "self", ")", ":", "\n", "\t\t", "'''\n\t\tLoads and stores the tokens for dev/test data \n\t\t'''", "\n", "with", "open", "(", "self", ".", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "\t\t\t\t", "split", "=", "line", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "\n", "self", ".", "all_qry_tk", ".", "append", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "split", "[", "0", "]", ")", ")", "\n", "self", ".", "all_qry", ".", "append", "(", "split", "[", "0", "]", ")", "\n", "self", ".", "all_cnd_tk", ".", "append", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "split", "[", "1", "]", ")", ")", "\n", "self", ".", "all_cnd", ".", "append", "(", "split", "[", "1", "]", ")", "\n", "self", ".", "all_lbl", ".", "append", "(", "int", "(", "split", "[", "2", "]", ")", ")", "\n", "\n", "", "", "self", ".", "all_qry_tk", "=", "np", ".", "asarray", "(", "self", ".", "all_qry_tk", ")", "\n", "self", ".", "all_cnd_tk", "=", "np", ".", "asarray", "(", "self", ".", "all_cnd_tk", ")", "\n", "self", ".", "all_lbl", "=", "np", ".", "asarray", "(", "self", ".", "all_lbl", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "num_examples", "=", "len", "(", "self", ".", "all_qry_tk", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.iesl_stance.objects.Batcher.Batcher.train_load_data": [[153, 173], ["numpy.asarray", "numpy.asarray", "numpy.asarray", "len", "codecs.open", "line.encode().strip().decode().split", "Batcher.Batcher.all_qry_tk.append", "Batcher.Batcher.all_pos_tk.append", "Batcher.Batcher.all_neg_tk.append", "len", "print", "Batcher.Batcher.tokenizer.tokenize", "Batcher.Batcher.tokenizer.tokenize", "Batcher.Batcher.tokenizer.tokenize", "line.encode().strip().decode", "Batcher.Batcher.tokenizer.tokenize", "line.encode().strip", "line.encode"], "methods", ["home.repos.pwc.inspect_result.iesl_stance.objects.Tokenizer.Char.tokenize", "home.repos.pwc.inspect_result.iesl_stance.objects.Tokenizer.Char.tokenize", "home.repos.pwc.inspect_result.iesl_stance.objects.Tokenizer.Char.tokenize", "home.repos.pwc.inspect_result.iesl_stance.objects.Tokenizer.Char.tokenize"], ["", "def", "train_load_data", "(", "self", ")", ":", "\n", "\t\t", "'''\n\t\tLoads and stores the tokens for test data \n\t\t'''", "\n", "with", "codecs", ".", "open", "(", "self", ".", "input_file", ",", "\"r\"", ",", "\"UTF-8\"", ",", "errors", "=", "\"ignore\"", ")", "as", "inp", ":", "\n", "\t\t\t", "for", "line", "in", "inp", ":", "\n", "\t\t\t\t", "split", "=", "line", ".", "encode", "(", "\"UTF-8\"", ")", ".", "strip", "(", ")", ".", "decode", "(", "\"UTF-8\"", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "\n", "if", "(", "len", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "split", "[", "0", "]", ")", ")", "<=", "0", ")", ":", "\n", "\t\t\t\t\t", "print", "(", "line", ")", "\n", "raise", "ValueError", "\n", "\n", "", "self", ".", "all_qry_tk", ".", "append", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "split", "[", "0", "]", ")", ")", "\n", "self", ".", "all_pos_tk", ".", "append", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "split", "[", "1", "]", ")", ")", "\n", "self", ".", "all_neg_tk", ".", "append", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "split", "[", "2", "]", ")", ")", "\n", "\n", "", "", "self", ".", "all_qry_tk", "=", "np", ".", "asarray", "(", "self", ".", "all_qry_tk", ")", "\n", "self", ".", "all_pos_tk", "=", "np", ".", "asarray", "(", "self", ".", "all_pos_tk", ")", "\n", "self", ".", "all_neg_tk", "=", "np", ".", "asarray", "(", "self", ".", "all_neg_tk", ")", "\n", "self", ".", "num_examples", "=", "len", "(", "self", ".", "all_qry_tk", ")", "\n", "", "", ""]]}