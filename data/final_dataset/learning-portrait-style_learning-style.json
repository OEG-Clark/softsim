{"home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.ArtDataset.__init__": [[215, 228], ["metadata_df.reset_index"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "image_folder", ",", "triplet_df", ",", "metadata_df", ",", "largest_height", ",", "largest_width", ",", "transform", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            image_folder (string): Directory with all the images.\n            metadata_df (Pandas Dataframe): Dataframe containing the metadata\n            transform (Torchvision.Transform) Transform to be applied to the image data\n        \"\"\"", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "metadata", "=", "metadata_df", ".", "reset_index", "(", ")", "\n", "self", ".", "triplets", "=", "triplet_df", "\n", "self", ".", "image_folder", "=", "image_folder", "\n", "self", ".", "largest_height", "=", "largest_height", "\n", "self", ".", "largest_width", "=", "largest_width", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.ArtDataset.__len__": [[229, 231], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "triplets", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.ArtDataset.return_transformed_image": [[232, 238], ["PIL.Image.open", "vae_trip.ArtDataset.transform", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d.", "os.path.join"], "methods", ["None"], ["", "def", "return_transformed_image", "(", "self", ",", "image_filename", ")", ":", "\n", "        ", "image", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "image_folder", ",", "image_filename", ")", ")", "\n", "(", "width", ",", "height", ")", "=", "image", ".", "size", "\n", "tensor_image", "=", "self", ".", "transform", "(", "image", ")", "\n", "pad_layer", "=", "nn", ".", "ZeroPad2d", "(", "(", "0", ",", "self", ".", "largest_width", "-", "width", ",", "0", ",", "self", ".", "largest_height", "-", "height", ")", ")", "\n", "return", "pad_layer", "(", "tensor_image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.ArtDataset.get_random_artist_image": [[239, 243], ["random.choice"], "methods", ["None"], ["", "def", "get_random_artist_image", "(", "self", ",", "artist", ")", ":", "\n", "        ", "artist_indices", "=", "self", ".", "metadata", "[", "self", ".", "metadata", "[", "'cleaned_artist'", "]", "==", "artist", "]", ".", "index", "\n", "random_artist_idx", "=", "random", ".", "choice", "(", "artist_indices", ")", "\n", "return", "self", ".", "metadata", ".", "iloc", "[", "random_artist_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.ArtDataset.__getitem__": [[244, 297], ["zip", "int", "vae_trip.ArtDataset.return_transformed_image"], "methods", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.ArtDataset.return_transformed_image"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "      ", "row", "=", "self", ".", "triplets", ".", "iloc", "[", "idx", "]", "\n", "\n", "positive_idx", "=", "int", "(", "row", "[", "'Positive'", "]", ")", "-", "1", "\n", "negative_idx", "=", "(", "1", "-", "positive_idx", ")", "\n", "\n", "triplet_names", "=", "[", "'1'", ",", "'2'", ",", "'anchor'", "]", "\n", "\n", "# Re-Arranges it so now it's of the form positive, negative, anchor.", "\n", "triplet_files", "=", "[", "row", "[", "triplet_names", "[", "positive_idx", "]", "]", ",", "row", "[", "triplet_names", "[", "negative_idx", "]", "]", ",", "row", "[", "triplet_names", "[", "2", "]", "]", "]", "\n", "labels", "=", "[", "'positive'", ",", "'negative'", ",", "'anchor'", "]", "\n", "\n", "triplet_objects", "=", "{", "}", "\n", "\n", "for", "filename", ",", "label", "in", "zip", "(", "triplet_files", ",", "labels", ")", ":", "\n", "        ", "triplet_object", "=", "{", "}", "\n", "\n", "triplet_image", "=", "{", "}", "\n", "triplet_corresponding", "=", "{", "}", "\n", "\n", "image_metadata", "=", "self", ".", "metadata", ".", "loc", "[", "self", ".", "metadata", "[", "'filename'", "]", "==", "filename", "]", "\n", "image_name", "=", "image_metadata", "[", "'filename'", "]", ".", "values", "[", "0", "]", "\n", "\n", "triplet_image", "[", "'artist'", "]", "=", "image_metadata", "[", "'cleaned_artist'", "]", ".", "values", "[", "0", "]", "\n", "triplet_image", "[", "'image'", "]", "=", "self", ".", "return_transformed_image", "(", "image_name", ")", "\n", "\n", "triplet_image", "[", "'normalized_midpoint'", "]", "=", "image_metadata", "[", "'normalized_midpoint'", "]", ".", "values", "[", "0", "]", "\n", "triplet_image", "[", "'normalized_start'", "]", "=", "image_metadata", "[", "'normalized_start'", "]", ".", "values", "[", "0", "]", "\n", "triplet_image", "[", "'normalized_end'", "]", "=", "image_metadata", "[", "'normalized_end'", "]", ".", "values", "[", "0", "]", "\n", "\n", "triplet_image", "[", "'width'", "]", "=", "image_metadata", "[", "'width'", "]", ".", "values", "[", "0", "]", "\n", "triplet_image", "[", "'height'", "]", "=", "image_metadata", "[", "'height'", "]", ".", "values", "[", "0", "]", "\n", "\n", "#random_artist = self.get_random_artist_image(triplet_image['artist'])", "\n", "\n", "#triplet_corresponding['image'] = self.return_transformed_image(random_artist['filename'])", "\n", "#triplet_corresponding['filename'] = random_artist['filename']", "\n", "\n", "#triplet_corresponding['normalized_midpoint'] = random_artist['normalized_midpoint']", "\n", "#triplet_corresponding['normalized_start'] = random_artist['normalized_start']", "\n", "#triplet_corresponding['normalized_end'] = random_artist['normalized_end']", "\n", "\n", "#triplet_corresponding['width'] = random_artist['width']", "\n", "#triplet_corresponding['height'] = random_artist['height']", "\n", "\n", "#triplet_corresponding['should_mask'] = (random_artist['filename'] == image_metadata['filename'].values[0])", "\n", "\n", "triplet_object", "[", "'triplet'", "]", "=", "triplet_image", "\n", "#triplet_object['corresponding'] = triplet_corresponding", "\n", "\n", "triplet_objects", "[", "label", "]", "=", "triplet_object", "\n", "\n", "", "return", "triplet_objects", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.VAE_latent_artist_discriminator.__init__": [[433, 439], ["torch.Module.__init__", "vae_trip.VAE_latent_artist_discriminator.initialize_latent_artist_discriminator", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.TRIPLET_VGG.__init__", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_latent_artist_discriminator.initialize_latent_artist_discriminator"], ["  ", "def", "__init__", "(", "self", ",", "encoding_length", ")", ":", "\n", "        ", "super", "(", "VAE_latent_artist_discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "encoding_length", "=", "encoding_length", "\n", "self", ".", "initialize_latent_artist_discriminator", "(", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.VAE_latent_artist_discriminator.initialize_latent_artist_discriminator": [[446, 456], ["torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "int", "int", "int", "int", "int", "int", "int"], "methods", ["None"], ["", "def", "initialize_latent_artist_discriminator", "(", "self", ")", ":", "\n", "      ", "self", ".", "latent_artist_discriminate_1", "=", "nn", ".", "Linear", "(", "2", "*", "self", ".", "encoding_length", ",", "self", ".", "encoding_length", "*", "4", ")", "\n", "self", ".", "latent_artist_bn_1", "=", "nn", ".", "BatchNorm1d", "(", "self", ".", "encoding_length", "*", "4", ")", "\n", "self", ".", "latent_artist_discriminate_2", "=", "nn", ".", "Linear", "(", "self", ".", "encoding_length", "*", "4", ",", "self", ".", "encoding_length", "*", "2", ")", "\n", "self", ".", "latent_artist_bn_2", "=", "nn", ".", "BatchNorm1d", "(", "self", ".", "encoding_length", "*", "2", ")", "\n", "self", ".", "latent_artist_discriminate_3", "=", "nn", ".", "Linear", "(", "int", "(", "self", ".", "encoding_length", "*", "2", ")", ",", "int", "(", "self", ".", "encoding_length", ")", ")", "\n", "self", ".", "latent_artist_bn_3", "=", "nn", ".", "BatchNorm1d", "(", "int", "(", "self", ".", "encoding_length", ")", ")", "\n", "self", ".", "latent_artist_discriminate_4", "=", "nn", ".", "Linear", "(", "int", "(", "self", ".", "encoding_length", ")", ",", "int", "(", "self", ".", "encoding_length", "/", "2", ")", ")", "\n", "self", ".", "latent_artist_bn_4", "=", "nn", ".", "BatchNorm1d", "(", "int", "(", "self", ".", "encoding_length", "/", "2", ")", ")", "\n", "self", ".", "latent_artist_discriminate_5", "=", "nn", ".", "Linear", "(", "int", "(", "self", ".", "encoding_length", "/", "2", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.VAE_latent_artist_discriminator.latent_artist_discriminator_forward": [[463, 470], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "vae_trip.VAE_latent_artist_discriminator.latent_artist_discriminate_5", "vae_trip.VAE_latent_artist_discriminator.sigmoid", "vae_trip.VAE_latent_artist_discriminator.latent_artist_bn_1", "vae_trip.VAE_latent_artist_discriminator.latent_artist_bn_2", "vae_trip.VAE_latent_artist_discriminator.latent_artist_bn_3", "vae_trip.VAE_latent_artist_discriminator.latent_artist_bn_4", "vae_trip.VAE_latent_artist_discriminator.latent_artist_discriminate_1", "vae_trip.VAE_latent_artist_discriminator.latent_artist_discriminate_2", "vae_trip.VAE_latent_artist_discriminator.latent_artist_discriminate_3", "vae_trip.VAE_latent_artist_discriminator.latent_artist_discriminate_4"], "methods", ["None"], ["", "def", "latent_artist_discriminator_forward", "(", "self", ",", "x", ")", ":", "\n", "      ", "x", "=", "F", ".", "relu", "(", "self", ".", "latent_artist_bn_1", "(", "self", ".", "latent_artist_discriminate_1", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "latent_artist_bn_2", "(", "self", ".", "latent_artist_discriminate_2", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "latent_artist_bn_3", "(", "self", ".", "latent_artist_discriminate_3", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "latent_artist_bn_4", "(", "self", ".", "latent_artist_discriminate_4", "(", "x", ")", ")", ")", "\n", "x", "=", "self", ".", "latent_artist_discriminate_5", "(", "x", ")", "\n", "return", "self", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.VAE_latent_artist_discriminator.forward": [[471, 473], ["vae_trip.VAE_latent_artist_discriminator.latent_artist_discriminator_forward"], "methods", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_latent_artist_discriminator.latent_artist_discriminator_forward"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "      ", "return", "self", ".", "latent_artist_discriminator_forward", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.VAE_base.__init__": [[478, 490], ["torch.Module.__init__", "vae_trip.VAE_base.initialize_base_vae_enocder", "vae_trip.VAE_base.initialize_base_vae_reparameterization", "vae_trip.VAE_base.initialize_base_vae_decoder", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.TRIPLET_VGG.__init__", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_base.initialize_base_vae_enocder", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_base.initialize_base_vae_reparameterization", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_base.initialize_base_vae_decoder"], ["    ", "def", "__init__", "(", "self", ",", "latent_size", ",", "artist_latent_size", ",", "num_artists", ")", ":", "\n", "        ", "super", "(", "VAE_base", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "latent_size", "=", "latent_size", "\n", "self", ".", "artist_latent_size", "=", "artist_latent_size", "\n", "self", ".", "num_artists", "=", "num_artists", "\n", "\n", "self", ".", "initialize_base_vae_enocder", "(", ")", "\n", "self", ".", "initialize_base_vae_reparameterization", "(", ")", "\n", "self", ".", "initialize_base_vae_decoder", "(", ")", "\n", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.VAE_base.initialize_base_vae_enocder": [[501, 520], ["torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["None"], ["", "def", "initialize_base_vae_enocder", "(", "self", ")", ":", "\n", "        ", "self", ".", "base_encode_conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "8", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "base_conv1_bn", "=", "nn", ".", "BatchNorm2d", "(", "8", ")", "\n", "self", ".", "base_encode_conv2", "=", "nn", ".", "Conv2d", "(", "8", ",", "16", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "base_conv2_bn", "=", "nn", ".", "BatchNorm2d", "(", "16", ")", "\n", "self", ".", "base_encode_conv3", "=", "nn", ".", "Conv2d", "(", "16", ",", "32", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "base_conv3_bn", "=", "nn", ".", "BatchNorm2d", "(", "32", ")", "\n", "self", ".", "base_encode_conv4", "=", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "base_conv4_bn", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "base_encode_conv5", "=", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "base_conv5_bn", "=", "nn", ".", "BatchNorm2d", "(", "128", ")", "\n", "self", ".", "base_encode_conv6", "=", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "base_conv6_bn", "=", "nn", ".", "BatchNorm2d", "(", "256", ")", "\n", "\n", "self", ".", "base_encode_conv7", "=", "nn", ".", "Conv2d", "(", "256", ",", "512", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "base_conv7_bn", "=", "nn", ".", "BatchNorm2d", "(", "512", ")", "\n", "\n", "self", ".", "base_encode_conv8", "=", "nn", ".", "Conv2d", "(", "512", ",", "1024", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "base_conv8_bn", "=", "nn", ".", "BatchNorm2d", "(", "1024", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.VAE_base.initialize_base_vae_reparameterization": [[521, 525], ["torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["None"], ["", "def", "initialize_base_vae_reparameterization", "(", "self", ")", ":", "\n", "        ", "self", ".", "base_ln_encode_mean", "=", "nn", ".", "Linear", "(", "4096", ",", "self", ".", "latent_size", ")", "\n", "self", ".", "base_ln_encode_variance", "=", "nn", ".", "Linear", "(", "4096", ",", "self", ".", "latent_size", ")", "\n", "self", ".", "base_ln_decode_variance", "=", "nn", ".", "Linear", "(", "self", ".", "latent_size", ",", "4096", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.VAE_base.initialize_base_vae_decoder": [[526, 544], ["torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["None"], ["", "def", "initialize_base_vae_decoder", "(", "self", ")", ":", "\n", "        ", "self", ".", "base_decode_trans_conv1", "=", "nn", ".", "ConvTranspose2d", "(", "4096", ",", "512", ",", "(", "5", ",", "4", ")", ",", "stride", "=", "2", ")", "\n", "self", ".", "base_conv1_trans_bn", "=", "nn", ".", "BatchNorm2d", "(", "512", ")", "\n", "self", ".", "base_decode_trans_conv2", "=", "nn", ".", "ConvTranspose2d", "(", "512", ",", "256", ",", "5", ",", "stride", "=", "2", ")", "\n", "self", ".", "base_conv2_trans_bn", "=", "nn", ".", "BatchNorm2d", "(", "256", ")", "\n", "self", ".", "base_decode_trans_conv3", "=", "nn", ".", "ConvTranspose2d", "(", "256", ",", "128", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "base_conv3_trans_bn", "=", "nn", ".", "BatchNorm2d", "(", "128", ")", "\n", "self", ".", "base_decode_trans_conv4", "=", "nn", ".", "ConvTranspose2d", "(", "128", ",", "64", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "base_conv4_trans_bn", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "base_decode_trans_conv5", "=", "nn", ".", "ConvTranspose2d", "(", "64", ",", "32", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "(", "0", ",", "1", ")", ")", "\n", "self", ".", "base_conv5_trans_bn", "=", "nn", ".", "BatchNorm2d", "(", "32", ")", "\n", "self", ".", "base_decode_trans_conv6", "=", "nn", ".", "ConvTranspose2d", "(", "32", ",", "16", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "(", "0", ",", "1", ")", ")", "\n", "self", ".", "base_conv6_trans_bn", "=", "nn", ".", "BatchNorm2d", "(", "16", ")", "\n", "self", ".", "base_decode_trans_conv7", "=", "nn", ".", "ConvTranspose2d", "(", "16", ",", "8", ",", "3", ",", "stride", "=", "2", ")", "\n", "self", ".", "base_conv7_trans_bn", "=", "nn", ".", "BatchNorm2d", "(", "8", ")", "\n", "self", ".", "base_decode_trans_conv8", "=", "nn", ".", "ConvTranspose2d", "(", "8", ",", "3", ",", "3", ",", "stride", "=", "1", ")", "\n", "#self.base_conv8_trans_bn = nn.BatchNorm2d(4)", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.VAE_base.vae_base_encode": [[551, 567], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "vae_trip.VAE_base.base_conv1_bn", "vae_trip.VAE_base.base_conv2_bn", "vae_trip.VAE_base.base_conv3_bn", "vae_trip.VAE_base.base_conv4_bn", "vae_trip.VAE_base.base_conv5_bn", "vae_trip.VAE_base.base_conv6_bn", "vae_trip.VAE_base.base_conv7_bn", "vae_trip.VAE_base.base_conv8_bn", "vae_trip.VAE_base.base_ln_encode_mean", "vae_trip.VAE_base.base_ln_encode_variance", "vae_trip.VAE_base.base_encode_conv1", "vae_trip.VAE_base.base_encode_conv2", "vae_trip.VAE_base.base_encode_conv3", "vae_trip.VAE_base.base_encode_conv4", "vae_trip.VAE_base.base_encode_conv5", "vae_trip.VAE_base.base_encode_conv6", "vae_trip.VAE_base.base_encode_conv7", "vae_trip.VAE_base.base_encode_conv8", "torch.relu.view", "torch.relu.view"], "methods", ["None"], ["", "def", "vae_base_encode", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "base_conv1_bn", "(", "self", ".", "base_encode_conv1", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "base_conv2_bn", "(", "self", ".", "base_encode_conv2", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "base_conv3_bn", "(", "self", ".", "base_encode_conv3", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "base_conv4_bn", "(", "self", ".", "base_encode_conv4", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "base_conv5_bn", "(", "self", ".", "base_encode_conv5", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "base_conv6_bn", "(", "self", ".", "base_encode_conv6", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "base_conv7_bn", "(", "self", ".", "base_encode_conv7", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "base_conv8_bn", "(", "self", ".", "base_encode_conv8", "(", "x", ")", ")", ")", "\n", "\n", "mean", ",", "log_variance", "=", "self", ".", "base_ln_encode_mean", "(", "x", ".", "view", "(", "-", "1", ",", "4096", ")", ")", ",", "self", ".", "base_ln_encode_variance", "(", "x", ".", "view", "(", "-", "1", ",", "4096", ")", ")", "\n", "std", "=", "torch", ".", "exp", "(", "0.5", "*", "log_variance", ")", "\n", "ns", "=", "torch", ".", "randn_like", "(", "std", ")", "\n", "z", "=", "ns", "*", "std", "+", "mean", "\n", "\n", "return", "z", ",", "mean", ",", "log_variance", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.VAE_base.vae_base_decode": [[568, 580], ["vae_trip.VAE_base.base_ln_decode_variance", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "vae_trip.VAE_base.base_decode_trans_conv8", "vae_trip.VAE_base.sigmoid", "vae_trip.VAE_base.base_conv1_trans_bn", "vae_trip.VAE_base.base_conv2_trans_bn", "vae_trip.VAE_base.base_conv3_trans_bn", "vae_trip.VAE_base.base_conv4_trans_bn", "vae_trip.VAE_base.base_conv5_trans_bn", "vae_trip.VAE_base.base_conv6_trans_bn", "vae_trip.VAE_base.base_conv7_trans_bn", "vae_trip.VAE_base.base_decode_trans_conv1", "vae_trip.VAE_base.base_decode_trans_conv2", "vae_trip.VAE_base.base_decode_trans_conv3", "vae_trip.VAE_base.base_decode_trans_conv4", "vae_trip.VAE_base.base_decode_trans_conv5", "vae_trip.VAE_base.base_decode_trans_conv6", "vae_trip.VAE_base.base_decode_trans_conv7", "vae_trip.VAE_base.view"], "methods", ["None"], ["", "def", "vae_base_decode", "(", "self", ",", "variance", ")", ":", "\n", "        ", "z", "=", "self", ".", "base_ln_decode_variance", "(", "variance", ")", "\n", "z", "=", "F", ".", "relu", "(", "self", ".", "base_conv1_trans_bn", "(", "self", ".", "base_decode_trans_conv1", "(", "z", ".", "view", "(", "-", "1", ",", "4096", ",", "1", ",", "1", ")", ")", ")", ")", "\n", "z", "=", "F", ".", "relu", "(", "self", ".", "base_conv2_trans_bn", "(", "self", ".", "base_decode_trans_conv2", "(", "z", ")", ")", ")", "\n", "z", "=", "F", ".", "relu", "(", "self", ".", "base_conv3_trans_bn", "(", "self", ".", "base_decode_trans_conv3", "(", "z", ")", ")", ")", "\n", "z", "=", "F", ".", "relu", "(", "self", ".", "base_conv4_trans_bn", "(", "self", ".", "base_decode_trans_conv4", "(", "z", ")", ")", ")", "\n", "z", "=", "F", ".", "relu", "(", "self", ".", "base_conv5_trans_bn", "(", "self", ".", "base_decode_trans_conv5", "(", "z", ")", ")", ")", "\n", "z", "=", "F", ".", "relu", "(", "self", ".", "base_conv6_trans_bn", "(", "self", ".", "base_decode_trans_conv6", "(", "z", ")", ")", ")", "\n", "z", "=", "F", ".", "relu", "(", "self", ".", "base_conv7_trans_bn", "(", "self", ".", "base_decode_trans_conv7", "(", "z", ")", ")", ")", "\n", "z", "=", "self", ".", "base_decode_trans_conv8", "(", "z", ")", "\n", "\n", "return", "self", ".", "sigmoid", "(", "z", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.VAE_base.forward": [[581, 586], ["vae_trip.VAE_base.vae_base_encode", "vae_trip.VAE_base.vae_base_decode"], "methods", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_base.vae_base_encode", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_base.vae_base_decode"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "z", ",", "mean", ",", "log_variance", "=", "self", ".", "vae_base_encode", "(", "x", ")", "\n", "output_image", "=", "self", ".", "vae_base_decode", "(", "z", ")", "\n", "\n", "return", "output_image", ",", "mean", ",", "log_variance", ",", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.PercepLoss.__init__": [[614, 632], ["super().__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "range", "range", "range", "torchvision.models.vgg16", "torchvision.models.vgg16", "vae_trip.PercepLoss.slice1.add_module", "vae_trip.PercepLoss.slice2.add_module", "vae_trip.PercepLoss.slice3.add_module", "vae_trip.PercepLoss.parameters", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.TRIPLET_VGG.__init__"], ["    ", "def", "__init__", "(", "self", ",", "requires_grad", "=", "False", ")", ":", "\n", "        ", "super", "(", "PercepLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "vgg_pretrained_features", "=", "models", ".", "vgg16", "(", "pretrained", "=", "True", ")", ".", "features", "\n", "self", ".", "slice1", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice2", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice3", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "#self.slice4 = torch.nn.Sequential()", "\n", "for", "x", "in", "range", "(", "4", ")", ":", "\n", "            ", "self", ".", "slice1", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "4", ",", "9", ")", ":", "\n", "            ", "self", ".", "slice2", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "9", ",", "16", ")", ":", "\n", "            ", "self", ".", "slice3", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "#for x in range(16, 23):", "\n", "#self.slice4.add_module(str(x), vgg_pretrained_features[x])", "\n", "", "if", "not", "requires_grad", ":", "\n", "            ", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.PercepLoss.forward": [[633, 645], ["vae_trip.PercepLoss.slice1", "vae_trip.PercepLoss.slice2", "vae_trip.PercepLoss.slice3", "collections.namedtuple", "collections.namedtuple."], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "X", ")", ":", "\n", "        ", "h", "=", "self", ".", "slice1", "(", "X", ")", "\n", "h_relu1_2", "=", "h", "\n", "h", "=", "self", ".", "slice2", "(", "h", ")", "\n", "h_relu2_2", "=", "h", "\n", "h", "=", "self", ".", "slice3", "(", "h", ")", "\n", "h_relu3_3", "=", "h", "\n", "#h = self.slice4(h)", "\n", "#h_relu4_3 = h", "\n", "vgg_outputs", "=", "namedtuple", "(", "\"VggOutputs\"", ",", "[", "'relu1_2'", ",", "'relu2_2'", ",", "'relu3_3'", "]", ")", "\n", "out", "=", "vgg_outputs", "(", "h_relu1_2", ",", "h_relu2_2", ",", "h_relu3_3", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.safe_exit": [[76, 81], ["print", "sys.stdout.flush", "sys.stdout.flush", "sys.stdout.flush"], "function", ["None"], ["def", "safe_exit", "(", "signal_num", ",", "ec", "=", "0", ",", "total_iters", "=", "0", ",", "exp_name", "=", "\"\"", ")", ":", "\n", "    ", "print", "(", "\"Caught a signal\"", ",", "signal_num", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "global", "exit_code", "\n", "exit_code", "=", "signal_num", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.find_latest_checkpoint_in_dir": [[658, 680], ["os.listdir", "os.listdir.remove", "pretrained_model.split", "int", "print", "print", "len", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "prefix_split[].split"], "function", ["None"], ["def", "find_latest_checkpoint_in_dir", "(", "load_dir", ",", "prefix", ")", ":", "\n", "  ", "pretrained_models", "=", "os", ".", "listdir", "(", "load_dir", ")", "\n", "if", "'.ipynb_checkpoints'", "in", "pretrained_models", ":", "\n", "    ", "pretrained_models", ".", "remove", "(", "'.ipynb_checkpoints'", ")", "\n", "", "max_model_name", "=", "\"\"", "\n", "max_model_no", "=", "-", "1", "\n", "for", "pretrained_model", "in", "pretrained_models", ":", "\n", "    ", "prefix_split", "=", "pretrained_model", ".", "split", "(", "f\"{prefix}\"", ")", "\n", "if", "len", "(", "prefix_split", ")", "!=", "2", ":", "\n", "      ", "continue", "\n", "", "model_no", "=", "int", "(", "prefix_split", "[", "1", "]", ".", "split", "(", "\".pt\"", ")", "[", "0", "]", ")", "\n", "if", "model_no", ">", "max_model_no", ":", "\n", "      ", "max_model_no", "=", "model_no", "\n", "max_model_name", "=", "pretrained_model", "\n", "", "", "epoch", "=", "0", "\n", "if", "max_model_name", "==", "\"\"", ":", "\n", "    ", "print", "(", "\"Could not find pretrained model.\"", ")", "\n", "return", "None", "\n", "", "else", ":", "\n", "    ", "print", "(", "f\"Loaded pretrained model: {max_model_name}\"", ")", "\n", "epoch", "=", "max_model_no", "\n", "return", "epoch", ",", "torch", ".", "load", "(", "f'{load_dir}/{max_model_name}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.display_first_n_of_batch": [[700, 710], ["matplotlib.pyplot.subplots", "f.set_figheight", "f.set_figwidth", "range", "matplotlib.pyplot.show", "numpy.transpose", "axarr[].imshow", "batch[].cpu().detach().numpy", "batch[].cpu().detach", "batch[].cpu"], "function", ["None"], ["def", "display_first_n_of_batch", "(", "batch", ",", "n", ")", ":", "\n", "  ", "f", ",", "axarr", "=", "plt", ".", "subplots", "(", "1", ",", "n", ")", "\n", "f", ".", "set_figheight", "(", "n", ")", "\n", "f", ".", "set_figwidth", "(", "2", "*", "n", ")", "\n", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "      ", "imgorg", "=", "np", ".", "transpose", "(", "batch", "[", "i", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", "(", "1", ",", "2", ",", "0", ")", ")", "\n", "axarr", "[", "i", "]", ".", "imshow", "(", "imgorg", ")", "\n", "\n", "", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.loss_function": [[713, 736], ["recon_x.cpu.cpu", "x.cpu.cpu", "mean.cpu.cpu", "logvariance.cpu.cpu", "data_widths.cpu.cpu", "data_heights.cpu.cpu", "torch.binary_cross_entropy().cpu", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.binary_cross_entropy", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "mean.cpu.pow", "logvariance.cpu.exp"], "function", ["None"], ["", "def", "loss_function", "(", "recon_x", ",", "x", ",", "mean", ",", "logvariance", ",", "data_widths", ",", "data_heights", ")", ":", "\n", "    ", "recon_x", "=", "recon_x", ".", "cpu", "(", ")", "\n", "x", "=", "x", ".", "cpu", "(", ")", "\n", "mean", "=", "mean", ".", "cpu", "(", ")", "\n", "logvariance", "=", "logvariance", ".", "cpu", "(", ")", "\n", "data_widths", "=", "data_widths", ".", "cpu", "(", ")", "\n", "data_heights", "=", "data_heights", ".", "cpu", "(", ")", "\n", "\n", "BCE", "=", "F", ".", "binary_cross_entropy", "(", "recon_x", ",", "x", ",", "reduction", "=", "'none'", ")", ".", "cpu", "(", ")", "\n", "mask_matrix", "=", "torch", ".", "zeros", "(", "recon_x", ".", "shape", ")", "\n", "\n", "# Iterate through each element in the batch", "\n", "for", "i", "in", "range", "(", "0", ",", "recon_x", ".", "shape", "[", "0", "]", ")", ":", "\n", "      ", "mask_matrix", "[", "i", ",", ":", ",", "0", ":", "data_heights", "[", "i", "]", ",", "0", ":", "data_widths", "[", "i", "]", "]", "=", "torch", ".", "ones", "(", "(", "3", ",", "data_heights", "[", "i", "]", ",", "data_widths", "[", "i", "]", ")", ")", "\n", "\n", "# Normalize KL Divergence loss by batch size", "\n", "", "KLD", "=", "0.5", "*", "(", "torch", ".", "sum", "(", "mean", ".", "pow", "(", "2", ")", "+", "logvariance", ".", "exp", "(", ")", "-", "logvariance", "-", "1", ")", "/", "recon_x", ".", "shape", "[", "0", "]", ")", "\n", "\n", "if", "MASK_TYPE", "==", "\"mask\"", ":", "\n", "      ", "masked_BCE", "=", "BCE", "*", "mask_matrix", "\n", "return", "(", "KLD", ")", ",", "(", "torch", ".", "sum", "(", "masked_BCE", "/", "(", "recon_x", ".", "shape", "[", "1", "]", "*", "torch", ".", "sum", "(", "data_widths", "*", "data_heights", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "      ", "return", "(", "KLD", ")", ",", "(", "torch", ".", "sum", "(", "BCE", ")", "/", "(", "recon_x", ".", "shape", "[", "0", "]", "*", "recon_x", ".", "shape", "[", "1", "]", "*", "recon_x", ".", "shape", "[", "2", "]", "*", "recon_x", ".", "shape", "[", "3", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.discriminator_loss": [[737, 742], ["prediction.cpu.cpu", "gt.cpu.cpu", "torch.BCELoss", "nn.BCELoss."], "function", ["None"], ["", "", "def", "discriminator_loss", "(", "prediction", ",", "gt", ")", ":", "\n", "  ", "prediction", "=", "prediction", ".", "cpu", "(", ")", "\n", "gt", "=", "gt", ".", "cpu", "(", ")", "\n", "BCE_loss", "=", "nn", ".", "BCELoss", "(", ")", "\n", "return", "BCE_loss", "(", "prediction", ",", "gt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.discriminator_loss_no_reduction": [[743, 748], ["prediction.cpu.cpu", "gt.cpu.cpu", "torch.BCELoss", "nn.BCELoss."], "function", ["None"], ["", "def", "discriminator_loss_no_reduction", "(", "prediction", ",", "gt", ")", ":", "\n", "  ", "prediction", "=", "prediction", ".", "cpu", "(", ")", "\n", "gt", "=", "gt", ".", "cpu", "(", ")", "\n", "BCE_loss", "=", "nn", ".", "BCELoss", "(", "reduction", "=", "'none'", ")", "\n", "return", "BCE_loss", "(", "prediction", ",", "gt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.discriminator_kl_divergence": [[749, 755], ["mean.cpu.cpu", "logvariance.cpu.cpu", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "mean.cpu.pow", "logvariance.cpu.exp"], "function", ["None"], ["", "def", "discriminator_kl_divergence", "(", "mean", ",", "logvariance", ")", ":", "\n", "  ", "mean", "=", "mean", ".", "cpu", "(", ")", "\n", "logvariance", "=", "logvariance", ".", "cpu", "(", ")", "\n", "\n", "KLD", "=", "0.5", "*", "torch", ".", "sum", "(", "mean", ".", "pow", "(", "2", ")", "+", "logvariance", ".", "exp", "(", ")", "-", "logvariance", "-", "1", ")", "\n", "return", "KLD", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.artist_prediction_loss": [[756, 765], ["artist_prediction_vector.cpu.cpu", "gt_one_hot_artist.cpu.cpu", "mean.cpu.cpu", "logvariance.cpu.cpu", "torch.BCELoss", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "nn.BCELoss.", "artist_prediction_vector.cpu.float", "gt_one_hot_artist.cpu.float", "mean.cpu.pow", "logvariance.cpu.exp"], "function", ["None"], ["", "def", "artist_prediction_loss", "(", "artist_prediction_vector", ",", "gt_one_hot_artist", ",", "mean", ",", "logvariance", ")", ":", "\n", "  ", "artist_prediction_vector", "=", "artist_prediction_vector", ".", "cpu", "(", ")", "\n", "gt_one_hot_artist", "=", "gt_one_hot_artist", ".", "cpu", "(", ")", "\n", "mean", "=", "mean", ".", "cpu", "(", ")", "\n", "logvariance", "=", "logvariance", ".", "cpu", "(", ")", "\n", "\n", "BCE_loss", "=", "nn", ".", "BCELoss", "(", ")", "\n", "KLD", "=", "0.5", "*", "(", "torch", ".", "sum", "(", "mean", ".", "pow", "(", "2", ")", "+", "logvariance", ".", "exp", "(", ")", "-", "logvariance", "-", "1", ")", "/", "artist_prediction_vector", ".", "shape", "[", "0", "]", ")", "\n", "return", "ARTIST_PREDICTION_WEIGHT", "*", "BCE_loss", "(", "artist_prediction_vector", ".", "float", "(", ")", ",", "gt_one_hot_artist", ".", "float", "(", ")", ")", "+", "ARTIST_KLD_WEIGHT", "*", "KLD", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.kl_divergence_two_gaussians": [[766, 776], ["p_mean.cpu.cpu", "q_mean.cpu.cpu", "p_logvar.cpu().exp", "q_logvar.cpu().exp", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "p_logvar.cpu", "q_logvar.cpu"], "function", ["None"], ["", "def", "kl_divergence_two_gaussians", "(", "p_mean", ",", "p_logvar", ",", "q_mean", ",", "q_logvar", ")", ":", "\n", "  ", "p_mean", "=", "p_mean", ".", "cpu", "(", ")", "\n", "q_mean", "=", "q_mean", ".", "cpu", "(", ")", "\n", "p_var", "=", "p_logvar", ".", "cpu", "(", ")", ".", "exp", "(", ")", "\n", "q_var", "=", "q_logvar", ".", "cpu", "(", ")", ".", "exp", "(", ")", "\n", "\n", "p", "=", "torch", ".", "distributions", ".", "normal", ".", "Normal", "(", "p_mean", ",", "torch", ".", "sqrt", "(", "p_var", ")", ")", "\n", "q", "=", "torch", ".", "distributions", ".", "normal", ".", "Normal", "(", "q_mean", ",", "torch", ".", "sqrt", "(", "q_var", ")", ")", "\n", "\n", "return", "torch", ".", "distributions", ".", "kl", ".", "kl_divergence", "(", "p", ",", "q", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.kl_divergence_two_gaussians_std": [[777, 787], ["p_mean.cpu.cpu", "q_mean.cpu.cpu", "p_std.cpu.cpu", "q_std.cpu.cpu", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence"], "function", ["None"], ["", "def", "kl_divergence_two_gaussians_std", "(", "p_mean", ",", "p_std", ",", "q_mean", ",", "q_std", ")", ":", "\n", "  ", "p_mean", "=", "p_mean", ".", "cpu", "(", ")", "\n", "q_mean", "=", "q_mean", ".", "cpu", "(", ")", "\n", "p_std", "=", "p_std", ".", "cpu", "(", ")", "\n", "q_std", "=", "q_std", ".", "cpu", "(", ")", "\n", "\n", "p", "=", "torch", ".", "distributions", ".", "normal", ".", "Normal", "(", "p_mean", ",", "p_std", ")", "\n", "q", "=", "torch", ".", "distributions", ".", "normal", ".", "Normal", "(", "q_mean", ",", "q_std", ")", "\n", "\n", "return", "torch", ".", "distributions", ".", "kl", ".", "kl_divergence", "(", "p", ",", "q", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.artist_kl_divergence": [[788, 790], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "vae_trip.kl_divergence_two_gaussians"], "function", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.kl_divergence_two_gaussians"], ["", "def", "artist_kl_divergence", "(", "latent_mean", ",", "latent_logvar", ",", "pretrained_mean", ",", "pretrained_logvar", ")", ":", "\n", "  ", "return", "torch", ".", "mean", "(", "torch", ".", "sum", "(", "kl_divergence_two_gaussians", "(", "latent_mean", ",", "latent_logvar", ",", "pretrained_mean", ",", "pretrained_logvar", ")", ",", "dim", "=", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.triplet_loss": [[791, 806], ["torch.MSELoss", "range", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "total_trip_loss.cpu", "nn.MSELoss.", "nn.MSELoss.", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "triplet_loss", "(", "a_mean", ",", "p_mean", ",", "n_mean", ")", ":", "\n", "    ", "mse_criterion", "=", "nn", ".", "MSELoss", "(", ")", "\n", "total_trip_loss", "=", "0", "\n", "num_positives", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "a_mean", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "distance", "=", "mse_criterion", "(", "p_mean", "[", "i", "]", ",", "a_mean", "[", "i", "]", ")", "-", "mse_criterion", "(", "n_mean", "[", "i", "]", ",", "a_mean", "[", "i", "]", ")", "\n", "trip_loss", "=", "torch", ".", "clamp", "(", "distance", "+", "TRIPLET_ALPHA", ",", "min", "=", "0", ")", "\n", "if", "trip_loss", ">", "torch", ".", "tensor", "(", "0", ")", ":", "\n", "            ", "num_positives", "+=", "1", "\n", "\n", "", "total_trip_loss", "+=", "trip_loss", "\n", "", "if", "num_positives", "==", "0", ":", "\n", "        ", "return", "total_trip_loss", ".", "cpu", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "(", "total_trip_loss", "/", "num_positives", ")", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.calculate_perceptual_loss": [[815, 823], ["[].cpu", "[].cpu", "torch.MSELoss", "nn.MSELoss.", "loss_network", "loss_network", "x.to"], "function", ["None"], ["", "", "def", "calculate_perceptual_loss", "(", "recon_x", ",", "x", ")", ":", "\n", "# vgg_model = vgg_model.cuda()", "\n", "  ", "recon_features", "=", "loss_network", "(", "recon_x", ")", "[", "2", "]", ".", "cpu", "(", ")", "\n", "orig_features", "=", "loss_network", "(", "x", ".", "to", "(", "device", ")", ")", "[", "2", "]", ".", "cpu", "(", ")", "\n", "\n", "# vgg_model = vgg_model.cpu()", "\n", "mse_criterion", "=", "nn", ".", "MSELoss", "(", ")", "\n", "return", "mse_criterion", "(", "recon_features", ",", "orig_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.calculate_artist_discriminator_loss": [[824, 880], ["zip", "enumerate", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "discriminator", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "discriminator", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "enumerate", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "vae_trip.discriminator_loss_no_reduction", "enumerate", "vae_trip.discriminator_loss_no_reduction", "discriminator.squeeze", "torch.zeros.float().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "discriminator", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "discriminator.squeeze", "torch.zeros.float().squeeze", "vae_trip.discriminator_loss_no_reduction", "torch.zeros.float", "discriminator.squeeze", "torch.zeros.float().squeeze", "torch.zeros.float", "torch.zeros.float"], "function", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.discriminator_loss_no_reduction", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.discriminator_loss_no_reduction", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.discriminator_loss_no_reduction"], ["", "def", "calculate_artist_discriminator_loss", "(", "image_batches", ",", "triplet_latent_vectors", ",", "corresponding_latent_vectors", ")", ":", "\n", "# Here we go through all (6 choose 2) combinations of images and get the discriminator loss for each", "\n", "\n", "  ", "num_same_artists", "=", "0.0", "\n", "num_diff_artists", "=", "12", "*", "triplet_latent_vectors", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "\n", "same_artist_disc_loss", "=", "0.0", "\n", "diff_artist_disc_loss", "=", "0.0", "\n", "\n", "# FIRST CASE (3 Comparisons): The images of the same author (we check if they are also the same image, and if so we mask out that loss)", "\n", "for", "image_batch", ",", "triplet_latent", ",", "corr_latent", "in", "zip", "(", "image_batches", ",", "triplet_latent_vectors", ",", "corresponding_latent_vectors", ")", ":", "\n", "    ", "should_mask_vector", "=", "image_batch", "[", "\"corresponding\"", "]", "[", "\"should_mask\"", "]", "==", "0", "\n", "\n", "num_same_artists", "+=", "torch", ".", "sum", "(", "should_mask_vector", ")", "\n", "\n", "latent_concat", "=", "torch", ".", "cat", "(", "(", "triplet_latent", ",", "corr_latent", ")", ",", "dim", "=", "1", ")", "\n", "prediction", "=", "discriminator", "(", "latent_concat", ")", "\n", "\n", "disc_label", "=", "torch", ".", "ones", "(", "prediction", ".", "shape", ")", "\n", "\n", "same_artist_disc_loss", "+=", "torch", ".", "sum", "(", "should_mask_vector", "*", "discriminator_loss_no_reduction", "(", "prediction", ".", "squeeze", "(", ")", ",", "disc_label", ".", "float", "(", ")", ".", "squeeze", "(", ")", ")", ")", "\n", "\n", "# SECOND CASE (6 Comparisons): Compare each image from the triplet to each image in the corresponding that are not the same image", "\n", "", "for", "triplet_idx", ",", "triplet_latent", "in", "enumerate", "(", "triplet_latent_vectors", ")", ":", "\n", "    ", "for", "corr_idx", ",", "corr_latent", "in", "enumerate", "(", "corresponding_latent_vectors", ")", ":", "\n", "      ", "if", "(", "corr_idx", "==", "triplet_idx", ")", ":", "\n", "        ", "continue", "\n", "\n", "", "", "latent_concat", "=", "torch", ".", "cat", "(", "(", "triplet_latent", ",", "corr_latent", ")", ",", "dim", "=", "1", ")", "\n", "prediction", "=", "discriminator", "(", "latent_concat", ")", "\n", "\n", "disc_label", "=", "torch", ".", "zeros", "(", "prediction", ".", "shape", ")", "\n", "diff_artist_disc_loss", "+=", "torch", ".", "sum", "(", "discriminator_loss_no_reduction", "(", "prediction", ".", "squeeze", "(", ")", ",", "disc_label", ".", "float", "(", ")", ".", "squeeze", "(", ")", ")", ")", "\n", "\n", "# THIRD CASE (6 Comparisons): Compare each image from the same triplet", "\n", "", "latent_vectors_list", "=", "[", "triplet_latent_vectors", ",", "corresponding_latent_vectors", "]", "\n", "for", "latent_vectors_triplet", "in", "latent_vectors_list", ":", "\n", "    ", "for", "trip1_idx", ",", "trip1_latent", "in", "enumerate", "(", "latent_vectors_triplet", ")", ":", "\n", "      ", "for", "trip2_idx", ",", "trip2_latent", "in", "enumerate", "(", "latent_vectors_triplet", ")", ":", "\n", "        ", "if", "(", "trip1_idx", "==", "trip2_idx", ")", ":", "\n", "          ", "continue", "\n", "", "latent_concat", "=", "torch", ".", "cat", "(", "(", "trip1_latent", ",", "trip2_latent", ")", ",", "dim", "=", "1", ")", "\n", "prediction", "=", "discriminator", "(", "latent_concat", ")", "\n", "\n", "disc_label", "=", "torch", ".", "zeros", "(", "prediction", ".", "shape", ")", "\n", "diff_artist_disc_loss", "+=", "torch", ".", "sum", "(", "discriminator_loss_no_reduction", "(", "prediction", ".", "squeeze", "(", ")", ",", "disc_label", ".", "float", "(", ")", ".", "squeeze", "(", ")", ")", ")", "\n", "\n", "\n", "\n", "", "", "", "total_artist_loss", "=", "0.0", "\n", "if", "torch", ".", "sum", "(", "num_same_artists", ")", "==", "0", ":", "\n", "    ", "total_artist_loss", "=", "diff_artist_disc_loss", "/", "num_diff_artists", "\n", "", "else", ":", "\n", "    ", "total_artist_loss", "=", "(", "same_artist_disc_loss", "/", "num_same_artists", ")", "+", "(", "diff_artist_disc_loss", "/", "num_diff_artists", ")", "\n", "\n", "", "return", "total_artist_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.calculate_base_vae_test": [[887, 994], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "print", "time.time", "time.time", "base_optimizer.zero_grad", "print", "print", "vae_trip.triplet_loss", "print", "print", "kld_writer.add_scalar", "recon_writer.add_scalar", "triplet_writer.add_scalar", "perceptual_writer.add_scalar", "loss.item", "writer.add_scalar", "len", "len", "len", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "print", "loss.item", "exit", "exit", "vae", "vae_trip.loss_function", "vae_trip.calculate_perceptual_loss", "loss.item", "mean_kld_loss.item", "mean_recon_loss.item", "triplet_loss.item", "image_metadata[].to", "latent_mean.append", "latent_logvar.append", "triplet_latent_vectors.append", "corresponding_latent_vectors.append", "image_metadata[].to"], "function", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.triplet_loss", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.loss_function", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.calculate_perceptual_loss"], ["def", "calculate_base_vae_test", "(", "curr_epoch", ")", ":", "\n", "    ", "test_loss", "=", "0.0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch_idx", ",", "data", "in", "enumerate", "(", "test_dataset_loader", ")", ":", "\n", "            ", "print", "(", "f\"Evaluating batch {batch_idx} for {model_name}\"", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "time_elapsed", "=", "end", "-", "start_time", "\n", "\n", "if", "not", "IS_RUNNING_NOTEBOOK", ":", "\n", "              ", "if", "time_elapsed", ">=", "TIMEOUT", ":", "\n", "                  ", "exit", "(", "0", ")", "\n", "", "if", "exit_code", "is", "not", "None", ":", "\n", "                  ", "exit", "(", "3", ")", "\n", "\n", "", "", "base_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "positive_image_batch", "=", "data", "[", "'positive'", "]", "\n", "negative_image_batch", "=", "data", "[", "'negative'", "]", "\n", "anchor_image_batch", "=", "data", "[", "'anchor'", "]", "\n", "\n", "image_batches", "=", "[", "positive_image_batch", ",", "negative_image_batch", ",", "anchor_image_batch", "]", "\n", "latent_mean", "=", "[", "]", "\n", "latent_logvar", "=", "[", "]", "\n", "\n", "triplet_latent_vectors", "=", "[", "]", "\n", "corresponding_latent_vectors", "=", "[", "]", "\n", "\n", "total_kld_loss", "=", "0", "\n", "total_recon_loss", "=", "0", "\n", "total_artist_loss", "=", "0", "\n", "total_perceptual_loss", "=", "0", "\n", "#total_trip_loss = 0", "\n", "\n", "\n", "for", "image_batch", "in", "image_batches", ":", "\n", "              ", "triplet_keys", "=", "[", "\"triplet\"", "]", "\n", "for", "triplet_key", "in", "triplet_keys", ":", "\n", "                ", "image_metadata", "=", "image_batch", "[", "triplet_key", "]", "\n", "\n", "recon", ",", "mean", ",", "log_variance", ",", "latent_vector", "=", "vae", "(", "image_metadata", "[", "'image'", "]", ".", "to", "(", "device", ")", ")", "\n", "\n", "# Extract out just the portion related to the artist", "\n", "z_artist", "=", "latent_vector", "[", ":", ",", "0", ":", "LATENT_ARTIST_SIZE", "]", "\n", "\n", "if", "triplet_key", "==", "\"triplet\"", ":", "\n", "                  ", "latent_mean", ".", "append", "(", "mean", ")", "\n", "latent_logvar", ".", "append", "(", "log_variance", ")", "\n", "triplet_latent_vectors", ".", "append", "(", "z_artist", ")", "\n", "", "else", ":", "\n", "                  ", "corresponding_latent_vectors", ".", "append", "(", "z_artist", ")", "\n", "\n", "", "data_widths", "=", "image_metadata", "[", "'width'", "]", "\n", "data_heights", "=", "image_metadata", "[", "'height'", "]", "\n", "\n", "kld_loss", ",", "recon_loss", "=", "loss_function", "(", "recon", ",", "image_metadata", "[", "'image'", "]", ".", "to", "(", "device", ")", ",", "mean", ",", "log_variance", ",", "data_widths", ",", "data_heights", ")", "\n", "total_kld_loss", "+=", "kld_loss", "\n", "\n", "#with torch.no_grad():", "\n", "perceptual_loss", "=", "calculate_perceptual_loss", "(", "recon", ",", "image_metadata", "[", "'image'", "]", ")", "\n", "\n", "total_perceptual_loss", "+=", "perceptual_loss", "\n", "\n", "total_recon_loss", "+=", "recon_loss", "\n", "#kld_loss.backward()", "\n", "#recon_loss.backward()", "\n", "\n", "\n", "\n", "#total_artist_loss = calculate_artist_discriminator_loss(image_batches, triplet_latent_vectors, corresponding_latent_vectors)", "\n", "\n", "", "", "mean_kld_loss", "=", "(", "total_kld_loss", "/", "(", "len", "(", "image_batches", ")", ")", ")", "\n", "print", "(", "f\"AVG KLD Loss: {mean_kld_loss}\"", ")", "\n", "\n", "mean_recon_loss", "=", "(", "total_recon_loss", "/", "(", "len", "(", "image_batches", ")", ")", ")", "\n", "#print(f\"AVG Recon Loss: {mean_recon_loss}\")", "\n", "\n", "#mean_artist_loss = total_artist_loss / 2.0", "\n", "#print(f\"AVG Artist Discriminator Loss: {mean_artist_loss}\")", "\n", "\n", "mean_percep_loss", "=", "(", "total_perceptual_loss", "/", "(", "len", "(", "image_batches", ")", ")", ")", "\n", "print", "(", "f\"AVG Perceptual Loss: {mean_percep_loss}\"", ")", "\n", "\n", "mean_triplet_loss", "=", "triplet_loss", "(", "latent_mean", "[", "2", "]", ",", "latent_mean", "[", "0", "]", ",", "latent_mean", "[", "1", "]", ")", "\n", "print", "(", "f\"Triplet Loss: {mean_triplet_loss}\"", ")", "\n", "\n", "#loss = (VAE_DIVERGENCE_WEIGHT * mean_kld_loss) + (RECONSTRUCTION_WEIGHT * mean_recon_loss) +  (TRIPLET_LOSS_WEIGHT * mean_triplet_loss)", "\n", "loss", "=", "(", "VAE_DIVERGENCE_WEIGHT", "*", "mean_kld_loss", ")", "+", "(", "PERCEP_LOSS_WEIGHT", "*", "mean_percep_loss", ")", "+", "(", "RECONSTRUCTION_WEIGHT", "*", "mean_recon_loss", ")", "+", "(", "TRIPLET_LOSS_WEIGHT", "*", "mean_triplet_loss", ")", "\n", "#loss = (VAE_DIVERGENCE_WEIGHT * mean_kld_loss) + (RECONSTRUCTION_WEIGHT * mean_recon_loss) + (LATENT_ARTIST_WEIGHT * mean_artist_loss) + (TRIPLET_LOSS_WEIGHT * mean_triplet_loss)", "\n", "print", "(", "f\"Overall Loss: {loss}\"", ")", "\n", "\n", "if", "torch", ".", "isnan", "(", "loss", ")", "or", "loss", ".", "item", "(", ")", ">", "MAX_VAE_LOSS_THRESHOLD", ":", "\n", "              ", "pickle_name", "=", "f\"{log_folder}/epoch{epoch}_batch{batch_idx}.pickle\"", "\n", "print", "(", "\"Loss outside usual range. Skipping and reporting error\"", ")", "\n", "del", "loss", "\n", "continue", "\n", "\n", "", "kld_writer", ".", "add_scalar", "(", "f'Loss/Test_{model_name}'", ",", "VAE_DIVERGENCE_WEIGHT", "*", "mean_kld_loss", ".", "item", "(", ")", ",", "curr_epoch", ")", "\n", "recon_writer", ".", "add_scalar", "(", "f'Loss/Test_{model_name}'", ",", "RECONSTRUCTION_WEIGHT", "*", "mean_recon_loss", ".", "item", "(", ")", ",", "curr_epoch", ")", "\n", "#artist_writer.add_scalar(f'Loss/Test_{model_name}', LATENT_ARTIST_WEIGHT * mean_artist_loss.item(), curr_epoch)", "\n", "triplet_writer", ".", "add_scalar", "(", "f'Loss/Test_{model_name}'", ",", "TRIPLET_LOSS_WEIGHT", "*", "mean_triplet_loss", ".", "item", "(", ")", ",", "curr_epoch", ")", "\n", "perceptual_writer", ".", "add_scalar", "(", "f'Loss/Test_{model_name}'", ",", "PERCEP_LOSS_WEIGHT", "*", "mean_percep_loss", ",", "curr_epoch", ")", "\n", "\n", "test_loss", "+=", "loss", ".", "item", "(", ")", "\n", "writer", ".", "add_scalar", "(", "f'Loss/Test_{model_name}'", ",", "loss", ".", "item", "(", ")", ",", "curr_epoch", ")", "\n", "\n", "\n", "", "", "return", "test_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_trip.train_base_vae": [[999, 1174], ["print", "print", "range", "len", "enumerate", "print", "time.time", "time.time", "base_optimizer.zero_grad", "print", "print", "print", "vae_trip.triplet_loss", "print", "kld_writer.add_scalar", "recon_writer.add_scalar", "triplet_writer.add_scalar", "perceptual_writer.add_scalar", "print", "writer.add_scalar", "loss.backward", "loss.item", "base_optimizer.step", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "len", "len", "len", "losses.append", "losses.append", "losses.pop", "loss.item", "torchvision.utils.make_grid", "torchvision.utils.make_grid", "writer.add_image", "matplotlib.pyplot.subplots", "f.set_figheight", "f.set_figwidth", "range", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "vae_trip.calculate_base_vae_test", "print", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "print", "print", "vae.to.state_dict", "vae_trip.safe_exit", "print", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "vae_trip.safe_exit", "vae.to.to", "vae.to.", "vae_trip.calculate_perceptual_loss", "vae_trip.loss_function", "loss.item", "numpy.sum", "loss.item", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "print", "min", "numpy.transpose", "axarr[].imshow", "vae.to.state_dict", "os.path.exists", "vae.to.state_dict", "image_metadata[].to", "latent_mean.append", "latent_logvar.append", "triplet_latent_vectors.append", "corresponding_latent_vectors.append", "image_metadata[].to", "loss.item", "loss.item", "recon[].cpu().detach().numpy", "os.remove", "len", "recon[].cpu().detach", "recon[].cpu"], "function", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.triplet_loss", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.calculate_base_vae_test", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.safe_exit", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.safe_exit", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.calculate_perceptual_loss", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.loss_function"], ["def", "train_base_vae", "(", "vae", ",", "end_iters", ",", "results_folder", ",", "weights_folder", ",", "prefix", ",", "start_iters", ",", "log_folder", ")", ":", "\n", "#pdb.set_trace()", "\n", "    ", "loss_array", "=", "[", "]", "\n", "test_losses", "=", "[", "]", "\n", "display_interval", "=", "479", "\n", "save_interval", "=", "479", "*", "15", "\n", "print", "(", "f\"start iters: {start_iters}\"", ")", "\n", "print", "(", "f\"end iters: {end_iters}\"", ")", "\n", "for", "iters", "in", "range", "(", "start_iters", ",", "end_iters", ",", "len", "(", "train_dataset_loader", ")", ")", ":", "\n", "        ", "train_loss", "=", "0", "\n", "NUM_SAMPLES_IN_AVG", "=", "10", "\n", "losses", "=", "[", "]", "\n", "for", "batch_idx", ",", "data", "in", "enumerate", "(", "train_dataset_loader", ")", ":", "\n", "#pdb.set_trace()", "\n", "            ", "total_iters", "=", "batch_idx", "+", "iters", "\n", "if", "total_iters", ">=", "end_iters", ":", "\n", "                ", "save_filename", "=", "f'{prefix}{total_iters}.pt'", "\n", "save_path", "=", "f'{weights_folder}/{save_filename}'", "\n", "torch", ".", "save", "(", "vae", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "return", "\n", "", "print", "(", "f\"Evaluating batch {total_iters} for {model_name}\"", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "time_elapsed", "=", "end", "-", "start_time", "\n", "if", "not", "IS_RUNNING_NOTEBOOK", ":", "\n", "              ", "if", "time_elapsed", ">=", "TIMEOUT", ":", "\n", "                  ", "safe_exit", "(", "0", ")", "\n", "", "if", "exit_code", "is", "not", "None", ":", "\n", "                  ", "print", "(", "\"caught the exception!\"", ")", "\n", "save_filename", "=", "f'{prefix}{total_iters}.pt'", "\n", "save_path", "=", "f'{weights_folder}/{save_filename}'", "\n", "torch", ".", "save", "(", "vae", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "safe_exit", "(", "3", ")", "\n", "return", "\n", "\n", "\n", "", "", "base_optimizer", ".", "zero_grad", "(", ")", "\n", "#discriminator_optimizer.zero_grad()", "\n", "\n", "positive_image_batch", "=", "data", "[", "'positive'", "]", "\n", "negative_image_batch", "=", "data", "[", "'negative'", "]", "\n", "anchor_image_batch", "=", "data", "[", "'anchor'", "]", "\n", "\n", "image_batches", "=", "[", "positive_image_batch", ",", "negative_image_batch", ",", "anchor_image_batch", "]", "\n", "latent_mean", "=", "[", "]", "\n", "latent_logvar", "=", "[", "]", "\n", "\n", "triplet_latent_vectors", "=", "[", "]", "\n", "corresponding_latent_vectors", "=", "[", "]", "\n", "\n", "total_kld_loss", "=", "0", "\n", "total_recon_loss", "=", "0", "\n", "total_artist_loss", "=", "0", "\n", "total_perceptual_loss", "=", "0", "\n", "total_trip_loss", "=", "0", "\n", "\n", "for", "image_batch", "in", "image_batches", ":", "\n", "              ", "triplet_keys", "=", "[", "\"triplet\"", "]", "\n", "for", "triplet_key", "in", "triplet_keys", ":", "\n", "                ", "image_metadata", "=", "image_batch", "[", "triplet_key", "]", "\n", "\n", "vae", "=", "vae", ".", "to", "(", "device", ")", "\n", "recon", ",", "mean", ",", "log_variance", ",", "latent_vector", "=", "vae", "(", "image_metadata", "[", "'image'", "]", ".", "to", "(", "device", ")", ")", "\n", "\n", "# Extract out just the portion related to the artist", "\n", "z_artist", "=", "latent_vector", "[", ":", ",", "0", ":", "LATENT_ARTIST_SIZE", "]", "\n", "\n", "if", "triplet_key", "==", "\"triplet\"", ":", "\n", "                  ", "latent_mean", ".", "append", "(", "mean", ")", "\n", "latent_logvar", ".", "append", "(", "log_variance", ")", "\n", "triplet_latent_vectors", ".", "append", "(", "z_artist", ")", "\n", "", "else", ":", "\n", "                  ", "corresponding_latent_vectors", ".", "append", "(", "z_artist", ")", "\n", "\n", "", "data_widths", "=", "image_metadata", "[", "'width'", "]", "\n", "data_heights", "=", "image_metadata", "[", "'height'", "]", "\n", "\n", "perceptual_loss", "=", "calculate_perceptual_loss", "(", "recon", ",", "image_metadata", "[", "'image'", "]", ")", "\n", "\n", "kld_loss", ",", "recon_loss", "=", "loss_function", "(", "recon", ",", "image_metadata", "[", "'image'", "]", ".", "to", "(", "device", ")", ",", "mean", ",", "log_variance", ",", "data_widths", ",", "data_heights", ")", "\n", "total_kld_loss", "+=", "kld_loss", "\n", "total_recon_loss", "+=", "recon_loss", "\n", "total_perceptual_loss", "+=", "perceptual_loss", "\n", "#total_trip_loss += VAE_DIVERGENCE_WEIGHT * kld_loss + PERCEP_LOSS_WEIGHT * perceptual_loss", "\n", "#trip_loss = VAE_DIVERGENCE_WEIGHT * kld_loss + RECONSTRUCTION_WEIGHT * recon_loss", "\n", "#trip_loss.backward()", "\n", "\n", "\n", "\n", "#total_artist_loss = calculate_artist_discriminator_loss(image_batches, triplet_latent_vectors, corresponding_latent_vectors)", "\n", "\n", "", "", "mean_percep_loss", "=", "(", "total_perceptual_loss", "/", "(", "len", "(", "image_batches", ")", ")", ")", "\n", "print", "(", "f\"AVG Perceptual Loss: {PERCEP_LOSS_WEIGHT * mean_percep_loss}\"", ")", "\n", "\n", "mean_kld_loss", "=", "(", "total_kld_loss", "/", "(", "len", "(", "image_batches", ")", ")", ")", "\n", "print", "(", "f\"AVG KLD Loss: {VAE_DIVERGENCE_WEIGHT * mean_kld_loss}\"", ")", "\n", "\n", "mean_recon_loss", "=", "(", "total_recon_loss", "/", "(", "len", "(", "image_batches", ")", ")", ")", "\n", "print", "(", "f\"AVG Recon Loss: {RECONSTRUCTION_WEIGHT * mean_recon_loss}\"", ")", "\n", "\n", "#mean_artist_loss = total_artist_loss / 2", "\n", "#print(f\"AVG Artist Discriminator Loss: {LATENT_ARTIST_WEIGHT * mean_artist_loss}\")", "\n", "# pna -> apn", "\n", "mean_triplet_loss", "=", "triplet_loss", "(", "latent_mean", "[", "2", "]", ",", "latent_mean", "[", "0", "]", ",", "latent_mean", "[", "1", "]", ")", "\n", "\n", "#overall_loss = (total_trip_loss/3.0) + mean_triplet_loss", "\n", "#loss = VAE_DIVERGENCE_WEIGHT * mean_kld_loss + PERCEP_LOSS_WEIGHT * mean_percep_loss + TRIPLET_LOSS_WEIGHT * mean_triplet_loss", "\n", "loss", "=", "(", "VAE_DIVERGENCE_WEIGHT", "*", "mean_kld_loss", ")", "+", "(", "PERCEP_LOSS_WEIGHT", "*", "mean_percep_loss", ")", "+", "(", "RECONSTRUCTION_WEIGHT", "*", "mean_recon_loss", ")", "+", "TRIPLET_LOSS_WEIGHT", "*", "mean_triplet_loss", "\n", "print", "(", "f\"Overall Loss: {loss.item()}\"", ")", "\n", "\n", "if", "batch_idx", "<", "NUM_SAMPLES_IN_AVG", ":", "\n", "                 ", "losses", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "", "else", ":", "\n", "                 ", "avg", "=", "np", ".", "sum", "(", "losses", ")", "/", "NUM_SAMPLES_IN_AVG", "\n", "losses", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "losses", ".", "pop", "(", "0", ")", "\n", "if", "torch", ".", "isnan", "(", "loss", ")", "or", "loss", ".", "item", "(", ")", ">", "(", "avg", "+", "MAX_VAE_LOSS_THRESHOLD", ")", ":", "\n", "                   ", "pickle_name", "=", "f\"{log_folder}/epoch{epoch}_batch{batch_idx}.pickle\"", "\n", "print", "(", "\"Loss outside usual range. Skipping and reporting error\"", ")", "\n", "del", "loss", "\n", "del", "mean_percep_loss", "\n", "del", "mean_kld_loss", "\n", "del", "mean_recon_loss", "\n", "del", "mean_triplet_loss", "\n", "continue", "\n", "\n", "", "", "kld_writer", ".", "add_scalar", "(", "f'Loss/Train_{model_name}'", ",", "VAE_DIVERGENCE_WEIGHT", "*", "mean_kld_loss", ",", "total_iters", ")", "\n", "recon_writer", ".", "add_scalar", "(", "f'Loss/Train_{model_name}'", ",", "RECONSTRUCTION_WEIGHT", "*", "mean_recon_loss", ",", "total_iters", ")", "\n", "#artist_writer.add_scalar(f'Loss/Train_{model_name}', LATENT_ARTIST_WEIGHT * mean_artist_loss.item(), epoch * len(train_dataset_loader) + batch_idx)", "\n", "triplet_writer", ".", "add_scalar", "(", "f'Loss/Train_{model_name}'", ",", "TRIPLET_LOSS_WEIGHT", "*", "mean_triplet_loss", ",", "total_iters", ")", "\n", "perceptual_writer", ".", "add_scalar", "(", "f'Loss/Train_{model_name}'", ",", "PERCEP_LOSS_WEIGHT", "*", "mean_percep_loss", ",", "total_iters", ")", "\n", "\n", "print", "(", "f\"Step: {total_iters}\"", ")", "\n", "writer", ".", "add_scalar", "(", "f'Loss/Train_{model_name}'", ",", "loss", ".", "item", "(", ")", ",", "total_iters", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "base_optimizer", ".", "step", "(", ")", "\n", "#discriminator_optimizer.step()", "\n", "\n", "if", "total_iters", "%", "display_interval", "==", "0", ":", "\n", "              ", "grid", "=", "torchvision", ".", "utils", ".", "make_grid", "(", "recon", "[", "0", ":", "5", "]", ")", "\n", "writer", ".", "add_image", "(", "f'Images/{model_name}'", ",", "grid", ",", "total_iters", ")", "\n", "## Generate first 5 images of batch and save them to file", "\n", "f", ",", "axarr", "=", "plt", ".", "subplots", "(", "1", ",", "5", ")", "\n", "f", ".", "set_figheight", "(", "5", ")", "\n", "f", ".", "set_figwidth", "(", "10", ")", "\n", "\n", "for", "i", "in", "range", "(", "min", "(", "5", ",", "recon", ".", "shape", "[", "0", "]", ")", ")", ":", "\n", "                  ", "imgorg", "=", "np", ".", "transpose", "(", "recon", "[", "i", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", "(", "1", ",", "2", ",", "0", ")", ")", "\n", "axarr", "[", "i", "]", ".", "imshow", "(", "imgorg", ")", "\n", "\n", "", "image_save_path", "=", "f'{results_folder}/{prefix}{epoch}.png'", "\n", "plt", ".", "savefig", "(", "f\"{image_save_path}\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "## Calculate the test loss", "\n", "test_loss", "=", "calculate_base_vae_test", "(", "total_iters", ")", "\n", "\n", "print", "(", "'====> Iters: {} Average loss: {:.4f}'", ".", "format", "(", "\n", "total_iters", ",", "train_loss", "/", "len", "(", "train_dataset_loader", ".", "dataset", ")", ")", ")", "\n", "\n", "## Checkpointing", "\n", "save_filename", "=", "f'{prefix}{total_iters}.pt'", "\n", "save_path", "=", "f'{weights_folder}/{save_filename}'", "\n", "torch", ".", "save", "(", "vae", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "#disc_save_path = f'{LATENT_ARTIST_MODEL_LOAD_PATH}/{save_filename}'", "\n", "#torch.save(discriminator.state_dict, disc_save_path)", "\n", "\n", "print", "(", "f\"Saving weights to: {weights_folder}\"", ")", "\n", "if", "total_iters", "%", "save_interval", "!=", "0", ":", "\n", "                  ", "if", "os", ".", "path", ".", "exists", "(", "f'{weights_folder}/{prefix}{total_iters - display_interval}.pt'", ")", ":", "\n", "                      ", "os", ".", "remove", "(", "f'{weights_folder}/{prefix}{total_iters - display_interval}.pt'", ")", "\n", "#os.remove(f'{LATENT_ARTIST_MODEL_LOAD_PATH}/{prefix}{epoch - 1}.pt')", "\n", "", "", "print", "(", "f\"Saved images results to: {image_save_path}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.ArtDataset.__init__": [[193, 206], ["metadata_df.reset_index"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "image_folder", ",", "triplet_df", ",", "metadata_df", ",", "largest_height", ",", "largest_width", ",", "transform", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            image_folder (string): Directory with all the images.\n            metadata_df (Pandas Dataframe): Dataframe containing the metadata\n            transform (Torchvision.Transform) Transform to be applied to the image data\n        \"\"\"", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "metadata", "=", "metadata_df", ".", "reset_index", "(", ")", "\n", "self", ".", "triplets", "=", "triplet_df", "\n", "self", ".", "image_folder", "=", "image_folder", "\n", "self", ".", "largest_height", "=", "largest_height", "\n", "self", ".", "largest_width", "=", "largest_width", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.ArtDataset.__len__": [[207, 209], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "triplets", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.ArtDataset.return_transformed_image": [[210, 216], ["PIL.Image.open", "vae_no_trip.ArtDataset.transform", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d.", "os.path.join"], "methods", ["None"], ["", "def", "return_transformed_image", "(", "self", ",", "image_filename", ")", ":", "\n", "        ", "image", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "image_folder", ",", "image_filename", ")", ")", "\n", "(", "width", ",", "height", ")", "=", "image", ".", "size", "\n", "tensor_image", "=", "self", ".", "transform", "(", "image", ")", "\n", "pad_layer", "=", "nn", ".", "ZeroPad2d", "(", "(", "0", ",", "self", ".", "largest_width", "-", "width", ",", "0", ",", "self", ".", "largest_height", "-", "height", ")", ")", "\n", "return", "pad_layer", "(", "tensor_image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.ArtDataset.get_random_artist_image": [[217, 221], ["random.choice"], "methods", ["None"], ["", "def", "get_random_artist_image", "(", "self", ",", "artist", ")", ":", "\n", "        ", "artist_indices", "=", "self", ".", "metadata", "[", "self", ".", "metadata", "[", "'cleaned_artist'", "]", "==", "artist", "]", ".", "index", "\n", "random_artist_idx", "=", "random", ".", "choice", "(", "artist_indices", ")", "\n", "return", "self", ".", "metadata", ".", "iloc", "[", "random_artist_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.ArtDataset.__getitem__": [[222, 275], ["zip", "int", "vae_no_trip.ArtDataset.return_transformed_image"], "methods", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.ArtDataset.return_transformed_image"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "      ", "row", "=", "self", ".", "triplets", ".", "iloc", "[", "idx", "]", "\n", "\n", "positive_idx", "=", "int", "(", "row", "[", "'Positive'", "]", ")", "-", "1", "\n", "negative_idx", "=", "(", "1", "-", "positive_idx", ")", "\n", "\n", "triplet_names", "=", "[", "'1'", ",", "'2'", ",", "'anchor'", "]", "\n", "\n", "# Re-Arranges it so now it's of the form positive, negative, anchor.", "\n", "triplet_files", "=", "[", "row", "[", "triplet_names", "[", "positive_idx", "]", "]", ",", "row", "[", "triplet_names", "[", "negative_idx", "]", "]", ",", "row", "[", "triplet_names", "[", "2", "]", "]", "]", "\n", "labels", "=", "[", "'positive'", ",", "'negative'", ",", "'anchor'", "]", "\n", "\n", "triplet_objects", "=", "{", "}", "\n", "\n", "for", "filename", ",", "label", "in", "zip", "(", "triplet_files", ",", "labels", ")", ":", "\n", "        ", "triplet_object", "=", "{", "}", "\n", "\n", "triplet_image", "=", "{", "}", "\n", "triplet_corresponding", "=", "{", "}", "\n", "\n", "image_metadata", "=", "self", ".", "metadata", ".", "loc", "[", "self", ".", "metadata", "[", "'filename'", "]", "==", "filename", "]", "\n", "image_name", "=", "image_metadata", "[", "'filename'", "]", ".", "values", "[", "0", "]", "\n", "\n", "triplet_image", "[", "'artist'", "]", "=", "image_metadata", "[", "'cleaned_artist'", "]", ".", "values", "[", "0", "]", "\n", "triplet_image", "[", "'image'", "]", "=", "self", ".", "return_transformed_image", "(", "image_name", ")", "\n", "\n", "triplet_image", "[", "'normalized_midpoint'", "]", "=", "image_metadata", "[", "'normalized_midpoint'", "]", ".", "values", "[", "0", "]", "\n", "triplet_image", "[", "'normalized_start'", "]", "=", "image_metadata", "[", "'normalized_start'", "]", ".", "values", "[", "0", "]", "\n", "triplet_image", "[", "'normalized_end'", "]", "=", "image_metadata", "[", "'normalized_end'", "]", ".", "values", "[", "0", "]", "\n", "\n", "triplet_image", "[", "'width'", "]", "=", "image_metadata", "[", "'width'", "]", ".", "values", "[", "0", "]", "\n", "triplet_image", "[", "'height'", "]", "=", "image_metadata", "[", "'height'", "]", ".", "values", "[", "0", "]", "\n", "\n", "#random_artist = self.get_random_artist_image(triplet_image['artist'])", "\n", "\n", "#triplet_corresponding['image'] = self.return_transformed_image(random_artist['filename'])", "\n", "#triplet_corresponding['filename'] = random_artist['filename']", "\n", "\n", "#triplet_corresponding['normalized_midpoint'] = random_artist['normalized_midpoint']", "\n", "#triplet_corresponding['normalized_start'] = random_artist['normalized_start']", "\n", "#triplet_corresponding['normalized_end'] = random_artist['normalized_end']", "\n", "\n", "#triplet_corresponding['width'] = random_artist['width']", "\n", "#triplet_corresponding['height'] = random_artist['height']", "\n", "\n", "#triplet_corresponding['should_mask'] = (random_artist['filename'] == image_metadata['filename'].values[0])", "\n", "\n", "triplet_object", "[", "'triplet'", "]", "=", "triplet_image", "\n", "#triplet_object['corresponding'] = triplet_corresponding", "\n", "\n", "triplet_objects", "[", "label", "]", "=", "triplet_object", "\n", "\n", "", "return", "triplet_objects", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_latent_artist_discriminator.__init__": [[411, 417], ["torch.Module.__init__", "vae_no_trip.VAE_latent_artist_discriminator.initialize_latent_artist_discriminator", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.TRIPLET_VGG.__init__", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_latent_artist_discriminator.initialize_latent_artist_discriminator"], ["  ", "def", "__init__", "(", "self", ",", "encoding_length", ")", ":", "\n", "        ", "super", "(", "VAE_latent_artist_discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "encoding_length", "=", "encoding_length", "\n", "self", ".", "initialize_latent_artist_discriminator", "(", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_latent_artist_discriminator.initialize_latent_artist_discriminator": [[424, 434], ["torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "int", "int", "int", "int", "int", "int", "int"], "methods", ["None"], ["", "def", "initialize_latent_artist_discriminator", "(", "self", ")", ":", "\n", "      ", "self", ".", "latent_artist_discriminate_1", "=", "nn", ".", "Linear", "(", "2", "*", "self", ".", "encoding_length", ",", "self", ".", "encoding_length", "*", "4", ")", "\n", "self", ".", "latent_artist_bn_1", "=", "nn", ".", "BatchNorm1d", "(", "self", ".", "encoding_length", "*", "4", ")", "\n", "self", ".", "latent_artist_discriminate_2", "=", "nn", ".", "Linear", "(", "self", ".", "encoding_length", "*", "4", ",", "self", ".", "encoding_length", "*", "2", ")", "\n", "self", ".", "latent_artist_bn_2", "=", "nn", ".", "BatchNorm1d", "(", "self", ".", "encoding_length", "*", "2", ")", "\n", "self", ".", "latent_artist_discriminate_3", "=", "nn", ".", "Linear", "(", "int", "(", "self", ".", "encoding_length", "*", "2", ")", ",", "int", "(", "self", ".", "encoding_length", ")", ")", "\n", "self", ".", "latent_artist_bn_3", "=", "nn", ".", "BatchNorm1d", "(", "int", "(", "self", ".", "encoding_length", ")", ")", "\n", "self", ".", "latent_artist_discriminate_4", "=", "nn", ".", "Linear", "(", "int", "(", "self", ".", "encoding_length", ")", ",", "int", "(", "self", ".", "encoding_length", "/", "2", ")", ")", "\n", "self", ".", "latent_artist_bn_4", "=", "nn", ".", "BatchNorm1d", "(", "int", "(", "self", ".", "encoding_length", "/", "2", ")", ")", "\n", "self", ".", "latent_artist_discriminate_5", "=", "nn", ".", "Linear", "(", "int", "(", "self", ".", "encoding_length", "/", "2", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_latent_artist_discriminator.latent_artist_discriminator_forward": [[441, 448], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "vae_no_trip.VAE_latent_artist_discriminator.latent_artist_discriminate_5", "vae_no_trip.VAE_latent_artist_discriminator.sigmoid", "vae_no_trip.VAE_latent_artist_discriminator.latent_artist_bn_1", "vae_no_trip.VAE_latent_artist_discriminator.latent_artist_bn_2", "vae_no_trip.VAE_latent_artist_discriminator.latent_artist_bn_3", "vae_no_trip.VAE_latent_artist_discriminator.latent_artist_bn_4", "vae_no_trip.VAE_latent_artist_discriminator.latent_artist_discriminate_1", "vae_no_trip.VAE_latent_artist_discriminator.latent_artist_discriminate_2", "vae_no_trip.VAE_latent_artist_discriminator.latent_artist_discriminate_3", "vae_no_trip.VAE_latent_artist_discriminator.latent_artist_discriminate_4"], "methods", ["None"], ["", "def", "latent_artist_discriminator_forward", "(", "self", ",", "x", ")", ":", "\n", "      ", "x", "=", "F", ".", "relu", "(", "self", ".", "latent_artist_bn_1", "(", "self", ".", "latent_artist_discriminate_1", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "latent_artist_bn_2", "(", "self", ".", "latent_artist_discriminate_2", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "latent_artist_bn_3", "(", "self", ".", "latent_artist_discriminate_3", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "latent_artist_bn_4", "(", "self", ".", "latent_artist_discriminate_4", "(", "x", ")", ")", ")", "\n", "x", "=", "self", ".", "latent_artist_discriminate_5", "(", "x", ")", "\n", "return", "self", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_latent_artist_discriminator.forward": [[449, 451], ["vae_no_trip.VAE_latent_artist_discriminator.latent_artist_discriminator_forward"], "methods", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_latent_artist_discriminator.latent_artist_discriminator_forward"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "      ", "return", "self", ".", "latent_artist_discriminator_forward", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_base.__init__": [[456, 468], ["torch.Module.__init__", "vae_no_trip.VAE_base.initialize_base_vae_enocder", "vae_no_trip.VAE_base.initialize_base_vae_reparameterization", "vae_no_trip.VAE_base.initialize_base_vae_decoder", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.TRIPLET_VGG.__init__", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_base.initialize_base_vae_enocder", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_base.initialize_base_vae_reparameterization", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_base.initialize_base_vae_decoder"], ["    ", "def", "__init__", "(", "self", ",", "latent_size", ",", "artist_latent_size", ",", "num_artists", ")", ":", "\n", "        ", "super", "(", "VAE_base", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "latent_size", "=", "latent_size", "\n", "self", ".", "artist_latent_size", "=", "artist_latent_size", "\n", "self", ".", "num_artists", "=", "num_artists", "\n", "\n", "self", ".", "initialize_base_vae_enocder", "(", ")", "\n", "self", ".", "initialize_base_vae_reparameterization", "(", ")", "\n", "self", ".", "initialize_base_vae_decoder", "(", ")", "\n", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_base.initialize_base_vae_enocder": [[479, 498], ["torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["None"], ["", "def", "initialize_base_vae_enocder", "(", "self", ")", ":", "\n", "        ", "self", ".", "base_encode_conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "8", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "base_conv1_bn", "=", "nn", ".", "BatchNorm2d", "(", "8", ")", "\n", "self", ".", "base_encode_conv2", "=", "nn", ".", "Conv2d", "(", "8", ",", "16", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "base_conv2_bn", "=", "nn", ".", "BatchNorm2d", "(", "16", ")", "\n", "self", ".", "base_encode_conv3", "=", "nn", ".", "Conv2d", "(", "16", ",", "32", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "base_conv3_bn", "=", "nn", ".", "BatchNorm2d", "(", "32", ")", "\n", "self", ".", "base_encode_conv4", "=", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "base_conv4_bn", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "base_encode_conv5", "=", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "base_conv5_bn", "=", "nn", ".", "BatchNorm2d", "(", "128", ")", "\n", "self", ".", "base_encode_conv6", "=", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "base_conv6_bn", "=", "nn", ".", "BatchNorm2d", "(", "256", ")", "\n", "\n", "self", ".", "base_encode_conv7", "=", "nn", ".", "Conv2d", "(", "256", ",", "512", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "base_conv7_bn", "=", "nn", ".", "BatchNorm2d", "(", "512", ")", "\n", "\n", "self", ".", "base_encode_conv8", "=", "nn", ".", "Conv2d", "(", "512", ",", "1024", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "base_conv8_bn", "=", "nn", ".", "BatchNorm2d", "(", "1024", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_base.initialize_base_vae_reparameterization": [[499, 503], ["torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["None"], ["", "def", "initialize_base_vae_reparameterization", "(", "self", ")", ":", "\n", "        ", "self", ".", "base_ln_encode_mean", "=", "nn", ".", "Linear", "(", "4096", ",", "self", ".", "latent_size", ")", "\n", "self", ".", "base_ln_encode_variance", "=", "nn", ".", "Linear", "(", "4096", ",", "self", ".", "latent_size", ")", "\n", "self", ".", "base_ln_decode_variance", "=", "nn", ".", "Linear", "(", "self", ".", "latent_size", ",", "4096", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_base.initialize_base_vae_decoder": [[504, 522], ["torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["None"], ["", "def", "initialize_base_vae_decoder", "(", "self", ")", ":", "\n", "        ", "self", ".", "base_decode_trans_conv1", "=", "nn", ".", "ConvTranspose2d", "(", "4096", ",", "512", ",", "(", "5", ",", "4", ")", ",", "stride", "=", "2", ")", "\n", "self", ".", "base_conv1_trans_bn", "=", "nn", ".", "BatchNorm2d", "(", "512", ")", "\n", "self", ".", "base_decode_trans_conv2", "=", "nn", ".", "ConvTranspose2d", "(", "512", ",", "256", ",", "5", ",", "stride", "=", "2", ")", "\n", "self", ".", "base_conv2_trans_bn", "=", "nn", ".", "BatchNorm2d", "(", "256", ")", "\n", "self", ".", "base_decode_trans_conv3", "=", "nn", ".", "ConvTranspose2d", "(", "256", ",", "128", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "base_conv3_trans_bn", "=", "nn", ".", "BatchNorm2d", "(", "128", ")", "\n", "self", ".", "base_decode_trans_conv4", "=", "nn", ".", "ConvTranspose2d", "(", "128", ",", "64", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "base_conv4_trans_bn", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "base_decode_trans_conv5", "=", "nn", ".", "ConvTranspose2d", "(", "64", ",", "32", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "(", "0", ",", "1", ")", ")", "\n", "self", ".", "base_conv5_trans_bn", "=", "nn", ".", "BatchNorm2d", "(", "32", ")", "\n", "self", ".", "base_decode_trans_conv6", "=", "nn", ".", "ConvTranspose2d", "(", "32", ",", "16", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "(", "0", ",", "1", ")", ")", "\n", "self", ".", "base_conv6_trans_bn", "=", "nn", ".", "BatchNorm2d", "(", "16", ")", "\n", "self", ".", "base_decode_trans_conv7", "=", "nn", ".", "ConvTranspose2d", "(", "16", ",", "8", ",", "3", ",", "stride", "=", "2", ")", "\n", "self", ".", "base_conv7_trans_bn", "=", "nn", ".", "BatchNorm2d", "(", "8", ")", "\n", "self", ".", "base_decode_trans_conv8", "=", "nn", ".", "ConvTranspose2d", "(", "8", ",", "3", ",", "3", ",", "stride", "=", "1", ")", "\n", "#self.base_conv8_trans_bn = nn.BatchNorm2d(4)", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_base.vae_base_encode": [[529, 545], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "vae_no_trip.VAE_base.base_conv1_bn", "vae_no_trip.VAE_base.base_conv2_bn", "vae_no_trip.VAE_base.base_conv3_bn", "vae_no_trip.VAE_base.base_conv4_bn", "vae_no_trip.VAE_base.base_conv5_bn", "vae_no_trip.VAE_base.base_conv6_bn", "vae_no_trip.VAE_base.base_conv7_bn", "vae_no_trip.VAE_base.base_conv8_bn", "vae_no_trip.VAE_base.base_ln_encode_mean", "vae_no_trip.VAE_base.base_ln_encode_variance", "vae_no_trip.VAE_base.base_encode_conv1", "vae_no_trip.VAE_base.base_encode_conv2", "vae_no_trip.VAE_base.base_encode_conv3", "vae_no_trip.VAE_base.base_encode_conv4", "vae_no_trip.VAE_base.base_encode_conv5", "vae_no_trip.VAE_base.base_encode_conv6", "vae_no_trip.VAE_base.base_encode_conv7", "vae_no_trip.VAE_base.base_encode_conv8", "torch.relu.view", "torch.relu.view"], "methods", ["None"], ["", "def", "vae_base_encode", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "base_conv1_bn", "(", "self", ".", "base_encode_conv1", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "base_conv2_bn", "(", "self", ".", "base_encode_conv2", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "base_conv3_bn", "(", "self", ".", "base_encode_conv3", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "base_conv4_bn", "(", "self", ".", "base_encode_conv4", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "base_conv5_bn", "(", "self", ".", "base_encode_conv5", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "base_conv6_bn", "(", "self", ".", "base_encode_conv6", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "base_conv7_bn", "(", "self", ".", "base_encode_conv7", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "base_conv8_bn", "(", "self", ".", "base_encode_conv8", "(", "x", ")", ")", ")", "\n", "\n", "mean", ",", "log_variance", "=", "self", ".", "base_ln_encode_mean", "(", "x", ".", "view", "(", "-", "1", ",", "4096", ")", ")", ",", "self", ".", "base_ln_encode_variance", "(", "x", ".", "view", "(", "-", "1", ",", "4096", ")", ")", "\n", "std", "=", "torch", ".", "exp", "(", "0.5", "*", "log_variance", ")", "\n", "ns", "=", "torch", ".", "randn_like", "(", "std", ")", "\n", "z", "=", "ns", "*", "std", "+", "mean", "\n", "\n", "return", "z", ",", "mean", ",", "log_variance", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_base.vae_base_decode": [[546, 558], ["vae_no_trip.VAE_base.base_ln_decode_variance", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "vae_no_trip.VAE_base.base_decode_trans_conv8", "vae_no_trip.VAE_base.sigmoid", "vae_no_trip.VAE_base.base_conv1_trans_bn", "vae_no_trip.VAE_base.base_conv2_trans_bn", "vae_no_trip.VAE_base.base_conv3_trans_bn", "vae_no_trip.VAE_base.base_conv4_trans_bn", "vae_no_trip.VAE_base.base_conv5_trans_bn", "vae_no_trip.VAE_base.base_conv6_trans_bn", "vae_no_trip.VAE_base.base_conv7_trans_bn", "vae_no_trip.VAE_base.base_decode_trans_conv1", "vae_no_trip.VAE_base.base_decode_trans_conv2", "vae_no_trip.VAE_base.base_decode_trans_conv3", "vae_no_trip.VAE_base.base_decode_trans_conv4", "vae_no_trip.VAE_base.base_decode_trans_conv5", "vae_no_trip.VAE_base.base_decode_trans_conv6", "vae_no_trip.VAE_base.base_decode_trans_conv7", "vae_no_trip.VAE_base.view"], "methods", ["None"], ["", "def", "vae_base_decode", "(", "self", ",", "variance", ")", ":", "\n", "        ", "z", "=", "self", ".", "base_ln_decode_variance", "(", "variance", ")", "\n", "z", "=", "F", ".", "relu", "(", "self", ".", "base_conv1_trans_bn", "(", "self", ".", "base_decode_trans_conv1", "(", "z", ".", "view", "(", "-", "1", ",", "4096", ",", "1", ",", "1", ")", ")", ")", ")", "\n", "z", "=", "F", ".", "relu", "(", "self", ".", "base_conv2_trans_bn", "(", "self", ".", "base_decode_trans_conv2", "(", "z", ")", ")", ")", "\n", "z", "=", "F", ".", "relu", "(", "self", ".", "base_conv3_trans_bn", "(", "self", ".", "base_decode_trans_conv3", "(", "z", ")", ")", ")", "\n", "z", "=", "F", ".", "relu", "(", "self", ".", "base_conv4_trans_bn", "(", "self", ".", "base_decode_trans_conv4", "(", "z", ")", ")", ")", "\n", "z", "=", "F", ".", "relu", "(", "self", ".", "base_conv5_trans_bn", "(", "self", ".", "base_decode_trans_conv5", "(", "z", ")", ")", ")", "\n", "z", "=", "F", ".", "relu", "(", "self", ".", "base_conv6_trans_bn", "(", "self", ".", "base_decode_trans_conv6", "(", "z", ")", ")", ")", "\n", "z", "=", "F", ".", "relu", "(", "self", ".", "base_conv7_trans_bn", "(", "self", ".", "base_decode_trans_conv7", "(", "z", ")", ")", ")", "\n", "z", "=", "self", ".", "base_decode_trans_conv8", "(", "z", ")", "\n", "\n", "return", "self", ".", "sigmoid", "(", "z", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_base.forward": [[559, 564], ["vae_no_trip.VAE_base.vae_base_encode", "vae_no_trip.VAE_base.vae_base_decode"], "methods", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_base.vae_base_encode", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.VAE_base.vae_base_decode"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "z", ",", "mean", ",", "log_variance", "=", "self", ".", "vae_base_encode", "(", "x", ")", "\n", "output_image", "=", "self", ".", "vae_base_decode", "(", "z", ")", "\n", "\n", "return", "output_image", ",", "mean", ",", "log_variance", ",", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.PercepLoss.__init__": [[592, 610], ["super().__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "range", "range", "range", "torchvision.models.vgg16", "torchvision.models.vgg16", "vae_no_trip.PercepLoss.slice1.add_module", "vae_no_trip.PercepLoss.slice2.add_module", "vae_no_trip.PercepLoss.slice3.add_module", "vae_no_trip.PercepLoss.parameters", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.TRIPLET_VGG.__init__"], ["    ", "def", "__init__", "(", "self", ",", "requires_grad", "=", "False", ")", ":", "\n", "        ", "super", "(", "PercepLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "vgg_pretrained_features", "=", "models", ".", "vgg16", "(", "pretrained", "=", "True", ")", ".", "features", "\n", "self", ".", "slice1", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice2", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice3", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "#self.slice4 = torch.nn.Sequential()", "\n", "for", "x", "in", "range", "(", "4", ")", ":", "\n", "            ", "self", ".", "slice1", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "4", ",", "9", ")", ":", "\n", "            ", "self", ".", "slice2", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "9", ",", "16", ")", ":", "\n", "            ", "self", ".", "slice3", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "#for x in range(16, 23):", "\n", "#self.slice4.add_module(str(x), vgg_pretrained_features[x])", "\n", "", "if", "not", "requires_grad", ":", "\n", "            ", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.PercepLoss.forward": [[611, 623], ["vae_no_trip.PercepLoss.slice1", "vae_no_trip.PercepLoss.slice2", "vae_no_trip.PercepLoss.slice3", "collections.namedtuple", "collections.namedtuple."], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "X", ")", ":", "\n", "        ", "h", "=", "self", ".", "slice1", "(", "X", ")", "\n", "h_relu1_2", "=", "h", "\n", "h", "=", "self", ".", "slice2", "(", "h", ")", "\n", "h_relu2_2", "=", "h", "\n", "h", "=", "self", ".", "slice3", "(", "h", ")", "\n", "h_relu3_3", "=", "h", "\n", "#h = self.slice4(h)", "\n", "#h_relu4_3 = h", "\n", "vgg_outputs", "=", "namedtuple", "(", "\"VggOutputs\"", ",", "[", "'relu1_2'", ",", "'relu2_2'", ",", "'relu3_3'", "]", ")", "\n", "out", "=", "vgg_outputs", "(", "h_relu1_2", ",", "h_relu2_2", ",", "h_relu3_3", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.safe_exit": [[72, 77], ["print", "sys.stdout.flush", "sys.stdout.flush", "sys.stdout.flush"], "function", ["None"], ["def", "safe_exit", "(", "signal_num", ",", "ec", "=", "0", ",", "total_iters", "=", "0", ",", "exp_name", "=", "\"\"", ")", ":", "\n", "    ", "print", "(", "\"Caught a signal\"", ",", "signal_num", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "global", "exit_code", "\n", "exit_code", "=", "signal_num", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.find_latest_checkpoint_in_dir": [[636, 658], ["os.listdir", "os.listdir.remove", "pretrained_model.split", "int", "print", "print", "len", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "prefix_split[].split"], "function", ["None"], ["def", "find_latest_checkpoint_in_dir", "(", "load_dir", ",", "prefix", ")", ":", "\n", "  ", "pretrained_models", "=", "os", ".", "listdir", "(", "load_dir", ")", "\n", "if", "'.ipynb_checkpoints'", "in", "pretrained_models", ":", "\n", "    ", "pretrained_models", ".", "remove", "(", "'.ipynb_checkpoints'", ")", "\n", "", "max_model_name", "=", "\"\"", "\n", "max_model_no", "=", "-", "1", "\n", "for", "pretrained_model", "in", "pretrained_models", ":", "\n", "    ", "prefix_split", "=", "pretrained_model", ".", "split", "(", "f\"{prefix}\"", ")", "\n", "if", "len", "(", "prefix_split", ")", "!=", "2", ":", "\n", "      ", "continue", "\n", "", "model_no", "=", "int", "(", "prefix_split", "[", "1", "]", ".", "split", "(", "\".pt\"", ")", "[", "0", "]", ")", "\n", "if", "model_no", ">", "max_model_no", ":", "\n", "      ", "max_model_no", "=", "model_no", "\n", "max_model_name", "=", "pretrained_model", "\n", "", "", "epoch", "=", "0", "\n", "if", "max_model_name", "==", "\"\"", ":", "\n", "    ", "print", "(", "\"Could not find pretrained model.\"", ")", "\n", "return", "None", "\n", "", "else", ":", "\n", "    ", "print", "(", "f\"Loaded pretrained model: {max_model_name}\"", ")", "\n", "epoch", "=", "max_model_no", "\n", "return", "epoch", ",", "torch", ".", "load", "(", "f'{load_dir}/{max_model_name}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.display_first_n_of_batch": [[678, 688], ["matplotlib.pyplot.subplots", "f.set_figheight", "f.set_figwidth", "range", "matplotlib.pyplot.show", "numpy.transpose", "axarr[].imshow", "batch[].cpu().detach().numpy", "batch[].cpu().detach", "batch[].cpu"], "function", ["None"], ["def", "display_first_n_of_batch", "(", "batch", ",", "n", ")", ":", "\n", "  ", "f", ",", "axarr", "=", "plt", ".", "subplots", "(", "1", ",", "n", ")", "\n", "f", ".", "set_figheight", "(", "n", ")", "\n", "f", ".", "set_figwidth", "(", "2", "*", "n", ")", "\n", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "      ", "imgorg", "=", "np", ".", "transpose", "(", "batch", "[", "i", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", "(", "1", ",", "2", ",", "0", ")", ")", "\n", "axarr", "[", "i", "]", ".", "imshow", "(", "imgorg", ")", "\n", "\n", "", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.loss_function": [[691, 714], ["recon_x.cpu.cpu", "x.cpu.cpu", "mean.cpu.cpu", "logvariance.cpu.cpu", "data_widths.cpu.cpu", "data_heights.cpu.cpu", "torch.binary_cross_entropy().cpu", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.binary_cross_entropy", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "mean.cpu.pow", "logvariance.cpu.exp"], "function", ["None"], ["", "def", "loss_function", "(", "recon_x", ",", "x", ",", "mean", ",", "logvariance", ",", "data_widths", ",", "data_heights", ")", ":", "\n", "    ", "recon_x", "=", "recon_x", ".", "cpu", "(", ")", "\n", "x", "=", "x", ".", "cpu", "(", ")", "\n", "mean", "=", "mean", ".", "cpu", "(", ")", "\n", "logvariance", "=", "logvariance", ".", "cpu", "(", ")", "\n", "data_widths", "=", "data_widths", ".", "cpu", "(", ")", "\n", "data_heights", "=", "data_heights", ".", "cpu", "(", ")", "\n", "\n", "BCE", "=", "F", ".", "binary_cross_entropy", "(", "recon_x", ",", "x", ",", "reduction", "=", "'none'", ")", ".", "cpu", "(", ")", "\n", "mask_matrix", "=", "torch", ".", "zeros", "(", "recon_x", ".", "shape", ")", "\n", "\n", "# Iterate through each element in the batch", "\n", "for", "i", "in", "range", "(", "0", ",", "recon_x", ".", "shape", "[", "0", "]", ")", ":", "\n", "      ", "mask_matrix", "[", "i", ",", ":", ",", "0", ":", "data_heights", "[", "i", "]", ",", "0", ":", "data_widths", "[", "i", "]", "]", "=", "torch", ".", "ones", "(", "(", "3", ",", "data_heights", "[", "i", "]", ",", "data_widths", "[", "i", "]", ")", ")", "\n", "\n", "# Normalize KL Divergence loss by batch size", "\n", "", "KLD", "=", "0.5", "*", "(", "torch", ".", "sum", "(", "mean", ".", "pow", "(", "2", ")", "+", "logvariance", ".", "exp", "(", ")", "-", "logvariance", "-", "1", ")", "/", "recon_x", ".", "shape", "[", "0", "]", ")", "\n", "\n", "if", "MASK_TYPE", "==", "\"mask\"", ":", "\n", "      ", "masked_BCE", "=", "BCE", "*", "mask_matrix", "\n", "return", "(", "KLD", ")", ",", "(", "torch", ".", "sum", "(", "masked_BCE", "/", "(", "recon_x", ".", "shape", "[", "1", "]", "*", "torch", ".", "sum", "(", "data_widths", "*", "data_heights", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "      ", "return", "(", "KLD", ")", ",", "(", "torch", ".", "sum", "(", "BCE", ")", "/", "(", "recon_x", ".", "shape", "[", "0", "]", "*", "recon_x", ".", "shape", "[", "1", "]", "*", "recon_x", ".", "shape", "[", "2", "]", "*", "recon_x", ".", "shape", "[", "3", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.discriminator_loss": [[715, 720], ["prediction.cpu.cpu", "gt.cpu.cpu", "torch.BCELoss", "nn.BCELoss."], "function", ["None"], ["", "", "def", "discriminator_loss", "(", "prediction", ",", "gt", ")", ":", "\n", "  ", "prediction", "=", "prediction", ".", "cpu", "(", ")", "\n", "gt", "=", "gt", ".", "cpu", "(", ")", "\n", "BCE_loss", "=", "nn", ".", "BCELoss", "(", ")", "\n", "return", "BCE_loss", "(", "prediction", ",", "gt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.discriminator_loss_no_reduction": [[721, 726], ["prediction.cpu.cpu", "gt.cpu.cpu", "torch.BCELoss", "nn.BCELoss."], "function", ["None"], ["", "def", "discriminator_loss_no_reduction", "(", "prediction", ",", "gt", ")", ":", "\n", "  ", "prediction", "=", "prediction", ".", "cpu", "(", ")", "\n", "gt", "=", "gt", ".", "cpu", "(", ")", "\n", "BCE_loss", "=", "nn", ".", "BCELoss", "(", "reduction", "=", "'none'", ")", "\n", "return", "BCE_loss", "(", "prediction", ",", "gt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.discriminator_kl_divergence": [[727, 733], ["mean.cpu.cpu", "logvariance.cpu.cpu", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "mean.cpu.pow", "logvariance.cpu.exp"], "function", ["None"], ["", "def", "discriminator_kl_divergence", "(", "mean", ",", "logvariance", ")", ":", "\n", "  ", "mean", "=", "mean", ".", "cpu", "(", ")", "\n", "logvariance", "=", "logvariance", ".", "cpu", "(", ")", "\n", "\n", "KLD", "=", "0.5", "*", "torch", ".", "sum", "(", "mean", ".", "pow", "(", "2", ")", "+", "logvariance", ".", "exp", "(", ")", "-", "logvariance", "-", "1", ")", "\n", "return", "KLD", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.artist_prediction_loss": [[734, 743], ["artist_prediction_vector.cpu.cpu", "gt_one_hot_artist.cpu.cpu", "mean.cpu.cpu", "logvariance.cpu.cpu", "torch.BCELoss", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "nn.BCELoss.", "artist_prediction_vector.cpu.float", "gt_one_hot_artist.cpu.float", "mean.cpu.pow", "logvariance.cpu.exp"], "function", ["None"], ["", "def", "artist_prediction_loss", "(", "artist_prediction_vector", ",", "gt_one_hot_artist", ",", "mean", ",", "logvariance", ")", ":", "\n", "  ", "artist_prediction_vector", "=", "artist_prediction_vector", ".", "cpu", "(", ")", "\n", "gt_one_hot_artist", "=", "gt_one_hot_artist", ".", "cpu", "(", ")", "\n", "mean", "=", "mean", ".", "cpu", "(", ")", "\n", "logvariance", "=", "logvariance", ".", "cpu", "(", ")", "\n", "\n", "BCE_loss", "=", "nn", ".", "BCELoss", "(", ")", "\n", "KLD", "=", "0.5", "*", "(", "torch", ".", "sum", "(", "mean", ".", "pow", "(", "2", ")", "+", "logvariance", ".", "exp", "(", ")", "-", "logvariance", "-", "1", ")", "/", "artist_prediction_vector", ".", "shape", "[", "0", "]", ")", "\n", "return", "ARTIST_PREDICTION_WEIGHT", "*", "BCE_loss", "(", "artist_prediction_vector", ".", "float", "(", ")", ",", "gt_one_hot_artist", ".", "float", "(", ")", ")", "+", "ARTIST_KLD_WEIGHT", "*", "KLD", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.kl_divergence_two_gaussians": [[744, 754], ["p_mean.cpu.cpu", "q_mean.cpu.cpu", "p_logvar.cpu().exp", "q_logvar.cpu().exp", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "p_logvar.cpu", "q_logvar.cpu"], "function", ["None"], ["", "def", "kl_divergence_two_gaussians", "(", "p_mean", ",", "p_logvar", ",", "q_mean", ",", "q_logvar", ")", ":", "\n", "  ", "p_mean", "=", "p_mean", ".", "cpu", "(", ")", "\n", "q_mean", "=", "q_mean", ".", "cpu", "(", ")", "\n", "p_var", "=", "p_logvar", ".", "cpu", "(", ")", ".", "exp", "(", ")", "\n", "q_var", "=", "q_logvar", ".", "cpu", "(", ")", ".", "exp", "(", ")", "\n", "\n", "p", "=", "torch", ".", "distributions", ".", "normal", ".", "Normal", "(", "p_mean", ",", "torch", ".", "sqrt", "(", "p_var", ")", ")", "\n", "q", "=", "torch", ".", "distributions", ".", "normal", ".", "Normal", "(", "q_mean", ",", "torch", ".", "sqrt", "(", "q_var", ")", ")", "\n", "\n", "return", "torch", ".", "distributions", ".", "kl", ".", "kl_divergence", "(", "p", ",", "q", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.kl_divergence_two_gaussians_std": [[755, 765], ["p_mean.cpu.cpu", "q_mean.cpu.cpu", "p_std.cpu.cpu", "q_std.cpu.cpu", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence"], "function", ["None"], ["", "def", "kl_divergence_two_gaussians_std", "(", "p_mean", ",", "p_std", ",", "q_mean", ",", "q_std", ")", ":", "\n", "  ", "p_mean", "=", "p_mean", ".", "cpu", "(", ")", "\n", "q_mean", "=", "q_mean", ".", "cpu", "(", ")", "\n", "p_std", "=", "p_std", ".", "cpu", "(", ")", "\n", "q_std", "=", "q_std", ".", "cpu", "(", ")", "\n", "\n", "p", "=", "torch", ".", "distributions", ".", "normal", ".", "Normal", "(", "p_mean", ",", "p_std", ")", "\n", "q", "=", "torch", ".", "distributions", ".", "normal", ".", "Normal", "(", "q_mean", ",", "q_std", ")", "\n", "\n", "return", "torch", ".", "distributions", ".", "kl", ".", "kl_divergence", "(", "p", ",", "q", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.artist_kl_divergence": [[766, 768], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "vae_no_trip.kl_divergence_two_gaussians"], "function", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.kl_divergence_two_gaussians"], ["", "def", "artist_kl_divergence", "(", "latent_mean", ",", "latent_logvar", ",", "pretrained_mean", ",", "pretrained_logvar", ")", ":", "\n", "  ", "return", "torch", ".", "mean", "(", "torch", ".", "sum", "(", "kl_divergence_two_gaussians", "(", "latent_mean", ",", "latent_logvar", ",", "pretrained_mean", ",", "pretrained_logvar", ")", ",", "dim", "=", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.triplet_loss": [[769, 784], ["torch.MSELoss", "range", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "total_trip_loss.cpu", "nn.MSELoss.", "nn.MSELoss.", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "triplet_loss", "(", "a_mean", ",", "p_mean", ",", "n_mean", ")", ":", "\n", "    ", "mse_criterion", "=", "nn", ".", "MSELoss", "(", ")", "\n", "total_trip_loss", "=", "0", "\n", "num_positives", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "a_mean", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "distance", "=", "mse_criterion", "(", "p_mean", "[", "i", "]", ",", "a_mean", "[", "i", "]", ")", "-", "mse_criterion", "(", "n_mean", "[", "i", "]", ",", "a_mean", "[", "i", "]", ")", "\n", "trip_loss", "=", "torch", ".", "clamp", "(", "distance", "+", "TRIPLET_ALPHA", ",", "min", "=", "0", ")", "\n", "if", "trip_loss", ">", "torch", ".", "tensor", "(", "0", ")", ":", "\n", "            ", "num_positives", "+=", "1", "\n", "\n", "", "total_trip_loss", "+=", "trip_loss", "\n", "", "if", "num_positives", "==", "0", ":", "\n", "        ", "return", "total_trip_loss", ".", "cpu", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "(", "total_trip_loss", "/", "num_positives", ")", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.calculate_perceptual_loss": [[785, 793], ["[].cpu", "[].cpu", "torch.MSELoss", "nn.MSELoss.", "loss_network", "loss_network", "x.to"], "function", ["None"], ["", "", "def", "calculate_perceptual_loss", "(", "recon_x", ",", "x", ")", ":", "\n", "# vgg_model = vgg_model.cuda()", "\n", "  ", "recon_features", "=", "loss_network", "(", "recon_x", ")", "[", "2", "]", ".", "cpu", "(", ")", "\n", "orig_features", "=", "loss_network", "(", "x", ".", "to", "(", "device", ")", ")", "[", "2", "]", ".", "cpu", "(", ")", "\n", "\n", "# vgg_model = vgg_model.cpu()", "\n", "mse_criterion", "=", "nn", ".", "MSELoss", "(", ")", "\n", "return", "mse_criterion", "(", "recon_features", ",", "orig_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.calculate_artist_discriminator_loss": [[794, 850], ["zip", "enumerate", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "discriminator", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "discriminator", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "enumerate", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "vae_no_trip.discriminator_loss_no_reduction", "enumerate", "vae_no_trip.discriminator_loss_no_reduction", "discriminator.squeeze", "torch.zeros.float().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "discriminator", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "discriminator.squeeze", "torch.zeros.float().squeeze", "vae_no_trip.discriminator_loss_no_reduction", "torch.zeros.float", "discriminator.squeeze", "torch.zeros.float().squeeze", "torch.zeros.float", "torch.zeros.float"], "function", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.discriminator_loss_no_reduction", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.discriminator_loss_no_reduction", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.discriminator_loss_no_reduction"], ["", "def", "calculate_artist_discriminator_loss", "(", "image_batches", ",", "triplet_latent_vectors", ",", "corresponding_latent_vectors", ")", ":", "\n", "# Here we go through all (6 choose 2) combinations of images and get the discriminator loss for each", "\n", "\n", "  ", "num_same_artists", "=", "0.0", "\n", "num_diff_artists", "=", "12", "*", "triplet_latent_vectors", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "\n", "same_artist_disc_loss", "=", "0.0", "\n", "diff_artist_disc_loss", "=", "0.0", "\n", "\n", "# FIRST CASE (3 Comparisons): The images of the same author (we check if they are also the same image, and if so we mask out that loss)", "\n", "for", "image_batch", ",", "triplet_latent", ",", "corr_latent", "in", "zip", "(", "image_batches", ",", "triplet_latent_vectors", ",", "corresponding_latent_vectors", ")", ":", "\n", "    ", "should_mask_vector", "=", "image_batch", "[", "\"corresponding\"", "]", "[", "\"should_mask\"", "]", "==", "0", "\n", "\n", "num_same_artists", "+=", "torch", ".", "sum", "(", "should_mask_vector", ")", "\n", "\n", "latent_concat", "=", "torch", ".", "cat", "(", "(", "triplet_latent", ",", "corr_latent", ")", ",", "dim", "=", "1", ")", "\n", "prediction", "=", "discriminator", "(", "latent_concat", ")", "\n", "\n", "disc_label", "=", "torch", ".", "ones", "(", "prediction", ".", "shape", ")", "\n", "\n", "same_artist_disc_loss", "+=", "torch", ".", "sum", "(", "should_mask_vector", "*", "discriminator_loss_no_reduction", "(", "prediction", ".", "squeeze", "(", ")", ",", "disc_label", ".", "float", "(", ")", ".", "squeeze", "(", ")", ")", ")", "\n", "\n", "# SECOND CASE (6 Comparisons): Compare each image from the triplet to each image in the corresponding that are not the same image", "\n", "", "for", "triplet_idx", ",", "triplet_latent", "in", "enumerate", "(", "triplet_latent_vectors", ")", ":", "\n", "    ", "for", "corr_idx", ",", "corr_latent", "in", "enumerate", "(", "corresponding_latent_vectors", ")", ":", "\n", "      ", "if", "(", "corr_idx", "==", "triplet_idx", ")", ":", "\n", "        ", "continue", "\n", "\n", "", "", "latent_concat", "=", "torch", ".", "cat", "(", "(", "triplet_latent", ",", "corr_latent", ")", ",", "dim", "=", "1", ")", "\n", "prediction", "=", "discriminator", "(", "latent_concat", ")", "\n", "\n", "disc_label", "=", "torch", ".", "zeros", "(", "prediction", ".", "shape", ")", "\n", "diff_artist_disc_loss", "+=", "torch", ".", "sum", "(", "discriminator_loss_no_reduction", "(", "prediction", ".", "squeeze", "(", ")", ",", "disc_label", ".", "float", "(", ")", ".", "squeeze", "(", ")", ")", ")", "\n", "\n", "# THIRD CASE (6 Comparisons): Compare each image from the same triplet", "\n", "", "latent_vectors_list", "=", "[", "triplet_latent_vectors", ",", "corresponding_latent_vectors", "]", "\n", "for", "latent_vectors_triplet", "in", "latent_vectors_list", ":", "\n", "    ", "for", "trip1_idx", ",", "trip1_latent", "in", "enumerate", "(", "latent_vectors_triplet", ")", ":", "\n", "      ", "for", "trip2_idx", ",", "trip2_latent", "in", "enumerate", "(", "latent_vectors_triplet", ")", ":", "\n", "        ", "if", "(", "trip1_idx", "==", "trip2_idx", ")", ":", "\n", "          ", "continue", "\n", "", "latent_concat", "=", "torch", ".", "cat", "(", "(", "trip1_latent", ",", "trip2_latent", ")", ",", "dim", "=", "1", ")", "\n", "prediction", "=", "discriminator", "(", "latent_concat", ")", "\n", "\n", "disc_label", "=", "torch", ".", "zeros", "(", "prediction", ".", "shape", ")", "\n", "diff_artist_disc_loss", "+=", "torch", ".", "sum", "(", "discriminator_loss_no_reduction", "(", "prediction", ".", "squeeze", "(", ")", ",", "disc_label", ".", "float", "(", ")", ".", "squeeze", "(", ")", ")", ")", "\n", "\n", "\n", "\n", "", "", "", "total_artist_loss", "=", "0.0", "\n", "if", "torch", ".", "sum", "(", "num_same_artists", ")", "==", "0", ":", "\n", "    ", "total_artist_loss", "=", "diff_artist_disc_loss", "/", "num_diff_artists", "\n", "", "else", ":", "\n", "    ", "total_artist_loss", "=", "(", "same_artist_disc_loss", "/", "num_same_artists", ")", "+", "(", "diff_artist_disc_loss", "/", "num_diff_artists", ")", "\n", "\n", "", "return", "total_artist_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.calculate_base_vae_test": [[857, 964], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "print", "time.time", "time.time", "base_optimizer.zero_grad", "print", "print", "vae_no_trip.triplet_loss", "print", "print", "kld_writer.add_scalar", "recon_writer.add_scalar", "perceptual_writer.add_scalar", "loss.item", "writer.add_scalar", "len", "len", "len", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "print", "loss.item", "exit", "exit", "vae", "vae_no_trip.loss_function", "vae_no_trip.calculate_perceptual_loss", "loss.item", "mean_kld_loss.item", "mean_recon_loss.item", "image_metadata[].to", "latent_mean.append", "latent_logvar.append", "triplet_latent_vectors.append", "corresponding_latent_vectors.append", "image_metadata[].to"], "function", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.triplet_loss", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.loss_function", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.calculate_perceptual_loss"], ["def", "calculate_base_vae_test", "(", "curr_epoch", ")", ":", "\n", "    ", "test_loss", "=", "0.0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch_idx", ",", "data", "in", "enumerate", "(", "test_dataset_loader", ")", ":", "\n", "            ", "print", "(", "f\"Evaluating batch {batch_idx} for {model_name}\"", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "time_elapsed", "=", "end", "-", "start_time", "\n", "\n", "if", "not", "IS_RUNNING_NOTEBOOK", ":", "\n", "              ", "if", "time_elapsed", ">=", "TIMEOUT", ":", "\n", "                  ", "exit", "(", "0", ")", "\n", "", "if", "exit_code", "is", "not", "None", ":", "\n", "                  ", "exit", "(", "3", ")", "\n", "\n", "", "", "base_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "positive_image_batch", "=", "data", "[", "'positive'", "]", "\n", "negative_image_batch", "=", "data", "[", "'negative'", "]", "\n", "anchor_image_batch", "=", "data", "[", "'anchor'", "]", "\n", "\n", "image_batches", "=", "[", "positive_image_batch", ",", "negative_image_batch", ",", "anchor_image_batch", "]", "\n", "latent_mean", "=", "[", "]", "\n", "latent_logvar", "=", "[", "]", "\n", "\n", "triplet_latent_vectors", "=", "[", "]", "\n", "corresponding_latent_vectors", "=", "[", "]", "\n", "\n", "total_kld_loss", "=", "0", "\n", "total_recon_loss", "=", "0", "\n", "total_artist_loss", "=", "0", "\n", "total_perceptual_loss", "=", "0", "\n", "#total_trip_loss = 0", "\n", "\n", "\n", "for", "image_batch", "in", "image_batches", ":", "\n", "              ", "triplet_keys", "=", "[", "\"triplet\"", "]", "\n", "for", "triplet_key", "in", "triplet_keys", ":", "\n", "                ", "image_metadata", "=", "image_batch", "[", "triplet_key", "]", "\n", "\n", "recon", ",", "mean", ",", "log_variance", ",", "latent_vector", "=", "vae", "(", "image_metadata", "[", "'image'", "]", ".", "to", "(", "device", ")", ")", "\n", "\n", "# Extract out just the portion related to the artist", "\n", "z_artist", "=", "latent_vector", "[", ":", ",", "0", ":", "LATENT_ARTIST_SIZE", "]", "\n", "\n", "if", "triplet_key", "==", "\"triplet\"", ":", "\n", "                  ", "latent_mean", ".", "append", "(", "mean", ")", "\n", "latent_logvar", ".", "append", "(", "log_variance", ")", "\n", "triplet_latent_vectors", ".", "append", "(", "z_artist", ")", "\n", "", "else", ":", "\n", "                  ", "corresponding_latent_vectors", ".", "append", "(", "z_artist", ")", "\n", "\n", "", "data_widths", "=", "image_metadata", "[", "'width'", "]", "\n", "data_heights", "=", "image_metadata", "[", "'height'", "]", "\n", "\n", "kld_loss", ",", "recon_loss", "=", "loss_function", "(", "recon", ",", "image_metadata", "[", "'image'", "]", ".", "to", "(", "device", ")", ",", "mean", ",", "log_variance", ",", "data_widths", ",", "data_heights", ")", "\n", "total_kld_loss", "+=", "kld_loss", "\n", "\n", "#with torch.no_grad():", "\n", "perceptual_loss", "=", "calculate_perceptual_loss", "(", "recon", ",", "image_metadata", "[", "'image'", "]", ")", "\n", "\n", "total_perceptual_loss", "+=", "perceptual_loss", "\n", "\n", "total_recon_loss", "+=", "recon_loss", "\n", "#kld_loss.backward()", "\n", "#recon_loss.backward()", "\n", "\n", "\n", "\n", "#total_artist_loss = calculate_artist_discriminator_loss(image_batches, triplet_latent_vectors, corresponding_latent_vectors)", "\n", "\n", "", "", "mean_kld_loss", "=", "(", "total_kld_loss", "/", "(", "len", "(", "image_batches", ")", ")", ")", "\n", "print", "(", "f\"AVG KLD Loss: {mean_kld_loss}\"", ")", "\n", "\n", "mean_recon_loss", "=", "(", "total_recon_loss", "/", "(", "len", "(", "image_batches", ")", ")", ")", "\n", "#print(f\"AVG Recon Loss: {mean_recon_loss}\")", "\n", "\n", "#mean_artist_loss = total_artist_loss / 2.0", "\n", "#print(f\"AVG Artist Discriminator Loss: {mean_artist_loss}\")", "\n", "\n", "mean_percep_loss", "=", "(", "total_perceptual_loss", "/", "(", "len", "(", "image_batches", ")", ")", ")", "\n", "print", "(", "f\"AVG Perceptual Loss: {mean_percep_loss}\"", ")", "\n", "\n", "mean_triplet_loss", "=", "triplet_loss", "(", "latent_mean", "[", "2", "]", ",", "latent_mean", "[", "0", "]", ",", "latent_mean", "[", "1", "]", ")", "\n", "print", "(", "f\"Triplet Loss: {mean_triplet_loss}\"", ")", "\n", "\n", "#loss = (VAE_DIVERGENCE_WEIGHT * mean_kld_loss) + (RECONSTRUCTION_WEIGHT * mean_recon_loss) +  (TRIPLET_LOSS_WEIGHT * mean_triplet_loss)", "\n", "loss", "=", "(", "VAE_DIVERGENCE_WEIGHT", "*", "mean_kld_loss", ")", "+", "(", "PERCEP_LOSS_WEIGHT", "*", "mean_percep_loss", ")", "+", "(", "RECONSTRUCTION_WEIGHT", "*", "mean_recon_loss", ")", "#+ (TRIPLET_LOSS_WEIGHT * mean_triplet_loss)", "\n", "#loss = (VAE_DIVERGENCE_WEIGHT * mean_kld_loss) + (RECONSTRUCTION_WEIGHT * mean_recon_loss) + (LATENT_ARTIST_WEIGHT * mean_artist_loss) + (TRIPLET_LOSS_WEIGHT * mean_triplet_loss)", "\n", "print", "(", "f\"Overall Loss: {loss}\"", ")", "\n", "\n", "if", "torch", ".", "isnan", "(", "loss", ")", "or", "loss", ".", "item", "(", ")", ">", "MAX_VAE_LOSS_THRESHOLD", ":", "\n", "              ", "pickle_name", "=", "f\"{log_folder}/epoch{epoch}_batch{batch_idx}.pickle\"", "\n", "print", "(", "\"Loss outside usual range. Skipping and reporting error\"", ")", "\n", "del", "loss", "\n", "continue", "\n", "\n", "", "kld_writer", ".", "add_scalar", "(", "f'Loss/Test_{model_name}'", ",", "VAE_DIVERGENCE_WEIGHT", "*", "mean_kld_loss", ".", "item", "(", ")", ",", "curr_epoch", ")", "\n", "recon_writer", ".", "add_scalar", "(", "f'Loss/Test_{model_name}'", ",", "RECONSTRUCTION_WEIGHT", "*", "mean_recon_loss", ".", "item", "(", ")", ",", "curr_epoch", ")", "\n", "#artist_writer.add_scalar(f'Loss/Test_{model_name}', LATENT_ARTIST_WEIGHT * mean_artist_loss.item(), curr_epoch)", "\n", "#triplet_writer.add_scalar(f'Loss/Test_{model_name}', TRIPLET_LOSS_WEIGHT * mean_triplet_loss.item(), curr_epoch)", "\n", "perceptual_writer", ".", "add_scalar", "(", "f'Loss/Test_{model_name}'", ",", "PERCEP_LOSS_WEIGHT", "*", "mean_percep_loss", ",", "curr_epoch", ")", "\n", "\n", "test_loss", "+=", "loss", ".", "item", "(", ")", "\n", "writer", ".", "add_scalar", "(", "f'Loss/Test_{model_name}'", ",", "loss", ".", "item", "(", ")", ",", "curr_epoch", ")", "\n", "\n", "\n", "", "", "return", "test_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.train_base_vae": [[969, 1144], ["print", "print", "range", "len", "enumerate", "print", "time.time", "time.time", "base_optimizer.zero_grad", "print", "print", "print", "vae_no_trip.triplet_loss", "print", "kld_writer.add_scalar", "recon_writer.add_scalar", "perceptual_writer.add_scalar", "print", "writer.add_scalar", "loss.backward", "loss.item", "base_optimizer.step", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "len", "len", "len", "losses.append", "losses.append", "losses.pop", "loss.item", "torchvision.utils.make_grid", "torchvision.utils.make_grid", "writer.add_image", "matplotlib.pyplot.subplots", "f.set_figheight", "f.set_figwidth", "range", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "vae_no_trip.calculate_base_vae_test", "print", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "print", "print", "vae.to.state_dict", "vae_no_trip.safe_exit", "print", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "vae_no_trip.safe_exit", "vae.to.to", "vae.to.", "vae_no_trip.calculate_perceptual_loss", "vae_no_trip.loss_function", "loss.item", "numpy.sum", "loss.item", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "print", "min", "numpy.transpose", "axarr[].imshow", "vae.to.state_dict", "os.path.exists", "vae.to.state_dict", "image_metadata[].to", "latent_mean.append", "latent_logvar.append", "triplet_latent_vectors.append", "corresponding_latent_vectors.append", "image_metadata[].to", "loss.item", "loss.item", "recon[].cpu().detach().numpy", "os.remove", "len", "recon[].cpu().detach", "recon[].cpu"], "function", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.triplet_loss", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.vae_no_trip.calculate_base_vae_test", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.safe_exit", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.safe_exit", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.calculate_perceptual_loss", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.loss_function"], ["def", "train_base_vae", "(", "vae", ",", "end_iters", ",", "results_folder", ",", "weights_folder", ",", "prefix", ",", "start_iters", ",", "log_folder", ")", ":", "\n", "#pdb.set_trace()", "\n", "    ", "loss_array", "=", "[", "]", "\n", "test_losses", "=", "[", "]", "\n", "display_interval", "=", "479", "\n", "save_interval", "=", "479", "*", "15", "\n", "print", "(", "f\"start iters: {start_iters}\"", ")", "\n", "print", "(", "f\"end iters: {end_iters}\"", ")", "\n", "for", "iters", "in", "range", "(", "start_iters", ",", "end_iters", ",", "len", "(", "train_dataset_loader", ")", ")", ":", "\n", "        ", "train_loss", "=", "0", "\n", "NUM_SAMPLES_IN_AVG", "=", "10", "\n", "losses", "=", "[", "]", "\n", "for", "batch_idx", ",", "data", "in", "enumerate", "(", "train_dataset_loader", ")", ":", "\n", "#pdb.set_trace()", "\n", "            ", "total_iters", "=", "batch_idx", "+", "iters", "\n", "if", "total_iters", ">=", "end_iters", ":", "\n", "                ", "save_filename", "=", "f'{prefix}{total_iters}.pt'", "\n", "save_path", "=", "f'{weights_folder}/{save_filename}'", "\n", "torch", ".", "save", "(", "vae", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "return", "\n", "", "print", "(", "f\"Evaluating batch {total_iters} for {model_name}\"", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "time_elapsed", "=", "end", "-", "start_time", "\n", "if", "not", "IS_RUNNING_NOTEBOOK", ":", "\n", "              ", "if", "time_elapsed", ">=", "TIMEOUT", ":", "\n", "                  ", "safe_exit", "(", "0", ")", "\n", "", "if", "exit_code", "is", "not", "None", ":", "\n", "                  ", "print", "(", "\"caught the exception!\"", ")", "\n", "save_filename", "=", "f'{prefix}{total_iters}.pt'", "\n", "save_path", "=", "f'{weights_folder}/{save_filename}'", "\n", "torch", ".", "save", "(", "vae", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "safe_exit", "(", "3", ")", "\n", "return", "\n", "\n", "\n", "", "", "base_optimizer", ".", "zero_grad", "(", ")", "\n", "#discriminator_optimizer.zero_grad()", "\n", "\n", "positive_image_batch", "=", "data", "[", "'positive'", "]", "\n", "negative_image_batch", "=", "data", "[", "'negative'", "]", "\n", "anchor_image_batch", "=", "data", "[", "'anchor'", "]", "\n", "\n", "image_batches", "=", "[", "positive_image_batch", ",", "negative_image_batch", ",", "anchor_image_batch", "]", "\n", "latent_mean", "=", "[", "]", "\n", "latent_logvar", "=", "[", "]", "\n", "\n", "triplet_latent_vectors", "=", "[", "]", "\n", "corresponding_latent_vectors", "=", "[", "]", "\n", "\n", "total_kld_loss", "=", "0", "\n", "total_recon_loss", "=", "0", "\n", "total_artist_loss", "=", "0", "\n", "total_perceptual_loss", "=", "0", "\n", "total_trip_loss", "=", "0", "\n", "\n", "for", "image_batch", "in", "image_batches", ":", "\n", "              ", "triplet_keys", "=", "[", "\"triplet\"", "]", "\n", "for", "triplet_key", "in", "triplet_keys", ":", "\n", "                ", "image_metadata", "=", "image_batch", "[", "triplet_key", "]", "\n", "\n", "vae", "=", "vae", ".", "to", "(", "device", ")", "\n", "recon", ",", "mean", ",", "log_variance", ",", "latent_vector", "=", "vae", "(", "image_metadata", "[", "'image'", "]", ".", "to", "(", "device", ")", ")", "\n", "\n", "# Extract out just the portion related to the artist", "\n", "z_artist", "=", "latent_vector", "[", ":", ",", "0", ":", "LATENT_ARTIST_SIZE", "]", "\n", "\n", "if", "triplet_key", "==", "\"triplet\"", ":", "\n", "                  ", "latent_mean", ".", "append", "(", "mean", ")", "\n", "latent_logvar", ".", "append", "(", "log_variance", ")", "\n", "triplet_latent_vectors", ".", "append", "(", "z_artist", ")", "\n", "", "else", ":", "\n", "                  ", "corresponding_latent_vectors", ".", "append", "(", "z_artist", ")", "\n", "\n", "", "data_widths", "=", "image_metadata", "[", "'width'", "]", "\n", "data_heights", "=", "image_metadata", "[", "'height'", "]", "\n", "\n", "perceptual_loss", "=", "calculate_perceptual_loss", "(", "recon", ",", "image_metadata", "[", "'image'", "]", ")", "\n", "\n", "kld_loss", ",", "recon_loss", "=", "loss_function", "(", "recon", ",", "image_metadata", "[", "'image'", "]", ".", "to", "(", "device", ")", ",", "mean", ",", "log_variance", ",", "data_widths", ",", "data_heights", ")", "\n", "total_kld_loss", "+=", "kld_loss", "\n", "total_recon_loss", "+=", "recon_loss", "\n", "total_perceptual_loss", "+=", "perceptual_loss", "\n", "#total_trip_loss += VAE_DIVERGENCE_WEIGHT * kld_loss + PERCEP_LOSS_WEIGHT * perceptual_loss", "\n", "#trip_loss = VAE_DIVERGENCE_WEIGHT * kld_loss + RECONSTRUCTION_WEIGHT * recon_loss", "\n", "#trip_loss.backward()", "\n", "\n", "\n", "\n", "#total_artist_loss = calculate_artist_discriminator_loss(image_batches, triplet_latent_vectors, corresponding_latent_vectors)", "\n", "\n", "", "", "mean_percep_loss", "=", "(", "total_perceptual_loss", "/", "(", "len", "(", "image_batches", ")", ")", ")", "\n", "print", "(", "f\"AVG Perceptual Loss: {PERCEP_LOSS_WEIGHT * mean_percep_loss}\"", ")", "\n", "\n", "mean_kld_loss", "=", "(", "total_kld_loss", "/", "(", "len", "(", "image_batches", ")", ")", ")", "\n", "print", "(", "f\"AVG KLD Loss: {VAE_DIVERGENCE_WEIGHT * mean_kld_loss}\"", ")", "\n", "\n", "mean_recon_loss", "=", "(", "total_recon_loss", "/", "(", "len", "(", "image_batches", ")", ")", ")", "\n", "print", "(", "f\"AVG Recon Loss: {RECONSTRUCTION_WEIGHT * mean_recon_loss}\"", ")", "\n", "\n", "#mean_artist_loss = total_artist_loss / 2", "\n", "#print(f\"AVG Artist Discriminator Loss: {LATENT_ARTIST_WEIGHT * mean_artist_loss}\")", "\n", "# pna -> apn", "\n", "mean_triplet_loss", "=", "triplet_loss", "(", "latent_mean", "[", "2", "]", ",", "latent_mean", "[", "0", "]", ",", "latent_mean", "[", "1", "]", ")", "\n", "\n", "#overall_loss = (total_trip_loss/3.0) + mean_triplet_loss", "\n", "#loss = VAE_DIVERGENCE_WEIGHT * mean_kld_loss + PERCEP_LOSS_WEIGHT * mean_percep_loss + TRIPLET_LOSS_WEIGHT * mean_triplet_loss", "\n", "loss", "=", "(", "VAE_DIVERGENCE_WEIGHT", "*", "mean_kld_loss", ")", "+", "(", "PERCEP_LOSS_WEIGHT", "*", "mean_percep_loss", ")", "+", "(", "RECONSTRUCTION_WEIGHT", "*", "mean_recon_loss", ")", "#+ TRIPLET_LOSS_WEIGHT * mean_triplet_loss", "\n", "print", "(", "f\"Overall Loss: {loss.item()}\"", ")", "\n", "\n", "if", "batch_idx", "<", "NUM_SAMPLES_IN_AVG", ":", "\n", "                 ", "losses", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "", "else", ":", "\n", "                 ", "avg", "=", "np", ".", "sum", "(", "losses", ")", "/", "NUM_SAMPLES_IN_AVG", "\n", "losses", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "losses", ".", "pop", "(", "0", ")", "\n", "if", "torch", ".", "isnan", "(", "loss", ")", "or", "loss", ".", "item", "(", ")", ">", "(", "avg", "+", "MAX_VAE_LOSS_THRESHOLD", ")", ":", "\n", "                   ", "pickle_name", "=", "f\"{log_folder}/epoch{epoch}_batch{batch_idx}.pickle\"", "\n", "print", "(", "\"Loss outside usual range. Skipping and reporting error\"", ")", "\n", "del", "loss", "\n", "del", "mean_percep_loss", "\n", "del", "mean_kld_loss", "\n", "del", "mean_recon_loss", "\n", "del", "mean_triplet_loss", "\n", "continue", "\n", "\n", "", "", "kld_writer", ".", "add_scalar", "(", "f'Loss/Train_{model_name}'", ",", "VAE_DIVERGENCE_WEIGHT", "*", "mean_kld_loss", ",", "total_iters", ")", "\n", "recon_writer", ".", "add_scalar", "(", "f'Loss/Train_{model_name}'", ",", "RECONSTRUCTION_WEIGHT", "*", "mean_recon_loss", ",", "total_iters", ")", "\n", "#artist_writer.add_scalar(f'Loss/Train_{model_name}', LATENT_ARTIST_WEIGHT * mean_artist_loss.item(), epoch * len(train_dataset_loader) + batch_idx)", "\n", "#triplet_writer.add_scalar(f'Loss/Train_{model_name}', TRIPLET_LOSS_WEIGHT * mean_triplet_loss, total_iters)", "\n", "perceptual_writer", ".", "add_scalar", "(", "f'Loss/Train_{model_name}'", ",", "PERCEP_LOSS_WEIGHT", "*", "mean_percep_loss", ",", "total_iters", ")", "\n", "\n", "print", "(", "f\"Step: {total_iters}\"", ")", "\n", "writer", ".", "add_scalar", "(", "f'Loss/Train_{model_name}'", ",", "loss", ".", "item", "(", ")", ",", "total_iters", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "base_optimizer", ".", "step", "(", ")", "\n", "#discriminator_optimizer.step()", "\n", "\n", "if", "total_iters", "%", "display_interval", "==", "0", ":", "\n", "              ", "grid", "=", "torchvision", ".", "utils", ".", "make_grid", "(", "recon", "[", "0", ":", "5", "]", ")", "\n", "writer", ".", "add_image", "(", "f'Images/{model_name}'", ",", "grid", ",", "total_iters", ")", "\n", "## Generate first 5 images of batch and save them to file", "\n", "f", ",", "axarr", "=", "plt", ".", "subplots", "(", "1", ",", "5", ")", "\n", "f", ".", "set_figheight", "(", "5", ")", "\n", "f", ".", "set_figwidth", "(", "10", ")", "\n", "\n", "for", "i", "in", "range", "(", "min", "(", "5", ",", "recon", ".", "shape", "[", "0", "]", ")", ")", ":", "\n", "                  ", "imgorg", "=", "np", ".", "transpose", "(", "recon", "[", "i", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", "(", "1", ",", "2", ",", "0", ")", ")", "\n", "axarr", "[", "i", "]", ".", "imshow", "(", "imgorg", ")", "\n", "\n", "", "image_save_path", "=", "f'{results_folder}/{prefix}{epoch}.png'", "\n", "plt", ".", "savefig", "(", "f\"{image_save_path}\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "## Calculate the test loss", "\n", "test_loss", "=", "calculate_base_vae_test", "(", "total_iters", ")", "\n", "\n", "print", "(", "'====> Iters: {} Average loss: {:.4f}'", ".", "format", "(", "\n", "total_iters", ",", "train_loss", "/", "len", "(", "train_dataset_loader", ".", "dataset", ")", ")", ")", "\n", "\n", "## Checkpointing", "\n", "save_filename", "=", "f'{prefix}{total_iters}.pt'", "\n", "save_path", "=", "f'{weights_folder}/{save_filename}'", "\n", "torch", ".", "save", "(", "vae", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "#disc_save_path = f'{LATENT_ARTIST_MODEL_LOAD_PATH}/{save_filename}'", "\n", "#torch.save(discriminator.state_dict, disc_save_path)", "\n", "\n", "print", "(", "f\"Saving weights to: {weights_folder}\"", ")", "\n", "if", "total_iters", "%", "save_interval", "!=", "0", ":", "\n", "                  ", "if", "os", ".", "path", ".", "exists", "(", "f'{weights_folder}/{prefix}{total_iters - display_interval}.pt'", ")", ":", "\n", "                      ", "os", ".", "remove", "(", "f'{weights_folder}/{prefix}{total_iters - display_interval}.pt'", ")", "\n", "#os.remove(f'{LATENT_ARTIST_MODEL_LOAD_PATH}/{prefix}{epoch - 1}.pt')", "\n", "", "", "print", "(", "f\"Saved images results to: {image_save_path}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.ArtDataset.__init__": [[216, 229], ["metadata_df.reset_index"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "image_folder", ",", "triplet_df", ",", "metadata_df", ",", "largest_height", ",", "largest_width", ",", "transform", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            image_folder (string): Directory with all the images.\n            metadata_df (Pandas Dataframe): Dataframe containing the metadata\n            transform (Torchvision.Transform) Transform to be applied to the image data\n        \"\"\"", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "metadata", "=", "metadata_df", ".", "reset_index", "(", ")", "\n", "self", ".", "triplets", "=", "triplet_df", "\n", "self", ".", "image_folder", "=", "image_folder", "\n", "self", ".", "largest_height", "=", "largest_height", "\n", "self", ".", "largest_width", "=", "largest_width", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.ArtDataset.__len__": [[230, 232], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "triplets", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.ArtDataset.return_transformed_image": [[233, 239], ["PIL.Image.open", "triplet_vgg.ArtDataset.transform", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d.", "os.path.join"], "methods", ["None"], ["", "def", "return_transformed_image", "(", "self", ",", "image_filename", ")", ":", "\n", "        ", "image", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "image_folder", ",", "image_filename", ")", ")", "\n", "(", "width", ",", "height", ")", "=", "image", ".", "size", "\n", "tensor_image", "=", "self", ".", "transform", "(", "image", ")", "\n", "pad_layer", "=", "nn", ".", "ZeroPad2d", "(", "(", "0", ",", "self", ".", "largest_width", "-", "width", ",", "0", ",", "self", ".", "largest_height", "-", "height", ")", ")", "\n", "return", "pad_layer", "(", "tensor_image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.ArtDataset.get_random_artist_image": [[240, 244], ["random.choice"], "methods", ["None"], ["", "def", "get_random_artist_image", "(", "self", ",", "artist", ")", ":", "\n", "        ", "artist_indices", "=", "self", ".", "metadata", "[", "self", ".", "metadata", "[", "'cleaned_artist'", "]", "==", "artist", "]", ".", "index", "\n", "random_artist_idx", "=", "random", ".", "choice", "(", "artist_indices", ")", "\n", "return", "self", ".", "metadata", ".", "iloc", "[", "random_artist_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.ArtDataset.__getitem__": [[245, 298], ["zip", "int", "triplet_vgg.ArtDataset.return_transformed_image"], "methods", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.ArtDataset.return_transformed_image"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "      ", "row", "=", "self", ".", "triplets", ".", "iloc", "[", "idx", "]", "\n", "\n", "positive_idx", "=", "int", "(", "row", "[", "'Positive'", "]", ")", "-", "1", "\n", "negative_idx", "=", "(", "1", "-", "positive_idx", ")", "\n", "\n", "triplet_names", "=", "[", "'1'", ",", "'2'", ",", "'anchor'", "]", "\n", "\n", "# Re-Arranges it so now it's of the form positive, negative, anchor.", "\n", "triplet_files", "=", "[", "row", "[", "triplet_names", "[", "positive_idx", "]", "]", ",", "row", "[", "triplet_names", "[", "negative_idx", "]", "]", ",", "row", "[", "triplet_names", "[", "2", "]", "]", "]", "\n", "labels", "=", "[", "'positive'", ",", "'negative'", ",", "'anchor'", "]", "\n", "\n", "triplet_objects", "=", "{", "}", "\n", "\n", "for", "filename", ",", "label", "in", "zip", "(", "triplet_files", ",", "labels", ")", ":", "\n", "        ", "triplet_object", "=", "{", "}", "\n", "\n", "triplet_image", "=", "{", "}", "\n", "triplet_corresponding", "=", "{", "}", "\n", "\n", "image_metadata", "=", "self", ".", "metadata", ".", "loc", "[", "self", ".", "metadata", "[", "'filename'", "]", "==", "filename", "]", "\n", "image_name", "=", "image_metadata", "[", "'filename'", "]", ".", "values", "[", "0", "]", "\n", "\n", "triplet_image", "[", "'artist'", "]", "=", "image_metadata", "[", "'cleaned_artist'", "]", ".", "values", "[", "0", "]", "\n", "triplet_image", "[", "'image'", "]", "=", "self", ".", "return_transformed_image", "(", "image_name", ")", "\n", "\n", "triplet_image", "[", "'normalized_midpoint'", "]", "=", "image_metadata", "[", "'normalized_midpoint'", "]", ".", "values", "[", "0", "]", "\n", "triplet_image", "[", "'normalized_start'", "]", "=", "image_metadata", "[", "'normalized_start'", "]", ".", "values", "[", "0", "]", "\n", "triplet_image", "[", "'normalized_end'", "]", "=", "image_metadata", "[", "'normalized_end'", "]", ".", "values", "[", "0", "]", "\n", "\n", "triplet_image", "[", "'width'", "]", "=", "image_metadata", "[", "'width'", "]", ".", "values", "[", "0", "]", "\n", "triplet_image", "[", "'height'", "]", "=", "image_metadata", "[", "'height'", "]", ".", "values", "[", "0", "]", "\n", "\n", "#random_artist = self.get_random_artist_image(triplet_image['artist'])", "\n", "\n", "#triplet_corresponding['image'] = self.return_transformed_image(random_artist['filename'])", "\n", "#triplet_corresponding['filename'] = random_artist['filename']", "\n", "\n", "#triplet_corresponding['normalized_midpoint'] = random_artist['normalized_midpoint']", "\n", "#triplet_corresponding['normalized_start'] = random_artist['normalized_start']", "\n", "#triplet_corresponding['normalized_end'] = random_artist['normalized_end']", "\n", "\n", "#triplet_corresponding['width'] = random_artist['width']", "\n", "#triplet_corresponding['height'] = random_artist['height']", "\n", "\n", "#triplet_corresponding['should_mask'] = (random_artist['filename'] == image_metadata['filename'].values[0])", "\n", "\n", "triplet_object", "[", "'triplet'", "]", "=", "triplet_image", "\n", "#triplet_object['corresponding'] = triplet_corresponding", "\n", "\n", "triplet_objects", "[", "label", "]", "=", "triplet_object", "\n", "\n", "", "return", "triplet_objects", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.TRIPLET_VGG.__init__": [[427, 434], ["torch.Module.__init__", "torchvision.models.vgg16().to", "triplet_vgg.TRIPLET_VGG.pretrained_net.eval", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torchvision.models.vgg16"], "methods", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.TRIPLET_VGG.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "TRIPLET_VGG", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pretrained_net", "=", "models", ".", "vgg16", "(", "pretrained", "=", "True", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "pretrained_net", "=", "self", ".", "pretrained_net", ".", "eval", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "4096", ",", "2048", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm1d", "(", "2048", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "2048", ",", "1024", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.TRIPLET_VGG.forward": [[435, 455], ["triplet_vgg.TRIPLET_VGG.bn1", "triplet_vgg.TRIPLET_VGG.fc2", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "triplet_vgg.TRIPLET_VGG.pretrained_net.avgpool", "model.view", "enumerate", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "model", "model", "triplet_vgg.TRIPLET_VGG.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "      ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "activations", "=", "None", "\n", "output", "=", "x", "\n", "for", "_", ",", "model", "in", "enumerate", "(", "self", ".", "pretrained_net", ".", "features", ")", ":", "\n", "          ", "output", "=", "model", "(", "output", ")", "\n", "\n", "", "output", "=", "self", ".", "pretrained_net", ".", "avgpool", "(", "output", ")", "\n", "output", "=", "output", ".", "view", "(", "output", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "# for _, model in enumerate(pretrained_net.avgpool):", "\n", "# output = model(output)", "\n", "for", "layer_id", ",", "model", "in", "enumerate", "(", "self", ".", "pretrained_net", ".", "classifier", ")", ":", "\n", "          ", "output", "=", "model", "(", "output", ")", "\n", "if", "layer_id", "==", "3", ":", "\n", "            ", "break", "\n", "\n", "", "", "", "output", "=", "self", ".", "bn1", "(", "F", ".", "relu", "(", "self", ".", "fc1", "(", "output", ")", ")", ")", "\n", "output", "=", "self", ".", "fc2", "(", "output", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.safe_exit": [[72, 77], ["print", "sys.stdout.flush", "sys.stdout.flush", "sys.stdout.flush"], "function", ["None"], ["def", "safe_exit", "(", "signal_num", ",", "ec", "=", "0", ",", "total_iters", "=", "0", ",", "exp_name", "=", "\"\"", ")", ":", "\n", "    ", "print", "(", "\"Caught a signal\"", ",", "signal_num", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "global", "exit_code", "\n", "exit_code", "=", "signal_num", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.find_latest_checkpoint_in_dir": [[463, 485], ["os.listdir", "os.listdir.remove", "pretrained_model.split", "int", "print", "print", "len", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "prefix_split[].split"], "function", ["None"], ["def", "find_latest_checkpoint_in_dir", "(", "load_dir", ",", "prefix", ")", ":", "\n", "  ", "pretrained_models", "=", "os", ".", "listdir", "(", "load_dir", ")", "\n", "if", "'.ipynb_checkpoints'", "in", "pretrained_models", ":", "\n", "    ", "pretrained_models", ".", "remove", "(", "'.ipynb_checkpoints'", ")", "\n", "", "max_model_name", "=", "\"\"", "\n", "max_model_no", "=", "-", "1", "\n", "for", "pretrained_model", "in", "pretrained_models", ":", "\n", "    ", "prefix_split", "=", "pretrained_model", ".", "split", "(", "f\"{prefix}\"", ")", "\n", "if", "len", "(", "prefix_split", ")", "!=", "2", ":", "\n", "      ", "continue", "\n", "", "model_no", "=", "int", "(", "prefix_split", "[", "1", "]", ".", "split", "(", "\".pt\"", ")", "[", "0", "]", ")", "\n", "if", "model_no", ">", "max_model_no", ":", "\n", "      ", "max_model_no", "=", "model_no", "\n", "max_model_name", "=", "pretrained_model", "\n", "", "", "epoch", "=", "0", "\n", "if", "max_model_name", "==", "\"\"", ":", "\n", "    ", "print", "(", "\"Could not find pretrained model.\"", ")", "\n", "return", "None", "\n", "", "else", ":", "\n", "    ", "print", "(", "f\"Loaded pretrained model: {max_model_name}\"", ")", "\n", "epoch", "=", "max_model_no", "\n", "return", "epoch", ",", "torch", ".", "load", "(", "f'{load_dir}/{max_model_name}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.display_first_n_of_batch": [[503, 513], ["matplotlib.pyplot.subplots", "f.set_figheight", "f.set_figwidth", "range", "matplotlib.pyplot.show", "numpy.transpose", "axarr[].imshow", "batch[].cpu().detach().numpy", "batch[].cpu().detach", "batch[].cpu"], "function", ["None"], ["def", "display_first_n_of_batch", "(", "batch", ",", "n", ")", ":", "\n", "  ", "f", ",", "axarr", "=", "plt", ".", "subplots", "(", "1", ",", "n", ")", "\n", "f", ".", "set_figheight", "(", "n", ")", "\n", "f", ".", "set_figwidth", "(", "2", "*", "n", ")", "\n", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "      ", "imgorg", "=", "np", ".", "transpose", "(", "batch", "[", "i", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", "(", "1", ",", "2", ",", "0", ")", ")", "\n", "axarr", "[", "i", "]", ".", "imshow", "(", "imgorg", ")", "\n", "\n", "", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.loss_function": [[516, 539], ["recon_x.cpu.cpu", "x.cpu.cpu", "mean.cpu.cpu", "logvariance.cpu.cpu", "data_widths.cpu.cpu", "data_heights.cpu.cpu", "torch.binary_cross_entropy().cpu", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.binary_cross_entropy", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "mean.cpu.pow", "logvariance.cpu.exp"], "function", ["None"], ["", "def", "loss_function", "(", "recon_x", ",", "x", ",", "mean", ",", "logvariance", ",", "data_widths", ",", "data_heights", ")", ":", "\n", "    ", "recon_x", "=", "recon_x", ".", "cpu", "(", ")", "\n", "x", "=", "x", ".", "cpu", "(", ")", "\n", "mean", "=", "mean", ".", "cpu", "(", ")", "\n", "logvariance", "=", "logvariance", ".", "cpu", "(", ")", "\n", "data_widths", "=", "data_widths", ".", "cpu", "(", ")", "\n", "data_heights", "=", "data_heights", ".", "cpu", "(", ")", "\n", "\n", "BCE", "=", "F", ".", "binary_cross_entropy", "(", "recon_x", ",", "x", ",", "reduction", "=", "'none'", ")", ".", "cpu", "(", ")", "\n", "mask_matrix", "=", "torch", ".", "zeros", "(", "recon_x", ".", "shape", ")", "\n", "\n", "# Iterate through each element in the batch", "\n", "for", "i", "in", "range", "(", "0", ",", "recon_x", ".", "shape", "[", "0", "]", ")", ":", "\n", "      ", "mask_matrix", "[", "i", ",", ":", ",", "0", ":", "data_heights", "[", "i", "]", ",", "0", ":", "data_widths", "[", "i", "]", "]", "=", "torch", ".", "ones", "(", "(", "3", ",", "data_heights", "[", "i", "]", ",", "data_widths", "[", "i", "]", ")", ")", "\n", "\n", "# Normalize KL Divergence loss by batch size", "\n", "", "KLD", "=", "0.5", "*", "(", "torch", ".", "sum", "(", "mean", ".", "pow", "(", "2", ")", "+", "logvariance", ".", "exp", "(", ")", "-", "logvariance", "-", "1", ")", "/", "recon_x", ".", "shape", "[", "0", "]", ")", "\n", "\n", "if", "MASK_TYPE", "==", "\"mask\"", ":", "\n", "      ", "masked_BCE", "=", "BCE", "*", "mask_matrix", "\n", "return", "(", "KLD", ")", ",", "(", "torch", ".", "sum", "(", "masked_BCE", "/", "(", "recon_x", ".", "shape", "[", "1", "]", "*", "torch", ".", "sum", "(", "data_widths", "*", "data_heights", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "      ", "return", "(", "KLD", ")", ",", "(", "torch", ".", "sum", "(", "BCE", ")", "/", "(", "recon_x", ".", "shape", "[", "0", "]", "*", "recon_x", ".", "shape", "[", "1", "]", "*", "recon_x", ".", "shape", "[", "2", "]", "*", "recon_x", ".", "shape", "[", "3", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.discriminator_loss": [[540, 545], ["prediction.cpu.cpu", "gt.cpu.cpu", "torch.BCELoss", "nn.BCELoss."], "function", ["None"], ["", "", "def", "discriminator_loss", "(", "prediction", ",", "gt", ")", ":", "\n", "  ", "prediction", "=", "prediction", ".", "cpu", "(", ")", "\n", "gt", "=", "gt", ".", "cpu", "(", ")", "\n", "BCE_loss", "=", "nn", ".", "BCELoss", "(", ")", "\n", "return", "BCE_loss", "(", "prediction", ",", "gt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.discriminator_loss_no_reduction": [[546, 551], ["prediction.cpu.cpu", "gt.cpu.cpu", "torch.BCELoss", "nn.BCELoss."], "function", ["None"], ["", "def", "discriminator_loss_no_reduction", "(", "prediction", ",", "gt", ")", ":", "\n", "  ", "prediction", "=", "prediction", ".", "cpu", "(", ")", "\n", "gt", "=", "gt", ".", "cpu", "(", ")", "\n", "BCE_loss", "=", "nn", ".", "BCELoss", "(", "reduction", "=", "'none'", ")", "\n", "return", "BCE_loss", "(", "prediction", ",", "gt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.discriminator_kl_divergence": [[552, 558], ["mean.cpu.cpu", "logvariance.cpu.cpu", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "mean.cpu.pow", "logvariance.cpu.exp"], "function", ["None"], ["", "def", "discriminator_kl_divergence", "(", "mean", ",", "logvariance", ")", ":", "\n", "  ", "mean", "=", "mean", ".", "cpu", "(", ")", "\n", "logvariance", "=", "logvariance", ".", "cpu", "(", ")", "\n", "\n", "KLD", "=", "0.5", "*", "torch", ".", "sum", "(", "mean", ".", "pow", "(", "2", ")", "+", "logvariance", ".", "exp", "(", ")", "-", "logvariance", "-", "1", ")", "\n", "return", "KLD", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.artist_prediction_loss": [[559, 568], ["artist_prediction_vector.cpu.cpu", "gt_one_hot_artist.cpu.cpu", "mean.cpu.cpu", "logvariance.cpu.cpu", "torch.BCELoss", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "nn.BCELoss.", "artist_prediction_vector.cpu.float", "gt_one_hot_artist.cpu.float", "mean.cpu.pow", "logvariance.cpu.exp"], "function", ["None"], ["", "def", "artist_prediction_loss", "(", "artist_prediction_vector", ",", "gt_one_hot_artist", ",", "mean", ",", "logvariance", ")", ":", "\n", "  ", "artist_prediction_vector", "=", "artist_prediction_vector", ".", "cpu", "(", ")", "\n", "gt_one_hot_artist", "=", "gt_one_hot_artist", ".", "cpu", "(", ")", "\n", "mean", "=", "mean", ".", "cpu", "(", ")", "\n", "logvariance", "=", "logvariance", ".", "cpu", "(", ")", "\n", "\n", "BCE_loss", "=", "nn", ".", "BCELoss", "(", ")", "\n", "KLD", "=", "0.5", "*", "(", "torch", ".", "sum", "(", "mean", ".", "pow", "(", "2", ")", "+", "logvariance", ".", "exp", "(", ")", "-", "logvariance", "-", "1", ")", "/", "artist_prediction_vector", ".", "shape", "[", "0", "]", ")", "\n", "return", "ARTIST_PREDICTION_WEIGHT", "*", "BCE_loss", "(", "artist_prediction_vector", ".", "float", "(", ")", ",", "gt_one_hot_artist", ".", "float", "(", ")", ")", "+", "ARTIST_KLD_WEIGHT", "*", "KLD", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.kl_divergence_two_gaussians": [[569, 579], ["p_mean.cpu.cpu", "q_mean.cpu.cpu", "p_logvar.cpu().exp", "q_logvar.cpu().exp", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "p_logvar.cpu", "q_logvar.cpu"], "function", ["None"], ["", "def", "kl_divergence_two_gaussians", "(", "p_mean", ",", "p_logvar", ",", "q_mean", ",", "q_logvar", ")", ":", "\n", "  ", "p_mean", "=", "p_mean", ".", "cpu", "(", ")", "\n", "q_mean", "=", "q_mean", ".", "cpu", "(", ")", "\n", "p_var", "=", "p_logvar", ".", "cpu", "(", ")", ".", "exp", "(", ")", "\n", "q_var", "=", "q_logvar", ".", "cpu", "(", ")", ".", "exp", "(", ")", "\n", "\n", "p", "=", "torch", ".", "distributions", ".", "normal", ".", "Normal", "(", "p_mean", ",", "torch", ".", "sqrt", "(", "p_var", ")", ")", "\n", "q", "=", "torch", ".", "distributions", ".", "normal", ".", "Normal", "(", "q_mean", ",", "torch", ".", "sqrt", "(", "q_var", ")", ")", "\n", "\n", "return", "torch", ".", "distributions", ".", "kl", ".", "kl_divergence", "(", "p", ",", "q", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.kl_divergence_two_gaussians_std": [[581, 591], ["p_mean.cpu.cpu", "q_mean.cpu.cpu", "p_std.cpu.cpu", "q_std.cpu.cpu", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence", "torch.distributions.kl.kl_divergence"], "function", ["None"], ["", "def", "kl_divergence_two_gaussians_std", "(", "p_mean", ",", "p_std", ",", "q_mean", ",", "q_std", ")", ":", "\n", "  ", "p_mean", "=", "p_mean", ".", "cpu", "(", ")", "\n", "q_mean", "=", "q_mean", ".", "cpu", "(", ")", "\n", "p_std", "=", "p_std", ".", "cpu", "(", ")", "\n", "q_std", "=", "q_std", ".", "cpu", "(", ")", "\n", "\n", "p", "=", "torch", ".", "distributions", ".", "normal", ".", "Normal", "(", "p_mean", ",", "p_std", ")", "\n", "q", "=", "torch", ".", "distributions", ".", "normal", ".", "Normal", "(", "q_mean", ",", "q_std", ")", "\n", "\n", "return", "torch", ".", "distributions", ".", "kl", ".", "kl_divergence", "(", "p", ",", "q", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.artist_kl_divergence": [[592, 594], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "triplet_vgg.kl_divergence_two_gaussians"], "function", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.kl_divergence_two_gaussians"], ["", "def", "artist_kl_divergence", "(", "latent_mean", ",", "latent_logvar", ",", "pretrained_mean", ",", "pretrained_logvar", ")", ":", "\n", "  ", "return", "torch", ".", "mean", "(", "torch", ".", "sum", "(", "kl_divergence_two_gaussians", "(", "latent_mean", ",", "latent_logvar", ",", "pretrained_mean", ",", "pretrained_logvar", ")", ",", "dim", "=", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.triplet_loss": [[595, 610], ["torch.MSELoss", "range", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "total_trip_loss.cpu", "nn.MSELoss.", "nn.MSELoss.", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "triplet_loss", "(", "a_mean", ",", "p_mean", ",", "n_mean", ")", ":", "\n", "    ", "mse_criterion", "=", "nn", ".", "MSELoss", "(", ")", "\n", "total_trip_loss", "=", "0", "\n", "num_positives", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "a_mean", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "distance", "=", "mse_criterion", "(", "p_mean", "[", "i", "]", ",", "a_mean", "[", "i", "]", ")", "-", "mse_criterion", "(", "n_mean", "[", "i", "]", ",", "a_mean", "[", "i", "]", ")", "\n", "trip_loss", "=", "torch", ".", "clamp", "(", "distance", "+", "TRIPLET_ALPHA", ",", "min", "=", "0", ")", "\n", "if", "trip_loss", ">", "torch", ".", "tensor", "(", "0", ")", ":", "\n", "            ", "num_positives", "+=", "1", "\n", "\n", "", "total_trip_loss", "+=", "trip_loss", "\n", "", "if", "num_positives", "==", "0", ":", "\n", "        ", "return", "total_trip_loss", ".", "cpu", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "(", "total_trip_loss", "/", "num_positives", ")", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.calculate_perceptual_loss": [[611, 619], ["[].cpu", "[].cpu", "torch.MSELoss", "nn.MSELoss.", "loss_network", "loss_network", "x.to"], "function", ["None"], ["", "", "def", "calculate_perceptual_loss", "(", "recon_x", ",", "x", ")", ":", "\n", "# vgg_model = vgg_model.cuda()", "\n", "  ", "recon_features", "=", "loss_network", "(", "recon_x", ")", "[", "2", "]", ".", "cpu", "(", ")", "\n", "orig_features", "=", "loss_network", "(", "x", ".", "to", "(", "device", ")", ")", "[", "2", "]", ".", "cpu", "(", ")", "\n", "\n", "# vgg_model = vgg_model.cpu()", "\n", "mse_criterion", "=", "nn", ".", "MSELoss", "(", ")", "\n", "return", "mse_criterion", "(", "recon_features", ",", "orig_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.calculate_artist_discriminator_loss": [[620, 676], ["zip", "enumerate", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "discriminator", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "discriminator", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "enumerate", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "triplet_vgg.discriminator_loss_no_reduction", "enumerate", "triplet_vgg.discriminator_loss_no_reduction", "discriminator.squeeze", "torch.zeros.float().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "discriminator", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "discriminator.squeeze", "torch.zeros.float().squeeze", "triplet_vgg.discriminator_loss_no_reduction", "torch.zeros.float", "discriminator.squeeze", "torch.zeros.float().squeeze", "torch.zeros.float", "torch.zeros.float"], "function", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.discriminator_loss_no_reduction", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.discriminator_loss_no_reduction", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.discriminator_loss_no_reduction"], ["", "def", "calculate_artist_discriminator_loss", "(", "image_batches", ",", "triplet_latent_vectors", ",", "corresponding_latent_vectors", ")", ":", "\n", "# Here we go through all (6 choose 2) combinations of images and get the discriminator loss for each", "\n", "\n", "  ", "num_same_artists", "=", "0.0", "\n", "num_diff_artists", "=", "12", "*", "triplet_latent_vectors", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "\n", "same_artist_disc_loss", "=", "0.0", "\n", "diff_artist_disc_loss", "=", "0.0", "\n", "\n", "# FIRST CASE (3 Comparisons): The images of the same author (we check if they are also the same image, and if so we mask out that loss)", "\n", "for", "image_batch", ",", "triplet_latent", ",", "corr_latent", "in", "zip", "(", "image_batches", ",", "triplet_latent_vectors", ",", "corresponding_latent_vectors", ")", ":", "\n", "    ", "should_mask_vector", "=", "image_batch", "[", "\"corresponding\"", "]", "[", "\"should_mask\"", "]", "==", "0", "\n", "\n", "num_same_artists", "+=", "torch", ".", "sum", "(", "should_mask_vector", ")", "\n", "\n", "latent_concat", "=", "torch", ".", "cat", "(", "(", "triplet_latent", ",", "corr_latent", ")", ",", "dim", "=", "1", ")", "\n", "prediction", "=", "discriminator", "(", "latent_concat", ")", "\n", "\n", "disc_label", "=", "torch", ".", "ones", "(", "prediction", ".", "shape", ")", "\n", "\n", "same_artist_disc_loss", "+=", "torch", ".", "sum", "(", "should_mask_vector", "*", "discriminator_loss_no_reduction", "(", "prediction", ".", "squeeze", "(", ")", ",", "disc_label", ".", "float", "(", ")", ".", "squeeze", "(", ")", ")", ")", "\n", "\n", "# SECOND CASE (6 Comparisons): Compare each image from the triplet to each image in the corresponding that are not the same image", "\n", "", "for", "triplet_idx", ",", "triplet_latent", "in", "enumerate", "(", "triplet_latent_vectors", ")", ":", "\n", "    ", "for", "corr_idx", ",", "corr_latent", "in", "enumerate", "(", "corresponding_latent_vectors", ")", ":", "\n", "      ", "if", "(", "corr_idx", "==", "triplet_idx", ")", ":", "\n", "        ", "continue", "\n", "\n", "", "", "latent_concat", "=", "torch", ".", "cat", "(", "(", "triplet_latent", ",", "corr_latent", ")", ",", "dim", "=", "1", ")", "\n", "prediction", "=", "discriminator", "(", "latent_concat", ")", "\n", "\n", "disc_label", "=", "torch", ".", "zeros", "(", "prediction", ".", "shape", ")", "\n", "diff_artist_disc_loss", "+=", "torch", ".", "sum", "(", "discriminator_loss_no_reduction", "(", "prediction", ".", "squeeze", "(", ")", ",", "disc_label", ".", "float", "(", ")", ".", "squeeze", "(", ")", ")", ")", "\n", "\n", "# THIRD CASE (6 Comparisons): Compare each image from the same triplet", "\n", "", "latent_vectors_list", "=", "[", "triplet_latent_vectors", ",", "corresponding_latent_vectors", "]", "\n", "for", "latent_vectors_triplet", "in", "latent_vectors_list", ":", "\n", "    ", "for", "trip1_idx", ",", "trip1_latent", "in", "enumerate", "(", "latent_vectors_triplet", ")", ":", "\n", "      ", "for", "trip2_idx", ",", "trip2_latent", "in", "enumerate", "(", "latent_vectors_triplet", ")", ":", "\n", "        ", "if", "(", "trip1_idx", "==", "trip2_idx", ")", ":", "\n", "          ", "continue", "\n", "", "latent_concat", "=", "torch", ".", "cat", "(", "(", "trip1_latent", ",", "trip2_latent", ")", ",", "dim", "=", "1", ")", "\n", "prediction", "=", "discriminator", "(", "latent_concat", ")", "\n", "\n", "disc_label", "=", "torch", ".", "zeros", "(", "prediction", ".", "shape", ")", "\n", "diff_artist_disc_loss", "+=", "torch", ".", "sum", "(", "discriminator_loss_no_reduction", "(", "prediction", ".", "squeeze", "(", ")", ",", "disc_label", ".", "float", "(", ")", ".", "squeeze", "(", ")", ")", ")", "\n", "\n", "\n", "\n", "", "", "", "total_artist_loss", "=", "0.0", "\n", "if", "torch", ".", "sum", "(", "num_same_artists", ")", "==", "0", ":", "\n", "    ", "total_artist_loss", "=", "diff_artist_disc_loss", "/", "num_diff_artists", "\n", "", "else", ":", "\n", "    ", "total_artist_loss", "=", "(", "same_artist_disc_loss", "/", "num_same_artists", ")", "+", "(", "diff_artist_disc_loss", "/", "num_diff_artists", ")", "\n", "\n", "", "return", "total_artist_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.test_vgg_triplet": [[682, 702], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "len", "base_optimizer.zero_grad", "triplet_vgg.triplet_loss", "triplet_vgg", "latents.append", "triplet_img.to"], "function", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.triplet_loss"], ["def", "test_vgg_triplet", "(", "model", ")", ":", "\n", "  ", "total_loss", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "    ", "for", "batch_idx", ",", "data", "in", "enumerate", "(", "test_dataset_loader", ")", ":", "\n", "      ", "latents", "=", "[", "]", "\n", "triplet_keys", "=", "[", "'anchor'", ",", "'positive'", ",", "'negative'", "]", "\n", "\n", "for", "key", "in", "triplet_keys", ":", "\n", "        ", "triplet_img", "=", "data", "[", "key", "]", "[", "'triplet'", "]", "[", "'image'", "]", "\n", "outputs", "=", "triplet_vgg", "(", "triplet_img", ".", "to", "(", "device", ")", ")", "\n", "latents", ".", "append", "(", "outputs", ")", "\n", "\n", "", "train_loss", "=", "0", "\n", "base_optimizer", ".", "zero_grad", "(", ")", "\n", "latent_loss", "=", "triplet_loss", "(", "latents", "[", "0", "]", ",", "latents", "[", "1", "]", ",", "latents", "[", "2", "]", ")", "\n", "train_loss", "+=", "latent_loss", "\n", "\n", "total_loss", "+=", "train_loss", "\n", "\n", "", "", "return", "total_loss", "/", "len", "(", "test_dataset_loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.train_vgg_triplet": [[703, 754], ["range", "len", "enumerate", "triplet_vgg.test_vgg_triplet", "triplet_writer.add_scalar", "print", "print", "time.time", "time.time", "base_optimizer.zero_grad", "triplet_vgg.triplet_loss", "train_loss.backward", "writer.add_scalar", "print", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "model", "latents.append", "model.state_dict", "vae.state_dict", "triplet_vgg.safe_exit", "print", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "triplet_vgg.safe_exit", "triplet_img.to", "model.state_dict"], "function", ["home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.test_vgg_triplet", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.triplet_loss", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.safe_exit", "home.repos.pwc.inspect_result.learning-portrait-style_learning-style.None.triplet_vgg.safe_exit"], ["", "def", "train_vgg_triplet", "(", "model", ",", "start_iters", ",", "end_iters", ",", "weights_folder", ",", "prefix", ")", ":", "\n", "  ", "num_epochs", "=", "0", "\n", "for", "iters", "in", "range", "(", "start_iters", ",", "end_iters", ",", "len", "(", "train_dataset_loader", ")", ")", ":", "\n", "    ", "for", "batch_idx", ",", "data", "in", "enumerate", "(", "train_dataset_loader", ")", ":", "\n", "      ", "total_iters", "=", "batch_idx", "+", "iters", "\n", "if", "total_iters", ">=", "end_iters", ":", "\n", "          ", "save_filename", "=", "f'{prefix}{total_iters}.pt'", "\n", "save_path", "=", "f'{weights_folder}/{save_filename}'", "\n", "torch", ".", "save", "(", "vae", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "return", "\n", "", "print", "(", "f\"Evaluating batch {total_iters} for {model_name}\"", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "time_elapsed", "=", "end", "-", "start_time", "\n", "if", "not", "IS_RUNNING_NOTEBOOK", ":", "\n", "        ", "if", "time_elapsed", ">=", "TIMEOUT", ":", "\n", "            ", "safe_exit", "(", "0", ")", "\n", "", "if", "exit_code", "is", "not", "None", ":", "\n", "            ", "print", "(", "\"caught the exception!\"", ")", "\n", "save_filename", "=", "f'{prefix}{total_iters}.pt'", "\n", "save_path", "=", "f'{weights_folder}/{save_filename}'", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "safe_exit", "(", "3", ")", "\n", "return", "\n", "\n", "", "", "latents", "=", "[", "]", "\n", "triplet_keys", "=", "[", "'anchor'", ",", "'positive'", ",", "'negative'", "]", "\n", "\n", "for", "key", "in", "triplet_keys", ":", "\n", "        ", "triplet_img", "=", "data", "[", "key", "]", "[", "'triplet'", "]", "[", "'image'", "]", "\n", "outputs", "=", "model", "(", "triplet_img", ".", "to", "(", "device", ")", ")", "\n", "latents", ".", "append", "(", "outputs", ")", "\n", "\n", "", "train_loss", "=", "0", "\n", "base_optimizer", ".", "zero_grad", "(", ")", "\n", "latent_loss", "=", "triplet_loss", "(", "latents", "[", "0", "]", ",", "latents", "[", "1", "]", ",", "latents", "[", "2", "]", ")", "\n", "train_loss", "+=", "latent_loss", "\n", "\n", "train_loss", ".", "backward", "(", ")", "\n", "writer", ".", "add_scalar", "(", "f'Loss/Train_{model_name}'", ",", "train_loss", ",", "total_iters", ")", "\n", "\n", "print", "(", "f\"Loss: {train_loss}\"", ")", "\n", "\n", "", "num_epochs", "+=", "1", "\n", "if", "num_epochs", "%", "5", "==", "0", ":", "\n", "        ", "save_filename", "=", "f'{prefix}{total_iters}.pt'", "\n", "save_path", "=", "f'{weights_folder}/{save_filename}'", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "\n", "", "test_loss", "=", "test_vgg_triplet", "(", "model", ")", "\n", "triplet_writer", ".", "add_scalar", "(", "f'Loss/Test_{model_name}'", ",", "test_loss", ",", "total_iters", ")", "\n", "print", "(", "f\"TEST LOSS: {test_loss} FOR EPOCH: {total_iters}\"", ")", "\n", "\n"]]}