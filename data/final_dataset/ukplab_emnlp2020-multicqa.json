{"home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert-ranker.run_experiment.run_cmd": [[13, 101], ["click.command", "click.argument", "experiment.config.load_config", "run_experiment.run_cmd.run"], "function", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.config.load_config"], ["@", "click", ".", "command", "(", ")", "\n", "@", "click", ".", "argument", "(", "'config_file'", ")", "\n", "def", "run_cmd", "(", "config_file", ")", ":", "\n", "    ", "config", "=", "load_config", "(", "config_file", ")", "\n", "\n", "def", "run", "(", ")", ":", "\n", "        ", "\"\"\"This program is the starting point for every experiment. It pulls together the configuration and all\n        necessary experiment classes to load\n\n        \"\"\"", "\n", "run_name", "=", "config", ".", "get", "(", "'run_name'", ",", "'undefined name'", ")", "\n", "config_global", "=", "config", "[", "'global'", "]", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "config_global", "[", "'output_path'", "]", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "config_global", "[", "'output_path'", "]", ")", "\n", "\n", "", "write_config", "(", "config", ",", "config_global", "[", "'output_path'", "]", ")", "\n", "\n", "# setup a logger", "\n", "logger", "=", "setup_logger", "(", "config", "[", "'logger'", "]", ",", "config_global", "[", "'output_path'", "]", ",", "name", "=", "'experiment'", ")", "\n", "\n", "# we allow to set the random seed in the config file for reproducibility. However, when running on GPU, results", "\n", "# can still be nondeterministic", "\n", "if", "'random_seed'", "in", "config_global", ":", "\n", "            ", "seed", "=", "config_global", "[", "'random_seed'", "]", "\n", "logger", ".", "info", "(", "'Using fixed random seed'", ".", "format", "(", "seed", ")", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "tf", ".", "set_random_seed", "(", "seed", ")", "\n", "\n", "# We are now fetching all relevant modules. It is strictly required that these module contain a variable named", "\n", "# 'component' that points to a class which inherits from experiment.Data, experiment.Experiment,", "\n", "# experiment.Trainer or experiment.Evaluator", "\n", "", "multi_data_module", "=", "MultiData", "(", "config", "[", "'data'", "]", ",", "config", ",", "logger", ")", "\n", "for", "dataset_config", "in", "config", "[", "'data'", "]", ":", "\n", "            ", "data_module", "=", "dataset_config", "[", "'data-module'", "]", "\n", "splits", "=", "dataset_config", ".", "get", "(", "'splits'", ",", "[", "'train'", ",", "'dev'", ",", "'test'", "]", ")", "\n", "DataClass", "=", "importlib", ".", "import_module", "(", "data_module", ")", ".", "component", "\n", "data", "=", "DataClass", "(", "dataset_config", ",", "config_global", ",", "logger", ")", "\n", "multi_data_module", ".", "add", "(", "data", ",", "splits", ")", "\n", "\n", "", "model_module", "=", "config", "[", "'model-module'", "]", "\n", "training_module", "=", "config", "[", "'training-module'", "]", "\n", "evaluation_module", "=", "config", ".", "get", "(", "'evaluation-module'", ",", "None", ")", "\n", "\n", "# The modules are now dynamically loaded", "\n", "ModelClass", "=", "importlib", ".", "import_module", "(", "model_module", ")", ".", "component", "\n", "TrainingClass", "=", "importlib", ".", "import_module", "(", "training_module", ")", ".", "component", "\n", "EvaluationClass", "=", "importlib", ".", "import_module", "(", "evaluation_module", ")", ".", "component", "\n", "\n", "if", "\"adapter_mean_estimation-module\"", "in", "config", ":", "\n", "            ", "ame_module", "=", "config", "[", "\"adapter_mean_estimation-module\"", "]", "\n", "AMEClass", "=", "importlib", ".", "import_module", "(", "ame_module", ")", ".", "component", "\n", "ame", "=", "AMEClass", "(", "config", "[", "'adapter_mean_estimation'", "]", ",", "config_global", ",", "logger", ")", "\n", "\n", "# We then wire together all the modules and start training", "\n", "", "model", "=", "ModelClass", "(", "config", "[", "'model'", "]", ",", "config_global", ",", "logger", ")", "\n", "training", "=", "TrainingClass", "(", "config", "[", "'training'", "]", ",", "config_global", ",", "logger", ")", "\n", "evaluation", "=", "EvaluationClass", "(", "config", "[", "'evaluation'", "]", ",", "config_global", ",", "logger", ")", "\n", "\n", "# setup the data (validate, create generators, load data, or else)", "\n", "logger", ".", "info", "(", "'Setting up the data'", ")", "\n", "multi_data_module", ".", "setup", "(", ")", "\n", "# build the model (e.g. compile it)", "\n", "logger", ".", "info", "(", "'Building the model'", ")", "\n", "model", ".", "build", "(", "multi_data_module", ")", "\n", "\n", "# start the training process", "\n", "if", "not", "config", "[", "\"training\"", "]", ".", "get", "(", "\"skip\"", ",", "False", ")", ":", "\n", "            ", "logger", ".", "info", "(", "'Starting the training process'", ")", "\n", "training", ".", "start", "(", "model", ",", "multi_data_module", ",", "evaluation", ")", "\n", "", "dev_score", "=", "training", ".", "restore_best_epoch", "(", "model", ",", "multi_data_module", ",", "evaluation", ")", "\n", "\n", "# perform evaluation, if required", "\n", "if", "not", "config", "[", "'evaluation'", "]", ".", "get", "(", "'skip'", ",", "False", ")", ":", "\n", "            ", "logger", ".", "info", "(", "'Evaluating'", ")", "\n", "results", "=", "evaluation", ".", "start", "(", "model", ",", "multi_data_module", ",", "valid_only", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "'Skipping evaluation'", ")", "\n", "results", "=", "{", "'dev'", ":", "dev_score", "}", "\n", "\n", "", "logger", ".", "info", "(", "'DONE'", ")", "\n", "\n", "return", "{", "\n", "'run_name'", ":", "run_name", ",", "\n", "'results'", ":", "results", "\n", "}", "\n", "\n", "", "run", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert-ranker.run_eval.run_cmd": [[15, 98], ["click.command", "click.argument", "click.option", "experiment.config.load_config", "experiment.config.load_config", "run_eval.run_cmd.run"], "function", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.config.load_config", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.config.load_config"], ["@", "click", ".", "command", "(", ")", "\n", "@", "click", ".", "argument", "(", "'config_file'", ")", "\n", "@", "click", ".", "option", "(", "'--do-test/--no-do-test'", ",", "default", "=", "False", ")", "\n", "def", "run_cmd", "(", "config_file", ",", "do_test", ")", ":", "\n", "    ", "config_eval", "=", "load_config", "(", "config_file", ")", "\n", "config_experiment", "=", "load_config", "(", "config_eval", "[", "'global'", "]", "[", "'experiment_config'", "]", ")", "\n", "\n", "def", "run", "(", ")", ":", "\n", "        ", "\"\"\"This program is the starting point for evaluations without training\"\"\"", "\n", "run_name", "=", "config_eval", ".", "get", "(", "'run_name'", ",", "'undefined name'", ")", "\n", "config_eval_global", "=", "config_eval", "[", "'global'", "]", "\n", "config_experiment_global", "=", "config_experiment", "[", "'global'", "]", "\n", "\n", "output_dir", "=", "config_eval_global", "[", "'evaluation_output'", "]", "\n", "restore_weights", "=", "config_eval_global", ".", "get", "(", "'restore_epoch'", ",", "'best'", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "path", ".", "join", "(", "output_dir", ",", "'log.txt'", ")", ")", ":", "\n", "            ", "with", "open", "(", "path", ".", "join", "(", "output_dir", ",", "'log.txt'", ")", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "if", "'Results for all datasets in dev'", "in", "f", ".", "read", "(", ")", ":", "\n", "                    ", "return", "'exp. already finished'", "\n", "\n", "", "", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "output_dir", ")", "\n", "", "write_config", "(", "config_eval", ",", "output_dir", ")", "\n", "\n", "# setup a logger", "\n", "logger", "=", "setup_logger", "(", "config_eval", "[", "'logger'", "]", ",", "output_dir", ",", "name", "=", "'experiment'", ")", "\n", "\n", "# we allow to set the random seed in the config file for reproducibility. However, when running on GPU, results", "\n", "# can still be nondeterministic", "\n", "if", "'random_seed'", "in", "config_experiment_global", ":", "\n", "            ", "seed", "=", "config_experiment_global", "[", "'random_seed'", "]", "\n", "logger", ".", "info", "(", "'Using fixed random seed'", ".", "format", "(", "seed", ")", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "tf", ".", "set_random_seed", "(", "seed", ")", "\n", "\n", "", "multi_data_module_eval", "=", "MultiData", "(", "config_eval", "[", "'data'", "]", ",", "config_eval_global", ",", "logger", ")", "\n", "for", "dataset_config", "in", "config_eval", "[", "'data'", "]", ":", "\n", "            ", "data_module", "=", "dataset_config", "[", "'data-module'", "]", "\n", "splits", "=", "dataset_config", ".", "get", "(", "'splits'", ",", "[", "'train'", ",", "'dev'", ",", "'test'", "]", ")", "\n", "DataClass", "=", "importlib", ".", "import_module", "(", "data_module", ")", ".", "component", "\n", "data", "=", "DataClass", "(", "dataset_config", ",", "config_eval_global", ",", "logger", ")", "\n", "multi_data_module_eval", ".", "add", "(", "data", ",", "splits", ")", "\n", "\n", "", "model_module", "=", "config_experiment", "[", "'model-module'", "]", "\n", "evaluation_module", "=", "config_eval", "[", "'evaluation-module'", "]", "\n", "\n", "# The modules are now dynamically loaded", "\n", "ModelClass", "=", "importlib", ".", "import_module", "(", "model_module", ")", ".", "component", "\n", "EvaluationClass", "=", "importlib", ".", "import_module", "(", "evaluation_module", ")", ".", "component", "\n", "\n", "# We then wire together all the modules and start training", "\n", "model", "=", "ModelClass", "(", "config_experiment", "[", "'model'", "]", ",", "config_experiment_global", ",", "logger", ")", "\n", "evaluation", "=", "EvaluationClass", "(", "config_eval", "[", "'evaluation'", "]", ",", "config_eval_global", ",", "logger", ")", "\n", "\n", "# setup the data (validate, create generators, load data, or else)", "\n", "logger", ".", "info", "(", "'Setting up the data'", ")", "\n", "multi_data_module_eval", ".", "setup", "(", ")", "\n", "# build the model (e.g. compile it)", "\n", "logger", ".", "info", "(", "'Building the model'", ")", "\n", "\n", "model", ".", "set_bert_configs_from_output_folder", "(", "restore_weights", ")", "# sets necessary huggingface bert restore paths", "\n", "model", ".", "build", "(", "multi_data_module_eval", ")", "\n", "if", "hasattr", "(", "model", ".", "bert", ".", "config", ",", "'adapter_attention'", ")", ":", "\n", "            ", "model", ".", "bert", ".", "bert", ".", "enable_adapters", "(", "unfreeze_adapters", "=", "True", ",", "unfreeze_attention", "=", "True", ")", "\n", "", "elif", "hasattr", "(", "model", ".", "bert", ".", "config", ",", "'adapters'", ")", ":", "\n", "            ", "model", ".", "bert", ".", "bert", ".", "enable_adapters", "(", "unfreeze_adapters", "=", "True", ",", "unfreeze_attention", "=", "False", ")", "\n", "\n", "", "state", "=", "QATrainStatePyTorch", "(", "path", ".", "join", "(", "config_experiment_global", "[", "'output_path'", "]", ",", "'checkpoints'", ")", ",", "\n", "less_is_better", "=", "False", ",", "logger", "=", "logger", ")", "\n", "state", ".", "load", "(", "model", ".", "bert", ",", "optimizer", "=", "None", ",", "weights", "=", "restore_weights", ",", "strict", "=", "False", ")", "\n", "\n", "logger", ".", "info", "(", "'Evaluating'", ")", "\n", "results", "=", "evaluation", ".", "start", "(", "model", ",", "multi_data_module_eval", ",", "valid_only", "=", "not", "do_test", ")", "\n", "\n", "logger", ".", "info", "(", "'DONE'", ")", "\n", "\n", "return", "{", "\n", "'run_name'", ":", "run_name", ",", "\n", "'results'", ":", "results", "\n", "}", "\n", "\n", "", "run", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.test.test_config.TestConfig.test_read_config_simple": [[7, 19], ["experiment.config.read_config", "test_config.TestConfig.assertDictEqual"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.config.read_config"], ["    ", "def", "test_read_config_simple", "(", "self", ")", ":", "\n", "        ", "config_str", "=", "\"\"\"\n            Projects:\n              C/C++ Libraries:\n              - libyaml       # \"C\" Fast YAML 1.1\n              - Syck          # (dated) \"C\" YAML 1.0\n              - yaml-cpp      # C++ YAML 1.2 implementation\n        \"\"\"", "\n", "config", "=", "read_config", "(", "config_str", ")", "\n", "self", ".", "assertDictEqual", "(", "config", ",", "{", "\n", "'Projects'", ":", "{", "\n", "'C/C++ Libraries'", ":", "[", "'libyaml'", ",", "'Syck'", ",", "'yaml-cpp'", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.test.test_config.TestConfig.test_read_config_merge": [[22, 44], ["experiment.config.read_config", "test_config.TestConfig.assertDictEqual"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.config.read_config"], ["", "def", "test_read_config_merge", "(", "self", ")", ":", "\n", "        ", "config_default_str", "=", "\"\"\"\n            Projects:\n              C/C++ Libraries:\n              - libyaml       # \"C\" Fast YAML 1.1\n              - Syck          # (dated) \"C\" YAML 1.0\n              - yaml-cpp      # C++ YAML 1.2 implementation\n              Other Libraries:\n              - pyyaml\n        \"\"\"", "\n", "config_str", "=", "\"\"\"\n            Projects:\n              C/C++ Libraries:\n            Something: Test\n        \"\"\"", "\n", "config", "=", "read_config", "(", "config_str", ",", "config_default_str", ")", "\n", "self", ".", "assertDictEqual", "(", "config", ",", "{", "\n", "'Projects'", ":", "{", "\n", "'C/C++ Libraries'", ":", "None", ",", "\n", "'Other Libraries'", ":", "[", "'pyyaml'", "]", "\n", "}", ",", "\n", "'Something'", ":", "'Test'", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.config.load_config": [[8, 22], ["os.path.join", "os.path.dirname", "open", "open", "config.read_config", "user_config_file.read", "default_config_file.read"], "function", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.config.read_config", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read"], ["def", "load_config", "(", "config_path", ",", "default_config_path", "=", "None", ")", ":", "\n", "    ", "\"\"\"Loads and reads a yaml configuration file which extends the default_config of this project\n\n    :param config_path: path of the configuration file to load\n    :type config_path: str\n    :param default_config_path: the path of the default configuration file. If not set, the function will use the\n                                default_config.yaml file in the root directory.\n    :type default_config_path: str\n    :return: the configuration dictionary\n    :rtype: dict\n    \"\"\"", "\n", "default_config_path", "=", "path", ".", "join", "(", "path", ".", "dirname", "(", "__file__", ")", ",", "'..'", ",", "'default_config.yaml'", ")", "\n", "with", "open", "(", "config_path", ",", "'r'", ")", "as", "user_config_file", ",", "open", "(", "default_config_path", ",", "'r'", ")", "as", "default_config_file", ":", "\n", "        ", "return", "read_config", "(", "user_config_file", ".", "read", "(", ")", ",", "default_config_file", ".", "read", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.config.read_config": [[24, 37], ["yaml.load", "experiment.util.merge_dicts", "yaml.load", "dict"], "function", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.load", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.util.merge_dicts", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.load"], ["", "", "def", "read_config", "(", "config_str", ",", "default_config_str", "=", "None", ")", ":", "\n", "    ", "\"\"\"Reads a yaml configuration string which extends the default_config string, if there is one\n\n    :param config_str: the configuration to read\n    :type config_str: str\n    :param default_config_str: the default configuration. If set to None, the default configuration will be empty\n    :type default_config_path: str\n    :return: the configuration dictionary\n    :rtype: dict\n    \"\"\"", "\n", "user_config", "=", "yaml", ".", "load", "(", "config_str", ")", "\n", "default_config_str", "=", "yaml", ".", "load", "(", "default_config_str", ")", "if", "default_config_str", "else", "dict", "(", ")", "\n", "return", "merge_dicts", "(", "default_config_str", ",", "user_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.config.write_config": [[39, 50], ["os.path.isdir", "os.path.join", "open", "yaml.dump"], "function", ["None"], ["", "def", "write_config", "(", "config_dict", ",", "output_path", ")", ":", "\n", "    ", "\"\"\"Writes a configuration dict and saves it to a file\n\n    :param config_dict: the configuration data\n    :param output_path: either the file path or a folder path where the config should be stored\n    :return:\n    \"\"\"", "\n", "if", "path", ".", "isdir", "(", "output_path", ")", ":", "\n", "        ", "output_path", "=", "path", ".", "join", "(", "output_path", ",", "'run_config.yaml'", ")", "\n", "", "with", "open", "(", "output_path", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "yaml", ".", "dump", "(", "config_dict", ",", "f", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.__init__": [[8, 15], ["checkpointing.QATrainStatePyTorch.initialize"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.initialize"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "less_is_better", ",", "logger", ")", ":", "\n", "        ", "\"\"\"See experiment.qa_pointwise.train.QATrainState\"\"\"", "\n", "self", ".", "path", "=", "path", "\n", "self", ".", "logger", "=", "logger", "\n", "self", ".", "less_is_better", "=", "less_is_better", "\n", "\n", "self", ".", "initialize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.initialize": [[16, 23], ["os.mkdir", "os.path.exists"], "methods", ["None"], ["", "def", "initialize", "(", "self", ")", ":", "\n", "        ", "self", ".", "scores", "=", "[", "]", "\n", "self", ".", "best_score", "=", "-", "1", "if", "not", "self", ".", "less_is_better", "else", "2", "\n", "self", ".", "best_epoch", "=", "0", "\n", "self", ".", "recorded_epochs", "=", "0", "\n", "if", "self", ".", "path", "and", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "path", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "self", ".", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.load": [[24, 54], ["os.path.exists", "isinstance", "os.path.exists", "op", "len", "checkpointing.QATrainStatePyTorch.checkpoint_file", "checkpointing.QATrainStatePyTorch.checkpoint_file", "checkpointing.QATrainStatePyTorch.logger.info", "torch.load", "model.load_state_dict", "checkpointing.QATrainStatePyTorch.logger.info", "open", "scores.index", "optimizer.load_state_dict", "scores.append", "torch.load.get", "float"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.checkpoint_file", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.checkpoint_file", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.load"], ["", "", "def", "load", "(", "self", ",", "model", ",", "optimizer", ",", "weights", "=", "'last'", ",", "strict", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        :param weights: 'last' or 'best'\n        :return:\n        \"\"\"", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "scores_file", ")", ":", "\n", "            ", "scores", "=", "[", "]", "\n", "with", "open", "(", "self", ".", "scores_file", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "for", "line", "in", "f", ":", "\n", "                    ", "scores", ".", "append", "(", "float", "(", "line", ")", ")", "\n", "\n", "", "", "self", ".", "scores", "=", "scores", "\n", "op", "=", "max", "if", "not", "self", ".", "less_is_better", "else", "min", "\n", "self", ".", "best_score", "=", "op", "(", "scores", ")", "\n", "self", ".", "best_epoch", "=", "scores", ".", "index", "(", "self", ".", "best_score", ")", "+", "1", "\n", "self", ".", "recorded_epochs", "=", "len", "(", "scores", ")", "\n", "\n", "", "if", "isinstance", "(", "weights", ",", "str", ")", ":", "\n", "            ", "restore_path", "=", "self", ".", "checkpoint_file", "(", "self", ".", "recorded_epochs", "if", "weights", "==", "'last'", "else", "self", ".", "best_epoch", ")", "\n", "", "else", ":", "\n", "            ", "restore_path", "=", "self", ".", "checkpoint_file", "(", "weights", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "restore_path", ")", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "'Restoring model weights from: {}'", ".", "format", "(", "restore_path", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "restore_path", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ",", "strict", "=", "strict", ")", "\n", "if", "optimizer", "is", "not", "None", "and", "checkpoint", ".", "get", "(", "'optimizer'", ")", "is", "not", "None", ":", "\n", "                ", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "'Could not restore weights. Path does not exist: {}'", ".", "format", "(", "restore_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.record": [[55, 91], ["checkpointing.QATrainStatePyTorch.scores.append", "checkpointing.QATrainStatePyTorch.logger.info", "torch.save", "model.config.to_json_file", "range", "open", "f.write", "checkpointing.QATrainStatePyTorch.checkpoint_file", "os.path.join", "checkpointing.QATrainStatePyTorch.logger.info", "checkpointing.QATrainStatePyTorch.checkpoint_file", "model.state_dict", "os.path.exists", "os.remove", "optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PretrainedConfig.to_json_file", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.checkpoint_file", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.checkpoint_file"], ["", "", "def", "record", "(", "self", ",", "model", ",", "optimizer", ",", "score", ",", "backup_checkpoint_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"Records a checkpoint\n\n        :param model:\n        :param optimizer:\n        :param score:\n        :param backup_checkpoint_every: optionally we can set a value to keep the checkpoint of every n-th epoch. This\n                is used for measuring performance with varying training times later\n        :return:\n        \"\"\"", "\n", "self", ".", "recorded_epochs", "+=", "1", "\n", "self", ".", "scores", ".", "append", "(", "score", ")", "\n", "with", "open", "(", "self", ".", "scores_file", ",", "'a'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "'{}\\n'", ".", "format", "(", "score", ")", ")", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "'Checkpointing epoch {}'", ".", "format", "(", "self", ".", "recorded_epochs", ")", ")", "\n", "\n", "torch", ".", "save", "(", "{", "\n", "'model'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", "if", "optimizer", "else", "None", "\n", "}", ",", "self", ".", "checkpoint_file", "(", "self", ".", "recorded_epochs", ")", ")", "\n", "model", ".", "config", ".", "to_json_file", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path", ",", "\"huggingface-config.json\"", ")", ")", "\n", "\n", "if", "(", "not", "self", ".", "less_is_better", "and", "score", ">", "self", ".", "best_score", ")", "or", "(", "self", ".", "less_is_better", "and", "score", "<", "self", ".", "best_score", ")", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "'New best score {} (previous: {})'", ".", "format", "(", "score", ",", "self", ".", "best_score", ")", ")", "\n", "self", ".", "best_score", "=", "score", "\n", "self", ".", "best_epoch", "=", "self", ".", "recorded_epochs", "\n", "\n", "# remove old checkpoints", "\n", "", "for", "i", "in", "range", "(", "1", ",", "self", ".", "recorded_epochs", ")", ":", "\n", "            ", "if", "backup_checkpoint_every", ">", "0", "and", "i", "%", "backup_checkpoint_every", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "", "save_path", "=", "self", ".", "checkpoint_file", "(", "i", ")", "\n", "if", "i", "!=", "self", ".", "best_epoch", "and", "os", ".", "path", ".", "exists", "(", "save_path", ")", ":", "\n", "                ", "os", ".", "remove", "(", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.clear": [[92, 95], ["shutil.rmtree", "checkpointing.QATrainStatePyTorch.initialize"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.initialize"], ["", "", "", "def", "clear", "(", "self", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "self", ".", "path", ")", "\n", "self", ".", "initialize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.scores_file": [[96, 99], ["os.path.join"], "methods", ["None"], ["", "@", "property", "\n", "def", "scores_file", "(", "self", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "path", ",", "'scores.txt'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.checkpoint_file": [[100, 102], ["os.path.join"], "methods", ["None"], ["", "def", "checkpoint_file", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "path", ",", "'model-checkpoint-{}.tar'", ".", "format", "(", "epoch", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.run_util.setup_logger": [[6, 22], ["logging.getLogger", "logging.Formatter", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "os.path.join", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler", "logging.getLogger.setLevel"], "function", ["None"], ["def", "setup_logger", "(", "config_logger", ",", "out_folder", ",", "name", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "name", ")", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "'%(asctime)s - %(name)s - %(levelname)s - %(message)s'", ")", "\n", "handler_stdout", "=", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "\n", "handler_stdout", ".", "setLevel", "(", "config_logger", "[", "'level'", "]", ")", "\n", "handler_stdout", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", ".", "addHandler", "(", "handler_stdout", ")", "\n", "\n", "log_file_path", "=", "path", ".", "join", "(", "out_folder", ",", "'log.txt'", ")", "\n", "handler_file", "=", "logging", ".", "FileHandler", "(", "log_file_path", ")", "\n", "handler_file", ".", "setLevel", "(", "config_logger", "[", "'level'", "]", ")", "\n", "handler_file", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", ".", "addHandler", "(", "handler_file", ")", "\n", "\n", "logger", ".", "setLevel", "(", "config_logger", "[", "'level'", "]", ")", "\n", "return", "logger", "\n", "", ""]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.InputExample.__init__": [[21, 37], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "        ", "\"\"\"Constructs a InputExample.\n\n        Args:\n            guid: Unique id for the example.\n            text_a: string. The untokenized text of the first sequence. For single\n            sequence tasks, only this sequence must be specified.\n            text_b: (Optional) string. The untokenized text of the second sequence.\n            Only must be specified for sequence pair tasks.\n            label: (Optional) string. The label of the example. This should be\n            specified for train and dev examples, but not for test examples.\n        \"\"\"", "\n", "self", ".", "guid", "=", "guid", "\n", "self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.InputFeatures.__init__": [[42, 47], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_id", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "label_id", "=", "label_id", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.BertWrapperModel.__init__": [[158, 179], ["experiment.Model.__init__", "bert_utils.BertWrapperModel.config.get", "bert_utils.BertWrapperModel.config.get", "bert_utils.BertWrapperModel.config.get"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "config_global", ",", "logger", ")", ":", "\n", "        ", "\"\"\"This is general BERT wrapper model. It can be used for BERT CLS classification, and BERT repr. learning\n\n        You must set _MODEL_CLASS, _TOKENIZER_CLASS and _CONFIG_CLASS to a superclass of one of Huggingface's model and tokenizer classes.\n        :param config: The model configuration\n        :param config_global: The global experiment configuation\n        :param logger: The logger of the current experiment\n        \"\"\"", "\n", "super", "(", "BertWrapperModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "config_global", ",", "logger", ")", "\n", "self", ".", "question_length", "=", "self", ".", "config_global", "[", "'question_length'", "]", "\n", "self", ".", "answer_length", "=", "self", ".", "config_global", "[", "'answer_length'", "]", "\n", "self", ".", "bert_model_name", "=", "self", ".", "config", "[", "'bert_model'", "]", "\n", "self", ".", "lowercased", "=", "True", "if", "'uncased'", "in", "self", ".", "bert_model_name", "else", "False", "\n", "\n", "self", ".", "bert", "=", "None", "\n", "self", ".", "tokenizer", "=", "None", "\n", "self", ".", "device", "=", "None", "\n", "\n", "self", ".", "create_adapters", "=", "self", ".", "config", ".", "get", "(", "'create_adapters'", ",", "[", "]", ")", "\n", "self", ".", "adapter_downsample", "=", "self", ".", "config", ".", "get", "(", "'adapter_downsample'", ",", "None", ")", "\n", "self", ".", "adapter_attention_type", "=", "self", ".", "config", ".", "get", "(", "\"adapter_attention_type\"", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.BertWrapperModel.set_bert_configs_from_output_folder": [[180, 192], ["os.path.join", "os.path.join", "sorted", "os.path.join", "glob.glob.glob", "int", "re.findall"], "methods", ["None"], ["", "def", "set_bert_configs_from_output_folder", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "checkpoints_path", "=", "path", ".", "join", "(", "self", ".", "config_global", "[", "'output_path'", "]", ",", "'checkpoints'", ")", "\n", "self", ".", "config", "[", "\"huggingface_config\"", "]", "=", "path", ".", "join", "(", "checkpoints_path", ",", "\"/huggingface-config.json\"", ")", "\n", "\n", "if", "epoch", "==", "'best'", ":", "\n", "            ", "checkpoints", "=", "sorted", "(", "glob", "(", "checkpoints_path", "+", "'/*.tar'", ")", ",", "key", "=", "lambda", "x", ":", "int", "(", "re", ".", "findall", "(", "r'(\\d+).tar'", ",", "x", ")", "[", "0", "]", ")", ")", "\n", "path_best_checkpoint", "=", "checkpoints", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "path_best_checkpoint", "=", "path", ".", "join", "(", "checkpoints_path", ",", "'model-checkpoint-{}.tar'", ".", "format", "(", "epoch", ")", ")", "\n", "\n", "", "self", ".", "config", "[", "\"base_checkpoint\"", "]", "=", "path_best_checkpoint", "\n", "self", ".", "config", "[", "\"base_head_checkpoint\"", "]", "=", "path_best_checkpoint", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.BertWrapperModel.build": [[193, 258], ["bert_utils.BertWrapperModel._TOKENIZER_CLASS.from_pretrained", "torch.device", "bert_utils.BertWrapperModel.bert.to", "os.path.exists", "bert_utils.BertWrapperModel.logger.info", "bert_utils.BertWrapperModel._CONFIG_CLASS.from_json_file", "bert_utils.BertWrapperModel._MODEL_CLASS", "bert_utils.BertWrapperModel._MODEL_CLASS", "os.path.exists", "bert_utils.BertWrapperModel.logger.info", "bert_utils.BertWrapperModel.bert.state_dict", "os.path.exists", "bert_utils.BertWrapperModel.logger.info", "bert_utils.BertWrapperModel.logger.info", "bert_utils.BertWrapperModel.bert.load_state_dict", "torch.load", "checkpoint.pop", "bert_utils.BertWrapperModel.bert.load_state_dict", "bert_utils.BertWrapperModel.logger.warn", "torch.load", "bert_utils.BertWrapperModel.logger.info", "bert_utils.BertWrapperModel.bert.bert.add_adapter", "any", "bert_utils.BertWrapperModel.logger.info", "bert_utils.BertWrapperModel.bert.bert.add_attention_layer", "bert_utils.BertWrapperModel.config.get", "torch.cuda.is_available", "bert_utils.BertWrapperModel.config.get", "delete_keys.append", "missing_keys.append", "head_state_dict.keys", "hasattr", "hasattr", "len", "set", "set"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.load", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.load", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.add_adapter", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.add_attention_layer"], ["", "def", "build", "(", "self", ",", "data", ")", ":", "\n", "        ", "if", "\"huggingface_config\"", "in", "self", ".", "config", "and", "os", ".", "path", ".", "exists", "(", "self", ".", "config", "[", "\"huggingface_config\"", "]", ")", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\n", "\"Creating model with config {}. Weights will not be initialised to a pretrained model. Use a checkpoint or 'model.base_checkpoint'\"", ".", "format", "(", "\n", "self", ".", "config", "[", "\"huggingface_config\"", "]", ")", ")", "\n", "config", "=", "self", ".", "_CONFIG_CLASS", ".", "from_json_file", "(", "self", ".", "config", "[", "\"huggingface_config\"", "]", ")", "\n", "self", ".", "bert", "=", "self", ".", "_MODEL_CLASS", "(", "from_pretrained", "=", "False", ",", "config", "=", "config", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bert", "=", "self", ".", "_MODEL_CLASS", "(", "from_pretrained", "=", "True", ",", "model_name", "=", "self", ".", "bert_model_name", ",", "\n", "cache_dir", "=", "self", ".", "config", ".", "get", "(", "'bert_cache_dir'", ",", "None", ")", ")", "\n", "\n", "", "if", "\"base_checkpoint\"", "in", "self", ".", "config", "and", "os", ".", "path", ".", "exists", "(", "self", ".", "config", "[", "\"base_checkpoint\"", "]", ")", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Loading base checkpoint from {}\"", ".", "format", "(", "self", ".", "config", "[", "\"base_checkpoint\"", "]", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "self", ".", "config", "[", "\"base_checkpoint\"", "]", ")", "[", "\"model\"", "]", "\n", "bert_state_dict", "=", "self", ".", "bert", ".", "state_dict", "(", ")", "\n", "# old checkpoint might be of model that inherits from BertModel, thus it has to many parameters which we remove", "\n", "delete_keys", "=", "[", "]", "\n", "for", "key", "in", "checkpoint", ":", "\n", "                ", "if", "key", "not", "in", "bert_state_dict", ":", "\n", "                    ", "delete_keys", ".", "append", "(", "key", ")", "\n", "", "", "for", "key", "in", "delete_keys", ":", "\n", "                ", "checkpoint", ".", "pop", "(", "key", ")", "\n", "", "can_load_checkpoint", "=", "True", "\n", "missing_keys", "=", "[", "]", "\n", "for", "key", "in", "bert_state_dict", ":", "\n", "                ", "if", "key", "not", "in", "checkpoint", ":", "\n", "# not needed with load_state_dict(*, strict=True)", "\n", "# can_load_checkpoint = False", "\n", "                    ", "missing_keys", ".", "append", "(", "key", ")", "\n", "", "", "if", "can_load_checkpoint", ":", "\n", "                ", "self", ".", "bert", ".", "load_state_dict", "(", "checkpoint", ",", "strict", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "logger", ".", "warn", "(", "\"Can not load the base checkpoint. Missing keys: {}\"", ".", "format", "(", "missing_keys", ")", ")", "\n", "\n", "", "", "if", "\"base_head_checkpoint\"", "in", "self", ".", "config", "and", "os", ".", "path", ".", "exists", "(", "self", ".", "config", "[", "\"base_head_checkpoint\"", "]", ")", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Loading base head checkpoint from {}\"", ".", "format", "(", "self", ".", "config", "[", "\"base_head_checkpoint\"", "]", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "self", ".", "config", "[", "\"base_head_checkpoint\"", "]", ")", "[", "\"model\"", "]", "\n", "head_state_dict", "=", "{", "}", "\n", "for", "key", "in", "checkpoint", ":", "\n", "                ", "if", "\"bert\"", "not", "in", "key", ":", "\n", "                    ", "head_state_dict", "[", "key", "]", "=", "checkpoint", "[", "key", "]", "\n", "", "", "self", ".", "logger", ".", "info", "(", "\"Loaded head parameters: {}\"", ".", "format", "(", "head_state_dict", ".", "keys", "(", ")", ")", ")", "\n", "self", ".", "bert", ".", "load_state_dict", "(", "head_state_dict", ",", "strict", "=", "False", ")", "\n", "\n", "# if self.adapter_attention_type is None:", "\n", "", "for", "adapter_name", "in", "self", ".", "create_adapters", ":", "\n", "            ", "if", "not", "hasattr", "(", "self", ".", "bert", ".", "bert", ".", "config", ",", "'adapters'", ")", "or", "adapter_name", "not", "in", "self", ".", "bert", ".", "bert", ".", "config", ".", "adapters", ":", "\n", "                ", "self", ".", "logger", ".", "info", "(", "'Adding adapter \"{}\" with downsampling factor {} to BERT'", ".", "format", "(", "\n", "adapter_name", ",", "self", ".", "adapter_downsample", "\n", ")", ")", "\n", "self", ".", "bert", ".", "bert", ".", "add_adapter", "(", "adapter_name", ",", "self", ".", "adapter_downsample", ")", "\n", "\n", "", "", "if", "self", ".", "adapter_attention_type", "is", "not", "None", ":", "\n", "            ", "if", "not", "hasattr", "(", "self", ".", "bert", ".", "bert", ".", "config", ",", "'adapter_attention'", ")", "or", "any", "(", "[", "len", "(", "set", "(", "self", ".", "create_adapters", ")", "-", "set", "(", "adapters", ")", ")", "==", "0", "\n", "for", "adapters", "in", "self", ".", "bert", ".", "bert", ".", "config", ".", "adapter_attention", "]", ")", ":", "\n", "                ", "self", ".", "logger", ".", "info", "(", "'Adding adapter attention for adapters \"{}\" with type {} to BERT'", ".", "format", "(", "\n", "self", ".", "create_adapters", ",", "self", ".", "adapter_attention_type", ")", ")", "\n", "self", ".", "bert", ".", "bert", ".", "add_attention_layer", "(", "self", ".", "create_adapters", ",", "self", ".", "adapter_attention_type", ")", "\n", "\n", "", "", "self", ".", "tokenizer", "=", "self", ".", "_TOKENIZER_CLASS", ".", "from_pretrained", "(", "self", ".", "bert_model_name", ",", "\n", "cache_dir", "=", "self", ".", "config", ".", "get", "(", "'bert_cache_dir'", ",", "None", ")", ",", "\n", "do_lower_case", "=", "self", ".", "lowercased", ")", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "self", ".", "bert", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.BertTraining.__init__": [[261, 309], ["experiment.Training.__init__", "config.get", "config.get", "experiment.checkpointing.QATrainStatePyTorch", "tensorboardX.SummaryWriter", "bert_utils.BertTraining.config.get", "bert_utils.BertTraining.logger.debug", "bert_utils.BertTraining.config.get", "bert_utils.BertTraining.logger.debug", "bert_utils.BertTraining.config.get", "bert_utils.BertTraining.config.get", "bert_utils.BertTraining.config.get", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "dict", "os.path.isdir", "bert_utils.BertTraining.logger.info", "bert_utils.BertTraining.state.clear", "bert_utils.BertTraining.logger.warning", "bert_utils.BertTraining.config_checkpointing.get", "bert_utils.BertTraining.config_checkpointing.get", "list", "list", "list", "list"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.clear"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "config_global", ",", "logger", ")", ":", "\n", "        ", "super", "(", "BertTraining", ",", "self", ")", ".", "__init__", "(", "config", ",", "config_global", ",", "logger", ")", "\n", "\n", "self", ".", "epoch_max_examples", "=", "config", ".", "get", "(", "'epoch_max_examples'", ")", "\n", "\n", "# checkpointing and weight restoring", "\n", "self", ".", "config_checkpointing", "=", "config", ".", "get", "(", "'checkpointing'", ",", "dict", "(", ")", ")", "\n", "self", ".", "state", "=", "QATrainStatePyTorch", "(", "self", ".", "checkpoint_folder", ",", "\n", "less_is_better", "=", "self", ".", "config_checkpointing", ".", "get", "(", "'score_less_is_better'", ",", "False", ")", ",", "\n", "logger", "=", "self", ".", "logger", ")", "\n", "if", "self", ".", "config_checkpointing", ".", "get", "(", "'remove_save_folder_on_start'", ",", "False", ")", "is", "True", "and", "os", ".", "path", ".", "isdir", "(", "self", ".", "checkpoint_folder", ")", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "'Removing old save folder'", ")", "\n", "self", ".", "state", ".", "clear", "(", ")", "\n", "\n", "# tensorboard", "\n", "", "self", ".", "tensorboard", "=", "SummaryWriter", "(", "self", ".", "tensorboard_folder", ")", "\n", "\n", "self", ".", "n_train_answers", "=", "config", "[", "'n_train_answers'", "]", "\n", "self", ".", "length_question", "=", "self", ".", "config_global", "[", "'question_length'", "]", "\n", "self", ".", "length_answer", "=", "self", ".", "config_global", "[", "'answer_length'", "]", "\n", "self", ".", "n_epochs", "=", "self", ".", "config", "[", "'epochs'", "]", "\n", "self", ".", "backup_checkpoint_every", "=", "self", ".", "config", ".", "get", "(", "'backup_checkpoint_every'", ",", "-", "1", ")", "\n", "self", ".", "logger", ".", "debug", "(", "'Checkpoint backup '", "+", "\n", "(", "'enabled ({} ep)'", ".", "format", "(", "\n", "self", ".", "backup_checkpoint_every", ")", "if", "self", ".", "backup_checkpoint_every", ">", "0", "else", "'disabled'", ")", "\n", ")", "\n", "\n", "self", ".", "chkpt_optimizer", "=", "self", ".", "config", ".", "get", "(", "'checkpoint_optimizer'", ",", "True", ")", "\n", "self", ".", "logger", ".", "debug", "(", "'Checkpoint optimizer? {}'", ".", "format", "(", "self", ".", "chkpt_optimizer", ")", ")", "\n", "\n", "self", ".", "batchsize", "=", "self", ".", "config", "[", "'batchsize'", "]", "\n", "self", ".", "gradient_accumulation_steps", "=", "self", ".", "config", ".", "get", "(", "'gradient_accumulation_steps'", ",", "1", ")", "\n", "self", ".", "batchsize_neg_ranking", "=", "self", ".", "config", ".", "get", "(", "'batchsize_neg_ranking'", ",", "64", ")", "\n", "if", "\"train_adapter\"", "in", "config", ":", "\n", "            ", "self", ".", "adapter_task", "=", "config", "[", "\"train_adapter\"", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "adapter_task", "=", "None", "\n", "", "self", ".", "use_all_negative_sampling", "=", "self", ".", "config", ".", "get", "(", "'use_all_negative_sampling'", ",", "False", ")", "\n", "if", "self", ".", "use_all_negative_sampling", ":", "\n", "            ", "self", ".", "logger", ".", "warning", "(", "'Using all answers for negative sampling!'", ")", "\n", "\n", "# to enable multitasking capabilities we cache instances and questions separately for each dataset", "\n", "", "self", ".", "data", "=", "None", "\n", "self", ".", "train_positive_instances", "=", "defaultdict", "(", "lambda", ":", "list", "(", ")", ")", "\n", "self", ".", "train_questions", "=", "defaultdict", "(", "lambda", ":", "list", "(", ")", ")", "\n", "self", ".", "train_random_indices", "=", "defaultdict", "(", "lambda", ":", "list", "(", ")", ")", "\n", "self", ".", "train_negative_answers", "=", "defaultdict", "(", "lambda", ":", "list", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.BertTraining.get_loss": [[310, 319], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_loss", "(", "self", ",", "model", ",", "step_examples", ",", "tasks", "=", "None", ")", ":", "\n", "        ", "\"\"\"Calls this method during training to obtain the loss of the model for some examples\n\n        :param model: BertWrapperModel\n        :param step_examples: list[InputExample] or list[(InputExample, InputExample, label)]\n        :param tasks: list[str] or None of adapter name(s)\n        :return:\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.BertTraining.start": [[320, 460], ["bert_utils.BertTraining.prepare_training", "hasattr", "bert_utils.BertTraining.config.get", "bert_utils.BertTraining.config.get", "list", "int", "transformers.AdamW", "bert_utils.BertTraining.state.load", "bert_utils.BertTraining.logger.info", "range", "bert_utils.BertTraining.logger.info", "model.bert.bert.parameters", "model.bert.bert.enable_adapters", "hasattr", "bert_utils.BertTraining.logger.warn", "model.bert.bert.named_parameters", "bert_utils.BertTraining.logger.info", "model.bert.lin_layer.named_parameters", "model.bert.named_parameters", "bert_utils.BertTraining.get_n_batches", "transformers.get_constant_schedule_with_warmup", "transformers.get_constant_schedule", "bert_utils.BertTraining.logger.info", "bert_utils.BertTraining.get_n_batches", "bert_utils.BertTraining.logger.info", "bert_utils.BertTraining.logger.debug", "bert_utils.BertTraining.prepare_next_epoch", "bert_utils.BertTraining.create_progress_bar", "bert_utils.BertTraining.logger.debug", "bert_utils.BertTraining.logger.debug", "bert_utils.BertTraining.", "bert_utils.BertTraining.logger.info", "bert_utils.BertTraining.config.get", "bert_utils.BertTraining.logger.info", "model.bert.bert.parameters", "model.bert.bert.enable_adapters", "bert_utils.BertTraining.logger.warn", "bert_utils.BertTraining.config.get", "bert_utils.BertTraining.get_n_batches", "bert_utils.BertTraining.config.get", "bert_utils.BertTraining.config.get", "bert_utils.BertTraining.config.get", "range", "bert_utils.BertTraining.get_next_batch", "int", "range", "transformers.AdamW.step", "transformers.get_constant_schedule.step", "transformers.AdamW.zero_grad", "bert_utils.BertTraining.tensorboard.add_scalars", "train_losses.append", "numpy.mean", "bert_utils.BertTraining.logger.info", "evaluation.start", "bert_utils.BertTraining.tensorboard.add_scalar", "bert_utils.BertTraining.tensorboard.add_scalars", "valid_score_other_measures.items", "bert_utils.BertTraining.state.record", "bert_utils.BertTraining.logger.info", "bert_utils.BertTraining.state.record", "bert_utils.BertTraining.get_n_batches", "int", "numpy.ceil", "bert_utils.BertTraining.get_loss", "bert_utils.BertTraining.backward", "bert_utils.BertTraining.item", "bert_utils.BertTraining.config.get", "torch.nn.utils.clip_grad_norm_", "numpy.mean", "list", "list", "dict", "bert_utils.BertTraining.tensorboard.add_scalar", "any", "bert_utils.BertTraining.get_n_batches", "model.bert.parameters", "bert_utils.BertTraining.config.get", "valid_score.values", "valid_score_other_measures.values", "any", "len", "valid_score_other_measures.items"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_batch_same_q.BertTrainingPointwiseAllQSameBatch.prepare_training", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.load", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.enable_adapters", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_batch_same_q.BertTrainingPointwiseAllQSameBatch.get_n_batches", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_batch_same_q.BertTrainingPointwiseAllQSameBatch.get_n_batches", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_with_negative_pools.BertTrainingPointwiseWithNegativePools.prepare_next_epoch", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.ComponentBase.create_progress_bar", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.enable_adapters", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_batch_same_q.BertTrainingPointwiseAllQSameBatch.get_n_batches", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_batch_same_q.BertTrainingPointwiseAllQSameBatch.get_next_batch", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_use.QAEvaluationUSE.start", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.record", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.record", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_batch_same_q.BertTrainingPointwiseAllQSameBatch.get_n_batches", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_batch_same_q.BertTrainingPointwiseAllQSameBatch.get_loss", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_batch_same_q.BertTrainingPointwiseAllQSameBatch.get_n_batches"], ["", "def", "start", "(", "self", ",", "model", ",", "data", ",", "evaluation", ")", ":", "\n", "        ", "\"\"\"\n\n        :param model:\n        :type model: BertWrapperModel\n        :param data:\n        :type data: MultiData\n        :type evaluation: Evaluation\n        \"\"\"", "\n", "self", ".", "prepare_training", "(", "model", ",", "data", ")", "\n", "\n", "if", "hasattr", "(", "model", ".", "bert", ".", "config", ",", "'adapter_attention'", ")", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Adapter attention detected. Freezing all weights except the adapter attention\"", ")", "\n", "for", "param", "in", "model", ".", "bert", ".", "bert", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "model", ".", "bert", ".", "bert", ".", "enable_adapters", "(", "unfreeze_adapters", "=", "False", ",", "unfreeze_attention", "=", "True", ")", "\n", "", "elif", "hasattr", "(", "model", ".", "bert", ".", "config", ",", "'adapters'", ")", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Adapters detected. Freezing all weights except the adapters\"", ")", "\n", "for", "param", "in", "model", ".", "bert", ".", "bert", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "model", ".", "bert", ".", "bert", ".", "enable_adapters", "(", "unfreeze_adapters", "=", "True", ",", "unfreeze_attention", "=", "False", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "get", "(", "'freeze_bert'", ",", "False", ")", ":", "\n", "            ", "self", ".", "logger", ".", "warn", "(", "'FREEZING BERT'", ")", "\n", "for", "name", ",", "param", "in", "model", ".", "bert", ".", "bert", ".", "named_parameters", "(", ")", ":", "\n", "                ", "self", ".", "logger", ".", "warn", "(", "'freeze {}'", ".", "format", "(", "name", ")", ")", "\n", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "if", "self", ".", "config", ".", "get", "(", "'freeze_head'", ",", "False", ")", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Freezing the weights of the classification head\"", ")", "\n", "for", "name", ",", "param", "in", "model", ".", "bert", ".", "lin_layer", ".", "named_parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "# for param in model.bert.parameters():", "\n", "#     if param.requires_grad:", "\n", "#         print(param)", "\n", "\n", "# Prepare BERT optimizer", "\n", "", "", "param_optimizer", "=", "list", "(", "model", ".", "bert", ".", "named_parameters", "(", ")", ")", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "self", ".", "config", ".", "get", "(", "'weight_decay'", ",", "0.0", ")", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "t_total", "=", "self", ".", "get_n_batches", "(", ")", "*", "self", ".", "n_epochs", "\n", "num_warmup_steps", "=", "int", "(", "self", ".", "get_n_batches", "(", ")", "*", "self", ".", "config", ".", "get", "(", "'warmup_proportion'", ",", "0.1", ")", ")", "\n", "\n", "optimizer", "=", "AdamW", "(", "\n", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "self", ".", "config", ".", "get", "(", "'learning_rate'", ",", "5e-5", ")", ",", "\n", "eps", "=", "self", ".", "config", ".", "get", "(", "'adam_epsilon'", ",", "1e-8", ")", "\n", ")", "\n", "# correct_bias=False)", "\n", "\n", "if", "num_warmup_steps", ">", "0", ":", "\n", "            ", "scheduler", "=", "transformers", ".", "get_constant_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", ")", "\n", "", "else", ":", "\n", "# scheduler = WarmupConstantSchedule(optimizer=optimizer, warmup_steps=num_warmup_steps)", "\n", "            ", "scheduler", "=", "transformers", ".", "get_constant_schedule", "(", "optimizer", ")", "\n", "\n", "", "self", ".", "state", ".", "load", "(", "model", ".", "bert", ",", "optimizer", ",", "weights", "=", "'last'", ")", "\n", "start_epoch", "=", "self", ".", "state", ".", "recorded_epochs", "+", "1", "\n", "end_epoch", "=", "self", ".", "n_epochs", "+", "1", "\n", "\n", "if", "self", ".", "state", ".", "recorded_epochs", ">", "0", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "'Loaded the weights of last epoch {} with valid score={}'", ".", "format", "(", "\n", "self", ".", "state", ".", "recorded_epochs", ",", "self", ".", "state", ".", "scores", "[", "-", "1", "]", "\n", ")", ")", "\n", "# if start_epoch < end_epoch and not self.config.get('skip_restore_validation', False):", "\n", "#     self.logger.info('Now calculating validation score (to verify the restoring success)')", "\n", "#     valid_score = list(evaluation.start(model, data, valid_only=True)[0].values())[0]", "\n", "#     self.logger.info('Score={:.4f}'.format(valid_score))", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "'Running from epoch {} to epoch {}'", ".", "format", "(", "start_epoch", ",", "end_epoch", "-", "1", ")", ")", "\n", "\n", "global_step", "=", "self", ".", "get_n_batches", "(", ")", "*", "self", ".", "state", ".", "recorded_epochs", "\n", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "end_epoch", ")", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "'Epoch {}/{}'", ".", "format", "(", "epoch", ",", "self", ".", "n_epochs", ")", ")", "\n", "\n", "self", ".", "logger", ".", "debug", "(", "'Preparing epoch'", ")", "\n", "self", ".", "prepare_next_epoch", "(", "model", ",", "data", ",", "epoch", ")", "\n", "\n", "bar", "=", "self", ".", "create_progress_bar", "(", "'loss'", ")", "\n", "train_losses", "=", "[", "]", "# used to calculate the epoch train loss", "\n", "recent_train_losses", "=", "[", "]", "# used to calculate the display loss", "\n", "\n", "self", ".", "logger", ".", "debug", "(", "'Training'", ")", "\n", "self", ".", "logger", ".", "debug", "(", "'{} minibatches with size {}'", ".", "format", "(", "self", ".", "get_n_batches", "(", ")", ",", "self", ".", "batchsize", ")", ")", "\n", "\n", "for", "_", "in", "bar", "(", "range", "(", "int", "(", "self", ".", "get_n_batches", "(", ")", ")", ")", ")", ":", "\n", "# self.global_step += self.batchsize", "\n", "                ", "train_examples", "=", "self", ".", "get_next_batch", "(", "model", ",", "data", ")", "\n", "batch_loss", "=", "0", "\n", "\n", "batch_steps", "=", "int", "(", "np", ".", "ceil", "(", "len", "(", "train_examples", ")", "/", "(", "self", ".", "batchsize", "/", "self", ".", "gradient_accumulation_steps", ")", ")", ")", "\n", "for", "i", "in", "range", "(", "batch_steps", ")", ":", "\n", "                    ", "step_size", "=", "self", ".", "batchsize", "//", "self", ".", "gradient_accumulation_steps", "\n", "step_examples", "=", "train_examples", "[", "i", "*", "step_size", ":", "(", "i", "+", "1", ")", "*", "step_size", "]", "\n", "step_loss", "=", "self", ".", "get_loss", "(", "model", ",", "step_examples", ",", "self", ".", "adapter_task", ")", "\n", "step_loss", "=", "step_loss", "/", "self", ".", "gradient_accumulation_steps", "\n", "step_loss", ".", "backward", "(", ")", "\n", "batch_loss", "+=", "step_loss", ".", "item", "(", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "get", "(", "'max_grad_norm'", ",", "0", ")", ">", "0", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "bert", ".", "parameters", "(", ")", ",", "self", ".", "config", ".", "get", "(", "'max_grad_norm'", ")", ")", "\n", "# Gradient clipping is not in AdamW anymore (so you can use amp without issue)", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", "epoch", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "self", ".", "tensorboard", ".", "add_scalars", "(", "'scores'", ",", "{", "'train_loss'", ":", "batch_loss", "}", ",", "global_step", "=", "global_step", ")", "\n", "\n", "recent_train_losses", "=", "(", "[", "batch_loss", "]", "+", "recent_train_losses", ")", "[", ":", "20", "]", "\n", "train_losses", ".", "append", "(", "recent_train_losses", "[", "0", "]", ")", "\n", "bar", ".", "dynamic_messages", "[", "'loss'", "]", "=", "np", ".", "mean", "(", "recent_train_losses", ")", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "'train loss={:.6f}'", ".", "format", "(", "np", ".", "mean", "(", "train_losses", ")", ")", ")", "\n", "\n", "if", "self", ".", "config", ".", "get", "(", "'evaluate_dev'", ",", "True", ")", ":", "\n", "                ", "self", ".", "logger", ".", "info", "(", "'Now calculating validation score'", ")", "\n", "valid_score", ",", "valid_score_other_measures", "=", "evaluation", ".", "start", "(", "model", ",", "data", ",", "valid_only", "=", "True", ")", "\n", "valid_score", "=", "list", "(", "valid_score", ".", "values", "(", ")", ")", "[", "0", "]", "# get only the dev split (there wont be any other split)", "\n", "valid_score_other_measures", "=", "list", "(", "valid_score_other_measures", ".", "values", "(", ")", ")", "[", "0", "]", "\n", "\n", "self", ".", "tensorboard", ".", "add_scalar", "(", "'valid_score'", ",", "valid_score", ",", "global_step", "=", "global_step", ")", "\n", "self", ".", "tensorboard", ".", "add_scalars", "(", "'scores'", ",", "\n", "dict", "(", "[", "(", "'valid_'", "+", "k", ",", "v", ")", "for", "k", ",", "v", ",", "in", "valid_score_other_measures", ".", "items", "(", ")", "]", ")", ",", "\n", "global_step", "=", "global_step", ")", "\n", "for", "key", ",", "value", "in", "valid_score_other_measures", ".", "items", "(", ")", ":", "\n", "                    ", "self", ".", "tensorboard", ".", "add_scalar", "(", "key", ",", "value", ",", "global_step", "=", "global_step", ")", "\n", "\n", "", "self", ".", "state", ".", "record", "(", "model", ".", "bert", ",", "optimizer", "if", "self", ".", "chkpt_optimizer", "else", "None", ",", "valid_score", ",", "self", ".", "backup_checkpoint_every", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "logger", ".", "info", "(", "'Not validating dev. Setting score to epoch'", ")", "\n", "self", ".", "state", ".", "record", "(", "model", ".", "bert", ",", "optimizer", "if", "self", ".", "chkpt_optimizer", "else", "None", ",", "epoch", ",", "self", ".", "backup_checkpoint_every", ")", "\n", "\n", "", "", "return", "self", ".", "state", ".", "best_epoch", ",", "self", ".", "state", ".", "best_score", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.BertTraining.restore_best_epoch": [[461, 474], ["bert_utils.BertTraining.logger.info", "bert_utils.BertTraining.state.load", "bert_utils.BertTraining.logger.info", "bert_utils.BertTraining.logger.info", "bert_utils.BertTraining.logger.info", "list", "[].values", "evaluation.start"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.load", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_use.QAEvaluationUSE.start"], ["", "def", "restore_best_epoch", "(", "self", ",", "model", ",", "data", ",", "evaluation", ",", "validate", "=", "True", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "'Restoring the weights of the best epoch {} with score {}'", ".", "format", "(", "\n", "self", ".", "state", ".", "best_epoch", ",", "self", ".", "state", ".", "best_score", "\n", ")", ")", "\n", "self", ".", "state", ".", "load", "(", "model", ".", "bert", ",", "optimizer", "=", "None", ",", "weights", "=", "'best'", ")", "\n", "if", "validate", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "'Now calculating validation score (to verify the restoring success)'", ")", "\n", "valid_score", "=", "list", "(", "evaluation", ".", "start", "(", "model", ",", "data", ",", "valid_only", "=", "True", ")", "[", "0", "]", ".", "values", "(", ")", ")", "[", "0", "]", "\n", "self", ".", "logger", ".", "info", "(", "'Score={:.4f}'", ".", "format", "(", "valid_score", ")", ")", "\n", "return", "valid_score", "\n", "", "else", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "'Skipping calculating validation score (to verify the restoring success)!'", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.BertTraining.remove_checkpoints": [[475, 478], ["bert_utils.BertTraining.state.clear"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.clear"], ["", "", "def", "remove_checkpoints", "(", "self", ")", ":", "\n", "        ", "\"\"\"Removes all the persisted checkpoint data that was generated during training for restoring purposes\"\"\"", "\n", "self", ".", "state", ".", "clear", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.BertTraining.prepare_training": [[479, 488], ["None"], "methods", ["None"], ["", "def", "prepare_training", "(", "self", ",", "model", ",", "data", ")", ":", "\n", "        ", "\"\"\"Prepares data that is used in all training epochs, i.e., positive pairs.\n        Sets the value of train_positive_instances\n\n        :param model:\n        :param data:\n        :return:\n        \"\"\"", "\n", "self", ".", "data", "=", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.BertTraining.get_batch_indices": [[489, 509], ["len", "numpy.random.permutation().tolist", "numpy.random.permutation", "len"], "methods", ["None"], ["", "def", "get_batch_indices", "(", "self", ",", "dataset_id", ",", "size", ")", ":", "\n", "        ", "\"\"\"Keeps track of random indices for processing the train splits. Ensures that all instances of a train dataset\n        are used throughout the training independent of how large epochs are.\n\n        :return: Next set of random indices for a given dataset.\n        \"\"\"", "\n", "indices", "=", "self", ".", "train_random_indices", "[", "dataset_id", "]", "\n", "batch_indices", "=", "indices", "[", ":", "size", "]", "\n", "missing_indices", "=", "size", "-", "len", "(", "batch_indices", ")", "\n", "\n", "if", "missing_indices", ">", "0", ":", "\n", "# indices are empty, create a new random permutation", "\n", "            ", "indices", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ".", "train_positive_instances", "[", "dataset_id", "]", ")", ")", ".", "tolist", "(", ")", "\n", "batch_indices", "+=", "indices", "[", ":", "missing_indices", "]", "\n", "remaining_indices", "=", "indices", "[", "missing_indices", ":", "]", "\n", "", "else", ":", "\n", "            ", "remaining_indices", "=", "indices", "[", "size", ":", "]", "\n", "\n", "", "self", ".", "train_random_indices", "[", "dataset_id", "]", "=", "remaining_indices", "\n", "return", "batch_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.BertTraining.get_random_answers": [[510, 530], ["len", "numpy.random.shuffle", "list", "list", "list"], "methods", ["None"], ["", "def", "get_random_answers", "(", "self", ",", "dataset_id", ",", "n", ")", ":", "\n", "        ", "neg_answers", "=", "self", ".", "train_negative_answers", "[", "dataset_id", "]", "\n", "batch_neg_answers", "=", "neg_answers", "[", ":", "n", "]", "\n", "missing_answers", "=", "n", "-", "len", "(", "batch_neg_answers", ")", "\n", "\n", "if", "missing_answers", ">", "0", ":", "\n", "# indices are empty, create a new random permutation", "\n", "            ", "if", "self", ".", "use_all_negative_sampling", ":", "\n", "                ", "negative_samples", "=", "list", "(", "self", ".", "data", ".", "datas_train", "[", "dataset_id", "]", ".", "archive", ".", "answers", ")", "\n", "negative_samples", "+=", "list", "(", "self", ".", "data", ".", "datas_train", "[", "dataset_id", "]", ".", "archive", ".", "additional_answers", ")", "\n", "", "else", ":", "\n", "                ", "negative_samples", "=", "list", "(", "self", ".", "data", ".", "datas_train", "[", "dataset_id", "]", ".", "archive", ".", "train", ".", "answers", ")", "\n", "", "np", ".", "random", ".", "shuffle", "(", "negative_samples", ")", "\n", "batch_neg_answers", "+=", "negative_samples", "[", ":", "missing_answers", "]", "\n", "remaining_neg_answers", "=", "negative_samples", "[", "missing_answers", ":", "]", "\n", "", "else", ":", "\n", "            ", "remaining_neg_answers", "=", "neg_answers", "[", "n", ":", "]", "\n", "\n", "", "self", ".", "train_negative_answers", "[", "dataset_id", "]", "=", "remaining_neg_answers", "\n", "return", "batch_neg_answers", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.BertTraining.prepare_next_epoch": [[531, 536], ["None"], "methods", ["None"], ["", "def", "prepare_next_epoch", "(", "self", ",", "model", ",", "data", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Prepares the next epoch\n\n        \"\"\"", "\n", "self", ".", "batch_i", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.BertTraining.get_n_batches": [[537, 543], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_n_batches", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n\n        :return: the number of batches in one epoch (this depends on the training strategy that is used)\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.BertTraining.get_next_batch": [[544, 552], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_next_batch", "(", "self", ",", "model", ",", "data", ")", ":", "\n", "        ", "\"\"\"Return the training data for the next batch. If we configured multiple training datasets, each positive\n        example will only be paired with negative examples from the same training set (see self.train_dataset_ids)\n\n        :return: list[InputExample] or list[(InputExample, InputExample, label)]\n        :rtype: list\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.convert_examples_to_features": [[49, 134], ["isinstance", "enumerate", "tokenizer.tokenize", "len", "add_solo_special_tokens", "tokenizer.convert_tokens_to_ids", "features.append", "isinstance", "isinstance", "tokenizer.tokenize", "len", "bert_utils._truncate_seq_pair", "len", "add_pair_special_tokens", "len", "len", "len", "len", "example.guid.startswith", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "bert_utils.InputFeatures", "len", "len", "len", "len", "tokenizer.convert_tokens_to_ids", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils._truncate_seq_pair"], ["", "", "def", "convert_examples_to_features", "(", "examples", ",", "max_seq_length", ",", "tokenizer", ",", "logger", ",", "show_example", "=", "True", ")", ":", "\n", "    ", "\"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"", "\n", "\n", "# tokens_a_longer_max_seq_length = 0", "\n", "features", "=", "[", "]", "\n", "\n", "if", "isinstance", "(", "tokenizer", ",", "RobertaTokenizer", ")", ":", "\n", "        ", "solo_special_tokens_num", "=", "2", "\n", "pair_special_tokens_num", "=", "4", "\n", "pair_b_special_tokens_num", "=", "2", "\n", "add_solo_special_tokens", "=", "lambda", "tokens_a", ":", "[", "tokenizer", ".", "cls_token", "]", "+", "tokens_a", "+", "[", "tokenizer", ".", "sep_token", "]", "\n", "add_pair_special_tokens", "=", "lambda", "t", ",", "tokens_b", ":", "t", "+", "[", "tokenizer", ".", "sep_token", "]", "+", "tokens_b", "+", "[", "tokenizer", ".", "sep_token", "]", "\n", "", "elif", "isinstance", "(", "tokenizer", ",", "BertTokenizer", ")", "or", "isinstance", "(", "tokenizer", ",", "AlbertTokenizer", ")", ":", "\n", "        ", "solo_special_tokens_num", "=", "2", "\n", "pair_special_tokens_num", "=", "3", "\n", "pair_b_special_tokens_num", "=", "1", "\n", "add_solo_special_tokens", "=", "lambda", "tokens_a", ":", "[", "tokenizer", ".", "cls_token", "]", "+", "tokens_a", "+", "[", "tokenizer", ".", "sep_token", "]", "\n", "add_pair_special_tokens", "=", "lambda", "t", ",", "tokens_b", ":", "t", "+", "tokens_b", "+", "[", "tokenizer", ".", "sep_token", "]", "\n", "\n", "", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "tokens_a", "=", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "tokens_b", "=", "None", "\n", "\n", "len_tokens_a", "=", "len", "(", "tokens_a", ")", "\n", "len_tokens_b", "=", "0", "\n", "\n", "if", "example", ".", "text_b", ":", "\n", "            ", "tokens_b", "=", "tokenizer", ".", "tokenize", "(", "example", ".", "text_b", ")", "\n", "len_tokens_b", "=", "len", "(", "tokens_b", ")", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total", "\n", "# length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "max_seq_length", "-", "pair_special_tokens_num", ")", "\n", "", "else", ":", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "            ", "if", "len", "(", "tokens_a", ")", ">", "max_seq_length", "-", "solo_special_tokens_num", ":", "\n", "                ", "tokens_a", "=", "tokens_a", "[", ":", "(", "max_seq_length", "-", "solo_special_tokens_num", ")", "]", "\n", "\n", "# if (len_tokens_a + len_tokens_b) > (max_seq_length - solo_special_tokens_num):", "\n", "#    tokens_a_longer_max_seq_length += 1", "\n", "\n", "", "", "tokens", "=", "add_solo_special_tokens", "(", "tokens_a", ")", "\n", "segment_ids", "=", "[", "0", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "            ", "tokens", "=", "add_pair_special_tokens", "(", "tokens", ",", "tokens_b", ")", "\n", "segment_ids", "+=", "[", "1", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "pair_b_special_tokens_num", ")", "\n", "\n", "", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding", "=", "[", "0", "]", "*", "(", "max_seq_length", "-", "len", "(", "input_ids", ")", ")", "\n", "input_ids", "+=", "[", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "tokenizer", ".", "pad_token", "]", ")", "[", "0", "]", "]", "*", "(", "max_seq_length", "-", "len", "(", "input_ids", ")", ")", "\n", "input_mask", "+=", "padding", "\n", "segment_ids", "+=", "padding", "\n", "\n", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "\n", "label_id", "=", "example", ".", "label", "\n", "\n", "if", "show_example", "and", "ex_index", "<", "1", "and", "example", ".", "guid", ".", "startswith", "(", "'train-'", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "(", "\"tokens: %s\"", "%", "\" \"", ".", "join", "(", "\n", "[", "str", "(", "x", ")", "for", "x", "in", "tokens", "]", ")", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"segment_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label: %s (id = %d)\"", "%", "(", "example", ".", "label", ",", "label_id", ")", ")", "\n", "\n", "", "features", ".", "append", "(", "\n", "InputFeatures", "(", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "label_id", "=", "label_id", ")", ")", "\n", "\n", "# logger.debug(\":: Sentences longer than max_sequence_length: %d\" % (tokens_a_longer_max_seq_length))", "\n", "# logger.debug(\":: Num sentences: %d\" % (len(examples)))", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils._truncate_seq_pair": [[136, 151], ["len", "len", "len", "len", "tokens_a.pop", "tokens_b.pop"], "function", ["None"], ["", "def", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "max_length", ")", ":", "\n", "    ", "\"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"", "\n", "\n", "# This is a simple heuristic which will always truncate the longer sequence", "\n", "# one token at a time. This makes more sense than truncating an equal percent", "\n", "# of tokens from each, since if one sequence is very short then each token", "\n", "# that's truncated likely contains more information than a longer sequence.", "\n", "while", "True", ":", "\n", "        ", "total_length", "=", "len", "(", "tokens_a", ")", "+", "len", "(", "tokens_b", ")", "\n", "if", "total_length", "<=", "max_length", ":", "\n", "            ", "break", "\n", "", "if", "len", "(", "tokens_a", ")", ">", "len", "(", "tokens_b", ")", ":", "\n", "            ", "tokens_a", ".", "pop", "(", ")", "\n", "", "else", ":", "\n", "            ", "tokens_b", ".", "pop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.ComponentBase.__init__": [[8, 18], ["dict", "dict"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.ComponentBase.create_progress_bar": [[19, 32], ["__init__.ComponentBase.config_global.get", "progressbar.SimpleProgress", "progressbar.Bar", "progressbar.ETA", "widgets.append", "progressbar.ProgressBar", "progressbar.NullBar", "progressbar.DynamicMessage"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.Data.setup": [[35, 37], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.Data.get_fold_data": [[38, 47], ["NotImplementedError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.MultiData.__init__": [[50, 60], ["__init__.ComponentBase.__init__"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.MultiData.setup": [[61, 64], ["data.setup"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.__init__.QAData.setup"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.MultiData.add": [[65, 72], ["isinstance", "__init__.MultiData.datas.append", "len", "__init__.MultiData._datas_dict[].append", "set"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.MultiData.datas_train": [[73, 76], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.MultiData.datas_dev": [[77, 80], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.MultiData.datas_test": [[81, 84], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.Model.__init__": [[87, 92], ["__init__.ComponentBase.__init__", "collections.OrderedDict"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.Model.build": [[94, 96], ["NotImplementedError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.Training.start": [[99, 109], ["NotImplementedError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.Training.checkpoint_folder": [[110, 113], ["os.path.join"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.Training.tensorboard_folder": [[114, 117], ["os.path.join"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.Training.restore_best_epoch": [[118, 120], ["NotImplementedError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.Training.remove_checkpoints": [[121, 124], ["NotImplementedError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.Evaluation.start": [[127, 137], ["NotImplementedError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.util.flatten": [[6, 8], ["None"], "function", ["None"], ["def", "flatten", "(", "x", ")", ":", "\n", "    ", "return", "[", "item", "for", "sublist", "in", "x", "for", "item", "in", "sublist", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.util.merge_dicts": [[10, 25], ["dict_a.copy", "isinstance", "isinstance", "util.merge_dicts"], "function", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.util.merge_dicts"], ["", "def", "merge_dicts", "(", "dict_a", ",", "dict_b", ")", ":", "\n", "    ", "\"\"\"Performs a recursive merge of two dicts dict_a and dict_b, wheras dict_b always overwrites the values of dict_a\n\n    :param dict_a: the first dictionary. This is the weak dictionary which will always be overwritten by dict_b (dict_a\n                   therefore is a default dictionary type\n    :param dict_b: the second dictionary. This is the strong dictionary which will always overwrite vales of dict_a\n    :return:\n    \"\"\"", "\n", "merge_result", "=", "dict_a", ".", "copy", "(", ")", "\n", "for", "key", "in", "dict_b", ":", "\n", "        ", "if", "key", "in", "dict_a", "and", "isinstance", "(", "dict_a", "[", "key", "]", ",", "dict", ")", "and", "isinstance", "(", "dict_b", "[", "key", "]", ",", "dict", ")", ":", "\n", "            ", "merge_result", "[", "key", "]", "=", "merge_dicts", "(", "dict_a", "[", "key", "]", ",", "dict_b", "[", "key", "]", ")", "\n", "", "else", ":", "\n", "            ", "merge_result", "[", "key", "]", "=", "dict_b", "[", "key", "]", "\n", "", "", "return", "merge_result", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.util.replace_dict_values": [[27, 46], ["dict", "key.split", "util.replace_dict_values"], "function", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.util.replace_dict_values"], ["", "def", "replace_dict_values", "(", "source", ",", "replacements", ")", ":", "\n", "    ", "\"\"\"Creates a copy of the source dictionary and replaces all values specified in a replacement list\n\n    :param source: The source dictionary\n    :param replacements: The replacements. This is a list of key/value tuples, where dots in the key describe the\n    hierarchy (e.g. my.property)\n    :return: a copy of source with the replacements\n    \"\"\"", "\n", "result", "=", "dict", "(", "source", ")", "\n", "for", "key", ",", "value", "in", "replacements", ":", "\n", "        ", "if", "'.'", "in", "key", ":", "\n", "            ", "split", "=", "key", ".", "split", "(", "'.'", ")", "\n", "result", "[", "split", "[", "0", "]", "]", "=", "replace_dict_values", "(", "\n", "result", "[", "split", "[", "0", "]", "]", ",", "\n", "[", "(", "'.'", ".", "join", "(", "split", "[", "1", ":", "]", ")", ",", "value", ")", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "result", "[", "key", "]", "=", "value", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.util.read_embeddings": [[48, 81], ["isinstance", "collections.OrderedDict", "set", "open", "gzip.open", "path.endswith", "line.strip().split", "line.strip", "numpy.array", "float", "logger.debug", "print"], "function", ["None"], ["", "def", "read_embeddings", "(", "path", ",", "vocab", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "    ", "\"\"\"Reads an embeddings file and returns a dictionary with the mapping from word to vector. For reproducibility and\n    debugging reasons we are returning an ordered dict here.\n\n    :param path: path of the embeddings file\n    :type path: str\n    :param vocab: the vocabulary to keep\n    :type vocab: list[str] | set[str]\n    :rtype: OrderedDict[str, list[float]]\n    :return:\n    \"\"\"", "\n", "if", "isinstance", "(", "vocab", ",", "list", ")", ":", "\n", "        ", "vocab", "=", "set", "(", "vocab", ")", "# __contains__ for sets is much faster", "\n", "\n", "", "result", "=", "OrderedDict", "(", ")", "\n", "fopen", "=", "open", "(", "path", ",", "'r'", ")", "if", "not", "path", ".", "endswith", "(", "'gz'", ")", "else", "gzip", ".", "open", "(", "path", ",", "'rb'", ")", "\n", "with", "fopen", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "if", "line", ":", "\n", "                ", "tv", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "word", "=", "tv", "[", "0", "]", "\n", "if", "vocab", "is", "None", "or", "word", "in", "vocab", ":", "\n", "                    ", "try", ":", "\n", "                        ", "vector", "=", "np", ".", "array", "(", "[", "float", "(", "v", ")", "for", "v", "in", "tv", "[", "1", ":", "]", "]", ")", "\n", "result", "[", "word", "]", "=", "vector", "\n", "", "except", ":", "\n", "                        ", "message", "=", "\"Embeddings reader: Could not convert line: {}\"", ".", "format", "(", "line", ")", "\n", "if", "logger", "is", "not", "None", ":", "\n", "                            ", "logger", ".", "debug", "(", "message", ")", "\n", "", "else", ":", "\n", "                            ", "print", "(", "message", ")", "\n", "\n", "", "", "", "", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.util.unique_items": [[83, 94], ["id_fn", "result.append"], "function", ["None"], ["", "def", "unique_items", "(", "seq", ")", ":", "\n", "    ", "\"\"\"A function that returns all unique items of a list in an order-preserving way\"\"\"", "\n", "id_fn", "=", "lambda", "x", ":", "x", "\n", "seen_items", "=", "{", "}", "\n", "result", "=", "[", "]", "\n", "for", "item", "in", "seq", ":", "\n", "        ", "marker", "=", "id_fn", "(", "item", ")", "\n", "if", "marker", "in", "seen_items", ":", "continue", "\n", "seen_items", "[", "marker", "]", "=", "1", "\n", "result", ".", "append", "(", "item", ")", "\n", "", "return", "result", "\n", "", ""]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.model.roberta_sigmoid.RobertaSigmoid.__init__": [[12, 19], ["experiment.qa.model.BaseModel.__init__", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["def", "__init__", "(", "self", ",", "from_pretrained", ",", "model_name", "=", "None", ",", "cache_dir", "=", "None", ",", "config", "=", "None", ",", "num_labels", "=", "1", ")", ":", "\n", "        ", "super", "(", "RobertaSigmoid", ",", "self", ")", ".", "__init__", "(", "from_pretrained", ",", "model_name", "=", "model_name", ",", "cache_dir", "=", "cache_dir", ",", "config", "=", "config", ")", "\n", "assert", "num_labels", "==", "1", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "lin_layer", "=", "nn", ".", "Linear", "(", "self", ".", "config", ".", "hidden_size", ",", "num_labels", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.model.roberta_sigmoid.RobertaSigmoid.forward": [[20, 33], ["roberta_sigmoid.RobertaSigmoid.lin_layer", "roberta_sigmoid.RobertaSigmoid.sigmoid", "roberta_sigmoid.RobertaSigmoid.bert"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "tasks", "=", "None", ")", ":", "\n", "# we set the token type ids to zero", "\n", "# -> https://github.com/huggingface/transformers/issues/1443#issuecomment-581019419", "\n", "        ", "encoded_layers", ",", "pooled_output", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "token_type_ids", "=", "token_type_ids", "*", "0.0", ",", "attention_mask", "=", "attention_mask", ",", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "head_mask", "\n", ")", "[", ":", "2", "]", "\n", "\n", "# sent_encoding = pooled_output", "\n", "sent_encoding", "=", "encoded_layers", "[", ":", ",", "0", ",", ":", "]", "\n", "# sent_encoding = self.dropout(sent_encoding)", "\n", "sent_encoding", "=", "self", ".", "lin_layer", "(", "sent_encoding", ")", "\n", "return", "self", ".", "sigmoid", "(", "sent_encoding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.model.bert_sigmoid.BertSigmoid.__init__": [[13, 20], ["experiment.qa.model.BaseModel.__init__", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["def", "__init__", "(", "self", ",", "from_pretrained", ",", "model_name", "=", "None", ",", "cache_dir", "=", "None", ",", "config", "=", "None", ",", "num_labels", "=", "1", ")", ":", "\n", "        ", "super", "(", "BertSigmoid", ",", "self", ")", ".", "__init__", "(", "from_pretrained", ",", "model_name", "=", "model_name", ",", "cache_dir", "=", "cache_dir", ",", "config", "=", "config", ")", "\n", "assert", "num_labels", "==", "1", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "lin_layer", "=", "nn", ".", "Linear", "(", "self", ".", "config", ".", "hidden_size", ",", "num_labels", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.model.bert_sigmoid.BertSigmoid.forward": [[21, 32], ["bert_sigmoid.BertSigmoid.lin_layer", "bert_sigmoid.BertSigmoid.sigmoid", "bert_sigmoid.BertSigmoid.bert"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "tasks", "=", "None", ")", ":", "\n", "        ", "encoded_layers", ",", "pooled_output", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "attention_mask", "=", "attention_mask", ",", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "head_mask", ",", "tasks", "=", "tasks", "\n", ")", "[", ":", "2", "]", "\n", "\n", "# sent_encoding = pooled_output", "\n", "sent_encoding", "=", "encoded_layers", "[", ":", ",", "0", ",", ":", "]", "\n", "# sent_encoding = self.dropout(sent_encoding)", "\n", "sent_encoding", "=", "self", ".", "lin_layer", "(", "sent_encoding", ")", "\n", "return", "self", ".", "sigmoid", "(", "sent_encoding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.model.bert_sigmoid.BertSigmoid.average_standard_bert_output": [[33, 50], ["torch.sum", "attention_mask[].repeat", "torch.sum", "bert_sigmoid.BertSigmoid.bert", "length[].repeat", "encoded_layers.size", "encoded_layers.size"], "methods", ["None"], ["", "def", "average_standard_bert_output", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "encoded_layers", ",", "_", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "attention_mask", "=", "attention_mask", ",", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "head_mask", "\n", ")", "[", ":", "2", "]", "\n", "\n", "attention_mask", "=", "(", "attention_mask", "==", "0", ")", ".", "float", "(", ")", ".", "to", "(", "encoded_layers", ".", "device", ")", "\n", "\n", "length", "=", "torch", ".", "sum", "(", "attention_mask", ",", "dim", "=", "1", ")", "\n", "\n", "attention_mask", "=", "attention_mask", "[", ":", ",", ":", ",", "None", "]", ".", "repeat", "(", "(", "1", ",", "1", ",", "encoded_layers", ".", "size", "(", ")", "[", "-", "1", "]", ")", ")", "\n", "\n", "encoded_layers", "=", "encoded_layers", "*", "attention_mask", "\n", "\n", "layer_sum", "=", "torch", ".", "sum", "(", "encoded_layers", ",", "dim", "=", "1", ")", "\n", "mean", "=", "layer_sum", "/", "length", "[", ":", ",", "None", "]", ".", "repeat", "(", "1", ",", "encoded_layers", ".", "size", "(", ")", "[", "-", "1", "]", ")", "\n", "return", "mean", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.model.__init__.BaseModel.__init__": [[9, 23], ["torch.nn.Module.__init__", "__init__.BaseModel._MODEL.from_pretrained", "__init__.BaseModel._MODEL"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel.from_pretrained"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.model.no_model.NoModel.build": [[4, 6], ["None"], "methods", ["None"], ["    ", "def", "build", "(", "self", ",", "data", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_with_negative_pools_batch_same_q.BertTrainingPointwiseWithNegativePoolsAllQSameBatch.__init__": [[13, 24], ["experiment.bert_utils.BertTraining.__init__", "collections.defaultdict", "list"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Same as training_bert_batch_same_q but every batch contains pos/neg examples from the current question\n\n        :param args:\n        :param kwargs:\n        \"\"\"", "\n", "super", "(", "BertTrainingPointwiseWithNegativePoolsAllQSameBatch", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "cur_dataset", "=", "0", "\n", "self", ".", "n_batches", "=", "None", "\n", "\n", "self", ".", "batches", "=", "defaultdict", "(", "lambda", ":", "list", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_with_negative_pools_batch_same_q.BertTrainingPointwiseWithNegativePoolsAllQSameBatch.get_loss": [[25, 44], ["model.bert.train", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.nn.BCELoss", "torch.nn.BCELoss.", "model.bert", "torch.tensor().to.view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "get_loss", "(", "self", ",", "model", ",", "step_examples", ",", "tasks", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param model: BertWrapperModel\n        :param step_examples: list[InputExample]\n        :param tasks: list[str] or None of adapter name(s)\n        :return:\n        \"\"\"", "\n", "model", ".", "bert", ".", "train", "(", ")", "\n", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "step_examples", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "model", ".", "device", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "step_examples", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "model", ".", "device", ")", "\n", "segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "step_examples", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "\n", "model", ".", "device", ")", "\n", "label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "step_examples", "]", ",", "dtype", "=", "torch", ".", "float", ")", ".", "to", "(", "model", ".", "device", ")", "\n", "\n", "loss_fct", "=", "BCELoss", "(", ")", "\n", "step_loss", "=", "loss_fct", "(", "model", ".", "bert", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "tasks", "=", "tasks", ")", ",", "label_ids", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "\n", "return", "step_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_with_negative_pools_batch_same_q.BertTrainingPointwiseWithNegativePoolsAllQSameBatch.prepare_training": [[45, 69], ["super().prepare_training", "enumerate", "min", "len", "dataset_batches.append", "len", "batch.append", "experiment.bert_utils.convert_examples_to_features", "training_bert_with_negative_pools_batch_same_q.BertTrainingPointwiseWithNegativePoolsAllQSameBatch.batches.values", "experiment.bert_utils.InputExample"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_batch_same_q.BertTrainingPointwiseAllQSameBatch.prepare_training", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.convert_examples_to_features"], ["", "def", "prepare_training", "(", "self", ",", "model", ",", "data", ")", ":", "\n", "        ", "super", "(", "BertTrainingPointwiseWithNegativePoolsAllQSameBatch", ",", "self", ")", ".", "prepare_training", "(", "model", ",", "data", ")", "\n", "\n", "# create features for all training examples", "\n", "for", "i", ",", "dataset", "in", "enumerate", "(", "data", ".", "datas_train", ")", ":", "\n", "            ", "dataset_batches", "=", "[", "]", "\n", "for", "pool", "in", "dataset", ".", "archive", ".", "train", ".", "qa", ":", "\n", "                ", "batch", "=", "[", "]", "\n", "for", "a", "in", "pool", ".", "pooled_answers", ":", "\n", "                    ", "batch", ".", "append", "(", "\n", "InputExample", "(", "pool", ".", "question", ".", "metadata", "[", "'id'", "]", ",", "pool", ".", "question", ".", "text", ",", "a", ".", "text", ",", "\n", "label", "=", "1.0", "if", "a", "in", "pool", ".", "ground_truth", "else", "0.0", ")", "\n", ")", "\n", "", "dataset_batches", ".", "append", "(", "\n", "convert_examples_to_features", "(", "\n", "batch", ",", "self", ".", "length_question", "+", "self", ".", "length_answer", ",", "model", ".", "tokenizer", ",", "self", ".", "logger", ",", "\n", "show_example", "=", "False", "\n", ")", "\n", ")", "\n", "", "self", ".", "batches", "[", "i", "]", "=", "dataset_batches", "\n", "\n", "# calculate number of batches", "\n", "", "min_batches", "=", "min", "(", "[", "len", "(", "v", ")", "for", "v", "in", "self", ".", "batches", ".", "values", "(", ")", "]", ")", "\n", "self", ".", "n_batches", "=", "min_batches", "*", "len", "(", "self", ".", "batches", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_with_negative_pools_batch_same_q.BertTrainingPointwiseWithNegativePoolsAllQSameBatch.get_n_batches": [[70, 72], ["None"], "methods", ["None"], ["", "def", "get_n_batches", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_batches", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_with_negative_pools_batch_same_q.BertTrainingPointwiseWithNegativePoolsAllQSameBatch.get_batch_indices": [[73, 87], ["len", "numpy.random.permutation().tolist", "numpy.random.permutation", "len"], "methods", ["None"], ["", "def", "get_batch_indices", "(", "self", ",", "dataset_id", ",", "size", ")", ":", "\n", "        ", "indices", "=", "self", ".", "train_random_indices", "[", "dataset_id", "]", "\n", "batch_indices", "=", "indices", "[", ":", "size", "]", "\n", "missing_indices", "=", "size", "-", "len", "(", "batch_indices", ")", "\n", "\n", "if", "missing_indices", ">", "0", ":", "\n", "            ", "indices", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ".", "batches", "[", "dataset_id", "]", ")", ")", ".", "tolist", "(", ")", "\n", "batch_indices", "+=", "indices", "[", ":", "missing_indices", "]", "\n", "remaining_indices", "=", "indices", "[", "missing_indices", ":", "]", "\n", "", "else", ":", "\n", "            ", "remaining_indices", "=", "indices", "[", "size", ":", "]", "\n", "\n", "", "self", ".", "train_random_indices", "[", "dataset_id", "]", "=", "remaining_indices", "\n", "return", "batch_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_with_negative_pools_batch_same_q.BertTrainingPointwiseWithNegativePoolsAllQSameBatch.get_next_batch": [[88, 96], ["len", "len", "training_bert_with_negative_pools_batch_same_q.BertTrainingPointwiseWithNegativePoolsAllQSameBatch.get_batch_indices"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_with_negative_pools_batch_same_q.BertTrainingPointwiseWithNegativePoolsAllQSameBatch.get_batch_indices"], ["", "def", "get_next_batch", "(", "self", ",", "model", ",", "data", ")", ":", "\n", "        ", "self", ".", "cur_dataset", "=", "(", "self", ".", "cur_dataset", "+", "1", ")", "%", "len", "(", "self", ".", "batches", ")", "\n", "batch_index", "=", "self", ".", "get_batch_indices", "(", "self", ".", "cur_dataset", ",", "size", "=", "1", ")", "[", "0", "]", "\n", "\n", "batch_examples", "=", "self", ".", "batches", "[", "self", ".", "cur_dataset", "]", "[", "batch_index", "]", "\n", "\n", "self", ".", "batch_i", "+=", "len", "(", "batch_examples", ")", "\n", "return", "batch_examples", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_with_negative_pools.BertTrainingPointwiseWithNegativePools.__init__": [[14, 38], ["experiment.bert_utils.BertTraining.__init__", "training_bert_with_negative_pools.BertTrainingPointwiseWithNegativePools.config.get", "training_bert_with_negative_pools.BertTrainingPointwiseWithNegativePools.config.get", "training_bert_with_negative_pools.BertTrainingPointwiseWithNegativePools.config.get", "collections.defaultdict", "dict", "list"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"This does random sampling of negative answers. Optionally, if n_train_answers is set to a value greater than\n        one, this will sample for each question *n_train_answers* negative answers, which are ranked with the currently\n        trained model. The best-ranked answer is chosen as a negative sample.\n\n        :param args:\n        :param kwargs:\n        \"\"\"", "\n", "super", "(", "BertTrainingPointwiseWithNegativePools", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "cur_dataset", "=", "0", "\n", "self", ".", "n_batches", "=", "None", "\n", "\n", "self", ".", "max_negative_per_answer", "=", "self", ".", "config", ".", "get", "(", "'max_negative_per_answer'", ",", "10", ")", "\n", "self", ".", "negative_sample_from_top_n", "=", "self", ".", "config", ".", "get", "(", "'negative_sample_from_top_n'", ",", "False", ")", "\n", "# negative samples can be randomly sampled from the top-n of a pool. Sometimes the pools position indicates", "\n", "# similarity from the retrieval (e.g., InsuranceQA v2). However, for some datasets the most similar might be too", "\n", "# similar to train a model. Thus we enable the option to draw negative samples from the top-n", "\n", "\n", "# self.max_negative_per_answer = self.config.get('neg', 10)", "\n", "self", ".", "random_flip_inputs", "=", "self", ".", "config", ".", "get", "(", "'random_flip_inputs'", ",", "False", ")", "\n", "# Randomly flip inputs (titles, bodies) 50% of the time during training", "\n", "\n", "self", ".", "train_instances", "=", "defaultdict", "(", "lambda", ":", "list", "(", ")", ")", "\n", "self", ".", "train_instances_epoch_index", "=", "dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_with_negative_pools.BertTrainingPointwiseWithNegativePools.potentially_flip_inputs": [[39, 47], ["bool", "random.getrandbits"], "methods", ["None"], ["", "def", "potentially_flip_inputs", "(", "self", ",", "a", ",", "b", ")", ":", "\n", "        ", "if", "self", ".", "random_flip_inputs", ":", "\n", "            ", "if", "bool", "(", "random", ".", "getrandbits", "(", "1", ")", ")", ":", "\n", "                ", "return", "a", ",", "b", "\n", "", "else", ":", "\n", "                ", "return", "b", ",", "a", "\n", "", "", "else", ":", "\n", "            ", "return", "a", ",", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_with_negative_pools.BertTrainingPointwiseWithNegativePools.get_loss": [[48, 67], ["model.bert.train", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.nn.BCELoss", "torch.nn.BCELoss.", "model.bert", "torch.tensor().to.view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "", "def", "get_loss", "(", "self", ",", "model", ",", "step_examples", ",", "tasks", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param model: BertWrapperModel\n        :param step_examples: list[InputExample]\n        :param tasks: list[str] or None of adapter name(s)\n        :return:\n        \"\"\"", "\n", "model", ".", "bert", ".", "train", "(", ")", "\n", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "step_examples", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "model", ".", "device", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "step_examples", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "model", ".", "device", ")", "\n", "segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "step_examples", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "\n", "model", ".", "device", ")", "\n", "label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "step_examples", "]", ",", "dtype", "=", "torch", ".", "float", ")", ".", "to", "(", "model", ".", "device", ")", "\n", "\n", "loss_fct", "=", "BCELoss", "(", ")", "\n", "step_loss", "=", "loss_fct", "(", "model", ".", "bert", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "tasks", "=", "tasks", ")", ",", "label_ids", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "\n", "return", "step_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_with_negative_pools.BertTrainingPointwiseWithNegativePools.prepare_training": [[68, 112], ["super().prepare_training", "enumerate", "min", "len", "math.ceil", "experiment.bert_utils.convert_examples_to_features", "len", "float", "training_bert_with_negative_pools.BertTrainingPointwiseWithNegativePools.potentially_flip_inputs", "dataset_examples.append", "list", "random.shuffle", "training_bert_with_negative_pools.BertTrainingPointwiseWithNegativePools.potentially_flip_inputs", "neg.append", "training_bert_with_negative_pools.BertTrainingPointwiseWithNegativePools.train_instances.values", "experiment.bert_utils.InputExample", "experiment.bert_utils.InputExample", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_batch_same_q.BertTrainingPointwiseAllQSameBatch.prepare_training", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.convert_examples_to_features", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_with_negative_pools.BertTrainingPointwiseWithNegativePools.potentially_flip_inputs", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_with_negative_pools.BertTrainingPointwiseWithNegativePools.potentially_flip_inputs"], ["", "def", "prepare_training", "(", "self", ",", "model", ",", "data", ")", ":", "\n", "        ", "super", "(", "BertTrainingPointwiseWithNegativePools", ",", "self", ")", ".", "prepare_training", "(", "model", ",", "data", ")", "\n", "\n", "# create features for all training examples", "\n", "for", "i", ",", "dataset", "in", "enumerate", "(", "data", ".", "datas_train", ")", ":", "\n", "            ", "dataset_examples", "=", "[", "]", "\n", "for", "pool", "in", "dataset", ".", "archive", ".", "train", ".", "qa", ":", "\n", "                ", "for", "a", "in", "pool", ".", "ground_truth", ":", "\n", "                    ", "input_a", ",", "input_b", "=", "self", ".", "potentially_flip_inputs", "(", "pool", ".", "question", ".", "text", ",", "a", ".", "text", ")", "\n", "dataset_examples", ".", "append", "(", "\n", "InputExample", "(", "pool", ".", "question", ".", "metadata", "[", "'id'", "]", ",", "input_a", ",", "input_b", ",", "label", "=", "1.0", ")", "\n", ")", "\n", "\n", "", "neg", "=", "[", "]", "\n", "\n", "pot_neg_answer_list", "=", "pool", ".", "pooled_answers", "\n", "if", "self", ".", "negative_sample_from_top_n", "is", "not", "False", ":", "\n", "                    ", "pot_neg_answer_list", "=", "list", "(", "pool", ".", "pooled_answers", "[", ":", "self", ".", "negative_sample_from_top_n", "]", ")", "\n", "random", ".", "shuffle", "(", "pot_neg_answer_list", ")", "\n", "\n", "", "for", "a", "in", "pot_neg_answer_list", ":", "\n", "                    ", "if", "a", "in", "pool", ".", "ground_truth", ":", "\n", "                        ", "continue", "\n", "\n", "", "input_a", ",", "input_b", "=", "self", ".", "potentially_flip_inputs", "(", "pool", ".", "question", ".", "text", ",", "a", ".", "text", ")", "\n", "neg", ".", "append", "(", "\n", "InputExample", "(", "pool", ".", "question", ".", "metadata", "[", "'id'", "]", ",", "input_a", ",", "input_b", ",", "label", "=", "0.0", ")", "\n", ")", "\n", "if", "len", "(", "neg", ")", ">=", "self", ".", "max_negative_per_answer", "*", "len", "(", "pool", ".", "ground_truth", ")", ":", "\n", "                        ", "break", "\n", "", "", "dataset_examples", "+=", "neg", "\n", "\n", "", "self", ".", "train_instances", "[", "i", "]", "=", "convert_examples_to_features", "(", "\n", "dataset_examples", ",", "self", ".", "length_question", "+", "self", ".", "length_answer", ",", "model", ".", "tokenizer", ",", "self", ".", "logger", "\n", ")", "\n", "\n", "# calculate number of batches", "\n", "", "min_examples", "=", "min", "(", "[", "len", "(", "v", ")", "for", "v", "in", "self", ".", "train_instances", ".", "values", "(", ")", "]", ")", "\n", "n_datasets", "=", "len", "(", "self", ".", "train_instances", ")", "\n", "if", "self", ".", "epoch_max_examples", "is", "None", "or", "min_examples", "*", "n_datasets", "<", "self", ".", "epoch_max_examples", ":", "\n", "            ", "examples_per_epoch", "=", "min_examples", "*", "n_datasets", "\n", "", "else", ":", "\n", "            ", "examples_per_epoch", "=", "self", ".", "epoch_max_examples", "\n", "", "self", ".", "n_batches", "=", "math", ".", "ceil", "(", "examples_per_epoch", "/", "float", "(", "self", ".", "batchsize", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_with_negative_pools.BertTrainingPointwiseWithNegativePools.prepare_next_epoch": [[113, 120], ["super().prepare_next_epoch", "training_bert_with_negative_pools.BertTrainingPointwiseWithNegativePools.train_instances.items", "random.shuffle"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_with_negative_pools.BertTrainingPointwiseWithNegativePools.prepare_next_epoch"], ["", "def", "prepare_next_epoch", "(", "self", ",", "model", ",", "data", ",", "epoch", ")", ":", "\n", "        ", "super", "(", "BertTrainingPointwiseWithNegativePools", ",", "self", ")", ".", "prepare_next_epoch", "(", "model", ",", "data", ",", "epoch", ")", "\n", "\n", "# we shuffle the train instances for each epoch so that there is no need to", "\n", "for", "dataset", ",", "instances", "in", "self", ".", "train_instances", ".", "items", "(", ")", ":", "\n", "            ", "random", ".", "shuffle", "(", "instances", ")", "\n", "self", ".", "train_instances_epoch_index", "[", "dataset", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_with_negative_pools.BertTrainingPointwiseWithNegativePools.get_n_batches": [[121, 123], ["None"], "methods", ["None"], ["", "", "def", "get_n_batches", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_batches", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_with_negative_pools.BertTrainingPointwiseWithNegativePools.get_next_batch": [[124, 138], ["len"], "methods", ["None"], ["", "def", "get_next_batch", "(", "self", ",", "model", ",", "data", ")", ":", "\n", "        ", "self", ".", "cur_dataset", "=", "(", "self", ".", "cur_dataset", "+", "1", ")", "%", "len", "(", "self", ".", "train_instances", ")", "\n", "\n", "# indices", "\n", "index_start", "=", "self", ".", "train_instances_epoch_index", "[", "self", ".", "cur_dataset", "]", "\n", "index_end", "=", "index_start", "+", "self", ".", "batchsize", "\n", "\n", "batch_examples", "=", "self", ".", "train_instances", "[", "self", ".", "cur_dataset", "]", "[", "index_start", ":", "index_end", "]", "\n", "\n", "# set the new dataset index and batch index", "\n", "self", ".", "train_instances_epoch_index", "[", "self", ".", "cur_dataset", "]", "=", "index_end", "\n", "self", ".", "batch_i", "+=", "1", "\n", "\n", "return", "batch_examples", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert.BertTrainingPointwise.__init__": [[12, 23], ["experiment.bert_utils.BertTraining.__init__"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"This does random sampling of negative answers. Optionally, if n_train_answers is set to a value greater than\n        one, this will sample for each question *n_train_answers* negative answers, which are ranked with the currently\n        trained model. The best-ranked answer is chosen as a negative sample.\n\n        :param args:\n        :param kwargs:\n        \"\"\"", "\n", "super", "(", "BertTrainingPointwise", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "cur_dataset", "=", "0", "\n", "self", ".", "n_batches", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert.BertTrainingPointwise.get_loss": [[24, 45], ["model.bert.train", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.nn.BCELoss", "torch.nn.BCELoss.", "model.bert", "torch.tensor().to.view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "get_loss", "(", "self", ",", "model", ",", "step_examples", ",", "tasks", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param model: BertWrapperModel\n        :param step_examples: list[InputExample]\n        :param tasks: list[str] or None of adapter name(s)\n        :return:\n        \"\"\"", "\n", "model", ".", "bert", ".", "train", "(", ")", "\n", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "step_examples", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "model", ".", "device", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "step_examples", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "model", ".", "device", ")", "\n", "segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "step_examples", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "\n", "model", ".", "device", ")", "\n", "label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "step_examples", "]", ",", "dtype", "=", "torch", ".", "float", ")", ".", "to", "(", "model", ".", "device", ")", "\n", "\n", "loss_fct", "=", "BCELoss", "(", ")", "\n", "step_loss", "=", "loss_fct", "(", "model", ".", "bert", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "tasks", "=", "tasks", ")", ",", "label_ids", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "# loss_fct = MSELoss()", "\n", "# step_loss = loss_fct(model.bert(input_ids, segment_ids, input_mask), label_ids.view(-1))", "\n", "\n", "return", "step_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert.BertTrainingPointwise.prepare_training": [[46, 73], ["super().prepare_training", "enumerate", "min", "len", "math.ceil", "training_bert.BertTrainingPointwise.logger.debug", "training_bert.BertTrainingPointwise.logger.debug", "experiment.bert_utils.convert_examples_to_features", "training_bert.BertTrainingPointwise.logger.debug", "len", "float", "training_bert.BertTrainingPointwise.train_questions[].append", "dataset_examples.append", "training_bert.BertTrainingPointwise.train_questions.values", "experiment.bert_utils.InputExample"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_batch_same_q.BertTrainingPointwiseAllQSameBatch.prepare_training", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.convert_examples_to_features"], ["", "def", "prepare_training", "(", "self", ",", "model", ",", "data", ")", ":", "\n", "        ", "super", "(", "BertTrainingPointwise", ",", "self", ")", ".", "prepare_training", "(", "model", ",", "data", ")", "\n", "\n", "# create features for all training examples", "\n", "for", "i", ",", "dataset", "in", "enumerate", "(", "data", ".", "datas_train", ")", ":", "\n", "            ", "self", ".", "logger", ".", "debug", "(", "'prepare training data for dataset {}'", ".", "format", "(", "dataset", ".", "archive", ".", "name", ")", ")", "\n", "dataset_examples", "=", "[", "]", "\n", "for", "pool", "in", "dataset", ".", "archive", ".", "train", ".", "qa", ":", "\n", "                ", "for", "gt", "in", "pool", ".", "ground_truth", ":", "\n", "                    ", "self", ".", "train_questions", "[", "i", "]", ".", "append", "(", "pool", ".", "question", ")", "\n", "dataset_examples", ".", "append", "(", "\n", "InputExample", "(", "pool", ".", "question", ".", "metadata", "[", "'id'", "]", ",", "pool", ".", "question", ".", "text", ",", "gt", ".", "text", ",", "label", "=", "1.0", ")", "\n", ")", "\n", "", "", "self", ".", "logger", ".", "debug", "(", "'convert_examples_to_features for dataset {}'", ".", "format", "(", "dataset", ".", "archive", ".", "name", ")", ")", "\n", "self", ".", "train_positive_instances", "[", "i", "]", "=", "convert_examples_to_features", "(", "\n", "dataset_examples", ",", "self", ".", "length_question", "+", "self", ".", "length_answer", ",", "model", ".", "tokenizer", ",", "self", ".", "logger", "\n", ")", "\n", "self", ".", "logger", ".", "debug", "(", "'done for dataset {}'", ".", "format", "(", "dataset", ".", "archive", ".", "name", ")", ")", "\n", "\n", "# calculate number of batches", "\n", "", "min_examples", "=", "min", "(", "[", "len", "(", "v", ")", "for", "v", "in", "self", ".", "train_questions", ".", "values", "(", ")", "]", ")", "\n", "n_datasets", "=", "len", "(", "self", ".", "train_questions", ")", "\n", "if", "self", ".", "epoch_max_examples", "is", "None", ":", "#or min_examples * 2 * n_datasets < self.epoch_max_examples:", "\n", "            ", "examples_per_epoch", "=", "min_examples", "*", "2", "*", "n_datasets", "\n", "", "else", ":", "\n", "            ", "examples_per_epoch", "=", "self", ".", "epoch_max_examples", "\n", "", "self", ".", "n_batches", "=", "math", ".", "ceil", "(", "examples_per_epoch", "/", "float", "(", "self", ".", "batchsize", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert.BertTrainingPointwise.get_n_batches": [[74, 76], ["None"], "methods", ["None"], ["", "def", "get_n_batches", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_batches", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert.BertTrainingPointwise.get_next_batch": [[77, 130], ["int", "training_bert.BertTrainingPointwise.get_batch_indices", "training_bert.BertTrainingPointwise.get_random_answers", "enumerate", "experiment.bert_utils.convert_examples_to_features", "len", "batch_examples.append", "model.bert.eval", "range", "enumerate", "len", "experiment.bert_utils.InputExample", "int", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "batch_examples.append", "math.ceil", "torch.no_grad", "model.bert", "model.bert.squeeze().tolist", "torch.tensor", "torch.tensor", "torch.tensor", "len", "float", "model.bert.squeeze", "numpy.argmax"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_with_negative_pools_batch_same_q.BertTrainingPointwiseWithNegativePoolsAllQSameBatch.get_batch_indices", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.BertTraining.get_random_answers", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.convert_examples_to_features"], ["", "def", "get_next_batch", "(", "self", ",", "model", ",", "data", ")", ":", "\n", "        ", "self", ".", "cur_dataset", "=", "(", "self", ".", "cur_dataset", "+", "1", ")", "%", "len", "(", "self", ".", "train_questions", ")", "\n", "batchsize_half", "=", "int", "(", "self", ".", "batchsize", "/", "2", ")", "\n", "indices", "=", "self", ".", "get_batch_indices", "(", "self", ".", "cur_dataset", ",", "batchsize_half", ")", "\n", "\n", "batch_examples", "=", "[", "]", "\n", "prediction_examples", "=", "[", "]", "\n", "\n", "unrelated_answers_all_qs", "=", "self", ".", "get_random_answers", "(", "self", ".", "cur_dataset", ",", "self", ".", "n_train_answers", "*", "len", "(", "indices", ")", ")", "\n", "for", "idx", ",", "example_i", "in", "enumerate", "(", "indices", ")", ":", "\n", "            ", "batch_examples", ".", "append", "(", "self", ".", "train_positive_instances", "[", "self", ".", "cur_dataset", "]", "[", "example_i", "]", ")", "\n", "\n", "unrelated_answers", "=", "unrelated_answers_all_qs", "[", "idx", "*", "self", ".", "n_train_answers", ":", "(", "idx", "+", "1", ")", "*", "self", ".", "n_train_answers", "]", "\n", "prediction_examples", "+=", "[", "\n", "InputExample", "(", "self", ".", "train_questions", "[", "self", ".", "cur_dataset", "]", "[", "example_i", "]", ".", "metadata", "[", "'id'", "]", ",", "\n", "self", ".", "train_questions", "[", "self", ".", "cur_dataset", "]", "[", "example_i", "]", ".", "text", ",", "\n", "a", ".", "text", ",", "label", "=", "0.0", ")", "\n", "for", "a", "in", "unrelated_answers", "\n", "]", "\n", "\n", "", "prediction_examples", "=", "convert_examples_to_features", "(", "\n", "prediction_examples", ",", "self", ".", "length_question", "+", "self", ".", "length_answer", ",", "model", ".", "tokenizer", ",", "self", ".", "logger", ",", "\n", "show_example", "=", "False", "\n", ")", "\n", "\n", "# we only execute all this negative sampling using the network IF we choose between more than one neg. answer", "\n", "if", "self", ".", "n_train_answers", ">", "1", ":", "\n", "            ", "prediction_results", "=", "[", "]", "\n", "model", ".", "bert", ".", "eval", "(", ")", "\n", "for", "predict_batch", "in", "range", "(", "int", "(", "math", ".", "ceil", "(", "len", "(", "prediction_examples", ")", "/", "float", "(", "self", ".", "batchsize_neg_ranking", ")", ")", ")", ")", ":", "\n", "                ", "batch_start_idx", "=", "predict_batch", "*", "self", ".", "batchsize_neg_ranking", "\n", "predict_batch_examples", "=", "prediction_examples", "[", "\n", "batch_start_idx", ":", "batch_start_idx", "+", "self", ".", "batchsize_neg_ranking", "]", "\n", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "predict_batch_examples", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "\n", "model", ".", "device", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "predict_batch_examples", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "\n", "model", ".", "device", ")", "\n", "segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "predict_batch_examples", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "\n", "model", ".", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "scores", "=", "model", ".", "bert", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "prediction_results", "+=", "scores", ".", "squeeze", "(", "dim", "=", "1", ")", ".", "tolist", "(", ")", "\n", "\n", "", "", "for", "count", ",", "example_i", "in", "enumerate", "(", "indices", ")", ":", "\n", "                ", "predictions", "=", "prediction_results", "[", "self", ".", "n_train_answers", "*", "count", ":", "self", ".", "n_train_answers", "*", "(", "count", "+", "1", ")", "]", "\n", "incorrect_example", "=", "prediction_examples", "[", "np", ".", "argmax", "(", "predictions", ")", "+", "self", ".", "n_train_answers", "*", "count", "]", "\n", "batch_examples", ".", "append", "(", "incorrect_example", ")", "\n", "", "", "else", ":", "\n", "            ", "batch_examples", "+=", "prediction_examples", "\n", "\n", "", "self", ".", "batch_i", "+=", "1", "\n", "return", "batch_examples", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_batch_same_q.BertTrainingPointwiseAllQSameBatch.__init__": [[12, 23], ["experiment.bert_utils.BertTraining.__init__"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"This does random sampling of negative answers. Optionally, if n_train_answers is set to a value greater than\n        one, this will sample for each question *n_train_answers* negative answers, which are ranked with the currently\n        trained model. The best-ranked answer is chosen as a negative sample.\n\n        :param args:\n        :param kwargs:\n        \"\"\"", "\n", "super", "(", "BertTrainingPointwiseAllQSameBatch", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "cur_dataset", "=", "0", "\n", "self", ".", "n_batches", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_batch_same_q.BertTrainingPointwiseAllQSameBatch.get_loss": [[24, 43], ["model.bert.train", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.nn.BCELoss", "torch.nn.BCELoss.", "model.bert", "torch.tensor().to.view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "get_loss", "(", "self", ",", "model", ",", "step_examples", ",", "tasks", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param model: BertWrapperModel\n        :param step_examples: list[InputExample]\n        :param tasks: list[str] or None of adapter name(s)\n        :return:\n        \"\"\"", "\n", "model", ".", "bert", ".", "train", "(", ")", "\n", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "step_examples", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "model", ".", "device", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "step_examples", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "model", ".", "device", ")", "\n", "segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "step_examples", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "\n", "model", ".", "device", ")", "\n", "label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "step_examples", "]", ",", "dtype", "=", "torch", ".", "float", ")", ".", "to", "(", "model", ".", "device", ")", "\n", "\n", "loss_fct", "=", "BCELoss", "(", ")", "\n", "step_loss", "=", "loss_fct", "(", "model", ".", "bert", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "tasks", "=", "tasks", ")", ",", "label_ids", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "\n", "return", "step_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_batch_same_q.BertTrainingPointwiseAllQSameBatch.prepare_training": [[44, 68], ["super().prepare_training", "enumerate", "min", "len", "experiment.bert_utils.convert_examples_to_features", "len", "training_bert_batch_same_q.BertTrainingPointwiseAllQSameBatch.train_questions[].append", "dataset_examples.append", "training_bert_batch_same_q.BertTrainingPointwiseAllQSameBatch.train_questions.values", "experiment.bert_utils.InputExample"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_batch_same_q.BertTrainingPointwiseAllQSameBatch.prepare_training", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.convert_examples_to_features"], ["", "def", "prepare_training", "(", "self", ",", "model", ",", "data", ")", ":", "\n", "        ", "super", "(", "BertTrainingPointwiseAllQSameBatch", ",", "self", ")", ".", "prepare_training", "(", "model", ",", "data", ")", "\n", "\n", "# create features for all training examples", "\n", "for", "i", ",", "dataset", "in", "enumerate", "(", "data", ".", "datas_train", ")", ":", "\n", "            ", "dataset_examples", "=", "[", "]", "\n", "for", "pool", "in", "dataset", ".", "archive", ".", "train", ".", "qa", ":", "\n", "                ", "for", "gt", "in", "pool", ".", "ground_truth", ":", "\n", "                    ", "self", ".", "train_questions", "[", "i", "]", ".", "append", "(", "pool", ".", "question", ")", "\n", "dataset_examples", ".", "append", "(", "\n", "InputExample", "(", "pool", ".", "question", ".", "metadata", "[", "'id'", "]", ",", "pool", ".", "question", ".", "text", ",", "gt", ".", "text", ",", "label", "=", "1.0", ")", "\n", ")", "\n", "", "", "self", ".", "train_positive_instances", "[", "i", "]", "=", "convert_examples_to_features", "(", "\n", "dataset_examples", ",", "self", ".", "length_question", "+", "self", ".", "length_answer", ",", "model", ".", "tokenizer", ",", "self", ".", "logger", "\n", ")", "\n", "\n", "# calculate number of batches", "\n", "", "min_examples", "=", "min", "(", "[", "len", "(", "v", ")", "for", "v", "in", "self", ".", "train_questions", ".", "values", "(", ")", "]", ")", "\n", "n_datasets", "=", "len", "(", "self", ".", "train_questions", ")", "\n", "if", "self", ".", "epoch_max_examples", "is", "None", "or", "min_examples", "*", "n_datasets", "<", "self", ".", "epoch_max_examples", ":", "\n", "            ", "examples_per_epoch", "=", "min_examples", "*", "n_datasets", "\n", "", "else", ":", "\n", "            ", "examples_per_epoch", "=", "self", ".", "epoch_max_examples", "\n", "", "self", ".", "n_batches", "=", "examples_per_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_batch_same_q.BertTrainingPointwiseAllQSameBatch.get_n_batches": [[69, 71], ["None"], "methods", ["None"], ["", "def", "get_n_batches", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_batches", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_batch_same_q.BertTrainingPointwiseAllQSameBatch.get_next_batch": [[72, 93], ["training_bert_batch_same_q.BertTrainingPointwiseAllQSameBatch.get_batch_indices", "len", "experiment.bert_utils.convert_examples_to_features", "experiment.bert_utils.InputExample", "training_bert_batch_same_q.BertTrainingPointwiseAllQSameBatch.get_random_answers"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.training_bert_with_negative_pools_batch_same_q.BertTrainingPointwiseWithNegativePoolsAllQSameBatch.get_batch_indices", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.convert_examples_to_features", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.BertTraining.get_random_answers"], ["", "def", "get_next_batch", "(", "self", ",", "model", ",", "data", ")", ":", "\n", "        ", "self", ".", "cur_dataset", "=", "(", "self", ".", "cur_dataset", "+", "1", ")", "%", "len", "(", "self", ".", "train_questions", ")", "\n", "n_positive", "=", "self", ".", "batchsize", "//", "self", ".", "n_train_answers", "\n", "example_index", "=", "self", ".", "get_batch_indices", "(", "self", ".", "cur_dataset", ",", "n_positive", ")", "\n", "\n", "batch_examples", "=", "[", "]", "\n", "for", "i", "in", "example_index", ":", "\n", "            ", "unrelated_answers", "=", "[", "\n", "InputExample", "(", "self", ".", "train_questions", "[", "self", ".", "cur_dataset", "]", "[", "i", "]", ".", "metadata", "[", "'id'", "]", ",", "\n", "self", ".", "train_questions", "[", "self", ".", "cur_dataset", "]", "[", "i", "]", ".", "text", ",", "\n", "a", ".", "text", ",", "label", "=", "0.0", ")", "\n", "for", "a", "in", "self", ".", "get_random_answers", "(", "self", ".", "cur_dataset", ",", "self", ".", "n_train_answers", "-", "1", ")", "\n", "]", "\n", "unrelated_answers_features", "=", "convert_examples_to_features", "(", "\n", "unrelated_answers", ",", "self", ".", "length_question", "+", "self", ".", "length_answer", ",", "model", ".", "tokenizer", ",", "self", ".", "logger", ",", "\n", "show_example", "=", "False", "\n", ")", "\n", "batch_examples", "+=", "[", "self", ".", "train_positive_instances", "[", "self", ".", "cur_dataset", "]", "[", "i", "]", "]", "+", "unrelated_answers_features", "\n", "\n", "", "self", ".", "batch_i", "+=", "n_positive", "\n", "return", "batch_examples", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.no_training.NoTraining.__init__": [[9, 11], ["experiment.Training.__init__"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "config_global", ",", "logger", ")", ":", "\n", "        ", "super", "(", "NoTraining", ",", "self", ")", ".", "__init__", "(", "config", ",", "config_global", ",", "logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.no_training.NoTraining.start": [[12, 14], ["no_training.NoTraining.logger.info"], "methods", ["None"], ["", "def", "start", "(", "self", ",", "model", ",", "data", ",", "evaluation", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "\"Skipping training\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.no_training.NoTraining.restore_best_epoch": [[15, 17], ["None"], "methods", ["None"], ["", "def", "restore_best_epoch", "(", "self", ",", "model", ",", "data", ",", "evaluation", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.train.no_training.NoTraining.remove_checkpoints": [[18, 20], ["None"], "methods", ["None"], ["", "def", "remove_checkpoints", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_bert.QAEvaluationPointwise.__init__": [[11, 17], ["experiment.qa.evaluation.BasicQAEvaluation.__init__", "dict"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "config_global", ",", "logger", ")", ":", "\n", "        ", "super", "(", "QAEvaluationPointwise", ",", "self", ")", ".", "__init__", "(", "config", ",", "config_global", ",", "logger", ")", "\n", "self", ".", "length_question", "=", "self", ".", "config_global", "[", "'question_length'", "]", "\n", "self", ".", "length_answer", "=", "self", ".", "config_global", "[", "'answer_length'", "]", "\n", "\n", "self", ".", "_cache", "=", "dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_bert.QAEvaluationPointwise.start": [[18, 21], ["model.bert.eval", "super().start"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_use.QAEvaluationUSE.start"], ["", "def", "start", "(", "self", ",", "model", ",", "data", ",", "valid_only", "=", "False", ")", ":", "\n", "        ", "model", ".", "bert", ".", "eval", "(", ")", "\n", "return", "super", "(", "QAEvaluationPointwise", ",", "self", ")", ".", "start", "(", "model", ",", "data", ",", "valid_only", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_bert.QAEvaluationPointwise.score": [[22, 54], ["torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "evaluation_bert.QAEvaluationPointwise._cache.get", "input_ids_lst.append", "input_mask_lst.append", "segment_ids_lst.append", "label_ids_lst.append", "torch.no_grad", "model.bert", "model.bert.squeeze().cpu().numpy", "id", "id", "experiment.bert_utils.InputExample", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "experiment.bert_utils.convert_examples_to_features", "model.bert.squeeze().cpu", "model.bert.squeeze"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.convert_examples_to_features"], ["", "def", "score", "(", "self", ",", "qa_pairs", ",", "model", ",", "data", ",", "task", "=", "None", ")", ":", "\n", "        ", "input_ids_lst", "=", "[", "]", "\n", "input_mask_lst", "=", "[", "]", "\n", "segment_ids_lst", "=", "[", "]", "\n", "label_ids_lst", "=", "[", "]", "\n", "\n", "for", "(", "q", ",", "a", ",", "label", ")", "in", "qa_pairs", ":", "\n", "            ", "cache_id", "=", "'{}-{}'", ".", "format", "(", "id", "(", "q", ")", ",", "id", "(", "a", ")", ")", "\n", "example_features", "=", "self", ".", "_cache", ".", "get", "(", "cache_id", ")", "\n", "\n", "if", "example_features", "is", "None", ":", "\n", "                ", "example", "=", "InputExample", "(", "q", ".", "metadata", "[", "'id'", "]", ",", "q", ".", "text", ",", "a", ".", "text", ",", "label", "=", "label", ")", "\n", "example_features", "=", "convert_examples_to_features", "(", "[", "example", "]", ",", "self", ".", "length_question", "+", "self", ".", "length_answer", ",", "\n", "model", ".", "tokenizer", ",", "self", ".", "logger", ")", "[", "0", "]", "\n", "self", ".", "_cache", "[", "cache_id", "]", "=", "example_features", "\n", "\n", "", "input_ids_lst", ".", "append", "(", "example_features", ".", "input_ids", ")", "\n", "input_mask_lst", ".", "append", "(", "example_features", ".", "input_mask", ")", "\n", "segment_ids_lst", ".", "append", "(", "example_features", ".", "segment_ids", ")", "\n", "label_ids_lst", ".", "append", "(", "example_features", ".", "label_id", ")", "\n", "\n", "", "input_ids", "=", "torch", ".", "tensor", "(", "input_ids_lst", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "model", ".", "device", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "input_mask_lst", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "model", ".", "device", ")", "\n", "segment_ids", "=", "torch", ".", "tensor", "(", "segment_ids_lst", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "model", ".", "device", ")", "\n", "label_ids", "=", "torch", ".", "tensor", "(", "label_ids_lst", ",", "dtype", "=", "torch", ".", "float", ")", ".", "to", "(", "model", ".", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "scores", "=", "model", ".", "bert", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "label_ids", ",", "tasks", "=", "task", ")", "\n", "# loss_fct = nn.BCELoss()", "\n", "# loss = loss_fct(scores, label_ids.view(-1, 1))", "\n", "\n", "", "return", "scores", ".", "squeeze", "(", "dim", "=", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "None", "# loss.cpu().numpy()", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.semeval_search_engine_rank.QAEvaluationSemEvalSearchEngineRank.__init__": [[11, 13], ["experiment.qa.evaluation.BasicQAEvaluation.__init__"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "config_global", ",", "logger", ")", ":", "\n", "        ", "super", "(", "QAEvaluationSemEvalSearchEngineRank", ",", "self", ")", ".", "__init__", "(", "config", ",", "config_global", ",", "logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.semeval_search_engine_rank.QAEvaluationSemEvalSearchEngineRank.score": [[14, 17], ["numpy.array", "numpy.zeros", "int"], "methods", ["None"], ["", "def", "score", "(", "self", ",", "qa_pairs", ",", "model", ",", "data", ",", "task", "=", "None", ")", ":", "\n", "        ", "scores", "=", "[", "-", "int", "(", "a", ".", "metadata", "[", "'search_engine_rank'", "]", ")", "for", "(", "_", ",", "a", ",", "_", ")", "in", "qa_pairs", "]", "\n", "return", "np", ".", "array", "(", "scores", ")", ",", "np", ".", "zeros", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.__init__.BasicQAEvaluation.__init__": [[19, 27], ["experiment.Evaluation.__init__", "__init__.BasicQAEvaluation.config.get", "__init__.BasicQAEvaluation.config.get", "__init__.BasicQAEvaluation.config.get", "__init__.BasicQAEvaluation.config.get", "__init__.BasicQAEvaluation.config.get", "__init__.BasicQAEvaluation.config.get"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.__init__.BasicQAEvaluation.start": [[28, 172], ["dict", "collections.defaultdict", "results_all[].items", "__init__.BasicQAEvaluation.logger.info", "__init__.BasicQAEvaluation._log_results", "open", "pickle.load", "zip", "numpy.concatenate", "collections.defaultdict", "isinstance", "experiment.util.flatten", "__init__.BasicQAEvaluation.logger.info", "len", "dataset_split_results.items", "__init__.BasicQAEvaluation.logger.info", "__init__.BasicQAEvaluation.logger.info", "__init__.BasicQAEvaluation._log_results", "numpy.mean", "os.path.join", "config.get", "int", "__init__.BasicQAEvaluation.create_progress_bar", "__init__.BasicQAEvaluation.", "progressbar.progressbar.progressbar", "len", "sorted", "enumerate", "p5.append", "ranks.append", "average_precisions.append", "numpy.mean", "numpy.mean", "numpy.mean", "[].append", "collections.OrderedDict", "__init__.BasicQAEvaluation.logger.info", "numpy.linalg.norm", "list", "math.ceil", "range", "__init__.BasicQAEvaluation.score", "result[].tolist", "__init__.BasicQAEvaluation._get_mean_adapter", "int", "range", "__init__.BasicQAEvaluation.logger.debug", "__init__.BasicQAEvaluation.logger.debug", "zip", "numpy.mean", "__init__.BasicQAEvaluation.logger.warn", "precisions.append", "numpy.mean", "__init__.BasicQAEvaluation.logger.debug", "float", "sorted", "len", "math.ceil", "__init__.BasicQAEvaluation.score", "result[].tolist", "pool_gold_labels.append", "precisions.append", "pool_gold_labels.append", "p5_components.append", "len", "collections.OrderedDict.items", "len", "float", "len", "__init__.BasicQAEvaluation.logger.debug", "__init__.BasicQAEvaluation.logger.debug", "zip", "zip", "itertools.product", "len", "float", "float", "float", "len"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.__init__.BasicQAEvaluation._log_results", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.load", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.util.flatten", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.__init__.BasicQAEvaluation._log_results", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.ComponentBase.create_progress_bar", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_use.QAEvaluationUSE.score", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.__init__.BasicQAEvaluation._get_mean_adapter", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_use.QAEvaluationUSE.score"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.__init__.BasicQAEvaluation.prepare_data": [[173, 175], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.__init__.BasicQAEvaluation.score": [[176, 178], ["NotImplementedError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.__init__.BasicQAEvaluation._log_results": [[179, 185], ["__init__.BasicQAEvaluation.logger.info", "__init__.BasicQAEvaluation.logger.info", "__init__.BasicQAEvaluation.logger.info", "__init__.BasicQAEvaluation.logger.info"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.__init__.BasicQAEvaluation._get_mean_adapter": [[186, 202], ["experiment.bert_utils.convert_examples_to_features", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "experiment.bert_utils.InputExample", "torch.no_grad", "model.bert.average_standard_bert_output().cpu().numpy", "numpy.squeeze", "torch.tensor", "torch.tensor", "torch.tensor", "numpy.dot", "numpy.argmin", "model.bert.average_standard_bert_output().cpu", "numpy.linalg.norm", "model.bert.average_standard_bert_output"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.bert_utils.convert_examples_to_features", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.model.bert_sigmoid.BertSigmoid.average_standard_bert_output"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_sbert.QAEvaluationSBert.__init__": [[11, 16], ["experiment.qa.evaluation.BasicQAEvaluation.__init__", "sentence_transformers.SentenceTransformer"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "config_global", ",", "logger", ")", ":", "\n", "        ", "super", "(", "QAEvaluationSBert", ",", "self", ")", ".", "__init__", "(", "config", ",", "config_global", ",", "logger", ")", "\n", "os", ".", "environ", "[", "'TORCH_HOME'", "]", "=", "config", "[", "\"sbert\"", "]", "[", "\"cache_dir\"", "]", "\n", "self", ".", "model", "=", "SentenceTransformer", "(", "config", "[", "\"sbert\"", "]", "[", "\"model\"", "]", ")", "\n", "self", ".", "batch_size", "=", "config", "[", "\"batchsize\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_sbert.QAEvaluationSBert.start": [[17, 19], ["super().start"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_use.QAEvaluationUSE.start"], ["", "def", "start", "(", "self", ",", "model", ",", "data", ",", "valid_only", "=", "False", ")", ":", "\n", "        ", "return", "super", "(", "QAEvaluationSBert", ",", "self", ")", ".", "start", "(", "model", ",", "data", ",", "valid_only", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_sbert.QAEvaluationSBert.score": [[20, 29], ["torch.from_numpy", "torch.from_numpy", "torch.cosine_similarity", "numpy.stack", "numpy.stack", "torch.cosine_similarity.cpu().numpy", "numpy.zeros", "evaluation_sbert.QAEvaluationSBert.model.encode", "evaluation_sbert.QAEvaluationSBert.model.encode", "torch.cosine_similarity.cpu"], "methods", ["None"], ["", "def", "score", "(", "self", ",", "qa_pairs", ",", "model", ",", "data", ",", "tasks", ")", ":", "\n", "        ", "query_examples", "=", "[", "q", ".", "text", "for", "(", "q", ",", "_", ",", "_", ")", "in", "qa_pairs", "]", "\n", "doc_examples", "=", "[", "a", ".", "text", "for", "(", "_", ",", "a", ",", "_", ")", "in", "qa_pairs", "]", "\n", "\n", "repr_queries", "=", "torch", ".", "from_numpy", "(", "np", ".", "stack", "(", "self", ".", "model", ".", "encode", "(", "query_examples", ",", "batch_size", "=", "self", ".", "batch_size", ",", "show_progress_bar", "=", "False", ")", ")", ")", "\n", "repr_docs", "=", "torch", ".", "from_numpy", "(", "np", ".", "stack", "(", "self", ".", "model", ".", "encode", "(", "doc_examples", ",", "batch_size", "=", "self", ".", "batch_size", ",", "show_progress_bar", "=", "False", ")", ")", ")", "\n", "scores", "=", "torch", ".", "cosine_similarity", "(", "repr_queries", ",", "repr_docs", ")", "\n", "\n", "return", "scores", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "np", ".", "zeros", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_use_qa.QAEvaluationUSEQA.__init__": [[10, 16], ["experiment.qa.evaluation.BasicQAEvaluation.__init__", "tensorflow_hub.load"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.load"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "config_global", ",", "logger", ")", ":", "\n", "        ", "super", "(", "QAEvaluationUSEQA", ",", "self", ")", ".", "__init__", "(", "config", ",", "config_global", ",", "logger", ")", "\n", "self", ".", "batch_size", "=", "config", "[", "\"batchsize\"", "]", "\n", "\n", "self", ".", "module", "=", "hub", ".", "load", "(", "'https://tfhub.dev/google/universal-sentence-encoder-qa/3'", ")", "\n", "self", ".", "i", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_use_qa.QAEvaluationUSEQA.start": [[17, 19], ["super().start"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_use.QAEvaluationUSE.start"], ["", "def", "start", "(", "self", ",", "model", ",", "data", ",", "valid_only", "=", "False", ")", ":", "\n", "        ", "return", "super", "(", "QAEvaluationUSEQA", ",", "self", ")", ".", "start", "(", "model", ",", "data", ",", "valid_only", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_use_qa.QAEvaluationUSEQA.get_reps": [[20, 29], ["[].numpy", "[].numpy", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant"], "methods", ["None"], ["", "def", "get_reps", "(", "self", ",", "qs", ",", "docs", ")", ":", "\n", "# encode the texts", "\n", "        ", "repr_queries", "=", "self", ".", "module", ".", "signatures", "[", "'question_encoder'", "]", "(", "tf", ".", "constant", "(", "qs", ")", ")", "[", "'outputs'", "]", ".", "numpy", "(", ")", "\n", "repr_docs", "=", "self", ".", "module", ".", "signatures", "[", "'response_encoder'", "]", "(", "\n", "input", "=", "tf", ".", "constant", "(", "docs", ")", ",", "\n", "context", "=", "tf", ".", "constant", "(", "docs", ")", "\n", ")", "[", "'outputs'", "]", ".", "numpy", "(", ")", "\n", "\n", "return", "repr_queries", ",", "repr_docs", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_use_qa.QAEvaluationUSEQA.score": [[30, 37], ["evaluation_use_qa.QAEvaluationUSEQA.get_reps", "numpy.zeros", "numpy.linalg.norm", "numpy.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_use_qa.QAEvaluationUSEQA.get_reps"], ["", "def", "score", "(", "self", ",", "qa_pairs", ",", "model", ",", "data", ",", "tasks", ")", ":", "\n", "        ", "query_examples", "=", "[", "q", ".", "text", "[", ":", "4096", "]", "for", "(", "q", ",", "_", ",", "_", ")", "in", "qa_pairs", "]", "\n", "doc_examples", "=", "[", "a", ".", "text", "[", ":", "4096", "]", "for", "(", "_", ",", "a", ",", "_", ")", "in", "qa_pairs", "]", "\n", "q_reps", ",", "d_reps", "=", "self", ".", "get_reps", "(", "query_examples", ",", "doc_examples", ")", "\n", "\n", "scores", "=", "(", "q_reps", "*", "d_reps", ")", ".", "sum", "(", "axis", "=", "1", ")", "/", "(", "norm", "(", "q_reps", ",", "axis", "=", "1", ")", "*", "norm", "(", "d_reps", ",", "axis", "=", "1", ")", ")", "\n", "return", "scores", ",", "np", ".", "zeros", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_use.QAEvaluationUSE.__init__": [[11, 15], ["experiment.qa.evaluation.BasicQAEvaluation.__init__", "config[].get"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "config_global", ",", "logger", ")", ":", "\n", "        ", "super", "(", "QAEvaluationUSE", ",", "self", ")", ".", "__init__", "(", "config", ",", "config_global", ",", "logger", ")", "\n", "self", ".", "module_url", "=", "config", "[", "\"use\"", "]", "[", "\"model\"", "]", "\n", "self", ".", "batch_size", "=", "config", "[", "\"use\"", "]", ".", "get", "(", "\"batchsize\"", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_use.QAEvaluationUSE.start": [[16, 18], ["super().start"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_use.QAEvaluationUSE.start"], ["", "def", "start", "(", "self", ",", "model", ",", "data", ",", "valid_only", "=", "False", ")", ":", "\n", "        ", "return", "super", "(", "QAEvaluationUSE", ",", "self", ")", ".", "start", "(", "model", ",", "data", ",", "valid_only", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.evaluation.evaluation_use.QAEvaluationUSE.score": [[19, 59], ["tensorflow.Graph", "tensorflow.Graph.finalize", "numpy.concatenate", "tensorflow.Graph.as_default", "tensorflow.placeholder", "tensorflow_hub.Module", "evaluation_use.QAEvaluationUSE.embed", "tensorflow.group", "tensorflow.compat.v1.Session", "session.run", "tqdm.trange", "session.run", "session.run", "numpy.stack", "numpy.stack", "numpy.concatenate.append", "numpy.zeros", "int", "session.run", "session.run", "numpy.stack", "numpy.stack", "numpy.concatenate.append", "tensorflow.global_variables_initializer", "tensorflow.tables_initializer", "len", "numpy.linalg.norm", "numpy.linalg.norm", "numpy.linalg.norm", "numpy.linalg.norm"], "methods", ["None"], ["", "def", "score", "(", "self", ",", "qa_pairs", ",", "model", ",", "data", ",", "tasks", ")", ":", "\n", "        ", "query_examples", "=", "[", "q", ".", "text", "for", "(", "q", ",", "_", ",", "_", ")", "in", "qa_pairs", "]", "\n", "doc_examples", "=", "[", "a", ".", "text", "for", "(", "_", ",", "a", ",", "_", ")", "in", "qa_pairs", "]", "\n", "\n", "g", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "g", ".", "as_default", "(", ")", ":", "\n", "            ", "text_input", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "string", ",", "shape", "=", "[", "None", "]", ")", "\n", "self", ".", "embed", "=", "hub", ".", "Module", "(", "self", ".", "module_url", ")", "\n", "embedded_text", "=", "self", ".", "embed", "(", "text_input", ")", "\n", "init_op", "=", "tf", ".", "group", "(", "[", "tf", ".", "global_variables_initializer", "(", ")", ",", "tf", ".", "tables_initializer", "(", ")", "]", ")", "\n", "", "g", ".", "finalize", "(", ")", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "Session", "(", "graph", "=", "g", ")", "as", "session", ":", "\n", "            ", "session", ".", "run", "(", "init_op", ")", "\n", "scores", "=", "[", "]", "\n", "last_idx", "=", "0", "\n", "for", "i", "in", "trange", "(", "1", ",", "int", "(", "len", "(", "query_examples", ")", "/", "self", ".", "batch_size", ")", ")", ":", "\n", "                ", "repr_queries", "=", "session", ".", "run", "(", "embedded_text", ",", "\n", "feed_dict", "=", "{", "text_input", ":", "query_examples", "[", "\n", "(", "i", "-", "1", ")", "*", "self", ".", "batch_size", ":", "i", "*", "self", ".", "batch_size", "]", "}", ")", "\n", "repr_docs", "=", "session", ".", "run", "(", "embedded_text", ",", "\n", "feed_dict", "=", "{", "\n", "text_input", ":", "doc_examples", "[", "(", "i", "-", "1", ")", "*", "self", ".", "batch_size", ":", "i", "*", "self", ".", "batch_size", "]", "}", ")", "\n", "last_idx", "=", "i", "*", "self", ".", "batch_size", "\n", "repr_queries", "=", "np", ".", "stack", "(", "repr_queries", ")", "\n", "repr_docs", "=", "np", ".", "stack", "(", "repr_docs", ")", "\n", "scores", ".", "append", "(", "\n", "(", "repr_queries", "*", "repr_docs", ")", ".", "sum", "(", "axis", "=", "1", ")", "/", "(", "norm", "(", "repr_queries", ",", "axis", "=", "1", ")", "*", "norm", "(", "repr_docs", ",", "axis", "=", "1", ")", ")", ")", "\n", "", "repr_queries", "=", "session", ".", "run", "(", "embedded_text", ",", "\n", "feed_dict", "=", "{", "text_input", ":", "query_examples", "[", "last_idx", ":", "]", "}", ")", "\n", "repr_docs", "=", "session", ".", "run", "(", "embedded_text", ",", "\n", "feed_dict", "=", "{", "text_input", ":", "doc_examples", "[", "last_idx", ":", "]", "}", ")", "\n", "repr_queries", "=", "np", ".", "stack", "(", "repr_queries", ")", "\n", "repr_docs", "=", "np", ".", "stack", "(", "repr_docs", ")", "\n", "\n", "scores", ".", "append", "(", "\n", "(", "repr_queries", "*", "repr_docs", ")", ".", "sum", "(", "axis", "=", "1", ")", "/", "(", "norm", "(", "repr_queries", ",", "axis", "=", "1", ")", "*", "norm", "(", "repr_docs", ",", "axis", "=", "1", ")", ")", ")", "\n", "\n", "", "scores", "=", "np", ".", "concatenate", "(", "scores", ")", "\n", "return", "scores", ",", "np", ".", "zeros", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.models.MetadataItem.__init__": [[5, 7], ["dict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "metadata", "=", "dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.models.TextItem.__init__": [[10, 17], ["models.MetadataItem.__init__"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"\n\n        :type text: str\n        \"\"\"", "\n", "super", "(", "TextItem", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "text", "=", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.models.QAPool.__init__": [[20, 30], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "question", ",", "pooled_answers", ",", "ground_truth", ")", ":", "\n", "        ", "\"\"\"\n\n        :type question: TextItem\n        :type pooled_answers: list[TextItem]\n        :type ground_truth: list[TextItem]\n        \"\"\"", "\n", "self", ".", "question", "=", "question", "\n", "self", ".", "pooled_answers", "=", "pooled_answers", "\n", "self", ".", "ground_truth", "=", "ground_truth", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.models.Data.__init__": [[33, 43], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "split_name", ",", "qa", ",", "answers", ")", ":", "\n", "        ", "\"\"\"\n\n        :type split_name: str\n        :type qa: list[QAPool]\n        :type answers: list[TextItem]\n        \"\"\"", "\n", "self", ".", "split_name", "=", "split_name", "\n", "self", ".", "qa", "=", "qa", "\n", "self", ".", "answers", "=", "answers", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.models.Data.combine": [[44, 49], ["models.Data"], "methods", ["None"], ["", "def", "combine", "(", "self", ",", "other_data", ")", ":", "\n", "        ", "split_name", "=", "self", ".", "split_name", "\n", "qa", "=", "self", ".", "qa", "+", "other_data", ".", "qa", "\n", "answers", "=", "self", ".", "answers", "+", "other_data", ".", "answers", "\n", "return", "Data", "(", "split_name", ",", "qa", ",", "answers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.models.Data.questions": [[50, 53], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "questions", "(", "self", ")", ":", "\n", "        ", "return", "[", "p", ".", "question", "for", "p", "in", "self", ".", "qa", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.models.Data.shrink": [[54, 67], ["experiment.util.unique_items", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.util.unique_items"], ["", "def", "shrink", "(", "self", ",", "max_size", ",", "offset", ")", ":", "\n", "        ", "start", "=", "(", "offset", "*", "max_size", ")", "%", "len", "(", "self", ".", "qa", ")", "\n", "end", "=", "(", "(", "offset", "+", "1", ")", "*", "max_size", ")", "%", "len", "(", "self", ".", "qa", ")", "\n", "\n", "new_qa", "=", "[", "]", "\n", "if", "start", ">", "end", ":", "\n", "            ", "new_qa", "+=", "self", ".", "qa", "[", "start", ":", "]", "\n", "start", "=", "0", "\n", "", "new_qa", "+=", "self", ".", "qa", "[", "start", ":", "end", "]", "\n", "self", ".", "qa", "=", "new_qa", "\n", "\n", "self", ".", "answers", "=", "unique_items", "(", "[", "a", "for", "sl", "in", "self", ".", "qa", "for", "a", "in", "\n", "(", "sl", ".", "pooled_answers", "if", "sl", ".", "pooled_answers", "is", "not", "None", "else", "sl", ".", "ground_truth", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.models.Archive.__init__": [[70, 88], ["dict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "train", ",", "valid", ",", "test", ",", "questions", ",", "answers", ",", "additional_answers", "=", "None", ",", "generated_questions", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        :type name: str\n        :type train: Data\n        :type valid: Data\n        :type test: list[Data]\n        :type questions: list[TexItem]\n        :type answers: list[TexItem]\n        \"\"\"", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "valid", "=", "valid", "\n", "self", ".", "test", "=", "test", "\n", "self", ".", "questions", "=", "questions", "\n", "self", ".", "answers", "=", "answers", "\n", "self", ".", "additional_answers", "=", "additional_answers", "or", "[", "]", "\n", "self", ".", "generated_questions", "=", "generated_questions", "or", "dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.models.Archive.combine": [[89, 106], ["models.Archive.train.combine", "models.Archive.valid.combine", "dict", "models.Archive", "list", "list", "models.Archive.generated_questions.items", "other_archive.generated_questions.items"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.models.Archive.combine", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.models.Archive.combine"], ["", "def", "combine", "(", "self", ",", "other_archive", ")", ":", "\n", "        ", "\"\"\"Creates a combined dataset and returns that\n\n        :param other_archive:\n        :return:\n        \"\"\"", "\n", "name", "=", "'{}+{}'", ".", "format", "(", "self", ".", "name", ",", "other_archive", ".", "name", ")", "\n", "train", "=", "self", ".", "train", ".", "combine", "(", "other_archive", ".", "train", ")", "\n", "valid", "=", "self", ".", "valid", ".", "combine", "(", "other_archive", ".", "valid", ")", "\n", "test", "=", "self", ".", "test", "+", "other_archive", ".", "test", "\n", "questions", "=", "self", ".", "questions", "+", "other_archive", ".", "questions", "\n", "answers", "=", "self", ".", "answers", "+", "other_archive", ".", "answers", "\n", "additional_answers", "=", "self", ".", "additional_answers", "+", "other_archive", ".", "additional_answers", "\n", "generated_questions", "=", "dict", "(", "\n", "list", "(", "self", ".", "generated_questions", ".", "items", "(", ")", ")", "+", "list", "(", "other_archive", ".", "generated_questions", ".", "items", "(", ")", ")", "\n", ")", "\n", "return", "Archive", "(", "name", ",", "train", ",", "valid", ",", "test", ",", "questions", ",", "answers", ",", "additional_answers", ",", "generated_questions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.models.Archive.shrink": [[107, 119], ["split.shrink", "experiment.util.unique_items"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.models.Archive.shrink", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.util.unique_items"], ["", "def", "shrink", "(", "self", ",", "split", ",", "max_len", ",", "offset", "=", "0", ")", ":", "\n", "        ", "\"\"\"Reduces the size of a split of the archive\n\n        :param split:\n        :param max_len:\n        :return:\n        \"\"\"", "\n", "split", "=", "{", "'train'", ":", "self", ".", "train", ",", "'valid'", ":", "self", ".", "valid", "}", "[", "split", "]", "\n", "split", ".", "shrink", "(", "max_len", ",", "offset", ")", "\n", "\n", "self", ".", "questions", "=", "self", ".", "train", ".", "questions", "+", "self", ".", "valid", ".", "questions", "+", "[", "q", "for", "t", "in", "self", ".", "test", "for", "q", "in", "t", ".", "questions", "]", "\n", "self", ".", "answers", "=", "unique_items", "(", "self", ".", "train", ".", "answers", "+", "self", ".", "valid", ".", "answers", "+", "[", "a", "for", "t", "in", "self", ".", "test", "for", "a", "in", "t", ".", "answers", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.__init__.QAData.__init__": [[8, 24], ["experiment.Data.__init__", "__init__.QAData.config.get", "__init__.QAData.config.get", "__init__.QAData.config.get", "__init__.QAData.config.get", "__init__.QAData.config.get"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.__init__.QAData._get_train_readers": [[25, 28], ["NotImplementedError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.__init__.QAData._get_transfer_readers": [[29, 32], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.__init__.QAData.setup": [[33, 94], ["__init__.QAData._get_train_readers", "__init__.QAData.logger.info", "__init__.QAData.logger.debug", "__init__.QAData.logger.debug", "__init__.QAData.logger.debug", "reader.read", "__init__.QAData.logger.info", "__init__.QAData.logger.info", "__init__.QAData.config.get", "min", "min", "__init__.QAData.logger.info", "__init__.QAData.archive.combine", "r.read", "__init__.QAData.logger.debug", "len", "archive.shrink", "print", "archive.shrink", "print", "archive.shrink", "archive.shrink", "len", "len", "numpy.mean", "numpy.mean", "__init__.QAData._get_transfer_readers", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuData._get_train_readers", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.models.Archive.combine", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.models.Archive.shrink", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.models.Archive.shrink", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.models.Archive.shrink", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.models.Archive.shrink", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.insuranceqa.tsv.TSVData._get_transfer_readers"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.reader.ArchiveReader.__init__": [[5, 9], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "archive_path", ",", "lowercased", ",", "logger", ")", ":", "\n", "        ", "self", ".", "archive_path", "=", "archive_path", "\n", "self", ".", "lowercased", "=", "lowercased", "\n", "self", ".", "logger", "=", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.reader.ArchiveReader.name": [[10, 13], ["reader.ArchiveReader.archive_path.split"], "methods", ["None"], ["", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "archive_path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.reader.ArchiveReader.read": [[14, 16], ["NotImplementedError"], "methods", ["None"], ["", "def", "read", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.reader.TSVArchiveReader.read_tsv": [[19, 40], ["gzip.open", "open", "open.close", "isinstance", "line.lower.lower.rstrip", "line.lower.lower.decode", "line.lower.lower.lower", "result.append", "line.lower.lower.split"], "methods", ["None"], ["    ", "def", "read_tsv", "(", "self", ",", "file_path", ",", "is_gzip", "=", "False", ")", ":", "\n", "        ", "result", "=", "[", "]", "\n", "\n", "if", "is_gzip", ":", "\n", "            ", "f", "=", "gzip", ".", "open", "(", "file_path", ",", "'r'", ")", "\n", "", "else", ":", "\n", "            ", "f", "=", "open", "(", "file_path", ",", "'r'", ")", "\n", "\n", "", "try", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "if", "isinstance", "(", "line", ",", "bytes", ")", ":", "\n", "                    ", "line", "=", "line", ".", "decode", "(", "\"utf-8\"", ")", "\n", "", "line", "=", "line", ".", "rstrip", "(", ")", "\n", "if", "self", ".", "lowercased", ":", "\n", "                    ", "line", "=", "line", ".", "lower", "(", ")", "\n", "", "if", "line", ":", "\n", "                    ", "result", ".", "append", "(", "line", ".", "split", "(", "'\\t'", ")", ")", "\n", "", "", "", "finally", ":", "\n", "            ", "f", ".", "close", "(", ")", "\n", "\n", "", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.semeval.reader17.SemEvalData17._get_train_readers": [[15, 17], ["reader17.SemEvalReader17"], "methods", ["None"], ["    ", "def", "_get_train_readers", "(", "self", ")", ":", "\n", "        ", "return", "[", "SemEvalReader17", "(", "self", ".", "config", "[", "'path'", "]", ",", "self", ".", "lowercased", ",", "self", ".", "logger", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.semeval.reader17.SemEvalReader17.read": [[20, 31], ["reader17.SemEvalReader17.read_split", "reader17.SemEvalReader17.read_split", "reader17.SemEvalReader17.read_split", "Archive"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split"], ["    ", "def", "read", "(", "self", ")", ":", "\n", "        ", "train", "=", "self", ".", "read_split", "(", "\"train\"", ",", "\n", "\"sem-eval-2016-v3.2/train/SemEval2016-Task3-CQA-QL-train-part1.xml\"", ",", "\n", "\"sem-eval-2016-v3.2/train/SemEval2016-Task3-CQA-QL-train-part2.xml\"", ")", "\n", "valid", "=", "self", ".", "read_split", "(", "\"dev\"", ",", "\n", "\"sem-eval-2016-v3.2/dev/SemEval2016-Task3-CQA-QL-dev.xml\"", ")", "\n", "test17", "=", "self", ".", "read_split", "(", "\"test-17\"", ",", "\n", "\"test/English/SemEval2017-task3-English-test.xml\"", ")", "\n", "\n", "all_items", "=", "train", ".", "questions", "+", "valid", ".", "questions", "\n", "return", "Archive", "(", "self", ".", "name", ",", "train", ",", "valid", ",", "[", "test17", "]", ",", "all_items", ",", "all_items", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.semeval.reader.SemEvalData._get_train_readers": [[14, 16], ["reader.SemEvalReader"], "methods", ["None"], ["", "def", "read", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.semeval.reader.SemEvalReader.file_path": [[19, 21], ["os.path.join"], "methods", ["None"], ["    ", "def", "read_tsv", "(", "self", ",", "file_path", ",", "is_gzip", "=", "False", ")", ":", "\n", "        ", "result", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.semeval.reader.SemEvalReader.read_xml": [[22, 52], ["dict", "collections.defaultdict", "bs4.BeautifulSoup.find_all", "open", "bs4.BeautifulSoup", "q.find", "pools[].append", "list", "reader.SemEvalReader.file_path", "f.read", "q.find", "q.find", "q.find.find", "q.find.find", "relq_text.lower.lower.lower", "q_text.lower.lower.lower"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.file_path", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read"], ["if", "is_gzip", ":", "\n", "            ", "f", "=", "gzip", ".", "open", "(", "file_path", ",", "'r'", ")", "\n", "", "else", ":", "\n", "            ", "f", "=", "open", "(", "file_path", ",", "'r'", ")", "\n", "\n", "", "try", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "if", "isinstance", "(", "line", ",", "bytes", ")", ":", "\n", "                    ", "line", "=", "line", ".", "decode", "(", "\"utf-8\"", ")", "\n", "", "line", "=", "line", ".", "rstrip", "(", ")", "\n", "if", "self", ".", "lowercased", ":", "\n", "                    ", "line", "=", "line", ".", "lower", "(", ")", "\n", "", "if", "line", ":", "\n", "                    ", "result", ".", "append", "(", "line", ".", "split", "(", "'\\t'", ")", ")", "\n", "", "", "", "finally", ":", "\n", "            ", "f", ".", "close", "(", ")", "\n", "\n", "", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.semeval.reader.SemEvalReader.read_split": [[53, 84], ["dict", "enumerate", "Data", "reader.SemEvalReader.read_xml", "questions.items", "list", "TextItem", "all_pools.append", "dict.values", "org_q_ids.append", "pooled_qs.append", "QAPool", "label.lower", "ground_truth.append"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.semeval.reader.SemEvalReader.read_xml"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.semeval.reader.SemEvalReader.read": [[85, 96], ["reader.SemEvalReader.read_split", "reader.SemEvalReader.read_split", "reader.SemEvalReader.read_split", "Archive"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.wikipassageqa.reader.WikiPassageQAReader.read_split": [[19, 39], ["experiment.qa.data.models.Data", "open", "next", "os.path.join", "l.strip().split", "experiment.qa.data.models.TextItem", "numpy.random.shuffle", "datapoints.append", "experiment.qa.data.models.QAPool", "l.strip", "question.lower", "answers.items", "k.startswith", "relevant_passages.split"], "methods", ["None"], ["    ", "def", "read_tsv", "(", "self", ",", "file_path", ",", "is_gzip", "=", "False", ")", ":", "\n", "        ", "result", "=", "[", "]", "\n", "\n", "if", "is_gzip", ":", "\n", "            ", "f", "=", "gzip", ".", "open", "(", "file_path", ",", "'r'", ")", "\n", "", "else", ":", "\n", "            ", "f", "=", "open", "(", "file_path", ",", "'r'", ")", "\n", "\n", "", "try", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "if", "isinstance", "(", "line", ",", "bytes", ")", ":", "\n", "                    ", "line", "=", "line", ".", "decode", "(", "\"utf-8\"", ")", "\n", "", "line", "=", "line", ".", "rstrip", "(", ")", "\n", "if", "self", ".", "lowercased", ":", "\n", "                    ", "line", "=", "line", ".", "lower", "(", ")", "\n", "", "if", "line", ":", "\n", "                    ", "result", ".", "append", "(", "line", ".", "split", "(", "'\\t'", ")", ")", "\n", "", "", "", "finally", ":", "\n", "            ", "f", ".", "close", "(", ")", "\n", "\n", "", "return", "result", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.wikipassageqa.reader.WikiPassageQAReader.read": [[40, 57], ["collections.OrderedDict", "reader.WikiPassageQAReader.read_split", "reader.WikiPassageQAReader.read_split", "reader.WikiPassageQAReader.read_split", "experiment.qa.data.models.Archive", "open", "json.loads().items", "os.path.join", "passages.items", "json.loads", "experiment.qa.data.models.TextItem", "f.read", "passage_text.lower"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read"], ["", "", ""]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.wikipassageqa.reader.WikiPassageQAData._get_train_readers": [[60, 62], ["reader.WikiPassageQAReader"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.wikipassageqa.reader._get_text_item": [[12, 16], ["experiment.qa.data.models.TextItem"], "function", ["None"], ["        ", "return", "self", ".", "archive_path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "\n", "", "def", "read", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.insuranceqa.tsv.TSVData._get_train_readers": [[6, 8], ["experiment.qa.data.insuranceqa.reader.tsv_reader.TSVReader", "tsv.TSVData.config.get"], "methods", ["None"], ["    ", "def", "_get_train_readers", "(", "self", ")", ":", "\n", "        ", "return", "[", "TSVReader", "(", "p", ",", "self", ".", "lowercased", ",", "self", ".", "logger", ",", "self", ".", "config", ".", "get", "(", "'create_random_pools'", ")", ")", "for", "p", "in", "self", ".", "config", "[", "'train_data'", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.insuranceqa.tsv.TSVData._get_transfer_readers": [[9, 11], ["experiment.qa.data.insuranceqa.reader.tsv_reader.TSVReader", "tsv.TSVData.config.get", "tsv.TSVData.config.get"], "methods", ["None"], ["", "def", "_get_transfer_readers", "(", "self", ")", ":", "\n", "        ", "return", "[", "TSVReader", "(", "p", ",", "self", ".", "lowercased", ",", "self", ".", "logger", ",", "self", ".", "config", ".", "get", "(", "'create_random_pools'", ")", ")", "for", "p", "in", "self", ".", "config", ".", "get", "(", "'transfer_test'", ",", "[", "]", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.insuranceqa.v2.V2Data._get_train_readers": [[6, 8], ["experiment.qa.data.insuranceqa.reader.v2_reader.V2Reader"], "methods", ["None"], ["    ", "def", "_get_train_readers", "(", "self", ")", ":", "\n", "        ", "return", "[", "V2Reader", "(", "self", ".", "config", "[", "'insuranceqa'", "]", ",", "self", ".", "lowercased", ",", "self", ".", "logger", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.insuranceqa.json.JSONData._get_train_readers": [[6, 8], ["experiment.qa.data.insuranceqa.reader.json_reader.JSONArchiveReader"], "methods", ["None"], ["    ", "def", "_get_train_readers", "(", "self", ")", ":", "\n", "        ", "return", "[", "JSONArchiveReader", "(", "self", ".", "config", "[", "'insuranceqa'", "]", ",", "self", ".", "lowercased", ",", "self", ".", "logger", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.insuranceqa.v1.V1Data._get_train_readers": [[6, 8], ["experiment.qa.data.insuranceqa.reader.v1_reader.V1Reader"], "methods", ["None"], ["    ", "def", "_get_train_readers", "(", "self", ")", ":", "\n", "        ", "return", "[", "V1Reader", "(", "self", ".", "config", "[", "'insuranceqa'", "]", ",", "self", ".", "lowercased", ",", "self", ".", "logger", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.reader.v2_reader.V2Reader.__init__": [[9, 13], ["experiment.qa.data.reader.TSVArchiveReader.__init__"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "archive_path", ",", "lowercased", ",", "logger", ",", "pooled_answers", "=", "500", ",", "tokenizer", "=", "'raw'", ")", ":", "\n", "        ", "super", "(", "V2Reader", ",", "self", ")", ".", "__init__", "(", "archive_path", ",", "lowercased", ",", "logger", ")", "\n", "self", ".", "pooled_answers", "=", "pooled_answers", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.reader.v2_reader.V2Reader.file_path": [[14, 16], ["None"], "methods", ["None"], ["", "def", "file_path", "(", "self", ",", "filename", ")", ":", "\n", "        ", "return", "'{}/V2/{}'", ".", "format", "(", "self", ".", "archive_path", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.reader.v2_reader.V2Reader.read_split": [[17, 49], ["enumerate", "len", "len", "v2_reader.V2Reader.logger.info", "Data", "v2_reader.V2Reader.read_tsv", "TextItem", "datapoints.append", "v2_reader.V2Reader.file_path", "QAPool", "line[].split", "line[].split", "len", "line[].split"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.reader.TSVArchiveReader.read_tsv", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.file_path"], ["", "def", "read_split", "(", "self", ",", "name", ",", "vocab", ",", "answers", ")", ":", "\n", "        ", "filename", "=", "'InsuranceQA.question.anslabel.{}.{}.pool.solr.{}.encoded.gz'", ".", "format", "(", "\n", "self", ".", "tokenizer", ",", "self", ".", "pooled_answers", ",", "name", "\n", ")", "\n", "datapoints", "=", "[", "]", "\n", "split_answers", "=", "[", "]", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "self", ".", "read_tsv", "(", "self", ".", "file_path", "(", "filename", ")", ",", "is_gzip", "=", "True", ")", ")", ":", "\n", "            ", "question_tokens_text", "=", "' '", ".", "join", "(", "[", "vocab", "[", "t", "]", "for", "t", "in", "line", "[", "1", "]", ".", "split", "(", ")", "]", ")", "\n", "question", "=", "TextItem", "(", "question_tokens_text", ")", "\n", "question", ".", "metadata", "[", "'id'", "]", "=", "'{}-{}'", ".", "format", "(", "name", ",", "i", ")", "\n", "\n", "ground_truth", "=", "[", "answers", "[", "gt", "]", "for", "gt", "in", "line", "[", "2", "]", ".", "split", "(", "' '", ")", "]", "\n", "pool", "=", "[", "answers", "[", "pa", "]", "for", "pa", "in", "line", "[", "3", "]", ".", "split", "(", "' '", ")", "]", "\n", "\n", "# don't shuffle the pool as it would lead to near-random selection of negative examples during training when", "\n", "# using examples from the pool (since the pool is so large)", "\n", "# np.random.shuffle(pool)", "\n", "\n", "datapoints", ".", "append", "(", "QAPool", "(", "question", ",", "pool", ",", "ground_truth", ")", ")", "\n", "\n", "split_answers", "+=", "pool", "\n", "\n", "# if name != 'train':", "\n", "# we filter out all pools that do not contain any ground truth answer", "\n", "", "qa_pools_len_before", "=", "len", "(", "datapoints", ")", "\n", "datapoints", "=", "[", "p", "for", "p", "in", "datapoints", "if", "len", "(", "[", "1", "for", "gt", "in", "p", ".", "ground_truth", "if", "gt", "in", "p", ".", "pooled_answers", "]", ")", ">", "0", "]", "\n", "qa_pools_len_after", "=", "len", "(", "datapoints", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Split {} reduced to {} item from {} due to missing ground truth in pool\"", ".", "format", "(", "\n", "name", ",", "qa_pools_len_after", ",", "qa_pools_len_before", "\n", ")", ")", "\n", "\n", "return", "Data", "(", "'insuranceqa-v2 / {}'", ".", "format", "(", "name", ")", ",", "datapoints", ",", "split_answers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.reader.v2_reader.V2Reader.read": [[50, 68], ["dict", "dict", "v2_reader.V2Reader.read_tsv", "v2_reader.V2Reader.read_split", "v2_reader.V2Reader.read_split", "v2_reader.V2Reader.read_split", "Archive", "v2_reader.V2Reader.read_tsv", "v2_reader.V2Reader.file_path", "TextItem", "list", "v2_reader.V2Reader.file_path", "dict.values", "line[].split"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.reader.TSVArchiveReader.read_tsv", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.reader.TSVArchiveReader.read_tsv", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.file_path", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.file_path"], ["", "def", "read", "(", "self", ")", ":", "\n", "        ", "vocab", "=", "dict", "(", "self", ".", "read_tsv", "(", "self", ".", "file_path", "(", "'vocabulary'", ")", ")", ")", "\n", "answers_path", "=", "'InsuranceQA.label2answer.{}.encoded.gz'", ".", "format", "(", "self", ".", "tokenizer", ")", "\n", "answers", "=", "dict", "(", ")", "\n", "for", "line", "in", "self", ".", "read_tsv", "(", "self", ".", "file_path", "(", "answers_path", ")", ",", "is_gzip", "=", "True", ")", ":", "\n", "            ", "id", "=", "line", "[", "0", "]", "\n", "tokens_text", "=", "' '", ".", "join", "(", "[", "vocab", "[", "t", "]", "for", "t", "in", "line", "[", "1", "]", ".", "split", "(", "' '", ")", "]", ")", "\n", "answer", "=", "TextItem", "(", "tokens_text", ")", "\n", "answer", ".", "metadata", "[", "'id'", "]", "=", "id", "\n", "answers", "[", "id", "]", "=", "answer", "\n", "\n", "", "train", "=", "self", ".", "read_split", "(", "\"train\"", ",", "vocab", ",", "answers", ")", "\n", "valid", "=", "self", ".", "read_split", "(", "\"valid\"", ",", "vocab", ",", "answers", ")", "\n", "test", "=", "self", ".", "read_split", "(", "\"test\"", ",", "vocab", ",", "answers", ")", "\n", "\n", "questions", "=", "[", "qa", ".", "question", "for", "qa", "in", "(", "train", ".", "qa", "+", "valid", ".", "qa", "+", "test", ".", "qa", ")", "]", "\n", "\n", "return", "Archive", "(", "self", ".", "name", ",", "train", ",", "valid", ",", "[", "test", "]", ",", "questions", ",", "list", "(", "answers", ".", "values", "(", ")", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.reader.tsv_reader.TSVReader.__init__": [[12, 15], ["experiment.qa.data.reader.TSVArchiveReader.__init__"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "archive_path", ",", "lowercased", ",", "logger", ",", "create_random_pools", ")", ":", "\n", "        ", "super", "(", "TSVReader", ",", "self", ")", ".", "__init__", "(", "archive_path", ",", "lowercased", ",", "logger", ")", "\n", "self", ".", "create_random_pools", "=", "create_random_pools", "\n", "# if set to true, will generate random pools for the train split", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.reader.tsv_reader.TSVReader.file_path": [[17, 19], ["os.path.join"], "methods", ["None"], ["", "def", "file_path", "(", "self", ",", "filename", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "archive_path", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.reader.tsv_reader.TSVReader.read_items": [[20, 32], ["tsv_reader.TSVReader.file_path", "dict", "tsv_reader.TSVReader.read_tsv", "TextItem", "len", "text_ids.split"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.file_path", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.reader.TSVArchiveReader.read_tsv"], ["", "def", "read_items", "(", "self", ",", "name", ",", "vocab", ")", ":", "\n", "        ", "items_path", "=", "self", ".", "file_path", "(", "'{}.tsv.gz'", ".", "format", "(", "name", ")", ")", "\n", "items", "=", "dict", "(", ")", "\n", "for", "line", "in", "self", ".", "read_tsv", "(", "items_path", ",", "is_gzip", "=", "True", ")", ":", "\n", "            ", "id", "=", "line", "[", "0", "]", "\n", "text_ids", "=", "line", "[", "1", "]", "if", "len", "(", "line", ")", ">", "1", "else", "''", "\n", "tokens_text", "=", "' '", ".", "join", "(", "[", "vocab", "[", "t", "]", "for", "t", "in", "text_ids", ".", "split", "(", ")", "]", ")", "\n", "answer", "=", "TextItem", "(", "tokens_text", ")", "\n", "answer", ".", "metadata", "[", "'id'", "]", "=", "id", "\n", "items", "[", "id", "]", "=", "answer", "\n", "\n", "", "return", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.reader.tsv_reader.TSVReader.read_split": [[33, 63], ["tsv_reader.TSVReader.file_path", "enumerate", "Data", "tsv_reader.TSVReader.read_tsv", "datapoints.append", "len", "len", "tsv_reader.TSVReader.logger.info", "numpy.random.shuffle", "QAPool", "os.path.basename", "line[].split", "len", "line[].split", "len"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.file_path", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.reader.TSVArchiveReader.read_tsv"], ["", "def", "read_split", "(", "self", ",", "name", ",", "questions", ",", "answers", ")", ":", "\n", "        ", "split_path", "=", "self", ".", "file_path", "(", "'{}.tsv.gz'", ".", "format", "(", "name", ")", ")", "\n", "datapoints", "=", "[", "]", "\n", "split_answers", "=", "[", "]", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "self", ".", "read_tsv", "(", "split_path", ",", "is_gzip", "=", "True", ")", ")", ":", "\n", "            ", "question", "=", "questions", "[", "line", "[", "0", "]", "]", "\n", "ground_truth", "=", "[", "answers", "[", "gt_id", "]", "for", "gt_id", "in", "line", "[", "1", "]", ".", "split", "(", ")", "]", "\n", "pool", "=", "[", "answers", "[", "pa_id", "]", "for", "pa_id", "in", "line", "[", "2", "]", ".", "split", "(", ")", "]", "if", "len", "(", "line", ")", ">", "2", "else", "None", "\n", "\n", "if", "pool", "is", "not", "None", ":", "\n", "                ", "np", ".", "random", ".", "shuffle", "(", "pool", ")", "\n", "\n", "", "datapoints", ".", "append", "(", "QAPool", "(", "question", ",", "pool", ",", "ground_truth", ")", ")", "\n", "\n", "if", "pool", "is", "not", "None", ":", "\n", "                ", "split_answers", "+=", "pool", "\n", "", "else", ":", "\n", "                ", "split_answers", "+=", "ground_truth", "\n", "\n", "# we filter out all pools that do not contain any ground truth answer", "\n", "", "", "if", "name", "!=", "'train'", ":", "\n", "# we filter out all pools that do not contain any ground truth answer", "\n", "            ", "qa_pools_len_before", "=", "len", "(", "datapoints", ")", "\n", "datapoints", "=", "[", "p", "for", "p", "in", "datapoints", "if", "len", "(", "[", "1", "for", "gt", "in", "p", ".", "ground_truth", "if", "gt", "in", "p", ".", "pooled_answers", "]", ")", ">", "0", "]", "\n", "qa_pools_len_after", "=", "len", "(", "datapoints", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Split {} reduced to {} item from {} due to missing ground truth in pool\"", ".", "format", "(", "\n", "name", ",", "qa_pools_len_after", ",", "qa_pools_len_before", "\n", ")", ")", "\n", "\n", "", "return", "Data", "(", "'tsv({}) / {}'", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "self", ".", "archive_path", ")", ",", "name", ")", ",", "datapoints", ",", "split_answers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.reader.tsv_reader.TSVReader.read": [[64, 93], ["dict", "tsv_reader.TSVReader.read_items", "tsv_reader.TSVReader.read_items", "tsv_reader.TSVReader.read_split", "tsv_reader.TSVReader.read_split", "tsv_reader.TSVReader.read_split", "Archive", "tsv_reader.TSVReader.read_tsv", "tsv_reader.TSVReader.read_items", "list", "tsv_reader.TSVReader.logger.info", "list", "list", "tsv_reader.TSVReader.file_path", "list.values", "tsv_reader.TSVReader.logger.info", "random.sample", "tsv_reader.TSVReader.values", "tsv_reader.TSVReader.values", "len"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.read_items", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.read_items", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.reader.TSVArchiveReader.read_tsv", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.read_items", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.file_path"], ["", "def", "read", "(", "self", ")", ":", "\n", "        ", "vocab_filename", "=", "'vocab.tsv.gz'", "\n", "vocab", "=", "dict", "(", "self", ".", "read_tsv", "(", "self", ".", "file_path", "(", "vocab_filename", ")", ",", "is_gzip", "=", "True", ")", ")", "\n", "\n", "answers", "=", "self", ".", "read_items", "(", "'answers'", ",", "vocab", ")", "\n", "\n", "q_filename", "=", "'questions'", "\n", "questions", "=", "self", ".", "read_items", "(", "q_filename", ",", "vocab", ")", "\n", "\n", "try", ":", "\n", "            ", "additional_answers", "=", "self", ".", "read_items", "(", "\"additional-answers\"", ",", "vocab", ")", "\n", "additional_answers", "=", "list", "(", "additional_answers", ".", "values", "(", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "'Read {} additional (unrelated) answers'", ".", "format", "(", "len", "(", "additional_answers", ")", ")", ")", "\n", "", "except", ":", "\n", "            ", "additional_answers", "=", "None", "\n", "self", ".", "logger", ".", "info", "(", "'No additional answers found for this dataset'", ")", "\n", "\n", "", "train", "=", "self", ".", "read_split", "(", "\"train\"", ",", "questions", ",", "answers", ")", "\n", "valid", "=", "self", ".", "read_split", "(", "\"valid\"", ",", "questions", ",", "answers", ")", "\n", "test", "=", "self", ".", "read_split", "(", "\"test\"", ",", "questions", ",", "answers", ")", "\n", "\n", "if", "self", ".", "create_random_pools", ":", "\n", "            ", "for", "qa", "in", "train", ".", "qa", ":", "\n", "                ", "qa", ".", "pooled_answers", "=", "random", ".", "sample", "(", "train", ".", "answers", ",", "100", ")", "\n", "\n", "", "", "return", "Archive", "(", "\n", "self", ".", "name", ",", "train", ",", "valid", ",", "[", "test", "]", ",", "\n", "list", "(", "questions", ".", "values", "(", ")", ")", ",", "list", "(", "answers", ".", "values", "(", ")", ")", ",", "\n", "additional_answers", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.reader.v1_reader.V1Reader.file_path": [[11, 13], ["None"], "methods", ["None"], ["    ", "def", "file_path", "(", "self", ",", "filename", ")", ":", "\n", "        ", "return", "'{}/V1/{}'", ".", "format", "(", "self", ".", "archive_path", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.reader.v1_reader.V1Reader.read_split": [[14, 40], ["list", "numpy.random.shuffle", "enumerate", "Data", "answers.values", "v1_reader.V1Reader.read_tsv", "TextItem", "datapoints.append", "list", "v1_reader.V1Reader.file_path", "numpy.random.shuffle", "Token", "QAPool", "answers.values", "ground_truth_line.split", "question_line.split", "pool_line.split"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.reader.TSVArchiveReader.read_tsv", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.file_path"], ["", "def", "read_split", "(", "self", ",", "name", ",", "vocab", ",", "answers", ")", ":", "\n", "        ", "train", "=", "name", "==", "'train'", "\n", "filename", "=", "'question.train.token_idx.label'", "if", "train", "else", "'question.{}.label.token_idx.pool'", ".", "format", "(", "name", ")", "\n", "datapoints", "=", "[", "]", "\n", "\n", "answers_list", "=", "list", "(", "answers", ".", "values", "(", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "answers_list", ")", "\n", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "self", ".", "read_tsv", "(", "self", ".", "file_path", "(", "filename", ")", ")", ")", ":", "\n", "            ", "question_line", "=", "line", "[", "0", "]", "if", "train", "else", "line", "[", "1", "]", "\n", "ground_truth_line", "=", "line", "[", "1", "]", "if", "train", "else", "line", "[", "0", "]", "\n", "pool_line", "=", "None", "if", "train", "else", "line", "[", "2", "]", "\n", "\n", "ground_truth", "=", "[", "answers", "[", "gt", "]", "for", "gt", "in", "ground_truth_line", ".", "split", "(", "' '", ")", "]", "\n", "if", "pool_line", ":", "\n", "                ", "pool", "=", "[", "answers", "[", "pa", "]", "for", "pa", "in", "pool_line", ".", "split", "(", "' '", ")", "]", "\n", "np", ".", "random", ".", "shuffle", "(", "pool", ")", "\n", "", "else", ":", "\n", "                ", "pool", "=", "[", "]", "\n", "\n", "", "question_tokens", "=", "[", "Token", "(", "vocab", "[", "t", "]", ")", "for", "t", "in", "question_line", ".", "split", "(", ")", "]", "\n", "question", "=", "TextItem", "(", "' '", ".", "join", "(", "[", "t", ".", "text", "for", "t", "in", "question_tokens", "]", ")", ",", "question_tokens", ")", "\n", "\n", "datapoints", ".", "append", "(", "QAPool", "(", "question", ",", "pool", ",", "ground_truth", ")", ")", "\n", "\n", "", "return", "Data", "(", "'insuranceqa-v1 / {}'", ".", "format", "(", "name", ")", ",", "datapoints", ",", "list", "(", "answers", ".", "values", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.reader.v1_reader.V1Reader.read": [[41, 59], ["dict", "collections.OrderedDict", "v1_reader.V1Reader.read_tsv", "v1_reader.V1Reader.read_split", "v1_reader.V1Reader.read_split", "v1_reader.V1Reader.read_split", "v1_reader.V1Reader.read_split", "Archive", "v1_reader.V1Reader.read_tsv", "v1_reader.V1Reader.file_path", "TextItem", "list", "v1_reader.V1Reader.file_path", "Token", "collections.OrderedDict.values", "line[].split"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.reader.TSVArchiveReader.read_tsv", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.reader.TSVArchiveReader.read_tsv", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.file_path", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.file_path"], ["", "def", "read", "(", "self", ")", ":", "\n", "        ", "vocab", "=", "dict", "(", "self", ".", "read_tsv", "(", "self", ".", "file_path", "(", "'vocabulary'", ")", ")", ")", "\n", "answers", "=", "OrderedDict", "(", ")", "\n", "for", "line", "in", "self", ".", "read_tsv", "(", "self", ".", "file_path", "(", "'answers.label.token_idx'", ")", ")", ":", "\n", "            ", "id", "=", "line", "[", "0", "]", "\n", "tokens", "=", "[", "Token", "(", "vocab", "[", "t", "]", ")", "for", "t", "in", "line", "[", "1", "]", ".", "split", "(", "' '", ")", "]", "\n", "answer", "=", "TextItem", "(", "' '", ".", "join", "(", "t", ".", "text", "for", "t", "in", "tokens", ")", ",", "tokens", ")", "\n", "answer", ".", "metadata", "[", "'id'", "]", "=", "id", "\n", "answers", "[", "id", "]", "=", "answer", "\n", "\n", "", "train", "=", "self", ".", "read_split", "(", "\"train\"", ",", "vocab", ",", "answers", ")", "\n", "valid", "=", "self", ".", "read_split", "(", "\"dev\"", ",", "vocab", ",", "answers", ")", "\n", "test1", "=", "self", ".", "read_split", "(", "\"test1\"", ",", "vocab", ",", "answers", ")", "\n", "test2", "=", "self", ".", "read_split", "(", "\"test2\"", ",", "vocab", ",", "answers", ")", "\n", "\n", "questions", "=", "[", "qa", ".", "question", "for", "qa", "in", "train", ".", "qa", "+", "valid", ".", "qa", "+", "test1", ".", "qa", "+", "test2", ".", "qa", "]", "\n", "\n", "return", "Archive", "(", "self", ".", "name", ",", "train", ",", "valid", ",", "[", "test1", ",", "test2", "]", ",", "questions", ",", "list", "(", "answers", ".", "values", "(", ")", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.stackexchange_questions.reader.SEQuestionsData._get_train_readers": [[15, 17], ["reader.SEQuestionsReader"], "methods", ["None"], ["        ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.stackexchange_questions.reader.SEQuestionsReader.__init__": [[20, 22], ["experiment.qa.data.reader.TSVArchiveReader.__init__"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["        ", "result", "=", "[", "]", "\n", "\n", "if", "is_gzip", ":", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.stackexchange_questions.reader.SEQuestionsReader.file_path": [[23, 25], ["os.path.join"], "methods", ["None"], ["            ", "f", "=", "gzip", ".", "open", "(", "file_path", ",", "'r'", ")", "\n", "", "else", ":", "\n", "            ", "f", "=", "open", "(", "file_path", ",", "'r'", ")", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.stackexchange_questions.reader.SEQuestionsReader.read_items": [[26, 59], ["reader.SEQuestionsReader.file_path", "dict", "reader.SEQuestionsReader.read_tsv", "unidecode.unidecode.unidecode", "experiment.qa.data.models.TextItem", "experiment.qa.data.models.TextItem", "len", "unidecode.unidecode.unidecode", "reader.SEQuestionsReader.logger.info", "unidecode.unidecode.unidecode().strip", "line[].split", "title.lower.lower.lower", "body.lower.lower.lower", "experiment.qa.data.models.TextItem", "len", "len", "answer.lower", "unidecode.unidecode.unidecode"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.file_path", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.reader.TSVArchiveReader.read_tsv"], ["\n", "", "try", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "if", "isinstance", "(", "line", ",", "bytes", ")", ":", "\n", "                    ", "line", "=", "line", ".", "decode", "(", "\"utf-8\"", ")", "\n", "", "line", "=", "line", ".", "rstrip", "(", ")", "\n", "if", "self", ".", "lowercased", ":", "\n", "                    ", "line", "=", "line", ".", "lower", "(", ")", "\n", "", "if", "line", ":", "\n", "                    ", "result", ".", "append", "(", "line", ".", "split", "(", "'\\t'", ")", ")", "\n", "", "", "", "finally", ":", "\n", "            ", "f", ".", "close", "(", ")", "\n", "\n", "", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.stackexchange_questions.reader.SEQuestionsReader.read_split": [[60, 108], ["reader.SEQuestionsReader.file_path", "reader.SEQuestionsReader.read_tsv", "experiment.qa.data.models.Data", "datapoints.append", "len", "len", "reader.SEQuestionsReader.logger.info", "experiment.util.unique_items", "questions.keys", "questions.get", "len", "experiment.qa.data.models.QAPool", "os.path.basename", "k.endswith", "k.endswith", "truth.append", "questions.get", "questions.get", "line[].split", "len", "truth.append", "random.sample"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.file_path", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.reader.TSVArchiveReader.read_tsv", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.util.unique_items"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.stackexchange_questions.reader.SEQuestionsReader.read": [[109, 120], ["reader.SEQuestionsReader.read_items", "reader.SEQuestionsReader.read_split", "reader.SEQuestionsReader.read_split", "os.path.exists", "experiment.qa.data.models.Archive", "reader.SEQuestionsReader.file_path", "list", "list", "reader.SEQuestionsReader.read_split", "reader.SEQuestionsReader.values", "reader.SEQuestionsReader.values"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.read_items", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.file_path", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split"], []], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuData._get_train_readers": [[13, 15], ["askubuntu.AskUbuntuReader"], "methods", ["None"], ["    ", "def", "_get_train_readers", "(", "self", ")", ":", "\n", "        ", "return", "[", "AskUbuntuReader", "(", "self", ".", "config", "[", "'askubuntu'", "]", ",", "self", ".", "lowercased", ",", "self", ".", "logger", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.file_path": [[18, 20], ["os.path.join"], "methods", ["None"], ["    ", "def", "file_path", "(", "self", ",", "filename", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "archive_path", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_items": [[21, 42], ["askubuntu.AskUbuntuReader.file_path", "dict", "askubuntu.AskUbuntuReader.read_tsv", "TextItem", "len", "askubuntu.AskUbuntuReader.logger.info", "unidecode.unidecode.unidecode", "len", "unidecode.unidecode.unidecode", "unidecode.unidecode.unidecode", "len"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.file_path", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.reader.TSVArchiveReader.read_tsv"], ["", "def", "read_items", "(", "self", ")", ":", "\n", "        ", "items_path", "=", "self", ".", "file_path", "(", "'text_tokenized.txt.gz'", ")", "\n", "items", "=", "dict", "(", ")", "\n", "for", "line", "in", "self", ".", "read_tsv", "(", "items_path", ",", "is_gzip", "=", "True", ")", ":", "\n", "            ", "id", "=", "line", "[", "0", "]", "\n", "if", "len", "(", "line", ")", "<", "2", ":", "\n", "                ", "self", ".", "logger", ".", "info", "(", "'Item without title! Adding empty string for id {}'", ".", "format", "(", "id", ")", ")", "\n", "text", "=", "' '", "\n", "", "else", ":", "\n", "                ", "text", "=", "unidecode", "(", "line", "[", "1", "]", ")", "\n", "# TODO make title-only / title+body configurable", "\n", "", "if", "len", "(", "line", ")", ">", "2", ":", "\n", "                ", "text", "+=", "' '", "+", "unidecode", "(", "line", "[", "2", "]", ")", "\n", "\n", "", "body", "=", "unidecode", "(", "line", "[", "2", "]", ")", "if", "len", "(", "line", ")", ">", "2", "else", "' '", "\n", "\n", "ti", "=", "TextItem", "(", "text", ")", "\n", "ti", ".", "metadata", "[", "'id'", "]", "=", "id", "\n", "ti", ".", "metadata", "[", "'body'", "]", "=", "body", "\n", "items", "[", "id", "]", "=", "ti", "\n", "", "return", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split": [[43, 66], ["askubuntu.AskUbuntuReader.file_path", "enumerate", "Data", "askubuntu.AskUbuntuReader.read_tsv", "numpy.random.shuffle", "datapoints.append", "len", "len", "askubuntu.AskUbuntuReader.logger.info", "experiment.util.unique_items", "QAPool", "line[].split", "line[].split", "len"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.file_path", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data.reader.TSVArchiveReader.read_tsv", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.util.unique_items"], ["", "def", "read_split", "(", "self", ",", "name", ",", "questions", ")", ":", "\n", "        ", "split_path", "=", "self", ".", "file_path", "(", "'{}.txt'", ".", "format", "(", "name", ")", ")", "\n", "datapoints", "=", "[", "]", "\n", "split_questions", "=", "[", "]", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "self", ".", "read_tsv", "(", "split_path", ",", "is_gzip", "=", "False", ")", ")", ":", "\n", "            ", "query_question", "=", "questions", "[", "line", "[", "0", "]", "]", "\n", "ground_truth", "=", "[", "questions", "[", "gt_id", "]", "for", "gt_id", "in", "line", "[", "1", "]", ".", "split", "(", ")", "]", "\n", "pool", "=", "[", "questions", "[", "pa_id", "]", "for", "pa_id", "in", "line", "[", "2", "]", ".", "split", "(", ")", "]", "\n", "np", ".", "random", ".", "shuffle", "(", "pool", ")", "\n", "datapoints", ".", "append", "(", "QAPool", "(", "query_question", ",", "pool", ",", "ground_truth", ")", ")", "\n", "\n", "split_questions", "+=", "[", "query_question", "]", "+", "ground_truth", "+", "pool", "\n", "\n", "# we filter out all pools that do not contain any ground truth answer (except train!)", "\n", "", "if", "name", "!=", "'train_random'", ":", "\n", "            ", "qa_pools_len_before", "=", "len", "(", "datapoints", ")", "\n", "datapoints", "=", "[", "p", "for", "p", "in", "datapoints", "if", "len", "(", "[", "1", "for", "gt", "in", "p", ".", "ground_truth", "if", "gt", "in", "p", ".", "pooled_answers", "]", ")", ">", "0", "]", "\n", "qa_pools_len_after", "=", "len", "(", "datapoints", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Split {} reduced to {} item from {} due to missing ground truth in pool\"", ".", "format", "(", "\n", "name", ",", "qa_pools_len_after", ",", "qa_pools_len_before", "\n", ")", ")", "\n", "\n", "", "return", "Data", "(", "'askubuntu / {}'", ".", "format", "(", "name", ")", ",", "datapoints", ",", "unique_items", "(", "split_questions", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read": [[67, 75], ["askubuntu.AskUbuntuReader.read_items", "askubuntu.AskUbuntuReader.read_split", "askubuntu.AskUbuntuReader.read_split", "askubuntu.AskUbuntuReader.read_split", "Archive", "list", "list", "askubuntu.AskUbuntuReader.values", "askubuntu.AskUbuntuReader.values"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.read_items", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read_split"], ["", "def", "read", "(", "self", ")", ":", "\n", "        ", "items", "=", "self", ".", "read_items", "(", ")", "\n", "\n", "train", "=", "self", ".", "read_split", "(", "\"train_random\"", ",", "items", ")", "\n", "valid", "=", "self", ".", "read_split", "(", "\"dev\"", ",", "items", ")", "\n", "test", "=", "self", ".", "read_split", "(", "\"test\"", ",", "items", ")", "\n", "\n", "return", "Archive", "(", "self", ".", "name", ",", "train", ",", "valid", ",", "[", "test", "]", ",", "list", "(", "items", ".", "values", "(", ")", ")", ",", "list", "(", "items", ".", "values", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.adapter.Adapter.__init__": [[6, 42], ["torch.nn.Module.__init__", "seq_list.append", "seq_list.append", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "non_linearity.lower", "torch.nn.ReLU", "adapter.Adapter.adapter_down.apply", "adapter.Adapter.adapter_attention.apply", "adapter.Adapter.adapter_up.apply"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "down_sample", "=", "None", ",", "non_linearity", "=", "'relu'", ",", "init_bert_weights", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "\n", "# list for all modules of the adapter, passed into nn.Sequential()", "\n", "seq_list", "=", "[", "]", "\n", "\n", "# if a downsample size is not passed, we just half the size of the original input", "\n", "self", ".", "down_sample", "=", "down_sample", "\n", "if", "down_sample", "is", "None", ":", "\n", "            ", "self", ".", "down_sample", "=", "self", ".", "input_size", "//", "2", "\n", "\n", "# Linear down projection of the input", "\n", "", "seq_list", ".", "append", "(", "nn", ".", "Linear", "(", "self", ".", "input_size", ",", "self", ".", "down_sample", ")", ")", "\n", "\n", "# select non-linearity", "\n", "# TODO give more options than just relu, or pass the non_linearity directly, not as a string", "\n", "if", "non_linearity", ".", "lower", "(", ")", "==", "'relu'", ":", "\n", "            ", "self", ".", "non_linearity", "=", "nn", ".", "ReLU", "(", ")", "\n", "", "seq_list", ".", "append", "(", "self", ".", "non_linearity", ")", "\n", "\n", "# sequential adapter, first downproject, then non-linearity then upsample. In the forward pass we include the", "\n", "# residual connection", "\n", "self", ".", "adapter_down", "=", "nn", ".", "Sequential", "(", "*", "seq_list", ")", "\n", "\n", "# attention layer that learns the usefulness of the different adapters. Is only trained in the later steps", "\n", "self", ".", "adapter_attention", "=", "nn", ".", "Linear", "(", "self", ".", "down_sample", ",", "1", ")", "\n", "\n", "# Up projection to input size", "\n", "self", ".", "adapter_up", "=", "nn", ".", "Linear", "(", "self", ".", "down_sample", ",", "self", ".", "input_size", ")", "\n", "\n", "# if we want to initialize with the bert strategy then this function is called for all the linear layers", "\n", "if", "init_bert_weights", ":", "\n", "            ", "self", ".", "adapter_down", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "self", ".", "adapter_attention", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "self", ".", "adapter_up", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.adapter.Adapter.forward": [[43, 50], ["adapter.Adapter.adapter_down", "adapter.Adapter.adapter_attention", "adapter.Adapter.adapter_up"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "residual_input", ")", ":", "\n", "        ", "down", "=", "self", ".", "adapter_down", "(", "x", ")", "\n", "attention", "=", "self", ".", "adapter_attention", "(", "down", ")", "\n", "up", "=", "self", ".", "adapter_up", "(", "down", ")", "\n", "output", "=", "up", "+", "residual_input", "\n", "\n", "return", "output", ",", "attention", ",", "down", ",", "up", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.adapter.Adapter.init_bert_weights": [[53, 67], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "init_bert_weights", "(", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "# module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "BertLayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.adapter.BertAdapterAttention.__init__": [[70, 105], ["torch.nn.Module.__init__", "int", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "adapter.BertAdapterAttention.query.apply", "torch.nn.Linear", "adapter.BertAdapterAttention.key.apply", "torch.nn.Linear", "adapter.BertAdapterAttention.value.apply", "int", "int", "int", "torch.zeros", "int", "int"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertAdapterAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "self", ".", "dense_size", "=", "int", "(", "config", ".", "hidden_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n", "if", "not", "self", ".", "config", ".", "fusion_config", "[", "'query'", "]", "and", "not", "self", ".", "config", ".", "fusion_config", "[", "'key'", "]", "and", "not", "self", ".", "config", ".", "fusion_config", "[", "'value'", "]", ":", "\n", "            ", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "self", ".", "dense_size", ",", "1", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "fusion_config", "[", "'query'", "]", ":", "\n", "            ", "self", ".", "query", "=", "nn", ".", "Linear", "(", "int", "(", "config", ".", "hidden_size", ")", ",", "self", ".", "dense_size", ")", "\n", "self", ".", "query", ".", "apply", "(", "Adapter", ".", "init_bert_weights", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "fusion_config", "[", "'key'", "]", ":", "\n", "            ", "self", ".", "key", "=", "nn", ".", "Linear", "(", "self", ".", "dense_size", ",", "self", ".", "dense_size", ")", "\n", "self", ".", "key", ".", "apply", "(", "Adapter", ".", "init_bert_weights", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "fusion_config", "[", "'value'", "]", ":", "\n", "            ", "self", ".", "value", "=", "nn", ".", "Linear", "(", "int", "(", "config", ".", "hidden_size", ")", ",", "int", "(", "config", ".", "hidden_size", ")", ",", "bias", "=", "False", ")", "\n", "self", ".", "value", ".", "apply", "(", "Adapter", ".", "init_bert_weights", ")", "\n", "if", "self", ".", "config", ".", "fusion_config", "[", "'value_initialized'", "]", ":", "\n", "                ", "self", ".", "value", ".", "weight", ".", "data", "=", "(", "\n", "torch", ".", "zeros", "(", "int", "(", "config", ".", "hidden_size", ")", ",", "int", "(", "config", ".", "hidden_size", ")", ")", "+", "0.000001", "\n", ")", ".", "fill_diagonal_", "(", "1.0", ")", "\n", "\n", "", "", "if", "self", ".", "config", ".", "fusion_config", "[", "'temperature'", "]", ":", "\n", "            ", "self", ".", "T", "=", "50.0", "\n", "", "else", ":", "\n", "            ", "self", ".", "T", "=", "1.0", "\n", "\n", "", "self", ".", "reduction", "=", "self", ".", "T", "/", "1000.0", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.adapter.BertAdapterAttention.forward": [[106, 159], ["torch.squeeze", "adapter.BertAdapterAttention.dropout", "max", "torch.squeeze", "residual[].repeat", "adapter.BertAdapterAttention.query", "adapter.BertAdapterAttention.key", "adapter.BertAdapterAttention.value", "torch.matmul", "torch.nn.Softmax", "attention_probs.detach().cpu().numpy", "torch.matmul", "adapter.BertAdapterAttention.value", "value.size", "adapter.BertAdapterAttention.unsqueeze", "adapter.BertAdapterAttention.transpose", "attention_probs.unsqueeze", "attention_probs.detach().cpu", "attention_probs.detach"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "residual", ",", "attention_mask", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "config", ".", "fusion_config", "[", "'residual_before'", "]", ":", "\n", "            ", "value", "+=", "residual", "[", ":", ",", ":", ",", "None", ",", ":", "]", ".", "repeat", "(", "1", ",", "1", ",", "value", ".", "size", "(", "2", ")", ",", "1", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "fusion_config", "[", "'query'", "]", ":", "\n", "            ", "query_layer", "=", "self", ".", "query", "(", "query", ")", "\n", "", "else", ":", "\n", "            ", "query_layer", "=", "query", "\n", "\n", "", "if", "self", ".", "config", ".", "fusion_config", "[", "'key'", "]", ":", "\n", "            ", "key_layer", "=", "self", ".", "key", "(", "key", ")", "\n", "", "else", ":", "\n", "            ", "key_layer", "=", "key", "\n", "\n", "", "if", "self", ".", "config", ".", "fusion_config", "[", "'value'", "]", "and", "self", ".", "config", ".", "fusion_config", "[", "'value_before_softmax'", "]", ":", "\n", "# key/value have dims => batch, toks, number-of-adapters, feats", "\n", "            ", "value_layer", "=", "self", ".", "value", "(", "value", ")", "\n", "", "else", ":", "\n", "            ", "value_layer", "=", "value", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "", "attention_scores", "=", "torch", ".", "squeeze", "(", "torch", ".", "matmul", "(", "query_layer", ".", "unsqueeze", "(", "2", ")", ",", "key_layer", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", ",", "dim", "=", "2", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_scores", "=", "self", ".", "dropout", "(", "attention_scores", ")", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "# attention_probs = nn.Softmax(dim=-1)(attention_scores)", "\n", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", "/", "self", ".", "T", ")", "\n", "\n", "# attention_probs = torch.zeros_like(attention_probs)", "\n", "# attention_probs[:, :, 0] = 1.0", "\n", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "self", ".", "recent_attention", "=", "attention_probs", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "self", ".", "T", "=", "max", "(", "self", ".", "T", "-", "self", ".", "reduction", ",", "1.0", ")", "\n", "\n", "# use the value layer or not TODO this is currently hardcoded", "\n", "context_layer", "=", "torch", ".", "squeeze", "(", "torch", ".", "matmul", "(", "attention_probs", ".", "unsqueeze", "(", "2", ")", ",", "value_layer", ")", ",", "dim", "=", "2", ")", "\n", "# context_layer = torch.squeeze(torch.matmul(attention_probs.unsqueeze(2), value), dim=2)", "\n", "\n", "if", "self", ".", "config", ".", "fusion_config", "[", "'value'", "]", "and", "not", "self", ".", "config", ".", "fusion_config", "[", "'value_before_softmax'", "]", ":", "\n", "# key/value have dims => batch, toks, number-of-adapters, feats", "\n", "            ", "context_layer", "=", "self", ".", "value", "(", "context_layer", ")", "\n", "", "else", ":", "\n", "            ", "context_layer", "=", "context_layer", "\n", "\n", "", "if", "not", "self", ".", "config", ".", "fusion_config", "[", "'residual_before'", "]", ":", "\n", "            ", "context_layer", "+=", "residual", "\n", "\n", "", "return", "context_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.adapter.BertLayerNorm.__init__": [[164, 171], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.ones", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "eps", "=", "1e-12", ")", ":", "\n", "        ", "\"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n        \"\"\"", "\n", "super", "(", "BertLayerNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "hidden_size", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "hidden_size", ")", ")", "\n", "self", ".", "variance_epsilon", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.adapter.BertLayerNorm.forward": [[172, 177], ["x.mean", "torch.sqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "u", "=", "x", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "s", "=", "(", "x", "-", "u", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "x", "=", "(", "x", "-", "u", ")", "/", "torch", ".", "sqrt", "(", "s", "+", "self", ".", "variance_epsilon", ")", "\n", "return", "self", ".", "weight", "*", "x", "+", "self", ".", "bias", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PretrainedConfig.__init__": [[101, 108], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "finetuning_task", "=", "kwargs", ".", "pop", "(", "'finetuning_task'", ",", "None", ")", "\n", "self", ".", "num_labels", "=", "kwargs", ".", "pop", "(", "'num_labels'", ",", "2", ")", "\n", "self", ".", "output_attentions", "=", "kwargs", ".", "pop", "(", "'output_attentions'", ",", "False", ")", "\n", "self", ".", "output_hidden_states", "=", "kwargs", ".", "pop", "(", "'output_hidden_states'", ",", "False", ")", "\n", "self", ".", "torchscript", "=", "kwargs", ".", "pop", "(", "'torchscript'", ",", "False", ")", "\n", "self", ".", "pruned_heads", "=", "kwargs", ".", "pop", "(", "'pruned_heads'", ",", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PretrainedConfig.save_pretrained": [[109, 119], ["os.path.isdir", "os.path.join", "modeling_utils.PretrainedConfig.to_json_file"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PretrainedConfig.to_json_file"], ["", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save a configuration object to the directory `save_directory`, so that it\n            can be re-loaded using the :func:`~pytorch_transformers.PretrainedConfig.from_pretrained` class method.\n        \"\"\"", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ",", "\"Saving path should be a directory where the model and configuration can be saved\"", "\n", "\n", "# If we save using the predefined names, we can load using `from_pretrained`", "\n", "output_config_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "CONFIG_NAME", ")", "\n", "\n", "self", ".", "to_json_file", "(", "output_config_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PretrainedConfig.from_pretrained": [[120, 221], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "cls.from_json_file", "hasattr", "kwargs.items", "logger.info", "os.path.isdir", "transformers.file_utils.cached_path", "logger.info", "logger.info", "dict", "hasattr", "kwargs.pop", "os.path.join", "setattr", "to_remove.append", "logger.error", "logger.error", "int", "set", "cls.from_json_file.pruned_heads.items", "cls.pretrained_config_archive_map.keys"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PretrainedConfig.from_json_file"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiate a :class:`~pytorch_transformers.PretrainedConfig` (or a derived class) from a pre-trained model configuration.\n\n        Parameters:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model configuration to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing a configuration file saved using the :func:`~pytorch_transformers.PretrainedConfig.save_pretrained` method, e.g.: ``./my_model_directory/``.\n                - a path or url to a saved configuration JSON `file`, e.g.: ``./my_model_directory/configuration.json``.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            kwargs: (`optional`) dict: key/value pairs with which to update the configuration object after loading.\n\n                - The values in kwargs of any keys which are configuration attributes will be used to override the loaded values.\n                - Behavior concerning key/value pairs whose keys are *not* configuration attributes is controlled by the `return_unused_kwargs` keyword parameter.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            return_unused_kwargs: (`optional`) bool:\n\n                - If False, then this function returns just the final configuration object.\n                - If True, then this functions returns a tuple `(config, unused_kwargs)` where `unused_kwargs` is a dictionary consisting of the key/value pairs whose keys are not configuration attributes: ie the part of kwargs which has not been used to update `config` and is otherwise ignored.\n\n        Examples::\n\n            # We can't instantiate directly the base class `PretrainedConfig` so let's show the examples on a\n            # derived class: BertConfig\n            config = BertConfig.from_pretrained('bert-base-uncased')    # Download configuration from S3 and cache.\n            config = BertConfig.from_pretrained('./test/saved_model/')  # E.g. config (or model) was saved using `save_pretrained('./test/saved_model/')`\n            config = BertConfig.from_pretrained('./test/saved_model/my_configuration.json')\n            config = BertConfig.from_pretrained('bert-base-uncased', output_attention=True, foo=False)\n            assert config.output_attention == True\n            config, unused_kwargs = BertConfig.from_pretrained('bert-base-uncased', output_attention=True,\n                                                               foo=False, return_unused_kwargs=True)\n            assert config.output_attention == True\n            assert unused_kwargs == {'foo': False}\n\n        \"\"\"", "\n", "cache_dir", "=", "kwargs", ".", "pop", "(", "'cache_dir'", ",", "None", ")", "\n", "force_download", "=", "kwargs", ".", "pop", "(", "'force_download'", ",", "False", ")", "\n", "proxies", "=", "kwargs", ".", "pop", "(", "'proxies'", ",", "None", ")", "\n", "return_unused_kwargs", "=", "kwargs", ".", "pop", "(", "'return_unused_kwargs'", ",", "False", ")", "\n", "\n", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_config_archive_map", ":", "\n", "            ", "config_file", "=", "cls", ".", "pretrained_config_archive_map", "[", "pretrained_model_name_or_path", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "            ", "config_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "CONFIG_NAME", ")", "\n", "", "else", ":", "\n", "            ", "config_file", "=", "pretrained_model_name_or_path", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_config_file", "=", "cached_path", "(", "config_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", "as", "e", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_config_archive_map", ":", "\n", "                ", "logger", ".", "error", "(", "\n", "\"Couldn't reach server at '{}' to download pretrained model configuration file.\"", ".", "format", "(", "\n", "config_file", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find any file \"", "\n", "\"associated to this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "cls", ".", "pretrained_config_archive_map", ".", "keys", "(", ")", ")", ",", "\n", "config_file", ")", ")", "\n", "", "raise", "e", "\n", "", "if", "resolved_config_file", "==", "config_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading configuration file {}\"", ".", "format", "(", "config_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading configuration file {} from cache at {}\"", ".", "format", "(", "\n", "config_file", ",", "resolved_config_file", ")", ")", "\n", "\n", "# Load config", "\n", "", "config", "=", "cls", ".", "from_json_file", "(", "resolved_config_file", ")", "\n", "\n", "if", "hasattr", "(", "config", ",", "'pruned_heads'", ")", ":", "\n", "            ", "config", ".", "pruned_heads", "=", "dict", "(", "(", "int", "(", "key", ")", ",", "set", "(", "value", ")", ")", "for", "key", ",", "value", "in", "config", ".", "pruned_heads", ".", "items", "(", ")", ")", "\n", "\n", "# Update config with kwargs if needed", "\n", "", "to_remove", "=", "[", "]", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "hasattr", "(", "config", ",", "key", ")", ":", "\n", "                ", "setattr", "(", "config", ",", "key", ",", "value", ")", "\n", "to_remove", ".", "append", "(", "key", ")", "\n", "", "", "for", "key", "in", "to_remove", ":", "\n", "            ", "kwargs", ".", "pop", "(", "key", ",", "None", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Model config %s\"", ",", "config", ")", "\n", "if", "return_unused_kwargs", ":", "\n", "            ", "return", "config", ",", "kwargs", "\n", "", "else", ":", "\n", "            ", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PretrainedConfig.from_dict": [[222, 229], ["cls", "json_object.items"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "json_object", ")", ":", "\n", "        ", "\"\"\"Constructs a `Config` from a Python dictionary of parameters.\"\"\"", "\n", "config", "=", "cls", "(", "vocab_size_or_config_json_file", "=", "-", "1", ")", "\n", "for", "key", ",", "value", "in", "json_object", ".", "items", "(", ")", ":", "\n", "            ", "config", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PretrainedConfig.from_json_file": [[230, 236], ["cls.from_dict", "io.open", "reader.read", "json.loads"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PretrainedConfig.from_dict", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read"], ["", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ")", ":", "\n", "        ", "\"\"\"Constructs a `BertConfig` from a json file of parameters.\"\"\"", "\n", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "return", "cls", ".", "from_dict", "(", "json", ".", "loads", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PretrainedConfig.__eq__": [[237, 239], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "__dict__", "==", "other", ".", "__dict__", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PretrainedConfig.__repr__": [[240, 242], ["str", "modeling_utils.PretrainedConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PretrainedConfig.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PretrainedConfig.to_dict": [[243, 247], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PretrainedConfig.to_json_string": [[248, 251], ["json.dumps", "modeling_utils.PretrainedConfig.to_dict"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PretrainedConfig.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PretrainedConfig.to_json_file": [[252, 256], ["io.open", "writer.write", "modeling_utils.PretrainedConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PretrainedConfig.to_json_string"], ["", "def", "to_json_file", "(", "self", ",", "json_file_path", ")", ":", "\n", "        ", "\"\"\" Save this instance to a json file.\"\"\"", "\n", "with", "open", "(", "json_file_path", ",", "\"w\"", ",", "encoding", "=", "'utf-8'", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel.__init__": [[280, 291], ["torch.nn.Module.__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "PreTrainedModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "not", "isinstance", "(", "config", ",", "PretrainedConfig", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Parameter config in `{}(config)` should be an instance of class `PretrainedConfig`. \"", "\n", "\"To create a model from a pretrained model use \"", "\n", "\"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "__class__", ".", "__name__", "\n", ")", ")", "\n", "# Save config in model", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel._get_resized_embeddings": [[292, 325], ["old_embeddings.weight.size", "torch.nn.Embedding", "torch.nn.Embedding.to", "modeling_utils.PreTrainedModel._init_weights", "min"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertPreTrainedModel._init_weights"], ["", "def", "_get_resized_embeddings", "(", "self", ",", "old_embeddings", ",", "new_num_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\" Build a resized Embedding Module from a provided token Embedding Module.\n            Increasing the size will add newly initialized vectors at the end\n            Reducing the size will remove vectors from the end\n\n        Args:\n            new_num_tokens: (`optional`) int\n                New number of tokens in the embedding matrix.\n                Increasing the size will add newly initialized vectors at the end\n                Reducing the size will remove vectors from the end\n                If not provided or None: return the provided token Embedding Module.\n        Return: ``torch.nn.Embeddings``\n            Pointer to the resized Embedding Module or the old Embedding Module if new_num_tokens is None\n        \"\"\"", "\n", "if", "new_num_tokens", "is", "None", ":", "\n", "            ", "return", "old_embeddings", "\n", "\n", "", "old_num_tokens", ",", "old_embedding_dim", "=", "old_embeddings", ".", "weight", ".", "size", "(", ")", "\n", "if", "old_num_tokens", "==", "new_num_tokens", ":", "\n", "            ", "return", "old_embeddings", "\n", "\n", "# Build new embeddings", "\n", "", "new_embeddings", "=", "nn", ".", "Embedding", "(", "new_num_tokens", ",", "old_embedding_dim", ")", "\n", "new_embeddings", ".", "to", "(", "old_embeddings", ".", "weight", ".", "device", ")", "\n", "\n", "# initialize all new embeddings (in particular added tokens)", "\n", "self", ".", "_init_weights", "(", "new_embeddings", ")", "\n", "\n", "# Copy word embeddings from the previous weights", "\n", "num_tokens_to_copy", "=", "min", "(", "old_num_tokens", ",", "new_num_tokens", ")", "\n", "new_embeddings", ".", "weight", ".", "data", "[", ":", "num_tokens_to_copy", ",", ":", "]", "=", "old_embeddings", ".", "weight", ".", "data", "[", ":", "num_tokens_to_copy", ",", ":", "]", "\n", "\n", "return", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel._tie_or_clone_weights": [[326, 340], ["torch.nn.Parameter", "hasattr", "torch.nn.functional.pad", "second_module.weight.clone"], "methods", ["None"], ["", "def", "_tie_or_clone_weights", "(", "self", ",", "first_module", ",", "second_module", ")", ":", "\n", "        ", "\"\"\" Tie or clone module weights depending of weither we are using TorchScript or not\n        \"\"\"", "\n", "if", "self", ".", "config", ".", "torchscript", ":", "\n", "            ", "first_module", ".", "weight", "=", "nn", ".", "Parameter", "(", "second_module", ".", "weight", ".", "clone", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "first_module", ".", "weight", "=", "second_module", ".", "weight", "\n", "\n", "", "if", "hasattr", "(", "first_module", ",", "'bias'", ")", "and", "first_module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "first_module", ".", "bias", ".", "data", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "\n", "first_module", ".", "bias", ".", "data", ",", "\n", "(", "0", ",", "first_module", ".", "weight", ".", "shape", "[", "0", "]", "-", "first_module", ".", "bias", ".", "shape", "[", "0", "]", ")", ",", "\n", "'constant'", ",", "\n", "0", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel.resize_token_embeddings": [[342, 369], ["getattr", "getattr._resize_token_embeddings", "hasattr", "modeling_utils.PreTrainedModel.tie_weights"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel._resize_token_embeddings", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertForMaskedLM.tie_weights"], ["", "", "def", "resize_token_embeddings", "(", "self", ",", "new_num_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\" Resize input token embeddings matrix of the model if new_num_tokens != config.vocab_size.\n        Take care of tying weights embeddings afterwards if the model class has a `tie_weights()` method.\n\n        Arguments:\n\n            new_num_tokens: (`optional`) int:\n                New number of tokens in the embedding matrix. Increasing the size will add newly initialized vectors at the end. Reducing the size will remove vectors from the end.\n                If not provided or None: does nothing and just returns a pointer to the input tokens ``torch.nn.Embeddings`` Module of the model.\n\n        Return: ``torch.nn.Embeddings``\n            Pointer to the input tokens Embeddings Module of the model\n        \"\"\"", "\n", "base_model", "=", "getattr", "(", "self", ",", "self", ".", "base_model_prefix", ",", "self", ")", "# get the base model if needed", "\n", "model_embeds", "=", "base_model", ".", "_resize_token_embeddings", "(", "new_num_tokens", ")", "\n", "if", "new_num_tokens", "is", "None", ":", "\n", "            ", "return", "model_embeds", "\n", "\n", "# Update base model and current model config", "\n", "", "self", ".", "config", ".", "vocab_size", "=", "new_num_tokens", "\n", "base_model", ".", "vocab_size", "=", "new_num_tokens", "\n", "\n", "# Tie weights again if needed", "\n", "if", "hasattr", "(", "self", ",", "'tie_weights'", ")", ":", "\n", "            ", "self", ".", "tie_weights", "(", ")", "\n", "\n", "", "return", "model_embeds", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel.init_weights": [[370, 378], ["modeling_utils.PreTrainedModel.apply", "modeling_utils.PreTrainedModel.prune_heads"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertAttention.prune_heads"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Initialize and prunes weights if needed. \"\"\"", "\n", "# Initialize weights", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n", "# Prune heads if needed", "\n", "if", "self", ".", "config", ".", "pruned_heads", ":", "\n", "            ", "self", ".", "prune_heads", "(", "self", ".", "config", ".", "pruned_heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel.prune_heads": [[379, 395], ["getattr", "heads_to_prune.items", "getattr._prune_heads", "list", "set", "set", "modeling_utils.PreTrainedModel.config.pruned_heads.get"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel._prune_heads"], ["", "", "def", "prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the base model.\n\n            Arguments:\n\n                heads_to_prune: dict with keys being selected layer indices (`int`) and associated values being the list of heads to prune in said layer (list of `int`).\n                E.g. {1: [0, 2], 2: [2, 3]} will prune heads 0 and 2 on layer 1 and heads 2 and 3 on layer 2.\n        \"\"\"", "\n", "base_model", "=", "getattr", "(", "self", ",", "self", ".", "base_model_prefix", ",", "self", ")", "# get the base model if needed", "\n", "\n", "# save new sets of pruned heads as union of previously stored pruned heads and newly pruned heads", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "union_heads", "=", "set", "(", "self", ".", "config", ".", "pruned_heads", ".", "get", "(", "layer", ",", "[", "]", ")", ")", "|", "set", "(", "heads", ")", "\n", "self", ".", "config", ".", "pruned_heads", "[", "layer", "]", "=", "list", "(", "union_heads", ")", "# Unfortunately we have to store it as list for JSON", "\n", "\n", "", "base_model", ".", "_prune_heads", "(", "heads_to_prune", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel.save_pretrained": [[396, 412], ["os.path.isdir", "model_to_save.config.save_pretrained", "os.path.join", "torch.save", "hasattr", "model_to_save.state_dict"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel.save_pretrained"], ["", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save a model and its configuration file to a directory, so that it\n            can be re-loaded using the `:func:`~pytorch_transformers.PreTrainedModel.from_pretrained`` class method.\n        \"\"\"", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ",", "\"Saving path should be a directory where the model and configuration can be saved\"", "\n", "\n", "# Only save the model it-self if we are using distributed training", "\n", "model_to_save", "=", "self", ".", "module", "if", "hasattr", "(", "self", ",", "'module'", ")", "else", "self", "\n", "\n", "# Save configuration file", "\n", "model_to_save", ".", "config", ".", "save_pretrained", "(", "save_directory", ")", "\n", "\n", "# If we save using the predefined names, we can load using `from_pretrained`", "\n", "output_model_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "WEIGHTS_NAME", ")", "\n", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_model_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel.from_pretrained": [[413, 607], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "cls", "torch.load.keys", "zip", "getattr", "torch.load.copy", "modeling_utils.PreTrainedModel.from_pretrained.load"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.load"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"Instantiate a pretrained pytorch model from a pre-trained model configuration.\n\n        The model is set in evaluation mode by default using ``model.eval()`` (Dropout modules are deactivated)\n        To train the model, you should first set it back in training mode with ``model.train()``\n\n        The warning ``Weights from XXX not initialized from pretrained model`` means that the weights of XXX do not come pre-trained with the rest of the model.\n        It is up to you to train those weights with a downstream fine-tuning task.\n\n        The warning ``Weights from XXX not used in YYY`` means that the layer XXX is not used by YYY, therefore those weights are discarded.\n\n        Parameters:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing model weights saved using :func:`~pytorch_transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `tensorflow index checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In this case, ``from_tf`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~pytorch_transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~pytorch_transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~pytorch_transformers.PreTrainedModel.save_pretrained` and :func:`~pytorch_transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~pytorch_transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = BertModel.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = BertModel.from_pretrained('./test/saved_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = BertModel.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = BertConfig.from_json_file('./tf_model/my_tf_model_config.json')\n            model = BertModel.from_pretrained('./tf_model/my_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n        \"\"\"", "\n", "config", "=", "kwargs", ".", "pop", "(", "'config'", ",", "None", ")", "\n", "state_dict", "=", "kwargs", ".", "pop", "(", "'state_dict'", ",", "None", ")", "\n", "cache_dir", "=", "kwargs", ".", "pop", "(", "'cache_dir'", ",", "None", ")", "\n", "from_tf", "=", "kwargs", ".", "pop", "(", "'from_tf'", ",", "False", ")", "\n", "force_download", "=", "kwargs", ".", "pop", "(", "'force_download'", ",", "False", ")", "\n", "proxies", "=", "kwargs", ".", "pop", "(", "'proxies'", ",", "None", ")", "\n", "output_loading_info", "=", "kwargs", ".", "pop", "(", "'output_loading_info'", ",", "False", ")", "\n", "\n", "# Load config", "\n", "if", "config", "is", "None", ":", "\n", "            ", "config", ",", "model_kwargs", "=", "cls", ".", "config_class", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "\n", "cache_dir", "=", "cache_dir", ",", "return_unused_kwargs", "=", "True", ",", "\n", "force_download", "=", "force_download", ",", "\n", "**", "kwargs", "\n", ")", "\n", "", "else", ":", "\n", "            ", "model_kwargs", "=", "kwargs", "\n", "\n", "# Load model", "\n", "", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "            ", "archive_file", "=", "cls", ".", "pretrained_model_archive_map", "[", "pretrained_model_name_or_path", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "            ", "if", "from_tf", ":", "\n", "# Directly load from a TensorFlow checkpoint", "\n", "                ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", ")", "\n", "", "else", ":", "\n", "                ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "from_tf", ":", "\n", "# Directly load from a TensorFlow checkpoint", "\n", "                ", "archive_file", "=", "pretrained_model_name_or_path", "+", "\".index\"", "\n", "", "else", ":", "\n", "                ", "archive_file", "=", "pretrained_model_name_or_path", "\n", "# redirect to the cache, if necessary", "\n", "", "", "try", ":", "\n", "            ", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", "as", "e", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "                ", "logger", ".", "error", "(", "\n", "\"Couldn't reach server at '{}' to download pretrained weights.\"", ".", "format", "(", "\n", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find any file \"", "\n", "\"associated to this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "cls", ".", "pretrained_model_archive_map", ".", "keys", "(", ")", ")", ",", "\n", "archive_file", ")", ")", "\n", "", "raise", "e", "\n", "", "if", "resolved_archive_file", "==", "archive_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading weights file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading weights file {} from cache at {}\"", ".", "format", "(", "\n", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "\n", "# Instantiate model.", "\n", "", "model", "=", "cls", "(", "config", ",", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "\n", "if", "state_dict", "is", "None", "and", "not", "from_tf", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "resolved_archive_file", ",", "map_location", "=", "'cpu'", ")", "\n", "", "if", "from_tf", ":", "\n", "# Directly load from a TensorFlow checkpoint", "\n", "            ", "return", "cls", ".", "load_tf_weights", "(", "model", ",", "config", ",", "resolved_archive_file", "[", ":", "-", "6", "]", ")", "# Remove the '.index'", "\n", "\n", "# Convert old format to new format if needed from a PyTorch state_dict", "\n", "", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "new_key", "=", "None", "\n", "if", "'gamma'", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "new_key", ":", "\n", "                ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "            ", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "# Load from a PyTorch state_dict", "\n", "", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "metadata", "=", "getattr", "(", "state_dict", ",", "'_metadata'", ",", "None", ")", "\n", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "            ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "''", ")", ":", "\n", "            ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                ", "if", "child", "is", "not", "None", ":", "\n", "                    ", "load", "(", "child", ",", "prefix", "+", "name", "+", "'.'", ")", "\n", "\n", "# Make sure we are able to load base models as well as derived models (with heads)", "\n", "", "", "", "start_prefix", "=", "''", "\n", "model_to_load", "=", "model", "\n", "if", "not", "hasattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "and", "any", "(", "s", ".", "startswith", "(", "cls", ".", "base_model_prefix", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "start_prefix", "=", "cls", ".", "base_model_prefix", "+", "'.'", "\n", "", "if", "hasattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "and", "not", "any", "(", "s", ".", "startswith", "(", "cls", ".", "base_model_prefix", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "model_to_load", "=", "getattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "\n", "\n", "", "load", "(", "model_to_load", ",", "prefix", "=", "start_prefix", ")", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights from pretrained model not used in {}: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", ")", "\n", "", "if", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Error(s) in loading state_dict for {}:\\n\\t{}'", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", ")", ")", "\n", "\n", "", "if", "hasattr", "(", "model", ",", "'tie_weights'", ")", ":", "\n", "            ", "model", ".", "tie_weights", "(", ")", "# make sure word embedding weights are still tied", "\n", "\n", "# Set model in evaluation mode to desactivate DropOut modules by default", "\n", "", "model", ".", "eval", "(", ")", "\n", "\n", "if", "output_loading_info", ":", "\n", "            ", "loading_info", "=", "{", "\"missing_keys\"", ":", "missing_keys", ",", "\"unexpected_keys\"", ":", "unexpected_keys", ",", "\"error_msgs\"", ":", "error_msgs", "}", "\n", "return", "model", ",", "loading_info", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.Conv1D.__init__": [[610, 620], ["torch.nn.Module.__init__", "torch.empty", "torch.nn.init.normal_", "torch.nn.Parameter", "torch.nn.Parameter", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "nx", ")", ":", "\n", "        ", "\"\"\" Conv1D layer as defined by Radford et al. for OpenAI GPT (and also used in GPT-2)\n            Basically works like a Linear layer but the weights are transposed\n        \"\"\"", "\n", "super", "(", "Conv1D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nf", "=", "nf", "\n", "w", "=", "torch", ".", "empty", "(", "nx", ",", "nf", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "w", ",", "std", "=", "0.02", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "w", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "nf", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.Conv1D.forward": [[621, 626], ["torch.addmm", "x.view.view.view", "x.view.view.view", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "size_out", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "nf", ",", ")", "\n", "x", "=", "torch", ".", "addmm", "(", "self", ".", "bias", ",", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", ",", "self", ".", "weight", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "size_out", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PoolerStartLogits.__init__": [[630, 633], ["torch.nn.Module.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "PoolerStartLogits", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PoolerStartLogits.forward": [[634, 646], ["modeling_utils.PoolerStartLogits.dense().squeeze", "modeling_utils.PoolerStartLogits.dense"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "p_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\" Args:\n            **p_mask**: (`optional`) ``torch.FloatTensor`` of shape `(batch_size, seq_len)`\n                invalid position mask such as query and special symbols (PAD, SEP, CLS)\n                1.0 means token should be masked.\n        \"\"\"", "\n", "x", "=", "self", ".", "dense", "(", "hidden_states", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "if", "p_mask", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "1e30", "*", "p_mask", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PoolerEndLogits.__init__": [[651, 657], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.LayerNorm", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "PoolerEndLogits", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense_0", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dense_1", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PoolerEndLogits.forward": [[658, 687], ["modeling_utils.PoolerEndLogits.dense_0", "modeling_utils.PoolerEndLogits.activation", "modeling_utils.PoolerEndLogits.LayerNorm", "modeling_utils.PoolerEndLogits.dense_1().squeeze", "start_positions[].expand", "hidden_states.gather", "start_states.expand.expand.expand", "torch.cat", "modeling_utils.PoolerEndLogits.dense_1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "start_states", "=", "None", ",", "start_positions", "=", "None", ",", "p_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\" Args:\n            One of ``start_states``, ``start_positions`` should be not None.\n            If both are set, ``start_positions`` overrides ``start_states``.\n\n            **start_states**: ``torch.LongTensor`` of shape identical to hidden_states\n                hidden states of the first tokens for the labeled span.\n            **start_positions**: ``torch.LongTensor`` of shape ``(batch_size,)``\n                position of the first token for the labeled span:\n            **p_mask**: (`optional`) ``torch.FloatTensor`` of shape ``(batch_size, seq_len)``\n                Mask of invalid position such as query and special symbols (PAD, SEP, CLS)\n                1.0 means token should be masked.\n        \"\"\"", "\n", "assert", "start_states", "is", "not", "None", "or", "start_positions", "is", "not", "None", ",", "\"One of start_states, start_positions should be not None\"", "\n", "if", "start_positions", "is", "not", "None", ":", "\n", "            ", "slen", ",", "hsz", "=", "hidden_states", ".", "shape", "[", "-", "2", ":", "]", "\n", "start_positions", "=", "start_positions", "[", ":", ",", "None", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, 1, hsz)", "\n", "start_states", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "start_positions", ")", "# shape (bsz, 1, hsz)", "\n", "start_states", "=", "start_states", ".", "expand", "(", "-", "1", ",", "slen", ",", "-", "1", ")", "# shape (bsz, slen, hsz)", "\n", "\n", "", "x", "=", "self", ".", "dense_0", "(", "torch", ".", "cat", "(", "[", "hidden_states", ",", "start_states", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "LayerNorm", "(", "x", ")", "\n", "x", "=", "self", ".", "dense_1", "(", "x", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "if", "p_mask", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "1e30", "*", "p_mask", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PoolerAnswerClass.__init__": [[691, 696], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "PoolerAnswerClass", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense_0", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "dense_1", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PoolerAnswerClass.forward": [[697, 731], ["modeling_utils.PoolerAnswerClass.dense_0", "modeling_utils.PoolerAnswerClass.activation", "modeling_utils.PoolerAnswerClass.dense_1().squeeze", "start_positions[].expand", "hidden_states.gather().squeeze", "cls_index[].expand", "hidden_states.gather().squeeze", "torch.cat", "modeling_utils.PoolerAnswerClass.dense_1", "hidden_states.gather", "hidden_states.gather"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "start_states", "=", "None", ",", "start_positions", "=", "None", ",", "cls_index", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            One of ``start_states``, ``start_positions`` should be not None.\n            If both are set, ``start_positions`` overrides ``start_states``.\n\n            **start_states**: ``torch.LongTensor`` of shape identical to ``hidden_states``.\n                hidden states of the first tokens for the labeled span.\n            **start_positions**: ``torch.LongTensor`` of shape ``(batch_size,)``\n                position of the first token for the labeled span.\n            **cls_index**: torch.LongTensor of shape ``(batch_size,)``\n                position of the CLS token. If None, take the last token.\n\n            note(Original repo):\n                no dependency on end_feature so that we can obtain one single `cls_logits`\n                for each sample\n        \"\"\"", "\n", "hsz", "=", "hidden_states", ".", "shape", "[", "-", "1", "]", "\n", "assert", "start_states", "is", "not", "None", "or", "start_positions", "is", "not", "None", ",", "\"One of start_states, start_positions should be not None\"", "\n", "if", "start_positions", "is", "not", "None", ":", "\n", "            ", "start_positions", "=", "start_positions", "[", ":", ",", "None", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, 1, hsz)", "\n", "start_states", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "start_positions", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, hsz)", "\n", "\n", "", "if", "cls_index", "is", "not", "None", ":", "\n", "            ", "cls_index", "=", "cls_index", "[", ":", ",", "None", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, 1, hsz)", "\n", "cls_token_state", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "cls_index", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, hsz)", "\n", "", "else", ":", "\n", "            ", "cls_token_state", "=", "hidden_states", "[", ":", ",", "-", "1", ",", ":", "]", "# shape (bsz, hsz)", "\n", "\n", "", "x", "=", "self", ".", "dense_0", "(", "torch", ".", "cat", "(", "[", "start_states", ",", "cls_token_state", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "dense_1", "(", "x", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.SQuADHead.__init__": [[773, 781], ["torch.nn.Module.__init__", "modeling_utils.PoolerStartLogits", "modeling_utils.PoolerEndLogits", "modeling_utils.PoolerAnswerClass"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "SQuADHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "start_n_top", "=", "config", ".", "start_n_top", "\n", "self", ".", "end_n_top", "=", "config", ".", "end_n_top", "\n", "\n", "self", ".", "start_logits", "=", "PoolerStartLogits", "(", "config", ")", "\n", "self", ".", "end_logits", "=", "PoolerEndLogits", "(", "config", ")", "\n", "self", ".", "answer_class", "=", "PoolerAnswerClass", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.SQuADHead.forward": [[782, 840], ["modeling_utils.SQuADHead.start_logits", "modeling_utils.SQuADHead.end_logits", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "hidden_states.size", "torch.nn.functional.softmax", "torch.topk", "start_top_index.unsqueeze().expand", "torch.gather", "torch.einsum.unsqueeze().expand", "hidden_states.unsqueeze().expand_as", "modeling_utils.SQuADHead.end_logits", "torch.nn.functional.softmax", "torch.topk", "end_top_log_probs.view.view.view", "end_top_index.view.view.view", "torch.einsum", "modeling_utils.SQuADHead.answer_class", "modeling_utils.SQuADHead.answer_class", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss.", "p_mask.unsqueeze", "x.squeeze_", "start_top_index.unsqueeze", "torch.einsum.unsqueeze", "hidden_states.unsqueeze", "x.dim"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "start_positions", "=", "None", ",", "end_positions", "=", "None", ",", "\n", "cls_index", "=", "None", ",", "is_impossible", "=", "None", ",", "p_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "(", ")", "\n", "\n", "start_logits", "=", "self", ".", "start_logits", "(", "hidden_states", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, let's remove the dimension added by batch splitting", "\n", "            ", "for", "x", "in", "(", "start_positions", ",", "end_positions", ",", "cls_index", ",", "is_impossible", ")", ":", "\n", "                ", "if", "x", "is", "not", "None", "and", "x", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "x", ".", "squeeze_", "(", "-", "1", ")", "\n", "\n", "# during training, compute the end logits based on the ground truth of the start position", "\n", "", "", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "\n", "if", "cls_index", "is", "not", "None", "and", "is_impossible", "is", "not", "None", ":", "\n", "# Predict answerability from the representation of CLS and START", "\n", "                ", "cls_logits", "=", "self", ".", "answer_class", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "cls_index", "=", "cls_index", ")", "\n", "loss_fct_cls", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "cls_loss", "=", "loss_fct_cls", "(", "cls_logits", ",", "is_impossible", ")", "\n", "\n", "# note(zhiliny): by default multiply the loss by 0.5 so that the scale is comparable to start_loss and end_loss", "\n", "total_loss", "+=", "cls_loss", "*", "0.5", "\n", "\n", "", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "else", ":", "\n", "# during inference, compute the end logits based on beam search", "\n", "            ", "bsz", ",", "slen", ",", "hsz", "=", "hidden_states", ".", "size", "(", ")", "\n", "start_log_probs", "=", "F", ".", "softmax", "(", "start_logits", ",", "dim", "=", "-", "1", ")", "# shape (bsz, slen)", "\n", "\n", "start_top_log_probs", ",", "start_top_index", "=", "torch", ".", "topk", "(", "start_log_probs", ",", "self", ".", "start_n_top", ",", "dim", "=", "-", "1", ")", "# shape (bsz, start_n_top)", "\n", "start_top_index_exp", "=", "start_top_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "torch", ".", "gather", "(", "hidden_states", ",", "-", "2", ",", "start_top_index_exp", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "start_states", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "slen", ",", "-", "1", ",", "-", "1", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "\n", "hidden_states_expanded", "=", "hidden_states", ".", "unsqueeze", "(", "2", ")", ".", "expand_as", "(", "start_states", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "p_mask", "=", "p_mask", ".", "unsqueeze", "(", "-", "1", ")", "if", "p_mask", "is", "not", "None", "else", "None", "\n", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states_expanded", ",", "start_states", "=", "start_states", ",", "p_mask", "=", "p_mask", ")", "\n", "end_log_probs", "=", "F", ".", "softmax", "(", "end_logits", ",", "dim", "=", "1", ")", "# shape (bsz, slen, start_n_top)", "\n", "\n", "end_top_log_probs", ",", "end_top_index", "=", "torch", ".", "topk", "(", "end_log_probs", ",", "self", ".", "end_n_top", ",", "dim", "=", "1", ")", "# shape (bsz, end_n_top, start_n_top)", "\n", "end_top_log_probs", "=", "end_top_log_probs", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "end_top_index", "=", "end_top_index", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "\n", "start_states", "=", "torch", ".", "einsum", "(", "\"blh,bl->bh\"", ",", "hidden_states", ",", "start_log_probs", ")", "\n", "cls_logits", "=", "self", ".", "answer_class", "(", "hidden_states", ",", "start_states", "=", "start_states", ",", "cls_index", "=", "cls_index", ")", "\n", "\n", "outputs", "=", "(", "start_top_log_probs", ",", "start_top_index", ",", "end_top_log_probs", ",", "end_top_index", ",", "cls_logits", ")", "+", "outputs", "\n", "\n", "# return start_top_log_probs, start_top_index, end_top_log_probs, end_top_index, cls_logits", "\n", "# or (if labels are provided) (total_loss,)", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.SequenceSummary.__init__": [[857, 886], ["torch.nn.Module.__init__", "Identity", "Identity", "Identity", "Identity", "hasattr", "hasattr", "torch.nn.Linear", "hasattr", "torch.nn.Tanh", "hasattr", "torch.nn.Dropout", "hasattr", "torch.nn.Dropout", "hasattr"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "SequenceSummary", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "summary_type", "=", "config", ".", "summary_type", "if", "hasattr", "(", "config", ",", "'summary_use_proj'", ")", "else", "'last'", "\n", "if", "self", ".", "summary_type", "==", "'attn'", ":", "\n", "# We should use a standard multi-head attention module with absolute positional embedding for that.", "\n", "# Cf. https://github.com/zihangdai/xlnet/blob/master/modeling.py#L253-L276", "\n", "# We can probably just use the multi-head attention module of PyTorch >=1.1.0", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "summary", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "'summary_use_proj'", ")", "and", "config", ".", "summary_use_proj", ":", "\n", "            ", "if", "hasattr", "(", "config", ",", "'summary_proj_to_labels'", ")", "and", "config", ".", "summary_proj_to_labels", "and", "config", ".", "num_labels", ">", "0", ":", "\n", "                ", "num_classes", "=", "config", ".", "num_labels", "\n", "", "else", ":", "\n", "                ", "num_classes", "=", "config", ".", "hidden_size", "\n", "", "self", ".", "summary", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_classes", ")", "\n", "\n", "", "self", ".", "activation", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "'summary_activation'", ")", "and", "config", ".", "summary_activation", "==", "'tanh'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n", "", "self", ".", "first_dropout", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "'summary_first_dropout'", ")", "and", "config", ".", "summary_first_dropout", ">", "0", ":", "\n", "            ", "self", ".", "first_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "summary_first_dropout", ")", "\n", "\n", "", "self", ".", "last_dropout", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "'summary_last_dropout'", ")", "and", "config", ".", "summary_last_dropout", ">", "0", ":", "\n", "            ", "self", ".", "last_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "summary_last_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.SequenceSummary.forward": [[887, 917], ["modeling_utils.SequenceSummary.first_dropout", "modeling_utils.SequenceSummary.summary", "modeling_utils.SequenceSummary.activation", "modeling_utils.SequenceSummary.last_dropout", "hidden_states.mean", "hidden_states.gather().squeeze", "torch.full_like", "cls_index.expand.expand.unsqueeze().unsqueeze", "cls_index.expand.expand.expand", "hidden_states.gather", "cls_index.expand.expand.unsqueeze", "hidden_states.size", "cls_index.expand.expand.dim"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "hidden_states", ",", "cls_index", "=", "None", ")", ":", "\n", "        ", "\"\"\" hidden_states: float Tensor in shape [bsz, seq_len, hidden_size], the hidden-states of the last layer.\n            cls_index: [optional] position of the classification token if summary_type == 'cls_index',\n                shape (bsz,) or more generally (bsz, ...) where ... are optional leading dimensions of hidden_states.\n                if summary_type == 'cls_index' and cls_index is None:\n                    we take the last token of the sequence as classification token\n        \"\"\"", "\n", "if", "self", ".", "summary_type", "==", "'last'", ":", "\n", "            ", "output", "=", "hidden_states", "[", ":", ",", "-", "1", "]", "\n", "", "elif", "self", ".", "summary_type", "==", "'first'", ":", "\n", "            ", "output", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "", "elif", "self", ".", "summary_type", "==", "'mean'", ":", "\n", "            ", "output", "=", "hidden_states", ".", "mean", "(", "dim", "=", "1", ")", "\n", "", "elif", "self", ".", "summary_type", "==", "'cls_index'", ":", "\n", "            ", "if", "cls_index", "is", "None", ":", "\n", "                ", "cls_index", "=", "torch", ".", "full_like", "(", "hidden_states", "[", "...", ",", ":", "1", ",", ":", "]", ",", "hidden_states", ".", "shape", "[", "-", "2", "]", "-", "1", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "else", ":", "\n", "                ", "cls_index", "=", "cls_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "cls_index", "=", "cls_index", ".", "expand", "(", "(", "-", "1", ",", ")", "*", "(", "cls_index", ".", "dim", "(", ")", "-", "1", ")", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", ")", "\n", "# shape of cls_index: (bsz, XX, 1, hidden_size) where XX are optional leading dim of hidden_states", "\n", "", "output", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "cls_index", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, XX, hidden_size)", "\n", "", "elif", "self", ".", "summary_type", "==", "'attn'", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "output", "=", "self", ".", "first_dropout", "(", "output", ")", "\n", "output", "=", "self", ".", "summary", "(", "output", ")", "\n", "output", "=", "self", ".", "activation", "(", "output", ")", "\n", "output", "=", "self", ".", "last_dropout", "(", "output", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.prune_linear_layer": [[919, 942], ["index.to.to", "layer.weight.index_select().clone().detach", "list", "len", "torch.nn.Linear().to", "nn.Linear().to.weight.copy_", "layer.weight.size", "layer.weight.index_select().clone().detach.contiguous", "nn.Linear().to.bias.copy_", "layer.weight.index_select().clone", "layer.bias.clone().detach", "layer.bias[].clone().detach", "torch.nn.Linear", "layer.bias[].clone().detach.contiguous", "layer.weight.index_select", "layer.bias.clone", "layer.bias[].clone"], "function", ["None"], ["", "", "def", "prune_linear_layer", "(", "layer", ",", "index", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\" Prune a linear layer (a model parameters) to keep only entries in index.\n        Return the pruned layer as a new layer with requires_grad=True.\n        Used to remove heads.\n    \"\"\"", "\n", "index", "=", "index", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "W", "=", "layer", ".", "weight", ".", "index_select", "(", "dim", ",", "index", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "if", "layer", ".", "bias", "is", "not", "None", ":", "\n", "        ", "if", "dim", "==", "1", ":", "\n", "            ", "b", "=", "layer", ".", "bias", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "            ", "b", "=", "layer", ".", "bias", "[", "index", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "", "new_size", "=", "list", "(", "layer", ".", "weight", ".", "size", "(", ")", ")", "\n", "new_size", "[", "dim", "]", "=", "len", "(", "index", ")", "\n", "new_layer", "=", "nn", ".", "Linear", "(", "new_size", "[", "1", "]", ",", "new_size", "[", "0", "]", ",", "bias", "=", "layer", ".", "bias", "is", "not", "None", ")", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "weight", ".", "copy_", "(", "W", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "True", "\n", "if", "layer", ".", "bias", "is", "not", "None", ":", "\n", "        ", "new_layer", ".", "bias", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "bias", ".", "copy_", "(", "b", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "bias", ".", "requires_grad", "=", "True", "\n", "", "return", "new_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.prune_conv1d_layer": [[944, 966], ["index.to.to", "layer.weight.index_select().clone().detach", "list", "len", "Conv1D().to", "Conv1D().to.weight.copy_", "Conv1D().to.bias.copy_", "layer.bias.clone().detach", "layer.bias[].clone().detach", "layer.weight.size", "layer.weight.index_select().clone().detach.contiguous", "layer.bias[].clone().detach.contiguous", "layer.weight.index_select().clone", "modeling_utils.Conv1D", "layer.bias.clone", "layer.bias[].clone", "layer.weight.index_select"], "function", ["None"], ["", "def", "prune_conv1d_layer", "(", "layer", ",", "index", ",", "dim", "=", "1", ")", ":", "\n", "    ", "\"\"\" Prune a Conv1D layer (a model parameters) to keep only entries in index.\n        A Conv1D work as a Linear layer (see e.g. BERT) but the weights are transposed.\n        Return the pruned layer as a new layer with requires_grad=True.\n        Used to remove heads.\n    \"\"\"", "\n", "index", "=", "index", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "W", "=", "layer", ".", "weight", ".", "index_select", "(", "dim", ",", "index", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "if", "dim", "==", "0", ":", "\n", "        ", "b", "=", "layer", ".", "bias", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "        ", "b", "=", "layer", ".", "bias", "[", "index", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "new_size", "=", "list", "(", "layer", ".", "weight", ".", "size", "(", ")", ")", "\n", "new_size", "[", "dim", "]", "=", "len", "(", "index", ")", "\n", "new_layer", "=", "Conv1D", "(", "new_size", "[", "1", "]", ",", "new_size", "[", "0", "]", ")", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "weight", ".", "copy_", "(", "W", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "True", "\n", "new_layer", ".", "bias", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "bias", ".", "copy_", "(", "b", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "bias", ".", "requires_grad", "=", "True", "\n", "return", "new_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.prune_layer": [[968, 979], ["isinstance", "modeling_utils.prune_linear_layer", "isinstance", "modeling_utils.prune_conv1d_layer", "ValueError"], "function", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.prune_conv1d_layer"], ["", "def", "prune_layer", "(", "layer", ",", "index", ",", "dim", "=", "None", ")", ":", "\n", "    ", "\"\"\" Prune a Conv1D or nn.Linear layer (a model parameters) to keep only entries in index.\n        Return the pruned layer as a new layer with requires_grad=True.\n        Used to remove heads.\n    \"\"\"", "\n", "if", "isinstance", "(", "layer", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "return", "prune_linear_layer", "(", "layer", ",", "index", ",", "dim", "=", "0", "if", "dim", "is", "None", "else", "dim", ")", "\n", "", "elif", "isinstance", "(", "layer", ",", "Conv1D", ")", ":", "\n", "        ", "return", "prune_conv1d_layer", "(", "layer", ",", "index", ",", "dim", "=", "1", "if", "dim", "is", "None", "else", "dim", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Can't prune layer of class {}\"", ".", "format", "(", "layer", ".", "__class__", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertConfig.__init__": [[185, 221], ["modeling_utils.PretrainedConfig.__init__", "isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "ValueError", "reader.read"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.askubuntu.askubuntu.AskUbuntuReader.read"], ["def", "__init__", "(", "self", ",", "\n", "vocab_size_or_config_json_file", "=", "30522", ",", "\n", "hidden_size", "=", "768", ",", "\n", "num_hidden_layers", "=", "12", ",", "\n", "num_attention_heads", "=", "12", ",", "\n", "intermediate_size", "=", "3072", ",", "\n", "hidden_act", "=", "\"gelu\"", ",", "\n", "hidden_dropout_prob", "=", "0.1", ",", "\n", "attention_probs_dropout_prob", "=", "0.1", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "type_vocab_size", "=", "2", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "layer_norm_eps", "=", "1e-12", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "BertConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "vocab_size", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_hidden_layers", "=", "num_hidden_layers", "\n", "self", ".", "num_attention_heads", "=", "num_attention_heads", "\n", "self", ".", "hidden_act", "=", "hidden_act", "\n", "self", ".", "intermediate_size", "=", "intermediate_size", "\n", "self", ".", "hidden_dropout_prob", "=", "hidden_dropout_prob", "\n", "self", ".", "attention_probs_dropout_prob", "=", "attention_probs_dropout_prob", "\n", "self", ".", "max_position_embeddings", "=", "max_position_embeddings", "\n", "self", ".", "type_vocab_size", "=", "type_vocab_size", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "self", ".", "layer_norm_eps", "=", "layer_norm_eps", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"First argument must be either a vocabulary size (int)\"", "\n", "\" or the path to a pretrained model config file (str)\"", ")", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertEmbeddings.__init__": [[235, 245], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEmbeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertEmbeddings.forward": [[246, 262], ["input_ids.size", "modeling_bert.BertEmbeddings.word_embeddings", "modeling_bert.BertEmbeddings.position_embeddings", "modeling_bert.BertEmbeddings.token_type_embeddings", "modeling_bert.BertEmbeddings.LayerNorm", "modeling_bert.BertEmbeddings.dropout", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "torch.zeros_like", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ")", ":", "\n", "        ", "seq_length", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "", "words_embeddings", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "words_embeddings", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertSelfAttention.__init__": [[265, 282], ["torch.nn.Module.__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", ")", "\n", "", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertSelfAttention.transpose_for_scores": [[283, 287], ["x.view.view.view", "x.view.view.permute", "x.view.view.size"], "methods", ["None"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertSelfAttention.forward": [[288, 322], ["modeling_bert.BertSelfAttention.query", "modeling_bert.BertSelfAttention.key", "modeling_bert.BertSelfAttention.value", "modeling_bert.BertSelfAttention.transpose_for_scores", "modeling_bert.BertSelfAttention.transpose_for_scores", "modeling_bert.BertSelfAttention.transpose_for_scores", "torch.matmul", "modeling_bert.BertSelfAttention.dropout", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "modeling_bert.BertSelfAttention.transpose", "math.sqrt", "torch.nn.Softmax", "context_layer.view.view.permute", "context_layer.view.view.size"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertSelfAttention.transpose_for_scores"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "# Apply the attention mask is (precomputed for all layers in BertModel forward() function)", "\n", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attention_probs", "=", "attention_probs", "*", "head_mask", "\n", "\n", "", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "\n", "outputs", "=", "(", "context_layer", ",", "attention_probs", ")", "if", "self", ".", "output_attentions", "else", "(", "context_layer", ",", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertSelfOutput.__init__": [[325, 333], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout", "torch.nn.ModuleDict", "dict"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n", "self", ".", "attention_adapters", "=", "nn", ".", "ModuleDict", "(", "dict", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertSelfOutput.forward": [[334, 340], ["modeling_bert.BertSelfOutput.dense", "modeling_bert.BertSelfOutput.dropout", "modeling_bert.BertSelfOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ",", "tasks", "=", "None", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertAttention.__init__": [[343, 348], ["torch.nn.Module.__init__", "modeling_bert.BertSelfAttention", "modeling_bert.BertSelfOutput", "set"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self", "=", "BertSelfAttention", "(", "config", ")", "\n", "self", ".", "output", "=", "BertSelfOutput", "(", "config", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertAttention.prune_heads": [[349, 371], ["torch.ones", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous().eq", "[].long", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_bert.BertAttention.pruned_heads.union", "len", "set", "len", "sum", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous", "torch.arange", "mask.view().contiguous().eq.view().contiguous().eq.view", "len"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.prune_linear_layer"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "mask", "=", "torch", ".", "ones", "(", "self", ".", "self", ".", "num_attention_heads", ",", "self", ".", "self", ".", "attention_head_size", ")", "\n", "heads", "=", "set", "(", "heads", ")", "-", "self", ".", "pruned_heads", "# Convert to set and emove already pruned heads", "\n", "for", "head", "in", "heads", ":", "\n", "# Compute how many pruned heads are before the head and move the index accordingly", "\n", "            ", "head", "=", "head", "-", "sum", "(", "1", "if", "h", "<", "head", "else", "0", "for", "h", "in", "self", ".", "pruned_heads", ")", "\n", "mask", "[", "head", "]", "=", "0", "\n", "", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "contiguous", "(", ")", ".", "eq", "(", "1", ")", "\n", "index", "=", "torch", ".", "arange", "(", "len", "(", "mask", ")", ")", "[", "mask", "]", ".", "long", "(", ")", "\n", "\n", "# Prune linear layers", "\n", "self", ".", "self", ".", "query", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "query", ",", "index", ")", "\n", "self", ".", "self", ".", "key", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "key", ",", "index", ")", "\n", "self", ".", "self", ".", "value", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "value", ",", "index", ")", "\n", "self", ".", "output", ".", "dense", "=", "prune_linear_layer", "(", "self", ".", "output", ".", "dense", ",", "index", ",", "dim", "=", "1", ")", "\n", "\n", "# Update hyper params and store pruned heads", "\n", "self", ".", "self", ".", "num_attention_heads", "=", "self", ".", "self", ".", "num_attention_heads", "-", "len", "(", "heads", ")", "\n", "self", ".", "self", ".", "all_head_size", "=", "self", ".", "self", ".", "attention_head_size", "*", "self", ".", "self", ".", "num_attention_heads", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertAttention.forward": [[372, 377], ["modeling_bert.BertAttention.self", "modeling_bert.BertAttention.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_tensor", ",", "attention_mask", ",", "head_mask", "=", "None", ",", "tasks", "=", "None", ")", ":", "\n", "        ", "self_outputs", "=", "self", ".", "self", "(", "input_tensor", ",", "attention_mask", ",", "head_mask", ")", "\n", "attention_output", "=", "self", ".", "output", "(", "self_outputs", "[", "0", "]", ",", "input_tensor", ",", "tasks", "=", "tasks", ")", "\n", "outputs", "=", "(", "attention_output", ",", ")", "+", "self_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertIntermediate.__init__": [[380, 387], ["torch.nn.Module.__init__", "torch.nn.Linear", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertIntermediate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "intermediate_size", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "config", ".", "hidden_act", ",", "unicode", ")", ")", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "config", ".", "hidden_act", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertIntermediate.forward": [[388, 392], ["modeling_bert.BertIntermediate.dense", "modeling_bert.BertIntermediate.intermediate_act_fn"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "intermediate_act_fn", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertOutput.__init__": [[395, 412], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout", "torch.nn.ModuleDict", "torch.nn.ModuleDict", "hasattr", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n", "self", ".", "bert_adapter_att", "=", "nn", ".", "ModuleDict", "(", "dict", "(", ")", ")", "\n", "\n", "self", ".", "layer_adapters", "=", "nn", ".", "ModuleDict", "(", "dict", "(", ")", ")", "\n", "\n", "self", ".", "adapters_enabled", "=", "False", "\n", "if", "hasattr", "(", "config", ",", "'adapters'", ")", ":", "\n", "            ", "self", ".", "adapters_enabled", "=", "True", "\n", "\n", "# Flag to log warning only once", "\n", "", "self", ".", "adapter_tasks_none_warning_issued", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertOutput.add_attention_layer": [[413, 422], ["isinstance", "task_names.split", "adapter.BertAdapterAttention", "Exception"], "methods", ["None"], ["", "def", "add_attention_layer", "(", "self", ",", "task_names", ",", "attention_type", ")", ":", "\n", "        ", "\"\"\"See BertModel.add_attention_layer\"\"\"", "\n", "task_names", "=", "task_names", "if", "isinstance", "(", "task_names", ",", "list", ")", "else", "task_names", ".", "split", "(", "'_'", ")", "\n", "if", "attention_type", "==", "'tok-lvl'", ":", "\n", "            ", "layer", "=", "BertAdapterAttention", "(", "self", ".", "config", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unknown attention type: {}'", ".", "format", "(", "attention_type", ")", ")", "\n", "\n", "", "self", ".", "bert_adapter_att", "[", "'_'", ".", "join", "(", "task_names", ")", "]", "=", "layer", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertOutput.add_adapter": [[423, 425], ["adapter.Adapter"], "methods", ["None"], ["", "def", "add_adapter", "(", "self", ",", "task_name", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "self", ".", "layer_adapters", "[", "task_name", "]", "=", "adapter", ".", "Adapter", "(", "self", ".", "config", ".", "hidden_size", ",", "down_sample", "=", "downsample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertOutput.disable_adapters": [[426, 428], ["None"], "methods", ["None"], ["", "def", "disable_adapters", "(", "self", ")", ":", "\n", "        ", "self", ".", "adapters_enabled", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertOutput.enable_adapters": [[429, 444], ["modeling_bert.BertOutput.layer_adapters.parameters", "modeling_bert.BertOutput.layer_adapters.values", "modeling_bert.BertOutput.bert_adapter_att.parameters", "adap.adapter_attention.parameters"], "methods", ["None"], ["", "def", "enable_adapters", "(", "self", ",", "unfreeze_adapters", ",", "unfreeze_attention", ")", ":", "\n", "        ", "self", ".", "adapters_enabled", "=", "True", "\n", "if", "unfreeze_adapters", ":", "\n", "            ", "for", "param", "in", "self", ".", "layer_adapters", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "True", "\n", "", "", "if", "unfreeze_attention", ":", "\n", "            ", "for", "adap", "in", "self", ".", "layer_adapters", ".", "values", "(", ")", ":", "\n", "                ", "for", "param", "in", "adap", ".", "adapter_attention", ".", "parameters", "(", ")", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "True", "\n", "\n", "# for param in self.attention_layer_norm.parameters():", "\n", "#     param.requires_grad = True", "\n", "\n", "", "", "for", "param", "in", "self", ".", "bert_adapter_att", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertOutput.forward": [[445, 501], ["modeling_bert.BertOutput.dense", "modeling_bert.BertOutput.dropout", "modeling_bert.BertOutput.LayerNorm", "up.detach().cpu().numpy", "modeling_bert.BertOutput.LayerNorm", "modeling_bert.BertOutput.detach().cpu().numpy", "modeling_bert.BertOutput.LayerNorm", "len", "torch.stack", "layer_output_list.permute.permute.permute", "torch.stack", "down_list.permute.permute.permute", "torch.stack", "up_list.permute.permute.permute", "logger.warning", "layer_output_list.permute.permute.append", "down_list.permute.permute.append", "up_list.permute.permute.append", "Exception", "up.detach().cpu", "modeling_bert.BertOutput.detach().cpu", "up.detach", "modeling_bert.BertOutput.detach"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ",", "attention_mask", ",", "tasks", "=", "None", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "residual", "=", "hidden_states", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "\n", "if", "not", "self", ".", "adapters_enabled", ":", "\n", "            ", "return", "hidden_states", "\n", "", "else", ":", "\n", "            ", "if", "tasks", "is", "None", ":", "\n", "                ", "if", "not", "self", ".", "adapter_tasks_none_warning_issued", ":", "\n", "                    ", "logger", ".", "warning", "(", "'No tasks given, but adapters are active. Using standard BERT. Deactivate adapters?'", ")", "\n", "self", ".", "adapter_tasks_none_warning_issued", "=", "True", "\n", "", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n", "", "if", "len", "(", "tasks", ")", ">", "1", ":", "\n", "# we use adapter attention", "\n", "                ", "layer_output_list", ",", "down_list", ",", "up_list", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "task", "in", "tasks", ":", "\n", "                    ", "intermediate_output", ",", "adapter_attention", ",", "down", ",", "up", "=", "self", ".", "layer_adapters", "[", "task", "]", "(", "\n", "hidden_states", ",", "residual_input", "=", "residual", "\n", ")", "\n", "layer_output_list", ".", "append", "(", "intermediate_output", ")", "\n", "down_list", ".", "append", "(", "down", ")", "\n", "up_list", ".", "append", "(", "up", ")", "\n", "\n", "", "layer_output_list", "=", "torch", ".", "stack", "(", "layer_output_list", ")", "\n", "layer_output_list", "=", "layer_output_list", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ")", "\n", "down_list", "=", "torch", ".", "stack", "(", "down_list", ")", "\n", "down_list", "=", "down_list", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ")", "\n", "up_list", "=", "torch", ".", "stack", "(", "up_list", ")", "\n", "up_list", "=", "up_list", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ")", "\n", "\n", "attn_name", "=", "'_'", ".", "join", "(", "tasks", ")", "\n", "if", "attn_name", "not", "in", "self", ".", "bert_adapter_att", ":", "\n", "                    ", "raise", "Exception", "(", "'{} attention layer does not exist'", ".", "format", "(", "attn_name", ")", ")", "\n", "# attn_name = list(self.bert_adapter_att.keys())[0]", "\n", "\n", "", "hidden_states", "=", "self", ".", "bert_adapter_att", "[", "attn_name", "]", "(", "hidden_states", ",", "up_list", ",", "up_list", ",", "residual", "=", "residual", ",", "\n", "attention_mask", "=", "attention_mask", ")", "\n", "\n", "", "else", ":", "\n", "# we use only one task adapter without attention", "\n", "                ", "hidden_states", ",", "adapter_attention", ",", "down", ",", "up", "=", "self", ".", "layer_adapters", "[", "tasks", "[", "0", "]", "]", "(", "\n", "hidden_states", ",", "\n", "residual_input", "=", "residual", "\n", ")", "\n", "\n", "", "self", ".", "adapter_output_representation", "=", "up", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "\n", "self", ".", "bert_output_representation", "=", "hidden_states", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertLayer.__init__": [[504, 509], ["torch.nn.Module.__init__", "modeling_bert.BertAttention", "modeling_bert.BertIntermediate", "modeling_bert.BertOutput"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention", "=", "BertAttention", "(", "config", ")", "\n", "self", ".", "intermediate", "=", "BertIntermediate", "(", "config", ")", "\n", "self", ".", "output", "=", "BertOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertLayer.add_attention_layer": [[510, 512], ["modeling_bert.BertLayer.output.add_attention_layer"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.add_attention_layer"], ["", "def", "add_attention_layer", "(", "self", ",", "task_names", ",", "attention_type", ")", ":", "\n", "        ", "self", ".", "output", ".", "add_attention_layer", "(", "task_names", ",", "attention_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertLayer.add_adapter": [[513, 515], ["modeling_bert.BertLayer.output.add_adapter"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.add_adapter"], ["", "def", "add_adapter", "(", "self", ",", "task_name", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "self", ".", "output", ".", "add_adapter", "(", "task_name", ",", "downsample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertLayer.disable_adapters": [[516, 518], ["modeling_bert.BertLayer.output.disable_adapters"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.disable_adapters"], ["", "def", "disable_adapters", "(", "self", ")", ":", "\n", "        ", "self", ".", "output", ".", "disable_adapters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertLayer.enable_adapters": [[519, 521], ["modeling_bert.BertLayer.output.enable_adapters"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.enable_adapters"], ["", "def", "enable_adapters", "(", "self", ",", "unfreeze_adapters", ",", "unfreeze_attention", ")", ":", "\n", "        ", "self", ".", "output", ".", "enable_adapters", "(", "unfreeze_adapters", ",", "unfreeze_attention", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertLayer.forward": [[522, 531], ["modeling_bert.BertLayer.attention", "modeling_bert.BertLayer.intermediate", "modeling_bert.BertLayer.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "None", ",", "tasks", "=", "None", ")", ":", "\n", "        ", "attention_outputs", "=", "self", ".", "attention", "(", "hidden_states", ",", "attention_mask", ",", "head_mask", ",", "tasks", "=", "tasks", ")", "\n", "attention_output", "=", "attention_outputs", "[", "0", "]", "\n", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "\n", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ",", "attention_mask", ",", "tasks", "=", "tasks", ")", "\n", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "attention_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertEncoder.__init__": [[534, 539], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "modeling_bert.BertLayer", "range"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "BertLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertEncoder.add_attention_layer": [[540, 543], ["layer.add_attention_layer"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.add_attention_layer"], ["", "def", "add_attention_layer", "(", "self", ",", "task_names", ",", "attention_type", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layer", ":", "\n", "            ", "layer", ".", "add_attention_layer", "(", "task_names", ",", "attention_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertEncoder.add_adapter": [[544, 547], ["layer.add_adapter"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.add_adapter"], ["", "", "def", "add_adapter", "(", "self", ",", "task_name", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layer", ":", "\n", "            ", "layer", ".", "add_adapter", "(", "task_name", ",", "downsample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertEncoder.disable_adapters": [[548, 551], ["layer.disable_adapters"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.disable_adapters"], ["", "", "def", "disable_adapters", "(", "self", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layer", ":", "\n", "            ", "layer", ".", "disable_adapters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertEncoder.enable_adapters": [[552, 555], ["layer.enable_adapters"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.enable_adapters"], ["", "", "def", "enable_adapters", "(", "self", ",", "unfreeze_adapters", ",", "unfreeze_attention", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layer", ":", "\n", "            ", "layer", ".", "enable_adapters", "(", "unfreeze_adapters", ",", "unfreeze_attention", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertEncoder.forward": [[556, 579], ["enumerate", "layer_module"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "None", ",", "tasks", "=", "None", ")", ":", "\n", "        ", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "(", ")", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "layer_outputs", "=", "layer_module", "(", "hidden_states", ",", "attention_mask", ",", "head_mask", "[", "i", "]", ",", "tasks", "=", "tasks", ")", "\n", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "\n", "# Add last layer", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last-layer hidden state, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertPooler.__init__": [[582, 586], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPooler", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertPooler.forward": [[587, 594], ["modeling_bert.BertPooler.dense", "modeling_bert.BertPooler.activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "# We \"pool\" the model by simply taking the hidden state corresponding", "\n", "# to the first token.", "\n", "        ", "first_token_tensor", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "pooled_output", "=", "self", ".", "dense", "(", "first_token_tensor", ")", "\n", "pooled_output", "=", "self", ".", "activation", "(", "pooled_output", ")", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertPredictionHeadTransform.__init__": [[597, 605], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPredictionHeadTransform", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "config", ".", "hidden_act", ",", "unicode", ")", ")", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "config", ".", "hidden_act", "\n", "", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertPredictionHeadTransform.forward": [[606, 611], ["modeling_bert.BertPredictionHeadTransform.dense", "modeling_bert.BertPredictionHeadTransform.transform_act_fn", "modeling_bert.BertPredictionHeadTransform.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "transform_act_fn", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertLMPredictionHead.__init__": [[614, 625], ["torch.nn.Module.__init__", "modeling_bert.BertPredictionHeadTransform", "torch.nn.Linear", "torch.nn.Parameter", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertLMPredictionHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "BertPredictionHeadTransform", "(", "config", ")", "\n", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "\n", "config", ".", "vocab_size", ",", "\n", "bias", "=", "False", ")", "\n", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "config", ".", "vocab_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertLMPredictionHead.forward": [[626, 630], ["modeling_bert.BertLMPredictionHead.transform", "modeling_bert.BertLMPredictionHead.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "transform", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "decoder", "(", "hidden_states", ")", "+", "self", ".", "bias", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertOnlyMLMHead.__init__": [[633, 636], ["torch.nn.Module.__init__", "modeling_bert.BertLMPredictionHead"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOnlyMLMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertOnlyMLMHead.forward": [[637, 640], ["modeling_bert.BertOnlyMLMHead.predictions"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "return", "prediction_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertOnlyNSPHead.__init__": [[643, 646], ["torch.nn.Module.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOnlyNSPHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertOnlyNSPHead.forward": [[647, 650], ["modeling_bert.BertOnlyNSPHead.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pooled_output", ")", ":", "\n", "        ", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertPreTrainingHeads.__init__": [[653, 657], ["torch.nn.Module.__init__", "modeling_bert.BertLMPredictionHead", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPreTrainingHeads", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertPreTrainingHeads.forward": [[658, 662], ["modeling_bert.BertPreTrainingHeads.predictions", "modeling_bert.BertPreTrainingHeads.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ",", "pooled_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "prediction_scores", ",", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertPreTrainedModel._init_weights": [[673, 684], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "BertLayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.__init__": [[782, 798], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertEmbeddings", "modeling_bert.BertEncoder", "modeling_bert.BertPooler", "hasattr", "hasattr", "modeling_bert.BertModel.init_weights", "modeling_bert.BertModel.encoder.add_adapter", "modeling_bert.BertModel.encoder.add_attention_layer"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel.init_weights", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.add_adapter", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.add_attention_layer"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "embeddings", "=", "BertEmbeddings", "(", "config", ")", "\n", "self", ".", "encoder", "=", "BertEncoder", "(", "config", ")", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "\n", "if", "hasattr", "(", "config", ",", "'adapters'", ")", ":", "\n", "            ", "for", "task", "in", "config", ".", "adapters", ":", "\n", "                ", "self", ".", "encoder", ".", "add_adapter", "(", "task", ",", "self", ".", "config", ".", "adapter_downsample", ")", "\n", "\n", "", "", "if", "hasattr", "(", "config", ",", "'adapter_attention'", ")", ":", "\n", "            ", "for", "task_names", "in", "config", ".", "adapter_attention", ":", "\n", "                ", "self", ".", "encoder", ".", "add_attention_layer", "(", "task_names", ",", "self", ".", "config", ".", "adapter_attention_type", ")", "\n", "\n", "", "", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.add_attention_layer": [[799, 825], ["modeling_bert.BertModel.encoder.add_attention_layer", "modeling_bert.BertModel.config.adapter_attention.append", "hasattr"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.add_attention_layer"], ["", "def", "add_attention_layer", "(", "self", ",", "task_names", ",", "attention_type", ")", ":", "\n", "        ", "\"\"\"Adds a new attention layer for specified tasks\n\n        :param task_names:\n        :return:\n        \"\"\"", "\n", "# todo configure externally", "\n", "self", ".", "config", ".", "fusion_config", "=", "{", "}", "\n", "self", ".", "config", ".", "fusion_config", "[", "'key'", "]", "=", "True", "\n", "self", ".", "config", ".", "fusion_config", "[", "'query'", "]", "=", "True", "\n", "self", ".", "config", ".", "fusion_config", "[", "'query_before_ln'", "]", "=", "False", "\n", "self", ".", "config", ".", "fusion_config", "[", "'regularization'", "]", "=", "True", "\n", "self", ".", "config", ".", "fusion_config", "[", "'residual_before'", "]", "=", "False", "\n", "self", ".", "config", ".", "fusion_config", "[", "'temperature'", "]", "=", "False", "\n", "# self.config.fusion_config['value'] = True", "\n", "self", ".", "config", ".", "fusion_config", "[", "'value'", "]", "=", "False", "\n", "self", ".", "config", ".", "fusion_config", "[", "'value_before_softmax'", "]", "=", "True", "\n", "self", ".", "config", ".", "fusion_config", "[", "'value_initialized'", "]", "=", "True", "\n", "\n", "self", ".", "encoder", ".", "add_attention_layer", "(", "task_names", ",", "attention_type", ")", "\n", "if", "not", "hasattr", "(", "self", ".", "config", ",", "'adapter_attention'", ")", ":", "\n", "            ", "self", ".", "config", ".", "adapter_attention", "=", "[", "]", "\n", "self", ".", "config", ".", "adapter_attention_type", "=", "attention_type", "\n", "\n", "", "assert", "attention_type", "==", "self", ".", "config", ".", "adapter_attention_type", "\n", "self", ".", "config", ".", "adapter_attention", ".", "append", "(", "task_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.add_adapter": [[826, 838], ["modeling_bert.BertModel.encoder.add_adapter", "modeling_bert.BertModel.config.adapters.append", "hasattr"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.add_adapter"], ["", "def", "add_adapter", "(", "self", ",", "task_name", ",", "downsample", ")", ":", "\n", "        ", "\"\"\"Adds a new adapter to the network\n\n        :param task_name: the adapter task\n        :param downsample: the downsampling factor (1 = equal size bottleneck, 2=1/2 size bottleneck etc.)\n        \"\"\"", "\n", "self", ".", "encoder", ".", "add_adapter", "(", "task_name", ",", "downsample", ")", "\n", "if", "not", "hasattr", "(", "self", ".", "config", ",", "'adapters'", ")", ":", "\n", "            ", "self", ".", "config", ".", "adapters", "=", "[", "]", "\n", "self", ".", "config", ".", "adapter_downsample", "=", "downsample", "\n", "", "assert", "self", ".", "config", ".", "adapter_downsample", "==", "downsample", "\n", "self", ".", "config", ".", "adapters", ".", "append", "(", "task_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.enable_adapters": [[839, 841], ["modeling_bert.BertModel.encoder.enable_adapters"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.enable_adapters"], ["", "def", "enable_adapters", "(", "self", ",", "unfreeze_adapters", ",", "unfreeze_attention", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "enable_adapters", "(", "unfreeze_adapters", ",", "unfreeze_attention", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.disable_adapters": [[842, 844], ["modeling_bert.BertModel.encoder.disable_adapters"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.disable_adapters"], ["", "def", "disable_adapters", "(", "self", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "disable_adapters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel._resize_token_embeddings": [[845, 850], ["modeling_bert.BertModel._get_resized_embeddings"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel._get_resized_embeddings"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "old_embeddings", "=", "self", ".", "embeddings", ".", "word_embeddings", "\n", "new_embeddings", "=", "self", ".", "_get_resized_embeddings", "(", "old_embeddings", ",", "new_num_tokens", ")", "\n", "self", ".", "embeddings", ".", "word_embeddings", "=", "new_embeddings", "\n", "return", "self", ".", "embeddings", ".", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel._prune_heads": [[851, 858], ["heads_to_prune.items", "modeling_bert.BertModel.encoder.layer[].attention.prune_heads"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertAttention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n            See base class PreTrainedModel\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertModel.forward": [[859, 911], ["torch.ones_like.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "modeling_bert.BertModel.embeddings", "modeling_bert.BertModel.encoder", "modeling_bert.BertModel.pooler", "torch.ones_like", "torch.zeros_like", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "set", "set", "len", "Exception", "torch.ones_like.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "modeling_bert.BertModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "list", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_bert.BertModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "\n", "tasks", "=", "None", ")", ":", "\n", "        ", "if", "tasks", "is", "not", "None", ":", "\n", "            ", "tasks_not_in_model", "=", "set", "(", "tasks", ")", "-", "set", "(", "self", ".", "config", ".", "adapters", ")", "\n", "if", "len", "(", "tasks_not_in_model", ")", ">", "0", ":", "\n", "                ", "raise", "Exception", "(", "'Adapters not found: {}'", ".", "format", "(", "', '", ".", "join", "(", "list", "(", "tasks_not_in_model", ")", ")", ")", ")", "\n", "\n", "", "", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones_like", "(", "input_ids", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "num_hidden_layers", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "\n", "-", "1", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "num_hidden_layers", "\n", "\n", "", "embedding_output", "=", "self", ".", "embeddings", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ")", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "embedding_output", ",", "extended_attention_mask", ",", "head_mask", "=", "head_mask", ",", "tasks", "=", "tasks", ")", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "sequence_output", ",", "pooled_output", ",", ")", "+", "encoder_outputs", "[", "\n", "1", ":", "]", "# add hidden_states and attentions if they are here", "\n", "return", "outputs", "# sequence_output, pooled_output, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertForPreTraining.__init__": [[954, 962], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "modeling_bert.BertPreTrainingHeads", "modeling_bert.BertForPreTraining.init_weights", "modeling_bert.BertForPreTraining.tie_weights"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel.init_weights", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertForMaskedLM.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForPreTraining", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertPreTrainingHeads", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertForPreTraining.tie_weights": [[963, 969], ["modeling_bert.BertForPreTraining._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "cls", ".", "predictions", ".", "decoder", ",", "\n", "self", ".", "bert", ".", "embeddings", ".", "word_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertForPreTraining.forward": [[970, 989], ["modeling_bert.BertForPreTraining.bert", "modeling_bert.BertForPreTraining.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "prediction_scores.view", "masked_lm_labels.view", "seq_relationship_score.view", "next_sentence_label.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "masked_lm_labels", "=", "None", ",", "\n", "next_sentence_label", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "outputs", "[", ":", "2", "]", "\n", "prediction_scores", ",", "seq_relationship_score", "=", "self", ".", "cls", "(", "sequence_output", ",", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", "seq_relationship_score", ",", ")", "+", "outputs", "[", "\n", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "masked_lm_labels", "is", "not", "None", "and", "next_sentence_label", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "next_sentence_loss", "=", "loss_fct", "(", "seq_relationship_score", ".", "view", "(", "-", "1", ",", "2", ")", ",", "next_sentence_label", ".", "view", "(", "-", "1", ")", ")", "\n", "total_loss", "=", "masked_lm_loss", "+", "next_sentence_loss", "\n", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), prediction_scores, seq_relationship_score, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertForMaskedLM.__init__": [[1024, 1032], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "modeling_bert.BertOnlyMLMHead", "modeling_bert.BertForMaskedLM.init_weights", "modeling_bert.BertForMaskedLM.tie_weights"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel.init_weights", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertForMaskedLM.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyMLMHead", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertForMaskedLM.tie_weights": [[1033, 1039], ["modeling_bert.BertForMaskedLM._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "cls", ".", "predictions", ".", "decoder", ",", "\n", "self", ".", "bert", ".", "embeddings", ".", "word_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertForMaskedLM.forward": [[1040, 1055], ["modeling_bert.BertForMaskedLM.bert", "modeling_bert.BertForMaskedLM.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_bert.BertForMaskedLM.view", "masked_lm_labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "masked_lm_labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "cls", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "# Add hidden states and attention if they are here", "\n", "if", "masked_lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "masked_lm_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (masked_lm_loss), prediction_scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertForNextSentencePrediction.__init__": [[1090, 1097], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "modeling_bert.BertOnlyNSPHead", "modeling_bert.BertForNextSentencePrediction.init_weights"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForNextSentencePrediction", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyNSPHead", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertForNextSentencePrediction.forward": [[1098, 1113], ["modeling_bert.BertForNextSentencePrediction.bert", "modeling_bert.BertForNextSentencePrediction.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_bert.BertForNextSentencePrediction.view", "next_sentence_label.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "next_sentence_label", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "seq_relationship_score", "=", "self", ".", "cls", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "seq_relationship_score", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "if", "next_sentence_label", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "next_sentence_loss", "=", "loss_fct", "(", "seq_relationship_score", ".", "view", "(", "-", "1", ",", "2", ")", ",", "next_sentence_label", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "next_sentence_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (next_sentence_loss), seq_relationship_score, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertForSequenceClassification.__init__": [[1150, 1159], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling_bert.BertForSequenceClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertForSequenceClassification.forward": [[1160, 1182], ["modeling_bert.BertForSequenceClassification.bert", "modeling_bert.BertForSequenceClassification.dropout", "modeling_bert.BertForSequenceClassification.classifier", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_bert.BertForSequenceClassification.view", "labels.view", "modeling_bert.BertForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertForMultipleChoice.__init__": [[1256, 1264], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling_bert.BertForMultipleChoice.init_weights"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForMultipleChoice", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertForMultipleChoice.forward": [[1265, 1289], ["input_ids.view", "modeling_bert.BertForMultipleChoice.bert", "modeling_bert.BertForMultipleChoice.dropout", "modeling_bert.BertForMultipleChoice.classifier", "modeling_bert.BertForMultipleChoice.view", "input_ids.size", "position_ids.view", "token_type_ids.view", "attention_mask.view", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "position_ids.size", "token_type_ids.size", "attention_mask.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "num_choices", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "\n", "flat_input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "position_ids", ".", "size", "(", "-", "1", ")", ")", "if", "position_ids", "is", "not", "None", "else", "None", "\n", "flat_token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "flat_attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "outputs", "=", "self", ".", "bert", "(", "flat_input_ids", ",", "position_ids", "=", "flat_position_ids", ",", "token_type_ids", "=", "flat_token_type_ids", ",", "\n", "attention_mask", "=", "flat_attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "reshaped_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "num_choices", ")", "\n", "\n", "outputs", "=", "(", "reshaped_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), reshaped_logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertForTokenClassification.__init__": [[1324, 1333], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling_bert.BertForTokenClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertForTokenClassification.forward": [[1334, 1357], ["modeling_bert.BertForTokenClassification.bert", "modeling_bert.BertForTokenClassification.dropout", "modeling_bert.BertForTokenClassification.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "attention_mask.view", "modeling_bert.BertForTokenClassification.view", "labels.view", "modeling_bert.BertForTokenClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "[", "active_loss", "]", "\n", "active_labels", "=", "labels", ".", "view", "(", "-", "1", ")", "[", "active_loss", "]", "\n", "loss", "=", "loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertForQuestionAnswering.__init__": [[1400, 1408], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "torch.nn.Linear", "modeling_bert.BertForQuestionAnswering.init_weights"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.BertForQuestionAnswering.forward": [[1409, 1439], ["modeling_bert.BertForQuestionAnswering.bert", "modeling_bert.BertForQuestionAnswering.qa_outputs", "modeling_bert.BertForQuestionAnswering.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "start_positions", "=", "None", ",", "\n", "end_positions", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), start_logits, end_logits, (hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.load_tf_weights_in_bert": [[71, 136], ["os.path.abspath", "logger.info", "tf.train.list_variables", "zip", "logger.info", "tf.train.load_variable", "names.append", "arrays.append", "name.split.split", "any", "logger.info", "torch.from_numpy", "logger.error", "logger.info", "re.fullmatch", "getattr", "re.split", "getattr", "len", "int", "np.transpose", "getattr", "getattr", "getattr", "getattr", "logger.info"], "function", ["None"], ["def", "load_tf_weights_in_bert", "(", "model", ",", "config", ",", "tf_checkpoint_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "\"Converting TensorFlow checkpoint from {}\"", ".", "format", "(", "tf_path", ")", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ")", "\n", "\n", "", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "name", "=", "name", ".", "split", "(", "'/'", ")", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "any", "(", "n", "in", "[", "\"adam_v\"", ",", "\"adam_m\"", ",", "\"global_step\"", "]", "for", "n", "in", "name", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "continue", "\n", "", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r'[A-Za-z]+_\\d+'", ",", "m_name", ")", ":", "\n", "                ", "l", "=", "re", ".", "split", "(", "r'_(\\d+)'", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "l", "=", "[", "m_name", "]", "\n", "", "if", "l", "[", "0", "]", "==", "'kernel'", "or", "l", "[", "0", "]", "==", "'gamma'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'output_bias'", "or", "l", "[", "0", "]", "==", "'beta'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'bias'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'output_weights'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'squad'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'classifier'", ")", "\n", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "pointer", "=", "getattr", "(", "pointer", ",", "l", "[", "0", "]", ")", "\n", "", "except", "AttributeError", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "continue", "\n", "", "", "if", "len", "(", "l", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "l", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "if", "m_name", "[", "-", "11", ":", "]", "==", "'_embeddings'", ":", "\n", "            ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "m_name", "==", "'kernel'", ":", "\n", "            ", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.gelu": [[138, 145], ["torch.erf", "math.sqrt"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\"Implementation of the gelu activation function.\n        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "return", "x", "*", "0.5", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.bert_models.modeling_bert.swish": [[147, 149], ["torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_train_data_standard.SEDataReader.__init__": [[53, 58], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_file_path", ")", ":", "\n", "        ", "\"\"\"\n        data_file_path : (string) path to the posts.xml file\n        \"\"\"", "\n", "self", ".", "data_file_path", "=", "data_file_path", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_train_data_standard.SEDataReader.question_data_filter": [[59, 62], ["dict", "sample.get"], "methods", ["None"], ["", "def", "question_data_filter", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "dict", "(", "(", "k", ",", "sample", ".", "get", "(", "k", ",", "None", ")", ")", "for", "k", "in", "\n", "[", "'Id'", ",", "'Title'", ",", "'Body'", ",", "'Tags'", ",", "'ParentId'", ",", "'PostTypeId'", ",", "'AcceptedAnswerId'", ",", "'Score'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_train_data_standard.SEDataReader.n_items_unfiltered": [[63, 66], ["subprocess.check_output", "int", "subprocess.check_output.split"], "methods", ["None"], ["", "def", "n_items_unfiltered", "(", "self", ")", ":", "\n", "        ", "out", "=", "subprocess", ".", "check_output", "(", "[", "'wc'", ",", "'-l'", ",", "self", ".", "data_file_path", "]", ")", "\n", "return", "int", "(", "out", ".", "split", "(", ")", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_train_data_standard.SEDataReader.read_items": [[67, 88], ["io.open", "tqdm", "tqdm.tqdm", "tqdm.tqdm", "tqdm.tqdm.tqdm", "xml.fromstring", "logger.info", "int", "create_train_data_standard.SEDataReader.question_data_filter", "l.strip", "int", "l.strip"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.question_data_filter"], ["", "def", "read_items", "(", "self", ",", "allowed_post_types", "=", "(", "POST_TYPE_QUESTION", ",", ")", ",", "min_score", "=", "0", ",", "max_year", "=", "None", ")", ":", "\n", "        ", "with", "io", ".", "open", "(", "self", ".", "data_file_path", ",", "'r'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "for", "l", "in", "tqdm", "(", "f", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "sample", "=", "ET", ".", "fromstring", "(", "l", ".", "strip", "(", ")", ")", ".", "attrib", "\n", "", "except", "ET", ".", "ParseError", "as", "e", ":", "\n", "                    ", "logger", ".", "info", "(", "'(Ignoring) ERROR in parsing line (QUESTION READER):\\n{}\\n'", ".", "format", "(", "l", ".", "strip", "(", ")", ")", ")", "\n", "sample", "=", "None", "\n", "", "if", "sample", ":", "\n", "                    ", "has_min_score", "=", "int", "(", "sample", "[", "'Score'", "]", ")", ">=", "min_score", "\n", "has_max_year", "=", "True", "if", "max_year", "is", "None", "else", "int", "(", "sample", "[", "'CreationDate'", "]", "[", ":", "4", "]", ")", "<=", "max_year", "\n", "\n", "if", "sample", "[", "'PostTypeId'", "]", "in", "allowed_post_types", "and", "has_max_year", "and", "has_min_score", ":", "\n", "                        ", "SEDataReader", ".", "num_retrieved", "+=", "1", "\n", "filtered_sample", "=", "self", ".", "question_data_filter", "(", "sample", ")", "\n", "yield", "filtered_sample", "\n", "", "else", ":", "\n", "                        ", "SEDataReader", ".", "num_skipped_other_posttype", "+=", "1", "\n", "\n", "", "", "else", ":", "\n", "                    ", "SEDataReader", ".", "num_skipped_sample_none", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_train_data_standard._clean_text": [[90, 96], ["bs4.BeautifulSoup", "res.replace.replace", "res.replace.replace", "i.splitlines"], "function", ["None"], ["", "", "", "", "", "def", "_clean_text", "(", "t", ")", ":", "\n", "    ", "soup", "=", "BeautifulSoup", "(", "t", ",", "'lxml'", ")", "\n", "res", "=", "' '", ".", "join", "(", "[", "''", ".", "join", "(", "i", ".", "splitlines", "(", ")", ")", "for", "i", "in", "soup", ".", "strings", "]", ")", "\n", "res", "=", "res", ".", "replace", "(", "u\"\\\\'\"", ",", "u\" '\"", ")", "\n", "res", "=", "res", ".", "replace", "(", "u'\\t'", ",", "u''", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_train_data_standard.read_questions": [[98, 130], ["logger.info", "create_train_data_standard.SEDataReader", "create_train_data_standard.SEDataReader.read_items", "set", "logger.info", "nltk.corpus.stopwords.words", "item.get", "item.get", "item.get", "item.get.lower().split", "item.get.lower().split", "questionids.append", "logger.debug", "item.get.lower", "item.get.lower", "len", "len", "len", "len", "set", "set"], "function", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.read_items"], ["", "def", "read_questions", "(", "path", ")", ":", "\n", "    ", "logger", ".", "info", "(", "'Reading questions'", ")", "\n", "reader", "=", "SEDataReader", "(", "path", "+", "\"/Posts.xml\"", ")", "\n", "r", "=", "reader", ".", "read_items", "(", "POST_TYPE_QUESTION", ")", "\n", "\n", "questiondict", "=", "{", "}", "\n", "questionids", "=", "[", "]", "\n", "\n", "en_stopwords", "=", "set", "(", "stopwords", ".", "words", "(", "'english'", ")", ")", "\n", "\n", "skipped", "=", "0", "\n", "for", "item", "in", "r", ":", "\n", "        ", "question", "=", "item", ".", "get", "(", "'Id'", ")", "\n", "title", "=", "item", ".", "get", "(", "'Title'", ")", "\n", "body", "=", "item", ".", "get", "(", "'Body'", ")", "\n", "\n", "title_toks", "=", "title", ".", "lower", "(", ")", ".", "split", "(", ")", "\n", "body_toks", "=", "body", ".", "lower", "(", ")", ".", "split", "(", ")", "\n", "# We ensure that title and body are not the same, and are non-empty", "\n", "if", "len", "(", "title_toks", ")", ">", "3", "and", "len", "(", "body_toks", ")", ">", "3", "and", "title", "!=", "body", "and", "len", "(", "\n", "en_stopwords", "&", "set", "(", "title_toks", ")", ")", ">", "0", "and", "len", "(", "en_stopwords", "&", "set", "(", "body_toks", ")", ")", ">", "0", ":", "\n", "\n", "            ", "questionids", ".", "append", "(", "question", ")", "\n", "q", "=", "{", "'TITLE'", ":", "title", ",", "'BODY'", ":", "body", "}", "\n", "questiondict", "[", "question", "]", "=", "q", "\n", "", "else", ":", "\n", "            ", "skipped", "+=", "1", "\n", "logger", ".", "debug", "(", "'skipping question'", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "'Skipped questions: {}'", ".", "format", "(", "skipped", ")", ")", "\n", "\n", "return", "questiondict", ",", "questionids", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_train_data_standard.create_data": [[132, 267], ["click.command", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "create_train_data_standard.read_questions", "logger.info", "logger.info", "logger.info", "min", "logger.info", "logger.info", "logger.info", "random.sample", "logger.info", "logger.info", "os.path.exists", "os.makedirs", "set", "random.sample", "int", "len", "logger.info", "len", "gzip.open", "gzip.open", "gzip.open", "click.Choice", "open", "set", "len", "len", "len", "len", "len", "len", "len", "create_train_data_standard._clean_text", "create_train_data_standard._clean_text", "f.write", "f.write", "logger.info", "tensorflow.Graph", "tf.Graph.finalize", "tensorflow.ConfigProto", "tensorflow.reset_default_graph", "logger.info", "logger.info", "logger.info", "faiss.IndexFlatIP", "faiss.index_cpu_to_gpu.add", "logger.info", "tqdm", "tqdm.tqdm", "len", "tf.Graph.as_default", "tensorflow.placeholder", "hub.Module.", "tensorflow.group", "tensorflow.Session", "sess.run", "logger.info", "numpy.empty().astype", "tqdm", "tqdm.tqdm", "numpy.linalg.norm", "faiss.StandardGpuResources", "faiss.index_cpu_to_gpu", "enumerate", "faiss.index_cpu_to_gpu.reconstruct", "faiss.index_cpu_to_gpu.search", "f.write", "f.write", "l.strip", "tensorflow_hub.Module", "range", "sess.run", "numpy.vstack", "sampled_qids.index", "numpy.reshape", "logger.info", "logger.info", "tensorflow_hub.Module", "Exception", "tensorflow.global_variables_initializer", "tensorflow.tables_initializer", "t.lower", "numpy.empty", "len", "logger.info", "str", "random.sample"], "function", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.read_questions", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data._clean_text", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data._clean_text", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.MultiData.add"], ["", "@", "click", ".", "command", "(", ")", "\n", "@", "click", ".", "option", "(", "'--se_path'", ",", "required", "=", "True", ",", "\n", "help", "=", "'Path pointing to the folder of the StackExchange dump (that contains the Posts.xml file)'", ")", "\n", "@", "click", ".", "option", "(", "'--excluded_ids_path'", ",", "\n", "help", "=", "'Path of the file that contains the excluded ids (line by line)'", ")", "\n", "@", "click", ".", "option", "(", "'--target_folder'", ",", "required", "=", "True", ",", "help", "=", "'Output folder (will be created)'", ")", "\n", "@", "click", ".", "option", "(", "'--n_train_queries'", ",", "required", "=", "True", ",", "type", "=", "int", ",", "help", "=", "'Number of training queries'", ")", "\n", "@", "click", ".", "option", "(", "'--n_dev_queries'", ",", "required", "=", "True", ",", "type", "=", "int", ",", "help", "=", "'Number of development queries'", ")", "\n", "@", "click", ".", "option", "(", "'--n_dev_queries_max_percentage'", ",", "required", "=", "True", ",", "default", "=", "0.2", ",", "type", "=", "float", ",", "help", "=", "'Max % of dev/train'", ")", "\n", "@", "click", ".", "option", "(", "'--n_max_questions'", ",", "required", "=", "True", ",", "type", "=", "int", ",", "\n", "help", "=", "'Maximum number of total questions (for negative sampling during training)'", ")", "\n", "@", "click", ".", "option", "(", "'--pool_size'", ",", "required", "=", "True", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of negative examples that are chosen for the dev split'", ")", "\n", "@", "click", ".", "option", "(", "'--pooling'", ",", "type", "=", "click", ".", "Choice", "(", "[", "'none'", ",", "'use'", ",", "'p-means'", "]", ")", ",", "help", "=", "'Use sentence embeddings and FAISS to '", "\n", "'create candidate pools'", ")", "\n", "@", "click", ".", "option", "(", "'--gpu'", ",", "is_flag", "=", "True", ",", "help", "=", "'Use the GPU Index for FAISS'", ")", "\n", "def", "create_data", "(", "se_path", ",", "excluded_ids_path", ",", "target_folder", ",", "n_train_queries", ",", "n_dev_queries", ",", "n_dev_queries_max_percentage", ",", "\n", "n_max_questions", ",", "pool_size", ",", "pooling", ",", "gpu", "=", "False", ")", ":", "\n", "    ", "questiondict", ",", "qids", "=", "read_questions", "(", "se_path", ")", "\n", "\n", "if", "not", "path", ".", "exists", "(", "target_folder", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "target_folder", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "if", "excluded_ids_path", ":", "\n", "        ", "with", "open", "(", "excluded_ids_path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "excluded_ids", "=", "set", "(", "[", "l", ".", "strip", "(", ")", "for", "l", "in", "f", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "excluded_ids", "=", "set", "(", ")", "\n", "\n", "", "logger", ".", "info", "(", "'len(excluded_ids)={}'", ".", "format", "(", "len", "(", "excluded_ids", ")", ")", ")", "\n", "qids_other", "=", "[", "qid", "for", "qid", "in", "qids", "if", "qid", "not", "in", "excluded_ids", "]", "\n", "logger", ".", "info", "(", "'len(qids_other)={}'", ".", "format", "(", "len", "(", "qids_other", ")", ")", ")", "\n", "\n", "sampled_qids", "=", "qids_other", "if", "len", "(", "qids_other", ")", "<=", "n_max_questions", "else", "random", ".", "sample", "(", "qids_other", ",", "n_max_questions", ")", "\n", "# the number of included questions in the dataset. this can be more than the number of queries so that we have", "\n", "# more variation for random sampling while not including too many queries (for large forums)", "\n", "\n", "logger", ".", "info", "(", "'N sampled_qids = {}'", ".", "format", "(", "len", "(", "sampled_qids", ")", ")", ")", "\n", "\n", "# adjust number of dev queries, if needed", "\n", "n_dev_queries", "=", "min", "(", "int", "(", "len", "(", "sampled_qids", ")", "*", "n_dev_queries_max_percentage", ")", ",", "n_dev_queries", ")", "\n", "logger", ".", "info", "(", "'n_dev_queries_max_percentage={}'", ".", "format", "(", "n_dev_queries_max_percentage", ")", ")", "\n", "logger", ".", "info", "(", "'n_questions={}'", ".", "format", "(", "len", "(", "qids", ")", ")", ")", "\n", "logger", ".", "info", "(", "'n_dev_queries={}'", ".", "format", "(", "n_dev_queries", ")", ")", "\n", "\n", "n_sample_train_dev", "=", "n_train_queries", "+", "n_dev_queries", "\n", "if", "len", "(", "qids_other", ")", "<", "n_sample_train_dev", ":", "\n", "        ", "logger", ".", "info", "(", "'Number of questions in SE dump less than train+dev (={})'", ".", "format", "(", "n_sample_train_dev", ")", ")", "\n", "n_sample_train_dev", "=", "len", "(", "qids_other", ")", "\n", "\n", "", "sampled_qids_train_dev", "=", "random", ".", "sample", "(", "sampled_qids", ",", "n_sample_train_dev", ")", "\n", "sampled_qids_train", "=", "sampled_qids_train_dev", "[", ":", "-", "n_dev_queries", "]", "\n", "sampled_qids_dev", "=", "sampled_qids_train_dev", "[", "-", "n_dev_queries", ":", "]", "\n", "\n", "logger", ".", "info", "(", "'N sampled_qids_train = {}'", ".", "format", "(", "len", "(", "sampled_qids_train", ")", ")", ")", "\n", "logger", ".", "info", "(", "'N sampled_qids_dev = {}'", ".", "format", "(", "len", "(", "sampled_qids_dev", ")", ")", ")", "\n", "\n", "with", "gzip", ".", "open", "(", "target_folder", "+", "\"/questions.tsv.gz\"", ",", "'wt'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "for", "qid", "in", "sampled_qids", ":", "\n", "            ", "title", "=", "_clean_text", "(", "questiondict", "[", "qid", "]", "[", "'TITLE'", "]", ")", "\n", "body", "=", "_clean_text", "(", "questiondict", "[", "qid", "]", "[", "'BODY'", "]", ")", "\n", "f", ".", "write", "(", "'{}\\t{}\\t{}\\n'", ".", "format", "(", "qid", ",", "title", ",", "body", ")", ")", "\n", "\n", "", "", "with", "gzip", ".", "open", "(", "target_folder", "+", "\"/train.tsv.gz\"", ",", "'wt'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "for", "qid", "in", "sampled_qids_train", ":", "\n", "            ", "f", ".", "write", "(", "'{}\\n'", ".", "format", "(", "qid", ")", ")", "\n", "\n", "", "", "with", "gzip", ".", "open", "(", "target_folder", "+", "\"/dev.tsv.gz\"", ",", "'wt'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "if", "pooling", "!=", "\"none\"", ":", "\n", "# pooling with USE sentence embeddings over question titles and similarity search", "\n", "            ", "logger", ".", "info", "(", "'Building FAISS index with sentence embeddings of Q titles'", ")", "\n", "g", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "g", ".", "as_default", "(", ")", ":", "\n", "                ", "sentences_placeholder", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "string", ",", "shape", "=", "[", "None", "]", ")", "\n", "if", "pooling", "==", "'use'", ":", "\n", "# sentence_encoder = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder-large/3\")", "\n", "                    ", "sentence_encoder", "=", "hub", ".", "Module", "(", "\"https://tfhub.dev/google/universal-sentence-encoder-qa/3\"", ")", "\n", "lowercase", "=", "False", "\n", "dim", "=", "512", "\n", "", "elif", "pooling", "==", "'p-means'", ":", "\n", "                    ", "sentence_encoder", "=", "hub", ".", "Module", "(", "\"https://public.ukp.informatik.tu-darmstadt.de/arxiv2018-xling-sentence-embeddings/tf-hub/monolingual/1\"", ")", "\n", "lowercase", "=", "True", "\n", "dim", "=", "3600", "\n", "", "else", ":", "\n", "                    ", "raise", "Exception", "(", "'Unknown pooling method \"{}\"'", ".", "format", "(", "pooling", ")", ")", "\n", "", "graph", "=", "sentence_encoder", "(", "sentences_placeholder", ")", "\n", "init_op", "=", "tf", ".", "group", "(", "[", "tf", ".", "global_variables_initializer", "(", ")", ",", "tf", ".", "tables_initializer", "(", ")", "]", ")", "\n", "", "g", ".", "finalize", "(", ")", "\n", "\n", "sess_config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", "\n", "sess_config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "with", "tf", ".", "Session", "(", "graph", "=", "g", ",", "config", "=", "sess_config", ")", "as", "sess", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "titles", "=", "[", "questiondict", "[", "qid", "]", "[", "'TITLE'", "]", "for", "qid", "in", "sampled_qids", "]", "\n", "if", "lowercase", ":", "\n", "                    ", "titles", "=", "[", "t", ".", "lower", "(", ")", "for", "t", "in", "titles", "]", "\n", "", "logger", ".", "info", "(", "'Computing all embeddings...'", ")", "\n", "embeddings", "=", "np", ".", "empty", "(", "(", "0", ",", "dim", ")", ")", ".", "astype", "(", "'float32'", ")", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "sampled_qids", ")", ",", "128", ")", ")", ":", "\n", "                    ", "e", "=", "sess", ".", "run", "(", "graph", ",", "feed_dict", "=", "{", "sentences_placeholder", ":", "titles", "[", "i", ":", "i", "+", "128", "]", "}", ")", "\n", "embeddings", "=", "np", ".", "vstack", "(", "(", "embeddings", ",", "e", ")", ")", "\n", "", "", "tf", ".", "reset_default_graph", "(", ")", "# release memory", "\n", "\n", "logger", ".", "info", "(", "'Normalizing embeddings...'", ")", "\n", "embeddings", "=", "embeddings", "/", "LA", ".", "norm", "(", "embeddings", ",", "axis", "=", "0", ")", "\n", "# normalize embeddings so that IP-index does cosine similarity", "\n", "\n", "logger", ".", "info", "(", "'Adding embeddings to FAISS index...'", ")", "\n", "logger", ".", "info", "(", "'embeddings shape: {}'", ".", "format", "(", "embeddings", ".", "shape", ")", ")", "\n", "index", "=", "faiss", ".", "IndexFlatIP", "(", "512", ")", "\n", "index", ".", "add", "(", "embeddings", ")", "\n", "if", "gpu", ":", "\n", "                ", "res", "=", "faiss", ".", "StandardGpuResources", "(", ")", "# use a single GPU", "\n", "index", "=", "faiss", ".", "index_cpu_to_gpu", "(", "res", ",", "0", ",", "index", ")", "\n", "\n", "", "logger", ".", "info", "(", "'Querying FAISS...'", ")", "\n", "for", "i", ",", "qid", "in", "tqdm", "(", "enumerate", "(", "sampled_qids_dev", ")", ")", ":", "\n", "                ", "embedding", "=", "index", ".", "reconstruct", "(", "sampled_qids", ".", "index", "(", "qid", ")", ")", "\n", "_", ",", "similar_items", "=", "index", ".", "search", "(", "np", ".", "reshape", "(", "embedding", ",", "[", "1", ",", "-", "1", "]", ")", ",", "pool_size", ")", "\n", "similar_items_qids", "=", "[", "sampled_qids", "[", "j", "]", "for", "j", "in", "similar_items", "[", "0", "]", "]", "\n", "neg", "=", "' '", ".", "join", "(", "similar_items_qids", ")", "\n", "f", ".", "write", "(", "'{}\\t{}\\n'", ".", "format", "(", "qid", ",", "neg", ")", ")", "\n", "\n", "# print some examples", "\n", "if", "i", "<", "3", ":", "\n", "                    ", "logger", ".", "info", "(", "'Query: {}'", ".", "format", "(", "questiondict", "[", "qid", "]", "[", "'TITLE'", "]", ")", ")", "\n", "for", "qid_similar", "in", "similar_items_qids", "[", ":", "3", "]", ":", "\n", "                        ", "logger", ".", "info", "(", "'=>: {}'", ".", "format", "(", "questiondict", "[", "qid_similar", "]", "[", "'TITLE'", "]", ")", ")", "\n", "", "logger", ".", "info", "(", "'-'", "*", "10", ")", "\n", "", "", "", "else", ":", "\n", "# pooling with random sampling", "\n", "            ", "for", "qid", "in", "sampled_qids_dev", ":", "\n", "                ", "neg", "=", "' '", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "random", ".", "sample", "(", "sampled_qids_train_dev", ",", "pool_size", ")", "]", ")", "\n", "f", ".", "write", "(", "'{}\\t{}\\n'", ".", "format", "(", "qid", ",", "neg", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.print_duplicate_ids.SELinkReader.__init__": [[29, 34], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_file_path", ")", ":", "\n", "        ", "\"\"\"\n        data_file_path : (string) path to the PostLinks.xml file\n        \"\"\"", "\n", "self", ".", "data_file_path", "=", "data_file_path", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.print_duplicate_ids.SELinkReader.n_items_unfiltered": [[35, 38], ["subprocess.check_output", "int", "subprocess.check_output.split"], "methods", ["None"], ["", "def", "n_items_unfiltered", "(", "self", ")", ":", "\n", "        ", "out", "=", "subprocess", ".", "check_output", "(", "[", "'wc'", ",", "'-l'", ",", "self", ".", "data_file_path", "]", ")", "\n", "return", "int", "(", "out", ".", "split", "(", ")", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.print_duplicate_ids.SELinkReader.read_ids": [[39, 52], ["set", "io.open", "tqdm", "tqdm.tqdm", "tqdm.tqdm", "tqdm.tqdm.tqdm", "xml.fromstring", "set.add", "set.add", "logger.info", "l.strip", "l.strip"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.MultiData.add", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.MultiData.add"], ["", "def", "read_ids", "(", "self", ")", ":", "\n", "        ", "ids", "=", "set", "(", ")", "\n", "with", "io", ".", "open", "(", "self", ".", "data_file_path", ",", "'r'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "for", "l", "in", "tqdm", "(", "f", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "sample", "=", "ET", ".", "fromstring", "(", "l", ".", "strip", "(", ")", ")", ".", "attrib", "\n", "# id=3 -> duplicate https://meta.stackexchange.com/questions/2677/database-schema-documentation-for-the-public-data-dump-and-sede", "\n", "if", "sample", "[", "'LinkTypeId'", "]", "==", "'3'", ":", "\n", "                        ", "ids", ".", "add", "(", "sample", "[", "'PostId'", "]", ")", "\n", "ids", ".", "add", "(", "sample", "[", "'RelatedPostId'", "]", ")", "\n", "", "", "except", "ET", ".", "ParseError", "as", "e", ":", "\n", "                    ", "logger", ".", "info", "(", "'(Ignoring) ERROR in parsing line (QUESTION READER):\\n{}\\n'", ".", "format", "(", "l", ".", "strip", "(", ")", ")", ")", "\n", "", "", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.print_duplicate_ids.create_data": [[54, 61], ["click.command", "click.argument", "click.argument", "print_duplicate_ids.SELinkReader", "print_duplicate_ids.SELinkReader.read_ids", "output.write", "click.File"], "function", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.print_duplicate_ids.SELinkReader.read_ids"], ["", "", "@", "click", ".", "command", "(", ")", "\n", "@", "click", ".", "argument", "(", "'se_input'", ")", "\n", "@", "click", ".", "argument", "(", "'output'", ",", "type", "=", "click", ".", "File", "(", "'wt'", ")", ")", "\n", "def", "create_data", "(", "se_input", ",", "output", ")", ":", "\n", "    ", "reader", "=", "SELinkReader", "(", "se_input", ")", "\n", "dup_ids", "=", "reader", ".", "read_ids", "(", ")", "\n", "output", ".", "write", "(", "'{}\\n'", ".", "format", "(", "'\\n'", ".", "join", "(", "dup_ids", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.__init__": [[49, 54], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_file_path", ")", ":", "\n", "        ", "\"\"\"\n        data_file_path : (string) path to the posts.xml file\n        \"\"\"", "\n", "self", ".", "data_file_path", "=", "data_file_path", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.question_data_filter": [[55, 58], ["dict", "sample.get"], "methods", ["None"], ["", "def", "question_data_filter", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "dict", "(", "(", "k", ",", "sample", ".", "get", "(", "k", ",", "None", ")", ")", "for", "k", "in", "\n", "[", "'Id'", ",", "'Title'", ",", "'Body'", ",", "'Tags'", ",", "'ParentId'", ",", "'PostTypeId'", ",", "'AcceptedAnswerId'", ",", "'Score'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.n_items_unfiltered": [[59, 62], ["subprocess.check_output", "int", "subprocess.check_output.split"], "methods", ["None"], ["", "def", "n_items_unfiltered", "(", "self", ")", ":", "\n", "        ", "out", "=", "subprocess", ".", "check_output", "(", "[", "'wc'", ",", "'-l'", ",", "self", ".", "data_file_path", "]", ")", "\n", "return", "int", "(", "out", ".", "split", "(", ")", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.read_items": [[63, 84], ["io.open", "tqdm", "tqdm.tqdm", "tqdm.tqdm", "tqdm.tqdm.tqdm", "xml.fromstring", "logger.info", "int", "create_extended_train_data.SEDataReader.question_data_filter", "l.strip", "int", "l.strip"], "methods", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.question_data_filter"], ["", "def", "read_items", "(", "self", ",", "allowed_post_types", "=", "(", "POST_TYPE_QUESTION", ",", ")", ",", "min_score", "=", "0", ",", "max_year", "=", "None", ")", ":", "\n", "        ", "with", "io", ".", "open", "(", "self", ".", "data_file_path", ",", "'r'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "for", "l", "in", "tqdm", "(", "f", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "sample", "=", "ET", ".", "fromstring", "(", "l", ".", "strip", "(", ")", ")", ".", "attrib", "\n", "", "except", "ET", ".", "ParseError", "as", "e", ":", "\n", "                    ", "logger", ".", "info", "(", "'(Ignoring) ERROR in parsing line (QUESTION READER):\\n{}\\n'", ".", "format", "(", "l", ".", "strip", "(", ")", ")", ")", "\n", "sample", "=", "None", "\n", "", "if", "sample", ":", "\n", "                    ", "has_min_score", "=", "int", "(", "sample", "[", "'Score'", "]", ")", ">=", "min_score", "\n", "has_max_year", "=", "True", "if", "max_year", "is", "None", "else", "int", "(", "sample", "[", "'CreationDate'", "]", "[", ":", "4", "]", ")", "<=", "max_year", "\n", "\n", "if", "sample", "[", "'PostTypeId'", "]", "in", "allowed_post_types", "and", "has_max_year", "and", "has_min_score", ":", "\n", "                        ", "SEDataReader", ".", "num_retrieved", "+=", "1", "\n", "filtered_sample", "=", "self", ".", "question_data_filter", "(", "sample", ")", "\n", "yield", "filtered_sample", "\n", "", "else", ":", "\n", "                        ", "SEDataReader", ".", "num_skipped_other_posttype", "+=", "1", "\n", "\n", "", "", "else", ":", "\n", "                    ", "SEDataReader", ".", "num_skipped_sample_none", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data._clean_text": [[86, 92], ["bs4.BeautifulSoup", "res.replace.replace", "res.replace.replace", "i.splitlines"], "function", ["None"], ["", "", "", "", "", "def", "_clean_text", "(", "t", ")", ":", "\n", "    ", "soup", "=", "BeautifulSoup", "(", "t", ",", "'lxml'", ")", "\n", "res", "=", "' '", ".", "join", "(", "[", "''", ".", "join", "(", "i", ".", "splitlines", "(", ")", ")", "for", "i", "in", "soup", ".", "strings", "]", ")", "\n", "res", "=", "res", ".", "replace", "(", "u\"\\\\'\"", ",", "u\" '\"", ")", "\n", "res", "=", "res", ".", "replace", "(", "u'\\t'", ",", "u''", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.read_questions": [[94, 127], ["logger.info", "create_extended_train_data.SEDataReader", "create_extended_train_data.SEDataReader.read_items", "set", "logger.info", "nltk.corpus.stopwords.words", "item.get", "item.get", "item.get", "item.get.lower().split", "item.get.lower().split", "questionids.append", "logger.debug", "item.get.lower", "item.get.lower", "len", "len", "len", "len", "item.get", "set", "set"], "function", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.read_items"], ["", "def", "read_questions", "(", "path", ",", "excluded_ids", ")", ":", "\n", "    ", "logger", ".", "info", "(", "'Reading questions'", ")", "\n", "reader", "=", "SEDataReader", "(", "path", "+", "\"/Posts.xml\"", ")", "\n", "r", "=", "reader", ".", "read_items", "(", "POST_TYPE_QUESTION", ")", "\n", "\n", "questiondict", "=", "{", "}", "\n", "questionids", "=", "[", "]", "\n", "\n", "en_stopwords", "=", "set", "(", "stopwords", ".", "words", "(", "'english'", ")", ")", "\n", "\n", "skipped", "=", "0", "\n", "for", "item", "in", "r", ":", "\n", "        ", "question", "=", "item", ".", "get", "(", "'Id'", ")", "\n", "title", "=", "item", ".", "get", "(", "'Title'", ")", "\n", "body", "=", "item", ".", "get", "(", "'Body'", ")", "\n", "\n", "if", "question", "not", "in", "excluded_ids", ":", "\n", "            ", "title_toks", "=", "title", ".", "lower", "(", ")", ".", "split", "(", ")", "\n", "body_toks", "=", "body", ".", "lower", "(", ")", ".", "split", "(", ")", "\n", "# We ensure that title and body are not the same, and are non-empty", "\n", "if", "len", "(", "title_toks", ")", ">", "3", "and", "len", "(", "body_toks", ")", ">", "3", "and", "title", "!=", "body", "and", "len", "(", "\n", "en_stopwords", "&", "set", "(", "title_toks", ")", ")", ">", "0", "and", "len", "(", "en_stopwords", "&", "set", "(", "body_toks", ")", ")", ">", "0", ":", "\n", "\n", "                ", "questionids", ".", "append", "(", "question", ")", "\n", "q", "=", "{", "'TITLE'", ":", "title", ",", "'BODY'", ":", "body", ",", "'ANSWER'", ":", "item", ".", "get", "(", "'AcceptedAnswerId'", ")", "}", "\n", "questiondict", "[", "question", "]", "=", "q", "\n", "", "else", ":", "\n", "                ", "skipped", "+=", "1", "\n", "logger", ".", "debug", "(", "'skipping question'", ")", "\n", "\n", "", "", "", "logger", ".", "info", "(", "'Skipped questions: {}'", ".", "format", "(", "skipped", ")", ")", "\n", "\n", "return", "questiondict", ",", "questionids", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.read_answers": [[129, 157], ["logger.info", "create_extended_train_data.SEDataReader", "create_extended_train_data.SEDataReader.read_items", "set", "logger.info", "nltk.corpus.stopwords.words", "item.get", "item.get", "item.get.lower().split", "answerids.append", "logger.debug", "item.get.lower", "len", "len", "set"], "function", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.SEDataReader.read_items"], ["", "def", "read_answers", "(", "path", ",", "keep_answer_ids", ")", ":", "\n", "    ", "logger", ".", "info", "(", "'Reading answers'", ")", "\n", "reader", "=", "SEDataReader", "(", "path", "+", "\"/Posts.xml\"", ")", "\n", "r", "=", "reader", ".", "read_items", "(", "POST_TYPE_ANSWER", ")", "\n", "\n", "answerdict", "=", "{", "}", "\n", "answerids", "=", "[", "]", "\n", "\n", "en_stopwords", "=", "set", "(", "stopwords", ".", "words", "(", "'english'", ")", ")", "\n", "\n", "skipped", "=", "0", "\n", "for", "item", "in", "r", ":", "\n", "        ", "answer", "=", "item", ".", "get", "(", "'Id'", ")", "\n", "if", "answer", "in", "keep_answer_ids", ":", "\n", "            ", "body", "=", "item", ".", "get", "(", "'Body'", ")", "\n", "body_toks", "=", "body", ".", "lower", "(", ")", ".", "split", "(", ")", "\n", "# We ensure that answer is non-empty", "\n", "if", "len", "(", "body_toks", ")", ">", "3", "and", "len", "(", "en_stopwords", "&", "set", "(", "body_toks", ")", ")", ">", "0", ":", "\n", "                ", "answerids", ".", "append", "(", "answer", ")", "\n", "a", "=", "{", "'BODY'", ":", "body", "}", "\n", "answerdict", "[", "answer", "]", "=", "a", "\n", "", "else", ":", "\n", "                ", "skipped", "+=", "1", "\n", "logger", ".", "debug", "(", "'skipping answer'", ")", "\n", "\n", "", "", "", "logger", ".", "info", "(", "'Skipped answers: {}'", ".", "format", "(", "skipped", ")", ")", "\n", "\n", "return", "answerdict", ",", "answerids", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.read_duplicates": [[159, 178], ["logger.info", "collections.defaultdict", "io.open", "list", "os.path.join", "xml.fromstring", "logger.info", "l.strip", "ids[].append", "ids[].append", "l.strip"], "function", ["None"], ["", "def", "read_duplicates", "(", "path", ",", "keep_question_ids", ")", ":", "\n", "    ", "logger", ".", "info", "(", "'Reading duplicates'", ")", "\n", "ids", "=", "defaultdict", "(", "lambda", ":", "list", "(", ")", ")", "\n", "with", "io", ".", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'PostLinks.xml'", ")", ",", "'r'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "for", "l", "in", "f", ":", "\n", "            ", "try", ":", "\n", "                ", "sample", "=", "ET", ".", "fromstring", "(", "l", ".", "strip", "(", ")", ")", ".", "attrib", "\n", "# id=3 -> duplicate https://meta.stackexchange.com/questions/2677/database-schema-documentation-for-the-public-data-dump-and-sede", "\n", "if", "sample", "[", "'LinkTypeId'", "]", "==", "'3'", ":", "\n", "                    ", "a", "=", "sample", "[", "'PostId'", "]", "\n", "b", "=", "sample", "[", "'RelatedPostId'", "]", "\n", "\n", "if", "a", "in", "keep_question_ids", "and", "b", "in", "keep_question_ids", ":", "\n", "                        ", "ids", "[", "a", "]", ".", "append", "(", "b", ")", "\n", "ids", "[", "b", "]", ".", "append", "(", "a", ")", "\n", "\n", "", "", "", "except", "ET", ".", "ParseError", "as", "e", ":", "\n", "                ", "logger", ".", "info", "(", "'(Ignoring) ERROR in parsing line (DUPLICATES READER):\\n{}\\n'", ".", "format", "(", "l", ".", "strip", "(", ")", ")", ")", "\n", "", "", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.create_data": [[180, 331], ["click.command", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "create_extended_train_data.read_questions", "set", "set", "create_extended_train_data.read_answers", "create_extended_train_data.read_duplicates", "logger.info", "logger.info", "logger.info", "set", "list", "list", "logger.info", "min", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "random.sample", "logger.info", "logger.info", "os.path.exists", "logger.info", "set", "os.path.exists", "os.makedirs", "read_duplicates.keys", "set", "len", "list", "random.shuffle", "random.sample", "int", "len", "logger.info", "len", "gzip.open", "gzip.open", "gzip.open", "click.Choice", "open", "set", "len", "len", "random.shuffle", "len", "len", "len", "len", "len", "create_extended_train_data._clean_text", "create_extended_train_data._clean_text", "f.write", "f.write", "logger.info", "tensorflow_hub.load", "logger.info", "numpy.empty().astype", "tqdm", "tqdm.tqdm", "logger.info", "logger.info", "logger.info", "faiss.IndexFlatIP", "faiss.index_cpu_to_gpu.add", "logger.info", "tqdm", "tqdm.tqdm", "questiondict.values", "len", "create_extended_train_data._clean_text", "Exception", "t.lower", "range", "[].numpy", "numpy.vstack", "numpy.linalg.norm", "faiss.StandardGpuResources", "faiss.index_cpu_to_gpu", "enumerate", "faiss.index_cpu_to_gpu.reconstruct", "faiss.index_cpu_to_gpu.search", "f.write", "f.write", "l.strip", "questiondict.items", "len", "numpy.empty", "len", "random.sample.index", "numpy.reshape", "logger.info", "logger.info", "len", "logger.info", "str", "random.sample", "tensorflow.constant"], "function", ["home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.read_questions", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.read_answers", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data.read_duplicates", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data._clean_text", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data._clean_text", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.checkpointing.QATrainStatePyTorch.load", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.experiment.__init__.MultiData.add", "home.repos.pwc.inspect_result.ukplab_emnlp2020-multicqa.data-creation.create_extended_train_data._clean_text"], ["", "@", "click", ".", "command", "(", ")", "\n", "@", "click", ".", "option", "(", "'--se_path'", ",", "required", "=", "True", ",", "\n", "help", "=", "'Path pointing to the folder of the StackExchange dump (that contains the Posts.xml file)'", ")", "\n", "@", "click", ".", "option", "(", "'--excluded_ids_path'", ",", "\n", "help", "=", "'Path of the file that contains the excluded question ids (line by line). Use an empty file to not exclude anything'", ")", "\n", "@", "click", ".", "option", "(", "'--target_folder'", ",", "required", "=", "True", ",", "help", "=", "'Output folder (will be created)'", ")", "\n", "@", "click", ".", "option", "(", "'--n_train_queries'", ",", "required", "=", "True", ",", "type", "=", "int", ",", "help", "=", "'Number of training queries'", ")", "\n", "@", "click", ".", "option", "(", "'--n_dev_queries'", ",", "required", "=", "True", ",", "type", "=", "int", ",", "help", "=", "'Number of development queries'", ")", "\n", "@", "click", ".", "option", "(", "'--n_dev_queries_max_percentage'", ",", "required", "=", "True", ",", "default", "=", "0.2", ",", "type", "=", "float", ",", "help", "=", "'Max % of dev/train'", ")", "\n", "@", "click", ".", "option", "(", "'--n_max_questions'", ",", "required", "=", "True", ",", "type", "=", "int", ",", "\n", "help", "=", "'Maximum number of total questions (for negative sampling during training)'", ")", "\n", "@", "click", ".", "option", "(", "'--pool_size'", ",", "required", "=", "True", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of negative examples that are chosen for the dev split'", ")", "\n", "@", "click", ".", "option", "(", "'--pooling'", ",", "type", "=", "click", ".", "Choice", "(", "[", "'none'", ",", "'use'", "]", ")", ",", "help", "=", "'Use sentence embeddings and FAISS to create candidate pools'", ")", "\n", "@", "click", ".", "option", "(", "'--gpu'", ",", "is_flag", "=", "True", ",", "help", "=", "'Use the GPU Index for FAISS'", ")", "\n", "def", "create_data", "(", "se_path", ",", "excluded_ids_path", ",", "target_folder", ",", "n_train_queries", ",", "n_dev_queries", ",", "n_dev_queries_max_percentage", ",", "\n", "n_max_questions", ",", "pool_size", ",", "pooling", ",", "gpu", "=", "False", ")", ":", "\n", "\n", "    ", "if", "excluded_ids_path", "and", "os", ".", "path", ".", "exists", "(", "excluded_ids_path", ")", ":", "\n", "        ", "with", "open", "(", "excluded_ids_path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "excluded_q_ids", "=", "set", "(", "[", "l", ".", "strip", "(", ")", "for", "l", "in", "f", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "'Either no excluded ids path given, or path does not exist! {}'", ".", "format", "(", "excluded_ids_path", ")", ")", "\n", "excluded_q_ids", "=", "set", "(", ")", "\n", "\n", "", "questiondict", ",", "qids", "=", "read_questions", "(", "se_path", ",", "excluded_ids", "=", "excluded_q_ids", ")", "\n", "qids", "=", "set", "(", "qids", ")", "\n", "\n", "accepted_answer_ids", "=", "set", "(", "[", "q", "[", "'ANSWER'", "]", "for", "q", "in", "questiondict", ".", "values", "(", ")", "if", "q", "[", "'ANSWER'", "]", "]", ")", "\n", "answerdict", ",", "aids", "=", "read_answers", "(", "se_path", ",", "accepted_answer_ids", ")", "\n", "duplicatesdict", "=", "read_duplicates", "(", "se_path", ",", "qids", ")", "\n", "\n", "if", "not", "path", ".", "exists", "(", "target_folder", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "target_folder", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "logger", ".", "info", "(", "'len(excluded_ids)={}'", ".", "format", "(", "len", "(", "excluded_q_ids", ")", ")", ")", "\n", "logger", ".", "info", "(", "'Now validating that no excluded ids were returned'", ")", "\n", "for", "qid", "in", "qids", ":", "\n", "        ", "assert", "qid", "not", "in", "excluded_q_ids", "\n", "", "logger", ".", "info", "(", "'[ok] did not include any excluded ids'", ")", "\n", "\n", "# the number of included questions in the dataset. this can be more than the number of queries so that we have", "\n", "# more variation for random sampling while not including too many queries (for large forums)", "\n", "#", "\n", "# we make sure to prefer ones with correct answers and duplicates before adding ones without", "\n", "q_with_duplicates", "=", "set", "(", "duplicatesdict", ".", "keys", "(", ")", ")", "\n", "q_with_only_a", "=", "set", "(", "[", "k", "for", "(", "k", ",", "q", ")", "in", "questiondict", ".", "items", "(", ")", "if", "q", "[", "'ANSWER'", "]", "]", ")", "-", "q_with_duplicates", "\n", "rest", "=", "list", "(", "qids", "-", "(", "q_with_duplicates", "|", "q_with_only_a", ")", ")", "\n", "\n", "sampled_qids", "=", "list", "(", "q_with_duplicates", ")", "\n", "if", "len", "(", "sampled_qids", ")", "<", "n_max_questions", ":", "\n", "        ", "q_with_only_a", "=", "list", "(", "q_with_only_a", ")", "\n", "random", ".", "shuffle", "(", "q_with_only_a", ")", "\n", "sampled_qids", "+=", "q_with_only_a", "[", ":", "n_max_questions", "-", "len", "(", "sampled_qids", ")", "]", "\n", "\n", "if", "len", "(", "sampled_qids", ")", "<", "n_max_questions", ":", "\n", "            ", "random", ".", "shuffle", "(", "rest", ")", "\n", "sampled_qids", "+=", "rest", "[", ":", "n_max_questions", "-", "len", "(", "sampled_qids", ")", "]", "\n", "", "", "else", ":", "\n", "        ", "sampled_qids", "=", "random", ".", "sample", "(", "sampled_qids", ",", "n_max_questions", ")", "\n", "\n", "", "logger", ".", "info", "(", "'N sampled_qids = {}'", ".", "format", "(", "len", "(", "sampled_qids", ")", ")", ")", "\n", "\n", "# adjust number of dev queries, if needed", "\n", "n_dev_queries", "=", "min", "(", "int", "(", "len", "(", "sampled_qids", ")", "*", "n_dev_queries_max_percentage", ")", ",", "n_dev_queries", ")", "\n", "logger", ".", "info", "(", "'n_dev_queries_max_percentage={}'", ".", "format", "(", "n_dev_queries_max_percentage", ")", ")", "\n", "logger", ".", "info", "(", "'n_questions(all)={}'", ".", "format", "(", "len", "(", "qids", ")", ")", ")", "\n", "logger", ".", "info", "(", "'n_questions(sampled)={}'", ".", "format", "(", "len", "(", "sampled_qids", ")", ")", ")", "\n", "logger", ".", "info", "(", "'n_train_queries={}'", ".", "format", "(", "n_train_queries", ")", ")", "\n", "logger", ".", "info", "(", "'n_dev_queries={}'", ".", "format", "(", "n_dev_queries", ")", ")", "\n", "\n", "n_sample_train_dev", "=", "n_train_queries", "+", "n_dev_queries", "\n", "if", "len", "(", "qids", ")", "<", "n_sample_train_dev", ":", "\n", "        ", "logger", ".", "info", "(", "'Number of questions in SE dump less than train+dev (={})'", ".", "format", "(", "n_sample_train_dev", ")", ")", "\n", "n_sample_train_dev", "=", "len", "(", "qids", ")", "\n", "\n", "", "sampled_qids_train_dev", "=", "random", ".", "sample", "(", "sampled_qids", ",", "n_sample_train_dev", ")", "\n", "sampled_qids_train", "=", "sampled_qids_train_dev", "[", ":", "-", "n_dev_queries", "]", "\n", "sampled_qids_dev", "=", "sampled_qids_train_dev", "[", "-", "n_dev_queries", ":", "]", "\n", "\n", "logger", ".", "info", "(", "'N sampled_qids_train = {}'", ".", "format", "(", "len", "(", "sampled_qids_train", ")", ")", ")", "\n", "logger", ".", "info", "(", "'N sampled_qids_dev = {}'", ".", "format", "(", "len", "(", "sampled_qids_dev", ")", ")", ")", "\n", "\n", "with", "gzip", ".", "open", "(", "target_folder", "+", "\"/questions.tsv.gz\"", ",", "'wt'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "for", "qid", "in", "sampled_qids", ":", "\n", "            ", "title", "=", "_clean_text", "(", "questiondict", "[", "qid", "]", "[", "'TITLE'", "]", ")", "\n", "body", "=", "_clean_text", "(", "questiondict", "[", "qid", "]", "[", "'BODY'", "]", ")", "\n", "\n", "answer", "=", "''", "\n", "answer_id", "=", "questiondict", "[", "qid", "]", "[", "'ANSWER'", "]", "\n", "if", "answer_id", "and", "answer_id", "in", "answerdict", ":", "\n", "                ", "answer", "=", "_clean_text", "(", "answerdict", "[", "answer_id", "]", "[", "'BODY'", "]", ")", "\n", "\n", "", "duplicates", "=", "','", ".", "join", "(", "[", "d", "for", "d", "in", "duplicatesdict", "[", "qid", "]", "]", ")", "\n", "\n", "f", ".", "write", "(", "'{}\\t{}\\t{}\\t{}\\t{}\\n'", ".", "format", "(", "qid", ",", "title", ",", "body", ",", "answer", ",", "duplicates", ")", ")", "\n", "\n", "", "", "with", "gzip", ".", "open", "(", "target_folder", "+", "\"/train.tsv.gz\"", ",", "'wt'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "for", "qid", "in", "sampled_qids_train", ":", "\n", "            ", "f", ".", "write", "(", "'{}\\n'", ".", "format", "(", "qid", ")", ")", "\n", "\n", "", "", "with", "gzip", ".", "open", "(", "target_folder", "+", "\"/dev.tsv.gz\"", ",", "'wt'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "if", "pooling", "!=", "\"none\"", ":", "\n", "# pooling with USE sentence embeddings over question titles and similarity search", "\n", "            ", "logger", ".", "info", "(", "'Building FAISS index with sentence embeddings of Q titles'", ")", "\n", "if", "pooling", "!=", "'use'", ":", "\n", "                ", "raise", "Exception", "(", "'Unknown pooling method \"{}\"'", ".", "format", "(", "pooling", ")", ")", "\n", "\n", "", "module", "=", "hub", ".", "load", "(", "'https://tfhub.dev/google/universal-sentence-encoder-qa/3'", ")", "\n", "dim", "=", "512", "\n", "\n", "titles", "=", "[", "questiondict", "[", "qid", "]", "[", "'TITLE'", "]", "for", "qid", "in", "sampled_qids", "]", "\n", "titles", "=", "[", "t", ".", "lower", "(", ")", "for", "t", "in", "titles", "]", "\n", "\n", "logger", ".", "info", "(", "'Computing all embeddings...'", ")", "\n", "embeddings", "=", "np", ".", "empty", "(", "(", "0", ",", "dim", ")", ")", ".", "astype", "(", "'float32'", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "sampled_qids", ")", ",", "128", ")", ")", ":", "\n", "                ", "e", "=", "module", ".", "signatures", "[", "'question_encoder'", "]", "(", "tf", ".", "constant", "(", "titles", "[", "i", ":", "i", "+", "128", "]", ")", ")", "[", "'outputs'", "]", ".", "numpy", "(", ")", "\n", "embeddings", "=", "np", ".", "vstack", "(", "(", "embeddings", ",", "e", ")", ")", "\n", "\n", "", "logger", ".", "info", "(", "'Normalizing embeddings...'", ")", "\n", "embeddings", "=", "embeddings", "/", "LA", ".", "norm", "(", "embeddings", ",", "axis", "=", "0", ")", "\n", "# normalize embeddings so that IP-index does cosine similarity", "\n", "\n", "logger", ".", "info", "(", "'Adding embeddings to FAISS index...'", ")", "\n", "logger", ".", "info", "(", "'embeddings shape: {}'", ".", "format", "(", "embeddings", ".", "shape", ")", ")", "\n", "index", "=", "faiss", ".", "IndexFlatIP", "(", "512", ")", "\n", "index", ".", "add", "(", "embeddings", ")", "\n", "if", "gpu", ":", "\n", "                ", "res", "=", "faiss", ".", "StandardGpuResources", "(", ")", "# use a single GPU", "\n", "index", "=", "faiss", ".", "index_cpu_to_gpu", "(", "res", ",", "0", ",", "index", ")", "\n", "\n", "", "logger", ".", "info", "(", "'Querying FAISS...'", ")", "\n", "for", "i", ",", "qid", "in", "tqdm", "(", "enumerate", "(", "sampled_qids_dev", ")", ")", ":", "\n", "                ", "embedding", "=", "index", ".", "reconstruct", "(", "sampled_qids", ".", "index", "(", "qid", ")", ")", "\n", "_", ",", "similar_items", "=", "index", ".", "search", "(", "np", ".", "reshape", "(", "embedding", ",", "[", "1", ",", "-", "1", "]", ")", ",", "pool_size", ")", "\n", "similar_items_qids", "=", "[", "sampled_qids", "[", "j", "]", "for", "j", "in", "similar_items", "[", "0", "]", "]", "\n", "neg", "=", "' '", ".", "join", "(", "similar_items_qids", ")", "\n", "f", ".", "write", "(", "'{}\\t{}\\n'", ".", "format", "(", "qid", ",", "neg", ")", ")", "\n", "\n", "# print some examples", "\n", "if", "i", "<", "3", ":", "\n", "                    ", "logger", ".", "info", "(", "'Query: {}'", ".", "format", "(", "questiondict", "[", "qid", "]", "[", "'TITLE'", "]", ")", ")", "\n", "for", "qid_similar", "in", "similar_items_qids", "[", ":", "3", "]", ":", "\n", "                        ", "logger", ".", "info", "(", "'=>: {}'", ".", "format", "(", "questiondict", "[", "qid_similar", "]", "[", "'TITLE'", "]", ")", ")", "\n", "", "logger", ".", "info", "(", "'-'", "*", "10", ")", "\n", "", "", "", "else", ":", "\n", "# pooling with random sampling", "\n", "            ", "for", "qid", "in", "sampled_qids_dev", ":", "\n", "                ", "neg", "=", "' '", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "random", ".", "sample", "(", "sampled_qids_train_dev", ",", "pool_size", ")", "]", ")", "\n", "f", ".", "write", "(", "'{}\\t{}\\n'", ".", "format", "(", "qid", ",", "neg", ")", ")", "\n", "\n"]]}