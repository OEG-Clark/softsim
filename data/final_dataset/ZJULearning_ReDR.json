{"home.repos.pwc.inspect_result.ZJULearning_ReDR.None.generate.main": [[13, 33], ["onmt.utils.parse.ArgumentParser.validate_translate_opts", "onmt.utils.logging.init_logger", "onmt.translate.translator.build_translator", "onmt.utils.misc.split_corpus", "onmt.utils.misc.split_corpus", "zip", "enumerate", "onmt.utils.misc.split_corpus", "onmt.utils.logging.init_logger.info", "onmt.translate.translator.build_translator.translate"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.parse.ArgumentParser.validate_translate_opts", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.logging.init_logger", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.build_translator", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.split_corpus", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.split_corpus", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.split_corpus", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator.translate"], ["def", "main", "(", "opt", ")", ":", "\n", "    ", "ArgumentParser", ".", "validate_translate_opts", "(", "opt", ")", "\n", "logger", "=", "init_logger", "(", "opt", ".", "log_file", ")", "\n", "\n", "translator", "=", "build_translator", "(", "opt", ",", "report_score", "=", "True", ")", "\n", "src_shards", "=", "split_corpus", "(", "opt", ".", "src", ",", "opt", ".", "shard_size", ")", "\n", "history_shards", "=", "split_corpus", "(", "opt", ".", "history", ",", "opt", ".", "shard_size", ")", "\n", "tgt_shards", "=", "split_corpus", "(", "opt", ".", "tgt", ",", "opt", ".", "shard_size", ")", "if", "opt", ".", "tgt", "is", "not", "None", "else", "[", "None", "]", "*", "opt", ".", "shard_size", "\n", "shard_pairs", "=", "zip", "(", "src_shards", ",", "history_shards", ",", "tgt_shards", ")", "\n", "\n", "for", "i", ",", "(", "src_shard", ",", "history_shard", ",", "tgt_shard", ")", "in", "enumerate", "(", "shard_pairs", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Translating shard %d.\"", "%", "i", ")", "\n", "translator", ".", "translate", "(", "\n", "src", "=", "src_shard", ",", "\n", "history", "=", "history_shard", ",", "\n", "tgt", "=", "opt", ".", "tgt", ",", "\n", "src_dir", "=", "opt", ".", "src_dir", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "attn_debug", "=", "opt", ".", "attn_debug", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.generate._get_parser": [[35, 41], ["onmt.utils.parse.ArgumentParser", "onmt.config_opts", "onmt.translate_opts"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.opts.config_opts", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.opts.translate_opts"], ["", "", "def", "_get_parser", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", "description", "=", "'translate.py'", ")", "\n", "\n", "opts", ".", "config_opts", "(", "parser", ")", "\n", "opts", ".", "translate_opts", "(", "parser", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.cqg_preprocess.unicode2ascii": [[43, 47], ["unicodedata.normalize", "unicodedata.category"], "function", ["None"], ["def", "unicode2ascii", "(", "s", ")", ":", "\n", "    ", "return", "''", ".", "join", "(", "\n", "c", "for", "c", "in", "unicodedata", ".", "normalize", "(", "'NFD'", ",", "s", ")", "\n", "if", "unicodedata", ".", "category", "(", "c", ")", "!=", "'Mn'", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.cqg_preprocess.normalize_string": [[50, 55], ["cqg_preprocess.unicode2ascii", "unicode2ascii.lower().strip", "unicode2ascii.lower"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.None.cqg_preprocess.unicode2ascii"], ["", "def", "normalize_string", "(", "s", ")", ":", "\n", "    ", "s", "=", "unicode2ascii", "(", "s", ".", "lower", "(", ")", ".", "strip", "(", ")", ")", "\n", "# s = re.sub(r\"([.!?])\", r\" \\1\", s)", "\n", "# s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.cqg_preprocess.remove_space": [[57, 60], ["re.sub"], "function", ["None"], ["", "def", "remove_space", "(", "s", ")", ":", "\n", "    ", "s", "=", "re", ".", "sub", "(", "r'\\s'", ",", "r' '", ",", "s", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.cqg_preprocess.filter_pair": [[62, 65], ["len", "len"], "function", ["None"], ["", "def", "filter_pair", "(", "p", ")", ":", "\n", "    ", "return", "len", "(", "p", "[", "0", "]", ")", "<", "MAX_LENGTH", "and", "len", "(", "p", "[", "1", "]", ")", "<", "MAX_LENGTH", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.cqg_preprocess.history_to_string": [[67, 81], ["enumerate", "len", "record.extend", "record.append", "record.extend", "text_list.extend"], "function", ["None"], ["", "def", "history_to_string", "(", "history", ",", "n_history", ")", ":", "\n", "    ", "flag", "=", "0", "\n", "if", "len", "(", "history", ")", ">", "n_history", ":", "\n", "        ", "text_list", "=", "[", "]", "\n", "", "else", ":", "\n", "        ", "text_list", "=", "[", "\"<sos>\"", "]", "\n", "", "for", "i", ",", "(", "que", ",", "ans", ")", "in", "enumerate", "(", "history", "[", "-", "n_history", "+", "flag", ":", "]", ")", ":", "\n", "        ", "record", "=", "[", "\"q{}\"", ".", "format", "(", "i", ")", "]", "\n", "record", ".", "extend", "(", "que", ")", "\n", "record", ".", "append", "(", "\"a{}\"", ".", "format", "(", "i", ")", ")", "\n", "record", ".", "extend", "(", "ans", ")", "\n", "\n", "text_list", ".", "extend", "(", "record", ")", "\n", "", "return", "text_list", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.cqg_preprocess.process_file": [[83, 126], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "json.load", "open", "open", "open", "open", "open", "tqdm.tqdm", "open", "zip", "cqg_preprocess.remove_space", "cqg_preprocess.remove_space", "cqg_preprocess.remove_space", "tokenizer", "tokenizer", "tokenizer", "cqg_preprocess.history_to_string", "history.append", "fhis.write", "fref.write", "ftgt.write", "fans.write", "fid.write", "que[].lower", "ans[].lower", "ans[].lower"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.cqg_preprocess.remove_space", "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.cqg_preprocess.remove_space", "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.cqg_preprocess.remove_space", "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.cqg_preprocess.history_to_string"], ["", "def", "process_file", "(", "tokenizer", ",", "data_type", ",", "json_file", ",", "out_root_dir", ",", "out_prefix", ",", "n_history", ")", ":", "\n", "    ", "\"\"\"\n    doc = nlp(u'An example sentence. Another sentence.')\n    assert (doc[0].text, doc[0].head.tag_) == ('An', 'NN')\n    \"\"\"", "\n", "data", "=", "json", ".", "load", "(", "open", "(", "json_file", ",", "\"r\"", ")", ")", "[", "\"data\"", "]", "\n", "history_file", "=", "os", ".", "path", ".", "join", "(", "out_root_dir", ",", "\"{}-history.{}.txt\"", ".", "format", "(", "out_prefix", ",", "data_type", ")", ")", "\n", "ref_file", "=", "os", ".", "path", ".", "join", "(", "out_root_dir", ",", "\"{}-src.{}.txt\"", ".", "format", "(", "out_prefix", ",", "data_type", ")", ")", "\n", "target_file", "=", "os", ".", "path", ".", "join", "(", "out_root_dir", ",", "\"{}-tgt.{}.txt\"", ".", "format", "(", "out_prefix", ",", "data_type", ")", ")", "\n", "ans_file", "=", "os", ".", "path", ".", "join", "(", "out_root_dir", ",", "\"{}-ans.{}.txt\"", ".", "format", "(", "out_prefix", ",", "data_type", ")", ")", "\n", "id_file", "=", "os", ".", "path", ".", "join", "(", "out_root_dir", ",", "\"{}-id.{}.txt\"", ".", "format", "(", "out_prefix", ",", "data_type", ")", ")", "\n", "with", "open", "(", "history_file", ",", "\"w\"", ")", "as", "fhis", ",", "open", "(", "ref_file", ",", "\"w\"", ")", "as", "fref", ",", "open", "(", "target_file", ",", "\"w\"", ")", "as", "ftgt", ",", "open", "(", "ans_file", ",", "'w'", ")", "as", "fans", ",", "open", "(", "id_file", ",", "'w'", ")", "as", "fid", ":", "\n", "        ", "for", "entry", "in", "tqdm", "(", "data", ")", ":", "\n", "# story = entry[\"story\"]", "\n", "            ", "questions", "=", "entry", "[", "\"questions\"", "]", "\n", "answers", "=", "entry", "[", "\"answers\"", "]", "\n", "history", "=", "[", "]", "\n", "for", "que", ",", "ans", "in", "zip", "(", "questions", ",", "answers", ")", ":", "\n", "                ", "que_raw_text", "=", "remove_space", "(", "que", "[", "\"input_text\"", "]", ".", "lower", "(", ")", ")", "\n", "ans_raw_text", "=", "remove_space", "(", "ans", "[", "\"input_text\"", "]", ".", "lower", "(", ")", ")", "\n", "ref_raw_text", "=", "remove_space", "(", "ans", "[", "'span_text'", "]", ".", "lower", "(", ")", ")", "\n", "identify", "=", "\"{},{}\"", ".", "format", "(", "entry", "[", "'id'", "]", ",", "que", "[", "'turn_id'", "]", ")", "\n", "que_tokens", "=", "tokenizer", "(", "que_raw_text", ")", "\n", "que_tokens", "=", "que_tokens", "[", ":", "MAX_LENGTH", "]", "\n", "ans_tokens", "=", "tokenizer", "(", "ans_raw_text", ")", "\n", "ans_tokens", "=", "ans_tokens", "[", ":", "MAX_LENGTH", "]", "\n", "ref_tokens", "=", "tokenizer", "(", "ref_raw_text", ")", "\n", "ref_tokens", "=", "ref_tokens", "[", ":", "MAX_LENGTH", "]", "\n", "ref_text", "=", "[", "token", ".", "text", "for", "token", "in", "ref_tokens", "]", "\n", "que_text", "=", "[", "token", ".", "text", "for", "token", "in", "que_tokens", "]", "\n", "ans_text", "=", "[", "token", ".", "text", "for", "token", "in", "ans_tokens", "]", "\n", "history_text", "=", "history_to_string", "(", "history", ",", "n_history", ")", "\n", "# we append this ans and que to history after generate history_text", "\n", "history", ".", "append", "(", "(", "que_text", ",", "ans_text", ")", ")", "\n", "fhis", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "\" \"", ".", "join", "(", "history_text", ")", ".", "strip", "(", ")", ")", ")", "\n", "fref", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "\" \"", ".", "join", "(", "ref_text", ")", ".", "strip", "(", ")", ")", ")", "\n", "ftgt", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "\" \"", ".", "join", "(", "que_text", ")", ".", "strip", "(", ")", ")", ")", "\n", "fans", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "\" \"", ".", "join", "(", "ans_text", ")", ".", "strip", "(", ")", ")", ")", "\n", "fid", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "identify", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.cqg_preprocess.preprocess": [[128, 148], ["English", "English().Defaults.create_tokenizer", "cqg_preprocess.process_file", "cqg_preprocess.process_file", "English"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.process_file", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.process_file"], ["", "", "", "", "def", "preprocess", "(", "args", ")", ":", "\n", "\n", "    ", "from", "spacy", ".", "lang", ".", "en", "import", "English", "\n", "nlp", "=", "English", "(", ")", "\n", "tokenizer", "=", "English", "(", ")", ".", "Defaults", ".", "create_tokenizer", "(", "nlp", ")", "\n", "process_file", "(", "\n", "tokenizer", ",", "\n", "\"train\"", ",", "\n", "args", ".", "raw_trainset_file", ",", "\n", "args", ".", "data_root_dir", ",", "\n", "args", ".", "out_prefix", ",", "\n", "args", ".", "n_history", ")", "\n", "\n", "process_file", "(", "\n", "tokenizer", ",", "\n", "\"dev\"", ",", "\n", "args", ".", "raw_devset_file", ",", "\n", "args", ".", "data_root_dir", ",", "\n", "args", ".", "out_prefix", ",", "\n", "args", ".", "n_history", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.train.ErrorHandler.__init__": [[64, 74], ["threading.Thread", "train.ErrorHandler.error_thread.start", "signal.signal"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.TranslationServer.start"], ["def", "__init__", "(", "self", ",", "error_queue", ")", ":", "\n", "        ", "\"\"\" init error handler \"\"\"", "\n", "import", "signal", "\n", "import", "threading", "\n", "self", ".", "error_queue", "=", "error_queue", "\n", "self", ".", "children_pids", "=", "[", "]", "\n", "self", ".", "error_thread", "=", "threading", ".", "Thread", "(", "\n", "target", "=", "self", ".", "error_listener", ",", "daemon", "=", "True", ")", "\n", "self", ".", "error_thread", ".", "start", "(", ")", "\n", "signal", ".", "signal", "(", "signal", ".", "SIGUSR1", ",", "self", ".", "signal_handler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.train.ErrorHandler.add_child": [[75, 78], ["train.ErrorHandler.children_pids.append"], "methods", ["None"], ["", "def", "add_child", "(", "self", ",", "pid", ")", ":", "\n", "        ", "\"\"\" error handler \"\"\"", "\n", "self", ".", "children_pids", ".", "append", "(", "pid", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.train.ErrorHandler.error_listener": [[79, 84], ["train.ErrorHandler.error_queue.get", "train.ErrorHandler.error_queue.put", "os.kill", "os.getpid"], "methods", ["None"], ["", "def", "error_listener", "(", "self", ")", ":", "\n", "        ", "\"\"\" error listener \"\"\"", "\n", "(", "rank", ",", "original_trace", ")", "=", "self", ".", "error_queue", ".", "get", "(", ")", "\n", "self", ".", "error_queue", ".", "put", "(", "(", "rank", ",", "original_trace", ")", ")", "\n", "os", ".", "kill", "(", "os", ".", "getpid", "(", ")", ",", "signal", ".", "SIGUSR1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.train.ErrorHandler.signal_handler": [[85, 94], ["train.ErrorHandler.error_queue.get", "Exception", "os.kill"], "methods", ["None"], ["", "def", "signal_handler", "(", "self", ",", "signalnum", ",", "stackframe", ")", ":", "\n", "        ", "\"\"\" signal handler \"\"\"", "\n", "for", "pid", "in", "self", ".", "children_pids", ":", "\n", "            ", "os", ".", "kill", "(", "pid", ",", "signal", ".", "SIGINT", ")", "# kill children processes", "\n", "", "(", "rank", ",", "original_trace", ")", "=", "self", ".", "error_queue", ".", "get", "(", ")", "\n", "msg", "=", "\"\"\"\\n\\n-- Tracebacks above this line can probably\n                 be ignored --\\n\\n\"\"\"", "\n", "msg", "+=", "original_trace", "\n", "raise", "Exception", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.train.main": [[15, 42], ["onmt.utils.parse.ArgumentParser.validate_train_opts", "onmt.utils.parse.ArgumentParser.update_model_opts", "onmt.utils.parse.ArgumentParser.validate_model_opts", "len", "torch.multiprocessing.get_context", "torch.multiprocessing.get_context.SimpleQueue", "train.ErrorHandler", "range", "procs.append", "procs[].start", "onmt.utils.logging.logger.info", "train.ErrorHandler.add_child", "p.join", "onmt.train_single.main", "onmt.train_single.main", "torch.multiprocessing.get_context.Process"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.parse.ArgumentParser.validate_train_opts", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.parse.ArgumentParser.update_model_opts", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.parse.ArgumentParser.validate_model_opts", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.TranslationServer.start", "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.train.ErrorHandler.add_child", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.create_vocabulary.main", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.create_vocabulary.main"], ["def", "main", "(", "opt", ")", ":", "\n", "    ", "ArgumentParser", ".", "validate_train_opts", "(", "opt", ")", "\n", "ArgumentParser", ".", "update_model_opts", "(", "opt", ")", "\n", "ArgumentParser", ".", "validate_model_opts", "(", "opt", ")", "\n", "\n", "nb_gpu", "=", "len", "(", "opt", ".", "gpu_ranks", ")", "\n", "\n", "if", "opt", ".", "world_size", ">", "1", ":", "\n", "        ", "mp", "=", "torch", ".", "multiprocessing", ".", "get_context", "(", "'spawn'", ")", "\n", "# Create a thread to listen for errors in the child processes.", "\n", "error_queue", "=", "mp", ".", "SimpleQueue", "(", ")", "\n", "error_handler", "=", "ErrorHandler", "(", "error_queue", ")", "\n", "# Train with multiprocessing.", "\n", "procs", "=", "[", "]", "\n", "for", "device_id", "in", "range", "(", "nb_gpu", ")", ":", "\n", "            ", "procs", ".", "append", "(", "mp", ".", "Process", "(", "target", "=", "run", ",", "args", "=", "(", "\n", "opt", ",", "device_id", ",", "error_queue", ",", ")", ",", "daemon", "=", "True", ")", ")", "\n", "procs", "[", "device_id", "]", ".", "start", "(", ")", "\n", "logger", ".", "info", "(", "\" Starting process pid: %d  \"", "%", "procs", "[", "device_id", "]", ".", "pid", ")", "\n", "error_handler", ".", "add_child", "(", "procs", "[", "device_id", "]", ".", "pid", ")", "\n", "", "for", "p", "in", "procs", ":", "\n", "            ", "p", ".", "join", "(", ")", "\n", "\n", "", "", "elif", "nb_gpu", "==", "1", ":", "# case 1 GPU only", "\n", "        ", "single_main", "(", "opt", ",", "0", ")", "\n", "", "else", ":", "# case only CPU", "\n", "        ", "single_main", "(", "opt", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.train.run": [[44, 58], ["onmt.utils.distributed.multi_init", "onmt.utils.distributed.multi_init", "onmt.train_single.main", "AssertionError", "error_queue.put", "traceback.format_exc"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.distributed.multi_init", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.distributed.multi_init", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.create_vocabulary.main"], ["", "", "def", "run", "(", "opt", ",", "device_id", ",", "error_queue", ")", ":", "\n", "    ", "\"\"\" run process \"\"\"", "\n", "try", ":", "\n", "        ", "gpu_rank", "=", "onmt", ".", "utils", ".", "distributed", ".", "multi_init", "(", "opt", ",", "device_id", ")", "\n", "if", "gpu_rank", "!=", "opt", ".", "gpu_ranks", "[", "device_id", "]", ":", "\n", "            ", "raise", "AssertionError", "(", "\"An error occurred in \\\n                  Distributed initialization\"", ")", "\n", "", "single_main", "(", "opt", ",", "device_id", ")", "\n", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "pass", "# killed by parent, do nothing", "\n", "", "except", "Exception", ":", "\n", "# propagate exception to parent process, keeping original traceback", "\n", "        ", "import", "traceback", "\n", "error_queue", ".", "put", "(", "(", "opt", ".", "gpu_ranks", "[", "device_id", "]", ",", "traceback", ".", "format_exc", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.train._get_parser": [[96, 103], ["onmt.utils.parse.ArgumentParser", "onmt.config_opts", "onmt.model_opts", "onmt.train_opts"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.opts.config_opts", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.opts.model_opts", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.opts.train_opts"], ["", "", "def", "_get_parser", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", "description", "=", "'train.py'", ")", "\n", "\n", "opts", ".", "config_opts", "(", "parser", ")", "\n", "opts", ".", "model_opts", "(", "parser", ")", "\n", "opts", ".", "train_opts", "(", "parser", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.preprocess.check_existing_pt_files": [[20, 29], ["pattern.format", "glob.glob", "sys.stderr.write", "sys.exit"], "function", ["None"], ["def", "check_existing_pt_files", "(", "opt", ")", ":", "\n", "    ", "\"\"\" Check if there are existing .pt files to avoid overwriting them \"\"\"", "\n", "pattern", "=", "opt", ".", "save_data", "+", "'.{}*.pt'", "\n", "for", "t", "in", "[", "'train'", ",", "'valid'", ",", "'vocab'", "]", ":", "\n", "        ", "path", "=", "pattern", ".", "format", "(", "t", ")", "\n", "if", "glob", ".", "glob", "(", "path", ")", ":", "\n", "            ", "sys", ".", "stderr", ".", "write", "(", "\"Please backup existing pt files: %s, \"", "\n", "\"to avoid overwriting them!\\n\"", "%", "path", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.preprocess.build_save_dataset": [[31, 86], ["onmt.utils.logging.logger.info", "onmt.utils.misc.split_corpus", "onmt.utils.misc.split_corpus", "onmt.utils.misc.split_corpus", "onmt.utils.misc.split_corpus", "zip", "onmt.utils.logging.logger.info", "enumerate", "functools.partial", "onmt.utils.logging.logger.info", "onmt.Dataset", "dataset_paths.append", "onmt.utils.logging.logger.info", "inputters.Dataset.save", "gc.collect", "gc.collect", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.split_corpus", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.split_corpus", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.split_corpus", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.split_corpus", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.ModelSaverBase.save"], ["", "", "", "def", "build_save_dataset", "(", "corpus_type", ",", "fields", ",", "src_reader", ",", "history_reader", ",", "ans_reader", ",", "tgt_reader", ",", "opt", ")", ":", "\n", "    ", "assert", "corpus_type", "in", "[", "'train'", ",", "'valid'", "]", "\n", "\n", "if", "corpus_type", "==", "'train'", ":", "\n", "        ", "src", "=", "opt", ".", "train_src", "\n", "history", "=", "opt", ".", "train_history", "\n", "ans", "=", "opt", ".", "train_ans", "\n", "tgt", "=", "opt", ".", "train_tgt", "\n", "", "else", ":", "\n", "        ", "src", "=", "opt", ".", "valid_src", "\n", "history", "=", "opt", ".", "valid_history", "\n", "ans", "=", "opt", ".", "valid_ans", "\n", "tgt", "=", "opt", ".", "valid_tgt", "\n", "\n", "", "logger", ".", "info", "(", "\"Reading source and target files: %s %s %s %s.\"", "%", "(", "src", ",", "history", ",", "ans", ",", "tgt", ")", ")", "\n", "\n", "src_shards", "=", "split_corpus", "(", "src", ",", "opt", ".", "shard_size", ")", "\n", "history_shards", "=", "split_corpus", "(", "history", ",", "opt", ".", "shard_size", ")", "\n", "ans_shards", "=", "split_corpus", "(", "ans", ",", "opt", ".", "shard_size", ")", "\n", "tgt_shards", "=", "split_corpus", "(", "tgt", ",", "opt", ".", "shard_size", ")", "\n", "shard_pairs", "=", "zip", "(", "src_shards", ",", "history_shards", ",", "ans_shards", ",", "tgt_shards", ")", "\n", "dataset_paths", "=", "[", "]", "\n", "if", "(", "corpus_type", "==", "\"train\"", "or", "opt", ".", "filter_valid", ")", "and", "tgt", "is", "not", "None", ":", "\n", "        ", "filter_pred", "=", "partial", "(", "\n", "inputters", ".", "filter_example", ",", "use_src_len", "=", "opt", ".", "data_type", "==", "\"text\"", ",", "use_history_len", "=", "False", ",", "\n", "max_src_len", "=", "opt", ".", "src_seq_length", ",", "max_history_len", "=", "-", "1", ",", "max_tgt_len", "=", "opt", ".", "tgt_seq_length", ")", "\n", "", "else", ":", "\n", "        ", "filter_pred", "=", "None", "\n", "", "logger", ".", "info", "(", "\"filter_pred is not used:{}\"", ".", "format", "(", "filter_pred", ")", ")", "\n", "for", "i", ",", "(", "src_shard", ",", "history_shard", ",", "ans_shard", ",", "tgt_shard", ")", "in", "enumerate", "(", "shard_pairs", ")", ":", "\n", "        ", "assert", "len", "(", "src_shard", ")", "==", "len", "(", "tgt_shard", ")", "and", "len", "(", "src_shard", ")", "==", "len", "(", "history_shard", ")", "and", "len", "(", "src_shard", ")", "==", "len", "(", "ans_shard", ")", "\n", "logger", ".", "info", "(", "\"Building shard %d.\"", "%", "i", ")", "\n", "dataset", "=", "inputters", ".", "Dataset", "(", "\n", "fields", ",", "\n", "readers", "=", "[", "src_reader", ",", "history_reader", ",", "ans_reader", ",", "tgt_reader", "]", "if", "tgt_reader", "else", "[", "src_reader", ",", "history_reader", ",", "ans_reader", "]", ",", "\n", "data", "=", "(", "[", "(", "\"src\"", ",", "src_shard", ")", ",", "(", "\"history\"", ",", "history_shard", ")", ",", "(", "\"ans\"", ",", "ans_shard", ")", ",", "(", "\"tgt\"", ",", "tgt_shard", ")", "]", "\n", "if", "tgt_reader", "else", "[", "(", "\"src\"", ",", "src_shard", ")", ",", "(", "\"history\"", ",", "history_shard", ")", ",", "(", "\"ans\"", ",", "ans_shard", ")", "]", ")", ",", "\n", "dirs", "=", "[", "opt", ".", "src_dir", ",", "opt", ".", "src_dir", ",", "opt", ".", "src_dir", ",", "None", "]", "if", "tgt_reader", "else", "[", "opt", ".", "src_dir", ",", "opt", ".", "src_dir", ",", "opt", ".", "src_dir", "]", ",", "\n", "sort_key", "=", "inputters", ".", "str2sortkey", "[", "opt", ".", "data_type", "]", ",", "\n", "filter_pred", "=", "None", "\n", ")", "\n", "\n", "data_path", "=", "\"{:s}.{:s}.{:d}.pt\"", ".", "format", "(", "opt", ".", "save_data", ",", "corpus_type", ",", "i", ")", "\n", "dataset_paths", ".", "append", "(", "data_path", ")", "\n", "\n", "logger", ".", "info", "(", "\" * saving %sth %s data shard to %s.\"", "\n", "%", "(", "i", ",", "corpus_type", ",", "data_path", ")", ")", "\n", "dataset", ".", "save", "(", "data_path", ")", "\n", "\n", "del", "dataset", ".", "examples", "\n", "gc", ".", "collect", "(", ")", "\n", "del", "dataset", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "", "return", "dataset_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.preprocess.build_save_vocab": [[88, 98], ["onmt.build_vocab", "torch.save"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.build_vocab", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.ModelSaverBase.save"], ["", "def", "build_save_vocab", "(", "train_dataset", ",", "fields", ",", "opt", ")", ":", "\n", "    ", "fields", "=", "inputters", ".", "build_vocab", "(", "\n", "train_dataset", ",", "fields", ",", "opt", ".", "data_type", ",", "opt", ".", "share_vocab", ",", "\n", "opt", ".", "src_vocab", ",", "opt", ".", "src_vocab_size", ",", "opt", ".", "src_words_min_frequency", ",", "\n", "opt", ".", "tgt_vocab", ",", "opt", ".", "tgt_vocab_size", ",", "opt", ".", "tgt_words_min_frequency", ",", "\n", "vocab_size_multiple", "=", "opt", ".", "vocab_size_multiple", "\n", ")", "\n", "\n", "vocab_path", "=", "opt", ".", "save_data", "+", "'.vocab.pt'", "\n", "torch", ".", "save", "(", "fields", ",", "vocab_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.preprocess.count_features": [[100, 109], ["codecs.open", "f.readline().split", "len", "first_tok.split", "f.readline"], "function", ["None"], ["", "def", "count_features", "(", "path", ")", ":", "\n", "    ", "\"\"\"\n    path: location of a corpus file with whitespace-delimited tokens and\n                    \uffe8-delimited features within the token\n    returns: the number of features in the dataset\n    \"\"\"", "\n", "with", "codecs", ".", "open", "(", "path", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "first_tok", "=", "f", ".", "readline", "(", ")", ".", "split", "(", "None", ",", "1", ")", "[", "0", "]", "\n", "return", "len", "(", "first_tok", ".", "split", "(", "u\"\uffe8\"", ")", ")", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.preprocess.main": [[111, 149], ["onmt.utils.parse.ArgumentParser.validate_preprocess_args", "torch.manual_seed", "preprocess.check_existing_pt_files", "onmt.utils.logging.init_logger", "onmt.utils.logging.logger.info", "preprocess.count_features", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.get_fields", "onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "onmt.utils.logging.logger.info", "preprocess.build_save_dataset", "onmt.utils.logging.logger.info", "preprocess.build_save_vocab", "preprocess.count_features", "onmt.utils.logging.logger.info", "preprocess.build_save_dataset"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.parse.ArgumentParser.validate_preprocess_args", "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.preprocess.check_existing_pt_files", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.logging.init_logger", "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.preprocess.count_features", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.get_fields", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.preprocess.build_save_dataset", "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.preprocess.build_save_vocab", "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.preprocess.count_features", "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.preprocess.build_save_dataset"], ["", "", "def", "main", "(", "opt", ")", ":", "\n", "    ", "ArgumentParser", ".", "validate_preprocess_args", "(", "opt", ")", "\n", "torch", ".", "manual_seed", "(", "opt", ".", "seed", ")", "\n", "check_existing_pt_files", "(", "opt", ")", "\n", "\n", "init_logger", "(", "opt", ".", "log_file", ")", "\n", "logger", ".", "info", "(", "\"Extracting features...\"", ")", "\n", "\n", "src_nfeats", "=", "count_features", "(", "opt", ".", "train_src", ")", "if", "opt", ".", "data_type", "==", "'text'", "else", "0", "\n", "tgt_nfeats", "=", "count_features", "(", "opt", ".", "train_tgt", ")", "# tgt always text so far", "\n", "logger", ".", "info", "(", "\" * number of source features: %d.\"", "%", "src_nfeats", ")", "\n", "logger", ".", "info", "(", "\" * number of target features: %d.\"", "%", "tgt_nfeats", ")", "\n", "\n", "logger", ".", "info", "(", "\"Building `Fields` object...\"", ")", "\n", "fields", "=", "inputters", ".", "get_fields", "(", "\n", "opt", ".", "data_type", ",", "\n", "src_nfeats", ",", "\n", "tgt_nfeats", ",", "\n", "dynamic_dict", "=", "opt", ".", "dynamic_dict", ",", "\n", "src_truncate", "=", "opt", ".", "src_seq_length_trunc", ",", "\n", "tgt_truncate", "=", "opt", ".", "tgt_seq_length_trunc", ")", "\n", "\n", "src_reader", "=", "inputters", ".", "str2reader", "[", "opt", ".", "data_type", "]", ".", "from_opt", "(", "opt", ")", "\n", "history_reader", "=", "inputters", ".", "str2reader", "[", "opt", ".", "data_type", "]", ".", "from_opt", "(", "opt", ")", "\n", "ans_reader", "=", "inputters", ".", "str2reader", "[", "opt", ".", "data_type", "]", ".", "from_opt", "(", "opt", ")", "\n", "tgt_reader", "=", "inputters", ".", "str2reader", "[", "\"text\"", "]", ".", "from_opt", "(", "opt", ")", "\n", "\n", "logger", ".", "info", "(", "\"Building & saving training data...\"", ")", "\n", "train_dataset_files", "=", "build_save_dataset", "(", "\n", "'train'", ",", "fields", ",", "src_reader", ",", "history_reader", ",", "ans_reader", ",", "tgt_reader", ",", "opt", ")", "\n", "\n", "if", "opt", ".", "valid_src", "and", "opt", ".", "valid_tgt", "and", "opt", ".", "valid_history", "and", "opt", ".", "valid_ans", ":", "\n", "        ", "logger", ".", "info", "(", "\"Building & saving validation data...\"", ")", "\n", "build_save_dataset", "(", "'valid'", ",", "fields", ",", "src_reader", ",", "history_reader", ",", "ans_reader", ",", "tgt_reader", ",", "opt", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Building & saving vocabulary...\"", ")", "\n", "build_save_vocab", "(", "train_dataset_files", ",", "fields", ",", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.None.preprocess._get_parser": [[151, 157], ["onmt.utils.parse.ArgumentParser", "onmt.config_opts", "onmt.preprocess_opts"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.opts.config_opts", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.opts.preprocess_opts"], ["", "def", "_get_parser", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", "description", "=", "'preprocess.py'", ")", "\n", "\n", "opts", ".", "config_opts", "(", "parser", ")", "\n", "opts", ".", "preprocess_opts", "(", "parser", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.opts.StoreLoggingLevelAction.__init__": [[788, 791], ["configargparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "help", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "StoreLoggingLevelAction", ",", "self", ")", ".", "__init__", "(", "\n", "option_strings", ",", "dest", ",", "help", "=", "help", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.opts.StoreLoggingLevelAction.__call__": [[792, 796], ["StoreLoggingLevelAction.LEVELS.get", "setattr"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "value", ",", "option_string", "=", "None", ")", ":", "\n", "# Get the key 'value' in the dict, or just use 'value'", "\n", "        ", "level", "=", "StoreLoggingLevelAction", ".", "LEVELS", ".", "get", "(", "value", ",", "value", ")", "\n", "setattr", "(", "namespace", ",", "self", ".", "dest", ",", "level", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.opts.DeprecateAction.__init__": [[801, 804], ["configargparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "help", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DeprecateAction", ",", "self", ")", ".", "__init__", "(", "option_strings", ",", "dest", ",", "nargs", "=", "0", ",", "\n", "help", "=", "help", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.opts.DeprecateAction.__call__": [[805, 809], ["configargparse.ArgumentTypeError"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "flag_name", ")", ":", "\n", "        ", "help", "=", "self", ".", "help", "if", "self", ".", "help", "is", "not", "None", "else", "\"\"", "\n", "msg", "=", "\"Flag '%s' is deprecated. %s\"", "%", "(", "flag_name", ",", "help", ")", "\n", "raise", "configargparse", ".", "ArgumentTypeError", "(", "msg", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.opts.config_opts": [[9, 15], ["parser.add", "parser.add"], "function", ["None"], ["def", "config_opts", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add", "(", "'-config'", ",", "'--config'", ",", "required", "=", "False", ",", "\n", "is_config_file_arg", "=", "True", ",", "help", "=", "'config file path'", ")", "\n", "parser", ".", "add", "(", "'-save_config'", ",", "'--save_config'", ",", "required", "=", "False", ",", "\n", "is_write_out_config_file_arg", "=", "True", ",", "\n", "help", "=", "'config file save path'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.opts.model_opts": [[17, 177], ["parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add"], "function", ["None"], ["", "def", "model_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\"\n    These options are passed to the construction of the model.\n    Be careful with these as they will be used during translation.\n    \"\"\"", "\n", "\n", "# Embedding Options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model-Embeddings'", ")", "\n", "group", ".", "add", "(", "'--src_word_vec_size'", ",", "'-src_word_vec_size'", ",", "\n", "type", "=", "int", ",", "default", "=", "300", ",", "\n", "help", "=", "'Word embedding size for src.'", ")", "\n", "group", ".", "add", "(", "'--tgt_word_vec_size'", ",", "'-tgt_word_vec_size'", ",", "\n", "type", "=", "int", ",", "default", "=", "300", ",", "\n", "help", "=", "'Word embedding size for tgt.'", ")", "\n", "group", ".", "add", "(", "'--word_vec_size'", ",", "'-word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Word embedding size for src and tgt.'", ")", "\n", "\n", "group", ".", "add", "(", "'--share_decoder_embeddings'", ",", "'-share_decoder_embeddings'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use a shared weight matrix for the input and \"", "\n", "\"output word  embeddings in the decoder.\"", ")", "\n", "group", ".", "add", "(", "'--share_embeddings'", ",", "'-share_embeddings'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Share the word embeddings between encoder \"", "\n", "\"and decoder. Need to use shared dictionary for this \"", "\n", "\"option.\"", ")", "\n", "group", ".", "add", "(", "'--position_encoding'", ",", "'-position_encoding'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use a sin to mark relative words positions. \"", "\n", "\"Necessary for non-RNN style models.\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model-Embedding Features'", ")", "\n", "group", ".", "add", "(", "'--feat_merge'", ",", "'-feat_merge'", ",", "type", "=", "str", ",", "default", "=", "'concat'", ",", "\n", "choices", "=", "[", "'concat'", ",", "'sum'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"Merge action for incorporating features embeddings. \"", "\n", "\"Options [concat|sum|mlp].\"", ")", "\n", "group", ".", "add", "(", "'--feat_vec_size'", ",", "'-feat_vec_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"If specified, feature embedding sizes \"", "\n", "\"will be set to this. Otherwise, feat_vec_exponent \"", "\n", "\"will be used.\"", ")", "\n", "group", ".", "add", "(", "'--feat_vec_exponent'", ",", "'-feat_vec_exponent'", ",", "\n", "type", "=", "float", ",", "default", "=", "0.7", ",", "\n", "help", "=", "\"If -feat_merge_size is not set, feature \"", "\n", "\"embedding sizes will be set to N^feat_vec_exponent \"", "\n", "\"where N is the number of values the feature takes.\"", ")", "\n", "\n", "# Encoder-Decoder Options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model- Encoder-Decoder'", ")", "\n", "group", ".", "add", "(", "'--model_type'", ",", "'-model_type'", ",", "default", "=", "'text'", ",", "\n", "choices", "=", "[", "'text'", ",", "'img'", ",", "'audio'", "]", ",", "\n", "help", "=", "\"Type of source model to use. Allows \"", "\n", "\"the system to incorporate non-text inputs. \"", "\n", "\"Options are [text|img|audio].\"", ")", "\n", "group", ".", "add", "(", "'--model_dtype'", ",", "'-model_dtype'", ",", "default", "=", "'fp32'", ",", "\n", "choices", "=", "[", "'fp32'", ",", "'fp16'", "]", ",", "\n", "help", "=", "'Data type of the model.'", ")", "\n", "\n", "group", ".", "add", "(", "'--encoder_type'", ",", "'-encoder_type'", ",", "type", "=", "str", ",", "default", "=", "'redr'", ")", "\n", "group", ".", "add", "(", "'--decoder_type'", ",", "'-decoder_type'", ",", "type", "=", "str", ",", "default", "=", "'rnn'", ")", "\n", "\n", "group", ".", "add", "(", "'--layers'", ",", "'-layers'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Number of layers in enc/dec.'", ")", "\n", "group", ".", "add", "(", "'--n_memory_layers'", ",", "'-n_memory_layers'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "'Number of layers in redr.'", ")", "\n", "\n", "group", ".", "add", "(", "'--enc_layers'", ",", "'-enc_layers'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'Number of layers in the encoder'", ")", "\n", "group", ".", "add", "(", "'--dec_layers'", ",", "'-dec_layers'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'Number of layers in the decoder'", ")", "\n", "group", ".", "add", "(", "'--rnn_size'", ",", "'-rnn_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Size of rnn hidden states. Overwrites \"", "\n", "\"enc_rnn_size and dec_rnn_size\"", ")", "\n", "group", ".", "add", "(", "'--enc_rnn_size'", ",", "'-enc_rnn_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "\"Size of encoder rnn hidden states. \"", "\n", "\"Must be equal to dec_rnn_size except for \"", "\n", "\"speech-to-text.\"", ")", "\n", "group", ".", "add", "(", "'--dec_rnn_size'", ",", "'-dec_rnn_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "\"Size of decoder rnn hidden states. \"", "\n", "\"Must be equal to enc_rnn_size except for \"", "\n", "\"speech-to-text.\"", ")", "\n", "group", ".", "add", "(", "'--audio_enc_pooling'", ",", "'-audio_enc_pooling'", ",", "\n", "type", "=", "str", ",", "default", "=", "'1'", ",", "\n", "help", "=", "\"The amount of pooling of audio encoder, \"", "\n", "\"either the same amount of pooling across all layers \"", "\n", "\"indicated by a single number, or different amounts of \"", "\n", "\"pooling per layer separated by comma.\"", ")", "\n", "group", ".", "add", "(", "'--cnn_kernel_width'", ",", "'-cnn_kernel_width'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "\"Size of windows in the cnn, the kernel_size is \"", "\n", "\"(cnn_kernel_width, 1) in conv layer\"", ")", "\n", "\n", "group", ".", "add", "(", "'--input_feed'", ",", "'-input_feed'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Feed the context vector at each time step as \"", "\n", "\"additional input (via concatenation with the word \"", "\n", "\"embeddings) to the decoder.\"", ")", "\n", "group", ".", "add", "(", "'--bridge'", ",", "'-bridge'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Have an additional layer between the last encoder \"", "\n", "\"state and the first decoder state\"", ")", "\n", "group", ".", "add", "(", "'--rnn_type'", ",", "'-rnn_type'", ",", "type", "=", "str", ",", "default", "=", "'LSTM'", ",", "\n", "choices", "=", "[", "'LSTM'", ",", "'GRU'", ",", "'SRU'", "]", ",", "\n", "action", "=", "CheckSRU", ",", "\n", "help", "=", "\"The gate type to use in the RNNs\"", ")", "\n", "# group.add('--residual', '-residual',   action=\"store_true\",", "\n", "#                     help=\"Add residual connections between RNN layers.\")", "\n", "\n", "group", ".", "add", "(", "'--brnn'", ",", "'-brnn'", ",", "action", "=", "DeprecateAction", ",", "\n", "help", "=", "\"Deprecated, use `encoder_type`.\"", ")", "\n", "\n", "group", ".", "add", "(", "'--context_gate'", ",", "'-context_gate'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "choices", "=", "[", "'source'", ",", "'target'", ",", "'both'", "]", ",", "\n", "help", "=", "\"Type of context gate to use. \"", "\n", "\"Do not select for no context gate.\"", ")", "\n", "\n", "# Attention options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model- Attention'", ")", "\n", "group", ".", "add", "(", "'--global_attention'", ",", "'-global_attention'", ",", "\n", "type", "=", "str", ",", "default", "=", "'general'", ",", "\n", "choices", "=", "[", "'dot'", ",", "'general'", ",", "'mlp'", ",", "'none'", "]", ",", "\n", "help", "=", "\"The attention type to use: \"", "\n", "\"dotprod or general (Luong) or MLP (Bahdanau)\"", ")", "\n", "group", ".", "add", "(", "'--global_attention_function'", ",", "'-global_attention_function'", ",", "\n", "type", "=", "str", ",", "default", "=", "\"softmax\"", ",", "choices", "=", "[", "\"softmax\"", ",", "\"sparsemax\"", "]", ")", "\n", "group", ".", "add", "(", "'--self_attn_type'", ",", "'-self_attn_type'", ",", "\n", "type", "=", "str", ",", "default", "=", "\"scaled-dot\"", ",", "\n", "help", "=", "'Self attention type in Transformer decoder '", "\n", "'layer -- currently \"scaled-dot\" or \"average\" '", ")", "\n", "group", ".", "add", "(", "'--max_relative_positions'", ",", "'-max_relative_positions'", ",", "\n", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Maximum distance between inputs in relative \"", "\n", "\"positions representations. \"", "\n", "\"For more detailed information, see: \"", "\n", "\"https://arxiv.org/pdf/1803.02155.pdf\"", ")", "\n", "group", ".", "add", "(", "'--heads'", ",", "'-heads'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "'Number of heads for transformer self-attention'", ")", "\n", "group", ".", "add", "(", "'--transformer_ff'", ",", "'-transformer_ff'", ",", "type", "=", "int", ",", "default", "=", "2048", ",", "\n", "help", "=", "'Size of hidden transformer feed-forward'", ")", "\n", "\n", "# Generator and loss options.", "\n", "group", ".", "add", "(", "'--copy_attn'", ",", "'-copy_attn'", ",", "action", "=", "\"store_false\"", ",", "default", "=", "True", ",", "\n", "help", "=", "'Train copy attention layer.'", ")", "\n", "group", ".", "add", "(", "'--copy_attn_type'", ",", "'-copy_attn_type'", ",", "\n", "type", "=", "str", ",", "default", "=", "'dot'", ",", "\n", "choices", "=", "[", "'dot'", ",", "'general'", ",", "'mlp'", ",", "'none'", "]", ",", "\n", "help", "=", "\"The copy attention type to use. Leave as None to use \"", "\n", "\"the same as -global_attention.\"", ")", "\n", "group", ".", "add", "(", "'--generator_function'", ",", "'-generator_function'", ",", "default", "=", "\"softmax\"", ",", "\n", "choices", "=", "[", "\"softmax\"", ",", "\"sparsemax\"", "]", ",", "\n", "help", "=", "\"Which function to use for generating \"", "\n", "\"probabilities over the target vocabulary (choices: \"", "\n", "\"softmax, sparsemax)\"", ")", "\n", "group", ".", "add", "(", "'--copy_attn_force'", ",", "'-copy_attn_force'", ",", "action", "=", "\"store_false\"", ",", "default", "=", "True", ",", "\n", "help", "=", "'When available, train to copy.'", ")", "\n", "group", ".", "add", "(", "'--reuse_copy_attn'", ",", "'-reuse_copy_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Reuse standard attention for copy\"", ")", "\n", "group", ".", "add", "(", "'--copy_loss_by_seqlength'", ",", "'-copy_loss_by_seqlength'", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Divide copy loss by length of sequence\"", ")", "\n", "group", ".", "add", "(", "'--coverage_attn'", ",", "'-coverage_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Train a coverage attention layer.'", ")", "\n", "group", ".", "add", "(", "'--lambda_coverage'", ",", "'-lambda_coverage'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "\n", "help", "=", "'Lambda value for coverage.'", ")", "\n", "group", ".", "add", "(", "'--loss_scale'", ",", "'-loss_scale'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\"For FP16 training, the static loss scale to use. If not \"", "\n", "\"set, the loss scale is dynamically computed.\"", ")", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.opts.preprocess_opts": [[180, 302], ["parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add"], "function", ["None"], ["", "def", "preprocess_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\" Pre-procesing options \"\"\"", "\n", "# Data options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Data'", ")", "\n", "\n", "group", ".", "add", "(", "'--train_src'", ",", "'-train_src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training source data\"", ")", "\n", "group", ".", "add", "(", "'--data_type'", ",", "'-data_type'", ",", "default", "=", "\"text\"", ",", "\n", "help", "=", "\"Type of the source input. Options: [text|img].\"", ")", "\n", "group", ".", "add", "(", "'--train_history'", ",", "'-train_history'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training history data\"", ")", "\n", "group", ".", "add", "(", "'--train_tgt'", ",", "'-train_tgt'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training target data\"", ")", "\n", "group", ".", "add", "(", "'--train_ans'", ",", "'-train_ans'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training ans data\"", ")", "\n", "\n", "group", ".", "add", "(", "'--valid_src'", ",", "'-valid_src'", ",", "\n", "help", "=", "\"Path to the validation source data\"", ")", "\n", "group", ".", "add", "(", "'--valid_history'", ",", "'-valid_history'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the valid history data\"", ")", "\n", "group", ".", "add", "(", "'--valid_tgt'", ",", "'-valid_tgt'", ",", "\n", "help", "=", "\"Path to the validation target data\"", ")", "\n", "group", ".", "add", "(", "'--valid_ans'", ",", "'-valid_ans'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the valid ans data\"", ")", "\n", "\n", "group", ".", "add", "(", "'--src_dir'", ",", "'-src_dir'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Source directory for image or audio files.\"", ")", "\n", "\n", "group", ".", "add", "(", "'--save_data'", ",", "'-save_data'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Output file for the prepared data\"", ")", "\n", "\n", "group", ".", "add", "(", "'--max_shard_size'", ",", "'-max_shard_size'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Deprecated use shard_size instead\"\"\"", ")", "\n", "\n", "group", ".", "add", "(", "'--shard_size'", ",", "'-shard_size'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Divide src_corpus and tgt_corpus into \"", "\n", "\"smaller multiple src_copus and tgt corpus files, then \"", "\n", "\"build shards, each shard will have \"", "\n", "\"opt.shard_size samples except last shard. \"", "\n", "\"shard_size=0 means no segmentation \"", "\n", "\"shard_size>0 means segment dataset into multiple shards, \"", "\n", "\"each shard has shard_size samples\"", ")", "\n", "\n", "# Dictionary options, for text corpus", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Vocab'", ")", "\n", "group", ".", "add", "(", "'--src_vocab'", ",", "'-src_vocab'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Path to an existing source vocabulary. Format: \"", "\n", "\"one word per line.\"", ")", "\n", "group", ".", "add", "(", "'--tgt_vocab'", ",", "'-tgt_vocab'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Path to an existing target vocabulary. Format: \"", "\n", "\"one word per line.\"", ")", "\n", "group", ".", "add", "(", "'--features_vocabs_prefix'", ",", "'-features_vocabs_prefix'", ",", "\n", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "\"Path prefix to existing features vocabularies\"", ")", "\n", "group", ".", "add", "(", "'--src_vocab_size'", ",", "'-src_vocab_size'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "\"Size of the source vocabulary\"", ")", "\n", "group", ".", "add", "(", "'--tgt_vocab_size'", ",", "'-tgt_vocab_size'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "\"Size of the target vocabulary\"", ")", "\n", "group", ".", "add", "(", "'--vocab_size_multiple'", ",", "'-vocab_size_multiple'", ",", "\n", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Make the vocabulary size a multiple of this value\"", ")", "\n", "\n", "group", ".", "add", "(", "'--src_words_min_frequency'", ",", "\n", "'-src_words_min_frequency'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "group", ".", "add", "(", "'--tgt_words_min_frequency'", ",", "\n", "'-tgt_words_min_frequency'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "\n", "group", ".", "add", "(", "'--dynamic_dict'", ",", "'-dynamic_dict'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Create dynamic dictionaries\"", ")", "\n", "group", ".", "add", "(", "'--share_vocab'", ",", "'-share_vocab'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Share source and target vocabulary\"", ")", "\n", "\n", "# Truncation options, for text corpus", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Pruning'", ")", "\n", "group", ".", "add", "(", "'--src_seq_length'", ",", "'-src_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Maximum source sequence length\"", ")", "\n", "group", ".", "add", "(", "'--src_seq_length_trunc'", ",", "'-src_seq_length_trunc'", ",", "\n", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Truncate source sequence length.\"", ")", "\n", "group", ".", "add", "(", "'--tgt_seq_length'", ",", "'-tgt_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Maximum target sequence length to keep.\"", ")", "\n", "group", ".", "add", "(", "'--tgt_seq_length_trunc'", ",", "'-tgt_seq_length_trunc'", ",", "\n", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Truncate target sequence length.\"", ")", "\n", "group", ".", "add", "(", "'--lower'", ",", "'-lower'", ",", "action", "=", "'store_true'", ",", "help", "=", "'lowercase data'", ")", "\n", "group", ".", "add", "(", "'--filter_valid'", ",", "'-filter_valid'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Filter validation data by src and/or tgt length'", ")", "\n", "\n", "# Data processing options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Random'", ")", "\n", "group", ".", "add", "(", "'--shuffle'", ",", "'-shuffle'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Shuffle data\"", ")", "\n", "group", ".", "add", "(", "'--seed'", ",", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "3435", ",", "\n", "help", "=", "\"Random seed\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add", "(", "'--report_every'", ",", "'-report_every'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "\"Report status every this many sentences\"", ")", "\n", "group", ".", "add", "(", "'--log_file'", ",", "'-log_file'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Output logs to a file under this path.\"", ")", "\n", "group", ".", "add", "(", "'--log_file_level'", ",", "'-log_file_level'", ",", "type", "=", "str", ",", "\n", "action", "=", "StoreLoggingLevelAction", ",", "\n", "choices", "=", "StoreLoggingLevelAction", ".", "CHOICES", ",", "\n", "default", "=", "\"0\"", ")", "\n", "\n", "# Options most relevant to speech", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "group", ".", "add", "(", "'--sample_rate'", ",", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add", "(", "'--window_size'", ",", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "\"Window size for spectrogram in seconds.\"", ")", "\n", "group", ".", "add", "(", "'--window_stride'", ",", "'-window_stride'", ",", "type", "=", "float", ",", "default", "=", ".01", ",", "\n", "help", "=", "\"Window stride for spectrogram in seconds.\"", ")", "\n", "group", ".", "add", "(", "'--window'", ",", "'-window'", ",", "default", "=", "'hamming'", ",", "\n", "help", "=", "\"Window type for spectrogram generation.\"", ")", "\n", "\n", "# Option most relevant to image input", "\n", "group", ".", "add", "(", "'--image_channel_size'", ",", "'-image_channel_size'", ",", "\n", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "choices", "=", "[", "3", ",", "1", "]", ",", "\n", "help", "=", "\"Using grayscale image can training \"", "\n", "\"model faster and smaller\"", ")", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.opts.train_opts": [[305, 607], ["os.path.expanduser", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "train_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\" Training and saving options \"\"\"", "\n", "\n", "homedir", "=", "os", ".", "path", ".", "expanduser", "(", "\"~\"", ")", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'General'", ")", "\n", "group", ".", "add", "(", "'--data'", ",", "'-data'", ",", "required", "=", "True", ",", "\n", "help", "=", "'Path prefix to the \".train.pt\" and '", "\n", "'\".valid.pt\" file path from preprocess.py'", ")", "\n", "\n", "# -1: disable , 0: always enable,", "\n", "group", ".", "add", "(", "'--enable_rl_after'", ",", "'-enable_rl_after'", ",", "type", "=", "int", ",", "default", "=", "90000", ",", "\n", "help", "=", "\"\"", ")", "\n", "group", ".", "add", "(", "'--rl_save_step'", ",", "'-rl_save_step'", ",", "type", "=", "int", ",", "default", "=", "5000", ",", "\n", "help", "=", "\"\"", ")", "\n", "group", ".", "add", "(", "'--drqa_vocab_path'", ",", "'-drqa_vocab_path'", ",", "\n", "default", "=", "os", ".", "path", ".", "join", "(", "\"drqa_param\"", ",", "\"vocab.pt\"", ")", ",", "\n", "help", "=", "\".\"", ")", "\n", "group", ".", "add", "(", "'--drqa_config_path'", ",", "'-drqa_config_path'", ",", "\n", "default", "=", "os", ".", "path", ".", "join", "(", "\"drqa_param\"", ",", "\"hparams.json\"", ")", ",", "\n", "help", "=", "\".\"", ")", "\n", "group", ".", "add", "(", "'--drqa_param_path'", ",", "'-drqa_model_path'", ",", "\n", "default", "=", "os", ".", "path", ".", "join", "(", "\"drqa_param\"", ",", "\"params/000000010.params\"", ")", ",", "\n", "help", "=", "\".\"", ")", "\n", "\n", "group", ".", "add", "(", "'--data_type'", ",", "'-data_type'", ",", "default", "=", "\"text\"", ",", "\n", "help", "=", "\"Type of the source input. Options: [text|img].\"", ")", "\n", "\n", "group", ".", "add", "(", "'--save_model'", ",", "'-save_model'", ",", "default", "=", "'model'", ",", "\n", "help", "=", "\"Model filename (the model will be saved as \"", "\n", "\"<save_model>_N.pt where N is the number \"", "\n", "\"of steps\"", ")", "\n", "\n", "group", ".", "add", "(", "'--save_checkpoint_steps'", ",", "'-save_checkpoint_steps'", ",", "\n", "type", "=", "int", ",", "default", "=", "5000", ",", "\n", "help", "=", "\"\"\"Save a checkpoint every X steps\"\"\"", ")", "\n", "group", ".", "add", "(", "'--keep_checkpoint'", ",", "'-keep_checkpoint'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Keep X checkpoints (negative: keep all)\"", ")", "\n", "\n", "# GPU", "\n", "group", ".", "add", "(", "'--gpuid'", ",", "'-gpuid'", ",", "default", "=", "[", "]", ",", "nargs", "=", "'*'", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Deprecated see world_size and gpu_ranks.\"", ")", "\n", "group", ".", "add", "(", "'--coverage_penalty'", ",", "'-coverage_penalty'", ",", "default", "=", "'none'", ",", "\n", "choices", "=", "[", "'none'", ",", "'wu'", ",", "'summary'", "]", ",", "\n", "help", "=", "\"Coverage Penalty to use.\"", ")", "\n", "group", ".", "add", "(", "'--length_penalty'", ",", "'-length_penalty'", ",", "default", "=", "'none'", ",", "\n", "choices", "=", "[", "'none'", ",", "'wu'", ",", "'avg'", "]", ",", "\n", "help", "=", "\"Length Penalty to use.\"", ")", "\n", "group", ".", "add", "(", "'--beta'", ",", "'-beta'", ",", "type", "=", "float", ",", "default", "=", "-", "0.", ",", "\n", "help", "=", "\"Coverage penalty parameter\"", ")", "\n", "group", ".", "add", "(", "'--alpha'", ",", "'-alpha'", ",", "type", "=", "float", ",", "default", "=", "0.", ",", "\n", "help", "=", "\"Google NMT length penalty parameter \"", "\n", "\"(higher = longer generation)\"", ")", "\n", "group", ".", "add", "(", "'--report_bleu'", ",", "'-report_bleu'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Report bleu score after translation, \"", "\n", "\"call tools/multi-bleu.perl on command line\"", ")", "\n", "group", ".", "add", "(", "'--report_rouge'", ",", "'-report_rouge'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Report rouge 1/2/3/L/SU4 score after translation \"", "\n", "\"call tools/test_rouge.py on command line\"", ")", "\n", "group", ".", "add", "(", "'--report_time'", ",", "'-report_time'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Report some translation time metrics\"", ")", "\n", "group", ".", "add", "(", "'--verbose'", ",", "'-verbose'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Print scores and predictions for each sentence'", ")", "\n", "group", ".", "add", "(", "'--replace_unk'", ",", "'-replace_unk'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Replace the generated UNK tokens with the \"", "\n", "\"source token that had highest attention weight. If \"", "\n", "\"phrase_table is provided, it will lookup the \"", "\n", "\"identified source token and give the corresponding \"", "\n", "\"target token. If it is not provided(or the identified \"", "\n", "\"source token does not exist in the table) then it \"", "\n", "\"will copy the source token\"", ")", "\n", "\n", "group", ".", "add", "(", "'--ignore_when_blocking'", ",", "'-ignore_when_blocking'", ",", "\n", "nargs", "=", "'+'", ",", "type", "=", "str", ",", "default", "=", "[", "]", ",", "\n", "help", "=", "\"Ignore these strings when blocking repeats. \"", "\n", "\"You want to block sentence delimiters.\"", ")", "\n", "group", ".", "add", "(", "'--block_ngram_repeat'", ",", "'-block_ngram_repeat'", ",", "\n", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Block repetition of ngrams during decoding.'", ")", "\n", "group", ".", "add", "(", "'--dump_beam'", ",", "'-dump_beam'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'File to dump beam information to.'", ")", "\n", "group", ".", "add", "(", "'--stepwise_penalty'", ",", "'-stepwise_penalty'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Apply penalty at every decoding step. \"", "\n", "\"Helpful for summary penalty.\"", ")", "\n", "group", ".", "add", "(", "'--random_sampling_temp'", ",", "'-random_sampling_temp'", ",", "\n", "default", "=", "1.", ",", "type", "=", "float", ",", "\n", "help", "=", "\"If doing random sampling, divide the logits by \"", "\n", "\"this before computing softmax during decoding.\"", ")", "\n", "group", ".", "add", "(", "'--random_sampling_topk'", ",", "'-random_sampling_topk'", ",", "\n", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Set this to -1 to do random sampling from full \"", "\n", "\"distribution. Set this to value k>1 to do random \"", "\n", "\"sampling restricted to the k most likely next tokens. \"", "\n", "\"Set this to 1 to use argmax or for doing beam \"", "\n", "\"search.\"", ")", "\n", "group", ".", "add", "(", "'--beam_size'", ",", "'-beam_size'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "'Beam size'", ")", "\n", "group", ".", "add", "(", "'--max_length'", ",", "'-max_length'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "'Maximum prediction length.'", ")", "\n", "group", ".", "add", "(", "'--min_length'", ",", "'-min_length'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Minimum prediction length'", ")", "\n", "group", ".", "add", "(", "'--n_best'", ",", "'-n_best'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "\"If verbose is set, will output the n_best \"", "\n", "\"decoded sentences\"", ")", "\n", "group", ".", "add", "(", "'--gpu'", ",", "'-gpu'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Device to run on\"", ")", "\n", "group", ".", "add", "(", "'--gpu_ranks'", ",", "'-gpu_ranks'", ",", "default", "=", "[", "]", ",", "nargs", "=", "'*'", ",", "type", "=", "int", ",", "\n", "help", "=", "\"list of ranks of each process.\"", ")", "\n", "group", ".", "add", "(", "'--world_size'", ",", "'-world_size'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"total number of distributed processes.\"", ")", "\n", "group", ".", "add", "(", "'--gpu_backend'", ",", "'-gpu_backend'", ",", "\n", "default", "=", "\"nccl\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Type of torch distributed backend\"", ")", "\n", "group", ".", "add", "(", "'--gpu_verbose_level'", ",", "'-gpu_verbose_level'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Gives more info on each process per GPU.\"", ")", "\n", "group", ".", "add", "(", "'--master_ip'", ",", "'-master_ip'", ",", "default", "=", "\"localhost\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"IP of master for torch.distributed training.\"", ")", "\n", "group", ".", "add", "(", "'--master_port'", ",", "'-master_port'", ",", "default", "=", "10000", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Port of master for torch.distributed training.\"", ")", "\n", "\n", "group", ".", "add", "(", "'--seed'", ",", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Random seed used for the experiments \"", "\n", "\"reproducibility.\"", ")", "\n", "\n", "# Init options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Initialization'", ")", "\n", "group", ".", "add", "(", "'--param_init'", ",", "'-param_init'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "\n", "help", "=", "\"Parameters are initialized over uniform distribution \"", "\n", "\"with support (-param_init, param_init). \"", "\n", "\"Use 0 to not use initialization\"", ")", "\n", "group", ".", "add", "(", "'--param_init_glorot'", ",", "'-param_init_glorot'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Init parameters with xavier_uniform. \"", "\n", "\"Required for transfomer.\"", ")", "\n", "\n", "group", ".", "add", "(", "'--train_from'", ",", "'-train_from'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "\"If training from a checkpoint then this is the \"", "\n", "\"path to the pretrained model's state_dict.\"", ")", "\n", "group", ".", "add", "(", "'--reset_optim'", ",", "'-reset_optim'", ",", "default", "=", "'none'", ",", "\n", "choices", "=", "[", "'none'", ",", "'all'", ",", "'states'", ",", "'keep_states'", "]", ",", "\n", "help", "=", "\"Optimization resetter when train_from.\"", ")", "\n", "\n", "# Pretrained word vectors", "\n", "group", ".", "add", "(", "'--pre_word_vecs_enc'", ",", "'-pre_word_vecs_enc'", ",", "\n", "help", "=", "\"If a valid path is specified, then this will load \"", "\n", "\"pretrained word embeddings on the encoder side. \"", "\n", "\"See README for specific formatting instructions.\"", ")", "\n", "group", ".", "add", "(", "'--pre_word_vecs_dec'", ",", "'-pre_word_vecs_dec'", ",", "\n", "help", "=", "\"If a valid path is specified, then this will load \"", "\n", "\"pretrained word embeddings on the decoder side. \"", "\n", "\"See README for specific formatting instructions.\"", ")", "\n", "# Fixed word vectors", "\n", "group", ".", "add", "(", "'--fix_word_vecs_enc'", ",", "'-fix_word_vecs_enc'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Fix word embeddings on the encoder side.\"", ")", "\n", "group", ".", "add", "(", "'--fix_word_vecs_dec'", ",", "'-fix_word_vecs_dec'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Fix word embeddings on the decoder side.\"", ")", "\n", "\n", "# Optimization options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Optimization- Type'", ")", "\n", "group", ".", "add", "(", "'--batch_size'", ",", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "'Maximum batch size for training'", ")", "\n", "group", ".", "add", "(", "'--batch_type'", ",", "'-batch_type'", ",", "default", "=", "'sents'", ",", "\n", "choices", "=", "[", "\"sents\"", ",", "\"tokens\"", "]", ",", "\n", "help", "=", "\"Batch grouping for batch_size. Standard \"", "\n", "\"is sents. Tokens will do dynamic batching\"", ")", "\n", "group", ".", "add", "(", "'--normalization'", ",", "'-normalization'", ",", "default", "=", "'sents'", ",", "\n", "choices", "=", "[", "\"sents\"", ",", "\"tokens\"", "]", ",", "\n", "help", "=", "'Normalization method of the gradient.'", ")", "\n", "group", ".", "add", "(", "'--accum_count'", ",", "'-accum_count'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Accumulate gradient this many times. \"", "\n", "\"Approximately equivalent to updating \"", "\n", "\"batch_size * accum_count batches at once. \"", "\n", "\"Recommended for Transformer.\"", ")", "\n", "group", ".", "add", "(", "'--valid_steps'", ",", "'-valid_steps'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "'Perfom validation every X steps'", ")", "\n", "group", ".", "add", "(", "'--valid_batch_size'", ",", "'-valid_batch_size'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "'Maximum batch size for validation'", ")", "\n", "group", ".", "add", "(", "'--max_generator_batches'", ",", "'-max_generator_batches'", ",", "\n", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Maximum batches of words in a sequence to run \"", "\n", "\"the generator on in parallel. Higher is faster, but \"", "\n", "\"uses more memory. Set to 0 to disable.\"", ")", "\n", "group", ".", "add", "(", "'--train_steps'", ",", "'-train_steps'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "'Number of training steps'", ")", "\n", "group", ".", "add", "(", "'--single_pass'", ",", "'-single_pass'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Make a single pass over the training dataset.\"", ")", "\n", "group", ".", "add", "(", "'--epochs'", ",", "'-epochs'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Deprecated epochs see train_steps'", ")", "\n", "group", ".", "add", "(", "'--optim'", ",", "'-optim'", ",", "default", "=", "'sgd'", ",", "\n", "choices", "=", "[", "'sgd'", ",", "'adagrad'", ",", "'adadelta'", ",", "'adam'", ",", "\n", "'sparseadam'", ",", "'adafactor'", ",", "'fusedadam'", "]", ",", "\n", "help", "=", "\"Optimization method.\"", ")", "\n", "group", ".", "add", "(", "'--adagrad_accumulator_init'", ",", "'-adagrad_accumulator_init'", ",", "\n", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Initializes the accumulator values in adagrad. \"", "\n", "\"Mirrors the initial_accumulator_value option \"", "\n", "\"in the tensorflow adagrad (use 0.1 for their default).\"", ")", "\n", "group", ".", "add", "(", "'--max_grad_norm'", ",", "'-max_grad_norm'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "\n", "help", "=", "\"If the norm of the gradient vector exceeds this, \"", "\n", "\"renormalize it to have the norm equal to \"", "\n", "\"max_grad_norm\"", ")", "\n", "group", ".", "add", "(", "'--dropout'", ",", "'-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.3", ",", "\n", "help", "=", "\"Dropout probability; applied in LSTM stacks.\"", ")", "\n", "group", ".", "add", "(", "'--truncated_decoder'", ",", "'-truncated_decoder'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Truncated bptt.\"\"\"", ")", "\n", "group", ".", "add", "(", "'--adam_beta1'", ",", "'-adam_beta1'", ",", "type", "=", "float", ",", "default", "=", "0.9", ",", "\n", "help", "=", "\"The beta1 parameter used by Adam. \"", "\n", "\"Almost without exception a value of 0.9 is used in \"", "\n", "\"the literature, seemingly giving good results, \"", "\n", "\"so we would discourage changing this value from \"", "\n", "\"the default without due consideration.\"", ")", "\n", "group", ".", "add", "(", "'--adam_beta2'", ",", "'-adam_beta2'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "\n", "help", "=", "'The beta2 parameter used by Adam. '", "\n", "'Typically a value of 0.999 is recommended, as this is '", "\n", "'the value suggested by the original paper describing '", "\n", "'Adam, and is also the value adopted in other frameworks '", "\n", "'such as Tensorflow and Kerras, i.e. see: '", "\n", "'https://www.tensorflow.org/api_docs/python/tf/train/Adam'", "\n", "'Optimizer or '", "\n", "'https://keras.io/optimizers/ . '", "\n", "'Whereas recently the paper \"Attention is All You Need\" '", "\n", "'suggested a value of 0.98 for beta2, this parameter may '", "\n", "'not work well for normal models / default '", "\n", "'baselines.'", ")", "\n", "group", ".", "add", "(", "'--label_smoothing'", ",", "'-label_smoothing'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "\"Label smoothing value epsilon. \"", "\n", "\"Probabilities of all non-true labels \"", "\n", "\"will be smoothed by epsilon / (vocab_size - 1). \"", "\n", "\"Set to zero to turn off label smoothing. \"", "\n", "\"For more detailed information, see: \"", "\n", "\"https://arxiv.org/abs/1512.00567\"", ")", "\n", "group", ".", "add", "(", "'--average_decay'", ",", "'-average_decay'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Moving average decay. \"", "\n", "\"Set to other than 0 (e.g. 1e-4) to activate. \"", "\n", "\"Similar to Marian NMT implementation: \"", "\n", "\"http://www.aclweb.org/anthology/P18-4020 \"", "\n", "\"For more detail on Exponential Moving Average: \"", "\n", "\"https://en.wikipedia.org/wiki/Moving_average\"", ")", "\n", "group", ".", "add", "(", "'--average_every'", ",", "'-average_every'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Step for moving average. \"", "\n", "\"Default is every update, \"", "\n", "\"if -average_decay is set.\"", ")", "\n", "\n", "# learning rate", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Optimization- Rate'", ")", "\n", "group", ".", "add", "(", "'--learning_rate'", ",", "'-learning_rate'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "\"Starting learning rate. \"", "\n", "\"Recommended settings: sgd = 1, adagrad = 0.1, \"", "\n", "\"adadelta = 1, adam = 0.001\"", ")", "\n", "group", ".", "add", "(", "'--learning_rate_decay'", ",", "'-learning_rate_decay'", ",", "\n", "type", "=", "float", ",", "default", "=", "0.95", ",", "\n", "help", "=", "\"If update_learning_rate, decay learning rate by \"", "\n", "\"this much if steps have gone past \"", "\n", "\"start_decay_steps\"", ")", "\n", "group", ".", "add", "(", "'--start_decay_steps'", ",", "'-start_decay_steps'", ",", "\n", "type", "=", "int", ",", "default", "=", "15000", ",", "\n", "help", "=", "\"Start decaying every decay_steps after \"", "\n", "\"start_decay_steps\"", ")", "\n", "group", ".", "add", "(", "'--decay_steps'", ",", "'-decay_steps'", ",", "type", "=", "int", ",", "default", "=", "5000", ",", "\n", "help", "=", "\"Decay every decay_steps\"", ")", "\n", "\n", "group", ".", "add", "(", "'--decay_method'", ",", "'-decay_method'", ",", "type", "=", "str", ",", "default", "=", "\"none\"", ",", "\n", "choices", "=", "[", "'noam'", ",", "'rsqrt'", ",", "'none'", "]", ",", "\n", "help", "=", "\"Use a custom decay rate.\"", ")", "\n", "group", ".", "add", "(", "'--warmup_steps'", ",", "'-warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "4000", ",", "\n", "help", "=", "\"Number of warmup steps for custom decay.\"", ")", "\n", "group", ".", "add", "(", "'--learning_rate_rl'", ",", "'-learning_rate_rl'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "\"Starting learning rate for RL. \"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add", "(", "'--report_every'", ",", "'-report_every'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Print stats at this interval.\"", ")", "\n", "group", ".", "add", "(", "'--log_file'", ",", "'-log_file'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Output logs to a file under this path.\"", ")", "\n", "group", ".", "add", "(", "'--log_file_level'", ",", "'-log_file_level'", ",", "type", "=", "str", ",", "\n", "action", "=", "StoreLoggingLevelAction", ",", "\n", "choices", "=", "StoreLoggingLevelAction", ".", "CHOICES", ",", "\n", "default", "=", "\"0\"", ")", "\n", "group", ".", "add", "(", "'--exp_host'", ",", "'-exp_host'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Send logs to this crayon server.\"", ")", "\n", "group", ".", "add", "(", "'--exp'", ",", "'-exp'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Name of the experiment for logging.\"", ")", "\n", "# Use TensorboardX for visualization during training", "\n", "group", ".", "add", "(", "'--tensorboard'", ",", "'-tensorboard'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Use tensorboardX for visualization during training. \"", "\n", "\"Must have the library tensorboardX.\"", ")", "\n", "group", ".", "add", "(", "\"--tensorboard_log_dir\"", ",", "\"-tensorboard_log_dir\"", ",", "\n", "type", "=", "str", ",", "default", "=", "\"runs/onmt\"", ",", "\n", "help", "=", "\"Log directory for Tensorboard. \"", "\n", "\"This is also the name of the run.\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "# Options most relevant to speech", "\n", "group", ".", "add", "(", "'--sample_rate'", ",", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add", "(", "'--window_size'", ",", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "\"Window size for spectrogram in seconds.\"", ")", "\n", "\n", "# Option most relevant to image input", "\n", "group", ".", "add", "(", "'--image_channel_size'", ",", "'-image_channel_size'", ",", "\n", "type", "=", "int", ",", "default", "=", "3", ",", "choices", "=", "[", "3", ",", "1", "]", ",", "\n", "help", "=", "\"Using grayscale image can training \"", "\n", "\"model faster and smaller\"", ")", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.opts.translate_opts": [[610, 766], ["parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add", "parser.add_argument_group.add"], "function", ["None"], ["", "def", "translate_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\" Translation / inference options \"\"\"", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model'", ")", "\n", "group", ".", "add", "(", "'--model'", ",", "'-model'", ",", "dest", "=", "'models'", ",", "metavar", "=", "'MODEL'", ",", "\n", "nargs", "=", "'+'", ",", "type", "=", "str", ",", "default", "=", "[", "]", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to model .pt file(s). \"", "\n", "\"Multiple models can be specified, \"", "\n", "\"for ensemble decoding.\"", ")", "\n", "group", ".", "add", "(", "'--fp32'", ",", "'-fp32'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Force the model to be in FP32 \"", "\n", "\"because FP16 is very slow on GTX1080(ti).\"", ")", "\n", "group", ".", "add", "(", "'--avg_raw_probs'", ",", "'-avg_raw_probs'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"If this is set, during ensembling scores from \"", "\n", "\"different models will be combined by averaging their \"", "\n", "\"raw probabilities and then taking the log. Otherwise, \"", "\n", "\"the log probabilities will be averaged directly. \"", "\n", "\"Necessary for models whose output layers can assign \"", "\n", "\"zero probability.\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Data'", ")", "\n", "group", ".", "add", "(", "'--data_type'", ",", "'-data_type'", ",", "default", "=", "\"text\"", ",", "\n", "help", "=", "\"Type of the source input. Options: [text|img].\"", ")", "\n", "\n", "group", ".", "add", "(", "'--src'", ",", "'-src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Source sequence to decode (one line per \"", "\n", "\"sequence)\"", ")", "\n", "group", ".", "add", "(", "'--history'", ",", "'-history'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Source sequence to decode (one line per \"", "\n", "\"sequence)\"", ")", "\n", "group", ".", "add", "(", "'--ans'", ",", "'-ans'", ",", "required", "=", "False", ",", "\n", "help", "=", "\"\"", ")", "\n", "group", ".", "add", "(", "'--src_dir'", ",", "'-src_dir'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'Source directory for image or audio files'", ")", "\n", "group", ".", "add", "(", "'--tgt'", ",", "'-tgt'", ",", "\n", "help", "=", "'True target sequence (optional)'", ")", "\n", "group", ".", "add", "(", "'--shard_size'", ",", "'-shard_size'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Divide src and tgt (if applicable) into \"", "\n", "\"smaller multiple src and tgt files, then \"", "\n", "\"build shards, each shard will have \"", "\n", "\"opt.shard_size samples except last shard. \"", "\n", "\"shard_size=0 means no segmentation \"", "\n", "\"shard_size>0 means segment dataset into multiple shards, \"", "\n", "\"each shard has shard_size samples\"", ")", "\n", "group", ".", "add", "(", "'--output'", ",", "'-output'", ",", "default", "=", "'pred.txt'", ",", "\n", "help", "=", "\"Path to output the predictions (each line will \"", "\n", "\"be the decoded sequence\"", ")", "\n", "group", ".", "add", "(", "'--report_bleu'", ",", "'-report_bleu'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Report bleu score after translation, \"", "\n", "\"call tools/multi-bleu.perl on command line\"", ")", "\n", "group", ".", "add", "(", "'--report_rouge'", ",", "'-report_rouge'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Report rouge 1/2/3/L/SU4 score after translation \"", "\n", "\"call tools/test_rouge.py on command line\"", ")", "\n", "group", ".", "add", "(", "'--report_time'", ",", "'-report_time'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Report some translation time metrics\"", ")", "\n", "\n", "# Options most relevant to summarization.", "\n", "group", ".", "add", "(", "'--dynamic_dict'", ",", "'-dynamic_dict'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Create dynamic dictionaries\"", ")", "\n", "group", ".", "add", "(", "'--share_vocab'", ",", "'-share_vocab'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Share source and target vocabulary\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Random Sampling'", ")", "\n", "group", ".", "add", "(", "'--random_sampling_topk'", ",", "'-random_sampling_topk'", ",", "\n", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Set this to -1 to do random sampling from full \"", "\n", "\"distribution. Set this to value k>1 to do random \"", "\n", "\"sampling restricted to the k most likely next tokens. \"", "\n", "\"Set this to 1 to use argmax or for doing beam \"", "\n", "\"search.\"", ")", "\n", "group", ".", "add", "(", "'--random_sampling_temp'", ",", "'-random_sampling_temp'", ",", "\n", "default", "=", "1.", ",", "type", "=", "float", ",", "\n", "help", "=", "\"If doing random sampling, divide the logits by \"", "\n", "\"this before computing softmax during decoding.\"", ")", "\n", "group", ".", "add", "(", "'--seed'", ",", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "829", ",", "\n", "help", "=", "\"Random seed\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Beam'", ")", "\n", "group", ".", "add", "(", "'--beam_size'", ",", "'-beam_size'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "'Beam size'", ")", "\n", "group", ".", "add", "(", "'--min_length'", ",", "'-min_length'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Minimum prediction length'", ")", "\n", "group", ".", "add", "(", "'--max_length'", ",", "'-max_length'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "'Maximum prediction length.'", ")", "\n", "group", ".", "add", "(", "'--max_sent_length'", ",", "'-max_sent_length'", ",", "action", "=", "DeprecateAction", ",", "\n", "help", "=", "\"Deprecated, use `-max_length` instead\"", ")", "\n", "\n", "# Alpha and Beta values for Google Length + Coverage penalty", "\n", "# Described here: https://arxiv.org/pdf/1609.08144.pdf, Section 7", "\n", "group", ".", "add", "(", "'--stepwise_penalty'", ",", "'-stepwise_penalty'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Apply penalty at every decoding step. \"", "\n", "\"Helpful for summary penalty.\"", ")", "\n", "group", ".", "add", "(", "'--length_penalty'", ",", "'-length_penalty'", ",", "default", "=", "'none'", ",", "\n", "choices", "=", "[", "'none'", ",", "'wu'", ",", "'avg'", "]", ",", "\n", "help", "=", "\"Length Penalty to use.\"", ")", "\n", "group", ".", "add", "(", "'--coverage_penalty'", ",", "'-coverage_penalty'", ",", "default", "=", "'none'", ",", "\n", "choices", "=", "[", "'none'", ",", "'wu'", ",", "'summary'", "]", ",", "\n", "help", "=", "\"Coverage Penalty to use.\"", ")", "\n", "group", ".", "add", "(", "'--alpha'", ",", "'-alpha'", ",", "type", "=", "float", ",", "default", "=", "0.", ",", "\n", "help", "=", "\"Google NMT length penalty parameter \"", "\n", "\"(higher = longer generation)\"", ")", "\n", "group", ".", "add", "(", "'--beta'", ",", "'-beta'", ",", "type", "=", "float", ",", "default", "=", "-", "0.", ",", "\n", "help", "=", "\"Coverage penalty parameter\"", ")", "\n", "group", ".", "add", "(", "'--block_ngram_repeat'", ",", "'-block_ngram_repeat'", ",", "\n", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Block repetition of ngrams during decoding.'", ")", "\n", "group", ".", "add", "(", "'--ignore_when_blocking'", ",", "'-ignore_when_blocking'", ",", "\n", "nargs", "=", "'+'", ",", "type", "=", "str", ",", "default", "=", "[", "]", ",", "\n", "help", "=", "\"Ignore these strings when blocking repeats. \"", "\n", "\"You want to block sentence delimiters.\"", ")", "\n", "group", ".", "add", "(", "'--replace_unk'", ",", "'-replace_unk'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Replace the generated UNK tokens with the \"", "\n", "\"source token that had highest attention weight. If \"", "\n", "\"phrase_table is provided, it will lookup the \"", "\n", "\"identified source token and give the corresponding \"", "\n", "\"target token. If it is not provided(or the identified \"", "\n", "\"source token does not exist in the table) then it \"", "\n", "\"will copy the source token\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add", "(", "'--verbose'", ",", "'-verbose'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Print scores and predictions for each sentence'", ")", "\n", "group", ".", "add", "(", "'--log_file'", ",", "'-log_file'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Output logs to a file under this path.\"", ")", "\n", "group", ".", "add", "(", "'--log_file_level'", ",", "'-log_file_level'", ",", "type", "=", "str", ",", "\n", "action", "=", "StoreLoggingLevelAction", ",", "\n", "choices", "=", "StoreLoggingLevelAction", ".", "CHOICES", ",", "\n", "default", "=", "\"0\"", ")", "\n", "group", ".", "add", "(", "'--attn_debug'", ",", "'-attn_debug'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Print best attn for each word'", ")", "\n", "group", ".", "add", "(", "'--dump_beam'", ",", "'-dump_beam'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'File to dump beam information to.'", ")", "\n", "group", ".", "add", "(", "'--n_best'", ",", "'-n_best'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"If verbose is set, will output the n_best \"", "\n", "\"decoded sentences\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Efficiency'", ")", "\n", "group", ".", "add", "(", "'--batch_size'", ",", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "'Batch size'", ")", "\n", "group", ".", "add", "(", "'--gpu'", ",", "'-gpu'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Device to run on\"", ")", "\n", "\n", "# Options most relevant to speech.", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "group", ".", "add", "(", "'--sample_rate'", ",", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add", "(", "'--window_size'", ",", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "'Window size for spectrogram in seconds'", ")", "\n", "group", ".", "add", "(", "'--window_stride'", ",", "'-window_stride'", ",", "type", "=", "float", ",", "default", "=", ".01", ",", "\n", "help", "=", "'Window stride for spectrogram in seconds'", ")", "\n", "group", ".", "add", "(", "'--window'", ",", "'-window'", ",", "default", "=", "'hamming'", ",", "\n", "help", "=", "'Window type for spectrogram generation'", ")", "\n", "\n", "# Option most relevant to image input", "\n", "group", ".", "add", "(", "'--image_channel_size'", ",", "'-image_channel_size'", ",", "\n", "type", "=", "int", ",", "default", "=", "3", ",", "choices", "=", "[", "3", ",", "1", "]", ",", "\n", "help", "=", "\"Using grayscale image can training \"", "\n", "\"model faster and smaller\"", ")", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer.__init__": [[95, 131], ["random.random.random", "trainer.Trainer.model.train"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer.train"], ["def", "__init__", "(", "self", ",", "model", ",", "train_loss", ",", "valid_loss", ",", "optim", ",", "\n", "trunc_size", "=", "0", ",", "shard_size", "=", "32", ",", "\n", "norm_method", "=", "\"sents\"", ",", "grad_accum_count", "=", "1", ",", "n_gpu", "=", "1", ",", "gpu_rank", "=", "1", ",", "\n", "gpu_verbose_level", "=", "0", ",", "report_manager", "=", "None", ",", "model_saver", "=", "None", ",", "\n", "average_decay", "=", "0", ",", "average_every", "=", "1", ",", "model_dtype", "=", "'fp32'", ",", "enable_rl_after", "=", "-", "1", ",", "rl_save_step", "=", "1000", ",", "tgt_field", "=", "None", ")", ":", "\n", "# Basic attributes.", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "train_loss", "=", "train_loss", "\n", "self", ".", "valid_loss", "=", "valid_loss", "\n", "self", ".", "optim", "=", "optim", "\n", "self", ".", "trunc_size", "=", "trunc_size", "\n", "self", ".", "shard_size", "=", "shard_size", "\n", "self", ".", "norm_method", "=", "norm_method", "\n", "self", ".", "grad_accum_count", "=", "grad_accum_count", "\n", "self", ".", "n_gpu", "=", "n_gpu", "\n", "self", ".", "gpu_rank", "=", "gpu_rank", "\n", "self", ".", "gpu_verbose_level", "=", "gpu_verbose_level", "\n", "self", ".", "report_manager", "=", "report_manager", "\n", "self", ".", "model_saver", "=", "model_saver", "\n", "self", ".", "average_decay", "=", "average_decay", "\n", "self", ".", "moving_average", "=", "None", "\n", "self", ".", "average_every", "=", "average_every", "\n", "self", ".", "model_dtype", "=", "model_dtype", "\n", "self", ".", "enable_rl_after", "=", "enable_rl_after", "\n", "self", ".", "rl_save_step", "=", "rl_save_step", "\n", "self", ".", "tgt_field", "=", "tgt_field", "\n", "self", ".", "trigger", "=", "random", "(", ")", "\n", "\n", "assert", "grad_accum_count", ">", "0", "\n", "if", "grad_accum_count", ">", "1", ":", "\n", "            ", "assert", "self", ".", "trunc_size", "==", "0", ",", "\"\"\"To enable accumulated gradients,\n                   you must disable target sequence truncating.\"\"\"", "\n", "\n", "# Set model in training mode.", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer._accum_batches": [[132, 149], ["batches.append", "batch.tgt[].ne().sum", "batch.tgt[].ne().sum.item", "len", "batch.tgt[].ne"], "methods", ["None"], ["", "def", "_accum_batches", "(", "self", ",", "iterator", ")", ":", "\n", "        ", "batches", "=", "[", "]", "\n", "normalization", "=", "0", "\n", "for", "batch", "in", "iterator", ":", "\n", "            ", "batches", ".", "append", "(", "batch", ")", "\n", "if", "self", ".", "norm_method", "==", "\"tokens\"", ":", "\n", "                ", "num_tokens", "=", "batch", ".", "tgt", "[", "1", ":", ",", ":", ",", "0", "]", ".", "ne", "(", "\n", "self", ".", "train_loss", ".", "padding_idx", ")", ".", "sum", "(", ")", "\n", "normalization", "+=", "num_tokens", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "                ", "normalization", "+=", "batch", ".", "batch_size", "\n", "", "if", "len", "(", "batches", ")", "==", "self", ".", "grad_accum_count", ":", "\n", "                ", "yield", "batches", ",", "normalization", "\n", "batches", "=", "[", "]", "\n", "normalization", "=", "0", "\n", "", "", "if", "batches", ":", "\n", "            ", "yield", "batches", ",", "normalization", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer._update_average": [[150, 163], ["max", "zip", "params.detach().float", "enumerate", "trainer.Trainer.model.parameters", "trainer.Trainer.model.parameters", "params.detach", "cpt.detach().float", "cpt.detach"], "methods", ["None"], ["", "", "def", "_update_average", "(", "self", ",", "step", ")", ":", "\n", "        ", "if", "self", ".", "moving_average", "is", "None", ":", "\n", "            ", "copy_params", "=", "[", "params", ".", "detach", "(", ")", ".", "float", "(", ")", "\n", "for", "params", "in", "self", ".", "model", ".", "parameters", "(", ")", "]", "\n", "self", ".", "moving_average", "=", "copy_params", "\n", "", "else", ":", "\n", "            ", "average_decay", "=", "max", "(", "self", ".", "average_decay", ",", "\n", "1", "-", "(", "step", "+", "1", ")", "/", "(", "step", "+", "10", ")", ")", "\n", "for", "(", "i", ",", "avg", ")", ",", "cpt", "in", "zip", "(", "enumerate", "(", "self", ".", "moving_average", ")", ",", "\n", "self", ".", "model", ".", "parameters", "(", ")", ")", ":", "\n", "                ", "self", ".", "moving_average", "[", "i", "]", "=", "(", "1", "-", "average_decay", ")", "*", "avg", "+", "cpt", ".", "detach", "(", ")", ".", "float", "(", ")", "*", "average_decay", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer.train": [[164, 261], ["onmt.utils.Statistics", "onmt.utils.Statistics", "trainer.Trainer._start_report_manager", "tqdm.tqdm.tqdm", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "itertools.islice", "enumerate", "trainer.Trainer._gradient_accumulation", "trainer.Trainer._maybe_report_training", "trainer.Trainer.model_saver.save", "trainer.Trainer._accum_batches", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "sum", "trainer.Trainer._update_average", "trainer.Trainer.optim.learning_rate", "trainer.Trainer.validate", "trainer.Trainer._maybe_gather_stats", "trainer.Trainer._report_step", "onmt.utils.distributed.all_gather_list", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "trainer.Trainer.optim.learning_rate", "trainer.Trainer.model_saver.save", "trainer.Trainer.model_saver.save", "len"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer._start_report_manager", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer._gradient_accumulation", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer._maybe_report_training", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer._accum_batches", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer._update_average", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.learning_rate", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer.validate", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer._maybe_gather_stats", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.report_manager.ReportMgr._report_step", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.learning_rate", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.ModelSaverBase.save"], ["", "", "", "def", "train", "(", "self", ",", "\n", "train_iter", ",", "\n", "train_steps", ",", "\n", "save_checkpoint_steps", "=", "5000", ",", "\n", "valid_iter", "=", "None", ",", "\n", "valid_steps", "=", "10000", ")", ":", "\n", "        ", "\"\"\"\n        The main training loop by iterating over `train_iter` and possibly\n        running validation on `valid_iter`.\n\n        Args:\n            train_iter: A generator that returns the next training batch.\n            train_steps: Run training for this many iterations.\n            save_checkpoint_steps: Save a checkpoint every this many\n              iterations.\n            valid_iter: A generator that returns the next validation batch.\n            valid_steps: Run evaluation every this many iterations.\n\n        Returns:\n            The gathered statistics.\n        \"\"\"", "\n", "if", "valid_iter", "is", "None", ":", "\n", "            ", "logger", ".", "info", "(", "'Start training loop without validation...'", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "'Start training loop and validate every %d steps...'", ",", "\n", "valid_steps", ")", "\n", "\n", "", "total_stats", "=", "onmt", ".", "utils", ".", "Statistics", "(", ")", "\n", "report_stats", "=", "onmt", ".", "utils", ".", "Statistics", "(", ")", "\n", "self", ".", "_start_report_manager", "(", "start_time", "=", "total_stats", ".", "start_time", ")", "\n", "\n", "if", "self", ".", "n_gpu", ">", "1", ":", "\n", "            ", "train_iter", "=", "itertools", ".", "islice", "(", "\n", "train_iter", ",", "self", ".", "gpu_rank", ",", "None", ",", "self", ".", "n_gpu", ")", "\n", "\n", "", "local_step", "=", "self", ".", "optim", ".", "training_step", "\n", "for", "i", ",", "(", "batches", ",", "normalization", ")", "in", "tqdm", "(", "enumerate", "(", "self", ".", "_accum_batches", "(", "train_iter", ")", ")", ")", ":", "\n", "            ", "local_step", "+=", "1", "\n", "\n", "if", "self", ".", "gpu_verbose_level", ">", "1", ":", "\n", "                ", "logger", ".", "info", "(", "\"GpuRank %d: index: %d\"", ",", "self", ".", "gpu_rank", ",", "i", ")", "\n", "", "if", "self", ".", "gpu_verbose_level", ">", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"GpuRank %d: reduce_counter: %d \\\n                            n_minibatch %d\"", "\n", "%", "(", "self", ".", "gpu_rank", ",", "i", "+", "1", ",", "len", "(", "batches", ")", ")", ")", "\n", "\n", "", "if", "self", ".", "n_gpu", ">", "1", ":", "\n", "                ", "normalization", "=", "sum", "(", "onmt", ".", "utils", ".", "distributed", "\n", ".", "all_gather_list", "\n", "(", "normalization", ")", ")", "\n", "\n", "", "self", ".", "_gradient_accumulation", "(", "\n", "batches", ",", "normalization", ",", "total_stats", ",", "\n", "report_stats", ",", "local_step", ")", "\n", "\n", "if", "self", ".", "average_decay", ">", "0", "and", "i", "%", "self", ".", "average_every", "==", "0", ":", "\n", "                ", "self", ".", "_update_average", "(", "local_step", ")", "\n", "\n", "", "report_stats", "=", "self", ".", "_maybe_report_training", "(", "\n", "local_step", ",", "train_steps", ",", "\n", "self", ".", "optim", ".", "learning_rate", "(", ")", ",", "\n", "report_stats", ")", "\n", "\n", "if", "valid_iter", "is", "not", "None", "and", "local_step", "%", "valid_steps", "==", "0", ":", "\n", "                ", "if", "self", ".", "gpu_verbose_level", ">", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "'GpuRank %d: validate step %d'", "\n", "%", "(", "self", ".", "gpu_rank", ",", "local_step", ")", ")", "\n", "", "valid_stats", "=", "self", ".", "validate", "(", "\n", "valid_iter", ",", "moving_average", "=", "self", ".", "moving_average", ")", "\n", "if", "self", ".", "gpu_verbose_level", ">", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "'GpuRank %d: gather valid stat \\\n                                step %d'", "%", "(", "self", ".", "gpu_rank", ",", "local_step", ")", ")", "\n", "", "valid_stats", "=", "self", ".", "_maybe_gather_stats", "(", "valid_stats", ")", "\n", "if", "self", ".", "gpu_verbose_level", ">", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "'GpuRank %d: report stat step %d'", "\n", "%", "(", "self", ".", "gpu_rank", ",", "local_step", ")", ")", "\n", "", "self", ".", "_report_step", "(", "self", ".", "optim", ".", "learning_rate", "(", ")", ",", "\n", "local_step", ",", "valid_stats", "=", "valid_stats", ")", "\n", "\n", "", "if", "self", ".", "enable_rl_after", "<", "0", "or", "local_step", "<=", "self", ".", "enable_rl_after", ":", "\n", "                ", "if", "(", "self", ".", "model_saver", "is", "not", "None", "\n", "and", "(", "save_checkpoint_steps", "!=", "0", "\n", "and", "local_step", "%", "save_checkpoint_steps", "==", "0", ")", ")", ":", "\n", "                    ", "self", ".", "model_saver", ".", "save", "(", "local_step", ",", "moving_average", "=", "self", ".", "moving_average", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "(", "self", ".", "model_saver", "is", "not", "None", "\n", "and", "(", "self", ".", "rl_save_step", "!=", "0", "\n", "and", "local_step", "%", "self", ".", "rl_save_step", "==", "0", ")", ")", ":", "\n", "                    ", "self", ".", "model_saver", ".", "save", "(", "local_step", ",", "moving_average", "=", "self", ".", "moving_average", ")", "\n", "\n", "", "", "if", "train_steps", ">", "0", "and", "local_step", ">=", "train_steps", ":", "\n", "                ", "break", "\n", "\n", "\n", "", "", "if", "self", ".", "model_saver", "is", "not", "None", ":", "\n", "            ", "self", ".", "model_saver", ".", "save", "(", "local_step", ",", "moving_average", "=", "self", ".", "moving_average", ")", "\n", "", "return", "total_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer.validate": [[262, 305], ["copy.deepcopy.eval", "copy.deepcopy", "zip", "torch.no_grad", "onmt.utils.Statistics", "copy.deepcopy.train", "copy.deepcopy.parameters", "copy.deepcopy.", "trainer.Trainer.valid_loss", "onmt.utils.Statistics.update", "avg.data.half", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer.train", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.update"], ["", "def", "validate", "(", "self", ",", "valid_iter", ",", "moving_average", "=", "None", ")", ":", "\n", "        ", "\"\"\" Validate model.\n            valid_iter: validate data iterator\n        Returns:\n            :obj:`nmt.Statistics`: validation loss statistics\n        \"\"\"", "\n", "if", "moving_average", ":", "\n", "            ", "valid_model", "=", "deepcopy", "(", "self", ".", "model", ")", "\n", "for", "avg", ",", "param", "in", "zip", "(", "self", ".", "moving_average", ",", "\n", "valid_model", ".", "parameters", "(", ")", ")", ":", "\n", "                ", "param", ".", "data", "=", "avg", ".", "data", ".", "half", "(", ")", "if", "self", ".", "model_dtype", "==", "\"fp16\"", "else", "avg", ".", "data", "\n", "", "", "else", ":", "\n", "            ", "valid_model", "=", "self", ".", "model", "\n", "\n", "# Set model in validating mode.", "\n", "", "valid_model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "stats", "=", "onmt", ".", "utils", ".", "Statistics", "(", ")", "\n", "\n", "for", "batch", "in", "valid_iter", ":", "\n", "                ", "src", ",", "src_lengths", "=", "batch", ".", "src", "if", "isinstance", "(", "batch", ".", "src", ",", "tuple", ")", "else", "(", "batch", ".", "src", ",", "None", ")", "\n", "history", ",", "history_lengths", "=", "batch", ".", "history", "if", "isinstance", "(", "batch", ".", "history", ",", "tuple", ")", "else", "(", "batch", ".", "src", ",", "None", ")", "\n", "tgt", "=", "batch", ".", "tgt", "\n", "\n", "# F-prop through the model.", "\n", "outputs", ",", "attns", ",", "_", "=", "valid_model", "(", "src", ",", "history", ",", "tgt", ",", "src_lengths", ",", "history_lengths", ")", "\n", "\n", "# Compute loss.", "\n", "_", ",", "batch_stats", "=", "self", ".", "valid_loss", "(", "batch", ",", "outputs", ",", "attns", ")", "\n", "\n", "# Update statistics.", "\n", "stats", ".", "update", "(", "batch_stats", ")", "\n", "\n", "", "", "if", "moving_average", ":", "\n", "            ", "del", "valid_model", "\n", "", "else", ":", "\n", "# Set model back to training mode.", "\n", "            ", "valid_model", ".", "train", "(", ")", "\n", "\n", "", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer._look_target_tokens": [[306, 319], ["len", "tokens.append", "tokens.append"], "methods", ["None"], ["", "def", "_look_target_tokens", "(", "self", ",", "tgt", ")", ":", "\n", "        ", "vocab", "=", "self", ".", "tgt_field", ".", "vocab", "\n", "tokens", "=", "[", "]", "\n", "\n", "for", "tok", "in", "tgt", ":", "\n", "            ", "if", "tok", "<", "len", "(", "vocab", ")", ":", "\n", "                ", "tokens", ".", "append", "(", "vocab", ".", "itos", "[", "tok", "]", ")", "\n", "", "else", ":", "\n", "                ", "tokens", ".", "append", "(", "vocab", ".", "itos", "[", "1", "]", ")", "\n", "", "if", "tokens", "[", "-", "1", "]", "==", "self", ".", "tgt_field", ".", "eos_token", ":", "\n", "                ", "tokens", "=", "tokens", "[", ":", "-", "1", "]", "\n", "break", "\n", "", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer._gradient_accumulation": [[321, 470], ["batch.tgt.size", "trainer.Trainer.model", "trainer.Trainer.model.reverse", "trainer.Trainer.train_loss", "total_stats.update", "report_stats.update", "trainer.Trainer.optim.step", "isinstance", "src_lengths.sum().item", "isinstance", "trainer.Trainer.optim.zero_grad", "torch.autograd.set_detect_anomaly", "results[].size", "range", "trainer.Trainer.optim.zero_grad", "trainer.Trainer.optim.backward", "trainer.Trainer.optim.step", "onmt.utils.distributed.all_reduce_and_rescale_tensors", "this_outputs.max", "results[].keys", "old_tgt.size", "range", "torch.tensor", "torch.cat.permute", "torch.cat().unsqueeze", "trainer.Trainer.train_loss", "trainer.Trainer.optim.step", "onmt.utils.distributed.all_reduce_and_rescale_tensors", "float", "src_lengths.sum", "this_outputs.size", "batch.tgt.size", "this_outputs.size", "len", "torch.ones", "torch.cat().unsqueeze", "trainer.Trainer.model.drqa_predict", "torch.tensor.append", "torch.ones", "new_tgt_bos.cuda.cuda.cuda", "trainer.Trainer.model.decoder.detach_state", "trainer.Trainer.optim.backward", "onmt.utils.distributed.all_reduce_and_rescale_tensors", "float", "trainer.Trainer.model.parameters", "batch.tgt.size", "len", "torch.tensor", "len", "len", "padding_vec.cuda.cuda.cuda", "pred_n.cuda.cuda.cuda", "torch.cat", "len", "torch.tensor.append", "torch.cat", "float", "trainer.Trainer.model.parameters", "torch.cat", "trainer.Trainer.model.parameters", "old_tgt.size"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.reverse", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.update", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.update", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.AdaFactor.step", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.zero_grad", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.zero_grad", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.AdaFactor.step", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.AdaFactor.step", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model.NMTModel.drqa_predict", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.decoder.RNNDecoderBase.detach_state", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.distributed.all_reduce_and_rescale_tensors"], ["", "def", "_gradient_accumulation", "(", "self", ",", "true_batches", ",", "normalization", ",", "total_stats", ",", "\n", "report_stats", ",", "local_step", ")", ":", "\n", "\n", "        ", "for", "batch", "in", "true_batches", ":", "\n", "            ", "target_size", "=", "batch", ".", "tgt", ".", "size", "(", "0", ")", "\n", "# Truncated BPTT(disabled): reminder not compatible with accum > 1", "\n", "trunc_size", "=", "target_size", "\n", "\n", "src", ",", "src_lengths", "=", "batch", ".", "src", "if", "isinstance", "(", "batch", ".", "src", ",", "tuple", ")", "else", "(", "batch", ".", "src", ",", "None", ")", "\n", "if", "src_lengths", "is", "not", "None", ":", "\n", "                ", "report_stats", ".", "n_src_words", "+=", "src_lengths", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "history", ",", "history_lengths", "=", "batch", ".", "history", "if", "isinstance", "(", "batch", ".", "history", ",", "tuple", ")", "else", "(", "batch", ".", "history", ",", "None", ")", "\n", "\n", "tgt_outer", "=", "batch", ".", "tgt", "\n", "\n", "bptt", "=", "False", "\n", "# --------------------------------", "\n", "# 1. Create truncated target.", "\n", "tgt", "=", "tgt_outer", "\n", "\n", "# 2. F-prop all but generator.", "\n", "if", "self", ".", "grad_accum_count", "==", "1", ":", "\n", "                ", "self", ".", "optim", ".", "zero_grad", "(", ")", "\n", "# outputs: seq, batch_size, linear_hidden", "\n", "", "outputs", ",", "attns", ",", "results", "=", "self", ".", "model", "(", "batch", ",", "src", ",", "history", ",", "tgt", ",", "src_lengths", ",", "history_lengths", ",", "bptt", "=", "bptt", ")", "\n", "preds_n", ",", "preds", ",", "src_raws", ",", "target_ans", "=", "self", ".", "model", ".", "reverse", "(", "results", ")", "\n", "scores", "=", "results", "[", "'scores'", "]", "\n", "if", "self", ".", "enable_rl_after", ">=", "0", "and", "local_step", ">", "self", ".", "enable_rl_after", "and", "self", ".", "trigger", "<", "0.2", ":", "\n", "                ", "torch", ".", "autograd", ".", "set_detect_anomaly", "(", "True", ")", "\n", "beam_size", "=", "results", "[", "'dec_outputs'", "]", ".", "size", "(", "2", ")", "\n", "for", "b", "in", "range", "(", "beam_size", ")", ":", "\n", "                    ", "this_outputs", "=", "results", "[", "'dec_outputs'", "]", "[", ":", ",", ":", ",", "b", ",", ":", "]", "\n", "best_value", ",", "best_index", "=", "this_outputs", ".", "max", "(", "-", "1", ")", "\n", "this_attns", "=", "{", "}", "\n", "for", "key", "in", "results", "[", "'dec_attns'", "]", ".", "keys", "(", ")", ":", "\n", "                        ", "this_attns", "[", "key", "]", "=", "results", "[", "'dec_attns'", "]", "[", "key", "]", "[", ":", ",", ":", ",", "b", ",", ":", "]", "\n", "", "assert", "batch", ".", "tgt", ".", "size", "(", "0", ")", "-", "1", "==", "this_outputs", ".", "size", "(", "0", ")", ",", "\" {} {}\"", ".", "format", "(", "batch", ".", "tgt", ".", "size", "(", ")", ",", "this_outputs", ".", "size", "(", ")", ")", "\n", "scales", "=", "[", "]", "\n", "old_tgt", "=", "batch", ".", "tgt", "\n", "max_len_tgt", "=", "old_tgt", ".", "size", "(", "0", ")", "\n", "new_tgt", "=", "None", "\n", "for", "batch_id", "in", "range", "(", "len", "(", "preds", ")", ")", ":", "\n", "                        ", "pred", "=", "preds", "[", "batch_id", "]", "[", "b", "]", "\n", "if", "len", "(", "preds_n", "[", "batch_id", "]", ")", "==", "0", ":", "\n", "                            ", "pred_n", "=", "torch", ".", "tensor", "(", "[", "]", ",", "dtype", "=", "old_tgt", ".", "dtype", ")", "\n", "", "else", ":", "\n", "                            ", "pred_n", "=", "preds_n", "[", "batch_id", "]", "[", "b", "]", "\n", "", "assert", "len", "(", "pred_n", ")", "<", "max_len_tgt", "\n", "padding_num", "=", "max_len_tgt", "-", "1", "-", "len", "(", "pred_n", ")", "\n", "padding_vec", "=", "torch", ".", "ones", "(", "padding_num", ",", "dtype", "=", "old_tgt", ".", "dtype", ")", "\n", "if", "self", ".", "n_gpu", ">=", "1", ":", "\n", "                            ", "padding_vec", "=", "padding_vec", ".", "cuda", "(", ")", "\n", "pred_n", "=", "pred_n", ".", "cuda", "(", ")", "\n", "", "pred_tgt", "=", "torch", ".", "cat", "(", "(", "pred_n", ",", "padding_vec", ")", ",", "0", ")", ".", "unsqueeze", "(", "0", ")", "# 1 * (max_len - 1)", "\n", "if", "new_tgt", "is", "not", "None", ":", "\n", "                            ", "new_tgt", "=", "torch", ".", "cat", "(", "(", "new_tgt", ",", "pred_tgt", ")", ",", "0", ")", "\n", "", "else", ":", "\n", "                            ", "new_tgt", "=", "pred_tgt", "\n", "", "src_raw", "=", "src_raws", "[", "batch_id", "]", "\n", "ans", "=", "target_ans", "[", "batch_id", "]", "\n", "if", "len", "(", "pred", ")", "==", "0", ":", "\n", "                            ", "scales", ".", "append", "(", "1.0", ")", "\n", "continue", "\n", "", "drqa_results", "=", "self", ".", "model", ".", "drqa_predict", "(", "\n", "doc", "=", "' '", ".", "join", "(", "src_raw", ")", ",", "que", "=", "' '", ".", "join", "(", "pred", ")", ",", "target", "=", "' '", ".", "join", "(", "ans", ")", ")", "\n", "f1_score", "=", "drqa_results", "[", "'f1'", "]", "\n", "scales", ".", "append", "(", "1.0", "-", "f1_score", ")", "\n", "", "scales", "=", "torch", ".", "tensor", "(", "scales", ",", "device", "=", "this_outputs", ".", "device", ")", "\n", "new_tgt", "=", "new_tgt", ".", "permute", "(", "1", ",", "0", ")", "\n", "# # init token id", "\n", "new_tgt_bos", "=", "torch", ".", "ones", "(", "size", "=", "(", "1", ",", "old_tgt", ".", "size", "(", "1", ")", ")", ",", "dtype", "=", "old_tgt", ".", "dtype", ")", "*", "2", "\n", "if", "self", ".", "n_gpu", ">=", "1", ":", "\n", "                        ", "new_tgt_bos", "=", "new_tgt_bos", ".", "cuda", "(", ")", "\n", "", "new_tgt", "=", "torch", ".", "cat", "(", "[", "new_tgt_bos", ",", "new_tgt", "]", ",", "dim", "=", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "batch", ".", "tgt", "=", "new_tgt", "\n", "loss", ",", "batch_stats", "=", "self", ".", "train_loss", "(", "\n", "batch", ",", "\n", "this_outputs", ",", "\n", "this_attns", ",", "\n", "normalization", "=", "normalization", ",", "\n", "shard_size", "=", "self", ".", "shard_size", ",", "\n", "trunc_start", "=", "0", ",", "\n", "trunc_size", "=", "trunc_size", ",", "\n", "retain_graph", "=", "True", ",", "\n", "scales", "=", "scales", ")", "\n", "batch", ".", "tgt", "=", "old_tgt", "\n", "# If truncated, don't backprop fully.", "\n", "# TO CHECK", "\n", "# if dec_state is not None:", "\n", "#    dec_state.detach()", "\n", "if", "self", ".", "model", ".", "decoder", ".", "state", "is", "not", "None", ":", "\n", "                        ", "self", ".", "model", ".", "decoder", ".", "detach_state", "(", ")", "\n", "", "if", "loss", "is", "not", "None", ":", "\n", "                        ", "self", ".", "optim", ".", "backward", "(", "loss", ")", "\n", "# --------------------------------", "\n", "# update only after all beam have done", "\n", "", "", "if", "self", ".", "grad_accum_count", "==", "1", ":", "\n", "                    ", "if", "self", ".", "n_gpu", ">", "1", ":", "\n", "                        ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "\n", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "onmt", ".", "utils", ".", "distributed", ".", "all_reduce_and_rescale_tensors", "(", "\n", "grads", ",", "float", "(", "1", ")", ")", "\n", "", "self", ".", "optim", ".", "step", "(", "rl", "=", "True", ")", "\n", "\n", "", "", "if", "self", ".", "grad_accum_count", "==", "1", ":", "\n", "                ", "self", ".", "optim", ".", "zero_grad", "(", ")", "\n", "\n", "# 3. Compute loss.", "\n", "", "loss", ",", "batch_stats", "=", "self", ".", "train_loss", "(", "\n", "batch", ",", "\n", "outputs", ",", "\n", "attns", ",", "\n", "normalization", "=", "normalization", ",", "\n", "shard_size", "=", "self", ".", "shard_size", ",", "\n", "trunc_start", "=", "0", ",", "\n", "trunc_size", "=", "trunc_size", ")", "\n", "\n", "if", "loss", "is", "not", "None", ":", "\n", "                ", "self", ".", "optim", ".", "backward", "(", "loss", ")", "\n", "\n", "\n", "# 4. Update the parameters and statistics.", "\n", "", "if", "self", ".", "grad_accum_count", "==", "1", ":", "\n", "# Multi GPU gradient gather", "\n", "                ", "if", "self", ".", "n_gpu", ">", "1", ":", "\n", "                    ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "\n", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "onmt", ".", "utils", ".", "distributed", ".", "all_reduce_and_rescale_tensors", "(", "\n", "grads", ",", "float", "(", "1", ")", ")", "\n", "", "self", ".", "optim", ".", "step", "(", ")", "\n", "\n", "", "total_stats", ".", "update", "(", "batch_stats", ")", "\n", "report_stats", ".", "update", "(", "batch_stats", ")", "\n", "\n", "# in case of multi step gradient accumulation,", "\n", "# update only after accum batches", "\n", "", "if", "self", ".", "grad_accum_count", ">", "1", ":", "\n", "            ", "if", "self", ".", "n_gpu", ">", "1", ":", "\n", "                ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "\n", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "onmt", ".", "utils", ".", "distributed", ".", "all_reduce_and_rescale_tensors", "(", "\n", "grads", ",", "float", "(", "1", ")", ")", "\n", "", "self", ".", "optim", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer._start_report_manager": [[471, 480], ["trainer.Trainer.report_manager.start"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.TranslationServer.start"], ["", "", "def", "_start_report_manager", "(", "self", ",", "start_time", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Simple function to start report manager (if any)\n        \"\"\"", "\n", "if", "self", ".", "report_manager", "is", "not", "None", ":", "\n", "            ", "if", "start_time", "is", "None", ":", "\n", "                ", "self", ".", "report_manager", ".", "start", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "report_manager", ".", "start_time", "=", "start_time", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer._maybe_gather_stats": [[481, 495], ["onmt.utils.Statistics.all_gather_stats"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.all_gather_stats"], ["", "", "", "def", "_maybe_gather_stats", "(", "self", ",", "stat", ")", ":", "\n", "        ", "\"\"\"\n        Gather statistics in multi-processes cases\n\n        Args:\n            stat(:obj:onmt.utils.Statistics): a Statistics object to gather\n                or None (it returns None in this case)\n\n        Returns:\n            stat: the updated (or unchanged) stat object\n        \"\"\"", "\n", "if", "stat", "is", "not", "None", "and", "self", ".", "n_gpu", ">", "1", ":", "\n", "            ", "return", "onmt", ".", "utils", ".", "Statistics", ".", "all_gather_stats", "(", "stat", ")", "\n", "", "return", "stat", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer._maybe_report_training": [[496, 506], ["trainer.Trainer.report_manager.report_training"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.report_manager.ReportMgrBase.report_training"], ["", "def", "_maybe_report_training", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "\n", "report_stats", ")", ":", "\n", "        ", "\"\"\"\n        Simple function to report training stats (if report_manager is set)\n        see `onmt.utils.ReportManagerBase.report_training` for doc\n        \"\"\"", "\n", "if", "self", ".", "report_manager", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "report_manager", ".", "report_training", "(", "\n", "step", ",", "num_steps", ",", "learning_rate", ",", "report_stats", ",", "\n", "multigpu", "=", "self", ".", "n_gpu", ">", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer._report_step": [[507, 517], ["trainer.Trainer.report_manager.report_step"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.report_manager.ReportMgrBase.report_step"], ["", "", "def", "_report_step", "(", "self", ",", "learning_rate", ",", "step", ",", "train_stats", "=", "None", ",", "\n", "valid_stats", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Simple function to report stats (if report_manager is set)\n        see `onmt.utils.ReportManagerBase.report_step` for doc\n        \"\"\"", "\n", "if", "self", ".", "report_manager", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "report_manager", ".", "report_step", "(", "\n", "learning_rate", ",", "step", ",", "train_stats", "=", "train_stats", ",", "\n", "valid_stats", "=", "valid_stats", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.build_trainer": [[21, 68], ["onmt.utils.loss.build_loss_compute", "onmt.utils.loss.build_loss_compute", "onmt.utils.build_report_manager", "onmt.Trainer", "dict"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.build_loss_compute", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.build_loss_compute", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.report_manager.build_report_manager"], ["def", "build_trainer", "(", "opt", ",", "device_id", ",", "model", ",", "fields", ",", "optim", ",", "model_saver", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Simplify `Trainer` creation based on user `opt`s*\n\n    Args:\n        opt (:obj:`Namespace`): user options (usually from argument parsing)\n        model (:obj:`onmt.models.NMTModel`): the model to train\n        fields (dict): dict of fields\n        optim (:obj:`onmt.utils.Optimizer`): optimizer used during training\n        data_type (str): string describing the type of data\n            e.g. \"text\", \"img\", \"audio\"\n        model_saver(:obj:`onmt.models.ModelSaverBase`): the utility object\n            used to save the model\n    \"\"\"", "\n", "\n", "tgt_field", "=", "dict", "(", "fields", ")", "[", "\"tgt\"", "]", ".", "base_field", "\n", "train_loss", "=", "onmt", ".", "utils", ".", "loss", ".", "build_loss_compute", "(", "model", ",", "tgt_field", ",", "opt", ")", "\n", "valid_loss", "=", "onmt", ".", "utils", ".", "loss", ".", "build_loss_compute", "(", "\n", "model", ",", "tgt_field", ",", "opt", ",", "train", "=", "False", ")", "\n", "\n", "trunc_size", "=", "opt", ".", "truncated_decoder", "# Badly named...", "\n", "shard_size", "=", "opt", ".", "max_generator_batches", "if", "opt", ".", "model_dtype", "==", "'fp32'", "else", "0", "\n", "norm_method", "=", "opt", ".", "normalization", "\n", "grad_accum_count", "=", "opt", ".", "accum_count", "\n", "n_gpu", "=", "opt", ".", "world_size", "\n", "average_decay", "=", "opt", ".", "average_decay", "\n", "average_every", "=", "opt", ".", "average_every", "\n", "if", "device_id", ">=", "0", ":", "\n", "        ", "gpu_rank", "=", "opt", ".", "gpu_ranks", "[", "device_id", "]", "\n", "", "else", ":", "\n", "        ", "gpu_rank", "=", "0", "\n", "n_gpu", "=", "0", "\n", "", "gpu_verbose_level", "=", "opt", ".", "gpu_verbose_level", "\n", "\n", "report_manager", "=", "onmt", ".", "utils", ".", "build_report_manager", "(", "opt", ")", "\n", "trainer", "=", "onmt", ".", "Trainer", "(", "model", ",", "train_loss", ",", "valid_loss", ",", "optim", ",", "trunc_size", ",", "\n", "shard_size", ",", "norm_method", ",", "\n", "grad_accum_count", ",", "n_gpu", ",", "gpu_rank", ",", "\n", "gpu_verbose_level", ",", "report_manager", ",", "\n", "tgt_field", "=", "tgt_field", ",", "\n", "model_saver", "=", "model_saver", "if", "gpu_rank", "==", "0", "else", "None", ",", "\n", "average_decay", "=", "average_decay", ",", "\n", "average_every", "=", "average_every", ",", "\n", "model_dtype", "=", "opt", ".", "model_dtype", ",", "\n", "enable_rl_after", "=", "opt", ".", "enable_rl_after", ",", "\n", "rl_save_step", "=", "opt", ".", "rl_save_step", ")", "\n", "return", "trainer", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.model_builder.build_embeddings": [[26, 59], ["onmt.modules.Embeddings", "len"], "function", ["None"], ["def", "build_embeddings", "(", "opt", ",", "text_field", ",", "for_encoder", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        opt: the option in current environment.\n        text_field(TextMultiField): word and feats field.\n        for_encoder(bool): build Embeddings for encoder or decoder?\n    \"\"\"", "\n", "emb_dim", "=", "opt", ".", "src_word_vec_size", "if", "for_encoder", "else", "opt", ".", "tgt_word_vec_size", "\n", "\n", "pad_indices", "=", "[", "f", ".", "vocab", ".", "stoi", "[", "f", ".", "pad_token", "]", "for", "_", ",", "f", "in", "text_field", "]", "\n", "word_padding_idx", ",", "feat_pad_indices", "=", "pad_indices", "[", "0", "]", ",", "pad_indices", "[", "1", ":", "]", "\n", "\n", "num_embs", "=", "[", "len", "(", "f", ".", "vocab", ")", "for", "_", ",", "f", "in", "text_field", "]", "\n", "num_word_embeddings", ",", "num_feat_embeddings", "=", "num_embs", "[", "0", "]", ",", "num_embs", "[", "1", ":", "]", "\n", "\n", "fix_word_vecs", "=", "opt", ".", "fix_word_vecs_enc", "if", "for_encoder", "else", "opt", ".", "fix_word_vecs_dec", "\n", "\n", "emb", "=", "Embeddings", "(", "\n", "word_vec_size", "=", "emb_dim", ",", "\n", "position_encoding", "=", "opt", ".", "position_encoding", ",", "\n", "feat_merge", "=", "opt", ".", "feat_merge", ",", "\n", "feat_vec_exponent", "=", "opt", ".", "feat_vec_exponent", ",", "\n", "feat_vec_size", "=", "opt", ".", "feat_vec_size", ",", "\n", "dropout", "=", "opt", ".", "dropout", ",", "\n", "word_padding_idx", "=", "word_padding_idx", ",", "\n", "feat_padding_idx", "=", "feat_pad_indices", ",", "\n", "word_vocab_size", "=", "num_word_embeddings", ",", "\n", "feat_vocab_sizes", "=", "num_feat_embeddings", ",", "\n", "sparse", "=", "opt", ".", "optim", "==", "\"sparseadam\"", ",", "\n", "fix_word_vecs", "=", "fix_word_vecs", "\n", ")", "\n", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.model_builder.build_encoder": [[61, 70], ["str2enc[].from_opt"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt"], ["", "def", "build_encoder", "(", "opt", ",", "embeddings", ")", ":", "\n", "    ", "\"\"\"\n    Various encoder dispatcher function.\n    Args:\n        opt: the option in current environment.\n        embeddings (Embeddings): vocab embeddings for this encoder.\n    \"\"\"", "\n", "enc_type", "=", "opt", ".", "encoder_type", "if", "opt", ".", "model_type", "==", "\"text\"", "else", "opt", ".", "model_type", "\n", "return", "str2enc", "[", "'redr'", "]", ".", "from_opt", "(", "opt", ",", "embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.model_builder.build_decoder": [[72, 82], ["str2dec[].from_opt"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt"], ["", "def", "build_decoder", "(", "opt", ",", "embeddings", ")", ":", "\n", "    ", "\"\"\"\n    Various decoder dispatcher function.\n    Args:\n        opt: the option in current environment.\n        embeddings (Embeddings): vocab embeddings for this decoder.\n    \"\"\"", "\n", "dec_type", "=", "\"ifrnn\"", "if", "opt", ".", "decoder_type", "==", "\"rnn\"", "and", "opt", ".", "input_feed", "else", "opt", ".", "decoder_type", "\n", "return", "str2dec", "[", "dec_type", "]", ".", "from_opt", "(", "opt", ",", "embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.model_builder.load_test_model": [[84, 108], ["torch.load", "torch.load", "onmt.utils.parse.ArgumentParser.ckpt_model_opts", "onmt.utils.parse.ArgumentParser.update_model_opts", "onmt.utils.parse.ArgumentParser.validate_model_opts", "onmt.old_style_vocab", "model_builder.build_base_model", "build_base_model.eval", "build_base_model.generator.eval", "onmt.load_old_vocab", "onmt.utils.misc.use_gpu", "build_base_model.float"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.parse.ArgumentParser.ckpt_model_opts", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.parse.ArgumentParser.update_model_opts", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.parse.ArgumentParser.validate_model_opts", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.old_style_vocab", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.model_builder.build_base_model", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.load_old_vocab", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.use_gpu"], ["", "def", "load_test_model", "(", "opt", ",", "model_path", "=", "None", ")", ":", "\n", "    ", "if", "model_path", "is", "None", ":", "\n", "        ", "model_path", "=", "opt", ".", "models", "[", "0", "]", "\n", "", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "\n", "model_opt", "=", "ArgumentParser", ".", "ckpt_model_opts", "(", "checkpoint", "[", "'opt'", "]", ")", "\n", "ArgumentParser", ".", "update_model_opts", "(", "model_opt", ")", "\n", "ArgumentParser", ".", "validate_model_opts", "(", "model_opt", ")", "\n", "vocab", "=", "checkpoint", "[", "'vocab'", "]", "\n", "if", "inputters", ".", "old_style_vocab", "(", "vocab", ")", ":", "\n", "        ", "fields", "=", "inputters", ".", "load_old_vocab", "(", "\n", "vocab", ",", "opt", ".", "data_type", ",", "dynamic_dict", "=", "model_opt", ".", "copy_attn", "\n", ")", "\n", "", "else", ":", "\n", "        ", "fields", "=", "vocab", "\n", "\n", "", "model", "=", "build_base_model", "(", "model_opt", ",", "opt", ",", "fields", ",", "use_gpu", "(", "opt", ")", ",", "checkpoint", ",", "\n", "opt", ".", "gpu", ")", "\n", "if", "opt", ".", "fp32", ":", "\n", "        ", "model", ".", "float", "(", ")", "\n", "", "model", ".", "eval", "(", ")", "\n", "model", ".", "generator", ".", "eval", "(", ")", "\n", "return", "fields", ",", "model", ",", "model_opt", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.model_builder.build_base_model": [[110, 227], ["model_builder.build_encoder", "model_builder.build_embeddings", "model_builder.build_decoder", "onmt.models.NMTModel", "onmt.models.NMTModel", "onmt.models.NMTModel.to", "model_builder.build_embeddings", "torch.device", "torch.device", "torch.Sequential", "len", "onmt.modules.CopyGenerator", "onmt.models.NMTModel.load_state_dict", "onmt.modules.CopyGenerator.load_state_dict", "hasattr", "hasattr", "hasattr", "onmt.models.NMTModel.half", "torch.device", "torch.device", "onmt.modules.sparse_activations.LogSparsemax", "onmt.modules.sparse_activations.LogSparsemax", "torch.LogSoftmax", "torch.Linear", "onmt.modules.util_class.Cast", "re.sub", "re.sub", "model_builder.build_base_model.fix_key"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.model_builder.build_encoder", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.load_state_dict", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.load_state_dict"], ["", "def", "build_base_model", "(", "model_opt", ",", "opt", ",", "fields", ",", "gpu", ",", "checkpoint", "=", "None", ",", "gpu_id", "=", "None", ")", ":", "\n", "    ", "\"\"\"Build a model from opts.\n\n    Args:\n        model_opt: the option loaded from checkpoint. It's important that\n            the opts have been updated and validated. See\n            :class:`onmt.utils.parse.ArgumentParser`.\n        fields (dict[str, torchtext.data.Field]):\n            `Field` objects for the model.\n        gpu (bool): whether to use gpu.\n        checkpoint: the model gnerated by train phase, or a resumed snapshot\n                    model from a stopped training.\n        gpu_id (int or NoneType): Which GPU to use.\n\n    Returns:\n        the NMTModel.\n    \"\"\"", "\n", "\n", "# Build embeddings.", "\n", "if", "model_opt", ".", "model_type", "==", "\"text\"", ":", "\n", "        ", "src_field", "=", "fields", "[", "\"src\"", "]", "\n", "src_emb", "=", "build_embeddings", "(", "model_opt", ",", "src_field", ")", "\n", "", "else", ":", "\n", "        ", "src_emb", "=", "None", "\n", "\n", "# Build encoder.", "\n", "", "redr_encoder", "=", "build_encoder", "(", "model_opt", ",", "src_emb", ")", "\n", "\n", "# Build decoder.", "\n", "tgt_field", "=", "fields", "[", "\"tgt\"", "]", "\n", "tgt_emb", "=", "build_embeddings", "(", "model_opt", ",", "tgt_field", ",", "for_encoder", "=", "False", ")", "\n", "\n", "# Share the embedding matrix - preprocess with share_vocab required.", "\n", "if", "model_opt", ".", "share_embeddings", ":", "\n", "# src/tgt vocab should be the same if `-share_vocab` is specified.", "\n", "        ", "assert", "src_field", ".", "base_field", ".", "vocab", "==", "tgt_field", ".", "base_field", ".", "vocab", ",", "\"preprocess with -share_vocab if you use share_embeddings\"", "\n", "\n", "tgt_emb", ".", "word_lut", ".", "weight", "=", "src_emb", ".", "word_lut", ".", "weight", "\n", "\n", "", "decoder", "=", "build_decoder", "(", "model_opt", ",", "tgt_emb", ")", "\n", "\n", "# Build NMTModel(= encoder + decoder).", "\n", "if", "gpu", "and", "gpu_id", "is", "not", "None", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "gpu_id", ")", "\n", "", "elif", "gpu", "and", "not", "gpu_id", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "", "elif", "not", "gpu", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "", "model", "=", "onmt", ".", "models", ".", "NMTModel", "(", "redr_encoder", ",", "decoder", ")", "\n", "\n", "# Build Generator.", "\n", "if", "not", "model_opt", ".", "copy_attn", ":", "\n", "        ", "if", "model_opt", ".", "generator_function", "==", "\"sparsemax\"", ":", "\n", "            ", "gen_func", "=", "onmt", ".", "modules", ".", "sparse_activations", ".", "LogSparsemax", "(", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "gen_func", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", "\n", "", "generator", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "model_opt", ".", "dec_rnn_size", ",", "\n", "len", "(", "fields", "[", "\"tgt\"", "]", ".", "base_field", ".", "vocab", ")", ")", ",", "\n", "Cast", "(", "torch", ".", "float32", ")", ",", "\n", "gen_func", "\n", ")", "\n", "if", "model_opt", ".", "share_decoder_embeddings", ":", "\n", "            ", "generator", "[", "0", "]", ".", "weight", "=", "decoder", ".", "embeddings", ".", "word_lut", ".", "weight", "\n", "", "", "else", ":", "\n", "        ", "tgt_base_field", "=", "fields", "[", "\"tgt\"", "]", ".", "base_field", "\n", "vocab_size", "=", "len", "(", "tgt_base_field", ".", "vocab", ")", "\n", "pad_idx", "=", "tgt_base_field", ".", "vocab", ".", "stoi", "[", "tgt_base_field", ".", "pad_token", "]", "\n", "generator", "=", "CopyGenerator", "(", "model_opt", ".", "dec_rnn_size", ",", "vocab_size", ",", "pad_idx", ")", "\n", "\n", "# Load the model states from checkpoint or initialize them.", "\n", "", "if", "checkpoint", "is", "not", "None", ":", "\n", "# This preserves backward-compat for models using customed layernorm", "\n", "        ", "def", "fix_key", "(", "s", ")", ":", "\n", "            ", "s", "=", "re", ".", "sub", "(", "r'(.*)\\.layer_norm((_\\d+)?)\\.b_2'", ",", "\n", "r'\\1.layer_norm\\2.bias'", ",", "s", ")", "\n", "s", "=", "re", ".", "sub", "(", "r'(.*)\\.layer_norm((_\\d+)?)\\.a_2'", ",", "\n", "r'\\1.layer_norm\\2.weight'", ",", "s", ")", "\n", "return", "s", "\n", "\n", "", "checkpoint", "[", "'model'", "]", "=", "{", "fix_key", "(", "k", ")", ":", "v", "\n", "for", "k", ",", "v", "in", "checkpoint", "[", "'model'", "]", ".", "items", "(", ")", "}", "\n", "# end of patch for backward compatibility", "\n", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ",", "strict", "=", "False", ")", "\n", "generator", ".", "load_state_dict", "(", "checkpoint", "[", "'generator'", "]", ",", "strict", "=", "False", ")", "\n", "", "else", ":", "\n", "        ", "if", "model_opt", ".", "param_init", "!=", "0.0", ":", "\n", "            ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "data", ".", "uniform_", "(", "-", "model_opt", ".", "param_init", ",", "model_opt", ".", "param_init", ")", "\n", "", "for", "p", "in", "generator", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "data", ".", "uniform_", "(", "-", "model_opt", ".", "param_init", ",", "model_opt", ".", "param_init", ")", "\n", "", "", "if", "model_opt", ".", "param_init_glorot", ":", "\n", "            ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "xavier_uniform_", "(", "p", ")", "\n", "", "", "for", "p", "in", "generator", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "xavier_uniform_", "(", "p", ")", "\n", "\n", "", "", "", "if", "hasattr", "(", "model", ".", "encoder", ".", "reference_encoder", ",", "'embeddings'", ")", ":", "\n", "            ", "model", ".", "encoder", ".", "reference_encoder", ".", "embeddings", ".", "load_pretrained_vectors", "(", "\n", "model_opt", ".", "pre_word_vecs_enc", ")", "\n", "", "if", "hasattr", "(", "model", ".", "encoder", ".", "history_encoder", ",", "'embeddings'", ")", ":", "\n", "            ", "model", ".", "encoder", ".", "history_encoder", ".", "embeddings", ".", "load_pretrained_vectors", "(", "\n", "model_opt", ".", "pre_word_vecs_enc", ")", "\n", "", "if", "hasattr", "(", "model", ".", "decoder", ",", "'embeddings'", ")", ":", "\n", "            ", "model", ".", "decoder", ".", "embeddings", ".", "load_pretrained_vectors", "(", "\n", "model_opt", ".", "pre_word_vecs_dec", ")", "\n", "\n", "", "", "model", ".", "generator", "=", "generator", "\n", "model", ".", "to", "(", "device", ")", "\n", "if", "model_opt", ".", "model_dtype", "==", "'fp16'", ":", "\n", "        ", "model", ".", "half", "(", ")", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.model_builder.build_model": [[229, 248], ["onmt.utils.logging.logger.info", "model_builder.build_base_model", "build_base_model.set_drqa_model", "onmt.utils.logging.logger.info", "onmt.utils.misc.use_gpu", "torch.load", "torch.load", "json.load", "types.SimpleNamespace", "clta.drqa_model.DrQA", "drqa_model.cuda.load", "onmt.utils.misc.use_gpu", "open", "drqa_model.cuda.cuda"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.model_builder.build_base_model", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model.NMTModel.set_drqa_model", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.use_gpu", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.use_gpu"], ["", "def", "build_model", "(", "model_opt", ",", "opt", ",", "fields", ",", "checkpoint", ")", ":", "\n", "    ", "logger", ".", "info", "(", "'Building model...'", ")", "\n", "model", "=", "build_base_model", "(", "model_opt", ",", "opt", ",", "fields", ",", "use_gpu", "(", "opt", ")", ",", "checkpoint", ")", "\n", "# drqa model", "\n", "drqa_model", "=", "None", "\n", "if", "opt", ".", "enable_rl_after", ">=", "0", ":", "\n", "        ", "vocab", "=", "torch", ".", "load", "(", "opt", ".", "drqa_vocab_path", ")", "\n", "json_config", "=", "json", ".", "load", "(", "open", "(", "opt", ".", "drqa_config_path", ",", "'r'", ")", ")", "\n", "args", "=", "SimpleNamespace", "(", "**", "json_config", ")", "\n", "drqa_model", "=", "DrQA", "(", "vocab", ",", "args", ")", "\n", "drqa_model", ".", "load", "(", "opt", ".", "drqa_param_path", ")", "\n", "drqa_model", ".", "gpu", "=", "False", "\n", "if", "use_gpu", "(", "opt", ")", ":", "\n", "            ", "drqa_model", "=", "drqa_model", ".", "cuda", "(", ")", "\n", "drqa_model", ".", "gpu", "=", "True", "\n", "", "", "model", ".", "set_drqa_model", "(", "drqa_model", ")", "\n", "# -----", "\n", "logger", ".", "info", "(", "model", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.train_single._check_save_model_path": [[20, 25], ["os.path.abspath", "os.path.dirname", "os.path.exists", "os.makedirs"], "function", ["None"], ["def", "_check_save_model_path", "(", "opt", ")", ":", "\n", "    ", "save_model_path", "=", "os", ".", "path", ".", "abspath", "(", "opt", ".", "save_model", ")", "\n", "model_dirname", "=", "os", ".", "path", ".", "dirname", "(", "save_model_path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "model_dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "model_dirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.train_single._tally_parameters": [[27, 36], ["model.named_parameters", "param.nelement", "param.nelement"], "function", ["None"], ["", "", "def", "_tally_parameters", "(", "model", ")", ":", "\n", "    ", "enc", "=", "0", "\n", "dec", "=", "0", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "'encoder'", "in", "name", ":", "\n", "            ", "enc", "+=", "param", ".", "nelement", "(", ")", "\n", "", "else", ":", "\n", "            ", "dec", "+=", "param", ".", "nelement", "(", ")", "\n", "", "", "return", "enc", "+", "dec", ",", "enc", ",", "dec", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.train_single.configure_process": [[38, 42], ["onmt.utils.misc.set_random_seed", "torch.cuda.set_device"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.set_random_seed"], ["", "def", "configure_process", "(", "opt", ",", "device_id", ")", ":", "\n", "    ", "if", "device_id", ">=", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "device_id", ")", "\n", "", "set_random_seed", "(", "opt", ".", "seed", ",", "device_id", ">=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.train_single.main": [[44, 138], ["train_single.configure_process", "onmt.utils.logging.init_logger", "onmt.inputters.inputter.old_style_vocab", "onmt.model_builder.build_model", "onmt.translate.GNMTGlobalScorer.from_opt", "onmt.translate.Translator.from_opt", "onmt.model_builder.build_model.set_translator", "train_single._tally_parameters", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "train_single._check_save_model_path", "onmt.utils.optimizers.Optimizer.from_opt", "onmt.models.build_model_saver", "onmt.trainer.build_trainer", "onmt.inputters.inputter.build_dataset_iter", "onmt.inputters.inputter.build_dataset_iter", "onmt.model_builder.build_model.set_vocabs", "onmt.model_builder.build_model.set_examples", "len", "onmt.trainer.build_trainer.train", "onmt.utils.logging.logger.info", "torch.load", "onmt.utils.parse.ArgumentParser.ckpt_model_opts", "onmt.utils.parse.ArgumentParser.update_model_opts", "onmt.utils.parse.ArgumentParser.validate_model_opts", "onmt.utils.logging.logger.info", "torch.load", "onmt.inputters.inputter.load_old_vocab", "len", "len", "len", "len", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.warning", "onmt.trainer.build_trainer.report_manager.tensorboard_writer.close", "iter", "onmt.utils.logging.logger.info", "len"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.train_single.configure_process", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.logging.init_logger", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.old_style_vocab", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.model_builder.build_model", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model.NMTModel.set_translator", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.train_single._tally_parameters", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.train_single._check_save_model_path", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.build_model_saver", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.build_trainer", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.build_dataset_iter", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.build_dataset_iter", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model.NMTModel.set_vocabs", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model.NMTModel.set_examples", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer.train", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.parse.ArgumentParser.ckpt_model_opts", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.parse.ArgumentParser.update_model_opts", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.parse.ArgumentParser.validate_model_opts", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.load_old_vocab"], ["", "def", "main", "(", "opt", ",", "device_id", ")", ":", "\n", "# NOTE: It's important that ``opt`` has been validated and updated", "\n", "# at this point.", "\n", "    ", "configure_process", "(", "opt", ",", "device_id", ")", "\n", "init_logger", "(", "opt", ".", "log_file", ")", "\n", "# Load checkpoint if we resume from a previous training.", "\n", "if", "opt", ".", "train_from", ":", "\n", "        ", "logger", ".", "info", "(", "'Loading checkpoint from %s'", "%", "opt", ".", "train_from", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "train_from", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "\n", "model_opt", "=", "ArgumentParser", ".", "ckpt_model_opts", "(", "checkpoint", "[", "\"opt\"", "]", ")", "\n", "ArgumentParser", ".", "update_model_opts", "(", "model_opt", ")", "\n", "ArgumentParser", ".", "validate_model_opts", "(", "model_opt", ")", "\n", "logger", ".", "info", "(", "'Loading vocab from checkpoint at %s.'", "%", "opt", ".", "train_from", ")", "\n", "vocab", "=", "checkpoint", "[", "'vocab'", "]", "\n", "", "else", ":", "\n", "        ", "checkpoint", "=", "None", "\n", "model_opt", "=", "opt", "\n", "# print(opt.data + '.vocab.pt')", "\n", "vocab", "=", "torch", ".", "load", "(", "opt", ".", "data", "+", "'.vocab.pt'", ")", "\n", "\n", "# check for code where vocab is saved instead of fields", "\n", "# (in the future this will be done in a smarter way)", "\n", "", "if", "old_style_vocab", "(", "vocab", ")", ":", "\n", "        ", "fields", "=", "load_old_vocab", "(", "\n", "vocab", ",", "opt", ".", "model_type", ",", "dynamic_dict", "=", "opt", ".", "copy_attn", ")", "\n", "", "else", ":", "\n", "        ", "fields", "=", "vocab", "\n", "\n", "# Report src and tgt vocab sizes, including for features", "\n", "", "for", "side", "in", "[", "'src'", ",", "'history'", ",", "'tgt'", "]", ":", "\n", "        ", "f", "=", "fields", "[", "side", "]", "\n", "try", ":", "\n", "            ", "f_iter", "=", "iter", "(", "f", ")", "\n", "", "except", "TypeError", ":", "\n", "            ", "f_iter", "=", "[", "(", "side", ",", "f", ")", "]", "\n", "", "for", "sn", ",", "sf", "in", "f_iter", ":", "\n", "            ", "if", "sf", ".", "use_vocab", ":", "\n", "                ", "logger", ".", "info", "(", "' * %s vocab size = %d'", "%", "(", "sn", ",", "len", "(", "sf", ".", "vocab", ")", ")", ")", "\n", "\n", "# Build model.", "\n", "", "", "", "model", "=", "build_model", "(", "model_opt", ",", "opt", ",", "fields", ",", "checkpoint", ")", "\n", "\n", "scorer", "=", "onmt", ".", "translate", ".", "GNMTGlobalScorer", ".", "from_opt", "(", "opt", ")", "\n", "translator", "=", "Translator", ".", "from_opt", "(", "\n", "model", ",", "\n", "fields", ",", "\n", "opt", ",", "\n", "model_opt", ",", "\n", "global_scorer", "=", "scorer", ")", "\n", "\n", "model", ".", "set_translator", "(", "translator", ")", "\n", "\n", "n_params", ",", "enc", ",", "dec", "=", "_tally_parameters", "(", "model", ")", "\n", "logger", ".", "info", "(", "'encoder: %d'", "%", "enc", ")", "\n", "logger", ".", "info", "(", "'decoder: %d'", "%", "dec", ")", "\n", "logger", ".", "info", "(", "'* number of parameters: %d'", "%", "n_params", ")", "\n", "_check_save_model_path", "(", "opt", ")", "\n", "\n", "# Build optimizer.", "\n", "optim", "=", "Optimizer", ".", "from_opt", "(", "model", ",", "opt", ",", "checkpoint", "=", "checkpoint", ")", "\n", "\n", "# Build model saver", "\n", "model_saver", "=", "build_model_saver", "(", "model_opt", ",", "opt", ",", "model", ",", "fields", ",", "optim", ")", "\n", "\n", "trainer", "=", "build_trainer", "(", "\n", "opt", ",", "device_id", ",", "model", ",", "fields", ",", "optim", ",", "model_saver", "=", "model_saver", ")", "\n", "\n", "train_iter", "=", "build_dataset_iter", "(", "\"train\"", ",", "fields", ",", "opt", ")", "\n", "valid_iter", "=", "build_dataset_iter", "(", "\n", "\"valid\"", ",", "fields", ",", "opt", ",", "is_train", "=", "False", ")", "\n", "assert", "len", "(", "train_iter", ".", "examples", ")", "==", "len", "(", "train_iter", ".", "src_vocabs", ")", ",", "\"src_vocabs not equal to examples\"", "\n", "assert", "len", "(", "valid_iter", ".", "examples", ")", "==", "len", "(", "valid_iter", ".", "src_vocabs", ")", ",", "\"src_vocabs not equal to examples\"", "\n", "model", ".", "set_vocabs", "(", "train_iter", ".", "src_vocabs", ",", "valid_iter", ".", "src_vocabs", ")", "\n", "model", ".", "set_examples", "(", "train_iter", ".", "examples", ",", "valid_iter", ".", "examples", ")", "\n", "\n", "if", "len", "(", "opt", ".", "gpu_ranks", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Starting training on GPU: %s'", "%", "opt", ".", "gpu_ranks", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "'Starting training on CPU, could be very slow'", ")", "\n", "", "train_steps", "=", "opt", ".", "train_steps", "\n", "if", "opt", ".", "single_pass", "and", "train_steps", ">", "0", ":", "\n", "        ", "logger", ".", "warning", "(", "\"Option single_pass is enabled, ignoring train_steps.\"", ")", "\n", "train_steps", "=", "0", "\n", "", "trainer", ".", "train", "(", "\n", "train_iter", ",", "\n", "train_steps", ",", "\n", "save_checkpoint_steps", "=", "opt", ".", "save_checkpoint_steps", ",", "\n", "valid_iter", "=", "valid_iter", ",", "\n", "valid_steps", "=", "opt", ".", "valid_steps", ")", "\n", "\n", "if", "opt", ".", "tensorboard", ":", "\n", "        ", "trainer", ".", "report_manager", ".", "tensorboard_writer", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.__init__": [[20, 26], ["time.time"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "loss", "=", "0", ",", "n_words", "=", "0", ",", "n_correct", "=", "0", ")", ":", "\n", "        ", "self", ".", "loss", "=", "loss", "\n", "self", ".", "n_words", "=", "n_words", "\n", "self", ".", "n_correct", "=", "n_correct", "\n", "self", ".", "n_src_words", "=", "0", "\n", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.all_gather_stats": [[27, 42], ["statistics.Statistics.all_gather_stats_list"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.all_gather_stats_list"], ["", "@", "staticmethod", "\n", "def", "all_gather_stats", "(", "stat", ",", "max_size", "=", "4096", ")", ":", "\n", "        ", "\"\"\"\n        Gather a `Statistics` object accross multiple process/nodes\n\n        Args:\n            stat(:obj:Statistics): the statistics object to gather\n                accross all processes/nodes\n            max_size(int): max buffer size to use\n\n        Returns:\n            `Statistics`, the update stats object\n        \"\"\"", "\n", "stats", "=", "Statistics", ".", "all_gather_stats_list", "(", "[", "stat", "]", ",", "max_size", "=", "max_size", ")", "\n", "return", "stats", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.all_gather_stats_list": [[43, 70], ["all_gather_list", "get_rank", "enumerate", "enumerate", "our_stats[].update"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.update"], ["", "@", "staticmethod", "\n", "def", "all_gather_stats_list", "(", "stat_list", ",", "max_size", "=", "4096", ")", ":", "\n", "        ", "\"\"\"\n        Gather a `Statistics` list accross all processes/nodes\n\n        Args:\n            stat_list(list([`Statistics`])): list of statistics objects to\n                gather accross all processes/nodes\n            max_size(int): max buffer size to use\n\n        Returns:\n            our_stats(list([`Statistics`])): list of updated stats\n        \"\"\"", "\n", "from", "torch", ".", "distributed", "import", "get_rank", "\n", "from", "onmt", ".", "utils", ".", "distributed", "import", "all_gather_list", "\n", "\n", "# Get a list of world_size lists with len(stat_list) Statistics objects", "\n", "all_stats", "=", "all_gather_list", "(", "stat_list", ",", "max_size", "=", "max_size", ")", "\n", "\n", "our_rank", "=", "get_rank", "(", ")", "\n", "our_stats", "=", "all_stats", "[", "our_rank", "]", "\n", "for", "other_rank", ",", "stats", "in", "enumerate", "(", "all_stats", ")", ":", "\n", "            ", "if", "other_rank", "==", "our_rank", ":", "\n", "                ", "continue", "\n", "", "for", "i", ",", "stat", "in", "enumerate", "(", "stats", ")", ":", "\n", "                ", "our_stats", "[", "i", "]", ".", "update", "(", "stat", ",", "update_n_src_words", "=", "True", ")", "\n", "", "", "return", "our_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.update": [[71, 87], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "stat", ",", "update_n_src_words", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Update statistics by suming values with another `Statistics` object\n\n        Args:\n            stat: another statistic object\n            update_n_src_words(bool): whether to update (sum) `n_src_words`\n                or not\n\n        \"\"\"", "\n", "self", ".", "loss", "+=", "stat", ".", "loss", "\n", "self", ".", "n_words", "+=", "stat", ".", "n_words", "\n", "self", ".", "n_correct", "+=", "stat", ".", "n_correct", "\n", "\n", "if", "update_n_src_words", ":", "\n", "            ", "self", ".", "n_src_words", "+=", "stat", ".", "n_src_words", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.accuracy": [[88, 95], ["None"], "methods", ["None"], ["", "", "def", "accuracy", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute accuracy \"\"\"", "\n", "# if self.n_words > 0:", "\n", "#     return 100 * (self.n_correct / self.n_words)", "\n", "# else:", "\n", "#     return 0", "\n", "return", "100", "*", "(", "self", ".", "n_correct", "/", "self", ".", "n_words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.xent": [[96, 103], ["None"], "methods", ["None"], ["", "def", "xent", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute cross entropy \"\"\"", "\n", "# if self.n_words > 0:", "\n", "#     return self.loss / self.n_words", "\n", "# else:", "\n", "#     return 0", "\n", "return", "self", ".", "loss", "/", "self", ".", "n_words", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.ppl": [[104, 111], ["math.exp", "min"], "methods", ["None"], ["", "def", "ppl", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute perplexity \"\"\"", "\n", "# if self.n_words > 0:", "\n", "#     return math.exp(min(self.loss / self.n_words, 100))", "\n", "# else:", "\n", "#     return math.exp(0)", "\n", "return", "math", ".", "exp", "(", "min", "(", "self", ".", "loss", "/", "self", ".", "n_words", ",", "100", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.elapsed_time": [[112, 115], ["time.time"], "methods", ["None"], ["", "def", "elapsed_time", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute elapsed time \"\"\"", "\n", "return", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.output": [[116, 140], ["statistics.Statistics.elapsed_time", "onmt.utils.logging.logger.info", "sys.stdout.flush", "statistics.Statistics.accuracy", "statistics.Statistics.ppl", "statistics.Statistics.xent", "time.time"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.elapsed_time", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.accuracy", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.ppl", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.xent"], ["", "def", "output", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "start", ")", ":", "\n", "        ", "\"\"\"Write out statistics to stdout.\n\n        Args:\n           step (int): current step\n           n_batch (int): total batches\n           start (int): start time of step.\n        \"\"\"", "\n", "t", "=", "self", ".", "elapsed_time", "(", ")", "\n", "step_fmt", "=", "\"%2d\"", "%", "step", "\n", "if", "num_steps", ">", "0", ":", "\n", "            ", "step_fmt", "=", "\"%s/%5d\"", "%", "(", "step_fmt", ",", "num_steps", ")", "\n", "", "logger", ".", "info", "(", "\n", "(", "\"Step %s; acc: %6.2f; ppl: %5.2f; xent: %4.2f; \"", "+", "\n", "\"lr: %7.5f; %3.0f/%3.0f tok/s; %6.0f sec\"", ")", "\n", "%", "(", "step_fmt", ",", "\n", "self", ".", "accuracy", "(", ")", ",", "\n", "self", ".", "ppl", "(", ")", ",", "\n", "self", ".", "xent", "(", ")", ",", "\n", "learning_rate", ",", "\n", "self", ".", "n_src_words", "/", "(", "t", "+", "1e-5", ")", ",", "\n", "self", ".", "n_words", "/", "(", "t", "+", "1e-5", ")", ",", "\n", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.log_tensorboard": [[141, 149], ["statistics.Statistics.elapsed_time", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "statistics.Statistics.xent", "statistics.Statistics.ppl", "statistics.Statistics.accuracy"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.elapsed_time", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.xent", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.ppl", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.accuracy"], ["", "def", "log_tensorboard", "(", "self", ",", "prefix", ",", "writer", ",", "learning_rate", ",", "step", ")", ":", "\n", "        ", "\"\"\" display statistics to tensorboard \"\"\"", "\n", "t", "=", "self", ".", "elapsed_time", "(", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/xent\"", ",", "self", ".", "xent", "(", ")", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/ppl\"", ",", "self", ".", "ppl", "(", ")", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/accuracy\"", ",", "self", ".", "accuracy", "(", ")", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/tgtper\"", ",", "self", ".", "n_words", "/", "t", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/lr\"", ",", "learning_rate", ",", "step", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.logging.init_logger": [[9, 25], ["logging.Formatter", "logging.getLogger", "logging.getLogger.setLevel", "logging.StreamHandler", "logging.StreamHandler.setFormatter", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler"], "function", ["None"], ["def", "init_logger", "(", "log_file", "=", "None", ",", "log_file_level", "=", "logging", ".", "NOTSET", ")", ":", "\n", "    ", "log_format", "=", "logging", ".", "Formatter", "(", "\"[%(asctime)s %(levelname)s] %(message)s\"", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "\n", "console_handler", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "console_handler", ".", "setFormatter", "(", "log_format", ")", "\n", "logger", ".", "handlers", "=", "[", "console_handler", "]", "\n", "\n", "if", "log_file", "and", "log_file", "!=", "''", ":", "\n", "        ", "file_handler", "=", "logging", ".", "FileHandler", "(", "log_file", ")", "\n", "file_handler", ".", "setLevel", "(", "log_file_level", ")", "\n", "file_handler", ".", "setFormatter", "(", "log_format", ")", "\n", "logger", ".", "addHandler", "(", "file_handler", ")", "\n", "\n", "", "return", "logger", "\n", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.distributed.is_master": [[16, 18], ["None"], "function", ["None"], ["def", "is_master", "(", "opt", ",", "device_id", ")", ":", "\n", "    ", "return", "opt", ".", "gpu_ranks", "[", "device_id", "]", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.distributed.multi_init": [[20, 33], ["torch.distributed.init_process_group", "torch.distributed.get_rank", "distributed.is_master"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.distributed.is_master"], ["", "def", "multi_init", "(", "opt", ",", "device_id", ")", ":", "\n", "    ", "dist_init_method", "=", "'tcp://{master_ip}:{master_port}'", ".", "format", "(", "\n", "master_ip", "=", "opt", ".", "master_ip", ",", "\n", "master_port", "=", "opt", ".", "master_port", ")", "\n", "dist_world_size", "=", "opt", ".", "world_size", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "opt", ".", "gpu_backend", ",", "init_method", "=", "dist_init_method", ",", "\n", "world_size", "=", "dist_world_size", ",", "rank", "=", "opt", ".", "gpu_ranks", "[", "device_id", "]", ")", "\n", "gpu_rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "if", "not", "is_master", "(", "opt", ",", "device_id", ")", ":", "\n", "        ", "logger", ".", "disabled", "=", "True", "\n", "\n", "", "return", "gpu_rank", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.distributed.all_reduce_and_rescale_tensors": [[35, 87], ["tensors[].new().zero_", "torch.distributed.all_reduce", "tensors[].new().zero_.div_", "len", "distributed.all_reduce_and_rescale_tensors.all_reduce_buffer"], "function", ["None"], ["", "def", "all_reduce_and_rescale_tensors", "(", "tensors", ",", "rescale_denom", ",", "\n", "buffer_size", "=", "10485760", ")", ":", "\n", "    ", "\"\"\"All-reduce and rescale tensors in chunks of the specified size.\n\n    Args:\n        tensors: list of Tensors to all-reduce\n        rescale_denom: denominator for rescaling summed Tensors\n        buffer_size: all-reduce chunk size in bytes\n    \"\"\"", "\n", "# buffer size in bytes, determine equiv. # of elements based on data type", "\n", "buffer_t", "=", "tensors", "[", "0", "]", ".", "new", "(", "\n", "math", ".", "ceil", "(", "buffer_size", "/", "tensors", "[", "0", "]", ".", "element_size", "(", ")", ")", ")", ".", "zero_", "(", ")", "\n", "buffer", "=", "[", "]", "\n", "\n", "def", "all_reduce_buffer", "(", ")", ":", "\n", "# copy tensors into buffer_t", "\n", "        ", "offset", "=", "0", "\n", "for", "t", "in", "buffer", ":", "\n", "            ", "numel", "=", "t", ".", "numel", "(", ")", "\n", "buffer_t", "[", "offset", ":", "offset", "+", "numel", "]", ".", "copy_", "(", "t", ".", "view", "(", "-", "1", ")", ")", "\n", "offset", "+=", "numel", "\n", "\n", "# all-reduce and rescale", "\n", "", "torch", ".", "distributed", ".", "all_reduce", "(", "buffer_t", "[", ":", "offset", "]", ")", "\n", "buffer_t", ".", "div_", "(", "rescale_denom", ")", "\n", "\n", "# copy all-reduced buffer back into tensors", "\n", "offset", "=", "0", "\n", "for", "t", "in", "buffer", ":", "\n", "            ", "numel", "=", "t", ".", "numel", "(", ")", "\n", "t", ".", "view", "(", "-", "1", ")", ".", "copy_", "(", "buffer_t", "[", "offset", ":", "offset", "+", "numel", "]", ")", "\n", "offset", "+=", "numel", "\n", "\n", "", "", "filled", "=", "0", "\n", "for", "t", "in", "tensors", ":", "\n", "        ", "sz", "=", "t", ".", "numel", "(", ")", "*", "t", ".", "element_size", "(", ")", "\n", "if", "sz", ">", "buffer_size", ":", "\n", "# tensor is bigger than buffer, all-reduce and rescale directly", "\n", "            ", "torch", ".", "distributed", ".", "all_reduce", "(", "t", ")", "\n", "t", ".", "div_", "(", "rescale_denom", ")", "\n", "", "elif", "filled", "+", "sz", ">", "buffer_size", ":", "\n", "# buffer is full, all-reduce and replace buffer with grad", "\n", "            ", "all_reduce_buffer", "(", ")", "\n", "buffer", "=", "[", "t", "]", "\n", "filled", "=", "sz", "\n", "", "else", ":", "\n", "# add tensor to buffer", "\n", "            ", "buffer", ".", "append", "(", "t", ")", "\n", "filled", "+=", "sz", "\n", "\n", "", "", "if", "len", "(", "buffer", ")", ">", "0", ":", "\n", "        ", "all_reduce_buffer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.distributed.all_gather_list": [[89, 123], ["torch.distributed.get_world_size", "pickle.dumps", "len", "torch.ByteTensor", "torch.distributed.all_gather", "range", "torch.cuda.ByteTensor", "ValueError", "list", "in_buffer.cuda", "bytes", "pickle.loads", "results.append", "hasattr", "all_gather_list._in_buffer.size", "torch.cuda.ByteTensor", "out_buffer[].item", "out_buffer[].tolist", "range", "out_buffer[].item"], "function", ["None"], ["", "", "def", "all_gather_list", "(", "data", ",", "max_size", "=", "4096", ")", ":", "\n", "    ", "\"\"\"Gathers arbitrary data from all nodes into a list.\"\"\"", "\n", "world_size", "=", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "\n", "if", "not", "hasattr", "(", "all_gather_list", ",", "'_in_buffer'", ")", "or", "max_size", "!=", "all_gather_list", ".", "_in_buffer", ".", "size", "(", ")", ":", "\n", "        ", "all_gather_list", ".", "_in_buffer", "=", "torch", ".", "cuda", ".", "ByteTensor", "(", "max_size", ")", "\n", "all_gather_list", ".", "_out_buffers", "=", "[", "\n", "torch", ".", "cuda", ".", "ByteTensor", "(", "max_size", ")", "\n", "for", "i", "in", "range", "(", "world_size", ")", "\n", "]", "\n", "", "in_buffer", "=", "all_gather_list", ".", "_in_buffer", "\n", "out_buffers", "=", "all_gather_list", ".", "_out_buffers", "\n", "\n", "enc", "=", "pickle", ".", "dumps", "(", "data", ")", "\n", "enc_size", "=", "len", "(", "enc", ")", "\n", "if", "enc_size", "+", "2", ">", "max_size", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "'encoded data exceeds max_size: {}'", ".", "format", "(", "enc_size", "+", "2", ")", ")", "\n", "", "assert", "max_size", "<", "255", "*", "256", "\n", "in_buffer", "[", "0", "]", "=", "enc_size", "//", "255", "# this encoding works for max_size < 65k", "\n", "in_buffer", "[", "1", "]", "=", "enc_size", "%", "255", "\n", "in_buffer", "[", "2", ":", "enc_size", "+", "2", "]", "=", "torch", ".", "ByteTensor", "(", "list", "(", "enc", ")", ")", "\n", "\n", "torch", ".", "distributed", ".", "all_gather", "(", "out_buffers", ",", "in_buffer", ".", "cuda", "(", ")", ")", "\n", "\n", "results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "world_size", ")", ":", "\n", "        ", "out_buffer", "=", "out_buffers", "[", "i", "]", "\n", "size", "=", "(", "255", "*", "out_buffer", "[", "0", "]", ".", "item", "(", ")", ")", "+", "out_buffer", "[", "1", "]", ".", "item", "(", ")", "\n", "\n", "bytes_list", "=", "bytes", "(", "out_buffer", "[", "2", ":", "size", "+", "2", "]", ".", "tolist", "(", ")", ")", "\n", "result", "=", "pickle", ".", "loads", "(", "bytes_list", ")", "\n", "results", ".", "append", "(", "result", ")", "\n", "", "return", "results", "\n", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.report_manager.ReportMgrBase.__init__": [[37, 47], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "report_every", ",", "start_time", "=", "-", "1.", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            report_every(int): Report status every this many sentences\n            start_time(float): manually set report start time. Negative values\n                means that you will need to set it later or use `start()`\n        \"\"\"", "\n", "self", ".", "report_every", "=", "report_every", "\n", "self", ".", "progress_step", "=", "0", "\n", "self", ".", "start_time", "=", "start_time", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.report_manager.ReportMgrBase.start": [[48, 50], ["time.time"], "methods", ["None"], ["", "def", "start", "(", "self", ")", ":", "\n", "        ", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.report_manager.ReportMgrBase.log": [[51, 53], ["onmt.utils.logging.logger.info"], "methods", ["None"], ["", "def", "log", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "logger", ".", "info", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.report_manager.ReportMgrBase.report_training": [[54, 82], ["ValueError", "report_manager.ReportMgrBase._report_training", "onmt.utils.Statistics", "onmt.utils.Statistics.all_gather_stats"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.report_manager.ReportMgr._report_training", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.all_gather_stats"], ["", "def", "report_training", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "\n", "report_stats", ",", "multigpu", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        This is the user-defined batch-level traing progress\n        report function.\n\n        Args:\n            step(int): current step count.\n            num_steps(int): total number of batches.\n            learning_rate(float): current learning rate.\n            report_stats(Statistics): old Statistics instance.\n        Returns:\n            report_stats(Statistics): updated Statistics instance.\n        \"\"\"", "\n", "if", "self", ".", "start_time", "<", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"\"\"ReportMgr needs to be started\n                                (set 'start_time' or use 'start()'\"\"\"", ")", "\n", "\n", "", "if", "step", "%", "self", ".", "report_every", "==", "0", ":", "\n", "            ", "if", "multigpu", ":", "\n", "                ", "report_stats", "=", "onmt", ".", "utils", ".", "Statistics", ".", "all_gather_stats", "(", "report_stats", ")", "\n", "", "self", ".", "_report_training", "(", "\n", "step", ",", "num_steps", ",", "learning_rate", ",", "report_stats", ")", "\n", "self", ".", "progress_step", "+=", "1", "\n", "return", "onmt", ".", "utils", ".", "Statistics", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "report_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.report_manager.ReportMgrBase._report_training": [[83, 86], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "_report_training", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" To be overridden \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.report_manager.ReportMgrBase.report_step": [[87, 98], ["report_manager.ReportMgrBase._report_step"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.report_manager.ReportMgr._report_step"], ["", "def", "report_step", "(", "self", ",", "lr", ",", "step", ",", "train_stats", "=", "None", ",", "valid_stats", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Report stats of a step\n\n        Args:\n            train_stats(Statistics): training stats\n            valid_stats(Statistics): validation stats\n            lr(float): current learning rate\n        \"\"\"", "\n", "self", ".", "_report_step", "(", "\n", "lr", ",", "step", ",", "train_stats", "=", "train_stats", ",", "valid_stats", "=", "valid_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.report_manager.ReportMgrBase._report_step": [[99, 101], ["NotImplementedError"], "methods", ["None"], ["", "def", "_report_step", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.report_manager.ReportMgr.__init__": [[104, 116], ["report_manager.ReportMgrBase.__init__"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "report_every", ",", "start_time", "=", "-", "1.", ",", "tensorboard_writer", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        A report manager that writes statistics on standard output as well as\n        (optionally) TensorBoard\n\n        Args:\n            report_every(int): Report status every this many sentences\n            tensorboard_writer(:obj:`tensorboard.SummaryWriter`):\n                The TensorBoard Summary writer to use or None\n        \"\"\"", "\n", "super", "(", "ReportMgr", ",", "self", ")", ".", "__init__", "(", "report_every", ",", "start_time", ")", "\n", "self", ".", "tensorboard_writer", "=", "tensorboard_writer", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.report_manager.ReportMgr.maybe_log_tensorboard": [[117, 121], ["stats.log_tensorboard"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.log_tensorboard"], ["", "def", "maybe_log_tensorboard", "(", "self", ",", "stats", ",", "prefix", ",", "learning_rate", ",", "step", ")", ":", "\n", "        ", "if", "self", ".", "tensorboard_writer", "is", "not", "None", ":", "\n", "            ", "stats", ".", "log_tensorboard", "(", "\n", "prefix", ",", "self", ".", "tensorboard_writer", ",", "learning_rate", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.report_manager.ReportMgr._report_training": [[122, 138], ["onmt.utils.Statistics.output", "report_manager.ReportMgr.maybe_log_tensorboard", "onmt.utils.Statistics"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.output", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.report_manager.ReportMgr.maybe_log_tensorboard"], ["", "", "def", "_report_training", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "\n", "report_stats", ")", ":", "\n", "        ", "\"\"\"\n        See base class method `ReportMgrBase.report_training`.\n        \"\"\"", "\n", "report_stats", ".", "output", "(", "step", ",", "num_steps", ",", "\n", "learning_rate", ",", "self", ".", "start_time", ")", "\n", "\n", "# Log the progress using the number of batches on the x-axis.", "\n", "self", ".", "maybe_log_tensorboard", "(", "report_stats", ",", "\n", "\"progress\"", ",", "\n", "learning_rate", ",", "\n", "self", ".", "progress_step", ")", "\n", "report_stats", "=", "onmt", ".", "utils", ".", "Statistics", "(", ")", "\n", "\n", "return", "report_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.report_manager.ReportMgr._report_step": [[139, 160], ["report_manager.ReportMgr.log", "report_manager.ReportMgr.log", "report_manager.ReportMgr.maybe_log_tensorboard", "report_manager.ReportMgr.log", "report_manager.ReportMgr.log", "report_manager.ReportMgr.maybe_log_tensorboard", "train_stats.ppl", "train_stats.accuracy", "valid_stats.ppl", "valid_stats.accuracy"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.report_manager.ReportMgr.maybe_log_tensorboard", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.report_manager.ReportMgr.maybe_log_tensorboard", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.ppl", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.accuracy", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.ppl", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.statistics.Statistics.accuracy"], ["", "def", "_report_step", "(", "self", ",", "lr", ",", "step", ",", "train_stats", "=", "None", ",", "valid_stats", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        See base class method `ReportMgrBase.report_step`.\n        \"\"\"", "\n", "if", "train_stats", "is", "not", "None", ":", "\n", "            ", "self", ".", "log", "(", "'Train perplexity: %g'", "%", "train_stats", ".", "ppl", "(", ")", ")", "\n", "self", ".", "log", "(", "'Train accuracy: %g'", "%", "train_stats", ".", "accuracy", "(", ")", ")", "\n", "\n", "self", ".", "maybe_log_tensorboard", "(", "train_stats", ",", "\n", "\"train\"", ",", "\n", "lr", ",", "\n", "step", ")", "\n", "\n", "", "if", "valid_stats", "is", "not", "None", ":", "\n", "            ", "self", ".", "log", "(", "'Validation perplexity: %g'", "%", "valid_stats", ".", "ppl", "(", ")", ")", "\n", "self", ".", "log", "(", "'Validation accuracy: %g'", "%", "valid_stats", ".", "accuracy", "(", ")", ")", "\n", "\n", "self", ".", "maybe_log_tensorboard", "(", "valid_stats", ",", "\n", "\"valid\"", ",", "\n", "lr", ",", "\n", "step", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.report_manager.build_report_manager": [[11, 27], ["report_manager.ReportMgr", "SummaryWriter", "datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], ["def", "build_report_manager", "(", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "tensorboard", ":", "\n", "        ", "from", "tensorboardX", "import", "SummaryWriter", "\n", "tensorboard_log_dir", "=", "opt", ".", "tensorboard_log_dir", "\n", "\n", "if", "not", "opt", ".", "train_from", ":", "\n", "            ", "tensorboard_log_dir", "+=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"/%b-%d_%H-%M-%S\"", ")", "\n", "\n", "", "writer", "=", "SummaryWriter", "(", "tensorboard_log_dir", ",", "\n", "comment", "=", "\"Unmt\"", ")", "\n", "", "else", ":", "\n", "        ", "writer", "=", "None", "\n", "\n", "", "report_mgr", "=", "ReportMgr", "(", "opt", ".", "report_every", ",", "start_time", "=", "-", "1", ",", "\n", "tensorboard_writer", "=", "writer", ")", "\n", "return", "report_mgr", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.parse.ArgumentParser.__init__": [[11, 20], ["configargparse.ArgumentParser.__init__"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "config_file_parser_class", "=", "cfargparse", ".", "YAMLConfigFileParser", ",", "\n", "formatter_class", "=", "cfargparse", ".", "ArgumentDefaultsHelpFormatter", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "ArgumentParser", ",", "self", ")", ".", "__init__", "(", "\n", "config_file_parser_class", "=", "config_file_parser_class", ",", "\n", "formatter_class", "=", "formatter_class", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.parse.ArgumentParser.defaults": [[21, 29], ["cls", "callback", "cls.parse_known_args"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "defaults", "(", "cls", ",", "*", "args", ")", ":", "\n", "        ", "\"\"\"Get default arguments added to a parser by all ``*args``.\"\"\"", "\n", "dummy_parser", "=", "cls", "(", ")", "\n", "for", "callback", "in", "args", ":", "\n", "            ", "callback", "(", "dummy_parser", ")", "\n", "", "defaults", "=", "dummy_parser", ".", "parse_known_args", "(", "[", "]", ")", "[", "0", "]", "\n", "return", "defaults", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.parse.ArgumentParser.update_model_opts": [[30, 48], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "update_model_opts", "(", "cls", ",", "model_opt", ")", ":", "\n", "        ", "if", "model_opt", ".", "word_vec_size", ">", "0", ":", "\n", "            ", "model_opt", ".", "src_word_vec_size", "=", "model_opt", ".", "word_vec_size", "\n", "model_opt", ".", "tgt_word_vec_size", "=", "model_opt", ".", "word_vec_size", "\n", "\n", "", "if", "model_opt", ".", "layers", ">", "0", ":", "\n", "            ", "model_opt", ".", "enc_layers", "=", "model_opt", ".", "layers", "\n", "model_opt", ".", "dec_layers", "=", "model_opt", ".", "layers", "\n", "\n", "", "if", "model_opt", ".", "rnn_size", ">", "0", ":", "\n", "            ", "model_opt", ".", "enc_rnn_size", "=", "model_opt", ".", "rnn_size", "\n", "model_opt", ".", "dec_rnn_size", "=", "model_opt", ".", "rnn_size", "\n", "\n", "", "model_opt", ".", "brnn", "=", "model_opt", ".", "encoder_type", "==", "\"brnn\"", "\n", "\n", "if", "model_opt", ".", "copy_attn_type", "is", "None", ":", "\n", "            ", "model_opt", ".", "copy_attn_type", "=", "model_opt", ".", "global_attention", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.parse.ArgumentParser.validate_model_opts": [[49, 69], ["onmt.utils.logging.logger.warning", "AssertionError"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "validate_model_opts", "(", "cls", ",", "model_opt", ")", ":", "\n", "        ", "assert", "model_opt", ".", "model_type", "in", "[", "\"text\"", ",", "\"img\"", ",", "\"audio\"", "]", ",", "\"Unsupported model type %s\"", "%", "model_opt", ".", "model_type", "\n", "\n", "# this check is here because audio allows the encoder and decoder to", "\n", "# be different sizes, but other model types do not yet", "\n", "same_size", "=", "model_opt", ".", "enc_rnn_size", "==", "model_opt", ".", "dec_rnn_size", "\n", "assert", "model_opt", ".", "model_type", "==", "'audio'", "or", "same_size", ",", "\"The encoder and decoder rnns must be the same size for now\"", "\n", "\n", "assert", "model_opt", ".", "rnn_type", "!=", "\"SRU\"", "or", "model_opt", ".", "gpu_ranks", ",", "\"Using SRU requires -gpu_ranks set.\"", "\n", "if", "model_opt", ".", "share_embeddings", ":", "\n", "            ", "if", "model_opt", ".", "model_type", "!=", "\"text\"", ":", "\n", "                ", "raise", "AssertionError", "(", "\n", "\"--share_embeddings requires --model_type text.\"", ")", "\n", "", "", "if", "model_opt", ".", "model_dtype", "==", "\"fp16\"", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"FP16 is experimental, the generated checkpoints may \"", "\n", "\"be incompatible with a future version\"", ")", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.parse.ArgumentParser.ckpt_model_opts": [[71, 79], ["cls.defaults", "cls.defaults.__dict__.update"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.parse.ArgumentParser.defaults", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.update"], ["", "", "@", "classmethod", "\n", "def", "ckpt_model_opts", "(", "cls", ",", "ckpt_opt", ")", ":", "\n", "# Load default opt values, then overwrite with the opts in", "\n", "# the checkpoint. That way, if there are new options added,", "\n", "# the defaults are used.", "\n", "        ", "opt", "=", "cls", ".", "defaults", "(", "opts", ".", "model_opts", ")", "\n", "opt", ".", "__dict__", ".", "update", "(", "ckpt_opt", ".", "__dict__", ")", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.parse.ArgumentParser.validate_train_opts": [[80, 93], ["AssertionError", "AssertionError", "AssertionError", "torch.cuda.is_available", "onmt.utils.logging.logger.info"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "validate_train_opts", "(", "cls", ",", "opt", ")", ":", "\n", "        ", "if", "opt", ".", "epochs", ":", "\n", "            ", "raise", "AssertionError", "(", "\n", "\"-epochs is deprecated please use -train_steps.\"", ")", "\n", "", "if", "opt", ".", "truncated_decoder", ">", "0", "and", "opt", ".", "accum_count", ">", "1", ":", "\n", "            ", "raise", "AssertionError", "(", "\"BPTT is not compatible with -accum > 1\"", ")", "\n", "", "if", "opt", ".", "gpuid", ":", "\n", "            ", "raise", "AssertionError", "(", "\"gpuid is deprecated \\\n                  see world_size and gpu_ranks\"", ")", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "opt", ".", "gpu_ranks", ":", "\n", "            ", "logger", ".", "info", "(", "\"WARNING: You have a CUDA device, \\\n                        should run with -gpu_ranks\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.parse.ArgumentParser.validate_translate_opts": [[94, 98], ["ValueError"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "validate_translate_opts", "(", "cls", ",", "opt", ")", ":", "\n", "        ", "if", "opt", ".", "beam_size", "!=", "1", "and", "opt", ".", "random_sampling_topk", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "'Can either do beam search OR random sampling.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.parse.ArgumentParser.validate_preprocess_args": [[99, 116], ["os.path.isfile", "os.path.isfile", "os.path.isfile", "os.path.isfile"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "validate_preprocess_args", "(", "cls", ",", "opt", ")", ":", "\n", "        ", "assert", "opt", ".", "max_shard_size", "==", "0", ",", "\"-max_shard_size is deprecated. Please use \\\n            -shard_size (number of examples) instead.\"", "\n", "assert", "opt", ".", "shuffle", "==", "0", ",", "\"-shuffle is not implemented. Please shuffle \\\n            your data before pre-processing.\"", "\n", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "opt", ".", "train_src", ")", "and", "os", ".", "path", ".", "isfile", "(", "opt", ".", "train_tgt", ")", ",", "\"Please check path of your train src and tgt files!\"", "\n", "\n", "assert", "not", "opt", ".", "valid_src", "or", "os", ".", "path", ".", "isfile", "(", "opt", ".", "valid_src", ")", ",", "\"Please check path of your valid src file!\"", "\n", "assert", "not", "opt", ".", "valid_tgt", "or", "os", ".", "path", ".", "isfile", "(", "opt", ".", "valid_tgt", ")", ",", "\"Please check path of your valid tgt file!\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.LossComputeBase.__init__": [[78, 82], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "criterion", ",", "generator", ")", ":", "\n", "        ", "super", "(", "LossComputeBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "criterion", "=", "criterion", "\n", "self", ".", "generator", "=", "generator", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.LossComputeBase.padding_idx": [[83, 86], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "padding_idx", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "criterion", ".", "ignore_index", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.LossComputeBase._make_shard_state": [[87, 100], ["None"], "methods", ["None"], ["", "def", "_make_shard_state", "(", "self", ",", "batch", ",", "output", ",", "range_", ",", "attns", "=", "None", ",", "scales", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Make shard state dictionary for shards() to return iterable\n        shards for efficient loss computation. Subclass must define\n        this method to match its own _compute_loss() interface.\n        Args:\n            batch: the current batch.\n            output: the predict output from the model.\n            range_: the range of examples for computing, the whole\n                    batch or a trunc of it?\n            attns: the attns dictionary returned from the model.\n        \"\"\"", "\n", "return", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.LossComputeBase._compute_loss": [[101, 113], ["None"], "methods", ["None"], ["", "def", "_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "target", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Compute the loss. Subclass must define this method.\n\n        Args:\n\n            batch: the current batch.\n            output: the predict output from the model.\n            target: the validate target to compare output with.\n            **kwargs(optional): additional info for computing loss.\n        \"\"\"", "\n", "return", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.LossComputeBase.__call__": [[114, 164], ["loss.LossComputeBase._make_shard_state", "onmt.utils.Statistics", "loss.shards", "loss.LossComputeBase._compute_loss", "loss.LossComputeBase._compute_loss", "loss.div().backward", "onmt.utils.Statistics.update", "batch.tgt.size", "float", "loss.div", "float"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.copy_generator.CopyGeneratorLossCompute._make_shard_state", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.shards", "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.copy_generator.CopyGeneratorLossCompute._compute_loss", "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.copy_generator.CopyGeneratorLossCompute._compute_loss", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.update"], ["", "def", "__call__", "(", "self", ",", "\n", "batch", ",", "\n", "output", ",", "\n", "attns", ",", "\n", "normalization", "=", "1.0", ",", "\n", "shard_size", "=", "0", ",", "\n", "trunc_start", "=", "0", ",", "\n", "trunc_size", "=", "None", ",", "\n", "retain_graph", "=", "False", ",", "\n", "scales", "=", "None", ")", ":", "\n", "        ", "\"\"\"Compute the forward loss, possibly in shards in which case this\n        method also runs the backward pass and returns ``None`` as the loss\n        value.\n\n        Also supports truncated BPTT for long sequences by taking a\n        range in the decoder output sequence to back propagate in.\n        Range is from `(trunc_start, trunc_start + trunc_size)`.\n\n        Note sharding is an exact efficiency trick to relieve memory\n        required for the generation buffers. Truncation is an\n        approximate efficiency trick to relieve the memory required\n        in the RNN buffers.\n\n        Args:\n          batch (batch) : batch of labeled examples\n          output (:obj:`FloatTensor`) :\n              output of decoder model `[tgt_len x batch x hidden]`\n          attns (dict) : dictionary of attention distributions\n              `[tgt_len x batch x src_len]`\n          normalization: Optional normalization factor.\n          shard_size (int) : maximum number of examples in a shard\n          trunc_start (int) : starting position of truncation window\n          trunc_size (int) : length of truncation window\n\n        Returns:\n            A tuple with the loss and a :obj:`onmt.utils.Statistics` instance.\n        \"\"\"", "\n", "if", "trunc_size", "is", "None", ":", "\n", "            ", "trunc_size", "=", "batch", ".", "tgt", ".", "size", "(", "0", ")", "-", "trunc_start", "\n", "", "trunc_range", "=", "(", "trunc_start", ",", "trunc_start", "+", "trunc_size", ")", "\n", "shard_state", "=", "self", ".", "_make_shard_state", "(", "batch", ",", "output", ",", "trunc_range", ",", "attns", ",", "scales", ")", "\n", "if", "shard_size", "==", "0", ":", "\n", "            ", "loss", ",", "stats", "=", "self", ".", "_compute_loss", "(", "batch", ",", "**", "shard_state", ")", "\n", "return", "loss", "/", "float", "(", "normalization", ")", ",", "stats", "\n", "", "batch_stats", "=", "onmt", ".", "utils", ".", "Statistics", "(", ")", "\n", "for", "shard", "in", "shards", "(", "shard_state", ",", "shard_size", ",", "retain_graph", "=", "retain_graph", ")", ":", "\n", "            ", "loss", ",", "stats", "=", "self", ".", "_compute_loss", "(", "batch", ",", "**", "shard", ")", "\n", "loss", ".", "div", "(", "float", "(", "normalization", ")", ")", ".", "backward", "(", ")", "\n", "batch_stats", ".", "update", "(", "stats", ")", "\n", "", "return", "None", ",", "batch_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.LossComputeBase._stats": [[165, 180], ["target.ne", "pred.eq().masked_select().sum().item", "target.ne.sum().item", "onmt.utils.Statistics", "scores.max", "loss.item", "pred.eq().masked_select().sum", "target.ne.sum", "pred.eq().masked_select", "pred.eq"], "methods", ["None"], ["", "def", "_stats", "(", "self", ",", "loss", ",", "scores", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            loss (:obj:`FloatTensor`): the loss computed by the loss criterion.\n            scores (:obj:`FloatTensor`): a score for each possible output\n            target (:obj:`FloatTensor`): true targets\n\n        Returns:\n            :obj:`onmt.utils.Statistics` : statistics for this batch.\n        \"\"\"", "\n", "pred", "=", "scores", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "non_padding", "=", "target", ".", "ne", "(", "self", ".", "padding_idx", ")", "\n", "num_correct", "=", "pred", ".", "eq", "(", "target", ")", ".", "masked_select", "(", "non_padding", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "num_non_padding", "=", "non_padding", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "return", "onmt", ".", "utils", ".", "Statistics", "(", "loss", ".", "item", "(", ")", ",", "num_non_padding", ",", "num_correct", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.LossComputeBase._bottle": [[181, 183], ["_v.view", "_v.size"], "methods", ["None"], ["", "def", "_bottle", "(", "self", ",", "_v", ")", ":", "\n", "        ", "return", "_v", ".", "view", "(", "-", "1", ",", "_v", ".", "size", "(", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.LossComputeBase._unbottle": [[184, 186], ["_v.view", "_v.size"], "methods", ["None"], ["", "def", "_unbottle", "(", "self", ",", "_v", ",", "batch_size", ")", ":", "\n", "        ", "return", "_v", ".", "view", "(", "-", "1", ",", "batch_size", ",", "_v", ".", "size", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.LabelSmoothingLoss.__init__": [[194, 205], ["torch.Module.__init__", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "loss.LabelSmoothingLoss.register_buffer", "torch.full.unsqueeze", "torch.full.unsqueeze", "torch.full.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "label_smoothing", ",", "tgt_vocab_size", ",", "ignore_index", "=", "-", "100", ")", ":", "\n", "        ", "assert", "0.0", "<", "label_smoothing", "<=", "1.0", "\n", "self", ".", "ignore_index", "=", "ignore_index", "\n", "super", "(", "LabelSmoothingLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "smoothing_value", "=", "label_smoothing", "/", "(", "tgt_vocab_size", "-", "2", ")", "\n", "one_hot", "=", "torch", ".", "full", "(", "(", "tgt_vocab_size", ",", ")", ",", "smoothing_value", ")", "\n", "one_hot", "[", "self", ".", "ignore_index", "]", "=", "0", "\n", "self", ".", "register_buffer", "(", "'one_hot'", ",", "one_hot", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "self", ".", "confidence", "=", "1.0", "-", "label_smoothing", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.LabelSmoothingLoss.forward": [[206, 216], ["loss.LabelSmoothingLoss.one_hot.repeat", "loss.LabelSmoothingLoss.scatter_", "loss.LabelSmoothingLoss.masked_fill_", "torch.kl_div", "torch.kl_div", "torch.kl_div", "target.size", "target.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "output", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        output (FloatTensor): batch_size x n_classes\n        target (LongTensor): batch_size\n        \"\"\"", "\n", "model_prob", "=", "self", ".", "one_hot", ".", "repeat", "(", "target", ".", "size", "(", "0", ")", ",", "1", ")", "\n", "model_prob", ".", "scatter_", "(", "1", ",", "target", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "confidence", ")", "\n", "model_prob", ".", "masked_fill_", "(", "(", "target", "==", "self", ".", "ignore_index", ")", ".", "unsqueeze", "(", "1", ")", ",", "0", ")", "\n", "\n", "return", "F", ".", "kl_div", "(", "output", ",", "model_prob", ",", "reduction", "=", "'sum'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.NMTLossCompute.__init__": [[223, 225], ["loss.LossComputeBase.__init__"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "criterion", ",", "generator", ",", "normalization", "=", "\"sents\"", ")", ":", "\n", "        ", "super", "(", "NMTLossCompute", ",", "self", ")", ".", "__init__", "(", "criterion", ",", "generator", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.NMTLossCompute._make_shard_state": [[226, 230], ["None"], "methods", ["None"], ["", "def", "_make_shard_state", "(", "self", ",", "batch", ",", "output", ",", "range_", ",", "attns", "=", "None", ",", "scales", "=", "None", ")", ":", "\n", "        ", "return", "{", "\n", "\"output\"", ":", "output", ",", "\n", "\"target\"", ":", "batch", ".", "tgt", "[", "range_", "[", "0", "]", "+", "1", ":", "range_", "[", "1", "]", ",", ":", ",", "0", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.NMTLossCompute._compute_loss": [[232, 242], ["loss.NMTLossCompute.NMTLossCompute._bottle", "loss.NMTLossCompute.NMTLossCompute.generator", "target.view", "loss.NMTLossCompute.NMTLossCompute.criterion", "loss.NMTLossCompute.NMTLossCompute._stats", "loss.NMTLossCompute.NMTLossCompute.clone"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.LossComputeBase._bottle", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.LossComputeBase._stats"], ["", "def", "_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "target", ")", ":", "\n", "        ", "bottled_output", "=", "self", ".", "_bottle", "(", "output", ")", "\n", "\n", "scores", "=", "self", ".", "generator", "(", "bottled_output", ")", "\n", "gtruth", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "\n", "loss", "=", "self", ".", "criterion", "(", "scores", ",", "gtruth", ")", "\n", "stats", "=", "self", ".", "_stats", "(", "loss", ".", "clone", "(", ")", ",", "scores", ",", "gtruth", ")", "\n", "\n", "return", "loss", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.build_loss_compute": [[15, 57], ["torch.device", "torch.device", "torch.device", "isinstance", "NMTLossCompute.to", "onmt.modules.CopyGeneratorLoss", "onmt.modules.CopyGeneratorLossCompute", "loss.NMTLossCompute", "onmt.utils.misc.use_gpu", "len", "loss.LabelSmoothingLoss", "isinstance", "len", "onmt.modules.sparse_losses.SparsemaxLoss", "torch.NLLLoss"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.use_gpu"], ["def", "build_loss_compute", "(", "model", ",", "tgt_field", ",", "opt", ",", "train", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Returns a LossCompute subclass which wraps around an nn.Module subclass\n    (such as nn.NLLLoss) which defines the loss criterion. The LossCompute\n    object allows this loss to be computed in shards and passes the relevant\n    data to a Statistics object which handles training/validation logging.\n    Currently, the NMTLossCompute class handles all loss computation except\n    for when using a copy mechanism.\n    \"\"\"", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "onmt", ".", "utils", ".", "misc", ".", "use_gpu", "(", "opt", ")", "else", "\"cpu\"", ")", "\n", "\n", "padding_idx", "=", "tgt_field", ".", "vocab", ".", "stoi", "[", "tgt_field", ".", "pad_token", "]", "\n", "unk_idx", "=", "tgt_field", ".", "vocab", ".", "stoi", "[", "tgt_field", ".", "unk_token", "]", "\n", "if", "opt", ".", "copy_attn", ":", "\n", "        ", "criterion", "=", "onmt", ".", "modules", ".", "CopyGeneratorLoss", "(", "\n", "len", "(", "tgt_field", ".", "vocab", ")", ",", "opt", ".", "copy_attn_force", ",", "\n", "unk_index", "=", "unk_idx", ",", "ignore_index", "=", "padding_idx", "\n", ")", "\n", "", "elif", "opt", ".", "label_smoothing", ">", "0", "and", "train", ":", "\n", "        ", "criterion", "=", "LabelSmoothingLoss", "(", "\n", "opt", ".", "label_smoothing", ",", "len", "(", "tgt_field", ".", "vocab", ")", ",", "ignore_index", "=", "padding_idx", "\n", ")", "\n", "", "elif", "isinstance", "(", "model", ".", "generator", "[", "-", "1", "]", ",", "LogSparsemax", ")", ":", "\n", "        ", "criterion", "=", "SparsemaxLoss", "(", "ignore_index", "=", "padding_idx", ",", "reduction", "=", "'sum'", ")", "\n", "", "else", ":", "\n", "        ", "criterion", "=", "nn", ".", "NLLLoss", "(", "ignore_index", "=", "padding_idx", ",", "reduction", "=", "'sum'", ")", "\n", "\n", "# if the loss function operates on vectors of raw logits instead of", "\n", "# probabilities, only the first part of the generator needs to be", "\n", "# passed to the NMTLossCompute. At the moment, the only supported", "\n", "# loss function of this kind is the sparsemax loss.", "\n", "", "use_raw_logits", "=", "isinstance", "(", "criterion", ",", "SparsemaxLoss", ")", "\n", "loss_gen", "=", "model", ".", "generator", "[", "0", "]", "if", "use_raw_logits", "else", "model", ".", "generator", "\n", "if", "opt", ".", "copy_attn", ":", "\n", "        ", "compute", "=", "onmt", ".", "modules", ".", "CopyGeneratorLossCompute", "(", "\n", "criterion", ",", "loss_gen", ",", "tgt_field", ".", "vocab", ",", "opt", ".", "copy_loss_by_seqlength", "\n", ")", "\n", "", "else", ":", "\n", "        ", "compute", "=", "NMTLossCompute", "(", "criterion", ",", "loss_gen", ")", "\n", "", "compute", ".", "to", "(", "device", ")", "\n", "\n", "return", "compute", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.filter_shard_state": [[244, 257], ["state.items", "isinstance", "torch.split", "torch.split", "torch.split", "v_chunk.data.clone.data.clone", "v_split.append"], "function", ["None"], ["", "", "def", "filter_shard_state", "(", "state", ",", "shard_size", "=", "None", ")", ":", "\n", "    ", "for", "k", ",", "v", "in", "state", ".", "items", "(", ")", ":", "\n", "        ", "if", "shard_size", "is", "None", ":", "\n", "            ", "yield", "k", ",", "v", "\n", "\n", "", "if", "v", "is", "not", "None", ":", "\n", "            ", "v_split", "=", "[", "]", "\n", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "for", "v_chunk", "in", "torch", ".", "split", "(", "v", ",", "shard_size", ")", ":", "\n", "                    ", "v_chunk", "=", "v_chunk", ".", "data", ".", "clone", "(", ")", "\n", "v_chunk", ".", "requires_grad", "=", "v", ".", "requires_grad", "\n", "v_split", ".", "append", "(", "v_chunk", ")", "\n", "", "", "yield", "k", ",", "(", "v", ",", "v_split", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.shards": [[259, 307], ["dict", "zip", "zip", "dict.items", "zip", "torch.autograd.backward", "torch.autograd.backward", "torch.autograd.backward", "loss.filter_shard_state", "loss.filter_shard_state", "dict", "isinstance", "variables.extend", "zip", "zip", "dict.items", "torch.split", "torch.split", "torch.split"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.filter_shard_state", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.filter_shard_state"], ["", "", "", "def", "shards", "(", "state", ",", "shard_size", ",", "eval_only", "=", "False", ",", "retain_graph", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        state: A dictionary which corresponds to the output of\n               *LossCompute._make_shard_state(). The values for\n               those keys are Tensor-like or None.\n        shard_size: The maximum size of the shards yielded by the model.\n        eval_only: If True, only yield the state, nothing else.\n              Otherwise, yield shards.\n\n    Yields:\n        Each yielded shard is a dict.\n\n    Side effect:\n        After the last shard, this function does back-propagation.\n    \"\"\"", "\n", "if", "eval_only", ":", "\n", "        ", "yield", "filter_shard_state", "(", "state", ")", "\n", "", "else", ":", "\n", "# non_none: the subdict of the state dictionary where the values", "\n", "# are not None.", "\n", "        ", "non_none", "=", "dict", "(", "filter_shard_state", "(", "state", ",", "shard_size", ")", ")", "\n", "\n", "# Now, the iteration:", "\n", "# state is a dictionary of sequences of tensor-like but we", "\n", "# want a sequence of dictionaries of tensors.", "\n", "# First, unzip the dictionary into a sequence of keys and a", "\n", "# sequence of tensor-like sequences.", "\n", "keys", ",", "values", "=", "zip", "(", "*", "(", "(", "k", ",", "[", "v_chunk", "for", "v_chunk", "in", "v_split", "]", ")", "\n", "for", "k", ",", "(", "_", ",", "v_split", ")", "in", "non_none", ".", "items", "(", ")", ")", ")", "\n", "\n", "# Now, yield a dictionary for each shard. The keys are always", "\n", "# the same. values is a sequence of length #keys where each", "\n", "# element is a sequence of length #shards. We want to iterate", "\n", "# over the shards, not over the keys: therefore, the values need", "\n", "# to be re-zipped by shard and then each shard can be paired", "\n", "# with the keys.", "\n", "for", "shard_tensors", "in", "zip", "(", "*", "values", ")", ":", "\n", "            ", "yield", "dict", "(", "zip", "(", "keys", ",", "shard_tensors", ")", ")", "\n", "\n", "# Assumed backprop'd", "\n", "", "variables", "=", "[", "]", "\n", "for", "k", ",", "(", "v", ",", "v_split", ")", "in", "non_none", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", "and", "state", "[", "k", "]", ".", "requires_grad", ":", "\n", "                ", "variables", ".", "extend", "(", "zip", "(", "torch", ".", "split", "(", "state", "[", "k", "]", ",", "shard_size", ")", ",", "\n", "[", "v_chunk", ".", "grad", "for", "v_chunk", "in", "v_split", "]", ")", ")", "\n", "", "", "inputs", ",", "grads", "=", "zip", "(", "*", "variables", ")", "\n", "torch", ".", "autograd", ".", "backward", "(", "inputs", ",", "grads", ",", "retain_graph", "=", "retain_graph", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.cnn_factory.GatedConv.__init__": [[21, 28], ["torch.Module.__init__", "onmt.modules.WeightNormConv2d", "torch.xavier_uniform_", "torch.xavier_uniform_", "torch.xavier_uniform_", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "width", "=", "3", ",", "dropout", "=", "0.2", ",", "nopad", "=", "False", ")", ":", "\n", "        ", "super", "(", "GatedConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "onmt", ".", "modules", ".", "WeightNormConv2d", "(", "\n", "input_size", ",", "2", "*", "input_size", ",", "kernel_size", "=", "(", "width", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ",", "\n", "padding", "=", "(", "width", "//", "2", "*", "(", "1", "-", "nopad", ")", ",", "0", ")", ")", "\n", "init", ".", "xavier_uniform_", "(", "self", ".", "conv", ".", "weight", ",", "gain", "=", "(", "4", "*", "(", "1", "-", "dropout", ")", ")", "**", "0.5", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.cnn_factory.GatedConv.forward": [[29, 35], ["cnn_factory.GatedConv.dropout", "cnn_factory.GatedConv.conv", "cnn_factory.GatedConv.split", "int", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "cnn_factory.GatedConv.size"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.dropout"], ["", "def", "forward", "(", "self", ",", "x_var", ")", ":", "\n", "        ", "x_var", "=", "self", ".", "dropout", "(", "x_var", ")", "\n", "x_var", "=", "self", ".", "conv", "(", "x_var", ")", "\n", "out", ",", "gate", "=", "x_var", ".", "split", "(", "int", "(", "x_var", ".", "size", "(", "1", ")", "/", "2", ")", ",", "1", ")", "\n", "out", "=", "out", "*", "torch", ".", "sigmoid", "(", "gate", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.cnn_factory.StackedCNN.__init__": [[40, 49], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "cnn_factory.StackedCNN.layers.append", "cnn_factory.GatedConv"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "cnn_kernel_width", "=", "3", ",", "\n", "dropout", "=", "0.2", ")", ":", "\n", "        ", "super", "(", "StackedCNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "\n", "GatedConv", "(", "input_size", ",", "cnn_kernel_width", ",", "dropout", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.cnn_factory.StackedCNN.forward": [[50, 55], ["conv"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "conv", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "x", "+", "conv", "(", "x", ")", "\n", "x", "*=", "SCALE_WEIGHT", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.cnn_factory.shape_transform": [[13, 16], ["torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.transpose", "torch.transpose", "torch.transpose"], "function", ["None"], ["def", "shape_transform", "(", "x", ")", ":", "\n", "    ", "\"\"\" Tranform the size of the tensors to fit for conv input. \"\"\"", "\n", "return", "torch", ".", "unsqueeze", "(", "torch", ".", "transpose", "(", "x", ",", "1", ",", "2", ")", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.rnn_factory.rnn_factory": [[8, 18], ["onmt.models.sru.SRU", "getattr"], "function", ["None"], ["def", "rnn_factory", "(", "rnn_type", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" rnn factory, Use pytorch version when available. \"\"\"", "\n", "no_pack_padded_seq", "=", "False", "\n", "if", "rnn_type", "==", "\"SRU\"", ":", "\n", "# SRU doesn't support PackedSequence.", "\n", "        ", "no_pack_padded_seq", "=", "True", "\n", "rnn", "=", "onmt", ".", "models", ".", "sru", ".", "SRU", "(", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "rnn", "=", "getattr", "(", "nn", ",", "rnn_type", ")", "(", "**", "kwargs", ")", "\n", "", "return", "rnn", ",", "no_pack_padded_seq", "\n", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.split_corpus": [[9, 19], ["open", "f.readlines", "list", "itertools.islice"], "function", ["None"], ["def", "split_corpus", "(", "path", ",", "shard_size", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "if", "shard_size", "<=", "0", ":", "\n", "            ", "yield", "f", ".", "readlines", "(", ")", "\n", "", "else", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "shard", "=", "list", "(", "islice", "(", "f", ",", "shard_size", ")", ")", "\n", "if", "not", "shard", ":", "\n", "                    ", "break", "\n", "", "yield", "shard", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq": [[21, 29], ["next", "all", "str"], "function", ["None"], ["", "", "", "", "def", "aeq", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"\n    Assert all arguments have the same value\n    \"\"\"", "\n", "arguments", "=", "(", "arg", "for", "arg", "in", "args", ")", "\n", "first", "=", "next", "(", "arguments", ")", "\n", "assert", "all", "(", "arg", "==", "first", "for", "arg", "in", "arguments", ")", ",", "\"Not all arguments have the same value: \"", "+", "str", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.sequence_mask": [[31, 41], ["lengths.numel", "torch.arange().type_as().repeat().lt", "lengths.max", "lengths.unsqueeze", "torch.arange().type_as().repeat", "torch.arange().type_as", "torch.arange"], "function", ["None"], ["", "def", "sequence_mask", "(", "lengths", ",", "max_len", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Creates a boolean mask from sequence lengths.\n    \"\"\"", "\n", "batch_size", "=", "lengths", ".", "numel", "(", ")", "\n", "max_len", "=", "max_len", "or", "lengths", ".", "max", "(", ")", "\n", "return", "(", "torch", ".", "arange", "(", "0", ",", "max_len", ")", "\n", ".", "type_as", "(", "lengths", ")", "\n", ".", "repeat", "(", "batch_size", ",", "1", ")", "\n", ".", "lt", "(", "lengths", ".", "unsqueeze", "(", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.tile": [[43, 63], ["list", "list", "x.permute().contiguous.size", "x.permute().contiguous.view().transpose().repeat().transpose().contiguous().view", "range", "x.permute().contiguous.permute().contiguous", "x.permute().contiguous.size", "x.permute().contiguous.permute().contiguous", "len", "x.permute().contiguous.view().transpose().repeat().transpose().contiguous", "x.permute().contiguous.size", "x.permute().contiguous.permute", "x.permute().contiguous.permute", "x.permute().contiguous.view().transpose().repeat().transpose", "x.permute().contiguous.view().transpose().repeat", "x.permute().contiguous.view().transpose", "x.permute().contiguous.view"], "function", ["None"], ["", "def", "tile", "(", "x", ",", "count", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Tiles x on dimension dim count times.\n    \"\"\"", "\n", "perm", "=", "list", "(", "range", "(", "len", "(", "x", ".", "size", "(", ")", ")", ")", ")", "\n", "if", "dim", "!=", "0", ":", "\n", "        ", "perm", "[", "0", "]", ",", "perm", "[", "dim", "]", "=", "perm", "[", "dim", "]", ",", "perm", "[", "0", "]", "\n", "x", "=", "x", ".", "permute", "(", "perm", ")", ".", "contiguous", "(", ")", "\n", "", "out_size", "=", "list", "(", "x", ".", "size", "(", ")", ")", "\n", "out_size", "[", "0", "]", "*=", "count", "\n", "batch", "=", "x", ".", "size", "(", "0", ")", "\n", "x", "=", "x", ".", "view", "(", "batch", ",", "-", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "repeat", "(", "count", ",", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "*", "out_size", ")", "\n", "if", "dim", "!=", "0", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "perm", ")", ".", "contiguous", "(", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.use_gpu": [[65, 71], ["hasattr", "hasattr", "len"], "function", ["None"], ["", "def", "use_gpu", "(", "opt", ")", ":", "\n", "    ", "\"\"\"\n    Creates a boolean if gpu used\n    \"\"\"", "\n", "return", "(", "hasattr", "(", "opt", ",", "'gpu_ranks'", ")", "and", "len", "(", "opt", ".", "gpu_ranks", ")", ">", "0", ")", "or", "(", "hasattr", "(", "opt", ",", "'gpu'", ")", "and", "opt", ".", "gpu", ">", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.set_random_seed": [[73, 87], ["torch.manual_seed", "random.seed", "torch.cuda.manual_seed"], "function", ["None"], ["", "def", "set_random_seed", "(", "seed", ",", "is_cuda", ")", ":", "\n", "    ", "\"\"\"Sets the random seed.\"\"\"", "\n", "if", "seed", ">", "0", ":", "\n", "        ", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "# this one is needed for torchtext random call (shuffled iterator)", "\n", "# in multi gpu it ensures datasets are read in the same order", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "# some cudnn methods can be random even after fixing the seed", "\n", "# unless you tell it to be deterministic", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n", "", "if", "is_cuda", "and", "seed", ">", "0", ":", "\n", "# These ensure same initialization in multi gpu mode", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.generate_relative_positions_matrix": [[89, 105], ["torch.clamp", "torch.arange().unsqueeze", "torch.arange", "torch.arange.unsqueeze().expand().transpose", "range_vec.unsqueeze().expand().transpose.transpose", "torch.arange", "torch.arange.unsqueeze().expand", "torch.arange.unsqueeze"], "function", ["None"], ["", "", "def", "generate_relative_positions_matrix", "(", "length", ",", "max_relative_positions", ",", "\n", "cache", "=", "False", ")", ":", "\n", "    ", "\"\"\"Generate the clipped relative positions matrix\n       for a given length and maximum relative positions\"\"\"", "\n", "if", "cache", ":", "\n", "        ", "distance_mat", "=", "torch", ".", "arange", "(", "-", "length", "+", "1", ",", "1", ",", "1", ")", ".", "unsqueeze", "(", "0", ")", "\n", "", "else", ":", "\n", "        ", "range_vec", "=", "torch", ".", "arange", "(", "length", ")", "\n", "range_mat", "=", "range_vec", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "length", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "distance_mat", "=", "range_mat", "-", "range_mat", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "distance_mat_clipped", "=", "torch", ".", "clamp", "(", "distance_mat", ",", "\n", "min", "=", "-", "max_relative_positions", ",", "\n", "max", "=", "max_relative_positions", ")", "\n", "# Shift values to be >= 0", "\n", "final_mat", "=", "distance_mat_clipped", "+", "max_relative_positions", "\n", "return", "final_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.relative_matmul": [[107, 122], ["x.permute", "x.permute.reshape", "torch.matmul.reshape", "x_tz_matmul.reshape.permute", "z.transpose", "torch.matmul", "torch.matmul"], "function", ["None"], ["", "def", "relative_matmul", "(", "x", ",", "z", ",", "transpose", ")", ":", "\n", "    ", "\"\"\"Helper function for relative positions attention.\"\"\"", "\n", "batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "heads", "=", "x", ".", "shape", "[", "1", "]", "\n", "length", "=", "x", ".", "shape", "[", "2", "]", "\n", "x_t", "=", "x", ".", "permute", "(", "2", ",", "0", ",", "1", ",", "3", ")", "\n", "x_t_r", "=", "x_t", ".", "reshape", "(", "length", ",", "heads", "*", "batch_size", ",", "-", "1", ")", "\n", "if", "transpose", ":", "\n", "        ", "z_t", "=", "z", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x_tz_matmul", "=", "torch", ".", "matmul", "(", "x_t_r", ",", "z_t", ")", "\n", "", "else", ":", "\n", "        ", "x_tz_matmul", "=", "torch", ".", "matmul", "(", "x_t_r", ",", "z", ")", "\n", "", "x_tz_matmul_r", "=", "x_tz_matmul", ".", "reshape", "(", "length", ",", "batch_size", ",", "heads", ",", "-", "1", ")", "\n", "x_tz_matmul_r_t", "=", "x_tz_matmul_r", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ")", "\n", "return", "x_tz_matmul_r_t", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.fn_args": [[124, 127], ["inspect.getfullargspec"], "function", ["None"], ["", "def", "fn_args", "(", "fun", ")", ":", "\n", "    ", "\"\"\"Returns the list of function arguments name.\"\"\"", "\n", "return", "inspect", ".", "getfullargspec", "(", "fun", ")", ".", "args", "\n", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.MultipleOptimizer.__init__": [[146, 149], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "op", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "self", ".", "optimizers", "=", "op", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.MultipleOptimizer.param_groups": [[150, 156], ["param_groups.extend"], "methods", ["None"], ["", "@", "property", "\n", "def", "param_groups", "(", "self", ")", ":", "\n", "        ", "param_groups", "=", "[", "]", "\n", "for", "optimizer", "in", "self", ".", "optimizers", ":", "\n", "            ", "param_groups", ".", "extend", "(", "optimizer", ".", "param_groups", ")", "\n", "", "return", "param_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.MultipleOptimizer.zero_grad": [[157, 161], ["op.zero_grad"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.zero_grad"], ["", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "for", "op", "in", "self", ".", "optimizers", ":", "\n", "            ", "op", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.MultipleOptimizer.step": [[162, 166], ["op.step"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.AdaFactor.step"], ["", "", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "for", "op", "in", "self", ".", "optimizers", ":", "\n", "            ", "op", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.MultipleOptimizer.state": [[167, 171], ["op.state.items"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "state", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "return", "{", "k", ":", "v", "for", "op", "in", "self", ".", "optimizers", "for", "k", ",", "v", "in", "op", ".", "state", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.MultipleOptimizer.state_dict": [[172, 175], ["op.state_dict"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "return", "[", "op", ".", "state_dict", "(", ")", "for", "op", "in", "self", ".", "optimizers", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.MultipleOptimizer.load_state_dict": [[176, 181], ["range", "len", "len", "len", "optimizers.MultipleOptimizer.optimizers[].load_state_dict"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dicts", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "assert", "len", "(", "state_dicts", ")", "==", "len", "(", "self", ".", "optimizers", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "state_dicts", ")", ")", ":", "\n", "            ", "self", ".", "optimizers", "[", "i", "]", ".", "load_state_dict", "(", "state_dicts", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.__init__": [[192, 216], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "optimizer", ",", "\n", "learning_rate", ",", "\n", "learning_rate_rl", ",", "\n", "learning_rate_decay_fn", "=", "None", ",", "\n", "max_grad_norm", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initializes the controller.\n\n       Args:\n         optimizer: A ``torch.optim.Optimizer`` instance.\n         learning_rate: The initial learning rate.\n         learning_rate_decay_fn: An optional callable taking the current step\n           as argument and return a learning rate scaling factor.\n         max_grad_norm: Clip gradients to this global norm.\n        \"\"\"", "\n", "self", ".", "_optimizer", "=", "optimizer", "\n", "self", ".", "_learning_rate", "=", "learning_rate", "\n", "self", ".", "_learning_rate_rl", "=", "learning_rate_rl", "\n", "self", ".", "_learning_rate_decay_fn", "=", "learning_rate_decay_fn", "\n", "self", ".", "_max_grad_norm", "=", "max_grad_norm", "or", "0", "\n", "self", ".", "_training_step", "=", "1", "\n", "self", ".", "_decay_step", "=", "1", "\n", "self", ".", "_with_fp16_wrapper", "=", "(", "\n", "optimizer", ".", "__class__", ".", "__name__", "==", "\"FP16_Optimizer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.from_opt": [[217, 273], ["cls", "isinstance", "optimizers.build_torch_optimizer", "torch.optimizer.state_dict", "torch.optimizer.state_dict", "optimizers.make_learning_rate_decay_fn", "cls.load_state_dict", "print"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.build_torch_optimizer", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.state_dict", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.state_dict", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.make_learning_rate_decay_fn", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.load_state_dict"], ["", "@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "model", ",", "opt", ",", "checkpoint", "=", "None", ")", ":", "\n", "        ", "\"\"\"Builds the optimizer from options.\n\n        Args:\n          cls: The ``Optimizer`` class to instantiate.\n          model: The model to optimize.\n          opt: The dict of user options.\n          checkpoint: An optional checkpoint to load states from.\n\n        Returns:\n          An ``Optimizer`` instance.\n        \"\"\"", "\n", "optim_opt", "=", "opt", "\n", "optim_state_dict", "=", "None", "\n", "\n", "if", "opt", ".", "train_from", "and", "checkpoint", "is", "not", "None", ":", "\n", "            ", "optim", "=", "checkpoint", "[", "'optim'", "]", "\n", "ckpt_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "ckpt_state_dict", "=", "{", "}", "\n", "if", "isinstance", "(", "optim", ",", "Optimizer", ")", ":", "# Backward compatibility.", "\n", "                ", "ckpt_state_dict", "[", "'training_step'", "]", "=", "optim", ".", "_step", "+", "1", "\n", "ckpt_state_dict", "[", "'decay_step'", "]", "=", "optim", ".", "_step", "+", "1", "\n", "ckpt_state_dict", "[", "'optimizer'", "]", "=", "optim", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "", "else", ":", "\n", "                ", "ckpt_state_dict", "=", "optim", "\n", "\n", "", "if", "opt", ".", "reset_optim", "==", "'none'", ":", "\n", "# Load everything from the checkpoint.", "\n", "                ", "optim_opt", "=", "ckpt_opt", "\n", "optim_state_dict", "=", "ckpt_state_dict", "\n", "", "elif", "opt", ".", "reset_optim", "==", "'all'", ":", "\n", "# Build everything from scratch.", "\n", "                ", "pass", "\n", "", "elif", "opt", ".", "reset_optim", "==", "'states'", ":", "\n", "# Reset optimizer, keep options.", "\n", "                ", "optim_opt", "=", "ckpt_opt", "\n", "optim_state_dict", "=", "ckpt_state_dict", "\n", "del", "optim_state_dict", "[", "'optimizer'", "]", "\n", "", "elif", "opt", ".", "reset_optim", "==", "'keep_states'", ":", "\n", "# Reset options, keep optimizer.", "\n", "                ", "optim_state_dict", "=", "ckpt_state_dict", "\n", "\n", "", "", "optimizer", "=", "cls", "(", "\n", "build_torch_optimizer", "(", "model", ",", "optim_opt", ")", ",", "\n", "optim_opt", ".", "learning_rate", ",", "\n", "optim_opt", ".", "learning_rate_rl", ",", "\n", "learning_rate_decay_fn", "=", "make_learning_rate_decay_fn", "(", "optim_opt", ")", ",", "\n", "max_grad_norm", "=", "optim_opt", ".", "max_grad_norm", ")", "\n", "if", "optim_state_dict", ":", "\n", "            ", "try", ":", "\n", "                ", "optimizer", ".", "load_state_dict", "(", "optim_state_dict", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "\"load optimizer error, build optimizer from begining\"", ")", "\n", "\n", "", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.training_step": [[274, 278], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "training_step", "(", "self", ")", ":", "\n", "        ", "\"\"\"The current training step.\"\"\"", "\n", "return", "self", ".", "_training_step", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.learning_rate": [[279, 287], ["optimizers.Optimizer._learning_rate_decay_fn"], "methods", ["None"], ["", "def", "learning_rate", "(", "self", ",", "rl", "=", "False", ")", ":", "\n", "        ", "\"\"\"Returns the current learning rate.\"\"\"", "\n", "if", "rl", ":", "\n", "            ", "self", ".", "_learning_rate", "=", "self", ".", "_learning_rate_rl", "\n", "", "if", "self", ".", "_learning_rate_decay_fn", "is", "None", ":", "\n", "            ", "return", "self", ".", "_learning_rate", "\n", "", "scale", "=", "self", ".", "_learning_rate_decay_fn", "(", "self", ".", "_decay_step", ")", "\n", "return", "scale", "*", "self", ".", "_learning_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.state_dict": [[290, 295], ["optimizers.Optimizer._optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "'training_step'", ":", "self", ".", "_training_step", ",", "\n", "'decay_step'", ":", "self", ".", "_decay_step", ",", "\n", "'optimizer'", ":", "self", ".", "_optimizer", ".", "state_dict", "(", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.load_state_dict": [[297, 304], ["optimizers.Optimizer._optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "_training_step", "=", "state_dict", "[", "'training_step'", "]", "\n", "# State can be partially restored.", "\n", "if", "'decay_step'", "in", "state_dict", ":", "\n", "            ", "self", ".", "_decay_step", "=", "state_dict", "[", "'decay_step'", "]", "\n", "", "if", "'optimizer'", "in", "state_dict", ":", "\n", "            ", "self", ".", "_optimizer", ".", "load_state_dict", "(", "state_dict", "[", "'optimizer'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.zero_grad": [[305, 308], ["optimizers.Optimizer._optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.zero_grad"], ["", "", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\"Zero the gradients of optimized parameters.\"\"\"", "\n", "self", ".", "_optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.backward": [[309, 319], ["optimizers.Optimizer._optimizer.backward", "loss.backward", "onmt.utils.misc.fn_args"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.fn_args"], ["", "def", "backward", "(", "self", ",", "loss", ")", ":", "\n", "        ", "\"\"\"Wrapper for backward pass. Some optimizer requires ownership of the\n        backward pass.\"\"\"", "\n", "if", "self", ".", "_with_fp16_wrapper", ":", "\n", "            ", "kwargs", "=", "{", "}", "\n", "if", "\"update_master_grads\"", "in", "fn_args", "(", "self", ".", "_optimizer", ".", "backward", ")", ":", "\n", "                ", "kwargs", "[", "\"update_master_grads\"", "]", "=", "True", "\n", "", "self", ".", "_optimizer", ".", "backward", "(", "loss", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.step": [[320, 340], ["optimizers.Optimizer.learning_rate", "optimizers.Optimizer._optimizer.step", "hasattr", "optimizers.Optimizer._optimizer.update_master_grads", "hasattr", "optimizers.Optimizer._optimizer.clip_master_grads", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.learning_rate", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.AdaFactor.step"], ["", "", "def", "step", "(", "self", ",", "rl", "=", "False", ")", ":", "\n", "        ", "\"\"\"Update the model parameters based on current gradients.\n\n        Optionally, will employ gradient modification or update learning\n        rate.\n        \"\"\"", "\n", "learning_rate", "=", "self", ".", "learning_rate", "(", "rl", ")", "\n", "if", "self", ".", "_with_fp16_wrapper", ":", "\n", "            ", "if", "hasattr", "(", "self", ".", "_optimizer", ",", "\"update_master_grads\"", ")", ":", "\n", "                ", "self", ".", "_optimizer", ".", "update_master_grads", "(", ")", "\n", "", "if", "hasattr", "(", "self", ".", "_optimizer", ",", "\"clip_master_grads\"", ")", "and", "self", ".", "_max_grad_norm", ">", "0", ":", "\n", "                ", "self", ".", "_optimizer", ".", "clip_master_grads", "(", "self", ".", "_max_grad_norm", ")", "\n", "", "", "for", "group", "in", "self", ".", "_optimizer", ".", "param_groups", ":", "\n", "            ", "group", "[", "'lr'", "]", "=", "learning_rate", "\n", "if", "not", "self", ".", "_with_fp16_wrapper", "and", "self", ".", "_max_grad_norm", ">", "0", ":", "\n", "                ", "clip_grad_norm_", "(", "group", "[", "'params'", "]", ",", "self", ".", "_max_grad_norm", ")", "\n", "", "", "self", ".", "_optimizer", ".", "step", "(", ")", "\n", "self", ".", "_decay_step", "+=", "1", "\n", "self", ".", "_training_step", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.AdaFactor.__init__": [[347, 364], ["dict", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "None", ",", "beta1", "=", "0.9", ",", "beta2", "=", "0.999", ",", "eps1", "=", "1e-30", ",", "\n", "eps2", "=", "1e-3", ",", "cliping_threshold", "=", "1", ",", "non_constant_decay", "=", "True", ",", "\n", "enable_factorization", "=", "True", ",", "ams_grad", "=", "True", ",", "weight_decay", "=", "0", ")", ":", "\n", "\n", "        ", "enable_momentum", "=", "beta1", "!=", "0", "\n", "\n", "if", "non_constant_decay", ":", "\n", "            ", "ams_grad", "=", "False", "\n", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "beta1", "=", "beta1", ",", "beta2", "=", "beta2", ",", "eps1", "=", "eps1", ",", "\n", "eps2", "=", "eps2", ",", "cliping_threshold", "=", "cliping_threshold", ",", "\n", "weight_decay", "=", "weight_decay", ",", "ams_grad", "=", "ams_grad", ",", "\n", "enable_factorization", "=", "enable_factorization", ",", "\n", "enable_momentum", "=", "enable_momentum", ",", "\n", "non_constant_decay", "=", "non_constant_decay", ")", "\n", "\n", "super", "(", "AdaFactor", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.AdaFactor.__setstate__": [[365, 367], ["super().__setstate__"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.AdaFactor.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", "AdaFactor", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.AdaFactor._experimental_reshape": [[368, 379], ["len", "copy.copy.copy", "len", "len", "functools.reduce", "functools.reduce"], "methods", ["None"], ["", "def", "_experimental_reshape", "(", "self", ",", "shape", ")", ":", "\n", "        ", "temp_shape", "=", "shape", "[", "2", ":", "]", "\n", "if", "len", "(", "temp_shape", ")", "==", "1", ":", "\n", "            ", "new_shape", "=", "(", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", "*", "shape", "[", "2", "]", ")", "\n", "", "else", ":", "\n", "            ", "tmp_div", "=", "len", "(", "temp_shape", ")", "//", "2", "+", "len", "(", "temp_shape", ")", "%", "2", "\n", "new_shape", "=", "(", "shape", "[", "0", "]", "*", "functools", ".", "reduce", "(", "operator", ".", "mul", ",", "\n", "temp_shape", "[", "tmp_div", ":", "]", ",", "1", ")", ",", "\n", "shape", "[", "1", "]", "*", "functools", ".", "reduce", "(", "operator", ".", "mul", ",", "\n", "temp_shape", "[", ":", "tmp_div", "]", ",", "1", ")", ")", "\n", "", "return", "new_shape", ",", "copy", "(", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.AdaFactor._check_shape": [[380, 393], ["len", "len", "len"], "methods", ["None"], ["", "def", "_check_shape", "(", "self", ",", "shape", ")", ":", "\n", "        ", "'''\n        output1 - True - algorithm for matrix, False - vector;\n        output2 - need reshape\n        '''", "\n", "if", "len", "(", "shape", ")", ">", "2", ":", "\n", "            ", "return", "True", ",", "True", "\n", "", "elif", "len", "(", "shape", ")", "==", "2", ":", "\n", "            ", "return", "True", ",", "False", "\n", "", "elif", "len", "(", "shape", ")", "==", "2", "and", "(", "shape", "[", "0", "]", "==", "1", "or", "shape", "[", "1", "]", "==", "1", ")", ":", "\n", "            ", "return", "False", ",", "False", "\n", "", "else", ":", "\n", "            ", "return", "False", ",", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.AdaFactor._rms": [[394, 396], ["math.sqrt", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "x.pow"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.mean", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.mean", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.mean", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.mean"], ["", "", "def", "_rms", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "sqrt", "(", "torch", ".", "mean", "(", "x", ".", "pow", "(", "2", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.AdaFactor.step": [[397, 513], ["closure", "optimizers.AdaFactor._check_shape", "p.data.size", "max", "torch.div.div_", "torch.div.div_", "p.data.add_", "RuntimeError", "grad.view.view.size", "optimizers.AdaFactor._experimental_reshape", "grad.view.view.view", "len", "optimizers.AdaFactor._rms", "exp_avg.mul_().add_", "exp_avg_sq_r.mul_().add_", "exp_avg_sq_c.mul_().add_", "torch.mul().div_", "torch.mul().div_", "torch.mul().div_", "torch.mul().div_", "exp_avg_sq.mul_().addcmul_().add_", "torch.div", "torch.div", "torch.div", "torch.div", "torch.max", "torch.max", "torch.max", "torch.max", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "max", "p.data.add_", "p.data.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.div().sqrt().add_", "torch.div().sqrt().add_", "torch.div().sqrt().add_", "torch.div().sqrt().add_", "torch.mul().div_.sqrt", "torch.mul().div_.sqrt", "exp_avg.mul_", "exp_avg_sq_r.mul_", "torch.mul().add_", "torch.mul().add_", "torch.mul().add_", "torch.mul().add_", "exp_avg_sq_c.mul_", "torch.mul().add_", "torch.mul().add_", "torch.mul().add_", "torch.mul().add_", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "exp_avg_sq.mul_().addcmul_", "optimizers.AdaFactor._rms", "torch.div.view", "torch.div.view", "torch.div().sqrt", "torch.div().sqrt", "torch.div().sqrt", "torch.div().sqrt", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "exp_avg_sq.mul_", "torch.div", "torch.div", "torch.div", "torch.div"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.AdaFactor._check_shape", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.AdaFactor._experimental_reshape", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.AdaFactor._rms", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.AdaFactor._rms"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse \\\n                                       gradients, use SparseAdam instead'", ")", "\n", "\n", "", "is_matrix", ",", "is_need_reshape", "=", "self", ".", "_check_shape", "(", "grad", ".", "size", "(", ")", ")", "\n", "new_shape", "=", "p", ".", "data", ".", "size", "(", ")", "\n", "if", "is_need_reshape", "and", "group", "[", "'enable_factorization'", "]", ":", "\n", "                    ", "new_shape", ",", "old_shape", "=", "self", ".", "_experimental_reshape", "(", "p", ".", "data", ".", "size", "(", ")", ")", "\n", "grad", "=", "grad", ".", "view", "(", "new_shape", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "if", "group", "[", "'enable_momentum'", "]", ":", "\n", "                        ", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros", "(", "new_shape", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "\n", "device", "=", "p", ".", "grad", ".", "device", ")", "\n", "\n", "", "if", "is_matrix", "and", "group", "[", "'enable_factorization'", "]", ":", "\n", "                        ", "state", "[", "'exp_avg_sq_R'", "]", "=", "torch", ".", "zeros", "(", "(", "1", ",", "new_shape", "[", "1", "]", ")", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "\n", "device", "=", "p", ".", "grad", ".", "device", ")", "\n", "state", "[", "'exp_avg_sq_C'", "]", "=", "torch", ".", "zeros", "(", "(", "new_shape", "[", "0", "]", ",", "1", ")", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "\n", "device", "=", "p", ".", "grad", ".", "device", ")", "\n", "", "else", ":", "\n", "                        ", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros", "(", "new_shape", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "\n", "device", "=", "p", ".", "grad", ".", "device", ")", "\n", "", "if", "group", "[", "'ams_grad'", "]", ":", "\n", "                        ", "state", "[", "'exp_avg_sq_hat'", "]", "=", "torch", ".", "zeros", "(", "new_shape", ",", "dtype", "=", "torch", ".", "float32", ",", "\n", "device", "=", "p", ".", "grad", ".", "device", ")", "\n", "\n", "", "", "if", "group", "[", "'enable_momentum'", "]", ":", "\n", "                    ", "exp_avg", "=", "state", "[", "'exp_avg'", "]", "\n", "\n", "", "if", "is_matrix", "and", "group", "[", "'enable_factorization'", "]", ":", "\n", "                    ", "exp_avg_sq_r", "=", "state", "[", "'exp_avg_sq_R'", "]", "\n", "exp_avg_sq_c", "=", "state", "[", "'exp_avg_sq_C'", "]", "\n", "", "else", ":", "\n", "                    ", "exp_avg_sq", "=", "state", "[", "'exp_avg_sq'", "]", "\n", "\n", "", "if", "group", "[", "'ams_grad'", "]", ":", "\n", "                    ", "exp_avg_sq_hat", "=", "state", "[", "'exp_avg_sq_hat'", "]", "\n", "\n", "", "state", "[", "'step'", "]", "+=", "1", "\n", "lr_t", "=", "group", "[", "'lr'", "]", "\n", "lr_t", "*=", "max", "(", "group", "[", "'eps2'", "]", ",", "self", ".", "_rms", "(", "p", ".", "data", ")", ")", "\n", "\n", "if", "group", "[", "'enable_momentum'", "]", ":", "\n", "                    ", "if", "group", "[", "'non_constant_decay'", "]", ":", "\n", "                        ", "beta1_t", "=", "group", "[", "'beta1'", "]", "*", "(", "1", "-", "group", "[", "'beta1'", "]", "**", "(", "state", "[", "'step'", "]", "-", "1", ")", ")", "/", "(", "1", "-", "group", "[", "'beta1'", "]", "**", "state", "[", "'step'", "]", ")", "\n", "", "else", ":", "\n", "                        ", "beta1_t", "=", "group", "[", "'beta1'", "]", "\n", "", "exp_avg", ".", "mul_", "(", "beta1_t", ")", ".", "add_", "(", "1", "-", "beta1_t", ",", "grad", ")", "\n", "\n", "", "if", "group", "[", "'non_constant_decay'", "]", ":", "\n", "                    ", "beta2_t", "=", "group", "[", "'beta2'", "]", "*", "(", "1", "-", "group", "[", "'beta2'", "]", "**", "(", "state", "[", "'step'", "]", "-", "1", ")", ")", "/", "(", "1", "-", "group", "[", "'beta2'", "]", "**", "state", "[", "'step'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "beta2_t", "=", "group", "[", "'beta2'", "]", "\n", "\n", "", "if", "is_matrix", "and", "group", "[", "'enable_factorization'", "]", ":", "\n", "                    ", "exp_avg_sq_r", ".", "mul_", "(", "beta2_t", ")", ".", "add_", "(", "1", "-", "beta2_t", ",", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "grad", ",", "grad", ")", ".", "\n", "add_", "(", "group", "[", "'eps1'", "]", ")", ",", "\n", "dim", "=", "0", ",", "keepdim", "=", "True", ")", ")", "\n", "exp_avg_sq_c", ".", "mul_", "(", "beta2_t", ")", ".", "add_", "(", "1", "-", "beta2_t", ",", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "grad", ",", "grad", ")", ".", "\n", "add_", "(", "group", "[", "'eps1'", "]", ")", ",", "\n", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "v", "=", "torch", ".", "mul", "(", "exp_avg_sq_c", ",", "\n", "exp_avg_sq_r", ")", ".", "div_", "(", "torch", ".", "sum", "(", "exp_avg_sq_r", ")", ")", "\n", "", "else", ":", "\n", "                    ", "exp_avg_sq", ".", "mul_", "(", "beta2_t", ")", ".", "addcmul_", "(", "1", "-", "beta2_t", ",", "grad", ",", "grad", ")", ".", "add_", "(", "(", "1", "-", "beta2_t", ")", "*", "group", "[", "'eps1'", "]", ")", "\n", "v", "=", "exp_avg_sq", "\n", "\n", "", "g", "=", "grad", "\n", "if", "group", "[", "'enable_momentum'", "]", ":", "\n", "                    ", "g", "=", "torch", ".", "div", "(", "exp_avg", ",", "1", "-", "beta1_t", "**", "state", "[", "'step'", "]", ")", "\n", "\n", "", "if", "group", "[", "'ams_grad'", "]", ":", "\n", "                    ", "torch", ".", "max", "(", "exp_avg_sq_hat", ",", "v", ",", "out", "=", "exp_avg_sq_hat", ")", "\n", "v", "=", "exp_avg_sq_hat", "\n", "u", "=", "torch", ".", "div", "(", "g", ",", "(", "torch", ".", "div", "(", "v", ",", "1", "-", "beta2_t", "**", "\n", "state", "[", "'step'", "]", ")", ")", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps1'", "]", ")", ")", "\n", "", "else", ":", "\n", "                    ", "u", "=", "torch", ".", "div", "(", "g", ",", "v", ".", "sqrt", "(", ")", ")", "\n", "\n", "", "u", ".", "div_", "(", "max", "(", "1", ",", "self", ".", "_rms", "(", "u", ")", "/", "group", "[", "'cliping_threshold'", "]", ")", ")", "\n", "p", ".", "data", ".", "add_", "(", "-", "lr_t", "*", "(", "u", ".", "view", "(", "old_shape", ")", "if", "is_need_reshape", "and", "\n", "group", "[", "'enable_factorization'", "]", "else", "u", ")", ")", "\n", "\n", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "                    ", "p", ".", "data", ".", "add_", "(", "-", "group", "[", "'weight_decay'", "]", "*", "lr_t", ",", "p", ".", "data", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.build_torch_optimizer": [[13, 102], ["torch.SGD", "opt.optim.startswith", "namespace.FP16_Optimizer", "model.parameters", "torch.Adagrad", "torch.Adadelta", "optimizers.AdaFactor", "torch.Adam", "model.named_parameters", "optimizers.MultipleOptimizer", "apex.optimizers.FusedAdam", "ValueError", "sparse.append", "dense.append", "torch.Adam", "torch.SparseAdam"], "function", ["None"], ["def", "build_torch_optimizer", "(", "model", ",", "opt", ")", ":", "\n", "    ", "\"\"\"Builds the PyTorch optimizer.\n\n    We use the default parameters for Adam that are suggested by\n    the original paper https://arxiv.org/pdf/1412.6980.pdf\n    These values are also used by other established implementations,\n    e.g. https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer\n    https://keras.io/optimizers/\n    Recently there are slightly different values used in the paper\n    \"Attention is all you need\"\n    https://arxiv.org/pdf/1706.03762.pdf, particularly the value beta2=0.98\n    was used there however, beta2=0.999 is still arguably the more\n    established value, so we use that here as well\n\n    Args:\n      model: The model to optimize.\n      opt. The dictionary of options.\n\n    Returns:\n      A ``torch.optim.Optimizer`` instance.\n    \"\"\"", "\n", "params", "=", "[", "p", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "betas", "=", "[", "opt", ".", "adam_beta1", ",", "opt", ".", "adam_beta2", "]", "\n", "if", "opt", ".", "optim", "==", "'sgd'", ":", "\n", "        ", "optimizer", "=", "optim", ".", "SGD", "(", "params", ",", "lr", "=", "opt", ".", "learning_rate", ")", "\n", "", "elif", "opt", ".", "optim", "==", "'adagrad'", ":", "\n", "        ", "optimizer", "=", "optim", ".", "Adagrad", "(", "\n", "params", ",", "\n", "lr", "=", "opt", ".", "learning_rate", ",", "\n", "initial_accumulator_value", "=", "opt", ".", "adagrad_accumulator_init", ")", "\n", "", "elif", "opt", ".", "optim", "==", "'adadelta'", ":", "\n", "        ", "optimizer", "=", "optim", ".", "Adadelta", "(", "params", ",", "lr", "=", "opt", ".", "learning_rate", ")", "\n", "", "elif", "opt", ".", "optim", "==", "'adafactor'", ":", "\n", "        ", "optimizer", "=", "AdaFactor", "(", "\n", "params", ",", "\n", "non_constant_decay", "=", "True", ",", "\n", "enable_factorization", "=", "True", ",", "\n", "weight_decay", "=", "0", ")", "\n", "", "elif", "opt", ".", "optim", "==", "'adam'", ":", "\n", "        ", "optimizer", "=", "optim", ".", "Adam", "(", "\n", "params", ",", "\n", "lr", "=", "opt", ".", "learning_rate", ",", "\n", "betas", "=", "betas", ",", "\n", "eps", "=", "1e-9", ")", "\n", "", "elif", "opt", ".", "optim", "==", "'sparseadam'", ":", "\n", "        ", "dense", "=", "[", "]", "\n", "sparse", "=", "[", "]", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "not", "param", ".", "requires_grad", ":", "\n", "                ", "continue", "\n", "# TODO: Find a better way to check for sparse gradients.", "\n", "", "if", "'embed'", "in", "name", ":", "\n", "                ", "sparse", ".", "append", "(", "param", ")", "\n", "", "else", ":", "\n", "                ", "dense", ".", "append", "(", "param", ")", "\n", "", "", "optimizer", "=", "MultipleOptimizer", "(", "\n", "[", "optim", ".", "Adam", "(", "\n", "dense", ",", "\n", "lr", "=", "opt", ".", "learning_rate", ",", "\n", "betas", "=", "betas", ",", "\n", "eps", "=", "1e-8", ")", ",", "\n", "optim", ".", "SparseAdam", "(", "\n", "sparse", ",", "\n", "lr", "=", "opt", ".", "learning_rate", ",", "\n", "betas", "=", "betas", ",", "\n", "eps", "=", "1e-8", ")", "]", ")", "\n", "", "elif", "opt", ".", "optim", "==", "'fusedadam'", ":", "\n", "        ", "import", "apex", "\n", "optimizer", "=", "apex", ".", "optimizers", ".", "FusedAdam", "(", "\n", "params", ",", "\n", "lr", "=", "opt", ".", "learning_rate", ",", "\n", "betas", "=", "betas", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid optimizer type: '", "+", "opt", ".", "optim", ")", "\n", "\n", "", "if", "opt", ".", "model_dtype", "==", "'fp16'", ":", "\n", "        ", "import", "apex", "\n", "static_loss_scale", "=", "opt", ".", "loss_scale", "\n", "dynamic_loss_scale", "=", "opt", ".", "loss_scale", "==", "0", "\n", "# TODO: clean this up when APEX unify its optimizer API.", "\n", "if", "opt", ".", "optim", ".", "startswith", "(", "'fused'", ")", ":", "\n", "            ", "namespace", "=", "apex", ".", "optimizers", "# Faster wrapper.", "\n", "", "else", ":", "\n", "            ", "namespace", "=", "apex", ".", "fp16_utils", "\n", "", "optimizer", "=", "namespace", ".", "FP16_Optimizer", "(", "\n", "optimizer", ",", "\n", "static_loss_scale", "=", "static_loss_scale", ",", "\n", "dynamic_loss_scale", "=", "dynamic_loss_scale", ")", "\n", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.make_learning_rate_decay_fn": [[104, 120], ["functools.partial", "functools.partial", "functools.partial"], "function", ["None"], ["", "def", "make_learning_rate_decay_fn", "(", "opt", ")", ":", "\n", "    ", "\"\"\"Returns the learning decay function from options.\"\"\"", "\n", "if", "opt", ".", "decay_method", "==", "'noam'", ":", "\n", "        ", "return", "functools", ".", "partial", "(", "\n", "noam_decay", ",", "\n", "warmup_steps", "=", "opt", ".", "warmup_steps", ",", "\n", "model_size", "=", "opt", ".", "rnn_size", ")", "\n", "", "elif", "opt", ".", "decay_method", "==", "'rsqrt'", ":", "\n", "        ", "return", "functools", ".", "partial", "(", "\n", "rsqrt_decay", ",", "warmup_steps", "=", "opt", ".", "warmup_steps", ")", "\n", "", "elif", "opt", ".", "start_decay_steps", "is", "not", "None", ":", "\n", "        ", "return", "functools", ".", "partial", "(", "\n", "exponential_decay", ",", "\n", "rate", "=", "opt", ".", "learning_rate_decay", ",", "\n", "decay_steps", "=", "opt", ".", "decay_steps", ",", "\n", "start_step", "=", "opt", ".", "start_decay_steps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.noam_decay": [[122, 129], ["min"], "function", ["None"], ["", "", "def", "noam_decay", "(", "step", ",", "warmup_steps", ",", "model_size", ")", ":", "\n", "    ", "\"\"\"Learning rate schedule described in\n    https://arxiv.org/pdf/1706.03762.pdf.\n    \"\"\"", "\n", "return", "(", "\n", "model_size", "**", "(", "-", "0.5", ")", "*", "\n", "min", "(", "step", "**", "(", "-", "0.5", ")", ",", "step", "*", "warmup_steps", "**", "(", "-", "1.5", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.exponential_decay": [[131, 136], ["max"], "function", ["None"], ["", "def", "exponential_decay", "(", "step", ",", "rate", ",", "decay_steps", ",", "start_step", "=", "0", ")", ":", "\n", "    ", "\"\"\"A standard exponential decay, scaling the learning rate by :obj:`rate`\n    every :obj:`decay_steps` steps.\n    \"\"\"", "\n", "return", "rate", "**", "(", "max", "(", "step", "-", "start_step", "+", "decay_steps", ",", "0", ")", "//", "decay_steps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.rsqrt_decay": [[138, 141], ["math.sqrt", "max"], "function", ["None"], ["", "def", "rsqrt_decay", "(", "step", ",", "warmup_steps", ")", ":", "\n", "    ", "\"\"\"Decay based on the reciprocal of the step square root.\"\"\"", "\n", "return", "1.0", "/", "sqrt", "(", "max", "(", "step", ",", "warmup_steps", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.text_dataset.TextDataReader.read": [[12, 36], ["isinstance", "enumerate", "onmt.inputters.datareader_base.DataReaderBase._read_file", "isinstance", "seq.decode.decode.decode"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.datareader_base.DataReaderBase._read_file"], ["    ", "def", "read", "(", "self", ",", "sequences", ",", "side", ",", "_dir", "=", "None", ")", ":", "\n", "        ", "\"\"\"Read text data from disk.\n\n        Args:\n            sequences (str or Iterable[str]):\n                path to text file or iterable of the actual text data.\n            side (str): Prefix used in return dict. Usually\n                ``\"src\"`` or ``\"tgt\"``.\n            _dir (NoneType): Leave as ``None``. This parameter exists to\n                conform with the :func:`DataReaderBase.read()` signature.\n\n        Yields:\n            dictionaries whose keys are the names of fields and whose\n            values are more or less the result of tokenizing with those\n            fields.\n        \"\"\"", "\n", "assert", "_dir", "is", "None", "or", "_dir", "==", "\"\"", ",", "\"Cannot use _dir with TextDataReader.\"", "\n", "if", "isinstance", "(", "sequences", ",", "str", ")", ":", "\n", "            ", "sequences", "=", "DataReaderBase", ".", "_read_file", "(", "sequences", ")", "\n", "", "for", "i", ",", "seq", "in", "enumerate", "(", "sequences", ")", ":", "\n", "            ", "if", "isinstance", "(", "seq", ",", "six", ".", "binary_type", ")", ":", "\n", "                ", "seq", "=", "seq", ".", "decode", "(", "\"utf-8\"", ")", "\n", "", "yield", "{", "side", ":", "seq", ",", "\"indices\"", ":", "i", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.text_dataset.TextMultiField.__init__": [[91, 96], ["torchtext.data.RawField.__init__", "sorted", "text_dataset.TextMultiField.fields.append"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "base_name", ",", "base_field", ",", "feats_fields", ")", ":", "\n", "        ", "super", "(", "TextMultiField", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fields", "=", "[", "(", "base_name", ",", "base_field", ")", "]", "\n", "for", "name", ",", "ff", "in", "sorted", "(", "feats_fields", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "0", "]", ")", ":", "\n", "            ", "self", ".", "fields", ".", "append", "(", "(", "name", ",", "ff", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.text_dataset.TextMultiField.base_field": [[97, 100], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "base_field", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "fields", "[", "0", "]", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.text_dataset.TextMultiField.process": [[101, 135], ["list", "text_dataset.TextMultiField.base_field.process", "torch.stack", "zip", "ff.process", "enumerate"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.process", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.process"], ["", "def", "process", "(", "self", ",", "batch", ",", "device", "=", "None", ")", ":", "\n", "        ", "\"\"\"Convert outputs of preprocess into Tensors.\n\n        Args:\n            batch (List[List[List[str]]]): A list of length batch size.\n                Each element is a list of the preprocess results for each\n                field (which are lists of str \"words\" or feature tags.\n            device (torch.device or str): The device on which the tensor(s)\n                are built.\n\n        Returns:\n            torch.LongTensor or Tuple[LongTensor, LongTensor]:\n                A tensor of shape ``(seq_len, batch_size, len(self.fields))``\n                where the field features are ordered like ``self.fields``.\n                If the base field returns lengths, these are also returned\n                and have shape ``(batch_size,)``.\n        \"\"\"", "\n", "\n", "# batch (list(list(list))): batch_size x len(self.fields) x seq_len", "\n", "batch_by_feat", "=", "list", "(", "zip", "(", "*", "batch", ")", ")", "\n", "base_data", "=", "self", ".", "base_field", ".", "process", "(", "batch_by_feat", "[", "0", "]", ",", "device", "=", "device", ")", "\n", "if", "self", ".", "base_field", ".", "include_lengths", ":", "\n", "# lengths: batch_size", "\n", "            ", "base_data", ",", "lengths", "=", "base_data", "\n", "\n", "", "feats", "=", "[", "ff", ".", "process", "(", "batch_by_feat", "[", "i", "]", ",", "device", "=", "device", ")", "\n", "for", "i", ",", "(", "_", ",", "ff", ")", "in", "enumerate", "(", "self", ".", "fields", "[", "1", ":", "]", ",", "1", ")", "]", "\n", "levels", "=", "[", "base_data", "]", "+", "feats", "\n", "# data: seq_len x batch_size x len(self.fields)", "\n", "data", "=", "torch", ".", "stack", "(", "levels", ",", "2", ")", "\n", "if", "self", ".", "base_field", ".", "include_lengths", ":", "\n", "            ", "return", "data", ",", "lengths", "\n", "", "else", ":", "\n", "            ", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.text_dataset.TextMultiField.preprocess": [[136, 149], ["f.preprocess"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.preprocess"], ["", "", "def", "preprocess", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Preprocess data.\n\n        Args:\n            x (str): A sentence string (words joined by whitespace).\n\n        Returns:\n            List[List[str]]: A list of length ``len(self.fields)`` containing\n                lists of tokens/feature tags for the sentence. The output\n                is ordered like ``self.fields``.\n        \"\"\"", "\n", "\n", "return", "[", "f", ".", "preprocess", "(", "x", ")", "for", "_", ",", "f", "in", "self", ".", "fields", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.text_dataset.TextMultiField.__getitem__": [[150, 152], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "self", ".", "fields", "[", "item", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.text_dataset.text_sort_key": [[38, 43], ["hasattr", "len", "len", "len"], "function", ["None"], ["", "", "", "def", "text_sort_key", "(", "ex", ")", ":", "\n", "    ", "\"\"\"Sort using the number of tokens in the sequence.\"\"\"", "\n", "if", "hasattr", "(", "ex", ",", "\"tgt\"", ")", ":", "\n", "        ", "return", "len", "(", "ex", ".", "src", "[", "0", "]", ")", ",", "len", "(", "ex", ".", "tgt", "[", "0", "]", ")", "\n", "", "return", "len", "(", "ex", ".", "src", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.text_dataset._feature_tokenize": [[46, 70], ["string.split", "t.split"], "function", ["None"], ["", "def", "_feature_tokenize", "(", "\n", "string", ",", "layer", "=", "0", ",", "tok_delim", "=", "None", ",", "feat_delim", "=", "None", ",", "truncate", "=", "None", ")", ":", "\n", "    ", "\"\"\"Split apart word features (like POS/NER tags) from the tokens.\n\n    Args:\n        string (str): A string with ``tok_delim`` joining tokens and\n            features joined by ``feat_delim``. For example,\n            ``\"hello|NOUN|'' Earth|NOUN|PLANET\"``.\n        layer (int): Which feature to extract. (Not used if there are no\n            features, indicated by ``feat_delim is None``). In the\n            example above, layer 2 is ``'' PLANET``.\n        truncate (int or NoneType): Restrict sequences to this length of\n            tokens.\n\n    Returns:\n        List[str] of tokens.\n    \"\"\"", "\n", "\n", "tokens", "=", "string", ".", "split", "(", "tok_delim", ")", "\n", "if", "truncate", "is", "not", "None", ":", "\n", "        ", "tokens", "=", "tokens", "[", ":", "truncate", "]", "\n", "", "if", "feat_delim", "is", "not", "None", ":", "\n", "        ", "tokens", "=", "[", "t", ".", "split", "(", "feat_delim", ")", "[", "layer", "]", "for", "t", "in", "tokens", "]", "\n", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.text_dataset.text_fields": [[154, 195], ["kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "range", "text_dataset.TextMultiField", "functools.partial", "torchtext.data.Field", "fields_.append", "str"], "function", ["None"], ["", "", "def", "text_fields", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Create text fields.\n\n    Args:\n        base_name (str): Name associated with the field.\n        n_feats (int): Number of word level feats (not counting the tokens)\n        include_lengths (bool): Optionally return the sequence lengths.\n        pad (str, optional): Defaults to ``\"<blank>\"``.\n        bos (str or NoneType, optional): Defaults to ``\"<s>\"``.\n        eos (str or NoneType, optional): Defaults to ``\"</s>\"``.\n        truncate (bool or NoneType, optional): Defaults to ``None``.\n\n    Returns:\n        TextMultiField\n    \"\"\"", "\n", "\n", "n_feats", "=", "kwargs", "[", "\"n_feats\"", "]", "\n", "include_lengths", "=", "kwargs", "[", "\"include_lengths\"", "]", "\n", "base_name", "=", "kwargs", "[", "\"base_name\"", "]", "\n", "pad", "=", "kwargs", ".", "get", "(", "\"pad\"", ",", "\"<blank>\"", ")", "\n", "bos", "=", "kwargs", ".", "get", "(", "\"bos\"", ",", "\"<s>\"", ")", "\n", "eos", "=", "kwargs", ".", "get", "(", "\"eos\"", ",", "\"</s>\"", ")", "\n", "truncate", "=", "kwargs", ".", "get", "(", "\"truncate\"", ",", "None", ")", "\n", "fields_", "=", "[", "]", "\n", "feat_delim", "=", "u\"\uffe8\"", "if", "n_feats", ">", "0", "else", "None", "\n", "for", "i", "in", "range", "(", "n_feats", "+", "1", ")", ":", "\n", "        ", "name", "=", "base_name", "+", "\"_feat_\"", "+", "str", "(", "i", "-", "1", ")", "if", "i", ">", "0", "else", "base_name", "\n", "tokenize", "=", "partial", "(", "\n", "_feature_tokenize", ",", "\n", "layer", "=", "i", ",", "\n", "truncate", "=", "truncate", ",", "\n", "feat_delim", "=", "feat_delim", ")", "\n", "use_len", "=", "i", "==", "0", "and", "include_lengths", "\n", "feat", "=", "Field", "(", "\n", "init_token", "=", "bos", ",", "eos_token", "=", "eos", ",", "\n", "pad_token", "=", "pad", ",", "tokenize", "=", "tokenize", ",", "\n", "include_lengths", "=", "use_len", ")", "\n", "fields_", ".", "append", "(", "(", "name", ",", "feat", ")", ")", "\n", "", "assert", "fields_", "[", "0", "]", "[", "0", "]", "==", "base_name", "# sanity check", "\n", "field", "=", "TextMultiField", "(", "fields_", "[", "0", "]", "[", "0", "]", ",", "fields_", "[", "0", "]", "[", "1", "]", ",", "fields_", "[", "1", ":", "]", ")", "\n", "return", "field", "\n", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.OrderedIterator.__init__": [[517, 524], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "dataset", ",", "\n", "batch_size", ",", "\n", "batch_size_multiple", "=", "1", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "OrderedIterator", ",", "self", ")", ".", "__init__", "(", "dataset", ",", "batch_size", ",", "**", "kwargs", ")", "\n", "self", ".", "batch_size_multiple", "=", "batch_size_multiple", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.OrderedIterator.create_batches": [[525, 546], ["inputter.OrderedIterator.create_batches._pool"], "methods", ["None"], ["", "def", "create_batches", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "train", ":", "\n", "            ", "def", "_pool", "(", "data", ",", "random_shuffler", ")", ":", "\n", "                ", "for", "p", "in", "torchtext", ".", "data", ".", "batch", "(", "data", ",", "self", ".", "batch_size", "*", "100", ")", ":", "\n", "                    ", "p_batch", "=", "batch_iter", "(", "\n", "sorted", "(", "p", ",", "key", "=", "self", ".", "sort_key", ")", ",", "\n", "self", ".", "batch_size", ",", "\n", "batch_size_fn", "=", "self", ".", "batch_size_fn", ",", "\n", "batch_size_multiple", "=", "self", ".", "batch_size_multiple", ")", "\n", "for", "b", "in", "random_shuffler", "(", "list", "(", "p_batch", ")", ")", ":", "\n", "                        ", "yield", "b", "\n", "\n", "", "", "", "self", ".", "batches", "=", "_pool", "(", "self", ".", "data", "(", ")", ",", "self", ".", "random_shuffler", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "batches", "=", "[", "]", "\n", "for", "b", "in", "batch_iter", "(", "\n", "self", ".", "data", "(", ")", ",", "\n", "self", ".", "batch_size", ",", "\n", "batch_size_fn", "=", "self", ".", "batch_size_fn", ",", "\n", "batch_size_multiple", "=", "self", ".", "batch_size_multiple", ")", ":", "\n", "                ", "self", ".", "batches", ".", "append", "(", "sorted", "(", "b", ",", "key", "=", "self", ".", "sort_key", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.DatasetLazyIter.__init__": [[561, 578], ["inputter.DatasetLazyIter.src_vocabs.extend", "inputter.DatasetLazyIter.examples.extend", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load"], ["def", "__init__", "(", "self", ",", "dataset_paths", ",", "fields", ",", "batch_size", ",", "batch_size_fn", ",", "\n", "batch_size_multiple", ",", "device", ",", "is_train", ",", "repeat", "=", "True", ",", "\n", "num_batches_multiple", "=", "1", ")", ":", "\n", "        ", "self", ".", "_paths", "=", "dataset_paths", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "batch_size_fn", "=", "batch_size_fn", "\n", "self", ".", "batch_size_multiple", "=", "batch_size_multiple", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "is_train", "=", "is_train", "\n", "self", ".", "repeat", "=", "repeat", "\n", "self", ".", "num_batches_multiple", "=", "num_batches_multiple", "\n", "self", ".", "src_vocabs", "=", "[", "]", "\n", "self", ".", "examples", "=", "[", "]", "\n", "for", "path", "in", "dataset_paths", ":", "\n", "            ", "self", ".", "src_vocabs", ".", "extend", "(", "torch", ".", "load", "(", "path", ")", ".", "src_vocabs", ")", "\n", "self", ".", "examples", ".", "extend", "(", "torch", ".", "load", "(", "path", ")", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.DatasetLazyIter._iter_dataset": [[579, 602], ["torch.load", "onmt.utils.logging.logger.info", "inputter.OrderedIterator", "gc.collect", "gc.collect", "len"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load"], ["", "", "def", "_iter_dataset", "(", "self", ",", "path", ")", ":", "\n", "        ", "cur_dataset", "=", "torch", ".", "load", "(", "path", ")", "\n", "logger", ".", "info", "(", "'Loading dataset from %s, number of examples: %d'", "%", "\n", "(", "path", ",", "len", "(", "cur_dataset", ")", ")", ")", "\n", "cur_dataset", ".", "fields", "=", "self", ".", "fields", "\n", "cur_iter", "=", "OrderedIterator", "(", "\n", "dataset", "=", "cur_dataset", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "batch_size_multiple", "=", "self", ".", "batch_size_multiple", ",", "\n", "batch_size_fn", "=", "self", ".", "batch_size_fn", ",", "\n", "device", "=", "self", ".", "device", ",", "\n", "train", "=", "self", ".", "is_train", ",", "\n", "sort", "=", "False", ",", "\n", "sort_within_batch", "=", "True", ",", "\n", "repeat", "=", "False", "\n", ")", "\n", "for", "batch", "in", "cur_iter", ":", "\n", "            ", "yield", "batch", "\n", "\n", "", "cur_dataset", ".", "examples", "=", "None", "\n", "gc", ".", "collect", "(", ")", "\n", "del", "cur_dataset", "\n", "gc", ".", "collect", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.DatasetLazyIter.__iter__": [[603, 625], ["itertools.cycle", "inputter.DatasetLazyIter._iter_dataset", "inputter.DatasetLazyIter._iter_dataset"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.DatasetLazyIter._iter_dataset", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.DatasetLazyIter._iter_dataset"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "num_batches", "=", "0", "\n", "paths", "=", "self", ".", "_paths", "\n", "if", "self", ".", "is_train", "and", "self", ".", "repeat", ":", "\n", "# Cycle through the shards indefinitely.", "\n", "            ", "paths", "=", "cycle", "(", "paths", ")", "\n", "", "for", "path", "in", "paths", ":", "\n", "            ", "for", "batch", "in", "self", ".", "_iter_dataset", "(", "path", ")", ":", "\n", "                ", "yield", "batch", "\n", "num_batches", "+=", "1", "\n", "", "", "if", "self", ".", "is_train", "and", "not", "self", ".", "repeat", "and", "num_batches", "%", "self", ".", "num_batches_multiple", "!=", "0", ":", "\n", "# When the dataset is not repeated, we might need to ensure that", "\n", "# the number of returned batches is the multiple of a given value.", "\n", "# This is important for multi GPU training to ensure that all", "\n", "# workers have the same number of batches to process.", "\n", "            ", "for", "path", "in", "paths", ":", "\n", "                ", "for", "batch", "in", "self", ".", "_iter_dataset", "(", "path", ")", ":", "\n", "                    ", "yield", "batch", "\n", "num_batches", "+=", "1", "\n", "if", "num_batches", "%", "self", ".", "num_batches_multiple", "==", "0", ":", "\n", "                        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._getstate": [[28, 30], ["dict", "dict"], "function", ["None"], ["def", "_getstate", "(", "self", ")", ":", "\n", "    ", "return", "dict", "(", "self", ".", "__dict__", ",", "stoi", "=", "dict", "(", "self", ".", "stoi", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._setstate": [[32, 35], ["inputter..__dict__.update", "collections.defaultdict"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.update"], ["", "def", "_setstate", "(", "self", ",", "state", ")", ":", "\n", "    ", "self", ".", "__dict__", ".", "update", "(", "state", ")", "\n", "self", ".", "stoi", "=", "defaultdict", "(", "lambda", ":", "0", ",", "self", ".", "stoi", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.make_src": [[41, 49], ["max", "torch.zeros", "enumerate", "max", "len", "enumerate", "t.size", "t.max"], "function", ["None"], ["def", "make_src", "(", "data", ",", "vocab", ")", ":", "\n", "    ", "src_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "src_vocab_size", "=", "max", "(", "[", "t", ".", "max", "(", ")", "for", "t", "in", "data", "]", ")", "+", "1", "\n", "alignment", "=", "torch", ".", "zeros", "(", "src_size", ",", "len", "(", "data", ")", ",", "src_vocab_size", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "        ", "for", "j", ",", "t", "in", "enumerate", "(", "sent", ")", ":", "\n", "            ", "alignment", "[", "j", ",", "i", ",", "t", "]", "=", "1", "\n", "", "", "return", "alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.make_tgt": [[51, 57], ["max", "torch.zeros().long", "enumerate", "t.size", "torch.zeros", "len", "sent.size"], "function", ["None"], ["", "def", "make_tgt", "(", "data", ",", "vocab", ")", ":", "\n", "    ", "tgt_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "alignment", "=", "torch", ".", "zeros", "(", "tgt_size", ",", "len", "(", "data", ")", ")", ".", "long", "(", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "        ", "alignment", "[", ":", "sent", ".", "size", "(", "0", ")", ",", "i", "]", "=", "sent", "\n", "", "return", "alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.get_fields": [[59, 147], ["torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field"], "function", ["None"], ["", "def", "get_fields", "(", "\n", "src_data_type", ",", "\n", "n_src_feats", ",", "\n", "n_tgt_feats", ",", "\n", "pad", "=", "'<blank>'", ",", "\n", "bos", "=", "'<s>'", ",", "\n", "eos", "=", "'</s>'", ",", "\n", "dynamic_dict", "=", "False", ",", "\n", "src_truncate", "=", "None", ",", "\n", "tgt_truncate", "=", "None", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        src_data_type: type of the source input. Options are [text|img|audio].\n        n_src_feats (int): the number of source features (not counting tokens)\n            to create a :class:`torchtext.data.Field` for. (If\n            ``src_data_type==\"text\"``, these fields are stored together\n            as a ``TextMultiField``).\n        n_tgt_feats (int): See above.\n        pad (str): Special pad symbol. Used on src and tgt side.\n        bos (str): Special beginning of sequence symbol. Only relevant\n            for tgt.\n        eos (str): Special end of sequence symbol. Only relevant\n            for tgt.\n        dynamic_dict (bool): Whether or not to include source map and\n            alignment fields.\n        src_truncate: Cut off src sequences beyond this (passed to\n            ``src_data_type``'s data reader - see there for more details).\n        tgt_truncate: Cut off tgt sequences beyond this (passed to\n            :class:`TextDataReader` - see there for more details).\n\n    Returns:\n        A dict mapping names to fields. These names need to match\n        the dataset example attributes.\n    \"\"\"", "\n", "\n", "assert", "src_data_type", "in", "[", "'text'", ",", "'img'", ",", "'audio'", "]", ",", "\"Data type not implemented\"", "\n", "assert", "not", "dynamic_dict", "or", "src_data_type", "==", "'text'", ",", "'it is not possible to use dynamic_dict with non-text input'", "\n", "fields", "=", "{", "}", "\n", "\n", "fields_getters", "=", "{", "\"text\"", ":", "text_fields", "}", "\n", "\n", "src_field_kwargs", "=", "{", "\"n_feats\"", ":", "n_src_feats", ",", "\n", "\"include_lengths\"", ":", "True", ",", "\n", "\"pad\"", ":", "pad", ",", "\"bos\"", ":", "None", ",", "\"eos\"", ":", "None", ",", "\n", "\"truncate\"", ":", "src_truncate", ",", "\n", "\"base_name\"", ":", "\"src\"", "}", "\n", "fields", "[", "\"src\"", "]", "=", "fields_getters", "[", "src_data_type", "]", "(", "**", "src_field_kwargs", ")", "\n", "\n", "# same with src", "\n", "history_field_kwargs", "=", "{", "\"n_feats\"", ":", "n_src_feats", ",", "\n", "\"include_lengths\"", ":", "True", ",", "\n", "\"pad\"", ":", "pad", ",", "\"bos\"", ":", "None", ",", "\"eos\"", ":", "None", ",", "\n", "\"truncate\"", ":", "src_truncate", ",", "\n", "\"base_name\"", ":", "\"history\"", "}", "\n", "fields", "[", "\"history\"", "]", "=", "fields_getters", "[", "src_data_type", "]", "(", "**", "history_field_kwargs", ")", "\n", "\n", "ans_field_kwargs", "=", "{", "\"n_feats\"", ":", "n_src_feats", ",", "\n", "\"include_lengths\"", ":", "True", ",", "\n", "\"pad\"", ":", "pad", ",", "\"bos\"", ":", "None", ",", "\"eos\"", ":", "None", ",", "\n", "\"truncate\"", ":", "src_truncate", ",", "\n", "\"base_name\"", ":", "\"ans\"", "}", "\n", "fields", "[", "\"ans\"", "]", "=", "fields_getters", "[", "src_data_type", "]", "(", "**", "ans_field_kwargs", ")", "\n", "\n", "tgt_field_kwargs", "=", "{", "\"n_feats\"", ":", "n_tgt_feats", ",", "\n", "\"include_lengths\"", ":", "False", ",", "\n", "\"pad\"", ":", "pad", ",", "\"bos\"", ":", "bos", ",", "\"eos\"", ":", "eos", ",", "\n", "\"truncate\"", ":", "tgt_truncate", ",", "\n", "\"base_name\"", ":", "\"tgt\"", "}", "\n", "fields", "[", "\"tgt\"", "]", "=", "fields_getters", "[", "\"text\"", "]", "(", "**", "tgt_field_kwargs", ")", "\n", "\n", "indices", "=", "Field", "(", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "long", ",", "sequential", "=", "False", ")", "\n", "fields", "[", "\"indices\"", "]", "=", "indices", "\n", "\n", "if", "dynamic_dict", ":", "\n", "        ", "src_map", "=", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "postprocessing", "=", "make_src", ",", "sequential", "=", "False", ")", "\n", "fields", "[", "\"src_map\"", "]", "=", "src_map", "\n", "\n", "align", "=", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "postprocessing", "=", "make_tgt", ",", "sequential", "=", "False", ")", "\n", "fields", "[", "\"alignment\"", "]", "=", "align", "\n", "\n", "", "return", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.load_old_vocab": [[149, 199], ["inputter._old_style_vocab", "inputter._old_style_field_list", "inputter._old_style_nesting", "dict", "sum", "sum", "inputter.get_fields", "dict.items", "dict.items", "dict", "list", "iter", "itertools.chain.from_iterable", "isinstance", "dict.values", "onmt.inputters.text_dataset.TextMultiField"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._old_style_vocab", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._old_style_field_list", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._old_style_nesting", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.get_fields"], ["", "def", "load_old_vocab", "(", "vocab", ",", "data_type", "=", "\"text\"", ",", "dynamic_dict", "=", "False", ")", ":", "\n", "    ", "\"\"\"Update a legacy vocab/field format.\n\n    Args:\n        vocab: a list of (field name, torchtext.vocab.Vocab) pairs. This is the\n            format formerly saved in *.vocab.pt files. Or, text data\n            not using a :class:`TextMultiField`.\n        data_type (str): text, img, or audio\n        dynamic_dict (bool): Used for copy attention.\n\n    Returns:\n        a dictionary whose keys are the field names and whose values Fields.\n    \"\"\"", "\n", "\n", "if", "_old_style_vocab", "(", "vocab", ")", ":", "\n", "# List[Tuple[str, Vocab]] -> List[Tuple[str, Field]]", "\n", "# -> dict[str, Field]", "\n", "        ", "vocab", "=", "dict", "(", "vocab", ")", "\n", "n_src_features", "=", "sum", "(", "'src_feat_'", "in", "k", "for", "k", "in", "vocab", ")", "\n", "n_tgt_features", "=", "sum", "(", "'tgt_feat_'", "in", "k", "for", "k", "in", "vocab", ")", "\n", "fields", "=", "get_fields", "(", "\n", "data_type", ",", "n_src_features", ",", "n_tgt_features", ",", "\n", "dynamic_dict", "=", "dynamic_dict", ")", "\n", "for", "n", ",", "f", "in", "fields", ".", "items", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "f_iter", "=", "iter", "(", "f", ")", "\n", "", "except", "TypeError", ":", "\n", "                ", "f_iter", "=", "[", "(", "n", ",", "f", ")", "]", "\n", "", "for", "sub_n", ",", "sub_f", "in", "f_iter", ":", "\n", "                ", "if", "sub_n", "in", "vocab", ":", "\n", "                    ", "sub_f", ".", "vocab", "=", "vocab", "[", "sub_n", "]", "\n", "", "", "", "return", "fields", "\n", "\n", "", "if", "_old_style_field_list", "(", "vocab", ")", ":", "# upgrade to multifield", "\n", "# Dict[str, List[Tuple[str, Field]]]", "\n", "# doesn't change structure - don't return early.", "\n", "        ", "fields", "=", "vocab", "\n", "for", "base_name", ",", "vals", "in", "fields", ".", "items", "(", ")", ":", "\n", "            ", "if", "(", "(", "base_name", "==", "'src'", "and", "data_type", "==", "'text'", ")", "or", "\n", "base_name", "==", "'tgt'", ")", ":", "\n", "                ", "assert", "not", "isinstance", "(", "vals", "[", "0", "]", "[", "1", "]", ",", "TextMultiField", ")", "\n", "fields", "[", "base_name", "]", "=", "[", "(", "base_name", ",", "TextMultiField", "(", "\n", "vals", "[", "0", "]", "[", "0", "]", ",", "vals", "[", "0", "]", "[", "1", "]", ",", "vals", "[", "1", ":", "]", ")", ")", "]", "\n", "\n", "", "", "", "if", "_old_style_nesting", "(", "vocab", ")", ":", "\n", "# Dict[str, List[Tuple[str, Field]]] -> List[Tuple[str, Field]]", "\n", "# -> dict[str, Field]", "\n", "        ", "fields", "=", "dict", "(", "list", "(", "chain", ".", "from_iterable", "(", "vocab", ".", "values", "(", ")", ")", ")", ")", "\n", "\n", "", "return", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._old_style_vocab": [[201, 218], ["isinstance", "any", "isinstance"], "function", ["None"], ["", "def", "_old_style_vocab", "(", "vocab", ")", ":", "\n", "    ", "\"\"\"Detect old-style vocabs (``List[Tuple[str, torchtext.data.Vocab]]``).\n\n    Args:\n        vocab: some object loaded from a *.vocab.pt file\n\n    Returns:\n        Whether ``vocab`` is a list of pairs where the second object\n        is a :class:`torchtext.vocab.Vocab` object.\n\n    This exists because previously only the vocab objects from the fields\n    were saved directly, not the fields themselves, and the fields needed to\n    be reconstructed at training and translation time.\n    \"\"\"", "\n", "\n", "return", "isinstance", "(", "vocab", ",", "list", ")", "and", "any", "(", "isinstance", "(", "v", "[", "1", "]", ",", "Vocab", ")", "for", "v", "in", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._old_style_nesting": [[220, 224], ["isinstance", "any", "isinstance", "vocab.values"], "function", ["None"], ["", "def", "_old_style_nesting", "(", "vocab", ")", ":", "\n", "    ", "\"\"\"Detect old-style nesting (``dict[str, List[Tuple[str, Field]]]``).\"\"\"", "\n", "return", "isinstance", "(", "vocab", ",", "dict", ")", "and", "any", "(", "isinstance", "(", "v", ",", "list", ")", "for", "v", "in", "vocab", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._old_style_field_list": [[226, 243], ["inputter._old_style_nesting", "inputter._old_style_vocab", "isinstance"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._old_style_nesting", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._old_style_vocab"], ["", "def", "_old_style_field_list", "(", "vocab", ")", ":", "\n", "    ", "\"\"\"Detect old-style text fields.\n\n    Not old style vocab, old nesting, and text-type fields not using\n    ``TextMultiField``.\n\n    Args:\n        vocab: some object loaded from a *.vocab.pt file\n\n    Returns:\n        Whether ``vocab`` is not an :func:`_old_style_vocab` and not\n        a :class:`TextMultiField` (using an old-style text representation).\n    \"\"\"", "\n", "\n", "# if tgt isn't using TextMultiField, then no text field is.", "\n", "return", "(", "not", "_old_style_vocab", "(", "vocab", ")", ")", "and", "_old_style_nesting", "(", "vocab", ")", "and", "(", "not", "isinstance", "(", "vocab", "[", "'tgt'", "]", "[", "0", "]", "[", "1", "]", ",", "TextMultiField", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.old_style_vocab": [[245, 249], ["inputter._old_style_vocab", "inputter._old_style_field_list", "inputter._old_style_nesting"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._old_style_vocab", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._old_style_field_list", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._old_style_nesting"], ["", "def", "old_style_vocab", "(", "vocab", ")", ":", "\n", "    ", "\"\"\"The vocab/fields need updated.\"\"\"", "\n", "return", "_old_style_vocab", "(", "vocab", ")", "or", "_old_style_field_list", "(", "vocab", ")", "or", "_old_style_nesting", "(", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.filter_example": [[251, 280], ["float", "float", "float", "len", "len", "len", "len"], "function", ["None"], ["", "def", "filter_example", "(", "ex", ",", "use_src_len", "=", "True", ",", "use_tgt_len", "=", "True", ",", "use_history_len", "=", "False", ",", "\n", "min_src_len", "=", "1", ",", "max_src_len", "=", "float", "(", "'inf'", ")", ",", "\n", "min_tgt_len", "=", "1", ",", "max_tgt_len", "=", "float", "(", "'inf'", ")", ",", "\n", "min_history_len", "=", "1", ",", "max_history_len", "=", "float", "(", "'inf'", ")", ")", ":", "\n", "    ", "\"\"\"Return whether an example is an acceptable length.\n\n    If used with a dataset as ``filter_pred``, use :func:`partial()`\n    for all keyword arguments.\n\n    Args:\n        ex (torchtext.data.Example): An object with a ``src`` and ``tgt``\n            property.\n        use_src_len (bool): Filter based on the length of ``ex.src``.\n        use_tgt_len (bool): Similar to above.\n        min_src_len (int): A non-negative minimally acceptable length\n            (examples of exactly this length will be included).\n        min_tgt_len (int): Similar to above.\n        max_src_len (int or float): A non-negative (possibly infinite)\n            maximally acceptable length (examples of exactly this length\n            will be included).\n        max_tgt_len (int or float): Similar to above.\n    \"\"\"", "\n", "src_len", "=", "len", "(", "ex", ".", "src", "[", "0", "]", ")", "\n", "history_len", "=", "len", "(", "ex", ".", "history", "[", "0", "]", ")", "\n", "tgt_len", "=", "len", "(", "ex", ".", "tgt", "[", "0", "]", ")", "\n", "history_len", "=", "len", "(", "ex", ".", "history", "[", "0", "]", ")", "\n", "return", "(", "not", "use_src_len", "or", "min_src_len", "<=", "src_len", "<=", "max_src_len", ")", "and", "(", "not", "use_tgt_len", "or", "min_tgt_len", "<=", "tgt_len", "<=", "max_tgt_len", ")", "and", "(", "not", "use_history_len", "or", "min_history_len", "<=", "history_len", "<=", "max_history_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._pad_vocab_to_multiple": [[282, 291], ["len", "vocab.extend", "int", "torchtext.vocab.Vocab", "math.ceil", "range", "collections.Counter"], "function", ["None"], ["", "def", "_pad_vocab_to_multiple", "(", "vocab", ",", "multiple", ")", ":", "\n", "    ", "vocab_size", "=", "len", "(", "vocab", ")", "\n", "if", "vocab_size", "%", "multiple", "==", "0", ":", "\n", "        ", "return", "\n", "", "target_size", "=", "int", "(", "math", ".", "ceil", "(", "vocab_size", "/", "multiple", ")", ")", "*", "multiple", "\n", "padding_tokens", "=", "[", "\n", "\"averyunlikelytoken%d\"", "%", "i", "for", "i", "in", "range", "(", "target_size", "-", "vocab_size", ")", "]", "\n", "vocab", ".", "extend", "(", "Vocab", "(", "Counter", "(", ")", ",", "specials", "=", "padding_tokens", ")", ")", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._build_field_vocab": [[293, 302], ["field.vocab_cls", "inputter._pad_vocab_to_multiple"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._pad_vocab_to_multiple"], ["", "def", "_build_field_vocab", "(", "field", ",", "counter", ",", "size_multiple", "=", "1", ",", "**", "kwargs", ")", ":", "\n", "# this is basically copy-pasted from torchtext.", "\n", "    ", "all_specials", "=", "[", "\n", "field", ".", "unk_token", ",", "field", ".", "pad_token", ",", "field", ".", "init_token", ",", "field", ".", "eos_token", "\n", "]", "\n", "specials", "=", "[", "tok", "for", "tok", "in", "all_specials", "if", "tok", "is", "not", "None", "]", "\n", "field", ".", "vocab", "=", "field", ".", "vocab_cls", "(", "counter", ",", "specials", "=", "specials", ",", "**", "kwargs", ")", "\n", "if", "size_multiple", ">", "1", ":", "\n", "        ", "_pad_vocab_to_multiple", "(", "field", ".", "vocab", ",", "size_multiple", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._load_vocab": [[304, 314], ["inputter._read_vocab_file", "len", "onmt.utils.logging.logger.info", "enumerate"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._read_vocab_file"], ["", "", "def", "_load_vocab", "(", "vocab_path", ",", "name", ",", "counters", ")", ":", "\n", "# counters changes in place", "\n", "    ", "vocab", "=", "_read_vocab_file", "(", "vocab_path", ",", "name", ")", "\n", "vocab_size", "=", "len", "(", "vocab", ")", "\n", "logger", ".", "info", "(", "'Loaded %s vocab has %d tokens.'", "%", "(", "name", ",", "vocab_size", ")", ")", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "vocab", ")", ":", "\n", "# keep the order of tokens specified in the vocab file by", "\n", "# adding them to the counter with decreasing counting values", "\n", "        ", "counters", "[", "name", "]", "[", "token", "]", "=", "vocab_size", "-", "i", "\n", "", "return", "vocab", ",", "vocab_size", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._build_fv_from_multifield": [[316, 325], ["inputter._build_field_vocab", "onmt.utils.logging.logger.info", "len"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._build_field_vocab"], ["", "def", "_build_fv_from_multifield", "(", "multifield", ",", "counters", ",", "build_fv_args", ",", "\n", "size_multiple", "=", "1", ")", ":", "\n", "    ", "for", "name", ",", "field", "in", "multifield", ":", "\n", "        ", "_build_field_vocab", "(", "\n", "field", ",", "\n", "counters", "[", "name", "]", ",", "\n", "size_multiple", "=", "size_multiple", ",", "\n", "**", "build_fv_args", "[", "name", "]", ")", "\n", "logger", ".", "info", "(", "\" * %s vocab size: %d.\"", "%", "(", "name", ",", "len", "(", "field", ".", "vocab", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.build_vocab": [[327, 437], ["collections.defaultdict", "enumerate", "collections.defaultdict", "dict", "dict", "inputter._build_fv_from_multifield", "inputter._load_vocab", "inputter._load_vocab", "torch.load", "onmt.utils.logging.logger.info", "inputter._build_fv_from_multifield", "inputter._build_fv_from_multifield", "fields.items", "gc.collect", "gc.collect", "gc.collect", "onmt.utils.logging.logger.info", "inputter._merge_field_vocabs", "onmt.utils.logging.logger.info", "zip", "len", "iter", "getattr", "len", "counters[].update", "getattr"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._build_fv_from_multifield", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._load_vocab", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._load_vocab", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._build_fv_from_multifield", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._build_fv_from_multifield", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._merge_field_vocabs", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.update"], ["", "", "def", "build_vocab", "(", "train_dataset_files", ",", "fields", ",", "data_type", ",", "share_vocab", ",", "\n", "src_vocab_path", ",", "src_vocab_size", ",", "src_words_min_frequency", ",", "\n", "tgt_vocab_path", ",", "tgt_vocab_size", ",", "tgt_words_min_frequency", ",", "\n", "vocab_size_multiple", "=", "1", ")", ":", "\n", "    ", "\"\"\"Build the fields for all data sides.\n\n    Args:\n        train_dataset_files: a list of train dataset pt file.\n        fields (dict[str, Field]): fields to build vocab for.\n        data_type (str): A supported data type string.\n        share_vocab (bool): share source and target vocabulary?\n        src_vocab_path (str): Path to src vocabulary file.\n        src_vocab_size (int): size of the source vocabulary.\n        src_words_min_frequency (int): the minimum frequency needed to\n            include a source word in the vocabulary.\n        tgt_vocab_path (str): Path to tgt vocabulary file.\n        tgt_vocab_size (int): size of the target vocabulary.\n        tgt_words_min_frequency (int): the minimum frequency needed to\n            include a target word in the vocabulary.\n        vocab_size_multiple (int): ensure that the vocabulary size is a\n            multiple of this value.\n\n    Returns:\n        Dict of Fields\n    \"\"\"", "\n", "\n", "counters", "=", "defaultdict", "(", "Counter", ")", "\n", "\n", "# Load vocabulary", "\n", "if", "src_vocab_path", ":", "\n", "        ", "src_vocab", ",", "src_vocab_size", "=", "_load_vocab", "(", "\n", "src_vocab_path", ",", "\"src\"", ",", "counters", ")", "\n", "", "else", ":", "\n", "        ", "src_vocab", "=", "None", "\n", "\n", "", "if", "tgt_vocab_path", ":", "\n", "        ", "tgt_vocab", ",", "tgt_vocab_size", "=", "_load_vocab", "(", "\n", "tgt_vocab_path", ",", "\"tgt\"", ",", "counters", ")", "\n", "", "else", ":", "\n", "        ", "tgt_vocab", "=", "None", "\n", "\n", "", "for", "i", ",", "path", "in", "enumerate", "(", "train_dataset_files", ")", ":", "\n", "        ", "dataset", "=", "torch", ".", "load", "(", "path", ")", "\n", "logger", ".", "info", "(", "\" * reloading %s.\"", "%", "path", ")", "\n", "for", "ex", "in", "dataset", ".", "examples", ":", "\n", "            ", "for", "name", ",", "field", "in", "fields", ".", "items", "(", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "f_iter", "=", "iter", "(", "field", ")", "\n", "", "except", "TypeError", ":", "\n", "                    ", "f_iter", "=", "[", "(", "name", ",", "field", ")", "]", "\n", "all_data", "=", "[", "getattr", "(", "ex", ",", "name", ",", "None", ")", "]", "\n", "", "else", ":", "\n", "                    ", "all_data", "=", "getattr", "(", "ex", ",", "name", ")", "\n", "", "for", "(", "sub_n", ",", "sub_f", ")", ",", "fd", "in", "zip", "(", "\n", "f_iter", ",", "all_data", ")", ":", "\n", "                    ", "has_vocab", "=", "(", "sub_n", "==", "'src'", "and", "src_vocab", ")", "or", "(", "sub_n", "==", "'tgt'", "and", "tgt_vocab", ")", "\n", "if", "sub_f", ".", "sequential", "and", "not", "has_vocab", ":", "\n", "                        ", "val", "=", "fd", "\n", "counters", "[", "sub_n", "]", ".", "update", "(", "val", ")", "\n", "\n", "# Drop the none-using from memory but keep the last", "\n", "", "", "", "", "if", "i", "<", "len", "(", "train_dataset_files", ")", "-", "1", ":", "\n", "            ", "dataset", ".", "examples", "=", "None", "\n", "gc", ".", "collect", "(", ")", "\n", "del", "dataset", ".", "examples", "\n", "gc", ".", "collect", "(", ")", "\n", "del", "dataset", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "", "", "build_fv_args", "=", "defaultdict", "(", "dict", ")", "\n", "build_fv_args", "[", "\"src\"", "]", "=", "dict", "(", "\n", "max_size", "=", "src_vocab_size", ",", "min_freq", "=", "src_words_min_frequency", ")", "\n", "build_fv_args", "[", "\"tgt\"", "]", "=", "dict", "(", "\n", "max_size", "=", "tgt_vocab_size", ",", "min_freq", "=", "tgt_words_min_frequency", ")", "\n", "tgt_multifield", "=", "fields", "[", "\"tgt\"", "]", "\n", "_build_fv_from_multifield", "(", "\n", "tgt_multifield", ",", "\n", "counters", ",", "\n", "build_fv_args", ",", "\n", "size_multiple", "=", "vocab_size_multiple", "if", "not", "share_vocab", "else", "1", ")", "\n", "if", "data_type", "==", "'text'", ":", "\n", "        ", "src_multifield", "=", "fields", "[", "\"src\"", "]", "\n", "_build_fv_from_multifield", "(", "\n", "src_multifield", ",", "\n", "counters", ",", "\n", "build_fv_args", ",", "\n", "size_multiple", "=", "vocab_size_multiple", "if", "not", "share_vocab", "else", "1", ")", "\n", "\n", "history_multifield", "=", "fields", "[", "\"history\"", "]", "\n", "_build_fv_from_multifield", "(", "\n", "history_multifield", ",", "\n", "counters", ",", "\n", "build_fv_args", ",", "\n", "size_multiple", "=", "vocab_size_multiple", "if", "not", "share_vocab", "else", "1", ")", "\n", "ans_multifield", "=", "fields", "[", "\"ans\"", "]", "\n", "\n", "if", "share_vocab", ":", "\n", "# `tgt_vocab_size` is ignored when sharing vocabularies", "\n", "            ", "logger", ".", "info", "(", "\" * merging src and tgt vocab...\"", ")", "\n", "src_field", "=", "src_multifield", ".", "base_field", "\n", "history_field", "=", "history_multifield", ".", "base_field", "\n", "ans_field", "=", "ans_multifield", ".", "base_field", "\n", "tgt_field", "=", "tgt_multifield", ".", "base_field", "\n", "_merge_field_vocabs", "(", "\n", "src_field", ",", "history_field", ",", "ans_field", ",", "tgt_field", ",", "vocab_size", "=", "src_vocab_size", ",", "\n", "min_freq", "=", "src_words_min_frequency", ",", "\n", "vocab_size_multiple", "=", "vocab_size_multiple", ")", "\n", "logger", ".", "info", "(", "\" * merged vocab size: %d.\"", "%", "len", "(", "src_field", ".", "vocab", ")", ")", "\n", "", "", "return", "fields", "# is the return necessary?", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._merge_field_vocabs": [[439, 459], ["sum", "torchtext.vocab.Vocab", "collections.Counter", "inputter._pad_vocab_to_multiple", "len", "len"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._pad_vocab_to_multiple"], ["", "def", "_merge_field_vocabs", "(", "src_field", ",", "history_field", ",", "ans_field", ",", "tgt_field", ",", "vocab_size", ",", "min_freq", ",", "\n", "vocab_size_multiple", ")", ":", "\n", "# in the long run, shouldn't it be possible to do this by calling", "\n", "# build_vocab with both the src and tgt data?", "\n", "    ", "specials", "=", "[", "tgt_field", ".", "unk_token", ",", "tgt_field", ".", "pad_token", ",", "\n", "tgt_field", ".", "init_token", ",", "tgt_field", ".", "eos_token", "]", "\n", "merged", "=", "sum", "(", "\n", "[", "src_field", ".", "vocab", ".", "freqs", ",", "history_field", ".", "vocab", ".", "freqs", ",", "tgt_field", ".", "vocab", ".", "freqs", "]", ",", "Counter", "(", ")", "\n", ")", "\n", "merged_vocab", "=", "Vocab", "(", "\n", "merged", ",", "specials", "=", "specials", ",", "\n", "max_size", "=", "vocab_size", ",", "min_freq", "=", "min_freq", "\n", ")", "\n", "if", "vocab_size_multiple", ">", "1", ":", "\n", "        ", "_pad_vocab_to_multiple", "(", "merged_vocab", ",", "vocab_size_multiple", ")", "\n", "", "src_field", ".", "vocab", "=", "merged_vocab", "\n", "history_field", ".", "vocab", "=", "merged_vocab", "\n", "tgt_field", ".", "vocab", "=", "merged_vocab", "\n", "ans_field", ".", "vocab", "=", "merged_vocab", "\n", "assert", "len", "(", "src_field", ".", "vocab", ")", "==", "len", "(", "tgt_field", ".", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._read_vocab_file": [[461, 480], ["onmt.utils.logging.logger.info", "os.path.exists", "RuntimeError", "codecs.open", "line.strip().split", "line.strip", "line.strip"], "function", ["None"], ["", "def", "_read_vocab_file", "(", "vocab_path", ",", "tag", ")", ":", "\n", "    ", "\"\"\"Loads a vocabulary from the given path.\n\n    Args:\n        vocab_path (str): Path to utf-8 text file containing vocabulary.\n            Each token should be on a line by itself. Tokens must not\n            contain whitespace (else only before the whitespace\n            is considered).\n        tag (str): Used for logging which vocab is being read.\n    \"\"\"", "\n", "\n", "logger", ".", "info", "(", "\"Loading {} vocabulary from {}\"", ".", "format", "(", "tag", ",", "vocab_path", ")", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "vocab_path", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "\n", "\"{} vocabulary not found at {}\"", ".", "format", "(", "tag", ",", "vocab_path", ")", ")", "\n", "", "else", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "vocab_path", ",", "'r'", ",", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "return", "[", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "0", "]", "for", "line", "in", "f", "if", "line", ".", "strip", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.batch_iter": [[482, 513], ["minibatch.append", "inputter.batch_iter.batch_size_fn"], "function", ["None"], ["", "", "", "def", "batch_iter", "(", "data", ",", "batch_size", ",", "batch_size_fn", "=", "None", ",", "batch_size_multiple", "=", "1", ")", ":", "\n", "    ", "\"\"\"Yield elements from data in chunks of batch_size, where each chunk size\n    is a multiple of batch_size_multiple.\n\n    This is an extended version of torchtext.data.batch.\n    \"\"\"", "\n", "if", "batch_size_fn", "is", "None", ":", "\n", "        ", "def", "batch_size_fn", "(", "new", ",", "count", ",", "sofar", ")", ":", "\n", "            ", "return", "count", "\n", "", "", "minibatch", ",", "size_so_far", "=", "[", "]", ",", "0", "\n", "for", "ex", "in", "data", ":", "\n", "        ", "minibatch", ".", "append", "(", "ex", ")", "\n", "size_so_far", "=", "batch_size_fn", "(", "ex", ",", "len", "(", "minibatch", ")", ",", "size_so_far", ")", "\n", "if", "size_so_far", ">=", "batch_size", ":", "\n", "            ", "overflowed", "=", "0", "\n", "if", "size_so_far", ">", "batch_size", ":", "\n", "                ", "overflowed", "+=", "1", "\n", "", "if", "batch_size_multiple", ">", "1", ":", "\n", "                ", "overflowed", "+=", "(", "\n", "(", "len", "(", "minibatch", ")", "-", "overflowed", ")", "%", "batch_size_multiple", ")", "\n", "", "if", "overflowed", "==", "0", ":", "\n", "                ", "yield", "minibatch", "\n", "minibatch", ",", "size_so_far", "=", "[", "]", ",", "0", "\n", "", "else", ":", "\n", "                ", "yield", "minibatch", "[", ":", "-", "overflowed", "]", "\n", "minibatch", "=", "minibatch", "[", "-", "overflowed", ":", "]", "\n", "size_so_far", "=", "0", "\n", "for", "i", ",", "ex", "in", "enumerate", "(", "minibatch", ")", ":", "\n", "                    ", "size_so_far", "=", "batch_size_fn", "(", "ex", ",", "i", "+", "1", ",", "size_so_far", ")", "\n", "", "", "", "", "if", "minibatch", ":", "\n", "        ", "yield", "minibatch", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.max_tok_len": [[627, 646], ["max", "max", "max", "len", "len"], "function", ["None"], ["", "", "", "", "", "", "def", "max_tok_len", "(", "new", ",", "count", ",", "sofar", ")", ":", "\n", "    ", "\"\"\"\n    In token batching scheme, the number of sequences is limited\n    such that the total number of src/tgt tokens (including padding)\n    in a batch <= batch_size\n    \"\"\"", "\n", "# Maintains the longest src and tgt length in the current batch", "\n", "global", "max_src_in_batch", ",", "max_tgt_in_batch", "# this is a hack", "\n", "# Reset current longest length at a new batch (count=1)", "\n", "if", "count", "==", "1", ":", "\n", "        ", "max_src_in_batch", "=", "0", "\n", "max_tgt_in_batch", "=", "0", "\n", "# Src: [<bos> w1 ... wN <eos>]", "\n", "", "max_src_in_batch", "=", "max", "(", "max_src_in_batch", ",", "len", "(", "new", ".", "src", "[", "0", "]", ")", "+", "2", ")", "\n", "# Tgt: [w1 ... wM <eos>]", "\n", "max_tgt_in_batch", "=", "max", "(", "max_tgt_in_batch", ",", "len", "(", "new", ".", "tgt", "[", "0", "]", ")", "+", "1", ")", "\n", "src_elements", "=", "count", "*", "max_src_in_batch", "\n", "tgt_elements", "=", "count", "*", "max_tgt_in_batch", "\n", "return", "max", "(", "src_elements", ",", "tgt_elements", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.build_dataset_iter": [[648, 674], ["list", "inputter.DatasetLazyIter", "sorted", "glob.glob"], "function", ["None"], ["", "def", "build_dataset_iter", "(", "corpus_type", ",", "fields", ",", "opt", ",", "is_train", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    This returns user-defined train/validate data iterator for the trainer\n    to iterate over. We implement simple ordered iterator strategy here,\n    but more sophisticated strategy like curriculum learning is ok too.\n    \"\"\"", "\n", "dataset_paths", "=", "list", "(", "sorted", "(", "\n", "glob", ".", "glob", "(", "opt", ".", "data", "+", "'.'", "+", "corpus_type", "+", "'*.pt'", ")", ")", ")", "\n", "if", "not", "dataset_paths", ":", "\n", "        ", "return", "None", "\n", "", "batch_size", "=", "opt", ".", "batch_size", "if", "is_train", "else", "opt", ".", "valid_batch_size", "\n", "batch_fn", "=", "max_tok_len", "if", "is_train", "and", "opt", ".", "batch_type", "==", "\"tokens\"", "else", "None", "\n", "batch_size_multiple", "=", "8", "if", "opt", ".", "model_dtype", "==", "\"fp16\"", "else", "1", "\n", "\n", "device", "=", "\"cuda\"", "if", "opt", ".", "gpu_ranks", "else", "\"cpu\"", "\n", "\n", "return", "DatasetLazyIter", "(", "\n", "dataset_paths", ",", "\n", "fields", ",", "\n", "batch_size", ",", "\n", "batch_fn", ",", "\n", "batch_size_multiple", ",", "\n", "device", ",", "\n", "is_train", ",", "\n", "repeat", "=", "not", "opt", ".", "single_pass", ",", "\n", "num_batches_multiple", "=", "opt", ".", "accum_count", "*", "opt", ".", "world_size", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.datareader_base.DataReaderBase.from_opt": [[19, 28], ["cls"], "methods", ["None"], ["@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Alternative constructor.\n\n        Args:\n            opt (argparse.Namespace): The parsed arguments.\n        \"\"\"", "\n", "\n", "return", "cls", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.datareader_base.DataReaderBase._read_file": [[29, 35], ["open"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_read_file", "(", "cls", ",", "path", ")", ":", "\n", "        ", "\"\"\"Line-by-line read a file as bytes.\"\"\"", "\n", "with", "open", "(", "path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "yield", "line", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.datareader_base.DataReaderBase._raise_missing_dep": [[36, 42], ["datareader_base.MissingDependencyException"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "_raise_missing_dep", "(", "*", "missing_deps", ")", ":", "\n", "        ", "\"\"\"Raise missing dep exception with standard error message.\"\"\"", "\n", "raise", "MissingDependencyException", "(", "\n", "\"Could not create reader. Be sure to install \"", "\n", "\"the following dependencies: \"", "+", "\", \"", ".", "join", "(", "missing_deps", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.datareader_base.DataReaderBase.read": [[43, 46], ["NotImplementedError"], "methods", ["None"], ["", "def", "read", "(", "self", ",", "data", ",", "side", ",", "src_dir", ")", ":", "\n", "        ", "\"\"\"Read data from file system and yield as dicts.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.dataset_base.Dataset.__init__": [[109, 142], ["itertools.starmap", "ex_fields.items", "torchtext.data.Dataset.__init__", "r.read", "zip", "torchtext.data.Example.fromdict", "fields.append", "len", "len", "len", "len", "zip", "dataset_base._dynamic_dict", "examples.append", "len", "fields.items", "filter_pred", "dataset_base.Dataset.src_vocabs.append"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.datareader_base.DataReaderBase.read", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.dataset_base._dynamic_dict", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.coqa_dataset.filter_pred"], ["def", "__init__", "(", "self", ",", "fields", ",", "readers", ",", "data", ",", "dirs", ",", "sort_key", ",", "\n", "filter_pred", "=", "None", ")", ":", "\n", "        ", "self", ".", "sort_key", "=", "sort_key", "\n", "can_copy", "=", "'src_map'", "in", "fields", "and", "'alignment'", "in", "fields", "\n", "read_iters", "=", "[", "r", ".", "read", "(", "dat", "[", "1", "]", ",", "dat", "[", "0", "]", ",", "dir_", ")", "for", "r", ",", "dat", ",", "dir_", "\n", "in", "zip", "(", "readers", ",", "data", ",", "dirs", ")", "]", "\n", "# self.src_vocabs is used in collapse_copy_scores and Translator.py", "\n", "self", ".", "src_vocabs", "=", "[", "]", "\n", "examples", "=", "[", "]", "\n", "for", "ex_dict", "in", "starmap", "(", "_join_dicts", ",", "zip", "(", "*", "read_iters", ")", ")", ":", "\n", "            ", "src_ex_vocab", "=", "None", "\n", "if", "can_copy", ":", "\n", "                ", "src_field", "=", "fields", "[", "'src'", "]", "\n", "tgt_field", "=", "fields", "[", "'tgt'", "]", "\n", "# this assumes src_field and tgt_field are both text", "\n", "src_ex_vocab", ",", "ex_dict", "=", "_dynamic_dict", "(", "\n", "ex_dict", ",", "src_field", ".", "base_field", ",", "tgt_field", ".", "base_field", ")", "\n", "", "ex_fields", "=", "{", "k", ":", "[", "(", "k", ",", "v", ")", "]", "for", "k", ",", "v", "in", "fields", ".", "items", "(", ")", "if", "\n", "k", "in", "ex_dict", "}", "\n", "ex", "=", "Example", ".", "fromdict", "(", "ex_dict", ",", "ex_fields", ")", "\n", "if", "(", "filter_pred", "is", "not", "None", "and", "filter_pred", "(", "ex", ")", ")", "or", "(", "filter_pred", "is", "None", ")", ":", "\n", "                ", "examples", ".", "append", "(", "ex", ")", "\n", "if", "can_copy", ":", "\n", "                    ", "self", ".", "src_vocabs", ".", "append", "(", "src_ex_vocab", ")", "\n", "\n", "# fields needs to have only keys that examples have as attrs", "\n", "", "", "", "fields", "=", "[", "]", "\n", "for", "_", ",", "nf_list", "in", "ex_fields", ".", "items", "(", ")", ":", "\n", "            ", "assert", "len", "(", "nf_list", ")", "==", "1", "\n", "fields", ".", "append", "(", "nf_list", "[", "0", "]", ")", "\n", "", "assert", "len", "(", "examples", ")", "==", "len", "(", "self", ".", "src_vocabs", ")", ",", "\"example {}, src_vocabs {}\"", ".", "format", "(", "len", "(", "examples", ")", ",", "len", "(", "self", ".", "src_vocabs", ")", ")", "\n", "\n", "super", "(", "Dataset", ",", "self", ")", ".", "__init__", "(", "examples", ",", "fields", ",", "filter_pred", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.dataset_base.Dataset.__getattr__": [[143, 151], ["vars", "getattr"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "attr", ")", ":", "\n", "# avoid infinite recursion when fields isn't defined", "\n", "        ", "if", "'fields'", "not", "in", "vars", "(", "self", ")", ":", "\n", "            ", "raise", "AttributeError", "\n", "", "if", "attr", "in", "self", ".", "fields", ":", "\n", "            ", "return", "(", "getattr", "(", "x", ",", "attr", ")", "for", "x", "in", "self", ".", "examples", ")", "\n", "", "else", ":", "\n", "            ", "raise", "AttributeError", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.dataset_base.Dataset.save": [[152, 156], ["torch.save"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.ModelSaverBase.save"], ["", "", "def", "save", "(", "self", ",", "path", ",", "remove_fields", "=", "True", ")", ":", "\n", "        ", "if", "remove_fields", ":", "\n", "            ", "self", ".", "fields", "=", "[", "]", "\n", "", "torch", ".", "save", "(", "self", ",", "path", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.dataset_base._join_dicts": [[12, 22], ["dict", "itertools.chain", "d.items"], "function", ["None"], ["def", "_join_dicts", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        dictionaries with disjoint keys.\n\n    Returns:\n        a single dictionary that has the union of these keys.\n    \"\"\"", "\n", "\n", "return", "dict", "(", "chain", "(", "*", "[", "d", ".", "items", "(", ")", "for", "d", "in", "args", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.dataset_base._dynamic_dict": [[24, 60], ["src_field.tokenize", "torchtext.vocab.Vocab", "torch.LongTensor", "collections.Counter", "tgt_field.tokenize", "torch.LongTensor"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.tokenize", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.tokenize"], ["", "def", "_dynamic_dict", "(", "example", ",", "src_field", ",", "tgt_field", ")", ":", "\n", "    ", "\"\"\"Create copy-vocab and numericalize with it.\n\n    In-place adds ``\"src_map\"`` to ``example``. That is the copy-vocab\n    numericalization of the tokenized ``example[\"src\"]``. If ``example``\n    has a ``\"tgt\"`` key, adds ``\"alignment\"`` to example. That is the\n    copy-vocab numericalization of the tokenized ``example[\"tgt\"]``. The\n    alignment has an initial and final UNK token to match the BOS and EOS\n    tokens.\n\n    Args:\n        example (dict): An example dictionary with a ``\"src\"`` key and\n            maybe a ``\"tgt\"`` key. (This argument changes in place!)\n        src_field (torchtext.data.Field): Field object.\n        tgt_field (torchtext.data.Field): Field object.\n\n    Returns:\n        torchtext.data.Vocab and ``example``, changed as described.\n    \"\"\"", "\n", "\n", "src", "=", "src_field", ".", "tokenize", "(", "example", "[", "\"src\"", "]", ")", "\n", "# make a small vocab containing just the tokens in the source sequence", "\n", "unk", "=", "src_field", ".", "unk_token", "\n", "pad", "=", "src_field", ".", "pad_token", "\n", "src_ex_vocab", "=", "Vocab", "(", "Counter", "(", "src", ")", ",", "specials", "=", "[", "unk", ",", "pad", "]", ")", "\n", "unk_idx", "=", "src_ex_vocab", ".", "stoi", "[", "unk", "]", "\n", "# Map source tokens to indices in the dynamic dict.", "\n", "src_map", "=", "torch", ".", "LongTensor", "(", "[", "src_ex_vocab", ".", "stoi", "[", "w", "]", "for", "w", "in", "src", "]", ")", "\n", "example", "[", "\"src_map\"", "]", "=", "src_map", "\n", "\n", "if", "\"tgt\"", "in", "example", ":", "\n", "        ", "tgt", "=", "tgt_field", ".", "tokenize", "(", "example", "[", "\"tgt\"", "]", ")", "\n", "mask", "=", "torch", ".", "LongTensor", "(", "\n", "[", "unk_idx", "]", "+", "[", "src_ex_vocab", ".", "stoi", "[", "w", "]", "for", "w", "in", "tgt", "]", "+", "[", "unk_idx", "]", ")", "\n", "example", "[", "\"alignment\"", "]", "=", "mask", "\n", "", "return", "src_ex_vocab", ",", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.util_class.Elementwise.__init__": [[18, 22], ["torch.ModuleList.__init__"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "merge", "=", "None", ",", "*", "args", ")", ":", "\n", "        ", "assert", "merge", "in", "[", "None", ",", "'first'", ",", "'concat'", ",", "'sum'", ",", "'mlp'", "]", "\n", "self", ".", "merge", "=", "merge", "\n", "super", "(", "Elementwise", ",", "self", ")", ".", "__init__", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.util_class.Elementwise.forward": [[23, 35], ["feat.squeeze", "len", "len", "f", "inputs.split", "zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sum"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "inputs_", "=", "[", "feat", ".", "squeeze", "(", "2", ")", "for", "feat", "in", "inputs", ".", "split", "(", "1", ",", "dim", "=", "2", ")", "]", "\n", "assert", "len", "(", "self", ")", "==", "len", "(", "inputs_", ")", "\n", "outputs", "=", "[", "f", "(", "x", ")", "for", "f", ",", "x", "in", "zip", "(", "self", ",", "inputs_", ")", "]", "\n", "if", "self", ".", "merge", "==", "'first'", ":", "\n", "            ", "return", "outputs", "[", "0", "]", "\n", "", "elif", "self", ".", "merge", "==", "'concat'", "or", "self", ".", "merge", "==", "'mlp'", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "outputs", ",", "2", ")", "\n", "", "elif", "self", ".", "merge", "==", "'sum'", ":", "\n", "            ", "return", "sum", "(", "outputs", ")", "\n", "", "else", ":", "\n", "            ", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.util_class.Cast.__init__": [[43, 46], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "dtype", ")", ":", "\n", "        ", "super", "(", "Cast", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_dtype", "=", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.util_class.Cast.forward": [[47, 49], ["x.to"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", ".", "to", "(", "self", ".", "_dtype", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.conv_multi_step_attention.ConvMultiStepAttention.__init__": [[27, 31], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ")", ":", "\n", "        ", "super", "(", "ConvMultiStepAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear_in", "=", "nn", ".", "Linear", "(", "input_size", ",", "input_size", ")", "\n", "self", ".", "mask", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.conv_multi_step_attention.ConvMultiStepAttention.apply_mask": [[32, 35], ["None"], "methods", ["None"], ["", "def", "apply_mask", "(", "self", ",", "mask", ")", ":", "\n", "        ", "\"\"\" Apply mask \"\"\"", "\n", "self", ".", "mask", "=", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.conv_multi_step_attention.ConvMultiStepAttention.forward": [[36, 81], ["base_target_emb.size", "input_from_dec.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "encoder_out_top.size", "encoder_out_combine.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "conv_multi_step_attention.seq_linear", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.bmm.data.masked_fill_", "torch.bmm.data.masked_fill_", "torch.bmm.data.masked_fill_", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "float"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.conv_multi_step_attention.seq_linear", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "forward", "(", "self", ",", "base_target_emb", ",", "input_from_dec", ",", "encoder_out_top", ",", "\n", "encoder_out_combine", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            base_target_emb: target emb tensor\n            input_from_dec: output of decode conv\n            encoder_out_top: the key matrix for calculation of attetion weight,\n                which is the top output of encode conv\n            encoder_out_combine:\n                the value matrix for the attention-weighted sum,\n                which is the combination of base emb and top output of encode\n        \"\"\"", "\n", "\n", "# checks", "\n", "# batch, channel, height, width = base_target_emb.size()", "\n", "batch", ",", "_", ",", "height", ",", "_", "=", "base_target_emb", ".", "size", "(", ")", "\n", "# batch_, channel_, height_, width_ = input_from_dec.size()", "\n", "batch_", ",", "_", ",", "height_", ",", "_", "=", "input_from_dec", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "height", ",", "height_", ")", "\n", "\n", "# enc_batch, enc_channel, enc_height = encoder_out_top.size()", "\n", "enc_batch", ",", "_", ",", "enc_height", "=", "encoder_out_top", ".", "size", "(", ")", "\n", "# enc_batch_, enc_channel_, enc_height_ = encoder_out_combine.size()", "\n", "enc_batch_", ",", "_", ",", "enc_height_", "=", "encoder_out_combine", ".", "size", "(", ")", "\n", "\n", "aeq", "(", "enc_batch", ",", "enc_batch_", ")", "\n", "aeq", "(", "enc_height", ",", "enc_height_", ")", "\n", "\n", "preatt", "=", "seq_linear", "(", "self", ".", "linear_in", ",", "input_from_dec", ")", "\n", "target", "=", "(", "base_target_emb", "+", "preatt", ")", "*", "SCALE_WEIGHT", "\n", "target", "=", "torch", ".", "squeeze", "(", "target", ",", "3", ")", "\n", "target", "=", "torch", ".", "transpose", "(", "target", ",", "1", ",", "2", ")", "\n", "pre_attn", "=", "torch", ".", "bmm", "(", "target", ",", "encoder_out_top", ")", "\n", "\n", "if", "self", ".", "mask", "is", "not", "None", ":", "\n", "            ", "pre_attn", ".", "data", ".", "masked_fill_", "(", "self", ".", "mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "", "attn", "=", "F", ".", "softmax", "(", "pre_attn", ",", "dim", "=", "2", ")", "\n", "\n", "context_output", "=", "torch", ".", "bmm", "(", "\n", "attn", ",", "torch", ".", "transpose", "(", "encoder_out_combine", ",", "1", ",", "2", ")", ")", "\n", "context_output", "=", "torch", ".", "transpose", "(", "\n", "torch", ".", "unsqueeze", "(", "context_output", ",", "3", ")", ",", "1", ",", "2", ")", "\n", "return", "context_output", ",", "attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.conv_multi_step_attention.seq_linear": [[11, 17], ["x.size", "linear", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "linear.view", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose", "torch.transpose", "torch.transpose"], "function", ["None"], ["def", "seq_linear", "(", "linear", ",", "x", ")", ":", "\n", "    ", "\"\"\" linear transform for 3-d tensor \"\"\"", "\n", "batch", ",", "hidden_size", ",", "length", ",", "_", "=", "x", ".", "size", "(", ")", "\n", "h", "=", "linear", "(", "torch", ".", "transpose", "(", "x", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "batch", "*", "length", ",", "hidden_size", ")", ")", "\n", "return", "torch", ".", "transpose", "(", "h", ".", "view", "(", "batch", ",", "length", ",", "hidden_size", ",", "1", ")", ",", "1", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.multi_headed_attn.MultiHeadedAttention.__init__": [[51, 76], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "head_count", ",", "model_dim", ",", "dropout", "=", "0.1", ",", "\n", "max_relative_positions", "=", "0", ")", ":", "\n", "        ", "assert", "model_dim", "%", "head_count", "==", "0", "\n", "self", ".", "dim_per_head", "=", "model_dim", "//", "head_count", "\n", "self", ".", "model_dim", "=", "model_dim", "\n", "\n", "super", "(", "MultiHeadedAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "head_count", "=", "head_count", "\n", "\n", "self", ".", "linear_keys", "=", "nn", ".", "Linear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ")", "\n", "self", ".", "linear_values", "=", "nn", ".", "Linear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ")", "\n", "self", ".", "linear_query", "=", "nn", ".", "Linear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "final_linear", "=", "nn", ".", "Linear", "(", "model_dim", ",", "model_dim", ")", "\n", "\n", "self", ".", "max_relative_positions", "=", "max_relative_positions", "\n", "\n", "if", "max_relative_positions", ">", "0", ":", "\n", "            ", "vocab_size", "=", "max_relative_positions", "*", "2", "+", "1", "\n", "self", ".", "relative_positions_embeddings", "=", "nn", ".", "Embedding", "(", "\n", "vocab_size", ",", "self", ".", "dim_per_head", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.multi_headed_attn.MultiHeadedAttention.forward": [[77, 230], ["shape.size", "shape.size", "multi_headed_attn.MultiHeadedAttention.size", "multi_headed_attn.MultiHeadedAttention.forward.shape"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "key", ",", "value", ",", "query", ",", "mask", "=", "None", ",", "\n", "layer_cache", "=", "None", ",", "type", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Compute the context vector and the attention vectors.\n\n        Args:\n           key (FloatTensor): set of `key_len`\n               key vectors ``(batch, key_len, dim)``\n           value (FloatTensor): set of `key_len`\n               value vectors ``(batch, key_len, dim)``\n           query (FloatTensor): set of `query_len`\n               query vectors  ``(batch, query_len, dim)``\n           mask: binary mask indicating which keys have\n               non-zero attention ``(batch, query_len, key_len)``\n        Returns:\n           (FloatTensor, FloatTensor):\n\n           * output context vectors ``(batch, query_len, dim)``\n           * one of the attention vectors ``(batch, query_len, key_len)``\n        \"\"\"", "\n", "\n", "# CHECKS", "\n", "# batch, k_len, d = key.size()", "\n", "# batch_, k_len_, d_ = value.size()", "\n", "# aeq(batch, batch_)", "\n", "# aeq(k_len, k_len_)", "\n", "# aeq(d, d_)", "\n", "# batch_, q_len, d_ = query.size()", "\n", "# aeq(batch, batch_)", "\n", "# aeq(d, d_)", "\n", "# aeq(self.model_dim % 8, 0)", "\n", "# if mask is not None:", "\n", "#    batch_, q_len_, k_len_ = mask.size()", "\n", "#    aeq(batch_, batch)", "\n", "#    aeq(k_len_, k_len)", "\n", "#    aeq(q_len_ == q_len)", "\n", "# END CHECKS", "\n", "\n", "batch_size", "=", "key", ".", "size", "(", "0", ")", "\n", "dim_per_head", "=", "self", ".", "dim_per_head", "\n", "head_count", "=", "self", ".", "head_count", "\n", "key_len", "=", "key", ".", "size", "(", "1", ")", "\n", "query_len", "=", "query", ".", "size", "(", "1", ")", "\n", "device", "=", "key", ".", "device", "\n", "\n", "def", "shape", "(", "x", ")", ":", "\n", "            ", "\"\"\"Projection.\"\"\"", "\n", "return", "x", ".", "view", "(", "batch_size", ",", "-", "1", ",", "head_count", ",", "dim_per_head", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "", "def", "unshape", "(", "x", ")", ":", "\n", "            ", "\"\"\"Compute context.\"\"\"", "\n", "return", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ",", "head_count", "*", "dim_per_head", ")", "\n", "\n", "# 1) Project key, value, and query.", "\n", "", "if", "layer_cache", "is", "not", "None", ":", "\n", "            ", "if", "type", "==", "\"self\"", ":", "\n", "                ", "query", ",", "key", ",", "value", "=", "self", ".", "linear_query", "(", "query", ")", ",", "self", ".", "linear_keys", "(", "query", ")", ",", "self", ".", "linear_values", "(", "query", ")", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "if", "layer_cache", "[", "\"self_keys\"", "]", "is", "not", "None", ":", "\n", "                    ", "key", "=", "torch", ".", "cat", "(", "\n", "(", "layer_cache", "[", "\"self_keys\"", "]", ".", "to", "(", "device", ")", ",", "key", ")", ",", "\n", "dim", "=", "2", ")", "\n", "", "if", "layer_cache", "[", "\"self_values\"", "]", "is", "not", "None", ":", "\n", "                    ", "value", "=", "torch", ".", "cat", "(", "\n", "(", "layer_cache", "[", "\"self_values\"", "]", ".", "to", "(", "device", ")", ",", "value", ")", ",", "\n", "dim", "=", "2", ")", "\n", "", "layer_cache", "[", "\"self_keys\"", "]", "=", "key", "\n", "layer_cache", "[", "\"self_values\"", "]", "=", "value", "\n", "", "elif", "type", "==", "\"context\"", ":", "\n", "                ", "query", "=", "self", ".", "linear_query", "(", "query", ")", "\n", "if", "layer_cache", "[", "\"memory_keys\"", "]", "is", "None", ":", "\n", "                    ", "key", ",", "value", "=", "self", ".", "linear_keys", "(", "key", ")", ",", "self", ".", "linear_values", "(", "value", ")", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "", "else", ":", "\n", "                    ", "key", ",", "value", "=", "layer_cache", "[", "\"memory_keys\"", "]", ",", "layer_cache", "[", "\"memory_values\"", "]", "\n", "", "layer_cache", "[", "\"memory_keys\"", "]", "=", "key", "\n", "layer_cache", "[", "\"memory_values\"", "]", "=", "value", "\n", "", "", "else", ":", "\n", "            ", "key", "=", "self", ".", "linear_keys", "(", "key", ")", "\n", "value", "=", "self", ".", "linear_values", "(", "value", ")", "\n", "query", "=", "self", ".", "linear_query", "(", "query", ")", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "\n", "", "if", "self", ".", "max_relative_positions", ">", "0", "and", "type", "==", "\"self\"", ":", "\n", "            ", "key_len", "=", "key", ".", "size", "(", "2", ")", "\n", "# 1 or key_len x key_len", "\n", "relative_positions_matrix", "=", "generate_relative_positions_matrix", "(", "\n", "key_len", ",", "self", ".", "max_relative_positions", ",", "\n", "cache", "=", "True", "if", "layer_cache", "is", "not", "None", "else", "False", ")", "\n", "#  1 or key_len x key_len x dim_per_head", "\n", "relations_keys", "=", "self", ".", "relative_positions_embeddings", "(", "\n", "relative_positions_matrix", ".", "to", "(", "device", ")", ")", "\n", "#  1 or key_len x key_len x dim_per_head", "\n", "relations_values", "=", "self", ".", "relative_positions_embeddings", "(", "\n", "relative_positions_matrix", ".", "to", "(", "device", ")", ")", "\n", "\n", "", "query", "=", "shape", "(", "query", ")", "\n", "\n", "key_len", "=", "key", ".", "size", "(", "2", ")", "\n", "query_len", "=", "query", ".", "size", "(", "2", ")", "\n", "\n", "# 2) Calculate and scale scores.", "\n", "query", "=", "query", "/", "math", ".", "sqrt", "(", "dim_per_head", ")", "\n", "# batch x num_heads x query_len x key_len", "\n", "query_key", "=", "torch", ".", "matmul", "(", "query", ",", "key", ".", "transpose", "(", "2", ",", "3", ")", ")", "\n", "\n", "if", "self", ".", "max_relative_positions", ">", "0", "and", "type", "==", "\"self\"", ":", "\n", "            ", "scores", "=", "query_key", "+", "relative_matmul", "(", "query", ",", "relations_keys", ",", "True", ")", "\n", "", "else", ":", "\n", "            ", "scores", "=", "query_key", "\n", "", "scores", "=", "scores", ".", "float", "(", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "# [B, 1, 1, T_values]", "\n", "scores", "=", "scores", ".", "masked_fill", "(", "mask", ",", "-", "1e18", ")", "\n", "\n", "# 3) Apply attention dropout and compute context vectors.", "\n", "", "attn", "=", "self", ".", "softmax", "(", "scores", ")", ".", "to", "(", "query", ".", "dtype", ")", "\n", "drop_attn", "=", "self", ".", "dropout", "(", "attn", ")", "\n", "\n", "context_original", "=", "torch", ".", "matmul", "(", "drop_attn", ",", "value", ")", "\n", "\n", "if", "self", ".", "max_relative_positions", ">", "0", "and", "type", "==", "\"self\"", ":", "\n", "            ", "context", "=", "unshape", "(", "context_original", "\n", "+", "relative_matmul", "(", "drop_attn", ",", "\n", "relations_values", ",", "\n", "False", ")", ")", "\n", "", "else", ":", "\n", "            ", "context", "=", "unshape", "(", "context_original", ")", "\n", "\n", "", "output", "=", "self", ".", "final_linear", "(", "context", ")", "\n", "# CHECK", "\n", "# batch_, q_len_, d_ = output.size()", "\n", "# aeq(q_len, q_len_)", "\n", "# aeq(batch, batch_)", "\n", "# aeq(d, d_)", "\n", "\n", "# Return one attn", "\n", "top_attn", "=", "attn", ".", "view", "(", "batch_size", ",", "head_count", ",", "\n", "query_len", ",", "key_len", ")", "[", ":", ",", "0", ",", ":", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "\n", "return", "output", ",", "top_attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.structured_attention.MatrixTree.__init__": [[13, 16], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "eps", "=", "1e-5", ")", ":", "\n", "        ", "self", ".", "eps", "=", "eps", "\n", "super", "(", "MatrixTree", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.structured_attention.MatrixTree.forward": [[17, 39], ["input.clone", "range", "input.exp", "input.size", "laplacian[].masked_fill", "input[].diag().exp", "laplacian[].masked_fill.inverse", "laplacian[].masked_fill.inverse.diag().unsqueeze().expand_as().transpose", "input[].exp().mul().clone", "input[].exp().mul().clone", "input[].diag().exp().mul", "torch.eye().ne", "torch.eye().ne", "torch.eye().ne", "torch.eye().ne", "torch.eye().ne", "torch.eye().ne", "torch.eye().ne", "torch.eye().ne", "torch.eye().ne", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "laplacian[].masked_fill.sum", "input[].diag", "laplacian[].masked_fill.inverse.diag().unsqueeze().expand_as", "input[].exp().mul", "input[].exp().mul", "input[].diag().exp", "laplacian[].masked_fill.inverse.transpose", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "laplacian[].masked_fill.inverse.transpose", "input.size", "laplacian[].masked_fill.inverse.diag().unsqueeze", "input[].exp", "input[].exp", "input[].diag", "laplacian[].masked_fill.inverse.diag"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "laplacian", "=", "input", ".", "exp", "(", ")", "+", "self", ".", "eps", "\n", "output", "=", "input", ".", "clone", "(", ")", "\n", "for", "b", "in", "range", "(", "input", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "lap", "=", "laplacian", "[", "b", "]", ".", "masked_fill", "(", "\n", "torch", ".", "eye", "(", "input", ".", "size", "(", "1", ")", ",", "device", "=", "input", ".", "device", ")", ".", "ne", "(", "0", ")", ",", "0", ")", "\n", "lap", "=", "-", "lap", "+", "torch", ".", "diag", "(", "lap", ".", "sum", "(", "0", ")", ")", "\n", "# store roots on diagonal", "\n", "lap", "[", "0", "]", "=", "input", "[", "b", "]", ".", "diag", "(", ")", ".", "exp", "(", ")", "\n", "inv_laplacian", "=", "lap", ".", "inverse", "(", ")", "\n", "\n", "factor", "=", "inv_laplacian", ".", "diag", "(", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "input", "[", "b", "]", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "term1", "=", "input", "[", "b", "]", ".", "exp", "(", ")", ".", "mul", "(", "factor", ")", ".", "clone", "(", ")", "\n", "term2", "=", "input", "[", "b", "]", ".", "exp", "(", ")", ".", "mul", "(", "inv_laplacian", ".", "transpose", "(", "0", ",", "1", ")", ")", ".", "clone", "(", ")", "\n", "term1", "[", ":", ",", "0", "]", "=", "0", "\n", "term2", "[", "0", "]", "=", "0", "\n", "output", "[", "b", "]", "=", "term1", "-", "term2", "\n", "roots_output", "=", "input", "[", "b", "]", ".", "diag", "(", ")", ".", "exp", "(", ")", ".", "mul", "(", "\n", "inv_laplacian", ".", "transpose", "(", "0", ",", "1", ")", "[", "0", "]", ")", "\n", "output", "[", "b", "]", "=", "output", "[", "b", "]", "+", "torch", ".", "diag", "(", "roots_output", ")", "\n", "", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.average_attn.AverageAttention.__init__": [[22, 30], ["torch.Module.__init__", "onmt.modules.position_ffn.PositionwiseFeedForward", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "model_dim", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "model_dim", "=", "model_dim", "\n", "\n", "super", "(", "AverageAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "average_layer", "=", "PositionwiseFeedForward", "(", "model_dim", ",", "model_dim", ",", "\n", "dropout", ")", "\n", "self", ".", "gating_layer", "=", "nn", ".", "Linear", "(", "model_dim", "*", "2", ",", "model_dim", "*", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.average_attn.AverageAttention.cumulative_average_mask": [[31, 52], ["torch.tril", "torch.tril", "torch.tril", "torch.tril", "mask.unsqueeze().expand", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "weights.transpose", "mask.unsqueeze"], "methods", ["None"], ["", "def", "cumulative_average_mask", "(", "self", ",", "batch_size", ",", "inputs_len", ")", ":", "\n", "        ", "\"\"\"\n        Builds the mask to compute the cumulative average as described in\n        :cite:`DBLP:journals/corr/abs-1805-00631` -- Figure 3\n\n        Args:\n            batch_size (int): batch size\n            inputs_len (int): length of the inputs\n\n        Returns:\n            (FloatTensor):\n\n            * A Tensor of shape ``(batch_size, input_len, input_len)``\n        \"\"\"", "\n", "\n", "triangle", "=", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "inputs_len", ",", "inputs_len", ")", ")", "\n", "weights", "=", "torch", ".", "ones", "(", "1", ",", "inputs_len", ")", "/", "torch", ".", "arange", "(", "\n", "1", ",", "inputs_len", "+", "1", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "mask", "=", "triangle", "*", "weights", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "return", "mask", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch_size", ",", "inputs_len", ",", "inputs_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.average_attn.AverageAttention.cumulative_average": [[53, 83], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "layer_cache[].to"], "methods", ["None"], ["", "def", "cumulative_average", "(", "self", ",", "inputs", ",", "mask_or_step", ",", "\n", "layer_cache", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Computes the cumulative average as described in\n        :cite:`DBLP:journals/corr/abs-1805-00631` -- Equations (1) (5) (6)\n\n        Args:\n            inputs (FloatTensor): sequence to average\n                ``(batch_size, input_len, dimension)``\n            mask_or_step: if cache is set, this is assumed\n                to be the current step of the\n                dynamic decoding. Otherwise, it is the mask matrix\n                used to compute the cumulative average.\n            layer_cache: a dictionary containing the cumulative average\n                of the previous step.\n\n        Returns:\n            a tensor of the same shape and type as ``inputs``.\n        \"\"\"", "\n", "\n", "if", "layer_cache", "is", "not", "None", ":", "\n", "            ", "step", "=", "mask_or_step", "\n", "device", "=", "inputs", ".", "device", "\n", "average_attention", "=", "(", "inputs", "+", "step", "*", "\n", "layer_cache", "[", "\"prev_g\"", "]", ".", "to", "(", "device", ")", ")", "/", "(", "step", "+", "1", ")", "\n", "layer_cache", "[", "\"prev_g\"", "]", "=", "average_attention", "\n", "return", "average_attention", "\n", "", "else", ":", "\n", "            ", "mask", "=", "mask_or_step", "\n", "return", "torch", ".", "matmul", "(", "mask", ",", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.average_attn.AverageAttention.forward": [[84, 113], ["inputs.size", "inputs.size", "average_attn.AverageAttention.cumulative_average", "average_attn.AverageAttention.average_layer", "average_attn.AverageAttention.gating_layer", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "average_attn.AverageAttention.cumulative_average_mask().to().float", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "average_attn.AverageAttention.cumulative_average_mask().to", "average_attn.AverageAttention.cumulative_average_mask"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.average_attn.AverageAttention.cumulative_average", "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.average_attn.AverageAttention.cumulative_average_mask"], ["", "", "def", "forward", "(", "self", ",", "inputs", ",", "mask", "=", "None", ",", "layer_cache", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (FloatTensor): ``(batch_size, input_len, model_dim)``\n\n        Returns:\n            (FloatTensor, FloatTensor):\n\n            * gating_outputs ``(batch_size, input_len, model_dim)``\n            * average_outputs average attention\n                ``(batch_size, input_len, model_dim)``\n        \"\"\"", "\n", "\n", "batch_size", "=", "inputs", ".", "size", "(", "0", ")", "\n", "inputs_len", "=", "inputs", ".", "size", "(", "1", ")", "\n", "\n", "device", "=", "inputs", ".", "device", "\n", "average_outputs", "=", "self", ".", "cumulative_average", "(", "\n", "inputs", ",", "self", ".", "cumulative_average_mask", "(", "batch_size", ",", "\n", "inputs_len", ")", ".", "to", "(", "device", ")", ".", "float", "(", ")", "\n", "if", "layer_cache", "is", "None", "else", "step", ",", "layer_cache", "=", "layer_cache", ")", "\n", "average_outputs", "=", "self", ".", "average_layer", "(", "average_outputs", ")", "\n", "gating_outputs", "=", "self", ".", "gating_layer", "(", "torch", ".", "cat", "(", "(", "inputs", ",", "\n", "average_outputs", ")", ",", "-", "1", ")", ")", "\n", "input_gate", ",", "forget_gate", "=", "torch", ".", "chunk", "(", "gating_outputs", ",", "2", ",", "dim", "=", "2", ")", "\n", "gating_outputs", "=", "torch", ".", "sigmoid", "(", "input_gate", ")", "*", "inputs", "+", "torch", ".", "sigmoid", "(", "forget_gate", ")", "*", "average_outputs", "\n", "\n", "return", "gating_outputs", ",", "average_outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.sparse_losses.SparsemaxLossFunction.forward": [[10, 32], ["input.size", "target.size", "onmt.utils.misc.aeq", "input.gather().squeeze", "onmt.modules.sparse_activations._threshold_and_support", "torch.where().sum", "torch.where().sum", "torch.where().sum", "torch.where().sum", "ctx.save_for_backward", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "input.gather", "torch.where", "torch.where", "torch.where", "torch.where", "target.unsqueeze", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.sparse_activations._threshold_and_support"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        input (FloatTensor): ``(n, num_classes)``.\n        target (LongTensor): ``(n,)``, the indices of the target classes\n        \"\"\"", "\n", "input_batch", ",", "classes", "=", "input", ".", "size", "(", ")", "\n", "target_batch", "=", "target", ".", "size", "(", "0", ")", "\n", "aeq", "(", "input_batch", ",", "target_batch", ")", "\n", "\n", "z_k", "=", "input", ".", "gather", "(", "1", ",", "target", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", ")", "\n", "tau_z", ",", "support_size", "=", "_threshold_and_support", "(", "input", ",", "dim", "=", "1", ")", "\n", "support", "=", "input", ">", "tau_z", "\n", "x", "=", "torch", ".", "where", "(", "\n", "support", ",", "input", "**", "2", "-", "tau_z", "**", "2", ",", "\n", "torch", ".", "tensor", "(", "0.0", ",", "device", "=", "input", ".", "device", ")", "\n", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "ctx", ".", "save_for_backward", "(", "input", ",", "target", ",", "tau_z", ")", "\n", "# clamping necessary because of numerical errors: loss should be lower", "\n", "# bounded by zero, but negative values near zero are possible without", "\n", "# the clamp", "\n", "return", "torch", ".", "clamp", "(", "x", "/", "2", "-", "z_k", "+", "0.5", ",", "min", "=", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.sparse_losses.SparsemaxLossFunction.backward": [[33, 40], ["torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like.scatter_", "torch.zeros_like.scatter_", "target.unsqueeze"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "input", ",", "target", ",", "tau_z", "=", "ctx", ".", "saved_tensors", "\n", "sparsemax_out", "=", "torch", ".", "clamp", "(", "input", "-", "tau_z", ",", "min", "=", "0", ")", "\n", "delta", "=", "torch", ".", "zeros_like", "(", "sparsemax_out", ")", "\n", "delta", ".", "scatter_", "(", "1", ",", "target", ".", "unsqueeze", "(", "1", ")", ",", "1", ")", "\n", "return", "sparsemax_out", "-", "delta", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.sparse_losses.SparsemaxLoss.__init__": [[56, 63], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "weight", "=", "None", ",", "ignore_index", "=", "-", "100", ",", "\n", "reduction", "=", "'elementwise_mean'", ")", ":", "\n", "        ", "assert", "reduction", "in", "[", "'elementwise_mean'", ",", "'sum'", ",", "'none'", "]", "\n", "self", ".", "reduction", "=", "reduction", "\n", "self", ".", "weight", "=", "weight", "\n", "self", ".", "ignore_index", "=", "ignore_index", "\n", "super", "(", "SparsemaxLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.sparse_losses.SparsemaxLoss.forward": [[64, 77], ["sparsemax_loss", "float", "loss.sum.sum.masked_fill_", "float", "loss.sum.sum.sum", "target.size", "loss.sum.sum.sum", "target.size", "ignored_positions.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "loss", "=", "sparsemax_loss", "(", "input", ",", "target", ")", "\n", "if", "self", ".", "ignore_index", ">=", "0", ":", "\n", "            ", "ignored_positions", "=", "target", "==", "self", ".", "ignore_index", "\n", "size", "=", "float", "(", "(", "target", ".", "size", "(", "0", ")", "-", "ignored_positions", ".", "sum", "(", ")", ")", ".", "item", "(", ")", ")", "\n", "loss", ".", "masked_fill_", "(", "ignored_positions", ",", "0.0", ")", "\n", "", "else", ":", "\n", "            ", "size", "=", "float", "(", "target", ".", "size", "(", "0", ")", ")", "\n", "", "if", "self", ".", "reduction", "==", "'sum'", ":", "\n", "            ", "loss", "=", "loss", ".", "sum", "(", ")", "\n", "", "elif", "self", ".", "reduction", "==", "'elementwise_mean'", ":", "\n", "            ", "loss", "=", "loss", ".", "sum", "(", ")", "/", "size", "\n", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.position_ffn.PositionwiseFeedForward.__init__": [[16, 24], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.Dropout", "torch.ReLU", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "d_ff", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "PositionwiseFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w_1", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_ff", ")", "\n", "self", ".", "w_2", "=", "nn", ".", "Linear", "(", "d_ff", ",", "d_model", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "dropout_1", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "dropout_2", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.position_ffn.PositionwiseFeedForward.forward": [[25, 38], ["position_ffn.PositionwiseFeedForward.dropout_1", "position_ffn.PositionwiseFeedForward.dropout_2", "position_ffn.PositionwiseFeedForward.relu", "position_ffn.PositionwiseFeedForward.w_2", "position_ffn.PositionwiseFeedForward.w_1", "position_ffn.PositionwiseFeedForward.layer_norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Layer definition.\n\n        Args:\n            x: ``(batch_size, input_len, model_dim)``\n\n        Returns:\n            (FloatTensor): Output ``(batch_size, input_len, model_dim)``.\n        \"\"\"", "\n", "\n", "inter", "=", "self", ".", "dropout_1", "(", "self", ".", "relu", "(", "self", ".", "w_1", "(", "self", ".", "layer_norm", "(", "x", ")", ")", ")", ")", "\n", "output", "=", "self", ".", "dropout_2", "(", "self", ".", "w_2", "(", "inter", ")", ")", "\n", "return", "output", "+", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.copy_generator.CopyGenerator.__init__": [[84, 89], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "output_size", ",", "pad_idx", ")", ":", "\n", "        ", "super", "(", "CopyGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "output_size", ")", "\n", "self", ".", "linear_copy", "=", "nn", ".", "Linear", "(", "input_size", ",", "1", ")", "\n", "self", ".", "pad_idx", "=", "pad_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.copy_generator.CopyGenerator.forward": [[90, 128], ["hidden.size", "attn.size", "src_map.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "copy_generator.CopyGenerator.linear", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "copy_prob.contiguous().view.contiguous().view.contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "float", "copy_generator.CopyGenerator.linear_copy", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "copy_prob.contiguous().view.contiguous().view.contiguous", "torch.mul.view().transpose", "torch.mul.view().transpose", "src_map.transpose", "torch.mul.view", "torch.mul.view"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq"], ["", "def", "forward", "(", "self", ",", "hidden", ",", "attn", ",", "src_map", ")", ":", "\n", "        ", "\"\"\"\n        Compute a distribution over the target dictionary\n        extended by the dynamic dictionary implied by copying\n        source words.\n\n        Args:\n           hidden (FloatTensor): hidden outputs ``(batch x tlen, input_size)``\n           attn (FloatTensor): attn for each ``(batch x tlen, input_size)``\n           src_map (FloatTensor):\n               A sparse indicator matrix mapping each source word to\n               its index in the \"extended\" vocab containing.\n               ``(src_len, batch, extra_words)``\n        \"\"\"", "\n", "\n", "# CHECKS", "\n", "batch_by_tlen", ",", "_", "=", "hidden", ".", "size", "(", ")", "\n", "batch_by_tlen_", ",", "slen", "=", "attn", ".", "size", "(", ")", "\n", "slen_", ",", "batch", ",", "cvocab", "=", "src_map", ".", "size", "(", ")", "\n", "aeq", "(", "batch_by_tlen", ",", "batch_by_tlen_", ")", "\n", "aeq", "(", "slen", ",", "slen_", ")", "\n", "\n", "# Original probabilities.", "\n", "logits", "=", "self", ".", "linear", "(", "hidden", ")", "\n", "logits", "[", ":", ",", "self", ".", "pad_idx", "]", "=", "-", "float", "(", "'inf'", ")", "\n", "prob", "=", "torch", ".", "softmax", "(", "logits", ",", "1", ")", "\n", "\n", "# Probability of copying p(z=1) batch.", "\n", "p_copy", "=", "torch", ".", "sigmoid", "(", "self", ".", "linear_copy", "(", "hidden", ")", ")", "\n", "# Probability of not copying: p_{word}(w) * (1 - p(z))", "\n", "out_prob", "=", "torch", ".", "mul", "(", "prob", ",", "1", "-", "p_copy", ")", "\n", "mul_attn", "=", "torch", ".", "mul", "(", "attn", ",", "p_copy", ")", "\n", "copy_prob", "=", "torch", ".", "bmm", "(", "\n", "mul_attn", ".", "view", "(", "-", "1", ",", "batch", ",", "slen", ")", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "src_map", ".", "transpose", "(", "0", ",", "1", ")", "\n", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "copy_prob", "=", "copy_prob", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "cvocab", ")", "\n", "return", "torch", ".", "cat", "(", "[", "out_prob", ",", "copy_prob", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.copy_generator.CopyGeneratorLoss.__init__": [[132, 140], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "vocab_size", ",", "force_copy", ",", "unk_index", "=", "0", ",", "\n", "ignore_index", "=", "-", "100", ",", "eps", "=", "1e-20", ")", ":", "\n", "        ", "super", "(", "CopyGeneratorLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "force_copy", "=", "force_copy", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "ignore_index", "=", "ignore_index", "\n", "self", ".", "unk_index", "=", "unk_index", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.copy_generator.CopyGeneratorLoss.forward": [[141, 173], ["scores.gather().squeeze", "scores.gather().squeeze", "torch.where", "torch.where", "torch.where", "torch.where", "align.unsqueeze", "torch.where.log", "torch.where.log", "scores.gather", "scores.gather", "target.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log"], ["", "def", "forward", "(", "self", ",", "scores", ",", "align", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            scores (FloatTensor): ``(batch_size*tgt_len)`` x dynamic vocab size\n                whose sum along dim 1 is less than or equal to 1, i.e. cols\n                softmaxed.\n            align (LongTensor): ``(batch_size x tgt_len)``\n            target (LongTensor): ``(batch_size x tgt_len)``\n        \"\"\"", "\n", "# probabilities assigned by the model to the gold targets", "\n", "vocab_probs", "=", "scores", ".", "gather", "(", "1", ",", "target", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "# probability of tokens copied from source", "\n", "copy_ix", "=", "align", ".", "unsqueeze", "(", "1", ")", "+", "self", ".", "vocab_size", "\n", "copy_tok_probs", "=", "scores", ".", "gather", "(", "1", ",", "copy_ix", ")", ".", "squeeze", "(", "1", ")", "\n", "# Set scores for unk to 0 and add eps", "\n", "copy_tok_probs", "[", "align", "==", "self", ".", "unk_index", "]", "=", "0", "\n", "copy_tok_probs", "+=", "self", ".", "eps", "# to avoid -inf logs", "\n", "\n", "# find the indices in which you do not use the copy mechanism", "\n", "non_copy", "=", "align", "==", "self", ".", "unk_index", "\n", "if", "not", "self", ".", "force_copy", ":", "\n", "            ", "non_copy", "=", "non_copy", "|", "(", "target", "!=", "self", ".", "unk_index", ")", "\n", "\n", "", "probs", "=", "torch", ".", "where", "(", "\n", "non_copy", ",", "copy_tok_probs", "+", "vocab_probs", ",", "copy_tok_probs", "\n", ")", "\n", "\n", "loss", "=", "-", "probs", ".", "log", "(", ")", "# just NLLLoss; can the module be incorporated?", "\n", "# Drop padding.", "\n", "loss", "[", "target", "==", "self", ".", "ignore_index", "]", "=", "0", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.copy_generator.CopyGeneratorLossCompute.__init__": [[177, 181], ["onmt.utils.loss.LossComputeBase.__init__"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "criterion", ",", "generator", ",", "tgt_vocab", ",", "normalize_by_length", ")", ":", "\n", "        ", "super", "(", "CopyGeneratorLossCompute", ",", "self", ")", ".", "__init__", "(", "criterion", ",", "generator", ")", "\n", "self", ".", "tgt_vocab", "=", "tgt_vocab", "\n", "self", ".", "normalize_by_length", "=", "normalize_by_length", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.copy_generator.CopyGeneratorLossCompute._make_shard_state": [[182, 194], ["getattr", "AssertionError", "attns.get"], "methods", ["None"], ["", "def", "_make_shard_state", "(", "self", ",", "batch", ",", "output", ",", "range_", ",", "attns", ",", "scales", "=", "None", ")", ":", "\n", "        ", "\"\"\"See base class for args description.\"\"\"", "\n", "if", "getattr", "(", "batch", ",", "\"alignment\"", ",", "None", ")", "is", "None", ":", "\n", "            ", "raise", "AssertionError", "(", "\"using -copy_attn you need to pass in \"", "\n", "\"-dynamic_dict during preprocess stage.\"", ")", "\n", "\n", "", "return", "{", "\n", "\"output\"", ":", "output", ",", "\n", "\"target\"", ":", "batch", ".", "tgt", "[", "range_", "[", "0", "]", "+", "1", ":", "range_", "[", "1", "]", ",", ":", ",", "0", "]", ",", "\n", "\"copy_attn\"", ":", "attns", ".", "get", "(", "\"copy\"", ")", ",", "\n", "\"align\"", ":", "batch", ".", "alignment", "[", "range_", "[", "0", "]", "+", "1", ":", "range_", "[", "1", "]", "]", ",", "\n", "\"scales\"", ":", "scales", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.copy_generator.CopyGeneratorLossCompute._compute_loss": [[196, 257], ["target.view.view.view", "align.view.view.view", "copy_generator.CopyGeneratorLossCompute.generator", "copy_generator.CopyGeneratorLossCompute.criterion", "copy_generator.collapse_copy_scores", "copy_generator.CopyGeneratorLossCompute._bottle", "target.view.view.clone", "copy_generator.CopyGeneratorLossCompute._stats", "copy_generator.CopyGeneratorLossCompute._bottle", "copy_generator.CopyGeneratorLossCompute._bottle", "copy_generator.CopyGeneratorLossCompute._unbottle", "len", "loss.sum.sum.sum().clone", "batch.tgt[].ne().sum().float", "loss.sum.sum.view().sum", "torch.div", "torch.div", "torch.div", "torch.div", "loss.sum.sum.sum", "loss.sum.sum.sum", "copy_generator.CopyGeneratorLossCompute.clone", "loss.sum.sum.sum", "batch.tgt[].ne().sum", "loss.sum.sum.view", "loss.sum.sum.sum", "loss.sum.sum.view().sum", "batch.tgt[].ne", "loss.sum.sum.view"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.copy_generator.collapse_copy_scores", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.LossComputeBase._bottle", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.LossComputeBase._stats", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.LossComputeBase._bottle", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.LossComputeBase._bottle", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.loss.LossComputeBase._unbottle"], ["", "def", "_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "target", ",", "copy_attn", ",", "align", ",", "scales", "=", "None", ")", ":", "\n", "        ", "\"\"\"Compute the loss.\n\n        The args must match :func:`self._make_shard_state()`.\n\n        Args:\n            batch: the current batch.\n            output: the predict output from the model.\n            target: the validate target to compare output with.\n            copy_attn: the copy attention value.\n            align: the align info.\n        \"\"\"", "\n", "\n", "target", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "align", "=", "align", ".", "view", "(", "-", "1", ")", "\n", "scores", "=", "self", ".", "generator", "(", "\n", "self", ".", "_bottle", "(", "output", ")", ",", "self", ".", "_bottle", "(", "copy_attn", ")", ",", "batch", ".", "src_map", "\n", ")", "\n", "loss", "=", "self", ".", "criterion", "(", "scores", ",", "align", ",", "target", ")", "\n", "\n", "# this block does not depend on the loss value computed above", "\n", "# and is used only for stats", "\n", "scores_data", "=", "collapse_copy_scores", "(", "\n", "self", ".", "_unbottle", "(", "scores", ".", "clone", "(", ")", ",", "batch", ".", "batch_size", ")", ",", "\n", "batch", ",", "self", ".", "tgt_vocab", ",", "batch", ".", "dataset", ".", "src_vocabs", ")", "\n", "scores_data", "=", "self", ".", "_bottle", "(", "scores_data", ")", "\n", "\n", "# this block does not depend on the loss value computed above", "\n", "# and is used only for stats", "\n", "# Correct target copy token instead of <unk>", "\n", "# tgt[i] = align[i] + len(tgt_vocab)", "\n", "# for i such that tgt[i] == 0 and align[i] != 0", "\n", "target_data", "=", "target", ".", "clone", "(", ")", "\n", "unk", "=", "self", ".", "criterion", ".", "unk_index", "\n", "correct_mask", "=", "(", "target_data", "==", "unk", ")", "&", "(", "align", "!=", "unk", ")", "\n", "offset_align", "=", "align", "[", "correct_mask", "]", "+", "len", "(", "self", ".", "tgt_vocab", ")", "\n", "target_data", "[", "correct_mask", "]", "+=", "offset_align", "\n", "\n", "# Compute sum of perplexities for stats", "\n", "stats", "=", "self", ".", "_stats", "(", "loss", ".", "sum", "(", ")", ".", "clone", "(", ")", ",", "scores_data", ",", "target_data", ")", "\n", "\n", "# this part looks like it belongs in CopyGeneratorLoss", "\n", "if", "self", ".", "normalize_by_length", ":", "\n", "# Compute Loss as NLL divided by seq length", "\n", "            ", "tgt_lens", "=", "batch", ".", "tgt", "[", ":", ",", ":", ",", "0", "]", ".", "ne", "(", "self", ".", "padding_idx", ")", ".", "sum", "(", "0", ")", ".", "float", "(", ")", "\n", "# Compute Total Loss per sequence in batch", "\n", "loss", "=", "loss", ".", "view", "(", "-", "1", ",", "batch", ".", "batch_size", ")", ".", "sum", "(", "0", ")", "\n", "# Divide by length of each sequence and sum", "\n", "loss", "=", "torch", ".", "div", "(", "loss", ",", "tgt_lens", ")", "\n", "if", "scales", "is", "not", "None", ":", "\n", "                ", "loss", "=", "loss", ".", "sum", "(", "0", ")", "*", "scales", "\n", "", "loss", "=", "loss", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "# 9 * 64, 32, 64", "\n", "            ", "if", "scales", "is", "not", "None", ":", "\n", "                ", "loss", "=", "loss", ".", "view", "(", "-", "1", ",", "batch", ".", "batch_size", ")", ".", "sum", "(", "0", ")", "*", "scales", "\n", "\n", "", "loss", "=", "loss", ".", "sum", "(", ")", "\n", "# print('loss: ', loss)", "\n", "\n", "", "return", "loss", ",", "stats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.copy_generator.collapse_copy_scores": [[8, 35], ["len", "range", "scores.size", "range", "len", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "score.index_add_", "score.index_fill_", "torch.Tensor().type_as.append", "torch.Tensor().type_as.append", "score.index_select", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "function", ["None"], ["def", "collapse_copy_scores", "(", "scores", ",", "batch", ",", "tgt_vocab", ",", "src_vocabs", ",", "\n", "batch_dim", "=", "1", ",", "batch_offset", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given scores from an expanded dictionary\n    corresponeding to a batch, sums together copies,\n    with a dictionary word when it is ambiguous.\n    \"\"\"", "\n", "offset", "=", "len", "(", "tgt_vocab", ")", "\n", "for", "b", "in", "range", "(", "scores", ".", "size", "(", "batch_dim", ")", ")", ":", "\n", "        ", "blank", "=", "[", "]", "\n", "fill", "=", "[", "]", "\n", "batch_id", "=", "batch_offset", "[", "b", "]", "if", "batch_offset", "is", "not", "None", "else", "b", "\n", "index", "=", "batch", ".", "indices", ".", "data", "[", "batch_id", "]", "\n", "src_vocab", "=", "src_vocabs", "[", "index", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "src_vocab", ")", ")", ":", "\n", "            ", "sw", "=", "src_vocab", ".", "itos", "[", "i", "]", "\n", "ti", "=", "tgt_vocab", ".", "stoi", "[", "sw", "]", "\n", "if", "ti", "!=", "0", ":", "\n", "                ", "blank", ".", "append", "(", "offset", "+", "i", ")", "\n", "fill", ".", "append", "(", "ti", ")", "\n", "", "", "if", "blank", ":", "\n", "            ", "blank", "=", "torch", ".", "Tensor", "(", "blank", ")", ".", "type_as", "(", "batch", ".", "indices", ".", "data", ")", "\n", "fill", "=", "torch", ".", "Tensor", "(", "fill", ")", ".", "type_as", "(", "batch", ".", "indices", ".", "data", ")", "\n", "score", "=", "scores", "[", ":", ",", "b", "]", "if", "batch_dim", "==", "1", "else", "scores", "[", "b", "]", "\n", "score", ".", "index_add_", "(", "1", ",", "fill", ",", "score", ".", "index_select", "(", "1", ",", "blank", ")", ")", "\n", "score", ".", "index_fill_", "(", "1", ",", "blank", ",", "1e-10", ")", "\n", "", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.embeddings.PositionalEncoding.__init__": [[22, 37], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "pe.unsqueeze.unsqueeze.unsqueeze", "torch.Module.__init__", "embeddings.PositionalEncoding.register_buffer", "torch.Dropout", "torch.Dropout", "ValueError", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "math.log"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log"], ["def", "__init__", "(", "self", ",", "dropout", ",", "dim", ",", "max_len", "=", "5000", ")", ":", "\n", "        ", "if", "dim", "%", "2", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot use sin/cos positional encoding with \"", "\n", "\"odd dim (got dim={:d})\"", ".", "format", "(", "dim", ")", ")", "\n", "", "pe", "=", "torch", ".", "zeros", "(", "max_len", ",", "dim", ")", "\n", "position", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ")", ".", "unsqueeze", "(", "1", ")", "\n", "div_term", "=", "torch", ".", "exp", "(", "(", "torch", ".", "arange", "(", "0", ",", "dim", ",", "2", ",", "dtype", "=", "torch", ".", "float", ")", "*", "\n", "-", "(", "math", ".", "log", "(", "10000.0", ")", "/", "dim", ")", ")", ")", "\n", "pe", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "sin", "(", "position", ".", "float", "(", ")", "*", "div_term", ")", "\n", "pe", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "cos", "(", "position", ".", "float", "(", ")", "*", "div_term", ")", "\n", "pe", "=", "pe", ".", "unsqueeze", "(", "1", ")", "\n", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "register_buffer", "(", "'pe'", ",", "pe", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.embeddings.PositionalEncoding.forward": [[38, 55], ["embeddings.PositionalEncoding.dropout", "math.sqrt", "embeddings.PositionalEncoding.size"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.dropout"], ["", "def", "forward", "(", "self", ",", "emb", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Embed inputs.\n\n        Args:\n            emb (FloatTensor): Sequence of word vectors\n                ``(seq_len, batch_size, self.dim)``\n            step (int or NoneType): If stepwise (``seq_len = 1``), use\n                the encoding for this position.\n        \"\"\"", "\n", "\n", "emb", "=", "emb", "*", "math", ".", "sqrt", "(", "self", ".", "dim", ")", "\n", "if", "step", "is", "None", ":", "\n", "            ", "emb", "=", "emb", "+", "self", ".", "pe", "[", ":", "emb", ".", "size", "(", "0", ")", "]", "\n", "", "else", ":", "\n", "            ", "emb", "=", "emb", "+", "self", ".", "pe", "[", "step", "]", "\n", "", "emb", "=", "self", ".", "dropout", "(", "emb", ")", "\n", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.embeddings.Embeddings.__init__": [[97, 172], ["embeddings.Embeddings._validate_args", "vocab_sizes.extend", "emb_dims.extend", "pad_indices.extend", "zip", "onmt.modules.util_class.Elementwise", "torch.Module.__init__", "torch.Sequential", "torch.Sequential", "embeddings.Embeddings.make_embedding.add_module", "torch.Embedding", "torch.Embedding", "sum", "sum", "torch.Sequential", "torch.Sequential", "embeddings.Embeddings.make_embedding.add_module", "embeddings.PositionalEncoding", "embeddings.Embeddings.make_embedding.add_module", "len", "len", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "len", "int"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.embeddings.Embeddings._validate_args", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "word_vec_size", ",", "\n", "word_vocab_size", ",", "\n", "word_padding_idx", ",", "\n", "position_encoding", "=", "False", ",", "\n", "feat_merge", "=", "\"concat\"", ",", "\n", "feat_vec_exponent", "=", "0.7", ",", "\n", "feat_vec_size", "=", "-", "1", ",", "\n", "feat_padding_idx", "=", "[", "]", ",", "\n", "feat_vocab_sizes", "=", "[", "]", ",", "\n", "dropout", "=", "0", ",", "\n", "sparse", "=", "False", ",", "\n", "fix_word_vecs", "=", "False", ")", ":", "\n", "        ", "self", ".", "_validate_args", "(", "feat_merge", ",", "feat_vocab_sizes", ",", "feat_vec_exponent", ",", "\n", "feat_vec_size", ",", "feat_padding_idx", ")", "\n", "\n", "if", "feat_padding_idx", "is", "None", ":", "\n", "            ", "feat_padding_idx", "=", "[", "]", "\n", "", "self", ".", "word_padding_idx", "=", "word_padding_idx", "\n", "\n", "self", ".", "word_vec_size", "=", "word_vec_size", "\n", "\n", "# Dimensions and padding for constructing the word embedding matrix", "\n", "vocab_sizes", "=", "[", "word_vocab_size", "]", "\n", "emb_dims", "=", "[", "word_vec_size", "]", "\n", "pad_indices", "=", "[", "word_padding_idx", "]", "\n", "\n", "# Dimensions and padding for feature embedding matrices", "\n", "# (these have no effect if feat_vocab_sizes is empty)", "\n", "if", "feat_merge", "==", "'sum'", ":", "\n", "            ", "feat_dims", "=", "[", "word_vec_size", "]", "*", "len", "(", "feat_vocab_sizes", ")", "\n", "", "elif", "feat_vec_size", ">", "0", ":", "\n", "            ", "feat_dims", "=", "[", "feat_vec_size", "]", "*", "len", "(", "feat_vocab_sizes", ")", "\n", "", "else", ":", "\n", "            ", "feat_dims", "=", "[", "int", "(", "vocab", "**", "feat_vec_exponent", ")", "\n", "for", "vocab", "in", "feat_vocab_sizes", "]", "\n", "", "vocab_sizes", ".", "extend", "(", "feat_vocab_sizes", ")", "\n", "emb_dims", ".", "extend", "(", "feat_dims", ")", "\n", "pad_indices", ".", "extend", "(", "feat_padding_idx", ")", "\n", "\n", "# The embedding matrix look-up tables. The first look-up table", "\n", "# is for words. Subsequent ones are for features, if any exist.", "\n", "emb_params", "=", "zip", "(", "vocab_sizes", ",", "emb_dims", ",", "pad_indices", ")", "\n", "embeddings", "=", "[", "nn", ".", "Embedding", "(", "vocab", ",", "dim", ",", "padding_idx", "=", "pad", ",", "sparse", "=", "sparse", ")", "\n", "for", "vocab", ",", "dim", ",", "pad", "in", "emb_params", "]", "\n", "emb_luts", "=", "Elementwise", "(", "feat_merge", ",", "embeddings", ")", "\n", "\n", "# The final output size of word + feature vectors. This can vary", "\n", "# from the word vector size if and only if features are defined.", "\n", "# This is the attribute you should access if you need to know", "\n", "# how big your embeddings are going to be.", "\n", "self", ".", "embedding_size", "=", "(", "sum", "(", "emb_dims", ")", "if", "feat_merge", "==", "'concat'", "\n", "else", "word_vec_size", ")", "\n", "\n", "# The sequence of operations that converts the input sequence", "\n", "# into a sequence of embeddings. At minimum this consists of", "\n", "# looking up the embeddings for each word and feature in the", "\n", "# input. Model parameters may require the sequence to contain", "\n", "# additional operations as well.", "\n", "super", "(", "Embeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "make_embedding", "=", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "make_embedding", ".", "add_module", "(", "'emb_luts'", ",", "emb_luts", ")", "\n", "\n", "if", "feat_merge", "==", "'mlp'", "and", "len", "(", "feat_vocab_sizes", ")", ">", "0", ":", "\n", "            ", "in_dim", "=", "sum", "(", "emb_dims", ")", "\n", "mlp", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "in_dim", ",", "word_vec_size", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "self", ".", "make_embedding", ".", "add_module", "(", "'mlp'", ",", "mlp", ")", "\n", "\n", "", "self", ".", "position_encoding", "=", "position_encoding", "\n", "\n", "if", "self", ".", "position_encoding", ":", "\n", "            ", "pe", "=", "PositionalEncoding", "(", "dropout", ",", "self", ".", "embedding_size", ")", "\n", "self", ".", "make_embedding", ".", "add_module", "(", "'pe'", ",", "pe", ")", "\n", "\n", "", "if", "fix_word_vecs", ":", "\n", "            ", "self", ".", "word_lut", ".", "weight", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.embeddings.Embeddings._validate_args": [[173, 199], ["len", "len", "ValueError", "warnings.warn", "warnings.warn", "warnings.warn", "ValueError", "len"], "methods", ["None"], ["", "", "def", "_validate_args", "(", "self", ",", "feat_merge", ",", "feat_vocab_sizes", ",", "feat_vec_exponent", ",", "\n", "feat_vec_size", ",", "feat_padding_idx", ")", ":", "\n", "        ", "if", "feat_merge", "==", "\"sum\"", ":", "\n", "# features must use word_vec_size", "\n", "            ", "if", "feat_vec_exponent", "!=", "0.7", ":", "\n", "                ", "warnings", ".", "warn", "(", "\"Merging with sum, but got non-default \"", "\n", "\"feat_vec_exponent. It will be unused.\"", ")", "\n", "", "if", "feat_vec_size", "!=", "-", "1", ":", "\n", "                ", "warnings", ".", "warn", "(", "\"Merging with sum, but got non-default \"", "\n", "\"feat_vec_size. It will be unused.\"", ")", "\n", "", "", "elif", "feat_vec_size", ">", "0", ":", "\n", "# features will use feat_vec_size", "\n", "            ", "if", "feat_vec_exponent", "!=", "-", "1", ":", "\n", "                ", "warnings", ".", "warn", "(", "\"Not merging with sum and positive \"", "\n", "\"feat_vec_size, but got non-default \"", "\n", "\"feat_vec_exponent. It will be unused.\"", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "feat_vec_exponent", "<=", "0", ":", "\n", "                ", "raise", "ValueError", "(", "\"Using feat_vec_exponent to determine \"", "\n", "\"feature vec size, but got feat_vec_exponent \"", "\n", "\"less than or equal to 0.\"", ")", "\n", "", "", "n_feats", "=", "len", "(", "feat_vocab_sizes", ")", "\n", "if", "n_feats", "!=", "len", "(", "feat_padding_idx", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Got unequal number of feat_vocab_sizes and \"", "\n", "\"feat_padding_idx ({:d} != {:d})\"", ".", "format", "(", "\n", "n_feats", ",", "len", "(", "feat_padding_idx", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.embeddings.Embeddings.word_lut": [[200, 204], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "word_lut", "(", "self", ")", ":", "\n", "        ", "\"\"\"Word look-up table.\"\"\"", "\n", "return", "self", ".", "make_embedding", "[", "0", "]", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.embeddings.Embeddings.emb_luts": [[205, 209], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "emb_luts", "(", "self", ")", ":", "\n", "        ", "\"\"\"Embedding look-up table.\"\"\"", "\n", "return", "self", ".", "make_embedding", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.embeddings.Embeddings.load_pretrained_vectors": [[210, 227], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load.size", "torch.load.size", "embeddings.Embeddings.word_lut.weight.data.copy_", "embeddings.Embeddings.word_lut.weight.data.copy_"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load"], ["", "def", "load_pretrained_vectors", "(", "self", ",", "emb_file", ")", ":", "\n", "        ", "\"\"\"Load in pretrained embeddings.\n\n        Args:\n          emb_file (str) : path to torch serialized embeddings\n        \"\"\"", "\n", "\n", "if", "emb_file", ":", "\n", "            ", "pretrained", "=", "torch", ".", "load", "(", "emb_file", ")", "\n", "pretrained_vec_size", "=", "pretrained", ".", "size", "(", "1", ")", "\n", "if", "self", ".", "word_vec_size", ">", "pretrained_vec_size", ":", "\n", "                ", "self", ".", "word_lut", ".", "weight", ".", "data", "[", ":", ",", ":", "pretrained_vec_size", "]", "=", "pretrained", "\n", "", "elif", "self", ".", "word_vec_size", "<", "pretrained_vec_size", ":", "\n", "                ", "self", ".", "word_lut", ".", "weight", ".", "data", ".", "copy_", "(", "pretrained", "[", ":", ",", ":", "self", ".", "word_vec_size", "]", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "word_lut", ".", "weight", ".", "data", ".", "copy_", "(", "pretrained", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.embeddings.Embeddings.forward": [[228, 248], ["enumerate", "embeddings.Embeddings.make_embedding", "embeddings.Embeddings.make_embedding._modules.values", "module", "module", "len", "embeddings.Embeddings.make_embedding._modules.values"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "source", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Computes the embeddings for words and features.\n\n        Args:\n            source (LongTensor): index tensor ``(len, batch, nfeat)``\n\n        Returns:\n            FloatTensor: Word embeddings ``(len, batch, embedding_size)``\n        \"\"\"", "\n", "\n", "if", "self", ".", "position_encoding", ":", "\n", "            ", "for", "i", ",", "module", "in", "enumerate", "(", "self", ".", "make_embedding", ".", "_modules", ".", "values", "(", ")", ")", ":", "\n", "                ", "if", "i", "==", "len", "(", "self", ".", "make_embedding", ".", "_modules", ".", "values", "(", ")", ")", "-", "1", ":", "\n", "                    ", "source", "=", "module", "(", "source", ",", "step", "=", "step", ")", "\n", "", "else", ":", "\n", "                    ", "source", "=", "module", "(", "source", ")", "\n", "", "", "", "else", ":", "\n", "            ", "source", "=", "self", ".", "make_embedding", "(", "source", ")", "\n", "\n", "", "return", "source", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.weight_norm.WeightNormLinear.__init__": [[44, 61], ["torch.Linear.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "weight_norm.WeightNormLinear.register_buffer", "weight_norm.WeightNormLinear.register_buffer", "weight_norm.WeightNormLinear.register_buffer", "weight_norm.WeightNormLinear.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__", "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.weight_norm.WeightNormConvTranspose2d.reset_parameters"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "\n", "init_scale", "=", "1.", ",", "polyak_decay", "=", "0.9995", ")", ":", "\n", "        ", "super", "(", "WeightNormLinear", ",", "self", ")", ".", "__init__", "(", "\n", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "V", "=", "self", ".", "weight", "\n", "self", ".", "g", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ")", ")", "\n", "self", ".", "b", "=", "self", ".", "bias", "\n", "\n", "self", ".", "register_buffer", "(", "\n", "'V_avg'", ",", "torch", ".", "zeros", "(", "out_features", ",", "in_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'g_avg'", ",", "torch", ".", "zeros", "(", "out_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'b_avg'", ",", "torch", ".", "zeros", "(", "out_features", ")", ")", "\n", "\n", "self", ".", "init_scale", "=", "init_scale", "\n", "self", ".", "polyak_decay", "=", "polyak_decay", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.weight_norm.WeightNormLinear.reset_parameters": [[62, 64], ["None"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.weight_norm.WeightNormLinear.forward": [[65, 99], ["weight_norm.WeightNormLinear.V.data.copy_", "weight_norm.WeightNormLinear.g.data.copy_", "weight_norm.WeightNormLinear.b.data.copy_", "weight_norm.WeightNormLinear.V_avg.copy_", "weight_norm.WeightNormLinear.g_avg.copy_", "weight_norm.WeightNormLinear.b_avg.copy_", "weight_norm.get_vars_maybe_avg", "torch.linear", "torch.linear", "torch.linear", "weight_norm.WeightNormLinear.V.data.norm().expand_as", "torch.linear", "torch.linear", "torch.linear", "x_init.mean().squeeze", "x_init.var().squeeze", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "scale_init.view().expand_as", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "b.view().expand_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "m_init.view().expand_as", "scalar.view().expand_as", "weight_norm.WeightNormLinear.V.data.norm", "x_init.mean", "x_init.var", "scale_init.view", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "b.view", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "m_init.view", "scalar.view", "weight_norm.WeightNormLinear.V.data.size"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.weight_norm.get_vars_maybe_avg", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.mean"], ["", "def", "forward", "(", "self", ",", "x", ",", "init", "=", "False", ")", ":", "\n", "        ", "if", "init", "is", "True", ":", "\n", "# out_features * in_features", "\n", "            ", "self", ".", "V", ".", "data", ".", "copy_", "(", "torch", ".", "randn", "(", "self", ".", "V", ".", "data", ".", "size", "(", ")", ")", ".", "type_as", "(", "\n", "self", ".", "V", ".", "data", ")", "*", "0.05", ")", "\n", "# norm is out_features * 1", "\n", "v_norm", "=", "self", ".", "V", ".", "data", "/", "self", ".", "V", ".", "data", ".", "norm", "(", "2", ",", "1", ")", ".", "expand_as", "(", "self", ".", "V", ".", "data", ")", "\n", "# batch_size * out_features", "\n", "x_init", "=", "F", ".", "linear", "(", "x", ",", "v_norm", ")", ".", "data", "\n", "# out_features", "\n", "m_init", ",", "v_init", "=", "x_init", ".", "mean", "(", "0", ")", ".", "squeeze", "(", "\n", "0", ")", ",", "x_init", ".", "var", "(", "0", ")", ".", "squeeze", "(", "0", ")", "\n", "# out_features", "\n", "scale_init", "=", "self", ".", "init_scale", "/", "torch", ".", "sqrt", "(", "v_init", "+", "1e-10", ")", "\n", "self", ".", "g", ".", "data", ".", "copy_", "(", "scale_init", ")", "\n", "self", ".", "b", ".", "data", ".", "copy_", "(", "-", "m_init", "*", "scale_init", ")", "\n", "x_init", "=", "scale_init", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x_init", ")", "*", "(", "x_init", "-", "m_init", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x_init", ")", ")", "\n", "self", ".", "V_avg", ".", "copy_", "(", "self", ".", "V", ".", "data", ")", "\n", "self", ".", "g_avg", ".", "copy_", "(", "self", ".", "g", ".", "data", ")", "\n", "self", ".", "b_avg", ".", "copy_", "(", "self", ".", "b", ".", "data", ")", "\n", "return", "x_init", "\n", "", "else", ":", "\n", "            ", "v", ",", "g", ",", "b", "=", "get_vars_maybe_avg", "(", "self", ",", "[", "'V'", ",", "'g'", ",", "'b'", "]", ",", "\n", "self", ".", "training", ",", "\n", "polyak_decay", "=", "self", ".", "polyak_decay", ")", "\n", "# batch_size * out_features", "\n", "x", "=", "F", ".", "linear", "(", "x", ",", "v", ")", "\n", "scalar", "=", "g", "/", "torch", ".", "norm", "(", "v", ",", "2", ",", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "x", "=", "scalar", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x", ")", "*", "x", "+", "b", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.weight_norm.WeightNormConv2d.__init__": [[102, 120], ["torch.Conv2d.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "weight_norm.WeightNormConv2d.register_buffer", "weight_norm.WeightNormConv2d.register_buffer", "weight_norm.WeightNormConv2d.register_buffer", "weight_norm.WeightNormConv2d.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "weight_norm.WeightNormConv2d.V.size"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__", "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.weight_norm.WeightNormConvTranspose2d.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "init_scale", "=", "1.", ",", "\n", "polyak_decay", "=", "0.9995", ")", ":", "\n", "        ", "super", "(", "WeightNormConv2d", ",", "self", ")", ".", "__init__", "(", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", ",", "stride", ",", "padding", ",", "\n", "dilation", ",", "groups", ")", "\n", "\n", "self", ".", "V", "=", "self", ".", "weight", "\n", "self", ".", "g", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ")", "\n", "self", ".", "b", "=", "self", ".", "bias", "\n", "\n", "self", ".", "register_buffer", "(", "'V_avg'", ",", "torch", ".", "zeros", "(", "self", ".", "V", ".", "size", "(", ")", ")", ")", "\n", "self", ".", "register_buffer", "(", "'g_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "self", ".", "register_buffer", "(", "'b_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "\n", "self", ".", "init_scale", "=", "init_scale", "\n", "self", ".", "polyak_decay", "=", "polyak_decay", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.weight_norm.WeightNormConv2d.reset_parameters": [[121, 123], ["None"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.weight_norm.WeightNormConv2d.forward": [[124, 170], ["weight_norm.WeightNormConv2d.V.data.copy_", "x_init.transpose().contiguous().view", "weight_norm.WeightNormConv2d.g.data.copy_", "weight_norm.WeightNormConv2d.b.data.copy_", "scale_init.view", "m_init.view", "weight_norm.WeightNormConv2d.V_avg.copy_", "weight_norm.WeightNormConv2d.g_avg.copy_", "weight_norm.WeightNormConv2d.b_avg.copy_", "weight_norm.get_vars_maybe_avg", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.conv2d", "torch.conv2d", "torch.conv2d", "weight_norm.WeightNormConv2d.V.data.view().norm().view().expand_as", "torch.conv2d", "torch.conv2d", "torch.conv2d", "x_init.transpose().contiguous().view.mean().squeeze", "x_init.transpose().contiguous().view.var().squeeze", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "scale_init.view.expand_as", "v.view", "len", "torch.norm.view().expand_as", "torch.norm.view().expand_as", "torch.norm.view().expand_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "x_init.transpose().contiguous", "m_init.view.expand_as", "torch.norm.size", "torch.norm.size", "torch.norm.size", "torch.norm.squeeze", "torch.norm.squeeze", "torch.norm.squeeze", "weight_norm.WeightNormConv2d.V.data.view().norm().view", "x_init.transpose().contiguous().view.mean", "x_init.transpose().contiguous().view.var", "torch.norm.view", "torch.norm.view", "torch.norm.view", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "x_init.transpose", "len", "len", "weight_norm.WeightNormConv2d.V.data.size", "weight_norm.WeightNormConv2d.V.data.view().norm", "x_init.size", "x_init.size", "weight_norm.WeightNormConv2d.V.data.view", "len", "len", "v.size"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.weight_norm.get_vars_maybe_avg", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.mean"], ["", "def", "forward", "(", "self", ",", "x", ",", "init", "=", "False", ")", ":", "\n", "        ", "if", "init", "is", "True", ":", "\n", "# out_channels, in_channels // groups, * kernel_size", "\n", "            ", "self", ".", "V", ".", "data", ".", "copy_", "(", "torch", ".", "randn", "(", "self", ".", "V", ".", "data", ".", "size", "(", ")", "\n", ")", ".", "type_as", "(", "self", ".", "V", ".", "data", ")", "*", "0.05", ")", "\n", "v_norm", "=", "self", ".", "V", ".", "data", "/", "self", ".", "V", ".", "data", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", ".", "norm", "(", "2", ",", "1", ")", ".", "view", "(", "self", ".", "out_channels", ",", "*", "(", "\n", "[", "1", "]", "*", "(", "len", "(", "self", ".", "kernel_size", ")", "+", "1", ")", ")", ")", ".", "expand_as", "(", "self", ".", "V", ".", "data", ")", "\n", "x_init", "=", "F", ".", "conv2d", "(", "x", ",", "v_norm", ",", "None", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", ".", "data", "\n", "t_x_init", "=", "x_init", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "self", ".", "out_channels", ",", "-", "1", ")", "\n", "m_init", ",", "v_init", "=", "t_x_init", ".", "mean", "(", "1", ")", ".", "squeeze", "(", "\n", "1", ")", ",", "t_x_init", ".", "var", "(", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "# out_features", "\n", "scale_init", "=", "self", ".", "init_scale", "/", "torch", ".", "sqrt", "(", "v_init", "+", "1e-10", ")", "\n", "self", ".", "g", ".", "data", ".", "copy_", "(", "scale_init", ")", "\n", "self", ".", "b", ".", "data", ".", "copy_", "(", "-", "m_init", "*", "scale_init", ")", "\n", "scale_init_shape", "=", "scale_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "m_init_shape", "=", "m_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "x_init", "=", "scale_init_shape", ".", "expand_as", "(", "\n", "x_init", ")", "*", "(", "x_init", "-", "m_init_shape", ".", "expand_as", "(", "x_init", ")", ")", "\n", "self", ".", "V_avg", ".", "copy_", "(", "self", ".", "V", ".", "data", ")", "\n", "self", ".", "g_avg", ".", "copy_", "(", "self", ".", "g", ".", "data", ")", "\n", "self", ".", "b_avg", ".", "copy_", "(", "self", ".", "b", ".", "data", ")", "\n", "return", "x_init", "\n", "", "else", ":", "\n", "            ", "v", ",", "g", ",", "b", "=", "get_vars_maybe_avg", "(", "\n", "self", ",", "[", "'V'", ",", "'g'", ",", "'b'", "]", ",", "self", ".", "training", ",", "\n", "polyak_decay", "=", "self", ".", "polyak_decay", ")", "\n", "\n", "scalar", "=", "torch", ".", "norm", "(", "v", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", ",", "2", ",", "1", ")", "\n", "if", "len", "(", "scalar", ".", "size", "(", ")", ")", "==", "2", ":", "\n", "                ", "scalar", "=", "g", "/", "scalar", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "scalar", "=", "g", "/", "scalar", "\n", "\n", "", "w", "=", "scalar", ".", "view", "(", "self", ".", "out_channels", ",", "*", "\n", "(", "[", "1", "]", "*", "(", "len", "(", "v", ".", "size", "(", ")", ")", "-", "1", ")", ")", ")", ".", "expand_as", "(", "v", ")", "*", "v", "\n", "\n", "x", "=", "F", ".", "conv2d", "(", "x", ",", "w", ",", "b", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.weight_norm.WeightNormConvTranspose2d.__init__": [[175, 195], ["torch.ConvTranspose2d.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "weight_norm.WeightNormConvTranspose2d.register_buffer", "weight_norm.WeightNormConvTranspose2d.register_buffer", "weight_norm.WeightNormConvTranspose2d.register_buffer", "weight_norm.WeightNormConvTranspose2d.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "weight_norm.WeightNormConvTranspose2d.V.size"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__", "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.weight_norm.WeightNormConvTranspose2d.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "output_padding", "=", "0", ",", "groups", "=", "1", ",", "init_scale", "=", "1.", ",", "\n", "polyak_decay", "=", "0.9995", ")", ":", "\n", "        ", "super", "(", "WeightNormConvTranspose2d", ",", "self", ")", ".", "__init__", "(", "\n", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", ",", "stride", ",", "\n", "padding", ",", "output_padding", ",", "\n", "groups", ")", "\n", "# in_channels, out_channels, *kernel_size", "\n", "self", ".", "V", "=", "self", ".", "weight", "\n", "self", ".", "g", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ")", "\n", "self", ".", "b", "=", "self", ".", "bias", "\n", "\n", "self", ".", "register_buffer", "(", "'V_avg'", ",", "torch", ".", "zeros", "(", "self", ".", "V", ".", "size", "(", ")", ")", ")", "\n", "self", ".", "register_buffer", "(", "'g_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "self", ".", "register_buffer", "(", "'b_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "\n", "self", ".", "init_scale", "=", "init_scale", "\n", "self", ".", "polyak_decay", "=", "polyak_decay", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.weight_norm.WeightNormConvTranspose2d.reset_parameters": [[196, 198], ["None"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.weight_norm.WeightNormConvTranspose2d.forward": [[199, 247], ["weight_norm.WeightNormConvTranspose2d.V.data.copy_", "x_init.tranpose().contiguous().view", "weight_norm.WeightNormConvTranspose2d.g.data.copy_", "weight_norm.WeightNormConvTranspose2d.b.data.copy_", "scale_init.view", "m_init.view", "weight_norm.WeightNormConvTranspose2d.V_avg.copy_", "weight_norm.WeightNormConvTranspose2d.g_avg.copy_", "weight_norm.WeightNormConvTranspose2d.b_avg.copy_", "weight_norm.get_vars_maybe_avg", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "weight_norm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view().norm().view().expand_as", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "x_init.tranpose().contiguous().view.mean().squeeze", "x_init.tranpose().contiguous().view.var().squeeze", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "scale_init.view.expand_as", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "scalar.view().expand_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "x_init.tranpose().contiguous", "m_init.view.expand_as", "weight_norm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view().norm().view", "x_init.tranpose().contiguous().view.mean", "x_init.tranpose().contiguous().view.var", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "scalar.view", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "x_init.tranpose", "len", "len", "v.transpose().contiguous().view", "weight_norm.WeightNormConvTranspose2d.V.data.size", "weight_norm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view().norm", "x_init.size", "x_init.size", "len", "v.transpose().contiguous", "weight_norm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view", "len", "v.transpose", "v.size", "weight_norm.WeightNormConvTranspose2d.V.data.transpose().contiguous", "weight_norm.WeightNormConvTranspose2d.V.data.transpose"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.weight_norm.get_vars_maybe_avg", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.mean"], ["", "def", "forward", "(", "self", ",", "x", ",", "init", "=", "False", ")", ":", "\n", "        ", "if", "init", "is", "True", ":", "\n", "# in_channels, out_channels, *kernel_size", "\n", "            ", "self", ".", "V", ".", "data", ".", "copy_", "(", "torch", ".", "randn", "(", "self", ".", "V", ".", "data", ".", "size", "(", ")", ")", ".", "type_as", "(", "\n", "self", ".", "V", ".", "data", ")", "*", "0.05", ")", "\n", "v_norm", "=", "self", ".", "V", ".", "data", "/", "self", ".", "V", ".", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", ".", "norm", "(", "2", ",", "1", ")", ".", "view", "(", "\n", "self", ".", "in_channels", ",", "self", ".", "out_channels", ",", "\n", "*", "(", "[", "1", "]", "*", "len", "(", "self", ".", "kernel_size", ")", ")", ")", ".", "expand_as", "(", "self", ".", "V", ".", "data", ")", "\n", "x_init", "=", "F", ".", "conv_transpose2d", "(", "\n", "x", ",", "v_norm", ",", "None", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "output_padding", ",", "self", ".", "groups", ")", ".", "data", "\n", "# self.out_channels, 1", "\n", "t_x_init", "=", "x_init", ".", "tranpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "self", ".", "out_channels", ",", "-", "1", ")", "\n", "# out_features", "\n", "m_init", ",", "v_init", "=", "t_x_init", ".", "mean", "(", "1", ")", ".", "squeeze", "(", "\n", "1", ")", ",", "t_x_init", ".", "var", "(", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "# out_features", "\n", "scale_init", "=", "self", ".", "init_scale", "/", "torch", ".", "sqrt", "(", "v_init", "+", "1e-10", ")", "\n", "self", ".", "g", ".", "data", ".", "copy_", "(", "scale_init", ")", "\n", "self", ".", "b", ".", "data", ".", "copy_", "(", "-", "m_init", "*", "scale_init", ")", "\n", "scale_init_shape", "=", "scale_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "m_init_shape", "=", "m_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "\n", "x_init", "=", "scale_init_shape", ".", "expand_as", "(", "x_init", ")", "*", "(", "x_init", "-", "m_init_shape", ".", "expand_as", "(", "x_init", ")", ")", "\n", "self", ".", "V_avg", ".", "copy_", "(", "self", ".", "V", ".", "data", ")", "\n", "self", ".", "g_avg", ".", "copy_", "(", "self", ".", "g", ".", "data", ")", "\n", "self", ".", "b_avg", ".", "copy_", "(", "self", ".", "b", ".", "data", ")", "\n", "return", "x_init", "\n", "", "else", ":", "\n", "            ", "v", ",", "g", ",", "b", "=", "get_vars_maybe_avg", "(", "\n", "self", ",", "[", "'V'", ",", "'g'", ",", "'b'", "]", ",", "self", ".", "training", ",", "\n", "polyak_decay", "=", "self", ".", "polyak_decay", ")", "\n", "scalar", "=", "g", "/", "torch", ".", "norm", "(", "v", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "self", ".", "out_channels", ",", "-", "1", ")", ",", "2", ",", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "w", "=", "scalar", ".", "view", "(", "self", ".", "in_channels", ",", "self", ".", "out_channels", ",", "\n", "*", "(", "[", "1", "]", "*", "(", "len", "(", "v", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", ".", "expand_as", "(", "v", ")", "*", "v", "\n", "\n", "x", "=", "F", ".", "conv_transpose2d", "(", "x", ",", "w", ",", "b", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "output_padding", ",", "\n", "self", ".", "groups", ")", "\n", "return", "x", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.weight_norm.get_var_maybe_avg": [[8, 20], ["getattr", "getattr"], "function", ["None"], ["def", "get_var_maybe_avg", "(", "namespace", ",", "var_name", ",", "training", ",", "polyak_decay", ")", ":", "\n", "    ", "\"\"\" utility for retrieving polyak averaged params\n        Update average\n    \"\"\"", "\n", "v", "=", "getattr", "(", "namespace", ",", "var_name", ")", "\n", "v_avg", "=", "getattr", "(", "namespace", ",", "var_name", "+", "'_avg'", ")", "\n", "v_avg", "-=", "(", "1", "-", "polyak_decay", ")", "*", "(", "v_avg", "-", "v", ".", "data", ")", "\n", "\n", "if", "training", ":", "\n", "        ", "return", "v", "\n", "", "else", ":", "\n", "        ", "return", "v_avg", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.weight_norm.get_vars_maybe_avg": [[22, 29], ["vars.append", "weight_norm.get_var_maybe_avg"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.weight_norm.get_var_maybe_avg"], ["", "", "def", "get_vars_maybe_avg", "(", "namespace", ",", "var_names", ",", "training", ",", "polyak_decay", ")", ":", "\n", "    ", "\"\"\" utility for retrieving polyak averaged params \"\"\"", "\n", "vars", "=", "[", "]", "\n", "for", "vn", "in", "var_names", ":", "\n", "        ", "vars", ".", "append", "(", "get_var_maybe_avg", "(", "\n", "namespace", ",", "vn", ",", "training", ",", "polyak_decay", ")", ")", "\n", "", "return", "vars", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.sparse_activations.SparsemaxFunction.forward": [[45, 63], ["input.max", "sparse_activations._threshold_and_support", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "ctx.save_for_backward"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.sparse_activations._threshold_and_support"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ",", "dim", "=", "0", ")", ":", "\n", "        ", "\"\"\"sparsemax: normalizing sparse transform (a la softmax)\n\n        Parameters:\n            input (Tensor): any shape\n            dim: dimension along which to apply sparsemax\n\n        Returns:\n            output (Tensor): same shape as input\n        \"\"\"", "\n", "ctx", ".", "dim", "=", "dim", "\n", "max_val", ",", "_", "=", "input", ".", "max", "(", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "\n", "input", "-=", "max_val", "# same numerical stability trick as for softmax", "\n", "tau", ",", "supp_size", "=", "_threshold_and_support", "(", "input", ",", "dim", "=", "dim", ")", "\n", "output", "=", "torch", ".", "clamp", "(", "input", "-", "tau", ",", "min", "=", "0", ")", "\n", "ctx", ".", "save_for_backward", "(", "supp_size", ",", "output", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.sparse_activations.SparsemaxFunction.backward": [[64, 75], ["grad_output.clone", "v_hat.unsqueeze.unsqueeze.unsqueeze", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where.sum", "torch.where.sum", "supp_size.to().squeeze", "supp_size.to"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "supp_size", ",", "output", "=", "ctx", ".", "saved_tensors", "\n", "dim", "=", "ctx", ".", "dim", "\n", "grad_input", "=", "grad_output", ".", "clone", "(", ")", "\n", "grad_input", "[", "output", "==", "0", "]", "=", "0", "\n", "\n", "v_hat", "=", "grad_input", ".", "sum", "(", "dim", "=", "dim", ")", "/", "supp_size", ".", "to", "(", "output", ".", "dtype", ")", ".", "squeeze", "(", ")", "\n", "v_hat", "=", "v_hat", ".", "unsqueeze", "(", "dim", ")", "\n", "grad_input", "=", "torch", ".", "where", "(", "output", "!=", "0", ",", "grad_input", "-", "v_hat", ",", "grad_input", ")", "\n", "return", "grad_input", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.sparse_activations.Sparsemax.__init__": [[82, 85], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", "=", "0", ")", ":", "\n", "        ", "self", ".", "dim", "=", "dim", "\n", "super", "(", "Sparsemax", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.sparse_activations.Sparsemax.forward": [[86, 88], ["sparsemax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "sparsemax", "(", "input", ",", "self", ".", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.sparse_activations.LogSparsemax.__init__": [[92, 95], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", "=", "0", ")", ":", "\n", "        ", "self", ".", "dim", "=", "dim", "\n", "super", "(", "LogSparsemax", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.sparse_activations.LogSparsemax.forward": [[96, 98], ["torch.log", "torch.log", "torch.log", "torch.log", "sparsemax"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "torch", ".", "log", "(", "sparsemax", "(", "input", ",", "self", ".", "dim", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.sparse_activations._make_ix_like": [[13, 19], ["input.size", "torch.arange", "torch.arange", "torch.arange.view().transpose", "input.dim", "torch.arange.view"], "function", ["None"], ["def", "_make_ix_like", "(", "input", ",", "dim", "=", "0", ")", ":", "\n", "    ", "d", "=", "input", ".", "size", "(", "dim", ")", "\n", "rho", "=", "torch", ".", "arange", "(", "1", ",", "d", "+", "1", ",", "device", "=", "input", ".", "device", ",", "dtype", "=", "input", ".", "dtype", ")", "\n", "view", "=", "[", "1", "]", "*", "input", ".", "dim", "(", ")", "\n", "view", "[", "0", "]", "=", "-", "1", "\n", "return", "rho", ".", "view", "(", "view", ")", ".", "transpose", "(", "0", ",", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.sparse_activations._threshold_and_support": [[21, 41], ["torch.sort", "torch.sort", "sparse_activations._make_ix_like", "support.sum().unsqueeze", "input_cumsum.gather", "support.sum().unsqueeze.to", "input_srt.cumsum", "support.sum"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.sparse_activations._make_ix_like"], ["", "def", "_threshold_and_support", "(", "input", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\"Sparsemax building block: compute the threshold\n\n    Args:\n        input: any dimension\n        dim: dimension along which to apply the sparsemax\n\n    Returns:\n        the threshold value\n    \"\"\"", "\n", "\n", "input_srt", ",", "_", "=", "torch", ".", "sort", "(", "input", ",", "descending", "=", "True", ",", "dim", "=", "dim", ")", "\n", "input_cumsum", "=", "input_srt", ".", "cumsum", "(", "dim", ")", "-", "1", "\n", "rhos", "=", "_make_ix_like", "(", "input", ",", "dim", ")", "\n", "support", "=", "rhos", "*", "input_srt", ">", "input_cumsum", "\n", "\n", "support_size", "=", "support", ".", "sum", "(", "dim", "=", "dim", ")", ".", "unsqueeze", "(", "dim", ")", "\n", "tau", "=", "input_cumsum", ".", "gather", "(", "dim", ",", "support_size", "-", "1", ")", "\n", "tau", "/=", "support_size", ".", "to", "(", "input", ".", "dtype", ")", "\n", "return", "tau", ",", "support_size", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.global_attention.GlobalAttention.__init__": [[71, 96], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "coverage", "=", "False", ",", "attn_type", "=", "\"dot\"", ",", "\n", "attn_func", "=", "\"softmax\"", ")", ":", "\n", "        ", "super", "(", "GlobalAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dim", "=", "dim", "\n", "assert", "attn_type", "in", "[", "\"dot\"", ",", "\"general\"", ",", "\"mlp\"", "]", ",", "(", "\n", "\"Please select a valid attention type (got {:s}).\"", ".", "format", "(", "\n", "attn_type", ")", ")", "\n", "self", ".", "attn_type", "=", "attn_type", "\n", "assert", "attn_func", "in", "[", "\"softmax\"", ",", "\"sparsemax\"", "]", ",", "(", "\n", "\"Please select a valid attention function.\"", ")", "\n", "self", ".", "attn_func", "=", "attn_func", "\n", "\n", "if", "self", ".", "attn_type", "==", "\"general\"", ":", "\n", "            ", "self", ".", "linear_in", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "False", ")", "\n", "", "elif", "self", ".", "attn_type", "==", "\"mlp\"", ":", "\n", "            ", "self", ".", "linear_context", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_query", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "v", "=", "nn", ".", "Linear", "(", "dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "# mlp wants it with bias", "\n", "", "out_bias", "=", "self", ".", "attn_type", "==", "\"mlp\"", "\n", "self", ".", "linear_out", "=", "nn", ".", "Linear", "(", "dim", "*", "2", ",", "dim", ",", "bias", "=", "out_bias", ")", "\n", "\n", "if", "coverage", ":", "\n", "            ", "self", ".", "linear_cover", "=", "nn", ".", "Linear", "(", "1", ",", "dim", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.global_attention.GlobalAttention.score": [[97, 137], ["h_s.size", "global_attention.GlobalAttention.view.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "h_s.transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "global_attention.GlobalAttention.linear_query", "wq.expand.expand.view", "wq.expand.expand.expand", "global_attention.GlobalAttention.linear_context", "uh.expand.expand.view", "uh.expand.expand.expand", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "global_attention.GlobalAttention.v().view", "global_attention.GlobalAttention.view.view", "global_attention.GlobalAttention.linear_in", "global_attention.GlobalAttention.view", "global_attention.GlobalAttention.view.view", "h_s.contiguous().view", "global_attention.GlobalAttention.v", "h_s.contiguous", "torch.tanh.view", "torch.tanh.view", "torch.tanh.view"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq"], ["", "", "def", "score", "(", "self", ",", "h_t", ",", "h_s", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n          h_t (FloatTensor): sequence of queries ``(batch, tgt_len, dim)``\n          h_s (FloatTensor): sequence of sources ``(batch, src_len, dim``\n\n        Returns:\n          FloatTensor: raw attention scores (unnormalized) for each src index\n            ``(batch, tgt_len, src_len)``\n        \"\"\"", "\n", "\n", "# Check input sizes", "\n", "src_batch", ",", "src_len", ",", "src_dim", "=", "h_s", ".", "size", "(", ")", "\n", "tgt_batch", ",", "tgt_len", ",", "tgt_dim", "=", "h_t", ".", "size", "(", ")", "\n", "aeq", "(", "src_batch", ",", "tgt_batch", ")", "\n", "aeq", "(", "src_dim", ",", "tgt_dim", ")", "\n", "aeq", "(", "self", ".", "dim", ",", "src_dim", ")", "\n", "\n", "if", "self", ".", "attn_type", "in", "[", "\"general\"", ",", "\"dot\"", "]", ":", "\n", "            ", "if", "self", ".", "attn_type", "==", "\"general\"", ":", "\n", "                ", "h_t_", "=", "h_t", ".", "view", "(", "tgt_batch", "*", "tgt_len", ",", "tgt_dim", ")", "\n", "h_t_", "=", "self", ".", "linear_in", "(", "h_t_", ")", "\n", "h_t", "=", "h_t_", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "tgt_dim", ")", "\n", "", "h_s_", "=", "h_s", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# (batch, t_len, d) x (batch, d, s_len) --> (batch, t_len, s_len)", "\n", "return", "torch", ".", "bmm", "(", "h_t", ",", "h_s_", ")", "\n", "", "else", ":", "\n", "            ", "dim", "=", "self", ".", "dim", "\n", "wq", "=", "self", ".", "linear_query", "(", "h_t", ".", "view", "(", "-", "1", ",", "dim", ")", ")", "\n", "wq", "=", "wq", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "1", ",", "dim", ")", "\n", "wq", "=", "wq", ".", "expand", "(", "tgt_batch", ",", "tgt_len", ",", "src_len", ",", "dim", ")", "\n", "\n", "uh", "=", "self", ".", "linear_context", "(", "h_s", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "dim", ")", ")", "\n", "uh", "=", "uh", ".", "view", "(", "src_batch", ",", "1", ",", "src_len", ",", "dim", ")", "\n", "uh", "=", "uh", ".", "expand", "(", "src_batch", ",", "tgt_len", ",", "src_len", ",", "dim", ")", "\n", "\n", "# (batch, t_len, s_len, d)", "\n", "wquh", "=", "torch", ".", "tanh", "(", "wq", "+", "uh", ")", "\n", "\n", "return", "self", ".", "v", "(", "wquh", ".", "view", "(", "-", "1", ",", "dim", ")", ")", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "src_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.global_attention.GlobalAttention.forward": [[138, 228], ["torch.tanh.size", "torch.tanh.size", "torch.tanh.size", "source.unsqueeze.unsqueeze.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "global_attention.GlobalAttention.score", "align_vectors.transpose().contiguous.transpose().contiguous.view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "global_attention.GlobalAttention.linear_out().view", "source.unsqueeze.unsqueeze.dim", "source.unsqueeze.unsqueeze.unsqueeze", "coverage.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "coverage.view().unsqueeze", "global_attention.GlobalAttention.linear_cover().view_as", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "onmt.utils.misc.sequence_mask", "mask.unsqueeze.unsqueeze.unsqueeze", "global_attention.GlobalAttention.masked_fill_", "torch.softmax", "torch.softmax", "torch.softmax", "onmt.modules.sparse_activations.sparsemax", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "attn_h.transpose().contiguous.transpose().contiguous.squeeze", "align_vectors.transpose().contiguous.transpose().contiguous.squeeze", "attn_h.transpose().contiguous.transpose().contiguous.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "align_vectors.transpose().contiguous.transpose().contiguous.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "attn_h.transpose().contiguous.transpose().contiguous.transpose().contiguous", "align_vectors.transpose().contiguous.transpose().contiguous.transpose().contiguous", "attn_h.transpose().contiguous.transpose().contiguous.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "align_vectors.transpose().contiguous.transpose().contiguous.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "global_attention.GlobalAttention.view", "global_attention.GlobalAttention.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "global_attention.GlobalAttention.linear_out", "coverage.view", "global_attention.GlobalAttention.linear_cover", "global_attention.GlobalAttention.size", "float", "attn_h.transpose().contiguous.transpose().contiguous.transpose", "align_vectors.transpose().contiguous.transpose().contiguous.transpose"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam.GNMTGlobalScorer.score", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.sequence_mask", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq"], ["", "", "def", "forward", "(", "self", ",", "source", ",", "memory_bank", ",", "memory_lengths", "=", "None", ",", "coverage", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n          source (FloatTensor): query vectors ``(batch, tgt_len, dim)``\n          memory_bank (FloatTensor): source vectors ``(batch, src_len, dim)``\n          memory_lengths (LongTensor): the source context lengths ``(batch,)``\n          coverage (FloatTensor): None (not supported yet)\n\n        Returns:\n          (FloatTensor, FloatTensor):\n\n          * Computed vector ``(tgt_len, batch, dim)``\n          * Attention distribtutions for each query\n            ``(tgt_len, batch, src_len)``\n        \"\"\"", "\n", "\n", "# one step input", "\n", "if", "source", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "one_step", "=", "True", "\n", "source", "=", "source", ".", "unsqueeze", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "one_step", "=", "False", "\n", "\n", "", "batch", ",", "source_l", ",", "dim", "=", "memory_bank", ".", "size", "(", ")", "\n", "batch_", ",", "target_l", ",", "dim_", "=", "source", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "dim", ",", "dim_", ")", "\n", "aeq", "(", "self", ".", "dim", ",", "dim", ")", "\n", "if", "coverage", "is", "not", "None", ":", "\n", "            ", "batch_", ",", "source_l_", "=", "coverage", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "source_l", ",", "source_l_", ")", "\n", "\n", "", "if", "coverage", "is", "not", "None", ":", "\n", "            ", "cover", "=", "coverage", ".", "view", "(", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "memory_bank", "+=", "self", ".", "linear_cover", "(", "cover", ")", ".", "view_as", "(", "memory_bank", ")", "\n", "memory_bank", "=", "torch", ".", "tanh", "(", "memory_bank", ")", "\n", "\n", "# compute attention scores, as in Luong et al.", "\n", "", "align", "=", "self", ".", "score", "(", "source", ",", "memory_bank", ")", "\n", "\n", "if", "memory_lengths", "is", "not", "None", ":", "\n", "            ", "mask", "=", "sequence_mask", "(", "memory_lengths", ",", "max_len", "=", "align", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "# Make it broadcastable.", "\n", "align", ".", "masked_fill_", "(", "1", "-", "mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "# Softmax or sparsemax to normalize attention weights", "\n", "", "if", "self", ".", "attn_func", "==", "\"softmax\"", ":", "\n", "            ", "align_vectors", "=", "F", ".", "softmax", "(", "align", ".", "view", "(", "batch", "*", "target_l", ",", "source_l", ")", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "align_vectors", "=", "sparsemax", "(", "align", ".", "view", "(", "batch", "*", "target_l", ",", "source_l", ")", ",", "-", "1", ")", "\n", "", "align_vectors", "=", "align_vectors", ".", "view", "(", "batch", ",", "target_l", ",", "source_l", ")", "\n", "\n", "# each context vector c_t is the weighted average", "\n", "# over all the source hidden states", "\n", "c", "=", "torch", ".", "bmm", "(", "align_vectors", ",", "memory_bank", ")", "\n", "\n", "# concatenate", "\n", "concat_c", "=", "torch", ".", "cat", "(", "[", "c", ",", "source", "]", ",", "2", ")", ".", "view", "(", "batch", "*", "target_l", ",", "dim", "*", "2", ")", "\n", "attn_h", "=", "self", ".", "linear_out", "(", "concat_c", ")", ".", "view", "(", "batch", ",", "target_l", ",", "dim", ")", "\n", "if", "self", ".", "attn_type", "in", "[", "\"general\"", ",", "\"dot\"", "]", ":", "\n", "            ", "attn_h", "=", "torch", ".", "tanh", "(", "attn_h", ")", "\n", "\n", "", "if", "one_step", ":", "\n", "            ", "attn_h", "=", "attn_h", ".", "squeeze", "(", "1", ")", "\n", "align_vectors", "=", "align_vectors", ".", "squeeze", "(", "1", ")", "\n", "\n", "# Check output sizes", "\n", "batch_", ",", "dim_", "=", "attn_h", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "dim", ",", "dim_", ")", "\n", "batch_", ",", "source_l_", "=", "align_vectors", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "source_l", ",", "source_l_", ")", "\n", "\n", "", "else", ":", "\n", "            ", "attn_h", "=", "attn_h", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "align_vectors", "=", "align_vectors", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "# Check output sizes", "\n", "target_l_", ",", "batch_", ",", "dim_", "=", "attn_h", ".", "size", "(", ")", "\n", "aeq", "(", "target_l", ",", "target_l_", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "dim", ",", "dim_", ")", "\n", "target_l_", ",", "batch_", ",", "source_l_", "=", "align_vectors", ".", "size", "(", ")", "\n", "aeq", "(", "target_l", ",", "target_l_", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "source_l", ",", "source_l_", ")", "\n", "\n", "", "return", "attn_h", ",", "align_vectors", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.gate.ContextGate.__init__": [[29, 38], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "ContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "input_size", "=", "embeddings_size", "+", "decoder_size", "+", "attention_size", "\n", "self", ".", "gate", "=", "nn", ".", "Linear", "(", "input_size", ",", "output_size", ",", "bias", "=", "True", ")", "\n", "self", ".", "sig", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "source_proj", "=", "nn", ".", "Linear", "(", "attention_size", ",", "output_size", ")", "\n", "self", ".", "target_proj", "=", "nn", ".", "Linear", "(", "embeddings_size", "+", "decoder_size", ",", "\n", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.gate.ContextGate.forward": [[39, 46], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "gate.ContextGate.sig", "gate.ContextGate.source_proj", "gate.ContextGate.target_proj", "gate.ContextGate.gate", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "input_tensor", "=", "torch", ".", "cat", "(", "(", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ",", "dim", "=", "1", ")", "\n", "z", "=", "self", ".", "sig", "(", "self", ".", "gate", "(", "input_tensor", ")", ")", "\n", "proj_source", "=", "self", ".", "source_proj", "(", "attn_state", ")", "\n", "proj_target", "=", "self", ".", "target_proj", "(", "\n", "torch", ".", "cat", "(", "(", "prev_emb", ",", "dec_state", ")", ",", "dim", "=", "1", ")", ")", "\n", "return", "z", ",", "proj_source", ",", "proj_target", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.gate.SourceContextGate.__init__": [[51, 57], ["torch.Module.__init__", "gate.ContextGate", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "SourceContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_gate", "=", "ContextGate", "(", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.gate.SourceContextGate.forward": [[58, 62], ["gate.SourceContextGate.context_gate", "gate.SourceContextGate.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "z", ",", "source", ",", "target", "=", "self", ".", "context_gate", "(", "\n", "prev_emb", ",", "dec_state", ",", "attn_state", ")", "\n", "return", "self", ".", "tanh", "(", "target", "+", "z", "*", "source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.gate.TargetContextGate.__init__": [[67, 73], ["torch.Module.__init__", "gate.ContextGate", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "TargetContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_gate", "=", "ContextGate", "(", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.gate.TargetContextGate.forward": [[74, 77], ["gate.TargetContextGate.context_gate", "gate.TargetContextGate.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "z", ",", "source", ",", "target", "=", "self", ".", "context_gate", "(", "prev_emb", ",", "dec_state", ",", "attn_state", ")", "\n", "return", "self", ".", "tanh", "(", "z", "*", "target", "+", "source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.gate.BothContextGate.__init__": [[82, 88], ["torch.Module.__init__", "gate.ContextGate", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "BothContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_gate", "=", "ContextGate", "(", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.gate.BothContextGate.forward": [[89, 92], ["gate.BothContextGate.context_gate", "gate.BothContextGate.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "z", ",", "source", ",", "target", "=", "self", ".", "context_gate", "(", "prev_emb", ",", "dec_state", ",", "attn_state", ")", "\n", "return", "self", ".", "tanh", "(", "(", "1.", "-", "z", ")", "*", "target", "+", "z", "*", "source", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.gate.context_gate_factory": [[6, 18], ["None"], "function", ["None"], ["def", "context_gate_factory", "(", "gate_type", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "    ", "\"\"\"Returns the correct ContextGate class\"\"\"", "\n", "\n", "gate_types", "=", "{", "'source'", ":", "SourceContextGate", ",", "\n", "'target'", ":", "TargetContextGate", ",", "\n", "'both'", ":", "BothContextGate", "}", "\n", "\n", "assert", "gate_type", "in", "gate_types", ",", "\"Not valid ContextGate type: {0}\"", ".", "format", "(", "\n", "gate_type", ")", "\n", "return", "gate_types", "[", "gate_type", "]", "(", "embeddings_size", ",", "decoder_size", ",", "attention_size", ",", "\n", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.decoder.DecoderBase.__init__": [[18, 21], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "attentional", "=", "True", ")", ":", "\n", "        ", "super", "(", "DecoderBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attentional", "=", "attentional", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.decoder.DecoderBase.from_opt": [[22, 30], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ",", "embeddings", ")", ":", "\n", "        ", "\"\"\"Alternate constructor.\n\n        Subclasses should override this method.\n        \"\"\"", "\n", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.decoder.RNNDecoderBase.__init__": [[83, 140], ["decoder.DecoderBase.__init__", "torch.Dropout", "torch.Dropout", "decoder.RNNDecoderBase._build_rnn", "onmt.modules.context_gate_factory", "onmt.modules.GlobalAttention", "onmt.modules.GlobalAttention", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.decoder.InputFeedRNNDecoder._build_rnn", "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.gate.context_gate_factory"], ["def", "__init__", "(", "self", ",", "rnn_type", ",", "bidirectional_encoder", ",", "num_layers", ",", "\n", "hidden_size", ",", "attn_type", "=", "\"general\"", ",", "attn_func", "=", "\"softmax\"", ",", "\n", "coverage_attn", "=", "False", ",", "context_gate", "=", "None", ",", "\n", "copy_attn", "=", "False", ",", "dropout", "=", "0.0", ",", "embeddings", "=", "None", ",", "\n", "reuse_copy_attn", "=", "False", ",", "copy_attn_type", "=", "\"general\"", ")", ":", "\n", "        ", "super", "(", "RNNDecoderBase", ",", "self", ")", ".", "__init__", "(", "\n", "attentional", "=", "attn_type", "!=", "\"none\"", "and", "attn_type", "is", "not", "None", ")", "\n", "\n", "self", ".", "bidirectional_encoder", "=", "bidirectional_encoder", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "# Decoder state", "\n", "self", ".", "state", "=", "{", "}", "\n", "\n", "# Build the RNN.", "\n", "self", ".", "rnn", "=", "self", ".", "_build_rnn", "(", "rnn_type", ",", "\n", "input_size", "=", "self", ".", "_input_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", ")", "\n", "\n", "# Set up the context gate.", "\n", "self", ".", "context_gate", "=", "None", "\n", "if", "context_gate", "is", "not", "None", ":", "\n", "            ", "self", ".", "context_gate", "=", "context_gate_factory", "(", "\n", "context_gate", ",", "self", ".", "_input_size", ",", "\n", "hidden_size", ",", "hidden_size", ",", "hidden_size", "\n", ")", "\n", "\n", "# Set up the standard attention.", "\n", "", "self", ".", "_coverage", "=", "coverage_attn", "\n", "if", "not", "self", ".", "attentional", ":", "\n", "            ", "if", "self", ".", "_coverage", ":", "\n", "                ", "raise", "ValueError", "(", "\"Cannot use coverage term with no attention.\"", ")", "\n", "", "self", ".", "attn", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "attn", "=", "GlobalAttention", "(", "\n", "hidden_size", ",", "coverage", "=", "coverage_attn", ",", "\n", "attn_type", "=", "attn_type", ",", "attn_func", "=", "attn_func", "\n", ")", "\n", "\n", "", "if", "copy_attn", "and", "not", "reuse_copy_attn", ":", "\n", "            ", "if", "copy_attn_type", "==", "\"none\"", "or", "copy_attn_type", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Cannot use copy_attn with copy_attn_type none\"", ")", "\n", "", "self", ".", "copy_attn", "=", "GlobalAttention", "(", "\n", "hidden_size", ",", "attn_type", "=", "copy_attn_type", ",", "attn_func", "=", "attn_func", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "copy_attn", "=", "None", "\n", "\n", "", "self", ".", "_reuse_copy_attn", "=", "reuse_copy_attn", "and", "copy_attn", "\n", "if", "self", ".", "_reuse_copy_attn", "and", "not", "self", ".", "attentional", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot reuse copy attention with no attention.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.decoder.RNNDecoderBase.from_opt": [[141, 158], ["cls"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ",", "embeddings", ")", ":", "\n", "        ", "\"\"\"Alternate constructor.\"\"\"", "\n", "return", "cls", "(", "\n", "opt", ".", "rnn_type", ",", "\n", "opt", ".", "brnn", ",", "\n", "opt", ".", "dec_layers", ",", "\n", "opt", ".", "dec_rnn_size", ",", "\n", "opt", ".", "global_attention", ",", "\n", "opt", ".", "global_attention_function", ",", "\n", "opt", ".", "coverage_attn", ",", "\n", "opt", ".", "context_gate", ",", "\n", "opt", ".", "copy_attn", ",", "\n", "opt", ".", "dropout", ",", "\n", "embeddings", ",", "\n", "opt", ".", "reuse_copy_attn", ",", "\n", "opt", ".", "copy_attn_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.decoder.RNNDecoderBase.init_state": [[159, 181], ["isinstance", "[].size", "[].data.new().zero_().unsqueeze", "tuple", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "decoder.RNNDecoderBase.init_state._fix_enc_hidden"], "methods", ["None"], ["", "def", "init_state", "(", "self", ",", "src", ",", "memory_bank", ",", "encoder_final", ")", ":", "\n", "        ", "\"\"\"Initialize decoder state with last state of the encoder.\"\"\"", "\n", "def", "_fix_enc_hidden", "(", "hidden", ")", ":", "\n", "# The encoder hidden is  (layers*directions) x batch x dim.", "\n", "# We need to convert it to layers x batch x (directions*dim).", "\n", "            ", "if", "self", ".", "bidirectional_encoder", ":", "\n", "                ", "hidden", "=", "torch", ".", "cat", "(", "[", "hidden", "[", "0", ":", "hidden", ".", "size", "(", "0", ")", ":", "2", "]", ",", "\n", "hidden", "[", "1", ":", "hidden", ".", "size", "(", "0", ")", ":", "2", "]", "]", ",", "2", ")", "\n", "", "return", "hidden", "\n", "\n", "", "if", "isinstance", "(", "encoder_final", ",", "tuple", ")", ":", "# LSTM", "\n", "            ", "self", ".", "state", "[", "\"hidden\"", "]", "=", "tuple", "(", "_fix_enc_hidden", "(", "enc_hid", ")", "\n", "for", "enc_hid", "in", "encoder_final", ")", "\n", "", "else", ":", "# GRU", "\n", "            ", "self", ".", "state", "[", "\"hidden\"", "]", "=", "(", "_fix_enc_hidden", "(", "encoder_final", ")", ",", ")", "\n", "\n", "# Init the input feed.", "\n", "", "batch_size", "=", "self", ".", "state", "[", "\"hidden\"", "]", "[", "0", "]", ".", "size", "(", "1", ")", "\n", "h_size", "=", "(", "batch_size", ",", "self", ".", "hidden_size", ")", "\n", "self", ".", "state", "[", "\"input_feed\"", "]", "=", "self", ".", "state", "[", "\"hidden\"", "]", "[", "0", "]", ".", "data", ".", "new", "(", "*", "h_size", ")", ".", "zero_", "(", ")", ".", "unsqueeze", "(", "0", ")", "\n", "self", ".", "state", "[", "\"coverage\"", "]", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.decoder.RNNDecoderBase.map_state": [[182, 185], ["tuple", "fn", "fn"], "methods", ["None"], ["", "def", "map_state", "(", "self", ",", "fn", ")", ":", "\n", "        ", "self", ".", "state", "[", "\"hidden\"", "]", "=", "tuple", "(", "fn", "(", "h", ",", "1", ")", "for", "h", "in", "self", ".", "state", "[", "\"hidden\"", "]", ")", "\n", "self", ".", "state", "[", "\"input_feed\"", "]", "=", "fn", "(", "self", ".", "state", "[", "\"input_feed\"", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.decoder.RNNDecoderBase.detach_state": [[186, 189], ["tuple", "decoder.RNNDecoderBase.state[].detach", "h.detach"], "methods", ["None"], ["", "def", "detach_state", "(", "self", ")", ":", "\n", "        ", "self", ".", "state", "[", "\"hidden\"", "]", "=", "tuple", "(", "h", ".", "detach", "(", ")", "for", "h", "in", "self", ".", "state", "[", "\"hidden\"", "]", ")", "\n", "self", ".", "state", "[", "\"input_feed\"", "]", "=", "self", ".", "state", "[", "\"input_feed\"", "]", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.decoder.RNNDecoderBase.forward": [[190, 233], ["decoder.RNNDecoderBase._run_forward_pass", "dec_outs[].unsqueeze", "isinstance", "[].unsqueeze", "type", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "type", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.decoder.InputFeedRNNDecoder._run_forward_pass"], ["", "def", "forward", "(", "self", ",", "tgt", ",", "memory_bank", ",", "memory_lengths", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tgt (LongTensor): sequences of padded tokens\n                 ``(tgt_len, batch, nfeats)``.\n            memory_bank (FloatTensor): vectors from the encoder\n                 ``(src_len, batch, hidden)``.\n            memory_lengths (LongTensor): the padded source lengths\n                ``(batch,)``.\n\n        Returns:\n            (FloatTensor, dict[str, FloatTensor]):\n\n            * dec_outs: output from the decoder (after attn)\n              ``(tgt_len, batch, hidden)``.\n            * attns: distribution over src at each tgt\n              ``(tgt_len, batch, src_len)``.\n        \"\"\"", "\n", "\n", "dec_state", ",", "dec_outs", ",", "attns", "=", "self", ".", "_run_forward_pass", "(", "\n", "tgt", ",", "memory_bank", ",", "memory_lengths", "=", "memory_lengths", ")", "\n", "\n", "# Update the state with the result.", "\n", "if", "not", "isinstance", "(", "dec_state", ",", "tuple", ")", ":", "\n", "            ", "dec_state", "=", "(", "dec_state", ",", ")", "\n", "", "self", ".", "state", "[", "\"hidden\"", "]", "=", "dec_state", "\n", "self", ".", "state", "[", "\"input_feed\"", "]", "=", "dec_outs", "[", "-", "1", "]", ".", "unsqueeze", "(", "0", ")", "\n", "self", ".", "state", "[", "\"coverage\"", "]", "=", "None", "\n", "if", "\"coverage\"", "in", "attns", ":", "\n", "            ", "self", ".", "state", "[", "\"coverage\"", "]", "=", "attns", "[", "\"coverage\"", "]", "[", "-", "1", "]", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "# Concatenates sequence of tensors along a new dimension.", "\n", "# NOTE: v0.3 to 0.4: dec_outs / attns[*] may not be list", "\n", "#       (in particular in case of SRU) it was not raising error in 0.3", "\n", "#       since stack(Variable) was allowed.", "\n", "#       In 0.4, SRU returns a tensor that shouldn't be stacke", "\n", "", "if", "type", "(", "dec_outs", ")", "==", "list", ":", "\n", "            ", "dec_outs", "=", "torch", ".", "stack", "(", "dec_outs", ")", "\n", "\n", "for", "k", "in", "attns", ":", "\n", "                ", "if", "type", "(", "attns", "[", "k", "]", ")", "==", "list", ":", "\n", "                    ", "attns", "[", "k", "]", "=", "torch", ".", "stack", "(", "attns", "[", "k", "]", ")", "\n", "", "", "", "return", "dec_outs", ",", "attns", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.decoder.StdRNNDecoder._run_forward_pass": [[251, 313], ["decoder.StdRNNDecoder.embeddings", "isinstance", "tgt.size", "rnn_output.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "decoder.StdRNNDecoder.dropout", "decoder.StdRNNDecoder.rnn", "decoder.StdRNNDecoder.rnn", "decoder.StdRNNDecoder.attn", "decoder.StdRNNDecoder.context_gate", "dec_outs.view.view.view", "rnn_output.transpose().contiguous", "memory_bank.transpose", "decoder.StdRNNDecoder.view", "rnn_output.view", "dec_outs.view.view.view", "decoder.StdRNNDecoder.size", "rnn_output.size", "dec_outs.view.view.size", "rnn_output.transpose"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.dropout"], ["def", "_run_forward_pass", "(", "self", ",", "tgt", ",", "memory_bank", ",", "memory_lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Private helper for running the specific RNN forward pass.\n        Must be overriden by all subclasses.\n\n        Args:\n            tgt (LongTensor): a sequence of input tokens tensors\n                ``(len, batch, nfeats)``.\n            memory_bank (FloatTensor): output(tensor sequence) from the\n                encoder RNN of size ``(src_len, batch, hidden_size)``.\n            memory_lengths (LongTensor): the source memory_bank lengths.\n\n        Returns:\n            (Tensor, List[FloatTensor], Dict[str, List[FloatTensor]):\n\n            * dec_state: final hidden state from the decoder.\n            * dec_outs: an array of output of every time\n              step from the decoder.\n            * attns: a dictionary of different\n              type of attention Tensor array of every time\n              step from the decoder.\n        \"\"\"", "\n", "\n", "assert", "self", ".", "copy_attn", "is", "None", "# TODO, no support yet.", "\n", "assert", "not", "self", ".", "_coverage", "# TODO, no support yet.", "\n", "\n", "attns", "=", "{", "}", "\n", "emb", "=", "self", ".", "embeddings", "(", "tgt", ")", "\n", "\n", "if", "isinstance", "(", "self", ".", "rnn", ",", "nn", ".", "GRU", ")", ":", "\n", "            ", "rnn_output", ",", "dec_state", "=", "self", ".", "rnn", "(", "emb", ",", "self", ".", "state", "[", "\"hidden\"", "]", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "rnn_output", ",", "dec_state", "=", "self", ".", "rnn", "(", "emb", ",", "self", ".", "state", "[", "\"hidden\"", "]", ")", "\n", "\n", "# Check", "\n", "", "tgt_len", ",", "tgt_batch", ",", "_", "=", "tgt", ".", "size", "(", ")", "\n", "output_len", ",", "output_batch", ",", "_", "=", "rnn_output", ".", "size", "(", ")", "\n", "aeq", "(", "tgt_len", ",", "output_len", ")", "\n", "aeq", "(", "tgt_batch", ",", "output_batch", ")", "\n", "\n", "# Calculate the attention.", "\n", "if", "not", "self", ".", "attentional", ":", "\n", "            ", "dec_outs", "=", "rnn_output", "\n", "", "else", ":", "\n", "            ", "dec_outs", ",", "p_attn", "=", "self", ".", "attn", "(", "\n", "rnn_output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ",", "\n", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "memory_lengths", "=", "memory_lengths", "\n", ")", "\n", "attns", "[", "\"std\"", "]", "=", "p_attn", "\n", "\n", "# Calculate the context gate.", "\n", "", "if", "self", ".", "context_gate", "is", "not", "None", ":", "\n", "            ", "dec_outs", "=", "self", ".", "context_gate", "(", "\n", "emb", ".", "view", "(", "-", "1", ",", "emb", ".", "size", "(", "2", ")", ")", ",", "\n", "rnn_output", ".", "view", "(", "-", "1", ",", "rnn_output", ".", "size", "(", "2", ")", ")", ",", "\n", "dec_outs", ".", "view", "(", "-", "1", ",", "dec_outs", ".", "size", "(", "2", ")", ")", "\n", ")", "\n", "dec_outs", "=", "dec_outs", ".", "view", "(", "tgt_len", ",", "tgt_batch", ",", "self", ".", "hidden_size", ")", "\n", "\n", "", "dec_outs", "=", "self", ".", "dropout", "(", "dec_outs", ")", "\n", "return", "dec_state", ",", "dec_outs", ",", "attns", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.decoder.StdRNNDecoder._build_rnn": [[314, 317], ["onmt.utils.rnn_factory.rnn_factory"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.rnn_factory.rnn_factory"], ["", "def", "_build_rnn", "(", "self", ",", "rnn_type", ",", "**", "kwargs", ")", ":", "\n", "        ", "rnn", ",", "_", "=", "rnn_factory", "(", "rnn_type", ",", "**", "kwargs", ")", "\n", "return", "rnn", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.decoder.StdRNNDecoder._input_size": [[318, 321], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_input_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", ".", "embedding_size", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.decoder.InputFeedRNNDecoder._run_forward_pass": [[351, 416], ["decoder.InputFeedRNNDecoder.state[].squeeze", "decoder.InputFeedRNNDecoder.size", "tgt.size", "onmt.utils.misc.aeq", "decoder.InputFeedRNNDecoder.embeddings", "decoder.InputFeedRNNDecoder.split", "decoder.InputFeedRNNDecoder.dim", "decoder.InputFeedRNNDecoder.state[].squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "decoder.InputFeedRNNDecoder.rnn", "decoder.InputFeedRNNDecoder.dropout", "decoder.InputFeedRNNDecoder.attn", "attns[].append", "decoder.InputFeedRNNDecoder.context_gate", "decoder.InputFeedRNNDecoder.copy_attn", "emb_t.squeeze", "memory_bank.transpose", "memory_bank.transpose"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.dropout", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["def", "_run_forward_pass", "(", "self", ",", "tgt", ",", "memory_bank", ",", "memory_lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        See StdRNNDecoder._run_forward_pass() for description\n        of arguments and return values.\n        \"\"\"", "\n", "# Additional args check.", "\n", "input_feed", "=", "self", ".", "state", "[", "\"input_feed\"", "]", ".", "squeeze", "(", "0", ")", "\n", "input_feed_batch", ",", "_", "=", "input_feed", ".", "size", "(", ")", "\n", "_", ",", "tgt_batch", ",", "_", "=", "tgt", ".", "size", "(", ")", "\n", "aeq", "(", "tgt_batch", ",", "input_feed_batch", ")", "\n", "# END Additional args check.", "\n", "\n", "dec_outs", "=", "[", "]", "\n", "attns", "=", "{", "}", "\n", "if", "self", ".", "attn", "is", "not", "None", ":", "\n", "            ", "attns", "[", "\"std\"", "]", "=", "[", "]", "\n", "", "if", "self", ".", "copy_attn", "is", "not", "None", "or", "self", ".", "_reuse_copy_attn", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "[", "]", "\n", "", "if", "self", ".", "_coverage", ":", "\n", "            ", "attns", "[", "\"coverage\"", "]", "=", "[", "]", "\n", "\n", "", "emb", "=", "self", ".", "embeddings", "(", "tgt", ")", "\n", "assert", "emb", ".", "dim", "(", ")", "==", "3", "# len x batch x embedding_dim", "\n", "\n", "dec_state", "=", "self", ".", "state", "[", "\"hidden\"", "]", "\n", "coverage", "=", "self", ".", "state", "[", "\"coverage\"", "]", ".", "squeeze", "(", "0", ")", "if", "self", ".", "state", "[", "\"coverage\"", "]", "is", "not", "None", "else", "None", "\n", "\n", "# Input feed concatenates hidden state with", "\n", "# input at every time step.", "\n", "for", "emb_t", "in", "emb", ".", "split", "(", "1", ")", ":", "\n", "            ", "decoder_input", "=", "torch", ".", "cat", "(", "[", "emb_t", ".", "squeeze", "(", "0", ")", ",", "input_feed", "]", ",", "1", ")", "\n", "rnn_output", ",", "dec_state", "=", "self", ".", "rnn", "(", "decoder_input", ",", "dec_state", ")", "\n", "if", "self", ".", "attentional", ":", "\n", "                ", "decoder_output", ",", "p_attn", "=", "self", ".", "attn", "(", "\n", "rnn_output", ",", "\n", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "memory_lengths", "=", "memory_lengths", ")", "\n", "attns", "[", "\"std\"", "]", ".", "append", "(", "p_attn", ")", "\n", "", "else", ":", "\n", "                ", "decoder_output", "=", "rnn_output", "\n", "", "if", "self", ".", "context_gate", "is", "not", "None", ":", "\n", "# TODO: context gate should be employed", "\n", "# instead of second RNN transform.", "\n", "                ", "decoder_output", "=", "self", ".", "context_gate", "(", "\n", "decoder_input", ",", "rnn_output", ",", "decoder_output", "\n", ")", "\n", "", "decoder_output", "=", "self", ".", "dropout", "(", "decoder_output", ")", "\n", "input_feed", "=", "decoder_output", "\n", "\n", "dec_outs", "+=", "[", "decoder_output", "]", "\n", "\n", "# Update the coverage attention.", "\n", "if", "self", ".", "_coverage", ":", "\n", "                ", "coverage", "=", "p_attn", "if", "coverage", "is", "None", "else", "p_attn", "+", "coverage", "\n", "attns", "[", "\"coverage\"", "]", "+=", "[", "coverage", "]", "\n", "\n", "", "if", "self", ".", "copy_attn", "is", "not", "None", ":", "\n", "                ", "_", ",", "copy_attn", "=", "self", ".", "copy_attn", "(", "\n", "decoder_output", ",", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", "attns", "[", "\"copy\"", "]", "+=", "[", "copy_attn", "]", "\n", "", "elif", "self", ".", "_reuse_copy_attn", ":", "\n", "                ", "attns", "[", "\"copy\"", "]", "=", "attns", "[", "\"std\"", "]", "\n", "\n", "", "", "return", "dec_state", ",", "dec_outs", ",", "attns", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.decoder.InputFeedRNNDecoder._build_rnn": [[417, 423], ["stacked_cell"], "methods", ["None"], ["", "def", "_build_rnn", "(", "self", ",", "rnn_type", ",", "input_size", ",", "\n", "hidden_size", ",", "num_layers", ",", "dropout", ")", ":", "\n", "        ", "assert", "rnn_type", "!=", "\"SRU\"", ",", "\"SRU doesn't support input feed! \"", "\"Please set -input_feed 0!\"", "\n", "stacked_cell", "=", "StackedLSTM", "if", "rnn_type", "==", "\"LSTM\"", "else", "StackedGRU", "\n", "return", "stacked_cell", "(", "num_layers", ",", "input_size", ",", "hidden_size", ",", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.decoder.InputFeedRNNDecoder._input_size": [[424, 428], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_input_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"Using input feed by concatenating input with attention vectors.\"\"\"", "\n", "return", "self", ".", "embeddings", ".", "embedding_size", "+", "self", ".", "hidden_size", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.__init__": [[18, 20], ["tuple"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model_dec_outs", ")", ":", "\n", "        ", "self", ".", "model_dec_outs", "=", "tuple", "(", "model_dec_outs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze": [[21, 27], ["ensemble.EnsembleDecoderOutput", "x.squeeze"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "squeeze", "(", "self", ",", "dim", "=", "None", ")", ":", "\n", "        ", "\"\"\"Delegate squeeze to avoid modifying\n        :func:`onmt.translate.translator.Translator.translate_batch()`\n        \"\"\"", "\n", "return", "EnsembleDecoderOutput", "(", "[", "\n", "x", ".", "squeeze", "(", "dim", ")", "for", "x", "in", "self", ".", "model_dec_outs", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.__getitem__": [[28, 30], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "model_dec_outs", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleEncoder.__init__": [[34, 37], ["onmt.encoders.encoder.EncoderBase.__init__", "torch.ModuleList", "torch.ModuleList"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "model_encoders", ")", ":", "\n", "        ", "super", "(", "EnsembleEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model_encoders", "=", "nn", ".", "ModuleList", "(", "model_encoders", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleEncoder.forward": [[38, 43], ["zip", "model_encoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "enc_hidden", ",", "memory_bank", ",", "_", "=", "zip", "(", "*", "[", "\n", "model_encoder", "(", "src", ",", "lengths", ")", "\n", "for", "model_encoder", "in", "self", ".", "model_encoders", "]", ")", "\n", "return", "enc_hidden", ",", "memory_bank", ",", "lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoder.__init__": [[47, 50], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "model_decoders", ")", ":", "\n", "        ", "super", "(", "EnsembleDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model_decoders", "=", "nn", ".", "ModuleList", "(", "model_decoders", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoder.forward": [[51, 64], ["zip", "ensemble.EnsembleDecoder.combine_attns", "ensemble.EnsembleDecoderOutput", "model_decoder", "enumerate"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoder.combine_attns"], ["", "def", "forward", "(", "self", ",", "tgt", ",", "memory_bank", ",", "memory_lengths", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"See :func:`onmt.decoders.decoder.DecoderBase.forward()`.\"\"\"", "\n", "# Memory_lengths is a single tensor shared between all models.", "\n", "# This assumption will not hold if Translator is modified", "\n", "# to calculate memory_lengths as something other than the length", "\n", "# of the input.", "\n", "dec_outs", ",", "attns", "=", "zip", "(", "*", "[", "\n", "model_decoder", "(", "\n", "tgt", ",", "memory_bank", "[", "i", "]", ",", "\n", "memory_lengths", "=", "memory_lengths", ",", "step", "=", "step", ")", "\n", "for", "i", ",", "model_decoder", "in", "enumerate", "(", "self", ".", "model_decoders", ")", "]", ")", "\n", "mean_attns", "=", "self", ".", "combine_attns", "(", "attns", ")", "\n", "return", "EnsembleDecoderOutput", "(", "dec_outs", ")", ",", "mean_attns", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoder.combine_attns": [[65, 70], ["attns[].keys", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.mean", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.mean", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.mean", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.mean"], ["", "def", "combine_attns", "(", "self", ",", "attns", ")", ":", "\n", "        ", "result", "=", "{", "}", "\n", "for", "key", "in", "attns", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "            ", "result", "[", "key", "]", "=", "torch", ".", "stack", "(", "[", "attn", "[", "key", "]", "for", "attn", "in", "attns", "]", ")", ".", "mean", "(", "0", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoder.init_state": [[71, 75], ["enumerate", "model_decoder.init_state"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoder.init_state"], ["", "def", "init_state", "(", "self", ",", "src", ",", "memory_bank", ",", "enc_hidden", ")", ":", "\n", "        ", "\"\"\" See :obj:`RNNDecoderBase.init_state()` \"\"\"", "\n", "for", "i", ",", "model_decoder", "in", "enumerate", "(", "self", ".", "model_decoders", ")", ":", "\n", "            ", "model_decoder", ".", "init_state", "(", "src", ",", "memory_bank", "[", "i", "]", ",", "enc_hidden", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoder.map_state": [[76, 79], ["model_decoder.map_state"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoder.map_state"], ["", "", "def", "map_state", "(", "self", ",", "fn", ")", ":", "\n", "        ", "for", "model_decoder", "in", "self", ".", "model_decoders", ":", "\n", "            ", "model_decoder", ".", "map_state", "(", "fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleGenerator.__init__": [[86, 90], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "model_generators", ",", "raw_probs", "=", "False", ")", ":", "\n", "        ", "super", "(", "EnsembleGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model_generators", "=", "nn", ".", "ModuleList", "(", "model_generators", ")", "\n", "self", ".", "_raw_probs", "=", "raw_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleGenerator.forward": [[91, 105], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.log", "torch.log", "torch.log", "torch.log", "torch.stack.mean", "torch.stack.mean", "torch.exp().mean", "torch.exp().mean", "torch.exp().mean", "torch.exp().mean", "mg", "mg", "zip", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.mean", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.mean", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.mean", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.mean", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.mean", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.mean"], ["", "def", "forward", "(", "self", ",", "hidden", ",", "attn", "=", "None", ",", "src_map", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Compute a distribution over the target dictionary\n        by averaging distributions from models in the ensemble.\n        All models in the ensemble must share a target vocabulary.\n        \"\"\"", "\n", "distributions", "=", "torch", ".", "stack", "(", "\n", "[", "mg", "(", "h", ")", "if", "attn", "is", "None", "else", "mg", "(", "h", ",", "attn", ",", "src_map", ")", "\n", "for", "h", ",", "mg", "in", "zip", "(", "hidden", ",", "self", ".", "model_generators", ")", "]", "\n", ")", "\n", "if", "self", ".", "_raw_probs", ":", "\n", "            ", "return", "torch", ".", "log", "(", "torch", ".", "exp", "(", "distributions", ")", ".", "mean", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "distributions", ".", "mean", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleModel.__init__": [[109, 116], ["ensemble.EnsembleEncoder", "ensemble.EnsembleDecoder", "onmt.models.NMTModel.__init__", "ensemble.EnsembleGenerator", "torch.ModuleList", "torch.ModuleList"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "models", ",", "raw_probs", "=", "False", ")", ":", "\n", "        ", "encoder", "=", "EnsembleEncoder", "(", "model", ".", "encoder", "for", "model", "in", "models", ")", "\n", "decoder", "=", "EnsembleDecoder", "(", "model", ".", "decoder", "for", "model", "in", "models", ")", "\n", "super", "(", "EnsembleModel", ",", "self", ")", ".", "__init__", "(", "encoder", ",", "decoder", ")", "\n", "self", ".", "generator", "=", "EnsembleGenerator", "(", "\n", "[", "model", ".", "generator", "for", "model", "in", "models", "]", ",", "raw_probs", ")", "\n", "self", ".", "models", "=", "nn", ".", "ModuleList", "(", "models", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.load_test_model": [[118, 150], ["ensemble.EnsembleModel", "onmt.model_builder.load_test_model", "models.append", "fields.items", "iter", "dict", "iter"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.load_test_model"], ["", "", "def", "load_test_model", "(", "opt", ")", ":", "\n", "    ", "\"\"\"Read in multiple models for ensemble.\"\"\"", "\n", "shared_fields", "=", "None", "\n", "shared_model_opt", "=", "None", "\n", "models", "=", "[", "]", "\n", "for", "model_path", "in", "opt", ".", "models", ":", "\n", "        ", "fields", ",", "model", ",", "model_opt", "=", "onmt", ".", "model_builder", ".", "load_test_model", "(", "opt", ",", "model_path", "=", "model_path", ")", "\n", "if", "shared_fields", "is", "None", ":", "\n", "            ", "shared_fields", "=", "fields", "\n", "", "else", ":", "\n", "            ", "for", "key", ",", "field", "in", "fields", ".", "items", "(", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "f_iter", "=", "iter", "(", "field", ")", "\n", "", "except", "TypeError", ":", "\n", "                    ", "f_iter", "=", "[", "(", "key", ",", "field", ")", "]", "\n", "", "for", "sn", ",", "sf", "in", "f_iter", ":", "\n", "                    ", "if", "sf", "is", "not", "None", "and", "'vocab'", "in", "sf", ".", "__dict__", ":", "\n", "                        ", "sh_field", "=", "shared_fields", "[", "key", "]", "\n", "try", ":", "\n", "                            ", "sh_f_iter", "=", "iter", "(", "sh_field", ")", "\n", "", "except", "TypeError", ":", "\n", "                            ", "sh_f_iter", "=", "[", "(", "key", ",", "sh_field", ")", "]", "\n", "", "sh_f_dict", "=", "dict", "(", "sh_f_iter", ")", "\n", "assert", "sf", ".", "vocab", ".", "stoi", "==", "sh_f_dict", "[", "sn", "]", ".", "vocab", ".", "stoi", ",", "\"Ensemble models must use the same \"", "\"preprocessed data\"", "\n", "", "", "", "", "models", ".", "append", "(", "model", ")", "\n", "if", "shared_model_opt", "is", "None", ":", "\n", "            ", "shared_model_opt", "=", "model_opt", "\n", "", "", "ensemble_model", "=", "EnsembleModel", "(", "models", ",", "opt", ".", "avg_raw_probs", ")", "\n", "return", "shared_fields", ",", "ensemble_model", ",", "shared_model_opt", "\n", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam_search.BeamSearch.__init__": [[56, 102], ["onmt.translate.decode_strategy.DecodeStrategy.__init__", "torch.zeros", "torch.arange", "torch.arange", "torch.tensor().repeat", "torch.empty", "torch.empty", "torch.empty", "range", "torch.tensor", "float"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "beam_size", ",", "batch_size", ",", "pad", ",", "bos", ",", "eos", ",", "n_best", ",", "mb_device", ",", "\n", "global_scorer", ",", "min_length", ",", "max_length", ",", "return_attention", ",", "\n", "block_ngram_repeat", ",", "exclusion_tokens", ",", "memory_lengths", ",", "\n", "stepwise_penalty", ")", ":", "\n", "        ", "super", "(", "BeamSearch", ",", "self", ")", ".", "__init__", "(", "\n", "pad", ",", "bos", ",", "eos", ",", "batch_size", ",", "mb_device", ",", "beam_size", ",", "min_length", ",", "\n", "block_ngram_repeat", ",", "exclusion_tokens", ",", "return_attention", ",", "\n", "max_length", ")", "\n", "# beam parameters", "\n", "self", ".", "global_scorer", "=", "global_scorer", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "self", ".", "n_best", "=", "n_best", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n", "# result caching", "\n", "self", ".", "hypotheses", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "# beam state", "\n", "self", ".", "top_beam_finished", "=", "torch", ".", "zeros", "(", "[", "batch_size", "]", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "self", ".", "_batch_offset", "=", "torch", ".", "arange", "(", "batch_size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "self", ".", "_beam_offset", "=", "torch", ".", "arange", "(", "\n", "0", ",", "batch_size", "*", "beam_size", ",", "step", "=", "beam_size", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "mb_device", ")", "\n", "self", ".", "topk_log_probs", "=", "torch", ".", "tensor", "(", "\n", "[", "0.0", "]", "+", "[", "float", "(", "\"-inf\"", ")", "]", "*", "(", "beam_size", "-", "1", ")", ",", "device", "=", "mb_device", "\n", ")", ".", "repeat", "(", "batch_size", ")", "\n", "self", ".", "select_indices", "=", "None", "\n", "self", ".", "_memory_lengths", "=", "memory_lengths", "\n", "\n", "# buffers for the topk scores and 'backpointer'", "\n", "self", ".", "topk_scores", "=", "torch", ".", "empty", "(", "(", "batch_size", ",", "beam_size", ")", ",", "\n", "dtype", "=", "torch", ".", "float", ",", "device", "=", "mb_device", ")", "\n", "self", ".", "topk_ids", "=", "torch", ".", "empty", "(", "(", "batch_size", ",", "beam_size", ")", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "mb_device", ")", "\n", "self", ".", "_batch_index", "=", "torch", ".", "empty", "(", "[", "batch_size", ",", "beam_size", "]", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "device", "=", "mb_device", ")", "\n", "self", ".", "done", "=", "False", "\n", "# \"global state\" of the old beam", "\n", "self", ".", "_prev_penalty", "=", "None", "\n", "self", ".", "_coverage", "=", "None", "\n", "\n", "self", ".", "_stepwise_cov_pen", "=", "(", "\n", "stepwise_penalty", "and", "self", ".", "global_scorer", ".", "has_cov_pen", ")", "\n", "self", ".", "_vanilla_cov_pen", "=", "(", "\n", "not", "stepwise_penalty", "and", "self", ".", "global_scorer", ".", "has_cov_pen", ")", "\n", "self", ".", "_cov_pen", "=", "self", ".", "global_scorer", ".", "has_cov_pen", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam_search.BeamSearch.current_predictions": [[103, 106], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "current_predictions", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "alive_seq", "[", ":", ",", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam_search.BeamSearch.current_origin": [[107, 110], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "current_origin", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "select_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam_search.BeamSearch.current_backptr": [[111, 116], ["beam_search.BeamSearch.select_indices.view().fmod", "beam_search.BeamSearch.select_indices.view"], "methods", ["None"], ["", "@", "property", "\n", "def", "current_backptr", "(", "self", ")", ":", "\n", "# for testing", "\n", "        ", "return", "self", ".", "select_indices", ".", "view", "(", "self", ".", "batch_size", ",", "self", ".", "beam_size", ")", ".", "fmod", "(", "self", ".", "beam_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam_search.BeamSearch.advance": [[117, 214], ["log_probs.size", "len", "beam_search.BeamSearch.ensure_min_length", "beam_search.BeamSearch.topk_log_probs.view", "beam_search.BeamSearch.block_ngram_repeats", "beam_search.BeamSearch.global_scorer.length_penalty", "curr_scores.reshape.reshape.reshape", "torch.topk", "torch.mul", "torch.div", "beam_search.BeamSearch._beam_offset[].unsqueeze", "beam_search.BeamSearch._batch_index.view", "beam_search.BeamSearch.topk_ids.fmod_", "dec_attn.keys", "torch.cat", "beam_search.BeamSearch.topk_ids.eq", "beam_search.BeamSearch.ensure_max_length", "beam_search.BeamSearch.global_scorer.cov_penalty().view", "torch.cat", "attn.index_select", "beam_search.BeamSearch.global_scorer.cov_penalty", "beam_search.BeamSearch.view", "torch.cat", "beam_search.BeamSearch.alive_seq.index_select", "beam_search.BeamSearch.topk_ids.view", "beam_search.BeamSearch.alive_attn.index_select", "torch.cat", "beam_search.BeamSearch.global_scorer.cov_penalty", "beam_search.BeamSearch.dec_outputs.index_select", "torch.zeros_like", "beam_search.BeamSearch._coverage.index_select", "beam_search.BeamSearch.global_scorer.cov_penalty().view", "beam_search.BeamSearch.dec_attns[].index_select", "beam_search.BeamSearch.global_scorer.cov_penalty"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.ensure_min_length", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.block_ngram_repeats", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.ensure_max_length"], ["", "def", "advance", "(", "self", ",", "log_probs", ",", "attn", ",", "dec_out_attn", ")", ":", "\n", "        ", "vocab_size", "=", "log_probs", ".", "size", "(", "-", "1", ")", "\n", "dec_out", ",", "dec_attn", "=", "dec_out_attn", "\n", "\n", "# using integer division to get an integer _B without casting", "\n", "_B", "=", "log_probs", ".", "shape", "[", "0", "]", "//", "self", ".", "beam_size", "\n", "\n", "\n", "if", "self", ".", "_stepwise_cov_pen", "and", "self", ".", "_prev_penalty", "is", "not", "None", ":", "\n", "            ", "self", ".", "topk_log_probs", "+=", "self", ".", "_prev_penalty", "\n", "self", ".", "topk_log_probs", "-=", "self", ".", "global_scorer", ".", "cov_penalty", "(", "\n", "self", ".", "_coverage", "+", "attn", ",", "self", ".", "global_scorer", ".", "beta", ")", ".", "view", "(", "\n", "_B", ",", "self", ".", "beam_size", ")", "\n", "\n", "# force the output to be longer than self.min_length", "\n", "", "step", "=", "len", "(", "self", ")", "\n", "self", ".", "ensure_min_length", "(", "log_probs", ")", "\n", "\n", "# Multiply probs by the beam probability.", "\n", "log_probs", "+=", "self", ".", "topk_log_probs", ".", "view", "(", "_B", "*", "self", ".", "beam_size", ",", "1", ")", "\n", "\n", "self", ".", "block_ngram_repeats", "(", "log_probs", ")", "\n", "\n", "# if the sequence ends now, then the penalty is the current", "\n", "# length + 1, to include the EOS token", "\n", "length_penalty", "=", "self", ".", "global_scorer", ".", "length_penalty", "(", "\n", "step", "+", "1", ",", "alpha", "=", "self", ".", "global_scorer", ".", "alpha", ")", "\n", "\n", "# Flatten probs into a list of possibilities.", "\n", "curr_scores", "=", "log_probs", "/", "length_penalty", "\n", "curr_scores", "=", "curr_scores", ".", "reshape", "(", "_B", ",", "self", ".", "beam_size", "*", "vocab_size", ")", "\n", "# torch.topk(curr_scores, self.beam_size, dim=-1,", "\n", "#            out=(self.topk_scores, self.topk_ids))", "\n", "self", ".", "topk_scores", ",", "self", ".", "topk_ids", "=", "torch", ".", "topk", "(", "curr_scores", ",", "self", ".", "beam_size", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Recover log probs.", "\n", "# Length penalty is just a scalar. It doesn't matter if it's applied", "\n", "# before or after the topk.", "\n", "# torch.mul(self.topk_scores, length_penalty, out=self.topk_log_probs)", "\n", "self", ".", "topk_log_probs", "=", "torch", ".", "mul", "(", "self", ".", "topk_scores", ",", "length_penalty", ")", "\n", "\n", "# Resolve beam origin and map to batch index flat representation.", "\n", "# torch.div(self.topk_ids, vocab_size, out=self._batch_index)", "\n", "self", ".", "_batch_index", "=", "torch", ".", "div", "(", "self", ".", "topk_ids", ",", "vocab_size", ")", "\n", "self", ".", "_batch_index", "+=", "self", ".", "_beam_offset", "[", ":", "_B", "]", ".", "unsqueeze", "(", "1", ")", "\n", "self", ".", "select_indices", "=", "self", ".", "_batch_index", ".", "view", "(", "_B", "*", "self", ".", "beam_size", ")", "\n", "\n", "self", ".", "topk_ids", ".", "fmod_", "(", "vocab_size", ")", "# resolve true word ids", "\n", "if", "self", ".", "dec_outputs", "is", "None", ":", "\n", "            ", "self", ".", "dec_outputs", "=", "dec_out", "\n", "", "else", ":", "\n", "            ", "self", ".", "dec_outputs", "=", "torch", ".", "cat", "(", "\n", "[", "self", ".", "dec_outputs", ".", "index_select", "(", "1", ",", "self", ".", "select_indices", ")", ",", "\n", "dec_out", "]", ",", "0", ")", "\n", "# self.dec_outputs = torch.cat((self.dec_outputs, dec_out), 0)", "\n", "", "for", "key", "in", "dec_attn", ".", "keys", "(", ")", ":", "\n", "            ", "if", "key", "not", "in", "self", ".", "dec_attns", ":", "\n", "                ", "self", ".", "dec_attns", "[", "key", "]", "=", "dec_attn", "[", "key", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "dec_attns", "[", "key", "]", "=", "torch", ".", "cat", "(", "\n", "[", "self", ".", "dec_attns", "[", "key", "]", ".", "index_select", "(", "1", ",", "self", ".", "select_indices", ")", ",", "dec_attn", "[", "key", "]", "]", ")", "\n", "\n", "# Append last prediction.", "\n", "# resort", "\n", "", "", "self", ".", "alive_seq", "=", "torch", ".", "cat", "(", "\n", "[", "self", ".", "alive_seq", ".", "index_select", "(", "0", ",", "self", ".", "select_indices", ")", ",", "\n", "self", ".", "topk_ids", ".", "view", "(", "_B", "*", "self", ".", "beam_size", ",", "1", ")", "]", ",", "-", "1", ")", "\n", "if", "self", ".", "return_attention", "or", "self", ".", "_cov_pen", ":", "\n", "            ", "current_attn", "=", "attn", ".", "index_select", "(", "1", ",", "self", ".", "select_indices", ")", "\n", "if", "step", "==", "1", ":", "\n", "                ", "self", ".", "alive_attn", "=", "current_attn", "\n", "# update global state (step == 1)", "\n", "if", "self", ".", "_cov_pen", ":", "# coverage penalty", "\n", "                    ", "self", ".", "_prev_penalty", "=", "torch", ".", "zeros_like", "(", "self", ".", "topk_log_probs", ")", "\n", "self", ".", "_coverage", "=", "current_attn", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "alive_attn", "=", "self", ".", "alive_attn", ".", "index_select", "(", "\n", "1", ",", "self", ".", "select_indices", ")", "\n", "self", ".", "alive_attn", "=", "torch", ".", "cat", "(", "[", "self", ".", "alive_attn", ",", "current_attn", "]", ",", "0", ")", "\n", "# update global state (step > 1)", "\n", "if", "self", ".", "_cov_pen", ":", "\n", "                    ", "self", ".", "_coverage", "=", "self", ".", "_coverage", ".", "index_select", "(", "\n", "1", ",", "self", ".", "select_indices", ")", "\n", "self", ".", "_coverage", "+=", "current_attn", "\n", "self", ".", "_prev_penalty", "=", "self", ".", "global_scorer", ".", "cov_penalty", "(", "\n", "self", ".", "_coverage", ",", "beta", "=", "self", ".", "global_scorer", ".", "beta", ")", ".", "view", "(", "\n", "_B", ",", "self", ".", "beam_size", ")", "\n", "\n", "", "", "", "if", "self", ".", "_vanilla_cov_pen", ":", "\n", "# shape: (batch_size x beam_size, 1)", "\n", "            ", "cov_penalty", "=", "self", ".", "global_scorer", ".", "cov_penalty", "(", "\n", "self", ".", "_coverage", ",", "\n", "beta", "=", "self", ".", "global_scorer", ".", "beta", ")", "\n", "self", ".", "topk_scores", "-=", "cov_penalty", ".", "view", "(", "_B", ",", "self", ".", "beam_size", ")", "\n", "\n", "", "self", ".", "is_finished", "=", "self", ".", "topk_ids", ".", "eq", "(", "self", ".", "eos", ")", "\n", "self", ".", "ensure_max_length", "(", ")", "\n", "# alive_seq: batch_size * beam_size, max_len", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam_search.BeamSearch.update_finished": [[216, 291], ["beam_search.BeamSearch.topk_log_probs.masked_fill_", "beam_search.BeamSearch.is_finished.to", "beam_search.BeamSearch.is_finished[].eq", "beam_search.BeamSearch.alive_seq.view", "range", "torch.tensor", "beam_search.BeamSearch.alive_attn.view", "beam_search.BeamSearch.is_finished.size", "beam_search.BeamSearch.is_finished[].nonzero().view", "len", "beam_search.BeamSearch.top_beam_finished.index_select", "beam_search.BeamSearch._batch_offset.index_select", "non_finished.to.to.to", "beam_search.BeamSearch.topk_log_probs.index_select", "beam_search.BeamSearch._batch_index.index_select", "beam_search.BeamSearch._batch_index.view", "beam_search.BeamSearch.index_select().view", "beam_search.BeamSearch.topk_scores.index_select", "beam_search.BeamSearch.topk_ids.index_select", "beam_search.BeamSearch.alive_attn.size", "beam_search.BeamSearch.hypotheses[].append", "sorted", "enumerate", "non_finished_batch.append", "beam_search.BeamSearch.alive_seq.size", "beam_search.BeamSearch.alive_attn.size", "attention.index_select().view", "beam_search.BeamSearch.is_finished[].nonzero", "len", "beam_search.BeamSearch.scores[].append", "beam_search.BeamSearch.predictions[].append", "beam_search.BeamSearch.attention[].append", "beam_search.BeamSearch.index_select", "beam_search.BeamSearch._coverage.view().index_select().view", "attention.index_select", "beam_search.BeamSearch._prev_penalty.index_select", "beam_search.BeamSearch._coverage.view().index_select", "beam_search.BeamSearch._coverage.view"], "methods", ["None"], ["", "def", "update_finished", "(", "self", ",", "training", ")", ":", "\n", "# Penalize beams that finished.", "\n", "        ", "_B_old", "=", "self", ".", "topk_log_probs", ".", "shape", "[", "0", "]", "\n", "step", "=", "self", ".", "alive_seq", ".", "shape", "[", "-", "1", "]", "# 1 greater than the step in advance", "\n", "self", ".", "topk_log_probs", ".", "masked_fill_", "(", "self", ".", "is_finished", ",", "-", "1e10", ")", "\n", "# on real data (newstest2017) with the pretrained transformer,", "\n", "# it's faster to not move this back to the original device", "\n", "self", ".", "is_finished", "=", "self", ".", "is_finished", ".", "to", "(", "'cpu'", ")", "\n", "self", ".", "top_beam_finished", "|=", "self", ".", "is_finished", "[", ":", ",", "0", "]", ".", "eq", "(", "1", ")", "\n", "# predictions: batch_size, beam_size, max_step + 1", "\n", "predictions", "=", "self", ".", "alive_seq", ".", "view", "(", "_B_old", ",", "self", ".", "beam_size", ",", "step", ")", "\n", "# is_finished: batch_size, beam_size", "\n", "attention", "=", "(", "\n", "self", ".", "alive_attn", ".", "view", "(", "\n", "step", "-", "1", ",", "_B_old", ",", "self", ".", "beam_size", ",", "self", ".", "alive_attn", ".", "size", "(", "-", "1", ")", ")", "\n", "if", "self", ".", "alive_attn", "is", "not", "None", "else", "None", ")", "\n", "non_finished_batch", "=", "[", "]", "\n", "# batch", "\n", "for", "i", "in", "range", "(", "self", ".", "is_finished", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "b", "=", "self", ".", "_batch_offset", "[", "i", "]", "\n", "finished_hyp", "=", "self", ".", "is_finished", "[", "i", "]", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "# Store finished hypotheses for this batch.", "\n", "for", "j", "in", "finished_hyp", ":", "\n", "                ", "self", ".", "hypotheses", "[", "b", "]", ".", "append", "(", "(", "\n", "self", ".", "topk_scores", "[", "i", ",", "j", "]", ",", "\n", "predictions", "[", "i", ",", "j", ",", "1", ":", "]", ",", "# Ignore start_token.", "\n", "attention", "[", ":", ",", "i", ",", "j", ",", ":", "self", ".", "_memory_lengths", "[", "i", "]", "]", "\n", "if", "attention", "is", "not", "None", "else", "None", ")", ")", "\n", "# End condition is the top beam finished and we can return", "\n", "# n_best hypotheses.", "\n", "", "if", "self", ".", "top_beam_finished", "[", "i", "]", "and", "len", "(", "\n", "self", ".", "hypotheses", "[", "b", "]", ")", ">=", "self", ".", "n_best", ":", "\n", "                ", "best_hyp", "=", "sorted", "(", "\n", "self", ".", "hypotheses", "[", "b", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "for", "n", ",", "(", "score", ",", "pred", ",", "attn", ")", "in", "enumerate", "(", "best_hyp", ")", ":", "\n", "                    ", "if", "n", ">=", "self", ".", "n_best", ":", "\n", "                        ", "break", "\n", "", "self", ".", "scores", "[", "b", "]", ".", "append", "(", "score", ")", "\n", "self", ".", "predictions", "[", "b", "]", ".", "append", "(", "pred", ")", "\n", "self", ".", "attention", "[", "b", "]", ".", "append", "(", "\n", "attn", "if", "attn", "is", "not", "None", "else", "[", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "non_finished_batch", ".", "append", "(", "i", ")", "\n", "", "", "non_finished", "=", "torch", ".", "tensor", "(", "non_finished_batch", ")", "\n", "# If all sentences are translated, no need to go further.", "\n", "if", "len", "(", "non_finished", ")", "==", "0", ":", "\n", "            ", "self", ".", "done", "=", "True", "\n", "return", "\n", "", "if", "not", "training", ":", "\n", "# Remove finished batches for the next step.", "\n", "            ", "_B_new", "=", "non_finished", ".", "shape", "[", "0", "]", "\n", "self", ".", "top_beam_finished", "=", "self", ".", "top_beam_finished", ".", "index_select", "(", "\n", "0", ",", "non_finished", ")", "\n", "self", ".", "_batch_offset", "=", "self", ".", "_batch_offset", ".", "index_select", "(", "0", ",", "non_finished", ")", "\n", "non_finished", "=", "non_finished", ".", "to", "(", "self", ".", "topk_ids", ".", "device", ")", "\n", "self", ".", "topk_log_probs", "=", "self", ".", "topk_log_probs", ".", "index_select", "(", "0", ",", "\n", "non_finished", ")", "\n", "self", ".", "_batch_index", "=", "self", ".", "_batch_index", ".", "index_select", "(", "0", ",", "non_finished", ")", "\n", "self", ".", "select_indices", "=", "self", ".", "_batch_index", ".", "view", "(", "_B_new", "*", "self", ".", "beam_size", ")", "\n", "self", ".", "alive_seq", "=", "predictions", ".", "index_select", "(", "0", ",", "non_finished", ")", ".", "view", "(", "-", "1", ",", "self", ".", "alive_seq", ".", "size", "(", "-", "1", ")", ")", "\n", "self", ".", "topk_scores", "=", "self", ".", "topk_scores", ".", "index_select", "(", "0", ",", "non_finished", ")", "\n", "self", ".", "topk_ids", "=", "self", ".", "topk_ids", ".", "index_select", "(", "0", ",", "non_finished", ")", "\n", "if", "self", ".", "alive_attn", "is", "not", "None", ":", "\n", "                ", "inp_seq_len", "=", "self", ".", "alive_attn", ".", "size", "(", "-", "1", ")", "\n", "self", ".", "alive_attn", "=", "attention", ".", "index_select", "(", "1", ",", "non_finished", ")", ".", "view", "(", "step", "-", "1", ",", "_B_new", "*", "self", ".", "beam_size", ",", "inp_seq_len", ")", "\n", "if", "self", ".", "_cov_pen", ":", "\n", "                    ", "self", ".", "_coverage", "=", "self", ".", "_coverage", ".", "view", "(", "1", ",", "_B_old", ",", "self", ".", "beam_size", ",", "inp_seq_len", ")", ".", "index_select", "(", "1", ",", "non_finished", ")", ".", "view", "(", "1", ",", "_B_new", "*", "self", ".", "beam_size", ",", "inp_seq_len", ")", "\n", "if", "self", ".", "_stepwise_cov_pen", ":", "\n", "                        ", "self", ".", "_prev_penalty", "=", "self", ".", "_prev_penalty", ".", "index_select", "(", "\n", "0", ",", "non_finished", ")", "\n", "", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.TranslationBuilder.__init__": [[24, 33], ["isinstance", "dict"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ",", "fields", ",", "n_best", "=", "1", ",", "replace_unk", "=", "False", ",", "\n", "has_tgt", "=", "False", ")", ":", "\n", "        ", "self", ".", "data", "=", "data", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "_has_text_src", "=", "isinstance", "(", "\n", "dict", "(", "self", ".", "fields", ")", "[", "\"src\"", "]", ",", "TextMultiField", ")", "\n", "self", ".", "n_best", "=", "n_best", "\n", "self", ".", "replace_unk", "=", "replace_unk", "\n", "self", ".", "has_tgt", "=", "has_tgt", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.TranslationBuilder._build_target_tokens": [[34, 52], ["range", "dict", "len", "tokens.append", "tokens.append", "len", "attn[].max", "max_index.item", "len"], "methods", ["None"], ["", "def", "_build_target_tokens", "(", "self", ",", "src", ",", "src_vocab", ",", "src_raw", ",", "pred", ",", "attn", ")", ":", "\n", "        ", "tgt_field", "=", "dict", "(", "self", ".", "fields", ")", "[", "\"tgt\"", "]", ".", "base_field", "\n", "vocab", "=", "tgt_field", ".", "vocab", "\n", "tokens", "=", "[", "]", "\n", "for", "tok", "in", "pred", ":", "\n", "            ", "if", "tok", "<", "len", "(", "vocab", ")", ":", "\n", "                ", "tokens", ".", "append", "(", "vocab", ".", "itos", "[", "tok", "]", ")", "\n", "", "else", ":", "\n", "                ", "tokens", ".", "append", "(", "src_vocab", ".", "itos", "[", "tok", "-", "len", "(", "vocab", ")", "]", ")", "\n", "", "if", "tokens", "[", "-", "1", "]", "==", "tgt_field", ".", "eos_token", ":", "\n", "                ", "tokens", "=", "tokens", "[", ":", "-", "1", "]", "\n", "break", "\n", "", "", "if", "self", ".", "replace_unk", "and", "attn", "is", "not", "None", "and", "src", "is", "not", "None", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "tokens", ")", ")", ":", "\n", "                ", "if", "tokens", "[", "i", "]", "==", "tgt_field", ".", "unk_token", ":", "\n", "                    ", "_", ",", "max_index", "=", "attn", "[", "i", "]", ".", "max", "(", "0", ")", "\n", "tokens", "[", "i", "]", "=", "src_raw", "[", "max_index", ".", "item", "(", ")", "]", "\n", "", "", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.TranslationBuilder.from_batch": [[53, 105], ["list", "torch.sort", "range", "len", "len", "zip", "[].index_select", "batch.tgt[].index_select", "Translation.Translation", "translations.append", "Translation.TranslationBuilder._build_target_tokens", "Translation.TranslationBuilder._build_target_tokens", "sorted", "range", "zip"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._build_target_tokens", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._build_target_tokens"], ["", "def", "from_batch", "(", "self", ",", "translation_batch", ")", ":", "\n", "        ", "batch", "=", "translation_batch", "[", "\"batch\"", "]", "\n", "assert", "(", "len", "(", "translation_batch", "[", "\"gold_score\"", "]", ")", "==", "\n", "len", "(", "translation_batch", "[", "\"predictions\"", "]", ")", ")", "\n", "batch_size", "=", "batch", ".", "batch_size", "\n", "\n", "preds", ",", "pred_score", ",", "attn", ",", "gold_score", ",", "indices", "=", "list", "(", "zip", "(", "\n", "*", "sorted", "(", "zip", "(", "translation_batch", "[", "\"predictions\"", "]", ",", "\n", "translation_batch", "[", "\"scores\"", "]", ",", "\n", "translation_batch", "[", "\"attention\"", "]", ",", "\n", "translation_batch", "[", "\"gold_score\"", "]", ",", "\n", "batch", ".", "indices", ".", "data", ")", ",", "\n", "key", "=", "lambda", "x", ":", "x", "[", "-", "1", "]", ")", ")", ")", "\n", "\n", "# Sorting", "\n", "inds", ",", "perm", "=", "torch", ".", "sort", "(", "batch", ".", "indices", ")", "\n", "if", "self", ".", "_has_text_src", ":", "\n", "            ", "src", "=", "batch", ".", "src", "[", "0", "]", "[", ":", ",", ":", ",", "0", "]", ".", "index_select", "(", "1", ",", "perm", ")", "\n", "", "else", ":", "\n", "            ", "src", "=", "None", "\n", "", "tgt", "=", "batch", ".", "tgt", "[", ":", ",", ":", ",", "0", "]", ".", "index_select", "(", "1", ",", "perm", ")", "if", "self", ".", "has_tgt", "else", "None", "\n", "\n", "translations", "=", "[", "]", "\n", "for", "b", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "if", "self", ".", "_has_text_src", ":", "\n", "                ", "src_vocab", "=", "self", ".", "data", ".", "src_vocabs", "[", "inds", "[", "b", "]", "]", "if", "self", ".", "data", ".", "src_vocabs", "else", "None", "\n", "src_raw", "=", "self", ".", "data", ".", "examples", "[", "inds", "[", "b", "]", "]", ".", "src", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "src_vocab", "=", "None", "\n", "src_raw", "=", "None", "\n", "", "pred_sents", "=", "[", "self", ".", "_build_target_tokens", "(", "\n", "src", "[", ":", ",", "b", "]", "if", "src", "is", "not", "None", "else", "None", ",", "\n", "src_vocab", ",", "src_raw", ",", "\n", "preds", "[", "b", "]", "[", "n", "]", ",", "attn", "[", "b", "]", "[", "n", "]", ")", "\n", "for", "n", "in", "range", "(", "self", ".", "n_best", ")", "]", "\n", "gold_sent", "=", "None", "\n", "if", "tgt", "is", "not", "None", ":", "\n", "                ", "gold_sent", "=", "self", ".", "_build_target_tokens", "(", "\n", "src", "[", ":", ",", "b", "]", "if", "src", "is", "not", "None", "else", "None", ",", "\n", "src_vocab", ",", "src_raw", ",", "\n", "tgt", "[", "1", ":", ",", "b", "]", "if", "tgt", "is", "not", "None", "else", "None", ",", "None", ")", "\n", "\n", "", "translation", "=", "Translation", "(", "\n", "src", "[", ":", ",", "b", "]", "if", "src", "is", "not", "None", "else", "None", ",", "\n", "src_raw", ",", "pred_sents", ",", "attn", "[", "b", "]", ",", "pred_score", "[", "b", "]", ",", "\n", "gold_sent", ",", "gold_score", "[", "b", "]", "\n", ")", "\n", "translations", ".", "append", "(", "translation", ")", "\n", "\n", "", "return", "translations", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.__init__": [[124, 133], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "src", ",", "src_raw", ",", "pred_sents", ",", "\n", "attn", ",", "pred_scores", ",", "tgt_sent", ",", "gold_score", ")", ":", "\n", "        ", "self", ".", "src", "=", "src", "\n", "self", ".", "src_raw", "=", "src_raw", "\n", "self", ".", "pred_sents", "=", "pred_sents", "\n", "self", ".", "attns", "=", "attn", "\n", "self", ".", "pred_scores", "=", "pred_scores", "\n", "self", ".", "gold_sent", "=", "tgt_sent", "\n", "self", ".", "gold_score", "=", "gold_score", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log": [[134, 157], ["msg.append", "msg.append", "msg.append", "msg.append", "len", "msg.append", "zip", "msg.append"], "methods", ["None"], ["", "def", "log", "(", "self", ",", "sent_number", ")", ":", "\n", "        ", "\"\"\"\n        Log translation.\n        \"\"\"", "\n", "\n", "msg", "=", "[", "'\\nSENT {}: {}\\n'", ".", "format", "(", "sent_number", ",", "self", ".", "src_raw", ")", "]", "\n", "\n", "best_pred", "=", "self", ".", "pred_sents", "[", "0", "]", "\n", "best_score", "=", "self", ".", "pred_scores", "[", "0", "]", "\n", "pred_sent", "=", "' '", ".", "join", "(", "best_pred", ")", "\n", "msg", ".", "append", "(", "'PRED {}: {}\\n'", ".", "format", "(", "sent_number", ",", "pred_sent", ")", ")", "\n", "msg", ".", "append", "(", "\"PRED SCORE: {:.4f}\\n\"", ".", "format", "(", "best_score", ")", ")", "\n", "\n", "if", "self", ".", "gold_sent", "is", "not", "None", ":", "\n", "            ", "tgt_sent", "=", "' '", ".", "join", "(", "self", ".", "gold_sent", ")", "\n", "msg", ".", "append", "(", "'GOLD {}: {}\\n'", ".", "format", "(", "sent_number", ",", "tgt_sent", ")", ")", "\n", "msg", ".", "append", "(", "(", "\"GOLD SCORE: {:.4f}\\n\"", ".", "format", "(", "self", ".", "gold_score", ")", ")", ")", "\n", "", "if", "len", "(", "self", ".", "pred_sents", ")", ">", "1", ":", "\n", "            ", "msg", ".", "append", "(", "'\\nBEST HYP:\\n'", ")", "\n", "for", "score", ",", "sent", "in", "zip", "(", "self", ".", "pred_scores", ",", "self", ".", "pred_sents", ")", ":", "\n", "                ", "msg", ".", "append", "(", "\"[{:.4f}] {}\\n\"", ".", "format", "(", "score", ",", "sent", ")", ")", "\n", "\n", "", "", "return", "\"\"", ".", "join", "(", "msg", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator.__init__": [[100, 197], ["frozenset", "len", "onmt.utils.misc.set_random_seed", "onmt.utils.misc.set_random_seed", "onmt.utils.misc.set_random_seed", "torch.device", "torch.device", "ValueError", "ValueError", "dict"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.set_random_seed", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.set_random_seed", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.set_random_seed"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "fields", ",", "\n", "src_reader", ",", "\n", "history_reader", ",", "\n", "tgt_reader", ",", "\n", "gpu", "=", "-", "1", ",", "\n", "n_best", "=", "1", ",", "\n", "min_length", "=", "0", ",", "\n", "max_length", "=", "100", ",", "\n", "beam_size", "=", "30", ",", "\n", "random_sampling_topk", "=", "1", ",", "\n", "random_sampling_temp", "=", "1", ",", "\n", "stepwise_penalty", "=", "None", ",", "\n", "dump_beam", "=", "False", ",", "\n", "block_ngram_repeat", "=", "0", ",", "\n", "ignore_when_blocking", "=", "frozenset", "(", ")", ",", "\n", "replace_unk", "=", "False", ",", "\n", "data_type", "=", "\"text\"", ",", "\n", "verbose", "=", "False", ",", "\n", "report_bleu", "=", "False", ",", "\n", "report_rouge", "=", "False", ",", "\n", "report_time", "=", "False", ",", "\n", "copy_attn", "=", "False", ",", "\n", "global_scorer", "=", "None", ",", "\n", "out_file", "=", "None", ",", "\n", "report_score", "=", "True", ",", "\n", "logger", "=", "None", ",", "\n", "seed", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "fields", "=", "fields", "\n", "tgt_field", "=", "dict", "(", "self", ".", "fields", ")", "[", "\"tgt\"", "]", ".", "base_field", "\n", "self", ".", "_tgt_vocab", "=", "tgt_field", ".", "vocab", "\n", "self", ".", "_tgt_eos_idx", "=", "self", ".", "_tgt_vocab", ".", "stoi", "[", "tgt_field", ".", "eos_token", "]", "\n", "self", ".", "_tgt_pad_idx", "=", "self", ".", "_tgt_vocab", ".", "stoi", "[", "tgt_field", ".", "pad_token", "]", "\n", "self", ".", "_tgt_bos_idx", "=", "self", ".", "_tgt_vocab", ".", "stoi", "[", "tgt_field", ".", "init_token", "]", "\n", "self", ".", "_tgt_unk_idx", "=", "self", ".", "_tgt_vocab", ".", "stoi", "[", "tgt_field", ".", "unk_token", "]", "\n", "self", ".", "_tgt_vocab_len", "=", "len", "(", "self", ".", "_tgt_vocab", ")", "\n", "\n", "self", ".", "_gpu", "=", "gpu", "\n", "self", ".", "_use_cuda", "=", "gpu", ">", "-", "1", "\n", "self", ".", "_dev", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "self", ".", "_gpu", ")", "if", "self", ".", "_use_cuda", "else", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "self", ".", "n_best", "=", "n_best", "\n", "self", ".", "max_length", "=", "max_length", "\n", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "self", ".", "random_sampling_temp", "=", "random_sampling_temp", "\n", "self", ".", "sample_from_topk", "=", "random_sampling_topk", "\n", "\n", "self", ".", "min_length", "=", "min_length", "\n", "self", ".", "stepwise_penalty", "=", "stepwise_penalty", "\n", "self", ".", "dump_beam", "=", "dump_beam", "\n", "self", ".", "block_ngram_repeat", "=", "block_ngram_repeat", "\n", "self", ".", "ignore_when_blocking", "=", "ignore_when_blocking", "\n", "self", ".", "_exclusion_idxs", "=", "{", "\n", "self", ".", "_tgt_vocab", ".", "stoi", "[", "t", "]", "for", "t", "in", "self", ".", "ignore_when_blocking", "}", "\n", "self", ".", "src_reader", "=", "src_reader", "\n", "self", ".", "history_reader", "=", "history_reader", "\n", "self", ".", "tgt_reader", "=", "tgt_reader", "\n", "self", ".", "replace_unk", "=", "replace_unk", "\n", "if", "self", ".", "replace_unk", "and", "not", "self", ".", "model", ".", "decoder", ".", "attentional", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"replace_unk requires an attentional decoder.\"", ")", "\n", "", "self", ".", "data_type", "=", "data_type", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "report_bleu", "=", "report_bleu", "\n", "self", ".", "report_rouge", "=", "report_rouge", "\n", "self", ".", "report_time", "=", "report_time", "\n", "\n", "self", ".", "copy_attn", "=", "copy_attn", "\n", "\n", "self", ".", "global_scorer", "=", "global_scorer", "\n", "if", "self", ".", "global_scorer", ".", "has_cov_pen", "and", "not", "self", ".", "model", ".", "decoder", ".", "attentional", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Coverage penalty requires an attentional decoder.\"", ")", "\n", "", "self", ".", "out_file", "=", "out_file", "\n", "self", ".", "report_score", "=", "report_score", "\n", "self", ".", "logger", "=", "logger", "\n", "\n", "self", ".", "use_filter_pred", "=", "False", "\n", "self", ".", "_filter_pred", "=", "None", "\n", "\n", "# for debugging", "\n", "self", ".", "beam_trace", "=", "self", ".", "dump_beam", "!=", "\"\"", "\n", "self", ".", "beam_accum", "=", "None", "\n", "if", "self", ".", "beam_trace", ":", "\n", "            ", "self", ".", "beam_accum", "=", "{", "\n", "\"predicted_ids\"", ":", "[", "]", ",", "\n", "\"beam_parent_ids\"", ":", "[", "]", ",", "\n", "\"scores\"", ":", "[", "]", ",", "\n", "\"log_probs\"", ":", "[", "]", "}", "\n", "\n", "", "set_random_seed", "(", "seed", ",", "self", ".", "_use_cuda", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator.from_opt": [[198, 257], ["onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "onmt.str2reader[].from_opt", "cls", "set"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt"], ["", "@", "classmethod", "\n", "def", "from_opt", "(", "\n", "cls", ",", "\n", "model", ",", "\n", "fields", ",", "\n", "opt", ",", "\n", "model_opt", ",", "\n", "global_scorer", "=", "None", ",", "\n", "out_file", "=", "None", ",", "\n", "report_score", "=", "True", ",", "\n", "logger", "=", "None", ")", ":", "\n", "        ", "\"\"\"Alternate constructor.\n\n        Args:\n            model (onmt.modules.NMTModel): See :func:`__init__()`.\n            fields (dict[str, torchtext.data.Field]): See\n                :func:`__init__()`.\n            opt (argparse.Namespace): Command line options\n            model_opt (argparse.Namespace): Command line options saved with\n                the model checkpoint.\n            global_scorer (onmt.translate.GNMTGlobalScorer): See\n                :func:`__init__()`..\n            out_file (TextIO or codecs.StreamReaderWriter): See\n                :func:`__init__()`.\n            report_score (bool) : See :func:`__init__()`.\n            logger (logging.Logger or NoneType): See :func:`__init__()`.\n        \"\"\"", "\n", "src_reader", "=", "inputters", ".", "str2reader", "[", "opt", ".", "data_type", "]", ".", "from_opt", "(", "opt", ")", "\n", "history_reader", "=", "inputters", ".", "str2reader", "[", "opt", ".", "data_type", "]", ".", "from_opt", "(", "opt", ")", "\n", "tgt_reader", "=", "inputters", ".", "str2reader", "[", "\"text\"", "]", ".", "from_opt", "(", "opt", ")", "\n", "return", "cls", "(", "\n", "model", ",", "\n", "fields", ",", "\n", "src_reader", ",", "\n", "history_reader", ",", "\n", "tgt_reader", ",", "\n", "gpu", "=", "opt", ".", "gpu", ",", "\n", "n_best", "=", "opt", ".", "n_best", ",", "\n", "min_length", "=", "opt", ".", "min_length", ",", "\n", "max_length", "=", "opt", ".", "max_length", ",", "\n", "beam_size", "=", "opt", ".", "beam_size", ",", "\n", "random_sampling_topk", "=", "opt", ".", "random_sampling_topk", ",", "\n", "random_sampling_temp", "=", "opt", ".", "random_sampling_temp", ",", "\n", "stepwise_penalty", "=", "opt", ".", "stepwise_penalty", ",", "\n", "dump_beam", "=", "opt", ".", "dump_beam", ",", "\n", "block_ngram_repeat", "=", "opt", ".", "block_ngram_repeat", ",", "\n", "ignore_when_blocking", "=", "set", "(", "opt", ".", "ignore_when_blocking", ")", ",", "\n", "replace_unk", "=", "opt", ".", "replace_unk", ",", "\n", "data_type", "=", "opt", ".", "data_type", ",", "\n", "verbose", "=", "opt", ".", "verbose", ",", "\n", "report_bleu", "=", "opt", ".", "report_bleu", ",", "\n", "report_rouge", "=", "opt", ".", "report_rouge", ",", "\n", "report_time", "=", "opt", ".", "report_time", ",", "\n", "copy_attn", "=", "model_opt", ".", "copy_attn", ",", "\n", "global_scorer", "=", "global_scorer", ",", "\n", "out_file", "=", "out_file", ",", "\n", "report_score", "=", "report_score", ",", "\n", "logger", "=", "logger", ",", "\n", "seed", "=", "opt", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._build_target_tokens": [[258, 276], ["range", "dict", "len", "tokens.append", "tokens.append", "len", "attn[].max", "max_index.item", "len"], "methods", ["None"], ["", "def", "_build_target_tokens", "(", "self", ",", "src", ",", "src_vocab", ",", "src_raw", ",", "pred", ",", "attn", ")", ":", "\n", "        ", "tgt_field", "=", "dict", "(", "self", ".", "fields", ")", "[", "\"tgt\"", "]", ".", "base_field", "\n", "vocab", "=", "tgt_field", ".", "vocab", "\n", "tokens", "=", "[", "]", "\n", "for", "tok", "in", "pred", ":", "\n", "            ", "if", "tok", "<", "len", "(", "vocab", ")", ":", "\n", "                ", "tokens", ".", "append", "(", "vocab", ".", "itos", "[", "tok", "]", ")", "\n", "", "else", ":", "\n", "                ", "tokens", ".", "append", "(", "src_vocab", ".", "itos", "[", "tok", "-", "len", "(", "vocab", ")", "]", ")", "\n", "", "if", "tokens", "[", "-", "1", "]", "==", "tgt_field", ".", "eos_token", ":", "\n", "                ", "tokens", "=", "tokens", "[", ":", "-", "1", "]", "\n", "break", "\n", "", "", "if", "self", ".", "replace_unk", "and", "attn", "is", "not", "None", "and", "src", "is", "not", "None", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "tokens", ")", ")", ":", "\n", "                ", "if", "tokens", "[", "i", "]", "==", "tgt_field", ".", "unk_token", ":", "\n", "                    ", "_", ",", "max_index", "=", "attn", "[", "i", "]", ".", "max", "(", "0", ")", "\n", "tokens", "[", "i", "]", "=", "src_raw", "[", "max_index", ".", "item", "(", ")", "]", "\n", "", "", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._log": [[277, 282], ["translator.Translator.logger.info", "print"], "methods", ["None"], ["", "def", "_log", "(", "self", ",", "msg", ")", ":", "\n", "        ", "if", "self", ".", "logger", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "msg", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._gold_score": [[283, 293], ["translator.Translator._score_target", "translator.Translator.model.decoder.init_state"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._score_target", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoder.init_state"], ["", "", "def", "_gold_score", "(", "self", ",", "batch", ",", "memory_bank", ",", "src_lengths", ",", "src_vocabs", ",", "\n", "use_src_map", ",", "enc_states", ",", "batch_size", ",", "src", ")", ":", "\n", "        ", "if", "\"tgt\"", "in", "batch", ".", "__dict__", ":", "\n", "            ", "gs", "=", "self", ".", "_score_target", "(", "\n", "batch", ",", "memory_bank", ",", "src_lengths", ",", "src_vocabs", ",", "\n", "batch", ".", "src_map", "if", "use_src_map", "else", "None", ")", "\n", "self", ".", "model", ".", "decoder", ".", "init_state", "(", "src", ",", "memory_bank", ",", "enc_states", ")", "\n", "", "else", ":", "\n", "            ", "gs", "=", "[", "0", "]", "*", "batch_size", "\n", "", "return", "gs", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator.translate": [[294, 377], ["onmt.Dataset", "onmt.Dataset", "onmt.Dataset", "onmt.OrderedIterator", "onmt.OrderedIterator", "onmt.OrderedIterator", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "tqdm.tqdm.tqdm", "ValueError", "translator.Translator.translate_batch", "onmt.translate.TranslationBuilder.from_batch", "onmt.translate.TranslationBuilder.from_batch", "onmt.translate.TranslationBuilder.from_batch", "len", "len", "translator.Translator.out_file.write", "translator.Translator.out_file.flush", "len"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator.translate_batch", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.TranslationBuilder.from_batch", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.TranslationBuilder.from_batch", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.TranslationBuilder.from_batch"], ["", "def", "translate", "(", "\n", "self", ",", "\n", "src", ",", "\n", "history", ",", "\n", "tgt", "=", "None", ",", "\n", "src_dir", "=", "None", ",", "\n", "batch_size", "=", "None", ",", "\n", "attn_debug", "=", "False", ")", ":", "\n", "        ", "\"\"\"Translate content of ``src`` and get gold scores from ``tgt``.\n\n        Args:\n            src: See :func:`self.src_reader.read()`.\n            tgt: See :func:`self.tgt_reader.read()`.\n            src_dir: See :func:`self.src_reader.read()` (only relevant\n                for certain types of data).\n            batch_size (int): size of examples per mini-batch\n            attn_debug (bool): enables the attention logging\n\n        Returns:\n            (`list`, `list`)\n\n            * all_scores is a list of `batch_size` lists of `n_best` scores\n            * all_predictions is a list of `batch_size` lists\n                of `n_best` predictions\n        \"\"\"", "\n", "self", ".", "tgt", "=", "tgt", "\n", "\n", "if", "batch_size", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"batch_size must be set\"", ")", "\n", "\n", "", "data", "=", "inputters", ".", "Dataset", "(", "\n", "self", ".", "fields", ",", "\n", "readers", "=", "(", "[", "self", ".", "src_reader", ",", "self", ".", "history_reader", ",", "self", ".", "tgt_reader", "]", "\n", "if", "tgt", "else", "[", "self", ".", "src_reader", ",", "self", ".", "history_reader", "]", ")", ",", "\n", "data", "=", "[", "(", "\"src\"", ",", "src", ")", ",", "(", "\"history\"", ",", "history", ")", ",", "(", "\"tgt\"", ",", "tgt", ")", "]", "if", "tgt", "else", "[", "(", "\"src\"", ",", "src", ")", ",", "(", "\"history\"", ",", "history", ")", "]", ",", "\n", "dirs", "=", "[", "src_dir", ",", "src_dir", ",", "None", "]", "if", "tgt", "else", "[", "src_dir", ",", "src_dir", "]", ",", "\n", "sort_key", "=", "inputters", ".", "str2sortkey", "[", "self", ".", "data_type", "]", ",", "\n", "filter_pred", "=", "self", ".", "_filter_pred", "\n", ")", "\n", "\n", "data_iter", "=", "inputters", ".", "OrderedIterator", "(", "\n", "dataset", "=", "data", ",", "\n", "device", "=", "self", ".", "_dev", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "train", "=", "False", ",", "\n", "sort", "=", "False", ",", "\n", "sort_within_batch", "=", "True", ",", "\n", "shuffle", "=", "False", "\n", ")", "\n", "\n", "xlation_builder", "=", "onmt", ".", "translate", ".", "TranslationBuilder", "(", "\n", "data", ",", "self", ".", "fields", ",", "self", ".", "n_best", ",", "self", ".", "replace_unk", ",", "tgt", "\n", ")", "\n", "\n", "# Statistics", "\n", "pred_score_total", ",", "pred_words_total", "=", "0", ",", "0", "\n", "gold_score_total", ",", "gold_words_total", "=", "0", ",", "0", "\n", "\n", "all_scores", "=", "[", "]", "\n", "all_predictions", "=", "[", "]", "\n", "\n", "for", "batch", "in", "tqdm", "(", "data_iter", ",", "total", "=", "len", "(", "data_iter", ")", ")", ":", "\n", "            ", "batch_data", "=", "self", ".", "translate_batch", "(", "\n", "batch", ",", "data", ".", "src_vocabs", ",", "attn_debug", "\n", ")", "\n", "translations", "=", "xlation_builder", ".", "from_batch", "(", "batch_data", ")", "\n", "\n", "for", "trans", "in", "translations", ":", "\n", "                ", "all_scores", "+=", "[", "trans", ".", "pred_scores", "[", ":", "self", ".", "n_best", "]", "]", "\n", "pred_score_total", "+=", "trans", ".", "pred_scores", "[", "0", "]", "\n", "pred_words_total", "+=", "len", "(", "trans", ".", "pred_sents", "[", "0", "]", ")", "\n", "if", "tgt", "is", "not", "None", ":", "\n", "                    ", "gold_score_total", "+=", "trans", ".", "gold_score", "\n", "gold_words_total", "+=", "len", "(", "trans", ".", "gold_sent", ")", "+", "1", "\n", "\n", "", "n_best_preds", "=", "[", "\" \"", ".", "join", "(", "pred", ")", "\n", "for", "pred", "in", "trans", ".", "pred_sents", "[", ":", "self", ".", "n_best", "]", "]", "\n", "all_predictions", "+=", "[", "n_best_preds", "]", "\n", "if", "self", ".", "out_file", "is", "not", "None", ":", "\n", "                    ", "self", ".", "out_file", ".", "write", "(", "'\\n'", ".", "join", "(", "n_best_preds", ")", "+", "'\\n'", ")", "\n", "self", ".", "out_file", ".", "flush", "(", ")", "\n", "\n", "", "", "", "return", "all_scores", ",", "all_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator.reverse": [[378, 407], ["list", "torch.sort", "[].index_select", "range", "zip", "target_ans.append", "src_raws.append", "total_pred.append", "translator.Translator._build_target_tokens", "sorted", "range", "zip", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._build_target_tokens"], ["", "def", "reverse", "(", "self", ",", "src_vocabs", ",", "examples", ",", "translation_batch", ")", ":", "\n", "        ", "batch", "=", "translation_batch", "[", "\"batch\"", "]", "\n", "batch_size", "=", "batch", ".", "batch_size", "\n", "preds", ",", "pred_score", ",", "attn", ",", "gold_score", ",", "indices", "=", "list", "(", "zip", "(", "\n", "*", "sorted", "(", "zip", "(", "translation_batch", "[", "\"predictions\"", "]", ",", "\n", "translation_batch", "[", "\"scores\"", "]", ",", "\n", "translation_batch", "[", "\"attention\"", "]", ",", "\n", "translation_batch", "[", "\"gold_score\"", "]", ",", "\n", "batch", ".", "indices", ".", "data", ")", ",", "\n", "key", "=", "lambda", "x", ":", "x", "[", "-", "1", "]", ")", ")", ")", "\n", "inds", ",", "perm", "=", "torch", ".", "sort", "(", "batch", ".", "indices", ")", "\n", "src", "=", "batch", ".", "src", "[", "0", "]", "[", ":", ",", ":", ",", "0", "]", ".", "index_select", "(", "1", ",", "perm", ")", "\n", "total_pred", "=", "[", "]", "\n", "src_raws", "=", "[", "]", "\n", "target_ans", "=", "[", "]", "\n", "for", "b", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "src_vocab", "=", "src_vocabs", "[", "inds", "[", "b", "]", "]", "if", "src_vocabs", "else", "None", "\n", "src_raw", "=", "examples", "[", "inds", "[", "b", "]", "]", ".", "src", "[", "0", "]", "\n", "ans", "=", "examples", "[", "inds", "[", "b", "]", "]", ".", "ans", "[", "0", "]", "\n", "target_ans", ".", "append", "(", "ans", ")", "\n", "src_raws", ".", "append", "(", "src_raw", ")", "\n", "pred_sents", "=", "[", "self", ".", "_build_target_tokens", "(", "\n", "src", "[", ":", ",", "b", "]", "if", "src", "is", "not", "None", "else", "None", ",", "\n", "src_vocab", ",", "src_raw", ",", "\n", "preds", "[", "b", "]", "[", "n", "]", "if", "len", "(", "preds", "[", "b", "]", ")", ">", "0", "else", "[", "]", ",", "attn", "[", "b", "]", "[", "n", "]", "if", "len", "(", "preds", "[", "b", "]", ")", ">", "0", "else", "[", "]", ")", "\n", "for", "n", "in", "range", "(", "self", ".", "n_best", ")", "]", "\n", "total_pred", ".", "append", "(", "pred_sents", ")", "\n", "", "return", "preds", ",", "total_pred", ",", "src_raws", ",", "target_ans", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._translate_random_sampling": [[408, 516], ["translator.Translator._run_encoder", "translator.Translator.model.decoder.init_state", "isinstance", "onmt.translate.random_sampling.RandomSampling", "onmt.translate.random_sampling.RandomSampling", "onmt.translate.random_sampling.RandomSampling", "range", "batch.tgt.size", "translator.Translator._gold_score", "onmt.translate.random_sampling.RandomSampling.alive_seq[].view", "onmt.translate.random_sampling.RandomSampling.alive_seq[].view", "onmt.translate.random_sampling.RandomSampling.alive_seq[].view", "translator.Translator._decode_and_generate", "onmt.translate.random_sampling.RandomSampling.advance", "onmt.translate.random_sampling.RandomSampling.advance", "onmt.translate.random_sampling.RandomSampling.advance", "onmt.translate.random_sampling.RandomSampling.is_finished.any", "onmt.translate.random_sampling.RandomSampling.is_finished.any", "onmt.translate.random_sampling.RandomSampling.is_finished.any", "onmt.translate.random_sampling.RandomSampling.dec_outputs.view", "onmt.translate.random_sampling.RandomSampling.dec_outputs.view", "onmt.translate.random_sampling.RandomSampling.dec_outputs.view", "onmt.translate.random_sampling.RandomSampling.update_finished", "onmt.translate.random_sampling.RandomSampling.update_finished", "onmt.translate.random_sampling.RandomSampling.update_finished", "isinstance", "memory_lengths.index_select.index_select.index_select", "translator.Translator.model.decoder.map_state", "[].view", "batch.tgt.size", "tuple", "memory_bank.index_select.index_select.index_select", "src_map.index_select.index_select.index_select", "batch.tgt.size", "state.index_select", "x.index_select"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._run_encoder", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoder.init_state", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._gold_score", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._decode_and_generate", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoder.map_state"], ["", "def", "_translate_random_sampling", "(", "\n", "self", ",", "\n", "batch", ",", "\n", "src_vocabs", ",", "\n", "max_length", ",", "\n", "min_length", "=", "0", ",", "\n", "sampling_temp", "=", "1.0", ",", "\n", "keep_topk", "=", "-", "1", ",", "\n", "return_attention", "=", "False", ",", "\n", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"Alternative to beam search. Do random sampling at each step.\"\"\"", "\n", "\n", "assert", "self", ".", "beam_size", "==", "1", "\n", "\n", "# TODO: support these blacklisted features.", "\n", "assert", "self", ".", "block_ngram_repeat", "==", "0", "\n", "\n", "batch_size", "=", "batch", ".", "batch_size", "\n", "beam_size", "=", "self", ".", "beam_size", "\n", "\n", "if", "training", ":", "\n", "            ", "max_tgt_length", "=", "batch", ".", "tgt", ".", "size", "(", "0", ")", "\n", "max_length", "=", "max_tgt_length", "-", "1", "\n", "\n", "\n", "\n", "# Encoder forward.", "\n", "", "src", ",", "enc_states", ",", "memory_bank", ",", "src_lengths", "=", "self", ".", "_run_encoder", "(", "batch", ")", "\n", "self", ".", "model", ".", "decoder", ".", "init_state", "(", "src", ",", "memory_bank", ",", "enc_states", ")", "\n", "\n", "use_src_map", "=", "self", ".", "copy_attn", "\n", "\n", "results", "=", "{", "\n", "\"predictions\"", ":", "None", ",", "\n", "\"scores\"", ":", "None", ",", "\n", "\"attention\"", ":", "None", ",", "\n", "\"batch\"", ":", "batch", ",", "\n", "\"gold_score\"", ":", "self", ".", "_gold_score", "(", "\n", "batch", ",", "memory_bank", ",", "src_lengths", ",", "src_vocabs", ",", "use_src_map", ",", "\n", "enc_states", ",", "batch_size", ",", "src", ")", "}", "\n", "\n", "memory_lengths", "=", "src_lengths", "\n", "src_map", "=", "batch", ".", "src_map", "if", "use_src_map", "else", "None", "\n", "\n", "if", "isinstance", "(", "memory_bank", ",", "tuple", ")", ":", "\n", "            ", "mb_device", "=", "memory_bank", "[", "0", "]", ".", "device", "\n", "", "else", ":", "\n", "            ", "mb_device", "=", "memory_bank", ".", "device", "\n", "\n", "", "random_sampler", "=", "RandomSampling", "(", "\n", "self", ".", "_tgt_pad_idx", ",", "self", ".", "_tgt_bos_idx", ",", "self", ".", "_tgt_eos_idx", ",", "\n", "batch_size", ",", "mb_device", ",", "min_length", ",", "self", ".", "block_ngram_repeat", ",", "\n", "self", ".", "_exclusion_idxs", ",", "return_attention", ",", "self", ".", "max_length", ",", "\n", "sampling_temp", ",", "keep_topk", ",", "memory_lengths", ")", "\n", "\n", "for", "step", "in", "range", "(", "max_length", ")", ":", "\n", "# Shape: (1, B, 1)", "\n", "            ", "decoder_input", "=", "random_sampler", ".", "alive_seq", "[", ":", ",", "-", "1", "]", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", "\n", "\n", "log_probs", ",", "attn", ",", "dec_out_attn", "=", "self", ".", "_decode_and_generate", "(", "\n", "decoder_input", ",", "\n", "memory_bank", ",", "\n", "batch", ",", "\n", "src_vocabs", ",", "\n", "memory_lengths", "=", "memory_lengths", ",", "\n", "src_map", "=", "src_map", ",", "\n", "step", "=", "step", ",", "\n", "batch_offset", "=", "random_sampler", ".", "select_indices", "\n", ")", "\n", "\n", "random_sampler", ".", "advance", "(", "log_probs", ",", "attn", ",", "dec_out_attn", ")", "\n", "any_batch_is_finished", "=", "random_sampler", ".", "is_finished", ".", "any", "(", ")", "\n", "if", "any_batch_is_finished", ":", "\n", "                ", "random_sampler", ".", "update_finished", "(", "training", ")", "\n", "if", "random_sampler", ".", "done", "and", "not", "training", ":", "\n", "                    ", "max_length", "=", "step", "\n", "break", "\n", "\n", "", "", "if", "any_batch_is_finished", ":", "\n", "                ", "select_indices", "=", "random_sampler", ".", "select_indices", "\n", "\n", "# Reorder states.", "\n", "if", "isinstance", "(", "memory_bank", ",", "tuple", ")", ":", "\n", "                    ", "memory_bank", "=", "tuple", "(", "x", ".", "index_select", "(", "1", ",", "select_indices", ")", "\n", "for", "x", "in", "memory_bank", ")", "\n", "", "else", ":", "\n", "                    ", "memory_bank", "=", "memory_bank", ".", "index_select", "(", "1", ",", "select_indices", ")", "\n", "\n", "", "memory_lengths", "=", "memory_lengths", ".", "index_select", "(", "0", ",", "select_indices", ")", "\n", "\n", "if", "src_map", "is", "not", "None", ":", "\n", "                    ", "src_map", "=", "src_map", ".", "index_select", "(", "1", ",", "select_indices", ")", "\n", "\n", "", "self", ".", "model", ".", "decoder", ".", "map_state", "(", "\n", "lambda", "state", ",", "dim", ":", "state", ".", "index_select", "(", "dim", ",", "select_indices", ")", ")", "\n", "\n", "", "", "results", "[", "\"scores\"", "]", "=", "random_sampler", ".", "scores", "\n", "results", "[", "\"predictions\"", "]", "=", "random_sampler", ".", "predictions", "\n", "results", "[", "\"attention\"", "]", "=", "random_sampler", ".", "attention", "\n", "\n", "# results[\"hypotheses\"] = random_sampler.hypotheses", "\n", "if", "training", ":", "\n", "            ", "results", "[", "\"dec_outputs\"", "]", "=", "random_sampler", ".", "dec_outputs", ".", "view", "(", "max_length", ",", "batch_size", ",", "beam_size", ",", "-", "1", ")", "\n", "results", "[", "\"dec_attns\"", "]", "=", "random_sampler", ".", "dec_attns", "\n", "for", "key", "in", "results", "[", "\"dec_attns\"", "]", ":", "\n", "                ", "results", "[", "\"dec_attns\"", "]", "[", "key", "]", "=", "results", "[", "\"dec_attns\"", "]", "[", "key", "]", ".", "view", "(", "max_length", ",", "batch_size", ",", "beam_size", ",", "-", "1", ")", "\n", "", "assert", "max_length", "==", "batch", ".", "tgt", ".", "size", "(", "0", ")", "-", "1", ",", "\"max_length {}, tgt {}\"", ".", "format", "(", "max_length", ",", "batch", ".", "tgt", ".", "size", "(", ")", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator.translate_batch": [[517, 540], ["grad_control", "translator.Translator._translate_random_sampling", "translator.Translator._translate_batch"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._translate_random_sampling", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._translate_batch"], ["", "def", "translate_batch", "(", "self", ",", "batch", ",", "src_vocabs", ",", "attn_debug", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"Translate a batch of sentences.\"\"\"", "\n", "grad_control", "=", "torch", ".", "enable_grad", "if", "training", "else", "torch", ".", "no_grad", "\n", "with", "grad_control", "(", ")", ":", "\n", "            ", "if", "self", ".", "beam_size", "==", "1", ":", "\n", "                ", "return", "self", ".", "_translate_random_sampling", "(", "\n", "batch", ",", "\n", "src_vocabs", ",", "\n", "self", ".", "max_length", ",", "\n", "min_length", "=", "self", ".", "min_length", ",", "\n", "sampling_temp", "=", "self", ".", "random_sampling_temp", ",", "\n", "keep_topk", "=", "self", ".", "sample_from_topk", ",", "\n", "return_attention", "=", "attn_debug", "or", "self", ".", "replace_unk", ",", "\n", "training", "=", "training", ")", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "_translate_batch", "(", "\n", "batch", ",", "\n", "src_vocabs", ",", "\n", "self", ".", "max_length", ",", "\n", "min_length", "=", "self", ".", "min_length", ",", "\n", "n_best", "=", "self", ".", "n_best", ",", "\n", "return_attention", "=", "attn_debug", "or", "self", ".", "replace_unk", ",", "\n", "training", "=", "training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._run_encoder": [[541, 557], ["translator.Translator.model.encoder", "isinstance", "isinstance", "torch.Tensor().type_as().long().fill_", "isinstance", "memory_bank.size", "torch.Tensor().type_as().long", "torch.Tensor().type_as", "torch.Tensor"], "methods", ["None"], ["", "", "", "def", "_run_encoder", "(", "self", ",", "batch", ")", ":", "\n", "        ", "src", ",", "src_lengths", "=", "batch", ".", "src", "if", "isinstance", "(", "batch", ".", "src", ",", "tuple", ")", "else", "(", "batch", ".", "src", ",", "None", ")", "\n", "\n", "history", ",", "history_lengths", "=", "batch", ".", "history", "if", "isinstance", "(", "batch", ".", "history", ",", "tuple", ")", "else", "(", "batch", ".", "history", ",", "None", ")", "\n", "\n", "enc_states", ",", "memory_bank", ",", "src_lengths", "=", "self", ".", "model", ".", "encoder", "(", "\n", "src", ",", "history", ",", "src_lengths", ",", "history_lengths", ")", "\n", "if", "src_lengths", "is", "None", ":", "\n", "            ", "assert", "not", "isinstance", "(", "memory_bank", ",", "tuple", ")", ",", "'Ensemble decoding only supported for text data'", "\n", "src_lengths", "=", "torch", ".", "Tensor", "(", "batch", ".", "batch_size", ")", ".", "type_as", "(", "memory_bank", ")", ".", "long", "(", ")", ".", "fill_", "(", "memory_bank", ".", "size", "(", "0", ")", ")", "\n", "", "return", "src", ",", "enc_states", ",", "memory_bank", ",", "src_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._decode_and_generate": [[558, 614], ["translator.Translator.model.decoder", "decoder_in.masked_fill.masked_fill.masked_fill", "translator.Translator.model.generator", "translator.Translator.model.generator", "onmt.modules.copy_generator.collapse_copy_scores", "onmt.modules.copy_generator.collapse_copy_scores", "onmt.modules.copy_generator.collapse_copy_scores", "scores.view.view.view", "scores.view.view.squeeze().log", "decoder_in.masked_fill.masked_fill.gt", "dec_out.squeeze", "dec_out.view", "attn.view", "scores.view.view.view", "scores.view.view.view", "decoder_in.masked_fill.masked_fill.size", "scores.view.view.size", "dec_out.size", "attn.size", "scores.view.view.size", "scores.view.view.size", "scores.view.view.squeeze"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.copy_generator.collapse_copy_scores", "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.copy_generator.collapse_copy_scores", "home.repos.pwc.inspect_result.ZJULearning_ReDR.modules.copy_generator.collapse_copy_scores", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "_decode_and_generate", "(", "\n", "self", ",", "\n", "decoder_in", ",", "\n", "memory_bank", ",", "\n", "batch", ",", "\n", "src_vocabs", ",", "\n", "memory_lengths", ",", "\n", "src_map", "=", "None", ",", "\n", "step", "=", "None", ",", "\n", "batch_offset", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "copy_attn", ":", "\n", "# Turn any copied words into UNKs.", "\n", "            ", "decoder_in", "=", "decoder_in", ".", "masked_fill", "(", "\n", "decoder_in", ".", "gt", "(", "self", ".", "_tgt_vocab_len", "-", "1", ")", ",", "self", ".", "_tgt_unk_idx", "\n", ")", "\n", "\n", "# Decoder forward, takes [tgt_len, batch, nfeats] as input", "\n", "# and [src_len, batch, hidden] as memory_bank", "\n", "# in case of inference tgt_len = 1, batch = beam times batch_size", "\n", "# in case of Gold Scoring tgt_len = actual length, batch = 1 batch", "\n", "", "dec_out", ",", "dec_attn", "=", "self", ".", "model", ".", "decoder", "(", "\n", "decoder_in", ",", "memory_bank", ",", "memory_lengths", "=", "memory_lengths", ",", "step", "=", "step", "\n", ")", "\n", "\n", "# Generator forward.", "\n", "if", "not", "self", ".", "copy_attn", ":", "\n", "            ", "if", "\"std\"", "in", "dec_attn", ":", "\n", "                ", "attn", "=", "dec_attn", "[", "\"std\"", "]", "\n", "", "else", ":", "\n", "                ", "attn", "=", "None", "\n", "", "log_probs", "=", "self", ".", "model", ".", "generator", "(", "dec_out", ".", "squeeze", "(", "0", ")", ")", "\n", "# returns [(batch_size x beam_size) , vocab ] when 1 step", "\n", "# or [ tgt_len, batch_size, vocab ] when full sentence", "\n", "", "else", ":", "\n", "            ", "attn", "=", "dec_attn", "[", "\"copy\"", "]", "\n", "scores", "=", "self", ".", "model", ".", "generator", "(", "dec_out", ".", "view", "(", "-", "1", ",", "dec_out", ".", "size", "(", "2", ")", ")", ",", "\n", "attn", ".", "view", "(", "-", "1", ",", "attn", ".", "size", "(", "2", ")", ")", ",", "\n", "src_map", ")", "\n", "# here we have scores [tgt_lenxbatch, vocab] or [beamxbatch, vocab]", "\n", "if", "batch_offset", "is", "None", ":", "\n", "                ", "scores", "=", "scores", ".", "view", "(", "batch", ".", "batch_size", ",", "-", "1", ",", "scores", ".", "size", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "scores", "=", "scores", ".", "view", "(", "-", "1", ",", "self", ".", "beam_size", ",", "scores", ".", "size", "(", "-", "1", ")", ")", "\n", "", "scores", "=", "collapse_copy_scores", "(", "\n", "scores", ",", "\n", "batch", ",", "\n", "self", ".", "_tgt_vocab", ",", "\n", "src_vocabs", ",", "\n", "batch_dim", "=", "0", ",", "\n", "batch_offset", "=", "batch_offset", "\n", ")", "\n", "scores", "=", "scores", ".", "view", "(", "decoder_in", ".", "size", "(", "0", ")", ",", "-", "1", ",", "scores", ".", "size", "(", "-", "1", ")", ")", "\n", "log_probs", "=", "scores", ".", "squeeze", "(", "0", ")", ".", "log", "(", ")", "\n", "# returns [(batch_size x beam_size) , vocab ] when 1 step", "\n", "# or [ tgt_len, batch_size, vocab ] when full sentence", "\n", "", "return", "log_probs", ",", "attn", ",", "(", "dec_out", ",", "dec_attn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._translate_batch": [[615, 734], ["translator.Translator._run_encoder", "translator.Translator.model.decoder.init_state", "translator.Translator.model.decoder.map_state", "isinstance", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.translate.beam_search.BeamSearch", "onmt.translate.beam_search.BeamSearch", "onmt.translate.beam_search.BeamSearch", "range", "batch.tgt.size", "translator.Translator._gold_score", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "tuple", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.translate.beam_search.BeamSearch.current_predictions.view", "onmt.translate.beam_search.BeamSearch.current_predictions.view", "onmt.translate.beam_search.BeamSearch.current_predictions.view", "translator.Translator._decode_and_generate", "onmt.translate.beam_search.BeamSearch.advance", "onmt.translate.beam_search.BeamSearch.advance", "onmt.translate.beam_search.BeamSearch.advance", "onmt.translate.beam_search.BeamSearch.is_finished.any", "onmt.translate.beam_search.BeamSearch.is_finished.any", "onmt.translate.beam_search.BeamSearch.is_finished.any", "translator.Translator.model.decoder.map_state", "onmt.translate.beam_search.BeamSearch.dec_outputs.view", "onmt.translate.beam_search.BeamSearch.dec_outputs.view", "onmt.translate.beam_search.BeamSearch.dec_outputs.view", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.translate.beam_search.BeamSearch.update_finished", "onmt.translate.beam_search.BeamSearch.update_finished", "onmt.translate.beam_search.BeamSearch.update_finished", "isinstance", "memory_lengths.index_select.index_select.index_select", "[].view", "batch.tgt.size", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "tuple", "memory_bank.index_select.index_select.index_select", "src_map.index_select.index_select.index_select", "state.index_select", "batch.tgt.size", "x.index_select"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._run_encoder", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoder.init_state", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoder.map_state", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.tile", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.tile", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.tile", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._gold_score", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.tile", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.tile", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.tile", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.tile", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.tile", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.tile", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._decode_and_generate", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.advance", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoder.map_state", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.tile", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.tile", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.tile", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.update_finished", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.tile", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.tile", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.tile"], ["", "def", "_translate_batch", "(", "\n", "self", ",", "\n", "batch", ",", "\n", "src_vocabs", ",", "\n", "max_length", ",", "\n", "min_length", "=", "0", ",", "\n", "n_best", "=", "1", ",", "\n", "return_attention", "=", "False", ",", "\n", "training", "=", "False", ")", ":", "\n", "# TODO: support these blacklisted features.", "\n", "        ", "assert", "not", "self", ".", "dump_beam", "\n", "\n", "# (0) Prep the components of the search.", "\n", "use_src_map", "=", "self", ".", "copy_attn", "\n", "beam_size", "=", "self", ".", "beam_size", "\n", "batch_size", "=", "batch", ".", "batch_size", "\n", "if", "training", ":", "\n", "            ", "max_tgt_length", "=", "batch", ".", "tgt", ".", "size", "(", "0", ")", "\n", "max_length", "=", "max_tgt_length", "-", "1", "\n", "# (1) Run the encoder on the src.", "\n", "", "src", ",", "enc_states", ",", "memory_bank", ",", "src_lengths", "=", "self", ".", "_run_encoder", "(", "batch", ")", "\n", "self", ".", "model", ".", "decoder", ".", "init_state", "(", "src", ",", "memory_bank", ",", "enc_states", ")", "\n", "\n", "results", "=", "{", "\n", "\"predictions\"", ":", "None", ",", "\n", "\"scores\"", ":", "None", ",", "\n", "\"attention\"", ":", "None", ",", "\n", "\"batch\"", ":", "batch", ",", "\n", "\"gold_score\"", ":", "self", ".", "_gold_score", "(", "\n", "batch", ",", "memory_bank", ",", "src_lengths", ",", "src_vocabs", ",", "use_src_map", ",", "\n", "enc_states", ",", "batch_size", ",", "src", ")", "}", "\n", "\n", "# (2) Repeat src objects `beam_size` times.", "\n", "# We use batch_size x beam_size", "\n", "src_map", "=", "(", "tile", "(", "batch", ".", "src_map", ",", "beam_size", ",", "dim", "=", "1", ")", "\n", "if", "use_src_map", "else", "None", ")", "\n", "self", ".", "model", ".", "decoder", ".", "map_state", "(", "\n", "lambda", "state", ",", "dim", ":", "tile", "(", "state", ",", "beam_size", ",", "dim", "=", "dim", ")", ")", "\n", "\n", "if", "isinstance", "(", "memory_bank", ",", "tuple", ")", ":", "\n", "            ", "memory_bank", "=", "tuple", "(", "tile", "(", "x", ",", "beam_size", ",", "dim", "=", "1", ")", "for", "x", "in", "memory_bank", ")", "\n", "mb_device", "=", "memory_bank", "[", "0", "]", ".", "device", "\n", "", "else", ":", "\n", "            ", "memory_bank", "=", "tile", "(", "memory_bank", ",", "beam_size", ",", "dim", "=", "1", ")", "\n", "mb_device", "=", "memory_bank", ".", "device", "\n", "", "memory_lengths", "=", "tile", "(", "src_lengths", ",", "beam_size", ")", "\n", "\n", "# (0) pt 2, prep the beam object", "\n", "beam", "=", "BeamSearch", "(", "\n", "beam_size", ",", "\n", "n_best", "=", "n_best", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "global_scorer", "=", "self", ".", "global_scorer", ",", "\n", "pad", "=", "self", ".", "_tgt_pad_idx", ",", "\n", "eos", "=", "self", ".", "_tgt_eos_idx", ",", "\n", "bos", "=", "self", ".", "_tgt_bos_idx", ",", "\n", "min_length", "=", "min_length", ",", "\n", "max_length", "=", "max_length", ",", "\n", "mb_device", "=", "mb_device", ",", "\n", "return_attention", "=", "return_attention", ",", "\n", "stepwise_penalty", "=", "self", ".", "stepwise_penalty", ",", "\n", "block_ngram_repeat", "=", "self", ".", "block_ngram_repeat", ",", "\n", "exclusion_tokens", "=", "self", ".", "_exclusion_idxs", ",", "\n", "memory_lengths", "=", "memory_lengths", ")", "\n", "\n", "for", "step", "in", "range", "(", "max_length", ")", ":", "\n", "# current_predictions: batch_size * beam_size", "\n", "            ", "decoder_input", "=", "beam", ".", "current_predictions", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", "\n", "\n", "# log_probs: batch_size * beam_size,  vocab(maybe include attn)", "\n", "log_probs", ",", "attn", ",", "dec_out_attn", "=", "self", ".", "_decode_and_generate", "(", "\n", "decoder_input", ",", "\n", "memory_bank", ",", "\n", "batch", ",", "\n", "src_vocabs", ",", "\n", "memory_lengths", "=", "memory_lengths", ",", "\n", "src_map", "=", "src_map", ",", "\n", "step", "=", "step", ",", "\n", "batch_offset", "=", "beam", ".", "_batch_offset", ")", "\n", "\n", "beam", ".", "advance", "(", "log_probs", ",", "attn", ",", "dec_out_attn", ")", "\n", "\n", "any_beam_is_finished", "=", "beam", ".", "is_finished", ".", "any", "(", ")", "\n", "# we do not early stop while training.", "\n", "if", "any_beam_is_finished", ":", "\n", "                ", "beam", ".", "update_finished", "(", "training", ")", "\n", "if", "beam", ".", "done", "and", "not", "training", ":", "\n", "                    ", "max_length", "=", "step", "\n", "break", "\n", "\n", "", "", "select_indices", "=", "beam", ".", "current_origin", "\n", "\n", "if", "any_beam_is_finished", ":", "\n", "# Reorder states.", "\n", "                ", "if", "isinstance", "(", "memory_bank", ",", "tuple", ")", ":", "\n", "                    ", "memory_bank", "=", "tuple", "(", "x", ".", "index_select", "(", "1", ",", "select_indices", ")", "\n", "for", "x", "in", "memory_bank", ")", "\n", "", "else", ":", "\n", "                    ", "memory_bank", "=", "memory_bank", ".", "index_select", "(", "1", ",", "select_indices", ")", "\n", "\n", "", "memory_lengths", "=", "memory_lengths", ".", "index_select", "(", "0", ",", "select_indices", ")", "\n", "\n", "if", "src_map", "is", "not", "None", ":", "\n", "                    ", "src_map", "=", "src_map", ".", "index_select", "(", "1", ",", "select_indices", ")", "\n", "\n", "", "", "self", ".", "model", ".", "decoder", ".", "map_state", "(", "\n", "lambda", "state", ",", "dim", ":", "state", ".", "index_select", "(", "dim", ",", "select_indices", ")", ")", "\n", "# batch_size * beam_size", "\n", "", "results", "[", "\"scores\"", "]", "=", "beam", ".", "scores", "\n", "results", "[", "\"predictions\"", "]", "=", "beam", ".", "predictions", "\n", "results", "[", "\"attention\"", "]", "=", "beam", ".", "attention", "\n", "results", "[", "\"hypotheses\"", "]", "=", "beam", ".", "hypotheses", "\n", "if", "training", ":", "\n", "            ", "results", "[", "\"dec_outputs\"", "]", "=", "beam", ".", "dec_outputs", ".", "view", "(", "max_length", ",", "batch_size", ",", "beam_size", ",", "-", "1", ")", "\n", "results", "[", "\"dec_attns\"", "]", "=", "beam", ".", "dec_attns", "\n", "for", "key", "in", "results", "[", "\"dec_attns\"", "]", ":", "\n", "                ", "results", "[", "\"dec_attns\"", "]", "[", "key", "]", "=", "results", "[", "\"dec_attns\"", "]", "[", "key", "]", ".", "view", "(", "max_length", ",", "batch_size", ",", "beam_size", ",", "-", "1", ")", "\n", "", "assert", "max_length", "==", "batch", ".", "tgt", ".", "size", "(", "0", ")", "-", "1", ",", "\"max_length {}, tgt {}\"", ".", "format", "(", "max_length", ",", "batch", ".", "tgt", ".", "size", "(", ")", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._score_target": [[735, 750], ["translator.Translator._decode_and_generate", "log_probs.gather", "gold_scores.sum().view.sum().view.sum().view", "gold_scores.sum().view.sum().view.sum"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._decode_and_generate"], ["", "def", "_score_target", "(", "self", ",", "batch", ",", "memory_bank", ",", "src_lengths", ",", "\n", "src_vocabs", ",", "src_map", ")", ":", "\n", "        ", "tgt", "=", "batch", ".", "tgt", "\n", "tgt_in", "=", "tgt", "[", ":", "-", "1", "]", "\n", "\n", "log_probs", ",", "attn", ",", "dec_out_attn", "=", "self", ".", "_decode_and_generate", "(", "\n", "tgt_in", ",", "memory_bank", ",", "batch", ",", "src_vocabs", ",", "\n", "memory_lengths", "=", "src_lengths", ",", "src_map", "=", "src_map", ")", "\n", "\n", "log_probs", "[", ":", ",", ":", ",", "self", ".", "_tgt_pad_idx", "]", "=", "0", "\n", "gold", "=", "tgt_in", "\n", "gold_scores", "=", "log_probs", ".", "gather", "(", "2", ",", "gold", ")", "\n", "gold_scores", "=", "gold_scores", ".", "sum", "(", "dim", "=", "0", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "return", "gold_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._report_score": [[751, 759], ["math.exp"], "methods", ["None"], ["", "def", "_report_score", "(", "self", ",", "name", ",", "score_total", ",", "words_total", ")", ":", "\n", "        ", "if", "words_total", "==", "0", ":", "\n", "            ", "msg", "=", "\"%s No words predicted\"", "%", "(", "name", ",", ")", "\n", "", "else", ":", "\n", "            ", "msg", "=", "(", "\"%s AVG SCORE: %.4f, %s PPL: %.4f\"", "%", "(", "\n", "name", ",", "score_total", "/", "words_total", ",", "\n", "name", ",", "math", ".", "exp", "(", "-", "score_total", "/", "words_total", ")", ")", ")", "\n", "", "return", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._report_bleu": [[760, 773], ["os.path.abspath", "translator.Translator.out_file.seek", "subprocess.check_output().decode", "subprocess.check_output().decode.strip", "subprocess.check_output"], "methods", ["None"], ["", "def", "_report_bleu", "(", "self", ",", "tgt_path", ")", ":", "\n", "        ", "import", "subprocess", "\n", "base_dir", "=", "os", ".", "path", ".", "abspath", "(", "__file__", "+", "\"/../../..\"", ")", "\n", "# Rollback pointer to the beginning.", "\n", "self", ".", "out_file", ".", "seek", "(", "0", ")", "\n", "# print(\"perl %s/tools/multi-bleu.perl %s\" % (base_dir, tgt_path))", "\n", "res", "=", "subprocess", ".", "check_output", "(", "\n", "\"perl %s/tools/multi-bleu.perl %s\"", "%", "(", "base_dir", ",", "tgt_path", ")", ",", "\n", "stdin", "=", "self", ".", "out_file", ",", "shell", "=", "True", "\n", ")", ".", "decode", "(", "\"utf-8\"", ")", "\n", "\n", "msg", "=", "\">> \"", "+", "res", ".", "strip", "(", ")", "\n", "return", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator._report_rouge": [[774, 782], ["os.path.abspath", "subprocess.check_output().decode().strip", "subprocess.check_output().decode", "subprocess.check_output"], "methods", ["None"], ["", "def", "_report_rouge", "(", "self", ",", "tgt_path", ",", "pred_path", ")", ":", "\n", "        ", "import", "subprocess", "\n", "base_dir", "=", "os", ".", "path", ".", "abspath", "(", "__file__", "+", "\"/../../..\"", ")", "\n", "msg", "=", "subprocess", ".", "check_output", "(", "\n", "\"python %s/tools/test_rouge.py -r %s -c %s\"", "%", "(", "base_dir", ",", "tgt_path", ",", "pred_path", ")", ",", "\n", "shell", "=", "True", ",", "stdin", "=", "self", ".", "out_file", "\n", ")", ".", "decode", "(", "\"utf-8\"", ")", ".", "strip", "(", ")", "\n", "return", "msg", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.wrap_translator": [[20, 35], ["onmt.translate.GNMTGlobalScorer.from_opt", "onmt.translate.GNMTGlobalScorer.from_opt", "onmt.translate.GNMTGlobalScorer.from_opt", "translator.Translator.from_opt"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt"], ["def", "wrap_translator", "(", "model", ",", "fields", ",", "opt", ",", "model_opt", ",", "report_score", "=", "True", ",", "logger", "=", "None", ",", "out_file", "=", "None", ")", ":", "\n", "\n", "    ", "scorer", "=", "onmt", ".", "translate", ".", "GNMTGlobalScorer", ".", "from_opt", "(", "opt", ")", "\n", "\n", "translator", "=", "Translator", ".", "from_opt", "(", "\n", "model", ",", "\n", "fields", ",", "\n", "opt", ",", "\n", "model_opt", ",", "\n", "global_scorer", "=", "scorer", ",", "\n", "out_file", "=", "out_file", ",", "\n", "report_score", "=", "report_score", ",", "\n", "logger", "=", "logger", "\n", ")", "\n", "return", "translator", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.build_translator": [[37, 57], ["load_test_model", "onmt.translate.GNMTGlobalScorer.from_opt", "onmt.translate.GNMTGlobalScorer.from_opt", "onmt.translate.GNMTGlobalScorer.from_opt", "translator.Translator.from_opt", "codecs.open"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.load_test_model", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt"], ["", "def", "build_translator", "(", "opt", ",", "report_score", "=", "True", ",", "logger", "=", "None", ",", "out_file", "=", "None", ")", ":", "\n", "    ", "if", "out_file", "is", "None", ":", "\n", "        ", "out_file", "=", "codecs", ".", "open", "(", "opt", ".", "output", ",", "'w+'", ",", "'utf-8'", ")", "\n", "\n", "", "load_test_model", "=", "onmt", ".", "model_builder", ".", "load_test_model", "\n", "fields", ",", "model", ",", "model_opt", "=", "load_test_model", "(", "opt", ")", "\n", "\n", "scorer", "=", "onmt", ".", "translate", ".", "GNMTGlobalScorer", ".", "from_opt", "(", "opt", ")", "\n", "\n", "translator", "=", "Translator", ".", "from_opt", "(", "\n", "model", ",", "\n", "fields", ",", "\n", "opt", ",", "\n", "model_opt", ",", "\n", "global_scorer", "=", "scorer", ",", "\n", "out_file", "=", "out_file", ",", "\n", "report_score", "=", "report_score", ",", "\n", "logger", "=", "logger", "\n", ")", "\n", "return", "translator", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.Timer.__init__": [[42, 48], ["translation_server.Timer.start"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.TranslationServer.start"], ["    ", "def", "__init__", "(", "self", ",", "start", "=", "False", ")", ":", "\n", "        ", "self", ".", "stime", "=", "-", "1", "\n", "self", ".", "prev", "=", "-", "1", "\n", "self", ".", "times", "=", "{", "}", "\n", "if", "start", ":", "\n", "            ", "self", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.Timer.start": [[49, 53], ["time.time"], "methods", ["None"], ["", "", "def", "start", "(", "self", ")", ":", "\n", "        ", "self", ".", "stime", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "prev", "=", "self", ".", "stime", "\n", "self", ".", "times", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.Timer.tick": [[54, 65], ["time.time"], "methods", ["None"], ["", "def", "tick", "(", "self", ",", "name", "=", "None", ",", "tot", "=", "False", ")", ":", "\n", "        ", "t", "=", "time", ".", "time", "(", ")", "\n", "if", "not", "tot", ":", "\n", "            ", "elapsed", "=", "t", "-", "self", ".", "prev", "\n", "", "else", ":", "\n", "            ", "elapsed", "=", "t", "-", "self", ".", "stime", "\n", "", "self", ".", "prev", "=", "t", "\n", "\n", "if", "name", "is", "not", "None", ":", "\n", "            ", "self", ".", "times", "[", "name", "]", "=", "elapsed", "\n", "", "return", "elapsed", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.TranslationServer.__init__": [[72, 75], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "models", "=", "{", "}", "\n", "self", ".", "next_id", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.TranslationServer.start": [[76, 102], ["translation_server.TranslationServer.confs.get", "enumerate", "open", "json.load", "conf.get", "translation_server.TranslationServer.preload_model", "conf.get", "conf.get", "conf.get", "conf.get", "conf.get", "ValueError", "kwargs.items"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.TranslationServer.preload_model"], ["", "def", "start", "(", "self", ",", "config_file", ")", ":", "\n", "        ", "\"\"\"Read the config file and pre-/load the models.\"\"\"", "\n", "self", ".", "config_file", "=", "config_file", "\n", "with", "open", "(", "self", ".", "config_file", ")", "as", "f", ":", "\n", "            ", "self", ".", "confs", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "self", ".", "models_root", "=", "self", ".", "confs", ".", "get", "(", "'models_root'", ",", "'./available_models'", ")", "\n", "for", "i", ",", "conf", "in", "enumerate", "(", "self", ".", "confs", "[", "\"models\"", "]", ")", ":", "\n", "            ", "if", "\"models\"", "not", "in", "conf", ":", "\n", "                ", "if", "\"model\"", "in", "conf", ":", "\n", "# backwards compatibility for confs", "\n", "                    ", "conf", "[", "\"models\"", "]", "=", "[", "conf", "[", "\"model\"", "]", "]", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\"\"\"Incorrect config file: missing 'models'\n                                        parameter for model #%d\"\"\"", "%", "i", ")", "\n", "", "", "kwargs", "=", "{", "'timeout'", ":", "conf", ".", "get", "(", "'timeout'", ",", "None", ")", ",", "\n", "'load'", ":", "conf", ".", "get", "(", "'load'", ",", "None", ")", ",", "\n", "'tokenizer_opt'", ":", "conf", ".", "get", "(", "'tokenizer'", ",", "None", ")", ",", "\n", "'on_timeout'", ":", "conf", ".", "get", "(", "'on_timeout'", ",", "None", ")", ",", "\n", "'model_root'", ":", "conf", ".", "get", "(", "'model_root'", ",", "self", ".", "models_root", ")", "\n", "}", "\n", "kwargs", "=", "{", "k", ":", "v", "for", "(", "k", ",", "v", ")", "in", "kwargs", ".", "items", "(", ")", "if", "v", "is", "not", "None", "}", "\n", "model_id", "=", "conf", ".", "get", "(", "\"id\"", ",", "None", ")", "\n", "opt", "=", "conf", "[", "\"opt\"", "]", "\n", "opt", "[", "\"models\"", "]", "=", "conf", "[", "\"models\"", "]", "\n", "self", ".", "preload_model", "(", "opt", ",", "model_id", "=", "model_id", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.TranslationServer.clone_model": [[103, 116], ["translation_server.TranslationServer.load_model", "translation_server.ServerModelError", "str"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.TranslationServer.load_model"], ["", "", "def", "clone_model", "(", "self", ",", "model_id", ",", "opt", ",", "timeout", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"Clone a model `model_id`.\n\n        Different options may be passed. If `opt` is None, it will use the\n        same set of options\n        \"\"\"", "\n", "if", "model_id", "in", "self", ".", "models", ":", "\n", "            ", "if", "opt", "is", "None", ":", "\n", "                ", "opt", "=", "self", ".", "models", "[", "model_id", "]", ".", "user_opt", "\n", "", "opt", "[", "\"models\"", "]", "=", "self", ".", "models", "[", "model_id", "]", ".", "opt", ".", "models", "\n", "return", "self", ".", "load_model", "(", "opt", ",", "timeout", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ServerModelError", "(", "\"No such model '%s'\"", "%", "str", "(", "model_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.TranslationServer.load_model": [[117, 124], ["translation_server.TranslationServer.preload_model"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.TranslationServer.preload_model"], ["", "", "def", "load_model", "(", "self", ",", "opt", ",", "model_id", "=", "None", ",", "**", "model_kwargs", ")", ":", "\n", "        ", "\"\"\"Load a model given a set of options\n        \"\"\"", "\n", "model_id", "=", "self", ".", "preload_model", "(", "opt", ",", "model_id", "=", "model_id", ",", "**", "model_kwargs", ")", "\n", "load_time", "=", "self", ".", "models", "[", "model_id", "]", ".", "load_time", "\n", "\n", "return", "model_id", ",", "load_time", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.TranslationServer.preload_model": [[125, 143], ["print", "translation_server.ServerModel", "translation_server.TranslationServer.models.keys", "ValueError", "translation_server.TranslationServer.models.keys"], "methods", ["None"], ["", "def", "preload_model", "(", "self", ",", "opt", ",", "model_id", "=", "None", ",", "**", "model_kwargs", ")", ":", "\n", "        ", "\"\"\"Preloading the model: updating internal datastructure\n\n        It will effectively load the model if `load` is set\n        \"\"\"", "\n", "if", "model_id", "is", "not", "None", ":", "\n", "            ", "if", "model_id", "in", "self", ".", "models", ".", "keys", "(", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"Model ID %d already exists\"", "%", "model_id", ")", "\n", "", "", "else", ":", "\n", "            ", "model_id", "=", "self", ".", "next_id", "\n", "while", "model_id", "in", "self", ".", "models", ".", "keys", "(", ")", ":", "\n", "                ", "model_id", "+=", "1", "\n", "", "self", ".", "next_id", "=", "model_id", "+", "1", "\n", "", "print", "(", "\"Pre-loading model %d\"", "%", "model_id", ")", "\n", "model", "=", "ServerModel", "(", "opt", ",", "model_id", ",", "**", "model_kwargs", ")", "\n", "self", ".", "models", "[", "model_id", "]", "=", "model", "\n", "\n", "return", "model_id", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.TranslationServer.run": [[144, 159], ["inputs[].get", "translation_server.TranslationServer.models[].run", "print", "translation_server.ServerModelError", "str", "str"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.run"], ["", "def", "run", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Translate `inputs`\n\n        We keep the same format as the Lua version i.e.\n        ``[{\"id\": model_id, \"src\": \"sequence to translate\"},{ ...}]``\n\n        We use inputs[0][\"id\"] as the model id\n        \"\"\"", "\n", "\n", "model_id", "=", "inputs", "[", "0", "]", ".", "get", "(", "\"id\"", ",", "0", ")", "\n", "if", "model_id", "in", "self", ".", "models", "and", "self", ".", "models", "[", "model_id", "]", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "models", "[", "model_id", "]", ".", "run", "(", "inputs", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Error No such model '%s'\"", "%", "str", "(", "model_id", ")", ")", "\n", "raise", "ServerModelError", "(", "\"No such model '%s'\"", "%", "str", "(", "model_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.TranslationServer.unload_model": [[160, 170], ["translation_server.TranslationServer.models[].unload", "translation_server.ServerModelError", "str"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.unload"], ["", "", "def", "unload_model", "(", "self", ",", "model_id", ")", ":", "\n", "        ", "\"\"\"Manually unload a model.\n\n        It will free the memory and cancel the timer\n        \"\"\"", "\n", "\n", "if", "model_id", "in", "self", ".", "models", "and", "self", ".", "models", "[", "model_id", "]", "is", "not", "None", ":", "\n", "            ", "self", ".", "models", "[", "model_id", "]", ".", "unload", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ServerModelError", "(", "\"No such model '%s'\"", "%", "str", "(", "model_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.TranslationServer.list_models": [[171, 178], ["translation_server.TranslationServer.models.items", "model.to_dict"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.to_dict"], ["", "", "def", "list_models", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the list of available models\n        \"\"\"", "\n", "models", "=", "[", "]", "\n", "for", "_", ",", "model", "in", "self", ".", "models", ".", "items", "(", ")", ":", "\n", "            ", "models", "+=", "[", "model", ".", "to_dict", "(", ")", "]", "\n", "", "return", "models", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.__init__": [[196, 227], ["translation_server.ServerModel.parse_opt", "onmt.utils.logging.init_logger", "threading.Event", "translation_server.ServerModel.loading_lock.set", "threading.Semaphore", "onmt.utils.misc.set_random_seed", "ValueError", "len", "os.path.join", "translation_server.ServerModel.load"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.parse_opt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.logging.init_logger", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.set_random_seed", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load"], ["def", "__init__", "(", "self", ",", "opt", ",", "model_id", ",", "tokenizer_opt", "=", "None", ",", "load", "=", "False", ",", "\n", "timeout", "=", "-", "1", ",", "on_timeout", "=", "\"to_cpu\"", ",", "model_root", "=", "\"./\"", ")", ":", "\n", "        ", "self", ".", "model_root", "=", "model_root", "\n", "self", ".", "opt", "=", "self", ".", "parse_opt", "(", "opt", ")", "\n", "if", "self", ".", "opt", ".", "n_best", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Values of n_best > 1 are not supported\"", ")", "\n", "\n", "", "self", ".", "model_id", "=", "model_id", "\n", "self", ".", "tokenizer_opt", "=", "tokenizer_opt", "\n", "self", ".", "timeout", "=", "timeout", "\n", "self", ".", "on_timeout", "=", "on_timeout", "\n", "\n", "self", ".", "unload_timer", "=", "None", "\n", "self", ".", "user_opt", "=", "opt", "\n", "self", ".", "tokenizer", "=", "None", "\n", "\n", "if", "len", "(", "self", ".", "opt", ".", "log_file", ")", ">", "0", ":", "\n", "            ", "log_file", "=", "os", ".", "path", ".", "join", "(", "model_root", ",", "self", ".", "opt", ".", "log_file", ")", "\n", "", "else", ":", "\n", "            ", "log_file", "=", "None", "\n", "", "self", ".", "logger", "=", "init_logger", "(", "log_file", "=", "log_file", ",", "\n", "log_file_level", "=", "self", ".", "opt", ".", "log_file_level", ")", "\n", "\n", "self", ".", "loading_lock", "=", "threading", ".", "Event", "(", ")", "\n", "self", ".", "loading_lock", ".", "set", "(", ")", "\n", "self", ".", "running_lock", "=", "threading", ".", "Semaphore", "(", "value", "=", "1", ")", "\n", "\n", "set_random_seed", "(", "self", ".", "opt", ".", "seed", ",", "self", ".", "opt", ".", "cuda", ")", "\n", "\n", "if", "load", ":", "\n", "            ", "self", ".", "load", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.parse_opt": [[228, 265], ["onmt.utils.parse.ArgumentParser", "onmt.opts.translate_opts", "onmt.utils.parse.ArgumentParser.parse_args.items", "onmt.utils.parse.ArgumentParser.parse_args", "onmt.utils.parse.ArgumentParser.validate_translate_opts", "isinstance", "os.path.join", "str", "type", "str"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.opts.translate_opts", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.parse.ArgumentParser.validate_translate_opts"], ["", "", "def", "parse_opt", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Parse the option set passed by the user using `onmt.opts`\n\n       Args:\n           opt (dict): Options passed by the user\n\n       Returns:\n           opt (argparse.Namespace): full set of options for the Translator\n        \"\"\"", "\n", "\n", "prec_argv", "=", "sys", ".", "argv", "\n", "sys", ".", "argv", "=", "sys", ".", "argv", "[", ":", "1", "]", "\n", "parser", "=", "ArgumentParser", "(", ")", "\n", "onmt", ".", "opts", ".", "translate_opts", "(", "parser", ")", "\n", "\n", "models", "=", "opt", "[", "'models'", "]", "\n", "if", "not", "isinstance", "(", "models", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "models", "=", "[", "models", "]", "\n", "", "opt", "[", "'models'", "]", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "model_root", ",", "model", ")", "\n", "for", "model", "in", "models", "]", "\n", "opt", "[", "'src'", "]", "=", "\"dummy_src\"", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "opt", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "==", "'models'", ":", "\n", "                ", "sys", ".", "argv", "+=", "[", "'-model'", "]", "\n", "sys", ".", "argv", "+=", "[", "str", "(", "model", ")", "for", "model", "in", "v", "]", "\n", "", "elif", "type", "(", "v", ")", "==", "bool", ":", "\n", "                ", "sys", ".", "argv", "+=", "[", "'-%s'", "%", "k", "]", "\n", "", "else", ":", "\n", "                ", "sys", ".", "argv", "+=", "[", "'-%s'", "%", "k", ",", "str", "(", "v", ")", "]", "\n", "\n", "", "", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "ArgumentParser", ".", "validate_translate_opts", "(", "opt", ")", "\n", "opt", ".", "cuda", "=", "opt", ".", "gpu", ">", "-", "1", "\n", "\n", "sys", ".", "argv", "=", "prec_argv", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.loaded": [[266, 269], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "loaded", "(", "self", ")", ":", "\n", "        ", "return", "hasattr", "(", "self", ",", "'translator'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.load": [[270, 326], ["translation_server.ServerModel.loading_lock.clear", "translation_server.Timer", "translation_server.ServerModel.logger.info", "translation_server.Timer.start", "translation_server.Timer.tick", "translation_server.Timer.tick", "translation_server.ServerModel.reset_unload_timer", "translation_server.ServerModel.loading_lock.set", "onmt.translate.translator.build_translator", "translation_server.ServerModel.logger.info", "translation_server.ServerModelError", "ValueError", "spm.SentencePieceProcessor", "os.path.join", "spm.SentencePieceProcessor.Load", "open", "ValueError", "dict", "translation_server.ServerModel.tokenizer_opt[].items", "pyonmttok.Tokenizer", "ValueError", "str", "ValueError", "key.endswith", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.TranslationServer.start", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.Timer.tick", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.Timer.tick", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.reset_unload_timer", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.build_translator"], ["", "def", "load", "(", "self", ")", ":", "\n", "        ", "self", ".", "loading_lock", ".", "clear", "(", ")", "\n", "\n", "timer", "=", "Timer", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Loading model %d\"", "%", "self", ".", "model_id", ")", "\n", "timer", ".", "start", "(", ")", "\n", "\n", "try", ":", "\n", "            ", "self", ".", "translator", "=", "build_translator", "(", "self", ".", "opt", ",", "\n", "report_score", "=", "False", ",", "\n", "out_file", "=", "open", "(", "os", ".", "devnull", ",", "\"w\"", ")", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "            ", "raise", "ServerModelError", "(", "\"Runtime Error: %s\"", "%", "str", "(", "e", ")", ")", "\n", "\n", "", "timer", ".", "tick", "(", "\"model_loading\"", ")", "\n", "if", "self", ".", "tokenizer_opt", "is", "not", "None", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Loading tokenizer\"", ")", "\n", "\n", "if", "\"type\"", "not", "in", "self", ".", "tokenizer_opt", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Missing mandatory tokenizer option 'type'\"", ")", "\n", "\n", "", "if", "self", ".", "tokenizer_opt", "[", "'type'", "]", "==", "'sentencepiece'", ":", "\n", "                ", "if", "\"model\"", "not", "in", "self", ".", "tokenizer_opt", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Missing mandatory tokenizer option 'model'\"", ")", "\n", "", "import", "sentencepiece", "as", "spm", "\n", "sp", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "model_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "model_root", ",", "\n", "self", ".", "tokenizer_opt", "[", "'model'", "]", ")", "\n", "sp", ".", "Load", "(", "model_path", ")", "\n", "self", ".", "tokenizer", "=", "sp", "\n", "", "elif", "self", ".", "tokenizer_opt", "[", "'type'", "]", "==", "'pyonmttok'", ":", "\n", "                ", "if", "\"params\"", "not", "in", "self", ".", "tokenizer_opt", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Missing mandatory tokenizer option 'params'\"", ")", "\n", "", "import", "pyonmttok", "\n", "if", "self", ".", "tokenizer_opt", "[", "\"mode\"", "]", "is", "not", "None", ":", "\n", "                    ", "mode", "=", "self", ".", "tokenizer_opt", "[", "\"mode\"", "]", "\n", "", "else", ":", "\n", "                    ", "mode", "=", "None", "\n", "# load can be called multiple times: modify copy", "\n", "", "tokenizer_params", "=", "dict", "(", "self", ".", "tokenizer_opt", "[", "\"params\"", "]", ")", "\n", "for", "key", ",", "value", "in", "self", ".", "tokenizer_opt", "[", "\"params\"", "]", ".", "items", "(", ")", ":", "\n", "                    ", "if", "key", ".", "endswith", "(", "\"path\"", ")", ":", "\n", "                        ", "tokenizer_params", "[", "key", "]", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "model_root", ",", "value", ")", "\n", "", "", "tokenizer", "=", "pyonmttok", ".", "Tokenizer", "(", "mode", ",", "\n", "**", "tokenizer_params", ")", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Invalid value for tokenizer type\"", ")", "\n", "\n", "", "", "self", ".", "load_time", "=", "timer", ".", "tick", "(", ")", "\n", "self", ".", "reset_unload_timer", "(", ")", "\n", "self", ".", "loading_lock", ".", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.run": [[327, 434], ["translation_server.ServerModel.stop_unload_timer", "translation_server.Timer", "translation_server.Timer.start", "translation_server.ServerModel.logger.info", "enumerate", "translation_server.Timer.tick", "translation_server.ServerModel.logger.info", "translation_server.ServerModel.reset_unload_timer", "translation_server.ServerModel.run.flatten_list"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.stop_unload_timer", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.TranslationServer.start", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.Timer.tick", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.reset_unload_timer"], ["", "@", "critical", "\n", "def", "run", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Translate `inputs` using this model\n\n        Args:\n            inputs (List[dict[str, str]]): [{\"src\": \"...\"},{\"src\": ...}]\n\n        Returns:\n            result (list): translations\n            times (dict): containing times\n        \"\"\"", "\n", "\n", "self", ".", "stop_unload_timer", "(", ")", "\n", "\n", "timer", "=", "Timer", "(", ")", "\n", "timer", ".", "start", "(", ")", "\n", "\n", "self", ".", "logger", ".", "info", "(", "\"Running translation using %d\"", "%", "self", ".", "model_id", ")", "\n", "\n", "if", "not", "self", ".", "loading_lock", ".", "is_set", "(", ")", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\n", "\"Model #%d is being loaded by another thread, waiting\"", "\n", "%", "self", ".", "model_id", ")", "\n", "if", "not", "self", ".", "loading_lock", ".", "wait", "(", "timeout", "=", "30", ")", ":", "\n", "                ", "raise", "ServerModelError", "(", "\"Model %d loading timeout\"", "\n", "%", "self", ".", "model_id", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "not", "self", ".", "loaded", ":", "\n", "                ", "self", ".", "load", "(", ")", "\n", "timer", ".", "tick", "(", "name", "=", "\"load\"", ")", "\n", "", "elif", "self", ".", "opt", ".", "cuda", ":", "\n", "                ", "self", ".", "to_gpu", "(", ")", "\n", "timer", ".", "tick", "(", "name", "=", "\"to_gpu\"", ")", "\n", "\n", "", "", "texts", "=", "[", "]", "\n", "head_spaces", "=", "[", "]", "\n", "tail_spaces", "=", "[", "]", "\n", "sslength", "=", "[", "]", "\n", "for", "i", ",", "inp", "in", "enumerate", "(", "inputs", ")", ":", "\n", "            ", "src", "=", "inp", "[", "'src'", "]", "\n", "if", "src", ".", "strip", "(", ")", "==", "\"\"", ":", "\n", "                ", "head_spaces", ".", "append", "(", "src", ")", "\n", "texts", ".", "append", "(", "\"\"", ")", "\n", "tail_spaces", ".", "append", "(", "\"\"", ")", "\n", "", "else", ":", "\n", "                ", "whitespaces_before", ",", "whitespaces_after", "=", "\"\"", ",", "\"\"", "\n", "match_before", "=", "re", ".", "search", "(", "r'^\\s+'", ",", "src", ")", "\n", "match_after", "=", "re", ".", "search", "(", "r'\\s+$'", ",", "src", ")", "\n", "if", "match_before", "is", "not", "None", ":", "\n", "                    ", "whitespaces_before", "=", "match_before", ".", "group", "(", "0", ")", "\n", "", "if", "match_after", "is", "not", "None", ":", "\n", "                    ", "whitespaces_after", "=", "match_after", ".", "group", "(", "0", ")", "\n", "", "head_spaces", ".", "append", "(", "whitespaces_before", ")", "\n", "tok", "=", "self", ".", "maybe_tokenize", "(", "src", ".", "strip", "(", ")", ")", "\n", "texts", ".", "append", "(", "tok", ")", "\n", "sslength", ".", "append", "(", "len", "(", "tok", ".", "split", "(", ")", ")", ")", "\n", "tail_spaces", ".", "append", "(", "whitespaces_after", ")", "\n", "\n", "", "", "empty_indices", "=", "[", "i", "for", "i", ",", "x", "in", "enumerate", "(", "texts", ")", "if", "x", "==", "\"\"", "]", "\n", "texts_to_translate", "=", "[", "x", "for", "x", "in", "texts", "if", "x", "!=", "\"\"", "]", "\n", "\n", "scores", "=", "[", "]", "\n", "predictions", "=", "[", "]", "\n", "if", "len", "(", "texts_to_translate", ")", ">", "0", ":", "\n", "            ", "try", ":", "\n", "                ", "scores", ",", "predictions", "=", "self", ".", "translator", ".", "translate", "(", "\n", "texts_to_translate", ",", "\n", "batch_size", "=", "self", ".", "opt", ".", "batch_size", ")", "\n", "", "except", "(", "RuntimeError", ",", "Exception", ")", "as", "e", ":", "\n", "                ", "err", "=", "\"Error: %s\"", "%", "str", "(", "e", ")", "\n", "self", ".", "logger", ".", "error", "(", "err", ")", "\n", "self", ".", "logger", ".", "error", "(", "\"repr(text_to_translate): \"", "\n", "+", "repr", "(", "texts_to_translate", ")", ")", "\n", "self", ".", "logger", ".", "error", "(", "\"model: #%s\"", "%", "self", ".", "model_id", ")", "\n", "self", ".", "logger", ".", "error", "(", "\"model opt: \"", "+", "str", "(", "self", ".", "opt", ".", "__dict__", ")", ")", "\n", "self", ".", "logger", ".", "error", "(", "traceback", ".", "format_exc", "(", ")", ")", "\n", "\n", "raise", "ServerModelError", "(", "err", ")", "\n", "\n", "", "", "timer", ".", "tick", "(", "name", "=", "\"translation\"", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"\"\"Using model #%d\\t%d inputs\n               \\ttranslation time: %f\"\"\"", "%", "(", "self", ".", "model_id", ",", "len", "(", "texts", ")", ",", "\n", "timer", ".", "times", "[", "'translation'", "]", ")", ")", "\n", "self", ".", "reset_unload_timer", "(", ")", "\n", "\n", "# NOTE: translator returns lists of `n_best` list", "\n", "#       we can ignore that (i.e. flatten lists) only because", "\n", "#       we restrict `n_best=1`", "\n", "def", "flatten_list", "(", "_list", ")", ":", "return", "sum", "(", "_list", ",", "[", "]", ")", "\n", "results", "=", "flatten_list", "(", "predictions", ")", "\n", "scores", "=", "[", "score_tensor", ".", "item", "(", ")", "\n", "for", "score_tensor", "in", "flatten_list", "(", "scores", ")", "]", "\n", "\n", "results", "=", "[", "self", ".", "maybe_detokenize", "(", "item", ")", "\n", "for", "item", "in", "results", "]", "\n", "\n", "# build back results with empty texts", "\n", "for", "i", "in", "empty_indices", ":", "\n", "            ", "results", ".", "insert", "(", "i", ",", "\"\"", ")", "\n", "scores", ".", "insert", "(", "i", ",", "0", ")", "\n", "\n", "", "results", "=", "[", "\"\"", ".", "join", "(", "items", ")", "\n", "for", "items", "in", "zip", "(", "head_spaces", ",", "results", ",", "tail_spaces", ")", "]", "\n", "\n", "self", ".", "logger", ".", "info", "(", "\"Translation Results: %d\"", ",", "len", "(", "results", ")", ")", "\n", "return", "results", ",", "scores", ",", "self", ".", "opt", ".", "n_best", ",", "timer", ".", "times", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.do_timeout": [[435, 449], ["translation_server.ServerModel.logger.info", "translation_server.ServerModel.unload", "translation_server.ServerModel.logger.info", "translation_server.ServerModel.to_cpu"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.unload", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.to_cpu"], ["", "def", "do_timeout", "(", "self", ")", ":", "\n", "        ", "\"\"\"Timeout function that frees GPU memory.\n\n        Moves the model to CPU or unloads it; depending on\n        attr`self.on_timemout` value\n        \"\"\"", "\n", "\n", "if", "self", ".", "on_timeout", "==", "\"unload\"", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Timeout: unloading model %d\"", "%", "self", ".", "model_id", ")", "\n", "self", ".", "unload", "(", ")", "\n", "", "if", "self", ".", "on_timeout", "==", "\"to_cpu\"", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Timeout: sending model %d to CPU\"", "\n", "%", "self", ".", "model_id", ")", "\n", "self", ".", "to_cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.unload": [[450, 457], ["translation_server.ServerModel.logger.info", "torch.cuda.empty_cache"], "methods", ["None"], ["", "", "@", "critical", "\n", "def", "unload", "(", "self", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "\"Unloading model %d\"", "%", "self", ".", "model_id", ")", "\n", "del", "self", ".", "translator", "\n", "if", "self", ".", "opt", ".", "cuda", ":", "\n", "            ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "", "self", ".", "unload_timer", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.stop_unload_timer": [[458, 461], ["translation_server.ServerModel.unload_timer.cancel"], "methods", ["None"], ["", "def", "stop_unload_timer", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "unload_timer", "is", "not", "None", ":", "\n", "            ", "self", ".", "unload_timer", ".", "cancel", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.reset_unload_timer": [[462, 469], ["translation_server.ServerModel.stop_unload_timer", "threading.Timer", "translation_server.ServerModel.unload_timer.start"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.stop_unload_timer", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.TranslationServer.start"], ["", "", "def", "reset_unload_timer", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "timeout", "<", "0", ":", "\n", "            ", "return", "\n", "\n", "", "self", ".", "stop_unload_timer", "(", ")", "\n", "self", ".", "unload_timer", "=", "threading", ".", "Timer", "(", "self", ".", "timeout", ",", "self", ".", "do_timeout", ")", "\n", "self", ".", "unload_timer", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.to_dict": [[470, 482], ["translation_server.ServerModel.user_opt.keys"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "hide_opt", "=", "[", "\"models\"", ",", "\"src\"", "]", "\n", "d", "=", "{", "\"model_id\"", ":", "self", ".", "model_id", ",", "\n", "\"opt\"", ":", "{", "k", ":", "self", ".", "user_opt", "[", "k", "]", "for", "k", "in", "self", ".", "user_opt", ".", "keys", "(", ")", "\n", "if", "k", "not", "in", "hide_opt", "}", ",", "\n", "\"models\"", ":", "self", ".", "user_opt", "[", "\"models\"", "]", ",", "\n", "\"loaded\"", ":", "self", ".", "loaded", ",", "\n", "\"timeout\"", ":", "self", ".", "timeout", ",", "\n", "}", "\n", "if", "self", ".", "tokenizer_opt", "is", "not", "None", ":", "\n", "            ", "d", "[", "\"tokenizer\"", "]", "=", "self", ".", "tokenizer_opt", "\n", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.to_cpu": [[483, 489], ["translation_server.ServerModel.translator.model.cpu", "torch.cuda.empty_cache"], "methods", ["None"], ["", "@", "critical", "\n", "def", "to_cpu", "(", "self", ")", ":", "\n", "        ", "\"\"\"Move the model to CPU and clear CUDA cache.\"\"\"", "\n", "self", ".", "translator", ".", "model", ".", "cpu", "(", ")", "\n", "if", "self", ".", "opt", ".", "cuda", ":", "\n", "            ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.to_gpu": [[490, 494], ["torch.cuda.set_device", "translation_server.ServerModel.translator.model.cuda"], "methods", ["None"], ["", "", "def", "to_gpu", "(", "self", ")", ":", "\n", "        ", "\"\"\"Move the model to GPU.\"\"\"", "\n", "torch", ".", "cuda", ".", "set_device", "(", "self", ".", "opt", ".", "gpu", ")", "\n", "self", ".", "translator", ".", "model", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.maybe_tokenize": [[495, 504], ["translation_server.ServerModel.tokenize"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.tokenize"], ["", "def", "maybe_tokenize", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"Tokenize the sequence (or not).\n\n        Same args/returns as `tokenize`\n        \"\"\"", "\n", "\n", "if", "self", ".", "tokenizer_opt", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "tokenize", "(", "sequence", ")", "\n", "", "return", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.tokenize": [[505, 525], ["ValueError", "translation_server.ServerModel.tokenizer.EncodeAsPieces", "translation_server.ServerModel.tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.tokenize"], ["", "def", "tokenize", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"Tokenize a single sequence.\n\n        Args:\n            sequence (str): The sequence to tokenize.\n\n        Returns:\n            tok (str): The tokenized sequence.\n        \"\"\"", "\n", "\n", "if", "self", ".", "tokenizer", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"No tokenizer loaded\"", ")", "\n", "\n", "", "if", "self", ".", "tokenizer_opt", "[", "\"type\"", "]", "==", "\"sentencepiece\"", ":", "\n", "            ", "tok", "=", "self", ".", "tokenizer", ".", "EncodeAsPieces", "(", "sequence", ")", "\n", "tok", "=", "\" \"", ".", "join", "(", "tok", ")", "\n", "", "elif", "self", ".", "tokenizer_opt", "[", "\"type\"", "]", "==", "\"pyonmttok\"", ":", "\n", "            ", "tok", ",", "_", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "sequence", ")", "\n", "tok", "=", "\" \"", ".", "join", "(", "tok", ")", "\n", "", "return", "tok", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.maybe_detokenize": [[526, 535], ["translation_server.ServerModel.detokenize", "sequence.split"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.detokenize"], ["", "def", "maybe_detokenize", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"De-tokenize the sequence (or not)\n\n        Same args/returns as :func:`tokenize()`\n        \"\"\"", "\n", "\n", "if", "self", ".", "tokenizer_opt", "is", "not", "None", "and", "''", ".", "join", "(", "sequence", ".", "split", "(", ")", ")", "!=", "''", ":", "\n", "            ", "return", "self", ".", "detokenize", "(", "sequence", ")", "\n", "", "return", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.detokenize": [[536, 551], ["ValueError", "translation_server.ServerModel.tokenizer.DecodePieces", "sequence.split", "translation_server.ServerModel.tokenizer.detokenize", "sequence.split"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.ServerModel.detokenize"], ["", "def", "detokenize", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"Detokenize a single sequence\n\n        Same args/returns as :func:`tokenize()`\n        \"\"\"", "\n", "\n", "if", "self", ".", "tokenizer", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"No tokenizer loaded\"", ")", "\n", "\n", "", "if", "self", ".", "tokenizer_opt", "[", "\"type\"", "]", "==", "\"sentencepiece\"", ":", "\n", "            ", "detok", "=", "self", ".", "tokenizer", ".", "DecodePieces", "(", "sequence", ".", "split", "(", ")", ")", "\n", "", "elif", "self", ".", "tokenizer_opt", "[", "\"type\"", "]", "==", "\"pyonmttok\"", ":", "\n", "            ", "detok", "=", "self", ".", "tokenizer", ".", "detokenize", "(", "sequence", ".", "split", "(", ")", ")", "\n", "\n", "", "return", "detok", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation_server.critical": [[21, 39], ["server_model.running_lock.release", "server_model.running_lock.acquire", "func", "server_model.running_lock.acquire", "translation_server.ServerModelError", "server_model.running_lock.release"], "function", ["None"], ["def", "critical", "(", "func", ")", ":", "\n", "    ", "\"\"\"Decorator for critical section (mutually exclusive code)\"\"\"", "\n", "def", "wrapper", "(", "server_model", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", ":", "\n", "            ", "if", "not", "server_model", ".", "running_lock", ".", "acquire", "(", "True", ",", "120", ")", ":", "\n", "                ", "raise", "ServerModelError", "(", "\"Model %d running lock timeout\"", "\n", "%", "server_model", ".", "model_id", ")", "\n", "", "", "else", ":", "\n", "# semaphore doesn't have a timeout arg in Python 2.7", "\n", "            ", "server_model", ".", "running_lock", ".", "acquire", "(", "True", ")", "\n", "", "try", ":", "\n", "            ", "o", "=", "func", "(", "server_model", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "(", "Exception", ",", "RuntimeError", ")", ":", "\n", "            ", "server_model", ".", "running_lock", ".", "release", "(", ")", "\n", "raise", "\n", "", "server_model", ".", "running_lock", ".", "release", "(", ")", "\n", "return", "o", "\n", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam.Beam.__init__": [[31, 76], ["set", "beam.Beam.tt.FloatTensor().zero_", "beam.Beam.tt.LongTensor().fill_", "beam.Beam.tt.FloatTensor", "beam.Beam.tt.LongTensor"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "pad", ",", "bos", ",", "eos", ",", "\n", "n_best", "=", "1", ",", "cuda", "=", "False", ",", "\n", "global_scorer", "=", "None", ",", "\n", "min_length", "=", "0", ",", "\n", "stepwise_penalty", "=", "False", ",", "\n", "block_ngram_repeat", "=", "0", ",", "\n", "exclusion_tokens", "=", "set", "(", ")", ")", ":", "\n", "\n", "        ", "self", ".", "size", "=", "size", "\n", "self", ".", "tt", "=", "torch", ".", "cuda", "if", "cuda", "else", "torch", "\n", "\n", "# The score for each translation on the beam.", "\n", "self", ".", "scores", "=", "self", ".", "tt", ".", "FloatTensor", "(", "size", ")", ".", "zero_", "(", ")", "\n", "self", ".", "all_scores", "=", "[", "]", "\n", "\n", "# The backpointers at each time-step.", "\n", "self", ".", "prev_ks", "=", "[", "]", "\n", "\n", "# The outputs at each time-step.", "\n", "self", ".", "next_ys", "=", "[", "self", ".", "tt", ".", "LongTensor", "(", "size", ")", "\n", ".", "fill_", "(", "pad", ")", "]", "\n", "self", ".", "next_ys", "[", "0", "]", "[", "0", "]", "=", "bos", "\n", "\n", "# Has EOS topped the beam yet.", "\n", "self", ".", "_eos", "=", "eos", "\n", "self", ".", "eos_top", "=", "False", "\n", "\n", "# The attentions (matrix) for each time.", "\n", "self", ".", "attn", "=", "[", "]", "\n", "\n", "# Time and k pair for finished.", "\n", "self", ".", "finished", "=", "[", "]", "\n", "self", ".", "n_best", "=", "n_best", "\n", "\n", "# Information for global scoring.", "\n", "self", ".", "global_scorer", "=", "global_scorer", "\n", "self", ".", "global_state", "=", "{", "}", "\n", "\n", "# Minimum prediction length", "\n", "self", ".", "min_length", "=", "min_length", "\n", "\n", "# Apply Penalty at every step", "\n", "self", ".", "stepwise_penalty", "=", "stepwise_penalty", "\n", "self", ".", "block_ngram_repeat", "=", "block_ngram_repeat", "\n", "self", ".", "exclusion_tokens", "=", "exclusion_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam.Beam.current_predictions": [[77, 80], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "current_predictions", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "next_ys", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam.Beam.current_origin": [[81, 85], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "current_origin", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the backpointers for the current timestep.\"\"\"", "\n", "return", "self", ".", "prev_ks", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam.Beam.advance": [[86, 166], ["word_probs.size", "len", "beam_scores.view", "beam_scores.view.topk", "beam.Beam.all_scores.append", "beam.Beam.prev_ks.append", "beam.Beam.next_ys.append", "beam.Beam.attn.append", "beam.Beam.global_scorer.update_global_state", "range", "beam.Beam.global_scorer.update_score", "range", "len", "range", "attn_out.index_select", "beam.Beam.next_ys[].size", "beam.Beam.all_scores.append", "len", "beam.Beam.scores.unsqueeze", "beam.Beam.next_ys[].size", "len", "range", "beam.Beam.global_scorer.score", "beam.Beam.finished.append", "beam.Beam.next_ys[].size", "beam.Beam.get_hyp", "set", "range", "set.add", "set", "tuple", "tuple", "len", "hyp[].item"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam.GNMTGlobalScorer.update_global_state", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam.GNMTGlobalScorer.update_score", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam.GNMTGlobalScorer.score", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam.Beam.get_hyp"], ["", "def", "advance", "(", "self", ",", "word_probs", ",", "attn_out", ")", ":", "\n", "        ", "\"\"\"\n        Given prob over words for every last beam `wordLk` and attention\n        `attn_out`: Compute and update the beam search.\n\n        Args:\n            word_probs (FloatTensor): probs of advancing from the last step\n                ``(K, words)``\n            attn_out (FloatTensor): attention at the last step\n\n        Returns:\n            bool: True if beam search is complete.\n        \"\"\"", "\n", "\n", "num_words", "=", "word_probs", ".", "size", "(", "1", ")", "\n", "if", "self", ".", "stepwise_penalty", ":", "\n", "            ", "self", ".", "global_scorer", ".", "update_score", "(", "self", ",", "attn_out", ")", "\n", "# force the output to be longer than self.min_length", "\n", "", "cur_len", "=", "len", "(", "self", ".", "next_ys", ")", "\n", "if", "cur_len", "<=", "self", ".", "min_length", ":", "\n", "# assumes there are len(word_probs) predictions OTHER", "\n", "# than EOS that are greater than -1e20", "\n", "            ", "for", "k", "in", "range", "(", "len", "(", "word_probs", ")", ")", ":", "\n", "                ", "word_probs", "[", "k", "]", "[", "self", ".", "_eos", "]", "=", "-", "1e20", "\n", "\n", "# Sum the previous scores.", "\n", "", "", "if", "len", "(", "self", ".", "prev_ks", ")", ">", "0", ":", "\n", "            ", "beam_scores", "=", "word_probs", "+", "self", ".", "scores", ".", "unsqueeze", "(", "1", ")", "\n", "# Don't let EOS have children.", "\n", "for", "i", "in", "range", "(", "self", ".", "next_ys", "[", "-", "1", "]", ".", "size", "(", "0", ")", ")", ":", "\n", "                ", "if", "self", ".", "next_ys", "[", "-", "1", "]", "[", "i", "]", "==", "self", ".", "_eos", ":", "\n", "                    ", "beam_scores", "[", "i", "]", "=", "-", "1e20", "\n", "\n", "# Block ngram repeats", "\n", "", "", "if", "self", ".", "block_ngram_repeat", ">", "0", ":", "\n", "                ", "le", "=", "len", "(", "self", ".", "next_ys", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "next_ys", "[", "-", "1", "]", ".", "size", "(", "0", ")", ")", ":", "\n", "                    ", "hyp", ",", "_", "=", "self", ".", "get_hyp", "(", "le", "-", "1", ",", "j", ")", "\n", "ngrams", "=", "set", "(", ")", "\n", "fail", "=", "False", "\n", "gram", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "le", "-", "1", ")", ":", "\n", "# Last n tokens, n = block_ngram_repeat", "\n", "                        ", "gram", "=", "(", "gram", "+", "\n", "[", "hyp", "[", "i", "]", ".", "item", "(", ")", "]", ")", "[", "-", "self", ".", "block_ngram_repeat", ":", "]", "\n", "# Skip the blocking if it is in the exclusion list", "\n", "if", "set", "(", "gram", ")", "&", "self", ".", "exclusion_tokens", ":", "\n", "                            ", "continue", "\n", "", "if", "tuple", "(", "gram", ")", "in", "ngrams", ":", "\n", "                            ", "fail", "=", "True", "\n", "", "ngrams", ".", "add", "(", "tuple", "(", "gram", ")", ")", "\n", "", "if", "fail", ":", "\n", "                        ", "beam_scores", "[", "j", "]", "=", "-", "10e20", "\n", "", "", "", "", "else", ":", "\n", "            ", "beam_scores", "=", "word_probs", "[", "0", "]", "\n", "", "flat_beam_scores", "=", "beam_scores", ".", "view", "(", "-", "1", ")", "\n", "best_scores", ",", "best_scores_id", "=", "flat_beam_scores", ".", "topk", "(", "self", ".", "size", ",", "0", ",", "\n", "True", ",", "True", ")", "\n", "\n", "self", ".", "all_scores", ".", "append", "(", "self", ".", "scores", ")", "\n", "self", ".", "scores", "=", "best_scores", "\n", "\n", "# best_scores_id is flattened beam x word array, so calculate which", "\n", "# word and beam each score came from", "\n", "prev_k", "=", "best_scores_id", "/", "num_words", "\n", "self", ".", "prev_ks", ".", "append", "(", "prev_k", ")", "\n", "self", ".", "next_ys", ".", "append", "(", "(", "best_scores_id", "-", "prev_k", "*", "num_words", ")", ")", "\n", "self", ".", "attn", ".", "append", "(", "attn_out", ".", "index_select", "(", "0", ",", "prev_k", ")", ")", "\n", "self", ".", "global_scorer", ".", "update_global_state", "(", "self", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "next_ys", "[", "-", "1", "]", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "if", "self", ".", "next_ys", "[", "-", "1", "]", "[", "i", "]", "==", "self", ".", "_eos", ":", "\n", "                ", "global_scores", "=", "self", ".", "global_scorer", ".", "score", "(", "self", ",", "self", ".", "scores", ")", "\n", "s", "=", "global_scores", "[", "i", "]", "\n", "self", ".", "finished", ".", "append", "(", "(", "s", ",", "len", "(", "self", ".", "next_ys", ")", "-", "1", ",", "i", ")", ")", "\n", "\n", "# End condition is when top-of-beam is EOS and no global score.", "\n", "", "", "if", "self", ".", "next_ys", "[", "-", "1", "]", "[", "0", "]", "==", "self", ".", "_eos", ":", "\n", "            ", "self", ".", "all_scores", ".", "append", "(", "self", ".", "scores", ")", "\n", "self", ".", "eos_top", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam.Beam.done": [[167, 170], ["len"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "done", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "eos_top", "and", "len", "(", "self", ".", "finished", ")", ">=", "self", ".", "n_best", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam.Beam.sort_finished": [[171, 185], ["beam.Beam.finished.sort", "len", "beam.Beam.global_scorer.score", "beam.Beam.finished.append", "len"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam.GNMTGlobalScorer.score"], ["", "def", "sort_finished", "(", "self", ",", "minimum", "=", "None", ")", ":", "\n", "        ", "if", "minimum", "is", "not", "None", ":", "\n", "            ", "i", "=", "0", "\n", "# Add from beam until we have minimum outputs.", "\n", "while", "len", "(", "self", ".", "finished", ")", "<", "minimum", ":", "\n", "                ", "global_scores", "=", "self", ".", "global_scorer", ".", "score", "(", "self", ",", "self", ".", "scores", ")", "\n", "s", "=", "global_scores", "[", "i", "]", "\n", "self", ".", "finished", ".", "append", "(", "(", "s", ",", "len", "(", "self", ".", "next_ys", ")", "-", "1", ",", "i", ")", ")", "\n", "i", "+=", "1", "\n", "\n", "", "", "self", ".", "finished", ".", "sort", "(", "key", "=", "lambda", "a", ":", "-", "a", "[", "0", "]", ")", "\n", "scores", "=", "[", "sc", "for", "sc", ",", "_", ",", "_", "in", "self", ".", "finished", "]", "\n", "ks", "=", "[", "(", "t", ",", "k", ")", "for", "_", ",", "t", ",", "k", "in", "self", ".", "finished", "]", "\n", "return", "scores", ",", "ks", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam.Beam.get_hyp": [[186, 194], ["range", "hyp.append", "attn.append", "torch.stack", "len"], "methods", ["None"], ["", "def", "get_hyp", "(", "self", ",", "timestep", ",", "k", ")", ":", "\n", "        ", "\"\"\"Walk back to construct the full hypothesis.\"\"\"", "\n", "hyp", ",", "attn", "=", "[", "]", ",", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "self", ".", "prev_ks", "[", ":", "timestep", "]", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "hyp", ".", "append", "(", "self", ".", "next_ys", "[", "j", "+", "1", "]", "[", "k", "]", ")", "\n", "attn", ".", "append", "(", "self", ".", "attn", "[", "j", "]", "[", "k", "]", ")", "\n", "k", "=", "self", ".", "prev_ks", "[", "j", "]", "[", "k", "]", "\n", "", "return", "hyp", "[", ":", ":", "-", "1", "]", ",", "torch", ".", "stack", "(", "attn", "[", ":", ":", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam.GNMTGlobalScorer.from_opt": [[214, 221], ["cls"], "methods", ["None"], ["@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ")", ":", "\n", "        ", "return", "cls", "(", "\n", "opt", ".", "alpha", ",", "\n", "opt", ".", "beta", ",", "\n", "opt", ".", "length_penalty", ",", "\n", "opt", ".", "coverage_penalty", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam.GNMTGlobalScorer.__init__": [[222, 235], ["beam.GNMTGlobalScorer._validate", "onmt.translate.penalties.PenaltyBuilder"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam.GNMTGlobalScorer._validate"], ["", "def", "__init__", "(", "self", ",", "alpha", ",", "beta", ",", "length_penalty", ",", "coverage_penalty", ")", ":", "\n", "        ", "self", ".", "_validate", "(", "alpha", ",", "beta", ",", "length_penalty", ",", "coverage_penalty", ")", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "beta", "=", "beta", "\n", "penalty_builder", "=", "penalties", ".", "PenaltyBuilder", "(", "coverage_penalty", ",", "\n", "length_penalty", ")", "\n", "self", ".", "has_cov_pen", "=", "penalty_builder", ".", "has_cov_pen", "\n", "# Term will be subtracted from probability", "\n", "self", ".", "cov_penalty", "=", "penalty_builder", ".", "coverage_penalty", "\n", "\n", "self", ".", "has_len_pen", "=", "penalty_builder", ".", "has_len_pen", "\n", "# Probability will be divided by this", "\n", "self", ".", "length_penalty", "=", "penalty_builder", ".", "length_penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam.GNMTGlobalScorer._validate": [[236, 258], ["warnings.warn", "warnings.warn", "warnings.warn", "warnings.warn"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_validate", "(", "cls", ",", "alpha", ",", "beta", ",", "length_penalty", ",", "coverage_penalty", ")", ":", "\n", "# these warnings indicate that either the alpha/beta", "\n", "# forces a penalty to be a no-op, or a penalty is a no-op but", "\n", "# the alpha/beta would suggest otherwise.", "\n", "        ", "if", "length_penalty", "is", "None", "or", "length_penalty", "==", "\"none\"", ":", "\n", "            ", "if", "alpha", "!=", "0", ":", "\n", "                ", "warnings", ".", "warn", "(", "\"Non-default `alpha` with no length penalty. \"", "\n", "\"`alpha` has no effect.\"", ")", "\n", "", "", "else", ":", "\n", "# using some length penalty", "\n", "            ", "if", "length_penalty", "==", "\"wu\"", "and", "alpha", "==", "0.", ":", "\n", "                ", "warnings", ".", "warn", "(", "\"Using length penalty Wu with alpha==0 \"", "\n", "\"is equivalent to using length penalty none.\"", ")", "\n", "", "", "if", "coverage_penalty", "is", "None", "or", "coverage_penalty", "==", "\"none\"", ":", "\n", "            ", "if", "beta", "!=", "0", ":", "\n", "                ", "warnings", ".", "warn", "(", "\"Non-default `beta` with no coverage penalty. \"", "\n", "\"`beta` has no effect.\"", ")", "\n", "", "", "else", ":", "\n", "# using some coverage penalty", "\n", "            ", "if", "beta", "==", "0.", ":", "\n", "                ", "warnings", ".", "warn", "(", "\"Non-default coverage penalty with beta==0 \"", "\n", "\"is equivalent to using coverage penalty none.\"", ")", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam.GNMTGlobalScorer.score": [[260, 270], ["beam.GNMTGlobalScorer.length_penalty", "len", "beam.GNMTGlobalScorer.cov_penalty"], "methods", ["None"], ["", "", "", "def", "score", "(", "self", ",", "beam", ",", "logprobs", ")", ":", "\n", "        ", "\"\"\"Rescore a prediction based on penalty functions.\"\"\"", "\n", "len_pen", "=", "self", ".", "length_penalty", "(", "len", "(", "beam", ".", "next_ys", ")", ",", "self", ".", "alpha", ")", "\n", "normalized_probs", "=", "logprobs", "/", "len_pen", "\n", "if", "not", "beam", ".", "stepwise_penalty", ":", "\n", "            ", "penalty", "=", "self", ".", "cov_penalty", "(", "beam", ".", "global_state", "[", "\"coverage\"", "]", ",", "\n", "self", ".", "beta", ")", "\n", "normalized_probs", "-=", "penalty", "\n", "\n", "", "return", "normalized_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam.GNMTGlobalScorer.update_score": [[271, 278], ["beam.global_state.keys", "beam.scores.add_", "beam.GNMTGlobalScorer.cov_penalty", "beam.scores.sub_"], "methods", ["None"], ["", "def", "update_score", "(", "self", ",", "beam", ",", "attn", ")", ":", "\n", "        ", "\"\"\"Update scores of a Beam that is not finished.\"\"\"", "\n", "if", "\"prev_penalty\"", "in", "beam", ".", "global_state", ".", "keys", "(", ")", ":", "\n", "            ", "beam", ".", "scores", ".", "add_", "(", "beam", ".", "global_state", "[", "\"prev_penalty\"", "]", ")", "\n", "penalty", "=", "self", ".", "cov_penalty", "(", "beam", ".", "global_state", "[", "\"coverage\"", "]", "+", "attn", ",", "\n", "self", ".", "beta", ")", "\n", "beam", ".", "scores", ".", "sub_", "(", "penalty", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.beam.GNMTGlobalScorer.update_global_state": [[279, 294], ["len", "beam.scores.clone().fill_", "beam.attn[].sum", "torch.min().sum", "beam.global_state[].index_select().add", "beam.GNMTGlobalScorer.cov_penalty", "beam.scores.clone", "torch.min", "beam.global_state[].index_select"], "methods", ["None"], ["", "", "def", "update_global_state", "(", "self", ",", "beam", ")", ":", "\n", "        ", "\"\"\"Keeps the coverage vector as sum of attentions.\"\"\"", "\n", "if", "len", "(", "beam", ".", "prev_ks", ")", "==", "1", ":", "\n", "            ", "beam", ".", "global_state", "[", "\"prev_penalty\"", "]", "=", "beam", ".", "scores", ".", "clone", "(", ")", ".", "fill_", "(", "0.0", ")", "\n", "beam", ".", "global_state", "[", "\"coverage\"", "]", "=", "beam", ".", "attn", "[", "-", "1", "]", "\n", "self", ".", "cov_total", "=", "beam", ".", "attn", "[", "-", "1", "]", ".", "sum", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "cov_total", "+=", "torch", ".", "min", "(", "beam", ".", "attn", "[", "-", "1", "]", ",", "\n", "beam", ".", "global_state", "[", "'coverage'", "]", ")", ".", "sum", "(", "1", ")", "\n", "beam", ".", "global_state", "[", "\"coverage\"", "]", "=", "beam", ".", "global_state", "[", "\"coverage\"", "]", ".", "index_select", "(", "0", ",", "beam", ".", "prev_ks", "[", "-", "1", "]", ")", ".", "add", "(", "beam", ".", "attn", "[", "-", "1", "]", ")", "\n", "\n", "prev_penalty", "=", "self", ".", "cov_penalty", "(", "beam", ".", "global_state", "[", "\"coverage\"", "]", ",", "\n", "self", ".", "beta", ")", "\n", "beam", ".", "global_state", "[", "\"prev_penalty\"", "]", "=", "prev_penalty", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.random_sampling.RandomSampling.__init__": [[86, 103], ["onmt.translate.decode_strategy.DecodeStrategy.__init__", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "pad", ",", "bos", ",", "eos", ",", "batch_size", ",", "device", ",", "\n", "min_length", ",", "block_ngram_repeat", ",", "exclusion_tokens", ",", "\n", "return_attention", ",", "max_length", ",", "sampling_temp", ",", "keep_topk", ",", "\n", "memory_length", ")", ":", "\n", "        ", "super", "(", "RandomSampling", ",", "self", ")", ".", "__init__", "(", "\n", "pad", ",", "bos", ",", "eos", ",", "batch_size", ",", "device", ",", "1", ",", "\n", "min_length", ",", "block_ngram_repeat", ",", "exclusion_tokens", ",", "\n", "return_attention", ",", "max_length", ")", "\n", "self", ".", "sampling_temp", "=", "sampling_temp", "\n", "self", ".", "keep_topk", "=", "keep_topk", "\n", "self", ".", "topk_scores", "=", "None", "\n", "self", ".", "memory_length", "=", "memory_length", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "select_indices", "=", "torch", ".", "arange", "(", "self", ".", "batch_size", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "self", ".", "original_batch_idx", "=", "torch", ".", "arange", "(", "self", ".", "batch_size", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.random_sampling.RandomSampling.advance": [[104, 147], ["random_sampling.RandomSampling.ensure_min_length", "random_sampling.RandomSampling.block_ngram_repeats", "random_sampling.sample_with_temperature", "dec_attn.keys", "topk_ids.eq", "torch.cat", "random_sampling.RandomSampling.ensure_max_length", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.ensure_min_length", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.block_ngram_repeats", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.random_sampling.sample_with_temperature", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.ensure_max_length"], ["", "def", "advance", "(", "self", ",", "log_probs", ",", "attn", ",", "dec_out_attn", ")", ":", "\n", "        ", "\"\"\"Select next tokens randomly from the top k possible next tokens.\n\n        Args:\n            log_probs (FloatTensor): Shaped ``(batch_size, vocab_size)``.\n                These can be logits (``(-inf, inf)``) or log-probs\n                (``(-inf, 0]``). (The distribution actually uses the\n                log-probabilities ``logits - logits.logsumexp(-1)``,\n                which equals the logits if they are log-probabilities summing\n                to 1.)\n            attn (FloatTensor): Shaped ``(1, B, inp_seq_len)``.\n        \"\"\"", "\n", "\n", "\n", "self", ".", "ensure_min_length", "(", "log_probs", ")", "\n", "self", ".", "block_ngram_repeats", "(", "log_probs", ")", "\n", "topk_ids", ",", "self", ".", "topk_scores", "=", "sample_with_temperature", "(", "\n", "log_probs", ",", "self", ".", "sampling_temp", ",", "self", ".", "keep_topk", ")", "\n", "\n", "\n", "\n", "dec_out", ",", "dec_attn", "=", "dec_out_attn", "\n", "if", "self", ".", "dec_outputs", "is", "None", ":", "\n", "            ", "self", ".", "dec_outputs", "=", "dec_out", "\n", "", "else", ":", "\n", "            ", "self", ".", "dec_outputs", "=", "torch", ".", "cat", "(", "(", "self", ".", "dec_outputs", ",", "dec_out", ")", ",", "0", ")", "\n", "", "for", "key", "in", "dec_attn", ".", "keys", "(", ")", ":", "\n", "            ", "if", "key", "not", "in", "self", ".", "dec_attns", ":", "\n", "                ", "self", ".", "dec_attns", "[", "key", "]", "=", "dec_attn", "[", "key", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "dec_attns", "[", "key", "]", "=", "torch", ".", "cat", "(", "\n", "[", "self", ".", "dec_attns", "[", "key", "]", ",", "dec_attn", "[", "key", "]", "]", ")", "\n", "\n", "\n", "", "", "self", ".", "is_finished", "=", "topk_ids", ".", "eq", "(", "self", ".", "eos", ")", "\n", "\n", "self", ".", "alive_seq", "=", "torch", ".", "cat", "(", "[", "self", ".", "alive_seq", ",", "topk_ids", "]", ",", "-", "1", ")", "\n", "if", "self", ".", "return_attention", ":", "\n", "            ", "if", "self", ".", "alive_attn", "is", "None", ":", "\n", "                ", "self", ".", "alive_attn", "=", "attn", "\n", "", "else", ":", "\n", "                ", "self", ".", "alive_attn", "=", "torch", ".", "cat", "(", "[", "self", ".", "alive_attn", ",", "attn", "]", ",", "0", ")", "\n", "", "", "self", ".", "ensure_max_length", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.random_sampling.RandomSampling.update_finished": [[151, 173], ["random_sampling.RandomSampling.is_finished.view().nonzero", "random_sampling.RandomSampling.view", "random_sampling.RandomSampling.is_finished.all", "random_sampling.RandomSampling.scores[].append", "random_sampling.RandomSampling.predictions[].append", "random_sampling.RandomSampling.attention[].append", "is_alive.nonzero().view", "random_sampling.RandomSampling.is_finished.view", "random_sampling.RandomSampling.is_finished.view", "is_alive.nonzero"], "methods", ["None"], ["", "def", "update_finished", "(", "self", ",", "training", ")", ":", "\n", "        ", "\"\"\"Finalize scores and predictions.\"\"\"", "\n", "# shape: (sum(~ self.is_finished), 1)", "\n", "finished_batches", "=", "self", ".", "is_finished", ".", "view", "(", "-", "1", ")", ".", "nonzero", "(", ")", "\n", "for", "b", "in", "finished_batches", ".", "view", "(", "-", "1", ")", ":", "\n", "            ", "b_orig", "=", "self", ".", "original_batch_idx", "[", "b", "]", "\n", "self", ".", "scores", "[", "b_orig", "]", ".", "append", "(", "self", ".", "topk_scores", "[", "b", ",", "0", "]", ")", "\n", "self", ".", "predictions", "[", "b_orig", "]", ".", "append", "(", "self", ".", "alive_seq", "[", "b", ",", "1", ":", "]", ")", "\n", "self", ".", "attention", "[", "b_orig", "]", ".", "append", "(", "\n", "self", ".", "alive_attn", "[", ":", ",", "b", ",", ":", "self", ".", "memory_length", "[", "b", "]", "]", "\n", "if", "self", ".", "alive_attn", "is", "not", "None", "else", "[", "]", ")", "\n", "", "self", ".", "done", "=", "self", ".", "is_finished", ".", "all", "(", ")", "\n", "if", "self", ".", "done", ":", "\n", "            ", "return", "\n", "", "if", "not", "training", ":", "\n", "# Remove finished batches for the next step.", "\n", "            ", "is_alive", "=", "~", "self", ".", "is_finished", ".", "view", "(", "-", "1", ")", "\n", "self", ".", "alive_seq", "=", "self", ".", "alive_seq", "[", "is_alive", "]", "\n", "if", "self", ".", "alive_attn", "is", "not", "None", ":", "\n", "                ", "self", ".", "alive_attn", "=", "self", ".", "alive_attn", "[", ":", ",", "is_alive", "]", "\n", "", "self", ".", "select_indices", "=", "is_alive", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "self", ".", "original_batch_idx", "=", "self", ".", "original_batch_idx", "[", "is_alive", "]", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.random_sampling.sample_with_temperature": [[6, 57], ["logits.masked_fill.topk", "torch.div", "torch.distributions.Multinomial", "torch.argmax", "logits.masked_fill.gather", "torch.topk", "top_values[].view", "kth_best.repeat().float.repeat().float", "torch.lt", "logits.masked_fill.masked_fill", "torch.distributions.Multinomial.sample", "kth_best.repeat().float.repeat"], "function", ["None"], ["def", "sample_with_temperature", "(", "logits", ",", "sampling_temp", ",", "keep_topk", ")", ":", "\n", "    ", "\"\"\"Select next tokens randomly from the top k possible next tokens.\n\n    Samples from a categorical distribution over the ``keep_topk`` words using\n    the category probabilities ``logits / sampling_temp``.\n\n    Args:\n        logits (FloatTensor): Shaped ``(batch_size, vocab_size)``.\n            These can be logits (``(-inf, inf)``) or log-probs (``(-inf, 0]``).\n            (The distribution actually uses the log-probabilities\n            ``logits - logits.logsumexp(-1)``, which equals the logits if\n            they are log-probabilities summing to 1.)\n        sampling_temp (float): Used to scale down logits. The higher the\n            value, the more likely it is that a non-max word will be\n            sampled.\n        keep_topk (int): This many words could potentially be chosen. The\n            other logits are set to have probability 0.\n\n    Returns:\n        (LongTensor, FloatTensor):\n\n        * topk_ids: Shaped ``(batch_size, 1)``. These are\n          the sampled word indices in the output vocab.\n        * topk_scores: Shaped ``(batch_size, 1)``. These\n          are essentially ``(logits / sampling_temp)[topk_ids]``.\n    \"\"\"", "\n", "\n", "if", "sampling_temp", "==", "0.0", "or", "keep_topk", "==", "1", ":", "\n", "# For temp=0.0, take the argmax to avoid divide-by-zero errors.", "\n", "# keep_topk=1 is also equivalent to argmax.", "\n", "        ", "topk_scores", ",", "topk_ids", "=", "logits", ".", "topk", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "if", "sampling_temp", ">", "0", ":", "\n", "            ", "topk_scores", "/=", "sampling_temp", "\n", "", "", "else", ":", "\n", "        ", "logits", "=", "torch", ".", "div", "(", "logits", ",", "sampling_temp", ")", "\n", "\n", "if", "keep_topk", ">", "0", ":", "\n", "            ", "top_values", ",", "top_indices", "=", "torch", ".", "topk", "(", "logits", ",", "keep_topk", ",", "dim", "=", "1", ")", "\n", "kth_best", "=", "top_values", "[", ":", ",", "-", "1", "]", ".", "view", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "kth_best", "=", "kth_best", ".", "repeat", "(", "[", "1", ",", "logits", ".", "shape", "[", "1", "]", "]", ")", ".", "float", "(", ")", "\n", "\n", "# Set all logits that are not in the top-k to -10000.", "\n", "# This puts the probabilities close to 0.", "\n", "ignore", "=", "torch", ".", "lt", "(", "logits", ",", "kth_best", ")", "\n", "logits", "=", "logits", ".", "masked_fill", "(", "ignore", ",", "-", "10000", ")", "\n", "\n", "", "dist", "=", "torch", ".", "distributions", ".", "Multinomial", "(", "\n", "logits", "=", "logits", ",", "total_count", "=", "1", ")", "\n", "topk_ids", "=", "torch", ".", "argmax", "(", "dist", ".", "sample", "(", ")", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "topk_scores", "=", "logits", ".", "gather", "(", "dim", "=", "1", ",", "index", "=", "topk_ids", ")", "\n", "", "return", "topk_ids", ",", "topk_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.penalties.PenaltyBuilder.__init__": [[25, 30], ["penalties.PenaltyBuilder._coverage_penalty", "penalties.PenaltyBuilder._length_penalty", "penalties.PenaltyBuilder._pen_is_none", "penalties.PenaltyBuilder._pen_is_none"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.penalties.PenaltyBuilder._coverage_penalty", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.penalties.PenaltyBuilder._length_penalty", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.penalties.PenaltyBuilder._pen_is_none", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.penalties.PenaltyBuilder._pen_is_none"], ["def", "__init__", "(", "self", ",", "cov_pen", ",", "length_pen", ")", ":", "\n", "        ", "self", ".", "has_cov_pen", "=", "not", "self", ".", "_pen_is_none", "(", "cov_pen", ")", "\n", "self", ".", "coverage_penalty", "=", "self", ".", "_coverage_penalty", "(", "cov_pen", ")", "\n", "self", ".", "has_len_pen", "=", "not", "self", ".", "_pen_is_none", "(", "length_pen", ")", "\n", "self", ".", "length_penalty", "=", "self", ".", "_length_penalty", "(", "length_pen", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.penalties.PenaltyBuilder._pen_is_none": [[31, 34], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_pen_is_none", "(", "pen", ")", ":", "\n", "        ", "return", "pen", "==", "\"none\"", "or", "pen", "is", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.penalties.PenaltyBuilder._coverage_penalty": [[35, 45], ["penalties.PenaltyBuilder._pen_is_none", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.penalties.PenaltyBuilder._pen_is_none"], ["", "def", "_coverage_penalty", "(", "self", ",", "cov_pen", ")", ":", "\n", "        ", "if", "cov_pen", "==", "\"wu\"", ":", "\n", "            ", "return", "self", ".", "coverage_wu", "\n", "", "elif", "cov_pen", "==", "\"summary\"", ":", "\n", "            ", "return", "self", ".", "coverage_summary", "\n", "", "elif", "self", ".", "_pen_is_none", "(", "cov_pen", ")", ":", "\n", "            ", "return", "self", ".", "coverage_none", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"No '{:s}' coverage penalty.\"", ".", "format", "(", "\n", "cov_pen", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.penalties.PenaltyBuilder._length_penalty": [[46, 56], ["penalties.PenaltyBuilder._pen_is_none", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.penalties.PenaltyBuilder._pen_is_none"], ["", "", "def", "_length_penalty", "(", "self", ",", "length_pen", ")", ":", "\n", "        ", "if", "length_pen", "==", "\"wu\"", ":", "\n", "            ", "return", "self", ".", "length_wu", "\n", "", "elif", "length_pen", "==", "\"avg\"", ":", "\n", "            ", "return", "self", ".", "length_average", "\n", "", "elif", "self", ".", "_pen_is_none", "(", "length_pen", ")", ":", "\n", "            ", "return", "self", ".", "length_none", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"No '{:s}' length penalty.\"", ".", "format", "(", "\n", "length_pen", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.penalties.PenaltyBuilder.coverage_wu": [[61, 73], ["torch.min().log().sum", "torch.min().log", "torch.min", "cov.clone().fill_", "cov.clone"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log"], ["", "", "def", "coverage_wu", "(", "self", ",", "cov", ",", "beta", "=", "0.", ")", ":", "\n", "        ", "\"\"\"GNMT coverage re-ranking score.\n\n        See \"Google's Neural Machine Translation System\" :cite:`wu2016google`.\n        ``cov`` is expected to be sized ``(*, seq_len)``, where ``*`` is\n        probably ``batch_size x beam_size`` but could be several\n        dimensions like ``(batch_size, beam_size)``. If ``cov`` is attention,\n        then the ``seq_len`` axis probably sums to (almost) 1.\n        \"\"\"", "\n", "\n", "penalty", "=", "-", "torch", ".", "min", "(", "cov", ",", "cov", ".", "clone", "(", ")", ".", "fill_", "(", "1.0", ")", ")", ".", "log", "(", ")", ".", "sum", "(", "-", "1", ")", "\n", "return", "beta", "*", "penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.penalties.PenaltyBuilder.coverage_summary": [[74, 79], ["torch.max().sum", "cov.size", "torch.max", "cov.clone().fill_", "cov.clone"], "methods", ["None"], ["", "def", "coverage_summary", "(", "self", ",", "cov", ",", "beta", "=", "0.", ")", ":", "\n", "        ", "\"\"\"Our summary penalty.\"\"\"", "\n", "penalty", "=", "torch", ".", "max", "(", "cov", ",", "cov", ".", "clone", "(", ")", ".", "fill_", "(", "1.0", ")", ")", ".", "sum", "(", "-", "1", ")", "\n", "penalty", "-=", "cov", ".", "size", "(", "-", "1", ")", "\n", "return", "beta", "*", "penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.penalties.PenaltyBuilder.coverage_none": [[80, 87], ["torch.zeros", "cov.dim", "none.unsqueeze.unsqueeze.unsqueeze"], "methods", ["None"], ["", "def", "coverage_none", "(", "self", ",", "cov", ",", "beta", "=", "0.", ")", ":", "\n", "        ", "\"\"\"Returns zero as penalty\"\"\"", "\n", "none", "=", "torch", ".", "zeros", "(", "(", "1", ",", ")", ",", "device", "=", "cov", ".", "device", ",", "\n", "dtype", "=", "torch", ".", "float", ")", "\n", "if", "cov", ".", "dim", "(", ")", "==", "3", ":", "\n", "            ", "none", "=", "none", ".", "unsqueeze", "(", "0", ")", "\n", "", "return", "none", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.penalties.PenaltyBuilder.length_wu": [[88, 95], ["None"], "methods", ["None"], ["", "def", "length_wu", "(", "self", ",", "cur_len", ",", "alpha", "=", "0.", ")", ":", "\n", "        ", "\"\"\"GNMT length re-ranking score.\n\n        See \"Google's Neural Machine Translation System\" :cite:`wu2016google`.\n        \"\"\"", "\n", "\n", "return", "(", "(", "5", "+", "cur_len", ")", "/", "6.0", ")", "**", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.penalties.PenaltyBuilder.length_average": [[96, 99], ["None"], "methods", ["None"], ["", "def", "length_average", "(", "self", ",", "cur_len", ",", "alpha", "=", "0.", ")", ":", "\n", "        ", "\"\"\"Returns the current sequence length.\"\"\"", "\n", "return", "cur_len", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.penalties.PenaltyBuilder.length_none": [[100, 103], ["None"], "methods", ["None"], ["", "def", "length_none", "(", "self", ",", "cur_len", ",", "alpha", "=", "0.", ")", ":", "\n", "        ", "\"\"\"Returns unmodified scores.\"\"\"", "\n", "return", "1.0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.__init__": [[57, 88], ["torch.full", "torch.zeros", "range", "range", "range"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "pad", ",", "bos", ",", "eos", ",", "batch_size", ",", "device", ",", "parallel_paths", ",", "\n", "min_length", ",", "block_ngram_repeat", ",", "exclusion_tokens", ",", "\n", "return_attention", ",", "max_length", ")", ":", "\n", "\n", "# magic indices", "\n", "        ", "self", ".", "pad", "=", "pad", "\n", "self", ".", "bos", "=", "bos", "\n", "self", ".", "eos", "=", "eos", "\n", "\n", "# result caching", "\n", "self", ".", "predictions", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "self", ".", "scores", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "self", ".", "attention", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "self", ".", "alive_seq", "=", "torch", ".", "full", "(", "\n", "[", "batch_size", "*", "parallel_paths", ",", "1", "]", ",", "self", ".", "bos", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "self", ".", "is_finished", "=", "torch", ".", "zeros", "(", "\n", "[", "batch_size", ",", "parallel_paths", "]", ",", "\n", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "device", ")", "\n", "self", ".", "alive_attn", "=", "None", "\n", "self", ".", "dec_outputs", "=", "None", "\n", "self", ".", "dec_attns", "=", "{", "}", "\n", "\n", "self", ".", "min_length", "=", "min_length", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "block_ngram_repeat", "=", "block_ngram_repeat", "\n", "self", ".", "exclusion_tokens", "=", "exclusion_tokens", "\n", "self", ".", "return_attention", "=", "return_attention", "\n", "\n", "self", ".", "done", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.__len__": [[89, 91], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "alive_seq", ".", "shape", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.ensure_min_length": [[92, 95], ["len"], "methods", ["None"], ["", "def", "ensure_min_length", "(", "self", ",", "log_probs", ")", ":", "\n", "        ", "if", "len", "(", "self", ")", "<=", "self", ".", "min_length", ":", "\n", "            ", "log_probs", "[", ":", ",", "self", ".", "eos", "]", "=", "-", "1e20", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.ensure_max_length": [[96, 102], ["len", "decode_strategy.DecodeStrategy.is_finished.fill_"], "methods", ["None"], ["", "", "def", "ensure_max_length", "(", "self", ",", "max_length", "=", "None", ")", ":", "\n", "# add one to account for BOS. Don't account for EOS because hitting", "\n", "# this implies it hasn't been found.", "\n", "        ", "length", "=", "self", ".", "max_length", "if", "max_length", "is", "None", "else", "max_length", "\n", "if", "len", "(", "self", ")", "==", "length", "+", "1", ":", "\n", "            ", "self", ".", "is_finished", ".", "fill_", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.block_ngram_repeats": [[103, 123], ["len", "range", "set", "range", "set.add", "set", "tuple", "tuple", "hyp[].item"], "methods", ["None"], ["", "", "def", "block_ngram_repeats", "(", "self", ",", "log_probs", ")", ":", "\n", "        ", "cur_len", "=", "len", "(", "self", ")", "\n", "if", "self", ".", "block_ngram_repeat", ">", "0", "and", "cur_len", ">", "1", ":", "\n", "            ", "for", "path_idx", "in", "range", "(", "self", ".", "alive_seq", ".", "shape", "[", "0", "]", ")", ":", "\n", "# skip BOS", "\n", "                ", "hyp", "=", "self", ".", "alive_seq", "[", "path_idx", ",", "1", ":", "]", "\n", "ngrams", "=", "set", "(", ")", "\n", "fail", "=", "False", "\n", "gram", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "cur_len", "-", "1", ")", ":", "\n", "# Last n tokens, n = block_ngram_repeat", "\n", "                    ", "gram", "=", "(", "gram", "+", "[", "hyp", "[", "i", "]", ".", "item", "(", ")", "]", ")", "[", "-", "self", ".", "block_ngram_repeat", ":", "]", "\n", "# skip the blocking if any token in gram is excluded", "\n", "if", "set", "(", "gram", ")", "&", "self", ".", "exclusion_tokens", ":", "\n", "                        ", "continue", "\n", "", "if", "tuple", "(", "gram", ")", "in", "ngrams", ":", "\n", "                        ", "fail", "=", "True", "\n", "", "ngrams", ".", "add", "(", "tuple", "(", "gram", ")", ")", "\n", "", "if", "fail", ":", "\n", "                    ", "log_probs", "[", "path_idx", "]", "=", "-", "10e20", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.advance": [[124, 132], ["NotImplementedError"], "methods", ["None"], ["", "", "", "", "def", "advance", "(", "self", ",", "log_probs", ",", "attn", ")", ":", "\n", "        ", "\"\"\"DecodeStrategy subclasses should override :func:`advance()`.\n\n        Advance is used to update ``self.alive_seq``, ``self.is_finished``,\n        and, when appropriate, ``self.alive_attn``.\n        \"\"\"", "\n", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.decode_strategy.DecodeStrategy.update_finished": [[133, 141], ["NotImplementedError"], "methods", ["None"], ["", "def", "update_finished", "(", "self", ")", ":", "\n", "        ", "\"\"\"DecodeStrategy subclasses should override :func:`update_finished()`.\n\n        ``update_finished`` is used to update ``self.predictions``,\n        ``self.scores``, and other \"output\" attributes.\n        \"\"\"", "\n", "\n", "raise", "NotImplementedError", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.stacked_rnn.StackedLSTM.__init__": [[12, 21], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "range", "stacked_rnn.StackedLSTM.layers.append", "torch.LSTMCell", "torch.LSTMCell"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "rnn_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "StackedLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "_", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "LSTMCell", "(", "input_size", ",", "rnn_size", ")", ")", "\n", "input_size", "=", "rnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.stacked_rnn.StackedLSTM.forward": [[22, 37], ["enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "layer", "stacked_rnn.StackedLSTM.dropout"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.dropout"], ["", "", "def", "forward", "(", "self", ",", "input_feed", ",", "hidden", ")", ":", "\n", "        ", "h_0", ",", "c_0", "=", "hidden", "\n", "h_1", ",", "c_1", "=", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "h_1_i", ",", "c_1_i", "=", "layer", "(", "input_feed", ",", "(", "h_0", "[", "i", "]", ",", "c_0", "[", "i", "]", ")", ")", "\n", "input_feed", "=", "h_1_i", "\n", "if", "i", "+", "1", "!=", "self", ".", "num_layers", ":", "\n", "                ", "input_feed", "=", "self", ".", "dropout", "(", "input_feed", ")", "\n", "", "h_1", "+=", "[", "h_1_i", "]", "\n", "c_1", "+=", "[", "c_1_i", "]", "\n", "\n", "", "h_1", "=", "torch", ".", "stack", "(", "h_1", ")", "\n", "c_1", "=", "torch", ".", "stack", "(", "c_1", ")", "\n", "\n", "return", "input_feed", ",", "(", "h_1", ",", "c_1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.stacked_rnn.StackedGRU.__init__": [[45, 54], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "range", "stacked_rnn.StackedGRU.layers.append", "torch.GRUCell", "torch.GRUCell"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "rnn_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "StackedGRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "_", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "GRUCell", "(", "input_size", ",", "rnn_size", ")", ")", "\n", "input_size", "=", "rnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.stacked_rnn.StackedGRU.forward": [[55, 66], ["enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "layer", "stacked_rnn.StackedGRU.dropout"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.dropout"], ["", "", "def", "forward", "(", "self", ",", "input_feed", ",", "hidden", ")", ":", "\n", "        ", "h_1", "=", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "h_1_i", "=", "layer", "(", "input_feed", ",", "hidden", "[", "0", "]", "[", "i", "]", ")", "\n", "input_feed", "=", "h_1_i", "\n", "if", "i", "+", "1", "!=", "self", ".", "num_layers", ":", "\n", "                ", "input_feed", "=", "self", ".", "dropout", "(", "input_feed", ")", "\n", "", "h_1", "+=", "[", "h_1_i", "]", "\n", "\n", "", "h_1", "=", "torch", ".", "stack", "(", "h_1", ")", "\n", "return", "input_feed", ",", "(", "h_1", ",", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model.NMTModel.__init__": [[15, 20], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "dcn_encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", "NMTModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "dcn_encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "translator", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model.NMTModel.set_translator": [[21, 23], ["None"], "methods", ["None"], ["", "def", "set_translator", "(", "self", ",", "translator", ")", ":", "\n", "        ", "self", ".", "translator", "=", "translator", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model.NMTModel.set_examples": [[24, 27], ["None"], "methods", ["None"], ["", "def", "set_examples", "(", "self", ",", "trainset_examples", ",", "devset_examples", ")", ":", "\n", "        ", "self", ".", "trainset_examples", "=", "trainset_examples", "\n", "self", ".", "devset_examples", "=", "devset_examples", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model.NMTModel.set_vocabs": [[28, 31], ["None"], "methods", ["None"], ["", "def", "set_vocabs", "(", "self", ",", "trainset_vocabs", ",", "devset_vocabs", ")", ":", "\n", "        ", "self", ".", "trainset_vocabs", "=", "trainset_vocabs", "\n", "self", ".", "devset_vocabs", "=", "devset_vocabs", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model.NMTModel.set_drqa_model": [[32, 34], ["None"], "methods", ["None"], ["", "def", "set_drqa_model", "(", "self", ",", "drqa_model", ")", ":", "\n", "        ", "self", ".", "drqa_model", "=", "drqa_model", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model.NMTModel.reverse": [[35, 37], ["model.NMTModel.translator.reverse"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.reverse"], ["", "def", "reverse", "(", "self", ",", "translation_batch", ")", ":", "\n", "        ", "return", "self", ".", "translator", ".", "reverse", "(", "self", ".", "trainset_vocabs", ",", "self", ".", "trainset_examples", ",", "translation_batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model.NMTModel.drqa_predict": [[38, 41], ["model.NMTModel.drqa_model.predict"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.predict"], ["", "def", "drqa_predict", "(", "self", ",", "doc", ",", "que", ",", "target", ")", ":", "\n", "        ", "results", "=", "self", ".", "drqa_model", ".", "predict", "(", "doc", "=", "doc", ",", "que", "=", "que", ",", "target", "=", "target", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model.NMTModel.forward": [[42, 74], ["model.NMTModel.encoder", "model.NMTModel.decoder", "model.NMTModel.translator.translate_batch", "model.NMTModel.decoder.init_state", "model.NMTModel.train", "model.NMTModel.train"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translator.Translator.translate_batch", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoder.init_state", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer.train", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer.train"], ["", "def", "forward", "(", "self", ",", "batch", ",", "src", ",", "history", ",", "tgt", ",", "src_lengths", ",", "history_lengths", ",", "bptt", "=", "False", ")", ":", "\n", "        ", "\"\"\"Forward propagate a `src` and `tgt` pair for training.\n        Possible initialized with a beginning decoder state.\n\n        Args:\n            src (Tensor): A source sequence passed to encoder.\n                typically for inputs this will be a padded `LongTensor`\n                of size ``(len, batch, features)``. However, may be an\n                image or other generic input depending on encoder.\n            tgt (LongTensor): A target sequence of size ``(tgt_len, batch)``.\n            lengths(LongTensor): The src lengths, pre-padding ``(batch,)``.\n            bptt (Boolean): A flag indicating if truncated bptt is set.\n                If reset then init_state\n\n        Returns:\n            (FloatTensor, dict[str, FloatTensor]):\n\n            * decoder output ``(tgt_len, batch, hidden)``\n            * dictionary attention dists of ``(tgt_len, batch, src_len)``\n        \"\"\"", "\n", "tgt", "=", "tgt", "[", ":", "-", "1", "]", "# exclude last target from inputs", "\n", "\n", "enc_state", ",", "memory_bank", ",", "src_lengths", "=", "self", ".", "encoder", "(", "src", ",", "history", ",", "src_lengths", ",", "history_lengths", ")", "\n", "\n", "if", "bptt", "is", "False", ":", "\n", "            ", "self", ".", "decoder", ".", "init_state", "(", "src", ",", "memory_bank", ",", "enc_state", ")", "\n", "\n", "", "dec_out", ",", "attns", "=", "self", ".", "decoder", "(", "tgt", ",", "memory_bank", ",", "\n", "memory_lengths", "=", "src_lengths", ")", "\n", "vocabs", "=", "self", ".", "trainset_vocabs", "if", "self", ".", "train", "(", ")", "else", "self", ".", "devset_vocabs", "\n", "results", "=", "self", ".", "translator", ".", "translate_batch", "(", "batch", ",", "vocabs", ",", "False", ",", "training", "=", "self", ".", "train", "(", ")", ")", "\n", "return", "dec_out", ",", "attns", ",", "results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.CheckSRU.__init__": [[17, 19], ["configargparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "CheckSRU", ",", "self", ")", ".", "__init__", "(", "option_strings", ",", "dest", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.CheckSRU.__call__": [[20, 25], ["setattr", "sru.check_sru_requirement"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.check_sru_requirement"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "option_string", "=", "None", ")", ":", "\n", "        ", "if", "values", "==", "'SRU'", ":", "\n", "            ", "check_sru_requirement", "(", "abort", "=", "True", ")", "\n", "# Check pass, set the args.", "\n", "", "setattr", "(", "namespace", ",", "self", ".", "dest", ",", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRU_Compute.__init__": [[381, 387], ["SRU_Compute.maybe_load_sru_mod", "torch.autograd.Function.__init__"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRU_Compute.maybe_load_sru_mod", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "activation_type", ",", "d_out", ",", "bidirectional", "=", "False", ")", ":", "\n", "        ", "SRU_Compute", ".", "maybe_load_sru_mod", "(", ")", "\n", "super", "(", "SRU_Compute", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "activation_type", "=", "activation_type", "\n", "self", ".", "d_out", "=", "d_out", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRU_Compute.maybe_load_sru_mod": [[388, 394], ["sru.load_sru_mod"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.load_sru_mod"], ["", "@", "staticmethod", "\n", "def", "maybe_load_sru_mod", "(", ")", ":", "\n", "        ", "global", "SRU_FWD_FUNC", "\n", "\n", "if", "SRU_FWD_FUNC", "is", "None", ":", "\n", "            ", "load_sru_mod", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRU_Compute.forward": [[395, 439], ["x.size", "min", "x.new", "x.new", "FUNC", "sru.SRU_Compute.save_for_backward", "x.size", "u.size", "x.new().zero_", "x.dim", "x.dim", "x.dim", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "x.new", "u.contiguous().data_ptr", "bias.data_ptr", "init_.contiguous().data_ptr", "x.new.data_ptr", "x.new.data_ptr", "x.contiguous().data_ptr", "mask_h.data_ptr", "u.contiguous", "init_.contiguous", "x.contiguous"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "u", ",", "x", ",", "bias", ",", "init", "=", "None", ",", "mask_h", "=", "None", ")", ":", "\n", "        ", "bidir", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "length", "=", "x", ".", "size", "(", "0", ")", "if", "x", ".", "dim", "(", ")", "==", "3", "else", "1", "\n", "batch", "=", "x", ".", "size", "(", "-", "2", ")", "\n", "d", "=", "self", ".", "d_out", "\n", "k", "=", "u", ".", "size", "(", "-", "1", ")", "//", "d", "\n", "k_", "=", "k", "//", "2", "if", "self", ".", "bidirectional", "else", "k", "\n", "ncols", "=", "batch", "*", "d", "*", "bidir", "\n", "thread_per_block", "=", "min", "(", "512", ",", "ncols", ")", "\n", "num_block", "=", "(", "ncols", "-", "1", ")", "//", "thread_per_block", "+", "1", "\n", "\n", "init_", "=", "x", ".", "new", "(", "ncols", ")", ".", "zero_", "(", ")", "if", "init", "is", "None", "else", "init", "\n", "size", "=", "(", "length", ",", "batch", ",", "d", "*", "bidir", ")", "if", "x", ".", "dim", "(", ")", "==", "3", "else", "(", "batch", ",", "d", "*", "bidir", ")", "\n", "c", "=", "x", ".", "new", "(", "*", "size", ")", "\n", "h", "=", "x", ".", "new", "(", "*", "size", ")", "\n", "\n", "FUNC", "=", "SRU_FWD_FUNC", "if", "not", "self", ".", "bidirectional", "else", "SRU_BiFWD_FUNC", "\n", "FUNC", "(", "args", "=", "[", "\n", "u", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "x", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", "if", "k_", "==", "3", "else", "0", ",", "\n", "bias", ".", "data_ptr", "(", ")", ",", "\n", "init_", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "mask_h", ".", "data_ptr", "(", ")", "if", "mask_h", "is", "not", "None", "else", "0", ",", "\n", "length", ",", "\n", "batch", ",", "\n", "d", ",", "\n", "k_", ",", "\n", "h", ".", "data_ptr", "(", ")", ",", "\n", "c", ".", "data_ptr", "(", ")", ",", "\n", "self", ".", "activation_type", "]", ",", "\n", "block", "=", "(", "thread_per_block", ",", "1", ",", "1", ")", ",", "grid", "=", "(", "num_block", ",", "1", ",", "1", ")", ",", "\n", "stream", "=", "SRU_STREAM", "\n", ")", "\n", "\n", "self", ".", "save_for_backward", "(", "u", ",", "x", ",", "bias", ",", "init", ",", "mask_h", ")", "\n", "self", ".", "intermediate", "=", "c", "\n", "if", "x", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "last_hidden", "=", "c", "\n", "", "elif", "self", ".", "bidirectional", ":", "\n", "# -> directions x batch x dim", "\n", "            ", "last_hidden", "=", "torch", ".", "stack", "(", "(", "c", "[", "-", "1", ",", ":", ",", ":", "d", "]", ",", "c", "[", "0", ",", ":", ",", "d", ":", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "last_hidden", "=", "c", "[", "-", "1", "]", "\n", "", "return", "h", ",", "last_hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRU_Compute.backward": [[440, 491], ["x.size", "min", "u.new", "x.new", "x.new", "FUNC", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x.size", "u.size", "x.new().zero_", "x.new", "x.new.sum().view", "x.dim", "u.size", "x.new", "x.size", "u.contiguous().data_ptr", "bias.data_ptr", "init_.contiguous().data_ptr", "c.data_ptr", "grad_h.contiguous().data_ptr", "torch.cat.contiguous().data_ptr", "torch.cat.contiguous().data_ptr", "u.new.data_ptr", "x.new.data_ptr", "x.new.data_ptr", "x.new.sum", "x.contiguous().data_ptr", "mask_h.data_ptr", "grad_x.data_ptr", "u.contiguous", "init_.contiguous", "grad_h.contiguous", "torch.cat.contiguous", "torch.cat.contiguous", "x.contiguous"], "methods", ["None"], ["", "def", "backward", "(", "self", ",", "grad_h", ",", "grad_last", ")", ":", "\n", "        ", "if", "self", ".", "bidirectional", ":", "\n", "            ", "grad_last", "=", "torch", ".", "cat", "(", "(", "grad_last", "[", "0", "]", ",", "grad_last", "[", "1", "]", ")", ",", "1", ")", "\n", "", "bidir", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "u", ",", "x", ",", "bias", ",", "init", ",", "mask_h", "=", "self", ".", "saved_tensors", "\n", "c", "=", "self", ".", "intermediate", "\n", "length", "=", "x", ".", "size", "(", "0", ")", "if", "x", ".", "dim", "(", ")", "==", "3", "else", "1", "\n", "batch", "=", "x", ".", "size", "(", "-", "2", ")", "\n", "d", "=", "self", ".", "d_out", "\n", "k", "=", "u", ".", "size", "(", "-", "1", ")", "//", "d", "\n", "k_", "=", "k", "//", "2", "if", "self", ".", "bidirectional", "else", "k", "\n", "ncols", "=", "batch", "*", "d", "*", "bidir", "\n", "thread_per_block", "=", "min", "(", "512", ",", "ncols", ")", "\n", "num_block", "=", "(", "ncols", "-", "1", ")", "//", "thread_per_block", "+", "1", "\n", "\n", "init_", "=", "x", ".", "new", "(", "ncols", ")", ".", "zero_", "(", ")", "if", "init", "is", "None", "else", "init", "\n", "grad_u", "=", "u", ".", "new", "(", "*", "u", ".", "size", "(", ")", ")", "\n", "grad_bias", "=", "x", ".", "new", "(", "2", ",", "batch", ",", "d", "*", "bidir", ")", "\n", "grad_init", "=", "x", ".", "new", "(", "batch", ",", "d", "*", "bidir", ")", "\n", "\n", "# For DEBUG", "\n", "# size = (length, batch, x.size(-1)) \\", "\n", "#         if x.dim() == 3 else (batch, x.size(-1))", "\n", "# grad_x = x.new(*x.size()) if k_ == 3 else x.new(*size).zero_()", "\n", "\n", "# Normal use", "\n", "grad_x", "=", "x", ".", "new", "(", "*", "x", ".", "size", "(", ")", ")", "if", "k_", "==", "3", "else", "None", "\n", "\n", "FUNC", "=", "SRU_BWD_FUNC", "if", "not", "self", ".", "bidirectional", "else", "SRU_BiBWD_FUNC", "\n", "FUNC", "(", "args", "=", "[", "\n", "u", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "x", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", "if", "k_", "==", "3", "else", "0", ",", "\n", "bias", ".", "data_ptr", "(", ")", ",", "\n", "init_", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "mask_h", ".", "data_ptr", "(", ")", "if", "mask_h", "is", "not", "None", "else", "0", ",", "\n", "c", ".", "data_ptr", "(", ")", ",", "\n", "grad_h", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "grad_last", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "length", ",", "\n", "batch", ",", "\n", "d", ",", "\n", "k_", ",", "\n", "grad_u", ".", "data_ptr", "(", ")", ",", "\n", "grad_x", ".", "data_ptr", "(", ")", "if", "k_", "==", "3", "else", "0", ",", "\n", "grad_bias", ".", "data_ptr", "(", ")", ",", "\n", "grad_init", ".", "data_ptr", "(", ")", ",", "\n", "self", ".", "activation_type", "]", ",", "\n", "block", "=", "(", "thread_per_block", ",", "1", ",", "1", ")", ",", "grid", "=", "(", "num_block", ",", "1", ",", "1", ")", ",", "\n", "stream", "=", "SRU_STREAM", "\n", ")", "\n", "return", "grad_u", ",", "grad_x", ",", "grad_bias", ".", "sum", "(", "1", ")", ".", "view", "(", "-", "1", ")", ",", "grad_init", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRUCell.__init__": [[494, 515], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "sru.SRUCell.init_weight", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRUCell.init_weight"], ["    ", "def", "__init__", "(", "self", ",", "n_in", ",", "n_out", ",", "dropout", "=", "0", ",", "rnn_dropout", "=", "0", ",", "\n", "bidirectional", "=", "False", ",", "use_tanh", "=", "1", ",", "use_relu", "=", "0", ")", ":", "\n", "        ", "super", "(", "SRUCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_in", "=", "n_in", "\n", "self", ".", "n_out", "=", "n_out", "\n", "self", ".", "rnn_dropout", "=", "rnn_dropout", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "activation_type", "=", "2", "if", "use_relu", "else", "(", "1", "if", "use_tanh", "else", "0", ")", "\n", "\n", "out_size", "=", "n_out", "*", "2", "if", "bidirectional", "else", "n_out", "\n", "k", "=", "4", "if", "n_in", "!=", "out_size", "else", "3", "\n", "self", ".", "size_per_dir", "=", "n_out", "*", "k", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "\n", "n_in", ",", "\n", "self", ".", "size_per_dir", "*", "2", "if", "bidirectional", "else", "self", ".", "size_per_dir", "\n", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "\n", "n_out", "*", "4", "if", "bidirectional", "else", "n_out", "*", "2", "\n", ")", ")", "\n", "self", ".", "init_weight", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRUCell.init_weight": [[516, 520], ["sru.SRUCell.weight.data.uniform_", "sru.SRUCell.bias.data.zero_"], "methods", ["None"], ["", "def", "init_weight", "(", "self", ")", ":", "\n", "        ", "val_range", "=", "(", "3.0", "/", "self", ".", "n_in", ")", "**", "0.5", "\n", "self", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "val_range", ",", "val_range", ")", "\n", "self", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRUCell.set_bias": [[521, 527], ["sru.SRUCell.bias.data[].zero_().add_", "sru.SRUCell.bias.data[].zero_().add_", "sru.SRUCell.bias.data[].zero_", "sru.SRUCell.bias.data[].zero_"], "methods", ["None"], ["", "def", "set_bias", "(", "self", ",", "bias_val", "=", "0", ")", ":", "\n", "        ", "n_out", "=", "self", ".", "n_out", "\n", "if", "self", ".", "bidirectional", ":", "\n", "            ", "self", ".", "bias", ".", "data", "[", "n_out", "*", "2", ":", "]", ".", "zero_", "(", ")", ".", "add_", "(", "bias_val", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", ".", "data", "[", "n_out", ":", "]", ".", "zero_", "(", ")", ".", "add_", "(", "bias_val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRUCell.forward": [[528, 561], ["input.size", "x_2d.mm", "input.data.new().zero_", "sru.SRUCell.get_dropout_mask_", "x.contiguous().view", "sru.SRUCell.get_dropout_mask_", "input.dim", "input.dim", "sru.SRUCell.expand_as", "x.dim", "sru.SRU_Compute", "sru.SRU_Compute", "input.data.new", "x.contiguous"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRUCell.get_dropout_mask_", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRUCell.get_dropout_mask_"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "c0", "=", "None", ")", ":", "\n", "        ", "assert", "input", ".", "dim", "(", ")", "==", "2", "or", "input", ".", "dim", "(", ")", "==", "3", "\n", "n_in", ",", "n_out", "=", "self", ".", "n_in", ",", "self", ".", "n_out", "\n", "batch", "=", "input", ".", "size", "(", "-", "2", ")", "\n", "if", "c0", "is", "None", ":", "\n", "            ", "c0", "=", "input", ".", "data", ".", "new", "(", "\n", "batch", ",", "n_out", "if", "not", "self", ".", "bidirectional", "else", "n_out", "*", "2", "\n", ")", ".", "zero_", "(", ")", "\n", "\n", "", "if", "self", ".", "training", "and", "(", "self", ".", "rnn_dropout", ">", "0", ")", ":", "\n", "            ", "mask", "=", "self", ".", "get_dropout_mask_", "(", "(", "batch", ",", "n_in", ")", ",", "self", ".", "rnn_dropout", ")", "\n", "x", "=", "input", "*", "mask", ".", "expand_as", "(", "input", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "input", "\n", "\n", "", "x_2d", "=", "x", "if", "x", ".", "dim", "(", ")", "==", "2", "else", "x", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "n_in", ")", "\n", "u", "=", "x_2d", ".", "mm", "(", "self", ".", "weight", ")", "\n", "\n", "if", "self", ".", "training", "and", "(", "self", ".", "dropout", ">", "0", ")", ":", "\n", "            ", "bidir", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "mask_h", "=", "self", ".", "get_dropout_mask_", "(", "\n", "(", "batch", ",", "n_out", "*", "bidir", ")", ",", "self", ".", "dropout", ")", "\n", "h", ",", "c", "=", "SRU_Compute", "(", "self", ".", "activation_type", ",", "n_out", ",", "\n", "self", ".", "bidirectional", ")", "(", "\n", "u", ",", "input", ",", "self", ".", "bias", ",", "c0", ",", "mask_h", "\n", ")", "\n", "", "else", ":", "\n", "            ", "h", ",", "c", "=", "SRU_Compute", "(", "self", ".", "activation_type", ",", "n_out", ",", "\n", "self", ".", "bidirectional", ")", "(", "\n", "u", ",", "input", ",", "self", ".", "bias", ",", "c0", "\n", ")", "\n", "\n", "", "return", "h", ",", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRUCell.get_dropout_mask_": [[562, 565], ["w.new().bernoulli_().div_", "w.new().bernoulli_", "w.new"], "methods", ["None"], ["", "def", "get_dropout_mask_", "(", "self", ",", "size", ",", "p", ")", ":", "\n", "        ", "w", "=", "self", ".", "weight", ".", "data", "\n", "return", "w", ".", "new", "(", "*", "size", ")", ".", "bernoulli_", "(", "1", "-", "p", ")", ".", "div_", "(", "1", "-", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRU.__init__": [[588, 615], ["sru.check_sru_requirement", "torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "range", "sru.SRUCell", "sru.SRU.rnn_lst.append"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.check_sru_requirement", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "\n", "num_layers", "=", "2", ",", "dropout", "=", "0", ",", "rnn_dropout", "=", "0", ",", "\n", "bidirectional", "=", "False", ",", "use_tanh", "=", "1", ",", "use_relu", "=", "0", ")", ":", "\n", "# An entry check here, will catch on train side and translate side", "\n", "# if requirements are not satisfied.", "\n", "        ", "check_sru_requirement", "(", "abort", "=", "True", ")", "\n", "super", "(", "SRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_in", "=", "input_size", "\n", "self", ".", "n_out", "=", "hidden_size", "\n", "self", ".", "depth", "=", "num_layers", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "rnn_dropout", "=", "rnn_dropout", "\n", "self", ".", "rnn_lst", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "out_size", "=", "hidden_size", "*", "2", "if", "bidirectional", "else", "hidden_size", "\n", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "sru_cell", "=", "SRUCell", "(", "\n", "n_in", "=", "self", ".", "n_in", "if", "i", "==", "0", "else", "self", ".", "out_size", ",", "\n", "n_out", "=", "self", ".", "n_out", ",", "\n", "dropout", "=", "dropout", "if", "i", "+", "1", "!=", "num_layers", "else", "0", ",", "\n", "rnn_dropout", "=", "rnn_dropout", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", "use_tanh", "=", "use_tanh", ",", "\n", "use_relu", "=", "use_relu", ",", "\n", ")", "\n", "self", ".", "rnn_lst", ".", "append", "(", "sru_cell", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRU.set_bias": [[616, 619], ["l.set_bias"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRU.set_bias"], ["", "", "def", "set_bias", "(", "self", ",", "bias_val", "=", "0", ")", ":", "\n", "        ", "for", "l", "in", "self", ".", "rnn_lst", ":", "\n", "            ", "l", ".", "set_bias", "(", "bias_val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.SRU.forward": [[620, 652], ["enumerate", "input.dim", "input.data.new().zero_", "isinstance", "rnn", "lstc.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "c0.dim", "h.squeeze", "input.data.new", "range", "c0.chunk", "input.size"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "c0", "=", "None", ",", "return_hidden", "=", "True", ")", ":", "\n", "        ", "assert", "input", ".", "dim", "(", ")", "==", "3", "# (len, batch, n_in)", "\n", "dir_", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "if", "c0", "is", "None", ":", "\n", "            ", "zeros", "=", "input", ".", "data", ".", "new", "(", "\n", "input", ".", "size", "(", "1", ")", ",", "self", ".", "n_out", "*", "dir_", "\n", ")", ".", "zero_", "(", ")", "\n", "c0", "=", "[", "zeros", "for", "i", "in", "range", "(", "self", ".", "depth", ")", "]", "\n", "", "else", ":", "\n", "            ", "if", "isinstance", "(", "c0", ",", "tuple", ")", ":", "\n", "# RNNDecoderState wraps hidden as a tuple.", "\n", "                ", "c0", "=", "c0", "[", "0", "]", "\n", "", "assert", "c0", ".", "dim", "(", ")", "==", "3", "# (depth, batch, dir_*n_out)", "\n", "c0", "=", "[", "h", ".", "squeeze", "(", "0", ")", "for", "h", "in", "c0", ".", "chunk", "(", "self", ".", "depth", ",", "0", ")", "]", "\n", "\n", "", "prevx", "=", "input", "\n", "lstc", "=", "[", "]", "\n", "for", "i", ",", "rnn", "in", "enumerate", "(", "self", ".", "rnn_lst", ")", ":", "\n", "            ", "h", ",", "c", "=", "rnn", "(", "prevx", ",", "c0", "[", "i", "]", ")", "\n", "prevx", "=", "h", "\n", "lstc", ".", "append", "(", "c", ")", "\n", "\n", "", "if", "self", ".", "bidirectional", ":", "\n", "# fh -> (layers*directions) x batch x dim", "\n", "            ", "fh", "=", "torch", ".", "cat", "(", "lstc", ")", "\n", "", "else", ":", "\n", "            ", "fh", "=", "torch", ".", "stack", "(", "lstc", ")", "\n", "\n", "", "if", "return_hidden", ":", "\n", "            ", "return", "prevx", ",", "fh", "\n", "", "else", ":", "\n", "            ", "return", "prevx", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.check_sru_requirement": [[32, 70], ["re.compile", "os.getenv", "torch.cuda.is_available", "torch.cuda.is_available", "AssertionError", "re.match", "AssertionError", "platform.system", "subprocess.check_output", "subprocess.check_output", "subprocess.check_output", "subprocess.check_output", "AssertionError"], "function", ["None"], ["", "", "def", "check_sru_requirement", "(", "abort", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Return True if check pass; if check fails and abort is True,\n    raise an Exception, othereise return False.\n    \"\"\"", "\n", "\n", "# Check 1.", "\n", "try", ":", "\n", "        ", "if", "platform", ".", "system", "(", ")", "==", "'Windows'", ":", "\n", "            ", "subprocess", ".", "check_output", "(", "'pip freeze | findstr cupy'", ",", "shell", "=", "True", ")", "\n", "subprocess", ".", "check_output", "(", "'pip freeze | findstr pynvrtc'", ",", "\n", "shell", "=", "True", ")", "\n", "", "else", ":", "# Unix-like systems", "\n", "            ", "subprocess", ".", "check_output", "(", "'pip freeze | grep -w cupy'", ",", "shell", "=", "True", ")", "\n", "subprocess", ".", "check_output", "(", "'pip freeze | grep -w pynvrtc'", ",", "\n", "shell", "=", "True", ")", "\n", "", "", "except", "subprocess", ".", "CalledProcessError", ":", "\n", "        ", "if", "not", "abort", ":", "\n", "            ", "return", "False", "\n", "", "raise", "AssertionError", "(", "\"Using SRU requires 'cupy' and 'pynvrtc' \"", "\n", "\"python packages installed.\"", ")", "\n", "\n", "# Check 2.", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "is", "False", ":", "\n", "        ", "if", "not", "abort", ":", "\n", "            ", "return", "False", "\n", "", "raise", "AssertionError", "(", "\"Using SRU requires pytorch built with cuda.\"", ")", "\n", "\n", "# Check 3.", "\n", "", "pattern", "=", "re", ".", "compile", "(", "\".*cuda/lib.*\"", ")", "\n", "ld_path", "=", "os", ".", "getenv", "(", "'LD_LIBRARY_PATH'", ",", "\"\"", ")", "\n", "if", "re", ".", "match", "(", "pattern", ",", "ld_path", ")", "is", "None", ":", "\n", "        ", "if", "not", "abort", ":", "\n", "            ", "return", "False", "\n", "", "raise", "AssertionError", "(", "\"Using SRU requires setting cuda lib path, e.g. \"", "\n", "\"export LD_LIBRARY_PATH=/usr/local/cuda/lib64.\"", ")", "\n", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.load_sru_mod": [[353, 377], ["sru.check_sru_requirement", "torch.device", "torch.device", "torch.rand().to", "torch.rand().to", "Program", "Program.compile", "function.Module", "function.Module.load", "function.Module.get_function", "function.Module.get_function", "function.Module.get_function", "function.Module.get_function", "collections.namedtuple", "collections.namedtuple.", "SRU_CODE.encode", "bytes", "torch.rand", "torch.rand", "sru_prog.compile.encode", "torch.cuda.current_stream", "torch.cuda.current_stream"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.models.sru.check_sru_requirement", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.encode", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.encode"], ["def", "load_sru_mod", "(", ")", ":", "\n", "    ", "global", "SRU_FWD_FUNC", ",", "SRU_BWD_FUNC", ",", "SRU_BiFWD_FUNC", ",", "SRU_BiBWD_FUNC", "\n", "global", "SRU_STREAM", "\n", "if", "check_sru_requirement", "(", ")", ":", "\n", "        ", "from", "cupy", ".", "cuda", "import", "function", "\n", "from", "pynvrtc", ".", "compiler", "import", "Program", "\n", "\n", "# This sets up device to use.", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "tmp_", "=", "torch", ".", "rand", "(", "1", ",", "1", ")", ".", "to", "(", "device", ")", "\n", "\n", "sru_prog", "=", "Program", "(", "SRU_CODE", ".", "encode", "(", "'utf-8'", ")", ",", "\n", "'sru_prog.cu'", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "sru_ptx", "=", "sru_prog", ".", "compile", "(", ")", "\n", "sru_mod", "=", "function", ".", "Module", "(", ")", "\n", "sru_mod", ".", "load", "(", "bytes", "(", "sru_ptx", ".", "encode", "(", ")", ")", ")", "\n", "\n", "SRU_FWD_FUNC", "=", "sru_mod", ".", "get_function", "(", "'sru_fwd'", ")", "\n", "SRU_BWD_FUNC", "=", "sru_mod", ".", "get_function", "(", "'sru_bwd'", ")", "\n", "SRU_BiFWD_FUNC", "=", "sru_mod", ".", "get_function", "(", "'sru_bi_fwd'", ")", "\n", "SRU_BiBWD_FUNC", "=", "sru_mod", ".", "get_function", "(", "'sru_bi_bwd'", ")", "\n", "\n", "stream", "=", "namedtuple", "(", "'Stream'", ",", "[", "'ptr'", "]", ")", "\n", "SRU_STREAM", "=", "stream", "(", "ptr", "=", "torch", ".", "cuda", ".", "current_stream", "(", ")", ".", "cuda_stream", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.ModelSaverBase.__init__": [[29, 40], ["collections.deque"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "base_path", ",", "model", ",", "model_opt", ",", "fields", ",", "optim", ",", "\n", "keep_checkpoint", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "base_path", "=", "base_path", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model_opt", "=", "model_opt", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "optim", "=", "optim", "\n", "self", ".", "last_saved_step", "=", "None", "\n", "self", ".", "keep_checkpoint", "=", "keep_checkpoint", "\n", "if", "keep_checkpoint", ">", "0", ":", "\n", "            ", "self", ".", "checkpoint_queue", "=", "deque", "(", "[", "]", ",", "maxlen", "=", "keep_checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.ModelSaverBase.save": [[41, 69], ["model_saver.ModelSaverBase._save", "copy.deepcopy", "zip", "model_saver.ModelSaverBase.checkpoint_queue.append", "copy.deepcopy.parameters", "param.data.copy_", "len", "model_saver.ModelSaverBase.checkpoint_queue.popleft", "model_saver.ModelSaverBase._rm_checkpoint"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.ModelSaver._save", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.ModelSaver._rm_checkpoint"], ["", "", "def", "save", "(", "self", ",", "step", ",", "moving_average", "=", "None", ")", ":", "\n", "        ", "\"\"\"Main entry point for model saver\n\n        It wraps the `_save` method with checks and apply `keep_checkpoint`\n        related logic\n        \"\"\"", "\n", "\n", "if", "self", ".", "keep_checkpoint", "==", "0", "or", "step", "==", "self", ".", "last_saved_step", ":", "\n", "            ", "return", "\n", "\n", "", "if", "moving_average", ":", "\n", "            ", "save_model", "=", "deepcopy", "(", "self", ".", "model", ")", "\n", "for", "avg", ",", "param", "in", "zip", "(", "moving_average", ",", "save_model", ".", "parameters", "(", ")", ")", ":", "\n", "                ", "param", ".", "data", ".", "copy_", "(", "avg", ".", "data", ")", "\n", "", "", "else", ":", "\n", "            ", "save_model", "=", "self", ".", "model", "\n", "\n", "", "chkpt", ",", "chkpt_name", "=", "self", ".", "_save", "(", "step", ",", "save_model", ")", "\n", "self", ".", "last_saved_step", "=", "step", "\n", "\n", "if", "moving_average", ":", "\n", "            ", "del", "save_model", "\n", "\n", "", "if", "self", ".", "keep_checkpoint", ">", "0", ":", "\n", "            ", "if", "len", "(", "self", ".", "checkpoint_queue", ")", "==", "self", ".", "checkpoint_queue", ".", "maxlen", ":", "\n", "                ", "todel", "=", "self", ".", "checkpoint_queue", ".", "popleft", "(", ")", "\n", "self", ".", "_rm_checkpoint", "(", "todel", ")", "\n", "", "self", ".", "checkpoint_queue", ".", "append", "(", "chkpt_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.ModelSaverBase._save": [[70, 84], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "_save", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"Save a resumable checkpoint.\n\n        Args:\n            step (int): step number\n\n        Returns:\n            (object, str):\n\n            * checkpoint: the saved object\n            * checkpoint_name: name (or path) of the saved checkpoint\n        \"\"\"", "\n", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.ModelSaverBase._rm_checkpoint": [[85, 94], ["NotImplementedError"], "methods", ["None"], ["", "def", "_rm_checkpoint", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"Remove a checkpoint\n\n        Args:\n            name(str): name that indentifies the checkpoint\n                (it may be a filepath)\n        \"\"\"", "\n", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.ModelSaver._save": [[99, 123], ["real_model.state_dict", "real_generator.state_dict", "onmt.utils.logging.logger.info", "torch.save", "torch.save", "torch.save", "torch.save", "isinstance", "isinstance", "model_saver.ModelSaver.optim.state_dict", "real_model.state_dict.items"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.state_dict", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.state_dict", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.state_dict"], ["def", "_save", "(", "self", ",", "step", ",", "model", ")", ":", "\n", "        ", "real_model", "=", "(", "model", ".", "module", "\n", "if", "isinstance", "(", "model", ",", "nn", ".", "DataParallel", ")", "\n", "else", "model", ")", "\n", "real_generator", "=", "(", "real_model", ".", "generator", ".", "module", "\n", "if", "isinstance", "(", "real_model", ".", "generator", ",", "nn", ".", "DataParallel", ")", "\n", "else", "real_model", ".", "generator", ")", "\n", "\n", "model_state_dict", "=", "real_model", ".", "state_dict", "(", ")", "\n", "model_state_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "model_state_dict", ".", "items", "(", ")", "\n", "if", "'generator'", "not", "in", "k", "}", "\n", "generator_state_dict", "=", "real_generator", ".", "state_dict", "(", ")", "\n", "checkpoint", "=", "{", "\n", "'model'", ":", "model_state_dict", ",", "\n", "'generator'", ":", "generator_state_dict", ",", "\n", "'vocab'", ":", "self", ".", "fields", ",", "\n", "'opt'", ":", "self", ".", "model_opt", ",", "\n", "'optim'", ":", "self", ".", "optim", ".", "state_dict", "(", ")", ",", "\n", "}", "\n", "\n", "logger", ".", "info", "(", "\"Saving checkpoint %s_step_%d.pt\"", "%", "(", "self", ".", "base_path", ",", "step", ")", ")", "\n", "checkpoint_path", "=", "'%s_step_%d.pt'", "%", "(", "self", ".", "base_path", ",", "step", ")", "\n", "torch", ".", "save", "(", "checkpoint", ",", "checkpoint_path", ")", "\n", "return", "checkpoint", ",", "checkpoint_path", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.ModelSaver._rm_checkpoint": [[124, 126], ["os.remove"], "methods", ["None"], ["", "def", "_rm_checkpoint", "(", "self", ",", "name", ")", ":", "\n", "        ", "os", ".", "remove", "(", "name", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.build_model_saver": [[11, 19], ["model_saver.ModelSaver"], "function", ["None"], ["def", "build_model_saver", "(", "model_opt", ",", "opt", ",", "model", ",", "fields", ",", "optim", ")", ":", "\n", "    ", "model_saver", "=", "ModelSaver", "(", "opt", ".", "save_model", ",", "\n", "model", ",", "\n", "model_opt", ",", "\n", "fields", ",", "\n", "optim", ",", "\n", "opt", ".", "keep_checkpoint", ")", "\n", "return", "model_saver", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.encoder.EncoderBase.from_opt": [[33, 36], ["None"], "methods", ["None"], ["@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ",", "embeddings", "=", "None", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.encoder.EncoderBase._check_args": [[37, 42], ["src.size", "lengths.size", "onmt.utils.misc.aeq"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.aeq"], ["", "def", "_check_args", "(", "self", ",", "src", ",", "lengths", "=", "None", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "_", ",", "n_batch", ",", "_", "=", "src", ".", "size", "(", ")", "\n", "if", "lengths", "is", "not", "None", ":", "\n", "            ", "n_batch_", ",", "=", "lengths", ".", "size", "(", ")", "\n", "aeq", "(", "n_batch", ",", "n_batch_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.encoder.EncoderBase.forward": [[43, 59], ["None"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            src (LongTensor):\n               padded sequences of sparse indices ``(src_len, batch, nfeat)``\n            lengths (LongTensor): length of each sequence ``(batch,)``\n\n\n        Returns:\n            (FloatTensor, FloatTensor):\n\n            * final encoder state, used to initialize decoder\n            * memory bank for attention, ``(src_len, batch, hidden)``\n        \"\"\"", "\n", "\n", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.rnn_encoder.RNNEncoder.__init__": [[26, 51], ["onmt.encoders.encoder.EncoderBase.__init__", "onmt.utils.rnn_factory.rnn_factory", "rnn_encoder.RNNEncoder._initialize_bridge"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.rnn_factory.rnn_factory", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.rnn_encoder.RNNEncoder._initialize_bridge"], ["def", "__init__", "(", "self", ",", "rnn_type", ",", "bidirectional", ",", "num_layers", ",", "\n", "hidden_size", ",", "dropout", "=", "0.0", ",", "embeddings", "=", "None", ",", "\n", "use_bridge", "=", "False", ")", ":", "\n", "        ", "super", "(", "RNNEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "embeddings", "is", "not", "None", "\n", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "assert", "hidden_size", "%", "num_directions", "==", "0", "\n", "hidden_size", "=", "hidden_size", "//", "num_directions", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "num_directions", "=", "num_directions", "\n", "\n", "self", ".", "rnn", ",", "self", ".", "no_pack_padded_seq", "=", "rnn_factory", "(", "rnn_type", ",", "\n", "input_size", "=", "embeddings", ".", "embedding_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bidirectional", "=", "bidirectional", ")", "\n", "\n", "# Initialize the bridge layer", "\n", "self", ".", "use_bridge", "=", "use_bridge", "\n", "if", "self", ".", "use_bridge", ":", "\n", "            ", "self", ".", "_initialize_bridge", "(", "rnn_type", ",", "\n", "hidden_size", ",", "\n", "num_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.rnn_encoder.RNNEncoder.from_opt": [[52, 63], ["cls"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ",", "embeddings", ")", ":", "\n", "        ", "\"\"\"Alternate constructor.\"\"\"", "\n", "return", "cls", "(", "\n", "opt", ".", "rnn_type", ",", "\n", "opt", ".", "brnn", ",", "\n", "opt", ".", "enc_layers", ",", "\n", "opt", ".", "enc_rnn_size", ",", "\n", "opt", ".", "dropout", ",", "\n", "embeddings", ",", "\n", "opt", ".", "bridge", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.rnn_encoder.RNNEncoder.forward": [[64, 106], ["rnn_encoder.RNNEncoder._check_args", "rnn_encoder.RNNEncoder.embeddings", "rnn_encoder.RNNEncoder.rnn", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "list", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "rnn_encoder.RNNEncoder.rnn", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "output.index_select.index_select.index_select", "hidden.index_select.index_select.index_select", "rnn_encoder.RNNEncoder._bridge", "lengths.view().tolist", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "lengths.view"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.encoder.EncoderBase._check_args", "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.rnn_encoder.RNNEncoder._bridge"], ["", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ",", "resort", "=", "False", ")", ":", "\n", "        ", "\"\"\"See :func:`EncoderBase.forward()`\"\"\"", "\n", "self", ".", "_check_args", "(", "src", ",", "lengths", ")", "\n", "\n", "emb", "=", "self", ".", "embeddings", "(", "src", ")", "\n", "# s_len, batch, emb_dim = emb.size()", "\n", "\n", "if", "not", "resort", ":", "\n", "            ", "packed_emb", "=", "emb", "\n", "if", "lengths", "is", "not", "None", "and", "not", "self", ".", "no_pack_padded_seq", ":", "\n", "# Lengths data is wrapped inside a Tensor.", "\n", "                ", "lengths_list", "=", "lengths", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "packed_emb", "=", "pack", "(", "emb", ",", "lengths_list", ")", "\n", "\n", "", "memory_bank", ",", "encoder_final", "=", "self", ".", "rnn", "(", "packed_emb", ")", "\n", "if", "lengths", "is", "not", "None", "and", "not", "self", ".", "no_pack_padded_seq", ":", "\n", "                ", "memory_bank", "=", "unpack", "(", "memory_bank", ")", "[", "0", "]", "\n", "\n", "", "", "else", ":", "\n", "\n", "            ", "_", ",", "idx_sort", "=", "torch", ".", "sort", "(", "lengths", ",", "dim", "=", "0", ",", "descending", "=", "True", ")", "\n", "_", ",", "idx_unsort", "=", "torch", ".", "sort", "(", "idx_sort", ",", "dim", "=", "0", ")", "\n", "\n", "input_lengths", "=", "list", "(", "lengths", "[", "idx_sort", "]", ")", "\n", "\n", "embedded", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "emb", ",", "input_lengths", ",", "batch_first", "=", "False", ")", "\n", "\n", "# if self.num_directions == 1:", "\n", "#     output, hidden = self.rnn(embedded)", "\n", "# else:", "\n", "output", ",", "(", "hidden", ",", "_", ")", "=", "self", ".", "rnn", "(", "embedded", ")", "\n", "\n", "output", ",", "_", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "output", ",", "batch_first", "=", "False", ")", "\n", "\n", "output", "=", "output", ".", "index_select", "(", "1", ",", "idx_unsort", ")", "\n", "hidden", "=", "hidden", ".", "index_select", "(", "1", ",", "idx_unsort", ")", "\n", "memory_bank", "=", "output", "\n", "encoder_final", "=", "hidden", "\n", "\n", "", "if", "self", ".", "use_bridge", ":", "\n", "            ", "encoder_final", "=", "self", ".", "_bridge", "(", "encoder_final", ")", "\n", "", "return", "encoder_final", ",", "memory_bank", ",", "lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.rnn_encoder.RNNEncoder._initialize_bridge": [[107, 121], ["torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "torch.Linear", "range"], "methods", ["None"], ["", "def", "_initialize_bridge", "(", "self", ",", "rnn_type", ",", "\n", "hidden_size", ",", "\n", "num_layers", ")", ":", "\n", "\n", "# LSTM has hidden and cell state, other only one", "\n", "        ", "number_of_states", "=", "2", "if", "rnn_type", "==", "\"LSTM\"", "else", "1", "\n", "# Total number of states", "\n", "self", ".", "total_hidden_dim", "=", "hidden_size", "*", "num_layers", "\n", "\n", "# Build a linear layer for each", "\n", "self", ".", "bridge", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Linear", "(", "self", ".", "total_hidden_dim", ",", "\n", "self", ".", "total_hidden_dim", ",", "\n", "bias", "=", "True", ")", "\n", "for", "_", "in", "range", "(", "number_of_states", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.rnn_encoder.RNNEncoder._bridge": [[122, 138], ["isinstance", "states.size", "linear", "torch.relu().view", "torch.relu().view", "torch.relu().view", "tuple", "rnn_encoder.RNNEncoder._bridge.bottle_hidden"], "methods", ["None"], ["", "def", "_bridge", "(", "self", ",", "hidden", ")", ":", "\n", "        ", "\"\"\"Forward hidden state through bridge.\"\"\"", "\n", "def", "bottle_hidden", "(", "linear", ",", "states", ")", ":", "\n", "            ", "\"\"\"\n            Transform from 3D to 2D, apply linear and return initial size\n            \"\"\"", "\n", "size", "=", "states", ".", "size", "(", ")", "\n", "result", "=", "linear", "(", "states", ".", "view", "(", "-", "1", ",", "self", ".", "total_hidden_dim", ")", ")", "\n", "return", "F", ".", "relu", "(", "result", ")", ".", "view", "(", "size", ")", "\n", "\n", "", "if", "isinstance", "(", "hidden", ",", "tuple", ")", ":", "# LSTM", "\n", "            ", "outs", "=", "tuple", "(", "[", "bottle_hidden", "(", "layer", ",", "hidden", "[", "ix", "]", ")", "\n", "for", "ix", ",", "layer", "in", "enumerate", "(", "self", ".", "bridge", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "outs", "=", "bottle_hidden", "(", "self", ".", "bridge", "[", "0", "]", ",", "hidden", ")", "\n", "", "return", "outs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.BaseRNN.__init__": [[14, 30], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "rnn_cell.lower", "rnn_cell.lower", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "max_len", ",", "hidden_size", ",", "input_dropout_p", ",", "dropout_p", ",", "n_layers", ",", "rnn_cell", ")", ":", "\n", "        ", "super", "(", "BaseRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "max_len", "=", "max_len", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "input_dropout_p", "=", "input_dropout_p", "\n", "self", ".", "input_dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "input_dropout_p", ")", "\n", "if", "rnn_cell", ".", "lower", "(", ")", "==", "'lstm'", ":", "\n", "            ", "self", ".", "rnn_cell", "=", "nn", ".", "LSTM", "\n", "", "elif", "rnn_cell", ".", "lower", "(", ")", "==", "'gru'", ":", "\n", "            ", "self", ".", "rnn_cell", "=", "nn", ".", "GRU", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unsupported RNN Cell: {0}\"", ".", "format", "(", "rnn_cell", ")", ")", "\n", "\n", "", "self", ".", "dropout_p", "=", "dropout_p", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.BaseRNN.forward": [[31, 33], ["NotImplementedError"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.EncoderRNN.__init__": [[36, 45], ["redr_encoder.BaseRNN.__init__", "redr_encoder.EncoderRNN.rnn_cell"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "max_len", ",", "hidden_size", ",", "\n", "input_dropout_p", "=", "0", ",", "dropout_p", "=", "0", ",", "\n", "n_layers", "=", "1", ",", "bidirectional", "=", "False", ",", "rnn_cell", "=", "'gru'", ",", "\n", "embedding", "=", "None", ",", "update_embedding", "=", "True", ")", ":", "\n", "        ", "super", "(", "EncoderRNN", ",", "self", ")", ".", "__init__", "(", "input_size", ",", "max_len", ",", "hidden_size", ",", "\n", "input_dropout_p", ",", "dropout_p", ",", "n_layers", ",", "rnn_cell", ")", "\n", "\n", "self", ".", "rnn", "=", "self", ".", "rnn_cell", "(", "input_size", ",", "hidden_size", ",", "n_layers", ",", "\n", "batch_first", "=", "True", ",", "bidirectional", "=", "bidirectional", ",", "dropout", "=", "dropout_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.EncoderRNN.forward": [[46, 68], ["redr_encoder.EncoderRNN.rnn", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "list", "redr_encoder.EncoderRNN.input_dropout", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "output.index_select.index_select.index_select", "hidden.index_select.index_select.index_select", "redr_encoder.EncoderRNN.rnn", "redr_encoder.EncoderRNN.rnn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "embedded", ",", "input_lengths", "=", "None", ")", ":", "\n", "        ", "if", "input_lengths", "is", "None", ":", "\n", "            ", "output", ",", "hidden", "=", "self", ".", "rnn", "(", "embedded", ")", "\n", "", "else", ":", "\n", "            ", "_", ",", "idx_sort", "=", "torch", ".", "sort", "(", "input_lengths", ",", "dim", "=", "0", ",", "descending", "=", "True", ")", "\n", "_", ",", "idx_unsort", "=", "torch", ".", "sort", "(", "idx_sort", ",", "dim", "=", "0", ")", "\n", "\n", "input_lengths", "=", "list", "(", "input_lengths", "[", "idx_sort", "]", ")", "\n", "\n", "embedded", "=", "self", ".", "input_dropout", "(", "embedded", ")", "\n", "embedded", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "embedded", ",", "input_lengths", ",", "batch_first", "=", "True", ")", "\n", "\n", "if", "not", "self", ".", "_bidirectional", ":", "\n", "                ", "output", ",", "hidden", "=", "self", ".", "rnn", "(", "embedded", ")", "\n", "", "else", ":", "\n", "                ", "output", ",", "(", "hidden", ",", "_", ")", "=", "self", ".", "rnn", "(", "embedded", ")", "\n", "\n", "", "output", ",", "_", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "output", ",", "batch_first", "=", "True", ")", "\n", "\n", "output", "=", "output", ".", "index_select", "(", "0", ",", "idx_unsort", ")", "\n", "hidden", "=", "hidden", ".", "index_select", "(", "1", ",", "idx_unsort", ")", "\n", "", "return", "output", ",", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDRLayer.__init__": [[72, 88], ["torch.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "redr_encoder.EncoderRNN", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "rnn_type", ",", "max_len", "=", "5000", ",", "num_layers", "=", "1", ",", "n_memory_layers", "=", "3", ")", ":", "\n", "        ", "super", "(", "ReDRLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_w_u", "=", "Parameter", "(", "torch", ".", "randn", "(", "hidden_size", ",", "1", ",", "requires_grad", "=", "True", ")", ")", "\n", "self", ".", "_w_c", "=", "Parameter", "(", "torch", ".", "randn", "(", "2", "*", "hidden_size", ",", "1", ",", "requires_grad", "=", "True", ")", ")", "\n", "self", ".", "_w_r", "=", "Parameter", "(", "torch", ".", "randn", "(", "hidden_size", ",", "1", ",", "requires_grad", "=", "True", ")", ")", "\n", "self", ".", "_b", "=", "Parameter", "(", "torch", ".", "randn", "(", "1", ",", "requires_grad", "=", "True", ")", ")", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "max_len", "=", "max_len", "\n", "self", ".", "n_memory_layers", "=", "n_memory_layers", "\n", "\n", "self", ".", "merge_encoder", "=", "EncoderRNN", "(", "\n", "input_size", "=", "hidden_size", "*", "3", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "n_layers", "=", "num_layers", ",", "\n", "rnn_cell", "=", "rnn_type", ",", "\n", "max_len", "=", "max_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDRLayer.forward": [[89, 141], ["isinstance", "isinstance", "doc_encoder_outputs.transpose.transpose.transpose", "que_encoder_outputs.transpose.transpose.transpose", "doc_encoder_outputs.transpose.transpose.size", "range", "[].unsqueeze", "[].unsqueeze", "que_encoder_outputs[].unsqueeze.size", "que_encoder_outputs[].unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "redr_encoder.ReDRLayer.merge_encoder", "_C.transpose", "_R.transpose", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.mm().contiguous().view", "torch.mm().contiguous().view", "torch.mm().contiguous().view", "torch.mm().contiguous().view", "torch.mm().contiguous().view", "torch.mm().contiguous().view", "torch.mm().contiguous().view", "torch.mm().contiguous().view", "torch.mm().contiguous().view", "torch.mm().contiguous().view", "torch.mm().contiguous().view", "torch.mm().contiguous().view", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "gates.unsqueeze.unsqueeze.unsqueeze", "_C.transpose", "torch.bmm.transpose", "torch.bmm.transpose", "torch.bmm.transpose", "torch.bmm.transpose", "torch.mm().contiguous", "torch.mm().contiguous", "torch.mm().contiguous", "torch.mm().contiguous", "torch.mm().contiguous", "torch.mm().contiguous", "torch.mm().contiguous", "torch.mm().contiguous", "torch.mm().contiguous", "torch.mm().contiguous", "torch.mm().contiguous", "torch.mm().contiguous", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "u_outputs.contiguous().view", "torch.bmm.transpose().contiguous().view", "torch.bmm.transpose().contiguous().view", "_R.contiguous().view", "u_outputs.contiguous", "torch.bmm.transpose().contiguous", "torch.bmm.transpose().contiguous", "_R.contiguous", "torch.bmm.transpose", "torch.bmm.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "doc_encoder_hidden", ",", "que_encoder_hidden", ",", "doc_encoder_outputs", ",", "que_encoder_outputs", ")", ":", "\n", "# ------------", "\n", "        ", "if", "isinstance", "(", "doc_encoder_hidden", ",", "tuple", ")", ":", "\n", "            ", "doc_encoder_hidden", "=", "doc_encoder_hidden", "[", "0", "]", "[", "-", "1", ",", ":", ",", ":", "]", ".", "unsqueeze", "(", "0", ")", "\n", "", "if", "isinstance", "(", "que_encoder_hidden", ",", "tuple", ")", ":", "\n", "            ", "que_encoder_hidden", "=", "que_encoder_hidden", "[", "0", "]", "[", "-", "1", ",", ":", ",", ":", "]", ".", "unsqueeze", "(", "0", ")", "\n", "", "if", "que_encoder_hidden", ".", "size", "(", "0", ")", "!=", "1", ":", "\n", "# get the last layer", "\n", "            ", "que_encoder_hidden", "=", "que_encoder_outputs", "[", "-", "1", ",", ":", ",", ":", "]", ".", "unsqueeze", "(", "0", ")", "\n", "", "doc_encoder_outputs", "=", "doc_encoder_outputs", ".", "transpose", "(", "0", ",", "1", ")", "\n", "que_encoder_outputs", "=", "que_encoder_outputs", ".", "transpose", "(", "0", ",", "1", ")", "\n", "batch_size", "=", "doc_encoder_outputs", ".", "size", "(", "0", ")", "\n", "gates", "=", "None", "\n", "nm_layers", "=", "self", ".", "n_memory_layers", "\n", "# batch * n * d", "\n", "_R", "=", "doc_encoder_outputs", "\n", "# batch * m * d", "\n", "_C", "=", "que_encoder_outputs", "\n", "for", "i", "in", "range", "(", "nm_layers", ")", ":", "\n", "# alignment matrix S = R^T C", "\n", "# que_encoder_output is context, history C_m", "\n", "            ", "_S", "=", "torch", ".", "bmm", "(", "_R", ",", "_C", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "# _S: B x l_doc x l_que", "\n", "# cq: B x hidden_size x l_que", "\n", "_H", "=", "torch", ".", "bmm", "(", "_R", ".", "transpose", "(", "1", ",", "2", ")", ",", "torch", ".", "softmax", "(", "_S", ",", "dim", "=", "-", "1", ")", ")", "\n", "_G0", "=", "torch", ".", "cat", "(", "(", "_C", ".", "transpose", "(", "1", ",", "2", ")", ",", "_H", ")", ",", "dim", "=", "1", ")", "# B x 2*hidden_size x m", "\n", "_G", "=", "torch", ".", "bmm", "(", "_G0", ",", "torch", ".", "softmax", "(", "_S", ".", "transpose", "(", "1", ",", "2", ")", ",", "dim", "=", "-", "1", ")", ")", "# B x 2*hidden_size x n", "\n", "u_inp", "=", "torch", ".", "cat", "(", "(", "_R", ",", "_G", ".", "transpose", "(", "1", ",", "2", ")", ")", ",", "dim", "=", "-", "1", ")", "# l_doc x B x 3*hidden_size", "\n", "# U: n * batch * hidden", "\n", "u_outputs", ",", "u_hidden", "=", "self", ".", "merge_encoder", "(", "u_inp", ")", "\n", "# n_layers * direction, batch_size, hidden_size", "\n", "encoder_hidden", "=", "u_hidden", "\n", "\n", "if", "i", "==", "0", ":", "\n", "                ", "_R", "=", "u_outputs", "\n", "", "else", ":", "\n", "# U, G, R: batch * n * d/2d", "\n", "                ", "item_a", "=", "torch", ".", "mm", "(", "u_outputs", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "self", ".", "hidden_size", ")", ",", "self", ".", "_w_u", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "item_b", "=", "torch", ".", "mm", "(", "_G", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "2", "*", "self", ".", "hidden_size", ")", ",", "self", ".", "_w_c", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "item_c", "=", "torch", ".", "mm", "(", "_R", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "self", ".", "hidden_size", ")", ",", "self", ".", "_w_r", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "gates", "=", "torch", ".", "sigmoid", "(", "(", "item_a", "+", "item_b", "+", "item_c", "+", "self", ".", "_b", ")", ")", "\n", "gates", "=", "gates", ".", "unsqueeze", "(", "-", "1", ")", "\n", "gated_u", "=", "gates", "*", "_R", "+", "(", "1", "-", "gates", ")", "*", "u_outputs", "\n", "_R", "=", "gated_u", "\n", "\n", "", "", "return", "encoder_hidden", ",", "_R", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.__init__": [[145, 154], ["onmt.encoders.encoder.EncoderBase.__init__", "onmt.encoders.rnn_encoder.RNNEncoder", "onmt.encoders.rnn_encoder.RNNEncoder", "redr_encoder.ReDRLayer"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "rnn_type", ",", "bidirectional", ",", "num_layers", ",", "\n", "hidden_size", ",", "dropout", "=", "0.0", ",", "embeddings", "=", "None", ",", "\n", "use_bridge", "=", "False", ",", "n_memory_layers", "=", "3", ")", ":", "\n", "        ", "super", "(", "ReDREncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "reference_encoder", "=", "RNNEncoder", "(", "\n", "rnn_type", ",", "bidirectional", ",", "num_layers", ",", "hidden_size", ",", "dropout", ",", "embeddings", ",", "use_bridge", ")", "\n", "self", ".", "history_encoder", "=", "RNNEncoder", "(", "\n", "rnn_type", ",", "bidirectional", ",", "num_layers", ",", "hidden_size", ",", "dropout", ",", "embeddings", ",", "use_bridge", ")", "\n", "self", ".", "redr_layer", "=", "ReDRLayer", "(", "hidden_size", ",", "rnn_type", ",", "num_layers", "=", "num_layers", ",", "n_memory_layers", "=", "n_memory_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.from_opt": [[155, 167], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_opt", "(", "cls", ",", "opt", ",", "embeddings", ")", ":", "\n", "        ", "\"\"\"Alternate constructor.\"\"\"", "\n", "return", "cls", "(", "\n", "opt", ".", "rnn_type", ",", "\n", "opt", ".", "brnn", ",", "\n", "opt", ".", "enc_layers", ",", "\n", "opt", ".", "enc_rnn_size", ",", "\n", "opt", ".", "dropout", ",", "\n", "embeddings", ",", "\n", "opt", ".", "bridge", ",", "\n", "opt", ".", "n_memory_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.encoders.redr_encoder.ReDREncoder.forward": [[168, 174], ["redr_encoder.ReDREncoder.reference_encoder", "redr_encoder.ReDREncoder.history_encoder", "redr_encoder.ReDREncoder.redr_layer", "src_enc_outputs.transpose.transpose.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src", ",", "history", ",", "src_lengths", "=", "None", ",", "history_lengths", "=", "None", ")", ":", "\n", "        ", "enc_state", ",", "memory_bank", ",", "src_lengths", "=", "self", ".", "reference_encoder", "(", "src", ",", "src_lengths", ")", "\n", "history_enc_state", ",", "history_memory_bank", ",", "history_lengths", "=", "self", ".", "history_encoder", "(", "history", ",", "history_lengths", ",", "resort", "=", "True", ")", "\n", "enc_hidden", ",", "src_enc_outputs", "=", "self", ".", "redr_layer", "(", "enc_state", ",", "history_enc_state", ",", "memory_bank", ",", "history_memory_bank", ")", "\n", "src_enc_outputs", "=", "src_enc_outputs", ".", "transpose", "(", "0", ",", "1", ")", "\n", "return", "enc_state", ",", "src_enc_outputs", ",", "src_lengths", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.embeddings_to_torch.get_vocabs": [[13, 33], ["torch.load", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.inputters.inputter._old_style_vocab", "vocs.append", "next", "len", "len"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._old_style_vocab"], ["def", "get_vocabs", "(", "dict_path", ")", ":", "\n", "    ", "fields", "=", "torch", ".", "load", "(", "dict_path", ")", "\n", "\n", "vocs", "=", "[", "]", "\n", "for", "side", "in", "[", "'src'", ",", "'tgt'", "]", ":", "\n", "        ", "if", "_old_style_vocab", "(", "fields", ")", ":", "\n", "            ", "vocab", "=", "next", "(", "(", "v", "for", "n", ",", "v", "in", "fields", "if", "n", "==", "side", ")", ",", "None", ")", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "vocab", "=", "fields", "[", "side", "]", ".", "base_field", ".", "vocab", "\n", "", "except", "AttributeError", ":", "\n", "                ", "vocab", "=", "fields", "[", "side", "]", ".", "vocab", "\n", "", "", "vocs", ".", "append", "(", "vocab", ")", "\n", "", "enc_vocab", ",", "dec_vocab", "=", "vocs", "\n", "\n", "logger", ".", "info", "(", "\"From: %s\"", "%", "dict_path", ")", "\n", "logger", ".", "info", "(", "\"\\t* source vocab: %d words\"", "%", "len", "(", "enc_vocab", ")", ")", "\n", "logger", ".", "info", "(", "\"\\t* target vocab: %d words\"", "%", "len", "(", "dec_vocab", ")", ")", "\n", "\n", "return", "enc_vocab", ",", "dec_vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.embeddings_to_torch.read_embeddings": [[35, 52], ["dict", "open", "enumerate", "line.decode().strip().split", "len", "len", "float", "line.decode().strip", "line.decode"], "function", ["None"], ["", "def", "read_embeddings", "(", "file_enc", ",", "skip_lines", "=", "0", ")", ":", "\n", "    ", "embs", "=", "dict", "(", ")", "\n", "with", "open", "(", "file_enc", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "            ", "if", "i", "<", "skip_lines", ":", "\n", "                ", "continue", "\n", "", "if", "not", "line", ":", "\n", "                ", "break", "\n", "", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "# is this reachable?", "\n", "                ", "continue", "\n", "\n", "", "l_split", "=", "line", ".", "decode", "(", "'utf8'", ")", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "if", "len", "(", "l_split", ")", "==", "2", ":", "\n", "                ", "continue", "\n", "", "embs", "[", "l_split", "[", "0", "]", "]", "=", "[", "float", "(", "em", ")", "for", "em", "in", "l_split", "[", "1", ":", "]", "]", "\n", "", "", "return", "embs", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.embeddings_to_torch.match_embeddings": [[54, 68], ["len", "numpy.zeros", "vocab.stoi.items", "six.next", "torch.Tensor", "six.itervalues", "len", "onmt.utils.logging.logger.info"], "function", ["None"], ["", "def", "match_embeddings", "(", "vocab", ",", "emb", ",", "opt", ")", ":", "\n", "    ", "dim", "=", "len", "(", "six", ".", "next", "(", "six", ".", "itervalues", "(", "emb", ")", ")", ")", "\n", "filtered_embeddings", "=", "np", ".", "zeros", "(", "(", "len", "(", "vocab", ")", ",", "dim", ")", ")", "\n", "count", "=", "{", "\"match\"", ":", "0", ",", "\"miss\"", ":", "0", "}", "\n", "for", "w", ",", "w_id", "in", "vocab", ".", "stoi", ".", "items", "(", ")", ":", "\n", "        ", "if", "w", "in", "emb", ":", "\n", "            ", "filtered_embeddings", "[", "w_id", "]", "=", "emb", "[", "w", "]", "\n", "count", "[", "'match'", "]", "+=", "1", "\n", "", "else", ":", "\n", "            ", "if", "opt", ".", "verbose", ":", "\n", "                ", "logger", ".", "info", "(", "u\"not found:\\t{}\"", ".", "format", "(", "w", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "", "count", "[", "'miss'", "]", "+=", "1", "\n", "\n", "", "", "return", "torch", ".", "Tensor", "(", "filtered_embeddings", ")", ",", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.embeddings_to_torch.main": [[70, 126], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "embeddings_to_torch.get_vocabs", "embeddings_to_torch.read_embeddings", "onmt.utils.logging.logger.info", "embeddings_to_torch.read_embeddings", "onmt.utils.logging.logger.info", "embeddings_to_torch.match_embeddings", "embeddings_to_torch.match_embeddings", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "torch.save", "torch.save", "onmt.utils.logging.logger.info", "len", "len", "str", "str", "filtered_enc_embeddings.size", "filtered_dec_embeddings.size"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.embeddings_to_torch.get_vocabs", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.embeddings_to_torch.read_embeddings", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.embeddings_to_torch.read_embeddings", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.embeddings_to_torch.match_embeddings", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.embeddings_to_torch.match_embeddings", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.ModelSaverBase.save", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.ModelSaverBase.save"], ["", "def", "main", "(", ")", ":", "\n", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'embeddings_to_torch.py'", ")", "\n", "parser", ".", "add_argument", "(", "'-emb_file_enc'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"source Embeddings from this file\"", ")", "\n", "parser", ".", "add_argument", "(", "'-emb_file_dec'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"target Embeddings from this file\"", ")", "\n", "parser", ".", "add_argument", "(", "'-output_file'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Output file for the prepared data\"", ")", "\n", "parser", ".", "add_argument", "(", "'-dict_file'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Dictionary file\"", ")", "\n", "parser", ".", "add_argument", "(", "'-verbose'", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'-skip_lines'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Skip first lines of the embedding file\"", ")", "\n", "parser", ".", "add_argument", "(", "'-type'", ",", "choices", "=", "[", "\"GloVe\"", ",", "\"word2vec\"", "]", ",", "\n", "default", "=", "\"GloVe\"", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "enc_vocab", ",", "dec_vocab", "=", "get_vocabs", "(", "opt", ".", "dict_file", ")", "\n", "\n", "skip_lines", "=", "1", "if", "opt", ".", "type", "==", "\"word2vec\"", "else", "opt", ".", "skip_lines", "\n", "src_vectors", "=", "read_embeddings", "(", "opt", ".", "emb_file_enc", ",", "skip_lines", ")", "\n", "logger", ".", "info", "(", "\"Got {} encoder embeddings from {}\"", ".", "format", "(", "\n", "len", "(", "src_vectors", ")", ",", "opt", ".", "emb_file_enc", ")", ")", "\n", "\n", "tgt_vectors", "=", "read_embeddings", "(", "opt", ".", "emb_file_dec", ")", "\n", "logger", ".", "info", "(", "\"Got {} decoder embeddings from {}\"", ".", "format", "(", "\n", "len", "(", "tgt_vectors", ")", ",", "opt", ".", "emb_file_dec", ")", ")", "\n", "\n", "filtered_enc_embeddings", ",", "enc_count", "=", "match_embeddings", "(", "\n", "enc_vocab", ",", "src_vectors", ",", "opt", ")", "\n", "filtered_dec_embeddings", ",", "dec_count", "=", "match_embeddings", "(", "\n", "dec_vocab", ",", "tgt_vectors", ",", "opt", ")", "\n", "logger", ".", "info", "(", "\"\\nMatching: \"", ")", "\n", "match_percent", "=", "[", "_", "[", "'match'", "]", "/", "(", "_", "[", "'match'", "]", "+", "_", "[", "'miss'", "]", ")", "*", "100", "\n", "for", "_", "in", "[", "enc_count", ",", "dec_count", "]", "]", "\n", "logger", ".", "info", "(", "\"\\t* enc: %d match, %d missing, (%.2f%%)\"", "\n", "%", "(", "enc_count", "[", "'match'", "]", ",", "\n", "enc_count", "[", "'miss'", "]", ",", "\n", "match_percent", "[", "0", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"\\t* dec: %d match, %d missing, (%.2f%%)\"", "\n", "%", "(", "dec_count", "[", "'match'", "]", ",", "\n", "dec_count", "[", "'miss'", "]", ",", "\n", "match_percent", "[", "1", "]", ")", ")", "\n", "\n", "logger", ".", "info", "(", "\"\\nFiltered embeddings:\"", ")", "\n", "logger", ".", "info", "(", "\"\\t* enc: %s\"", "%", "str", "(", "filtered_enc_embeddings", ".", "size", "(", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"\\t* dec: %s\"", "%", "str", "(", "filtered_dec_embeddings", ".", "size", "(", ")", ")", ")", "\n", "\n", "enc_output_file", "=", "opt", ".", "output_file", "+", "\".enc.pt\"", "\n", "dec_output_file", "=", "opt", ".", "output_file", "+", "\".dec.pt\"", "\n", "logger", ".", "info", "(", "\"\\nSaving embedding as:\\n\\t* enc: %s\\n\\t* dec: %s\"", "\n", "%", "(", "enc_output_file", ",", "dec_output_file", ")", ")", "\n", "torch", ".", "save", "(", "filtered_enc_embeddings", ",", "enc_output_file", ")", "\n", "torch", ".", "save", "(", "filtered_dec_embeddings", ",", "dec_output_file", ")", "\n", "logger", ".", "info", "(", "\"\\nDone.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.learn_bpe.create_parser": [[30, 57], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.FileType", "argparse.FileType"], "function", ["None"], ["def", "create_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "formatter_class", "=", "argparse", ".", "RawDescriptionHelpFormatter", ",", "\n", "description", "=", "\"learn BPE-based word segmentation\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--input'", ",", "'-i'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "default", "=", "sys", ".", "stdin", ",", "\n", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"Input text (default: standard input).\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--output'", ",", "'-o'", ",", "type", "=", "argparse", ".", "FileType", "(", "'w'", ")", ",", "default", "=", "sys", ".", "stdout", ",", "\n", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"Output file for BPE codes (default: standard output)\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--symbols'", ",", "'-s'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "\"Create this many new symbols (each representing a character n-gram) (default: %(default)s))\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--min-frequency'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "metavar", "=", "'FREQ'", ",", "\n", "help", "=", "'Stop if no symbol pair has frequency >= FREQ (default: %(default)s))'", ")", "\n", "parser", ".", "add_argument", "(", "'--dict-input'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If set, input file is interpreted as a dictionary where each line contains a word-count pair\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--verbose'", ",", "'-v'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"verbose mode.\"", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.learn_bpe.get_vocabulary": [[59, 71], ["collections.Counter", "line.strip().split", "int", "line.split", "line.strip"], "function", ["None"], ["", "def", "get_vocabulary", "(", "fobj", ",", "is_dict", "=", "False", ")", ":", "\n", "    ", "\"\"\"Read text and return dictionary that encodes vocabulary\n    \"\"\"", "\n", "vocab", "=", "Counter", "(", ")", "\n", "for", "line", "in", "fobj", ":", "\n", "        ", "if", "is_dict", ":", "\n", "            ", "word", ",", "count", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "vocab", "[", "word", "]", "=", "int", "(", "count", ")", "\n", "", "else", ":", "\n", "            ", "for", "word", "in", "line", ".", "split", "(", ")", ":", "\n", "                ", "vocab", "[", "word", "]", "+=", "1", "\n", "", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.learn_bpe.update_pair_statistics": [[73, 130], ["collections.defaultdict", "old_word.index", "word.index", "len", "len", "len", "len"], "function", ["None"], ["", "def", "update_pair_statistics", "(", "pair", ",", "changed", ",", "stats", ",", "indices", ")", ":", "\n", "    ", "\"\"\"Minimally update the indices and frequency of symbol pairs\n\n    if we merge a pair of symbols, only pairs that overlap with occurrences\n    of this pair are affected, and need to be updated.\n    \"\"\"", "\n", "stats", "[", "pair", "]", "=", "0", "\n", "indices", "[", "pair", "]", "=", "defaultdict", "(", "int", ")", "\n", "first", ",", "second", "=", "pair", "\n", "new_pair", "=", "first", "+", "second", "\n", "for", "j", ",", "word", ",", "old_word", ",", "freq", "in", "changed", ":", "\n", "\n", "# find all instances of pair, and update frequency/indices around it", "\n", "        ", "i", "=", "0", "\n", "while", "True", ":", "\n", "# find first symbol", "\n", "            ", "try", ":", "\n", "                ", "i", "=", "old_word", ".", "index", "(", "first", ",", "i", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "break", "\n", "# if first symbol is followed by second symbol, we've found an occurrence of pair (old_word[i:i+2])", "\n", "", "if", "i", "<", "len", "(", "old_word", ")", "-", "1", "and", "old_word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "# assuming a symbol sequence \"A B C\", if \"B C\" is merged, reduce the frequency of \"A B\"", "\n", "                ", "if", "i", ":", "\n", "                    ", "prev", "=", "old_word", "[", "i", "-", "1", ":", "i", "+", "1", "]", "\n", "stats", "[", "prev", "]", "-=", "freq", "\n", "indices", "[", "prev", "]", "[", "j", "]", "-=", "1", "\n", "", "if", "i", "<", "len", "(", "old_word", ")", "-", "2", ":", "\n", "# assuming a symbol sequence \"A B C B\", if \"B C\" is merged, reduce the frequency of \"C B\".", "\n", "# however, skip this if the sequence is A B C B C, because the frequency of \"C B\" will be reduced by the previous code block", "\n", "                    ", "if", "old_word", "[", "i", "+", "2", "]", "!=", "first", "or", "i", ">=", "len", "(", "old_word", ")", "-", "3", "or", "old_word", "[", "i", "+", "3", "]", "!=", "second", ":", "\n", "                        ", "nex", "=", "old_word", "[", "i", "+", "1", ":", "i", "+", "3", "]", "\n", "stats", "[", "nex", "]", "-=", "freq", "\n", "indices", "[", "nex", "]", "[", "j", "]", "-=", "1", "\n", "", "", "i", "+=", "2", "\n", "", "else", ":", "\n", "                ", "i", "+=", "1", "\n", "\n", "", "", "i", "=", "0", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "# find new pair", "\n", "                ", "i", "=", "word", ".", "index", "(", "new_pair", ",", "i", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "break", "\n", "# assuming a symbol sequence \"A BC D\", if \"B C\" is merged, increase the frequency of \"A BC\"", "\n", "", "if", "i", ":", "\n", "                ", "prev", "=", "word", "[", "i", "-", "1", ":", "i", "+", "1", "]", "\n", "stats", "[", "prev", "]", "+=", "freq", "\n", "indices", "[", "prev", "]", "[", "j", "]", "+=", "1", "\n", "# assuming a symbol sequence \"A BC B\", if \"B C\" is merged, increase the frequency of \"BC B\"", "\n", "# however, if the sequence is A BC BC, skip this step because the count of \"BC BC\" will be incremented by the previous code block", "\n", "", "if", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "!=", "new_pair", ":", "\n", "                ", "nex", "=", "word", "[", "i", ":", "i", "+", "2", "]", "\n", "stats", "[", "nex", "]", "+=", "freq", "\n", "indices", "[", "nex", "]", "[", "j", "]", "+=", "1", "\n", "", "i", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.learn_bpe.get_pair_statistics": [[132, 149], ["collections.defaultdict", "collections.defaultdict", "enumerate", "collections.defaultdict"], "function", ["None"], ["", "", "", "def", "get_pair_statistics", "(", "vocab", ")", ":", "\n", "    ", "\"\"\"Count frequency of all symbol pairs, and create index\"\"\"", "\n", "\n", "# data structure of pair frequencies", "\n", "stats", "=", "defaultdict", "(", "int", ")", "\n", "\n", "# index from pairs to words", "\n", "indices", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "int", ")", ")", "\n", "\n", "for", "i", ",", "(", "word", ",", "freq", ")", "in", "enumerate", "(", "vocab", ")", ":", "\n", "        ", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "            ", "stats", "[", "prev_char", ",", "char", "]", "+=", "freq", "\n", "indices", "[", "prev_char", ",", "char", "]", "[", "i", "]", "+=", "1", "\n", "prev_char", "=", "char", "\n", "\n", "", "", "return", "stats", ",", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.learn_bpe.replace_pair": [[151, 175], ["pair_str.replace.replace", "re.compile", "indices[].iteritems", "indices[].items", "re.compile.sub", "tuple", "changes.append", "tuple.split", "re.escape"], "function", ["None"], ["", "def", "replace_pair", "(", "pair", ",", "vocab", ",", "indices", ")", ":", "\n", "    ", "\"\"\"Replace all occurrences of a symbol pair ('A', 'B') with a new symbol 'AB'\"\"\"", "\n", "first", ",", "second", "=", "pair", "\n", "pair_str", "=", "''", ".", "join", "(", "pair", ")", "\n", "pair_str", "=", "pair_str", ".", "replace", "(", "'\\\\'", ",", "'\\\\\\\\'", ")", "\n", "changes", "=", "[", "]", "\n", "pattern", "=", "re", ".", "compile", "(", "\n", "r'(?<!\\S)'", "+", "re", ".", "escape", "(", "first", "+", "' '", "+", "second", ")", "+", "r'(?!\\S)'", ")", "\n", "if", "sys", ".", "version_info", "<", "(", "3", ",", "0", ")", ":", "\n", "        ", "iterator", "=", "indices", "[", "pair", "]", ".", "iteritems", "(", ")", "\n", "", "else", ":", "\n", "        ", "iterator", "=", "indices", "[", "pair", "]", ".", "items", "(", ")", "\n", "", "for", "j", ",", "freq", "in", "iterator", ":", "\n", "        ", "if", "freq", "<", "1", ":", "\n", "            ", "continue", "\n", "", "word", ",", "freq", "=", "vocab", "[", "j", "]", "\n", "new_word", "=", "' '", ".", "join", "(", "word", ")", "\n", "new_word", "=", "pattern", ".", "sub", "(", "pair_str", ",", "new_word", ")", "\n", "new_word", "=", "tuple", "(", "new_word", ".", "split", "(", ")", ")", "\n", "\n", "vocab", "[", "j", "]", "=", "(", "new_word", ",", "freq", ")", "\n", "changes", ".", "append", "(", "(", "j", ",", "new_word", ",", "word", ",", "freq", ")", ")", "\n", "\n", "", "return", "changes", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.learn_bpe.prune_stats": [[177, 191], ["list", "stats.items"], "function", ["None"], ["", "def", "prune_stats", "(", "stats", ",", "big_stats", ",", "threshold", ")", ":", "\n", "    ", "\"\"\"Prune statistics dict for efficiency of max()\n\n    The frequency of a symbol pair never increases, so pruning is generally safe\n    (until we the most frequent pair is less frequent than a pair we previously pruned)\n    big_stats keeps full statistics for when we need to access pruned items\n    \"\"\"", "\n", "for", "item", ",", "freq", "in", "list", "(", "stats", ".", "items", "(", ")", ")", ":", "\n", "        ", "if", "freq", "<", "threshold", ":", "\n", "            ", "del", "stats", "[", "item", "]", "\n", "if", "freq", "<", "0", ":", "\n", "                ", "big_stats", "[", "item", "]", "+=", "freq", "\n", "", "else", ":", "\n", "                ", "big_stats", "[", "item", "]", "=", "freq", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.learn_bpe.main": [[193, 237], ["outfile.write", "learn_bpe.get_vocabulary", "dict", "sorted", "learn_bpe.get_pair_statistics", "copy.deepcopy", "range", "dict.items", "max", "outfile.write", "learn_bpe.replace_pair", "learn_bpe.update_pair_statistics", "copy.deepcopy.values", "max", "learn_bpe.prune_stats", "copy.deepcopy", "max", "learn_bpe.prune_stats", "sys.stderr.write", "sys.stderr.write", "learn_bpe.prune_stats", "dict.items", "tuple"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.learn_bpe.get_vocabulary", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.learn_bpe.get_pair_statistics", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.learn_bpe.replace_pair", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.learn_bpe.update_pair_statistics", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.learn_bpe.prune_stats", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.learn_bpe.prune_stats", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.learn_bpe.prune_stats"], ["", "", "", "", "def", "main", "(", "infile", ",", "outfile", ",", "num_symbols", ",", "min_frequency", "=", "2", ",", "verbose", "=", "False", ",", "is_dict", "=", "False", ")", ":", "\n", "    ", "\"\"\"Learn num_symbols BPE operations from vocabulary, and write to outfile.\n    \"\"\"", "\n", "\n", "# version 0.2 changes the handling of the end-of-word token ('</w>');", "\n", "# version numbering allows bckward compatibility", "\n", "outfile", ".", "write", "(", "'#version: 0.2\\n'", ")", "\n", "\n", "vocab", "=", "get_vocabulary", "(", "infile", ",", "is_dict", ")", "\n", "vocab", "=", "dict", "(", "[", "(", "tuple", "(", "x", "[", ":", "-", "1", "]", ")", "+", "(", "x", "[", "-", "1", "]", "+", "'</w>'", ",", ")", ",", "y", ")", "\n", "for", "(", "x", ",", "y", ")", "in", "vocab", ".", "items", "(", ")", "]", ")", "\n", "sorted_vocab", "=", "sorted", "(", "vocab", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "stats", ",", "indices", "=", "get_pair_statistics", "(", "sorted_vocab", ")", "\n", "big_stats", "=", "copy", ".", "deepcopy", "(", "stats", ")", "\n", "# threshold is inspired by Zipfian assumption, but should only affect speed", "\n", "threshold", "=", "max", "(", "stats", ".", "values", "(", ")", ")", "/", "10", "\n", "for", "i", "in", "range", "(", "num_symbols", ")", ":", "\n", "        ", "if", "stats", ":", "\n", "            ", "most_frequent", "=", "max", "(", "stats", ",", "key", "=", "lambda", "x", ":", "(", "stats", "[", "x", "]", ",", "x", ")", ")", "\n", "\n", "# we probably missed the best pair because of pruning; go back to full statistics", "\n", "", "if", "not", "stats", "or", "(", "i", "and", "stats", "[", "most_frequent", "]", "<", "threshold", ")", ":", "\n", "            ", "prune_stats", "(", "stats", ",", "big_stats", ",", "threshold", ")", "\n", "stats", "=", "copy", ".", "deepcopy", "(", "big_stats", ")", "\n", "most_frequent", "=", "max", "(", "stats", ",", "key", "=", "lambda", "x", ":", "(", "stats", "[", "x", "]", ",", "x", ")", ")", "\n", "# threshold is inspired by Zipfian assumption, but should only affect speed", "\n", "threshold", "=", "stats", "[", "most_frequent", "]", "*", "i", "/", "(", "i", "+", "10000.0", ")", "\n", "prune_stats", "(", "stats", ",", "big_stats", ",", "threshold", ")", "\n", "\n", "", "if", "stats", "[", "most_frequent", "]", "<", "min_frequency", ":", "\n", "            ", "sys", ".", "stderr", ".", "write", "(", "\n", "'no pair has frequency >= {0}. Stopping\\n'", ".", "format", "(", "min_frequency", ")", ")", "\n", "break", "\n", "\n", "", "if", "verbose", ":", "\n", "            ", "sys", ".", "stderr", ".", "write", "(", "'pair {0}: {1} {2} -> {1}{2} (frequency {3})\\n'", ".", "format", "(", "\n", "i", ",", "most_frequent", "[", "0", "]", ",", "most_frequent", "[", "1", "]", ",", "stats", "[", "most_frequent", "]", ")", ")", "\n", "", "outfile", ".", "write", "(", "'{0} {1}\\n'", ".", "format", "(", "*", "most_frequent", ")", ")", "\n", "changes", "=", "replace_pair", "(", "most_frequent", ",", "sorted_vocab", ",", "indices", ")", "\n", "update_pair_statistics", "(", "most_frequent", ",", "changes", ",", "stats", ",", "indices", ")", "\n", "stats", "[", "most_frequent", "]", "=", "0", "\n", "if", "not", "i", "%", "100", ":", "\n", "            ", "prune_stats", "(", "stats", ",", "big_stats", ",", "threshold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.average_models.average_models": [[6, 31], ["enumerate", "torch.load", "avg_model.items", "avg_generator.items", "avg_model[].mul_().add_().div_", "avg_generator[].mul_().add_().div_", "avg_model[].mul_().add_", "avg_generator[].mul_().add_", "avg_model[].mul_", "avg_generator[].mul_"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load"], ["def", "average_models", "(", "model_files", ")", ":", "\n", "    ", "vocab", "=", "None", "\n", "opt", "=", "None", "\n", "avg_model", "=", "None", "\n", "avg_generator", "=", "None", "\n", "\n", "for", "i", ",", "model_file", "in", "enumerate", "(", "model_files", ")", ":", "\n", "        ", "m", "=", "torch", ".", "load", "(", "model_file", ")", "\n", "model_weights", "=", "m", "[", "'model'", "]", "\n", "generator_weights", "=", "m", "[", "'generator'", "]", "\n", "\n", "if", "i", "==", "0", ":", "\n", "            ", "vocab", ",", "opt", "=", "m", "[", "'vocab'", "]", ",", "m", "[", "'opt'", "]", "\n", "avg_model", "=", "model_weights", "\n", "avg_generator", "=", "generator_weights", "\n", "", "else", ":", "\n", "            ", "for", "(", "k", ",", "v", ")", "in", "avg_model", ".", "items", "(", ")", ":", "\n", "                ", "avg_model", "[", "k", "]", ".", "mul_", "(", "i", ")", ".", "add_", "(", "model_weights", "[", "k", "]", ")", ".", "div_", "(", "i", "+", "1", ")", "\n", "\n", "", "for", "(", "k", ",", "v", ")", "in", "avg_generator", ".", "items", "(", ")", ":", "\n", "                ", "avg_generator", "[", "k", "]", ".", "mul_", "(", "i", ")", ".", "add_", "(", "generator_weights", "[", "k", "]", ")", ".", "div_", "(", "i", "+", "1", ")", "\n", "\n", "", "", "", "final", "=", "{", "\"vocab\"", ":", "vocab", ",", "\"opt\"", ":", "opt", ",", "\"optim\"", ":", "None", ",", "\n", "\"generator\"", ":", "avg_generator", ",", "\"model\"", ":", "avg_model", "}", "\n", "return", "final", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.average_models.main": [[33, 43], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "average_models.average_models", "torch.save"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.average_models.average_models", "home.repos.pwc.inspect_result.ZJULearning_ReDR.models.model_saver.ModelSaverBase.save"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-models\"", ",", "\"-m\"", ",", "nargs", "=", "\"+\"", ",", "required", "=", "True", ",", "\n", "help", "=", "\"List of models\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-output\"", ",", "\"-o\"", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Output file\"", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "final", "=", "average_models", "(", "opt", ".", "models", ")", "\n", "torch", ".", "save", "(", "final", ",", "opt", ".", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.BPE.__init__": [[33, 60], ["codes.readline", "codes.readline.startswith", "dict", "dict", "tuple", "codes.seek", "tuple", "item.split", "int", "reversed", "apply_bpe.BPE.bpe_codes.items", "re.sub().split", "list", "enumerate", "re.sub", "codes.readline.split"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "codes", ",", "separator", "=", "'@@'", ",", "vocab", "=", "None", ",", "glossaries", "=", "None", ")", ":", "\n", "\n", "# check version information", "\n", "        ", "firstline", "=", "codes", ".", "readline", "(", ")", "\n", "if", "firstline", ".", "startswith", "(", "'#version:'", ")", ":", "\n", "            ", "self", ".", "version", "=", "tuple", "(", "[", "int", "(", "x", ")", "for", "x", "in", "re", ".", "sub", "(", "\n", "r'(\\.0+)*$'", ",", "''", ",", "firstline", ".", "split", "(", ")", "[", "-", "1", "]", ")", ".", "split", "(", "\".\"", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "version", "=", "(", "0", ",", "1", ")", "\n", "codes", ".", "seek", "(", "0", ")", "\n", "\n", "", "self", ".", "bpe_codes", "=", "[", "tuple", "(", "item", ".", "split", "(", ")", ")", "for", "item", "in", "codes", "]", "\n", "\n", "# some hacking to deal with duplicates (only consider first instance)", "\n", "self", ".", "bpe_codes", "=", "dict", "(", "\n", "[", "(", "code", ",", "i", ")", "for", "(", "i", ",", "code", ")", "in", "reversed", "(", "list", "(", "enumerate", "(", "self", ".", "bpe_codes", ")", ")", ")", "]", ")", "\n", "\n", "self", ".", "bpe_codes_reverse", "=", "dict", "(", "\n", "[", "(", "pair", "[", "0", "]", "+", "pair", "[", "1", "]", ",", "pair", ")", "for", "pair", ",", "i", "in", "self", ".", "bpe_codes", ".", "items", "(", ")", "]", ")", "\n", "\n", "self", ".", "separator", "=", "separator", "\n", "\n", "self", ".", "vocab", "=", "vocab", "\n", "\n", "self", ".", "glossaries", "=", "glossaries", "if", "glossaries", "else", "[", "]", "\n", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.BPE.segment": [[61, 80], ["sentence.split", "output.append", "output.append", "apply_bpe.BPE._isolate_glossaries", "apply_bpe.encode"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.BPE._isolate_glossaries", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.encode"], ["", "def", "segment", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "\"\"\"segment single sentence (whitespace-tokenized string) with BPE encoding\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "word", "in", "sentence", ".", "split", "(", ")", ":", "\n", "            ", "new_word", "=", "[", "out", "for", "segment", "in", "self", ".", "_isolate_glossaries", "(", "word", ")", "\n", "for", "out", "in", "encode", "(", "segment", ",", "\n", "self", ".", "bpe_codes", ",", "\n", "self", ".", "bpe_codes_reverse", ",", "\n", "self", ".", "vocab", ",", "\n", "self", ".", "separator", ",", "\n", "self", ".", "version", ",", "\n", "self", ".", "cache", ",", "\n", "self", ".", "glossaries", ")", "]", "\n", "\n", "for", "item", "in", "new_word", "[", ":", "-", "1", "]", ":", "\n", "                ", "output", ".", "append", "(", "item", "+", "self", ".", "separator", ")", "\n", "", "output", ".", "append", "(", "new_word", "[", "-", "1", "]", ")", "\n", "\n", "", "return", "' '", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.BPE._isolate_glossaries": [[81, 87], ["apply_bpe.isolate_glossary"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.isolate_glossary"], ["", "def", "_isolate_glossaries", "(", "self", ",", "word", ")", ":", "\n", "        ", "word_segments", "=", "[", "word", "]", "\n", "for", "gloss", "in", "self", ".", "glossaries", ":", "\n", "            ", "word_segments", "=", "[", "out_segments", "for", "segment", "in", "word_segments", "\n", "for", "out_segments", "in", "isolate_glossary", "(", "segment", ",", "gloss", ")", "]", "\n", "", "return", "word_segments", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.create_parser": [[89, 124], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.FileType", "argparse.FileType", "argparse.FileType", "argparse.FileType"], "function", ["None"], ["", "", "def", "create_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "formatter_class", "=", "argparse", ".", "RawDescriptionHelpFormatter", ",", "\n", "description", "=", "\"learn BPE-based word segmentation\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--input'", ",", "'-i'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "default", "=", "sys", ".", "stdin", ",", "\n", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"Input file (default: standard input).\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--codes'", ",", "'-c'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "metavar", "=", "'PATH'", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"File with BPE codes (created by learn_bpe.py).\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--output'", ",", "'-o'", ",", "type", "=", "argparse", ".", "FileType", "(", "'w'", ")", ",", "default", "=", "sys", ".", "stdout", ",", "\n", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"Output file (default: standard output)\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--separator'", ",", "'-s'", ",", "type", "=", "str", ",", "default", "=", "'@@'", ",", "metavar", "=", "'STR'", ",", "\n", "help", "=", "\"Separator between non-final subword units (default: '%(default)s'))\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--vocabulary'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "default", "=", "None", ",", "\n", "metavar", "=", "\"PATH\"", ",", "\n", "help", "=", "\"Vocabulary file (built with get_vocab.py). If provided, this script reverts any merge operations that produce an OOV.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--vocabulary-threshold'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "metavar", "=", "\"INT\"", ",", "\n", "help", "=", "\"Vocabulary threshold. If vocabulary is provided, any word with frequency < threshold will be treated as OOV\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--glossaries'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "default", "=", "None", ",", "\n", "metavar", "=", "\"STR\"", ",", "\n", "help", "=", "\"Glossaries. The strings provided in glossaries will not be affected\"", "+", "\n", "\"by the BPE (i.e. they will neither be broken into subwords, nor concatenated with other subwords\"", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.get_pairs": [[126, 137], ["set", "set.add"], "function", ["None"], ["", "def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"Return set of symbol pairs in a word.\n\n    word is represented as tuple of symbols (symbols being variable-length strings)\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.encode": [[139, 202], ["apply_bpe.get_pairs", "min", "tuple", "word[].endswith", "apply_bpe.check_vocab_and_split", "tuple", "len", "len", "apply_bpe.get_pairs", "tuple", "check_vocab_and_split.index", "tuple.extend", "tuple.append", "tuple.append", "bpe_codes.get", "tuple.extend", "word[].replace", "float", "len"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.get_pairs", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.check_vocab_and_split", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.get_pairs"], ["", "def", "encode", "(", "orig", ",", "bpe_codes", ",", "bpe_codes_reverse", ",", "vocab", ",", "separator", ",", "version", ",", "cache", ",", "glossaries", "=", "None", ")", ":", "\n", "    ", "\"\"\"Encode word based on list of BPE merge operations, which are applied consecutively\n    \"\"\"", "\n", "\n", "if", "orig", "in", "cache", ":", "\n", "        ", "return", "cache", "[", "orig", "]", "\n", "\n", "", "if", "orig", "in", "glossaries", ":", "\n", "        ", "cache", "[", "orig", "]", "=", "(", "orig", ",", ")", "\n", "return", "(", "orig", ",", ")", "\n", "\n", "", "if", "version", "==", "(", "0", ",", "1", ")", ":", "\n", "        ", "word", "=", "tuple", "(", "orig", ")", "+", "(", "'</w>'", ",", ")", "\n", "", "elif", "version", "==", "(", "0", ",", "2", ")", ":", "# more consistent handling of word-final segments", "\n", "        ", "word", "=", "tuple", "(", "orig", "[", ":", "-", "1", "]", ")", "+", "(", "orig", "[", "-", "1", "]", "+", "'</w>'", ",", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "        ", "return", "orig", "\n", "\n", "", "while", "True", ":", "\n", "        ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "bpe_codes", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "if", "bigram", "not", "in", "bpe_codes", ":", "\n", "            ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "            ", "break", "\n", "", "else", ":", "\n", "            ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "# don't print end-of-word symbols", "\n", "", "", "if", "word", "[", "-", "1", "]", "==", "'</w>'", ":", "\n", "        ", "word", "=", "word", "[", ":", "-", "1", "]", "\n", "", "elif", "word", "[", "-", "1", "]", ".", "endswith", "(", "'</w>'", ")", ":", "\n", "        ", "word", "=", "word", "[", ":", "-", "1", "]", "+", "(", "word", "[", "-", "1", "]", ".", "replace", "(", "'</w>'", ",", "''", ")", ",", ")", "\n", "\n", "", "if", "vocab", ":", "\n", "        ", "word", "=", "check_vocab_and_split", "(", "word", ",", "bpe_codes_reverse", ",", "vocab", ",", "separator", ")", "\n", "\n", "", "cache", "[", "orig", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.recursive_split": [[204, 230], ["apply_bpe.recursive_split", "apply_bpe.recursive_split"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.recursive_split", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.recursive_split"], ["", "def", "recursive_split", "(", "segment", ",", "bpe_codes", ",", "vocab", ",", "separator", ",", "final", "=", "False", ")", ":", "\n", "    ", "\"\"\"Recursively split segment into smaller units (by reversing BPE merges)\n    until all units are either in-vocabulary, or cannot be split futher.\"\"\"", "\n", "\n", "try", ":", "\n", "        ", "if", "final", ":", "\n", "            ", "left", ",", "right", "=", "bpe_codes", "[", "segment", "+", "'</w>'", "]", "\n", "right", "=", "right", "[", ":", "-", "4", "]", "\n", "", "else", ":", "\n", "            ", "left", ",", "right", "=", "bpe_codes", "[", "segment", "]", "\n", "", "", "except", ":", "\n", "#sys.stderr.write('cannot split {0} further.\\n'.format(segment))", "\n", "        ", "yield", "segment", "\n", "return", "\n", "\n", "", "if", "left", "+", "separator", "in", "vocab", ":", "\n", "        ", "yield", "left", "\n", "", "else", ":", "\n", "        ", "for", "item", "in", "recursive_split", "(", "left", ",", "bpe_codes", ",", "vocab", ",", "separator", ",", "False", ")", ":", "\n", "            ", "yield", "item", "\n", "\n", "", "", "if", "(", "final", "and", "right", "in", "vocab", ")", "or", "(", "not", "final", "and", "right", "+", "separator", "in", "vocab", ")", ":", "\n", "        ", "yield", "right", "\n", "", "else", ":", "\n", "        ", "for", "item", "in", "recursive_split", "(", "right", ",", "bpe_codes", ",", "vocab", ",", "separator", ",", "final", ")", ":", "\n", "            ", "yield", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.check_vocab_and_split": [[232, 255], ["out.append", "apply_bpe.recursive_split", "out.append", "apply_bpe.recursive_split", "out.append", "out.append"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.recursive_split", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.recursive_split"], ["", "", "", "def", "check_vocab_and_split", "(", "orig", ",", "bpe_codes", ",", "vocab", ",", "separator", ")", ":", "\n", "    ", "\"\"\"Check for each segment in word if it is in-vocabulary,\n    and segment OOV segments into smaller units by reversing the BPE merge operations\"\"\"", "\n", "\n", "out", "=", "[", "]", "\n", "\n", "for", "segment", "in", "orig", "[", ":", "-", "1", "]", ":", "\n", "        ", "if", "segment", "+", "separator", "in", "vocab", ":", "\n", "            ", "out", ".", "append", "(", "segment", ")", "\n", "", "else", ":", "\n", "#sys.stderr.write('OOV: {0}\\n'.format(segment))", "\n", "            ", "for", "item", "in", "recursive_split", "(", "segment", ",", "bpe_codes", ",", "vocab", ",", "separator", ",", "False", ")", ":", "\n", "                ", "out", ".", "append", "(", "item", ")", "\n", "\n", "", "", "", "segment", "=", "orig", "[", "-", "1", "]", "\n", "if", "segment", "in", "vocab", ":", "\n", "        ", "out", ".", "append", "(", "segment", ")", "\n", "", "else", ":", "\n", "#sys.stderr.write('OOV: {0}\\n'.format(segment))", "\n", "        ", "for", "item", "in", "recursive_split", "(", "segment", ",", "bpe_codes", ",", "vocab", ",", "separator", ",", "True", ")", ":", "\n", "            ", "out", ".", "append", "(", "item", ")", "\n", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.read_vocabulary": [[257, 270], ["set", "line.split", "int", "set.add"], "function", ["None"], ["", "def", "read_vocabulary", "(", "vocab_file", ",", "threshold", ")", ":", "\n", "    ", "\"\"\"read vocabulary file produced by get_vocab.py, and filter according to frequency threshold.\n    \"\"\"", "\n", "\n", "vocabulary", "=", "set", "(", ")", "\n", "\n", "for", "line", "in", "vocab_file", ":", "\n", "        ", "word", ",", "freq", "=", "line", ".", "split", "(", ")", "\n", "freq", "=", "int", "(", "freq", ")", "\n", "if", "threshold", "==", "None", "or", "freq", ">=", "threshold", ":", "\n", "            ", "vocabulary", ".", "add", "(", "word", ")", "\n", "\n", "", "", "return", "vocabulary", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.isolate_glossary": [[272, 288], ["word.split", "segment.strip", "splits[].strip"], "function", ["None"], ["", "def", "isolate_glossary", "(", "word", ",", "glossary", ")", ":", "\n", "    ", "\"\"\"\n    Isolate a glossary present inside a word.\n\n    Returns a list of subwords. In which all 'glossary' glossaries are isolated \n\n    For example, if 'USA' is the glossary and '1934USABUSA' the word, the return value is:\n        ['1934', 'USA', 'B', 'USA']\n    \"\"\"", "\n", "if", "word", "==", "glossary", "or", "glossary", "not", "in", "word", ":", "\n", "        ", "return", "[", "word", "]", "\n", "", "else", ":", "\n", "        ", "splits", "=", "word", ".", "split", "(", "glossary", ")", "\n", "segments", "=", "[", "segment", ".", "strip", "(", ")", "for", "split", "in", "splits", "[", ":", "-", "1", "]", "\n", "for", "segment", "in", "[", "split", ",", "glossary", "]", "if", "segment", "!=", "''", "]", "\n", "return", "segments", "+", "[", "splits", "[", "-", "1", "]", ".", "strip", "(", ")", "]", "if", "splits", "[", "-", "1", "]", "!=", "''", "else", "segments", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.extract_embeddings.write_embeddings": [[23, 30], ["open", "range", "min", "dict.itos[].encode", "range", "file.write", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.apply_bpe.encode"], ["def", "write_embeddings", "(", "filename", ",", "dict", ",", "embeddings", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'wb'", ")", "as", "file", ":", "\n", "        ", "for", "i", "in", "range", "(", "min", "(", "len", "(", "embeddings", ")", ",", "len", "(", "dict", ".", "itos", ")", ")", ")", ":", "\n", "            ", "str", "=", "dict", ".", "itos", "[", "i", "]", ".", "encode", "(", "\"utf-8\"", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "embeddings", "[", "0", "]", ")", ")", ":", "\n", "                ", "str", "=", "str", "+", "(", "\" %5f\"", "%", "(", "embeddings", "[", "i", "]", "[", "j", "]", ")", ")", ".", "encode", "(", "\"utf-8\"", ")", "\n", "", "file", ".", "write", "(", "str", "+", "b\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.extract_embeddings.main": [[32, 77], ["argparse.ArgumentParser", "onmt.opts.model_opts", "onmt.opts.model_opts", "onmt.opts.model_opts", "onmt.opts.model_opts", "parser.parse_args", "torch.load", "onmt.old_style_vocab", "onmt.model_builder.build_base_model", "onmt.model_builder.build_base_model", "onmt.model_builder.build_base_model", "onmt.model_builder.build_base_model", "encoder.embeddings.word_lut.weight.data.tolist", "decoder.embeddings.word_lut.weight.data.tolist", "onmt.utils.logging.logger.info", "extract_embeddings.write_embeddings", "onmt.utils.logging.logger.info", "extract_embeddings.write_embeddings", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "argparse.ArgumentParser.parse_known_args", "torch.cuda.set_device", "onmt.inputters.load_old_vocab", "onmt.inputters.load_old_vocab", "onmt.inputters.load_old_vocab", "onmt.inputters.load_old_vocab", "onmt.utils.misc.use_gpu"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.opts.model_opts", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.opts.model_opts", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.opts.model_opts", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.opts.model_opts", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.old_style_vocab", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.model_builder.build_base_model", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.model_builder.build_base_model", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.model_builder.build_base_model", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.model_builder.build_base_model", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.extract_embeddings.write_embeddings", "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.extract_embeddings.write_embeddings", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.load_old_vocab", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.load_old_vocab", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.load_old_vocab", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.load_old_vocab", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.misc.use_gpu"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "dummy_parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'train.py'", ")", "\n", "onmt", ".", "opts", ".", "model_opts", "(", "dummy_parser", ")", "\n", "dummy_opt", "=", "dummy_parser", ".", "parse_known_args", "(", "[", "]", ")", "[", "0", "]", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "opt", ".", "cuda", "=", "opt", ".", "gpu", ">", "-", "1", "\n", "if", "opt", ".", "cuda", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "opt", ".", "gpu", ")", "\n", "\n", "# Add in default model arguments, possibly added since training.", "\n", "", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "model", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "\n", "vocab", "=", "checkpoint", "[", "'vocab'", "]", "\n", "if", "inputters", ".", "old_style_vocab", "(", "vocab", ")", ":", "\n", "        ", "fields", "=", "onmt", ".", "inputters", ".", "load_old_vocab", "(", "vocab", ")", "\n", "", "else", ":", "\n", "        ", "fields", "=", "vocab", "\n", "", "src_dict", "=", "fields", "[", "'src'", "]", ".", "base_field", ".", "vocab", "# assumes src is text", "\n", "tgt_dict", "=", "fields", "[", "'tgt'", "]", ".", "base_field", ".", "vocab", "\n", "\n", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "for", "arg", "in", "dummy_opt", ".", "__dict__", ":", "\n", "        ", "if", "arg", "not", "in", "model_opt", ":", "\n", "            ", "model_opt", ".", "__dict__", "[", "arg", "]", "=", "dummy_opt", ".", "__dict__", "[", "arg", "]", "\n", "\n", "", "", "model", "=", "onmt", ".", "model_builder", ".", "build_base_model", "(", "\n", "model_opt", ",", "fields", ",", "use_gpu", "(", "opt", ")", ",", "checkpoint", ")", "\n", "encoder", "=", "model", ".", "encoder", "\n", "decoder", "=", "model", ".", "decoder", "\n", "\n", "encoder_embeddings", "=", "encoder", ".", "embeddings", ".", "word_lut", ".", "weight", ".", "data", ".", "tolist", "(", ")", "\n", "decoder_embeddings", "=", "decoder", ".", "embeddings", ".", "word_lut", ".", "weight", ".", "data", ".", "tolist", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"Writing source embeddings\"", ")", "\n", "write_embeddings", "(", "opt", ".", "output_dir", "+", "\"/src_embeddings.txt\"", ",", "src_dict", ",", "\n", "encoder_embeddings", ")", "\n", "\n", "logger", ".", "info", "(", "\"Writing target embeddings\"", ")", "\n", "write_embeddings", "(", "opt", ".", "output_dir", "+", "\"/tgt_embeddings.txt\"", ",", "tgt_dict", ",", "\n", "decoder_embeddings", ")", "\n", "\n", "logger", ".", "info", "(", "'... done.'", ")", "\n", "logger", ".", "info", "(", "'Converting model...'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.diversity.cal_entropy": [[6, 22], ["range", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "gg.strip().split", "range", "counter[].values", "range", "sum", "gg.strip", "counter[].values", "len", "len", "numpy.log", "numpy.log", "counter[].values"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log"], ["def", "cal_entropy", "(", "generated", ")", ":", "\n", "    ", "etp_score", "=", "[", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "]", "\n", "div_score", "=", "[", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "]", "\n", "counter", "=", "[", "defaultdict", "(", "int", ")", ",", "defaultdict", "(", "int", ")", ",", "defaultdict", "(", "int", ")", ",", "defaultdict", "(", "int", ")", "]", "\n", "for", "gg", "in", "generated", ":", "\n", "        ", "g", "=", "gg", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "for", "n", "in", "range", "(", "4", ")", ":", "\n", "            ", "for", "idx", "in", "range", "(", "len", "(", "g", ")", "-", "n", ")", ":", "\n", "                ", "ngram", "=", "' '", ".", "join", "(", "g", "[", "idx", ":", "idx", "+", "n", "+", "1", "]", ")", "\n", "counter", "[", "n", "]", "[", "ngram", "]", "+=", "1", "\n", "", "", "", "for", "n", "in", "range", "(", "4", ")", ":", "\n", "        ", "total", "=", "sum", "(", "counter", "[", "n", "]", ".", "values", "(", ")", ")", "+", "1e-10", "\n", "for", "v", "in", "counter", "[", "n", "]", ".", "values", "(", ")", ":", "\n", "            ", "etp_score", "[", "n", "]", "+=", "-", "(", "v", "+", "0.0", ")", "/", "total", "*", "(", "np", ".", "log", "(", "v", "+", "0.0", ")", "-", "np", ".", "log", "(", "total", ")", ")", "\n", "", "div_score", "[", "n", "]", "=", "(", "len", "(", "counter", "[", "n", "]", ".", "values", "(", ")", ")", "+", "0.0", ")", "/", "total", "\n", "", "return", "etp_score", ",", "div_score", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.diversity.main": [[24, 35], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "print", "open", "f.readlines", "diversity.cal_entropy"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.diversity.cal_entropy"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'-p'", ",", "type", "=", "str", ",", "default", "=", "\"pred.txt\"", ",", "\n", "help", "=", "'prediction file'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "with", "open", "(", "args", ".", "p", ")", "as", "f", ":", "\n", "        ", "ours", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "\n", "", "print", "(", "cal_entropy", "(", "ours", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.create_vocabulary.read_files_batch": [[7, 36], ["zip", "fd_list.append", "enumerate", "print", "fd.close", "sys.exit", "open", "line.rstrip().split.rstrip().split", "batch.append", "line.rstrip().split.rstrip"], "function", ["None"], ["def", "read_files_batch", "(", "file_list", ")", ":", "\n", "    ", "\"\"\"Reads the provided files in batches\"\"\"", "\n", "batch", "=", "[", "]", "# Keep batch for each file", "\n", "fd_list", "=", "[", "]", "# File descriptor list", "\n", "\n", "exit", "=", "False", "# Flag used for quitting the program in case of error", "\n", "\n", "try", ":", "\n", "        ", "for", "filename", "in", "file_list", ":", "\n", "            ", "fd_list", ".", "append", "(", "open", "(", "filename", ")", ")", "\n", "\n", "", "for", "lines", "in", "zip", "(", "*", "fd_list", ")", ":", "\n", "            ", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "                ", "line", "=", "line", ".", "rstrip", "(", "\"\\n\"", ")", ".", "split", "(", "\" \"", ")", "\n", "batch", ".", "append", "(", "line", ")", "\n", "\n", "", "yield", "batch", "\n", "batch", "=", "[", "]", "# Reset batch", "\n", "\n", "", "", "except", "IOError", ":", "\n", "        ", "print", "(", "\"Error reading file \"", "+", "filename", "+", "\".\"", ")", "\n", "exit", "=", "True", "# Flag to exit the program", "\n", "\n", "", "finally", ":", "\n", "        ", "for", "fd", "in", "fd_list", ":", "\n", "            ", "fd", ".", "close", "(", ")", "\n", "\n", "", "if", "exit", ":", "# An error occurred, end execution", "\n", "            ", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.create_vocabulary.main": [[38, 95], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "print", "create_vocabulary.read_files_batch", "print", "print", "torch.load", "_old_style_vocab", "print", "open", "sorted", "ValueError", "dict", "open", "vocabulary.items", "f.write", "len", "f.write"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.tools.create_vocabulary.read_files_batch", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter._old_style_vocab"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'-file_type'", ",", "default", "=", "'text'", ",", "\n", "choices", "=", "[", "'text'", ",", "'field'", "]", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"Options for vocabulary creation.\n                               The default is 'text' where the user passes\n                               a corpus or a list of corpora files for which\n                               they want to create a vocabulary from.\n                               If choosing the option 'field', we assume\n                               the file passed is a torch file created during\n                               the preprocessing stage of an already\n                               preprocessed corpus. The vocabulary file created\n                               will just be the vocabulary inside the field\n                               corresponding to the argument 'side'.\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-file\"", ",", "type", "=", "str", ",", "nargs", "=", "\"+\"", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"-out_file\"", ",", "type", "=", "str", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"-side\"", ",", "type", "=", "str", ")", "\n", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "vocabulary", "=", "{", "}", "\n", "if", "opt", ".", "file_type", "==", "'text'", ":", "\n", "        ", "print", "(", "\"Reading input file...\"", ")", "\n", "for", "batch", "in", "read_files_batch", "(", "opt", ".", "file", ")", ":", "\n", "            ", "for", "sentence", "in", "batch", ":", "\n", "                ", "for", "w", "in", "sentence", ":", "\n", "                    ", "if", "w", "in", "vocabulary", ":", "\n", "                        ", "vocabulary", "[", "w", "]", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "vocabulary", "[", "w", "]", "=", "1", "\n", "\n", "", "", "", "", "print", "(", "\"Writing vocabulary file...\"", ")", "\n", "with", "open", "(", "opt", ".", "out_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "for", "w", ",", "count", "in", "sorted", "(", "vocabulary", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "\n", "reverse", "=", "True", ")", ":", "\n", "                ", "f", ".", "write", "(", "\"{0}\\n\"", ".", "format", "(", "w", ")", ")", "\n", "", "", "", "else", ":", "\n", "        ", "import", "torch", "\n", "from", "onmt", ".", "inputters", ".", "inputter", "import", "_old_style_vocab", "\n", "print", "(", "\"Reading input file...\"", ")", "\n", "if", "not", "len", "(", "opt", ".", "file", ")", "==", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"If using -file_type='field', only pass one \"", "\n", "\"argument for -file.\"", ")", "\n", "", "vocabs", "=", "torch", ".", "load", "(", "opt", ".", "file", "[", "0", "]", ")", "\n", "voc", "=", "dict", "(", "vocabs", ")", "[", "opt", ".", "side", "]", "\n", "if", "_old_style_vocab", "(", "voc", ")", ":", "\n", "            ", "word_list", "=", "voc", ".", "itos", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "word_list", "=", "voc", "[", "0", "]", "[", "1", "]", ".", "base_field", ".", "vocab", ".", "itos", "\n", "", "except", "AttributeError", ":", "\n", "                ", "word_list", "=", "voc", "[", "0", "]", "[", "1", "]", ".", "vocab", ".", "itos", "\n", "\n", "", "", "print", "(", "\"Writing vocabulary file...\"", ")", "\n", "with", "open", "(", "opt", ".", "out_file", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "for", "w", "in", "word_list", ":", "\n", "                ", "f", ".", "write", "(", "u\"{0}\\n\"", ".", "format", "(", "w", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.coqa_dataset.RawDataField.__init__": [[38, 44], ["super().__init__", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "kwargs", ".", "get", "(", "'tokenize'", ")", "is", "None", ":", "\n", "            ", "kwargs", "[", "'tokenize'", "]", "=", "null_tokenizer", "\n", "", "if", "'unk_token'", "not", "in", "kwargs", ":", "\n", "            ", "kwargs", "[", "'unk_token'", "]", "=", "' UNK '", "\n", "", "super", "(", "RawDataField", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.coqa_dataset.RawDataField.process": [[45, 47], ["None"], "methods", ["None"], ["", "def", "process", "(", "self", ",", "batch", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.coqa_dataset.SimpleField.__init__": [[57, 63], ["super().__init__", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "kwargs", ".", "get", "(", "'tokenize'", ")", "is", "None", ":", "\n", "            ", "kwargs", "[", "'tokenize'", "]", "=", "'revtok'", "\n", "", "if", "'unk_token'", "not", "in", "kwargs", ":", "\n", "            ", "kwargs", "[", "'unk_token'", "]", "=", "' UNK '", "\n", "", "super", "(", "SimpleField", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.coqa_dataset.SimpleField.reverse": [[64, 88], ["batch.tolist.tolist.t", "torch.cuda.device_of", "batch.tolist.tolist.tolist", "coqa_dataset.SimpleField.reverse.trim"], "methods", ["None"], ["", "def", "reverse", "(", "self", ",", "batch", ")", ":", "\n", "        ", "if", "not", "self", ".", "batch_first", ":", "\n", "            ", "batch", "=", "batch", ".", "t", "(", ")", "\n", "", "with", "torch", ".", "cuda", ".", "device_of", "(", "batch", ")", ":", "\n", "            ", "batch", "=", "batch", ".", "tolist", "(", ")", "\n", "# denumericalize", "\n", "", "batch", "=", "[", "[", "self", ".", "vocab", ".", "itos", "[", "ind", "]", "for", "ind", "in", "ex", "]", "for", "ex", "in", "batch", "]", "\n", "\n", "def", "trim", "(", "s", ",", "t", ")", ":", "\n", "            ", "sentence", "=", "[", "]", "\n", "for", "w", "in", "s", ":", "\n", "                ", "if", "w", "==", "t", ":", "\n", "                    ", "break", "\n", "", "sentence", ".", "append", "(", "w", ")", "\n", "", "return", "sentence", "\n", "\n", "# trim past frst eos", "\n", "", "batch", "=", "[", "trim", "(", "ex", ",", "self", ".", "eos_token", ")", "for", "ex", "in", "batch", "]", "\n", "\n", "def", "filter_special", "(", "tok", ")", ":", "\n", "            ", "return", "tok", "not", "in", "(", "self", ".", "init_token", ",", "self", ".", "pad_token", ")", "\n", "\n", "", "batch", "=", "[", "filter", "(", "filter_special", ",", "ex", ")", "for", "ex", "in", "batch", "]", "\n", "return", "[", "' '", ".", "join", "(", "ex", ")", "for", "ex", "in", "batch", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.coqa_dataset.CoQADataset.__init__": [[93, 210], ["logging.info", "coqa_dataset.SimpleField", "coqa_dataset.SimpleField", "coqa_dataset.RawDataField", "coqa_dataset.RawDataField", "torchtext.data.Field", "torchtext.data.TabularDataset.splits", "coqa_dataset.CoQADataset._context.build_vocab", "logging.info", "logging.info", "logging.info", "get_embedding_vectors", "len"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.inputters.inputter.build_vocab", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.embedding.get_embedding_vectors"], ["def", "__init__", "(", "self", ",", "trainset_file", ",", "devset_file", ",", "device", ",", "vocab_size", "=", "None", ",", "embed_dir", "=", "None", ",", "embed_type", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        CoQA dataset\n        :param trainset_file: trainset file, tsv format\n        :param devset_file: deveset file, tsv format\n        :param device:\n        \"\"\"", "\n", "logging", ".", "info", "(", "\"Building dataset...\"", ")", "\n", "self", ".", "_device", "=", "device", "\n", "self", ".", "_context", "=", "SimpleField", "(", "\n", "sequential", "=", "True", ",", "\n", "include_lengths", "=", "True", ",", "\n", "batch_first", "=", "True", ",", "\n", "unk_token", "=", "CONST", ".", "UNK_TOKEN", ",", "\n", "pad_token", "=", "CONST", ".", "PAD_TOKEN", ",", "\n", "fix_length", "=", "None", ",", "\n", "use_vocab", "=", "True", ",", "\n", "tokenize", "=", "null_tokenizer", ",", "\n", "pad_first", "=", "False", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "\n", "lower", "=", "True", "\n", ")", "\n", "self", ".", "_question", "=", "SimpleField", "(", "\n", "sequential", "=", "True", ",", "\n", "include_lengths", "=", "True", ",", "\n", "batch_first", "=", "True", ",", "\n", "unk_token", "=", "CONST", ".", "UNK_TOKEN", ",", "\n", "pad_token", "=", "CONST", ".", "PAD_TOKEN", ",", "\n", "fix_length", "=", "None", ",", "\n", "use_vocab", "=", "True", ",", "\n", "tokenize", "=", "null_tokenizer", ",", "\n", "pad_first", "=", "False", ",", "\n", "is_target", "=", "True", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "\n", "lower", "=", "True", "\n", ")", "\n", "self", ".", "_answers", "=", "RawDataField", "(", "\n", "sequential", "=", "True", ",", "\n", "include_lengths", "=", "False", ",", "\n", "batch_first", "=", "True", ",", "\n", "fix_length", "=", "None", ",", "\n", "use_vocab", "=", "False", ",", "\n", "tokenize", "=", "null_tokenizer", ",", "\n", "pad_first", "=", "False", ",", "\n", "is_target", "=", "False", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "\n", "lower", "=", "True", "\n", ")", "\n", "self", ".", "_context_offsets", "=", "RawDataField", "(", "\n", "sequential", "=", "True", ",", "\n", "include_lengths", "=", "False", ",", "\n", "batch_first", "=", "True", ",", "\n", "fix_length", "=", "None", ",", "\n", "use_vocab", "=", "False", ",", "\n", "tokenize", "=", "null_tokenizer", ",", "\n", "pad_first", "=", "False", ",", "\n", "is_target", "=", "False", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "\n", "lower", "=", "False", "\n", ")", "\n", "self", ".", "_target", "=", "torchtext", ".", "data", ".", "Field", "(", "use_vocab", "=", "False", ",", "batch_first", "=", "True", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "\n", "trainset", ",", "devset", "=", "torchtext", ".", "data", ".", "TabularDataset", ".", "splits", "(", "\n", "path", "=", "'/'", ",", "\n", "train", "=", "trainset_file", ",", "\n", "validation", "=", "devset_file", ",", "\n", "filter_pred", "=", "filter_pred", ",", "\n", "format", "=", "'json'", ",", "\n", "fields", "=", "{", "\n", "'span_word'", ":", "(", "'context'", ",", "self", ".", "_context", ")", ",", "\n", "'span_offsets'", ":", "(", "'context_offsets'", ",", "self", ".", "_context_offsets", ")", ",", "\n", "'question_word'", ":", "(", "'question'", ",", "self", ".", "_question", ")", ",", "\n", "'answers'", ":", "(", "'answers'", ",", "self", ".", "_answers", ")", ",", "\n", "'targets_in_span'", ":", "(", "'targets'", ",", "self", ".", "_target", ")", "}", ")", "\n", "self", ".", "_trainset", "=", "trainset", "\n", "self", ".", "_devset", "=", "devset", "\n", "\n", "# issue of torchtext 0.3.1", "\n", "# We want share vocab between src and trg,", "\n", "# but torchtext only supports same field to share different column.", "\n", "# So we build vocab only on one field and assign this vocab to another.", "\n", "# However, trg contains some tokens which not appear in src(EOS_TOKEN, SOS_TOKEN),", "\n", "# These tokens are prepend in vocab dict in function build_vocab.", "\n", "# So we use Field of trg to build vocab to make sure these tokens are included in our vocab.", "\n", "if", "embed_type", "is", "None", ":", "\n", "            ", "embed_vectors", "=", "None", "\n", "embed_dim", "=", "0", "\n", "", "else", ":", "\n", "            ", "from", "lib", ".", "utils", ".", "embedding", "import", "get_embedding_vectors", "\n", "embed_vectors", ",", "embed_dim", "=", "get_embedding_vectors", "(", "embed_dir", ",", "embed_type", ",", "vocab_size", ")", "\n", "", "self", ".", "_embed_dim", "=", "embed_dim", "\n", "self", ".", "_context", ".", "build_vocab", "(", "\n", "trainset", ".", "context", ",", "devset", ".", "context", ",", "trainset", ".", "question", ",", "devset", ".", "question", ",", "\n", "max_size", "=", "vocab_size", "-", "2", ",", "# <unk>, <pad>", "\n", "vectors", "=", "embed_vectors", ")", "\n", "vocab", "=", "self", ".", "_context", ".", "vocab", "\n", "self", ".", "_vocab", "=", "vocab", "\n", "self", ".", "_vectors", "=", "vocab", ".", "vectors", "\n", "\n", "self", ".", "_question", ".", "vocab", "=", "vocab", "\n", "\"\"\"Inputs:\n        xq = question word indices             (batch, max_q_len)\n        xd = document word indices             (batch, max_d_len)\n        targets = span targets                 (batch,)\n        \"\"\"", "\n", "\n", "self", ".", "sos_token", "=", "CONST", ".", "SOS_TOKEN", "\n", "self", ".", "eos_token", "=", "CONST", ".", "EOS_TOKEN", "\n", "self", ".", "unk_token", "=", "CONST", ".", "UNK_TOKEN", "\n", "self", ".", "pad_token", "=", "CONST", ".", "PAD_TOKEN", "\n", "self", ".", "sos_id", "=", "self", ".", "_vocab", ".", "stoi", "[", "CONST", ".", "SOS_TOKEN", "]", "\n", "self", ".", "eos_id", "=", "self", ".", "_vocab", ".", "stoi", "[", "CONST", ".", "EOS_TOKEN", "]", "\n", "self", ".", "unk_id", "=", "self", ".", "_vocab", ".", "stoi", "[", "CONST", ".", "UNK_TOKEN", "]", "\n", "self", ".", "pad_id", "=", "self", ".", "_vocab", ".", "stoi", "[", "CONST", ".", "PAD_TOKEN", "]", "\n", "logging", ".", "info", "(", "\"Dataset is built.\"", ")", "\n", "logging", ".", "info", "(", "\"Vocab size: {}\"", ".", "format", "(", "len", "(", "vocab", ".", "itos", ")", ")", ")", "\n", "logging", ".", "info", "(", "\"Top 10 words: {}\"", ".", "format", "(", "vocab", ".", "itos", "[", ":", "10", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.coqa_dataset.CoQADataset.get_vectors": [[211, 213], ["None"], "methods", ["None"], ["", "def", "get_vectors", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_vectors", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.coqa_dataset.CoQADataset.get_num_train": [[214, 216], ["len"], "methods", ["None"], ["", "def", "get_num_train", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_trainset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.coqa_dataset.CoQADataset.get_vocab_size": [[217, 219], ["len"], "methods", ["None"], ["", "def", "get_vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_vocab", ".", "itos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.coqa_dataset.CoQADataset.get_embed_dim": [[220, 222], ["None"], "methods", ["None"], ["", "def", "get_embed_dim", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_embed_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.coqa_dataset.CoQADataset.get_num_dev": [[223, 225], ["len"], "methods", ["None"], ["", "def", "get_num_dev", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_devset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.coqa_dataset.CoQADataset.get_train_iterator": [[226, 234], ["torchtext.data.BucketIterator", "len"], "methods", ["None"], ["", "def", "get_train_iterator", "(", "self", ",", "batch_size", ",", "shuffle", "=", "None", ")", ":", "\n", "        ", "train_iter", "=", "torchtext", ".", "data", ".", "BucketIterator", "(", "\n", "dataset", "=", "self", ".", "_trainset", ",", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "shuffle", ",", "device", "=", "self", ".", "_device", ",", "\n", "sort_within_batch", "=", "True", ",", "\n", "sort_key", "=", "lambda", "x", ":", "len", "(", "x", ".", "context", "[", "0", "]", ")", ")", "\n", "# sort_key=lambda x: torchtext.data.interleave_keys(len(x.src), len(x.trg)))", "\n", "return", "train_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.coqa_dataset.CoQADataset.get_dev_iterator": [[235, 243], ["torchtext.data.BucketIterator", "len"], "methods", ["None"], ["", "def", "get_dev_iterator", "(", "self", ",", "batch_size", ",", "shuffle", "=", "None", ")", ":", "\n", "        ", "dev_iter", "=", "torchtext", ".", "data", ".", "BucketIterator", "(", "\n", "dataset", "=", "self", ".", "_devset", ",", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "shuffle", ",", "device", "=", "self", ".", "_device", ",", "\n", "sort_within_batch", "=", "True", ",", "\n", "sort_key", "=", "lambda", "x", ":", "len", "(", "x", ".", "context", "[", "0", "]", ")", ")", "\n", "# sort_key=lambda x: torchtext.data.interleave_keys(len(x.src), len(x.trg)))", "\n", "return", "dev_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.coqa_dataset.CoQADataset.reverse": [[244, 255], ["rep_list.append", "rep_str.append"], "methods", ["None"], ["", "def", "reverse", "(", "self", ",", "data", ")", ":", "\n", "        ", "vocab", "=", "self", ".", "_vocab", "\n", "rep_str", "=", "[", "]", "\n", "rep_list", "=", "[", "]", "\n", "for", "ex", "in", "data", ":", "\n", "            ", "l_ex", "=", "[", "vocab", ".", "itos", "[", "idx", "]", "for", "idx", "in", "ex", "if", "vocab", ".", "itos", "[", "idx", "]", "not", "in", "(", "\n", "CONST", ".", "PAD_TOKEN", ",", "CONST", ".", "SOS_TOKEN", ",", "CONST", ".", "EOS_TOKEN", ")", "]", "\n", "s_ex", "=", "' '", ".", "join", "(", "l_ex", ")", "\n", "rep_list", ".", "append", "(", "l_ex", ")", "\n", "rep_str", ".", "append", "(", "s_ex", ")", "\n", "", "return", "rep_list", ",", "rep_str", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.coqa_dataset.CoQADataset.get_vocab": [[256, 258], ["None"], "methods", ["None"], ["", "def", "get_vocab", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.coqa_dataset.null_tokenizer": [[15, 17], ["None"], "function", ["None"], ["def", "null_tokenizer", "(", "text", ")", ":", "\n", "    ", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.coqa_dataset.char_tokenizer": [[19, 25], ["list", "re.sub"], "function", ["None"], ["", "def", "char_tokenizer", "(", "text_list", ")", ":", "\n", "    ", "\"\"\"\n    @text: list of string\n    \"\"\"", "\n", "text_list", "=", "[", "re", ".", "sub", "(", "r'\\s'", ",", "' '", ",", "text", ")", "for", "text", "in", "text_list", "]", "\n", "return", "list", "(", "'\\t'", ".", "join", "(", "text_list", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.coqa_dataset.filter_pred": [[27, 32], ["None"], "function", ["None"], ["", "def", "filter_pred", "(", "example", ")", ":", "\n", "    ", "answers", "=", "example", ".", "answers", "\n", "if", "'unknown'", "in", "answers", "or", "'yes'", "in", "answers", "or", "'no'", "in", "answers", ":", "\n", "        ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.coqa_dataset.create_dataset": [[260, 263], ["coqa_dataset.CoQADataset"], "function", ["None"], ["", "", "def", "create_dataset", "(", "trainset_file", ",", "devset_file", ",", "device", ",", "vocab_size", "=", "None", ",", "embed_type", "=", "None", ",", "embed_dir", "=", "None", ")", ":", "\n", "    ", "return", "CoQADataset", "(", "trainset_file", ",", "devset_file", ",", "\n", "vocab_size", "=", "vocab_size", ",", "device", "=", "device", ",", "embed_type", "=", "embed_type", ",", "embed_dir", "=", "embed_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.config.update_model_specific_args": [[14, 65], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "argparse.ArgumentParser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "vars().update", "argparse.ArgumentParser.parse_known_args", "vars", "vars"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.update"], ["def", "update_model_specific_args", "(", "normal_args", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# parser.add_argument('--n_history', type=int, default=0)", "\n", "# parser.add_argument('--cased', type=bool, default=True, help='Cased or uncased version.')", "\n", "# parser.add_argument('--min_freq', type=int, default=20)", "\n", "# parser.add_argument('--top_vocab', type=int, default=100000)", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'model_spec'", ")", "\n", "group", ".", "add_argument", "(", "'--rnn_padding'", ",", "type", "=", "bool", ",", "default", "=", "False", ",", "help", "=", "'Whether to use RNN padding.'", ")", "\n", "group", ".", "add_argument", "(", "'--hidden_size'", ",", "type", "=", "int", ",", "default", "=", "300", ",", "help", "=", "'Set hidden size.'", ")", "\n", "group", ".", "add_argument", "(", "'--n_history'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "help", "=", "'...'", ")", "\n", "group", ".", "add_argument", "(", "'--num_layers'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'Number of layers for document/question encoding.'", ")", "\n", "group", ".", "add_argument", "(", "'--rnn_type'", ",", "type", "=", "str", ",", "choices", "=", "[", "'lstm'", ",", "'gru'", ",", "'rnn'", "]", ",", "default", "=", "'lstm'", ",", "help", "=", "'RNN type.'", ")", "\n", "group", ".", "add_argument", "(", "'--concat_rnn_layers'", ",", "type", "=", "bool", ",", "default", "=", "True", ",", "help", "=", "'Whether to concat RNN layers.'", ")", "\n", "group", ".", "add_argument", "(", "'--question_merge'", ",", "type", "=", "str", ",", "choices", "=", "[", "'avg'", ",", "'self_attn'", "]", ",", "\n", "default", "=", "'self_attn'", ",", "help", "=", "'The way of question encoding.'", ")", "\n", "group", ".", "add_argument", "(", "'--use_cove'", ",", "type", "=", "bool", ",", "default", "=", "False", ",", "help", "=", "'CoVe'", ")", "\n", "group", ".", "add_argument", "(", "'--fix_cove'", ",", "type", "=", "bool", ",", "default", "=", "True", ",", "help", "=", "'CoVe'", ")", "\n", "group", ".", "add_argument", "(", "'--use_qemb'", ",", "type", "=", "bool", ",", "default", "=", "True", ",", "help", "=", "'Whether to add question aligned embedding.'", ")", "\n", "group", ".", "add_argument", "(", "'--f_qem'", ",", "type", "=", "bool", ",", "default", "=", "True", ",", "help", "=", "'Add exact match question feature to embedding.'", ")", "\n", "group", ".", "add_argument", "(", "'--f_pos'", ",", "type", "=", "bool", ",", "default", "=", "False", ",", "help", "=", "'Add POS feature to embedding.'", ")", "\n", "group", ".", "add_argument", "(", "'--f_ner'", ",", "type", "=", "bool", ",", "default", "=", "False", ",", "help", "=", "'Add NER feature to embedding.'", ")", "\n", "group", ".", "add_argument", "(", "'--sum_loss'", ",", "type", "=", "bool", ",", "default", "=", "False", ",", "help", "=", "\"Set the type of loss.\"", ")", "\n", "group", ".", "add_argument", "(", "'--doc_self_attn'", ",", "type", "=", "bool", ",", "default", "=", "False", ",", "\n", "help", "=", "\"Set whether to use self attention on the document.\"", ")", "\n", "group", ".", "add_argument", "(", "'--resize_rnn_input'", ",", "type", "=", "bool", ",", "default", "=", "False", ",", "\n", "help", "=", "'Reshape input layer to hidden size dimension.'", ")", "\n", "group", ".", "add_argument", "(", "'--span_dependency'", ",", "type", "=", "bool", ",", "default", "=", "True", ",", "\n", "help", "=", "'Toggles dependency between the start and end span predictions for DrQA.'", ")", "\n", "group", ".", "add_argument", "(", "'--fix_embeddings'", ",", "type", "=", "bool", ",", "default", "=", "False", ",", "help", "=", "'Whether to fix embeddings.'", ")", "\n", "group", ".", "add_argument", "(", "'--dropout_rnn'", ",", "type", "=", "float", ",", "default", "=", "0.3", ",", "help", "=", "'Set RNN dropout in reader.'", ")", "\n", "group", ".", "add_argument", "(", "'--dropout_emb'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'Set embedding dropout.'", ")", "\n", "group", ".", "add_argument", "(", "'--dropout_ff'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'Set dropout for all feedforward layers.'", ")", "\n", "group", ".", "add_argument", "(", "'--dropout_rnn_output'", ",", "type", "=", "bool", ",", "default", "=", "True", ",", "help", "=", "'Whether to dropout last layer.'", ")", "\n", "group", ".", "add_argument", "(", "'--variational_dropout'", ",", "type", "=", "bool", ",", "default", "=", "True", ",", "help", "=", "'Set variational dropout on/off.'", ")", "\n", "group", ".", "add_argument", "(", "'--word_dropout'", ",", "type", "=", "bool", ",", "default", "=", "False", ",", "help", "=", "'Whether to dropout word.'", ")", "\n", "\n", "# Optimizer", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'training_spec'", ")", "\n", "group", ".", "add_argument", "(", "'--grad_clipping'", ",", "type", "=", "float", ",", "default", "=", "10.0", ",", "help", "=", "'Whether to use grad clipping.'", ")", "\n", "group", ".", "add_argument", "(", "'--weight_decay'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "help", "=", "'Set weight decay.'", ")", "\n", "group", ".", "add_argument", "(", "'--momentum'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "help", "=", "'Set momentum.'", ")", "\n", "group", ".", "add_argument", "(", "'--max_answer_len'", ",", "type", "=", "int", ",", "default", "=", "15", ",", "help", "=", "'Set max answer length for decoding.'", ")", "\n", "group", ".", "add_argument", "(", "'--predict_train'", ",", "type", "=", "bool", ",", "default", "=", "True", ",", "help", "=", "'Whether to predict on training set.'", ")", "\n", "group", ".", "add_argument", "(", "'--out_predictions'", ",", "type", "=", "bool", ",", "default", "=", "True", ",", "help", "=", "'Whether to output predictions.'", ")", "\n", "group", ".", "add_argument", "(", "'--predict_raw_text'", ",", "type", "=", "bool", ",", "default", "=", "True", ",", "\n", "help", "=", "'Whether to use raw text and offsets for prediction.'", ")", "\n", "args", "=", "parser", ".", "parse_known_args", "(", ")", "[", "0", "]", "\n", "\n", "vars", "(", "normal_args", ")", ".", "update", "(", "vars", "(", "args", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.debug_main.test_dataset": [[16, 19], ["print"], "function", ["None"], ["def", "test_dataset", "(", ")", ":", "\n", "    ", "print", "(", "\"!!!!!!!!\"", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.debug_main.debug_main": [[21, 29], ["os.path.expanduser", "torch.load", "json.load", "types.SimpleNamespace", "model.DrQA", "print", "print", "os.path.join", "open", "len", "os.path.join"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load"], ["", "def", "debug_main", "(", ")", ":", "\n", "    ", "homedir", "=", "os", ".", "path", ".", "expanduser", "(", "\"~\"", ")", "\n", "vocab", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "homedir", ",", "\"workspace/ml/nlp/clta/out/clta/clta1/vocab.pt\"", ")", ")", "\n", "json_config", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "homedir", ",", "\"workspace/ml/nlp/clta/out/clta/clta1/hparams.json\"", ")", ")", ")", "\n", "args", "=", "SimpleNamespace", "(", "**", "json_config", ")", "\n", "model", "=", "DrQA", "(", "vocab", ",", "args", ")", "\n", "print", "(", "len", "(", "vocab", ")", ")", "\n", "print", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.model_handler.create_model": [[16, 19], ["dataset.get_vocab", "drqa_model.DrQA"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.coqa_dataset.CoQADataset.get_vocab"], ["def", "create_model", "(", "dataset", ",", "args", ")", ":", "\n", "    ", "vocab", "=", "dataset", ".", "get_vocab", "(", ")", "\n", "return", "DrQA", "(", "vocab", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.model_handler.get_dataset": [[21, 33], ["coqa_dataset.create_dataset", "Exception"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.coqa_dataset.create_dataset"], ["", "def", "get_dataset", "(", "trainset_file", "=", "None", ",", "devset_file", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "    ", "global", "_dataset", "\n", "if", "_dataset", "is", "None", ":", "\n", "        ", "if", "trainset_file", "is", "None", "or", "devset_file", "is", "None", "or", "args", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Not supposed to be here.\"", ")", "\n", "", "_dataset", "=", "create_dataset", "(", "trainset_file", ",", "devset_file", ",", "\n", "vocab_size", "=", "args", ".", "vocab_size", ",", "\n", "device", "=", "args", ".", "device", ",", "\n", "embed_type", "=", "args", ".", "embed_type", ",", "\n", "embed_dir", "=", "args", ".", "embed_dir", ")", "\n", "args", ".", "sos_id", "=", "_dataset", ".", "sos_id", "\n", "", "return", "_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.model_handler.preprocess": [[35, 37], ["preprocessor.preprocess"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.preprocess"], ["", "def", "preprocess", "(", "args", ")", ":", "\n", "    ", "prepro", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.model_handler.update_model_args": [[39, 41], ["config.update_model_specific_args"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.config.update_model_specific_args"], ["", "def", "update_model_args", "(", "args", ")", ":", "\n", "    ", "update_model_specific_args", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.__init__": [[36, 141], ["torch.Module.__init__", "len", "torch.Embedding", "torch.Embedding", "torch.Embedding", "layers.StackedBRNN", "layers.StackedBRNN", "layers.BilinearSeqAttn", "layers.BilinearSeqAttn", "logging.warn", "vocab.vectors.size", "drqa_model.DrQA.w_embedding.weight.data.copy_", "drqa_model.DrQA.w_embedding.parameters", "cove.MTLSTM", "drqa_model.DrQA.mt_cove.parameters", "layers.SeqAttnMatch", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "layers.SeqAttnMatch", "NotImplementedError", "layers.LinearSeqAttn", "drqa_model.DrQA.mt_cove.parameters"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "vocab", ",", "args", ")", ":", "\n", "        ", "\"\"\"Configuration, word embeddings\"\"\"", "\n", "super", "(", "DrQA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# print(vocab.keys())", "\n", "# Store config", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "best_metrics", "=", "None", "\n", "self", ".", "metrics_history", "=", "{", "'f1'", ":", "[", "]", ",", "'em'", ":", "[", "]", "}", "\n", "self", ".", "gpu", "=", "False", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "vocab_size", "=", "len", "(", "vocab", ")", "\n", "if", "self", ".", "vocab_size", "!=", "args", ".", "vocab_size", ":", "\n", "            ", "logging", ".", "warn", "(", "\n", "\"required vocab_size is not equal to real vocab_size({} vs {})\"", ".", "format", "(", "\n", "args", ".", "vocab_size", ",", "self", ".", "vocab_size", ")", ")", "\n", "", "self", ".", "w_embedding", "=", "nn", ".", "Embedding", "(", "self", ".", "vocab_size", ",", "vocab", ".", "vectors", ".", "size", "(", "1", ")", ")", "\n", "if", "vocab", ".", "vectors", "is", "not", "None", ":", "\n", "            ", "self", ".", "w_embedding", ".", "weight", ".", "data", ".", "copy_", "(", "vocab", ".", "vectors", ")", "\n", "", "input_w_dim", "=", "self", ".", "w_embedding", ".", "embedding_dim", "\n", "if", "args", ".", "fix_embeddings", ":", "\n", "            ", "for", "p", "in", "self", ".", "w_embedding", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "self", ".", "mt_cove", "=", "None", "\n", "if", "args", ".", "use_cove", ":", "\n", "            ", "self", ".", "mt_cove", "=", "MTLSTM", "(", ")", "\n", "input_w_dim", "=", "input_w_dim", "+", "600", "\n", "for", "p", "in", "self", ".", "mt_cove", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "True", "\n", "", "", "q_input_size", "=", "input_w_dim", "\n", "\n", "# Projection for attention weighted question", "\n", "if", "self", ".", "args", ".", "use_qemb", ":", "\n", "            ", "self", ".", "qemb_match", "=", "SeqAttnMatch", "(", "input_w_dim", ")", "\n", "\n", "# Input size to RNN: word emb + question emb + manual features", "\n", "", "doc_input_size", "=", "input_w_dim", "\n", "if", "self", ".", "args", ".", "use_qemb", ":", "\n", "            ", "doc_input_size", "+=", "input_w_dim", "\n", "\n", "# Project document and question to the same size as their encoders", "\n", "", "if", "self", ".", "args", ".", "resize_rnn_input", ":", "\n", "            ", "self", ".", "doc_linear", "=", "nn", ".", "Linear", "(", "doc_input_size", ",", "args", ".", "hidden_size", ",", "bias", "=", "True", ")", "\n", "self", ".", "q_linear", "=", "nn", ".", "Linear", "(", "input_w_dim", ",", "args", ".", "hidden_size", ",", "bias", "=", "True", ")", "\n", "doc_input_size", "=", "q_input_size", "=", "args", ".", "hidden_size", "\n", "\n", "# RNN document encoder", "\n", "", "self", ".", "doc_rnn", "=", "StackedBRNN", "(", "\n", "input_size", "=", "doc_input_size", ",", "\n", "hidden_size", "=", "args", ".", "hidden_size", ",", "\n", "num_layers", "=", "args", ".", "num_layers", ",", "\n", "dropout_rate", "=", "args", ".", "dropout_rnn", ",", "\n", "dropout_output", "=", "args", ".", "dropout_rnn_output", ",", "\n", "variational_dropout", "=", "args", ".", "variational_dropout", ",", "\n", "concat_layers", "=", "args", ".", "concat_rnn_layers", ",", "\n", "rnn_type", "=", "self", ".", "_RNN_TYPES", "[", "args", ".", "rnn_type", "]", ",", "\n", "padding", "=", "args", ".", "rnn_padding", ",", "\n", "bidirectional", "=", "True", ",", "\n", ")", "\n", "\n", "# RNN question encoder", "\n", "self", ".", "question_rnn", "=", "StackedBRNN", "(", "\n", "input_size", "=", "q_input_size", ",", "\n", "hidden_size", "=", "args", ".", "hidden_size", ",", "\n", "num_layers", "=", "args", ".", "num_layers", ",", "\n", "dropout_rate", "=", "args", ".", "dropout_rnn", ",", "\n", "dropout_output", "=", "args", ".", "dropout_rnn_output", ",", "\n", "variational_dropout", "=", "args", ".", "variational_dropout", ",", "\n", "concat_layers", "=", "args", ".", "concat_rnn_layers", ",", "\n", "rnn_type", "=", "self", ".", "_RNN_TYPES", "[", "args", ".", "rnn_type", "]", ",", "\n", "padding", "=", "args", ".", "rnn_padding", ",", "\n", "bidirectional", "=", "True", ",", "\n", ")", "\n", "\n", "# Output sizes of rnn encoders", "\n", "doc_hidden_size", "=", "2", "*", "args", ".", "hidden_size", "\n", "question_hidden_size", "=", "2", "*", "args", ".", "hidden_size", "\n", "if", "args", ".", "concat_rnn_layers", ":", "\n", "            ", "doc_hidden_size", "*=", "args", ".", "num_layers", "\n", "question_hidden_size", "*=", "args", ".", "num_layers", "\n", "\n", "", "if", "args", ".", "doc_self_attn", ":", "\n", "            ", "self", ".", "doc_self_attn", "=", "SeqAttnMatch", "(", "doc_hidden_size", ")", "\n", "doc_hidden_size", "=", "doc_hidden_size", "+", "question_hidden_size", "\n", "\n", "# Question merging", "\n", "", "if", "args", ".", "question_merge", "not", "in", "[", "'avg'", ",", "'self_attn'", "]", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'question_merge = %s'", "%", "args", ".", "question_merge", ")", "\n", "", "if", "args", ".", "question_merge", "==", "'self_attn'", ":", "\n", "            ", "self", ".", "self_attn", "=", "LinearSeqAttn", "(", "question_hidden_size", ")", "\n", "\n", "# Bilinear attention for span start/end", "\n", "", "self", ".", "start_attn", "=", "BilinearSeqAttn", "(", "\n", "doc_hidden_size", ",", "\n", "question_hidden_size", ",", "\n", ")", "\n", "q_rep_size", "=", "question_hidden_size", "+", "doc_hidden_size", "if", "args", ".", "span_dependency", "else", "question_hidden_size", "\n", "self", ".", "end_attn", "=", "BilinearSeqAttn", "(", "\n", "doc_hidden_size", ",", "\n", "q_rep_size", ",", "\n", ")", "\n", "\n", "if", "args", ".", "fix_cove", "and", "self", ".", "mt_cove", "is", "not", "None", ":", "\n", "            ", "for", "p", "in", "self", ".", "mt_cove", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load": [[142, 147], ["drqa_model.DrQA.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "print"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.load_state_dict", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load"], ["", "", "", "def", "load", "(", "self", ",", "path", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "self", ".", "load_state_dict", "(", "torch", ".", "load", "(", "path", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "e", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.forward": [[148, 234], ["drqa_model.DrQA.w_embedding", "drqa_model.DrQA.w_embedding", "layers.dropout", "layers.dropout", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "enumerate", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "enumerate", "drqa_model.DrQA.doc_rnn", "drqa_model.DrQA.question_rnn", "layers.weighted_avg", "drqa_model.DrQA.start_attn", "drqa_model.DrQA.end_attn", "drqa_model.DrQA.extract_predictions", "kwargs.get", "xd_mask[].fill_", "xq_mask[].fill_", "drqa_model.DrQA.mt_cove", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "drqa_model.DrQA.mt_cove", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "drqa_model.DrQA.qemb_match", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "drqa_model.DrQA.doc_self_attn", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "layers.uniform_weights", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "drqa_model.DrQA.doc_linear", "drqa_model.DrQA.q_linear", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "drqa_model.DrQA.self_attn", "drqa_model.DrQA.contiguous", "drqa_model.DrQA.exp().unsqueeze", "drqa_model.DrQA.exp"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.dropout", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.dropout", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.weighted_avg", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.extract_predictions", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.uniform_weights", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.dropout", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.dropout", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.dropout", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.dropout", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.dropout", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.dropout"], ["", "", "def", "forward", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "'batch'", "in", "kwargs", ":", "\n", "            ", "batch", "=", "kwargs", "[", "'batch'", "]", "\n", "batch_que", ",", "que_lengths", "=", "batch", ".", "question", "\n", "batch_doc", ",", "doc_lengths", "=", "batch", ".", "context", "\n", "batch_offsets", "=", "batch", ".", "context_offsets", "\n", "batch_tgt", "=", "batch", ".", "targets", "\n", "raw_doc", "=", "None", "\n", "", "else", ":", "\n", "            ", "batch_que", ",", "que_lengths", "=", "kwargs", "[", "'question'", "]", "\n", "batch_doc", ",", "doc_lengths", ",", "raw_doc", "=", "kwargs", "[", "'context'", "]", "\n", "batch_offsets", "=", "kwargs", "[", "'context_offsets'", "]", "\n", "batch_tgt", "=", "kwargs", ".", "get", "(", "'targets'", ")", "\n", "\n", "# Embed both document and question", "\n", "", "xq_emb", "=", "self", ".", "w_embedding", "(", "batch_que", ")", "# (batch, max_q_len, word_embed)", "\n", "xd_emb", "=", "self", ".", "w_embedding", "(", "batch_doc", ")", "# (batch, max_d_len, word_embed)", "\n", "\n", "shared_axes", "=", "[", "2", "]", "if", "self", ".", "args", ".", "word_dropout", "else", "[", "]", "\n", "xq_emb", "=", "dropout", "(", "xq_emb", ",", "self", ".", "args", ".", "dropout_emb", ",", "shared_axes", "=", "shared_axes", ",", "training", "=", "self", ".", "training", ")", "\n", "xd_emb", "=", "dropout", "(", "xd_emb", ",", "self", ".", "args", ".", "dropout_emb", ",", "shared_axes", "=", "shared_axes", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "xd_mask", "=", "torch", ".", "ones_like", "(", "batch_doc", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "for", "i", ",", "q", "in", "enumerate", "(", "doc_lengths", ")", ":", "\n", "            ", "xd_mask", "[", "i", ",", ":", "q", "]", ".", "fill_", "(", "0", ")", "\n", "\n", "", "xq_mask", "=", "torch", ".", "ones_like", "(", "batch_que", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "for", "i", ",", "q", "in", "enumerate", "(", "que_lengths", ")", ":", "\n", "            ", "xq_mask", "[", "i", ",", ":", "q", "]", ".", "fill_", "(", "0", ")", "\n", "\n", "# -------------------------", "\n", "", "if", "self", ".", "mt_cove", "is", "not", "None", ":", "\n", "            ", "xq_emb_c", "=", "xq_emb", "\n", "xd_emb_c", "=", "xd_emb", "\n", "\n", "xq_emb_cove", "=", "self", ".", "mt_cove", "(", "xq_emb_c", ",", "mask", "=", "xq_mask", ")", "\n", "xq_emb", "=", "torch", ".", "cat", "(", "[", "xq_emb", ",", "xq_emb_cove", "]", ",", "-", "1", ")", "\n", "xd_emb_cove", "=", "self", ".", "mt_cove", "(", "xd_emb_c", ",", "mask", "=", "xd_mask", ")", "\n", "xd_emb", "=", "torch", ".", "cat", "(", "[", "xd_emb_c", ",", "xd_emb_cove", "]", ",", "-", "1", ")", "\n", "# ----------------------------", "\n", "\n", "# Add attention-weighted question representation", "\n", "", "if", "self", ".", "args", ".", "use_qemb", ":", "\n", "            ", "xq_weighted_emb", "=", "self", ".", "qemb_match", "(", "xd_emb", ",", "xq_emb", ",", "xq_mask", ")", "\n", "drnn_input", "=", "torch", ".", "cat", "(", "[", "xd_emb", ",", "xq_weighted_emb", "]", ",", "2", ")", "\n", "", "else", ":", "\n", "            ", "drnn_input", "=", "xd_emb", "\n", "\n", "# Project document and question to the same size as their encoders", "\n", "", "if", "self", ".", "args", ".", "resize_rnn_input", ":", "\n", "            ", "drnn_input", "=", "F", ".", "relu", "(", "self", ".", "doc_linear", "(", "drnn_input", ")", ")", "\n", "xq_emb", "=", "F", ".", "relu", "(", "self", ".", "q_linear", "(", "xq_emb", ")", ")", "\n", "if", "self", ".", "args", ".", "dropout_ff", ">", "0", ":", "\n", "                ", "drnn_input", "=", "F", ".", "dropout", "(", "drnn_input", ",", "training", "=", "self", ".", "training", ")", "\n", "xq_emb", "=", "F", ".", "dropout", "(", "xq_emb", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# Encode document with RNN", "\n", "", "", "doc_hiddens", "=", "self", ".", "doc_rnn", "(", "drnn_input", ",", "xd_mask", ")", "# (batch, max_d_len, hidden_size)", "\n", "\n", "# Document self attention", "\n", "if", "self", ".", "args", ".", "doc_self_attn", ":", "\n", "            ", "xd_weighted_emb", "=", "self", ".", "doc_self_attn", "(", "doc_hiddens", ",", "doc_hiddens", ",", "xd_mask", ")", "\n", "doc_hiddens", "=", "torch", ".", "cat", "(", "[", "doc_hiddens", ",", "xd_weighted_emb", "]", ",", "2", ")", "\n", "\n", "# Encode question with RNN + merge hiddens", "\n", "", "question_hiddens", "=", "self", ".", "question_rnn", "(", "xq_emb", ",", "xq_mask", ")", "\n", "if", "self", ".", "args", ".", "question_merge", "==", "'avg'", ":", "\n", "            ", "q_merge_weights", "=", "uniform_weights", "(", "question_hiddens", ",", "xq_mask", ")", "\n", "", "elif", "self", ".", "args", ".", "question_merge", "==", "'self_attn'", ":", "\n", "            ", "q_merge_weights", "=", "self", ".", "self_attn", "(", "question_hiddens", ".", "contiguous", "(", ")", ",", "xq_mask", ")", "\n", "", "question_hidden", "=", "weighted_avg", "(", "question_hiddens", ",", "q_merge_weights", ")", "\n", "\n", "# Predict start and end positions", "\n", "# doc_hiddens: batch, len, hidden_size * x", "\n", "# question_hidden: batch, hidden_size * x", "\n", "start_scores", "=", "self", ".", "start_attn", "(", "doc_hiddens", ",", "question_hidden", ",", "xd_mask", ")", "\n", "if", "self", ".", "args", ".", "span_dependency", ":", "\n", "            ", "question_hidden", "=", "torch", ".", "cat", "(", "[", "question_hidden", ",", "(", "doc_hiddens", "*", "start_scores", ".", "exp", "(", ")", ".", "unsqueeze", "(", "2", ")", ")", ".", "sum", "(", "1", ")", "]", ",", "1", ")", "\n", "", "end_scores", "=", "self", ".", "end_attn", "(", "doc_hiddens", ",", "question_hidden", ",", "xd_mask", ")", "\n", "# score: batch, length", "\n", "predictions", ",", "spans", "=", "self", ".", "extract_predictions", "(", "batch_doc", ",", "batch_offsets", ",", "start_scores", ",", "end_scores", ",", "raw_doc", ")", "\n", "\n", "return", "{", "'score_s'", ":", "start_scores", ",", "\n", "'score_e'", ":", "end_scores", ",", "\n", "'predictions'", ":", "predictions", ",", "\n", "'targets'", ":", "batch_tgt", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.evaluate": [[235, 283], ["drqa_model.DrQA.train", "tqdm.tqdm.tqdm", "drqa_model.DrQA.metrics_history[].append", "drqa_model.DrQA.metrics_history[].append", "drqa_model.DrQA.train", "enumerate", "drqa_model.DrQA.forward", "enumerate", "drqa_model.DrQA.extract_predictions", "drqa_model.DrQA.evaluate_predictions", "f1.append", "em.append", "sum", "len", "sum", "len", "len", "drqa_model.reverse", "drqa_model.reverse", "zip", "total_predictions.append"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer.train", "home.repos.pwc.inspect_result.ZJULearning_ReDR.onmt.trainer.Trainer.train", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.forward", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.extract_predictions", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.evaluate_predictions", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.reverse", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.reverse"], ["", "def", "evaluate", "(", "self", ",", "devset", ",", "out_predictions", "=", "False", ")", ":", "\n", "# Train/Eval mode", "\n", "        ", "self", ".", "train", "(", "False", ")", "\n", "# Run forward", "\n", "metrics", "=", "{", "\n", "'f1'", ":", "0.0", ",", "\n", "'em'", ":", "0.0", ",", "\n", "'loss'", ":", "0.0", "\n", "}", "\n", "is_best", "=", "False", "\n", "f1", "=", "[", "]", "\n", "em", "=", "[", "]", "\n", "total_predictions", "=", "[", "]", "\n", "for", "i", ",", "batch", "in", "tqdm", "(", "enumerate", "(", "devset", ")", ",", "total", "=", "len", "(", "devset", ")", ")", ":", "\n", "            ", "if", "self", ".", "args", ".", "debug", "and", "i", ">=", "10", ":", "\n", "                ", "break", "\n", "", "res", "=", "self", ".", "forward", "(", "batch", "=", "batch", ")", "\n", "batch_que", ",", "que_lengths", "=", "batch", ".", "question", "\n", "batch_doc", ",", "doc_lengths", "=", "batch", ".", "context", "\n", "batch_offsets", "=", "batch", ".", "context_offsets", "\n", "batch_answers", "=", "batch", ".", "answers", "\n", "\n", "context_str", "=", "reverse", "(", "self", ".", "vocab", ",", "batch_doc", ")", "[", "1", "]", "\n", "question_str", "=", "reverse", "(", "self", ".", "vocab", ",", "batch_que", ")", "[", "1", "]", "\n", "\n", "score_s", ",", "score_e", "=", "res", "[", "'score_s'", "]", ",", "res", "[", "'score_e'", "]", "\n", "predictions", "=", "res", "[", "'predictions'", "]", "\n", "for", "i", ",", "(", "context", ",", "question", ",", "answers", ",", "pred", ")", "in", "enumerate", "(", "zip", "(", "context_str", ",", "question_str", ",", "\n", "batch_answers", ",", "predictions", ")", ")", ":", "\n", "                ", "total_predictions", ".", "append", "(", "{", "\n", "'passage'", ":", "context", ",", "\n", "'question'", ":", "question", ",", "\n", "'answers'", ":", "answers", ",", "\n", "'prediction'", ":", "pred", "}", ")", "\n", "\n", "", "_pred", ",", "_spans", "=", "self", ".", "extract_predictions", "(", "batch_doc", ",", "batch_offsets", ",", "score_s", ",", "score_e", ")", "\n", "_f1", ",", "_em", "=", "self", ".", "evaluate_predictions", "(", "predictions", ",", "batch_answers", ")", "\n", "f1", ".", "append", "(", "_f1", ")", "\n", "em", ".", "append", "(", "_em", ")", "\n", "", "metrics", "[", "'f1'", "]", "=", "sum", "(", "f1", ")", "/", "len", "(", "f1", ")", "\n", "metrics", "[", "'em'", "]", "=", "sum", "(", "em", ")", "/", "len", "(", "em", ")", "\n", "self", ".", "metrics_history", "[", "'f1'", "]", ".", "append", "(", "metrics", "[", "'f1'", "]", ")", "\n", "self", ".", "metrics_history", "[", "'em'", "]", ".", "append", "(", "metrics", "[", "'em'", "]", ")", "\n", "self", ".", "train", "(", "True", ")", "\n", "if", "self", ".", "best_metrics", "is", "None", "or", "metrics", "[", "'f1'", "]", ">", "self", ".", "best_metrics", "[", "'f1'", "]", ":", "\n", "            ", "self", ".", "best_metrics", "=", "metrics", "\n", "is_best", "=", "True", "\n", "", "return", "{", "'predictions'", ":", "total_predictions", "}", ",", "metrics", ",", "is_best", ",", "self", ".", "metrics_history", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.extract_predictions": [[284, 305], ["score_s.exp().view.exp().view.size", "score_s.exp().view.exp().view.exp().view", "score_e.exp().view.exp().view.exp().view", "enumerate", "drqa_model.reverse", "zip", "predictions.append", "spans.append", "score_s.exp().view.exp().view.exp", "score_e.exp().view.exp().view.exp", "drqa_model.DrQA._scores_to_raw_text", "drqa_model.DrQA._scores_to_text"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.reverse", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA._scores_to_raw_text", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA._scores_to_text"], ["", "def", "extract_predictions", "(", "self", ",", "context", ",", "context_offsets", ",", "score_s", ",", "score_e", ",", "raw_doc", "=", "None", ")", ":", "\n", "# Transfer to CPU/normal tensors for numpy ops (and convert log probabilities to probabilities)", "\n", "        ", "batch_size", "=", "score_s", ".", "size", "(", "0", ")", "\n", "score_s", "=", "score_s", ".", "exp", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "score_e", "=", "score_e", ".", "exp", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "\n", "predictions", "=", "[", "]", "\n", "spans", "=", "[", "]", "\n", "if", "raw_doc", "is", "None", ":", "\n", "            ", "_", ",", "context_text", "=", "reverse", "(", "self", ".", "vocab", ",", "context", ")", "\n", "", "else", ":", "\n", "            ", "context_text", "=", "raw_doc", "\n", "", "for", "i", ",", "(", "_s", ",", "_e", ")", "in", "enumerate", "(", "zip", "(", "score_s", ",", "score_e", ")", ")", ":", "\n", "            ", "if", "self", ".", "args", ".", "predict_raw_text", ":", "\n", "                ", "prediction", ",", "span", "=", "self", ".", "_scores_to_raw_text", "(", "context_text", "[", "i", "]", ",", "\n", "context_offsets", "[", "i", "]", ",", "_s", ",", "_e", ")", "\n", "", "else", ":", "\n", "                ", "prediction", ",", "span", "=", "self", ".", "_scores_to_text", "(", "context_text", "[", "i", "]", ",", "_s", ",", "_e", ")", "\n", "", "predictions", ".", "append", "(", "prediction", ")", "\n", "spans", ".", "append", "(", "span", ")", "\n", "", "return", "predictions", ",", "spans", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA._scores_to_text": [[306, 313], ["torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "scores.cpu().detach().numpy.cpu().detach().numpy.triu_().tril_", "scores.cpu().detach().numpy.cpu().detach().numpy.cpu().detach().numpy", "numpy.unravel_index", "score_s.size", "score_s.squeeze", "score_e.squeeze", "numpy.argmax", "scores.cpu().detach().numpy.cpu().detach().numpy.triu_", "scores.cpu().detach().numpy.cpu().detach().numpy.cpu().detach", "int", "int", "scores.cpu().detach().numpy.cpu().detach().numpy.cpu"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "_scores_to_text", "(", "self", ",", "text", ",", "score_s", ",", "score_e", ")", ":", "\n", "        ", "max_len", "=", "self", ".", "args", ".", "max_answer_len", "or", "score_s", ".", "size", "(", "1", ")", "\n", "scores", "=", "torch", ".", "ger", "(", "score_s", ".", "squeeze", "(", ")", ",", "score_e", ".", "squeeze", "(", ")", ")", "\n", "scores", ".", "triu_", "(", ")", ".", "tril_", "(", "max_len", "-", "1", ")", "\n", "scores", "=", "scores", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "s_idx", ",", "e_idx", "=", "np", ".", "unravel_index", "(", "np", ".", "argmax", "(", "scores", ")", ",", "scores", ".", "shape", ")", "\n", "return", "' '", ".", "join", "(", "text", "[", "s_idx", ":", "e_idx", "+", "1", "]", ")", ",", "(", "int", "(", "s_idx", ")", ",", "int", "(", "e_idx", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA._scores_to_raw_text": [[314, 321], ["torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "scores.cpu().detach().numpy.cpu().detach().numpy.triu_().tril_", "scores.cpu().detach().numpy.cpu().detach().numpy.cpu().detach().numpy", "numpy.unravel_index", "score_s.size", "numpy.argmax", "scores.cpu().detach().numpy.cpu().detach().numpy.triu_", "scores.cpu().detach().numpy.cpu().detach().numpy.cpu().detach", "scores.cpu().detach().numpy.cpu().detach().numpy.cpu"], "methods", ["None"], ["", "def", "_scores_to_raw_text", "(", "self", ",", "raw_text", ",", "offsets", ",", "score_s", ",", "score_e", ")", ":", "\n", "        ", "max_len", "=", "self", ".", "args", ".", "max_answer_len", "or", "score_s", ".", "size", "(", "1", ")", "\n", "scores", "=", "torch", ".", "ger", "(", "score_s", ",", "score_e", ")", "\n", "scores", ".", "triu_", "(", ")", ".", "tril_", "(", "max_len", "-", "1", ")", "\n", "scores", "=", "scores", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "s_idx", ",", "e_idx", "=", "np", ".", "unravel_index", "(", "np", ".", "argmax", "(", "scores", ")", ",", "scores", ".", "shape", ")", "\n", "return", "raw_text", "[", "offsets", "[", "s_idx", "]", "[", "0", "]", ":", "offsets", "[", "e_idx", "]", "[", "1", "]", "]", ",", "(", "offsets", "[", "s_idx", "]", "[", "0", "]", ",", "offsets", "[", "e_idx", "]", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.evaluate_predictions": [[322, 326], ["eval_utils.compute_eval_metric", "eval_utils.compute_eval_metric"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.compute_eval_metric", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.compute_eval_metric"], ["", "def", "evaluate_predictions", "(", "self", ",", "predictions", ",", "answers", ")", ":", "\n", "        ", "f1_score", "=", "compute_eval_metric", "(", "'f1'", ",", "predictions", ",", "answers", ")", "\n", "em_score", "=", "compute_eval_metric", "(", "'em'", ",", "predictions", ",", "answers", ")", "\n", "return", "f1_score", ",", "em_score", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.calc_loss": [[328, 335], ["targets.size", "score_s.size", "score_e.size", "torch.nll_loss", "torch.nll_loss", "torch.nll_loss", "torch.nll_loss", "torch.nll_loss", "torch.nll_loss"], "methods", ["None"], ["", "def", "calc_loss", "(", "self", ",", "results", ",", "batch", ")", ":", "\n", "        ", "targets", "=", "batch", ".", "targets", "\n", "score_s", "=", "results", "[", "'score_s'", "]", "\n", "score_e", "=", "results", "[", "'score_e'", "]", "\n", "assert", "targets", ".", "size", "(", "0", ")", "==", "score_s", ".", "size", "(", "0", ")", "==", "score_e", ".", "size", "(", "0", ")", "\n", "loss", "=", "F", ".", "nll_loss", "(", "score_s", ",", "targets", "[", ":", ",", "0", "]", ")", "+", "F", ".", "nll_loss", "(", "score_e", ",", "targets", "[", ":", ",", "1", "]", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.predict": [[336, 374], ["_NLP", "_NLP", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "drqa_model.DrQA.forward", "tokenized_doc[].append", "tokenized_doc[].append", "tokenized_que[].append", "tokenized_que[].append", "doc_tensor.cuda.cuda.cuda", "doc_length.cuda.cuda.cuda", "que_tensor.cuda.cuda.cuda", "que_length.cuda.cuda.cuda", "offsets_tensor.cuda.cuda.cuda", "eval_utils.compute_eval_metric", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.forward", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.compute_eval_metric"], ["", "def", "predict", "(", "self", ",", "doc", ",", "que", ",", "target", "=", "None", ")", ":", "\n", "        ", "global", "_NLP", "\n", "assert", "_NLP", "is", "not", "None", ",", "\"_NLP is None, whether spacy is available?\"", "\n", "tokenized_doc", "=", "{", "'word'", ":", "[", "]", ",", "'offsets'", ":", "[", "]", "}", "\n", "tokenized_que", "=", "{", "'word'", ":", "[", "]", ",", "'offsets'", ":", "[", "]", "}", "\n", "for", "token", "in", "_NLP", "(", "doc", ")", ":", "\n", "            ", "tokenized_doc", "[", "'word'", "]", ".", "append", "(", "token", ".", "text", ")", "\n", "tokenized_doc", "[", "'offsets'", "]", ".", "append", "(", "(", "token", ".", "idx", ",", "token", ".", "idx", "+", "len", "(", "token", ".", "text", ")", ")", ")", "\n", "", "for", "token", "in", "_NLP", "(", "que", ")", ":", "\n", "            ", "tokenized_que", "[", "'word'", "]", ".", "append", "(", "token", ".", "text", ")", "\n", "tokenized_que", "[", "'offsets'", "]", ".", "append", "(", "(", "token", ".", "idx", ",", "token", ".", "idx", "+", "len", "(", "token", ".", "text", ")", ")", ")", "\n", "\n", "", "doc_ids", "=", "[", "self", ".", "vocab", ".", "stoi", "[", "w", "]", "for", "w", "in", "tokenized_doc", "[", "'word'", "]", "]", "\n", "offsets", "=", "tokenized_doc", "[", "'offsets'", "]", "\n", "que_ids", "=", "[", "self", ".", "vocab", ".", "stoi", "[", "w", "]", "for", "w", "in", "tokenized_que", "[", "'word'", "]", "]", "\n", "\n", "doc_tensor", "=", "torch", ".", "tensor", "(", "[", "doc_ids", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "doc_length", "=", "torch", ".", "tensor", "(", "[", "len", "(", "doc_ids", ")", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "que_tensor", "=", "torch", ".", "tensor", "(", "[", "que_ids", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "que_length", "=", "torch", ".", "tensor", "(", "[", "len", "(", "que_ids", ")", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "offsets_tensor", "=", "torch", ".", "tensor", "(", "[", "offsets", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "self", ".", "gpu", ":", "\n", "            ", "doc_tensor", "=", "doc_tensor", ".", "cuda", "(", ")", "\n", "doc_length", "=", "doc_length", ".", "cuda", "(", ")", "\n", "que_tensor", "=", "que_tensor", ".", "cuda", "(", ")", "\n", "que_length", "=", "que_length", ".", "cuda", "(", ")", "\n", "offsets_tensor", "=", "offsets_tensor", ".", "cuda", "(", ")", "\n", "\n", "", "results", "=", "self", ".", "forward", "(", "\n", "question", "=", "(", "que_tensor", ",", "que_length", ")", ",", "\n", "context", "=", "(", "doc_tensor", ",", "doc_length", ",", "[", "doc", "]", ")", ",", "\n", "context_offsets", "=", "offsets_tensor", ")", "\n", "if", "target", "is", "not", "None", ":", "\n", "            ", "results", "[", "'targets'", "]", "=", "target", "\n", "f1_score", "=", "compute_eval_metric", "(", "'f1'", ",", "results", "[", "\"predictions\"", "]", ",", "[", "[", "target", "]", "]", ")", "\n", "results", "[", "'f1'", "]", "=", "f1_score", "\n", "\n", "", "return", "results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.reverse": [[20, 30], ["rep_list.append", "rep_str.append"], "function", ["None"], ["", "def", "reverse", "(", "vocab", ",", "data", ")", ":", "\n", "    ", "rep_str", "=", "[", "]", "\n", "rep_list", "=", "[", "]", "\n", "for", "ex", "in", "data", ":", "\n", "        ", "l_ex", "=", "[", "vocab", ".", "itos", "[", "idx", "]", "for", "idx", "in", "ex", "if", "vocab", ".", "itos", "[", "idx", "]", "not", "in", "(", "\n", "CONST", ".", "PAD_TOKEN", ",", "CONST", ".", "SOS_TOKEN", ",", "CONST", ".", "EOS_TOKEN", ")", "]", "\n", "s_ex", "=", "' '", ".", "join", "(", "l_ex", ")", "\n", "rep_list", ".", "append", "(", "l_ex", ")", "\n", "rep_str", ".", "append", "(", "s_ex", ")", "\n", "", "return", "rep_list", ",", "rep_str", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.trip_space": [[17, 27], ["len", "len"], "function", ["None"], ["def", "trip_space", "(", "text", ")", ":", "\n", "    ", "start", "=", "0", "\n", "end", "=", "0", "\n", "while", "len", "(", "text", ")", ">", "0", "and", "text", "[", "0", "]", "in", "string", ".", "whitespace", ":", "\n", "        ", "text", "=", "text", "[", "1", ":", "]", "\n", "start", "+=", "1", "\n", "", "while", "len", "(", "text", ")", ">", "0", "and", "text", "[", "-", "1", "]", "in", "string", ".", "whitespace", ":", "\n", "        ", "text", "=", "text", "[", ":", "-", "1", "]", "\n", "end", "-=", "1", "\n", "", "return", "text", ",", "start", ",", "end", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor._str": [[29, 44], ["s.lower", "s.lower", "s.lower", "s.lower", "s.lower", "s.lower"], "function", ["None"], ["", "def", "_str", "(", "s", ")", ":", "\n", "    ", "\"\"\" Convert PTB tokens to normal tokens \"\"\"", "\n", "if", "(", "s", ".", "lower", "(", ")", "==", "'-lrb-'", ")", ":", "\n", "        ", "s", "=", "'('", "\n", "", "elif", "(", "s", ".", "lower", "(", ")", "==", "'-rrb-'", ")", ":", "\n", "        ", "s", "=", "')'", "\n", "", "elif", "(", "s", ".", "lower", "(", ")", "==", "'-lsb-'", ")", ":", "\n", "        ", "s", "=", "'['", "\n", "", "elif", "(", "s", ".", "lower", "(", ")", "==", "'-rsb-'", ")", ":", "\n", "        ", "s", "=", "']'", "\n", "", "elif", "(", "s", ".", "lower", "(", ")", "==", "'-lcb-'", ")", ":", "\n", "        ", "s", "=", "'{'", "\n", "", "elif", "(", "s", ".", "lower", "(", ")", "==", "'-rcb-'", ")", ":", "\n", "        ", "s", "=", "'}'", "\n", "", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.process": [[46, 74], ["_NLP", "output[].append", "output[].append", "output[].append", "text[].strip", "text[].strip", "print", "print", "exit", "len", "len"], "function", ["None"], ["", "def", "process", "(", "text", ",", "require_sents", "=", "False", ")", ":", "\n", "    ", "output", "=", "{", "'word'", ":", "[", "]", ",", "\n", "# 'lemma': [],", "\n", "# 'pos': [],", "\n", "# 'ner': [],", "\n", "'offsets'", ":", "[", "]", "}", "\n", "global", "_NLP", "\n", "doc", "=", "_NLP", "(", "text", ")", "\n", "if", "require_sents", ":", "\n", "        ", "output", "[", "'sent_offsets'", "]", "=", "[", "]", "\n", "for", "sent", "in", "doc", ".", "sents", ":", "\n", "            ", "pre", "=", "0", "\n", "post", "=", "0", "\n", "try", ":", "\n", "                ", "while", "text", "[", "sent", ".", "start_char", "+", "pre", "]", ".", "strip", "(", ")", "==", "\"\"", ":", "\n", "                    ", "pre", "+=", "1", "\n", "", "while", "text", "[", "sent", ".", "end_char", "-", "1", "-", "post", "]", ".", "strip", "(", ")", "==", "\"\"", ":", "\n", "                    ", "post", "+=", "1", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "e", ")", "\n", "print", "(", "text", ",", "len", "(", "text", ")", ",", "sent", ".", "start_char", ",", "sent", ".", "end_char", ",", "pre", ",", "post", ")", "\n", "exit", "(", ")", "\n", "", "output", "[", "'sent_offsets'", "]", ".", "append", "(", "(", "sent", ".", "start_char", "+", "pre", ",", "sent", ".", "end_char", "-", "post", ")", ")", "\n", "", "", "for", "token", "in", "doc", ":", "\n", "# context_token_span = [(w.idx, w.idx + len(w.text)) for w in c_doc]", "\n", "        ", "output", "[", "'word'", "]", ".", "append", "(", "token", ".", "text", ")", "\n", "output", "[", "'offsets'", "]", ".", "append", "(", "(", "token", ".", "idx", ",", "token", ".", "idx", "+", "len", "(", "token", ".", "text", ")", ")", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.normalize_answer": [[76, 94], ["preprocessor.normalize_answer.white_space_fix"], "function", ["None"], ["", "def", "normalize_answer", "(", "s", ")", ":", "\n", "    ", "\"\"\"Lower text and remove punctuation, storys and extra whitespace.\"\"\"", "\n", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "regex", "=", "re", ".", "compile", "(", "r'\\b(a|an|the)\\b'", ",", "re", ".", "UNICODE", ")", "\n", "return", "re", ".", "sub", "(", "regex", ",", "' '", ",", "text", ")", "\n", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.find_ref_span": [[96, 112], ["enumerate"], "function", ["None"], ["", "def", "find_ref_span", "(", "sent_offsets", ",", "target", ")", ":", "\n", "    ", "start", ",", "end", "=", "target", "\n", "ref_start", "=", "-", "1", "\n", "ref_end", "=", "-", "1", "\n", "# ref_start_idx = -1", "\n", "# ref_end_idx = -1", "\n", "for", "i", ",", "(", "sent_start", ",", "sent_end", ")", "in", "enumerate", "(", "sent_offsets", ")", ":", "\n", "# print(target, sent_start, sent_end)", "\n", "        ", "if", "start", ">=", "sent_start", "and", "start", "<=", "sent_end", ":", "\n", "            ", "ref_start", "=", "sent_start", "\n", "# ref_start_idx = i", "\n", "", "if", "end", ">=", "sent_start", "and", "end", "<=", "sent_end", ":", "\n", "            ", "ref_end", "=", "sent_end", "\n", "# ref_end_idx = i", "\n", "", "", "assert", "ref_end", ">=", "ref_start", "and", "ref_end", ">=", "0", "and", "ref_start", ">=", "0", ",", "\"ref span is wrong {}\"", ".", "format", "(", "(", "ref_start", ",", "ref_end", ")", ")", "\n", "return", "ref_start", ",", "ref_end", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.find_span_with_gt": [[114, 137], ["normalize_answer().split", "range", "len", "range", "len", "len", "preprocessor.normalize_answer", "range", "len", "normalize_answer().split", "sum", "len", "context[].lower", "collections.Counter", "collections.Counter", "common.values", "preprocessor.normalize_answer", "len", "len"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.normalize_answer", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.normalize_answer"], ["", "def", "find_span_with_gt", "(", "context", ",", "offsets", ",", "ground_truth", ")", ":", "\n", "    ", "best_f1", "=", "0.0", "\n", "best_span", "=", "(", "len", "(", "offsets", ")", "-", "1", ",", "len", "(", "offsets", ")", "-", "1", ")", "\n", "gt", "=", "normalize_answer", "(", "ground_truth", ")", ".", "split", "(", ")", "\n", "\n", "ls", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "offsets", ")", ")", "\n", "if", "context", "[", "offsets", "[", "i", "]", "[", "0", "]", ":", "offsets", "[", "i", "]", "[", "1", "]", "]", ".", "lower", "(", ")", "in", "gt", "]", "\n", "\n", "best_pred", "=", "None", "\n", "for", "i", "in", "range", "(", "len", "(", "ls", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "i", ",", "len", "(", "ls", ")", ")", ":", "\n", "            ", "pred", "=", "normalize_answer", "(", "context", "[", "offsets", "[", "ls", "[", "i", "]", "]", "[", "0", "]", ":", "offsets", "[", "ls", "[", "j", "]", "]", "[", "1", "]", "]", ")", ".", "split", "(", ")", "\n", "common", "=", "Counter", "(", "pred", ")", "&", "Counter", "(", "gt", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "num_same", ">", "0", ":", "\n", "                ", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "pred", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "gt", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "if", "f1", ">", "best_f1", ":", "\n", "                    ", "best_pred", "=", "pred", "\n", "best_f1", "=", "f1", "\n", "best_span", "=", "(", "ls", "[", "i", "]", ",", "ls", "[", "j", "]", ")", "\n", "", "", "", "", "return", "best_span", ",", "best_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.find_span": [[139, 147], ["enumerate"], "function", ["None"], ["", "def", "find_span", "(", "offsets", ",", "start", ",", "end", ")", ":", "\n", "    ", "start_index", "=", "end_index", "=", "-", "1", "\n", "for", "i", ",", "offset", "in", "enumerate", "(", "offsets", ")", ":", "\n", "        ", "if", "(", "start_index", "<", "0", ")", "or", "(", "start", ">=", "offset", "[", "0", "]", ")", ":", "\n", "            ", "start_index", "=", "i", "\n", "", "if", "(", "end_index", "<", "0", ")", "and", "(", "end", "<=", "offset", "[", "1", "]", ")", ":", "\n", "            ", "end_index", "=", "i", "\n", "", "", "return", "(", "start_index", ",", "end_index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.format_data": [[149, 214], ["open", "temp.append", "temp.extend", "history.append", "examples.append", "question_lens.append", "paragraph_lens.append", "fout.write", "len", "min", "enumerate", "len", "len", "len", "temp.append", "temp.extend", "temp.append", "temp.extend", "len", "len", "len", "len", "json.dumps"], "function", ["None"], ["", "def", "format_data", "(", "dataset", ",", "max_history", ",", "outfile", ")", ":", "\n", "    ", "paragraph_lens", "=", "[", "]", "\n", "question_lens", "=", "[", "]", "\n", "# paragraphs = []", "\n", "examples", "=", "[", "]", "\n", "with", "open", "(", "outfile", ",", "'w'", ")", "as", "fout", ":", "\n", "        ", "for", "paragraph", "in", "dataset", "[", "'data'", "]", ":", "\n", "            ", "history", "=", "[", "]", "\n", "for", "qas", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "                ", "temp", "=", "[", "]", "\n", "n_history", "=", "len", "(", "history", ")", "if", "max_history", "<", "0", "else", "min", "(", "max_history", ",", "len", "(", "history", ")", ")", "\n", "if", "n_history", ">", "0", ":", "\n", "                    ", "for", "i", ",", "(", "q", ",", "a", ")", "in", "enumerate", "(", "history", "[", "-", "n_history", ":", "]", ")", ":", "\n", "                        ", "d", "=", "n_history", "-", "i", "\n", "temp", ".", "append", "(", "'<Q{}>'", ".", "format", "(", "d", ")", ")", "\n", "temp", ".", "extend", "(", "q", ")", "\n", "temp", ".", "append", "(", "'<A{}>'", ".", "format", "(", "d", ")", ")", "\n", "temp", ".", "extend", "(", "a", ")", "\n", "", "", "temp", ".", "append", "(", "'<Q>'", ")", "\n", "temp", ".", "extend", "(", "qas", "[", "'annotated_question'", "]", "[", "'word'", "]", ")", "\n", "history", ".", "append", "(", "(", "qas", "[", "'annotated_question'", "]", "[", "'word'", "]", ",", "qas", "[", "'annotated_answer'", "]", "[", "'word'", "]", ")", ")", "\n", "qas", "[", "'annotated_question'", "]", "[", "'word'", "]", "=", "temp", "\n", "examples", ".", "append", "(", "qas", ")", "\n", "question_lens", ".", "append", "(", "len", "(", "qas", "[", "'annotated_question'", "]", "[", "'word'", "]", ")", ")", "\n", "paragraph_lens", ".", "append", "(", "len", "(", "paragraph", "[", "'annotated_context'", "]", "[", "'word'", "]", ")", ")", "\n", "ref_span", "=", "qas", "[", "'ref_span'", "]", "\n", "span_targets", "=", "qas", "[", "'span_targets'", "]", "\n", "targets_in_span", "=", "(", "qas", "[", "'answer_span'", "]", "[", "0", "]", "-", "span_targets", "[", "0", "]", ",", "\n", "qas", "[", "'answer_span'", "]", "[", "1", "]", "-", "span_targets", "[", "0", "]", ")", "\n", "\n", "question", "=", "qas", "[", "'annotated_question'", "]", "\n", "answers", "=", "[", "qas", "[", "'answer'", "]", "]", "\n", "spans", "=", "[", "qas", "[", "'span'", "]", "]", "\n", "if", "'additional_answers'", "in", "qas", ":", "\n", "                    ", "answers", "=", "answers", "+", "qas", "[", "'additional_answers'", "]", "\n", "spans", "=", "spans", "+", "qas", "[", "'additional_spans'", "]", "\n", "# print(targets_in_span, span_targets)", "\n", "", "assert", "(", "targets_in_span", "[", "0", "]", ">=", "0", "\n", "and", "targets_in_span", "[", "1", "]", ">=", "0", "\n", "and", "targets_in_span", "[", "0", "]", "<=", "len", "(", "qas", "[", "'annotated_span'", "]", "[", "'word'", "]", ")", "\n", "and", "targets_in_span", "[", "1", "]", "<=", "len", "(", "qas", "[", "'annotated_span'", "]", "[", "'word'", "]", ")", ")", "\n", "\n", "assert", "(", "span_targets", "[", "0", "]", ">=", "0", "\n", "and", "span_targets", "[", "1", "]", ">=", "0", "\n", "and", "span_targets", "[", "0", "]", "<=", "len", "(", "paragraph", "[", "'annotated_context'", "]", "[", "'word'", "]", ")", "\n", "and", "span_targets", "[", "1", "]", "<=", "len", "(", "paragraph", "[", "'annotated_context'", "]", "[", "'word'", "]", ")", ")", "\n", "\n", "sample", "=", "{", "'id'", ":", "(", "paragraph", "[", "'id'", "]", ",", "qas", "[", "'turn_id'", "]", ")", ",", "\n", "'question_word'", ":", "question", "[", "'word'", "]", ",", "\n", "# 'question_offsets': [x for sublist in question['offsets'],", "\n", "'question_offsets'", ":", "question", "[", "'offsets'", "]", ",", "\n", "'answers'", ":", "answers", ",", "\n", "'spans'", ":", "spans", ",", "\n", "'context_word'", ":", "paragraph", "[", "'annotated_context'", "]", "[", "'word'", "]", ",", "\n", "# 'context_offsets': [x for sublist in paragraph['annotated_context']['offsets'] for x in sublist],", "\n", "'context_offsets'", ":", "paragraph", "[", "'annotated_context'", "]", "[", "'offsets'", "]", ",", "\n", "'span_word'", ":", "qas", "[", "'annotated_span'", "]", "[", "'word'", "]", ",", "\n", "'span_offsets'", ":", "qas", "[", "'annotated_span'", "]", "[", "'offsets'", "]", ",", "\n", "'raw_context'", ":", "paragraph", "[", "'context'", "]", ",", "\n", "'new_ans'", ":", "None", "if", "'new_ans'", "not", "in", "qas", "else", "qas", "[", "'new_ans'", "]", ",", "\n", "'ref_span'", ":", "ref_span", ",", "\n", "'span_targets'", ":", "span_targets", ",", "\n", "'targets_in_span'", ":", "targets_in_span", ",", "\n", "'targets'", ":", "qas", "[", "'answer_span'", "]", "}", "\n", "fout", ".", "write", "(", "'{}\\n'", ".", "format", "(", "json", ".", "dumps", "(", "sample", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.process_file": [[216, 341], ["time.time", "enumerate", "preprocessor.format_data", "open", "json.load", "preprocessor.process", "[].append", "[].append", "[].append", "zip", "data.append", "open", "json.dump", "print", "len", "len", "datum[].items", "preprocessor.trip_space", "preprocessor.process", "preprocessor.process", "preprocessor.process", "[].append", "[].append", "[].lower", "_qas[].strip().lower", "_datum[].append", "len", "len", "[].lower.find", "preprocessor.find_span", "preprocessor.find_span", "preprocessor.find_span_with_gt", "preprocessor.find_ref_span", "preprocessor.find_span", "preprocessor.process", "len", "len", "len", "len", "len", "len", "len", "len", "len", "_qas[].strip", "new_span[].strip", "repr", "new_span.strip().lower", "len", "additional_answers[].append", "additional_spans[].append", "len", "len", "len", "len", "time.time", "ex[].strip", "new_span.strip"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.format_data", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.process", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.trip_space", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.process", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.process", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.process", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.find_span", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.find_span", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.find_span_with_gt", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.find_ref_span", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.find_span", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.process"], ["", "", "", "", "def", "process_file", "(", "data_file", ",", "output_file", ",", "n_history", ")", ":", "\n", "\n", "    ", "with", "open", "(", "data_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "dataset", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "data", "=", "[", "]", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "datum", "in", "enumerate", "(", "dataset", "[", "'data'", "]", ")", ":", "\n", "        ", "if", "i", "%", "10", "==", "0", ":", "\n", "            ", "print", "(", "'processing %d / %d (used_time = %.2fs)...'", "%", "\n", "(", "i", ",", "len", "(", "dataset", "[", "'data'", "]", ")", ",", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "", "context_str", "=", "datum", "[", "'story'", "]", "\n", "_datum", "=", "{", "'context'", ":", "context_str", ",", "\n", "'source'", ":", "datum", "[", "'source'", "]", ",", "\n", "'id'", ":", "datum", "[", "'id'", "]", ",", "\n", "'filename'", ":", "datum", "[", "'filename'", "]", "}", "\n", "_datum", "[", "'annotated_context'", "]", "=", "process", "(", "context_str", ",", "require_sents", "=", "True", ")", "\n", "_datum", "[", "'qas'", "]", "=", "[", "]", "\n", "_datum", "[", "'context'", "]", "+=", "UNK", "\n", "_datum", "[", "'annotated_context'", "]", "[", "'word'", "]", ".", "append", "(", "UNK", ")", "\n", "_datum", "[", "'annotated_context'", "]", "[", "'offsets'", "]", ".", "append", "(", "\n", "(", "len", "(", "_datum", "[", "'context'", "]", ")", "-", "len", "(", "UNK", ")", ",", "len", "(", "_datum", "[", "'context'", "]", ")", ")", ")", "\n", "_datum", "[", "'annotated_context'", "]", "[", "'sent_offsets'", "]", ".", "append", "(", "(", "len", "(", "_datum", "[", "'context'", "]", ")", "-", "len", "(", "UNK", ")", ",", "len", "(", "_datum", "[", "'context'", "]", ")", ")", ")", "\n", "\n", "assert", "len", "(", "datum", "[", "'questions'", "]", ")", "==", "len", "(", "datum", "[", "'answers'", "]", ")", "\n", "\n", "additional_answers", "=", "{", "}", "\n", "additional_spans", "=", "{", "}", "\n", "if", "'additional_answers'", "in", "datum", ":", "\n", "            ", "for", "k", ",", "answer", "in", "datum", "[", "'additional_answers'", "]", ".", "items", "(", ")", ":", "\n", "                ", "if", "len", "(", "answer", ")", "==", "len", "(", "datum", "[", "'answers'", "]", ")", ":", "\n", "                    ", "for", "ex", "in", "answer", ":", "\n", "                        ", "idx", "=", "ex", "[", "'turn_id'", "]", "\n", "if", "idx", "not", "in", "additional_answers", ":", "\n", "                            ", "additional_answers", "[", "idx", "]", "=", "[", "]", "\n", "additional_spans", "[", "idx", "]", "=", "[", "]", "\n", "", "additional_answers", "[", "idx", "]", ".", "append", "(", "ex", "[", "'input_text'", "]", ")", "\n", "additional_spans", "[", "idx", "]", ".", "append", "(", "ex", "[", "'span_text'", "]", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "", "", "for", "question", ",", "answer", "in", "zip", "(", "datum", "[", "'questions'", "]", ",", "datum", "[", "'answers'", "]", ")", ":", "\n", "# remove space in span text", "\n", "            ", "text", ",", "offset_s", ",", "offset_e", "=", "trip_space", "(", "answer", "[", "'span_text'", "]", ")", "\n", "answer", "[", "'span_text'", "]", "=", "text", "\n", "answer", "[", "'span_start'", "]", "+=", "offset_s", "\n", "answer", "[", "'span_end'", "]", "+=", "offset_e", "\n", "\n", "assert", "question", "[", "'turn_id'", "]", "==", "answer", "[", "'turn_id'", "]", "\n", "idx", "=", "question", "[", "'turn_id'", "]", "\n", "_qas", "=", "{", "'turn_id'", ":", "idx", ",", "\n", "'question'", ":", "question", "[", "'input_text'", "]", ",", "\n", "'span'", ":", "answer", "[", "'span_text'", "]", ",", "\n", "'answer'", ":", "answer", "[", "'input_text'", "]", "}", "\n", "if", "idx", "in", "additional_answers", ":", "\n", "                ", "_qas", "[", "'additional_answers'", "]", "=", "additional_answers", "[", "idx", "]", "\n", "_qas", "[", "'additional_spans'", "]", "=", "additional_spans", "[", "idx", "]", "\n", "\n", "", "_qas", "[", "'annotated_question'", "]", "=", "process", "(", "question", "[", "'input_text'", "]", ")", "\n", "_qas", "[", "'annotated_answer'", "]", "=", "process", "(", "answer", "[", "'input_text'", "]", ")", "\n", "\n", "_qas", "[", "'answer_span_start'", "]", "=", "answer", "[", "'span_start'", "]", "\n", "_qas", "[", "'answer_span_end'", "]", "=", "answer", "[", "'span_end'", "]", "\n", "\n", "_qas", "[", "'annotated_span'", "]", "=", "process", "(", "answer", "[", "'span_text'", "]", ")", "\n", "_qas", "[", "'span'", "]", "+=", "UNK", "\n", "_qas", "[", "'annotated_span'", "]", "[", "'word'", "]", ".", "append", "(", "UNK", ")", "\n", "_qas", "[", "'annotated_span'", "]", "[", "'offsets'", "]", ".", "append", "(", "\n", "(", "len", "(", "_qas", "[", "'span'", "]", ")", "-", "len", "(", "UNK", ")", ",", "len", "(", "_qas", "[", "'span'", "]", ")", ")", ")", "\n", "\n", "start", "=", "answer", "[", "'span_start'", "]", "\n", "end", "=", "answer", "[", "'span_end'", "]", "\n", "chosen_text", "=", "_datum", "[", "'context'", "]", "[", "start", ":", "end", "]", ".", "lower", "(", ")", "\n", "\n", "while", "len", "(", "chosen_text", ")", ">", "0", "and", "chosen_text", "[", "0", "]", "in", "string", ".", "whitespace", ":", "\n", "                ", "chosen_text", "=", "chosen_text", "[", "1", ":", "]", "\n", "start", "+=", "1", "\n", "", "while", "len", "(", "chosen_text", ")", ">", "0", "and", "chosen_text", "[", "-", "1", "]", "in", "string", ".", "whitespace", ":", "\n", "                ", "chosen_text", "=", "chosen_text", "[", ":", "-", "1", "]", "\n", "end", "-=", "1", "\n", "", "input_text", "=", "_qas", "[", "'answer'", "]", ".", "strip", "(", ")", ".", "lower", "(", ")", "\n", "if", "input_text", "in", "chosen_text", ":", "\n", "                ", "i", "=", "chosen_text", ".", "find", "(", "input_text", ")", "\n", "_qas", "[", "'answer_span'", "]", "=", "find_span", "(", "_datum", "[", "'annotated_context'", "]", "[", "'offsets'", "]", ",", "\n", "start", "+", "i", ",", "start", "+", "i", "+", "len", "(", "input_text", ")", ")", "\n", "span_targets", "=", "find_span", "(", "_datum", "[", "'annotated_context'", "]", "[", "'offsets'", "]", ",", "\n", "start", ",", "start", "+", "len", "(", "chosen_text", ")", ")", "\n", "# char index", "\n", "_qas", "[", "'ref_span'", "]", "=", "(", "_qas", "[", "'answer_span_start'", "]", ",", "_qas", "[", "'answer_span_end'", "]", ")", "\n", "# token index", "\n", "_qas", "[", "'span_targets'", "]", "=", "span_targets", "\n", "", "else", ":", "\n", "                ", "_qas", "[", "'answer_span'", "]", ",", "_qas", "[", "'new_ans'", "]", "=", "find_span_with_gt", "(", "_datum", "[", "'context'", "]", ",", "\n", "_datum", "[", "'annotated_context'", "]", "[", "'offsets'", "]", ",", "\n", "input_text", ")", "\n", "sent_offsets", "=", "_datum", "[", "'annotated_context'", "]", "[", "'sent_offsets'", "]", "\n", "answer_ch_span", "=", "(", "_datum", "[", "'annotated_context'", "]", "[", "'offsets'", "]", "[", "_qas", "[", "'answer_span'", "]", "[", "0", "]", "]", "[", "0", "]", ",", "\n", "_datum", "[", "'annotated_context'", "]", "[", "'offsets'", "]", "[", "_qas", "[", "'answer_span'", "]", "[", "1", "]", "]", "[", "1", "]", ")", "\n", "# new_answer_text = _datum['annotated_context']['word'][_qas['answer_span'][0]:_qas['answer_span'][1]+1]", "\n", "ref_span", "=", "find_ref_span", "(", "sent_offsets", ",", "answer_ch_span", ")", "\n", "span_targets", "=", "find_span", "(", "_datum", "[", "'annotated_context'", "]", "[", "'offsets'", "]", ",", "\n", "ref_span", "[", "0", "]", ",", "ref_span", "[", "1", "]", ")", "\n", "new_span", "=", "_datum", "[", "'context'", "]", "[", "ref_span", "[", "0", "]", ":", "ref_span", "[", "1", "]", "]", "\n", "assert", "new_span", "[", "0", "]", ".", "strip", "(", ")", "!=", "''", ",", "\"{} {}\"", ".", "format", "(", "repr", "(", "new_span", ")", ",", "ref_span", ")", "\n", "if", "new_span", ".", "strip", "(", ")", ".", "lower", "(", ")", "==", "'unknown'", ":", "\n", "                    ", "continue", "\n", "", "_qas", "[", "'annotated_span'", "]", "=", "process", "(", "new_span", ")", "\n", "_qas", "[", "'span'", "]", "=", "new_span", "\n", "# _qas['span'] += UNK", "\n", "# _qas['annotated_span']['word'].append(UNK)", "\n", "# _qas['annotated_span']['offsets'].append(", "\n", "#     (len(_qas['span']) - len(UNK), len(_qas['span'])))", "\n", "# char index", "\n", "_qas", "[", "'ref_span'", "]", "=", "ref_span", "\n", "# token index", "\n", "_qas", "[", "'span_targets'", "]", "=", "span_targets", "\n", "", "assert", "(", "_qas", "[", "'answer_span'", "]", "[", "0", "]", ">=", "_qas", "[", "'span_targets'", "]", "[", "0", "]", "\n", "and", "_qas", "[", "'answer_span'", "]", "[", "1", "]", ">=", "_qas", "[", "'span_targets'", "]", "[", "0", "]", ")", ",", "\"{} {}\"", ".", "format", "(", "\n", "_qas", "[", "'answer_span'", "]", ",", "_qas", "[", "'span_targets'", "]", ")", "\n", "_datum", "[", "'qas'", "]", ".", "append", "(", "_qas", ")", "\n", "", "data", ".", "append", "(", "_datum", ")", "\n", "\n", "", "dataset", "[", "'data'", "]", "=", "data", "\n", "with", "open", "(", "output_file", "+", "'.ori'", ",", "'w'", ")", "as", "fout", ":", "\n", "        ", "json", ".", "dump", "(", "dataset", ",", "fout", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", "\n", "", "format_data", "(", "dataset", ",", "n_history", ",", "output_file", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.preprocess": [[343, 356], ["spacy.load", "preprocessor.process_file", "preprocessor.process_file"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.drqa_model.DrQA.load", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.process_file", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.preprocessor.process_file"], ["", "def", "preprocess", "(", "args", ")", ":", "\n", "    ", "import", "spacy", "\n", "global", "_NLP", "\n", "_NLP", "=", "spacy", ".", "load", "(", "'en'", ",", "parser", "=", "False", ")", "\n", "process_file", "(", "\n", "args", ".", "raw_devset_file", ",", "\n", "args", ".", "devset_file", ",", "\n", "args", ".", "n_history", ")", "\n", "\n", "process_file", "(", "\n", "args", ".", "raw_trainset_file", ",", "\n", "args", ".", "trainset_file", ",", "\n", "args", ".", "n_history", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.StackedBRNN.__init__": [[11, 30], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "layers.StackedBRNN.rnns.append", "rnn_type"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "num_layers", ",", "dropout_rate", "=", "0", ",", "\n", "dropout_output", "=", "False", ",", "variational_dropout", "=", "False", ",", "rnn_type", "=", "nn", ".", "LSTM", ",", "\n", "concat_layers", "=", "False", ",", "padding", "=", "False", ",", "bidirectional", "=", "True", ",", "\n", "return_single_timestep", "=", "False", ")", ":", "\n", "        ", "super", "(", "StackedBRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "dropout_output", "=", "dropout_output", "\n", "self", ".", "dropout_rate", "=", "dropout_rate", "\n", "self", ".", "variational_dropout", "=", "variational_dropout", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "concat_layers", "=", "concat_layers", "\n", "self", ".", "return_single_timestep", "=", "return_single_timestep", "\n", "self", ".", "rnns", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "input_size", "=", "input_size", "if", "i", "==", "0", "else", "(", "2", "*", "hidden_size", "if", "bidirectional", "else", "hidden_size", ")", "\n", "self", ".", "rnns", ".", "append", "(", "rnn_type", "(", "input_size", ",", "hidden_size", ",", "\n", "num_layers", "=", "1", ",", "\n", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "bidirectional", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.StackedBRNN.forward": [[31, 40], ["layers.StackedBRNN._forward_unpadded", "layers.StackedBRNN._forward_padded"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.StackedBRNN._forward_unpadded", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.StackedBRNN._forward_padded"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "x_mask", ")", ":", "\n", "        ", "\"\"\"Can choose to either handle or ignore variable length sequences.\n        Always handle padding in eval.\n        \"\"\"", "\n", "# Pad if we care or if its during eval.", "\n", "if", "self", ".", "padding", "or", "self", ".", "return_single_timestep", "or", "not", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "_forward_padded", "(", "x", ",", "x_mask", ")", "\n", "# We don't care.", "\n", "", "return", "self", ".", "_forward_unpadded", "(", "x", ",", "x_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.StackedBRNN._forward_unpadded": [[41, 66], ["range", "layers.dropout", "outputs.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "layers.dropout"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.dropout", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.dropout"], ["", "def", "_forward_unpadded", "(", "self", ",", "x", ",", "x_mask", ")", ":", "\n", "        ", "\"\"\"Faster encoding that ignores any padding.\"\"\"", "\n", "\n", "# Encode all layers", "\n", "outputs", "=", "[", "x", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "rnn_input", "=", "outputs", "[", "-", "1", "]", "\n", "# Apply dropout to hidden input", "\n", "rnn_input", "=", "dropout", "(", "rnn_input", ",", "self", ".", "dropout_rate", ",", "\n", "shared_axes", "=", "[", "1", "]", "if", "self", ".", "variational_dropout", "else", "[", "]", ",", "training", "=", "self", ".", "training", ")", "\n", "# Forward", "\n", "rnn_output", "=", "self", ".", "rnns", "[", "i", "]", "(", "rnn_input", ")", "[", "0", "]", "\n", "outputs", ".", "append", "(", "rnn_output", ")", "\n", "\n", "# Concat hidden layers", "\n", "", "if", "self", ".", "concat_layers", ":", "\n", "            ", "output", "=", "torch", ".", "cat", "(", "outputs", "[", "1", ":", "]", ",", "2", ")", "# Concatenate hiddens at each timestep.", "\n", "", "else", ":", "\n", "            ", "output", "=", "outputs", "[", "-", "1", "]", "# Take only hiddens after final layer (for all timesteps).", "\n", "\n", "# Dropout on output layer", "\n", "", "if", "self", ".", "dropout_output", ":", "\n", "            ", "output", "=", "dropout", "(", "output", ",", "self", ".", "dropout_rate", ",", "\n", "shared_axes", "=", "[", "1", "]", "if", "self", ".", "variational_dropout", "else", "[", "]", ",", "training", "=", "self", ".", "training", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.StackedBRNN._forward_padded": [[67, 113], ["x_mask.eq().long().sum().squeeze", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "list", "x.index_select", "range", "torch.cat.index_select", "torch.cat.index_select", "torch.cat.index_select", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "single_outputs.append", "outputs.append", "layers.dropout", "x_mask.eq().long().sum", "layers.dropout", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_mask.eq().long", "x_mask.eq"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.dropout", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.dropout"], ["", "def", "_forward_padded", "(", "self", ",", "x", ",", "x_mask", ")", ":", "\n", "        ", "\"\"\"Slower (significantly), but more precise,\n        encoding that handles padding.\"\"\"", "\n", "# Compute sorted sequence lengths", "\n", "lengths", "=", "x_mask", ".", "eq", "(", "0", ")", ".", "long", "(", ")", ".", "sum", "(", "1", ")", ".", "squeeze", "(", ")", "\n", "_", ",", "idx_sort", "=", "torch", ".", "sort", "(", "lengths", ",", "dim", "=", "0", ",", "descending", "=", "True", ")", "\n", "_", ",", "idx_unsort", "=", "torch", ".", "sort", "(", "idx_sort", ",", "dim", "=", "0", ")", "\n", "\n", "lengths", "=", "list", "(", "lengths", "[", "idx_sort", "]", ")", "\n", "# Sort x", "\n", "rnn_input", "=", "x", ".", "index_select", "(", "0", ",", "idx_sort", ")", "\n", "\n", "# Encode all layers", "\n", "outputs", ",", "single_outputs", "=", "[", "rnn_input", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "rnn_input", "=", "outputs", "[", "-", "1", "]", "\n", "\n", "# Apply dropout to input", "\n", "if", "self", ".", "dropout_rate", ">", "0", ":", "\n", "                ", "rnn_input", "=", "dropout", "(", "rnn_input", ",", "self", ".", "dropout_rate", ",", "\n", "shared_axes", "=", "[", "1", "]", "if", "self", ".", "variational_dropout", "else", "[", "]", ",", "training", "=", "self", ".", "training", ")", "\n", "# Pack it", "\n", "", "rnn_input", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "rnn_input", ",", "lengths", ",", "batch_first", "=", "True", ")", "\n", "# Run it", "\n", "rnn_output", ",", "(", "hn", ",", "_", ")", "=", "self", ".", "rnns", "[", "i", "]", "(", "rnn_input", ")", "\n", "# Unpack it", "\n", "rnn_output", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "rnn_output", ",", "batch_first", "=", "True", ")", "[", "0", "]", "\n", "single_outputs", ".", "append", "(", "hn", "[", "-", "1", "]", ")", "\n", "outputs", ".", "append", "(", "rnn_output", ")", "\n", "\n", "", "if", "self", ".", "return_single_timestep", ":", "\n", "            ", "output", "=", "single_outputs", "[", "-", "1", "]", "\n", "# Concat hidden layers or take final", "\n", "", "elif", "self", ".", "concat_layers", ":", "\n", "            ", "output", "=", "torch", ".", "cat", "(", "outputs", "[", "1", ":", "]", ",", "2", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "outputs", "[", "-", "1", "]", "\n", "\n", "# Unsort", "\n", "", "output", "=", "output", ".", "index_select", "(", "0", ",", "idx_unsort", ")", "\n", "\n", "# Dropout on output layer", "\n", "if", "self", ".", "dropout_output", "and", "self", ".", "dropout_rate", ">", "0", ":", "\n", "            ", "output", "=", "dropout", "(", "output", ",", "self", ".", "dropout_rate", ",", "\n", "shared_axes", "=", "[", "1", "]", "if", "self", ".", "variational_dropout", "else", "[", "]", ",", "training", "=", "self", ".", "training", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.SeqAttnMatch.__init__": [[120, 126], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "identity", "=", "False", ")", ":", "\n", "        ", "super", "(", "SeqAttnMatch", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "not", "identity", ":", "\n", "            ", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "input_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "linear", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.SeqAttnMatch.forward": [[127, 158], ["torch.relu.bmm", "y_mask.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "F.relu.bmm.masked_fill_", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax.bmm", "layers.SeqAttnMatch.linear().view", "torch.relu", "torch.relu", "torch.relu", "layers.SeqAttnMatch.linear().view", "torch.relu", "torch.relu", "torch.relu", "torch.relu.transpose", "F.relu.bmm.size", "x.size", "y.size", "y_mask.unsqueeze().expand.unsqueeze().expand.unsqueeze", "float", "layers.SeqAttnMatch.linear", "layers.SeqAttnMatch.linear", "x.view", "y.view", "x.size", "y.size"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "y", ",", "y_mask", ")", ":", "\n", "        ", "\"\"\"Input shapes:\n            x = batch * len1 * h  (document)\n            y = batch * len2 * h  (question)\n            y_mask = batch * len2 (question mask)\n        Output shapes:\n            matched_seq = batch * len1 * h\n        \"\"\"", "\n", "# Project vectors", "\n", "if", "self", ".", "linear", ":", "\n", "            ", "x_proj", "=", "self", ".", "linear", "(", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "2", ")", ")", ")", ".", "view", "(", "x", ".", "size", "(", ")", ")", "\n", "x_proj", "=", "F", ".", "relu", "(", "x_proj", ")", "\n", "y_proj", "=", "self", ".", "linear", "(", "y", ".", "view", "(", "-", "1", ",", "y", ".", "size", "(", "2", ")", ")", ")", ".", "view", "(", "y", ".", "size", "(", ")", ")", "\n", "y_proj", "=", "F", ".", "relu", "(", "y_proj", ")", "\n", "", "else", ":", "\n", "            ", "x_proj", "=", "x", "\n", "y_proj", "=", "y", "\n", "\n", "# Compute scores", "\n", "", "scores", "=", "x_proj", ".", "bmm", "(", "y_proj", ".", "transpose", "(", "2", ",", "1", ")", ")", "# (batch, len1, len2)", "\n", "\n", "# Mask padding", "\n", "y_mask", "=", "y_mask", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "scores", ".", "size", "(", ")", ")", "# (batch, len1, len2)", "\n", "scores", ".", "masked_fill_", "(", "y_mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "# Normalize with softmax", "\n", "alpha", "=", "F", ".", "softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Take weighted average", "\n", "matched_seq", "=", "alpha", ".", "bmm", "(", "y", ")", "\n", "return", "matched_seq", "# (batch, len2, h)", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.BilinearSeqAttn.__init__": [[164, 170], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "x_size", ",", "y_size", ",", "identity", "=", "False", ")", ":", "\n", "        ", "super", "(", "BilinearSeqAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "not", "identity", ":", "\n", "            ", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "y_size", ",", "x_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "linear", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.BilinearSeqAttn.forward": [[171, 182], ["x.bmm().squeeze", "x.bmm().squeeze.masked_fill_", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "layers.BilinearSeqAttn.linear", "x.bmm", "float", "Wy.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "y", ",", "x_mask", ")", ":", "\n", "        ", "\"\"\"\n        x = batch * len * h1  (doc_hiddens)\n        y = batch * h2        (question_hidden)\n        x_mask = batch * len  (xd_mask)\n        \"\"\"", "\n", "Wy", "=", "self", ".", "linear", "(", "y", ")", "if", "self", ".", "linear", "is", "not", "None", "else", "y", "\n", "xWy", "=", "x", ".", "bmm", "(", "Wy", ".", "unsqueeze", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "\n", "xWy", ".", "masked_fill_", "(", "x_mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "alpha", "=", "F", ".", "log_softmax", "(", "xWy", ",", "dim", "=", "-", "1", ")", "\n", "return", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.LinearSeqAttn.__init__": [[188, 191], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ")", ":", "\n", "        ", "super", "(", "LinearSeqAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.LinearSeqAttn.forward": [[192, 202], ["x.view", "layers.LinearSeqAttn.linear().view", "layers.LinearSeqAttn.masked_fill_", "torch.softmax", "torch.softmax", "torch.softmax", "x.size", "x.size", "x.size", "layers.LinearSeqAttn.linear", "float"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_mask", ")", ":", "\n", "        ", "\"\"\"\n        x = batch * len * hdim\n        x_mask = batch * len\n        \"\"\"", "\n", "x_flat", "=", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", "\n", "scores", "=", "self", ".", "linear", "(", "x_flat", ")", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ")", "\n", "scores", ".", "masked_fill_", "(", "x_mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "alpha", "=", "F", ".", "softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "\n", "return", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.dropout": [[208, 218], ["list", "x.new().bernoulli_().div_", "mask.expand_as.expand_as", "x.size", "x.new().bernoulli_", "x.new"], "function", ["None"], ["", "", "def", "dropout", "(", "x", ",", "drop_prob", ",", "shared_axes", "=", "[", "]", ",", "training", "=", "False", ")", ":", "\n", "    ", "if", "drop_prob", "==", "0", "or", "(", "not", "training", ")", ":", "\n", "        ", "return", "x", "\n", "\n", "", "sz", "=", "list", "(", "x", ".", "size", "(", ")", ")", "\n", "for", "i", "in", "shared_axes", ":", "\n", "        ", "sz", "[", "i", "]", "=", "1", "\n", "", "mask", "=", "x", ".", "new", "(", "*", "sz", ")", ".", "bernoulli_", "(", "1.", "-", "drop_prob", ")", ".", "div_", "(", "1.", "-", "drop_prob", ")", "\n", "mask", "=", "mask", ".", "expand_as", "(", "x", ")", "\n", "return", "x", "*", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.multi_nll_loss": [[220, 229], ["scores.exp.exp", "range", "scores.exp.size", "torch.neg", "torch.neg", "torch.neg", "torch.log", "torch.log", "torch.log", "torch.masked_select().sum", "torch.masked_select().sum", "torch.masked_select().sum", "scores[].sum", "torch.masked_select", "torch.masked_select", "torch.masked_select"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log", "home.repos.pwc.inspect_result.ZJULearning_ReDR.translate.translation.Translation.log"], ["", "def", "multi_nll_loss", "(", "scores", ",", "target_mask", ")", ":", "\n", "    ", "\"\"\"\n    Select actions with sampling at train-time, argmax at test-time:\n    \"\"\"", "\n", "scores", "=", "scores", ".", "exp", "(", ")", "\n", "loss", "=", "0", "\n", "for", "i", "in", "range", "(", "scores", ".", "size", "(", "0", ")", ")", ":", "\n", "        ", "loss", "+=", "torch", ".", "neg", "(", "torch", ".", "log", "(", "torch", ".", "masked_select", "(", "scores", "[", "i", "]", ",", "target_mask", "[", "i", "]", ")", ".", "sum", "(", ")", "/", "scores", "[", "i", "]", ".", "sum", "(", ")", ")", ")", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.uniform_weights": [[231, 234], ["None"], "function", ["None"], ["", "def", "uniform_weights", "(", "x", ",", "x_mask", ")", ":", "\n", "    ", "\"\"\"Return uniform weights over non-masked input.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.layers.weighted_avg": [[236, 241], ["weights.unsqueeze().bmm().squeeze", "weights.unsqueeze().bmm", "weights.unsqueeze"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.decoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "weighted_avg", "(", "x", ",", "weights", ")", ":", "\n", "    ", "\"\"\"x = batch * len * d\n    weights = batch * len\n    \"\"\"", "\n", "return", "weights", ".", "unsqueeze", "(", "1", ")", ".", "bmm", "(", "x", ")", ".", "squeeze", "(", "1", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.embedding.get_embedding_vectors": [[12, 19], ["torchtext.vocab.GloVe", "NotImplementedError"], "function", ["None"], ["def", "get_embedding_vectors", "(", "directory", ",", "embed_type", ",", "vocab_size", ")", ":", "\n", "    ", "if", "embed_type", "==", "'glove'", ":", "\n", "        ", "vectors", "=", "torchtext", ".", "vocab", ".", "GloVe", "(", "name", "=", "'840B'", ",", "cache", "=", "directory", ",", "dim", "=", "300", ",", "max_vectors", "=", "vocab_size", ")", "\n", "dim", "=", "300", "\n", "return", "vectors", ",", "dim", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Embed type not support. one of [glove] is required\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.__init__": [[32, 38], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "history", "=", "[", "]", "\n", "self", ".", "last", "=", "None", "\n", "self", ".", "val", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.reset": [[39, 45], ["eval_utils.AverageMeter.mean", "eval_utils.AverageMeter.history.append"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.mean"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "last", "=", "self", ".", "mean", "(", ")", "\n", "self", ".", "history", ".", "append", "(", "self", ".", "last", ")", "\n", "self", ".", "val", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.update": [[46, 50], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.mean": [[51, 55], ["None"], "methods", ["None"], ["", "def", "mean", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "count", "==", "0", ":", "\n", "            ", "return", "0.", "\n", "", "return", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.normalize_text": [[12, 28], ["eval_utils.normalize_text.white_space_fix"], "function", ["None"], ["def", "normalize_text", "(", "s", ")", ":", "\n", "    ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "return", "re", ".", "sub", "(", "r'\\b(a|an|the)\\b'", ",", "' '", ",", "text", ")", "\n", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.compute_eval_metric": [[57, 83], ["zip", "numpy.mean", "max", "values.append", "metric_fn", "scores_for_ground_truths.append", "range", "numpy.mean", "eval_utils.compute_eval_metric.metric_max_over_ground_truths"], "function", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.mean", "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.AverageMeter.mean"], ["", "", "def", "compute_eval_metric", "(", "eval_metric", ",", "predictions", ",", "ground_truths", ",", "cross_eval", "=", "True", ")", ":", "\n", "    ", "fns", "=", "{", "'f1'", ":", "compute_f1_score", ",", "\n", "'em'", ":", "compute_em_score", "}", "\n", "\n", "def", "metric_max_over_ground_truths", "(", "metric_fn", ",", "prediction", ",", "ground_truths", ")", ":", "\n", "        ", "scores_for_ground_truths", "=", "[", "]", "\n", "for", "ground_truth", "in", "ground_truths", ":", "\n", "            ", "score", "=", "metric_fn", "(", "normalize_text", "(", "prediction", ")", ",", "normalize_text", "(", "ground_truth", ")", ")", "\n", "scores_for_ground_truths", ".", "append", "(", "score", ")", "\n", "", "return", "max", "(", "scores_for_ground_truths", ")", "\n", "\n", "", "values", "=", "[", "]", "\n", "for", "prediction", ",", "ground_truth_set", "in", "zip", "(", "predictions", ",", "ground_truths", ")", ":", "\n", "        ", "if", "cross_eval", "and", "len", "(", "ground_truth_set", ")", ">", "1", ":", "\n", "            ", "_scores", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "ground_truth_set", ")", ")", ":", "\n", "                ", "_ground_truth_set", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "ground_truth_set", ")", ")", ":", "\n", "                    ", "if", "j", "!=", "i", ":", "\n", "                        ", "_ground_truth_set", ".", "append", "(", "ground_truth_set", "[", "j", "]", ")", "\n", "", "", "_scores", ".", "append", "(", "metric_max_over_ground_truths", "(", "fns", "[", "eval_metric", "]", ",", "prediction", ",", "_ground_truth_set", ")", ")", "\n", "", "value", "=", "np", ".", "mean", "(", "_scores", ")", "\n", "", "else", ":", "\n", "            ", "value", "=", "metric_max_over_ground_truths", "(", "fns", "[", "eval_metric", "]", ",", "prediction", ",", "ground_truth_set", ")", "\n", "", "values", ".", "append", "(", "value", ")", "\n", "", "return", "np", ".", "mean", "(", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.compute_f1_score": [[85, 94], ["sum", "collections.Counter", "collections.Counter", "common.values", "len", "len", "prediction.split", "ground_truth.split", "prediction.split", "ground_truth.split"], "function", ["None"], ["", "def", "compute_f1_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "common", "=", "Counter", "(", "prediction", ".", "split", "(", ")", ")", "&", "Counter", "(", "ground_truth", ".", "split", "(", ")", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "num_same", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "prediction", ".", "split", "(", ")", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "ground_truth", ".", "split", "(", ")", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.eval_utils.compute_em_score": [[96, 98], ["None"], "function", ["None"], ["", "def", "compute_em_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "return", "1.0", "if", "prediction", "==", "ground_truth", "else", "0.0", "\n", "", ""]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__": [[27, 68], ["torch.nn.Module.__init__", "torch.load_url", "torch.load_url", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.LSTM", "torch.nn.LSTM", "cove.MTLSTM.rnn0.load_state_dict", "torch.nn.LSTM", "torch.nn.LSTM", "cove.MTLSTM.rnn1.load_state_dict", "torch.nn.LSTM", "torch.nn.LSTM", "cove.MTLSTM.rnn1.load_state_dict", "ValueError", "torch.load_url.items", "k.replace", "torch.load_url", "torch.load_url", "torch.load_url.items"], "methods", ["home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.__init__", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.load_state_dict", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.load_state_dict", "home.repos.pwc.inspect_result.ZJULearning_ReDR.utils.optimizers.Optimizer.load_state_dict"], ["    ", "def", "__init__", "(", "self", ",", "n_vocab", "=", "None", ",", "vectors", "=", "None", ",", "residual_embeddings", "=", "False", ",", "\n", "layer0", "=", "False", ",", "layer1", "=", "True", ",", "trainable", "=", "False", ",", "model_cache", "=", "MODEL_CACHE", ")", ":", "\n", "        ", "\"\"\"Initialize an MTLSTM. If layer0 and layer1 are True, they are concatenated along the last dimension so that layer0 outputs\n           contribute the first 600 entries and layer1 contributes the second 600 entries. If residual embeddings is also true, inputs\n           are also concatenated along the last dimension with any outputs such that they form the first 300 entries.\n\n        Arguments:\n            n_vocab (int): If not None, initialize MTLSTM with an embedding matrix with n_vocab vectors\n            vectors (Float Tensor): If not None, initialize embedding matrix with specified vectors (These should be 300d CommonCrawl GloVe vectors)\n            residual_embedding (bool): If True, concatenate the input GloVe embeddings with contextualized word vectors as final output\n            layer0 (bool): If True, return the outputs of the first layer of the MTLSTM\n            layer1 (bool): If True, return the outputs of the second layer of the MTLSTM\n            trainable (bool): If True, do not detach outputs; i.e. train the MTLSTM (recommended to leave False)\n            model_cache (str): path to the model file for the MTLSTM to load pretrained weights (defaults to the best MTLSTM from (McCann et al. 2017) --\n                               that MTLSTM was trained with 300d 840B GloVe on the WMT 2017 machine translation dataset.\n        \"\"\"", "\n", "super", "(", "MTLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer0", "=", "layer0", "\n", "self", ".", "layer1", "=", "layer1", "\n", "self", ".", "residual_embeddings", "=", "residual_embeddings", "\n", "self", ".", "trainable", "=", "trainable", "\n", "self", ".", "embed", "=", "False", "\n", "if", "n_vocab", "is", "not", "None", ":", "\n", "            ", "self", ".", "embed", "=", "True", "\n", "self", ".", "vectors", "=", "nn", ".", "Embedding", "(", "n_vocab", ",", "300", ")", "\n", "if", "vectors", "is", "not", "None", ":", "\n", "                ", "self", ".", "vectors", ".", "weight", ".", "data", "=", "vectors", "\n", "", "", "state_dict", "=", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'wmt-lstm'", "]", ",", "model_dir", "=", "model_cache", ")", "\n", "if", "layer0", ":", "\n", "            ", "layer0_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", "if", "'l0'", "in", "k", "}", "\n", "self", ".", "rnn0", "=", "nn", ".", "LSTM", "(", "300", ",", "300", ",", "num_layers", "=", "1", ",", "bidirectional", "=", "True", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "rnn0", ".", "load_state_dict", "(", "layer0_dict", ")", "\n", "if", "layer1", ":", "\n", "                ", "layer1_dict", "=", "{", "k", ".", "replace", "(", "'l1'", ",", "'l0'", ")", ":", "v", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", "if", "'l1'", "in", "k", "}", "\n", "self", ".", "rnn1", "=", "nn", ".", "LSTM", "(", "600", ",", "300", ",", "num_layers", "=", "1", ",", "bidirectional", "=", "True", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "rnn1", ".", "load_state_dict", "(", "layer1_dict", ")", "\n", "", "", "elif", "layer1", ":", "\n", "            ", "self", ".", "rnn1", "=", "nn", ".", "LSTM", "(", "300", ",", "300", ",", "num_layers", "=", "2", ",", "bidirectional", "=", "True", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "rnn1", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'wmt-lstm'", "]", ",", "model_dir", "=", "model_cache", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'At least one of layer0 and layer1 must be True.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ZJULearning_ReDR.clta.cove.MTLSTM.forward": [[69, 108], ["torch.sort", "torch.sort", "torch.sort", "torch.sort", "lens.tolist", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "cove.MTLSTM.vectors", "isinstance", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "cove.MTLSTM.rnn0", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.cat.append", "torch.cat.append", "cove.MTLSTM.rnn1", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.cat.append", "torch.cat.append", "torch.cat.detach", "torch.cat.detach", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cuda.device_of", "torch.cuda.device_of", "torch.cuda.device_of", "torch.cuda.device_of", "lengths.cuda.cuda.cuda", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inputs", ",", "lengths", "=", "None", ",", "mask", "=", "None", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            inputs (Tensor): If MTLSTM handles embedding, a Long Tensor of size (batch_size, timesteps).\n                             Otherwise, a Float Tensor of size (batch_size, timesteps, features).\n            lengths (Long Tensor): lenghts of each sequence for handling padding\n            hidden (Float Tensor): initial hidden state of the LSTM\n        \"\"\"", "\n", "assert", "lengths", "is", "not", "None", "or", "mask", "is", "not", "None", ",", "\"lengths and mask are both none.\"", "\n", "if", "lengths", "is", "None", ":", "\n", "            ", "lengths", "=", "torch", ".", "sum", "(", "1.0", "-", "mask", ",", "dim", "=", "-", "1", ",", "dtype", "=", "torch", ".", "int", ")", "\n", "", "if", "self", ".", "embed", ":", "\n", "            ", "inputs", "=", "self", ".", "vectors", "(", "inputs", ")", "\n", "", "if", "not", "isinstance", "(", "lengths", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "lengths", "=", "torch", ".", "Tensor", "(", "lengths", ")", ".", "long", "(", ")", "\n", "if", "inputs", ".", "is_cuda", ":", "\n", "                ", "with", "torch", ".", "cuda", ".", "device_of", "(", "inputs", ")", ":", "\n", "                    ", "lengths", "=", "lengths", ".", "cuda", "(", "torch", ".", "cuda", ".", "current_device", "(", ")", ")", "\n", "", "", "", "lens", ",", "indices", "=", "torch", ".", "sort", "(", "lengths", ",", "0", ",", "True", ")", "\n", "outputs", "=", "[", "inputs", "]", "if", "self", ".", "residual_embeddings", "else", "[", "]", "\n", "len_list", "=", "lens", ".", "tolist", "(", ")", "\n", "packed_inputs", "=", "pack", "(", "inputs", "[", "indices", "]", ",", "len_list", ",", "batch_first", "=", "True", ")", "\n", "\n", "if", "self", ".", "layer0", ":", "\n", "            ", "outputs0", ",", "hidden_t0", "=", "self", ".", "rnn0", "(", "packed_inputs", ",", "hidden", ")", "\n", "unpacked_outputs0", "=", "unpack", "(", "outputs0", ",", "batch_first", "=", "True", ")", "[", "0", "]", "\n", "_", ",", "_indices", "=", "torch", ".", "sort", "(", "indices", ",", "0", ")", "\n", "unpacked_outputs0", "=", "unpacked_outputs0", "[", "_indices", "]", "\n", "outputs", ".", "append", "(", "unpacked_outputs0", ")", "\n", "packed_inputs", "=", "outputs0", "\n", "", "if", "self", ".", "layer1", ":", "\n", "            ", "outputs1", ",", "hidden_t1", "=", "self", ".", "rnn1", "(", "packed_inputs", ",", "hidden", ")", "\n", "unpacked_outputs1", "=", "unpack", "(", "outputs1", ",", "batch_first", "=", "True", ")", "[", "0", "]", "\n", "_", ",", "_indices", "=", "torch", ".", "sort", "(", "indices", ",", "0", ")", "\n", "unpacked_outputs1", "=", "unpacked_outputs1", "[", "_indices", "]", "\n", "outputs", ".", "append", "(", "unpacked_outputs1", ")", "\n", "\n", "", "outputs", "=", "torch", ".", "cat", "(", "outputs", ",", "2", ")", "\n", "return", "outputs", "if", "self", ".", "trainable", "else", "outputs", ".", "detach", "(", ")", "\n", "\n"]]}