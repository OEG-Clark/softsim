{"home.repos.pwc.inspect_result.fenchri_walk-based-re.src.walk_re_wrapper.ModelWrapper.__init__": [[33, 52], ["loader.ConfigLoader", "loader.ConfigLoader.load_config", "utils.setup_log", "walk_re_wrapper.set_seed", "print", "loader.DataLoader", "train_loader", "dataset.RelationDataset().__call__", "print", "loader.DataLoader", "loader.DataLoader.", "dataset.RelationDataset().__call__", "dataset.RelationDataset", "dataset.RelationDataset"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.ConfigLoader.load_config", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.setup_log", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.walk_re.set_seed", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.__call__", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.__call__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "config", "=", "ConfigLoader", "(", ")", "\n", "self", ".", "parameters", "=", "config", ".", "load_config", "(", ")", "\n", "self", ".", "model_folder", "=", "setup_log", "(", "self", ".", "parameters", ",", "'train'", ")", "\n", "\n", "set_seed", "(", "0", ")", "\n", "\n", "###################################", "\n", "# Data Loading", "\n", "###################################", "\n", "print", "(", "'\\nLoading training data ...'", ")", "\n", "self", ".", "train_loader", "=", "DataLoader", "(", "parameters", "[", "'train_data'", "]", ",", "self", ".", "parameters", ")", "\n", "train_loader", "(", "embeds", "=", "self", ".", "parameters", "[", "'embeds'", "]", ")", "\n", "self", ".", "train_data", "=", "RelationDataset", "(", "train_loader", ",", "'train'", ",", "self", ".", "parameters", "[", "'unk_w_prob'", "]", ",", "train_loader", ")", ".", "__call__", "(", ")", "\n", "\n", "print", "(", "'\\nLoading testing data ...'", ")", "\n", "test_loader", "=", "DataLoader", "(", "self", ".", "parameters", "[", "'test_data'", "]", ",", "parameters", ")", "\n", "test_loader", "(", ")", "\n", "self", ".", "test_data", "=", "RelationDataset", "(", "test_loader", ",", "'test'", ",", "self", ".", "parameters", "[", "'unk_w_prob'", "]", ",", "train_loader", ")", ".", "__call__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.walk_re_wrapper.ModelWrapper.update_hyperparams": [[53, 56], ["params2upd.keys"], "methods", ["None"], ["", "def", "update_hyperparams", "(", "self", ",", "params2upd", ")", ":", "\n", "        ", "for", "item", "in", "params2upd", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "parameters", "[", "item", "]", "=", "params2upd", "[", "item", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.walk_re_wrapper.ModelWrapper.train": [[57, 71], ["nnet.trainer.Trainer", "nnet.trainer.Trainer.run", "nnet.trainer.Trainer.eval_epoch", "utils.save_model", "float", "utils.plot_learning_curve"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.run", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.eval_epoch", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.save_model", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.plot_learning_curve"], ["", "", "def", "train", "(", "self", ")", ":", "\n", "###################################", "\n", "# TRAINING", "\n", "###################################", "\n", "        ", "trainer", "=", "Trainer", "(", "{", "'train'", ":", "self", ".", "train_data", ",", "'test'", ":", "self", ".", "test_data", "}", ",", "\n", "self", ".", "parameters", ",", "self", ".", "train_loader", ",", "self", ".", "model_folder", ")", "\n", "trainer", ".", "run", "(", ")", "\n", "\n", "trainer", ".", "eval_epoch", "(", "final", "=", "True", ",", "save_predictions", "=", "True", ")", "\n", "save_model", "(", "model_folder", ",", "trainer", ".", "model", ",", "train_loader", ")", "\n", "if", "parameters", "[", "'plot'", "]", ":", "\n", "            ", "plot_learning_curve", "(", "trainer", ",", "model_folder", ")", "\n", "\n", "", "return", "float", "(", "trainer", ".", "best_score", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.walk_re_wrapper.set_seed": [[22, 30], ["torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all", "numpy.random.seed", "random.seed"], "function", ["None"], ["def", "set_seed", "(", "seed", ")", ":", "\n", "    ", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "# if you are using multi-GPU", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "# Numpy module", "\n", "random", ".", "seed", "(", "seed", ")", "# Python random module", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "False", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.converter.to_device": [[8, 12], ["torch.as_tensor().long().to", "torch.as_tensor().long", "torch.as_tensor().long", "torch.as_tensor", "torch.as_tensor"], "function", ["None"], ["def", "to_device", "(", "device", ",", "x", ")", ":", "\n", "    ", "if", "device", "is", "None", ":", "\n", "        ", "return", "torch", ".", "as_tensor", "(", "x", ")", ".", "long", "(", ")", "\n", "", "return", "torch", ".", "as_tensor", "(", "x", ")", ".", "long", "(", ")", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.converter.concat_examples": [[14, 45], ["isinstance", "isinstance", "len", "ValueError", "six.moves.range", "tuple", "isinstance", "isinstance", "len", "result.append", "converter.to_device", "len", "converter.to_device", "isinstance", "converter.to_device", "converter._concat_arrays", "converter._concat_arrays", "converter._concat_arrays"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.converter.to_device", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.converter.to_device", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.converter.to_device", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.converter._concat_arrays", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.converter._concat_arrays", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.converter._concat_arrays"], ["", "def", "concat_examples", "(", "batch", ",", "device", "=", "None", ",", "padding", "=", "-", "1", ")", ":", "\n", "    ", "assert", "device", "is", "None", "or", "isinstance", "(", "device", ",", "torch", ".", "device", ")", "\n", "if", "len", "(", "batch", ")", "==", "0", ":", "\n", "        ", "raise", "ValueError", "(", "'batch is empty'", ")", "\n", "\n", "", "first_elem", "=", "batch", "[", "0", "]", "\n", "\n", "if", "isinstance", "(", "first_elem", ",", "tuple", ")", ":", "\n", "        ", "result", "=", "[", "]", "\n", "if", "not", "isinstance", "(", "padding", ",", "tuple", ")", ":", "\n", "            ", "padding", "=", "[", "padding", "]", "*", "len", "(", "first_elem", ")", "\n", "\n", "", "for", "i", "in", "six", ".", "moves", ".", "range", "(", "len", "(", "first_elem", ")", ")", ":", "\n", "            ", "result", ".", "append", "(", "to_device", "(", "device", ",", "_concat_arrays", "(", "\n", "[", "example", "[", "i", "]", "for", "example", "in", "batch", "]", ",", "padding", "[", "i", "]", ")", ")", ")", "\n", "\n", "", "return", "tuple", "(", "result", ")", "\n", "\n", "", "elif", "isinstance", "(", "first_elem", ",", "dict", ")", ":", "\n", "        ", "result", "=", "{", "}", "\n", "if", "not", "isinstance", "(", "padding", ",", "dict", ")", ":", "\n", "            ", "padding", "=", "{", "key", ":", "padding", "for", "key", "in", "first_elem", "}", "\n", "\n", "", "for", "key", "in", "first_elem", ":", "\n", "            ", "result", "[", "key", "]", "=", "to_device", "(", "device", ",", "_concat_arrays", "(", "\n", "[", "example", "[", "key", "]", "for", "example", "in", "batch", "]", ",", "padding", "[", "key", "]", ")", ")", "\n", "\n", "", "return", "result", "\n", "\n", "", "else", ":", "\n", "        ", "return", "to_device", "(", "device", ",", "_concat_arrays", "(", "batch", ",", "padding", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.converter._concat_arrays": [[47, 60], ["converter._concat_arrays_with_padding", "numpy.concatenate"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.converter._concat_arrays_with_padding"], ["", "", "def", "_concat_arrays", "(", "arrays", ",", "padding", ")", ":", "\n", "# Convert `arrays` to numpy.ndarray if `arrays` consists of the built-in", "\n", "# types such as int, float or list.", "\n", "\n", "# if not isinstance(arrays[0], type(torch.get_default_dtype())):", "\n", "#    arrays = numpy.asarray(arrays)", "\n", "\n", "    ", "if", "padding", "is", "not", "None", ":", "\n", "        ", "arr_concat", "=", "_concat_arrays_with_padding", "(", "arrays", ",", "padding", ")", "\n", "", "else", ":", "\n", "        ", "arr_concat", "=", "numpy", ".", "concatenate", "(", "[", "array", "[", "None", "]", "for", "array", "in", "arrays", "]", ")", "\n", "\n", "", "return", "arr_concat", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.converter._concat_arrays_with_padding": [[62, 76], ["numpy.array", "tuple", "numpy.full", "six.moves.range", "numpy.any", "numpy.insert", "len", "tuple", "numpy.maximum", "len", "slice"], "function", ["None"], ["", "def", "_concat_arrays_with_padding", "(", "arrays", ",", "padding", ")", ":", "\n", "    ", "shape", "=", "numpy", ".", "array", "(", "arrays", "[", "0", "]", ".", "shape", ",", "dtype", "=", "int", ")", "\n", "for", "array", "in", "arrays", "[", "1", ":", "]", ":", "\n", "        ", "if", "numpy", ".", "any", "(", "shape", "!=", "array", ".", "shape", ")", ":", "\n", "            ", "numpy", ".", "maximum", "(", "shape", ",", "array", ".", "shape", ",", "shape", ")", "\n", "", "", "shape", "=", "tuple", "(", "numpy", ".", "insert", "(", "shape", ",", "0", ",", "len", "(", "arrays", ")", ")", ")", "\n", "\n", "result", "=", "numpy", ".", "full", "(", "shape", ",", "padding", ",", "dtype", "=", "arrays", "[", "0", "]", ".", "dtype", ")", "\n", "for", "i", "in", "six", ".", "moves", ".", "range", "(", "len", "(", "arrays", ")", ")", ":", "\n", "        ", "src", "=", "arrays", "[", "i", "]", "\n", "slices", "=", "tuple", "(", "slice", "(", "dim", ")", "for", "dim", "in", "src", ".", "shape", ")", "\n", "result", "[", "(", "i", ",", ")", "+", "slices", "]", "=", "src", "\n", "\n", "", "return", "result", "\n", "", ""]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.hyperparam_tuning.objective_function": [[21, 42], ["collections.OrderedDict", "model_wrapper.update_hyperparams", "model_wrapper.train", "len", "len"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.walk_re_wrapper.ModelWrapper.update_hyperparams", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.walk_re.train"], ["def", "objective_function", "(", "params", ")", ":", "\n", "    ", "\"\"\" \n    Function to optimize\n    \"\"\"", "\n", "named_params", "=", "OrderedDict", "(", ")", "\n", "if", "len", "(", "params", ")", "==", "5", ":", "\n", "        ", "named_params", "[", "'lr'", "]", "=", "params", "[", "0", "]", "\n", "named_params", "[", "'reg'", "]", "=", "params", "[", "1", "]", "\n", "named_params", "[", "'dropi'", "]", "=", "params", "[", "2", "]", "\n", "named_params", "[", "'dropo'", "]", "=", "params", "[", "3", "]", "\n", "named_params", "[", "'gradc'", "]", "=", "params", "[", "4", "]", "\n", "", "elif", "len", "(", "params", ")", "==", "6", ":", "\n", "        ", "named_params", "[", "'lr'", "]", "=", "params", "[", "0", "]", "\n", "named_params", "[", "'reg'", "]", "=", "params", "[", "1", "]", "\n", "named_params", "[", "'dropi'", "]", "=", "params", "[", "2", "]", "\n", "named_params", "[", "'dropo'", "]", "=", "params", "[", "3", "]", "\n", "named_params", "[", "'gradc'", "]", "=", "params", "[", "4", "]", "\n", "named_params", "[", "'beta'", "]", "=", "params", "[", "5", "]", "\n", "", "model_wrapper", ".", "update_hyperparams", "(", "named_params", ")", "\n", "score", "=", "model_wrapper", ".", "train", "(", ")", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.hyperparam_tuning.bayes_opt": [[44, 85], ["print", "print", "robo.fmin.bayesian_optimization", "print", "print", "print"], "function", ["None"], ["", "def", "bayes_opt", "(", ")", ":", "\n", "    ", "\"\"\" \n    Bayesian Optimization with RoBO.\n    Returns dictionary with results:\n        \"x_opt\" : the best found data point\n        \"f_opt\" : the corresponding function value\n        \"incumbents\": the incumbent (best found value) after each iteration\n        \"incumbent_value\": the function values of the incumbents\n        \"runtime\": the runtime in seconds after each iteration\n        \"overhead\": the optimization overhead \n                    (i.e. time data we do not spend to evaluate the function) \n                    of each iteration\n        \"X\": all data points that have been evaluated\n        \"y\": the corresponding function evaluations\n    \"\"\"", "\n", "print", "(", "'\\n============= START Bayesian OPTIMIZATION =============\\n'", ")", "\n", "print", "(", "\"\"\"Optimization parameters:\n                    - lower = {}\n                    - upper = {}\n                    - num_iter = {}\n                    - maximizer = {}\n                    - acq_func = {}\n                    - model_type = {} \n                    - n_init = {} \"\"\"", ".", "format", "(", "lower", ",", "upper", ",", "\n", "args", ".", "num_iterations", ",", "\n", "args", ".", "maximizer", ",", "\n", "args", ".", "acquisition_func", ",", "\n", "args", ".", "model_type", ",", "\n", "args", ".", "n_init", ")", ")", "\n", "\n", "results", "=", "bayesian_optimization", "(", "objective_function", ",", "\n", "lower", ",", "\n", "upper", ",", "\n", "num_iterations", "=", "args", ".", "num_iterations", ",", "\n", "maximizer", "=", "args", ".", "maximizer", ",", "\n", "acquisition_func", "=", "args", ".", "acquisition_func", ",", "\n", "model_type", "=", "args", ".", "model_type", ",", "\n", "n_init", "=", "args", ".", "n_init", ")", "\n", "print", "(", "results", "[", "\"x_opt\"", "]", ")", "\n", "print", "(", "results", "[", "\"f_opt\"", "]", ")", "\n", "print", "(", "'\\n============= END OPTIMIZATION =============\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.hyperparam_tuning.ent_search": [[87, 113], ["print", "print", "robo.fmin.entropy_search", "print", "print", "print"], "function", ["None"], ["", "def", "ent_search", "(", ")", ":", "\n", "    ", "\"\"\"\n    Entropy search\n    \"\"\"", "\n", "print", "(", "'\\n============= START Entropy Search OPTIMIZATION =============\\n'", ")", "\n", "print", "(", "\"\"\"Optimization parameters:\n                    - lower = {}\n                    - upper = {}\n                    - num_iter = {}\n                    - maximizer = {}\n                    - model_type = {} \n                    - n_init = {} \"\"\"", ".", "format", "(", "lower", ",", "upper", ",", "\n", "args", ".", "num_iterations", ",", "\n", "args", ".", "maximizer", ",", "\n", "args", ".", "model_type", ",", "\n", "args", ".", "n_init", ")", ")", "\n", "\n", "results", "=", "entropy_search", "(", "objective_function", ",", "\n", "lower", ",", "\n", "upper", ",", "\n", "num_iterations", "=", "args", ".", "num_iterations", ",", "\n", "maximizer", "=", "args", ".", "maximizer", ",", "\n", "model", "=", "args", ".", "model_type", ")", "\n", "print", "(", "results", "[", "\"x_opt\"", "]", ")", "\n", "print", "(", "results", "[", "\"f_opt\"", "]", ")", "\n", "print", "(", "'\\n============= END OPTIMIZATION =============\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.hyperparam_tuning.rand_search": [[115, 133], ["print", "print", "robo.fmin.random_search", "print", "print", "print"], "function", ["None"], ["", "def", "rand_search", "(", ")", ":", "\n", "    ", "\"\"\"\n    Random search\n    \"\"\"", "\n", "print", "(", "'\\n============= START Random Search OPTIMIZATION =============\\n'", ")", "\n", "print", "(", "\"\"\"Optimization parameters:\n                    - lower = {}\n                    - upper = {}\n                    - num_iter = {}\"\"\"", ".", "format", "(", "lower", ",", "upper", ",", "\n", "args", ".", "num_iterations", ")", ")", "\n", "\n", "results", "=", "random_search", "(", "objective_function", ",", "\n", "lower", ",", "\n", "upper", ",", "\n", "num_iterations", "=", "args", ".", "num_iterations", ")", "\n", "print", "(", "results", "[", "\"x_opt\"", "]", ")", "\n", "print", "(", "results", "[", "\"f_opt\"", "]", ")", "\n", "print", "(", "'\\n============= END OPTIMIZATION =============\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.hyperparam_tuning.boham": [[135, 160], ["print", "print", "robo.fmin.bohamiann", "print", "print", "print"], "function", ["None"], ["", "def", "boham", "(", ")", ":", "\n", "    ", "\"\"\"\n    Bayesian Networks\n    \"\"\"", "\n", "print", "(", "'\\n============= START Bohamiann OPTIMIZATION =============\\n'", ")", "\n", "print", "(", "\"\"\"Optimization parameters:\n                    - lower = {}\n                    - upper = {}\n                    - num_iter = {}\n                    - maximizer = {}\n                    - acq_func = {}\"\"\"", ".", "format", "(", "lower", ",", "\n", "upper", ",", "\n", "args", ".", "num_iterations", ",", "\n", "args", ".", "maximizer", ",", "\n", "args", ".", "acquisition_func", ")", ")", "\n", "\n", "results", "=", "bohamiann", "(", "objective_function", ",", "\n", "lower", ",", "\n", "upper", ",", "\n", "num_iterations", "=", "args", ".", "num_iterations", ",", "\n", "maximizer", "=", "args", ".", "maximizer", ",", "\n", "acquisition_func", "=", "args", ".", "acquisition_func", ")", "\n", "print", "(", "results", "[", "\"x_opt\"", "]", ")", "\n", "print", "(", "results", "[", "\"f_opt\"", "]", ")", "\n", "print", "(", "'\\n============= END OPTIMIZATION =============\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.hyperparam_tuning.main": [[162, 208], ["walk_re_wrapper.ModelWrapper", "logging.basicConfig", "np.array", "np.array", "np.array", "np.array", "hyperparam_tuning.bayes_opt", "hyperparam_tuning.rand_search", "hyperparam_tuning.ent_search", "hyperparam_tuning.boham"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.hyperparam_tuning.bayes_opt", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.hyperparam_tuning.rand_search", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.hyperparam_tuning.ent_search", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.hyperparam_tuning.boham"], ["", "def", "main", "(", ")", ":", "\n", "    ", "global", "args", ",", "lower", ",", "upper", ",", "iter_i", "\n", "model_wrapper", "=", "ModelWrapper", "(", ")", "\n", "args", "=", "model_wrapper", ".", "args", "\n", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "\n", "iter_i", "=", "0", "\n", "\"\"\"\n    Parameters search space:\n         learn | reg | dropi | dropo | gradc | beta \n    \"\"\"", "\n", "if", "args", ".", "walks_iter", ">", "0", ":", "\n", "        ", "lower", "=", "np", ".", "array", "(", "[", "0.001", ",", "# learn", "\n", "0.0000001", ",", "# reg", "\n", "0.0", ",", "# dropi", "\n", "0.0", ",", "# dropo", "\n", "5", ",", "# gradc", "\n", "0.5", "]", ")", "# beta", "\n", "\n", "upper", "=", "np", ".", "array", "(", "[", "0.003", ",", "# learn", "\n", "0.0001", ",", "# reg", "\n", "0.5", ",", "# dropi", "\n", "0.5", ",", "# dropo", "\n", "30", ",", "# gradc", "\n", "0.9", "]", ")", "# beta", "\n", "", "else", ":", "\n", "        ", "lower", "=", "np", ".", "array", "(", "[", "0.001", ",", "# learn", "\n", "0.0000001", ",", "# reg", "\n", "0.0", ",", "# dropi", "\n", "0.0", ",", "# dropo", "\n", "5", "]", ")", "# gradc", "\n", "\n", "upper", "=", "np", ".", "array", "(", "[", "0.003", ",", "# learn", "\n", "0.0001", ",", "# reg", "\n", "0.5", ",", "# dropi", "\n", "0.5", ",", "# dropo", "\n", "30", "]", ")", "# gradc", "\n", "\n", "", "if", "args", ".", "opt_method", "==", "'BayesOpt'", ":", "\n", "        ", "bayes_opt", "(", ")", "\n", "", "elif", "args", ".", "opt_method", "==", "'RandomSearch'", ":", "\n", "        ", "rand_search", "(", ")", "\n", "", "elif", "args", ".", "opt_method", "==", "'EntropySearch'", ":", "\n", "        ", "ent_search", "(", ")", "\n", "", "elif", "args", ".", "opt_method", "==", "'Bohamiann'", ":", "\n", "        ", "boham", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.dataset.RelationDataset.__init__": [[27, 33], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "loader", ",", "data_type", ",", "unk_w_prob", ",", "mappings", ")", ":", "\n", "        ", "self", ".", "unk_w_prob", "=", "unk_w_prob", "\n", "self", ".", "mappings", "=", "mappings", "\n", "self", ".", "loader", "=", "loader", "\n", "self", ".", "data_type", "=", "data_type", "\n", "self", ".", "data", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.dataset.RelationDataset.__call__": [[34, 180], ["tqdm.tqdm.tqdm", "dataset.RelationDataset.loader.sentences.keys", "tqdm.tqdm.tqdm.set_description", "numpy.array", "enumerate", "numpy.array", "list", "numpy.empty", "enumerate", "numpy.sum", "numpy.meshgrid", "numpy.empty", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "list", "numpy.array().reshape", "numpy.meshgrid", "numpy.arange", "numpy.empty", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "list", "numpy.array().reshape", "sum", "sum", "enumerate", "enumerate", "len", "len", "len", "len", "dataset.RelationDataset.loader.entities[].values", "dataset.RelationDataset.loader.entities[].keys", "numpy.ones", "numpy.ones", "dataset.RelationDataset.loader.pairs[].values", "numpy.arange", "numpy.arange", "map", "numpy.arange", "numpy.arange", "len", "map", "collections.OrderedDict", "dataset.RelationDataset.data_type.upper", "len", "len", "int", "numpy.array().reshape.ravel().tolist", "numpy.array", "len", "len", "numpy.array().reshape.ravel().tolist", "numpy.array", "len", "word.lower.lower.lower", "word.lower.lower.lower", "len", "len", "len", "len", "int", "numpy.arange", "numpy.arange", "numpy.array", "numpy.array", "dataset.RelationDataset.loader.rel2count.items", "dataset.RelationDataset.loader.rel2count.items", "random.uniform", "float", "int", "int", "int", "int", "list.index", "list.index", "list.index", "list.index", "numpy.array().reshape.ravel", "numpy.array().reshape.ravel", "len", "list.index", "list.index", "list.index", "list.index", "list.index", "list.index", "list.index", "list.index", "list.index", "list.index", "list.index", "list.index", "r.type.split", "r.type.split", "r.type.split"], "methods", ["None"], ["", "def", "__call__", "(", "self", ")", ":", "\n", "        ", "pbar", "=", "tqdm", "(", "self", ".", "loader", ".", "sentences", ".", "keys", "(", ")", ")", "\n", "\n", "all_l2r", "=", "0", "\n", "for", "pmid", "in", "pbar", ":", "\n", "            ", "pbar", ".", "set_description", "(", "'  Preparing {} data - Sentence ID {}'", ".", "format", "(", "self", ".", "data_type", ".", "upper", "(", ")", ",", "pmid", ")", ")", "\n", "\n", "# TEXT", "\n", "if", "self", ".", "data_type", "==", "'train'", ":", "\n", "                ", "sent", "=", "[", "]", "\n", "for", "w", ",", "word", "in", "enumerate", "(", "self", ".", "loader", ".", "sentences", "[", "pmid", "]", ")", ":", "\n", "                    ", "if", "self", ".", "loader", ".", "lower", ":", "\n", "                        ", "word", "=", "word", ".", "lower", "(", ")", "# make lowercase", "\n", "\n", "", "if", "(", "word", "in", "self", ".", "mappings", ".", "singletons", ")", "and", "(", "random", ".", "uniform", "(", "0", ",", "1", ")", "<", "float", "(", "self", ".", "unk_w_prob", ")", ")", ":", "\n", "                        ", "sent", "+=", "[", "self", ".", "mappings", ".", "word2index", "[", "'<UNK>'", "]", "]", "# UNK words = singletons", "\n", "", "else", ":", "\n", "                        ", "sent", "+=", "[", "self", ".", "mappings", ".", "word2index", "[", "word", "]", "]", "\n", "\n", "", "", "", "else", ":", "\n", "                ", "sent", "=", "[", "]", "\n", "for", "w", ",", "word", "in", "enumerate", "(", "self", ".", "loader", ".", "sentences", "[", "pmid", "]", ")", ":", "\n", "                    ", "if", "self", ".", "loader", ".", "lower", ":", "\n", "                        ", "word", "=", "word", ".", "lower", "(", ")", "# make lowercase", "\n", "\n", "", "if", "word", "in", "self", ".", "mappings", ".", "word2index", ":", "\n", "                        ", "sent", "+=", "[", "self", ".", "mappings", ".", "word2index", "[", "word", "]", "]", "\n", "", "else", ":", "\n", "                        ", "sent", "+=", "[", "self", ".", "mappings", ".", "word2index", "[", "'<UNK>'", "]", "]", "\n", "", "", "", "assert", "len", "(", "self", ".", "loader", ".", "sentences", "[", "pmid", "]", ")", "==", "len", "(", "sent", ")", ",", "'{}, {}'", ".", "format", "(", "len", "(", "sentence", ")", ",", "len", "(", "sent", ")", ")", "\n", "sent", "=", "np", ".", "array", "(", "sent", ",", "'i'", ")", "\n", "\n", "# ENTITIES [id, type, start, end]", "\n", "ent", "=", "[", "]", "\n", "for", "id_", ",", "e", "in", "enumerate", "(", "self", ".", "loader", ".", "entities", "[", "pmid", "]", ".", "values", "(", ")", ")", ":", "\n", "                ", "if", "e", ".", "type", "not", "in", "self", ".", "mappings", ".", "type2index", ":", "\n", "# print('Entity type not found', e.type)", "\n", "                    ", "ent", "+=", "[", "[", "id_", ",", "-", "1", ",", "int", "(", "e", ".", "start", ")", ",", "int", "(", "e", ".", "end", ")", "]", "]", "\n", "", "else", ":", "\n", "                    ", "ent", "+=", "[", "[", "id_", ",", "self", ".", "mappings", ".", "type2index", "[", "e", ".", "type", "]", ",", "int", "(", "e", ".", "start", ")", ",", "int", "(", "e", ".", "end", ")", "]", "]", "\n", "", "", "ent", "=", "np", ".", "array", "(", "ent", ",", "'i'", ")", "\n", "\n", "# RELATIONS", "\n", "ents_keys", "=", "list", "(", "self", ".", "loader", ".", "entities", "[", "pmid", "]", ".", "keys", "(", ")", ")", "# in order", "\n", "true_rels", "=", "-", "1", "*", "np", ".", "ones", "(", "(", "len", "(", "ents_keys", ")", ",", "len", "(", "ents_keys", ")", ")", ",", "'i'", ")", "\n", "rel_info", "=", "np", ".", "empty", "(", "(", "len", "(", "ents_keys", ")", ",", "len", "(", "ents_keys", ")", ")", ",", "dtype", "=", "'object_'", ")", "\n", "l2r", "=", "-", "1", "*", "np", ".", "ones", "(", "(", "len", "(", "ents_keys", ")", ",", "len", "(", "ents_keys", ")", ")", ",", "'i'", ")", "\n", "for", "id_", ",", "r", "in", "enumerate", "(", "self", ".", "loader", ".", "pairs", "[", "pmid", "]", ".", "values", "(", ")", ")", ":", "\n", "\n", "                ", "true_rels", "[", "ents_keys", ".", "index", "(", "r", ".", "arg1", ")", ",", "ents_keys", ".", "index", "(", "r", ".", "arg2", ")", "]", "=", "self", ".", "mappings", ".", "rel2index", "[", "r", ".", "type", "]", "\n", "rel_info", "[", "ents_keys", ".", "index", "(", "r", ".", "arg1", ")", ",", "\n", "ents_keys", ".", "index", "(", "r", ".", "arg2", ")", "]", "=", "{", "'pmid'", ":", "pmid", ",", "\n", "'doc'", ":", "self", ".", "loader", ".", "sentences", "[", "pmid", "]", ",", "\n", "'entA'", ":", "self", ".", "loader", ".", "entities", "[", "pmid", "]", "[", "r", ".", "arg1", "]", ",", "\n", "'entB'", ":", "self", ".", "loader", ".", "entities", "[", "pmid", "]", "[", "r", ".", "arg2", "]", ",", "\n", "'rel'", ":", "self", ".", "mappings", ".", "rel2index", "[", "r", ".", "type", "]", ",", "\n", "'dir'", ":", "r", ".", "direction", "}", "\n", "\n", "# inverse", "\n", "if", "r", ".", "type", "!=", "'1:NR:2'", ":", "\n", "                    ", "r_type_", "=", "self", ".", "mappings", ".", "rel2index", "[", "r", ".", "type", ".", "split", "(", "':'", ")", "[", "2", "]", "+", "':'", "+", "\n", "r", ".", "type", ".", "split", "(", "':'", ")", "[", "1", "]", "+", "':'", "+", "\n", "r", ".", "type", ".", "split", "(", "':'", ")", "[", "0", "]", "]", "\n", "true_rels", "[", "ents_keys", ".", "index", "(", "r", ".", "arg2", ")", ",", "ents_keys", ".", "index", "(", "r", ".", "arg1", ")", "]", "=", "r_type_", "\n", "rel_info", "[", "ents_keys", ".", "index", "(", "r", ".", "arg2", ")", ",", "\n", "ents_keys", ".", "index", "(", "r", ".", "arg1", ")", "]", "=", "{", "'pmid'", ":", "pmid", ",", "\n", "'doc'", ":", "self", ".", "loader", ".", "sentences", "[", "pmid", "]", ",", "\n", "'entA'", ":", "self", ".", "loader", ".", "entities", "[", "pmid", "]", "[", "r", ".", "arg2", "]", ",", "\n", "'entB'", ":", "self", ".", "loader", ".", "entities", "[", "pmid", "]", "[", "r", ".", "arg1", "]", ",", "\n", "'rel'", ":", "r_type_", ",", "\n", "'dir'", ":", "r", ".", "direction", "}", "\n", "", "else", ":", "\n", "                    ", "true_rels", "[", "ents_keys", ".", "index", "(", "r", ".", "arg2", ")", ",", "ents_keys", ".", "index", "(", "r", ".", "arg1", ")", "]", "=", "self", ".", "mappings", ".", "rel2index", "[", "r", ".", "type", "]", "\n", "rel_info", "[", "ents_keys", ".", "index", "(", "r", ".", "arg2", ")", ",", "\n", "ents_keys", ".", "index", "(", "r", ".", "arg1", ")", "]", "=", "{", "'pmid'", ":", "pmid", ",", "\n", "'doc'", ":", "self", ".", "loader", ".", "sentences", "[", "pmid", "]", ",", "\n", "'entA'", ":", "self", ".", "loader", ".", "entities", "[", "pmid", "]", "[", "r", ".", "arg2", "]", ",", "\n", "'entB'", ":", "self", ".", "loader", ".", "entities", "[", "pmid", "]", "[", "r", ".", "arg1", "]", ",", "\n", "'rel'", ":", "self", ".", "mappings", ".", "rel2index", "[", "r", ".", "type", "]", ",", "\n", "'dir'", ":", "r", ".", "direction", "}", "\n", "\n", "", "if", "int", "(", "self", ".", "loader", ".", "entities", "[", "pmid", "]", "[", "r", ".", "arg1", "]", ".", "end", ")", "-", "1", "<=", "int", "(", "self", ".", "loader", ".", "entities", "[", "pmid", "]", "[", "r", ".", "arg2", "]", ".", "start", ")", ":", "\n", "                    ", "l2r", "[", "ents_keys", ".", "index", "(", "r", ".", "arg1", ")", ",", "ents_keys", ".", "index", "(", "r", ".", "arg2", ")", "]", "=", "1", "\n", "", "else", ":", "\n", "                    ", "l2r", "[", "ents_keys", ".", "index", "(", "r", ".", "arg2", ")", ",", "ents_keys", ".", "index", "(", "r", ".", "arg1", ")", "]", "=", "1", "\n", "\n", "", "", "all_l2r", "+=", "np", ".", "sum", "(", "l2r", "!=", "-", "1", ")", "\n", "\n", "# POSITIONS", "\n", "# Create edge distances", "\n", "\n", "# entity-entity dist", "\n", "xv", ",", "yv", "=", "np", ".", "meshgrid", "(", "np", ".", "arange", "(", "ent", ".", "shape", "[", "0", "]", ")", ",", "np", ".", "arange", "(", "ent", ".", "shape", "[", "0", "]", ")", ",", "indexing", "=", "'ij'", ")", "\n", "dist_ee", "=", "np", ".", "empty", "(", "(", "ent", ".", "shape", "[", "0", "]", ",", "ent", ".", "shape", "[", "0", "]", ")", ",", "'i'", ")", "\n", "\n", "a_start", ",", "a_end", "=", "ent", "[", "xv", ",", "2", "]", ",", "ent", "[", "xv", ",", "3", "]", "-", "1", "\n", "b_start", ",", "b_end", "=", "ent", "[", "yv", ",", "2", "]", ",", "ent", "[", "yv", ",", "3", "]", "-", "1", "\n", "\n", "dist_ee", "=", "np", ".", "where", "(", "(", "a_end", "<", "b_start", ")", "&", "(", "b_start", "!=", "-", "1", ")", "&", "(", "a_end", "!=", "-", "1", ")", ",", "b_start", "-", "a_end", ",", "dist_ee", ")", "\n", "dist_ee", "=", "np", ".", "where", "(", "(", "b_end", "<", "a_start", ")", "&", "(", "b_end", "!=", "-", "1", ")", "&", "(", "a_start", "!=", "-", "1", ")", ",", "b_end", "-", "a_start", ",", "dist_ee", ")", "\n", "\n", "# limit max distance according to training set", "\n", "dist_ee", "=", "np", ".", "where", "(", "dist_ee", ">", "self", ".", "mappings", ".", "max_distance", ",", "self", ".", "mappings", ".", "max_distance", ",", "dist_ee", ")", "\n", "dist_ee", "=", "np", ".", "where", "(", "dist_ee", "<", "self", ".", "mappings", ".", "min_distance", ",", "self", ".", "mappings", ".", "min_distance", ",", "dist_ee", ")", "\n", "\n", "dist_ee", "=", "np", ".", "where", "(", "(", "b_start", "<=", "a_start", ")", "&", "(", "b_end", ">=", "a_end", ")", "# a is inside", "\n", "&", "(", "b_start", "!=", "-", "1", ")", "&", "(", "a_end", "!=", "-", "1", ")", "&", "(", "b_end", "!=", "-", "1", ")", "&", "(", "a_start", "!=", "-", "1", ")", ",", "'inside'", ",", "dist_ee", ")", "\n", "dist_ee", "=", "np", ".", "where", "(", "(", "b_start", ">=", "a_start", ")", "&", "(", "b_end", "<=", "a_end", ")", "# a is outside", "\n", "&", "(", "b_start", "!=", "-", "1", ")", "&", "(", "a_end", "!=", "-", "1", ")", "&", "(", "b_end", "!=", "-", "1", ")", "&", "(", "a_start", "!=", "-", "1", ")", ",", "'outside'", ",", "dist_ee", ")", "\n", "dist_ee", "[", "np", ".", "arange", "(", "ent", ".", "shape", "[", "0", "]", ")", ",", "np", ".", "arange", "(", "ent", ".", "shape", "[", "0", "]", ")", "]", "=", "'0'", "# diagonal to zero", "\n", "\n", "dist_ee", "=", "list", "(", "map", "(", "lambda", "y", ":", "self", ".", "mappings", ".", "pos2index", "[", "y", "]", ",", "dist_ee", ".", "ravel", "(", ")", ".", "tolist", "(", ")", ")", ")", "# map", "\n", "dist_ee", "=", "np", ".", "array", "(", "dist_ee", ",", "'i'", ")", ".", "reshape", "(", "(", "ent", ".", "shape", "[", "0", "]", ",", "ent", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n", "# entity-token dist", "\n", "xz", ",", "yz", "=", "np", ".", "meshgrid", "(", "np", ".", "arange", "(", "ent", ".", "shape", "[", "0", "]", ")", ",", "np", ".", "arange", "(", "len", "(", "self", ".", "loader", ".", "sentences", "[", "pmid", "]", ")", ")", ",", "indexing", "=", "'ij'", ")", "\n", "tokens", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "loader", ".", "sentences", "[", "pmid", "]", ")", ")", "\n", "\n", "dist_et", "=", "np", ".", "empty", "(", "(", "ent", ".", "shape", "[", "0", "]", ",", "len", "(", "self", ".", "loader", ".", "sentences", "[", "pmid", "]", ")", ")", ",", "'i'", ")", "\n", "a_start", ",", "a_end", "=", "ent", "[", "xz", ",", "2", "]", ",", "ent", "[", "xz", ",", "3", "]", "-", "1", "\n", "b_start", ",", "b_end", "=", "tokens", "[", "yz", "]", ",", "tokens", "[", "yz", "]", "\n", "\n", "dist_et", "=", "np", ".", "where", "(", "(", "a_end", "<", "b_start", ")", "&", "(", "b_start", "!=", "-", "1", ")", "&", "(", "a_end", "!=", "-", "1", ")", ",", "b_start", "-", "a_end", ",", "dist_et", ")", "\n", "dist_et", "=", "np", ".", "where", "(", "(", "b_end", "<", "a_start", ")", "&", "(", "b_end", "!=", "-", "1", ")", "&", "(", "a_start", "!=", "-", "1", ")", ",", "b_end", "-", "a_start", ",", "dist_et", ")", "\n", "\n", "# limit max distance according to training set", "\n", "dist_et", "=", "np", ".", "where", "(", "dist_et", ">", "self", ".", "mappings", ".", "max_distance", ",", "self", ".", "mappings", ".", "max_distance", ",", "dist_et", ")", "\n", "dist_et", "=", "np", ".", "where", "(", "dist_et", "<", "self", ".", "mappings", ".", "min_distance", ",", "self", ".", "mappings", ".", "min_distance", ",", "dist_et", ")", "\n", "\n", "dist_et", "=", "np", ".", "where", "(", "(", "b_start", "<=", "a_start", ")", "&", "(", "b_end", ">=", "a_end", ")", "\n", "&", "(", "b_start", "!=", "-", "1", ")", "&", "(", "a_end", "!=", "-", "1", ")", "&", "(", "b_end", "!=", "-", "1", ")", "&", "(", "a_start", "!=", "-", "1", ")", ",", "'0'", ",", "dist_et", ")", "\n", "dist_et", "=", "np", ".", "where", "(", "(", "b_start", ">=", "a_start", ")", "&", "(", "b_end", "<=", "a_end", ")", "\n", "&", "(", "b_start", "!=", "-", "1", ")", "&", "(", "a_end", "!=", "-", "1", ")", "&", "(", "b_end", "!=", "-", "1", ")", "&", "(", "a_start", "!=", "-", "1", ")", ",", "'0'", ",", "dist_et", ")", "\n", "\n", "dist_et", "=", "list", "(", "map", "(", "lambda", "y", ":", "self", ".", "mappings", ".", "pos2index", "[", "y", "]", ",", "dist_et", ".", "ravel", "(", ")", ".", "tolist", "(", ")", ")", ")", "\n", "dist_et", "=", "np", ".", "array", "(", "dist_et", ",", "'i'", ")", ".", "reshape", "(", "(", "ent", ".", "shape", "[", "0", "]", ",", "len", "(", "self", ".", "loader", ".", "sentences", "[", "pmid", "]", ")", ")", ")", "\n", "\n", "self", ".", "data", "+=", "[", "OrderedDict", "(", "{", "'sentId'", ":", "pmid", ",", "'text'", ":", "sent", ",", "'ents'", ":", "ent", ",", "'rels'", ":", "true_rels", ",", "\n", "'pos_ee'", ":", "dist_ee", ",", "'pos_et'", ":", "dist_et", ",", "'info'", ":", "rel_info", ",", "\n", "'word'", ":", "np", ".", "array", "(", "len", "(", "self", ".", "loader", ".", "sentences", "[", "pmid", "]", ")", ",", "'i'", ")", ",", "\n", "'entity'", ":", "np", ".", "array", "(", "ent", ".", "shape", "[", "0", "]", ",", "'i'", ")", ",", "\n", "'l2r'", ":", "l2r", "}", ")", "]", "\n", "", "assert", "all_l2r", "==", "sum", "(", "[", "v", "for", "k", ",", "v", "in", "self", ".", "loader", ".", "rel2count", ".", "items", "(", ")", "]", ")", ",", "'{} <> {}'", ".", "format", "(", "all_l2r", ",", "sum", "(", "[", "v", "for", "k", ",", "v", "in", "self", ".", "loader", ".", "rel2count", ".", "items", "(", ")", "]", ")", ")", "\n", "\n", "return", "self", ".", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.dataset.RelationDataset.__len__": [[181, 183], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.walk_re.set_seed": [[21, 29], ["torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all", "numpy.random.seed", "random.seed"], "function", ["None"], ["def", "set_seed", "(", "seed", ")", ":", "\n", "    ", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "# if you are using multi-GPU", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "# Numpy module", "\n", "random", ".", "seed", "(", "seed", ")", "# Python random module", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "False", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.walk_re.train": [[31, 58], ["utils.setup_log", "walk_re.set_seed", "print", "loader.DataLoader", "loader.DataLoader.", "dataset.RelationDataset().__call__", "print", "loader.DataLoader", "loader.DataLoader.", "dataset.RelationDataset().__call__", "nnet.trainer.Trainer", "nnet.trainer.Trainer.run", "nnet.trainer.Trainer.eval_epoch", "utils.plot_learning_curve", "dataset.RelationDataset", "dataset.RelationDataset"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.setup_log", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.walk_re.set_seed", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.__call__", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.__call__", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.run", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.eval_epoch", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.plot_learning_curve"], ["", "def", "train", "(", "parameters", ")", ":", "\n", "    ", "model_folder", "=", "setup_log", "(", "parameters", ",", "'train'", ")", "\n", "\n", "set_seed", "(", "0", ")", "\n", "\n", "###################################", "\n", "# Data Loading", "\n", "###################################", "\n", "print", "(", "'\\nLoading training data ...'", ")", "\n", "train_loader", "=", "DataLoader", "(", "parameters", "[", "'train_data'", "]", ",", "parameters", ")", "\n", "train_loader", "(", "embeds", "=", "parameters", "[", "'embeds'", "]", ")", "\n", "train_data", "=", "RelationDataset", "(", "train_loader", ",", "'train'", ",", "parameters", "[", "'unk_w_prob'", "]", ",", "train_loader", ")", ".", "__call__", "(", ")", "\n", "\n", "print", "(", "'\\nLoading testing data ...'", ")", "\n", "test_loader", "=", "DataLoader", "(", "parameters", "[", "'test_data'", "]", ",", "parameters", ")", "\n", "test_loader", "(", ")", "\n", "test_data", "=", "RelationDataset", "(", "test_loader", ",", "'test'", ",", "parameters", "[", "'unk_w_prob'", "]", ",", "train_loader", ")", ".", "__call__", "(", ")", "\n", "\n", "###################################", "\n", "# TRAINING", "\n", "###################################", "\n", "trainer", "=", "Trainer", "(", "{", "'train'", ":", "train_data", ",", "'test'", ":", "test_data", "}", ",", "parameters", ",", "train_loader", ",", "model_folder", ")", "\n", "trainer", ".", "run", "(", ")", "\n", "\n", "trainer", ".", "eval_epoch", "(", "final", "=", "True", ",", "save_predictions", "=", "True", ")", "\n", "if", "parameters", "[", "'plot'", "]", ":", "\n", "        ", "plot_learning_curve", "(", "trainer", ",", "model_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.walk_re.test": [[60, 76], ["print", "utils.setup_log", "print", "print", "loader.DataLoader", "loader.DataLoader.__call__", "dataset.RelationDataset().__call__", "nnet.trainer.Trainer", "utils.load_model", "utils.load_model.eval_epoch", "open", "pickle.load", "os.path.join", "dataset.RelationDataset"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.setup_log", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.__call__", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.__call__", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.load_model", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.eval_epoch"], ["", "", "def", "test", "(", "parameters", ")", ":", "\n", "    ", "print", "(", "'*** Testing Model ***'", ")", "\n", "model_folder", "=", "setup_log", "(", "parameters", ",", "'test'", ")", "\n", "\n", "print", "(", "'Loading mappings ...'", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "model_folder", ",", "'mappings.pkl'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "loader", "=", "pkl", ".", "load", "(", "f", ")", "\n", "\n", "", "print", "(", "'Loading testing data ...'", ")", "\n", "test_loader", "=", "DataLoader", "(", "parameters", "[", "'test_data'", "]", ",", "parameters", ")", "\n", "test_loader", ".", "__call__", "(", ")", "\n", "test_data", "=", "RelationDataset", "(", "test_loader", ",", "'test'", ",", "parameters", "[", "'unk_w_prob'", "]", ",", "loader", ")", ".", "__call__", "(", ")", "\n", "\n", "m", "=", "Trainer", "(", "{", "'train'", ":", "[", "]", ",", "'test'", ":", "test_data", "}", ",", "parameters", ",", "loader", ",", "model_folder", ")", "\n", "trainer", "=", "load_model", "(", "model_folder", ",", "m", ")", "\n", "trainer", ".", "eval_epoch", "(", "final", "=", "True", ",", "save_predictions", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.walk_re.main": [[78, 87], ["loader.ConfigLoader", "loader.ConfigLoader.load_config", "walk_re.train", "walk_re.test"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.ConfigLoader.load_config", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.walk_re.train", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.walk_re.test"], ["", "def", "main", "(", ")", ":", "\n", "    ", "config", "=", "ConfigLoader", "(", ")", "\n", "parameters", "=", "config", ".", "load_config", "(", ")", "\n", "\n", "if", "parameters", "[", "'train'", "]", ":", "\n", "        ", "train", "(", "parameters", ")", "\n", "\n", "", "elif", "parameters", "[", "'test'", "]", ":", "\n", "        ", "test", "(", "parameters", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.__init__": [[42, 44], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "*", "files", ")", ":", "\n", "        ", "self", ".", "files", "=", "files", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write": [[45, 49], ["f_.write", "f_.flush"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.flush"], ["", "def", "write", "(", "self", ",", "obj", ")", ":", "\n", "        ", "for", "f_", "in", "self", ".", "files", ":", "\n", "            ", "f_", ".", "write", "(", "obj", ")", "\n", "f_", ".", "flush", "(", ")", "# If you want the output to be visible immediately", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.flush": [[50, 53], ["f_.flush"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.flush"], ["", "", "def", "flush", "(", "self", ")", ":", "\n", "        ", "for", "f_", "in", "self", ".", "files", ":", "\n", "            ", "f_", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.setup_log": [[22, 39], ["os.path.join", "os.path.join", "open", "utils.Tee", "os.path.exists", "os.makedirs"], "function", ["None"], ["def", "setup_log", "(", "params", ",", "mode", ")", ":", "\n", "    ", "if", "params", "[", "'walks_iter'", "]", "==", "0", ":", "\n", "        ", "length", "=", "1", "\n", "", "else", ":", "\n", "        ", "length", "=", "2", "**", "params", "[", "'walks_iter'", "]", "\n", "", "folder_name", "=", "'beta{}-walks{}-att_{}-dir_{}'", ".", "format", "(", "\n", "params", "[", "'beta'", "]", ",", "\n", "length", ",", "params", "[", "'att'", "]", ",", "params", "[", "'direction'", "]", ")", "\n", "\n", "model_folder", "=", "os", ".", "path", ".", "join", "(", "params", "[", "'folder'", "]", ",", "folder_name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "model_folder", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "model_folder", ")", "\n", "", "log_file", "=", "os", ".", "path", ".", "join", "(", "model_folder", ",", "'info_'", "+", "mode", "+", "'.log'", ")", "\n", "\n", "f", "=", "open", "(", "log_file", ",", "'w'", ")", "\n", "sys", ".", "stdout", "=", "Tee", "(", "sys", ".", "stdout", ",", "f", ")", "\n", "return", "model_folder", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.ordered_load": [[55, 71], ["OrderedLoader.add_constructor", "yaml.load", "loader.flatten_mapping", "object_pairs_hook", "loader_.construct_pairs"], "function", ["None"], ["", "", "", "def", "ordered_load", "(", "stream", ",", "loader", "=", "yaml", ".", "Loader", ",", "object_pairs_hook", "=", "OrderedDict", ")", ":", "\n", "    ", "\"\"\"\n    Load yaml parameters in order\n    \"\"\"", "\n", "class", "OrderedLoader", "(", "loader", ")", ":", "\n", "        ", "pass", "\n", "\n", "", "def", "construct_mapping", "(", "loader_", ",", "node", ")", ":", "\n", "        ", "loader", ".", "flatten_mapping", "(", "node", ")", "\n", "return", "object_pairs_hook", "(", "loader_", ".", "construct_pairs", "(", "node", ")", ")", "\n", "\n", "", "OrderedLoader", ".", "add_constructor", "(", "\n", "yaml", ".", "resolver", ".", "BaseResolver", ".", "DEFAULT_MAPPING_TAG", ",", "\n", "construct_mapping", ")", "\n", "\n", "return", "yaml", ".", "load", "(", "stream", ",", "OrderedLoader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.humanized_time": [[73, 82], ["divmod", "divmod"], "function", ["None"], ["", "def", "humanized_time", "(", "second", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        second: time in seconds\n    Returns: human readable time (hours, minutes, seconds)\n    \"\"\"", "\n", "m", ",", "s", "=", "divmod", "(", "second", ",", "60", ")", "\n", "h", ",", "m", "=", "divmod", "(", "m", ",", "60", ")", "\n", "return", "\"%dh %02dm %02ds\"", "%", "(", "h", ",", "m", ",", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.observe": [[84, 98], ["model.namedparams", "print", "numpy.min", "numpy.max", "numpy.min", "numpy.max", "chainer.cuda.to_cpu", "chainer.cuda.to_cpu", "chainer.cuda.to_cpu", "chainer.cuda.to_cpu"], "function", ["None"], ["", "def", "observe", "(", "model", ")", ":", "\n", "    ", "\"\"\"\n    Observe model parameters: name, range of matrices & gradients\n\n    Args:\n        model: specified model object\n    \"\"\"", "\n", "for", "p_name", ",", "param", "in", "model", ".", "namedparams", "(", ")", ":", "\n", "        ", "p_data", ",", "p_grad", "=", "param", ".", "data", ",", "param", ".", "grad", "\n", "print", "(", "'Name: %s, Range of data: [%f, %f], Range of gradient: [%f, %f]'", "%", "\n", "(", "p_name", ",", "np", ".", "min", "(", "chainer", ".", "cuda", ".", "to_cpu", "(", "p_data", ".", "data", ")", ")", ",", "\n", "np", ".", "max", "(", "chainer", ".", "cuda", ".", "to_cpu", "(", "p_data", ".", "data", ")", ")", ",", "\n", "np", ".", "min", "(", "chainer", ".", "cuda", ".", "to_cpu", "(", "p_grad", ".", "data", ")", ")", ",", "\n", "np", ".", "max", "(", "chainer", ".", "cuda", ".", "to_cpu", "(", "p_grad", ".", "data", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.plot_learning_curve": [[100, 130], ["print", "list", "matplotlib.figure", "matplotlib.subplot", "matplotlib.plot", "matplotlib.plot", "matplotlib.legend", "matplotlib.ylabel", "matplotlib.yticks", "matplotlib.xticks", "matplotlib.subplot", "matplotlib.plot", "matplotlib.plot", "matplotlib.legend", "matplotlib.ylabel", "matplotlib.xlabel", "matplotlib.yticks", "matplotlib.xticks", "plt.figure.savefig", "print", "map", "numpy.arange", "numpy.arange", "numpy.arange", "len"], "function", ["None"], ["", "", "def", "plot_learning_curve", "(", "trainer", ",", "model_folder", ")", ":", "\n", "    ", "\"\"\"\n    Plot the learning curves for training and test set (loss and primary score measure)\n\n    Args:\n        trainer (Class): trainer object\n        model_folder (str): folder to save figures\n    \"\"\"", "\n", "print", "(", "'Plotting learning curves ... '", ",", "end", "=", "\"\"", ")", "\n", "x", "=", "list", "(", "map", "(", "int", ",", "np", ".", "arange", "(", "len", "(", "trainer", ".", "train_res", "[", "'loss'", "]", ")", ")", ")", ")", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "subplot", "(", "2", ",", "1", ",", "1", ")", "\n", "plt", ".", "plot", "(", "x", ",", "trainer", ".", "train_res", "[", "'loss'", "]", ",", "'b'", ",", "label", "=", "'train'", ")", "\n", "plt", ".", "plot", "(", "x", ",", "trainer", ".", "test_res", "[", "'loss'", "]", ",", "'g'", ",", "label", "=", "'test'", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "ylabel", "(", "'Loss'", ")", "\n", "plt", ".", "yticks", "(", "np", ".", "arange", "(", "0", ",", "1", ",", "0.1", ")", ")", "\n", "plt", ".", "xticks", "(", "x", ")", "\n", "\n", "plt", ".", "subplot", "(", "2", ",", "1", ",", "2", ")", "\n", "plt", ".", "plot", "(", "x", ",", "trainer", ".", "train_res", "[", "'score'", "]", ",", "'b'", ",", "label", "=", "'train'", ")", "\n", "plt", ".", "plot", "(", "x", ",", "trainer", ".", "test_res", "[", "'score'", "]", ",", "'g'", ",", "label", "=", "'test'", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "ylabel", "(", "'F1-score'", ")", "\n", "plt", ".", "xlabel", "(", "'Epochs'", ")", "\n", "plt", ".", "yticks", "(", "np", ".", "arange", "(", "0", ",", "1", ",", "0.1", ")", ")", "\n", "plt", ".", "xticks", "(", "x", ")", "\n", "\n", "fig", ".", "savefig", "(", "model_folder", "+", "'/learn_curves.png'", ",", "bbox_inches", "=", "'tight'", ")", "\n", "print", "(", "'END'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.print_hyperparams": [[132, 151], ["print"], "function", ["None"], ["", "def", "print_hyperparams", "(", "model_0", ")", ":", "\n", "    ", "print", "(", "\"\"\"\\nModel hyper-parameters:\n                - learn   {}\n                - reg     {}\n                - dropi   {}\n                - dropo   {}\n                - type    {}\n                - pos     {}\n                - gradc   {} \n                - out_dim {}\n                - beta    {} \"\"\"", ".", "format", "(", "model_0", ".", "lr", ",", "\n", "model_0", ".", "reg", ",", "\n", "model_0", ".", "dropi", ",", "\n", "model_0", ".", "dropo", ",", "\n", "model_0", ".", "type_dim", ",", "\n", "model_0", ".", "pos_dim", ",", "\n", "model_0", ".", "gc", ",", "\n", "model_0", ".", "out_dim", ",", "\n", "model_0", ".", "beta", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.print_options": [[153, 177], ["print"], "function", ["None"], ["", "def", "print_options", "(", "model_0", ",", "parameters", ")", ":", "\n", "    ", "print", "(", "\"\"\"\\nModel options:\n             - Train Data  {}\n             - Test Data   {}\n             - Embeddings  {}\n             - Save folder {}\n             - batchsize   {}\n\n             - walks_iter   {} --> Length = {}\n             - att          {}\n             - param_avg    {}\n             - nested       {}\n             - early_metric {}\n             - direction    {}\n             - lowercase    {}\\n\"\"\"", ".", "format", "(", "parameters", "[", "'train_data'", "]", ",", "parameters", "[", "'test_data'", "]", ",", "\n", "parameters", "[", "'embeds'", "]", ",", "parameters", "[", "'folder'", "]", ",", "\n", "parameters", "[", "'batch'", "]", ",", "\n", "model_0", ".", "walks_iter", ",", "2", "**", "parameters", "[", "'walks_iter'", "]", ",", "\n", "model_0", ".", "att", ",", "\n", "parameters", "[", "'param_avg'", "]", ",", "\n", "parameters", "[", "'nested'", "]", ",", "\n", "parameters", "[", "'early_metric'", "]", ",", "\n", "parameters", "[", "'direction'", "]", ",", "\n", "parameters", "[", "'lowercase'", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.save_model": [[179, 185], ["print", "torch.save", "print", "open", "pickle.dump", "model_0.state_dict", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "save_model", "(", "model_folder", ",", "model_0", ",", "loader", ")", ":", "\n", "    ", "print", "(", "'Saving the model ... '", ",", "end", "=", "\"\"", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "model_folder", ",", "'mappings.pkl'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pkl", ".", "dump", "(", "loader", ",", "f", ",", "pkl", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "torch", ".", "save", "(", "model_0", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "model_folder", ",", "'re.model'", ")", ")", "\n", "print", "(", "'END'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.load_model": [[187, 192], ["print", "m.model.load_state_dict", "print", "torch.load", "os.path.join"], "function", ["None"], ["", "def", "load_model", "(", "model_folder", ",", "m", ")", ":", "\n", "    ", "print", "(", "'\\nLoading model ... '", ",", "end", "=", "\"\"", ")", "\n", "m", ".", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "model_folder", ",", "'re.model'", ")", ",", "map_location", "=", "m", ".", "model", ".", "device", ")", ")", "\n", "print", "(", "'END'", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.print_results": [[194, 220], ["scores[].append", "scores[].append", "scores[].append", "print", "print", "print", "print", "print", "print", "utils.print_results.indent"], "function", ["None"], ["", "def", "print_results", "(", "scores", ",", "show_class", ",", "time", ")", ":", "\n", "    ", "def", "indent", "(", "txt", ",", "spaces", "=", "18", ")", ":", "\n", "        ", "return", "\"\\n\"", ".", "join", "(", "\" \"", "*", "spaces", "+", "ln", "for", "ln", "in", "txt", ".", "splitlines", "(", ")", ")", "\n", "\n", "", "if", "show_class", ":", "\n", "# print results for every class", "\n", "        ", "scores", "[", "'per_class'", "]", ".", "append", "(", "[", "'-----'", ",", "None", ",", "None", ",", "None", "]", ")", "\n", "scores", "[", "'per_class'", "]", ".", "append", "(", "[", "'macro score'", ",", "scores", "[", "'macro_p'", "]", ",", "scores", "[", "'macro_r'", "]", ",", "scores", "[", "'macro_f'", "]", "]", ")", "\n", "scores", "[", "'per_class'", "]", ".", "append", "(", "[", "'micro score'", ",", "scores", "[", "'micro_p'", "]", ",", "scores", "[", "'micro_r'", "]", ",", "scores", "[", "'micro_f'", "]", "]", ")", "\n", "print", "(", "' | Elapsed time: {}\\n'", ".", "format", "(", "humanized_time", "(", "time", ")", ")", ")", "\n", "print", "(", "indent", "(", "tabulate", "(", "scores", "[", "'per_class'", "]", ",", "\n", "headers", "=", "[", "'Class'", ",", "'P'", ",", "'R'", ",", "'F1'", "]", ",", "\n", "tablefmt", "=", "'orgtbl'", ",", "\n", "floatfmt", "=", "\".4f\"", ",", "\n", "missingval", "=", "\"\"", ")", ")", ")", "\n", "print", "(", ")", "\n", "", "else", ":", "\n", "# print overall scores", "\n", "        ", "print", "(", "' | MICRO P/R/F1 = {:.04f}\\t{:.04f}\\t{:.04f} | '", "\n", "'MACRO P/R/F1 = {:.04f}\\t{:.04f}\\t{:.04f} | '", ".", "format", "(", "scores", "[", "'micro_p'", "]", ",", "scores", "[", "'micro_r'", "]", ",", "\n", "scores", "[", "'micro_f'", "]", ",", "scores", "[", "'macro_p'", "]", ",", "\n", "scores", "[", "'macro_r'", "]", ",", "scores", "[", "'macro_f'", "]", ")", ",", "end", "=", "\"\"", ")", "\n", "\n", "print", "(", "'TP/ACTUAL/PRED {:<6}/{:<6}/{:<6} TOTAL {}'", ".", "format", "(", "scores", "[", "'tp'", "]", ",", "scores", "[", "'actual'", "]", ",", "scores", "[", "'pred'", "]", ",", "\n", "scores", "[", "'total'", "]", ")", ",", "end", "=", "\"\"", ")", "\n", "print", "(", "' | {}'", ".", "format", "(", "humanized_time", "(", "time", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.write_pred2file": [[222, 247], ["print", "print", "os.path.exists", "os.makedirs", "len", "len", "len", "len", "len", "len", "open", "zip", "os.path.join", "outfile.write", "int"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write"], ["", "", "def", "write_pred2file", "(", "predicts", ",", "probabs", ",", "rels_info", ",", "savef", ",", "rel_map", ")", ":", "\n", "    ", "\"\"\"\n    Write predictions to specific file in 'savef' folder\n    Args:\n        predicts: predictions\n        rels_info: gold relations information\n        savef: save folder\n        rel_map: mapping of relation types\n    \"\"\"", "\n", "print", "(", "'Writing predictions to file ... '", ",", "end", "=", "\"\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "savef", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "savef", ")", "\n", "\n", "", "assert", "len", "(", "predicts", ")", "==", "len", "(", "rels_info", ")", "==", "len", "(", "probabs", ")", ",", "'{} predictions != {} relations != {} probabilities'", ".", "format", "(", "len", "(", "predicts", ")", ",", "len", "(", "rels_info", ")", ",", "len", "(", "probabs", ")", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "savef", ",", "'preds.txt'", ")", ",", "'w'", ")", "as", "outfile", ":", "\n", "        ", "for", "pred", ",", "prob", ",", "pair_info", "in", "zip", "(", "predicts", ",", "probabs", ",", "rels_info", ")", ":", "\n", "            ", "doc_id", "=", "pair_info", "[", "'pmid'", "]", "\n", "arg1", "=", "pair_info", "[", "'entA'", "]", "\n", "arg2", "=", "pair_info", "[", "'entB'", "]", "\n", "\n", "prediction", "=", "rel_map", "[", "int", "(", "pred", ")", "]", "\n", "outfile", ".", "write", "(", "'{}|{}|{}|{}|{}\\n'", ".", "format", "(", "doc_id", ",", "arg1", ".", "id", ",", "arg2", ".", "id", ",", "prediction", ",", "prob", ")", ")", "\n", "", "", "print", "(", "'END'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.write_errors2file": [[249, 274], ["print", "print", "os.path.exists", "os.makedirs", "len", "len", "len", "len", "open", "zip", "os.path.join", "outfile.write", "outfile.write", "outfile.write", "outfile.write", "outfile.write", "int", "int", "int", "int"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write"], ["", "def", "write_errors2file", "(", "predicts", ",", "rels_info", ",", "savef", ",", "map_", "=", "None", ")", ":", "\n", "    ", "\"\"\" Write model errors to file \"\"\"", "\n", "print", "(", "'Writing errors to file ...'", ",", "end", "=", "\"\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "savef", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "savef", ")", "\n", "\n", "", "assert", "len", "(", "predicts", ")", "==", "len", "(", "rels_info", ")", ",", "'{} predictions != {} relations'", ".", "format", "(", "len", "(", "predicts", ")", ",", "len", "(", "rels_info", ")", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "savef", ",", "'errors.txt'", ")", ",", "'w'", ")", "as", "outfile", ":", "\n", "        ", "for", "pred", ",", "pair_info", "in", "zip", "(", "predicts", ",", "rels_info", ")", ":", "\n", "\n", "            ", "doc_id", "=", "pair_info", "[", "'pmid'", "]", "\n", "arg1", "=", "pair_info", "[", "'entA'", "]", "\n", "arg2", "=", "pair_info", "[", "'entB'", "]", "\n", "\n", "prediction", "=", "map_", "[", "int", "(", "pred", ")", "]", "\n", "truth", "=", "map_", "[", "int", "(", "pair_info", "[", "'rel'", "]", ")", "]", "\n", "\n", "if", "prediction", "!=", "truth", ":", "\n", "                ", "outfile", ".", "write", "(", "'Prediction --> {} \\t Truth --> {}\\n'", ".", "format", "(", "prediction", ",", "truth", ")", ")", "\n", "outfile", ".", "write", "(", "'DocID: {}\\n{}\\n'", ".", "format", "(", "doc_id", ",", "' '", ".", "join", "(", "pair_info", "[", "'doc'", "]", ")", ")", ")", "\n", "outfile", ".", "write", "(", "'Arg1: {} ({})\\ttokens: {}-{}\\n'", ".", "format", "(", "arg1", ".", "name", ",", "arg1", ".", "type", ",", "arg1", ".", "start", ",", "int", "(", "arg1", ".", "end", ")", "-", "1", ")", ")", "\n", "outfile", ".", "write", "(", "'Arg2: {} ({})\\ttokens: {}-{}\\n'", ".", "format", "(", "arg2", ".", "name", ",", "arg2", ".", "type", ",", "arg2", ".", "start", ",", "int", "(", "arg2", ".", "end", ")", "-", "1", ")", ")", "\n", "outfile", ".", "write", "(", "'\\n'", ")", "\n", "", "", "", "print", "(", "'END'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.write_bingo2file": [[276, 301], ["print", "print", "os.path.exists", "os.makedirs", "len", "len", "len", "len", "open", "zip", "os.path.join", "outfile.write", "outfile.write", "outfile.write", "outfile.write", "outfile.write", "int", "int", "int", "int"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write"], ["", "def", "write_bingo2file", "(", "predicts", ",", "rels_info", ",", "savef", ",", "map_", "=", "None", ")", ":", "\n", "    ", "\"\"\" Write correct predictions to file \"\"\"", "\n", "print", "(", "'Writing correct predictions to file ...'", ",", "end", "=", "\"\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "savef", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "savef", ")", "\n", "\n", "", "assert", "len", "(", "predicts", ")", "==", "len", "(", "rels_info", ")", ",", "'{} predictions != {} relations'", ".", "format", "(", "len", "(", "predicts", ")", ",", "len", "(", "rels_info", ")", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "savef", ",", "'correct.txt'", ")", ",", "'w'", ")", "as", "outfile", ":", "\n", "        ", "for", "pred", ",", "pair_info", "in", "zip", "(", "predicts", ",", "rels_info", ")", ":", "\n", "\n", "            ", "doc_id", "=", "pair_info", "[", "'pmid'", "]", "\n", "arg1", "=", "pair_info", "[", "'entA'", "]", "\n", "arg2", "=", "pair_info", "[", "'entB'", "]", "\n", "\n", "prediction", "=", "map_", "[", "int", "(", "pred", ")", "]", "\n", "truth", "=", "map_", "[", "int", "(", "pair_info", "[", "'rel'", "]", ")", "]", "\n", "\n", "if", "prediction", "==", "truth", "and", "truth", "!=", "'1:NR:2'", ":", "# write only the positives", "\n", "                ", "outfile", ".", "write", "(", "'Prediction --> {} \\t Truth --> {}\\n'", ".", "format", "(", "prediction", ",", "truth", ")", ")", "\n", "outfile", ".", "write", "(", "'DocID: {}\\n{}\\n'", ".", "format", "(", "doc_id", ",", "' '", ".", "join", "(", "pair_info", "[", "'doc'", "]", ")", ")", ")", "\n", "outfile", ".", "write", "(", "'Arg1: {} ({})\\ttokens: {}-{}\\n'", ".", "format", "(", "arg1", ".", "name", ",", "arg1", ".", "type", ",", "arg1", ".", "start", ",", "int", "(", "arg1", ".", "end", ")", "-", "1", ")", ")", "\n", "outfile", ".", "write", "(", "'Arg2: {} ({})\\ttokens: {}-{}\\n'", ".", "format", "(", "arg2", ".", "name", ",", "arg2", ".", "type", ",", "arg2", ".", "start", ",", "int", "(", "arg2", ".", "end", ")", "-", "1", ")", ")", "\n", "outfile", ".", "write", "(", "'\\n'", ")", "\n", "", "", "", "print", "(", "'END'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.ConfigLoader.__init__": [[22, 24], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.ConfigLoader.load_cmd": [[25, 44], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "load_cmd", "(", ")", ":", "\n", "        ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--config'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "'Yaml parameter file'", ")", "\n", "parser", ".", "add_argument", "(", "'--train'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Training mode - model is saved'", ")", "\n", "parser", ".", "add_argument", "(", "'--test'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Testing mode - needs a model to load'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu'", ",", "type", "=", "int", ",", "required", "=", "True", ",", "help", "=", "'GPU number, use -1 for CPU'", ")", "\n", "parser", ".", "add_argument", "(", "'--walks'", ",", "type", "=", "int", ",", "help", "=", "'Number of walk iterations'", ")", "\n", "parser", ".", "add_argument", "(", "'--att'", ",", "type", "=", "str", ",", "help", "=", "'Use attention or not'", ",", "choices", "=", "[", "'True'", ",", "'False'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--example'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Print the sentences and info in the 1st batch, then exit (useful for debugging)'", ")", "\n", "parser", ".", "add_argument", "(", "'--direction'", ",", "type", "=", "str", ",", "help", "=", "'Direction of arguments to classify'", ",", "choices", "=", "[", "'l2r'", ",", "'r2l'", ",", "'l2r+r2l'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--folder'", ",", "type", "=", "str", ",", "help", "=", "'Destination folder to save model, predictions and errors'", ")", "\n", "parser", ".", "add_argument", "(", "'--embeds'", ",", "type", "=", "str", ",", "help", "=", "'Pre-trained word embeds file'", ")", "\n", "parser", ".", "add_argument", "(", "'--train_data'", ",", "type", "=", "str", ",", "help", "=", "'Training data file'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_data'", ",", "type", "=", "str", ",", "help", "=", "'Test data dile'", ")", "\n", "parser", ".", "add_argument", "(", "'--epoch'", ",", "type", "=", "int", ",", "help", "=", "'Stopping epoch'", ")", "\n", "parser", ".", "add_argument", "(", "'--early_stop'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Use early stopping'", ")", "\n", "parser", ".", "add_argument", "(", "'--preds'", ",", "type", "=", "str", ",", "help", "=", "'Folder name for predictions'", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.ConfigLoader.load_config": [[45, 87], ["loader.ConfigLoader.load_cmd", "dict", "open", "yaml.load", "vars"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.ConfigLoader.load_cmd"], ["", "def", "load_config", "(", "self", ")", ":", "\n", "        ", "inp", "=", "self", ".", "load_cmd", "(", ")", "\n", "with", "open", "(", "vars", "(", "inp", ")", "[", "'config'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "parameters", "=", "yaml", ".", "load", "(", "f", ",", "Loader", "=", "yamlordereddictloader", ".", "Loader", ")", "\n", "\n", "", "parameters", "=", "dict", "(", "parameters", ")", "\n", "parameters", "[", "'train'", "]", "=", "inp", ".", "train", "\n", "parameters", "[", "'test'", "]", "=", "inp", ".", "test", "\n", "parameters", "[", "'gpu'", "]", "=", "inp", ".", "gpu", "\n", "parameters", "[", "'example'", "]", "=", "inp", ".", "example", "\n", "\n", "if", "inp", ".", "att", "!=", "None", ":", "\n", "            ", "parameters", "[", "'att'", "]", "=", "inp", ".", "att", "\n", "\n", "", "if", "inp", ".", "walks", ":", "\n", "            ", "parameters", "[", "'walks_iter'", "]", "=", "inp", ".", "walks", "\n", "\n", "", "if", "inp", ".", "folder", ":", "\n", "            ", "parameters", "[", "'folder'", "]", "=", "inp", ".", "folder", "\n", "\n", "", "if", "inp", ".", "embeds", ":", "\n", "            ", "parameters", "[", "'embeds'", "]", "=", "inp", ".", "embeds", "\n", "\n", "", "if", "inp", ".", "train_data", ":", "\n", "            ", "parameters", "[", "'train_data'", "]", "=", "inp", ".", "train_data", "\n", "\n", "", "if", "inp", ".", "test_data", ":", "\n", "            ", "parameters", "[", "'test_data'", "]", "=", "inp", ".", "test_data", "\n", "\n", "", "if", "inp", ".", "direction", ":", "\n", "            ", "parameters", "[", "'direction'", "]", "=", "inp", ".", "direction", "\n", "\n", "", "if", "inp", ".", "epoch", ":", "\n", "            ", "parameters", "[", "'epoch'", "]", "=", "inp", ".", "epoch", "\n", "\n", "", "if", "inp", ".", "preds", ":", "\n", "            ", "parameters", "[", "'save_preds'", "]", "=", "inp", ".", "preds", "\n", "\n", "", "if", "inp", ".", "early_stop", ":", "\n", "            ", "parameters", "[", "'early_stopping'", "]", "=", "inp", ".", "early_stop", "\n", "\n", "", "return", "parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.__init__": [[90, 113], ["collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "input_file", ",", "params", ")", ":", "\n", "        ", "self", ".", "input", "=", "input_file", "\n", "self", ".", "params", "=", "params", "\n", "\n", "self", ".", "max_distance", "=", "-", "9999999999", "\n", "self", ".", "min_distance", "=", "9999999999", "\n", "self", ".", "embeds_file", "=", "params", "[", "'embeds'", "]", "\n", "self", ".", "pre_words", "=", "[", "]", "\n", "self", ".", "pre_embeds", "=", "OrderedDict", "(", ")", "\n", "self", ".", "max_distance", "=", "0", "\n", "self", ".", "lower", "=", "params", "[", "'lowercase'", "]", "\n", "\n", "self", ".", "word2index", ",", "self", ".", "index2word", ",", "self", ".", "n_words", ",", "self", ".", "word2count", "=", "{", "'<UNK>'", ":", "0", "}", ",", "{", "0", ":", "'<UNK>'", "}", ",", "1", ",", "{", "'<UNK>'", ":", "1", "}", "\n", "self", ".", "type2index", ",", "self", ".", "index2type", ",", "self", ".", "n_type", ",", "self", ".", "type2count", "=", "{", "'O'", ":", "0", "}", ",", "{", "0", ":", "'O'", "}", ",", "1", ",", "{", "'O'", ":", "0", "}", "\n", "self", ".", "rel2index", ",", "self", ".", "index2rel", ",", "self", ".", "n_rel", ",", "self", ".", "rel2count", "=", "{", "'1:NR:2'", ":", "0", "}", ",", "{", "0", ":", "'1:NR:2'", "}", ",", "1", ",", "{", "'1:NR:2'", ":", "0", "}", "\n", "self", ".", "pos2index", ",", "self", ".", "index2pos", ",", "self", ".", "n_pos", ",", "self", ".", "pos2count", "=", "{", "'inside'", ":", "0", ",", "'outside'", ":", "1", "}", ",", "{", "0", ":", "'inside'", ",", "1", ":", "'outside'", "}", ",", "2", ",", "{", "'inside'", ":", "0", ",", "'outside'", ":", "0", "}", "\n", "\n", "self", ".", "sentences", ",", "self", ".", "entities", ",", "self", ".", "pairs", "=", "OrderedDict", "(", ")", ",", "OrderedDict", "(", ")", ",", "OrderedDict", "(", ")", "\n", "self", ".", "singletons", "=", "[", "]", "\n", "self", ".", "label2ignore", "=", "0", "\n", "self", ".", "reverse_l", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.normalize_string": [[114, 117], ["re.sub"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "normalize_string", "(", "string", ",", "str2rpl", "=", "'0'", ")", ":", "\n", "        ", "return", "re", ".", "sub", "(", "\"\\d\"", ",", "str2rpl", ",", "string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.find_singletons": [[118, 124], ["frozenset", "loader.DataLoader.word2count.items"], "methods", ["None"], ["", "def", "find_singletons", "(", "self", ",", "min_w_freq", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Find items with frequency <= 2 and based on probability\n        \"\"\"", "\n", "self", ".", "singletons", "=", "frozenset", "(", "[", "elem", "for", "elem", ",", "val", "in", "self", ".", "word2count", ".", "items", "(", ")", "\n", "if", "(", "(", "val", "<=", "min_w_freq", ")", "and", "elem", "!=", "'<UNK>'", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.add_relation": [[125, 133], ["None"], "methods", ["None"], ["", "def", "add_relation", "(", "self", ",", "rel", ")", ":", "\n", "        ", "if", "rel", "not", "in", "self", ".", "rel2index", ":", "\n", "            ", "self", ".", "rel2index", "[", "rel", "]", "=", "self", ".", "n_rel", "\n", "self", ".", "rel2count", "[", "rel", "]", "=", "1", "\n", "self", ".", "index2rel", "[", "self", ".", "n_rel", "]", "=", "rel", "\n", "self", ".", "n_rel", "+=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "rel2count", "[", "rel", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.add_word": [[134, 145], ["word.lower.lower.lower"], "methods", ["None"], ["", "", "def", "add_word", "(", "self", ",", "word", ")", ":", "\n", "        ", "if", "self", ".", "lower", ":", "\n", "            ", "word", "=", "word", ".", "lower", "(", ")", "\n", "\n", "", "if", "word", "not", "in", "self", ".", "word2index", ":", "\n", "            ", "self", ".", "word2index", "[", "word", "]", "=", "self", ".", "n_words", "\n", "self", ".", "word2count", "[", "word", "]", "=", "1", "\n", "self", ".", "index2word", "[", "self", ".", "n_words", "]", "=", "word", "\n", "self", ".", "n_words", "+=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "word2count", "[", "word", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.add_type": [[146, 154], ["None"], "methods", ["None"], ["", "", "def", "add_type", "(", "self", ",", "type", ")", ":", "\n", "        ", "if", "type", "not", "in", "self", ".", "type2index", ":", "\n", "            ", "self", ".", "type2index", "[", "type", "]", "=", "self", ".", "n_type", "\n", "self", ".", "type2count", "[", "type", "]", "=", "1", "\n", "self", ".", "index2type", "[", "self", ".", "n_type", "]", "=", "type", "\n", "self", ".", "n_type", "+=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "type2count", "[", "type", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.add_pos": [[155, 164], ["str"], "methods", ["None"], ["", "", "def", "add_pos", "(", "self", ",", "pos", ")", ":", "\n", "        ", "pos", "=", "str", "(", "pos", ")", "\n", "if", "pos", "not", "in", "self", ".", "pos2index", ":", "\n", "            ", "self", ".", "pos2index", "[", "pos", "]", "=", "self", ".", "n_pos", "\n", "self", ".", "pos2count", "[", "pos", "]", "=", "1", "\n", "self", ".", "index2pos", "[", "self", ".", "n_pos", "]", "=", "pos", "\n", "self", ".", "n_pos", "+=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "pos2count", "[", "pos", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.add_sentence": [[165, 168], ["loader.DataLoader.add_word"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.add_word"], ["", "", "def", "add_sentence", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "for", "word", "in", "sentence", ":", "\n", "            ", "self", ".", "add_word", "(", "word", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.find_maxmin_length": [[169, 176], ["None"], "methods", ["None"], ["", "", "def", "find_maxmin_length", "(", "self", ",", "length", ")", ":", "\n", "        ", "for", "l", "in", "length", ":", "\n", "            ", "if", "l", "-", "1", ">", "self", ".", "max_distance", ":", "\n", "                ", "self", ".", "max_distance", "=", "l", "-", "1", "\n", "\n", "", "if", "-", "l", "+", "1", "<", "self", ".", "min_distance", ":", "\n", "                ", "self", ".", "min_distance", "=", "-", "l", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.load_embeds": [[177, 200], ["collections.OrderedDict", "print", "open", "enumerate", "loader.DataLoader.pre_embeds.items", "len", "map", "len", "len", "line.rstrip().split", "line.rstrip().split", "line.rstrip().split", "print", "loader.DataLoader.add_word", "numpy.asarray", "line.split", "line.rstrip", "line.rstrip", "line.rstrip"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.add_word"], ["", "", "", "def", "load_embeds", "(", "self", ",", "word_dim", ")", ":", "\n", "        ", "\"\"\"\n        Load pre-trained word embeddings if specified\n        \"\"\"", "\n", "self", ".", "pre_embeds", "=", "OrderedDict", "(", ")", "\n", "with", "open", "(", "self", ".", "embeds_file", ",", "'r'", ")", "as", "vectors", ":", "\n", "            ", "for", "x", ",", "line", "in", "enumerate", "(", "vectors", ")", ":", "\n", "\n", "                ", "if", "x", "==", "0", "and", "len", "(", "line", ".", "split", "(", ")", ")", "==", "2", ":", "\n", "                    ", "words", ",", "num", "=", "map", "(", "int", ",", "line", ".", "rstrip", "(", ")", ".", "split", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "word", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", ")", "[", "0", "]", "\n", "vec", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", ")", "[", "1", ":", "]", "\n", "\n", "n", "=", "len", "(", "vec", ")", "\n", "if", "n", "!=", "word_dim", ":", "\n", "                        ", "print", "(", "'  Wrong dimensionality! -- line No{}, word: {}, len {}'", ".", "format", "(", "x", ",", "word", ",", "n", ")", ")", "\n", "continue", "\n", "", "else", ":", "\n", "                        ", "self", ".", "add_word", "(", "word", ")", "\n", "self", ".", "pre_embeds", "[", "word", "]", "=", "np", ".", "asarray", "(", "vec", ",", "'f'", ")", "\n", "", "", "", "", "self", ".", "pre_words", "=", "[", "w", "for", "w", ",", "e", "in", "self", ".", "pre_embeds", ".", "items", "(", ")", "]", "\n", "print", "(", "'  Found pre-trained word embeddings: {} x {}'", ".", "format", "(", "len", "(", "self", ".", "pre_embeds", ")", ",", "word_dim", ")", ",", "end", "=", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.read_n_map": [[201, 236], ["reader.read_relation_input", "loader.DataLoader.find_maxmin_length", "loader.DataLoader.sentences.items", "loader.DataLoader.entities.items", "numpy.arange", "loader.DataLoader.pairs.items", "list", "loader.DataLoader.add_sentence", "e.items", "loader.DataLoader.add_pos", "p.items", "loader.DataLoader.rel2index.keys", "len", "len", "len", "loader.DataLoader.add_type", "str", "loader.DataLoader.add_relation", "k.split", "print", "loader.DataLoader.add_relation"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.reader.read_relation_input", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.find_maxmin_length", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.add_sentence", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.add_pos", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.add_type", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.add_relation", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.add_relation"], ["", "def", "read_n_map", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Read input.\n        \"\"\"", "\n", "lengths", ",", "self", ".", "sentences", ",", "self", ".", "entities", ",", "self", ".", "pairs", "=", "read_relation_input", "(", "self", ".", "input", ",", "self", ".", "sentences", ",", "self", ".", "entities", ",", "self", ".", "pairs", ")", "\n", "\n", "self", ".", "find_maxmin_length", "(", "lengths", ")", "\n", "\n", "# map types and positions and relation types", "\n", "for", "did", ",", "d", "in", "self", ".", "sentences", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "add_sentence", "(", "d", ")", "\n", "\n", "", "for", "did", ",", "e", "in", "self", ".", "entities", ".", "items", "(", ")", ":", "\n", "            ", "for", "k", ",", "v", "in", "e", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "add_type", "(", "v", ".", "type", ")", "\n", "\n", "", "", "for", "pos", "in", "np", ".", "arange", "(", "-", "self", ".", "max_distance", ",", "self", ".", "max_distance", "+", "1", ")", ":", "\n", "            ", "self", ".", "add_pos", "(", "str", "(", "pos", ")", ")", "\n", "\n", "", "for", "did", ",", "p", "in", "self", ".", "pairs", ".", "items", "(", ")", ":", "\n", "            ", "for", "k", ",", "v", "in", "p", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "add_relation", "(", "v", ".", "type", ")", "\n", "\n", "# make sure all directions are there", "\n", "", "", "current_rels", "=", "list", "(", "self", ".", "rel2index", ".", "keys", "(", ")", ")", "\n", "for", "k", "in", "current_rels", ":", "\n", "            ", "if", "k", "!=", "'1:NR:2'", "and", "k", "!=", "'not_include'", ":", "\n", "               ", "rev", "=", "k", ".", "split", "(", "':'", ")", "\n", "if", "rev", "[", "2", "]", "+", "':'", "+", "rev", "[", "1", "]", "+", "':'", "+", "rev", "[", "0", "]", "not", "in", "current_rels", ":", "\n", "                   ", "print", "(", "'relation not found -- adding'", ",", "rev", "[", "2", "]", "+", "':'", "+", "rev", "[", "1", "]", "+", "':'", "+", "rev", "[", "0", "]", ")", "\n", "self", ".", "add_relation", "(", "rev", "[", "2", "]", "+", "':'", "+", "rev", "[", "1", "]", "+", "':'", "+", "rev", "[", "0", "]", ")", "\n", "self", ".", "rel2count", "[", "rev", "[", "2", "]", "+", "':'", "+", "rev", "[", "1", "]", "+", "':'", "+", "rev", "[", "0", "]", "]", "=", "0", "\n", "\n", "", "", "", "assert", "len", "(", "self", ".", "entities", ")", "==", "len", "(", "self", ".", "sentences", ")", "==", "len", "(", "self", ".", "pairs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.reverse_labels": [[237, 247], ["range", "numpy.array", "loader.DataLoader.index2rel[].split"], "methods", ["None"], ["", "def", "reverse_labels", "(", "self", ")", ":", "\n", "        ", "labmap", "=", "[", "]", "\n", "for", "e", "in", "range", "(", "0", ",", "self", ".", "n_rel", ")", ":", "\n", "            ", "x_", "=", "self", ".", "index2rel", "[", "e", "]", ".", "split", "(", "':'", ")", "\n", "if", "x_", "[", "1", "]", "==", "'NR'", ":", "\n", "                ", "labmap", "+=", "[", "self", ".", "rel2index", "[", "'1:NR:2'", "]", "]", "\n", "", "else", ":", "\n", "                ", "labmap", "+=", "[", "self", ".", "rel2index", "[", "x_", "[", "2", "]", "+", "':'", "+", "x_", "[", "1", "]", "+", "':'", "+", "x_", "[", "0", "]", "]", "]", "\n", "", "", "labmap", "=", "np", ".", "array", "(", "labmap", ",", "'i'", ")", "\n", "return", "labmap", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.statistics": [[248, 261], ["print", "print", "sorted", "print", "sorted", "print", "loader.DataLoader.rel2count.items", "print", "loader.DataLoader.type2count.items", "print", "len", "len", "sum", "sum", "len", "len", "loader.DataLoader.word2count.keys", "loader.DataLoader.word2count.keys", "len", "loader.DataLoader.rel2count.items", "loader.DataLoader.entities.values"], "methods", ["None"], ["", "def", "statistics", "(", "self", ")", ":", "\n", "        ", "\"\"\" Print statistics for the dataset \"\"\"", "\n", "print", "(", "'  # Sentences: {:<5}\\n  # words: {:<5}'", ".", "format", "(", "len", "(", "self", ".", "sentences", ")", ",", "len", "(", "self", ".", "word2count", ".", "keys", "(", ")", ")", ")", ")", "\n", "\n", "print", "(", "'  # Relations: {}'", ".", "format", "(", "sum", "(", "[", "v", "for", "k", ",", "v", "in", "self", ".", "rel2count", ".", "items", "(", ")", "]", ")", ")", ")", "\n", "for", "k", ",", "v", "in", "sorted", "(", "self", ".", "rel2count", ".", "items", "(", ")", ")", ":", "\n", "            ", "print", "(", "'\\t{:<10}\\t{:<5}\\tID: {}'", ".", "format", "(", "k", ",", "v", ",", "self", ".", "rel2index", "[", "k", "]", ")", ")", "\n", "\n", "", "print", "(", "'  # Entities: {}'", ".", "format", "(", "sum", "(", "[", "len", "(", "e", ")", "for", "e", "in", "self", ".", "entities", ".", "values", "(", ")", "]", ")", ")", ")", "\n", "for", "k", ",", "v", "in", "sorted", "(", "self", ".", "type2count", ".", "items", "(", ")", ")", ":", "\n", "            ", "print", "(", "'\\t{:<10}\\t{:<5}\\tID: {}'", ".", "format", "(", "k", ",", "v", ",", "self", ".", "type2index", "[", "k", "]", ")", ")", "\n", "\n", "", "print", "(", "'  # Singletons: {}/{}'", ".", "format", "(", "len", "(", "self", ".", "singletons", ")", ",", "len", "(", "self", ".", "word2count", ".", "keys", "(", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.__call__": [[262, 270], ["loader.DataLoader.read_n_map", "loader.DataLoader.find_singletons", "loader.DataLoader.reverse_labels", "loader.DataLoader.statistics", "loader.DataLoader.load_embeds", "print"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.read_n_map", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.find_singletons", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.reverse_labels", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.statistics", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.loader.DataLoader.load_embeds"], ["", "def", "__call__", "(", "self", ",", "embeds", "=", "None", ")", ":", "\n", "        ", "self", ".", "read_n_map", "(", ")", "\n", "self", ".", "find_singletons", "(", "self", ".", "params", "[", "'min_w_freq'", "]", ")", "# words with freq=1", "\n", "self", ".", "reverse_l", "=", "self", ".", "reverse_labels", "(", ")", "\n", "self", ".", "statistics", "(", ")", "\n", "if", "embeds", ":", "\n", "            ", "self", ".", "load_embeds", "(", "self", ".", "params", "[", "'word_dim'", "]", ")", "\n", "print", "(", "' --> # Words + Pre-trained: {:<5}'", ".", "format", "(", "self", ".", "n_words", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.reader.read_relation_input": [[17, 65], ["range", "open", "len", "line.rstrip().split.rstrip().split", "line[].split", "reader.read_relation_input.chunks"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.statistics.chunks"], ["def", "read_relation_input", "(", "input_file", ",", "documents", ",", "entities", ",", "relations", ")", ":", "\n", "    ", "\"\"\"\n    Read input file in special format\n    \"\"\"", "\n", "def", "chunks", "(", "l", ",", "n", ")", ":", "\n", "        ", "\"\"\" Successive n-sized chunks from l. \"\"\"", "\n", "res", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "l", ")", ",", "n", ")", ":", "\n", "            ", "assert", "len", "(", "l", "[", "i", ":", "i", "+", "n", "]", ")", "==", "n", ",", "'sequence of invalid length'", "\n", "res", "+=", "[", "l", "[", "i", ":", "i", "+", "n", "]", "]", "\n", "", "return", "res", "\n", "\n", "", "lengths", "=", "[", "]", "\n", "with", "open", "(", "input_file", ",", "'r'", ")", "as", "infile", ":", "\n", "        ", "for", "line", "in", "infile", ":", "\n", "            ", "line", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "docid", "=", "line", "[", "0", "]", "\n", "text", "=", "line", "[", "1", "]", ".", "split", "(", "' '", ")", "\n", "pairs", "=", "chunks", "(", "line", "[", "2", ":", "]", ",", "13", ")", "\n", "\n", "if", "docid", "not", "in", "documents", ":", "\n", "                ", "documents", "[", "docid", "]", "=", "text", "\n", "\n", "", "if", "docid", "not", "in", "entities", ":", "\n", "                ", "entities", "[", "docid", "]", "=", "OrderedDict", "(", ")", "\n", "\n", "", "if", "docid", "not", "in", "relations", ":", "\n", "                ", "relations", "[", "docid", "]", "=", "OrderedDict", "(", ")", "\n", "\n", "# max sentence length", "\n", "", "lengths", "+=", "[", "len", "(", "text", ")", "]", "\n", "\n", "all_pairs", "=", "0", "\n", "for", "p", "in", "pairs", ":", "\n", "                ", "if", "'R'", "+", "str", "(", "all_pairs", ")", "not", "in", "relations", "[", "docid", "]", ":", "\n", "                    ", "relations", "[", "docid", "]", "[", "'R'", "+", "str", "(", "all_pairs", ")", "]", "=", "PairInfo", "(", "'R'", "+", "str", "(", "all_pairs", ")", ",", "\n", "p", "[", "0", "]", ",", "p", "[", "3", "]", ",", "p", "[", "8", "]", ",", "p", "[", "1", "]", ",", "p", "[", "2", "]", ")", "\n", "all_pairs", "+=", "1", "\n", "\n", "# entities", "\n", "", "if", "p", "[", "3", "]", "not", "in", "entities", "[", "docid", "]", ":", "\n", "                    ", "entities", "[", "docid", "]", "[", "p", "[", "3", "]", "]", "=", "EntityInfo", "(", "p", "[", "3", "]", ",", "p", "[", "5", "]", ",", "p", "[", "4", "]", ",", "p", "[", "6", "]", ",", "p", "[", "7", "]", ")", "\n", "\n", "", "if", "p", "[", "8", "]", "not", "in", "entities", "[", "docid", "]", ":", "\n", "                    ", "entities", "[", "docid", "]", "[", "p", "[", "8", "]", "]", "=", "EntityInfo", "(", "p", "[", "8", "]", ",", "p", "[", "10", "]", ",", "p", "[", "9", "]", ",", "p", "[", "11", "]", ",", "p", "[", "12", "]", ")", "\n", "\n", "", "", "assert", "len", "(", "relations", "[", "docid", "]", ")", "==", "all_pairs", ",", "'Not all pairs assigned'", "\n", "", "", "return", "lengths", ",", "documents", ",", "entities", ",", "relations", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.AR_sigtest.load_data": [[16, 40], ["zip", "open", "line.rstrip().split.rstrip().split", "all[].update", "line.rstrip().split.rstrip", "[].split", "[].split", "line[].split", "line[].split"], "function", ["None"], ["def", "load_data", "(", "args", ")", ":", "\n", "    ", "all", ",", "intra", ",", "inter", "=", "{", "}", ",", "{", "}", ",", "{", "}", "\n", "all", "[", "'A'", "]", ",", "all", "[", "'B'", "]", ",", "all", "[", "'true'", "]", "=", "{", "}", ",", "{", "}", ",", "{", "}", "\n", "\n", "for", "system", ",", "typ", "in", "zip", "(", "[", "args", ".", "systemA", ",", "args", ".", "systemB", ",", "args", ".", "truth", "]", ",", "[", "'A'", ",", "'B'", ",", "'true'", "]", ")", ":", "\n", "        ", "with", "open", "(", "system", ",", "'r'", ")", "as", "pred", ":", "\n", "            ", "for", "line", "in", "pred", ":", "\n", "                ", "line", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "'|'", ")", "\n", "\n", "# format: {(PMID, arg1, arg2): rlabel}", "\n", "if", "':'", "in", "line", "[", "3", "]", ":", "\n", "                    ", "doc_id", "=", "line", "[", "0", "]", ".", "split", "(", "'**'", ")", "[", "0", "]", ".", "split", "(", "'.split'", ")", "[", "0", "]", "\n", "arg1", "=", "line", "[", "1", "]", "\n", "arg2", "=", "line", "[", "2", "]", "\n", "label", "=", "line", "[", "3", "]", "\n", "", "else", ":", "\n", "                    ", "doc_id", "=", "line", "[", "0", "]", ".", "split", "(", "'**'", ")", "[", "0", "]", ".", "split", "(", "'.split'", ")", "[", "0", "]", "\n", "arg1", "=", "line", "[", "1", "]", "\n", "arg2", "=", "line", "[", "2", "]", "\n", "label", "=", "'1:'", "+", "line", "[", "3", "]", "+", "':2'", "\n", "\n", "", "if", "label", "!=", "'1:NR:2'", ":", "\n", "                    ", "all", "[", "typ", "]", ".", "update", "(", "{", "(", "doc_id", ",", "arg1", ",", "arg2", ")", ":", "label", "}", ")", "\n", "", "", "", "", "return", "all", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.AR_sigtest.align": [[42, 80], ["print", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "len", "len", "len", "list", "list", "list", "all[].keys", "all[].keys", "all[].keys", "[].split", "[].split", "[].split"], "function", ["None"], ["", "def", "align", "(", "all", ")", ":", "\n", "    ", "all_n", "=", "{", "'A'", ":", "OrderedDict", "(", ")", ",", "'B'", ":", "OrderedDict", "(", ")", ",", "'true'", ":", "OrderedDict", "(", ")", "}", "\n", "\n", "print", "(", "len", "(", "all", "[", "'A'", "]", ")", ",", "len", "(", "all", "[", "'B'", "]", ")", ",", "len", "(", "all", "[", "'true'", "]", ")", ")", "\n", "\n", "for", "key", "in", "list", "(", "all", "[", "'A'", "]", ".", "keys", "(", ")", ")", "+", "list", "(", "all", "[", "'B'", "]", ".", "keys", "(", ")", ")", "+", "list", "(", "all", "[", "'true'", "]", ".", "keys", "(", ")", ")", ":", "\n", "\n", "        ", "if", "key", "in", "all_n", "[", "'A'", "]", "or", "(", "key", "[", "0", "]", ",", "key", "[", "2", "]", ",", "key", "[", "1", "]", ")", "in", "all_n", "[", "'A'", "]", ":", "\n", "            ", "continue", "\n", "", "elif", "key", "in", "all", "[", "'A'", "]", ":", "\n", "            ", "all_n", "[", "'A'", "]", "[", "key", "]", "=", "all", "[", "'A'", "]", "[", "key", "]", "\n", "", "elif", "(", "key", "[", "0", "]", ",", "key", "[", "2", "]", ",", "key", "[", "1", "]", ")", "in", "all", "[", "'A'", "]", ":", "\n", "            ", "t", "=", "all", "[", "'A'", "]", "[", "(", "key", "[", "0", "]", ",", "key", "[", "2", "]", ",", "key", "[", "1", "]", ")", "]", ".", "split", "(", "':'", ")", "\n", "all_n", "[", "'A'", "]", "[", "key", "]", "=", "t", "[", "2", "]", "+", "':'", "+", "t", "[", "1", "]", "+", "':'", "+", "t", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "all_n", "[", "'A'", "]", "[", "key", "]", "=", "'1:NR:2'", "\n", "\n", "", "if", "key", "in", "all_n", "[", "'B'", "]", "or", "(", "key", "[", "0", "]", ",", "key", "[", "2", "]", ",", "key", "[", "1", "]", ")", "in", "all_n", "[", "'B'", "]", ":", "\n", "            ", "continue", "\n", "", "elif", "key", "in", "all", "[", "'B'", "]", ":", "\n", "            ", "all_n", "[", "'B'", "]", "[", "key", "]", "=", "all", "[", "'B'", "]", "[", "key", "]", "\n", "", "elif", "(", "key", "[", "0", "]", ",", "key", "[", "2", "]", ",", "key", "[", "1", "]", ")", "in", "all", "[", "'B'", "]", ":", "\n", "            ", "t", "=", "all", "[", "'B'", "]", "[", "(", "key", "[", "0", "]", ",", "key", "[", "2", "]", ",", "key", "[", "1", "]", ")", "]", ".", "split", "(", "':'", ")", "\n", "all_n", "[", "'B'", "]", "[", "key", "]", "=", "t", "[", "2", "]", "+", "':'", "+", "t", "[", "1", "]", "+", "':'", "+", "t", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "all_n", "[", "'B'", "]", "[", "key", "]", "=", "'1:NR:2'", "\n", "\n", "", "if", "key", "in", "all_n", "[", "'true'", "]", "or", "(", "key", "[", "0", "]", ",", "key", "[", "2", "]", ",", "key", "[", "1", "]", ")", "in", "all_n", "[", "'true'", "]", ":", "\n", "            ", "continue", "\n", "", "elif", "key", "in", "all", "[", "'true'", "]", ":", "\n", "            ", "all_n", "[", "'true'", "]", "[", "key", "]", "=", "all", "[", "'true'", "]", "[", "key", "]", "\n", "", "elif", "(", "key", "[", "0", "]", ",", "key", "[", "2", "]", ",", "key", "[", "1", "]", ")", "in", "all", "[", "'true'", "]", ":", "\n", "            ", "t", "=", "all", "[", "'true'", "]", "[", "(", "key", "[", "0", "]", ",", "key", "[", "2", "]", ",", "key", "[", "1", "]", ")", "]", ".", "split", "(", "':'", ")", "\n", "all_n", "[", "'true'", "]", "[", "key", "]", "=", "t", "[", "2", "]", "+", "':'", "+", "t", "[", "1", "]", "+", "':'", "+", "t", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "all_n", "[", "'true'", "]", "[", "key", "]", "=", "'1:NR:2'", "\n", "\n", "", "", "return", "all_n", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.AR_sigtest.eval_": [[82, 103], ["list", "list", "len", "numpy.equal", "numpy.equal", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.sum", "numpy.sum", "numpy.sum", "AR_sigtest.prf", "list.values", "list.values", "numpy.equal", "numpy.not_equal", "numpy.not_equal", "numpy.bincount", "numpy.bincount", "numpy.bincount"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.perf_by_dist.prf"], ["", "def", "eval_", "(", "t", ",", "y", ")", ":", "\n", "    ", "t", "=", "list", "(", "t", ".", "values", "(", ")", ")", "\n", "y", "=", "list", "(", "y", ".", "values", "(", ")", ")", "\n", "\n", "label_num", "=", "len", "(", "map_", ")", "\n", "ignore_label", "=", "0", "\n", "\n", "mask_t", "=", "np", ".", "equal", "(", "t", ",", "ignore_label", ")", "# where the ground truth needs to be ignored", "\n", "mask_p", "=", "np", ".", "equal", "(", "y", ",", "ignore_label", ")", "# where the predicted needs to be ignored", "\n", "\n", "true", "=", "np", ".", "where", "(", "mask_t", ",", "label_num", ",", "t", ")", "# ground truth", "\n", "pred", "=", "np", ".", "where", "(", "mask_p", ",", "label_num", ",", "y", ")", "# output of NN", "\n", "\n", "tp_mask", "=", "np", ".", "where", "(", "np", ".", "equal", "(", "pred", ",", "true", ")", ",", "true", ",", "label_num", ")", "\n", "fp_mask", "=", "np", ".", "where", "(", "np", ".", "not_equal", "(", "pred", ",", "true", ")", ",", "pred", ",", "label_num", ")", "\n", "fn_mask", "=", "np", ".", "where", "(", "np", ".", "not_equal", "(", "pred", ",", "true", ")", ",", "true", ",", "label_num", ")", "\n", "\n", "tp", "=", "np", ".", "sum", "(", "np", ".", "bincount", "(", "tp_mask", ",", "minlength", "=", "label_num", "+", "1", ")", "[", ":", "label_num", "]", ")", "\n", "fp", "=", "np", ".", "sum", "(", "np", ".", "bincount", "(", "fp_mask", ",", "minlength", "=", "label_num", "+", "1", ")", "[", ":", "label_num", "]", ")", "\n", "fn", "=", "np", ".", "sum", "(", "np", ".", "bincount", "(", "fn_mask", ",", "minlength", "=", "label_num", "+", "1", ")", "[", ":", "label_num", "]", ")", "\n", "return", "prf", "(", "tp", ",", "fp", ",", "fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.AR_sigtest.prf": [[105, 110], ["float", "float"], "function", ["None"], ["", "def", "prf", "(", "tp", ",", "fp", ",", "fn", ")", ":", "\n", "    ", "micro_r", "=", "float", "(", "tp", ")", "/", "(", "tp", "+", "fn", ")", "if", "(", "tp", "+", "fn", "!=", "0", ")", "else", "0.0", "\n", "micro_p", "=", "float", "(", "tp", ")", "/", "(", "tp", "+", "fp", ")", "if", "(", "tp", "+", "fp", "!=", "0", ")", "else", "0.0", "\n", "micro_f", "=", "(", "(", "2", "*", "micro_p", "*", "micro_r", ")", "/", "(", "micro_p", "+", "micro_r", ")", ")", "if", "micro_p", "!=", "0.0", "and", "micro_r", "!=", "0.0", "else", "0.0", "\n", "return", "{", "'p'", ":", "micro_p", ",", "'r'", ":", "micro_r", ",", "'f'", ":", "micro_f", "}", "\n", "# return micro_f", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.AR_sigtest.sig_test": [[113, 146], ["tqdm.tqdm", "print", "print", "range", "collections.OrderedDict", "collections.OrderedDict", "system_A.keys", "numpy.abs", "numpy.abs", "random.randint", "AR_sigtest.eval_", "AR_sigtest.eval_", "AR_sigtest.eval_", "AR_sigtest.eval_"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.AR_sigtest.eval_", "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.AR_sigtest.eval_", "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.AR_sigtest.eval_", "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.AR_sigtest.eval_"], ["", "def", "sig_test", "(", "args", ",", "system_A", ",", "system_B", ",", "truth", ")", ":", "\n", "    ", "\"\"\"\n    Approximate Randomization significance test\n    https://cs.stanford.edu/people/wmorgan/sigtest.pdf\n    \"\"\"", "\n", "r", "=", "0", "\n", "for", "R_", "in", "tqdm", "(", "range", "(", "0", ",", "args", ".", "R", ")", ")", ":", "\n", "        ", "listX", "=", "OrderedDict", "(", ")", "\n", "listY", "=", "OrderedDict", "(", ")", "\n", "k", "=", "0", "\n", "\n", "for", "d", "in", "system_A", ".", "keys", "(", ")", ":", "\n", "            ", "choose", "=", "random", ".", "randint", "(", "0", ",", "1", ")", "\n", "if", "choose", "==", "0", ":", "\n", "                ", "listX", "[", "d", "]", "=", "system_A", "[", "d", "]", "\n", "listY", "[", "d", "]", "=", "system_B", "[", "d", "]", "\n", "", "else", ":", "\n", "                ", "listX", "[", "d", "]", "=", "system_B", "[", "d", "]", "\n", "listY", "[", "d", "]", "=", "system_A", "[", "d", "]", "\n", "\n", "", "", "t_xy", "=", "np", ".", "abs", "(", "eval_", "(", "listX", ",", "truth", ")", "[", "'f'", "]", "-", "eval_", "(", "listY", ",", "truth", ")", "[", "'f'", "]", ")", "\n", "t_ab", "=", "np", ".", "abs", "(", "eval_", "(", "system_A", ",", "truth", ")", "[", "'f'", "]", "-", "eval_", "(", "system_B", ",", "truth", ")", "[", "'f'", "]", ")", "\n", "\n", "if", "t_xy", ">=", "t_ab", ":", "\n", "            ", "r", "+=", "1", "\n", "\n", "", "", "significance", "=", "(", "r", "+", "1", ")", "/", "(", "args", ".", "R", "+", "1", ")", "\n", "if", "significance", "<", "0.05", ":", "\n", "        ", "decision", "=", "'SIG !!! :D'", "\n", "", "else", ":", "\n", "        ", "decision", "=", "'NOT SIG :('", "\n", "", "print", "(", "'Significance: {} ==> {}'", ".", "format", "(", "significance", ",", "decision", ")", ")", "\n", "print", "(", "'========================'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.AR_sigtest.main": [[148, 189], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "AR_sigtest.load_data", "AR_sigtest.align", "a_2[].values", "map_.copy", "map_.copy.keys", "zip", "print", "print", "print", "eval_().values", "eval_().values", "print", "print", "AR_sigtest.sig_test", "l.split", "AR_sigtest.eval_", "AR_sigtest.eval_"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.AR_sigtest.load_data", "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.AR_sigtest.align", "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.AR_sigtest.sig_test", "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.AR_sigtest.eval_", "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.AR_sigtest.eval_"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--systemA'", ",", "type", "=", "str", ",", "help", "=", "'predictions for system A'", ")", "\n", "parser", ".", "add_argument", "(", "'--systemB'", ",", "type", "=", "str", ",", "help", "=", "'predictions for system B'", ")", "\n", "parser", ".", "add_argument", "(", "'--truth'", ",", "type", "=", "str", ",", "help", "=", "'true values'", ")", "\n", "parser", ".", "add_argument", "(", "'--R'", ",", "type", "=", "int", ",", "default", "=", "10000", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "a_", "=", "load_data", "(", "args", ")", "\n", "a_2", "=", "align", "(", "a_", ")", "\n", "\n", "global", "map_", "\n", "cnt", "=", "1", "\n", "map_", "=", "{", "'1:NR:2'", ":", "0", "}", "\n", "for", "l", "in", "a_2", "[", "'true'", "]", ".", "values", "(", ")", ":", "\n", "        ", "if", "l", "not", "in", "map_", ":", "\n", "            ", "map_", "[", "l", "]", "=", "cnt", "\n", "cnt", "+=", "1", "\n", "\n", "", "", "map_2", "=", "map_", ".", "copy", "(", ")", "\n", "\n", "for", "l", "in", "map_2", ".", "keys", "(", ")", ":", "\n", "        ", "t", "=", "l", ".", "split", "(", "':'", ")", "\n", "if", "t", "[", "2", "]", "+", "':'", "+", "t", "[", "1", "]", "+", "':'", "+", "t", "[", "0", "]", "not", "in", "map_", ":", "\n", "            ", "map_", "[", "t", "[", "2", "]", "+", "':'", "+", "t", "[", "1", "]", "+", "':'", "+", "t", "[", "0", "]", "]", "=", "cnt", "\n", "cnt", "+=", "1", "\n", "\n", "", "", "for", "l1", ",", "l2", ",", "l3", "in", "zip", "(", "a_2", "[", "'A'", "]", ",", "a_2", "[", "'B'", "]", ",", "a_2", "[", "'true'", "]", ")", ":", "\n", "        ", "a_2", "[", "'A'", "]", "[", "l1", "]", "=", "map_", "[", "a_2", "[", "'A'", "]", "[", "l1", "]", "]", "\n", "a_2", "[", "'B'", "]", "[", "l1", "]", "=", "map_", "[", "a_2", "[", "'B'", "]", "[", "l1", "]", "]", "\n", "a_2", "[", "'true'", "]", "[", "l1", "]", "=", "map_", "[", "a_2", "[", "'true'", "]", "[", "l1", "]", "]", "\n", "\n", "", "print", "(", "args", ".", "systemA", ")", "\n", "print", "(", "args", ".", "systemB", ")", "\n", "\n", "print", "(", "'=== OVERALL ==='", ")", "\n", "p1", ",", "r1", ",", "f1", "=", "eval_", "(", "a_2", "[", "'A'", "]", ",", "a_2", "[", "'true'", "]", ")", ".", "values", "(", ")", "\n", "p2", ",", "r2", ",", "f2", "=", "eval_", "(", "a_2", "[", "'B'", "]", ",", "a_2", "[", "'true'", "]", ")", ".", "values", "(", ")", "\n", "print", "(", "'System A: P = {:.2f}\\tR = {:.2f}\\tF1 = {:.2f}'", ".", "format", "(", "p1", "*", "100", ",", "r1", "*", "100", ",", "f1", "*", "100", ")", ")", "\n", "print", "(", "'System B: P = {:.2f}\\tR = {:.2f}\\tF1 = {:.2f}'", ".", "format", "(", "p2", "*", "100", ",", "r2", "*", "100", ",", "f2", "*", "100", ")", ")", "\n", "sig_test", "(", "args", ",", "a_2", "[", "'A'", "]", ",", "a_2", "[", "'B'", "]", ",", "a_2", "[", "'true'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.eval.f1": [[24, 26], ["None"], "function", ["None"], ["def", "f1", "(", "p", ",", "r", ")", ":", "\n", "    ", "return", "(", "(", "2", "*", "p", "*", "r", ")", "/", "(", "p", "+", "r", ")", ")", "if", "p", "!=", "0.0", "and", "r", "!=", "0.0", "else", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.eval.prf": [[28, 33], ["float", "float"], "function", ["None"], ["", "def", "prf", "(", "tp", ",", "fp", ",", "fn", ")", ":", "\n", "    ", "p", "=", "float", "(", "tp", ")", "/", "(", "tp", "+", "fp", ")", "if", "(", "tp", "+", "fp", "!=", "0", ")", "else", "0.0", "\n", "r", "=", "float", "(", "tp", ")", "/", "(", "tp", "+", "fn", ")", "if", "(", "tp", "+", "fn", "!=", "0", ")", "else", "0.0", "\n", "f", "=", "(", "(", "2", "*", "p", "*", "r", ")", "/", "(", "p", "+", "r", ")", ")", "if", "p", "!=", "0.0", "and", "r", "!=", "0.0", "else", "0.0", "\n", "return", "[", "p", ",", "r", ",", "f", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.eval.evaluation": [[35, 120], ["frozenset", "frozenset", "tqdm.tqdm", "numpy.sum", "numpy.sum", "numpy.sum", "eval.prf", "open", "tqdm.tqdm", "open", "tqdm.tqdm", "line.rstrip().split.rstrip().split", "line2.rstrip().split.rstrip().split", "len", "len", "len", "eval.prf", "line.rstrip().split.rstrip", "line[].split", "line2.rstrip().split.rstrip", "line2[].split"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.perf_by_dist.prf", "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.perf_by_dist.prf"], ["", "def", "evaluation", "(", "preds", ",", "gold", ")", ":", "\n", "    ", "pr", ",", "gl", ",", "labels", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "with", "open", "(", "preds", ",", "'r'", ")", "as", "preds_file", ":", "\n", "        ", "for", "line", "in", "tqdm", "(", "preds_file", ")", ":", "\n", "            ", "line", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "'|'", ")", "\n", "\n", "doc_id", "=", "line", "[", "0", "]", "# .split('.split')[0]", "\n", "\n", "if", "line", "[", "3", "]", "==", "'1:NR:2'", ":", "\n", "                ", "arg1", "=", "line", "[", "1", "]", "\n", "arg2", "=", "line", "[", "2", "]", "\n", "label", "=", "line", "[", "3", "]", "\n", "", "elif", "':'", "not", "in", "line", "[", "3", "]", ":", "\n", "                ", "arg1", "=", "line", "[", "1", "]", "\n", "arg2", "=", "line", "[", "2", "]", "\n", "label", "=", "line", "[", "3", "]", "\n", "", "else", ":", "\n", "                ", "l", "=", "line", "[", "3", "]", ".", "split", "(", "':'", ")", "\n", "if", "l", "[", "1", "]", "!=", "'NR'", "and", "l", "[", "0", "]", "==", "'1'", ":", "\n", "                    ", "arg1", "=", "line", "[", "1", "]", "\n", "arg2", "=", "line", "[", "2", "]", "\n", "label", "=", "l", "[", "1", "]", "\n", "", "elif", "l", "[", "1", "]", "!=", "'NR'", "and", "l", "[", "0", "]", "==", "'2'", ":", "\n", "                    ", "arg1", "=", "line", "[", "2", "]", "\n", "arg2", "=", "line", "[", "1", "]", "\n", "label", "=", "l", "[", "1", "]", "\n", "", "else", ":", "\n", "                    ", "continue", "\n", "\n", "", "", "pr", "+=", "[", "(", "doc_id", ",", "arg1", ",", "arg2", ",", "label", ")", "]", "\n", "\n", "", "", "with", "open", "(", "gold", ",", "'r'", ")", "as", "gold_file", ":", "\n", "        ", "for", "line2", "in", "tqdm", "(", "gold_file", ")", ":", "\n", "            ", "line2", "=", "line2", ".", "rstrip", "(", ")", ".", "split", "(", "'|'", ")", "\n", "\n", "doc_id", "=", "line2", "[", "0", "]", "#.split('**')[0]", "\n", "\n", "if", "line2", "[", "3", "]", "==", "'1:NR:2'", ":", "\n", "                ", "arg1", "=", "line2", "[", "1", "]", "\n", "arg2", "=", "line2", "[", "2", "]", "\n", "label", "=", "line2", "[", "3", "]", "\n", "", "elif", "':'", "not", "in", "line2", "[", "3", "]", ":", "\n", "                ", "arg1", "=", "line2", "[", "1", "]", "\n", "arg2", "=", "line2", "[", "2", "]", "\n", "label", "=", "line2", "[", "3", "]", "\n", "", "else", ":", "\n", "                ", "l2", "=", "line2", "[", "3", "]", ".", "split", "(", "':'", ")", "\n", "if", "l2", "[", "1", "]", "!=", "'NR'", "and", "l2", "[", "0", "]", "==", "'1'", ":", "\n", "                    ", "arg1", "=", "line2", "[", "1", "]", "\n", "arg2", "=", "line2", "[", "2", "]", "\n", "label", "=", "l2", "[", "1", "]", "\n", "", "elif", "l2", "[", "1", "]", "!=", "'NR'", "and", "l2", "[", "0", "]", "==", "'2'", ":", "\n", "                    ", "arg1", "=", "line2", "[", "2", "]", "\n", "arg2", "=", "line2", "[", "1", "]", "\n", "label", "=", "l2", "[", "1", "]", "\n", "", "else", ":", "\n", "                    ", "continue", "\n", "\n", "", "", "if", "label", "not", "in", "labels", ":", "\n", "                ", "labels", "+=", "[", "label", "]", "\n", "", "gl", "+=", "[", "(", "doc_id", ",", "arg1", ",", "arg2", ",", "label", ")", "]", "\n", "\n", "", "", "tp", ",", "fp", ",", "fn", "=", "{", "}", ",", "{", "}", ",", "{", "}", "\n", "classes", "=", "{", "}", "\n", "\n", "gl", "=", "frozenset", "(", "gl", ")", "# in order to be faster", "\n", "pr", "=", "frozenset", "(", "pr", ")", "\n", "for", "l", "in", "labels", ":", "\n", "        ", "tp", "[", "l", "]", "=", "0", "\n", "fp", "[", "l", "]", "=", "0", "\n", "fn", "[", "l", "]", "=", "0", "\n", "\n", "", "for", "l", "in", "tqdm", "(", "labels", ")", ":", "\n", "        ", "if", "l", "!=", "'1:NR:2'", ":", "\n", "            ", "tp", "[", "l", "]", "+=", "len", "(", "[", "a", "for", "a", "in", "pr", "if", "a", "in", "gl", "and", "a", "[", "3", "]", "==", "l", "]", ")", "\n", "fp", "[", "l", "]", "+=", "len", "(", "[", "a", "for", "a", "in", "pr", "if", "a", "not", "in", "gl", "and", "a", "[", "3", "]", "==", "l", "]", ")", "\n", "fn", "[", "l", "]", "+=", "len", "(", "[", "a", "for", "a", "in", "gl", "if", "a", "not", "in", "pr", "and", "a", "[", "3", "]", "==", "l", "]", ")", "\n", "classes", "[", "l", "]", "=", "prf", "(", "tp", "[", "l", "]", ",", "fp", "[", "l", "]", ",", "fn", "[", "l", "]", ")", "\n", "\n", "", "", "tp_tot", "=", "np", ".", "sum", "(", "[", "tp", "[", "a", "]", "for", "a", "in", "tp", "]", ")", "\n", "fp_tot", "=", "np", ".", "sum", "(", "[", "fp", "[", "a", "]", "for", "a", "in", "fp", "]", ")", "# len([a for a in pr if a not in gl])", "\n", "fn_tot", "=", "np", ".", "sum", "(", "[", "fn", "[", "a", "]", "for", "a", "in", "fn", "]", ")", "# len([a for a in gl if a not in pr])", "\n", "\n", "total", "=", "prf", "(", "tp_tot", ",", "fp_tot", ",", "fn_tot", ")", "\n", "return", "total", ",", "classes", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.perf_by_ent.f1": [[32, 34], ["None"], "function", ["None"], ["def", "f1", "(", "p", ",", "r", ")", ":", "\n", "    ", "return", "(", "(", "2", "*", "p", "*", "r", ")", "/", "(", "p", "+", "r", ")", ")", "if", "p", "!=", "0.0", "and", "r", "!=", "0.0", "else", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.perf_by_ent.prf": [[36, 41], ["float", "float"], "function", ["None"], ["", "def", "prf", "(", "tp", ",", "fp", ",", "fn", ")", ":", "\n", "    ", "p", "=", "float", "(", "tp", ")", "/", "(", "tp", "+", "fp", ")", "if", "(", "tp", "+", "fp", "!=", "0", ")", "else", "0.0", "\n", "r", "=", "float", "(", "tp", ")", "/", "(", "tp", "+", "fn", ")", "if", "(", "tp", "+", "fn", "!=", "0", ")", "else", "0.0", "\n", "f", "=", "(", "(", "2", "*", "p", "*", "r", ")", "/", "(", "p", "+", "r", ")", ")", "if", "p", "!=", "0.0", "and", "r", "!=", "0.0", "else", "0.0", "\n", "return", "[", "p", ",", "r", ",", "f", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.perf_by_ent.evaluation": [[43, 126], ["frozenset", "frozenset", "numpy.sum", "numpy.sum", "numpy.sum", "perf_by_ent.prf", "open", "open", "len", "len", "line.rstrip().split.rstrip().split", "line2.rstrip().split.rstrip().split", "len", "len", "len", "perf_by_ent.prf", "line.rstrip().split.rstrip", "line[].split", "line2.rstrip().split.rstrip", "line2[].split"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.perf_by_dist.prf", "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.perf_by_dist.prf"], ["", "def", "evaluation", "(", "preds", ",", "gold", ")", ":", "\n", "    ", "pr", ",", "gl", ",", "labels", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "with", "open", "(", "preds", ",", "'r'", ")", "as", "preds_file", ":", "\n", "        ", "for", "line", "in", "preds_file", ":", "\n", "            ", "line", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "'|'", ")", "\n", "doc_id", "=", "line", "[", "0", "]", "\n", "\n", "if", "line", "[", "3", "]", "==", "'1:NR:2'", ":", "\n", "                ", "arg1", "=", "line", "[", "1", "]", "\n", "arg2", "=", "line", "[", "2", "]", "\n", "label", "=", "line", "[", "3", "]", "\n", "", "elif", "':'", "not", "in", "line", "[", "3", "]", ":", "\n", "                ", "arg1", "=", "line", "[", "1", "]", "\n", "arg2", "=", "line", "[", "2", "]", "\n", "label", "=", "line", "[", "3", "]", "\n", "", "else", ":", "\n", "                ", "l", "=", "line", "[", "3", "]", ".", "split", "(", "':'", ")", "\n", "if", "l", "[", "1", "]", "!=", "'NR'", "and", "l", "[", "0", "]", "==", "'1'", ":", "\n", "                    ", "arg1", "=", "line", "[", "1", "]", "\n", "arg2", "=", "line", "[", "2", "]", "\n", "label", "=", "l", "[", "1", "]", "\n", "", "elif", "l", "[", "1", "]", "!=", "'NR'", "and", "l", "[", "0", "]", "==", "'2'", ":", "\n", "                    ", "arg1", "=", "line", "[", "2", "]", "\n", "arg2", "=", "line", "[", "1", "]", "\n", "label", "=", "l", "[", "1", "]", "\n", "", "else", ":", "\n", "                    ", "continue", "\n", "", "", "pr", "+=", "[", "(", "doc_id", ",", "arg1", ",", "arg2", ",", "label", ")", "]", "\n", "\n", "", "", "with", "open", "(", "gold", ",", "'r'", ")", "as", "gold_file", ":", "\n", "        ", "for", "line2", "in", "gold_file", ":", "\n", "            ", "line2", "=", "line2", ".", "rstrip", "(", ")", ".", "split", "(", "'|'", ")", "\n", "\n", "doc_id", "=", "line2", "[", "0", "]", "\n", "\n", "if", "line2", "[", "3", "]", "==", "'1:NR:2'", ":", "\n", "                ", "arg1", "=", "line2", "[", "1", "]", "\n", "arg2", "=", "line2", "[", "2", "]", "\n", "label", "=", "line2", "[", "3", "]", "\n", "", "elif", "':'", "not", "in", "line2", "[", "3", "]", ":", "\n", "                ", "arg1", "=", "line2", "[", "1", "]", "\n", "arg2", "=", "line2", "[", "2", "]", "\n", "label", "=", "line2", "[", "3", "]", "\n", "", "else", ":", "\n", "                ", "l2", "=", "line2", "[", "3", "]", ".", "split", "(", "':'", ")", "\n", "if", "l2", "[", "1", "]", "!=", "'NR'", "and", "l2", "[", "0", "]", "==", "'1'", ":", "\n", "                    ", "arg1", "=", "line2", "[", "1", "]", "\n", "arg2", "=", "line2", "[", "2", "]", "\n", "label", "=", "l2", "[", "1", "]", "\n", "", "elif", "l2", "[", "1", "]", "!=", "'NR'", "and", "l2", "[", "0", "]", "==", "'2'", ":", "\n", "                    ", "arg1", "=", "line2", "[", "2", "]", "\n", "arg2", "=", "line2", "[", "1", "]", "\n", "label", "=", "l2", "[", "1", "]", "\n", "", "else", ":", "\n", "                    ", "continue", "\n", "\n", "", "", "if", "label", "not", "in", "labels", ":", "\n", "                ", "labels", "+=", "[", "label", "]", "\n", "", "gl", "+=", "[", "(", "doc_id", ",", "arg1", ",", "arg2", ",", "label", ")", "]", "\n", "\n", "", "", "tp", ",", "fp", ",", "fn", "=", "{", "}", ",", "{", "}", ",", "{", "}", "\n", "classes", "=", "{", "}", "\n", "\n", "gl", "=", "frozenset", "(", "gl", ")", "# in order to be faster", "\n", "pr", "=", "frozenset", "(", "pr", ")", "\n", "for", "l", "in", "labels", ":", "\n", "        ", "tp", "[", "l", "]", "=", "0", "\n", "fp", "[", "l", "]", "=", "0", "\n", "fn", "[", "l", "]", "=", "0", "\n", "\n", "", "for", "l", "in", "labels", ":", "\n", "        ", "if", "l", "!=", "'1:NR:2'", ":", "\n", "            ", "tp", "[", "l", "]", "+=", "len", "(", "[", "a", "for", "a", "in", "pr", "if", "a", "in", "gl", "and", "a", "[", "3", "]", "==", "l", "]", ")", "\n", "fp", "[", "l", "]", "+=", "len", "(", "[", "a", "for", "a", "in", "pr", "if", "a", "not", "in", "gl", "and", "a", "[", "3", "]", "==", "l", "]", ")", "\n", "fn", "[", "l", "]", "+=", "len", "(", "[", "a", "for", "a", "in", "gl", "if", "a", "not", "in", "pr", "and", "a", "[", "3", "]", "==", "l", "]", ")", "\n", "classes", "[", "l", "]", "=", "prf", "(", "tp", "[", "l", "]", ",", "fp", "[", "l", "]", ",", "fn", "[", "l", "]", ")", "\n", "\n", "", "", "tp_tot", "=", "np", ".", "sum", "(", "[", "tp", "[", "a", "]", "for", "a", "in", "tp", "]", ")", "\n", "fp_tot", "=", "np", ".", "sum", "(", "[", "fp", "[", "a", "]", "for", "a", "in", "fp", "]", ")", "# len([a for a in pr if a not in gl])", "\n", "fn_tot", "=", "np", ".", "sum", "(", "[", "fn", "[", "a", "]", "for", "a", "in", "fn", "]", ")", "# len([a for a in gl if a not in pr])", "\n", "\n", "total", "=", "prf", "(", "tp_tot", ",", "fp_tot", ",", "fn_tot", ")", "\n", "return", "len", "(", "pr", ")", ",", "len", "(", "gl", ")", ",", "total", ",", "classes", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.perf_by_dist.f1": [[31, 33], ["None"], "function", ["None"], ["def", "f1", "(", "p", ",", "r", ")", ":", "\n", "    ", "return", "(", "(", "2", "*", "p", "*", "r", ")", "/", "(", "p", "+", "r", ")", ")", "if", "p", "!=", "0.0", "and", "r", "!=", "0.0", "else", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.perf_by_dist.prf": [[35, 40], ["float", "float"], "function", ["None"], ["", "def", "prf", "(", "tp", ",", "fp", ",", "fn", ")", ":", "\n", "    ", "p", "=", "float", "(", "tp", ")", "/", "(", "tp", "+", "fp", ")", "if", "(", "tp", "+", "fp", "!=", "0", ")", "else", "0.0", "\n", "r", "=", "float", "(", "tp", ")", "/", "(", "tp", "+", "fn", ")", "if", "(", "tp", "+", "fn", "!=", "0", ")", "else", "0.0", "\n", "f", "=", "(", "(", "2", "*", "p", "*", "r", ")", "/", "(", "p", "+", "r", ")", ")", "if", "p", "!=", "0.0", "and", "r", "!=", "0.0", "else", "0.0", "\n", "return", "[", "p", ",", "r", ",", "f", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.perf_by_dist.evaluation": [[42, 126], ["frozenset", "frozenset", "numpy.sum", "numpy.sum", "numpy.sum", "perf_by_dist.prf", "open", "open", "len", "len", "line.rstrip().split.rstrip().split", "line2.rstrip().split.rstrip().split", "len", "len", "len", "perf_by_dist.prf", "line.rstrip().split.rstrip", "line[].split", "line2.rstrip().split.rstrip", "line2[].split"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.perf_by_dist.prf", "home.repos.pwc.inspect_result.fenchri_walk-based-re.analysis.perf_by_dist.prf"], ["", "def", "evaluation", "(", "preds", ",", "gold", ")", ":", "\n", "    ", "pr", ",", "gl", ",", "labels", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "with", "open", "(", "preds", ",", "'r'", ")", "as", "preds_file", ":", "\n", "        ", "for", "line", "in", "preds_file", ":", "\n", "            ", "line", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "'|'", ")", "\n", "doc_id", "=", "line", "[", "0", "]", "\n", "\n", "if", "line", "[", "3", "]", "==", "'1:NR:2'", ":", "\n", "                ", "arg1", "=", "line", "[", "1", "]", "\n", "arg2", "=", "line", "[", "2", "]", "\n", "label", "=", "line", "[", "3", "]", "\n", "", "elif", "':'", "not", "in", "line", "[", "3", "]", ":", "\n", "                ", "arg1", "=", "line", "[", "1", "]", "\n", "arg2", "=", "line", "[", "2", "]", "\n", "label", "=", "line", "[", "3", "]", "\n", "", "else", ":", "\n", "                ", "l", "=", "line", "[", "3", "]", ".", "split", "(", "':'", ")", "\n", "if", "l", "[", "1", "]", "!=", "'NR'", "and", "l", "[", "0", "]", "==", "'1'", ":", "\n", "                    ", "arg1", "=", "line", "[", "1", "]", "\n", "arg2", "=", "line", "[", "2", "]", "\n", "label", "=", "l", "[", "1", "]", "\n", "", "elif", "l", "[", "1", "]", "!=", "'NR'", "and", "l", "[", "0", "]", "==", "'2'", ":", "\n", "                    ", "arg1", "=", "line", "[", "2", "]", "\n", "arg2", "=", "line", "[", "1", "]", "\n", "label", "=", "l", "[", "1", "]", "\n", "", "else", ":", "\n", "                    ", "continue", "\n", "\n", "", "", "pr", "+=", "[", "(", "doc_id", ",", "arg1", ",", "arg2", ",", "label", ")", "]", "\n", "\n", "", "", "with", "open", "(", "gold", ",", "'r'", ")", "as", "gold_file", ":", "\n", "        ", "for", "line2", "in", "gold_file", ":", "\n", "            ", "line2", "=", "line2", ".", "rstrip", "(", ")", ".", "split", "(", "'|'", ")", "\n", "\n", "doc_id", "=", "line2", "[", "0", "]", "\n", "\n", "if", "line2", "[", "3", "]", "==", "'1:NR:2'", ":", "\n", "                ", "arg1", "=", "line2", "[", "1", "]", "\n", "arg2", "=", "line2", "[", "2", "]", "\n", "label", "=", "line2", "[", "3", "]", "\n", "", "elif", "':'", "not", "in", "line2", "[", "3", "]", ":", "\n", "                ", "arg1", "=", "line2", "[", "1", "]", "\n", "arg2", "=", "line2", "[", "2", "]", "\n", "label", "=", "line2", "[", "3", "]", "\n", "", "else", ":", "\n", "                ", "l2", "=", "line2", "[", "3", "]", ".", "split", "(", "':'", ")", "\n", "if", "l2", "[", "1", "]", "!=", "'NR'", "and", "l2", "[", "0", "]", "==", "'1'", ":", "\n", "                    ", "arg1", "=", "line2", "[", "1", "]", "\n", "arg2", "=", "line2", "[", "2", "]", "\n", "label", "=", "l2", "[", "1", "]", "\n", "", "elif", "l2", "[", "1", "]", "!=", "'NR'", "and", "l2", "[", "0", "]", "==", "'2'", ":", "\n", "                    ", "arg1", "=", "line2", "[", "2", "]", "\n", "arg2", "=", "line2", "[", "1", "]", "\n", "label", "=", "l2", "[", "1", "]", "\n", "", "else", ":", "\n", "                    ", "continue", "\n", "\n", "", "", "if", "label", "not", "in", "labels", ":", "\n", "                ", "labels", "+=", "[", "label", "]", "\n", "", "gl", "+=", "[", "(", "doc_id", ",", "arg1", ",", "arg2", ",", "label", ")", "]", "\n", "\n", "", "", "tp", ",", "fp", ",", "fn", "=", "{", "}", ",", "{", "}", ",", "{", "}", "\n", "classes", "=", "{", "}", "\n", "\n", "gl", "=", "frozenset", "(", "gl", ")", "# in order to be faster", "\n", "pr", "=", "frozenset", "(", "pr", ")", "\n", "for", "l", "in", "labels", ":", "\n", "        ", "tp", "[", "l", "]", "=", "0", "\n", "fp", "[", "l", "]", "=", "0", "\n", "fn", "[", "l", "]", "=", "0", "\n", "\n", "", "for", "l", "in", "labels", ":", "\n", "        ", "if", "l", "!=", "'1:NR:2'", ":", "\n", "            ", "tp", "[", "l", "]", "+=", "len", "(", "[", "a", "for", "a", "in", "pr", "if", "a", "in", "gl", "and", "a", "[", "3", "]", "==", "l", "]", ")", "\n", "fp", "[", "l", "]", "+=", "len", "(", "[", "a", "for", "a", "in", "pr", "if", "a", "not", "in", "gl", "and", "a", "[", "3", "]", "==", "l", "]", ")", "\n", "fn", "[", "l", "]", "+=", "len", "(", "[", "a", "for", "a", "in", "gl", "if", "a", "not", "in", "pr", "and", "a", "[", "3", "]", "==", "l", "]", ")", "\n", "classes", "[", "l", "]", "=", "prf", "(", "tp", "[", "l", "]", ",", "fp", "[", "l", "]", ",", "fn", "[", "l", "]", ")", "\n", "\n", "", "", "tp_tot", "=", "np", ".", "sum", "(", "[", "tp", "[", "a", "]", "for", "a", "in", "tp", "]", ")", "\n", "fp_tot", "=", "np", ".", "sum", "(", "[", "fp", "[", "a", "]", "for", "a", "in", "fp", "]", ")", "# len([a for a in pr if a not in gl])", "\n", "fn_tot", "=", "np", ".", "sum", "(", "[", "fn", "[", "a", "]", "for", "a", "in", "fn", "]", ")", "# len([a for a in gl if a not in pr])", "\n", "\n", "total", "=", "prf", "(", "tp_tot", ",", "fp_tot", ",", "fn_tot", ")", "\n", "return", "len", "(", "pr", ")", ",", "len", "(", "gl", ")", ",", "total", ",", "classes", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.modules.EmbedLayer.__init__": [[16, 41], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.torch.nn.Embedding", "torch.nn.Dropout", "torch.torch.nn.Dropout", "modules.EmbedLayer.load_pretrained"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.init_net.BaseNet.__init__", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.modules.EmbedLayer.load_pretrained"], ["    ", "def", "__init__", "(", "self", ",", "num_embeddings", ",", "embedding_dim", ",", "dropout", ",", "ignore", "=", "None", ",", "freeze", "=", "False", ",", "pretrained", "=", "None", ",", "mapping", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            num_embeddings: (tensor) number of unique items\n            embedding_dim: (int) dimensionality of vectors\n            dropout: (float) dropout rate\n            trainable: (bool) train or not\n            pretrained: (dict) pretrained embeddings\n            mapping: (dict) mapping of items to unique ids\n        \"\"\"", "\n", "super", "(", "EmbedLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "num_embeddings", "=", "num_embeddings", "\n", "self", ".", "freeze", "=", "freeze", "\n", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "num_embeddings", "=", "num_embeddings", ",", "\n", "embedding_dim", "=", "embedding_dim", ",", "\n", "padding_idx", "=", "ignore", ")", "\n", "\n", "if", "pretrained", ":", "\n", "            ", "self", ".", "load_pretrained", "(", "pretrained", ",", "mapping", ")", "\n", "", "self", ".", "embedding", ".", "weight", ".", "requires_grad", "=", "True", "# not freeze", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.modules.EmbedLayer.load_pretrained": [[42, 55], ["mapping.keys", "torch.nn.Parameter", "torch.torch.nn.Parameter", "torch.from_numpy", "torch.torch.from_numpy", "torch.torch.from_numpy", "torch.torch.torch.from_numpy", "word.lower", "torch.nn.Parameter", "torch.torch.nn.Parameter", "torch.from_numpy", "torch.torch.from_numpy", "torch.torch.from_numpy", "torch.torch.torch.from_numpy", "word.lower"], "methods", ["None"], ["", "def", "load_pretrained", "(", "self", ",", "pretrained", ",", "mapping", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            pretrained: (dict) keys are words, values are vectors\n            mapping: (dict) keys are words, values are unique ids\n\n        Returns: updates the embedding matrix with pre-trained embeddings\n        \"\"\"", "\n", "for", "word", "in", "mapping", ".", "keys", "(", ")", ":", "\n", "            ", "if", "word", "in", "pretrained", ":", "\n", "                ", "self", ".", "embedding", ".", "weight", ".", "data", "[", "mapping", "[", "word", "]", ",", ":", "]", "=", "nn", ".", "Parameter", "(", "torch", ".", "from_numpy", "(", "pretrained", "[", "word", "]", ")", ")", "\n", "", "elif", "word", ".", "lower", "(", ")", "in", "pretrained", ":", "\n", "                ", "self", ".", "embedding", ".", "weight", ".", "data", "[", "mapping", "[", "word", "]", ",", ":", "]", "=", "nn", ".", "Parameter", "(", "torch", ".", "from_numpy", "(", "pretrained", "[", "word", ".", "lower", "(", ")", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.modules.EmbedLayer.forward": [[56, 68], ["modules.EmbedLayer.embedding", "modules.EmbedLayer.drop"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "xs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            xs: (tensor) batchsize x word_ids\n\n        Returns: (tensor) batchsize x word_ids x dimensionality\n        \"\"\"", "\n", "embeds", "=", "self", ".", "embedding", "(", "xs", ")", "\n", "if", "self", ".", "drop", ".", "p", ">", "0", ":", "\n", "            ", "embeds", "=", "self", ".", "drop", "(", "embeds", ")", "\n", "\n", "", "return", "embeds", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.modules.Encoder.__init__": [[71, 113], ["torch.nn.Module.__init__", "torch.nn.LSTM", "torch.torch.nn.LSTM", "torch.nn.Dropout", "torch.torch.nn.Dropout", "filter", "getattr", "getattr.size", "torch.nn.init.constant_", "torch.torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.init_net.BaseNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "rnn_size", ",", "num_layers", ",", "bidirectional", ",", "dropout", ")", ":", "\n", "        ", "\"\"\"\n        Wrapper for LSTM encoder\n        Args:\n            input_size (int): the size of the input features\n            rnn_size (int):\n            num_layers (int):\n            bidirectional (bool):\n            dropout (float):\n        Returns: outputs, last_outputs\n        - **outputs** of shape `(batch, seq_len, hidden_size)`:\n          tensor containing the output features `(h_t)`\n          from the last layer of the LSTM, for each t.\n        - **last_outputs** of shape `(batch, hidden_size)`:\n          tensor containing the last output features\n          from the last layer of the LSTM, for each t=seq_len.\n        \"\"\"", "\n", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "enc", "=", "nn", ".", "LSTM", "(", "input_size", "=", "input_size", ",", "\n", "hidden_size", "=", "rnn_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", "dropout", "=", "dropout", ",", "\n", "batch_first", "=", "True", ")", "\n", "\n", "# the dropout \"layer\" for the output of the RNN", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "# define output feature size", "\n", "self", ".", "feature_size", "=", "rnn_size", "\n", "\n", "if", "bidirectional", ":", "\n", "            ", "self", ".", "feature_size", "*=", "2", "\n", "\n", "# initialize forget gate biases to 1", "\n", "", "for", "names", "in", "self", ".", "enc", ".", "_all_weights", ":", "\n", "            ", "for", "name", "in", "filter", "(", "lambda", "n", ":", "\"bias\"", "in", "n", ",", "names", ")", ":", "\n", "                ", "bias", "=", "getattr", "(", "self", ".", "enc", ",", "name", ")", "\n", "n", "=", "bias", ".", "size", "(", "0", ")", "\n", "start", ",", "end", "=", "n", "//", "4", ",", "n", "//", "2", "\n", "nn", ".", "init", ".", "constant_", "(", "bias", "[", "start", ":", "end", "]", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.modules.Encoder.sort": [[114, 121], ["lengths.sort", "sorted_idx.sort", "torch.linspace().long", "torch.torch.linspace().long", "torch.torch.linspace().long", "torch.torch.torch.linspace().long", "torch.linspace", "torch.torch.linspace", "torch.torch.linspace", "torch.torch.torch.linspace", "lengths.size", "lengths.size"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.modules.Encoder.sort", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.modules.Encoder.sort"], ["", "", "", "@", "staticmethod", "\n", "def", "sort", "(", "lengths", ")", ":", "\n", "        ", "sorted_len", ",", "sorted_idx", "=", "lengths", ".", "sort", "(", ")", "# indices that result in sorted sequence", "\n", "_", ",", "original_idx", "=", "sorted_idx", ".", "sort", "(", "0", ",", "descending", "=", "True", ")", "\n", "reverse_idx", "=", "torch", ".", "linspace", "(", "lengths", ".", "size", "(", "0", ")", "-", "1", ",", "0", ",", "lengths", ".", "size", "(", "0", ")", ")", ".", "long", "(", ")", "# for big-to-small", "\n", "\n", "return", "sorted_idx", ",", "original_idx", ",", "reverse_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.modules.Encoder.forward": [[122, 152], ["modules.Encoder.sort", "torch.nn.utils.rnn.pad_sequence", "torch.torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.torch.nn.utils.rnn.pack_padded_sequence", "modules.Encoder.enc.flatten_parameters", "modules.Encoder.enc", "torch.nn.utils.rnn.pad_packed_sequence", "torch.torch.nn.utils.rnn.pad_packed_sequence", "list", "modules.Encoder.drop"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.modules.Encoder.sort"], ["", "def", "forward", "(", "self", ",", "embeds", ",", "lengths", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        This is the heart of the model. This function, defines how the data\n        passes through the network.\n        Args:\n            embs (tensor): word embeddings\n            lengths (list): the lengths of each sentence\n        Returns: the logits for each class\n        \"\"\"", "\n", "# sort sequence", "\n", "sorted_idx", ",", "original_idx", ",", "reverse_idx", "=", "self", ".", "sort", "(", "lengths", ")", "\n", "\n", "# pad - sort - pack", "\n", "embeds", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "embeds", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "embeds", "=", "embeds", "[", "sorted_idx", "]", "[", "reverse_idx", "]", "# big-to-small", "\n", "packed", "=", "pack_padded_sequence", "(", "embeds", ",", "list", "(", "lengths", "[", "sorted_idx", "]", "[", "reverse_idx", "]", ".", "data", ")", ",", "batch_first", "=", "True", ")", "\n", "\n", "self", ".", "enc", ".", "flatten_parameters", "(", ")", "\n", "out_packed", ",", "_", "=", "self", ".", "enc", "(", "packed", ",", "hidden", ")", "\n", "\n", "# unpack", "\n", "outputs", ",", "_", "=", "pad_packed_sequence", "(", "out_packed", ",", "batch_first", "=", "True", ")", "\n", "\n", "# apply dropout to the outputs of the RNN", "\n", "if", "self", ".", "drop", ".", "p", ">", "0", ":", "\n", "            ", "outputs", "=", "self", ".", "drop", "(", "outputs", ")", "\n", "\n", "# unsort the list", "\n", "", "outputs", "=", "outputs", "[", "reverse_idx", "]", "[", "original_idx", "]", "[", "reverse_idx", "]", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.modules.Classifier.__init__": [[155, 168], ["torch.nn.Module.__init__", "torch.nn.Dropout", "torch.torch.nn.Dropout", "torch.nn.Linear", "torch.torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.init_net.BaseNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_size", ",", "out_size", ",", "dropout", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            in_size: input tensor dimensionality\n            out_size: outpout tensor dimensionality\n            dropout: dropout rate\n        \"\"\"", "\n", "super", "(", "Classifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "lin", "=", "nn", ".", "Linear", "(", "in_features", "=", "in_size", ",", "\n", "out_features", "=", "out_size", ",", "\n", "bias", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.modules.Classifier.forward": [[169, 181], ["modules.Classifier.lin", "modules.Classifier.drop"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "xs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            xs: (tensor) batchsize x * x features\n\n        Returns: (tensor) batchsize x * x class_size\n        \"\"\"", "\n", "if", "self", ".", "drop", ".", "p", ">", "0", ":", "\n", "            ", "xs", "=", "self", ".", "drop", "(", "xs", ")", "\n", "\n", "", "xs", "=", "self", ".", "lin", "(", "xs", ")", "\n", "return", "xs", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.__init__": [[25, 57], ["torch.device", "os.path.join", "trainer.Trainer.init_model", "trainer.Trainer.set_optimizer", "print_options", "print_hyperparams"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.init_model", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.set_optimizer", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.print_options", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.print_hyperparams"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "params", ",", "loader", ",", "model_folder", ")", ":", "\n", "        ", "self", ".", "converter", "=", "concat_examples", "\n", "self", ".", "data", "=", "data", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda:{}\"", ".", "format", "(", "params", "[", "'gpu'", "]", ")", "if", "params", "[", "'gpu'", "]", "!=", "-", "1", "else", "\"cpu\"", ")", "\n", "self", ".", "params", "=", "params", "\n", "self", ".", "loader", "=", "loader", "\n", "self", ".", "epoch", "=", "params", "[", "'epoch'", "]", "\n", "self", ".", "primary_metric", "=", "params", "[", "'early_metric'", "]", "\n", "self", ".", "es", "=", "params", "[", "'early_stopping'", "]", "\n", "self", ".", "pa", "=", "params", "[", "'param_avg'", "]", "\n", "self", ".", "show_class", "=", "params", "[", "'show_class'", "]", "\n", "self", ".", "saveto", "=", "os", ".", "path", ".", "join", "(", "model_folder", ",", "params", "[", "'save_preds'", "]", ")", "\n", "self", ".", "model_folder", "=", "model_folder", "\n", "\n", "self", ".", "best_score", "=", "0.0", "\n", "self", ".", "best_epoch", "=", "0", "\n", "self", ".", "best_loss", "=", "9999999999", "\n", "\n", "if", "params", "[", "'early_stopping'", "]", ":", "\n", "            ", "self", ".", "patience", "=", "params", "[", "'patience'", "]", "\n", "self", ".", "cur_patience", "=", "0", "\n", "\n", "", "if", "params", "[", "'param_avg'", "]", ":", "\n", "            ", "self", ".", "averaged_params", "=", "{", "}", "\n", "\n", "", "self", ".", "train_res", "=", "{", "'loss'", ":", "[", "]", ",", "'score'", ":", "[", "]", "}", "\n", "self", ".", "test_res", "=", "{", "'loss'", ":", "[", "]", ",", "'score'", ":", "[", "]", "}", "\n", "\n", "self", ".", "model", "=", "self", ".", "init_model", "(", ")", "\n", "self", ".", "optimizer", "=", "self", ".", "set_optimizer", "(", ")", "\n", "print_options", "(", "self", ".", "model", ",", "self", ".", "params", ")", "\n", "print_hyperparams", "(", "self", ".", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.init_model": [[58, 75], ["nnet.network.WalkBasedModel", "torch.cuda.set_device", "nnet.network.WalkBasedModel.to"], "methods", ["None"], ["", "def", "init_model", "(", "self", ")", ":", "\n", "        ", "model", "=", "WalkBasedModel", "(", "self", ".", "params", ",", "\n", "{", "'word_size'", ":", "self", ".", "loader", ".", "n_words", ",", "'pos_size'", ":", "self", ".", "loader", ".", "n_pos", ",", "\n", "'type_size'", ":", "self", ".", "loader", ".", "n_type", ",", "'rel_size'", ":", "self", ".", "loader", ".", "n_rel", "}", ",", "\n", "self", ".", "loader", ".", "pre_embeds", ",", "\n", "lab2ign", "=", "self", ".", "loader", ".", "label2ignore", ",", "\n", "o_type", "=", "self", ".", "loader", ".", "type2index", "[", "'O'", "]", ",", "\n", "maps", "=", "{", "'idx2word'", ":", "self", ".", "loader", ".", "index2word", ",", "'word2idx'", ":", "self", ".", "loader", ".", "word2index", ",", "\n", "'idx2rel'", ":", "self", ".", "loader", ".", "index2rel", ",", "'rel2idx'", ":", "self", ".", "loader", ".", "rel2index", ",", "\n", "'idx2pos'", ":", "self", ".", "loader", ".", "index2pos", ",", "'pos2idx'", ":", "self", ".", "loader", ".", "pos2index", ",", "\n", "'idx2type'", ":", "self", ".", "loader", ".", "index2type", ",", "'type2idx'", ":", "self", ".", "loader", ".", "type2index", "}", ")", "\n", "\n", "# GPU/CPU", "\n", "if", "self", ".", "params", "[", "'gpu'", "]", "!=", "-", "1", ":", "\n", "            ", "torch", ".", "cuda", ".", "set_device", "(", "self", ".", "device", ")", "\n", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.set_optimizer": [[76, 96], ["trainer.Trainer.model.named_parameters", "torch.optim.Adam", "print", "trainer.Trainer.model.named_parameters", "len", "dict", "dict", "len", "len", "list", "print", "trainer.Trainer.model.parameters"], "methods", ["None"], ["", "def", "set_optimizer", "(", "self", ")", ":", "\n", "# OPTIMIZER", "\n", "# do not regularize biases", "\n", "        ", "params2reg", "=", "[", "]", "\n", "params0reg", "=", "[", "]", "\n", "for", "p_name", ",", "p_value", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "'.bias'", "in", "p_name", ":", "\n", "                ", "params0reg", "+=", "[", "p_value", "]", "\n", "", "else", ":", "\n", "                ", "params2reg", "+=", "[", "p_value", "]", "\n", "", "", "assert", "len", "(", "params0reg", ")", "+", "len", "(", "params2reg", ")", "==", "len", "(", "list", "(", "self", ".", "model", ".", "parameters", "(", ")", ")", ")", "\n", "groups", "=", "[", "dict", "(", "params", "=", "params2reg", ")", ",", "dict", "(", "params", "=", "params0reg", ",", "weight_decay", "=", ".0", ")", "]", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "groups", ",", "lr", "=", "self", ".", "params", "[", "'lr'", "]", ",", "weight_decay", "=", "self", ".", "params", "[", "'reg'", "]", ",", "amsgrad", "=", "True", ")", "\n", "\n", "# Train Model", "\n", "print", "(", ")", "\n", "for", "p_name", ",", "p_value", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "p_value", ".", "requires_grad", ":", "\n", "                ", "print", "(", "p_name", ")", "\n", "", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.iterator": [[97, 107], ["random.shuffle", "range", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "iterator", "(", "x", ",", "shuffle_", "=", "False", ",", "batch_size", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Create a new iterator for this epoch.\n        Shuffle the data if specified.\n        \"\"\"", "\n", "if", "shuffle_", ":", "\n", "            ", "random", ".", "shuffle", "(", "x", ")", "\n", "", "new", "=", "[", "x", "[", "i", ":", "i", "+", "batch_size", "]", "for", "i", "in", "range", "(", "0", ",", "len", "(", "x", ")", ",", "batch_size", ")", "]", "\n", "return", "new", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.early_stopping": [[108, 135], ["save_model"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.save_model"], ["", "def", "early_stopping", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"\n        Perform early stopping.\n        If performance does not improve for a number of consecutive epochs ( == \"patience\")\n        then stop the training and keep the best epoch: stopped_epoch - patience\n\n        Args:\n            epoch (int): current training epoch\n\n        Returns: (int) best_epoch, (bool) stop\n        \"\"\"", "\n", "if", "self", ".", "test_res", "[", "'score'", "]", "[", "-", "1", "]", ">", "self", ".", "best_score", ":", "# improvement of primary metric", "\n", "            ", "self", ".", "best_score", "=", "self", ".", "test_res", "[", "'score'", "]", "[", "-", "1", "]", "\n", "self", ".", "best_epoch", "=", "epoch", "\n", "self", ".", "cur_patience", "=", "0", "\n", "save_model", "(", "self", ".", "model_folder", ",", "self", ".", "model", ",", "self", ".", "loader", ")", "\n", "\n", "#if self.test_res['loss'][-1] < self.best_loss:", "\n", "#    self.best_loss = self.test_res['loss'][-1]", "\n", "", "else", ":", "\n", "            ", "self", ".", "cur_patience", "+=", "1", "\n", "\n", "", "if", "self", ".", "patience", "==", "self", ".", "cur_patience", ":", "# early stop must take place", "\n", "            ", "self", ".", "best_epoch", "=", "epoch", "-", "self", ".", "patience", "\n", "return", "True", "\n", "", "else", ":", "\n", "            ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.parameter_averaging": [[136, 163], ["trainer.Trainer.model.named_parameters", "copy.deepcopy", "torch.from_numpy().to", "torch.from_numpy", "numpy.mean", "trainer.Trainer.averaged_params[].append", "numpy.mean", "p_value.data.to().numpy", "torch.from_numpy", "p_value.data.to"], "methods", ["None"], ["", "", "def", "parameter_averaging", "(", "self", ",", "epoch", "=", "None", ",", "reset", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Perform parameter averaging.\n        For each epoch, average the parameters up to this epoch and then evaluate on test set.\n        Args:\n            'reset' option: use the last epoch parameters for the next epoch\n            'epoch' given: estimate the average until this epoch\n        \"\"\"", "\n", "for", "p_name", ",", "p_value", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "p_name", "not", "in", "self", ".", "averaged_params", ":", "\n", "                ", "self", ".", "averaged_params", "[", "p_name", "]", "=", "[", "]", "\n", "\n", "", "if", "reset", ":", "\n", "                ", "p_new", "=", "copy", ".", "deepcopy", "(", "self", ".", "averaged_params", "[", "p_name", "]", "[", "-", "1", "]", ")", "# use last epoch param", "\n", "\n", "", "elif", "epoch", ":", "\n", "                ", "p_new", "=", "np", ".", "mean", "(", "self", ".", "averaged_params", "[", "p_name", "]", "[", ":", "epoch", "]", ",", "axis", "=", "0", ")", "# estimate average until this epoch", "\n", "\n", "", "else", ":", "\n", "                ", "self", ".", "averaged_params", "[", "p_name", "]", ".", "append", "(", "p_value", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", ")", "\n", "p_new", "=", "np", ".", "mean", "(", "self", ".", "averaged_params", "[", "p_name", "]", ",", "axis", "=", "0", ")", "# estimate average", "\n", "\n", "# assign to array", "\n", "", "if", "self", ".", "device", "!=", "'cpu'", ":", "\n", "                ", "p_value", ".", "data", "=", "torch", ".", "from_numpy", "(", "p_new", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "", "else", ":", "\n", "                ", "p_value", ".", "data", "=", "torch", ".", "from_numpy", "(", "p_new", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.run": [[164, 195], ["print", "random.shuffle", "range", "print", "trainer.Trainer.eval_epoch", "print", "trainer.Trainer.train_epoch", "trainer.Trainer.eval_epoch", "trainer.Trainer.early_stopping", "trainer.Trainer.parameter_averaging", "datetime.datetime.now().strftime", "trainer.Trainer.parameter_averaging", "trainer.Trainer.parameter_averaging", "datetime.datetime.now().strftime", "datetime.datetime.now", "datetime.datetime.now"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.eval_epoch", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.train_epoch", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.eval_epoch", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.early_stopping", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.parameter_averaging", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.parameter_averaging", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.parameter_averaging"], ["", "", "", "def", "run", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Run main training process.\n        \"\"\"", "\n", "print", "(", "'\\n======== START TRAINING: {} ========\\n'", ".", "format", "(", "\n", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%d-%m-%y_%H:%M:%S\"", ")", ")", ")", "\n", "\n", "random", ".", "shuffle", "(", "self", ".", "data", "[", "'train'", "]", ")", "# shuffle training data at least once", "\n", "\n", "for", "epoch", "in", "range", "(", "1", ",", "self", ".", "epoch", "+", "1", ")", ":", "\n", "            ", "self", ".", "train_epoch", "(", "epoch", ")", "\n", "\n", "if", "self", ".", "pa", ":", "\n", "                ", "self", ".", "parameter_averaging", "(", ")", "# use parameter averaging on the eval set", "\n", "\n", "", "self", ".", "eval_epoch", "(", ")", "\n", "\n", "stop", "=", "self", ".", "early_stopping", "(", "epoch", ")", "# early stopping criterion", "\n", "if", "self", ".", "es", "and", "stop", ":", "\n", "                ", "break", "\n", "\n", "", "if", "self", ".", "pa", ":", "\n", "                ", "self", ".", "parameter_averaging", "(", "reset", "=", "True", ")", "\n", "\n", "", "", "print", "(", "'Best epoch: {}'", ".", "format", "(", "self", ".", "best_epoch", ")", ")", "\n", "if", "self", ".", "pa", ":", "\n", "            ", "self", ".", "parameter_averaging", "(", "epoch", "=", "self", ".", "best_epoch", ")", "\n", "", "self", ".", "eval_epoch", "(", "final", "=", "True", ",", "save_predictions", "=", "True", ")", "\n", "\n", "print", "(", "'\\n======== END TRAINING: {} ========\\n'", ".", "format", "(", "\n", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%d-%m-%y_%H:%M:%S\"", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.train_epoch": [[196, 235], ["time.time", "trainer.Trainer.model.train", "trainer.Trainer.iterator", "time.time", "trainer.Trainer.performance", "print", "print_results", "trainer.Trainer.convert_batch", "loss.backward", "torch.nn.utils.clip_grad_norm_", "trainer.Trainer.optimizer.step", "torch.autograd.detect_anomaly", "trainer.Trainer.optimizer.zero_grad", "trainer.Trainer.model", "preds.to().data.tolist", "probs.to().data.tolist", "truth.to().data.tolist", "trainer.Trainer.model.parameters", "loss.item", "stats[].to().data.numpy", "stats[].to().data.numpy", "stats[].to().data.numpy", "stats[].to().data.numpy", "preds.to", "probs.to", "truth.to", "stats[].to", "stats[].to", "stats[].to", "stats[].to"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.walk_re.train", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.iterator", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.performance", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.print_results", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.convert_batch"], ["", "def", "train_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"\n        Train model on the training set for 1 epoch, estimate performance and average loss.\n        \"\"\"", "\n", "t1", "=", "time", ".", "time", "(", ")", "\n", "output_tr", "=", "{", "'tp'", ":", "[", "]", ",", "'fp'", ":", "[", "]", ",", "'fn'", ":", "[", "]", ",", "'tn'", ":", "[", "]", ",", "'loss'", ":", "[", "]", ",", "'preds'", ":", "[", "]", ",", "'truth'", ":", "[", "]", ",", "'probs'", ":", "[", "]", "}", "\n", "\n", "self", ".", "model", "=", "self", ".", "model", ".", "train", "(", ")", "\n", "train_iter", "=", "self", ".", "iterator", "(", "self", ".", "data", "[", "'train'", "]", ",", "batch_size", "=", "self", ".", "params", "[", "'batch'", "]", ",", "shuffle_", "=", "True", ")", "\n", "\n", "for", "batch", "in", "train_iter", ":", "\n", "            ", "batch", "=", "self", ".", "convert_batch", "(", "batch", ")", "\n", "\n", "with", "autograd", ".", "detect_anomaly", "(", ")", ":", "\n", "                ", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "loss", ",", "stats", ",", "probs", ",", "preds", ",", "truth", ",", "att_scores", "=", "self", ".", "model", "(", "batch", ")", "\n", "output_tr", "[", "'preds'", "]", "+=", "preds", ".", "to", "(", "'cpu'", ")", ".", "data", ".", "tolist", "(", ")", "\n", "output_tr", "[", "'probs'", "]", "+=", "probs", ".", "to", "(", "'cpu'", ")", ".", "data", ".", "tolist", "(", ")", "\n", "output_tr", "[", "'truth'", "]", "+=", "truth", ".", "to", "(", "'cpu'", ")", ".", "data", ".", "tolist", "(", ")", "\n", "output_tr", "[", "'loss'", "]", "+=", "[", "loss", ".", "item", "(", ")", "]", "\n", "output_tr", "[", "'tp'", "]", "+=", "[", "stats", "[", "'tp'", "]", ".", "to", "(", "'cpu'", ")", ".", "data", ".", "numpy", "(", ")", "]", "\n", "output_tr", "[", "'fp'", "]", "+=", "[", "stats", "[", "'fp'", "]", ".", "to", "(", "'cpu'", ")", ".", "data", ".", "numpy", "(", ")", "]", "\n", "output_tr", "[", "'fn'", "]", "+=", "[", "stats", "[", "'fn'", "]", ".", "to", "(", "'cpu'", ")", ".", "data", ".", "numpy", "(", ")", "]", "\n", "output_tr", "[", "'tn'", "]", "+=", "[", "stats", "[", "'tn'", "]", ".", "to", "(", "'cpu'", ")", ".", "data", ".", "numpy", "(", ")", "]", "\n", "\n", "", "loss", ".", "backward", "(", ")", "# backward computation", "\n", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "params", "[", "'gc'", "]", ")", "# gradient clipping", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "# update", "\n", "\n", "", "t2", "=", "time", ".", "time", "(", ")", "\n", "\n", "# estimate performance", "\n", "total_loss", ",", "scores", "=", "self", ".", "performance", "(", "output_tr", ")", "\n", "self", ".", "train_res", "[", "'loss'", "]", "+=", "[", "total_loss", "]", "\n", "self", ".", "train_res", "[", "'score'", "]", "+=", "[", "scores", "[", "self", ".", "primary_metric", "]", "]", "\n", "\n", "print", "(", "'Epoch: {:02d} | TRAIN | LOSS = {:.04f}'", ".", "format", "(", "epoch", ",", "total_loss", ")", ",", "end", "=", "\"\"", ")", "\n", "print_results", "(", "scores", ",", "self", ".", "show_class", ",", "t2", "-", "t1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.eval_epoch": [[236, 286], ["time.time", "trainer.Trainer.model.eval", "trainer.Trainer.iterator", "time.time", "trainer.Trainer.performance", "print", "print_results", "print", "trainer.Trainer.convert_batch", "write_pred2file", "write_errors2file", "write_bingo2file", "numpy.where", "pids.extend", "torch.no_grad", "trainer.Trainer.model", "preds.to().data.tolist", "probs.to().data.tolist", "truth.to().data.tolist", "loss.item", "stats[].to().data.numpy", "stats[].to().data.numpy", "stats[].to().data.numpy", "stats[].to().data.numpy", "preds.to", "probs.to", "truth.to", "stats[].to", "stats[].to", "stats[].to", "stats[].to"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.iterator", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.performance", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.print_results", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.convert_batch", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.write_pred2file", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.write_errors2file", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.write_bingo2file"], ["", "def", "eval_epoch", "(", "self", ",", "final", "=", "False", ",", "save_predictions", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Evaluate model on the test set for one epoch, estimate performance and average loss.\n        Args:\n            final: Final model evaluation\n            save_predictions: save (or not) ... predictions :)\n        \"\"\"", "\n", "t1", "=", "time", ".", "time", "(", ")", "\n", "output_ts", "=", "{", "'tp'", ":", "[", "]", ",", "'fp'", ":", "[", "]", ",", "'fn'", ":", "[", "]", ",", "'tn'", ":", "[", "]", ",", "'loss'", ":", "[", "]", ",", "'preds'", ":", "[", "]", ",", "'truth'", ":", "[", "]", ",", "'probs'", ":", "[", "]", "}", "\n", "\n", "save_attention", "=", "[", "]", "\n", "pids", "=", "[", "]", "\n", "self", ".", "model", "=", "self", ".", "model", ".", "eval", "(", ")", "\n", "test_iter", "=", "self", ".", "iterator", "(", "self", ".", "data", "[", "'test'", "]", ",", "batch_size", "=", "self", ".", "params", "[", "'batch'", "]", ",", "shuffle_", "=", "False", ")", "\n", "\n", "for", "batch_", "in", "test_iter", ":", "\n", "\n", "            ", "for", "b", "in", "batch_", ":", "\n", "                ", "to_keep", "=", "np", ".", "where", "(", "b", "[", "'l2r'", "]", "!=", "-", "1", ")", "\n", "pids", ".", "extend", "(", "b", "[", "'info'", "]", "[", "to_keep", "]", ")", "\n", "\n", "", "batch_", "=", "self", ".", "convert_batch", "(", "batch_", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "loss", ",", "stats", ",", "probs", ",", "preds", ",", "truth", ",", "att_scores", "=", "self", ".", "model", "(", "batch_", ")", "\n", "\n", "output_ts", "[", "'preds'", "]", "+=", "preds", ".", "to", "(", "'cpu'", ")", ".", "data", ".", "tolist", "(", ")", "\n", "output_ts", "[", "'probs'", "]", "+=", "probs", ".", "to", "(", "'cpu'", ")", ".", "data", ".", "tolist", "(", ")", "\n", "output_ts", "[", "'truth'", "]", "+=", "truth", ".", "to", "(", "'cpu'", ")", ".", "data", ".", "tolist", "(", ")", "\n", "output_ts", "[", "'loss'", "]", "+=", "[", "loss", ".", "item", "(", ")", "]", "\n", "output_ts", "[", "'tp'", "]", "+=", "[", "stats", "[", "'tp'", "]", ".", "to", "(", "'cpu'", ")", ".", "data", ".", "numpy", "(", ")", "]", "\n", "output_ts", "[", "'fp'", "]", "+=", "[", "stats", "[", "'fp'", "]", ".", "to", "(", "'cpu'", ")", ".", "data", ".", "numpy", "(", ")", "]", "\n", "output_ts", "[", "'fn'", "]", "+=", "[", "stats", "[", "'fn'", "]", ".", "to", "(", "'cpu'", ")", ".", "data", ".", "numpy", "(", ")", "]", "\n", "output_ts", "[", "'tn'", "]", "+=", "[", "stats", "[", "'tn'", "]", ".", "to", "(", "'cpu'", ")", ".", "data", ".", "numpy", "(", ")", "]", "\n", "\n", "", "", "t2", "=", "time", ".", "time", "(", ")", "\n", "\n", "# estimate performance", "\n", "total_loss", ",", "scores", "=", "self", ".", "performance", "(", "output_ts", ")", "\n", "\n", "if", "not", "final", ":", "\n", "            ", "self", ".", "test_res", "[", "'loss'", "]", "+=", "[", "total_loss", "]", "\n", "self", ".", "test_res", "[", "'score'", "]", "+=", "[", "scores", "[", "self", ".", "primary_metric", "]", "]", "\n", "", "print", "(", "'            TEST  | LOSS = {:.04f}'", ".", "format", "(", "total_loss", ")", ",", "end", "=", "\"\"", ")", "\n", "print_results", "(", "scores", ",", "self", ".", "show_class", ",", "t2", "-", "t1", ")", "\n", "print", "(", ")", "\n", "\n", "if", "save_predictions", ":", "\n", "            ", "write_pred2file", "(", "output_ts", "[", "'preds'", "]", ",", "output_ts", "[", "'probs'", "]", ",", "pids", ",", "self", ".", "saveto", ",", "self", ".", "loader", ".", "index2rel", ")", "\n", "write_errors2file", "(", "output_ts", "[", "'preds'", "]", ",", "pids", ",", "self", ".", "saveto", ",", "self", ".", "loader", ".", "index2rel", ")", "\n", "write_bingo2file", "(", "output_ts", "[", "'preds'", "]", ",", "pids", ",", "self", ".", "saveto", ",", "self", ".", "loader", ".", "index2rel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.performance": [[287, 382], ["trainer.Trainer.performance.prf1"], "methods", ["None"], ["", "", "def", "performance", "(", "self", ",", "stats", ")", ":", "\n", "        ", "\"\"\"\n        Estimate performance: micro and macro average precision, recall, F1 score.\n        CPU based\n        \"\"\"", "\n", "def", "lab_map", "(", "a", ")", ":", "\n", "            ", "tmp", "=", "self", ".", "loader", ".", "index2rel", "[", "a", "]", "\n", "tmp", "=", "tmp", ".", "split", "(", "':'", ")", "\n", "if", "tmp", "[", "1", "]", "==", "'NR'", ":", "\n", "                ", "return", "self", ".", "loader", ".", "rel2index", "[", "'1:NR:2'", "]", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "loader", ".", "rel2index", "[", "tmp", "[", "2", "]", "+", "':'", "+", "tmp", "[", "1", "]", "+", "':'", "+", "tmp", "[", "0", "]", "]", "\n", "\n", "", "", "def", "fbeta_score", "(", "precision", ",", "recall", ",", "beta", "=", "1.0", ")", ":", "\n", "            ", "beta_square", "=", "beta", "*", "beta", "\n", "if", "(", "precision", "!=", "0.0", ")", "and", "(", "recall", "!=", "0.0", ")", ":", "\n", "                ", "res", "=", "(", "(", "1", "+", "beta_square", ")", "*", "precision", "*", "recall", "/", "(", "beta_square", "*", "precision", "+", "recall", ")", ")", "\n", "", "else", ":", "\n", "                ", "res", "=", "0.0", "\n", "", "return", "res", "\n", "\n", "", "def", "micro_scores", "(", "all_tp", ",", "all_fp", ",", "all_fn", ",", "all_tn", ")", ":", "\n", "            ", "atp", "=", "np", ".", "sum", "(", "all_tp", ")", "\n", "afp", "=", "np", ".", "sum", "(", "all_fp", ")", "\n", "afn", "=", "np", ".", "sum", "(", "all_fn", ")", "\n", "atn", "=", "np", ".", "sum", "(", "all_tn", ")", "\n", "micro_p", "=", "(", "1.0", "*", "atp", ")", "/", "(", "atp", "+", "afp", ")", "if", "(", "atp", "+", "afp", "!=", "0", ")", "else", "0.0", "\n", "micro_r", "=", "(", "1.0", "*", "atp", ")", "/", "(", "atp", "+", "afn", ")", "if", "(", "atp", "+", "afn", "!=", "0", ")", "else", "0.0", "\n", "micro_f", "=", "fbeta_score", "(", "micro_p", ",", "micro_r", ")", "\n", "return", "micro_p", ",", "micro_r", ",", "micro_f", ",", "atp", ",", "afp", ",", "afn", ",", "atn", "\n", "\n", "", "def", "macro_scores", "(", "all_tp", ",", "all_fp", ",", "all_fn", ")", ":", "\n", "            ", "ctp", "=", "[", "]", "\n", "cfp", "=", "[", "]", "\n", "cfn", "=", "[", "]", "\n", "\n", "if", "':'", "in", "list", "(", "self", ".", "loader", ".", "rel2index", ".", "keys", "(", ")", ")", "[", "-", "1", "]", ":", "\n", "                ", "seen", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "self", ".", "loader", ".", "n_rel", ")", ":", "\n", "                    ", "if", "i", "==", "self", ".", "loader", ".", "label2ignore", ":", "\n", "                        ", "continue", "\n", "", "elif", "(", "i", "in", "seen", ")", "or", "(", "lab_map", "(", "i", ")", "in", "seen", ")", ":", "\n", "                        ", "continue", "\n", "", "else", ":", "\n", "                        ", "ctp", ".", "append", "(", "all_tp", "[", "i", "]", "+", "all_tp", "[", "lab_map", "(", "i", ")", "]", ")", "\n", "cfp", ".", "append", "(", "all_fp", "[", "i", "]", "+", "all_fp", "[", "lab_map", "(", "i", ")", "]", ")", "\n", "cfn", ".", "append", "(", "all_fn", "[", "i", "]", "+", "all_fn", "[", "lab_map", "(", "i", ")", "]", ")", "\n", "seen", ".", "append", "(", "i", ")", "\n", "seen", ".", "append", "(", "lab_map", "(", "i", ")", ")", "\n", "", "", "", "else", ":", "\n", "                ", "for", "i", "in", "range", "(", "0", ",", "self", ".", "loader", ".", "n_rel", ")", ":", "\n", "                    ", "if", "i", "==", "self", ".", "loader", ".", "label2ignore", ":", "\n", "                        ", "continue", "\n", "", "else", ":", "\n", "                        ", "ctp", ".", "append", "(", "all_tp", "[", "i", "]", ")", "\n", "cfp", ".", "append", "(", "all_fp", "[", "i", "]", ")", "\n", "cfn", ".", "append", "(", "all_fn", "[", "i", "]", ")", "\n", "\n", "", "", "", "pp", "=", "[", "]", "\n", "rr", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "0", ",", "len", "(", "ctp", ")", ")", ":", "\n", "                ", "pp", ".", "append", "(", "(", "1.0", "*", "ctp", "[", "j", "]", ")", "/", "(", "ctp", "[", "j", "]", "+", "cfp", "[", "j", "]", ")", "if", "(", "ctp", "[", "j", "]", "+", "cfp", "[", "j", "]", ")", "!=", "0", "else", "0.0", ")", "\n", "rr", ".", "append", "(", "(", "1.0", "*", "ctp", "[", "j", "]", ")", "/", "(", "ctp", "[", "j", "]", "+", "cfn", "[", "j", "]", ")", "if", "(", "ctp", "[", "j", "]", "+", "cfn", "[", "j", "]", ")", "!=", "0", "else", "0.0", ")", "\n", "", "assert", "len", "(", "pp", ")", "==", "len", "(", "rr", ")", "\n", "\n", "macro_p", "=", "np", ".", "mean", "(", "pp", ")", "\n", "macro_r", "=", "np", ".", "mean", "(", "rr", ")", "\n", "macro_f", "=", "fbeta_score", "(", "macro_p", ",", "macro_r", ")", "\n", "return", "macro_p", ",", "macro_r", ",", "macro_f", "\n", "\n", "", "def", "accuracy", "(", "atp", ",", "afp", ",", "afn", ",", "atn", ")", ":", "\n", "            ", "return", "(", "atp", "+", "atn", ")", "/", "(", "atp", "+", "atn", "+", "afp", "+", "afn", ")", "if", "(", "atp", "+", "atn", "+", "afp", "+", "afn", ")", "else", "0.0", "\n", "\n", "", "def", "prf1", "(", "all_tp", ",", "all_fp", ",", "all_fn", ",", "all_tn", ")", ":", "\n", "            ", "assert", "len", "(", "all_tp", ")", "==", "len", "(", "all_fp", ")", "==", "len", "(", "all_fn", ")", "==", "len", "(", "all_tn", ")", "\n", "\n", "all_tp", "=", "np", ".", "sum", "(", "all_tp", ",", "axis", "=", "0", ")", "# sum per class for all batches", "\n", "all_fp", "=", "np", ".", "sum", "(", "all_fp", ",", "axis", "=", "0", ")", "\n", "all_fn", "=", "np", ".", "sum", "(", "all_fn", ",", "axis", "=", "0", ")", "\n", "all_tn", "=", "np", ".", "sum", "(", "all_tn", ",", "axis", "=", "0", ")", "\n", "\n", "micro_p", ",", "micro_r", ",", "micro_f", ",", "atp", ",", "afp", ",", "afn", ",", "atn", "=", "micro_scores", "(", "all_tp", ",", "all_fp", ",", "all_fn", ",", "all_tn", ")", "\n", "macro_p", ",", "macro_r", ",", "macro_f", "=", "macro_scores", "(", "all_tp", ",", "all_fp", ",", "all_fn", ")", "\n", "acc", "=", "accuracy", "(", "atp", ",", "afp", ",", "afn", ",", "atn", ")", "\n", "\n", "return", "{", "'acc'", ":", "acc", ",", "\n", "'micro_p'", ":", "micro_p", ",", "'micro_r'", ":", "micro_r", ",", "'micro_f'", ":", "micro_f", ",", "\n", "'macro_p'", ":", "macro_p", ",", "'macro_r'", ":", "macro_r", ",", "'macro_f'", ":", "macro_f", ",", "\n", "'tp'", ":", "atp", ",", "'actual'", ":", "atp", "+", "afn", ",", "'pred'", ":", "atp", "+", "afp", ",", "'total'", ":", "len", "(", "stats", "[", "'preds'", "]", ")", ",", "\n", "'per_class'", ":", "[", "]", "}", "\n", "\n", "", "fin_loss", "=", "sum", "(", "stats", "[", "'loss'", "]", ")", "/", "len", "(", "stats", "[", "'loss'", "]", ")", "\n", "scores", "=", "prf1", "(", "stats", "[", "'tp'", "]", ",", "stats", "[", "'fp'", "]", ",", "stats", "[", "'fn'", "]", ",", "stats", "[", "'tn'", "]", ")", "\n", "return", "fin_loss", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.convert_batch": [[383, 407], ["converter.concat_examples", "enumerate", "sys.exit", "print", "print", "print", "print", "print", "print", "print", "b_.items", "numpy.array().reshape", "numpy.array().reshape", "numpy.array", "numpy.array", "b[].ravel", "b[].ravel"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.converter.concat_examples"], ["", "def", "convert_batch", "(", "self", ",", "batch", ")", ":", "\n", "# TODO faster", "\n", "        ", "batch", "=", "[", "{", "key", ":", "value", "for", "key", ",", "value", "in", "b_", ".", "items", "(", ")", "if", "key", "!=", "'info'", "and", "key", "!=", "'sentId'", "}", "for", "b_", "in", "batch", "]", "\n", "\n", "converted_batch", "=", "concat_examples", "(", "batch", ",", "device", "=", "self", ".", "device", ",", "padding", "=", "-", "1", ")", "\n", "\n", "if", "self", ".", "params", "[", "'example'", "]", ":", "\n", "            ", "for", "i", ",", "b", "in", "enumerate", "(", "batch", ")", ":", "\n", "                ", "print", "(", "'===== DOCUMENT NO {} ====='", ".", "format", "(", "i", ")", ")", "\n", "print", "(", "' '", ".", "join", "(", "[", "self", ".", "loader", ".", "index2word", "[", "t", "]", "for", "t", "in", "b", "[", "'text'", "]", "]", ")", ")", "\n", "print", "(", "b", "[", "'ents'", "]", ")", "\n", "print", "(", "b", "[", "'rels'", "]", ")", "\n", "print", "(", "np", ".", "array", "(", "[", "self", ".", "loader", ".", "index2pos", "[", "t", "]", "for", "t", "in", "\n", "b", "[", "'pos_ee'", "]", ".", "ravel", "(", ")", "]", ")", ".", "reshape", "(", "-", "1", ",", "b", "[", "'pos_ee'", "]", ".", "shape", "[", "0", "]", ",", "b", "[", "'pos_ee'", "]", ".", "shape", "[", "1", "]", ")", ")", "\n", "print", "(", "np", ".", "array", "(", "[", "self", ".", "loader", ".", "index2pos", "[", "t", "]", "for", "t", "in", "\n", "b", "[", "'pos_et'", "]", ".", "ravel", "(", ")", "]", ")", ".", "reshape", "(", "-", "1", ",", "b", "[", "'pos_et'", "]", ".", "shape", "[", "0", "]", ",", "b", "[", "'pos_et'", "]", ".", "shape", "[", "1", "]", ")", ")", "\n", "print", "(", ")", "\n", "", "sys", ".", "exit", "(", ")", "\n", "\n", "", "converted_batch", "[", "'text'", "]", "=", "converted_batch", "[", "'text'", "]", "[", "converted_batch", "[", "'text'", "]", "!=", "-", "1", "]", "\n", "converted_batch", "[", "'ents'", "]", "[", ":", ",", ":", ",", "1", "]", "[", "converted_batch", "[", "'ents'", "]", "[", ":", ",", ":", ",", "1", "]", "==", "-", "1", "]", "=", "self", ".", "loader", ".", "n_type", "# mask padded", "\n", "converted_batch", "[", "'pos_ee'", "]", "[", "converted_batch", "[", "'pos_ee'", "]", "==", "-", "1", "]", "=", "self", ".", "loader", ".", "n_pos", "\n", "converted_batch", "[", "'pos_et'", "]", "[", "converted_batch", "[", "'pos_et'", "]", "==", "-", "1", "]", "=", "self", ".", "loader", ".", "n_pos", "\n", "return", "converted_batch", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.embedding_layer": [[23, 45], ["network.WalkBasedModel.word_embed", "network.WalkBasedModel.pos_embed", "network.WalkBasedModel.pos_embed", "network.WalkBasedModel.type_embed", "network.WalkBasedModel.type_embed", "torch.tensor().to().unsqueeze", "torch.tensor().to().unsqueeze", "torch.tensor().to().unsqueeze", "torch.tensor().to().unsqueeze", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["def", "embedding_layer", "(", "self", ",", "words_", ",", "ents_type_", ",", "ents_pos_", ",", "toks_pos_", ")", ":", "\n", "        ", "\"\"\"\n        Embedding layer:\n            B: batch size\n            E: entities\n            D: dimensionality\n            W: words\n        Associate, words, entity types, positions with vectors.\n        Apply dropout to word embeddings\n        \"\"\"", "\n", "# words", "\n", "w_embed", "=", "self", ".", "word_embed", "(", "words_", ")", "# (B, W, D)", "\n", "\n", "# positions", "\n", "pe_embed", "=", "self", ".", "pos_embed", "(", "ents_pos_", ")", "# (B, E, E, D)", "\n", "pt_embed", "=", "self", ".", "pos_embed", "(", "toks_pos_", ")", "# (B, E, W, D)", "\n", "\n", "# entity types", "\n", "te_embed", "=", "self", ".", "type_embed", "(", "ents_type_", ")", "# (B, E, D)", "\n", "tt_embed", "=", "self", ".", "type_embed", "(", "torch", ".", "tensor", "(", "[", "self", ".", "o_type", "]", ")", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "return", "w_embed", ",", "pe_embed", ",", "pt_embed", ",", "te_embed", ",", "tt_embed", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.encoder_layer": [[46, 56], ["network.WalkBasedModel.encoder", "torch.split", "torch.split", "torch.split", "torch.split", "word_sec.tolist"], "methods", ["None"], ["", "def", "encoder_layer", "(", "self", ",", "word_sec", ",", "w_embeds", ")", ":", "\n", "        ", "\"\"\"\n        BLSTM layer:\n            Transform batch of sentences to list\n            Pass from BiLSTM\n            Pad sequence - form batch again\n            Dropout after BLSTM\n        \"\"\"", "\n", "ys", "=", "self", ".", "encoder", "(", "torch", ".", "split", "(", "w_embeds", ",", "word_sec", ".", "tolist", "(", ")", ",", "dim", "=", "0", ")", ",", "word_sec", ")", "# (B, W, D)", "\n", "return", "ys", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.merge_tokens": [[57, 69], ["torch.broadcast_tensors", "torch.broadcast_tensors", "torch.broadcast_tensors", "torch.broadcast_tensors", "torch.div", "torch.div", "torch.div", "torch.div", "info[].unsqueeze", "info[].unsqueeze", "[].to", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.clamp().unsqueeze", "torch.clamp().unsqueeze", "torch.clamp().unsqueeze", "torch.clamp().unsqueeze", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.lt", "torch.lt", "torch.lt", "torch.lt"], "methods", ["None"], ["", "def", "merge_tokens", "(", "self", ",", "info", ",", "enc_seq", ")", ":", "\n", "        ", "\"\"\"\n        Merge tokens into entities; create binary matrix with indicators for merging\n        \"\"\"", "\n", "start", ",", "end", ",", "w_ids", "=", "torch", ".", "broadcast_tensors", "(", "info", "[", ":", ",", ":", ",", "2", "]", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", "info", "[", ":", ",", ":", ",", "3", "]", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", "torch", ".", "arange", "(", "enc_seq", ".", "shape", "[", "1", "]", ")", "[", "None", ",", "None", "]", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "\n", "index_t", "=", "(", "torch", ".", "ge", "(", "w_ids", ",", "start", ")", "&", "torch", ".", "lt", "(", "w_ids", ",", "end", ")", ")", ".", "type", "(", "'torch.FloatTensor'", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "entities", "=", "torch", ".", "div", "(", "torch", ".", "matmul", "(", "index_t", ",", "enc_seq", ")", ",", "\n", "torch", ".", "clamp", "(", "torch", ".", "sum", "(", "index_t", ",", "dim", "=", "2", ")", ",", "1.0", ",", "100.0", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "return", "entities", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.make_pair_indices": [[70, 97], ["torch.where", "torch.where", "torch.where", "torch.where", "torch.matmul().type().to", "torch.matmul().type().to", "torch.matmul().type().to", "torch.matmul().type().to", "torch.nonzero().unbind", "torch.nonzero().unbind", "torch.nonzero().unbind", "torch.nonzero().unbind", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.split", "torch.split", "torch.split", "torch.split", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.split", "torch.split", "torch.split", "torch.split", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.lt", "torch.lt", "torch.lt", "torch.lt", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.cat.tolist", "torch.cat.tolist", "e_section.tolist", "torch.arange().unsqueeze().to", "torch.arange().unsqueeze().to", "torch.arange().unsqueeze().to", "torch.arange().unsqueeze().to", "e_section.unsqueeze", "torch.matmul().type", "torch.matmul().type", "torch.matmul().type", "torch.matmul().type", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.as_tensor().to().repeat", "torch.as_tensor().to().repeat", "torch.as_tensor().to().repeat", "torch.as_tensor().to().repeat", "torch.max", "torch.max", "torch.max", "torch.max", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "torch.where.unsqueeze", "torch.where.unsqueeze", "torch.where.unsqueeze", "torch.where.unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor"], "methods", ["None"], ["", "def", "make_pair_indices", "(", "self", ",", "e_section", ")", ":", "\n", "        ", "\"\"\"\n        Construct matrix with a mapping from 3D points -> 1D point\n        (batch, row, col) --> pair No\n        e.g. [[  0,  1,  2, -1, -1 ],\n              [  3,  4,  5, -1, -1 ],\n              [  6,  7,  8, -1, -1 ],\n              [ -1, -1, -1, -1, -1 ],\n              [ -1, -1, -1, -1, -1 ]]\n        \"\"\"", "\n", "fshape", "=", "(", "e_section", ".", "shape", "[", "0", "]", ",", "torch", ".", "max", "(", "e_section", ")", ".", "item", "(", ")", ")", "\n", "\n", "args_mask", "=", "torch", ".", "where", "(", "torch", ".", "lt", "(", "torch", ".", "arange", "(", "fshape", "[", "1", "]", ")", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "self", ".", "device", ")", ",", "e_section", ".", "unsqueeze", "(", "1", ")", ")", ",", "\n", "torch", ".", "ones", "(", "fshape", ")", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "torch", ".", "zeros", "(", "fshape", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "\n", "cond", "=", "torch", ".", "matmul", "(", "args_mask", ".", "unsqueeze", "(", "-", "1", ")", ",", "args_mask", ".", "unsqueeze", "(", "1", ")", ")", ".", "type", "(", "'torch.ByteTensor'", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "bat", ",", "rows", ",", "cols", "=", "torch", ".", "nonzero", "(", "cond", ")", ".", "unbind", "(", "dim", "=", "1", ")", "\n", "\n", "# create a mapping array (to return the flat indice of a certain pair)", "\n", "temp", "=", "torch", ".", "cat", "(", "[", "torch", ".", "as_tensor", "(", "[", "i", "]", ")", ".", "to", "(", "self", ".", "device", ")", ".", "repeat", "(", "i", ")", "for", "i", "in", "e_section", "]", ",", "dim", "=", "0", ")", "\n", "# torch.repeat_interleave(e_section, e_section, dim=0).tolist()", "\n", "map_pair", "=", "torch", ".", "split", "(", "torch", ".", "arange", "(", "bat", ".", "shape", "[", "0", "]", ")", ".", "to", "(", "self", ".", "device", ")", ",", "temp", ".", "tolist", "(", ")", ")", "\n", "map_pair", "=", "pad_sequence", "(", "map_pair", ",", "batch_first", "=", "True", ",", "padding_value", "=", "-", "1", ")", "\n", "map_pair", "=", "torch", ".", "split", "(", "map_pair", ",", "e_section", ".", "tolist", "(", ")", ")", "\n", "map_pair", "=", "pad_sequence", "(", "map_pair", ",", "batch_first", "=", "True", ",", "padding_value", "=", "-", "1", ")", "\n", "return", "bat", ",", "rows", ",", "cols", ",", "cond", ",", "map_pair", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.construct_pair": [[98, 114], ["network.WalkBasedModel.merge_tokens", "network.WalkBasedModel.make_pair_indices", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.merge_tokens", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.make_pair_indices"], ["", "def", "construct_pair", "(", "self", ",", "info", ",", "e_section", ",", "enc_out", ",", "pe_embed", ",", "te_embed", ")", ":", "\n", "        ", "\"\"\"\n        Pair representation:\n            - Extract entities from BLSTM (average of vectors if > 1 words)\n            - pair: (blstm1 + etype1 + pos12, blstm2 + etype2 + pos21)\n        \"\"\"", "\n", "# average for words with more than 1 token", "\n", "args", "=", "self", ".", "merge_tokens", "(", "info", ",", "enc_out", ")", "# (B, E, dim)", "\n", "\n", "bat", ",", "rows", ",", "cols", ",", "condition", ",", "map_pair", "=", "self", ".", "make_pair_indices", "(", "e_section", ")", "\n", "\n", "pair_a", "=", "torch", ".", "cat", "(", "(", "args", "[", "bat", ",", "rows", "]", ",", "te_embed", "[", "bat", ",", "rows", "]", ",", "pe_embed", "[", "bat", ",", "rows", ",", "cols", "]", ")", ",", "dim", "=", "1", ")", "\n", "pair_b", "=", "torch", ".", "cat", "(", "(", "args", "[", "bat", ",", "cols", "]", ",", "te_embed", "[", "bat", ",", "cols", "]", ",", "pe_embed", "[", "bat", ",", "cols", ",", "rows", "]", ")", ",", "dim", "=", "1", ")", "\n", "\n", "pairs", "=", "torch", ".", "cat", "(", "(", "pair_a", ",", "pair_b", ")", ",", "dim", "=", "1", ")", "# (BEE, dim)", "\n", "return", "bat", ",", "rows", ",", "cols", ",", "args", ",", "pairs", ",", "condition", ",", "map_pair", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.find_word_context": [[115, 131], ["torch.broadcast_tensors", "torch.broadcast_tensors", "torch.broadcast_tensors", "torch.broadcast_tensors", "torch.lt", "torch.lt", "torch.lt", "torch.lt", "torch.all", "torch.all", "torch.all", "torch.all", "info[].unsqueeze", "info[].unsqueeze", "[].to", "word_section.unsqueeze().repeat().unsqueeze", "torch.lt", "torch.lt", "torch.lt", "torch.lt", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "word_section.unsqueeze().repeat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "word_section.unsqueeze", "torch.max", "torch.max", "torch.max", "torch.max"], "methods", ["None"], ["", "def", "find_word_context", "(", "self", ",", "info", ",", "word_section", ",", "bat", ",", "rows", ",", "cols", ")", ":", "\n", "        ", "\"\"\"\n        Create mask for context words of each pair\n        \"\"\"", "\n", "# context tokens (remaining words in the sentence)", "\n", "start", ",", "end", ",", "w_ids", ",", "w_sec", "=", "torch", ".", "broadcast_tensors", "(", "info", "[", ":", ",", ":", ",", "2", "]", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", "info", "[", ":", ",", ":", ",", "3", "]", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", "torch", ".", "arange", "(", "torch", ".", "max", "(", "word_section", ")", ".", "item", "(", ")", ")", "[", "None", ",", "None", "]", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "word_section", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "(", "1", ",", "info", ".", "shape", "[", "1", "]", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "\n", "toks", "=", "(", "torch", ".", "lt", "(", "w_ids", ",", "start", ")", "|", "torch", ".", "ge", "(", "w_ids", ",", "end", ")", ")", "# target ents", "\n", "w_pad", "=", "torch", ".", "lt", "(", "w_ids", ",", "w_sec", ")", "\n", "tmp_", "=", "torch", ".", "all", "(", "toks", ",", "dim", "=", "1", ")", "# all entities excluded", "\n", "cntx_toks", "=", "(", "tmp_", "[", ":", ",", "None", "]", "&", "w_pad", ")", "\n", "return", "cntx_toks", "[", "bat", ",", "rows", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.find_entity_context": [[132, 145], ["torch.broadcast_tensors", "torch.broadcast_tensors", "torch.broadcast_tensors", "torch.broadcast_tensors", "info[].unsqueeze", "[].to", "ent_section.unsqueeze().repeat().unsqueeze", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.lt", "torch.lt", "torch.lt", "torch.lt", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.lt", "torch.lt", "torch.lt", "torch.lt", "ent_section.unsqueeze().repeat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "ent_section.unsqueeze"], "methods", ["None"], ["", "def", "find_entity_context", "(", "self", ",", "info", ",", "ent_section", ",", "bat", ",", "rows", ",", "cols", ")", ":", "\n", "        ", "\"\"\"\n        Create mask for context entities of each pair\n        \"\"\"", "\n", "e_ids", ",", "o_ids", ",", "e_sec", "=", "torch", ".", "broadcast_tensors", "(", "info", "[", ":", ",", ":", ",", "0", "]", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", "torch", ".", "arange", "(", "info", ".", "shape", "[", "1", "]", ")", "[", "None", ",", "None", "]", ".", "to", "(", "self", ".", "device", ")", ",", "# total", "\n", "ent_section", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "(", "1", ",", "info", ".", "shape", "[", "1", "]", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "\n", "e1", "=", "torch", ".", "ne", "(", "e_ids", "[", "bat", ",", "rows", "]", ",", "o_ids", "[", "bat", ",", "rows", "]", ")", "&", "torch", ".", "lt", "(", "o_ids", "[", "bat", ",", "rows", "]", ",", "e_sec", "[", "bat", ",", "rows", "]", ")", "\n", "e2", "=", "torch", ".", "ne", "(", "e_ids", "[", "bat", ",", "cols", "]", ",", "o_ids", "[", "bat", ",", "cols", "]", ")", "&", "torch", ".", "lt", "(", "o_ids", "[", "bat", ",", "cols", "]", ",", "e_sec", "[", "bat", ",", "cols", "]", ")", "\n", "cntx_ents", "=", "(", "e1", "&", "e2", ")", "\n", "return", "cntx_ents", "# (BEE, E)", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.construct_context": [[146, 165], ["network.WalkBasedModel.find_word_context", "network.WalkBasedModel.find_entity_context", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.broadcast_tensors", "torch.broadcast_tensors", "torch.broadcast_tensors", "torch.broadcast_tensors", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "network.WalkBasedModel.unsqueeze", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "network.WalkBasedModel.unsqueeze", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.find_word_context", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.find_entity_context"], ["", "def", "construct_context", "(", "self", ",", "bat", ",", "rows", ",", "cols", ",", "info", ",", "ent_section", ",", "word_section", ",", "args", ",", "enc_out", ",", "\n", "pe_embed", ",", "pt_embed", ",", "te_embed", ",", "tt_embed", ",", "map_pair", ")", ":", "\n", "        ", "\"\"\"\n        Form context for each target pair: word + type_word + pos_word_E1 + pos_word_E2\n        'map_pair' is unnecessary, used for debugging\n        \"\"\"", "\n", "ct_mask", "=", "self", ".", "find_word_context", "(", "info", ",", "word_section", ",", "bat", ",", "rows", ",", "cols", ")", "\n", "ce_mask", "=", "self", ".", "find_entity_context", "(", "info", ",", "ent_section", ",", "bat", ",", "rows", ",", "cols", ")", "\n", "\n", "# matrix", "\n", "context_ents", "=", "torch", ".", "cat", "(", "(", "args", "[", "bat", "]", ",", "te_embed", "[", "bat", "]", ",", "pe_embed", "[", "bat", ",", "rows", "]", ",", "pe_embed", "[", "bat", ",", "cols", "]", ")", ",", "dim", "=", "2", ")", "\n", "tt_embed", ",", "_", "=", "torch", ".", "broadcast_tensors", "(", "tt_embed", ",", "torch", ".", "zeros", "(", "(", "bat", ".", "shape", "[", "0", "]", ",", "enc_out", ".", "shape", "[", "1", "]", ",", "1", ")", ")", ")", "\n", "context_toks", "=", "torch", ".", "cat", "(", "(", "enc_out", "[", "bat", "]", ",", "tt_embed", ",", "pt_embed", "[", "bat", ",", "rows", "]", ",", "pt_embed", "[", "bat", ",", "cols", "]", ")", ",", "dim", "=", "2", ")", "\n", "\n", "context_ents", "=", "torch", ".", "where", "(", "ce_mask", ".", "unsqueeze", "(", "2", ")", ",", "context_ents", ",", "torch", ".", "zeros_like", "(", "context_ents", ")", ")", "\n", "context_toks", "=", "torch", ".", "where", "(", "ct_mask", ".", "unsqueeze", "(", "2", ")", ",", "context_toks", ",", "torch", ".", "zeros_like", "(", "context_toks", ")", ")", "\n", "\n", "context4pairs", "=", "torch", ".", "cat", "(", "(", "context_ents", ",", "context_toks", ")", ",", "dim", "=", "1", ")", "# (BEE, E+W, dim)", "\n", "return", "context4pairs", ",", "torch", ".", "cat", "(", "(", "ce_mask", ",", "ct_mask", ")", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.classification": [[166, 206], ["torch.nonzero().unbind", "torch.nonzero().unbind", "torch.nonzero().unbind", "torch.nonzero().unbind", "network.WalkBasedModel.classifier", "torch.cross_entropy", "torch.cross_entropy", "torch.softmax().detach_().max", "torch.softmax().detach_().max", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "network.WalkBasedModel.classifier", "torch.cross_entropy", "torch.cross_entropy", "network.WalkBasedModel.reverse_labels", "torch.softmax().detach_().max", "torch.softmax().detach_().max", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.softmax().detach_", "torch.softmax().detach_", "network.WalkBasedModel.classifier", "network.WalkBasedModel.classifier", "network.WalkBasedModel.correct_predictions", "print", "sys.exit", "torch.softmax().detach_", "torch.softmax().detach_", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.softmax().detach_", "torch.softmax().detach_", "torch.softmax().detach_", "torch.softmax().detach_", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.reverse_labels", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.correct_predictions"], ["", "def", "classification", "(", "self", ",", "l2r_", ",", "gtruth_", ",", "pairs", ",", "map_pair", ")", ":", "\n", "        ", "\"\"\"\n        Softmax classifier\n        - separate classification of L2R and R2L pairs\n        \"\"\"", "\n", "# Separate pairs into: left-to-right and right-to-left, self relations (e.g. AA) not included", "\n", "l2r", "=", "torch", ".", "nonzero", "(", "torch", ".", "ne", "(", "l2r_", ",", "-", "1", ")", ")", ".", "unbind", "(", "dim", "=", "1", ")", "\n", "\n", "# separate gold labels", "\n", "l2r_truth", "=", "gtruth_", "[", "l2r", "[", "0", "]", ",", "l2r", "[", "1", "]", ",", "l2r", "[", "2", "]", "]", "\n", "r2l_truth", "=", "gtruth_", "[", "l2r", "[", "0", "]", ",", "l2r", "[", "2", "]", ",", "l2r", "[", "1", "]", "]", "\n", "\n", "# predictions", "\n", "l2r_pairs", "=", "pairs", "[", "map_pair", "[", "l2r", "[", "0", "]", ",", "l2r", "[", "1", "]", ",", "l2r", "[", "2", "]", "]", "]", "\n", "r2l_pairs", "=", "pairs", "[", "map_pair", "[", "l2r", "[", "0", "]", ",", "l2r", "[", "2", "]", ",", "l2r", "[", "1", "]", "]", "]", "\n", "\n", "if", "self", ".", "direction", "==", "'l2r'", ":", "\n", "            ", "l2r_pairs", "=", "self", ".", "classifier", "(", "l2r_pairs", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "l2r_pairs", ",", "l2r_truth", ")", "\n", "probs", ",", "preds", "=", "F", ".", "softmax", "(", "l2r_pairs", ",", "dim", "=", "1", ")", ".", "detach_", "(", ")", ".", "max", "(", "dim", "=", "1", ")", "\n", "\n", "", "elif", "self", ".", "direction", "==", "'r2l'", ":", "\n", "            ", "r2l_pairs", "=", "self", ".", "classifier", "(", "r2l_pairs", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "r2l_pairs", ",", "r2l_truth", ")", "\n", "reverse", "=", "self", ".", "reverse_labels", "(", ")", "\n", "probs", ",", "b", "=", "F", ".", "softmax", "(", "r2l_pairs", ",", "dim", "=", "1", ")", ".", "detach_", "(", ")", ".", "max", "(", "dim", "=", "1", ")", "\n", "preds", "=", "reverse", "[", "b", "]", "\n", "\n", "", "elif", "self", ".", "direction", "==", "'l2r+r2l'", ":", "\n", "            ", "l2r_pairs", "=", "self", ".", "classifier", "(", "l2r_pairs", ")", "\n", "r2l_pairs", "=", "self", ".", "classifier", "(", "r2l_pairs", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "l2r_pairs", ",", "l2r_truth", ")", "+", "F", ".", "cross_entropy", "(", "r2l_pairs", ",", "r2l_truth", ")", "\n", "probs", ",", "preds", "=", "self", ".", "correct_predictions", "(", "F", ".", "softmax", "(", "l2r_pairs", ",", "dim", "=", "1", ")", ".", "detach_", "(", ")", ",", "\n", "F", ".", "softmax", "(", "r2l_pairs", ",", "dim", "=", "1", ")", ".", "detach_", "(", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "print", "(", "'Wrong directionality selection!'", ")", "\n", "sys", ".", "exit", "(", "0", ")", "\n", "\n", "", "return", "loss", ",", "probs", ",", "preds", ",", "l2r_truth", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.forward": [[207, 256], ["network.WalkBasedModel.embedding_layer", "network.WalkBasedModel.encoder_layer", "network.WalkBasedModel.construct_pair", "network.WalkBasedModel.reduce", "network.WalkBasedModel.classification", "network.WalkBasedModel.measure_statistics", "network.WalkBasedModel.construct_context", "network.WalkBasedModel.attention", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "network.WalkBasedModel.walk_layer", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.embedding_layer", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.encoder_layer", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.construct_pair", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.classification", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.measure_statistics", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.construct_context"], ["", "def", "forward", "(", "self", ",", "binp", ")", ":", "\n", "        ", "\"\"\"\n        Forward computation\n        1. embedding layer\n        2. encoder (BLSTM) layer\n        3. Pair representation layer\n            + Context representation\n            + Attention\n            + Linear layer for dimensionality reduction\n        4. Walk Generation layer\n        5. Classification layer\n        \"\"\"", "\n", "# 1. Embedding layer", "\n", "w_embed", ",", "pe_embed", ",", "pt_embed", ",", "te_embed", ",", "tt_embed", "=", "self", ".", "embedding_layer", "(", "binp", "[", "'text'", "]", ",", "binp", "[", "'ents'", "]", "[", ":", ",", ":", ",", "1", "]", ",", "binp", "[", "'pos_ee'", "]", ",", "binp", "[", "'pos_et'", "]", ")", "\n", "\n", "# 2. Encoder (BLSTM) layer", "\n", "enc_out", "=", "self", ".", "encoder_layer", "(", "binp", "[", "'word'", "]", ",", "w_embed", ")", "\n", "\n", "# 3. Pair representation layer", "\n", "bat", ",", "rows", ",", "cols", ",", "args", ",", "pairs", ",", "condition", ",", "map_pair", "=", "self", ".", "construct_pair", "(", "binp", "[", "'ents'", "]", ",", "binp", "[", "'entity'", "]", ",", "enc_out", ",", "\n", "pe_embed", ",", "te_embed", ")", "\n", "\n", "if", "self", ".", "att", ":", "\n", "            ", "context", ",", "mask", "=", "self", ".", "construct_context", "(", "bat", ",", "rows", ",", "cols", ",", "binp", "[", "'ents'", "]", ",", "binp", "[", "'entity'", "]", ",", "binp", "[", "'word'", "]", ",", "args", ",", "\n", "enc_out", ",", "pe_embed", ",", "pt_embed", ",", "te_embed", ",", "tt_embed", ",", "map_pair", ")", "\n", "\n", "# ATTENTION on context of every pair --> arg1 + arg2 + context (BEE, D)", "\n", "context", ",", "scores", "=", "self", ".", "attention", "(", "context", ",", "mask", "=", "mask", ")", "\n", "\n", "# Target pair representation", "\n", "pairs", "=", "torch", ".", "cat", "(", "(", "pairs", ",", "context", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# reduce dimensionality of target pairs representations", "\n", "", "pairs", "=", "self", ".", "reduce", "(", "pairs", ")", "\n", "\n", "# 4. Walks", "\n", "if", "self", ".", "walks_iter", ">", "0", ":", "\n", "            ", "pairs", "=", "self", ".", "walk_layer", "(", "pairs", ",", "condition", ",", "map_pair", ")", "\n", "\n", "# 5. Classification + Loss", "\n", "", "loss", ",", "probs", ",", "preds", ",", "truth", "=", "self", ".", "classification", "(", "binp", "[", "'l2r'", "]", ",", "binp", "[", "'rels'", "]", ",", "pairs", ",", "map_pair", ")", "\n", "stats_", "=", "self", ".", "measure_statistics", "(", "preds", ",", "truth", ")", "\n", "\n", "if", "self", ".", "att", ":", "\n", "            ", "return", "loss", ",", "stats_", ",", "probs", ",", "preds", ",", "truth", ",", "scores", "\n", "", "else", ":", "\n", "            ", "return", "loss", ",", "stats_", ",", "probs", ",", "preds", ",", "truth", ",", "torch", ".", "zeros_like", "(", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.measure_statistics": [[257, 282], ["torch.as_tensor().long().to", "torch.as_tensor().long().to", "torch.as_tensor().long().to", "torch.as_tensor().long().to", "torch.as_tensor().long().to", "torch.as_tensor().long().to", "torch.as_tensor().long().to", "torch.as_tensor().long().to", "torch.eq().view", "torch.eq().view", "torch.eq().view", "torch.eq().view", "torch.eq().view", "torch.eq().view", "torch.eq().view", "torch.eq().view", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "t.view", "y.view", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.bincount", "torch.as_tensor().long", "torch.as_tensor().long", "torch.as_tensor().long", "torch.as_tensor().long", "torch.as_tensor().long", "torch.as_tensor().long", "torch.as_tensor().long", "torch.as_tensor().long", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor"], "methods", ["None"], ["", "", "def", "measure_statistics", "(", "self", ",", "*", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        Calculate: True Positives (TP), False Positives (FP), False Negatives (FN)\n        GPU & CPU code\n        \"\"\"", "\n", "y", ",", "t", "=", "inputs", "\n", "\n", "label_num", "=", "torch", ".", "as_tensor", "(", "[", "self", ".", "sizes", "[", "'rel_size'", "]", "]", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "ignore_label", "=", "torch", ".", "as_tensor", "(", "[", "self", ".", "lab2ign", "]", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "mask_t", "=", "torch", ".", "eq", "(", "t", ",", "ignore_label", ")", ".", "view", "(", "-", "1", ")", "# true = no_relation", "\n", "mask_p", "=", "torch", ".", "eq", "(", "y", ",", "ignore_label", ")", ".", "view", "(", "-", "1", ")", "# pred = no_relation", "\n", "\n", "true", "=", "torch", ".", "where", "(", "mask_t", ",", "label_num", ",", "t", ".", "view", "(", "-", "1", ")", ")", "# t: ground truth labels (replace ignored with +1)", "\n", "pred", "=", "torch", ".", "where", "(", "mask_p", ",", "label_num", ",", "y", ".", "view", "(", "-", "1", ")", ")", "# y: output of neural network (replace ignored with +1)", "\n", "\n", "tp_mask", "=", "torch", ".", "where", "(", "torch", ".", "eq", "(", "pred", ",", "true", ")", ",", "true", ",", "label_num", ")", "\n", "fp_mask", "=", "torch", ".", "where", "(", "torch", ".", "ne", "(", "pred", ",", "true", ")", ",", "pred", ",", "label_num", ")", "# this includes wrong positive classes as well", "\n", "fn_mask", "=", "torch", ".", "where", "(", "torch", ".", "ne", "(", "pred", ",", "true", ")", ",", "true", ",", "label_num", ")", "\n", "\n", "tp", "=", "torch", ".", "bincount", "(", "tp_mask", ",", "minlength", "=", "self", ".", "sizes", "[", "'rel_size'", "]", "+", "1", ")", "[", ":", "self", ".", "sizes", "[", "'rel_size'", "]", "]", "\n", "fp", "=", "torch", ".", "bincount", "(", "fp_mask", ",", "minlength", "=", "self", ".", "sizes", "[", "'rel_size'", "]", "+", "1", ")", "[", ":", "self", ".", "sizes", "[", "'rel_size'", "]", "]", "\n", "fn", "=", "torch", ".", "bincount", "(", "fn_mask", ",", "minlength", "=", "self", ".", "sizes", "[", "'rel_size'", "]", "+", "1", ")", "[", ":", "self", ".", "sizes", "[", "'rel_size'", "]", "]", "\n", "tn", "=", "torch", ".", "sum", "(", "mask_t", "&", "mask_p", ")", "\n", "return", "{", "'tp'", ":", "tp", ",", "'fp'", ":", "fp", ",", "'fn'", ":", "fn", ",", "'tn'", ":", "tn", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.reverse_labels": [[283, 292], ["range", "torch.tensor().long().to", "torch.tensor().long().to", "torch.tensor().long().to", "torch.tensor().long().to", "[].split", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "reverse_labels", "(", "self", ")", ":", "\n", "        ", "labmap", "=", "[", "]", "\n", "for", "e", "in", "range", "(", "0", ",", "self", ".", "sizes", "[", "'rel_size'", "]", ")", ":", "\n", "            ", "x_", "=", "self", ".", "maps", "[", "'idx2rel'", "]", "[", "e", "]", ".", "split", "(", "':'", ")", "\n", "if", "x_", "[", "1", "]", "==", "'NR'", ":", "\n", "                ", "labmap", "+=", "[", "self", ".", "maps", "[", "'rel2idx'", "]", "[", "'1:NR:2'", "]", "]", "\n", "", "else", ":", "\n", "                ", "labmap", "+=", "[", "self", ".", "maps", "[", "'rel2idx'", "]", "[", "x_", "[", "2", "]", "+", "':'", "+", "x_", "[", "1", "]", "+", "':'", "+", "x_", "[", "0", "]", "]", "]", "\n", "", "", "return", "torch", ".", "tensor", "(", "labmap", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.correct_predictions": [[293, 338], ["network.WalkBasedModel.reverse_labels", "torch.as_tensor().long().to", "torch.as_tensor().long().to", "torch.as_tensor().long().to", "torch.as_tensor().long().to", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.full().long().to", "torch.full().long().to", "torch.full().long().to", "torch.full().long().to", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.full().long().to.float", "torch.full().long().to.float", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.full().long().to.float", "torch.full().long().to.float", "torch.full().long().to.float", "torch.full().long().to.float", "torch.full().long().to.float", "torch.full().long().to.float", "torch.full().long().to.float", "torch.full().long().to.float", "torch.full().long().to.float", "torch.full().long().to.float", "torch.full().long().to.float", "torch.full().long().to.float", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.as_tensor().long", "torch.as_tensor().long", "torch.as_tensor().long", "torch.as_tensor().long", "torch.full().long", "torch.full().long", "torch.full().long", "torch.full().long", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.full().long().to.float", "torch.full().long().to.float", "torch.lt", "torch.lt", "torch.lt", "torch.lt", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.full().long().to.float", "torch.full().long().to.float", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.full().long().to.float", "torch.full().long().to.float", "torch.lt", "torch.lt", "torch.lt", "torch.lt", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.full().long().to.float", "torch.full().long().to.float", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full().long().to.float", "torch.full().long().to.float", "torch.full().long().to.float", "torch.full().long().to.float", "torch.full().long().to.float", "torch.full().long().to.float", "torch.full().long().to.float", "torch.full().long().to.float", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.network.WalkBasedModel.reverse_labels"], ["", "def", "correct_predictions", "(", "self", ",", "even_pred", ",", "odd_pred", ")", ":", "\n", "        ", "\"\"\"\n        Correct predictions: From 2 direction relations choose\n            - if reverse labels -> keep one of them\n            - if one positive, one negative -> keep the positive\n            - if different labels -> more confident (highest probability)\n        \"\"\"", "\n", "labmap", "=", "self", ".", "reverse_labels", "(", ")", "\n", "lab2ign", "=", "torch", ".", "as_tensor", "(", "[", "self", ".", "lab2ign", "]", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# split predictions into 2 arrays: relations (even) & inv-relations (odd)", "\n", "even_probs", ",", "even_lb", "=", "torch", ".", "max", "(", "even_pred", ",", "dim", "=", "1", ")", "\n", "odd_probs", ",", "odd_lb", "=", "torch", ".", "max", "(", "odd_pred", ",", "dim", "=", "1", ")", "\n", "inv_odd_lb", "=", "labmap", "[", "odd_lb", "]", "\n", "\n", "minus", "=", "torch", ".", "full", "(", "even_probs", ".", "shape", ",", "-", "1", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# if inverse of one-another (e.g. 1:rel:2 & 2:rel:1 of both NR) (this is correct) --> keep them the L2R label", "\n", "x1", "=", "torch", ".", "where", "(", "torch", ".", "eq", "(", "even_lb", ",", "inv_odd_lb", ")", ",", "even_lb", ",", "minus", ")", "\n", "x1_p", "=", "torch", ".", "where", "(", "torch", ".", "eq", "(", "even_lb", ",", "inv_odd_lb", ")", ",", "even_probs", ",", "minus", ".", "float", "(", ")", ")", "\n", "\n", "# if both are positive with different labels --> choose from probability", "\n", "cond", "=", "torch", ".", "ne", "(", "even_lb", ",", "lab2ign", ")", "&", "torch", ".", "ne", "(", "odd_lb", ",", "lab2ign", ")", "&", "torch", ".", "ne", "(", "even_lb", ",", "inv_odd_lb", ")", "\n", "xa", "=", "torch", ".", "where", "(", "cond", ",", "even_probs", ",", "minus", ".", "float", "(", ")", ")", "\n", "xb", "=", "torch", ".", "where", "(", "cond", ",", "odd_probs", ",", "minus", ".", "float", "(", ")", ")", "\n", "\n", "x2", "=", "torch", ".", "where", "(", "torch", ".", "ge", "(", "xa", ",", "xb", ")", "&", "torch", ".", "ne", "(", "xa", ",", "minus", ".", "float", "(", ")", ")", "&", "torch", ".", "ne", "(", "xb", ",", "minus", ".", "float", "(", ")", ")", ",", "even_lb", ",", "minus", ")", "\n", "x3", "=", "torch", ".", "where", "(", "torch", ".", "lt", "(", "xa", ",", "xb", ")", "&", "torch", ".", "ne", "(", "xa", ",", "minus", ".", "float", "(", ")", ")", "&", "torch", ".", "ne", "(", "xb", ",", "minus", ".", "float", "(", ")", ")", ",", "inv_odd_lb", ",", "minus", ")", "\n", "x2_p", "=", "torch", ".", "where", "(", "torch", ".", "ge", "(", "xa", ",", "xb", ")", "&", "torch", ".", "ne", "(", "xa", ",", "minus", ".", "float", "(", ")", ")", "&", "torch", ".", "ne", "(", "xb", ",", "minus", ".", "float", "(", ")", ")", ",", "even_probs", ",", "minus", ".", "float", "(", ")", ")", "\n", "x3_p", "=", "torch", ".", "where", "(", "torch", ".", "lt", "(", "xa", ",", "xb", ")", "&", "torch", ".", "ne", "(", "xa", ",", "minus", ".", "float", "(", ")", ")", "&", "torch", ".", "ne", "(", "xb", ",", "minus", ".", "float", "(", ")", ")", ",", "odd_probs", ",", "minus", ".", "float", "(", ")", ")", "\n", "\n", "# if one positive & one negative --> choose the positive", "\n", "x4", "=", "torch", ".", "where", "(", "torch", ".", "eq", "(", "even_lb", ",", "lab2ign", ")", "&", "torch", ".", "ne", "(", "odd_lb", ",", "lab2ign", ")", ",", "inv_odd_lb", ",", "minus", ")", "\n", "x4_p", "=", "torch", ".", "where", "(", "torch", ".", "eq", "(", "even_lb", ",", "lab2ign", ")", "&", "torch", ".", "ne", "(", "odd_lb", ",", "lab2ign", ")", ",", "odd_probs", ",", "minus", ".", "float", "(", ")", ")", "\n", "x5", "=", "torch", ".", "where", "(", "torch", ".", "ne", "(", "even_lb", ",", "lab2ign", ")", "&", "torch", ".", "eq", "(", "odd_lb", ",", "lab2ign", ")", ",", "even_lb", ",", "minus", ")", "\n", "x5_p", "=", "torch", ".", "where", "(", "torch", ".", "ne", "(", "even_lb", ",", "lab2ign", ")", "&", "torch", ".", "eq", "(", "odd_lb", ",", "lab2ign", ")", ",", "even_probs", ",", "minus", ".", "float", "(", ")", ")", "\n", "\n", "fin", "=", "torch", ".", "stack", "(", "[", "x1", ",", "x2", ",", "x3", ",", "x4", ",", "x5", "]", ",", "dim", "=", "0", ")", "\n", "fin_p", "=", "torch", ".", "stack", "(", "[", "x1_p", ",", "x2_p", ",", "x3_p", ",", "x4_p", ",", "x5_p", "]", ",", "dim", "=", "0", ")", "\n", "\n", "assert", "(", "torch", ".", "sum", "(", "torch", ".", "clamp", "(", "fin", ",", "-", "1.0", ",", "0.0", ")", ",", "dim", "=", "0", ")", "==", "-", "4", ")", ".", "all", "(", ")", ",", "\"EVALUATION: error\"", "\n", "assert", "(", "torch", ".", "sum", "(", "torch", ".", "clamp", "(", "fin_p", ",", "-", "1.0", ",", "0.0", ")", ",", "dim", "=", "0", ")", "==", "-", "4", ")", ".", "all", "(", ")", ",", "\"EVALUATION: error\"", "\n", "fin_preds", "=", "torch", ".", "max", "(", "fin", ",", "dim", "=", "0", ")", "[", "0", "]", "\n", "fin_probs", "=", "torch", ".", "max", "(", "fin_p", ",", "dim", "=", "0", ")", "[", "0", "]", "\n", "return", "fin_probs", ",", "fin_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.layers.VectorAttentionLayer.__init__": [[21, 27], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.empty", "torch.empty", "torch.empty", "torch.empty"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.init_net.BaseNet.__init__"], ["def", "__init__", "(", "self", ",", "embed_size", ",", "device", ")", ":", "\n", "        ", "super", "(", "VectorAttentionLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "q", "=", "nn", ".", "Parameter", "(", "nn", ".", "init", ".", "normal_", "(", "torch", ".", "empty", "(", "embed_size", ",", "1", ")", ")", ",", "requires_grad", "=", "True", ")", "# (D,1)", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "embed_size", "=", "embed_size", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.layers.VectorAttentionLayer.forward": [[28, 46], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.softmax", "torch.softmax", "torch.where", "torch.where", "torch.where", "torch.where", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "layers.VectorAttentionLayer.tanh", "layers.VectorAttentionLayer.q.unsqueeze", "mask.unsqueeze", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "torch.isinf().all", "torch.isinf().all", "torch.isinf().all", "torch.isinf().all", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.eq().all", "torch.eq().all", "torch.eq().all", "torch.eq().all", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.where.transpose", "torch.where.transpose", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.isinf", "torch.isinf", "torch.isinf", "torch.isinf", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "float"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "xs", ",", "mask", "=", "None", ")", ":", "\n", "        ", "a_scores", "=", "torch", ".", "matmul", "(", "self", ".", "tanh", "(", "xs", ")", ",", "self", ".", "q", ".", "unsqueeze", "(", "0", ")", ")", "# (BEE, W, 1)", "\n", "\n", "# replace with -inf so that softmax returns 0 in words that should not be included", "\n", "a_scores", "=", "torch", ".", "where", "(", "mask", ".", "unsqueeze", "(", "2", ")", ",", "a_scores", ",", "torch", ".", "as_tensor", "(", "[", "float", "(", "'-inf'", ")", "]", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "\n", "# if no context", "\n", "a_scores", "=", "torch", ".", "where", "(", "torch", ".", "isinf", "(", "a_scores", ")", ".", "all", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ",", "\n", "torch", ".", "full_like", "(", "a_scores", ",", "1.0", ")", ",", "a_scores", ")", "\n", "a_scores", "=", "F", ".", "softmax", "(", "a_scores", ",", "dim", "=", "1", ")", "# (BEE, W, 1)", "\n", "\n", "# if no context", "\n", "a_scores", "=", "torch", ".", "where", "(", "torch", ".", "eq", "(", "a_scores", ",", "1", "/", "a_scores", ".", "shape", "[", "1", "]", ")", ".", "all", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ",", "\n", "torch", ".", "zeros_like", "(", "a_scores", ")", ",", "a_scores", ")", "\n", "\n", "y_expect", "=", "torch", ".", "matmul", "(", "a_scores", ".", "transpose", "(", "1", ",", "2", ")", ",", "xs", ")", "# (BEE, 1, D)", "\n", "y_expect", "=", "torch", ".", "squeeze", "(", "y_expect", ",", "dim", "=", "1", ")", "\n", "return", "y_expect", ",", "torch", ".", "squeeze", "(", "a_scores", ",", "dim", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.layers.WalkLayer.__init__": [[56, 64], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.empty", "torch.empty", "torch.empty", "torch.empty"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.init_net.BaseNet.__init__"], ["def", "__init__", "(", "self", ",", "embed_size", ",", "iter_", ",", "beta", ",", "device", ")", ":", "\n", "        ", "super", "(", "WalkLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "W", "=", "nn", ".", "Parameter", "(", "nn", ".", "init", ".", "normal_", "(", "torch", ".", "empty", "(", "embed_size", ",", "embed_size", ")", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "embed_size", "=", "embed_size", "\n", "self", ".", "iter", "=", "iter_", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.layers.WalkLayer.generate": [[65, 79], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "a.view.view.view", "b.view.view.view", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "mask.unsqueeze", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "mask.unsqueeze", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["None"], ["", "def", "generate", "(", "self", ",", "old_pairs", ",", "part1", ",", "part2", ",", "items", ")", ":", "\n", "# value == -1 indicates invalid pair (padded)", "\n", "        ", "bilin", "=", "torch", ".", "matmul", "(", "old_pairs", ",", "self", ".", "W", ")", "\n", "a", "=", "bilin", "[", "part1", "]", "\n", "b", "=", "old_pairs", "[", "part2", "]", "\n", "mask", "=", "(", "torch", ".", "ge", "(", "part1", ",", "0", ")", "&", "torch", ".", "ge", "(", "part2", ",", "0", ")", ")", "# mask padded intermediate entities", "\n", "\n", "a", "=", "torch", ".", "where", "(", "mask", ".", "unsqueeze", "(", "1", ")", ",", "a", ",", "torch", ".", "zeros_like", "(", "a", ")", ")", "\n", "b", "=", "torch", ".", "where", "(", "mask", ".", "unsqueeze", "(", "1", ")", ",", "b", ",", "torch", ".", "zeros_like", "(", "b", ")", ")", "\n", "a", "=", "a", ".", "view", "(", "-", "1", ",", "items", ",", "a", ".", "shape", "[", "1", "]", ")", "\n", "b", "=", "b", ".", "view", "(", "-", "1", ",", "items", ",", "b", ".", "shape", "[", "1", "]", ")", "\n", "\n", "new_pairs", "=", "a", "*", "b", "# elementwise", "\n", "return", "old_pairs", ",", "new_pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.layers.WalkLayer.aggregate": [[80, 96], ["float", "float", "float", "float", "torch.where", "torch.where", "torch.where", "torch.where", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.isinf().all", "torch.isinf().all", "torch.isinf().all", "torch.isinf().all", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "layers.WalkLayer.sigmoid", "torch.eq().all", "torch.eq().all", "torch.eq().all", "torch.eq().all", "torch.isinf", "torch.isinf", "torch.isinf", "torch.isinf", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["None"], ["", "def", "aggregate", "(", "self", ",", "old_pairs", ",", "new_pairs", ",", "idx", ",", "items", ",", "map_pair", ")", ":", "\n", "# mask invalid", "\n", "        ", "new_pairs", "[", "(", "idx", "[", "2", "]", "==", "idx", "[", "3", "]", ")", ".", "view", "(", "-", "1", ",", "items", ")", "]", "=", "float", "(", "'-inf'", ")", "# A -> C -> C", "\n", "new_pairs", "[", "(", "idx", "[", "1", "]", "==", "idx", "[", "3", "]", ")", ".", "view", "(", "-", "1", ",", "items", ")", "]", "=", "float", "(", "'-inf'", ")", "# A -> A -> C", "\n", "new_pairs", "[", "map_pair", "[", ":", ",", "torch", ".", "arange", "(", "items", ")", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "torch", ".", "arange", "(", "items", ")", ".", "to", "(", "self", ".", "device", ")", "]", ",", ":", "]", "=", "float", "(", "'-inf'", ")", "# A -> * -> A", "\n", "new_pairs", "[", "torch", ".", "eq", "(", "new_pairs", ",", "torch", ".", "zeros_like", "(", "new_pairs", ")", ")", ".", "all", "(", "dim", "=", "2", ")", "]", "=", "float", "(", "'-inf'", ")", "# padded entities", "\n", "\n", "mat", "=", "torch", ".", "where", "(", "torch", ".", "isinf", "(", "new_pairs", ")", ".", "all", "(", "dim", "=", "1", ")", ",", "# If no valid intermediate node", "\n", "torch", ".", "ones_like", "(", "old_pairs", ")", ",", "\n", "torch", ".", "full_like", "(", "old_pairs", ",", "self", ".", "beta", ")", ")", "# [:, 0].unsqueeze(-1)", "\n", "\n", "new_pairs", "=", "torch", ".", "sum", "(", "self", ".", "sigmoid", "(", "new_pairs", ")", ",", "dim", "=", "1", ")", "# non-linearity & sum pooling", "\n", "# new_pairs = torch.lerp(new_pairs, old_pairs, weight=mat)  # interpolation", "\n", "new_pairs", "=", "(", "mat", "*", "old_pairs", ")", "+", "(", "(", "1", "-", "mat", ")", "*", "new_pairs", ")", "# interpolation", "\n", "return", "new_pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.layers.WalkLayer.forward": [[97, 111], ["torch.broadcast_tensors", "torch.broadcast_tensors", "torch.broadcast_tensors", "torch.broadcast_tensors", "torch.nonzero().unbind", "torch.nonzero().unbind", "torch.nonzero().unbind", "torch.nonzero().unbind", "range", "cond.unsqueeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "layers.WalkLayer.generate", "layers.WalkLayer.aggregate", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.layers.WalkLayer.generate", "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.layers.WalkLayer.aggregate"], ["", "def", "forward", "(", "self", ",", "pairs", ",", "cond", ",", "map_pair", ")", ":", "\n", "        ", "cond", ",", "_", "=", "torch", ".", "broadcast_tensors", "(", "cond", ".", "unsqueeze", "(", "-", "1", ")", ",", "torch", ".", "zeros", "(", "(", "1", ",", "1", ",", "1", ",", "cond", ".", "shape", "[", "1", "]", ")", ")", ")", "\n", "\n", "idx", "=", "torch", ".", "nonzero", "(", "cond", ")", ".", "unbind", "(", "dim", "=", "1", ")", "# batch [0], row [1], col [2], intermediate [3]", "\n", "items", "=", "map_pair", ".", "shape", "[", "1", "]", "\n", "\n", "part1", "=", "map_pair", "[", "idx", "[", "0", "]", ",", "idx", "[", "1", "]", ",", "idx", "[", "3", "]", "]", "\n", "part2", "=", "map_pair", "[", "idx", "[", "0", "]", ",", "idx", "[", "3", "]", ",", "idx", "[", "2", "]", "]", "\n", "\n", "for", "_", "in", "range", "(", "0", ",", "self", ".", "iter", ")", ":", "\n", "            ", "old_pairs", ",", "new_pairs", "=", "self", ".", "generate", "(", "pairs", ",", "part1", ",", "part2", ",", "items", ")", "\n", "pairs", "=", "self", ".", "aggregate", "(", "old_pairs", ",", "new_pairs", ",", "idx", ",", "items", ",", "map_pair", ")", "\n", "\n", "", "return", "pairs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.init_net.BaseNet.__init__": [[19, 99], ["torch.nn.Module.__init__", "torch.device", "nnet.modules.EmbedLayer", "nnet.modules.EmbedLayer", "nnet.modules.EmbedLayer", "nnet.modules.Encoder", "nnet.modules.Classifier", "VectorAttentionLayer", "torch.nn.Linear", "torch.nn.Linear", "WalkLayer"], "methods", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.init_net.BaseNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "sizes", ",", "pembeds", ",", "lab2ign", "=", "None", ",", "o_type", "=", "None", ",", "maps", "=", "None", ")", ":", "\n", "        ", "super", "(", "BaseNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "w_dim", "=", "2", "*", "params", "[", "'lstm_dim'", "]", "\n", "self", ".", "e_dim", "=", "2", "*", "params", "[", "'lstm_dim'", "]", "\n", "\n", "self", ".", "maps", "=", "maps", "\n", "self", ".", "lab2ign", "=", "lab2ign", "\n", "self", ".", "o_type", "=", "o_type", "\n", "self", ".", "direction", "=", "params", "[", "'direction'", "]", "\n", "self", ".", "sizes", "=", "sizes", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda:{}\"", ".", "format", "(", "params", "[", "'gpu'", "]", ")", "if", "params", "[", "'gpu'", "]", "!=", "-", "1", "else", "\"cpu\"", ")", "\n", "\n", "#############################################", "\n", "# Layers", "\n", "#############################################", "\n", "self", ".", "word_embed", "=", "EmbedLayer", "(", "num_embeddings", "=", "sizes", "[", "'word_size'", "]", ",", "\n", "embedding_dim", "=", "params", "[", "'word_dim'", "]", ",", "\n", "dropout", "=", "params", "[", "'dropi'", "]", ",", "\n", "ignore", "=", "None", ",", "\n", "freeze", "=", "False", ",", "\n", "pretrained", "=", "pembeds", ",", "\n", "mapping", "=", "maps", "[", "'word2idx'", "]", ")", "\n", "\n", "self", ".", "pos_embed", "=", "EmbedLayer", "(", "num_embeddings", "=", "sizes", "[", "'pos_size'", "]", "+", "1", ",", "\n", "embedding_dim", "=", "params", "[", "'pos_dim'", "]", ",", "\n", "dropout", "=", "0.0", ",", "\n", "ignore", "=", "sizes", "[", "'pos_size'", "]", ",", "\n", "freeze", "=", "False", ",", "\n", "pretrained", "=", "None", ",", "\n", "mapping", "=", "maps", "[", "'pos2idx'", "]", ")", "\n", "self", ".", "w_dim", "+=", "2", "*", "params", "[", "'pos_dim'", "]", "\n", "self", ".", "e_dim", "+=", "params", "[", "'pos_dim'", "]", "\n", "\n", "self", ".", "type_embed", "=", "EmbedLayer", "(", "num_embeddings", "=", "sizes", "[", "'type_size'", "]", "+", "1", ",", "\n", "embedding_dim", "=", "params", "[", "'type_dim'", "]", ",", "\n", "dropout", "=", "0.0", ",", "\n", "ignore", "=", "sizes", "[", "'type_size'", "]", ",", "\n", "freeze", "=", "False", ",", "\n", "pretrained", "=", "None", ",", "\n", "mapping", "=", "maps", "[", "'type2idx'", "]", ")", "\n", "self", ".", "w_dim", "+=", "params", "[", "'type_dim'", "]", "\n", "self", ".", "e_dim", "+=", "params", "[", "'type_dim'", "]", "\n", "\n", "self", ".", "encoder", "=", "Encoder", "(", "input_size", "=", "params", "[", "'word_dim'", "]", ",", "\n", "rnn_size", "=", "params", "[", "'out_dim'", "]", ",", "\n", "num_layers", "=", "1", ",", "\n", "bidirectional", "=", "True", ",", "\n", "dropout", "=", "0.0", ")", "\n", "\n", "if", "params", "[", "'att'", "]", ":", "\n", "            ", "self", ".", "attention", "=", "VectorAttentionLayer", "(", "self", ".", "w_dim", ",", "self", ".", "device", ")", "\n", "self", ".", "reduce", "=", "nn", ".", "Linear", "(", "2", "*", "self", ".", "e_dim", "+", "self", ".", "w_dim", ",", "params", "[", "'out_dim'", "]", ",", "bias", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "reduce", "=", "nn", ".", "Linear", "(", "2", "*", "self", ".", "e_dim", ",", "params", "[", "'out_dim'", "]", ",", "bias", "=", "False", ")", "\n", "\n", "", "if", "params", "[", "'walks_iter'", "]", ">", "0", ":", "\n", "            ", "self", ".", "walk_layer", "=", "WalkLayer", "(", "params", "[", "'out_dim'", "]", ",", "params", "[", "'walks_iter'", "]", ",", "params", "[", "'beta'", "]", ",", "self", ".", "device", ")", "\n", "\n", "", "self", ".", "classifier", "=", "Classifier", "(", "in_size", "=", "params", "[", "'out_dim'", "]", ",", "\n", "out_size", "=", "sizes", "[", "'rel_size'", "]", ",", "\n", "dropout", "=", "params", "[", "'dropo'", "]", ")", "\n", "\n", "#############################################", "\n", "# Hyper-parameters", "\n", "#############################################", "\n", "self", ".", "beta", "=", "params", "[", "'beta'", "]", "\n", "self", ".", "att", "=", "params", "[", "'att'", "]", "\n", "self", ".", "word_dim", "=", "params", "[", "'word_dim'", "]", "\n", "self", ".", "pos_dim", "=", "params", "[", "'pos_dim'", "]", "\n", "self", ".", "type_dim", "=", "params", "[", "'type_dim'", "]", "\n", "self", ".", "dropi", "=", "params", "[", "'dropi'", "]", "\n", "self", ".", "dropm", "=", "params", "[", "'dropm'", "]", "\n", "self", ".", "dropo", "=", "params", "[", "'dropo'", "]", "\n", "self", ".", "out_dim", "=", "params", "[", "'out_dim'", "]", "\n", "self", ".", "lstm_dim", "=", "params", "[", "'lstm_dim'", "]", "\n", "self", ".", "walks_iter", "=", "params", "[", "'walks_iter'", "]", "\n", "self", ".", "lr", "=", "params", "[", "'lr'", "]", "\n", "self", ".", "gc", "=", "params", "[", "'gc'", "]", "\n", "self", ".", "reg", "=", "params", "[", "'reg'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.statistics.chunks": [[25, 32], ["range", "len", "len"], "function", ["None"], ["def", "chunks", "(", "l", ",", "n", ")", ":", "\n", "    ", "\"\"\"\n    Yield successive n-sized chunks from l.\n    \"\"\"", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "l", ")", ",", "n", ")", ":", "\n", "        ", "assert", "len", "(", "l", "[", "i", ":", "i", "+", "n", "]", ")", "==", "n", "\n", "yield", "l", "[", "i", ":", "i", "+", "n", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.tools.generate_pairs": [[26, 85], ["collections.OrderedDict", "itertools.combinations", "len", "tqdm.tqdm.write", "PairStruct", "tqdm.tqdm.write", "PairStruct", "PairStruct", "PairStruct", "PairStruct", "str"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write"], ["def", "generate_pairs", "(", "uents", ",", "true_rels", ")", ":", "\n", "    ", "\"\"\"\n    Generate pais based on their direction as well L2R or R2L\n    \"\"\"", "\n", "pairs", "=", "OrderedDict", "(", ")", "\n", "combs", "=", "combinations", "(", "uents", ",", "2", ")", "\n", "\n", "count_not_found", "=", "0", "\n", "unk", "=", "0", "\n", "total_rels", "=", "len", "(", "true_rels", ")", "\n", "found_rels", "=", "0", "\n", "\n", "for", "c", "in", "combs", ":", "\n", "        ", "target", "=", "[", "c", "[", "0", "]", ",", "c", "[", "1", "]", "]", "\n", "\n", "if", "target", "[", "0", "]", ".", "word_id", "[", "-", "1", "]", "<=", "target", "[", "1", "]", ".", "word_id", "[", "0", "]", ":", "# A before B (in text)", "\n", "            ", "a1", "=", "target", "[", "0", "]", "\n", "a2", "=", "target", "[", "1", "]", "\n", "", "else", ":", "# B before A (in text)", "\n", "            ", "a1", "=", "target", "[", "1", "]", "\n", "a2", "=", "target", "[", "0", "]", "\n", "\n", "", "not_found_rels", "=", "0", "\n", "\n", "for", "tr", "in", "true_rels", ":", "\n", "# AB existing relation", "\n", "            ", "if", "(", "tr", ".", "arg1", "==", "a1", ".", "entid", ")", "and", "(", "tr", ".", "arg2", "==", "a2", ".", "entid", ")", ":", "\n", "                ", "if", "tr", ".", "type", "==", "'Other'", ":", "\n", "                    ", "pairs", "[", "tr", ".", "relid", "]", "=", "PairStruct", "(", "tr", ".", "docid", ",", "'1:NR:2'", ",", "a1", ",", "a2", ",", "'L2R'", ",", "'NON-CROSS'", ")", "\n", "found_rels", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "pairs", "[", "tr", ".", "relid", "]", "=", "PairStruct", "(", "tr", ".", "docid", ",", "'1:'", "+", "tr", ".", "type", "+", "':2'", ",", "a1", ",", "a2", ",", "'L2R'", ",", "'NON-CROSS'", ")", "\n", "found_rels", "+=", "1", "\n", "\n", "# BA existing relation ", "\n", "", "", "elif", "(", "tr", ".", "arg1", "==", "a2", ".", "entid", ")", "and", "(", "tr", ".", "arg2", "==", "a1", ".", "entid", ")", ":", "\n", "                ", "if", "tr", ".", "type", "==", "'Other'", ":", "\n", "                    ", "pairs", "[", "tr", ".", "relid", "]", "=", "PairStruct", "(", "tr", ".", "docid", ",", "'1:NR:2'", ",", "a1", ",", "a2", ",", "'R2L'", ",", "'NON-CROSS'", ")", "\n", "found_rels", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "pairs", "[", "tr", ".", "relid", "]", "=", "PairStruct", "(", "tr", ".", "docid", ",", "'2:'", "+", "tr", ".", "type", "+", "':1'", ",", "a1", ",", "a2", ",", "'R2L'", ",", "'NON-CROSS'", ")", "\n", "found_rels", "+=", "1", "\n", "\n", "# relation not found", "\n", "", "", "else", ":", "\n", "                ", "not_found_rels", "+=", "1", "\n", "\n", "# this pair does not have a relation", "\n", "", "", "if", "not_found_rels", "==", "total_rels", ":", "\n", "            ", "pairs", "[", "'R_neg'", "+", "str", "(", "unk", ")", "]", "=", "PairStruct", "(", "a1", ".", "docid", ",", "'1:NR:2'", ",", "a1", ",", "a2", ",", "'L2R'", ",", "'NON-CROSS'", ")", "\n", "unk", "+=", "1", "\n", "\n", "", "", "if", "found_rels", "!=", "total_rels", ":", "\n", "        ", "count_not_found", "+=", "(", "total_rels", "-", "found_rels", ")", "\n", "tqdm", ".", "write", "(", "'FOUND {} <> TOTAL {}, diff {}'", ".", "format", "(", "found_rels", ",", "total_rels", ",", "total_rels", "-", "found_rels", ")", ")", "\n", "for", "p", "in", "true_rels", ":", "\n", "            ", "if", "p", ".", "relid", "not", "in", "pairs", ":", "\n", "                ", "tqdm", ".", "write", "(", "'{}, {}'", ".", "format", "(", "p", ".", "arg1", ",", "p", ".", "arg2", ")", ")", "\n", "", "", "", "return", "pairs", ",", "count_not_found", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.tools.generate_pairs_types": [[87, 131], ["collections.OrderedDict", "itertools.permutations", "len", "tqdm.tqdm.write", "zip", "print", "PairStruct", "PairStruct", "PairStruct", "str"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write"], ["", "def", "generate_pairs_types", "(", "uents", ",", "type1", ",", "type2", ",", "true_rels", ")", ":", "\n", "    ", "\"\"\"\n    Generate pais based on their direction as well L2R or R2L\n    \"\"\"", "\n", "pairs", "=", "OrderedDict", "(", ")", "\n", "combs", "=", "permutations", "(", "uents", ",", "2", ")", "\n", "\n", "count_not_found", "=", "0", "\n", "unk", "=", "0", "\n", "total_rels", "=", "len", "(", "true_rels", ")", "\n", "found_rels", "=", "0", "\n", "\n", "for", "c", "in", "combs", ":", "\n", "        ", "a1", "=", "c", "[", "0", "]", "\n", "a2", "=", "c", "[", "1", "]", "\n", "\n", "not_found_rels", "=", "0", "\n", "for", "tr", "in", "true_rels", ":", "\n", "            ", "if", "(", "tr", ".", "arg1", "==", "a1", ".", "entid", ")", "and", "(", "tr", ".", "arg2", "==", "a2", ".", "entid", ")", ":", "\n", "                ", "if", "tr", ".", "type", "==", "'Other'", ":", "\n", "                    ", "pairs", "[", "tr", ".", "relid", "]", "=", "PairStruct", "(", "tr", ".", "docid", ",", "'1:NR:2'", ",", "a1", ",", "a2", ",", "'L2R'", ",", "'NON-CROSS'", ")", "\n", "found_rels", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "pairs", "[", "tr", ".", "relid", "]", "=", "PairStruct", "(", "tr", ".", "docid", ",", "'1:'", "+", "tr", ".", "type", "+", "':2'", ",", "a1", ",", "a2", ",", "'L2R'", ",", "'NON-CROSS'", ")", "\n", "found_rels", "+=", "1", "\n", "\n", "# relation not found", "\n", "", "", "else", ":", "\n", "                ", "not_found_rels", "+=", "1", "\n", "\n", "# this pair does not have a relation", "\n", "", "", "if", "not_found_rels", "==", "total_rels", ":", "\n", "            ", "for", "t1", ",", "t2", "in", "zip", "(", "type1", ",", "type2", ")", ":", "\n", "                ", "if", "(", "a1", ".", "type", "==", "t1", ")", "and", "(", "a2", ".", "type", "==", "t2", ")", ":", "# and (a1.word_id != a2.word_id):", "\n", "                    ", "pairs", "[", "'R_neg'", "+", "str", "(", "unk", ")", "]", "=", "PairStruct", "(", "a1", ".", "docid", ",", "'1:NR:2'", ",", "a1", ",", "a2", ",", "'L2R'", ",", "'NON-CROSS'", ")", "\n", "unk", "+=", "1", "\n", "\n", "", "", "", "", "if", "found_rels", "!=", "total_rels", ":", "\n", "        ", "count_not_found", "+=", "(", "total_rels", "-", "found_rels", ")", "\n", "tqdm", ".", "write", "(", "'FOUND {} <> TOTAL {}, diff {}'", ".", "format", "(", "found_rels", ",", "total_rels", ",", "total_rels", "-", "found_rels", ")", ")", "\n", "for", "p", "in", "true_rels", ":", "\n", "            ", "if", "p", ".", "relid", "not", "in", "pairs", ":", "\n", "                ", "print", "(", "'{}, {}'", ".", "format", "(", "p", ".", "arg1", ",", "p", ".", "arg2", ")", ")", "\n", "", "", "", "return", "pairs", ",", "count_not_found", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.tools.fix_sent_break": [[133, 146], ["sents_break.split", "sents_break[].replace"], "function", ["None"], ["", "def", "fix_sent_break", "(", "sents", ",", "entities", ")", ":", "\n", "    ", "\"\"\"\n    Fix sentence break if inside an entity.\n    Args:\n        sents: (list) old sentences\n        entities: (list of structs) entities\n    Returns: (list) new sentences\n    \"\"\"", "\n", "sents_break", "=", "'\\n'", ".", "join", "(", "sents", ")", "\n", "for", "e", "in", "entities", ":", "\n", "        ", "if", "'\\n'", "in", "sents_break", "[", "e", ".", "off1", ":", "e", ".", "off2", "]", ":", "\n", "            ", "sents_break", "=", "sents_break", "[", "0", ":", "e", ".", "off1", "]", "+", "sents_break", "[", "e", ".", "off1", ":", "e", ".", "off2", "]", ".", "replace", "(", "'\\n'", ",", "''", ")", "+", "sents_break", "[", "e", ".", "off2", ":", "]", "\n", "", "", "return", "sents_break", ".", "split", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.tools.adjust_offsets": [[148, 228], ["len", "len", "terms.copy", "terms.values", "int", "int", "terms[].append", "terms.copy.keys", "terms.copy.keys", "newtext[].replace().replace", "term[].replace().replace", "tqdm.tqdm.write", "terms.copy.keys", "terms.copy.keys", "EntStruct", "newtext[].replace", "term[].replace", "repr", "repr", "tqdm.tqdm.write", "exit", "repr", "repr"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write"], ["", "def", "adjust_offsets", "(", "old_sents", ",", "new_sents", ",", "old_entities", ")", ":", "\n", "    ", "\"\"\"\n    Adjust offsets  of entities\n    Args:\n        old sents: (list) old, non-tokenized sentences\n        new_sents: (list) new, tokenized sentences\n        old_entities: (list of structs) entities with old offsets\n    Returns: (list of struces) entities with new offsets\n    \"\"\"", "\n", "original", "=", "\" \"", ".", "join", "(", "old_sents", ")", "\n", "newtext", "=", "\" \"", ".", "join", "(", "new_sents", ")", "\n", "new_entities", "=", "[", "]", "\n", "terms", "=", "{", "}", "\n", "for", "e", "in", "old_entities", ":", "\n", "        ", "start", "=", "int", "(", "e", ".", "off1", ")", "\n", "end", "=", "int", "(", "e", ".", "off2", ")", "\n", "\n", "if", "(", "start", ",", "end", ")", "not", "in", "terms", ":", "\n", "            ", "terms", "[", "(", "start", ",", "end", ")", "]", "=", "[", "[", "start", ",", "end", ",", "e", ".", "type", ",", "e", ".", "name", ",", "e", ".", "docid", ",", "e", ".", "entid", "]", "]", "\n", "", "else", ":", "\n", "            ", "terms", "[", "(", "start", ",", "end", ")", "]", ".", "append", "(", "[", "start", ",", "end", ",", "e", ".", "type", ",", "e", ".", "name", ",", "e", ".", "docid", ",", "e", ".", "entid", "]", ")", "\n", "\n", "", "", "orgidx", "=", "0", "\n", "newidx", "=", "0", "\n", "orglen", "=", "len", "(", "original", ")", "\n", "newlen", "=", "len", "(", "newtext", ")", "\n", "\n", "terms2", "=", "terms", ".", "copy", "(", ")", "\n", "while", "orgidx", "<", "orglen", "and", "newidx", "<", "newlen", ":", "\n", "# print(repr(original[orgidx]), orgidx, repr(newtext[newidx]), newidx)", "\n", "\n", "        ", "if", "original", "[", "orgidx", "]", "==", "newtext", "[", "newidx", "]", ":", "\n", "            ", "orgidx", "+=", "1", "\n", "newidx", "+=", "1", "\n", "", "elif", "newtext", "[", "newidx", "]", "==", "'\\n'", ":", "\n", "            ", "newidx", "+=", "1", "\n", "", "elif", "original", "[", "orgidx", "]", "==", "'\\n'", ":", "\n", "            ", "orgidx", "+=", "1", "\n", "", "elif", "original", "[", "orgidx", "]", "==", "' '", ":", "\n", "            ", "orgidx", "+=", "1", "\n", "", "elif", "newtext", "[", "newidx", "]", "==", "' '", ":", "\n", "            ", "newidx", "+=", "1", "\n", "", "else", ":", "\n", "            ", "tqdm", ".", "write", "(", "\"Non-existent text: %d\\t --> %s != %s \"", "%", "(", "orgidx", ",", "repr", "(", "original", "[", "orgidx", "-", "10", ":", "orgidx", "+", "10", "]", ")", ",", "\n", "repr", "(", "newtext", "[", "newidx", "-", "10", ":", "newidx", "+", "10", "]", ")", ")", ")", "\n", "exit", "(", "0", ")", "\n", "\n", "", "starts", "=", "[", "key", "[", "0", "]", "for", "key", "in", "terms2", ".", "keys", "(", ")", "]", "\n", "ends", "=", "[", "key", "[", "1", "]", "for", "key", "in", "terms2", ".", "keys", "(", ")", "]", "\n", "\n", "if", "orgidx", "in", "starts", ":", "\n", "            ", "tt", "=", "[", "key", "for", "key", "in", "terms2", ".", "keys", "(", ")", "if", "key", "[", "0", "]", "==", "orgidx", "]", "# take all pairs with start == orgidx", "\n", "for", "sel", "in", "tt", ":", "\n", "                ", "for", "l", "in", "terms", "[", "sel", "]", ":", "\n", "                    ", "l", "[", "0", "]", "=", "newidx", "\n", "", "for", "l", "in", "terms2", "[", "sel", "]", ":", "\n", "                    ", "l", "[", "0", "]", "=", "newidx", "\n", "\n", "", "", "", "if", "orgidx", "in", "ends", ":", "\n", "            ", "tt2", "=", "[", "key", "for", "key", "in", "terms2", ".", "keys", "(", ")", "if", "key", "[", "1", "]", "==", "orgidx", "]", "# take all pairs with end == orgidx", "\n", "for", "sel2", "in", "tt2", ":", "\n", "                ", "for", "l", "in", "terms", "[", "sel2", "]", ":", "\n", "                    ", "l", "[", "1", "]", "=", "newidx", "\n", "", "for", "l", "in", "terms2", "[", "sel2", "]", ":", "\n", "                    ", "if", "l", "[", "1", "]", "==", "orgidx", ":", "\n", "                        ", "l", "[", "1", "]", "=", "newidx", "\n", "\n", "", "", "", "for", "t_", "in", "tt2", ":", "\n", "                ", "del", "terms2", "[", "t_", "]", "\n", "\n", "", "", "", "for", "ts", "in", "terms", ".", "values", "(", ")", ":", "\n", "        ", "for", "term", "in", "ts", ":", "\n", "            ", "if", "newtext", "[", "term", "[", "0", "]", ":", "term", "[", "1", "]", "]", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "==", "term", "[", "3", "]", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ".", "replace", "(", "'\\n'", ",", "\"\"", ")", ":", "\n", "\n", "                ", "new_entities", "+=", "[", "EntStruct", "(", "term", "[", "4", "]", ",", "term", "[", "5", "]", ",", "newtext", "[", "term", "[", "0", "]", ":", "term", "[", "1", "]", "]", ",", "term", "[", "0", "]", ",", "term", "[", "1", "]", ",", "term", "[", "2", "]", ",", "-", "1", ",", "[", "]", ")", "]", "\n", "", "else", ":", "\n", "                ", "tqdm", ".", "write", "(", "'ERROR: {} ({}-{}) <=> {}'", ".", "format", "(", "repr", "(", "newtext", "[", "term", "[", "0", "]", ":", "term", "[", "1", "]", "]", ")", ",", "term", "[", "0", "]", ",", "term", "[", "1", "]", ",", "\n", "repr", "(", "term", "[", "3", "]", ")", ")", ")", "\n", "", "", "", "return", "new_entities", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.tools.offsets2tokids": [[230, 275], ["enumerate", "utils.using_split2", "int", "int", "len", "len", "tqdm.tqdm.write", "print", "span2append.append", "text[].split", "utils.using_split2", "span2append.append", "repr", "repr", "span2append.append", "span2append.append", "len", "span2append.append", "tqdm.tqdm.write", "set().intersection", "set", "set", "range", "range", "text.split"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.utils.using_split2", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write", "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.utils.using_split2", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write"], ["", "def", "offsets2tokids", "(", "sents", ",", "entities", ")", ":", "\n", "    ", "\"\"\"\n    Convert entities to token Ids\n    Args:\n        sents:\n        entities:\n    Returns:\n    \"\"\"", "\n", "text", "=", "\" \"", ".", "join", "(", "sents", ")", "\n", "\n", "for", "e", "in", "entities", ":", "\n", "\n", "        ", "span2append", "=", "[", "]", "\n", "for", "tok_id", ",", "(", "tok", ",", "start", ",", "end", ")", "in", "enumerate", "(", "using_split2", "(", "text", ")", ")", ":", "\n", "            ", "start", "=", "int", "(", "start", ")", "\n", "end", "=", "int", "(", "end", ")", "\n", "\n", "if", "(", "start", ",", "end", ")", "==", "(", "e", ".", "off1", ",", "e", ".", "off2", ")", ":", "\n", "                ", "span2append", ".", "append", "(", "tok_id", ")", "\n", "\n", "", "elif", "start", "==", "e", ".", "off1", "and", "end", "<", "e", ".", "off2", ":", "\n", "                ", "span2append", ".", "append", "(", "tok_id", ")", "\n", "\n", "", "elif", "start", ">", "e", ".", "off1", "and", "end", "<", "e", ".", "off2", ":", "\n", "                ", "span2append", ".", "append", "(", "tok_id", ")", "\n", "\n", "", "elif", "start", ">", "e", ".", "off1", "and", "end", "==", "e", ".", "off2", ":", "\n", "                ", "span2append", ".", "append", "(", "tok_id", ")", "\n", "\n", "", "elif", "len", "(", "set", "(", "range", "(", "start", ",", "end", ")", ")", ".", "intersection", "(", "set", "(", "range", "(", "e", ".", "off1", ",", "e", ".", "off2", ")", ")", ")", ")", ">", "0", ":", "\n", "                ", "span2append", ".", "append", "(", "tok_id", ")", "\n", "\n", "# entity has more characters (incomplete tokenization)", "\n", "tqdm", ".", "write", "(", "'entity: {:<10} ({}-{}) <-> token: {:<10} ({}-{}) <-> final: {:<10}'", ".", "format", "(", "\n", "text", "[", "e", ".", "off1", ":", "e", ".", "off2", "]", ",", "e", ".", "off1", ",", "e", ".", "off2", ",", "tok", ",", "start", ",", "end", ",", "\n", "' '", ".", "join", "(", "text", ".", "split", "(", "' '", ")", "[", "span2append", "[", "0", "]", ":", "span2append", "[", "-", "1", "]", "+", "1", "]", ")", ")", ")", "\n", "\n", "# include all tokens!", "\n", "", "", "if", "len", "(", "span2append", ")", "!=", "len", "(", "text", "[", "e", ".", "off1", ":", "e", ".", "off2", "]", ".", "split", "(", "' '", ")", ")", ":", "\n", "            ", "tqdm", ".", "write", "(", "'DOC_ID {}, new entity {}, tokens {}, old entity {}'", ".", "format", "(", "\n", "e", ".", "docid", ",", "repr", "(", "text", "[", "e", ".", "off1", ":", "e", ".", "off2", "]", ")", ",", "span2append", ",", "repr", "(", "e", ".", "name", ")", ")", ")", "\n", "print", "(", "using_split2", "(", "text", ")", ")", "\n", "", "else", ":", "\n", "            ", "e", ".", "word_id", "=", "span2append", "\n", "", "", "return", "entities", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.tools.ent2sent": [[277, 302], ["enumerate", "len", "set().issubset", "len", "tqdm.tqdm.write", "set", "len", "set", "numpy.arange", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write"], ["", "def", "ent2sent", "(", "sents", ",", "entities", ")", ":", "\n", "    ", "\"\"\"\n    Find the sentence where the entity belongs.\n    Args:\n        sents:\n        entities:\n    Returns:\n    \"\"\"", "\n", "cur", "=", "0", "\n", "new_sent_range", "=", "[", "]", "\n", "for", "s", "in", "sents", ":", "\n", "        ", "new_sent_range", "+=", "[", "(", "cur", ",", "cur", "+", "len", "(", "s", ")", ")", "]", "\n", "cur", "+=", "len", "(", "s", ")", "+", "1", "\n", "\n", "", "for", "e", "in", "entities", ":", "\n", "        ", "sent_no", "=", "[", "]", "\n", "for", "s_no", ",", "sr", "in", "enumerate", "(", "new_sent_range", ")", ":", "\n", "            ", "if", "set", "(", "np", ".", "arange", "(", "e", ".", "off1", ",", "e", ".", "off2", ")", ")", ".", "issubset", "(", "set", "(", "np", ".", "arange", "(", "sr", "[", "0", "]", ",", "sr", "[", "1", "]", ")", ")", ")", ":", "\n", "                ", "sent_no", "+=", "[", "s_no", "]", "\n", "\n", "", "", "if", "len", "(", "sent_no", ")", "==", "1", ":", "\n", "            ", "e", ".", "sent_no", "=", "sent_no", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "tqdm", ".", "write", "(", "'{} ({}, {}) -- {}'", ".", "format", "(", "sent_no", ",", "e", ".", "off1", ",", "e", ".", "off2", ",", "new_sent_range", ")", ")", "\n", "", "", "return", "entities", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.tools.check_entities": [[304, 394], ["itertools.combinations", "tqdm.tqdm.write", "len", "entities.remove", "set", "set", "set", "set", "len", "len", "len", "len", "list", "list", "repr", "repr", "len", "len"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write"], ["", "def", "check_entities", "(", "entities", ",", "relations", ",", "include_nested", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Remove -- duplicate entries\n           -- nested entities\n           -- entities that are not found in text\n    Args:\n        entities:  (list of structs) entities\n        include_nested: (bool) include/not nested entities\n    Returns: (list of structs) entities\n    \"\"\"", "\n", "todel", "=", "[", "]", "\n", "if", "not", "entities", ":", "\n", "        ", "pass", "\n", "", "else", ":", "\n", "        ", "for", "a", ",", "b", "in", "combinations", "(", "entities", ",", "2", ")", ":", "\n", "            ", "overlap", "=", "set", "(", "a", ".", "word_id", ")", "&", "set", "(", "b", ".", "word_id", ")", "\n", "if", "set", "(", "a", ".", "word_id", ")", "==", "set", "(", "b", ".", "word_id", ")", ":", "#  same ids exactly", "\n", "                ", "in_r", "=", "False", "\n", "for", "r", "in", "relations", ":", "\n", "                    ", "if", "r", ".", "arg1", "==", "a", ".", "entid", ":", "\n", "                        ", "e2r", "=", "b", "\n", "in_r", "=", "True", "\n", "other", "=", "a", "\n", "", "elif", "r", ".", "arg1", "==", "b", ".", "entid", ":", "\n", "                        ", "e2r", "=", "a", "\n", "in_r", "=", "True", "\n", "other", "=", "b", "\n", "", "elif", "r", ".", "arg2", "==", "a", ".", "entid", ":", "\n", "                        ", "e2r", "=", "b", "\n", "in_r", "=", "True", "\n", "other", "=", "a", "\n", "", "elif", "r", ".", "arg2", "==", "b", ".", "entid", ":", "\n", "                        ", "e2r", "=", "a", "\n", "in_r", "=", "True", "\n", "other", "=", "b", "\n", "", "", "if", "in_r", "==", "False", ":", "\n", "                    ", "e2r", "=", "b", "\n", "other", "=", "a", "\n", "", "todel", "+=", "[", "(", "'Entity {} ({}) in doc {} is same with {} ({}) -> ignore'", ".", "format", "(", "repr", "(", "e2r", ".", "name", ")", ",", "e2r", ".", "type", ",", "e2r", ".", "docid", ",", "repr", "(", "other", ".", "name", ")", ",", "other", ".", "type", ")", ",", "e2r", ")", "]", "\n", "\n", "#            elif bool(overlap):  # overlapping ranges", "\n", "\n", "#                # partial overlap -- ignore anyway", "\n", "#                if (len(list(overlap)) != len(a.word_id)) and (len(list(overlap)) != len(b.word_id)):", "\n", "#                    if len(a.word_id) > len(b.word_id):", "\n", "#                        other = a", "\n", "#                        e2r = b", "\n", "#                    else:", "\n", "#                        e2r = a  # remove shorter entity", "\n", "#                        other = b", "\n", "#                    if e2r not in todel:", "\n", "#                        todel += [('Entity {} in doc {} partially overlaps with {} -> ignore'.format(repr(e2r.name), e2r.docid, repr(other.name)), e2r)]", "\n", "\n", "# nested", "\n", "", "if", "(", "len", "(", "list", "(", "overlap", ")", ")", "==", "len", "(", "a", ".", "word_id", ")", ")", "or", "(", "len", "(", "list", "(", "overlap", ")", ")", "==", "len", "(", "b", ".", "word_id", ")", ")", ":", "\n", "                ", "if", "include_nested", ":", "\n", "                    ", "continue", "\n", "", "else", ":", "\n", "                    ", "in_r", "=", "False", "\n", "for", "r", "in", "relations", ":", "\n", "                        ", "if", "r", ".", "arg1", "==", "a", ".", "entid", ":", "\n", "                            ", "e2r", "=", "b", "\n", "in_r", "=", "True", "\n", "", "elif", "r", ".", "arg1", "==", "b", ".", "entid", ":", "\n", "                            ", "e2r", "=", "a", "\n", "in_r", "=", "True", "\n", "", "elif", "r", ".", "arg2", "==", "a", ".", "entid", ":", "\n", "                            ", "e2r", "=", "b", "\n", "in_r", "=", "True", "\n", "", "elif", "r", ".", "arg2", "==", "b", ".", "entid", ":", "\n", "                            ", "e2r", "=", "a", "\n", "in_r", "=", "True", "\n", "", "", "if", "in_r", "==", "False", ":", "\n", "                        ", "if", "len", "(", "a", ".", "word_id", ")", ">", "len", "(", "b", ".", "word_id", ")", ":", "\n", "                            ", "e2r", "=", "b", "\n", "", "else", ":", "\n", "                            ", "e2r", "=", "a", "# remove shorter entity", "\n", "", "", "if", "e2r", "not", "in", "todel", ":", "\n", "                        ", "todel", "+=", "[", "(", "'Entity {} in doc {} is nested -> ignore'", ".", "format", "(", "e2r", ".", "entid", ",", "e2r", ".", "docid", ")", ",", "e2r", ")", "]", "\n", "\n", "", "", "", "", "for", "e", "in", "entities", ":", "\n", "            ", "if", "not", "e", ".", "word_id", ":", "\n", "                ", "if", "e", "not", "in", "todel", ":", "\n", "                    ", "todel", "+=", "[", "(", "'Entity {} in doc {} not found in text -> ignore'", ".", "format", "(", "e", ".", "entid", ",", "e", ".", "docid", ")", ",", "e", ")", "]", "\n", "\n", "", "", "", "", "for", "txt", ",", "td", "in", "todel", ":", "\n", "        ", "tqdm", ".", "write", "(", "txt", ")", "\n", "if", "td", "in", "entities", ":", "\n", "            ", "entities", ".", "remove", "(", "td", ")", "\n", "", "", "return", "entities", ",", "len", "(", "todel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.tools.check_relations": [[396, 451], ["itertools.combinations", "tqdm.tqdm.write", "len", "relations.remove"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write"], ["", "def", "check_relations", "(", "entities", ",", "relations", ")", ":", "\n", "    ", "\"\"\"\n    Remove -- duplicate entries\n           -- relations with missing arguments\n    Args:\n        entities: (list of structs) entities\n        relations: (list of structs) relations\n    Returns: (list of structs) relations\n    \"\"\"", "\n", "todel", "=", "[", "]", "\n", "# check if entities are missing", "\n", "for", "r", "in", "relations", ":", "\n", "        ", "okA", "=", "False", "\n", "okB", "=", "False", "\n", "for", "e", "in", "entities", ":", "\n", "            ", "if", "r", ".", "arg1", "==", "e", ".", "entid", ":", "\n", "                ", "okA", "=", "True", "\n", "\n", "", "if", "r", ".", "arg2", "==", "e", ".", "entid", ":", "\n", "                ", "okB", "=", "True", "\n", "\n", "", "if", "okA", "and", "okB", ":", "\n", "                ", "break", "\n", "\n", "", "", "if", "okA", "and", "okB", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "todel", "+=", "[", "(", "'Relation {} in doc {} misses an entity -> ignore <<----------'", ".", "format", "(", "r", ".", "relid", ",", "r", ".", "docid", ")", ",", "r", ")", "]", "\n", "\n", "# check for duplicates", "\n", "", "", "for", "a", ",", "b", "in", "combinations", "(", "relations", ",", "2", ")", ":", "\n", "        ", "if", "(", "a", ".", "type", "==", "b", ".", "type", ")", "and", "(", "a", ".", "arg1", "==", "b", ".", "arg1", ")", "and", "(", "a", ".", "arg2", "==", "b", ".", "arg2", ")", ":", "\n", "            ", "todel", "+=", "[", "(", "'Relation {} in doc {} is duplicate -> ignore <<---------- {} same'", ".", "format", "(", "a", ".", "relid", ",", "r", ".", "docid", ",", "a", ".", "type", ")", ",", "a", ")", "]", "\n", "", "elif", "(", "a", ".", "type", "!=", "b", ".", "type", ")", "and", "(", "a", ".", "arg1", "==", "b", ".", "arg1", ")", "and", "(", "a", ".", "arg2", "==", "b", ".", "arg2", ")", ":", "\n", "            ", "if", "a", ".", "type", "==", "'Other'", ":", "\n", "                ", "todel", "+=", "[", "(", "'Relation {} in doc {} is duplicate -> ignore <<---------- {} {}'", ".", "format", "(", "a", ".", "relid", ",", "r", ".", "docid", ",", "a", ".", "type", ",", "b", ".", "type", ")", ",", "a", ")", "]", "\n", "", "elif", "b", ".", "type", "==", "'Other'", ":", "\n", "                ", "todel", "+=", "[", "(", "'Relation {} in doc {} is duplicate -> ignore <<---------- {} {}'", ".", "format", "(", "a", ".", "relid", ",", "r", ".", "docid", ",", "b", ".", "type", ",", "a", ".", "type", ")", ",", "b", ")", "]", "\n", "", "else", ":", "\n", "                ", "todel", "+=", "[", "(", "'Relation {} in doc {} is duplicate -> ignore <<---------- {} <>'", ".", "format", "(", "a", ".", "relid", ",", "r", ".", "docid", ",", "a", ".", "type", ")", ",", "a", ")", "]", "\n", "", "", "elif", "(", "a", ".", "type", "!=", "b", ".", "type", ")", "and", "(", "a", ".", "arg1", "==", "b", ".", "arg2", ")", "and", "(", "a", ".", "arg2", "==", "b", ".", "arg1", ")", ":", "\n", "            ", "if", "a", ".", "type", "==", "'Other'", ":", "\n", "                ", "todel", "+=", "[", "(", "'Relation {} in doc {} is duplicate -> ignore <<---------- {} {}'", ".", "format", "(", "a", ".", "relid", ",", "r", ".", "docid", ",", "a", ".", "type", ",", "b", ".", "type", ")", ",", "a", ")", "]", "\n", "", "elif", "b", ".", "type", "==", "'Other'", ":", "\n", "                ", "todel", "+=", "[", "(", "'Relation {} in doc {} is duplicate -> ignore <<---------- {} {}'", ".", "format", "(", "a", ".", "relid", ",", "r", ".", "docid", ",", "b", ".", "type", ",", "a", ".", "type", ")", ",", "b", ")", "]", "\n", "", "else", ":", "\n", "                ", "todel", "+=", "[", "(", "'Relation {} in doc {} is duplicate -> ignore <<---------- {} <>'", ".", "format", "(", "a", ".", "relid", ",", "r", ".", "docid", ",", "a", ".", "type", ")", ",", "a", ")", "]", "\n", "", "", "elif", "(", "a", ".", "type", "==", "b", ".", "type", ")", "and", "(", "a", ".", "arg1", "==", "b", ".", "arg2", ")", "and", "(", "a", ".", "arg2", "==", "b", ".", "arg1", ")", ":", "\n", "            ", "todel", "+=", "[", "(", "'Relation {} in doc {} is duplicate -> ignore <<---------- {} same reverse'", ".", "format", "(", "a", ".", "relid", ",", "r", ".", "docid", ",", "a", ".", "type", ")", ",", "a", ")", "]", "\n", "\n", "", "", "for", "txt", ",", "tdr", "in", "todel", ":", "\n", "        ", "tqdm", ".", "write", "(", "txt", ")", "\n", "if", "tdr", "in", "relations", ":", "\n", "            ", "relations", ".", "remove", "(", "tdr", ")", "\n", "", "", "return", "relations", ",", "len", "(", "todel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.tools.doc2sent": [[453, 502], ["collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "enumerate", "len", "len", "print", "print", "len", "print", "int", "numpy.sum", "len", "s.split"], "function", ["None"], ["", "def", "doc2sent", "(", "entities", ",", "relations", ",", "sentences", ")", ":", "\n", "    ", "\"\"\"\n    Map entities and relations to sentences.\n    Args:\n        entities: (list of structs) entities in document\n        relations: (list of structs) relations in document\n        sentences: (list) sentences in documents\n    Returns: (list of structs) entities in sents,\n             (list of structs) relations in sents,\n             (list) sents\n    \"\"\"", "\n", "new_entities", "=", "OrderedDict", "(", ")", "\n", "new_relations", "=", "OrderedDict", "(", ")", "\n", "new_sents", "=", "OrderedDict", "(", ")", "\n", "\n", "total_r", "=", "0", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "sentences", ")", ":", "\n", "        ", "new_sents", "[", "i", "]", "=", "s", "\n", "new_entities", "[", "i", "]", "=", "[", "]", "\n", "new_relations", "[", "i", "]", "=", "[", "]", "\n", "\n", "included_ents", "=", "[", "]", "\n", "for", "e", "in", "entities", ":", "\n", "            ", "if", "e", ".", "sent_no", "==", "i", ":", "\n", "                ", "take", "=", "e", "\n", "# TODO change the offsets as well", "\n", "take", ".", "word_id", "=", "[", "int", "(", "w", "-", "np", ".", "sum", "(", "[", "len", "(", "s", ".", "split", "(", "' '", ")", ")", "for", "s", "in", "sentences", "[", ":", "i", "]", "]", ")", ")", "for", "w", "in", "e", ".", "word_id", "]", "\n", "new_entities", "[", "i", "]", "+=", "[", "take", "]", "\n", "included_ents", "+=", "[", "take", ".", "entid", "]", "\n", "\n", "", "", "for", "r", "in", "relations", ":", "\n", "            ", "if", "(", "r", ".", "arg1", "in", "included_ents", ")", "and", "(", "r", ".", "arg2", "in", "included_ents", ")", ":", "\n", "                ", "new_relations", "[", "i", "]", "+=", "[", "r", "]", "\n", "\n", "", "", "total_r", "+=", "len", "(", "new_relations", "[", "i", "]", ")", "\n", "\n", "", "if", "total_r", "!=", "len", "(", "relations", ")", ":", "\n", "        ", "all_ids", "=", "[", "]", "\n", "for", "i", "in", "new_relations", ":", "\n", "            ", "print", "(", "new_sents", "[", "i", "]", ")", "\n", "for", "ir", "in", "new_relations", "[", "i", "]", ":", "\n", "                ", "all_ids", "+=", "[", "ir", ".", "relid", "]", "\n", "\n", "", "", "print", "(", "total_r", ",", "'<>'", ",", "len", "(", "relations", ")", ")", "# new_relations)", "\n", "for", "r", "in", "relations", ":", "\n", "            ", "if", "r", ".", "relid", "not", "in", "all_ids", ":", "\n", "                ", "print", "(", "r", ".", "relid", ")", "\n", "\n", "", "", "", "return", "new_sents", ",", "new_entities", ",", "new_relations", "\n", "", ""]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.reduce_embeds.load_pretrained_embeddings": [[15, 44], ["subprocess.run", "int", "collections.OrderedDict", "print", "collections.OrderedDict", "print", "open", "tqdm.tqdm", "subprocess.run.stdout.decode().split", "enumerate", "len", "map", "len", "subprocess.run.stdout.decode", "len", "line.rstrip().split", "line.rstrip().split", "line.rstrip().split", "len", "numpy.asarray", "line.split", "line.rstrip", "line.rstrip", "line.rstrip"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.nnet.trainer.Trainer.run"], ["def", "load_pretrained_embeddings", "(", "embeds", ",", "dim", ")", ":", "\n", "    ", "\"\"\"\n        :param params: input parameters\n        :returns\n            dictionary with words (keys) and embeddings (values)\n    \"\"\"", "\n", "if", "embeds", ":", "\n", "        ", "result", "=", "subprocess", ".", "run", "(", "[", "'wc'", ",", "'-l'", ",", "embeds", "]", ",", "stdout", "=", "subprocess", ".", "PIPE", ")", "\n", "lens", "=", "int", "(", "result", ".", "stdout", ".", "decode", "(", "'utf-8'", ")", ".", "split", "(", "' '", ")", "[", "0", "]", ")", "\n", "\n", "E", "=", "OrderedDict", "(", ")", "\n", "with", "open", "(", "embeds", ",", "'r'", ")", "as", "vectors", ":", "\n", "            ", "for", "x", ",", "line", "in", "tqdm", "(", "enumerate", "(", "vectors", ")", ",", "desc", "=", "'Loading embeddings'", ",", "total", "=", "lens", ")", ":", "\n", "                ", "if", "x", "==", "0", "and", "len", "(", "line", ".", "split", "(", ")", ")", "==", "2", ":", "\n", "                    ", "words", ",", "num", "=", "map", "(", "int", ",", "line", ".", "rstrip", "(", ")", ".", "split", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "word", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", ")", "[", "0", "]", "\n", "vec", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", ")", "[", "1", ":", "]", "\n", "n", "=", "len", "(", "vec", ")", "\n", "if", "len", "(", "vec", ")", "!=", "dim", ":", "\n", "# print('Wrong dimensionality: {} {} != {}'.format(word, len(vec), num))", "\n", "                        ", "continue", "\n", "", "else", ":", "\n", "                        ", "E", "[", "word", "]", "=", "np", ".", "asarray", "(", "vec", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "", "", "", "print", "(", "'Pre-trained word embeddings: {} x {}'", ".", "format", "(", "len", "(", "E", ")", ",", "n", ")", ")", "\n", "", "else", ":", "\n", "        ", "E", "=", "OrderedDict", "(", ")", "\n", "print", "(", "'No pre-trained word embeddings loaded.'", ")", "\n", "", "return", "E", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.reduce_embeds.main": [[46, 93], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "print", "list", "set", "set", "reduce_embeds.load_pretrained_embeddings", "collections.OrderedDict", "tqdm.tqdm", "print", "print", "print", "map", "load_pretrained_embeddings.keys", "open", "collections.OrderedDict.items", "open", "len", "outfile.write", "len", "line.split.split", "x.lower", "line.split.strip().split", "l.split", "set.append", "map", "line.split.strip", "list"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.reduce_embeds.load_pretrained_embeddings", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--full_embeds'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--out_embeds'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--in_data'", ",", "nargs", "=", "'+'", ")", "\n", "parser", ".", "add_argument", "(", "'--dim'", ",", "type", "=", "int", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "words", "=", "[", "]", "\n", "print", "(", "'\\nExtracting words from the dataset ... '", ")", "\n", "\n", "for", "filef", "in", "args", ".", "in_data", ":", "\n", "        ", "with", "open", "(", "filef", ",", "'r'", ")", "as", "infile", ":", "\n", "            ", "for", "line", "in", "infile", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "[", "1", "]", "\n", "line", "=", "line", ".", "split", "(", "'|'", ")", "\n", "line", "=", "[", "l", ".", "split", "(", "' '", ")", "for", "l", "in", "line", "]", "\n", "line", "=", "[", "item", "for", "sublist", "in", "line", "for", "item", "in", "sublist", "]", "\n", "\n", "for", "l", "in", "line", ":", "\n", "                    ", "words", ".", "append", "(", "l", ")", "\n", "\n", "# make lowercase", "\n", "", "", "", "", "words_lower", "=", "list", "(", "map", "(", "lambda", "x", ":", "x", ".", "lower", "(", ")", ",", "words", ")", ")", "\n", "words", "=", "set", "(", "words", ")", "\n", "words_lower", "=", "set", "(", "words_lower", ")", "# lowercased", "\n", "\n", "# Load embeddings", "\n", "embeddings", "=", "load_pretrained_embeddings", "(", "args", ".", "full_embeds", ",", "args", ".", "dim", ")", "\n", "\n", "new_embeds", "=", "OrderedDict", "(", ")", "\n", "for", "w", "in", "tqdm", "(", "embeddings", ".", "keys", "(", ")", ",", "desc", "=", "'Matching words'", ")", ":", "\n", "        ", "if", "(", "w", "in", "words", ")", "or", "(", "w", "in", "words_lower", ")", ":", "\n", "            ", "if", "w", "not", "in", "new_embeds", ":", "\n", "                ", "new_embeds", "[", "w", "]", "=", "embeddings", "[", "w", "]", "\n", "\n", "", "", "", "print", "(", "'Writing final embeddings {} x {} ... '", ".", "format", "(", "len", "(", "new_embeds", ")", ",", "args", ".", "dim", ")", ",", "end", "=", "\"\"", ")", "\n", "with", "open", "(", "args", ".", "out_embeds", ",", "'w'", ")", "as", "outfile", ":", "\n", "        ", "for", "k", ",", "v", "in", "new_embeds", ".", "items", "(", ")", ":", "\n", "            ", "outfile", ".", "write", "(", "'{} {}\\n'", ".", "format", "(", "k", ",", "' '", ".", "join", "(", "map", "(", "str", ",", "list", "(", "v", ")", ")", ")", ")", ")", "\n", "", "", "print", "(", "'Done'", ")", "\n", "\n", "coverage", "=", "0", "\n", "for", "w", "in", "words", ":", "\n", "        ", "if", "w", "in", "new_embeds", ":", "\n", "            ", "coverage", "+=", "1", "\n", "", "", "print", "(", "'Coverage (words in embeds/total words): {}/{}'", ".", "format", "(", "coverage", ",", "len", "(", "words", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.process.write2file": [[24, 53], ["tools.check_entities", "tools.check_relations", "tools.generate_pairs_types", "tools.generate_pairs", "data_out.write", "pairs.items", "data_out.write", "data_out.write", "data_out.write", "data_out.write", "new_sents.lower", "p.arg1.name.lower", "p.arg2.name.lower"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.tools.check_entities", "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.tools.check_relations", "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.tools.generate_pairs_types", "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.tools.generate_pairs", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write"], ["def", "write2file", "(", "new_sents", ",", "new_entities", ",", "new_relations", ",", "args", ",", "doc_id", ",", "data_out", ",", "not_found", ",", "positive", ",", "negative", ",", "no_pairs", ")", ":", "\n", "# generate pairs", "\n", "    ", "new_entities", ",", "missed_ents", "=", "check_entities", "(", "new_entities", ",", "new_relations", ",", "include_nested", "=", "args", ".", "nested", ")", "\n", "new_relations", ",", "missed_rels", "=", "check_relations", "(", "new_entities", ",", "new_relations", ")", "\n", "\n", "if", "args", ".", "type1", "and", "args", ".", "type2", ":", "\n", "        ", "pairs", ",", "cnf", "=", "generate_pairs_types", "(", "new_entities", ",", "args", ".", "type1", ",", "args", ".", "type2", ",", "new_relations", ")", "\n", "", "else", ":", "\n", "        ", "pairs", ",", "cnf", "=", "generate_pairs", "(", "new_entities", ",", "new_relations", ")", "\n", "", "not_found", "+=", "cnf", "\n", "\n", "if", "not", "pairs", ":", "\n", "        ", "no_pairs", "+=", "1", "\n", "", "else", ":", "\n", "        ", "data_out", ".", "write", "(", "'{}\\t{}'", ".", "format", "(", "doc_id", ",", "new_sents", ".", "lower", "(", ")", ")", ")", "\n", "\n", "for", "args_", ",", "p", "in", "pairs", ".", "items", "(", ")", ":", "\n", "            ", "if", "p", ".", "type", "!=", "'1:NR:2'", "and", "p", ".", "type", "!=", "'not_include'", ":", "\n", "                ", "positive", "+=", "1", "\n", "", "elif", "p", ".", "type", "==", "'1:NR:2'", ":", "\n", "                ", "negative", "+=", "1", "\n", "\n", "", "data_out", ".", "write", "(", "'\\t{}\\t{}\\t{}'", ".", "format", "(", "p", ".", "type", ",", "p", ".", "dir", ",", "p", ".", "cross", ")", ")", "\n", "data_out", ".", "write", "(", "'\\t{}\\t{}\\t{}\\t{}\\t{}'", ".", "format", "(", "p", ".", "arg1", ".", "entid", ",", "p", ".", "arg1", ".", "name", ".", "lower", "(", ")", ",", "p", ".", "arg1", ".", "type", ",", "\n", "p", ".", "arg1", ".", "word_id", "[", "0", "]", ",", "p", ".", "arg1", ".", "word_id", "[", "-", "1", "]", "+", "1", ")", ")", "\n", "data_out", ".", "write", "(", "'\\t{}\\t{}\\t{}\\t{}\\t{}'", ".", "format", "(", "p", ".", "arg2", ".", "entid", ",", "p", ".", "arg2", ".", "name", ".", "lower", "(", ")", ",", "p", ".", "arg2", ".", "type", ",", "\n", "p", ".", "arg2", ".", "word_id", "[", "0", "]", ",", "p", ".", "arg2", ".", "word_id", "[", "-", "1", "]", "+", "1", ")", ")", "\n", "", "data_out", ".", "write", "(", "'\\n'", ")", "\n", "", "return", "not_found", ",", "positive", ",", "negative", ",", "no_pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.process.read_brat": [[55, 100], ["collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "tqdm.tqdm", "print", "print", "os.path.exists", "os.makedirs", "glob.glob", "print", "[].split", "open", "open", "print", "sum", "sum", "line.rstrip().split.startswith", "len", "TextStruct", "line.rstrip().split.rstrip().split", "line[].split", "line.rstrip().split.startswith", "len", "len", "len", "filef.split", "line.rstrip().split.rstrip", "EntStruct", "line.rstrip().split.rstrip().split", "line[].split", "collections.OrderedDict.values", "collections.OrderedDict.values", "line.rstrip().split.rstrip", "int", "int", "RelStruct", "line.rstrip().split.rstrip", "region[].split", "region[].split"], "function", ["None"], ["", "def", "read_brat", "(", "args", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_file", "+", "'_files'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "output_file", "+", "'_files'", ")", "\n", "\n", "", "abstracts", "=", "OrderedDict", "(", ")", "\n", "entities", "=", "OrderedDict", "(", ")", "\n", "relations", "=", "OrderedDict", "(", ")", "\n", "\n", "for", "filef", "in", "tqdm", "(", "glob", "(", "args", ".", "input_folder", "+", "'*.txt'", ")", ",", "desc", "=", "'Reading'", ")", ":", "\n", "        ", "filename", "=", "filef", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.txt'", ")", "[", "0", "]", "\n", "\n", "if", "filename", "not", "in", "abstracts", ":", "\n", "            ", "abstracts", "[", "filename", "]", "=", "[", "]", "\n", "", "if", "filename", "not", "in", "entities", ":", "\n", "            ", "entities", "[", "filename", "]", "=", "[", "]", "\n", "", "if", "filename", "not", "in", "relations", ":", "\n", "            ", "relations", "[", "filename", "]", "=", "[", "]", "\n", "\n", "", "with", "open", "(", "filef", ",", "'r'", ")", "as", "infile", ":", "\n", "            ", "for", "line", "in", "infile", ":", "\n", "                ", "abstracts", "[", "filename", "]", "+=", "[", "TextStruct", "(", "filename", ",", "line", ".", "rstrip", "(", ")", ")", "]", "\n", "\n", "", "", "with", "open", "(", "args", ".", "input_folder", "+", "filename", "+", "'.ann'", ",", "'r'", ")", "as", "infile", ":", "\n", "            ", "for", "line", "in", "infile", ":", "\n", "                ", "if", "line", ".", "startswith", "(", "'T'", ")", ":", "\n", "                    ", "line", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "'\\t'", ",", "2", ")", "\n", "region", "=", "line", "[", "1", "]", ".", "split", "(", "' '", ")", "\n", "entities", "[", "filename", "]", "+=", "[", "EntStruct", "(", "filename", ",", "line", "[", "0", "]", ",", "line", "[", "2", "]", ",", "int", "(", "region", "[", "1", "]", ")", ",", "int", "(", "region", "[", "2", "]", ")", ",", "\n", "region", "[", "0", "]", ",", "-", "1", ",", "[", "]", ")", "]", "\n", "\n", "", "elif", "line", ".", "startswith", "(", "'R'", ")", ":", "\n", "                    ", "line", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "region", "=", "line", "[", "1", "]", ".", "split", "(", "' '", ")", "\n", "relations", "[", "filename", "]", "+=", "[", "RelStruct", "(", "filename", ",", "line", "[", "0", "]", ",", "region", "[", "0", "]", ",", "region", "[", "1", "]", ".", "split", "(", "'Arg1:'", ")", "[", "1", "]", ",", "\n", "region", "[", "2", "]", ".", "split", "(", "'Arg2:'", ")", "[", "1", "]", ")", "]", "\n", "\n", "", "", "", "", "if", "args", ".", "level", "==", "'doc'", ":", "\n", "        ", "print", "(", "'# Documents: {}'", ".", "format", "(", "len", "(", "abstracts", ")", ")", ")", "\n", "", "elif", "args", ".", "level", "==", "'sent'", ":", "\n", "        ", "print", "(", "'# Sentences: {}'", ".", "format", "(", "len", "(", "abstracts", ")", ")", ")", "\n", "\n", "", "print", "(", "'# Entities: {}'", ".", "format", "(", "sum", "(", "[", "len", "(", "e", ")", "for", "e", "in", "entities", ".", "values", "(", ")", "]", ")", ")", ")", "\n", "print", "(", "'# Pairs: {}'", ".", "format", "(", "sum", "(", "[", "len", "(", "r", ")", "for", "r", "in", "relations", ".", "values", "(", ")", "]", ")", ")", ")", "\n", "\n", "return", "abstracts", ",", "entities", ",", "relations", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.process.main": [[102, 184], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "process.read_brat", "tqdm.tqdm", "print", "print", "print", "print", "print", "list", "open", "abstracts.keys", "tqdm.tqdm.set_description", "len", "tools.fix_sent_break", "tools.adjust_offsets", "tools.offsets2tokids", "tools.ent2sent", "tools.offsets2tokids", "tools.ent2sent", "tools.doc2sent", "new_sents.keys", "process.write2file", "utils.sentence_split_genia", "utils.sentence_split_stanford", "open", "f.write", "utils.tokenize_genia", "utils.tokenize_stanford", "open", "f.write", "process.write2file", "item.replace", "a.txt.split", "a.txt.split", "str", "str"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.process.read_brat", "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.tools.fix_sent_break", "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.tools.adjust_offsets", "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.tools.offsets2tokids", "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.tools.ent2sent", "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.tools.offsets2tokids", "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.tools.ent2sent", "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.tools.doc2sent", "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.process.write2file", "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.utils.sentence_split_genia", "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.utils.sentence_split_stanford", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write", "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.utils.tokenize_genia", "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.utils.tokenize_stanford", "home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write", "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.process.write2file"], ["", "def", "main", "(", ")", ":", "\n", "    ", "\"\"\"\n    Main processing function\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--input_folder'", ",", "'-i'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--output_file'", ",", "'-o'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--level'", ",", "choices", "=", "[", "'doc'", ",", "'sent'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--domain'", ",", "choices", "=", "[", "'gen'", ",", "'bio'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--processed'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--nested'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--type1'", ",", "nargs", "=", "'*'", ")", "\n", "parser", ".", "add_argument", "(", "'--type2'", ",", "nargs", "=", "'*'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "abstracts", ",", "entities", ",", "relations", "=", "read_brat", "(", "args", ")", "\n", "not_found", ",", "positive", ",", "negative", ",", "no_pairs", "=", "0", ",", "0", ",", "0", ",", "0", "\n", "all_ents", "=", "0", "\n", "\n", "pbar", "=", "tqdm", "(", "list", "(", "abstracts", ".", "keys", "(", ")", ")", ")", "\n", "with", "open", "(", "args", ".", "output_file", "+", "'.data'", ",", "'w'", ")", "as", "data_out", ":", "\n", "        ", "for", "i", "in", "pbar", ":", "\n", "            ", "pbar", ".", "set_description", "(", "\"Processing DOC_ID {}\"", ".", "format", "(", "i", ")", ")", "\n", "\n", "if", "not", "args", ".", "processed", ":", "\n", "# sentence splitting", "\n", "                ", "orig_sentences", "=", "[", "item", "for", "sublist", "in", "[", "a", ".", "txt", ".", "split", "(", "'\\n'", ")", "for", "a", "in", "abstracts", "[", "i", "]", "]", "for", "item", "in", "sublist", "]", "\n", "orig_sentences", "=", "[", "item", ".", "replace", "(", "''", ",", "' '", ")", "if", "item", "==", "''", "else", "item", "for", "item", "in", "orig_sentences", "]", "\n", "\n", "if", "args", ".", "domain", "==", "'bio'", ":", "\n", "                    ", "split_sents", "=", "sentence_split_genia", "(", "orig_sentences", ")", "\n", "", "else", ":", "\n", "                    ", "split_sents", "=", "sentence_split_stanford", "(", "orig_sentences", ")", "\n", "", "split_sents", "=", "fix_sent_break", "(", "split_sents", ",", "entities", "[", "i", "]", ")", "\n", "\n", "with", "open", "(", "args", ".", "output_file", "+", "'_files/'", "+", "i", "+", "'.split.txt'", ",", "'w'", ")", "as", "f", ":", "\n", "                    ", "f", ".", "write", "(", "'\\n'", ".", "join", "(", "split_sents", ")", ")", "\n", "\n", "# tokenisation", "\n", "", "if", "args", ".", "domain", "==", "'bio'", ":", "\n", "                    ", "token_sents", "=", "tokenize_genia", "(", "split_sents", ")", "\n", "", "else", ":", "\n", "                    ", "token_sents", "=", "tokenize_stanford", "(", "split_sents", ")", "\n", "\n", "", "with", "open", "(", "args", ".", "output_file", "+", "'_files/'", "+", "i", "+", "'.split.tok.txt'", ",", "'w'", ")", "as", "f", ":", "\n", "                    ", "f", ".", "write", "(", "'\\n'", ".", "join", "(", "token_sents", ")", ")", "\n", "\n", "# adjust offsets", "\n", "", "new_entities", "=", "adjust_offsets", "(", "orig_sentences", ",", "token_sents", ",", "entities", "[", "i", "]", ")", "\n", "new_entities", "=", "offsets2tokids", "(", "token_sents", ",", "new_entities", ")", "\n", "new_entities", "=", "ent2sent", "(", "token_sents", ",", "new_entities", ")", "\n", "sentences", "=", "token_sents", "\n", "\n", "", "else", ":", "\n", "                ", "new_entities", "=", "entities", "[", "i", "]", "\n", "sentences", "=", "[", "item", "for", "sublist", "in", "[", "a", ".", "txt", ".", "split", "(", "'\\n'", ")", "for", "a", "in", "abstracts", "[", "i", "]", "]", "for", "item", "in", "sublist", "]", "\n", "new_entities", "=", "offsets2tokids", "(", "sentences", ",", "new_entities", ")", "\n", "new_entities", "=", "ent2sent", "(", "sentences", ",", "new_entities", ")", "\n", "\n", "# from doc to sentence", "\n", "", "if", "args", ".", "level", "==", "'doc'", ":", "\n", "                ", "new_sents", ",", "new_entities", ",", "new_relations", "=", "doc2sent", "(", "new_entities", ",", "relations", "[", "i", "]", ",", "sentences", ")", "\n", "\n", "for", "s_id", "in", "new_sents", ".", "keys", "(", ")", ":", "\n", "                    ", "not_found", ",", "positive", ",", "negative", ",", "no_pairs", "=", "write2file", "(", "new_sents", "[", "s_id", "]", ",", "new_entities", "[", "s_id", "]", ",", "new_relations", "[", "s_id", "]", ",", "\n", "args", ",", "str", "(", "i", ")", "+", "'**'", "+", "str", "(", "s_id", ")", ",", "\n", "data_out", ",", "\n", "not_found", ",", "positive", ",", "negative", ",", "no_pairs", ")", "\n", "\n", "", "", "else", ":", "\n", "                ", "new_relations", "=", "relations", "[", "i", "]", "\n", "not_found", ",", "positive", ",", "negative", ",", "no_pairs", "=", "write2file", "(", "' '", ".", "join", "(", "sentences", ")", ",", "new_entities", ",", "new_relations", ",", "args", ",", "i", ",", "\n", "data_out", ",", "not_found", ",", "positive", ",", "negative", ",", "no_pairs", ")", "\n", "", "all_ents", "+=", "len", "(", "new_entities", ")", "\n", "\n", "", "", "print", "(", "'Total positive pairs:'", ",", "positive", ")", "\n", "print", "(", "'Total negative pairs:'", ",", "negative", ")", "\n", "print", "(", "'Total not found pairs:'", ",", "not_found", ")", "\n", "print", "(", "'Sentences without pairs:'", ",", "no_pairs", ")", "\n", "print", "(", "'Entities:'", ",", "all_ents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.utils.using_split2": [[34, 51], ["line.split", "index", "_len", "append"], "function", ["None"], ["", "log_file", "=", "os", ".", "path", ".", "join", "(", "model_folder", ",", "'info_'", "+", "mode", "+", "'.log'", ")", "\n", "\n", "f", "=", "open", "(", "log_file", ",", "'w'", ")", "\n", "sys", ".", "stdout", "=", "Tee", "(", "sys", ".", "stdout", ",", "f", ")", "\n", "return", "model_folder", "\n", "\n", "\n", "", "class", "Tee", "(", "object", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "*", "files", ")", ":", "\n", "        ", "self", ".", "files", "=", "files", "\n", "\n", "", "def", "write", "(", "self", ",", "obj", ")", ":", "\n", "        ", "for", "f_", "in", "self", ".", "files", ":", "\n", "            ", "f_", ".", "write", "(", "obj", ")", "\n", "f_", ".", "flush", "(", ")", "# If you want the output to be visible immediately", "\n", "\n", "", "", "def", "flush", "(", "self", ")", ":", "\n", "        ", "for", "f_", "in", "self", ".", "files", ":", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.utils.replace2symbol": [[53, 60], ["string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace", "string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace", "string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace", "string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace", "string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace", "string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace", "string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace", "string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace", "string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace"], "function", ["None"], ["\n", "\n", "", "", "", "def", "ordered_load", "(", "stream", ",", "loader", "=", "yaml", ".", "Loader", ",", "object_pairs_hook", "=", "OrderedDict", ")", ":", "\n", "    ", "\"\"\"\n    Load yaml parameters in order\n    \"\"\"", "\n", "class", "OrderedLoader", "(", "loader", ")", ":", "\n", "        ", "pass", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.utils.replace2space": [[62, 69], ["string.replace.replace"], "function", ["None"], ["", "def", "construct_mapping", "(", "loader_", ",", "node", ")", ":", "\n", "        ", "loader", ".", "flatten_mapping", "(", "node", ")", "\n", "return", "object_pairs_hook", "(", "loader_", ".", "construct_pairs", "(", "node", ")", ")", "\n", "\n", "", "OrderedLoader", ".", "add_constructor", "(", "\n", "yaml", ".", "resolver", ".", "BaseResolver", ".", "DEFAULT_MAPPING_TAG", ",", "\n", "construct_mapping", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.utils.sentence_split_stanford": [[71, 82], ["nlp.annotate", "split_lines.append"], "function", ["None"], ["\n", "\n", "", "def", "humanized_time", "(", "second", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        second: time in seconds\n    Returns: human readable time (hours, minutes, seconds)\n    \"\"\"", "\n", "m", ",", "s", "=", "divmod", "(", "second", ",", "60", ")", "\n", "h", ",", "m", "=", "divmod", "(", "m", ",", "60", ")", "\n", "return", "\"%dh %02dm %02ds\"", "%", "(", "h", ",", "m", ",", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.utils.tokenize_stanford": [[84, 120], ["enumerate", "nlp.annotate", "enumerate", "re.sub().strip.replace", "re.sub().strip.replace", "re.sub().strip.replace", "re.sub().strip.replace", "re.sub().strip.replace", "re.sub().strip.replace", "re.sub().strip.replace", "re.sub().strip.replace", "re.sub().strip.replace", "re.sub().strip.replace", "re.sub().strip.replace", "re.sub().strip.replace", "re.sub().strip.replace", "re.sub().strip.replace", "re.sub().strip.replace", "re.sub().strip", "token_sents.append", "re.sub().strip.append", "re.sub", "re.sub().strip.append", "re.sub().strip.append", "t.replace"], "function", ["None"], ["", "def", "observe", "(", "model", ")", ":", "\n", "    ", "\"\"\"\n    Observe model parameters: name, range of matrices & gradients\n\n    Args:\n        model: specified model object\n    \"\"\"", "\n", "for", "p_name", ",", "param", "in", "model", ".", "namedparams", "(", ")", ":", "\n", "        ", "p_data", ",", "p_grad", "=", "param", ".", "data", ",", "param", ".", "grad", "\n", "print", "(", "'Name: %s, Range of data: [%f, %f], Range of gradient: [%f, %f]'", "%", "\n", "(", "p_name", ",", "np", ".", "min", "(", "chainer", ".", "cuda", ".", "to_cpu", "(", "p_data", ".", "data", ")", ")", ",", "\n", "np", ".", "max", "(", "chainer", ".", "cuda", ".", "to_cpu", "(", "p_data", ".", "data", ")", ")", ",", "\n", "np", ".", "min", "(", "chainer", ".", "cuda", ".", "to_cpu", "(", "p_grad", ".", "data", ")", ")", ",", "\n", "np", ".", "max", "(", "chainer", ".", "cuda", ".", "to_cpu", "(", "p_grad", ".", "data", ")", ")", ")", ")", "\n", "\n", "\n", "", "", "def", "plot_learning_curve", "(", "trainer", ",", "model_folder", ")", ":", "\n", "    ", "\"\"\"\n    Plot the learning curves for training and test set (loss and primary score measure)\n\n    Args:\n        trainer (Class): trainer object\n        model_folder (str): folder to save figures\n    \"\"\"", "\n", "print", "(", "'Plotting learning curves ... '", ",", "end", "=", "\"\"", ")", "\n", "x", "=", "list", "(", "map", "(", "int", ",", "np", ".", "arange", "(", "len", "(", "trainer", ".", "train_res", "[", "'loss'", "]", ")", ")", ")", ")", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "subplot", "(", "2", ",", "1", ",", "1", ")", "\n", "plt", ".", "plot", "(", "x", ",", "trainer", ".", "train_res", "[", "'loss'", "]", ",", "'b'", ",", "label", "=", "'train'", ")", "\n", "plt", ".", "plot", "(", "x", ",", "trainer", ".", "test_res", "[", "'loss'", "]", ",", "'g'", ",", "label", "=", "'test'", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "ylabel", "(", "'Loss'", ")", "\n", "plt", ".", "yticks", "(", "np", ".", "arange", "(", "0", ",", "1", ",", "0.1", ")", ")", "\n", "plt", ".", "xticks", "(", "x", ")", "\n", "\n", "plt", ".", "subplot", "(", "2", ",", "1", ",", "2", ")", "\n", "plt", ".", "plot", "(", "x", ",", "trainer", ".", "train_res", "[", "'score'", "]", ",", "'b'", ",", "label", "=", "'train'", ")", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.utils.sentence_split_genia": [[122, 187], ["os.chdir", "os.system", "os.system", "os.chdir", "open", "open", "ofile.write", "len", "line.rstrip().endswith", "line.rstrip().endswith", "split_lines.append", "line.rstrip", "line.rstrip", "line.rstrip().endswith", "line.rstrip", "line.rstrip", "line.rstrip().endswith", "line.rstrip", "line.rstrip", "line.rstrip", "line.rstrip", "line.rstrip", "line.rstrip", "line.rstrip"], "function", ["home.repos.pwc.inspect_result.fenchri_walk-based-re.src.utils.Tee.write"], ["plt", ".", "legend", "(", ")", "\n", "plt", ".", "ylabel", "(", "'F1-score'", ")", "\n", "plt", ".", "xlabel", "(", "'Epochs'", ")", "\n", "plt", ".", "yticks", "(", "np", ".", "arange", "(", "0", ",", "1", ",", "0.1", ")", ")", "\n", "plt", ".", "xticks", "(", "x", ")", "\n", "\n", "fig", ".", "savefig", "(", "model_folder", "+", "'/learn_curves.png'", ",", "bbox_inches", "=", "'tight'", ")", "\n", "print", "(", "'END'", ")", "\n", "\n", "\n", "", "def", "print_hyperparams", "(", "model_0", ")", ":", "\n", "    ", "print", "(", "\"\"\"\\nModel hyper-parameters:\n                - learn   {}\n                - reg     {}\n                - dropi   {}\n                - dropo   {}\n                - type    {}\n                - pos     {}\n                - gradc   {} \n                - out_dim {}\n                - beta    {} \"\"\"", ".", "format", "(", "model_0", ".", "lr", ",", "\n", "model_0", ".", "reg", ",", "\n", "model_0", ".", "dropi", ",", "\n", "model_0", ".", "dropo", ",", "\n", "model_0", ".", "type_dim", ",", "\n", "model_0", ".", "pos_dim", ",", "\n", "model_0", ".", "gc", ",", "\n", "model_0", ".", "out_dim", ",", "\n", "model_0", ".", "beta", ")", ")", "\n", "\n", "\n", "", "def", "print_options", "(", "model_0", ",", "parameters", ")", ":", "\n", "    ", "print", "(", "\"\"\"\\nModel options:\n             - Train Data  {}\n             - Test Data   {}\n             - Embeddings  {}\n             - Save folder {}\n             - batchsize   {}\n\n             - walks_iter   {} --> Length = {}\n             - att          {}\n             - param_avg    {}\n             - nested       {}\n             - early_metric {}\n             - direction    {}\n             - lowercase    {}\\n\"\"\"", ".", "format", "(", "parameters", "[", "'train_data'", "]", ",", "parameters", "[", "'test_data'", "]", ",", "\n", "parameters", "[", "'embeds'", "]", ",", "parameters", "[", "'folder'", "]", ",", "\n", "parameters", "[", "'batch'", "]", ",", "\n", "model_0", ".", "walks_iter", ",", "2", "**", "parameters", "[", "'walks_iter'", "]", ",", "\n", "model_0", ".", "att", ",", "\n", "parameters", "[", "'param_avg'", "]", ",", "\n", "parameters", "[", "'nested'", "]", ",", "\n", "parameters", "[", "'early_metric'", "]", ",", "\n", "parameters", "[", "'direction'", "]", ",", "\n", "parameters", "[", "'lowercase'", "]", ")", ")", "\n", "\n", "\n", "", "def", "save_model", "(", "model_folder", ",", "model_0", ",", "loader", ")", ":", "\n", "    ", "print", "(", "'Saving the model ... '", ",", "end", "=", "\"\"", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "model_folder", ",", "'mappings.pkl'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pkl", ".", "dump", "(", "loader", ",", "f", ",", "pkl", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "torch", ".", "save", "(", "model_0", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "model_folder", ",", "'re.model'", ")", ")", "\n", "print", "(", "'END'", ")", "\n", "\n", "\n", "", "def", "load_model", "(", "model_folder", ",", "m", ")", ":", "\n"]], "home.repos.pwc.inspect_result.fenchri_walk-based-re.data_processing.utils.tokenize_genia": [[189, 243], ["enumerate", "genia_tagger.tag", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "re.sub().strip", "token_sents.append", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.append", "re.sub", "text.replace.append", "text.replace.append", "t.replace"], "function", ["None"], ["m", ".", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "model_folder", ",", "'re.model'", ")", ",", "map_location", "=", "m", ".", "model", ".", "device", ")", ")", "\n", "print", "(", "'END'", ")", "\n", "return", "m", "\n", "\n", "\n", "", "def", "print_results", "(", "scores", ",", "show_class", ",", "time", ")", ":", "\n", "    ", "def", "indent", "(", "txt", ",", "spaces", "=", "18", ")", ":", "\n", "        ", "return", "\"\\n\"", ".", "join", "(", "\" \"", "*", "spaces", "+", "ln", "for", "ln", "in", "txt", ".", "splitlines", "(", ")", ")", "\n", "\n", "", "if", "show_class", ":", "\n", "# print results for every class", "\n", "        ", "scores", "[", "'per_class'", "]", ".", "append", "(", "[", "'-----'", ",", "None", ",", "None", ",", "None", "]", ")", "\n", "scores", "[", "'per_class'", "]", ".", "append", "(", "[", "'macro score'", ",", "scores", "[", "'macro_p'", "]", ",", "scores", "[", "'macro_r'", "]", ",", "scores", "[", "'macro_f'", "]", "]", ")", "\n", "scores", "[", "'per_class'", "]", ".", "append", "(", "[", "'micro score'", ",", "scores", "[", "'micro_p'", "]", ",", "scores", "[", "'micro_r'", "]", ",", "scores", "[", "'micro_f'", "]", "]", ")", "\n", "print", "(", "' | Elapsed time: {}\\n'", ".", "format", "(", "humanized_time", "(", "time", ")", ")", ")", "\n", "print", "(", "indent", "(", "tabulate", "(", "scores", "[", "'per_class'", "]", ",", "\n", "headers", "=", "[", "'Class'", ",", "'P'", ",", "'R'", ",", "'F1'", "]", ",", "\n", "tablefmt", "=", "'orgtbl'", ",", "\n", "floatfmt", "=", "\".4f\"", ",", "\n", "missingval", "=", "\"\"", ")", ")", ")", "\n", "print", "(", ")", "\n", "", "else", ":", "\n", "# print overall scores", "\n", "        ", "print", "(", "' | MICRO P/R/F1 = {:.04f}\\t{:.04f}\\t{:.04f} | '", "\n", "'MACRO P/R/F1 = {:.04f}\\t{:.04f}\\t{:.04f} | '", ".", "format", "(", "scores", "[", "'micro_p'", "]", ",", "scores", "[", "'micro_r'", "]", ",", "\n", "scores", "[", "'micro_f'", "]", ",", "scores", "[", "'macro_p'", "]", ",", "\n", "scores", "[", "'macro_r'", "]", ",", "scores", "[", "'macro_f'", "]", ")", ",", "end", "=", "\"\"", ")", "\n", "\n", "print", "(", "'TP/ACTUAL/PRED {:<6}/{:<6}/{:<6} TOTAL {}'", ".", "format", "(", "scores", "[", "'tp'", "]", ",", "scores", "[", "'actual'", "]", ",", "scores", "[", "'pred'", "]", ",", "\n", "scores", "[", "'total'", "]", ")", ",", "end", "=", "\"\"", ")", "\n", "print", "(", "' | {}'", ".", "format", "(", "humanized_time", "(", "time", ")", ")", ")", "\n", "\n", "\n", "", "", "def", "write_pred2file", "(", "predicts", ",", "probabs", ",", "rels_info", ",", "savef", ",", "rel_map", ")", ":", "\n", "    ", "\"\"\"\n    Write predictions to specific file in 'savef' folder\n    Args:\n        predicts: predictions\n        rels_info: gold relations information\n        savef: save folder\n        rel_map: mapping of relation types\n    \"\"\"", "\n", "print", "(", "'Writing predictions to file ... '", ",", "end", "=", "\"\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "savef", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "savef", ")", "\n", "\n", "", "assert", "len", "(", "predicts", ")", "==", "len", "(", "rels_info", ")", "==", "len", "(", "probabs", ")", ",", "'{} predictions != {} relations != {} probabilities'", ".", "format", "(", "len", "(", "predicts", ")", ",", "len", "(", "rels_info", ")", ",", "len", "(", "probabs", ")", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "savef", ",", "'preds.txt'", ")", ",", "'w'", ")", "as", "outfile", ":", "\n", "        ", "for", "pred", ",", "prob", ",", "pair_info", "in", "zip", "(", "predicts", ",", "probabs", ",", "rels_info", ")", ":", "\n", "            ", "doc_id", "=", "pair_info", "[", "'pmid'", "]", "\n", "arg1", "=", "pair_info", "[", "'entA'", "]", "\n", "arg2", "=", "pair_info", "[", "'entB'", "]", "\n", "\n"]]}